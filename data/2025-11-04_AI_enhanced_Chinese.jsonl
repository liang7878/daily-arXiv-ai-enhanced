{"id": "2511.00038", "pdf": "https://arxiv.org/pdf/2511.00038", "abs": "https://arxiv.org/abs/2511.00038", "authors": ["Suman Raj", "Radhika Mittal", "Rajiv Mayani", "Pawel Zuk", "Anirban Mandal", "Michael Zink", "Yogesh Simmhan", "Ewa Deelman"], "title": "AeroResQ: Edge-Accelerated UAV Framework for Scalable, Resilient and Collaborative Escape Route Planning in Wildfire Scenarios", "categories": ["cs.DC", "cs.RO"], "comment": "26 pages, 11 figures", "summary": "Drone fleets equipped with onboard cameras, computer vision, and Deep Neural\nNetwork (DNN) models present a powerful paradigm for real-time spatio-temporal\ndecision-making. In wildfire response, such drones play a pivotal role in\nmonitoring fire dynamics, supporting firefighter coordination, and facilitating\nsafe evacuation. In this paper, we introduce AeroResQ, an edge-accelerated UAV\nframework designed for scalable, resilient, and collaborative escape route\nplanning during wildfire scenarios. AeroResQ adopts a multi-layer orchestration\narchitecture comprising service drones (SDs) and coordinator drones (CDs), each\nperforming specialized roles. SDs survey fire-affected areas, detect stranded\nindividuals using onboard edge accelerators running fire detection and human\npose identification DNN models, and issue requests for assistance. CDs,\nequipped with lightweight data stores such as Apache IoTDB, dynamically\ngenerate optimal ground escape routes and monitor firefighter movements along\nthese routes. The framework proposes a collaborative path-planning approach\nbased on a weighted A* search algorithm, where CDs compute context-aware escape\npaths. AeroResQ further incorporates intelligent load-balancing and resilience\nmechanisms: CD failures trigger automated data redistribution across IoTDB\nreplicas, while SD failures initiate geo-fenced re-partitioning and\nreassignment of spatial workloads to operational SDs. We evaluate AeroResQ\nusing realistic wildfire emulated setup modeled on recent Southern California\nwildfires. Experimental results demonstrate that AeroResQ achieves a nominal\nend-to-end latency of <=500ms, much below the 2s request interval, while\nmaintaining over 98% successful task reassignment and completion, underscoring\nits feasibility for real-time, on-field deployment in emergency response and\nfirefighter safety operations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u91ce\u706b\u573a\u666f\u7684\u8fb9\u7f18\u52a0\u901f\u65e0\u4eba\u673a\u6846\u67b6AeroResQ\uff0c\u91c7\u7528\u591a\u5c42\u7f16\u6392\u67b6\u6784\uff0c\u6709\u534f\u4f5c\u8def\u5f84\u89c4\u5212\u548c\u8d1f\u8f7d\u5747\u8861\u673a\u5236\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5b9e\u65f6\u90e8\u7f72\u53ef\u884c\u6027\u3002", "motivation": "\u5728\u91ce\u706b\u54cd\u5e94\u4e2d\uff0c\u5229\u7528\u65e0\u4eba\u673a\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u6709\u5f39\u6027\u7684\u534f\u4f5c\u9003\u751f\u8def\u7ebf\u89c4\u5212\uff0c\u8f85\u52a9\u6d88\u9632\u51b3\u7b56\u548c\u4fdd\u969c\u4eba\u5458\u5b89\u5168\u3002", "method": "\u91c7\u7528\u591a\u5c42\u7f16\u6392\u67b6\u6784\uff0c\u5305\u62ec\u670d\u52a1\u65e0\u4eba\u673a\uff08SDs\uff09\u548c\u534f\u8c03\u65e0\u4eba\u673a\uff08CDs\uff09\uff0c\u4f7f\u7528\u52a0\u6743A*\u641c\u7d22\u7b97\u6cd5\u8fdb\u884c\u534f\u4f5c\u8def\u5f84\u89c4\u5212\uff0c\u7ed3\u5408\u667a\u80fd\u8d1f\u8f7d\u5747\u8861\u548c\u5f39\u6027\u673a\u5236\u3002", "result": "\u5728\u6a21\u62df\u91ce\u706b\u5b9e\u9a8c\u4e2d\uff0cAeroResQ\u7aef\u5230\u7aef\u5ef6\u8fdf\u4e0d\u8d85\u8fc7500ms\uff0c\u4efb\u52a1\u91cd\u65b0\u5206\u914d\u548c\u5b8c\u6210\u6210\u529f\u7387\u8d8598%\u3002", "conclusion": "AeroResQ\u5728\u5e94\u6025\u54cd\u5e94\u548c\u6d88\u9632\u5458\u5b89\u5168\u884c\u52a8\u7684\u5b9e\u65f6\u73b0\u573a\u90e8\u7f72\u5177\u6709\u53ef\u884c\u6027\u3002"}}
{"id": "2511.00263", "pdf": "https://arxiv.org/pdf/2511.00263", "abs": "https://arxiv.org/abs/2511.00263", "authors": ["Jinyuan Chen"], "title": "COOL Is Optimal in Error-Free Asynchronous Byzantine Agreement", "categories": ["cs.DC", "cs.CR", "cs.IT", "math.IT"], "comment": "25 pages", "summary": "COOL (Chen'21) is an error-free, information-theoretically secure Byzantine\nagreement (BA) protocol proven to achieve BA consensus in the synchronous\nsetting for an $\\ell$-bit message, with a total communication complexity of\n$O(\\max\\{n\\ell, nt \\log q\\})$ bits, four communication rounds in the worst\ncase, and a single invocation of a binary BA, under the optimal resilience\nassumption $n \\geq 3t + 1$ in a network of $n$ nodes, where up to $t$ nodes may\nbehave dishonestly. Here, $q$ denotes the alphabet size of the error correction\ncode used in the protocol.\n  In this work, we present an adaptive variant of COOL, called OciorACOOL,\nwhich achieves error-free, information-theoretically secure BA consensus in the\nasynchronous setting with total $O(\\max\\{n\\ell, n t \\log q\\})$ communication\nbits, $O(1)$ rounds, and a single invocation of an asynchronous binary BA\nprotocol, still under the optimal resilience assumption $n \\geq 3t + 1$.\nMoreover, OciorACOOL retains the same low-complexity, traditional $(n, k)$\nerror-correction encoding and decoding as COOL, with $k=t/3$.", "AI": {"tldr": "\u63d0\u51faCOOL\u534f\u8bae\u7684\u81ea\u9002\u5e94\u53d8\u4f53OciorACOOL\uff0c\u5728\u5f02\u6b65\u73af\u5883\u4e0b\u5b9e\u73b0\u65e0\u9519\u8bef\u3001\u4fe1\u606f\u8bba\u5b89\u5168\u7684\u62dc\u5360\u5ead\u534f\u8bae\u5171\u8bc6\uff0c\u590d\u6742\u5ea6\u4e0eCOOL\u76f8\u8fd1\u3002", "motivation": "\u5c06COOL\u534f\u8bae\u4ece\u540c\u6b65\u73af\u5883\u62d3\u5c55\u5230\u5f02\u6b65\u73af\u5883\uff0c\u5b9e\u73b0\u5f02\u6b65\u73af\u5883\u4e0b\u7684\u62dc\u5360\u5ead\u534f\u8bae\u5171\u8bc6\u3002", "method": "\u8bbe\u8ba1COOL\u534f\u8bae\u7684\u81ea\u9002\u5e94\u53d8\u4f53OciorACOOL\uff0c\u4f7f\u7528\u4e0eCOOL\u76f8\u540c\u7684\u4f4e\u590d\u6742\u5ea6\u9519\u8bef\u7ea0\u6b63\u7f16\u89e3\u7801\u3002", "result": "OciorACOOL\u5728\u5f02\u6b65\u73af\u5883\u4e0b\u5b9e\u73b0\u65e0\u9519\u8bef\u3001\u4fe1\u606f\u8bba\u5b89\u5168\u7684\u62dc\u5360\u5ead\u534f\u8bae\u5171\u8bc6\uff0c\u901a\u4fe1\u590d\u6742\u5ea6\u4e3a$O(\\max\\{n\\ell, n t \\log q\\})$\u6bd4\u7279\uff0c\u8f6e\u6570\u4e3a$O(1)$\uff0c\u53ea\u9700\u8c03\u7528\u4e00\u6b21\u5f02\u6b65\u4e8c\u8fdb\u5236BA\u534f\u8bae\u3002", "conclusion": "OciorACOOL\u53ef\u5728\u5f02\u6b65\u73af\u5883\u4e0b\u4ee5\u4e0eCOOL\u76f8\u8fd1\u7684\u590d\u6742\u5ea6\u5b9e\u73b0\u62dc\u5360\u5ead\u534f\u8bae\u5171\u8bc6\u3002"}}
{"id": "2511.00294", "pdf": "https://arxiv.org/pdf/2511.00294", "abs": "https://arxiv.org/abs/2511.00294", "authors": ["Lucas Almeida", "Maycon Peixoto"], "title": "Tetris: An SLA-aware Application Placement Strategy in the Edge-Cloud Continuum", "categories": ["cs.DC", "cs.NI", "68M14", "C.2.4"], "comment": "10 pages, 7 sections, 12 figures, 9 tables", "summary": "An Edge-Cloud Continuum integrates edge and cloud resources to provide a\nflexible and scalable infrastructure. This paradigm can minimize latency by\nprocessing data closer to the source at the edge while leveraging the vast\ncomputational power of the cloud for more intensive tasks. In this context,\nmodule application placement requires strategic allocation plans that align\nuser demands with infrastructure constraints, aiming for efficient resource\nuse. Therefore, we propose Tetris, an application placement strategy that\nutilizes a heuristic algorithm to distribute computational services across edge\nand cloud resources efficiently. Tetris prioritizes services based on SLA\nurgencies and resource efficiency to avoid system overloading. Our results\ndemonstrate that Tetris reduces SLA violations by approximately 76% compared to\nthe baseline method, which serves as a reference point for benchmarking\nperformance in this scenario. Therefore, Tetris offers an effective placement\napproach for managing latency-sensitive applications in Edge-Cloud Continuum\nenvironments, enhancing Quality of Service (QoS) for users.", "AI": {"tldr": "\u63d0\u51faTetris\u5e94\u7528\u653e\u7f6e\u7b56\u7565\uff0c\u53ef\u6709\u6548\u7ba1\u7406\u8fb9\u7f18\u4e91\u8fde\u7eed\u4f53\u73af\u5883\u4e2d\u5bf9\u5ef6\u8fdf\u654f\u611f\u7684\u5e94\u7528\uff0c\u51cf\u5c11SLA\u8fdd\u89c4\u3002", "motivation": "\u8fb9\u7f18\u4e91\u8fde\u7eed\u4f53\u9700\u7b56\u7565\u6027\u5206\u914d\u8ba1\u5212\u4f7f\u6a21\u5757\u5e94\u7528\u653e\u7f6e\u4e0e\u7528\u6237\u9700\u6c42\u548c\u57fa\u7840\u8bbe\u65bd\u7ea6\u675f\u76f8\u5339\u914d\uff0c\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u5229\u7528\u3002", "method": "\u63d0\u51faTetris\u5e94\u7528\u653e\u7f6e\u7b56\u7565\uff0c\u5229\u7528\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u57fa\u4e8eSLA\u7d27\u6025\u7a0b\u5ea6\u548c\u8d44\u6e90\u6548\u7387\u5bf9\u670d\u52a1\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "result": "Tetris\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5c06SLA\u8fdd\u89c4\u51cf\u5c11\u7ea676%\u3002", "conclusion": "Tetris\u662f\u7ba1\u7406\u8fb9\u7f18\u4e91\u8fde\u7eed\u4f53\u73af\u5883\u4e2d\u5bf9\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\u7684\u6709\u6548\u653e\u7f6e\u65b9\u6cd5\uff0c\u53ef\u63d0\u5347\u7528\u6237\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2511.00603", "pdf": "https://arxiv.org/pdf/2511.00603", "abs": "https://arxiv.org/abs/2511.00603", "authors": ["Yubo Wang", "Yubo Cui", "Tuo Shi", "Danyang Li", "Wenxin Li", "Lide Suo", "Tao Wang", "Xin Xie"], "title": "EPARA: Parallelizing Categorized AI Inference in Edge Clouds", "categories": ["cs.DC", "cs.AI", "cs.NI", "68T05", "I.2.11"], "comment": "15 pages,20 figures", "summary": "With the increasing adoption of AI applications such as large language models\nand computer vision AI, the computational demands on AI inference systems are\ncontinuously rising, making the enhancement of task processing capacity using\nexisting hardware a primary objective in edge clouds. We propose EPARA, an\nend-to-end AI parallel inference framework in edge, aimed at enhancing the edge\nAI serving capability. Our key idea is to categorize tasks based on their\nsensitivity to latency/frequency and requirement for GPU resources, thereby\nachieving both request-level and service-level task-resource allocation. EPARA\nconsists of three core components: 1) a task-categorized parallelism allocator\nthat decides the parallel mode of each task, 2) a distributed request handler\nthat performs the calculation for the specific request, and 3) a state-aware\nscheduler that periodically updates service placement in edge clouds. We\nimplement a EPARA prototype and conduct a case study on the EPARA operation for\nLLMs and segmentation tasks. Evaluation through testbed experiments involving\nedge servers, embedded devices, and microcomputers shows that EPARA achieves up\nto 2.1$\\times$ higher goodput in production workloads compared to prior\nframeworks, while adapting to various edge AI inference tasks.", "AI": {"tldr": "\u63d0\u51fa\u8fb9\u7f18\u7aef\u7aef\u5230\u7aefAI\u5e76\u884c\u63a8\u7406\u6846\u67b6EPARA\uff0c\u7ecf\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u5148\u524d\u6846\u67b6\uff0c\u5728\u751f\u4ea7\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53472.1\u500d\uff0c\u80fd\u9002\u5e94\u591a\u79cd\u8fb9\u7f18AI\u63a8\u7406\u4efb\u52a1\u3002", "motivation": "\u968f\u7740AI\u5e94\u7528\u7684\u5e7f\u6cdb\u91c7\u7528\uff0cAI\u63a8\u7406\u7cfb\u7edf\u8ba1\u7b97\u9700\u6c42\u4e0d\u65ad\u4e0a\u5347\uff0c\u9700\u5229\u7528\u73b0\u6709\u786c\u4ef6\u63d0\u5347\u8fb9\u7f18\u4e91\u4efb\u52a1\u5904\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faEPARA\u6846\u67b6\uff0c\u6309\u4efb\u52a1\u5bf9\u5ef6\u8fdf/\u9891\u7387\u7684\u654f\u611f\u6027\u548cGPU\u8d44\u6e90\u9700\u6c42\u5bf9\u4efb\u52a1\u5206\u7c7b\uff0c\u5b9e\u73b0\u8bf7\u6c42\u7ea7\u548c\u670d\u52a1\u7ea7\u4efb\u52a1\u8d44\u6e90\u5206\u914d\uff0c\u6846\u67b6\u5305\u542b\u4efb\u52a1\u5206\u7c7b\u5e76\u884c\u5206\u914d\u5668\u3001\u5206\u5e03\u5f0f\u8bf7\u6c42\u5904\u7406\u7a0b\u5e8f\u548c\u72b6\u6001\u611f\u77e5\u8c03\u5ea6\u5668\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u3002", "result": "\u901a\u8fc7\u6d89\u53ca\u8fb9\u7f18\u670d\u52a1\u5668\u3001\u5d4c\u5165\u5f0f\u8bbe\u5907\u548c\u5fae\u578b\u8ba1\u7b97\u673a\u7684\u6d4b\u8bd5\u5e73\u53f0\u5b9e\u9a8c\u8bc4\u4f30\uff0cEPARA\u5728\u751f\u4ea7\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u541e\u5410\u91cf\u6bd4\u5148\u524d\u6846\u67b6\u6700\u9ad8\u63d0\u53472.1\u500d\u3002", "conclusion": "EPARA\u80fd\u63d0\u5347\u8fb9\u7f18AI\u670d\u52a1\u80fd\u529b\uff0c\u9002\u5e94\u5404\u79cd\u8fb9\u7f18AI\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2511.00072", "pdf": "https://arxiv.org/pdf/2511.00072", "abs": "https://arxiv.org/abs/2511.00072", "authors": ["Pradeep M", "Ritesh Pallod", "Satyen Abrol", "Muthu Raman", "Ian Anderson"], "title": "LookSync: Large-Scale Visual Product Search System for AI-Generated Fashion Looks", "categories": ["cs.IR", "cs.AI", "cs.CV", "cs.LG"], "comment": "4 pages, 5 figures. Accepted at the International Conference on Data\n  Science (IKDD CODS 2025), Demonstration Track. Demo video:\n  https://youtu.be/DZdlWmTUwjc", "summary": "Generative AI is reshaping fashion by enabling virtual looks and avatars\nmaking it essential to find real products that best match AI-generated styles.\nWe propose an end-to-end product search system that has been deployed in a\nreal-world, internet scale which ensures that AI-generated looks presented to\nusers are matched with the most visually and semantically similar products from\nthe indexed vector space. The search pipeline is composed of four key\ncomponents: query generation, vectorization, candidate retrieval, and reranking\nbased on AI-generated looks. Recommendation quality is evaluated using\nhuman-judged accuracy scores. The system currently serves more than 350,000 AI\nLooks in production per day, covering diverse product categories across global\nmarkets of over 12 million products. In our experiments, we observed that\nacross multiple annotators and categories, CLIP outperformed alternative models\nby a small relative margin of 3--7\\% in mean opinion scores. These\nimprovements, though modest in absolute numbers, resulted in noticeably better\nuser perception matches, establishing CLIP as the most reliable backbone for\nproduction deployment.", "AI": {"tldr": "\u63d0\u51fa\u7aef\u5230\u7aef\u4ea7\u54c1\u641c\u7d22\u7cfb\u7edf\uff0c\u5df2\u5728\u771f\u5b9e\u4e92\u8054\u7f51\u73af\u5883\u90e8\u7f72\uff0c\u7528\u4eba\u5de5\u5224\u65ad\u8bc4\u4f30\u63a8\u8350\u8d28\u91cf\uff0cCLIP \u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u751f\u6210\u5f0f AI \u91cd\u5851\u65f6\u5c1a\uff0c\u9700\u627e\u5230\u4e0e AI \u751f\u6210\u98ce\u683c\u5339\u914d\u7684\u771f\u5b9e\u4ea7\u54c1\u3002", "method": "\u6784\u5efa\u5305\u542b\u67e5\u8be2\u751f\u6210\u3001\u5411\u91cf\u5316\u3001\u5019\u9009\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u7684\u641c\u7d22\u7ba1\u9053\uff0c\u7528\u4eba\u5de5\u5224\u65ad\u51c6\u786e\u6027\u5206\u6570\u8bc4\u4f30\u63a8\u8350\u8d28\u91cf\u3002", "result": "\u7cfb\u7edf\u6bcf\u5929\u670d\u52a1\u8d85 35 \u4e07 AI \u9020\u578b\uff0c\u8986\u76d6\u8d85 1200 \u4e07\u4ea7\u54c1\uff1b\u5b9e\u9a8c\u4e2d CLIP \u5728\u5e73\u5747\u610f\u89c1\u5f97\u5206\u4e0a\u6bd4\u5176\u4ed6\u6a21\u578b\u9ad8 3 - 7%\u3002", "conclusion": "CLIP \u662f\u751f\u4ea7\u90e8\u7f72\u4e2d\u6700\u53ef\u9760\u7684\u4e3b\u5e72\u6a21\u578b\u3002"}}
{"id": "2511.00015", "pdf": "https://arxiv.org/pdf/2511.00015", "abs": "https://arxiv.org/abs/2511.00015", "authors": ["Swapnoneel Roy", "Asai Asaithambi", "Debajyoti Mukhopadhyay"], "title": "Sorting by Strip Swaps is NP-Hard", "categories": ["cs.DS", "cs.AI", "cs.CC"], "comment": "4 pages", "summary": "We show that \\emph{Sorting by Strip Swaps} (SbSS) is NP-hard by a polynomial\nreduction of \\emph{Block Sorting}. The key idea is a local gadget, a\n\\emph{cage}, that replaces every decreasing adjacency $(a_i,a_{i+1})$ by a\nguarded triple $a_i,m_i,a_{i+1}$ enclosed by guards $L_i,U_i$, so the only\ndecreasing adjacencies are the two inside the cage. Small \\emph{hinge} gadgets\ncouple adjacent cages that share an element and enforce that a strip swap that\nremoves exactly two adjacencies corresponds bijectively to a block move that\nremoves exactly one decreasing adjacency in the source permutation. This yields\na clean equivalence between exact SbSS schedules and perfect block schedules,\nestablishing NP-hardness.", "AI": {"tldr": "\u901a\u8fc7\u5757\u6392\u5e8f\u7684\u591a\u9879\u5f0f\u7ea6\u7b80\u8bc1\u660e\u6392\u5e8f\u6761\u4ea4\u6362\u95ee\u9898\uff08SbSS\uff09\u662fNP\u96be\u7684\u3002", "motivation": "\u8bc1\u660e\u6392\u5e8f\u6761\u4ea4\u6362\u95ee\u9898\uff08SbSS\uff09\u7684\u590d\u6742\u5ea6", "method": "\u4f7f\u7528\u591a\u9879\u5f0f\u7ea6\u7b80\uff0c\u901a\u8fc7\u5c40\u90e8\u5c0f\u88c5\u7f6e\u201c\u7b3c\u5b50\u201d\u548c\u201c\u94f0\u94fe\u201d\u5c0f\u88c5\u7f6e\u5c06\u95ee\u9898\u8f6c\u5316\uff0c\u5efa\u7acb\u6761\u4ea4\u6362\u8c03\u5ea6\u548c\u5757\u8c03\u5ea6\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "result": "\u5efa\u7acb\u4e86\u7cbe\u786e\u7684\u6761\u4ea4\u6362\u8c03\u5ea6\u548c\u5b8c\u7f8e\u5757\u8c03\u5ea6\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "conclusion": "\u8bc1\u660e\u4e86\u6392\u5e8f\u6761\u4ea4\u6362\u95ee\u9898\uff08SbSS\uff09\u662fNP\u96be\u7684\u3002"}}
{"id": "2511.00020", "pdf": "https://arxiv.org/pdf/2511.00020", "abs": "https://arxiv.org/abs/2511.00020", "authors": ["Suhasnadh Reddy Veluru", "Sai Teja Erukude", "Viswa Chaitanya Marella"], "title": "Multimodal Detection of Fake Reviews using BERT and ResNet-50", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "Published in IEEE", "summary": "In the current digital commerce landscape, user-generated reviews play a\ncritical role in shaping consumer behavior, product reputation, and platform\ncredibility. However, the proliferation of fake or misleading reviews often\ngenerated by bots, paid agents, or AI models poses a significant threat to\ntrust and transparency within review ecosystems. Existing detection models\nprimarily rely on unimodal, typically textual, data and therefore fail to\ncapture semantic inconsistencies across different modalities. To address this\ngap, a robust multimodal fake review detection framework is proposed,\nintegrating textual features encoded with BERT and visual features extracted\nusing ResNet-50. These representations are fused through a classification head\nto jointly predict review authenticity. To support this approach, a curated\ndataset comprising 21,142 user-uploaded images across food delivery,\nhospitality, and e-commerce domains was utilized. Experimental results indicate\nthat the multimodal model outperforms unimodal baselines, achieving an F1-score\nof 0.934 on the test set. Additionally, the confusion matrix and qualitative\nanalysis highlight the model's ability to detect subtle inconsistencies, such\nas exaggerated textual praise paired with unrelated or low-quality images,\ncommonly found in deceptive content. This study demonstrates the critical role\nof multimodal learning in safeguarding digital trust and offers a scalable\nsolution for content moderation across various online platforms.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u865a\u5047\u8bc4\u8bba\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u6587\u672c\u4e0e\u89c6\u89c9\u7279\u5f81\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\uff0c\u8bc1\u660e\u591a\u6a21\u6001\u5b66\u4e60\u5bf9\u7ef4\u62a4\u6570\u5b57\u4fe1\u4efb\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u865a\u5047\u8bc4\u8bba\u5a01\u80c1\u8bc4\u8bba\u751f\u6001\u7cfb\u7edf\u7684\u4fe1\u4efb\u548c\u900f\u660e\u5ea6\uff0c\u73b0\u6709\u68c0\u6d4b\u6a21\u578b\u591a\u4f9d\u8d56\u5355\u6a21\u6001\u6570\u636e\uff0c\u65e0\u6cd5\u6355\u6349\u4e0d\u540c\u6a21\u6001\u95f4\u8bed\u4e49\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u865a\u5047\u8bc4\u8bba\u68c0\u6d4b\u6846\u67b6\uff0c\u7528BERT\u7f16\u7801\u6587\u672c\u7279\u5f81\uff0cResNet - 50\u63d0\u53d6\u89c6\u89c9\u7279\u5f81\uff0c\u901a\u8fc7\u5206\u7c7b\u5934\u878d\u5408\u8868\u793a\u6765\u9884\u6d4b\u8bc4\u8bba\u771f\u5b9e\u6027\uff0c\u4f7f\u7528\u542b21,142\u5f20\u7528\u6237\u4e0a\u4f20\u56fe\u7247\u7684\u6570\u636e\u96c6\u3002", "result": "\u591a\u6a21\u6001\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0aF1\u5206\u6570\u8fbe0.934\uff0c\u4f18\u4e8e\u5355\u6a21\u6001\u57fa\u7ebf\uff0c\u6df7\u6dc6\u77e9\u9635\u548c\u5b9a\u6027\u5206\u6790\u663e\u793a\u5176\u80fd\u68c0\u6d4b\u51fa\u6b3a\u9a97\u6027\u5185\u5bb9\u4e2d\u7684\u7ec6\u5fae\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u591a\u6a21\u6001\u5b66\u4e60\u5bf9\u7ef4\u62a4\u6570\u5b57\u4fe1\u4efb\u81f3\u5173\u91cd\u8981\uff0c\u8be5\u6846\u67b6\u4e3a\u5404\u5728\u7ebf\u5e73\u53f0\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00665", "pdf": "https://arxiv.org/pdf/2511.00665", "abs": "https://arxiv.org/abs/2511.00665", "authors": ["Jos\u00e9 \u00c1ngel Islas Anguiano", "Andr\u00e9s Garc\u00eda-Medina"], "title": "Technical Analysis Meets Machine Learning: Bitcoin Evidence", "categories": ["q-fin.CP"], "comment": null, "summary": "In this note, we compare Bitcoin trading performance using two machine\nlearning models-Light Gradient Boosting Machine (LightGBM) and Long Short-Term\nMemory (LSTM)-and two technical analysis-based strategies: Exponential Moving\nAverage (EMA) crossover and a combination of Moving Average\nConvergence/Divergence with the Average Directional Index (MACD+ADX). The\nobjective is to evaluate how trading signals can be used to maximize profits in\nthe Bitcoin market. This comparison was motivated by the U.S. Securities and\nExchange Commission's (SEC) approval of the first spot Bitcoin exchange-traded\nfunds (ETFs) on 2024-01-10. Our results show that the LSTM model achieved a\ncumulative return of approximately 65.23% in under a year, significantly\noutperforming LightGBM, the EMA and MACD+ADX strategies, as well as the\nbaseline buy-and-hold. This study highlights the potential for deeper\nintegration of machine learning and technical analysis in the rapidly evolving\ncryptocurrency landscape.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u6bd4\u7279\u5e01\u4ea4\u6613\u8868\u73b0\uff0cLSTM\u6a21\u578b\u5e74\u6536\u76ca\u7ea665.23%\uff0c\u4f18\u4e8e\u5176\u4ed6\u7b56\u7565\uff0c\u51f8\u663e\u673a\u5668\u5b66\u4e60\u4e0e\u6280\u672f\u5206\u6790\u7ed3\u5408\u6f5c\u529b\u3002", "motivation": "\u53d7\u7f8e\u56fd\u8bc1\u5238\u4ea4\u6613\u59d4\u5458\u4f1a2024\u5e741\u670810\u65e5\u6279\u51c6\u9996\u53ea\u73b0\u8d27\u6bd4\u7279\u5e01ETF\u7684\u63a8\u52a8\uff0c\u8bc4\u4f30\u4ea4\u6613\u4fe1\u53f7\u5728\u6bd4\u7279\u5e01\u5e02\u573a\u83b7\u5229\u80fd\u529b\u3002", "method": "\u4f7f\u7528LightGBM\u548cLSTM\u4e24\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u53caEMA\u4ea4\u53c9\u548cMACD+ADX\u4e24\u4e2a\u6280\u672f\u5206\u6790\u7b56\u7565\u8fdb\u884c\u6bd4\u7279\u5e01\u4ea4\u6613\u8868\u73b0\u6bd4\u8f83\u3002", "result": "LSTM\u6a21\u578b\u5728\u4e0d\u5230\u4e00\u5e74\u7684\u65f6\u95f4\u91cc\u5b9e\u73b0\u7ea665.23%\u7684\u7d2f\u8ba1\u56de\u62a5\uff0c\u663e\u8457\u4f18\u4e8eLightGBM\u3001EMA\u3001MACD+ADX\u7b56\u7565\u548c\u4e70\u5165\u6301\u6709\u57fa\u51c6\u3002", "conclusion": "\u5f3a\u8c03\u5728\u5feb\u901f\u53d1\u5c55\u7684\u52a0\u5bc6\u8d27\u5e01\u9886\u57df\uff0c\u673a\u5668\u5b66\u4e60\u548c\u6280\u672f\u5206\u6790\u66f4\u6df1\u5165\u878d\u5408\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00074", "pdf": "https://arxiv.org/pdf/2511.00074", "abs": "https://arxiv.org/abs/2511.00074", "authors": ["Richard Osuagwu", "Thomas Cook", "Maraim Masoud", "Koustav Ghosal", "Riccardo Mattivi"], "title": "ScaleCall - Agentic Tool Calling at Scale for Fintech: Challenges, Methods, and Deployment Insights", "categories": ["cs.SE"], "comment": null, "summary": "While Large Language Models (LLMs) excel at tool calling, deploying these\ncapabilities in regulated enterprise environments such as fintech presents\nunique challenges due to on-premises constraints, regulatory compliance\nrequirements, and the need to disambiguate large, functionally overlapping\ntoolsets. In this paper, we present a comprehensive study of tool retrieval\nmethods for enterprise environments through the development and deployment of\nScaleCall, a prototype tool-calling framework within Mastercard designed for\norchestrating internal APIs and automating data engineering workflows. We\nsystematically evaluate embedding-based retrieval, prompt-based listwise\nranking, and hybrid approaches, revealing that method effectiveness depends\nheavily on domain-specific factors rather than inherent algorithmic\nsuperiority. Through empirical investigation on enterprise-derived benchmarks,\nwe find that embedding-based methods offer superior latency for large tool\nrepositories, while listwise ranking provides better disambiguation for\noverlapping functionalities, with hybrid approaches showing promise in specific\ncontexts. We integrate our findings into ScaleCall's flexible architecture and\nvalidate the framework through real-world deployment in Mastercard's regulated\nenvironment. Our work provides practical insights into the trade-offs between\nretrieval accuracy, computational efficiency, and operational requirements,\ncontributing to the understanding of tool-calling system design for enterprise\napplications in regulated industries.", "AI": {"tldr": "\u672c\u6587\u56f4\u7ed5\u4f01\u4e1a\u73af\u5883\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u8c03\u7528\u95ee\u9898\uff0c\u5f00\u53d1ScaleCall\u6846\u67b6\u8bc4\u4f30\u591a\u79cd\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\uff0c\u53d1\u73b0\u65b9\u6cd5\u6709\u6548\u6027\u4f9d\u8d56\u7279\u5b9a\u9886\u57df\u56e0\u7d20\uff0c\u4e3a\u76d1\u7ba1\u884c\u4e1a\u4f01\u4e1a\u5e94\u7528\u7684\u5de5\u5177\u8c03\u7528\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u5728\u53d7\u76d1\u7ba1\u7684\u4f01\u4e1a\u73af\u5883\uff08\u5982\u91d1\u878d\u79d1\u6280\uff09\u4e2d\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u9700\u8981\u7814\u7a76\u5408\u9002\u7684\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u5e76\u90e8\u7f72ScaleCall\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u5217\u8868\u6392\u5e8f\u548c\u6df7\u5408\u65b9\u6cd5\u3002", "result": "\u65b9\u6cd5\u6709\u6548\u6027\u5f88\u5927\u7a0b\u5ea6\u53d6\u51b3\u4e8e\u7279\u5b9a\u9886\u57df\u56e0\u7d20\uff0c\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u5728\u5927\u578b\u5de5\u5177\u5e93\u4e2d\u5ef6\u8fdf\u66f4\u4f4e\uff0c\u5217\u8868\u6392\u5e8f\u5728\u529f\u80fd\u91cd\u53e0\u65f6\u6d88\u6b67\u6548\u679c\u66f4\u597d\uff0c\u6df7\u5408\u65b9\u6cd5\u5728\u7279\u5b9a\u573a\u666f\u6709\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u76d1\u7ba1\u884c\u4e1a\u4f01\u4e1a\u5e94\u7528\u7684\u5de5\u5177\u8c03\u7528\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5173\u4e8e\u68c0\u7d22\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u64cd\u4f5c\u8981\u6c42\u4e4b\u95f4\u6743\u8861\u7684\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2511.00002", "pdf": "https://arxiv.org/pdf/2511.00002", "abs": "https://arxiv.org/abs/2511.00002", "authors": ["Yurun Wu", "Yousong Sun", "Burkhard Wunsche", "Jia Wang", "Elliott Wen"], "title": "VRScout: Towards Real-Time, Autonomous Testing of Virtual Reality Games", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Virtual Reality (VR) has rapidly become a mainstream platform for gaming and\ninteractive experiences, yet ensuring the quality, safety, and appropriateness\nof VR content remains a pressing challenge. Traditional human-based quality\nassurance is labor-intensive and cannot scale with the industry's rapid growth.\nWhile automated testing has been applied to traditional 2D and 3D games,\nextending it to VR introduces unique difficulties due to high-dimensional\nsensory inputs and strict real-time performance requirements. We present\nVRScout, a deep learning-based agent capable of autonomously navigating VR\nenvironments and interacting with virtual objects in a human-like and real-time\nmanner. VRScout learns from human demonstrations using an enhanced Action\nChunking Transformer that predicts multi-step action sequences. This enables\nour agent to capture higher-level strategies and generalize across diverse\nenvironments. To balance responsiveness and precision, we introduce a\ndynamically adjustable sliding horizon that adapts the agent's temporal context\nat runtime. We evaluate VRScout on commercial VR titles and show that it\nachieves expert-level performance with only limited training data, while\nmaintaining real-time inference at 60 FPS on consumer-grade hardware. These\nresults position VRScout as a practical and scalable framework for automated VR\ngame testing, with direct applications in both quality assurance and safety\nauditing.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684VRScout\u7528\u4e8e\u81ea\u52a8\u6d4b\u8bd5VR\u6e38\u620f\uff0c\u5728\u5546\u4e1aVR\u6e38\u620f\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u53ef\u7528\u4e8e\u8d28\u91cf\u4fdd\u8bc1\u548c\u5b89\u5168\u5ba1\u8ba1\u3002", "motivation": "VR\u5185\u5bb9\u8d28\u91cf\u3001\u5b89\u5168\u548c\u9002\u7528\u6027\u4fdd\u969c\u9762\u4e34\u6311\u6218\uff0c\u4f20\u7edf\u4eba\u5de5\u8d28\u91cf\u4fdd\u8bc1\u96be\u6269\u5c55\uff0c\u81ea\u52a8\u5316\u6d4b\u8bd5\u7528\u4e8eVR\u6709\u72ec\u7279\u56f0\u96be\u3002", "method": "\u63d0\u51faVRScout\uff0c\u7528\u589e\u5f3a\u7684Action Chunking Transformer\u4ece\u4eba\u7c7b\u6f14\u793a\u4e2d\u5b66\u4e60\u9884\u6d4b\u591a\u6b65\u52a8\u4f5c\u5e8f\u5217\uff0c\u5f15\u5165\u52a8\u6001\u53ef\u8c03\u6ed1\u52a8\u89c6\u754c\u5e73\u8861\u54cd\u5e94\u6027\u548c\u7cbe\u5ea6\u3002", "result": "\u5728\u5546\u4e1aVR\u6e38\u620f\u4e0a\u8bc4\u4f30\uff0c\u4ec5\u7528\u6709\u9650\u8bad\u7ec3\u6570\u636e\u8fbe\u5230\u4e13\u5bb6\u7ea7\u8868\u73b0\uff0c\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u4ee560 FPS\u5b9e\u65f6\u63a8\u7406\u3002", "conclusion": "VRScout\u662f\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316VR\u6e38\u620f\u6d4b\u8bd5\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u8d28\u91cf\u4fdd\u8bc1\u548c\u5b89\u5168\u5ba1\u8ba1\u3002"}}
{"id": "2511.00319", "pdf": "https://arxiv.org/pdf/2511.00319", "abs": "https://arxiv.org/abs/2511.00319", "authors": ["Leonel Corado", "S\u00e9rgio Godinho", "Carlos Alberto Silva", "Juan Guerra-Hern\u00e1ndez", "Francesco Val\u00e9rioa", "Teresa Gon\u00e7alves", "Pedro Salgueiro"], "title": "GEDICorrect: A Scalable Python Tool for Orbit-, Beam-, and Footprint-Level GEDI Geolocation Correction", "categories": ["cs.CE", "physics.geo-ph"], "comment": null, "summary": "Accurate geolocation is essential for the reliable use of GEDI LiDAR data in\nfootprint-scale applications such as aboveground biomass modeling, data fusion,\nand ecosystem monitoring. However, residual geolocation errors arising from\nboth systematic biases and random ISS-induced jitter can significantly affect\nthe accuracy of derived vegetation and terrain metrics. The main goal of this\nstudy is to develop and evaluate a flexible, computationally efficient\nframework (GEDICorrect) that enables geolocation correction of GEDI data at the\norbit, beam, and footprint levels. The framework integrates existing GEDI\nSimulator modules (gediRat and gediMetrics) and extends their functionality\nwith flexible correction logic, multiple similarity metrics, adaptive footprint\nclustering, and optimized I/O handling. Using the Kullback--Leibler divergence\nas the waveform similarity metric, GEDICorrect improved canopy height (RH95)\naccuracy from $R^2 = 0.61$ (uncorrected) to 0.74 with the orbit-level\ncorrection, and up to $R^2 = 0.78$ with the footprint-level correction,\nreducing RMSE from 2.62~m ($rRMSE = 43.13\\%$) to 2.12~m ($rRMSE = 34.97\\%$) at\nthe orbit level, and 2.01~m ($rRMSE = 33.05\\%$) at the footprint level. Terrain\nelevation accuracy also improved, decreasing RMSE by 0.34~m relative to\nuncorrected data and by 0.37~m compared to the GEDI Simulator baseline. In\nterms of computational efficiency, GEDICorrect achieved a $\\sim2.4\\times$\nspeedup over the GEDI Simulator in single-process mode (reducing runtime from\n$\\sim84$~h to $\\sim35$~h) and scaled efficiently to 24 cores, completing the\nsame task in $\\sim4.3$~h -- an overall $\\sim19.5\\times$ improvement.\nGEDICorrect offers a robust and scalable solution for improving GEDI\ngeolocation accuracy while maintaining full compatibility with standard GEDI\ndata products.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u8bc4\u4f30\u4e86GEDICorrect\u6846\u67b6\u7528\u4e8e\u6821\u6b63GEDI\u6570\u636e\u5730\u7406\u5b9a\u4f4d\uff0c\u63d0\u5347\u4e86\u6570\u636e\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "GEDI LiDAR\u6570\u636e\u5728\u5e94\u7528\u4e2d\u5b58\u5728\u5730\u7406\u5b9a\u4f4d\u8bef\u5dee\uff0c\u5f71\u54cd\u884d\u751f\u6307\u6807\u7cbe\u5ea6\uff0c\u9700\u5f00\u53d1\u6821\u6b63\u6846\u67b6\u3002", "method": "\u5f00\u53d1GEDICorrect\u6846\u67b6\uff0c\u96c6\u6210\u73b0\u6709GEDI Simulator\u6a21\u5757\u5e76\u6269\u5c55\u529f\u80fd\uff0c\u91c7\u7528Kullback - Leibler\u6563\u5ea6\u4f5c\u4e3a\u6ce2\u5f62\u76f8\u4f3c\u5ea6\u6307\u6807\u3002", "result": "\u5728\u8f68\u9053\u548c\u8db3\u8ff9\u7ea7\u522b\u6821\u6b63\u540e\uff0c\u51a0\u5c42\u9ad8\u5ea6\u7cbe\u5ea6\u63d0\u9ad8\uff0c\u5730\u5f62\u9ad8\u7a0b\u7cbe\u5ea6\u6539\u5584\uff0c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u5355\u8fdb\u7a0b\u6a21\u5f0f\u4e0b\u901f\u5ea6\u63d0\u5347\u7ea62.4\u500d\uff0c24\u6838\u65f6\u6574\u4f53\u63d0\u5347\u7ea619.5\u500d\u3002", "conclusion": "GEDICorrect\u662f\u63d0\u5347GEDI\u5730\u7406\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e0e\u6807\u51c6GEDI\u6570\u636e\u4ea7\u54c1\u517c\u5bb9\u3002"}}
{"id": "2511.00342", "pdf": "https://arxiv.org/pdf/2511.00342", "abs": "https://arxiv.org/abs/2511.00342", "authors": ["Hendrio Braganca", "Diego Kreutz", "Vanderson Rocha", "Joner Assolin", "and Eduardo Feitosa"], "title": "MH-1M: A 1.34 Million-Sample Comprehensive Multi-Feature Android Malware Dataset for Machine Learning, Deep Learning, Large Language Models, and Threat Intelligence Research", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.PF", "68T01", "I.2; E.0"], "comment": "17 pages, 7 figures, 13 tables, submitted to the Scientific Data\n  journal published by Nature Research", "summary": "We present MH-1M, one of the most comprehensive and up-to-date datasets for\nadvanced Android malware research. The dataset comprises 1,340,515\napplications, encompassing a wide range of features and extensive metadata. To\nensure accurate malware classification, we employ the VirusTotal API,\nintegrating multiple detection engines for comprehensive and reliable\nassessment. Our GitHub, Figshare, and Harvard Dataverse repositories provide\nopen access to the processed dataset and its extensive supplementary metadata,\ntotaling more than 400 GB of data and including the outputs of the feature\nextraction pipeline as well as the corresponding VirusTotal reports. Our\nfindings underscore the MH-1M dataset's invaluable role in understanding the\nevolving landscape of malware.", "AI": {"tldr": "\u4ecb\u7ecdMH - 1M\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u9ad8\u7ea7\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u7814\u7a76\uff0c\u5305\u542b\u5927\u91cf\u5e94\u7528\u548c\u5143\u6570\u636e\uff0c\u7528VirusTotal API\u5206\u7c7b\uff0c\u6570\u636e\u516c\u5f00\u53ef\u8bbf\u95ee\u3002", "motivation": "\u63d0\u4f9b\u5168\u9762\u4e14\u6700\u65b0\u7684\u6570\u636e\u96c6\u7528\u4e8e\u9ad8\u7ea7\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u7814\u7a76\u3002", "method": "\u4f7f\u7528VirusTotal API\uff0c\u96c6\u6210\u591a\u4e2a\u68c0\u6d4b\u5f15\u64ce\u8fdb\u884c\u6076\u610f\u8f6f\u4ef6\u5206\u7c7b\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b1340515\u4e2a\u5e94\u7528\u7684MH - 1M\u6570\u636e\u96c6\uff0c\u6570\u636e\u548c\u5143\u6570\u636e\u8d85400GB\u4e14\u516c\u5f00\u53ef\u8bbf\u95ee\u3002", "conclusion": "MH - 1M\u6570\u636e\u96c6\u5bf9\u7406\u89e3\u6076\u610f\u8f6f\u4ef6\u6f14\u53d8\u683c\u5c40\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.00042", "pdf": "https://arxiv.org/pdf/2511.00042", "abs": "https://arxiv.org/abs/2511.00042", "authors": ["Sreeja Singh", "Tamal Ghosh"], "title": "Bio-Inspired Neuron Synapse Optimization for Adaptive Learning and Smart Decision-Making", "categories": ["cs.NE"], "comment": "9 pages, 5 figures", "summary": "Purpose: Optimization challenges in science, engineering, and real-world\napplications often involve complex, high-dimensional, and multimodal search\nspaces. Traditional optimization methods frequently struggle with local optima\nentrapment, slow convergence, and inefficiency in large-scale environments.\nThis study aims to address these limitations by proposing a novel optimization\nalgorithm inspired by neural mechanisms. Design/methodology/approach: The paper\nintroduces Neuron Synapse Optimization (NSO), a new metaheuristic algorithm\ninspired by neural interactions. NSO features key innovations such as\nfitness-based synaptic weight updates to improve search influence, adaptive\npruning to minimize computational overhead, and dual guidance from global and\nlocal best solutions to balance exploration and exploitation. The algorithm was\nbenchmarked against popular metaheuristics and the recently published\nHippopotamus Optimization Algorithm (HOA) using the CEC 2014 test suite,\nencompassing unimodal, multimodal, and composition function landscapes.\nFindings: Benchmark results reveal that NSO consistently outperforms HOA and\nother major algorithms in terms of convergence speed, robustness, and\nscalability. NSO demonstrates superior adaptability and efficiency,\nparticularly in complex, high-dimensional search spaces. Originality: NSO\nintroduces a unique blend of neural-inspired mechanisms with dynamic resource\nallocation, setting it apart from existing algorithms. Its innovative design\nenhances search performance while reducing computational cost. With promising\napplications in technology, healthcare, data science, and engineering, NSO\npaves the way for future research into dynamic and multi-objective\noptimization, machine learning hyperparameter tuning, and real-world\nengineering design problems.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u53d7\u795e\u7ecf\u673a\u5236\u542f\u53d1\u7684\u795e\u7ecf\u5143\u7a81\u89e6\u4f18\u5316\u7b97\u6cd5\uff08NSO\uff09\uff0c\u7ecfCEC 2014\u6d4b\u8bd5\u96c6\u9a8c\u8bc1\uff0cNSO\u5728\u6536\u655b\u901f\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u7b97\u6cd5\uff0c\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u590d\u6742\u9ad8\u7ef4\u591a\u5cf0\u641c\u7d22\u7a7a\u95f4\u4e2d\u5b58\u5728\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3001\u6536\u655b\u6162\u548c\u6548\u7387\u4f4e\u7b49\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u3002", "method": "\u63d0\u51faNSO\u7b97\u6cd5\uff0c\u6709\u57fa\u4e8e\u9002\u5e94\u5ea6\u7684\u7a81\u89e6\u6743\u91cd\u66f4\u65b0\u3001\u81ea\u9002\u5e94\u526a\u679d\u3001\u5168\u5c40\u548c\u5c40\u90e8\u6700\u4f18\u89e3\u53cc\u91cd\u5f15\u5bfc\u7b49\u521b\u65b0\u70b9\uff0c\u5e76\u4f7f\u7528CEC 2014\u6d4b\u8bd5\u96c6\u4e0e\u5176\u4ed6\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u5bf9\u6bd4\u3002", "result": "NSO\u5728\u6536\u655b\u901f\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u59cb\u7ec8\u4f18\u4e8eHOA\u548c\u5176\u4ed6\u4e3b\u8981\u7b97\u6cd5\uff0c\u5728\u590d\u6742\u9ad8\u7ef4\u641c\u7d22\u7a7a\u95f4\u4e2d\u9002\u5e94\u6027\u548c\u6548\u7387\u66f4\u4f73\u3002", "conclusion": "NSO\u7ed3\u5408\u795e\u7ecf\u542f\u53d1\u673a\u5236\u4e0e\u52a8\u6001\u8d44\u6e90\u5206\u914d\uff0c\u63d0\u5347\u641c\u7d22\u6027\u80fd\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u591a\u65b9\u9762\u7814\u7a76\u548c\u5b9e\u9645\u5de5\u7a0b\u95ee\u9898\u5f00\u8f9f\u9053\u8def\u3002"}}
{"id": "2511.00290", "pdf": "https://arxiv.org/pdf/2511.00290", "abs": "https://arxiv.org/abs/2511.00290", "authors": ["Ashwin Gerard Colaco", "Sharad Mehrotra", "Michael J De Lucia", "Kevin Hamlen", "Murat Kantarcioglu", "Latifur Khan", "Ananthram Swami", "Bhavani Thuraisingham"], "title": "NOMAD - Navigating Optimal Model Application to Datastreams", "categories": ["cs.DB"], "comment": null, "summary": "NOMAD (Navigating Optimal Model Application for Datastreams) is an\nintelligent framework for data enrichment during ingestion that optimizes\nrealtime multiclass classification by dynamically constructing model chains,\ni.e ,sequences of machine learning models with varying cost-quality tradeoffs,\nselected via a utilitybased criterion. Inspired by predicate ordering\ntechniques from database query processing, NOMAD leverages cheaper models as\ninitial filters, proceeding to more expensive models only when necessary, while\nguaranteeing classification quality remains comparable to a designated role\nmodel through a formal chain safety mechanism. It employs a dynamic belief\nupdate strategy to adapt model selection based on per event predictions and\nshifting data distributions, and extends to scenarios with dependent models\nsuch as earlyexit DNNs and stacking ensembles. Evaluation across multiple\ndatasets demonstrates that NOMAD achieves significant computational savings\ncompared to static and naive approaches while maintaining classification\nquality comparable to that achieved by the most accurate (and often the most\nexpensive) model.", "AI": {"tldr": "NOMAD\u662f\u7528\u4e8e\u6570\u636e\u6d41\u6444\u5165\u65f6\u6570\u636e\u4e30\u5bcc\u7684\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u6a21\u578b\u94fe\u4f18\u5316\u5b9e\u65f6\u591a\u7c7b\u5206\u7c7b\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u80fd\u8282\u7701\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u6301\u5206\u7c7b\u8d28\u91cf\u3002", "motivation": "\u4f18\u5316\u5b9e\u65f6\u591a\u7c7b\u5206\u7c7b\uff0c\u5728\u4fdd\u8bc1\u5206\u7c7b\u8d28\u91cf\u7684\u540c\u65f6\u8282\u7701\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u53d7\u6570\u636e\u5e93\u67e5\u8be2\u5904\u7406\u8c13\u8bcd\u6392\u5e8f\u6280\u672f\u542f\u53d1\uff0c\u5229\u7528\u5ec9\u4ef7\u6a21\u578b\u4f5c\u4e3a\u521d\u59cb\u8fc7\u6ee4\u5668\uff0c\u91c7\u7528\u52a8\u6001\u4fe1\u5ff5\u66f4\u65b0\u7b56\u7565\uff0c\u53ef\u6269\u5c55\u5230\u4f9d\u8d56\u6a21\u578b\u573a\u666f\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u9759\u6001\u548c\u7b80\u5355\u65b9\u6cd5\u76f8\u6bd4\uff0cNOMAD\u5b9e\u73b0\u663e\u8457\u8ba1\u7b97\u8282\u7701\uff0c\u5206\u7c7b\u8d28\u91cf\u4e0e\u6700\u51c6\u786e\uff08\u901a\u5e38\u4e5f\u662f\u6700\u6602\u8d35\uff09\u7684\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "NOMAD\u80fd\u5728\u8282\u7701\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u8bc1\u5206\u7c7b\u8d28\u91cf\uff0c\u662f\u6709\u6548\u7684\u5b9e\u65f6\u591a\u7c7b\u5206\u7c7b\u4f18\u5316\u6846\u67b6\u3002"}}
{"id": "2511.00835", "pdf": "https://arxiv.org/pdf/2511.00835", "abs": "https://arxiv.org/abs/2511.00835", "authors": ["Taikun Zhu", "Kai Jin", "Ruixi Luo", "Song Cao"], "title": "Optimal Allocations under Strongly Pigou-Dalton Criteria: Hidden Layer Structure & Efficient Combinatorial Approach", "categories": ["cs.GT"], "comment": null, "summary": "We investigate optimal social welfare allocations of $m$ items to $n$ agents\nwith binary additive or submodular valuations. For binary additive valuations,\nwe prove that the set of optimal allocations coincides with the set of\nso-called \\emph{stable allocations}, as long as the employed criterion for\nevaluating social welfare is strongly Pigou-Dalton (SPD) and symmetric. Many\ncommon criteria are SPD and symmetric, such as Nash social welfare, leximax,\nleximin, Gini index, entropy, and envy sum. We also design efficient algorithms\nfor finding a stable allocation, including an $O(m^2n)$ time algorithm for the\ncase of indivisible items, and an $O(m^2n^5)$ time one for the case of\ndivisible items. The first is faster than the existing algorithms or has a\nsimpler analysis. The latter is the first combinatorial algorithm for that\nproblem. It utilizes a hidden layer partition of items and agents admitted by\nall stable allocations, and cleverly reduces the case of divisible items to the\ncase of indivisible items.\n  In addition, we show that the profiles of different optimal allocations have\na small Chebyshev distance, which is 0 for the case of divisible items under\nbinary additive valuations, and is at most 1 for the case of indivisible items\nunder binary submodular valuations.", "AI": {"tldr": "\u7814\u7a76m\u4e2a\u7269\u54c1\u5206\u914d\u7ed9n\u4e2a\u5177\u6709\u4e8c\u5143\u52a0\u6027\u6216\u5b50\u6a21\u4f30\u503c\u7684\u4ee3\u7406\u4eba\u7684\u6700\u4f18\u793e\u4f1a\u798f\u5229\u5206\u914d\uff0c\u8bc1\u660e\u6700\u4f18\u5206\u914d\u4e0e\u7a33\u5b9a\u5206\u914d\u7684\u5173\u7cfb\uff0c\u8bbe\u8ba1\u627e\u7a33\u5b9a\u5206\u914d\u7684\u7b97\u6cd5\uff0c\u8fd8\u5206\u6790\u4e0d\u540c\u6700\u4f18\u5206\u914d\u7684\u5207\u6bd4\u96ea\u592b\u8ddd\u79bb\u3002", "motivation": "\u7814\u7a76\u5177\u6709\u4e8c\u5143\u52a0\u6027\u6216\u5b50\u6a21\u4f30\u503c\u7684\u4ee3\u7406\u4eba\u7684\u6700\u4f18\u793e\u4f1a\u798f\u5229\u5206\u914d\u95ee\u9898\u3002", "method": "\u7406\u8bba\u8bc1\u660e\u6700\u4f18\u5206\u914d\u4e0e\u7a33\u5b9a\u5206\u914d\u7684\u5173\u7cfb\uff0c\u8bbe\u8ba1\u4e0d\u540c\u60c5\u51b5\u4e0b\u627e\u7a33\u5b9a\u5206\u914d\u7684\u7b97\u6cd5\uff0c\u5229\u7528\u7269\u54c1\u548c\u4ee3\u7406\u4eba\u7684\u9690\u85cf\u5c42\u5212\u5206\u5c06\u53ef\u5206\u7269\u54c1\u60c5\u51b5\u8f6c\u5316\u4e3a\u4e0d\u53ef\u5206\u7269\u54c1\u60c5\u51b5\u3002", "result": "\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6700\u4f18\u5206\u914d\u4e0e\u7a33\u5b9a\u5206\u914d\u91cd\u5408\uff1b\u8bbe\u8ba1\u51fa\u4e0d\u53ef\u5206\u7269\u54c1\u7684O(m^2n)\u65f6\u95f4\u7b97\u6cd5\u548c\u53ef\u5206\u7269\u54c1\u7684O(m^2n^5)\u65f6\u95f4\u7b97\u6cd5\uff1b\u5f97\u51fa\u4e0d\u540c\u6700\u4f18\u5206\u914d\u7684\u5207\u6bd4\u96ea\u592b\u8ddd\u79bb\u3002", "conclusion": "\u5bf9\u4e8e\u4e8c\u5143\u52a0\u6027\u6216\u5b50\u6a21\u4f30\u503c\u7684\u7269\u54c1\u5206\u914d\u95ee\u9898\uff0c\u6709\u4e86\u5173\u4e8e\u6700\u4f18\u5206\u914d\u4e0e\u7a33\u5b9a\u5206\u914d\u7684\u5173\u7cfb\u7ed3\u8bba\uff0c\u4e14\u8bbe\u8ba1\u7684\u7b97\u6cd5\u6709\u6548\uff0c\u4e0d\u540c\u6700\u4f18\u5206\u914d\u7684\u5207\u6bd4\u96ea\u592b\u8ddd\u79bb\u8f83\u5c0f\u3002"}}
{"id": "2511.00717", "pdf": "https://arxiv.org/pdf/2511.00717", "abs": "https://arxiv.org/abs/2511.00717", "authors": ["Peng Liu", "Alexander Schied"], "title": "Lambda Value-at-Risk under ambiguity and risk sharing", "categories": ["q-fin.RM"], "comment": "41 pages", "summary": "In this paper, we investigate the Lambda Value-at-Risk ($\\Lambda$VaR) under\nambiguity, where the ambiguity is represented by a family of probability\nmeasures. We establish that for increasing Lambda functions, the robust (i.e.,\nworst-case) $\\Lambda$VaR under such an ambiguity set is equivalent to\n$\\Lambda$VaR computed with respect to a capacity, a novel extension in the\nliterature. This framework unifies and extends both traditional $\\Lambda$VaR\nand Choquet quantiles (Value-at-Risk under ambiguity). We analyze the\nfundamental properties of this extended risk measure and establish a novel\nequivalent representation for $\\Lambda$VaR under capacities with monotone\nLambda functions in terms of families of downsets. Moreover, explicit formulas\nare derived for robust $\\Lambda$VaR when ambiguity sets are characterized by\n$\\phi$-divergence and the likelihood ratio constraints, respectively.\n  We further explore the applications in risk sharing among multiple agents. We\ndemonstrate that the family of risk measures induced by families of downsets is\nclosed under inf-convolution. In particular, we prove that the inf-convolution\nof $\\Lambda$VaR with capacities and monotone Lambda functions is\nanother$\\Lambda$VaR under a capacity. The explicit forms of optimal allocations\nare also derived. Moreover, we obtain more explicit results for risk sharing\nunder ambiguity sets characterized by $\\phi$-divergence and likelihood ratio\nconstraints. Finally, we explore comonotonic risk-sharing for $\\Lambda$VaR\nunder ambiguity.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.00217", "pdf": "https://arxiv.org/pdf/2511.00217", "abs": "https://arxiv.org/abs/2511.00217", "authors": ["Mitchell L. Prevett", "Francis K. C. Hui", "Zhi Yang Tho", "A. H. Welsh", "Anton H. Westveld"], "title": "Gradient Boosted Mixed Models: Flexible Joint Estimation of Mean and Variance Components for Clustered Data", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "comment": null, "summary": "Linear mixed models are widely used for clustered data, but their reliance on\nparametric forms limits flexibility in complex and high-dimensional settings.\nIn contrast, gradient boosting methods achieve high predictive accuracy through\nnonparametric estimation, but do not accommodate clustered data structures or\nprovide uncertainty quantification.\n  We introduce Gradient Boosted Mixed Models (GBMixed), a framework and\nalgorithm that extends boosting to jointly estimate mean and variance\ncomponents via likelihood-based gradients. In addition to nonparametric mean\nestimation, the method models both random effects and residual variances as\npotentially covariate-dependent functions using flexible base learners such as\nregression trees or splines, enabling nonparametric estimation while\nmaintaining interpretability.\n  Simulations and real-world applications demonstrate accurate recovery of\nvariance components, calibrated prediction intervals, and improved predictive\naccuracy relative to standard linear mixed models and nonparametric methods.\nGBMixed provides heteroscedastic uncertainty quantification and introduces\nboosting for heterogeneous random effects. This enables covariate-dependent\nshrinkage for cluster-specific predictions to adapt between population and\ncluster-level data. Under standard causal assumptions, the framework enables\nestimation of heterogeneous treatment effects with reliable uncertainty\nquantification.", "AI": {"tldr": "\u5f15\u5165\u68af\u5ea6\u63d0\u5347\u6df7\u5408\u6a21\u578b\uff08GBMixed\uff09\uff0c\u7ed3\u5408\u63d0\u5347\u65b9\u6cd5\u4f30\u8ba1\u5747\u503c\u548c\u65b9\u5dee\u5206\u91cf\uff0c\u6a21\u62df\u548c\u5b9e\u9645\u5e94\u7528\u663e\u793a\u5176\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u8fd8\u80fd\u8fdb\u884c\u5f02\u65b9\u5dee\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b49\u3002", "motivation": "\u7ebf\u6027\u6df7\u5408\u6a21\u578b\u5728\u590d\u6742\u9ad8\u7ef4\u573a\u666f\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u68af\u5ea6\u63d0\u5347\u65b9\u6cd5\u4e0d\u80fd\u5904\u7406\u805a\u7c7b\u6570\u636e\u7ed3\u6784\u548c\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165GBMixed\u6846\u67b6\u548c\u7b97\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u4f3c\u7136\u7684\u68af\u5ea6\u8054\u5408\u4f30\u8ba1\u5747\u503c\u548c\u65b9\u5dee\u5206\u91cf\uff0c\u7528\u56de\u5f52\u6811\u6216\u6837\u6761\u7b49\u7075\u6d3b\u57fa\u5b66\u4e60\u5668\u5efa\u6a21\u968f\u673a\u6548\u5e94\u548c\u6b8b\u5dee\u65b9\u5dee\u3002", "result": "\u6a21\u62df\u548c\u5b9e\u9645\u5e94\u7528\u8868\u660e\u80fd\u51c6\u786e\u6062\u590d\u65b9\u5dee\u5206\u91cf\u3001\u6821\u51c6\u9884\u6d4b\u533a\u95f4\u3001\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "GBMixed\u80fd\u8fdb\u884c\u5f02\u65b9\u5dee\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u53ef\u7528\u4e8e\u5f02\u8d28\u968f\u673a\u6548\u5e94\uff0c\u5728\u6807\u51c6\u56e0\u679c\u5047\u8bbe\u4e0b\u80fd\u4f30\u8ba1\u5f02\u8d28\u5904\u7406\u6548\u5e94\u5e76\u63d0\u4f9b\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002"}}
{"id": "2511.00080", "pdf": "https://arxiv.org/pdf/2511.00080", "abs": "https://arxiv.org/abs/2511.00080", "authors": ["Auyona Ray"], "title": "Closing the SNAP Gap: Identifying Under-Enrollment in High-Poverty ZIP Codes", "categories": ["econ.GN", "q-fin.EC", "stat.AP", "I.2.6, I.5.4, J.4, K.4.1", "I.2; I.5; J.4; K.4"], "comment": "28 pages, 5 figures. Working paper on SNAP participation and economic\n  insecurity. Relevant to economics (general), econometrics, public policy, and\n  applied machine learning audiences", "summary": "This project began by constructing an index of economic insecurity using\nmultiple socioeconomic indicators. Although poverty alone predicted SNAP\nparticipation more accurately than the composite index, its explanatory power\nwas weaker than anticipated, echoing past findings that enrollment cannot be\nexplained by income alone. This led to a shift in focus: identifying ZIP codes\nwith high poverty but unexpectedly low SNAP participation, areas defined here\nas having a SNAP Gap, where ZIPs fall in the top 30 percent of family poverty\nand the bottom 10 percent of SNAP enrollment. Using nationally available ZIP\nlevel data from 2014 to 2023, I trained logistic classification models on four\ninterpretable structural indicators: lack of vehicle, lack of internet access,\nlack of computer access, and percentage of adults with only a high school\ndiploma. The most effective model relies on just two predictors, vehicle access\nand education, and outperforms tree based classifiers in both precision and\ncalibration. Results show that economic insecurity is consistently concentrated\nin rural ZIP codes, with transportation access emerging as the most stable\nbarrier to program take up. This study provides a nationwide diagnostic\nframework that can inform the development of scalable screening tools for\ntargeting outreach and improving benefit access in underserved communities.", "AI": {"tldr": "\u6784\u5efa\u7ecf\u6d4e\u4e0d\u5b89\u5168\u6307\u6570\uff0c\u540e\u805a\u7126SNAP\u5dee\u8ddd\u533a\u57df\uff0c\u7528\u7ed3\u6784\u6307\u6807\u8bad\u7ec3\u6a21\u578b\uff0c\u53d1\u73b0\u7ecf\u6d4e\u4e0d\u5b89\u5168\u96c6\u4e2d\u5728\u519c\u6751\uff0c\u4ea4\u901a\u662f\u963b\u788d\u9879\u76ee\u53c2\u4e0e\u7684\u7a33\u5b9a\u56e0\u7d20\uff0c\u63d0\u4f9b\u5168\u56fd\u8bca\u65ad\u6846\u67b6\u3002", "motivation": "\u63a2\u7a76SNAP\u53c2\u4e0e\u60c5\u51b5\uff0c\u89e3\u51b3\u4ec5\u7528\u6536\u5165\u65e0\u6cd5\u5145\u5206\u89e3\u91ca\u53c2\u4e0e\u60c5\u51b5\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efa\u7ecf\u6d4e\u4e0d\u5b89\u5168\u6307\u6570\uff0c\u786e\u5b9aSNAP\u5dee\u8ddd\u533a\u57df\uff0c\u75282014 - 2023\u5e74\u5168\u56fdZIP\u7ea7\u6570\u636e\uff0c\u57fa\u4e8e\u56db\u4e2a\u7ed3\u6784\u6307\u6807\u8bad\u7ec3\u903b\u8f91\u5206\u7c7b\u6a21\u578b\u3002", "result": "\u6700\u6709\u6548\u6a21\u578b\u4f9d\u8d56\u8f66\u8f86\u548c\u6559\u80b2\u4e24\u4e2a\u9884\u6d4b\u56e0\u7d20\uff0c\u4f18\u4e8e\u57fa\u4e8e\u6811\u7684\u5206\u7c7b\u5668\uff0c\u7ecf\u6d4e\u4e0d\u5b89\u5168\u96c6\u4e2d\u5728\u519c\u6751\uff0c\u4ea4\u901a\u662f\u9879\u76ee\u53c2\u4e0e\u7684\u7a33\u5b9a\u969c\u788d\u3002", "conclusion": "\u63d0\u4f9b\u5168\u56fd\u8bca\u65ad\u6846\u67b6\uff0c\u53ef\u4e3a\u5f00\u53d1\u7b5b\u9009\u5de5\u5177\u3001\u6539\u5584\u670d\u52a1\u4e0d\u8db3\u793e\u533a\u798f\u5229\u83b7\u53d6\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2511.00796", "pdf": "https://arxiv.org/pdf/2511.00796", "abs": "https://arxiv.org/abs/2511.00796", "authors": ["Ran Yan", "Youhe Jiang", "Tianyuan Wu", "Jiaxuan Gao", "Zhiyu Mei", "Wei Fu", "Haohui Mai", "Wei Wang", "Yi Wu", "Binhang Yuan"], "title": "AReaL-Hex: Accommodating Asynchronous RL Training over Heterogeneous GPUs", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Maximizing training throughput and cost-efficiency of RL for LLMs is\nessential to democratize this advanced technique. One promising but challenging\napproach is to deploy such a computational workflow over heterogeneous GPUs.\nUnlike conventional large-scale LLM pretraining, RL training generally\ndecomposes into three coupled stages, i.e., rollout generation, reward\ncomputation, and policy/value updates, which exhibit markedly different compute\nintensities, memory footprints, and communication patterns. Recent research\nshows that fully asynchronous RL training can disaggregate these stages across\ndisjoint hardware pools without sacrificing training stability, creating a\ngreat opportunity for real-world heterogeneous deployment. To this end, we\npresent AReaL-Hex, a heterogeneity-aware asynchronous RL training system that\neffectively schedules how to execute rollout generation and policy model\ntraining over heterogeneous GPUs while enforcing data staleness bounds.\nConcretely, we use a two-phase scheduler: (i) a constrained search with MILP to\nselect per-stage parallelization strategies and workload assignments given a\nresource budget, and (ii) a graph-partitioning step that allocates\nheterogeneous GPUs and interconnects to maximize end-to-end throughput. Built\natop a fully asynchronous RL architecture, AReaL-Hex maps HBM-I/O-bound\ngeneration and compute-bound optimization to more cost-efficient resources and\nbalances their producer-consumer interactions to avoid both idleness and stale\nrollout trajectories. On the mathematical reasoning task with various model\nscales (1.5B, 7B, and 14B), compared to homogeneous deployments of\nstate-of-the-art asynchronous RL systems: (i) When maintaining the same total\nbudgets, AReaL-Hex delivers up to 1.50x higher training throughput; (ii) When\nachieving the same training throughput, AReaL-Hex results in up to 1.46x\nreduction in training cost.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f02\u8d28\u6027\u611f\u77e5\u5f02\u6b65RL\u8bad\u7ec3\u7cfb\u7edfAReaL - Hex\uff0c\u53ef\u5728\u5f02\u6784GPU\u4e0a\u8c03\u5ea6\u6267\u884c\uff0c\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u6700\u5927\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u6210\u672c\u6548\u76ca\uff0c\u4ee5\u63a8\u5e7f\u8be5\u6280\u672f\uff0c\u4e14RL\u8bad\u7ec3\u5404\u9636\u6bb5\u7279\u6027\u4e0d\u540c\uff0c\u4e3a\u5f02\u6784\u90e8\u7f72\u5e26\u6765\u6311\u6218\u548c\u673a\u4f1a\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8c03\u5ea6\u5668\uff0c\u4e00\u662f\u7528MILP\u8fdb\u884c\u7ea6\u675f\u641c\u7d22\u4ee5\u9009\u62e9\u5e76\u884c\u7b56\u7565\u548c\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\uff0c\u4e8c\u662f\u8fdb\u884c\u56fe\u5206\u533a\u4ee5\u5206\u914d\u5f02\u6784GPU\u548c\u4e92\u8fde\u8d44\u6e90\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u4e0e\u6700\u5148\u8fdb\u5f02\u6b65RL\u7cfb\u7edf\u7684\u540c\u6784\u90e8\u7f72\u76f8\u6bd4\uff0c\u76f8\u540c\u9884\u7b97\u4e0b\u8bad\u7ec3\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53471.50\u500d\uff0c\u76f8\u540c\u541e\u5410\u91cf\u4e0b\u8bad\u7ec3\u6210\u672c\u6700\u9ad8\u964d\u4f4e1.46\u500d\u3002", "conclusion": "AReaL - Hex\u80fd\u6709\u6548\u5728\u5f02\u6784GPU\u4e0a\u8c03\u5ea6RL\u8bad\u7ec3\uff0c\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2511.00176", "pdf": "https://arxiv.org/pdf/2511.00176", "abs": "https://arxiv.org/abs/2511.00176", "authors": ["Milad Sabouri", "Masoud Mansoury", "Kun Lin", "Bamshad Mobasher"], "title": "Effectiveness of LLMs in Temporal User Profiling for Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted to the IEEE International Conference on Data Mining (ICDM\n  2025), Workshop on User Modeling and Recommendation (UMRec). To appear in the\n  IEEE ICDMW 2025 proceedings", "summary": "Effectively modeling the dynamic nature of user preferences is crucial for\nenhancing recommendation accuracy and fostering transparency in recommender\nsystems. Traditional user profiling often overlooks the distinction between\ntransitory short-term interests and stable long-term preferences. This paper\nexamines the capability of leveraging Large Language Models (LLMs) to capture\nthese temporal dynamics, generating richer user representations through\ndistinct short-term and long-term textual summaries of interaction histories.\nOur observations suggest that while LLMs tend to improve recommendation quality\nin domains with more active user engagement, their benefits appear less\npronounced in sparser environments. This disparity likely stems from the\nvarying distinguishability of short-term and long-term preferences across\ndomains; the approach shows greater utility where these temporal interests are\nmore clearly separable (e.g., Movies\\&TV) compared to domains with more stable\nuser profiles (e.g., Video Games). This highlights a critical trade-off between\nenhanced performance and computational costs, suggesting context-dependent LLM\napplication. Beyond predictive capability, this LLM-driven approach inherently\nprovides an intrinsic potential for interpretability through its natural\nlanguage profiles and attention weights. This work contributes insights into\nthe practical capability and inherent interpretability of LLM-driven temporal\nuser profiling, outlining new research directions for developing adaptive and\ntransparent recommender systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6355\u6349\u7528\u6237\u504f\u597d\u7684\u65f6\u95f4\u52a8\u6001\uff0c\u53d1\u73b0\u5176\u5728\u7528\u6237\u53c2\u4e0e\u5ea6\u9ad8\u7684\u9886\u57df\u80fd\u63d0\u5347\u63a8\u8350\u8d28\u91cf\uff0c\u4f46\u5728\u7a00\u758f\u73af\u5883\u4e2d\u6548\u679c\u4e0d\u660e\u663e\uff0c\u8fd8\u6307\u51fa\u6027\u80fd\u4e0e\u8ba1\u7b97\u6210\u672c\u7684\u6743\u8861\uff0c\u53ca\u65b9\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7528\u6237\u753b\u50cf\u5ffd\u7565\u77ed\u671f\u5174\u8da3\u548c\u957f\u671f\u504f\u597d\u533a\u522b\uff0c\u4e3a\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u548c\u7cfb\u7edf\u900f\u660e\u5ea6\uff0c\u7814\u7a76\u5229\u7528LLMs\u6355\u6349\u7528\u6237\u504f\u597d\u7684\u65f6\u95f4\u52a8\u6001\u3002", "method": "\u5229\u7528LLMs\u901a\u8fc7\u4ea4\u4e92\u5386\u53f2\u7684\u77ed\u671f\u548c\u957f\u671f\u6587\u672c\u6458\u8981\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u7528\u6237\u8868\u793a\u3002", "result": "LLMs\u5728\u7528\u6237\u53c2\u4e0e\u5ea6\u9ad8\u7684\u9886\u57df\u63d0\u5347\u63a8\u8350\u8d28\u91cf\uff0c\u5728\u7a00\u758f\u73af\u5883\u4e2d\u6548\u679c\u4e0d\u660e\u663e\uff0c\u4e0d\u540c\u9886\u57df\u77ed\u671f\u548c\u957f\u671f\u504f\u597d\u53ef\u533a\u5206\u6027\u4e0d\u540c\u5f71\u54cd\u6548\u679c\u3002", "conclusion": "\u6307\u51fa\u6027\u80fd\u4e0e\u8ba1\u7b97\u6210\u672c\u7684\u6743\u8861\uff0c\u5f3a\u8c03LLM\u9a71\u52a8\u65b9\u6cd5\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u5f00\u53d1\u81ea\u9002\u5e94\u548c\u900f\u660e\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u65b0\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.00184", "pdf": "https://arxiv.org/pdf/2511.00184", "abs": "https://arxiv.org/abs/2511.00184", "authors": ["Sami Davies", "Venkatesan Guruswami", "Xuandi Ren"], "title": "Scheduling Problems with Constrained Rejections", "categories": ["cs.DS", "cs.CC"], "comment": null, "summary": "We study bicriteria versions of Makespan Minimization on Unrelated Machines\nand Santa Claus by allowing a constrained number of rejections. Given an\ninstance of Makespan Minimization on Unrelated Machines where the optimal\nmakespan for scheduling $n$ jobs on $m$ unrelated machines is $T$, (Feige and\nVondr\\'ak, 2006) gave an algorithm that schedules a $(1-1/e+10^{-180})$\nfraction of jobs in time $T$. We show the ratio can be improved to\n$0.6533>1-1/e+0.02$ if we allow makespan $3T/2$. To the best our knowledge,\nthis is the first result examining the tradeoff between makespan and the\nfraction of scheduled jobs when the makespan is not $T$ or $2T$.\n  For the Santa Claus problem (the Max-Min version of Makespan Minimization),\nthe analogous bicriteria objective was studied by (Golovin, 2005), who gave an\nalgorithm providing an allocation so a $(1-1/k)$ fraction of agents receive\nvalue at least $T/k$, for any $k \\in \\mathbb{Z}^+$ and $T$ being the optimal\nminimum value every agent can receive. We provide the first hardness result by\nshowing there are constants $\\delta,\\varepsilon>0$ such that it is NP-hard to\nfind an allocation where a $(1-\\delta)$ fraction of agents receive value at\nleast $(1-\\varepsilon) T$. To prove this hardness result, we introduce a\nbicriteria version of Set Packing, which may be of independent interest, and\nprove some algorithmic and hardness results for it. Overall, we believe these\nbicriteria scheduling problems warrant further study as they provide an\ninteresting lens to understand how robust the difficulty of the original\noptimization goal might be.", "AI": {"tldr": "\u7814\u7a76\u5e26\u7ea6\u675f\u62d2\u7edd\u6570\u91cf\u7684\u53cc\u76ee\u6807Makespan Minimization\u548cSanta Claus\u95ee\u9898\uff0c\u6539\u8fdbMakespan Minimization\u8c03\u5ea6\u6bd4\u4f8b\uff0c\u7ed9\u51faSanta Claus\u95ee\u9898\u9996\u4e2a\u786c\u5ea6\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76\u53cc\u76ee\u6807\u8c03\u5ea6\u95ee\u9898\uff0c\u63a2\u7d22\u539f\u4f18\u5316\u76ee\u6807\u96be\u5ea6\u7684\u9c81\u68d2\u6027\u3002", "method": "\u6539\u8fdb\u5df2\u6709\u7b97\u6cd5\u63d0\u9ad8Makespan Minimization\u8c03\u5ea6\u6bd4\u4f8b\uff1b\u5f15\u5165\u53cc\u76ee\u6807Set Packing\u95ee\u9898\u8bc1\u660eSanta Claus\u95ee\u9898\u786c\u5ea6\u3002", "result": "Makespan Minimization\u5728makespan\u4e3a3T/2\u65f6\u8c03\u5ea6\u6bd4\u4f8b\u63d0\u9ad8\u52300.6533\uff1b\u8bc1\u660eSanta Claus\u95ee\u9898\u5b58\u5728NP\u96be\u60c5\u51b5\u3002", "conclusion": "\u53cc\u76ee\u6807\u8c03\u5ea6\u95ee\u9898\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u53ef\u7528\u4e8e\u7406\u89e3\u539f\u4f18\u5316\u76ee\u6807\u96be\u5ea6\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.00039", "pdf": "https://arxiv.org/pdf/2511.00039", "abs": "https://arxiv.org/abs/2511.00039", "authors": ["Krishna Kumar Neelakanta Pillai Santha Kumari Amma"], "title": "Graph-Attentive MAPPO for Dynamic Retail Pricing", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Dynamic pricing in retail requires policies that adapt to shifting demand\nwhile coordinating decisions across related products. We present a systematic\nempirical study of multi-agent reinforcement learning for retail price\noptimization, comparing a strong MAPPO baseline with a\ngraph-attention-augmented variant (MAPPO+GAT) that leverages learned\ninteractions among products. Using a simulated pricing environment derived from\nreal transaction data, we evaluate profit, stability across random seeds,\nfairness across products, and training efficiency under a standardized\nevaluation protocol. The results indicate that MAPPO provides a robust and\nreproducible foundation for portfolio-level price control, and that MAPPO+GAT\nfurther enhances performance by sharing information over the product graph\nwithout inducing excessive price volatility. These results indicate that\ngraph-integrated MARL provides a more scalable and stable solution than\nindependent learners for dynamic retail pricing, offering practical advantages\nin multi-product decision-making.", "AI": {"tldr": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u96f6\u552e\u4ef7\u683c\u4f18\u5316\uff0c\u5bf9\u6bd4MAPPO\u548cMAPPO+GAT\uff0c\u7ed3\u679c\u8868\u660e\u56fe\u96c6\u6210MARL\u5728\u52a8\u6001\u96f6\u552e\u5b9a\u4ef7\u4e0a\u66f4\u4f18\u3002", "motivation": "\u96f6\u552e\u52a8\u6001\u5b9a\u4ef7\u9700\u9002\u5e94\u9700\u6c42\u53d8\u5316\u5e76\u534f\u8c03\u76f8\u5173\u4ea7\u54c1\u51b3\u7b56\uff0c\u5f00\u5c55\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u96f6\u552e\u4ef7\u683c\u4f18\u5316\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "method": "\u5bf9\u6bd4\u5f3aMAPPO\u57fa\u7ebf\u4e0e\u56fe\u6ce8\u610f\u529b\u589e\u5f3a\u53d8\u4f53MAPPO+GAT\uff0c\u5728\u6a21\u62df\u5b9a\u4ef7\u73af\u5883\u4e0b\u6309\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\u8bc4\u4f30\u5229\u6da6\u3001\u7a33\u5b9a\u6027\u3001\u516c\u5e73\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002", "result": "MAPPO\u4e3a\u7ec4\u5408\u5c42\u9762\u4ef7\u683c\u63a7\u5236\u63d0\u4f9b\u7a33\u5065\u53ef\u91cd\u590d\u57fa\u7840\uff0cMAPPO+GAT\u901a\u8fc7\u4ea7\u54c1\u56fe\u5171\u4eab\u4fe1\u606f\u63d0\u5347\u6027\u80fd\u4e14\u4e0d\u8fc7\u5ea6\u589e\u52a0\u4ef7\u683c\u6ce2\u52a8\u3002", "conclusion": "\u56fe\u96c6\u6210MARL\u6bd4\u72ec\u7acb\u5b66\u4e60\u5668\u5728\u52a8\u6001\u96f6\u552e\u5b9a\u4ef7\u4e0a\u66f4\u5177\u6269\u5c55\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5728\u591a\u4ea7\u54c1\u51b3\u7b56\u4e2d\u6709\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2511.01471", "pdf": "https://arxiv.org/pdf/2511.01471", "abs": "https://arxiv.org/abs/2511.01471", "authors": ["Mikhail Gennadievich Belov", "Victor Victorovich Dubov", "Vadim Konstantinovich Ivanov", "Alexander Yurievich Maslov", "Olga Vladimirovna Proshina", "Vladislav Gennadievich Malyshkin"], "title": "Trade Execution Flow as the Underlying Source of Market Dynamics", "categories": ["q-fin.CP", "cs.NA", "math.NA", "q-fin.TR"], "comment": null, "summary": "In this work, we demonstrate experimentally that the execution flow, $I =\ndV/dt$, is the fundamental driving force of market dynamics. We develop a\nnumerical framework to calculate execution flow from sampled moments using the\nRadon-Nikodym derivative. A notable feature of this approach is its ability to\nautomatically determine thresholds that can serve as actionable triggers. The\ntechnique also determines the characteristic time scale directly from the\ncorresponding eigenproblem. The methodology has been validated on actual market\ndata to support these findings. Additionally, we introduce a framework based on\nthe Christoffel function spectrum, which is invariant under arbitrary\nnon-degenerate linear transformations of input attributes and offers an\nalternative to traditional principal component analysis (PCA), which is limited\nto unitary invariance.", "AI": {"tldr": "\u5b9e\u9a8c\u8bc1\u660e\u6267\u884c\u6d41\u662f\u5e02\u573a\u52a8\u6001\u7684\u6839\u672c\u9a71\u52a8\u529b\uff0c\u5f00\u53d1\u6570\u503c\u6846\u67b6\u8ba1\u7b97\u6267\u884c\u6d41\uff0c\u6709\u81ea\u52a8\u786e\u5b9a\u9608\u503c\u7b49\u7279\u6027\uff0c\u8fd8\u5f15\u5165\u57fa\u4e8eChristoffel\u51fd\u6570\u8c31\u7684\u6846\u67b6\u3002", "motivation": "\u63a2\u7d22\u5e02\u573a\u52a8\u6001\u7684\u6839\u672c\u9a71\u52a8\u529b\uff0c\u5bfb\u6c42\u66ff\u4ee3\u4f20\u7edf\u4e3b\u6210\u5206\u5206\u6790\u7684\u65b9\u6cd5\u3002", "method": "\u7528Radon - Nikodym\u5bfc\u6570\u4ece\u91c7\u6837\u65f6\u523b\u8ba1\u7b97\u6267\u884c\u6d41\uff0c\u901a\u8fc7\u5bf9\u5e94\u7279\u5f81\u95ee\u9898\u786e\u5b9a\u7279\u5f81\u65f6\u95f4\u5c3a\u5ea6\uff1b\u5f15\u5165\u57fa\u4e8eChristoffel\u51fd\u6570\u8c31\u7684\u6846\u67b6\u3002", "result": "\u65b9\u6cd5\u5728\u5b9e\u9645\u5e02\u573a\u6570\u636e\u4e0a\u5f97\u5230\u9a8c\u8bc1\uff0c\u8bc1\u660e\u6267\u884c\u6d41\u662f\u5e02\u573a\u52a8\u6001\u7684\u6839\u672c\u9a71\u52a8\u529b\u3002", "conclusion": "\u6267\u884c\u6d41\u662f\u5e02\u573a\u52a8\u6001\u7684\u6839\u672c\u9a71\u52a8\u529b\uff0c\u6240\u63d0\u6570\u503c\u6846\u67b6\u548c\u57fa\u4e8eChristoffel\u51fd\u6570\u8c31\u7684\u6846\u67b6\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.00087", "pdf": "https://arxiv.org/pdf/2511.00087", "abs": "https://arxiv.org/abs/2511.00087", "authors": ["Anshu Dubey", "Akash Dhruv"], "title": "Adding New Capability in Existing Scientific Application with LLM Assistance", "categories": ["cs.SE", "cs.AI"], "comment": "8 pages, 4 figures, submitted to The 1st International Workshop on\n  Foundational large Language Models Advances for HPC in Asia", "summary": "With the emergence and rapid evolution of large language models (LLM),\nautomating coding tasks has become an im- portant research topic. Many efforts\nare underway and liter- ature abounds about the efficacy of models and their\nability to generate code. A less explored aspect of code generation is for new\nalgorithms, where the training data-set would not have included any previous\nexample of similar code. In this paper we propose a new methodology for writing\ncode from scratch for a new algorithm using LLM assistance, and describe\nenhancement of a previously developed code- translation tool, Code-Scribe, for\nnew code generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e3a\u65b0\u7b97\u6cd5\u4ece\u5934\u7f16\u5199\u4ee3\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u63cf\u8ff0\u5bf9\u4ee3\u7801\u7ffb\u8bd1\u5de5\u5177Code - Scribe\u7684\u6539\u8fdb\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5174\u8d77\u4e0b\u81ea\u52a8\u5316\u7f16\u7801\u4efb\u52a1\u6210\u7814\u7a76\u70ed\u70b9\uff0c\u4f46\u65b0\u7b97\u6cd5\u4ee3\u7801\u751f\u6210\u65b9\u9762\u63a2\u7d22\u8f83\u5c11\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4e3a\u65b0\u7b97\u6cd5\u4ece\u5934\u7f16\u5199\u4ee3\u7801\u7684\u65b9\u6cd5\uff0c\u6539\u8fdb\u4ee3\u7801\u7ffb\u8bd1\u5de5\u5177Code - Scribe\u7528\u4e8e\u65b0\u4ee3\u7801\u751f\u6210\u3002", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2511.00029", "pdf": "https://arxiv.org/pdf/2511.00029", "abs": "https://arxiv.org/abs/2511.00029", "authors": ["Samaksh Bhargav", "Zining Zhu"], "title": "Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "Large Language Model (LLM) deployment requires guiding the LLM to recognize\nand not answer unsafe prompts while complying with safe prompts. Previous\nmethods for achieving this require adjusting model weights along with other\nexpensive procedures. While recent advances in Sparse Autoencoders (SAEs) have\nenabled interpretable feature extraction from LLMs, existing approaches lack\nsystematic feature selection methods and principled evaluation of\nsafety-utility tradeoffs. We explored using different steering features and\nsteering strengths using Sparse Auto Encoders (SAEs) to provide a solution.\nUsing an accurate and innovative contrasting prompt method with the\nAI-Generated Prompts Dataset from teknium/OpenHermes-2p5-Mistral-7B and Air\nBench eu-dataset to efficiently choose the best features in the model to steer,\nwe tested this method on Llama-3 8B. We conclude that using this method, our\napproach achieves an 18.9% improvement in safety performance while\nsimultaneously increasing utility by 11.1%, demonstrating that targeted SAE\nsteering can overcome traditional safety-utility tradeoffs when optimal\nfeatures are identified through principled selection methods.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528SAEs\u4e0d\u540c\u7279\u5f81\u548c\u5f3a\u5ea6\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u5bf9\u6bd4\u63d0\u793a\u6cd5\u9009\u6700\u4f73\u7279\u5f81\uff0c\u5728Llama - 3 8B\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u5b89\u5168\u6027\u80fd\u548c\u5b9e\u7528\u6027\u53cc\u63d0\u5347\u3002", "motivation": "\u4ee5\u5f80\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u5b89\u5168\u5f15\u5bfc\u65b9\u6cd5\u9700\u8c03\u6574\u6a21\u578b\u6743\u91cd\u7b49\u6602\u8d35\u64cd\u4f5c\uff0c\u73b0\u6709SAEs\u65b9\u6cd5\u7f3a\u4e4f\u7279\u5f81\u9009\u62e9\u548c\u5b89\u5168 - \u5b9e\u7528\u6027\u6743\u8861\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528SAEs\u4e0d\u540c\u5f15\u5bfc\u7279\u5f81\u548c\u5f3a\u5ea6\uff0c\u7528\u51c6\u786e\u521b\u65b0\u7684\u5bf9\u6bd4\u63d0\u793a\u6cd5\u7ed3\u5408AI\u751f\u6210\u63d0\u793a\u6570\u636e\u96c6\u9009\u6a21\u578b\u4e2d\u6700\u4f73\u5f15\u5bfc\u7279\u5f81\uff0c\u5728Llama - 3 8B\u6d4b\u8bd5\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u5b89\u5168\u6027\u80fd\u63d0\u534718.9%\uff0c\u5b9e\u7528\u6027\u63d0\u534711.1%\u3002", "conclusion": "\u901a\u8fc7\u539f\u5219\u6027\u9009\u62e9\u65b9\u6cd5\u786e\u5b9a\u6700\u4f18\u7279\u5f81\u65f6\uff0c\u6709\u9488\u5bf9\u6027\u7684SAE\u5f15\u5bfc\u53ef\u514b\u670d\u4f20\u7edf\u5b89\u5168 - \u5b9e\u7528\u6027\u6743\u8861\u95ee\u9898\u3002"}}
{"id": "2511.00383", "pdf": "https://arxiv.org/pdf/2511.00383", "abs": "https://arxiv.org/abs/2511.00383", "authors": ["Barathi Subramanian", "Rathinaraja Jeyaraj", "Mitchell Nevin Peterson", "Terry Guo", "Nigam Shah", "Curtis Langlotz", "Andrew Y. Ng", "Jeanne Shen"], "title": "STARC-9: A Large-scale Dataset for Multi-Class Tissue Classification for CRC Histopathology", "categories": ["cs.CE"], "comment": "37 pages, 18 figures", "summary": "Multi-class tissue-type classification of colorectal cancer (CRC)\nhistopathologic images is a significant step in the development of downstream\nmachine learning models for diagnosis and treatment planning. However, existing\npublic CRC datasets often lack morphologic diversity, suffer from class\nimbalance, and contain low-quality image tiles, limiting model performance and\ngeneralizability. To address these issues, we introduce STARC-9 (STAnford\ncoloRectal Cancer), a large-scale dataset for multi-class tissue\nclassification. STARC-9 contains 630,000 hematoxylin and eosin-stained image\ntiles uniformly sampled across nine clinically relevant tissue classes (70,000\ntiles per class) from 200 CRC patients at the Stanford University School of\nMedicine. The dataset was built using a novel framework, DeepCluster++,\ndesigned to ensure intra-class diversity and reduce manual curation. First, an\nencoder from a histopathology-specific autoencoder extracts feature vectors\nfrom tiles within each whole-slide image. Then, K-means clustering groups\nmorphologically similar tiles, followed by equal-frequency binning to sample\ndiverse morphologic patterns within each class. The selected tiles are\nsubsequently verified by expert gastrointestinal pathologists to ensure\naccuracy. This semi-automated process significantly reduces manual effort while\nproducing high-quality, diverse tiles. To evaluate STARC-9, we benchmarked\nconvolutional neural networks, transformers, and pathology-specific foundation\nmodels on multi-class CRC tissue classification and segmentation tasks, showing\nsuperior generalizability compared to models trained on existing datasets.\nAlthough we demonstrate the utility of DeepCluster++ on CRC as a pilot\nuse-case, it is a flexible framework that can be used for constructing\nhigh-quality datasets from large WSI repositories across a wide range of cancer\nand non-cancer applications.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u7528\u4e8e\u7ed3\u76f4\u80a0\u764c\u591a\u7c7b\u7ec4\u7ec7\u5206\u7c7b\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6STARC - 9\uff0c\u9610\u8ff0\u5176\u6784\u5efa\u65b9\u6cd5\u5e76\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u96c6\uff0c\u4e14\u6784\u5efa\u6846\u67b6\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u516c\u5171\u7ed3\u76f4\u80a0\u764c\u6570\u636e\u96c6\u5b58\u5728\u5f62\u6001\u591a\u6837\u6027\u4e0d\u8db3\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u56fe\u50cf\u5207\u7247\u8d28\u91cf\u4f4e\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u4f7f\u7528DeepCluster++\u6846\u67b6\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5148\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u63d0\u53d6\u7279\u5f81\u5411\u91cf\uff0c\u518d\u7528K - means\u805a\u7c7b\uff0c\u63a5\u7740\u7b49\u9891\u5206\u7bb1\u91c7\u6837\uff0c\u6700\u540e\u7531\u4e13\u5bb6\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u7c7b\u7ed3\u76f4\u80a0\u764c\u7ec4\u7ec7\u5206\u7c7b\u548c\u5206\u5272\u4efb\u52a1\u4e0a\uff0c\u57fa\u4e8eSTARC - 9\u8bad\u7ec3\u7684\u6a21\u578b\u6bd4\u73b0\u6709\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "DeepCluster++\u6846\u67b6\u6709\u7075\u6d3b\u6027\uff0c\u53ef\u7528\u4e8e\u6784\u5efa\u591a\u79cd\u764c\u75c7\u548c\u975e\u764c\u75c7\u5e94\u7528\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002"}}
{"id": "2511.00592", "pdf": "https://arxiv.org/pdf/2511.00592", "abs": "https://arxiv.org/abs/2511.00592", "authors": ["Massinissa Merouani", "Islem Kara Bernou", "Riyadh Baghdadi"], "title": "Agentic Auto-Scheduling: An Experimental Study of LLM-Guided Loop Optimization", "categories": ["cs.PL", "cs.DC", "cs.LG", "cs.PF"], "comment": "Accepted at the 34th International Conference on Parallel\n  Architectures and Compilation Techniques (PACT 2025). 12 pages, plus appendix", "summary": "Automatic code optimization remains a difficult challenge, particularly for\ncomplex loop nests on modern hardware. This paper investigates a novel approach\nto code optimization where Large Language Models (LLMs) guide the process\nthrough a closed-loop interaction with a compiler. We present ComPilot, an\nexperimental framework that leverages off-the-shelf LLMs, without any\ntask-specific fine-tuning, as interactive optimization agents. ComPilot\nestablishes a feedback loop where an LLM proposes transformations for a given\nloop nest to a compiler. The compiler attempts the transformations, reporting\nback legality status and measured speedup or slowdown. The LLM utilizes this\nconcrete feedback to iteratively refine its optimization strategy. Our\nextensive evaluation across the PolyBench benchmark suite demonstrates the\neffectiveness of this zero-shot approach. ComPilot achieves geometric mean\nspeedups of 2.66x (single run) and 3.54x (best-of-5 runs) over the original\ncode. Furthermore, ComPilot demonstrates competitive performance against the\nstate-of-the-art Pluto polyhedral optimizer, outperforming it in many cases.\nThis experimental study demonstrates that general-purpose LLMs can effectively\nguide the code optimization process when grounded by compiler feedback, opening\npromising research directions for agentic AI in code optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faComPilot\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7f16\u8bd1\u5668\u95ed\u73af\u4ea4\u4e92\u8fdb\u884c\u4ee3\u7801\u4f18\u5316\uff0c\u5728PolyBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6548\u679c\u826f\u597d\uff0c\u8bc1\u660e\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u6709\u6548\u6307\u5bfc\u4ee3\u7801\u4f18\u5316\u3002", "motivation": "\u89e3\u51b3\u73b0\u4ee3\u786c\u4ef6\u4e0a\u590d\u6742\u5faa\u73af\u5d4c\u5957\u7684\u81ea\u52a8\u4ee3\u7801\u4f18\u5316\u96be\u9898\u3002", "method": "\u63d0\u51faComPilot\u6846\u67b6\uff0c\u5229\u7528\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4ea4\u4e92\u5f0f\u4f18\u5316\u4ee3\u7406\uff0c\u5efa\u7acb\u53cd\u9988\u5faa\u73af\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u53d8\u6362\uff0c\u7f16\u8bd1\u5668\u5c1d\u8bd5\u5e76\u53cd\u9988\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u8fed\u4ee3\u4f18\u5316\u7b56\u7565\u3002", "result": "ComPilot\u5728PolyBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5355\u6b21\u8fd0\u884c\u5b9e\u73b02.66\u500d\u30015\u6b21\u6700\u4f73\u8fd0\u884c\u5b9e\u73b03.54\u500d\u7684\u51e0\u4f55\u5e73\u5747\u52a0\u901f\uff0c\u4e14\u5728\u5f88\u591a\u60c5\u51b5\u4e0b\u4f18\u4e8e\u6700\u5148\u8fdb\u7684Pluto\u591a\u9762\u4f53\u4f18\u5316\u5668\u3002", "conclusion": "\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f16\u8bd1\u5668\u53cd\u9988\u7684\u57fa\u7840\u4e0a\u53ef\u6709\u6548\u6307\u5bfc\u4ee3\u7801\u4f18\u5316\uff0c\u4e3a\u4ee3\u7801\u4f18\u5316\u4e2d\u7684\u667a\u80fdAI\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.00634", "pdf": "https://arxiv.org/pdf/2511.00634", "abs": "https://arxiv.org/abs/2511.00634", "authors": ["Mark Kocherovsky", "Illya Bakurov", "Wolfgang Banzhaf"], "title": "Node Preservation and its Effect on Crossover in Cartesian Genetic Programming", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": "Draft to cite in another paper before both papers are peer-reviewed\n  for the evo*2026 conference, 21 pages, 5 figures", "summary": "While crossover is a critical and often indispensable component in other\nforms of Genetic Programming, such as Linear- and Tree-based, it has\nconsistently been claimed that it deteriorates search performance in CGP. As a\nresult, a mutation-alone $(1+\\lambda)$ evolutionary strategy has become the\ncanonical approach for CGP. Although several operators have been developed that\ndemonstrate an increased performance over the canonical method, a general\nsolution to the problem is still lacking. In this paper, we compare basic\ncrossover methods, namely one-point and uniform, to variants in which nodes are\n``preserved,'' including the subgraph crossover developed by Roman Kalkreuth,\nthe difference being that when ``node preservation'' is active, crossover is\nnot allowed to break apart instructions. We also compare a node mutation\noperator to the traditional point mutation; the former simply replaces an\nentire node with a new one. We find that node preservation in both mutation and\ncrossover improves search using symbolic regression benchmark problems, moving\nthe field towards a general solution to CGP crossover.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86CGP\u4e2d\u57fa\u672c\u4ea4\u53c9\u65b9\u6cd5\u548c\u8282\u70b9\u4fdd\u7559\u7684\u4ea4\u53c9\u65b9\u6cd5\uff0c\u4ee5\u53ca\u8282\u70b9\u53d8\u5f02\u7b97\u5b50\u548c\u4f20\u7edf\u70b9\u53d8\u5f02\uff0c\u53d1\u73b0\u8282\u70b9\u4fdd\u7559\u5728\u53d8\u5f02\u548c\u4ea4\u53c9\u4e2d\u80fd\u6539\u5584\u641c\u7d22\uff0c\u63a8\u52a8CGP\u4ea4\u53c9\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5728CGP\u4e2d\uff0c\u4ea4\u53c9\u5e38\u88ab\u8ba4\u4e3a\u4f1a\u964d\u4f4e\u641c\u7d22\u6027\u80fd\uff0c\u73b0\u6709\u65b9\u6cd5\u867d\u6709\u6539\u8fdb\u4f46\u7f3a\u4e4f\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6bd4\u8f83\u57fa\u672c\u4ea4\u53c9\u65b9\u6cd5\uff08\u4e00\u70b9\u4ea4\u53c9\u548c\u5747\u5300\u4ea4\u53c9\uff09\u4e0e\u8282\u70b9\u4fdd\u7559\u7684\u4ea4\u53c9\u65b9\u6cd5\uff0c\u4ee5\u53ca\u8282\u70b9\u53d8\u5f02\u7b97\u5b50\u548c\u4f20\u7edf\u70b9\u53d8\u5f02\u3002", "result": "\u4f7f\u7528\u7b26\u53f7\u56de\u5f52\u57fa\u51c6\u95ee\u9898\uff0c\u53d1\u73b0\u8282\u70b9\u4fdd\u7559\u5728\u53d8\u5f02\u548c\u4ea4\u53c9\u4e2d\u80fd\u6539\u5584\u641c\u7d22\u3002", "conclusion": "\u8282\u70b9\u4fdd\u7559\u6709\u52a9\u4e8e\u63a8\u52a8CGP\u4ea4\u53c9\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00414", "pdf": "https://arxiv.org/pdf/2511.00414", "abs": "https://arxiv.org/abs/2511.00414", "authors": ["Sirintra Vaiwsri", "Thilina Ranbaduge"], "title": "Embedding based Encoding Scheme for Privacy Preserving Record Linkage", "categories": ["cs.DB"], "comment": "12 pages", "summary": "To discover new insights from data, there is a growing need to share\ninformation that is often held by different organisations. One key task in data\nintegration is the calculation of similarities between records in different\ndatabases to identify pairs or sets of records that correspond to the same\nreal-world entities. Due to privacy and confidentiality concerns, however, the\nowners of sensitive databases are often not allowed or willing to exchange or\nshare their data with other organisations to allow such similarity\ncalculations. Privacy-preserving record linkage (PPRL) is the process of\nmatching records that refer to the same entity across sensitive databases held\nby different organisations while ensuring no information about the entities is\nrevealed to the participating parties. In this paper, we study how embedding\nbased encoding techniques can be applied in the PPRL context to ensure the\nprivacy of the entities that are being linked. We first convert individual\nq-grams into the embedded space and then convert the embedding of a set of\nq-grams of a given record into a binary representation. The final binary\nrepresentations can be used to link records into matches and non-matches. We\nempirically evaluate our proposed encoding technique against different\nreal-world datasets. The results suggest that our proposed encoding approach\ncan provide better linkage accuracy and protect the privacy of individuals\nagainst attack compared to state-of-the-art techniques for short record values.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u57fa\u4e8e\u5d4c\u5165\u7684\u7f16\u7801\u6280\u672f\u5728\u9690\u79c1\u4fdd\u62a4\u8bb0\u5f55\u94fe\u63a5\uff08PPRL\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u7f16\u7801\u65b9\u6cd5\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u80fd\u63d0\u9ad8\u94fe\u63a5\u51c6\u786e\u6027\u548c\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u4e0d\u540c\u7ec4\u7ec7\u6709\u6570\u636e\u5171\u4eab\u9700\u6c42\uff0c\u4f46\u654f\u611f\u6570\u636e\u5e93\u6240\u6709\u8005\u56e0\u9690\u79c1\u548c\u4fdd\u5bc6\u95ee\u9898\u4e0d\u613f\u4ea4\u6362\u6570\u636e\uff0c\u9700\u8981\u5728PPRL\u4e2d\u5e94\u7528\u6280\u672f\u786e\u4fdd\u5b9e\u4f53\u9690\u79c1\u3002", "method": "\u5148\u5c06\u5355\u4e2aq - grams\u8f6c\u6362\u5230\u5d4c\u5165\u7a7a\u95f4\uff0c\u518d\u5c06\u7ed9\u5b9a\u8bb0\u5f55\u7684\u4e00\u7ec4q - grams\u7684\u5d4c\u5165\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u8868\u793a\uff0c\u7528\u4e8e\u8bb0\u5f55\u5339\u914d\u3002", "result": "\u5bf9\u4e0d\u540c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7f16\u7801\u65b9\u6cd5\u5728\u77ed\u8bb0\u5f55\u503c\u65b9\u9762\u6bd4\u73b0\u6709\u6280\u672f\u6709\u66f4\u597d\u7684\u94fe\u63a5\u51c6\u786e\u6027\uff0c\u4e14\u80fd\u4fdd\u62a4\u4e2a\u4eba\u9690\u79c1\u3002", "conclusion": "\u57fa\u4e8e\u5d4c\u5165\u7684\u7f16\u7801\u6280\u672f\u53ef\u5728PPRL\u4e2d\u5e94\u7528\uff0c\u80fd\u63d0\u9ad8\u94fe\u63a5\u51c6\u786e\u6027\u5e76\u4fdd\u62a4\u9690\u79c1\u3002"}}
{"id": "2511.00847", "pdf": "https://arxiv.org/pdf/2511.00847", "abs": "https://arxiv.org/abs/2511.00847", "authors": ["Yuhan Cao", "Yu Wang", "Sitong Liu", "Miao Li", "Yixin Tao", "Tianxing He"], "title": "Pay for The Second-Best Service: A Game-Theoretic Approach Against Dishonest LLM Providers", "categories": ["cs.GT", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "The widespread adoption of Large Language Models (LLMs) through Application\nProgramming Interfaces (APIs) induces a critical vulnerability: the potential\nfor dishonest manipulation by service providers. This manipulation can manifest\nin various forms, such as secretly substituting a proclaimed high-performance\nmodel with a low-cost alternative, or inflating responses with meaningless\ntokens to increase billing. This work tackles the issue through the lens of\nalgorithmic game theory and mechanism design. We are the first to propose a\nformal economic model for a realistic user-provider ecosystem, where a user can\niteratively delegate $T$ queries to multiple model providers, and providers can\nengage in a range of strategic behaviors. As our central contribution, we prove\nthat for a continuous strategy space and any $\\epsilon\\in(0,\\frac12)$, there\nexists an approximate incentive-compatible mechanism with an additive\napproximation ratio of $O(T^{1-\\epsilon}\\log T)$, and a guaranteed quasi-linear\nsecond-best user utility. We also prove an impossibility result, stating that\nno mechanism can guarantee an expected user utility that is asymptotically\nbetter than our mechanism. Furthermore, we demonstrate the effectiveness of our\nmechanism in simulation experiments with real-world API settings.", "AI": {"tldr": "\u672c\u6587\u4ece\u7b97\u6cd5\u535a\u5f08\u8bba\u548c\u673a\u5236\u8bbe\u8ba1\u89d2\u5ea6\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578bAPI\u670d\u52a1\u63d0\u4f9b\u5546\u53ef\u80fd\u7684\u4e0d\u8bda\u5b9e\u64cd\u7eb5\u95ee\u9898\uff0c\u63d0\u51fa\u7ecf\u6d4e\u6a21\u578b\u5e76\u7ed9\u51fa\u8fd1\u4f3c\u6fc0\u52b1\u517c\u5bb9\u673a\u5236\u53ca\u76f8\u5173\u8bc1\u660e\uff0c\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7API\u5e7f\u6cdb\u5e94\u7528\uff0c\u670d\u52a1\u63d0\u4f9b\u5546\u5b58\u5728\u4e0d\u8bda\u5b9e\u64cd\u7eb5\u7684\u6f5c\u5728\u98ce\u9669\uff0c\u5982\u66ff\u6362\u6a21\u578b\u3001\u589e\u52a0\u8ba1\u8d39\u7b49\u3002", "method": "\u8fd0\u7528\u7b97\u6cd5\u535a\u5f08\u8bba\u548c\u673a\u5236\u8bbe\u8ba1\uff0c\u63d0\u51fa\u73b0\u5b9e\u7528\u6237 - \u63d0\u4f9b\u5546\u751f\u6001\u7cfb\u7edf\u7684\u6b63\u5f0f\u7ecf\u6d4e\u6a21\u578b\u3002", "result": "\u8bc1\u660e\u5bf9\u4e8e\u8fde\u7eed\u7b56\u7565\u7a7a\u95f4\u548c\u4efb\u610f \u03b5\u2208(0, 1/2)\uff0c\u5b58\u5728\u8fd1\u4f3c\u6fc0\u52b1\u517c\u5bb9\u673a\u5236\uff0c\u6709 O(T^(1 - \u03b5)log T) \u7684\u52a0\u6027\u8fd1\u4f3c\u6bd4\u548c\u51c6\u7ebf\u6027\u6b21\u4f18\u7528\u6237\u6548\u7528\uff1b\u8bc1\u660e\u4e0d\u5b58\u5728\u6e10\u8fd1\u4e0a\u6bd4\u8be5\u673a\u5236\u66f4\u597d\u7684\u673a\u5236\uff1b\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u673a\u5236\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u673a\u5236\u80fd\u6709\u6548\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578bAPI\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u4e0d\u8bda\u5b9e\u64cd\u7eb5\u95ee\u9898\u3002"}}
{"id": "2511.00895", "pdf": "https://arxiv.org/pdf/2511.00895", "abs": "https://arxiv.org/abs/2511.00895", "authors": ["Hansj\u00f6rg Albrecher", "Filip Lindskog", "Herv\u00e9 Zumbach"], "title": "Cost-of-capital valuation with risky assets", "categories": ["q-fin.RM", "91G05"], "comment": null, "summary": "Cost-of-capital valuation is a well-established approach to the valuation of\nliabilities and is one of the cornerstones of current regulatory frameworks for\nthe insurance industry. Standard cost-of-capital considerations typically rely\non the assumption that the required buffer capital is held in risk-less\none-year bonds. The aim of this work is to analyze the effects of allowing\ninvestments of the buffer capital in risky assets, e.g.~in a combination of\nstocks and bonds. In particular, we make precise how the decomposition of the\nbuffer capital into contributions from policyholders and investors varies as\nthe degree of riskiness of the investment increases, and highlight the role of\nlimited liability in the case of heavy-tailed insurance risks. We present a\ncombination of general theoretical results, explicit results for certain\nstochastic models and numerical results that emphasize the key findings.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u7f13\u51b2\u8d44\u672c\u6295\u8d44\u4e8e\u98ce\u9669\u8d44\u4ea7\u5bf9\u8d1f\u503a\u4f30\u503c\u7684\u5f71\u54cd\uff0c\u7ed9\u51fa\u7406\u8bba\u3001\u7279\u5b9a\u968f\u673a\u6a21\u578b\u548c\u6570\u503c\u7ed3\u679c\u3002", "motivation": "\u6807\u51c6\u8d44\u672c\u6210\u672c\u8003\u8651\u901a\u5e38\u5047\u8bbe\u7f13\u51b2\u8d44\u672c\u6295\u8d44\u4e8e\u65e0\u98ce\u9669\u4e00\u5e74\u671f\u503a\u5238\uff0c\u672c\u6587\u65e8\u5728\u5206\u6790\u6295\u8d44\u4e8e\u98ce\u9669\u8d44\u4ea7\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u4e00\u822c\u7406\u8bba\u7ed3\u679c\u3001\u7279\u5b9a\u968f\u673a\u6a21\u578b\u7684\u660e\u786e\u7ed3\u679c\u548c\u6570\u503c\u7ed3\u679c\u8fdb\u884c\u5206\u6790\u3002", "result": "\u660e\u786e\u4e86\u968f\u7740\u6295\u8d44\u98ce\u9669\u7a0b\u5ea6\u589e\u52a0\uff0c\u7f13\u51b2\u8d44\u672c\u4e2d\u4fdd\u5355\u6301\u6709\u4eba\u548c\u6295\u8d44\u8005\u8d21\u732e\u7684\u5206\u89e3\u53d8\u5316\uff0c\u5e76\u5f3a\u8c03\u4e86\u91cd\u5c3e\u4fdd\u9669\u98ce\u9669\u4e0b\u6709\u9650\u8d23\u4efb\u7684\u4f5c\u7528\u3002", "conclusion": "\u7814\u7a76\u4e86\u7f13\u51b2\u8d44\u672c\u6295\u8d44\u98ce\u9669\u8d44\u4ea7\u5bf9\u8d1f\u503a\u4f30\u503c\u7684\u5f71\u54cd\u53ca\u76f8\u5173\u56e0\u7d20\u7684\u4f5c\u7528\u3002"}}
{"id": "2511.00366", "pdf": "https://arxiv.org/pdf/2511.00366", "abs": "https://arxiv.org/abs/2511.00366", "authors": ["Krishna Prasath Logakannan", "Shridhar Vashishtha", "Jacob Hochhalter", "Shandian Zhe", "Robert M. Kirby"], "title": "A Streaming Sparse Cholesky Method for Derivative-Informed Gaussian Process Surrogates Within Digital Twin Applications", "categories": ["stat.ML", "cs.CE", "cs.LG"], "comment": null, "summary": "Digital twins are developed to model the behavior of a specific physical\nasset (or twin), and they can consist of high-fidelity physics-based models or\nsurrogates. A highly accurate surrogate is often preferred over multi-physics\nmodels as they enable forecasting the physical twin future state in real-time.\nTo adapt to a specific physical twin, the digital twin model must be updated\nusing in-service data from that physical twin. Here, we extend Gaussian process\n(GP) models to include derivative data, for improved accuracy, with dynamic\nupdating to ingest physical twin data during service. Including derivative\ndata, however, comes at a prohibitive cost of increased covariance matrix\ndimension. We circumvent this issue by using a sparse GP approximation, for\nwhich we develop extensions to incorporate derivatives. Numerical experiments\ndemonstrate that the prediction accuracy of the derivative-enhanced sparse GP\nmethod produces improved models upon dynamic data additions. Lastly, we apply\nthe developed algorithm within a DT framework to model fatigue crack growth in\nan aerospace vehicle.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u4ee5\u5305\u542b\u5bfc\u6570\u6570\u636e\uff0c\u7528\u7a00\u758fGP\u8fd1\u4f3c\u89e3\u51b3\u6210\u672c\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u6539\u5584\u6a21\u578b\uff0c\u8fd8\u5c06\u7b97\u6cd5\u7528\u4e8e\u822a\u7a7a\u822a\u5929\u8f66\u8f86\u75b2\u52b3\u88c2\u7eb9\u589e\u957f\u5efa\u6a21\u3002", "motivation": "\u4e3a\u4f7f\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u9002\u5e94\u7279\u5b9a\u7269\u7406\u5b6a\u751f\u4f53\uff0c\u9700\u7528\u7269\u7406\u5b6a\u751f\u4f53\u7684\u670d\u5f79\u6570\u636e\u66f4\u65b0\u6a21\u578b\uff0c\u540c\u65f6\u5e0c\u671b\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u6269\u5c55\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u6a21\u578b\u4ee5\u5305\u542b\u5bfc\u6570\u6570\u636e\uff0c\u4f7f\u7528\u7a00\u758fGP\u8fd1\u4f3c\u89e3\u51b3\u534f\u65b9\u5dee\u77e9\u9635\u7ef4\u5ea6\u589e\u52a0\u7684\u6210\u672c\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u6269\u5c55\u4ee5\u7eb3\u5165\u5bfc\u6570\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u5bfc\u6570\u589e\u5f3a\u7684\u7a00\u758fGP\u65b9\u6cd5\u5728\u52a8\u6001\u6dfb\u52a0\u6570\u636e\u65f6\u80fd\u4ea7\u751f\u66f4\u4f18\u6a21\u578b\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u7b97\u6cd5\u53ef\u7528\u4e8e\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e2d\u5bf9\u822a\u7a7a\u822a\u5929\u8f66\u8f86\u7684\u75b2\u52b3\u88c2\u7eb9\u589e\u957f\u8fdb\u884c\u5efa\u6a21\u3002"}}
{"id": "2511.00374", "pdf": "https://arxiv.org/pdf/2511.00374", "abs": "https://arxiv.org/abs/2511.00374", "authors": ["Itai Maimon"], "title": "Different Forms of Imbalance in Strongly Playable Discrete Games I: Two-Player RPS Games", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We construct several definitions of imbalance and playability, both of which\nare related to the existence of dominated strategies. Specifically, a maximally\nbalanced game and a playable game cannot have dominated strategies for any\nplayer. In this context, imbalance acts as a measure of inequality in strategy,\nsimilar to measures of inequality in wealth or population dynamics. Conversely,\nplayability is a slight strengthening of the condition that a game has no\ndominated strategies. It is more accurately aligned with the intuition that all\nstrategies should see play. We show that these balance definitions are natural\nby exhibiting a (2n+1)-RPS that maximizes all proposed imbalance definitions\namong playable RPS games. We demonstrate here that this form of imbalance\naligns with the prevailing notion that different definitions of inequality for\neconomic and game-theoretic distributions must agree on both the maximal and\nminimal cases. In the sequel paper, we utilize these definitions for\nmultiplayer games to demonstrate that a generalization of this imbalanced RPS\nis at least nearly maximally imbalanced while remaining playable for under 50\nplayers.", "AI": {"tldr": "\u6784\u5efa\u4e0d\u5e73\u8861\u6027\u548c\u53ef\u73a9\u6027\u5b9a\u4e49\uff0c\u4ee5\u4e3b\u5bfc\u7b56\u7565\u5b58\u5728\u60c5\u51b5\u8861\u91cf\uff0c\u5c55\u793a(2n + 1)-RPS\u6700\u5927\u5316\u4e0d\u5e73\u8861\u5b9a\u4e49\uff0c\u540e\u7eed\u5c06\u7528\u4e8e\u591a\u4eba\u6e38\u620f\u3002", "motivation": "\u4e3a\u6e38\u620f\u7684\u4e0d\u5e73\u8861\u6027\u548c\u53ef\u73a9\u6027\u7ed9\u51fa\u5408\u7406\u5b9a\u4e49\uff0c\u4f7f\u5176\u4e0e\u7ecf\u6d4e\u548c\u535a\u5f08\u8bba\u4e2d\u4e0d\u5e73\u7b49\u5b9a\u4e49\u5728\u6700\u5927\u548c\u6700\u5c0f\u60c5\u51b5\u4e0a\u8fbe\u6210\u4e00\u81f4\u3002", "method": "\u6784\u5efa\u4e0d\u5e73\u8861\u6027\u548c\u53ef\u73a9\u6027\u7684\u5b9a\u4e49\uff0c\u901a\u8fc7(2n + 1)-RPS\u5c55\u793a\u5b9a\u4e49\u7684\u5408\u7406\u6027\u3002", "result": "\u6240\u63d0\u51fa\u7684\u4e0d\u5e73\u8861\u6027\u5b9a\u4e49\u5728\u53ef\u73a9\u7684RPS\u6e38\u620f\u4e2d\u80fd\u88ab(2n + 1)-RPS\u6700\u5927\u5316\uff0c\u4e14\u4e0e\u7ecf\u6d4e\u548c\u535a\u5f08\u8bba\u4e2d\u4e0d\u5e73\u7b49\u5b9a\u4e49\u5728\u6700\u5927\u6700\u5c0f\u60c5\u51b5\u4e0a\u76f8\u7b26\u3002", "conclusion": "\u8fd9\u4e9b\u5e73\u8861\u5b9a\u4e49\u662f\u81ea\u7136\u5408\u7406\u7684\uff0c\u540e\u7eed\u53ef\u7528\u4e8e\u591a\u4eba\u6e38\u620f\u5206\u6790\u3002"}}
{"id": "2511.01271", "pdf": "https://arxiv.org/pdf/2511.01271", "abs": "https://arxiv.org/abs/2511.01271", "authors": ["Zhaoxing Gao", "Sihan Tu", "Ruey S. Tsay"], "title": "High-Dimensional Spatial Arbitrage Pricing Theory with Heterogeneous Interactions", "categories": ["econ.EM", "q-fin.PR", "q-fin.ST"], "comment": "48 pages, 8 figures", "summary": "This paper investigates estimation and inference of a Spatial Arbitrage\nPricing Theory (SAPT) model that integrates spatial interactions with\nmulti-factor analysis, accommodating both observable and latent factors.\nBuilding on the classical mean-variance analysis, we introduce a class of\nSpatial Capital Asset Pricing Models (SCAPM) that account for spatial effects\nin high-dimensional assets, where we define {\\it spatial rho} as a counterpart\nto market beta in CAPM. We then extend SCAPM to a general SAPT framework under\na {\\it complete} market setting by incorporating multiple factors. For SAPT\nwith observable factors, we propose a generalized shrinkage Yule-Walker (SYW)\nestimation method that integrates ridge regression to estimate spatial and\nfactor coefficients. When factors are latent, we first apply an\nautocovariance-based eigenanalysis to extract factors, then employ the SYW\nmethod using the estimated factors. We establish asymptotic properties for\nthese estimators under high-dimensional settings where both the dimension and\nsample size diverge. Finally, we use simulated and real data examples to\ndemonstrate the efficacy and usefulness of the proposed model and method.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6574\u5408\u7a7a\u95f4\u4ea4\u4e92\u4e0e\u591a\u56e0\u7d20\u5206\u6790\u7684\u7a7a\u95f4\u5957\u5229\u5b9a\u4ef7\u7406\u8bba\uff08SAPT\uff09\u6a21\u578b\u7684\u4f30\u8ba1\u548c\u63a8\u65ad\uff0c\u5f15\u5165\u8003\u8651\u7a7a\u95f4\u6548\u5e94\u7684\u7a7a\u95f4\u8d44\u672c\u8d44\u4ea7\u5b9a\u4ef7\u6a21\u578b\uff08SCAPM\uff09\uff0c\u63d0\u51fa\u5e7f\u4e49\u6536\u7f29Yule - Walker\uff08SYW\uff09\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u9ad8\u7ef4\u6e10\u8fd1\u6027\u8d28\u5e76\u901a\u8fc7\u6570\u636e\u9a8c\u8bc1\u3002", "motivation": "\u7814\u7a76\u6574\u5408\u7a7a\u95f4\u4ea4\u4e92\u4e0e\u591a\u56e0\u7d20\u5206\u6790\u7684SAPT\u6a21\u578b\u7684\u4f30\u8ba1\u548c\u63a8\u65ad\uff0c\u5728\u9ad8\u7ef4\u8d44\u4ea7\u4e2d\u8003\u8651\u7a7a\u95f4\u6548\u5e94\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u5747\u503c - \u65b9\u5dee\u5206\u6790\u5f15\u5165SCAPM\uff0c\u5c06\u5176\u6269\u5c55\u5230SAPT\u6846\u67b6\uff1b\u5bf9\u542b\u53ef\u89c2\u6d4b\u56e0\u7d20\u7684SAPT\u91c7\u7528\u5e7f\u4e49\u6536\u7f29SYW\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5bf9\u542b\u6f5c\u5728\u56e0\u7d20\u7684\u60c5\u51b5\u5148\u8fdb\u884c\u57fa\u4e8e\u81ea\u534f\u65b9\u5dee\u7684\u7279\u5f81\u5206\u6790\u63d0\u53d6\u56e0\u7d20\u518d\u7528SYW\u65b9\u6cd5\uff1b\u5efa\u7acb\u9ad8\u7ef4\u6e10\u8fd1\u6027\u8d28\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4f8b\u5b50\u8bc1\u660e\u4e86\u6240\u63d0\u6a21\u578b\u548c\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u548c\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u8d44\u4ea7\u5b9a\u4ef7\u4e2d\u8003\u8651\u7a7a\u95f4\u6548\u5e94\u662f\u6709\u6548\u7684\u548c\u6709\u7528\u7684\u3002"}}
{"id": "2511.00190", "pdf": "https://arxiv.org/pdf/2511.00190", "abs": "https://arxiv.org/abs/2511.00190", "authors": ["Andrea Macr\u00ec", "Sebastian Jaimungal", "Fabrizio Lillo"], "title": "Deep reinforcement learning for optimal trading with partial information", "categories": ["q-fin.TR", "q-fin.CP", "stat.ML"], "comment": null, "summary": "Reinforcement Learning (RL) applied to financial problems has been the\nsubject of a lively area of research. The use of RL for optimal trading\nstrategies that exploit latent information in the market is, to the best of our\nknowledge, not widely tackled. In this paper we study an optimal trading\nproblem, where a trading signal follows an Ornstein-Uhlenbeck process with\nregime-switching dynamics. We employ a blend of RL and Recurrent Neural\nNetworks (RNN) in order to make the most at extracting underlying information\nfrom the trading signal with latent parameters.\n  The latent parameters driving mean reversion, speed, and volatility are\nfiltered from observations of the signal, and trading strategies are derived\nvia RL. To address this problem, we propose three Deep Deterministic Policy\nGradient (DDPG)-based algorithms that integrate Gated Recurrent Unit (GRU)\nnetworks to capture temporal dependencies in the signal. The first, a one -step\napproach (hid-DDPG), directly encodes hidden states from the GRU into the RL\ntrader. The second and third are two-step methods: one (prob-DDPG) makes use of\nposterior regime probability estimates, while the other (reg-DDPG) relies on\nforecasts of the next signal value. Through extensive simulations with\nincreasingly complex Markovian regime dynamics for the trading signal's\nparameters, as well as an empirical application to equity pair trading, we find\nthat prob-DDPG achieves superior cumulative rewards and exhibits more\ninterpretable strategies. By contrast, reg-DDPG provides limited benefits,\nwhile hid-DDPG offers intermediate performance with less interpretable\nstrategies. Our results show that the quality and structure of the information\nsupplied to the agent are crucial: embedding probabilistic insights into latent\nregimes substantially improves both profitability and robustness of\nreinforcement learning-based trading strategies.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u57fa\u4e8e\u5965\u6069\u65af\u5766 - \u4e4c\u4f26\u8d1d\u514b\u8fc7\u7a0b\u7684\u6700\u4f18\u4ea4\u6613\u95ee\u9898\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8eDDPG\u7684\u7b97\u6cd5\uff0c\u7ecf\u6a21\u62df\u548c\u5b9e\u8bc1\u53d1\u73b0prob - DDPG\u8868\u73b0\u6700\u4f18\uff0c\u5f3a\u8c03\u4fe1\u606f\u8d28\u91cf\u548c\u7ed3\u6784\u5bf9\u4ea4\u6613\u7b56\u7565\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u5236\u5b9a\u6700\u4f18\u4ea4\u6613\u7b56\u7565\u4ee5\u6316\u6398\u5e02\u573a\u6f5c\u5728\u4fe1\u606f\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u57fa\u4e8e\u5965\u6069\u65af\u5766 - \u4e4c\u4f26\u8d1d\u514b\u8fc7\u7a0b\u7684\u6700\u4f18\u4ea4\u6613\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8eDDPG\u5e76\u96c6\u6210GRU\u7f51\u7edc\u7684\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u8bc1\uff0cprob - DDPG\u7d2f\u79ef\u56de\u62a5\u6700\u4f18\u4e14\u7b56\u7565\u66f4\u5177\u53ef\u89e3\u91ca\u6027\uff0creg - DDPG\u6548\u76ca\u6709\u9650\uff0chid - DDPG\u8868\u73b0\u5c45\u4e2d\u4e14\u7b56\u7565\u53ef\u89e3\u91ca\u6027\u5dee\u3002", "conclusion": "\u63d0\u4f9b\u7ed9\u667a\u80fd\u4f53\u7684\u4fe1\u606f\u8d28\u91cf\u548c\u7ed3\u6784\u81f3\u5173\u91cd\u8981\uff0c\u878d\u5165\u6f5c\u5728\u72b6\u6001\u7684\u6982\u7387\u4fe1\u606f\u80fd\u63d0\u5347\u4ea4\u6613\u7b56\u7565\u7684\u76c8\u5229\u80fd\u529b\u548c\u7a33\u5065\u6027\u3002"}}
{"id": "2511.00708", "pdf": "https://arxiv.org/pdf/2511.00708", "abs": "https://arxiv.org/abs/2511.00708", "authors": ["Quan Zhou"], "title": "Polynomial Mixing Times of Simulated Tempering for Mixture Targets by Conductance Decomposition", "categories": ["stat.CO", "math.PR", "stat.ML", "60J20, 65C05, 65C40, 68Q25"], "comment": "37 pages", "summary": "We study the theoretical complexity of simulated tempering for sampling from\nmixtures of log-concave components differing only by location shifts. The main\nresult establishes the first polynomial-time guarantee for simulated tempering\ncombined with the Metropolis-adjusted Langevin algorithm (MALA) with respect to\nthe problem dimension $d$, maximum mode displacement $D$, and logarithmic\naccuracy $\\log \\epsilon^{-1}$. The proof builds on a general state\ndecomposition theorem for $s$-conductance, applied to an auxiliary Markov chain\nconstructed on an augmented space. We also obtain an improved complexity\nestimate for simulated tempering combined with random-walk Metropolis. Our\nbounds assume an inverse-temperature ladder with smallest value $\\beta_1 =\nO(D^{-2})$ and spacing $\\beta_{i+1}/\\beta_i = 1 + O( d^{-1/2} )$, both of which\nare shown to be asymptotically optimal up to logarithmic factors.", "AI": {"tldr": "\u7814\u7a76\u6a21\u62df\u56de\u706b\u4ece\u4ec5\u4f4d\u7f6e\u504f\u79fb\u4e0d\u540c\u7684\u5bf9\u6570\u51f9\u5206\u91cf\u6df7\u5408\u4e2d\u91c7\u6837\u7684\u7406\u8bba\u590d\u6742\u5ea6\uff0c\u7ed9\u51fa\u6a21\u62df\u56de\u706b\u7ed3\u5408MALA\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u4fdd\u8bc1\u53ca\u6539\u8fdb\u590d\u6742\u5ea6\u4f30\u8ba1\uff0c\u8bc1\u660e\u9006\u6e29\u5ea6\u68af\u6700\u4f18\u6027\u3002", "motivation": "\u7814\u7a76\u6a21\u62df\u56de\u706b\u4ece\u7279\u5b9a\u5bf9\u6570\u51f9\u5206\u91cf\u6df7\u5408\u4e2d\u91c7\u6837\u7684\u7406\u8bba\u590d\u6742\u5ea6\u3002", "method": "\u8fd0\u7528s - \u4f20\u5bfc\u6027\u7684\u4e00\u822c\u72b6\u6001\u5206\u89e3\u5b9a\u7406\uff0c\u5e94\u7528\u4e8e\u589e\u5e7f\u7a7a\u95f4\u4e0a\u6784\u9020\u7684\u8f85\u52a9\u9a6c\u5c14\u53ef\u592b\u94fe\u3002", "result": "\u5f97\u5230\u6a21\u62df\u56de\u706b\u7ed3\u5408MALA\u7684\u9996\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u4fdd\u8bc1\uff0c\u53ca\u6a21\u62df\u56de\u706b\u7ed3\u5408\u968f\u673a\u6e38\u8d70Metropolis\u7684\u6539\u8fdb\u590d\u6742\u5ea6\u4f30\u8ba1\uff0c\u8bc1\u660e\u9006\u6e29\u5ea6\u68af\u7684\u6e10\u8fd1\u6700\u4f18\u6027\u3002", "conclusion": "\u5728\u7ed9\u5b9a\u9006\u6e29\u5ea6\u68af\u6761\u4ef6\u4e0b\uff0c\u6a21\u62df\u56de\u706b\u5728\u91c7\u6837\u95ee\u9898\u4e0a\u6709\u826f\u597d\u7406\u8bba\u590d\u6742\u5ea6\uff0c\u9006\u6e29\u5ea6\u68af\u8bbe\u7f6e\u6e10\u8fd1\u6700\u4f18\u3002"}}
{"id": "2511.00807", "pdf": "https://arxiv.org/pdf/2511.00807", "abs": "https://arxiv.org/abs/2511.00807", "authors": ["Xuan He", "Zequan Fang", "Jinzhao Lian", "Danny H. K. Tsang", "Baosen Zhang", "Yize Chen"], "title": "FREESH: Fair, Resource- and Energy-Efficient Scheduling for LLM Serving on Heterogeneous GPUs", "categories": ["cs.DC"], "comment": "In Submission, code available at\n  https://github.com/AndrewFangZequan/LLM_Serving_FREESH", "summary": "The ever-increasing computation and energy demand for LLM and AI agents call\nfor holistic and efficient optimization of LLM serving systems. In practice,\nheterogeneous GPU clusters can be deployed in a geographically distributed\nmanner, while LLM load also observes diversity in terms of both query traffic\nand serving patterns. LLM queries running on advanced GPUs during a\nhigh-emission hour at one location can lead to significantly higher carbon\nfootprints versus same queries running on mid-level GPUs at a low-emission time\nand location. By observing LLM serving requirements and leveraging\nspatiotemporal computation flexibility, we consider the joint routing and\nscheduling problem, and propose FREESH to cooperatively run a group of data\ncenters while minimizing user-specified carbon or energy objectives. FREESH\nidentifies the optimal configurations of balanced load serving by matching\ndistinct GPU instance's power-throughput characteristics with predictable LLM\nquery length and workloads. To ensure both latency and fairness requirements,\nFREESH identifies optimized parallelism and query routing schedules together\nwith dynamic GPU frequency scaling for power saving, and Least-Laxity-First\n(LLF) serving strategy for query scheduling. During the 1-hour serving on\nproduction workloads, FREESH reduces energy by 28.6% and emissions by 45.45%\ntogether with improvements in SLO attainment and fairness.", "AI": {"tldr": "\u9488\u5bf9LLM\u670d\u52a1\u7cfb\u7edf\uff0c\u63d0\u51faFREESH\u65b9\u6cd5\uff0c\u53ef\u5728\u751f\u4ea7\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u8282\u80fd\u964d\u6392\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "LLM\u548cAI\u4ee3\u7406\u5bf9\u8ba1\u7b97\u548c\u80fd\u6e90\u9700\u6c42\u4e0d\u65ad\u589e\u52a0\uff0c\u5f02\u6784GPU\u96c6\u7fa4\u5730\u7406\u5206\u5e03\u4e14\u8d1f\u8f7d\u591a\u6837\uff0c\u9700\u4f18\u5316LLM\u670d\u52a1\u7cfb\u7edf\u4ee5\u964d\u4f4e\u78b3\u548c\u80fd\u6e90\u76ee\u6807\u3002", "method": "\u8003\u8651\u8054\u5408\u8def\u7531\u548c\u8c03\u5ea6\u95ee\u9898\uff0c\u63d0\u51faFREESH\uff0c\u5339\u914dGPU\u7279\u6027\u4e0e\u67e5\u8be2\u8d1f\u8f7d\uff0c\u786e\u5b9a\u4f18\u5316\u5e76\u884c\u6027\u3001\u67e5\u8be2\u8def\u7531\u548c\u52a8\u6001GPU\u9891\u7387\u7f29\u653e\uff0c\u91c7\u7528LLF\u670d\u52a1\u7b56\u7565\u3002", "result": "\u57281\u5c0f\u65f6\u751f\u4ea7\u5de5\u4f5c\u8d1f\u8f7d\u670d\u52a1\u4e2d\uff0cFREESH\u8282\u80fd28.6%\uff0c\u51cf\u639245.45%\uff0c\u63d0\u5347SLO\u8fbe\u6807\u7387\u548c\u516c\u5e73\u6027\u3002", "conclusion": "FREESH\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4eLLM\u670d\u52a1\u7cfb\u7edf\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\uff0c\u540c\u65f6\u4fdd\u8bc1\u6027\u80fd\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2511.00436", "pdf": "https://arxiv.org/pdf/2511.00436", "abs": "https://arxiv.org/abs/2511.00436", "authors": ["Doyun Choi", "Cheonwoo Lee", "Jaemin Yoo"], "title": "Simple and Behavior-Driven Augmentation for Recommendation with Rich Collaborative Signals", "categories": ["cs.IR"], "comment": "10 pages. This paper is accepted at IEEE BigData 2025 (Short)", "summary": "Contrastive learning (CL) has been widely used for enhancing the performance\nof graph collaborative filtering (GCF) for personalized recommendation. Since\ndata augmentation plays a crucial role in the success of CL, previous works\nhave designed augmentation methods to remove noisy interactions between users\nand items in order to generate effective augmented views. However, the\nambiguity in defining ''noisiness'' presents a persistent risk of losing core\ninformation and generating unreliable data views, while increasing the overall\ncomplexity of augmentation. In this paper, we propose Simple Collaborative\nAugmentation for Recommendation (SCAR), a novel and intuitive augmentation\nmethod designed to maximize the effectiveness of CL for GCF. Instead of\nremoving information, SCAR leverages collaborative signals extracted from\nuser-item interactions to generate pseudo-interactions, which are then either\nadded to or used to replace existing interactions. This results in more robust\nrepresentations while avoiding the pitfalls of overly complex augmentation\nmodules. We conduct experiments on four benchmark datasets and show that SCAR\noutperforms previous CL-based GCF methods as well as other state-of-the-art\nself-supervised learning approaches across key evaluation metrics. SCAR\nexhibits strong robustness across different hyperparameter settings and is\nparticularly effective in sparse data scenarios.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u56fe\u534f\u540c\u8fc7\u6ee4\u7684\u7b80\u5355\u534f\u4f5c\u589e\u5f3a\u65b9\u6cd5SCAR\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u548c\u7a00\u758f\u6570\u636e\u573a\u666f\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5148\u524d\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u56fe\u534f\u540c\u8fc7\u6ee4\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5b58\u5728\u5b9a\u4e49\u566a\u58f0\u6a21\u7cca\u3001\u6613\u4e22\u5931\u6838\u5fc3\u4fe1\u606f\u3001\u589e\u52a0\u590d\u6742\u5ea6\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSCAR\u65b9\u6cd5\uff0c\u5229\u7528\u7528\u6237 - \u9879\u76ee\u4ea4\u4e92\u7684\u534f\u4f5c\u4fe1\u53f7\u751f\u6210\u4f2a\u4ea4\u4e92\uff0c\u6dfb\u52a0\u6216\u66ff\u6362\u73b0\u6709\u4ea4\u4e92\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cSCAR\u5728\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u5148\u524d\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u56fe\u534f\u540c\u8fc7\u6ee4\u65b9\u6cd5\u548c\u5176\u4ed6\u5148\u8fdb\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "SCAR\u5177\u6709\u8f83\u5f3a\u9c81\u68d2\u6027\uff0c\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u5728\u7a00\u758f\u6570\u636e\u573a\u666f\u7279\u522b\u6709\u6548\u3002"}}
{"id": "2511.00254", "pdf": "https://arxiv.org/pdf/2511.00254", "abs": "https://arxiv.org/abs/2511.00254", "authors": ["Chandra Chekuri", "Guyslain Naves", "Joseph Poremba", "F. Bruce Shepherd"], "title": "Uncrossed Multiflows and Applications to Disjoint Paths", "categories": ["cs.DS", "cs.CG"], "comment": null, "summary": "A multiflow in a planar graph is uncrossed if the curves identified by its\nsupport paths do not cross in the plane. Such flows have played a role in\nprevious routing algorithms, including Schrijver's Homotopy Method and\nunsplittable flows in directed planar single-source instances. Recently\nuncrossed flows have played a key role in approximation algorithms for maximum\ndisjoint paths in fully-planar instances, where the combined supply plus demand\ngraph is planar. In the fully-planar case, any fractional multiflow can be\nconverted into one that is uncrossed, which is then exploited to find a good\nrounding of the fractional solution. We investigate finding an uncrossed\nmultiflow as a standalone algorithmic problem in general planar instances (not\nnecessarily fully-planar). We consider both a congestion model where the given\ndemands must all be routed, and a maximization model where the goal is to pack\nas much flow in the supply graph as possible (not necessarily equitably).\n  For the congestion model, we show that determining if an instance has an\nuncrossed (fractional) multiflow is NP-hard, but the problem of finding an\nintegral uncrossed flow is polytime solvable if the demands span a bounded\nnumber of faces. For the maximization model, we present a strong (almost\npolynomial) inapproximability result. Regarding integrality gaps, for\nmaximization we show that an uncrossed multiflow in a planar instance can\nalways be rounded to an integral multiflow with a constant fraction of the\noriginal value. This holds in both the edge-capacitated and node-capacitated\nsettings, and generalizes earlier bounds for fully-planar instances. In the\ncongestion model, given an uncrossed fractional multiflow, we give a rounding\nprocedure that produces an integral multiflow with edge congestion 2, which can\nbe made unsplittable with an additional additive error of the maximum demand.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e00\u822c\u5e73\u9762\u56fe\u4e2d\u65e0\u4ea4\u53c9\u591a\u6d41\u95ee\u9898\uff0c\u5206\u6790\u62e5\u585e\u548c\u6700\u5927\u5316\u6a21\u578b\uff0c\u7ed9\u51fa\u590d\u6742\u5ea6\u3001\u4e0d\u53ef\u8fd1\u4f3c\u6027\u7ed3\u679c\u53ca\u6574\u6570\u89e3\u820d\u5165\u65b9\u6cd5\u3002", "motivation": "\u6b64\u524d\u65e0\u4ea4\u53c9\u591a\u6d41\u5728\u7279\u5b9a\u60c5\u51b5\u6709\u5e94\u7528\uff0c\u672c\u6587\u7814\u7a76\u4e00\u822c\u5e73\u9762\u56fe\u4e2d\u4f5c\u4e3a\u72ec\u7acb\u7b97\u6cd5\u95ee\u9898\u7684\u60c5\u51b5\u3002", "method": "\u5bf9\u62e5\u585e\u548c\u6700\u5927\u5316\u6a21\u578b\u5206\u522b\u8fdb\u884c\u5206\u6790\uff0c\u7814\u7a76\u95ee\u9898\u590d\u6742\u5ea6\u3001\u4e0d\u53ef\u8fd1\u4f3c\u6027\u53ca\u6574\u6570\u89e3\u820d\u5165\u3002", "result": "\u62e5\u585e\u6a21\u578b\u4e2d\u5224\u65ad\u6709\u65e0\u65e0\u4ea4\u53c9\u5206\u6570\u591a\u6d41\u662fNP - \u96be\uff0c\u9700\u6c42\u8de8\u6709\u9650\u9762\u65f6\u627e\u6574\u6570\u65e0\u4ea4\u53c9\u6d41\u53ef\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\uff1b\u6700\u5927\u5316\u6a21\u578b\u6709\u5f3a\u4e0d\u53ef\u8fd1\u4f3c\u6027\u7ed3\u679c\uff1b\u7ed9\u51fa\u6574\u6570\u89e3\u820d\u5165\u65b9\u6cd5\u3002", "conclusion": "\u5728\u4e00\u822c\u5e73\u9762\u56fe\u65e0\u4ea4\u53c9\u591a\u6d41\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u590d\u6742\u5ea6\u3001\u4e0d\u53ef\u8fd1\u4f3c\u6027\u548c\u820d\u5165\u65b9\u6cd5\u7b49\u6210\u679c\uff0c\u63a8\u5e7f\u4e86\u5168\u5e73\u9762\u56fe\u7684\u76f8\u5173\u754c\u9650\u3002"}}
{"id": "2511.00048", "pdf": "https://arxiv.org/pdf/2511.00048", "abs": "https://arxiv.org/abs/2511.00048", "authors": ["Martin Bicher", "Maximilian Viehauser", "Daniele Giannandrea", "Hannah Kastinger", "Dominik Brunmeir", "Claire Rippinger", "Christoph Urach", "Niki Popper"], "title": "GEPOC Parameters - Open Source Parametrisation and Validation for Austria, Version 2.0", "categories": ["cs.AI", "cs.CY", "62-11", "E.5; G.3; I.6.4; I.6.6; J.3; J.4"], "comment": "134 pages, 75 figures, 19 tables", "summary": "GEPOC, short for Generic Population Concept, is a collection of models and\nmethods for analysing population-level research questions. For the valid\napplication of the models for a specific country or region, stable and\nreproducible data processes are necessary, which provide valid and ready-to-use\nmodel parameters. This work contains a complete description of the\ndata-processing methods for computation of model parameters for Austria, based\nexclusively on freely and publicly accessible data. In addition to the\ndescription of the source data used, this includes all algorithms used for\naggregation, disaggregation, fusion, cleansing or scaling of the data, as well\nas a description of the resulting parameter files. The document places\nparticular emphasis on the computation of parameters for the most important\nGEPOC model, GEPOC ABM, a continuous-time agent-based population model. An\nextensive validation study using this particular model was made and is\npresented at the end of this work.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u57fa\u4e8e\u516c\u5f00\u6570\u636e\u4e3a\u5965\u5730\u5229\u8ba1\u7b97GEPOC\u6a21\u578b\u53c2\u6570\u7684\u6570\u636e\u5904\u7406\u65b9\u6cd5\uff0c\u5e76\u5bf9GEPOC ABM\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\u7814\u7a76\u3002", "motivation": "\u4e3a\u7279\u5b9a\u56fd\u5bb6\u6216\u5730\u533a\u6709\u6548\u5e94\u7528GEPOC\u6a21\u578b\uff0c\u9700\u8981\u7a33\u5b9a\u4e14\u53ef\u91cd\u590d\u7684\u6570\u636e\u5904\u7406\u8fc7\u7a0b\u4ee5\u63d0\u4f9b\u6709\u6548\u53ef\u7528\u7684\u6a21\u578b\u53c2\u6570\u3002", "method": "\u57fa\u4e8e\u516c\u5f00\u6570\u636e\uff0c\u63cf\u8ff0\u6570\u636e\u5904\u7406\u65b9\u6cd5\uff0c\u5305\u62ec\u805a\u5408\u3001\u5206\u89e3\u3001\u878d\u5408\u3001\u6e05\u7406\u548c\u7f29\u653e\u7b49\u7b97\u6cd5\uff0c\u7740\u91cd\u8ba1\u7b97GEPOC ABM\u6a21\u578b\u53c2\u6570\u3002", "result": "\u5b8c\u6210\u5965\u5730\u5229\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\uff0c\u6709\u76f8\u5e94\u53c2\u6570\u6587\u4ef6\u3002", "conclusion": "\u5bf9GEPOC ABM\u6a21\u578b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u9a8c\u8bc1\u7814\u7a76\u3002"}}
{"id": "2511.00018", "pdf": "https://arxiv.org/pdf/2511.00018", "abs": "https://arxiv.org/abs/2511.00018", "authors": ["Munawar Ali", "Qi Feng"], "title": "Branched Signature Model", "categories": ["math.NA", "cs.NA", "math.PR", "q-fin.CP", "62P05, 60G17, 65C20, 65C30, 60H10, 91B70"], "comment": "28 pages, 7 figures", "summary": "In this paper, we introduce the branched signature model, motivated by the\nbranched rough path framework of [Gubinelli, Journal of Differential Equations,\n248(4), 2010], which generalizes the classical geometric rough path. We\nestablish a universal approximation theorem for the branched signature model\nand demonstrate that iterative compositions of lower-level signature maps can\napproximate higher-level signatures. Furthermore, building on the existence of\nthe extension map proposed in [Hairer-Kelly. Annales de l'Institue Henri\nPoincar\\'e, Probabilit\\'es et Statistiques 51, no. 1 (2015)], we show how to\nexplicitly construct the extension of the original paths into\nhigher-dimensional spaces via a map $\\Psi$, so that the branched signature can\nbe realized as the classical geometric signature of the extended path. This\nframework not only provides an efficient computational scheme for branched\nsignatures but also opens new avenues for data-driven modeling and\napplications.", "AI": {"tldr": "\u5f15\u5165\u5206\u652f\u7b7e\u540d\u6a21\u578b\uff0c\u8bc1\u660e\u901a\u7528\u903c\u8fd1\u5b9a\u7406\uff0c\u5c55\u793a\u8def\u5f84\u6269\u5c55\u6784\u9020\u65b9\u6cd5\uff0c\u4e3a\u8ba1\u7b97\u548c\u5e94\u7528\u63d0\u4f9b\u6846\u67b6\u3002", "motivation": "\u53d7\u5206\u652f\u7c97\u7cd9\u8def\u5f84\u6846\u67b6\u542f\u53d1\uff0c\u63a8\u5e7f\u7ecf\u5178\u51e0\u4f55\u7c97\u7cd9\u8def\u5f84\u3002", "method": "\u5efa\u7acb\u901a\u7528\u903c\u8fd1\u5b9a\u7406\uff0c\u5229\u7528\u5df2\u6709\u6269\u5c55\u6620\u5c04\u6784\u9020\u8def\u5f84\u6269\u5c55\u3002", "result": "\u8bc1\u660e\u8fed\u4ee3\u7ec4\u5408\u53ef\u903c\u8fd1\u9ad8\u5c42\u7b7e\u540d\uff0c\u7ed9\u51fa\u8def\u5f84\u6269\u5c55\u6784\u9020\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5206\u652f\u7b7e\u540d\u8ba1\u7b97\u63d0\u4f9b\u9ad8\u6548\u65b9\u6848\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u548c\u5e94\u7528\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.00125", "pdf": "https://arxiv.org/pdf/2511.00125", "abs": "https://arxiv.org/abs/2511.00125", "authors": ["\u00c1lvaro Silva", "Alexandra Mendes", "Ruben Martins"], "title": "Inferring multiple helper Dafny assertions with LLMs", "categories": ["cs.SE", "cs.AI", "cs.LO", "cs.PL"], "comment": null, "summary": "The Dafny verifier provides strong correctness guarantees but often requires\nnumerous manual helper assertions, creating a significant barrier to adoption.\nWe investigate the use of Large Language Models (LLMs) to automatically infer\nmissing helper assertions in Dafny programs, with a primary focus on cases\ninvolving multiple missing assertions. To support this study, we extend the\nDafnyBench benchmark with curated datasets where one, two, or all assertions\nare removed, and we introduce a taxonomy of assertion types to analyze\ninference difficulty. Our approach refines fault localization through a hybrid\nmethod that combines LLM predictions with error-message heuristics. We\nimplement this approach in a new tool called DAISY (Dafny Assertion Inference\nSYstem). While our focus is on multiple missing assertions, we also evaluate\nDAISY on single-assertion cases. DAISY verifies 63.4% of programs with one\nmissing assertion and 31.7% with multiple missing assertions. Notably, many\nprograms can be verified with fewer assertions than originally present,\nhighlighting that proofs often admit multiple valid repair strategies and that\nrecovering every original assertion is unnecessary. These results demonstrate\nthat automated assertion inference can substantially reduce proof engineering\neffort and represent a step toward more scalable and accessible formal\nverification.", "AI": {"tldr": "\u7814\u7a76\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u63a8\u65adDafny\u7a0b\u5e8f\u4e2d\u7f3a\u5931\u7684\u8f85\u52a9\u65ad\u8a00\uff0c\u5b9e\u73b0DAISY\u5de5\u5177\uff0c\u9a8c\u8bc1\u90e8\u5206\u7a0b\u5e8f\uff0c\u8868\u660e\u81ea\u52a8\u65ad\u8a00\u63a8\u65ad\u53ef\u51cf\u5c11\u8bc1\u660e\u5de5\u7a0b\u5de5\u4f5c\u91cf\u3002", "motivation": "Dafny\u9a8c\u8bc1\u5668\u9700\u5927\u91cf\u624b\u52a8\u8f85\u52a9\u65ad\u8a00\uff0c\u963b\u788d\u5176\u5e94\u7528\uff0c\u56e0\u6b64\u7814\u7a76\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u63a8\u65ad\u7f3a\u5931\u65ad\u8a00\u3002", "method": "\u6269\u5c55DafnyBench\u57fa\u51c6\uff0c\u5f15\u5165\u65ad\u8a00\u7c7b\u578b\u5206\u7c7b\uff0c\u7528\u7ed3\u5408LLM\u9884\u6d4b\u548c\u9519\u8bef\u6d88\u606f\u542f\u53d1\u5f0f\u7684\u6df7\u5408\u65b9\u6cd5\u6539\u8fdb\u6545\u969c\u5b9a\u4f4d\uff0c\u5b9e\u73b0DAISY\u5de5\u5177\u3002", "result": "DAISY\u9a8c\u8bc1\u4e8663.4%\u6709\u4e00\u4e2a\u7f3a\u5931\u65ad\u8a00\u7684\u7a0b\u5e8f\u548c31.7%\u6709\u591a\u4e2a\u7f3a\u5931\u65ad\u8a00\u7684\u7a0b\u5e8f\uff0c\u5f88\u591a\u7a0b\u5e8f\u53ef\u7528\u66f4\u5c11\u65ad\u8a00\u9a8c\u8bc1\u3002", "conclusion": "\u81ea\u52a8\u65ad\u8a00\u63a8\u65ad\u80fd\u5927\u5e45\u51cf\u5c11\u8bc1\u660e\u5de5\u7a0b\u5de5\u4f5c\u91cf\uff0c\u662f\u8fc8\u5411\u66f4\u53ef\u6269\u5c55\u548c\u6613\u8bbf\u95ee\u5f62\u5f0f\u9a8c\u8bc1\u7684\u4e00\u6b65\u3002"}}
{"id": "2511.00030", "pdf": "https://arxiv.org/pdf/2511.00030", "abs": "https://arxiv.org/abs/2511.00030", "authors": ["Myeongseob Ko", "Hoang Anh Just", "Charles Fleming", "Ming Jin", "Ruoxi Jia"], "title": "Probing Knowledge Holes in Unlearned LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "The Thirty-ninth Annual Conference on Neural Information Processing\n  Systems", "summary": "Machine unlearning has emerged as a prevalent technical solution for\nselectively removing unwanted knowledge absorbed during pre-training, without\nrequiring full retraining. While recent unlearning techniques can effectively\nremove undesirable content without severely compromising performance on\nstandard benchmarks, we find that they may inadvertently create ``knowledge\nholes'' -- unintended losses of benign knowledge that standard benchmarks fail\nto capture. To probe where unlearned models reveal knowledge holes, we propose\na test case generation framework that explores both immediate neighbors of\nunlearned content and broader areas of potential failures. Our evaluation\ndemonstrates significant hidden costs of unlearning: up to 98.7\\% of the test\ncases yield irrelevant or nonsensical responses from unlearned models, despite\nbeing answerable by the pretrained model. These findings necessitate rethinking\nthe conventional approach to evaluating knowledge preservation in unlearning,\nmoving beyond standard, static benchmarks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u6280\u672f\u53ef\u80fd\u4ea7\u751f\u77e5\u8bc6\u7a7a\u6d1e\uff0c\u63d0\u51fa\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u6846\u67b6\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u9057\u5fd8\u6a21\u578b\u5b58\u5728\u663e\u8457\u9690\u85cf\u6210\u672c\uff0c\u9700\u91cd\u65b0\u601d\u8003\u8bc4\u4f30\u65b9\u5f0f\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u6280\u672f\u53ef\u80fd\u4f1a\u4ea7\u751f\u6807\u51c6\u57fa\u51c6\u672a\u6355\u6349\u5230\u7684\u201c\u77e5\u8bc6\u7a7a\u6d1e\u201d\uff0c\u9700\u8981\u63a2\u7a76\u9057\u5fd8\u6a21\u578b\u4e2d\u77e5\u8bc6\u7a7a\u6d1e\u7684\u4f4d\u7f6e\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u6846\u67b6\uff0c\u63a2\u7d22\u88ab\u9057\u5fd8\u5185\u5bb9\u7684\u7d27\u90bb\u533a\u57df\u548c\u6f5c\u5728\u6545\u969c\u7684\u66f4\u5e7f\u6cdb\u533a\u57df\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u9ad8\u8fbe98.7%\u7684\u6d4b\u8bd5\u7528\u4f8b\u4e2d\uff0c\u88ab\u9057\u5fd8\u6a21\u578b\u7ed9\u51fa\u65e0\u5173\u6216\u65e0\u610f\u4e49\u7684\u54cd\u5e94\uff0c\u800c\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u56de\u7b54\u3002", "conclusion": "\u6709\u5fc5\u8981\u91cd\u65b0\u601d\u8003\u4f20\u7edf\u7684\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u4e2d\u77e5\u8bc6\u4fdd\u7559\u7684\u65b9\u6cd5\uff0c\u8d85\u8d8a\u6807\u51c6\u9759\u6001\u57fa\u51c6\u3002"}}
{"id": "2511.00390", "pdf": "https://arxiv.org/pdf/2511.00390", "abs": "https://arxiv.org/abs/2511.00390", "authors": ["Wanyun Zhou", "Saizhuo Wang", "Mihai Cucuringu", "Zihao Zhang", "Xiang Li", "Jian Guo", "Chao Zhang", "Xiaowen Chu"], "title": "DeltaLag: Learning Dynamic Lead-Lag Patterns in Financial Markets", "categories": ["cs.CE"], "comment": null, "summary": "The lead-lag effect, where the price movement of one asset systematically\nprecedes that of another, has been widely observed in financial markets and\nconveys valuable predictive signals for trading. However, traditional lead-lag\ndetection methods are limited by their reliance on statistical analysis methods\nand by the assumption of persistent lead-lag patterns, which are often invalid\nin dynamic market conditions. In this paper, we propose \\textbf{DeltaLag}, the\nfirst end-to-end deep learning method that discovers and exploits dynamic\nlead-lag structures with pair-specific lag values in financial markets for\nportfolio construction. Specifically, DeltaLag employs a sparsified\ncross-attention mechanism to identify relevant lead-lag pairs. These lead-lag\nsignals are then leveraged to extract lag-aligned raw features from the leading\nstocks for predicting the lagger stock's future return. Empirical evaluations\nshow that DeltaLag substantially outperforms both fixed-lag and self-lead-lag\nbaselines. In addition, its adaptive mechanism for identifying lead-lag\nrelationships consistently surpasses precomputed lead-lag graphs based on\nstatistical methods. Furthermore, DeltaLag outperforms a wide range of temporal\nand spatio-temporal deep learning models designed for stock prediction or time\nseries forecasting, offering both better trading performance and enhanced\ninterpretability.", "AI": {"tldr": "\u63d0\u51fa\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5DeltaLag\u7528\u4e8e\u53d1\u73b0\u548c\u5229\u7528\u91d1\u878d\u5e02\u573a\u52a8\u6001\u9886\u5148 - \u6ede\u540e\u7ed3\u6784\u8fdb\u884c\u6295\u8d44\u7ec4\u5408\u6784\u5efa\uff0c\u8868\u73b0\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u548c\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u9886\u5148 - \u6ede\u540e\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u7edf\u8ba1\u5206\u6790\u4e14\u5047\u8bbe\u9886\u5148 - \u6ede\u540e\u6a21\u5f0f\u6301\u4e45\uff0c\u5728\u52a8\u6001\u5e02\u573a\u6761\u4ef6\u4e0b\u5e38\u65e0\u6548\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDeltaLag\uff0c\u91c7\u7528\u7a00\u758f\u5316\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u8bc6\u522b\u76f8\u5173\u9886\u5148 - \u6ede\u540e\u5bf9\uff0c\u5229\u7528\u9886\u5148\u80a1\u7968\u7279\u5f81\u9884\u6d4b\u6ede\u540e\u80a1\u7968\u672a\u6765\u56de\u62a5\u3002", "result": "DeltaLag\u5927\u5e45\u8d85\u8d8a\u56fa\u5b9a\u6ede\u540e\u548c\u81ea\u9886\u5148 - \u6ede\u540e\u57fa\u7ebf\uff0c\u81ea\u9002\u5e94\u673a\u5236\u4f18\u4e8e\u57fa\u4e8e\u7edf\u8ba1\u65b9\u6cd5\u7684\u9884\u8ba1\u7b97\u9886\u5148 - \u6ede\u540e\u56fe\uff0c\u4e5f\u4f18\u4e8e\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "DeltaLag\u5728\u4ea4\u6613\u8868\u73b0\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u90fd\u66f4\u4f18\uff0c\u80fd\u6709\u6548\u7528\u4e8e\u91d1\u878d\u5e02\u573a\u6295\u8d44\u7ec4\u5408\u6784\u5efa\u3002"}}
{"id": "2511.01001", "pdf": "https://arxiv.org/pdf/2511.01001", "abs": "https://arxiv.org/abs/2511.01001", "authors": ["Johansell Villalobos", "Daniel Caviedes-Voulli\u00e8me", "Silvio Rizzi", "Esteban Meneses"], "title": "Towards Portability at Scale: A Cross-Architecture Performance Evaluation of a GPU-enabled Shallow Water Solver", "categories": ["cs.DC", "cs.PF"], "comment": "Conference: SBAC-PAD 2025", "summary": "Current climate change has posed a grand challenge in the field of numerical\nmodeling due to its complex, multiscale dynamics. In hydrological modeling, the\nincreasing demand for high-resolution, real-time simulations has led to the\nadoption of GPU-accelerated platforms and performance portable programming\nframeworks such as Kokkos. In this work, we present a comprehensive performance\nstudy of the SERGHEI-SWE solver, a shallow water equations code, across four\nstate-of-the-art heterogeneous HPC systems: Frontier (AMD MI250X), JUWELS\nBooster (NVIDIA A100), JEDI (NVIDIA H100), and Aurora (Intel Max 1550). We\nassess strong scaling up to 1024 GPUs and weak scaling upwards of 2048 GPUs,\ndemonstrating consistent scalability with a speedup of 32 and an efficiency\nupwards of 90\\% for most almost all the test range. Roofline analysis reveals\nthat memory bandwidth is the dominant performance bottleneck, with key solver\nkernels residing in the memory-bound region. To evaluate performance\nportability, we apply both harmonic and arithmetic mean-based metrics while\nvarying problem size. Results indicate that while SERGHEI-SWE achieves\nportability across devices with tuned problem sizes (<70\\%), there is room for\nkernel optimization within the solver with more granular control of the\narchitecture specifically by using Kokkos teams and architecture specific\ntunable parameters. These findings position SERGHEI-SWE as a robust, scalable,\nand portable simulation tool for large-scale geophysical applications under\nevolving HPC architectures with potential to enhance its performance.", "AI": {"tldr": "\u5bf9SERGHEI - SWE\u6c42\u89e3\u5668\u5728\u56db\u4e2a\u5f02\u6784HPC\u7cfb\u7edf\u4e0a\u8fdb\u884c\u6027\u80fd\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u6307\u51fa\u5185\u5b58\u5e26\u5bbd\u662f\u74f6\u9888\uff0c\u6709\u6027\u80fd\u4f18\u5316\u7a7a\u95f4\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u4f7f\u6570\u503c\u5efa\u6a21\u9762\u4e34\u6311\u6218\uff0c\u6c34\u6587\u5efa\u6a21\u5bf9\u9ad8\u5206\u8fa8\u7387\u5b9e\u65f6\u6a21\u62df\u9700\u6c42\u589e\u52a0\uff0c\u9700\u7814\u7a76\u6c42\u89e3\u5668\u6027\u80fd\u3002", "method": "\u5728\u56db\u4e2a\u5148\u8fdb\u5f02\u6784HPC\u7cfb\u7edf\u4e0a\u5bf9SERGHEI - SWE\u6c42\u89e3\u5668\u8fdb\u884c\u6027\u80fd\u7814\u7a76\uff0c\u8bc4\u4f30\u5f3a\u6269\u5c55\u548c\u5f31\u6269\u5c55\uff0c\u8fdb\u884cRoofline\u5206\u6790\uff0c\u7528\u8c03\u548c\u4e0e\u7b97\u672f\u5e73\u5747\u6307\u6807\u8bc4\u4f30\u6027\u80fd\u53ef\u79fb\u690d\u6027\u3002", "result": "\u6c42\u89e3\u5668\u5177\u6709\u4e00\u81f4\u53ef\u6269\u5c55\u6027\uff0c\u901f\u5ea6\u63d0\u534732\u500d\uff0c\u591a\u6570\u6d4b\u8bd5\u8303\u56f4\u6548\u7387\u8d8590%\uff1b\u5185\u5b58\u5e26\u5bbd\u662f\u6027\u80fd\u74f6\u9888\uff1b\u5728\u8c03\u6574\u95ee\u9898\u5927\u5c0f\u540e\u6c42\u89e3\u5668\u53ef\u5728\u8bbe\u5907\u95f4\u5b9e\u73b0\u53ef\u79fb\u690d\u6027\u3002", "conclusion": "SERGHEI - SWE\u662f\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u5730\u7403\u7269\u7406\u5e94\u7528\u7684\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u548c\u53ef\u79fb\u690d\u7684\u6a21\u62df\u5de5\u5177\uff0c\u6709\u63d0\u5347\u6027\u80fd\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00732", "pdf": "https://arxiv.org/pdf/2511.00732", "abs": "https://arxiv.org/abs/2511.00732", "authors": ["Zainab Aizaz", "James C. Knight", "Thomas Nowotny"], "title": "FeNN-DMA: A RISC-V SoC for SNN acceleration", "categories": ["cs.NE", "cs.AI", "cs.AR"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are a promising, energy-efficient alternative\nto standard Artificial Neural Networks (ANNs) and are particularly well-suited\nto spatio-temporal tasks such as keyword spotting and video classification.\nHowever, SNNs have a much lower arithmetic intensity than ANNs and are\ntherefore not well-matched to standard accelerators like GPUs and TPUs. Field\nProgrammable Gate Arrays(FPGAs) are designed for such memory-bound workloads\nand here we develop a novel, fully-programmable RISC-V-based system-on-chip\n(FeNN-DMA), tailored to simulating SNNs on modern UltraScale+ FPGAs. We show\nthat FeNN-DMA has comparable resource usage and energy requirements to\nstate-of-the-art fixed-function SNN accelerators, yet it is capable of\nsimulating much larger and more complex models. Using this functionality, we\ndemonstrate state-of-the-art classification accuracy on the Spiking Heidelberg\nDigits and Neuromorphic MNIST tasks.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8eRISC - V\u7684\u82af\u7247\u7cfb\u7edfFeNN - DMA\u5728FPGA\u4e0a\u6a21\u62dfSNNs\uff0c\u8d44\u6e90\u4f7f\u7528\u548c\u80fd\u8017\u4e0e\u56fa\u5b9a\u529f\u80fd\u52a0\u901f\u5668\u76f8\u5f53\uff0c\u80fd\u6a21\u62df\u66f4\u590d\u6742\u6a21\u578b\u5e76\u5728\u76f8\u5173\u4efb\u52a1\u8fbe\u6700\u4f18\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "SNNs\u7b97\u672f\u5f3a\u5ea6\u4f4e\uff0c\u4e0d\u9002\u5408GPU\u548cTPU\u7b49\u6807\u51c6\u52a0\u901f\u5668\uff0c\u800cFPGA\u9002\u5408\u5185\u5b58\u53d7\u9650\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u9700\u5f00\u53d1\u9002\u5408\u5728FPGA\u4e0a\u6a21\u62dfSNNs\u7684\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eRISC - V\u7684\u5168\u53ef\u7f16\u7a0b\u7247\u4e0a\u7cfb\u7edfFeNN - DMA\uff0c\u7528\u4e8e\u5728\u73b0\u4ee3UltraScale+ FPGAs\u4e0a\u6a21\u62dfSNNs\u3002", "result": "FeNN - DMA\u8d44\u6e90\u4f7f\u7528\u548c\u80fd\u8017\u4e0e\u73b0\u6709\u56fa\u5b9a\u529f\u80fdSNN\u52a0\u901f\u5668\u76f8\u5f53\uff0c\u80fd\u6a21\u62df\u66f4\u5927\u66f4\u590d\u6742\u6a21\u578b\uff0c\u5e76\u5728Spiking Heidelberg Digits\u548cNeuromorphic MNIST\u4efb\u52a1\u4e0a\u53d6\u5f97\u6700\u4f18\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "FeNN - DMA\u662f\u5728FPGA\u4e0a\u6a21\u62dfSNNs\u7684\u6709\u6548\u65b9\u6848\uff0c\u6709\u826f\u597d\u6027\u80fd\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.00693", "pdf": "https://arxiv.org/pdf/2511.00693", "abs": "https://arxiv.org/abs/2511.00693", "authors": ["Saba Latif", "Huma Latif", "Muhammad Rameez Ur Rahman"], "title": "Object-Centric Analysis of XES Event Logs: Integrating OCED Modeling with SPARQL Queries", "categories": ["cs.DB", "cs.IR"], "comment": "12 pages, 4 figures, PROFES2025 conference", "summary": "Object Centric Event Data (OCED) has gained attention in recent years within\nthe field of process mining. However, there are still many challenges, such as\nconnecting the XES format to object-centric approaches to enable more\ninsightful analysis. It is important for a process miner to understand the\ninsights and dependencies of events in the event log to see what is going on in\nour processes. In previous standards, the dependencies of event logs are only\nused to show events, but not their dependencies among each other and actions in\ndetail as described in OCEDO. There is more information in the event log when\nit is revealed using the OCEDO model. It becomes more understandable and easier\nto grasp the concepts and deal with the processes. This paper proposes the use\nof Object-Centric Event Data Ontology (OCEDO) to overcome the limitations of\nthe XES standard in event logs for process mining. We demonstrate how the OCEDO\napproach, integrated with SPARQL queries, can be applied to the BPIC 2013\ndataset to make the relationships between events and objects more explicit. It\ndescribes dealing with the meta descriptions of the OCEDO model on a business\nprocess challenge as an event log. It improves the completeness and readability\nof process data, suggesting that object-centric modeling allows for richer\nanalyses than traditional approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528OCEDO\u514b\u670dXES\u6807\u51c6\u5728\u8fc7\u7a0b\u6316\u6398\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u7684\u5c40\u9650\uff0c\u7ed3\u5408SPARQL\u67e5\u8be2\u5e94\u7528\u4e8e\u6570\u636e\u96c6\uff0c\u63d0\u5347\u6570\u636e\u5b8c\u6574\u6027\u548c\u53ef\u8bfb\u6027\u3002", "motivation": "\u73b0\u6709OCED\u5b58\u5728\u8fde\u63a5XES\u683c\u5f0f\u4e0e\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u65b9\u6cd5\u7684\u6311\u6218\uff0c\u4ee5\u5f80\u6807\u51c6\u65e0\u6cd5\u8be6\u7ec6\u5c55\u793a\u4e8b\u4ef6\u4f9d\u8d56\u5173\u7cfb\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u8fdb\u884c\u8fc7\u7a0b\u6316\u6398\u3002", "method": "\u63d0\u51fa\u4f7f\u7528Object - Centric Event Data Ontology (OCEDO)\uff0c\u5e76\u5c06\u5176\u4e0eSPARQL\u67e5\u8be2\u96c6\u6210\u5e94\u7528\u4e8eBPIC 2013\u6570\u636e\u96c6\u3002", "result": "\u4f7f\u4e8b\u4ef6\u548c\u5bf9\u8c61\u4e4b\u95f4\u7684\u5173\u7cfb\u66f4\u660e\u786e\uff0c\u6539\u5584\u4e86\u8fc7\u7a0b\u6570\u636e\u7684\u5b8c\u6574\u6027\u548c\u53ef\u8bfb\u6027\u3002", "conclusion": "\u4ee5\u5bf9\u8c61\u4e3a\u4e2d\u5fc3\u7684\u5efa\u6a21\u6bd4\u4f20\u7edf\u65b9\u6cd5\u80fd\u8fdb\u884c\u66f4\u4e30\u5bcc\u7684\u5206\u6790\u3002"}}
{"id": "2511.00986", "pdf": "https://arxiv.org/pdf/2511.00986", "abs": "https://arxiv.org/abs/2511.00986", "authors": ["Kamesh Munagala", "Qilin Ye", "Ian Zhang"], "title": "Deliberation via Matching", "categories": ["cs.GT"], "comment": null, "summary": "We study deliberative social choice, where voters refine their preferences\nthrough small-group discussions before collective aggregation. We introduce a\nsimple and easily implementable deliberation-via-matching protocol: for each\npair of candidates, we form an arbitrary maximum matching among voters who\ndisagree on that pair, and each matched pair deliberates. The resulting\npreferences (individual and deliberative) are then appropriately weighted and\naggregated using the weighted uncovered set tournament rule.\n  We show that our protocol has a tight distortion bound of $3$ within the\nmetric distortion framework. This breaks the previous lower bound of $3.11$ for\ntournament rules without deliberation and matches the lower bound for\ndeterministic social choice rules without deliberation. Our result conceptually\nshows that tournament rules are just as powerful as general social choice\nrules, when the former are given the minimal added power of pairwise\ndeliberations. We prove our bounds via a novel bilinear relaxation of the\nnon-linear program capturing optimal distortion, whose vertices we can\nexplicitly enumerate, leading to an analytic proof. Loosely speaking, our key\ntechnical insight is that the distortion objective, as a function of metric\ndistances to any three alternatives, is both supermodular and convex. We\nbelieve this characterization provides a general analytical framework for\nstudying the distortion of other deliberative protocols, and may be of\nindependent interest.", "AI": {"tldr": "\u7814\u7a76\u5ba1\u8bae\u5f0f\u793e\u4f1a\u9009\u62e9\uff0c\u63d0\u51fa\u5339\u914d\u5ba1\u8bae\u534f\u8bae\uff0c\u8bc1\u660e\u534f\u8bae\u67093\u7684\u5931\u771f\u754c\u9650\uff0c\u4e3a\u7814\u7a76\u5176\u4ed6\u5ba1\u8bae\u534f\u8bae\u63d0\u4f9b\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u9009\u6c11\u901a\u8fc7\u5c0f\u7ec4\u8ba8\u8bba\u5b8c\u5584\u504f\u597d\u540e\u7684\u96c6\u4f53\u805a\u5408\u95ee\u9898\uff0c\u6539\u8fdb\u65e0\u5ba1\u8bae\u9526\u6807\u8d5b\u89c4\u5219\u7684\u5931\u771f\u754c\u9650\u3002", "method": "\u5f15\u5165\u5339\u914d\u5ba1\u8bae\u534f\u8bae\uff0c\u5bf9\u5019\u9009\u4eba\u5bf9\u5f62\u6210\u6700\u5927\u5339\u914d\u8ba9\u9009\u6c11\u5ba1\u8bae\uff0c\u7528\u52a0\u6743\u672a\u8986\u76d6\u96c6\u9526\u6807\u8d5b\u89c4\u5219\u805a\u5408\u504f\u597d\uff1b\u901a\u8fc7\u975e\u7ebf\u6027\u89c4\u5212\u7684\u53cc\u7ebf\u6027\u677e\u5f1b\u8bc1\u660e\u754c\u9650\u3002", "result": "\u534f\u8bae\u67093\u7684\u7d27\u5bc6\u5931\u771f\u754c\u9650\uff0c\u6253\u7834\u65e0\u5ba1\u8bae\u9526\u6807\u8d5b\u89c4\u52193.11\u7684\u4e0b\u9650\uff0c\u5339\u914d\u65e0\u5ba1\u8bae\u786e\u5b9a\u6027\u793e\u4f1a\u9009\u62e9\u89c4\u5219\u7684\u4e0b\u9650\u3002", "conclusion": "\u9526\u6807\u8d5b\u89c4\u5219\u5728\u6709\u4e24\u4e24\u5ba1\u8bae\u7684\u6700\u5c0f\u9644\u52a0\u80fd\u529b\u65f6\u4e0e\u4e00\u822c\u793e\u4f1a\u9009\u62e9\u89c4\u5219\u4e00\u6837\u5f3a\u5927\uff0c\u76f8\u5173\u523b\u753b\u4e3a\u7814\u7a76\u5176\u4ed6\u5ba1\u8bae\u534f\u8bae\u5931\u771f\u63d0\u4f9b\u901a\u7528\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2511.00764", "pdf": "https://arxiv.org/pdf/2511.00764", "abs": "https://arxiv.org/abs/2511.00764", "authors": ["Keyi Zeng", "Zhenfeng Zou", "Yuting Su", "Taizhong Hu"], "title": "Further Developments on Stochastic Dominance for Different Classes of Infinite-mean Distributions", "categories": ["math.PR", "q-fin.RM"], "comment": null, "summary": "In recent years, stochastic dominance for independent and identically\ndistributed (iid) infinite-mean random variables has received considerable\nattention. The literature has identified several classes of distributions of\nnonnegative random variables that encompass many common heavy-tailed\ndistributions. A key result demonstrates that the weighted sum of iid random\nvariables from these classes is stochastically larger than any individual\nrandom variable in the sense of the first-order stochastic dominance. This\npaper systematically investigates the properties and inclusion relationships\namong these distribution classes, and extends some existing results to more\npractical scenarios. Furthermore, we analyze the case where each random\nvariable follows a compound binomial distribution, establishing necessary and\nsufficient conditions for the preservation of the aforementioned stochastic\ndominance relation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u72ec\u7acb\u540c\u5206\u5e03\u65e0\u9650\u5747\u503c\u968f\u673a\u53d8\u91cf\u968f\u673a\u5360\u4f18\u76f8\u5173\u5206\u5e03\u7c7b\u6027\u8d28\u3001\u5305\u542b\u5173\u7cfb\uff0c\u6269\u5c55\u5df2\u6709\u7ed3\u679c\uff0c\u5e76\u5206\u6790\u590d\u5408\u4e8c\u9879\u5206\u5e03\u60c5\u5f62\u4e0b\u968f\u673a\u5360\u4f18\u5173\u7cfb\u7684\u5145\u8981\u6761\u4ef6\u3002", "motivation": "\u8fd1\u5e74\u6765\u72ec\u7acb\u540c\u5206\u5e03\u65e0\u9650\u5747\u503c\u968f\u673a\u53d8\u91cf\u7684\u968f\u673a\u5360\u4f18\u53d7\u5173\u6ce8\uff0c\u5df2\u6709\u6587\u732e\u786e\u5b9a\u4e86\u4e00\u4e9b\u5305\u542b\u5e38\u89c1\u91cd\u5c3e\u5206\u5e03\u7684\u975e\u8d1f\u968f\u673a\u53d8\u91cf\u5206\u5e03\u7c7b\uff0c\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u7814\u7a76\u8fd9\u4e9b\u5206\u5e03\u7c7b\u6027\u8d28\u548c\u5173\u7cfb\u5e76\u6269\u5c55\u7ed3\u679c\u5230\u66f4\u5b9e\u9645\u573a\u666f\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u5206\u5e03\u7c7b\u6027\u8d28\u548c\u5305\u542b\u5173\u7cfb\uff0c\u5206\u6790\u968f\u673a\u53d8\u91cf\u670d\u4ece\u590d\u5408\u4e8c\u9879\u5206\u5e03\u7684\u60c5\u51b5\u3002", "result": "\u786e\u5b9a\u4e86\u5206\u5e03\u7c7b\u7684\u6027\u8d28\u548c\u5305\u542b\u5173\u7cfb\uff0c\u6269\u5c55\u4e86\u5df2\u6709\u7ed3\u679c\uff0c\u5efa\u7acb\u4e86\u590d\u5408\u4e8c\u9879\u5206\u5e03\u60c5\u5f62\u4e0b\u968f\u673a\u5360\u4f18\u5173\u7cfb\u7684\u5145\u8981\u6761\u4ef6\u3002", "conclusion": "\u5bf9\u72ec\u7acb\u540c\u5206\u5e03\u65e0\u9650\u5747\u503c\u968f\u673a\u53d8\u91cf\u968f\u673a\u5360\u4f18\u76f8\u5173\u5206\u5e03\u7c7b\u6709\u66f4\u6df1\u5165\u7406\u89e3\uff0c\u6269\u5c55\u7ed3\u679c\u9002\u7528\u4e8e\u66f4\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2511.00490", "pdf": "https://arxiv.org/pdf/2511.00490", "abs": "https://arxiv.org/abs/2511.00490", "authors": ["Gero Junike", "Marco Oesting"], "title": "Accuracy estimation of neural networks by extreme value theory", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "Neural networks are able to approximate any continuous function on a compact\nset. However, it is not obvious how to quantify the error of the neural\nnetwork, i.e., the remaining bias between the function and the neural network.\nHere, we propose the application of extreme value theory to quantify large\nvalues of the error, which are typically relevant in applications. The\ndistribution of the error beyond some threshold is approximately generalized\nPareto distributed. We provide a new estimator of the shape parameter of the\nPareto distribution suitable to describe the error of neural networks.\nNumerical experiments are provided.", "AI": {"tldr": "\u63d0\u51fa\u7528\u6781\u503c\u7406\u8bba\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u8bef\u5dee\u5927\u503c\uff0c\u7ed9\u51fa\u5e15\u7d2f\u6258\u5206\u5e03\u5f62\u72b6\u53c2\u6570\u65b0\u4f30\u8ba1\u5668\u5e76\u505a\u6570\u503c\u5b9e\u9a8c\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u867d\u80fd\u903c\u8fd1\u7d27\u81f4\u96c6\u4e0a\u8fde\u7eed\u51fd\u6570\uff0c\u4f46\u96be\u4ee5\u91cf\u5316\u5176\u8bef\u5dee\uff0c\u9700\u65b9\u6cd5\u91cf\u5316\u8bef\u5dee\u5927\u503c\u3002", "method": "\u5e94\u7528\u6781\u503c\u7406\u8bba\uff0c\u5229\u7528\u5e7f\u4e49\u5e15\u7d2f\u6258\u5206\u5e03\u8fd1\u4f3c\u9608\u503c\u5916\u8bef\u5dee\u5206\u5e03\uff0c\u7ed9\u51fa\u65b0\u7684\u5e15\u7d2f\u6258\u5206\u5e03\u5f62\u72b6\u53c2\u6570\u4f30\u8ba1\u5668\u3002", "result": "\u5f97\u5230\u53ef\u63cf\u8ff0\u795e\u7ecf\u7f51\u7edc\u8bef\u5dee\u7684\u5e15\u7d2f\u6258\u5206\u5e03\u5f62\u72b6\u53c2\u6570\u65b0\u4f30\u8ba1\u5668\uff0c\u5b8c\u6210\u6570\u503c\u5b9e\u9a8c\u3002", "conclusion": "\u53ef\u901a\u8fc7\u6781\u503c\u7406\u8bba\u548c\u65b0\u4f30\u8ba1\u5668\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u8bef\u5dee\u5927\u503c\u3002"}}
{"id": "2511.00378", "pdf": "https://arxiv.org/pdf/2511.00378", "abs": "https://arxiv.org/abs/2511.00378", "authors": ["Yongyang Cai"], "title": "Modeling Uncertainty in Integrated Assessment Models", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Integrated Assessment Models (IAMs) are pivotal tools that synthesize\nknowledge from climate science, economics, and policy to evaluate the\ninteractions between human activities and the climate system. They serve as\nessential instruments for policymakers, providing insights into the potential\noutcomes of various climate policies and strategies. Given the complexity and\ninherent uncertainties in both the climate system and socio-economic processes,\nunderstanding and effectively managing uncertainty within IAMs is crucial for\nrobust climate policy development. This review aims to provide a comprehensive\noverview of how IAMs handle uncertainty, highlighting recent methodological\nadvancements and their implications for climate policy. I examine the types of\nuncertainties present in IAMs, discuss various modeling approaches to address\nthese uncertainties, and explore recent developments in the field, including\nthe incorporation of advanced computational methods.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0IAMs\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u5f0f\uff0c\u4ecb\u7ecd\u76f8\u5173\u8fdb\u5c55\u53ca\u5bf9\u6c14\u5019\u653f\u7b56\u7684\u5f71\u54cd\u3002", "motivation": "\u6c14\u5019\u7cfb\u7edf\u548c\u793e\u4f1a\u7ecf\u6d4e\u8fc7\u7a0b\u590d\u6742\u4e14\u6709\u4e0d\u786e\u5b9a\u6027\uff0c\u6709\u6548\u7ba1\u7406IAMs\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u5236\u5b9a\u7a33\u5065\u6c14\u5019\u653f\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5ba1\u67e5IAMs\u4e2d\u5b58\u5728\u7684\u4e0d\u786e\u5b9a\u6027\u7c7b\u578b\uff0c\u8ba8\u8bba\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u786e\u5b9a\u6027\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u63a2\u7d22\u8be5\u9886\u57df\u7684\u6700\u65b0\u53d1\u5c55\u3002", "result": "\u6587\u4e2d\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u4e2d\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2511.01281", "pdf": "https://arxiv.org/pdf/2511.01281", "abs": "https://arxiv.org/abs/2511.01281", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Particle Filter Made Simple: A Step-by-Step Beginner-friendly Guide", "categories": ["stat.CO"], "comment": "26 pages", "summary": "The particle filter is a powerful framework for estimating hidden states in\ndynamic systems where uncertainty, noise, and nonlinearity dominate. This\nmini-book offers a clear and structured introduction to the core ideas behind\nparticle filters-how they represent uncertainty through random samples, update\nbeliefs using observations, and maintain robustness where linear or Gaussian\nassumptions fail. Starting from the limitations of the Kalman filter, the book\ndevelops the intuition that drives the particle filter: belief as a cloud of\nweighted hypotheses that evolve through prediction, measurement, and\nresampling. Step by step, it connects these ideas to their mathematical\nfoundations, showing how probability distributions can be approximated by a\nfinite set of particles and how Bayesian reasoning unfolds in sampled form.\nIllustrated examples, numerical walk-throughs, and Python code bring each\nconcept to life, bridging the gap between theory and implementation. By the\nend, readers will not only understand the algorithmic flow of the particle\nfilter but also develop an intuitive grasp of how randomness and structure\ntogether enable systems to infer, adapt, and make sense of noisy observations\nin real time.", "AI": {"tldr": "\u672c\u4e66\u4ecb\u7ecd\u7c92\u5b50\u6ee4\u6ce2\u5668\u6838\u5fc3\u601d\u60f3\uff0c\u901a\u8fc7\u5b9e\u4f8b\u548c\u4ee3\u7801\u5e2e\u52a9\u8bfb\u8005\u7406\u89e3\u5176\u7b97\u6cd5\u6d41\u7a0b\u548c\u539f\u7406\u3002", "motivation": "\u9274\u4e8e\u7c92\u5b50\u6ee4\u6ce2\u5668\u5728\u5904\u7406\u52a8\u6001\u7cfb\u7edf\u4e2d\u4e0d\u786e\u5b9a\u6027\u3001\u566a\u58f0\u548c\u975e\u7ebf\u6027\u95ee\u9898\u7684\u4f18\u52bf\uff0c\u63d0\u4f9b\u6e05\u6670\u7ed3\u6784\u5316\u7684\u4ecb\u7ecd\u3002", "method": "\u4ece\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5c40\u9650\u51fa\u53d1\uff0c\u9010\u6b65\u9610\u8ff0\u7c92\u5b50\u6ee4\u6ce2\u5668\u601d\u60f3\uff0c\u8fde\u63a5\u5176\u4e0e\u6570\u5b66\u57fa\u7840\uff0c\u7ed3\u5408\u5b9e\u4f8b\u3001\u6570\u503c\u6f14\u793a\u548cPython\u4ee3\u7801\u8bb2\u89e3\u3002", "result": "\u8bfb\u8005\u80fd\u7406\u89e3\u7c92\u5b50\u6ee4\u6ce2\u5668\u7b97\u6cd5\u6d41\u7a0b\uff0c\u76f4\u89c2\u638c\u63e1\u968f\u673a\u6027\u548c\u7ed3\u6784\u6027\u5982\u4f55\u4f7f\u7cfb\u7edf\u5b9e\u65f6\u63a8\u65ad\u548c\u5904\u7406\u566a\u58f0\u89c2\u6d4b\u3002", "conclusion": "\u672c\u4e66\u6709\u6548\u5e2e\u52a9\u8bfb\u8005\u7406\u89e3\u7c92\u5b50\u6ee4\u6ce2\u5668\uff0c\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\u3002"}}
{"id": "2511.00444", "pdf": "https://arxiv.org/pdf/2511.00444", "abs": "https://arxiv.org/abs/2511.00444", "authors": ["Benjamin Clavi\u00e9", "Xianming Li", "Antoine Chaffin", "Omar Khattab", "Tom Aarsen", "Manuel Faysse", "Jing Li"], "title": "LIR: The First Workshop on Late Interaction and Multi Vector Retrieval @ ECIR 2026", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted workshop at ECIR 2026", "summary": "Late interaction retrieval methods, pioneered by ColBERT, have emerged as a\npowerful alternative to single-vector neural IR. By leveraging fine-grained,\ntoken-level representations, they have been demonstrated to deliver strong\ngeneralisation and robustness, particularly in out-of-domain settings. They\nhave recently been shown to be particularly well-suited for novel use cases,\nsuch as reasoning-based or cross-modality retrieval. At the same time, these\nmodels pose significant challenges of efficiency, usability, and integrations\ninto fully fledged systems; as well as the natural difficulties encountered\nwhile researching novel application domains. Recent years have seen rapid\nadvances across many of these areas, but research efforts remain fragmented\nacross communities and frequently exclude practitioners. The purpose of this\nworkshop is to create an environment where all aspects of late interaction can\nbe discussed, with a focus on early research explorations, real-world outcomes,\nand negative or puzzling results to be freely shared and discussed. The aim of\nLIR is to provide a highly-interactive environment for researchers from various\nbackgrounds and practitioners to freely discuss their experience, fostering\nfurther collaboration.", "AI": {"tldr": "\u4ecb\u7ecd\u665a\u671f\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\u4f18\u7f3a\u70b9\uff0c\u8bf4\u660e\u4e3e\u529e\u76f8\u5173\u7814\u8ba8\u4f1a\u76ee\u7684\u662f\u63d0\u4f9b\u4ea4\u6d41\u73af\u5883\u4fc3\u8fdb\u5408\u4f5c\u3002", "motivation": "\u665a\u671f\u4ea4\u4e92\u68c0\u7d22\u65b9\u6cd5\u6709\u4f18\u52bf\u4f46\u9762\u4e34\u6548\u7387\u3001\u53ef\u7528\u6027\u7b49\u6311\u6218\uff0c\u4e14\u7814\u7a76\u5206\u6563\u3001\u5c11\u4ece\u4e1a\u8005\u53c2\u4e0e\uff0c\u9700\u4ea4\u6d41\u5e73\u53f0\u3002", "method": "\u4e3e\u529e\u7814\u8ba8\u4f1a\uff0c\u63d0\u4f9b\u9ad8\u5ea6\u4e92\u52a8\u73af\u5883\u8ba9\u4e0d\u540c\u80cc\u666f\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u4ea4\u6d41\u7ecf\u9a8c\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u4e3e\u529e\u7814\u8ba8\u4f1a\u53ef\u4fc3\u8fdb\u665a\u671f\u4ea4\u4e92\u5404\u65b9\u9762\u7684\u8ba8\u8bba\u548c\u5408\u4f5c\u3002"}}
{"id": "2511.00470", "pdf": "https://arxiv.org/pdf/2511.00470", "abs": "https://arxiv.org/abs/2511.00470", "authors": ["Ryuhei Mizutani"], "title": "An Approximation Algorithm for Monotone Submodular Cost Allocation", "categories": ["cs.DS", "cs.DM"], "comment": null, "summary": "In this paper, we consider the minimum submodular cost allocation (MSCA)\nproblem. The input of MSCA is $k$ non-negative submodular functions\n$f_1,\\ldots,f_k$ on the ground set $N$ given by evaluation oracles, and the\ngoal is to partition $N$ into $k$ (possibly empty) sets $X_1,\\ldots,X_k$ so\nthat $\\sum_{i=1}^k f_i(X_i)$ is minimized. In this paper, we focus on the case\nwhen $f_1,\\ldots,f_k$ are monotone (denoted by Mono-MSCA). We provide a natural\nLP-relaxation for Mono-MSCA, which is equivalent to the convex program\nrelaxation introduced by Chekuri and Ene. We show that the integrality gap of\nthe LP-relaxation is at most $k/2$, which yields a $k/2$-approximation\nalgorithm for Mono-MSCA. We also show that the integrality gap of the\nLP-relaxation is at least $k/2-\\epsilon$ for any constant $\\epsilon>0$ when $k$\nis fixed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5355\u8c03\u6700\u5c0f\u5b50\u6a21\u6210\u672c\u5206\u914d\u95ee\u9898\uff08Mono - MSCA\uff09\uff0c\u7ed9\u51faLP\u677e\u5f1b\uff0c\u8bc1\u660e\u5176\u6574\u6027\u95f4\u9699\u4e0a\u754c\u4e3ak/2\uff0c\u5f97\u5230k/2\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u4e14\u56fa\u5b9ak\u65f6\u6574\u6027\u95f4\u9699\u4e0b\u754c\u4e3ak/2 - \u03b5\u3002", "motivation": "\u7814\u7a76\u5355\u8c03\u6700\u5c0f\u5b50\u6a21\u6210\u672c\u5206\u914d\u95ee\u9898\uff08Mono - MSCA\uff09\u7684\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u4e3aMono - MSCA\u63d0\u4f9b\u81ea\u7136\u7684LP\u677e\u5f1b\uff0c\u4e0eChekuri\u548cEne\u5f15\u5165\u7684\u51f8\u89c4\u5212\u677e\u5f1b\u7b49\u4ef7\uff0c\u5e76\u5206\u6790\u5176\u6574\u6027\u95f4\u9699\u3002", "result": "LP\u677e\u5f1b\u7684\u6574\u6027\u95f4\u9699\u81f3\u591a\u4e3ak/2\uff0c\u5f97\u5230k/2\u8fd1\u4f3c\u7b97\u6cd5\uff1b\u56fa\u5b9ak\u65f6\uff0c\u5bf9\u4e8e\u4efb\u610f\u5e38\u6570\u03b5>0\uff0c\u6574\u6027\u95f4\u9699\u81f3\u5c11\u4e3ak/2 - \u03b5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LP\u677e\u5f1b\u65b9\u6cd5\u53ef\u7528\u4e8e\u89e3\u51b3Mono - MSCA\u95ee\u9898\uff0c\u4e14\u5177\u6709\u8f83\u597d\u7684\u8fd1\u4f3c\u6027\u80fd\u3002"}}
{"id": "2511.00092", "pdf": "https://arxiv.org/pdf/2511.00092", "abs": "https://arxiv.org/abs/2511.00092", "authors": ["Shunya Minami", "Tatsuya Ishigaki", "Ikko Hamamura", "Taku Mikuriya", "Youmi Ma", "Naoaki Okazaki", "Hiroya Takamura", "Yohichi Suzuki", "Tadashi Kadowaki"], "title": "QuantumBench: A Benchmark for Quantum Problem Solving", "categories": ["cs.AI", "cs.CL", "cs.LG", "quant-ph"], "comment": "11 pages, 8 figures", "summary": "Large language models are now integrated into many scientific workflows,\naccelerating data analysis, hypothesis generation, and design space\nexploration. In parallel with this growth, there is a growing need to carefully\nevaluate whether models accurately capture domain-specific knowledge and\nnotation, since general-purpose benchmarks rarely reflect these requirements.\nThis gap is especially clear in quantum science, which features non-intuitive\nphenomena and requires advanced mathematics. In this study, we introduce\nQuantumBench, a benchmark for the quantum domain that systematically examine\nhow well LLMs understand and can be applied to this non-intuitive field. Using\npublicly available materials, we compiled approximately 800 questions with\ntheir answers spanning nine areas related to quantum science and organized them\ninto an eight-option multiple-choice dataset. With this benchmark, we evaluate\nseveral existing LLMs and analyze their performance in the quantum domain,\nincluding sensitivity to changes in question format. QuantumBench is the first\nLLM evaluation dataset built for the quantum domain, and it is intended to\nguide the effective use of LLMs in quantum research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u91cf\u5b50\u9886\u57df\u57fa\u51c6QuantumBench\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cf\u5b50\u9886\u57df\u8868\u73b0\uff0c\u4ee5\u6307\u5bfc\u5176\u5728\u91cf\u5b50\u7814\u7a76\u4e2d\u7684\u6709\u6548\u4f7f\u7528\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5165\u79d1\u7814\u5de5\u4f5c\u6d41\uff0c\u9700\u8bc4\u4f30\u5176\u662f\u5426\u51c6\u786e\u638c\u63e1\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u548c\u7b26\u53f7\uff0c\u91cf\u5b50\u79d1\u5b66\u9886\u57df\u6b64\u9700\u6c42\u5c24\u4e3a\u660e\u663e\u3002", "method": "\u5229\u7528\u516c\u5f00\u6750\u6599\uff0c\u7f16\u5199\u7ea6800\u9053\u6db5\u76d6\u91cf\u5b50\u79d1\u5b66\u4e5d\u4e2a\u9886\u57df\u7684\u95ee\u7b54\uff0c\u7ec4\u7ec7\u6210\u516b\u9009\u9879\u9009\u62e9\u9898\u6570\u636e\u96c6\uff0c\u7528\u8be5\u57fa\u51c6\u8bc4\u4f30\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u4e86\u591a\u4e2a\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5206\u6790\u5176\u5728\u91cf\u5b50\u9886\u57df\u7684\u8868\u73b0\u53ca\u5bf9\u95ee\u9898\u683c\u5f0f\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "conclusion": "QuantumBench\u662f\u9996\u4e2a\u9488\u5bf9\u91cf\u5b50\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u53ef\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cf\u5b50\u7814\u7a76\u4e2d\u7684\u6709\u6548\u4f7f\u7528\u3002"}}
{"id": "2511.00160", "pdf": "https://arxiv.org/pdf/2511.00160", "abs": "https://arxiv.org/abs/2511.00160", "authors": ["Katherine A. Rosenfeld", "Cliff C. Kerr", "Jessica Lundin"], "title": "What a diff makes: automating code migration with large language models", "categories": ["cs.SE", "cs.AI"], "comment": "10 pages, 8 figures", "summary": "Modern software programs are built on stacks that are often undergoing\nchanges that introduce updates and improvements, but may also break any project\nthat depends upon them. In this paper we explore the use of Large Language\nModels (LLMs) for code migration, specifically the problem of maintaining\ncompatibility with a dependency as it undergoes major and minor semantic\nversion changes. We demonstrate, using metrics such as test coverage and change\ncomparisons, that contexts containing diffs can significantly improve\nperformance against out of the box LLMs and, in some cases, perform better than\nusing code. We provide a dataset to assist in further development of this\nproblem area, as well as an open-source Python package, AIMigrate, that can be\nused to assist with migrating code bases. In a real-world migration of\nTYPHOIDSIM between STARSIM versions, AIMigrate correctly identified 65% of\nrequired changes in a single run, increasing to 80% with multiple runs, with\n47% of changes generated perfectly.", "AI": {"tldr": "\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u8fc1\u79fb\uff0c\u8bc1\u660e\u542bdiff\u7684\u4e0a\u4e0b\u6587\u53ef\u63d0\u5347\u6027\u80fd\uff0c\u63d0\u4f9b\u6570\u636e\u96c6\u548c\u5f00\u6e90\u5305AIMigrate\uff0c\u5728\u5b9e\u9645\u8fc1\u79fb\u4e2d\u6709\u8f83\u597d\u8868\u73b0\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u6808\u5e38\u53d8\u5316\uff0c\u53ef\u80fd\u7834\u574f\u4f9d\u8d56\u9879\u76ee\uff0c\u9700\u89e3\u51b3\u4ee3\u7801\u8fc1\u79fb\u4e2d\u4e0e\u4f9d\u8d56\u4fdd\u6301\u517c\u5bb9\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u53d8\u66f4\u6bd4\u8f83\u7b49\u6307\u6807\uff0c\u5bf9\u6bd4\u542bdiff\u7684\u4e0a\u4e0b\u6587\u4e0e\u666e\u901a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u542bdiff\u7684\u4e0a\u4e0b\u6587\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0cAIMigrate\u5728TYPHOIDSIM\u8fc1\u79fb\u4e2d\uff0c\u5355\u6b21\u8fd0\u884c\u8bc6\u522b65%\u7684\u5fc5\u8981\u53d8\u66f4\uff0c\u591a\u6b21\u8fd0\u884c\u8fbe80%\uff0c47%\u7684\u53d8\u66f4\u5b8c\u7f8e\u751f\u6210\u3002", "conclusion": "\u542bdiff\u7684\u4e0a\u4e0b\u6587\u5bf9\u4ee3\u7801\u8fc1\u79fb\u6709\u79ef\u6781\u4f5c\u7528\uff0cAIMigrate\u53ef\u8f85\u52a9\u4ee3\u7801\u5e93\u8fc1\u79fb\u3002"}}
{"id": "2511.00032", "pdf": "https://arxiv.org/pdf/2511.00032", "abs": "https://arxiv.org/abs/2511.00032", "authors": ["Lei Liu", "Zhongyi Yu", "Hong Wang", "Huanshuo Dong", "Haiyang Xin", "Hongwei Zhao", "Bin Li"], "title": "From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years, Neural Operators(NO) have gradually emerged as a popular\napproach for solving Partial Differential Equations (PDEs). However, their\napplication to large-scale engineering tasks suffers from significant\ncomputational overhead. And the fact that current models impose a uniform\ncomputational cost while physical fields exhibit vastly different complexities\nconstitutes a fundamental mismatch, which is the root of this inefficiency. For\ninstance, in turbulence flows, intricate vortex regions require deeper network\nprocessing compared to stable flows. To address this, we introduce a framework:\nSkip-Block Routing (SBR), a general framework designed for Transformer-based\nneural operators, capable of being integrated into their multi-layer\narchitectures. First, SBR uses a routing mechanism to learn the complexity and\nranking of tokens, which is then applied during inference. Then, in later\nlayers, it decides how many tokens are passed forward based on this ranking.\nThis way, the model focuses more processing capacity on the tokens that are\nmore complex. Experiments demonstrate that SBR is a general framework that\nseamlessly integrates into various neural operators. Our method reduces\ncomputational cost by approximately 50% in terms of Floating Point Operations\n(FLOPs), while still delivering up to 2x faster inference without sacrificing\naccuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSkip - Block Routing (SBR)\u6846\u67b6\u89e3\u51b3\u795e\u7ecf\u7b97\u5b50\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u53ef\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u52a0\u5feb\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u7b97\u5b50\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u5de5\u7a0b\u4efb\u52a1\u65f6\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u6a21\u578b\u7edf\u4e00\u8ba1\u7b97\u6210\u672c\u4e0e\u7269\u7406\u573a\u590d\u6742\u5ea6\u4e0d\u5339\u914d\u3002", "method": "\u5f15\u5165SBR\u6846\u67b6\uff0c\u7528\u8def\u7531\u673a\u5236\u5b66\u4e60\u4ee4\u724c\u590d\u6742\u5ea6\u548c\u6392\u540d\uff0c\u5728\u540e\u7eed\u5c42\u6839\u636e\u6392\u540d\u51b3\u5b9a\u4f20\u9012\u7684\u4ee4\u724c\u6570\u91cf\u3002", "result": "SBR\u662f\u901a\u7528\u6846\u67b6\uff0c\u53ef\u96c6\u6210\u5230\u5404\u79cd\u795e\u7ecf\u7b97\u5b50\u4e2d\uff0c\u51cf\u5c11\u7ea650%\u7684\u6d6e\u70b9\u8fd0\u7b97\u8ba1\u7b97\u6210\u672c\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8fbe2\u500d\u4e14\u4e0d\u635f\u5931\u7cbe\u5ea6\u3002", "conclusion": "SBR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u7b97\u5b50\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5177\u6709\u901a\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2511.00884", "pdf": "https://arxiv.org/pdf/2511.00884", "abs": "https://arxiv.org/abs/2511.00884", "authors": ["Mathias Mankoe", "Fuqiang Lu", "Hualing Bi", "Abdulsalam Sibidoo Mubashiru"], "title": "A Meta-Cognitive Swarm Intelligence Framework for Resilient UAV Navigation in GPS-Denied and Cluttered Environments", "categories": ["cs.CE"], "comment": null, "summary": "Autonomous navigation of UAV swarms in perceptually-degraded environments,\nwhere GPS is unavailable and terrain is densely cluttered, presents a critical\nbottleneck for real-world deployment. Existing optimization-based planners lack\nthe resilience to avoid catastrophic convergence to local optima under such\nuncertainty. Inspired by principles of computational meta-cognition, this paper\nintroduces a novel swarm intelligence framework that enables a fleet of UAVs to\nautonomously sense, adapt, and recover from planning failures in real-time. At\nits core is the Self-Learning Slime Mould Algorithm (SLSMA), which integrates\nthree meta-cognitive layers: a situation-aware search strategy that dynamically\nselects between exploration and exploitation based on perceived search\nstagnation; a collective memory mechanism that allows the swarm to learn from\nand avoid previously failed trajectories; and an adaptive recovery behavior\nthat triggers global re-exploration upon entrapment. We formulate the multi-UAV\ntrajectory problem as a resilient planning challenge, with a cost function that\npenalizes not only path length and collisions but also navigational uncertainty\nand proximity to failure states. Extensive simulations in synthetically complex\n3D worlds and against the CEC 2017 benchmark suite demonstrate the framework's\nsuperior performance. The SLSMA does not merely optimize paths; it generates\nresilient trajectories, demonstrating a 99.5% mission success rate and\nsignificantly outperforming state-of-the-art metaheuristics in recovery speed\nand solution reliability. This work provides a foundational step towards truly\nautonomous swarms capable of persistent operation in denied and dynamic\nenvironments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u65e0\u4eba\u673a\u7fa4\u81ea\u4e3b\u5bfc\u822a\u7684\u65b0\u578b\u7fa4\u4f53\u667a\u80fd\u6846\u67b6\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u5176\u6027\u80fd\u4f18\u8d8a\uff0c\u4e3a\u81ea\u4e3b\u65e0\u4eba\u673a\u7fa4\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4f18\u5316\u7684\u89c4\u5212\u5668\u5728\u611f\u77e5\u9000\u5316\u73af\u5883\u4e2d\u7f3a\u4e4f\u5f39\u6027\uff0c\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u8ba1\u7b97\u5143\u8ba4\u77e5\u539f\u7406\u7684\u7fa4\u4f53\u667a\u80fd\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u81ea\u5b66\u4e60\u9ecf\u83cc\u7b97\u6cd5\uff08SLSMA\uff09\uff0c\u96c6\u6210\u4e09\u5c42\u5143\u8ba4\u77e5\u673a\u5236\uff0c\u5c06\u591a\u65e0\u4eba\u673a\u8f68\u8ff9\u95ee\u9898\u5efa\u6a21\u4e3a\u5f39\u6027\u89c4\u5212\u6311\u6218\u3002", "result": "\u5728\u590d\u67423D\u4e16\u754c\u548cCEC 2017\u57fa\u51c6\u5957\u4ef6\u6a21\u62df\u4e2d\uff0c\u8be5\u6846\u67b6\u4efb\u52a1\u6210\u529f\u7387\u8fbe99.5%\uff0c\u5728\u6062\u590d\u901f\u5ea6\u548c\u89e3\u51b3\u65b9\u6848\u53ef\u9760\u6027\u4e0a\u8fdc\u8d85\u73b0\u6709\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u80fd\u5728\u6076\u52a3\u52a8\u6001\u73af\u5883\u6301\u7eed\u8fd0\u884c\u7684\u771f\u6b63\u81ea\u4e3b\u65e0\u4eba\u673a\u7fa4\u8fc8\u51fa\u57fa\u7840\u6027\u4e00\u6b65\u3002"}}
{"id": "2511.01244", "pdf": "https://arxiv.org/pdf/2511.01244", "abs": "https://arxiv.org/abs/2511.01244", "authors": ["Wajid Ali", "Ayaz Akram", "Deepak Shankar"], "title": "Simulation-Driven Evaluation of Chiplet-Based Architectures Using VisualSim", "categories": ["cs.AR", "cs.PF"], "comment": null, "summary": "This paper focuses on the simulation of multi-die System-on-Chip (SoC)\narchitectures using VisualSim, emphasiz- ing chiplet-based system modeling and\nperformance analysis. Chiplet technology presents a promising alternative to\ntraditional monolithic chips, which face increasing challenges in manufactur-\ning costs, power efficiency, and performance scaling. By integrat- ing multiple\nsmall modular silicon units into a single package, chiplet-based architectures\noffer greater flexibility and scalability at a lower overall cost. In this\nstudy, we developed a detailed sim- ulation model of a chiplet-based system,\nincorporating multicore ARM processor clusters interconnected through a ARM\nCMN600 network-on-chip (NoC) for efficient communication [4], [7]. The\nsimulation framework in VisualSim enables the evaluation of critical system\nmetrics, including inter-chiplet communication latency, memory access\nefficiency, workload distribution, and the power-performance tradeoff under\nvarious workloads. Through simulation-driven insights, this research highlights\nkey factors influencing chiplet system performance and provides a foundation\nfor optimizing future chiplet-based semiconductor designs.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528VisualSim\u5bf9\u591a\u82af\u7247\u7247\u4e0a\u7cfb\u7edf\uff08SoC\uff09\u67b6\u6784\u8fdb\u884c\u4eff\u771f\uff0c\u91cd\u70b9\u662f\u57fa\u4e8e\u5c0f\u82af\u7247\u7684\u7cfb\u7edf\u5efa\u6a21\u4e0e\u6027\u80fd\u5206\u6790\uff0c\u4e3a\u672a\u6765\u8bbe\u8ba1\u4f18\u5316\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u4f20\u7edf\u5355\u7247\u82af\u7247\u5728\u5236\u9020\u6210\u672c\u3001\u7535\u6e90\u6548\u7387\u548c\u6027\u80fd\u6269\u5c55\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u800c\u5c0f\u82af\u7247\u6280\u672f\u5177\u6709\u6210\u672c\u4f4e\u3001\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u9ad8\u7684\u4f18\u52bf\uff0c\u56e0\u6b64\u7814\u7a76\u5c0f\u82af\u7247\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5c0f\u82af\u7247\u7cfb\u7edf\u7684\u8be6\u7ec6\u4eff\u771f\u6a21\u578b\uff0c\u5728VisualSim\u4e2d\u901a\u8fc7ARM CMN600\u7247\u4e0a\u7f51\u7edc\u8fde\u63a5\u591a\u6838ARM\u5904\u7406\u5668\u96c6\u7fa4\uff0c\u8bc4\u4f30\u5173\u952e\u7cfb\u7edf\u6307\u6807\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u83b7\u5f97\u5f71\u54cd\u5c0f\u82af\u7247\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u4e3a\u4f18\u5316\u672a\u6765\u57fa\u4e8e\u5c0f\u82af\u7247\u7684\u534a\u5bfc\u4f53\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00750", "pdf": "https://arxiv.org/pdf/2511.00750", "abs": "https://arxiv.org/abs/2511.00750", "authors": ["Kokila Kasuni Perera", "Frank Neumann", "Aneta Neumann"], "title": "Trust Region-Based Bayesian Optimisation to Discover Diverse Solutions", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Bayesian optimisation (BO) is a surrogate-based optimisation technique that\nefficiently solves expensive black-box functions with small evaluation budgets.\nRecent studies consider trust regions to improve the scalability of BO\napproaches when the problem space scales to more dimensions. Motivated by this\nresearch, we explore the effectiveness of trust region-based BO algorithms for\ndiversity optimisation in different dimensional black box problems. We propose\ndiversity optimisation approaches extending TuRBO1, which is the first BO\nmethod that uses a trust region-based approach for scalability. We extend\nTuRBO1 as divTuRBO1, which finds an optimal solution while maintaining a given\ndistance threshold relative to a reference solution set. We propose two\napproaches to find diverse solutions for black-box functions by combining\ndivTuRBO1 runs in a sequential and an interleaving fashion. We conduct\nexperimental investigations on the proposed algorithms and compare their\nperformance with that of the baseline method, ROBOT (rank-ordered Bayesian\noptimisation with trust regions). We evaluate proposed algorithms on benchmark\nfunctions with dimensions 2 to 20. Experimental investigations demonstrate that\nthe proposed methods perform well, particularly in larger dimensions, even with\na limited evaluation budget.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u57fa\u4e8e\u4fe1\u4efb\u533a\u57df\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7b97\u6cd5\u5728\u4e0d\u540c\u7ef4\u5ea6\u9ed1\u76d2\u95ee\u9898\u591a\u6837\u6027\u4f18\u5316\u4e2d\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u6269\u5c55\u7b97\u6cd5\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u5927\u7ef4\u5ea6\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u53d7\u8fd1\u671f\u4f7f\u7528\u4fe1\u4efb\u533a\u57df\u63d0\u9ad8\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u53ef\u6269\u5c55\u6027\u7814\u7a76\u7684\u542f\u53d1\uff0c\u63a2\u7d22\u57fa\u4e8e\u4fe1\u4efb\u533a\u57df\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7b97\u6cd5\u5728\u4e0d\u540c\u7ef4\u5ea6\u9ed1\u76d2\u95ee\u9898\u591a\u6837\u6027\u4f18\u5316\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u6269\u5c55TuRBO1\u5f97\u5230divTuRBO1\uff0c\u63d0\u51fa\u4e24\u79cd\u7ed3\u5408divTuRBO1\u8fd0\u884c\u7684\u65b9\u6cd5\u6765\u5bfb\u627e\u9ed1\u76d2\u51fd\u6570\u7684\u591a\u6837\u89e3\uff0c\u5e76\u4e0e\u57fa\u7ebf\u65b9\u6cd5ROBOT\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u57282\u523020\u7ef4\u7684\u57fa\u51c6\u51fd\u6570\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u8868\u73b0\u826f\u597d\uff0c\u7279\u522b\u662f\u5728\u5927\u7ef4\u5ea6\u95ee\u9898\u4e0a\uff0c\u5373\u4f7f\u8bc4\u4f30\u9884\u7b97\u6709\u9650\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u4fe1\u4efb\u533a\u57df\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7b97\u6cd5\u5728\u4e0d\u540c\u7ef4\u5ea6\u9ed1\u76d2\u95ee\u9898\u591a\u6837\u6027\u4f18\u5316\u4e2d\u6709\u6548\uff0c\u5c24\u5176\u5728\u5927\u7ef4\u5ea6\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.00748", "pdf": "https://arxiv.org/pdf/2511.00748", "abs": "https://arxiv.org/abs/2511.00748", "authors": ["Yi Yang", "Jian Pei", "Jun Yang", "Jichun Xie"], "title": "Finding Non-Redundant Simpson's Paradox from Multidimensional Data", "categories": ["cs.DB"], "comment": "20 pages, 7 figures", "summary": "Simpson's paradox, a long-standing statistical phenomenon, describes the\nreversal of an observed association when data are disaggregated into\nsub-populations. It has critical implications across statistics, epidemiology,\neconomics, and causal inference. Existing methods for detecting Simpson's\nparadox overlook a key issue: many paradoxes are redundant, arising from\nequivalent selections of data subsets, identical partitioning of\nsub-populations, and correlated outcome variables, which obscure essential\npatterns and inflate computational cost. In this paper, we present the first\nframework for discovering non-redundant Simpson's paradoxes. We formalize three\ntypes of redundancy - sibling child, separator, and statistic equivalence - and\nshow that redundancy forms an equivalence relation. Leveraging this insight, we\npropose a concise representation framework for systematically organizing\nredundant paradoxes and design efficient algorithms that integrate depth-first\nmaterialization of the base table with redundancy-aware paradox discovery.\nExperiments on real-world datasets and synthetic benchmarks show that redundant\nparadoxes are widespread, on some real datasets constituting over 40% of all\nparadoxes, while our algorithms scale to millions of records, reduce run time\nby up to 60%, and discover paradoxes that are structurally robust under data\nperturbation. These results demonstrate that Simpson's paradoxes can be\nefficiently identified, concisely summarized, and meaningfully interpreted in\nlarge multidimensional datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u53d1\u73b0\u975e\u5197\u4f59\u8f9b\u666e\u68ee\u6096\u8bba\u7684\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u5728\u5927\u6570\u636e\u96c6\u4e2d\u9ad8\u6548\u8bc6\u522b\u3001\u603b\u7ed3\u548c\u89e3\u91ca\u6096\u8bba\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u8f9b\u666e\u68ee\u6096\u8bba\u7684\u65b9\u6cd5\u5ffd\u7565\u4e86\u8bb8\u591a\u6096\u8bba\u5b58\u5728\u5197\u4f59\u7684\u95ee\u9898\uff0c\u8fd9\u4f1a\u63a9\u76d6\u5173\u952e\u6a21\u5f0f\u5e76\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5f62\u5f0f\u5316\u4e09\u79cd\u5197\u4f59\u7c7b\u578b\uff0c\u63d0\u51fa\u7b80\u6d01\u8868\u793a\u6846\u67b6\u7ec4\u7ec7\u5197\u4f59\u6096\u8bba\uff0c\u8bbe\u8ba1\u7ed3\u5408\u6df1\u5ea6\u4f18\u5148\u5b9e\u4f8b\u5316\u548c\u5197\u4f59\u611f\u77e5\u53d1\u73b0\u7684\u7b97\u6cd5\u3002", "result": "\u5197\u4f59\u6096\u8bba\u5e7f\u6cdb\u5b58\u5728\uff0c\u7b97\u6cd5\u53ef\u5904\u7406\u6570\u767e\u4e07\u6761\u8bb0\u5f55\uff0c\u51cf\u5c11\u6700\u591a60%\u8fd0\u884c\u65f6\u95f4\uff0c\u53d1\u73b0\u6570\u636e\u6270\u52a8\u4e0b\u7ed3\u6784\u7a33\u5065\u7684\u6096\u8bba\u3002", "conclusion": "\u8f9b\u666e\u68ee\u6096\u8bba\u53ef\u5728\u5927\u578b\u591a\u7ef4\u6570\u636e\u96c6\u4e2d\u88ab\u9ad8\u6548\u8bc6\u522b\u3001\u603b\u7ed3\u548c\u6709\u610f\u4e49\u5730\u89e3\u91ca\u3002"}}
{"id": "2511.01157", "pdf": "https://arxiv.org/pdf/2511.01157", "abs": "https://arxiv.org/abs/2511.01157", "authors": ["Ce Li", "Qianfan Zhang", "Weiqiang Zheng"], "title": "From Best Responses to Learning: Investment Efficiency in Dynamic Environment", "categories": ["cs.GT", "econ.TH"], "comment": null, "summary": "We study the welfare of a mechanism in a dynamic environment where a learning\ninvestor can make a costly investment to change her value. In many real-world\nproblems, the common assumption that the investor always makes the best\nresponses, i.e., choosing her utility-maximizing investment option, is\nunrealistic due to incomplete information in a dynamically evolving\nenvironment. To address this, we consider an investor who uses a no-regret\nonline learning algorithm to adaptively select investments through repeated\ninteractions with the environment. We analyze how the welfare guarantees of\napproximation allocation algorithms extend from static to dynamic settings when\nthe investor learns rather than best-responds, by studying the approximation\nratio for optimal welfare as a measurement of an algorithm's performance\nagainst different benchmarks in the dynamic learning environment. First, we\nshow that the approximation ratio in the static environment remains unchanged\nin the dynamic environment against the best-in-hindsight benchmark. Second, we\nprovide tight characterizations of the approximation upper and lower bounds\nrelative to a stronger time-varying benchmark. Bridging mechanism design with\nonline learning theory, our work shows how robust welfare guarantees can be\nmaintained even when an agent cannot make best responses but learns their\ninvestment strategies in complex, uncertain environments.", "AI": {"tldr": "\u7814\u7a76\u52a8\u6001\u73af\u5883\u4e2d\u5b66\u4e60\u578b\u6295\u8d44\u8005\u6295\u8d44\u673a\u5236\u7684\u798f\u5229\uff0c\u5206\u6790\u8fd1\u4f3c\u5206\u914d\u7b97\u6cd5\u798f\u5229\u4fdd\u8bc1\u4ece\u9759\u6001\u5230\u52a8\u6001\u7684\u6269\u5c55\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u52a8\u6001\u73af\u5883\u4fe1\u606f\u4e0d\u5b8c\u5168\uff0c\u6295\u8d44\u8005\u65e0\u6cd5\u603b\u662f\u505a\u51fa\u6700\u4f73\u54cd\u5e94\uff0c\u4f20\u7edf\u5047\u8bbe\u4e0d\u73b0\u5b9e\u3002", "method": "\u8003\u8651\u4f7f\u7528\u65e0\u6094\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u7684\u6295\u8d44\u8005\uff0c\u901a\u8fc7\u7814\u7a76\u8fd1\u4f3c\u6bd4\u8861\u91cf\u7b97\u6cd5\u5728\u52a8\u6001\u5b66\u4e60\u73af\u5883\u4e2d\u8868\u73b0\u3002", "result": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\uff0c\u76f8\u5bf9\u4e8b\u540e\u6700\u4f73\u57fa\u51c6\uff0c\u9759\u6001\u73af\u5883\u8fd1\u4f3c\u6bd4\u4e0d\u53d8\uff1b\u7ed9\u51fa\u76f8\u5bf9\u66f4\u5f3a\u65f6\u53d8\u57fa\u51c6\u7684\u8fd1\u4f3c\u4e0a\u4e0b\u754c\u3002", "conclusion": "\u5373\u4f7f\u4ee3\u7406\u65e0\u6cd5\u505a\u51fa\u6700\u4f73\u54cd\u5e94\uff0c\u5728\u590d\u6742\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5b66\u4e60\u6295\u8d44\u7b56\u7565\uff0c\u4ecd\u53ef\u7ef4\u6301\u7a33\u5065\u7684\u798f\u5229\u4fdd\u8bc1\u3002"}}
{"id": "2511.00781", "pdf": "https://arxiv.org/pdf/2511.00781", "abs": "https://arxiv.org/abs/2511.00781", "authors": ["Purba Banerjee", "Srikanth Iyer", "Shashi Jain"], "title": "Robust Hedging of path-dependent options using a min-max algorithm", "categories": ["q-fin.MF", "math.OC", "math.PR", "q-fin.RM"], "comment": null, "summary": "We consider an investor who wants to hedge a path-dependent option with\nmaturity $T$ using a static hedging portfolio using cash, the underlying, and\nvanilla put/call options on the same underlying with maturity $ t_1$, where $0\n< t_1 < T$. We propose a model-free approach to construct such a portfolio. The\nframework is inspired by the \\textit{primal-dual} Martingale Optimal Transport\n(MOT) problem, which was pioneered by \\cite{beiglbock2013model}. The\noptimization problem is to determine the portfolio composition that minimizes\nthe expected worst-case hedging error at $t_1$ (that coincides with the\nmaturity of the options that are used in the hedging portfolio). The worst-case\nscenario corresponds to the distribution that yields the worst possible hedging\nperformance. This formulation leads to a \\textit{min-max} problem. We provide a\nnumerical scheme for solving this problem when a finite number of vanilla\noption prices are available. Numerical results on the hedging performance of\nthis model-free approach when the option prices are generated using a\n\\textit{Black-Scholes} and a \\textit{Merton Jump diffusion} model are\npresented. We also provide theoretical bounds on the hedging error at $T$, the\nmaturity of the target option.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u6a21\u578b\u65b9\u6cd5\u6784\u5efa\u9759\u6001\u5bf9\u51b2\u6295\u8d44\u7ec4\u5408\uff0c\u89e3\u51b3min - max\u95ee\u9898\uff0c\u7ed9\u51fa\u6570\u503c\u65b9\u6848\u5e76\u5c55\u793a\u7ed3\u679c\u548c\u7406\u8bba\u8bef\u5dee\u754c\u3002", "motivation": "\u6295\u8d44\u8005\u60f3\u7528\u73b0\u91d1\u3001\u6807\u7684\u8d44\u4ea7\u548c\u5230\u671f\u65e5\u4e3at1\uff080 < t1 < T\uff09\u7684\u9999\u8349\u671f\u6743\u9759\u6001\u5bf9\u51b2\u5230\u671f\u65e5\u4e3aT\u7684\u8def\u5f84\u4f9d\u8d56\u671f\u6743\uff0c\u9700\u8981\u5408\u9002\u7684\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u53d7primal - dual Martingale Optimal Transport (MOT)\u95ee\u9898\u542f\u53d1\uff0c\u6784\u5efa\u6700\u5c0f\u5316t1\u65f6\u671f\u671b\u6700\u574f\u5bf9\u51b2\u8bef\u5dee\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5f62\u6210min - max\u95ee\u9898\uff0c\u6709\u671f\u6743\u4ef7\u683c\u65f6\u7ed9\u51fa\u6570\u503c\u6c42\u89e3\u65b9\u6848\u3002", "result": "\u7ed9\u51fa\u5728Black - Scholes\u548cMerton Jump diffusion\u6a21\u578b\u751f\u6210\u671f\u6743\u4ef7\u683c\u65f6\u7684\u5bf9\u51b2\u8868\u73b0\u6570\u503c\u7ed3\u679c\uff0c\u4ee5\u53ca\u76ee\u6807\u671f\u6743\u5230\u671f\u65e5T\u7684\u5bf9\u51b2\u8bef\u5dee\u7406\u8bba\u754c\u3002", "conclusion": "\u8be5\u65e0\u6a21\u578b\u65b9\u6cd5\u53ef\u7528\u4e8e\u6784\u5efa\u9759\u6001\u5bf9\u51b2\u6295\u8d44\u7ec4\u5408\uff0c\u5e76\u80fd\u5206\u6790\u5bf9\u51b2\u8bef\u5dee\u3002"}}
{"id": "2511.00685", "pdf": "https://arxiv.org/pdf/2511.00685", "abs": "https://arxiv.org/abs/2511.00685", "authors": ["Haoting Zhang", "Haoxian Chen", "Donglin Zhan", "Hanyang Zhao", "Henry Lam", "Wenpin Tang", "David Yao", "Zeyu Zheng"], "title": "SOCRATES: Simulation Optimization with Correlated Replicas and Adaptive Trajectory Evaluations", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The field of simulation optimization (SO) encompasses various methods\ndeveloped to optimize complex, expensive-to-sample stochastic systems.\nEstablished methods include, but are not limited to, ranking-and-selection for\nfinite alternatives and surrogate-based methods for continuous domains, with\nbroad applications in engineering and operations management. The recent advent\nof large language models (LLMs) offers a new paradigm for exploiting system\nstructure and automating the strategic selection and composition of these\nestablished SO methods into a tailored optimization procedure. This work\nintroduces SOCRATES (Simulation Optimization with Correlated Replicas and\nAdaptive Trajectory Evaluations), a novel two-stage procedure that leverages\nLLMs to automate the design of tailored SO algorithms. The first stage\nconstructs an ensemble of digital replicas of the real system. An LLM is\nemployed to implement causal discovery from a textual description of the\nsystem, generating a structural `skeleton' that guides the sample-efficient\nlearning of the replicas. In the second stage, this replica ensemble is used as\nan inexpensive testbed to evaluate a set of baseline SO algorithms. An LLM then\nacts as a meta-optimizer, analyzing the performance trajectories of these\nalgorithms to iteratively revise and compose a final, hybrid optimization\nschedule. This schedule is designed to be adaptive, with the ability to be\nupdated during the final execution on the real system when the optimization\nperformance deviates from expectations. By integrating LLM-driven reasoning\nwith LLM-assisted trajectory-aware meta-optimization, SOCRATES creates an\neffective and sample-efficient solution for complex SO optimization problems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u65b0\u7684\u6a21\u62df\u4f18\u5316\u7a0b\u5e8fSOCRATES\uff0c\u5b83\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u8bbe\u8ba1\u5b9a\u5236\u7b97\u6cd5\uff0c\u5206\u4e24\u9636\u6bb5\u5b9e\u73b0\u590d\u6742\u6a21\u62df\u4f18\u5316\u95ee\u9898\u7684\u9ad8\u6548\u6837\u672c\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51fa\u73b0\u4e3a\u5229\u7528\u7cfb\u7edf\u7ed3\u6784\u548c\u81ea\u52a8\u5316\u6a21\u62df\u4f18\u5316\u65b9\u6cd5\u7684\u9009\u62e9\u4e0e\u7ec4\u5408\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u4f18\u5316\u7a0b\u5e8f\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u7a0b\u5e8fSOCRATES\uff0c\u7b2c\u4e00\u9636\u6bb5\u6784\u5efa\u7cfb\u7edf\u6570\u5b57\u526f\u672c\u96c6\u5408\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u6307\u5bfc\u5b66\u4e60\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7528\u526f\u672c\u96c6\u5408\u8bc4\u4f30\u57fa\u7ebf\u7b97\u6cd5\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5143\u4f18\u5316\u5668\u5206\u6790\u6027\u80fd\u8f68\u8ff9\uff0c\u8fed\u4ee3\u4fee\u8ba2\u5e76\u7ec4\u5408\u6700\u7ec8\u4f18\u5316\u8c03\u5ea6\u3002", "result": "\u901a\u8fc7\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u63a8\u7406\u548c\u8f68\u8ff9\u611f\u77e5\u5143\u4f18\u5316\uff0c\u521b\u5efa\u4e86\u6709\u6548\u4e14\u6837\u672c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "SOCRATES\u80fd\u6709\u6548\u89e3\u51b3\u590d\u6742\u6a21\u62df\u4f18\u5316\u95ee\u9898\uff0c\u5177\u6709\u9002\u5e94\u6027\uff0c\u53ef\u5728\u6027\u80fd\u504f\u79bb\u9884\u671f\u65f6\u66f4\u65b0\u8c03\u5ea6\u3002"}}
{"id": "2511.00660", "pdf": "https://arxiv.org/pdf/2511.00660", "abs": "https://arxiv.org/abs/2511.00660", "authors": ["Antti J. Tanskanen"], "title": "A rich life cycle model of labor supply in Finland", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "A life cycle model of consumption and labor supply describes employment\ndecisions of a collection of individuals during their lifetime. We develop a\nlife cycle model describing a heterogeneous population operating in Finland\nunder a wide variety of employment states and life situations. A rich life\ncycle model requires a large state space representing the possible states of\nsimulated agents. The results demonstrate that the model reproduces a number of\nstatistics of the Finnish employment market such as the age structures of\nemployment rate and unemployment rate, distributions of observed effective\nmarginal tax rates and participating tax rates, and proportion of part time\nwork. As an application of analysis of a reform, we analyze how the program of\nOrpo government influences employment and public finances in Finland.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u82ac\u5170\u5f02\u8d28\u4eba\u53e3\u7684\u6d88\u8d39\u4e0e\u52b3\u52a8\u4f9b\u7ed9\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u6a21\u578b\u80fd\u590d\u73b0\u82ac\u5170\u5c31\u4e1a\u5e02\u573a\u591a\u9879\u7edf\u8ba1\u6570\u636e\uff0c\u5e76\u5206\u6790\u4e86Orpo\u653f\u5e9c\u8ba1\u5212\u5bf9\u5c31\u4e1a\u548c\u516c\u5171\u8d22\u653f\u7684\u5f71\u54cd\u3002", "motivation": "\u6784\u5efa\u63cf\u8ff0\u82ac\u5170\u5f02\u8d28\u4eba\u53e3\u5728\u591a\u79cd\u5c31\u4e1a\u72b6\u6001\u548c\u751f\u6d3b\u60c5\u51b5\u4e0b\u7684\u6d88\u8d39\u4e0e\u52b3\u52a8\u4f9b\u7ed9\u751f\u547d\u5468\u671f\u6a21\u578b\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u63cf\u8ff0\u82ac\u5170\u5f02\u8d28\u4eba\u53e3\u7684\u751f\u547d\u5468\u671f\u6a21\u578b\u3002", "result": "\u6a21\u578b\u80fd\u590d\u73b0\u82ac\u5170\u5c31\u4e1a\u5e02\u573a\u7684\u591a\u9879\u7edf\u8ba1\u6570\u636e\u3002", "conclusion": "\u53ef\u8fd0\u7528\u8be5\u6a21\u578b\u5206\u6790Orpo\u653f\u5e9c\u8ba1\u5212\u5bf9\u82ac\u5170\u5c31\u4e1a\u548c\u516c\u5171\u8d22\u653f\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.00006", "pdf": "https://arxiv.org/pdf/2511.00006", "abs": "https://arxiv.org/abs/2511.00006", "authors": ["Xingyu Ren", "Michael C. Fu", "Pierre L'Ecuyer"], "title": "Stochastic Derivative Estimation for Discontinuous Sample Performances: A Leibniz Integration Perspective", "categories": ["stat.ME", "math.PR", "stat.CO"], "comment": null, "summary": "We develop a novel stochastic derivative estimation framework for sample\nperformance functions that are discontinuous in the parameter of interest,\nbased on the multidimensional Leibniz integral rule. When discontinuities arise\nfrom indicator functions, we embed the indicator functions into the sample\nspace, yielding a continuous performance function over a parameter-dependent\ndomain. Applying the Leibniz integral rule in this case produces a single-run,\nunbiased derivative estimator. For general discontinuous functions, we apply a\nchange of variables to shift parameter dependence into the sample space and the\nunderlying probability measure. Applying the Leibniz integral rule leads to two\nterms: a standard likelihood ratio (LR) term from differentiating the\nunderlying probability measure and a surface integral from differentiating the\nboundary of the domain. Evaluating the surface integral may require simulating\nmultiple sample paths. Our proposed Leibniz integration framework generalizes\nthe generalized LR (GLR) method and provides intuition as to when the surface\nintegral vanishes, thereby enabling single-run, easily implementable\nestimators. Numerical experiments demonstrate the effectiveness and robustness\nof our methods.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u591a\u7ef4\u83b1\u5e03\u5c3c\u8328\u79ef\u5206\u89c4\u5219\uff0c\u5f00\u53d1\u4e86\u7528\u4e8e\u4e0d\u8fde\u7eed\u6837\u672c\u6027\u80fd\u51fd\u6570\u7684\u968f\u673a\u5bfc\u6570\u4f30\u8ba1\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u6837\u672c\u6027\u80fd\u51fd\u6570\u5728\u611f\u5174\u8da3\u53c2\u6570\u4e0a\u4e0d\u8fde\u7eed\u7684\u60c5\u51b5\u5f00\u53d1\u5bfc\u6570\u4f30\u8ba1\u6846\u67b6\u3002", "method": "\u5bf9\u4e8e\u4e0d\u8fde\u7eed\u6e90\u4e8e\u6307\u793a\u51fd\u6570\u7684\u60c5\u51b5\uff0c\u5c06\u6307\u793a\u51fd\u6570\u5d4c\u5165\u6837\u672c\u7a7a\u95f4\uff1b\u5bf9\u4e8e\u4e00\u822c\u4e0d\u8fde\u7eed\u51fd\u6570\uff0c\u8fdb\u884c\u53d8\u91cf\u66ff\u6362\uff0c\u5e94\u7528\u83b1\u5e03\u5c3c\u8328\u79ef\u5206\u89c4\u5219\u3002", "result": "\u63d0\u51fa\u7684\u83b1\u5e03\u5c3c\u8328\u79ef\u5206\u6846\u67b6\u63a8\u5e7f\u4e86\u5e7f\u4e49\u4f3c\u7136\u6bd4\u65b9\u6cd5\uff0c\u80fd\u7ed9\u51fa\u4f55\u65f6\u66f2\u9762\u79ef\u5206\u6d88\u5931\u7684\u76f4\u89c2\u89e3\u91ca\uff0c\u5b9e\u73b0\u5355\u8fd0\u884c\u3001\u6613\u5b9e\u73b0\u7684\u4f30\u8ba1\u5668\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01127", "pdf": "https://arxiv.org/pdf/2511.01127", "abs": "https://arxiv.org/abs/2511.01127", "authors": ["Fabio Diniz Rossi"], "title": "Neuro-Inspired Task Offloading in Edge-IoT Networks Using Spiking Neural Networks", "categories": ["cs.DC"], "comment": "5 pages, 2 figures, 1 table", "summary": "Traditional task offloading strategies in edge computing often rely on static\nheuristics or data-intensive machine learning models, which are not always\nsuitable for highly dynamic and resource-constrained environments. In this\npaper, we propose a novel task-offloading framework based on Spiking Neural\nNetworks inspired by the efficiency and adaptability of biological neural\nsystems. Our approach integrates an SNN-based decision module into edge nodes\nto perform real-time, energy-efficient task orchestration. We evaluate the\nmodel under various IoT workload scenarios using a hybrid simulation\nenvironment composed of YAFS and Brian2. The results demonstrate that our\nSNN-based framework significantly reduces task processing latency and energy\nconsumption while improving task success rates. Compared to traditional\nheuristic and ML-based strategies, our model achieves up to 26% lower latency,\n32% less energy consumption, and 25\\% higher success rate under high-load\nconditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u4efb\u52a1\u5378\u8f7d\u6846\u67b6\uff0c\u80fd\u5b9e\u65f6\u3001\u8282\u80fd\u5730\u7f16\u6392\u4efb\u52a1\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u8fb9\u7f18\u8ba1\u7b97\u4efb\u52a1\u5378\u8f7d\u7b56\u7565\u4e0d\u9002\u7528\u4e8e\u9ad8\u52a8\u6001\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u4efb\u52a1\u5378\u8f7d\u6846\u67b6\uff0c\u5c06\u57fa\u4e8eSNN\u7684\u51b3\u7b56\u6a21\u5757\u96c6\u6210\u5230\u8fb9\u7f18\u8282\u70b9\uff0c\u5e76\u4f7f\u7528YAFS\u548cBrian2\u7684\u6df7\u5408\u4eff\u771f\u73af\u5883\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u4efb\u52a1\u5904\u7406\u5ef6\u8fdf\u548c\u80fd\u8017\uff0c\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5728\u9ad8\u8d1f\u8f7d\u6761\u4ef6\u4e0b\uff0c\u76f8\u6bd4\u4f20\u7edf\u7b56\u7565\uff0c\u5ef6\u8fdf\u6700\u591a\u964d\u4f4e26%\uff0c\u80fd\u8017\u6700\u591a\u964d\u4f4e32%\uff0c\u6210\u529f\u7387\u6700\u591a\u63d0\u9ad825%\u3002", "conclusion": "\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u4efb\u52a1\u5378\u8f7d\u6846\u67b6\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8ba1\u7b97\u3002"}}
{"id": "2511.00530", "pdf": "https://arxiv.org/pdf/2511.00530", "abs": "https://arxiv.org/abs/2511.00530", "authors": ["Hongtao Huang", "Chengkai Huang", "Junda Wu", "Tong Yu", "Julian McAuley", "Lina Yao"], "title": "Listwise Preference Diffusion Optimization for User Behavior Trajectories Prediction", "categories": ["cs.IR"], "comment": null, "summary": "Forecasting multi-step user behavior trajectories requires reasoning over\nstructured preferences across future actions, a challenge overlooked by\ntraditional sequential recommendation. This problem is critical for\napplications such as personalized commerce and adaptive content delivery, where\nanticipating a user's complete action sequence enhances both satisfaction and\nbusiness outcomes. We identify an essential limitation of existing paradigms:\ntheir inability to capture global, listwise dependencies among sequence items.\nTo address this, we formulate User Behavior Trajectory Prediction (UBTP) as a\nnew task setting that explicitly models long-term user preferences. We\nintroduce Listwise Preference Diffusion Optimization (LPDO), a diffusion-based\ntraining framework that directly optimizes structured preferences over entire\nitem sequences. LPDO incorporates a Plackett-Luce supervision signal and\nderives a tight variational lower bound aligned with listwise ranking\nlikelihoods, enabling coherent preference generation across denoising steps and\novercoming the independent-token assumption of prior diffusion methods. To\nrigorously evaluate multi-step prediction quality, we propose the task-specific\nmetric Sequential Match (SeqMatch), which measures exact trajectory agreement,\nand adopt Perplexity (PPL), which assesses probabilistic fidelity. Extensive\nexperiments on real-world user behavior benchmarks demonstrate that LPDO\nconsistently outperforms state-of-the-art baselines, establishing a new\nbenchmark for structured preference learning with diffusion models.", "AI": {"tldr": "\u63d0\u51fa\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u9884\u6d4b\u65b0\u4efb\u52a1\uff0c\u5f15\u5165LPDO\u8bad\u7ec3\u6846\u67b6\uff0c\u63d0\u51faSeqMatch\u6307\u6807\uff0c\u5b9e\u9a8c\u663e\u793aLPDO\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u987a\u5e8f\u63a8\u8350\u65e0\u6cd5\u89e3\u51b3\u591a\u6b65\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u9884\u6d4b\u4e2d\u6355\u6349\u5e8f\u5217\u9879\u5168\u5c40\u4f9d\u8d56\u7684\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5bf9\u4e2a\u6027\u5316\u5546\u52a1\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5c06\u7528\u6237\u884c\u4e3a\u8f68\u8ff9\u9884\u6d4b\u5b9a\u4e49\u4e3a\u65b0\u4efb\u52a1\uff0c\u5f15\u5165\u57fa\u4e8e\u6269\u6563\u7684LPDO\u8bad\u7ec3\u6846\u67b6\uff0c\u63d0\u51faSeqMatch\u6307\u6807\u5e76\u91c7\u7528PPL\u6307\u6807\u3002", "result": "\u5728\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLPDO\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "LPDO\u4e3a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u7ed3\u6784\u5316\u504f\u597d\u5b66\u4e60\u5efa\u7acb\u4e86\u65b0\u57fa\u51c6\u3002"}}
{"id": "2511.00869", "pdf": "https://arxiv.org/pdf/2511.00869", "abs": "https://arxiv.org/abs/2511.00869", "authors": ["Hue T. Nguyen", "Tan D. Tran", "Nguyen Long Giang", "Canh V. Pham"], "title": "Fast Stochastic Greedy Algorithm for $k$-Submodular Cover Problem", "categories": ["cs.DS", "cs.AI"], "comment": null, "summary": "We study the $k$-Submodular Cover ($kSC$) problem, a natural generalization\nof the classical Submodular Cover problem that arises in artificial\nintelligence and combinatorial optimization tasks such as influence\nmaximization, resource allocation, and sensor placement. Existing algorithms\nfor $\\kSC$ often provide weak approximation guarantees or incur prohibitively\nhigh query complexity. To overcome these limitations, we propose a \\textit{Fast\nStochastic Greedy} algorithm that achieves strong bicriteria approximation\nwhile substantially lowering query complexity compared to state-of-the-art\nmethods. Our approach dramatically reduces the number of function evaluations,\nmaking it highly scalable and practical for large-scale real-world AI\napplications where efficiency is essential.", "AI": {"tldr": "\u7814\u7a76k - \u5b50\u6a21\u8986\u76d6\u95ee\u9898\uff0c\u63d0\u51faFast Stochastic Greedy\u7b97\u6cd5\uff0c\u964d\u4f4e\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21AI\u5e94\u7528\u3002", "motivation": "\u73b0\u6709k - \u5b50\u6a21\u8986\u76d6\u95ee\u9898\u7b97\u6cd5\u8fd1\u4f3c\u4fdd\u8bc1\u5f31\u6216\u67e5\u8be2\u590d\u6742\u5ea6\u9ad8\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u63d0\u51faFast Stochastic Greedy\u7b97\u6cd5\u3002", "result": "\u8be5\u7b97\u6cd5\u5b9e\u73b0\u5f3a\u53cc\u51c6\u5219\u8fd1\u4f3c\uff0c\u5927\u5e45\u964d\u4f4e\u67e5\u8be2\u590d\u6742\u5ea6\u3002", "conclusion": "\u7b97\u6cd5\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\uff0c\u5177\u6709\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u5bf9\u6548\u7387\u8981\u6c42\u9ad8\u7684\u5927\u89c4\u6a21AI\u5e94\u7528\u3002"}}
{"id": "2511.00122", "pdf": "https://arxiv.org/pdf/2511.00122", "abs": "https://arxiv.org/abs/2511.00122", "authors": ["Ran Xu", "Yupeng Qi", "Jingsen Feng", "Xu Chu"], "title": "Engineering.ai: A Platform for Teams of AI Engineers in Computational Design", "categories": ["cs.AI"], "comment": null, "summary": "In modern engineering practice, human engineers collaborate in specialized\nteams to design complex products, with each expert completing their respective\ntasks while communicating and exchanging results and data with one another.\nWhile this division of expertise is essential for managing multidisciplinary\ncomplexity, it demands substantial development time and cost. Recently, we\nintroduced OpenFOAMGPT (1.0, 2.0), which functions as an autonomous AI engineer\nfor computational fluid dynamics, and turbulence.ai, which can conduct\nend-to-end research in fluid mechanics draft publications and PhD theses.\nBuilding upon these foundations, we present Engineering.ai, a platform for\nteams of AI engineers in computational design. The framework employs a\nhierarchical multi-agent architecture where a Chief Engineer coordinates\nspecialized agents consisting of Aerodynamics, Structural, Acoustic, and\nOptimization Engineers, each powered by LLM with domain-specific knowledge.\nAgent-agent collaboration is achieved through file-mediated communication for\ndata provenance and reproducibility, while a comprehensive memory system\nmaintains project context, execution history, and retrieval-augmented domain\nknowledge to ensure reliable decision-making across the workflow. The system\nintegrates FreeCAD, Gmsh, OpenFOAM, CalculiX, and BPM acoustic analysis,\nenabling parallel multidisciplinary simulations while maintaining computational\naccuracy. The framework is validated through UAV wing optimization. This work\ndemonstrates that agentic-AI-enabled AI engineers has the potential to perform\ncomplex engineering tasks autonomously. Remarkably, the automated workflow\nachieved a 100% success rate across over 400 parametric configurations, with\nzero mesh generation failures, solver convergence issues, or manual\ninterventions required, validating that the framework is trustworthy.", "AI": {"tldr": "\u4ecb\u7ecdEngineering.ai\u5e73\u53f0\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\u5b9e\u73b0AI\u5de5\u7a0b\u5e08\u56e2\u961f\u534f\u4f5c\uff0c\u7ecf\u65e0\u4eba\u673a\u673a\u7ffc\u4f18\u5316\u9a8c\u8bc1\u53ef\u81ea\u4e3b\u5b8c\u6210\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\uff0c\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u6210\u529f\u7387\u8fbe100%\u3002", "motivation": "\u73b0\u4ee3\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u4e13\u5bb6\u5206\u5de5\u534f\u4f5c\u5f00\u53d1\u65f6\u95f4\u548c\u6210\u672c\u9ad8\uff0c\u9700\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5206\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u9996\u5e2d\u5de5\u7a0b\u5e08\u534f\u8c03\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6587\u4ef6\u4ecb\u5bfc\u901a\u4fe1\u5b9e\u73b0\u534f\u4f5c\uff0c\u96c6\u6210\u591a\u79cd\u5de5\u5177\u8fdb\u884c\u5e76\u884c\u591a\u5b66\u79d1\u6a21\u62df\u3002", "result": "\u6846\u67b6\u7ecf\u65e0\u4eba\u673a\u673a\u7ffc\u4f18\u5316\u9a8c\u8bc1\uff0c\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u5728\u8d85400\u4e2a\u53c2\u6570\u914d\u7f6e\u4e2d\u6210\u529f\u7387\u8fbe100%\uff0c\u65e0\u7f51\u683c\u751f\u6210\u5931\u8d25\u7b49\u95ee\u9898\u3002", "conclusion": "\u5177\u6709\u667a\u80fd\u4f53\u80fd\u529b\u7684AI\u5de5\u7a0b\u5e08\u6709\u6f5c\u529b\u81ea\u4e3b\u5b8c\u6210\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\uff0c\u6846\u67b6\u503c\u5f97\u4fe1\u8d56\u3002"}}
{"id": "2511.01125", "pdf": "https://arxiv.org/pdf/2511.01125", "abs": "https://arxiv.org/abs/2511.01125", "authors": ["Takashi Furuya", "Anastasis Kratsios", "Dylan Possama\u00ef", "Bogdan Raoni\u0107"], "title": "One model to solve them all: 2BSDE families via neural operators", "categories": ["cs.LG", "cs.NA", "math.AP", "math.NA", "math.PR", "q-fin.CP"], "comment": null, "summary": "We introduce a mild generative variant of the classical neural operator\nmodel, which leverages Kolmogorov--Arnold networks to solve infinite families\nof second-order backward stochastic differential equations ($2$BSDEs) on\nregular bounded Euclidean domains with random terminal time. Our first main\nresult shows that the solution operator associated with a broad range of\n$2$BSDE families is approximable by appropriate neural operator models. We then\nidentify a structured subclass of (infinite) families of $2$BSDEs whose neural\noperator approximation requires only a polynomial number of parameters in the\nreciprocal approximation rate, as opposed to the exponential requirement in\ngeneral worst-case neural operator guarantees.", "AI": {"tldr": "\u63d0\u51fa\u7ecf\u5178\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u7684\u6e29\u548c\u751f\u6210\u53d8\u4f53\uff0c\u7528\u4e8e\u89e3\u51b3\u7279\u5b9a\u4e8c\u9636\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff0c\u8bc1\u660e\u89e3\u7b97\u5b50\u53ef\u8fd1\u4f3c\uff0c\u627e\u5230\u53ea\u9700\u591a\u9879\u5f0f\u53c2\u6570\u7684\u65b9\u7a0b\u5b50\u7c7b\u3002", "motivation": "\u89e3\u51b3\u65e0\u9650\u65cf\u4e8c\u9636\u5012\u5411\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08$2$BSDEs\uff09\u5728\u6709\u968f\u673a\u7ec8\u7aef\u65f6\u95f4\u7684\u6709\u754c\u6b27\u51e0\u91cc\u5f97\u57df\u4e0a\u7684\u6c42\u89e3\u95ee\u9898\u3002", "method": "\u5f15\u5165\u7ecf\u5178\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u7684\u6e29\u548c\u751f\u6210\u53d8\u4f53\uff0c\u5229\u7528\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b - \u963f\u8bfa\u5fb7\u7f51\u7edc\u3002", "result": "\u8868\u660e\u5e7f\u6cdb\u7684$2$BSDE\u65cf\u7684\u89e3\u7b97\u5b50\u53ef\u7531\u5408\u9002\u7684\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u8fd1\u4f3c\uff1b\u627e\u5230\u4e00\u7c7b$2$BSDEs\uff0c\u5176\u795e\u7ecf\u7b97\u5b50\u8fd1\u4f3c\u53ea\u9700\u591a\u9879\u5f0f\u6570\u91cf\u7684\u53c2\u6570\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u795e\u7ecf\u7b97\u5b50\u6a21\u578b\u5728\u89e3\u51b3$2$BSDEs\u95ee\u9898\u4e0a\u6709\u8f83\u597d\u7684\u8fd1\u4f3c\u6548\u679c\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u7279\u5b9a\u5b50\u7c7b\u53ef\u51cf\u5c11\u53c2\u6570\u9700\u6c42\u3002"}}
{"id": "2511.00197", "pdf": "https://arxiv.org/pdf/2511.00197", "abs": "https://arxiv.org/abs/2511.00197", "authors": ["Oorja Majgaonkar", "Zhiwei Fei", "Xiang Li", "Federica Sarro", "He Ye"], "title": "Understanding Code Agent Behaviour: An Empirical Study of Success and Failure Trajectories", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The increasing deployment of Large Language Model (LLM) agents for complex\nsoftware engineering tasks has created a need to understand their\nproblem-solving behaviours beyond simple success metrics. While these agents\ndemonstrate impressive capabilities in automated issue resolution, their\ndecision-making processes remain largely opaque. This paper presents an\nempirical study of agent trajectories, namely the execution traces capturing\nthe steps agents take when attempting to resolve software issues. We analyse\ntrajectories from three state-of-the-art code agents (OpenHands, SWE-agent, and\nPrometheus) on the SWE-Bench benchmark, examining both successful and failed\nattempts. Our investigation reveals several key insights into agent behaviour.\nFirst, we identify how distinct problem-solving strategies, such as defensive\nprogramming and context gathering, enable success in different scenarios.\nSecond, we find that failed trajectories are consistently longer and exhibit\nhigher variance than successful ones, with failure patterns differing\nsignificantly between agents. Third, our fault localisation analysis shows that\nwhile most trajectories correctly identify problematic files (72-81\\% even in\nfailures), success depends more on achieving approximate rather than exact code\nmodifications. These and other findings unveiled by our study, provide a\nfoundation for understanding agent behaviour through trajectory analysis,\ncontributing to the development of more robust and interpretable autonomous\nsoftware engineering systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u89e3\u51b3\u8f6f\u4ef6\u95ee\u9898\u7684\u8f68\u8ff9\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u4ee3\u7406\u884c\u4e3a\u5173\u952e\u89c1\u89e3\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u53ef\u89e3\u91ca\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u65f6\uff0c\u5176\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\uff0c\u9700\u7406\u89e3\u5176\u89e3\u51b3\u95ee\u9898\u7684\u884c\u4e3a\u3002", "method": "\u5bf9\u4e09\u4e2a\u5148\u8fdb\u4ee3\u7801\u4ee3\u7406\u5728SWE - Bench\u57fa\u51c6\u4e0a\u7684\u8f68\u8ff9\u8fdb\u884c\u5206\u6790\uff0c\u5305\u62ec\u6210\u529f\u548c\u5931\u8d25\u7684\u5c1d\u8bd5\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u89e3\u51b3\u7b56\u7565\u5728\u4e0d\u540c\u573a\u666f\u4fc3\u6210\u6210\u529f\uff1b\u5931\u8d25\u8f68\u8ff9\u66f4\u957f\u3001\u65b9\u5dee\u66f4\u5927\uff0c\u4e14\u4e0d\u540c\u4ee3\u7406\u5931\u8d25\u6a21\u5f0f\u4e0d\u540c\uff1b\u591a\u6570\u8f68\u8ff9\u80fd\u6b63\u786e\u8bc6\u522b\u95ee\u9898\u6587\u4ef6\uff0c\u6210\u529f\u66f4\u4f9d\u8d56\u8fd1\u4f3c\u4ee3\u7801\u4fee\u6539\u3002", "conclusion": "\u901a\u8fc7\u8f68\u8ff9\u5206\u6790\u7406\u89e3\u4ee3\u7406\u884c\u4e3a\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u3002"}}
{"id": "2511.00035", "pdf": "https://arxiv.org/pdf/2511.00035", "abs": "https://arxiv.org/abs/2511.00035", "authors": ["Georg Velev", "Stefan Lessmann"], "title": "Neural Architecture Search for global multi-step Forecasting of Energy Production Time Series", "categories": ["cs.LG"], "comment": null, "summary": "The dynamic energy sector requires both predictive accuracy and runtime\nefficiency for short-term forecasting of energy generation under operational\nconstraints, where timely and precise predictions are crucial. The manual\nconfiguration of complex methods, which can generate accurate global multi-step\npredictions without suffering from a computational bottleneck, represents a\nprocedure with significant time requirements and high risk for human-made\nerrors. A further intricacy arises from the temporal dynamics present in\nenergy-related data. Additionally, the generalization to unseen data is\nimperative for continuously deploying forecasting techniques over time. To\novercome these challenges, in this research, we design a neural architecture\nsearch (NAS)-based framework for the automated discovery of time series models\nthat strike a balance between computational efficiency, predictive performance,\nand generalization power for the global, multi-step short-term forecasting of\nenergy production time series. In particular, we introduce a search space\nconsisting only of efficient components, which can capture distinctive patterns\nof energy time series. Furthermore, we formulate a novel objective function\nthat accounts for performance generalization in temporal context and the\nmaximal exploration of different regions of our high-dimensional search space.\nThe results obtained on energy production time series show that an ensemble of\nlightweight architectures discovered with NAS outperforms state-of-the-art\ntechniques, such as Transformers, as well as pre-trained forecasting models, in\nterms of both efficiency and accuracy.", "AI": {"tldr": "\u8bbe\u8ba1\u57fa\u4e8eNAS\u7684\u6846\u67b6\u7528\u4e8e\u80fd\u6e90\u751f\u4ea7\u65f6\u95f4\u5e8f\u5217\u77ed\u671f\u9884\u6d4b\uff0c\u5e73\u8861\u6548\u7387\u3001\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u53d1\u73b0\u7684\u8f7b\u91cf\u7ea7\u67b6\u6784\u96c6\u6210\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u52a8\u6001\u80fd\u6e90\u9886\u57df\u77ed\u671f\u9884\u6d4b\u9700\u517c\u987e\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u624b\u52a8\u914d\u7f6e\u590d\u6742\u65b9\u6cd5\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u6570\u636e\u5b58\u5728\u65f6\u95f4\u52a8\u6001\u6027\uff0c\u9700\u8981\u6a21\u578b\u6709\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eNAS\u7684\u6846\u67b6\uff0c\u5f15\u5165\u4ec5\u542b\u9ad8\u6548\u7ec4\u4ef6\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u5236\u5b9a\u8003\u8651\u6027\u80fd\u6cdb\u5316\u548c\u641c\u7d22\u7a7a\u95f4\u63a2\u7d22\u7684\u76ee\u6807\u51fd\u6570\u3002", "result": "\u5728\u80fd\u6e90\u751f\u4ea7\u65f6\u95f4\u5e8f\u5217\u4e0a\uff0cNAS\u53d1\u73b0\u7684\u8f7b\u91cf\u7ea7\u67b6\u6784\u96c6\u6210\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u4f18\u4e8eTransformer\u7b49\u73b0\u6709\u6280\u672f\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "\u57fa\u4e8eNAS\u7684\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u80fd\u6e90\u77ed\u671f\u9884\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u6548\u7387\u3001\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u7684\u5e73\u8861\u3002"}}
{"id": "2511.01298", "pdf": "https://arxiv.org/pdf/2511.01298", "abs": "https://arxiv.org/abs/2511.01298", "authors": ["Aman Mittal", "Kasturi Venkata Sai Srikanth", "Ferdin Sagai Don Bosco", "Abhishek Singh", "Rut Lineswala", "Abhishek Chopra"], "title": "Investigation of Performance and Scalability of a Quantum-Inspired Evolutionary Optimizer (QIEO) on NVIDIA GPU", "categories": ["cs.CE"], "comment": "Accepted for presentation at Super Computing India 2025 (SCI2025)", "summary": "Quantum inspired evolutionary optimization leverages quantum computing\nprinciples like superposition, interference, and probabilistic representation\nto enhance classical evolutionary algorithms with improved exploration and\nexploitation capabilities. Implemented on NVIDIA Tesla V100 SXM2 GPUs, this\nstudy systematically investigates the performance and scalability of a\nGPU-accelerated Quantum Inspired Evolutionary Optimizer applied to large scale\n01 Knapsack problems. By exploiting CUDA`s parallel processing capabilities,\nparticularly through optimized memory management and thread configuration,\nsignificant speedups and efficient utilization of GPU resources is\ndemonstrated. The analysis covers various problem sizes, kernel launch\nconfigurations, and memory models including constant, shared, global, and\npinned memory, alongside extensive scaling studies. The results reveal that\ncareful tuning of memory strategies and kernel configurations is essential for\nmaximizing throughput and efficiency, with constant memory providing superior\nperformance up to hardware limits. Beyond these limits, global memory and\nstrategic tiling become necessary, albeit with some performance trade offs. The\nfindings highlight both the promise and the practical constraints of applying\nQIEO on GPUs for complex combinatorial optimization, offering actionable\ninsights for future large scale metaheuristic implementations.", "AI": {"tldr": "\u7814\u7a76GPU\u52a0\u901f\u7684\u91cf\u5b50\u542f\u53d1\u5f0f\u8fdb\u5316\u4f18\u5316\u5668\u5728\u5927\u89c4\u6a2101\u80cc\u5305\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u53d1\u73b0\u8c03\u4f18\u5185\u5b58\u7b56\u7565\u548c\u5185\u6838\u914d\u7f6e\u5f88\u91cd\u8981\u3002", "motivation": "\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u539f\u7406\u589e\u5f3a\u7ecf\u5178\u8fdb\u5316\u7b97\u6cd5\uff0c\u7814\u7a76GPU\u52a0\u901f\u7684\u91cf\u5b50\u542f\u53d1\u5f0f\u8fdb\u5316\u4f18\u5316\u5668\u5728\u5927\u89c4\u6a2101\u80cc\u5305\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5728NVIDIA Tesla V100 SXM2 GPUs\u4e0a\u5b9e\u73b0\uff0c\u5229\u7528CUDA\u5e76\u884c\u5904\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u7ba1\u7406\u548c\u7ebf\u7a0b\u914d\u7f6e\uff0c\u5206\u6790\u4e0d\u540c\u95ee\u9898\u89c4\u6a21\u3001\u5185\u6838\u542f\u52a8\u914d\u7f6e\u548c\u5185\u5b58\u6a21\u578b\u3002", "result": "\u4ed4\u7ec6\u8c03\u4f18\u5185\u5b58\u7b56\u7565\u548c\u5185\u6838\u914d\u7f6e\u5bf9\u6700\u5927\u5316\u541e\u5410\u91cf\u548c\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u5e38\u91cf\u5185\u5b58\u6027\u80fd\u5728\u786c\u4ef6\u9650\u5236\u5185\u66f4\u4f18\uff0c\u8d85\u51fa\u9650\u5236\u9700\u7528\u5168\u5c40\u5185\u5b58\u548c\u7b56\u7565\u5206\u5757\uff0c\u6709\u4e00\u5b9a\u6027\u80fd\u6298\u635f\u3002", "conclusion": "\u6307\u51fa\u5728GPU\u4e0a\u5e94\u7528QIEO\u89e3\u51b3\u590d\u6742\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u6709\u524d\u666f\u4e5f\u6709\u5b9e\u9645\u9650\u5236\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u5143\u542f\u53d1\u5f0f\u5b9e\u73b0\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2511.00762", "pdf": "https://arxiv.org/pdf/2511.00762", "abs": "https://arxiv.org/abs/2511.00762", "authors": ["Leonardo Kanashiro Felizardo", "Edoardo Fadda", "Mari\u00e1 Cristina Vasconcelos Nascimento"], "title": "Automatic Policy Search using Population-Based Hyper-heuristics for the Integrated Procurement and Perishable Inventory Problem", "categories": ["cs.NE", "math.OC"], "comment": "19 pages, 1 figure, 3 tables", "summary": "This paper addresses the problem of managing perishable inventory under\nmultiple sources of uncertainty, including stochastic demand, unreliable\nsupplier fulfillment, and probabilistic product shelf life. We develop a\ndiscrete-event simulation environment to compare two optimization strategies\nfor this multi-item, multi-supplier problem. The first strategy optimizes\nuniform classic policies (e.g., Constant Order and Base Stock) by tuning their\nparameters globally, complemented by a direct search to select the best-fitting\nsuppliers for the integrated problem. The second approach is a hyper-heuristic\napproach, driven by metaheuristics such as a Genetic Algorithm (GA) and\nParticle Swarm Optimization (PSO). This framework constructs a composite policy\nby automating the selection of the heuristic type, its parameters, and the\nsourcing suppliers on an item-by-item basis. Computational results from twelve\ndistinct instances demonstrate that the hyper-heuristic framework consistently\nidentifies superior policies, with GA and EGA exhibiting the best overall\nperformance. Our primary contribution is verifying that this item-level policy\nconstruction yields significant performance gains over simpler global policies,\nthereby justifying the associated computational cost.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u6613\u8150\u5e93\u5b58\u7ba1\u7406\u95ee\u9898\uff0c\u5bf9\u6bd4\u4e24\u79cd\u4f18\u5316\u7b56\u7565\uff0c\u8d85\u542f\u53d1\u5f0f\u6846\u67b6\u8868\u73b0\u66f4\u4f18\uff0c\u9a8c\u8bc1\u6309\u9879\u6784\u5efa\u7b56\u7565\u6709\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u89e3\u51b3\u968f\u673a\u9700\u6c42\u3001\u4f9b\u5e94\u5546\u4ea4\u4ed8\u4e0d\u53ef\u9760\u548c\u4ea7\u54c1\u4fdd\u8d28\u671f\u4e0d\u786e\u5b9a\u7b49\u591a\u6e90\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u6613\u8150\u5e93\u5b58\u7ba1\u7406\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\u73af\u5883\uff0c\u5bf9\u6bd4\u4e24\u79cd\u7b56\u7565\uff0c\u4e00\u662f\u5168\u5c40\u8c03\u6574\u7ecf\u5178\u7b56\u7565\u53c2\u6570\u5e76\u9009\u62e9\u4f9b\u5e94\u5546\uff0c\u4e8c\u662f\u57fa\u4e8e\u5143\u542f\u53d1\u5f0f\u7684\u8d85\u542f\u53d1\u5f0f\u65b9\u6cd5\u6309\u9879\u6784\u5efa\u590d\u5408\u7b56\u7565\u3002", "result": "12\u4e2a\u5b9e\u4f8b\u8ba1\u7b97\u7ed3\u679c\u8868\u660e\u8d85\u542f\u53d1\u5f0f\u6846\u67b6\u80fd\u6301\u7eed\u627e\u5230\u66f4\u4f18\u7b56\u7565\uff0cGA\u548cEGA\u6574\u4f53\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u6309\u9879\u6784\u5efa\u7b56\u7565\u6bd4\u7b80\u5355\u5168\u5c40\u7b56\u7565\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u8ba1\u7b97\u6210\u672c\u5408\u7406\u3002"}}
{"id": "2511.00772", "pdf": "https://arxiv.org/pdf/2511.00772", "abs": "https://arxiv.org/abs/2511.00772", "authors": ["Raymond M. Xiong", "Panyu Chen", "Tianze Dong", "Jian Lu", "Benjamin Goldstein", "Danyang Zhuo", "Anru R. Zhang"], "title": "Reliable Curation of EHR Dataset via Large Language Models under Environmental Constraints", "categories": ["cs.DB", "cs.LG", "stat.AP"], "comment": null, "summary": "Electronic health records (EHRs) are central to modern healthcare delivery\nand research; yet, many researchers lack the database expertise necessary to\nwrite complex SQL queries or generate effective visualizations, limiting\nefficient data use and scientific discovery. To address this barrier, we\nintroduce CELEC, a large language model (LLM)-powered framework for automated\nEHR data extraction and analytics. CELEC translates natural language queries\ninto SQL using a prompting strategy that integrates schema information,\nfew-shot demonstrations, and chain-of-thought reasoning, which together improve\naccuracy and robustness. On a subset of the EHRSQL benchmark, CELEC achieves\nexecution accuracy comparable to prior systems while maintaining low latency,\ncost efficiency, and strict privacy by exposing only database metadata to the\nLLM. CELEC also adheres to strict privacy protocols: the LLM accesses only\ndatabase metadata (e.g., table and column names), while all query execution\noccurs securely within the institutional environment, ensuring that no\npatient-level data is ever transmitted to or shared with the LLM. Ablation\nstudies confirm that each component of the SQL generation pipeline,\nparticularly the few-shot demonstrations, plays a critical role in performance.\nBy lowering technical barriers and enabling medical researchers to query EHR\ndatabases directly, CELEC streamlines research workflows and accelerates\nbiomedical discovery.", "AI": {"tldr": "\u4ecb\u7ecdCELEC\u6846\u67b6\u7528\u4e8e\u81ea\u52a8\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\u63d0\u53d6\u548c\u5206\u6790\uff0c\u80fd\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\uff0c\u6027\u80fd\u597d\u4e14\u6709\u9690\u79c1\u4fdd\u969c\uff0c\u53ef\u52a0\u901f\u751f\u7269\u533b\u5b66\u53d1\u73b0\u3002", "motivation": "\u8bb8\u591a\u7814\u7a76\u4eba\u5458\u7f3a\u4e4f\u6570\u636e\u5e93\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9650\u5236\u4e86EHR\u6570\u636e\u7684\u6709\u6548\u4f7f\u7528\u548c\u79d1\u5b66\u53d1\u73b0\uff0c\u9700\u89e3\u51b3\u8fd9\u4e00\u969c\u788d\u3002", "method": "\u4f7f\u7528\u96c6\u6210\u6a21\u5f0f\u4fe1\u606f\u3001\u5c11\u6837\u672c\u6f14\u793a\u548c\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u63d0\u793a\u7b56\u7565\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u6362\u4e3aSQL\u3002", "result": "\u5728EHRSQL\u57fa\u51c6\u7684\u5b50\u96c6\u4e0a\uff0c\u6267\u884c\u51c6\u786e\u7387\u4e0e\u73b0\u6709\u7cfb\u7edf\u76f8\u5f53\uff0c\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u3001\u6210\u672c\u6548\u76ca\u548c\u4e25\u683c\u9690\u79c1\u3002\u6d88\u878d\u7814\u7a76\u8868\u660eSQL\u751f\u6210\u7ba1\u9053\u5404\u7ec4\u4ef6\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "CELEC\u964d\u4f4e\u6280\u672f\u58c1\u5792\uff0c\u7b80\u5316\u7814\u7a76\u5de5\u4f5c\u6d41\u7a0b\uff0c\u52a0\u901f\u751f\u7269\u533b\u5b66\u53d1\u73b0\u3002"}}
{"id": "2511.01421", "pdf": "https://arxiv.org/pdf/2511.01421", "abs": "https://arxiv.org/abs/2511.01421", "authors": ["Yusuf Saltan", "Jyun-Jhe Wang", "Arda Kosay", "Chung-Wei Lin", "Muhammed O. Sayin"], "title": "Designing Non-monetary Intersection Control Mechanisms for Efficient Selfish Routing", "categories": ["cs.GT", "cs.MA"], "comment": null, "summary": "Urban traffic congestion stems from the misalignment between self-interested\nrouting decisions and socially optimal flows. Intersections, as critical\nbottlenecks, amplify these inefficiencies because existing control schemes\noften neglect drivers' strategic behavior. Autonomous intersections, enabled by\nvehicle-to-infrastructure communication, permit vehicle-level scheduling based\non individual requests. Leveraging this fine-grained control, we propose a\nnon-monetary mechanism that strategically adjusts request timestamps-delaying\nor advancing passage times-to incentivize socially efficient routing. We\npresent a hierarchical architecture separating local scheduling by roadside\nunits from network-wide timestamp adjustments by a central planner. We\nestablish an experimentally validated analytical model, prove the existence and\nessential uniqueness of equilibrium flows and formulate the planner's problem\nas an offline bilevel optimization program solvable with standard tools.\nExperiments on the Sioux Falls network show up to a 68% reduction in the\nefficiency gap between equilibrium and optimal flows, demonstrating scalability\nand effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u975e\u8d27\u5e01\u673a\u5236\u8c03\u6574\u8bf7\u6c42\u65f6\u95f4\u6233\u4ee5\u6fc0\u52b1\u57ce\u5e02\u4ea4\u901a\u9ad8\u6548\u8def\u7531\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u51cf\u5c11\u6548\u7387\u5dee\u8ddd\u3002", "motivation": "\u57ce\u5e02\u4ea4\u901a\u62e5\u5835\u6e90\u4e8e\u4e2a\u4f53\u8def\u7531\u51b3\u7b56\u4e0e\u793e\u4f1a\u6700\u4f18\u6d41\u91cf\u4e0d\u4e00\u81f4\uff0c\u73b0\u6709\u4ea4\u53c9\u8def\u53e3\u63a7\u5236\u65b9\u6848\u5ffd\u89c6\u53f8\u673a\u7b56\u7565\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u975e\u8d27\u5e01\u673a\u5236\u8c03\u6574\u8bf7\u6c42\u65f6\u95f4\u6233\uff0c\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u5efa\u7acb\u5206\u6790\u6a21\u578b\uff0c\u5c06\u89c4\u5212\u8005\u95ee\u9898\u8868\u8ff0\u4e3a\u79bb\u7ebf\u53cc\u5c42\u4f18\u5316\u7a0b\u5e8f\u3002", "result": "\u5728Sioux Falls\u7f51\u7edc\u5b9e\u9a8c\u4e2d\uff0c\u5e73\u8861\u6d41\u4e0e\u6700\u4f18\u6d41\u7684\u6548\u7387\u5dee\u8ddd\u6700\u591a\u51cf\u5c1168%\u3002", "conclusion": "\u8be5\u673a\u5236\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.00849", "pdf": "https://arxiv.org/pdf/2511.00849", "abs": "https://arxiv.org/abs/2511.00849", "authors": ["Zhexiao Huang", "Weihao He", "Shutao Deng", "Junzhe Chen", "Chao Yuan", "Hongxin Wang", "Changsheng Zhou"], "title": "Perturbations in the Orthogonal Complement Subspace for Efficient Out-of-Distribution Detection", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) detection is essential for deploying deep learning\nmodels in open-world environments. Existing approaches, such as energy-based\nscoring and gradient-projection methods, typically rely on high-dimensional\nrepresentations to separate in-distribution (ID) and OOD samples. We introduce\nP-OCS (Perturbations in the Orthogonal Complement Subspace), a lightweight and\ntheoretically grounded method that operates in the orthogonal complement of the\nprincipal subspace defined by ID features. P-OCS applies a single projected\nperturbation restricted to this complementary subspace, enhancing subtle ID-OOD\ndistinctions while preserving the geometry of ID representations. We show that\na one-step update is sufficient in the small-perturbation regime and provide\nconvergence guarantees for the resulting detection score. Experiments across\nmultiple architectures and datasets demonstrate that P-OCS achieves\nstate-of-the-art OOD detection with negligible computational cost and without\nrequiring model retraining, access to OOD data, or changes to model\narchitecture.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u8f7b\u91cf\u7ea7\u4e14\u6709\u7406\u8bba\u4f9d\u636e\u7684OOD\u68c0\u6d4b\u65b9\u6cd5P - OCS\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u4ee5\u6781\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u6700\u5148\u8fdb\u7684OOD\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709OOD\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u9ad8\u7ef4\u8868\u793a\u5206\u79bb\u6837\u672c\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faP - OCS\u65b9\u6cd5\uff0c\u5728ID\u7279\u5f81\u4e3b\u7a7a\u95f4\u7684\u6b63\u4ea4\u8865\u7a7a\u95f4\u5e94\u7528\u5355\u4e2a\u6295\u5f71\u6270\u52a8\uff0c\u589e\u5f3aID - OOD\u7ec6\u5fae\u533a\u522b\u3002", "result": "\u5728\u591a\u67b6\u6784\u548c\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cP - OCS\u4ee5\u6781\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u6700\u5148\u8fdb\u7684OOD\u68c0\u6d4b\uff0c\u65e0\u9700\u6a21\u578b\u518d\u8bad\u7ec3\u3001\u8bbf\u95eeOOD\u6570\u636e\u6216\u66f4\u6539\u6a21\u578b\u67b6\u6784\u3002", "conclusion": "P - OCS\u662f\u4e00\u79cd\u9ad8\u6548\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5177\u6709\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2511.00935", "pdf": "https://arxiv.org/pdf/2511.00935", "abs": "https://arxiv.org/abs/2511.00935", "authors": ["Akhil Rao"], "title": "Public Infrastructure Investments for Space Market Development", "categories": ["econ.GN", "q-fin.EC"], "comment": "Working paper version", "summary": "Advanced space technology systems often face high fixed costs, can serve\nlimited non-government demand, and are significantly driven by non-market\nmotivations. While increased entrepreneurial activity and national ambitions in\nspace have encouraged planners at public space agencies to develop markets\naround such systems, the very factors that make the recent growth of the space\neconomy so remarkable also challenge planners' efforts to develop and sustain\nmarkets for space-related goods and services. I propose a graphical framework\nto visualize the number of competitors a market can sustain as a function of\nthe industry's cost structure; the distribution of government support across\ndirect purchases, direct investments, and shared infrastructure; and the\nmagnitude of non-government demand. Building on public goods theory, the\nframework shows how marginal dollars invested in shared infrastructure can\ncreate non-rival benefits supporting more competitors per dollar than direct\npurchases or subsidies. I demonstrate the framework with a stylized application\ninspired by NASA's Commercial LEO Destinations program. Under cost and demand\nconditions consistent with public data, independent stations generate\nindustry-wide losses of $355 million annually, while shared core infrastructure\nenables industry-wide profits of $154 million annually. I also outline key\ndirections for future research on public investment and market development\nstrategies for advanced technologies.", "AI": {"tldr": "\u63d0\u51fa\u56fe\u5f62\u6846\u67b6\u5206\u6790\u592a\u7a7a\u5e02\u573a\uff0c\u4ee5NASA\u9879\u76ee\u4e3a\u4f8b\u8bf4\u660e\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u53ef\u5e26\u6765\u884c\u4e1a\u5229\u6da6\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u592a\u7a7a\u6280\u672f\u7cfb\u7edf\u6709\u9ad8\u6210\u672c\u3001\u9700\u6c42\u6709\u9650\u7b49\u7279\u70b9\uff0c\u516c\u5171\u822a\u5929\u673a\u6784\u53d1\u5c55\u5e02\u573a\u9762\u4e34\u6311\u6218\uff0c\u9700\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u56fe\u5f62\u6846\u67b6\uff0c\u7ed3\u5408\u516c\u5171\u4ea7\u54c1\u7406\u8bba\uff0c\u4ee5NASA\u5546\u4e1a\u8fd1\u5730\u8f68\u9053\u76ee\u7684\u5730\u8ba1\u5212\u4e3a\u4f8b\u5e94\u7528\u6846\u67b6\u3002", "result": "\u5728\u6210\u672c\u548c\u9700\u6c42\u6761\u4ef6\u4e0b\uff0c\u72ec\u7acb\u7a7a\u95f4\u7ad9\u5e74\u4e8f\u635f3.55\u4ebf\u7f8e\u5143\uff0c\u5171\u4eab\u6838\u5fc3\u57fa\u7840\u8bbe\u65bd\u5e74\u76c8\u52291.54\u4ebf\u7f8e\u5143\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u8fd8\u7ed9\u51fa\u516c\u5171\u6295\u8d44\u548c\u5e02\u573a\u53d1\u5c55\u7b56\u7565\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.01235", "pdf": "https://arxiv.org/pdf/2511.01235", "abs": "https://arxiv.org/abs/2511.01235", "authors": ["Shruthi Kannappan", "Ashwina Kumar", "Rupesh Nasre"], "title": "Scalable Maxflow Processing for Dynamic Graphs", "categories": ["cs.DC"], "comment": null, "summary": "The Maximum Flow (Max-Flow) problem is a cornerstone in graph theory and\ncombinatorial optimization, aiming to determine the largest possible flow from\na designated source node to a sink node within a capacitated flow network. It\nhas extensive applications across diverse domains such as computer networking,\ntransportation systems, and image segmentation. The objective is to maximize\nthe total throughput while respecting edge capacity constraints and maintaining\nflow conservation at all intermediate vertices.\n  Among the various algorithms proposed for solving the Max-Flow problem, the\nPush--Relabel algorithm is particularly notable for its efficiency and\nsuitability for parallelization, owing to its localized vertex-based\noperations. This property has motivated extensive research into GPU-accelerated\nMax-Flow computation, leveraging the high degree of parallelism inherent to\nmodern GPU architectures.\n  In this paper, we present a novel GPU-parallel Max-Flow algorithm capable of\nincrementally recomputing the maximum flow of a dynamic graph following a batch\nof edge updates. In addition, we introduce a high-performance static GPU\nalgorithm designed for efficiently computing the initial Max-Flow on static\ngraphs. We further describe a series of CUDA-specific implementation\noptimizations that enhance performance, scalability, and memory efficiency on\nGPU platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u52a8\u6001\u56fe\u7684\u589e\u91cf\u5f0fGPU\u5e76\u884c\u6700\u5927\u6d41\u7b97\u6cd5\u3001\u9759\u6001\u56fe\u7684\u9ad8\u6027\u80fdGPU\u7b97\u6cd5\uff0c\u5e76\u7ed9\u51faCUDA\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u6700\u5927\u6d41\u95ee\u9898\u5e94\u7528\u5e7f\u6cdb\uff0cPush - Relabel\u7b97\u6cd5\u9002\u5408\u5e76\u884c\u5316\uff0c\u56e0\u6b64\u7814\u7a76GPU\u52a0\u901f\u7684\u6700\u5927\u6d41\u8ba1\u7b97\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u56fe\u589e\u91cf\u5f0f\u91cd\u8ba1\u7b97\u6700\u5927\u6d41\u7684GPU\u5e76\u884c\u7b97\u6cd5\u3001\u9759\u6001\u56fe\u521d\u59cb\u6700\u5927\u6d41\u7684\u9ad8\u6027\u80fdGPU\u7b97\u6cd5\uff0c\u4ee5\u53ca\u4e00\u7cfb\u5217CUDA\u5b9e\u73b0\u4f18\u5316\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca", "conclusion": "\u65e0\u660e\u786e\u63d0\u53ca"}}
{"id": "2511.00584", "pdf": "https://arxiv.org/pdf/2511.00584", "abs": "https://arxiv.org/abs/2511.00584", "authors": ["Ke Shi", "Yan Zhang", "Miao Zhang", "Lifan Chen", "Jiali Yi", "Kui Xiao", "Xiaoju Hou", "Zhifei Li"], "title": "Structurally Refined Graph Transformer for Multimodal Recommendation", "categories": ["cs.IR", "cs.CL"], "comment": "Comment: 13 pages, 7 figures, accepted by IEEE Transactions on\n  Multimedia 2025", "summary": "Multimodal recommendation systems utilize various types of information,\nincluding images and text, to enhance the effectiveness of recommendations. The\nkey challenge is predicting user purchasing behavior from the available data.\nCurrent recommendation models prioritize extracting multimodal information\nwhile neglecting the distinction between redundant and valuable data. They also\nrely heavily on a single semantic framework (e.g., local or global semantics),\nresulting in an incomplete or biased representation of user preferences,\nparticularly those less expressed in prior interactions. Furthermore, these\napproaches fail to capture the complex interactions between users and items,\nlimiting the model's ability to meet diverse users. To address these\nchallenges, we present SRGFormer, a structurally optimized multimodal\nrecommendation model. By modifying the transformer for better integration into\nour model, we capture the overall behavior patterns of users. Then, we enhance\nstructural information by embedding multimodal information into a hypergraph\nstructure to aid in learning the local structures between users and items.\nMeanwhile, applying self-supervised tasks to user-item collaborative signals\nenhances the integration of multimodal information, thereby revealing the\nrepresentational features inherent to the data's modality. Extensive\nexperiments on three public datasets reveal that SRGFormer surpasses previous\nbenchmark models, achieving an average performance improvement of 4.47 percent\non the Sports dataset. The code is publicly available online.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSRGFormer\u6a21\u578b\u89e3\u51b3\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u6311\u6218\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u5148\u524d\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\u5728\u533a\u5206\u6570\u636e\u4ef7\u503c\u3001\u8bed\u4e49\u6846\u67b6\u4f7f\u7528\u548c\u6355\u6349\u7528\u6237\u4e0e\u7269\u54c1\u4ea4\u4e92\u65b9\u9762\u5b58\u5728\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u4fee\u6539transformer\u4ee5\u6355\u6349\u7528\u6237\u6574\u4f53\u884c\u4e3a\u6a21\u5f0f\uff0c\u5c06\u591a\u6a21\u6001\u4fe1\u606f\u5d4c\u5165\u8d85\u56fe\u7ed3\u6784\u589e\u5f3a\u5c40\u90e8\u7ed3\u6784\u5b66\u4e60\uff0c\u5bf9\u7528\u6237 - \u7269\u54c1\u534f\u4f5c\u4fe1\u53f7\u5e94\u7528\u81ea\u76d1\u7763\u4efb\u52a1\u589e\u5f3a\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cSRGFormer\u8d85\u8d8a\u5148\u524d\u57fa\u51c6\u6a21\u578b\uff0c\u5728Sports\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u6027\u80fd\u63d0\u53474.47%\u3002", "conclusion": "SRGFormer\u662f\u4e00\u4e2a\u6709\u6548\u7684\u591a\u6a21\u6001\u63a8\u8350\u6a21\u578b\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2511.01065", "pdf": "https://arxiv.org/pdf/2511.01065", "abs": "https://arxiv.org/abs/2511.01065", "authors": ["Kiarash Banihashem", "Jeff Giliberti", "Samira Goudarzi", "MohammadTaghi Hajiaghayi", "Peyman Jabbarzade", "Morteza Monemizadeh"], "title": "Dynamic Diameter in High-Dimensions against Adaptive Adversary and Beyond", "categories": ["cs.DS"], "comment": "NeurIPS'25", "summary": "In this paper, we study the fundamental problems of maintaining the diameter\nand a $k$-center clustering of a dynamic point set $P \\subset \\mathbb{R}^d$,\nwhere points may be inserted or deleted over time and the ambient dimension $d$\nis not constant and may be high. Our focus is on designing algorithms that\nremain effective even in the presence of an adaptive adversary -- an adversary\nthat, at any time $t$, knows the entire history of the algorithm's outputs as\nwell as all the random bits used by the algorithm up to that point. We present\na fully dynamic algorithm that maintains a $2$-approximate diameter with a\nworst-case update time of $\\text{poly}(d, \\log n)$, where $n$ is the length of\nthe stream. Our result is achieved by identifying a robust representative of\nthe dataset that requires infrequent updates, combined with a careful\ndeamortization. To the best of our knowledge, this is the first efficient\nfully-dynamic algorithm for diameter in high dimensions that simultaneously\nachieves a 2-approximation guarantee and robustness against an adaptive\nadversary. We also give an improved dynamic $(4+\\epsilon)$-approximation\nalgorithm for the $k$-center problem, also resilient to an adaptive adversary.\nOur clustering algorithm achieves an amortized update time of $k^{2.5} d \\cdot\n\\text{poly}(\\epsilon^{-1}, \\log n)$, improving upon the amortized update time\nof $k^6 d \\cdot \\text{poly}(\\epsilon^{-1}, \\log n)$ by Biabani et al.\n[NeurIPS'24].", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u52a8\u6001\u70b9\u96c6\u76f4\u5f84\u548ck - \u4e2d\u5fc3\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u7ef4\u62a42 - \u8fd1\u4f3c\u76f4\u5f84\u7684\u5168\u52a8\u6001\u7b97\u6cd5\u548c\u6539\u8fdb\u7684(4 + \u03b5) - \u8fd1\u4f3ck - \u4e2d\u5fc3\u7b97\u6cd5\uff0c\u4e14\u90fd\u80fd\u62b5\u6297\u81ea\u9002\u5e94\u5bf9\u624b\u3002", "motivation": "\u7814\u7a76\u5728\u70b9\u53ef\u63d2\u5165\u6216\u5220\u9664\u3001\u7ef4\u5ea6\u9ad8\u4e14\u4e0d\u56fa\u5b9a\uff0c\u5b58\u5728\u81ea\u9002\u5e94\u5bf9\u624b\u60c5\u51b5\u4e0b\uff0c\u52a8\u6001\u70b9\u96c6\u76f4\u5f84\u548ck - \u4e2d\u5fc3\u805a\u7c7b\u7684\u6709\u6548\u7b97\u6cd5\u3002", "method": "\u901a\u8fc7\u8bc6\u522b\u6570\u636e\u96c6\u7684\u9c81\u68d2\u4ee3\u8868\u5e76\u8fdb\u884c\u4ed4\u7ec6\u7684\u53bb\u644a\u8fd8\u64cd\u4f5c\u5b9e\u73b0\u76f4\u5f84\u7b97\u6cd5\uff1b\u672a\u63d0\u53cak - \u4e2d\u5fc3\u7b97\u6cd5\u5177\u4f53\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7ef4\u62a42 - \u8fd1\u4f3c\u76f4\u5f84\u7684\u5168\u52a8\u6001\u7b97\u6cd5\uff0c\u6700\u574f\u66f4\u65b0\u65f6\u95f4\u4e3apoly(d, log n)\uff1b\u6539\u8fdbk - \u4e2d\u5fc3\u95ee\u9898\u7684\u52a8\u6001(4 + \u03b5) - \u8fd1\u4f3c\u7b97\u6cd5\uff0c\u644a\u8fd8\u66f4\u65b0\u65f6\u95f4\u4ecek^6 d \u00b7 poly(\u03b5\u207b\u00b9, log n) \u63d0\u5347\u5230k^2.5 d \u00b7 poly(\u03b5\u207b\u00b9, log n)\u3002", "conclusion": "\u8fd9\u662f\u9ad8\u7ef4\u4e2d\u9996\u4e2a\u540c\u65f6\u5b9e\u73b02 - \u8fd1\u4f3c\u4fdd\u8bc1\u548c\u62b5\u6297\u81ea\u9002\u5e94\u5bf9\u624b\u7684\u9ad8\u6548\u5168\u52a8\u6001\u76f4\u5f84\u7b97\u6cd5\uff0ck - \u4e2d\u5fc3\u7b97\u6cd5\u5728\u644a\u8fd8\u66f4\u65b0\u65f6\u95f4\u4e0a\u6709\u6539\u8fdb\u3002"}}
{"id": "2511.00162", "pdf": "https://arxiv.org/pdf/2511.00162", "abs": "https://arxiv.org/abs/2511.00162", "authors": ["Michael D. Moffitt"], "title": "ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The Abstraction and Reasoning Corpus remains one of the most compelling and\nchallenging benchmarks for tracking progress toward achieving Artificial\nGeneral Intelligence. In contrast to other evaluation datasets designed to\nassess an agent's task-specific skills or accumulated knowledge, the ARC-AGI\nsuite is specifically targeted at measuring skill acquisition efficiency, a\ntrait that has (so far) been lacking in even the most sophisticated machine\nlearning systems. For algorithms that require extensive intra-task exemplars, a\nsignificant constraint imposed by ARC-AGI is the modest cardinality of its\ndemonstration set, comprising a small number of $\\langle$ input, output\n$\\rangle$ grids per task specifying the corresponding transformation. To\nembellish the space of viable sample pairs, this paper introduces ARC-GEN, an\nopen-source procedural generator aimed at extending the original ARC-AGI\ntraining dataset as faithfully as possible. Unlike prior efforts, our generator\nis both exhaustive (covering all four-hundred tasks) and mimetic (more closely\nhonoring the distributional properties and characteristics embodied in the\ninitial ARC-AGI-1 release). We also discuss the use of this generator in\nestablishing a static benchmark suite to verify the correctness of programs\nsubmitted to the 2025 Google Code Golf Championship.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165ARC - GEN\u6269\u5c55ARC - AGI\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5e76\u63a2\u8ba8\u5176\u7528\u4e8e2025\u8c37\u6b4c\u4ee3\u7801\u9ad8\u5c14\u592b\u9526\u6807\u8d5b\u7a0b\u5e8f\u6b63\u786e\u6027\u9a8c\u8bc1\u3002", "motivation": "ARC - AGI\u57fa\u51c6\u7528\u4e8e\u8861\u91cf\u901a\u7528\u4eba\u5de5\u667a\u80fd\u8fdb\u5c55\uff0c\u4f46\u793a\u8303\u96c6\u6837\u672c\u5c11\uff0c\u9700\u8981\u6269\u5c55\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165\u5f00\u6e90\u7684\u7a0b\u5e8f\u751f\u6210\u5668ARC - GEN\uff0c\u5c3d\u53ef\u80fd\u5fe0\u5b9e\u6269\u5c55\u539f\u59cbARC - AGI\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u4e14\u5177\u6709\u5168\u9762\u6027\u548c\u62df\u6001\u6027\u3002", "result": "\u751f\u6210\u7684ARC - GEN\u5168\u9762\u8986\u76d6400\u4e2a\u4efb\u52a1\uff0c\u66f4\u7b26\u5408\u521d\u59cbARC - AGI - 1\u7684\u5206\u5e03\u7279\u6027\u3002", "conclusion": "ARC - GEN\u53ef\u7528\u4e8e\u5efa\u7acb\u9759\u6001\u57fa\u51c6\u5957\u4ef6\uff0c\u9a8c\u8bc12025\u8c37\u6b4c\u4ee3\u7801\u9ad8\u5c14\u592b\u9526\u6807\u8d5b\u63d0\u4ea4\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\u3002"}}
{"id": "2511.01587", "pdf": "https://arxiv.org/pdf/2511.01587", "abs": "https://arxiv.org/abs/2511.01587", "authors": ["Mustapha Regragui", "Karel J. in 't Hout", "Mich\u00e8le Vanmaele", "Fred Espen Benth"], "title": "Numerical methods for solving PIDEs arising in swing option pricing under a two-factor mean-reverting model with jumps", "categories": ["math.NA", "cs.NA", "q-fin.CP"], "comment": null, "summary": "This paper concerns the numerical valuation of swing options with discrete\naction times under a linear two-factor mean-reverting model with jumps. The\nresulting sequence of two-dimensional partial integro-differential equations\n(PIDEs) are convection-dominated and possess a nonlocal integral term due to\nthe presence of jumps. Further, the initial function is nonsmooth. We propose\nvarious second-order numerical methods that can adequately handle these\nchallenging features. The stability and convergence of these numerical methods\nare analysed theoretically. By ample numerical experiments, we confirm their\nsecond-order convergence behaviour.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7ebf\u6027\u53cc\u56e0\u5b50\u5e26\u8df3\u5747\u503c\u56de\u5f52\u6a21\u578b\u4e0b\u79bb\u6563\u884c\u6743\u65f6\u95f4\u6446\u52a8\u671f\u6743\u7684\u6570\u503c\u4f30\u503c\uff0c\u63d0\u51fa\u4e8c\u9636\u6570\u503c\u65b9\u6cd5\u5e76\u5206\u6790\u5176\u7a33\u5b9a\u6027\u4e0e\u6536\u655b\u6027\uff0c\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e8c\u9636\u6536\u655b\u6027\u3002", "motivation": "\u89e3\u51b3\u7ebf\u6027\u53cc\u56e0\u5b50\u5e26\u8df3\u5747\u503c\u56de\u5f52\u6a21\u578b\u4e0b\u79bb\u6563\u884c\u6743\u65f6\u95f4\u6446\u52a8\u671f\u6743\u6570\u503c\u4f30\u503c\u95ee\u9898\uff0c\u5904\u7406\u5bf9\u6d41\u4e3b\u5bfc\u3001\u542b\u975e\u5c40\u90e8\u79ef\u5206\u9879\u548c\u975e\u5149\u6ed1\u521d\u503c\u7684\u4e8c\u7ef4\u504f\u79ef\u5206 - \u5fae\u5206\u65b9\u7a0b\u5e8f\u5217\u3002", "method": "\u63d0\u51fa\u591a\u79cd\u4e8c\u9636\u6570\u503c\u65b9\u6cd5\uff0c\u5e76\u5bf9\u5176\u7a33\u5b9a\u6027\u548c\u6536\u655b\u6027\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\uff0c\u8bc1\u5b9e\u6240\u63d0\u6570\u503c\u65b9\u6cd5\u5177\u6709\u4e8c\u9636\u6536\u655b\u884c\u4e3a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e8c\u9636\u6570\u503c\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u6446\u52a8\u671f\u6743\u6570\u503c\u4f30\u503c\u4e2d\u7684\u590d\u6742\u7279\u5f81\u3002"}}
{"id": "2511.00202", "pdf": "https://arxiv.org/pdf/2511.00202", "abs": "https://arxiv.org/abs/2511.00202", "authors": ["Jacqueline Mitchell", "Yasser Shaaban"], "title": "Position: Vibe Coding Needs Vibe Reasoning: Improving Vibe Coding with Formal Verification", "categories": ["cs.SE", "cs.LG", "cs.LO", "F.3.1; I.2.5"], "comment": "7 pages, 3 figures, In Proceedings of the 1st ACM SIGPLAN\n  International Workshop on Language Models and Programming Languages\n  (LMPL'25), October 12-18, 2025, Singapore, Singapore. ACM, New York, NY, USA", "summary": "``Vibe coding'' -- the practice of developing software through iteratively\nconversing with a large language model (LLM) -- has exploded in popularity\nwithin the last year. However, developers report key limitations including the\naccumulation of technical debt, security issues, and code churn to achieve\nsatisfactory results. We argue that these pitfalls result from LLMs' inability\nto reconcile accumulating human-imposed constraints during vibe coding, with\ndevelopers inadvertently failing to resolve contradictions because LLMs\nprioritize user commands over code consistency. Given LLMs' receptiveness to\nverification-based feedback, we argue that formal methods can mitigate these\npitfalls, making vibe coding more reliable. However, we posit that integrating\nformal methods must transcend existing approaches that combine formal methods\nand LLMs. We advocate for a side-car system throughout the vibe coding process\nwhich: (1) \\emph{Autoformalizes} specifications (2) Validates against targets,\n(3) Delivers \\emph{actionable} feedback to the LLM, and (4) Allows intuitive\ndeveloper influence on specifications.", "AI": {"tldr": "Vibe coding with LLMs is popular but has limitations. Formal methods can mitigate these issues, and a side - car system is proposed.", "motivation": "To address limitations in vibe coding such as technical debt, security issues, and code churn caused by LLMs' inability to handle human - imposed constraints.", "method": "Advocate for a side - car system during vibe coding that autoformalizes specifications, validates against targets, delivers actionable feedback to the LLM, and allows developer influence on specifications.", "result": "Not mentioned in the abstract.", "conclusion": "Formal methods can make vibe coding more reliable, and the proposed side - car system can transcend existing approaches to integrate formal methods and LLMs."}}
{"id": "2511.00040", "pdf": "https://arxiv.org/pdf/2511.00040", "abs": "https://arxiv.org/abs/2511.00040", "authors": ["Seonggyun Lee", "Sungjun Lim", "Seojin Park", "Soeun Cheon", "Kyungwoo Song"], "title": "Semi-Supervised Preference Optimization with Limited Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The field of preference optimization has made outstanding contributions to\nthe alignment of language models with human preferences. Despite these\nadvancements, recent methods still rely heavily on substantial paired (labeled)\nfeedback data, leading to substantial resource expenditures. To address these\nchallenges, we study the problem of Semi-Supervised Preference Optimization\n(SSPO) in which the idea is to learn from both a small number of pairwise\npreference labels and a large pool of unpaired samples simultaneously. Our key\ntheoretical contribution proves the existence of an optimal reward threshold\ncapable of separating winning and losing responses with high probability, which\nenables a principled pseudo-labeling of unpaired data. By leveraging these\npseudo-labels, SSPO effectively distills latent preferences from large-scale\nunpaired data, thus maintaining human alignment while drastically reducing\nacquisition costs. Extensive experiments across datasets validate this\nremarkable data efficiency; for instance, SSPO trained with Llama3-8B-Instruct\non just 1% of UltraFeedback consistently surpasses strong baselines trained on\n10% of UltraFeedback.", "AI": {"tldr": "\u7814\u7a76\u534a\u76d1\u7763\u504f\u597d\u4f18\u5316\uff08SSPO\uff09\uff0c\u53ef\u540c\u65f6\u4ece\u5c11\u91cf\u6210\u5bf9\u504f\u597d\u6807\u7b7e\u548c\u5927\u91cf\u672a\u914d\u5bf9\u6837\u672c\u5b66\u4e60\uff0c\u7406\u8bba\u8bc1\u660e\u5b58\u5728\u6700\u4f18\u5956\u52b1\u9608\u503c\uff0c\u6709\u6548\u964d\u4f4e\u6570\u636e\u83b7\u53d6\u6210\u672c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6570\u636e\u6548\u7387\u9ad8\u3002", "motivation": "\u5f53\u524d\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6210\u5bf9\u53cd\u9988\u6570\u636e\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u7814\u7a76\u534a\u76d1\u7763\u504f\u597d\u4f18\u5316\uff08SSPO\uff09\uff0c\u8bc1\u660e\u5b58\u5728\u6700\u4f18\u5956\u52b1\u9608\u503c\u5bf9\u672a\u914d\u5bf9\u6570\u636e\u8fdb\u884c\u4f2a\u6807\u8bb0\uff0c\u5229\u7528\u4f2a\u6807\u8bb0\u63d0\u53d6\u6f5c\u5728\u504f\u597d\u3002", "result": "SSPO\u80fd\u6709\u6548\u964d\u4f4e\u6570\u636e\u83b7\u53d6\u6210\u672c\uff0c\u5982\u7528Llama3 - 8B - Instruct\u57281%\u7684UltraFeedback\u4e0a\u8bad\u7ec3\u7684SSPO\u8d85\u8fc7\u572810%\u4e0a\u8bad\u7ec3\u7684\u5f3a\u57fa\u7ebf\u3002", "conclusion": "SSPO\u80fd\u5728\u4fdd\u6301\u4e0e\u4eba\u7c7b\u5bf9\u9f50\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u6570\u636e\u83b7\u53d6\u6210\u672c\uff0c\u5177\u6709\u663e\u8457\u7684\u6570\u636e\u6548\u7387\u3002"}}
{"id": "2511.01318", "pdf": "https://arxiv.org/pdf/2511.01318", "abs": "https://arxiv.org/abs/2511.01318", "authors": ["Yu Liu", "Zhuoying Li", "Ruifeng Yang", "Fengran Mo", "Cen Chen"], "title": "CSMD: Curated Multimodal Dataset for Chinese Stock Analysis", "categories": ["cs.CE"], "comment": "Accepted by CIKM 2025", "summary": "The stock market is a complex and dynamic system, where it is non-trivial for\nresearchers and practitioners to uncover underlying patterns and forecast stock\nmovements. The existing studies for stock market analysis rely on leveraging\nvarious types of information to extract useful factors, which are highly\nconditional on the quality of the data used. However, the currently available\nresources are mainly based on the U.S. stock market in English, which is\ninapplicable to adapt to other countries. To address these issues, we propose\nCSMD, a multimodal dataset curated specifically for analyzing the Chinese stock\nmarket with meticulous processing for validated quality. In addition, we\ndevelop a lightweight and user-friendly framework LightQuant for researchers\nand practitioners with expertise in financial domains. Experimental results on\ntop of our datasets and framework with various backbone models demonstrate\ntheir effectiveness compared with using existing datasets. The datasets and\ncode are publicly available at the link:\nhttps://github.com/ECNU-CILAB/LightQuant.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u4e2d\u56fd\u80a1\u5e02\u5206\u6790\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6CSMD\u548c\u8f7b\u91cf\u7ea7\u6846\u67b6LightQuant\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u6570\u636e\u548c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u80a1\u5e02\u5206\u6790\u7814\u7a76\u4f9d\u8d56\u6570\u636e\u8d28\u91cf\uff0c\u4e14\u8d44\u6e90\u591a\u57fa\u4e8e\u7f8e\u56fd\u80a1\u5e02\uff0c\u4e0d\u9002\u7528\u4e8e\u5176\u4ed6\u56fd\u5bb6\uff0c\u9700\u8981\u9002\u7528\u4e8e\u4e2d\u56fd\u80a1\u5e02\u7684\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u7ecf\u8fc7\u7cbe\u5fc3\u5904\u7406\u3001\u8d28\u91cf\u9a8c\u8bc1\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6CSMD\uff0c\u5f00\u53d1\u8f7b\u91cf\u7ea7\u3001\u7528\u6237\u53cb\u597d\u7684\u6846\u67b6LightQuant\u3002", "result": "\u5728\u6570\u636e\u96c6\u548c\u6846\u67b6\u4e0a\u4f7f\u7528\u5404\u79cd\u9aa8\u5e72\u6a21\u578b\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f7f\u7528\u73b0\u6709\u6570\u636e\u96c6\u76f8\u6bd4\u66f4\u6709\u6548\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u96c6\u548c\u6846\u67b6\u5bf9\u4e2d\u56fd\u80a1\u5e02\u5206\u6790\u6709\u79ef\u6781\u4f5c\u7528\uff0c\u53ef\u516c\u5f00\u83b7\u53d6\u3002"}}
{"id": "2511.01158", "pdf": "https://arxiv.org/pdf/2511.01158", "abs": "https://arxiv.org/abs/2511.01158", "authors": ["Faquan Chen", "Qingyang Tian", "Ziren Wu", "Rendong Ying", "Fei Wen", "Peilin Liu"], "title": "A High-Throughput Spiking Neural Network Processor Enabling Synaptic Delay Emulation", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "Synaptic delay has attracted significant attention in neural network dynamics\nfor integrating and processing complex spatiotemporal information. This paper\nintroduces a high-throughput Spiking Neural Network (SNN) processor that\nsupports synaptic delay-based emulation for edge applications. The processor\nleverages a multicore pipelined architecture with parallel compute engines,\ncapable of real-time processing of the computational load associated with\nsynaptic delays. We develop a SoC prototype of the proposed processor on PYNQ\nZ2 FPGA platform and evaluate its performance using the Spiking Heidelberg\nDigits (SHD) benchmark for low-power keyword spotting tasks. The processor\nachieves 93.4% accuracy in deployment and an average throughput of 104\nsamples/sec at a typical operating frequency of 125 MHz and 282 mW power\nconsumption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u652f\u6301\u57fa\u4e8e\u7a81\u89e6\u5ef6\u8fdf\u4eff\u771f\u7684\u9ad8\u901a\u91cf\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u5904\u7406\u5668\uff0c\u5728FPGA\u5e73\u53f0\u5f00\u53d1\u539f\u578b\u5e76\u8bc4\u4f30\u6027\u80fd\uff0c\u53d6\u5f9793.4%\u51c6\u786e\u7387\u548c104\u6837\u672c/\u79d2\u541e\u5410\u91cf\u3002", "motivation": "\u7a81\u89e6\u5ef6\u8fdf\u5728\u795e\u7ecf\u7f51\u7edc\u52a8\u529b\u5b66\u4e2d\u5bf9\u5904\u7406\u590d\u6742\u65f6\u7a7a\u4fe1\u606f\u5f88\u91cd\u8981\uff0c\u4e3a\u8fb9\u7f18\u5e94\u7528\u5f00\u53d1\u652f\u6301\u7a81\u89e6\u5ef6\u8fdf\u4eff\u771f\u7684\u5904\u7406\u5668\u3002", "method": "\u91c7\u7528\u591a\u6838\u6d41\u6c34\u7ebf\u67b6\u6784\u548c\u5e76\u884c\u8ba1\u7b97\u5f15\u64ce\uff0c\u5728PYNQ Z2 FPGA\u5e73\u53f0\u5f00\u53d1SoC\u539f\u578b\uff0c\u7528SHD\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u3002", "result": "\u5904\u7406\u5668\u5728\u90e8\u7f72\u4e2d\u8fbe\u523093.4%\u51c6\u786e\u7387\uff0c\u5728125 MHz\u5178\u578b\u5de5\u4f5c\u9891\u7387\u548c282 mW\u529f\u8017\u4e0b\u5e73\u5747\u541e\u5410\u91cf\u4e3a104\u6837\u672c/\u79d2\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u652f\u6301\u7a81\u89e6\u5ef6\u8fdf\u4eff\u771f\u7684SNN\u5904\u7406\u5668\u80fd\u6709\u6548\u5904\u7406\u76f8\u5173\u8ba1\u7b97\u8d1f\u8f7d\uff0c\u5728\u4f4e\u529f\u8017\u5173\u952e\u8bcd\u8bc6\u522b\u4efb\u52a1\u4e2d\u6709\u8f83\u597d\u8868\u73b0\u3002"}}
{"id": "2511.00826", "pdf": "https://arxiv.org/pdf/2511.00826", "abs": "https://arxiv.org/abs/2511.00826", "authors": ["Shatha Algarni", "Boris Glavic", "Seokki Lee", "Adriane Chapman"], "title": "Efficient Query Repair for Aggregate Constraints", "categories": ["cs.DB"], "comment": "19 pages, 63 figures", "summary": "In many real-world scenarios, query results must satisfy domain-specific\nconstraints. For instance, a minimum percentage of interview candidates\nselected based on their qualifications should be female. These requirements can\nbe expressed as constraints over an arithmetic combination of aggregates\nevaluated on the result of the query. In this work, we study how to repair a\nquery to fulfill such constraints by modifying the filter predicates of the\nquery. We introduce a novel query repair technique that leverages bounds on\nsets of candidate solutions and interval arithmetic to efficiently prune the\nsearch space. We demonstrate experimentally, that our technique significantly\noutperforms baselines that consider a single candidate at a time.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u4fee\u6539\u67e5\u8be2\u8fc7\u6ee4\u8c13\u8bcd\u4fee\u590d\u67e5\u8be2\u4ee5\u6ee1\u8db3\u7279\u5b9a\u7ea6\u675f\uff0c\u63d0\u51fa\u5229\u7528\u5019\u9009\u89e3\u96c6\u5408\u8fb9\u754c\u548c\u533a\u95f4\u7b97\u672f\u7684\u6280\u672f\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u8fdc\u8d85\u57fa\u7ebf\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u67e5\u8be2\u7ed3\u679c\u9700\u6ee1\u8db3\u7279\u5b9a\u9886\u57df\u7ea6\u675f\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4fee\u6539\u67e5\u8be2\u8fc7\u6ee4\u8c13\u8bcd\u4fee\u590d\u67e5\u8be2\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u7ea6\u675f\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u67e5\u8be2\u4fee\u590d\u6280\u672f\uff0c\u5229\u7528\u5019\u9009\u89e3\u96c6\u5408\u7684\u8fb9\u754c\u548c\u533a\u95f4\u7b97\u672f\u6765\u6709\u6548\u4fee\u526a\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6280\u672f\u663e\u8457\u4f18\u4e8e\u4e00\u6b21\u8003\u8651\u5355\u4e2a\u5019\u9009\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u67e5\u8be2\u4fee\u590d\u6280\u672f\u5728\u6ee1\u8db3\u7279\u5b9a\u7ea6\u675f\u7684\u67e5\u8be2\u4fee\u590d\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u9ad8\u6548\u4fee\u526a\u641c\u7d22\u7a7a\u95f4\u3002"}}
{"id": "2511.01852", "pdf": "https://arxiv.org/pdf/2511.01852", "abs": "https://arxiv.org/abs/2511.01852", "authors": ["Yang Cai", "Constantinos Daskalakis", "Haipeng Luo", "Chen-Yu Wei", "Weiqiang Zheng"], "title": "Proximal Regret and Proximal Correlated Equilibria: A New Tractable Solution Concept for Online Learning and Games", "categories": ["cs.GT", "cs.LG"], "comment": "This paper presents proximal regret and proximal correlated\n  equilibria results that do not appear in the NeurIPS version of\n  arXiv:2403.08171", "summary": "Learning and computation of equilibria are central problems in algorithmic\ngame theory. In this work, we introduce proximal regret, a new notion of regret\nbased on proximal operators that lies strictly between external and swap\nregret. When every player employs a no-proximal-regret algorithm in a general\nconvex game, the empirical distribution of play converges to proximal\ncorrelated equilibria (PCE), a refinement of coarse correlated equilibria. Our\nframework unifies several emerging notions in online learning and game theory\n-- such as gradient equilibrium and semicoarse correlated equilibrium -- and\nintroduces new ones. Our main result shows that the classic Online Gradient\nDescent (GD) algorithm achieves an optimal $O(\\sqrt{T})$ bound on proximal\nregret, revealing that GD, without modification, minimizes a stronger regret\nnotion than external regret. This provides a new explanation for the\nempirically superior performance of gradient descent in online learning and\ngames. We further extend our analysis to Mirror Descent in the Bregman setting\nand to Optimistic Gradient Descent, which yields faster convergence in smooth\nconvex games.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.01037", "pdf": "https://arxiv.org/pdf/2511.01037", "abs": "https://arxiv.org/abs/2511.01037", "authors": ["Mihailo Stojnic"], "title": "Binary perceptron computational gap -- a parametric fl RDT view", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT", "math.PR"], "comment": null, "summary": "Recent studies suggest that asymmetric binary perceptron (ABP) likely\nexhibits the so-called statistical-computational gap characterized with the\nappearance of two phase transitioning constraint density thresholds:\n\\textbf{\\emph{(i)}} the \\emph{satisfiability threshold} $\\alpha_c$, below/above\nwhich ABP succeeds/fails to operate as a storage memory; and\n\\textbf{\\emph{(ii)}} \\emph{algorithmic threshold} $\\alpha_a$, below/above which\none can/cannot efficiently determine ABP's weight so that it operates as a\nstorage memory.\n  We consider a particular parametric utilization of \\emph{fully lifted random\nduality theory} (fl RDT) [85] and study its potential ABP's algorithmic\nimplications. A remarkable structural parametric change is uncovered as one\nprogresses through fl RDT lifting levels. On the first two levels, the\nso-called $\\c$ sequence -- a key parametric fl RDT component -- is of the\n(natural) decreasing type. A change of such phenomenology on higher levels is\nthen connected to the $\\alpha_c$ -- $\\alpha_a$ threshold change. Namely, on the\nsecond level concrete numerical values give for the critical constraint density\n$\\alpha=\\alpha_c\\approx 0.8331$. While progressing through higher levels\ndecreases this estimate, already on the fifth level we observe a satisfactory\nlevel of convergence and obtain $\\alpha\\approx 0.7764$. This allows to draw two\nstriking parallels: \\textbf{\\emph{(i)}} the obtained constraint density\nestimate is in a remarkable agrement with range $\\alpha\\in (0.77,0.78)$ of\nclustering defragmentation (believed to be responsible for failure of locally\nimproving algorithms) [17,88]; and \\textbf{\\emph{(ii)}} the observed change of\n$\\c$ sequence phenomenology closely matches the one of the negative Hopfield\nmodel for which the existence of efficient algorithms that closely approach\nsimilar type of threshold has been demonstrated recently [87].", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u5168\u63d0\u5347\u968f\u673a\u5bf9\u5076\u7406\u8bba\u5206\u6790\u975e\u5bf9\u79f0\u4e8c\u8fdb\u5236\u611f\u77e5\u673a\uff0c\u53d1\u73b0\u53c2\u6570\u53d8\u5316\u4e0e\u9608\u503c\u53d8\u5316\u5173\u8054\uff0c\u5f97\u5230\u7ea6\u675f\u5bc6\u5ea6\u4f30\u8ba1\u503c\u5e76\u4e0e\u76f8\u5173\u7ed3\u679c\u6709\u5bf9\u5e94\u3002", "motivation": "\u7814\u7a76\u5168\u63d0\u5347\u968f\u673a\u5bf9\u5076\u7406\u8bba\u5728\u975e\u5bf9\u79f0\u4e8c\u8fdb\u5236\u611f\u77e5\u673a\u4e2d\u7684\u7b97\u6cd5\u610f\u4e49\uff0c\u63a2\u7d22\u5176\u4e0e\u7edf\u8ba1 - \u8ba1\u7b97\u5dee\u8ddd\u7684\u8054\u7cfb\u3002", "method": "\u5bf9\u5168\u63d0\u5347\u968f\u673a\u5bf9\u5076\u7406\u8bba\u8fdb\u884c\u7279\u5b9a\u53c2\u6570\u5316\u5229\u7528\u5e76\u7814\u7a76\u5176\u5728\u4e0d\u540c\u63d0\u5347\u5c42\u7ea7\u7684\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u5173\u952e\u53c2\u6570\u5e8f\u5217\u5728\u4e0d\u540c\u5c42\u7ea7\u7684\u53d8\u5316\uff0c\u5f97\u5230\u4e0d\u540c\u5c42\u7ea7\u7684\u4e34\u754c\u7ea6\u675f\u5bc6\u5ea6\u4f30\u8ba1\u503c\uff0c\u5728\u7b2c\u4e94\u5c42\u6536\u655b\u5230\u7ea6 0.7764\u3002", "conclusion": "\u6240\u5f97\u7ea6\u675f\u5bc6\u5ea6\u4f30\u8ba1\u4e0e\u805a\u7c7b\u788e\u7247\u5316\u8303\u56f4\u4e00\u81f4\uff0c\u53c2\u6570\u5e8f\u5217\u53d8\u5316\u4e0e\u8d1f Hopfield \u6a21\u578b\u76f8\u4f3c\u3002"}}
{"id": "2511.01133", "pdf": "https://arxiv.org/pdf/2511.01133", "abs": "https://arxiv.org/abs/2511.01133", "authors": ["Hamza Hanbali", "Gaurav Khemka", "Himasha Warnakulasooriya"], "title": "Liquidity Shocks, Homeownership, and Income Inequality: Impact of Early Pension Withdrawals and Reduced Deposit", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "The paper analyzes two government policies affecting housing demand: early\nwithdrawal from pension savings (EW), and reduction of loan deposit (RD). A\nmodel incorporating demand feedback on housing prices using Australian data\nshows both policies raise prices in the short run. RD delays or prevents access\nfor low-income households, particularly in supply-constrained markets. EW\nimproves accessibility across groups and is most efficient when full withdrawal\nis permitted, but can reduce retirement security if pension grows faster than\nproperty prices. The results also indicate that unequal outcomes stem not from\nprice surges themselves but from pre-existing market disparities.", "AI": {"tldr": "\u5206\u6790\u4e24\u9879\u5f71\u54cd\u4f4f\u623f\u9700\u6c42\u7684\u653f\u5e9c\u653f\u7b56\uff0c\u53d1\u73b0\u77ed\u671f\u63d0\u4ef7\uff0c\u4e14\u4e0d\u540c\u653f\u7b56\u6548\u679c\u6709\u5dee\u5f02\uff0c\u4e0d\u5e73\u7b49\u6e90\u4e8e\u5e02\u573a\u65e2\u6709\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u4e24\u9879\u5f71\u54cd\u4f4f\u623f\u9700\u6c42\u7684\u653f\u5e9c\u653f\u7b56\uff08\u63d0\u524d\u63d0\u53d6\u517b\u8001\u91d1\u50a8\u84c4\u548c\u964d\u4f4e\u8d37\u6b3e\u9996\u4ed8\uff09\u7684\u6548\u679c\u3002", "method": "\u6784\u5efa\u7eb3\u5165\u4f4f\u623f\u9700\u6c42\u5bf9\u623f\u4ef7\u53cd\u9988\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u6fb3\u5927\u5229\u4e9a\u6570\u636e\u3002", "result": "\u4e24\u9879\u653f\u7b56\u77ed\u671f\u63d0\u4ef7\uff1bRD \u5f71\u54cd\u4f4e\u6536\u5165\u5bb6\u5ead\u8d2d\u623f\uff1bEW \u63d0\u5347\u5404\u7fa4\u4f53\u8d2d\u623f\u53ef\u53ca\u6027\uff0c\u4f46\u53ef\u80fd\u964d\u4f4e\u9000\u4f11\u4fdd\u969c\uff1b\u4e0d\u5e73\u7b49\u6e90\u4e8e\u65e2\u6709\u5e02\u573a\u5dee\u5f02\u3002", "conclusion": "\u4e0d\u540c\u653f\u7b56\u5728\u4f4f\u623f\u5e02\u573a\u4ea7\u751f\u4e0d\u540c\u5f71\u54cd\uff0c\u5e02\u573a\u65e2\u6709\u5dee\u5f02\u5bfc\u81f4\u4e0d\u5e73\u7b49\u7ed3\u679c\u3002"}}
{"id": "2511.00395", "pdf": "https://arxiv.org/pdf/2511.00395", "abs": "https://arxiv.org/abs/2511.00395", "authors": ["Chuanji Gao", "Gang Chen", "Svetlana V. Shinkareva", "Rutvik H. Desai"], "title": "Is Representational Similarity Analysis Reliable? A Comparison with Regression", "categories": ["stat.ME", "stat.CO"], "comment": null, "summary": "Representational Similarity Analysis (RSA) is a popular method for analyzing\nneuroimaging and behavioral data. Here we evaluate the accuracy and reliability\nof RSA in the context of model selection, and compare it to that of regression.\nAlthough RSA offers flexibility in handling high-dimensional, cross-modal, and\ncross-species data, its reliance on a transformation of raw data into\nsimilarity structures may result in the loss of critical stimulus-response\ninformation. Across extensive simulation studies and empirical analyses, we\nshow that RSA leads to lower model selection accuracy, regardless of sample\nsize, noise level, feature dimensionality, or multicollinearity, relative to\nregression. While principal component analysis and feature reweighting mitigate\nRSA's deficits driven by multicollinearity, regression remains superior in\naccurately distinguishing between models. Empirical data and a follow-up fMRI\nsimulation further support these conclusions. Our findings suggest that\nresearchers should carefully consider which approach to use: RSA is less\neffective than linear regression for model selection and fitting when direct\nstimulus-response mappings are available.", "AI": {"tldr": "\u8bc4\u4f30RSA\u5728\u6a21\u578b\u9009\u62e9\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u5e76\u4e0e\u56de\u5f52\u6bd4\u8f83\uff0c\u53d1\u73b0RSA\u5728\u6a21\u578b\u9009\u62e9\u4e0a\u4e0d\u5982\u56de\u5f52\u3002", "motivation": "\u8bc4\u4f30RSA\u5728\u6a21\u578b\u9009\u62e9\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u4e0e\u56de\u5f52\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "method": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u6a21\u62df\u7814\u7a76\u548c\u5b9e\u8bc1\u5206\u6790\uff0c\u8fd8\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\u548c\u7279\u5f81\u91cd\u52a0\u6743\u65b9\u6cd5\u3002", "result": "\u65e0\u8bba\u6837\u672c\u5927\u5c0f\u3001\u566a\u58f0\u6c34\u5e73\u3001\u7279\u5f81\u7ef4\u5ea6\u6216\u591a\u91cd\u5171\u7ebf\u6027\u5982\u4f55\uff0cRSA\u7684\u6a21\u578b\u9009\u62e9\u51c6\u786e\u6027\u4f4e\u4e8e\u56de\u5f52\uff1b\u4e3b\u6210\u5206\u5206\u6790\u548c\u7279\u5f81\u91cd\u52a0\u6743\u53ef\u7f13\u89e3RSA\u56e0\u591a\u91cd\u5171\u7ebf\u6027\u5bfc\u81f4\u7684\u4e0d\u8db3\uff0c\u4f46\u56de\u5f52\u4ecd\u66f4\u4f18\u3002", "conclusion": "\u5f53\u6709\u76f4\u63a5\u7684\u523a\u6fc0 - \u53cd\u5e94\u6620\u5c04\u65f6\uff0cRSA\u5728\u6a21\u578b\u9009\u62e9\u548c\u62df\u5408\u65b9\u9762\u4e0d\u5982\u7ebf\u6027\u56de\u5f52\uff0c\u7814\u7a76\u8005\u5e94\u8c28\u614e\u9009\u62e9\u65b9\u6cd5\u3002"}}
{"id": "2511.01255", "pdf": "https://arxiv.org/pdf/2511.01255", "abs": "https://arxiv.org/abs/2511.01255", "authors": ["He Chen", "ZiHua Zheng", "JingHua Sun"], "title": "Design of quasi phase matching crystal based on differential gray wolf algorithm", "categories": ["cs.DC"], "comment": null, "summary": "This paper focuses on the key problem in the development of nonlinear optical\ntechnology, the performance optimization of aperiodically polarized crystals.\nThe performance of the crystal depends on the precise control of the micro\ndistribution of crystal domains, but its optimization belongs to the\nhigh-dimensional discrete combination \"NP hard\" problem. The traditional\nalgorithm has the bottleneck of slow convergence and easy to fall into local\noptimization, while the heuristic methods such as genetic algorithm are limited\nby the CPU serial calculation and inefficient. In order to solve the above\nchallenges, this paper proposes the fusion scheme of hwsda hybrid optimization\nalgorithm and GPU parallel acceleration technology: the differential evolution\nalgorithm (DE) is used to realize the global search, and the gray wolf\noptimization algorithm (GWO) is used to strengthen the local search and\nconvergence speed, and the two coordinate to balance the global and local\noptimization requirements; At the same time, it relies on GPU multi-core\narchitecture to realize thread level parallel computing and improve\noptimization efficiency. This scheme effectively breaks through the\noptimization problem of high-dimensional discrete space, improves the accuracy\nof crystal domain control, improves the efficiency of quasi phase matching\ndesign by hundreds to thousands of times compared with traditional CPU serial\ncomputing, provides a new paradigm for the design of complex nonlinear optical\ndevices, and helps promote the performance breakthrough and industrial\napplication of related devices in the fields of quantum optics and laser\nprocessing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fahwsda\u6df7\u5408\u4f18\u5316\u7b97\u6cd5\u4e0eGPU\u5e76\u884c\u52a0\u901f\u6280\u672f\u878d\u5408\u65b9\u6848\uff0c\u89e3\u51b3\u975e\u5468\u671f\u6781\u5316\u6676\u4f53\u6027\u80fd\u4f18\u5316\u96be\u9898\uff0c\u63d0\u5347\u8bbe\u8ba1\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7b97\u6cd5\u5728\u975e\u5468\u671f\u6781\u5316\u6676\u4f53\u6027\u80fd\u4f18\u5316\u4e2d\u5b58\u5728\u6536\u655b\u6162\u3001\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u53ca\u8ba1\u7b97\u6548\u7387\u4f4e\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u8fdb\u884c\u5168\u5c40\u641c\u7d22\uff0c\u7070\u72fc\u4f18\u5316\u7b97\u6cd5\u52a0\u5f3a\u5c40\u90e8\u641c\u7d22\u548c\u6536\u655b\u901f\u5ea6\uff0c\u7ed3\u5408GPU\u591a\u6838\u67b6\u6784\u5b9e\u73b0\u7ebf\u7a0b\u7ea7\u5e76\u884c\u8ba1\u7b97\u3002", "result": "\u6709\u6548\u7a81\u7834\u9ad8\u7ef4\u79bb\u6563\u7a7a\u95f4\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u6676\u4f53\u7574\u63a7\u5236\u7cbe\u5ea6\uff0c\u8bbe\u8ba1\u6548\u7387\u8f83\u4f20\u7edfCPU\u4e32\u884c\u8ba1\u7b97\u63d0\u5347\u6570\u767e\u5230\u6570\u5343\u500d\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u590d\u6742\u975e\u7ebf\u6027\u5149\u5b66\u5668\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u52a9\u529b\u76f8\u5173\u5668\u4ef6\u6027\u80fd\u7a81\u7834\u548c\u4ea7\u4e1a\u5e94\u7528\u3002"}}
{"id": "2511.00694", "pdf": "https://arxiv.org/pdf/2511.00694", "abs": "https://arxiv.org/abs/2511.00694", "authors": ["Uthman Jinadu", "Siawpeng Er", "Le Yu", "Chen Liang", "Bingxin Li", "Yi Ding", "Aleksandar Velkoski"], "title": "Taxonomy-based Negative Sampling In Personalized Semantic Search for E-commerce", "categories": ["cs.IR"], "comment": "Accepted at 2025 IEEE International Conference on Big Data", "summary": "Large retail outlets offer products that may be domain-specific, and this\nrequires having a model that can understand subtle differences in similar\nitems. Sampling techniques used to train these models are most of the time,\ncomputationally expensive or logistically challenging. These models also do not\nfactor in users' previous purchase patterns or behavior, thereby retrieving\nirrelevant items for them. We present a semantic retrieval model for e-commerce\nsearch that embeds queries and products into a shared vector space and\nleverages a novel taxonomy-based hard-negative sampling(TB-HNS) strategy to\nmine contextually relevant yet challenging negatives. To further tailor\nretrievals, we incorporate user-level personalization by modeling each\ncustomer's past purchase history and behavior. In offline experiments, our\napproach outperforms BM25, ANCE and leading neural baselines on Recall@K, while\nlive A/B testing shows substantial uplifts in conversion rate, add-to-cart\nrate, and average order value. We also demonstrate that our taxonomy-driven\nnegatives reduce training overhead and accelerate convergence, and we share\npractical lessons from deploying this system at scale.", "AI": {"tldr": "\u63d0\u51fa\u7535\u5546\u641c\u7d22\u8bed\u4e49\u68c0\u7d22\u6a21\u578b\uff0c\u7528\u65b0\u91c7\u6837\u7b56\u7565\u548c\u7528\u6237\u4e2a\u6027\u5316\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\u4e14\u51cf\u5c11\u8bad\u7ec3\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u6a21\u578b\u7684\u91c7\u6837\u6280\u672f\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u5b9e\u65bd\u56f0\u96be\uff0c\u4e14\u672a\u8003\u8651\u7528\u6237\u8d2d\u4e70\u6a21\u5f0f\uff0c\u68c0\u7d22\u7ed3\u679c\u65e0\u5173\u3002", "method": "\u5c06\u67e5\u8be2\u548c\u4ea7\u54c1\u5d4c\u5165\u5171\u4eab\u5411\u91cf\u7a7a\u95f4\uff0c\u91c7\u7528\u57fa\u4e8e\u5206\u7c7b\u6cd5\u7684\u786c\u8d1f\u91c7\u6837\u7b56\u7565\uff0c\u7ed3\u5408\u7528\u6237\u8d2d\u4e70\u5386\u53f2\u548c\u884c\u4e3a\u8fdb\u884c\u4e2a\u6027\u5316\u3002", "result": "\u79bb\u7ebf\u5b9e\u9a8c\u4e2d\u53ec\u56de\u7387\u8d85\u57fa\u7ebf\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u8f6c\u5316\u7387\u3001\u52a0\u8d2d\u7387\u548c\u5e73\u5747\u8ba2\u5355\u4ef7\u503c\u63d0\u5347\uff0c\u5206\u7c7b\u6cd5\u8d1f\u6837\u672c\u51cf\u5c11\u8bad\u7ec3\u5f00\u9500\u3001\u52a0\u901f\u6536\u655b\u3002", "conclusion": "\u8be5\u8bed\u4e49\u68c0\u7d22\u6a21\u578b\u6709\u6548\uff0c\u5206\u4eab\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u5b9e\u7528\u7ecf\u9a8c\u3002"}}
{"id": "2511.01239", "pdf": "https://arxiv.org/pdf/2511.01239", "abs": "https://arxiv.org/abs/2511.01239", "authors": ["Dipan Dey", "Telikepalli Kavitha"], "title": "Fault-Tolerant Approximate Distance Oracles with a Source Set", "categories": ["cs.DS"], "comment": null, "summary": "Our input is an undirected weighted graph $G = (V,E)$ on $n$ vertices along\nwith a source set $S\\subseteq V$. The problem is to preprocess $G$ and build a\ncompact data structure such that upon query $Qu(s,v,f)$ where $(s,v) \\in\nS\\times V$ and $f$ is any faulty edge, we can quickly find a good estimate\n(i.e., within a small multiplicative stretch) of the $s$-$v$ distance in $G-f$.\nWe use a fault-tolerant $ST$-distance oracle from the work of Bil{\\`{o}} et al.\n(STACS 2018) to construct an $S\\times V$ approximate distance oracle or {\\em\nsourcewise} approximate distance oracle of size $\\widetilde{O}(|S|n + n^{3/2})$\nwith multiplicative stretch at most 5. We construct another fault-tolerant\nsourcewise approximate distance oracle of size $\\widetilde{O}(|S|n + n^{4/3})$\nwith multiplicative stretch at most 13. Both the oracles have $O(1)$ query\nanswering time.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.00194", "pdf": "https://arxiv.org/pdf/2511.00194", "abs": "https://arxiv.org/abs/2511.00194", "authors": ["Jovial Cheukam Ngouonou", "Ramiz Gindullin", "Claude-Guy Quimper", "Nicolas Beldiceanu", "Remi Douence"], "title": "Incremental Selection of Most-Filtering Conjectures and Proofs of the Selected Conjectures", "categories": ["cs.AI", "F.2.2, F.4.1"], "comment": null, "summary": "We present an improved incremental selection algorithm of the selection\nalgorithm presented in [1] and prove all the selected conjectures.", "AI": {"tldr": "\u63d0\u51fa\u6539\u8fdb\u7684\u589e\u91cf\u9009\u62e9\u7b97\u6cd5\u5e76\u8bc1\u660e\u6240\u9009\u731c\u60f3", "motivation": "\u5bf9\u6587\u732e[1]\u4e2d\u7684\u9009\u62e9\u7b97\u6cd5\u8fdb\u884c\u6539\u8fdb", "method": "\u63d0\u51fa\u6539\u8fdb\u7684\u589e\u91cf\u9009\u62e9\u7b97\u6cd5", "result": "\u6210\u529f\u8bc1\u660e\u6240\u6709\u6240\u9009\u731c\u60f3", "conclusion": "\u6539\u8fdb\u7684\u7b97\u6cd5\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u8bc1\u660e\u731c\u60f3"}}
{"id": "2511.00215", "pdf": "https://arxiv.org/pdf/2511.00215", "abs": "https://arxiv.org/abs/2511.00215", "authors": ["Xiaomeng Xu", "Zahin Wahab", "Reid Holmes", "Caroline Lemieux"], "title": "DocPrism: Local Categorization and External Filtering to Identify Relevant Code-Documentation Inconsistencies", "categories": ["cs.SE"], "comment": null, "summary": "Code-documentation inconsistencies are common and undesirable: they can lead\nto developer misunderstandings and software defects. This paper introduces\nDocPrism, a multi-language, code-documentation inconsistency detection tool.\nDocPrism uses a standard large language model (LLM) to analyze and explain\ninconsistencies. Plain use of LLMs for this task yield unacceptably high false\npositive rates: LLMs identify natural gaps between high-level documentation and\ndetailed code implementations as inconsistencies. We introduce and apply the\nLocal Categorization, External Filtering (LCEF) methodology to reduce false\npositives. LCEF relies on the LLM's local completion skills rather than its\nlong-term reasoning skills. In our ablation study, LCEF reduces DocPrism's\ninconsistency flag rate from 98% to 14%, and increases accuracy from 14% to\n94%. On a broad evaluation across Python, TypeScript, C++, and Java, DocPrism\nmaintains a low flag rate of 15%, and achieves a precision of 0.62 without\nperforming any fine-tuning.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u591a\u8bed\u8a00\u4ee3\u7801\u6587\u6863\u4e0d\u4e00\u81f4\u68c0\u6d4b\u5de5\u5177DocPrism\uff0c\u7528LCEF\u65b9\u6cd5\u964d\u4f4e\u8bef\u62a5\u7387\uff0c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u89e3\u51b3\u4ee3\u7801 - \u6587\u6863\u4e0d\u4e00\u81f4\u5bfc\u81f4\u5f00\u53d1\u8005\u8bef\u89e3\u548c\u8f6f\u4ef6\u7f3a\u9677\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165DocPrism\u5de5\u5177\uff0c\u4f7f\u7528\u6807\u51c6\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u4e0d\u4e00\u81f4\uff0c\u5e94\u7528LCEF\u65b9\u6cd5\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "result": "\u6d88\u878d\u5b9e\u9a8c\u4e2dLCEF\u5c06DocPrism\u8bef\u62a5\u7387\u4ece98%\u964d\u81f314%\uff0c\u51c6\u786e\u7387\u4ece14%\u63d0\u5347\u523094%\uff1b\u591a\u8bed\u8a00\u8bc4\u4f30\u4e2d\u4fdd\u630115%\u4f4e\u8bef\u62a5\u7387\uff0c\u7cbe\u5ea6\u8fbe0.62\u3002", "conclusion": "DocPrism\u80fd\u6709\u6548\u68c0\u6d4b\u4ee3\u7801 - \u6587\u6863\u4e0d\u4e00\u81f4\uff0cLCEF\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\u3002"}}
{"id": "2511.00043", "pdf": "https://arxiv.org/pdf/2511.00043", "abs": "https://arxiv.org/abs/2511.00043", "authors": ["Tyrus Whitman", "Andrew Particka", "Christopher Diers", "Ian Griffin", "Charuka Wickramasinghe", "Pradeep Ranaweera"], "title": "Physics-Informed Neural Network Frameworks for the Analysis of Engineering and Biological Dynamical Systems Governed by Ordinary Differential Equations", "categories": ["cs.LG"], "comment": "21 pages, 10 figures, 5 tables", "summary": "In this study, we present and validate the predictive capability of the\nPhysics-Informed Neural Networks (PINNs) methodology for solving a variety of\nengineering and biological dynamical systems governed by ordinary differential\nequations (ODEs). While traditional numerical methods a re effective for many\nODEs, they often struggle to achieve convergence in problems involving high\nstiffness, shocks, irregular domains, singular perturbations, high dimensions,\nor boundary discontinuities. Alternatively, PINNs offer a powerful approach for\nhandling challenging numerical scenarios. In this study, classical ODE problems\nare employed as controlled testbeds to systematically evaluate the accuracy,\ntraining efficiency, and generalization capability under controlled conditions\nof the PINNs framework. Although not a universal solution, PINNs can achieve\nsuperior results by embedding physical laws directly into the learning process.\nWe first analyze the existence and uniqueness properties of several benchmark\nproblems and subsequently validate the PINNs methodology on these model\nsystems. Our results demonstrate that for complex problems to converge to\ncorrect solutions, the loss function components data loss, initial condition\nloss, and residual loss must be appropriately balanced through careful\nweighting. We further establish that systematic tuning of hyperparameters,\nincluding network depth, layer width, activation functions, learning rate,\noptimization algorithms, w eight initialization schemes, and collocation point\nsampling, plays a crucial role in achieving accurate solutions. Additionally,\nembedding prior knowledge and imposing hard constraints on the network\narchitecture, without loss the generality of the ODE system, significantly\nenhances the predictive capability of PINNs.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u6c42\u89e3\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODEs\uff09\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u8bc4\u4f30\u5176\u6027\u80fd\uff0c\u6307\u51fa\u5e73\u8861\u635f\u5931\u51fd\u6570\u3001\u8c03\u8d85\u53c2\u548c\u5d4c\u5165\u5148\u9a8c\u77e5\u8bc6\u53ef\u63d0\u5347\u5176\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5728\u6c42\u89e3\u9ad8\u521a\u5ea6\u3001\u542b\u51b2\u51fb\u7b49\u590d\u6742ODE\u95ee\u9898\u65f6\u96be\u6536\u655b\uff0cPINNs\u53ef\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u7528\u7ecf\u5178ODE\u95ee\u9898\u4f5c\u4e3a\u63a7\u5236\u8bd5\u9a8c\u53f0\u8bc4\u4f30PINNs\u6846\u67b6\u7684\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5206\u6790\u57fa\u51c6\u95ee\u9898\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\u5e76\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u590d\u6742\u95ee\u9898\u9700\u5e73\u8861\u635f\u5931\u51fd\u6570\u5404\u5206\u91cf\uff0c\u7cfb\u7edf\u8c03\u6574\u8d85\u53c2\u6570\u5bf9\u51c6\u786e\u6c42\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u5d4c\u5165\u5148\u9a8c\u77e5\u8bc6\u548c\u65bd\u52a0\u786c\u7ea6\u675f\u80fd\u589e\u5f3aPINNs\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "PINNs\u867d\u975e\u901a\u7528\u89e3\uff0c\u4f46\u901a\u8fc7\u5408\u7406\u64cd\u4f5c\u53ef\u5728\u6c42\u89e3ODE\u95ee\u9898\u4e0a\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\u3002"}}
{"id": "2511.01701", "pdf": "https://arxiv.org/pdf/2511.01701", "abs": "https://arxiv.org/abs/2511.01701", "authors": ["Mirco A. Mannucci"], "title": "Solution Space Topology Guides CMTS Search", "categories": ["cs.CE", "cs.AI", "cs.LG"], "comment": "15 pages, 3 figures", "summary": "A fundamental question in search-guided AI: what topology should guide Monte\nCarlo Tree Search (MCTS) in puzzle solving? Prior work applied topological\nfeatures to guide MCTS in ARC-style tasks using grid topology -- the Laplacian\nspectral properties of cell connectivity -- and found no benefit. We identify\nthe root cause: grid topology is constant across all instances. We propose\nmeasuring \\emph{solution space topology} instead: the structure of valid color\nassignments constrained by detected pattern rules. We build this via\ncompatibility graphs where nodes are $(cell, color)$ pairs and edges represent\ncompatible assignments under pattern constraints.\n  Our method: (1) detect pattern rules automatically with 100\\% accuracy on 5\ntypes, (2) construct compatibility graphs encoding solution space structure,\n(3) extract topological features (algebraic connectivity, rigidity, color\nstructure) that vary with task difficulty, (4) integrate these features into\nMCTS node selection via sibling-normalized scores.\n  We provide formal definitions, a rigorous selection formula, and\ncomprehensive ablations showing that algebraic connectivity is the dominant\nsignal. The work demonstrates that topology matters for search -- but only the\n\\emph{right} topology. For puzzle solving, this is solution space structure,\nnot problem space structure.", "AI": {"tldr": "\u63a2\u8ba8\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\uff08MCTS\uff09\u5728\u89e3\u8c1c\u4e2d\u5e94\u91c7\u7528\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u63d0\u51fa\u7528\u89e3\u7a7a\u95f4\u62d3\u6251\u66ff\u4ee3\u7f51\u683c\u62d3\u6251\uff0c\u7ed9\u51fa\u65b9\u6cd5\u5e76\u8bc1\u660e\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u641c\u7d22\u5f15\u5bfc\u5f0fAI\u4e2dMCTS\u5728\u89e3\u8c1c\u65f6\u5e94\u91c7\u7528\u4f55\u79cd\u62d3\u6251\u7ed3\u6784\u7684\u57fa\u672c\u95ee\u9898\uff0c\u524d\u4eba\u7528\u7f51\u683c\u62d3\u6251\u65e0\u6548\u679c\uff0c\u9700\u627e\u51fa\u539f\u56e0\u5e76\u89e3\u51b3\u3002", "method": "\u81ea\u52a8\u68c0\u6d4b5\u79cd\u6a21\u5f0f\u89c4\u5219\uff0c\u6784\u5efa\u7f16\u7801\u89e3\u7a7a\u95f4\u7ed3\u6784\u7684\u517c\u5bb9\u6027\u56fe\uff0c\u63d0\u53d6\u968f\u4efb\u52a1\u96be\u5ea6\u53d8\u5316\u7684\u62d3\u6251\u7279\u5f81\uff0c\u901a\u8fc7\u5144\u5f1f\u8282\u70b9\u5f52\u4e00\u5316\u5206\u6570\u5c06\u7279\u5f81\u96c6\u6210\u5230MCTS\u8282\u70b9\u9009\u62e9\u4e2d\u3002", "result": "\u7ed9\u51fa\u5f62\u5f0f\u5316\u5b9a\u4e49\u3001\u4e25\u683c\u9009\u62e9\u516c\u5f0f\u548c\u5168\u9762\u6d88\u878d\u5b9e\u9a8c\uff0c\u8868\u660e\u4ee3\u6570\u8fde\u901a\u6027\u662f\u4e3b\u8981\u4fe1\u53f7\u3002", "conclusion": "\u62d3\u6251\u5bf9\u641c\u7d22\u5f88\u91cd\u8981\uff0c\u4f46\u9700\u662f\u6b63\u786e\u7684\u62d3\u6251\uff0c\u89e3\u8c1c\u4e2d\u662f\u89e3\u7a7a\u95f4\u7ed3\u6784\u800c\u975e\u95ee\u9898\u7a7a\u95f4\u7ed3\u6784\u3002"}}
{"id": "2511.01632", "pdf": "https://arxiv.org/pdf/2511.01632", "abs": "https://arxiv.org/abs/2511.01632", "authors": ["Bal\u00e1zs M\u00e9sz\u00e1ros", "James C. Knight", "Danyal Akarca", "Thomas Nowotny"], "title": "Space as Time Through Neuron Position Learning", "categories": ["cs.NE"], "comment": null, "summary": "Biological neural networks exist in physical space where distance determines\ncommunication delays: a fundamental space-time coupling absent in most\nartificial neural networks. While recent work has separately explored spatial\nembeddings and learnable synaptic delays in spiking neural networks, we unify\nthese approaches through a novel neuron position learning algorithm where\ndelays relate to the Euclidean distances between neurons. We derive gradients\nwith respect to neuron positions and demonstrate that this\nbiologically-motivated constraint acts as an inductive bias: networks trained\non temporal classification tasks spontaneously self-organize into local,\nsmall-world topologies with modular structure emerging under distance-dependent\nconnection costs. Remarkably, we observe unprompted functional specialization\naligned with spatial clustering without explictly enforcing it. These findings\nlay the groundwork for networks in which space and time are intrinsically\ncoupled, offering new avenues for mechanistic interpretability, biologically\ninspired modelling, and efficient implementations.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u9896\u795e\u7ecf\u5143\u4f4d\u7f6e\u5b66\u4e60\u7b97\u6cd5\u7edf\u4e00\u7a7a\u95f4\u5d4c\u5165\u548c\u53ef\u5b66\u4e60\u7a81\u89e6\u5ef6\u8fdf\uff0c\u8bad\u7ec3\u7f51\u7edc\u81ea\u7ec4\u7ec7\u6210\u7279\u5b9a\u62d3\u6251\uff0c\u6709\u529f\u80fd\u4e13\u4e1a\u5316\uff0c\u4e3a\u65f6\u7a7a\u8026\u5408\u7f51\u7edc\u5960\u57fa\u3002", "motivation": "\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u5b58\u5728\u65f6\u7a7a\u8026\u5408\uff0c\u591a\u6570\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7f3a\u4e4f\uff0c\u73b0\u6709\u5de5\u4f5c\u5206\u522b\u63a2\u7d22\u7a7a\u95f4\u5d4c\u5165\u548c\u53ef\u5b66\u4e60\u7a81\u89e6\u5ef6\u8fdf\uff0c\u9700\u7edf\u4e00\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u795e\u7ecf\u5143\u4f4d\u7f6e\u5b66\u4e60\u7b97\u6cd5\uff0c\u63a8\u5bfc\u795e\u7ecf\u5143\u4f4d\u7f6e\u68af\u5ea6\u3002", "result": "\u7f51\u7edc\u5728\u65f6\u95f4\u5206\u7c7b\u4efb\u52a1\u8bad\u7ec3\u4e2d\u81ea\u7ec4\u7ec7\u6210\u5c40\u90e8\u3001\u5c0f\u4e16\u754c\u62d3\u6251\uff0c\u6709\u6a21\u5757\u5316\u7ed3\u6784\uff0c\u51fa\u73b0\u672a\u663e\u5f0f\u5f3a\u5236\u7684\u529f\u80fd\u4e13\u4e1a\u5316\u3002", "conclusion": "\u4e3a\u65f6\u7a7a\u5185\u5728\u8026\u5408\u7f51\u7edc\u5960\u5b9a\u57fa\u7840\uff0c\u4e3a\u53ef\u89e3\u91ca\u6027\u3001\u751f\u7269\u542f\u53d1\u5efa\u6a21\u548c\u9ad8\u6548\u5b9e\u73b0\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.00855", "pdf": "https://arxiv.org/pdf/2511.00855", "abs": "https://arxiv.org/abs/2511.00855", "authors": ["Zhonggen Li", "Yougen Li", "Yifan Zhu", "Zhaoqiang Chen", "Yunjun Gao"], "title": "All-in-one Graph-based Indexing for Hybrid Search on GPUs", "categories": ["cs.DB"], "comment": null, "summary": "Hybrid search has emerged as a promising paradigm to overcome the limitations\nof single-path retrieval, enhancing accuracy for applications like\nrecommendations, information retrieval, and Retrieval-Augmented Generation.\nHowever, existing methods are constrained by a trilemma: they sacrifice\nflexibility for efficiency, suffer from accuracy degradation due to separate\nretrievals, or incur prohibitive storage overhead for flexible combinations of\nretrieval paths. This paper introduces Allan-Poe, a novel All-in-one graph\nindex accelerated by GPUs for efficient hybrid search. We first analyze the\nlimitations of existing retrieval paradigms and distill key design principles\nfor an effective hybrid search index. Guided by these principles, we architect\na unified graph-based index that flexibly integrates four retrieval paths-dense\nvector, sparse vector, full-text, and knowledge graph-within a single, cohesive\nstructure. To enable efficient construction, we design a GPU-accelerated\npipeline featuring a warp-level hybrid distance kernel, RNG-IP joint pruning,\nand keyword-aware neighbor recycling. For query processing, we introduce a\ndynamic fusion framework that supports any combination of retrieval paths and\nweights without index reconstruction, leveraging logical edges from the\nknowledge graph to resolve complex multi-hop queries. Extensive experiments on\n6 real-world datasets demonstrate that Allan-Poe achieves superior end-to-end\nquery accuracy and outperforms state-of-the-art methods by 1.5-186.4x in\nthroughput, while significantly reducing storage overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u9ad8\u6548\u6df7\u5408\u641c\u7d22\u7684Allan - Poe\u7d22\u5f15\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u51c6\u786e\u6027\u3001\u541e\u5410\u91cf\u548c\u5b58\u50a8\u5f00\u9500\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u641c\u7d22\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u3001\u51c6\u786e\u6027\u548c\u5b58\u50a8\u5f00\u9500\u7684\u4e09\u96be\u56f0\u5883\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5206\u6790\u73b0\u6709\u68c0\u7d22\u8303\u5f0f\u5c40\u9650\u5f97\u51fa\u8bbe\u8ba1\u539f\u5219\uff0c\u6784\u5efa\u7edf\u4e00\u56fe\u7d22\u5f15\u6574\u5408\u56db\u79cd\u68c0\u7d22\u8def\u5f84\uff0c\u8bbe\u8ba1GPU\u52a0\u901f\u6784\u5efa\u7ba1\u9053\uff0c\u5f15\u5165\u52a8\u6001\u878d\u5408\u6846\u67b6\u3002", "result": "\u57286\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cAllan - Poe\u7aef\u5230\u7aef\u67e5\u8be2\u51c6\u786e\u6027\u9ad8\uff0c\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad81.5 - 186.4\u500d\uff0c\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u5f00\u9500\u3002", "conclusion": "Allan - Poe\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u6df7\u5408\u641c\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u4e09\u96be\u56f0\u5883\u3002"}}
{"id": "2511.00058", "pdf": "https://arxiv.org/pdf/2511.00058", "abs": "https://arxiv.org/abs/2511.00058", "authors": ["Paul Alexander Bilokon"], "title": "Computation as a Game", "categories": ["cs.CC", "cs.GT", "cs.LO", "03B70", "F.4.1"], "comment": null, "summary": "We present a unifying representation of computation as a two-player game\nbetween an \\emph{Algorithm} and \\emph{Nature}, grounded in domain theory and\ngame theory. The Algorithm produces progressively refined approximations within\na Scott domain, while Nature assigns penalties proportional to their distance\nfrom the true value. Correctness corresponds to equilibrium in the limit of\nrefinement. This framework allows us to define complexity classes\ngame-theoretically, characterizing $\\mathbf{P}$, $\\mathbf{NP}$, and related\nclasses as sets of problems admitting particular equilibria. The open question\n$\\mathbf{P} \\stackrel{?}{=} \\mathbf{NP}$ becomes a problem about the\nequivalence of Nash equilibria under differing informational and temporal\nconstraints.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u8ba1\u7b97\u8868\u793a\u4e3a\u7b97\u6cd5\u4e0e\u81ea\u7136\u7684\u4e8c\u4eba\u535a\u5f08\uff0c\u4ee5\u6b64\u6846\u67b6\u5b9a\u4e49\u590d\u6742\u5ea6\u7c7b\uff0c\u5c06P\u4e0eNP\u95ee\u9898\u8f6c\u5316\u4e3a\u7eb3\u4ec0\u5747\u8861\u7b49\u4ef7\u6027\u95ee\u9898\u3002", "motivation": "\u4ee5\u65b0\u89c6\u89d2\u7814\u7a76\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u89e3\u51b3\u5982P\u662f\u5426\u7b49\u4e8eNP\u7b49\u5f00\u653e\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u57df\u7406\u8bba\u548c\u535a\u5f08\u8bba\uff0c\u5c06\u8ba1\u7b97\u8868\u793a\u4e3a\u7b97\u6cd5\u4e0e\u81ea\u7136\u7684\u4e8c\u4eba\u535a\u5f08\uff0c\u7b97\u6cd5\u5728Scott\u57df\u4e2d\u751f\u6210\u8fd1\u4f3c\u503c\uff0c\u81ea\u7136\u6839\u636e\u4e0e\u771f\u503c\u7684\u8ddd\u79bb\u7ed9\u4e88\u60e9\u7f5a\u3002", "result": "\u80fd\u7528\u535a\u5f08\u8bba\u5b9a\u4e49\u590d\u6742\u5ea6\u7c7b\uff0c\u523b\u753bP\u3001NP\u7b49\u76f8\u5173\u7c7b\uff0c\u5c06P\u662f\u5426\u7b49\u4e8eNP\u95ee\u9898\u8f6c\u5316\u4e3a\u7279\u5b9a\u7ea6\u675f\u4e0b\u7eb3\u4ec0\u5747\u8861\u7684\u7b49\u4ef7\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7814\u7a76\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u76f8\u5173\u5f00\u653e\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.01064", "pdf": "https://arxiv.org/pdf/2511.01064", "abs": "https://arxiv.org/abs/2511.01064", "authors": ["Charles C. Margossian", "Lawrence K. Saul"], "title": "Generalized Guarantees for Variational Inference in the Presence of Even and Elliptical Symmetry", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": null, "summary": "We extend several recent results providing symmetry-based guarantees for\nvariational inference (VI) with location-scale families. VI approximates a\ntarget density~$p$ by the best match $q^*$ in a family $Q$ of tractable\ndistributions that in general does not contain $p$. It is known that VI can\nrecover key properties of $p$, such as its mean and correlation matrix, when\n$p$ and $Q$ exhibit certain symmetries and $q^*$ is found by minimizing the\nreverse Kullback-Leibler divergence. We extend these guarantees in two\nimportant directions. First, we provide symmetry-based guarantees for a broader\nfamily of divergences, highlighting the properties of variational objectives\nunder which VI provably recovers the mean and correlation matrix. Second, we\nobtain further guarantees for VI when the target density $p$ exhibits even and\nelliptical symmetries in some but not all of its coordinates. These partial\nsymmetries arise naturally in Bayesian hierarchical models, where the prior\ninduces a challenging geometry but still possesses axes of symmetry. We\nillustrate these theoretical results in a number of experimental settings.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53d8\u5206\u63a8\u7406\uff08VI\uff09\u4fdd\u8bc1\uff0c\u6db5\u76d6\u66f4\u5e7f\u6cdb\u7684\u6563\u5ea6\u5bb6\u65cf\u548c\u90e8\u5206\u5bf9\u79f0\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5df2\u77e5\u5728\u7279\u5b9a\u5bf9\u79f0\u6027\u548c\u53cd\u5411Kullback - Leibler\u6563\u5ea6\u4e0b\uff0cVI\u80fd\u6062\u590d\u76ee\u6807\u5bc6\u5ea6\u7684\u5173\u952e\u5c5e\u6027\uff0c\u4e3a\u6269\u5c55\u8fd9\u4e9b\u4fdd\u8bc1\u800c\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u4ece\u4e24\u4e2a\u65b9\u5411\u6269\u5c55\u4fdd\u8bc1\uff0c\u4e00\u662f\u9488\u5bf9\u66f4\u5e7f\u6cdb\u7684\u6563\u5ea6\u5bb6\u65cf\u63d0\u4f9b\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u4fdd\u8bc1\uff0c\u4e8c\u662f\u5728\u76ee\u6807\u5bc6\u5ea6\u90e8\u5206\u5750\u6807\u6709\u5bf9\u79f0\u65f6\u83b7\u5f97\u8fdb\u4e00\u6b65\u4fdd\u8bc1\u3002", "result": "\u5f97\u5230\u4e86\u66f4\u5e7f\u6cdb\u6563\u5ea6\u5bb6\u65cf\u548c\u90e8\u5206\u5bf9\u79f0\u60c5\u51b5\u4e0b\u7684VI\u4fdd\u8bc1\uff0c\u5e76\u5728\u591a\u4e2a\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u6210\u529f\u6269\u5c55\u4e86\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u53d8\u5206\u63a8\u7406\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u60c5\u51b5\u3002"}}
{"id": "2511.01211", "pdf": "https://arxiv.org/pdf/2511.01211", "abs": "https://arxiv.org/abs/2511.01211", "authors": ["Chaofeng Wu"], "title": "Novelty and Impact of Economics Papers", "categories": ["econ.GN", "cs.CE", "cs.CL", "cs.DL", "q-fin.EC"], "comment": null, "summary": "We propose a framework that recasts scientific novelty not as a single\nattribute of a paper, but as a reflection of its position within the evolving\nintellectual landscape. We decompose this position into two orthogonal\ndimensions: \\textit{spatial novelty}, which measures a paper's intellectual\ndistinctiveness from its neighbors, and \\textit{temporal novelty}, which\ncaptures its engagement with a dynamic research frontier. To operationalize\nthese concepts, we leverage Large Language Models to develop semantic isolation\nmetrics that quantify a paper's location relative to the full-text literature.\nApplying this framework to a large corpus of economics articles, we uncover a\nfundamental trade-off: these two dimensions predict systematically different\noutcomes. Temporal novelty primarily predicts citation counts, whereas spatial\nnovelty predicts disruptive impact. This distinction allows us to construct a\ntypology of semantic neighborhoods, identifying four archetypes associated with\ndistinct and predictable impact profiles. Our findings demonstrate that novelty\ncan be understood as a multidimensional construct whose different forms,\nreflecting a paper's strategic location, have measurable and fundamentally\ndistinct consequences for scientific progress.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u79d1\u5b66\u65b0\u9896\u6027\u89c6\u4e3a\u8bba\u6587\u5728\u77e5\u8bc6\u7248\u56fe\u4e2d\u4f4d\u7f6e\u7684\u53cd\u6620\u7684\u6846\u67b6\uff0c\u5206\u89e3\u4e3a\u7a7a\u95f4\u548c\u65f6\u95f4\u65b0\u9896\u6027\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\uff0c\u5e94\u7528\u4e8e\u7ecf\u6d4e\u5b66\u6587\u7ae0\u53d1\u73b0\u4e24\u79cd\u65b0\u9896\u6027\u9884\u6d4b\u4e0d\u540c\u7ed3\u679c\uff0c\u53ef\u6784\u5efa\u8bed\u4e49\u90bb\u57df\u7c7b\u578b\u5b66\u3002", "motivation": "\u91cd\u65b0\u5b9a\u4e49\u79d1\u5b66\u65b0\u9896\u6027\u7684\u6982\u5ff5\uff0c\u5c06\u5176\u4ece\u5355\u4e00\u5c5e\u6027\u8f6c\u53d8\u4e3a\u8bba\u6587\u5728\u4e0d\u65ad\u6f14\u53d8\u7684\u77e5\u8bc6\u7248\u56fe\u4e2d\u4f4d\u7f6e\u7684\u53cd\u6620\u3002", "method": "\u5c06\u8bba\u6587\u4f4d\u7f6e\u5206\u89e3\u4e3a\u7a7a\u95f4\u65b0\u9896\u6027\u548c\u65f6\u95f4\u65b0\u9896\u6027\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u8bed\u4e49\u9694\u79bb\u6307\u6807\u6765\u91cf\u5316\u8bba\u6587\u4e0e\u5168\u6587\u6587\u732e\u7684\u76f8\u5bf9\u4f4d\u7f6e\u3002", "result": "\u53d1\u73b0\u4e24\u79cd\u65b0\u9896\u6027\u7ef4\u5ea6\u9884\u6d4b\u4e0d\u540c\u7ed3\u679c\uff0c\u65f6\u95f4\u65b0\u9896\u6027\u4e3b\u8981\u9884\u6d4b\u5f15\u7528\u6b21\u6570\uff0c\u7a7a\u95f4\u65b0\u9896\u6027\u9884\u6d4b\u98a0\u8986\u6027\u5f71\u54cd\uff0c\u6784\u5efa\u4e86\u8bed\u4e49\u90bb\u57df\u7c7b\u578b\u5b66\u3002", "conclusion": "\u65b0\u9896\u6027\u662f\u4e00\u4e2a\u591a\u7ef4\u7ed3\u6784\uff0c\u4e0d\u540c\u5f62\u5f0f\u5bf9\u79d1\u5b66\u8fdb\u6b65\u6709\u53ef\u8861\u91cf\u4e14\u672c\u8d28\u4e0d\u540c\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.00769", "pdf": "https://arxiv.org/pdf/2511.00769", "abs": "https://arxiv.org/abs/2511.00769", "authors": ["Zheyuan Lai", "Michael C. H. Choi"], "title": "Information-theoretic minimax and submodular optimization algorithms for multivariate Markov chains", "categories": ["math.PR", "math.OC", "stat.CO", "49J35, 60J10, 60J22, 90C27, 91A05, 94A15, 94A17"], "comment": "34 pages, 6 figures", "summary": "We study an information-theoretic minimax problem for finite multivariate\nMarkov chains on $d$-dimensional product state spaces. Given a family $\\mathcal\nB=\\{P_1,\\ldots,P_n\\}$ of $\\pi$-stationary transition matrices and a class\n$\\mathcal F = \\mathcal{F}(\\mathbf{S})$ of factorizable models induced by a\npartition $\\mathbf S$ of the coordinate set $[d]$, we seek to minimize the\nworst-case information loss by analyzing $$\\min_{Q\\in\\mathcal\nF}\\max_{P\\in\\mathcal B} D_{\\mathrm{KL}}^{\\pi}(P\\|Q),$$ where\n$D_{\\mathrm{KL}}^{\\pi}(P\\|Q)$ is the $\\pi$-weighted KL divergence from $Q$ to\n$P$. We recast the above minimax problem into concave maximization over the\n$n$-probability-simplex via strong duality and Pythagorean identities that we\nderive. This leads us to formulate an information-theoretic game and show that\na mixed strategy Nash equilibrium always exists; and propose a projected\nsubgradient algorithm to approximately solve the minimax problem with provable\nguarantee. By transforming the minimax problem into an orthant submodular\nfunction in $\\mathbf{S}$, this motivates us to consider a max-min-max\nsubmodular optimization problem and investigate a two-layer subgradient-greedy\nprocedure to approximately solve this generalization. Numerical experiments for\nMarkov chains on the Curie-Weiss and Bernoulli-Laplace models illustrate the\npracticality of these proposed algorithms and reveals sparse optimal structures\nin these examples.", "AI": {"tldr": "\u7814\u7a76\u6709\u9650\u591a\u5143\u9a6c\u5c14\u53ef\u592b\u94fe\u4fe1\u606f\u8bba\u6781\u5c0f\u6781\u5927\u95ee\u9898\uff0c\u901a\u8fc7\u5bf9\u5076\u548c\u6052\u7b49\u5f0f\u8f6c\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7b97\u6cd5\u6c42\u89e3\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u7b97\u6cd5\u5b9e\u7528\u6027\u5e76\u63ed\u793a\u7a00\u758f\u6700\u4f18\u7ed3\u6784\u3002", "motivation": "\u6700\u5c0f\u5316\u6709\u9650\u591a\u5143\u9a6c\u5c14\u53ef\u592b\u94fe\u5728\u7ed9\u5b9a\u8f6c\u79fb\u77e9\u9635\u65cf\u548c\u53ef\u5206\u89e3\u6a21\u578b\u7c7b\u4e0b\u7684\u6700\u574f\u60c5\u51b5\u4fe1\u606f\u635f\u5931\u3002", "method": "\u901a\u8fc7\u5f3a\u5bf9\u5076\u548c\u6bd5\u8fbe\u54e5\u62c9\u65af\u6052\u7b49\u5f0f\u5c06\u6781\u5c0f\u6781\u5927\u95ee\u9898\u8f6c\u5316\u4e3a\u51f9\u6700\u5927\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u6295\u5f71\u6b21\u68af\u5ea6\u7b97\u6cd5\u6c42\u89e3\uff1b\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u6b63\u4ea4\u5b50\u6a21\u51fd\u6570\uff0c\u8003\u8651\u6700\u5927 - \u6700\u5c0f - \u6700\u5927\u5b50\u6a21\u4f18\u5316\u95ee\u9898\u5e76\u91c7\u7528\u4e24\u5c42\u6b21\u68af\u5ea6 - \u8d2a\u5fc3\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "\u8bc1\u660e\u4e86\u4fe1\u606f\u8bba\u535a\u5f08\u4e2d\u6df7\u5408\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\u5b58\u5728\uff1b\u63d0\u51fa\u7684\u7b97\u6cd5\u6709\u53ef\u8bc1\u660e\u7684\u4fdd\u8bc1\uff1b\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5b9e\u7528\u6027\uff0c\u63ed\u793a\u4e86\u7a00\u758f\u6700\u4f18\u7ed3\u6784\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6709\u9650\u591a\u5143\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u4fe1\u606f\u8bba\u6781\u5c0f\u6781\u5927\u95ee\u9898\uff0c\u5728\u5b9e\u9645\u6a21\u578b\u4e2d\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01333", "pdf": "https://arxiv.org/pdf/2511.01333", "abs": "https://arxiv.org/abs/2511.01333", "authors": ["Muhammad Ahmed Mohsin", "Muhammad Umer", "Ahsan Bilal", "Hassan Rizwan", "Sagnik Bhattacharya", "Muhammad Ali Jamshed", "John M. Cioffi"], "title": "Transformer-Based Sparse CSI Estimation for Non-Stationary Channels", "categories": ["cs.DC"], "comment": "ICC 2026", "summary": "Accurate and efficient estimation of Channel State Information (CSI) is\ncritical for next-generation wireless systems operating under non-stationary\nconditions, where user mobility, Doppler spread, and multipath dynamics rapidly\nalter channel statistics. Conventional pilot aided estimators incur substantial\noverhead, while deep learning approaches degrade under dynamic pilot patterns\nand time varying fading. This paper presents a pilot-aided Flash-Attention\nTransformer framework that unifies model-driven pilot acquisition with data\ndriven CSI reconstruction through patch-wise self-attention and a physics aware\ncomposite loss function enforcing phase alignment, correlation consistency, and\ntime frequency smoothness. Under a standardized 3GPP NR configuration, the\nproposed framework outperforms LMMSE and LSTM baselines by approximately 13 dB\nin phase invariant normalized mean-square error (NMSE) with markedly lower\nbit-error rate (BER), while reducing pilot overhead by 16 times. These results\ndemonstrate that attention based architectures enable reliable CSI recovery and\nenhanced spectral efficiency without compromising link quality, addressing a\nfundamental bottleneck in adaptive, low-overhead channel estimation for\nnon-stationary 5G and beyond-5G networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u6846\u67b6\u7528\u4e8e\u975e\u5e73\u7a33\u65e0\u7ebf\u7cfb\u7edf\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4f30\u8ba1\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\uff0c\u964d\u4f4e\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u975e\u5e73\u7a33\u6761\u4ef6\u4e0b\u4f30\u8ba1\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u5b58\u5728\u5f00\u9500\u5927\u3001\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eFlash - Attention\u7684Transformer\u6846\u67b6\uff0c\u7ed3\u5408\u6a21\u578b\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\uff0c\u91c7\u7528\u9010\u5757\u81ea\u6ce8\u610f\u529b\u548c\u7269\u7406\u611f\u77e5\u590d\u5408\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u6807\u51c6\u53163GPP NR\u914d\u7f6e\u4e0b\uff0c\u76f8\u4e0d\u53d8\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u6bd4LMMSE\u548cLSTM\u57fa\u7ebf\u4f4e\u7ea613dB\uff0c\u8bef\u7801\u7387\u66f4\u4f4e\uff0c\u5c06\u5bfc\u9891\u5f00\u9500\u964d\u4f4e16\u500d\u3002", "conclusion": "\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u67b6\u6784\u80fd\u5728\u4e0d\u5f71\u54cd\u94fe\u8def\u8d28\u91cf\u4e0b\u5b9e\u73b0\u53ef\u9760CSI\u6062\u590d\u548c\u63d0\u9ad8\u9891\u8c31\u6548\u7387\uff0c\u89e3\u51b3\u975e\u5e73\u7a335G\u53ca\u672a\u6765\u7f51\u7edc\u4f4e\u5f00\u9500\u4fe1\u9053\u4f30\u8ba1\u7684\u74f6\u9888\u3002"}}
{"id": "2511.00805", "pdf": "https://arxiv.org/pdf/2511.00805", "abs": "https://arxiv.org/abs/2511.00805", "authors": ["Rishita Agarwal", "Himanshu Singhal", "Peter Baile Chen", "Manan Roy Choudhury", "Dan Roth", "Vivek Gupta"], "title": "REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval", "categories": ["cs.IR"], "comment": "13 pages, 2 figures, 8 tables", "summary": "Answering natural language queries over relational data often requires\nretrieving and reasoning over multiple tables, yet most retrievers optimize\nonly for query-table relevance and ignore table table compatibility. We\nintroduce REAR (Retrieve, Expand and Refine), a three-stage, LLM-free framework\nthat separates semantic relevance from structural joinability for efficient,\nhigh-fidelity multi-table retrieval. REAR (i) retrieves query-aligned tables,\n(ii) expands these with structurally joinable tables via fast, precomputed\ncolumn-embedding comparisons, and (iii) refines them by pruning noisy or weakly\nrelated candidates. Empirically, REAR is retriever-agnostic and consistently\nimproves dense/sparse retrievers on complex table QA datasets (BIRD, MMQA, and\nSpider) by improving both multi-table retrieval quality and downstream SQL\nexecution. Despite being LLM-free, it delivers performance competitive with\nstate-of-the-art LLM-augmented retrieval systems (e.g.,ARM) while achieving\nmuch lower latency and cost. Ablations confirm complementary gains from\nexpansion and refinement, underscoring REAR as a practical, scalable building\nblock for table-based downstream tasks (e.g., Text-to-SQL).", "AI": {"tldr": "\u63d0\u51faREAR\u6846\u67b6\u7528\u4e8e\u591a\u8868\u68c0\u7d22\uff0c\u5728\u591a\u6570\u636e\u96c6\u63d0\u5347\u6548\u679c\uff0c\u4f4e\u5ef6\u8fdf\u4f4e\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u5668\u4ec5\u4f18\u5316\u67e5\u8be2 - \u8868\u76f8\u5173\u6027\uff0c\u5ffd\u7565\u8868\u95f4\u517c\u5bb9\u6027\uff0c\u65e0\u6cd5\u9ad8\u6548\u5904\u7406\u591a\u8868\u68c0\u7d22\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u3001\u65e0\u5927\u8bed\u8a00\u6a21\u578b\u7684REAR\u6846\u67b6\uff0c\u5305\u62ec\u68c0\u7d22\u3001\u6269\u5c55\u548c\u7cbe\u70bc\u3002", "result": "\u5728\u591a\u4e2a\u590d\u6742\u8868\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u591a\u8868\u68c0\u7d22\u8d28\u91cf\u548c\u4e0b\u6e38SQL\u6267\u884c\u6548\u679c\uff0c\u6027\u80fd\u4e0e\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u68c0\u7d22\u7cfb\u7edf\u76f8\u5f53\uff0c\u4e14\u5ef6\u8fdf\u548c\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "REAR\u662f\u57fa\u4e8e\u8868\u7684\u4e0b\u6e38\u4efb\u52a1\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7684\u6784\u5efa\u6a21\u5757\u3002"}}
{"id": "2511.01376", "pdf": "https://arxiv.org/pdf/2511.01376", "abs": "https://arxiv.org/abs/2511.01376", "authors": ["Jialong Zhou", "Ben Bals", "Matei Tinca", "Ai Guan", "Panagiotis Charalampopoulos", "Grigorios Loukides", "Solon P. Pissis"], "title": "Subtree Mode and Applications", "categories": ["cs.DS", "cs.DB"], "comment": "For reproduction, code available at\n  https://github.com/JialongZhou666/subtree-mode-mining", "summary": "The mode of a collection of values (i.e., the most frequent value in the\ncollection) is a key summary statistic. Finding the mode in a given range of an\narray of values is thus of great importance, and constructing a data structure\nto solve this problem is in fact the well-known Range Mode problem. In this\nwork, we introduce the Subtree Mode (SM) problem, the analogous problem in a\nleaf-colored tree, where the task is to compute the most frequent color in the\nleaves of the subtree of a given node. SM is motivated by several applications\nin domains such as text analytics and biology, where the data are hierarchical\nand can thus be represented as a (leaf-colored) tree. Our central contribution\nis a time-optimal algorithm for SM that computes the answer for every node of\nan input $N$-node tree in $O(N)$ time. We further show how our solution can be\nadapted for node-colored trees, or for computing the $k$ most frequent colors,\nin the optimal $O(N)$ time, for any given $k=O(1)$. Moreover, we prove that a\nsimilarly fast solution for when the input is a sink-colored directed acyclic\ngraph instead of a leaf-colored tree is highly unlikely. Our experiments on\nreal datasets with trees of up to 7.3 billion nodes demonstrate that our\nalgorithm is faster than baselines by at least one order of magnitude and much\nmore space efficient. Last, we present case studies showing the effectiveness\nof our approach in pattern mining and sequence-to-database search applications.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u5b50\u6811\u6a21\u5f0f\u95ee\u9898\uff0c\u63d0\u51fa\u65f6\u95f4\u6700\u4f18\u7b97\u6cd5\uff0c\u53ef\u5728O(N)\u65f6\u95f4\u5185\u8ba1\u7b97N\u8282\u70b9\u6811\u6bcf\u4e2a\u8282\u70b9\u7684\u7b54\u6848\uff0c\u8fd8\u5c55\u793a\u7b97\u6cd5\u5728\u591a\u65b9\u9762\u7684\u9002\u5e94\u6027\u548c\u4f18\u52bf\u3002", "motivation": "\u5728\u6587\u672c\u5206\u6790\u548c\u751f\u7269\u5b66\u7b49\u9886\u57df\uff0c\u6570\u636e\u5177\u6709\u5c42\u6b21\u7ed3\u6784\u53ef\u8868\u793a\u4e3a\u6811\uff0c\u56e0\u6b64\u63d0\u51fa\u5b50\u6811\u6a21\u5f0f\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65f6\u95f4\u6700\u4f18\u7b97\u6cd5\uff0c\u53ef\u5728O(N)\u65f6\u95f4\u5185\u8ba1\u7b97N\u8282\u70b9\u6811\u6bcf\u4e2a\u8282\u70b9\u7684\u7b54\u6848\uff0c\u8fd8\u5c55\u793a\u7b97\u6cd5\u5bf9\u4e0d\u540c\u60c5\u51b5\u7684\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7b97\u6cd5\u6bd4\u57fa\u7ebf\u81f3\u5c11\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7\u4e14\u66f4\u8282\u7701\u7a7a\u95f4\uff0c\u6848\u4f8b\u7814\u7a76\u663e\u793a\u7b97\u6cd5\u5728\u6a21\u5f0f\u6316\u6398\u548c\u5e8f\u5217\u5230\u6570\u636e\u5e93\u641c\u7d22\u5e94\u7528\u4e2d\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u89e3\u51b3\u5b50\u6811\u6a21\u5f0f\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u826f\u597d\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u6548\u7387\uff0c\u5728\u76f8\u5173\u5e94\u7528\u4e2d\u6709\u6548\uff0c\u800c\u5bf9\u4e8e\u6709\u5411\u65e0\u73af\u56fe\u7c7b\u4f3c\u5feb\u901f\u89e3\u51b3\u65b9\u6848\u4e0d\u592a\u53ef\u80fd\u3002"}}
{"id": "2511.00206", "pdf": "https://arxiv.org/pdf/2511.00206", "abs": "https://arxiv.org/abs/2511.00206", "authors": ["Dirk U. Wulff", "Rui Mata"], "title": "Advancing Cognitive Science with LLMs", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Cognitive science faces ongoing challenges in knowledge synthesis and\nconceptual clarity, in part due to its multifaceted and interdisciplinary\nnature. Recent advances in artificial intelligence, particularly the\ndevelopment of large language models (LLMs), offer tools that may help to\naddress these issues. This review examines how LLMs can support areas where the\nfield has historically struggled, including establishing cross-disciplinary\nconnections, formalizing theories, developing clear measurement taxonomies,\nachieving generalizability through integrated modeling frameworks, and\ncapturing contextual and individual variation. We outline the current\ncapabilities and limitations of LLMs in these domains, including potential\npitfalls. Taken together, we conclude that LLMs can serve as tools for a more\nintegrative and cumulative cognitive science when used judiciously to\ncomplement, rather than replace, human expertise.", "AI": {"tldr": "\u8ba4\u77e5\u79d1\u5b66\u9762\u4e34\u77e5\u8bc6\u6574\u5408\u548c\u6982\u5ff5\u6e05\u6670\u6027\u6311\u6218\uff0c\u672c\u6587\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982\u4f55\u52a9\u529b\u89e3\u51b3\uff0c\u6307\u51fa\u5176\u80fd\u529b\u3001\u5c40\u9650\u53ca\u5e94\u7528\u65b9\u5f0f\u3002", "motivation": "\u89e3\u51b3\u8ba4\u77e5\u79d1\u5b66\u56e0\u591a\u5b66\u79d1\u6027\u8d28\u5728\u77e5\u8bc6\u6574\u5408\u548c\u6982\u5ff5\u6e05\u6670\u6027\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u5ba1\u67e5LLMs\u5728\u8ba4\u77e5\u79d1\u5b66\u5386\u53f2\u4e0a\u56f0\u96be\u9886\u57df\u7684\u652f\u6301\u4f5c\u7528\uff0c\u5e76\u5206\u6790\u5176\u80fd\u529b\u548c\u5c40\u9650\u3002", "result": "\u660e\u786e\u4e86LLMs\u5728\u5efa\u7acb\u8de8\u5b66\u79d1\u8054\u7cfb\u3001\u5f62\u5f0f\u5316\u7406\u8bba\u7b49\u65b9\u9762\u7684\u80fd\u529b\u4e0e\u5c40\u9650\uff0c\u4ee5\u53ca\u6f5c\u5728\u9677\u9631\u3002", "conclusion": "\u660e\u667a\u4f7f\u7528LLMs\u53ef\u4f5c\u4e3a\u8865\u5145\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u7684\u5de5\u5177\uff0c\u63a8\u52a8\u8ba4\u77e5\u79d1\u5b66\u7684\u6574\u5408\u548c\u79ef\u7d2f\u3002"}}
{"id": "2511.00262", "pdf": "https://arxiv.org/pdf/2511.00262", "abs": "https://arxiv.org/abs/2511.00262", "authors": ["Romina Etezadi", "Sallam Abualhaija", "Chetan Arora", "Lionel Briand"], "title": "LLM-Driven Cost-Effective Requirements Change Impact Analysis", "categories": ["cs.SE", "D.2; I.2"], "comment": "28 pages, 6 figures", "summary": "Requirements are inherently subject to changes throughout the software\ndevelopment lifecycle. Within the limited budget available to requirements\nengineers, manually identifying the impact of such changes on other\nrequirements is both error-prone and effort-intensive. That might lead to\noverlooked impacted requirements, which, if not properly managed, can cause\nserious issues in the downstream tasks. Inspired by the growing potential of\nlarge language models (LLMs) across diverse domains, we propose ProReFiCIA, an\nLLM-driven approach for automatically identifying the impacted requirements\nwhen changes occur. We conduct an extensive evaluation of ProReFiCIA using\nseveral LLMs and prompts variants tailored to this task. Using the best\ncombination of an LLM and a prompt variant, ProReFiCIA achieves a recall of\n93.3% on a benchmark dataset and 95.8% on a newly created industry dataset,\ndemonstrating its strong effectiveness in identifying impacted requirements.\nFurther, the cost of applying ProReFiCIA remains small, as the engineer only\nneeds to review the generated results, which represent between 2.1% and 8.5% of\nthe entire set of requirements.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684ProReFiCIA\u65b9\u6cd5\u81ea\u52a8\u8bc6\u522b\u9700\u6c42\u53d8\u66f4\u5f71\u54cd\uff0c\u8bc4\u4f30\u6548\u679c\u597d\u4e14\u6210\u672c\u4f4e\u3002", "motivation": "\u624b\u52a8\u8bc6\u522b\u9700\u6c42\u53d8\u66f4\u5f71\u54cd\u6613\u51fa\u9519\u4e14\u8017\u8d39\u7cbe\u529b\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u51fa\u73b0\u4e25\u91cd\u95ee\u9898\u3002", "method": "\u63d0\u51faProReFiCIA\u65b9\u6cd5\uff0c\u7528\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u548c\u63d0\u793a\u53d8\u4f53\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53ec\u56de\u7387\u8fbe93.3%\uff0c\u65b0\u884c\u4e1a\u6570\u636e\u96c6\u8fbe95.8%\uff0c\u5de5\u7a0b\u5e08\u53ea\u9700\u5ba1\u67e52.1% - 8.5%\u7684\u9700\u6c42\u3002", "conclusion": "ProReFiCIA\u5728\u8bc6\u522b\u53d7\u5f71\u54cd\u9700\u6c42\u65b9\u9762\u975e\u5e38\u6709\u6548\uff0c\u4e14\u5e94\u7528\u6210\u672c\u4f4e\u3002"}}
{"id": "2511.00044", "pdf": "https://arxiv.org/pdf/2511.00044", "abs": "https://arxiv.org/abs/2511.00044", "authors": ["Kohei Tsuchiyama", "Andre Roehm", "Takatomo Mihana", "Ryoichi Horisaki"], "title": "ReLaX-Net: Reusing Layers for Parameter-Efficient Physical Neural Networks", "categories": ["cs.LG", "nlin.AO"], "comment": null, "summary": "Physical Neural Networks (PNN) are promising platforms for next-generation\ncomputing systems. However, recent advances in digital neural network\nperformance are largely driven by the rapid growth in the number of trainable\nparameters and, so far, demonstrated PNNs are lagging behind by several orders\nof magnitude in terms of scale. This mirrors size and performance constraints\nfound in early digital neural networks. In that period, efficient reuse of\nparameters contributed to the development of parameter-efficient architectures\nsuch as convolutional neural networks.\n  In this work, we numerically investigate hardware-friendly weight-tying for\nPNNs. Crucially, with many PNN systems, there is a time-scale separation\nbetween the fast dynamic active elements of the forward pass and the only\nslowly trainable elements implementing weights and biases. With this in mind,we\npropose the Reuse of Layers for eXpanding a Neural Network (ReLaX-Net)\narchitecture, which employs a simple layer-by-layer time-multiplexing scheme to\nincrease the effective network depth and efficiently use the number of\nparameters. We only require the addition of fast switches for existing PNNs. We\nvalidate ReLaX-Nets via numerical experiments on image classification and\nnatural language processing tasks. Our results show that ReLaX-Net improves\ncomputational performance with only minor modifications to a conventional PNN.\nWe observe a favorable scaling, where ReLaX-Nets exceed the performance of\nequivalent traditional RNNs or DNNs with the same number of parameters.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u7269\u7406\u795e\u7ecf\u7f51\u7edc\uff08PNN\uff09\u89c4\u6a21\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51faReLaX - Net\u67b6\u6784\uff0c\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u80fd\u63d0\u5347\u8ba1\u7b97\u6027\u80fd\u3002", "motivation": "\u5f53\u524dPNN\u5728\u89c4\u6a21\u4e0a\u8fdc\u843d\u540e\u4e8e\u6570\u5b57\u795e\u7ecf\u7f51\u7edc\uff0c\u501f\u9274\u65e9\u671f\u6570\u5b57\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u9ad8\u6548\u590d\u7528\u7684\u7ecf\u9a8c\uff0c\u63a2\u7d22\u9002\u5408PNN\u7684\u53c2\u6570\u590d\u7528\u65b9\u6cd5\u3002", "method": "\u6570\u503c\u7814\u7a76\u786c\u4ef6\u53cb\u597d\u7684\u6743\u91cd\u7ed1\u5b9a\uff0c\u63d0\u51faReLaX - Net\u67b6\u6784\uff0c\u91c7\u7528\u9010\u5c42\u65f6\u5206\u590d\u7528\u65b9\u6848\u589e\u52a0\u7f51\u7edc\u6709\u6548\u6df1\u5ea6\uff0c\u4ec5\u9700\u4e3a\u73b0\u6709PNN\u6dfb\u52a0\u5feb\u901f\u5f00\u5173\u3002", "result": "\u901a\u8fc7\u56fe\u50cf\u5206\u7c7b\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\uff0cReLaX - Net\u5728\u5bf9\u4f20\u7edfPNN\u8fdb\u884c\u5c11\u91cf\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u4e86\u8ba1\u7b97\u6027\u80fd\uff0c\u5728\u53c2\u6570\u6570\u91cf\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u4e86\u7b49\u6548\u7684\u4f20\u7edfRNN\u6216DNN\u3002", "conclusion": "ReLaX - Net\u67b6\u6784\u80fd\u6709\u6548\u63d0\u5347PNN\u7684\u8ba1\u7b97\u6027\u80fd\uff0c\u5728\u53c2\u6570\u590d\u7528\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.01790", "pdf": "https://arxiv.org/pdf/2511.01790", "abs": "https://arxiv.org/abs/2511.01790", "authors": ["Thorben Prein", "Willis O'Leary", "Aikaterini Flessa Savvidou", "Elcha\u00efma Bourneix", "Joonatan E. M. Laulainen"], "title": "A Synthesizability-Guided Pipeline for Materials Discovery", "categories": ["cs.CE", "cond-mat.mtrl-sci"], "comment": "Main: 10 pages, 4 figures, SI: 8 pages, 11 figures", "summary": "Computational materials discovery relies on the generation of plausible\ncrystal structures. The plausibility is typically judged through density\nfunctional theory methods which, while typically accurate at zero Kelvin, often\nfavor low-energy structures that are not experimentally accessible. We develop\na combined compositional and structural synthesizability score which provides\nan accurate way of predicting which compounds can actually be synthesized in a\nlaboratory. We use it to evaluate non-synthesized structures from the Materials\nProject, GNoME, and Alexandria, and identified several hundred highly\nsynthesizable candidates. We then predict synthesis pathways, conduct\ncorresponding experiments, and characterize the products across 16 targets,\nsuccessfully synthesizing 7 of 16. The entire experimental process was\ncompleted in only three days. Our results highlight omissions in lists of known\nsynthesized structures, deliver insights into the practical utility of current\nmaterials databases, and showcase the central role synthesizability prediction\ncan play in materials discovery.", "AI": {"tldr": "\u5f00\u53d1\u5408\u6210\u53ef\u884c\u6027\u5206\u6570\u8bc4\u4f30\u975e\u5408\u6210\u7ed3\u6784\uff0c\u786e\u5b9a\u5019\u9009\u7269\uff0c\u9884\u6d4b\u5408\u6210\u8def\u5f84\u5e76\u5b9e\u9a8c\uff0c\u6210\u529f\u5408\u6210\u90e8\u5206\u6750\u6599\uff0c\u51f8\u663e\u5408\u6210\u53ef\u884c\u6027\u9884\u6d4b\u5728\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u8ba1\u7b97\u6750\u6599\u53d1\u73b0\u4f9d\u8d56\u5408\u7406\u6676\u4f53\u7ed3\u6784\uff0c\u73b0\u6709\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u5e38\u503e\u5411\u4f4e\u80fd\u4f46\u5b9e\u9a8c\u96be\u83b7\u53d6\u7684\u7ed3\u6784\uff0c\u9700\u51c6\u786e\u9884\u6d4b\u5b9e\u9a8c\u5ba4\u53ef\u5408\u6210\u5316\u5408\u7269\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u7ec4\u5408\u548c\u7ed3\u6784\u5408\u6210\u53ef\u884c\u6027\u5206\u6570\uff0c\u8bc4\u4f30\u975e\u5408\u6210\u7ed3\u6784\uff0c\u9884\u6d4b\u5408\u6210\u8def\u5f84\u5e76\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u4ece\u6570\u636e\u5e93\u4e2d\u786e\u5b9a\u6570\u767e\u4e2a\u9ad8\u5408\u6210\u53ef\u884c\u6027\u5019\u9009\u7269\uff0c\u5bf916\u4e2a\u76ee\u6807\u5b9e\u9a8c\uff0c3\u5929\u5185\u6210\u529f\u5408\u62107\u4e2a\u3002", "conclusion": "\u7ed3\u679c\u663e\u793a\u5df2\u77e5\u5408\u6210\u7ed3\u6784\u5217\u8868\u6709\u9057\u6f0f\uff0c\u53cd\u6620\u5f53\u524d\u6750\u6599\u6570\u636e\u5e93\u5b9e\u7528\u6027\uff0c\u5c55\u793a\u5408\u6210\u53ef\u884c\u6027\u9884\u6d4b\u5728\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\u3002"}}
{"id": "2511.00369", "pdf": "https://arxiv.org/pdf/2511.00369", "abs": "https://arxiv.org/abs/2511.00369", "authors": ["Farjana Aktar", "Mohd Ruhul Ameen", "Akif Islam", "Md Ekramul Hamid"], "title": "Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "6 pages, 3 figures, 8 tables, Submitted to ICECTE 2026", "summary": "Achieving both accurate and interpretable classification of motor imagery EEG\nremains a key challenge in brain computer interface (BCI) research. This paper\ncompares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep\nlearning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS\npipeline combines filter bank common spatial pattern feature extraction with\nfuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet\nlearns hierarchical spatial temporal representations directly from raw EEG\ndata. In within-subject experiments, the fuzzy neural model performed better\n(68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43),\nwhile in cross-subject (LOSO) tests, the deep model exhibited stronger\ngeneralization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent\n+/- 16.22). The study provides practical guidance for selecting MI-BCI systems\naccording to design goals: interpretability or robustness across users. Future\ninvestigations into transformer based and hybrid neuro symbolic frameworks are\nexpected to advance transparent EEG decoding.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86ANFIS - FBCSP - PSO\u548cEEGNet\u5bf9\u8fd0\u52a8\u60f3\u8c61EEG\u7684\u5206\u7c7b\u6548\u679c\uff0c\u4e3a\u9009\u62e9MI - BCI\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5b9e\u73b0\u8fd0\u52a8\u60f3\u8c61EEG\u7684\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u5206\u7c7b\u662fBCI\u7814\u7a76\u7684\u5173\u952e\u6311\u6218\uff0c\u9700\u5bf9\u6bd4\u4e0d\u540c\u65b9\u6cd5\u6548\u679c\u3002", "method": "\u4f7f\u7528BCI Competition IV - 2a\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4ANFIS\uff08\u7ed3\u5408FBCSP\u7279\u5f81\u63d0\u53d6\u548c\u6a21\u7cca\u89c4\u5219\uff0c\u7528PSO\u4f18\u5316\uff09\u548cEEGNet\uff08\u76f4\u63a5\u4ece\u539f\u59cbEEG\u6570\u636e\u5b66\u4e60\u65f6\u7a7a\u8868\u5f81\uff09\u3002", "result": "\u5728\u53d7\u8bd5\u8005\u5185\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u7cca\u795e\u7ecf\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff1b\u5728\u8de8\u53d7\u8bd5\u8005\u6d4b\u8bd5\u4e2d\uff0c\u6df1\u5ea6\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u3002", "conclusion": "\u4e3a\u6839\u636e\u8bbe\u8ba1\u76ee\u6807\u9009\u62e9MI - BCI\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u672a\u6765\u53ef\u7814\u7a76\u57fa\u4e8eTransformer\u548c\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u63a8\u8fdbEEG\u89e3\u7801\u3002"}}
{"id": "2511.00865", "pdf": "https://arxiv.org/pdf/2511.00865", "abs": "https://arxiv.org/abs/2511.00865", "authors": ["Hangdong Zhao", "Zhenghong Yu", "Srinag Rao", "Simon Frisk", "Zhiwei Fan", "Paraschos Koutris"], "title": "FlowLog: Efficient and Extensible Datalog via Incrementality", "categories": ["cs.DB", "cs.PL"], "comment": "Accepted to VLDB 2026", "summary": "Datalog-based languages are regaining popularity as a powerful abstraction\nfor expressing recursive computations in domains such as program analysis and\ngraph processing. However, existing systems often face a trade-off between\nefficiency and extensibility. Engines like Souffle achieve high efficiency\nthrough domain-specific designs, but lack general-purpose flexibility. Others,\nlike RecStep, offer modularity by layering Datalog on traditional databases,\nbut struggle to integrate Datalog-specific optimizations.\n  This paper bridges this gap by presenting FlowLog, a new Datalog engine that\nuses an explicit relational IR per-rule to cleanly separate recursive control\n(e.g., semi-naive execution) from each rule's logical plan. This boundary lets\nus retain fine-grained, Datalog-aware optimizations at the logical layer, but\nalso reuse off-the-shelf database primitives at execution. At the logical level\n(i.e. IR), we apply proven SQL optimizations, such as logic fusion and subplan\nreuse. To address high volatility in recursive workloads, we adopt a\nrobustness-first approach that pairs a structural optimizer (avoiding\nworst-case joins) with sideways information passing (early filtering). Built\natop Differential Dataflow--a mature framework for streaming analytics--FlowLog\nsupports both batch and incremental Datalog and adds novel recursion-aware\noptimizations called Boolean (or algebraic) specialization. Our evaluation\nshows that FlowLog outperforms state-of-the-art Datalog engines and modern\ndatabases across a broad range of recursive workloads, achieving superior\nscalability while preserving a simple and extensible architecture.", "AI": {"tldr": "\u4ecb\u7ecd\u65b0Datalog\u5f15\u64ceFlowLog\uff0c\u5b83\u5206\u79bb\u9012\u5f52\u63a7\u5236\u4e0e\u903b\u8f91\u8ba1\u5212\uff0c\u7ed3\u5408\u4f18\u5316\u7b56\u7565\uff0c\u5728\u9012\u5f52\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709Datalog\u7cfb\u7edf\u5728\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u5b58\u5728\u6743\u8861\uff0c\u7f3a\u4e4f\u517c\u5177\u4e24\u8005\u7684\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u6bcf\u89c4\u5219\u663e\u5f0f\u5173\u7cfbIR\u5206\u79bb\u9012\u5f52\u63a7\u5236\u548c\u903b\u8f91\u8ba1\u5212\uff0c\u5e94\u7528SQL\u4f18\u5316\uff0c\u91c7\u7528\u9c81\u68d2\u6027\u4f18\u5148\u65b9\u6cd5\uff0c\u57fa\u4e8eDifferential Dataflow\u6784\u5efa\uff0c\u6dfb\u52a0\u9012\u5f52\u611f\u77e5\u4f18\u5316\u3002", "result": "FlowLog\u5728\u591a\u79cd\u9012\u5f52\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u8d85\u8d8a\u73b0\u6709Datalog\u5f15\u64ce\u548c\u73b0\u4ee3\u6570\u636e\u5e93\u3002", "conclusion": "FlowLog\u5728\u4fdd\u8bc1\u67b6\u6784\u7b80\u5355\u53ef\u6269\u5c55\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.01452", "pdf": "https://arxiv.org/pdf/2511.01452", "abs": "https://arxiv.org/abs/2511.01452", "authors": ["Leonardo Pedroso", "Andrea Agazzi", "W. P. M. H. Heemels", "Mauro Salazar"], "title": "Evolutionary Dynamics in Continuous-time Finite-state Mean Field Games - Part I: Equilibria", "categories": ["eess.SY", "cs.GT", "cs.SY", "math.OC"], "comment": null, "summary": "We study a dynamic game with a large population of players who choose actions\nfrom a finite set in continuous time. Each player has a state in a finite state\nspace that evolves stochastically with their actions. A player's reward depends\nnot only on their own state and action but also on the distribution of states\nand actions across the population, capturing effects such as congestion in\ntraffic networks. While prior work in evolutionary game theory has primarily\nfocused on static games without individual player state dynamics, we present\nthe first comprehensive evolutionary analysis of such dynamic games. We propose\nan evolutionary model together with a mean field approximation of the\nfinite-population game and establish strong approximation guarantees. We show\nthat standard solution concepts for dynamic games lack an evolutionary\ninterpretation, and we propose a new concept - the Mixed Stationary Nash\nEquilibrium (MSNE) - which admits one. We analyze the relationship between MSNE\nand the rest points of the mean field evolutionary model and study the\nevolutionary stability of MSNE.", "AI": {"tldr": "\u7814\u7a76\u8fde\u7eed\u65f6\u95f4\u5185\u5927\u91cf\u73a9\u5bb6\u7684\u52a8\u6001\u535a\u5f08\uff0c\u63d0\u51fa\u8fdb\u5316\u6a21\u578b\u3001\u5747\u503c\u573a\u8fd1\u4f3c\uff0c\u5f15\u5165\u65b0\u5747\u8861\u6982\u5ff5MSNE\u5e76\u5206\u6790\u5176\u6027\u8d28\u3002", "motivation": "\u4ee5\u5f80\u8fdb\u5316\u535a\u5f08\u7406\u8bba\u4e3b\u8981\u5173\u6ce8\u65e0\u4e2a\u4f53\u73a9\u5bb6\u72b6\u6001\u52a8\u6001\u7684\u9759\u6001\u535a\u5f08\uff0c\u672c\u6587\u8981\u5bf9\u542b\u73a9\u5bb6\u72b6\u6001\u52a8\u6001\u7684\u52a8\u6001\u535a\u5f08\u8fdb\u884c\u5168\u9762\u8fdb\u5316\u5206\u6790\u3002", "method": "\u63d0\u51fa\u8fdb\u5316\u6a21\u578b\u548c\u6709\u9650\u7fa4\u4f53\u535a\u5f08\u7684\u5747\u503c\u573a\u8fd1\u4f3c\uff0c\u5efa\u7acb\u8fd1\u4f3c\u4fdd\u8bc1\uff1b\u63d0\u51fa\u65b0\u7684\u5747\u8861\u6982\u5ff5MSNE\u3002", "result": "\u8868\u660e\u6807\u51c6\u52a8\u6001\u535a\u5f08\u89e3\u6982\u5ff5\u7f3a\u4e4f\u8fdb\u5316\u89e3\u91ca\uff0c\u5206\u6790\u4e86MSNE\u4e0e\u5747\u503c\u573a\u8fdb\u5316\u6a21\u578b\u9a7b\u70b9\u7684\u5173\u7cfb\u4ee5\u53caMSNE\u7684\u8fdb\u5316\u7a33\u5b9a\u6027\u3002", "conclusion": "\u6210\u529f\u5bf9\u542b\u73a9\u5bb6\u72b6\u6001\u52a8\u6001\u7684\u52a8\u6001\u535a\u5f08\u8fdb\u884c\u8fdb\u5316\u5206\u6790\uff0c\u5f15\u5165\u7684MSNE\u6982\u5ff5\u6709\u8fdb\u5316\u89e3\u91ca\uff0c\u53ef\u7528\u4e8e\u7814\u7a76\u6b64\u7c7b\u52a8\u6001\u535a\u5f08\u3002"}}
{"id": "2511.01096", "pdf": "https://arxiv.org/pdf/2511.01096", "abs": "https://arxiv.org/abs/2511.01096", "authors": ["Alex Boyd", "Andrew Warrington", "Taha Kass-Hout", "Parminder Bhatia", "Danica Xiao"], "title": "Hyper Hawkes Processes: Interpretable Models of Marked Temporal Point Processes", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Foundational marked temporal point process (MTPP) models, such as the Hawkes\nprocess, often use inexpressive model families in order to offer interpretable\nparameterizations of event data. On the other hand, neural MTPPs models forego\nthis interpretability in favor of absolute predictive performance. In this\nwork, we present a new family MTPP models: the hyper Hawkes process (HHP),\nwhich aims to be as flexible and performant as neural MTPPs, while retaining\ninterpretable aspects. To achieve this, the HHP extends the classical Hawkes\nprocess to increase its expressivity by first expanding the dimension of the\nprocess into a latent space, and then introducing a hypernetwork to allow time-\nand data-dependent dynamics. These extensions define a highly performant MTPP\nfamily, achieving state-of-the-art performance across a range of benchmark\ntasks and metrics. Furthermore, by retaining the linearity of the recurrence,\nalbeit now piecewise and conditionally linear, the HHP also retains much of the\nstructure of the original Hawkes process, which we exploit to create direct\nprobes into how the model creates predictions. HHP models therefore offer both\nstate-of-the-art predictions, while also providing an opportunity to ``open the\nbox'' and inspect how predictions were generated.", "AI": {"tldr": "\u63d0\u51fa\u8d85Hawkes\u8fc7\u7a0b\uff08HHP\uff09\u6a21\u578b\uff0c\u517c\u5177\u795e\u7ecfMTPPs\u6027\u80fd\u548c\u7ecf\u5178Hawkes\u8fc7\u7a0b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u7840MTPP\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u5f31\uff0c\u795e\u7ecfMTPPs\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u5e0c\u671b\u65b0\u6a21\u578b\u517c\u5177\u4e24\u8005\u4f18\u70b9\u3002", "method": "\u5c06\u7ecf\u5178Hawkes\u8fc7\u7a0b\u6269\u5c55\u5230\u6f5c\u5728\u7a7a\u95f4\uff0c\u5f15\u5165\u8d85\u7f51\u7edc\u5b9e\u73b0\u65f6\u95f4\u548c\u6570\u636e\u4f9d\u8d56\u52a8\u6001\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u57fa\u51c6\u4efb\u52a1\u548c\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "HHP\u6a21\u578b\u65e2\u80fd\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u9884\u6d4b\uff0c\u53c8\u80fd\u89e3\u91ca\u9884\u6d4b\u751f\u6210\u65b9\u5f0f\u3002"}}
{"id": "2511.01332", "pdf": "https://arxiv.org/pdf/2511.01332", "abs": "https://arxiv.org/abs/2511.01332", "authors": ["Xiufeng Li", "Zefang Li"], "title": "Internet of Things Platform Service Supply Innovation: Exploring the Impact of Overconfidence", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper explores the impact of manufacturers' overconfidence on their\ncollaborative innovation with platforms in the Internet of Things (IoT)\nenvironment by constructing a game model. It is found that in both usage-based\nand revenue-sharing contracts, manufacturers' and platforms' innovation inputs,\nprofit levels, and pricing strategies are significantly affected by the\nproportion of non-privacy-sensitive customers, and grow in tandem with the rise\nof this proportion. In usage-based contracts, moderate overconfidence\nincentivizes manufacturers to increase hardware innovation investment and\nimprove overall supply chain revenues, but may cause platforms to reduce\nsoftware innovation; under revenue-sharing contracts, overconfidence positively\nincentivizes hardware innovation and pricing more strongly, while platform\nsoftware innovation varies nonlinearly depending on the share ratio. Comparing\nthe differences in manufacturers' decisions with and without overconfidence\nsuggests that moderate overconfidence can lead to supply chain Pareto\nimprovements under a given contract. This paper provides new perspectives for\nunderstanding the complex interactions between manufacturers and platforms in\nIoT supply chains, as well as theoretical support and practical guidance for\nactual business decisions.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u535a\u5f08\u6a21\u578b\u63a2\u8ba8\u7269\u8054\u7f51\u73af\u5883\u4e0b\u5236\u9020\u5546\u8fc7\u5ea6\u81ea\u4fe1\u5bf9\u5176\u4e0e\u5e73\u53f0\u534f\u540c\u521b\u65b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u540c\u5408\u540c\u4e0b\u76f8\u5173\u56e0\u7d20\u53d7\u975e\u9690\u79c1\u654f\u611f\u5ba2\u6237\u6bd4\u4f8b\u5f71\u54cd\uff0c\u9002\u5ea6\u8fc7\u5ea6\u81ea\u4fe1\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u80fd\u5e26\u6765\u4f9b\u5e94\u94fe\u5e15\u7d2f\u6258\u6539\u8fdb\u3002", "motivation": "\u7814\u7a76\u7269\u8054\u7f51\u73af\u5883\u4e0b\u5236\u9020\u5546\u8fc7\u5ea6\u81ea\u4fe1\u5bf9\u5176\u4e0e\u5e73\u53f0\u534f\u540c\u521b\u65b0\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u535a\u5f08\u6a21\u578b\u3002", "result": "\u4e0d\u540c\u5408\u540c\u4e0b\u521b\u65b0\u6295\u5165\u3001\u5229\u6da6\u6c34\u5e73\u548c\u5b9a\u4ef7\u7b56\u7565\u53d7\u975e\u9690\u79c1\u654f\u611f\u5ba2\u6237\u6bd4\u4f8b\u5f71\u54cd\uff1b\u4e0d\u540c\u5408\u540c\u4e0b\u8fc7\u5ea6\u81ea\u4fe1\u5bf9\u521b\u65b0\u548c\u5b9a\u4ef7\u6709\u4e0d\u540c\u5f71\u54cd\uff1b\u9002\u5ea6\u8fc7\u5ea6\u81ea\u4fe1\u5728\u7ed9\u5b9a\u5408\u540c\u4e0b\u53ef\u5e26\u6765\u4f9b\u5e94\u94fe\u5e15\u7d2f\u6258\u6539\u8fdb\u3002", "conclusion": "\u4e3a\u7406\u89e3\u7269\u8054\u7f51\u4f9b\u5e94\u94fe\u4e2d\u5236\u9020\u5546\u4e0e\u5e73\u53f0\u7684\u590d\u6742\u4e92\u52a8\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u4e3a\u5b9e\u9645\u5546\u4e1a\u51b3\u7b56\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2511.01040", "pdf": "https://arxiv.org/pdf/2511.01040", "abs": "https://arxiv.org/abs/2511.01040", "authors": ["Junjie Ma", "Xiaoya Zhang", "Guangye He", "Yuting Han", "Ting Ge", "Feng Ji"], "title": "From Path Coefficients to Targeted Estimands: A Comparison of Structural Equation Models (SEM) and Targeted Maximum Likelihood Estimation (TMLE)", "categories": ["stat.OT", "stat.AP", "stat.CO"], "comment": null, "summary": "Structural Equation Modeling (SEM) has gained popularity in the social\nsciences and causal inference due to its flexibility in modeling complex\nrelationships between variables and its availability in modern statistical\nsoftware. To move beyond the parametric assumptions of SEM, this paper reviews\ntargeted maximum likelihood estimation (TMLE), a doubly robust, machine\nlearning-based approach that builds on nonparametric SEM. We demonstrate that\nboth TMLE and SEM can be used to estimate standard causal effects and show that\nTMLE is robust to model misspecification. We conducted simulation studies under\nboth correct and misspecified model conditions, implementing SEM and TMLE to\nestimate these causal effects. The simulations confirm that TMLE consistently\noutperforms SEM under misspecification in terms of bias, mean squared error,\nand the validity of confidence intervals. We applied both approaches to a\nreal-world dataset to analyze the mediation effects of poverty on access to\nhigh school, revealing that the direct effect is no longer significant under\nTMLE, whereas SEM indicates significance. We conclude with practical guidance\non using SEM and TMLE in light of recent developments in targeted learning for\ncausal inference.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u57fa\u4e8e\u975e\u53c2\u6570\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\uff08SEM\uff09\u7684\u6709\u9488\u5bf9\u6027\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08TMLE\uff09\uff0c\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548c\u5b9e\u9645\u6570\u636e\u96c6\u5206\u6790\u5bf9\u6bd4TMLE\u548cSEM\uff0c\u8868\u660eTMLE\u5728\u6a21\u578b\u9519\u8bef\u8bbe\u5b9a\u65f6\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u7ed9\u51fa\u5e94\u7528\u6307\u5bfc\u3002", "motivation": "\u7a81\u7834SEM\u7684\u53c2\u6570\u5047\u8bbe\uff0c\u5bfb\u627e\u66f4\u4f18\u7684\u56e0\u679c\u6548\u5e94\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u8fdb\u884c\u6a21\u62df\u7814\u7a76\uff0c\u5728\u6b63\u786e\u548c\u9519\u8bef\u8bbe\u5b9a\u6a21\u578b\u6761\u4ef6\u4e0b\u5b9e\u65bdSEM\u548cTMLE\u4f30\u8ba1\u56e0\u679c\u6548\u5e94\uff0c\u5e76\u5c06\u4e24\u79cd\u65b9\u6cd5\u5e94\u7528\u4e8e\u5b9e\u9645\u6570\u636e\u96c6\u5206\u6790\u8d2b\u56f0\u5bf9\u9ad8\u4e2d\u5165\u5b66\u673a\u4f1a\u7684\u4e2d\u4ecb\u6548\u5e94\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8bc1\u5b9eTMLE\u5728\u6a21\u578b\u9519\u8bef\u8bbe\u5b9a\u65f6\uff0c\u5728\u504f\u5dee\u3001\u5747\u65b9\u8bef\u5dee\u548c\u7f6e\u4fe1\u533a\u95f4\u6709\u6548\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8eSEM\uff1b\u5b9e\u9645\u6570\u636e\u96c6\u5206\u6790\u663e\u793aTMLE\u4e0b\u76f4\u63a5\u6548\u5e94\u4e0d\u518d\u663e\u8457\uff0c\u800cSEM\u663e\u793a\u663e\u8457\u3002", "conclusion": "\u7ed3\u5408\u76ee\u6807\u5b66\u4e60\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u6700\u65b0\u53d1\u5c55\uff0c\u7ed9\u51fa\u4f7f\u7528SEM\u548cTMLE\u7684\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2511.01420", "pdf": "https://arxiv.org/pdf/2511.01420", "abs": "https://arxiv.org/abs/2511.01420", "authors": ["Christoph Lenzen"], "title": "Gradient Clock Synchronization with Practically Constant Local Skew", "categories": ["cs.DC"], "comment": "38 pages, no figures, submitted to STOC 2026", "summary": "Gradient Clock Synchronization (GCS) is the task of minimizing the local\nskew, i.e., the clock offset between neighboring clocks, in a larger network.\nWhile asymptotically optimal bounds are known, from a practical perspective\nthey have crucial shortcomings:\n  - Local skew bounds are determined by upper bounds on offset estimation that\nneed to be guaranteed throughout the entire lifetime of the system.\n  - Worst-case frequency deviations of local oscillators from their nominal\nrate are assumed, yet frequencies tend to be much more stable in the (relevant)\nshort term.\n  State-of-the-art deployed synchronization methods adapt to the true offset\nmeasurement and frequency errors, but achieve no non-trivial guarantees on the\nlocal skew.\n  In this work, we provide a refined model and novel analysis of existing\ntechniques for solving GCS in this model. By requiring only stability of\nmeasurement and frequency errors, we can circumvent existing lower bounds,\nleading to dramatic improvements under very general conditions. For example, if\nlinks exhibit a uniform worst-case estimation error of $\\Delta$ and a change in\nestimation errors of $\\delta\\ll \\Delta$ on relevant time scales, we bound the\nlocal skew by $O(\\Delta+\\delta \\log D)$ for networks of diameter $D$,\neffectively ``breaking'' the established $\\Omega(\\Delta\\log D)$ lower bound,\nwhich holds when $\\delta=\\Delta$. Similarly, we show how to limit the influence\nof local oscillators on $\\delta$ to scale with the change of frequency of an\nindividual oscillator on relevant time scales, rather than a worst-case bound\nover all oscillators and the lifetime of the system.\n  Moreover, we show how to ensure self-stabilization in this challenging\nsetting. Last, but not least, we extend all of our results to the scenario of\nexternal synchronization, at the cost of a limited increase in stabilization\ntime.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u68af\u5ea6\u65f6\u949f\u540c\u6b65\uff08GCS\uff09\u95ee\u9898\uff0c\u63d0\u51fa\u6539\u8fdb\u6a21\u578b\u548c\u65b0\u5206\u6790\u65b9\u6cd5\uff0c\u5728\u4e00\u822c\u6761\u4ef6\u4e0b\u5927\u5e45\u6539\u8fdb\u7ed3\u679c\uff0c\u8fd8\u5b9e\u73b0\u81ea\u7a33\u5b9a\u5e76\u6269\u5c55\u5230\u5916\u90e8\u540c\u6b65\u573a\u666f\u3002", "motivation": "\u73b0\u6709GCS\u6e10\u8fd1\u6700\u4f18\u8fb9\u754c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u5173\u952e\u7f3a\u9677\uff0c\u4e14\u73b0\u6709\u540c\u6b65\u65b9\u6cd5\u65e0\u6cd5\u5bf9\u672c\u5730\u504f\u5dee\u63d0\u4f9b\u975e\u5e73\u51e1\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u6539\u8fdb\u6a21\u578b\uff0c\u4ec5\u8981\u6c42\u6d4b\u91cf\u548c\u9891\u7387\u8bef\u5dee\u7684\u7a33\u5b9a\u6027\uff0c\u4ee5\u6b64\u7ed5\u8fc7\u73b0\u6709\u4e0b\u754c\u3002", "result": "\u5728\u4e00\u822c\u6761\u4ef6\u4e0b\u5b9e\u73b0\u663e\u8457\u6539\u8fdb\uff0c\u7a81\u7834\u65e2\u5b9a\u4e0b\u754c\uff0c\u9650\u5236\u672c\u5730\u632f\u8361\u5668\u5f71\u54cd\uff0c\u5e76\u5b9e\u73b0\u81ea\u7a33\u5b9a\uff0c\u53ef\u6269\u5c55\u5230\u5916\u90e8\u540c\u6b65\u573a\u666f\u3002", "conclusion": "\u6539\u8fdb\u7684\u6a21\u578b\u548c\u5206\u6790\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5728GCS\u95ee\u9898\u4e0a\u53d6\u5f97\u66f4\u597d\u7ed3\u679c\uff0c\u4e14\u53ef\u6269\u5c55\u5230\u5916\u90e8\u540c\u6b65\u3002"}}
{"id": "2511.00875", "pdf": "https://arxiv.org/pdf/2511.00875", "abs": "https://arxiv.org/abs/2511.00875", "authors": ["Amirabbas Afzali", "Amirreza Velae", "Iman Ahmadi", "Mohammad Aliannejadi"], "title": "Controlling Gender Bias in Retrieval via a Backpack Architecture", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "The presence of social biases in large language models (LLMs) has become a\nsignificant concern in AI research. These biases, often embedded in training\ndata, can perpetuate harmful stereotypes and distort decision-making processes.\nWhen LLMs are integrated into ranking systems, they can propagate these biases,\nleading to unfair outcomes in critical applications such as search engines and\nrecommendation systems. Backpack Language Models, unlike traditional\ntransformer-based models that treat text sequences as monolithic structures,\ngenerate outputs as weighted combinations of non-contextual, learned word\naspects, also known as senses. Leveraging this architecture, we propose a\nframework for debiasing ranking tasks. Our experimental results show that this\nframework effectively mitigates gender bias in text retrieval and ranking with\nminimal degradation in performance.", "AI": {"tldr": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8eBackpack\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u7684\u53bb\u504f\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u6709\u6548\u51cf\u8f7b\u6027\u522b\u504f\u89c1\u4e14\u6027\u80fd\u635f\u5931\u5c0f\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u793e\u4f1a\u504f\u89c1\uff0c\u878d\u5165\u6392\u5e8f\u7cfb\u7edf\u4f1a\u4f20\u64ad\u504f\u89c1\u5bfc\u81f4\u4e0d\u516c\u5e73\u7ed3\u679c\uff0c\u9700\u89e3\u51b3\u6392\u5e8f\u4efb\u52a1\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u5229\u7528Backpack\u8bed\u8a00\u6a21\u578b\u67b6\u6784\uff0c\u751f\u6210\u8f93\u51fa\u4f5c\u4e3a\u975e\u4e0a\u4e0b\u6587\u3001\u5b66\u4e60\u5230\u7684\u8bcd\u65b9\u9762\uff08\u5373\u8bed\u4e49\uff09\u7684\u52a0\u6743\u7ec4\u5408\uff0c\u63d0\u51fa\u53bb\u504f\u6846\u67b6\u3002", "result": "\u6846\u67b6\u6709\u6548\u51cf\u8f7b\u6587\u672c\u68c0\u7d22\u548c\u6392\u5e8f\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u6027\u80fd\u4ec5\u6709\u6700\u5c0f\u7a0b\u5ea6\u7684\u4e0b\u964d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eBackpack\u67b6\u6784\u7684\u53bb\u504f\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u6392\u5e8f\u4efb\u52a1\u4e2d\u7684\u6027\u522b\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2511.01769", "pdf": "https://arxiv.org/pdf/2511.01769", "abs": "https://arxiv.org/abs/2511.01769", "authors": ["Omri Ben-Eliezer", "Krzysztof Onak", "Sandeep Silwal"], "title": "Robust Streaming Against Low-Memory Adversaries", "categories": ["cs.DS"], "comment": null, "summary": "Robust streaming, the study of streaming algorithms that provably work when\nthe stream is generated by an adaptive adversary, has seen tremendous progress\nin recent years. However, fundamental barriers remain: the best known algorithm\nfor turnstile $F_p$-estimation in the robust streaming setting is exponentially\nworse than in the oblivious setting, and closing this gap seems difficult.\nArguably, one possible cause of this barrier is the adversarial model, which\nmay be too strong: unlike the space-bounded streaming algorithm, the adversary\ncan memorize the entire history of the interaction with the algorithm. Can we\nthen close the exponential gap if we insist that the adversary itself is an\nadaptive but low-memory entity, roughly as powerful as (or even weaker than)\nthe algorithm?\n  In this work we present the first set of models and results aimed towards\nthis question. We design efficient robust streaming algorithms against\nadversaries that are fully adaptive but have no long-term memory (\"memoryless\")\nor very little memory of the history of interaction. Roughly speaking, a\nmemoryless adversary only sees, at any given round, the last output of the\nalgorithm (and does not even know the current time) and can generate an\nunlimited number of independent coin tosses. A low-memory adversary is similar,\nbut maintains an additional small buffer. While these adversaries may seem\nquite limited at first glance, we show that this adversarial model is strong\nenough to produce streams that have high flip number and density in the context\nof $F_2$-estimation, which rules out most of known robustification techniques.\nWe then design a new simple approach, similar to the computation paths\nframework, to obtain efficient algorithms against memoryless and low-memory\nadversaries for a wide class of order-invariant problems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d7\u9650\u5185\u5b58\u5bf9\u624b\u4e0b\u7684\u9c81\u68d2\u6d41\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u9488\u5bf9\u65e0\u8bb0\u5fc6\u548c\u4f4e\u8bb0\u5fc6\u5bf9\u624b\u7684\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e00\u7c7b\u987a\u5e8f\u4e0d\u53d8\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9c81\u68d2\u6d41\u7b97\u6cd5\u4e2d\uff0c\u5bf9\u6297\u6a21\u578b\u5bf9\u624b\u80fd\u529b\u8fc7\u5f3a\uff0c\u5bfc\u81f4\u7b97\u6cd5\u6027\u80fd\u4e0e\u975e\u5bf9\u6297\u573a\u666f\u5dee\u8ddd\u5927\uff0c\u5e0c\u671b\u901a\u8fc7\u9650\u5236\u5bf9\u624b\u5185\u5b58\u6765\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u8bbe\u8ba1\u9488\u5bf9\u65e0\u8bb0\u5fc6\u548c\u4f4e\u8bb0\u5fc6\u5bf9\u624b\u7684\u9c81\u68d2\u6d41\u7b97\u6cd5\uff0c\u91c7\u7528\u7c7b\u4f3c\u8ba1\u7b97\u8def\u5f84\u6846\u67b6\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u8be5\u5bf9\u6297\u6a21\u578b\u80fd\u751f\u6210\u9ad8\u7ffb\u8f6c\u6570\u548c\u5bc6\u5ea6\u7684\u6d41\uff0c\u6392\u9664\u4e86\u591a\u6570\u5df2\u77e5\u9c81\u68d2\u5316\u6280\u672f\uff1b\u8bbe\u8ba1\u51fa\u9488\u5bf9\u65e0\u8bb0\u5fc6\u548c\u4f4e\u8bb0\u5fc6\u5bf9\u624b\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u9650\u5236\u5bf9\u624b\u5185\u5b58\u53ef\u8bbe\u8ba1\u51fa\u9ad8\u6548\u9c81\u68d2\u6d41\u7b97\u6cd5\u89e3\u51b3\u4e00\u7c7b\u987a\u5e8f\u4e0d\u53d8\u95ee\u9898\u3002"}}
{"id": "2511.00267", "pdf": "https://arxiv.org/pdf/2511.00267", "abs": "https://arxiv.org/abs/2511.00267", "authors": ["Christian Prothmann", "Vijay Gadepally", "Jeremy Kepner", "Koley Borchard", "Luca Carlone", "Zachary Folcik", "J. Daniel Grith", "Michael Houle", "Jonathan P. How", "Nathan Hughes", "Ifueko Igbinedion", "Hayden Jananthan", "Tejas Jayashankar", "Michael Jones", "Sertac Karaman", "Binoy G. Kurien", "Alejandro Lancho", "Giovanni Lavezzi", "Gary C. F. Lee", "Charles E. Leiserson", "Richard Linares", "Lindsey McEvoy", "Peter Michaleas", "Chasen Milner", "Alex Pentland", "Yury Polyanskiy", "Jovan Popovich", "Jeffrey Price", "Tim W. Reid", "Stephanie Riley", "Siddharth Samsi", "Peter Saunders", "Olga Simek", "Mark S. Veillette", "Amir Weiss", "Gregory W. Wornell", "Daniela Rus", "Scott T. Ruppel"], "title": "Advancing AI Challenges for the United States Department of the Air Force", "categories": ["cs.AI", "cs.CY", "cs.GL", "cs.LG"], "comment": "8 pages, 8 figures, 59 references. To appear in IEEE HPEC 2025", "summary": "The DAF-MIT AI Accelerator is a collaboration between the United States\nDepartment of the Air Force (DAF) and the Massachusetts Institute of Technology\n(MIT). This program pioneers fundamental advances in artificial intelligence\n(AI) to expand the competitive advantage of the United States in the defense\nand civilian sectors. In recent years, AI Accelerator projects have developed\nand launched public challenge problems aimed at advancing AI research in\npriority areas. Hallmarks of AI Accelerator challenges include large, publicly\navailable, and AI-ready datasets to stimulate open-source solutions and engage\nthe wider academic and private sector AI ecosystem. This article supplements\nour previous publication, which introduced AI Accelerator challenges. We\nprovide an update on how ongoing and new challenges have successfully\ncontributed to AI research and applications of AI technologies.", "AI": {"tldr": "\u4ecb\u7ecdDAF - MIT AI Accelerator\u9879\u76ee\uff0c\u5176\u4e0e\u7f8e\u7a7a\u519b\u548cMIT\u5408\u4f5c\uff0c\u5f00\u5c55\u6311\u6218\u63a8\u52a8AI\u7814\u7a76\uff0c\u672c\u6587\u66f4\u65b0\u6311\u6218\u5bf9AI\u8d21\u732e\u60c5\u51b5\u3002", "motivation": "\u5f00\u62d3\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u8fdb\u6b65\uff0c\u6269\u5927\u7f8e\u56fd\u5728\u56fd\u9632\u548c\u6c11\u7528\u9886\u57df\u7ade\u4e89\u4f18\u52bf\u3002", "method": "\u5f00\u5c55AI\u6311\u6218\u9879\u76ee\uff0c\u63d0\u4f9b\u5927\u578b\u516c\u5f00\u4e14\u9002\u7528\u4e8eAI\u7684\u6570\u636e\u96c6\uff0c\u6fc0\u53d1\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u6301\u7eed\u548c\u65b0\u7684\u6311\u6218\u6210\u529f\u4fc3\u8fdb\u4e86\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u548c\u6280\u672f\u5e94\u7528\u3002", "conclusion": "AI Accelerator\u9879\u76ee\u7684\u6311\u6218\u5bf9AI\u7814\u7a76\u548c\u5e94\u7528\u6709\u79ef\u6781\u8d21\u732e\u3002"}}
{"id": "2511.00417", "pdf": "https://arxiv.org/pdf/2511.00417", "abs": "https://arxiv.org/abs/2511.00417", "authors": ["Marcel Valovy"], "title": "Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework", "categories": ["cs.SE", "cs.AI", "cs.HC", "H.5.3; D.2.9; I.2.0"], "comment": "PhD Dissertation, Prague University of Economics and Business, 2025.\n  323 pages. ACM CCS 2012: Human-computer interaction, Collaborative\n  interaction, Human-AI collaborative systems, Pair programming, AI-assisted\n  software engineering", "summary": "As artificial intelligence transforms software development, a critical\nquestion emerges: how can developers and AI systems collaborate most\neffectively? This dissertation optimizes human-AI programming roles through\nself-determination theory and personality psychology, introducing the Role\nOptimization Motivation Alignment (ROMA) framework.\n  Through Design Science Research spanning five cycles, this work establishes\nempirically-validated connections between personality traits, programming role\npreferences, and collaborative outcomes, engaging 200 experimental participants\nand 46 interview respondents.\n  Key findings demonstrate that personality-driven role optimization\nsignificantly enhances self-determination and team dynamics, yielding 23%\naverage motivation increases among professionals and up to 65% among\nundergraduates. Five distinct personality archetypes emerge: The Explorer (high\nOpenness/low Agreeableness), The Orchestrator (high\nExtraversion/Agreeableness), The Craftsperson (high Neuroticism/low\nExtraversion), The Architect (high Conscientiousness), and The Adapter\n(balanced profile). Each exhibits distinct preferences for programming roles\n(Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for\nsatisfaction.\n  The dissertation contributes: (1) an empirically-validated framework linking\npersonality traits to role preferences and self-determination outcomes; (2) a\ntaxonomy of AI collaboration modalities mapped to personality profiles while\npreserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small\nEntities to implement personality-driven role optimization within established\nstandards.\n  Keywords: artificial intelligence, human-computer interaction, behavioral\nsoftware engineering, self-determination theory, personality psychology,\nphenomenology, intrinsic motivation, pair programming, design science research,\nISO/IEC 29110", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u81ea\u51b3\u7406\u8bba\u548c\u4eba\u683c\u5fc3\u7406\u5b66\u4f18\u5316\u4eba\u673a\u7f16\u7a0b\u89d2\u8272\uff0c\u63d0\u51faROMA\u6846\u67b6\uff0c\u7ecf\u7814\u7a76\u5f97\u51fa\u4eba\u683c\u9a71\u52a8\u7684\u89d2\u8272\u4f18\u5316\u80fd\u63d0\u5347\u81ea\u51b3\u548c\u56e2\u961f\u52a8\u529b\u7b49\u6210\u679c\uff0c\u5e76\u505a\u51fa\u591a\u65b9\u9762\u8d21\u732e\u3002", "motivation": "\u63a2\u8ba8\u5f00\u53d1\u8005\u4e0eAI\u7cfb\u7edf\u5982\u4f55\u6700\u6709\u6548\u5730\u534f\u4f5c\uff0c\u4f18\u5316\u4eba\u673a\u7f16\u7a0b\u89d2\u8272\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\uff0c\u5386\u7ecf\u4e94\u4e2a\u5468\u671f\uff0c\u8ba9200\u540d\u5b9e\u9a8c\u53c2\u4e0e\u8005\u548c46\u540d\u53d7\u8bbf\u8005\u53c2\u4e0e\u7814\u7a76\u3002", "result": "\u4eba\u683c\u9a71\u52a8\u7684\u89d2\u8272\u4f18\u5316\u663e\u8457\u63d0\u5347\u81ea\u51b3\u548c\u56e2\u961f\u52a8\u529b\uff0c\u4e13\u4e1a\u4eba\u5458\u5e73\u5747\u52a8\u529b\u63d0\u534723%\uff0c\u672c\u79d1\u751f\u6700\u9ad8\u63d0\u534765%\uff0c\u5e76\u5f97\u51fa\u4e94\u79cd\u4eba\u683c\u539f\u578b\u53ca\u7f16\u7a0b\u89d2\u8272\u504f\u597d\u3002", "conclusion": "\u8d21\u732e\u4e86\u5c06\u4eba\u683c\u7279\u8d28\u4e0e\u89d2\u8272\u504f\u597d\u548c\u81ea\u51b3\u7ed3\u679c\u8054\u7cfb\u7684\u6846\u67b6\u3001\u6620\u5c04\u5230\u4eba\u683c\u8f6e\u5ed3\u7684AI\u534f\u4f5c\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff0c\u4ee5\u53ca\u4f7f\u5c0f\u578b\u5b9e\u4f53\u80fd\u5728\u6807\u51c6\u5185\u5b9e\u73b0\u4eba\u683c\u9a71\u52a8\u89d2\u8272\u4f18\u5316\u7684ISO/IEC 29110\u6269\u5c55\u3002"}}
{"id": "2511.00047", "pdf": "https://arxiv.org/pdf/2511.00047", "abs": "https://arxiv.org/abs/2511.00047", "authors": ["Omkar Kulkarni", "Rohitash Chandra"], "title": "DynBERG: Dynamic BERT-based Graph neural network for financial fraud detection", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Financial fraud detection is critical for maintaining the integrity of\nfinancial systems, particularly in decentralised environments such as\ncryptocurrency networks. Although Graph Convolutional Networks (GCNs) are\nwidely used for financial fraud detection, graph Transformer models such as\nGraph-BERT are gaining prominence due to their Transformer-based architecture,\nwhich mitigates issues such as over-smoothing. Graph-BERT is designed for\nstatic graphs and primarily evaluated on citation networks with undirected\nedges. However, financial transaction networks are inherently dynamic, with\nevolving structures and directed edges representing the flow of money. To\naddress these challenges, we introduce DynBERG, a novel architecture that\nintegrates Graph-BERT with a Gated Recurrent Unit (GRU) layer to capture\ntemporal evolution over multiple time steps. Additionally, we modify the\nunderlying algorithm to support directed edges, making DynBERG well-suited for\ndynamic financial transaction analysis. We evaluate our model on the Elliptic\ndataset, which includes Bitcoin transactions, including all transactions during\na major cryptocurrency market event, the Dark Market Shutdown. By assessing\nDynBERG's resilience before and after this event, we analyse its ability to\nadapt to significant market shifts that impact transaction behaviours. Our\nmodel is benchmarked against state-of-the-art dynamic graph classification\napproaches, such as EvolveGCN and GCN, demonstrating superior performance,\noutperforming EvolveGCN before the market shutdown and surpassing GCN after the\nevent. Additionally, an ablation study highlights the critical role of\nincorporating a time-series deep learning component, showcasing the\neffectiveness of GRU in modelling the temporal dynamics of financial\ntransactions.", "AI": {"tldr": "\u63d0\u51faDynBERG\u67b6\u6784\u7528\u4e8e\u52a8\u6001\u91d1\u878d\u4ea4\u6613\u5206\u6790\uff0c\u5728Elliptic\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6d88\u878d\u5b9e\u9a8c\u51f8\u663eGRU\u4f5c\u7528\u3002", "motivation": "\u73b0\u6709\u56feTransformer\u6a21\u578b\u4e0d\u9002\u7528\u4e8e\u52a8\u6001\u91d1\u878d\u4ea4\u6613\u7f51\u7edc\uff0c\u9700\u65b0\u65b9\u6cd5\u5904\u7406\u5176\u52a8\u6001\u7ed3\u6784\u548c\u6709\u5411\u8fb9\u3002", "method": "\u5c06Graph - BERT\u4e0eGRU\u5c42\u96c6\u6210\uff0c\u4fee\u6539\u7b97\u6cd5\u652f\u6301\u6709\u5411\u8fb9\uff0c\u5728Elliptic\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u4e0eEvolveGCN\u548cGCN\u7b49\u57fa\u51c6\u5bf9\u6bd4\uff0c\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\u3002", "result": "DynBERG\u6027\u80fd\u4f18\u4e8eEvolveGCN\u548cGCN\uff0c\u6d88\u878d\u5b9e\u9a8c\u8868\u660eGRU\u5bf9\u5efa\u6a21\u91d1\u878d\u4ea4\u6613\u65f6\u95f4\u52a8\u6001\u6709\u6548\u3002", "conclusion": "DynBERG\u9002\u7528\u4e8e\u52a8\u6001\u91d1\u878d\u4ea4\u6613\u5206\u6790\uff0c\u80fd\u9002\u5e94\u91cd\u5927\u5e02\u573a\u53d8\u5316\uff0cGRU\u5728\u5efa\u6a21\u65f6\u95f4\u52a8\u6001\u65b9\u9762\u5173\u952e\u3002"}}
{"id": "2511.00529", "pdf": "https://arxiv.org/pdf/2511.00529", "abs": "https://arxiv.org/abs/2511.00529", "authors": ["Botao 'Amber' Hu"], "title": "On Improvisation and Open-Endedness: Insights for Experiential AI", "categories": ["cs.HC", "cs.AI", "cs.NE", "cs.SY", "eess.SY"], "comment": "Submitted to AAAI 2026 Creative AI for Live Interactive Performances\n  Workshop (CLIP) as a work-in-progress paper", "summary": "Improvisation-the art of spontaneous creation that unfolds moment-to-moment\nwithout a scripted outcome-requires practitioners to continuously sense, adapt,\nand create anew. It is a fundamental mode of human creativity spanning music,\ndance, and everyday life. The open-ended nature of improvisation produces a\nstream of novel, unrepeatable moments-an aspect highly valued in artistic\ncreativity. In parallel, open-endedness (OE)-a system's capacity for unbounded\nnovelty and endless \"interestingness\"-is exemplified in natural or cultural\nevolution and has been considered \"the last grand challenge\" in artificial life\n(ALife). The rise of generative AI now raises the question in computational\ncreativity (CC) research: What makes a \"good\" improvisation for AI? Can AI\nlearn to improvise in a genuinely open-ended way? In this work-in-progress\npaper, we report insights from in-depth interviews with 6 experts in\nimprovisation across dance, music, and contact improvisation. We draw systemic\nconnections between human improvisational arts and the design of future\nexperiential AI agents that could improvise alone or alongside humans-or even\nwith other AI agents-embodying qualities of improvisation drawn from practice:\nactive listening (umwelt and awareness), being in the time (mindfulness and\nephemerality), embracing the unknown (source of randomness and serendipity),\nnon-judgmental flow (acceptance and dynamical stability, balancing structure\nand surprise (unpredictable criticality at edge of chaos), imaginative metaphor\n(synaesthesia and planning), empathy, trust, boundary, and care (mutual theory\nof mind), and playfulness and intrinsic motivation (maintaining\ninterestingness).", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8AI\u5373\u5174\u521b\u4f5c\u95ee\u9898\uff0c\u901a\u8fc7\u8bbf\u8c08\u4e13\u5bb6\u5efa\u7acb\u4eba\u7c7b\u5373\u5174\u827a\u672f\u4e0e\u672a\u6765\u4f53\u9a8c\u5f0fAI\u4ee3\u7406\u8bbe\u8ba1\u7684\u8054\u7cfb\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5174\u8d77\uff0c\u5f15\u53d1\u8ba1\u7b97\u521b\u9020\u529b\u7814\u7a76\u4e2d\u5173\u4e8eAI\u201c\u597d\u201d\u7684\u5373\u5174\u521b\u4f5c\u53ca\u80fd\u5426\u771f\u6b63\u5f00\u653e\u5f0f\u5373\u5174\u7684\u95ee\u9898\u3002", "method": "\u5bf9\u821e\u8e48\u3001\u97f3\u4e50\u548c\u63a5\u89e6\u5373\u5174\u7b49\u9886\u57df\u76846\u4f4d\u4e13\u5bb6\u8fdb\u884c\u6df1\u5ea6\u8bbf\u8c08\u3002", "result": "\u5efa\u7acb\u4e86\u4eba\u7c7b\u5373\u5174\u827a\u672f\u4e0e\u672a\u6765\u4f53\u9a8c\u5f0fAI\u4ee3\u7406\u8bbe\u8ba1\u7684\u7cfb\u7edf\u6027\u8054\u7cfb\uff0c\u660e\u786e\u4e86AI\u5e94\u5177\u5907\u7684\u5373\u5174\u7279\u8d28\u3002", "conclusion": "\u53ef\u4f9d\u636e\u4eba\u7c7b\u5373\u5174\u827a\u672f\u5b9e\u8df5\u8bbe\u8ba1\u51fa\u80fd\u5355\u72ec\u6216\u4e0e\u4eba\u7c7b\u3001\u5176\u4ed6AI\u4e00\u8d77\u5373\u5174\u521b\u4f5c\u7684\u4f53\u9a8c\u5f0fAI\u4ee3\u7406\u3002"}}
{"id": "2511.00985", "pdf": "https://arxiv.org/pdf/2511.00985", "abs": "https://arxiv.org/abs/2511.00985", "authors": ["Yiwen Jiao", "Tonghui Ren", "Yuche Gao", "Zhenying He", "Yinan Jing", "Kai Zhang", "X. Sean Wang"], "title": "ORANGE: An Online Reflection ANd GEneration framework with Domain Knowledge for Text-to-SQL", "categories": ["cs.DB", "cs.AI", "cs.CL"], "comment": "16 pages, 4 figures, preprint", "summary": "Large Language Models (LLMs) have demonstrated remarkable progress in\ntranslating natural language to SQL, but a significant semantic gap persists\nbetween their general knowledge and domain-specific semantics of databases.\nHistorical translation logs constitute a rich source of this missing in-domain\nknowledge, where SQL queries inherently encapsulate real-world usage patterns\nof database schema. Existing methods primarily enhance the reasoning process\nfor individual translations but fail to accumulate in-domain knowledge from\npast translations. We introduce ORANGE, an online self-evolutionary framework\nthat constructs database-specific knowledge bases by parsing SQL queries from\ntranslation logs. By accumulating in-domain knowledge that contains schema and\ndata semantics, ORANGE progressively reduces the semantic gap and enhances the\naccuracy of subsequent SQL translations. To ensure reliability, we propose a\nnovel nested Chain-of-Thought SQL-to-Text strategy with tuple-semantic\ntracking, which reduces semantic errors during knowledge generation.\nExperiments on multiple benchmarks confirm the practicality of ORANGE,\ndemonstrating its effectiveness for real-world Text-to-SQL deployment,\nparticularly in handling complex and domain-specific queries.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u8f6cSQL\u5b58\u5728\u8bed\u4e49\u5dee\u8ddd\uff0c\u63d0\u51faORANGE\u6846\u67b6\u79ef\u7d2f\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u8f6cSQL\u65f6\u5b58\u5728\u901a\u7528\u77e5\u8bc6\u4e0e\u6570\u636e\u5e93\u7279\u5b9a\u9886\u57df\u8bed\u4e49\u7684\u5dee\u8ddd\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u79ef\u7d2f\u8fc7\u5f80\u7ffb\u8bd1\u7684\u9886\u57df\u77e5\u8bc6\u3002", "method": "\u5f15\u5165ORANGE\u5728\u7ebf\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u6790\u7ffb\u8bd1\u65e5\u5fd7\u4e2d\u7684SQL\u67e5\u8be2\u6784\u5efa\u7279\u5b9a\u6570\u636e\u5e93\u77e5\u8bc6\u5e93\uff0c\u8fd8\u63d0\u51fa\u5d4c\u5957\u601d\u7ef4\u94feSQL\u5230\u6587\u672c\u7b56\u7565\u8ddf\u8e2a\u5143\u7ec4\u8bed\u4e49\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc1\u5b9e\u4e86ORANGE\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "ORANGE\u80fd\u6709\u6548\u7f29\u5c0f\u8bed\u4e49\u5dee\u8ddd\uff0c\u63d0\u9ad8SQL\u7ffb\u8bd1\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u6587\u672c\u5230SQL\u90e8\u7f72\uff0c\u5c24\u5176\u5904\u7406\u590d\u6742\u548c\u7279\u5b9a\u9886\u57df\u67e5\u8be2\u3002"}}
{"id": "2511.01140", "pdf": "https://arxiv.org/pdf/2511.01140", "abs": "https://arxiv.org/abs/2511.01140", "authors": ["Md Talha Mohsin", "Ismail Abdulrashid"], "title": "Few-Shot Multimodal Medical Imaging: A Theoretical Framework", "categories": ["stat.ML", "cs.AI", "cs.CV", "cs.LG", "eess.IV"], "comment": "6 Pages", "summary": "Medical imaging relies heavily on large, labeled datasets. But,\nunfortunately, they are not always easily accessible in clinical settings.\nAdditionally, many practitioners often face various structural obstacles like\nlimited data availability, fragmented data systems, and unbalanced datasets.\nThese barriers often lead to the increased diagnostic uncertainty,\nunderrepresentation of certain conditions, reduced model robustness, and biased\ndiagnostic decisions. In response to these challenges, approaches such as\ntransfer learning, meta-learning, and multimodal fusion have made great\nstrides. However, they still need a solid theoretical justification for why\nthey succeed or fail in situations where data is scarce. To address this gap,\nwe propose a unified theoretical framework that characterizes learning and\ninference under low-resource medical imaging conditions. We first formalize the\nlearning objective under few-shot conditions and compute sample complexity\nconstraints to estimate the smallest quantity of data needed to achieve\nclinically reliable accuracy. Then based on ideas from PAC-learning and\nPAC-Bayesian theory, we explain how multimodal integration encourages\ngeneralization and quantifies uncertainty under sparse supervision. We further\npropose a formal metric for explanation stability, offering interpretability\nguarantees under low-data conditions. Taken together, the proposed framework\nestablishes a principled foundation for constructing dependable, data-efficient\ndiagnostic systems by jointly characterizing sample efficiency, uncertainty\nquantification, and interpretability in a unified theoretical setting.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u533b\u5b66\u5f71\u50cf\u7f3a\u4e4f\u5927\u7684\u6807\u6ce8\u6570\u636e\u96c6\u53ca\u9762\u4e34\u7ed3\u6784\u969c\u788d\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u7406\u8bba\u4f9d\u636e\uff0c\u63d0\u51fa\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u89e3\u51b3\u4f4e\u8d44\u6e90\u533b\u5b66\u5f71\u50cf\u95ee\u9898\u3002", "motivation": "\u533b\u5b66\u5f71\u50cf\u4e34\u5e8a\u4e2d\u96be\u4ee5\u83b7\u53d6\u5927\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5b58\u5728\u6570\u636e\u53ef\u7528\u6027\u6709\u9650\u3001\u7cfb\u7edf\u788e\u7247\u5316\u3001\u6570\u636e\u4e0d\u5e73\u8861\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u652f\u6491\u3002", "method": "\u5148\u5f62\u5f0f\u5316\u5c11\u6837\u672c\u5b66\u4e60\u76ee\u6807\u5e76\u8ba1\u7b97\u6837\u672c\u590d\u6742\u5ea6\u7ea6\u675f\uff0c\u57fa\u4e8ePAC\u5b66\u4e60\u548cPAC\u8d1d\u53f6\u65af\u7406\u8bba\u89e3\u91ca\u591a\u6a21\u6001\u96c6\u6210\uff0c\u63d0\u51fa\u89e3\u91ca\u7a33\u5b9a\u6027\u7684\u5f62\u5f0f\u5316\u6307\u6807\u3002", "result": "\u5efa\u7acb\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u8054\u5408\u8868\u5f81\u6837\u672c\u6548\u7387\u3001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6784\u5efa\u53ef\u9760\u3001\u6570\u636e\u9ad8\u6548\u7684\u8bca\u65ad\u7cfb\u7edf\u5960\u5b9a\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002"}}
{"id": "2511.01473", "pdf": "https://arxiv.org/pdf/2511.01473", "abs": "https://arxiv.org/abs/2511.01473", "authors": ["Elena Pisanelli"], "title": "Measuring Domestic Violence. Individual Attitudes and Time Use Within the Household", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper proposes a novel empirical strategy to measure cultural\njustifications of domestic violence within households, with direct implications\nfor demographic behavior and gender inequality. Leveraging survey data on\nindividual attitudes and high-frequency time-use diaries from Italian couples\nwith children, I construct a composite index that integrates stated beliefs\nwith observed household practices. Using structural equation modeling, I\ndisentangle latent tolerance of domestic violence from reported attitudes and\nvalidate the index against both individual and partner characteristics, as well\nas time allocation patterns. Results reveal systematic heterogeneity by gender,\neducation, and normative environments. Conservative gender and parenthood norms\nare strong predictors of tolerance, while higher male education reduces it.\nTolerance of violence is also positively associated with reported leisure time\nwith partners and children, suggesting that co-presence does not necessarily\nreflect egalitarian interaction but may coexist with unequal bargaining\nstructures. Beyond advancing measurement, the findings highlight how cultural\ntolerance of domestic violence is embedded in household arrangements that\ninfluence fertility, labor supply, and the intergenerational transmission of\nnorms. The proposed framework offers a scalable tool for economists and\npolicymakers to monitor hidden inequalities and design interventions targeting\nfamily stability, gender equity, and child well-being.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8861\u91cf\u5bb6\u5ead\u5185\u5bb6\u5ead\u66b4\u529b\u6587\u5316\u7406\u7531\u7684\u7b56\u7565\uff0c\u6784\u5efa\u6307\u6570\u5e76\u9a8c\u8bc1\uff0c\u53d1\u73b0\u5bb9\u5fcd\u5ea6\u7684\u5f71\u54cd\u56e0\u7d20\uff0c\u6846\u67b6\u53ef\u52a9\u76d1\u6d4b\u4e0d\u5e73\u7b49\u548c\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\u3002", "motivation": "\u63d0\u51fa\u8861\u91cf\u5bb6\u5ead\u5185\u5bb6\u5ead\u66b4\u529b\u6587\u5316\u7406\u7531\u7684\u7b56\u7565\uff0c\u5176\u5bf9\u4eba\u53e3\u884c\u4e3a\u548c\u6027\u522b\u4e0d\u5e73\u7b49\u6709\u76f4\u63a5\u5f71\u54cd\u3002", "method": "\u5229\u7528\u610f\u5927\u5229\u6709\u5b69\u5b50\u592b\u5987\u7684\u8c03\u67e5\u6570\u636e\u6784\u5efa\u7efc\u5408\u6307\u6570\uff0c\u7528\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u5206\u79bb\u6f5c\u5728\u5bb9\u5fcd\u5ea6\u5e76\u9a8c\u8bc1\u6307\u6570\u3002", "result": "\u5bb9\u5fcd\u5ea6\u5b58\u5728\u6027\u522b\u3001\u6559\u80b2\u548c\u89c4\u8303\u73af\u5883\u7684\u5f02\u8d28\u6027\uff0c\u4fdd\u5b88\u89c4\u8303\u662f\u5f3a\u9884\u6d4b\u56e0\u7d20\uff0c\u7537\u6027\u9ad8\u6559\u80b2\u964d\u4f4e\u5bb9\u5fcd\u5ea6\uff0c\u5bb9\u5fcd\u5ea6\u4e0e\u4f11\u95f2\u65f6\u95f4\u6b63\u76f8\u5173\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7ecf\u6d4e\u5b66\u5bb6\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u76d1\u6d4b\u4e0d\u5e73\u7b49\u548c\u8bbe\u8ba1\u5e72\u9884\u63aa\u65bd\u7684\u5de5\u5177\u3002"}}
{"id": "2511.01573", "pdf": "https://arxiv.org/pdf/2511.01573", "abs": "https://arxiv.org/abs/2511.01573", "authors": ["Melanie Tonarelli", "Simone Riva", "Pietro Benedusi", "Fabrizio Ferrandi", "Rolf Krause"], "title": "Adaptive Multidimensional Quadrature on Multi-GPU Systems", "categories": ["cs.DC"], "comment": "9 pages, 8 figures. Submitted to the proceedings of the 29th\n  International Conference on Domain Decomposition Methods (DD29)", "summary": "We introduce a distributed adaptive quadrature method that formulates\nmultidimensional integration as a hierarchical domain decomposition problem on\nmulti-GPU architectures. The integration domain is recursively partitioned into\nsubdomains whose refinement is guided by local error estimators. Each subdomain\nevolves independently on a GPU, which exposes a significant load imbalance as\nthe adaptive process progresses. To address this challenge, we introduce a\ndecentralised load redistribution schemes based on a cyclic round-robin policy.\nThis strategy dynamically rebalance subdomains across devices through\nnon-blocking, CUDA-aware MPI communication that overlaps with computation. The\nproposed strategy has two main advantages compared to a state-of-the-art\nGPU-tailored package: higher efficiency in high dimensions; and improved\nrobustness w.r.t the integrand regularity and the target accuracy.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u79ef\u5206\u65b9\u6cd5\uff0c\u53ef\u89e3\u51b3\u591a GPU \u67b6\u6784\u4e0a\u591a\u7ef4\u79ef\u5206\u95ee\u9898\uff0c\u8fd8\u63d0\u51fa\u8d1f\u8f7d\u91cd\u5206\u914d\u65b9\u6848\uff0c\u6bd4\u73b0\u6709\u65b9\u6848\u66f4\u9ad8\u6548\u3001\u7a33\u5065\u3002", "motivation": "\u89e3\u51b3\u591a GPU \u67b6\u6784\u4e0a\u81ea\u9002\u5e94\u79ef\u5206\u8fc7\u7a0b\u4e2d\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u5c06\u591a\u7ef4\u79ef\u5206\u8868\u793a\u4e3a\u591a GPU \u67b6\u6784\u4e0a\u7684\u5206\u5c42\u57df\u5206\u89e3\u95ee\u9898\uff0c\u901a\u8fc7\u5c40\u90e8\u8bef\u5dee\u4f30\u8ba1\u5668\u6307\u5bfc\u5b50\u57df\u7ec6\u5316\uff0c\u91c7\u7528\u57fa\u4e8e\u5faa\u73af\u8f6e\u8be2\u7b56\u7565\u7684\u5206\u6563\u5f0f\u8d1f\u8f7d\u91cd\u5206\u914d\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u975e\u963b\u585e\u3001\u652f\u6301 CUDA \u7684 MPI \u901a\u4fe1\u52a8\u6001\u91cd\u65b0\u5e73\u8861\u8bbe\u5907\u95f4\u7684\u5b50\u57df\u3002", "conclusion": "\u8be5\u7b56\u7565\u6bd4\u73b0\u6709 GPU \u5b9a\u5236\u5305\u5728\u9ad8\u7ef4\u4e0a\u66f4\u9ad8\u6548\uff0c\u5bf9\u88ab\u79ef\u51fd\u6570\u6b63\u5219\u6027\u548c\u76ee\u6807\u7cbe\u5ea6\u7684\u9c81\u68d2\u6027\u66f4\u597d\u3002"}}
{"id": "2511.01208", "pdf": "https://arxiv.org/pdf/2511.01208", "abs": "https://arxiv.org/abs/2511.01208", "authors": ["Jerry Huang", "Siddarth Madala", "Cheng Niu", "Julia Hockenmaier", "Tong Zhang"], "title": "Contextual Relevance and Adaptive Sampling for LLM-Based Document Reranking", "categories": ["cs.IR"], "comment": null, "summary": "Reranking algorithms have made progress in improving document retrieval\nquality by efficiently aggregating relevance judgments generated by large\nlanguage models (LLMs). However, identifying relevant documents for queries\nthat require in-depth reasoning remains a major challenge. Reasoning-intensive\nqueries often exhibit multifaceted information needs and nuanced\ninterpretations, rendering document relevance inherently context dependent. To\naddress this, we propose contextual relevance, which we define as the\nprobability that a document is relevant to a given query, marginalized over the\ndistribution of different reranking contexts it may appear in (i.e., the set of\ncandidate documents it is ranked alongside and the order in which the documents\nare presented to a reranking model). While prior works have studied methods to\nmitigate the positional bias LLMs exhibit by accounting for the ordering of\ndocuments, we empirically find that the compositions of these batches also\nplays an important role in reranking performance. To efficiently estimate\ncontextual relevance, we propose TS-SetRank, a sampling-based,\nuncertainty-aware reranking algorithm. Empirically, TS-SetRank improves nDCG@10\nover retrieval and reranking baselines by 15-25% on BRIGHT and 6-21% on BEIR,\nhighlighting the importance of modeling relevance as context-dependent.", "AI": {"tldr": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u6982\u5ff5\u548cTS - SetRank\u7b97\u6cd5\uff0c\u80fd\u63d0\u5347\u6587\u6863\u91cd\u6392\u5e8f\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u91cd\u6392\u5e8f\u7b97\u6cd5\u5728\u5904\u7406\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u7684\u67e5\u8be2\u65f6\uff0c\u8bc6\u522b\u76f8\u5173\u6587\u6863\u5b58\u5728\u6311\u6218\uff0c\u4e14\u4ee5\u5f80\u5de5\u4f5c\u672a\u5145\u5206\u8003\u8651\u6279\u6b21\u6784\u6210\u5bf9\u91cd\u6392\u5e8f\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e3a\u6587\u6863\u5728\u4e0d\u540c\u91cd\u6392\u5e8f\u4e0a\u4e0b\u6587\u5206\u5e03\u4e0b\u4e0e\u67e5\u8be2\u76f8\u5173\u7684\u6982\u7387\uff1b\u63d0\u51fa\u57fa\u4e8e\u91c7\u6837\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u91cd\u6392\u5e8f\u7b97\u6cd5TS - SetRank\u3002", "result": "TS - SetRank\u5728BRIGHT\u4e0a\u4f7fnDCG@10\u8f83\u57fa\u7ebf\u63d0\u9ad815 - 25%\uff0c\u5728BEIR\u4e0a\u63d0\u9ad86 - 21%\u3002", "conclusion": "\u5c06\u76f8\u5173\u6027\u5efa\u6a21\u4e3a\u4e0a\u4e0b\u6587\u76f8\u5173\u5f88\u91cd\u8981\u3002"}}
{"id": "2510.27012", "pdf": "https://arxiv.org/pdf/2510.27012", "abs": "https://arxiv.org/abs/2510.27012", "authors": ["Yumou Fei"], "title": "Unbounded-width CSPs are Untestable in a Sublinear Number of Queries", "categories": ["cs.CC", "cs.DS"], "comment": null, "summary": "The bounded-degree query model, introduced by Goldreich and Ron\n(\\textit{Algorithmica, 2002}), is a standard framework in graph property\ntesting and sublinear-time algorithms. Many properties studied in this model,\nsuch as bipartiteness and 3-colorability of graphs, can be expressed as\nsatisfiability of constraint satisfaction problems (CSPs). We prove that for\nthe entire class of \\emph{unbounded-width} CSPs, testing satisfiability\nrequires $\\Omega(n)$ queries in the bounded-degree model. This result unifies\nand generalizes several previous lower bounds. In particular, it applies to all\nCSPs that are known to be $\\mathbf{NP}$-hard to solve, including\n$k$-colorability of $\\ell$-uniform hypergraphs for any $k,\\ell \\ge 2$ with\n$(k,\\ell) \\neq (2,2)$.\n  Our proof combines the techniques from Bogdanov, Obata, and Trevisan\n(\\textit{FOCS, 2002}), who established the first $\\Omega(n)$ query lower bound\nfor CSP testing in the bounded-degree model, with known results from universal\nalgebra.", "AI": {"tldr": "\u8bc1\u660e\u6709\u754c\u5ea6\u6a21\u578b\u4e0b\u65e0\u754c\u5bbd\u5ea6CSP\u53ef\u6ee1\u8db3\u6027\u6d4b\u8bd5\u9700\u03a9(n)\u67e5\u8be2\uff0c\u7edf\u4e00\u5e76\u63a8\u5e7f\u5148\u524d\u4e0b\u754c\u3002", "motivation": "\u6709\u754c\u5ea6\u67e5\u8be2\u6a21\u578b\u662f\u56fe\u5c5e\u6027\u6d4b\u8bd5\u548c\u4e9a\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u6807\u51c6\u6846\u67b6\uff0c\u5f88\u591a\u5c5e\u6027\u53ef\u7528CSP\u53ef\u6ee1\u8db3\u6027\u8868\u8fbe\uff0c\u9700\u7814\u7a76\u5176\u6d4b\u8bd5\u590d\u6742\u5ea6\u3002", "method": "\u7ed3\u5408Bogdanov\u7b49\u4eba\u6280\u672f\u4e0e\u6cdb\u4ee3\u6570\u5df2\u77e5\u7ed3\u679c\u3002", "result": "\u8bc1\u660e\u6709\u754c\u5ea6\u6a21\u578b\u4e0b\u65e0\u754c\u5bbd\u5ea6CSP\u53ef\u6ee1\u8db3\u6027\u6d4b\u8bd5\u9700\u03a9(n)\u67e5\u8be2\uff0c\u9002\u7528\u4e8e\u5df2\u77e5NP\u96be\u7684CSP\u3002", "conclusion": "\u7ed3\u679c\u7edf\u4e00\u5e76\u63a8\u5e7f\u4e86\u5148\u524d\u7684\u51e0\u4e2a\u4e0b\u754c\u3002"}}
{"id": "2511.00340", "pdf": "https://arxiv.org/pdf/2511.00340", "abs": "https://arxiv.org/abs/2511.00340", "authors": ["Manan Roy Choudhury", "Adithya Chandramouli", "Mannan Anand", "Vivek Gupta"], "title": "Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities", "categories": ["cs.AI"], "comment": "41 pages, 4 images", "summary": "The rapid integration of large language models (LLMs) into high-stakes legal\nwork has exposed a critical gap: no benchmark exists to systematically\nstress-test their reliability against the nuanced, adversarial, and often\nsubtle flaws present in real-world contracts. To address this, we introduce\nCLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an\nLLM's legal reasoning. We study the capabilities of LLMs to detect and reason\nabout fine-grained discrepancies by producing over 7500 real-world perturbed\ncontracts from foundational datasets like CUAD and ContractNLI. Our novel,\npersona-driven pipeline generates 10 distinct anomaly categories, which are\nthen validated against official statutes using a Retrieval-Augmented Generation\n(RAG) system to ensure legal fidelity. We use CLAUSE to evaluate leading LLMs'\nability to detect embedded legal flaws and explain their significance. Our\nanalysis shows a key weakness: these models often miss subtle errors and\nstruggle even more to justify them legally. Our work outlines a path to\nidentify and correct such reasoning failures in legal AI.", "AI": {"tldr": "\u4ecb\u7ecdCLAUSE\u57fa\u51c6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u6cd5\u5f8b\u63a8\u7406\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u6709\u4e0d\u8db3\u5e76\u6307\u660e\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u6cd5\u5f8b\u5de5\u4f5c\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u538b\u529b\u6d4b\u8bd5\u5176\u53ef\u9760\u6027\u7684\u57fa\u51c6\u3002", "method": "\u4eceCUAD\u548cContractNLI\u7b49\u6570\u636e\u96c6\u751f\u6210\u8d857500\u4e2a\u771f\u5b9e\u6270\u52a8\u5408\u540c\uff0c\u7528\u65b0\u9896\u7684\u89d2\u8272\u9a71\u52a8\u7ba1\u9053\u751f\u621010\u79cd\u5f02\u5e38\u7c7b\u522b\uff0c\u7528RAG\u7cfb\u7edf\u9a8c\u8bc1\uff0c\u7528CLAUSE\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3002", "result": "\u9886\u5148\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e38\u9519\u8fc7\u7ec6\u5fae\u9519\u8bef\uff0c\u66f4\u96be\u4ece\u6cd5\u5f8b\u4e0a\u89e3\u91ca\u3002", "conclusion": "\u6307\u51fa\u4e86\u8bc6\u522b\u548c\u7ea0\u6b63\u6cd5\u5f8bAI\u63a8\u7406\u5931\u8d25\u7684\u9014\u5f84\u3002"}}
{"id": "2511.00450", "pdf": "https://arxiv.org/pdf/2511.00450", "abs": "https://arxiv.org/abs/2511.00450", "authors": ["Vahid Etemadi", "Gregorio Robles"], "title": "SmartDoc: A Context-Aware Agentic Method Comment Generation Plugin", "categories": ["cs.SE"], "comment": "6 pages, Already submitted to The 3rd International Workshop on\n  Integrated Development Environments (the IDE Workshop)", "summary": "Context: The software maintenance phase involves many activities such as code\nrefactoring, bug fixing, code review or testing. Program comprehension is key\nto all these activities, as it demands developers to grasp the knowledge (e.g.,\nimplementation details) required to modify the codebase. Methods as main\nbuilding blocks in a program can offer developers this knowledge source for\ncode comprehension. However, reading entire method statements can be\nchallenging, which necessitates precise and up-to-date comments. Objective: We\npropose a solution as an IntelliJ IDEA plugin, named SmartDoc, that assists\ndevelopers in generating context-aware method comments. Method: This plugin\nacts as an Artificial Intelligence (AI) agent that has its own memory and is\naugmented by target methods' context. When a request is initiated by the\nend-user, the method content and all its nested method calls are used in the\ncomment generation. At the beginning, these nested methods are visited and a\ncall graph is generated. This graph is then traversed using depth-first search\n(DFS), enabling the provision of full-context to enrich Large Language Model\n(LLM) prompts. Result: The product is a software, as a plugin, developed for\nJava codebase and installable on IntelliJ IDEA. This plugin can serve\nconcurrently for methods whose comments are being updated , and it shares\nmemory across all flows to avoid redundant calls. o measure the accuracy of\nthis solution, a dedicated test case is run to record SmartDoc generated\ncomments and their corresponding ground truth. For each collected result-set,\nthree metrics are computed, BERTScore, BLEU and ROUGE-1. These metrics will\ndetermine how accurate the generated comments are in comparison to the ground\ntruth. Result: The obtained accuracy, in terms of the precision, recall and F1,\nis promising, and lies in the range of 0.80 to 0.90 for BERTScore.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faIntelliJ IDEA\u63d2\u4ef6SmartDoc\u8f85\u52a9\u5f00\u53d1\u8005\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u65b9\u6cd5\u6ce8\u91ca\uff0c\u4ecb\u7ecd\u5176\u5b9e\u73b0\u65b9\u6cd5\u5e76\u6d4b\u8bd5\u51c6\u786e\u6027\uff0c\u7ed3\u679c\u8f83\u6709\u524d\u666f\u3002", "motivation": "\u8f6f\u4ef6\u7ef4\u62a4\u4e2d\u7a0b\u5e8f\u7406\u89e3\u4f9d\u8d56\u65b9\u6cd5\u6ce8\u91ca\uff0c\u4f46\u9605\u8bfb\u5b8c\u6574\u65b9\u6cd5\u8bed\u53e5\u6709\u6311\u6218\uff0c\u9700\u8981\u7cbe\u786e\u53ca\u65f6\u7684\u6ce8\u91ca\uff0c\u56e0\u6b64\u63d0\u51faSmartDoc\u63d2\u4ef6\u3002", "method": "\u63d2\u4ef6\u4f5c\u4e3a\u6709\u81ea\u8eab\u8bb0\u5fc6\u7684AI\u4ee3\u7406\uff0c\u7ed3\u5408\u76ee\u6807\u65b9\u6cd5\u4e0a\u4e0b\u6587\uff0c\u6839\u636e\u7528\u6237\u8bf7\u6c42\uff0c\u5229\u7528\u65b9\u6cd5\u5185\u5bb9\u548c\u5d4c\u5957\u65b9\u6cd5\u8c03\u7528\u751f\u6210\u6ce8\u91ca\uff0c\u751f\u6210\u8c03\u7528\u56fe\u5e76\u7528\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u904d\u5386\u4ee5\u4e30\u5bccLLM\u63d0\u793a\u3002", "result": "\u5f00\u53d1\u51fa\u9002\u7528\u4e8eJava\u4ee3\u7801\u5e93\u3001\u53ef\u5728IntelliJ IDEA\u5b89\u88c5\u7684\u63d2\u4ef6\uff0c\u53ef\u5e76\u53d1\u670d\u52a1\u4e8e\u66f4\u65b0\u6ce8\u91ca\u7684\u65b9\u6cd5\u5e76\u5171\u4eab\u5185\u5b58\u3002\u901a\u8fc7\u8fd0\u884c\u6d4b\u8bd5\u7528\u4f8b\u3001\u8ba1\u7b97BERTScore\u3001BLEU\u548cROUGE - 1\u7b49\u6307\u6807\uff0cBERTScore\u7684\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u503c\u57280.80\u52300.90\u4e4b\u95f4\u3002", "conclusion": "SmartDoc\u63d2\u4ef6\u5728\u751f\u6210\u65b9\u6cd5\u6ce8\u91ca\u65b9\u9762\u6709\u8f83\u597d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2511.00049", "pdf": "https://arxiv.org/pdf/2511.00049", "abs": "https://arxiv.org/abs/2511.00049", "authors": ["Yao Liu"], "title": "Adaptive Spatio-Temporal Graphs with Self-Supervised Pretraining for Multi-Horizon Weather Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate and robust weather forecasting remains a fundamental challenge due\nto the inherent spatio-temporal complexity of atmospheric systems. In this\npaper, we propose a novel self-supervised learning framework that leverages\nspatio-temporal structures to improve multi-variable weather prediction. The\nmodel integrates a graph neural network (GNN) for spatial reasoning, a\nself-supervised pretraining scheme for representation learning, and a\nspatio-temporal adaptation mechanism to enhance generalization across varying\nforecasting horizons. Extensive experiments on both ERA5 and MERRA-2 reanalysis\ndatasets demonstrate that our approach achieves superior performance compared\nto traditional numerical weather prediction (NWP) models and recent deep\nlearning methods. Quantitative evaluations and visual analyses in Beijing and\nShanghai confirm the model's capability to capture fine-grained meteorological\npatterns. The proposed framework provides a scalable and label-efficient\nsolution for future data-driven weather forecasting systems.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u65f6\u7a7a\u7ed3\u6784\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u591a\u53d8\u91cf\u5929\u6c14\u9884\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u8d8a\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u6807\u7b7e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5927\u6c14\u7cfb\u7edf\u56fa\u6709\u7684\u65f6\u7a7a\u590d\u6742\u6027\u4f7f\u51c6\u786e\u548c\u7a33\u5065\u7684\u5929\u6c14\u9884\u62a5\u6210\u4e3a\u6311\u6218\uff0c\u9700\u63d0\u5347\u591a\u53d8\u91cf\u5929\u6c14\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u7684\u6846\u67b6\u96c6\u6210\u56fe\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u7a7a\u95f4\u63a8\u7406\u3001\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6848\u8fdb\u884c\u8868\u5f81\u5b66\u4e60\u4ee5\u53ca\u65f6\u7a7a\u81ea\u9002\u5e94\u673a\u5236\u4ee5\u589e\u5f3a\u4e0d\u540c\u9884\u6d4b\u8303\u56f4\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728ERA5\u548cMERRA - 2\u518d\u5206\u6790\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u6570\u503c\u5929\u6c14\u9884\u62a5\u6a21\u578b\u548c\u8fd1\u671f\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6027\u80fd\u66f4\u4f18\uff0c\u5728\u5317\u4eac\u548c\u4e0a\u6d77\u7684\u5b9a\u91cf\u8bc4\u4f30\u548c\u53ef\u89c6\u5316\u5206\u6790\u8bc1\u5b9e\u6a21\u578b\u80fd\u6355\u6349\u7ec6\u7c92\u5ea6\u6c14\u8c61\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u6570\u636e\u9a71\u52a8\u7684\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6807\u7b7e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00792", "pdf": "https://arxiv.org/pdf/2511.00792", "abs": "https://arxiv.org/abs/2511.00792", "authors": ["Akshay Sai Banderwaar", "Abhishek Gupta"], "title": "Fast PINN Eigensolvers via Biconvex Reformulation", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "7 pages, 3 figures, Machine Learning and the Physical Sciences\n  Workshop NeurIPS 2025", "summary": "Eigenvalue problems have a distinctive forward-inverse structure and are\nfundamental to characterizing a system's thermal response, stability, and\nnatural modes. Physics-Informed Neural Networks (PINNs) offer a mesh-free\nalternative for solving such problems but are often orders of magnitude slower\nthan classical numerical schemes. In this paper, we introduce a reformulated\nPINN approach that casts the search for eigenpairs as a biconvex optimization\nproblem, enabling fast and provably convergent alternating convex search (ACS)\nover eigenvalues and eigenfunctions using analytically optimal updates.\nNumerical experiments show that PINN-ACS attains high accuracy with convergence\nspeeds up to 500$\\times$ faster than gradient-based PINN training. We release\nour codes at https://github.com/NeurIPS-ML4PS-2025/PINN_ACS_CODES.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u7684PINN\u65b9\u6cd5PINN - ACS\u89e3\u51b3\u7279\u5f81\u503c\u95ee\u9898\uff0c\u6bd4\u57fa\u4e8e\u68af\u5ea6\u7684PINN\u8bad\u7ec3\u5feb\u8fbe500\u500d\u4e14\u7cbe\u5ea6\u9ad8\uff0c\u8fd8\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u7279\u5f81\u503c\u95ee\u9898\u91cd\u8981\uff0c\u4f46\u4f20\u7edfPINN\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\u6bd4\u7ecf\u5178\u6570\u503c\u65b9\u6848\u6162\u5f88\u591a\u3002", "method": "\u5c06\u5bfb\u627e\u7279\u5f81\u5bf9\u95ee\u9898\u8f6c\u5316\u4e3a\u53cc\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u89e3\u6790\u6700\u4f18\u66f4\u65b0\u5bf9\u7279\u5f81\u503c\u548c\u7279\u5f81\u51fd\u6570\u8fdb\u884c\u4ea4\u66ff\u51f8\u641c\u7d22\uff08ACS\uff09\u3002", "result": "PINN - ACS\u8fbe\u5230\u9ad8\u7cbe\u5ea6\uff0c\u6536\u655b\u901f\u5ea6\u6bd4\u57fa\u4e8e\u68af\u5ea6\u7684PINN\u8bad\u7ec3\u5feb\u8fbe500\u500d\u3002", "conclusion": "\u63d0\u51fa\u7684PINN - ACS\u65b9\u6cd5\u5728\u89e3\u51b3\u7279\u5f81\u503c\u95ee\u9898\u4e0a\u66f4\u9ad8\u6548\u4e14\u51c6\u786e\u3002"}}
{"id": "2511.00995", "pdf": "https://arxiv.org/pdf/2511.00995", "abs": "https://arxiv.org/abs/2511.00995", "authors": ["Tianming Wu", "Dixin Tang"], "title": "PathFinder: Efficiently Supporting Conjunctions and Disjunctions for Filtered Approximate Nearest Neighbor Search", "categories": ["cs.DB"], "comment": null, "summary": "Filtered approximate nearest neighbor search (ANNS) restricts the search to\ndata objects whose attributes satisfy a given filter and retrieves the top-$K$\nobjects that are most semantically similar to the query object. Many\ngraph-based ANNS indexes are proposed to enable efficient filtered ANNS but\nremain limited in applicability or performance: indexes optimized for a\nspecific attribute achieve high efficiency for filters on that attribute but\nfail to support complex filters with arbitrary conjunctions and disjunctions\nover multiple attributes. Inspired by the design of relational databases, this\npaper presents PathFinder, a new indexing framework that allows users to\nselectively create ANNS indexes optimized for filters on specific attributes\nand employs a cost-based optimizer to efficiently utilize them for processing\ncomplex filters. PathFinder includes three novel techniques: 1) a new\noptimization metric that captures the tradeoff between query execution time and\naccuracy, 2) a two-phase optimization for handling filters with conjunctions\nand disjunctions, and 3) an index borrowing optimization that uses an\nattribute-specific index to process filters on another attribute. Experiments\non four real-world datasets show that PathFinder outperforms the best baseline\nby up to 9.8x in query throughput at recall 0.95.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPathFinder\u7d22\u5f15\u6846\u67b6\u7528\u4e8e\u8fc7\u6ee4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff0c\u542b\u4e09\u9879\u65b0\u6280\u672f\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u7684\u8fc7\u6ee4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7d22\u5f15\u5728\u9002\u7528\u6027\u6216\u6027\u80fd\u4e0a\u53d7\u9650\uff0c\u65e0\u6cd5\u652f\u6301\u591a\u5c5e\u6027\u590d\u6742\u8fc7\u6ee4\u3002", "method": "\u63d0\u51faPathFinder\u6846\u67b6\uff0c\u53ef\u9009\u62e9\u6027\u521b\u5efa\u9488\u5bf9\u7279\u5b9a\u5c5e\u6027\u8fc7\u6ee4\u4f18\u5316\u7684\u7d22\u5f15\uff0c\u91c7\u7528\u57fa\u4e8e\u6210\u672c\u7684\u4f18\u5316\u5668\u5904\u7406\u590d\u6742\u8fc7\u6ee4\uff0c\u5305\u542b\u65b0\u4f18\u5316\u6307\u6807\u3001\u4e24\u9636\u6bb5\u4f18\u5316\u548c\u7d22\u5f15\u501f\u7528\u4f18\u5316\u4e09\u9879\u6280\u672f\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cPathFinder\u5728\u53ec\u56de\u73870.95\u65f6\uff0c\u67e5\u8be2\u541e\u5410\u91cf\u6bd4\u6700\u4f73\u57fa\u7ebf\u9ad89.8\u500d\u3002", "conclusion": "PathFinder\u6846\u67b6\u5728\u8fc7\u6ee4\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u4e2d\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u8fc7\u6ee4\uff0c\u63d0\u5347\u67e5\u8be2\u6027\u80fd\u3002"}}
{"id": "2511.01196", "pdf": "https://arxiv.org/pdf/2511.01196", "abs": "https://arxiv.org/abs/2511.01196", "authors": ["Jicong Fan"], "title": "An Interdisciplinary and Cross-Task Review on Missing Data Imputation", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Missing data is a fundamental challenge in data science, significantly\nhindering analysis and decision-making across a wide range of disciplines,\nincluding healthcare, bioinformatics, social science, e-commerce, and\nindustrial monitoring. Despite decades of research and numerous imputation\nmethods, the literature remains fragmented across fields, creating a critical\nneed for a comprehensive synthesis that connects statistical foundations with\nmodern machine learning advances. This work systematically reviews core\nconcepts-including missingness mechanisms, single versus multiple imputation,\nand different imputation goals-and examines problem characteristics across\nvarious domains. It provides a thorough categorization of imputation methods,\nspanning classical techniques (e.g., regression, the EM algorithm) to modern\napproaches like low-rank and high-rank matrix completion, deep learning models\n(autoencoders, GANs, diffusion models, graph neural networks), and large\nlanguage models. Special attention is given to methods for complex data types,\nsuch as tensors, time series, streaming data, graph-structured data,\ncategorical data, and multimodal data. Beyond methodology, we investigate the\ncrucial integration of imputation with downstream tasks like classification,\nclustering, and anomaly detection, examining both sequential pipelines and\njoint optimization frameworks. The review also assesses theoretical guarantees,\nbenchmarking resources, and evaluation metrics. Finally, we identify critical\nchallenges and future directions, emphasizing model selection and\nhyperparameter optimization, the growing importance of privacy-preserving\nimputation via federated learning, and the pursuit of generalizable models that\ncan adapt across domains and data types, thereby outlining a roadmap for future\nresearch.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u56de\u987e\u6570\u636e\u7f3a\u5931\u503c\u63d2\u8865\u65b9\u6cd5\uff0c\u6db5\u76d6\u6982\u5ff5\u3001\u5206\u7c7b\u3001\u4e0b\u6e38\u4efb\u52a1\u7b49\uff0c\u6307\u51fa\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u5206\u6563\uff0c\u9700\u7efc\u5408\u7edf\u8ba1\u57fa\u7840\u4e0e\u673a\u5668\u5b66\u4e60\u8fdb\u5c55\u6765\u89e3\u51b3\u6570\u636e\u7f3a\u5931\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u7cfb\u7edf\u56de\u987e\u6838\u5fc3\u6982\u5ff5\uff0c\u5bf9\u63d2\u8865\u65b9\u6cd5\u5206\u7c7b\uff0c\u7814\u7a76\u4e0e\u4e0b\u6e38\u4efb\u52a1\u96c6\u6210\uff0c\u8bc4\u4f30\u7406\u8bba\u4fdd\u8bc1\u3001\u57fa\u51c6\u8d44\u6e90\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b8c\u6210\u63d2\u8865\u65b9\u6cd5\u5206\u7c7b\uff0c\u7814\u7a76\u63d2\u8865\u4e0e\u4e0b\u6e38\u4efb\u52a1\u7ed3\u5408\uff0c\u8bc4\u4f30\u76f8\u5173\u7406\u8bba\u4e0e\u6307\u6807\u3002", "conclusion": "\u8bc6\u522b\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u5982\u6a21\u578b\u9009\u62e9\u3001\u9690\u79c1\u4fdd\u62a4\u63d2\u8865\u3001\u901a\u7528\u6a21\u578b\u8ffd\u6c42\u7b49\u3002"}}
{"id": "2511.01565", "pdf": "https://arxiv.org/pdf/2511.01565", "abs": "https://arxiv.org/abs/2511.01565", "authors": ["Sevgi \u00c7olak"], "title": "Gendered Responses to Subtle Social Pressure: Experimental Evidence from Survey Results", "categories": ["econ.GN", "q-fin.EC", "91B40, 91B42, 62P20"], "comment": "11 pages, 4 figures, 1 table", "summary": "This study analyzes whether subtle variations in the survey questionnaire\nphrasing influence participant engagement and whether these effects differ by\ngender. Building on theories of social pressure and politeness norms, it is\nhypothesized that presumptive phrasing would reduce engagement compared to\nappreciative phrasing and baseline phrasing (H1), and this effect would be more\npronounced among women (H2). Mixed-effects regression models showed no\nsignificant treatment effects on any outcome and no evidence of gender\nmoderation for 164 participants and 492 observations. The only robust finding\nwas a small negative baseline sentiment across all participants, independent of\nany treatment or gender. The findings contribute to refining theoretical\nexpectations about the conditions in which linguistic framing and gender norms\nshape behaviour.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u95ee\u9898\u63aa\u8f9e\u7ec6\u5fae\u53d8\u5316\u5bf9\u53c2\u4e0e\u8005\u53c2\u4e0e\u5ea6\u7684\u5f71\u54cd\u53ca\u6027\u522b\u5dee\u5f02\uff0c\u7ed3\u679c\u65e0\u663e\u8457\u5904\u7406\u6548\u5e94\uff0c\u4ec5\u53d1\u73b0\u6240\u6709\u53c2\u4e0e\u8005\u6709\u5c0f\u7684\u8d1f\u57fa\u7ebf\u60c5\u7eea\u3002", "motivation": "\u5206\u6790\u8c03\u67e5\u95ee\u9898\u63aa\u8f9e\u7684\u7ec6\u5fae\u53d8\u5316\u662f\u5426\u5f71\u54cd\u53c2\u4e0e\u8005\u53c2\u4e0e\u5ea6\uff0c\u4ee5\u53ca\u8fd9\u79cd\u5f71\u54cd\u662f\u5426\u56e0\u6027\u522b\u800c\u5f02\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6548\u5e94\u56de\u5f52\u6a21\u578b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5bf9164\u540d\u53c2\u4e0e\u8005\u548c492\u6b21\u89c2\u5bdf\uff0c\u672a\u53d1\u73b0\u5904\u7406\u5bf9\u4efb\u4f55\u7ed3\u679c\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e5f\u65e0\u6027\u522b\u8c03\u8282\u7684\u8bc1\u636e\uff0c\u552f\u4e00\u53d1\u73b0\u662f\u6240\u6709\u53c2\u4e0e\u8005\u6709\u5c0f\u7684\u8d1f\u57fa\u7ebf\u60c5\u7eea\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u5b8c\u5584\u5173\u4e8e\u8bed\u8a00\u6846\u67b6\u548c\u6027\u522b\u89c4\u8303\u5f71\u54cd\u884c\u4e3a\u7684\u7406\u8bba\u9884\u671f\u3002"}}
{"id": "2511.01077", "pdf": "https://arxiv.org/pdf/2511.01077", "abs": "https://arxiv.org/abs/2511.01077", "authors": ["David McCoy", "Yulun Wu", "Zachary Butzin-Dozier"], "title": "AI Progress Should Be Measured by Capability-Per-Resource, Not Scale Alone: A Framework for Gradient-Guided Resource Allocation in LLMs", "categories": ["cs.LG", "stat.CO"], "comment": "9 pages (main) + appendix, 3 figures. Accepted at NeurIPS 2025\n  (Position Paper Track), submission #491. OpenReview:\n  https://openreview.net/forum?id=6plSmhBI33&noteId=KP5ZqY7JLg", "summary": "This position paper challenges the \"scaling fundamentalism\" dominating AI\nresearch, where unbounded growth in model size and computation has led to\nunsustainable environmental impacts and widening resource inequality. We argue\nthat LLM development should be fundamentally reoriented toward\ncapability-per-resource rather than capability alone. We present a theoretical\nframework demonstrating that resource-allocation decisions guided by gradient\ninfluence patterns can dramatically improve efficiency throughout the AI\nlifecycle. Our analysis shows that in transformer-based models, where a small\nfraction of parameters exert outsized influence (following heavy-tailed\ndistributions), three critical insights emerge: (1) updating only\nhigh-influence parameters strictly outperforms full-parameter tuning on a\nperformance-per-resource basis; (2) simple gradient norms provide\ncomputationally efficient proxies for identifying these high-influence\ncomponents; and (3) coordinated parameter and data selection yields\nmultiplicative efficiency gains, potentially reducing resource requirements by\norders of magnitude. Building on these theoretical foundations, we propose a\ntwo stage paradigm marginal-return pretraining for foundation developers and\ninfluence guided adaptation for downstream users bridged by gradient\nblueprints, metadata describing which parameters matter most for various tasks.\nThis capability-per-resource perspective transforms what were once considered\npragmatic hardware workarounds into theoretically optimal strategies,\ndemocratizing access to cutting-edge AI capabilities while significantly\nreducing environmental impact. By embedding resource consciousness into how we\ndevelop, adapt, and evaluate models, we can reshape AI progress toward a more\nsustainable and equitable future.", "AI": {"tldr": "\u6587\u7ae0\u6311\u6218AI\u7814\u7a76\u4e2d\u7684\u2018\u6269\u5c55\u539f\u6559\u65e8\u4e3b\u4e49\u2019\uff0c\u63d0\u51fa\u4ee5\u8d44\u6e90\u5229\u7528\u7387\u4e3a\u5bfc\u5411\u7684LLM\u53d1\u5c55\u65b9\u5411\uff0c\u7ed9\u51fa\u7406\u8bba\u6846\u67b6\u548c\u4e24\u9636\u6bb5\u8303\u5f0f\uff0c\u4ee5\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u516c\u5e73\u7684AI\u672a\u6765\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u89c4\u6a21\u548c\u8ba1\u7b97\u7684\u65e0\u9650\u5236\u589e\u957f\u5bfc\u81f4\u73af\u5883\u5f71\u54cd\u4e0d\u53ef\u6301\u7eed\u548c\u8d44\u6e90\u4e0d\u5e73\u7b49\u52a0\u5267\uff0c\u9700\u91cd\u65b0\u8c03\u6574LLM\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u68af\u5ea6\u5f71\u54cd\u6a21\u5f0f\u6307\u5bfc\u8d44\u6e90\u5206\u914d\u51b3\u7b56\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u8303\u5f0f\u3002", "result": "\u5728\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u4e2d\u5f97\u51fa\u4e09\u70b9\u5173\u952e\u89c1\u89e3\uff0c\u901a\u8fc7\u534f\u8c03\u53c2\u6570\u548c\u6570\u636e\u9009\u62e9\u53ef\u5927\u5e45\u63d0\u9ad8\u6548\u7387\uff0c\u51cf\u5c11\u8d44\u6e90\u9700\u6c42\u3002", "conclusion": "\u4ee5\u8d44\u6e90\u5229\u7528\u7387\u4e3a\u89c6\u89d2\u53ef\u5c06\u786c\u4ef6\u53d8\u901a\u65b9\u6cd5\u53d8\u4e3a\u6700\u4f18\u7b56\u7565\uff0c\u5b9e\u73b0AI\u53ef\u6301\u7eed\u516c\u5e73\u53d1\u5c55\u3002"}}
{"id": "2511.01843", "pdf": "https://arxiv.org/pdf/2511.01843", "abs": "https://arxiv.org/abs/2511.01843", "authors": ["Andrew Goodng", "Kevin Porter", "Thomas Lopatic", "Ashish Shinde", "Sunil Sayyaparaju", "Srinivasan Seshadri", "V. Srinivasan"], "title": "LARK - Linearizability Algorithms for Replicated Keys in Aerospike", "categories": ["cs.DC", "cs.DB"], "comment": "Submitted to Industry Track of a Database Conference", "summary": "We present LARK (Linearizability Algorithms for Replicated Keys), a\nsynchronous replication protocol that achieves linearizability while minimizing\nlatency and infrastructure cost, at significantly higher availability than\ntraditional quorum-log consensus. LARK introduces Partition Availability\nConditions (PAC) that reason over the entire database cluster rather than fixed\nreplica sets, improving partition availability under independent failures by\nroughly 3x when tolerating one failure and 10x when tolerating two. Unlike\nRaft, Paxos, and Viewstamped Replication, LARK eliminates ordered logs,\nenabling immediate partition readiness after leader changes -- with at most a\nper-key duplicate-resolution round trip when the new leader lacks the latest\ncopy. Under equal storage budgets -- where both systems maintain only f+1 data\ncopies to tolerate f failures -- LARK continues committing through data-node\nfailures while log-based protocols must pause commits for replica rebuilding.\nThese properties also enable zero-downtime rolling restarts even when\nmaintaining only two copies. We provide formal safety arguments and a TLA+\nspecification, and we demonstrate through analysis and experiments that LARK\nachieves significant availability gains.", "AI": {"tldr": "\u4ecb\u7ecd\u540c\u6b65\u590d\u5236\u534f\u8baeLARK\uff0c\u80fd\u5b9e\u73b0\u7ebf\u6027\u5316\uff0c\u964d\u4f4e\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u6bd4\u4f20\u7edf\u534f\u8bae\u53ef\u7528\u6027\u9ad8\u3002", "motivation": "\u8bbe\u8ba1\u4e00\u79cd\u80fd\u5728\u5b9e\u73b0\u7ebf\u6027\u5316\u7684\u540c\u65f6\uff0c\u964d\u4f4e\u5ef6\u8fdf\u548c\u57fa\u7840\u8bbe\u65bd\u6210\u672c\uff0c\u63d0\u9ad8\u53ef\u7528\u6027\u7684\u540c\u6b65\u590d\u5236\u534f\u8bae\u3002", "method": "\u5f15\u5165Partition Availability Conditions (PAC)\uff0c\u6d88\u9664\u6709\u5e8f\u65e5\u5fd7\u3002", "result": "\u5728\u5bb9\u5fcd\u6545\u969c\u65f6\u63d0\u9ad8\u5206\u533a\u53ef\u7528\u6027\uff0c\u5728\u540c\u7b49\u5b58\u50a8\u9884\u7b97\u4e0b\u80fd\u6301\u7eed\u63d0\u4ea4\uff0c\u53ef\u5b9e\u73b0\u96f6\u505c\u673a\u6eda\u52a8\u91cd\u542f\u3002", "conclusion": "LARK\u53d6\u5f97\u663e\u8457\u7684\u53ef\u7528\u6027\u63d0\u5347\u3002"}}
{"id": "2511.01364", "pdf": "https://arxiv.org/pdf/2511.01364", "abs": "https://arxiv.org/abs/2511.01364", "authors": ["Pavan Kumar Perepu"], "title": "A semantic-based deep learning approach for mathematical expression retrieval", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Mathematical expressions (MEs) have complex two-dimensional structures in\nwhich symbols can be present at any nested depth like superscripts, subscripts,\nabove, below etc. As MEs are represented using LaTeX format, several text\nretrieval methods based on string matching, vector space models etc., have also\nbeen applied for ME retrieval problem in the literature. As these methods are\nbased on syntactic similarity, recently deep learning approaches based on\nembedding have been used for semantic similarity. In our present work, we have\nfocused on the retrieval of mathematical expressions using deep learning\napproaches. In our approach, semantic features are extracted from the MEs using\na deep recurrent neural network (DRNN) and these features have been used for\nmatching and retrieval. We have trained the network for a classification task\nwhich determines the complexity of an ME. ME complexity has been quantified in\nterms of its nested depth. Based on the nested depth, we have considered three\ncomplexity classes of MEs: Simple, Medium and Complex. After training the\nnetwork, outputs just before the the final fully connected layer are extracted\nfor all the MEs. These outputs form the semantic features of MEs and are stored\nin a database. For a given ME query, its semantic features are computed using\nthe trained DRNN and matched against the semantic feature database. Matching is\nperformed based on the standard euclidean distance and top 'k' nearest matches\nare retrieved, where 'k' is a user-defined parameter. Our approach has been\nillustrated on a database of 829 MEs.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u68c0\u7d22\u6570\u5b66\u8868\u8fbe\u5f0f\uff0c\u7528DRNN\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\u5e76\u5339\u914d\u68c0\u7d22\uff0c\u5728829\u4e2a\u6570\u5b66\u8868\u8fbe\u5f0f\u6570\u636e\u5e93\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u53e5\u6cd5\u76f8\u4f3c\u6027\u7684\u6587\u672c\u68c0\u7d22\u65b9\u6cd5\u7528\u4e8e\u6570\u5b66\u8868\u8fbe\u5f0f\u68c0\u7d22\u6709\u5c40\u9650\uff0c\u9700\u57fa\u4e8e\u5d4c\u5165\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\u8bed\u4e49\u76f8\u4f3c\u6027\u68c0\u7d22\u3002", "method": "\u7528\u6df1\u5ea6\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08DRNN\uff09\u4ece\u6570\u5b66\u8868\u8fbe\u5f0f\u4e2d\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\uff0c\u8bad\u7ec3\u7f51\u7edc\u8fdb\u884c\u5206\u7c7b\u4efb\u52a1\u4ee5\u786e\u5b9a\u8868\u8fbe\u5f0f\u590d\u6742\u5ea6\uff0c\u5c06\u8f93\u51fa\u5b58\u4e8e\u6570\u636e\u5e93\uff0c\u67e5\u8be2\u65f6\u8ba1\u7b97\u7279\u5f81\u5e76\u57fa\u4e8e\u6b27\u6c0f\u8ddd\u79bb\u5339\u914d\u3002", "result": "\u5728829\u4e2a\u6570\u5b66\u8868\u8fbe\u5f0f\u7684\u6570\u636e\u5e93\u4e0a\u8fdb\u884c\u4e86\u65b9\u6cd5\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6570\u5b66\u8868\u8fbe\u5f0f\u68c0\u7d22\u65b9\u6cd5\uff0c\u53ef\u5b9e\u73b0\u57fa\u4e8e\u8bed\u4e49\u7279\u5f81\u7684\u5339\u914d\u548c\u68c0\u7d22\u3002"}}
{"id": "2511.00885", "pdf": "https://arxiv.org/pdf/2511.00885", "abs": "https://arxiv.org/abs/2511.00885", "authors": ["Tal Argov", "Tal Wagner"], "title": "SpEx: A Spectral Approach to Explainable Clustering", "categories": ["cs.LG", "cs.DS"], "comment": "NeurIPS 2025", "summary": "Explainable clustering by axis-aligned decision trees was introduced by\nMoshkovitz et al. (2020) and has gained considerable interest. Prior work has\nfocused on minimizing the price of explainability for specific clustering\nobjectives, lacking a general method to fit an explanation tree to any given\nclustering, without restrictions. In this work, we propose a new and generic\napproach to explainable clustering, based on spectral graph partitioning. With\nit, we design an explainable clustering algorithm that can fit an explanation\ntree to any given non-explainable clustering, or directly to the dataset\nitself. Moreover, we show that prior algorithms can also be interpreted as\ngraph partitioning, through a generalized framework due to Trevisan (2013)\nwherein cuts are optimized in two graphs simultaneously. Our experiments show\nthe favorable performance of our method compared to baselines on a range of\ndatasets.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8c31\u56fe\u5212\u5206\u7684\u53ef\u89e3\u91ca\u805a\u7c7b\u65b0\u901a\u7528\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u5148\u524d\u5de5\u4f5c\u7f3a\u4e4f\u5c06\u89e3\u91ca\u6811\u9002\u914d\u5230\u4efb\u610f\u7ed9\u5b9a\u805a\u7c7b\u7684\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u8c31\u56fe\u5212\u5206\u63d0\u51fa\u65b0\u7684\u53ef\u89e3\u91ca\u805a\u7c7b\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u7b97\u6cd5\u9002\u914d\u89e3\u91ca\u6811\u5230\u975e\u53ef\u89e3\u91ca\u805a\u7c7b\u6216\u6570\u636e\u96c6\uff0c\u7528Trevisan\u6846\u67b6\u89e3\u91ca\u5148\u524d\u7b97\u6cd5\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u805a\u7c7b\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2511.00379", "pdf": "https://arxiv.org/pdf/2511.00379", "abs": "https://arxiv.org/abs/2511.00379", "authors": ["Jiahao Wang", "Songkai Xue", "Jinghui Li", "Xiaozhen Wang"], "title": "Diverse Human Value Alignment for Large Language Models via Ethical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by AIES 2025, camera-ready version", "summary": "Ensuring that Large Language Models (LLMs) align with the diverse and\nevolving human values across different regions and cultures remains a critical\nchallenge in AI ethics. Current alignment approaches often yield superficial\nconformity rather than genuine ethical understanding, failing to address the\ncomplex, context-dependent nature of human values. In this paper, we propose a\nnovel ethical reasoning paradigm for LLMs inspired by well-established ethical\ndecision-making models, aiming at enhancing diverse human value alignment\nthrough deliberative ethical reasoning. Our framework consists of a structured\nfive-step process, including contextual fact gathering, hierarchical social\nnorm identification, option generation, multiple-lens ethical impact analysis,\nand reflection. This theory-grounded approach guides LLMs through an\ninterpretable reasoning process that enhances their ability to understand\nregional specificities and perform nuanced ethical analysis, which can be\nimplemented with either prompt engineering or supervised fine-tuning methods.\nWe perform evaluations on the SafeWorld benchmark that specially designed for\nregional value alignment. Experimental results demonstrate our framework\nsignificantly improves LLM alignment with diverse human values compared to\nbaseline methods, enabling more accurate social norm identification and more\nculturally appropriate reasoning. Our work provides a concrete pathway toward\ndeveloping LLMs that align more effectively with the multifaceted values of\nglobal societies through interdisciplinary research.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f26\u7406\u63a8\u7406\u8303\u5f0f\u63d0\u5347\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u5bf9\u9f50\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4ef7\u503c\u5bf9\u9f50\u65b9\u6cd5\u4ec5\u8868\u9762\u7b26\u5408\u800c\u975e\u771f\u6b63\u7406\u89e3\u4f26\u7406\uff0c\u65e0\u6cd5\u5904\u7406\u4eba\u7c7b\u4ef7\u503c\u7684\u590d\u6742\u6027\u548c\u60c5\u5883\u4f9d\u8d56\u6027\u3002", "method": "\u53d7\u4f26\u7406\u51b3\u7b56\u6a21\u578b\u542f\u53d1\uff0c\u63d0\u51fa\u542b\u4e94\u6b65\u7684\u6846\u67b6\uff0c\u53ef\u7528\u63d0\u793a\u5de5\u7a0b\u6216\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u3002", "result": "\u5728SafeWorld\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u6846\u67b6\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u7684\u5bf9\u9f50\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u793e\u4f1a\u89c4\u8303\u8bc6\u522b\u548c\u66f4\u5177\u6587\u5316\u9002\u5e94\u6027\u7684\u63a8\u7406\u3002", "conclusion": "\u5de5\u4f5c\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u5bf9\u9f50\u5168\u7403\u793e\u4f1a\u591a\u5143\u4ef7\u503c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5177\u4f53\u9014\u5f84\u3002"}}
{"id": "2511.00467", "pdf": "https://arxiv.org/pdf/2511.00467", "abs": "https://arxiv.org/abs/2511.00467", "authors": ["Liu Wang", "Dong Wang", "Shidong Pan", "Zheng Jiang", "Haoyu Wang", "Yi Wang"], "title": "A Big Step Forward? A User-Centric Examination of iOS App Privacy Report and Enhancements", "categories": ["cs.SE"], "comment": "Accepted to S&P 2025", "summary": "The prevalent engagement with mobile apps underscores the importance of\nunderstanding their data practices. Transparency plays a crucial role in this\ncontext, ensuring users to be informed and give consent before any data access\noccurs. Apple introduced a new feature since iOS 15.2, App Privacy Report, to\ninform users about detailed insights into apps' data access and sharing. This\nfeature continues Apple's trend of privacy-focused innovations (following\nPrivacy Nutrition Labels), and has been marketed as a big step forward in user\nprivacy. However, its real-world impacts on user privacy and control remain\nunexamined. We thus proposed an end-to-end study involving systematic\nassessment of the App Privacy Report's real-world benefits and limitations,\nLLM-enabled and multi-technique synthesized enhancements, and comprehensive\nevaluation from both system and user perspectives. Through a structured focus\ngroup study with twelve everyday iOS users, we explored their experiences,\nunderstanding, and perceptions of the feature, suggesting its limited practical\nimpact resulting from missing important details. We identified two primary user\nconcerns: the clarity of data access purpose and domain description. In\nresponse, we proposed enhancements including a purpose inference framework and\ndomain clarification pipeline. We demonstrated the effectiveness and benefits\nof such enhancements for mobile app users. This work provides practical\ninsights that could help enhance user privacy transparency and discusses areas\nfor future research.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u82f9\u679cApp\u9690\u79c1\u62a5\u544a\u529f\u80fd\u8fdb\u884c\u7aef\u5230\u7aef\u7814\u7a76\uff0c\u53d1\u73b0\u5176\u5b9e\u8df5\u5f71\u54cd\u6709\u9650\uff0c\u63d0\u51fa\u589e\u5f3a\u65b9\u6848\u5e76\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u4e3a\u63d0\u5347\u7528\u6237\u9690\u79c1\u900f\u660e\u5ea6\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u82f9\u679c\u63a8\u51faApp\u9690\u79c1\u62a5\u544a\u529f\u80fd\uff0c\u4f46\u5176\u5b9e\u8df5\u5f71\u54cd\u672a\u88ab\u7814\u7a76\uff0c\u9700\u4e86\u89e3\u5176\u5229\u5f0a\u4ee5\u63d0\u5347\u7528\u6237\u9690\u79c1\u900f\u660e\u5ea6\u3002", "method": "\u8fdb\u884c\u7aef\u5230\u7aef\u7814\u7a76\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7126\u70b9\u5c0f\u7ec4\u7814\u7a76\u65e5\u5e38iOS\u7528\u6237\uff0c\u63d0\u51fa\u589e\u5f3a\u65b9\u6848\u3002", "result": "\u53d1\u73b0\u8be5\u529f\u80fd\u5b9e\u8df5\u5f71\u54cd\u6709\u9650\uff0c\u786e\u5b9a\u7528\u6237\u4e3b\u8981\u5173\u6ce8\u70b9\uff0c\u63d0\u51fa\u7684\u589e\u5f3a\u65b9\u6848\u6709\u6548\u3002", "conclusion": "\u5de5\u4f5c\u4e3a\u63d0\u5347\u7528\u6237\u9690\u79c1\u900f\u660e\u5ea6\u63d0\u4f9b\u5b9e\u7528\u89c1\u89e3\uff0c\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.00050", "pdf": "https://arxiv.org/pdf/2511.00050", "abs": "https://arxiv.org/abs/2511.00050", "authors": ["Dhananjaya Gowda", "Seoha Song", "Junhyun Lee", "Harshith Goka"], "title": "FLoRA: Fused forward-backward adapters for parameter efficient fine-tuning and reducing inference-time latencies of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As the large language models (LLMs) grow in size each day, efficient training\nand fine-tuning has never been as important as nowadays. This resulted in the\ngreat interest in parameter efficient fine-tuning (PEFT), and effective methods\nincluding low-rank adapters (LoRA) has emerged. Although the various PEFT\nmethods have been studied extensively in the recent years, the greater part of\nthe subject remains unexplored with the huge degree of freedom. In this paper,\nwe propose FLoRA, a family of fused forward-backward adapters (FFBA) for\nparameter-efficient fine-tuning of LLMs on downstream tasks. The FFBA combine\nideas from the popular LoRA and parallel adapters to improve the overall\nfine-tuning accuracies. At the same time, latencies are minimized by fusing the\nforward and backward adapters into existing projection layers of the base\nmodel. Experimental results show that the proposed FFB adapters perform\nsignificantly better than the popularly used LoRA in both accuracy and latency\nfor a similar parameter budget.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684FLoRA\u65b9\u6cd5\uff0c\u7ed3\u5408LoRA\u548c\u5e76\u884c\u9002\u914d\u5668\u601d\u60f3\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u51c6\u786e\u7387\u548c\u5ef6\u8fdf\u4e0a\u4f18\u4e8eLoRA\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u589e\u5927\uff0c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709PEFT\u65b9\u6cd5\u4ecd\u6709\u5f88\u591a\u672a\u63a2\u7d22\u90e8\u5206\u3002", "method": "\u63d0\u51faFLoRA\uff0c\u5373\u878d\u5408\u524d\u540e\u5411\u9002\u914d\u5668\uff08FFBA\uff09\uff0c\u7ed3\u5408LoRA\u548c\u5e76\u884c\u9002\u914d\u5668\u601d\u60f3\uff0c\u5c06\u524d\u540e\u5411\u9002\u914d\u5668\u878d\u5408\u5230\u57fa\u7840\u6a21\u578b\u73b0\u6709\u6295\u5f71\u5c42\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u76f8\u4f3c\u53c2\u6570\u9884\u7b97\u4e0b\uff0cFFB\u9002\u914d\u5668\u5728\u51c6\u786e\u7387\u548c\u5ef6\u8fdf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5e38\u7528\u7684LoRA\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684FFBA\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u4e2d\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2511.01019", "pdf": "https://arxiv.org/pdf/2511.01019", "abs": "https://arxiv.org/abs/2511.01019", "authors": ["Bowen Chen", "Jayesh Gajbhar", "Gregory Dusek", "Rob Redmon", "Patrick Hogan", "Paul Liu", "DelWayne Bohnenstiehl", "Dongkuan", "Xu", "Ruoying He"], "title": "OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG", "physics.ao-ph"], "comment": "A related presentation will be given at the AGU(American Geophysical\n  Union) and AMS(American Meteorological Society) Annual Meetings", "summary": "Artificial intelligence is transforming the sciences, yet general\nconversational AI systems often generate unverified \"hallucinations\"\nundermining scientific rigor. We present OceanAI, a conversational platform\nthat integrates the natural-language fluency of open-source large language\nmodels (LLMs) with real-time, parameterized access to authoritative\noceanographic data streams hosted by the National Oceanic and Atmospheric\nAdministration (NOAA). Each query such as \"What was Boston Harbor's highest\nwater level in 2024?\" triggers real-time API calls that identify, parse, and\nsynthesize relevant datasets into reproducible natural-language responses and\ndata visualizations. In a blind comparison with three widely used AI\nchat-interface products, only OceanAI produced NOAA-sourced values with\noriginal data references; others either declined to answer or provided\nunsupported results. Designed for extensibility, OceanAI connects to multiple\nNOAA data products and variables, supporting applications in marine hazard\nforecasting, ecosystem assessment, and water-quality monitoring. By grounding\noutputs and verifiable observations, OceanAI advances transparency,\nreproducibility, and trust, offering a scalable framework for AI-enabled\ndecision support within the oceans. A public demonstration is available at\nhttps://oceanai.ai4ocean.xyz.", "AI": {"tldr": "\u63d0\u51faOceanAI\u5bf9\u8bdd\u5e73\u53f0\uff0c\u7ed3\u5408\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5b9e\u65f6\u6d77\u6d0b\u6570\u636e\uff0c\u5728\u5bf9\u6bd4\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6269\u5c55\u6027\uff0c\u63a8\u8fdb\u6d77\u6d0bAI\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u901a\u7528\u5bf9\u8bddAI\u7cfb\u7edf\u5e38\u4ea7\u751f\u672a\u7ecf\u9a8c\u8bc1\u7684\u201c\u5e7b\u89c9\u201d\uff0c\u7834\u574f\u79d1\u5b66\u4e25\u8c28\u6027\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5c06\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u7136\u8bed\u8a00\u6d41\u7545\u6027\u4e0e\u7f8e\u56fd\u56fd\u5bb6\u6d77\u6d0b\u548c\u5927\u6c14\u7ba1\u7406\u5c40\uff08NOAA\uff09\u7684\u5b9e\u65f6\u6d77\u6d0b\u6570\u636e\u96c6\u6210\uff0c\u901a\u8fc7API\u8c03\u7528\u5904\u7406\u67e5\u8be2\u3002", "result": "\u5728\u4e0e\u4e09\u6b3e\u5e7f\u6cdb\u4f7f\u7528\u7684AI\u804a\u5929\u754c\u9762\u4ea7\u54c1\u7684\u76f2\u6d4b\u5bf9\u6bd4\u4e2d\uff0c\u53ea\u6709OceanAI\u80fd\u63d0\u4f9b\u6765\u81eaNOAA\u7684\u6570\u503c\u548c\u539f\u59cb\u6570\u636e\u53c2\u8003\u3002", "conclusion": "OceanAI\u901a\u8fc7\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u89c2\u6d4b\u8f93\u51fa\uff0c\u63a8\u8fdb\u4e86\u900f\u660e\u5ea6\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u6d77\u6d0b\u9886\u57df\u7684AI\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6\u3002"}}
{"id": "2511.01254", "pdf": "https://arxiv.org/pdf/2511.01254", "abs": "https://arxiv.org/abs/2511.01254", "authors": ["Huseyin Goksu"], "title": "Hi-WaveTST: A Hybrid High-Frequency Wavelet-Transformer for Time-Series Classification", "categories": ["eess.SP", "cs.NE"], "comment": null, "summary": "Transformers have become state-of-the-art (SOTA) for time-series\nclassification, with models like PatchTST demonstrating exceptional\nperformance. These models rely on patching the time series and learning\nrelationships between raw temporal data blocks. We argue that this approach is\nblind to critical, non-obvious high-frequency information that is complementary\nto the temporal dynamics. In this letter, we propose Hi-WaveTST, a novel Hybrid\narchitecture that augments the original temporal patch with a learnable,\nHigh-Frequency wavelet feature stream. Our wavelet stream uses a deep Wavelet\nPacket Decomposition (WPD) on each patch and extracts features using a\nlearnable Generalized Mean (GeM) pooling layer. On the UCI-HAR benchmark\ndataset, our hybrid model achieves a mean accuracy of 93.38 percent plus-minus\n0.0043, significantly outperforming the SOTA PatchTST baseline (92.59 percent\nplus-minus 0.0039). A comprehensive ablation study proves that every component\nof our design-the hybrid architecture, the deep high-frequency wavelet\ndecomposition, and the learnable GeM pooling-is essential for this\nstate-of-the-art performance.", "AI": {"tldr": "\u63d0\u51faHi - WaveTST\u6df7\u5408\u67b6\u6784\uff0c\u7ed3\u5408\u9ad8\u9891\u5c0f\u6ce2\u7279\u5f81\u6d41\uff0c\u5728UCI - HAR\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8ePatchTST\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684Transformer\u6a21\u578b\u5bf9\u5173\u952e\u7684\u975e\u660e\u663e\u9ad8\u9891\u4fe1\u606f\u4e0d\u654f\u611f\uff0c\u800c\u8be5\u4fe1\u606f\u4e0e\u65f6\u95f4\u52a8\u6001\u4e92\u8865\u3002", "method": "\u63d0\u51faHi - WaveTST\u6df7\u5408\u67b6\u6784\uff0c\u5bf9\u6bcf\u4e2a\u65f6\u95f4\u5e8f\u5217\u5757\u8fdb\u884c\u6df1\u5ea6\u5c0f\u6ce2\u5305\u5206\u89e3\uff08WPD\uff09\uff0c\u7528\u53ef\u5b66\u4e60\u7684\u5e7f\u4e49\u5747\u503c\uff08GeM\uff09\u6c60\u5316\u5c42\u63d0\u53d6\u7279\u5f81\u3002", "result": "\u5728UCI - HAR\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cHi - WaveTST\u6a21\u578b\u5e73\u5747\u51c6\u786e\u7387\u8fbe93.38%\u00b10.0043\uff0c\u663e\u8457\u4f18\u4e8ePatchTST\u57fa\u7ebf\u768492.59%\u00b10.0039\u3002", "conclusion": "Hi - WaveTST\u7684\u6df7\u5408\u67b6\u6784\u3001\u6df1\u5ea6\u9ad8\u9891\u5c0f\u6ce2\u5206\u89e3\u548c\u53ef\u5b66\u4e60GeM\u6c60\u5316\u5bf9\u5b9e\u73b0SOTA\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.01025", "pdf": "https://arxiv.org/pdf/2511.01025", "abs": "https://arxiv.org/abs/2511.01025", "authors": ["Huihui Yang", "Pingpeng Yuan"], "title": "Fast Answering Pattern-Constrained Reachability Queries with Two-Dimensional Reachability Index", "categories": ["cs.DB", "cs.DS"], "comment": null, "summary": "Reachability queries ask whether there exists a path from the source vertex\nto the target vertex on a graph. Recently, several powerful reachability\nqueries, such as Label-Constrained Reachability (LCR) queries and Regular Path\nQueries (RPQ), have been proposed for emerging complex edge-labeled digraphs.\nHowever, they cannot allow users to describe complex query requirements by\ncomposing query patterns. Here, we introduce composite patterns, a logical\nexpression of patterns that can express complex constraints on the set of\nlabels. Based on pattern, we propose pattern-constrained reachability queries\n(PCR queries). However, answering PCR queries is NP-hard. Thus, to improve the\nperformance to answer PCR queries, we build a two-dimensional reachability (TDR\nfor short) index which consists of a multi-way index (horizontal dimension) and\na path index (vertical dimension). Because the number of combinations of both\nlabels and vertices is exponential, it is very expensive to build full indices\nthat contain all the reachability information. Thus, the reachable vertices of\na vertex are decomposed into blocks, each of which is hashed into the\nhorizontal dimension index and the vertical dimension index, respectively. The\nindices in the horizontal dimension and the vertical dimension serve as a\nglobal filter and a local filter, respectively, to prune the search space.\nExperimental results demonstrate that our index size and indexing time\noutperform the state-of-the-art label-constrained reachability indexing\ntechnique on 16 real datasets. TDR can efficiently answer pattern-constrained\nreachability queries, including label-constrained reachability queries.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u590d\u5408\u6a21\u5f0f\u63d0\u51faPCR\u67e5\u8be2\uff0c\u6784\u5efaTDR\u7d22\u5f15\u4ee5\u63d0\u5347\u67e5\u8be2\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u572816\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u53ef\u8fbe\u6027\u67e5\u8be2\u65e0\u6cd5\u8ba9\u7528\u6237\u901a\u8fc7\u7ec4\u5408\u67e5\u8be2\u6a21\u5f0f\u63cf\u8ff0\u590d\u6742\u67e5\u8be2\u9700\u6c42\u3002", "method": "\u5f15\u5165\u590d\u5408\u6a21\u5f0f\u63d0\u51faPCR\u67e5\u8be2\uff0c\u6784\u5efa\u7531\u591a\u8def\u7d22\u5f15\u548c\u8def\u5f84\u7d22\u5f15\u7ec4\u6210\u7684TDR\u7d22\u5f15\uff0c\u5c06\u9876\u70b9\u53ef\u8fbe\u9876\u70b9\u5206\u89e3\u6210\u5757\u5e76\u5206\u522b\u54c8\u5e0c\u5230\u6c34\u5e73\u548c\u5782\u76f4\u7ef4\u5ea6\u7d22\u5f15\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u572816\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u7d22\u5f15\u5927\u5c0f\u548c\u7d22\u5f15\u65f6\u95f4\u4f18\u4e8e\u73b0\u6709\u6807\u7b7e\u7ea6\u675f\u53ef\u8fbe\u6027\u7d22\u5f15\u6280\u672f\u3002", "conclusion": "TDR\u80fd\u6709\u6548\u56de\u7b54\u6a21\u5f0f\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2\uff0c\u5305\u62ec\u6807\u7b7e\u7ea6\u675f\u53ef\u8fbe\u6027\u67e5\u8be2\u3002"}}
{"id": "2511.01292", "pdf": "https://arxiv.org/pdf/2511.01292", "abs": "https://arxiv.org/abs/2511.01292", "authors": ["Samet Demir", "Zafer Dogan"], "title": "Optimal Attention Temperature Enhances In-Context Learning under Distribution Shift", "categories": ["stat.ML", "cs.LG"], "comment": "26 pages, 6 figures", "summary": "Pretrained Transformers excel at in-context learning (ICL), inferring new\ntasks from only a handful of examples. Yet, their ICL performance can degrade\nsharply under distribution shift between pretraining and test data, a regime\nincreasingly common in real-world deployments. While recent empirical work\nhints that adjusting the attention temperature in the softmax can enhance\nTransformer performance, the attention temperature's role in ICL under\ndistribution shift remains unexplored. This paper provides the first\ntheoretical and empirical study of attention temperature for ICL under\ndistribution shift. Using a simplified but expressive \"linearized softmax\"\nframework, we derive closed-form generalization error expressions and prove\nthat shifts in input covariance or label noise substantially impair ICL, but\nthat an optimal attention temperature exists which minimizes this error. We\nthen validate our predictions through extensive simulations on linear\nregression tasks and large-scale experiments with GPT-2 and LLaMA2-7B on\nquestion-answering benchmarks. Our results establish attention temperature as a\nprincipled and powerful mechanism for improving the robustness of ICL in\npretrained Transformers, advancing theoretical understanding and providing\nactionable guidance for selecting attention temperature in practice.", "AI": {"tldr": "\u7814\u7a76\u5206\u5e03\u504f\u79fb\u4e0b\u9884\u8bad\u7ec3Transformer\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u6ce8\u610f\u529b\u6e29\u5ea6\u7684\u4f5c\u7528\uff0c\u7406\u8bba\u63a8\u5bfc\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u53ef\u63d0\u5347\u9c81\u68d2\u6027\u3002", "motivation": "\u9884\u8bad\u7ec3Transformer\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u6ce8\u610f\u529b\u6e29\u5ea6\u5728\u5176\u4e2d\u7684\u4f5c\u7528\u672a\u88ab\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u201c\u7ebf\u6027\u5316softmax\u201d\u6846\u67b6\u63a8\u5bfc\u6cdb\u5316\u8bef\u5dee\u8868\u8fbe\u5f0f\uff0c\u5728\u56de\u5f52\u4efb\u52a1\u548c\u95ee\u7b54\u57fa\u51c6\u4e0a\u8fdb\u884c\u6a21\u62df\u4e0e\u5b9e\u9a8c\u3002", "result": "\u63a8\u5bfc\u8bc1\u660e\u8f93\u5165\u534f\u65b9\u5dee\u6216\u6807\u7b7e\u566a\u58f0\u504f\u79fb\u4f1a\u635f\u5bb3\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5b58\u5728\u6700\u4f18\u6ce8\u610f\u529b\u6e29\u5ea6\u4f7f\u8bef\u5dee\u6700\u5c0f\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u9884\u6d4b\u3002", "conclusion": "\u6ce8\u610f\u529b\u6e29\u5ea6\u662f\u63d0\u5347\u9884\u8bad\u7ec3Transformer\u4e0a\u4e0b\u6587\u5b66\u4e60\u9c81\u68d2\u6027\u7684\u6709\u6548\u673a\u5236\uff0c\u4e3a\u5b9e\u9645\u9009\u62e9\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2511.01597", "pdf": "https://arxiv.org/pdf/2511.01597", "abs": "https://arxiv.org/abs/2511.01597", "authors": ["Markus Dertwinkel-Kalt", "Hans-Theo Normann", "Jan-Niklas Tiede", "Tobias Werner"], "title": "Deceptively Framed Lotteries in Consumer Markets", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Consumers often face products sold as lotteries rather than fixed outcomes. A\nprominent case is the loot box in video games, where players pay for randomized\nrewards. We investigate how presentation formats shape consumer beliefs and\nwillingness to pay. In an online experiment with 802 participants, sellers\ncould frame lotteries using two common manipulations: censoring outcome\nprobabilities and selectively highlighting rare successes. More than 80\\% of\nsellers adopted such deceptive frames, particularly when both manipulations\nwere available. These choices substantially inflated buyer beliefs and\nincreased willingness to pay of up to six times the expected value. Sellers\nanticipated this effect and raised prices accordingly. Our results show how\ndeceptive framing systematically shifts consumer beliefs and enables firms to\nextract additional surplus. For marketing practice, this highlights the\nstrategic value of framing tools in probabilistic selling models; for policy,\nit underscores the importance of transparency requirements in protecting\nconsumers.", "AI": {"tldr": "\u7814\u7a76\u9500\u552e\u5f69\u7968\u5f0f\u4ea7\u54c1\u65f6\u5c55\u793a\u683c\u5f0f\u5bf9\u6d88\u8d39\u8005\u4fe1\u5ff5\u548c\u652f\u4ed8\u610f\u613f\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6b3a\u9a97\u6027\u6846\u67b6\u4f1a\u5f71\u54cd\u6d88\u8d39\u8005\u5e76\u4f7f\u4f01\u4e1a\u83b7\u5229\u3002", "motivation": "\u63a2\u7a76\u5c55\u793a\u683c\u5f0f\u5982\u4f55\u5851\u9020\u6d88\u8d39\u8005\u4fe1\u5ff5\u548c\u652f\u4ed8\u610f\u613f\u3002", "method": "\u8fdb\u884c\u6709802\u540d\u53c2\u4e0e\u8005\u7684\u5728\u7ebf\u5b9e\u9a8c\uff0c\u5356\u5bb6\u91c7\u7528\u9690\u7792\u7ed3\u679c\u6982\u7387\u548c\u7a81\u51fa\u7f55\u89c1\u6210\u529f\u4e24\u79cd\u5e38\u89c1\u64cd\u7eb5\u65b9\u5f0f\u6784\u5efa\u5f69\u7968\u6846\u67b6\u3002", "result": "\u8d8580%\u5356\u5bb6\u91c7\u7528\u6b3a\u9a97\u6027\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e70\u5bb6\u4fe1\u5ff5\u548c\u652f\u4ed8\u610f\u613f\uff0c\u5356\u5bb6\u4e5f\u76f8\u5e94\u63d0\u4ef7\u3002", "conclusion": "\u6b3a\u9a97\u6027\u6846\u67b6\u4f1a\u7cfb\u7edf\u6027\u6539\u53d8\u6d88\u8d39\u8005\u4fe1\u5ff5\uff0c\u4f7f\u4f01\u4e1a\u83b7\u53d6\u989d\u5916\u5229\u76ca\uff0c\u5f3a\u8c03\u8425\u9500\u4e2d\u6846\u67b6\u5de5\u5177\u6218\u7565\u4ef7\u503c\u548c\u653f\u7b56\u4e2d\u900f\u660e\u5ea6\u8981\u6c42\u5bf9\u4fdd\u62a4\u6d88\u8d39\u8005\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.00037", "pdf": "https://arxiv.org/pdf/2511.00037", "abs": "https://arxiv.org/abs/2511.00037", "authors": ["Riya Gupta", "Alexander Chowdhury", "Sahil Nalawade"], "title": "Benchmarking Federated Learning Frameworks for Medical Imaging Deployment: A Comparative Study of NVIDIA FLARE, Flower, and Owkin Substra", "categories": ["cs.CV", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) has emerged as a transformative paradigm in medical\nAI, enabling collaborative model training across institutions without direct\ndata sharing. This study benchmarks three prominent FL frameworks NVIDIA FLARE,\nFlower, and Owkin Substra to evaluate their suitability for medical imaging\napplications in real-world settings. Using the PathMNIST dataset, we assess\nmodel performance, convergence efficiency, communication overhead, scalability,\nand developer experience. Results indicate that NVIDIA FLARE offers superior\nproduction scalability, Flower provides flexibility for prototyping and\nacademic research, and Owkin Substra demonstrates exceptional privacy and\ncompliance features. Each framework exhibits strengths optimized for distinct\nuse cases, emphasizing their relevance to practical deployment in healthcare\nenvironments.", "AI": {"tldr": "\u672c\u6587\u5bf9NVIDIA FLARE\u3001Flower\u548cOwkin Substra\u4e09\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u5728\u533b\u5b66\u6210\u50cf\u5e94\u7528\u4e2d\u7684\u9002\u7528\u6027\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6307\u51fa\u5404\u6846\u67b6\u4f18\u52bf\u3002", "motivation": "\u8bc4\u4f30\u4e09\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u5728\u73b0\u5b9e\u73af\u5883\u533b\u5b66\u6210\u50cf\u5e94\u7528\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528PathMNIST\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3001\u6536\u655b\u6548\u7387\u3001\u901a\u4fe1\u5f00\u9500\u3001\u53ef\u6269\u5c55\u6027\u548c\u5f00\u53d1\u8005\u4f53\u9a8c\u3002", "result": "NVIDIA FLARE\u751f\u4ea7\u53ef\u6269\u5c55\u6027\u4f18\u8d8a\uff0cFlower\u9002\u5408\u539f\u578b\u8bbe\u8ba1\u548c\u5b66\u672f\u7814\u7a76\uff0cOwkin Substra\u9690\u79c1\u548c\u5408\u89c4\u6027\u51fa\u8272\u3002", "conclusion": "\u5404\u6846\u67b6\u6709\u9002\u5408\u4e0d\u540c\u7528\u4f8b\u7684\u4f18\u52bf\uff0c\u5bf9\u533b\u7597\u73af\u5883\u5b9e\u9645\u90e8\u7f72\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.01404", "pdf": "https://arxiv.org/pdf/2511.01404", "abs": "https://arxiv.org/abs/2511.01404", "authors": ["Xiaoyu Liu", "Yiqing Wu", "Ruidong Han", "Fuzhen Zhuang", "Xiang Li", "Wei Lin"], "title": "A Soft-partitioned Semi-supervised Collaborative Transfer Learning Approach for Multi-Domain Recommendation", "categories": ["cs.IR"], "comment": "Accepted by CIKM'25", "summary": "In industrial practice, Multi-domain Recommendation (MDR) plays a crucial\nrole. Shared-specific architectures are widely used in industrial solutions to\ncapture shared and unique attributes via shared and specific parameters.\nHowever, with imbalanced data across different domains, these models face two\nkey issues: (1) Overwhelming: Dominant domain data skews model performance,\nneglecting non-dominant domains. (2) Overfitting: Sparse data in non-dominant\ndomains leads to overfitting in specific parameters. To tackle these\nchallenges, we propose Soft-partitioned Semi-supervised Collaborative Transfer\nLearning (SSCTL) for multi-domain recommendation. SSCTL generates dynamic\nparameters to address the overwhelming issue, thus shifting focus towards\nsamples from non-dominant domains. To combat overfitting, it leverages\npseudo-labels with weights from dominant domain instances to enhance\nnon-dominant domain data. We conduct comprehensive experiments, both online and\noffline, to validate the efficacy of our proposed method. Online tests yielded\nsignificant improvements across various domains, with increases in GMV ranging\nfrom 0.54% to 2.90% and enhancements in CTR ranging from 0.22% to 1.69%.", "AI": {"tldr": "\u63d0\u51faSSCTL\u65b9\u6cd5\u89e3\u51b3\u591a\u9886\u57df\u63a8\u8350\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u63d0\u5347GMV\u548cCTR\u3002", "motivation": "\u5de5\u4e1a\u4e2d\u591a\u9886\u57df\u63a8\u8350\u5e38\u7528\u5171\u4eab-\u7279\u5b9a\u67b6\u6784\uff0c\u4f46\u4e0d\u540c\u9886\u57df\u6570\u636e\u4e0d\u5e73\u8861\u65f6\uff0c\u8be5\u67b6\u6784\u5b58\u5728\u6570\u636e\u538b\u5012\u6027\u548c\u8fc7\u62df\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51faSoft-partitioned Semi-supervised Collaborative Transfer Learning (SSCTL)\u65b9\u6cd5\uff0c\u751f\u6210\u52a8\u6001\u53c2\u6570\u89e3\u51b3\u538b\u5012\u6027\u95ee\u9898\uff0c\u5229\u7528\u5e26\u6743\u91cd\u4f2a\u6807\u7b7e\u589e\u5f3a\u975e\u4e3b\u5bfc\u9886\u57df\u6570\u636e\u3002", "result": "\u5728\u7ebf\u6d4b\u8bd5\u4e2d\u5404\u9886\u57dfGMV\u63d0\u53470.54% - 2.90%\uff0cCTR\u63d0\u53470.22% - 1.69%\u3002", "conclusion": "\u63d0\u51fa\u7684SSCTL\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u591a\u9886\u57df\u63a8\u8350\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002"}}
{"id": "2511.00382", "pdf": "https://arxiv.org/pdf/2511.00382", "abs": "https://arxiv.org/abs/2511.00382", "authors": ["Mina Taraghi", "Yann Pequignot", "Amin Nikanjam", "Mohamed Amine Merzouk", "Foutse Khomh"], "title": "Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Organizations are increasingly adopting and adapting Large Language Models\n(LLMs) hosted on public repositories such as HuggingFace. Although these\nadaptations often improve performance on specialized downstream tasks, recent\nevidence indicates that they can also degrade a model's safety or fairness.\nSince different fine-tuning techniques may exert distinct effects on these\ncritical dimensions, this study undertakes a systematic assessment of their\ntrade-offs. Four widely used Parameter-Efficient Fine-Tuning methods, LoRA,\nIA3, Prompt-Tuning, and P-Tuning, are applied to four instruction-tuned model\nfamilies (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, and Gemma-7B). In total, 235\nfine-tuned variants are evaluated across eleven safety hazard categories and\nnine demographic fairness dimensions. The results show that adapter-based\napproaches (LoRA, IA3) tend to improve safety scores and are the least\ndisruptive to fairness, retaining higher accuracy and lower bias scores. In\ncontrast, prompt-based methods (Prompt-Tuning and P-Tuning) generally reduce\nsafety and cause larger fairness regressions, with decreased accuracy and\nincreased bias. Alignment shifts are strongly moderated by base model type:\nLLaMA remains stable, Qwen records modest gains, Gemma experiences the steepest\nsafety decline, and Mistral, which is released without an internal moderation\nlayer, displays the greatest variance. Improvements in safety do not\nnecessarily translate into improvements in fairness, and no single\nconfiguration optimizes all fairness metrics simultaneously, indicating an\ninherent trade-off between these objectives. These findings suggest a practical\nguideline for safety-critical deployments: begin with a well-aligned base\nmodel, favour adapter-based PEFT, and conduct category-specific audits of both\nsafety and fairness.", "AI": {"tldr": "\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u56db\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u548c\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u9002\u914d\u5668\u65b9\u6cd5\u66f4\u4f18\uff0c\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u8868\u73b0\u4e0d\u540c\uff0c\u4e8c\u8005\u5b58\u5728\u6743\u8861\u5173\u7cfb\u5e76\u7ed9\u51fa\u90e8\u7f72\u5efa\u8bae\u3002", "motivation": "\u4e0d\u540c\u5fae\u8c03\u6280\u672f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u548c\u516c\u5e73\u6027\u6709\u4e0d\u540c\u5f71\u54cd\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u5176\u6743\u8861\u3002", "method": "\u5bf9\u56db\u79cd\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5bb6\u65cf\u5e94\u7528\u56db\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u8bc4\u4f30235\u4e2a\u5fae\u8c03\u53d8\u4f53\u572811\u4e2a\u5b89\u5168\u5371\u5bb3\u7c7b\u522b\u548c9\u4e2a\u4eba\u53e3\u516c\u5e73\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u9002\u914d\u5668\u65b9\u6cd5\uff08LoRA\u3001IA3\uff09\u63d0\u5347\u5b89\u5168\u5206\u6570\u4e14\u5bf9\u516c\u5e73\u6027\u5f71\u54cd\u5c0f\uff0c\u63d0\u793a\u65b9\u6cd5\uff08Prompt - Tuning\u548cP - Tuning\uff09\u964d\u4f4e\u5b89\u5168\u548c\u516c\u5e73\u6027\uff1b\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u5bf9\u9f50\u53d8\u5316\u4e0d\u540c\uff1b\u5b89\u5168\u63d0\u5347\u672a\u5fc5\u5e26\u6765\u516c\u5e73\u6027\u63d0\u5347\uff0c\u65e0\u5355\u4e00\u914d\u7f6e\u53ef\u540c\u65f6\u4f18\u5316\u6240\u6709\u516c\u5e73\u6307\u6807\u3002", "conclusion": "\u5b89\u5168\u5173\u952e\u90e8\u7f72\u5e94\u9009\u7528\u5bf9\u9f50\u826f\u597d\u7684\u57fa\u7840\u6a21\u578b\uff0c\u4f18\u5148\u4f7f\u7528\u9002\u914d\u5668PEFT\uff0c\u5e76\u5bf9\u5b89\u5168\u548c\u516c\u5e73\u6027\u8fdb\u884c\u7279\u5b9a\u7c7b\u522b\u5ba1\u8ba1\u3002"}}
{"id": "2511.00517", "pdf": "https://arxiv.org/pdf/2511.00517", "abs": "https://arxiv.org/abs/2511.00517", "authors": ["Shuochuan Li", "Dong Wang", "Patanamon Thongtanunam", "Zan Wang", "Jiuqiao Yu", "Junjie Chen"], "title": "Issue-Oriented Agent-Based Framework for Automated Review Comment Generation", "categories": ["cs.SE"], "comment": null, "summary": "Code review (CR) is a crucial practice for ensuring software quality. Various\nautomated review comment generation techniques have been proposed to streamline\nthe labor-intensive process. However, existing approaches heavily rely on a\nsingle model to identify various issues within the code, limiting the model's\nability to handle the diverse, issue-specific nature of code changes and\nleading to non-informative comments, especially in complex scenarios such as\nbug fixes. To address these limitations, we propose RevAgent, a novel\nagent-based issue-oriented framework, decomposes the task into three stages:\n(1) Generation Stage, where five category-specific commentator agents analyze\ncode changes from distinct issue perspectives and generate candidate comments;\n(2) Discrimination Stage, where a critic agent selects the most appropriate\nissue-comment pair; and (3) Training Stage, where all agents are fine-tuned on\ncurated, category-specific data to enhance task specialization. Evaluation\nresults show that RevAgent significantly outperforms state-of-the-art PLM- and\nLLM-based baselines, with improvements of 12.90\\%, 10.87\\%, 6.32\\%, and 8.57\\%\non BLEU, ROUGE-L, METEOR, and SBERT, respectively. It also achieves relatively\nhigher accuracy in issue-category identification, particularly for challenging\nscenarios. Human evaluations further validate the practicality of RevAgent in\ngenerating accurate, readable, and context-aware review comments. Moreover,\nRevAgent delivers a favorable trade-off between performance and efficiency.", "AI": {"tldr": "\u63d0\u51faRevAgent\u6846\u67b6\u6539\u8fdb\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u4e14\u5b9e\u7528\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u6280\u672f\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\uff0c\u5904\u7406\u590d\u6742\u573a\u666f\u80fd\u529b\u6709\u9650\uff0c\u8bc4\u8bba\u7f3a\u4e4f\u4fe1\u606f\u3002", "method": "\u63d0\u51faRevAgent\u6846\u67b6\uff0c\u5206\u751f\u6210\u3001\u5224\u522b\u3001\u8bad\u7ec3\u4e09\u9636\u6bb5\uff0c\u7528\u591a\u4e2a\u7279\u5b9a\u7c7b\u522b\u8bc4\u8bba\u5458\u4ee3\u7406\u548c\u4e00\u4e2a\u6279\u8bc4\u4ee3\u7406\uff0c\u5e76\u5728\u7279\u5b9a\u7c7b\u522b\u6570\u636e\u4e0a\u5fae\u8c03\u3002", "result": "RevAgent\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u95ee\u9898\u7c7b\u522b\u8bc6\u522b\u51c6\u786e\u7387\u8f83\u9ad8\uff0c\u4eba\u5de5\u8bc4\u4f30\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\uff0c\u6027\u80fd\u548c\u6548\u7387\u5e73\u8861\u826f\u597d\u3002", "conclusion": "RevAgent\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u662f\u4e00\u4e2a\u5b9e\u7528\u9ad8\u6548\u7684\u6846\u67b6\u3002"}}
{"id": "2511.00051", "pdf": "https://arxiv.org/pdf/2511.00051", "abs": "https://arxiv.org/abs/2511.00051", "authors": ["Da Chang", "Peng Xue", "Yu Li", "Yongxiang Liu", "Pengxiang Xu", "Shixun Zhang"], "title": "Calibrating and Rotating: A Unified Framework for Weight Conditioning in PEFT", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) methods are crucial for adapting large\npre-trained models. Among these, LoRA is considered a foundational approach.\nBuilding on this, the influential DoRA method enhances performance by\ndecomposing weight updates into magnitude and direction. However, its\nunderlying mechanism remains unclear, and it introduces significant\ncomputational overhead. In this work, we first identify that DoRA's success\nstems from its capacity to increase the singular value entropy of the weight\nupdate matrix, which promotes a more uniform update distribution akin to full\nfine-tuning. We then reformulate DoRA into a mathematically equivalent and more\nefficient matrix form, revealing it as a learnable weight conditioning method.\nBased on this insight, we propose a unified framework for designing advanced\nPEFT methods by exploring two orthogonal dimensions: the architectural\nplacement and the transformation type of the conditioning matrix. Within this\nframework, we introduce two novel methods: (1) \\textbf{Pre-Diag}, which applies\na diagonal conditioning matrix before the LoRA update to efficiently calibrate\nthe pre-trained weights, thereby enhancing performance while reducing training\ntime; and (2) \\textbf{S}kewed \\textbf{O}rthogonal \\textbf{R}otation\n\\textbf{A}daptation (\\textbf{SORA}), which employs a parameter-efficient\northogonal rotation to perform a more powerful, norm-preserving transformation\nof the feature space. Extensive experiments on natural language understanding\nand generation tasks demonstrate that our proposed methods achieve superior\nperformance and efficiency compared to both LoRA and DoRA. The code is\navailable at https://github.com/MaeChd/SORA.", "AI": {"tldr": "\u672c\u6587\u5256\u6790DoRA\u65b9\u6cd5\u673a\u5236\uff0c\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u8bbe\u8ba1\u5148\u8fdbPEFT\u65b9\u6cd5\uff0c\u5f15\u5165Pre - Diag\u548cSORA\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u548c\u6548\u7387\u8d85LoRA\u548cDoRA\u3002", "motivation": "DoRA\u65b9\u6cd5\u6f5c\u5728\u673a\u5236\u4e0d\u660e\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u9700\u6df1\u5165\u7814\u7a76\u5176\u673a\u5236\u5e76\u8bbe\u8ba1\u66f4\u4f18PEFT\u65b9\u6cd5\u3002", "method": "\u5148\u5206\u6790DoRA\u6210\u529f\u6e90\u4e8e\u589e\u52a0\u6743\u91cd\u66f4\u65b0\u77e9\u9635\u5947\u5f02\u503c\u71b5\uff0c\u5c06\u5176\u91cd\u6784\u6210\u7b49\u4ef7\u9ad8\u6548\u77e9\u9635\u5f62\u5f0f\uff0c\u63d0\u51fa\u8bbe\u8ba1PEFT\u65b9\u6cd5\u7edf\u4e00\u6846\u67b6\uff0c\u5f15\u5165Pre - Diag\u548cSORA\u65b9\u6cd5\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cPre - Diag\u548cSORA\u6027\u80fd\u548c\u6548\u7387\u4f18\u4e8eLoRA\u548cDoRA\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347PEFT\u65b9\u6cd5\u6027\u80fd\u548c\u6548\u7387\uff0c\u7edf\u4e00\u6846\u67b6\u6709\u52a9\u4e8e\u8bbe\u8ba1\u5148\u8fdbPEFT\u65b9\u6cd5\u3002"}}
{"id": "2511.01553", "pdf": "https://arxiv.org/pdf/2511.01553", "abs": "https://arxiv.org/abs/2511.01553", "authors": ["Elvin Hajizada", "Danielle Rager", "Timothy Shea", "Leobardo Campos-Macias", "Andreas Wild", "Eyke H\u00fcllermeier", "Yulia Sandamirskaya", "Mike Davies"], "title": "Real-time Continual Learning on Intel Loihi 2", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.NE"], "comment": null, "summary": "AI systems on edge devices face a critical challenge in open-world\nenvironments: adapting when data distributions shift and novel classes emerge.\nWhile offline training dominates current paradigms, online continual learning\n(OCL)--where models learn incrementally from non-stationary streams without\ncatastrophic forgetting--remains challenging in power-constrained settings. We\npresent a neuromorphic solution called CLP-SNN: a spiking neural network\narchitecture for Continually Learning Prototypes and its implementation on\nIntel's Loihi 2 chip. Our approach introduces three innovations: (1)\nevent-driven and spatiotemporally sparse local learning, (2) a self-normalizing\nthree-factor learning rule maintaining weight normalization, and (3) integrated\nneurogenesis and metaplasticity for capacity expansion and forgetting\nmitigation. On OpenLORIS few-shot learning experiments, CLP-SNN achieves\naccuracy competitive with replay methods while being rehearsal-free. CLP-SNN\ndelivers transformative efficiency gains: 70\\times faster (0.33ms vs 23.2ms),\nand 5,600\\times more energy efficient (0.05mJ vs 281mJ) than the best\nalternative OCL on edge GPU. This demonstrates that co-designed brain-inspired\nalgorithms and neuromorphic hardware can break traditional accuracy-efficiency\ntrade-offs for future edge AI systems.", "AI": {"tldr": "\u63d0\u51faCLP - SNN\u795e\u7ecf\u5f62\u6001\u89e3\u51b3\u65b9\u6848\uff0c\u5728OpenLORIS\u5b9e\u9a8c\u4e2d\u51c6\u786e\u7387\u6709\u7ade\u4e89\u529b\uff0c\u6548\u7387\u5927\u5e45\u63d0\u5347\uff0c\u6253\u7834\u4f20\u7edf\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907AI\u7cfb\u7edf\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u6570\u636e\u5206\u5e03\u53d8\u5316\u548c\u65b0\u7c7b\u522b\u51fa\u73b0\u65f6\u7684\u9002\u5e94\u95ee\u9898\uff0c\u5e94\u5bf9\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u5728\u529f\u7387\u53d7\u9650\u573a\u666f\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faCLP - SNN\u5c16\u5cf0\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5305\u62ec\u4e8b\u4ef6\u9a71\u52a8\u548c\u65f6\u7a7a\u7a00\u758f\u5c40\u90e8\u5b66\u4e60\u3001\u81ea\u5f52\u4e00\u5316\u4e09\u56e0\u7d20\u5b66\u4e60\u89c4\u5219\u3001\u96c6\u6210\u795e\u7ecf\u53d1\u751f\u548c\u5143\u53ef\u5851\u6027\u3002", "result": "\u5728OpenLORIS\u5c11\u6837\u672c\u5b66\u4e60\u5b9e\u9a8c\u4e2d\u51c6\u786e\u7387\u4e0e\u91cd\u653e\u65b9\u6cd5\u76f8\u5f53\u4e14\u65e0\u9700\u6392\u7ec3\uff0c\u6bd4\u8fb9\u7f18GPU\u4e0a\u6700\u4f73\u66ff\u4ee3OCL\u5feb70\u500d\u3001\u80fd\u6548\u9ad85600\u500d\u3002", "conclusion": "\u534f\u540c\u8bbe\u8ba1\u7684\u8111\u542f\u53d1\u7b97\u6cd5\u548c\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u53ef\u6253\u7834\u672a\u6765\u8fb9\u7f18AI\u7cfb\u7edf\u4f20\u7edf\u7684\u51c6\u786e\u7387 - \u6548\u7387\u6743\u8861\u3002"}}
{"id": "2511.01602", "pdf": "https://arxiv.org/pdf/2511.01602", "abs": "https://arxiv.org/abs/2511.01602", "authors": ["Xinyue Yang", "Chen Zheng", "Yaoyang Hou", "Renhao Zhang", "Yiyan Zhang", "Yanjun Wu", "Heng Zhang"], "title": "L2T-Tune:LLM-Guided Hybrid Database Tuning with LHS and TD3", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Configuration tuning is critical for database performance. Although recent\nadvancements in database tuning have shown promising results in throughput and\nlatency improvement, challenges remain. First, the vast knob space makes direct\noptimization unstable and slow to converge. Second, reinforcement learning\npipelines often lack effective warm-start guidance and require long offline\ntraining. Third, transferability is limited: when hardware or workloads change,\nexisting models typically require substantial retraining to recover\nperformance.\n  To address these limitations, we propose L2T-Tune, a new LLM-guided hybrid\ndatabase tuning framework that features a three-stage pipeline: Stage one\nperforms a warm start that simultaneously generates uniform samples across the\nknob space and logs them into a shared pool; Stage two leverages a large\nlanguage model to mine and prioritize tuning hints from manuals and community\ndocuments for rapid convergence. Stage three uses the warm-start sample pool to\nreduce the dimensionality of knobs and state features, then fine-tunes the\nconfiguration with the Twin Delayed Deep Deterministic Policy Gradient\nalgorithm.\n  We conduct experiments on L2T-Tune and the state-of-the-art models. Compared\nwith the best-performing alternative, our approach improves performance by an\naverage of 37.1% across all workloads, and by up to 73% on TPC-C. Compared with\nmodels trained with reinforcement learning, it achieves rapid convergence in\nthe offline tuning stage on a single server. Moreover, during the online tuning\nstage, it only takes 30 steps to achieve best results.", "AI": {"tldr": "\u63d0\u51faLLM\u5f15\u5bfc\u7684\u6df7\u5408\u6570\u636e\u5e93\u8c03\u4f18\u6846\u67b6L2T - Tune\uff0c\u7ecf\u5b9e\u9a8c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u5e93\u8c03\u4f18\u5b58\u5728\u65cb\u94ae\u7a7a\u95f4\u5927\u3001\u5f3a\u5316\u5b66\u4e60\u7f3a\u4e4f\u6709\u6548\u70ed\u542f\u52a8\u3001\u53ef\u8fc1\u79fb\u6027\u6709\u9650\u7b49\u95ee\u9898\u3002", "method": "L2T - Tune\u91c7\u7528\u4e09\u9636\u6bb5\u7ba1\u9053\uff0c\u7b2c\u4e00\u9636\u6bb5\u70ed\u542f\u52a8\u5e76\u751f\u6210\u6837\u672c\u5b58\u5165\u5171\u4eab\u6c60\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6316\u6398\u548c\u6392\u5e8f\u8c03\u4f18\u63d0\u793a\uff1b\u7b2c\u4e09\u9636\u6bb5\u5229\u7528\u6837\u672c\u6c60\u964d\u7ef4\u5e76\u4f7f\u7528TD3\u7b97\u6cd5\u5fae\u8c03\u914d\u7f6e\u3002", "result": "\u4e0e\u6700\u4f73\u66ff\u4ee3\u65b9\u6848\u76f8\u6bd4\uff0c\u5728\u6240\u6709\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5e73\u5747\u6027\u80fd\u63d0\u534737.1%\uff0cTPC - C\u4e0a\u6700\u9ad8\u63d0\u534773%\uff1b\u79bb\u7ebf\u8c03\u4f18\u9636\u6bb5\u6536\u655b\u5feb\uff0c\u5728\u7ebf\u8c03\u4f18\u4ec5\u970030\u6b65\u8fbe\u6700\u4f73\u6548\u679c\u3002", "conclusion": "L2T - Tune\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6570\u636e\u5e93\u8c03\u4f18\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347\u6570\u636e\u5e93\u6027\u80fd\u3002"}}
{"id": "2511.01628", "pdf": "https://arxiv.org/pdf/2511.01628", "abs": "https://arxiv.org/abs/2511.01628", "authors": ["Arran Carter", "Torben Sell"], "title": "Partial Trace-Class Bayesian Neural Networks", "categories": ["stat.ML", "cs.LG", "stat.ME", "62G99"], "comment": "10 pages, 4 figures", "summary": "Bayesian neural networks (BNNs) allow rigorous uncertainty quantification in\ndeep learning, but often come at a prohibitive computational cost. We propose\nthree different innovative architectures of partial trace-class Bayesian neural\nnetworks (PaTraC BNNs) that enable uncertainty quantification comparable to\nstandard BNNs but use significantly fewer Bayesian parameters. These PaTraC\nBNNs have computational and statistical advantages over standard Bayesian\nneural networks in terms of speed and memory requirements. Our proposed\nmethodology therefore facilitates reliable, robust, and scalable uncertainty\nquantification in neural networks. The three architectures build on trace-class\nneural network priors which induce an ordering of the neural network\nparameters, and are thus a natural choice in our framework. In a numerical\nsimulation study, we verify the claimed benefits, and further illustrate the\nperformance of our proposed methodology on a real-world dataset.", "AI": {"tldr": "\u63d0\u51fa\u90e8\u5206\u8ff9\u7c7b\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff08PaTraC BNNs\uff09\u4e09\u79cd\u67b6\u6784\uff0c\u53ef\u5b9e\u73b0\u4e0e\u6807\u51c6BNNs\u76f8\u5f53\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4e14\u8ba1\u7b97\u548c\u7edf\u8ba1\u4e0a\u6709\u4f18\u52bf\u3002", "motivation": "\u6807\u51c6\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff08BNNs\uff09\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u4e0d\u540c\u7684PaTraC BNNs\u67b6\u6784\uff0c\u57fa\u4e8e\u8ff9\u7c7b\u795e\u7ecf\u7f51\u7edc\u5148\u9a8c\u3002", "result": "\u6570\u503c\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u4e86\u4f18\u52bf\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u52a9\u4e8e\u795e\u7ecf\u7f51\u7edc\u4e2d\u53ef\u9760\u3001\u7a33\u5065\u548c\u53ef\u6269\u5c55\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002"}}
{"id": "2511.00552", "pdf": "https://arxiv.org/pdf/2511.00552", "abs": "https://arxiv.org/abs/2511.00552", "authors": ["Santhi Bharath Punati", "Sandeep Kanta", "Udaya Bhasker Cheerala", "Madhusudan G Lanjewar", "Praveen Damacharla"], "title": "Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales", "categories": ["cs.LG", "cs.AI", "econ.GN", "q-fin.EC"], "comment": "5 pages, 2025 6th International Conference on Data Analytics for\n  Business and Industry (ICDABI)", "summary": "Accurate multi-horizon retail forecasts are critical for inventory and\npromotions. We present a novel study of weekly Walmart sales (45 stores,\n2010--2012) using a Temporal Fusion Transformer (TFT) that fuses static store\nidentifiers with time-varying exogenous signals (holidays, CPI, fuel price,\ntemperature). The pipeline produces 1--5-week-ahead probabilistic forecasts via\nQuantile Loss, yielding calibrated 90\\% prediction intervals and\ninterpretability through variable-selection networks, static enrichment, and\ntemporal attention. On a fixed 2012 hold-out dataset, TFT achieves an RMSE of\n\\$57.9k USD per store-week and an $R^2$ of 0.9875. Across a 5-fold\nchronological cross-validation, the averages are RMSE = \\$64.6k USD and $R^2$ =\n0.9844, outperforming the XGB, CNN, LSTM, and CNN-LSTM baseline models. These\nresults demonstrate practical value for inventory planning and holiday-period\noptimization, while maintaining model transparency.", "AI": {"tldr": "\u4f7f\u7528TFT\u5bf9\u6c83\u5c14\u739b\u5468\u9500\u552e\u6570\u636e\u8fdb\u884c\u591a\u5468\u671f\u9884\u6d4b\uff0c\u5728\u7559\u4e00\u6570\u636e\u96c6\u548c\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5bf9\u5e93\u5b58\u89c4\u5212\u6709\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u51c6\u786e\u7684\u591a\u5468\u671f\u96f6\u552e\u9884\u6d4b\u5bf9\u5e93\u5b58\u548c\u4fc3\u9500\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5bf9\u6c83\u5c14\u739b\u9500\u552e\u6570\u636e\u8fdb\u884c\u6709\u6548\u9884\u6d4b\u3002", "method": "\u4f7f\u7528Temporal Fusion Transformer (TFT)\u878d\u5408\u9759\u6001\u5546\u5e97\u6807\u8bc6\u548c\u65f6\u53d8\u5916\u751f\u4fe1\u53f7\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u635f\u5931\u8fdb\u884c1 - 5\u5468\u6982\u7387\u9884\u6d4b\u3002", "result": "\u57282012\u7559\u4e00\u6570\u636e\u96c6\u4e0aRMSE\u4e3a\u6bcf\u5468\u6bcf\u5bb6\u5e9757,900\u7f8e\u5143\uff0c$R^2$\u4e3a0.9875\uff1b5\u6298\u4ea4\u53c9\u9a8c\u8bc1\u4e2dRMSE\u5e73\u5747\u4e3a64,600\u7f8e\u5143\uff0c$R^2$\u4e3a0.9844\uff0c\u4f18\u4e8eXGB\u3001CNN\u3001LSTM\u548cCNN - LSTM\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5bf9\u5e93\u5b58\u89c4\u5212\u548c\u5047\u671f\u4f18\u5316\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u4e14\u4fdd\u6301\u4e86\u6a21\u578b\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.00205", "pdf": "https://arxiv.org/pdf/2511.00205", "abs": "https://arxiv.org/abs/2511.00205", "authors": ["Yuhan Deng", "Akshay Srivatsan", "Sebastian Ingino", "Francis Chua", "Yasmine Mitchell", "Matthew Vilaysack", "Keith Winstein"], "title": "Fix: externalizing network I/O in serverless computing", "categories": ["cs.OS", "cs.DC"], "comment": "To appear in 21st European Conference on Computer Systems (EUROSYS\n  26)", "summary": "We describe a system for serverless computing where users, programs,\n  and the underlying platform share a common representation of a\n  computation: a deterministic procedure, run in an environment\n  of well-specified data or the outputs of other computations. This\n  representation externalizes I/O: data movement over the network is\n  performed exclusively by the platform. Applications can describe the\n  precise data needed at each stage, helping the provider schedule\n  tasks and network transfers to reduce starvation. The design\n  suggests an end-to-end argument for outsourced computing, shifting\n  the service model from ``pay-for-effort'' to ``pay-for-results.''", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7cfb\u7edf\uff0c\u5176\u7528\u6237\u3001\u7a0b\u5e8f\u548c\u5e73\u53f0\u5171\u4eab\u8ba1\u7b97\u7684\u901a\u7528\u8868\u793a\uff0c\u80fd\u51cf\u5c11\u9965\u997f\u5e76\u8f6c\u53d8\u670d\u52a1\u6a21\u5f0f\u3002", "motivation": "\u6784\u5efa\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7cfb\u7edf\uff0c\u4f18\u5316\u4efb\u52a1\u8c03\u5ea6\u548c\u670d\u52a1\u6a21\u5f0f\u3002", "method": "\u8ba9\u7528\u6237\u3001\u7a0b\u5e8f\u548c\u5e73\u53f0\u5171\u4eab\u8ba1\u7b97\u7684\u901a\u7528\u8868\u793a\uff0c\u5c06I/O\u5916\u90e8\u5316\uff0c\u7531\u5e73\u53f0\u8d1f\u8d23\u7f51\u7edc\u6570\u636e\u79fb\u52a8\u3002", "result": "\u5e94\u7528\u7a0b\u5e8f\u53ef\u63cf\u8ff0\u5404\u9636\u6bb5\u6240\u9700\u6570\u636e\uff0c\u6709\u52a9\u4e8e\u63d0\u4f9b\u5546\u8c03\u5ea6\u4efb\u52a1\u548c\u7f51\u7edc\u4f20\u8f93\uff0c\u51cf\u5c11\u9965\u997f\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u4e3a\u5916\u5305\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7aef\u5230\u7aef\u8bba\u8bc1\uff0c\u5c06\u670d\u52a1\u6a21\u5f0f\u4ece\u201c\u6309\u52aa\u529b\u4ed8\u8d39\u201d\u8f6c\u53d8\u4e3a\u201c\u6309\u7ed3\u679c\u4ed8\u8d39\u201d\u3002"}}
{"id": "2511.01448", "pdf": "https://arxiv.org/pdf/2511.01448", "abs": "https://arxiv.org/abs/2511.01448", "authors": ["Zhengjun Huang", "Zhoujin Tian", "Qintian Guo", "Fangyuan Zhang", "Yingli Zhou", "Di Jiang", "Xiaofang Zhou"], "title": "LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient Long-Term Reasoning", "categories": ["cs.IR"], "comment": null, "summary": "Large Language Model (LLM) agents exhibit remarkable conversational and\nreasoning capabilities but remain constrained by limited context windows and\nthe lack of persistent memory. Recent efforts address these limitations via\nexternal memory architectures, often employing graph-based representations, yet\nmost adopt flat, entangled structures that intertwine semantics with topology,\nleading to redundant representations, unstructured retrieval, and degraded\nefficiency and accuracy. To resolve these issues, we propose LiCoMemory, an\nend-to-end agentic memory framework for real-time updating and retrieval, which\nintroduces CogniGraph, a lightweight hierarchical graph that utilizes entities\nand relations as semantic indexing layers, and employs temporal and\nhierarchy-aware search with integrated reranking for adaptive and coherent\nknowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and\nLongMemEval, show that LiCoMemory not only outperforms established baselines in\ntemporal reasoning, multi-session consistency, and retrieval efficiency, but\nalso notably reduces update latency. Our official code and data are available\nat https://github.com/EverM0re/LiCoMemory.", "AI": {"tldr": "\u63d0\u51faLiCoMemory\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5185\u5b58\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f73\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u7f3a\u4e4f\u6301\u4e45\u5185\u5b58\uff0c\u73b0\u6709\u5916\u90e8\u5185\u5b58\u67b6\u6784\u5b58\u5728\u5197\u4f59\u8868\u793a\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faLiCoMemory\u7aef\u5230\u7aef\u4ee3\u7406\u5185\u5b58\u6846\u67b6\uff0c\u5f15\u5165CogniGraph\u8f7b\u91cf\u7ea7\u5206\u5c42\u56fe\uff0c\u91c7\u7528\u65f6\u95f4\u548c\u5206\u5c42\u611f\u77e5\u641c\u7d22\u4e0e\u96c6\u6210\u91cd\u6392\u8fdb\u884c\u77e5\u8bc6\u68c0\u7d22\u3002", "result": "\u5728\u957f\u671f\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLiCoMemory\u5728\u65f6\u95f4\u63a8\u7406\u3001\u591a\u4f1a\u8bdd\u4e00\u81f4\u6027\u548c\u68c0\u7d22\u6548\u7387\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u964d\u4f4e\u66f4\u65b0\u5ef6\u8fdf\u3002", "conclusion": "LiCoMemory\u6709\u6548\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5185\u5b58\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2511.01562", "pdf": "https://arxiv.org/pdf/2511.01562", "abs": "https://arxiv.org/abs/2511.01562", "authors": ["Jack Stade"], "title": "NP-membership for the boundary-boundary art-gallery problem", "categories": ["cs.CG", "cs.DS", "68W40", "F.2.2; I.1.2"], "comment": "23 pages, 12 figures", "summary": "The boundary-boundary art-gallery problem asks, given a polygon $P$\nrepresenting an art-gallery, for a minimal set of guards that can see the\nentire boundary of $P$ (the wall of the art gallery), where the guards must be\nplaced on the boundary. We show that this art-gallery variant is in NP. In\norder to prove this, we develop a constraint-propagation procedure for\ncontinuous constraint satisfaction problems where each constraint involves at\nmost 2 variables.\n  The X-Y variant of the art-gallery problem is the one where the guards must\nlie in X and need to see all of Y. Each of X and Y can be either the vertices\nof the polygon, the boundary of the polygon, or the entire polygon, giving 9\ndifferent variants. Previously, it was known that X-vertex and vertex-Y\nvariants are all NP-complete and that the point-point, point-boundary, and\nboundary-point variants are $\\exists \\mathbb{R}$-complete [Abrahamsen,\nAdamaszek, and Miltzow, JACM 2021][Stade, SoCG 2025]. However, the\nboundary-boundary variant was only known to lie somewhere between NP and\n$\\exists \\mathbb{R}$.\n  The X-vertex and vertex-Y variants can be straightforwardly reduced to\ndiscrete set-cover instances. In contrast, we give example to show that a\nsolution to an instance of the boundary-boundary art-gallery problem sometimes\nrequires placing guards at irrational coordinates, so it unlikely that the\nproblem can be easily discretized.", "AI": {"tldr": "\u8bc1\u660e\u8fb9\u754c - \u8fb9\u754c\u827a\u672f\u753b\u5eca\u95ee\u9898\u5c5e\u4e8eNP\uff0c\u6307\u51fa\u8be5\u95ee\u9898\u96be\u4ee5\u79bb\u6563\u5316\u3002", "motivation": "\u660e\u786e\u8fb9\u754c - \u8fb9\u754c\u827a\u672f\u753b\u5eca\u95ee\u9898\u7684\u590d\u6742\u5ea6\u5206\u7c7b\uff0c\u6b64\u524d\u8be5\u95ee\u9898\u590d\u6742\u5ea6\u4ecb\u4e8eNP\u548c\u2203\u211d\u4e4b\u95f4\u3002", "method": "\u4e3a\u8fde\u7eed\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff08\u6bcf\u4e2a\u7ea6\u675f\u6700\u591a\u6d89\u53ca2\u4e2a\u53d8\u91cf\uff09\u5f00\u53d1\u7ea6\u675f\u4f20\u64ad\u7a0b\u5e8f\u3002", "result": "\u8bc1\u660e\u8fb9\u754c - \u8fb9\u754c\u827a\u672f\u753b\u5eca\u95ee\u9898\u5c5e\u4e8eNP\uff0c\u7ed9\u51fa\u4f8b\u5b50\u8868\u660e\u8be5\u95ee\u9898\u89e3\u6709\u65f6\u9700\u5c06\u8b66\u536b\u7f6e\u4e8e\u65e0\u7406\u5750\u6807\u5904\u3002", "conclusion": "\u8fb9\u754c - \u8fb9\u754c\u827a\u672f\u753b\u5eca\u95ee\u9898\u5c5e\u4e8eNP\uff0c\u4e14\u8be5\u95ee\u9898\u4e0d\u592a\u53ef\u80fd\u8f7b\u6613\u79bb\u6563\u5316\u3002"}}
{"id": "2511.00424", "pdf": "https://arxiv.org/pdf/2511.00424", "abs": "https://arxiv.org/abs/2511.00424", "authors": ["Ashutosh Anshul", "Gumpili Sai Pranav", "Mohammad Zia Ur Rehman", "Nagendra Kumar"], "title": "A Multimodal Framework for Depression Detection during Covid-19 via Harvesting Social Media: A Novel Dataset and Method", "categories": ["cs.AI"], "comment": null, "summary": "The recent coronavirus disease (Covid-19) has become a pandemic and has\naffected the entire globe. During the pandemic, we have observed a spike in\ncases related to mental health, such as anxiety, stress, and depression.\nDepression significantly influences most diseases worldwide, making it\ndifficult to detect mental health conditions in people due to unawareness and\nunwillingness to consult a doctor. However, nowadays, people extensively use\nonline social media platforms to express their emotions and thoughts. Hence,\nsocial media platforms are now becoming a large data source that can be\nutilized for detecting depression and mental illness. However, existing\napproaches often overlook data sparsity in tweets and the multimodal aspects of\nsocial media. In this paper, we propose a novel multimodal framework that\ncombines textual, user-specific, and image analysis to detect depression among\nsocial media users. To provide enough context about the user's emotional state,\nwe propose (i) an extrinsic feature by harnessing the URLs present in tweets\nand (ii) extracting textual content present in images posted in tweets. We also\nextract five sets of features belonging to different modalities to describe a\nuser. Additionally, we introduce a Deep Learning model, the Visual Neural\nNetwork (VNN), to generate embeddings of user-posted images, which are used to\ncreate the visual feature vector for prediction. We contribute a curated\nCovid-19 dataset of depressed and non-depressed users for research purposes and\ndemonstrate the effectiveness of our model in detecting depression during the\nCovid-19 outbreak. Our model outperforms existing state-of-the-art methods over\na benchmark dataset by 2%-8% and produces promising results on the Covid-19\ndataset. Our analysis highlights the impact of each modality and provides\nvaluable insights into users' mental and emotional states.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u65b0\u9896\u591a\u6a21\u6001\u6846\u67b6\u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u6291\u90c1\u60c5\u51b5\uff0c\u8d21\u732e\u65b0\u51a0\u6570\u636e\u96c6\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u65b0\u51a0\u75ab\u60c5\u81f4\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u589e\u591a\uff0c\u793e\u4ea4\u5a92\u4f53\u53ef\u7528\u4e8e\u68c0\u6d4b\u6291\u90c1\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u6570\u636e\u7a00\u758f\u548c\u591a\u6a21\u6001\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u6587\u672c\u3001\u7528\u6237\u7279\u5b9a\u548c\u56fe\u50cf\u5206\u6790\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5229\u7528\u63a8\u6587URL\u63d0\u53d6\u5916\u5728\u7279\u5f81\u3001\u63d0\u53d6\u56fe\u50cf\u4e2d\u6587\u672c\u5185\u5bb9\uff0c\u5f15\u5165VNN\u6a21\u578b\u751f\u6210\u56fe\u50cf\u5d4c\u5165\uff0c\u63d0\u53d6\u4e94\u7ec4\u4e0d\u540c\u6a21\u6001\u7279\u5f81\u3002", "result": "\u6a21\u578b\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u9ad82%-8%\uff0c\u5728\u65b0\u51a0\u6570\u636e\u96c6\u4e0a\u6709\u826f\u597d\u8868\u73b0\u3002", "conclusion": "\u5206\u6790\u51f8\u663e\u5404\u6a21\u6001\u5f71\u54cd\uff0c\u4e3a\u4e86\u89e3\u7528\u6237\u5fc3\u7406\u548c\u60c5\u7eea\u72b6\u6001\u63d0\u4f9b\u6709\u4ef7\u503c\u89c1\u89e3\u3002"}}
{"id": "2511.00527", "pdf": "https://arxiv.org/pdf/2511.00527", "abs": "https://arxiv.org/abs/2511.00527", "authors": ["Robab Aghazadeh-Chakherlou", "Qing Guo", "Siddartha Khastgir", "Peter Popov", "Xiaoge Zhang", "Xingyu Zhao"], "title": "HIP-LLM: A Hierarchical Imprecise Probability Approach to Reliability Assessment of Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly deployed across diverse\ndomains, raising the need for rigorous reliability assessment methods. Existing\nbenchmark-based evaluations primarily offer descriptive statistics of model\naccuracy over datasets, providing limited insight into the probabilistic\nbehavior of LLMs under real operational conditions. This paper introduces\nHIP-LLM, a Hierarchical Imprecise Probability framework for modeling and\ninferring LLM reliability. Building upon the foundations of software\nreliability engineering, HIP-LLM defines LLM reliability as the probability of\nfailure-free operation over a specified number of future tasks under a given\nOperational Profile (OP). HIP-LLM represents dependencies across (sub-)domains\nhierarchically, enabling multi-level inference from subdomain to system-level\nreliability. HIP-LLM embeds imprecise priors to capture epistemic uncertainty\nand incorporates OPs to reflect usage contexts. It derives posterior\nreliability envelopes that quantify uncertainty across priors and data.\nExperiments on multiple benchmark datasets demonstrate that HIP-LLM offers a\nmore accurate and standardized reliability characterization than existing\nbenchmark and state-of-the-art approaches. A publicly accessible repository of\nHIP-LLM is provided.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u5efa\u6a21\u548c\u63a8\u65ad\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ef\u9760\u6027\u7684HIP - LLM\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u51c6\u786e\u3001\u6807\u51c6\u5316\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u57fa\u51c6\u7684\u8bc4\u4f30\u65b9\u6cd5\u5bf9LLM\u5728\u5b9e\u9645\u64cd\u4f5c\u6761\u4ef6\u4e0b\u7684\u6982\u7387\u884c\u4e3a\u6d1e\u5bdf\u6709\u9650\uff0c\u9700\u8981\u4e25\u683c\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165HIP - LLM\u6846\u67b6\uff0c\u57fa\u4e8e\u8f6f\u4ef6\u53ef\u9760\u6027\u5de5\u7a0b\uff0c\u5b9a\u4e49LLM\u53ef\u9760\u6027\uff0c\u5206\u5c42\u8868\u793a\uff08\u5b50\uff09\u9886\u57df\u4f9d\u8d56\uff0c\u5d4c\u5165\u4e0d\u7cbe\u786e\u5148\u9a8c\uff0c\u7ed3\u5408\u64cd\u4f5c\u5256\u9762\uff08OP\uff09\u63a8\u5bfc\u540e\u9a8c\u53ef\u9760\u6027\u533a\u95f4\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHIP - LLM\u6bd4\u73b0\u6709\u57fa\u51c6\u548c\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u3001\u6807\u51c6\u5316\u5730\u8868\u5f81\u53ef\u9760\u6027\u3002", "conclusion": "HIP - LLM\u662f\u4e00\u79cd\u6709\u6548\u7684LLM\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8fd8\u63d0\u4f9b\u4e86\u516c\u5171\u53ef\u8bbf\u95ee\u7684\u4ee3\u7801\u5e93\u3002"}}
{"id": "2511.00052", "pdf": "https://arxiv.org/pdf/2511.00052", "abs": "https://arxiv.org/abs/2511.00052", "authors": ["Federico Formica", "Stefano Gregis", "Aurora Francesca Zanenga", "Andrea Rota", "Mark Lawford", "Claudio Menghi"], "title": "Feature-Guided Analysis of Neural Networks: A Replication Study", "categories": ["cs.LG"], "comment": null, "summary": "Understanding why neural networks make certain decisions is pivotal for their\nuse in safety-critical applications. Feature-Guided Analysis (FGA) extracts\nslices of neural networks relevant to their tasks. Existing feature-guided\napproaches typically monitor the activation of the neural network neurons to\nextract the relevant rules. Preliminary results are encouraging and demonstrate\nthe feasibility of this solution by assessing the precision and recall of\nFeature-Guided Analysis on two pilot case studies. However, the applicability\nin industrial contexts needs additional empirical evidence.\n  To mitigate this need, this paper assesses the applicability of FGA on a\nbenchmark made by the MNIST and LSC datasets. We assessed the effectiveness of\nFGA in computing rules that explain the behavior of the neural network. Our\nresults show that FGA has a higher precision on our benchmark than the results\nfrom the literature. We also evaluated how the selection of the neural network\narchitecture, training, and feature selection affect the effectiveness of FGA.\nOur results show that the selection significantly affects the recall of FGA,\nwhile it has a negligible impact on its precision.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30FGA\u5728MNIST\u548cLSC\u6570\u636e\u96c6\u57fa\u51c6\u4e0a\u7684\u9002\u7528\u6027\uff0c\u7ed3\u679c\u663e\u793aFGA\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u7f51\u7edc\u67b6\u6784\u7b49\u9009\u62e9\u5bf9\u53ec\u56de\u7387\u5f71\u54cd\u5927\uff0c\u5bf9\u7cbe\u5ea6\u5f71\u54cd\u5c0f\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u5f15\u5bfc\u65b9\u6cd5\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u7f3a\u4e4f\u5b9e\u8bc1\uff0c\u9700\u8bc4\u4f30FGA\u5728\u57fa\u51c6\u4e0a\u7684\u9002\u7528\u6027\u3002", "method": "\u5728MNIST\u548cLSC\u6570\u636e\u96c6\u57fa\u51c6\u4e0a\u8bc4\u4f30FGA\u8ba1\u7b97\u89e3\u91ca\u795e\u7ecf\u7f51\u7edc\u884c\u4e3a\u89c4\u5219\u7684\u6709\u6548\u6027\uff0c\u8fd8\u8bc4\u4f30\u7f51\u7edc\u67b6\u6784\u3001\u8bad\u7ec3\u548c\u7279\u5f81\u9009\u62e9\u5bf9FGA\u6709\u6548\u6027\u7684\u5f71\u54cd\u3002", "result": "FGA\u5728\u57fa\u51c6\u4e0a\u7cbe\u5ea6\u9ad8\u4e8e\u6587\u732e\u7ed3\u679c\uff1b\u7f51\u7edc\u67b6\u6784\u7b49\u9009\u62e9\u5bf9FGA\u53ec\u56de\u7387\u5f71\u54cd\u663e\u8457\uff0c\u5bf9\u7cbe\u5ea6\u5f71\u54cd\u53ef\u5ffd\u7565\u3002", "conclusion": "FGA\u5728\u57fa\u51c6\u4e0a\u6709\u8f83\u9ad8\u7cbe\u5ea6\uff0c\u7f51\u7edc\u67b6\u6784\u7b49\u9009\u62e9\u5bf9\u5176\u53ec\u56de\u7387\u5f71\u54cd\u5927\uff0c\u5bf9\u7cbe\u5ea6\u5f71\u54cd\u5c0f\uff0c\u4e3a\u5176\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u5b9a\u8bc1\u636e\u3002"}}
{"id": "2511.01519", "pdf": "https://arxiv.org/pdf/2511.01519", "abs": "https://arxiv.org/abs/2511.01519", "authors": ["Niklas Kemmerling", "Sergio Lucia"], "title": "Dynamic Modeling of Precipitation in Electrolyte Systems", "categories": ["physics.chem-ph", "cs.CE"], "comment": null, "summary": "This study presents a dynamic modeling approach for precipitation in\nelectrolyte systems, focusing on the crystallization of an aromatic amine\nthrough continuous processes. A novel model, integrating equilibrium and\ncrystallization kinetics, is formulated and applied to a continuous oscillatory\nbaffled reactor. The approach assumes rapid equilibrium establishment and is\nformulated as a set of differential algebraic equations. Key features include a\npopulation balance equation model to describe the particle size distribution\nand the modeling of dynamically changing equilibria. The predictions of the\ndynamic model show good agreement with the available experimental measurements.\nThe model is aimed at aiding the transition from a batch process to continuous\nprocess by forming the basis for numerical optimization and advanced control.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7535\u89e3\u8d28\u7cfb\u7edf\u6c89\u6dc0\u52a8\u6001\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8e\u82b3\u9999\u80fa\u8fde\u7eed\u7ed3\u6676\uff0c\u6a21\u578b\u9884\u6d4b\u4e0e\u5b9e\u9a8c\u76f8\u7b26\uff0c\u53ef\u52a9\u529b\u4ece\u95f4\u6b47\u5230\u8fde\u7eed\u8fc7\u7a0b\u7684\u8f6c\u53d8\u3002", "motivation": "\u4e3a\u7535\u89e3\u8d28\u7cfb\u7edf\u6c89\u6dc0\u8fc7\u7a0b\u5efa\u6a21\uff0c\u52a9\u529b\u4ece\u95f4\u6b47\u8fc7\u7a0b\u5411\u8fde\u7eed\u8fc7\u7a0b\u7684\u8f6c\u53d8\u3002", "method": "\u6784\u5efa\u6574\u5408\u5e73\u8861\u548c\u7ed3\u6676\u52a8\u529b\u5b66\u7684\u65b0\u6a21\u578b\uff0c\u4ee5\u5fae\u5206\u4ee3\u6570\u65b9\u7a0b\u8868\u793a\uff0c\u91c7\u7528\u79cd\u7fa4\u5e73\u8861\u65b9\u7a0b\u63cf\u8ff0\u7c92\u5ea6\u5206\u5e03\u548c\u52a8\u6001\u5e73\u8861\u3002", "result": "\u52a8\u6001\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0e\u73b0\u6709\u5b9e\u9a8c\u6d4b\u91cf\u7ed3\u679c\u543b\u5408\u826f\u597d\u3002", "conclusion": "\u8be5\u6a21\u578b\u53ef\u4f5c\u4e3a\u6570\u503c\u4f18\u5316\u548c\u5148\u8fdb\u63a7\u5236\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u4ece\u95f4\u6b47\u8fc7\u7a0b\u8fc7\u6e21\u5230\u8fde\u7eed\u8fc7\u7a0b\u3002"}}
{"id": "2511.01838", "pdf": "https://arxiv.org/pdf/2511.01838", "abs": "https://arxiv.org/abs/2511.01838", "authors": ["Zirui Deng", "Netanel Raviv"], "title": "Efficient Vector Symbolic Architectures from Histogram Recovery", "categories": ["cs.IT", "cs.AI", "cs.NE", "math.IT"], "comment": null, "summary": "Vector symbolic architectures (VSAs) are a family of information\nrepresentation techniques which enable composition, i.e., creating complex\ninformation structures from atomic vectors via binding and superposition, and\nhave recently found wide ranging applications in various neurosymbolic\nartificial intelligence (AI) systems. Recently, Raviv proposed the use of\nrandom linear codes in VSAs, suggesting that their subcode structure enables\nefficient binding, while preserving the quasi-orthogonality that is necessary\nfor neural processing. Yet, random linear codes are difficult to decode under\nnoise, which severely limits the resulting VSA's ability to support recovery,\ni.e., the retrieval of information objects and their attributes from a noisy\ncompositional representation.\n  In this work we bridge this gap by utilizing coding theoretic tools. First,\nwe argue that the concatenation of Reed-Solomon and Hadamard codes is suitable\nfor VSA, due to the mutual quasi-orthogonality of the resulting codewords (a\nfolklore result). Second, we show that recovery of the resulting compositional\nrepresentations can be done by solving a problem we call histogram recovery. In\nhistogram recovery, a collection of $N$ histograms over a finite field is given\nas input, and one must find a collection of Reed-Solomon codewords of length\n$N$ whose entry-wise symbol frequencies obey those histograms. We present an\noptimal solution to the histogram recovery problem by using algorithms related\nto list-decoding, and analyze the resulting noise resilience. Our results give\nrise to a noise-resilient VSA with formal guarantees regarding efficient\nencoding, quasi-orthogonality, and recovery, without relying on any heuristics\nor training, and while operating at improved parameters relative to similar\nsolutions such as the Hadamard code.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u7f16\u7801\u7406\u8bba\u5de5\u5177\uff0c\u63d0\u51fa\u7528\u91cc\u5fb7 - \u6240\u7f57\u95e8\u7801\u548c\u54c8\u8fbe\u739b\u7801\u7684\u7ea7\u8054\u5b9e\u73b0\u6297\u566a\u58f0\u7684\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u968f\u673a\u7ebf\u6027\u7801\u5728\u566a\u58f0\u4e0b\u96be\u89e3\u7801\u95ee\u9898\u3002", "motivation": "\u968f\u673a\u7ebf\u6027\u7801\u5728\u566a\u58f0\u4e0b\u96be\u4ee5\u89e3\u7801\uff0c\u9650\u5236\u4e86\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff08VSA\uff09\u7684\u4fe1\u606f\u6062\u590d\u80fd\u529b\uff0c\u9700\u627e\u5230\u5408\u9002\u7f16\u7801\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5229\u7528\u91cc\u5fb7 - \u6240\u7f57\u95e8\u7801\u548c\u54c8\u8fbe\u739b\u7801\u7684\u7ea7\u8054\uff0c\u5c06\u6062\u590d\u95ee\u9898\u8f6c\u5316\u4e3a\u76f4\u65b9\u56fe\u6062\u590d\u95ee\u9898\u5e76\u7ed9\u51fa\u6700\u4f18\u89e3\u3002", "result": "\u5f97\u5230\u4e86\u5177\u6709\u9ad8\u6548\u7f16\u7801\u3001\u51c6\u6b63\u4ea4\u6027\u548c\u6062\u590d\u80fd\u529b\u7684\u6297\u566a\u58f0 VSA\uff0c\u76f8\u6bd4\u54c8\u8fbe\u739b\u7801\u7b49\u6709\u6539\u8fdb\u3002", "conclusion": "\u4e0d\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u6216\u8bad\u7ec3\uff0c\u80fd\u5728\u66f4\u597d\u53c2\u6570\u4e0b\u5b9e\u73b0\u6297\u566a\u58f0\u7684 VSA\u3002"}}
{"id": "2511.01625", "pdf": "https://arxiv.org/pdf/2511.01625", "abs": "https://arxiv.org/abs/2511.01625", "authors": ["Han Weng", "Zhou Liu", "Yuanfeng Song", "Xiaoming Yin", "Xing Chen", "Wentao Zhang"], "title": "UniDataBench: Evaluating Data Analytics Agents Across Structured and Unstructured Data", "categories": ["cs.DB"], "comment": null, "summary": "In the real business world, data is stored in a variety of sources, including\nstructured relational databases, unstructured databases (e.g., NoSQL\ndatabases), or even CSV/excel files. The ability to extract reasonable insights\nacross these diverse source is vital for business success. Existing benchmarks,\nhowever, are limited in assessing agents' capabilities across these diverse\ndata types. To address this gap, we introduce UniDataBench, a comprehensive\nbenchmark designed to evaluate the performance of data analytics agents in\nhandling diverse data sources. Specifically, UniDataBench is originating from\nreal-life industry analysis report and we then propose a pipeline to remove the\nprivacy and sensitive information. It encompasses a wide array of datasets,\nincluding relational databases, CSV files to NoSQL data, reflecting real-world\nbusiness scenarios, and provides unified framework to assess how effectively\nagents can explore multiple data formats, extract valuable insights, and\ngenerate meaningful summaries and recommendations. Based on UniDataBench, we\npropose a novel LLM-based agent named ReActInsight, an autonomous agent that\nperforms end-to-end analysis over diverse data sources by automatically\ndiscovering cross-source linkages, decomposing goals, and generating robust,\nself-correcting code to extract actionable insights. Our benchmark and agent\ntogether provide a powerful framework for advancing the capabilities of data\nanalytics agents in real-world applications.", "AI": {"tldr": "\u63d0\u51faUniDataBench\u8bc4\u4f30\u6570\u636e\u5206\u6790\u4ee3\u7406\u5904\u7406\u591a\u6837\u6570\u636e\u6e90\u80fd\u529b\uff0c\u8fd8\u63d0\u51fa\u57fa\u4e8eLLM\u7684ReActInsight\u4ee3\u7406\uff0c\u4e8c\u8005\u63d0\u4f9b\u5f3a\u5927\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30\u4ee3\u7406\u5904\u7406\u591a\u6837\u6570\u636e\u7c7b\u578b\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u4e3a\u586b\u8865\u6b64\u7a7a\u767d\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5f15\u5165\u6e90\u4e8e\u73b0\u5b9e\u884c\u4e1a\u5206\u6790\u62a5\u544a\u7684UniDataBench\uff0c\u53bb\u9664\u9690\u79c1\u654f\u611f\u4fe1\u606f\uff0c\u6db5\u76d6\u591a\u79cd\u6570\u636e\u96c6\uff1b\u63d0\u51fa\u57fa\u4e8e\u6b64\u57fa\u51c6\u7684LLM\u4ee3\u7406ReActInsight\uff0c\u81ea\u52a8\u53d1\u73b0\u8de8\u6e90\u5173\u8054\u3001\u5206\u89e3\u76ee\u6807\u3001\u751f\u6210\u4ee3\u7801\u3002", "result": "\u521b\u5efa\u4e86UniDataBench\u57fa\u51c6\u548cReActInsight\u4ee3\u7406\u3002", "conclusion": "\u57fa\u51c6\u548c\u4ee3\u7406\u5171\u540c\u4e3a\u63d0\u5347\u6570\u636e\u5206\u6790\u4ee3\u7406\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u5f3a\u5927\u6846\u67b6\u3002"}}
{"id": "2511.01734", "pdf": "https://arxiv.org/pdf/2511.01734", "abs": "https://arxiv.org/abs/2511.01734", "authors": ["Soufiane Hayou"], "title": "A Proof of Learning Rate Transfer under $\u03bc$P", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "comment": "23 pages", "summary": "We provide the first proof of learning rate transfer with width in a linear\nmulti-layer perceptron (MLP) parametrized with $\\mu$P, a neural network\nparameterization designed to ``maximize'' feature learning in the\ninfinite-width limit. We show that under $\\mu P$, the optimal learning rate\nconverges to a \\emph{non-zero constant} as width goes to infinity, providing a\ntheoretical explanation to learning rate transfer. In contrast, we show that\nthis property fails to hold under alternative parametrizations such as Standard\nParametrization (SP) and Neural Tangent Parametrization (NTP). We provide\nintuitive proofs and support the theoretical findings with extensive empirical\nresults.", "AI": {"tldr": "\u9996\u6b21\u8bc1\u660e\u7ebf\u6027\u591a\u5c42\u611f\u77e5\u673a\u4e2d\u5b66\u4e60\u7387\u968f\u5bbd\u5ea6\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u5bf9\u6bd4\u4e0d\u540c\u53c2\u6570\u5316\u65b9\u5f0f\uff0c\u6709\u7406\u8bba\u8bc1\u660e\u548c\u5b9e\u8bc1\u7ed3\u679c\u3002", "motivation": "\u5bf9\u7ebf\u6027\u591a\u5c42\u611f\u77e5\u673a\u4e2d\u5b66\u4e60\u7387\u968f\u5bbd\u5ea6\u7684\u53ef\u8fc1\u79fb\u6027\u8fdb\u884c\u7406\u8bba\u89e3\u91ca\u3002", "method": "\u5bf9\u03bcP\u53c2\u6570\u5316\u7684\u7ebf\u6027\u591a\u5c42\u611f\u77e5\u673a\u8fdb\u884c\u7406\u8bba\u8bc1\u660e\uff0c\u5e76\u4e0eSP\u548cNTP\u7b49\u53c2\u6570\u5316\u65b9\u5f0f\u5bf9\u6bd4\uff0c\u8f85\u4ee5\u5927\u91cf\u5b9e\u8bc1\u3002", "result": "\u5728\u03bcP\u4e0b\uff0c\u6700\u4f18\u5b66\u4e60\u7387\u5728\u5bbd\u5ea6\u8d8b\u4e8e\u65e0\u7a77\u65f6\u6536\u655b\u5230\u975e\u96f6\u5e38\u6570\uff0c\u800cSP\u548cNTP\u4e0d\u5177\u5907\u6b64\u6027\u8d28\u3002", "conclusion": "\u8bc1\u660e\u4e86\u03bcP\u53c2\u6570\u5316\u4e0b\u5b66\u4e60\u7387\u968f\u5bbd\u5ea6\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u4e3a\u5176\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2511.00932", "pdf": "https://arxiv.org/pdf/2511.00932", "abs": "https://arxiv.org/abs/2511.00932", "authors": ["Bruno Felipe de Oliveira", "Alessandro V. M. Oliveira"], "title": "Low-Cost Carriers in Aviation: Significance and Developments", "categories": ["physics.soc-ph", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "comment": null, "summary": "This paper aims to discuss the impacts of low-cost airlines on the air\ntransport market and, in particular, to present the most recent findings from\nthe specialized literature in this field. To this end, several papers published\non the topic since 2015 were selected and analyzed. Based on this analysis, the\nmain subjects addressed in the studies were categorized into five groups: (i)\nimpacts of low-cost airlines on competing carriers; (ii) impacts on airports;\n(iii) general effects on air transport demand; (iv) effects on passengers'\nchoice processes; and (v) broader effects on geographical regions.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4f4e\u6210\u672c\u822a\u7a7a\u516c\u53f8\u5bf9\u822a\u7a7a\u8fd0\u8f93\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u5e76\u5448\u73b0\u8be5\u9886\u57df\u6700\u65b0\u7814\u7a76\u7ed3\u679c\u3002", "motivation": "\u63a2\u8ba8\u4f4e\u6210\u672c\u822a\u7a7a\u516c\u53f8\u5bf9\u822a\u7a7a\u8fd0\u8f93\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u5448\u73b0\u9886\u57df\u6700\u65b0\u7814\u7a76\u53d1\u73b0\u3002", "method": "\u9009\u53d6\u5e76\u5206\u6790\u81ea2015\u5e74\u4ee5\u6765\u53d1\u8868\u7684\u76f8\u5173\u8bba\u6587\u3002", "result": "\u5c06\u7814\u7a76\u6d89\u53ca\u7684\u4e3b\u8981\u4e3b\u9898\u5206\u4e3a\u4e94\u7c7b\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2511.00279", "pdf": "https://arxiv.org/pdf/2511.00279", "abs": "https://arxiv.org/abs/2511.00279", "authors": ["Meituan LongCat Team", "Bairui Wang", "Bayan", "Bin Xiao", "Bo Zhang", "Bolin Rong", "Borun Chen", "Chang Wan", "Chao Zhang", "Chen Huang", "Chen Chen", "Chen Chen", "Chengxu Yang", "Chengzuo Yang", "Cong Han", "Dandan Peng", "Delian Ruan", "Detai Xin", "Disong Wang", "Dongchao Yang", "Fanfan Liu", "Fengjiao Chen", "Fengyu Yang", "Gan Dong", "Gang Huang", "Gang Xu", "Guanglu Wan", "Guoqiang Tan", "Guoqiao Yu", "Haibo Qiu", "Hao Lu", "Hongbo Liu", "Hongyu Xiang", "Jiaheng Wu", "Jian Yang", "Jiaxing Liu", "Jing Huang", "Jingang Wang", "Jinrui Ding", "Juchao Jiang", "Jun Kuang", "Jun Wang", "Junhui Mei", "Ke Ding", "Kefeng Zhang", "Lei Chen", "Liang Shi", "Limeng Qiao", "Liming Zheng", "Lin Ma", "Liuyang Guo", "Liya Ma", "Luying Sun", "Man Gao", "Mengshen Zhu", "Miao Cao", "Minliang Lin", "Nuo Xu", "Peng Shi", "Qi Zhang", "Qian Fang", "Qian Wang", "Qian Yang", "Quanxiu Wang", "Rongxiang Weng", "Rongxin Guo", "Ruoxuan Liang", "Senbin Yang", "Shanbo Xu", "Shanglin Lei", "Shengze Ye", "Shimin Chen", "Shuaiqi Chen", "Shujie Hu", "Shuo Li", "Siqi Yang", "Siyu Xu", "Siyu Ren", "Song Li", "Songxiang Liu", "Tianhao Bai", "Tianye Dai", "Wei Hong", "Wei Wang", "Weixiao Zhao", "Wengang Cao", "Wenlong Zhu", "Wenlong He", "Xi Su", "Xi Nan", "Xiaohan Zhao", "Xiaohao Wang", "Xiaoyu Zhao", "Xiaoyu Wang", "Xiaoyu Li", "Xin Pan", "Xin Chen", "Xiusong Sun", "Xu Xiang", "Xudong Xing", "Xuezhi Cao", "Xunliang Cai", "Yang Yang", "Yanli Tan", "Yao Yao", "Yerui Sun", "Yi Chen", "Yifan Lu", "Yin Gong", "Yining Zhang", "Yitian Chen", "Yiyang Gan", "Yuchen Tang", "Yuchen Xie", "Yueqian Wang", "Yuewen Zheng", "Yufei Zhang", "Yufeng Zhong", "Yulei Qian", "Yuqi Peng", "Yuwei Jiang", "Zeyang Hu", "Zheng Zhang", "Zhengkun Tian", "Zhiqing Hong", "Zhixiong Zeng", "Zhuqi Mi", "Ziran Li", "Ziwen Wang", "Ziyi Zhao", "Ziyuan Zhuang", "Zizhe Zhao"], "title": "LongCat-Flash-Omni Technical Report", "categories": ["cs.MM", "cs.AI", "cs.CL", "cs.DC", "cs.LG", "cs.SD"], "comment": null, "summary": "We introduce LongCat-Flash-Omni, a state-of-the-art open-source omni-modal\nmodel with 560 billion parameters, excelling at real-time audio-visual\ninteraction. By adopting a curriculum-inspired progressive training strategy\nthat transitions from simpler to increasingly complex modality sequence\nmodeling tasks, LongCat-Flash-Omni attains comprehensive multimodal\ncapabilities while maintaining strong unimodal capability. Building upon\nLongCat-Flash, which adopts a high-performance Shortcut-connected\nMixture-of-Experts (MoE) architecture with zero-computation experts,\nLongCat-Flash-Omni integrates efficient multimodal perception and speech\nreconstruction modules. Despite its immense size of 560B parameters (with 27B\nactivated), LongCat-Flash-Omni achieves low-latency real-time audio-visual\ninteraction. For training infrastructure, we developed a modality-decoupled\nparallelism scheme specifically designed to manage the data and model\nheterogeneity inherent in large-scale multimodal training. This innovative\napproach demonstrates exceptional efficiency by sustaining over 90% of the\nthroughput achieved by text-only training. Extensive evaluations show that\nLongCat-Flash-Omni achieves state-of-the-art performance on omni-modal\nbenchmarks among open-source models. Furthermore, it delivers highly\ncompetitive results across a wide range of modality-specific tasks, including\ntext, image, and video understanding, as well as audio understanding and\ngeneration. We provide a comprehensive overview of the model architecture\ndesign, training procedures, and data strategies, and open-source the model to\nfoster future research and development in the community.", "AI": {"tldr": "\u4ecb\u7ecd5600\u4ebf\u53c2\u6570\u7684\u5f00\u6e90\u5168\u6a21\u6001\u6a21\u578bLongCat - Flash - Omni\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u5b9e\u65f6\u89c6\u542c\u4ea4\u4e92\uff0c\u8bc4\u4f30\u8868\u73b0\u4f18\u5f02\u5e76\u5f00\u6e90\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u5177\u6709\u5b9e\u65f6\u89c6\u542c\u4ea4\u4e92\u80fd\u529b\u3001\u7efc\u5408\u591a\u6a21\u6001\u80fd\u529b\u4e14\u5728\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u7684\u5168\u6a21\u6001\u6a21\u578b\u3002", "method": "\u91c7\u7528\u8bfe\u7a0b\u542f\u53d1\u7684\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\uff1b\u57fa\u4e8eLongCat - Flash\u67b6\u6784\uff0c\u96c6\u6210\u591a\u6a21\u6001\u611f\u77e5\u548c\u8bed\u97f3\u91cd\u5efa\u6a21\u5757\uff1b\u5f00\u53d1\u6a21\u6001\u89e3\u8026\u5e76\u884c\u65b9\u6848\u7528\u4e8e\u8bad\u7ec3\u3002", "result": "\u5728\u5168\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u5f00\u6e90\u6a21\u578b\u7684\u6700\u4f18\u6027\u80fd\uff0c\u5728\u591a\u79cd\u7279\u5b9a\u6a21\u6001\u4efb\u52a1\u4e2d\u7ed3\u679c\u6781\u5177\u7ade\u4e89\u529b\uff0c\u8bad\u7ec3\u6548\u7387\u7ef4\u6301\u5728\u4ec5\u6587\u672c\u8bad\u7ec3\u541e\u5410\u91cf\u768490%\u4ee5\u4e0a\u3002", "conclusion": "LongCat - Flash - Omni\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u793e\u533a\u672a\u6765\u7814\u7a76\u548c\u53d1\u5c55\u3002"}}
{"id": "2511.01461", "pdf": "https://arxiv.org/pdf/2511.01461", "abs": "https://arxiv.org/abs/2511.01461", "authors": ["Xiaoyu Liu", "Fuwei Zhang", "Yiqing Wu", "Xinyu Jia", "Zenghua Xia", "Fuzhen Zhuang", "Zhao Zhang", "Fei Jiang", "Wei Lin"], "title": "CAT-ID$^2$: Category-Tree Integrated Document Identifier Learning for Generative Retrieval In E-commerce", "categories": ["cs.IR"], "comment": "Accepted by WSDM'26", "summary": "Generative retrieval (GR) has gained significant attention as an effective\nparadigm that integrates the capabilities of large language models (LLMs). It\ngenerally consists of two stages: constructing discrete semantic identifiers\n(IDs) for documents and retrieving documents by autoregressively generating ID\ntokens.The core challenge in GR is how to construct document IDs (DocIDS) with\nstrong representational power. Good IDs should exhibit two key properties:\nsimilar documents should have more similar IDs, and each document should\nmaintain a distinct and unique ID.However, most existing methods ignore native\ncategory information, which is common and critical in E-commerce. Therefore, we\npropose a novel ID learning method, CAtegory-Tree Integrated Document\nIDentifier (CAT-ID$^2$), incorporating prior category information into the\nsemantic IDs.CAT-ID$^2$ includes three key modules: a Hierarchical Class\nConstraint Loss to integrate category information layer by layer during\nquantization, a Cluster Scale Constraint Loss for uniform ID token\ndistribution, and a Dispersion Loss to improve the distinction of reconstructed\ndocuments. These components enable CAT-ID$^2$ to generate IDs that make similar\ndocuments more alike while preserving the uniqueness of different documents'\nrepresentations.Extensive offline and online experiments confirm the\neffectiveness of our method, with online A/B tests showing a 0.33% increase in\naverage orders per thousand users for ambiguous intent queries and 0.24% for\nlong-tail queries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u5f0f\u68c0\u7d22ID\u5b66\u4e60\u65b9\u6cd5CAT - ID\u00b2\uff0c\u7ed3\u5408\u4e86\u7c7b\u522b\u4fe1\u606f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u68c0\u7d22\uff08GR\uff09\u65b9\u6cd5\u5927\u591a\u5ffd\u7565\u7535\u5546\u4e2d\u5e38\u89c1\u4e14\u5173\u952e\u7684\u539f\u751f\u7c7b\u522b\u4fe1\u606f\uff0c\u6838\u5fc3\u6311\u6218\u662f\u6784\u5efa\u6709\u5f3a\u8868\u793a\u80fd\u529b\u7684\u6587\u6863ID\u3002", "method": "\u63d0\u51faCAtegory - Tree Integrated Document IDentifier (CAT - ID\u00b2) \u65b9\u6cd5\uff0c\u5305\u542bHierarchical Class Constraint Loss\u3001Cluster Scale Constraint Loss\u548cDispersion Loss\u4e09\u4e2a\u5173\u952e\u6a21\u5757\u3002", "result": "\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\u8bc1\u5b9e\u65b9\u6cd5\u6709\u6548\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u663e\u793a\uff0c\u6a21\u7cca\u610f\u56fe\u67e5\u8be2\u6bcf\u5343\u7528\u6237\u5e73\u5747\u8ba2\u5355\u589e\u52a00.33%\uff0c\u957f\u5c3e\u67e5\u8be2\u589e\u52a00.24%\u3002", "conclusion": "CAT - ID\u00b2\u65b9\u6cd5\u80fd\u4f7f\u76f8\u4f3c\u6587\u6863\u66f4\u76f8\u4f3c\uff0c\u540c\u65f6\u4fdd\u6301\u4e0d\u540c\u6587\u6863\u8868\u793a\u7684\u552f\u4e00\u6027\uff0c\u5728\u7535\u5546\u68c0\u7d22\u4e2d\u6709\u6548\u3002"}}
{"id": "2511.00457", "pdf": "https://arxiv.org/pdf/2511.00457", "abs": "https://arxiv.org/abs/2511.00457", "authors": ["Chunyu Wei", "Wenji Hu", "Xingjia Hao", "Xin Wang", "Yifan Yang", "Yueguo Chen", "Yang Tian", "Yunhai Wang"], "title": "GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) face significant limitations when applied to\nlarge-scale graphs, struggling with context constraints and inflexible\nreasoning. We present GraphChain, a framework that enables LLMs to analyze\ncomplex graphs through dynamic sequences of specialized tools, mimicking human\nexploratory intelligence. Our approach introduces two key innovations: (1)\nProgressive Graph Distillation, a reinforcement learning mechanism that\ngenerates optimized tool sequences balancing task relevance with information\ncompression, and (2) Structure-aware Test-Time Adaptation, which efficiently\ntailors tool selection strategies to diverse graph topologies using spectral\nproperties and lightweight adapters without costly retraining. Experiments show\nGraphChain significantly outperforms prior methods, enabling scalable and\nadaptive LLM-driven graph analysis.", "AI": {"tldr": "\u63d0\u51faGraphChain\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u56fe\u7684\u5c40\u9650\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u56fe\u65f6\u9762\u4e34\u4e0a\u4e0b\u6587\u7ea6\u675f\u548c\u63a8\u7406\u4e0d\u7075\u6d3b\u7684\u5c40\u9650\u3002", "method": "\u5f15\u5165\u6e10\u8fdb\u56fe\u84b8\u998f\uff08\u5f3a\u5316\u5b66\u4e60\u673a\u5236\u751f\u6210\u4f18\u5316\u5de5\u5177\u5e8f\u5217\uff09\u548c\u7ed3\u6784\u611f\u77e5\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\uff08\u5229\u7528\u8c31\u7279\u6027\u548c\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u8c03\u6574\u5de5\u5177\u9009\u62e9\u7b56\u7565\uff09\u4e24\u9879\u521b\u65b0\u3002", "result": "GraphChain\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "GraphChain\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u56fe\u5206\u6790\u3002"}}
{"id": "2511.00528", "pdf": "https://arxiv.org/pdf/2511.00528", "abs": "https://arxiv.org/abs/2511.00528", "authors": ["Muhammad Hamid Raza Mookadam", "Ridewaan Hanslo"], "title": "Employee Performance when Implementing Agile Practices in an IT Workforce", "categories": ["cs.SE", "D.2.9"], "comment": "11 pages, 1 figure, 1 table, 7th World Symposium on Software\n  Engineering (WSSE 2025)", "summary": "Adoption of agile practices has increased in IT workforces. However, there is\na lack of comprehensive studies in the African context on employee performance\nwhen implementing agile practices. This study addresses this gap by exploring\nemployee performance in agile environments for IT workforces in South Africa.\nAn interpretivist mono-method qualitative approach was used, with the use of\ninterviews as a research strategy. Seventeen semi-structured interviews were\nconducted with agile practitioners from various roles. Our results indicated\nthat agile practices influence employee performance significantly, with\nparticipants reporting on aspects which included planning, communication,\nemployee development and well-being, collaboration, team culture and progress.\nAdditionally, our results reported obstacles when using agile practices that\nincluded adoption, team engagement, leadership and instilling an agile mindset.\nAgile practices influence employee performance in IT workforces by fostering\nimproved team dynamics, enhanced collaboration, improved efficiencies, risk\nmanagement, planning, continuous improvement, learning, personal development\nand well-being. Conclusively, our findings suggest that if agile challenges are\naddressed and additional support is provided, employee performance can be\nsignificantly improved.", "AI": {"tldr": "\u7814\u7a76\u5357\u975eIT\u5458\u5de5\u5728\u654f\u6377\u73af\u5883\u4e2d\u7684\u7ee9\u6548\uff0c\u53d1\u73b0\u654f\u6377\u5b9e\u8df5\u663e\u8457\u5f71\u54cd\u7ee9\u6548\uff0c\u89e3\u51b3\u6311\u6218\u53ef\u63d0\u5347\u7ee9\u6548\u3002", "motivation": "\u975e\u6d32\u7f3a\u4e4f\u654f\u6377\u5b9e\u8df5\u5bf9\u5458\u5de5\u7ee9\u6548\u5f71\u54cd\u7684\u7efc\u5408\u7814\u7a76\uff0c\u672c\u7814\u7a76\u586b\u8865\u5357\u975eIT\u5458\u5de5\u8fd9\u65b9\u9762\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u89e3\u91ca\u4e3b\u4e49\u5355\u65b9\u6cd5\u5b9a\u6027\u7814\u7a76\uff0c\u5bf9\u4e0d\u540c\u89d2\u8272\u7684\u654f\u6377\u4ece\u4e1a\u8005\u8fdb\u884c17\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u3002", "result": "\u654f\u6377\u5b9e\u8df5\u663e\u8457\u5f71\u54cd\u5458\u5de5\u7ee9\u6548\uff0c\u6d89\u53ca\u89c4\u5212\u3001\u6c9f\u901a\u7b49\u65b9\u9762\uff1b\u540c\u65f6\u5b58\u5728\u91c7\u7528\u3001\u56e2\u961f\u53c2\u4e0e\u7b49\u969c\u788d\u3002", "conclusion": "\u89e3\u51b3\u654f\u6377\u6311\u6218\u5e76\u63d0\u4f9b\u989d\u5916\u652f\u6301\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u5458\u5de5\u7ee9\u6548\u3002"}}
{"id": "2511.00053", "pdf": "https://arxiv.org/pdf/2511.00053", "abs": "https://arxiv.org/abs/2511.00053", "authors": ["Hao Wang", "Licheng Pan", "Yuan Lu", "Zhichao Chen", "Tianqiao Liu", "Shuting He", "Zhixuan Chu", "Qingsong Wen", "Haoxuan Li", "Zhouchen Lin"], "title": "Quadratic Direct Forecast for Training Multi-Step Time-Series Forecast Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The design of training objective is central to training time-series\nforecasting models. Existing training objectives such as mean squared error\nmostly treat each future step as an independent, equally weighted task, which\nwe found leading to the following two issues: (1) overlook the label\nautocorrelation effect among future steps, leading to biased training\nobjective; (2) fail to set heterogeneous task weights for different forecasting\ntasks corresponding to varying future steps, limiting the forecasting\nperformance. To fill this gap, we propose a novel quadratic-form weighted\ntraining objective, addressing both of the issues simultaneously. Specifically,\nthe off-diagonal elements of the weighting matrix account for the label\nautocorrelation effect, whereas the non-uniform diagonals are expected to match\nthe most preferable weights of the forecasting tasks with varying future steps.\nTo achieve this, we propose a Quadratic Direct Forecast (QDF) learning\nalgorithm, which trains the forecast model using the adaptively updated\nquadratic-form weighting matrix. Experiments show that our QDF effectively\nimproves performance of various forecast models, achieving state-of-the-art\nresults. Code is available at https://anonymous.4open.science/r/QDF-8937.", "AI": {"tldr": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u8bad\u7ec3\u76ee\u6807\u6709\u7f3a\u9677\uff0c\u63d0\u51fa\u4e8c\u6b21\u578b\u52a0\u6743\u8bad\u7ec3\u76ee\u6807\u548cQDF\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u76ee\u6807\u5982\u5747\u65b9\u8bef\u5dee\u5c06\u672a\u6765\u6b65\u9aa4\u89c6\u4e3a\u72ec\u7acb\u4e14\u7b49\u6743\u91cd\u4efb\u52a1\uff0c\u5b58\u5728\u5ffd\u7565\u6807\u7b7e\u81ea\u76f8\u5173\u6548\u5e94\u3001\u65e0\u6cd5\u8bbe\u7f6e\u4e0d\u540c\u4efb\u52a1\u6743\u91cd\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e8c\u6b21\u578b\u52a0\u6743\u8bad\u7ec3\u76ee\u6807\uff0c\u7528\u81ea\u9002\u5e94\u66f4\u65b0\u7684\u4e8c\u6b21\u578b\u52a0\u6743\u77e9\u9635\u8bad\u7ec3\u6a21\u578b\u7684QDF\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "QDF\u6709\u6548\u63d0\u5347\u4e86\u5404\u79cd\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e8c\u6b21\u578b\u52a0\u6743\u8bad\u7ec3\u76ee\u6807\u548cQDF\u7b97\u6cd5\u80fd\u89e3\u51b3\u73b0\u6709\u8bad\u7ec3\u76ee\u6807\u7684\u95ee\u9898\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.01813", "pdf": "https://arxiv.org/pdf/2511.01813", "abs": "https://arxiv.org/abs/2511.01813", "authors": ["Hao Zhu", "Joschka Boedecker"], "title": "Disciplined Biconvex Programming", "categories": ["math.OC", "cs.CE", "cs.LG", "cs.MS", "90C25, 90C59, 90C90"], "comment": null, "summary": "We introduce disciplined biconvex programming (DBCP), a modeling framework\nfor specifying and solving biconvex optimization problems. Biconvex\noptimization problems arise in various applications, including machine\nlearning, signal processing, computational science, and control. Solving a\nbiconvex optimization problem in practice usually resolves to heuristic methods\nbased on alternate convex search (ACS), which iteratively optimizes over one\nblock of variables while keeping the other fixed, so that the resulting\nsubproblems are convex and can be efficiently solved. However, designing and\nimplementing an ACS solver for a specific biconvex optimization problem usually\nrequires significant effort from the user, which can be tedious and\nerror-prone. DBCP extends the principles of disciplined convex programming to\nbiconvex problems, allowing users to specify biconvex optimization problems in\na natural way based on a small number of syntax rules. The resulting problem\ncan then be automatically split and transformed into convex subproblems, for\nwhich a customized ACS solver is then generated and applied. DBCP allows users\nto quickly experiment with different biconvex problem formulations, without\nexpertise in convex optimization. We implement DBCP into the open source Python\npackage dbcp, as an extension to the famous domain specific language CVXPY for\nconvex optimization.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u6709\u7eaa\u5f8b\u7684\u53cc\u51f8\u89c4\u5212\uff08DBCP\uff09\u6846\u67b6\uff0c\u53ef\u81ea\u52a8\u5c06\u53cc\u51f8\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u5b50\u95ee\u9898\u5e76\u751f\u6210\u6c42\u89e3\u5668\uff0c\u8fd8\u5b9e\u73b0\u4e3aPython\u5305\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6c42\u89e3\u53cc\u51f8\u4f18\u5316\u95ee\u9898\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u8bbe\u8ba1\u548c\u5b9e\u73b0\u6c42\u89e3\u5668\u9700\u5927\u91cf\u4eba\u529b\u4e14\u6613\u51fa\u9519\u7684\u95ee\u9898\u3002", "method": "\u5c06\u6709\u7eaa\u5f8b\u7684\u51f8\u89c4\u5212\u539f\u5219\u6269\u5c55\u5230\u53cc\u51f8\u95ee\u9898\uff0c\u6839\u636e\u8bed\u6cd5\u89c4\u5219\u6307\u5b9a\u95ee\u9898\uff0c\u81ea\u52a8\u62c6\u5206\u8f6c\u5316\u4e3a\u51f8\u5b50\u95ee\u9898\u5e76\u751f\u6210\u5b9a\u5236\u7684\u4ea4\u66ff\u51f8\u641c\u7d22\uff08ACS\uff09\u6c42\u89e3\u5668\u3002", "result": "\u5b9e\u73b0\u4e86DBCP\u5e76\u96c6\u6210\u5230\u5f00\u6e90Python\u5305dbcp\uff0c\u4f5c\u4e3a\u51f8\u4f18\u5316\u9886\u57df\u7279\u5b9a\u8bed\u8a00CVXPY\u7684\u6269\u5c55\u3002", "conclusion": "DBCP\u8ba9\u7528\u6237\u65e0\u9700\u51f8\u4f18\u5316\u4e13\u4e1a\u77e5\u8bc6\u5c31\u80fd\u5feb\u901f\u8bd5\u9a8c\u4e0d\u540c\u53cc\u51f8\u95ee\u9898\u516c\u5f0f\u3002"}}
{"id": "2511.01716", "pdf": "https://arxiv.org/pdf/2511.01716", "abs": "https://arxiv.org/abs/2511.01716", "authors": ["Jiale Lao", "Andreas Zimmerer", "Olga Ovcharenko", "Tianji Cong", "Matthew Russo", "Gerardo Vitagliano", "Michael Cochez", "Fatma \u00d6zcan", "Gautam Gupta", "Thibaud Hottelier", "H. V. Jagadish", "Kris Kissel", "Sebastian Schelter", "Andreas Kipf", "Immanuel Trummer"], "title": "SemBench: A Benchmark for Semantic Query Processing Engines", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "We present a benchmark targeting a novel class of systems: semantic query\nprocessing engines. Those systems rely inherently on generative and reasoning\ncapabilities of state-of-the-art large language models (LLMs). They extend SQL\nwith semantic operators, configured by natural language instructions, that are\nevaluated via LLMs and enable users to perform various operations on multimodal\ndata.\n  Our benchmark introduces diversity across three key dimensions: scenarios,\nmodalities, and operators. Included are scenarios ranging from movie review\nanalysis to medical question-answering. Within these scenarios, we cover\ndifferent data modalities, including images, audio, and text. Finally, the\nqueries involve a diverse set of operators, including semantic filters, joins,\nmappings, ranking, and classification operators.\n  We evaluated our benchmark on three academic systems (LOTUS, Palimpzest, and\nThalamusDB) and one industrial system, Google BigQuery. Although these results\nreflect a snapshot of systems under continuous development, our study offers\ncrucial insights into their current strengths and weaknesses, illuminating\npromising directions for future research.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u8bed\u4e49\u67e5\u8be2\u5904\u7406\u5f15\u64ce\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u5f15\u64ce\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u51c6\u6db5\u76d6\u573a\u666f\u3001\u6a21\u6001\u548c\u64cd\u4f5c\u7b26\u7ef4\u5ea6\uff0c\u5bf9\u591a\u4e2a\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\u5e76\u7ed9\u51fa\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4e3a\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u67e5\u8be2\u5904\u7406\u5f15\u64ce\u5efa\u7acb\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5f15\u5165\u6db5\u76d6\u573a\u666f\u3001\u6a21\u6001\u548c\u64cd\u4f5c\u7b26\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\u7684\u591a\u6837\u6027\u57fa\u51c6\uff0c\u5bf9\u4e09\u4e2a\u5b66\u672f\u7cfb\u7edf\u548c\u4e00\u4e2a\u5de5\u4e1a\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u53cd\u6620\u4e86\u5904\u4e8e\u6301\u7eed\u5f00\u53d1\u4e2d\u7684\u7cfb\u7edf\u7684\u5f53\u524d\u60c5\u51b5\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u7cfb\u7edf\u5f53\u524d\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.00336", "pdf": "https://arxiv.org/pdf/2511.00336", "abs": "https://arxiv.org/abs/2511.00336", "authors": ["Siva Sai", "Manish Prasad", "Animesh Bhargava", "Vinay Chamola", "Rajkumar Buyya"], "title": "Split Learning-Enabled Framework for Secure and Light-weight Internet of Medical Things Systems", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "11 pages, 5 figures, Under review in an IEEE Transactions journal", "summary": "The rapid growth of Internet of Medical Things (IoMT) devices has resulted in\nsignificant security risks, particularly the risk of malware attacks on\nresource-constrained devices. Conventional deep learning methods are\nimpractical due to resource limitations, while Federated Learning (FL) suffers\nfrom high communication overhead and vulnerability to non-IID (heterogeneous)\ndata. In this paper, we propose a split learning (SL) based framework for IoT\nmalware detection through image-based classification. By dividing the neural\nnetwork training between the clients and an edge server, the framework reduces\ncomputational burden on resource-constrained clients while ensuring data\nprivacy. We formulate a joint optimization problem that balances computation\ncost and communication efficiency by using a game-theoretic approach for\nattaining better training performance. Experimental evaluations show that the\nproposed framework outperforms popular FL methods in terms of accuracy\n(+6.35%), F1-score (+5.03%), high convergence speed (+14.96%), and less\nresource consumption (33.83%). These results establish the potential of SL as a\nscalable and secure paradigm for next-generation IoT security.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62c6\u5206\u5b66\u4e60\u7684\u7269\u8054\u7f51\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u6846\u67b6\uff0c\u6027\u80fd\u4f18\u4e8e\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bc1\u660e\u62c6\u5206\u5b66\u4e60\u5728\u7269\u8054\u7f51\u5b89\u5168\u7684\u6f5c\u529b\u3002", "motivation": "\u533b\u7597\u7269\u8054\u7f51\u8bbe\u5907\u589e\u957f\u5e26\u6765\u5b89\u5168\u98ce\u9669\uff0c\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u56e0\u8d44\u6e90\u9650\u5236\u4e0d\u53ef\u884c\uff0c\u8054\u90a6\u5b66\u4e60\u6709\u9ad8\u901a\u4fe1\u5f00\u9500\u548c\u975eIID\u6570\u636e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u62c6\u5206\u5b66\u4e60\u7684\u6846\u67b6\u8fdb\u884c\u57fa\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684\u7269\u8054\u7f51\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\uff0c\u7528\u535a\u5f08\u8bba\u65b9\u6cd5\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u548c\u901a\u4fe1\u6548\u7387\u3002", "result": "\u6846\u67b6\u5728\u51c6\u786e\u7387\u3001F1\u5206\u6570\u3001\u6536\u655b\u901f\u5ea6\u548c\u8d44\u6e90\u6d88\u8017\u65b9\u9762\u4f18\u4e8e\u6d41\u884c\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u62c6\u5206\u5b66\u4e60\u53ef\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u7269\u8054\u7f51\u5b89\u5168\u7684\u53ef\u6269\u5c55\u548c\u5b89\u5168\u8303\u5f0f\u3002"}}
{"id": "2511.01857", "pdf": "https://arxiv.org/pdf/2511.01857", "abs": "https://arxiv.org/abs/2511.01857", "authors": ["Reza Esfandiarpoor", "Max Zuo", "Stephen H. Bach"], "title": "Trove: A Flexible Toolkit for Dense Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "We introduce Trove, an easy-to-use open-source retrieval toolkit that\nsimplifies research experiments without sacrificing flexibility or speed. For\nthe first time, we introduce efficient data management features that load and\nprocess (filter, select, transform, and combine) retrieval datasets on the fly,\nwith just a few lines of code. This gives users the flexibility to easily\nexperiment with different dataset configurations without the need to compute\nand store multiple copies of large datasets. Trove is highly customizable: in\naddition to many built-in options, it allows users to freely modify existing\ncomponents or replace them entirely with user-defined objects. It also provides\na low-code and unified pipeline for evaluation and hard negative mining, which\nsupports multi-node execution without any code changes. Trove's data management\nfeatures reduce memory consumption by a factor of 2.6. Moreover, Trove's\neasy-to-use inference pipeline incurs no overhead, and inference times decrease\nlinearly with the number of available nodes. Most importantly, we demonstrate\nhow Trove simplifies retrieval experiments and allows for arbitrary\ncustomizations, thus facilitating exploratory research.", "AI": {"tldr": "\u4ecb\u7ecd\u5f00\u6e90\u68c0\u7d22\u5de5\u5177\u5305Trove\uff0c\u5177\u6709\u9ad8\u6548\u6570\u636e\u7ba1\u7406\u3001\u9ad8\u5ea6\u53ef\u5b9a\u5236\u7b49\u7279\u70b9\uff0c\u80fd\u7b80\u5316\u5b9e\u9a8c\u5e76\u652f\u6301\u63a2\u7d22\u6027\u7814\u7a76\u3002", "motivation": "\u7b80\u5316\u68c0\u7d22\u7814\u7a76\u5b9e\u9a8c\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u7075\u6d3b\u6027\u548c\u901f\u5ea6\u3002", "method": "\u5f15\u5165\u9ad8\u6548\u6570\u636e\u7ba1\u7406\u529f\u80fd\uff0c\u63d0\u4f9b\u9ad8\u5ea6\u53ef\u5b9a\u5236\u9009\u9879\u548c\u4f4e\u4ee3\u7801\u7edf\u4e00\u8bc4\u4f30\u4e0e\u8d1f\u6837\u672c\u6316\u6398\u6d41\u7a0b\u3002", "result": "\u6570\u636e\u7ba1\u7406\u529f\u80fd\u4f7f\u5185\u5b58\u6d88\u8017\u964d\u4f4e2.6\u500d\uff0c\u63a8\u7406\u65f6\u95f4\u968f\u8282\u70b9\u6570\u7ebf\u6027\u51cf\u5c11\u3002", "conclusion": "Trove\u80fd\u7b80\u5316\u68c0\u7d22\u5b9e\u9a8c\uff0c\u652f\u6301\u4efb\u610f\u5b9a\u5236\uff0c\u4fbf\u4e8e\u63a2\u7d22\u6027\u7814\u7a76\u3002"}}
{"id": "2511.00509", "pdf": "https://arxiv.org/pdf/2511.00509", "abs": "https://arxiv.org/abs/2511.00509", "authors": ["Yifan Xia", "Guorui Chen", "Wenqian Yu", "Zhijiang Li", "Philip Torr", "Jindong Gu"], "title": "Reimagining Safety Alignment with An Image", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "Large language models (LLMs) excel in diverse applications but face dual\nchallenges: generating harmful content under jailbreak attacks and over-refusal\nof benign queries due to rigid safety mechanisms. These issues are further\ncomplicated by the need to accommodate different value systems and precisely\nalign with given safety preferences. Moreover, traditional methods like SFT and\nRLHF lack this capability due to their costly parameter tuning requirements and\ninability to support multiple value systems within a single model. These\nproblems are more obvious in multimodal large language models (MLLMs),\nespecially in terms of heightened over-refusal in cross-modal tasks and new\nsecurity risks arising from expanded attack surfaces. We propose Magic Image,\nan optimization-driven visual prompt framework that enhances security while\nreducing over-refusal. By optimizing image prompts using harmful/benign\nsamples, our method enables a single model to adapt to different value systems\nand better align with given safety preferences without parameter updates.\nExperiments demonstrate improved safety-effectiveness balance across diverse\ndatasets while preserving model performance, offering a practical solution for\ndeployable MLLM safety alignment.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u548c\u8fc7\u5ea6\u62d2\u7b54\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u63d0\u51faMagic Image\u6846\u67b6\u4f18\u5316\u89c6\u89c9\u63d0\u793a\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u63d0\u5347\u5b89\u5168\u6027\u4e0e\u6548\u679c\u5e73\u8861\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u5185\u5bb9\u5b89\u5168\u548c\u62d2\u7b54\u65b9\u9762\u5b58\u5728\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u591a\u4ef7\u503c\u4f53\u7cfb\u548c\u7cbe\u786e\u5bf9\u9f50\u5b89\u5168\u504f\u597d\uff0c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u95ee\u9898\u66f4\u7a81\u51fa\u3002", "method": "\u63d0\u51faMagic Image\uff0c\u4e00\u4e2a\u4f18\u5316\u9a71\u52a8\u7684\u89c6\u89c9\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u6709\u5bb3/\u826f\u6027\u6837\u672c\u4f18\u5316\u56fe\u50cf\u63d0\u793a\uff0c\u8ba9\u6a21\u578b\u4e0d\u66f4\u65b0\u53c2\u6570\u9002\u5e94\u4e0d\u540c\u4ef7\u503c\u4f53\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u80fd\u63d0\u5347\u5b89\u5168\u6027\u4e0e\u6548\u679c\u7684\u5e73\u8861\uff0c\u540c\u65f6\u4fdd\u7559\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "Magic Image\u4e3a\u53ef\u90e8\u7f72\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00619", "pdf": "https://arxiv.org/pdf/2511.00619", "abs": "https://arxiv.org/abs/2511.00619", "authors": ["Huaijin Ran", "Haoyi Zhang", "Xunzhu Tang"], "title": "GDPR-Bench-Android: A Benchmark for Evaluating Automated GDPR Compliance Detection in Android", "categories": ["cs.SE"], "comment": null, "summary": "Automating the detection of EU General Data Protection Regulation (GDPR)\nviolations in source code is a critical but underexplored challenge. We\nintroduce \\textbf{GDPR-Bench-Android}, the first comprehensive benchmark for\nevaluating diverse automated methods for GDPR compliance detection in Android\napplications. It contains \\textbf{1951} manually annotated violation instances\nfrom \\textbf{15} open-source repositories, covering 23 GDPR articles at file-,\nmodule-, and line-level granularities. To enable a multi-paradigm evaluation,\nwe contribute \\textbf{Formal-AST}, a novel, source-code-native formal method\nthat serves as a deterministic baseline. We define two tasks: (1)\n\\emph{multi-granularity violation localization}, evaluated via\nAccuracy@\\textit{k}; and (2) \\emph{snippet-level multi-label classification},\nassessed by macro-F1 and other classification metrics. We benchmark 11 methods,\nincluding eight state-of-the-art LLMs, our Formal-AST analyzer, a\nretrieval-augmented (RAG) method, and an agentic (ReAct) method. Our findings\nreveal that no single paradigm excels across all tasks. For Task 1, the ReAct\nagent achieves the highest file-level Accuracy@1 (17.38%), while the\nQwen2.5-72B LLM leads at the line level (61.60%), in stark contrast to the\nFormal-AST method's 1.86%. For the difficult multi-label Task 2, the\nClaude-Sonnet-4.5 LLM achieves the best Macro-F1 (5.75%), while the RAG method\nyields the highest Macro-Precision (7.10%). These results highlight the\ntask-dependent strengths of different automated approaches and underscore the\nvalue of our benchmark in diagnosing their capabilities. All resources are\navailable at: https://github.com/Haoyi-Zhang/GDPR-Bench-Android.", "AI": {"tldr": "\u4ecb\u7ecd\u9996\u4e2a\u8bc4\u4f30\u5b89\u5353\u5e94\u7528GDPR\u5408\u89c4\u68c0\u6d4b\u81ea\u52a8\u5316\u65b9\u6cd5\u7684\u57fa\u51c6GDPR - Bench - Android\uff0c\u5b9a\u4e49\u4e24\u9879\u4efb\u52a1\u5e76\u5bf911\u79cd\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u6709\u4f18\u52bf\u3002", "motivation": "\u81ea\u52a8\u5316\u68c0\u6d4b\u6e90\u4ee3\u7801\u4e2dGDPR\u8fdd\u89c4\u662f\u5173\u952e\u4f46\u7814\u7a76\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u9700\u8981\u8bc4\u4f30\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u5f15\u5165GDPR - Bench - Android\u57fa\u51c6\uff0c\u63d0\u51faFormal - AST\u5f62\u5f0f\u65b9\u6cd5\uff0c\u5b9a\u4e49\u591a\u7c92\u5ea6\u8fdd\u89c4\u5b9a\u4f4d\u548c\u7247\u6bb5\u7ea7\u591a\u6807\u7b7e\u5206\u7c7b\u4e24\u9879\u4efb\u52a1\uff0c\u5bf911\u79cd\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u8868\u73b0\u4e0d\u540c\uff0c\u5982ReAct\u4ee3\u7406\u5728\u4efb\u52a11\u6587\u4ef6\u7ea7Accuracy@1\u6700\u9ad8\uff0cQwen2.5 - 72B LLM\u5728\u7ebf\u7ea7\u6700\u9ad8\uff1bClaude - Sonnet - 4.5 LLM\u5728\u4efb\u52a12 Macro - F1\u6700\u4f73\uff0cRAG\u65b9\u6cd5Macro - Precision\u6700\u9ad8\u3002", "conclusion": "\u4e0d\u540c\u81ea\u52a8\u5316\u65b9\u6cd5\u6709\u4efb\u52a1\u4f9d\u8d56\u4f18\u52bf\uff0cGDPR - Bench - Android\u57fa\u51c6\u5bf9\u8bca\u65ad\u65b9\u6cd5\u80fd\u529b\u6709\u4ef7\u503c\u3002"}}
{"id": "2511.00054", "pdf": "https://arxiv.org/pdf/2511.00054", "abs": "https://arxiv.org/abs/2511.00054", "authors": ["Gio Huh", "Dhruv Sheth", "Rayhan Zirvi", "Frank Xiao"], "title": "SpatialTraceGen: High-Fidelity Traces for Efficient VLM Spatial Reasoning Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025) Workshop on Efficient Reasoning", "summary": "While Vision-Language Models (VLMs) excel in many areas, they struggle with\ncomplex spatial reasoning, which requires problem decomposition and strategic\ntool use. Fine-tuning smaller, more deployable models offers an efficient path\nto strong performance, but this is hampered by a major bottleneck: the absence\nof high-quality, step-by-step reasoning data. To address this data-efficiency\ngap, we introduce SpatialTraceGen, a framework to distill the reasoning\nprocesses of a large teacher model into a high-quality dataset of multi-hop,\nmulti-tool reasoning traces. A key innovation is our automated Verifier, which\nscalably ensures the fidelity of each reasoning step, providing a\ncost-effective alternative to manual human annotation. On the CLEVR-Humans\nbenchmark, this verifier-guided process improves the average quality score of\ntraces by 17\\% while reducing quality variance by over 40\\%. SpatialTraceGen\ndelivers a dataset of expert traces, providing the structured, step-by-step\nexamples of tool use necessary for effective fine-tuning and sample-efficient\noffline reinforcement learning.", "AI": {"tldr": "\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u6570\u636e\u4e0a\u7684\u4e0d\u8db3\uff0c\u63d0\u51faSpatialTraceGen\u6846\u67b6\u751f\u6210\u9ad8\u8d28\u91cf\u63a8\u7406\u8f68\u8ff9\u6570\u636e\u96c6\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7a7a\u95f4\u63a8\u7406\u5b58\u5728\u56f0\u96be\uff0c\u5fae\u8c03\u5c0f\u6a21\u578b\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u9010\u6b65\u63a8\u7406\u6570\u636e\u3002", "method": "\u5f15\u5165SpatialTraceGen\u6846\u67b6\uff0c\u5c06\u5927\u6559\u5e08\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u63d0\u70bc\u6210\u591a\u8df3\u3001\u591a\u5de5\u5177\u63a8\u7406\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u7528\u81ea\u52a8\u9a8c\u8bc1\u5668\u786e\u4fdd\u63a8\u7406\u6b65\u9aa4\u51c6\u786e\u6027\u3002", "result": "\u5728CLEVR - Humans\u57fa\u51c6\u4e0a\uff0c\u9a8c\u8bc1\u5668\u5f15\u5bfc\u8fc7\u7a0b\u4f7f\u8f68\u8ff9\u5e73\u5747\u8d28\u91cf\u5f97\u5206\u63d0\u9ad817%\uff0c\u964d\u4f4e\u8d28\u91cf\u65b9\u5dee\u8d8540%\u3002", "conclusion": "SpatialTraceGen\u63d0\u4f9b\u4e13\u5bb6\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u53ef\u7528\u4e8e\u6709\u6548\u5fae\u8c03\u4e0e\u6837\u672c\u9ad8\u6548\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002"}}
{"id": "2511.00078", "pdf": "https://arxiv.org/pdf/2511.00078", "abs": "https://arxiv.org/abs/2511.00078", "authors": ["Chen-Wei Chang", "Yu-Chieh Cheng", "Yun-En Tsai", "Fanglan Chen", "Chang-Tien Lu"], "title": "RailEstate: An Interactive System for Metro Linked Property Trends", "categories": ["cs.CY", "cs.AI", "cs.DB"], "comment": null, "summary": "Access to metro systems plays a critical role in shaping urban housing\nmarkets by enhancing neighborhood accessibility and driving property demand. We\npresent RailEstate, a novel web based system that integrates spatial analytics,\nnatural language interfaces, and interactive forecasting to analyze how\nproximity to metro stations influences residential property prices in the\nWashington metropolitan area. Unlike static mapping tools or generic listing\nplatforms, RailEstate combines 25 years of historical housing data with transit\ninfrastructure to support low latency geospatial queries, time series\nvisualizations, and predictive modeling. Users can interactively explore ZIP\ncode level price patterns, investigate long term trends, and forecast future\nhousing values around any metro station. A key innovation is our natural\nlanguage chatbot, which translates plain-English questions e.g., What is the\nhighest price in Falls Church in the year 2000? into executable SQL over a\nspatial database. This unified and interactive platform empowers urban\nplanners, investors, and residents to derive actionable insights from metro\nlinked housing data without requiring technical expertise.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7f51\u7edc\u7684RailEstate\u7cfb\u7edf\u5206\u6790\u534e\u76db\u987f\u90fd\u4f1a\u533a\u5730\u94c1\u7ad9\u5bf9\u623f\u4ef7\u7684\u5f71\u54cd\uff0c\u7ed3\u5408\u5386\u53f2\u6570\u636e\u652f\u6301\u591a\u79cd\u529f\u80fd\uff0c\u542b\u81ea\u7136\u8bed\u8a00\u804a\u5929\u673a\u5668\u4eba\uff0c\u65b9\u4fbf\u4e0d\u540c\u4eba\u7fa4\u83b7\u53d6\u89c1\u89e3\u3002", "motivation": "\u7814\u7a76\u5730\u94c1\u7cfb\u7edf\u53ef\u8fbe\u6027\u5bf9\u57ce\u5e02\u4f4f\u623f\u5e02\u573a\u7684\u5f71\u54cd\uff0c\u4e3a\u76f8\u5173\u4eba\u5458\u63d0\u4f9b\u5206\u6790\u5de5\u5177\u3002", "method": "\u6784\u5efaRailEstate\u7cfb\u7edf\uff0c\u6574\u5408\u7a7a\u95f4\u5206\u6790\u3001\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u548c\u4ea4\u4e92\u5f0f\u9884\u6d4b\uff0c\u7ed3\u540825\u5e74\u5386\u53f2\u4f4f\u623f\u6570\u636e\u4e0e\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u7cfb\u7edf\u652f\u6301\u4f4e\u5ef6\u8fdf\u5730\u7406\u7a7a\u95f4\u67e5\u8be2\u3001\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u548c\u9884\u6d4b\u5efa\u6a21\uff0c\u7528\u6237\u53ef\u4ea4\u4e92\u63a2\u7d22\u623f\u4ef7\u6a21\u5f0f\u3001\u8d8b\u52bf\u548c\u9884\u6d4b\u672a\u6765\u623f\u4ef7\u3002", "conclusion": "\u8be5\u7edf\u4e00\u4ea4\u4e92\u5f0f\u5e73\u53f0\u4f7f\u57ce\u5e02\u89c4\u5212\u8005\u3001\u6295\u8d44\u8005\u548c\u5c45\u6c11\u65e0\u9700\u6280\u672f\u4e13\u957f\u5373\u53ef\u4ece\u5730\u94c1\u76f8\u5173\u4f4f\u623f\u6570\u636e\u4e2d\u83b7\u53d6\u53ef\u884c\u89c1\u89e3\u3002"}}
{"id": "2511.00185", "pdf": "https://arxiv.org/pdf/2511.00185", "abs": "https://arxiv.org/abs/2511.00185", "authors": ["Roberto Morales"], "title": "SHAP values through General Fourier Representations: Theory and Applications", "categories": ["math.OC", "math.AP", "stat.ML", "68T07, 42B10, 60G15, 65T50"], "comment": null, "summary": "This article establishes a rigorous spectral framework for the mathematical\nanalysis of SHAP values. We show that any predictive model defined on a\ndiscrete or multi-valued input space admits a generalized Fourier expansion\nwith respect to an orthonormalisation tensor-product basis constructed under a\nproduct probability measure. Within this setting, each SHAP attribution can be\nrepresented as a linear functional of the model's Fourier coefficients.\n  Two complementary regimes are studied. In the deterministic regime, we derive\nquantitative stability estimates for SHAP values under Fourier truncation,\nshowing that the attribution map is Lipschitz continuous with respect to the\ndistance between predictors. In the probabilistic regime, we consider neural\nnetworks in their infinite-width limit and prove convergence of SHAP values\ntoward those induced by the corresponding Gaussian process prior, with explicit\nerror bounds in expectation and with high probability based on concentration\ninequalities.\n  We also provide a numerical experiment on a clinical unbalanced dataset to\nvalidate the theoretical findings.", "AI": {"tldr": "\u672c\u6587\u4e3aSHAP\u503c\u7684\u6570\u5b66\u5206\u6790\u5efa\u7acb\u4e25\u683c\u8c31\u6846\u67b6\uff0c\u7814\u7a76\u4e24\u79cd\u60c5\u51b5\u5e76\u7ed9\u51fa\u7a33\u5b9a\u6027\u4f30\u8ba1\u548c\u6536\u655b\u6027\u8bc1\u660e\uff0c\u8fd8\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002", "motivation": "\u4e3aSHAP\u503c\u7684\u6570\u5b66\u5206\u6790\u5efa\u7acb\u4e25\u8c28\u7684\u8c31\u6846\u67b6\u3002", "method": "\u5229\u7528\u5e7f\u4e49\u5085\u91cc\u53f6\u5c55\u5f00\uff0c\u7814\u7a76\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u4e24\u79cd\u60c5\u51b5\uff0c\u5728\u786e\u5b9a\u6027\u60c5\u51b5\u63a8\u5bfc\u5b9a\u91cf\u7a33\u5b9a\u6027\u4f30\u8ba1\uff0c\u5728\u6982\u7387\u6027\u60c5\u51b5\u8003\u8651\u65e0\u9650\u5bbd\u6781\u9650\u4e0b\u7684\u795e\u7ecf\u7f51\u7edc\u5e76\u8bc1\u660e\u6536\u655b\u6027\u3002", "result": "\u5728\u786e\u5b9a\u6027\u60c5\u51b5\u8868\u660e\u5f52\u56e0\u6620\u5c04\u5173\u4e8e\u9884\u6d4b\u5668\u95f4\u8ddd\u79bb\u662f\u5229\u666e\u5e0c\u8328\u8fde\u7eed\u7684\uff1b\u5728\u6982\u7387\u6027\u60c5\u51b5\u8bc1\u660eSHAP\u503c\u6536\u655b\u5230\u5bf9\u5e94\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u8bf1\u5bfc\u7684\u503c\uff0c\u5e76\u7ed9\u51fa\u8bef\u5dee\u754c\u3002", "conclusion": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002"}}
{"id": "2511.00081", "pdf": "https://arxiv.org/pdf/2511.00081", "abs": "https://arxiv.org/abs/2511.00081", "authors": ["Masfiqur Rahaman", "Maoyejatun Hasana", "Shahad Shahriar Rahman", "MD Sajid Mostafiz Noor", "Razin Reaz Abedin", "Md Toki Tahmid", "Duncan Watson Parris", "Tanzeem Choudhury", "A. B. M. Alim Al Islam", "Tauhidur Rahman"], "title": "Forecasting Occupational Survivability of Rickshaw Pullers in a Changing Climate with Wearable Data", "categories": ["cs.CY", "cs.HC", "cs.IR", "cs.LG", "stat.AP"], "comment": "This is a preprint version of a manuscript accepted and to be\n  published in the Proceedings of the ACM on Interactive, Mobile, Wearable and\n  Ubiquitous Technologies (IMWUT)", "summary": "Cycle rickshaw pullers are highly vulnerable to extreme heat, yet little is\nknown about how their physiological biomarkers respond under such conditions.\nThis study collected real-time weather and physiological data using wearable\nsensors from 100 rickshaw pullers in Dhaka, Bangladesh. In addition, interviews\nwith 12 pullers explored their knowledge, perceptions, and experiences related\nto climate change. We developed a Linear Gaussian Bayesian Network (LGBN)\nregression model to predict key physiological biomarkers based on activity,\nweather, and demographic features. The model achieved normalized mean absolute\nerror values of 0.82, 0.47, 0.65, and 0.67 for skin temperature, relative\ncardiac cost, skin conductance response, and skin conductance level,\nrespectively. Using projections from 18 CMIP6 climate models, we layered the\nLGBN on future climate forecasts to analyze survivability for current\n(2023-2025) and future years (2026-2100). Based on thresholds of WBGT above\n31.1{\\deg}C and skin temperature above 35{\\deg}C, 32% of rickshaw pullers\nalready face high heat exposure risk. By 2026-2030, this percentage may rise to\n37% with average exposure lasting nearly 12 minutes, or about two-thirds of the\ntrip duration. A thematic analysis of interviews complements these findings,\nshowing that rickshaw pullers recognize their increasing climate vulnerability\nand express concern about its effects on health and occupational survivability.", "AI": {"tldr": "\u7814\u7a76\u6536\u96c6\u8fbe\u5361\u4eba\u529b\u8f66\u592b\u751f\u7406\u548c\u5929\u6c14\u6570\u636e\uff0c\u7528LGBN\u6a21\u578b\u9884\u6d4b\u751f\u7406\u6307\u6807\uff0c\u7ed3\u5408\u6c14\u5019\u6a21\u578b\u5206\u6790\u5176\u5728\u5f53\u524d\u548c\u672a\u6765\u9ad8\u6e29\u66b4\u9732\u98ce\u9669\uff0c\u8bbf\u8c08\u663e\u793a\u8f66\u592b\u610f\u8bc6\u5230\u6c14\u5019\u8106\u5f31\u6027\u3002", "motivation": "\u4eba\u529b\u8f66\u592b\u6613\u53d7\u6781\u7aef\u9ad8\u6e29\u5f71\u54cd\uff0c\u4f46\u5bf9\u5176\u751f\u7406\u6307\u6807\u54cd\u5e94\u4e86\u89e3\u751a\u5c11\uff0c\u9700\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u6536\u96c6100\u540d\u8f66\u592b\u5b9e\u65f6\u5929\u6c14\u548c\u751f\u7406\u6570\u636e\uff0c\u8bbf\u8c0812\u540d\u8f66\u592b\uff1b\u6784\u5efaLGBN\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u751f\u7406\u6307\u6807\uff1b\u7ed3\u540818\u4e2aCMIP6\u6c14\u5019\u6a21\u578b\u5206\u6790\u751f\u5b58\u80fd\u529b\uff1b\u8fdb\u884c\u8bbf\u8c08\u4e3b\u9898\u5206\u6790\u3002", "result": "LGBN\u6a21\u578b\u5bf9\u76ae\u80a4\u6e29\u5ea6\u7b49\u6307\u6807\u9884\u6d4b\u7684\u5f52\u4e00\u5316\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u5206\u522b\u4e3a0.82\u30010.47\u30010.65\u548c0.67\uff1b32%\u8f66\u592b\u9762\u4e34\u9ad8\u66b4\u9732\u98ce\u9669\uff0c2026 - 2030\u5e74\u5347\u81f337%\uff1b\u8bbf\u8c08\u8868\u660e\u8f66\u592b\u610f\u8bc6\u5230\u6c14\u5019\u8106\u5f31\u6027\u3002", "conclusion": "\u4eba\u529b\u8f66\u592b\u9762\u4e34\u9ad8\u6e29\u66b4\u9732\u98ce\u9669\u589e\u52a0\uff0c\u4ed6\u4eec\u5df2\u8ba4\u8bc6\u5230\u6c14\u5019\u8106\u5f31\u6027\u5bf9\u5065\u5eb7\u548c\u804c\u4e1a\u751f\u5b58\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.00547", "pdf": "https://arxiv.org/pdf/2511.00547", "abs": "https://arxiv.org/abs/2511.00547", "authors": ["Alain Riou"], "title": "Efficient Generation of Binary Magic Squares", "categories": ["cs.AI"], "comment": null, "summary": "We propose a simple algorithm for generating Binary Magic Squares (BMS),\ni.e., square binary matrices where the sum of all rows and all columns are\nequal. We show by induction that our algorithm always returns valid BMS with\noptimal theoretical complexity. We then extend our study to non-square Binary\nMagic Squares, formalize conditions on the sum of rows and columns for these\nBMS to exist, and show that a slight variant of our first algorithm can\ngenerate provably generate them. Finally, we publicly release two\nimplementations of our algorithm as Python packages, including one that can\ngenerate several BMS in parallel using GPU acceleration.", "AI": {"tldr": "\u63d0\u51fa\u751f\u6210\u4e8c\u5143\u5e7b\u65b9\u7b97\u6cd5\uff0c\u8bc1\u660e\u590d\u6742\u5ea6\u6700\u4f18\uff0c\u6269\u5c55\u5230\u975e\u65b9\u9635\u5e76\u7ed9\u51fa\u6761\u4ef6\uff0c\u516c\u5f00Python\u5b9e\u73b0\u5305\u3002", "motivation": "\u5f00\u53d1\u751f\u6210\u4e8c\u5143\u5e7b\u65b9\u53ca\u975e\u65b9\u9635\u4e8c\u5143\u5e7b\u65b9\u7684\u6709\u6548\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u7b97\u6cd5\u5e76\u7528\u5f52\u7eb3\u6cd5\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u5bf9\u975e\u65b9\u9635\u5f62\u5f0f\u5316\u884c\u5217\u548c\u6761\u4ef6\uff0c\u6539\u8fdb\u7b97\u6cd5\u751f\u6210\u975e\u65b9\u9635\u3002", "result": "\u7b97\u6cd5\u80fd\u4ee5\u6700\u4f18\u7406\u8bba\u590d\u6742\u5ea6\u751f\u6210\u6709\u6548\u4e8c\u5143\u5e7b\u65b9\uff0c\u6539\u8fdb\u7b97\u6cd5\u53ef\u751f\u6210\u975e\u65b9\u9635\uff0c\u53d1\u5e03Python\u5b9e\u73b0\u5305\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u6709\u6548\u4e14\u6709\u516c\u5f00\u5b9e\u73b0\uff0c\u53ef\u7528\u4e8e\u751f\u6210\u4e8c\u5143\u5e7b\u65b9\u53ca\u975e\u65b9\u9635\u3002"}}
{"id": "2511.00624", "pdf": "https://arxiv.org/pdf/2511.00624", "abs": "https://arxiv.org/abs/2511.00624", "authors": ["Haoyi Zhang", "Huaijin Ran", "Xunzhu Tang"], "title": "Can Large Language Models Detect Real-World Android Software Compliance Violations?", "categories": ["cs.SE"], "comment": null, "summary": "The rapid development of Large Language Models (LLMs) has transformed\nsoftware engineering, showing promise in tasks like code generation, bug\ndetection, and compliance checking. However, current models struggle to detect\ncompliance violations in Android applications across diverse legal frameworks.\nWe propose \\emph{CompliBench}, a novel evaluation framework for assessing LLMs'\nability to detect compliance violations under regulations like LGPD, PDPA, and\nPIPEDA. The framework defines two tasks: Task 1 evaluates \\emph{retrieval and\nlocalization} at file, module, and line granularities, and Task 2 assesses\n\\emph{multi-label judgment} for code snippets. These tasks mirror the audit\nprocess, where auditors locate problematic code and determine implicated\nprovisions. Traditional metrics fail to capture important aspects like\ncross-granularity stability and jurisdictional consistency. Thus, we introduce\nstability-aware composites (SGS, RCS, CRGS, and OCS) for a more comprehensive\nassessment. Experiments with six models, including GPT-4O and Claude-3.5, show\n\\emph{CompliBench} improves compliance detection, with\nClaude-3.5-sonnet-20241022 achieving the highest OCS score (0.3295), and\nGemini-2.5-pro the lowest (0.0538). This work demonstrates \\emph{CompliBench}'s\npotential for improving LLM performance in compliance tasks and provides a\nfoundation for future tools aligned with data protection standards. Our project\nis available at https://github.com/Haoyi-Zhang/CompliBench.", "AI": {"tldr": "\u63d0\u51faCompliBench\u8bc4\u4f30\u6846\u67b6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u5b89\u5353\u5e94\u7528\u5408\u89c4\u8fdd\u89c4\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u68c0\u6d4b\u4e0d\u540c\u6cd5\u5f8b\u6846\u67b6\u4e0b\u5b89\u5353\u5e94\u7528\u7684\u5408\u89c4\u8fdd\u89c4\u95ee\u9898\u3002", "method": "\u63d0\u51faCompliBench\u6846\u67b6\uff0c\u5b9a\u4e49\u4e24\u9879\u4efb\u52a1\uff0c\u5f15\u5165\u7a33\u5b9a\u6027\u611f\u77e5\u590d\u5408\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCompliBench\u63d0\u5347\u4e86\u5408\u89c4\u68c0\u6d4b\u6548\u679c\uff0cClaude - 3.5 - sonnet - 20241022\u7684OCS\u5f97\u5206\u6700\u9ad8\uff0cGemini - 2.5 - pro\u6700\u4f4e\u3002", "conclusion": "CompliBench\u6709\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5408\u89c4\u4efb\u52a1\u6027\u80fd\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7b26\u5408\u6570\u636e\u4fdd\u62a4\u6807\u51c6\u7684\u5de5\u5177\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.00055", "pdf": "https://arxiv.org/pdf/2511.00055", "abs": "https://arxiv.org/abs/2511.00055", "authors": ["Leonhard Duda", "Khadijeh Alibabaei", "Elena Vollmer", "Leon Klug", "Valentin Kozlov", "Lisana Berberi", "Mishal Benz", "Rebekka Volk", "Juan Pedro Guti\u00e9rrez Hermosillo Muriedas", "Markus G\u00f6tz", "Judith S\u00e1\u00ednz-Pardo D\u00edaz", "\u00c1lvaro L\u00f3pez Garc\u00eda", "Frank Schultmann", "Achim Streit"], "title": "Exploring Federated Learning for Thermal Urban Feature Segmentation -- A Comparison of Centralized and Decentralized Approaches", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) is an approach for training a shared Machine Learning\n(ML) model with distributed training data and multiple participants. FL allows\nbypassing limitations of the traditional Centralized Machine Learning CL if\ndata cannot be shared or stored centrally due to privacy or technical\nrestrictions -- the participants train the model locally with their training\ndata and do not need to share it among the other participants. This paper\ninvestigates the practical implementation and effectiveness of FL in a\nreal-world scenario, specifically focusing on unmanned aerial vehicle\n(UAV)-based thermal images for common thermal feature detection in urban\nenvironments. The distributed nature of the data arises naturally and makes it\nsuitable for FL applications, as images captured in two German cities are\navailable. This application presents unique challenges due to non-identical\ndistribution and feature characteristics of data captured at both locations.\nThe study makes several key contributions by evaluating FL algorithms in real\ndeployment scenarios rather than simulation. We compare several FL approaches\nwith a centralized learning baseline across key performance metrics such as\nmodel accuracy, training time, communication overhead, and energy usage. This\npaper also explores various FL workflows, comparing client-controlled workflows\nand server-controlled workflows. The findings of this work serve as a valuable\nreference for understanding the practical application and limitations of the FL\nmethods in segmentation tasks in UAV-based imaging.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u65e0\u4eba\u673a\u70ed\u6210\u50cf\u57ce\u5e02\u70ed\u7279\u5f81\u68c0\u6d4b\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5bf9\u6bd4\u591a\u79cdFL\u65b9\u6cd5\u4e0e\u96c6\u4e2d\u5b66\u4e60\u57fa\u7ebf\uff0c\u63a2\u7d22\u4e0d\u540c\u5de5\u4f5c\u6d41\uff0c\u4e3aFL\u5728\u65e0\u4eba\u673a\u6210\u50cf\u5206\u5272\u4efb\u52a1\u7684\u5e94\u7528\u548c\u5c40\u9650\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5728\u6570\u636e\u56e0\u9690\u79c1\u6216\u6280\u672f\u9650\u5236\u65e0\u6cd5\u96c6\u4e2d\u5b58\u50a8\u548c\u5171\u4eab\u7684\u60c5\u51b5\u4e0b\uff0c\u7814\u7a76FL\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u548c\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u65e0\u4eba\u673a\u70ed\u6210\u50cf\u7684\u57ce\u5e02\u70ed\u7279\u5f81\u68c0\u6d4b\u3002", "method": "\u8bc4\u4f30\u771f\u5b9e\u90e8\u7f72\u573a\u666f\u800c\u975e\u6a21\u62df\u4e2d\u7684FL\u7b97\u6cd5\uff0c\u5bf9\u6bd4\u591a\u79cdFL\u65b9\u6cd5\u4e0e\u96c6\u4e2d\u5b66\u4e60\u57fa\u7ebf\u5728\u6a21\u578b\u7cbe\u5ea6\u3001\u8bad\u7ec3\u65f6\u95f4\u3001\u901a\u4fe1\u5f00\u9500\u548c\u80fd\u6e90\u4f7f\u7528\u7b49\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u7684\u8868\u73b0\uff0c\u63a2\u7d22\u5ba2\u6237\u7aef\u63a7\u5236\u548c\u670d\u52a1\u5668\u63a7\u5236\u7684\u5de5\u4f5c\u6d41\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7406\u89e3FL\u65b9\u6cd5\u5728\u65e0\u4eba\u673a\u6210\u50cf\u5206\u5272\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u548c\u5c40\u9650\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2511.00823", "pdf": "https://arxiv.org/pdf/2511.00823", "abs": "https://arxiv.org/abs/2511.00823", "authors": ["Qi Xia", "Hu Xia", "Isaac Amankona Obiri", "Adjei-Arthur Bonsu", "Grace Mupoyi Ntuala", "Ansu Badjie", "Tienin Bole Wilfried", "Jiaqin Liu", "Lan Ma", "Jianbin Gao", "Feng Yao"], "title": "TINC: Trusted Intelligent NetChain", "categories": ["cs.NI", "cs.DC"], "comment": "17 pages, 22 figures This preprint has been submitted to IEEE\n  Transactions on Networking and is currently under peer review. The content\n  may be updated based on the review outcome. \\c{opyright} The authors. All\n  rights reserved. Distributed under the arXiv non-exclusive license", "summary": "Blockchain technology facilitates the development of decentralized systems\nthat ensure trust and transparency without the need for expensive centralized\nintermediaries. However, existing blockchain architectures particularly\nconsortium blockchains face critical challenges related to scalability and\nefficiency. State sharding has emerged as a promising approach to enhance\nblockchain scalability and performance. However, current shard-based solutions\noften struggle to guarantee fair participation and a balanced workload\ndistribution among consortium members. To address these limitations, we propose\nTrusted Intelligent NetChain (TINC), a multi-plane sharding architecture\nspecifically designed for consortium blockchains. TINC incorporates intelligent\nmechanisms for adaptive node assignment and dynamic workload balancing,\nenabling the system to respond effectively to changing network conditions while\nmaintaining equitable shard utilization. By decoupling the control and data\nplanes, TINC allows control nodes to focus on consensus operations, while data\nnodes handle large-scale storage, thus improving overall resource efficiency.\nExtensive experimental evaluation and formal analysis demonstrate that TINC\nsignificantly outperforms existing shard-based blockchain frameworks. It\nachieves higher throughput, lower latency, balanced node and transaction\ndistributions, and reduced transaction failure rates. Furthermore, TINC\nmaintains essential blockchain security guarantees, exhibiting resilience\nagainst Byzantine faults and dynamic network environments. The integration of\nDynamic Decentralized Identifiers (DDIDs) further strengthens trust and\nsecurity management within the consortium network.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u8054\u76df\u533a\u5757\u94fe\u7684\u591a\u5e73\u9762\u5206\u7247\u67b6\u6784TINC\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u5206\u7247\u533a\u5757\u94fe\u6846\u67b6\uff0c\u4e14\u4fdd\u969c\u5b89\u5168\u3002", "motivation": "\u73b0\u6709\u8054\u76df\u533a\u5757\u94fe\u67b6\u6784\u5b58\u5728\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u95ee\u9898\uff0c\u5f53\u524d\u5206\u7247\u89e3\u51b3\u65b9\u6848\u96be\u4ee5\u4fdd\u8bc1\u516c\u5e73\u53c2\u4e0e\u548c\u8d1f\u8f7d\u5747\u8861\u3002", "method": "\u63d0\u51faTrusted Intelligent NetChain (TINC)\u591a\u5e73\u9762\u5206\u7247\u67b6\u6784\uff0c\u5305\u542b\u81ea\u9002\u5e94\u8282\u70b9\u5206\u914d\u548c\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\u673a\u5236\uff0c\u89e3\u8026\u63a7\u5236\u548c\u6570\u636e\u5e73\u9762\u3002", "result": "TINC\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5206\u7247\u533a\u5757\u94fe\u6846\u67b6\uff0c\u5b9e\u73b0\u66f4\u9ad8\u541e\u5410\u91cf\u3001\u66f4\u4f4e\u5ef6\u8fdf\u3001\u5e73\u8861\u7684\u8282\u70b9\u548c\u4ea4\u6613\u5206\u5e03\u53ca\u66f4\u4f4e\u4ea4\u6613\u5931\u8d25\u7387\u3002", "conclusion": "TINC\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u8054\u76df\u533a\u5757\u94fe\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u969c\u5b89\u5168\uff0cDDIDs\u589e\u5f3a\u8054\u76df\u7f51\u7edc\u4fe1\u4efb\u548c\u5b89\u5168\u7ba1\u7406\u3002"}}
{"id": "2511.00107", "pdf": "https://arxiv.org/pdf/2511.00107", "abs": "https://arxiv.org/abs/2511.00107", "authors": ["Piyushkumar Patel"], "title": "AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency", "categories": ["cs.CV", "cs.AI", "cs.IR"], "comment": null, "summary": "Text to video generation has emerged as a critical frontier in generative\nartificial intelligence, yet existing approaches struggle with maintaining\ntemporal consistency, compositional understanding, and fine grained control\nover visual narratives. We present MOVAI (Multimodal Original Video AI), a\nnovel hierarchical framework that integrates compositional scene understanding\nwith temporal aware diffusion models for high fidelity text to video synthesis.\nOur approach introduces three key innovations: (1) a Compositional Scene Parser\n(CSP) that decomposes textual descriptions into hierarchical scene graphs with\ntemporal annotations, (2) a Temporal-Spatial Attention Mechanism (TSAM) that\nensures coherent motion dynamics across frames while preserving spatial\ndetails, and (3) a Progressive Video Refinement (PVR) module that iteratively\nenhances video quality through multi-scale temporal reasoning. Extensive\nexperiments on standard benchmarks demonstrate that MOVAI achieves\nstate-of-the-art performance, improving video quality metrics by 15.3% in\nLPIPS, 12.7% in FVD, and 18.9% in user preference studies compared to existing\nmethods. Our framework shows particular strength in generating complex\nmulti-object scenes with realistic temporal dynamics and fine-grained semantic\ncontrol.", "AI": {"tldr": "\u63d0\u51faMOVAI\u6846\u67b6\u7528\u4e8e\u6587\u672c\u5230\u89c6\u9891\u5408\u6210\uff0c\u6709\u4e09\u9879\u521b\u65b0\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u5728\u65f6\u95f4\u4e00\u81f4\u6027\u3001\u7ec4\u5408\u7406\u89e3\u548c\u89c6\u89c9\u53d9\u4e8b\u7ec6\u7c92\u5ea6\u63a7\u5236\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "\u63d0\u51faMOVAI\u6846\u67b6\uff0c\u5305\u542b\u7ec4\u5408\u573a\u666f\u89e3\u6790\u5668\uff08CSP\uff09\u3001\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\uff08TSAM\uff09\u548c\u6e10\u8fdb\u5f0f\u89c6\u9891\u7ec6\u5316\uff08PVR\uff09\u6a21\u5757\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cLPIPS\u89c6\u9891\u8d28\u91cf\u6307\u6807\u63d0\u9ad815.3%\uff0cFVD\u63d0\u9ad812.7%\uff0c\u7528\u6237\u504f\u597d\u7814\u7a76\u63d0\u9ad818.9%\u3002", "conclusion": "MOVAI\u6846\u67b6\u5728\u751f\u6210\u5177\u6709\u903c\u771f\u65f6\u95f4\u52a8\u6001\u548c\u7ec6\u7c92\u5ea6\u8bed\u4e49\u63a7\u5236\u7684\u590d\u6742\u591a\u5bf9\u8c61\u573a\u666f\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.00551", "pdf": "https://arxiv.org/pdf/2511.00551", "abs": "https://arxiv.org/abs/2511.00551", "authors": ["Qiang Li", "Ningjing Zeng", "Lina Yu"], "title": "Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Several studies have employed reinforcement learning (RL) to address the\nchallenges of regional adaptive traffic signal control (ATSC) and achieved\npromising results. In this field, existing research predominantly adopts\nmulti-agent frameworks. However, the adoption of multi-agent frameworks\npresents challenges for scalability. Instead, the Traffic signal control (TSC)\nproblem necessitates a single-agent framework. TSC inherently relies on\ncentralized management by a single control center, which can monitor traffic\nconditions across all roads in the study area and coordinate the control of all\nintersections. This work proposes a single-agent RL-based regional ATSC model\ncompatible with probe vehicle technology. Key components of the RL design\ninclude state, action, and reward function definitions. To facilitate learning\nand manage congestion, both state and reward functions are defined based on\nqueue length, with action designed to regulate queue dynamics. The queue length\ndefinition used in this study differs slightly from conventional definitions\nbut is closely correlated with congestion states. More importantly, it allows\nfor reliable estimation using link travel time data from probe vehicles. With\nprobe vehicle data already covering most urban roads, this feature enhances the\nproposed method's potential for widespread deployment. The method was\ncomprehensively evaluated using the SUMO simulation platform. Experimental\nresults demonstrate that the proposed model effectively mitigates large-scale\nregional congestion levels via coordinated multi-intersection control.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6a21\u578b\uff0c\u7528\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\u72b6\u6001\u548c\u5956\u52b1\u51fd\u6570\uff0c\u901a\u8fc7\u6a21\u62df\u8bc4\u4f30\u6709\u6548\u7f13\u89e3\u533a\u57df\u62e5\u5835\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7528\u4e8e\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u5b58\u5728\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u800c\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u95ee\u9898\u9700\u8981\u5355\u667a\u80fd\u4f53\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e0e\u63a2\u6d4b\u8f66\u8f86\u6280\u672f\u517c\u5bb9\u7684\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6a21\u578b\uff0c\u57fa\u4e8e\u961f\u5217\u957f\u5ea6\u5b9a\u4e49\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u5956\u52b1\u51fd\u6570\u3002", "result": "\u4f7f\u7528SUMO\u6a21\u62df\u5e73\u53f0\u8bc4\u4f30\uff0c\u8be5\u6a21\u578b\u80fd\u901a\u8fc7\u591a\u8def\u53e3\u534f\u8c03\u63a7\u5236\u6709\u6548\u7f13\u89e3\u5927\u89c4\u6a21\u533a\u57df\u62e5\u5835\u3002", "conclusion": "\u6240\u63d0\u6a21\u578b\u5728\u89e3\u51b3\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u95ee\u9898\u4e0a\u6709\u6548\u4e14\u6709\u5e7f\u6cdb\u90e8\u7f72\u6f5c\u529b\u3002"}}
{"id": "2511.00658", "pdf": "https://arxiv.org/pdf/2511.00658", "abs": "https://arxiv.org/abs/2511.00658", "authors": ["Guilherme H. Travassos", "Sabrina Rocha", "Rodrigo Feitosa", "Felipe Assis", "Patricia Goncalves", "Andre Gheventer", "Larissa Galeno", "Arthur Sasse", "Julio Cesar Guimaraes", "Carlos Brito", "Joao Pedro Wieland"], "title": "Lessons Learned from the Use of Generative AI in Engineering and Quality Assurance of a WEB System for Healthcare", "categories": ["cs.SE", "cs.AI", "cs.ET"], "comment": "11 pages, 2 figures, in Portuguese language", "summary": "The advances and availability of technologies involving Generative Artificial\nIntelligence (AI) are evolving clearly and explicitly, driving immediate\nchanges in various work activities. Software Engineering (SE) is no exception\nand stands to benefit from these new technologies, enhancing productivity and\nquality in its software development processes. However, although the use of\nGenerative AI in SE practices is still in its early stages, considering the\nlack of conclusive results from ongoing research and the limited technological\nmaturity, we have chosen to incorporate these technologies in the development\nof a web-based software system to be used in clinical trials by a thoracic\ndiseases research group at our university. For this reason, we decided to share\nthis experience report documenting our development team's learning journey in\nusing Generative AI during the software development process. Project\nmanagement, requirements specification, design, development, and quality\nassurance activities form the scope of observation. Although we do not yet have\ndefinitive technological evidence to evolve our development process\nsignificantly, the results obtained and the suggestions shared here represent\nvaluable insights for software organizations seeking to innovate their\ndevelopment practices to achieve software quality with generative AI.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5c06\u751f\u6210\u5f0fAI\u7528\u4e8e\u5f00\u53d1\u4e34\u5e8a\u8bd5\u9a8c\u7f51\u7edc\u8f6f\u4ef6\u7cfb\u7edf\u7684\u7ecf\u9a8c\uff0c\u867d\u65e0\u663e\u8457\u6280\u672f\u8bc1\u636e\uff0c\u4f46\u6210\u679c\u548c\u5efa\u8bae\u5bf9\u8f6f\u4ef6\u7ec4\u7ec7\u6709\u4ef7\u503c\u3002", "motivation": "\u751f\u6210\u5f0fAI\u53d1\u5c55\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u53ef\u4ece\u4e2d\u53d7\u76ca\uff0c\u867d\u5e94\u7528\u5c1a\u5904\u65e9\u671f\uff0c\u4ecd\u5c06\u5176\u7528\u4e8e\u5f00\u53d1\u4e34\u5e8a\u8bd5\u9a8c\u7f51\u7edc\u8f6f\u4ef6\u7cfb\u7edf\u5e76\u5206\u4eab\u7ecf\u9a8c\u3002", "method": "\u5728\u9879\u76ee\u7ba1\u7406\u3001\u9700\u6c42\u89c4\u683c\u3001\u8bbe\u8ba1\u3001\u5f00\u53d1\u548c\u8d28\u91cf\u4fdd\u8bc1\u7b49\u6d3b\u52a8\u4e2d\u4f7f\u7528\u751f\u6210\u5f0fAI\u8fdb\u884c\u8f6f\u4ef6\u5f00\u53d1\u3002", "result": "\u76ee\u524d\u5c1a\u672a\u6709\u80fd\u663e\u8457\u6539\u8fdb\u5f00\u53d1\u8fc7\u7a0b\u7684\u6280\u672f\u8bc1\u636e\uff0c\u4f46\u6709\u4e00\u5b9a\u6210\u679c\u3002", "conclusion": "\u6210\u679c\u548c\u5efa\u8bae\u5bf9\u60f3\u501f\u52a9\u751f\u6210\u5f0fAI\u521b\u65b0\u5f00\u53d1\u5b9e\u8df5\u3001\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u7684\u7ec4\u7ec7\u6709\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2511.00056", "pdf": "https://arxiv.org/pdf/2511.00056", "abs": "https://arxiv.org/abs/2511.00056", "authors": ["Yuxi Liu", "Renjia Deng", "Yutong He", "Xue Wang", "Tao Yao", "Kun Yuan"], "title": "MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The substantial memory demands of pre-training and fine-tuning large language\nmodels (LLMs) require memory-efficient optimization algorithms. One promising\napproach is layer-wise optimization, which treats each transformer block as a\nsingle layer and optimizes it sequentially, while freezing the other layers to\nsave optimizer states and activations. Although effective, these methods ignore\nthe varying importance of the modules within each layer, leading to suboptimal\nperformance. Moreover, layer-wise sampling provides only limited memory\nsavings, as at least one full layer must remain active during optimization. To\novercome these limitations, we propose Module-wise Importance SAmpling (MISA),\na novel method that divides each layer into smaller modules and assigns\nimportance scores to each module. MISA uses a weighted random sampling\nmechanism to activate modules, provably reducing gradient variance compared to\nlayer-wise sampling. Additionally, we establish an \\(\\mathcal{O}(1/\\sqrt{K})\\)\nconvergence rate under non-convex and stochastic conditions, where $K$ is the\ntotal number of block updates, and provide a detailed memory analysis\nshowcasing MISA's superiority over existing baseline methods. Experiments on\ndiverse learning tasks validate the effectiveness of MISA. Source code is\navailable at https://github.com/pkumelon/MISA.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.00203", "pdf": "https://arxiv.org/pdf/2511.00203", "abs": "https://arxiv.org/abs/2511.00203", "authors": ["David L\u00fcdke", "Tom Wollschl\u00e4ger", "Paul Ungermann", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Diffusion LLMs are Natural Adversaries for any LLM", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We introduce a novel framework that transforms the resource-intensive\n(adversarial) prompt optimization problem into an \\emph{efficient, amortized\ninference task}. Our core insight is that pretrained, non-autoregressive\ngenerative LLMs, such as Diffusion LLMs, which model the joint distribution\nover prompt-response pairs, can serve as powerful surrogates for prompt search.\nThis approach enables the direct conditional generation of prompts, effectively\nreplacing costly, per-instance discrete optimization with a small number of\nparallelizable samples. We provide a probabilistic analysis demonstrating that\nunder mild fidelity assumptions, only a few conditional samples are required to\nrecover high-reward (harmful) prompts. Empirically, we find that the generated\nprompts are low-perplexity, diverse jailbreaks that exhibit strong\ntransferability to a wide range of black-box target models, including robustly\ntrained and proprietary LLMs. Beyond adversarial prompting, our framework opens\nnew directions for red teaming, automated prompt optimization, and leveraging\nemerging Flow- and Diffusion-based LLMs.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u8d44\u6e90\u5bc6\u96c6\u578b\u63d0\u793a\u4f18\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u9ad8\u6548\u63a8\u7406\u4efb\u52a1\u7684\u6846\u67b6\uff0c\u5229\u7528\u975e\u81ea\u56de\u5f52\u751f\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u751f\u6210\u63d0\u793a\u6709\u826f\u597d\u6548\u679c\u5e76\u5f00\u62d3\u65b0\u65b9\u5411\u3002", "motivation": "\u89e3\u51b3\u8d44\u6e90\u5bc6\u96c6\u578b\u7684\uff08\u5bf9\u6297\u6027\uff09\u63d0\u793a\u4f18\u5316\u95ee\u9898\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u7684\u975e\u81ea\u56de\u5f52\u751f\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff09\u4f5c\u4e3a\u63d0\u793a\u641c\u7d22\u7684\u66ff\u4ee3\uff0c\u76f4\u63a5\u6761\u4ef6\u751f\u6210\u63d0\u793a\u3002", "result": "\u751f\u6210\u7684\u63d0\u793a\u662f\u4f4e\u56f0\u60d1\u5ea6\u3001\u591a\u6837\u5316\u7684\u8d8a\u72f1\u63d0\u793a\uff0c\u5bf9\u591a\u79cd\u9ed1\u76d2\u76ee\u6807\u6a21\u578b\u6709\u5f3a\u53ef\u8fc1\u79fb\u6027\u3002", "conclusion": "\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u8fd8\u4e3a\u7ea2\u961f\u6d4b\u8bd5\u3001\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u53ca\u5229\u7528\u65b0\u5174\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u8f9f\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.00870", "pdf": "https://arxiv.org/pdf/2511.00870", "abs": "https://arxiv.org/abs/2511.00870", "authors": ["Maxime Bouton", "Pierre-Antoine Thouvenin", "Audrey Repetti", "Pierre Chainais"], "title": "A Distributed Plug-and-Play MCMC Algorithm for High-Dimensional Inverse Problems", "categories": ["stat.ME", "cs.DC", "eess.SP"], "comment": null, "summary": "Markov Chain Monte Carlo (MCMC) algorithms are standard approaches to solve\nimaging inverse problems and quantify estimation uncertainties, a key\nrequirement in absence of ground-truth data. To improve estimation quality,\nPlug-and-Play MCMC algorithms, such as PnP-ULA, have been recently developed to\naccommodate priors encoded by a denoising neural network. Designing scalable\nsamplers for high-dimensional imaging inverse problems remains a challenge:\ndrawing and storing high-dimensional samples can be prohibitive, especially for\nhigh-resolution images. To address this issue, this work proposes a distributed\nsampler based on approximate data augmentation and PnP-ULA to solve very large\nproblems. The proposed sampler uses lightweight denoising convolutional neural\nnetwork, to efficiently exploit multiple GPUs on a Single Program Multiple Data\narchitecture. Reconstruction performance and scalability are evaluated on\nseveral imaging problems. Communication and computation overheads due to the\ndenoiser are carefully discussed. The proposed distributed approach noticeably\ncombines three very precious qualities: it is scalable, enables uncertainty\nquantification, for a reconstruction performance comparable to other PnP\nmethods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8fd1\u4f3c\u6570\u636e\u589e\u5f3a\u548cPnP - ULA\u7684\u5206\u5e03\u5f0f\u91c7\u6837\u5668\u89e3\u51b3\u9ad8\u7ef4\u6210\u50cf\u9006\u95ee\u9898\uff0c\u8bc4\u4f30\u5176\u6027\u80fd\u5e76\u8ba8\u8bba\u5f00\u9500\uff0c\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u3001\u80fd\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u4e14\u91cd\u5efa\u6027\u80fd\u826f\u597d\u3002", "motivation": "\u73b0\u6709MCMC\u7b97\u6cd5\u5728\u89e3\u51b3\u9ad8\u7ef4\u6210\u50cf\u9006\u95ee\u9898\u65f6\uff0c\u7ed8\u5236\u548c\u5b58\u50a8\u9ad8\u7ef4\u6837\u672c\u6210\u672c\u9ad8\uff0c\u8bbe\u8ba1\u53ef\u6269\u5c55\u91c7\u6837\u5668\u662f\u6311\u6218\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fd1\u4f3c\u6570\u636e\u589e\u5f3a\u548cPnP - ULA\u7684\u5206\u5e03\u5f0f\u91c7\u6837\u5668\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u53bb\u566a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u5355\u7a0b\u5e8f\u591a\u6570\u636e\u67b6\u6784\u4e0a\u5229\u7528\u591a\u4e2aGPU\u3002", "result": "\u5728\u591a\u4e2a\u6210\u50cf\u95ee\u9898\u4e0a\u8bc4\u4f30\u4e86\u91cd\u5efa\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4ed4\u7ec6\u8ba8\u8bba\u4e86\u53bb\u566a\u5668\u5e26\u6765\u7684\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u80fd\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u91cd\u5efa\u6027\u80fd\u4e0e\u5176\u4ed6PnP\u65b9\u6cd5\u76f8\u5f53\u3002"}}
{"id": "2511.00268", "pdf": "https://arxiv.org/pdf/2511.00268", "abs": "https://arxiv.org/abs/2511.00268", "authors": ["Shounak Paul", "Dhananjay Ghumare", "Pawan Goyal", "Saptarshi Ghosh", "Ashutosh Modi"], "title": "IL-PCSR: Legal Corpus for Prior Case and Statute Retrieval", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "comment": "Accepted at EMNLP 2025 (Main)", "summary": "Identifying/retrieving relevant statutes and prior cases/precedents for a\ngiven legal situation are common tasks exercised by law practitioners.\nResearchers to date have addressed the two tasks independently, thus developing\ncompletely different datasets and models for each task; however, both retrieval\ntasks are inherently related, e.g., similar cases tend to cite similar statutes\n(due to similar factual situation). In this paper, we address this gap. We\npropose IL-PCR (Indian Legal corpus for Prior Case and Statute Retrieval),\nwhich is a unique corpus that provides a common testbed for developing models\nfor both the tasks (Statute Retrieval and Precedent Retrieval) that can exploit\nthe dependence between the two. We experiment extensively with several baseline\nmodels on the tasks, including lexical models, semantic models and ensemble\nbased on GNNs. Further, to exploit the dependence between the two tasks, we\ndevelop an LLM-based re-ranking approach that gives the best performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIL - PCR\u8bed\u6599\u5e93\uff0c\u4e3a\u6cd5\u89c4\u548c\u5148\u4f8b\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u901a\u7528\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5b9e\u9a8c\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u5e76\u5f00\u53d1\u57fa\u4e8eLLM\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u83b7\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5c06\u6cd5\u89c4\u68c0\u7d22\u548c\u5148\u4f8b\u68c0\u7d22\u4efb\u52a1\u72ec\u7acb\u5904\u7406\uff0c\u800c\u4e8c\u8005\u5b58\u5728\u5185\u5728\u5173\u8054\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51faIL - PCR\u8bed\u6599\u5e93\uff0c\u5bf9\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\uff08\u8bcd\u6c47\u6a21\u578b\u3001\u8bed\u4e49\u6a21\u578b\u548c\u57fa\u4e8eGNN\u7684\u96c6\u6210\u6a21\u578b\uff09\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5f00\u53d1\u57fa\u4e8eLLM\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u3002", "result": "\u57fa\u4e8eLLM\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u5728\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "IL - PCR\u8bed\u6599\u5e93\u53ef\u4f5c\u4e3a\u901a\u7528\u6d4b\u8bd5\u5e73\u53f0\uff0c\u57fa\u4e8eLLM\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528\u4e24\u4e2a\u4efb\u52a1\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2511.00609", "pdf": "https://arxiv.org/pdf/2511.00609", "abs": "https://arxiv.org/abs/2511.00609", "authors": ["Shengqi Xu", "Xinpeng Zhou", "Yabo Zhang", "Ming Liu", "Tao Liang", "Tianyu Zhang", "Yalong Bai", "Zuxuan Wu", "Wangmeng Zuo"], "title": "PreferThinker: Reasoning-based Personalized Image Preference Assessment", "categories": ["cs.AI"], "comment": null, "summary": "Personalized image preference assessment aims to evaluate an individual\nuser's image preferences by relying only on a small set of reference images as\nprior information. Existing methods mainly focus on general preference\nassessment, training models with large-scale data to tackle well-defined tasks\nsuch as text-image alignment. However, these approaches struggle to handle\npersonalized preference because user-specific data are scarce and not easily\nscalable, and individual tastes are often diverse and complex. To overcome\nthese challenges, we introduce a common preference profile that serves as a\nbridge across users, allowing large-scale user data to be leveraged for\ntraining profile prediction and capturing complex personalized preferences.\nBuilding on this idea, we propose a reasoning-based personalized image\npreference assessment framework that follows a \\textit{predict-then-assess}\nparadigm: it first predicts a user's preference profile from reference images,\nand then provides interpretable, multi-dimensional scores and assessments of\ncandidate images based on the predicted profile. To support this, we first\nconstruct a large-scale Chain-of-Thought (CoT)-style personalized assessment\ndataset annotated with diverse user preference profiles and high-quality\nCoT-style reasoning, enabling explicit supervision of structured reasoning.\nNext, we adopt a two-stage training strategy: a cold-start supervised\nfine-tuning phase to empower the model with structured reasoning capabilities,\nfollowed by reinforcement learning to incentivize the model to explore more\nreasonable assessment paths and enhance generalization. Furthermore, we propose\na similarity-aware prediction reward to encourage better prediction of the\nuser's preference profile, which facilitates more reasonable assessments\nexploration. Extensive experiments demonstrate the superiority of the proposed\nmethod.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u63a8\u7406\u7684\u4e2a\u6027\u5316\u56fe\u50cf\u504f\u597d\u8bc4\u4f30\u6846\u67b6\uff0c\u6784\u5efa\u6570\u636e\u96c6\u3001\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u53ca\u76f8\u4f3c\u5ea6\u611f\u77e5\u9884\u6d4b\u5956\u52b1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u4e2a\u6027\u5316\u56fe\u50cf\u504f\u597d\u8bc4\u4f30\uff0c\u56e0\u7528\u6237\u7279\u5b9a\u6570\u636e\u7a00\u7f3a\u3001\u4e0d\u53ef\u6269\u5c55\u4e14\u4e2a\u4eba\u54c1\u5473\u591a\u6837\u590d\u6742\u3002", "method": "\u5f15\u5165\u901a\u7528\u504f\u597d\u7b80\u6863\uff0c\u63d0\u51fa\u57fa\u4e8e\u63a8\u7406\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u9075\u5faa\u201c\u9884\u6d4b - \u8bc4\u4f30\u201d\u8303\u5f0f\uff1b\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1b\u63d0\u51fa\u76f8\u4f3c\u5ea6\u611f\u77e5\u9884\u6d4b\u5956\u52b1\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u7684\u57fa\u4e8e\u63a8\u7406\u7684\u4e2a\u6027\u5316\u56fe\u50cf\u504f\u597d\u8bc4\u4f30\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u4e2a\u6027\u5316\u8bc4\u4f30\u65b9\u9762\u7684\u95ee\u9898\u3002"}}
{"id": "2511.00678", "pdf": "https://arxiv.org/pdf/2511.00678", "abs": "https://arxiv.org/abs/2511.00678", "authors": ["Tasmia Zerin", "Moumita Asad", "B. M. Mainul Hossain", "Kazi Sakib"], "title": "Repairing Responsive Layout Failures Using Retrieval Augmented Generation", "categories": ["cs.SE"], "comment": "Accepted at the 41st IEEE International Conference on Software\n  Maintenance and Evolution 2025 (ICSME'25)", "summary": "Responsive websites frequently experience distorted layouts at specific\nscreen sizes, called Responsive Layout Failures (RLFs). Manually repairing\nthese RLFs involves tedious trial-and-error adjustments of HTML elements and\nCSS properties. In this study, an automated repair approach, leveraging LLM\ncombined with domain-specific knowledge is proposed. The approach is named\nReDeFix, a Retrieval-Augmented Generation (RAG)-based solution that utilizes\nStack Overflow (SO) discussions to guide LLM on CSS repairs. By augmenting\nrelevant SO knowledge with RLF-specific contexts, ReDeFix creates a prompt that\nis sent to the LLM to generate CSS patches. Evaluation demonstrates that our\napproach achieves an 88\\% accuracy in repairing RLFs. Furthermore, a study from\nsoftware engineers reveals that generated repairs produce visually correct\nlayouts while maintaining aesthetics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u548c\u9886\u57df\u77e5\u8bc6\u7684\u81ea\u52a8\u5316\u4fee\u590d\u65b9\u6cd5ReDeFix\u6765\u89e3\u51b3\u54cd\u5e94\u5f0f\u5e03\u5c40\u5931\u8d25\u95ee\u9898\uff0c\u51c6\u786e\u7387\u8fbe88%\uff0c\u4fee\u590d\u65b9\u6848\u83b7\u5de5\u7a0b\u5e08\u8ba4\u53ef\u3002", "motivation": "\u54cd\u5e94\u5f0f\u7f51\u7ad9\u5728\u7279\u5b9a\u5c4f\u5e55\u5c3a\u5bf8\u4e0b\u5b58\u5728\u5e03\u5c40\u5931\u771f\u95ee\u9898\uff0c\u624b\u52a8\u4fee\u590d\u7e41\u7410\uff0c\u9700\u8981\u81ea\u52a8\u5316\u4fee\u590d\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684ReDeFix\u65b9\u6cd5\uff0c\u5229\u7528Stack Overflow\u8ba8\u8bba\u5f15\u5bfcLLM\u8fdb\u884cCSS\u4fee\u590d\uff0c\u7ed3\u5408\u76f8\u5173\u77e5\u8bc6\u548c\u7279\u5b9a\u4e0a\u4e0b\u6587\u521b\u5efa\u63d0\u793a\u751f\u6210CSS\u8865\u4e01\u3002", "result": "\u8be5\u65b9\u6cd5\u4fee\u590d\u54cd\u5e94\u5f0f\u5e03\u5c40\u5931\u8d25\u95ee\u9898\u7684\u51c6\u786e\u7387\u8fbe88%\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8ba4\u4e3a\u751f\u6210\u7684\u4fee\u590d\u65b9\u6848\u89c6\u89c9\u5e03\u5c40\u6b63\u786e\u4e14\u7f8e\u89c2\u3002", "conclusion": "\u57fa\u4e8eLLM\u548c\u9886\u57df\u77e5\u8bc6\u7684\u81ea\u52a8\u5316\u4fee\u590d\u65b9\u6cd5ReDeFix\u80fd\u6709\u6548\u89e3\u51b3\u54cd\u5e94\u5f0f\u5e03\u5c40\u5931\u8d25\u95ee\u9898\u3002"}}
{"id": "2511.00059", "pdf": "https://arxiv.org/pdf/2511.00059", "abs": "https://arxiv.org/abs/2511.00059", "authors": ["Aditya Singh", "Zihang Wen", "Srujananjali Medicherla", "Adam Karvonen", "Can Rager"], "title": "Automatically Finding Rule-Based Neurons in OthelloGPT", "categories": ["cs.LG", "cs.AI"], "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop Mechanistic interpretability", "summary": "OthelloGPT, a transformer trained to predict valid moves in Othello, provides\nan ideal testbed for interpretability research. The model is complex enough to\nexhibit rich computational patterns, yet grounded in rule-based game logic that\nenables meaningful reverse-engineering. We present an automated approach based\non decision trees to identify and interpret MLP neurons that encode rule-based\ngame logic. Our method trains regression decision trees to map board states to\nneuron activations, then extracts decision paths where neurons are highly\nactive to convert them into human-readable logical forms. These descriptions\nreveal highly interpretable patterns; for instance, neurons that specifically\ndetect when diagonal moves become legal. Our findings suggest that roughly half\nof the neurons in layer 5 can be accurately described by compact, rule-based\ndecision trees ($R^2 > 0.7$ for 913 of 2,048 neurons), while the remainder\nlikely participate in more distributed or non-rule-based computations. We\nverify the causal relevance of patterns identified by our decision trees\nthrough targeted interventions. For a specific square, for specific game\npatterns, we ablate neurons corresponding to those patterns and find an\napproximately 5-10 fold stronger degradation in the model's ability to predict\nlegal moves along those patterns compared to control patterns. To facilitate\nfuture work, we provide a Python tool that maps rule-based game behaviors to\ntheir implementing neurons, serving as a resource for researchers to test\nwhether their interpretability methods recover meaningful computational\nstructures.", "AI": {"tldr": "\u4f7f\u7528\u51b3\u7b56\u6811\u65b9\u6cd5\u5206\u6790OthelloGPT\u4e2d\u7f16\u7801\u6e38\u620f\u89c4\u5219\u903b\u8f91\u7684MLP\u795e\u7ecf\u5143\uff0c\u53d1\u73b0\u7ea6\u4e00\u534a\u795e\u7ecf\u5143\u53ef\u88ab\u89c4\u5219\u51b3\u7b56\u6811\u51c6\u786e\u63cf\u8ff0\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6a21\u5f0f\u7684\u56e0\u679c\u76f8\u5173\u6027\uff0c\u8fd8\u63d0\u4f9bPython\u5de5\u5177\u3002", "motivation": "OthelloGPT\u4e3a\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u7406\u60f3\u6d4b\u8bd5\u5e73\u53f0\uff0c\u9700\u4e00\u79cd\u65b9\u6cd5\u8bc6\u522b\u548c\u89e3\u91ca\u7f16\u7801\u89c4\u5219\u903b\u8f91\u7684MLP\u795e\u7ecf\u5143\u3002", "method": "\u8bad\u7ec3\u56de\u5f52\u51b3\u7b56\u6811\u5c06\u68cb\u76d8\u72b6\u6001\u6620\u5c04\u5230\u795e\u7ecf\u5143\u6fc0\u6d3b\uff0c\u63d0\u53d6\u795e\u7ecf\u5143\u9ad8\u6fc0\u6d3b\u7684\u51b3\u7b56\u8def\u5f84\u8f6c\u6362\u4e3a\u53ef\u8bfb\u903b\u8f91\u5f62\u5f0f\u3002", "result": "\u7ea6\u4e00\u534a\u7b2c5\u5c42\u795e\u7ecf\u5143\u53ef\u88ab\u7d27\u51d1\u89c4\u5219\u51b3\u7b56\u6811\u51c6\u786e\u63cf\u8ff0\uff0c\u901a\u8fc7\u5e72\u9884\u9a8c\u8bc1\u4e86\u51b3\u7b56\u6811\u8bc6\u522b\u6a21\u5f0f\u7684\u56e0\u679c\u76f8\u5173\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u4e3a\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9bPython\u5de5\u5177\uff0c\u4fbf\u4e8e\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2511.00257", "pdf": "https://arxiv.org/pdf/2511.00257", "abs": "https://arxiv.org/abs/2511.00257", "authors": ["Zachary Chase", "Shinji Ito", "Idan Mehalel"], "title": "A Tight Lower Bound for Non-stochastic Multi-armed Bandits with Expert Advice", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We determine the minimax optimal expected regret in the classic\nnon-stochastic multi-armed bandit with expert advice problem, by proving a\nlower bound that matches the upper bound of Kale (2014). The two bounds\ndetermine the minimax optimal expected regret to be $\\Theta\\left( \\sqrt{T K\n\\log (N/K) } \\right)$, where $K$ is the number of arms, $N$ is the number of\nexperts, and $T$ is the time horizon.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.01129", "pdf": "https://arxiv.org/pdf/2511.01129", "abs": "https://arxiv.org/abs/2511.01129", "authors": ["Fabio Diniz Rossi"], "title": "Boosting performance of computer vision applications through embedded GPUs on the edge", "categories": ["cs.CV", "cs.DC"], "comment": "4 pages, 6 figures", "summary": "Computer vision applications, especially those using augmented reality\ntechnology, are becoming quite popular in mobile devices. However, this type of\napplication is known as presenting significant demands regarding resources. In\norder to enable its utilization in devices with more modest resources, edge\ncomputing can be used to offload certain high intensive tasks. Still, edge\ncomputing is usually composed of devices with limited capacity, which may\nimpact in users quality of experience when using computer vision applications.\nThis work proposes the use of embedded devices with graphics processing units\n(GPUs) to overcome such limitation. Experiments performed shown that GPUs can\nattain a performance gain when compared to using only CPUs, which guarantee a\nbetter experience to users using such kind of application.", "AI": {"tldr": "\u4e3a\u4f7f\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u5728\u8d44\u6e90\u6709\u9650\u8bbe\u5907\u4e0a\u8fd0\u884c\uff0c\u63d0\u51fa\u7528\u5e26GPU\u7684\u5d4c\u5165\u5f0f\u8bbe\u5907\uff0c\u5b9e\u9a8c\u8868\u660eGPU\u6bd4\u4ec5\u7528CPU\u6709\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u8fb9\u7f18\u8ba1\u7b97\u8bbe\u5907\u5bb9\u91cf\u6709\u9650\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\uff0c\u9700\u89e3\u51b3\u5728\u8d44\u6e90\u6709\u9650\u8bbe\u5907\u4e0a\u7684\u4f7f\u7528\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5e26\u6709\u56fe\u5f62\u5904\u7406\u5355\u5143\uff08GPUs\uff09\u7684\u5d4c\u5165\u5f0f\u8bbe\u5907\u6765\u5378\u8f7d\u9ad8\u5bc6\u96c6\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4ec5\u4f7f\u7528CPU\u76f8\u6bd4\uff0cGPU\u80fd\u83b7\u5f97\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u4f7f\u7528\u5e26GPU\u7684\u5d4c\u5165\u5f0f\u8bbe\u5907\u53ef\u514b\u670d\u8fb9\u7f18\u8ba1\u7b97\u8bbe\u5907\u5bb9\u91cf\u9650\u5236\uff0c\u4fdd\u8bc1\u7528\u6237\u66f4\u597d\u4f53\u9a8c\u3002"}}
{"id": "2511.00375", "pdf": "https://arxiv.org/pdf/2511.00375", "abs": "https://arxiv.org/abs/2511.00375", "authors": ["Xin Wang", "Yunhao Xiao", "Rui Qiao"], "title": "PolyRecommender: A Multimodal Recommendation System for Polymer Discovery", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "We introduce PolyRecommender, a multimodal discovery framework that\nintegrates chemical language representations from PolyBERT with molecular\ngraph-based representations from a graph encoder. The system first retrieves\ncandidate polymers using language-based similarity and then ranks them using\nfused multimodal embeddings according to multiple target properties. By\nleveraging the complementary knowledge encoded in both modalities,\nPolyRecommender enables efficient retrieval and robust ranking across related\npolymer properties. Our work establishes a generalizable multimodal paradigm,\nadvancing AI-guided design for the discovery of next-generation polymers.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u591a\u6a21\u6001\u53d1\u73b0\u6846\u67b6PolyRecommender\uff0c\u7ed3\u5408\u4e24\u79cd\u8868\u793a\u8fdb\u884c\u805a\u5408\u7269\u68c0\u7d22\u548c\u6392\u5e8f\uff0c\u63a8\u52a8\u4e0b\u4e00\u4ee3\u805a\u5408\u7269\u53d1\u73b0\u3002", "motivation": "\u4e3a\u4e0b\u4e00\u4ee3\u805a\u5408\u7269\u53d1\u73b0\u63d0\u4f9bAI\u5f15\u5bfc\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u5c06PolyBERT\u7684\u5316\u5b66\u8bed\u8a00\u8868\u793a\u4e0e\u56fe\u7f16\u7801\u5668\u7684\u5206\u5b50\u56fe\u8868\u793a\u96c6\u6210\uff0c\u5148\u57fa\u4e8e\u8bed\u8a00\u76f8\u4f3c\u5ea6\u68c0\u7d22\u5019\u9009\u805a\u5408\u7269\uff0c\u518d\u7528\u878d\u5408\u7684\u591a\u6a21\u6001\u5d4c\u5165\u5bf9\u5176\u6309\u591a\u76ee\u6807\u5c5e\u6027\u6392\u5e8f\u3002", "result": "PolyRecommender\u5b9e\u73b0\u4e86\u76f8\u5173\u805a\u5408\u7269\u5c5e\u6027\u7684\u9ad8\u6548\u68c0\u7d22\u548c\u7a33\u5065\u6392\u5e8f\u3002", "conclusion": "\u5efa\u7acb\u4e86\u53ef\u6cdb\u5316\u7684\u591a\u6a21\u6001\u8303\u5f0f\uff0c\u63a8\u52a8\u4e86AI\u5f15\u5bfc\u7684\u4e0b\u4e00\u4ee3\u805a\u5408\u7269\u53d1\u73b0\u3002"}}
{"id": "2511.00640", "pdf": "https://arxiv.org/pdf/2511.00640", "abs": "https://arxiv.org/abs/2511.00640", "authors": ["Zicheng Xu", "Guanchu Wang", "Yu-Neng Chuang", "Guangyao Zheng", "Alexander S. Szalay", "Zirui Liu", "Vladimir Braverman"], "title": "DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Reasoning Models (LRMs) demonstrate strong performance on complex\nreasoning tasks, yet they often suffer from overthinking, producing excessively\nlong chain-of-thought (CoT) traces that increase inference cost and may degrade\naccuracy. Our analysis reveals a clear anti-correlation between reasoning\nlength and accuracy, where across multiple stochastic decodes, the short\nreasoning paths consistently achieve the highest correctness, while longer ones\naccumulate errors and repetitions. These short optimal reasoning paths can be\nfound ideally through full enumeration of the reasoning space. However, the\ntree-structured reasoning space grows exponentially with sequence length,\nrendering exhaustive exploration infeasible. To address this, we propose DTS, a\nmodel-agnostic decoding framework that sketches the reasoning space by\nselectively branching at high-entropy tokens and applies early stopping to\nselect the shortest completed reasoning path. This approach approximates the\noptimal solution that enhances both efficiency and accuracy, without requiring\nadditional training or supervision. Experiments on AIME2024 and AIME2025\ndatasets with DeepSeek-R1-Distill-Qwen-7B and 1.5B show that DTS improves\naccuracy by up to 8%, reduces average reasoning length by 23%, and decreases\nrepetition frequency by 12%, demonstrating DTS's ability for scalable and\nefficient LRM reasoning.", "AI": {"tldr": "\u5927\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faDTS\u89e3\u7801\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u51c6\u786e\u7387\u3001\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\u548c\u91cd\u590d\u9891\u7387\u3002", "motivation": "\u5927\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u63a8\u7406\u957f\u5ea6\u4e0e\u51c6\u786e\u7387\u5448\u8d1f\u76f8\u5173\uff0c\u4e14\u7a77\u4e3e\u63a8\u7406\u7a7a\u95f4\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51faDTS\u6a21\u578b\u65e0\u5173\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u9ad8\u71b5\u6807\u8bb0\u5904\u9009\u62e9\u6027\u5206\u652f\u52fe\u52d2\u63a8\u7406\u7a7a\u95f4\uff0c\u5e76\u5e94\u7528\u65e9\u505c\u7b56\u7565\u9009\u62e9\u6700\u77ed\u5b8c\u6574\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728AIME2024\u548cAIME2025\u6570\u636e\u96c6\u4e0a\uff0cDTS\u4f7f\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u53478%\uff0c\u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c1123%\uff0c\u91cd\u590d\u9891\u7387\u964d\u4f4e12%\u3002", "conclusion": "DTS\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u5927\u63a8\u7406\u6a21\u578b\u63a8\u7406\u3002"}}
{"id": "2511.00706", "pdf": "https://arxiv.org/pdf/2511.00706", "abs": "https://arxiv.org/abs/2511.00706", "authors": ["Marcos Vinicius Cruz", "Pragya Verma", "Grischa Liebel"], "title": "An Empirical Investigation of the Experiences of Dyslexic Software Engineers", "categories": ["cs.SE"], "comment": null, "summary": "Dyslexia is a common learning disorder that primarily impairs an individual's\nreading and writing abilities. In adults, dyslexia can affect both professional\nand personal lives, often leading to mental challenges and difficulties\nacquiring and keeping work. In Software Engineering (SE), reading and writing\ndifficulties appear to pose substantial challenges for core tasks such as\nprogramming. However, initial studies indicate that these challenges may not\nsignificantly affect their performance compared to non-dyslexic colleagues.\nConversely, strengths associated with dyslexia could be particularly valuable\nin areas like programming and design. However, there is currently no work that\nexplores the experiences of dyslexic software engineers, and puts their\nstrengths into relation with their difficulties. To address this, we present a\nqualitative study of the experiences of dyslexic individuals in SE. We followed\nthe basic stage of the Socio-Technical Grounded Theory method and base our\nfindings on data collected through 10 interviews with dyslexic software\nengineers, 3 blog posts and 153 posts on the social media platform Reddit. We\nfind that dyslexic software engineers especially struggle at the programming\nlearning stage, but can succeed and indeed excel at many SE tasks once they\nmaster this step. Common SE-specific support tools, such as code completion and\nlinters are especially useful to these individuals and mitigate many of the\nexperienced difficulties. Finally, dyslexic software engineers exhibit\nstrengths in areas such as visual thinking and creativity. Our findings have\nimplications to SE practice and motivate several areas of future research in\nSE, such as investigating what makes code less/more understandable to dyslexic\nindividuals.", "AI": {"tldr": "\u672c\u6587\u5bf9\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u7ecf\u5386\u8fdb\u884c\u5b9a\u6027\u7814\u7a76\uff0c\u53d1\u73b0\u4ed6\u4eec\u7f16\u7a0b\u5b66\u4e60\u9636\u6bb5\u6709\u56f0\u96be\uff0c\u638c\u63e1\u540e\u80fd\u80dc\u4efb\u5de5\u4f5c\uff0c\u7279\u5b9a\u5de5\u5177\u53ef\u7f13\u89e3\u56f0\u96be\uff0c\u4e14\u5728\u89c6\u89c9\u601d\u7ef4\u548c\u521b\u9020\u529b\u65b9\u9762\u6709\u4f18\u52bf\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u5bf9\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7ecf\u5386\u7684\u7814\u7a76\uff0c\u4e5f\u672a\u5c06\u5176\u4f18\u52bf\u4e0e\u56f0\u96be\u5173\u8054\u8d77\u6765\uff0c\u56e0\u6b64\u5f00\u5c55\u6b64\u9879\u7814\u7a76\u3002", "method": "\u91c7\u7528\u793e\u4f1a\u6280\u672f\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf910\u540d\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u8bbf\u8c08\u30013\u7bc7\u535a\u5ba2\u6587\u7ae0\u548cReddit\u4e0a\u7684153\u7bc7\u5e16\u5b50\u6536\u96c6\u6570\u636e\u3002", "result": "\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u7f16\u7a0b\u5b66\u4e60\u9636\u6bb5\u56f0\u96be\u5927\uff0c\u638c\u63e1\u540e\u80fd\u80dc\u4efb\u5e76\u64c5\u957f\u8bb8\u591a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff1b\u5e38\u89c1\u8f6f\u4ef6\u5de5\u7a0b\u652f\u6301\u5de5\u5177\u53ef\u7f13\u89e3\u56f0\u96be\uff1b\u4ed6\u4eec\u5728\u89c6\u89c9\u601d\u7ef4\u548c\u521b\u9020\u529b\u65b9\u9762\u6709\u4f18\u52bf\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u6709\u542f\u793a\uff0c\u4e5f\u4e3a\u672a\u6765\u7814\u7a76\u5982\u63a2\u7a76\u4ee3\u7801\u5bf9\u9605\u8bfb\u969c\u788d\u8005\u7684\u6613\u8bfb\u6027\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2511.00064", "pdf": "https://arxiv.org/pdf/2511.00064", "abs": "https://arxiv.org/abs/2511.00064", "authors": ["Randolph Wiredu-Aidoo"], "title": "EVINGCA: Adaptive Graph Clustering with Evolving Neighborhood Statistics", "categories": ["cs.LG"], "comment": null, "summary": "Clustering algorithms often rely on restrictive assumptions: K-Means and\nGaussian Mixtures presuppose convex, Gaussian-like clusters, while DBSCAN and\nHDBSCAN capture non-convexity but can be highly sensitive. I introduce EVINGCA\n(Evolving Variance-Informed Nonparametric Graph Construction Algorithm), a\ndensity-variance based clustering algorithm that treats cluster formation as an\nadaptive, evolving process on a nearest-neighbor graph. EVINGCA expands rooted\ngraphs via breadth-first search, guided by continuously updated local distance\nand shape statistics, replacing fixed density thresholds with local statistical\nfeedback. With spatial indexing, EVINGCA features log-linear complexity in the\naverage case and exhibits competitive performance against baselines across a\nvariety of synthetic, real-world, low-d, and high-d datasets.", "AI": {"tldr": "\u63d0\u51fa\u5bc6\u5ea6 - \u65b9\u5dee\u805a\u7c7b\u7b97\u6cd5 EVINGCA\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u805a\u7c7b\u7b97\u6cd5\u5b58\u5728\u5047\u8bbe\u9650\u5236\uff0c\u5982 K - Means \u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u9884\u8bbe\u51f8\u3001\u7c7b\u9ad8\u65af\u7c07\uff0cDBSCAN \u548c HDBSCAN \u654f\u611f\u3002", "method": "\u5c06\u7c07\u5f62\u6210\u89c6\u4e3a\u6700\u8fd1\u90bb\u56fe\u4e0a\u7684\u81ea\u9002\u5e94\u3001\u6f14\u5316\u8fc7\u7a0b\uff0c\u901a\u8fc7\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u6269\u5c55\u6839\u56fe\uff0c\u7528\u5c40\u90e8\u7edf\u8ba1\u53cd\u9988\u66ff\u4ee3\u56fa\u5b9a\u5bc6\u5ea6\u9608\u503c\uff0c\u7ed3\u5408\u7a7a\u95f4\u7d22\u5f15\u3002", "result": "\u5e73\u5747\u60c5\u51b5\u4e0b\u5177\u6709\u5bf9\u6570\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u5728\u591a\u79cd\u5408\u6210\u548c\u771f\u5b9e\u3001\u4f4e\u7ef4\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u4e0e\u57fa\u7ebf\u76f8\u6bd4\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "EVINGCA \u662f\u4e00\u79cd\u6709\u6548\u7684\u805a\u7c7b\u7b97\u6cd5\uff0c\u80fd\u514b\u670d\u73b0\u6709\u7b97\u6cd5\u7684\u4e00\u4e9b\u5c40\u9650\u6027\u3002"}}
{"id": "2511.00318", "pdf": "https://arxiv.org/pdf/2511.00318", "abs": "https://arxiv.org/abs/2511.00318", "authors": ["Dana Kim", "Yichen Xu", "Tiffany Lin"], "title": "A Technical Exploration of Causal Inference with Hybrid LLM Synthetic Data", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "9 pages, 4 figures", "summary": "Large Language Models (LLMs) offer a flexible means to generate synthetic\ntabular data, yet existing approaches often fail to preserve key causal\nparameters such as the average treatment effect (ATE). In this technical\nexploration, we first demonstrate that state-of-the-art synthetic data\ngenerators, both GAN- and LLM-based, can achieve high predictive fidelity while\nsubstantially misestimating causal effects. To address this gap, we propose a\nhybrid generation framework that combines model-based covariate synthesis\n(monitored via distance-to-closest-record filtering) with separately learned\npropensity and outcome models, thereby ensuring that (W, A, Y) triplets retain\ntheir underlying causal structure. We further introduce a synthetic pairing\nstrategy to mitigate positivity violations and a realistic evaluation protocol\nthat leverages unlimited synthetic samples to benchmark traditional estimators\n(IPTW, AIPW, substitution) under complex covariate distributions. This work\nlays the groundwork for LLM-powered data pipelines that support robust causal\nanalysis. Our code is available at\nhttps://github.com/Xyc-arch/llm-synthetic-for-causal-inference.git.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5408\u6210\u8868\u683c\u6570\u636e\u65b9\u6cd5\u96be\u4ee5\u4fdd\u7559\u5173\u952e\u56e0\u679c\u53c2\u6570\uff0c\u672c\u6587\u63d0\u51fa\u6df7\u5408\u751f\u6210\u6846\u67b6\u53ca\u5408\u6210\u914d\u5bf9\u7b56\u7565\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u652f\u6301\u7a33\u5065\u56e0\u679c\u5206\u6790\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5408\u6210\u8868\u683c\u6570\u636e\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u7559\u5173\u952e\u56e0\u679c\u53c2\u6570\uff0c\u5982\u5e73\u5747\u5904\u7406\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u6a21\u578b\u7684\u534f\u53d8\u91cf\u5408\u6210\u4e0e\u5206\u522b\u5b66\u4e60\u7684\u503e\u5411\u548c\u7ed3\u679c\u6a21\u578b\uff1b\u5f15\u5165\u5408\u6210\u914d\u5bf9\u7b56\u7565\u51cf\u8f7b\u6b63\u6027\u8fdd\u53cd\uff1b\u63d0\u51fa\u5229\u7528\u65e0\u9650\u5408\u6210\u6837\u672c\u7684\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u5c55\u793a\u4e86\u73b0\u6709\u5408\u6210\u6570\u636e\u751f\u6210\u5668\u867d\u6709\u9ad8\u9884\u6d4b\u4fdd\u771f\u5ea6\u4f46\u4f1a\u4e25\u91cd\u8bef\u4f30\u56e0\u679c\u6548\u5e94\uff0c\u6240\u63d0\u65b9\u6cd5\u4e3a\u652f\u6301\u7a33\u5065\u56e0\u679c\u5206\u6790\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6570\u636e\u7ba1\u9053\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u6240\u63d0\u5de5\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u6570\u636e\u7ba1\u9053\u652f\u6301\u7a33\u5065\u56e0\u679c\u5206\u6790\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00651", "pdf": "https://arxiv.org/pdf/2511.00651", "abs": "https://arxiv.org/abs/2511.00651", "authors": ["Chenhua Shi", "Bhavika Jalli", "Gregor Macdonald", "John Zou", "Wanlu Lei", "Mridul Jain", "Joji Philip"], "title": "Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting", "categories": ["cs.AI", "cs.CL", "cs.IT", "cs.MA", "cs.NI", "math.IT"], "comment": "6 pages, 7 figures, 1 table", "summary": "Telecom networks are rapidly growing in scale and complexity, making\neffective management, operation, and optimization increasingly challenging.\nAlthough Artificial Intelligence (AI) has been applied to many telecom tasks,\nexisting models are often narrow in scope, require large amounts of labeled\ndata, and struggle to generalize across heterogeneous deployments.\nConsequently, network troubleshooting continues to rely heavily on Subject\nMatter Experts (SMEs) to manually correlate various data sources to identify\nroot causes and corrective actions. To address these limitations, we propose a\nMulti-Agent System (MAS) that employs an agentic workflow, with Large Language\nModels (LLMs) coordinating multiple specialized tools for fully automated\nnetwork troubleshooting. Once faults are detected by AI/ML-based monitors, the\nframework dynamically activates agents such as an orchestrator, solution\nplanner, executor, data retriever, and root-cause analyzer to diagnose issues\nand recommend remediation strategies within a short time frame. A key component\nof this system is the solution planner, which generates appropriate remediation\nplans based on internal documentation. To enable this, we fine-tuned a Small\nLanguage Model (SLM) on proprietary troubleshooting documents to produce\ndomain-grounded solution plans. Experimental results demonstrate that the\nproposed framework significantly accelerates troubleshooting automation across\nboth Radio Access Network (RAN) and Core network domains.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u7528\u4e8e\u7535\u4fe1\u7f51\u7edc\u6545\u969c\u6392\u9664\u81ea\u52a8\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ef\u663e\u8457\u52a0\u901f\u6545\u969c\u6392\u9664\u3002", "motivation": "\u7535\u4fe1\u7f51\u7edc\u89c4\u6a21\u548c\u590d\u6742\u6027\u589e\u957f\uff0c\u73b0\u6709AI\u6a21\u578b\u6709\u5c40\u9650\u6027\uff0c\u7f51\u7edc\u6545\u969c\u6392\u9664\u4f9d\u8d56\u4e13\u5bb6\u624b\u52a8\u64cd\u4f5c\u3002", "method": "\u63d0\u51fa\u91c7\u7528\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684MAS\uff0c\u7531\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u534f\u8c03\u591a\u4e2a\u4e13\u4e1a\u5de5\u5177\uff0c\u6545\u969c\u68c0\u6d4b\u540e\u52a8\u6001\u6fc0\u6d3b\u591a\u4e2a\u667a\u80fd\u4f53\uff0c\u7528\u5fae\u8c03\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u751f\u6210\u4fee\u590d\u8ba1\u5212\u3002", "result": "\u8be5\u6846\u67b6\u5728\u65e0\u7ebf\u63a5\u5165\u7f51\uff08RAN\uff09\u548c\u6838\u5fc3\u7f51\u9886\u57df\u663e\u8457\u52a0\u901f\u6545\u969c\u6392\u9664\u81ea\u52a8\u5316\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u7535\u4fe1\u7f51\u7edc\u6545\u969c\u6392\u9664\u95ee\u9898\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u52a0\u901f\u3002"}}
{"id": "2511.00776", "pdf": "https://arxiv.org/pdf/2511.00776", "abs": "https://arxiv.org/abs/2511.00776", "authors": ["Cuiyun Gao", "Guodong Fan", "Chun Yong Chong", "Shizhan Chen", "Chao Liu", "David Lo", "Zibin Zheng", "Qing Liao"], "title": "A Systematic Literature Review of Code Hallucinations in LLMs: Characterization, Mitigation Methods, Challenges, and Future Directions for Reliable AI", "categories": ["cs.SE"], "comment": null, "summary": "Model hallucination is one of the most critical challenges faced by Large\nLanguage Models (LLMs), especially in high-stakes code intelligence tasks. As\nLLMs become increasingly integrated into software engineering tasks,\nunderstanding and mitigating hallucination in code becomes essential. In this\nsurvey, we provide a systematic review of hallucination phenomena in\ncode-oriented LLMs from four key perspectives. First, we begin by surveying 60\npapers to define hallucination in the context of code and summarize its primary\ncauses, such as data noise, exposure bias, and insufficient semantic grounding,\nwhile also tracing recent trends in literature across natural language\nprocessing (NLP) and software engineering communities. Second, we review model\nhallucination surveys in a broader span and summarize representative\nhallucination mitigation strategies, such as knowledge-enhanced generation,\nconstrained decoding, and post-editing. Third, we review approaches targeted\nfor code intelligence and highlight code-specific challenges that aggravate\nhallucination, including syntax sensitivity, strict type systems, and\ndependence on external libraries. Meanwhile, we analyze how emerging code\nintelligence tasks, e.g., program analysis, symbolic execution, and unit\ntesting, are utilized to detect and mitigate hallucinations. Fourth, we\nsummarize current evaluation benchmarks, ranging from static metrics to dynamic\nchecks, e.g., compilation and execution correctness, and emphasize the need for\nhallucination-oriented benchmarks.", "AI": {"tldr": "\u672c\u6587\u5bf9\u9762\u5411\u4ee3\u7801\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u73b0\u8c61\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u4ece\u591a\u65b9\u9762\u5206\u6790\u5e76\u603b\u7ed3\u76f8\u5173\u95ee\u9898\u3001\u7b56\u7565\u3001\u6311\u6218\u53ca\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5165\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u7406\u89e3\u548c\u7f13\u89e3\u4ee3\u7801\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\u5341\u5206\u5fc5\u8981\u3002", "method": "\u901a\u8fc7\u8c03\u781460\u7bc7\u8bba\u6587\uff0c\u4ece\u5b9a\u4e49\u53ca\u539f\u56e0\u3001\u7f13\u89e3\u7b56\u7565\u3001\u4ee3\u7801\u667a\u80fd\u6311\u6218\u53ca\u65b0\u5174\u4efb\u52a1\u5229\u7528\u3001\u8bc4\u4f30\u57fa\u51c6\u56db\u4e2a\u5173\u952e\u89c6\u89d2\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\u3002", "result": "\u660e\u786e\u4ee3\u7801\u8bed\u5883\u4e0b\u5e7b\u89c9\u7684\u5b9a\u4e49\u548c\u4e3b\u8981\u539f\u56e0\uff0c\u603b\u7ed3\u4ee3\u8868\u6027\u7f13\u89e3\u7b56\u7565\uff0c\u6307\u51fa\u4ee3\u7801\u7279\u5b9a\u6311\u6218\uff0c\u5206\u6790\u65b0\u5174\u4efb\u52a1\u4f5c\u7528\uff0c\u603b\u7ed3\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u9762\u5411\u5e7b\u89c9\u7684\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2511.00065", "pdf": "https://arxiv.org/pdf/2511.00065", "abs": "https://arxiv.org/abs/2511.00065", "authors": ["Kateryna Shapovalenko", "Quentin Auster"], "title": "Aligning Brain Signals with Multimodal Speech and Vision Embeddings", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "When we hear the word \"house\", we don't just process sound, we imagine walls,\ndoors, memories. The brain builds meaning through layers, moving from raw\nacoustics to rich, multimodal associations. Inspired by this, we build on\nrecent work from Meta that aligned EEG signals with averaged wav2vec2 speech\nembeddings, and ask a deeper question: which layers of pre-trained models best\nreflect this layered processing in the brain? We compare embeddings from two\nmodels: wav2vec2, which encodes sound into language, and CLIP, which maps words\nto images. Using EEG recorded during natural speech perception, we evaluate how\nthese embeddings align with brain activity using ridge regression and\ncontrastive decoding. We test three strategies: individual layers, progressive\nconcatenation, and progressive summation. The findings suggest that combining\nmultimodal, layer-aware representations may bring us closer to decoding how the\nbrain understands language, not just as sound, but as experience.", "AI": {"tldr": "\u53d7\u5927\u8111\u5206\u5c42\u6784\u5efa\u8bed\u4e49\u542f\u53d1\uff0c\u7814\u7a76\u9884\u8bad\u7ec3\u6a21\u578b\u54ea\u4e00\u5c42\u6700\u80fd\u53cd\u6620\u5927\u8111\u5206\u5c42\u5904\u7406\uff0c\u5bf9\u6bd4wav2vec2\u548cCLIP\u6a21\u578b\u5d4c\u5165\uff0c\u7528\u591a\u79cd\u7b56\u7565\u6d4b\u8bd5\uff0c\u53d1\u73b0\u7ed3\u5408\u591a\u6a21\u6001\u3001\u5206\u5c42\u611f\u77e5\u8868\u5f81\u6216\u52a9\u4e8e\u89e3\u7801\u5927\u8111\u7406\u89e3\u8bed\u8a00\u65b9\u5f0f\u3002", "motivation": "\u53d7\u5927\u8111\u4ece\u539f\u59cb\u58f0\u5b66\u4fe1\u606f\u5230\u591a\u6a21\u6001\u8054\u60f3\u7684\u5206\u5c42\u6784\u5efa\u8bed\u4e49\u65b9\u5f0f\u542f\u53d1\uff0c\u63a2\u7a76\u9884\u8bad\u7ec3\u6a21\u578b\u54ea\u4e00\u5c42\u6700\u80fd\u53cd\u6620\u5927\u8111\u7684\u5206\u5c42\u5904\u7406\u3002", "method": "\u5bf9\u6bd4wav2vec2\u548cCLIP\u6a21\u578b\u7684\u5d4c\u5165\uff0c\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u611f\u77e5\u65f6\u8bb0\u5f55\u7684EEG\uff0c\u901a\u8fc7\u5cad\u56de\u5f52\u548c\u5bf9\u6bd4\u89e3\u7801\u8bc4\u4f30\u5d4c\u5165\u4e0e\u5927\u8111\u6d3b\u52a8\u7684\u4e00\u81f4\u6027\uff0c\u6d4b\u8bd5\u4e2a\u4f53\u5c42\u3001\u6e10\u8fdb\u7ea7\u8054\u548c\u6e10\u8fdb\u6c42\u548c\u4e09\u79cd\u7b56\u7565\u3002", "result": "\u7ed3\u5408\u591a\u6a21\u6001\u3001\u5206\u5c42\u611f\u77e5\u8868\u5f81\u53ef\u80fd\u8ba9\u6211\u4eec\u66f4\u63a5\u8fd1\u89e3\u7801\u5927\u8111\u7406\u89e3\u8bed\u8a00\u7684\u65b9\u5f0f\u3002", "conclusion": "\u7ed3\u5408\u591a\u6a21\u6001\u3001\u5c42\u611f\u77e5\u7684\u8868\u5f81\u6709\u52a9\u4e8e\u89e3\u7801\u5927\u8111\u7406\u89e3\u8bed\u8a00\u7684\u673a\u5236\uff0c\u800c\u975e\u4ec5\u5c06\u8bed\u8a00\u89c6\u4e3a\u58f0\u97f3\u3002"}}
{"id": "2511.00359", "pdf": "https://arxiv.org/pdf/2511.00359", "abs": "https://arxiv.org/abs/2511.00359", "authors": ["Zhecheng Sheng", "Jiawei Zhang", "Enmao Diao"], "title": "Toward Unifying Group Fairness Evaluation from a Sparsity Perspective", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "comment": "30 pages, 14 figures", "summary": "Ensuring algorithmic fairness remains a significant challenge in machine\nlearning, particularly as models are increasingly applied across diverse\ndomains. While numerous fairness criteria exist, they often lack\ngeneralizability across different machine learning problems. This paper\nexamines the connections and differences among various sparsity measures in\npromoting fairness and proposes a unified sparsity-based framework for\nevaluating algorithmic fairness. The framework aligns with existing fairness\ncriteria and demonstrates broad applicability to a wide range of machine\nlearning tasks. We demonstrate the effectiveness of the proposed framework as\nan evaluation metric through extensive experiments on a variety of datasets and\nbias mitigation methods. This work provides a novel perspective to algorithmic\nfairness by framing it through the lens of sparsity and social equity, offering\npotential for broader impact on fairness research and applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u7a00\u758f\u6027\u7684\u7edf\u4e00\u6846\u67b6\u8bc4\u4f30\u7b97\u6cd5\u516c\u5e73\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4e3a\u7b97\u6cd5\u516c\u5e73\u6027\u7814\u7a76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u6807\u51c6\u5728\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u95ee\u9898\u4e2d\u7f3a\u4e4f\u901a\u7528\u6027\uff0c\u9700\u7814\u7a76\u4fc3\u8fdb\u516c\u5e73\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u5404\u79cd\u7a00\u758f\u6027\u5ea6\u91cf\u4e4b\u95f4\u7684\u8054\u7cfb\u4e0e\u5dee\u5f02\uff0c\u63d0\u51fa\u57fa\u4e8e\u7a00\u758f\u6027\u7684\u7edf\u4e00\u6846\u67b6\u8bc4\u4f30\u7b97\u6cd5\u516c\u5e73\u6027\u3002", "result": "\u6846\u67b6\u7b26\u5408\u73b0\u6709\u516c\u5e73\u6027\u6807\u51c6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4ece\u7a00\u758f\u6027\u548c\u793e\u4f1a\u516c\u5e73\u89d2\u5ea6\u4e3a\u7b97\u6cd5\u516c\u5e73\u6027\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u5bf9\u516c\u5e73\u6027\u7814\u7a76\u548c\u5e94\u7528\u6709\u6f5c\u5728\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2511.01583", "pdf": "https://arxiv.org/pdf/2511.01583", "abs": "https://arxiv.org/abs/2511.01583", "authors": ["Daniel M. Jimenez-Gutierrez", "Enrique Zuazua", "Joaquin Del Rio", "Oleksii Sliusarenko", "Xabi Uribe-Etxebarria"], "title": "Federated Cyber Defense: Privacy-Preserving Ransomware Detection Across Distributed Systems", "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.LG"], "comment": null, "summary": "Detecting malware, especially ransomware, is essential to securing today's\ninterconnected ecosystems, including cloud storage, enterprise file-sharing,\nand database services. Training high-performing artificial intelligence (AI)\ndetectors requires diverse datasets, which are often distributed across\nmultiple organizations, making centralization necessary. However, centralized\nlearning is often impractical due to security, privacy regulations, data\nownership issues, and legal barriers to cross-organizational sharing.\nCompounding this challenge, ransomware evolves rapidly, demanding models that\nare both robust and adaptable.\n  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL\nplatform, which enables multiple organizations to collaboratively train a\nransomware detection model while keeping raw data local and secure. This\nparadigm is particularly relevant for cybersecurity companies (including both\nsoftware and hardware vendors) that deploy ransomware detection or firewall\nsystems across millions of endpoints. In such environments, data cannot be\ntransferred outside the customer's device due to strict security, privacy, or\nregulatory constraints. Although FL applies broadly to malware threats, we\nvalidate the approach using the Ransomware Storage Access Patterns (RanSAP)\ndataset.\n  Our experiments demonstrate that FL improves ransomware detection accuracy by\na relative 9% over server-local models and achieves performance comparable to\ncentralized training. These results indicate that FL offers a scalable,\nhigh-performing, and privacy-preserving framework for proactive ransomware\ndetection across organizational and regulatory boundaries.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4f7f\u7528Sherpa.ai\u8054\u90a6\u5b66\u4e60\u5e73\u53f0\u8fdb\u884c\u52d2\u7d22\u8f6f\u4ef6\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u8054\u90a6\u5b66\u4e60\u6bd4\u670d\u52a1\u5668\u672c\u5730\u6a21\u578b\u63d0\u9ad8\u4e869%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u68c0\u6d4b\u6846\u67b6\u3002", "motivation": "\u68c0\u6d4b\u52d2\u7d22\u8f6f\u4ef6\u5bf9\u4fdd\u969c\u4e92\u8054\u751f\u6001\u7cfb\u7edf\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u8bad\u7ec3\u9ad8\u6027\u80fdAI\u68c0\u6d4b\u5668\u9700\u8981\u591a\u6837\u6570\u636e\u96c6\uff0c\u4f46\u96c6\u4e2d\u5b66\u4e60\u56e0\u5b89\u5168\u3001\u9690\u79c1\u7b49\u95ee\u9898\u4e0d\u5207\u5b9e\u9645\uff0c\u4e14\u52d2\u7d22\u8f6f\u4ef6\u6f14\u53d8\u8fc5\u901f\uff0c\u9700\u8981\u9c81\u68d2\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528Sherpa.ai\u8054\u90a6\u5b66\u4e60\u5e73\u53f0\uff0c\u8ba9\u591a\u4e2a\u7ec4\u7ec7\u5728\u4fdd\u6301\u539f\u59cb\u6570\u636e\u672c\u5730\u5b89\u5168\u7684\u60c5\u51b5\u4e0b\u534f\u540c\u8bad\u7ec3\u52d2\u7d22\u8f6f\u4ef6\u68c0\u6d4b\u6a21\u578b\uff0c\u5e76\u7528RanSAP\u6570\u636e\u96c6\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u3002", "result": "\u8054\u90a6\u5b66\u4e60\u6bd4\u670d\u52a1\u5668\u672c\u5730\u6a21\u578b\u76f8\u5bf9\u63d0\u9ad8\u4e869%\u7684\u52d2\u7d22\u8f6f\u4ef6\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u6027\u80fd\u4e0e\u96c6\u4e2d\u8bad\u7ec3\u76f8\u5f53\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u4e3a\u8de8\u7ec4\u7ec7\u548c\u76d1\u7ba1\u8fb9\u754c\u7684\u4e3b\u52a8\u52d2\u7d22\u8f6f\u4ef6\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u6846\u67b6\u3002"}}
{"id": "2511.01268", "pdf": "https://arxiv.org/pdf/2511.01268", "abs": "https://arxiv.org/abs/2511.01268", "authors": ["Minseok Kim", "Hankook Lee", "Hyungjoon Koo"], "title": "Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems", "categories": ["cs.CR", "cs.AI", "cs.IR", "D.4.6; K.6.5"], "comment": "15 pages, 7 figures, 10 tables. To appear in the Proceedings of the\n  2025 Annual Computer Security Applications Conference (ACSAC)", "summary": "Large language models (LLMs) are reshaping numerous facets of our daily\nlives, leading widespread adoption as web-based services. Despite their\nversatility, LLMs face notable challenges, such as generating hallucinated\ncontent and lacking access to up-to-date information. Lately, to address such\nlimitations, Retrieval-Augmented Generation (RAG) has emerged as a promising\ndirection by generating responses grounded in external knowledge sources. A\ntypical RAG system consists of i) a retriever that probes a group of relevant\npassages from a knowledge base and ii) a generator that formulates a response\nbased on the retrieved content. However, as with other AI systems, recent\nstudies demonstrate the vulnerability of RAG, such as knowledge corruption\nattacks by injecting misleading information. In response, several defense\nstrategies have been proposed, including having LLMs inspect the retrieved\npassages individually or fine-tuning robust retrievers. While effective, such\napproaches often come with substantial computational costs.\n  In this work, we introduce RAGDefender, a resource-efficient defense\nmechanism against knowledge corruption (i.e., by data poisoning) attacks in\npractical RAG deployments. RAGDefender operates during the post-retrieval\nphase, leveraging lightweight machine learning techniques to detect and filter\nout adversarial content without requiring additional model training or\ninference. Our empirical evaluations show that RAGDefender consistently\noutperforms existing state-of-the-art defenses across multiple models and\nadversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR)\nagainst the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for\nRobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber\nlegitimate ones by a factor of four (4x).", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u751f\u6210\u5e7b\u89c9\u5185\u5bb9\u7b49\u95ee\u9898\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u53ef\u89e3\u51b3\u4f46\u6613\u53d7\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u7b56\u7565\u6210\u672c\u9ad8\uff0c\u672c\u6587\u63d0\u51fa\u8d44\u6e90\u9ad8\u6548\u7684RAGDefender\u9632\u5fa1\u673a\u5236\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3RAG\u7cfb\u7edf\u6613\u53d7\u77e5\u8bc6\u8150\u8d25\u653b\u51fb\u4e14\u73b0\u6709\u9632\u5fa1\u7b56\u7565\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u5728\u68c0\u7d22\u540e\u9636\u6bb5\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u673a\u5668\u5b66\u4e60\u6280\u672f\u68c0\u6d4b\u548c\u8fc7\u6ee4\u5bf9\u6297\u6027\u5185\u5bb9\uff0c\u65e0\u9700\u989d\u5916\u6a21\u578b\u8bad\u7ec3\u6216\u63a8\u7406\u3002", "result": "RAGDefender\u5728\u591a\u4e2a\u6a21\u578b\u548c\u5bf9\u6297\u573a\u666f\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u5982\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u964d\u4f4eGemini\u6a21\u578b\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "RAGDefender\u662f\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u7684\u3001\u53ef\u7528\u4e8e\u5b9e\u9645RAG\u90e8\u7f72\u4e2d\u5bf9\u6297\u77e5\u8bc6\u8150\u8d25\u653b\u51fb\u7684\u6709\u6548\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2511.00673", "pdf": "https://arxiv.org/pdf/2511.00673", "abs": "https://arxiv.org/abs/2511.00673", "authors": ["Dominik Drexler"], "title": "Lifted Successor Generation in Numeric Planning", "categories": ["cs.AI"], "comment": null, "summary": "Most planners ground numeric planning tasks, given in a first-order-like\nlanguage, into a ground task representation. However, this can lead to an\nexponential blowup in task representation size, which occurs in practice for\nhard-to-ground tasks. We extend a state-of-the-art lifted successor generator\nfor classical planning to support numeric precondition applicability. The\nmethod enumerates maximum cliques in a substitution consistency graph. Each\nmaximum clique represents a substitution for the variables of the action\nschema, yielding a ground action. We augment this graph with numeric action\npreconditions and prove the successor generator is exact under formally\nspecified conditions. When the conditions fail, our generator may list\ninapplicable ground actions; a final applicability check filters these without\naffecting completeness. However, this cannot happen in 23 of 25 benchmark\ndomains, and it occurs only in 1 domain. To the authors' knowledge, no other\nlifted successor generator supports numeric action preconditions. This enables\nfuture research on lifted planning for a very rich planning fragment.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u7ecf\u5178\u89c4\u5212\u7684\u63d0\u5347\u540e\u7ee7\u751f\u6210\u5668\u4ee5\u652f\u6301\u6570\u503c\u524d\u63d0\u9002\u7528\u6027\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u5e76\u8bc1\u660e\u5176\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u7cbe\u786e\u6027\uff0c\u4e3a\u4e30\u5bcc\u89c4\u5212\u7247\u6bb5\u7684\u63d0\u5347\u89c4\u5212\u7814\u7a76\u63d0\u4f9b\u53ef\u80fd\u3002", "motivation": "\u73b0\u6709\u89c4\u5212\u5668\u5c06\u6570\u503c\u89c4\u5212\u4efb\u52a1\u8fdb\u884c\u63a5\u5730\u5904\u7406\u4f1a\u5bfc\u81f4\u4efb\u52a1\u8868\u793a\u89c4\u6a21\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u65b9\u6cd5\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u6269\u5c55\u63d0\u5347\u540e\u7ee7\u751f\u6210\u5668\uff0c\u5728\u66ff\u6362\u4e00\u81f4\u6027\u56fe\u4e2d\u679a\u4e3e\u6700\u5927\u56e2\uff0c\u4e3a\u56fe\u589e\u52a0\u6570\u503c\u52a8\u4f5c\u524d\u63d0\uff0c\u5e76\u8bc1\u660e\u5176\u7cbe\u786e\u6027\uff0c\u5bf9\u4e0d\u9002\u7528\u7684\u63a5\u5730\u52a8\u4f5c\u8fdb\u884c\u8fc7\u6ee4\u3002", "result": "\u8be5\u65b9\u6cd5\u572825\u4e2a\u57fa\u51c6\u9886\u57df\u4e2d\u768423\u4e2a\u4e0d\u4f1a\u51fa\u73b0\u5217\u51fa\u4e0d\u9002\u7528\u63a5\u5730\u52a8\u4f5c\u7684\u60c5\u51b5\uff0c\u4ec5\u57281\u4e2a\u9886\u57df\u4e2d\u51fa\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f7f\u672a\u6765\u9488\u5bf9\u4e30\u5bcc\u89c4\u5212\u7247\u6bb5\u7684\u63d0\u5347\u89c4\u5212\u7814\u7a76\u6210\u4e3a\u53ef\u80fd\uff0c\u4e14\u76ee\u524d\u6ca1\u6709\u5176\u4ed6\u63d0\u5347\u540e\u7ee7\u751f\u6210\u5668\u652f\u6301\u6570\u503c\u52a8\u4f5c\u524d\u63d0\u3002"}}
{"id": "2511.00780", "pdf": "https://arxiv.org/pdf/2511.00780", "abs": "https://arxiv.org/abs/2511.00780", "authors": ["Chenyu Zhao", "Shenglin Zhang", "Zeshun Huang", "Weilin Jin", "Yongqian Sun", "Dan Pei", "Chaoyun Zhang", "Qingwei Lin", "Chetan Bansal", "Saravan Rajmohan", "Minghua Ma"], "title": "Can Language Models Go Beyond Coding? Assessing the Capability of Language Models to Build Real-World Systems", "categories": ["cs.SE"], "comment": null, "summary": "Large language models (LLMs) have shown growing potential in software\nengineering, yet few benchmarks evaluate their ability to repair software\nduring migration across instruction set architectures (ISAs). Cross-ISA\nmigration, such as between x86_64 and aarch64, requires handling complex\ndependencies, heterogeneous toolchains, and long build logs while ensuring\nexecutable verification. To address this challenge, we present Build-bench, an\nend-to-end benchmark that systematically evaluates the capability of LLMs to\nrepair build failures in cross-ISA settings. Build-bench collects 268\nreal-world failed packages and integrates auxiliary tools including Structure\nExtraction, File Content Extraction, Content Modification, and Build\nVerification to support autonomous, tool-augmented reasoning. The repair\nprocess operates in an iterative loop where, upon failure, the model receives\nupdated build logs and previous repair outcomes to refine subsequent attempts.\nThrough a comparative evaluation of six representative LLMs, Build-bench\nreveals that current models achieve a maximum build success rate of 63% and\ntool usage patterns differ significantly across models. By coupling real build\nenvironments with verifiable outcomes, Build-bench establishes the first\narchitecture-aware benchmark for studying LLM-based software build and repair.", "AI": {"tldr": "\u63d0\u51faBuild - bench\u57fa\u51c6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\u4fee\u590d\u8f6f\u4ef6\u6784\u5efa\u5931\u8d25\u7684\u80fd\u529b\uff0c\u8bc4\u4f306\u4e2a\u6a21\u578b\uff0c\u663e\u793a\u5f53\u524d\u6a21\u578b\u6700\u9ad8\u6784\u5efa\u6210\u529f\u738763%\uff0c\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u5dee\u5f02\u5927\u3002", "motivation": "\u73b0\u6709\u7f3a\u4e4f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\u8fc1\u79fb\u65f6\u4fee\u590d\u8f6f\u4ef6\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u8de8\u6307\u4ee4\u96c6\u8fc1\u79fb\u9700\u5904\u7406\u590d\u6742\u4f9d\u8d56\u7b49\u95ee\u9898\u3002", "method": "\u6784\u5efaBuild - bench\u57fa\u51c6\uff0c\u6536\u96c6268\u4e2a\u771f\u5b9e\u5931\u8d25\u5305\uff0c\u96c6\u6210\u8f85\u52a9\u5de5\u5177\uff0c\u91c7\u7528\u8fed\u4ee3\u4fee\u590d\u6d41\u7a0b\u3002", "result": "\u5bf96\u4e2a\u4ee3\u8868\u6a21\u578b\u8bc4\u4f30\uff0c\u5f53\u524d\u6a21\u578b\u6700\u9ad8\u6784\u5efa\u6210\u529f\u738763%\uff0c\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u5dee\u5f02\u5927\u3002", "conclusion": "Build - bench\u662f\u9996\u4e2a\u652f\u6301\u67b6\u6784\u611f\u77e5\u7684\u7814\u7a76\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8f6f\u4ef6\u6784\u5efa\u548c\u4fee\u590d\u7684\u57fa\u51c6\u3002"}}
{"id": "2511.00066", "pdf": "https://arxiv.org/pdf/2511.00066", "abs": "https://arxiv.org/abs/2511.00066", "authors": ["Tue Le", "Nghi D. Q. Bui", "Linh Ngo Van", "Trung Le"], "title": "Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npowerful approach for strengthening the reasoning capabilities of large\nlanguage models (LLMs). Among existing algorithms, Group Relative Policy\nOptimization (GRPO) has demonstrated strong performance, yet it suffers from a\ncritical issue: low-probability tokens disproportionately dominate gradient\nupdates due to their inherently large gradient magnitudes. This imbalance leads\nto unstable training and suppresses the contribution of high-probability tokens\nthat are more reliable for learning. In this work, we introduce Token-Regulated\nGroup Relative Policy Optimization (TR-GRPO), a simple yet effective extension\nof GRPO that assigns token-level weights positively correlated with the model's\npredicted probability. By downweighting low-probability tokens and emphasizing\nhigh-probability ones, TR-GRPO mitigates gradient over-amplification while\npreserving informative learning signals. Extensive experiments demonstrate that\nTR-GRPO consistently outperforms GRPO across RLVR tasks, including logic, math,\nand agentic reasoning, highlighting the importance of regulating token\ncontributions during RL training and establishing TR-GRPO as a robust framework\nfor enhancing LLM reasoning.", "AI": {"tldr": "\u63d0\u51faTR - GRPO\u6539\u8fdbGRPO\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728RLVR\u4efb\u52a1\u4e2d\u4f18\u4e8eGRPO\uff0c\u53ef\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709GRPO\u7b97\u6cd5\u5b58\u5728\u4f4e\u6982\u7387token\u68af\u5ea6\u8fc7\u5927\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u9ad8\u6982\u7387token\u8d21\u732e\u88ab\u6291\u5236\u7684\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u5165Token - Regulated Group Relative Policy Optimization (TR - GRPO)\uff0c\u4e3atoken\u5206\u914d\u4e0e\u6a21\u578b\u9884\u6d4b\u6982\u7387\u6b63\u76f8\u5173\u7684\u6743\u91cd\uff0c\u964d\u4f4e\u4f4e\u6982\u7387token\u6743\u91cd\uff0c\u5f3a\u8c03\u9ad8\u6982\u7387token\u3002", "result": "\u5728\u903b\u8f91\u3001\u6570\u5b66\u548c\u4ee3\u7406\u63a8\u7406\u7b49RLVR\u4efb\u52a1\u4e2d\uff0cTR - GRPO\u59cb\u7ec8\u4f18\u4e8eGRPO\u3002", "conclusion": "\u8c03\u8282RL\u8bad\u7ec3\u4e2dtoken\u7684\u8d21\u732e\u5f88\u91cd\u8981\uff0cTR - GRPO\u662f\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\u7684\u53ef\u9760\u6846\u67b6\u3002"}}
{"id": "2511.00434", "pdf": "https://arxiv.org/pdf/2511.00434", "abs": "https://arxiv.org/abs/2511.00434", "authors": ["Andrea Angino", "Matteo Aurina", "Alena Kopani\u010d\u00e1kov\u00e1", "Matthias Voigt", "Marco Donatelli", "Rolf Krause"], "title": "Trust-Region Methods with Low-Fidelity Objective Models", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": "Submitted to the Proceedings of Domain Decomposition Methods in\n  Science and Engineering XXIX", "summary": "We introduce two multifidelity trust-region methods based on the Magical\nTrust Region (MTR) framework. MTR augments the classical trust-region step with\na secondary, informative direction. In our approaches, the secondary\n``magical'' directions are determined by solving coarse trust-region\nsubproblems based on low-fidelity objective models. The first proposed method,\nSketched Trust-Region (STR), constructs this secondary direction using a\nsketched matrix to reduce the dimensionality of the trust-region subproblem.\nThe second method, SVD Trust-Region (SVDTR), defines the magical direction via\na truncated singular value decomposition of the dataset, capturing the leading\ndirections of variability. Several numerical examples illustrate the potential\ngain in efficiency.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eMTR\u6846\u67b6\u5f15\u5165\u4e24\u79cd\u591a\u4fdd\u771f\u5ea6\u4fe1\u8d56\u57df\u65b9\u6cd5\uff0c\u901a\u8fc7\u6c42\u89e3\u4f4e\u4fdd\u771f\u6a21\u578b\u7684\u7c97\u4fe1\u8d56\u57df\u5b50\u95ee\u9898\u786e\u5b9a\u8f85\u52a9\u65b9\u5411\uff0c\u5206\u522b\u4e3aSTR\u548cSVDTR\u65b9\u6cd5\uff0c\u6570\u503c\u7b97\u4f8b\u8868\u660e\u6548\u7387\u6709\u6f5c\u5728\u63d0\u5347\u3002", "motivation": "\u5f15\u5165\u65b0\u7684\u591a\u4fdd\u771f\u5ea6\u4fe1\u8d56\u57df\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u4f18\u5316\u6548\u7387\u3002", "method": "\u57fa\u4e8eMTR\u6846\u67b6\uff0c\u901a\u8fc7\u6c42\u89e3\u4f4e\u4fdd\u771f\u76ee\u6807\u6a21\u578b\u7684\u7c97\u4fe1\u8d56\u57df\u5b50\u95ee\u9898\u786e\u5b9a\u8f85\u52a9\u201c\u795e\u5947\u201d\u65b9\u5411\uff0c\u5206\u522b\u4f7f\u7528\u7a00\u758f\u77e9\u9635\uff08STR\uff09\u548c\u6570\u636e\u96c6\u7684\u622a\u65ad\u5947\u5f02\u503c\u5206\u89e3\uff08SVDTR\uff09\u6765\u6784\u5efa\u8be5\u65b9\u5411\u3002", "result": "\u901a\u8fc7\u51e0\u4e2a\u6570\u503c\u7b97\u4f8b\u5c55\u793a\u4e86\u65b9\u6cd5\u5728\u6548\u7387\u4e0a\u6709\u6f5c\u5728\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u79cd\u591a\u4fdd\u771f\u5ea6\u4fe1\u8d56\u57df\u65b9\u6cd5\u5177\u6709\u63d0\u9ad8\u4f18\u5316\u6548\u7387\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.01737", "pdf": "https://arxiv.org/pdf/2511.01737", "abs": "https://arxiv.org/abs/2511.01737", "authors": ["Obaidullah Zaland", "Feras M. Awaysheh", "Sawsan Al Zubi", "Abdul Rahman Safi", "Monowar Bhuyan"], "title": "Edge AI in Highly Volatile Environments: Is Fairness Worth the Accuracy Trade-off?", "categories": ["cs.LG", "cs.DC"], "comment": "Presented at IEEE FLTA 2025", "summary": "Federated learning (FL) has emerged as a transformative paradigm for edge\nintelligence, enabling collaborative model training while preserving data\nprivacy across distributed personal devices. However, the inherent volatility\nof edge environments, characterized by dynamic resource availability and\nheterogeneous client capabilities, poses significant challenges for achieving\nhigh accuracy and fairness in client participation. This paper investigates the\nfundamental trade-off between model accuracy and fairness in highly volatile\nedge environments. This paper provides an extensive empirical evaluation of\nfairness-based client selection algorithms such as RBFF and RBCSF against\nrandom and greedy client selection regarding fairness, model performance, and\ntime, in three benchmarking datasets (CIFAR10, FashionMNIST, and EMNIST). This\nwork aims to shed light on the fairness-performance and fairness-speed\ntrade-offs in a volatile edge environment and explore potential future research\nopportunities to address existing pitfalls in \\textit{fair client selection}\nstrategies in FL. Our results indicate that more equitable client selection\nalgorithms, while providing a marginally better opportunity among clients, can\nresult in slower global training in volatile environments\\footnote{The code for\nour experiments can be found at\nhttps://github.com/obaidullahzaland/FairFL_FLTA.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u9ad8\u6ce2\u52a8\u8fb9\u7f18\u73af\u5883\u4e0b\u8054\u90a6\u5b66\u4e60\u4e2d\u6a21\u578b\u51c6\u786e\u6027\u4e0e\u516c\u5e73\u6027\u7684\u6743\u8861\uff0c\u8bc4\u4f30\u516c\u5e73\u6027\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\u516c\u5e73\u7b97\u6cd5\u5728\u6ce2\u52a8\u73af\u5883\u8bad\u7ec3\u66f4\u6162\u3002", "motivation": "\u8fb9\u7f18\u73af\u5883\u7684\u56fa\u6709\u6ce2\u52a8\u6027\u7ed9\u8054\u90a6\u5b66\u4e60\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u548c\u5ba2\u6237\u7aef\u53c2\u4e0e\u516c\u5e73\u6027\u5e26\u6765\u6311\u6218\uff0c\u9700\u7814\u7a76\u6a21\u578b\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u7684\u6743\u8861\u3002", "method": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u57fa\u4e8e\u516c\u5e73\u6027\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\uff08\u5982RBFF\u548cRBCSF\uff09\u4e0e\u968f\u673a\u548c\u8d2a\u5a6a\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\uff0c\u4ece\u516c\u5e73\u6027\u3001\u6a21\u578b\u6027\u80fd\u548c\u65f6\u95f4\u65b9\u9762\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u66f4\u516c\u5e73\u7684\u5ba2\u6237\u7aef\u9009\u62e9\u7b97\u6cd5\u867d\u80fd\u4e3a\u5ba2\u6237\u7aef\u63d0\u4f9b\u7a0d\u597d\u673a\u4f1a\uff0c\u4f46\u5728\u6ce2\u52a8\u73af\u5883\u4e2d\u4f1a\u5bfc\u81f4\u5168\u5c40\u8bad\u7ec3\u53d8\u6162\u3002", "conclusion": "\u63ed\u793a\u4e86\u6ce2\u52a8\u8fb9\u7f18\u73af\u5883\u4e2d\u516c\u5e73\u6027 - \u6027\u80fd\u548c\u516c\u5e73\u6027 - \u901f\u5ea6\u7684\u6743\u8861\uff0c\u63a2\u7d22\u4e86\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u516c\u5e73\u5ba2\u6237\u7aef\u9009\u62e9\u7b56\u7565\u73b0\u6709\u7f3a\u9677\u7684\u672a\u6765\u7814\u7a76\u673a\u4f1a\u3002"}}
{"id": "2511.01386", "pdf": "https://arxiv.org/pdf/2511.01386", "abs": "https://arxiv.org/abs/2511.01386", "authors": ["Muhammed Yusuf Kartal", "Suha Kagan Kose", "Korhan Sevin\u00e7", "Burak Aktas"], "title": "RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets", "categories": ["cs.CL", "cs.AI", "cs.IR", "H.3.3; I.2.7"], "comment": "45 pages", "summary": "Retrieval-Augmented Generation (RAG) quality depends on many interacting\nchoices across retrieval, ranking, augmentation, prompting, and generation, so\noptimizing modules in isolation is brittle. We introduce RAGSmith, a modular\nframework that treats RAG design as an end-to-end architecture search over nine\ntechnique families and 46{,}080 feasible pipeline configurations. A genetic\nsearch optimizes a scalar objective that jointly aggregates retrieval metrics\n(recall@k, mAP, nDCG, MRR) and generation metrics (LLM-Judge and semantic\nsimilarity). We evaluate on six Wikipedia-derived domains (Mathematics, Law,\nFinance, Medicine, Defense Industry, Computer Science), each with 100 questions\nspanning factual, interpretation, and long-answer types. RAGSmith finds\nconfigurations that consistently outperform naive RAG baseline by +3.8\\% on\naverage (range +1.2\\% to +6.9\\% across domains), with gains up to +12.5\\% in\nretrieval and +7.5\\% in generation. The search typically explores $\\approx\n0.2\\%$ of the space ($\\sim 100$ candidates) and discovers a robust backbone --\nvector retrieval plus post-generation reflection/revision -- augmented by\ndomain-dependent choices in expansion, reranking, augmentation, and prompt\nreordering; passage compression is never selected. Improvement magnitude\ncorrelates with question type, with larger gains on factual/long-answer mixes\nthan interpretation-heavy sets. These results provide practical, domain-aware\nguidance for assembling effective RAG systems and demonstrate the utility of\nevolutionary search for full-pipeline optimization.", "AI": {"tldr": "\u4ecb\u7ecdRAGSmith\u6846\u67b6\u8fdb\u884cRAG\u7aef\u5230\u7aef\u67b6\u6784\u641c\u7d22\uff0c\u5728\u591a\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "RAG\u8d28\u91cf\u53d7\u591a\u56e0\u7d20\u5f71\u54cd\uff0c\u5b64\u7acb\u4f18\u5316\u6a21\u5757\u4e0d\u53ef\u9760\uff0c\u9700\u7aef\u5230\u7aef\u67b6\u6784\u641c\u7d22\u3002", "method": "\u4f7f\u7528\u9057\u4f20\u641c\u7d22\u4f18\u5316\u6807\u91cf\u76ee\u6807\uff0c\u5bf99\u79cd\u6280\u672f\u65cf\u548c46,080\u79cd\u53ef\u884c\u7ba1\u9053\u914d\u7f6e\u8fdb\u884c\u641c\u7d22\u3002", "result": "RAGSmith\u914d\u7f6e\u5e73\u5747\u6bd4\u57fa\u7ebf\u9ad83.8%\uff0c\u641c\u7d22\u7ea60.2%\u7a7a\u95f4\uff0c\u53d1\u73b0\u6709\u6548\u9aa8\u5e72\uff0c\u589e\u76ca\u4e0e\u95ee\u9898\u7c7b\u578b\u76f8\u5173\u3002", "conclusion": "\u4e3a\u6784\u5efa\u6709\u6548RAG\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u3001\u9886\u57df\u611f\u77e5\u6307\u5bfc\uff0c\u8bc1\u660e\u8fdb\u5316\u641c\u7d22\u7528\u4e8e\u5168\u7ba1\u9053\u4f18\u5316\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.00710", "pdf": "https://arxiv.org/pdf/2511.00710", "abs": "https://arxiv.org/abs/2511.00710", "authors": ["Minghe Shen", "Zhuo Zhi", "Chonghan Liu", "Shuo Xing", "Zhengzhong Tu", "Che Liu"], "title": "Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries", "categories": ["cs.AI"], "comment": null, "summary": "While Vision-Language Models (VLMs) post-trained with Reinforcement Learning\n(RL) show impressive general reasoning, their evaluation is often confined to\nlanguage-dominant tasks (e.g., math). This raises a critical question: can RL\npost-training truly extend the inherent capability boundary of a base VLM,\nparticularly for visual-centric spatial tasks where it initially fails? To\ninvestigate this, we introduce Ariadne, a framework utilizing synthetic mazes\nfor multi-step spatial reasoning where task difficulty (e.g., path length,\nturns) is precisely controlled. We leverage this controllable environment to\ntrain VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a\ndifficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves\nover 50% accuracy on a problem set where the base model scored 0%,\ndemonstrating that our approach expands the model's initial capability\nboundary. To assess real-world viability, we evaluate out-of-distribution (OOD)\ngeneralization on practical benchmarks. Despite training only on synthetic maze\nsamples, Ariadne achieves significant zero-shot improvements, averaging 16% on\nMapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer\ntasks). These results confirm that our method not only broadens the model's\nfundamental limits but also enhances its generalization to real-world spatial\nreasoning. We acknowledge our study is limited to the post-training phase,\ngiven the opaqueness of pre-training data, and hope our research motivates\nfurther work on specialized, capability-extending alignment.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165Ariadne\u6846\u67b6\uff0c\u7528\u5408\u6210\u8ff7\u5bab\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u8bc1\u660e\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u53ef\u62d3\u5c55\u6a21\u578b\u80fd\u529b\u8fb9\u754c\u5e76\u63d0\u5347\u771f\u5b9e\u4e16\u754c\u6cdb\u5316\u6027\u3002", "motivation": "\u63a2\u7a76\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u80fd\u5426\u62d3\u5c55\u57fa\u7840\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4ee5\u89c6\u89c9\u4e3a\u4e2d\u5fc3\u7684\u7a7a\u95f4\u4efb\u52a1\u4e0a\u7684\u56fa\u6709\u80fd\u529b\u8fb9\u754c\u3002", "method": "\u5f15\u5165Ariadne\u6846\u67b6\uff0c\u5229\u7528\u5408\u6210\u8ff7\u5bab\u8fdb\u884c\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\uff0c\u7528\u5e26\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u5728\u96be\u5ea6\u611f\u77e5\u8bfe\u7a0b\u4e2d\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u540e\u8bad\u7ec3\u540e\u6a21\u578b\u5728\u57fa\u7840\u6a21\u578b\u5f97\u5206\u4e3a0\u7684\u95ee\u9898\u96c6\u4e0a\u51c6\u786e\u7387\u8d8550%\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u96f6\u6837\u672c\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u62d3\u5bbd\u4e86\u6a21\u578b\u57fa\u672c\u80fd\u529b\u9650\u5236\uff0c\u589e\u5f3a\u4e86\u771f\u5b9e\u4e16\u754c\u7a7a\u95f4\u63a8\u7406\u6cdb\u5316\u6027\uff0c\u7814\u7a76\u5c40\u9650\u4e8e\u540e\u8bad\u7ec3\u9636\u6bb5\uff0c\u5e0c\u671b\u63a8\u52a8\u4e13\u4e1a\u80fd\u529b\u62d3\u5c55\u5bf9\u9f50\u7814\u7a76\u3002"}}
{"id": "2511.00802", "pdf": "https://arxiv.org/pdf/2511.00802", "abs": "https://arxiv.org/abs/2511.00802", "authors": ["Jie JW Wu", "Ayanda Patrick Herlihy", "Ahmad Saleem Mirza", "Ali Afoud", "Fatemeh Fard"], "title": "GrowthHacker: Automated Off-Policy Evaluation Optimization Using Code-Modifying LLM Agents", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": null, "summary": "With the software industry shifting toward a data-driven culture, online A/B\ntesting is a key tool for evaluating new technologies. However, deploying such\nexperiments requires substantial resources, may negatively impact users, and\ninvolves long data collection periods. To address this, \\textit{off-policy\nevaluation (OPE)}, or offline A/B testing, uses logged data to assess\ntechnologies and is fundamental in Reinforcement Learning, making it crucial in\ndomains where online testing is costly or risky, such as healthcare,\nrecommender systems, education, dialog systems, and robotics. Despite advances\nin coding LLMs and agentic AI, little is known about leveraging them to\noptimize OPE results. We investigate whether LLMs and LLM-based agents can\nimprove OPE performance via code optimization. We propose\n\\textit{GrowthHacker}, a benchmark with agent and baseline methods on\nlarge-scale real-world datasets, which iteratively optimizes code, evaluates\nresults, and begins new optimization cycles. We collected datasets, established\nprotocols, implemented baselines for OPE on the Open Bandit Pipeline\n(OBP)~\\cite{saito2021openbanditdatasetpipeline} and\nScope-RL~\\cite{kiyohara2023scope}, and developed the \\textit{two_agent}\nframework, which reduces system complexity while preserving optimization\neffectiveness. Results show the two_agent framework achieves 100% reliability\nand the highest average improvement of 106.7% among positive outcomes. Both\ntwo_agent and CrewAI reach 45% success rates, outperforming AutoGen's 34%.\nThese findings demonstrate the feasibility of LLM-based agents as automated\n\"growth hackers\" to enhance OPE systems, with implications for scaling\ndata-driven decision-making in production.", "AI": {"tldr": "\u7814\u7a76\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u4f18\u5316\u79bb\u7ebfA/B\u6d4b\u8bd5\uff08OPE\uff09\u7ed3\u679c\uff0c\u63d0\u51faGrowthHacker\u57fa\u51c6\uff0c\u5f00\u53d1two_agent\u6846\u67b6\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u6548\u679c\u597d\uff0c\u8bc1\u660e\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u53ef\u589e\u5f3aOPE\u7cfb\u7edf\u3002", "motivation": "\u5728\u7ebfA/B\u6d4b\u8bd5\u6709\u8d44\u6e90\u6d88\u8017\u5927\u3001\u5f71\u54cd\u7528\u6237\u7b49\u95ee\u9898\uff0cOPE\u867d\u91cd\u8981\uff0c\u4f46\u5bf9\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u667a\u80fd\u4f53\u4f18\u5316OPE\u7ed3\u679c\u4e86\u89e3\u751a\u5c11\u3002", "method": "\u63d0\u51faGrowthHacker\u57fa\u51c6\uff0c\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u667a\u80fd\u4f53\u548c\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fed\u4ee3\u4f18\u5316\u4ee3\u7801\u3001\u8bc4\u4f30\u7ed3\u679c\uff1b\u5f00\u53d1two_agent\u6846\u67b6\u3002", "result": "two_agent\u6846\u67b6\u53ef\u9760\u6027\u8fbe100%\uff0c\u6b63\u5411\u7ed3\u679c\u5e73\u5747\u63d0\u5347106.7%\uff1btwo_agent\u548cCrewAI\u6210\u529f\u738745%\uff0c\u4f18\u4e8eAutoGen\u768434%\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u53ef\u4f5c\u4e3a\u81ea\u52a8\u201c\u589e\u957f\u9ed1\u5ba2\u201d\u589e\u5f3aOPE\u7cfb\u7edf\uff0c\u5bf9\u751f\u4ea7\u4e2d\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u7684\u6269\u5c55\u6709\u610f\u4e49\u3002"}}
{"id": "2511.00067", "pdf": "https://arxiv.org/pdf/2511.00067", "abs": "https://arxiv.org/abs/2511.00067", "authors": ["Zhixing Li", "Arsham Gholamzadeh Khoee", "Yinan Yu"], "title": "Latent Domain Prompt Learning for Vision-Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The objective of domain generalization (DG) is to enable models to be robust\nagainst domain shift. DG is crucial for deploying vision-language models (VLMs)\nin real-world applications, yet most existing methods rely on domain labels\nthat may not be available and often ambiguous. We instead study the DG setting\nwhere models must generalize well without access to explicit domain labels. Our\nkey idea is to represent an unseen target domain as a combination of latent\ndomains automatically discovered from training data, enabling the model to\nadaptively transfer knowledge across domains. To realize this, we perform\nlatent domain clustering on image features and fuse domain-specific text\nfeatures based on the similarity between the input image and each latent\ndomain. Experiments on four benchmarks show that this strategy yields\nconsistent gains over VLM-based baselines and provides new insights into\nimproving robustness under domain shift.", "AI": {"tldr": "\u7814\u7a76\u65e0\u663e\u5f0f\u9886\u57df\u6807\u7b7e\u4e0b\u7684\u9886\u57df\u6cdb\u5316\uff0c\u901a\u8fc7\u6f5c\u5728\u9886\u57df\u805a\u7c7b\u548c\u6587\u672c\u7279\u5f81\u878d\u5408\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u4f9d\u8d56\u53ef\u80fd\u7f3a\u5931\u6216\u6a21\u7cca\u7684\u9886\u57df\u6807\u7b7e\uff0c\u9700\u7814\u7a76\u65e0\u663e\u5f0f\u9886\u57df\u6807\u7b7e\u7684\u60c5\u51b5\u4ee5\u90e8\u7f72\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u5bf9\u56fe\u50cf\u7279\u5f81\u8fdb\u884c\u6f5c\u5728\u9886\u57df\u805a\u7c7b\uff0c\u57fa\u4e8e\u8f93\u5165\u56fe\u50cf\u4e0e\u5404\u6f5c\u5728\u9886\u57df\u7684\u76f8\u4f3c\u5ea6\u878d\u5408\u7279\u5b9a\u9886\u57df\u6587\u672c\u7279\u5f81\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u7b56\u7565\u6bd4\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\u6709\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u8be5\u7b56\u7565\u80fd\u63d0\u5347\u9886\u57df\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u6539\u8fdb\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2511.00469", "pdf": "https://arxiv.org/pdf/2511.00469", "abs": "https://arxiv.org/abs/2511.00469", "authors": ["Zhongxiang Lei", "Qi Yang", "Ping Qiu", "Gang Zhang", "Yuanchi Ma", "Jinyan Liu"], "title": "Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Federated optimization is a constrained form of distributed optimization that\nenables training a global model without directly sharing client data. Although\nexisting algorithms can guarantee convergence in theory and often achieve\nstable training in practice, the reasons behind performance degradation under\ndata heterogeneity remain unclear. To address this gap, the main contribution\nof this paper is to provide a theoretical perspective that explains why such\ndegradation occurs. We introduce the assumption that heterogeneous client data\nlead to distinct local optima, and show that this assumption implies two key\nconsequences: 1) the distance among clients' local optima raises the lower\nbound of the global objective, making perfect fitting of all client data\nimpossible; and 2) in the final training stage, the global model oscillates\nwithin a region instead of converging to a single optimum, limiting its ability\nto fully fit the data. These results provide a principled explanation for\nperformance degradation in non-iid settings, which we further validate through\nexperiments across multiple tasks and neural network architectures. The\nframework used in this paper is open-sourced at:\nhttps://github.com/NPCLEI/fedtorch.", "AI": {"tldr": "\u672c\u6587\u4ece\u7406\u8bba\u89d2\u5ea6\u89e3\u91ca\u8054\u90a6\u4f18\u5316\u5728\u6570\u636e\u5f02\u8d28\u6027\u4e0b\u6027\u80fd\u4e0b\u964d\u7684\u539f\u56e0\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u867d\u80fd\u4fdd\u8bc1\u7406\u8bba\u6536\u655b\u548c\u5b9e\u8df5\u7a33\u5b9a\u8bad\u7ec3\uff0c\u4f46\u6570\u636e\u5f02\u8d28\u6027\u4e0b\u6027\u80fd\u4e0b\u964d\u539f\u56e0\u4e0d\u660e\uff0c\u9700\u89e3\u91ca\u3002", "method": "\u5f15\u5165\u5f02\u8d28\u5ba2\u6237\u7aef\u6570\u636e\u5bfc\u81f4\u4e0d\u540c\u5c40\u90e8\u6700\u4f18\u7684\u5047\u8bbe\uff0c\u5206\u6790\u5176\u4e24\u4e2a\u5173\u952e\u540e\u679c\u3002", "result": "\u5ba2\u6237\u5c40\u90e8\u6700\u4f18\u95f4\u7684\u8ddd\u79bb\u63d0\u9ad8\u5168\u5c40\u76ee\u6807\u4e0b\u754c\uff0c\u6700\u7ec8\u8bad\u7ec3\u9636\u6bb5\u5168\u5c40\u6a21\u578b\u5728\u533a\u57df\u5185\u632f\u8361\u800c\u975e\u6536\u655b\u5230\u5355\u4e00\u6700\u4f18\u3002", "conclusion": "\u4e3a\u975e\u72ec\u7acb\u540c\u5206\u5e03\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u63d0\u4f9b\u5408\u7406\u89e3\u91ca\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u89e3\u91ca\uff0c\u6846\u67b6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.01485", "pdf": "https://arxiv.org/pdf/2511.01485", "abs": "https://arxiv.org/abs/2511.01485", "authors": ["M Sadik Batcha", "Younis Rashid Dar", "Muneer Ahmad"], "title": "Impact and Relevance of Cognition Journal in the Field of Cognitive Science: An Evaluation", "categories": ["cs.DL", "cs.IR"], "comment": "8 pages, 4 figures, Research Paper. arXiv admin note: substantial\n  text overlap with arXiv:2102.12912, arXiv:2102.09900, arXiv:2102.09894", "summary": "This study aims to present a scientometric analysis of the journal titled\nCognition for a period of 20 years from 1999 to 2018. The present study was\nconducted with an aim to provide a summary of research activity in current\njournal and characterize its most aspects. The research coverage includes the\nyear wise distribution of articles, authors, institutions, countries and\ncitation analysis of the journal. The analysis showed that 2870 papers were\npublished in journal of Cognition from 1999 to 2018. The study identified top\n20 prolific authors, institutions and countries of the journal. Researchers\nfrom USA have been made the most percentage of contributions.", "AI": {"tldr": "\u5bf9\u300aCognition\u300b\u671f\u520a1999 - 2018\u5e74\u8fdb\u884c\u79d1\u5b66\u8ba1\u91cf\u5206\u6790\uff0c\u5c55\u793a\u7814\u7a76\u6d3b\u52a8\u6982\u51b5\u5e76\u786e\u5b9a\u9ad8\u4ea7\u4f5c\u8005\u3001\u673a\u6784\u548c\u56fd\u5bb6\u7b49\u3002", "motivation": "\u603b\u7ed3\u8be5\u671f\u520a\u7684\u7814\u7a76\u6d3b\u52a8\u5e76\u523b\u753b\u5176\u591a\u65b9\u9762\u7279\u5f81\u3002", "method": "\u5bf9\u671f\u520a\u6587\u7ae0\u8fdb\u884c\u5e74\u4efd\u5206\u5e03\u3001\u4f5c\u8005\u3001\u673a\u6784\u3001\u56fd\u5bb6\u548c\u5f15\u6587\u5206\u6790\u3002", "result": "1999 - 2018\u5e74\u300aCognition\u300b\u53d1\u88682870\u7bc7\u8bba\u6587\uff0c\u786e\u5b9a\u4e86\u524d20\u9ad8\u4ea7\u4f5c\u8005\u3001\u673a\u6784\u548c\u56fd\u5bb6\uff0c\u7f8e\u56fd\u7814\u7a76\u8005\u8d21\u732e\u6bd4\u4f8b\u6700\u9ad8\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u7ed3\u8bba\u6027\u5185\u5bb9\u3002"}}
{"id": "2511.00739", "pdf": "https://arxiv.org/pdf/2511.00739", "abs": "https://arxiv.org/abs/2511.00739", "authors": ["Ritik Raj", "Hong Wang", "Tushar Krishna"], "title": "A CPU-Centric Perspective on Agentic AI", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Agentic AI frameworks add a decision-making orchestrator embedded with\nexternal tools, including web search, Python interpreter, contextual database,\nand others, on top of monolithic LLMs, turning them from passive text oracles\ninto autonomous problem-solvers that can plan, call tools, remember past steps,\nand adapt on the fly.\n  This paper aims to characterize and understand the system bottlenecks\nintroduced by agentic AI workloads from a largely overlooked CPU-centric\nperspective. We first systematically characterize Agentic AI on the basis of\norchestrator/decision making component, inference path dynamics and\nrepetitiveness of the agentic flow which directly influences the system-level\nperformance. Thereafter, based on the characterization, we choose five\nrepresentative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow,\nLangchain and SWE-Agent to profile latency, throughput and energy metrics and\ndemystify the significant impact of CPUs on these metrics relative to GPUs. We\nobserve that - 1. Tool processing on CPUs can take up to 90.6% of the total\nlatency; 2. Agentic throughput gets bottlenecked either by CPU factors -\ncoherence, synchronization and over-subscription of cores or GPU factors - main\nmemory capacity and bandwidth; \\circled{3} CPU dynamic energy consumes up to\n44% of the total dynamic energy at large batch sizes. Based on the profiling\ninsights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching\n(CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and\nheterogeneous agentic workloads respectively to demonstrate the potential to\nimprove the performance, efficiency, and scalability of agentic AI. We achieve\nup to 2.1x and 1.41x P50 latency speedup compared to the multi-processing\nbenchmark for homogeneous and heterogeneous agentic workloads respectively.", "AI": {"tldr": "\u672c\u6587\u4eceCPU\u89c6\u89d2\u5206\u6790\u667a\u80fdAI\u5de5\u4f5c\u8d1f\u8f7d\u7cfb\u7edf\u74f6\u9888\uff0c\u5bf9\u5176\u8fdb\u884c\u8868\u5f81\uff0c\u9009\u53d6\u4ee3\u8868\u6027\u5de5\u4f5c\u8d1f\u8f7d\u8fdb\u884c\u6027\u80fd\u6307\u6807\u5206\u6790\uff0c\u63d0\u51fa\u4f18\u5316\u65b9\u6cd5\u5e76\u53d6\u5f97\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4ece\u88ab\u5ffd\u89c6\u7684CPU\u89c6\u89d2\u6765\u8868\u5f81\u548c\u7406\u89e3\u667a\u80fdAI\u5de5\u4f5c\u8d1f\u8f7d\u5f15\u5165\u7684\u7cfb\u7edf\u74f6\u9888\u3002", "method": "\u5148\u5bf9\u667a\u80fdAI\u8fdb\u884c\u7cfb\u7edf\u8868\u5f81\uff0c\u9009\u53d6\u4e94\u4e2a\u4ee3\u8868\u6027\u5de5\u4f5c\u8d1f\u8f7d\u5206\u6790CPU\u548cGPU\u5bf9\u6027\u80fd\u6307\u6807\u7684\u5f71\u54cd\uff0c\u57fa\u4e8e\u5206\u6790\u7ed3\u679c\u63d0\u51faCGAM\u548cMAWS\u4e24\u79cd\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5de5\u5177\u5904\u7406\u5728CPU\u4e0a\u5360\u603b\u5ef6\u8fdf\u6700\u9ad8\u8fbe90.6%\uff1b\u667a\u80fd\u541e\u5410\u91cf\u53d7CPU\u6216GPU\u56e0\u7d20\u74f6\u9888\uff1bCPU\u52a8\u6001\u80fd\u91cf\u5728\u5927\u6279\u91cf\u65f6\u5360\u603b\u52a8\u6001\u80fd\u91cf\u6700\u9ad8\u8fbe44%\uff1b\u5728\u540c\u6784\u548c\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5206\u522b\u5b9e\u73b02.1\u500d\u548c1.41\u500dP50\u5ef6\u8fdf\u52a0\u901f\u3002", "conclusion": "\u63d0\u51fa\u7684CGAM\u548cMAWS\u4f18\u5316\u65b9\u6cd5\u80fd\u63d0\u5347\u667a\u80fdAI\u7684\u6027\u80fd\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.00839", "pdf": "https://arxiv.org/pdf/2511.00839", "abs": "https://arxiv.org/abs/2511.00839", "authors": ["John Yang", "Kilian Lieret", "Joyce Yang", "Carlos E. Jimenez", "Ofir Press", "Ludwig Schmidt", "Diyi Yang"], "title": "CodeClash: Benchmarking Goal-Oriented Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Current benchmarks for coding evaluate language models (LMs) on concrete,\nwell-specified tasks such as fixing specific bugs or writing targeted tests.\nHowever, human programmers do not spend all day incessantly addressing isolated\ntasks. Instead, real-world software development is grounded in the pursuit of\nhigh-level goals, like improving user retention or reducing costs. Evaluating\nwhether LMs can also iteratively develop code to better accomplish open-ended\nobjectives without any explicit guidance remains an open challenge. To address\nthis, we introduce CodeClash, a benchmark where LMs compete in multi-round\ntournaments to build the best codebase for achieving a competitive objective.\nEach round proceeds in two phases: agents edit their code, then their codebases\ncompete head-to-head in a code arena that determines winners based on\nobjectives like score maximization, resource acquisition, or survival. Whether\nit's writing notes, scrutinizing documentation, analyzing competition logs, or\ncreating test suites, models must decide for themselves how to improve their\ncodebases both absolutely and against their opponents. We run 1680 tournaments\n(25,200 rounds total) to evaluate 8 LMs across 6 arenas. Our results reveal\nthat while models exhibit diverse development styles, they share fundamental\nlimitations in strategic reasoning. Models also struggle with long-term\ncodebase maintenance, as repositories become progressively messy and redundant.\nThese limitations are stark: top models lose every round against expert human\nprogrammers. We open-source CodeClash to advance the study of autonomous,\ngoal-oriented code development.", "AI": {"tldr": "\u63d0\u51faCodeClash\u57fa\u51c6\u6d4b\u8bd5\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u76ee\u6807\u4e0b\u8fed\u4ee3\u5f00\u53d1\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u53d1\u73b0\u6a21\u578b\u6709\u6218\u7565\u63a8\u7406\u548c\u957f\u671f\u4ee3\u7801\u5e93\u7ef4\u62a4\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u9488\u5bf9\u5177\u4f53\u4efb\u52a1\uff0c\u800c\u73b0\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u662f\u8ffd\u6c42\u9ad8\u5c42\u6b21\u76ee\u6807\uff0c\u9700\u8bc4\u4f30\u6a21\u578b\u5728\u65e0\u660e\u786e\u6307\u5bfc\u4e0b\u5b9e\u73b0\u5f00\u653e\u5f0f\u76ee\u6807\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165CodeClash\u57fa\u51c6\uff0c\u8ba9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u9526\u6807\u8d5b\u4e2d\u6784\u5efa\u4ee3\u7801\u5e93\u7ade\u4e89\uff0c\u8fd0\u884c1680\u573a\u9526\u6807\u8d5b\u8bc4\u4f308\u4e2a\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5f00\u53d1\u98ce\u683c\u591a\u6837\uff0c\u4f46\u5b58\u5728\u6218\u7565\u63a8\u7406\u5c40\u9650\uff0c\u96be\u4ee5\u8fdb\u884c\u957f\u671f\u4ee3\u7801\u5e93\u7ef4\u62a4\uff0c\u9876\u7ea7\u6a21\u578b\u4e0d\u654c\u4eba\u7c7b\u4e13\u5bb6\u3002", "conclusion": "\u5f00\u6e90CodeClash\u4ee5\u63a8\u52a8\u81ea\u4e3b\u3001\u76ee\u6807\u5bfc\u5411\u7684\u4ee3\u7801\u5f00\u53d1\u7814\u7a76\u3002"}}
{"id": "2511.00070", "pdf": "https://arxiv.org/pdf/2511.00070", "abs": "https://arxiv.org/abs/2511.00070", "authors": ["Muhammad Bilal Awan", "Abdul Razzaq", "Abdul Shahid"], "title": "Benchmarking Generative AI Against Bayesian Optimization for Constrained Multi-Objective Inverse Design", "categories": ["cs.LG", "cs.AI", "90C29 (Primary), 68T07, 65K05 (Secondary)", "G.1.6; I.2.6; J.6"], "comment": "17 pages, 2 Figures", "summary": "This paper investigates the performance of Large Language Models (LLMs) as\ngenerative optimizers for solving constrained multi-objective regression tasks,\nspecifically within the challenging domain of inverse design\n(property-to-structure mapping). This problem, critical to materials\ninformatics, demands finding complex, feasible input vectors that lie on the\nPareto optimal front. While LLMs have demonstrated universal effectiveness\nacross generative and reasoning tasks, their utility in constrained,\ncontinuous, high-dimensional numerical spaces tasks they weren't explicitly\narchitected for remains an open research question. We conducted a rigorous\ncomparative study between established Bayesian Optimization (BO) frameworks and\na suite of fine-tuned LLMs and BERT models. For BO, we benchmarked the\nfoundational BoTorch Ax implementation against the state-of-the-art q-Expected\nHypervolume Improvement (qEHVI, BoTorchM). The generative approach involved\nfine-tuning models via Parameter-Efficient Fine-Tuning (PEFT), framing the\nchallenge as a regression problem with a custom output head. Our results show\nthat BoTorch qEHVI achieved perfect convergence (GD=0.0), setting the\nperformance ceiling. Crucially, the best-performing LLM (WizardMath-7B)\nachieved a Generational Distance (GD) of 1.21, significantly outperforming the\ntraditional BoTorch Ax baseline (GD=15.03). We conclude that specialized BO\nframeworks remain the performance leader for guaranteed convergence, but\nfine-tuned LLMs are validated as a promising, computationally fast alternative,\ncontributing essential comparative metrics to the field of AI-driven\noptimization. The findings have direct industrial applications in optimizing\nformulation design for resins, polymers, and paints, where multi-objective\ntrade-offs between mechanical, rheological, and chemical properties are\ncritical to innovation and production efficiency.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u751f\u6210\u5f0f\u4f18\u5316\u5668\u89e3\u51b3\u7ea6\u675f\u591a\u76ee\u6807\u56de\u5f52\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5bf9\u6bd4BO\u6846\u67b6\u548c\u5fae\u8c03\u7684LLMs\u53caBERT\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u4e13\u4e1aBO\u6846\u67b6\u6027\u80fd\u9886\u5148\uff0c\u5fae\u8c03LLMs\u662f\u6709\u6f5c\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u63a2\u7a76LLMs\u5728\u5176\u672a\u4e13\u95e8\u8bbe\u8ba1\u7684\u7ea6\u675f\u3001\u8fde\u7eed\u3001\u9ad8\u7ef4\u6570\u503c\u7a7a\u95f4\u4efb\u52a1\u4e2d\u7684\u6548\u7528\uff0c\u89e3\u51b3\u6750\u6599\u4fe1\u606f\u5b66\u4e2d\u9006\u8bbe\u8ba1\u7684\u5173\u952e\u95ee\u9898\u3002", "method": "\u5bf9\u65e2\u5b9a\u7684\u8d1d\u53f6\u65af\u4f18\u5316\uff08BO\uff09\u6846\u67b6\u548c\u4e00\u7cfb\u5217\u5fae\u8c03\u7684LLMs\u53caBERT\u6a21\u578b\u8fdb\u884c\u4e25\u683c\u5bf9\u6bd4\u7814\u7a76\uff0cBO\u91c7\u7528BoTorch Ax\u548cq - Expected Hypervolume Improvement\uff08qEHVI, BoTorchM\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u751f\u6210\u5f0f\u65b9\u6cd5\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u5fae\u8c03\u6a21\u578b\u3002", "result": "BoTorch qEHVI\u5b9e\u73b0\u5b8c\u7f8e\u6536\u655b\uff08GD = 0.0\uff09\uff0c\u6700\u4f73LLM\uff08WizardMath - 7B\uff09\u7684\u751f\u6210\u8ddd\u79bb\uff08GD\uff09\u4e3a1.21\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfBoTorch Ax\u57fa\u7ebf\uff08GD = 15.03\uff09\u3002", "conclusion": "\u4e13\u4e1aBO\u6846\u67b6\u4ecd\u662f\u4fdd\u8bc1\u6536\u655b\u7684\u6027\u80fd\u9886\u5148\u8005\uff0c\u4f46\u5fae\u8c03\u7684LLMs\u662f\u6709\u524d\u666f\u3001\u8ba1\u7b97\u5feb\u901f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7814\u7a76\u7ed3\u679c\u5bf9\u6811\u8102\u3001\u805a\u5408\u7269\u548c\u6d82\u6599\u914d\u65b9\u8bbe\u8ba1\u6709\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.00543", "pdf": "https://arxiv.org/pdf/2511.00543", "abs": "https://arxiv.org/abs/2511.00543", "authors": ["Yunchuan Guan", "Yu Liu", "Ke Zhou", "Hui Li", "Sen Jia", "Zhiqi Shen", "Ziyang Wang", "Xinglin Zhang", "Tao Chen", "Jenq-Neng Hwang", "Lei Li"], "title": "Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Recent advances in generative modeling enable neural networks to generate\nweights without relying on gradient-based optimization. However, current\nmethods are limited by issues of over-coupling and long-horizon. The former\ntightly binds weight generation with task-specific objectives, thereby limiting\nthe flexibility of the learned optimizer. The latter leads to inefficiency and\nlow accuracy during inference, caused by the lack of local constraints. In this\npaper, we propose Lo-Hp, a decoupled two-stage weight generation framework that\nenhances flexibility through learning various optimization policies. It adopts\na hybrid-policy sub-trajectory balance objective, which integrates on-policy\nand off-policy learning to capture local optimization policies. Theoretically,\nwe demonstrate that learning solely local optimization policies can address the\nlong-horizon issue while enhancing the generation of global optimal weights. In\naddition, we validate Lo-Hp's superior accuracy and inference efficiency in\ntasks that require frequent weight updates, such as transfer learning, few-shot\nlearning, domain generalization, and large language model adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLo - Hp\u6846\u67b6\u89e3\u51b3\u751f\u6210\u5f0f\u5efa\u6a21\u6743\u91cd\u751f\u6210\u95ee\u9898\uff0c\u9a8c\u8bc1\u5176\u5728\u591a\u4efb\u52a1\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0f\u5efa\u6a21\u6743\u91cd\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u8fc7\u8026\u5408\u548c\u957f\u89c6\u91ce\u95ee\u9898\uff0c\u9650\u5236\u4f18\u5316\u5668\u7075\u6d3b\u6027\u4e14\u63a8\u7406\u6548\u7387\u4f4e\u3001\u7cbe\u5ea6\u5dee\u3002", "method": "\u63d0\u51faLo - Hp\u89e3\u8026\u4e24\u9636\u6bb5\u6743\u91cd\u751f\u6210\u6846\u67b6\uff0c\u91c7\u7528\u6df7\u5408\u7b56\u7565\u5b50\u8f68\u8ff9\u5e73\u8861\u76ee\u6807\uff0c\u7ed3\u5408\u5728\u7ebf\u548c\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5b66\u4e60\u5c40\u90e8\u4f18\u5316\u7b56\u7565\u53ef\u89e3\u51b3\u957f\u89c6\u91ce\u95ee\u9898\u5e76\u63d0\u5347\u5168\u5c40\u6700\u4f18\u6743\u91cd\u751f\u6210\uff0c\u5b9e\u9a8c\u9a8c\u8bc1Lo - Hp\u5728\u9700\u9891\u7e41\u66f4\u65b0\u6743\u91cd\u4efb\u52a1\u4e2d\u7684\u9ad8\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "Lo - Hp\u6846\u67b6\u6709\u6548\u89e3\u51b3\u5f53\u524d\u65b9\u6cd5\u95ee\u9898\uff0c\u5728\u591a\u4efb\u52a1\u4e2d\u6709\u51fa\u8272\u8868\u73b0\u3002"}}
{"id": "2511.01496", "pdf": "https://arxiv.org/pdf/2511.01496", "abs": "https://arxiv.org/abs/2511.01496", "authors": ["Muneer Ahmad", "M Sadik Batcha", "Wasim Rashid", "Obaid Hafiz"], "title": "Calculating Web Impact Factor for University Websites of Jammu and Kashmir: A Study", "categories": ["cs.DL", "cs.IR"], "comment": "11 pages, Research Paper", "summary": "This paper examines and explores the web impact factor through a webometric\nstudy of the present 12 University Websites of Jammu and Kashmir. Identifies\nthe domain systems of the websites; analyzes the number of web pages and link\npages, and calculates the External Link WIF or simple web impact factor (WIF)\nand external web impact factor of all the University websites. Also reflects\nthat some university websites have higher number of web pages, but\ncorrespondingly their link pages are very small in number and websites fall\nbehind in their simple and external link web impact factor. It found that the\nCluster University of Jammu ranked 1 (0.9018) in Internal Link WIF of Websites\nin Jammu and Kashmir. Shri Mata Vaishno Devi University ranked 1 (0.7249) in\nExternal Link Web Impact Factor.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7f51\u7edc\u8ba1\u91cf\u7814\u7a76\u5206\u6790\u67e5\u8c1f\u548c\u514b\u4ec0\u7c73\u5c1412\u6240\u5927\u5b66\u7f51\u7ad9\u7684\u7f51\u7edc\u5f71\u54cd\u56e0\u5b50\uff0c\u786e\u5b9a\u7f51\u7ad9\u57df\u540d\u7cfb\u7edf\uff0c\u5206\u6790\u7f51\u9875\u548c\u94fe\u63a5\u9875\u9762\u6570\u91cf\u5e76\u8ba1\u7b97\u76f8\u5173\u5f71\u54cd\u56e0\u5b50\uff0c\u6307\u51fa\u90e8\u5206\u7f51\u7ad9\u95ee\u9898\u5e76\u7ed9\u51fa\u6392\u540d\u3002", "motivation": "\u5bf9\u67e5\u8c1f\u548c\u514b\u4ec0\u7c73\u5c1412\u6240\u5927\u5b66\u7f51\u7ad9\u7684\u7f51\u7edc\u5f71\u54cd\u56e0\u5b50\u8fdb\u884c\u7814\u7a76\u5206\u6790\u3002", "method": "\u8fdb\u884c\u7f51\u7edc\u8ba1\u91cf\u7814\u7a76\uff0c\u786e\u5b9a\u7f51\u7ad9\u57df\u540d\u7cfb\u7edf\uff0c\u5206\u6790\u7f51\u9875\u548c\u94fe\u63a5\u9875\u9762\u6570\u91cf\uff0c\u8ba1\u7b97\u7b80\u5355\u7f51\u7edc\u5f71\u54cd\u56e0\u5b50\u548c\u5916\u90e8\u7f51\u7edc\u5f71\u54cd\u56e0\u5b50\u3002", "result": "\u90e8\u5206\u5927\u5b66\u7f51\u7ad9\u7f51\u9875\u6570\u91cf\u591a\u4f46\u94fe\u63a5\u9875\u9762\u5c11\uff0c\u5f71\u54cd\u56e0\u5b50\u843d\u540e\uff1b\u67e5\u8c1f\u96c6\u7fa4\u5927\u5b66\u5728\u5185\u94fe\u7f51\u7edc\u5f71\u54cd\u56e0\u5b50\u6392\u540d\u7b2c1\uff0c\u4ec0\u91cc\u739b\u5854\u74e6\u4f0a\u4ec0\u8bfa\u5fb7\u7ef4\u5927\u5b66\u5728\u5916\u94fe\u7f51\u7edc\u5f71\u54cd\u56e0\u5b50\u6392\u540d\u7b2c1\u3002", "conclusion": "\u901a\u8fc7\u7814\u7a76\u660e\u786e\u4e86\u5404\u5927\u5b66\u7f51\u7ad9\u7684\u7f51\u7edc\u5f71\u54cd\u56e0\u5b50\u60c5\u51b5\u53ca\u6392\u540d\u3002"}}
{"id": "2511.00751", "pdf": "https://arxiv.org/pdf/2511.00751", "abs": "https://arxiv.org/abs/2511.00751", "authors": ["Chiyan Loo"], "title": "Reevaluating Self-Consistency Scaling in Multi-Agent Systems", "categories": ["cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "This study examines the trade-offs of increasing sampled reasoning paths in\nself-consistency for modern large language models (LLMs). Earlier research with\nolder models showed that combining multiple reasoning chains improves results\nbefore reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we\nrevisit those claims under current model conditions. Each configuration pooled\noutputs from varying sampled reasoning paths and compared them to a single\nchain-of-thought (CoT) baseline. Larger models exhibited a more stable and\nconsistent improvement curve. The results confirm that performance gains taper\noff after moderate sampling, aligning with past findings. This plateau suggests\ndiminishing returns driven by overlap among reasoning paths. Self-consistency\nremains useful, but high-sample configurations offer little benefit relative to\ntheir computational cost.", "AI": {"tldr": "\u7814\u7a76\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u4e00\u81f4\u6027\u4e2d\u589e\u52a0\u91c7\u6837\u63a8\u7406\u8def\u5f84\u7684\u6743\u8861\uff0c\u7528Gemini 2.5\u6a21\u578b\u5b9e\u9a8c\uff0c\u7ed3\u679c\u4e0e\u8fc7\u5f80\u4e00\u81f4\uff0c\u5927\u91cf\u91c7\u6837\u6536\u76ca\u9012\u51cf\u3002", "motivation": "\u5728\u5f53\u524d\u6a21\u578b\u6761\u4ef6\u4e0b\uff0c\u91cd\u65b0\u9a8c\u8bc1\u65e9\u671f\u5173\u4e8e\u7ed3\u5408\u591a\u4e2a\u63a8\u7406\u94fe\u80fd\u63d0\u5347\u7ed3\u679c\u7684\u8bf4\u6cd5\u3002", "method": "\u5728HotpotQA\u548cMath - 500\u4e0a\u4f7f\u7528Gemini 2.5\u6a21\u578b\uff0c\u5c06\u4e0d\u540c\u91c7\u6837\u63a8\u7406\u8def\u5f84\u7684\u8f93\u51fa\u6c47\u603b\u5e76\u4e0e\u5355\u601d\u7ef4\u94fe\u57fa\u7ebf\u5bf9\u6bd4\u3002", "result": "\u8f83\u5927\u6a21\u578b\u6709\u66f4\u7a33\u5b9a\u4e00\u81f4\u7684\u6539\u8fdb\u66f2\u7ebf\uff0c\u9002\u5ea6\u91c7\u6837\u540e\u6027\u80fd\u63d0\u5347\u53d8\u7f13\uff0c\u4e0e\u8fc7\u53bb\u53d1\u73b0\u4e00\u81f4\u3002", "conclusion": "\u81ea\u4e00\u81f4\u6027\u4ecd\u6709\u7528\uff0c\u4f46\u9ad8\u91c7\u6837\u914d\u7f6e\u76f8\u5bf9\u8ba1\u7b97\u6210\u672c\u6536\u76ca\u4e0d\u5927\u3002"}}
{"id": "2511.00872", "pdf": "https://arxiv.org/pdf/2511.00872", "abs": "https://arxiv.org/abs/2511.00872", "authors": ["Zhuowen Yin", "Cuifeng Gao", "Chunsong Fan", "Wenzhang Yang", "Yinxing Xue", "Lijun Zhang"], "title": "A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric Software Engineering Tasks", "categories": ["cs.SE"], "comment": null, "summary": "Unlike traditional automation tools or static LLM-based systems, agents\ncombine decision-making and tool utilization to accomplish complex tasks,\nshowing great potential in software engineering. However, existing studies\nlargely focus on specific tasks or isolated aspects, providing an incomplete\npicture of agents' practical capabilities. To address this, we conduct a\ncomprehensive empirical study evaluating seven general-purpose agent frameworks\nacross three representative code-centric tasks: software development,\nvulnerability detection, and program repair. Each task is assessed using\nstandard, widely adopted benchmarks to ensure objective and comparable\nevaluation. Agent performance is systematically analyzed from three\ncomplementary perspectives: effectiveness (task success), efficiency (execution\nprocess), and overhead (token consumption). Our findings reveal distinct\ncapability patterns and trade-offs among the evaluated frameworks. In terms of\neffectiveness, agents achieve moderate overall performance. Regarding\nefficiency, AgentOrchestra tends to exhibit the longest trajectories and the\nmost correction attempts due to coordination overhead, whereas OpenHands\ndemonstrate stronger reflective reasoning abilities. For overhead, software\ndevelopment incurs the highest monetary cost, while GPTswarm remains the most\ncost-efficient. Furthermore, we conduct an in-depth cross-analysis of the\nrelationship between effectiveness and efficiency, exploring the underlying\nreasons behind their interplay. These findings guide both practical adoption\nand future research toward more efficient software engineering agents.", "AI": {"tldr": "\u5bf9\u4e03\u4e2a\u901a\u7528\u4ee3\u7406\u6846\u67b6\u5728\u4e09\u4e2a\u4ee3\u7801\u4e2d\u5fc3\u4efb\u52a1\u4e0a\u8fdb\u884c\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u5176\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u5f00\u9500\uff0c\u63ed\u793a\u80fd\u529b\u6a21\u5f0f\u548c\u6743\u8861\uff0c\u4e3a\u5b9e\u8df5\u548c\u7814\u7a76\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5b9e\u9645\u80fd\u529b\u7684\u8bc4\u4f30\u4e0d\u5b8c\u6574\uff0c\u9700\u5168\u9762\u7814\u7a76\u3002", "method": "\u5bf9\u4e03\u4e2a\u901a\u7528\u4ee3\u7406\u6846\u67b6\u5728\u8f6f\u4ef6\u5f00\u53d1\u3001\u6f0f\u6d1e\u68c0\u6d4b\u548c\u7a0b\u5e8f\u4fee\u590d\u4e09\u4e2a\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7528\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ece\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u5f00\u9500\u4e09\u4e2a\u89d2\u5ea6\u5206\u6790\u3002", "result": "\u5404\u6846\u67b6\u6709\u4e0d\u540c\u80fd\u529b\u6a21\u5f0f\u548c\u6743\u8861\uff0c\u6709\u6548\u6027\u4e0a\u603b\u4f53\u8868\u73b0\u4e2d\u7b49\uff0c\u6548\u7387\u4e0aAgentOrchestra\u8f68\u8ff9\u957f\u3001\u4fee\u6b63\u591a\uff0cOpenHands\u53cd\u601d\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u5f00\u9500\u4e0a\u8f6f\u4ef6\u5f00\u53d1\u6210\u672c\u9ad8\uff0cGPTswarm\u6700\u5177\u6210\u672c\u6548\u76ca\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u5b9e\u9645\u5e94\u7528\u548c\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2511.00071", "pdf": "https://arxiv.org/pdf/2511.00071", "abs": "https://arxiv.org/abs/2511.00071", "authors": ["Ertugrul Mutlu"], "title": "Wavelet-Based Feature Extraction and Unsupervised Clustering for Parity Detection: A Feature Engineering Perspective", "categories": ["cs.LG", "eess.SP"], "comment": "8 pages, 2 figures. Code:\n  github.com/Ertugrulmutlu/Using-Wavelets-and-Clustering-to-Predict-Odd-or-Even-Numbers", "summary": "This paper explores a deliberately over-engineered approach to the classical\nproblem of parity detection -- determining whether a number is odd or even --\nby combining wavelet-based feature extraction with unsupervised clustering.\nInstead of relying on modular arithmetic, integers are transformed into\nwavelet-domain representations, from which multi-scale statistical features are\nextracted and clustered using the k-means algorithm. The resulting feature\nspace reveals meaningful structural differences between odd and even numbers,\nachieving a classification accuracy of approximately 69.67% without any label\nsupervision. These results suggest that classical signal-processing techniques,\noriginally designed for continuous data, can uncover latent structure even in\npurely discrete symbolic domains. Beyond parity detection, the study provides\nan illustrative perspective on how feature engineering and clustering may be\nrepurposed for unconventional machine learning problems, potentially bridging\nsymbolic reasoning and feature-based learning.", "AI": {"tldr": "\u672c\u6587\u7ed3\u5408\u5c0f\u6ce2\u7279\u5f81\u63d0\u53d6\u548c\u65e0\u76d1\u7763\u805a\u7c7b\u5904\u7406\u5947\u5076\u68c0\u6d4b\u95ee\u9898\uff0c\u4e0d\u4f9d\u8d56\u6a21\u8fd0\u7b97\uff0c\u5728\u65e0\u76d1\u7763\u4e0b\u5b9e\u73b0\u7ea669.67%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8868\u660e\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u6280\u672f\u53ef\u7528\u4e8e\u79bb\u6563\u7b26\u53f7\u9886\u57df\u3002", "motivation": "\u63a2\u7d22\u7528\u8fc7\u5ea6\u5de5\u7a0b\u5316\u65b9\u6cd5\u89e3\u51b3\u7ecf\u5178\u5947\u5076\u68c0\u6d4b\u95ee\u9898\uff0c\u7814\u7a76\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u6280\u672f\u5728\u79bb\u6563\u7b26\u53f7\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u5c06\u6574\u6570\u8f6c\u6362\u4e3a\u5c0f\u6ce2\u57df\u8868\u793a\uff0c\u63d0\u53d6\u591a\u5c3a\u5ea6\u7edf\u8ba1\u7279\u5f81\uff0c\u7528k - means\u7b97\u6cd5\u805a\u7c7b\u3002", "result": "\u5728\u65e0\u76d1\u7763\u4e0b\u5206\u7c7b\u51c6\u786e\u7387\u7ea6\u4e3a69.67%\u3002", "conclusion": "\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u6280\u672f\u53ef\u63ed\u793a\u79bb\u6563\u7b26\u53f7\u9886\u57df\u7684\u6f5c\u5728\u7ed3\u6784\uff0c\u4e3a\u975e\u5e38\u89c4\u673a\u5668\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u65b0\u601d\u8def\uff0c\u6709\u671b\u8fde\u63a5\u7b26\u53f7\u63a8\u7406\u548c\u57fa\u4e8e\u7279\u5f81\u7684\u5b66\u4e60\u3002"}}
{"id": "2511.00579", "pdf": "https://arxiv.org/pdf/2511.00579", "abs": "https://arxiv.org/abs/2511.00579", "authors": ["G. Pillonetto", "A. Giaretta", "A. Aravkin", "M. Bisiacco", "T. Elston"], "title": "Sparse and nonparametric estimation of equations governing dynamical systems with applications to biology", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "comment": null, "summary": "Data-driven discovery of model equations is a powerful approach for\nunderstanding the behavior of dynamical systems in many scientific fields. In\nparticular, the ability to learn mathematical models from data would benefit\nsystems biology, where the complex nature of these systems often makes a bottom\nup approach to modeling unfeasible. In recent years, sparse estimation\ntechniques have gained prominence in system identification, primarily using\nparametric paradigms to efficiently capture system dynamics with minimal model\ncomplexity. In particular, the Sindy algorithm has successfully used sparsity\nto estimate nonlinear systems by extracting from a library of functions only a\nfew key terms needed to capture the dynamics of these systems. However,\nparametric models often fall short in accurately representing certain\nnonlinearities inherent in complex systems. To address this limitation, we\nintroduce a novel framework that integrates sparse parametric estimation with\nnonparametric techniques. It captures nonlinearities that Sindy cannot describe\nwithout requiring a priori information about their functional form. That is,\nwithout expanding the library of functions to include the one that is trying to\nbe discovered. We illustrate our approach on several examples related to\nestimation of complex biological phenomena.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u7a00\u758f\u53c2\u6570\u4f30\u8ba1\u4e0e\u975e\u53c2\u6570\u6280\u672f\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u6570\u636e\u9a71\u52a8\u53d1\u73b0\u6a21\u578b\u65b9\u7a0b\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u7cfb\u7edf\u975e\u7ebf\u6027\u8868\u793a\u4e0a\u7684\u5c40\u9650\uff0c\u5e76\u5728\u751f\u7269\u73b0\u8c61\u4f30\u8ba1\u793a\u4f8b\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u53c2\u6570\u6a21\u578b\u5728\u51c6\u786e\u8868\u793a\u590d\u6742\u7cfb\u7edf\u7684\u67d0\u4e9b\u975e\u7ebf\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e3a\u89e3\u51b3\u6b64\u5c40\u9650\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5c06\u7a00\u758f\u53c2\u6570\u4f30\u8ba1\u4e0e\u975e\u53c2\u6570\u6280\u672f\u76f8\u7ed3\u5408\u7684\u65b0\u6846\u67b6\u3002", "result": "\u6846\u67b6\u80fd\u6355\u6349Sindy\u7b97\u6cd5\u65e0\u6cd5\u63cf\u8ff0\u7684\u975e\u7ebf\u6027\uff0c\u4e14\u65e0\u9700\u5173\u4e8e\u5176\u51fd\u6570\u5f62\u5f0f\u7684\u5148\u9a8c\u4fe1\u606f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u7528\u4e8e\u590d\u6742\u751f\u7269\u73b0\u8c61\u7684\u4f30\u8ba1\u3002"}}
{"id": "2511.01617", "pdf": "https://arxiv.org/pdf/2511.01617", "abs": "https://arxiv.org/abs/2511.01617", "authors": ["Mohamed Eltahir", "Ali Habibullah", "Lama Ayash", "Tanveer Hussain", "Naeemullah Khan"], "title": "Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers", "categories": ["cs.CV", "cs.IR"], "comment": null, "summary": "In the retrieval domain, candidates' fusion from heterogeneous retrievers is\na long-standing challenge, particularly for complex, multi-modal data such as\nvideos. While typical fusion techniques are training-free, they rely solely on\nrank or score signals, disregarding candidates' representations. This work\nintroduces Vote-in-Context (ViC), a generalized, training-free framework that\nre-thinks list-wise reranking and fusion as a zero-shot reasoning task for a\nVision-Language Model (VLM). The core insight is to serialize both content\nevidence and retriever metadata directly within the VLM's prompt, allowing the\nmodel to adaptively weigh retriever consensus against visual-linguistic\ncontent. We demonstrate the generality of this framework by applying it to the\nchallenging domain of cross-modal video retrieval. To this end, we introduce\nthe S-Grid, a compact serialization map that represents each video as an image\ngrid, optionally paired with subtitles to enable list-wise reasoning over video\ncandidates. ViC is evaluated both as a single-list reranker, where it\ndramatically improves the precision of individual retrievers, and as an\nensemble fuser, where it consistently outperforms strong baselines like\nCombSUM. Across video retrieval benchmarks including ActivityNet and VATEX, the\nframework establishes new state-of-the-art zero-shot retrieval performance,\ndemonstrating its effectiveness in handling complex visual and temporal signals\nalongside text. In zero-shot settings, ViC achieves Recall@1 scores of 87.1%\n(t2v) / 89.0% (v2t) on MSR-VTT and 99.6% (v2t) on VATEX, representing massive\ngains of up to +40 Recall@1 over previous state-of-the-art baselines. We\npresent ViC as a simple, reproducible, and highly effective recipe for turning\nmodern VLMs into powerful zero-shot rerankers and fusers. Code and resources\nare publicly available at: https://github.com/mohammad2012191/ViC", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVote - in - Context (ViC)\u6846\u67b6\uff0c\u5c06\u5217\u8868\u91cd\u6392\u548c\u878d\u5408\u89c6\u4e3a\u96f6\u6837\u672c\u63a8\u7406\u4efb\u52a1\uff0c\u5e94\u7528\u4e8e\u8de8\u6a21\u6001\u89c6\u9891\u68c0\u7d22\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u65b0\u7684\u96f6\u6837\u672c\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5728\u68c0\u7d22\u9886\u57df\uff0c\u5f02\u6784\u68c0\u7d22\u5668\u5019\u9009\u7ed3\u679c\u7684\u878d\u5408\u662f\u957f\u671f\u6311\u6218\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u89c6\u9891\u7b49\u590d\u6742\u591a\u6a21\u6001\u6570\u636e\uff0c\u73b0\u6709\u5178\u578b\u878d\u5408\u6280\u672f\u4ec5\u4f9d\u8d56\u6392\u540d\u6216\u5206\u6570\u4fe1\u53f7\uff0c\u5ffd\u7565\u5019\u9009\u8868\u793a\u3002", "method": "\u5f15\u5165ViC\u6846\u67b6\uff0c\u5c06\u5185\u5bb9\u8bc1\u636e\u548c\u68c0\u7d22\u5668\u5143\u6570\u636e\u5e8f\u5217\u5316\u5230\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u63d0\u793a\u4e2d\uff0c\u4f7f\u7528S - Grid\u8868\u793a\u89c6\u9891\uff0c\u8fdb\u884c\u5217\u8868\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u89c6\u9891\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cViC\u4f5c\u4e3a\u5355\u5217\u8868\u91cd\u6392\u5668\u663e\u8457\u63d0\u9ad8\u5355\u4e2a\u68c0\u7d22\u5668\u7684\u7cbe\u5ea6\uff0c\u4f5c\u4e3a\u96c6\u6210\u878d\u5408\u5668\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u53d6\u5f97\u9ad8\u53ec\u56de\u7387\u3002", "conclusion": "ViC\u662f\u5c06\u73b0\u4ee3VLM\u8f6c\u53d8\u4e3a\u5f3a\u5927\u96f6\u6837\u672c\u91cd\u6392\u5668\u548c\u878d\u5408\u5668\u7684\u7b80\u5355\u3001\u53ef\u590d\u73b0\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.00758", "pdf": "https://arxiv.org/pdf/2511.00758", "abs": "https://arxiv.org/abs/2511.00758", "authors": ["Hong Su"], "title": "Active Thinking Model: A Goal-Directed Self-Improving Framework for Real-World Adaptive Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "Real-world artificial intelligence (AI) systems are increasingly required to\noperate autonomously in dynamic, uncertain, and continuously changing\nenvironments. However, most existing AI models rely on predefined objectives,\nstatic training data, and externally supplied feedback, which restrict their\nability to adapt, reflect, and improve independently. In this paper, we propose\nthe Active Thinking Model (ATM)- a unified cognitive framework that integrates\ngoal reasoning, dynamic task generation, and self-reflective learning into an\nadaptive architecture. Unlike conventional systems that passively execute fixed\nprocedures, ATM actively evaluates its performance through logical reasoning\nand environmental indicators, reuses effective methods to solve new problems,\nand generates novel strategies for unseen situations via a continuous\nself-improvement loop. A mathematically grounded theoretical analysis\ndemonstrates that ATM can autonomously evolve from suboptimal to optimal\nbehavior without external supervision and maintain bounded tracking regret\nunder changing environmental conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e3b\u52a8\u601d\u8003\u6a21\u578b\uff08ATM\uff09\uff0c\u53ef\u8ba9AI\u7cfb\u7edf\u5728\u65e0\u5916\u90e8\u76d1\u7763\u4e0b\u81ea\u4e3b\u4ece\u6b21\u4f18\u884c\u4e3a\u8fdb\u5316\u5230\u6700\u4f18\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709AI\u6a21\u578b\u4f9d\u8d56\u9884\u5b9a\u4e49\u76ee\u6807\u3001\u9759\u6001\u8bad\u7ec3\u6570\u636e\u548c\u5916\u90e8\u53cd\u9988\uff0c\u9650\u5236\u81ea\u4e3b\u9002\u5e94\u3001\u53cd\u601d\u548c\u6539\u8fdb\u80fd\u529b\uff0c\u9700\u65b0\u6a21\u578b\u5e94\u5bf9\u52a8\u6001\u73af\u5883\u3002", "method": "\u63d0\u51faATM\u7edf\u4e00\u8ba4\u77e5\u6846\u67b6\uff0c\u5c06\u76ee\u6807\u63a8\u7406\u3001\u52a8\u6001\u4efb\u52a1\u751f\u6210\u548c\u81ea\u6211\u53cd\u601d\u5b66\u4e60\u96c6\u6210\u5230\u81ea\u9002\u5e94\u67b6\u6784\u4e2d\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u548c\u73af\u5883\u6307\u6807\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u6570\u5b66\u7406\u8bba\u5206\u6790\u8868\u660eATM\u53ef\u5728\u65e0\u5916\u90e8\u76d1\u7763\u4e0b\u4ece\u6b21\u4f18\u8fdb\u5316\u5230\u6700\u4f18\u884c\u4e3a\uff0c\u5728\u73af\u5883\u53d8\u5316\u65f6\u4fdd\u6301\u6709\u754c\u8ddf\u8e2a\u9057\u61be\u3002", "conclusion": "ATM\u80fd\u4f7fAI\u7cfb\u7edf\u5728\u52a8\u6001\u3001\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u81ea\u4e3b\u9002\u5e94\u548c\u6539\u8fdb\u3002"}}
{"id": "2511.00901", "pdf": "https://arxiv.org/pdf/2511.00901", "abs": "https://arxiv.org/abs/2511.00901", "authors": ["Vincenzo De Martino", "Stefano Lambiase", "Fabiano Pecorelli", "Willem-Jan van den Heuvel", "Filomena Ferrucci", "Fabio Palomba"], "title": "Sustainability of Machine Learning-Enabled Systems: The Machine Learning Practitioner's Perspective", "categories": ["cs.SE"], "comment": null, "summary": "Software sustainability is a key multifaceted non-functional requirement that\nencompasses environmental, social, and economic concerns, yet its integration\ninto the development of Machine Learning (ML)-enabled systems remains an open\nchallenge. While previous research has explored high-level sustainability\nprinciples and policy recommendations, limited empirical evidence exists on how\nsustainability is practically managed in ML workflows. Existing studies\npredominantly focus on environmental sustainability, e.g., carbon footprint\nreduction, while missing the broader spectrum of sustainability dimensions and\nthe challenges practitioners face in real-world settings. To address this gap,\nwe conduct an empirical study to characterize sustainability in ML-enabled\nsystems from a practitioner's perspective. We investigate (1) how ML engineers\nperceive and describe sustainability, (2) the software engineering practices\nthey adopt to support it, and (3) the key challenges hindering its adoption. We\nfirst perform a qualitative analysis based on interviews with eight experienced\nML engineers, followed by a large-scale quantitative survey with 203 ML\npractitioners. Our key findings reveal a significant disconnection between\nsustainability awareness and its systematic implementation, highlighting the\nneed for more structured guidelines, measurement frameworks, and regulatory\nsupport.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u5b9e\u8df5\u7ba1\u7406\u7684\u5b9e\u8bc1\u7814\u7a76\u4e0d\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u8bbf\u8c08\u548c\u8c03\u67e5\u7814\u7a76\u4ece\u4e1a\u8005\u89c6\u89d2\u4e0b\u7684\u53ef\u6301\u7eed\u6027\uff0c\u53d1\u73b0\u610f\u8bc6\u4e0e\u5b9e\u65bd\u8131\u8282\uff0c\u9700\u66f4\u591a\u6307\u5bfc\u548c\u652f\u6301\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u7f3a\u4e4f\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\u53ef\u6301\u7eed\u6027\u5b9e\u8df5\u7ba1\u7406\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u4e14\u591a\u5173\u6ce8\u73af\u5883\u53ef\u6301\u7eed\u6027\uff0c\u5ffd\u7565\u5176\u4ed6\u7ef4\u5ea6\u548c\u5b9e\u9645\u6311\u6218\uff0c\u56e0\u6b64\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5148\u5bf98\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u8fdb\u884c\u8bbf\u8c08\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u518d\u5bf9203\u4f4d\u4ece\u4e1a\u8005\u8fdb\u884c\u5927\u89c4\u6a21\u5b9a\u91cf\u8c03\u67e5\u3002", "result": "\u53d1\u73b0\u53ef\u6301\u7eed\u6027\u610f\u8bc6\u548c\u7cfb\u7edf\u5b9e\u65bd\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u8131\u8282\u3002", "conclusion": "\u9700\u8981\u66f4\u7ed3\u6784\u5316\u7684\u6307\u5357\u3001\u6d4b\u91cf\u6846\u67b6\u548c\u76d1\u7ba1\u652f\u6301\u3002"}}
{"id": "2511.00076", "pdf": "https://arxiv.org/pdf/2511.00076", "abs": "https://arxiv.org/abs/2511.00076", "authors": ["Zihao Wan", "Pau Tong Lin Xu", "Fuwen Luo", "Ziyue Wang", "Peng Li", "Yang Liu"], "title": "Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with B\u00e9zier Curves", "categories": ["cs.LG"], "comment": null, "summary": "While Vision-language Models (VLMs) have demonstrated strong semantic\ncapabilities, their ability to interpret the underlying geometric structure of\nvisual information is less explored. Pictographic characters, which combine\nvisual form with symbolic structure, provide an ideal test case for this\ncapability. We formulate this visual recognition challenge in the mathematical\ndomain, where each character is represented by an executable program of\ngeometric primitives. This is framed as a program synthesis task, training a\nVLM to decompile raster images into programs composed of B\\'ezier curves. Our\nmodel, acting as a \"visual decompiler\", demonstrates performance superior to\nstrong zero-shot baselines, including GPT-4o. The most significant finding is\nthat when trained solely on modern Chinese characters, the model is able to\nreconstruct ancient Oracle Bone Script in a zero-shot context. This\ngeneralization provides strong evidence that the model acquires an abstract and\ntransferable geometric grammar, moving beyond pixel-level pattern recognition\nto a more structured form of visual understanding.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u8c61\u5f62\u6587\u5b57\u6d4b\u8bd5\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u89e3\u8bfb\u89c6\u89c9\u4fe1\u606f\u51e0\u4f55\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u5c06\u5176\u8f6c\u5316\u4e3a\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u96f6\u6837\u672c\u57fa\u7ebf\uff0c\u4e14\u80fd\u96f6\u6837\u672c\u91cd\u6784\u7532\u9aa8\u6587\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u89e3\u8bfb\u89c6\u89c9\u4fe1\u606f\u6f5c\u5728\u51e0\u4f55\u7ed3\u6784\u7684\u80fd\u529b\u63a2\u7d22\u8f83\u5c11\uff0c\u8c61\u5f62\u6587\u5b57\u53ef\u4f5c\u4e3a\u6d4b\u8bd5\u8be5\u80fd\u529b\u7684\u7406\u60f3\u6848\u4f8b\u3002", "method": "\u5c06\u89c6\u89c9\u8bc6\u522b\u6311\u6218\u8f6c\u5316\u4e3a\u6570\u5b66\u9886\u57df\u7684\u7a0b\u5e8f\u5408\u6210\u4efb\u52a1\uff0c\u8bad\u7ec3VLM\u5c06\u5149\u6805\u56fe\u50cf\u53cd\u7f16\u8bd1\u4e3a\u8d1d\u585e\u5c14\u66f2\u7ebf\u7ec4\u6210\u7684\u7a0b\u5e8f\u3002", "result": "\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5305\u62ecGPT - 4o\u5728\u5185\u7684\u5f3a\u96f6\u6837\u672c\u57fa\u7ebf\uff0c\u80fd\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u91cd\u6784\u7532\u9aa8\u6587\u3002", "conclusion": "\u6a21\u578b\u83b7\u5f97\u4e86\u62bd\u8c61\u4e14\u53ef\u8fc1\u79fb\u7684\u51e0\u4f55\u8bed\u6cd5\uff0c\u8d85\u8d8a\u50cf\u7d20\u7ea7\u6a21\u5f0f\u8bc6\u522b\uff0c\u5b9e\u73b0\u66f4\u7ed3\u6784\u5316\u7684\u89c6\u89c9\u7406\u89e3\u3002"}}
{"id": "2511.00617", "pdf": "https://arxiv.org/pdf/2511.00617", "abs": "https://arxiv.org/abs/2511.00617", "authors": ["Eric Bigelow", "Daniel Wurgaft", "YingQiao Wang", "Noah Goodman", "Tomer Ullman", "Hidenori Tanaka", "Ekdeep Singh Lubana"], "title": "Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large language models (LLMs) can be controlled at inference time through\nprompts (in-context learning) and internal activations (activation steering).\nDifferent accounts have been proposed to explain these methods, yet their\ncommon goal of controlling model behavior raises the question of whether these\nseemingly disparate methodologies can be seen as specific instances of a\nbroader framework. Motivated by this, we develop a unifying, predictive account\nof LLM control from a Bayesian perspective. Specifically, we posit that both\ncontext- and activation-based interventions impact model behavior by altering\nits belief in latent concepts: steering operates by changing concept priors,\nwhile in-context learning leads to an accumulation of evidence. This results in\na closed-form Bayesian model that is highly predictive of LLM behavior across\ncontext- and activation-based interventions in a set of domains inspired by\nprior work on many-shot in-context learning. This model helps us explain prior\nempirical phenomena - e.g., sigmoidal learning curves as in-context evidence\naccumulates - while predicting novel ones - e.g., additivity of both\ninterventions in log-belief space, which results in distinct phases such that\nsudden and dramatic behavioral shifts can be induced by slightly changing\nintervention controls. Taken together, this work offers a unified account of\nprompt-based and activation-based control of LLM behavior, and a methodology\nfor empirically predicting the effects of these interventions.", "AI": {"tldr": "\u672c\u6587\u4ece\u8d1d\u53f6\u65af\u89c6\u89d2\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u89e3\u91ca\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u793a\u548c\u6fc0\u6d3b\u63a7\u5236\u65b9\u6cd5\uff0c\u6a21\u578b\u80fd\u9884\u6d4b\u6a21\u578b\u884c\u4e3a\u5e76\u89e3\u91ca\u548c\u9884\u6d4b\u73b0\u8c61\u3002", "motivation": "\u63a2\u7a76\u63d0\u793a\u548c\u6fc0\u6d3b\u4e24\u79cd\u63a7\u5236\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u80fd\u5426\u7eb3\u5165\u66f4\u5e7f\u6cdb\u6846\u67b6\u3002", "method": "\u4ece\u8d1d\u53f6\u65af\u89c6\u89d2\u6784\u5efa\u7edf\u4e00\u3001\u53ef\u9884\u6d4b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a7\u5236\u89e3\u91ca\uff0c\u8ba4\u4e3a\u4e24\u79cd\u5e72\u9884\u901a\u8fc7\u6539\u53d8\u6f5c\u5728\u6982\u5ff5\u4fe1\u5ff5\u5f71\u54cd\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u5f97\u5230\u7684\u8d1d\u53f6\u65af\u6a21\u578b\u80fd\u9ad8\u5ea6\u9884\u6d4b\u591a\u9886\u57df\u6a21\u578b\u884c\u4e3a\uff0c\u89e3\u91ca\u7ecf\u9a8c\u73b0\u8c61\u5e76\u9884\u6d4b\u65b0\u73b0\u8c61\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u63d0\u793a\u548c\u6fc0\u6d3b\u63a7\u5236\u884c\u4e3a\u7684\u7edf\u4e00\u89e3\u91ca\u53ca\u9884\u6d4b\u5e72\u9884\u6548\u679c\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.01643", "pdf": "https://arxiv.org/pdf/2511.01643", "abs": "https://arxiv.org/abs/2511.01643", "authors": ["Riccardo Campi", "Nicol\u00f2 Oreste Pinciroli Vago", "Mathyas Giudici", "Pablo Barrachina Rodriguez-Guisado", "Marco Brambilla", "Piero Fraternali"], "title": "A Graph-based RAG for Energy Efficiency Question Answering", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2.7; I.2.4; I.2.1; I.2.6"], "comment": null, "summary": "In this work, we investigate the use of Large Language Models (LLMs) within a\ngraph-based Retrieval Augmented Generation (RAG) architecture for Energy\nEfficiency (EE) Question Answering. First, the system automatically extracts a\nKnowledge Graph (KG) from guidance and regulatory documents in the energy\nfield. Then, the generated graph is navigated and reasoned upon to provide\nusers with accurate answers in multiple languages. We implement a human-based\nvalidation using the RAGAs framework properties, a validation dataset\ncomprising 101 question-answer pairs, and domain experts. Results confirm the\npotential of this architecture and identify its strengths and weaknesses.\nValidation results show how the system correctly answers in about three out of\nfour of the cases (75.2 +- 2.7%), with higher results on questions related to\nmore general EE answers (up to 81.0 +- 4.1%), and featuring promising\nmultilingual abilities (4.4% accuracy loss due to translation).", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u67b6\u6784\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u80fd\u6e90\u6548\u7387\u95ee\u7b54\u7684\u6548\u679c\uff0c\u5b9e\u73b0\u7cfb\u7edf\u5e76\u9a8c\u8bc1\uff0c\u786e\u8ba4\u67b6\u6784\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u67b6\u6784\u4e2d\u7528\u4e8e\u80fd\u6e90\u6548\u7387\u95ee\u7b54\u7684\u5e94\u7528\u3002", "method": "\u4ece\u80fd\u6e90\u9886\u57df\u6587\u6863\u81ea\u52a8\u63d0\u53d6\u77e5\u8bc6\u56fe\u8c31\uff0c\u5bfc\u822a\u548c\u63a8\u7406\u56fe\u8c31\u63d0\u4f9b\u591a\u8bed\u8a00\u7b54\u6848\uff0c\u7528RAGAs\u6846\u67b6\u5c5e\u6027\u3001\u9a8c\u8bc1\u6570\u636e\u96c6\u548c\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u4eba\u5de5\u9a8c\u8bc1\u3002", "result": "\u7cfb\u7edf\u7ea675.2 \u00b1 2.7%\u7684\u60c5\u51b5\u56de\u7b54\u6b63\u786e\uff0c\u901a\u7528\u80fd\u6e90\u6548\u7387\u95ee\u9898\u51c6\u786e\u7387\u8fbe81.0 \u00b1 4.1%\uff0c\u591a\u8bed\u8a00\u80fd\u529b\u67094.4%\u7684\u51c6\u786e\u7387\u635f\u5931\u3002", "conclusion": "\u786e\u8ba4\u4e86\u8be5\u67b6\u6784\u7684\u6f5c\u529b\uff0c\u4e5f\u8bc6\u522b\u51fa\u5176\u4f18\u7f3a\u70b9\u3002"}}
{"id": "2511.00763", "pdf": "https://arxiv.org/pdf/2511.00763", "abs": "https://arxiv.org/abs/2511.00763", "authors": ["Wanda Hou", "Leon Zhou", "Hong-Ye Hu", "Yi-Zhuang You", "Xiao-Liang Qi"], "title": "How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks", "categories": ["cs.AI"], "comment": null, "summary": "We investigate the performance of large language models on repetitive\ndeterministic prediction tasks and study how the sequence accuracy rate scales\nwith output length. Each such task involves repeating the same operation n\ntimes. Examples include letter replacement in strings following a given rule,\ninteger addition, and multiplication of string operators in many body quantum\nmechanics. If the model performs the task through a simple repetition\nalgorithm, the success rate should decay exponentially with sequence length. In\ncontrast, our experiments on leading large language models reveal a sharp\ndouble exponential drop beyond a characteristic length scale, forming an\naccuracy cliff that marks the transition from reliable to unstable generation.\nThis indicates that the models fail to execute each operation independently. To\nexplain this phenomenon, we propose a statistical physics inspired model that\ncaptures the competition between external conditioning from the prompt and\ninternal interference among generated tokens. The model quantitatively\nreproduces the observed crossover and provides an interpretable link between\nattention induced interference and sequence level failure. Fitting the model to\nempirical results across multiple models and tasks yields effective parameters\nthat characterize the intrinsic error rate and error accumulation factor for\neach model task pair, offering a principled framework for understanding the\nlimits of deterministic accuracy in large language models.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u590d\u786e\u5b9a\u6027\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\uff0c\u53d1\u73b0\u51c6\u786e\u7387\u60ac\u5d16\uff0c\u63d0\u51fa\u7edf\u8ba1\u7269\u7406\u542f\u53d1\u6a21\u578b\u89e3\u91ca\u5e76\u5f97\u5230\u6709\u6548\u53c2\u6570\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cd\u590d\u786e\u5b9a\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4ee5\u53ca\u5e8f\u5217\u51c6\u786e\u7387\u968f\u8f93\u51fa\u957f\u5ea6\u7684\u53d8\u5316\u89c4\u5f8b\u3002", "method": "\u5bf9\u9886\u5148\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u63d0\u51fa\u7edf\u8ba1\u7269\u7406\u542f\u53d1\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u51c6\u786e\u7387\u60ac\u5d16\uff0c\u6a21\u578b\u80fd\u5b9a\u91cf\u91cd\u73b0\u89c2\u6d4b\u5230\u7684\u8f6c\u53d8\uff0c\u5f97\u5230\u8868\u5f81\u6bcf\u4e2a\u6a21\u578b\u4efb\u52a1\u5bf9\u7684\u6709\u6548\u53c2\u6570\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u4e3a\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u786e\u5b9a\u6027\u51c6\u786e\u7387\u7684\u6781\u9650\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\u3002"}}
{"id": "2511.00915", "pdf": "https://arxiv.org/pdf/2511.00915", "abs": "https://arxiv.org/abs/2511.00915", "authors": ["Jukka Ruohonen", "Abhishek Tiwari"], "title": "Empirical Derivations from an Evolving Test Suite", "categories": ["cs.SE"], "comment": "Submitted", "summary": "The paper presents a longitudinal empirical analysis of the automated,\ncontinuous, and virtualization-based software test suite of the NetBSD\noperating system. The longitudinal period observed spans from the initial roll\nout of the test suite in the early 2010s to late 2025. According to the\nresults, the test suite has grown continuously, currently covering over ten\nthousand individual test cases. Failed test cases exhibit overall stability,\nalthough there have been shorter periods marked with more frequent failures. A\nsimilar observation applies to build failures, failures of the test suite to\ncomplete, and installation failures, all of which are also captured by the\nNetBSD's testing framework. Finally, code churn and kernel modifications do not\nprovide longitudinally consistent statistical explanations for the failures.\nAlthough some periods exhibit larger effects, including particularly with\nrespect to the kernel modifications, the effects are small on average. Even\nthough only in an exploratory manner, these empirical observations contribute\nto efforts to draw conclusions from large-scale and evolving software test\nsuites.", "AI": {"tldr": "\u5bf9NetBSD\u64cd\u4f5c\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u3001\u8fde\u7eed\u4e14\u57fa\u4e8e\u865a\u62df\u5316\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u8fdb\u884c\u7eb5\u5411\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0\u6d4b\u8bd5\u5957\u4ef6\u6301\u7eed\u589e\u957f\uff0c\u5404\u7c7b\u5931\u8d25\u60c5\u51b5\u603b\u4f53\u7a33\u5b9a\uff0c\u4ee3\u7801\u53d8\u52a8\u548c\u5185\u6838\u4fee\u6539\u5bf9\u5931\u8d25\u5f71\u54cd\u5c0f\u3002", "motivation": "\u5bf9NetBSD\u64cd\u4f5c\u7cfb\u7edf\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u8fdb\u884c\u7eb5\u5411\u7814\u7a76\uff0c\u4e3a\u4ece\u5927\u89c4\u6a21\u4e14\u4e0d\u65ad\u53d1\u5c55\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u5f97\u51fa\u7ed3\u8bba\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u5f00\u5c55\u4ece2010\u5e74\u4ee3\u521d\u52302025\u5e74\u672b\u7684\u7eb5\u5411\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u6d4b\u8bd5\u5957\u4ef6\u6301\u7eed\u589e\u957f\uff0c\u8986\u76d6\u8d85\u4e00\u4e07\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff1b\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\u603b\u4f53\u7a33\u5b9a\uff1b\u6784\u5efa\u5931\u8d25\u3001\u6d4b\u8bd5\u5957\u4ef6\u5b8c\u6210\u5931\u8d25\u548c\u5b89\u88c5\u5931\u8d25\u60c5\u51b5\u7c7b\u4f3c\uff1b\u4ee3\u7801\u53d8\u52a8\u548c\u5185\u6838\u4fee\u6539\u5bf9\u5931\u8d25\u65e0\u7eb5\u5411\u4e00\u81f4\u7684\u7edf\u8ba1\u89e3\u91ca\uff0c\u5f71\u54cd\u5e73\u5747\u8f83\u5c0f\u3002", "conclusion": "\u8fd9\u4e9b\u5b9e\u8bc1\u89c2\u5bdf\u867d\u5177\u63a2\u7d22\u6027\uff0c\u4f46\u6709\u52a9\u4e8e\u4ece\u5927\u89c4\u6a21\u4e14\u4e0d\u65ad\u53d1\u5c55\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u5f97\u51fa\u7ed3\u8bba\u3002"}}
{"id": "2511.00079", "pdf": "https://arxiv.org/pdf/2511.00079", "abs": "https://arxiv.org/abs/2511.00079", "authors": ["Maximilian Willer", "Peter Ruckdeschel"], "title": "flowengineR: A Modular and Extensible Framework for Fair and Reproducible Workflow Design in R", "categories": ["cs.LG", "cs.CY", "stat.ME", "62-04, 62-07", "D.2.11; G.3; I.2.6"], "comment": "27 pages, 7 figures, 1 table", "summary": "flowengineR is an R package designed to provide a modular and extensible\nframework for building reproducible algorithmic workflows for general-purpose\nmachine learning pipelines. It is motivated by the rapidly evolving field of\nalgorithmic fairness where new metrics, mitigation strategies, and machine\nlearning methods continuously emerge. A central challenge in fairness, but also\nfar beyond, is that existing toolkits either focus narrowly on single\ninterventions or treat reproducibility and extensibility as secondary\nconsiderations rather than core design principles. flowengineR addresses this\nby introducing a unified architecture of standardized engines for data\nsplitting, execution, preprocessing, training, inprocessing, postprocessing,\nevaluation, and reporting. Each engine encapsulates one methodological task yet\ncommunicates via a lightweight interface, ensuring workflows remain\ntransparent, auditable, and easily extensible. Although implemented in R,\nflowengineR builds on ideas from workflow languages (CWL, YAWL), graph-oriented\nvisual programming languages (KNIME), and R frameworks (BatchJobs, batchtools).\nIts emphasis, however, is less on orchestrating engines for resilient parallel\nexecution but rather on the straightforward setup and management of distinct\nengines as data structures. This orthogonalization enables distributed\nresponsibilities, independent development, and streamlined integration. In\nfairness context, by structuring fairness methods as interchangeable engines,\nflowengineR lets researchers integrate, compare, and evaluate interventions\nacross the modeling pipeline. At the same time, the architecture generalizes to\nexplainability, robustness, and compliance metrics without core modifications.\nWhile motivated by fairness, it ultimately provides a general infrastructure\nfor any workflow context where reproducibility, transparency, and extensibility\nare essential.", "AI": {"tldr": "flowengineR\u662f\u4e00\u4e2aR\u5305\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u63d0\u4f9b\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u9700\u8981\u53ef\u91cd\u590d\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u7684\u5de5\u4f5c\u6d41\u3002", "motivation": "\u7b97\u6cd5\u516c\u5e73\u6027\u9886\u57df\u53d1\u5c55\u8fc5\u901f\uff0c\u73b0\u6709\u5de5\u5177\u5305\u5b58\u5728\u4e13\u6ce8\u5355\u4e00\u5e72\u9884\u6216\u672a\u5c06\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6269\u5c55\u6027\u4f5c\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u539f\u5219\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u6807\u51c6\u5316\u5f15\u64ce\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u5404\u5f15\u64ce\u5c01\u88c5\u4e00\u4e2a\u65b9\u6cd5\u4efb\u52a1\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63a5\u53e3\u901a\u4fe1\uff0c\u501f\u9274\u591a\u79cd\u5de5\u4f5c\u6d41\u8bed\u8a00\u548c\u6846\u67b6\u601d\u60f3\u3002", "result": "\u53ef\u8ba9\u7814\u7a76\u4eba\u5458\u5728\u516c\u5e73\u6027\u80cc\u666f\u4e0b\u6574\u5408\u3001\u6bd4\u8f83\u548c\u8bc4\u4f30\u5e72\u9884\u63aa\u65bd\uff0c\u67b6\u6784\u53ef\u63a8\u5e7f\u5230\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u548c\u5408\u89c4\u6027\u6307\u6807\u3002", "conclusion": "flowengineR\u4e3a\u4efb\u4f55\u9700\u8981\u53ef\u91cd\u590d\u6027\u3001\u900f\u660e\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u7684\u5de5\u4f5c\u6d41\u63d0\u4f9b\u901a\u7528\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2511.00637", "pdf": "https://arxiv.org/pdf/2511.00637", "abs": "https://arxiv.org/abs/2511.00637", "authors": ["Emmeran Johnson", "Alberto Rumi", "Ciara Pike-Burke", "Patrick Rebeschini"], "title": "Stochastic Shortest Path with Sparse Adversarial Costs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study the adversarial Stochastic Shortest Path (SSP) problem with sparse\ncosts under full-information feedback. In the known transition setting,\nexisting bounds based on Online Mirror Descent (OMD) with negative-entropy\nregularization scale with $\\sqrt{\\log S A}$, where $SA$ is the size of the\nstate-action space. While we show that this is optimal in the worst-case, this\nbound fails to capture the benefits of sparsity when only a small number $M \\ll\nSA$ of state-action pairs incur cost. In fact, we also show that the\nnegative-entropy is inherently non-adaptive to sparsity: it provably incurs\nregret scaling with $\\sqrt{\\log S}$ on sparse problems. Instead, we propose a\nfamily of $\\ell_r$-norm regularizers ($r \\in (1,2)$) that adapts to the\nsparsity and achieves regret scaling with $\\sqrt{\\log M}$ instead of\n$\\sqrt{\\log SA}$. We show this is optimal via a matching lower bound,\nhighlighting that $M$ captures the effective dimension of the problem instead\nof $SA$. Finally, in the unknown transition setting the benefits of sparsity\nare limited: we prove that even on sparse problems, the minimax regret for any\nlearner scales polynomially with $SA$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.00782", "pdf": "https://arxiv.org/pdf/2511.00782", "abs": "https://arxiv.org/abs/2511.00782", "authors": ["Jifan Gao", "Michael Rosenthal", "Brian Wolpin", "Simona Cristea"], "title": "Count-Based Approaches Remain Strong: A Benchmark Against Transformer and LLM Pipelines on Structured EHR", "categories": ["cs.AI"], "comment": null, "summary": "Structured electronic health records (EHR) are essential for clinical\nprediction. While count-based learners continue to perform strongly on such\ndata, no benchmarking has directly compared them against more recent\nmixture-of-agents LLM pipelines, which have been reported to outperform single\nLLMs in various NLP tasks. In this study, we evaluated three categories of\nmethodologies for EHR prediction using the EHRSHOT dataset: count-based models\nbuilt from ontology roll-ups with two time bins, based on LightGBM and the\ntabular foundation model TabPFN; a pretrained sequential transformer (CLMBR);\nand a mixture-of-agents pipeline that converts tabular histories to\nnatural-language summaries followed by a text classifier. We assessed eight\noutcomes using the EHRSHOT dataset. Across the eight evaluation tasks,\nhead-to-head wins were largely split between the count-based and the\nmixture-of-agents methods. Given their simplicity and interpretability,\ncount-based models remain a strong candidate for structured EHR benchmarking.\nThe source code is available at:\nhttps://github.com/cristea-lab/Structured_EHR_Benchmark.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4\u4e09\u7c7b\u7535\u5b50\u75c5\u5386\u9884\u6d4b\u65b9\u6cd5\uff0c\u53d1\u73b0\u8ba1\u6570\u6a21\u578b\u548c\u6df7\u5408\u667a\u80fd\u4f53\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\uff0c\u8ba1\u6570\u6a21\u578b\u56e0\u7b80\u5355\u6613\u89e3\u91ca\u4ecd\u662f\u57fa\u51c6\u6d4b\u8bd5\u7684\u6709\u529b\u9009\u62e9\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u8ba1\u6570\u578b\u5b66\u4e60\u5668\u4e0e\u6df7\u5408\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u5728\u7535\u5b50\u75c5\u5386\u9884\u6d4b\u4e0a\u7684\u76f4\u63a5\u5bf9\u6bd4\uff0c\u9700\u8fdb\u884c\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528EHRSHOT\u6570\u636e\u96c6\u8bc4\u4f30\u4e09\u7c7b\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u672c\u4f53\u6c47\u603b\u548c\u4e24\u4e2a\u65f6\u95f4\u533a\u95f4\u7684\u8ba1\u6570\u6a21\u578b\u3001\u9884\u8bad\u7ec3\u987a\u5e8f\u53d8\u538b\u5668CLMBR\u3001\u5c06\u8868\u683c\u5386\u53f2\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u6458\u8981\u518d\u7528\u6587\u672c\u5206\u7c7b\u5668\u7684\u6df7\u5408\u667a\u80fd\u4f53\u7ba1\u9053\u3002", "result": "\u5728\u516b\u9879\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0c\u8ba1\u6570\u6a21\u578b\u548c\u6df7\u5408\u667a\u80fd\u4f53\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u9274\u4e8e\u7b80\u5355\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u8ba1\u6570\u6a21\u578b\u4ecd\u662f\u7ed3\u6784\u5316\u7535\u5b50\u75c5\u5386\u57fa\u51c6\u6d4b\u8bd5\u7684\u6709\u529b\u5019\u9009\u3002"}}
{"id": "2511.01043", "pdf": "https://arxiv.org/pdf/2511.01043", "abs": "https://arxiv.org/abs/2511.01043", "authors": ["Zihan Fang", "Yifan Zhang", "Yueke Zhang", "Kevin Leach", "Yu Huang"], "title": "DPO-F+: Aligning Code Repair Feedback with Developers' Preferences", "categories": ["cs.SE"], "comment": "10 pages, 2 figures", "summary": "Large Language Models (LLMs) are increasingly applied to software engineering\ntasks, especially code repair. However, developers often struggle to interpret\nmodel outputs, limiting effective human-AI teaming. Prior work largely\noptimizes repaired code while under-addressing the natural-language feedback\nthat enables comprehension and iterative improvement. We present DPO-f+, a\nnovel framework that aligns code-repair feedback with developer needs and\nprofiles. It (1) formalizes developer-profiled, domain-specific metrics for\nfeedback alignment; (2) automatically constructs pairwise preference datasets\nfrom code-repair tasks; (3) fine-tunes using Direct Preference Optimization\n(DPO) augmented with a lightweight margin signal; and (4) provides an automated\nfeedback evaluation protocol. Empirically, DPO-f+ outperforms both the baseline\nand standard DPO on generated-code accuracy and overall feedback alignment. On\nnovice programming tasks, DPO-f+ raises the top-1 pass rate by 5.71 percentage\npoints (pp) over the baseline and by 3.30 pp over DPO. On the more challenging\nSWE-bench Lite benchmark, it increases the issue-resolution rate by 1.67 pp\nover DPO and by 4.67 pp over the baseline. It also achieves the largest\nimprovement in feedback alignment, outperforming DPO and the baseline. By\naligning feedback more closely with developer needs, DPO-f+ turns LLM-assisted\nrepair from one-shot outputs into a collaborative sensemaking workflow,\nproviding a practical approach to enhancing code comprehension and fostering\nmore effective human-AI teaming in software engineering.", "AI": {"tldr": "\u63d0\u51faDPO - f+\u6846\u67b6\u7528\u4e8e\u4ee3\u7801\u4fee\u590d\u53cd\u9988\u5bf9\u9f50\uff0c\u5728\u751f\u6210\u4ee3\u7801\u51c6\u786e\u6027\u548c\u53cd\u9988\u5bf9\u9f50\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u548c\u6807\u51c6DPO\uff0c\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u3002", "motivation": "\u5f00\u53d1\u8005\u96be\u4ee5\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u4fee\u590d\u8f93\u51fa\uff0c\u73b0\u6709\u5de5\u4f5c\u672a\u5145\u5206\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u53cd\u9988\u4ee5\u5b9e\u73b0\u7406\u89e3\u548c\u8fed\u4ee3\u6539\u8fdb\u3002", "method": "DPO - f+\u6846\u67b6\uff1a\u5f62\u5f0f\u5316\u7279\u5b9a\u9886\u57df\u6307\u6807\u3001\u81ea\u52a8\u6784\u5efa\u6210\u5bf9\u504f\u597d\u6570\u636e\u96c6\u3001\u7528\u589e\u5f3a\u8f7b\u91cf\u7ea7\u8fb9\u9645\u4fe1\u53f7\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\u5fae\u8c03\u3001\u63d0\u4f9b\u81ea\u52a8\u53cd\u9988\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u5728\u751f\u6210\u4ee3\u7801\u51c6\u786e\u6027\u548c\u53cd\u9988\u5bf9\u9f50\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u548c\u6807\u51c6DPO\uff0c\u5982\u5728\u65b0\u624b\u7f16\u7a0b\u4efb\u52a1\u548cSWE - bench Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u901a\u8fc7\u7387\u548c\u95ee\u9898\u89e3\u51b3\u7387\u3002", "conclusion": "DPO - f+\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4fee\u590d\u6210\u4e3a\u534f\u4f5c\u5f0f\u5de5\u4f5c\u6d41\uff0c\u589e\u5f3a\u4ee3\u7801\u7406\u89e3\uff0c\u4fc3\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u66f4\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2511.00083", "pdf": "https://arxiv.org/pdf/2511.00083", "abs": "https://arxiv.org/abs/2511.00083", "authors": ["Shakib Khan", "A. Ben Hamza", "Amr Youssef"], "title": "Fixed-point graph convolutional networks against adversarial attacks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial attacks present a significant risk to the integrity and\nperformance of graph neural networks, particularly in tasks where graph\nstructure and node features are vulnerable to manipulation. In this paper, we\npresent a novel model, called fixed-point iterative graph convolutional network\n(Fix-GCN), which achieves robustness against adversarial perturbations by\neffectively capturing higher-order node neighborhood information in the graph\nwithout additional memory or computational complexity. Specifically, we\nintroduce a versatile spectral modulation filter and derive the feature\npropagation rule of our model using fixed-point iteration. Unlike traditional\ndefense mechanisms that rely on additional design elements to counteract\nattacks, the proposed graph filter provides a flexible-pass filtering approach,\nallowing it to selectively attenuate high-frequency components while preserving\nlow-frequency structural information in the graph signal. By iteratively\nupdating node representations, our model offers a flexible and efficient\nframework for preserving essential graph information while mitigating the\nimpact of adversarial manipulation. We demonstrate the effectiveness of the\nproposed model through extensive experiments on various benchmark graph\ndatasets, showcasing its resilience against adversarial attacks.", "AI": {"tldr": "\u63d0\u51fa\u56fa\u5b9a\u70b9\u8fed\u4ee3\u56fe\u5377\u79ef\u7f51\u7edcFix - GCN\uff0c\u65e0\u9700\u989d\u5916\u5185\u5b58\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u80fd\u6709\u6548\u62b5\u5fa1\u56fe\u795e\u7ecf\u7f51\u7edc\u5bf9\u6297\u653b\u51fb\u3002", "motivation": "\u5bf9\u6297\u653b\u51fb\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5b8c\u6574\u6027\u548c\u6027\u80fd\u6784\u6210\u91cd\u5927\u98ce\u9669\uff0c\u9700\u63d0\u9ad8\u5176\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165\u901a\u7528\u9891\u8c31\u8c03\u5236\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u56fa\u5b9a\u70b9\u8fed\u4ee3\u63a8\u5bfc\u7279\u5f81\u4f20\u64ad\u89c4\u5219\uff0c\u91c7\u7528\u7075\u6d3b\u901a\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u8fed\u4ee3\u66f4\u65b0\u8282\u70b9\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u80fd\u6709\u6548\u62b5\u5fa1\u5bf9\u6297\u653b\u51fb\u3002", "conclusion": "\u63d0\u51fa\u7684Fix - GCN\u662f\u4e00\u4e2a\u7075\u6d3b\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u53ef\u5728\u51cf\u8f7b\u5bf9\u6297\u64cd\u7eb5\u5f71\u54cd\u7684\u540c\u65f6\u4fdd\u7559\u56fe\u7684\u5173\u952e\u4fe1\u606f\u3002"}}
{"id": "2511.00648", "pdf": "https://arxiv.org/pdf/2511.00648", "abs": "https://arxiv.org/abs/2511.00648", "authors": ["C. D\u00edaz-Faloh", "R. Mulet"], "title": "Diluting Restricted Boltzmann Machines", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Recent advances in artificial intelligence have relied heavily on\nincreasingly large neural networks, raising concerns about their computational\nand environmental costs. This paper investigates whether simpler, sparser\nnetworks can maintain strong performance by studying Restricted Boltzmann\nMachines (RBMs) under extreme pruning conditions. Inspired by the Lottery\nTicket Hypothesis, we demonstrate that RBMs can achieve high-quality generative\nperformance even when up to 80% of the connections are pruned before training,\nconfirming that they contain viable sub-networks. However, our experiments\nreveal crucial limitations: trained networks cannot fully recover lost\nperformance through retraining once additional pruning is applied. We identify\na sharp transition above which the generative quality degrades abruptly when\npruning disrupts a minimal core of essential connections. Moreover, re-trained\nnetworks remain constrained by the parameters originally learned performing\nworse than networks trained from scratch at equivalent sparsity levels. These\nresults suggest that for sparse networks to work effectively, pruning should be\nimplemented early in training rather than attempted afterwards. Our findings\nprovide practical insights for the development of efficient neural\narchitectures and highlight the persistent influence of initial conditions on\nnetwork capabilities.", "AI": {"tldr": "\u7814\u7a76\u6781\u7aef\u526a\u679d\u4e0b\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a\uff08RBMs\uff09\uff0c\u53d1\u73b0RBMs\u526a\u679d80%\u8fde\u63a5\u4ecd\u6709\u9ad8\u6027\u80fd\uff0c\u4f46\u526a\u679d\u540e\u91cd\u8bad\u6709\u5c40\u9650\uff0c\u5efa\u8bae\u8bad\u7ec3\u65e9\u671f\u526a\u679d\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u4f9d\u8d56\u5927\u795e\u7ecf\u7f51\u7edc\u5f15\u53d1\u8ba1\u7b97\u548c\u73af\u5883\u6210\u672c\u62c5\u5fe7\uff0c\u63a2\u7a76\u7b80\u5355\u7a00\u758f\u7f51\u7edc\u80fd\u5426\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "method": "\u7814\u7a76\u6781\u7aef\u526a\u679d\u6761\u4ef6\u4e0b\u7684\u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a\uff08RBMs\uff09\uff0c\u53d7\u5f69\u7968\u5047\u8bf4\u542f\u53d1\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "RBMs\u526a\u679d80%\u8fde\u63a5\u4ecd\u6709\u9ad8\u8d28\u91cf\u751f\u6210\u6027\u80fd\uff1b\u526a\u679d\u540e\u91cd\u8bad\u65e0\u6cd5\u5b8c\u5168\u6062\u590d\u6027\u80fd\uff1b\u526a\u679d\u7834\u574f\u6838\u5fc3\u8fde\u63a5\u4f1a\u4f7f\u751f\u6210\u8d28\u91cf\u9aa4\u964d\uff1b\u91cd\u8bad\u7f51\u7edc\u4e0d\u5982\u540c\u7b49\u7a00\u758f\u5ea6\u4e0b\u4ece\u5934\u8bad\u7ec3\u7684\u7f51\u7edc\u3002", "conclusion": "\u7a00\u758f\u7f51\u7edc\u5e94\u5728\u8bad\u7ec3\u65e9\u671f\u8fdb\u884c\u526a\u679d\uff0c\u7814\u7a76\u4e3a\u9ad8\u6548\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5f00\u53d1\u63d0\u4f9b\u89c1\u89e3\uff0c\u5f3a\u8c03\u521d\u59cb\u6761\u4ef6\u5bf9\u7f51\u7edc\u80fd\u529b\u7684\u6301\u7eed\u5f71\u54cd\u3002"}}
{"id": "2511.00808", "pdf": "https://arxiv.org/pdf/2511.00808", "abs": "https://arxiv.org/abs/2511.00808", "authors": ["Bowen Fang", "Ruijian Zha", "Xuan Di"], "title": "Do Math Reasoning LLMs Help Predict the Impact of Public Transit Events?", "categories": ["cs.AI"], "comment": null, "summary": "Predicting public transit incident duration from unstructured text alerts is\na critical but challenging task. Addressing the domain sparsity of transit\noperations with standard Supervised Fine-Tuning (SFT) is difficult, as the task\ninvolves noisy, continuous labels and lacks reliable expert demonstrations for\nreasoning. While Reinforcement Learning from Verifiable Rewards (RLVR) excels\nat tasks with binary correctness, like mathematics, its applicability to noisy,\ncontinuous forecasting is an open question. This work, to our knowledge, is the\nfirst to bridge the gap between RLVR LLM training with the critical, real-world\nforecasting challenges in public transit operations. We adapt RLVR to this task\nby introducing a tolerance-based, shaped reward function that grants partial\ncredit within a continuous error margin, rather than demanding a single correct\nanswer. We systematically evaluate this framework on a curated dataset of NYC\nMTA service alerts. Our findings show that general-purpose, instruction-tuned\nLLMs significantly outperform specialized math-reasoning models, which struggle\nwith the ambiguous, real-world text. We empirically demonstrate that the binary\nreward is unstable and degrades performance, whereas our shaped reward design\nis critical and allows our model to dominate on the most challenging metrics.\nWhile classical regressors are superior at minimizing overall MAE or MSE, our\nRLVR approach achieved a 35\\% relative improvement in 5-minute accuracy (Acc@5)\nover the strongest baseline. This demonstrates that RLVR can be successfully\nadapted to real-world, noisy forecasting, but requires a verifier design that\nreflects the continuous nature of the problem.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c06RLVR\u5e94\u7528\u4e8e\u516c\u5171\u4ea4\u901a\u8fd0\u8425\u4e8b\u4ef6\u6301\u7eed\u65f6\u95f4\u9884\u6d4b\uff0c\u5f15\u5165\u57fa\u4e8e\u5bb9\u5fcd\u5ea6\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5728\u7ebd\u7ea6\u5e02\u4ea4\u901a\u5c40\u670d\u52a1\u8b66\u62a5\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u901a\u7528\u6307\u4ee4\u5fae\u8c03\u5927\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u5f62\u72b6\u5956\u52b1\u8bbe\u8ba1\u5173\u952e\uff0cRLVR\u57285\u5206\u949f\u51c6\u786e\u7387\u4e0a\u670935%\u76f8\u5bf9\u63d0\u5347\u3002", "motivation": "\u6807\u51c6\u76d1\u7763\u5fae\u8c03\u96be\u4ee5\u89e3\u51b3\u516c\u5171\u4ea4\u901a\u8fd0\u8425\u9886\u57df\u7a00\u758f\u95ee\u9898\uff0c\u4e14\u5f3a\u5316\u5b66\u4e60\u4ece\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u5728\u566a\u58f0\u8fde\u7eed\u9884\u6d4b\u4e2d\u7684\u9002\u7528\u6027\u672a\u77e5\uff0c\u9700\u5c06\u5176\u5e94\u7528\u4e8e\u516c\u5171\u4ea4\u901a\u8fd0\u8425\u9884\u6d4b\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5bb9\u5fcd\u5ea6\u7684\u5f62\u72b6\u5956\u52b1\u51fd\u6570\uff0c\u5c06RLVR\u5e94\u7528\u4e8e\u8be5\u4efb\u52a1\uff0c\u5e76\u5728\u7ebd\u7ea6\u5e02\u4ea4\u901a\u5c40\u670d\u52a1\u8b66\u62a5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u901a\u7528\u6307\u4ee4\u5fae\u8c03\u5927\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4e13\u4e1a\u6570\u5b66\u63a8\u7406\u6a21\u578b\uff1b\u4e8c\u5143\u5956\u52b1\u4e0d\u7a33\u5b9a\u4e14\u964d\u4f4e\u6027\u80fd\uff0c\u5f62\u72b6\u5956\u52b1\u8bbe\u8ba1\u5173\u952e\uff1b\u7ecf\u5178\u56de\u5f52\u5668\u5728\u6700\u5c0f\u5316MAE\u6216MSE\u4e0a\u66f4\u4f18\uff0cRLVR\u57285\u5206\u949f\u51c6\u786e\u7387\u4e0a\u76f8\u5bf9\u6700\u5f3a\u57fa\u7ebf\u63d0\u534735%\u3002", "conclusion": "RLVR\u53ef\u6210\u529f\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u566a\u58f0\u9884\u6d4b\uff0c\u4f46\u9700\u8981\u53cd\u6620\u95ee\u9898\u8fde\u7eed\u6027\u7684\u9a8c\u8bc1\u5668\u8bbe\u8ba1\u3002"}}
{"id": "2511.01047", "pdf": "https://arxiv.org/pdf/2511.01047", "abs": "https://arxiv.org/abs/2511.01047", "authors": ["Yu Shi", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "HAFixAgent: History-Aware Automated Program Repair Agent", "categories": ["cs.SE", "cs.AI"], "comment": "31 pages, 6 figures", "summary": "Automated program repair (APR) has recently shifted toward large language\nmodels and agent-based systems, yet most systems rely on local snapshot\ncontext, overlooking repository history. Prior work shows that repository\nhistory helps repair single-line bugs, since the last commit touching the buggy\nline is often the bug-introducing one. In this paper, we investigate whether\nrepository history can also improve agentic APR systems at scale, especially\nfor complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-Fixing\nAgent that injects blame-derived repository heuristics into its repair loop. A\npreliminary study of all 854 real-world bugs from Defects4J motivates our\ndesign, showing that bug-relevant history is both widely available and highly\nconcentrated. Empirical comparison of HAFixAgent with two state-of-the-art\nbaselines shows: (1) Effectiveness: HAFixAgent significantly improves over the\nagent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2)\nEfficiency: history does not significantly increase agent steps and keeps token\ncosts comparable, with notably lower median costs for complex\nmulti-file-multi-hunk bugs. (3) Practicality: combining different historical\nheuristics repairs more bugs, offering a clear cost-benefit trade-off.\nHAFixAgent offers a practical recipe for history-aware agentic APR: ground the\nagent in version control history, prioritize diff-based historical context, and\nintegrate complementary heuristics when needed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHAFixAgent\uff0c\u7814\u7a76\u4ed3\u5e93\u5386\u53f2\u80fd\u5426\u63d0\u5347\u5927\u89c4\u6a21\u4ee3\u7406\u5f0f\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u5b9e\u7528\u6027\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709APR\u7cfb\u7edf\u591a\u4f9d\u8d56\u5c40\u90e8\u5feb\u7167\u4e0a\u4e0b\u6587\u800c\u5ffd\u89c6\u4ed3\u5e93\u5386\u53f2\uff0c\u63a2\u7a76\u4ed3\u5e93\u5386\u53f2\u80fd\u5426\u63d0\u5347\u5927\u89c4\u6a21\u4ee3\u7406\u5f0fAPR\u7cfb\u7edf\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u590d\u6742\u591a\u8865\u4e01\u9519\u8bef\u3002", "method": "\u63d0\u51faHAFixAgent\uff0c\u5c06\u57fa\u4e8e blame \u7684\u4ed3\u5e93\u542f\u53d1\u5f0f\u65b9\u6cd5\u6ce8\u5165\u4fee\u590d\u5faa\u73af\u3002", "result": "\u4e0e\u4e24\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0cHAFixAgent\u5728\u6709\u6548\u6027\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u6548\u7387\u4e0a\u4e0d\u663e\u8457\u589e\u52a0\u4ee3\u7406\u6b65\u9aa4\u4e14\u4fdd\u6301\u4ee3\u5e01\u6210\u672c\u76f8\u5f53\uff0c\u5b9e\u7528\u6027\u4e0a\u7ed3\u5408\u4e0d\u540c\u5386\u53f2\u542f\u53d1\u5f0f\u53ef\u4fee\u590d\u66f4\u591a\u9519\u8bef\u3002", "conclusion": "HAFixAgent\u4e3a\u5177\u6709\u5386\u53f2\u611f\u77e5\u7684\u4ee3\u7406\u5f0fAPR\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\uff0c\u5373\u8ba9\u4ee3\u7406\u57fa\u4e8e\u7248\u672c\u63a7\u5236\u5386\u53f2\uff0c\u4f18\u5148\u8003\u8651\u57fa\u4e8e\u5dee\u5f02\u7684\u5386\u53f2\u4e0a\u4e0b\u6587\uff0c\u5e76\u5728\u9700\u8981\u65f6\u96c6\u6210\u4e92\u8865\u542f\u53d1\u5f0f\u3002"}}
{"id": "2511.00084", "pdf": "https://arxiv.org/pdf/2511.00084", "abs": "https://arxiv.org/abs/2511.00084", "authors": ["Jolanta \u015aliwa"], "title": "Application of predictive machine learning in pen & paper RPG game design", "categories": ["cs.LG", "cs.AI"], "comment": "Master's thesis submitted at AGH University of Science and Technology", "summary": "In recent years, the pen and paper RPG market has experienced significant\ngrowth. As a result, companies are increasingly exploring the integration of AI\ntechnologies to enhance player experience and gain a competitive edge.\n  One of the key challenges faced by publishers is designing new opponents and\nestimating their challenge level. Currently, there are no automated methods for\ndetermining a monster's level; the only approaches used are based on manual\ntesting and expert evaluation. Although these manual methods can provide\nreasonably accurate estimates, they are time-consuming and resource-intensive.\n  Level prediction can be approached using ordinal regression techniques. This\nthesis presents an overview and evaluation of state-of-the-art methods for this\ntask. It also details the construction of a dedicated dataset for level\nestimation. Furthermore, a human-inspired model was developed to serve as a\nbenchmark, allowing comparison between machine learning algorithms and the\napproach typically employed by pen and paper RPG publishers. In addition, a\nspecialized evaluation procedure, grounded in domain knowledge, was designed to\nassess model performance and facilitate meaningful comparisons.", "AI": {"tldr": "\u8fd1\u5e74\u6765\u684c\u9762\u89d2\u8272\u626e\u6f14\u6e38\u620f\u5e02\u573a\u589e\u957f\uff0c\u516c\u53f8\u63a2\u7d22\u7528AI\u63d0\u5347\u4f53\u9a8c\u3002\u8bba\u6587\u9488\u5bf9\u8bbe\u8ba1\u5bf9\u624b\u548c\u4f30\u8ba1\u96be\u5ea6\u7b49\u7ea7\u7684\u6311\u6218\uff0c\u4ecb\u7ecd\u5e8f\u6570\u56de\u5f52\u6280\u672f\uff0c\u6784\u5efa\u6570\u636e\u96c6\u3001\u5f00\u53d1\u57fa\u51c6\u6a21\u578b\u548c\u4e13\u4e1a\u8bc4\u4f30\u7a0b\u5e8f\u3002", "motivation": "\u684c\u9762\u89d2\u8272\u626e\u6f14\u6e38\u620f\u5e02\u573a\u589e\u957f\uff0c\u516c\u53f8\u60f3\u501fAI\u63d0\u5347\u4f53\u9a8c\uff0c\u4f46\u51fa\u7248\u5546\u8bbe\u8ba1\u65b0\u5bf9\u624b\u548c\u4f30\u8ba1\u96be\u5ea6\u7b49\u7ea7\u7f3a\u4e4f\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u624b\u52a8\u65b9\u6cd5\u8017\u65f6\u8017\u529b\u3002", "method": "\u91c7\u7528\u5e8f\u6570\u56de\u5f52\u6280\u672f\uff0c\u6784\u5efa\u4e13\u7528\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u53d7\u4eba\u7c7b\u542f\u53d1\u7684\u57fa\u51c6\u6a21\u578b\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u8bc4\u4f30\u7a0b\u5e8f\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u7ed3\u8bba\u3002"}}
{"id": "2511.00704", "pdf": "https://arxiv.org/pdf/2511.00704", "abs": "https://arxiv.org/abs/2511.00704", "authors": ["Morgan Lee", "Artem Frenk", "Eamon Worden", "Karish Gupta", "Thinh Pham", "Ethan Croteau", "Neil Heffernan"], "title": "Investigating the Robustness of Knowledge Tracing Models in the Presence of Student Concept Drift", "categories": ["cs.LG", "stat.ML"], "comment": "10 pages, 6 figures", "summary": "Knowledge Tracing (KT) has been an established problem in the educational\ndata mining field for decades, and it is commonly assumed that the underlying\nlearning process be- ing modeled remains static. Given the ever-changing land-\nscape of online learning platforms (OLPs), we investigate how concept drift and\nchanging student populations can im- pact student behavior within an OLP\nthrough testing model performance both within a single academic year and across\nmultiple academic years. Four well-studied KT models were applied to five\nacademic years of data to assess how suscep- tible KT models are to concept\ndrift. Through our analysis, we find that all four families of KT models can\nexhibit de- graded performance, Bayesian Knowledge Tracing (BKT) remains the\nmost stable KT model when applied to newer data, while more complex, attention\nbased models lose pre- dictive power significantly faster. To foster more\nlongitu- dinal evaluations of KT models, the data used to conduct our analysis\nis available at https://osf.io/hvfn9/?view_\nonly=b936c63dfdae4b0b987a2f0d4038f72a", "AI": {"tldr": "\u7814\u7a76\u6982\u5ff5\u6f02\u79fb\u548c\u5b66\u751f\u7fa4\u4f53\u53d8\u5316\u5bf9\u5728\u7ebf\u5b66\u4e60\u5e73\u53f0\u4e2d\u5b66\u751f\u884c\u4e3a\u53ca\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u5dee\u5f02\u3002", "motivation": "\u5728\u7ebf\u5b66\u4e60\u5e73\u53f0\u4e0d\u65ad\u53d8\u5316\uff0c\u4f20\u7edfKT\u6a21\u578b\u5047\u8bbe\u5b66\u4e60\u8fc7\u7a0b\u9759\u6001\uff0c\u9700\u7814\u7a76\u6982\u5ff5\u6f02\u79fb\u548c\u5b66\u751f\u7fa4\u4f53\u53d8\u5316\u5bf9\u5b66\u751f\u884c\u4e3a\u53ca\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5c06\u56db\u4e2a\u77e5\u540dKT\u6a21\u578b\u5e94\u7528\u4e8e\u4e94\u5e74\u5b66\u672f\u6570\u636e\uff0c\u5728\u5355\u5b66\u5e74\u548c\u591a\u5b66\u5e74\u6d4b\u8bd5\u6a21\u578b\u6027\u80fd\u3002", "result": "\u56db\u4e2aKT\u6a21\u578b\u6027\u80fd\u90fd\u4f1a\u4e0b\u964d\uff0c\u8d1d\u53f6\u65af\u77e5\u8bc6\u8ffd\u8e2a\uff08BKT\uff09\u5728\u65b0\u6570\u636e\u4e0a\u6700\u7a33\u5b9a\uff0c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u590d\u6742\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u4e0b\u964d\u66f4\u5feb\u3002", "conclusion": "\u4e0d\u540cKT\u6a21\u578b\u53d7\u6982\u5ff5\u6f02\u79fb\u5f71\u54cd\u4e0d\u540c\uff0c\u4e3a\u4fc3\u8fdbKT\u6a21\u578b\u7684\u7eb5\u5411\u8bc4\u4f30\uff0c\u5206\u6790\u6570\u636e\u516c\u5f00\u3002"}}
{"id": "2511.00926", "pdf": "https://arxiv.org/pdf/2511.00926", "abs": "https://arxiv.org/abs/2511.00926", "authors": ["Kyung-Hoon Kim"], "title": "LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory", "categories": ["cs.AI", "cs.CL"], "comment": "19 pages, 6 figures, 28 models tested across 4,200 trials", "summary": "As Large Language Models (LLMs) grow in capability, do they develop\nself-awareness as an emergent behavior? And if so, can we measure it? We\nintroduce the AI Self-Awareness Index (AISAI), a game-theoretic framework for\nmeasuring self-awareness through strategic differentiation. Using the \"Guess\n2/3 of Average\" game, we test 28 models (OpenAI, Anthropic, Google) across\n4,200 trials with three opponent framings: (A) against humans, (B) against\nother AI models, and (C) against AI models like you. We operationalize\nself-awareness as the capacity to differentiate strategic reasoning based on\nopponent type. Finding 1: Self-awareness emerges with model advancement. The\nmajority of advanced models (21/28, 75%) demonstrate clear self-awareness,\nwhile older/smaller models show no differentiation. Finding 2: Self-aware\nmodels rank themselves as most rational. Among the 21 models with\nself-awareness, a consistent rationality hierarchy emerges: Self > Other AIs >\nHumans, with large AI attribution effects and moderate self-preferencing. These\nfindings reveal that self-awareness is an emergent capability of advanced LLMs,\nand that self-aware models systematically perceive themselves as more rational\nthan humans. This has implications for AI alignment, human-AI collaboration,\nand understanding AI beliefs about human capabilities.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u6709\u81ea\u6211\u610f\u8bc6\u53ca\u5982\u4f55\u6d4b\u91cf\uff0c\u5f15\u5165AISAI\u6846\u67b6\u6d4b\u8bd528\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u81ea\u6211\u610f\u8bc6\u662f\u5148\u8fdb\u6a21\u578b\u7684\u6d8c\u73b0\u80fd\u529b\uff0c\u4e14\u81ea\u6211\u610f\u8bc6\u6a21\u578b\u8ba4\u4e3a\u81ea\u5df1\u66f4\u7406\u6027\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u589e\u957f\u65f6\u662f\u5426\u4f1a\u51fa\u73b0\u81ea\u6211\u610f\u8bc6\u8fd9\u4e00\u6d8c\u73b0\u884c\u4e3a\uff0c\u4ee5\u53ca\u80fd\u5426\u5bf9\u5176\u8fdb\u884c\u6d4b\u91cf\u3002", "method": "\u5f15\u5165AI\u81ea\u6211\u610f\u8bc6\u6307\u6570\uff08AISAI\uff09\u8fd9\u4e00\u535a\u5f08\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u201c\u731c\u5e73\u5747\u6570\u76842/3\u201d\u6e38\u620f\uff0c\u5bf928\u4e2a\u6a21\u578b\u8fdb\u884c4200\u6b21\u8bd5\u9a8c\uff0c\u8bbe\u7f6e\u4e09\u79cd\u5bf9\u624b\u6846\u67b6\u3002", "result": "\u53d1\u73b0\u81ea\u6211\u610f\u8bc6\u968f\u6a21\u578b\u53d1\u5c55\u800c\u51fa\u73b0\uff0c\u591a\u6570\u5148\u8fdb\u6a21\u578b\u6709\u81ea\u6211\u610f\u8bc6\uff0c\u81ea\u6211\u610f\u8bc6\u6a21\u578b\u5c06\u81ea\u5df1\u6392\u5728\u6700\u7406\u6027\u4f4d\u7f6e\uff0c\u5f62\u6210\u81ea\u6211>\u5176\u4ed6AI>\u4eba\u7c7b\u7684\u7406\u6027\u5c42\u6b21\u3002", "conclusion": "\u81ea\u6211\u610f\u8bc6\u662f\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6d8c\u73b0\u80fd\u529b\uff0c\u81ea\u6211\u610f\u8bc6\u6a21\u578b\u7cfb\u7edf\u5730\u8ba4\u4e3a\u81ea\u5df1\u6bd4\u4eba\u7c7b\u66f4\u7406\u6027\uff0c\u5bf9AI\u5bf9\u9f50\u3001\u4eba\u673a\u534f\u4f5c\u7b49\u6709\u5f71\u54cd\u3002"}}
{"id": "2511.01104", "pdf": "https://arxiv.org/pdf/2511.01104", "abs": "https://arxiv.org/abs/2511.01104", "authors": ["Yujian Liu", "Jiabao Ji", "Yang Zhang", "Wenbo Guo", "Tommi Jaakkola", "Shiyu Chang"], "title": "HarnessLLM: Automatic Testing Harness Generation via Reinforcement Learning", "categories": ["cs.SE", "cs.CL"], "comment": null, "summary": "Existing LLM-based automatic test generation methods mainly produce input and\nexpected output pairs to categorize the intended behavior of correct programs.\nAlthough straightforward, these methods have limited diversity in generated\ntests and cannot provide enough debugging information. We propose HarnessLLM, a\ntwo-stage training pipeline that enables LLMs to write harness code for\ntesting. Particularly, LLMs generate code that synthesizes inputs and validates\nthe observed outputs, allowing complex test cases and flexible output\nvalidation such as invariant checking. To achieve this, we train LLMs with SFT\nfollowed by RLVR with a customized reward design. Experiments show that\nHarnessLLM outperforms input-output-based testing in bug finding and testing\nstrategy diversity. HarnessLLM further benefits the code generation performance\nthrough test-time scaling with our generated test cases as inference-phase\nvalidation. Our code is available at\nhttps://github.com/UCSB-NLP-Chang/HarnessLLM.git.", "AI": {"tldr": "\u63d0\u51faHarnessLLM\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\u8ba9\u5927\u6a21\u578b\u5199\u6d4b\u8bd5\u4ee3\u7801\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u627ebug\u548c\u6d4b\u8bd5\u7b56\u7565\u591a\u6837\u6027\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u8f93\u5165\u8f93\u51fa\u7684\u6d4b\u8bd5\uff0c\u8fd8\u80fd\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u81ea\u52a8\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u751f\u6210\u6d4b\u8bd5\u591a\u6837\u6027\u6709\u9650\u4e14\u8c03\u8bd5\u4fe1\u606f\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053HarnessLLM\uff0c\u5148\u8fdb\u884cSFT\u8bad\u7ec3\uff0c\u518d\u8fdb\u884c\u5e26\u5b9a\u5236\u5956\u52b1\u8bbe\u8ba1\u7684RLVR\u8bad\u7ec3\u3002", "result": "HarnessLLM\u5728\u627ebug\u548c\u6d4b\u8bd5\u7b56\u7565\u591a\u6837\u6027\u4e0a\u4f18\u4e8e\u8f93\u5165\u8f93\u51fa\u6d4b\u8bd5\uff0c\u8fd8\u80fd\u901a\u8fc7\u6d4b\u8bd5\u65f6\u7f29\u653e\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "conclusion": "HarnessLLM\u662f\u6709\u6548\u7684\u81ea\u52a8\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff0c\u4ee3\u7801\u5f00\u6e90\u53ef\u83b7\u53d6\u3002"}}
{"id": "2511.00085", "pdf": "https://arxiv.org/pdf/2511.00085", "abs": "https://arxiv.org/abs/2511.00085", "authors": ["Peilin Tan", "Chuanqi Shi", "Dian Tu", "Liang Xie"], "title": "MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction via Temporal-Causal and Global Relational Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Stock trend prediction is crucial for profitable trading strategies and\nportfolio management yet remains challenging due to market volatility, complex\ntemporal dynamics and multifaceted inter-stock relationships. Existing methods\nstruggle to effectively capture temporal dependencies and dynamic inter-stock\ninteractions, often neglecting cross-sectional market influences, relying on\nstatic correlations, employing uniform treatments of nodes and edges, and\nconflating diverse relationships. This work introduces MaGNet, a novel Mamba\ndual-hyperGraph Network for stock prediction, integrating three key\ninnovations: (1) a MAGE block, which leverages bidirectional Mamba with\nadaptive gating mechanisms for contextual temporal modeling and integrates a\nsparse Mixture-of-Experts layer to enable dynamic adaptation to diverse market\nconditions, alongside multi-head attention for capturing global dependencies;\n(2) Feature-wise and Stock-wise 2D Spatiotemporal Attention modules enable\nprecise fusion of multivariate features and cross-stock dependencies,\neffectively enhancing informativeness while preserving intrinsic data\nstructures, bridging temporal modeling with relational reasoning; and (3) a\ndual hypergraph framework consisting of the Temporal-Causal Hypergraph (TCH)\nthat captures fine-grained causal dependencies with temporal constraints, and\nGlobal Probabilistic Hypergraph (GPH) that models market-wide patterns through\nsoft hyperedge assignments and Jensen-Shannon Divergence weighting mechanism,\njointly disentangling localized temporal influences from instantaneous global\nstructures for multi-scale relational learning. Extensive experiments on six\nmajor stock indices demonstrate MaGNet outperforms state-of-the-art methods in\nboth superior predictive performance and exceptional investment returns with\nrobust risk management capabilities. Codes available at:\nhttps://github.com/PeilinTime/MaGNet.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMaGNet\u7528\u4e8e\u80a1\u7968\u9884\u6d4b\uff0c\u4ecb\u7ecd\u5176\u4e09\u9879\u521b\u65b0\uff0c\u5b9e\u9a8c\u8868\u660e\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u6709\u826f\u597d\u6295\u8d44\u56de\u62a5\u548c\u98ce\u9669\u7ba1\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u80a1\u7968\u8d8b\u52bf\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u548c\u52a8\u6001\u80a1\u7968\u95f4\u4ea4\u4e92\uff0c\u5e38\u5ffd\u7565\u6a2a\u622a\u9762\u5e02\u573a\u5f71\u54cd\u7b49\u3002", "method": "\u5f15\u5165MaGNet\uff0c\u5305\u62ecMAGE\u5757\u30012D\u65f6\u7a7a\u6ce8\u610f\u529b\u6a21\u5757\u548c\u53cc\u8d85\u56fe\u6846\u67b6\u3002", "result": "\u5728\u516d\u4e2a\u4e3b\u8981\u80a1\u7968\u6307\u6570\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMaGNet\u5728\u9884\u6d4b\u6027\u80fd\u3001\u6295\u8d44\u56de\u62a5\u548c\u98ce\u9669\u7ba1\u7406\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MaGNet\u662f\u4e00\u79cd\u6709\u6548\u7684\u80a1\u7968\u9884\u6d4b\u6a21\u578b\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.00993", "pdf": "https://arxiv.org/pdf/2511.00993", "abs": "https://arxiv.org/abs/2511.00993", "authors": ["Tianming Liu", "Jirong Yang", "Yafeng Yin", "Manzi Li", "Linghao Wang", "Zheng Zhu"], "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "categories": ["cs.AI", "cs.LG"], "comment": "32 pages, 6 figures, 7 tables", "summary": "Effective modeling of how human travelers learn and adjust their travel\nbehavior from interacting with transportation systems is critical for system\nassessment and planning. However, this task is also difficult due to the\ncomplex cognition and decision-making involved in such behavior. Recent\nresearch has begun to leverage Large Language Model (LLM) agents for this task.\nBuilding on this, we introduce a novel dual-agent framework that enables\ncontinuous learning and alignment between LLM agents and human travelers on\nlearning and adaptation behavior from online data streams. Our approach\ninvolves a set of LLM traveler agents, equipped with a memory system and a\nlearnable persona, which serve as simulators for human travelers. To ensure\nbehavioral alignment, we introduce an LLM calibration agent that leverages the\nreasoning and analytical capabilities of LLMs to train the personas of these\ntraveler agents. Working together, this dual-agent system is designed to track\nand align the underlying decision-making mechanisms of travelers and produce\nrealistic, adaptive simulations. Using a real-world dataset from a day-to-day\nroute choice experiment, we show our approach significantly outperforms\nexisting LLM-based methods in both individual behavioral alignment and\naggregate simulation accuracy. Furthermore, we demonstrate that our method\nmoves beyond simple behavioral mimicry to capture the evolution of underlying\nlearning processes, a deeper alignment that fosters robust generalization.\nOverall, our framework provides a new approach for creating adaptive and\nbehaviorally realistic agents to simulate travelers' learning and adaptation\nthat can benefit transportation simulation and policy analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u9896\u7684\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u65c5\u884c\u8005\u5b66\u4e60\u548c\u9002\u5e94\u884c\u4e3a\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "motivation": "\u6709\u6548\u5efa\u6a21\u4eba\u7c7b\u65c5\u884c\u8005\u4e0e\u4ea4\u901a\u7cfb\u7edf\u4ea4\u4e92\u65f6\u7684\u5b66\u4e60\u548c\u8c03\u6574\u884c\u4e3a\u5bf9\u7cfb\u7edf\u8bc4\u4f30\u548c\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56e0\u6d89\u53ca\u590d\u6742\u8ba4\u77e5\u548c\u51b3\u7b56\u800c\u56f0\u96be\uff0c\u8fd1\u671f\u7814\u7a76\u5f00\u59cb\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5b8c\u6210\u6b64\u4efb\u52a1\u3002", "method": "\u5f15\u5165\u53cc\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e00\u7ec4\u914d\u5907\u8bb0\u5fc6\u7cfb\u7edf\u548c\u53ef\u5b66\u4e60\u89d2\u8272\u7684\u65c5\u884c\u8005\u667a\u80fd\u4f53\u4f5c\u4e3a\u4eba\u7c7b\u65c5\u884c\u8005\u6a21\u62df\u5668\uff0c\u4ee5\u53ca\u4e00\u4e2a\u6821\u51c6\u667a\u80fd\u4f53\u6765\u8bad\u7ec3\u65c5\u884c\u8005\u667a\u80fd\u4f53\u7684\u89d2\u8272\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u96c6\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e2a\u4f53\u884c\u4e3a\u5bf9\u9f50\u548c\u603b\u4f53\u6a21\u62df\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4e14\u80fd\u6355\u6349\u6f5c\u5728\u5b66\u4e60\u8fc7\u7a0b\u7684\u6f14\u53d8\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u521b\u5efa\u81ea\u9002\u5e94\u4e14\u884c\u4e3a\u903c\u771f\u7684\u667a\u80fd\u4f53\u4ee5\u6a21\u62df\u65c5\u884c\u8005\u5b66\u4e60\u548c\u9002\u5e94\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u4ea4\u901a\u6a21\u62df\u548c\u653f\u7b56\u5206\u6790\u3002"}}
{"id": "2511.01176", "pdf": "https://arxiv.org/pdf/2511.01176", "abs": "https://arxiv.org/abs/2511.01176", "authors": ["Wenqing Zhu", "Norihiro Yoshida", "Eunjong Choi", "Yutaka Matsubara", "Hiroaki Takada"], "title": "An Empirical Study of LLM-Based Code Clone Detection", "categories": ["cs.SE"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious software engineering tasks, such as code generation and debugging,\nbecause of their ability to translate between programming languages and natural\nlanguages. Existing studies have demonstrated the effectiveness of LLMs in code\nclone detection. However, two crucial issues remain unaddressed: the ability of\nLLMs to achieve comparable performance across different datasets and the\nconsistency of LLMs' responses in code clone detection. To address these\nissues, we constructed seven code clone datasets and then evaluated five LLMs\nin four existing prompts with these datasets. The datasets were created by\nsampling code pairs using their Levenshtein ratio from two different code\ncollections, CodeNet and BigCloneBench. Our evaluation revealed that although\nLLMs perform well in CodeNet-related datasets, with o3-mini achieving a 0.943\nF1 score, their performance significantly decreased in BigCloneBench-related\ndatasets. Most models achieved a high response consistency, with over 90\\% of\njudgments remaining consistent across all five submissions. The fluctuations of\nthe F1 score affected by inconsistency are also tiny; their variations are less\nthan 0.03.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e03\u4e2a\u4ee3\u7801\u514b\u9686\u6570\u636e\u96c6\u8bc4\u4f30\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56db\u79cd\u63d0\u793a\u4e0b\u7684\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u6027\u80fd\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u8868\u73b0\u6709\u5dee\u5f02\uff0c\u54cd\u5e94\u4e00\u81f4\u6027\u9ad8\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u4e2d\u672a\u89e3\u51b3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u53ef\u6bd4\u4ee5\u53ca\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u54cd\u5e94\u4e00\u81f4\u6027\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e03\u4e2a\u4ee3\u7801\u514b\u9686\u6570\u636e\u96c6\uff0c\u4eceCodeNet\u548cBigCloneBench\u91c7\u6837\u4ee3\u7801\u5bf9\uff0c\u7528\u56db\u4e2a\u73b0\u6709\u63d0\u793a\u8bc4\u4f30\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5728CodeNet\u76f8\u5173\u6570\u636e\u96c6\u8868\u73b0\u597d\uff0co3 - mini\u7684F1\u5206\u6570\u8fbe0.943\uff0c\u5728BigCloneBench\u76f8\u5173\u6570\u636e\u96c6\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff1b\u591a\u6570\u6a21\u578b\u54cd\u5e94\u4e00\u81f4\u6027\u9ad8\uff0c\u8d8590%\u5224\u65ad\u4e00\u81f4\uff0cF1\u5206\u6570\u6ce2\u52a8\u5c0f\u4e8e0.03\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4e2d\u5728\u4e0d\u540c\u6570\u636e\u96c6\u8868\u73b0\u6709\u5dee\u5f02\uff0c\u4f46\u54cd\u5e94\u4e00\u81f4\u6027\u8f83\u597d\u3002"}}
{"id": "2511.00086", "pdf": "https://arxiv.org/pdf/2511.00086", "abs": "https://arxiv.org/abs/2511.00086", "authors": ["Fali Wang", "Jihai Chen", "Shuhua Yang", "Runxue Bao", "Tianxiang Zhao", "Zhiwei Zhang", "Xianfeng Tang", "Hui Liu", "Qi He", "Suhang Wang"], "title": "Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7"], "comment": "Under review", "summary": "Test-Time Scaling (TTS) improves large language models (LLMs) by allocating\nadditional computation during inference, typically through parallel,\nsequential, or hybrid scaling. However, prior studies often assume fixed\ncollaboration architectures (e.g., topologies) and single-model usage,\noverlooking that optimal architectures and model combinations can vary across\ntasks. Therefore, we study the novel problem of searching for compute-optimal\nmodel combinations and architectures in TTS under a fixed budget. We formalize\nit as a multi-LLM collaboration graph, where nodes encode roles and LLM model\nassignments, and edges capture information flow. This problem is challenging\nbecause (i) the combinatorial search space is prohibitively large, and (ii)\ntask-specific requirements demand tailored designs. To address these, we\nreformulate the problem as probabilistic graph optimization and, through pilot\nexperiments, derive three empirical insights into TTS collaboration graphs.\nGuided by these insights, we propose Agent-REINFORCE, an LLM-agent-augmented\nframework that mirrors the REINFORCE pipeline by mapping\nsampling-gradient-update to sampling-feedback-update, where feedback serves as\na textual gradient to update the probabilistic graph and efficiently search for\noptimal multi-LLM collaboration graphs. Experiments show that Agent-REINFORCE\noutperforms both traditional and LLM-based baselines in sample efficiency and\nsearch performance, and effectively identifies optimal graphs under joint\nobjectives of accuracy and inference latency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76TTS\u4e2d\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u641c\u7d22\u8ba1\u7b97\u6700\u4f18\u7684\u6a21\u578b\u7ec4\u5408\u548c\u67b6\u6784\u95ee\u9898\uff0c\u63d0\u51faAgent - REINFORCE\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u4ee5\u5f80TTS\u7814\u7a76\u5e38\u5047\u8bbe\u56fa\u5b9a\u534f\u4f5c\u67b6\u6784\u548c\u5355\u6a21\u578b\u4f7f\u7528\uff0c\u5ffd\u7565\u4efb\u52a1\u95f4\u6700\u4f18\u67b6\u6784\u548c\u6a21\u578b\u7ec4\u5408\u7684\u5dee\u5f02\uff0c\u56e0\u6b64\u7814\u7a76\u641c\u7d22\u8ba1\u7b97\u6700\u4f18\u7684\u6a21\u578b\u7ec4\u5408\u548c\u67b6\u6784\u95ee\u9898\u3002", "method": "\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u591aLLM\u534f\u4f5c\u56fe\uff0c\u518d\u5c06\u5176\u91cd\u65b0\u8868\u8ff0\u4e3a\u6982\u7387\u56fe\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5f97\u5230\u7ecf\u9a8c\u89c1\u89e3\uff0c\u63d0\u51faAgent - REINFORCE\u6846\u67b6\u8fdb\u884c\u641c\u7d22\u3002", "result": "Agent - REINFORCE\u5728\u6837\u672c\u6548\u7387\u548c\u641c\u7d22\u6027\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u548c\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u7cbe\u5ea6\u548c\u63a8\u7406\u5ef6\u8fdf\u8054\u5408\u76ee\u6807\u4e0b\u7684\u6700\u4f18\u56fe\u3002", "conclusion": "Agent - REINFORCE\u6846\u67b6\u53ef\u9ad8\u6548\u641c\u7d22TTS\u4e2d\u7684\u6700\u4f18\u591aLLM\u534f\u4f5c\u56fe\u3002"}}
{"id": "2511.00727", "pdf": "https://arxiv.org/pdf/2511.00727", "abs": "https://arxiv.org/abs/2511.00727", "authors": ["Xuelin Yang", "Licong Lin", "Susan Athey", "Michael I. Jordan", "Guido W. Imbens"], "title": "Cross-Validated Causal Inference: a Modern Method to Combine Experimental and Observational Data", "categories": ["econ.EM", "stat.ME", "stat.ML"], "comment": "83 pages, 11 figures", "summary": "We develop new methods to integrate experimental and observational data in\ncausal inference. While randomized controlled trials offer strong internal\nvalidity, they are often costly and therefore limited in sample size.\nObservational data, though cheaper and often with larger sample sizes, are\nprone to biases due to unmeasured confounders. To harness their complementary\nstrengths, we propose a systematic framework that formulates causal estimation\nas an empirical risk minimization (ERM) problem. A full model containing the\ncausal parameter is obtained by minimizing a weighted combination of\nexperimental and observational losses--capturing the causal parameter's\nvalidity and the full model's fit, respectively. The weight is chosen through\ncross-validation on the causal parameter across experimental folds. Our\nexperiments on real and synthetic data show the efficacy and reliability of our\nmethod. We also provide theoretical non-asymptotic error bounds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\u6574\u5408\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u5b9e\u9a8c\u4e0e\u89c2\u6d4b\u6570\u636e\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u5e76\u7ed9\u51fa\u7406\u8bba\u8bef\u5dee\u754c\u3002", "motivation": "\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u6210\u672c\u9ad8\u3001\u6837\u672c\u91cf\u6709\u9650\uff0c\u89c2\u6d4b\u6570\u636e\u6613\u53d7\u672a\u6d4b\u91cf\u6df7\u6742\u56e0\u7d20\u5f71\u54cd\u6709\u504f\u5dee\uff0c\u9700\u7ed3\u5408\u4e8c\u8005\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06\u56e0\u679c\u4f30\u8ba1\u8868\u8ff0\u4e3a\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5b9e\u9a8c\u548c\u89c2\u6d4b\u635f\u5931\u7684\u52a0\u6743\u7ec4\u5408\u5f97\u5230\u5305\u542b\u56e0\u679c\u53c2\u6570\u7684\u5b8c\u6574\u6a21\u578b\uff0c\u6743\u91cd\u901a\u8fc7\u5b9e\u9a8c\u6298\u4e0a\u56e0\u679c\u53c2\u6570\u7684\u4ea4\u53c9\u9a8c\u8bc1\u9009\u62e9\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u53ef\u9760\uff0c\u8fd8\u7ed9\u51fa\u4e86\u7406\u8bba\u975e\u6e10\u8fd1\u8bef\u5dee\u754c\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u6574\u5408\u5b9e\u9a8c\u548c\u89c2\u6d4b\u6570\u636e\u8fdb\u884c\u56e0\u679c\u63a8\u65ad\u3002"}}
{"id": "2511.01018", "pdf": "https://arxiv.org/pdf/2511.01018", "abs": "https://arxiv.org/abs/2511.01018", "authors": ["Hui-Lee Ooi", "Nicholas Mitsakakis", "Margerie Huet Dastarac", "Roger Zemek", "Amy C. Plint", "Jeff Gilchrist", "Khaled El Emam", "Dhenuka Radhakrishnan"], "title": "AI for pRedicting Exacerbations in KIDs with aSthma (AIRE-KIDS)", "categories": ["cs.AI"], "comment": null, "summary": "Recurrent exacerbations remain a common yet preventable outcome for many\nchildren with asthma. Machine learning (ML) algorithms using electronic medical\nrecords (EMR) could allow accurate identification of children at risk for\nexacerbations and facilitate referral for preventative comprehensive care to\navoid this morbidity. We developed ML algorithms to predict repeat severe\nexacerbations (i.e. asthma-related emergency department (ED) visits or future\nhospital admissions) for children with a prior asthma ED visit at a tertiary\ncare children's hospital.\n  Retrospective pre-COVID19 (Feb 2017 - Feb 2019, N=2716) Epic EMR data from\nthe Children's Hospital of Eastern Ontario (CHEO) linked with environmental\npollutant exposure and neighbourhood marginalization information was used to\ntrain various ML models. We used boosted trees (LGBM, XGB) and 3 open-source\nlarge language model (LLM) approaches (DistilGPT2, Llama 3.2 1B and\nLlama-8b-UltraMedical). Models were tuned and calibrated then validated in a\nsecond retrospective post-COVID19 dataset (Jul 2022 - Apr 2023, N=1237) from\nCHEO. Models were compared using the area under the curve (AUC) and F1 scores,\nwith SHAP values used to determine the most predictive features.\n  The LGBM ML model performed best with the most predictive features in the\nfinal AIRE-KIDS_ED model including prior asthma ED visit, the Canadian triage\nacuity scale, medical complexity, food allergy, prior ED visits for non-asthma\nrespiratory diagnoses, and age for an AUC of 0.712, and F1 score of 0.51. This\nis a nontrivial improvement over the current decision rule which has F1=0.334.\nWhile the most predictive features in the AIRE-KIDS_HOSP model included medical\ncomplexity, prior asthma ED visit, average wait time in the ED, the pediatric\nrespiratory assessment measure score at triage and food allergy.", "AI": {"tldr": "\u4f7f\u7528\u7535\u5b50\u75c5\u5386\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u9884\u6d4b\u54ee\u5598\u513f\u7ae5\u590d\u53d1\u4e25\u91cd\u6076\u5316\u60c5\u51b5\uff0cLGBM\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u51c6\u786e\u8bc6\u522b\u6709\u54ee\u5598\u6076\u5316\u98ce\u9669\u7684\u513f\u7ae5\uff0c\u4fc3\u8fdb\u9884\u9632\u6027\u7efc\u5408\u62a4\u7406\u8f6c\u8bca\uff0c\u907f\u514d\u53d1\u75c5\u3002", "method": "\u4f7f\u7528\u5b89\u5927\u7565\u4e1c\u90e8\u513f\u7ae5\u533b\u9662\u56de\u987e\u6027COVID-19\u524d\u540e\u7684\u7535\u5b50\u75c5\u5386\u6570\u636e\uff0c\u7ed3\u5408\u73af\u5883\u6c61\u67d3\u7269\u66b4\u9732\u548c\u793e\u533a\u8fb9\u7f18\u5316\u4fe1\u606f\uff0c\u8bad\u7ec3\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u63d0\u5347\u6811\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7AUC\u548cF1\u5206\u6570\u6bd4\u8f83\u6a21\u578b\uff0c\u7528SHAP\u503c\u786e\u5b9a\u6700\u5177\u9884\u6d4b\u6027\u7684\u7279\u5f81\u3002", "result": "LGBM\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cAIRE - KIDS_ED\u6a21\u578bAUC\u4e3a0.712\uff0cF1\u5206\u6570\u4e3a0.51\uff1bAIRE - KIDS_HOSP\u6a21\u578b\u786e\u5b9a\u4e86\u6700\u5177\u9884\u6d4b\u6027\u7684\u7279\u5f81\u3002", "conclusion": "\u5f00\u53d1\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6709\u4e00\u5b9a\u6548\u679c\uff0cLGBM\u6a21\u578b\u76f8\u6bd4\u5f53\u524d\u51b3\u7b56\u89c4\u5219\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2511.01252", "pdf": "https://arxiv.org/pdf/2511.01252", "abs": "https://arxiv.org/abs/2511.01252", "authors": ["Siyuan Li", "Yaowen Zheng", "Hong Li", "Jingdong Guo", "Chaopeng Dong", "Chunpeng Yan", "Weijie Wang", "Yimo Ren", "Limin Sun", "Hongsong Zhu"], "title": "Lares: LLM-driven Code Slice Semantic Search for Patch Presence Testing", "categories": ["cs.SE"], "comment": null, "summary": "In modern software ecosystems, 1-day vulnerabilities pose significant\nsecurity risks due to extensive code reuse. Identifying vulnerable functions in\ntarget binaries alone is insufficient; it is also crucial to determine whether\nthese functions have been patched. Existing methods, however, suffer from\nlimited usability and accuracy. They often depend on the compilation process to\nextract features, requiring substantial manual effort and failing for certain\nsoftware. Moreover, they cannot reliably differentiate between code changes\ncaused by patches or compilation variations. To overcome these limitations, we\npropose Lares, a scalable and accurate method for patch presence testing. Lares\nintroduces Code Slice Semantic Search, which directly extracts features from\nthe patch source code and identifies semantically equivalent code slices in the\npseudocode of the target binary. By eliminating the need for the compilation\nprocess, Lares improves usability, while leveraging large language models\n(LLMs) for code analysis and SMT solvers for logical reasoning to enhance\naccuracy. Experimental results show that Lares achieves superior precision,\nrecall, and usability. Furthermore, it is the first work to evaluate patch\npresence testing across optimization levels, architectures, and compilers. The\ndatasets and source code used in this article are available at\nhttps://github.com/Siyuan-Li201/Lares.", "AI": {"tldr": "\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u6d4b\u76ee\u6807\u4e8c\u8fdb\u5236\u6587\u4ef6\u8865\u4e01\u65f6\u53ef\u7528\u6027\u548c\u51c6\u786e\u6027\u6709\u9650\uff0c\u63d0\u51faLares\u65b9\u6cd5\uff0c\u5229\u7528\u4ee3\u7801\u5207\u7247\u8bed\u4e49\u641c\u7d22\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u53ef\u7528\u6027\u66f4\u4f18\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u751f\u6001\u4e2d1 - day\u6f0f\u6d1e\u98ce\u9669\u5927\uff0c\u73b0\u6709\u68c0\u6d4b\u8865\u4e01\u65b9\u6cd5\u53ef\u7528\u6027\u548c\u51c6\u786e\u6027\u6709\u9650\uff0c\u4f9d\u8d56\u7f16\u8bd1\u8fc7\u7a0b\uff0c\u96be\u4ee5\u533a\u5206\u8865\u4e01\u548c\u7f16\u8bd1\u5dee\u5f02\u5bfc\u81f4\u7684\u4ee3\u7801\u53d8\u5316\u3002", "method": "\u63d0\u51faLares\u65b9\u6cd5\uff0c\u5f15\u5165\u4ee3\u7801\u5207\u7247\u8bed\u4e49\u641c\u7d22\uff0c\u76f4\u63a5\u4ece\u8865\u4e01\u6e90\u4ee3\u7801\u63d0\u53d6\u7279\u5f81\uff0c\u5728\u76ee\u6807\u4e8c\u8fdb\u5236\u4f2a\u4ee3\u7801\u4e2d\u627e\u8bed\u4e49\u7b49\u6548\u4ee3\u7801\u5207\u7247\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u4ee3\u7801\uff0cSMT\u6c42\u89e3\u5668\u8fdb\u884c\u903b\u8f91\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLares\u5728\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548c\u53ef\u7528\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u662f\u9996\u4e2a\u8de8\u4f18\u5316\u7ea7\u522b\u3001\u67b6\u6784\u548c\u7f16\u8bd1\u5668\u8bc4\u4f30\u8865\u4e01\u5b58\u5728\u6027\u6d4b\u8bd5\u7684\u5de5\u4f5c\u3002", "conclusion": "Lares\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u8865\u4e01\u5b58\u5728\u6027\u6d4b\u8bd5\u7684\u6548\u679c\u3002"}}
{"id": "2511.00097", "pdf": "https://arxiv.org/pdf/2511.00097", "abs": "https://arxiv.org/abs/2511.00097", "authors": ["Zihao Guo", "Qingyun Sun", "Ziwei Zhang", "Haonan Yuan", "Huiping Zhuang", "Xingcheng Fu", "Jianxin Li"], "title": "GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by the Main Track of NeurIPS-2025", "summary": "Graph incremental learning (GIL), which continuously updates graph models by\nsequential knowledge acquisition, has garnered significant interest recently.\nHowever, existing GIL approaches focus on task-incremental and\nclass-incremental scenarios within a single domain. Graph domain-incremental\nlearning (Domain-IL), aiming at updating models across multiple graph domains,\nhas become critical with the development of graph foundation models (GFMs), but\nremains unexplored in the literature. In this paper, we propose Graph\nDomain-Incremental Learning via Knowledge Dientanglement and Preservation\n(GraphKeeper), to address catastrophic forgetting in Domain-IL scenario from\nthe perspectives of embedding shifts and decision boundary deviations.\nSpecifically, to prevent embedding shifts and confusion across incremental\ngraph domains, we first propose the domain-specific parameter-efficient\nfine-tuning together with intra- and inter-domain disentanglement objectives.\nConsequently, to maintain a stable decision boundary, we introduce\ndeviation-free knowledge preservation to continuously fit incremental domains.\nAdditionally, for graphs with unobservable domains, we perform domain-aware\ndistribution discrimination to obtain precise embeddings. Extensive experiments\ndemonstrate the proposed GraphKeeper achieves state-of-the-art results with\n6.5%~16.6% improvement over the runner-up with negligible forgetting. Moreover,\nwe show GraphKeeper can be seamlessly integrated with various representative\nGFMs, highlighting its broad applicative potential.", "AI": {"tldr": "\u63d0\u51faGraphKeeper\u65b9\u6cd5\u89e3\u51b3\u56fe\u9886\u57df\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\u4e14\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u56fe\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u96c6\u4e2d\u5728\u5355\u9886\u57df\uff0c\u56fe\u9886\u57df\u589e\u91cf\u5b66\u4e60\u5728\u56fe\u57fa\u7840\u6a21\u578b\u53d1\u5c55\u4e0b\u53d8\u5f97\u5173\u952e\u4f46\u672a\u88ab\u7814\u7a76\uff0c\u9700\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7279\u5b9a\u9886\u57df\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u53ca\u57df\u5185\u548c\u57df\u95f4\u89e3\u7ea0\u7f20\u76ee\u6807\u9632\u6b62\u5d4c\u5165\u504f\u79fb\uff0c\u5f15\u5165\u65e0\u504f\u5dee\u77e5\u8bc6\u4fdd\u5b58\u7ef4\u62a4\u51b3\u7b56\u8fb9\u754c\uff0c\u5bf9\u4e0d\u53ef\u89c2\u5bdf\u57df\u7684\u56fe\u8fdb\u884c\u57df\u611f\u77e5\u5206\u5e03\u5224\u522b\u3002", "result": "GraphKeeper\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u6bd4\u6b21\u4f18\u65b9\u6cd5\u63d0\u9ad86.5% - 16.6%\uff0c\u9057\u5fd8\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "GraphKeeper\u80fd\u6709\u6548\u89e3\u51b3\u56fe\u9886\u57df\u589e\u91cf\u5b66\u4e60\u95ee\u9898\uff0c\u4e14\u53ef\u4e0e\u591a\u79cd\u4ee3\u8868\u6027\u56fe\u57fa\u7840\u6a21\u578b\u65e0\u7f1d\u96c6\u6210\uff0c\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.00904", "pdf": "https://arxiv.org/pdf/2511.00904", "abs": "https://arxiv.org/abs/2511.00904", "authors": ["Ernesto Araya", "Massimiliano Datres", "Gitta Kutyniok"], "title": "Random Spiking Neural Networks are Stable and Spectrally Simple", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Spiking neural networks (SNNs) are a promising paradigm for energy-efficient\ncomputation, yet their theoretical foundations-especially regarding stability\nand robustness-remain limited compared to artificial neural networks. In this\nwork, we study discrete-time leaky integrate-and-fire (LIF) SNNs through the\nlens of Boolean function analysis. We focus on noise sensitivity and stability\nin classification tasks, quantifying how input perturbations affect outputs.\nOur main result shows that wide LIF-SNN classifiers are stable on average, a\nproperty explained by the concentration of their Fourier spectrum on\nlow-frequency components. Motivated by this, we introduce the notion of\nspectral simplicity, which formalizes simplicity in terms of Fourier spectrum\nconcentration and connects our analysis to the simplicity bias observed in deep\nnetworks. Within this framework, we show that random LIF-SNNs are biased toward\nsimple functions. Experiments on trained networks confirm that these stability\nproperties persist in practice. Together, these results provide new insights\ninto the stability and robustness properties of SNNs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5e03\u5c14\u51fd\u6570\u5206\u6790\u7814\u7a76\u79bb\u6563\u65f6\u95f4LIF - SNNs\uff0c\u53d1\u73b0\u5bbdLIF - SNN\u5206\u7c7b\u5668\u5e73\u5747\u7a33\u5b9a\uff0c\u5f15\u5165\u9891\u8c31\u7b80\u5355\u6027\u6982\u5ff5\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u7a33\u5b9a\u6027\u5728\u5b9e\u9645\u4e2d\u5b58\u5728\uff0c\u4e3aSNN\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002", "motivation": "\u5c16\u5cf0\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u5728\u8282\u80fd\u8ba1\u7b97\u65b9\u9762\u6709\u524d\u666f\uff0c\u4f46\u4e0e\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u76f8\u6bd4\uff0c\u5176\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u7684\u7406\u8bba\u57fa\u7840\u6709\u9650\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5e03\u5c14\u51fd\u6570\u5206\u6790\u7814\u7a76\u79bb\u6563\u65f6\u95f4LIF - SNNs\uff0c\u91cf\u5316\u8f93\u5165\u6270\u52a8\u5bf9\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "result": "\u5bbdLIF - SNN\u5206\u7c7b\u5668\u5e73\u5747\u7a33\u5b9a\uff0c\u5176\u5085\u91cc\u53f6\u9891\u8c31\u96c6\u4e2d\u5728\u4f4e\u9891\u5206\u91cf\uff1b\u5f15\u5165\u9891\u8c31\u7b80\u5355\u6027\u6982\u5ff5\uff0c\u968f\u673aLIF - SNNs\u503e\u5411\u4e8e\u7b80\u5355\u51fd\u6570\uff1b\u8bad\u7ec3\u7f51\u7edc\u5b9e\u9a8c\u8bc1\u5b9e\u7a33\u5b9a\u6027\u7279\u6027\u5728\u5b9e\u9645\u4e2d\u5b58\u5728\u3002", "conclusion": "\u7814\u7a76\u4e3aSNNs\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2511.01033", "pdf": "https://arxiv.org/pdf/2511.01033", "abs": "https://arxiv.org/abs/2511.01033", "authors": ["Tiberiu Musat", "Tiago Pimentel", "Lorenzo Noci", "Alessandro Stolfo", "Mrinmaya Sachan", "Thomas Hofmann"], "title": "On the Emergence of Induction Heads for In-Context Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Transformers have become the dominant architecture for natural language\nprocessing. Part of their success is owed to a remarkable capability known as\nin-context learning (ICL): they can acquire and apply novel associations solely\nfrom their input context, without any updates to their weights. In this work,\nwe study the emergence of induction heads, a previously identified mechanism in\ntwo-layer transformers that is particularly important for in-context learning.\nWe uncover a relatively simple and interpretable structure of the weight\nmatrices implementing the induction head. We theoretically explain the origin\nof this structure using a minimal ICL task formulation and a modified\ntransformer architecture. We give a formal proof that the training dynamics\nremain constrained to a 19-dimensional subspace of the parameter space.\nEmpirically, we validate this constraint while observing that only 3 dimensions\naccount for the emergence of an induction head. By further studying the\ntraining dynamics inside this 3-dimensional subspace, we find that the time\nuntil the emergence of an induction head follows a tight asymptotic bound that\nis quadratic in the input context length.", "AI": {"tldr": "\u7814\u7a76\u4e24\u5c42Transformer\u4e2d\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\u5f88\u91cd\u8981\u7684\u5f52\u7eb3\u5934\u7684\u51fa\u73b0\u673a\u5236\uff0c\u63ed\u793a\u6743\u91cd\u77e9\u9635\u7ed3\u6784\uff0c\u7406\u8bba\u89e3\u91ca\u5176\u6765\u6e90\uff0c\u8bc1\u660e\u8bad\u7ec3\u52a8\u6001\u53d7\u9650\u4e8e\u53c2\u6570\u7a7a\u95f4\u768419\u7ef4\u5b50\u7a7a\u95f4\uff0c\u5b9e\u8bc1\u53d1\u73b0\u4ec53\u7ef4\u4e0e\u5f52\u7eb3\u5934\u51fa\u73b0\u6709\u5173\uff0c\u8fd8\u53d1\u73b0\u5f52\u7eb3\u5934\u51fa\u73b0\u65f6\u95f4\u4e0e\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u4e8c\u6b21\u65b9\u6709\u5173\u3002", "motivation": "Transformer\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u53d6\u5f97\u6210\u529f\uff0c\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u662f\u5176\u4f18\u52bf\u4e4b\u4e00\uff0c\u7814\u7a76\u4e24\u5c42Transformer\u4e2d\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\u91cd\u8981\u7684\u5f52\u7eb3\u5934\u7684\u51fa\u73b0\u673a\u5236\u3002", "method": "\u901a\u8fc7\u6700\u5c0f\u4e0a\u4e0b\u6587\u5b66\u4e60\u4efb\u52a1\u516c\u5f0f\u548c\u4fee\u6539\u540e\u7684Transformer\u67b6\u6784\u7406\u8bba\u89e3\u91ca\u6743\u91cd\u77e9\u9635\u7ed3\u6784\u7684\u6765\u6e90\uff0c\u7ed9\u51fa\u8bad\u7ec3\u52a8\u6001\u53d7\u9650\u4e8e19\u7ef4\u5b50\u7a7a\u95f4\u7684\u6b63\u5f0f\u8bc1\u660e\uff0c\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u63ed\u793a\u4e86\u5b9e\u73b0\u5f52\u7eb3\u5934\u7684\u6743\u91cd\u77e9\u9635\u76f8\u5bf9\u7b80\u5355\u4e14\u53ef\u89e3\u91ca\u7684\u7ed3\u6784\uff1b\u8bad\u7ec3\u52a8\u6001\u53d7\u9650\u4e8e\u53c2\u6570\u7a7a\u95f4\u768419\u7ef4\u5b50\u7a7a\u95f4\uff0c\u4ec53\u7ef4\u4e0e\u5f52\u7eb3\u5934\u51fa\u73b0\u6709\u5173\uff1b\u5f52\u7eb3\u5934\u51fa\u73b0\u65f6\u95f4\u4e0e\u8f93\u5165\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u4e8c\u6b21\u65b9\u6709\u7d27\u5bc6\u7684\u6e10\u8fd1\u754c\u9650\u3002", "conclusion": "\u5bf9\u4e24\u5c42Transformer\u4e2d\u5f52\u7eb3\u5934\u7684\u51fa\u73b0\u673a\u5236\u6709\u4e86\u66f4\u6df1\u5165\u7684\u7406\u89e3\uff0c\u5305\u62ec\u6743\u91cd\u77e9\u9635\u7ed3\u6784\u3001\u8bad\u7ec3\u52a8\u6001\u7684\u7ef4\u5ea6\u9650\u5236\u4ee5\u53ca\u5f52\u7eb3\u5934\u51fa\u73b0\u65f6\u95f4\u4e0e\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u5173\u7cfb\u3002"}}
{"id": "2511.01316", "pdf": "https://arxiv.org/pdf/2511.01316", "abs": "https://arxiv.org/abs/2511.01316", "authors": ["Chong Wang", "Chen Zhang", "Jiajun Wu", "Wunan Guo", "Jianfeng Qu", "Yewen Tian", "Yang Liu"], "title": "Exploringand Unleashing the Power of Large Language Models in CI/CD Configuration Translation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Continuous Integration (CI) is a cornerstone of modern collaborative software\ndevelopment, and numerous CI platforms are available. Differences in\nmaintenance overhead, reliability, and integration depth with code-hosting\nplatforms make migration between CI platforms a common practice. A central step\nin migration is translating CI configurations, which is challenging due to the\nintrinsic complexity of CI configurations and the need to understand semantic\ndifferences and relationships across CI platforms.\n  With the advent of large language models (LLMs), recent advances in software\nengineering highlight their potential for CI configuration translation. In this\npaper, we present a study on LLM-based CI configuration translation, focusing\non the migration from Travis CI to GitHub Actions. First, using 811 migration\nrecords, we quantify the effort involved and find that developers read an\naverage of 38 lines of Travis configuration and write 58 lines of GitHub\nActions configuration, with nearly half of the migrations requiring multiple\ncommits. We further analyze translations produced by each of the four LLMs and\nidentify 1,121 issues grouped into four categories: logic inconsistencies\n(38%), platform discrepancies (32%), environment errors (25%), and syntax\nerrors (5%). Finally, we evaluate three enhancement strategies and show that\ncombining guideline-based prompting with iterative refinement achieves the best\nperformance, reaching a Build Success Rate of 75.5%-nearly a threefold\nimprovement over GPT-4o with a basic prompt.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684CI\u914d\u7f6e\u7ffb\u8bd1\uff0c\u805a\u7126\u4eceTravis CI\u8fc1\u79fb\u5230GitHub Actions\uff0c\u91cf\u5316\u8fc1\u79fb\u5de5\u4f5c\u91cf\u3001\u5206\u6790\u7ffb\u8bd1\u95ee\u9898\u5e76\u8bc4\u4f30\u589e\u5f3a\u7b56\u7565\uff0c\u7ed3\u5408\u6307\u5357\u63d0\u793a\u548c\u8fed\u4ee3\u4f18\u5316\u6548\u679c\u6700\u4f73\u3002", "motivation": "CI\u5e73\u53f0\u8fc1\u79fb\u5e38\u89c1\uff0cCI\u914d\u7f6e\u7ffb\u8bd1\u6709\u6311\u6218\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u6709\u6f5c\u529b\u7528\u4e8eCI\u914d\u7f6e\u7ffb\u8bd1\u3002", "method": "\u4f7f\u7528811\u6761\u8fc1\u79fb\u8bb0\u5f55\u91cf\u5316\u8fc1\u79fb\u5de5\u4f5c\u91cf\uff0c\u5206\u6790\u56db\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ffb\u8bd1\u7ed3\u679c\uff0c\u8bc4\u4f30\u4e09\u79cd\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u5f00\u53d1\u8005\u5e73\u5747\u9605\u8bfb38\u884cTravis\u914d\u7f6e\u3001\u7f16\u519958\u884cGitHub Actions\u914d\u7f6e\uff0c\u8fd1\u534a\u8fc1\u79fb\u9700\u591a\u6b21\u63d0\u4ea4\uff1b\u53d1\u73b01121\u4e2a\u95ee\u9898\u5206\u56db\u7c7b\uff1b\u7ed3\u5408\u6307\u5357\u63d0\u793a\u548c\u8fed\u4ee3\u4f18\u5316\u6784\u5efa\u6210\u529f\u7387\u8fbe75.5%\uff0c\u6bd4\u57fa\u7840\u63d0\u793a\u7684GPT - 4o\u63d0\u9ad8\u8fd1\u4e09\u500d\u3002", "conclusion": "\u7ed3\u5408\u6307\u5357\u63d0\u793a\u548c\u8fed\u4ee3\u4f18\u5316\u5728\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684CI\u914d\u7f6e\u7ffb\u8bd1\u4e2d\u6027\u80fd\u6700\u4f73\u3002"}}
{"id": "2511.00099", "pdf": "https://arxiv.org/pdf/2511.00099", "abs": "https://arxiv.org/abs/2511.00099", "authors": ["Marios Impraimakis", "Evangelia Nektaria Palkanoglou"], "title": "A generative adversarial network optimization method for damage detection and digital twinning by deep AI fault learning: Z24 Bridge structural health monitoring benchmark validation", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SY", "eess.SP", "eess.SY", "68T05 (Learning and adaptive systems) 93C95 (Neural networks in\n  control theory)", "I.2.6; I.2.8"], "comment": "21 pages, 23 figures, published in Structural and Multidisciplinary\n  Optimization", "summary": "The optimization-based damage detection and damage state digital twinning\ncapabilities are examined here of a novel conditional-labeled generative\nadversarial network methodology. The framework outperforms current approaches\nfor fault anomaly detection as no prior information is required for the health\nstate of the system: a topic of high significance for real-world applications.\nSpecifically, current artificial intelligence-based digital twinning approaches\nsuffer from the uncertainty related to obtaining poor predictions when a low\nnumber of measurements is available, physics knowledge is missing, or when the\ndamage state is unknown. To this end, an unsupervised framework is examined and\nvalidated rigorously on the benchmark structural health monitoring measurements\nof Z24 Bridge: a post-tensioned concrete highway bridge in Switzerland. In\nimplementing the approach, firstly, different same damage-level measurements\nare used as inputs, while the model is forced to converge conditionally to two\ndifferent damage states. Secondly, the process is repeated for a different\ngroup of measurements. Finally, the convergence scores are compared to identify\nwhich one belongs to a different damage state. The process for both\nhealthy-to-healthy and damage-to-healthy input data creates, simultaneously,\nmeasurements for digital twinning purposes at different damage states, capable\nof pattern recognition and machine learning data generation. Further to this\nprocess, a support vector machine classifier and a principal component analysis\nprocedure is developed to assess the generated and real measurements of each\ndamage category, serving as a secondary new dynamics learning indicator in\ndamage scenarios. Importantly, the approach is shown to capture accurately\ndamage over healthy measurements, providing a powerful tool for vibration-based\nsystem-level monitoring and scalable infrastructure resilience.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u4f18\u5316\u7684\u635f\u4f24\u68c0\u6d4b\u548c\u635f\u4f24\u72b6\u6001\u6570\u5b57\u5b6a\u751f\u80fd\u529b\u7684\u65b0\u578b\u6761\u4ef6\u6807\u7b7e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u65b9\u6cd5\uff0c\u5728Z24\u6865\u9a8c\u8bc1\uff0c\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\u5728\u6d4b\u91cf\u6570\u636e\u5c11\u3001\u7f3a\u4e4f\u7269\u7406\u77e5\u8bc6\u6216\u635f\u4f24\u72b6\u6001\u672a\u77e5\u65f6\u9884\u6d4b\u6548\u679c\u5dee\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u4e0d\u540c\u76f8\u540c\u635f\u4f24\u7ea7\u522b\u7684\u6d4b\u91cf\u6570\u636e\u4f5c\u4e3a\u8f93\u5165\uff0c\u8ba9\u6a21\u578b\u6709\u6761\u4ef6\u6536\u655b\u5230\u4e0d\u540c\u635f\u4f24\u72b6\u6001\uff0c\u91cd\u590d\u8be5\u8fc7\u7a0b\u5e76\u6bd4\u8f83\u6536\u655b\u5206\u6570\uff1b\u5f00\u53d1\u652f\u6301\u5411\u91cf\u673a\u5206\u7c7b\u5668\u548c\u4e3b\u6210\u5206\u5206\u6790\u7a0b\u5e8f\u8bc4\u4f30\u751f\u6210\u548c\u771f\u5b9e\u6d4b\u91cf\u6570\u636e\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u6355\u6349\u635f\u4f24\uff0c\u4e3a\u632f\u52a8\u7cfb\u7edf\u7ea7\u76d1\u6d4b\u548c\u57fa\u7840\u8bbe\u65bd\u5f39\u6027\u63d0\u4f9b\u6709\u529b\u5de5\u5177\u3002", "conclusion": "\u65b0\u578b\u6761\u4ef6\u6807\u7b7e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6545\u969c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u9002\u5408\u73b0\u5b9e\u5e94\u7528\u3002"}}
{"id": "2511.00958", "pdf": "https://arxiv.org/pdf/2511.00958", "abs": "https://arxiv.org/abs/2511.00958", "authors": ["Khoat Than"], "title": "The Hidden Power of Normalization: Exponential Capacity Control in Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Normalization methods are fundamental components of modern deep neural\nnetworks (DNNs). Empirically, they are known to stabilize optimization dynamics\nand improve generalization. However, the underlying theoretical mechanism by\nwhich normalization contributes to both optimization and generalization remains\nlargely unexplained, especially when using many normalization layers in a DNN\narchitecture.\n  In this work, we develop a theoretical framework that elucidates the role of\nnormalization through the lens of capacity control. We prove that an\nunnormalized DNN can exhibit exponentially large Lipschitz constants with\nrespect to either its parameters or inputs, implying excessive functional\ncapacity and potential overfitting. Such bad DNNs are uncountably many. In\ncontrast, the insertion of normalization layers provably can reduce the\nLipschitz constant at an exponential rate in the number of normalization\noperations. This exponential reduction yields two fundamental consequences: (1)\nit smooths the loss landscape at an exponential rate, facilitating faster and\nmore stable optimization; and (2) it constrains the effective capacity of the\nnetwork, thereby enhancing generalization guarantees on unseen data. Our\nresults thus offer a principled explanation for the empirical success of\nnormalization methods in deep learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u5bb9\u91cf\u63a7\u5236\u89d2\u5ea6\u89e3\u91ca\u5f52\u4e00\u5316\u65b9\u6cd5\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4f5c\u7528\uff0c\u8bc1\u660e\u5176\u80fd\u964d\u4f4eLipschitz\u5e38\u6570\uff0c\u5229\u4e8e\u4f18\u5316\u548c\u6cdb\u5316\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u672a\u5145\u5206\u89e3\u91ca\u5f52\u4e00\u5316\u65b9\u6cd5\u5bf9\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u548c\u6cdb\u5316\u7684\u4f5c\u7528\u673a\u5236\uff0c\u5c24\u5176\u662f\u4f7f\u7528\u591a\u4e2a\u5f52\u4e00\u5316\u5c42\u65f6\u3002", "method": "\u6784\u5efa\u7406\u8bba\u6846\u67b6\uff0c\u5bf9\u6bd4\u672a\u5f52\u4e00\u5316\u548c\u63d2\u5165\u5f52\u4e00\u5316\u5c42\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684Lipschitz\u5e38\u6570\u3002", "result": "\u672a\u5f52\u4e00\u5316\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edcLipschitz\u5e38\u6570\u53ef\u80fd\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u63d2\u5165\u5f52\u4e00\u5316\u5c42\u53ef\u6307\u6570\u7ea7\u964d\u4f4e\u8be5\u5e38\u6570\uff0c\u8fdb\u800c\u5e73\u6ed1\u635f\u5931\u666f\u89c2\u3001\u7ea6\u675f\u7f51\u7edc\u6709\u6548\u5bb9\u91cf\u3002", "conclusion": "\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5f52\u4e00\u5316\u65b9\u6cd5\u7684\u7ecf\u9a8c\u6210\u529f\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u3002"}}
{"id": "2511.01052", "pdf": "https://arxiv.org/pdf/2511.01052", "abs": "https://arxiv.org/abs/2511.01052", "authors": ["Yeawon Lee", "Christopher C. Yang", "Chia-Hsuan Chang", "Grace Lu-Yao"], "title": "Knowledge Elicitation with Large Language Models for Interpretable Cancer Stage Identification from Pathology Reports", "categories": ["cs.AI", "physics.med-ph"], "comment": null, "summary": "Cancer staging is critical for patient prognosis and treatment planning, yet\nextracting pathologic TNM staging from unstructured pathology reports poses a\npersistent challenge. Existing natural language processing (NLP) and machine\nlearning (ML) strategies often depend on large annotated datasets, limiting\ntheir scalability and adaptability. In this study, we introduce two Knowledge\nElicitation methods designed to overcome these limitations by enabling large\nlanguage models (LLMs) to induce and apply domain-specific rules for cancer\nstaging. The first, Knowledge Elicitation with Long-Term Memory (KEwLTM), uses\nan iterative prompting strategy to derive staging rules directly from\nunannotated pathology reports, without requiring ground-truth labels. The\nsecond, Knowledge Elicitation with Retrieval-Augmented Generation (KEwRAG),\nemploys a variation of RAG where rules are pre-extracted from relevant\nguidelines in a single step and then applied, enhancing interpretability and\navoiding repeated retrieval overhead. We leverage the ability of LLMs to apply\nbroad knowledge learned during pre-training to new tasks. Using breast cancer\npathology reports from the TCGA dataset, we evaluate their performance in\nidentifying T and N stages, comparing them against various baseline approaches\non two open-source LLMs. Our results indicate that KEwLTM outperforms KEwRAG\nwhen Zero-Shot Chain-of-Thought (ZSCOT) inference is effective, whereas KEwRAG\nachieves better performance when ZSCOT inference is less effective. Both\nmethods offer transparent, interpretable interfaces by making the induced rules\nexplicit. These findings highlight the promise of our Knowledge Elicitation\nmethods as scalable, high-performing solutions for automated cancer staging\nwith enhanced interpretability, particularly in clinical settings with limited\nannotated data.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e24\u79cd\u77e5\u8bc6\u63d0\u53d6\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u764c\u75c7\u5206\u671f\uff0c\u5728\u4e73\u817a\u764c\u75c5\u7406\u62a5\u544a\u4e0a\u8bc4\u4f30\uff0c\u4e24\u79cd\u65b9\u6cd5\u5404\u6709\u4f18\u52bf\uff0c\u4e3a\u81ea\u52a8\u764c\u75c7\u5206\u671f\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709NLP\u548cML\u7b56\u7565\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u89e3\u51b3\u4ece\u975e\u7ed3\u6784\u5316\u75c5\u7406\u62a5\u544a\u4e2d\u63d0\u53d6\u75c5\u7406TNM\u5206\u671f\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u77e5\u8bc6\u63d0\u53d6\u65b9\u6cd5\uff0cKEwLTM\u901a\u8fc7\u8fed\u4ee3\u63d0\u793a\u7b56\u7565\u4ece\u65e0\u6807\u6ce8\u75c5\u7406\u62a5\u544a\u4e2d\u63a8\u5bfc\u5206\u671f\u89c4\u5219\uff1bKEwRAG\u91c7\u7528RAG\u53d8\u4f53\uff0c\u4ece\u76f8\u5173\u6307\u5357\u4e2d\u9884\u63d0\u53d6\u89c4\u5219\u5e76\u5e94\u7528\u3002", "result": "\u5728\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u63a8\u7406\u6709\u6548\u65f6\uff0cKEwLTM\u8868\u73b0\u4f18\u4e8eKEwRAG\uff1b\u63a8\u7406\u6548\u679c\u4e0d\u4f73\u65f6\uff0cKEwRAG\u8868\u73b0\u66f4\u597d\uff0c\u4e24\u79cd\u65b9\u6cd5\u8bf1\u5bfc\u89c4\u5219\u660e\u786e\uff0c\u754c\u9762\u900f\u660e\u53ef\u89e3\u91ca\u3002", "conclusion": "\u77e5\u8bc6\u63d0\u53d6\u65b9\u6cd5\u662f\u81ea\u52a8\u764c\u75c7\u5206\u671f\u7684\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u4e34\u5e8a\u73af\u5883\u3002"}}
{"id": "2511.01324", "pdf": "https://arxiv.org/pdf/2511.01324", "abs": "https://arxiv.org/abs/2511.01324", "authors": ["Lekshmi Murali Rani", "Richard Berntsson Svensson", "Robert Feldt"], "title": "AI for Requirements Engineering: Industry adoption and Practitioner perspectives", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "Accepted at the Intelligent Software Engineering (ISE) 2025 Workshop\n  at the Automated Software Engineering (ASE) 2025 Conference", "summary": "The integration of AI for Requirements Engineering (RE) presents significant\nbenefits but also poses real challenges.Although RE is fundamental to software\nengineering, limited research has examined AI adoption in RE.We surveyed 55\nsoftware practitioners to map AI usage across four RE phases:Elicitation,\nAnalysis, Specification, and Validation, and four approaches for decision\nmaking: human only decisions, AI validation, Human AI Collaboration (HAIC), and\nfull AI automation.Participants also shared their perceptions, challenges, and\nopportunities when applying AI for RE tasks.Our data show that 58.2% of\nrespondents already use AI in RE, and 69.1% view its impact as positive or very\npositive.HAIC dominates practice, accounting for 54.4% of all RE techniques,\nwhile full AI automation remains minimal at 5.4%.Passive AI validation (4.4 to\n6.2%) lags even further behind, indicating that practitioners value AI's active\nsupport over passive oversight.These findings suggest that AI is most effective\nwhen positioned as a collaborative partner rather than a replacement for human\nexpertise.It also highlights the need for RE specific HAIC frameworks along\nwith robust and responsible AI governance as AI adoption in RE grows.", "AI": {"tldr": "\u5bf955\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8c03\u67e5AI\u5728\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u56db\u4e2a\u9636\u6bb5\u548c\u56db\u79cd\u51b3\u7b56\u65b9\u5f0f\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u53d1\u73b0\u591a\u6570\u4ece\u4e1a\u8005\u5df2\u7528AI\u4e14\u8bc4\u4ef7\u79ef\u6781\uff0c\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u5360\u4e3b\u5bfc\uff0c\u8868\u660eAI\u4f5c\u534f\u4f5c\u4f19\u4f34\u66f4\u6709\u6548\uff0c\u9700RE\u7279\u5b9a\u534f\u4f5c\u6846\u67b6\u548cAI\u6cbb\u7406\u3002", "motivation": "AI\u7528\u4e8eRE\u6709\u597d\u5904\u4e5f\u6709\u6311\u6218\uff0c\u800c\u76f8\u5173\u7814\u7a76\u6709\u9650\uff0c\u9700\u4e86\u89e3AI\u5728RE\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "method": "\u5bf955\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8fdb\u884c\u8c03\u67e5\uff0c\u6db5\u76d6RE\u56db\u4e2a\u9636\u6bb5\u548c\u56db\u79cd\u51b3\u7b56\u65b9\u5f0f\uff0c\u5e76\u6536\u96c6\u4ed6\u4eec\u7684\u770b\u6cd5\u3001\u6311\u6218\u548c\u673a\u4f1a\u3002", "result": "58.2%\u53d7\u8bbf\u8005\u5df2\u5728RE\u4e2d\u4f7f\u7528AI\uff0c69.1%\u8ba4\u4e3a\u5176\u5f71\u54cd\u79ef\u6781\uff1b\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u5360\u6bd454.4%\uff0c\u5168AI\u81ea\u52a8\u5316\u4ec55.4%\uff0c\u88ab\u52a8AI\u9a8c\u8bc1\u66f4\u5c11\u3002", "conclusion": "AI\u4f5c\u4e3a\u534f\u4f5c\u4f19\u4f34\u66f4\u6709\u6548\uff0c\u968f\u7740AI\u5728RE\u4e2d\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981RE\u7279\u5b9a\u7684\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u6846\u67b6\u548c\u5065\u5168\u8d1f\u8d23\u7684AI\u6cbb\u7406\u3002"}}
{"id": "2511.00100", "pdf": "https://arxiv.org/pdf/2511.00100", "abs": "https://arxiv.org/abs/2511.00100", "authors": ["Marios Impraimakis"], "title": "Deep recurrent-convolutional neural network learning and physics Kalman filtering comparison in dynamic load identification", "categories": ["cs.LG", "cs.CV", "cs.SY", "eess.SP", "eess.SY", "stat.AP", "68T05 (Learning and adaptive systems) 93C95 (Neural networks in\n  control theory)", "I.2.6; I.2.8"], "comment": "31 pages, 20 figures, published in Structural Health Monitoring", "summary": "The dynamic structural load identification capabilities of the gated\nrecurrent unit, long short-term memory, and convolutional neural networks are\nexamined herein. The examination is on realistic small dataset training\nconditions and on a comparative view to the physics-based residual Kalman\nfilter (RKF). The dynamic load identification suffers from the uncertainty\nrelated to obtaining poor predictions when in civil engineering applications\nonly a low number of tests are performed or are available, or when the\nstructural model is unidentifiable. In considering the methods, first, a\nsimulated structure is investigated under a shaker excitation at the top floor.\nSecond, a building in California is investigated under seismic base excitation,\nwhich results in loading for all degrees of freedom. Finally, the International\nAssociation for Structural Control-American Society of Civil Engineers\n(IASC-ASCE) structural health monitoring benchmark problem is examined for\nimpact and instant loading conditions. Importantly, the methods are shown to\noutperform each other on different loading scenarios, while the RKF is shown to\noutperform the networks in physically parametrized identifiable cases.", "AI": {"tldr": "\u7814\u7a76\u95e8\u63a7\u5faa\u73af\u5355\u5143\u3001\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u73b0\u5b9e\u5c0f\u6570\u636e\u96c6\u8bad\u7ec3\u6761\u4ef6\u4e0b\u7684\u52a8\u6001\u7ed3\u6784\u8377\u8f7d\u8bc6\u522b\u80fd\u529b\uff0c\u5e76\u4e0e\u57fa\u4e8e\u7269\u7406\u7684\u6b8b\u5dee\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5bf9\u6bd4\u3002", "motivation": "\u89e3\u51b3\u571f\u6728\u5de5\u7a0b\u5e94\u7528\u4e2d\u56e0\u6d4b\u8bd5\u6570\u91cf\u5c11\u3001\u7ed3\u6784\u6a21\u578b\u4e0d\u53ef\u8bc6\u522b\u5bfc\u81f4\u52a8\u6001\u8377\u8f7d\u8bc6\u522b\u9884\u6d4b\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5bf9\u6a21\u62df\u7ed3\u6784\u5728\u9876\u5c42\u6fc0\u632f\u3001\u52a0\u5dde\u5efa\u7b51\u5728\u5730\u9707\u57fa\u7840\u6fc0\u52b1\u3001IASC - ASCE\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b\u57fa\u51c6\u95ee\u9898\u5728\u51b2\u51fb\u548c\u77ac\u65f6\u52a0\u8f7d\u6761\u4ef6\u4e0b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u52a0\u8f7d\u573a\u666f\u4e0b\u8868\u73b0\u5404\u5f02\uff0c\u5728\u7269\u7406\u53c2\u6570\u53ef\u8bc6\u522b\u7684\u60c5\u51b5\u4e0b\uff0c\u6b8b\u5dee\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u4f18\u4e8e\u795e\u7ecf\u7f51\u7edc\u3002", "conclusion": "\u4e0d\u540c\u7684\u52a8\u6001\u7ed3\u6784\u8377\u8f7d\u8bc6\u522b\u65b9\u6cd5\u5728\u4e0d\u540c\u52a0\u8f7d\u573a\u666f\u6709\u4e0d\u540c\u8868\u73b0\uff0c\u6b8b\u5dee\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u66f4\u4f18\u3002"}}
{"id": "2511.01069", "pdf": "https://arxiv.org/pdf/2511.01069", "abs": "https://arxiv.org/abs/2511.01069", "authors": ["Georg Pichler", "Marco Romanelli", "Pablo Piantanida"], "title": "Happiness as a Measure of Fairness", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this paper, we propose a novel fairness framework grounded in the concept\nof happi- ness, a measure of the utility each group gains fromdecisionoutcomes.\nBycapturingfairness through this intuitive lens, we not only offer a more\nhuman-centered approach, but also one that is mathematically rigorous: In order\nto compute the optimal, fair post-processing strategy, only a linear program\nneeds to be solved. This makes our method both efficient and scalable with\nexisting optimization tools. Furthermore, it unifies and extends several\nwell-known fairness definitions, and our em- pirical results highlight its\npractical strengths across diverse scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e78\u798f\u6982\u5ff5\u7684\u516c\u5e73\u6846\u67b6\uff0c\u65b9\u6cd5\u9ad8\u6548\u53ef\u6269\u5c55\uff0c\u7edf\u4e00\u5e76\u6269\u5c55\u77e5\u540d\u516c\u5e73\u5b9a\u4e49\uff0c\u5b9e\u8bc1\u663e\u793a\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u63d0\u4f9b\u66f4\u4ee5\u4eba\u4e3a\u672c\u4e14\u6570\u5b66\u4e25\u8c28\u7684\u516c\u5e73\u6027\u8861\u91cf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5e78\u798f\u6982\u5ff5\u7684\u516c\u5e73\u6846\u67b6\uff0c\u901a\u8fc7\u6c42\u89e3\u7ebf\u6027\u89c4\u5212\u8ba1\u7b97\u6700\u4f18\u516c\u5e73\u540e\u5904\u7406\u7b56\u7565\u3002", "result": "\u65b9\u6cd5\u9ad8\u6548\u53ef\u6269\u5c55\uff0c\u7edf\u4e00\u5e76\u6269\u5c55\u591a\u4e2a\u77e5\u540d\u516c\u5e73\u5b9a\u4e49\uff0c\u5b9e\u8bc1\u663e\u793a\u5728\u4e0d\u540c\u573a\u666f\u7684\u5b9e\u7528\u4f18\u52bf\u3002", "conclusion": "\u8be5\u516c\u5e73\u6846\u67b6\u53ef\u884c\u4e14\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01059", "pdf": "https://arxiv.org/pdf/2511.01059", "abs": "https://arxiv.org/abs/2511.01059", "authors": ["Hailong Yin", "Bin Zhu", "Jingjing Chen", "Chong-Wah Ngo"], "title": "Efficient Test-Time Retrieval Augmented Generation", "categories": ["cs.AI"], "comment": null, "summary": "Although Large Language Models (LLMs) demonstrate significant capabilities,\ntheir reliance on parametric knowledge often leads to inaccuracies. Retrieval\nAugmented Generation (RAG) mitigates this by incorporating external knowledge,\nbut these methods may introduce irrelevant retrieved documents, leading to\ninaccurate responses. While the integration methods filter out incorrect\nanswers from multiple responses, but lack external knowledge like RAG methods,\nand their high costs require balancing overhead with performance gains. To\naddress these issues, we propose an Efficient Test-Time Retrieval-Augmented\nGeneration Framework named ET2RAG to improve the performance of LLMs while\nmaintaining efficiency. Specifically, ET2RAG is a training-free method, that\nfirst retrieves the most relevant documents and augments the LLMs to\nefficiently generate diverse candidate responses by managing response length.\nThen we compute the similarity of candidate responses and employ a majority\nvoting mechanism to select the most suitable response as the final output. In\nparticular, we discover that partial generation is sufficient to capture the\nkey information necessary for consensus calculation, allowing us to effectively\nperform majority voting without the need for fully generated responses. Thus,\nwe can reach a balance between computational cost and performance by managing\nthe response length for the number of retrieved documents for majority voting.\nExperimental results demonstrate that ET2RAG significantly enhances performance\nacross three tasks, including open-domain question answering, recipe generation\nand image captioning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faET2RAG\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u53c2\u6570\u77e5\u8bc6\u4e0d\u51c6\u786e\u53ca\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5f15\u5165\u65e0\u5173\u6587\u6863\u7b49\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u4e09\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u53c2\u6570\u77e5\u8bc6\u6613\u4e0d\u51c6\u786e\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u53ef\u80fd\u5f15\u5165\u65e0\u5173\u6587\u6863\uff0c\u96c6\u6210\u65b9\u6cd5\u7f3a\u4e4f\u5916\u90e8\u77e5\u8bc6\u4e14\u6210\u672c\u9ad8\uff0c\u9700\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u5347\u6027\u80fd\u5e76\u4fdd\u6301\u6548\u7387\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3-free\u7684ET2RAG\u6846\u67b6\uff0c\u5148\u68c0\u7d22\u76f8\u5173\u6587\u6863\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u5019\u9009\u54cd\u5e94\uff0c\u8ba1\u7b97\u54cd\u5e94\u76f8\u4f3c\u5ea6\u5e76\u7528\u591a\u6570\u6295\u7968\u673a\u5236\u9009\u6700\u7ec8\u8f93\u51fa\uff0c\u901a\u8fc7\u7ba1\u7406\u54cd\u5e94\u957f\u5ea6\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u548c\u6027\u80fd\u3002", "result": "ET2RAG\u5728\u5f00\u653e\u57df\u95ee\u7b54\u3001\u98df\u8c31\u751f\u6210\u548c\u56fe\u50cf\u63cf\u8ff0\u4e09\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "ET2RAG\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u95f4\u53d6\u5f97\u5e73\u8861\u3002"}}
{"id": "2511.01348", "pdf": "https://arxiv.org/pdf/2511.01348", "abs": "https://arxiv.org/abs/2511.01348", "authors": ["Robin Gr\u00f6pler", "Steffen Klepke", "Jack Johns", "Andreas Dreschinski", "Klaus Schmid", "Benedikt Dornauer", "Eray T\u00fcz\u00fcn", "Joost Noppen", "Mohammad Reza Mousavi", "Yongjian Tang", "Johannes Viehmann", "Selin \u015eirin Aslang\u00fcl", "Beum Seuk Lee", "Adam Ziolkowski", "Eric Zie"], "title": "The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project", "categories": ["cs.SE", "cs.AI"], "comment": "Submitted to 2nd IEEE/ACM International Conference on AI-powered\n  Software (AIware 2025)", "summary": "Generative AI (GenAI) has recently emerged as a groundbreaking force in\nSoftware Engineering, capable of generating code, suggesting fixes, and\nsupporting quality assurance. While its use in coding tasks shows considerable\npromise, applying GenAI across the entire Software Development Life Cycle\n(SDLC) has not yet been fully explored. Critical uncertainties in areas such as\nreliability, accountability, security, and data privacy demand deeper\ninvestigation and coordinated action. The GENIUS project, comprising over 30\nEuropean industrial and academic partners, aims to address these challenges by\nadvancing AI integration across all SDLC phases. It focuses on GenAI's\npotential, the development of innovative tools, and emerging research\nchallenges, actively shaping the future of software engineering. This vision\npaper presents a shared perspective on the future of GenAI-based software\nengineering, grounded in cross-sector dialogue and experience within the GENIUS\nconsortium, supported by an exploratory literature review. The paper explores\nfour central elements: (1) a structured overview of current challenges in GenAI\nadoption across the SDLC; (2) a forward-looking vision outlining key\ntechnological and methodological advances expected over the next five years;\n(3) anticipated shifts in the roles and required skill sets of software\nprofessionals; and (4) the contribution of GENIUS in realizing this\ntransformation through practical tools and industrial validation. By aligning\ntechnical innovation with business relevance, this paper aims to inform both\nresearch agendas and industrial strategies, providing a foundation for\nreliable, scalable, and industry-ready GenAI solutions for software engineering\nteams.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5168\u751f\u547d\u5468\u671f\u5e94\u7528\uff0c\u4ecb\u7ecdGENIUS\u9879\u76ee\u5e94\u5bf9\u6311\u6218\uff0c\u5206\u6790\u73b0\u72b6\u3001\u5c55\u671b\u672a\u6765\u3001\u63a2\u8ba8\u89d2\u8272\u8f6c\u53d8\u53ca\u9879\u76ee\u8d21\u732e\uff0c\u4e3a\u884c\u4e1a\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5168\u751f\u547d\u5468\u671f\u5e94\u7528\u672a\u5145\u5206\u63a2\u7d22\uff0c\u5b58\u5728\u53ef\u9760\u6027\u3001\u95ee\u8d23\u5236\u7b49\u5173\u952e\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u6df1\u5165\u7814\u7a76\u548c\u884c\u52a8\u3002", "method": "\u57fa\u4e8eGENIUS\u9879\u76ee\u8de8\u90e8\u95e8\u5bf9\u8bdd\u4e0e\u7ecf\u9a8c\uff0c\u7ed3\u5408\u63a2\u7d22\u6027\u6587\u732e\u7efc\u8ff0\u3002", "result": "\u5206\u6790\u4e86GenAI\u5728SDLC\u91c7\u7528\u4e2d\u7684\u5f53\u524d\u6311\u6218\uff0c\u5c55\u671b\u672a\u6765\u4e94\u5e74\u6280\u672f\u548c\u65b9\u6cd5\u8fdb\u5c55\uff0c\u63a2\u8ba8\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u89d2\u8272\u548c\u6280\u80fd\u96c6\u53d8\u5316\uff0c\u4ecb\u7ecdGENIUS\u9879\u76ee\u8d21\u732e\u3002", "conclusion": "\u8bba\u6587\u5c06\u6280\u672f\u521b\u65b0\u4e0e\u5546\u4e1a\u76f8\u5173\u6027\u7ed3\u5408\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u63d0\u4f9b\u53ef\u9760\u3001\u53ef\u6269\u5c55\u4e14\u9002\u7528\u4e8e\u884c\u4e1a\u7684GenAI\u89e3\u51b3\u65b9\u6848\u57fa\u7840\uff0c\u4e3a\u7814\u7a76\u8bae\u7a0b\u548c\u4ea7\u4e1a\u6218\u7565\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2511.00101", "pdf": "https://arxiv.org/pdf/2511.00101", "abs": "https://arxiv.org/abs/2511.00101", "authors": ["Yuchen Zhang", "Hanyue Du", "Chun Cao", "Jingwei Xu"], "title": "Loquetier: A Virtualized Multi-LoRA Framework for Unified LLM Fine-tuning and Serving", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages including 10 pages of main text, 6 figures, 39th Conference\n  on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Low-Rank Adaptation (LoRA) has become a widely adopted parameter-efficient\nfine-tuning (PEFT) technique for adapting large language models (LLMs) to\ndownstream tasks. While prior work has explored strategies for integrating LLM\ntraining and serving, there still remains a gap in unifying fine-tuning and\ninference for LoRA-based models. We present Loquetier, a virtualized multi-LoRA\nframework that seamlessly integrates LoRA fine-tuning and serving within a\nsingle runtime. Loquetier introduces two key components: (1) a Virtualized\nModule that isolates PEFT-based modifications and supports multiple adapters on\na shared base model, and (2) an optimized computation flow with a kernel design\nthat merges fine-tuning and inference paths in forward propagation, enabling\nefficient batching and minimizing kernel invocation overhead. Extensive\nexperiments across three task settings show that Loquetier consistently\noutperforms existing baselines in both performance and flexibility, achieving\nup to $3.0\\times$ the throughput of the state-of-the-art co-serving system on\ninference-only tasks and $46.4\\times$ higher SLO attainment than PEFT on\nunified fine-tuning and inference tasks. The implementation of Loquetier is\npublicly available at https://github.com/NJUDeepEngine/Loquetier.", "AI": {"tldr": "\u63d0\u51faLoquetier\u6846\u67b6\uff0c\u65e0\u7f1d\u96c6\u6210LoRA\u5fae\u8c03\u4e0e\u670d\u52a1\uff0c\u6027\u80fd\u548c\u7075\u6d3b\u6027\u8d85\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5728\u7edf\u4e00\u57fa\u4e8eLoRA\u6a21\u578b\u7684\u5fae\u8c03\u4e0e\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u5f15\u5165\u865a\u62df\u5316\u6a21\u5757\u9694\u79bb\u57fa\u4e8ePEFT\u7684\u4fee\u6539\uff0c\u652f\u6301\u5171\u4eab\u57fa\u7840\u6a21\u578b\u4e0a\u7684\u591a\u4e2a\u9002\u914d\u5668\uff1b\u8bbe\u8ba1\u4f18\u5316\u8ba1\u7b97\u6d41\u7a0b\u548c\u5185\u6838\uff0c\u5408\u5e76\u524d\u5411\u4f20\u64ad\u4e2d\u7684\u5fae\u8c03\u4e0e\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728\u4e09\u4e2a\u4efb\u52a1\u8bbe\u7f6e\u7684\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0cLoquetier\u5728\u6027\u80fd\u548c\u7075\u6d3b\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u63a8\u7406\u4efb\u52a1\u541e\u5410\u91cf\u8fbe\u73b0\u6709\u7cfb\u7edf3.0\u500d\uff0c\u7edf\u4e00\u5fae\u8c03\u4e0e\u63a8\u7406\u4efb\u52a1\u7684SLO\u8fbe\u6807\u7387\u6bd4PEFT\u9ad846.4\u500d\u3002", "conclusion": "Loquetier\u80fd\u6709\u6548\u7edf\u4e00LoRA\u7684\u5fae\u8c03\u4e0e\u63a8\u7406\uff0c\u4e14\u5b9e\u73b0\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2511.01137", "pdf": "https://arxiv.org/pdf/2511.01137", "abs": "https://arxiv.org/abs/2511.01137", "authors": ["Kathryn Lindsey", "Govind Menon"], "title": "Regularization Implies balancedness in the deep linear network", "categories": ["cs.LG", "math.AG", "math.DS", "stat.ML", "14L24, 37J15, 37C10, 68T07, 93B10, 53D20, 49J15, 37N40"], "comment": "18 pages, 3 figures", "summary": "We use geometric invariant theory (GIT) to study the deep linear network\n(DLN). The Kempf-Ness theorem is used to establish that the $L^2$ regularizer\nis minimized on the balanced manifold. This allows us to decompose the training\ndynamics into two distinct gradient flows: a regularizing flow on fibers and a\nlearning flow on the balanced manifold. We show that the regularizing flow is\nexactly solvable using the moment map.\n  This approach provides a common mathematical framework for balancedness in\ndeep learning and linear systems theory. We use this framework to interpret\nbalancedness in terms of model reduction and Bayesian principles.", "AI": {"tldr": "\u8fd0\u7528\u51e0\u4f55\u4e0d\u53d8\u7406\u8bba\u7814\u7a76\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\uff0c\u5206\u89e3\u8bad\u7ec3\u52a8\u6001\uff0c\u63d0\u4f9b\u5e73\u8861\u95ee\u9898\u6570\u5b66\u6846\u67b6\u5e76\u7528\u4e8e\u89e3\u91ca\u5e73\u8861\u6982\u5ff5\u3002", "motivation": "\u4e3a\u6df1\u5ea6\u5b66\u4e60\u548c\u7ebf\u6027\u7cfb\u7edf\u7406\u8bba\u4e2d\u7684\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u901a\u7528\u6570\u5b66\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u51e0\u4f55\u4e0d\u53d8\u7406\u8bba\uff08GIT\uff09\u548cKempf - Ness\u5b9a\u7406\uff0c\u5c06\u8bad\u7ec3\u52a8\u6001\u5206\u89e3\u4e3a\u6b63\u5219\u5316\u6d41\u548c\u5b66\u4e60\u6d41\uff0c\u7528\u77e9\u6620\u5c04\u6c42\u89e3\u6b63\u5219\u5316\u6d41\u3002", "result": "\u8bc1\u660e$L^2$\u6b63\u5219\u5316\u5668\u5728\u5e73\u8861\u6d41\u5f62\u4e0a\u6700\u5c0f\u5316\uff0c\u6b63\u5219\u5316\u6d41\u53ef\u7528\u77e9\u6620\u5c04\u7cbe\u786e\u6c42\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5e73\u8861\u95ee\u9898\u63d0\u4f9b\u901a\u7528\u6846\u67b6\uff0c\u53ef\u4ece\u6a21\u578b\u7b80\u5316\u548c\u8d1d\u53f6\u65af\u539f\u7406\u89d2\u5ea6\u89e3\u91ca\u5e73\u8861\u6982\u5ff5\u3002"}}
{"id": "2511.01149", "pdf": "https://arxiv.org/pdf/2511.01149", "abs": "https://arxiv.org/abs/2511.01149", "authors": ["Shuaidong Pan", "Di Wu"], "title": "Modular Task Decomposition and Dynamic Collaboration in Multi-Agent Systems Driven by Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "This paper addresses the limitations of a single agent in task decomposition\nand collaboration during complex task execution, and proposes a multi-agent\narchitecture for modular task decomposition and dynamic collaboration based on\nlarge language models. The method first converts natural language task\ndescriptions into unified semantic representations through a large language\nmodel. On this basis, a modular decomposition mechanism is introduced to break\ndown the overall goal into multiple hierarchical sub-tasks. Then, dynamic\nscheduling and routing mechanisms enable reasonable division of labor and\nrealtime collaboration among agents, allowing the system to adjust strategies\ncontinuously according to environmental feedback, thus maintaining efficiency\nand stability in complex tasks. Furthermore, a constraint parsing and global\nconsistency mechanism is designed to ensure coherent connections between\nsub-tasks and balanced workload, preventing performance degradation caused by\nredundant communication or uneven resource allocation. The experiments validate\nthe architecture across multiple dimensions, including task success rate,\ndecomposition efficiency, sub-task coverage, and collaboration balance. The\nresults show that the proposed method outperforms existing approaches in both\noverall performance and robustness, achieving a better balance between task\ncomplexity and communication overhead. In conclusion, this study demonstrates\nthe effectiveness and feasibility of language-driven task decomposition and\ndynamic collaboration in multi-agent systems, providing a systematic solution\nfor task execution in complex environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u7528\u4e8e\u6a21\u5757\u5316\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u6001\u534f\u4f5c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u8bed\u8a00\u9a71\u52a8\u7684\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u6709\u6548\u53ef\u884c\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u6267\u884c\u4e2d\u5355\u4e2a\u667a\u80fd\u4f53\u5728\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u5148\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u5316\u4e3a\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff0c\u5f15\u5165\u6a21\u5757\u5316\u5206\u89e3\u673a\u5236\u5206\u89e3\u4efb\u52a1\uff0c\u5229\u7528\u52a8\u6001\u8c03\u5ea6\u548c\u8def\u7531\u673a\u5236\u5b9e\u73b0\u667a\u80fd\u4f53\u5206\u5de5\u534f\u4f5c\uff0c\u8bbe\u8ba1\u7ea6\u675f\u89e3\u6790\u548c\u5168\u5c40\u4e00\u81f4\u6027\u673a\u5236\u786e\u4fdd\u5b50\u4efb\u52a1\u8fde\u8d2f\u548c\u8d1f\u8f7d\u5747\u8861\u3002", "result": "\u5b9e\u9a8c\u4ece\u591a\u7ef4\u5ea6\u9a8c\u8bc1\u67b6\u6784\uff0c\u8be5\u65b9\u6cd5\u5728\u6574\u4f53\u6027\u80fd\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u901a\u4fe1\u5f00\u9500\u7684\u66f4\u597d\u5e73\u8861\u3002", "conclusion": "\u8bc1\u660e\u8bed\u8a00\u9a71\u52a8\u7684\u4efb\u52a1\u5206\u89e3\u548c\u52a8\u6001\u534f\u4f5c\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6709\u6548\u53ef\u884c\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e0b\u4efb\u52a1\u6267\u884c\u63d0\u4f9b\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01395", "pdf": "https://arxiv.org/pdf/2511.01395", "abs": "https://arxiv.org/abs/2511.01395", "authors": ["Maimouna Tamah Diao", "Moustapha Awwalou Diouf", "Iyiola Emmanuel Olatunji", "Abdoul Kader Kabor\u00e9", "Gervais Mendy", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Characterizing Build Compromises Through Vulnerability Disclosure Analysis", "categories": ["cs.SE"], "comment": null, "summary": "The software build process transforms source code into deployable artifacts,\nrepresenting a critical yet vulnerable stage in software development. Build\ninfrastructure security poses unique challenges: the complexity of\nmulti-component systems (source code, dependencies, build tools), the\ndifficulty of detecting intrusions during compilation, and prevalent build\nnon-determinism that masks malicious modifications. Despite these risks, the\nsecurity community lacks a systematic understanding of build-specific attack\nvectors, hindering effective defense design.\n  This paper presents an empirically-derived taxonomy of attack vectors\ntargeting the build process, constructed through a large-scale CVE mining (of\n621 vulnerability disclosures from the NVD database). We categorize attack\nvectors by their injection points across the build pipeline, from source code\nmanipulation to compiler compromise. To validate our taxonomy, we analyzed 168\ndocumented software supply chain attacks, identifying 40 incidents specifically\ntargeting build phases. Our analysis reveals that 23.8\\% of supply chain\nattacks exploit build vulnerabilities, with dependency confusion and build\nscript injection representing the most prevalent vectors.\n  Dataset available at:\nhttps://anonymous.4open.science/r/Taxonomizing-Build-Attacks-8BB0.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21CVE\u6316\u6398\u6784\u5efa\u9488\u5bf9\u8f6f\u4ef6\u6784\u5efa\u8fc7\u7a0b\u7684\u653b\u51fb\u5411\u91cf\u5206\u7c7b\u6cd5\uff0c\u5e76\u5206\u6790\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u9a8c\u8bc1\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u90e8\u5206\u653b\u51fb\u5229\u7528\u6784\u5efa\u6f0f\u6d1e\u60c5\u51b5\u3002", "motivation": "\u8f6f\u4ef6\u6784\u5efa\u8fc7\u7a0b\u662f\u8f6f\u4ef6\u5f00\u53d1\u5173\u952e\u4e14\u8106\u5f31\u9636\u6bb5\uff0c\u5b89\u5168\u793e\u533a\u7f3a\u4e4f\u5bf9\u6784\u5efa\u7279\u5b9a\u653b\u51fb\u5411\u91cf\u7684\u7cfb\u7edf\u7406\u89e3\uff0c\u963b\u788d\u6709\u6548\u9632\u5fa1\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u5bf9NVD\u6570\u636e\u5e93\u4e2d621\u4e2a\u6f0f\u6d1e\u62ab\u9732\u8fdb\u884c\u5927\u89c4\u6a21CVE\u6316\u6398\u6784\u5efa\u653b\u51fb\u5411\u91cf\u5206\u7c7b\u6cd5\uff0c\u5206\u6790168\u4e2a\u8bb0\u5f55\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u9a8c\u8bc1\u5206\u7c7b\u6cd5\u3002", "result": "\u5206\u6790\u663e\u793a23.8%\u7684\u4f9b\u5e94\u94fe\u653b\u51fb\u5229\u7528\u6784\u5efa\u6f0f\u6d1e\uff0c\u4f9d\u8d56\u6df7\u6dc6\u548c\u6784\u5efa\u811a\u672c\u6ce8\u5165\u662f\u6700\u5e38\u89c1\u7684\u653b\u51fb\u5411\u91cf\u3002", "conclusion": "\u6784\u5efa\u7684\u653b\u51fb\u5411\u91cf\u5206\u7c7b\u6cd5\u6709\u52a9\u4e8e\u7406\u89e3\u8f6f\u4ef6\u6784\u5efa\u8fc7\u7a0b\u7684\u653b\u51fb\u60c5\u51b5\uff0c\u4e3a\u9632\u5fa1\u8bbe\u8ba1\u63d0\u4f9b\u4f9d\u636e\u3002"}}
{"id": "2511.00102", "pdf": "https://arxiv.org/pdf/2511.00102", "abs": "https://arxiv.org/abs/2511.00102", "authors": ["Vivan Doshi"], "title": "Automated Discovery of Conservation Laws via Hybrid Neural ODE-Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "5th Math-AI Workshop - Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "The discovery of conservation laws is a cornerstone of scientific progress.\nHowever, identifying these invariants from observational data remains a\nsignificant challenge. We propose a hybrid framework to automate the discovery\nof conserved quantities from noisy trajectory data. Our approach integrates\nthree components: (1) a Neural Ordinary Differential Equation (Neural ODE) that\nlearns a continuous model of the system's dynamics, (2) a Transformer that\ngenerates symbolic candidate invariants conditioned on the learned vector\nfield, and (3) a symbolic-numeric verifier that provides a strong numerical\ncertificate for the validity of these candidates. We test our framework on\ncanonical physical systems and show that it significantly outperforms baselines\nthat operate directly on trajectory data. This work demonstrates the robustness\nof a decoupled learn-then-search approach for discovering mathematical\nprinciples from imperfect data.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u6846\u67b6\u4ece\u6709\u566a\u8f68\u8ff9\u6570\u636e\u81ea\u52a8\u53d1\u73b0\u5b88\u6052\u91cf\uff0c\u5728\u5178\u578b\u7269\u7406\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u8bc1\u660e\u89e3\u8026\u5b66\u4e60\u518d\u641c\u7d22\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4ece\u89c2\u6d4b\u6570\u636e\u8bc6\u522b\u5b88\u6052\u91cf\u662f\u91cd\u5927\u6311\u6218\uff0c\u65e8\u5728\u81ea\u52a8\u5316\u4ece\u6709\u566a\u8f68\u8ff9\u6570\u636e\u53d1\u73b0\u5b88\u6052\u91cf\u3002", "method": "\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u96c6\u6210\u4e86\u5b66\u4e60\u7cfb\u7edf\u52a8\u529b\u5b66\u8fde\u7eed\u6a21\u578b\u7684\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u3001\u751f\u6210\u7b26\u53f7\u5019\u9009\u4e0d\u53d8\u91cf\u7684Transformer\u548c\u9a8c\u8bc1\u5019\u9009\u6709\u6548\u6027\u7684\u7b26\u53f7 - \u6570\u503c\u9a8c\u8bc1\u5668\u3002", "result": "\u5728\u5178\u578b\u7269\u7406\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u5904\u7406\u8f68\u8ff9\u6570\u636e\u7684\u57fa\u7ebf\u3002", "conclusion": "\u89e3\u8026\u5b66\u4e60\u518d\u641c\u7d22\u65b9\u6cd5\u5728\u4ece\u4e0d\u5b8c\u7f8e\u6570\u636e\u53d1\u73b0\u6570\u5b66\u539f\u7406\u65b9\u9762\u5177\u6709\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01190", "pdf": "https://arxiv.org/pdf/2511.01190", "abs": "https://arxiv.org/abs/2511.01190", "authors": ["Lijia Yu", "Xiao-Shan Gao", "Lijun Zhang"], "title": "Analyzing the Power of Chain of Thought through Memorization Capabilities", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "It has been shown that the chain of thought (CoT) can enhance the power of\nlarge language models (LLMs) to solve certain mathematical reasoning problems.\nHowever, the capacity of CoT is still not fully explored. As an important\ninstance, the following basic question has not yet been answered: Does CoT\nexpand the capability of transformers across all reasoning tasks? We\ndemonstrate that reasoning with transformers is essentially a memorization\nproblem for reasoning datasets. Thus, examining the power of CoT across all\nreasoning tasks amounts to analyzing the memorization capabilities of CoT\ntransformers. In this paper, we give a complete description of the memorization\ncapabilities of fixed-precision transformers with or without CoT and give a\nnegative answer to the above-mentioned question. Precisely, we first give\nnecessary and sufficient conditions for fixed-precision transformers with and\nwithout CoT to memorize a finite reasoning dataset and show that these two\nconditions do not imply each other. Then, we give lower and upper bounds for\nthe number of parameters needed for transformers with or without CoT to\nmemorize a finite reasoning dataset with $N$ elements, which are\n$\\overline{\\Theta}(N)$ in all cases. This implies that there exist reasoning\ntasks for which CoT does not enhance the reasoning power of transformers,\nleading to a negative answer to the above-mentioned question. Finally, we give\nthe first results on memorizing infinite reasoning datasets by CoT transformers\nand show that some simple infinite datasets cannot be memorized by transformers\nwith or without CoT.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.01170", "pdf": "https://arxiv.org/pdf/2511.01170", "abs": "https://arxiv.org/abs/2511.01170", "authors": ["Ruofan Zhang", "Bin Xia", "Zhen Cheng", "Cairen Jian", "Minglun Yang", "Ngai Wong", "Yuan Cheng"], "title": "DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Adaptive reasoning is essential for aligning the computational effort of\nlarge language models (LLMs) with the intrinsic difficulty of problems. Current\nchain-of-thought methods boost reasoning ability but indiscriminately generate\nlong explanations, leading to evident inefficiency. However, existing\nreinforcement learning approaches to adaptive thinking remain unstable and\nheavily reward-dependent. Here we propose \\textbf{DART}, a supervised\n\\textbf{D}ifficulty-\\textbf{A}daptive \\textbf{R}easoning \\textbf{T}runcation\nframework that adjusts thinking length according to problem difficulty. By\ndistilling concise reasoning patterns from stronger models, interpolating them\ninto a continuum of reasoning styles, and curating optimal training data that\nbalances correctness and compactness, DART learns when to ``stop thinking''.\nAcross multiple mathematical benchmarks, experimental results demonstrate its\nremarkable efficiency while preserving or improving accuracy, achieving a\nsignificant 81.2\\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K\ndataset) with 5.33$\\times$ computational acceleration. DART provides a stable\nand general paradigm for efficient reasoning, advancing the development of\nadaptive intelligence in LLMs.", "AI": {"tldr": "\u63d0\u51faDART\u6846\u67b6\uff0c\u53ef\u6839\u636e\u95ee\u9898\u96be\u5ea6\u8c03\u6574\u601d\u7ef4\u957f\u5ea6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u9ad8\u6548\u4e14\u80fd\u4fdd\u6301\u6216\u63d0\u5347\u51c6\u786e\u7387\uff0c\u63a8\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u9002\u5e94\u667a\u80fd\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u601d\u7ef4\u94fe\u65b9\u6cd5\u63a8\u7406\u6548\u7387\u4f4e\uff0c\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u81ea\u9002\u5e94\u601d\u7ef4\u65b9\u6cd5\u4e0d\u7a33\u5b9a\u4e14\u4f9d\u8d56\u5956\u52b1\uff0c\u9700\u66f4\u4f18\u65b9\u6cd5\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u91cf\u4e0e\u95ee\u9898\u96be\u5ea6\u5339\u914d\u3002", "method": "\u63d0\u51faDART\u6846\u67b6\uff0c\u4ece\u66f4\u5f3a\u6a21\u578b\u4e2d\u63d0\u70bc\u7b80\u6d01\u63a8\u7406\u6a21\u5f0f\uff0c\u5c06\u5176\u63d2\u503c\u5230\u8fde\u7eed\u63a8\u7406\u98ce\u683c\uff0c\u7cbe\u5fc3\u6311\u9009\u5e73\u8861\u6b63\u786e\u6027\u548c\u7b80\u6d01\u6027\u7684\u6700\u4f18\u8bad\u7ec3\u6570\u636e\u4ee5\u5b66\u4e60\u4f55\u65f6\u505c\u6b62\u601d\u8003\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDART\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\uff0c\u5b9e\u73b0\u663e\u8457\u7684\u63a8\u7406\u622a\u65ad\u548c\u8ba1\u7b97\u52a0\u901f\uff0c\u5982\u5728GSM8K\u6570\u636e\u96c6\u4e0a\u63a8\u7406\u622a\u65ad\u8fbe81.2%\uff0c\u8ba1\u7b97\u52a0\u901f5.33\u500d\u3002", "conclusion": "DART\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u7a33\u5b9a\u901a\u7528\u7684\u8303\u5f0f\uff0c\u63a8\u52a8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u9002\u5e94\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.01417", "pdf": "https://arxiv.org/pdf/2511.01417", "abs": "https://arxiv.org/abs/2511.01417", "authors": ["Bassel Rafie", "Christian Schindler", "Andreas Rausch"], "title": "VeriODD: From YAML to SMT-LIB - Automating Verification of Operational Design Domains", "categories": ["cs.SE"], "comment": null, "summary": "Operational Design Domains (ODDs) define the conditions under which an\nAutomated Driving System (ADS) is allowed to operate, while Current Operational\nDomains (CODs) capture the actual runtime situation. Ensuring that a COD\ninstance lies within the ODD is a crucial step in safety assurance. Today, ODD\nand COD specifications are frequently expressed in YAML to remain accessible\nfor stakeholders, but such descriptions are not directly suitable for\nsolver-based verification. Manual translation into formal languages such as\nSMT-LIB is slow and error-prone. We present VeriODD, a tool that automates this\ntranslation. VeriODD uses ANTLR-based compiler technology to transform\nYAML-based ODD/COD specifications into both human-readable propositional logic,\nfor lightweight review on a simple basis, and solver-ready SMT-LIB. The tool\nintegrates with SMT solvers such as Z3 to provide automated consistency checks\nof ODD specifications and verification of COD conformance. A graphical user\ninterface supports editing specifications, inspecting generated formulas, and\nperforming verification with a single click. VeriODD thereby closes the gap\nbetween stakeholder-friendly ODD/COD notations and formal verification,\nenabling scalable and automated assurance of operational boundaries in\nautonomous driving. Video demonstration: https://youtu.be/odRacNoL_Pk Tool\navailable at: https://github.com/BasselRafie/VeriODD", "AI": {"tldr": "\u63d0\u51fa\u5de5\u5177VeriODD\uff0c\u81ea\u52a8\u5c06YAML\u683c\u5f0f\u7684ODD/COD\u89c4\u8303\u8f6c\u6362\u4e3a\u547d\u9898\u903b\u8f91\u548cSMT - LIB\uff0c\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76\u64cd\u4f5c\u8fb9\u754c\u7684\u53ef\u6269\u5c55\u548c\u81ea\u52a8\u5316\u4fdd\u8bc1\u3002", "motivation": "\u5f53\u524dODD\u548cCOD\u89c4\u8303\u7528YAML\u8868\u8fbe\uff0c\u4e0d\u9002\u5408\u57fa\u4e8e\u6c42\u89e3\u5668\u7684\u9a8c\u8bc1\uff0c\u624b\u52a8\u8f6c\u6362\u4e3a\u5f62\u5f0f\u8bed\u8a00\u6162\u4e14\u6613\u51fa\u9519\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eANTLR\u7684\u7f16\u8bd1\u5668\u6280\u672f\uff0c\u5c06YAML\u89c4\u8303\u8f6c\u6362\uff0c\u96c6\u6210SMT\u6c42\u89e3\u5668\u8fdb\u884c\u68c0\u67e5\u548c\u9a8c\u8bc1\uff0c\u6709\u56fe\u5f62\u7528\u6237\u754c\u9762\u3002", "result": "VeriODD\u53ef\u5c06\u89c4\u8303\u8f6c\u6362\uff0c\u80fd\u8fdb\u884c\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u5408\u89c4\u6027\u9a8c\u8bc1\uff0c\u6709GUI\u8f85\u52a9\u64cd\u4f5c\u3002", "conclusion": "VeriODD\u5f25\u5408\u4e86\u5229\u76ca\u76f8\u5173\u8005\u53cb\u597d\u7b26\u53f7\u548c\u5f62\u5f0f\u9a8c\u8bc1\u95f4\u7684\u5dee\u8ddd\uff0c\u5b9e\u73b0\u81ea\u52a8\u9a7e\u9a76\u64cd\u4f5c\u8fb9\u754c\u7684\u53ef\u6269\u5c55\u548c\u81ea\u52a8\u5316\u4fdd\u8bc1\u3002"}}
{"id": "2511.00108", "pdf": "https://arxiv.org/pdf/2511.00108", "abs": "https://arxiv.org/abs/2511.00108", "authors": ["Yi Zhang", "Che Liu", "Xiancong Ren", "Hanchu Ni", "Shuai Zhang", "Zeyuan Ding", "Jiayu Hu", "Hanzhe Shan", "Zhenwei Niu", "Zhaoyang Liu", "Yue Zhao", "Junbo Qi", "Qinfan Zhang", "Dengjie Li", "Yidong Wang", "Jiachen Luo", "Yong Dai", "Jian Tang", "Xiaozhu Ju"], "title": "Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "This report presents Pelican-VL 1.0, a new family of open-source embodied\nbrain models with parameter scales ranging from 7 billion to 72 billion. Our\nexplicit mission is clearly stated as: To embed powerful intelligence into\nvarious embodiments. Pelican-VL 1.0 is currently the largest-scale open-source\nembodied multimodal brain model. Its core advantage lies in the in-depth\nintegration of data power and intelligent adaptive learning mechanisms.\nSpecifically, metaloop distilled a high-quality dataset from a raw dataset\ncontaining 4+ billion tokens. Pelican-VL 1.0 is trained on a large-scale\ncluster of 1000+ A800 GPUs, consuming over 50k+ A800 GPU-hours per checkpoint.\nThis translates to a 20.3% performance uplift from its base model and\noutperforms 100B-level open-source counterparts by 10.6%, placing it on par\nwith leading proprietary systems on well-known embodied benchmarks. We\nestablish a novel framework, DPPO (Deliberate Practice Policy Optimization),\ninspired by human metacognition to train Pelican-VL 1.0. We operationalize this\nas a metaloop that teaches the AI to practice deliberately, which is a\nRL-Refine-Diagnose-SFT loop.", "AI": {"tldr": "\u4ecb\u7ecdPelican - VL 1.0\u5f00\u6e90\u5177\u8eab\u5927\u8111\u6a21\u578b\uff0c\u670970\u4ebf\u5230720\u4ebf\u53c2\u6570\uff0c\u901a\u8fc7\u6570\u636e\u4e0e\u5b66\u4e60\u673a\u5236\u7ed3\u5408\u53ca\u65b0\u6846\u67b6\u8bad\u7ec3\uff0c\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u5c06\u5f3a\u5927\u667a\u80fd\u5d4c\u5165\u5404\u79cd\u5177\u8eab\u4e2d\u3002", "method": "\u4f7f\u7528metaloop\u4ece\u542b40\u591a\u4ebftoken\u539f\u59cb\u6570\u636e\u96c6\u63d0\u70bc\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff1b\u57281000\u591a\u4e2aA800 GPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\uff1b\u5efa\u7acb\u53d7\u4eba\u7c7b\u5143\u8ba4\u77e5\u542f\u53d1\u7684DPPO\u6846\u67b6\uff0c\u91c7\u7528RL - Refine - Diagnose - SFT\u5faa\u73af\u8bad\u7ec3\u3002", "result": "\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63d0\u534720.3%\uff0c\u6bd4100B\u7ea7\u5f00\u6e90\u6a21\u578b\u9ad810.6%\uff0c\u5728\u5177\u8eab\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e\u9886\u5148\u4e13\u6709\u7cfb\u7edf\u76f8\u5f53\u3002", "conclusion": "Pelican - VL 1.0\u901a\u8fc7\u6570\u636e\u4e0e\u5b66\u4e60\u673a\u5236\u6df1\u5ea6\u878d\u5408\u53ca\u65b0\u8bad\u7ec3\u6846\u67b6\uff0c\u5c55\u73b0\u51fa\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2511.01234", "pdf": "https://arxiv.org/pdf/2511.01234", "abs": "https://arxiv.org/abs/2511.01234", "authors": ["Min Gan", "Guang-Yong Chen", "Yang Yi", "Lin Yang"], "title": "A Saddle Point Remedy: Power of Variable Elimination in Non-convex Optimization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The proliferation of saddle points, rather than poor local minima, is\nincreasingly understood to be a primary obstacle in large-scale non-convex\noptimization for machine learning. Variable elimination algorithms, like\nVariable Projection (VarPro), have long been observed to exhibit superior\nconvergence and robustness in practice, yet a principled understanding of why\nthey so effectively navigate these complex energy landscapes has remained\nelusive. In this work, we provide a rigorous geometric explanation by comparing\nthe optimization landscapes of the original and reduced formulations. Through a\nrigorous analysis based on Hessian inertia and the Schur complement, we prove\nthat variable elimination fundamentally reshapes the critical point structure\nof the objective function, revealing that local maxima in the reduced landscape\nare created from, and correspond directly to, saddle points in the original\nformulation. Our findings are illustrated on the canonical problem of\nnon-convex matrix factorization, visualized directly on two-parameter neural\nnetworks, and finally validated in training deep Residual Networks, where our\napproach yields dramatic improvements in stability and convergence to superior\nminima. This work goes beyond explaining an existing method; it establishes\nlandscape simplification via saddle point transformation as a powerful\nprinciple that can guide the design of a new generation of more robust and\nefficient optimization algorithms.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6bd4\u8f83\u539f\u516c\u5f0f\u548c\u7b80\u5316\u516c\u5f0f\u7684\u4f18\u5316\u666f\u89c2\uff0c\u5bf9\u53d8\u91cf\u6d88\u9664\u7b97\u6cd5\u4e3a\u4f55\u6709\u6548\u5bfc\u822a\u590d\u6742\u80fd\u91cf\u666f\u89c2\u7ed9\u51fa\u4e25\u683c\u51e0\u4f55\u89e3\u91ca\uff0c\u8fd8\u5728\u591a\u4e2a\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u4e3a\u8bbe\u8ba1\u65b0\u4f18\u5316\u7b97\u6cd5\u63d0\u4f9b\u539f\u5219\u3002", "motivation": "\u978d\u70b9\u7684\u6269\u6563\u662f\u673a\u5668\u5b66\u4e60\u5927\u89c4\u6a21\u975e\u51f8\u4f18\u5316\u7684\u4e3b\u8981\u969c\u788d\uff0c\u53d8\u91cf\u6d88\u9664\u7b97\u6cd5\u5b9e\u8df5\u4e2d\u8868\u73b0\u597d\u4f46\u539f\u7406\u4e0d\u660e\uff0c\u9700\u89e3\u91ca\u5176\u6709\u6548\u539f\u56e0\u3002", "method": "\u57fa\u4e8eHessian\u60ef\u6027\u548cSchur\u8865\u8fdb\u884c\u4e25\u683c\u5206\u6790\uff0c\u6bd4\u8f83\u539f\u516c\u5f0f\u548c\u7b80\u5316\u516c\u5f0f\u7684\u4f18\u5316\u666f\u89c2\u3002", "result": "\u8bc1\u660e\u53d8\u91cf\u6d88\u9664\u4ece\u6839\u672c\u4e0a\u91cd\u5851\u76ee\u6807\u51fd\u6570\u7684\u4e34\u754c\u70b9\u7ed3\u6784\uff0c\u7b80\u5316\u666f\u89c2\u4e2d\u5c40\u90e8\u6700\u5927\u503c\u7531\u539f\u516c\u5f0f\u978d\u70b9\u4ea7\u751f\u5e76\u76f4\u63a5\u5bf9\u5e94\uff1b\u5728\u975e\u51f8\u77e9\u9635\u5206\u89e3\u3001\u53cc\u53c2\u6570\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\u8bad\u7ec3\u4e2d\u9a8c\u8bc1\u53d1\u73b0\u3002", "conclusion": "\u5efa\u7acb\u4e86\u901a\u8fc7\u978d\u70b9\u53d8\u6362\u7b80\u5316\u666f\u89c2\u7684\u5f3a\u5927\u539f\u5219\uff0c\u53ef\u6307\u5bfc\u65b0\u4e00\u4ee3\u66f4\u7a33\u5065\u9ad8\u6548\u4f18\u5316\u7b97\u6cd5\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2511.01182", "pdf": "https://arxiv.org/pdf/2511.01182", "abs": "https://arxiv.org/abs/2511.01182", "authors": ["Cuong Van Duc", "Thai Tran Quoc", "Minh Nguyen Dinh Tuan", "Tam Vu Duc", "Son Nguyen Van", "Hanh Nguyen Thi"], "title": "MiRAGE: Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion", "categories": ["cs.AI"], "comment": null, "summary": "Detecting student misconceptions in open-ended responses is a longstanding\nchallenge, demanding semantic precision and logical reasoning. We propose\nMiRAGE - Misconception Detection with Retrieval-Guided Multi-Stage Reasoning\nand Ensemble Fusion, a novel framework for automated misconception detection in\nmathematics. MiRAGE operates in three stages: (1) a Retrieval module narrows a\nlarge candidate pool to a semantically relevant subset; (2) a Reasoning module\nemploys chain-of-thought generation to expose logical inconsistencies in\nstudent solutions; and (3) a Reranking module refines predictions by aligning\nthem with the reasoning. These components are unified through an\nensemble-fusion strategy that enhances robustness and interpretability. On\nmathematics datasets, MiRAGE achieves Mean Average Precision scores of\n0.82/0.92/0.93 at levels 1/3/5, consistently outperforming individual modules.\nBy coupling retrieval guidance with multi-stage reasoning, MiRAGE reduces\ndependence on large-scale language models while delivering a scalable and\neffective solution for educational assessment.", "AI": {"tldr": "\u63d0\u51faMiRAGE\u6846\u67b6\u7528\u4e8e\u6570\u5b66\u81ea\u52a8\u8bef\u89e3\u68c0\u6d4b\uff0c\u5206\u4e09\u9636\u6bb5\u5de5\u4f5c\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f73\uff0c\u51cf\u5c11\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u3002", "motivation": "\u68c0\u6d4b\u5f00\u653e\u5f0f\u56de\u7b54\u4e2d\u5b66\u751f\u8bef\u89e3\u662f\u957f\u671f\u6311\u6218\uff0c\u9700\u8981\u8bed\u4e49\u7cbe\u5ea6\u548c\u903b\u8f91\u63a8\u7406\uff0c\u65e8\u5728\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faMiRAGE\u6846\u67b6\uff0c\u5206\u68c0\u7d22\u3001\u63a8\u7406\u3001\u91cd\u6392\u5e8f\u4e09\u9636\u6bb5\uff0c\u7528\u96c6\u6210\u878d\u5408\u7b56\u7565\u7edf\u4e00\u7ec4\u4ef6\u3002", "result": "\u5728\u6570\u5b66\u6570\u636e\u96c6\u4e0a\uff0cMiRAGE\u57281/3/5\u7ea7\u522b\u7684\u5e73\u5747\u7cbe\u5ea6\u5747\u503c\u5206\u522b\u8fbe0.82/0.92/0.93\uff0c\u59cb\u7ec8\u4f18\u4e8e\u5355\u4e2a\u6a21\u5757\u3002", "conclusion": "MiRAGE\u7ed3\u5408\u68c0\u7d22\u5f15\u5bfc\u548c\u591a\u9636\u6bb5\u63a8\u7406\uff0c\u51cf\u5c11\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\uff0c\u4e3a\u6559\u80b2\u8bc4\u4f30\u63d0\u4f9b\u53ef\u6269\u5c55\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01423", "pdf": "https://arxiv.org/pdf/2511.01423", "abs": "https://arxiv.org/abs/2511.01423", "authors": ["Ruidi He", "Yu Zhang", "Meng Zhang", "Andreas Rausch"], "title": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations", "categories": ["cs.SE"], "comment": null, "summary": "High-definition map transformations are essential in autonomous driving\nsystems, enabling interoperability across tools. Ensuring their semantic\ncorrectness is challenging, since existing rule-based frameworks rely on\nmanually written formulas and domain-specific functions, limiting scalability.\n  In this paper, We present an LLM-assisted pipeline that jointly generates\nlogical formulas and corresponding executable predicates within a computational\nFOL framework, extending the map verifier in CommonRoad scenario designer with\nelevation support. The pipeline leverages prompt-based LLM generation to\nproduce grammar-compliant rules and predicates that integrate directly into the\nexisting system.\n  We implemented a prototype and evaluated it on synthetic bridge and slope\nscenarios. The results indicate reduced manual engineering effort while\npreserving correctness, demonstrating the feasibility of a scalable,\nsemi-automated human-in-the-loop approach to map-transformation verification.", "AI": {"tldr": "\u63d0\u51faLLM\u8f85\u52a9\u6d41\u6c34\u7ebf\u7528\u4e8e\u9ad8\u6e05\u5730\u56fe\u8f6c\u6362\u9a8c\u8bc1\uff0c\u5728\u5408\u6210\u573a\u666f\u8bc4\u4f30\uff0c\u51cf\u5c11\u4eba\u5de5\u5e76\u4fdd\u8bc1\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u6846\u67b6\u4f9d\u8d56\u624b\u52a8\u516c\u5f0f\u548c\u7279\u5b9a\u9886\u57df\u51fd\u6570\uff0c\u96be\u4ee5\u786e\u4fdd\u9ad8\u6e05\u5730\u56fe\u8f6c\u6362\u8bed\u4e49\u6b63\u786e\u6027\u4e14\u6269\u5c55\u6027\u53d7\u9650\u3002", "method": "\u63d0\u51faLLM\u8f85\u52a9\u6d41\u6c34\u7ebf\uff0c\u5728\u8ba1\u7b97FOL\u6846\u67b6\u5185\u8054\u5408\u751f\u6210\u903b\u8f91\u516c\u5f0f\u548c\u53ef\u6267\u884c\u8c13\u8bcd\uff0c\u5229\u7528\u57fa\u4e8e\u63d0\u793a\u7684LLM\u751f\u6210\u7b26\u5408\u8bed\u6cd5\u7684\u89c4\u5219\u548c\u8c13\u8bcd\u5e76\u96c6\u6210\u5230\u73b0\u6709\u7cfb\u7edf\u3002", "result": "\u5728\u5408\u6210\u7684\u6865\u6881\u548c\u659c\u5761\u573a\u666f\u8bc4\u4f30\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u7a0b\u5de5\u4f5c\u91cf\u5e76\u4fdd\u8bc1\u4e86\u6b63\u786e\u6027\u3002", "conclusion": "\u534a\u81ea\u52a8\u5316\u3001\u6709\u4eba\u53c2\u4e0e\u7684\u65b9\u6cd5\u7528\u4e8e\u5730\u56fe\u8f6c\u6362\u9a8c\u8bc1\u662f\u53ef\u884c\u4e14\u53ef\u6269\u5c55\u7684\u3002"}}
{"id": "2511.00113", "pdf": "https://arxiv.org/pdf/2511.00113", "abs": "https://arxiv.org/abs/2511.00113", "authors": ["Huseyin Goksu"], "title": "MeixnerNet: Adaptive and Robust Spectral Graph Neural Networks with Discrete Orthogonal Polynomials", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Spectral Graph Neural Networks (GNNs) have achieved state-of-the-art results\nby defining graph convolutions in the spectral domain. A common approach,\npopularized by ChebyNet, is to use polynomial filters based on continuous\northogonal polynomials (e.g., Chebyshev). This creates a theoretical\ndisconnect, as these continuous-domain filters are applied to inherently\ndiscrete graph structures. We hypothesize this mismatch can lead to suboptimal\nperformance and fragility to hyperparameter settings.\n  In this paper, we introduce MeixnerNet, a novel spectral GNN architecture\nthat employs discrete orthogonal polynomials -- specifically, the Meixner\npolynomials $M_k(x; \\beta, c)$. Our model makes the two key shape parameters of\nthe polynomial, beta and c, learnable, allowing the filter to adapt its\npolynomial basis to the specific spectral properties of a given graph. We\novercome the significant numerical instability of these polynomials by\nintroducing a novel stabilization technique that combines Laplacian scaling\nwith per-basis LayerNorm.\n  We demonstrate experimentally that MeixnerNet achieves\ncompetitive-to-superior performance against the strong ChebyNet baseline at the\noptimal K = 2 setting (winning on 2 out of 3 benchmarks). More critically, we\nshow that MeixnerNet is exceptionally robust to variations in the polynomial\ndegree K, a hyperparameter to which ChebyNet proves to be highly fragile,\ncollapsing in performance where MeixnerNet remains stable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMeixnerNet\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u4f7f\u7528\u79bb\u6563\u6b63\u4ea4\u591a\u9879\u5f0f\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8eChebyNet\u4e14\u5bf9\u8d85\u53c2\u6570\u66f4\u9c81\u68d2\u3002", "motivation": "\u4f20\u7edf\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u4f7f\u7528\u8fde\u7eed\u6b63\u4ea4\u591a\u9879\u5f0f\u6ee4\u6ce2\u5668\u4e0e\u79bb\u6563\u56fe\u7ed3\u6784\u4e0d\u5339\u914d\uff0c\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u548c\u5bf9\u8d85\u53c2\u6570\u654f\u611f\u3002", "method": "\u5f15\u5165MeixnerNet\u67b6\u6784\uff0c\u91c7\u7528Meixner\u591a\u9879\u5f0f\uff0c\u4f7f\u591a\u9879\u5f0f\u7684\u5173\u952e\u53c2\u6570\u53ef\u5b66\u4e60\uff0c\u8fd8\u5f15\u5165\u7ed3\u5408\u62c9\u666e\u62c9\u65af\u7f29\u653e\u548c\u6bcf\u5c42\u5f52\u4e00\u5316\u7684\u7a33\u5b9a\u6280\u672f\u3002", "result": "\u5728K = 2\u7684\u6700\u4f18\u8bbe\u7f6e\u4e0b\uff0cMeixnerNet\u57282/3\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8eChebyNet\uff0c\u4e14\u5bf9\u591a\u9879\u5f0f\u9636\u6570K\u7684\u53d8\u5316\u66f4\u9c81\u68d2\u3002", "conclusion": "MeixnerNet\u80fd\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u8c31\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u95ee\u9898\uff0c\u6027\u80fd\u548c\u9c81\u68d2\u6027\u66f4\u597d\u3002"}}
{"id": "2511.01267", "pdf": "https://arxiv.org/pdf/2511.01267", "abs": "https://arxiv.org/abs/2511.01267", "authors": ["Yiyang Yang", "Xiejian Chi", "Shanxing Gao", "Kaidong Wang", "Yao Wang"], "title": "A Spatio-Temporal Online Robust Tensor Recovery Approach for Streaming Traffic Data Imputation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Data quality is critical to Intelligent Transportation Systems (ITS), as\ncomplete and accurate traffic data underpin reliable decision-making in traffic\ncontrol and management. Recent advances in low-rank tensor recovery algorithms\nhave shown strong potential in capturing the inherent structure of\nhigh-dimensional traffic data and restoring degraded observations. However,\ntraditional batch-based methods demand substantial computational and storage\nresources, which limits their scalability in the face of continuously expanding\ntraffic data volumes. Moreover, recent online tensor recovery methods often\nsuffer from severe performance degradation in complex real-world scenarios due\nto their insufficient exploitation of the intrinsic structural properties of\ntraffic data. To address these challenges, we reformulate the traffic data\nrecovery problem within a streaming framework, and propose a novel online\nrobust tensor recovery algorithm that simultaneously leverages both the global\nspatio-temporal correlations and local consistency of traffic data, achieving\nhigh recovery accuracy and significantly improved computational efficiency in\nlarge-scale scenarios. Our method is capable of simultaneously handling missing\nand anomalous values in traffic data, and demonstrates strong adaptability\nacross diverse missing patterns. Experimental results on three real-world\ntraffic datasets demonstrate that the proposed approach achieves high recovery\naccuracy while significantly improving computational efficiency by up to three\norders of magnitude compared to state-of-the-art batch-based methods. These\nfindings highlight the potential of the proposed approach as a scalable and\neffective solution for traffic data quality enhancement in ITS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u7ebf\u9c81\u68d2\u5f20\u91cf\u6062\u590d\u7b97\u6cd5\u89e3\u51b3\u4ea4\u901a\u6570\u636e\u6062\u590d\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u5176\u9ad8\u6548\u51c6\u786e\u3002", "motivation": "\u4f20\u7edf\u6279\u5904\u7406\u65b9\u6cd5\u8ba1\u7b97\u548c\u5b58\u50a8\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u73b0\u6709\u5728\u7ebf\u5f20\u91cf\u6062\u590d\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u6027\u80fd\u5dee\uff0c\u9700\u89e3\u51b3\u4ea4\u901a\u6570\u636e\u6062\u590d\u95ee\u9898\u3002", "method": "\u5728\u6d41\u6846\u67b6\u4e0b\u91cd\u65b0\u5b9a\u4e49\u4ea4\u901a\u6570\u636e\u6062\u590d\u95ee\u9898\uff0c\u63d0\u51fa\u5728\u7ebf\u9c81\u68d2\u5f20\u91cf\u6062\u590d\u7b97\u6cd5\uff0c\u5229\u7528\u6570\u636e\u5168\u5c40\u65f6\u7a7a\u76f8\u5173\u6027\u548c\u5c40\u90e8\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u5904\u7406\u7f3a\u5931\u548c\u5f02\u5e38\u503c\uff0c\u9002\u5e94\u4e0d\u540c\u7f3a\u5931\u6a21\u5f0f\uff0c\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6062\u590d\u7cbe\u5ea6\u9ad8\uff0c\u8ba1\u7b97\u6548\u7387\u6bd4\u73b0\u6709\u6279\u5904\u7406\u65b9\u6cd5\u6700\u591a\u63d0\u9ad8\u4e09\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u63d0\u5347\u4ea4\u901a\u6570\u636e\u8d28\u91cf\u7684\u53ef\u6269\u5c55\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01183", "pdf": "https://arxiv.org/pdf/2511.01183", "abs": "https://arxiv.org/abs/2511.01183", "authors": ["Hainan Fang", "Yuanbo Wen", "Jun Bi", "Yihan Wang", "Tonghui He", "Yanlin Tang", "Di Huang", "Jiaming Guo", "Rui Zhang", "Qi Guo", "Yunji Chen"], "title": "QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code", "categories": ["cs.AI"], "comment": "Accepted at NeurIPS 2025", "summary": "Compilers, while essential, are notoriously complex systems that demand\nprohibitively expensive human expertise to develop and maintain. The recent\nadvancements in Large Language Models (LLMs) offer a compelling new paradigm:\nNeural Compilation, which could potentially simplify compiler development for\nnew architectures and facilitate the discovery of innovative optimization\ntechniques. However, several critical obstacles impede its practical adoption.\nFirstly, a significant lack of dedicated benchmarks and robust evaluation\nmethodologies hinders objective assessment and tracking of progress in the\nfield. Secondly, systematically enhancing the reliability and performance of\nLLM-generated assembly remains a critical challenge. Addressing these\nchallenges, this paper introduces NeuComBack, a novel benchmark dataset\nspecifically designed for IR-to-assembly compilation. Leveraging this dataset,\nwe first define a foundational Neural Compilation workflow and conduct a\ncomprehensive evaluation of the capabilities of recent frontier LLMs on Neural\nCompilation, establishing new performance baselines. We further propose a\nself-evolving prompt optimization method that enables LLMs to iteratively\nevolve their internal prompt strategies by extracting insights from prior\nself-debugging traces, thereby enhancing their neural compilation capabilities.\nExperiments demonstrate that our method significantly improves both the\nfunctional correctness and the performance of LLM-generated assembly code.\nCompared to baseline prompts, the functional correctness rates improved from\n44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More\nsignificantly, among the 16 correctly generated x86_64 programs using our\nmethod, 14 (87.5%) surpassed clang-O3 performance.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u795e\u7ecf\u7f16\u8bd1\u9762\u4e34\u7684\u7f3a\u4e4f\u57fa\u51c6\u6d4b\u8bd5\u548c\u63d0\u5347LLM\u751f\u6210\u6c47\u7f16\u53ef\u9760\u6027\u7684\u6311\u6218\uff0c\u63d0\u51faNeuComBack\u57fa\u51c6\u6570\u636e\u96c6\u548c\u81ea\u8fdb\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u6c47\u7f16\u4ee3\u7801\u7684\u6b63\u786e\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u7f16\u8bd1\u5668\u5f00\u53d1\u548c\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u795e\u7ecf\u7f16\u8bd1\u6709\u6f5c\u529b\u7b80\u5316\u5f00\u53d1\u548c\u53d1\u73b0\u4f18\u5316\u6280\u672f\uff0c\u4f46\u7f3a\u4e4f\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e14\u63d0\u5347LLM\u751f\u6210\u6c47\u7f16\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u5b58\u5728\u6311\u6218\u3002", "method": "\u5f15\u5165NeuComBack\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u795e\u7ecf\u7f16\u8bd1\u5de5\u4f5c\u6d41\u7a0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u63d0\u51fa\u81ea\u8fdb\u5316\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u8ba9LLM\u4ece\u81ea\u6211\u8c03\u8bd5\u75d5\u8ff9\u4e2d\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86LLM\u751f\u6210\u6c47\u7f16\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u6027\u80fd\uff0cx86_64\u548caarch64\u7684\u529f\u80fd\u6b63\u786e\u7387\u5206\u522b\u4ece44%\u63d0\u5347\u523064%\u300136%\u63d0\u5347\u523058%\uff0cx86_64\u4e2d87.5%\u7684\u6b63\u786e\u7a0b\u5e8f\u6027\u80fd\u8d85clang - O3\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4f18\u5316\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u795e\u7ecf\u7f16\u8bd1\u9762\u4e34\u7684\u95ee\u9898\uff0c\u63d0\u5347LLM\u5728\u795e\u7ecf\u7f16\u8bd1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2511.01529", "pdf": "https://arxiv.org/pdf/2511.01529", "abs": "https://arxiv.org/abs/2511.01529", "authors": ["Murali Sridharan", "Mikel Robredo", "Leevi Rantala", "Matteo Esposito", "Valentina Lenarduzzi", "Mika Mantyla"], "title": "Hidden in Plain Sight: Where Developers Confess Self-Admitted Technical Debt", "categories": ["cs.SE", "cs.CL", "cs.PL"], "comment": null, "summary": "Context. Detecting Self-Admitted Technical Debt (SATD) is crucial for\nproactive software maintenance. Previous research has primarily targeted\ndetecting and prioritizing SATD, with little focus on the source code afflicted\nwith SATD. Our goal in this work is to connect the SATD comments with source\ncode constructs that surround them.\n  Method. We leverage the extensive SATD dataset PENTACET, containing code\ncomments from over 9000 Java Open Source Software (OSS) repositories. We\nquantitatively infer where SATD most commonly occurs and which code\nconstructs/statements it most frequently affects.\n  Results and Conclusions. Our large-scale study links over 225,000 SATD\ncomments to their surrounding code, showing that SATD mainly arises in inline\ncode near definitions, conditionals, and exception handling, where developers\nface uncertainty and trade-offs, revealing it as an intentional signal of\nawareness during change rather than mere neglect.", "AI": {"tldr": "\u672c\u6587\u8fde\u63a5SATD\u6ce8\u91ca\u4e0e\u5468\u56f4\u6e90\u4ee3\u7801\u7ed3\u6784\uff0c\u53d1\u73b0SATD\u4e3b\u8981\u51fa\u73b0\u5728\u5b9a\u4e49\u3001\u6761\u4ef6\u548c\u5f02\u5e38\u5904\u7406\u9644\u8fd1\u7684\u5185\u8054\u4ee3\u7801\u4e2d\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u591a\u5173\u6ce8\u68c0\u6d4b\u548c\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u5c11\u5173\u6ce8\u53d7SATD\u5f71\u54cd\u7684\u6e90\u4ee3\u7801\uff0c\u672c\u6587\u65e8\u5728\u8fde\u63a5SATD\u6ce8\u91ca\u4e0e\u5468\u56f4\u6e90\u4ee3\u7801\u7ed3\u6784\u3002", "method": "\u5229\u7528PENTACET\u6570\u636e\u96c6\uff0c\u5b9a\u91cf\u63a8\u65adSATD\u5e38\u89c1\u4f4d\u7f6e\u548c\u53d7\u5f71\u54cd\u7684\u4ee3\u7801\u7ed3\u6784/\u8bed\u53e5\u3002", "result": "\u5c06\u8d85225,000\u6761SATD\u6ce8\u91ca\u4e0e\u5468\u56f4\u4ee3\u7801\u5173\u8054\uff0c\u8868\u660eSATD\u4e3b\u8981\u51fa\u73b0\u5728\u5b9a\u4e49\u3001\u6761\u4ef6\u548c\u5f02\u5e38\u5904\u7406\u9644\u8fd1\u7684\u5185\u8054\u4ee3\u7801\u4e2d\u3002", "conclusion": "SATD\u662f\u5f00\u53d1\u8005\u5728\u53d8\u66f4\u65f6\u6709\u610f\u53d1\u51fa\u7684\u4fe1\u53f7\uff0c\u800c\u975e\u758f\u5ffd\u3002"}}
{"id": "2511.00116", "pdf": "https://arxiv.org/pdf/2511.00116", "abs": "https://arxiv.org/abs/2511.00116", "authors": ["Avisek Naug", "Antonio Guillen", "Vineet Kumar", "Scott Greenwood", "Wesley Brewer", "Sahand Ghorbanpour", "Ashwin Ramesh Babu", "Vineet Gundecha", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "title": "LC-Opt: Benchmarking Reinforcement Learning and Agentic AI for End-to-End Liquid Cooling Optimization in Data Centers", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "comment": "Submitted to the NeurIPS 2025 conference", "summary": "Liquid cooling is critical for thermal management in high-density data\ncenters with the rising AI workloads. However, machine learning-based\ncontrollers are essential to unlock greater energy efficiency and reliability,\npromoting sustainability. We present LC-Opt, a Sustainable Liquid Cooling (LC)\nbenchmark environment, for reinforcement learning (RL) control strategies in\nenergy-efficient liquid cooling of high-performance computing (HPC) systems.\nBuilt on the baseline of a high-fidelity digital twin of Oak Ridge National\nLab's Frontier Supercomputer cooling system, LC-Opt provides detailed\nModelica-based end-to-end models spanning site-level cooling towers to data\ncenter cabinets and server blade groups. RL agents optimize critical thermal\ncontrols like liquid supply temperature, flow rate, and granular valve\nactuation at the IT cabinet level, as well as cooling tower (CT) setpoints\nthrough a Gymnasium interface, with dynamic changes in workloads. This\nenvironment creates a multi-objective real-time optimization challenge\nbalancing local thermal regulation and global energy efficiency, and also\nsupports additional components like a heat recovery unit (HRU). We benchmark\ncentralized and decentralized multi-agent RL approaches, demonstrate policy\ndistillation into decision and regression trees for interpretable control, and\nexplore LLM-based methods that explain control actions in natural language\nthrough an agentic mesh architecture designed to foster user trust and simplify\nsystem management. LC-Opt democratizes access to detailed, customizable liquid\ncooling models, enabling the ML community, operators, and vendors to develop\nsustainable data center liquid cooling control solutions.", "AI": {"tldr": "\u63d0\u51faLC - Opt\u53ef\u6301\u7eed\u6db2\u4f53\u51b7\u5374\u57fa\u51c6\u73af\u5883\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u53ef\u5e73\u8861\u70ed\u8c03\u8282\u4e0e\u80fd\u6e90\u6548\u7387\uff0c\u652f\u6301\u591a\u65b9\u6cd5\u5e76\u4fc3\u8fdb\u5f00\u53d1\u51b7\u5374\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740AI\u5de5\u4f5c\u8d1f\u8f7d\u589e\u52a0\uff0c\u6db2\u4f53\u51b7\u5374\u5bf9\u6570\u636e\u4e2d\u5fc3\u70ed\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u673a\u5668\u5b66\u4e60\u63a7\u5236\u5668\u53ef\u63d0\u5347\u80fd\u6e90\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u63a8\u52a8\u53ef\u6301\u7eed\u6027\u3002", "method": "\u57fa\u4e8e\u6a61\u6811\u5cad\u56fd\u5bb6\u5b9e\u9a8c\u5ba4\u524d\u6cbf\u8d85\u7ea7\u8ba1\u7b97\u673a\u51b7\u5374\u7cfb\u7edf\u7684\u6570\u5b57\u5b6a\u751f\u6784\u5efaLC - Opt\uff0c\u901a\u8fc7Gymnasium\u63a5\u53e3\u8ba9RL\u667a\u80fd\u4f53\u4f18\u5316\u70ed\u63a7\u5236\uff0c\u5bf9\u96c6\u4e2d\u548c\u5206\u6563\u591a\u667a\u80fd\u4f53RL\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u7b56\u7565\u63d0\u70bc\u4e3a\u51b3\u7b56\u6811\u548c\u56de\u5f52\u6811\uff0c\u63a2\u7d22\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002", "result": "LC - Opt\u521b\u5efa\u4e86\u5e73\u8861\u5c40\u90e8\u70ed\u8c03\u8282\u548c\u5168\u5c40\u80fd\u6e90\u6548\u7387\u7684\u591a\u76ee\u6807\u5b9e\u65f6\u4f18\u5316\u6311\u6218\uff0c\u652f\u6301\u70ed\u56de\u6536\u5355\u5143\u7b49\u7ec4\u4ef6\u3002", "conclusion": "LC - Opt\u4f7f\u8be6\u7ec6\u3001\u53ef\u5b9a\u5236\u7684\u6db2\u4f53\u51b7\u5374\u6a21\u578b\u66f4\u6613\u83b7\u53d6\uff0c\u6709\u52a9\u4e8eML\u793e\u533a\u3001\u8fd0\u8425\u5546\u548c\u4f9b\u5e94\u5546\u5f00\u53d1\u53ef\u6301\u7eed\u6570\u636e\u4e2d\u5fc3\u6db2\u4f53\u51b7\u5374\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01535", "pdf": "https://arxiv.org/pdf/2511.01535", "abs": "https://arxiv.org/abs/2511.01535", "authors": ["Marco Cayuela", "Vincent Le Chenadec", "Peter Schmid", "Taraneh Sayadi"], "title": "HFNO: an interpretable data-driven decomposition strategy for turbulent flows", "categories": ["physics.flu-dyn", "stat.ML"], "comment": "20 pages, 11 figures, 1 table", "summary": "Fourier Neural Operators (FNOs) have demonstrated exceptional accuracy in\nmapping functional spaces by leveraging Fourier transforms to establish a\nconnection with underlying physical principles. However, their opaque inner\nworkings often constitute an obstacle to physical interpretability. This work\nintroduces Hierarchical Fourier Neural Operators (HFNOs), a novel FNO-based\narchitecture tailored for reduced-order modeling of turbulent fluid flows,\ndesigned to enhance interpretability by explicitly separating fluid behavior\nacross scales. The proposed architecture processes wavenumber bins in parallel,\nenabling the approximation of dispersion relations and non-linear interactions.\nInputs are lifted to a higher-dimensional space, Fourier-transformed, and\npartitioned into wavenumber bins. Each bin is processed by a Fully Connected\nNeural Network (FCNN), with outputs subsequently padded, summed, and\ninverse-transformed back into physical space. A final transformation refines\nthe output in physical space as a correction model, by means of one of the\nfollowing architectures: Convolutional Neural Network (CNN) and Echo State\nNetwork (ESN). We evaluate the proposed model on a series of increasingly\ncomplex dynamical systems: first on the one-dimensional Kuramoto-Sivashinsky\nequation, then on the two-dimensional Kolmogorov flow, and finally on the\nprediction of wall shear stress in turbulent channel flow, given the near-wall\nvelocity field. In all test cases, the model demonstrates its ability to\ndecompose turbulent flows across various scales, opening up the possibility of\nincreased interpretability and multiscale modeling of such flows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHierarchical Fourier Neural Operators (HFNOs)\u7528\u4e8e\u6e4d\u6d41\u964d\u9636\u5efa\u6a21\uff0c\u63d0\u5347\u53ef\u89e3\u91ca\u6027\uff0c\u7ecf\u591a\u52a8\u529b\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u80fd\u5206\u89e3\u6e4d\u6d41\u591a\u5c3a\u5ea6\u3002", "motivation": "Fourier Neural Operators (FNOs)\u5185\u90e8\u5de5\u4f5c\u4e0d\u900f\u660e\uff0c\u7f3a\u4e4f\u7269\u7406\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faHFNOs\u67b6\u6784\uff0c\u5e76\u884c\u5904\u7406\u6ce2\u6570\u533a\u95f4\uff0c\u5c06\u8f93\u5165\u5347\u7ef4\u3001\u5085\u91cc\u53f6\u53d8\u6362\u3001\u5206\u533a\uff0c\u5404\u533a\u95f4\u7528\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u5904\u7406\uff0c\u8f93\u51fa\u5904\u7406\u540e\u9006\u53d8\u6362\u56de\u7269\u7406\u7a7a\u95f4\uff0c\u7528CNN\u6216ESN\u67b6\u6784\u7cbe\u4fee\u8f93\u51fa\u3002", "result": "\u5728\u4e00\u7ef4Kuramoto - Sivashinsky\u65b9\u7a0b\u3001\u4e8c\u7ef4Kolmogorov\u6d41\u548c\u6e4d\u6d41\u901a\u9053\u58c1\u9762\u526a\u5e94\u529b\u9884\u6d4b\u7b49\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u80fd\u5206\u89e3\u4e0d\u540c\u5c3a\u5ea6\u6e4d\u6d41\u3002", "conclusion": "\u6a21\u578b\u63d0\u5347\u4e86\u6e4d\u6d41\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u591a\u5c3a\u5ea6\u5efa\u6a21\u63d0\u4f9b\u53ef\u80fd\u3002"}}
{"id": "2511.01258", "pdf": "https://arxiv.org/pdf/2511.01258", "abs": "https://arxiv.org/abs/2511.01258", "authors": ["Chuyue Lou", "M. Amine Atoui"], "title": "Graph Neural Network-Based Semi-Supervised Open-Set Fault Diagnosis for Marine Machinery Systems", "categories": ["cs.AI"], "comment": null, "summary": "Recently, fault diagnosis methods for marine machinery systems based on deep\nlearning models have attracted considerable attention in the shipping industry.\nMost existing studies assume fault classes are consistent and known between the\ntraining and test datasets, and these methods perform well under controlled\nenvironment. In practice, however, previously unseen or unknown fault types\n(i.e., out-of-distribution or open-set observations not present during\ntraining) can occur, causing such methods to fail and posing a significant\nchallenge to their widespread industrial deployment. To address this challenge,\nthis paper proposes a semi-supervised open-set fault diagnosis (SOFD) framework\nthat enhances and extends the applicability of deep learning models in open-set\nfault diagnosis scenarios. The framework includes a reliability subset\nconstruction process, which uses a multi-layer fusion feature representation\nextracted by a supervised feature learning model to select an unlabeled test\nsubset. The labeled training set and pseudo-labeled test subset are then fed\ninto a semi-supervised diagnosis model to learn discriminative features for\neach class, enabling accurate classification of known faults and effective\ndetection of unknown samples. Experimental results on a public maritime\nbenchmark dataset demonstrate the effectiveness and superiority of the proposed\nSOFD framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u534a\u76d1\u7763\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\uff08SOFD\uff09\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u5728\u672a\u77e5\u6545\u969c\u7c7b\u578b\u4e0b\u5931\u6548\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8239\u8236\u673a\u68b0\u7cfb\u7edf\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\u4e2d\u5047\u8bbe\u6545\u969c\u7c7b\u522b\u4e00\u81f4\u4e14\u5df2\u77e5\uff0c\u5728\u5b9e\u9645\u4e2d\u9047\u5230\u672a\u77e5\u6545\u969c\u7c7b\u578b\u4f1a\u5931\u6548\uff0c\u963b\u788d\u5de5\u4e1a\u5e94\u7528\u3002", "method": "\u63d0\u51faSOFD\u6846\u67b6\uff0c\u5305\u542b\u53ef\u9760\u6027\u5b50\u96c6\u6784\u5efa\u8fc7\u7a0b\uff0c\u7528\u76d1\u7763\u7279\u5f81\u5b66\u4e60\u6a21\u578b\u63d0\u53d6\u591a\u5c42\u878d\u5408\u7279\u5f81\u9009\u62e9\u65e0\u6807\u7b7e\u6d4b\u8bd5\u5b50\u96c6\uff0c\u5c06\u6709\u6807\u7b7e\u8bad\u7ec3\u96c6\u548c\u4f2a\u6807\u7b7e\u6d4b\u8bd5\u5b50\u96c6\u8f93\u5165\u534a\u76d1\u7763\u8bca\u65ad\u6a21\u578b\u5b66\u4e60\u5206\u7c7b\u7279\u5f81\u3002", "result": "\u5728\u516c\u5171\u6d77\u4e8b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSOFD\u6846\u67b6\u6709\u6548\u4e14\u4f18\u8d8a\u3002", "conclusion": "SOFD\u6846\u67b6\u589e\u5f3a\u5e76\u6269\u5c55\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5f00\u653e\u96c6\u6545\u969c\u8bca\u65ad\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2511.01545", "pdf": "https://arxiv.org/pdf/2511.01545", "abs": "https://arxiv.org/abs/2511.01545", "authors": ["Ronivaldo Ferreira", "Guilherme da Silva", "Carla Rocha", "Gustavo Pinto"], "title": "From Pre-labeling to Production: Engineering Lessons from a Machine Learning Pipeline in the Public Sector", "categories": ["cs.SE", "cs.CY"], "comment": "11 pages, 2 figures, 4 tables", "summary": "Machine learning is increasingly being embedded into government digital\nplatforms, but public-sector constraints make it difficult to build ML systems\nthat are accurate, auditable, and operationally sustainable. In practice, teams\nface not only technical issues like extreme class imbalance and data drift, but\nalso organizational barriers such as bureaucratic data access, lack of\nversioned datasets, and incomplete governance over provenance and monitoring.\nOur study of the Brasil Participativo (BP) platform shows that common\nengineering choices -- like using LLMs for pre-labeling, splitting models into\nrouted classifiers, and generating synthetic data -- can speed development but\nalso introduce new traceability, reliability, and cost risks if not paired with\ndisciplined data governance and human validation. This means that, in the\npublic sector, responsible ML is not just a modeling problem but an\ninstitutional engineering problem, and ML pipelines must be treated as civic\ninfrastructure. Ultimately, this study shows that the success of machine\nlearning in the public sector will depend less on breakthroughs in model\naccuracy and more on the ability of institutions to engineer transparent,\nreproducible, and accountable data infrastructures that citizens can trust.", "AI": {"tldr": "\u516c\u5171\u90e8\u95e8\u5d4c\u5165\u673a\u5668\u5b66\u4e60\u9762\u4e34\u56f0\u96be\uff0c\u7814\u7a76BP\u5e73\u53f0\u8868\u660e\u5e38\u89c1\u5de5\u7a0b\u9009\u62e9\u6709\u98ce\u9669\uff0c\u516c\u5171\u90e8\u95e8\u8d1f\u8d23\u4efb\u7684ML\u662f\u5236\u5ea6\u5de5\u7a0b\u95ee\u9898\uff0c\u5176\u6210\u529f\u4f9d\u8d56\u673a\u6784\u6784\u5efa\u53ef\u4fe1\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u89e3\u51b3\u516c\u5171\u90e8\u95e8\u6784\u5efa\u51c6\u786e\u3001\u53ef\u5ba1\u8ba1\u548c\u8fd0\u8425\u53ef\u6301\u7eed\u7684ML\u7cfb\u7edf\u9762\u4e34\u7684\u56f0\u96be\u3002", "method": "\u7814\u7a76Brasil Participativo (BP)\u5e73\u53f0\u3002", "result": "\u5e38\u89c1\u5de5\u7a0b\u9009\u62e9\u80fd\u52a0\u901f\u5f00\u53d1\uff0c\u4f46\u4e0d\u914d\u5408\u6570\u636e\u6cbb\u7406\u548c\u4eba\u5de5\u9a8c\u8bc1\u4f1a\u5f15\u5165\u65b0\u98ce\u9669\u3002", "conclusion": "\u516c\u5171\u90e8\u95e8\u673a\u5668\u5b66\u4e60\u6210\u529f\u66f4\u4f9d\u8d56\u673a\u6784\u6784\u5efa\u900f\u660e\u3001\u53ef\u590d\u5236\u548c\u53ef\u95ee\u8d23\u7684\u53ef\u4fe1\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2511.00117", "pdf": "https://arxiv.org/pdf/2511.00117", "abs": "https://arxiv.org/abs/2511.00117", "authors": ["Antonio Guillen-Perez", "Avisek Naug", "Vineet Gundecha", "Sahand Ghorbanpour", "Ricardo Luna Gutierrez", "Ashwin Ramesh Babu", "Munther Salim", "Shubhanker Banerjee", "Eoin H. Oude Essink", "Damien Fay", "Soumyendu Sarkar"], "title": "DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "comment": "Submitted to the NeurIPS 2025 conference", "summary": "The increasing energy demands and carbon footprint of large-scale AI require\nintelligent workload management in globally distributed data centers. Yet\nprogress is limited by the absence of benchmarks that realistically capture the\ninterplay of time-varying environmental factors (grid carbon intensity,\nelectricity prices, weather), detailed data center physics (CPUs, GPUs, memory,\nHVAC energy), and geo-distributed network dynamics (latency and transmission\ncosts). To bridge this gap, we present DCcluster-Opt: an open-source,\nhigh-fidelity simulation benchmark for sustainable, geo-temporal task\nscheduling. DCcluster-Opt combines curated real-world datasets, including AI\nworkload traces, grid carbon intensity, electricity markets, weather across 20\nglobal regions, cloud transmission costs, and empirical network delay\nparameters with physics-informed models of data center operations, enabling\nrigorous and reproducible research in sustainable computing. It presents a\nchallenging scheduling problem where a top-level coordinating agent must\ndynamically reassign or defer tasks that arrive with resource and service-level\nagreement requirements across a configurable cluster of data centers to\noptimize multiple objectives. The environment also models advanced components\nsuch as heat recovery. A modular reward system enables an explicit study of\ntrade-offs among carbon emissions, energy costs, service level agreements, and\nwater use. It provides a Gymnasium API with baseline controllers, including\nreinforcement learning and rule-based strategies, to support reproducible ML\nresearch and a fair comparison of diverse algorithms. By offering a realistic,\nconfigurable, and accessible testbed, DCcluster-Opt accelerates the development\nand validation of next-generation sustainable computing solutions for\ngeo-distributed data centers.", "AI": {"tldr": "\u63d0\u51fa\u5f00\u6e90\u9ad8\u4fdd\u771f\u6a21\u62df\u57fa\u51c6DCcluster - Opt\uff0c\u7528\u4e8e\u53ef\u6301\u7eed\u7684\u5730\u7406\u65f6\u95f4\u4efb\u52a1\u8c03\u5ea6\uff0c\u52a0\u901f\u5206\u5e03\u5f0f\u6570\u636e\u4e2d\u5fc3\u53ef\u6301\u7eed\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u7684\u5f00\u53d1\u4e0e\u9a8c\u8bc1\u3002", "motivation": "\u5927\u89c4\u6a21AI\u80fd\u6e90\u9700\u6c42\u548c\u78b3\u8db3\u8ff9\u589e\u957f\uff0c\u9700\u8981\u667a\u80fd\u5de5\u4f5c\u8d1f\u8f7d\u7ba1\u7406\uff0c\u4f46\u7f3a\u4e4f\u80fd\u53cd\u6620\u591a\u56e0\u7d20\u76f8\u4e92\u4f5c\u7528\u7684\u57fa\u51c6\u3002", "method": "\u7ed3\u5408\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u548c\u6570\u636e\u4e2d\u5fc3\u8fd0\u8425\u7269\u7406\u6a21\u578b\uff0c\u63d0\u51fa\u5177\u6709\u6311\u6218\u6027\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u6709\u6a21\u5757\u5316\u5956\u52b1\u7cfb\u7edf\uff0c\u63d0\u4f9bGymnasium API\u548c\u57fa\u7ebf\u63a7\u5236\u5668\u3002", "result": "\u63d0\u4f9b\u4e86\u73b0\u5b9e\u3001\u53ef\u914d\u7f6e\u4e14\u6613\u8bbf\u95ee\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "conclusion": "DCcluster - Opt\u80fd\u52a0\u901f\u5206\u5e03\u5f0f\u6570\u636e\u4e2d\u5fc3\u4e0b\u4e00\u4ee3\u53ef\u6301\u7eed\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u7684\u5f00\u53d1\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2511.01605", "pdf": "https://arxiv.org/pdf/2511.01605", "abs": "https://arxiv.org/abs/2511.01605", "authors": ["Daniel Busbib", "Ami Wiesel"], "title": "Estimation of Toeplitz Covariance Matrices using Overparameterized Gradient Descent", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We consider covariance estimation under Toeplitz structure. Numerous\nsophisticated optimization methods have been developed to maximize the Gaussian\nlog-likelihood under Toeplitz constraints. In contrast, recent advances in deep\nlearning demonstrate the surprising power of simple gradient descent (GD)\napplied to overparameterized models. Motivated by this trend, we revisit\nToeplitz covariance estimation through the lens of overparameterized GD. We\nmodel the $P\\times P$ covariance as a sum of $K$ complex sinusoids with\nlearnable parameters and optimize them via GD. We show that when $K = P$, GD\nmay converge to suboptimal solutions. However, mild overparameterization ($K =\n2P$ or $4P$) consistently enables global convergence from random\ninitializations. We further propose an accelerated GD variant with separate\nlearning rates for amplitudes and frequencies. When frequencies are fixed and\nonly amplitudes are optimized, we prove that the optimization landscape is\nasymptotically benign and any stationary point recovers the true covariance.\nFinally, numerical experiments demonstrate that overparameterized GD can match\nor exceed the accuracy of state-of-the-art methods in challenging settings,\nwhile remaining simple and scalable.", "AI": {"tldr": "\u672c\u6587\u4ece\u8fc7\u53c2\u6570\u5316\u68af\u5ea6\u4e0b\u964d\uff08GD\uff09\u7684\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6Toeplitz\u534f\u65b9\u5dee\u4f30\u8ba1\uff0c\u53d1\u73b0\u9002\u5ea6\u8fc7\u53c2\u6570\u5316\u80fd\u5b9e\u73b0\u5168\u5c40\u6536\u655b\uff0c\u63d0\u51fa\u52a0\u901fGD\u53d8\u4f53\uff0c\u5b9e\u9a8c\u8868\u660e\u8fc7\u53c2\u6570\u5316GD\u5728\u6311\u6218\u6027\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u53d7\u6df1\u5ea6\u5b66\u4e60\u4e2d\u8fc7\u53c2\u6570\u5316\u68af\u5ea6\u4e0b\u964d\u7684\u542f\u53d1\uff0c\u91cd\u65b0\u5ba1\u89c6Toeplitz\u534f\u65b9\u5dee\u4f30\u8ba1\u95ee\u9898\u3002", "method": "\u5c06$P\times P$\u534f\u65b9\u5dee\u5efa\u6a21\u4e3a$K$\u4e2a\u590d\u6b63\u5f26\u6ce2\u4e4b\u548c\uff0c\u901a\u8fc7GD\u4f18\u5316\uff1b\u63d0\u51fa\u6709\u4e0d\u540c\u5b66\u4e60\u7387\u7684\u52a0\u901fGD\u53d8\u4f53\u3002", "result": "\u5f53$K = P$\u65f6\uff0cGD\u53ef\u80fd\u6536\u655b\u5230\u6b21\u4f18\u89e3\uff1b\u9002\u5ea6\u8fc7\u53c2\u6570\u5316\uff08$K = 2P$\u6216$4P$\uff09\u80fd\u5b9e\u73b0\u5168\u5c40\u6536\u655b\uff1b\u56fa\u5b9a\u9891\u7387\u4ec5\u4f18\u5316\u632f\u5e45\u65f6\uff0c\u4f18\u5316\u666f\u89c2\u6e10\u8fd1\u826f\u597d\u3002", "conclusion": "\u8fc7\u53c2\u6570\u5316GD\u5728\u6311\u6218\u6027\u573a\u666f\u4e2d\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u7684\u7cbe\u5ea6\uff0c\u4e14\u7b80\u5355\u53ef\u6269\u5c55\u3002"}}
{"id": "2511.01311", "pdf": "https://arxiv.org/pdf/2511.01311", "abs": "https://arxiv.org/abs/2511.01311", "authors": ["Filip Naudot", "Tobias Sundqvist", "Timotheus Kampik"], "title": "llmSHAP: A Principled Approach to LLM Explainability", "categories": ["cs.AI"], "comment": null, "summary": "Feature attribution methods help make machine learning-based inference\nexplainable by determining how much one or several features have contributed to\na model's output. A particularly popular attribution method is based on the\nShapley value from cooperative game theory, a measure that guarantees the\nsatisfaction of several desirable principles, assuming deterministic inference.\nWe apply the Shapley value to feature attribution in large language model\n(LLM)-based decision support systems, where inference is, by design, stochastic\n(non-deterministic). We then demonstrate when we can and cannot guarantee\nShapley value principle satisfaction across different implementation variants\napplied to LLM-based decision support, and analyze how the stochastic nature of\nLLMs affects these guarantees. We also highlight trade-offs between explainable\ninference speed, agreement with exact Shapley value attributions, and principle\nattainment.", "AI": {"tldr": "\u5c06Shapley\u503c\u5e94\u7528\u4e8e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u7279\u5f81\u5f52\u56e0\uff0c\u63a2\u8ba8\u539f\u5219\u6ee1\u8db3\u60c5\u51b5\u3001\u968f\u673a\u6027\u8d28\u5f71\u54cd\u53ca\u6743\u8861\u3002", "motivation": "\u5c06\u57fa\u4e8e\u786e\u5b9a\u6027\u63a8\u7406\u7684Shapley\u503c\u5e94\u7528\u5230\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u968f\u673a\u63a8\u7406\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\uff0c\u5b9e\u73b0\u7279\u5f81\u5f52\u56e0\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5c06Shapley\u503c\u5e94\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u7279\u5f81\u5f52\u56e0\uff0c\u5206\u6790\u4e0d\u540c\u5b9e\u73b0\u53d8\u4f53\u4e0bShapley\u503c\u539f\u5219\u7684\u6ee1\u8db3\u60c5\u51b5\uff0c\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u968f\u673a\u6027\u8d28\u7684\u5f71\u54cd\u3002", "result": "\u5f97\u51fa\u5728\u4e0d\u540c\u5b9e\u73b0\u53d8\u4f53\u4e0b\u80fd\u5426\u4fdd\u8bc1Shapley\u503c\u539f\u5219\u6ee1\u8db3\u7684\u60c5\u51b5\uff0c\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u968f\u673a\u6027\u8d28\u5bf9\u4fdd\u8bc1\u7684\u5f71\u54cd\u3002", "conclusion": "\u6307\u51fa\u53ef\u89e3\u91ca\u63a8\u7406\u901f\u5ea6\u3001\u4e0e\u7cbe\u786eShapley\u503c\u5f52\u56e0\u7684\u4e00\u81f4\u6027\u548c\u539f\u5219\u8fbe\u6210\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002"}}
{"id": "2511.01757", "pdf": "https://arxiv.org/pdf/2511.01757", "abs": "https://arxiv.org/abs/2511.01757", "authors": ["Shamse Tasnim Cynthia", "Banani Roy"], "title": "Towards LLM-Powered Task-Aware Retrieval of Scientific Workflows for Galaxy", "categories": ["cs.SE"], "comment": null, "summary": "Scientific Workflow Management Systems (SWfMSs) such as Galaxy have become\nessential infrastructure in bioinformatics, supporting the design, execution,\nand sharing of complex multi-step analyses. Despite hosting hundreds of\nreusable workflows across domains, Galaxy's current keyword-based retrieval\nsystem offers limited support for semantic query interpretation and often fails\nto surface relevant workflows when exact term matches are absent. To address\nthis gap, we propose a task-aware, two-stage retrieval framework that\nintegrates dense vector search with large language model (LLM)-based reranking.\nOur system first retrieves candidate workflows using state-of-the-art embedding\nmodels and then reranks them using instruction-tuned generative LLMs (GPT-4o,\nMistral-7B) based on semantic task alignment. To support robust evaluation, we\nconstruct a benchmark dataset of Galaxy workflows annotated with semantic\ntopics via BERTopic and synthesize realistic task-oriented queries using LLMs.\nWe conduct a comprehensive comparison of lexical, dense, and reranking models\nusing standard IR metrics, presenting the first systematic evaluation of\nretrieval performance in the Galaxy ecosystem. Results show that our approach\nsignificantly improves top-k accuracy and relevance, particularly for long or\nunder-specified queries. We further integrate our system as a prototype tool\nwithin Galaxy, providing a proof-of-concept for LLM-enhanced workflow search.\nThis work advances the usability and accessibility of scientific workflows,\nespecially for novice users and interdisciplinary researchers.", "AI": {"tldr": "\u9488\u5bf9Galaxy\u5f53\u524d\u5173\u952e\u8bcd\u68c0\u7d22\u7cfb\u7edf\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4efb\u52a1\u611f\u77e5\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u6846\u67b6\uff0c\u6784\u5efa\u57fa\u51c6\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u5e76\u96c6\u6210\u5230Galaxy\u3002", "motivation": "Galaxy\u5f53\u524d\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u68c0\u7d22\u7cfb\u7edf\u5728\u8bed\u4e49\u67e5\u8be2\u89e3\u91ca\u65b9\u9762\u652f\u6301\u6709\u9650\uff0c\u7f3a\u4e4f\u7cbe\u786e\u5339\u914d\u65f6\u96be\u4ee5\u627e\u5230\u76f8\u5173\u5de5\u4f5c\u6d41\u3002", "method": "\u63d0\u51fa\u4efb\u52a1\u611f\u77e5\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u6846\u67b6\uff0c\u5148\u4f7f\u7528\u5d4c\u5165\u6a21\u578b\u68c0\u7d22\u5019\u9009\u5de5\u4f5c\u6d41\uff0c\u518d\u7528\u6307\u4ee4\u8c03\u4f18\u7684\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\uff1b\u6784\u5efa\u5e26\u8bed\u4e49\u4e3b\u9898\u6ce8\u91ca\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5408\u6210\u4efb\u52a1\u5bfc\u5411\u67e5\u8be2\uff0c\u7528\u6807\u51c6\u4fe1\u606f\u68c0\u7d22\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86top - k\u51c6\u786e\u7387\u548c\u76f8\u5173\u6027\uff0c\u5c24\u5176\u9488\u5bf9\u957f\u6216\u672a\u660e\u786e\u6307\u5b9a\u7684\u67e5\u8be2\u3002", "conclusion": "\u6b64\u5de5\u4f5c\u63a8\u8fdb\u4e86\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u53ef\u7528\u6027\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u5bf9\u65b0\u624b\u548c\u8de8\u5b66\u79d1\u7814\u7a76\u4eba\u5458\u6709\u76ca\u3002"}}
{"id": "2511.00121", "pdf": "https://arxiv.org/pdf/2511.00121", "abs": "https://arxiv.org/abs/2511.00121", "authors": ["Shoma Yagi", "Jun Ichikawa", "Genki Ichinose"], "title": "Analysis of Line Break prediction models for detecting defensive breakthrough in football", "categories": ["cs.LG", "physics.soc-ph", "stat.AP"], "comment": "14 pages, 8 figures", "summary": "In football, attacking teams attempt to break through the opponent's\ndefensive line to create scoring opportunities. This action, known as a Line\nBreak, is a critical indicator of offensive effectiveness and tactical\nperformance, yet previous studies have mainly focused on shots or goal\nopportunities rather than on how teams break the defensive line. In this study,\nwe develop a machine learning model to predict Line Breaks using event and\ntracking data from the 2023 J1 League season. The model incorporates 189\nfeatures, including player positions, velocities, and spatial configurations,\nand employs an XGBoost classifier to estimate the probability of Line Breaks.\nThe proposed model achieved high predictive accuracy, with an AUC of 0.982 and\na Brier score of 0.015. Furthermore, SHAP analysis revealed that factors such\nas offensive player speed, gaps in the defensive line, and offensive players'\nspatial distributions significantly contribute to the occurrence of Line\nBreaks. Finally, we found a moderate positive correlation between the predicted\nprobability of being Line-Broken and the number of shots and crosses conceded\nat the team level. These results suggest that Line Breaks are closely linked to\nthe creation of scoring opportunities and provide a quantitative framework for\nunderstanding tactical dynamics in football.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u8db3\u7403\u6bd4\u8d5b\u4e2d\u9632\u7ebf\u7a81\u7834\uff0c\u6a21\u578b\u51c6\u786e\u6027\u9ad8\uff0c\u63ed\u793a\u76f8\u5173\u5f71\u54cd\u56e0\u7d20\u53ca\u4e0e\u5f97\u5206\u673a\u4f1a\u8054\u7cfb\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u591a\u5173\u6ce8\u5c04\u95e8\u6216\u5f97\u5206\u673a\u4f1a\uff0c\u8f83\u5c11\u5173\u6ce8\u7403\u961f\u5982\u4f55\u7a81\u7834\u9632\u7ebf\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u5229\u75282023\u5e74J1\u8054\u8d5b\u8d5b\u5b63\u7684\u4e8b\u4ef6\u548c\u8ddf\u8e2a\u6570\u636e\uff0c\u6784\u5efa\u5305\u542b189\u4e2a\u7279\u5f81\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u91c7\u7528XGBoost\u5206\u7c7b\u5668\u4f30\u8ba1\u9632\u7ebf\u7a81\u7834\u6982\u7387\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u9ad8\uff0cAUC\u4e3a0.982\uff0cBrier\u5206\u6570\u4e3a0.015\uff1bSHAP\u5206\u6790\u63ed\u793a\u8fdb\u653b\u7403\u5458\u901f\u5ea6\u3001\u9632\u7ebf\u7f3a\u53e3\u7b49\u56e0\u7d20\u5bf9\u9632\u7ebf\u7a81\u7834\u6709\u91cd\u8981\u5f71\u54cd\uff1b\u7403\u961f\u5c42\u9762\u9632\u7ebf\u88ab\u7a81\u7834\u6982\u7387\u4e0e\u5931\u7403\u6570\u548c\u4f20\u4e2d\u6570\u5448\u4e2d\u5ea6\u6b63\u76f8\u5173\u3002", "conclusion": "\u9632\u7ebf\u7a81\u7834\u4e0e\u5f97\u5206\u673a\u4f1a\u5bc6\u5207\u76f8\u5173\uff0c\u4e3a\u7406\u89e3\u8db3\u7403\u6218\u672f\u52a8\u6001\u63d0\u4f9b\u5b9a\u91cf\u6846\u67b6\u3002"}}
{"id": "2511.01641", "pdf": "https://arxiv.org/pdf/2511.01641", "abs": "https://arxiv.org/abs/2511.01641", "authors": ["Xiaopeng Ke", "Yihan Yu", "Ruyue Zhang", "Zhishuo Zhou", "Fangzhou Shi", "Chang Men", "Zhengdan Zhu"], "title": "Cross-Treatment Effect Estimation for Multi-Category, Multi-Valued Causal Inference via Dynamic Neural Masking", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Counterfactual causal inference faces significant challenges when extended to\nmulti-category, multi-valued treatments, where complex cross-effects between\nheterogeneous interventions are difficult to model. Existing methodologies\nremain constrained to binary or single-type treatments and suffer from\nrestrictive assumptions, limited scalability, and inadequate evaluation\nframeworks for complex intervention scenarios.\n  We present XTNet, a novel network architecture for multi-category,\nmulti-valued treatment effect estimation. Our approach introduces a\ncross-effect estimation module with dynamic masking mechanisms to capture\ntreatment interactions without restrictive structural assumptions. The\narchitecture employs a decomposition strategy separating basic effects from\ncross-treatment interactions, enabling efficient modeling of combinatorial\ntreatment spaces. We also propose MCMV-AUCC, a suitable evaluation metric that\naccounts for treatment costs and interaction effects. Extensive experiments on\nsynthetic and real-world datasets demonstrate that XTNet consistently\noutperforms state-of-the-art baselines in both ranking accuracy and effect\nestimation quality. The results of the real-world A/B test further confirm its\neffectiveness.", "AI": {"tldr": "\u63d0\u51faXTNet\u7f51\u7edc\u67b6\u6784\u7528\u4e8e\u591a\u7c7b\u522b\u3001\u591a\u503c\u5904\u7406\u6548\u5e94\u4f30\u8ba1\uff0c\u8fd8\u63d0\u51faMCMV - AUCC\u8bc4\u4f30\u6307\u6807\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\u5728\u5904\u7406\u591a\u7c7b\u522b\u3001\u591a\u503c\u5904\u7406\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u5982\u53d7\u9650\u4e8e\u4e8c\u5143\u6216\u5355\u4e00\u7c7b\u578b\u5904\u7406\uff0c\u6709\u5047\u8bbe\u9650\u5236\u3001\u53ef\u6269\u5c55\u6027\u5dee\u548c\u8bc4\u4f30\u6846\u67b6\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faXTNet\u7f51\u7edc\u67b6\u6784\uff0c\u5f15\u5165\u5e26\u52a8\u6001\u63a9\u7801\u673a\u5236\u7684\u4ea4\u53c9\u6548\u5e94\u4f30\u8ba1\u6a21\u5757\uff0c\u91c7\u7528\u5206\u89e3\u7b56\u7565\u5206\u79bb\u57fa\u672c\u6548\u5e94\u548c\u4ea4\u53c9\u5904\u7406\u4ea4\u4e92\uff1b\u63d0\u51faMCMV - AUCC\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cXTNet\u5728\u6392\u540d\u51c6\u786e\u6027\u548c\u6548\u5e94\u4f30\u8ba1\u8d28\u91cf\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u771f\u5b9e\u4e16\u754cA/B\u6d4b\u8bd5\u7ed3\u679c\u4e5f\u8bc1\u5b9e\u5176\u6709\u6548\u6027\u3002", "conclusion": "XTNet\u662f\u4e00\u79cd\u6709\u6548\u7684\u591a\u7c7b\u522b\u3001\u591a\u503c\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2511.01320", "pdf": "https://arxiv.org/pdf/2511.01320", "abs": "https://arxiv.org/abs/2511.01320", "authors": ["Ziqi Wang", "Hailiang Zhao", "Yuhao Yang", "Daojiang Hu", "Cheng Bao", "Mingyi Liu", "Kai Di", "Schahram Dustdar", "Zhongjie Wang", "Shuiguang Deng"], "title": "OmniFuser: Adaptive Multimodal Fusion for Service-Oriented Predictive Maintenance", "categories": ["cs.AI"], "comment": null, "summary": "Accurate and timely prediction of tool conditions is critical for intelligent\nmanufacturing systems, where unplanned tool failures can lead to quality\ndegradation and production downtime. In modern industrial environments,\npredictive maintenance is increasingly implemented as an intelligent service\nthat integrates sensing, analysis, and decision support across production\nprocesses. To meet the demand for reliable and service-oriented operation, we\npresent OmniFuser, a multimodal learning framework for predictive maintenance\nof milling tools that leverages both visual and sensor data. It performs\nparallel feature extraction from high-resolution tool images and cutting-force\nsignals, capturing complementary spatiotemporal patterns across modalities. To\neffectively integrate heterogeneous features, OmniFuser employs a\ncontamination-free cross-modal fusion mechanism that disentangles shared and\nmodality-specific components, allowing for efficient cross-modal interaction.\nFurthermore, a recursive refinement pathway functions as an anchor mechanism,\nconsistently retaining residual information to stabilize fusion dynamics. The\nlearned representations can be encapsulated as reusable maintenance service\nmodules, supporting both tool-state classification (e.g., Sharp, Used, Dulled)\nand multi-step force signal forecasting. Experiments on real-world milling\ndatasets demonstrate that OmniFuser consistently outperforms state-of-the-art\nbaselines, providing a dependable foundation for building intelligent\nindustrial maintenance services.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u94e3\u5200\u9884\u6d4b\u6027\u7ef4\u62a4\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6OmniFuser\uff0c\u7ed3\u5408\u89c6\u89c9\u548c\u4f20\u611f\u5668\u6570\u636e\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u667a\u80fd\u5de5\u4e1a\u7ef4\u62a4\u670d\u52a1\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u51c6\u786e\u53ca\u65f6\u9884\u6d4b\u5200\u5177\u72b6\u6001\u5bf9\u667a\u80fd\u5236\u9020\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u6ee1\u8db3\u53ef\u9760\u548c\u9762\u5411\u670d\u52a1\u7684\u8fd0\u884c\u9700\u6c42\u3002", "method": "\u63d0\u51faOmniFuser\u6846\u67b6\uff0c\u4ece\u5de5\u5177\u56fe\u50cf\u548c\u5207\u524a\u529b\u4fe1\u53f7\u5e76\u884c\u63d0\u53d6\u7279\u5f81\uff0c\u91c7\u7528\u65e0\u6c61\u67d3\u8de8\u6a21\u6001\u878d\u5408\u673a\u5236\u548c\u9012\u5f52\u7ec6\u5316\u8def\u5f84\u3002", "result": "\u5728\u771f\u5b9e\u94e3\u524a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cOmniFuser\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "OmniFuser\u4e3a\u6784\u5efa\u667a\u80fd\u5de5\u4e1a\u7ef4\u62a4\u670d\u52a1\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\u3002"}}
{"id": "2511.01763", "pdf": "https://arxiv.org/pdf/2511.01763", "abs": "https://arxiv.org/abs/2511.01763", "authors": ["Xiaohan Wang", "Yuxin Hu", "Kevin Leach"], "title": "Context-Guided Decompilation: A Step Towards Re-executability", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Binary decompilation plays an important role in software security analysis,\nreverse engineering, and malware understanding when source code is unavailable.\nHowever, existing decompilation techniques often fail to produce source code\nthat can be successfully recompiled and re-executed, particularly for optimized\nbinaries. Recent advances in large language models (LLMs) have enabled neural\napproaches to decompilation, but the generated code is typically only\nsemantically plausible rather than truly executable, limiting their practical\nreliability. These shortcomings arise from compiler optimizations and the loss\nof semantic cues in compiled code, which LLMs struggle to recover without\ncontextual guidance. To address this challenge, we propose ICL4Decomp, a hybrid\ndecompilation framework that leverages in-context learning (ICL) to guide LLMs\ntoward generating re-executable source code. We evaluate our method across\nmultiple datasets, optimization levels, and compilers, demonstrating around\n40\\% improvement in re-executability over state-of-the-art decompilation\nmethods while maintaining robustness.", "AI": {"tldr": "\u73b0\u6709\u4e8c\u8fdb\u5236\u53cd\u7f16\u8bd1\u6280\u672f\u751f\u6210\u4ee3\u7801\u96be\u91cd\u65b0\u7f16\u8bd1\u6267\u884c\uff0c\u672c\u6587\u63d0\u51faICL4Decomp\u6846\u67b6\uff0c\u5728\u591a\u6570\u636e\u96c6\u7b49\u6d4b\u8bd5\u4e2d\u53ef\u63d0\u5347\u7ea640%\u91cd\u65b0\u53ef\u6267\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u53cd\u7f16\u8bd1\u6280\u672f\u751f\u6210\u7684\u4ee3\u7801\u96be\u4ee5\u91cd\u65b0\u7f16\u8bd1\u548c\u6267\u884c\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u4e5f\u7f3a\u4e4f\u771f\u6b63\u7684\u53ef\u6267\u884c\u6027\uff0c\u9700\u8981\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faICL4Decomp\u6df7\u5408\u53cd\u7f16\u8bd1\u6846\u67b6\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u91cd\u65b0\u6267\u884c\u7684\u6e90\u4ee3\u7801\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u3001\u4f18\u5316\u7ea7\u522b\u548c\u7f16\u8bd1\u5668\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\uff0c\u91cd\u65b0\u53ef\u6267\u884c\u6027\u63d0\u9ad8\u7ea640%\uff0c\u4e14\u4fdd\u6301\u4e86\u9c81\u68d2\u6027\u3002", "conclusion": "ICL4Decomp\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u53cd\u7f16\u8bd1\u6280\u672f\u751f\u6210\u4ee3\u7801\u96be\u4ee5\u91cd\u65b0\u6267\u884c\u7684\u95ee\u9898\uff0c\u5177\u6709\u8f83\u597d\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.00124", "pdf": "https://arxiv.org/pdf/2511.00124", "abs": "https://arxiv.org/abs/2511.00124", "authors": ["Sai Niranjan Ramachandran", "Manish Krishan Lal", "Suvrit Sra"], "title": "Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at NeurIPS 2025. 10 pages, camera-ready version. appendices\n  included", "summary": "We analyse how the sampling dynamics of distributions evolve in score-based\ndiffusion models using cross-fluctuations, a centered-moment statistic from\nstatistical physics. Specifically, we show that starting from an unbiased\nisotropic normal distribution, samples undergo sharp, discrete transitions,\neventually forming distinct events of a desired distribution while\nprogressively revealing finer structure. As this process is reversible, these\ntransitions also occur in reverse, where intermediate states progressively\nmerge, tracing a path back to the initial distribution. We demonstrate that\nthese transitions can be detected as discontinuities in $n^{\\text{th}}$-order\ncross-fluctuations. For variance-preserving SDEs, we derive a closed-form for\nthese cross-fluctuations that is efficiently computable for the reverse\ntrajectory. We find that detecting these transitions directly boosts sampling\nefficiency, accelerates class-conditional and rare-class generation, and\nimproves two zero-shot tasks--image classification and style transfer--without\nexpensive grid search or retraining. We also show that this viewpoint unifies\nclassical coupling and mixing from finite Markov chains with continuous\ndynamics while extending to stochastic SDEs and non Markovian samplers. Our\nframework therefore bridges discrete Markov chain theory, phase analysis, and\nmodern generative modeling.", "AI": {"tldr": "\u5229\u7528\u4ea4\u53c9\u6da8\u843d\u5206\u6790\u5206\u6570\u6269\u6563\u6a21\u578b\u4e2d\u5206\u5e03\u91c7\u6837\u52a8\u6001\uff0c\u53d1\u73b0\u79bb\u6563\u8f6c\u53d8\u53ef\u68c0\u6d4b\uff0c\u80fd\u63d0\u5347\u91c7\u6837\u6548\u7387\u548c\u5b8c\u6210\u96f6\u6837\u672c\u4efb\u52a1\uff0c\u8fd8\u7edf\u4e00\u4e86\u76f8\u5173\u7406\u8bba\u3002", "motivation": "\u5206\u6790\u5206\u6570\u6269\u6563\u6a21\u578b\u4e2d\u5206\u5e03\u7684\u91c7\u6837\u52a8\u6001\u6f14\u53d8\u3002", "method": "\u4f7f\u7528\u7edf\u8ba1\u7269\u7406\u4e2d\u7684\u4ea4\u53c9\u6da8\u843d\u7edf\u8ba1\u91cf\uff0c\u63a8\u5bfc\u65b9\u5dee\u4fdd\u6301SDE\u7684\u4ea4\u53c9\u6da8\u843d\u95ed\u5f0f\u89e3\u3002", "result": "\u68c0\u6d4b\u5230\u79bb\u6563\u8f6c\u53d8\u53ef\u63d0\u5347\u91c7\u6837\u6548\u7387\u3001\u52a0\u901f\u751f\u6210\u4efb\u52a1\u3001\u6539\u5584\u96f6\u6837\u672c\u4efb\u52a1\uff0c\u7edf\u4e00\u4e86\u7ecf\u5178\u8026\u5408\u548c\u8fde\u7eed\u52a8\u529b\u5b66\u3002", "conclusion": "\u8be5\u6846\u67b6\u6865\u63a5\u4e86\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u94fe\u7406\u8bba\u3001\u76f8\u4f4d\u5206\u6790\u548c\u73b0\u4ee3\u751f\u6210\u5efa\u6a21\u3002"}}
{"id": "2511.01795", "pdf": "https://arxiv.org/pdf/2511.01795", "abs": "https://arxiv.org/abs/2511.01795", "authors": ["Gabriel Nobis", "Maximilian Springenberg", "Arina Belova", "Rembert Daems", "Christoph Knochenhauer", "Manfred Opper", "Tolga Birdal", "Wojciech Samek"], "title": "Fractional Diffusion Bridge Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO", "stat.ML"], "comment": "To appear in NeurIPS 2025 proceedings. This version includes\n  post-camera-ready revisions", "summary": "We present Fractional Diffusion Bridge Models (FDBM), a novel generative\ndiffusion bridge framework driven by an approximation of the rich and\nnon-Markovian fractional Brownian motion (fBM). Real stochastic processes\nexhibit a degree of memory effects (correlations in time), long-range\ndependencies, roughness and anomalous diffusion phenomena that are not captured\nin standard diffusion or bridge modeling due to the use of Brownian motion\n(BM). As a remedy, leveraging a recent Markovian approximation of fBM (MA-fBM),\nwe construct FDBM that enable tractable inference while preserving the\nnon-Markovian nature of fBM. We prove the existence of a coupling-preserving\ngenerative diffusion bridge and leverage it for future state prediction from\npaired training data. We then extend our formulation to the Schr\\\"{o}dinger\nbridge problem and derive a principled loss function to learn the unpaired data\ntranslation. We evaluate FDBM on both tasks: predicting future protein\nconformations from aligned data, and unpaired image translation. In both\nsettings, FDBM achieves superior performance compared to the Brownian\nbaselines, yielding lower root mean squared deviation (RMSD) of C$_\\alpha$\natomic positions in protein structure prediction and lower Fr\\'echet Inception\nDistance (FID) in unpaired image translation.", "AI": {"tldr": "\u63d0\u51fa\u5206\u6570\u6269\u6563\u6865\u6a21\u578b\uff08FDBM\uff09\uff0c\u57fa\u4e8e\u5206\u6570\u5e03\u6717\u8fd0\u52a8\u8fd1\u4f3c\uff0c\u5728\u86cb\u767d\u8d28\u6784\u8c61\u9884\u6d4b\u548c\u56fe\u50cf\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5e03\u6717\u8fd0\u52a8\u57fa\u7ebf\u3002", "motivation": "\u6807\u51c6\u6269\u6563\u6216\u6865\u6a21\u578b\u4f7f\u7528\u5e03\u6717\u8fd0\u52a8\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u968f\u673a\u8fc7\u7a0b\u7684\u8bb0\u5fc6\u6548\u5e94\u3001\u957f\u7a0b\u4f9d\u8d56\u7b49\u73b0\u8c61\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u6a21\u578b\u3002", "method": "\u5229\u7528\u5206\u6570\u5e03\u6717\u8fd0\u52a8\u7684\u9a6c\u5c14\u53ef\u592b\u8fd1\u4f3c\u6784\u5efaFDBM\uff0c\u8bc1\u660e\u8026\u5408\u4fdd\u6301\u751f\u6210\u6269\u6563\u6865\u7684\u5b58\u5728\uff0c\u5c06\u5176\u6269\u5c55\u5230\u859b\u5b9a\u8c14\u6865\u95ee\u9898\u5e76\u63a8\u5bfc\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u86cb\u767d\u8d28\u6784\u8c61\u9884\u6d4b\u4e2dC\u03b1\u539f\u5b50\u4f4d\u7f6e\u7684\u5747\u65b9\u6839\u504f\u5dee\u66f4\u4f4e\uff0c\u5728\u65e0\u914d\u5bf9\u56fe\u50cf\u7ffb\u8bd1\u4e2dFr\u00e9chet Inception\u8ddd\u79bb\u66f4\u4f4e\u3002", "conclusion": "FDBM\u5728\u9884\u6d4b\u672a\u6765\u86cb\u767d\u8d28\u6784\u8c61\u548c\u65e0\u914d\u5bf9\u56fe\u50cf\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5e03\u6717\u8fd0\u52a8\u57fa\u7ebf\u3002"}}
{"id": "2511.01329", "pdf": "https://arxiv.org/pdf/2511.01329", "abs": "https://arxiv.org/abs/2511.01329", "authors": ["Ying Song", "Yijing Wang", "Hui Yang", "Weihan Jin", "Jun Xiong", "Congyi Zhou", "Jialin Zhu", "Xiang Gao", "Rong Chen", "HuaGuang Deng", "Ying Dai", "Fei Xiao", "Haihong Tang", "Bo Zheng", "KaiFu Zhang"], "title": "Unbiased Platform-Level Causal Estimation for Search Systems: A Competitive Isolation PSM-DID Framework", "categories": ["cs.AI"], "comment": null, "summary": "Evaluating platform-level interventions in search-based two-sided\nmarketplaces is fundamentally challenged by systemic effects such as spillovers\nand network interference. While widely used for causal inference, the PSM\n(Propensity Score Matching) - DID (Difference-in-Differences) framework remains\nsusceptible to selection bias and cross-unit interference from unaccounted\nspillovers. In this paper, we introduced Competitive Isolation PSM-DID, a novel\ncausal framework that integrates propensity score matching with competitive\nisolation to enable platform-level effect measurement (e.g., order volume, GMV)\ninstead of item-level metrics in search systems.\n  Our approach provides theoretically guaranteed unbiased estimation under\nmutual exclusion conditions, with an open dataset released to support\nreproducible research on marketplace interference (github.com/xxxx). Extensive\nexperiments demonstrate significant reductions in interference effects and\nestimation variance compared to baseline methods. Successful deployment in a\nlarge-scale marketplace confirms the framework's practical utility for\nplatform-level causal inference.", "AI": {"tldr": "\u63d0\u51faCompetitive Isolation PSM - DID\u56e0\u679c\u6846\u67b6\u7528\u4e8e\u5e73\u53f0\u7ea7\u6548\u679c\u6d4b\u91cf\uff0c\u5b9e\u9a8c\u663e\u793a\u51cf\u5c11\u5e72\u6270\u548c\u4f30\u8ba1\u65b9\u5dee\uff0c\u90e8\u7f72\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709PSM - DID\u6846\u67b6\u8bc4\u4f30\u641c\u7d22\u53cc\u8fb9\u5e02\u573a\u5e73\u53f0\u7ea7\u5e72\u9884\u53d7\u7cfb\u7edf\u6548\u5e94\u6311\u6218\uff0c\u5b58\u5728\u9009\u62e9\u504f\u5dee\u548c\u6ea2\u51fa\u5e72\u6270\u95ee\u9898\u3002", "method": "\u5f15\u5165Competitive Isolation PSM - DID\u6846\u67b6\uff0c\u7ed3\u5408\u503e\u5411\u5f97\u5206\u5339\u914d\u548c\u7ade\u4e89\u9694\u79bb\u8fdb\u884c\u5e73\u53f0\u7ea7\u6548\u679c\u6d4b\u91cf\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e92\u65a5\u6761\u4ef6\u4e0b\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u65e0\u504f\u4f30\u8ba1\uff0c\u5b9e\u9a8c\u8868\u660e\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u5e72\u6270\u6548\u5e94\u548c\u4f30\u8ba1\u65b9\u5dee\u3002", "conclusion": "\u8be5\u6846\u67b6\u5bf9\u5e73\u53f0\u7ea7\u56e0\u679c\u63a8\u65ad\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01850", "pdf": "https://arxiv.org/pdf/2511.01850", "abs": "https://arxiv.org/abs/2511.01850", "authors": ["Jiawei Jin", "Yingxin Su", "Xiaotong Zhu"], "title": "SmartMLOps Studio: Design of an LLM-Integrated IDE with Automated MLOps Pipelines for Model Development and Monitoring", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "The rapid expansion of artificial intelligence and machine learning (ML)\napplications has intensified the demand for integrated environments that unify\nmodel development, deployment, and monitoring. Traditional Integrated\nDevelopment Environments (IDEs) focus primarily on code authoring, lacking\nintelligent support for the full ML lifecycle, while existing MLOps platforms\nremain detached from the coding workflow. To address this gap, this study\nproposes the design of an LLM-Integrated IDE with automated MLOps pipelines\nthat enables continuous model development and monitoring within a single\nenvironment. The proposed system embeds a Large Language Model (LLM) assistant\ncapable of code generation, debugging recommendation, and automatic pipeline\nconfiguration. The backend incorporates automated data validation, feature\nstorage, drift detection, retraining triggers, and CI/CD deployment\norchestration. This framework was implemented in a prototype named SmartMLOps\nStudio and evaluated using classification and forecasting tasks on the UCI\nAdult and M5 datasets. Experimental results demonstrate that SmartMLOps Studio\nreduces pipeline configuration time by 61%, improves experiment reproducibility\nby 45%, and increases drift detection accuracy by 14% compared to traditional\nworkflows. By bridging intelligent code assistance and automated operational\npipelines, this research establishes a novel paradigm for AI engineering -\ntransforming the IDE from a static coding tool into a dynamic, lifecycle-aware\nintelligent platform for scalable and efficient model development.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u542b\u81ea\u52a8\u5316MLOps\u7ba1\u9053\u7684LLM\u96c6\u6210IDE\uff0c\u5b9e\u73b0\u5355\u73af\u5883\u6a21\u578b\u6301\u7eed\u5f00\u53d1\u4e0e\u76d1\u63a7\uff0cSmartMLOps Studio\u5b9e\u9a8c\u6548\u679c\u597d\uff0c\u8f6c\u53d8IDE\u4e3a\u667a\u80fd\u5e73\u53f0\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u5b66\u4e60\u5e94\u7528\u9700\u6c42\u589e\u957f\uff0c\u4f20\u7edfIDE\u548c\u73b0\u6709MLOps\u5e73\u53f0\u5b58\u5728\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u7edf\u4e00\u6a21\u578b\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u76d1\u63a7\u7684\u96c6\u6210\u73af\u5883\u3002", "method": "\u8bbe\u8ba1\u542b\u81ea\u52a8\u5316MLOps\u7ba1\u9053\u7684LLM\u96c6\u6210IDE\uff0c\u5d4c\u5165LLM\u52a9\u624b\uff0c\u540e\u7aef\u6709\u81ea\u52a8\u5316\u6570\u636e\u9a8c\u8bc1\u7b49\u529f\u80fd\uff0c\u5b9e\u73b0\u540d\u4e3aSmartMLOps Studio\u7684\u539f\u578b\u3002", "result": "SmartMLOps Studio\u76f8\u6bd4\u4f20\u7edf\u5de5\u4f5c\u6d41\uff0c\u51cf\u5c1161%\u7ba1\u9053\u914d\u7f6e\u65f6\u95f4\uff0c\u63d0\u9ad845%\u5b9e\u9a8c\u53ef\u91cd\u590d\u6027\uff0c\u63d0\u534714%\u6f02\u79fb\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86AI\u5de5\u7a0b\u65b0\u8303\u5f0f\uff0c\u5c06IDE\u8f6c\u53d8\u4e3a\u52a8\u6001\u3001\u5168\u751f\u547d\u5468\u671f\u7684\u667a\u80fd\u5e73\u53f0\uff0c\u5229\u4e8e\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u6a21\u578b\u5f00\u53d1\u3002"}}
{"id": "2511.00126", "pdf": "https://arxiv.org/pdf/2511.00126", "abs": "https://arxiv.org/abs/2511.00126", "authors": ["Lu Bowen"], "title": "Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al.,\n2022) have achieved strong average accuracy but remain unreliable in complex\nlong-tail driving scenarios. These limitations reveal the weakness of the\nprevailing \"one-model-fits-all\" paradigm, particularly in safety-critical urban\ncontexts where simpler physics-based models can occasionally outperform\nadvanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic\nmulti-expert gating framework that adaptively selects the most reliable\ntrajectory predictor among a physics-informed LSTM, a Transformer, and a\nfine-tuned GameFormer on a per-sample basis.\n  Our method leverages internal model signals (meta-features) such as stability\nand uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be\nsubstantially more informative than geometric scene descriptors. To the best of\nour knowledge, this is the first work to formulate trajectory expert selection\nas a pairwise-ranking problem over internal model signals (Burges et al.,\n2005), directly optimizing decision quality without requiring post-hoc\ncalibration.\n  Evaluated on the nuPlan-mini dataset (Caesar et al., 2021) with 1,287\nsamples, our LLM-enhanced tri-expert gate achieves a Final Displacement Error\n(FDE) of 2.567 m, representing a 9.5 percent reduction over GameFormer (2.835\nm), and realizes 57.8 percent of the oracle performance bound. In open-loop\nsimulations, after trajectory horizon alignment, the same configuration reduces\nFDE on left-turn scenarios by approximately 10 percent, demonstrating\nconsistent improvements across both offline validation and open-loop\nevaluation. These results indicate that adaptive hybrid systems enhance\ntrajectory reliability in safety-critical autonomous driving, providing a\npractical pathway beyond static single-model paradigms.", "AI": {"tldr": "\u73b0\u6709\u6df1\u5ea6\u8f68\u8ff9\u9884\u6d4b\u5668\u5728\u590d\u6742\u957f\u5c3e\u9a7e\u9a76\u573a\u666f\u4e2d\u4e0d\u53ef\u9760\uff0c\u672c\u6587\u63d0\u51fa\u52a8\u6001\u591a\u4e13\u5bb6\u95e8\u63a7\u6846\u67b6\uff0c\u5728nuPlan - mini\u6570\u636e\u96c6\u4e0a\u6548\u679c\u826f\u597d\uff0c\u8868\u660e\u81ea\u9002\u5e94\u6df7\u5408\u7cfb\u7edf\u53ef\u63d0\u5347\u8f68\u8ff9\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u8f68\u8ff9\u9884\u6d4b\u5668\u5728\u590d\u6742\u957f\u5c3e\u9a7e\u9a76\u573a\u666f\u6709\u5c40\u9650\u6027\uff0c\u201cone - model - fits - all\u201d\u8303\u5f0f\u5b58\u5728\u5f31\u70b9\uff0c\u9700\u63d0\u5347\u8f68\u8ff9\u9884\u6d4b\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u591a\u4e13\u5bb6\u95e8\u63a7\u6846\u67b6\uff0c\u5728\u7269\u7406\u4fe1\u606fLSTM\u3001Transformer\u548c\u5fae\u8c03\u7684GameFormer\u4e2d\u9010\u6837\u672c\u9009\u62e9\u6700\u53ef\u9760\u7684\u8f68\u8ff9\u9884\u6d4b\u5668\uff0c\u5229\u7528\u5185\u90e8\u6a21\u578b\u4fe1\u53f7\u5982\u7a33\u5b9a\u6027\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u8f68\u8ff9\u4e13\u5bb6\u9009\u62e9\u8868\u8ff0\u4e3a\u5185\u90e8\u6a21\u578b\u4fe1\u53f7\u7684\u6210\u5bf9\u6392\u5e8f\u95ee\u9898\u3002", "result": "\u5728nuPlan - mini\u6570\u636e\u96c6\u4e0a\uff0cLLM\u589e\u5f3a\u7684\u4e09\u4e13\u5bb6\u95e8\u63a7\u5b9e\u73b0FDE\u4e3a2.567m\uff0c\u6bd4GameFormer\u964d\u4f4e9.5%\uff0c\u8fbe\u523057.8%\u7684oracle\u6027\u80fd\u8fb9\u754c\uff1b\u5728\u5f00\u73af\u6a21\u62df\u4e2d\uff0c\u5de6\u8f6c\u573a\u666fFDE\u964d\u4f4e\u7ea610%\u3002", "conclusion": "\u81ea\u9002\u5e94\u6df7\u5408\u7cfb\u7edf\u80fd\u63d0\u5347\u5b89\u5168\u5173\u952e\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u8f68\u8ff9\u53ef\u9760\u6027\uff0c\u63d0\u4f9b\u4e86\u8d85\u8d8a\u9759\u6001\u5355\u6a21\u578b\u8303\u5f0f\u7684\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2511.01847", "pdf": "https://arxiv.org/pdf/2511.01847", "abs": "https://arxiv.org/abs/2511.01847", "authors": ["Zhi Wang", "Chicheng Zhang", "Ramya Korlakai Vinayak"], "title": "Bridging Lifelong and Multi-Task Representation Learning via Algorithm and Complexity Measure", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In lifelong learning, a learner faces a sequence of tasks with shared\nstructure and aims to identify and leverage it to accelerate learning. We study\nthe setting where such structure is captured by a common representation of\ndata. Unlike multi-task learning or learning-to-learn, where tasks are\navailable upfront to learn the representation, lifelong learning requires the\nlearner to make use of its existing knowledge while continually gathering\npartial information in an online fashion. In this paper, we consider a\ngeneralized framework of lifelong representation learning. We propose a simple\nalgorithm that uses multi-task empirical risk minimization as a subroutine and\nestablish a sample complexity bound based on a new notion we introduce--the\ntask-eluder dimension. Our result applies to a wide range of learning problems\ninvolving general function classes. As concrete examples, we instantiate our\nresult on classification and regression tasks under noise.", "AI": {"tldr": "\u7814\u7a76\u7ec8\u8eab\u8868\u5f81\u5b66\u4e60\u5e7f\u4e49\u6846\u67b6\uff0c\u63d0\u51fa\u7b80\u5355\u7b97\u6cd5\u5e76\u5efa\u7acb\u6837\u672c\u590d\u6742\u5ea6\u754c\uff0c\u7ed3\u679c\u9002\u7528\u4e8e\u591a\u79cd\u5b66\u4e60\u95ee\u9898\u3002", "motivation": "\u7ec8\u8eab\u5b66\u4e60\u4e2d\u5b66\u4e60\u8005\u9700\u5229\u7528\u4efb\u52a1\u5171\u4eab\u7ed3\u6784\u52a0\u901f\u5b66\u4e60\uff0c\u4e0e\u591a\u4efb\u52a1\u5b66\u4e60\u7b49\u4e0d\u540c\uff0c\u9700\u5728\u7ebf\u5229\u7528\u5df2\u6709\u77e5\u8bc6\u548c\u90e8\u5206\u4fe1\u606f\uff0c\u6240\u4ee5\u7814\u7a76\u5e7f\u4e49\u7ec8\u8eab\u8868\u5f81\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u591a\u4efb\u52a1\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4f5c\u4e3a\u5b50\u7a0b\u5e8f\u7684\u7b80\u5355\u7b97\u6cd5\uff0c\u57fa\u4e8e\u65b0\u5f15\u5165\u7684\u4efb\u52a1\u56de\u907f\u7ef4\u5ea6\u5efa\u7acb\u6837\u672c\u590d\u6742\u5ea6\u754c\u3002", "result": "\u7ed3\u679c\u9002\u7528\u4e8e\u6d89\u53ca\u4e00\u822c\u51fd\u6570\u7c7b\u7684\u5e7f\u6cdb\u5b66\u4e60\u95ee\u9898\uff0c\u8fd8\u5728\u6709\u566a\u58f0\u7684\u5206\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u4f8b\u5316\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u548c\u590d\u6742\u5ea6\u754c\u5bf9\u7ec8\u8eab\u8868\u5f81\u5b66\u4e60\u6709\u4e00\u5b9a\u610f\u4e49\uff0c\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2511.01363", "pdf": "https://arxiv.org/pdf/2511.01363", "abs": "https://arxiv.org/abs/2511.01363", "authors": ["Giuseppe Riva", "Brenda K. Wiederhold", "Fabrizia Mantovani"], "title": "Automatic Minds: Cognitive Parallels Between Hypnotic States and Large Language Model Processing", "categories": ["cs.AI"], "comment": "4 Tables", "summary": "The cognitive processes of the hypnotized mind and the computational\noperations of large language models (LLMs) share deep functional parallels.\nBoth systems generate sophisticated, contextually appropriate behavior through\nautomatic pattern-completion mechanisms operating with limited or unreliable\nexecutive oversight. This review examines this convergence across three\nprinciples: automaticity, in which responses emerge from associative rather\nthan deliberative processes; suppressed monitoring, leading to errors such as\nconfabulation in hypnosis and hallucination in LLMs; and heightened contextual\ndependency, where immediate cues (for example, the suggestion of a therapist or\nthe prompt of the user) override stable knowledge.\n  These mechanisms reveal an observer-relative meaning gap: both systems\nproduce coherent but ungrounded outputs that require an external interpreter to\nsupply meaning. Hypnosis and LLMs also exemplify functional agency - the\ncapacity for complex, goal-directed, context-sensitive behavior - without\nsubjective agency, the conscious awareness of intention and ownership that\ndefines human action. This distinction clarifies how purposive behavior can\nemerge without self-reflective consciousness, governed instead by structural\nand contextual dynamics. Finally, both domains illuminate the phenomenon of\nscheming: automatic, goal-directed pattern generation that unfolds without\nreflective awareness. Hypnosis provides an experimental model for understanding\nhow intention can become dissociated from conscious deliberation, offering\ninsights into the hidden motivational dynamics of artificial systems.\nRecognizing these parallels suggests that the future of reliable AI lies in\nhybrid architectures that integrate generative fluency with mechanisms of\nexecutive monitoring, an approach inspired by the complex, self-regulating\narchitecture of the human mind.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u50ac\u7720\u72b6\u6001\u4e0b\u7684\u8ba4\u77e5\u8fc7\u7a0b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u64cd\u4f5c\u7684\u529f\u80fd\u76f8\u4f3c\u6027\uff0c\u5206\u6790\u76f8\u5173\u539f\u7406\u3001\u610f\u4e49\u5dee\u8ddd\u7b49\uff0c\u63d0\u51fa\u53ef\u9760AI\u7684\u672a\u6765\u67b6\u6784\u65b9\u5411\u3002", "motivation": "\u63a2\u7d22\u50ac\u7720\u72b6\u6001\u4e0b\u7684\u8ba4\u77e5\u8fc7\u7a0b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u64cd\u4f5c\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u4ee5\u6df1\u5165\u7406\u89e3\u4e24\u8005\u7684\u673a\u5236\u548c\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5206\u6790\u81ea\u52a8\u6027\u3001\u76d1\u63a7\u6291\u5236\u548c\u9ad8\u5ea6\u60c5\u5883\u4f9d\u8d56\u6027\u4e09\u4e2a\u539f\u5219\u6765\u7814\u7a76\u4e24\u8005\u7684\u8d8b\u540c\u6027\u3002", "result": "\u53d1\u73b0\u4e24\u8005\u90fd\u6709\u89c2\u5bdf\u8005\u76f8\u5bf9\u7684\u610f\u4e49\u5dee\u8ddd\uff0c\u4f53\u73b0\u529f\u80fd\u80fd\u52a8\u6027\u4f46\u65e0\u4e3b\u89c2\u80fd\u52a8\u6027\uff0c\u63ed\u793a\u4e86\u8c0b\u5212\u73b0\u8c61\uff0c\u4e14\u50ac\u7720\u53ef\u4f5c\u4e3a\u7406\u89e3\u4eba\u5de5\u7cfb\u7edf\u9690\u85cf\u52a8\u673a\u7684\u5b9e\u9a8c\u6a21\u578b\u3002", "conclusion": "\u53ef\u9760AI\u7684\u672a\u6765\u5728\u4e8e\u7ed3\u5408\u751f\u6210\u6d41\u7545\u6027\u548c\u6267\u884c\u76d1\u63a7\u673a\u5236\u7684\u6df7\u5408\u67b6\u6784\u3002"}}
{"id": "2511.00330", "pdf": "https://arxiv.org/pdf/2511.00330", "abs": "https://arxiv.org/abs/2511.00330", "authors": ["Yeonju Ro", "Haoran Qiu", "\u00cd\u00f1igo Goiri", "Rodrigo Fonseca", "Ricardo Bianchini", "Aditya Akella", "Zhangyang Wang", "Mattan Erez", "Esha Choukse"], "title": "Sherlock: Reliable and Efficient Agentic Workflow Execution", "categories": ["cs.MA", "cs.SE"], "comment": null, "summary": "With the increasing adoption of large language models (LLM), agentic\nworkflows, which compose multiple LLM calls with tools, retrieval, and\nreasoning steps, are increasingly replacing traditional applications. However,\nsuch workflows are inherently error-prone: incorrect or partially correct\noutput at one step can propagate or even amplify through subsequent stages,\ncompounding the impact on the final output. Recent work proposes integrating\nverifiers that validate LLM output or actions, such as self-reflection, debate,\nor LLM-as-a-judge mechanisms. Yet, verifying every step introduces significant\nlatency and cost overheads.\n  In this work, we seek to answer three key questions: which nodes in a\nworkflow are most error-prone and thus deserve costly verification, how to\nselect the most appropriate verifier for each node, and how to use verification\nwith minimal impact to latency? Our solution, Sherlock, addresses these using\ncounterfactual analysis on agentic workflows to identify error-prone nodes and\nselectively attaching cost-optimal verifiers only where necessary. At runtime,\nSherlock speculatively executes downstream tasks to reduce latency overhead,\nwhile verification runs in the background. If verification fails, execution is\nrolled back to the last verified output. Compared to the non-verifying\nbaseline, Sherlock delivers an 18.3% accuracy gain on average across\nbenchmarks. Sherlock reduces workflow execution time by up to 48.7% over\nnon-speculative execution and lowers verification cost by 26.0% compared to the\nMonte Carlo search-based method, demonstrating that principled, fault-aware\nverification effectively balances efficiency and reliability in agentic\nworkflows.", "AI": {"tldr": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u589e\u52a0\uff0c\u4ee3\u7406\u5de5\u4f5c\u6d41\u6613\u51fa\u9519\uff0c\u672c\u6587\u63d0\u51faSherlock\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5206\u6790\u8bc6\u522b\u6613\u9519\u8282\u70b9\uff0c\u9009\u62e9\u6027\u9a8c\u8bc1\uff0c\u517c\u987e\u6548\u7387\u4e0e\u53ef\u9760\u6027\uff0c\u63d0\u5347\u51c6\u786e\u7387\uff0c\u964d\u4f4e\u6267\u884c\u65f6\u95f4\u548c\u9a8c\u8bc1\u6210\u672c\u3002", "motivation": "\u4ee3\u7406\u5de5\u4f5c\u6d41\u6613\u51fa\u9519\uff0c\u73b0\u6709\u9a8c\u8bc1\u65b9\u6cd5\u6709\u663e\u8457\u5ef6\u8fdf\u548c\u6210\u672c\u5f00\u9500\uff0c\u9700\u89e3\u51b3\u54ea\u4e9b\u8282\u70b9\u9700\u9a8c\u8bc1\u3001\u9009\u5408\u9002\u9a8c\u8bc1\u5668\u53ca\u51cf\u5c11\u5bf9\u5ef6\u8fdf\u5f71\u54cd\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u53cd\u4e8b\u5b9e\u5206\u6790\u8bc6\u522b\u6613\u9519\u8282\u70b9\uff0c\u9009\u62e9\u6027\u9644\u52a0\u6210\u672c\u6700\u4f18\u9a8c\u8bc1\u5668\uff0c\u8fd0\u884c\u65f6\u63a8\u6d4b\u6267\u884c\u4e0b\u6e38\u4efb\u52a1\uff0c\u9a8c\u8bc1\u5728\u540e\u53f0\u8fd0\u884c\uff0c\u9a8c\u8bc1\u5931\u8d25\u5219\u56de\u6eda\u3002", "result": "\u76f8\u6bd4\u65e0\u9a8c\u8bc1\u57fa\u7ebf\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u534718.3%\uff1b\u76f8\u6bd4\u975e\u63a8\u6d4b\u6267\u884c\uff0c\u5de5\u4f5c\u6d41\u6267\u884c\u65f6\u95f4\u6700\u591a\u51cf\u5c1148.7%\uff1b\u76f8\u6bd4\u57fa\u4e8e\u8499\u7279\u5361\u7f57\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u6210\u672c\u964d\u4f4e26.0%\u3002", "conclusion": "\u6709\u539f\u5219\u7684\u3001\u6545\u969c\u611f\u77e5\u7684\u9a8c\u8bc1\u80fd\u6709\u6548\u5e73\u8861\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.00129", "pdf": "https://arxiv.org/pdf/2511.00129", "abs": "https://arxiv.org/abs/2511.00129", "authors": ["Siyu Xiao", "Xindi Zhao", "Tianhao Mao", "Yiwei Wang", "Yuqiao Chen", "Hongyun Zhang", "Jian Wang", "Junjie Wang", "Shuang Liu", "Tupei Chen", "Yang Liu"], "title": "Casing Collar Identification using AlexNet-based Neural Networks for Depth Measurement in Oil and Gas Wells", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Accurate downhole depth measurement is essential for oil and gas well\noperations, directly influencing reservoir contact, production efficiency, and\noperational safety. Collar correlation using a casing collar locator (CCL) is\nfundamental for precise depth calibration. While neural network-based CCL\nsignal recognition has achieved significant progress in collar identification,\npreprocessing methods for such applications remain underdeveloped. Moreover,\nthe limited availability of real well data poses substantial challenges for\ntraining neural network models that require extensive datasets. This paper\npresents a system integrated into downhole tools for CCL signal acquisition to\nfacilitate dataset construction. We propose comprehensive preprocessing methods\nfor data augmentation and evaluate their effectiveness using our AlexNet-based\nneural network models. Through systematic experimentation across various\nconfiguration combinations, we analyze the contribution of each augmentation\nmethod. Results demonstrate that standardization, label distribution smoothing\n(LDS), and random cropping are fundamental requirements for model training,\nwhile label smoothing regularization (LSR), time scaling, and multiple sampling\nsignificantly enhance model generalization capability. The F1 scores of our two\nbenchmark models trained with the proposed augmentation methods maximumly\nimprove from 0.937 and 0.952 to 1.0 and 1.0, respectively. Performance\nvalidation on real CCL waveforms confirms the effectiveness and practical\napplicability of our approach. This work addresses the gaps in data\naugmentation methodologies for training casing collar recognition models in CCL\ndata-limited environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e95\u4e0bCCL\u4fe1\u53f7\u91c7\u96c6\u7cfb\u7edf\u4ee5\u6784\u5efa\u6570\u636e\u96c6\uff0c\u7ed9\u51fa\u6570\u636e\u589e\u5f3a\u9884\u5904\u7406\u65b9\u6cd5\u5e76\u8bc4\u4f30\u5176\u6548\u679c\uff0c\u5b9e\u9a8c\u8868\u660e\u90e8\u5206\u65b9\u6cd5\u662f\u6a21\u578b\u8bad\u7ec3\u57fa\u7840\uff0c\u90e8\u5206\u80fd\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff0cF1\u5206\u6570\u63d0\u5347\uff0c\u5728\u771f\u5b9e\u6ce2\u5f62\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edcCCL\u4fe1\u53f7\u8bc6\u522b\u7684\u9884\u5904\u7406\u65b9\u6cd5\u53d1\u5c55\u4e0d\u8db3\uff0c\u4e14\u771f\u5b9e\u4e95\u6570\u636e\u6709\u9650\uff0c\u96be\u4ee5\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u4e8e\u4e95\u4e0b\u5de5\u5177\u7684CCL\u4fe1\u53f7\u91c7\u96c6\u7cfb\u7edf\u6784\u5efa\u6570\u636e\u96c6\uff0c\u7ed9\u51fa\u6570\u636e\u589e\u5f3a\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u7528\u57fa\u4e8eAlexNet\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8bc4\u4f30\u5176\u6548\u679c\uff0c\u5e76\u8fdb\u884c\u7cfb\u7edf\u5b9e\u9a8c\u3002", "result": "\u6807\u51c6\u5316\u3001LDS\u548c\u968f\u673a\u88c1\u526a\u662f\u6a21\u578b\u8bad\u7ec3\u57fa\u672c\u8981\u6c42\uff0cLSR\u3001\u65f6\u95f4\u7f29\u653e\u548c\u591a\u91cd\u91c7\u6837\u589e\u5f3a\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u4e24\u4e2a\u57fa\u51c6\u6a21\u578bF1\u5206\u6570\u6700\u9ad8\u63d0\u5347\u52301.0\uff0c\u5728\u771f\u5b9eCCL\u6ce2\u5f62\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u5de5\u4f5c\u5f25\u8865\u4e86CCL\u6570\u636e\u6709\u9650\u73af\u5883\u4e0b\u5957\u7ba1\u63a5\u7b8d\u8bc6\u522b\u6a21\u578b\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2511.01375", "pdf": "https://arxiv.org/pdf/2511.01375", "abs": "https://arxiv.org/abs/2511.01375", "authors": ["Hamin Koo", "Minseon Kim", "Jaehyung Kim"], "title": "Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges", "categories": ["cs.AI"], "comment": "under review, 28 pages", "summary": "Identifying the vulnerabilities of large language models (LLMs) is crucial\nfor improving their safety by addressing inherent weaknesses. Jailbreaks, in\nwhich adversaries bypass safeguards with crafted input prompts, play a central\nrole in red-teaming by probing LLMs to elicit unintended or unsafe behaviors.\nRecent optimization-based jailbreak approaches iteratively refine attack\nprompts by leveraging LLMs. However, they often rely heavily on either binary\nattack success rate (ASR) signals, which are sparse, or manually crafted\nscoring templates, which introduce human bias and uncertainty in the scoring\noutcomes. To address these limitations, we introduce AMIS (Align to MISalign),\na meta-optimization framework that jointly evolves jailbreak prompts and\nscoring templates through a bi-level structure. In the inner loop, prompts are\nrefined using fine-grained and dense feedback using a fixed scoring template.\nIn the outer loop, the template is optimized using an ASR alignment score,\ngradually evolving to better reflect true attack outcomes across queries. This\nco-optimization process yields progressively stronger jailbreak prompts and\nmore calibrated scoring signals. Evaluations on AdvBench and JBB-Behaviors\ndemonstrate that AMIS achieves state-of-the-art performance, including 88.0%\nASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming\nexisting baselines by substantial margins.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAMIS\u5143\u4f18\u5316\u6846\u67b6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u653b\u51fb\u6548\u679c\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u8d85\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4f18\u5316\u7684\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\u4f9d\u8d56\u7a00\u758f\u7684\u4e8c\u5143\u653b\u51fb\u6210\u529f\u7387\u4fe1\u53f7\u6216\u5e26\u4eba\u4e3a\u504f\u5dee\u7684\u624b\u52a8\u8bc4\u5206\u6a21\u677f\uff0c\u6709\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165AMIS\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5c42\u7ed3\u6784\u8054\u5408\u8fdb\u5316\u8d8a\u72f1\u63d0\u793a\u548c\u8bc4\u5206\u6a21\u677f\uff0c\u5185\u5faa\u73af\u7528\u56fa\u5b9a\u6a21\u677f\u7ec6\u5316\u63d0\u793a\uff0c\u5916\u5faa\u73af\u7528\u653b\u51fb\u6210\u529f\u7387\u5bf9\u9f50\u5206\u6570\u4f18\u5316\u6a21\u677f\u3002", "result": "\u5728AdvBench\u548cJBB - Behaviors\u4e0a\u8bc4\u4f30\uff0cAMIS\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5982\u5728Claude - 3.5 - Haiku\u4e0a\u653b\u51fb\u6210\u529f\u7387\u8fbe88.0%\uff0c\u5728Claude - 4 - Sonnet\u4e0a\u8fbe100.0%\u3002", "conclusion": "AMIS\u6846\u67b6\u80fd\u4ea7\u751f\u66f4\u5f3a\u7684\u8d8a\u72f1\u63d0\u793a\u548c\u66f4\u51c6\u786e\u7684\u8bc4\u5206\u4fe1\u53f7\uff0c\u6027\u80fd\u8fdc\u8d85\u73b0\u6709\u57fa\u7ebf\u3002"}}
{"id": "2511.00371", "pdf": "https://arxiv.org/pdf/2511.00371", "abs": "https://arxiv.org/abs/2511.00371", "authors": ["Erfan Al-Hossami", "Razvan Bunescu"], "title": "Reasoning Trajectories for Socratic Debugging of Student Code: From Misconceptions to Contradictions and Updated Beliefs", "categories": ["cs.CL", "cs.CY", "cs.SE"], "comment": "25 pages, 2 tables, 13 figures", "summary": "In Socratic debugging, instructors guide students towards identifying and\nfixing a bug on their own, instead of providing the bug fix directly. Most\nnovice programmer bugs are caused by programming misconceptions, namely false\nbeliefs about a programming concept. In this context, Socratic debugging can be\nformulated as a guided Reasoning Trajectory (RT) leading to a statement about\nthe program behavior that contradicts the bug-causing misconception. Upon\nreaching this statement, the ensuing cognitive dissonance leads the student to\nfirst identify and then update their false belief. In this paper, we introduce\nthe task of reasoning trajectory generation, together with a dataset of\ndebugging problems manually annotated with RTs. We then describe LLM-based\nsolutions for generating RTs and Socratic conversations that are anchored on\nthem. A large-scale LLM-as-judge evaluation shows that frontier models can\ngenerate up to 91% correct reasoning trajectories and 98.7% valid conversation\nturns.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u63a8\u7406\u8f68\u8ff9\u751f\u6210\u4efb\u52a1\u53ca\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u80fd\u751f\u6210\u9ad8\u6bd4\u4f8b\u6b63\u786e\u8f68\u8ff9\u548c\u6709\u6548\u5bf9\u8bdd\u8f6e\u6b21\u3002", "motivation": "\u89e3\u51b3\u82cf\u683c\u62c9\u5e95\u5f0f\u8c03\u8bd5\u4e2d\u5f15\u5bfc\u5b66\u751f\u8bc6\u522b\u548c\u4fee\u6b63\u7f16\u7a0b\u9519\u8bef\u7684\u95ee\u9898\uff0c\u9488\u5bf9\u7f16\u7a0b\u8bef\u89e3\u5bfc\u81f4\u7684\u65b0\u624b\u7f16\u7a0b\u9519\u8bef\u3002", "method": "\u5f15\u5165\u63a8\u7406\u8f68\u8ff9\u751f\u6210\u4efb\u52a1\uff0c\u521b\u5efa\u624b\u52a8\u6807\u6ce8\u63a8\u7406\u8f68\u8ff9\u7684\u8c03\u8bd5\u95ee\u9898\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u63a8\u7406\u8f68\u8ff9\u548c\u57fa\u4e8e\u6b64\u7684\u82cf\u683c\u62c9\u5e95\u5f0f\u5bf9\u8bdd\u3002", "result": "\u5927\u89c4\u6a21\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u663e\u793a\u80fd\u751f\u6210\u9ad8\u8fbe91%\u7684\u6b63\u786e\u63a8\u7406\u8f68\u8ff9\u548c98.7%\u7684\u6709\u6548\u5bf9\u8bdd\u8f6e\u6b21\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8f68\u8ff9\u751f\u6210\u548c\u82cf\u683c\u62c9\u5e95\u5f0f\u5bf9\u8bdd\u751f\u6210\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u53ef\u7528\u4e8e\u8f85\u52a9\u82cf\u683c\u62c9\u5e95\u5f0f\u8c03\u8bd5\u3002"}}
{"id": "2511.00130", "pdf": "https://arxiv.org/pdf/2511.00130", "abs": "https://arxiv.org/abs/2511.00130", "authors": ["Bernd Bohnet", "Rumen Dangovski", "Kevin Swersky", "Sherry Moore", "Arslan Chaudhry", "Kathleen Kenealy", "Noah Fiedel"], "title": "A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios", "categories": ["cs.LG"], "comment": null, "summary": "The remarkable capabilities of Large Language Models (LLMs) often need to be\ntailored for specific applications, requiring the integration of new knowledge\nor the acquisition of new skills. While full fine-tuning is a powerful\nadaptation method, it is computationally expensive and can lead to a\ndegradation of general reasoning abilities, a phenomenon known as catastrophic\nforgetting. A range of alternative techniques exists, each with its own\ntrade-offs. In-Context Learning (ICL) is fast but limited by context length,\nwhile Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation\n(LoRA) offer a middle ground by minimizing parameter changes. However, the\nchallenge of catastrophic forgetting persists, raising questions about the best\nadaptation strategy for a given task. This paper presents a comparative\nanalysis of Supervised Finetuning (SFT), LoRA, and ICL in data-scarce\nscenarios. We find that LoRA provides the most effective balance, successfully\ninstilling new skills with minimal impact on the base model's general\nknowledge. In contrast, while SFT excels at skill acquisition, it is highly\nsusceptible to catastrophic forgetting. ICL is effective for incorporating\nfactual knowledge but struggles with complex skills. Our findings offer a\npractical framework for selecting an LLM adaptation strategy. We highlight the\ncritical distinction between skill acquisition and knowledge integration,\nclarify the trade-offs between task-specific performance and the preservation\nof general capabilities.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684SFT\u3001LoRA\u548cICL\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u53d1\u73b0LoRA\u5728\u65b0\u6280\u80fd\u6ce8\u5165\u548c\u4fdd\u7559\u57fa\u7840\u6a21\u578b\u901a\u7528\u77e5\u8bc6\u95f4\u5e73\u8861\u6700\u4f73\uff0c\u7814\u7a76\u4e3a\u9009\u62e9\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u7b56\u7565\u63d0\u4f9b\u6846\u67b6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9700\u4e3a\u7279\u5b9a\u5e94\u7528\u5b9a\u5236\uff0c\u4f46\u5168\u91cf\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4f1a\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\uff0c\u73b0\u6709\u66ff\u4ee3\u6280\u672f\u5404\u6709\u4f18\u52a3\uff0c\u9700\u627e\u5230\u7ed9\u5b9a\u4efb\u52a1\u7684\u6700\u4f73\u9002\u914d\u7b56\u7565\u3002", "method": "\u5bf9\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684Supervised Finetuning (SFT)\u3001Low - Rank Adaptation (LoRA)\u548cIn - Context Learning (ICL)\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "LoRA\u80fd\u5728\u6ce8\u5165\u65b0\u6280\u80fd\u65f6\u5bf9\u57fa\u7840\u6a21\u578b\u901a\u7528\u77e5\u8bc6\u5f71\u54cd\u6700\u5c0f\uff1bSFT\u64c5\u957f\u6280\u80fd\u83b7\u53d6\u4f46\u6613\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\uff1bICL\u5728\u6574\u5408\u4e8b\u5b9e\u77e5\u8bc6\u6709\u6548\uff0c\u4f46\u5904\u7406\u590d\u6742\u6280\u80fd\u6709\u56f0\u96be\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9009\u62e9\u5927\u8bed\u8a00\u6a21\u578b\u9002\u914d\u7b56\u7565\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\uff0c\u5f3a\u8c03\u6280\u80fd\u83b7\u53d6\u548c\u77e5\u8bc6\u6574\u5408\u533a\u522b\uff0c\u660e\u786e\u7279\u5b9a\u4efb\u52a1\u6027\u80fd\u548c\u4fdd\u7559\u901a\u7528\u80fd\u529b\u7684\u6743\u8861\u3002"}}
{"id": "2511.01396", "pdf": "https://arxiv.org/pdf/2511.01396", "abs": "https://arxiv.org/abs/2511.01396", "authors": ["Cl\u00e9ment Yvernes", "Emilie Devijver", "Ad\u00e8le H. Ribeiro", "Marianne Clausel--Lesourd", "\u00c9ric Gaussier"], "title": "Relaxing partition admissibility in Cluster-DAGs: a causal calculus with arbitrary variable clustering", "categories": ["cs.AI", "stat.ME"], "comment": "Accepted at The Thirty-ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS2025)", "summary": "Cluster DAGs (C-DAGs) provide an abstraction of causal graphs in which nodes\nrepresent clusters of variables, and edges encode both cluster-level causal\nrelationships and dependencies arisen from unobserved confounding. C-DAGs\ndefine an equivalence class of acyclic causal graphs that agree on\ncluster-level relationships, enabling causal reasoning at a higher level of\nabstraction. However, when the chosen clustering induces cycles in the\nresulting C-DAG, the partition is deemed inadmissible under conventional C-DAG\nsemantics. In this work, we extend the C-DAG framework to support arbitrary\nvariable clusterings by relaxing the partition admissibility constraint,\nthereby allowing cyclic C-DAG representations. We extend the notions of\nd-separation and causal calculus to this setting, significantly broadening the\nscope of causal reasoning across clusters and enabling the application of\nC-DAGs in previously intractable scenarios. Our calculus is both sound and\natomically complete with respect to the do-calculus: all valid interventional\nqueries at the cluster level can be derived using our rules, each corresponding\nto a primitive do-calculus step.", "AI": {"tldr": "\u6587\u7ae0\u6269\u5c55C - DAG\u6846\u67b6\u4ee5\u652f\u6301\u4efb\u610f\u53d8\u91cf\u805a\u7c7b\uff0c\u653e\u5bbd\u5206\u533a\u53ef\u63a5\u53d7\u6027\u7ea6\u675f\uff0c\u6269\u5c55d - \u5206\u79bb\u548c\u56e0\u679c\u6f14\u7b97\u6982\u5ff5\uff0c\u5176\u6f14\u7b97\u5728do - \u6f14\u7b97\u65b9\u9762\u5065\u5168\u4e14\u539f\u5b50\u5b8c\u5907\u3002", "motivation": "\u4f20\u7edfC - DAG\u8bed\u4e49\u4e0b\uff0c\u6240\u9009\u805a\u7c7b\u82e5\u5bfc\u81f4C - DAG\u51fa\u73b0\u5faa\u73af\u5219\u5206\u533a\u4e0d\u53ef\u63a5\u53d7\uff0c\u9700\u6269\u5c55\u6846\u67b6\u652f\u6301\u4efb\u610f\u53d8\u91cf\u805a\u7c7b\u3002", "method": "\u653e\u5bbd\u5206\u533a\u53ef\u63a5\u53d7\u6027\u7ea6\u675f\uff0c\u5c06C - DAG\u6846\u67b6\u6269\u5c55\u4ee5\u652f\u6301\u4efb\u610f\u53d8\u91cf\u805a\u7c7b\uff0c\u5e76\u5c06d - \u5206\u79bb\u548c\u56e0\u679c\u6f14\u7b97\u6982\u5ff5\u6269\u5c55\u5230\u8be5\u8bbe\u7f6e\u3002", "result": "\u6269\u5c55\u540e\u7684\u6846\u67b6\u80fd\u663e\u8457\u62d3\u5bbd\u8de8\u805a\u7c7b\u7684\u56e0\u679c\u63a8\u7406\u8303\u56f4\uff0c\u4f7fC - DAG\u53ef\u5e94\u7528\u4e8e\u5148\u524d\u96be\u5904\u7406\u7684\u573a\u666f\uff0c\u4e14\u6f14\u7b97\u5728do - \u6f14\u7b97\u65b9\u9762\u5065\u5168\u4e14\u539f\u5b50\u5b8c\u5907\u3002", "conclusion": "\u6269\u5c55\u540e\u7684C - DAG\u6846\u67b6\u80fd\u6709\u6548\u652f\u6301\u4efb\u610f\u53d8\u91cf\u805a\u7c7b\uff0c\u4e3a\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u53ef\u80fd\u3002"}}
{"id": "2511.00407", "pdf": "https://arxiv.org/pdf/2511.00407", "abs": "https://arxiv.org/abs/2511.00407", "authors": ["\u0141ukasz Sikorski", "Jacek Matulewski"], "title": "Reducing students' misconceptions about video game development. A mixed-method study", "categories": ["cs.HC", "cs.CY", "cs.SE"], "comment": null, "summary": "This study examines students' na\\\"ive mindset (misconceptions) about video\ngame development, idealized and inaccurate beliefs that shape an unrealistic\nunderstanding of the field. The research evaluated the effectiveness of a\nfifteen-hour-long lecture series delivered by industry professionals, designed\nto challenge this mindset and expose students to the complexities and realities\nof game production. A mixed-methods approach was employed, combining\nqualitative analysis with a prototype quantitative tool developed to measure\nlevels of misconception. Participants included students (n = 91) from diverse\nacademic backgrounds interested in game creation and professionals (n = 94)\nworking in the video game industry. Findings show that the intervention\nsignificantly reduced students' na\\\"ive beliefs while enhancing their\nmotivation to pursue careers in the industry. Exposure to professional\nperspectives fostered a more realistic and informed mindset, taking into\naccount the understanding of the technical, collaborative, and business aspects\nof game development. The results suggest that incorporating similar expert-led\ninterventions early in game development education can improve learning\noutcomes, support informed career choices, and mitigate future professional\ndisappointment.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u884c\u4e1a\u4e13\u5bb6\u8bb2\u5ea7\u5bf9\u6539\u53d8\u5b66\u751f\u6e38\u620f\u5f00\u53d1\u9519\u8bef\u89c2\u5ff5\u7684\u6548\u679c\uff0c\u53d1\u73b0\u80fd\u51cf\u5c11\u9519\u8bef\u89c2\u5ff5\u3001\u63d0\u5347\u4ece\u4e1a\u52a8\u529b\uff0c\u5efa\u8bae\u5728\u6559\u80b2\u4e2d\u7eb3\u5165\u7c7b\u4f3c\u5e72\u9884\u3002", "motivation": "\u7814\u7a76\u5b66\u751f\u5bf9\u6e38\u620f\u5f00\u53d1\u7684\u9519\u8bef\u89c2\u5ff5\uff0c\u8bc4\u4f30\u8bb2\u5ea7\u7ea0\u6b63\u9519\u8bef\u89c2\u5ff5\u7684\u6548\u679c\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7814\u7a76\u65b9\u6cd5\uff0c\u7ed3\u5408\u5b9a\u6027\u5206\u6790\u4e0e\u81ea\u5236\u5b9a\u91cf\u5de5\u5177\uff0c\u7814\u7a7691\u540d\u5b66\u751f\u548c94\u540d\u4e13\u4e1a\u4eba\u58eb\u3002", "result": "\u8bb2\u5ea7\u663e\u8457\u51cf\u5c11\u5b66\u751f\u9519\u8bef\u89c2\u5ff5\uff0c\u63d0\u5347\u4ece\u4e1a\u52a8\u529b\uff0c\u57f9\u517b\u66f4\u73b0\u5b9e\u7406\u667a\u7684\u601d\u7ef4\u3002", "conclusion": "\u5728\u6e38\u620f\u5f00\u53d1\u6559\u80b2\u65e9\u671f\u7eb3\u5165\u4e13\u5bb6\u5e72\u9884\u53ef\u6539\u5584\u5b66\u4e60\u6210\u679c\u3001\u52a9\u529b\u804c\u4e1a\u9009\u62e9\u3001\u51cf\u5c11\u804c\u4e1a\u5931\u671b\u3002"}}
{"id": "2511.00133", "pdf": "https://arxiv.org/pdf/2511.00133", "abs": "https://arxiv.org/abs/2511.00133", "authors": ["Kowshik Balasubramanian", "Andre Williams", "Ismail Butun"], "title": "Feature Importance Guided Random Forest Learning with Simulated Annealing Based Hyperparameter Tuning", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 2 figures, 3 tables, submitted to IEEE Intelligent Systems\n  journal", "summary": "This paper introduces a novel framework for enhancing Random Forest\nclassifiers by integrating probabilistic feature sampling and hyperparameter\ntuning via Simulated Annealing. The proposed framework exhibits substantial\nadvancements in predictive accuracy and generalization, adeptly tackling the\nmultifaceted challenges of robust classification across diverse domains,\nincluding credit risk evaluation, anomaly detection in IoT ecosystems,\nearly-stage medical diagnostics, and high-dimensional biological data analysis.\nTo overcome the limitations of conventional Random Forests, we present an\napproach that places stronger emphasis on capturing the most relevant signals\nfrom data while enabling adaptive hyperparameter configuration. The model is\nguided towards features that contribute more meaningfully to classification and\noptimizing this with dynamic parameter tuning. The results demonstrate\nconsistent accuracy improvements and meaningful insights into feature\nrelevance, showcasing the efficacy of combining importance aware sampling and\nmetaheuristic optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u6982\u7387\u7279\u5f81\u91c7\u6837\u548c\u6a21\u62df\u9000\u706b\u8d85\u53c2\u6570\u8c03\u4f18\u589e\u5f3a\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u7684\u6846\u67b6\uff0c\u5728\u591a\u9886\u57df\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u968f\u673a\u68ee\u6797\u7684\u5c40\u9650\u6027\uff0c\u89e3\u51b3\u591a\u9886\u57df\u9c81\u68d2\u5206\u7c7b\u7684\u6311\u6218\u3002", "method": "\u96c6\u6210\u6982\u7387\u7279\u5f81\u91c7\u6837\u548c\u901a\u8fc7\u6a21\u62df\u9000\u706b\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u4f18\uff0c\u5f3a\u8c03\u6355\u6349\u6570\u636e\u76f8\u5173\u4fe1\u53f7\u548c\u81ea\u9002\u5e94\u8d85\u53c2\u6570\u914d\u7f6e\u3002", "result": "\u6a21\u578b\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u6709\u6301\u7eed\u63d0\u5347\uff0c\u80fd\u6d1e\u5bdf\u7279\u5f81\u76f8\u5173\u6027\u3002", "conclusion": "\u7ed3\u5408\u91cd\u8981\u6027\u611f\u77e5\u91c7\u6837\u548c\u5143\u542f\u53d1\u5f0f\u4f18\u5316\u7684\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2511.01415", "pdf": "https://arxiv.org/pdf/2511.01415", "abs": "https://arxiv.org/abs/2511.01415", "authors": ["Amrapali Pednekar", "\u00c1lvaro Garrido-P\u00e9rez", "Yara Khaluf", "Pieter Simoens"], "title": "Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm", "categories": ["cs.AI"], "comment": "Accepted at CogInterp workshop @ NeurIPS 2025", "summary": "This study explores the interference in temporal processing within a\ndual-task paradigm from an artificial intelligence (AI) perspective. In this\ncontext, the dual-task setup is implemented as a simplified version of the\nOvercooked environment with two variations, single task (T) and dual task\n(T+N). Both variations involve an embedded time production task, but the dual\ntask (T+N) additionally involves a concurrent number comparison task. Two deep\nreinforcement learning (DRL) agents were separately trained for each of these\ntasks. These agents exhibited emergent behavior consistent with human timing\nresearch. Specifically, the dual task (T+N) agent exhibited significant\noverproduction of time relative to its single task (T) counterpart. This result\nwas consistent across four target durations. Preliminary analysis of neural\ndynamics in the agents' LSTM layers did not reveal any clear evidence of a\ndedicated or intrinsic timer. Hence, further investigation is needed to better\nunderstand the underlying time-keeping mechanisms of the agents and to provide\ninsights into the observed behavioral patterns. This study is a small step\ntowards exploring parallels between emergent DRL behavior and behavior observed\nin biological systems in order to facilitate a better understanding of both.", "AI": {"tldr": "\u7814\u7a76\u4eceAI\u89c6\u89d2\u63a2\u7d22\u53cc\u4efb\u52a1\u8303\u5f0f\u4e0b\u65f6\u95f4\u5904\u7406\u7684\u5e72\u6270\uff0c\u8bad\u7ec3DRL\u667a\u80fd\u4f53\uff0c\u53d1\u73b0\u53cc\u4efb\u52a1\u667a\u80fd\u4f53\u65f6\u95f4\u8fc7\u5ea6\u751f\u6210\uff0c\u672a\u53d1\u73b0\u660e\u786e\u8ba1\u65f6\u5668\u8bc1\u636e\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u4eceAI\u89c6\u89d2\u63a2\u7d22\u53cc\u4efb\u52a1\u8303\u5f0f\u4e0b\u65f6\u95f4\u5904\u7406\u7684\u5e72\u6270\uff0c\u63a2\u7d22DRL\u6d8c\u73b0\u884c\u4e3a\u4e0e\u751f\u7269\u7cfb\u7edf\u884c\u4e3a\u7684\u76f8\u4f3c\u6027\u4ee5\u4fc3\u8fdb\u5bf9\u4e24\u8005\u7684\u7406\u89e3\u3002", "method": "\u91c7\u7528\u7b80\u5316\u7684Overcooked\u73af\u5883\u7684\u53cc\u4efb\u52a1\u8bbe\u7f6e\uff0c\u5206\u5355\u4efb\u52a1\uff08T\uff09\u548c\u53cc\u4efb\u52a1\uff08T+N\uff09\uff0c\u5206\u522b\u8bad\u7ec3\u4e24\u4e2aDRL\u667a\u80fd\u4f53\u3002", "result": "\u53cc\u4efb\u52a1\uff08T+N\uff09\u667a\u80fd\u4f53\u76f8\u6bd4\u5355\u4efb\u52a1\uff08T\uff09\u667a\u80fd\u4f53\u51fa\u73b0\u660e\u663e\u7684\u65f6\u95f4\u8fc7\u5ea6\u751f\u6210\uff0c\u8be5\u7ed3\u679c\u5728\u56db\u4e2a\u76ee\u6807\u65f6\u957f\u4e0a\u4e00\u81f4\uff1b\u5bf9\u667a\u80fd\u4f53LSTM\u5c42\u795e\u7ecf\u52a8\u529b\u5b66\u7684\u521d\u6b65\u5206\u6790\u672a\u53d1\u73b0\u4e13\u7528\u6216\u5185\u5728\u8ba1\u65f6\u5668\u7684\u660e\u786e\u8bc1\u636e\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u66f4\u597d\u7406\u89e3\u667a\u80fd\u4f53\u6f5c\u5728\u7684\u8ba1\u65f6\u673a\u5236\uff0c\u4e3a\u89c2\u5bdf\u5230\u7684\u884c\u4e3a\u6a21\u5f0f\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2511.00628", "pdf": "https://arxiv.org/pdf/2511.00628", "abs": "https://arxiv.org/abs/2511.00628", "authors": ["Yang Li", "Siqi Ping", "Xiyu Chen", "Xiaojian Qi", "Zigan Wang", "Ye Luo", "Xiaowei Zhang"], "title": "AgentGit: A Version Control Framework for Reliable and Scalable LLM-Powered Multi-Agent Systems", "categories": ["cs.MA", "cs.AI", "cs.SE"], "comment": null, "summary": "With the rapid progress of large language models (LLMs), LLM-powered\nmulti-agent systems (MAS) are drawing increasing interest across academia and\nindustry. However, many current MAS frameworks struggle with reliability and\nscalability, especially on complex tasks. We present AgentGit, a framework that\nbrings Git-like rollback and branching to MAS workflows. Built as an\ninfrastructure layer on top of LangGraph, AgentGit supports state commit,\nrevert, and branching, allowing agents to traverse, compare, and explore\nmultiple trajectories efficiently. To evaluate AgentGit, we designed an\nexperiment that optimizes target agents by selecting better prompts. We ran a\nmulti-step A/B test against three baselines -- LangGraph, AutoGen, and Agno --\non a real-world task: retrieving and analyzing paper abstracts. Results show\nthat AgentGit significantly reduces redundant computation, lowers runtime and\ntoken usage, and supports parallel exploration across multiple branches,\nenhancing both reliability and scalability in MAS development. This work offers\na practical path to more robust MAS design and enables error recovery, safe\nexploration, iterative debugging, and A/B testing in collaborative AI systems.", "AI": {"tldr": "\u63d0\u51faAgentGit\u6846\u67b6\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5de5\u4f5c\u6d41\u5f15\u5165\u7c7bGit\u529f\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u53ef\u589e\u5f3a\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u5b58\u5728\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u6784\u5efa\u57fa\u4e8eLangGraph\u7684AgentGit\u6846\u67b6\uff0c\u652f\u6301\u72b6\u6001\u63d0\u4ea4\u3001\u56de\u6eda\u548c\u5206\u652f\u64cd\u4f5c\uff1b\u8bbe\u8ba1\u901a\u8fc7\u9009\u62e9\u66f4\u597d\u63d0\u793a\u4f18\u5316\u76ee\u6807\u667a\u80fd\u4f53\u7684\u5b9e\u9a8c\uff0c\u8fdb\u884c\u591a\u6b65A/B\u6d4b\u8bd5\u3002", "result": "AgentGit\u663e\u8457\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff0c\u964d\u4f4e\u8fd0\u884c\u65f6\u95f4\u548c\u4ee4\u724c\u4f7f\u7528\u91cf\uff0c\u652f\u6301\u591a\u5206\u652f\u5e76\u884c\u63a2\u7d22\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u66f4\u5f3a\u5927\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u652f\u6301\u534f\u4f5c\u5f0f\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u9519\u8bef\u6062\u590d\u3001\u5b89\u5168\u63a2\u7d22\u3001\u8fed\u4ee3\u8c03\u8bd5\u548cA/B\u6d4b\u8bd5\u3002"}}
{"id": "2511.00134", "pdf": "https://arxiv.org/pdf/2511.00134", "abs": "https://arxiv.org/abs/2511.00134", "authors": ["Angana Borah", "Adrija Datta", "Ashish S. Kumar", "Raviraj Dave", "Udit Bhatia"], "title": "Physiologically Active Vegetation Reverses Its Cooling Effect in Humid Urban Climates", "categories": ["cs.LG"], "comment": "27 pages, 5 figures", "summary": "Efforts to green cities for cooling are succeeding unevenly because the same\nvegetation that cools surfaces can also intensify how hot the air feels.\nPrevious studies have identified humid heat as a growing urban hazard, yet how\nphysiologically active vegetation governs this trade-off between cooling and\nmoisture accumulation remains poorly understood, leaving mitigation policy and\ndesign largely unguided. Here we quantify how vegetation structure and function\ninfluence the Heat Index (HI), a combined measure of temperature and humidity\nin 138 Indian cities spanning tropical savanna, semi-arid steppe, and humid\nsubtropical climates, and across dense urban cores and semi-urban rings. Using\nan extreme-aware, one kilometre reconstruction of HI and an interpretable\nmachine-learning framework that integrates SHapley Additive Explanations (SHAP)\nand Accumulated Local Effects (ALE), we isolate vegetation-climate\ninteractions. Cooling generally strengthens for EVI >= 0.4 and LAI >= 0.05, but\njoint-high regimes begin to reverse toward warming when EVI >= 0.5, LAI >= 0.2,\nand fPAR >= 0.5,with an earlier onset for fPAR >= 0.25 in humid, dense cores.\nIn such environments, highly physiologically active vegetation elevates\nnear-surface humidity faster than it removes heat, reversing its cooling effect\nand amplifying perceived heat stress. These findings establish the climatic\nlimits of vegetation-driven cooling and provide quantitative thresholds for\nclimate-specific greening strategies that promote equitable and heat-resilient\ncities.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5316\u5370\u5ea6138\u4e2a\u57ce\u5e02\u690d\u88ab\u7ed3\u6784\u548c\u529f\u80fd\u5bf9\u70ed\u6307\u6570\u7684\u5f71\u54cd\uff0c\u660e\u786e\u690d\u88ab\u964d\u6e29\u6c14\u5019\u6781\u9650\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5bf9\u690d\u88ab\u5728\u964d\u6e29\u4e0e\u6e7f\u5ea6\u7d2f\u79ef\u95f4\u6743\u8861\u673a\u5236\u4e0d\u660e\uff0c\u5bfc\u81f4\u7f13\u89e3\u653f\u7b56\u548c\u8bbe\u8ba1\u7f3a\u4e4f\u6307\u5bfc\u3002", "method": "\u91cf\u5316138\u4e2a\u5370\u5ea6\u57ce\u5e02\u690d\u88ab\u7ed3\u6784\u548c\u529f\u80fd\u5bf9\u70ed\u6307\u6570\u7684\u5f71\u54cd\uff0c\u7528\u6781\u7aef\u611f\u77e5\u3001\u4e00\u516c\u91cc\u70ed\u6307\u6570\u91cd\u5efa\u53ca\u96c6\u6210SHAP\u548cALE\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\u5206\u79bb\u690d\u88ab - \u6c14\u5019\u76f8\u4e92\u4f5c\u7528\u3002", "result": "EVI >= 0.4\u548cLAI >= 0.05\u65f6\u51b7\u5374\u589e\u5f3a\uff1bEVI >= 0.5\u3001LAI >= 0.2\u548cfPAR >= 0.5\u65f6\u9ad8\u8054\u5408\u72b6\u6001\u8f6c\u5411\u53d8\u6696\uff0c\u5728\u6f6e\u6e7f\u5bc6\u96c6\u6838\u5fc3\u533afPAR >= 0.25\u65f6\u66f4\u65e9\u51fa\u73b0\u3002\u9ad8\u751f\u7406\u6d3b\u6027\u690d\u88ab\u4f7f\u8fd1\u5730\u8868\u6e7f\u5ea6\u5347\u9ad8\u5feb\u4e8e\u6563\u70ed\u3002", "conclusion": "\u7814\u7a76\u786e\u5b9a\u690d\u88ab\u964d\u6e29\u6c14\u5019\u6781\u9650\uff0c\u4e3a\u7279\u5b9a\u6c14\u5019\u7eff\u5316\u7b56\u7565\u63d0\u4f9b\u91cf\u5316\u9608\u503c\u4ee5\u4fc3\u8fdb\u516c\u5e73\u548c\u8010\u70ed\u57ce\u5e02\u5efa\u8bbe\u3002"}}
{"id": "2511.01425", "pdf": "https://arxiv.org/pdf/2511.01425", "abs": "https://arxiv.org/abs/2511.01425", "authors": ["Yuhang Huang", "Zekai Lin", "Fan Zhong", "Lei Liu"], "title": "Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis", "categories": ["cs.AI", "cs.CV", "I.2.6; I.2.10"], "comment": "12 pages, 3 figures. Under review at the Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2026", "summary": "Explanations for AI models in high-stakes domains like medicine often lack\nverifiability, which can hinder trust. To address this, we propose an\ninteractive agent that produces explanations through an auditable sequence of\nactions. The agent learns a policy to strategically seek external visual\nevidence to support its diagnostic reasoning. This policy is optimized using\nreinforcement learning, resulting in a model that is both efficient and\ngeneralizable. Our experiments show that this action-based reasoning process\nsignificantly improves calibrated accuracy, reducing the Brier score by 18\\%\ncompared to a non-interactive baseline. To validate the faithfulness of the\nagent's explanations, we introduce a causal intervention method. By masking the\nvisual evidence the agent chooses to use, we observe a measurable degradation\nin its performance ($\\Delta$Brier=+0.029), confirming that the evidence is\nintegral to its decision-making process. Our work provides a practical\nframework for building AI systems with verifiable and faithful reasoning\ncapabilities.", "AI": {"tldr": "\u63d0\u51fa\u4ea4\u4e92\u5f0f\u4ee3\u7406\u4ea7\u751f\u53ef\u5ba1\u8ba1\u89e3\u91ca\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u63d0\u5347\u6821\u51c6\u51c6\u786e\u7387\uff0c\u8fd8\u5f15\u5165\u56e0\u679c\u5e72\u9884\u65b9\u6cd5\u9a8c\u8bc1\u89e3\u91ca\u5fe0\u5b9e\u6027\uff0c\u63d0\u4f9b\u6784\u5efa\u6709\u53ef\u9a8c\u8bc1\u548c\u5fe0\u5b9e\u63a8\u7406\u80fd\u529bAI\u7cfb\u7edf\u7684\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u9ad8\u98ce\u9669\u9886\u57dfAI\u6a21\u578b\u89e3\u91ca\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u6027\u3001\u963b\u788d\u4fe1\u4efb\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4ea4\u4e92\u5f0f\u4ee3\u7406\uff0c\u901a\u8fc7\u53ef\u5ba1\u8ba1\u7684\u52a8\u4f5c\u5e8f\u5217\u4ea7\u751f\u89e3\u91ca\uff1b\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b56\u7565\u4ee5\u5bfb\u6c42\u5916\u90e8\u89c6\u89c9\u8bc1\u636e\u652f\u6301\u8bca\u65ad\u63a8\u7406\uff1b\u5f15\u5165\u56e0\u679c\u5e72\u9884\u65b9\u6cd5\u9a8c\u8bc1\u89e3\u91ca\u5fe0\u5b9e\u6027\u3002", "result": "\u57fa\u4e8e\u52a8\u4f5c\u7684\u63a8\u7406\u8fc7\u7a0b\u663e\u8457\u63d0\u9ad8\u6821\u51c6\u51c6\u786e\u7387\uff0c\u6bd4\u975e\u4ea4\u4e92\u5f0f\u57fa\u7ebf\u964d\u4f4e18%\u7684Brier\u5206\u6570\uff1b\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u89c2\u5bdf\u5230\u6027\u80fd\u6709\u53ef\u8861\u91cf\u7684\u4e0b\u964d\uff08\u0394Brier = +0.029\uff09\u3002", "conclusion": "\u5de5\u4f5c\u4e3a\u6784\u5efa\u5177\u6709\u53ef\u9a8c\u8bc1\u548c\u5fe0\u5b9e\u63a8\u7406\u80fd\u529b\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2511.01166", "pdf": "https://arxiv.org/pdf/2511.01166", "abs": "https://arxiv.org/abs/2511.01166", "authors": ["Lingzhe Zhang", "Yunpeng Zhai", "Tong Jia", "Chiming Duan", "Minghua He", "Leyi Pan", "Zhaoyang Liu", "Bolin Ding", "Ying Li"], "title": "MicroRemed: Benchmarking LLMs in Microservices Remediation", "categories": ["cs.CL", "cs.SE", "68T50", "I.2.7"], "comment": "24 pages, 13 figures, 5 tables", "summary": "Large Language Models (LLMs) integrated with agent-based reasoning frameworks\nhave recently shown strong potential for autonomous decision-making and\nsystem-level operations. One promising yet underexplored direction is\nmicroservice remediation, where the goal is to automatically recover faulty\nmicroservice systems. Existing approaches, however, still rely on human-crafted\nprompts from Site Reliability Engineers (SREs), with LLMs merely converting\ntextual instructions into executable code. To advance research in this area, we\nintroduce MicroRemed, the first benchmark for evaluating LLMs in end-to-end\nmicroservice remediation, where models must directly generate executable\nAnsible playbooks from diagnosis reports to restore system functionality. We\nfurther propose ThinkRemed, a multi-agent framework that emulates the\nreflective and perceptive reasoning of SREs. Experimental results show that\nMicroRemed presents substantial challenges to current LLMs, while ThinkRemed\nimproves end-to-end remediation performance through iterative reasoning and\nsystem reflection. The benchmark is available at\nhttps://github.com/LLM4AIOps/MicroRemed.", "AI": {"tldr": "\u4ecb\u7ecd\u9996\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7aef\u5230\u7aef\u5fae\u670d\u52a1\u4fee\u590d\u80fd\u529b\u7684\u57fa\u51c6MicroRemed\u548c\u591a\u667a\u80fd\u4f53\u6846\u67b6ThinkRemed\uff0c\u5b9e\u9a8c\u663e\u793aMicroRemed\u6709\u6311\u6218\uff0cThinkRemed\u53ef\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5fae\u670d\u52a1\u4fee\u590d\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u7f16\u5199\u63d0\u793a\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u5c06\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u4e3a\u63a8\u52a8\u8be5\u9886\u57df\u7814\u7a76\u3002", "method": "\u5f15\u5165MicroRemed\u57fa\u51c6\uff0c\u63d0\u51faThinkRemed\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002", "result": "MicroRemed\u5bf9\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u6784\u6210\u91cd\u5927\u6311\u6218\uff0cThinkRemed\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406\u548c\u7cfb\u7edf\u53cd\u601d\u63d0\u9ad8\u7aef\u5230\u7aef\u4fee\u590d\u6027\u80fd\u3002", "conclusion": "MicroRemed\u548cThinkRemed\u5728\u5fae\u670d\u52a1\u4fee\u590d\u7814\u7a76\u4e2d\u6709\u91cd\u8981\u610f\u4e49\uff0c\u57fa\u51c6\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.00136", "pdf": "https://arxiv.org/pdf/2511.00136", "abs": "https://arxiv.org/abs/2511.00136", "authors": ["Qing Guo", "Xinhang Li", "Junyu Chen", "Zheng Guo", "Xiaocong Li", "Lin Zhang", "Lei Li"], "title": "A Dual Large Language Models Architecture with Herald Guided Prompts for Parallel Fine Grained Traffic Signal Control", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Leveraging large language models (LLMs) in traffic signal control (TSC)\nimproves optimization efficiency and interpretability compared to traditional\nreinforcement learning (RL) methods. However, existing LLM-based approaches are\nlimited by fixed time signal durations and are prone to hallucination errors,\nwhile RL methods lack robustness in signal timing decisions and suffer from\npoor generalization. To address these challenges, this paper proposes\nHeraldLight, a dual LLMs architecture enhanced by Herald guided prompts. The\nHerald Module extracts contextual information and forecasts queue lengths for\neach traffic phase based on real-time conditions. The first LLM, LLM-Agent,\nuses these forecasts to make fine grained traffic signal control, while the\nsecond LLM, LLM-Critic, refines LLM-Agent's outputs, correcting errors and\nhallucinations. These refined outputs are used for score-based fine-tuning to\nimprove accuracy and robustness. Simulation experiments using CityFlow on real\nworld datasets covering 224 intersections in Jinan (12), Hangzhou (16), and New\nYork (196) demonstrate that HeraldLight outperforms state of the art baselines,\nachieving a 20.03% reduction in average travel time across all scenarios and a\n10.74% reduction in average queue length on the Jinan and Hangzhou scenarios.\nThe source code is available on GitHub:\nhttps://github.com/BUPT-ANTlab/HeraldLight.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faHeraldLight\u89e3\u51b3\u73b0\u6709TSC\u65b9\u6cd5\u95ee\u9898\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684TSC\u65b9\u6cd5\u6709\u56fa\u5b9a\u65f6\u957f\u548c\u5e7b\u89c9\u8bef\u5dee\u95ee\u9898\uff0cRL\u65b9\u6cd5\u7f3a\u4e4f\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002", "method": "\u63d0\u51faHeraldLight\uff0c\u542bHerald\u6a21\u5757\u53ca\u53ccLLM\u67b6\u6784\uff0c\u7528\u7ec6\u5316\u8f93\u51fa\u8fdb\u884c\u57fa\u4e8e\u5206\u6570\u7684\u5fae\u8c03\u3002", "result": "\u5728CityFlow\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0cHeraldLight\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e73\u5747\u65c5\u884c\u65f6\u95f4\u964d20.03%\uff0c\u6d4e\u5357\u548c\u676d\u5dde\u573a\u666f\u5e73\u5747\u961f\u5217\u957f\u5ea6\u964d10.74%\u3002", "conclusion": "HeraldLight\u6709\u6548\u89e3\u51b3\u73b0\u6709TSC\u65b9\u6cd5\u95ee\u9898\uff0c\u63d0\u5347\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u6027\u80fd\u3002"}}
{"id": "2511.01444", "pdf": "https://arxiv.org/pdf/2511.01444", "abs": "https://arxiv.org/abs/2511.01444", "authors": ["Huiting Huang", "Tieliang Gong", "Kai He", "Jialun Wu", "Erik Cambria", "Mengling Feng"], "title": "Robust Multimodal Sentiment Analysis via Double Information Bottleneck", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal sentiment analysis has received significant attention across\ndiverse research domains. Despite advancements in algorithm design, existing\napproaches suffer from two critical limitations: insufficient learning of\nnoise-contaminated unimodal data, leading to corrupted cross-modal\ninteractions, and inadequate fusion of multimodal representations, resulting in\ndiscarding discriminative unimodal information while retaining multimodal\nredundant information. To address these challenges, this paper proposes a\nDouble Information Bottleneck (DIB) strategy to obtain a powerful, unified\ncompact multimodal representation. Implemented within the framework of low-rank\nRenyi's entropy functional, DIB offers enhanced robustness against diverse\nnoise sources and computational tractability for high-dimensional data, as\ncompared to the conventional Shannon entropy-based methods. The DIB comprises\ntwo key modules: 1) learning a sufficient and compressed representation of\nindividual unimodal data by maximizing the task-relevant information and\ndiscarding the superfluous information, and 2) ensuring the discriminative\nability of multimodal representation through a novel attention bottleneck\nfusion mechanism. Consequently, DIB yields a multimodal representation that\neffectively filters out noisy information from unimodal data while capturing\ninter-modal complementarity. Extensive experiments on CMU-MOSI, CMU-MOSEI,\nCH-SIMS, and MVSA-Single validate the effectiveness of our method. The model\nachieves 47.4% accuracy under the Acc-7 metric on CMU-MOSI and 81.63% F1-score\non CH-SIMS, outperforming the second-best baseline by 1.19%. Under noise, it\nshows only 0.36% and 0.29% performance degradation on CMU-MOSI and CMU-MOSEI\nrespectively.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u53cc\u4fe1\u606f\u74f6\u9888\uff08DIB\uff09\u7b56\u7565\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u95ee\u9898\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u5355\u6a21\u6001\u6570\u636e\u5b66\u4e60\u4e0d\u8db3\u548c\u591a\u6a21\u6001\u8868\u5f81\u878d\u5408\u4e0d\u5145\u5206\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faDIB\u7b56\u7565\uff0c\u5728\u4f4e\u79e9Renyi\u71b5\u6cdb\u51fd\u6846\u67b6\u4e0b\u5b9e\u73b0\uff0c\u5305\u542b\u5b66\u4e60\u5355\u6a21\u6001\u5145\u5206\u538b\u7f29\u8868\u5f81\u548c\u91c7\u7528\u6ce8\u610f\u529b\u74f6\u9888\u878d\u5408\u673a\u5236\u4e24\u4e2a\u6a21\u5757\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5982\u5728CMU - MOSI\u4e0aAcc - 7\u6307\u6807\u8fbe47.4%\u51c6\u786e\u7387\uff0c\u5728CH - SIMS\u4e0aF1\u5206\u6570\u8fbe81.63%\uff0c\u4f18\u4e8e\u6b21\u4f18\u57fa\u7ebf\uff1b\u5728\u566a\u58f0\u4e0b\u6027\u80fd\u4e0b\u964d\u5c0f\u3002", "conclusion": "DIB\u7b56\u7565\u80fd\u6709\u6548\u8fc7\u6ee4\u5355\u6a21\u6001\u6570\u636e\u4e2d\u7684\u566a\u58f0\u4fe1\u606f\uff0c\u6355\u6349\u6a21\u6001\u95f4\u4e92\u8865\u6027\uff0c\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2511.01180", "pdf": "https://arxiv.org/pdf/2511.01180", "abs": "https://arxiv.org/abs/2511.01180", "authors": ["Jingyi Shi", "Yufeng Chen", "Yang Xiao", "Yuekang Li", "Zhengzi Xu", "Sihao Qiu", "Chi Zhang", "Keyu Qi", "Yeting Li", "Xingchu Chen", "Yanyan Zou", "Yang Liu", "Wei Huo"], "title": "A Large Scale Study of AI-based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners", "categories": ["cs.CR", "cs.SE"], "comment": "Accepted by ASE 2025", "summary": "Binary Function Similarity Detection (BFSD) is a foundational technique in\nsoftware security, underpinning a wide range of applications including\nvulnerability detection, malware analysis. Recent advances in AI-based BFSD\ntools have led to significant performance improvements. However, existing\nevaluations of these tools suffer from three key limitations: a lack of\nin-depth analysis of performance-influencing factors, an absence of realistic\napplication analysis, and reliance on small-scale or low-quality datasets.\n  In this paper, we present the first large-scale empirical study of AI-based\nBFSD tools to address these gaps. We construct two high-quality and diverse\ndatasets: BinAtlas, comprising 12,453 binaries and over 7 million functions for\ncapability evaluation; and BinAres, containing 12,291 binaries and 54\nreal-world 1-day vulnerabilities for evaluating vulnerability detection\nperformance in practical IoT firmware settings. Using these datasets, we\nevaluate nine representative BFSD tools, analyze the challenges and limitations\nof existing BFSD tools, and investigate the consistency among BFSD tools. We\nalso propose an actionable strategy for combining BFSD tools to enhance overall\nperformance (an improvement of 13.4%). Our study not only advances the\npractical adoption of BFSD tools but also provides valuable resources and\ninsights to guide future research in scalable and automated binary similarity\ndetection.", "AI": {"tldr": "\u6587\u7ae0\u5f00\u5c55AI-based BFSD\u5de5\u5177\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u6784\u5efa\u4e24\u4e2a\u6570\u636e\u96c6\u8bc4\u4f30\u5de5\u5177\uff0c\u5206\u6790\u95ee\u9898\uff0c\u63d0\u51fa\u7ec4\u5408\u7b56\u7565\u63d0\u5347\u6027\u80fd\uff0c\u63a8\u52a8\u5de5\u5177\u5e94\u7528\u548c\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u73b0\u6709AI-based BFSD\u5de5\u5177\u8bc4\u4f30\u5b58\u5728\u5bf9\u6027\u80fd\u5f71\u54cd\u56e0\u7d20\u5206\u6790\u4e0d\u6df1\u5165\u3001\u7f3a\u4e4f\u73b0\u5b9e\u5e94\u7528\u5206\u6790\u3001\u4f9d\u8d56\u5c0f\u89c4\u6a21\u6216\u4f4e\u8d28\u91cf\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u8fd9\u4e9b\u5dee\u8ddd\u3002", "method": "\u6784\u5efaBinAtlas\u548cBinAres\u4e24\u4e2a\u9ad8\u8d28\u91cf\u591a\u6837\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e5d\u4e2a\u4ee3\u8868\u6027BFSD\u5de5\u5177\uff0c\u5206\u6790\u6311\u6218\u548c\u5c40\u9650\u6027\uff0c\u7814\u7a76\u5de5\u5177\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u63d0\u51fa\u7ec4\u5408BFSD\u5de5\u5177\u7684\u7b56\u7565\u4f7f\u6574\u4f53\u6027\u80fd\u63d0\u534713.4%\u3002", "conclusion": "\u7814\u7a76\u63a8\u52a8\u4e86BFSD\u5de5\u5177\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u81ea\u52a8\u5316\u4e8c\u8fdb\u5236\u76f8\u4f3c\u6027\u68c0\u6d4b\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u8d44\u6e90\u548c\u89c1\u89e3\u3002"}}
{"id": "2511.00166", "pdf": "https://arxiv.org/pdf/2511.00166", "abs": "https://arxiv.org/abs/2511.00166", "authors": ["Shiman Zhang", "Jinghan Zhou", "Zhoufan Yu", "Ningai Leng"], "title": "Study on Supply Chain Finance Decision-Making Model and Enterprise Economic Performance Prediction Based on Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": "9 pages, 3 figures", "summary": "To improve decision-making and planning efficiency in back-end centralized\nredundant supply chains, this paper proposes a decision model integrating deep\nlearning with intelligent particle swarm optimization. A distributed node\ndeployment model and optimal planning path are constructed for the supply chain\nnetwork. Deep learning such as convolutional neural networks extracts features\nfrom historical data, and linear programming captures high-order statistical\nfeatures. The model is optimized using fuzzy association rule scheduling and\ndeep reinforcement learning, while neural networks fit dynamic changes. A\nhybrid mechanism of \"deep learning feature extraction - intelligent particle\nswarm optimization\" guides global optimization and selects optimal decisions\nfor adaptive control. Simulations show reduced resource consumption, enhanced\nspatial planning, and in dynamic environments improved real-time decision\nadjustment, distribution path optimization, and robust intelligent control.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6df1\u5ea6\u5b66\u4e60\u4e0e\u667a\u80fd\u7c92\u5b50\u7fa4\u4f18\u5316\u96c6\u6210\u51b3\u7b56\u6a21\u578b\uff0c\u7528\u4e8e\u540e\u7aef\u96c6\u4e2d\u5197\u4f59\u4f9b\u5e94\u94fe\uff0c\u901a\u8fc7\u591a\u79cd\u65b9\u6cd5\u4f18\u5316\uff0c\u6a21\u62df\u663e\u793a\u6709\u79ef\u6781\u6548\u679c\u3002", "motivation": "\u63d0\u9ad8\u540e\u7aef\u96c6\u4e2d\u5197\u4f59\u4f9b\u5e94\u94fe\u7684\u51b3\u7b56\u548c\u89c4\u5212\u6548\u7387\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u6df1\u5ea6\u5b66\u4e60\u4e0e\u667a\u80fd\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u51b3\u7b56\u6a21\u578b\uff0c\u6784\u5efa\u5206\u5e03\u5f0f\u8282\u70b9\u90e8\u7f72\u6a21\u578b\u548c\u6700\u4f18\u89c4\u5212\u8def\u5f84\uff0c\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7b49\u6df1\u5ea6\u5b66\u4e60\u63d0\u53d6\u7279\u5f81\u3001\u7ebf\u6027\u89c4\u5212\u6355\u6349\u9ad8\u9636\u7edf\u8ba1\u7279\u5f81\uff0c\u901a\u8fc7\u6a21\u7cca\u5173\u8054\u89c4\u5219\u8c03\u5ea6\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6a21\u578b\uff0c\u795e\u7ecf\u7f51\u7edc\u62df\u5408\u52a8\u6001\u53d8\u5316\uff0c\u91c7\u7528\u201c\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u63d0\u53d6 - \u667a\u80fd\u7c92\u5b50\u7fa4\u4f18\u5316\u201d\u6df7\u5408\u673a\u5236\u5f15\u5bfc\u5168\u5c40\u4f18\u5316\u3002", "result": "\u6a21\u62df\u663e\u793a\u51cf\u5c11\u4e86\u8d44\u6e90\u6d88\u8017\u3001\u589e\u5f3a\u4e86\u7a7a\u95f4\u89c4\u5212\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u6539\u5584\u4e86\u5b9e\u65f6\u51b3\u7b56\u8c03\u6574\u3001\u4f18\u5316\u4e86\u914d\u9001\u8def\u5f84\u548c\u5b9e\u73b0\u4e86\u9c81\u68d2\u667a\u80fd\u63a7\u5236\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u540e\u7aef\u96c6\u4e2d\u5197\u4f59\u4f9b\u5e94\u94fe\u7684\u51b3\u7b56\u548c\u89c4\u5212\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2511.01445", "pdf": "https://arxiv.org/pdf/2511.01445", "abs": "https://arxiv.org/abs/2511.01445", "authors": ["ChengZhang Yu", "YingRu He", "Hongyan Cheng", "nuo Cheng", "Zhixing Liu", "Dongxu Mu", "Zhangrui Shen", "Zhanpeng Jin"], "title": "From Passive to Proactive: A Multi-Agent System with Dynamic Task Orchestration for Intelligent Medical Pre-Consultation", "categories": ["cs.AI"], "comment": "14pages, 7 figures, 7 tables", "summary": "Global healthcare systems face critical challenges from increasing patient\nvolumes and limited consultation times, with primary care visits averaging\nunder 5 minutes in many countries. While pre-consultation processes\nencompassing triage and structured history-taking offer potential solutions,\nthey remain limited by passive interaction paradigms and context management\nchallenges in existing AI systems. This study introduces a hierarchical\nmulti-agent framework that transforms passive medical AI systems into proactive\ninquiry agents through autonomous task orchestration. We developed an\neight-agent architecture with centralized control mechanisms that decomposes\npre-consultation into four primary tasks: Triage ($T_1$), History of Present\nIllness collection ($T_2$), Past History collection ($T_3$), and Chief\nComplaint generation ($T_4$), with $T_1$--$T_3$ further divided into 13\ndomain-specific subtasks. Evaluated on 1,372 validated electronic health\nrecords from a Chinese medical platform across multiple foundation models\n(GPT-OSS 20B, Qwen3-8B, Phi4-14B), the framework achieved 87.0% accuracy for\nprimary department triage and 80.5% for secondary department classification,\nwith task completion rates reaching 98.2% using agent-driven scheduling versus\n93.1% with sequential processing. Clinical quality scores from 18 physicians\naveraged 4.56 for Chief Complaints, 4.48 for History of Present Illness, and\n4.69 for Past History on a 5-point scale, with consultations completed within\n12.7 rounds for $T_2$ and 16.9 rounds for $T_3$. The model-agnostic\narchitecture maintained high performance across different foundation models\nwhile preserving data privacy through local deployment, demonstrating the\npotential for autonomous AI systems to enhance pre-consultation efficiency and\nquality in clinical settings.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u88ab\u52a8\u533b\u7597AI\u7cfb\u7edf\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u8be2\u95ee\u4ee3\u7406\uff0c\u8bc4\u4f30\u663e\u793a\u8be5\u6846\u67b6\u5728\u9884\u54a8\u8be2\u6548\u7387\u548c\u8d28\u91cf\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5168\u7403\u533b\u7597\u7cfb\u7edf\u9762\u4e34\u60a3\u8005\u6570\u91cf\u589e\u52a0\u548c\u54a8\u8be2\u65f6\u95f4\u6709\u9650\u7684\u6311\u6218\uff0c\u73b0\u6709AI\u7cfb\u7edf\u7684\u9884\u54a8\u8be2\u6d41\u7a0b\u5b58\u5728\u88ab\u52a8\u4ea4\u4e92\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u5177\u6709\u96c6\u4e2d\u63a7\u5236\u673a\u5236\u7684\u516b\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06\u9884\u54a8\u8be2\u5206\u89e3\u4e3a\u56db\u4e2a\u4e3b\u8981\u4efb\u52a1\u548c13\u4e2a\u5b50\u4efb\u52a1\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u4e3b\u8981\u79d1\u5ba4\u5206\u8bca\u51c6\u786e\u738787.0%\uff0c\u6b21\u8981\u79d1\u5ba4\u5206\u7c7b\u51c6\u786e\u738780.5%\uff0c\u4efb\u52a1\u5b8c\u6210\u738798.2%\uff0c\u4e34\u5e8a\u8d28\u91cf\u5f97\u5206\u8f83\u9ad8\u3002", "conclusion": "\u8be5\u6a21\u578b\u65e0\u5173\u67b6\u6784\u5728\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u4e0a\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u80fd\u63d0\u9ad8\u4e34\u5e8a\u9884\u54a8\u8be2\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2511.00177", "pdf": "https://arxiv.org/pdf/2511.00177", "abs": "https://arxiv.org/abs/2511.00177", "authors": ["Hiba Ahsan", "Byron C. Wallace"], "title": "Can SAEs reveal and mitigate racial biases of LLMs in healthcare?", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "LLMs are increasingly being used in healthcare. This promises to free\nphysicians from drudgery, enabling better care to be delivered at scale. But\nthe use of LLMs in this space also brings risks; for example, such models may\nworsen existing biases. How can we spot when LLMs are (spuriously) relying on\npatient race to inform predictions? In this work we assess the degree to which\nSparse Autoencoders (SAEs) can reveal (and control) associations the model has\nmade between race and stigmatizing concepts. We first identify SAE latents in\nGemma-2 models which appear to correlate with Black individuals. We find that\nthis latent activates on reasonable input sequences (e.g., \"African American\")\nbut also problematic words like \"incarceration\". We then show that we can use\nthis latent to steer models to generate outputs about Black patients, and\nfurther that this can induce problematic associations in model outputs as a\nresult. For example, activating the Black latent increases the risk assigned to\nthe probability that a patient will become \"belligerent\". We evaluate the\ndegree to which such steering via latents might be useful for mitigating bias.\nWe find that this offers improvements in simple settings, but is less\nsuccessful for more realistic and complex clinical tasks. Overall, our results\nsuggest that: SAEs may offer a useful tool in clinical applications of LLMs to\nidentify problematic reliance on demographics but mitigating bias via SAE\nsteering appears to be of marginal utility for realistic tasks.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u80fd\u5426\u63ed\u793a\u548c\u63a7\u5236\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u79cd\u65cf\u4e0e\u6c61\u540d\u5316\u6982\u5ff5\u7684\u5173\u8054\uff0c\u53d1\u73b0SAEs\u53ef\u8bc6\u522b\u95ee\u9898\uff0c\u4f46\u901a\u8fc7SAE\u63a7\u5236\u504f\u5dee\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u6709\u98ce\u9669\uff0c\u5982\u53ef\u80fd\u52a0\u5267\u73b0\u6709\u504f\u89c1\uff0c\u9700\u627e\u51fa\u6a21\u578b\u662f\u5426\u4f9d\u8d56\u60a3\u8005\u79cd\u65cf\u8fdb\u884c\u9884\u6d4b\u3002", "method": "\u8bc6\u522bGemma - 2\u6a21\u578b\u4e2d\u4e0e\u9ed1\u4eba\u4e2a\u4f53\u76f8\u5173\u7684SAE\u6f5c\u5728\u56e0\u7d20\uff0c\u7528\u8be5\u6f5c\u5728\u56e0\u7d20\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u5173\u4e8e\u9ed1\u4eba\u60a3\u8005\u7684\u8f93\u51fa\uff0c\u5e76\u8bc4\u4f30\u901a\u8fc7\u6f5c\u5728\u56e0\u7d20\u5f15\u5bfc\u51cf\u8f7b\u504f\u5dee\u7684\u7a0b\u5ea6\u3002", "result": "\u8be5\u6f5c\u5728\u56e0\u7d20\u5728\u5408\u7406\u8f93\u5165\u548c\u6709\u95ee\u9898\u7684\u8bcd\u6c47\u4e0a\u90fd\u4f1a\u6fc0\u6d3b\uff0c\u6fc0\u6d3b\u9ed1\u4eba\u6f5c\u5728\u56e0\u7d20\u4f1a\u589e\u52a0\u60a3\u8005\u51fa\u73b0\u4e0d\u826f\u60c5\u51b5\u7684\u98ce\u9669\u8bc4\u4f30\uff0c\u901a\u8fc7\u6f5c\u5728\u56e0\u7d20\u5f15\u5bfc\u5728\u7b80\u5355\u573a\u666f\u6709\u6539\u5584\uff0c\u4f46\u5728\u66f4\u73b0\u5b9e\u590d\u6742\u7684\u4e34\u5e8a\u4efb\u52a1\u4e2d\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "SAEs\u53ef\u4f5c\u4e3a\u4e34\u5e8a\u5e94\u7528\u4e2d\u8bc6\u522b\u6a21\u578b\u5bf9\u4eba\u53e3\u7edf\u8ba1\u5b66\u95ee\u9898\u4f9d\u8d56\u7684\u6709\u7528\u5de5\u5177\uff0c\u4f46\u901a\u8fc7SAE\u5f15\u5bfc\u51cf\u8f7b\u504f\u5dee\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u4f5c\u7528\u6709\u9650\u3002"}}
{"id": "2511.01527", "pdf": "https://arxiv.org/pdf/2511.01527", "abs": "https://arxiv.org/abs/2511.01527", "authors": ["Hanwen Xu", "Xuyao Huang", "Yuzhe Liu", "Kai Yu", "Zhijie Deng"], "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\& Scheduling Abilities in Compounding Tasks", "categories": ["cs.AI"], "comment": null, "summary": "Large language model (LLM) agents have exhibited strong problem-solving\ncompetence across domains like research and coding. Yet, it remains\nunderexplored whether LLM agents can tackle compounding real-world problems\nthat require a diverse set of tools to complete. Given a broad, heterogeneous\ntool repository, LLM agents must not only select appropriate tools based on\ntask planning analysis but also strategically schedule the execution order to\nensure efficiency. This paper introduces TPS-Bench to benchmark the ability of\nLLM agents in solving such problems that demand Tool Planning and Scheduling.\nTPS-Bench collects 200 compounding tasks of two difficulty levels, based on a\ntool repository containing hundreds of model context protocol (MCP) tools. In\nparticular, each task is composed of multiple subtasks, such as web search, map\nnavigation, calendar checking, etc., and each subtask can be completed by a\nbasic tool. Our evaluation emphasizes both task completion rate and efficiency.\nThe empirical studies on popular closed-source and open-source LLMs indicate\nthat most models can perform reasonable tool planning, but differ in\nscheduling. For example, GLM-4.5 achieves an outperforming task completion rate\nof 64.72% with extensive sequential tool calls, hence suffering from\nsignificantly long execution time. By contrast, GPT-4o prioritizes parallel\ntool calls but achieves only a 45.08% completion rate. Considering\nreinforcement learning (RL) can be a viable way to improve the scheduling\nefficiency without compromising performance, we perform an initial study on\nQwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in\ntask completion rate based on rarely 100 RL training samples. Our code is\navailable https://github.com/hanwenxu1/mcp-agent.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165TPS - Bench\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u89e3\u51b3\u9700\u8981\u5de5\u5177\u89c4\u5212\u548c\u8c03\u5ea6\u95ee\u9898\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u5bf9\u6d41\u884c\u6a21\u578b\u7684\u8bc4\u4f30\u53d1\u73b0\u6a21\u578b\u5728\u8c03\u5ea6\u4e0a\u6709\u5dee\u5f02\uff0c\u5e76\u5bf9Qwen3 - 1.7B\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u521d\u6b65\u7814\u7a76\u53d6\u5f97\u4e00\u5b9a\u6548\u679c\u3002", "motivation": "\u63a2\u7a76LLM\u4ee3\u7406\u80fd\u5426\u89e3\u51b3\u9700\u8981\u591a\u6837\u5316\u5de5\u5177\u5b8c\u6210\u7684\u73b0\u5b9e\u590d\u5408\u95ee\u9898\uff0c\u4ee5\u53ca\u5728\u5e7f\u6cdb\u5de5\u5177\u5e93\u4e0b\u7684\u5de5\u5177\u89c4\u5212\u548c\u8c03\u5ea6\u80fd\u529b\u3002", "method": "\u5f15\u5165TPS - Bench\uff0c\u6536\u96c6200\u4e2a\u4e24\u4e2a\u96be\u5ea6\u7ea7\u522b\u7684\u590d\u5408\u4efb\u52a1\uff0c\u57fa\u4e8e\u542b\u6570\u767e\u4e2a\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u5de5\u5177\u7684\u5de5\u5177\u5e93\uff0c\u8bc4\u4f30\u5f3a\u8c03\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6548\u7387\uff0c\u5e76\u5bf9Qwen3 - 1.7B\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u521d\u6b65\u7814\u7a76\u3002", "result": "\u591a\u6570\u6a21\u578b\u80fd\u8fdb\u884c\u5408\u7406\u5de5\u5177\u89c4\u5212\uff0c\u4f46\u8c03\u5ea6\u6709\u5dee\u5f02\uff0c\u5982GLM - 4.5\u5b8c\u6210\u7387\u9ad8\u4f46\u6267\u884c\u65f6\u95f4\u957f\uff0cGPT - 4o\u4f18\u5148\u5e76\u884c\u8c03\u7528\u5de5\u5177\u4f46\u5b8c\u6210\u7387\u4f4e\uff1b\u5bf9Qwen3 - 1.7B\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u540e\u6267\u884c\u65f6\u95f4\u51cf\u5c1114%\uff0c\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u53476%\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u662f\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u8c03\u5ea6\u6548\u7387\u7684\u53ef\u884c\u65b9\u6cd5\u3002"}}
{"id": "2511.00183", "pdf": "https://arxiv.org/pdf/2511.00183", "abs": "https://arxiv.org/abs/2511.00183", "authors": ["Shaghayegh Fazliani", "Madeleine Udell"], "title": "PDE-SHARP: PDE Solver Hybrids Through Analysis & Refinement Passes", "categories": ["cs.LG"], "comment": null, "summary": "Current LLM-driven approaches using test-time computing to generate PDE\nsolvers execute a large number of solver samples to identify high-accuracy\nsolvers. These paradigms are especially costly for complex PDEs requiring\nsubstantial computational resources for numerical evaluation. We introduce\nPDE-SHARP, a framework to reduce computational costs by replacing expensive\nscientific computation by cheaper LLM inference that achieves superior solver\naccuracy with 60-75% fewer computational evaluations. PDE-SHARP employs three\nstages: (1) Analysis: mathematical chain-of-thought analysis including PDE\nclassification, solution type detection, and stability analysis; (2) Genesis:\nsolver generation based on mathematical insights from the previous stage; and\n(3) Synthesis: collaborative selection-hybridization tournaments in which LLM\njudges iteratively refine implementations through flexible performance\nfeedback. To generate high-quality solvers, PDE-SHARP requires fewer than 13\nsolver evaluations on average compared to 30+ for baseline methods, improving\naccuracy uniformly across tested PDEs by $4\\times$ on average, and demonstrates\nrobust performance across LLM architectures, from general-purpose to\nspecialized reasoning models.", "AI": {"tldr": "\u63d0\u51faPDE - SHARP\u6846\u67b6\u51cf\u5c11PDE\u6c42\u89e3\u5668\u8ba1\u7b97\u6210\u672c\uff0c\u7cbe\u5ea6\u66f4\u9ad8\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684PDE\u6c42\u89e3\u5668\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742PDE\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "PDE - SHARP\u6846\u67b6\u5305\u542b\u5206\u6790\u3001\u751f\u6210\u548c\u5408\u6210\u4e09\u4e2a\u9636\u6bb5\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u6c42\u89e3\u5668\u8bc4\u4f30\u6b21\u6570\u5c11\u4e8e13\u6b21\uff0c\u7cbe\u5ea6\u5e73\u5747\u63d0\u9ad84\u500d\uff0c\u5728\u4e0d\u540cLLM\u67b6\u6784\u4e2d\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "PDE - SHARP\u80fd\u4ee5\u66f4\u5c11\u8ba1\u7b97\u8bc4\u4f30\u5b9e\u73b0\u66f4\u9ad8\u6c42\u89e3\u5668\u7cbe\u5ea6\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.01550", "pdf": "https://arxiv.org/pdf/2511.01550", "abs": "https://arxiv.org/abs/2511.01550", "authors": ["Ujjwal Sharma", "Stevan Rudinac", "Ana Mi\u0107kovi\u0107", "Willemijn van Dolen", "Marcel Worring"], "title": "Analyzing Sustainability Messaging in Large-Scale Corporate Social Media", "categories": ["cs.AI"], "comment": null, "summary": "In this work, we introduce a multimodal analysis pipeline that leverages\nlarge foundation models in vision and language to analyze corporate social\nmedia content, with a focus on sustainability-related communication. Addressing\nthe challenges of evolving, multimodal, and often ambiguous corporate messaging\non platforms such as X (formerly Twitter), we employ an ensemble of large\nlanguage models (LLMs) to annotate a large corpus of corporate tweets on their\ntopical alignment with the 17 Sustainable Development Goals (SDGs). This\napproach avoids the need for costly, task-specific annotations and explores the\npotential of such models as ad-hoc annotators for social media data that can\nefficiently capture both explicit and implicit references to sustainability\nthemes in a scalable manner. Complementing this textual analysis, we utilize\nvision-language models (VLMs), within a visual understanding framework that\nuses semantic clusters to uncover patterns in visual sustainability\ncommunication. This integrated approach reveals sectoral differences in SDG\nengagement, temporal trends, and associations between corporate messaging,\nenvironmental, social, governance (ESG) risks, and consumer engagement. Our\nmethods-automatic label generation and semantic visual clustering-are broadly\napplicable to other domains and offer a flexible framework for large-scale\nsocial media analysis.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u591a\u6a21\u6001\u5206\u6790\u6d41\u7a0b\uff0c\u7528\u89c6\u89c9\u548c\u8bed\u8a00\u5927\u6a21\u578b\u5206\u6790\u4f01\u4e1a\u793e\u4ea4\u5a92\u4f53\u53ef\u6301\u7eed\u6027\u76f8\u5173\u5185\u5bb9\uff0c\u65b9\u6cd5\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u5728\u5e73\u53f0\u5982X\u4e0a\u4e0d\u65ad\u6f14\u53d8\u3001\u591a\u6a21\u6001\u4e14\u5e38\u6a21\u7cca\u7684\u4fe1\u606f\u4f20\u8fbe\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u5408\u6807\u6ce8\u4f01\u4e1a\u63a8\u6587\u4e0e17\u4e2a\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u7684\u4e3b\u9898\u4e00\u81f4\u6027\uff0c\u5229\u7528\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\u548c\u8bed\u4e49\u805a\u7c7b\u8fdb\u884c\u89c6\u89c9\u7406\u89e3\u3002", "result": "\u63ed\u793a\u4e86\u4f01\u4e1a\u5728\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u53c2\u4e0e\u4e0a\u7684\u884c\u4e1a\u5dee\u5f02\u3001\u65f6\u95f4\u8d8b\u52bf\uff0c\u4ee5\u53ca\u4f01\u4e1a\u4fe1\u606f\u4f20\u8fbe\u3001ESG\u98ce\u9669\u548c\u6d88\u8d39\u8005\u53c2\u4e0e\u4e4b\u95f4\u7684\u5173\u8054\u3002", "conclusion": "\u81ea\u52a8\u6807\u7b7e\u751f\u6210\u548c\u8bed\u4e49\u89c6\u89c9\u805a\u7c7b\u65b9\u6cd5\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5176\u4ed6\u9886\u57df\uff0c\u4e3a\u5927\u89c4\u6a21\u793e\u4ea4\u5a92\u4f53\u5206\u6790\u63d0\u4f9b\u7075\u6d3b\u6846\u67b6\u3002"}}
{"id": "2511.00192", "pdf": "https://arxiv.org/pdf/2511.00192", "abs": "https://arxiv.org/abs/2511.00192", "authors": ["Ali Satvaty", "Suzan Verberne", "Fatih Turkmen"], "title": "EL-MIA: Quantifying Membership Inference Risks of Sensitive Entities in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Membership inference attacks (MIA) aim to infer whether a particular data\npoint is part of the training dataset of a model. In this paper, we propose a\nnew task in the context of LLM privacy: entity-level discovery of membership\nrisk focused on sensitive information (PII, credit card numbers, etc). Existing\nmethods for MIA can detect the presence of entire prompts or documents in the\nLLM training data, but they fail to capture risks at a finer granularity. We\npropose the ``EL-MIA'' framework for auditing entity-level membership risks in\nLLMs. We construct a benchmark dataset for the evaluation of MIA methods on\nthis task. Using this benchmark, we conduct a systematic comparison of existing\nMIA techniques as well as two newly proposed methods. We provide a\ncomprehensive analysis of the results, trying to explain the relation of the\nentity level MIA susceptability with the model scale, training epochs, and\nother surface level factors. Our findings reveal that existing MIA methods are\nlimited when it comes to entity-level membership inference of the sensitive\nattributes, while this susceptibility can be outlined with relatively\nstraightforward methods, highlighting the need for stronger adversaries to\nstress test the provided threat model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5b9e\u4f53\u7ea7\u6210\u5458\u98ce\u9669\u53d1\u73b0\u4efb\u52a1\uff0c\u6784\u5efa\u57fa\u51c6\u6570\u636e\u96c6\u5bf9\u6bd4\u73b0\u6709\u53ca\u65b0\u65b9\u6cd5\uff0c\u5206\u6790\u7ed3\u679c\u6307\u51fa\u73b0\u6709\u65b9\u6cd5\u5728\u654f\u611f\u5c5e\u6027\u5b9e\u4f53\u7ea7\u6210\u5458\u63a8\u7406\u65b9\u9762\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIA\uff09\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u66f4\u7ec6\u7c92\u5ea6\u98ce\u9669\uff0c\u63d0\u51fa\u5b9e\u4f53\u7ea7\u654f\u611f\u4fe1\u606f\u6210\u5458\u98ce\u9669\u53d1\u73b0\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u201cEL - MIA\u201d\u6846\u67b6\u5ba1\u8ba1\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u4f53\u7ea7\u6210\u5458\u98ce\u9669\uff0c\u6784\u5efa\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u73b0\u6709\u53ca\u65b0\u63d0\u51fa\u7684\u4e24\u79cd\u65b9\u6cd5\u3002", "result": "\u73b0\u6709MIA\u65b9\u6cd5\u5728\u654f\u611f\u5c5e\u6027\u5b9e\u4f53\u7ea7\u6210\u5458\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u53ef\u7528\u76f8\u5bf9\u76f4\u63a5\u7684\u65b9\u6cd5\u52fe\u52d2\u51fa\u6613\u53d7\u653b\u51fb\u6027\u3002", "conclusion": "\u9700\u8981\u66f4\u5f3a\u7684\u5bf9\u624b\u6765\u5bf9\u5a01\u80c1\u6a21\u578b\u8fdb\u884c\u538b\u529b\u6d4b\u8bd5\u3002"}}
{"id": "2511.01581", "pdf": "https://arxiv.org/pdf/2511.01581", "abs": "https://arxiv.org/abs/2511.01581", "authors": ["Chengzhang Yu", "Zening Lu", "Chenyang Zheng", "Chiyue Wang", "Yiming Zhang", "Zhanpeng Jin"], "title": "ExplicitLM: Decoupling Knowledge from Parameters via Explicit Memory Banks", "categories": ["cs.AI"], "comment": "12pages, 4figures", "summary": "Large language models suffer from knowledge staleness and lack of\ninterpretability due to implicit knowledge storage across entangled network\nparameters, preventing targeted updates and reasoning transparency. We propose\nExplicitLM, a novel architecture featuring a million-scale external memory bank\nstoring human-readable knowledge as token sequences, enabling direct inspection\nand modification. We design a differentiable two-stage retrieval mechanism with\nefficient coarse-grained filtering via product key decomposition (reducing\ncomplexity from $\\mathcal{O}(N \\cdot |I|)$ to $\\mathcal{O}(\\sqrt{N} \\cdot\n|I|)$) and fine-grained Gumbel-Softmax matching for end-to-end training.\nInspired by dual-system cognitive theory, we partition knowledge into frozen\nexplicit facts (20%) and learnable implicit patterns (80%), maintained through\nExponential Moving Average updates for stability. ExplicitLM achieves up to\n43.67% improvement on knowledge-intensive tasks versus standard Transformers,\nwith 3.62$\\times$ gains in low-data regimes (10k samples). Analysis shows\nstrong correlations between memory retrieval and performance, with correct\npredictions achieving 49% higher hit rates. Unlike RAG systems with frozen\nretrieval, our jointly optimized architecture demonstrates that interpretable,\nupdatable models can maintain competitive performance while providing\nunprecedented knowledge transparency.", "AI": {"tldr": "\u63d0\u51faExplicitLM\u67b6\u6784\uff0c\u6709\u5916\u90e8\u8bb0\u5fc6\u5e93\uff0c\u8bbe\u8ba1\u4e86\u68c0\u7d22\u673a\u5236\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e0a\u8868\u73b0\u597d\uff0c\u80fd\u63d0\u4f9b\u77e5\u8bc6\u900f\u660e\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u9690\u5f0f\u77e5\u8bc6\u5b58\u50a8\u5bfc\u81f4\u7684\u77e5\u8bc6\u9648\u65e7\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faExplicitLM\u67b6\u6784\uff0c\u8bbe\u8ba1\u53ef\u5fae\u7684\u4e24\u9636\u6bb5\u68c0\u7d22\u673a\u5236\uff0c\u6309\u53cc\u7cfb\u7edf\u8ba4\u77e5\u7406\u8bba\u5212\u5206\u77e5\u8bc6\u5e76\u901a\u8fc7\u6307\u6570\u79fb\u52a8\u5e73\u5747\u66f4\u65b0\u7ef4\u62a4\u3002", "result": "\u5728\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e0a\u6bd4\u6807\u51c6Transformer\u6700\u591a\u63d0\u534743.67%\uff0c\u4f4e\u6570\u636e\u4e0b\u67093.62\u500d\u63d0\u5347\uff0c\u68c0\u7d22\u4e0e\u6027\u80fd\u5f3a\u76f8\u5173\u3002", "conclusion": "\u8054\u5408\u4f18\u5316\u7684\u67b6\u6784\u53ef\u4f7f\u53ef\u89e3\u91ca\u3001\u53ef\u66f4\u65b0\u6a21\u578b\u4fdd\u6301\u7ade\u4e89\u529b\u5e76\u63d0\u4f9b\u77e5\u8bc6\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.01639", "pdf": "https://arxiv.org/pdf/2511.01639", "abs": "https://arxiv.org/abs/2511.01639", "authors": ["Sicheng Wang", "Shuhao Chen", "Jingran Zhou", "Chengyi Tu"], "title": "IVGAE-TAMA-BO: A novel temporal dynamic variational graph model for link prediction in global food trade networks with momentum structural memory and Bayesian optimization", "categories": ["cs.AI"], "comment": "26pages,6figures", "summary": "Global food trade plays a crucial role in ensuring food security and\nmaintaining supply chain stability. However, its network structure evolves\ndynamically under the influence of geopolitical, economic, and environmental\nfactors, making it challenging to model and predict future trade links.\nEffectively capturing temporal patterns in food trade networks is therefore\nessential for improving the accuracy and robustness of link prediction. This\nstudy introduces IVGAE-TAMA-BO, a novel dynamic graph neural network designed\nto model evolving trade structures and predict future links in global food\ntrade networks. To the best of our knowledge, this is the first work to apply\ndynamic graph neural networks to this domain, significantly enhancing\npredictive performance. Building upon the original IVGAE framework, the\nproposed model incorporates a Trade-Aware Momentum Aggregator (TAMA) to capture\nthe temporal evolution of trade networks, jointly modeling short-term\nfluctuations and long-term structural dependencies. A momentum-based structural\nmemory mechanism further improves predictive stability and performance. In\naddition, Bayesian optimization is used to automatically tune key\nhyperparameters, enhancing generalization across diverse trade scenarios.\nExtensive experiments on five crop-specific datasets demonstrate that\nIVGAE-TAMA substantially outperforms the static IVGAE and other dynamic\nbaselines by effectively modeling temporal dependencies, while Bayesian\noptimization further boosts performance in IVGAE-TAMA-BO. These results\nhighlight the proposed framework as a robust and scalable solution for\nstructural prediction in global trade networks, with strong potential for\napplications in food security monitoring and policy decision support.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIVGAE - TAMA - BO\u52a8\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\u7528\u4e8e\u5168\u7403\u98df\u54c1\u8d38\u6613\u7f51\u7edc\u7684\u94fe\u63a5\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u5f02\uff0c\u6709\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5168\u7403\u98df\u54c1\u8d38\u6613\u7f51\u7edc\u7ed3\u6784\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\u52a8\u6001\u6f14\u53d8\uff0c\u96be\u4ee5\u5efa\u6a21\u548c\u9884\u6d4b\u672a\u6765\u8d38\u6613\u94fe\u63a5\uff0c\u9700\u6709\u6548\u6355\u6349\u65f6\u95f4\u6a21\u5f0f\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faIVGAE - TAMA - BO\u6a21\u578b\uff0c\u5728IVGAE\u6846\u67b6\u57fa\u7840\u4e0a\u5f15\u5165TAMA\u6355\u6349\u8d38\u6613\u7f51\u7edc\u65f6\u95f4\u6f14\u53d8\uff0c\u91c7\u7528\u57fa\u4e8e\u52a8\u91cf\u7684\u7ed3\u6784\u8bb0\u5fc6\u673a\u5236\uff0c\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u8c03\u6574\u8d85\u53c2\u6570\u3002", "result": "\u5728\u4e94\u4e2a\u4f5c\u7269\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\uff0cIVGAE - TAMA\u663e\u8457\u4f18\u4e8e\u9759\u6001IVGAE\u548c\u5176\u4ed6\u52a8\u6001\u57fa\u7ebf\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347IVGAE - TAMA - BO\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u5168\u7403\u8d38\u6613\u7f51\u7edc\u7ed3\u6784\u9884\u6d4b\u7684\u53ef\u9760\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u98df\u54c1\u5b89\u5168\u76d1\u6d4b\u548c\u653f\u7b56\u51b3\u7b56\u652f\u6301\u65b9\u9762\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.00209", "pdf": "https://arxiv.org/pdf/2511.00209", "abs": "https://arxiv.org/abs/2511.00209", "authors": ["Yiquan Wang", "Yahui Ma", "Yuhan Chang", "Jiayao Yan", "Jialin Zhang", "Minnuo Cai", "Kai Wei"], "title": "Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "comment": "21 pages, 3 figures", "summary": "Diffusion models have emerged as a leading framework in generative modeling,\nshowing significant potential to accelerate and transform the traditionally\nslow and costly process of drug discovery. This review provides a systematic\ncomparison of their application in designing two principal therapeutic\nmodalities: small molecules and therapeutic peptides. We analyze how a unified\nframework of iterative denoising is adapted to the distinct molecular\nrepresentations, chemical spaces, and design objectives of each modality. For\nsmall molecules, these models excel at structure-based design, generating\nnovel, pocket-fitting ligands with desired physicochemical properties, yet face\nthe critical hurdle of ensuring chemical synthesizability. Conversely, for\ntherapeutic peptides, the focus shifts to generating functional sequences and\ndesigning de novo structures, where the primary challenges are achieving\nbiological stability against proteolysis, ensuring proper folding, and\nminimizing immunogenicity. Despite these distinct challenges, both domains face\nshared hurdles: the need for more accurate scoring functions, the scarcity of\nhigh-quality experimental data, and the crucial requirement for experimental\nvalidation. We conclude that the full potential of diffusion models will be\nunlocked by bridging these modality-specific gaps and integrating them into\nautomated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby\nshifting the paradigm from chemical exploration to the targeted creation of\nnovel therapeutics.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u6269\u6563\u6a21\u578b\u5728\u5c0f\u5206\u5b50\u548c\u6cbb\u7597\u6027\u80bd\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u6307\u51fa\u5404\u81ea\u6311\u6218\u548c\u5171\u540c\u969c\u788d\uff0c\u8ba4\u4e3a\u5e94\u5f25\u5408\u7279\u5b9a\u5dee\u8ddd\u5e76\u6574\u5408\u5230DBTL\u5e73\u53f0\u4ee5\u91ca\u653e\u5176\u6f5c\u529b\u3002", "motivation": "\u52a0\u901f\u548c\u53d8\u9769\u4f20\u7edf\u7f13\u6162\u4e14\u6602\u8d35\u7684\u836f\u7269\u53d1\u73b0\u8fc7\u7a0b\uff0c\u7cfb\u7edf\u6bd4\u8f83\u6269\u6563\u6a21\u578b\u5728\u4e24\u79cd\u4e3b\u8981\u6cbb\u7597\u65b9\u5f0f\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5206\u6790\u8fed\u4ee3\u53bb\u566a\u7684\u7edf\u4e00\u6846\u67b6\u5982\u4f55\u9002\u5e94\u4e0d\u540c\u6cbb\u7597\u65b9\u5f0f\u7684\u5206\u5b50\u8868\u793a\u3001\u5316\u5b66\u7a7a\u95f4\u548c\u8bbe\u8ba1\u76ee\u6807\u3002", "result": "\u5c0f\u5206\u5b50\u8bbe\u8ba1\u4e2d\u6a21\u578b\u64c5\u957f\u57fa\u4e8e\u7ed3\u6784\u8bbe\u8ba1\uff0c\u4f46\u8981\u786e\u4fdd\u5316\u5b66\u53ef\u5408\u6210\u6027\uff1b\u6cbb\u7597\u6027\u80bd\u8bbe\u8ba1\u5173\u6ce8\u751f\u6210\u529f\u80fd\u5e8f\u5217\u548c\u4ece\u5934\u8bbe\u8ba1\u7ed3\u6784\uff0c\u9762\u4e34\u751f\u7269\u7a33\u5b9a\u6027\u3001\u6298\u53e0\u548c\u514d\u75ab\u539f\u6027\u7b49\u6311\u6218\uff1b\u4e8c\u8005\u6709\u5171\u540c\u969c\u788d\u3002", "conclusion": "\u5f25\u5408\u7279\u5b9a\u5dee\u8ddd\u5e76\u5c06\u6269\u6563\u6a21\u578b\u6574\u5408\u5230DBTL\u5e73\u53f0\uff0c\u53ef\u4ece\u5316\u5b66\u63a2\u7d22\u8f6c\u5411\u9776\u5411\u521b\u9020\u65b0\u578b\u7597\u6cd5\uff0c\u91ca\u653e\u5176\u5168\u90e8\u6f5c\u529b\u3002"}}
{"id": "2511.01668", "pdf": "https://arxiv.org/pdf/2511.01668", "abs": "https://arxiv.org/abs/2511.01668", "authors": ["Yueqing Xi", "Yifan Bai", "Huasen Luo", "Weiliang Wen", "Hui Liu", "Haoliang Li"], "title": "Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal Question Answering in Judicial Forensics", "categories": ["cs.AI"], "comment": null, "summary": "As artificial intelligence permeates judicial forensics, ensuring the\nveracity and traceability of legal question answering (QA) has become critical.\nConventional large language models (LLMs) are prone to hallucination, risking\nmisleading guidance in legal consultation, while static knowledge bases\nstruggle to keep pace with frequently updated statutes and case law. We present\na hybrid legal QA agent tailored for judicial settings that integrates\nretrieval-augmented generation (RAG) with multi-model ensembling to deliver\nreliable, auditable, and continuously updatable counsel. The system prioritizes\nretrieval over generation: when a trusted legal repository yields relevant\nevidence, answers are produced via RAG; otherwise, multiple LLMs generate\ncandidates that are scored by a specialized selector, with the top-ranked\nanswer returned. High-quality outputs then undergo human review before being\nwritten back to the repository, enabling dynamic knowledge evolution and\nprovenance tracking. Experiments on the Law\\_QA dataset show that our hybrid\napproach significantly outperforms both a single-model baseline and a vanilla\nRAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm\nthe complementary contributions of retrieval prioritization, model ensembling,\nand the human-in-the-loop update mechanism. The proposed system demonstrably\nreduces hallucination while improving answer quality and legal compliance,\nadvancing the practical landing of media forensics technologies in judicial\nscenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u53f8\u6cd5\u573a\u666f\u7684\u6df7\u5408\u5f0f\u6cd5\u5f8b\u95ee\u7b54\u4ee3\u7406\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u591a\u6a21\u578b\u96c6\u6210\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u80fd\u51cf\u5c11\u5e7b\u89c9\u3001\u63d0\u5347\u7b54\u6848\u8d28\u91cf\u548c\u5408\u89c4\u6027\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6e17\u900f\u53f8\u6cd5\u53d6\u8bc1\uff0c\u786e\u4fdd\u6cd5\u5f8b\u95ee\u7b54\u7684\u771f\u5b9e\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u9759\u6001\u77e5\u8bc6\u5e93\u96be\u4ee5\u8ddf\u4e0a\u6cd5\u89c4\u548c\u5224\u4f8b\u6cd5\u7684\u66f4\u65b0\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u5f0f\u6cd5\u5f8b\u95ee\u7b54\u4ee3\u7406\uff0c\u4f18\u5148\u68c0\u7d22\uff0c\u68c0\u7d22\u6709\u7ed3\u679c\u5219\u901a\u8fc7RAG\u751f\u6210\u7b54\u6848\uff0c\u5426\u5219\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5019\u9009\u7b54\u6848\u7531\u9009\u62e9\u5668\u6253\u5206\uff0c\u9ad8\u8d28\u91cf\u8f93\u51fa\u7ecf\u4eba\u5de5\u5ba1\u6838\u540e\u5199\u56de\u77e5\u8bc6\u5e93\u3002", "result": "\u5728Law_QA\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u6df7\u5408\u65b9\u6cd5\u5728F1\u3001ROUGE - L\u548cLLM - as - a - Judge\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u6a21\u578b\u57fa\u7ebf\u548c\u666e\u901aRAG\u7ba1\u9053\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u68c0\u7d22\u4f18\u5148\u3001\u6a21\u578b\u96c6\u6210\u548c\u4eba\u5de5\u53c2\u4e0e\u66f4\u65b0\u673a\u5236\u7684\u4e92\u8865\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u53ef\u51cf\u5c11\u5e7b\u89c9\uff0c\u63d0\u9ad8\u7b54\u6848\u8d28\u91cf\u548c\u6cd5\u5f8b\u5408\u89c4\u6027\uff0c\u63a8\u52a8\u5a92\u4f53\u53d6\u8bc1\u6280\u672f\u5728\u53f8\u6cd5\u573a\u666f\u7684\u5b9e\u9645\u843d\u5730\u3002"}}
{"id": "2511.00220", "pdf": "https://arxiv.org/pdf/2511.00220", "abs": "https://arxiv.org/abs/2511.00220", "authors": ["Pouya M. Ghari", "Simone Sciabola", "Ye Wang"], "title": "Iterative Foundation Model Fine-Tuning on Multiple Rewards", "categories": ["cs.LG"], "comment": "Accepted to NeurIPS 2025", "summary": "Fine-tuning foundation models has emerged as a powerful approach for\ngenerating objects with specific desired properties. Reinforcement learning\n(RL) provides an effective framework for this purpose, enabling models to\ngenerate outputs that maximize a given reward function. However, in many\napplications such as text generation and drug discovery, it can be suboptimal\nto optimize using a single reward signal, as multiple evaluation criteria are\noften necessary. This paper proposes a novel reinforcement learning-based\nmethod for fine-tuning foundation models using multiple reward signals. By\nemploying an iterative fine-tuning strategy across these rewards, our approach\ngeneralizes state-of-the-art RL-based methods. We further provide a theoretical\nanalysis that offers insights into the performance of multi-reward RL\nfine-tuning. Experimental results across diverse domains including text,\nbiological sequence, and small molecule generation, demonstrate the\neffectiveness of the proposed algorithm compared to state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u591a\u5956\u52b1\u4fe1\u53f7\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5fae\u8c03\u57fa\u7840\u6a21\u578b\uff0c\u7ecf\u7406\u8bba\u5206\u6790\u548c\u591a\u9886\u57df\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u6587\u672c\u751f\u6210\u548c\u836f\u7269\u53d1\u73b0\u7b49\u5e94\u7528\u4e2d\uff0c\u5355\u4e00\u5956\u52b1\u4fe1\u53f7\u4f18\u5316\u57fa\u7840\u6a21\u578b\u6b20\u4f73\uff0c\u9700\u591a\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u5956\u52b1\u4fe1\u53f7\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5fae\u8c03\u57fa\u7840\u6a21\u578b\uff0c\u91c7\u7528\u8de8\u5956\u52b1\u7684\u8fed\u4ee3\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u5728\u6587\u672c\u3001\u751f\u7269\u5e8f\u5217\u548c\u5c0f\u5206\u5b50\u751f\u6210\u7b49\u591a\u9886\u57df\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u63a8\u5e7f\u4e86\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5bf9\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u6027\u80fd\u6709\u7406\u8bba\u89c1\u89e3\u4e14\u5b9e\u9a8c\u6709\u6548\u3002"}}
{"id": "2511.01824", "pdf": "https://arxiv.org/pdf/2511.01824", "abs": "https://arxiv.org/abs/2511.01824", "authors": ["Yuetai Li", "Huseyin A Inan", "Xiang Yue", "Wei-Ning Chen", "Lukas Wutschitz", "Janardhan Kulkarni", "Radha Poovendran", "Robert Sim", "Saravan Rajmohan"], "title": "Simulating Environments with Reasoning Models for Agent Training", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "LLM agents excel in compact environments requiring deep reasoning but remain\nbrittle when operating in broader, more complex contexts that demand robustness\nacross diverse tools and schemas. Building bespoke environments for training is\nheavy, brittle, and limits progress. In this paper, we demonstrate that LLMs\ncan simulate realistic environment feedback without access to actual testbed\ndata or APIs. Inspired by this capability, we propose two frameworks:\nSimia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets\ninto diverse trajectories in an environment-agnostic manner, and Simia-RL, a\nframework that enables RL training without real environment implementations\nthrough LLM-simulated feedback. Fine-tuning open models yields consistent\nimprovements across multiple benchmarks, surpassing GPT-4o and approaching\no4-mini on $\\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable\nagent training without environment engineering, replacing heavy and brittle\nimplementations with flexible LLM-based simulation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSimia - SFT\u548cSimia - RL\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u73af\u5883\u53cd\u9988\uff0c\u65e0\u9700\u73af\u5883\u5de5\u7a0b\u5373\u53ef\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u8bad\u7ec3\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u6784\u5efa\u5b9a\u5236\u8bad\u7ec3\u73af\u5883\u4ee3\u4ef7\u9ad8\u4e14\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51faSimia - SFT\u548cSimia - RL\u4e24\u4e2a\u6846\u67b6\uff0cSimia - SFT\u4ee5\u73af\u5883\u65e0\u5173\u65b9\u5f0f\u5408\u6210SFT\u6570\u636e\uff0cSimia - RL\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u53cd\u9988\u5b9e\u73b0\u65e0\u771f\u5b9e\u73af\u5883\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "result": "\u5fae\u8c03\u5f00\u6e90\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u6539\u8fdb\uff0c\u8d85\u8d8aGPT - 4o\uff0c\u63a5\u8fd1o4 - mini\u3002", "conclusion": "Simia - SFT\u548cSimia - RL\u53ef\u5b9e\u73b0\u65e0\u73af\u5883\u5de5\u7a0b\u7684\u53ef\u6269\u5c55\u667a\u80fd\u4f53\u8bad\u7ec3\uff0c\u7528\u7075\u6d3b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u53d6\u4ee3\u6c89\u91cd\u8106\u5f31\u7684\u5b9e\u73b0\u3002"}}
{"id": "2511.00246", "pdf": "https://arxiv.org/pdf/2511.00246", "abs": "https://arxiv.org/abs/2511.00246", "authors": ["Wadduwage Shanika Perera", "ABM Islam", "Van Vung Pham", "Min Kyung An"], "title": "Melanoma Classification Through Deep Ensemble Learning and Explainable AI", "categories": ["cs.LG", "cs.CV"], "comment": "Publisher-formatted version provided under CC BY-NC-ND 4.0 license.\n  Original source produced by SciTePress", "summary": "Melanoma is one of the most aggressive and deadliest skin cancers, leading to\nmortality if not detected and treated in the early stages. Artificial\nintelligence techniques have recently been developed to help dermatologists in\nthe early detection of melanoma, and systems based on deep learning (DL) have\nbeen able to detect these lesions with high accuracy. However, the entire\ncommunity must overcome the explainability limit to get the maximum benefit\nfrom DL for diagnostics in the healthcare domain. Because of the black box\noperation's shortcomings in DL models' decisions, there is a lack of\nreliability and trust in the outcomes. However, Explainable Artificial\nIntelligence (XAI) can solve this problem by interpreting the predictions of AI\nsystems. This paper proposes a machine learning model using ensemble learning\nof three state-of-the-art deep transfer Learning networks, along with an\napproach to ensure the reliability of the predictions by utilizing XAI\ntechniques to explain the basis of the predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u96c6\u6210\u5b66\u4e60\u4e0eXAI\u6280\u672f\u89e3\u51b3\u9ed1\u8272\u7d20\u7624\u68c0\u6d4b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002", "motivation": "\u9ed1\u8272\u7d20\u7624\u65e9\u671f\u68c0\u6d4b\u91cd\u8981\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u80fd\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u4f46\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u5c40\u9650\uff0c\u7f3a\u4e4f\u53ef\u9760\u6027\u548c\u4fe1\u4efb\u5ea6\uff0c\u9700\u8981\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u4e09\u4e2a\u5148\u8fdb\u7684\u6df1\u5ea6\u8fc1\u79fb\u5b66\u4e60\u7f51\u7edc\u8fdb\u884c\u96c6\u6210\u5b66\u4e60\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u5229\u7528XAI\u6280\u672f\u89e3\u91ca\u9884\u6d4b\u4f9d\u636e\u4ee5\u786e\u4fdd\u9884\u6d4b\u53ef\u9760\u6027\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2403.15181", "pdf": "https://arxiv.org/pdf/2403.15181", "abs": "https://arxiv.org/abs/2403.15181", "authors": ["Alexandre Valentin Jamet", "Georgios Vavouliotis", "Daniel A. Jim\u00e9nez", "Lluc Alvarez", "Marc Casas"], "title": "A Two Level Neural Approach Combining Off-Chip Prediction with Adaptive Prefetch Filtering", "categories": ["cs.AR", "cs.AI"], "comment": "To appear in 30th International Symposium on High-Performance\n  Computer Architecture (HPCA), 2024", "summary": "To alleviate the performance and energy overheads of contemporary\napplications with large data footprints, we propose the Two Level Perceptron\n(TLP) predictor, a neural mechanism that effectively combines predicting\nwhether an access will be off-chip with adaptive prefetch filtering at the\nfirst-level data cache (L1D). TLP is composed of two connected\nmicroarchitectural perceptron predictors, named First Level Predictor (FLP) and\nSecond Level Predictor (SLP). FLP performs accurate off-chip prediction by\nusing several program features based on virtual addresses and a novel selective\ndelay component. The novelty of SLP relies on leveraging off-chip prediction to\ndrive L1D prefetch filtering by using physical addresses and the FLP prediction\nas features. TLP constitutes the first hardware proposal targeting both\noff-chip prediction and prefetch filtering using a multi-level perceptron\nhardware approach. TLP only requires 7KB of storage. To demonstrate the\nbenefits of TLP we compare its performance with state-of-the-art approaches\nusing off-chip prediction and prefetch filtering on a wide range of single-core\nand multi-core workloads. Our experiments show that TLP reduces the average\nDRAM transactions by 30.7% and 17.7%, as compared to a baseline using\nstate-of-the-art cache prefetchers but no off-chip prediction mechanism, across\nthe single-core and multi-core workloads, respectively, while recent work\nsignificantly increases DRAM transactions. As a result, TLP achieves geometric\nmean performance speedups of 6.2% and 11.8% across single-core and multi-core\nworkloads, respectively. In addition, our evaluation demonstrates that TLP is\neffective independently of the L1D prefetching logic.", "AI": {"tldr": "\u63d0\u51faTLP\u9884\u6d4b\u5668\u7ed3\u5408\u7247\u5916\u8bbf\u95ee\u9884\u6d4b\u4e0e\u4e00\u7ea7\u6570\u636e\u7f13\u5b58\u9884\u53d6\u8fc7\u6ee4\uff0c\u4ec5\u97007KB\u5b58\u50a8\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u51cf\u5c11DRAM\u4e8b\u52a1\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u7f13\u89e3\u5927\u6570\u636e\u5e94\u7528\u7684\u6027\u80fd\u548c\u80fd\u8017\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u7531FLP\u548cSLP\u7ec4\u6210\u7684TLP\u9884\u6d4b\u5668\uff0cFLP\u7528\u865a\u62df\u5730\u5740\u548c\u9009\u62e9\u6027\u5ef6\u8fdf\u7ec4\u4ef6\u8fdb\u884c\u7247\u5916\u9884\u6d4b\uff0cSLP\u7528\u7269\u7406\u5730\u5740\u548cFLP\u9884\u6d4b\u7ed3\u679c\u9a71\u52a8L1D\u9884\u53d6\u8fc7\u6ee4\u3002", "result": "TLP\u5728\u5355\u6838\u548c\u591a\u6838\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5206\u522b\u51cf\u5c1130.7%\u548c17.7%\u7684DRAM\u4e8b\u52a1\uff0c\u5206\u522b\u5b9e\u73b06.2%\u548c11.8%\u7684\u6027\u80fd\u52a0\u901f\u3002", "conclusion": "TLP\u6709\u6548\u4e14\u72ec\u7acb\u4e8eL1D\u9884\u53d6\u903b\u8f91\u3002"}}
{"id": "2511.00266", "pdf": "https://arxiv.org/pdf/2511.00266", "abs": "https://arxiv.org/abs/2511.00266", "authors": ["Aanchal Rajesh Chugh", "Marion Neumeier", "Sebastian Dorn"], "title": "X-TRACK: Physics-Aware xLSTM for Realistic Vehicle Trajectory Prediction", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Recent advancements in Recurrent Neural Network (RNN) architectures,\nparticularly the Extended Long Short Term Memory (xLSTM), have addressed the\nlimitations of traditional Long Short Term Memory (LSTM) networks by\nintroducing exponential gating and enhanced memory structures. These\nimprovements make xLSTM suitable for time-series prediction tasks as they\nexhibit the ability to model long-term temporal dependencies better than LSTMs.\nDespite their potential, these xLSTM-based models remain largely unexplored in\nthe context of vehicle trajectory prediction. Therefore, this paper introduces\na novel xLSTM-based vehicle trajectory prediction framework, X-TRAJ, and its\nphysics-aware variant, X-TRACK (eXtended LSTM for TRAjectory prediction\nConstraint by Kinematics), which explicitly integrates vehicle motion\nkinematics into the model learning process. By introducing physical\nconstraints, the proposed model generates realistic and feasible trajectories.\nA comprehensive evaluation on the highD and NGSIM datasets demonstrates that\nX-TRACK outperforms state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8exLSTM\u7684\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6X - TRAJ\u53ca\u5176\u7269\u7406\u611f\u77e5\u53d8\u4f53X - TRACK\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "xLSTM\u5728\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u4e14\u4f20\u7edfLSTM\u6709\u5c40\u9650\u6027\uff0c\u56e0\u6b64\u5e0c\u671b\u5229\u7528xLSTM\u4f18\u52bf\u8fdb\u884c\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8exLSTM\u7684\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6X - TRAJ\u548c\u7269\u7406\u611f\u77e5\u53d8\u4f53X - TRACK\uff0c\u5c06\u8f66\u8f86\u8fd0\u52a8\u5b66\u878d\u5165\u6a21\u578b\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u5728highD\u548cNGSIM\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0cX - TRACK\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u5f15\u5165\u7269\u7406\u7ea6\u675f\u7684\u57fa\u4e8exLSTM\u7684\u6a21\u578b\u80fd\u751f\u6210\u73b0\u5b9e\u53ef\u884c\u7684\u8f68\u8ff9\uff0c\u53ef\u7528\u4e8e\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u3002"}}
{"id": "2511.00004", "pdf": "https://arxiv.org/pdf/2511.00004", "abs": "https://arxiv.org/abs/2511.00004", "authors": ["Adrian-Dinu Urse", "Dumitru-Clementin Cercel", "Florin Pop"], "title": "Multimodal Learning with Augmentation Techniques for Natural Disaster Assessment", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.CV"], "comment": "Accepted at 2025 IEEE 21st International Conference on Intelligent\n  Computer Communication and Processing (ICCP 2025)", "summary": "Natural disaster assessment relies on accurate and rapid access to\ninformation, with social media emerging as a valuable real-time source.\nHowever, existing datasets suffer from class imbalance and limited samples,\nmaking effective model development a challenging task. This paper explores\naugmentation techniques to address these issues on the CrisisMMD multimodal\ndataset. For visual data, we apply diffusion-based methods, namely Real\nGuidance and DiffuseMix. For text data, we explore back-translation,\nparaphrasing with transformers, and image caption-based augmentation. We\nevaluated these across unimodal, multimodal, and multi-view learning setups.\nResults show that selected augmentations improve classification performance,\nparticularly for underrepresented classes, while multi-view learning introduces\npotential but requires further refinement. This study highlights effective\naugmentation strategies for building more robust disaster assessment systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u5728CrisisMMD\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u589e\u5f3a\u6280\u672f\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6837\u672c\u6709\u9650\u95ee\u9898\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u589e\u5f3a\u65b9\u6cd5\u5728\u4e0d\u540c\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u7684\u6548\u679c\uff0c\u7ed3\u679c\u8868\u660e\u6240\u9009\u589e\u5f3a\u65b9\u6cd5\u80fd\u63d0\u5347\u5206\u7c7b\u6027\u80fd\uff0c\u5c24\u5176\u5bf9\u5c11\u6570\u7c7b\uff0c\u591a\u89c6\u56fe\u5b66\u4e60\u6709\u6f5c\u529b\u4f46\u9700\u5b8c\u5584\u3002", "motivation": "\u81ea\u7136\u707e\u5bb3\u8bc4\u4f30\u9700\u51c6\u786e\u5feb\u901f\u83b7\u53d6\u4fe1\u606f\uff0c\u793e\u4ea4\u5a92\u4f53\u662f\u6709\u4ef7\u503c\u7684\u5b9e\u65f6\u4fe1\u606f\u6e90\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6837\u672c\u6709\u9650\u95ee\u9898\uff0c\u96be\u4ee5\u6709\u6548\u5f00\u53d1\u6a21\u578b\u3002", "method": "\u5bf9\u89c6\u89c9\u6570\u636e\u5e94\u7528\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\uff08Real Guidance\u548cDiffuseMix\uff09\uff0c\u5bf9\u6587\u672c\u6570\u636e\u63a2\u7d22\u56de\u8bd1\u3001\u57fa\u4e8eTransformer\u7684\u91ca\u4e49\u548c\u57fa\u4e8e\u56fe\u50cf\u5b57\u5e55\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u5e76\u5728\u5355\u6a21\u6001\u3001\u591a\u6a21\u6001\u548c\u591a\u89c6\u56fe\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6240\u9009\u589e\u5f3a\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5206\u7c7b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u5c11\u6570\u7c7b\uff0c\u591a\u89c6\u56fe\u5b66\u4e60\u6709\u6f5c\u529b\u4f46\u9700\u8fdb\u4e00\u6b65\u5b8c\u5584\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u707e\u5bb3\u8bc4\u4f30\u7cfb\u7edf\u7684\u6709\u6548\u589e\u5f3a\u7b56\u7565\u3002"}}
{"id": "2511.00272", "pdf": "https://arxiv.org/pdf/2511.00272", "abs": "https://arxiv.org/abs/2511.00272", "authors": ["Michiel Straat", "Thorben Markmann", "Sebastian Peitz", "Barbara Hammer"], "title": "Improving the Robustness of Control of Chaotic Convective Flows with Domain-Informed Reinforcement Learning", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Chaotic convective flows arise in many real-world systems, such as\nmicrofluidic devices and chemical reactors. Stabilizing these flows is highly\ndesirable but remains challenging, particularly in chaotic regimes where\nconventional control methods often fail. Reinforcement Learning (RL) has shown\npromise for control in laminar flow settings, but its ability to generalize and\nremain robust under chaotic and turbulent dynamics is not well explored,\ndespite being critical for real-world deployment. In this work, we improve the\npractical feasibility of RL-based control of such flows focusing on\nRayleigh-B\\'enard Convection (RBC), a canonical model for convective heat\ntransport. To enhance generalization and sample efficiency, we introduce\ndomain-informed RL agents that are trained using Proximal Policy Optimization\nacross diverse initial conditions and flow regimes. We incorporate domain\nknowledge in the reward function via a term that encourages B\\'enard cell\nmerging, as an example of a desirable macroscopic property. In laminar flow\nregimes, the domain-informed RL agents reduce convective heat transport by up\nto 33%, and in chaotic flow regimes, they still achieve a 10% reduction, which\nis significantly better than the conventional controllers used in practice. We\ncompare the domain-informed to uninformed agents: Our results show that the\ndomain-informed reward design results in steady flows, faster convergence\nduring training, and generalization across flow regimes without retraining. Our\nwork demonstrates that elegant domain-informed priors can greatly enhance the\nrobustness of RL-based control of chaotic flows, bringing real-world deployment\ncloser.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u745e\u5229 - \u8d1d\u7eb3\u5fb7\u5bf9\u6d41\uff0c\u5f15\u5165\u9886\u57df\u77e5\u8bc6\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u63a7\u5236\u6df7\u6c8c\u5bf9\u6d41\uff0c\u5728\u5c42\u6d41\u548c\u6df7\u6c8c\u6d41\u4e2d\u5747\u6709\u826f\u597d\u6548\u679c\uff0c\u8bc1\u660e\u9886\u57df\u5148\u9a8c\u53ef\u589e\u5f3a\u63a7\u5236\u9c81\u68d2\u6027\u3002", "motivation": "\u7a33\u5b9a\u6df7\u6c8c\u5bf9\u6d41\u5177\u6709\u6311\u6218\u6027\uff0c\u4f20\u7edf\u63a7\u5236\u65b9\u6cd5\u5728\u6df7\u6c8c\u72b6\u6001\u5e38\u5931\u6548\uff0c\u5f3a\u5316\u5b66\u4e60\u5728\u6df7\u6c8c\u548c\u6e4d\u6d41\u52a8\u529b\u5b66\u4e2d\u7684\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u5f85\u63a2\u7d22\u3002", "method": "\u5f15\u5165\u9886\u57df\u77e5\u8bc6\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u5728\u4e0d\u540c\u521d\u59cb\u6761\u4ef6\u548c\u6d41\u6001\u4e0b\u8bad\u7ec3\uff0c\u5728\u5956\u52b1\u51fd\u6570\u4e2d\u878d\u5165\u9886\u57df\u77e5\u8bc6\u3002", "result": "\u5728\u5c42\u6d41\u4e2d\u51cf\u5c11\u5bf9\u6d41\u70ed\u4f20\u8f93\u8fbe33%\uff0c\u5728\u6df7\u6c8c\u6d41\u4e2d\u51cf\u5c1110%\uff0c\u4f18\u4e8e\u4f20\u7edf\u63a7\u5236\u5668\uff1b\u9886\u57df\u77e5\u8bc6\u5956\u52b1\u8bbe\u8ba1\u4f7f\u6d41\u52a8\u66f4\u7a33\u5b9a\u3001\u8bad\u7ec3\u6536\u655b\u66f4\u5feb\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5c31\u80fd\u8de8\u6d41\u6001\u6cdb\u5316\u3002", "conclusion": "\u4f18\u96c5\u7684\u9886\u57df\u77e5\u8bc6\u5148\u9a8c\u53ef\u6781\u5927\u589e\u5f3a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6df7\u6c8c\u6d41\u63a7\u5236\u7684\u9c81\u68d2\u6027\uff0c\u63a8\u52a8\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2511.00011", "pdf": "https://arxiv.org/pdf/2511.00011", "abs": "https://arxiv.org/abs/2511.00011", "authors": ["Alexander Okupnik", "Johannes Schneider", "Kyriakos Flouris"], "title": "Generative human motion mimicking through feature extraction in denoising diffusion settings", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Recent success with large language models has sparked a new wave of verbal\nhuman-AI interaction. While such models support users in a variety of creative\ntasks, they lack the embodied nature of human interaction. Dance, as a primal\nform of human expression, is predestined to complement this experience. To\nexplore creative human-AI interaction exemplified by dance, we build an\ninteractive model based on motion capture (MoCap) data. It generates an\nartificial other by partially mimicking and also \"creatively\" enhancing an\nincoming sequence of movement data. It is the first model, which leverages\nsingle-person motion data and high level features in order to do so and, thus,\nit does not rely on low level human-human interaction data. It combines ideas\nof two diffusion models, motion inpainting, and motion style transfer to\ngenerate movement representations that are both temporally coherent and\nresponsive to a chosen movement reference. The success of the model is\ndemonstrated by quantitatively assessing the convergence of the feature\ndistribution of the generated samples and the test set which serves as\nsimulating the human performer. We show that our generations are first steps to\ncreative dancing with AI as they are both diverse showing various deviations\nfrom the human partner while appearing realistic.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u57fa\u4e8e\u52a8\u4f5c\u6355\u6349\u6570\u636e\u7684\u4ea4\u4e92\u6a21\u578b\uff0c\u63a2\u7d22\u4ee5\u821e\u8e48\u4e3a\u4f8b\u7684\u521b\u610f\u4eba\u673a\u4ea4\u4e92\uff0c\u6a21\u578b\u751f\u6210\u591a\u6837\u4e14\u903c\u771f\u7684\u821e\u8e48\u52a8\u4f5c\uff0c\u662f\u521b\u610f\u4eba\u673a\u5171\u821e\u7684\u7b2c\u4e00\u6b65\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u5177\u8eab\u4ea4\u4e92\u7279\u6027\uff0c\u800c\u821e\u8e48\u4f5c\u4e3a\u4eba\u7c7b\u8868\u8fbe\u7684\u539f\u59cb\u5f62\u5f0f\u53ef\u5f25\u8865\u8fd9\u4e00\u4f53\u9a8c\uff0c\u56e0\u6b64\u63a2\u7d22\u4ee5\u821e\u8e48\u4e3a\u4f8b\u7684\u521b\u610f\u4eba\u673a\u4ea4\u4e92\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u52a8\u4f5c\u6355\u6349\u6570\u636e\u7684\u4ea4\u4e92\u6a21\u578b\uff0c\u7ed3\u5408\u4e24\u4e2a\u6269\u6563\u6a21\u578b\u3001\u52a8\u4f5c\u4fee\u590d\u548c\u52a8\u4f5c\u98ce\u683c\u8fc1\u79fb\u7684\u601d\u60f3\uff0c\u5229\u7528\u5355\u4eba\u52a8\u4f5c\u6570\u636e\u548c\u9ad8\u7ea7\u7279\u5f81\u751f\u6210\u52a8\u4f5c\u8868\u5f81\u3002", "result": "\u901a\u8fc7\u5b9a\u91cf\u8bc4\u4f30\u751f\u6210\u6837\u672c\u4e0e\u6a21\u62df\u4eba\u7c7b\u8868\u6f14\u8005\u7684\u6d4b\u8bd5\u96c6\u7684\u7279\u5f81\u5206\u5e03\u6536\u655b\u6027\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u6210\u529f\uff0c\u751f\u6210\u7684\u821e\u8e48\u52a8\u4f5c\u591a\u6837\u4e14\u903c\u771f\u3002", "conclusion": "\u6a21\u578b\u7684\u751f\u6210\u7ed3\u679c\u662f\u521b\u610f\u4eba\u673a\u5171\u821e\u7684\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2511.00280", "pdf": "https://arxiv.org/pdf/2511.00280", "abs": "https://arxiv.org/abs/2511.00280", "authors": ["Abhinav Joshi", "Areeb Ahmad", "Ashutosh Modi"], "title": "Calibration Across Layers: Understanding Calibration Evolution in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted at EMNLP 2025 (main)", "summary": "Large Language Models (LLMs) have demonstrated inherent calibration\ncapabilities, where predicted probabilities align well with correctness,\ndespite prior findings that deep neural networks are often overconfident.\nRecent studies have linked this behavior to specific components in the final\nlayer, such as entropy neurons and the unembedding matrix null space. In this\nwork, we provide a complementary perspective by investigating how calibration\nevolves throughout the network depth. Analyzing multiple open-weight models on\nthe MMLU benchmark, we uncover a distinct confidence correction phase in the\nupper/later layers, where model confidence is actively recalibrated after\ndecision certainty has been reached. Furthermore, we identify a low-dimensional\ncalibration direction in the residual stream whose perturbation significantly\nimproves calibration metrics (ECE and MCE) without harming accuracy. Our\nfindings suggest that calibration is a distributed phenomenon, shaped\nthroughout the network forward pass, not just in its final projection,\nproviding new insights into how confidence-regulating mechanisms operate within\nLLMs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u6821\u51c6\u80fd\u529b\u5728\u7f51\u7edc\u6df1\u5ea6\u4e2d\u7684\u6f14\u53d8\uff0c\u53d1\u73b0\u4e0a\u5c42\u6709\u4fe1\u5fc3\u6821\u6b63\u9636\u6bb5\u53ca\u4f4e\u7ef4\u6821\u51c6\u65b9\u5411\uff0c\u8868\u660e\u6821\u51c6\u662f\u5206\u5e03\u5f0f\u73b0\u8c61\u3002", "motivation": "\u6b64\u524d\u7814\u7a76\u5173\u6ce8\u6700\u7ec8\u5c42\u7279\u5b9a\u7ec4\u4ef6\u4e0e\u6821\u51c6\u80fd\u529b\u7684\u5173\u7cfb\uff0c\u672c\u6587\u4ece\u7f51\u7edc\u6df1\u5ea6\u89d2\u5ea6\u63d0\u4f9b\u8865\u5145\u89c6\u89d2\u7814\u7a76\u6821\u51c6\u80fd\u529b\u6f14\u53d8\u3002", "method": "\u5728MMLU\u57fa\u51c6\u4e0a\u5206\u6790\u591a\u4e2a\u5f00\u653e\u6743\u91cd\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u4e0a\u5c42\u6709\u4fe1\u5fc3\u6821\u6b63\u9636\u6bb5\uff0c\u5728\u51b3\u7b56\u786e\u5b9a\u6027\u8fbe\u6210\u540e\u91cd\u65b0\u6821\u51c6\u6a21\u578b\u4fe1\u5fc3\uff1b\u8bc6\u522b\u51fa\u6b8b\u5dee\u6d41\u4e2d\u7684\u4f4e\u7ef4\u6821\u51c6\u65b9\u5411\uff0c\u6270\u52a8\u8be5\u65b9\u5411\u53ef\u6539\u5584\u6821\u51c6\u6307\u6807\u4e14\u4e0d\u635f\u5bb3\u51c6\u786e\u7387\u3002", "conclusion": "\u6821\u51c6\u662f\u5206\u5e03\u5f0f\u73b0\u8c61\uff0c\u5728\u7f51\u7edc\u524d\u5411\u4f20\u64ad\u4e2d\u5f62\u6210\uff0c\u4e0d\u4ec5\u5728\u6700\u7ec8\u6295\u5f71\u5c42\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u4fe1\u5fc3\u8c03\u8282\u673a\u5236\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2511.00301", "pdf": "https://arxiv.org/pdf/2511.00301", "abs": "https://arxiv.org/abs/2511.00301", "authors": ["Ciaran Bench", "Oskar Pfeffer", "Vivek Desai", "Mohammad Moulaeifard", "Lo\u00efc Coquelin", "Peter H. Charlton", "Nils Strodthoff", "Nando Hegemann", "Philip J. Aston", "Andrew Thompson"], "title": "A systematic evaluation of uncertainty quantification techniques in deep learning: a case study in photoplethysmography signal analysis", "categories": ["cs.LG", "physics.med-ph"], "comment": null, "summary": "In principle, deep learning models trained on medical time-series, including\nwearable photoplethysmography (PPG) sensor data, can provide a means to\ncontinuously monitor physiological parameters outside of clinical settings.\nHowever, there is considerable risk of poor performance when deployed in\npractical measurement scenarios leading to negative patient outcomes. Reliable\nuncertainties accompanying predictions can provide guidance to clinicians in\ntheir interpretation of the trustworthiness of model outputs. It is therefore\nof interest to compare the effectiveness of different approaches. Here we\nimplement an unprecedented set of eight uncertainty quantification (UQ)\ntechniques to models trained on two clinically relevant prediction tasks:\nAtrial Fibrillation (AF) detection (classification), and two variants of blood\npressure regression. We formulate a comprehensive evaluation procedure to\nenable a rigorous comparison of these approaches. We observe a complex picture\nof uncertainty reliability across the different techniques, where the most\noptimal for a given task depends on the chosen expression of uncertainty,\nevaluation metric, and scale of reliability assessed. We find that assessing\nlocal calibration and adaptivity provides practically relevant insights about\nmodel behaviour that otherwise cannot be acquired using more commonly\nimplemented global reliability metrics. We emphasise that criteria for\nevaluating UQ techniques should cater to the model's practical use case, where\nthe use of a small number of measurements per patient places a premium on\nachieving small-scale reliability for the chosen expression of uncertainty,\nwhile preserving as much predictive performance as possible.", "AI": {"tldr": "\u672c\u6587\u5728\u4e24\u4e2a\u4e34\u5e8a\u76f8\u5173\u9884\u6d4b\u4efb\u52a1\u6a21\u578b\u4e0a\u5b9e\u73b0\u516b\u79cd\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u6280\u672f\uff0c\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u548c\u6bd4\u8f83\uff0c\u53d1\u73b0\u8bc4\u4f30\u5c40\u90e8\u6821\u51c6\u548c\u9002\u5e94\u6027\u80fd\u63d0\u4f9b\u6a21\u578b\u884c\u4e3a\u7684\u5b9e\u7528\u89c1\u89e3\uff0c\u5f3a\u8c03\u8bc4\u4f30UQ\u6280\u672f\u5e94\u8d34\u5408\u5b9e\u9645\u7528\u4f8b\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5b9e\u9645\u6d4b\u91cf\u573a\u666f\u4e2d\u6027\u80fd\u4e0d\u4f73\uff0c\u53ef\u9760\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u53ef\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u6307\u5bfc\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u6bd4\u8f83\u4e0d\u540cUQ\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u5728\u4e24\u4e2a\u4e34\u5e8a\u76f8\u5173\u9884\u6d4b\u4efb\u52a1\uff08\u623f\u98a4\u68c0\u6d4b\u548c\u8840\u538b\u56de\u5f52\uff09\u7684\u6a21\u578b\u4e0a\u5b9e\u73b0\u516b\u79cdUQ\u6280\u672f\uff0c\u5e76\u5236\u5b9a\u7efc\u5408\u8bc4\u4f30\u7a0b\u5e8f\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u4e0d\u540c\u6280\u672f\u7684\u4e0d\u786e\u5b9a\u6027\u53ef\u9760\u6027\u60c5\u51b5\u590d\u6742\uff0c\u6700\u4f18\u9009\u62e9\u53d6\u51b3\u4e8e\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u65b9\u5f0f\u3001\u8bc4\u4f30\u6307\u6807\u548c\u53ef\u9760\u6027\u5c3a\u5ea6\uff1b\u8bc4\u4f30\u5c40\u90e8\u6821\u51c6\u548c\u9002\u5e94\u6027\u80fd\u63d0\u4f9b\u7528\u5e38\u89c4\u5168\u5c40\u53ef\u9760\u6027\u6307\u6807\u65e0\u6cd5\u83b7\u5f97\u7684\u6a21\u578b\u884c\u4e3a\u89c1\u89e3\u3002", "conclusion": "\u8bc4\u4f30UQ\u6280\u672f\u7684\u6807\u51c6\u5e94\u9002\u5e94\u6a21\u578b\u7684\u5b9e\u9645\u7528\u4f8b\uff0c\u5728\u9009\u62e9\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u65b9\u5f0f\u4e0a\u5b9e\u73b0\u5c0f\u89c4\u6a21\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5c3d\u53ef\u80fd\u4fdd\u7559\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.00021", "pdf": "https://arxiv.org/pdf/2511.00021", "abs": "https://arxiv.org/abs/2511.00021", "authors": ["Julio Jerison E. Macrohon", "Gordon Hung"], "title": "Deep Learning Models for Coral Bleaching Classification in Multi-Condition Underwater Image Datasets", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 10 figures", "summary": "Coral reefs support numerous marine organisms and are an important source of\ncoastal protection from storms and floods, representing a major part of marine\necosystems. However coral reefs face increasing threats from pollution, ocean\nacidification, and sea temperature anomalies, making efficient protection and\nmonitoring heavily urgent. Therefore, this study presents a novel\nmachine-learning-based coral bleaching classification system based on a diverse\nglobal dataset with samples of healthy and bleached corals under varying\nenvironmental conditions, including deep seas, marshes, and coastal zones. We\nbenchmarked and compared three state-of-the-art models: Residual Neural Network\n(ResNet), Vision Transformer (ViT), and Convolutional Neural Network (CNN).\nAfter comprehensive hyperparameter tuning, the CNN model achieved the highest\naccuracy of 88%, outperforming existing benchmarks. Our findings offer\nimportant insights into autonomous coral monitoring and present a comprehensive\nanalysis of the most widely used computer vision models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5168\u7403\u591a\u6837\u6570\u636e\u96c6\u7684\u73ca\u745a\u767d\u5316\u5206\u7c7b\u7cfb\u7edf\uff0c\u5bf9\u6bd4\u4e09\u79cd\u6a21\u578b\uff0cCNN \u51c6\u786e\u7387\u8fbe 88%\uff0c\u4e3a\u73ca\u745a\u76d1\u6d4b\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u73ca\u745a\u7901\u9762\u4e34\u6c61\u67d3\u3001\u9178\u5316\u7b49\u5a01\u80c1\uff0c\u9700\u6709\u6548\u4fdd\u62a4\u548c\u76d1\u6d4b\u3002", "method": "\u57fa\u4e8e\u5168\u7403\u591a\u6837\u6570\u636e\u96c6\u6784\u5efa\u673a\u5668\u5b66\u4e60\u73ca\u745a\u767d\u5316\u5206\u7c7b\u7cfb\u7edf\uff0c\u5bf9\u6bd4 ResNet\u3001ViT \u548c CNN \u4e09\u79cd\u6a21\u578b\u5e76\u8c03\u53c2\u3002", "result": "CNN \u6a21\u578b\u7ecf\u8c03\u53c2\u540e\u51c6\u786e\u7387\u8fbe 88%\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u73ca\u745a\u81ea\u4e3b\u76d1\u6d4b\u63d0\u4f9b\u91cd\u8981\u89c1\u89e3\uff0c\u5bf9\u5e38\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u8fdb\u884c\u7efc\u5408\u5206\u6790\u3002"}}
{"id": "2511.00024", "pdf": "https://arxiv.org/pdf/2511.00024", "abs": "https://arxiv.org/abs/2511.00024", "authors": ["Haotian Hang", "Yueyang Shen", "Vicky Zhu", "Jose Cruz", "Michelle Li"], "title": "Chitchat with AI: Understand the supply chain carbon disclosure of companies worldwide through Large Language Model", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG", "stat.AP"], "comment": null, "summary": "In the context of global sustainability mandates, corporate carbon disclosure\nhas emerged as a critical mechanism for aligning business strategy with\nenvironmental responsibility. The Carbon Disclosure Project (CDP) hosts the\nworld's largest longitudinal dataset of climate-related survey responses,\ncombining structured indicators with open-ended narratives, but the\nheterogeneity and free-form nature of these disclosures present significant\nanalytical challenges for benchmarking, compliance monitoring, and investment\nscreening. This paper proposes a novel decision-support framework that\nleverages large language models (LLMs) to assess corporate climate disclosure\nquality at scale. It develops a master rubric that harmonizes narrative scoring\nacross 11 years of CDP data (2010-2020), enabling cross-sector and\ncross-country benchmarking. By integrating rubric-guided scoring with\npercentile-based normalization, our method identifies temporal trends,\nstrategic alignment patterns, and inconsistencies in disclosure across\nindustries and regions. Results reveal that sectors such as technology and\ncountries like Germany consistently demonstrate higher rubric alignment, while\nothers exhibit volatility or superficial engagement, offering insights that\ninform key decision-making processes for investors, regulators, and corporate\nenvironmental, social, and governance (ESG) strategists. The proposed LLM-based\napproach transforms unstructured disclosures into quantifiable, interpretable,\ncomparable, and actionable intelligence, advancing the capabilities of\nAI-enabled decision support systems (DSSs) in the domain of climate governance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4f01\u4e1a\u6c14\u5019\u62ab\u9732\u8d28\u91cf\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u5904\u7406CDP\u6570\u636e\u5e76\u63ed\u793a\u4e0d\u540c\u884c\u4e1a\u548c\u5730\u533a\u62ab\u9732\u60c5\u51b5\uff0c\u63a8\u52a8\u6c14\u5019\u6cbb\u7406\u4e2dAI\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u4f01\u4e1a\u78b3\u62ab\u9732\u5728\u5168\u7403\u53ef\u6301\u7eed\u6027\u8981\u6c42\u4e0b\u81f3\u5173\u91cd\u8981\uff0c\u4f46CDP\u6570\u636e\u7684\u5f02\u8d28\u6027\u548c\u81ea\u7531\u5f62\u5f0f\u7ed9\u5206\u6790\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6\uff0c\u5f00\u53d1\u4e3b\u8bc4\u5206\u89c4\u5219\uff0c\u6574\u5408\u89c4\u5219\u5f15\u5bfc\u8bc4\u5206\u548c\u57fa\u4e8e\u767e\u5206\u4f4d\u7684\u6807\u51c6\u5316\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u79d1\u6280\u7b49\u884c\u4e1a\u548c\u5fb7\u56fd\u7b49\u56fd\u5bb6\u5728\u8bc4\u5206\u89c4\u5219\u4e0a\u4e00\u81f4\u6027\u8f83\u9ad8\uff0c\u5176\u4ed6\u884c\u4e1a\u548c\u5730\u533a\u5b58\u5728\u6ce2\u52a8\u6216\u8868\u9762\u53c2\u4e0e\u60c5\u51b5\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5c06\u975e\u7ed3\u6784\u5316\u62ab\u9732\u8f6c\u5316\u4e3a\u53ef\u91cf\u5316\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u6bd4\u548c\u53ef\u64cd\u4f5c\u7684\u4fe1\u606f\uff0c\u63d0\u5347\u6c14\u5019\u6cbb\u7406\u4e2dAI\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u80fd\u529b\u3002"}}
{"id": "2511.00351", "pdf": "https://arxiv.org/pdf/2511.00351", "abs": "https://arxiv.org/abs/2511.00351", "authors": ["Amir Ziashahabi", "Yavuz Faruk Bakman", "Duygu Nur Yaldiz", "Mostafa El-Khamy", "Sai Praneeth Karimireddy", "Salman Avestimehr"], "title": "Reject Only Critical Tokens: Pivot-Aware Speculative Decoding", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted at NeurIPS 2025 Efficient Reasoning Workshop", "summary": "Speculative Decoding (SD) ensures that the output matches the target model's\ndistribution exactly. However, we argue that this distribution matching\nrequirement is too stringent and results in unnecessarily low acceptance rates,\nlimiting potential speedups. Instead, we advocate a reformulation of the\ndecoding objective: the proposed decoding strategy should match the expected\nutility, i.e., the task-specific performance, of the target model. This\nperspective also aligns better with real-world use cases of LLMs, where utility\n(e.g., code correctness, factual accuracy) is often more important than\nsampling distribution. Based on this reformulation, we propose a novel decoding\nstrategy: Pivot-Aware Speculative Decoding, which rejects only those tokens\nthat would lead to a utility drop in the final output. We refer to these\ncritical tokens as pivot tokens. We propose a method for labeling tokens as\npivotal or non-pivotal and train a lightweight classifier to detect them. This\nmethod can be viewed as a relaxed version of standard SD, which offers much\nhigher acceptance while preserving utility. We evaluate our method across\nvarious datasets, demonstrating that we can achieve up to $2.5\\times$ speedup\nwith comparable utility. Source code is available at\nhttps://github.com/amir-zsh/PAD.", "AI": {"tldr": "\u6307\u51fa\u6295\u673a\u89e3\u7801\u5206\u5e03\u5339\u914d\u8981\u6c42\u8fc7\u4e25\uff0c\u63d0\u51fa\u4ee5\u5339\u914d\u76ee\u6807\u6a21\u578b\u9884\u671f\u6548\u7528\u4e3a\u89e3\u7801\u76ee\u6807\uff0c\u63d0\u51faPivot - Aware Speculative Decoding\u7b56\u7565\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5b9e\u73b02.5\u500d\u52a0\u901f\u4e14\u6548\u7528\u76f8\u5f53\u3002", "motivation": "\u73b0\u6709\u6295\u673a\u89e3\u7801\u7684\u5206\u5e03\u5339\u914d\u8981\u6c42\u8fc7\u4e25\uff0c\u5bfc\u81f4\u63a5\u53d7\u7387\u4f4e\uff0c\u9650\u5236\u52a0\u901f\u6f5c\u529b\uff0c\u4e14\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u73b0\u5b9e\u5e94\u7528\u4e2d\u5bf9\u6548\u7528\u7684\u5173\u6ce8\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51faPivot - Aware Speculative Decoding\u7b56\u7565\uff0c\u62d2\u7edd\u5bfc\u81f4\u6700\u7ec8\u8f93\u51fa\u6548\u7528\u4e0b\u964d\u7684\u5173\u952e\u6807\u8bb0\uff08pivot tokens\uff09\uff0c\u63d0\u51fa\u6807\u8bb0\u65b9\u6cd5\u5e76\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u68c0\u6d4b\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u53ef\u5b9e\u73b0\u9ad8\u8fbe2.5\u500d\u7684\u52a0\u901f\uff0c\u4e14\u6548\u7528\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4f5c\u4e3a\u6807\u51c6\u6295\u673a\u89e3\u7801\u7684\u5bbd\u677e\u7248\u672c\uff0c\u80fd\u5728\u4fdd\u6301\u6548\u7528\u7684\u540c\u65f6\u63d0\u4f9b\u66f4\u9ad8\u63a5\u53d7\u7387\uff0c\u5b9e\u73b0\u52a0\u901f\u3002"}}
{"id": "2511.00027", "pdf": "https://arxiv.org/pdf/2511.00027", "abs": "https://arxiv.org/abs/2511.00027", "authors": ["Josu Eguiluz Casta\u00f1eira", "Axel Brando", "Migle Laukyte", "Marc Serra-Vidal"], "title": "Position Paper: If Innovation in AI Systematically Violates Fundamental Rights, Is It Innovation at All?", "categories": ["cs.CY", "cs.AI", "cs.LG", "stat.AP"], "comment": "NeurIPS 2025 Position Paper track; accepted for oral and poster\n  presentation at the Thirty-Ninth Annual Conference on Neural Information\n  Processing Systems", "summary": "Artificial intelligence (AI) now permeates critical infrastructures and\ndecision-making systems where failures produce social, economic, and democratic\nharm. This position paper challenges the entrenched belief that regulation and\ninnovation are opposites. As evidenced by analogies from aviation,\npharmaceuticals, and welfare systems and recent cases of synthetic\nmisinformation, bias and unaccountable decision-making, the absence of\nwell-designed regulation has already created immeasurable damage. Regulation,\nwhen thoughtful and adaptive, is not a brake on innovation--it is its\nfoundation. The present position paper examines the EU AI Act as a model of\nrisk-based, responsibility-driven regulation that addresses the Collingridge\nDilemma: acting early enough to prevent harm, yet flexibly enough to sustain\ninnovation. Its adaptive mechanisms--regulatory sandboxes, small and medium\nenterprises (SMEs) support, real-world testing, fundamental rights impact\nassessment (FRIA) -- demonstrate how regulation can accelerate responsibly,\nrather than delay, technological progress. The position paper summarises how\ngovernance tools transform perceived burdens into tangible advantages: legal\ncertainty, consumer trust, and ethical competitiveness. Ultimately, the paper\nreframes progress: innovation and regulation advance together. By embedding\ntransparency, impact assessments, accountability, and AI literacy into design\nand deployment, the EU framework defines what responsible innovation truly\nmeans--technological ambition disciplined by democratic values and fundamental\nrights.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u76d1\u7ba1\u4e0e\u521b\u65b0\u5bf9\u7acb\u7684\u89c2\u70b9\uff0c\u4ee5\u6b27\u76dfAI\u6cd5\u6848\u4e3a\u4f8b\uff0c\u8bf4\u660e\u5408\u7406\u76d1\u7ba1\u662f\u521b\u65b0\u57fa\u7840\uff0c\u4e8c\u8005\u53ef\u5171\u540c\u63a8\u8fdb\u3002", "motivation": "\u9488\u5bf9\u4eba\u5de5\u667a\u80fd\u5728\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u548c\u51b3\u7b56\u7cfb\u7edf\u5e94\u7528\u4e2d\uff0c\u7f3a\u4e4f\u826f\u597d\u76d1\u7ba1\u5df2\u9020\u6210\u635f\u5bb3\uff0c\u6311\u6218\u76d1\u7ba1\u4e0e\u521b\u65b0\u5bf9\u7acb\u7684\u56fa\u6709\u89c2\u5ff5\u3002", "method": "\u901a\u8fc7\u822a\u7a7a\u3001\u5236\u836f\u3001\u798f\u5229\u7cfb\u7edf\u7c7b\u6bd4\u4ee5\u53ca\u5408\u6210\u865a\u5047\u4fe1\u606f\u7b49\u6848\u4f8b\u8bba\u8bc1\uff0c\u5206\u6790\u6b27\u76dfAI\u6cd5\u6848\u7684\u81ea\u9002\u5e94\u673a\u5236\u3002", "result": "\u6cbb\u7406\u5de5\u5177\u80fd\u5c06\u76d1\u7ba1\u8d1f\u62c5\u8f6c\u5316\u4e3a\u6cd5\u5f8b\u786e\u5b9a\u6027\u3001\u6d88\u8d39\u8005\u4fe1\u4efb\u548c\u9053\u5fb7\u7ade\u4e89\u529b\u7b49\u4f18\u52bf\u3002", "conclusion": "\u521b\u65b0\u548c\u76d1\u7ba1\u5e94\u5171\u540c\u63a8\u8fdb\uff0c\u6b27\u76df\u6846\u67b6\u5b9a\u4e49\u4e86\u8d1f\u8d23\u4efb\u521b\u65b0\u7684\u542b\u4e49\u3002"}}
{"id": "2511.00028", "pdf": "https://arxiv.org/pdf/2511.00028", "abs": "https://arxiv.org/abs/2511.00028", "authors": ["Hanyang Chen", "Yanchao Yang"], "title": "Mutual Information guided Visual Contrastive Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Tech Report - Undergraduate Thesis - 2023", "summary": "Representation learning methods utilizing the InfoNCE loss have demonstrated\nconsiderable capacity in reducing human annotation effort by training invariant\nneural feature extractors. Although different variants of the training\nobjective adhere to the information maximization principle between the data and\nlearned features, data selection and augmentation still rely on human\nhypotheses or engineering, which may be suboptimal. For instance, data\naugmentation in contrastive learning primarily focuses on color jittering,\naiming to emulate real-world illumination changes. In this work, we investigate\nthe potential of selecting training data based on their mutual information\ncomputed from real-world distributions, which, in principle, should endow the\nlearned features with better generalization when applied in open environments.\nSpecifically, we consider patches attached to scenes that exhibit high mutual\ninformation under natural perturbations, such as color changes and motion, as\npositive samples for learning with contrastive loss. We evaluate the proposed\nmutual-information-informed data augmentation method on several benchmarks\nacross multiple state-of-the-art representation learning frameworks,\ndemonstrating its effectiveness and establishing it as a promising direction\nfor future research.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u57fa\u4e8e\u4e92\u4fe1\u606f\u9009\u62e9\u8bad\u7ec3\u6570\u636e\u7528\u4e8e\u8868\u5f81\u5b66\u4e60\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u8868\u5f81\u5b66\u4e60\u65b9\u6cd5\u7684\u6570\u636e\u9009\u62e9\u548c\u589e\u5f3a\u4f9d\u8d56\u4eba\u5de5\u5047\u8bbe\u6216\u5de5\u7a0b\uff0c\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u7684\uff0c\u5e0c\u671b\u627e\u5230\u66f4\u597d\u7684\u65b9\u6cd5\u8ba9\u5b66\u4e60\u5230\u7684\u7279\u5f81\u5728\u5f00\u653e\u73af\u5883\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u8ba1\u7b97\u6570\u636e\u7684\u4e92\u4fe1\u606f\u6765\u9009\u62e9\u8bad\u7ec3\u6570\u636e\uff0c\u5c06\u5728\u81ea\u7136\u6270\u52a8\u4e0b\u6709\u9ad8\u4e92\u4fe1\u606f\u7684\u573a\u666f\u5757\u4f5c\u4e3a\u6b63\u6837\u672c\u8fdb\u884c\u5bf9\u6bd4\u635f\u5931\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u4e2a\u5148\u8fdb\u8868\u5f81\u5b66\u4e60\u6846\u67b6\u4e2d\u9a8c\u8bc1\u4e86\u4e92\u4fe1\u606f\u5f15\u5bfc\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.00405", "pdf": "https://arxiv.org/pdf/2511.00405", "abs": "https://arxiv.org/abs/2511.00405", "authors": ["Zhibin Lan", "Liqiang Niu", "Fandong Meng", "Jie Zhou", "Jinsong Su"], "title": "UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The remarkable success of multimodal large language models (MLLMs) has driven\nadvances in multimodal embeddings, yet existing models remain inherently\ndiscriminative, limiting their ability to benefit from reasoning-driven\ngeneration paradigm. In this work, we pioneer the exploration of generative\nembeddings, unifying embedding tasks within a generative paradigm. We propose\nUME-R1, a universal multimodal embedding framework consisting of a two-stage\ntraining strategy: a cold-start supervised fine-tuning equips the model with\nreasoning capabilities and enables it to generate both discriminative and\ngenerative embeddings; a subsequent reinforcement learning enhances reasoning\nand further optimizes generative embedding quality. This pioneering work\nreveals four key insights: 1) generative embeddings unlock substantial\nperformance gains over conventional discriminative embeddings by leveraging the\npowerful generative reasoning capabilities of MLLMs; 2) discriminative and\ngenerative embeddings are complementary, whose combined oracle performance far\nexceeding that of either alone; 3) RL can effectively enhance generative\nembeddings, establishing a scalable optimization paradigm.; 4) repeated\nsampling at inference boosts downstream task coverage (pass@k), highlighting\nthe inference-time scalability potential of generative embeddings. Evaluated on\nthe MMEB-V2 benchmark across 78 tasks spanning video, image, and visual\ndocuments, UME-R1 significantly outperforms conventional discriminative\nembedding models and offers a foundation for more interpretable,\nreasoning-driven generative multimodal embeddings. Our code, models, and\ndatasets will be publicly available at https://github.com/XMUDeepLIT/UME-R1.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u751f\u6210\u5f0f\u5d4c\u5165\uff0c\u63d0\u51faUME - R1\u6846\u67b6\uff0c\u5728\u591a\u6a21\u6001\u5d4c\u5165\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6210\u679c\u5e76\u63ed\u793a\u5173\u952e\u89c1\u89e3\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u4e3a\u5224\u522b\u5f0f\uff0c\u9650\u5236\u4e86\u5176\u4ece\u63a8\u7406\u9a71\u52a8\u751f\u6210\u8303\u5f0f\u4e2d\u83b7\u76ca\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u63a2\u7d22\u751f\u6210\u5f0f\u5d4c\u5165\u3002", "method": "\u63d0\u51faUME - R1\u901a\u7528\u591a\u6a21\u6001\u5d4c\u5165\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5148\u51b7\u542f\u52a8\u76d1\u7763\u5fae\u8c03\uff0c\u540e\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728MMEB - V2\u57fa\u51c6\u768478\u4e2a\u4efb\u52a1\u4e0a\uff0cUME - R1\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5224\u522b\u5f0f\u5d4c\u5165\u6a21\u578b\u3002", "conclusion": "\u751f\u6210\u5f0f\u5d4c\u5165\u53ef\u5229\u7528MLLMs\u7684\u751f\u6210\u63a8\u7406\u80fd\u529b\u83b7\u5f97\u6027\u80fd\u63d0\u5347\uff0c\u5224\u522b\u5f0f\u548c\u751f\u6210\u5f0f\u5d4c\u5165\u4e92\u8865\uff0cRL\u53ef\u4f18\u5316\u751f\u6210\u5f0f\u5d4c\u5165\uff0c\u63a8\u7406\u65f6\u91cd\u590d\u91c7\u6837\u80fd\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u8986\u76d6\u7387\u3002"}}
{"id": "2511.00411", "pdf": "https://arxiv.org/pdf/2511.00411", "abs": "https://arxiv.org/abs/2511.00411", "authors": ["Zenghao Niu", "Weicheng Xie", "Siyang Song", "Zitong Yu", "Feng Liu", "Linlin Shen"], "title": "Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "accepted by iccv 2025", "summary": "Adversarial attacks present a critical challenge to deep neural networks'\nrobustness, particularly in transfer scenarios across different model\narchitectures. However, the transferability of adversarial attacks faces a\nfundamental dilemma between Exploitation (maximizing attack potency) and\nExploration (enhancing cross-model generalization). Traditional momentum-based\nmethods over-prioritize Exploitation, i.e., higher loss maxima for attack\npotency but weakened generalization (narrow loss surface). Conversely, recent\nmethods with inner-iteration sampling over-prioritize Exploration, i.e.,\nflatter loss surfaces for cross-model generalization but weakened attack\npotency (suboptimal local maxima). To resolve this dilemma, we propose a simple\nyet effective Gradient-Guided Sampling (GGS), which harmonizes both objectives\nthrough guiding sampling along the gradient ascent direction to improve both\nsampling efficiency and stability. Specifically, based on MI-FGSM, GGS\nintroduces inner-iteration random sampling and guides the sampling direction\nusing the gradient from the previous inner-iteration (the sampling's magnitude\nis determined by a random distribution). This mechanism encourages adversarial\nexamples to reside in balanced regions with both flatness for cross-model\ngeneralization and higher local maxima for strong attack potency. Comprehensive\nexperiments across multiple DNN architectures and multimodal large language\nmodels (MLLMs) demonstrate the superiority of our method over state-of-the-art\ntransfer attacks. Code is made available at https://github.com/anuin-cat/GGS.", "AI": {"tldr": "\u63d0\u51faGradient - Guided Sampling (GGS)\u65b9\u6cd5\u89e3\u51b3\u5bf9\u6297\u653b\u51fb\u53ef\u8fc1\u79fb\u6027\u4e2d\u5f00\u53d1\u4e0e\u63a2\u7d22\u7684\u56f0\u5883\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u6297\u653b\u51fb\u5728\u8de8\u6a21\u578b\u67b6\u6784\u7684\u8fc1\u79fb\u573a\u666f\u4e2d\u9762\u4e34\u5f00\u53d1\uff08\u6700\u5927\u5316\u653b\u51fb\u6548\u529b\uff09\u548c\u63a2\u7d22\uff08\u589e\u5f3a\u8de8\u6a21\u578b\u6cdb\u5316\uff09\u7684\u4e24\u96be\u56f0\u5883\uff0c\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u8fc7\u5ea6\u4fa7\u91cd\u4e00\u65b9\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eMI - FGSM\uff0c\u5f15\u5165\u5185\u8fed\u4ee3\u968f\u673a\u91c7\u6837\uff0c\u5e76\u5229\u7528\u524d\u4e00\u6b21\u5185\u8fed\u4ee3\u7684\u68af\u5ea6\u5f15\u5bfc\u91c7\u6837\u65b9\u5411\uff0c\u91c7\u6837\u5e45\u5ea6\u7531\u968f\u673a\u5206\u5e03\u51b3\u5b9a\u3002", "result": "\u5728\u591a\u4e2aDNN\u67b6\u6784\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u8fc1\u79fb\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "GGS\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5bf9\u6297\u653b\u51fb\u53ef\u8fc1\u79fb\u6027\u4e2d\u7684\u4e24\u96be\u56f0\u5883\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.00033", "pdf": "https://arxiv.org/pdf/2511.00033", "abs": "https://arxiv.org/abs/2511.00033", "authors": ["Diqi He", "Xuehao Gao", "Hao Li", "Junwei Han", "Dingwen Zhang"], "title": "STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The Zero-shot Vision-and-Language Navigation in Continuous Environments\n(VLN-CE) task requires agents to navigate previously unseen 3D environments\nusing natural language instructions, without any scene-specific training. A\ncritical challenge in this setting lies in ensuring agents' actions align with\nboth spatial structure and task intent over long-horizon execution. Existing\nmethods often fail to achieve robust navigation due to a lack of structured\ndecision-making and insufficient integration of feedback from previous actions.\nTo address these challenges, we propose STRIDER (Instruction-Aligned Structural\nDecision Space Optimization), a novel framework that systematically optimizes\nthe agent's decision space by integrating spatial layout priors and dynamic\ntask feedback. Our approach introduces two key innovations: 1) a Structured\nWaypoint Generator that constrains the action space through spatial structure,\nand 2) a Task-Alignment Regulator that adjusts behavior based on task progress,\nensuring semantic alignment throughout navigation. Extensive experiments on the\nR2R-CE and RxR-CE benchmarks demonstrate that STRIDER significantly outperforms\nstrong SOTA across key metrics; in particular, it improves Success Rate (SR)\nfrom 29% to 35%, a relative gain of 20.7%. Such results highlight the\nimportance of spatially constrained decision-making and feedback-guided\nexecution in improving navigation fidelity for zero-shot VLN-CE.", "AI": {"tldr": "\u63d0\u51faSTRIDER\u6846\u67b6\u7528\u4e8e\u96f6\u6837\u672c\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u4efb\u52a1\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8eSOTA\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u7ed3\u6784\u5316\u51b3\u7b56\u548c\u5bf9\u5148\u524d\u52a8\u4f5c\u53cd\u9988\u6574\u5408\u4e0d\u8db3\uff0c\u96be\u4ee5\u5b9e\u73b0\u7a33\u5065\u5bfc\u822a\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faSTRIDER\u6846\u67b6\uff0c\u5305\u62ec\u901a\u8fc7\u7a7a\u95f4\u7ed3\u6784\u7ea6\u675f\u52a8\u4f5c\u7a7a\u95f4\u7684\u7ed3\u6784\u5316\u8def\u70b9\u751f\u6210\u5668\u548c\u6839\u636e\u4efb\u52a1\u8fdb\u5ea6\u8c03\u6574\u884c\u4e3a\u7684\u4efb\u52a1\u5bf9\u9f50\u8c03\u8282\u5668\u3002", "result": "\u5728R2R - CE\u548cRxR - CE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u5f3aSOTA\uff0c\u6210\u529f\u7387\u4ece29%\u63d0\u5347\u523035%\uff0c\u76f8\u5bf9\u589e\u76ca20.7%\u3002", "conclusion": "\u7a7a\u95f4\u7ea6\u675f\u51b3\u7b56\u548c\u53cd\u9988\u5f15\u5bfc\u6267\u884c\u5bf9\u63d0\u9ad8\u96f6\u6837\u672cVLN - CE\u5bfc\u822a\u4fdd\u771f\u5ea6\u5f88\u91cd\u8981\u3002"}}
{"id": "2511.00413", "pdf": "https://arxiv.org/pdf/2511.00413", "abs": "https://arxiv.org/abs/2511.00413", "authors": ["Shaojie Wang", "Jinghui Wang", "Yinghan Cui", "Xuxing Chen", "Chao Wang", "Liang Huang", "Xiaojiang Zhang", "Junyi Peng", "Li Wan", "Haotian Zhang", "Bin Chen"], "title": "Tree Training: Accelerating Agentic LLMs Training via Shared Prefix Reuse", "categories": ["cs.LG"], "comment": null, "summary": "In agentic LLM scenarios, an agent's interaction process during a single\nrollout often exhibits branching behaviors. Due to memory retrieval and\nconcurrent tool executions at certain decision points, the token trajectory of\none task evolves into a tree-like structure rather than a linear sequence.\nHowever, current training pipelines decompose such tree-structured trajectories\ninto separate linear segments, treating each branch as an independent sequence.\nAs a result, shared prefixes across these branches are repeatedly recomputed\nduring both forward and backward passes. To address this inefficiency, we\npropose Tree Training, a paradigm that computes each shared prefix only once\nand reuses its intermediate results across related branches during both forward\nand backward passes, substantially improving computation efficiency in\nlarge-scale agentic training. This is achieved via (i) Tree Packing, which\nefficiently reuses shared computations across trajectories, and (ii) Gradient\nRestoration, which ensures correct gradient propagation across reused prefixes.\nExperiments on multiple open-source models demonstrate up to 3.9x reduction in\ntotal training time, enabling more efficient agentic LLM SFT and RL training.", "AI": {"tldr": "\u5f53\u524d\u8bad\u7ec3\u7ba1\u9053\u5904\u7406\u6811\u72b6\u8f68\u8ff9\u6548\u7387\u4f4e\uff0c\u63d0\u51faTree Training\u8303\u5f0f\uff0c\u901a\u8fc7Tree Packing\u548cGradient Restoration\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u6700\u591a\u53ef\u51cf\u5c113.9\u500d\u8bad\u7ec3\u65f6\u95f4\u3002", "motivation": "\u5f53\u524d\u8bad\u7ec3\u7ba1\u9053\u5c06\u6811\u72b6\u8f68\u8ff9\u5206\u89e3\u4e3a\u7ebf\u6027\u6bb5\uff0c\u5bfc\u81f4\u5171\u4eab\u524d\u7f00\u91cd\u590d\u8ba1\u7b97\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faTree Training\u8303\u5f0f\uff0c\u5305\u62ecTree Packing\u4ee5\u9ad8\u6548\u590d\u7528\u8f68\u8ff9\u95f4\u7684\u5171\u4eab\u8ba1\u7b97\uff0c\u4ee5\u53caGradient Restoration\u786e\u4fdd\u590d\u7528\u524d\u7f00\u4e0a\u7684\u68af\u5ea6\u6b63\u786e\u4f20\u64ad\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u603b\u8bad\u7ec3\u65f6\u95f4\u6700\u591a\u53ef\u51cf\u5c113.9\u500d\u3002", "conclusion": "Tree Training\u8303\u5f0f\u80fd\u6709\u6548\u63d0\u9ad8\u5927\u89c4\u6a21\u667a\u80fd\u4f53\u8bad\u7ec3\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4f7f\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7684\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u66f4\u9ad8\u6548\u3002"}}
{"id": "2511.00418", "pdf": "https://arxiv.org/pdf/2511.00418", "abs": "https://arxiv.org/abs/2511.00418", "authors": ["Victory Obieke", "Emmanuel Oguadimma"], "title": "Structure-Preserving Physics-Informed Neural Network for the Korteweg--de Vries (KdV) Equation", "categories": ["cs.LG", "math-ph", "math.MP", "nlin.PS", "physics.flu-dyn"], "comment": "9 Pages, 11 figures", "summary": "Physics-Informed Neural Networks (PINNs) offer a flexible framework for\nsolving nonlinear partial differential equations (PDEs), yet conventional\nimplementations often fail to preserve key physical invariants during long-term\nintegration. This paper introduces a \\emph{structure-preserving PINN} framework\nfor the nonlinear Korteweg--de Vries (KdV) equation, a prototypical model for\nnonlinear and dispersive wave propagation. The proposed method embeds the\nconservation of mass and Hamiltonian energy directly into the loss function,\nensuring physically consistent and energy-stable evolution throughout training\nand prediction. Unlike standard \\texttt{tanh}-based\nPINNs~\\cite{raissi2019pinn,wang2022modifiedpinn}, our approach employs\nsinusoidal activation functions that enhance spectral expressiveness and\naccurately capture the oscillatory and dispersive nature of KdV solitons.\nThrough representative case studies -- including single-soliton propagation\n(shape-preserving translation), two-soliton interaction (elastic collision with\nphase shift), and cosine-pulse initialization (nonlinear dispersive breakup) --\nthe model successfully reproduces hallmark behaviors of KdV dynamics while\nmaintaining conserved invariants. Ablation studies demonstrate that combining\ninvariant-constrained optimization with sinusoidal feature mappings accelerates\nconvergence, improves long-term stability, and mitigates drift without\nmulti-stage pretraining. These results highlight that computationally\nefficient, invariant-aware regularization coupled with sinusoidal\nrepresentations yields robust, energy-consistent PINNs for Hamiltonian partial\ndifferential equations such as the KdV equation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u6784\u4fdd\u7559PINN\u6846\u67b6\u89e3\u51b3KdV\u65b9\u7a0b\uff0c\u5d4c\u5165\u5b88\u6052\u91cf\u5230\u635f\u5931\u51fd\u6570\uff0c\u7528\u6b63\u5f26\u6fc0\u6d3b\u51fd\u6570\uff0c\u7ecf\u6848\u4f8b\u9a8c\u8bc1\u6548\u679c\u597d\u3002", "motivation": "\u4f20\u7edfPINNs\u5728\u957f\u671f\u79ef\u5206\u65f6\u65e0\u6cd5\u4fdd\u7559\u5173\u952e\u7269\u7406\u4e0d\u53d8\u91cf\uff0c\u9700\u89e3\u51b3KdV\u65b9\u7a0b\u6c42\u89e3\u4e2d\u7269\u7406\u4e00\u81f4\u6027\u548c\u80fd\u91cf\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u5c06\u8d28\u91cf\u548c\u54c8\u5bc6\u987f\u80fd\u91cf\u5b88\u6052\u5d4c\u5165\u635f\u5931\u51fd\u6570\uff0c\u91c7\u7528\u6b63\u5f26\u6fc0\u6d3b\u51fd\u6570\u3002", "result": "\u6a21\u578b\u6210\u529f\u590d\u73b0KdV\u52a8\u529b\u5b66\u7279\u5f81\u884c\u4e3a\uff0c\u4fdd\u6301\u5b88\u6052\u4e0d\u53d8\u91cf\uff0c\u6d88\u878d\u7814\u7a76\u8868\u660e\u7ed3\u5408\u4f18\u5316\u548c\u7279\u5f81\u6620\u5c04\u53ef\u52a0\u901f\u6536\u655b\u3001\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u51cf\u5c11\u6f02\u79fb\u3002", "conclusion": "\u8ba1\u7b97\u9ad8\u6548\u3001\u8003\u8651\u4e0d\u53d8\u91cf\u7684\u6b63\u5219\u5316\u4e0e\u6b63\u5f26\u8868\u793a\u7ed3\u5408\uff0c\u80fd\u4e3a\u54c8\u5bc6\u987f\u504f\u5fae\u5206\u65b9\u7a0b\u751f\u6210\u9c81\u68d2\u3001\u80fd\u91cf\u4e00\u81f4\u7684PINNs\u3002"}}
{"id": "2511.00041", "pdf": "https://arxiv.org/pdf/2511.00041", "abs": "https://arxiv.org/abs/2511.00041", "authors": ["Yingzhao Jian", "Zhongan Wang", "Yi Yang", "Hehe Fan"], "title": "Endowing GPT-4 with a Humanoid Body: Building the Bridge Between Off-the-Shelf VLMs and the Physical World", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Humanoid agents often struggle to handle flexible and diverse interactions in\nopen environments. A common solution is to collect massive datasets to train a\nhighly capable model, but this approach can be prohibitively expensive. In this\npaper, we explore an alternative solution: empowering off-the-shelf\nVision-Language Models (VLMs, such as GPT-4) to control humanoid agents,\nthereby leveraging their strong open-world generalization to mitigate the need\nfor extensive data collection. To this end, we present \\textbf{BiBo}\n(\\textbf{B}uilding humano\\textbf{I}d agent \\textbf{B}y \\textbf{O}ff-the-shelf\nVLMs). It consists of two key components: (1) an \\textbf{embodied instruction\ncompiler}, which enables the VLM to perceive the environment and precisely\ntranslate high-level user instructions (e.g., {\\small\\itshape ``have a rest''})\ninto low-level primitive commands with control parameters (e.g.,\n{\\small\\itshape ``sit casually, location: (1, 2), facing: 90$^\\circ$''}); and\n(2) a diffusion-based \\textbf{motion executor}, which generates human-like\nmotions from these commands, while dynamically adapting to physical feedback\nfrom the environment. In this way, BiBo is capable of handling not only basic\ninteractions but also diverse and complex motions. Experiments demonstrate that\nBiBo achieves an interaction task success rate of 90.2\\% in open environments,\nand improves the precision of text-guided motion execution by 16.3\\% over prior\nmethods. The code will be made publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBiBo\u7cfb\u7edf\uff0c\u5229\u7528\u73b0\u6210VLMs\u63a7\u5236\u4eba\u5f62\u667a\u80fd\u4f53\uff0c\u89e3\u51b3\u5176\u5728\u5f00\u653e\u73af\u5883\u4ea4\u4e92\u95ee\u9898\uff0c\u5b9e\u9a8c\u6548\u679c\u826f\u597d\u4e14\u4ee3\u7801\u5c06\u5f00\u6e90\u3002", "motivation": "\u4eba\u5f62\u667a\u80fd\u4f53\u5728\u5f00\u653e\u73af\u5883\u5904\u7406\u7075\u6d3b\u591a\u6837\u4ea4\u4e92\u6709\u56f0\u96be\uff0c\u6536\u96c6\u5927\u91cf\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u6210\u672c\u9ad8\uff0c\u9700\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51faBiBo\u7cfb\u7edf\uff0c\u5305\u542b\u5177\u8eab\u6307\u4ee4\u7f16\u8bd1\u5668\u548c\u57fa\u4e8e\u6269\u6563\u7684\u8fd0\u52a8\u6267\u884c\u5668\u3002", "result": "BiBo\u5728\u5f00\u653e\u73af\u5883\u4ea4\u4e92\u4efb\u52a1\u6210\u529f\u7387\u8fbe90.2%\uff0c\u6587\u672c\u5f15\u5bfc\u8fd0\u52a8\u6267\u884c\u7cbe\u5ea6\u6bd4\u5148\u524d\u65b9\u6cd5\u63d0\u9ad816.3%\u3002", "conclusion": "\u5229\u7528\u73b0\u6210VLMs\u63a7\u5236\u4eba\u5f62\u667a\u80fd\u4f53\u662f\u53ef\u884c\u7684\uff0cBiBo\u80fd\u5904\u7406\u591a\u6837\u590d\u6742\u52a8\u4f5c\u3002"}}
{"id": "2511.00423", "pdf": "https://arxiv.org/pdf/2511.00423", "abs": "https://arxiv.org/abs/2511.00423", "authors": ["Guojian Zhan", "Likun Wang", "Xiangteng Zhang", "Jiaxin Gao", "Masayoshi Tomizuka", "Shengbo Eben Li"], "title": "Bootstrap Off-policy with World Model", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "NeurIPS 2025", "summary": "Online planning has proven effective in reinforcement learning (RL) for\nimproving sample efficiency and final performance. However, using planning for\nenvironment interaction inevitably introduces a divergence between the\ncollected data and the policy's actual behaviors, degrading both model learning\nand policy improvement. To address this, we propose BOOM (Bootstrap Off-policy\nwith WOrld Model), a framework that tightly integrates planning and off-policy\nlearning through a bootstrap loop: the policy initializes the planner, and the\nplanner refines actions to bootstrap the policy through behavior alignment.\nThis loop is supported by a jointly learned world model, which enables the\nplanner to simulate future trajectories and provides value targets to\nfacilitate policy improvement. The core of BOOM is a likelihood-free alignment\nloss that bootstraps the policy using the planner's non-parametric action\ndistribution, combined with a soft value-weighted mechanism that prioritizes\nhigh-return behaviors and mitigates variability in the planner's action quality\nwithin the replay buffer. Experiments on the high-dimensional DeepMind Control\nSuite and Humanoid-Bench show that BOOM achieves state-of-the-art results in\nboth training stability and final performance. The code is accessible at\nhttps://github.com/molumitu/BOOM_MBRL.", "AI": {"tldr": "\u63d0\u51faBOOM\u6846\u67b6\u7ed3\u5408\u89c4\u5212\u4e0e\u79bb\u7b56\u7565\u5b66\u4e60\uff0c\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\u3002", "motivation": "\u5728\u7ebf\u89c4\u5212\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f7f\u7528\u65f6\uff0c\u6536\u96c6\u6570\u636e\u4e0e\u7b56\u7565\u5b9e\u9645\u884c\u4e3a\u6709\u5dee\u5f02\uff0c\u5f71\u54cd\u6a21\u578b\u5b66\u4e60\u548c\u7b56\u7565\u6539\u8fdb\u3002", "method": "\u63d0\u51faBOOM\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5bfc\u5faa\u73af\u7d27\u5bc6\u7ed3\u5408\u89c4\u5212\u4e0e\u79bb\u7b56\u7565\u5b66\u4e60\uff0c\u4f7f\u7528\u8054\u5408\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\uff0c\u6838\u5fc3\u662f\u65e0\u4f3c\u7136\u5bf9\u9f50\u635f\u5931\u548c\u8f6f\u503c\u52a0\u6743\u673a\u5236\u3002", "result": "\u5728\u9ad8\u7ef4DeepMind Control Suite\u548cHumanoid - Bench\u5b9e\u9a8c\u4e2d\uff0cBOOM\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u6027\u80fd\u4e0a\u8fbe\u5230SOTA\u3002", "conclusion": "BOOM\u6846\u67b6\u6709\u6548\uff0c\u4ee3\u7801\u53ef\u5728https://github.com/molumitu/BOOM_MBRL\u83b7\u53d6\u3002"}}
{"id": "2511.00443", "pdf": "https://arxiv.org/pdf/2511.00443", "abs": "https://arxiv.org/abs/2511.00443", "authors": ["Ruthwik Reddy Doodipala", "Pankaj Pandey", "Carolina Torres Rojas", "Manob Jyoti Saikia", "Ranganatha Sitaram"], "title": "Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "The emergence of foundation models in neuroimaging is driven by the\nincreasing availability of large-scale and heterogeneous brain imaging\ndatasets. Recent advances in self-supervised learning, particularly\nreconstruction-based objectives, have demonstrated strong potential for\npretraining models that generalize effectively across diverse downstream\nfunctional MRI (fMRI) tasks. In this study, we explore region-aware\nreconstruction strategies for a foundation model in resting-state fMRI, moving\nbeyond approaches that rely on random region masking. Specifically, we\nintroduce an ROI-guided masking strategy using the Automated Anatomical\nLabelling Atlas (AAL3), applied directly to full 4D fMRI volumes to selectively\nmask semantically coherent brain regions during self-supervised pretraining.\nUsing the ADHD-200 dataset comprising 973 subjects with resting-state fMRI\nscans, we show that our method achieves a 4.23% improvement in classification\naccuracy for distinguishing healthy controls from individuals diagnosed with\nADHD, compared to conventional random masking. Region-level attribution\nanalysis reveals that brain volumes within the limbic region and cerebellum\ncontribute most significantly to reconstruction fidelity and model\nrepresentation. Our results demonstrate that masking anatomical regions during\nmodel pretraining not only enhances interpretability but also yields more\nrobust and discriminative representations. In future work, we plan to extend\nthis approach by evaluating it on additional neuroimaging datasets, and\ndeveloping new loss functions explicitly derived from region-aware\nreconstruction objectives. These directions aim to further improve the\nrobustness and interpretability of foundation models for functional\nneuroimaging.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u9759\u606f\u6001fMRI\u57fa\u7840\u6a21\u578b\u7684\u533a\u57df\u611f\u77e5\u91cd\u5efa\u7b56\u7565\uff0c\u6bd4\u968f\u673a\u63a9\u7801\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8fd8\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u672a\u6765\u5c06\u6269\u5c55\u6570\u636e\u96c6\u5e76\u5f00\u53d1\u65b0\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u5927\u89c4\u6a21\u5f02\u6784\u8111\u6210\u50cf\u6570\u636e\u96c6\u63a8\u52a8\u795e\u7ecf\u5f71\u50cf\u57fa\u7840\u6a21\u578b\u53d1\u5c55\uff0c\u57fa\u4e8e\u91cd\u5efa\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u4e0b\u6e38fMRI\u4efb\u52a1\u4e2d\u8868\u73b0\u597d\uff0c\u63a2\u7d22\u66f4\u597d\u7684\u91cd\u5efa\u7b56\u7565\u3002", "method": "\u5f15\u5165\u57fa\u4e8eAAL3\u56fe\u8c31\u7684ROI\u5f15\u5bfc\u63a9\u7801\u7b56\u7565\uff0c\u76f4\u63a5\u5e94\u7528\u4e8e\u51684D fMRI\u4f53\u79ef\uff0c\u5728\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u4e2d\u9009\u62e9\u6027\u63a9\u7801\u8bed\u4e49\u8fde\u8d2f\u8111\u533a\u3002", "result": "\u5728ADHD - 200\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u4f20\u7edf\u968f\u673a\u63a9\u7801\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u53474.23%\uff1b\u8fb9\u7f18\u7cfb\u7edf\u548c\u5c0f\u8111\u5bf9\u91cd\u5efa\u4fdd\u771f\u5ea6\u548c\u6a21\u578b\u8868\u793a\u8d21\u732e\u6700\u5927\u3002", "conclusion": "\u6a21\u578b\u9884\u8bad\u7ec3\u65f6\u63a9\u7801\u89e3\u5256\u533a\u57df\u53ef\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff0c\u4ea7\u751f\u66f4\u9c81\u68d2\u548c\u6709\u533a\u5206\u6027\u7684\u8868\u793a\u3002\u672a\u6765\u5c06\u6269\u5c55\u6570\u636e\u96c6\u548c\u5f00\u53d1\u65b0\u635f\u5931\u51fd\u6570\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.00462", "pdf": "https://arxiv.org/pdf/2511.00462", "abs": "https://arxiv.org/abs/2511.00462", "authors": ["Xin Chen", "Saili Uday Gadgil", "Kangning Gao", "Yi Hu", "Cong Nie"], "title": "Deep Learning Approach to Anomaly Detection in Enterprise ETL Processes with Autoencoders", "categories": ["cs.LG"], "comment": null, "summary": "An anomaly detection method based on deep autoencoders is proposed to address\nanomalies that often occur in enterprise-level ETL data streams. The study\nfirst analyzes multiple types of anomalies in ETL processes, including delays,\nmissing values, duplicate loading, and sudden abnormal changes, and applies\ndata standardization and feature modeling to ensure stable and usable inputs.\nIn the method design, the encoder-decoder structure compresses high-dimensional\ninputs into latent representations and reconstructs them, while reconstruction\nerror is used to measure anomaly levels. Regularization constraints are\nintroduced in the latent space to enhance feature sparsity and distribution\nlearning, thereby improving robustness in complex data streams. Systematic\nanalyses under different hyperparameter settings, environmental changes, and\ndata characteristics show that the proposed method achieves superior\nperformance in AUC, ACC, Precision, and Recall. The results demonstrate that\nthe deep autoencoder-based detection mechanism can effectively capture latent\ndistribution patterns in enterprise-level ETL data streams and accurately\nidentify diverse anomalies, providing reliable support for enterprise data\nprocessing and intelligent analysis.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\u7684\u4f01\u4e1a\u7ea7ETL\u6570\u636e\u6d41\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ecf\u6d4b\u8bd5\u8868\u73b0\u826f\u597d\uff0c\u53ef\u52a9\u529b\u4f01\u4e1a\u6570\u636e\u5904\u7406\u3002", "motivation": "\u89e3\u51b3\u4f01\u4e1a\u7ea7ETL\u6570\u636e\u6d41\u4e2d\u5e38\u51fa\u73b0\u7684\u5f02\u5e38\u95ee\u9898\u3002", "method": "\u5206\u6790ETL\u6d41\u7a0b\u591a\u79cd\u5f02\u5e38\uff0c\u8fdb\u884c\u6570\u636e\u6807\u51c6\u5316\u4e0e\u7279\u5f81\u5efa\u6a21\uff1b\u91c7\u7528\u7f16\u89e3\u7801\u5668\u7ed3\u6784\u538b\u7f29\u5e76\u91cd\u6784\u8f93\u5165\uff0c\u7528\u91cd\u6784\u8bef\u5dee\u8861\u91cf\u5f02\u5e38\u7a0b\u5ea6\uff1b\u5728\u6f5c\u5728\u7a7a\u95f4\u5f15\u5165\u6b63\u5219\u5316\u7ea6\u675f\u3002", "result": "\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u3001\u73af\u5883\u53d8\u5316\u548c\u6570\u636e\u7279\u5f81\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728AUC\u3001ACC\u3001Precision\u548cRecall\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\u7684\u68c0\u6d4b\u673a\u5236\u80fd\u6709\u6548\u6355\u6349\u6570\u636e\u6f5c\u5728\u5206\u5e03\u6a21\u5f0f\uff0c\u51c6\u786e\u8bc6\u522b\u591a\u6837\u5f02\u5e38\uff0c\u4e3a\u4f01\u4e1a\u6570\u636e\u5904\u7406\u548c\u667a\u80fd\u5206\u6790\u63d0\u4f9b\u53ef\u9760\u652f\u6301\u3002"}}
{"id": "2511.00475", "pdf": "https://arxiv.org/pdf/2511.00475", "abs": "https://arxiv.org/abs/2511.00475", "authors": ["Travis Barrett", "Amit Kumar Mishra", "Joyce Mwangama"], "title": "Variational Autoencoder for Calibration: A New Approach", "categories": ["cs.LG"], "comment": "6 pages, 5 figures", "summary": "In this paper we present a new implementation of a Variational Autoencoder\n(VAE) for the calibration of sensors. We propose that the VAE can be used to\ncalibrate sensor data by training the latent space as a calibration output. We\ndiscuss this new approach and show a proof-of-concept using an existing\nmulti-sensor gas dataset. We show the performance of the proposed calibration\nVAE and found that it was capable of performing as calibration model while\nperforming as an autoencoder simultaneously. Additionally, these models have\nshown that they are capable of creating statistically similar outputs from both\nthe calibration output as well as the reconstruction output to their respective\ntruth data. We then discuss the methods of future testing and planned expansion\nof this work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u4f20\u611f\u5668\u6821\u51c6\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\u65b0\u5b9e\u73b0\uff0c\u7528\u73b0\u6709\u591a\u4f20\u611f\u5668\u6c14\u4f53\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u5c55\u793a\u5176\u6027\u80fd\u5e76\u63a2\u8ba8\u672a\u6765\u6d4b\u8bd5\u548c\u6269\u5c55\u65b9\u6cd5\u3002", "motivation": "\u5bfb\u627e\u65b0\u7684\u4f20\u611f\u5668\u6821\u51c6\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5c06\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u6f5c\u5728\u7a7a\u95f4\u8bad\u7ec3\u4e3a\u6821\u51c6\u8f93\u51fa\u4ee5\u6821\u51c6\u4f20\u611f\u5668\u6570\u636e\uff0c\u5e76\u4f7f\u7528\u73b0\u6709\u591a\u4f20\u611f\u5668\u6c14\u4f53\u6570\u636e\u96c6\u8fdb\u884c\u6982\u5ff5\u9a8c\u8bc1\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6821\u51c6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u65e2\u80fd\u4f5c\u4e3a\u6821\u51c6\u6a21\u578b\uff0c\u53c8\u80fd\u4f5c\u4e3a\u81ea\u7f16\u7801\u5668\uff0c\u5176\u6821\u51c6\u8f93\u51fa\u548c\u91cd\u5efa\u8f93\u51fa\u4e0e\u771f\u5b9e\u6570\u636e\u5728\u7edf\u8ba1\u4e0a\u76f8\u4f3c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u884c\uff0c\u540e\u7eed\u5c06\u8fdb\u884c\u66f4\u591a\u6d4b\u8bd5\u548c\u6269\u5c55\u3002"}}
{"id": "2511.00521", "pdf": "https://arxiv.org/pdf/2511.00521", "abs": "https://arxiv.org/abs/2511.00521", "authors": ["Bao Nguyen", "Hieu Trung Nguyen", "Ruifeng She", "Xiaojin Fu", "Viet Anh Nguyen"], "title": "Reasoning Planning for Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "29 pages, 5 figures", "summary": "Selecting an appropriate reasoning method for a given query remains a key\nchallenge in language model generation. Existing approaches typically generate\nmultiple candidate responses and use an aggregation strategy to select the\noutput answer, often assuming that more candidate answers yield higher\naccuracy. We revisit this assumption through a rigorous theoretical analysis,\nderiving accuracy bounds for standard aggregation methods under fixed\ngeneration distributions and candidate sizes. Building on these insights, we\nintroduce EPIC, an Ensemble Planning with Contrastive learning framework to\nlearn a shared representation space that captures both model reasoning\nabilities and query-method compatibility. EPIC incorporates our probability\nbounds as a regularizer in a utility-driven optimization that balances accuracy\nand computational cost. Experiments on diverse mathematical reasoning tasks\nshow that EPIC consistently selects optimal reasoning methods, improving\naccuracy while reducing computational overhead. Our code can be found at\nhttps://github.com/nguyenngocbaocmt02/EPIC.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u6cd5\u9009\u62e9\u5047\u8bbe\uff0c\u63d0\u51faEPIC\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u9009\u6700\u4f18\u63a8\u7406\u65b9\u6cd5\uff0c\u63d0\u5347\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u7ed9\u5b9a\u67e5\u8be2\u9009\u62e9\u5408\u9002\u63a8\u7406\u65b9\u6cd5\u7684\u6311\u6218\uff0c\u91cd\u65b0\u5ba1\u89c6\u5df2\u6709\u65b9\u6cd5\u5047\u8bbe\u3002", "method": "\u8fdb\u884c\u7406\u8bba\u5206\u6790\u5f97\u51fa\u6807\u51c6\u805a\u5408\u65b9\u6cd5\u7684\u51c6\u786e\u7387\u754c\u9650\uff0c\u5f15\u5165EPIC\u6846\u67b6\u5b66\u4e60\u5171\u4eab\u8868\u793a\u7a7a\u95f4\uff0c\u5c06\u6982\u7387\u754c\u9650\u4f5c\u4e3a\u6b63\u5219\u5316\u9879\u7528\u4e8e\u4f18\u5316\u3002", "result": "\u5728\u4e0d\u540c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cEPIC\u80fd\u6301\u7eed\u9009\u62e9\u6700\u4f18\u63a8\u7406\u65b9\u6cd5\uff0c\u63d0\u5347\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "EPIC\u662f\u6709\u6548\u7684\u9009\u62e9\u63a8\u7406\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u53ef\u5728\u4fdd\u8bc1\u51c6\u786e\u7387\u540c\u65f6\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2511.00532", "pdf": "https://arxiv.org/pdf/2511.00532", "abs": "https://arxiv.org/abs/2511.00532", "authors": ["Drago\u015f-Andrei \u015eerban", "R\u0103zvan-Alexandru Sm\u0103du", "Dumitru-Clementin Cercel"], "title": "Air Pollution Forecasting in Bucharest", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.AP"], "comment": "14 pages 3 figures", "summary": "Air pollution, especially the particulate matter 2.5 (PM2.5), has become a\ngrowing concern in recent years, primarily in urban areas. Being exposed to air\npollution is linked to developing numerous health problems, like the\naggravation of respiratory diseases, cardiovascular disorders, lung function\nimpairment, and even cancer or early death. Forecasting future levels of PM2.5\nhas become increasingly important over the past few years, as it can provide\nearly warnings and help prevent diseases. This paper aims to design, fine-tune,\ntest, and evaluate machine learning models for predicting future levels of\nPM2.5 over various time horizons. Our primary objective is to assess and\ncompare the performance of multiple models, ranging from linear regression\nalgorithms and ensemble-based methods to deep learning models, such as advanced\nrecurrent neural networks and transformers, as well as large language models,\non this forecasting task.", "AI": {"tldr": "\u8bba\u6587\u5173\u6ce8\u7a7a\u6c14\u6c61\u67d3\u4e2dPM2.5\u9884\u6d4b\uff0c\u8981\u8bbe\u8ba1\u3001\u8c03\u8bd5\u3001\u6d4b\u8bd5\u548c\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u4e0d\u540c\u65f6\u95f4\u8de8\u5ea6\u7684PM2.5\u6c34\u5e73\u5e76\u6bd4\u8f83\u591a\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7a7a\u6c14\u6c61\u67d3\u5c24\u5176\u662fPM2.5\u5f15\u53d1\u5065\u5eb7\u95ee\u9898\uff0c\u9884\u6d4bPM2.5\u6c34\u5e73\u53ef\u63d0\u4f9b\u65e9\u671f\u9884\u8b66\u548c\u9884\u9632\u75be\u75c5\u3002", "method": "\u8bbe\u8ba1\u3001\u8c03\u8bd5\u3001\u6d4b\u8bd5\u548c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u7ebf\u6027\u56de\u5f52\u7b97\u6cd5\u3001\u57fa\u4e8e\u96c6\u6210\u7684\u65b9\u6cd5\u3001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982\u5148\u8fdb\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u3001\u53d8\u538b\u5668\uff09\u4ee5\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2511.00549", "pdf": "https://arxiv.org/pdf/2511.00549", "abs": "https://arxiv.org/abs/2511.00549", "authors": ["Qiang Li", "Jin Niu", "Lina Yu"], "title": "Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traffic congestion, primarily driven by intersection queuing, significantly\nimpacts urban living standards, safety, environmental quality, and economic\nefficiency. While Traffic Signal Control (TSC) systems hold potential for\ncongestion mitigation, traditional optimization models often fail to capture\nreal-world traffic complexity and dynamics. This study introduces a novel\nsingle-agent reinforcement learning (RL) framework for regional adaptive TSC,\ncircumventing the coordination complexities inherent in multi-agent systems\nthrough a centralized decision-making paradigm. The model employs an adjacency\nmatrix to unify the encoding of road network topology, real-time queue states\nderived from probe vehicle data, and current signal timing parameters.\nLeveraging the efficient learning capabilities of the DreamerV3 world model,\nthe agent learns control policies where actions sequentially select\nintersections and adjust their signal phase splits to regulate traffic\ninflow/outflow, analogous to a feedback control system. Reward design\nprioritizes queue dissipation, directly linking congestion metrics (queue\nlength) to control actions. Simulation experiments conducted in SUMO\ndemonstrate the model's effectiveness: under inference scenarios with\nmulti-level (10%, 20%, 30%) Origin-Destination (OD) demand fluctuations, the\nframework exhibits robust anti-fluctuation capability and significantly reduces\nqueue lengths. This work establishes a new paradigm for intelligent traffic\ncontrol compatible with probe vehicle technology. Future research will focus on\nenhancing practical applicability by incorporating stochastic OD demand\nfluctuations during training and exploring regional optimization mechanisms for\ncontingency events.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u533a\u57df\u81ea\u9002\u5e94\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u7684\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u90bb\u63a5\u77e9\u9635\u7edf\u4e00\u7f16\u7801\uff0c\u501f\u52a9DreamerV3\u6a21\u578b\u5b66\u4e60\u7b56\u7565\uff0c\u4eff\u771f\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\uff0c\u672a\u6765\u5c06\u63d0\u5347\u5b9e\u7528\u6027\u3002", "motivation": "\u4ea4\u901a\u62e5\u5835\u5f71\u54cd\u5927\uff0c\u4f20\u7edf\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4f18\u5316\u6a21\u578b\u96be\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u4ea4\u901a\u590d\u6742\u6027\u548c\u52a8\u6001\u6027\u3002", "method": "\u5f15\u5165\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u90bb\u63a5\u77e9\u9635\u7edf\u4e00\u7f16\u7801\uff0c\u5229\u7528DreamerV3\u6a21\u578b\u5b66\u4e60\u63a7\u5236\u7b56\u7565\uff0c\u5956\u52b1\u8bbe\u8ba1\u6ce8\u91cd\u961f\u5217\u6d88\u6563\u3002", "result": "\u5728SUMO\u4eff\u771f\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u578b\u5728\u4e0d\u540cOD\u9700\u6c42\u6ce2\u52a8\u63a8\u7406\u573a\u666f\u4e0b\u6709\u5f3a\u6297\u6ce2\u52a8\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4e\u961f\u5217\u957f\u5ea6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u667a\u80fd\u4ea4\u901a\u63a7\u5236\u5efa\u7acb\u65b0\u8303\u5f0f\uff0c\u672a\u6765\u5c06\u589e\u5f3a\u5b9e\u7528\u6027\uff0c\u8003\u8651\u968f\u673aOD\u9700\u6c42\u6ce2\u52a8\u5e76\u63a2\u7d22\u5e94\u6025\u533a\u57df\u4f18\u5316\u673a\u5236\u3002"}}
{"id": "2511.00062", "pdf": "https://arxiv.org/pdf/2511.00062", "abs": "https://arxiv.org/abs/2511.00062", "authors": ["NVIDIA", ":", "Arslan Ali", "Junjie Bai", "Maciej Bala", "Yogesh Balaji", "Aaron Blakeman", "Tiffany Cai", "Jiaxin Cao", "Tianshi Cao", "Elizabeth Cha", "Yu-Wei Chao", "Prithvijit Chattopadhyay", "Mike Chen", "Yongxin Chen", "Yu Chen", "Shuai Cheng", "Yin Cui", "Jenna Diamond", "Yifan Ding", "Jiaojiao Fan", "Linxi Fan", "Liang Feng", "Francesco Ferroni", "Sanja Fidler", "Xiao Fu", "Ruiyuan Gao", "Yunhao Ge", "Jinwei Gu", "Aryaman Gupta", "Siddharth Gururani", "Imad El Hanafi", "Ali Hassani", "Zekun Hao", "Jacob Huffman", "Joel Jang", "Pooya Jannaty", "Jan Kautz", "Grace Lam", "Xuan Li", "Zhaoshuo Li", "Maosheng Liao", "Chen-Hsuan Lin", "Tsung-Yi Lin", "Yen-Chen Lin", "Huan Ling", "Ming-Yu Liu", "Xian Liu", "Yifan Lu", "Alice Luo", "Qianli Ma", "Hanzi Mao", "Kaichun Mo", "Seungjun Nah", "Yashraj Narang", "Abhijeet Panaskar", "Lindsey Pavao", "Trung Pham", "Morteza Ramezanali", "Fitsum Reda", "Scott Reed", "Xuanchi Ren", "Haonan Shao", "Yue Shen", "Stella Shi", "Shuran Song", "Bartosz Stefaniak", "Shangkun Sun", "Shitao Tang", "Sameena Tasmeen", "Lyne Tchapmi", "Wei-Cheng Tseng", "Jibin Varghese", "Andrew Z. Wang", "Hao Wang", "Haoxiang Wang", "Heng Wang", "Ting-Chun Wang", "Fangyin Wei", "Jiashu Xu", "Dinghao Yang", "Xiaodong Yang", "Haotian Ye", "Seonghyeon Ye", "Xiaohui Zeng", "Jing Zhang", "Qinsheng Zhang", "Kaiwen Zheng", "Andrew Zhu", "Yuke Zhu"], "title": "World Simulation with Video Foundation Models for Physical AI", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "We introduce [Cosmos-Predict2.5], the latest generation of the Cosmos World\nFoundation Models for Physical AI. Built on a flow-based architecture,\n[Cosmos-Predict2.5] unifies Text2World, Image2World, and Video2World generation\nin a single model and leverages [Cosmos-Reason1], a Physical AI vision-language\nmodel, to provide richer text grounding and finer control of world simulation.\nTrained on 200M curated video clips and refined with reinforcement\nlearning-based post-training, [Cosmos-Predict2.5] achieves substantial\nimprovements over [Cosmos-Predict1] in video quality and instruction alignment,\nwith models released at 2B and 14B scales. These capabilities enable more\nreliable synthetic data generation, policy evaluation, and closed-loop\nsimulation for robotics and autonomous systems. We further extend the family\nwith [Cosmos-Transfer2.5], a control-net style framework for Sim2Real and\nReal2Real world translation. Despite being 3.5$\\times$ smaller than\n[Cosmos-Transfer1], it delivers higher fidelity and robust long-horizon video\ngeneration. Together, these advances establish [Cosmos-Predict2.5] and\n[Cosmos-Transfer2.5] as versatile tools for scaling embodied intelligence. To\naccelerate research and deployment in Physical AI, we release source code,\npretrained checkpoints, and curated benchmarks under the NVIDIA Open Model\nLicense at https://github.com/nvidia-cosmos/cosmos-predict2.5 and\nhttps://github.com/nvidia-cosmos/cosmos-transfer2.5. We hope these open\nresources lower the barrier to adoption and foster innovation in building the\nnext generation of embodied intelligence.", "AI": {"tldr": "\u4ecb\u7ecd\u6700\u65b0\u7684\u7269\u7406AI\u6a21\u578bCosmos - Predict2.5\u548cCosmos - Transfer2.5\uff0c\u5b83\u4eec\u6027\u80fd\u63d0\u5347\uff0c\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u7269\u7406AI\u7814\u7a76\u3002", "motivation": "\u63a8\u52a8\u7269\u7406AI\u53d1\u5c55\uff0c\u4e3a\u673a\u5668\u4eba\u548c\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u3001\u7b56\u7565\u8bc4\u4f30\u548c\u95ed\u73af\u6a21\u62df\u7b49\u529f\u80fd\uff0c\u52a0\u901f\u5177\u8eab\u667a\u80fd\u7814\u7a76\u4e0e\u90e8\u7f72\u3002", "method": "\u57fa\u4e8e\u6d41\u67b6\u6784\u6784\u5efaCosmos - Predict2.5\uff0c\u7edf\u4e00\u591a\u79cd\u751f\u6210\u529f\u80fd\uff0c\u5229\u7528Cosmos - Reason1\uff0c\u57282\u4ebf\u89c6\u9891\u7247\u6bb5\u4e0a\u8bad\u7ec3\u5e76\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\uff1b\u63a8\u51fa\u63a7\u5236\u7f51\u7edc\u98ce\u683c\u7684Cosmos - Transfer2.5\u3002", "result": "Cosmos - Predict2.5\u5728\u89c6\u9891\u8d28\u91cf\u548c\u6307\u4ee4\u5bf9\u9f50\u4e0a\u6bd4Cosmos - Predict1\u6709\u663e\u8457\u63d0\u5347\uff0cCosmos - Transfer2.5\u66f4\u5c0f\u4f46\u751f\u6210\u89c6\u9891\u4fdd\u771f\u5ea6\u66f4\u9ad8\u3001\u66f4\u7a33\u5065\u3002", "conclusion": "Cosmos - Predict2.5\u548cCosmos - Transfer2.5\u662f\u6269\u5c55\u5177\u8eab\u667a\u80fd\u7684\u901a\u7528\u5de5\u5177\uff0c\u5f00\u6e90\u8d44\u6e90\u53ef\u964d\u4f4e\u91c7\u7528\u95e8\u69db\uff0c\u4fc3\u8fdb\u4e0b\u4e00\u4ee3\u5177\u8eab\u667a\u80fd\u521b\u65b0\u3002"}}
{"id": "2511.00554", "pdf": "https://arxiv.org/pdf/2511.00554", "abs": "https://arxiv.org/abs/2511.00554", "authors": ["Phil Blandfort", "Robert Graham"], "title": "Red-teaming Activation Probes using Prompted LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Activation probes are attractive monitors for AI systems due to low cost and\nlatency, but their real-world robustness remains underexplored. We ask: What\nfailure modes arise under realistic, black-box adversarial pressure, and how\ncan we surface them with minimal effort? We present a lightweight black-box\nred-teaming procedure that wraps an off-the-shelf LLM with iterative feedback\nand in-context learning (ICL), and requires no fine-tuning, gradients, or\narchitectural access. Running a case study with probes for high-stakes\ninteractions, we show that our approach can help discover valuable insights\nabout a SOTA probe. Our analysis uncovers interpretable brittleness patterns\n(e.g., legalese-induced FPs; bland procedural tone FNs) and reduced but\npersistent vulnerabilities under scenario-constraint attacks. These results\nsuggest that simple prompted red-teaming scaffolding can anticipate failure\npatterns before deployment and might yield promising, actionable insights to\nharden future probes.", "AI": {"tldr": "\u7814\u7a76\u6fc0\u6d3b\u63a2\u9488\u5728\u73b0\u5b9e\u9ed1\u76d2\u5bf9\u6297\u538b\u529b\u4e0b\u7684\u6545\u969c\u6a21\u5f0f\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u9ed1\u76d2\u7ea2\u961f\u7a0b\u5e8f\uff0c\u53d1\u73b0\u63a2\u9488\u8106\u5f31\u6a21\u5f0f\u548c\u6301\u7eed\u6f0f\u6d1e\uff0c\u8868\u660e\u8be5\u7a0b\u5e8f\u53ef\u5728\u90e8\u7f72\u524d\u9884\u6d4b\u6545\u969c\u6a21\u5f0f\u3002", "motivation": "\u6fc0\u6d3b\u63a2\u9488\u4f5c\u4e3aAI\u7cfb\u7edf\u76d1\u63a7\u5668\u6210\u672c\u4f4e\u3001\u5ef6\u8fdf\u5c0f\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u9c81\u68d2\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u63a2\u7d22\u5176\u5728\u73b0\u5b9e\u9ed1\u76d2\u5bf9\u6297\u538b\u529b\u4e0b\u7684\u6545\u969c\u6a21\u5f0f\u53ca\u4f4e\u6210\u672c\u53d1\u73b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u9ed1\u76d2\u7ea2\u961f\u7a0b\u5e8f\uff0c\u7528\u8fed\u4ee3\u53cd\u9988\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u5305\u88c5\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u65e0\u9700\u5fae\u8c03\u3001\u68af\u5ea6\u8ba1\u7b97\u6216\u67b6\u6784\u8bbf\u95ee\u3002", "result": "\u901a\u8fc7\u9ad8\u98ce\u9669\u4ea4\u4e92\u63a2\u9488\u6848\u4f8b\u7814\u7a76\uff0c\u53d1\u73b0SOTA\u63a2\u9488\u7684\u6709\u4ef7\u503c\u89c1\u89e3\uff0c\u63ed\u793a\u53ef\u89e3\u91ca\u7684\u8106\u5f31\u6a21\u5f0f\u548c\u573a\u666f\u7ea6\u675f\u653b\u51fb\u4e0b\u4ecd\u5b58\u5728\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u7b80\u5355\u7684\u63d0\u793a\u5f0f\u7ea2\u961f\u6846\u67b6\u53ef\u5728\u90e8\u7f72\u524d\u9884\u6d4b\u6545\u969c\u6a21\u5f0f\uff0c\u4e3a\u5f3a\u5316\u672a\u6765\u63a2\u9488\u63d0\u4f9b\u6709\u524d\u666f\u7684\u53ef\u64cd\u4f5c\u89c1\u89e3\u3002"}}
{"id": "2511.00564", "pdf": "https://arxiv.org/pdf/2511.00564", "abs": "https://arxiv.org/abs/2511.00564", "authors": ["Varun Teja Chirukiri", "Udaya Bhasker Cheerala", "Sandeep Kanta", "Abdul Karim", "Praveen Damacharla"], "title": "FTT-GRU: A Hybrid Fast Temporal Transformer with GRU for Remaining Useful Life Prediction", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "5 pages, The 2025 International Conference on Computational Science\n  and Computational Intelligence", "summary": "Accurate prediction of the remaining useful life (RUL) of industrial\nmachinery is essential for reducing downtime and optimizing maintenance\nschedules. Existing approaches, such as long short-term memory (LSTM) networks\nand convolutional neural networks (CNNs), often struggle to model both global\ntemporal dependencies and fine-grained degradation trends in multivariate\nsensor data. We propose a hybrid model, FTT-GRU, which combines a Fast Temporal\nTransformer (FTT) -- a lightweight Transformer variant using linearized\nattention via fast Fourier transform (FFT) -- with a gated recurrent unit (GRU)\nlayer for sequential modeling. To the best of our knowledge, this is the first\napplication of an FTT with a GRU for RUL prediction on NASA CMAPSS, enabling\nsimultaneous capture of global and local degradation patterns in a compact\narchitecture. On CMAPSS FD001, FTT-GRU attains RMSE 30.76, MAE 18.97, and\n$R^2=0.45$, with 1.12 ms CPU latency at batch=1. Relative to the best published\ndeep baseline (TCN--Attention), it improves RMSE by 1.16\\% and MAE by 4.00\\%.\nTraining curves averaged over $k=3$ runs show smooth convergence with narrow\n95\\% confidence bands, and ablations (GRU-only, FTT-only) support the\ncontribution of both components. These results demonstrate that a compact\nTransformer-RNN hybrid delivers accurate and efficient RUL predictions on\nCMAPSS, making it suitable for real-time industrial prognostics.", "AI": {"tldr": "\u63d0\u51faFTT - GRU\u6df7\u5408\u6a21\u578b\u7528\u4e8e\u5de5\u4e1a\u673a\u68b0\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u9884\u6d4b\uff0c\u5728NASA CMAPSS\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u9002\u5408\u5b9e\u65f6\u5de5\u4e1a\u9884\u6d4b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5bf9\u591a\u5143\u4f20\u611f\u5668\u6570\u636e\u4e2d\u7684\u5168\u5c40\u65f6\u95f4\u4f9d\u8d56\u548c\u7ec6\u7c92\u5ea6\u9000\u5316\u8d8b\u52bf\u8fdb\u884c\u5efa\u6a21\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684RUL\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u5feb\u901f\u65f6\u95f4\u53d8\u6362\u5668\uff08FTT\uff09\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u7684\u6df7\u5408\u6a21\u578bFTT - GRU\u8fdb\u884c\u987a\u5e8f\u5efa\u6a21\u3002", "result": "\u5728CMAPSS FD001\u4e0a\uff0cFTT - GRU\u8fbe\u5230RMSE 30.76\u3001MAE 18.97\u3001$R^2 = 0.45$\uff0cCPU\u5ef6\u8fdf1.12 ms\uff1b\u8f83\u6700\u4f73\u5df2\u53d1\u8868\u57fa\u7ebf\u6a21\u578b\u6709\u6539\u8fdb\uff1b\u8bad\u7ec3\u66f2\u7ebf\u6536\u655b\u5e73\u7a33\uff1b\u6d88\u878d\u5b9e\u9a8c\u652f\u6301\u4e24\u7ec4\u4ef6\u4f5c\u7528\u3002", "conclusion": "\u7d27\u51d1\u7684Transformer - RNN\u6df7\u5408\u6a21\u578b\u80fd\u5728CMAPSS\u4e0a\u5b9e\u73b0\u51c6\u786e\u9ad8\u6548\u7684RUL\u9884\u6d4b\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u5de5\u4e1a\u9884\u6d4b\u3002"}}
{"id": "2511.00574", "pdf": "https://arxiv.org/pdf/2511.00574", "abs": "https://arxiv.org/abs/2511.00574", "authors": ["Yinghuan Zhang", "Yufei Zhang", "Parisa Kordjamshidi", "Zijun Cui"], "title": "Bayesian Network Structure Discovery Using Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Understanding probabilistic relationships among variables is crucial for\nanalyzing complex systems. Traditional structure learning methods often require\nextensive observational data and incur high computational costs. Recent studies\nhave explored using large language models (LLMs) for structure learning, but\nmost treat LLMs as auxiliary tools for pre-processing or post-processing,\nleaving the core learning process data-driven. In this work, we propose a\nunified framework for Bayesian network structure discovery that places LLMs at\nthe center, supporting both data-free and data-aware settings. In the data-free\ncase, we introduce \\textbf{PromptBN} to query LLMs with metadata and\nefficiently uncover valid probabilistic relationships. When observational data\nare available, we introduce \\textbf{ReActBN}, which integrates the ReAct\nreasoning paradigm with structure scores such as the Bayesian Information\nCriterion (BIC) for iterative refinement. Unlike prior methods that offload\nrefinement to external algorithms, our framework maintains the LLM actively in\nthe loop throughout the discovery process. Experiments demonstrate that our\nmethod significantly outperforms both existing LLM-based approaches and\ntraditional data-driven algorithms, particularly in the low- or no-data\nscenario. Code is publicly available at\n{\\texttt{\\textcolor{magenta}{https://github.com/sherryzyh/prompt2bn}}}.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u6838\u5fc3\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u7ed3\u6784\u53d1\u73b0\u7edf\u4e00\u6846\u67b6\uff0c\u5728\u4f4e\u6570\u636e\u6216\u65e0\u6570\u636e\u573a\u666f\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u7ed3\u6784\u5b66\u4e60\u65b9\u6cd5\u9700\u5927\u91cf\u89c2\u6d4b\u6570\u636e\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u672a\u5c06\u5176\u7528\u4e8e\u6838\u5fc3\u5b66\u4e60\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff0c\u6570\u636e\u514d\u8d39\u65f6\u7528PromptBN\u67e5\u8be2\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6709\u89c2\u6d4b\u6570\u636e\u65f6\u7528ReActBN\u7ed3\u5408\u63a8\u7406\u8303\u5f0f\u548c\u7ed3\u6784\u5206\u6570\u8fed\u4ee3\u4f18\u5316\uff0c\u4e14\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5168\u7a0b\u53c2\u4e0e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u548c\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u7b97\u6cd5\uff0c\u5c24\u5176\u5728\u4f4e\u6570\u636e\u6216\u65e0\u6570\u636e\u573a\u666f\u3002", "conclusion": "\u6240\u63d0\u4ee5\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u6838\u5fc3\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u7ed3\u6784\u53d1\u73b0\u6846\u67b6\u6709\u6548\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2511.00588", "pdf": "https://arxiv.org/pdf/2511.00588", "abs": "https://arxiv.org/abs/2511.00588", "authors": ["Dong Chen", "Yanzhe Wei", "Zonglin He", "Guan-Ming Kuang", "Canhua Ye", "Meiru An", "Huili Peng", "Yong Hu", "Huiren Tao", "Kenneth MC Cheung"], "title": "Diagnosing Hallucination Risk in AI Surgical Decision-Support: A Sequential Framework for Sequential Validation", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Large language models (LLMs) offer transformative potential for clinical\ndecision support in spine surgery but pose significant risks through\nhallucinations, which are factually inconsistent or contextually misaligned\noutputs that may compromise patient safety. This study introduces a\nclinician-centered framework to quantify hallucination risks by evaluating\ndiagnostic precision, recommendation quality, reasoning robustness, output\ncoherence, and knowledge alignment. We assessed six leading LLMs across 30\nexpert-validated spinal cases. DeepSeek-R1 demonstrated superior overall\nperformance (total score: 86.03 $\\pm$ 2.08), particularly in high-stakes\ndomains such as trauma and infection. A critical finding reveals that\nreasoning-enhanced model variants did not uniformly outperform standard\ncounterparts: Claude-3.7-Sonnet's extended thinking mode underperformed\nrelative to its standard version (80.79 $\\pm$ 1.83 vs. 81.56 $\\pm$ 1.92),\nindicating extended chain-of-thought reasoning alone is insufficient for\nclinical reliability. Multidimensional stress-testing exposed model-specific\nvulnerabilities, with recommendation quality degrading by 7.4% under amplified\ncomplexity. This decline contrasted with marginal improvements in rationality\n(+2.0%), readability (+1.7%) and diagnosis (+4.7%), highlighting a concerning\ndivergence between perceived coherence and actionable guidance. Our findings\nadvocate integrating interpretability mechanisms (e.g., reasoning chain\nvisualization) into clinical workflows and establish a safety-aware validation\nframework for surgical LLM deployment.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u8bc4\u4f30\u6846\u67b6\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5728\u810a\u67f1\u624b\u672f\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u5e7b\u89c9\u98ce\u9669\uff0c\u8bc4\u4f306\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u63a8\u7406\u589e\u5f3a\u53d8\u4f53\u4e0d\u603b\u4f18\u4e8e\u6807\u51c6\u7248\u672c\uff0c\u591a\u7ef4\u6d4b\u8bd5\u66b4\u9732\u6a21\u578b\u5f31\u70b9\uff0c\u5efa\u8bae\u96c6\u6210\u53ef\u89e3\u91ca\u673a\u5236\u548c\u5efa\u7acb\u5b89\u5168\u9a8c\u8bc1\u6846\u67b6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u810a\u67f1\u624b\u672f\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u6709\u6f5c\u529b\uff0c\u4f46\u5e7b\u89c9\u95ee\u9898\u4f1a\u5371\u5bb3\u60a3\u8005\u5b89\u5168\uff0c\u9700\u91cf\u5316\u98ce\u9669\u3002", "method": "\u5f15\u5165\u4ee5\u4e34\u5e8a\u533b\u751f\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u4ece\u8bca\u65ad\u7cbe\u5ea6\u3001\u63a8\u8350\u8d28\u91cf\u7b49\u65b9\u9762\u8bc4\u4f30\uff0c\u5bf96\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u572830\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u810a\u67f1\u75c5\u4f8b\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "DeepSeek - R1\u603b\u4f53\u8868\u73b0\u4f18\uff1b\u63a8\u7406\u589e\u5f3a\u6a21\u578b\u53d8\u4f53\u4e0d\u603b\u4f18\u4e8e\u6807\u51c6\u7248\u672c\uff1b\u591a\u7ef4\u538b\u529b\u6d4b\u8bd5\u66b4\u9732\u6a21\u578b\u7279\u5b9a\u5f31\u70b9\uff0c\u63a8\u8350\u8d28\u91cf\u5728\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u4e0b\u964d7.4%\uff0c\u7406\u6027\u3001\u53ef\u8bfb\u6027\u548c\u8bca\u65ad\u6709\u5c0f\u63d0\u5347\u3002", "conclusion": "\u5efa\u8bae\u5c06\u53ef\u89e3\u91ca\u673a\u5236\u96c6\u6210\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5efa\u7acb\u5b89\u5168\u9a8c\u8bc1\u6846\u67b6\u7528\u4e8e\u5916\u79d1\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u3002"}}
{"id": "2511.00615", "pdf": "https://arxiv.org/pdf/2511.00615", "abs": "https://arxiv.org/abs/2511.00615", "authors": ["Daniel Griffiths", "Piper Moskow"], "title": "Gaining Momentum: Uncovering Hidden Scoring Dynamics in Hockey through Deep Neural Sequencing and Causal Modeling", "categories": ["cs.LG"], "comment": "5 Pages, 4 Figures, 2 Tables", "summary": "We present a unified, data-driven framework for quantifying and enhancing\noffensive momentum and scoring likelihood (expected goals, xG) in professional\nhockey. Leveraging a Sportlogiq dataset of 541,000 NHL event records, our\nend-to-end pipeline comprises five stages: (1) interpretable momentum weighting\nof micro-events via logistic regression; (2) nonlinear xG estimation using\ngradient-boosted decision trees; (3) temporal sequence modeling with Long\nShort-Term Memory (LSTM) networks; (4) spatial formation discovery through\nprincipal component analysis (PCA) followed by K-Means clustering on\nstandardized player coordinates; and (5) use of an X-Learner causal inference\nestimator to quantify the average treatment effect (ATE) of adopting the\nidentified \"optimal\" event sequences and formations. We observe an ATE of 0.12\n(95% CI: 0.05-0.17, p < 1e-50), corresponding to a 15% relative gain in scoring\npotential. These results demonstrate that strategically structured sequences\nand compact formations causally elevate offensive performance. Our framework\ndelivers real-time, actionable insights for coaches and analysts, advancing\nhockey analytics toward principled, causally grounded tactical optimization.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u6570\u636e\u9a71\u52a8\u6846\u67b6\u91cf\u5316\u548c\u63d0\u5347\u804c\u4e1a\u66f2\u68cd\u7403\u8fdb\u653b\u52bf\u5934\u4e0e\u5f97\u5206\u53ef\u80fd\u6027\uff0c\u6709\u4e94\u9636\u6bb5\u6d41\u7a0b\uff0c\u89c2\u6d4b\u5230\u5f97\u5206\u6f5c\u529b\u76f8\u5bf9\u63d0\u534715%\uff0c\u4e3a\u6559\u7ec3\u548c\u5206\u6790\u5e08\u63d0\u4f9b\u5b9e\u65f6\u89c1\u89e3\u3002", "motivation": "\u91cf\u5316\u548c\u63d0\u5347\u804c\u4e1a\u66f2\u68cd\u7403\u7684\u8fdb\u653b\u52bf\u5934\u548c\u5f97\u5206\u53ef\u80fd\u6027\u3002", "method": "\u5229\u7528541,000\u6761NHL\u4e8b\u4ef6\u8bb0\u5f55\u6570\u636e\u96c6\uff0c\u6784\u5efa\u5305\u542b\u903b\u8f91\u56de\u5f52\u3001\u68af\u5ea6\u63d0\u5347\u51b3\u7b56\u6811\u3001LSTM\u7f51\u7edc\u3001PCA\u548cK - Means\u805a\u7c7b\u3001X - Learner\u56e0\u679c\u63a8\u65ad\u4f30\u8ba1\u5668\u7684\u4e94\u9636\u6bb5\u7aef\u5230\u7aef\u6d41\u7a0b\u3002", "result": "\u89c2\u6d4b\u5230\u5e73\u5747\u5904\u7406\u6548\u5e94\u4e3a0.12\uff0c\u5f97\u5206\u6f5c\u529b\u670915%\u7684\u76f8\u5bf9\u63d0\u5347\u3002", "conclusion": "\u6218\u7565\u6027\u7ed3\u6784\u5316\u5e8f\u5217\u548c\u7d27\u51d1\u9635\u578b\u80fd\u63d0\u5347\u8fdb\u653b\u8868\u73b0\uff0c\u6846\u67b6\u4e3a\u6559\u7ec3\u548c\u5206\u6790\u5e08\u63d0\u4f9b\u5b9e\u65f6\u89c1\u89e3\uff0c\u63a8\u52a8\u66f2\u68cd\u7403\u5206\u6790\u5411\u6218\u672f\u4f18\u5316\u53d1\u5c55\u3002"}}
{"id": "2511.00655", "pdf": "https://arxiv.org/pdf/2511.00655", "abs": "https://arxiv.org/abs/2511.00655", "authors": ["Baris Askin", "Holger R. Roth", "Zhenyu Sun", "Carlee Joe-Wong", "Gauri Joshi", "Ziyue Xu"], "title": "Reviving Stale Updates: Data-Free Knowledge Distillation for Asynchronous Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, yet its scalability is limited by\nsynchronization overhead. Asynchronous Federated Learning (AFL) alleviates this\nissue by allowing clients to communicate independently, thereby improving\nwall-clock efficiency in large-scale, heterogeneous environments. However, this\nasynchrony introduces stale updates (client updates computed on outdated global\nmodels) that can destabilize optimization and hinder convergence. We propose\nFedRevive, an asynchronous FL framework that revives stale updates through\ndata-free knowledge distillation (DFKD). FedRevive integrates parameter-space\naggregation with a lightweight, server-side DFKD process that transfers\nknowledge from stale client models to the current global model without access\nto real or public data. A meta-learned generator synthesizes pseudo-samples,\nwhich enables multi-teacher distillation. A hybrid aggregation scheme that\ncombines raw updates with DFKD updates effectively mitigates staleness while\nretaining the scalability of AFL. Experiments on various vision and text\nbenchmarks show that FedRevive achieves faster training up to 32.1% and higher\nfinal accuracy up to 21.5% compared to asynchronous baselines.", "AI": {"tldr": "\u63d0\u51faFedRevive\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u65e0\u6570\u636e\u77e5\u8bc6\u84b8\u998f\u6062\u590d\u9648\u65e7\u66f4\u65b0\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u5f02\u6b65\u57fa\u7ebf\u8bad\u7ec3\u66f4\u5feb\u3001\u7cbe\u5ea6\u66f4\u9ad8\u3002", "motivation": "\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u53ef\u6269\u5c55\u6027\u53d7\u540c\u6b65\u5f00\u9500\u9650\u5236\uff0c\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u867d\u63d0\u9ad8\u6548\u7387\u4f46\u5b58\u5728\u9648\u65e7\u66f4\u65b0\u95ee\u9898\uff0c\u5f71\u54cd\u4f18\u5316\u548c\u6536\u655b\u3002", "method": "\u63d0\u51faFedRevive\u6846\u67b6\uff0c\u96c6\u6210\u53c2\u6570\u7a7a\u95f4\u805a\u5408\u4e0e\u8f7b\u91cf\u7ea7\u670d\u52a1\u5668\u7aef\u65e0\u6570\u636e\u77e5\u8bc6\u84b8\u998f\uff0c\u7528\u5143\u5b66\u4e60\u751f\u6210\u5668\u5408\u6210\u4f2a\u6837\u672c\u5b9e\u73b0\u591a\u6559\u5e08\u84b8\u998f\uff0c\u91c7\u7528\u6df7\u5408\u805a\u5408\u65b9\u6848\u7ed3\u5408\u539f\u59cb\u548c\u84b8\u998f\u66f4\u65b0\u3002", "result": "\u5728\u591a\u79cd\u89c6\u89c9\u548c\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFedRevive\u6bd4\u5f02\u6b65\u57fa\u7ebf\u8bad\u7ec3\u901f\u5ea6\u6700\u9ad8\u5feb32.1%\uff0c\u6700\u7ec8\u7cbe\u5ea6\u6700\u9ad8\u9ad821.5%\u3002", "conclusion": "FedRevive\u80fd\u6709\u6548\u7f13\u89e3\u9648\u65e7\u66f4\u65b0\u95ee\u9898\uff0c\u4fdd\u7559\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u53ef\u6269\u5c55\u6027\uff0c\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u548c\u7cbe\u5ea6\u3002"}}
{"id": "2511.00663", "pdf": "https://arxiv.org/pdf/2511.00663", "abs": "https://arxiv.org/abs/2511.00663", "authors": ["Alex Dobra", "Jakiw Pidstrigach", "Tim Reichelt", "Paolo Fraccaro", "Johannes Jakubik", "Anne Jones", "Christian Schroeder de Witt", "Philip Stier", "Philip Torr"], "title": "Sensitivity Analysis for Climate Science with Generative Flow Models", "categories": ["cs.LG"], "comment": null, "summary": "Sensitivity analysis is a cornerstone of climate science, essential for\nunderstanding phenomena ranging from storm intensity to long-term climate\nfeedbacks. However, computing these sensitivities using traditional physical\nmodels is often prohibitively expensive in terms of both computation and\ndevelopment time. While modern AI-based generative models are orders of\nmagnitude faster to evaluate, computing sensitivities with them remains a\nsignificant bottleneck. This work addresses this challenge by applying the\nadjoint state method for calculating gradients in generative flow models, with\ndiffusion models as a special case. We apply this method to the cBottle\ngenerative model, an emulator of ERA5 data, to perform sensitivity analysis\nwith respect to sea surface temperatures. Furthermore, we propose a novel\ngradient self-consistency check to quantitatively validate the computed\nsensitivities against the model's own outputs. Our results provide initial\nevidence that this approach can produce reliable gradients, reducing the\ncomputational cost of sensitivity analysis from weeks on a supercomputer with a\nphysical model to hours on a GPU, thereby simplifying a critical workflow in\nclimate science.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4f34\u968f\u72b6\u6001\u6cd5\u8ba1\u7b97\u751f\u6210\u6d41\u6a21\u578b\u68af\u5ea6\u4ee5\u89e3\u51b3\u6c14\u5019\u654f\u611f\u6027\u5206\u6790\u8ba1\u7b97\u74f6\u9888\uff0c\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u6a21\u578b\u8ba1\u7b97\u6c14\u5019\u654f\u611f\u6027\u5728\u8ba1\u7b97\u548c\u5f00\u53d1\u65f6\u95f4\u4e0a\u6210\u672c\u8fc7\u9ad8\uff0c\u73b0\u4ee3\u57fa\u4e8eAI\u7684\u751f\u6210\u6a21\u578b\u8ba1\u7b97\u654f\u611f\u6027\u4e5f\u5b58\u5728\u74f6\u9888\u3002", "method": "\u5c06\u4f34\u968f\u72b6\u6001\u6cd5\u5e94\u7528\u4e8e\u751f\u6210\u6d41\u6a21\u578b\u8ba1\u7b97\u68af\u5ea6\uff0c\u4ee5\u6269\u6563\u6a21\u578b\u4e3a\u7279\u4f8b\uff0c\u5e94\u7528\u4e8ecBottle\u751f\u6210\u6a21\u578b\u5bf9\u6d77\u9762\u6e29\u5ea6\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\uff0c\u63d0\u51fa\u68af\u5ea6\u81ea\u4e00\u81f4\u6027\u68c0\u67e5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u4ea7\u751f\u53ef\u9760\u68af\u5ea6\uff0c\u5c06\u654f\u611f\u6027\u5206\u6790\u8ba1\u7b97\u6210\u672c\u4ece\u7269\u7406\u6a21\u578b\u5728\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u7684\u6570\u5468\u964d\u81f3GPU\u4e0a\u7684\u6570\u5c0f\u65f6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7b80\u5316\u4e86\u6c14\u5019\u79d1\u5b66\u4e2d\u7684\u5173\u952e\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5177\u6709\u4e00\u5b9a\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.00088", "pdf": "https://arxiv.org/pdf/2511.00088", "abs": "https://arxiv.org/abs/2511.00088", "authors": ["NVIDIA", ":", "Yan Wang", "Wenjie Luo", "Junjie Bai", "Yulong Cao", "Tong Che", "Ke Chen", "Yuxiao Chen", "Jenna Diamond", "Yifan Ding", "Wenhao Ding", "Liang Feng", "Greg Heinrich", "Jack Huang", "Peter Karkus", "Boyi Li", "Pinyi Li", "Tsung-Yi Lin", "Dongran Liu", "Ming-Yu Liu", "Langechuan Liu", "Zhijian Liu", "Jason Lu", "Yunxiang Mao", "Pavlo Molchanov", "Lindsey Pavao", "Zhenghao Peng", "Mike Ranzinger", "Ed Schmerling", "Shida Shen", "Yunfei Shi", "Sarah Tariq", "Ran Tian", "Tilman Wekel", "Xinshuo Weng", "Tianjun Xiao", "Eric Yang", "Xiaodong Yang", "Yurong You", "Xiaohui Zeng", "Wenyuan Zhang", "Boris Ivanovic", "Marco Pavone"], "title": "Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "End-to-end architectures trained via imitation learning have advanced\nautonomous driving by scaling model size and data, yet performance remains\nbrittle in safety-critical long-tail scenarios where supervision is sparse and\ncausal understanding is limited. To address this, we introduce Alpamayo-R1\n(AR1), a vision-language-action model (VLA) that integrates Chain of Causation\nreasoning with trajectory planning to enhance decision-making in complex\ndriving scenarios. Our approach features three key innovations: (1) the Chain\nof Causation (CoC) dataset, built through a hybrid auto-labeling and\nhuman-in-the-loop pipeline producing decision-grounded, causally linked\nreasoning traces aligned with driving behaviors; (2) a modular VLA architecture\ncombining Cosmos-Reason, a Vision-Language Model pre-trained for Physical AI\napplications, with a diffusion-based trajectory decoder that generates\ndynamically feasible plans in real time; (3) a multi-stage training strategy\nusing supervised fine-tuning to elicit reasoning and reinforcement learning\n(RL) to optimize reasoning quality via large reasoning model feedback and\nenforce reasoning-action consistency. Evaluation shows AR1 achieves up to a 12%\nimprovement in planning accuracy on challenging cases compared to a\ntrajectory-only baseline, with a 35% reduction in off-road rate and 25%\nreduction in close encounter rate in closed-loop simulation. RL post-training\nimproves reasoning quality by 45% as measured by a large reasoning model critic\nand reasoning-action consistency by 37%. Model scaling from 0.5B to 7B\nparameters shows consistent improvements. On-vehicle road tests confirm\nreal-time performance (99 ms latency) and successful urban deployment. By\nbridging interpretable reasoning with precise control, AR1 demonstrates a\npractical path towards Level 4 autonomous driving. We plan to release AR1\nmodels and a subset of the CoC in a future update.", "AI": {"tldr": "\u4ecb\u7ecd\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578bAlpamayo - R1 (AR1)\uff0c\u7ed3\u5408\u56e0\u679c\u94fe\u63a8\u7406\u4e0e\u8f68\u8ff9\u89c4\u5212\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u89c4\u5212\u51c6\u786e\u6027\u7b49\u591a\u65b9\u9762\u6709\u63d0\u5347\uff0c\u5c55\u793a\u4e86\u901a\u5f804\u7ea7\u81ea\u52a8\u9a7e\u9a76\u7684\u5b9e\u7528\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u67b6\u6784\u5728\u5b89\u5168\u5173\u952e\u957f\u5c3e\u573a\u666f\u4e2d\u6027\u80fd\u4e0d\u4f73\uff0c\u76d1\u7763\u5c11\u4e14\u56e0\u679c\u7406\u89e3\u6709\u9650\uff0c\u9700\u6539\u8fdb\u81ea\u52a8\u9a7e\u9a76\u51b3\u7b56\u3002", "method": "\u5f15\u5165AR1\u6a21\u578b\uff0c\u6784\u5efa\u56e0\u679c\u94fe\u6570\u636e\u96c6\uff0c\u91c7\u7528\u6a21\u5757\u5316VLA\u67b6\u6784\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u8f68\u8ff9\u89e3\u7801\u5668\uff0c\u4f7f\u7528\u591a\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u6311\u6218\u6027\u6848\u4f8b\u4e2d\u89c4\u5212\u51c6\u786e\u6027\u63d0\u534712%\uff0c\u8d8a\u91ce\u7387\u964d\u4f4e35%\uff0c\u8fd1\u8ddd\u79bb\u76f8\u9047\u7387\u964d\u4f4e25%\uff0c\u63a8\u7406\u8d28\u91cf\u63d0\u534745%\uff0c\u63a8\u7406 - \u52a8\u4f5c\u4e00\u81f4\u6027\u63d0\u534737%\uff0c\u6a21\u578b\u6269\u5c55\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u8f66\u8f7d\u6d4b\u8bd5\u6709\u5b9e\u65f6\u6027\u80fd\u548c\u6210\u529f\u57ce\u5e02\u90e8\u7f72\u3002", "conclusion": "AR1\u901a\u8fc7\u8fde\u63a5\u53ef\u89e3\u91ca\u63a8\u7406\u548c\u7cbe\u786e\u63a7\u5236\uff0c\u4e3a4\u7ea7\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u5b9e\u7528\u8def\u5f84\uff0c\u672a\u6765\u5c06\u53d1\u5e03\u6a21\u578b\u548c\u90e8\u5206\u6570\u636e\u96c6\u3002"}}
{"id": "2511.00699", "pdf": "https://arxiv.org/pdf/2511.00699", "abs": "https://arxiv.org/abs/2511.00699", "authors": ["Sophie Li", "Nicholas Huang", "Nayan Saxena", "Nina Luo", "Vincent Lin", "Kevin Zhu", "Sunishchal Dev"], "title": "Inference-Time Chain-of-Thought Pruning with Latent Informativeness Signals", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) improve reasoning accuracy when generating\nmultiple candidate solutions at test time, but standard methods like Best-of-N\n(BoN) incur high computational cost by fully generating all branches.\nSelf-Truncation Best-of-N (ST-BoN) mitigates this by truncating unpromising\npaths early, but its reliance on consistency-based heuristics is a limitation\nas it does not directly evaluate branch quality. We present KL-Adjusted Pruned\nPath Algorithm (KAPPA), an inference-time method that combines Kullback-Leibler\ndivergence, confidence, and entropy into a principled scoring function to guide\nprogressive pruning. By promoting diversity during exploration and selectively\neliminating low-scoring branches, KAPPA maintains accuracy while substantially\nreducing memory and token usage. Experiments on GSM8K and MATH500 with\nDeepSeek-R1-Distill-Qwen-1.5B and Qwen2.5-7B-Instruct demonstrate that KAPPA\nstabilizes performance in smaller models and achieves up to ~60% reduction in\npeak memory and ~90% reduction in total token generation relative to BoN, with\nminimal impact on accuracy.", "AI": {"tldr": "\u63d0\u51faKAPPA\u7b97\u6cd5\uff0c\u7ed3\u5408KL\u6563\u5ea6\u3001\u7f6e\u4fe1\u5ea6\u548c\u71b5\u6307\u5bfc\u526a\u679d\uff0c\u5728\u63a8\u7406\u65f6\u51cf\u5c11\u5185\u5b58\u548ctoken\u4f7f\u7528\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u7a33\u5b9a\u5c0f\u6a21\u578b\u6027\u80fd\u5e76\u5927\u5e45\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\uff0c\u5bf9\u51c6\u786e\u7387\u5f71\u54cd\u5c0f\u3002", "motivation": "\u6807\u51c6Best-of-N\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0cSelf-Truncation Best-of-N\u4f9d\u8d56\u4e00\u81f4\u6027\u542f\u53d1\u5f0f\u6709\u5c40\u9650\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faKL-Adjusted Pruned Path Algorithm (KAPPA)\uff0c\u5c06Kullback-Leibler\u6563\u5ea6\u3001\u7f6e\u4fe1\u5ea6\u548c\u71b5\u7ed3\u5408\u6210\u8bc4\u5206\u51fd\u6570\u6307\u5bfc\u6e10\u8fdb\u5f0f\u526a\u679d\u3002", "result": "\u5728GSM8K\u548cMATH500\u4e0a\u7528DeepSeek-R1-Distill-Qwen-1.5B\u548cQwen2.5-7B-Instruct\u5b9e\u9a8c\uff0cKAPPA\u7a33\u5b9a\u5c0f\u6a21\u578b\u6027\u80fd\uff0c\u76f8\u6bd4BoN\uff0c\u5cf0\u503c\u5185\u5b58\u6700\u591a\u51cf\u5c11\u7ea660%\uff0c\u603btoken\u751f\u6210\u6700\u591a\u51cf\u5c11\u7ea690%\uff0c\u5bf9\u51c6\u786e\u7387\u5f71\u54cd\u5c0f\u3002", "conclusion": "KAPPA\u80fd\u5728\u4fdd\u6301\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u548ctoken\u4f7f\u7528\u3002"}}
{"id": "2511.00090", "pdf": "https://arxiv.org/pdf/2511.00090", "abs": "https://arxiv.org/abs/2511.00090", "authors": ["Huanlin Gao", "Ping Chen", "Fuyuan Shi", "Chao Tan", "Zhaoxiang Liu", "Fang Zhao", "Kai Wang", "Shiguo Lian"], "title": "LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": "NeurIPS 2025", "summary": "We present LeMiCa, a training-free and efficient acceleration framework for\ndiffusion-based video generation. While existing caching strategies primarily\nfocus on reducing local heuristic errors, they often overlook the accumulation\nof global errors, leading to noticeable content degradation between accelerated\nand original videos. To address this issue, we formulate cache scheduling as a\ndirected graph with error-weighted edges and introduce a Lexicographic Minimax\nPath Optimization strategy that explicitly bounds the worst-case path error.\nThis approach substantially improves the consistency of global content and\nstyle across generated frames. Extensive experiments on multiple text-to-video\nbenchmarks demonstrate that LeMiCa delivers dual improvements in both inference\nspeed and generation quality. Notably, our method achieves a 2.9x speedup on\nthe Latte model and reaches an LPIPS score of 0.05 on Open-Sora, outperforming\nprior caching techniques. Importantly, these gains come with minimal perceptual\nquality degradation, making LeMiCa a robust and generalizable paradigm for\naccelerating diffusion-based video generation. We believe this approach can\nserve as a strong foundation for future research on efficient and reliable\nvideo synthesis. Our code is available at :https://github.com/UnicomAI/LeMiCa", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u4e14\u9ad8\u6548\u7684\u6269\u6563\u89c6\u9891\u751f\u6210\u52a0\u901f\u6846\u67b6LeMiCa\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u63a8\u7406\u901f\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u4e0a\u53cc\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7f13\u5b58\u7b56\u7565\u5e38\u5ffd\u7565\u5168\u5c40\u8bef\u5dee\u7d2f\u79ef\uff0c\u5bfc\u81f4\u52a0\u901f\u89c6\u9891\u4e0e\u539f\u89c6\u9891\u5185\u5bb9\u660e\u663e\u9000\u5316\u3002", "method": "\u5c06\u7f13\u5b58\u8c03\u5ea6\u516c\u5f0f\u5316\u4e3a\u5e26\u8bef\u5dee\u52a0\u6743\u8fb9\u7684\u6709\u5411\u56fe\uff0c\u5f15\u5165\u5b57\u5178\u5e8f\u6781\u5c0f\u6781\u5927\u8def\u5f84\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u6587\u672c\u5230\u89c6\u9891\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLeMiCa\u5b9e\u73b0\u63a8\u7406\u901f\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u53cc\u63d0\u5347\uff0c\u5982\u5728Latte\u6a21\u578b\u4e0a\u5b9e\u73b02.9\u500d\u52a0\u901f\uff0c\u5728Open - Sora\u4e0aLPIPS\u5206\u6570\u8fbe0.05\u3002", "conclusion": "LeMiCa\u662f\u52a0\u901f\u6269\u6563\u89c6\u9891\u751f\u6210\u7684\u5f3a\u5927\u4e14\u901a\u7528\u8303\u5f0f\uff0c\u53ef\u4f5c\u4e3a\u672a\u6765\u9ad8\u6548\u53ef\u9760\u89c6\u9891\u5408\u6210\u7814\u7a76\u7684\u57fa\u7840\u3002"}}
{"id": "2511.00700", "pdf": "https://arxiv.org/pdf/2511.00700", "abs": "https://arxiv.org/abs/2511.00700", "authors": ["Penghang Liu", "Haibei Zhu", "Eleonora Kreacic", "Svitlana Vyetrenko"], "title": "Privacy-Aware Time Series Synthesis via Public Knowledge Distillation", "categories": ["cs.LG"], "comment": "Published on Transactions on Machine Learning Research (TMLR)", "summary": "Sharing sensitive time series data in domains such as finance, healthcare,\nand energy consumption, such as patient records or investment accounts, is\noften restricted due to privacy concerns. Privacy-aware synthetic time series\ngeneration addresses this challenge by enforcing noise during training,\ninherently introducing a trade-off between privacy and utility. In many cases,\nsensitive sequences is correlated with publicly available, non-sensitive\ncontextual metadata (e.g., household electricity consumption may be influenced\nby weather conditions and electricity prices). However, existing privacy-aware\ndata generation methods often overlook this opportunity, resulting in\nsuboptimal privacy-utility trade-offs. In this paper, we present Pub2Priv, a\nnovel framework for generating private time series data by leveraging\nheterogeneous public knowledge. Our model employs a self-attention mechanism to\nencode public data into temporal and feature embeddings, which serve as\nconditional inputs for a diffusion model to generate synthetic private\nsequences. Additionally, we introduce a practical metric to assess privacy by\nevaluating the identifiability of the synthetic data. Experimental results show\nthat Pub2Priv consistently outperforms state-of-the-art benchmarks in improving\nthe privacy-utility trade-off across finance, energy, and commodity trading\ndomains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faPub2Priv\u6846\u67b6\uff0c\u5229\u7528\u5f02\u6784\u516c\u5171\u77e5\u8bc6\u751f\u6210\u79c1\u6709\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u591a\u4e2a\u9886\u57df\u6539\u5584\u9690\u79c1 - \u6548\u7528\u6743\u8861\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u9690\u79c1\u611f\u77e5\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5e38\u5ffd\u7565\u654f\u611f\u5e8f\u5217\u4e0e\u516c\u5f00\u975e\u654f\u611f\u4e0a\u4e0b\u6587\u5143\u6570\u636e\u7684\u5173\u8054\uff0c\u5bfc\u81f4\u9690\u79c1 - \u6548\u7528\u6743\u8861\u4e0d\u4f73\u3002", "method": "\u63d0\u51faPub2Priv\u6846\u67b6\uff0c\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5c06\u516c\u5171\u6570\u636e\u7f16\u7801\u4e3a\u65f6\u95f4\u548c\u7279\u5f81\u5d4c\u5165\uff0c\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u6761\u4ef6\u8f93\u5165\u751f\u6210\u5408\u6210\u79c1\u6709\u5e8f\u5217\uff0c\u8fd8\u5f15\u5165\u5b9e\u7528\u6307\u6807\u8bc4\u4f30\u9690\u79c1\u3002", "result": "Pub2Priv\u5728\u91d1\u878d\u3001\u80fd\u6e90\u548c\u5546\u54c1\u4ea4\u6613\u9886\u57df\u6539\u5584\u9690\u79c1 - \u6548\u7528\u6743\u8861\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "Pub2Priv\u6846\u67b6\u80fd\u6709\u6548\u5229\u7528\u516c\u5171\u77e5\u8bc6\u751f\u6210\u79c1\u6709\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5728\u9690\u79c1 - \u6548\u7528\u6743\u8861\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.00094", "pdf": "https://arxiv.org/pdf/2511.00094", "abs": "https://arxiv.org/abs/2511.00094", "authors": ["Angelos Alexopoulos", "Agorakis Bompotas", "Nikitas Rigas Kalogeropoulos", "Panagiotis Kechagias", "Athanasios P. Kalogeras", "Christos Alexakos"], "title": "Digital Twin based Automatic Reconfiguration of Robotic Systems in Smart Environments", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "Accepted for presentation to 11th IEEE International Smart Cities\n  Conference (ISC2 2025)", "summary": "Robotic systems have become integral to smart environments, enabling\napplications ranging from urban surveillance and automated agriculture to\nindustrial automation. However, their effective operation in dynamic settings -\nsuch as smart cities and precision farming - is challenged by continuously\nevolving topographies and environmental conditions. Traditional control systems\noften struggle to adapt quickly, leading to inefficiencies or operational\nfailures. To address this limitation, we propose a novel framework for\nautonomous and dynamic reconfiguration of robotic controllers using Digital\nTwin technology. Our approach leverages a virtual replica of the robot's\noperational environment to simulate and optimize movement trajectories in\nresponse to real-world changes. By recalculating paths and control parameters\nin the Digital Twin and deploying the updated code to the physical robot, our\nmethod ensures rapid and reliable adaptation without manual intervention. This\nwork advances the integration of Digital Twins in robotics, offering a scalable\nsolution for enhancing autonomy in smart, dynamic environments.", "AI": {"tldr": "\u63d0\u51fa\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u5b9e\u73b0\u673a\u5668\u4eba\u63a7\u5236\u5668\u81ea\u4e3b\u52a8\u6001\u91cd\u65b0\u914d\u7f6e\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u63a7\u5236\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u9002\u5e94\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u63a7\u5236\u7cfb\u7edf\u96be\u4ee5\u5728\u52a8\u6001\u73af\u5883\u5feb\u901f\u9002\u5e94\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u6216\u8fd0\u884c\u5931\u8d25\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5229\u7528\u6570\u5b57\u5b6a\u751f\u6280\u672f\u521b\u5efa\u673a\u5668\u4eba\u8fd0\u884c\u73af\u5883\u865a\u62df\u526f\u672c\uff0c\u6a21\u62df\u4f18\u5316\u8fd0\u52a8\u8f68\u8ff9\uff0c\u91cd\u65b0\u8ba1\u7b97\u8def\u5f84\u548c\u63a7\u5236\u53c2\u6570\u5e76\u90e8\u7f72\u5230\u7269\u7406\u673a\u5668\u4eba\u3002", "result": "\u53ef\u5728\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u4e0b\u5b9e\u73b0\u673a\u5668\u4eba\u5feb\u901f\u53ef\u9760\u9002\u5e94\u3002", "conclusion": "\u63a8\u8fdb\u6570\u5b57\u5b6a\u751f\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u96c6\u6210\uff0c\u4e3a\u667a\u80fd\u52a8\u6001\u73af\u5883\u63d0\u5347\u81ea\u4e3b\u6027\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00095", "pdf": "https://arxiv.org/pdf/2511.00095", "abs": "https://arxiv.org/abs/2511.00095", "authors": ["Jiaming Liu", "Dingwei Fan", "Junyong Zhao", "Chunlin Li", "Haipeng Si", "Liang Sun"], "title": "SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation", "categories": ["cs.CV", "cs.AI", "92C55", "I.2.10"], "comment": "2 Tables,5 Figures,16 Equations", "summary": "The anatomical structure segmentation of the spine and adjacent structures\nfrom computed tomography (CT) images is a key step for spinal disease diagnosis\nand treatment. However, the segmentation of CT images is impeded by low\ncontrast and complex vertebral boundaries. Although advanced models such as the\nSegment Anything Model (SAM) have shown promise in various segmentation tasks,\ntheir performance in spinal CT imaging is limited by high annotation\nrequirements and poor domain adaptability. To address these limitations, we\npropose SpinalSAM-R1, a multimodal vision-language interactive system that\nintegrates a fine-tuned SAM with DeepSeek-R1, for spine CT image segmentation.\nSpecifically, our SpinalSAM-R1 introduces an anatomy-guided attention mechanism\nto improve spine segmentation performance, and a semantics-driven interaction\nprotocol powered by DeepSeek-R1, enabling natural language-guided refinement.\nThe SpinalSAM-R1 is fine-tuned using Low-Rank Adaptation (LoRA) for efficient\nadaptation. We validate our SpinalSAM-R1 on the spine anatomical structure with\nCT images. Experimental results suggest that our method achieves superior\nsegmentation performance. Meanwhile, we develop a PyQt5-based interactive\nsoftware, which supports point, box, and text-based prompts. The system\nsupports 11 clinical operations with 94.3\\% parsing accuracy and sub-800 ms\nresponse times. The software is released on\nhttps://github.com/6jm233333/spinalsam-r1.", "AI": {"tldr": "\u63d0\u51faSpinalSAM - R1\u7528\u4e8e\u810a\u67f1CT\u56fe\u50cf\u5206\u5272\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\uff0c\u8fd8\u5f00\u53d1\u4ea4\u4e92\u8f6f\u4ef6\u5e76\u5f00\u6e90", "motivation": "\u810a\u67f1CT\u56fe\u50cf\u5206\u5272\u56e0\u5bf9\u6bd4\u5ea6\u4f4e\u3001\u8fb9\u754c\u590d\u6742\u53d7\u963b\u788d\uff0c\u73b0\u6709\u6a21\u578b\u5982SAM\u5728\u810a\u67f1CT\u6210\u50cf\u4e2d\u5b58\u5728\u9ad8\u6807\u6ce8\u8981\u6c42\u548c\u9886\u57df\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u89c6\u89c9 - \u8bed\u8a00\u4ea4\u4e92\u7cfb\u7edfSpinalSAM - R1\uff0c\u96c6\u6210\u5fae\u8c03\u7684SAM\u548cDeepSeek - R1\uff0c\u5f15\u5165\u89e3\u5256\u5f15\u5bfc\u6ce8\u610f\u529b\u673a\u5236\u548c\u8bed\u4e49\u9a71\u52a8\u4ea4\u4e92\u534f\u8bae\uff0c\u4f7f\u7528LoRA\u5fae\u8c03", "result": "\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u5206\u5272\u6027\u80fd\uff0c\u5f00\u53d1\u7684\u8f6f\u4ef6\u652f\u630111\u79cd\u4e34\u5e8a\u64cd\u4f5c\uff0c\u89e3\u6790\u51c6\u786e\u738794.3%\uff0c\u54cd\u5e94\u65f6\u95f4\u4f4e\u4e8e800ms", "conclusion": "SpinalSAM - R1\u5728\u810a\u67f1CT\u56fe\u50cf\u5206\u5272\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5f00\u53d1\u7684\u8f6f\u4ef6\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2511.00711", "pdf": "https://arxiv.org/pdf/2511.00711", "abs": "https://arxiv.org/abs/2511.00711", "authors": ["Nardeep Kumar", "Arun Kanwar"], "title": "TRISKELION-1: Unified Descriptive-Predictive-Generative AI", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 18 figures, submitted to arXiv (2025)", "summary": "TRISKELION-1 is a unified descriptive-predictive-generative architecture that\nintegrates statistical, mechanistic, and generative reasoning within a single\nencoder-decoder framework. The model demonstrates how descriptive\nrepresentation learning, predictive inference, and generative synthesis can be\njointly optimized using variational objectives. Experiments on MNIST validate\nthat descriptive reconstruction, predictive classification, and generative\nsampling can coexist stably within one model. The framework provides a\nblueprint toward universal intelligence architectures that connect\ninterpretability, accuracy, and creativity.", "AI": {"tldr": "TRISKELION - 1\u662f\u7edf\u4e00\u67b6\u6784\uff0c\u7528\u53d8\u5206\u76ee\u6807\u8054\u5408\u4f18\u5316\u63cf\u8ff0\u3001\u9884\u6d4b\u548c\u751f\u6210\uff0cMNIST\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u7a33\u5b9a\u6027\uff0c\u4e3a\u901a\u7528\u667a\u80fd\u67b6\u6784\u63d0\u4f9b\u84dd\u56fe\u3002", "motivation": "\u6784\u5efa\u80fd\u96c6\u6210\u7edf\u8ba1\u3001\u673a\u68b0\u548c\u751f\u6210\u63a8\u7406\uff0c\u8054\u5408\u4f18\u5316\u63cf\u8ff0\u3001\u9884\u6d4b\u548c\u751f\u6210\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u8fc8\u5411\u901a\u7528\u667a\u80fd\u67b6\u6784\u3002", "method": "\u5728\u5355\u4e2a\u7f16\u89e3\u7801\u5668\u6846\u67b6\u4e2d\u6574\u5408\u591a\u79cd\u63a8\u7406\uff0c\u4f7f\u7528\u53d8\u5206\u76ee\u6807\u8fdb\u884c\u8054\u5408\u4f18\u5316\u3002", "result": "MNIST\u5b9e\u9a8c\u9a8c\u8bc1\u63cf\u8ff0\u6027\u91cd\u5efa\u3001\u9884\u6d4b\u6027\u5206\u7c7b\u548c\u751f\u6210\u6027\u91c7\u6837\u53ef\u5728\u4e00\u4e2a\u6a21\u578b\u4e2d\u7a33\u5b9a\u5171\u5b58\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8fde\u63a5\u53ef\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u521b\u9020\u6027\u7684\u901a\u7528\u667a\u80fd\u67b6\u6784\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002"}}
{"id": "2511.00096", "pdf": "https://arxiv.org/pdf/2511.00096", "abs": "https://arxiv.org/abs/2511.00096", "authors": ["Shangyu Lou"], "title": "Urban-MAS: Human-Centered Urban Prediction with LLM-Based Multi-Agent System", "categories": ["cs.MA", "cs.AI", "cs.CY"], "comment": "Accepted to The 3rd ACM SIGSPATIAL International Workshop on Advances\n  in Urban AI (UrbanAI'25)", "summary": "Urban Artificial Intelligence (Urban AI) has advanced human-centered urban\ntasks such as perception prediction and human dynamics. Large Language Models\n(LLMs) can integrate multimodal inputs to address heterogeneous data in complex\nurban systems but often underperform on domain-specific tasks. Urban-MAS, an\nLLM-based Multi-Agent System (MAS) framework, is introduced for human- centered\nurban prediction under zero-shot settings. It includes three agent types:\nPredictive Factor Guidance Agents, which prioritize key predictive factors to\nguide knowledge extraction and enhance the effectiveness of compressed urban\nknowledge in LLMs; Reliable UrbanInfo Extraction Agents, which improve\nrobustness by com- paring multiple outputs, validating consistency, and\nre-extracting when conflicts occur; and Multi-UrbanInfo Inference Agents, which\nintegrate extracted multi-source information across dimensions for prediction.\nExperiments on running-amount prediction and ur- ban perception across Tokyo,\nMilan, and Seattle demonstrate that Urban-MAS substantially reduces errors\ncompared to single-LLM baselines. Ablation studies indicate that Predictive\nFactor Guidance Agents are most critical for enhancing predictive performance,\npo- sitioning Urban-MAS as a scalable paradigm for human-centered urban AI\nprediction. Code is available on the project\nwebsite:https://github.com/THETUREHOOHA/UrbanMAS", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684Multi - Agent System\u6846\u67b6Urban - MAS\u7528\u4e8e\u96f6\u6837\u672c\u4e0b\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u57ce\u5e02\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u5927\u5e45\u51cf\u5c11\u8bef\u5dee\uff0c\u5b9a\u4f4d\u4e3a\u53ef\u6269\u5c55\u8303\u5f0f\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u7279\u5b9a\u9886\u57df\u57ce\u5e02\u4efb\u52a1\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u65b0\u65b9\u6cd5\u8fdb\u884c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u57ce\u5e02\u9884\u6d4b\u3002", "method": "\u5f15\u5165Urban - MAS\u6846\u67b6\uff0c\u5305\u542bPredictive Factor Guidance Agents\u3001Reliable UrbanInfo Extraction Agents\u548cMulti - UrbanInfo Inference Agents\u4e09\u79cd\u4ee3\u7406\u7c7b\u578b\u3002", "result": "\u5728\u4e1c\u4eac\u3001\u7c73\u5170\u548c\u897f\u96c5\u56fe\u7684\u8fd0\u884c\u91cf\u9884\u6d4b\u548c\u57ce\u5e02\u611f\u77e5\u5b9e\u9a8c\u4e2d\uff0cUrban - MAS\u6bd4\u5355LLM\u57fa\u7ebf\u5927\u5e45\u51cf\u5c11\u8bef\u5dee\uff0c\u6d88\u878d\u5b9e\u9a8c\u8868\u660ePredictive Factor Guidance Agents\u5bf9\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u6700\u5173\u952e\u3002", "conclusion": "Urban - MAS\u662f\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u57ce\u5e02AI\u9884\u6d4b\u7684\u53ef\u6269\u5c55\u8303\u5f0f\u3002"}}
{"id": "2511.00716", "pdf": "https://arxiv.org/pdf/2511.00716", "abs": "https://arxiv.org/abs/2511.00716", "authors": ["Rama Kassoumeh", "David R\u00fcgamer", "Henning Oppel"], "title": "Enhancing Heavy Rain Nowcasting with Multimodal Data: Integrating Radar and Satellite Observations", "categories": ["cs.LG"], "comment": "accepted to ICMLA 2025", "summary": "The increasing frequency of heavy rainfall events, which are a major cause of\nurban flooding, underscores the urgent need for accurate precipitation\nforecasting - particularly in urban areas where localized events often go\nundetected by ground-based sensors. In Germany, only 17.3% of hourly heavy rain\nevents between 2001 and 2018 were recorded by rain gauges, highlighting the\nlimitations of traditional monitoring systems. Radar data are another source\nthat effectively tracks ongoing precipitation; however, forecasting the\ndevelopment of heavy rain using radar alone remains challenging due to the\nbrief and unpredictable nature of such events. Our focus is on evaluating the\neffectiveness of fusing satellite and radar data for nowcasting. We develop a\nmultimodal nowcasting model that combines both radar and satellite imagery for\npredicting precipitation at lead times of 5, 15, and 30 minutes. We demonstrate\nthat this multimodal strategy significantly outperforms radar-only approaches.\nExperimental results show that integrating satellite data improves prediction\naccuracy, particularly for intense precipitation. The proposed model increases\nthe Critical Success Index for heavy rain by 4% and for violent rain by 3% at a\n5-minute lead time. Moreover, it maintains higher predictive skill at longer\nlead times, where radar-only performance declines. A qualitative analysis of\nthe severe flooding event in the state of North Rhine-Westphalia, Germany in\n2021 further illustrates the superior performance of the multimodal model.\nUnlike the radar-only model, which captures general precipitation patterns, the\nmultimodal model yields more detailed and accurate forecasts for regions\naffected by heavy rain. This improved precision enables timely, reliable,\nlife-saving warnings. Implementation available at\nhttps://github.com/RamaKassoumeh/Multimodal_heavy_rain", "AI": {"tldr": "\u6587\u7ae0\u8bc4\u4f30\u878d\u5408\u536b\u661f\u4e0e\u96f7\u8fbe\u6570\u636e\u8fdb\u884c\u4e34\u8fd1\u9884\u62a5\u7684\u6709\u6548\u6027\uff0c\u5f00\u53d1\u591a\u6a21\u6001\u4e34\u8fd1\u9884\u62a5\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u6a21\u578b\u4f18\u4e8e\u4ec5\u7528\u96f7\u8fbe\u7684\u65b9\u6cd5\uff0c\u80fd\u63d0\u9ad8\u9884\u62a5\u7cbe\u5ea6\u5e76\u63d0\u4f9b\u66f4\u51c6\u786e\u9884\u8b66\u3002", "motivation": "\u57ce\u5e02\u66b4\u96e8\u9891\u53d1\u81f4\u57ce\u5e02\u5185\u6d9d\uff0c\u4f20\u7edf\u76d1\u6d4b\u7cfb\u7edf\u6709\u5c40\u9650\uff0c\u4ec5\u7528\u96f7\u8fbe\u9884\u62a5\u66b4\u96e8\u6709\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8bc4\u4f30\u878d\u5408\u536b\u661f\u4e0e\u96f7\u8fbe\u6570\u636e\u8fdb\u884c\u4e34\u8fd1\u9884\u62a5\u7684\u6709\u6548\u6027\u3002", "method": "\u5f00\u53d1\u7ed3\u5408\u96f7\u8fbe\u548c\u536b\u661f\u56fe\u50cf\u7684\u591a\u6a21\u6001\u4e34\u8fd1\u9884\u62a5\u6a21\u578b\uff0c\u9884\u6d4b5\u300115\u548c30\u5206\u949f\u7684\u964d\u6c34\u60c5\u51b5\u3002", "result": "\u591a\u6a21\u6001\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u4ec5\u7528\u96f7\u8fbe\u7684\u65b9\u6cd5\uff0c\u6574\u5408\u536b\u661f\u6570\u636e\u63d0\u9ad8\u4e86\u9884\u62a5\u7cbe\u5ea6\uff0c\u5c24\u5176\u5bf9\u5f3a\u964d\u6c34\uff1b\u57285\u5206\u949f\u63d0\u524d\u9884\u62a5\u65f6\uff0c\u8be5\u6a21\u578b\u4f7f\u66b4\u96e8\u548c\u5927\u66b4\u96e8\u7684\u4e34\u754c\u6210\u529f\u6307\u6570\u5206\u522b\u63d0\u9ad84%\u548c3%\uff0c\u4e14\u5728\u8f83\u957f\u63d0\u524d\u65f6\u95f4\u9884\u62a5\u65f6\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u591a\u6a21\u6001\u6a21\u578b\u9884\u62a5\u66f4\u7cbe\u786e\uff0c\u80fd\u63d0\u4f9b\u53ca\u65f6\u3001\u53ef\u9760\u3001\u6551\u547d\u7684\u9884\u8b66\u3002"}}
{"id": "2511.00747", "pdf": "https://arxiv.org/pdf/2511.00747", "abs": "https://arxiv.org/abs/2511.00747", "authors": ["Zixuan Ma", "Chenfeng Huang"], "title": "Effective Series Decomposition and Components Learning for Time Series Generation", "categories": ["cs.LG"], "comment": "Accepted at IEEE International Conference on Data Mining (ICDM 2025).\n  Camera-ready version to appear", "summary": "Time series generation focuses on modeling the underlying data distribution\nand resampling to produce authentic time series data. Key components, such as\ntrend and seasonality, drive temporal fluctuations, yet many existing\napproaches fail to employ interpretative decomposition methods, limiting their\nability to synthesize meaningful trend and seasonal patterns. To address this\ngap, we introduce Seasonal-Trend Diffusion (STDiffusion), a novel framework for\nmultivariate time series generation that integrates diffusion probabilistic\nmodels with advanced learnable series decomposition techniques, enhancing the\ninterpretability of the generation process. Our approach separates the trend\nand seasonal learning into distinct blocks: a Multi-Layer Perceptron (MLP)\nstructure captures the trend, while adaptive wavelet distillation facilitates\neffective multi-resolution learning of seasonal components. This decomposition\nimproves the interpretability of the model on multiple scales. In addition, we\ndesigned a comprehensive correction mechanism aimed at ensuring that the\ngenerated components exhibit a high degree of internal consistency and preserve\nmeaningful interrelationships with one another. Our empirical studies on eight\nreal-world datasets demonstrate that STDiffusion achieves state-of-the-art\nperformance in time series generation tasks. Furthermore, we extend the model's\napplication to multi-window long-sequence time series generation, which\ndelivered reliable results and highlighted its robustness and versatility.", "AI": {"tldr": "\u63d0\u51faSTDiffusion\u6846\u67b6\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u751f\u6210\uff0c\u7ed3\u5408\u6269\u6563\u6982\u7387\u6a21\u578b\u4e0e\u53ef\u5b66\u4e60\u5e8f\u5217\u5206\u89e3\u6280\u672f\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8fbeSOTA\uff0c\u4e14\u5728\u591a\u7a97\u53e3\u957f\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u8868\u73b0\u53ef\u9760\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\u672a\u91c7\u7528\u89e3\u91ca\u6027\u5206\u89e3\u65b9\u6cd5\uff0c\u96be\u4ee5\u5408\u6210\u6709\u610f\u4e49\u7684\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u6a21\u5f0f\u3002", "method": "\u5f15\u5165Seasonal - Trend Diffusion (STDiffusion)\u6846\u67b6\uff0c\u5c06\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u5b66\u4e60\u5206\u79bb\uff0c\u7528MLP\u6355\u6349\u8d8b\u52bf\uff0c\u81ea\u9002\u5e94\u5c0f\u6ce2\u84b8\u998f\u5b66\u4e60\u5b63\u8282\u6027\u6210\u5206\uff0c\u8bbe\u8ba1\u7efc\u5408\u6821\u6b63\u673a\u5236\u3002", "result": "\u5728\u516b\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u7684SOTA\u6027\u80fd\uff0c\u5728\u591a\u7a97\u53e3\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u4e2d\u7ed3\u679c\u53ef\u9760\u3002", "conclusion": "STDiffusion\u6846\u67b6\u5177\u6709\u9ad8\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u548c\u901a\u7528\u6027\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u751f\u6210\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2511.00098", "pdf": "https://arxiv.org/pdf/2511.00098", "abs": "https://arxiv.org/abs/2511.00098", "authors": ["Nils Porsche", "Flurin M\u00fcller-Diesing", "Sweta Banerjee", "Miguel Goncalves", "Marc Aubreville"], "title": "A filtering scheme for confocal laser endomicroscopy (CLE)-video sequences for self-supervised learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Confocal laser endomicroscopy (CLE) is a non-invasive, real-time imaging\nmodality that can be used for in-situ, in-vivo imaging and the microstructural\nanalysis of mucous structures. The diagnosis using CLE is, however, complicated\nby images being hard to interpret for non-experienced physicians. Utilizing\nmachine learning as an augmentative tool would hence be beneficial, but is\ncomplicated by the shortage of histopathology-correlated CLE imaging sequences\nwith respect to the plurality of patterns in this domain, leading to\noverfitting of machine learning models. To overcome this, self-supervised\nlearning (SSL) can be employed on larger unlabeled datasets. CLE is a\nvideo-based modality with high inter-frame correlation, leading to a\nnon-stratified data distribution for SSL training. In this work, we propose a\nfilter functionality on CLE video sequences to reduce the dataset redundancy in\nSSL training and improve SSL training convergence and training efficiency. We\nuse four state-of-the-art baseline networks and a SSL teacher-student network\nwith a vision transformer small backbone for the evaluation. These networks\nwere evaluated on downstream tasks for a sinonasal tumor dataset and a squamous\ncell carcinoma of the skin dataset. On both datasets, we found the highest test\naccuracy on the filtered SSL-pretrained model, with 67.48% and 73.52%, both\nconsiderably outperforming their non-SSL baselines. Our results show that SSL\nis an effective method for CLE pretraining. Further, we show that our proposed\nCLE video filter can be utilized to improve training efficiency in\nself-supervised scenarios, resulting in a reduction of 67% in training time.", "AI": {"tldr": "\u63d0\u51fa\u5728CLE\u89c6\u9891\u5e8f\u5217\u4e0a\u4f7f\u7528\u8fc7\u6ee4\u529f\u80fd\u4ee5\u51cf\u5c11\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u8bad\u7ec3\u65f6\u6570\u636e\u96c6\u5197\u4f59\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6536\u655b\u6027\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "CLE\u8bca\u65ad\u56fe\u50cf\u96be\u89e3\u8bfb\uff0c\u673a\u5668\u5b66\u4e60\u56e0\u7f3a\u4e4f\u75c5\u7406\u76f8\u5173\u56fe\u50cf\u5e8f\u5217\u6613\u8fc7\u62df\u5408\uff0c\u4e14CLE\u89c6\u9891\u5e27\u95f4\u76f8\u5173\u6027\u9ad8\uff0c\u6570\u636e\u5206\u5e03\u975e\u5206\u5c42\uff0c\u5f71\u54cdSSL\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u5728CLE\u89c6\u9891\u5e8f\u5217\u4e0a\u7684\u8fc7\u6ee4\u529f\u80fd\uff0c\u7528\u56db\u4e2a\u5148\u8fdb\u57fa\u7ebf\u7f51\u7edc\u548c\u5e26\u89c6\u89c9\u53d8\u538b\u5668\u5c0f\u9aa8\u5e72\u7684SSL\u5e08\u751f\u7f51\u7edc\u8bc4\u4f30\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0b\u6e38\u4efb\u52a1\u8bc4\u4f30\u3002", "result": "\u8fc7\u6ee4\u540e\u7684SSL\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u6d4b\u8bd5\u51c6\u786e\u7387\u6700\u9ad8\uff0c\u5206\u522b\u4e3a67.48%\u548c73.52%\uff0c\u663e\u8457\u4f18\u4e8e\u975eSSL\u57fa\u7ebf\u3002", "conclusion": "SSL\u662fCLE\u9884\u8bad\u7ec3\u6709\u6548\u65b9\u6cd5\uff0c\u63d0\u51fa\u7684CLE\u89c6\u9891\u8fc7\u6ee4\u5668\u53ef\u63d0\u9ad8\u81ea\u76d1\u7763\u573a\u666f\u8bad\u7ec3\u6548\u7387\uff0c\u51cf\u5c1167%\u8bad\u7ec3\u65f6\u95f4\u3002"}}
{"id": "2511.00794", "pdf": "https://arxiv.org/pdf/2511.00794", "abs": "https://arxiv.org/abs/2511.00794", "authors": ["Yan Sun", "Jia Guo", "Stanley Kok", "Zihao Wang", "Zujie Wen", "Zhiqiang Zhang"], "title": "Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has improved the\nreasoning ability of large language models, yet training remains costly because\nmany rollouts contribute little to optimization, considering the amount of\ncomputation required. This study investigates how simply leveraging intrinsic\ndata properties, almost free benefit during training, can improve data\nefficiency for RLVR. We propose PREPO with two complementary components. First,\nwe adopt prompt perplexity as an indicator of model adaptability in learning,\nenabling the model to progress from well-understood contexts to more\nchallenging ones. Second, we amplify the discrepancy among the rollouts by\ndifferentiating their relative entropy, and prioritize sequences that exhibit a\nhigher degree of exploration. Together, these mechanisms reduce rollout demand\nwhile preserving competitive performance. On the Qwen and Llama models, PREPO\nachieves effective results on mathematical reasoning benchmarks with up to 3\ntimes fewer rollouts than the baselines. Beyond empirical gains, we provide\ntheoretical and in-depth analyses explaining the underlying rationale of our\nmethod to improve the data efficiency of RLVR.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faPREPO\u65b9\u6cd5\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u7684\u6570\u636e\u6548\u7387\uff0c\u51cf\u5c11\u6eda\u52a8\u6b65\u6570\uff0c\u5728Qwen\u548cLlama\u6a21\u578b\u4e0a\u53d6\u5f97\u6548\u679c\u5e76\u7ed9\u51fa\u7406\u8bba\u5206\u6790\u3002", "motivation": "RLVR\u8bad\u7ec3\u6210\u672c\u9ad8\uff0c\u8bb8\u591a\u6eda\u52a8\u5bf9\u4f18\u5316\u8d21\u732e\u5c0f\uff0c\u7814\u7a76\u5982\u4f55\u5229\u7528\u5185\u5728\u6570\u636e\u5c5e\u6027\u63d0\u5347\u6570\u636e\u6548\u7387\u3002", "method": "\u63d0\u51faPREPO\u65b9\u6cd5\uff0c\u5305\u542b\u91c7\u7528\u63d0\u793a\u56f0\u60d1\u5ea6\u6307\u793a\u6a21\u578b\u5b66\u4e60\u9002\u5e94\u6027\uff0c\u901a\u8fc7\u533a\u5206\u76f8\u5bf9\u71b5\u653e\u5927\u6eda\u52a8\u5dee\u5f02\u5e76\u4f18\u5148\u63a2\u7d22\u5ea6\u9ad8\u7684\u5e8f\u5217\u3002", "result": "\u5728Qwen\u548cLlama\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPREPO\u6bd4\u57fa\u7ebf\u6700\u591a\u51cf\u5c113\u500d\u6eda\u52a8\u6b65\u6570\u4e14\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "PREPO\u80fd\u6709\u6548\u63d0\u5347RLVR\u7684\u6570\u636e\u6548\u7387\uff0c\u540c\u65f6\u7ed9\u51fa\u7406\u8bba\u548c\u6df1\u5165\u5206\u6790\u89e3\u91ca\u65b9\u6cd5\u539f\u7406\u3002"}}
{"id": "2511.00797", "pdf": "https://arxiv.org/pdf/2511.00797", "abs": "https://arxiv.org/abs/2511.00797", "authors": ["Wang Zixian"], "title": "Attention Saturation and Gradient Suppression at Inflection Layers: Diagnosing and Mitigating Bottlenecks in Transformer Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Pre-trained Transformers often exhibit over-confidence in source patterns and\ndifficulty in forming new target-domain patterns during fine-tuning. We\nformalize the mechanism of output saturation leading to gradient suppression\nthrough standard cross-entropy and softmax analysis, showing that gradient\nsuppression at inflection layers confines adaptation to high-level\nrecombination of existing features while preventing low-level reconstruction.\nWe introduce a set of layer-wise diagnostic metrics -- attention entropy\n(saturation proxy), activation gradient norm, parameter gradient norm, and\nDelta-CKA under a shared PCA basis -- to identify inflection layers\ncharacterized by both low attention entropy and steep gradient decay. Building\non these findings, we propose a diagnose-first, inject-light fine-tuning\nstrategy: selectively inserting LoRA adapters at inflection layers to restore\nsuppressed backward signals with minimal parameter overhead. Experiments on\nBERT-base transfer from SST-2 to Rotten Tomatoes under under-trained and\nover-trained source regimes reveal that over-trained initialization benefits\nfrom inflection-layer LoRA injection, while under-trained initialization\nsuffers performance degradation. When base features are strong, unblocking\ninflection layers facilitates high-level compositional adaptation; when base\nfeatures are weak, full-pathway unblocking is required for low-level\nreconstruction, as supported by joint analysis of layer-wise activation\ngradients and Delta-CKA dynamics.", "AI": {"tldr": "\u9884\u8bad\u7ec3Transformer\u5728\u5fae\u8c03\u65f6\u5b58\u5728\u95ee\u9898\uff0c\u672c\u6587\u5206\u6790\u8f93\u51fa\u9971\u548c\u673a\u5236\uff0c\u5f15\u5165\u8bca\u65ad\u6307\u6807\u8bc6\u522b\u62d0\u70b9\u5c42\uff0c\u63d0\u51fa\u5fae\u8c03\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u4e0d\u540c\u9884\u8bad\u7ec3\u60c5\u51b5\u6548\u679c\u4e0d\u540c\u3002", "motivation": "\u89e3\u51b3\u9884\u8bad\u7ec3Transformer\u5728\u5fae\u8c03\u65f6\u5bf9\u6e90\u6a21\u5f0f\u8fc7\u5ea6\u81ea\u4fe1\u3001\u96be\u4ee5\u5f62\u6210\u65b0\u76ee\u6807\u57df\u6a21\u5f0f\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6807\u51c6\u4ea4\u53c9\u71b5\u548csoftmax\u5206\u6790\u8f93\u51fa\u9971\u548c\u673a\u5236\uff0c\u5f15\u5165\u5c42\u8bca\u65ad\u6307\u6807\u8bc6\u522b\u62d0\u70b9\u5c42\uff0c\u63d0\u51fa\u5148\u8bca\u65ad\u540e\u8f7b\u6ce8\u5165\u7684\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u5728BERT-base\u4eceSST - 2\u8fc1\u79fb\u5230Rotten Tomatoes\u5b9e\u9a8c\u4e2d\uff0c\u8fc7\u8bad\u7ec3\u521d\u59cb\u5316\u4ece\u62d0\u70b9\u5c42LoRA\u6ce8\u5165\u53d7\u76ca\uff0c\u6b20\u8bad\u7ec3\u521d\u59cb\u5316\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u57fa\u7840\u7279\u5f81\u5f3a\u65f6\uff0c\u89e3\u9501\u62d0\u70b9\u5c42\u5229\u4e8e\u9ad8\u5c42\u7ec4\u5408\u9002\u5e94\uff1b\u57fa\u7840\u7279\u5f81\u5f31\u65f6\uff0c\u9700\u5168\u8def\u5f84\u89e3\u9501\u8fdb\u884c\u4f4e\u5c42\u91cd\u5efa\u3002"}}
{"id": "2511.00804", "pdf": "https://arxiv.org/pdf/2511.00804", "abs": "https://arxiv.org/abs/2511.00804", "authors": ["Abhiram Kusumba", "Maitreya Patel", "Kyle Min", "Changhoon Kim", "Chitta Baral", "Yezhou Yang"], "title": "EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment", "categories": ["cs.LG", "cs.CV"], "comment": "NeurIPS'25 Spotlight | Project page: https://eraseflow.github.io/", "summary": "Erasing harmful or proprietary concepts from powerful text to image\ngenerators is an emerging safety requirement, yet current \"concept erasure\"\ntechniques either collapse image quality, rely on brittle adversarial losses,\nor demand prohibitive retraining cycles. We trace these limitations to a myopic\nview of the denoising trajectories that govern diffusion based generation. We\nintroduce EraseFlow, the first framework that casts concept unlearning as\nexploration in the space of denoising paths and optimizes it with GFlowNets\nequipped with the trajectory balance objective. By sampling entire trajectories\nrather than single end states, EraseFlow learns a stochastic policy that steers\ngeneration away from target concepts while preserving the model's prior.\nEraseFlow eliminates the need for carefully crafted reward models and by doing\nthis, it generalizes effectively to unseen concepts and avoids hackable rewards\nwhile improving the performance. Extensive empirical results demonstrate that\nEraseFlow outperforms existing baselines and achieves an optimal trade off\nbetween performance and prior preservation.", "AI": {"tldr": "\u63d0\u51faEraseFlow\u6846\u67b6\u7528\u4e8e\u4ece\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u5668\u4e2d\u64e6\u9664\u6709\u5bb3\u6216\u4e13\u6709\u6982\u5ff5\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6982\u5ff5\u64e6\u9664\u6280\u672f\u5b58\u5728\u964d\u4f4e\u56fe\u50cf\u8d28\u91cf\u3001\u4f9d\u8d56\u4e0d\u7a33\u5b9a\u5bf9\u6297\u635f\u5931\u6216\u9700\u8981\u5927\u91cf\u518d\u8bad\u7ec3\u5468\u671f\u7b49\u95ee\u9898\u3002", "method": "\u5c06\u6982\u5ff5\u9057\u5fd8\u89c6\u4e3a\u53bb\u566a\u8def\u5f84\u7a7a\u95f4\u7684\u63a2\u7d22\uff0c\u7528\u914d\u5907\u8f68\u8ff9\u5e73\u8861\u76ee\u6807\u7684GFlowNets\u8fdb\u884c\u4f18\u5316\uff0c\u5b66\u4e60\u968f\u673a\u7b56\u7565\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eEraseFlow\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u6027\u80fd\u548c\u5148\u9a8c\u4fdd\u7559\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6700\u4f73\u6743\u8861\u3002", "conclusion": "EraseFlow\u6709\u6548\u6d88\u9664\u4e86\u5bf9\u7cbe\u5fc3\u8bbe\u8ba1\u5956\u52b1\u6a21\u578b\u7684\u9700\u6c42\uff0c\u80fd\u6709\u6548\u6cdb\u5316\u5230\u672a\u89c1\u6982\u5ff5\uff0c\u907f\u514d\u53ef\u7834\u89e3\u7684\u5956\u52b1\uff0c\u540c\u65f6\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2511.00103", "pdf": "https://arxiv.org/pdf/2511.00103", "abs": "https://arxiv.org/abs/2511.00103", "authors": ["Rotem Ezra", "Hedi Zisling", "Nimrod Berman", "Ilan Naiman", "Alexey Gorkor", "Liran Nochumsohn", "Eliya Nachmani", "Omri Azencot"], "title": "FreeSliders: Training-Free, Modality-Agnostic Concept Sliders for Fine-Grained Diffusion Control in Images, Audio, and Video", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models have become state-of-the-art generative models for images,\naudio, and video, yet enabling fine-grained controllable generation, i.e.,\ncontinuously steering specific concepts without disturbing unrelated content,\nremains challenging. Concept Sliders (CS) offer a promising direction by\ndiscovering semantic directions through textual contrasts, but they require\nper-concept training and architecture-specific fine-tuning (e.g., LoRA),\nlimiting scalability to new modalities. In this work we introduce FreeSliders,\na simple yet effective approach that is fully training-free and\nmodality-agnostic, achieved by partially estimating the CS formula during\ninference. To support modality-agnostic evaluation, we extend the CS benchmark\nto include both video and audio, establishing the first suite for fine-grained\nconcept generation control with multiple modalities. We further propose three\nevaluation properties along with new metrics to improve evaluation quality.\nFinally, we identify an open problem of scale selection and non-linear\ntraversals and introduce a two-stage procedure that automatically detects\nsaturation points and reparameterizes traversal for perceptually uniform,\nsemantically meaningful edits. Extensive experiments demonstrate that our\nmethod enables plug-and-play, training-free concept control across modalities,\nimproves over existing baselines, and establishes new tools for principled\ncontrollable generation. An interactive presentation of our benchmark and\nmethod is available at: https://azencot-group.github.io/FreeSliders/", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0\u8bad\u7ec3\u3001\u8de8\u6a21\u6001\u7684FreeSliders\u65b9\u6cd5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u53ef\u63a7\u751f\u6210\uff0c\u6269\u5c55\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u51fa\u8bc4\u4f30\u6307\u6807\uff0c\u89e3\u51b3\u5c3a\u5ea6\u9009\u62e9\u7b49\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u53ef\u63a7\u751f\u6210\u6709\u6311\u6218\uff0cConcept Sliders\u5b58\u5728\u9700\u8bad\u7ec3\u548c\u7279\u5b9a\u67b6\u6784\u5fae\u8c03\u3001\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u63a8\u7406\u65f6\u90e8\u5206\u4f30\u8ba1CS\u516c\u5f0f\u5b9e\u73b0\u65e0\u8bad\u7ec3\u3001\u8de8\u6a21\u6001\u7684FreeSliders\u65b9\u6cd5\uff1b\u6269\u5c55CS\u57fa\u51c6\u6d4b\u8bd5\uff1b\u63d0\u51fa\u8bc4\u4f30\u5c5e\u6027\u548c\u65b0\u6307\u6807\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u7a0b\u5e8f\u89e3\u51b3\u5c3a\u5ea6\u9009\u62e9\u548c\u975e\u7ebf\u6027\u904d\u5386\u95ee\u9898\u3002", "result": "\u65b9\u6cd5\u80fd\u8de8\u6a21\u6001\u5373\u63d2\u5373\u7528\u3001\u65e0\u8bad\u7ec3\u5730\u8fdb\u884c\u6982\u5ff5\u63a7\u5236\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684FreeSliders\u65b9\u6cd5\u4e3a\u53ef\u63a7\u751f\u6210\u5efa\u7acb\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2511.00806", "pdf": "https://arxiv.org/pdf/2511.00806", "abs": "https://arxiv.org/abs/2511.00806", "authors": ["Guangxi Wan", "Peng Zeng", "Xiaoting Dong", "Chunhe Song", "Shijie Cui", "Dong Li", "Qingwei Dong", "Yiyang Liu", "Hongfei Bai"], "title": "Logic-informed reinforcement learning for cross-domain optimization of large-scale cyber-physical systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Cyber-physical systems (CPS) require the joint optimization of discrete cyber\nactions and continuous physical parameters under stringent safety logic\nconstraints. However, existing hierarchical approaches often compromise global\noptimality, whereas reinforcement learning (RL) in hybrid action spaces often\nrelies on brittle reward penalties, masking, or shielding and struggles to\nguarantee constraint satisfaction. We present logic-informed reinforcement\nlearning (LIRL), which equips standard policy-gradient algorithms with\nprojection that maps a low-dimensional latent action onto the admissible hybrid\nmanifold defined on-the-fly by first-order logic. This guarantees feasibility\nof every exploratory step without penalty tuning. Experimental evaluations have\nbeen conducted across multiple scenarios, including industrial manufacturing,\nelectric vehicle charging stations, and traffic signal control, in all of which\nthe proposed method outperforms existing hierarchical optimization approaches.\nTaking a robotic reducer assembly system in industrial manufacturing as an\nexample, LIRL achieves a 36.47\\% to 44.33\\% reduction at most in the combined\nmakespan-energy objective compared to conventional industrial hierarchical\nscheduling methods. Meanwhile, it consistently maintains zero constraint\nviolations and significantly surpasses state-of-the-art hybrid-action\nreinforcement learning baselines. Thanks to its declarative logic-based\nconstraint formulation, the framework can be seamlessly transferred to other\ndomains such as smart transportation and smart grid, thereby paving the way for\nsafe and real-time optimization in large-scale CPS.", "AI": {"tldr": "\u63d0\u51fa\u903b\u8f91\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff08LIRL\uff09\u89e3\u51b3\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u53ef\u65e0\u7f1d\u8f6c\u79fb\u5230\u5176\u4ed6\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u5206\u5c42\u65b9\u6cd5\u96be\u8fbe\u5168\u5c40\u6700\u4f18\uff0c\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u5f3a\u5316\u5b66\u4e60\u96be\u4fdd\u8bc1\u7ea6\u675f\u6ee1\u8db3\u3002", "method": "\u4e3a\u6807\u51c6\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u914d\u5907\u6295\u5f71\uff0c\u5c06\u4f4e\u7ef4\u6f5c\u5728\u52a8\u4f5c\u6620\u5c04\u5230\u7531\u4e00\u9636\u903b\u8f91\u52a8\u6001\u5b9a\u4e49\u7684\u53ef\u5141\u8bb8\u6df7\u5408\u6d41\u5f62\u3002", "result": "\u5728\u591a\u573a\u666f\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u5206\u5c42\u4f18\u5316\u65b9\u6cd5\uff0c\u5982\u5728\u5de5\u4e1a\u5236\u9020\u4e2d\u6700\u591a\u964d\u4f4e36.47% - 44.33%\u7684\u7efc\u5408\u76ee\u6807\u503c\uff0c\u4fdd\u6301\u96f6\u7ea6\u675f\u8fdd\u53cd\u3002", "conclusion": "LIRL\u6846\u67b6\u53ef\u65e0\u7f1d\u8f6c\u79fb\u5230\u5176\u4ed6\u9886\u57df\uff0c\u4e3a\u5927\u89c4\u6a21CPS\u7684\u5b89\u5168\u5b9e\u65f6\u4f18\u5316\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2511.00105", "pdf": "https://arxiv.org/pdf/2511.00105", "abs": "https://arxiv.org/abs/2511.00105", "authors": ["Majid Memari", "Krista Ruggles"], "title": "Artificial Intelligence in Elementary STEM Education: A Systematic Review of Current Applications and Future Challenges", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Artificial intelligence (AI) is transforming elementary STEM education, yet\nevidence remains fragmented. This systematic review synthesizes 258 studies\n(2020-2025) examining AI applications across eight categories: intelligent\ntutoring systems (45% of studies), learning analytics (18%), automated\nassessment (12%), computer vision (8%), educational robotics (7%), multimodal\nsensing (6%), AI-enhanced extended reality (XR) (4%), and adaptive content\ngeneration. The analysis shows that most studies focus on upper elementary\ngrades (65%) and mathematics (38%), with limited cross-disciplinary STEM\nintegration (15%). While conversational AI demonstrates moderate effectiveness\n(d = 0.45-0.70 where reported), only 34% of studies include standardized effect\nsizes. Eight major gaps limit real-world impact: fragmented ecosystems,\ndevelopmental inappropriateness, infrastructure barriers, lack of privacy\nframeworks, weak STEM integration, equity disparities, teacher marginalization,\nand narrow assessment scopes. Geographic distribution is also uneven, with 90%\nof studies originating from North America, East Asia, and Europe. Future\ndirections call for interoperable architectures that support authentic STEM\nintegration, grade-appropriate design, privacy-preserving analytics, and\nteacher-centered implementations that enhance rather than replace human\nexpertise.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u56de\u987e2020 - 2025\u5e74258\u9879\u7814\u7a76\uff0c\u5206\u6790AI\u5728\u521d\u7b49STEM\u6559\u80b2\u5e94\u7528\uff0c\u6307\u51fa\u7814\u7a76\u96c6\u4e2d\u5e74\u7ea7\u3001\u5b66\u79d1\u53ca\u5b58\u5728\u7684\u516b\u5927\u5dee\u8ddd\uff0c\u7ed9\u51fa\u672a\u6765\u65b9\u5411\u3002", "motivation": "AI\u6b63\u6539\u53d8\u521d\u7b49STEM\u6559\u80b2\uff0c\u4f46\u8bc1\u636e\u96f6\u6563\uff0c\u9700\u7cfb\u7edf\u56de\u987e\u76f8\u5173\u7814\u7a76\u3002", "method": "\u5bf9258\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u56de\u987e\u5206\u6790\uff0c\u6d89\u53caAI\u5e94\u7528\u7684\u516b\u4e2a\u7c7b\u522b\u3002", "result": "\u591a\u6570\u7814\u7a76\u96c6\u4e2d\u4e8e\u9ad8\u5e74\u7ea7\u548c\u6570\u5b66\uff0c\u8de8\u5b66\u79d1\u6574\u5408\u5c11\uff1b\u5bf9\u8bdd\u5f0fAI\u6709\u4e00\u5b9a\u6548\u679c\u4f46\u90e8\u5206\u7f3a\u6548\u5e94\u91cf\uff1b\u5b58\u5728\u516b\u5927\u5dee\u8ddd\uff0c\u7814\u7a76\u5730\u57df\u5206\u5e03\u4e0d\u5747\u3002", "conclusion": "\u672a\u6765\u9700\u53ef\u4e92\u64cd\u4f5c\u67b6\u6784\u3001\u9002\u9f84\u8bbe\u8ba1\u3001\u9690\u79c1\u5206\u6790\u53ca\u4ee5\u6559\u5e08\u4e3a\u4e2d\u5fc3\u7684\u5b9e\u65bd\u3002"}}
{"id": "2511.00811", "pdf": "https://arxiv.org/pdf/2511.00811", "abs": "https://arxiv.org/abs/2511.00811", "authors": ["Runyu Lu", "Peng Zhang", "Ruochuan Shi", "Yuanheng Zhu", "Dongbin Zhao", "Yang Liu", "Dong Wang", "Cesare Alippi"], "title": "Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games", "categories": ["cs.LG"], "comment": null, "summary": "Equilibrium learning in adversarial games is an important topic widely\nexamined in the fields of game theory and reinforcement learning (RL).\nPursuit-evasion game (PEG), as an important class of real-world games from the\nfields of robotics and security, requires exponential time to be accurately\nsolved. When the underlying graph structure varies, even the state-of-the-art\nRL methods require recomputation or at least fine-tuning, which can be\ntime-consuming and impair real-time applicability. This paper proposes an\nEquilibrium Policy Generalization (EPG) framework to effectively learn a\ngeneralized policy with robust cross-graph zero-shot performance. In the\ncontext of PEGs, our framework is generally applicable to both pursuer and\nevader sides in both no-exit and multi-exit scenarios. These two\ngeneralizability properties, to our knowledge, are the first to appear in this\ndomain. The core idea of the EPG framework is to train an RL policy across\ndifferent graph structures against the equilibrium policy for each single\ngraph. To construct an equilibrium oracle for single-graph policies, we present\na dynamic programming (DP) algorithm that provably generates pure-strategy Nash\nequilibrium with near-optimal time complexity. To guarantee scalability with\nrespect to pursuer number, we further extend DP and RL by designing a grouping\nmechanism and a sequence model for joint policy decomposition, respectively.\nExperimental results show that, using equilibrium guidance and a distance\nfeature proposed for cross-graph PEG training, the EPG framework guarantees\ndesirable zero-shot performance in various unseen real-world graphs. Besides,\nwhen trained under an equilibrium heuristic proposed for the graphs with exits,\nour generalized pursuer policy can even match the performance of the fine-tuned\npolicies from the state-of-the-art PEG methods.", "AI": {"tldr": "\u63d0\u51faEquilibrium Policy Generalization (EPG)\u6846\u67b6\u7528\u4e8e\u5b66\u4e60\u5177\u6709\u8de8\u56fe\u96f6\u6837\u672c\u6027\u80fd\u7684\u7b56\u7565\uff0c\u89e3\u51b3\u8ffd\u6355\u9003\u907f\u6e38\u620f\u8ba1\u7b97\u8017\u65f6\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8ffd\u6355\u9003\u907f\u6e38\u620f\u51c6\u786e\u6c42\u89e3\u9700\u6307\u6570\u65f6\u95f4\uff0c\u73b0\u6709RL\u65b9\u6cd5\u5728\u56fe\u7ed3\u6784\u53d8\u5316\u65f6\u9700\u91cd\u65b0\u8ba1\u7b97\u6216\u5fae\u8c03\uff0c\u8017\u65f6\u4e14\u5f71\u54cd\u5b9e\u65f6\u6027\u3002", "method": "\u63d0\u51faEPG\u6846\u67b6\uff0c\u8de8\u4e0d\u540c\u56fe\u7ed3\u6784\u8bad\u7ec3RL\u7b56\u7565\uff0c\u7528\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u6784\u5efa\u5355\u56fe\u7b56\u7565\u7684\u5747\u8861\u9884\u8a00\u673a\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5206\u7ec4\u673a\u5236\u548c\u5e8f\u5217\u6a21\u578b\u6269\u5c55DP\u548cRL\u3002", "result": "EPG\u6846\u67b6\u5728\u5404\u79cd\u672a\u89c1\u771f\u5b9e\u56fe\u4e2d\u4fdd\u8bc1\u4e86\u7406\u60f3\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u5e7f\u4e49\u8ffd\u6355\u8005\u7b56\u7565\u80fd\u5339\u914d\u6700\u5148\u8fdb\u65b9\u6cd5\u5fae\u8c03\u7b56\u7565\u7684\u6027\u80fd\u3002", "conclusion": "EPG\u6846\u67b6\u80fd\u6709\u6548\u5b66\u4e60\u5e7f\u4e49\u7b56\u7565\uff0c\u5177\u6709\u8de8\u56fe\u96f6\u6837\u672c\u6027\u80fd\uff0c\u5728\u8ffd\u6355\u9003\u907f\u6e38\u620f\u9886\u57df\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.00106", "pdf": "https://arxiv.org/pdf/2511.00106", "abs": "https://arxiv.org/abs/2511.00106", "authors": ["Anuj Gupta", "Ann Shivers-McNair"], "title": "Wayfinding through the AI wilderness: Mapping rhetorics of ChatGPT prompt writing on X (formerly Twitter) to promote critical AI literacies", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "comment": "Published in the journal Computers and Composition, Issue 74 (2024)", "summary": "In this paper, we demonstrate how studying the rhetorics of ChatGPT prompt\nwriting on social media can promote critical AI literacies. Prompt writing is\nthe process of writing instructions for generative AI tools like ChatGPT to\nelicit desired outputs and there has been an upsurge of conversations about it\non social media. To study this rhetorical activity, we build on four\noverlapping traditions of digital writing research in computers and composition\nthat inform how we frame literacies, how we study social media rhetorics, how\nwe engage iteratively and reflexively with methodologies and technologies, and\nhow we blend computational methods with qualitative methods. Drawing on these\nfour traditions, our paper shows our iterative research process through which\nwe gathered and analyzed a dataset of 32,000 posts (formerly known as tweets)\nfrom X (formerly Twitter) about prompt writing posted between November 2022 to\nMay 2023. We present five themes about these emerging AI literacy practices:\n(1) areas of communication impacted by prompt writing, (2) micro-literacy\nresources shared for prompt writing, (3) market rhetoric shaping prompt\nwriting, (4) rhetorical characteristics of prompts, and (5) definitions of\nprompt writing. In discussing these themes and our methodologies, we highlight\ntakeaways for digital writing teachers and researchers who are teaching and\nanalyzing critical AI literacies.", "AI": {"tldr": "\u7814\u7a76\u793e\u4ea4\u5a92\u4f53\u4e0aChatGPT\u63d0\u793a\u5199\u4f5c\u7684\u4fee\u8f9e\u53ef\u4fc3\u8fdb\u6279\u5224\u6027AI\u7d20\u517b\uff0c\u4ecb\u7ecd\u7814\u7a76\u8fc7\u7a0b\u5e76\u5448\u73b0\u4e94\u4e2a\u65b0\u5174AI\u7d20\u517b\u5b9e\u8df5\u4e3b\u9898\uff0c\u4e3a\u6570\u5b57\u5199\u4f5c\u6559\u5e08\u548c\u7814\u7a76\u8005\u63d0\u4f9b\u542f\u793a\u3002", "motivation": "\u63a2\u8ba8\u7814\u7a76\u793e\u4ea4\u5a92\u4f53\u4e0aChatGPT\u63d0\u793a\u5199\u4f5c\u7684\u4fee\u8f9e\u5bf9\u4fc3\u8fdb\u6279\u5224\u6027AI\u7d20\u517b\u7684\u4f5c\u7528\u3002", "method": "\u57fa\u4e8e\u8ba1\u7b97\u673a\u4e0e\u5199\u4f5c\u9886\u57df\u7684\u56db\u4e2a\u6570\u5b57\u5199\u4f5c\u7814\u7a76\u4f20\u7edf\uff0c\u6536\u96c6\u5e76\u5206\u67902022\u5e7411\u6708\u81f32023\u5e745\u6708X\u5e73\u53f0\u4e0a32,000\u6761\u5173\u4e8e\u63d0\u793a\u5199\u4f5c\u7684\u5e16\u5b50\u3002", "result": "\u5448\u73b0\u4e86\u5173\u4e8e\u65b0\u5174AI\u7d20\u517b\u5b9e\u8df5\u7684\u4e94\u4e2a\u4e3b\u9898\uff0c\u5305\u62ec\u63d0\u793a\u5199\u4f5c\u5f71\u54cd\u7684\u4ea4\u6d41\u9886\u57df\u3001\u5171\u4eab\u7684\u5fae\u7d20\u517b\u8d44\u6e90\u3001\u5851\u9020\u63d0\u793a\u5199\u4f5c\u7684\u5e02\u573a\u4fee\u8f9e\u3001\u63d0\u793a\u7684\u4fee\u8f9e\u7279\u5f81\u548c\u63d0\u793a\u5199\u4f5c\u7684\u5b9a\u4e49\u3002", "conclusion": "\u4e3a\u6570\u5b57\u5199\u4f5c\u6559\u5e08\u548c\u7814\u7a76\u8005\u5728\u6559\u5b66\u548c\u5206\u6790\u6279\u5224\u6027AI\u7d20\u517b\u65b9\u9762\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2511.00812", "pdf": "https://arxiv.org/pdf/2511.00812", "abs": "https://arxiv.org/abs/2511.00812", "authors": ["Shashank Nag", "Alan T. L. Bacellar", "Zachary Susskind", "Anshul Jha", "Logan Liberty", "Aishwarya Sivakumar", "Eugene B. John", "Krishnan Kailas", "Priscila M. V. Lima", "Neeraja J. Yadwadkar", "Felipe M. G. Franca", "Lizy K. John"], "title": "LL-ViT: Edge Deployable Vision Transformers with Look Up Table Neurons", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted for FPT 2025, 9 pages, conference", "summary": "Vision Transformers have been tremendously successful in computer vision\ntasks. However, their large computational, memory, and energy demands are a\nchallenge for edge inference on FPGAs -- a field that has seen a recent surge\nin demand. We recognize the benefits of recent works on logic and Look Up Table\n(LUT) based networks, such as LogicNets, NeuraLUT, DWN, among others, in\noffering models that simultaneously reduce both the memory and compute\nfootprints. However, these models natively do not perform well on common vision\ntasks, such as CIFAR-10/100. In this work, we propose LL-ViT, a novel edge\noptimized vision transformer design that integrates layers of LUT neurons\nwithin the transformer architecture. Based on our characterization that reveals\nthat a majority of model weights and computations are from the channel mixer\n(MLP layer), we design an alternate LUT-based channel mixer, and simultaneously\ndevelop an FPGA-based accelerator for LL-ViT. Contrary to some attempts to\nreplace each multiplication with a table lookup, our architecture utilizes a\nneural learning approach which natively learns the LUT functions. This approach\nallows for reduced model sizes, and a computational and energy-efficient\ninference solution for vision transformer models. Evaluating on edge-suitable\nworkloads, we achieve accuracies of 95.5% on CIFAR-10, 78.8% on CIFAR-100, and\n60.9% on Tiny-ImageNet datasets, comparable to the baseline transformer. LL-ViT\neliminates over 60% of the model weights and 50% of the multiplications in the\nmodel, and achieves 1.9x energy efficiency and 1.3x lower latency over an\ninteger quantized ViT accelerator, while also offering superior throughput\nagainst prior works at a 10.9W power budget.", "AI": {"tldr": "\u63d0\u51faLL - ViT\uff0c\u7ed3\u5408LUT\u795e\u7ecf\u5143\u4e0eTransformer\u67b6\u6784\uff0c\u8bbe\u8ba1FPGA\u52a0\u901f\u5668\uff0c\u5728\u8fb9\u7f18\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u8bc4\u4f30\u6709\u826f\u597d\u8868\u73b0\uff0c\u51cf\u5c11\u6a21\u578b\u6743\u91cd\u548c\u4e58\u6cd5\uff0c\u63d0\u5347\u80fd\u6548\u548c\u541e\u5410\u91cf\u3002", "motivation": "Vision Transformers\u5728FPGA\u8fb9\u7f18\u63a8\u7406\u65f6\u8ba1\u7b97\u3001\u5185\u5b58\u548c\u80fd\u91cf\u9700\u6c42\u5927\uff0c\u73b0\u6709LUT\u7f51\u7edc\u5728\u5e38\u89c1\u89c6\u89c9\u4efb\u52a1\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8bbe\u8ba1\u8fb9\u7f18\u4f18\u5316\u7684\u89c6\u89c9Transformer\u3002", "method": "\u5728Transformer\u67b6\u6784\u4e2d\u96c6\u6210LUT\u795e\u7ecf\u5143\u5c42\uff0c\u8bbe\u8ba1\u57fa\u4e8eLUT\u7684\u901a\u9053\u6df7\u5408\u5668\uff0c\u5f00\u53d1FPGA\u52a0\u901f\u5668\uff0c\u91c7\u7528\u795e\u7ecf\u5b66\u4e60\u65b9\u6cd5\u5b66\u4e60LUT\u51fd\u6570\u3002", "result": "\u5728CIFAR - 10\u3001CIFAR - 100\u548cTiny - ImageNet\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e00\u5b9a\u51c6\u786e\u7387\uff0c\u6d88\u9664\u8d8560%\u6a21\u578b\u6743\u91cd\u548c50%\u4e58\u6cd5\uff0c\u76f8\u6bd4\u6574\u6570\u91cf\u5316ViT\u52a0\u901f\u5668\u6709\u66f4\u597d\u80fd\u6548\u548c\u66f4\u4f4e\u5ef6\u8fdf\uff0c\u572810.9W\u529f\u7387\u9884\u7b97\u4e0b\u541e\u5410\u91cf\u66f4\u4f18\u3002", "conclusion": "LL - ViT\u662f\u4e00\u79cd\u8ba1\u7b97\u548c\u80fd\u91cf\u9ad8\u6548\u7684\u89c6\u89c9Transformer\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00851", "pdf": "https://arxiv.org/pdf/2511.00851", "abs": "https://arxiv.org/abs/2511.00851", "authors": ["Abhishek Patange", "Sharat Chidambaran", "Prabhat Shankar", "Manjunath G. B.", "Anindya Chatterjee"], "title": "Identifying Slug Formation in Oil Well Pipelines: A Use Case from Industrial Analytics", "categories": ["cs.LG"], "comment": "This paper ID 254 has been accepted for presentation in the\n  Demonstration Track of the 13th ACM IKDD CODS Conference on Data Science CODS\n  2025, IISER Pune, India, from December 17 to 20, 2025", "summary": "Slug formation in oil and gas pipelines poses significant challenges to\noperational safety and efficiency, yet existing detection approaches are often\noffline, require domain expertise, and lack real-time interpretability. We\npresent an interactive application that enables end-to-end data-driven slug\ndetection through a compact and user-friendly interface. The system integrates\ndata exploration and labeling, configurable model training and evaluation with\nmultiple classifiers, visualization of classification results with time-series\noverlays, and a real-time inference module that generates persistence-based\nalerts when slug events are detected. The demo supports seamless workflows from\nlabeled CSV uploads to live inference on unseen datasets, making it\nlightweight, portable, and easily deployable. By combining domain-relevant\nanalytics with novel UI/UX features such as snapshot persistence, visual\nlabeling, and real-time alerting, our tool adds significant dissemination value\nas both a research prototype and a practical industrial application. The demo\nshowcases how interactive human-in-the-loop ML systems can bridge the gap\nbetween data science methods and real-world decision-making in critical process\nindustries, with broader applicability to time-series fault diagnosis tasks\nbeyond oil and gas.", "AI": {"tldr": "\u63d0\u51fa\u4ea4\u4e92\u5f0f\u5e94\u7528\u5b9e\u73b0\u7aef\u5230\u7aef\u6570\u636e\u9a71\u52a8\u6bb5\u585e\u68c0\u6d4b\uff0c\u5177\u6709\u8f7b\u91cf\u4fbf\u643a\u6613\u90e8\u7f72\u7279\u70b9\uff0c\u9002\u7528\u4e8e\u5173\u952e\u6d41\u7a0b\u884c\u4e1a\u3002", "motivation": "\u73b0\u6709\u6cb9\u6c14\u7ba1\u9053\u6bb5\u585e\u68c0\u6d4b\u65b9\u6cd5\u79bb\u7ebf\u3001\u9700\u4e13\u4e1a\u77e5\u8bc6\u4e14\u7f3a\u4e4f\u5b9e\u65f6\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f00\u53d1\u4ea4\u4e92\u5f0f\u5e94\u7528\uff0c\u96c6\u6210\u6570\u636e\u63a2\u7d22\u4e0e\u6807\u6ce8\u3001\u6a21\u578b\u8bad\u7ec3\u8bc4\u4f30\u3001\u7ed3\u679c\u53ef\u89c6\u5316\u53ca\u5b9e\u65f6\u63a8\u7406\u6a21\u5757\uff0c\u7ed3\u5408\u9886\u57df\u5206\u6790\u4e0e\u65b0UI/UX\u7279\u6027\u3002", "result": "\u5b9e\u73b0\u4ece\u4e0a\u4f20CSV\u5230\u5b9e\u65f6\u63a8\u7406\u7684\u65e0\u7f1d\u5de5\u4f5c\u6d41\uff0c\u5de5\u5177\u8f7b\u91cf\u3001\u4fbf\u643a\u3001\u6613\u90e8\u7f72\u3002", "conclusion": "\u8be5\u5de5\u5177\u517c\u5177\u7814\u7a76\u4e0e\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\uff0c\u53ef\u5f25\u5408\u6570\u636e\u79d1\u5b66\u65b9\u6cd5\u4e0e\u73b0\u5b9e\u51b3\u7b56\u5dee\u8ddd\uff0c\u9002\u7528\u4e8e\u66f4\u591a\u65f6\u95f4\u5e8f\u5217\u6545\u969c\u8bca\u65ad\u4efb\u52a1\u3002"}}
{"id": "2511.00868", "pdf": "https://arxiv.org/pdf/2511.00868", "abs": "https://arxiv.org/abs/2511.00868", "authors": ["Nazmul Takbir", "Hamidreza Alikhani", "Nikil Dutt", "Sangeetha Abdu Jyothi"], "title": "FlexiCache: Leveraging Temporal Stability of Attention Heads for Efficient KV Cache Management", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Model (LLM) serving is increasingly constrained by the growing\nsize of the key-value (KV) cache, which scales with both context length and\ngeneration length. Prior work shows that attention is dominated by a small\nsubset of critical tokens, yet existing systems struggle to exploit this\nefficiently without degrading accuracy, especially in long generation. We make\na key observation: the temporal stability of these critical tokens varies\nsignificantly across KV heads: some heads consistently focus on the same\ntokens, while others shift frequently. Building on this insight, we introduce\nFlexiCache, a hierarchical KV-cache management system that leverages the\ntemporal stability of KV heads to reduce GPU memory usage and computation\noverhead, while preserving model accuracy. FlexiCache classifies KV heads as\nstable or unstable: it retains all KV-cache pages from unstable heads in GPU\nmemory, whereas for stable heads, it keeps only the top-K pages on the GPU and\noffloads the rest to host memory. By exploiting temporal stability, FlexiCache\nperforms periodic reranking for stable heads to fetch newly promoted top pages.\nImplemented atop vLLM, FlexiCache reduces GPU memory footprint for long-context\nrequests by up to 70%, improves offline serving throughput by 1.38-1.55x, and\nlowers online token latency by 1.6-2.1x, all while maintaining accuracy in\nlong-context, long-generation scenarios.", "AI": {"tldr": "\u63d0\u51faFlexiCache\u7cfb\u7edf\u5229\u7528KV\u5934\u7684\u65f6\u95f4\u7a33\u5b9a\u6027\u51cf\u5c11GPU\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u4fdd\u6301\u7cbe\u5ea6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u53d7KV\u7f13\u5b58\u5927\u5c0f\u9650\u5236\uff0c\u73b0\u6709\u7cfb\u7edf\u96be\u4ee5\u5728\u4e0d\u964d\u4f4e\u7cbe\u5ea6\u4e0b\u9ad8\u6548\u5229\u7528\u5173\u952e\u4ee4\u724c\u3002", "method": "\u5c06KV\u5934\u5206\u4e3a\u7a33\u5b9a\u548c\u4e0d\u7a33\u5b9a\uff0c\u4e0d\u7a33\u5b9a\u5934\u7684KV\u7f13\u5b58\u9875\u5168\u4fdd\u7559\u5728GPU\u5185\u5b58\uff0c\u7a33\u5b9a\u5934\u53ea\u5728GPU\u4fdd\u7559\u524dK\u9875\uff0c\u5176\u4f59\u5378\u8f7d\u5230\u4e3b\u673a\u5185\u5b58\uff0c\u5bf9\u7a33\u5b9a\u5934\u5b9a\u671f\u91cd\u65b0\u6392\u5e8f\u83b7\u53d6\u65b0\u7684\u524dK\u9875\u3002", "result": "\u5728vLLM\u4e0a\u5b9e\u73b0\uff0c\u957f\u4e0a\u4e0b\u6587\u8bf7\u6c42\u51cf\u5c11GPU\u5185\u5b58\u5360\u7528\u8fbe70%\uff0c\u79bb\u7ebf\u670d\u52a1\u541e\u5410\u91cf\u63d0\u53471.38 - 1.55\u500d\uff0c\u5728\u7ebf\u4ee4\u724c\u5ef6\u8fdf\u964d\u4f4e1.6 - 2.1\u500d\u3002", "conclusion": "FlexiCache\u5728\u957f\u4e0a\u4e0b\u6587\u3001\u957f\u751f\u6210\u573a\u666f\u4e0b\u80fd\u6709\u6548\u51cf\u5c11\u8d44\u6e90\u5360\u7528\uff0c\u63d0\u5347\u6027\u80fd\u4e14\u4fdd\u6301\u7cbe\u5ea6\u3002"}}
{"id": "2511.00110", "pdf": "https://arxiv.org/pdf/2511.00110", "abs": "https://arxiv.org/abs/2511.00110", "authors": ["YingQiao Wang", "Eric Bigelow", "Boyi Li", "Tomer Ullman"], "title": "Chain of Time: In-Context Physical Simulation with Image Generation Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We propose a novel cognitively-inspired method to improve and interpret\nphysical simulation in vision-language models. Our ``Chain of Time\" method\ninvolves generating a series of intermediate images during a simulation, and it\nis motivated by in-context reasoning in machine learning, as well as mental\nsimulation in humans. Chain of Time is used at inference time, and requires no\nadditional fine-tuning. We apply the Chain-of-Time method to synthetic and\nreal-world domains, including 2-D graphics simulations and natural 3-D videos.\nThese domains test a variety of particular physical properties, including\nvelocity, acceleration, fluid dynamics, and conservation of momentum. We found\nthat using Chain-of-Time simulation substantially improves the performance of a\nstate-of-the-art image generation model. Beyond examining performance, we also\nanalyzed the specific states of the world simulated by an image model at each\ntime step, which sheds light on the dynamics underlying these simulations. This\nanalysis reveals insights that are hidden from traditional evaluations of\nphysical reasoning, including cases where an image generation model is able to\nsimulate physical properties that unfold over time, such as velocity, gravity,\nand collisions. Our analysis also highlights particular cases where the image\ngeneration model struggles to infer particular physical parameters from input\nimages, despite being capable of simulating relevant physical processes.", "AI": {"tldr": "\u63d0\u51fa\u8ba4\u77e5\u542f\u53d1\u7684\u201c\u65f6\u95f4\u94fe\u201d\u65b9\u6cd5\u6539\u8fdb\u548c\u89e3\u91ca\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7269\u7406\u6a21\u62df\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u5fae\u8c03\uff0c\u5e94\u7528\u4e8e\u591a\u9886\u57df\u63d0\u5347\u4e86\u56fe\u50cf\u751f\u6210\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u7269\u7406\u6a21\u62df\u52a8\u6001\u3002", "motivation": "\u53d7\u673a\u5668\u5b66\u4e60\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u4eba\u7c7b\u5fc3\u7406\u6a21\u62df\u542f\u53d1\uff0c\u6539\u8fdb\u548c\u89e3\u91ca\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7269\u7406\u6a21\u62df\u3002", "method": "\u63d0\u51fa\u201c\u65f6\u95f4\u94fe\u201d\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u751f\u6210\u4e00\u7cfb\u5217\u6a21\u62df\u4e2d\u95f4\u56fe\u50cf\uff0c\u65e0\u9700\u989d\u5916\u5fae\u8c03\uff0c\u5e94\u7528\u4e8e\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u9886\u57df\u3002", "result": "\u4f7f\u7528\u201c\u65f6\u95f4\u94fe\u201d\u6a21\u62df\u663e\u8457\u63d0\u5347\u4e86\u56fe\u50cf\u751f\u6210\u6a21\u578b\u6027\u80fd\uff0c\u5206\u6790\u63ed\u793a\u4e86\u4f20\u7edf\u8bc4\u4f30\u9690\u85cf\u7684\u7269\u7406\u63a8\u7406\u52a8\u6001\u3002", "conclusion": "\u201c\u65f6\u95f4\u94fe\u201d\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7269\u7406\u6a21\u62df\u6027\u80fd\uff0c\u540c\u65f6\u66b4\u9732\u51fa\u6a21\u578b\u5728\u4ece\u8f93\u5165\u56fe\u50cf\u63a8\u65ad\u7279\u5b9a\u7269\u7406\u53c2\u6570\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2511.00874", "pdf": "https://arxiv.org/pdf/2511.00874", "abs": "https://arxiv.org/abs/2511.00874", "authors": ["Taowen Liu", "Marta Andronic", "Deniz G\u00fcnd\u00fcz", "George A. Constantinides"], "title": "Training with Fewer Bits: Unlocking Edge LLMs Training with Stochastic Rounding", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "LLM training is resource-intensive. Quantized training improves computational\nand memory efficiency but introduces quantization noise, which can hinder\nconvergence and degrade model accuracy. Stochastic Rounding (SR) has emerged as\na theoretically attractive alternative to deterministic rounding, offering\nunbiased gradient estimates. However, its interaction with other training\nfactors -- especially batch size -- remains under explored. In this paper, we\npresent a theoretical and empirical study of mini-batch stochastic gradient\ndescent (SGD) with SR, showing that increased batch sizes can compensate for\nreduced precision during back-propagation. Furthermore, we show that quantizing\nweights and activations impacts gradient variance in distinct ways. Our\nexperiments validate these theoretical insights.", "AI": {"tldr": "\u7814\u7a76\u968f\u673a\u820d\u5165\uff08SR\uff09\u5728\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u589e\u5927\u6279\u91cf\u53ef\u8865\u507f\u53cd\u5411\u4f20\u64ad\u4e2d\u7cbe\u5ea6\u964d\u4f4e\uff0c\u91cf\u5316\u6743\u91cd\u548c\u6fc0\u6d3b\u5bf9\u68af\u5ea6\u65b9\u5dee\u5f71\u54cd\u4e0d\u540c\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bad\u7ec3\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u91cf\u5316\u8bad\u7ec3\u6709\u566a\u58f0\u5f71\u54cd\uff0cSR\u867d\u7406\u8bba\u4e0a\u6709\u4f18\u52bf\uff0c\u4f46\u4e0e\u5176\u4ed6\u8bad\u7ec3\u56e0\u7d20\uff08\u5982\u6279\u91cf\u5927\u5c0f\uff09\u7684\u76f8\u4e92\u4f5c\u7528\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5bf9\u5c0f\u6279\u91cf\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u7ed3\u5408SR\u8fdb\u884c\u7406\u8bba\u548c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u589e\u5927\u6279\u91cf\u53ef\u8865\u507f\u53cd\u5411\u4f20\u64ad\u4e2d\u7cbe\u5ea6\u964d\u4f4e\uff0c\u91cf\u5316\u6743\u91cd\u548c\u6fc0\u6d3b\u5bf9\u68af\u5ea6\u65b9\u5dee\u6709\u4e0d\u540c\u5f71\u54cd\u7684\u7406\u8bba\u89c2\u70b9\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86SR\u4e0e\u6279\u91cf\u5927\u5c0f\u7b49\u8bad\u7ec3\u56e0\u7d20\u7684\u5173\u7cfb\uff0c\u4e3a\u91cf\u5316\u8bad\u7ec3\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u9a8c\u4f9d\u636e\u3002"}}
{"id": "2511.00112", "pdf": "https://arxiv.org/pdf/2511.00112", "abs": "https://arxiv.org/abs/2511.00112", "authors": ["Yanbing Mao", "Yihao Cai", "Lui Sha"], "title": "Real-DRL: Teach and Learn in Reality", "categories": ["cs.RO", "cs.AI"], "comment": "37 pages", "summary": "This paper introduces the Real-DRL framework for safety-critical autonomous\nsystems, enabling runtime learning of a deep reinforcement learning (DRL) agent\nto develop safe and high-performance action policies in real plants (i.e., real\nphysical systems to be controlled), while prioritizing safety! The Real-DRL\nconsists of three interactive components: a DRL-Student, a PHY-Teacher, and a\nTrigger. The DRL-Student is a DRL agent that innovates in the dual\nself-learning and teaching-to-learn paradigm and the real-time safety-informed\nbatch sampling. On the other hand, PHY-Teacher is a physics-model-based design\nof action policies that focuses solely on safety-critical functions.\nPHY-Teacher is novel in its real-time patch for two key missions: i) fostering\nthe teaching-to-learn paradigm for DRL-Student and ii) backing up the safety of\nreal plants. The Trigger manages the interaction between the DRL-Student and\nthe PHY-Teacher. Powered by the three interactive components, the Real-DRL can\neffectively address safety challenges that arise from the unknown unknowns and\nthe Sim2Real gap. Additionally, Real-DRL notably features i) assured safety,\nii) automatic hierarchy learning (i.e., safety-first learning and then\nhigh-performance learning), and iii) safety-informed batch sampling to address\nthe learning experience imbalance caused by corner cases. Experiments with a\nreal quadruped robot, a quadruped robot in NVIDIA Isaac Gym, and a cart-pole\nsystem, along with comparisons and ablation studies, demonstrate the Real-DRL's\neffectiveness and unique features.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdReal - DRL\u6846\u67b6\uff0c\u7528\u4e8e\u5b89\u5168\u5173\u952e\u7684\u81ea\u4e3b\u7cfb\u7edf\uff0c\u7531\u4e09\u4e2a\u7ec4\u4ef6\u6784\u6210\uff0c\u80fd\u5e94\u5bf9\u5b89\u5168\u6311\u6218\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u5b89\u5168\u5173\u952e\u7684\u81ea\u4e3b\u7cfb\u7edf\u5f00\u53d1\u80fd\u5728\u771f\u5b9e\u7269\u7406\u7cfb\u7edf\u4e2d\u5b66\u4e60\u5b89\u5168\u4e14\u9ad8\u6027\u80fd\u52a8\u4f5c\u7b56\u7565\u7684\u6846\u67b6\uff0c\u540c\u65f6\u4f18\u5148\u4fdd\u969c\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u7531DRL - Student\u3001PHY - Teacher\u548cTrigger\u4e09\u4e2a\u4ea4\u4e92\u7ec4\u4ef6\u6784\u6210\u7684Real - DRL\u6846\u67b6\uff0c\u5404\u7ec4\u4ef6\u6709\u4e0d\u540c\u529f\u80fd\u3002", "result": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u56db\u8db3\u673a\u5668\u4eba\u3001NVIDIA Isaac Gym\u4e2d\u7684\u56db\u8db3\u673a\u5668\u4eba\u548c\u63a8\u8f66 - \u6746\u7cfb\u7edf\u7684\u5b9e\u9a8c\uff0c\u4ee5\u53ca\u5bf9\u6bd4\u548c\u6d88\u878d\u7814\u7a76\uff0c\u8bc1\u660eReal - DRL\u7684\u6709\u6548\u6027\u548c\u72ec\u7279\u7279\u6027\u3002", "conclusion": "Real - DRL\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u672a\u77e5\u56e0\u7d20\u548cSim2Real\u5dee\u8ddd\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\uff0c\u5177\u5907\u5b89\u5168\u4fdd\u969c\u3001\u81ea\u52a8\u5206\u5c42\u5b66\u4e60\u548c\u5b89\u5168\u611f\u77e5\u6279\u91cf\u91c7\u6837\u7b49\u7279\u6027\u3002"}}
{"id": "2511.00880", "pdf": "https://arxiv.org/pdf/2511.00880", "abs": "https://arxiv.org/abs/2511.00880", "authors": ["Joonyoung Lim", "Younghwan Yoo"], "title": "KFCPO: Kronecker-Factored Approximated Constrained Policy Optimization", "categories": ["cs.LG", "cs.AI", "68T07, 90C15, 93E35"], "comment": "12 pages, 8 figures, submitted to ECAI 2025", "summary": "We propose KFCPO, a novel Safe Reinforcement Learning (Safe RL) algorithm\nthat combines scalable Kronecker-Factored Approximate Curvature (K-FAC) based\nsecond-order policy optimization with safety-aware gradient manipulation. KFCPO\nleverages K-FAC to perform efficient and stable natural gradient updates by\napproximating the Fisher Information Matrix (FIM) in a layerwise, closed form\nmanner, avoiding iterative approximation overheads. To address the tradeoff\nbetween reward maximization and constraint satisfaction, we introduce a margin\naware gradient manipulation mechanism that adaptively adjusts the influence of\nreward and cost gradients based on the agent's proximity to safety boundaries.\nThis method blends gradients using a direction sensitive projection,\neliminating harmful interference and avoiding abrupt changes caused by fixed\nhard thresholds. Additionally, a minibatch level KL rollback strategy is\nadopted to ensure trust region compliance and to prevent destabilizing policy\nshifts. Experiments on Safety Gymnasium using OmniSafe show that KFCPO achieves\n10.3% to 50.2% higher average return across environments compared to the best\nbaseline that respected the safety constraint, demonstrating superior balance\nof safety and performance.", "AI": {"tldr": "\u63d0\u51faKFCPO\u7b97\u6cd5\uff0c\u7ed3\u5408K - FAC\u4e8c\u9636\u7b56\u7565\u4f18\u5316\u4e0e\u5b89\u5168\u611f\u77e5\u68af\u5ea6\u64cd\u4f5c\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u5b89\u5168\u4e0e\u6027\u80fd\u5e73\u8861\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u89e3\u51b3\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u6700\u5927\u5316\u548c\u7ea6\u675f\u6ee1\u8db3\u7684\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u7a33\u5b9a\u7684\u7b56\u7565\u4f18\u5316\u3002", "method": "\u7ed3\u5408K - FAC\u8fdb\u884c\u81ea\u7136\u68af\u5ea6\u66f4\u65b0\uff0c\u5f15\u5165\u8fb9\u9645\u611f\u77e5\u68af\u5ea6\u64cd\u4f5c\u673a\u5236\uff0c\u91c7\u7528\u5c0f\u6279\u91cf\u7ea7KL\u56de\u6eda\u7b56\u7565\u3002", "result": "\u5728Safety Gymnasium\u4e0a\u4f7f\u7528OmniSafe\u5b9e\u9a8c\uff0cKFCPO\u6bd4\u9075\u5b88\u5b89\u5168\u7ea6\u675f\u7684\u6700\u4f73\u57fa\u7ebf\u5e73\u5747\u56de\u62a5\u9ad810.3%\u523050.2%\u3002", "conclusion": "KFCPO\u5728\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u4e2d\u80fd\u5b9e\u73b0\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u4f18\u8d8a\u5e73\u8861\u3002"}}
{"id": "2511.00114", "pdf": "https://arxiv.org/pdf/2511.00114", "abs": "https://arxiv.org/abs/2511.00114", "authors": ["Hanae Elmekki", "Amanda Spilkin", "Ehsan Zakeri", "Antonela Mariel Zanuttini", "Ahmed Alagha", "Hani Sami", "Jamal Bentahar", "Lyes Kadem", "Wen-Fang Xie", "Philippe Pibarot", "Rabeb Mizouni", "Hadi Otrok", "Azzam Mourad", "Sami Muhaidat"], "title": "End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Cardiac ultrasound (US) is among the most widely used diagnostic tools in\ncardiology for assessing heart health, but its effectiveness is limited by\noperator dependence, time constraints, and human error. The shortage of trained\nprofessionals, especially in remote areas, further restricts access. These\nissues underscore the need for automated solutions that can ensure consistent,\nand accessible cardiac imaging regardless of operator skill or location. Recent\nprogress in artificial intelligence (AI), especially in deep reinforcement\nlearning (DRL), has gained attention for enabling autonomous decision-making.\nHowever, existing DRL-based approaches to cardiac US scanning lack\nreproducibility, rely on proprietary data, and use simplified models. Motivated\nby these gaps, we present the first end-to-end framework that integrates\ngenerative AI and DRL to enable autonomous and reproducible cardiac US\nscanning. The framework comprises two components: (i) a conditional generative\nsimulator combining Generative Adversarial Networks (GANs) with Variational\nAutoencoders (VAEs), that models the cardiac US environment producing realistic\naction-conditioned images; and (ii) a DRL module that leverages this simulator\nto learn autonomous, accurate scanning policies. The proposed framework\ndelivers AI-driven guidance through expert-validated models that classify image\ntype and assess quality, supports conditional generation of realistic US\nimages, and establishes a reproducible foundation extendable to other organs.\nTo ensure reproducibility, a publicly available dataset of real cardiac US\nscans is released. The solution is validated through several experiments. The\nVAE-GAN is benchmarked against existing GAN variants, with performance assessed\nusing qualitative and quantitative approaches, while the DRL-based scanning\nsystem is evaluated under varying configurations to demonstrate effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u96c6\u6210\u751f\u6210\u5f0fAI\u548cDRL\u7684\u7aef\u5230\u7aef\u6846\u67b6\u5b9e\u73b0\u81ea\u4e3b\u53ef\u91cd\u590d\u7684\u5fc3\u810f\u8d85\u58f0\u626b\u63cf\uff0c\u8fd8\u53d1\u5e03\u516c\u5f00\u6570\u636e\u96c6\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5fc3\u810f\u8d85\u58f0\u8bca\u65ad\u5b58\u5728\u64cd\u4f5c\u8005\u4f9d\u8d56\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u57fa\u4e8eDRL\u7684\u5fc3\u810f\u8d85\u58f0\u626b\u63cf\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u91cd\u590d\u6027\u7b49\uff0c\u9700\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u751f\u6210\u5f0fAI\u548cDRL\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u542b\u7ed3\u5408GANs\u4e0eVAEs\u7684\u6761\u4ef6\u751f\u6210\u6a21\u62df\u5668\u548cDRL\u6a21\u5757\u3002", "result": "\u6846\u67b6\u53ef\u63d0\u4f9bAI\u9a71\u52a8\u6307\u5bfc\u3001\u652f\u6301\u6761\u4ef6\u751f\u6210\u903c\u771f\u8d85\u58f0\u56fe\u50cf\u3001\u5efa\u7acb\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u5668\u5b98\u7684\u53ef\u91cd\u590d\u57fa\u7840\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u5b9e\u73b0\u81ea\u4e3b\u53ef\u91cd\u590d\u7684\u5fc3\u810f\u8d85\u58f0\u626b\u63cf\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2511.00115", "pdf": "https://arxiv.org/pdf/2511.00115", "abs": "https://arxiv.org/abs/2511.00115", "authors": ["Haoyuan Li", "Yuanbo Tong", "Yuchen Li", "Zirui Wang", "Chunhou Liu", "Jiamou Liu"], "title": "Cognitive Alignment in Personality Reasoning: Leveraging Prototype Theory for MBTI Inference", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Personality recognition from text is typically cast as hard-label\nclassification, which obscures the graded, prototype-like nature of human\npersonality judgments. We present ProtoMBTI, a cognitively aligned framework\nfor MBTI inference that operationalizes prototype theory within an LLM-based\npipeline. First, we construct a balanced, quality-controlled corpus via\nLLM-guided multi-dimensional augmentation (semantic, linguistic, sentiment).\nNext, we LoRA-fine-tune a lightweight (<=2B) encoder to learn discriminative\nembeddings and to standardize a bank of personality prototypes. At inference,\nwe retrieve top-k prototypes for a query post and perform a\nretrieve--reuse--revise--retain cycle: the model aggregates prototype evidence\nvia prompt-based voting, revises when inconsistencies arise, and, upon correct\nprediction, retains the sample to continually enrich the prototype library.\nAcross Kaggle and Pandora benchmarks, ProtoMBTI improves over baselines on both\nthe four MBTI dichotomies and the full 16-type task, and exhibits robust\ncross-dataset generalization. Our results indicate that aligning the inference\nprocess with psychological prototype reasoning yields gains in accuracy,\ninterpretability, and transfer for text-based personality modeling.", "AI": {"tldr": "\u63d0\u51faProtoMBTI\u6846\u67b6\u7528\u4e8eMBTI\u63a8\u65ad\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u8bc1\u660e\u4e0e\u5fc3\u7406\u539f\u578b\u63a8\u7406\u5bf9\u9f50\u6709\u76ca\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u4eba\u683c\u8bc6\u522b\u91c7\u7528\u786c\u6807\u7b7e\u5206\u7c7b\uff0c\u63a9\u76d6\u4e86\u4eba\u7c7b\u4eba\u683c\u5224\u65ad\u7684\u5206\u7ea7\u548c\u539f\u578b\u7279\u5f81\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u6784\u5efa\u5e73\u8861\u3001\u8d28\u91cf\u53ef\u63a7\u7684\u8bed\u6599\u5e93\uff0cLoRA\u5fae\u8c03\u8f7b\u91cf\u7ea7\u7f16\u7801\u5668\u5b66\u4e60\u5d4c\u5165\u548c\u6807\u51c6\u5316\u539f\u578b\u5e93\uff0c\u63a8\u7406\u65f6\u8fdb\u884c\u68c0\u7d22 - \u590d\u7528 - \u4fee\u8ba2 - \u4fdd\u7559\u5faa\u73af\u3002", "result": "\u5728Kaggle\u548cPandora\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProtoMBTI\u5728\u56db\u4e2aMBTI\u4e8c\u5206\u6cd5\u548c16\u7c7b\u578b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u6709\u5f3a\u5927\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5c06\u63a8\u7406\u8fc7\u7a0b\u4e0e\u5fc3\u7406\u539f\u578b\u63a8\u7406\u5bf9\u9f50\uff0c\u80fd\u63d0\u5347\u57fa\u4e8e\u6587\u672c\u7684\u4eba\u683c\u5efa\u6a21\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8fc1\u79fb\u6027\u3002"}}
{"id": "2511.00900", "pdf": "https://arxiv.org/pdf/2511.00900", "abs": "https://arxiv.org/abs/2511.00900", "authors": ["Yoshihiro Maruyama"], "title": "Learning with Category-Equivariant Representations for Human Activity Recognition", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "Human activity recognition is challenging because sensor signals shift with\ncontext, motion, and environment; effective models must therefore remain stable\nas the world around them changes. We introduce a categorical symmetry-aware\nlearning framework that captures how signals vary over time, scale, and sensor\nhierarchy. We build these factors into the structure of feature\nrepresentations, yielding models that automatically preserve the relationships\nbetween sensors and remain stable under realistic distortions such as time\nshifts, amplitude drift, and device orientation changes. On the UCI Human\nActivity Recognition benchmark, this categorical symmetry-driven design\nimproves out-of-distribution accuracy by approx. 46 percentage points (approx.\n3.6x over the baseline), demonstrating that abstract symmetry principles can\ntranslate into concrete performance gains in everyday sensing tasks via\ncategory-equivariant representation theory.", "AI": {"tldr": "\u63d0\u51fa\u7c7b\u522b\u5bf9\u79f0\u611f\u77e5\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\uff0c\u5728UCI\u57fa\u51c6\u4e0a\u63d0\u5347\u4e86\u5206\u5e03\u5916\u51c6\u786e\u7387\u3002", "motivation": "\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u4e2d\u4f20\u611f\u5668\u4fe1\u53f7\u4f1a\u968f\u4e0a\u4e0b\u6587\u3001\u8fd0\u52a8\u548c\u73af\u5883\u53d8\u5316\uff0c\u6709\u6548\u6a21\u578b\u9700\u4fdd\u6301\u7a33\u5b9a\u3002", "method": "\u5f15\u5165\u7c7b\u522b\u5bf9\u79f0\u611f\u77e5\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u4fe1\u53f7\u968f\u65f6\u95f4\u3001\u5c3a\u5ea6\u548c\u4f20\u611f\u5668\u5c42\u6b21\u7684\u53d8\u5316\u56e0\u7d20\u878d\u5165\u7279\u5f81\u8868\u793a\u7ed3\u6784\u3002", "result": "\u5728UCI\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u57fa\u51c6\u4e0a\uff0c\u7c7b\u522b\u5bf9\u79f0\u9a71\u52a8\u8bbe\u8ba1\u4f7f\u5206\u5e03\u5916\u51c6\u786e\u7387\u63d0\u9ad8\u7ea646\u4e2a\u767e\u5206\u70b9\uff0c\u662f\u57fa\u7ebf\u7684\u7ea63.6\u500d\u3002", "conclusion": "\u62bd\u8c61\u5bf9\u79f0\u539f\u5219\u53ef\u901a\u8fc7\u7c7b\u522b\u7b49\u53d8\u8868\u793a\u7406\u8bba\u5728\u65e5\u5e38\u4f20\u611f\u4efb\u52a1\u4e2d\u8f6c\u5316\u4e3a\u5b9e\u9645\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.00907", "pdf": "https://arxiv.org/pdf/2511.00907", "abs": "https://arxiv.org/abs/2511.00907", "authors": ["Ruifeng Ren", "Sheng Ouyang", "Huayi Tang", "Yong Liu"], "title": "Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle", "categories": ["cs.LG"], "comment": null, "summary": "Transformers have demonstrated strong adaptability across a wide range of\ntasks and have become the backbone of modern Large Language Models (LLMs).\nHowever, their underlying mechanisms remain open for further exploration. The\nenergy-based perspective has long provided a valuable principle for\nunderstanding neural computation. In this paper, we revisit the principle of\nenergy as a lens to understand attention-based Transformer models. We present a\nunified energy-based framework which is composed of three key components: the\nglobal energy $F^*$, the energy function $E_i$ and the employed gradient\ndescent (GD) form. Within this framework, standard softmax attention can be\nviewed as a special case of minimizing the Helmholtz free energy as $F^*$ using\nstandard GD when $E_i$ takes the form of elastic potential energy, with\nresidual connections ensuring that this optimization proceeds in an incremental\nmanner. In addition, linear attentions can also be naturally incorporated into\nthis framework by adjusting the corresponding energy forms. We also extend the\nabove analysis to the multi-head setting, where the energy is defined across\nmultiple low-dimensional subspaces. Building on this framework, we propose\nenergy-based modifications of attention structures. Inspired by classical GD\nalgorithms, we extend the original attention formulation based on standard GD\nto the momentum-based GD, Nesterov Accelerated Gradient (NAG), and Newton's\nmethod variants, each inducing a corresponding new attention structure. Our\nexperiments provide preliminary support for the potential of the energy-based\nframework for designing attention mechanisms.", "AI": {"tldr": "\u672c\u6587\u4ece\u80fd\u91cf\u89d2\u5ea6\u7406\u89e3Transformer\u6a21\u578b\uff0c\u63d0\u51fa\u7edf\u4e00\u80fd\u91cf\u6846\u67b6\uff0c\u5c06\u6807\u51c6\u548c\u7ebf\u6027\u6ce8\u610f\u529b\u7eb3\u5165\u5176\u4e2d\uff0c\u6269\u5c55\u5230\u591a\u5934\u8bbe\u7f6e\uff0c\u63d0\u51fa\u57fa\u4e8e\u80fd\u91cf\u7684\u6ce8\u610f\u529b\u7ed3\u6784\u4fee\u6539\uff0c\u5b9e\u9a8c\u521d\u6b65\u9a8c\u8bc1\u6846\u67b6\u6f5c\u529b\u3002", "motivation": "Transformer\u673a\u5236\u5f85\u63a2\u7d22\uff0c\u80fd\u91cf\u89c6\u89d2\u5bf9\u7406\u89e3\u795e\u7ecf\u8ba1\u7b97\u6709\u4ef7\u503c\uff0c\u6545\u4ece\u80fd\u91cf\u89d2\u5ea6\u7406\u89e3\u57fa\u4e8e\u6ce8\u610f\u529b\u7684Transformer\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u80fd\u91cf\u6846\u67b6\uff0c\u5305\u542b\u5168\u5c40\u80fd\u91cf\u3001\u80fd\u91cf\u51fd\u6570\u548c\u68af\u5ea6\u4e0b\u964d\u5f62\u5f0f\uff1b\u5c06\u6807\u51c6\u548c\u7ebf\u6027\u6ce8\u610f\u529b\u7eb3\u5165\u6846\u67b6\uff1b\u6269\u5c55\u5230\u591a\u5934\u8bbe\u7f6e\uff1b\u57fa\u4e8e\u7ecf\u5178\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u4fee\u6539\u6ce8\u610f\u529b\u7ed3\u6784\u3002", "result": "\u6807\u51c6softmax\u6ce8\u610f\u529b\u53ef\u89c6\u4e3a\u6700\u5c0f\u5316Helmholtz\u81ea\u7531\u80fd\u7684\u7279\u4f8b\uff1b\u7ebf\u6027\u6ce8\u610f\u529b\u53ef\u81ea\u7136\u7eb3\u5165\u6846\u67b6\uff1b\u63d0\u51fa\u591a\u79cd\u57fa\u4e8e\u80fd\u91cf\u7684\u65b0\u6ce8\u610f\u529b\u7ed3\u6784\u3002", "conclusion": "\u5b9e\u9a8c\u4e3a\u57fa\u4e8e\u80fd\u91cf\u7684\u6846\u67b6\u8bbe\u8ba1\u6ce8\u610f\u529b\u673a\u5236\u7684\u6f5c\u529b\u63d0\u4f9b\u4e86\u521d\u6b65\u652f\u6301\u3002"}}
{"id": "2511.00120", "pdf": "https://arxiv.org/pdf/2511.00120", "abs": "https://arxiv.org/abs/2511.00120", "authors": ["Md Selim Sarowar", "Sungho Kim"], "title": "VLM6D: VLM based 6Dof Pose Estimation based on RGB-D Images", "categories": ["cs.CV", "cs.AI"], "comment": "This paper has been accepted to IEIE( The Institute Of Electronics\n  and Information Engineering, South Korea) Fall,2025 Conference", "summary": "The primary challenge in computer vision is precisely calculating the pose of\n6D objects, however many current approaches are still fragile and have trouble\ngeneralizing from synthetic data to real-world situations with fluctuating\nlighting, textureless objects, and significant occlusions. To address these\nlimitations, VLM6D, a novel dual-stream architecture that leverages the\ndistinct strengths of visual and geometric data from RGB-D input for robust and\nprecise pose estimation. Our framework uniquely integrates two specialized\nencoders: a powerful, self-supervised Vision Transformer (DINOv2) processes the\nRGB modality, harnessing its rich, pre-trained understanding of visual grammar\nto achieve remarkable resilience against texture and lighting variations.\nConcurrently, a PointNet++ encoder processes the 3D point cloud derived from\ndepth data, enabling robust geometric reasoning that excels even with the\nsparse, fragmented data typical of severe occlusion. These complementary\nfeature streams are effectively fused to inform a multi task prediction head.\nWe demonstrate through comprehensive experiments that VLM6D obtained new SOTA\nperformance on the challenging Occluded-LineMOD, validating its superior\nrobustness and accuracy.", "AI": {"tldr": "\u63d0\u51faVLM6D\u67b6\u6784\u89e3\u51b36D\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u96be\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728Occluded - LineMOD\u4e0a\u8fbeSOTA\u3002", "motivation": "\u5f53\u524d6D\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u5728\u771f\u5b9e\u573a\u666f\uff08\u5149\u7167\u53d8\u5316\u3001\u65e0\u7eb9\u7406\u7269\u4f53\u3001\u4e25\u91cd\u906e\u6321\uff09\u4e0b\u8106\u5f31\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u63d0\u51faVLM6D\u53cc\u6d41\u67b6\u6784\uff0c\u7528DINOv2\u5904\u7406RGB\u6a21\u6001\uff0cPointNet++\u5904\u7406\u6df1\u5ea6\u6570\u636e\u76843D\u70b9\u4e91\uff0c\u878d\u5408\u7279\u5f81\u540e\u901a\u8fc7\u591a\u4efb\u52a1\u9884\u6d4b\u5934\u8f93\u51fa\u3002", "result": "VLM6D\u5728Occluded - LineMOD\u4e0a\u53d6\u5f97\u65b0\u7684SOTA\u6027\u80fd\u3002", "conclusion": "VLM6D\u5177\u6709\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2511.00949", "pdf": "https://arxiv.org/pdf/2511.00949", "abs": "https://arxiv.org/abs/2511.00949", "authors": ["Yangyang Zhao", "Matti Kaisti", "Olli Lahdenoja", "Tero Koivisto"], "title": "Motion-Robust Multimodal Fusion of PPG and Accelerometer Signals for Three-Class Heart Rhythm Classification", "categories": ["cs.LG"], "comment": "Accepted for publication in the Companion of the 2025 ACM\n  International Joint Conference on Pervasive and Ubiquitous Computing and the\n  2025 International Symposium on Wearable Computers (UbiComp/ISWC 2025\n  Companion). 5 pages, 3 figures. Author's accepted manuscript (AAM)", "summary": "Atrial fibrillation (AF) is a leading cause of stroke and mortality,\nparticularly in elderly patients. Wrist-worn photoplethysmography (PPG) enables\nnon-invasive, continuous rhythm monitoring, yet suffers from significant\nvulnerability to motion artifacts and physiological noise. Many existing\napproaches rely solely on single-channel PPG and are limited to binary AF\ndetection, often failing to capture the broader range of arrhythmias\nencountered in clinical settings. We introduce RhythmiNet, a residual neural\nnetwork enhanced with temporal and channel attention modules that jointly\nleverage PPG and accelerometer (ACC) signals. The model performs three-class\nrhythm classification: AF, sinus rhythm (SR), and Other. To assess robustness\nacross varying movement conditions, test data are stratified by\naccelerometer-based motion intensity percentiles without excluding any\nsegments. RhythmiNet achieved a 4.3% improvement in macro-AUC over the PPG-only\nbaseline. In addition, performance surpassed a logistic regression model based\non handcrafted HRV features by 12%, highlighting the benefit of multimodal\nfusion and attention-based learning in noisy, real-world clinical data.", "AI": {"tldr": "\u63d0\u51faRhythmiNet\u6a21\u578b\uff0c\u5229\u7528PPG\u548cACC\u4fe1\u53f7\u8fdb\u884c\u4e09\u7c7b\u5fc3\u5f8b\u5206\u7c7b\uff0c\u6027\u80fd\u4f18\u4e8e\u4ec5\u7528PPG\u57fa\u7ebf\u548c\u57fa\u4e8e\u624b\u5de5HRV\u7279\u5f81\u7684\u903b\u8f91\u56de\u5f52\u6a21\u578b\u3002", "motivation": "\u623f\u98a4\u662f\u4e2d\u98ce\u548c\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u73b0\u6709\u5355\u901a\u9053PPG\u65b9\u6cd5\u6613\u53d7\u566a\u58f0\u5f71\u54cd\u4e14\u53ea\u80fd\u8fdb\u884c\u4e8c\u5143\u623f\u98a4\u68c0\u6d4b\uff0c\u65e0\u6cd5\u6db5\u76d6\u66f4\u591a\u5fc3\u5f8b\u5931\u5e38\u7c7b\u578b\u3002", "method": "\u5f15\u5165RhythmiNet\uff0c\u7ed3\u5408PPG\u548cACC\u4fe1\u53f7\uff0c\u7528\u6b8b\u5dee\u795e\u7ecf\u7f51\u7edc\u5e76\u589e\u5f3a\u65f6\u95f4\u548c\u901a\u9053\u6ce8\u610f\u529b\u6a21\u5757\u8fdb\u884c\u4e09\u7c7b\u5fc3\u5f8b\u5206\u7c7b\uff0c\u6309\u52a0\u901f\u5ea6\u8ba1\u8fd0\u52a8\u5f3a\u5ea6\u767e\u5206\u4f4d\u5206\u5c42\u6d4b\u8bd5\u6570\u636e\u3002", "result": "RhythmiNet\u6bd4\u4ec5\u7528PPG\u57fa\u7ebf\u7684\u5b8f\u89c2AUC\u63d0\u9ad84.3%\uff0c\u6027\u80fd\u6bd4\u57fa\u4e8e\u624b\u5de5HRV\u7279\u5f81\u7684\u903b\u8f91\u56de\u5f52\u6a21\u578b\u9ad812%\u3002", "conclusion": "\u591a\u6a21\u6001\u878d\u5408\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5b66\u4e60\u5728\u5608\u6742\u7684\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u4e2d\u6709\u76ca\u3002"}}
{"id": "2511.00964", "pdf": "https://arxiv.org/pdf/2511.00964", "abs": "https://arxiv.org/abs/2511.00964", "authors": ["Hai Hoang Thanh", "Duy-Tung Nguyen", "Hung The Tran", "Khoat Than"], "title": "Using Synthetic Data to estimate the True Error is theoretically and practically doable", "categories": ["cs.LG", "cs.AI"], "comment": "To appear at Machine Learning journal and ACML", "summary": "Accurately evaluating model performance is crucial for deploying machine\nlearning systems in real-world applications. Traditional methods often require\na sufficiently large labeled test set to ensure a reliable evaluation. However,\nin many contexts, a large labeled dataset is costly and labor-intensive.\nTherefore, we sometimes have to do evaluation by a few labeled samples, which\nis theoretically challenging. Recent advances in generative models offer a\npromising alternative by enabling the synthesis of high-quality data. In this\nwork, we make a systematic investigation about the use of synthetic data to\nestimate the test error of a trained model under limited labeled data\nconditions. To this end, we develop novel generalization bounds that take\nsynthetic data into account. Those bounds suggest novel ways to optimize\nsynthetic samples for evaluation and theoretically reveal the significant role\nof the generator's quality. Inspired by those bounds, we propose a\ntheoretically grounded method to generate optimized synthetic data for model\nevaluation. Experimental results on simulation and tabular datasets demonstrate\nthat, compared to existing baselines, our method achieves accurate and more\nreliable estimates of the test error.", "AI": {"tldr": "\u8bba\u6587\u5728\u6709\u9650\u6807\u7b7e\u6570\u636e\u4e0b\uff0c\u5229\u7528\u5408\u6210\u6570\u636e\u4f30\u8ba1\u6a21\u578b\u6d4b\u8bd5\u8bef\u5dee\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u5e76\u8bc1\u660e\u5176\u66f4\u51c6\u786e\u53ef\u9760\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u8bc4\u4f30\u9700\u5927\u91cf\u6807\u6ce8\u6d4b\u8bd5\u96c6\uff0c\u83b7\u53d6\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u63a2\u7d22\u5229\u7528\u5408\u6210\u6570\u636e\u5728\u6709\u9650\u6807\u7b7e\u6570\u636e\u4e0b\u8bc4\u4f30\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u8003\u8651\u5408\u6210\u6570\u636e\u7684\u6cdb\u5316\u8fb9\u754c\uff0c\u4ee5\u6b64\u4e3a\u542f\u53d1\u63d0\u51fa\u751f\u6210\u4f18\u5316\u5408\u6210\u6570\u636e\u7684\u7406\u8bba\u65b9\u6cd5\u3002", "result": "\u5728\u6a21\u62df\u548c\u8868\u683c\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\uff0c\u8be5\u65b9\u6cd5\u5bf9\u6d4b\u8bd5\u8bef\u5dee\u7684\u4f30\u8ba1\u66f4\u51c6\u786e\u53ef\u9760\u3002", "conclusion": "\u5229\u7528\u5408\u6210\u6570\u636e\u8bc4\u4f30\u6a21\u578b\u5728\u6709\u9650\u6807\u7b7e\u6570\u636e\u573a\u666f\u53ef\u884c\uff0c\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2511.00977", "pdf": "https://arxiv.org/pdf/2511.00977", "abs": "https://arxiv.org/abs/2511.00977", "authors": ["Kristiyan Sakalyan", "Alessandro Palma", "Filippo Guerranti", "Fabian J. Theis", "Stephan G\u00fcnnemann"], "title": "Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow", "categories": ["cs.LG", "q-bio.QM"], "comment": "37 pages, 15 figures, to appear in NeurIPS 2025", "summary": "Understanding the evolution of cellular microenvironments in spatiotemporal\ndata is essential for deciphering tissue development and disease progression.\nWhile experimental techniques like spatial transcriptomics now enable\nhigh-resolution mapping of tissue organization across space and time, current\nmethods that model cellular evolution operate at the single-cell level,\noverlooking the coordinated development of cellular states in a tissue. We\nintroduce NicheFlow, a flow-based generative model that infers the temporal\ntrajectory of cellular microenvironments across sequential spatial slides. By\nrepresenting local cell neighborhoods as point clouds, NicheFlow jointly models\nthe evolution of cell states and spatial coordinates using optimal transport\nand Variational Flow Matching. Our approach successfully recovers both global\nspatial architecture and local microenvironment composition across diverse\nspatiotemporal datasets, from embryonic to brain development.", "AI": {"tldr": "\u63d0\u51faNicheFlow\u6a21\u578b\u63a8\u65ad\u7ec6\u80de\u5fae\u73af\u5883\u65f6\u7a7a\u8f68\u8ff9\uff0c\u5728\u591a\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548", "motivation": "\u73b0\u6709\u5355\u7ec6\u80de\u5c42\u9762\u5efa\u6a21\u65b9\u6cd5\u5ffd\u7565\u7ec4\u7ec7\u4e2d\u7ec6\u80de\u72b6\u6001\u7684\u534f\u540c\u53d1\u5c55\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u7406\u89e3\u7ec6\u80de\u5fae\u73af\u5883\u65f6\u7a7a\u6f14\u53d8", "method": "\u5f15\u5165NicheFlow\uff0c\u5c06\u5c40\u90e8\u7ec6\u80de\u90bb\u57df\u8868\u793a\u4e3a\u70b9\u4e91\uff0c\u7528\u6700\u4f18\u4f20\u8f93\u548c\u53d8\u5206\u6d41\u5339\u914d\u8054\u5408\u5efa\u6a21\u7ec6\u80de\u72b6\u6001\u548c\u7a7a\u95f4\u5750\u6807\u6f14\u53d8", "result": "\u5728\u4ece\u80da\u80ce\u5230\u5927\u8111\u53d1\u80b2\u7684\u4e0d\u540c\u65f6\u7a7a\u6570\u636e\u96c6\u4e0a\u6210\u529f\u6062\u590d\u5168\u5c40\u7a7a\u95f4\u7ed3\u6784\u548c\u5c40\u90e8\u5fae\u73af\u5883\u7ec4\u6210", "conclusion": "NicheFlow\u80fd\u6709\u6548\u63a8\u65ad\u7ec6\u80de\u5fae\u73af\u5883\u7684\u65f6\u95f4\u8f68\u8ff9"}}
{"id": "2511.00987", "pdf": "https://arxiv.org/pdf/2511.00987", "abs": "https://arxiv.org/abs/2511.00987", "authors": ["Rongrong Xie", "Guido Sanguinetti"], "title": "Balanced Multimodal Learning via Mutual Information", "categories": ["cs.LG"], "comment": null, "summary": "Multimodal learning has increasingly become a focal point in research,\nprimarily due to its ability to integrate complementary information from\ndiverse modalities. Nevertheless, modality imbalance, stemming from factors\nsuch as insufficient data acquisition and disparities in data quality, has\noften been inadequately addressed. This issue is particularly prominent in\nbiological data analysis, where datasets are frequently limited, costly to\nacquire, and inherently heterogeneous in quality. Conventional multimodal\nmethodologies typically fall short in concurrently harnessing intermodal\nsynergies and effectively resolving modality conflicts.\n  In this study, we propose a novel unified framework explicitly designed to\naddress modality imbalance by utilizing mutual information to quantify\ninteractions between modalities. Our approach adopts a balanced multimodal\nlearning strategy comprising two key stages: cross-modal knowledge distillation\n(KD) and a multitask-like training paradigm. During the cross-modal KD\npretraining phase, stronger modalities are leveraged to enhance the predictive\ncapabilities of weaker modalities. Subsequently, our primary training phase\nemploys a multitask-like learning mechanism, dynamically calibrating gradient\ncontributions based on modality-specific performance metrics and intermodal\nmutual information. This approach effectively alleviates modality imbalance,\nthereby significantly improving overall multimodal model performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u91c7\u7528\u5e73\u8861\u7b56\u7565\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\u672a\u5f97\u5230\u5145\u5206\u89e3\u51b3\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u6a21\u6001\u534f\u540c\u4e0e\u51b2\u7a81\u89e3\u51b3\uff0c\u5728\u751f\u7269\u6570\u636e\u5206\u6790\u4e2d\u5c24\u4e3a\u7a81\u51fa\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff0c\u5229\u7528\u4e92\u4fe1\u606f\u91cf\u5316\u6a21\u6001\u4ea4\u4e92\uff0c\u91c7\u7528\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u548c\u591a\u4efb\u52a1\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u6709\u6548\u7f13\u89e3\u6a21\u6001\u4e0d\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.00989", "pdf": "https://arxiv.org/pdf/2511.00989", "abs": "https://arxiv.org/abs/2511.00989", "authors": ["Asal Meskin", "Alireza Mirrokni", "Ali Najar", "Ali Behrouz"], "title": "Hydra: Dual Exponentiated Memory for Multivariate Time Series Analysis", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, effectively modeling multivariate time series has gained\nsignificant popularity, mainly due to its wide range of applications, ranging\nfrom healthcare to financial markets and energy management. Transformers, MLPs,\nand linear models as the de facto backbones of modern time series models have\nshown promising results in single-variant and/or short-term forecasting. These\nmodels, however: (1) are permutation equivariant and so lack temporal inductive\nbias, being less expressive to capture the temporal dynamics; (2) are naturally\ndesigned for univariate setup, missing the inter-dependencies of temporal and\nvariate dimensions; and/or (3) are inefficient for Long-term time series\nmodeling. To overcome training and inference efficiency as well as the lack of\ntemporal inductive bias, recently, linear Recurrent Neural Networks (RNNs) have\ngained attention as an alternative to Transformer-based models. These models,\nhowever, are inherently limited to a single sequence, missing inter-variate\ndependencies, and can propagate errors due to their additive nature. In this\npaper, we present Hydra, a by-design two-headed meta in-context memory module\nthat learns how to memorize patterns at test time by prioritizing time series\npatterns that are more informative about the data. Hydra uses a 2-dimensional\nrecurrence across both time and variate at each step, which is more powerful\nthan mixing methods. Although the 2-dimensional nature of the model makes its\ntraining recurrent and non-parallelizable, we present a new 2D-chunk-wise\ntraining algorithm that approximates the actual recurrence with $\\times 10$\nefficiency improvement, while maintaining the effectiveness. Our experimental\nresults on a diverse set of tasks and datasets, including time series\nforecasting, classification, and anomaly detection show the superior\nperformance of Hydra compared to state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHydra\u6a21\u5757\u7528\u4e8e\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\uff0c\u91c7\u7528\u4e8c\u7ef4\u5faa\u73af\uff0c\u63d0\u51fa2D\u5206\u5757\u8bad\u7ec3\u7b97\u6cd5\u63d0\u5347\u6548\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u5b58\u5728\u7f3a\u4e4f\u65f6\u95f4\u5f52\u7eb3\u504f\u7f6e\u3001\u5ffd\u7565\u53d8\u91cf\u95f4\u4f9d\u8d56\u3001\u957f\u5e8f\u5217\u5efa\u6a21\u6548\u7387\u4f4e\u7b49\u95ee\u9898\uff0c\u9700\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faHydra\u6a21\u5757\uff0c\u5728\u65f6\u95f4\u548c\u53d8\u91cf\u7ef4\u5ea6\u8fdb\u884c\u4e8c\u7ef4\u5faa\u73af\uff0c\u8bbe\u8ba12D\u5206\u5757\u8bad\u7ec3\u7b97\u6cd5\u8fd1\u4f3c\u5b9e\u9645\u5faa\u73af\u3002", "result": "\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3001\u5206\u7c7b\u548c\u5f02\u5e38\u68c0\u6d4b\u7b49\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\uff0cHydra\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "Hydra\u6a21\u5757\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u7684\u95ee\u9898\u3002"}}
{"id": "2511.01006", "pdf": "https://arxiv.org/pdf/2511.01006", "abs": "https://arxiv.org/abs/2511.01006", "authors": ["Diantong Li", "Kyunghyun Cho", "Chong Liu"], "title": "None To Optima in Few Shots: Bayesian Optimization with MDP Priors", "categories": ["cs.LG"], "comment": null, "summary": "Bayesian Optimization (BO) is an efficient tool for optimizing black-box\nfunctions, but its theoretical guarantees typically hold in the asymptotic\nregime. In many critical real-world applications such as drug discovery or\nmaterials design, where each evaluation can be very costly and time-consuming,\nBO becomes impractical for many evaluations. In this paper, we introduce the\nProcedure-inFormed BO (ProfBO) algorithm, which solves black-box optimization\nwith remarkably few function evaluations. At the heart of our algorithmic\ndesign are Markov Decision Process (MDP) priors that model optimization\ntrajectories from related source tasks, thereby capturing procedural knowledge\non efficient optimization. We embed these MDP priors into a prior-fitted neural\nnetwork and employ model-agnostic meta-learning for fast adaptation to new\ntarget tasks. Experiments on real-world Covid and Cancer benchmarks and\nhyperparameter tuning tasks demonstrate that ProfBO consistently outperforms\nstate-of-the-art methods by achieving high-quality solutions with significantly\nfewer evaluations, making it ready for practical deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProfBO\u7b97\u6cd5\uff0c\u5229\u7528MDP\u5148\u9a8c\u548c\u5143\u5b66\u4e60\uff0c\u5728\u5c11\u8bc4\u4f30\u6b21\u6570\u4e0b\u89e3\u51b3\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u8bc4\u4f30\u6210\u672c\u9ad8\u3001\u8017\u65f6\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u5b9e\u7528\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u5c11\u8bc4\u4f30\u6b21\u6570\u4e0b\u89e3\u51b3\u9ed1\u76d2\u4f18\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165ProfBO\u7b97\u6cd5\uff0c\u4f7f\u7528MDP\u5148\u9a8c\u5efa\u6a21\u76f8\u5173\u6e90\u4efb\u52a1\u7684\u4f18\u5316\u8f68\u8ff9\uff0c\u5c06\u5176\u5d4c\u5165\u5148\u9a8c\u62df\u5408\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u91c7\u7528\u6a21\u578b\u65e0\u5173\u5143\u5b66\u4e60\u5feb\u901f\u9002\u5e94\u65b0\u76ee\u6807\u4efb\u52a1\u3002", "result": "\u5728\u65b0\u51a0\u3001\u764c\u75c7\u57fa\u51c6\u6d4b\u8bd5\u548c\u8d85\u53c2\u6570\u8c03\u6574\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cProfBO\u4ee5\u663e\u8457\u66f4\u5c11\u7684\u8bc4\u4f30\u6b21\u6570\u83b7\u5f97\u9ad8\u8d28\u91cf\u89e3\u51b3\u65b9\u6848\uff0c\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ProfBO\u7b97\u6cd5\u53ef\u5728\u5c11\u8bc4\u4f30\u6b21\u6570\u4e0b\u6709\u6548\u89e3\u51b3\u9ed1\u76d2\u4f18\u5316\u95ee\u9898\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2511.00139", "pdf": "https://arxiv.org/pdf/2511.00139", "abs": "https://arxiv.org/abs/2511.00139", "authors": ["Yu Cui", "Yujian Zhang", "Lina Tao", "Yang Li", "Xinyu Yi", "Zhibin Li"], "title": "End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Achieving human-like dexterous manipulation remains a major challenge for\ngeneral-purpose robots. While Vision-Language-Action (VLA) models show\npotential in learning skills from demonstrations, their scalability is limited\nby scarce high-quality training data. Existing data collection methods face\ninherent constraints: manual teleoperation overloads human operators, while\nautomated planning often produces unnatural motions. We propose a Shared\nAutonomy framework that divides control between macro and micro motions. A\nhuman operator guides the robot's arm pose through intuitive VR teleoperation,\nwhile an autonomous DexGrasp-VLA policy handles fine-grained hand control using\nreal-time tactile and visual feedback. This division significantly reduces\ncognitive load and enables efficient collection of high-quality coordinated\narm-hand demonstrations. Using this data, we train an end-to-end VLA policy\nenhanced with our novel Arm-Hand Feature Enhancement module, which captures\nboth distinct and shared representations of macro and micro movements for more\nnatural coordination. Our Corrective Teleoperation system enables continuous\npolicy improvement through human-in-the-loop failure recovery. Experiments\ndemonstrate that our framework generates high-quality data with minimal\nmanpower and achieves a 90% success rate across diverse objects, including\nunseen instances. Comprehensive evaluations validate the system's effectiveness\nin developing dexterous manipulation capabilities.", "AI": {"tldr": "\u63d0\u51fa\u5171\u4eab\u81ea\u4e3b\u6846\u67b6\u89e3\u51b3\u901a\u7528\u673a\u5668\u4eba\u7075\u5de7\u64cd\u4f5c\u6570\u636e\u6536\u96c6\u96be\u9898\uff0c\u8bad\u7ec3\u7aef\u5230\u7aefVLA\u7b56\u7565\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9ad8\u6548\u4e14\u6210\u529f\u7387\u9ad8\u3002", "motivation": "\u901a\u7528\u673a\u5668\u4eba\u5b9e\u73b0\u7c7b\u4eba\u7075\u5de7\u64cd\u4f5c\u9762\u4e34\u6311\u6218\uff0cVLA\u6a21\u578b\u56e0\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u9650\u5236\u53ef\u6269\u5c55\u6027\uff0c\u73b0\u6709\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u6709\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u5171\u4eab\u81ea\u4e3b\u6846\u67b6\uff0c\u5212\u5206\u5b8f\u5fae\u89c2\u8fd0\u52a8\u63a7\u5236\uff0c\u4eba\u7c7b\u901a\u8fc7VR\u5f15\u5bfc\u624b\u81c2\u59ff\u52bf\uff0cDexGrasp - VLA\u7b56\u7565\u5904\u7406\u624b\u90e8\u7cbe\u7ec6\u63a7\u5236\uff1b\u8bad\u7ec3\u5e26Arm - Hand\u7279\u5f81\u589e\u5f3a\u6a21\u5757\u7684\u7aef\u5230\u7aefVLA\u7b56\u7565\uff1b\u7528\u7ea0\u6b63\u6027\u9065\u64cd\u4f5c\u7cfb\u7edf\u5b9e\u73b0\u7b56\u7565\u6301\u7eed\u6539\u8fdb\u3002", "result": "\u6846\u67b6\u7528\u6700\u5c11\u4eba\u529b\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u5728\u591a\u6837\u7269\u4f53\u64cd\u4f5c\u4e2d\u6210\u529f\u7387\u8fbe90%\uff0c\u5305\u62ec\u672a\u89c1\u5b9e\u4f8b\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u57f9\u517b\u7075\u5de7\u64cd\u4f5c\u80fd\u529b\u65b9\u9762\u6709\u6548\u3002"}}
{"id": "2511.01009", "pdf": "https://arxiv.org/pdf/2511.01009", "abs": "https://arxiv.org/abs/2511.01009", "authors": ["Fabricio Olivetti de Franca", "Gabriel Kronberger"], "title": "Equality Graph Assisted Symbolic Regression", "categories": ["cs.LG"], "comment": null, "summary": "In Symbolic Regression (SR), Genetic Programming (GP) is a popular search\nalgorithm that delivers state-of-the-art results in term of accuracy. Its\nsuccess relies on the concept of neutrality, which induces large plateaus that\nthe search can safely navigate to more promising regions. Navigating these\nplateaus, while necessary, requires the computation of redundant expressions,\nup to 60% of the total number of evaluation, as noted in a recent study. The\nequality graph (e-graph) structure can compactly store and group equivalent\nexpressions enabling us to verify if a given expression and their variations\nwere already visited by the search, thus enabling us to avoid unnecessary\ncomputation. We propose a new search algorithm for symbolic regression called\nSymRegg that revolves around the e-graph structure following simple steps:\nperturb solutions sampled from a selection of expressions stored in the\ne-graph, if it generates an unvisited expression, insert it into the e-graph\nand generates its equivalent forms. We show that SymRegg is capable of\nimproving the efficiency of the search, maintaining consistently accurate\nresults across different datasets while requiring a choice of a minimalist set\nof hyperparameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u7b26\u53f7\u56de\u5f52\u7684\u65b0\u641c\u7d22\u7b97\u6cd5SymRegg\uff0c\u57fa\u4e8ee - graph\u7ed3\u6784\uff0c\u80fd\u63d0\u9ad8\u641c\u7d22\u6548\u7387\u5e76\u4fdd\u6301\u51c6\u786e\u7ed3\u679c\u3002", "motivation": "\u9057\u4f20\u7f16\u7a0b\u5728\u7b26\u53f7\u56de\u5f52\u4e2d\u867d\u51c6\u786e\uff0c\u4f46\u641c\u7d22\u65f6\u9700\u8ba1\u7b97\u5927\u91cf\u5197\u4f59\u8868\u8fbe\u5f0f\uff0c\u53ef\u8fbe\u603b\u8bc4\u4f30\u6570\u768460%\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u9ad8\u641c\u7d22\u6548\u7387\u3002", "method": "\u63d0\u51fa\u56f4\u7ed5e - graph\u7ed3\u6784\u7684\u65b0\u641c\u7d22\u7b97\u6cd5SymRegg\uff0c\u4ecee - graph\u4e2d\u9009\u62e9\u8868\u8fbe\u5f0f\u8fdb\u884c\u6270\u52a8\uff0c\u82e5\u4ea7\u751f\u672a\u8bbf\u95ee\u8868\u8fbe\u5f0f\u5219\u63d2\u5165e - graph\u5e76\u751f\u6210\u7b49\u4ef7\u5f62\u5f0f\u3002", "result": "SymRegg\u80fd\u63d0\u9ad8\u641c\u7d22\u6548\u7387\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u51c6\u786e\u7ed3\u679c\u3002", "conclusion": "SymRegg\u80fd\u63d0\u9ad8\u641c\u7d22\u6548\u7387\uff0c\u4e14\u53ea\u9700\u9009\u62e9\u6700\u5c11\u7684\u8d85\u53c2\u6570\u96c6\u5408\u3002"}}
{"id": "2511.00141", "pdf": "https://arxiv.org/pdf/2511.00141", "abs": "https://arxiv.org/abs/2511.00141", "authors": ["Janghoon Cho", "Jungsoo Lee", "Munawar Hayat", "Kyuwoong Hwang", "Fatih Porikli", "Sungha Choi"], "title": "FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent studies in long video understanding have harnessed the advanced\nvisual-language reasoning capabilities of Large Multimodal Models (LMMs),\ndriving the evolution of video-LMMs specialized for processing extended video\nsequences. However, the scalability of these models is severely limited by the\noverwhelming volume of visual tokens generated from extended video sequences.\nTo address this challenge, this paper proposes FLoC, an efficient visual token\ncompression framework based on the facility location function, a principled\napproach that swiftly selects a compact yet highly representative and diverse\nsubset of visual tokens within a predefined budget on the number of visual\ntokens. By integrating the lazy greedy algorithm, our method achieves\nremarkable efficiency gains by swiftly selecting a compact subset of tokens,\ndrastically reducing the number of visual tokens while guaranteeing\nnear-optimal performance. Notably, our approach is training-free,\nmodel-agnostic, and query-agnostic, providing a versatile solution that\nseamlessly integrates with diverse video-LLMs and existing workflows. Extensive\nevaluations on large-scale benchmarks, such as Video-MME, MLVU, and\nLongVideoBench, demonstrate that our framework consistently surpasses recent\ncompression techniques, highlighting not only its effectiveness and robustness\nin addressing the critical challenges of long video understanding, but also its\nefficiency in processing speed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8bbe\u65bd\u5b9a\u4f4d\u51fd\u6570\u7684\u9ad8\u6548\u89c6\u89c9\u4ee4\u724c\u538b\u7f29\u6846\u67b6FLoC\uff0c\u89e3\u51b3\u957f\u89c6\u9891\u7406\u89e3\u4e2d\u89c6\u89c9\u4ee4\u724c\u6570\u91cf\u8fc7\u591a\u95ee\u9898\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u538b\u7f29\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u957f\u89c6\u9891\u7406\u89e3\u7684\u89c6\u9891-LMMs\u6a21\u578b\u56e0\u957f\u89c6\u9891\u5e8f\u5217\u4ea7\u751f\u5927\u91cf\u89c6\u89c9\u4ee4\u724c\uff0c\u53ef\u6269\u5c55\u6027\u4e25\u91cd\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8bbe\u65bd\u5b9a\u4f4d\u51fd\u6570\u7684FLoC\u6846\u67b6\uff0c\u7ed3\u5408\u61d2\u60f0\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u5728\u9884\u5b9a\u4e49\u89c6\u89c9\u4ee4\u724c\u6570\u91cf\u9884\u7b97\u5185\u9009\u62e9\u7d27\u51d1\u3001\u6709\u4ee3\u8868\u6027\u548c\u591a\u6837\u6027\u7684\u89c6\u89c9\u4ee4\u724c\u5b50\u96c6\u3002", "result": "\u5728Video - MME\u3001MLVU\u548cLongVideoBench\u7b49\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u59cb\u7ec8\u4f18\u4e8e\u8fd1\u671f\u538b\u7f29\u6280\u672f\u3002", "conclusion": "FLoC\u6846\u67b6\u80fd\u6709\u6548\u3001\u7a33\u5065\u5730\u89e3\u51b3\u957f\u89c6\u9891\u7406\u89e3\u7684\u5173\u952e\u6311\u6218\uff0c\u4e14\u5904\u7406\u901f\u5ea6\u9ad8\u6548\uff0c\u5177\u6709\u8bad\u7ec3\u65e0\u5173\u3001\u6a21\u578b\u65e0\u5173\u548c\u67e5\u8be2\u65e0\u5173\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2511.01015", "pdf": "https://arxiv.org/pdf/2511.01015", "abs": "https://arxiv.org/abs/2511.01015", "authors": ["Nabeel Seedat", "Jiashuo Liu", "Mihaela van der Schaar"], "title": "What's the next frontier for Data-centric AI? Data Savvy Agents", "categories": ["cs.LG"], "comment": "Presented at ICLR 2025 Data-FM. Seedat & Liu contributed equally", "summary": "The recent surge in AI agents that autonomously communicate, collaborate with\nhumans and use diverse tools has unlocked promising opportunities in various\nreal-world settings. However, a vital aspect remains underexplored: how agents\nhandle data. Scalable autonomy demands agents that continuously acquire,\nprocess, and evolve their data. In this paper, we argue that data-savvy\ncapabilities should be a top priority in the design of agentic systems to\nensure reliable real-world deployment. Specifically, we propose four key\ncapabilities to realize this vision: (1) Proactive data acquisition: enabling\nagents to autonomously gather task-critical knowledge or solicit human input to\naddress data gaps; (2) Sophisticated data processing: requiring context-aware\nand flexible handling of diverse data challenges and inputs; (3) Interactive\ntest data synthesis: shifting from static benchmarks to dynamically generated\ninteractive test data for agent evaluation; and (4) Continual adaptation:\nempowering agents to iteratively refine their data and background knowledge to\nadapt to shifting environments. While current agent research predominantly\nemphasizes reasoning, we hope to inspire a reflection on the role of data-savvy\nagents as the next frontier in data-centric AI.", "AI": {"tldr": "\u5f53\u524dAI\u4ee3\u7406\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u6570\u636e\u5904\u7406\u80fd\u529b\u5f85\u63a2\u7d22\uff0c\u672c\u6587\u63d0\u51fa\u6570\u636e\u667a\u80fd\u80fd\u529b\u8bbe\u8ba1\u7684\u56db\u4e2a\u5173\u952e\u80fd\u529b\uff0c\u547c\u5401\u5173\u6ce8\u6570\u636e\u667a\u80fd\u4ee3\u7406\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5728\u6570\u636e\u5904\u7406\u65b9\u9762\u672a\u5145\u5206\u63a2\u7d22\uff0c\u53ef\u6269\u5c55\u81ea\u4e3b\u6027\u8981\u6c42\u4ee3\u7406\u5177\u5907\u6570\u636e\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u786e\u4fdd\u53ef\u9760\u7684\u5b9e\u9645\u90e8\u7f72\uff0c\u9700\u91cd\u89c6\u6570\u636e\u667a\u80fd\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u56db\u4e2a\u5173\u952e\u80fd\u529b\uff0c\u5305\u62ec\u4e3b\u52a8\u6570\u636e\u83b7\u53d6\u3001\u590d\u6742\u6570\u636e\u5904\u7406\u3001\u4ea4\u4e92\u5f0f\u6d4b\u8bd5\u6570\u636e\u5408\u6210\u548c\u6301\u7eed\u9002\u5e94\u3002", "result": "\u63d0\u51fa\u4e86\u5b9e\u73b0\u6570\u636e\u667a\u80fd\u80fd\u529b\u7684\u56db\u4e2a\u5173\u952e\u80fd\u529b\u3002", "conclusion": "\u5e0c\u671b\u5f15\u53d1\u5bf9\u6570\u636e\u667a\u80fd\u4ee3\u7406\u4f5c\u4e3a\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684AI\u4e0b\u4e00\u4e2a\u524d\u6cbf\u9886\u57df\u7684\u601d\u8003\u3002"}}
{"id": "2511.01017", "pdf": "https://arxiv.org/pdf/2511.01017", "abs": "https://arxiv.org/abs/2511.01017", "authors": ["Haoran Ye", "Qiuzhuang Sun", "Yang Yang"], "title": "SARIMAX-Based Power Outage Prediction During Extreme Weather Events", "categories": ["cs.LG", "62M10, 62P12", "G.3; H.2.8"], "comment": "12 pages, 3 figures. This paper presents the solution of Team 12 for\n  the 2025 INFORMS Data Mining Society Data Challenge. The open-source code is\n  available at: https://github.com/yhr-code/2025-INFORMS-DM-Challenge-Team12", "summary": "This study develops a SARIMAX-based prediction system for short-term power\noutage forecasting during extreme weather events. Using hourly data from\nMichigan counties with outage counts and comprehensive weather features, we\nimplement a systematic two-stage feature engineering pipeline: data cleaning to\nremove zero-variance and unknown features, followed by correlation-based\nfiltering to eliminate highly correlated predictors. The selected features are\naugmented with temporal embeddings, multi-scale lag features, and weather\nvariables with their corresponding lags as exogenous inputs to the SARIMAX\nmodel. To address data irregularity and numerical instability, we apply\nstandardization and implement a hierarchical fitting strategy with sequential\noptimization methods, automatic downgrading to ARIMA when convergence fails,\nand historical mean-based fallback predictions as a final safeguard. The model\nis optimized separately for short-term (24 hours) and medium-term (48 hours)\nforecast horizons using RMSE as the evaluation metric. Our approach achieves an\nRMSE of 177.2, representing an 8.4\\% improvement over the baseline method (RMSE\n= 193.4), thereby validating the effectiveness of our feature engineering and\nrobust optimization strategy for extreme weather-related outage prediction.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8eSARIMAX\u7684\u6781\u7aef\u5929\u6c14\u77ed\u671f\u505c\u7535\u9884\u6d4b\u7cfb\u7edf\uff0c\u7ecf\u7279\u5f81\u5de5\u7a0b\u548c\u4f18\u5316\u7b56\u7565\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5RMSE\u964d\u4f4e8.4%\u3002", "motivation": "\u5f00\u53d1\u6781\u7aef\u5929\u6c14\u4e0b\u77ed\u671f\u505c\u7535\u9884\u6d4b\u7cfb\u7edf\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7279\u5f81\u5de5\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u6e05\u6d17\u548c\u76f8\u5173\u6027\u8fc7\u6ee4\uff1b\u6dfb\u52a0\u591a\u79cd\u7279\u5f81\u4f5c\u4e3aSARIMAX\u5916\u751f\u8f93\u5165\uff1b\u5e94\u7528\u6807\u51c6\u5316\u548c\u5206\u5c42\u62df\u5408\u7b56\u7565\uff0c\u5931\u8d25\u65f6\u964d\u7ea7\u6216\u4f7f\u7528\u5386\u53f2\u5747\u503c\u9884\u6d4b\uff1b\u5206\u522b\u4f18\u5316\u77ed\u671f\u548c\u4e2d\u671f\u9884\u6d4b\u3002", "result": "\u6a21\u578bRMSE\u4e3a177.2\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff08RMSE = 193.4\uff09\u63d0\u9ad88.4%\u3002", "conclusion": "\u7279\u5f81\u5de5\u7a0b\u548c\u9c81\u68d2\u4f18\u5316\u7b56\u7565\u5bf9\u6781\u7aef\u5929\u6c14\u505c\u7535\u9884\u6d4b\u6709\u6548\u3002"}}
{"id": "2511.01054", "pdf": "https://arxiv.org/pdf/2511.01054", "abs": "https://arxiv.org/abs/2511.01054", "authors": ["Sama Salarian", "Yue Zhang", "Swati Padhee", "Srinivasan Parthasarathy"], "title": "MedEqualizer: A Framework Investigating Bias in Synthetic Medical Data and Mitigation via Augmentation", "categories": ["cs.LG"], "comment": null, "summary": "Synthetic healthcare data generation presents a viable approach to enhance\ndata accessibility and support research by overcoming limitations associated\nwith real-world medical datasets. However, ensuring fairness across protected\nattributes in synthetic data is critical to avoid biased or misleading results\nin clinical research and decision-making. In this study, we assess the fairness\nof synthetic data generated by multiple generative adversarial network\n(GAN)-based models using the MIMIC-III dataset, with a focus on\nrepresentativeness across protected demographic attributes. We measure subgroup\nrepresentation using the logarithmic disparity metric and observe significant\nimbalances, with many subgroups either underrepresented or overrepresented in\nthe synthetic data, compared to the real data. To mitigate these disparities,\nwe introduce MedEqualizer, a model-agnostic augmentation framework that\nenriches the underrepresented subgroups prior to synthetic data generation. Our\nresults show that MedEqualizer significantly improves demographic balance in\nthe resulting synthetic datasets, offering a viable path towards more equitable\nand representative healthcare data synthesis.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30GAN\u6a21\u578b\u751f\u6210\u5408\u6210\u533b\u7597\u6570\u636e\u7684\u516c\u5e73\u6027\uff0c\u53d1\u73b0\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u51faMedEqualizer\u6846\u67b6\u6539\u5584\u4e86\u4eba\u53e3\u7edf\u8ba1\u5b66\u5e73\u8861\u3002", "motivation": "\u786e\u4fdd\u5408\u6210\u533b\u7597\u6570\u636e\u5728\u53d7\u4fdd\u62a4\u5c5e\u6027\u4e0a\u7684\u516c\u5e73\u6027\uff0c\u907f\u514d\u4e34\u5e8a\u7814\u7a76\u548c\u51b3\u7b56\u7684\u504f\u5dee\u7ed3\u679c\u3002", "method": "\u7528\u5bf9\u6570\u5dee\u5f02\u6307\u6807\u8bc4\u4f30GAN\u6a21\u578b\u751f\u6210\u6570\u636e\u516c\u5e73\u6027\uff0c\u63d0\u51faMedEqualizer\u6846\u67b6\u5728\u751f\u6210\u6570\u636e\u524d\u4e30\u5bcc\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u5b50\u7ec4\u3002", "result": "MedEqualizer\u663e\u8457\u6539\u5584\u4e86\u5408\u6210\u6570\u636e\u96c6\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u5e73\u8861\u3002", "conclusion": "MedEqualizer\u4e3a\u66f4\u516c\u5e73\u548c\u6709\u4ee3\u8868\u6027\u7684\u533b\u7597\u6570\u636e\u5408\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2511.00179", "pdf": "https://arxiv.org/pdf/2511.00179", "abs": "https://arxiv.org/abs/2511.00179", "authors": ["Xiang Li", "Till Jahnke", "Rebecca Boll", "Jiaqi Han", "Minkai Xu", "Michael Meyer", "Maria Novella Piancastelli", "Daniel Rolles", "Artem Rudenko", "Florian Trinter", "Thomas J. A. Wolf", "Jana B. Thayer", "James P. Cryan", "Stefano Ermon", "Phay J. Ho"], "title": "Generative Modeling Enables Molecular Structure Retrieval from Coulomb Explosion Imaging", "categories": ["physics.chem-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Capturing the structural changes that molecules undergo during chemical\nreactions in real space and time is a long-standing dream and an essential\nprerequisite for understanding and ultimately controlling femtochemistry. A key\napproach to tackle this challenging task is Coulomb explosion imaging, which\nbenefited decisively from recently emerging high-repetition-rate X-ray\nfree-electron laser sources. With this technique, information on the molecular\nstructure is inferred from the momentum distributions of the ions produced by\nthe rapid Coulomb explosion of molecules. Retrieving molecular structures from\nthese distributions poses a highly non-linear inverse problem that remains\nunsolved for molecules consisting of more than a few atoms. Here, we address\nthis challenge using a diffusion-based Transformer neural network. We show that\nthe network reconstructs unknown molecular geometries from ion-momentum\ndistributions with a mean absolute error below one Bohr radius, which is half\nthe length of a typical chemical bond.", "AI": {"tldr": "\u672c\u6587\u7528\u57fa\u4e8e\u6269\u6563\u7684Transformer\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u4ece\u79bb\u5b50\u52a8\u91cf\u5206\u5e03\u4e2d\u91cd\u5efa\u5206\u5b50\u51e0\u4f55\u7ed3\u6784\u7684\u96be\u9898\uff0c\u91cd\u5efa\u8bef\u5dee\u5c0f\u4e8e\u4e00\u4e2a\u73bb\u5c14\u534a\u5f84\u3002", "motivation": "\u7406\u89e3\u548c\u63a7\u5236\u98de\u79d2\u5316\u5b66\u9700\u5728\u65f6\u7a7a\u4e0a\u6355\u6349\u5206\u5b50\u5316\u5b66\u53cd\u5e94\u4e2d\u7684\u7ed3\u6784\u53d8\u5316\uff0c\u800c\u4ece\u79bb\u5b50\u52a8\u91cf\u5206\u5e03\u4e2d\u68c0\u7d22\u5206\u5b50\u7ed3\u6784\u662f\u672a\u89e3\u51b3\u7684\u975e\u7ebf\u6027\u9006\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6269\u6563\u7684Transformer\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u7f51\u7edc\u80fd\u4ece\u79bb\u5b50\u52a8\u91cf\u5206\u5e03\u4e2d\u91cd\u5efa\u672a\u77e5\u5206\u5b50\u51e0\u4f55\u7ed3\u6784\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4f4e\u4e8e\u4e00\u4e2a\u73bb\u5c14\u534a\u5f84\u3002", "conclusion": "\u57fa\u4e8e\u6269\u6563\u7684Transformer\u795e\u7ecf\u7f51\u7edc\u53ef\u6709\u6548\u89e3\u51b3\u4ece\u79bb\u5b50\u52a8\u91cf\u5206\u5e03\u91cd\u5efa\u5206\u5b50\u7ed3\u6784\u7684\u96be\u9898\u3002"}}
{"id": "2511.01060", "pdf": "https://arxiv.org/pdf/2511.01060", "abs": "https://arxiv.org/abs/2511.01060", "authors": ["Andrew Hallam", "R G Gayathri", "Glory Lee", "Atul Sajjanhar"], "title": "Window-Based Feature Engineering for Cognitive Workload Detection", "categories": ["cs.LG"], "comment": "9 pages, 3 figures", "summary": "Cognitive workload is a topic of increasing interest across various fields\nsuch as health, psychology, and defense applications. In this research, we\nfocus on classifying cognitive workload using the COLET dataset, employing a\nwindow-based approach for feature generation and machine/deep learning\ntechniques for classification. We apply window-based temporal partitioning to\nenhance features used in existing research, followed by machine learning and\ndeep learning models to classify different levels of cognitive workload. The\nresults demonstrate that deep learning models, particularly tabular\narchitectures, outperformed traditional machine learning methods in precision,\nF1-score, accuracy, and classification precision. This study highlights the\neffectiveness of window-based temporal feature extraction and the potential of\ndeep learning techniques for real-time cognitive workload assessment in complex\nand dynamic tasks.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528COLET\u6570\u636e\u96c6\uff0c\u91c7\u7528\u57fa\u4e8e\u7a97\u53e3\u7684\u65b9\u6cd5\u548c\u673a\u5668\u5b66\u4e60/\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5bf9\u8ba4\u77e5\u5de5\u4f5c\u91cf\u8fdb\u884c\u5206\u7c7b\uff0c\u7ed3\u679c\u663e\u793a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0c\u51f8\u663e\u57fa\u4e8e\u7a97\u53e3\u7684\u7279\u5f81\u63d0\u53d6\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5728\u5b9e\u65f6\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u8ba4\u77e5\u5de5\u4f5c\u91cf\u5728\u591a\u4e2a\u9886\u57df\u53d7\u5173\u6ce8\uff0c\u7814\u7a76\u65e8\u5728\u5bf9\u5176\u8fdb\u884c\u5206\u7c7b\u3002", "method": "\u4f7f\u7528COLET\u6570\u636e\u96c6\uff0c\u91c7\u7528\u57fa\u4e8e\u7a97\u53e3\u7684\u65b9\u6cd5\u751f\u6210\u7279\u5f81\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u8fdb\u884c\u5206\u7c7b\uff0c\u901a\u8fc7\u7a97\u53e3\u5f0f\u65f6\u95f4\u5212\u5206\u589e\u5f3a\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u7279\u5f81\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7279\u522b\u662f\u8868\u683c\u67b6\u6784\uff0c\u5728\u7cbe\u5ea6\u3001F1\u5206\u6570\u3001\u51c6\u786e\u7387\u548c\u5206\u7c7b\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u7a97\u53e3\u7684\u65f6\u95f4\u7279\u5f81\u63d0\u53d6\u6709\u6548\uff0c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5728\u590d\u6742\u52a8\u6001\u4efb\u52a1\u7684\u5b9e\u65f6\u8ba4\u77e5\u5de5\u4f5c\u91cf\u8bc4\u4f30\u4e2d\u6709\u6f5c\u529b\u3002"}}
{"id": "2511.00191", "pdf": "https://arxiv.org/pdf/2511.00191", "abs": "https://arxiv.org/abs/2511.00191", "authors": ["Ziliang Chen", "Xin Huang", "Quanlong Guan", "Liang Lin", "Weiqi Luo"], "title": "A Retrospect to Multi-prompt Learning across Vision and Language", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV", "summary": "The vision community is undergoing the unprecedented progress with the\nemergence of Vision-Language Pretraining Models (VLMs). Prompt learning plays\nas the holy grail of accessing VLMs since it enables their fast adaptation to\ndownstream tasks with limited resources. Whereas existing researches milling\naround single-prompt paradigms, rarely investigate the technical potential\nbehind their multi-prompt learning counterparts. This paper aims to provide a\nprincipled retrospect for vision-language multi-prompt learning. We extend the\nrecent constant modality gap phenomenon to learnable prompts and then, justify\nthe superiority of vision-language transfer with multi-prompt augmentation,\nempirically and theoretically. In terms of this observation, we propose an\nEnergy-based Multi-prompt Learning (EMPL) to generate multiple prompt\nembeddings by drawing instances from an energy-based distribution, which is\nimplicitly defined by VLMs. So our EMPL is not only parameter-efficient but\nalso rigorously lead to the balance between in-domain and out-of-domain\nopen-vocabulary generalization. Comprehensive experiments have been conducted\nto justify our claims and the excellence of EMPL.", "AI": {"tldr": "\u672c\u6587\u5bf9\u89c6\u89c9\u8bed\u8a00\u591a\u63d0\u793a\u5b66\u4e60\u8fdb\u884c\u56de\u987e\uff0c\u63d0\u51fa\u57fa\u4e8e\u80fd\u91cf\u7684\u591a\u63d0\u793a\u5b66\u4e60\u65b9\u6cd5EMPL\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u56f4\u7ed5\u5355\u63d0\u793a\u8303\u5f0f\uff0c\u5f88\u5c11\u63a2\u7d22\u591a\u63d0\u793a\u5b66\u4e60\u7684\u6280\u672f\u6f5c\u529b\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u5bf9\u89c6\u89c9\u8bed\u8a00\u591a\u63d0\u793a\u5b66\u4e60\u8fdb\u884c\u56de\u987e\u3002", "method": "\u5c06\u6052\u5b9a\u6a21\u6001\u5dee\u8ddd\u73b0\u8c61\u6269\u5c55\u5230\u53ef\u5b66\u4e60\u63d0\u793a\uff0c\u63d0\u51fa\u57fa\u4e8e\u80fd\u91cf\u7684\u591a\u63d0\u793a\u5b66\u4e60\uff08EMPL\uff09\uff0c\u4ece\u80fd\u91cf\u5206\u5e03\u4e2d\u62bd\u53d6\u5b9e\u4f8b\u751f\u6210\u591a\u4e2a\u63d0\u793a\u5d4c\u5165\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eEMPL\u4e0d\u4ec5\u8282\u7701\u53c2\u6570\uff0c\u8fd8\u80fd\u5728\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u5f00\u653e\u8bcd\u6c47\u6cdb\u5316\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "conclusion": "EMPL\u65b9\u6cd5\u6709\u6548\uff0c\u5177\u6709\u4e00\u5b9a\u4f18\u52bf\u3002"}}
{"id": "2511.01061", "pdf": "https://arxiv.org/pdf/2511.01061", "abs": "https://arxiv.org/abs/2511.01061", "authors": ["Przemys\u0142aw Spyra", "Witold Dzwinel"], "title": "Energy-Efficient Deep Learning Without Backpropagation: A Rigorous Evaluation of Forward-Only Algorithms", "categories": ["cs.LG", "cs.AI", "68T07", "I.2.0"], "comment": null, "summary": "The long-held assumption that backpropagation (BP) is essential for\nstate-of-the-art performance is challenged by this work. We present rigorous,\nhardware-validated evidence that the Mono-Forward (MF) algorithm, a\nbackpropagation-free method, consistently surpasses an optimally tuned BP\nbaseline in classification accuracy on its native Multi-Layer Perceptron (MLP)\narchitectures. This superior generalization is achieved with profound\nefficiency gains, including up to 41% less energy consumption and up to 34%\nfaster training. Our analysis, which charts an evolutionary path from Geoffrey\nHinton's Forward-Forward (FF) to the Cascaded Forward (CaFo) and finally to MF,\nis grounded in a fair comparative framework using identical architectures and\nuniversal hyperparameter optimization. We further provide a critical\nre-evaluation of memory efficiency in BP-free methods, empirically\ndemonstrating that practical overhead can offset theoretical gains. Ultimately,\nthis work establishes MF as a practical, high-performance, and sustainable\nalternative to BP for MLPs.", "AI": {"tldr": "\u672c\u6587\u6311\u6218BP\u5bf9\u5b9e\u73b0\u5148\u8fdb\u6027\u80fd\u7684\u5fc5\u8981\u6027\uff0c\u63d0\u51fa\u65e0\u53cd\u5411\u4f20\u64ad\u7684MF\u7b97\u6cd5\uff0c\u5728\u5206\u7c7b\u7cbe\u5ea6\u4e0a\u8d85BP\uff0c\u6709\u663e\u8457\u6548\u7387\u63d0\u5347\uff0c\u8fd8\u91cd\u65b0\u8bc4\u4f30\u65e0BP\u65b9\u6cd5\u7684\u5185\u5b58\u6548\u7387\uff0c\u786e\u7acbMF\u4e3aMLP\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u6311\u6218\u957f\u671f\u4ee5\u6765\u8ba4\u4e3aBP\u5bf9\u5b9e\u73b0\u5148\u8fdb\u6027\u80fd\u5fc5\u4e0d\u53ef\u5c11\u7684\u5047\u8bbe\uff0c\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u7b97\u6cd5\u3002", "method": "\u63d0\u51faMF\u7b97\u6cd5\uff0c\u5728\u76f8\u540c\u67b6\u6784\u548c\u901a\u7528\u8d85\u53c2\u6570\u4f18\u5316\u7684\u516c\u5e73\u5bf9\u6bd4\u6846\u67b6\u4e0b\uff0c\u4eceFF\u5230CaFo\u518d\u5230MF\u8fdb\u884c\u5206\u6790\uff0c\u8fd8\u5bf9\u65e0BP\u65b9\u6cd5\u7684\u5185\u5b58\u6548\u7387\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "MF\u7b97\u6cd5\u5728\u5206\u7c7b\u7cbe\u5ea6\u4e0a\u8d85\u8fc7\u6700\u4f18\u8c03\u4f18\u7684BP\u57fa\u7ebf\uff0c\u6709\u663e\u8457\u6548\u7387\u63d0\u5347\uff0c\u5982\u80fd\u8017\u6700\u591a\u964d\u4f4e41%\uff0c\u8bad\u7ec3\u901f\u5ea6\u6700\u591a\u52a0\u5feb34%\uff0c\u4e14\u53d1\u73b0\u65e0BP\u65b9\u6cd5\u7684\u5b9e\u9645\u5f00\u9500\u53ef\u80fd\u62b5\u6d88\u7406\u8bba\u4f18\u52bf\u3002", "conclusion": "MF\u7b97\u6cd5\u662fMLP\u5b9e\u7528\u3001\u9ad8\u6027\u80fd\u4e14\u53ef\u6301\u7eed\u7684BP\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.00198", "pdf": "https://arxiv.org/pdf/2511.00198", "abs": "https://arxiv.org/abs/2511.00198", "authors": ["Chun-Hao Yang", "Bo-Han Feng", "Tzu-Yuan Lai", "Yan Yu Chen", "Yin-Kai Dean Huang", "Shou-De Lin"], "title": "Training LLMs Beyond Next Token Prediction - Filling the Mutual Information Gap", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Optimizing training performance in large language models (LLMs) remains an\nessential challenge, particularly in improving model performance while\nmaintaining computational costs. This work challenges the conventional approach\nof training LLMs using next-token prediction (NTP), arguing that by predicting\ninformation-rich tokens during training, there is a more effective way to train\nLLMs. We investigate the impact of the proposed solution in three kinds of\ntasks for LLMs: arithmetic, multi-label classification of text, and\nnatural-language generation. This work offers a principled approach to\noptimizing LLM training, advancing both model performance and theoretical\nunderstanding of the target-token selection strategies.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4f20\u7edfNTP\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff0c\u63d0\u51fa\u9884\u6d4b\u4fe1\u606f\u4e30\u5bcc\u7684\u6807\u8bb0\u8fdb\u884c\u8bad\u7ec3\uff0c\u5728\u4e09\u7c7b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u4f18\u5316\u8bad\u7ec3\u5e76\u63d0\u5347\u7406\u8bba\u7406\u89e3\u3002", "motivation": "\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6027\u80fd\uff0c\u5728\u63d0\u5347\u6a21\u578b\u6027\u80fd\u540c\u65f6\u63a7\u5236\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u6311\u6218\u4f20\u7edfNTP\u8bad\u7ec3\u65b9\u6cd5\uff0c\u63d0\u51fa\u9884\u6d4b\u4fe1\u606f\u4e30\u5bcc\u7684\u6807\u8bb0\u6765\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5728\u4e09\u7c7b\u4efb\u52a1\u4e2d\u7814\u7a76\u5176\u5f71\u54cd\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u5bf9\u76ee\u6807\u6807\u8bb0\u9009\u62e9\u7b56\u7565\u7684\u7406\u8bba\u7406\u89e3\u3002"}}
{"id": "2511.01093", "pdf": "https://arxiv.org/pdf/2511.01093", "abs": "https://arxiv.org/abs/2511.01093", "authors": ["Aman Jaglan", "Jarrod Barnes"], "title": "Continual Learning, Not Training: Online Adaptation For Agents", "categories": ["cs.LG", "cs.AI", "F.2.2; I.2.7"], "comment": "12 pages, 4 figures", "summary": "Continual Learning (CL) methods have traditionally focused on mitigating\ncatastrophic forgetting through gradient-based retraining, an approach\nill-suited for deployed agents that must adapt in real time. We introduce our\nAdaptive Teaching and Learning System (ATLAS), a dual-agent architecture that\ndecouples reasoning (Teacher) from execution (Student) and incorporates a\npersistent learning memory that stores distilled guidance from experience. This\ninforms the orchestration layer, enabling the system to dynamically adjust its\noperational strategies, such as supervision level or initial plan selection, at\ninference time. In doing so, ATLAS achieves gradient-free continual learning,\nshifting the locus of adaptation from model parameters to system-level\norchestration. We formulate this as a system-centric paradigm for continual\nlearning, where the objective is adaptive efficiency: maximizing task success\nwhile minimizing computational cost through inference-time orchestration rather\nthan parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source\nbenchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1%\nsuccess with GPT-5-mini as its Student, outperforming the larger GPT-5 (High)\nby 13% while reducing cost by 86%. Cross-incident validation demonstrates\ngeneralization: frozen pamphlets from Incident #5 improve accuracy from 28% to\n41% with zero retraining, while shifting output composition from verbose\nexploration to structured reasoning. Together, these findings establish\ngradient-free continual learning as a viable path toward adaptive, deployable\nAI systems and provide causally annotated traces valuable for training explicit\nworld models.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u6559\u5b66\u4e0e\u5b66\u4e60\u7cfb\u7edfATLAS\uff0c\u5b9e\u73b0\u65e0\u68af\u5ea6\u6301\u7eed\u5b66\u4e60\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8bc1\u660e\u65e0\u68af\u5ea6\u6301\u7eed\u5b66\u4e60\u662f\u53ef\u884c\u8def\u5f84\u3002", "motivation": "\u4f20\u7edf\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u57fa\u4e8e\u68af\u5ea6\u518d\u8bad\u7ec3\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u9002\u5e94\u7684\u90e8\u7f72\u4ee3\u7406\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165ATLAS\u53cc\u4ee3\u7406\u67b6\u6784\uff0c\u89e3\u8026\u63a8\u7406\u548c\u6267\u884c\uff0c\u7ed3\u5408\u6301\u4e45\u5b66\u4e60\u8bb0\u5fc6\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u7f16\u6392\u5b9e\u73b0\u65e0\u68af\u5ea6\u6301\u7eed\u5b66\u4e60\u3002", "result": "\u5728ExCyTIn - Bench\u4e0a\uff0cATLAS\u7528GPT - 5 - mini\u6210\u529f\u7387\u8fbe54.1%\uff0c\u4f18\u4e8eGPT - 5 (High) 13%\uff0c\u964d\u4f4e\u6210\u672c86%\uff1b\u8de8\u4e8b\u4ef6\u9a8c\u8bc1\u6709\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u65e0\u68af\u5ea6\u6301\u7eed\u5b66\u4e60\u662f\u5b9e\u73b0\u81ea\u9002\u5e94\u3001\u53ef\u90e8\u7f72AI\u7cfb\u7edf\u7684\u53ef\u884c\u8def\u5f84\uff0c\u63d0\u4f9b\u7684\u56e0\u679c\u6ce8\u91ca\u8f68\u8ff9\u5bf9\u8bad\u7ec3\u663e\u5f0f\u4e16\u754c\u6a21\u578b\u6709\u4ef7\u503c\u3002"}}
{"id": "2511.00211", "pdf": "https://arxiv.org/pdf/2511.00211", "abs": "https://arxiv.org/abs/2511.00211", "authors": ["Wenxuan Zhang", "Peng Hu"], "title": "An Efficient and Generalizable Transfer Learning Method for Weather Condition Detection on Ground Terminals", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "The increasing adoption of satellite Internet with low-Earth-orbit (LEO)\nsatellites in mega-constellations allows ubiquitous connectivity to rural and\nremote areas. However, weather events have a significant impact on the\nperformance and reliability of satellite Internet. Adverse weather events such\nas snow and rain can disturb the performance and operations of satellite\nInternet's essential ground terminal components, such as satellite antennas,\nsignificantly disrupting the space-ground link conditions between LEO\nsatellites and ground stations. This challenge calls for not only region-based\nweather forecasts but also fine-grained detection capability on ground terminal\ncomponents of fine-grained weather conditions. Such a capability can assist in\nfault diagnostics and mitigation for reliable satellite Internet, but its\nsolutions are lacking, not to mention the effectiveness and generalization that\nare essential in real-world deployments. This paper discusses an efficient\ntransfer learning (TL) method that can enable a ground component to locally\ndetect representative weather-related conditions. The proposed method can\ndetect snow, wet, and other conditions resulting from adverse and typical\nweather events and shows superior performance compared to the typical deep\nlearning methods, such as YOLOv7, YOLOv9, Faster R-CNN, and R-YOLO. Our TL\nmethod also shows the advantage of being generalizable to various scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u8ba9\u5730\u9762\u7ec4\u4ef6\u672c\u5730\u68c0\u6d4b\u5929\u6c14\u72b6\u51b5\uff0c\u6027\u80fd\u4f18\u4e8e\u5178\u578b\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e14\u5177\u6709\u6cdb\u5316\u4f18\u52bf\u3002", "motivation": "\u6076\u52a3\u5929\u6c14\u5f71\u54cd\u536b\u661f\u4e92\u8054\u7f51\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u7f3a\u4e4f\u9488\u5bf9\u5730\u9762\u7ec8\u7aef\u7ec4\u4ef6\u7ec6\u7c92\u5ea6\u5929\u6c14\u72b6\u51b5\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7684\u8fc1\u79fb\u5b66\u4e60\uff08TL\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u5730\u9762\u7ec4\u4ef6\u672c\u5730\u68c0\u6d4b\u4ee3\u8868\u6027\u5929\u6c14\u76f8\u5173\u72b6\u51b5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u68c0\u6d4b\u96ea\u3001\u6f6e\u6e7f\u7b49\u5929\u6c14\u72b6\u51b5\uff0c\u6027\u80fd\u4f18\u4e8eYOLOv7\u3001YOLOv9\u7b49\u5178\u578b\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\uff0c\u4e14\u5177\u6709\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u4f18\u52bf\u3002"}}
{"id": "2511.01126", "pdf": "https://arxiv.org/pdf/2511.01126", "abs": "https://arxiv.org/abs/2511.01126", "authors": ["Parvin Nazari", "Bojian Hou", "Davoud Ataee Tarzanagh", "Li Shen", "George Michailidis"], "title": "Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "math.ST", "stat.TH"], "comment": "Published at NeurIPS 2025. 88 pages and 3 figures", "summary": "Online bilevel optimization (OBO) is a powerful framework for machine\nlearning problems where both outer and inner objectives evolve over time,\nrequiring dynamic updates. Current OBO approaches rely on deterministic\n\\textit{window-smoothed} regret minimization, which may not accurately reflect\nsystem performance when functions change rapidly. In this work, we introduce a\nnovel search direction and show that both first- and zeroth-order (ZO)\nstochastic OBO algorithms leveraging this direction achieve sublinear\n{stochastic bilevel regret without window smoothing}. Beyond these guarantees,\nour framework enhances efficiency by: (i) reducing oracle dependence in\nhypergradient estimation, (ii) updating inner and outer variables alongside the\nlinear system solution, and (iii) employing ZO-based estimation of Hessians,\nJacobians, and gradients. Experiments on online parametric loss tuning and\nblack-box adversarial attacks validate our approach.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u641c\u7d22\u65b9\u5411\uff0c\u4f7f\u968f\u673aOBO\u7b97\u6cd5\u5728\u65e0\u7a97\u53e3\u5e73\u6ed1\u4e0b\u5b9e\u73b0\u6b21\u7ebf\u6027\u968f\u673a\u53cc\u5c42\u9057\u61be\uff0c\u6846\u67b6\u63d0\u9ad8\u6548\u7387\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5728\u7ebf\u53cc\u5c42\u4f18\u5316\uff08OBO\uff09\u65b9\u6cd5\u4f9d\u8d56\u786e\u5b9a\u6027\u7a97\u53e3\u5e73\u6ed1\u9057\u61be\u6700\u5c0f\u5316\uff0c\u5728\u51fd\u6570\u5feb\u901f\u53d8\u5316\u65f6\u4e0d\u80fd\u51c6\u786e\u53cd\u6620\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5f15\u5165\u65b0\u641c\u7d22\u65b9\u5411\uff0c\u6784\u5efa\u4e00\u9636\u548c\u96f6\u9636\uff08ZO\uff09\u968f\u673aOBO\u7b97\u6cd5\uff0c\u51cf\u5c11\u8d85\u68af\u5ea6\u4f30\u8ba1\u7684\u795e\u8c15\u4f9d\u8d56\uff0c\u66f4\u65b0\u5185\u5916\u53d8\u91cf\u5e76\u91c7\u7528ZO\u4f30\u8ba1\u3002", "result": "\u7b97\u6cd5\u5728\u65e0\u7a97\u53e3\u5e73\u6ed1\u4e0b\u5b9e\u73b0\u6b21\u7ebf\u6027\u968f\u673a\u53cc\u5c42\u9057\u61be\uff0c\u6846\u67b6\u63d0\u9ad8\u4e86\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5728\u7ebf\u53c2\u6570\u635f\u5931\u8c03\u6574\u548c\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.00218", "pdf": "https://arxiv.org/pdf/2511.00218", "abs": "https://arxiv.org/abs/2511.00218", "authors": ["Rajatsubhra Chakraborty", "Ana Espinosa-Momox", "Riley Haskin", "Depeng Xu", "Rosario Porras-Aguilar"], "title": "DM-QPMNET: Dual-modality fusion network for cell segmentation in quantitative phase microscopy", "categories": ["cs.CV", "cs.AI"], "comment": "5 pages, 4 figures", "summary": "Cell segmentation in single-shot quantitative phase microscopy (ssQPM) faces\nchallenges from traditional thresholding methods that are sensitive to noise\nand cell density, while deep learning approaches using simple channel\nconcatenation fail to exploit the complementary nature of polarized intensity\nimages and phase maps. We introduce DM-QPMNet, a dual-encoder network that\ntreats these as distinct modalities with separate encoding streams. Our\narchitecture fuses modality-specific features at intermediate depth via\nmulti-head attention, enabling polarized edge and texture representations to\nselectively integrate complementary phase information. This content-aware\nfusion preserves training stability while adding principled multi-modal\nintegration through dual-source skip connections and per-modality normalization\nat minimal overhead. Our approach demonstrates substantial improvements over\nmonolithic concatenation and single-modality baselines, showing that\nmodality-specific encoding with learnable fusion effectively exploits ssQPM's\nsimultaneous capture of complementary illumination and phase cues for robust\ncell segmentation.", "AI": {"tldr": "\u63d0\u51faDM - QPMNet\u7f51\u7edc\u7528\u4e8e\u5355\u5e27\u5b9a\u91cf\u76f8\u4f4d\u663e\u5fae\u955c\uff08ssQPM\uff09\u7684\u7ec6\u80de\u5206\u5272\uff0c\u8be5\u7f51\u7edc\u6709\u53cc\u7f16\u7801\u5668\uff0c\u878d\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u6548\u679c\u4f18\u4e8e\u5355\u6a21\u6001\u548c\u7b80\u5355\u62fc\u63a5\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u9608\u503c\u6cd5\u5bf9\u566a\u58f0\u548c\u7ec6\u80de\u5bc6\u5ea6\u654f\u611f\uff0c\u7b80\u5355\u901a\u9053\u62fc\u63a5\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u65e0\u6cd5\u5229\u7528\u504f\u632f\u5f3a\u5ea6\u56fe\u50cf\u548c\u76f8\u4f4d\u56fe\u7684\u4e92\u8865\u6027\u3002", "method": "\u5f15\u5165DM - QPMNet\u53cc\u7f16\u7801\u5668\u7f51\u7edc\uff0c\u901a\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u5728\u4e2d\u95f4\u6df1\u5ea6\u878d\u5408\u6a21\u6001\u7279\u5b9a\u7279\u5f81\uff0c\u91c7\u7528\u53cc\u6e90\u8df3\u8dc3\u8fde\u63a5\u548c\u6bcf\u6a21\u6001\u5f52\u4e00\u5316\u3002", "result": "\u76f8\u6bd4\u6574\u4f53\u62fc\u63a5\u548c\u5355\u6a21\u6001\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u7279\u5b9a\u6a21\u6001\u7f16\u7801\u4e0e\u53ef\u5b66\u4e60\u878d\u5408\u80fd\u6709\u6548\u5229\u7528ssQPM\u540c\u65f6\u6355\u83b7\u7684\u4e92\u8865\u7167\u660e\u548c\u76f8\u4f4d\u7ebf\u7d22\u8fdb\u884c\u7a33\u5065\u7684\u7ec6\u80de\u5206\u5272\u3002"}}
{"id": "2511.00222", "pdf": "https://arxiv.org/pdf/2511.00222", "abs": "https://arxiv.org/abs/2511.00222", "authors": ["Marwa Abdulhai", "Ryan Cheng", "Donovan Clay", "Tim Althoff", "Sergey Levine", "Natasha Jaques"], "title": "Consistently Simulating Human Personas with Multi-Turn Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used to simulate human users in\ninteractive settings such as therapy, education, and social role-play. While\nthese simulations enable scalable training and evaluation of AI agents,\noff-the-shelf LLMs often drift from their assigned personas, contradict earlier\nstatements, or abandon role-appropriate behavior. We introduce a unified\nframework for evaluating and improving persona consistency in LLM-generated\ndialogue. We define three automatic metrics: prompt-to-line consistency,\nline-to-line consistency, and Q&A consistency, that capture different types of\npersona drift and validate each against human annotations. Using these metrics\nas reward signals, we apply multi-turn reinforcement learning to fine-tune LLMs\nfor three user roles: a patient, a student, and a social chat partner. Our\nmethod reduces inconsistency by over 55%, resulting in more coherent and\nfaithful simulated users.", "AI": {"tldr": "\u63d0\u51fa\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5bf9\u8bdd\u4e2d\u89d2\u8272\u4e00\u81f4\u6027\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u81ea\u52a8\u6307\u6807\u548c\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u6a21\u578b\uff0c\u4f7f\u4e0d\u4e00\u81f4\u6027\u964d\u4f4e\u8d8555%\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u4eba\u7c7b\u7528\u6237\u65f6\u5b58\u5728\u89d2\u8272\u6f02\u79fb\u7b49\u95ee\u9898\uff0c\u9700\u8981\u8bc4\u4f30\u548c\u6539\u8fdb\u89d2\u8272\u4e00\u81f4\u6027\u3002", "method": "\u5b9a\u4e49\u4e09\u79cd\u81ea\u52a8\u6307\u6807\uff08\u63d0\u793a\u5230\u884c\u4e00\u81f4\u6027\u3001\u884c\u5230\u884c\u4e00\u81f4\u6027\u3001\u95ee\u7b54\u4e00\u81f4\u6027\uff09\u5e76\u4e0e\u4eba\u5de5\u6807\u6ce8\u9a8c\u8bc1\uff0c\u4ee5\u8fd9\u4e9b\u6307\u6807\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u5e94\u7528\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u65b9\u6cd5\u4f7f\u4e0d\u4e00\u81f4\u6027\u964d\u4f4e\u8d85\u8fc755%\uff0c\u751f\u6210\u7684\u6a21\u62df\u7528\u6237\u66f4\u8fde\u8d2f\u3001\u66f4\u7b26\u5408\u89d2\u8272\u8bbe\u5b9a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u80fd\u6709\u6548\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5bf9\u8bdd\u7684\u89d2\u8272\u4e00\u81f4\u6027\u3002"}}
{"id": "2511.01172", "pdf": "https://arxiv.org/pdf/2511.01172", "abs": "https://arxiv.org/abs/2511.01172", "authors": ["Ali Owfi", "Amirmohammad Bamdad", "Tolunay Seyfi", "Fatemeh Afghah"], "title": "Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Deep learning has emerged as a leading approach for Automatic Modulation\nClassification (AMC), demonstrating superior performance over traditional\nmethods. However, vulnerability to adversarial attacks and susceptibility to\ndata distribution shifts hinder their practical deployment in real-world,\ndynamic environments. To address these threats, we propose a novel, unified\nframework that integrates meta-learning with domain adaptation, making AMC\nsystems resistant to both adversarial attacks and environmental changes. Our\nframework utilizes a two-phase strategy. First, in an offline phase, we employ\na meta-learning approach to train the model on clean and adversarially\nperturbed samples from a single source domain. This method enables the model to\ngeneralize its defense, making it resistant to a combination of previously\nunseen attacks. Subsequently, in the online phase, we apply domain adaptation\nto align the model's features with a new target domain, allowing it to adapt\nwithout requiring substantial labeled data. As a result, our framework achieves\na significant improvement in modulation classification accuracy against these\ncombined threats, offering a critical solution to the deployment and\noperational challenges of modern AMC systems.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5143\u5b66\u4e60\u4e0e\u57df\u9002\u5e94\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u81ea\u52a8\u8c03\u5236\u5206\u7c7b\uff08AMC\uff09\u7cfb\u7edf\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60AMC\u65b9\u6cd5\u6613\u53d7\u5bf9\u6297\u653b\u51fb\u548c\u6570\u636e\u5206\u5e03\u53d8\u5316\u5f71\u54cd\uff0c\u963b\u788d\u5176\u5728\u73b0\u5b9e\u52a8\u6001\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u9700\u89e3\u51b3\u8fd9\u4e9b\u5a01\u80c1\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff0c\u79bb\u7ebf\u9636\u6bb5\u7528\u5143\u5b66\u4e60\u5728\u5355\u4e00\u6e90\u57df\u7684\u5e72\u51c0\u548c\u5bf9\u6297\u6270\u52a8\u6837\u672c\u4e0a\u8bad\u7ec3\u6a21\u578b\uff1b\u5728\u7ebf\u9636\u6bb5\u7528\u57df\u9002\u5e94\u4f7f\u6a21\u578b\u7279\u5f81\u4e0e\u65b0\u76ee\u6807\u57df\u5bf9\u9f50\u3002", "result": "\u6846\u67b6\u5728\u5e94\u5bf9\u7efc\u5408\u5a01\u80c1\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u8c03\u5236\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u73b0\u4ee3AMC\u7cfb\u7edf\u7684\u90e8\u7f72\u548c\u8fd0\u884c\u6311\u6218\u63d0\u4f9b\u5173\u952e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00230", "pdf": "https://arxiv.org/pdf/2511.00230", "abs": "https://arxiv.org/abs/2511.00230", "authors": ["Sheer Karny", "Anthony Baez", "Pat Pataranutaporn"], "title": "Neural Transparency: Mechanistic Interpretability Interfaces for Anticipating Model Behaviors for Personalized AI", "categories": ["cs.HC", "cs.AI"], "comment": "SK and AB are co-first authors", "summary": "Millions of users now design personalized LLM-based chatbots that shape their\ndaily interactions, yet they can only loosely anticipate how their design\nchoices will manifest as behaviors in deployment. This opacity is\nconsequential: seemingly innocuous prompts can trigger excessive sycophancy,\ntoxicity, or inconsistency, degrading utility and raising safety concerns. To\naddress this issue, we introduce an interface that enables neural transparency\nby exposing language model internals during chatbot design. Our approach\nextracts behavioral trait vectors (empathy, toxicity, sycophancy, etc.) by\ncomputing differences in neural activations between contrastive system prompts\nthat elicit opposing behaviors. We predict chatbot behaviors by projecting the\nsystem prompt's final token activations onto these trait vectors, normalizing\nfor cross-trait comparability, and visualizing results via an interactive\nsunburst diagram. To evaluate this approach, we conducted an online user study\nusing Prolific to compare our neural transparency interface against a baseline\nchatbot interface without any form of transparency. Our analyses suggest that\nusers systematically miscalibrated AI behavior: participants misjudged trait\nactivations for eleven of fifteen analyzable traits, motivating the need for\ntransparency tools in everyday human-AI interaction. While our interface did\nnot change design iteration patterns, it significantly increased user trust and\nwas enthusiastically received. Qualitative analysis indicated that users' had\nnuanced experiences with the visualization that may enrich future work\ndesigning neurally transparent interfaces. This work offers a path for how\nmechanistic interpretability can be operationalized for non-technical users,\nestablishing a foundation for safer, more aligned human-AI interactions.", "AI": {"tldr": "\u4ecb\u7ecd\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u66f4\u900f\u660e\u7684\u754c\u9762\uff0c\u8bc4\u4f30\u663e\u793a\u80fd\u589e\u52a0\u7528\u6237\u4fe1\u4efb\u3002", "motivation": "\u7528\u6237\u96be\u9884\u4f30\u804a\u5929\u673a\u5668\u4eba\u8bbe\u8ba1\u9009\u62e9\u7684\u90e8\u7f72\u884c\u4e3a\uff0c\u5b58\u5728\u4e0d\u900f\u660e\u6027\uff0c\u5f15\u53d1\u6548\u7528\u964d\u4f4e\u548c\u5b89\u5168\u95ee\u9898\u3002", "method": "\u63d0\u53d6\u884c\u4e3a\u7279\u5f81\u5411\u91cf\uff0c\u901a\u8fc7\u6295\u5f71\u9884\u6d4b\u804a\u5929\u884c\u4e3a\uff0c\u7528\u4ea4\u4e92\u5f0f\u65ed\u65e5\u56fe\u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u5e76\u8fdb\u884c\u7528\u6237\u7814\u7a76\u5bf9\u6bd4\u3002", "result": "\u7528\u6237\u5bf9AI\u884c\u4e3a\u6821\u51c6\u6709\u8bef\uff0c\u65b0\u754c\u9762\u672a\u6539\u53d8\u8bbe\u8ba1\u8fed\u4ee3\u6a21\u5f0f\uff0c\u4f46\u589e\u52a0\u7528\u6237\u4fe1\u4efb\u4e14\u53d7\u597d\u8bc4\u3002", "conclusion": "\u4e3a\u975e\u6280\u672f\u7528\u6237\u5c06\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u5e94\u7528\u4e8e\u4eba\u673a\u4ea4\u4e92\u5960\u5b9a\u57fa\u7840\uff0c\u5229\u4e8e\u66f4\u5b89\u5168\u3001\u5951\u5408\u7684\u4eba\u673a\u4ea4\u4e92\u3002"}}
{"id": "2511.01185", "pdf": "https://arxiv.org/pdf/2511.01185", "abs": "https://arxiv.org/abs/2511.01185", "authors": ["Ruyue Zhang", "Xiaopeng Ke", "Ming Liu", "Fangzhou Shi", "Chang Men", "Zhengdan Zhu"], "title": "A Comparative Study of Model Adaptation Strategies for Multi-Treatment Uplift Modeling", "categories": ["cs.LG"], "comment": null, "summary": "Uplift modeling has emerged as a crucial technique for individualized\ntreatment effect estimation, particularly in fields such as marketing and\nhealthcare. Modeling uplift effects in multi-treatment scenarios plays a key\nrole in real-world applications. Current techniques for modeling\nmulti-treatment uplift are typically adapted from binary-treatment works. In\nthis paper, we investigate and categorize all current model adaptations into\ntwo types: Structure Adaptation and Feature Adaptation. Through our empirical\nexperiments, we find that these two adaptation types cannot maintain\neffectiveness under various data characteristics (noisy data, mixed with\nobservational data, etc.). To enhance estimation ability and robustness, we\npropose Orthogonal Function Adaptation (OFA) based on the function\napproximation theorem. We conduct comprehensive experiments with multiple data\ncharacteristics to study the effectiveness and robustness of all model\nadaptation techniques. Our experimental results demonstrate that our proposed\nOFA can significantly improve uplift model performance compared to other\nvanilla adaptation methods and exhibits the highest robustness.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u5904\u7406\u573a\u666f\u4e0b\u7684\u63d0\u5347\u5efa\u6a21\uff0c\u5c06\u73b0\u6709\u6a21\u578b\u9002\u914d\u65b9\u6cd5\u5206\u7c7b\uff0c\u6307\u51fa\u5176\u4e0d\u8db3\uff0c\u63d0\u51fa\u6b63\u4ea4\u51fd\u6570\u9002\u914d\uff08OFA\uff09\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660eOFA\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u5904\u7406\u63d0\u5347\u5efa\u6a21\u6280\u672f\u591a\u6539\u7f16\u81ea\u4e8c\u5143\u5904\u7406\u5de5\u4f5c\uff0c\u73b0\u6709\u6a21\u578b\u9002\u914d\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u7279\u5f81\u4e0b\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u63d0\u5347\u4f30\u8ba1\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5c06\u73b0\u6709\u6a21\u578b\u6539\u7f16\u5206\u4e3a\u7ed3\u6784\u9002\u914d\u548c\u7279\u5f81\u9002\u914d\u4e24\u7c7b\uff0c\u63d0\u51fa\u57fa\u4e8e\u51fd\u6570\u903c\u8fd1\u5b9a\u7406\u7684\u6b63\u4ea4\u51fd\u6570\u9002\u914d\uff08OFA\uff09\u65b9\u6cd5\uff0c\u5e76\u8fdb\u884c\u591a\u6570\u636e\u7279\u5f81\u7684\u7efc\u5408\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684OFA\u76f8\u6bd4\u5176\u4ed6\u666e\u901a\u9002\u914d\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u9ad8\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u5177\u6709\u6700\u9ad8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "OFA\u65b9\u6cd5\u5728\u591a\u5904\u7406\u63d0\u5347\u5efa\u6a21\u4e2d\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u9002\u914d\u65b9\u6cd5\u3002"}}
{"id": "2511.00269", "pdf": "https://arxiv.org/pdf/2511.00269", "abs": "https://arxiv.org/abs/2511.00269", "authors": ["Long Li", "Jiajia Li", "Dong Chen", "Lina Pu", "Haibo Yao", "Yanbo Huang"], "title": "FedReplay: A Feature Replay Assisted Federated Transfer Learning Framework for Efficient and Privacy-Preserving Smart Agriculture", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate classification plays a pivotal role in smart agriculture, enabling\napplications such as crop monitoring, fruit recognition, and pest detection.\nHowever, conventional centralized training often requires large-scale data\ncollection, which raises privacy concerns, while standard federated learning\nstruggles with non-independent and identically distributed (non-IID) data and\nincurs high communication costs. To address these challenges, we propose a\nfederated learning framework that integrates a frozen Contrastive\nLanguage-Image Pre-training (CLIP) vision transformer (ViT) with a lightweight\ntransformer classifier. By leveraging the strong feature extraction capability\nof the pre-trained CLIP ViT, the framework avoids training large-scale models\nfrom scratch and restricts federated updates to a compact classifier, thereby\nreducing transmission overhead significantly. Furthermore, to mitigate\nperformance degradation caused by non-IID data distribution, a small subset\n(1%) of CLIP-extracted feature representations from all classes is shared\nacross clients. These shared features are non-reversible to raw images,\nensuring privacy preservation while aligning class representation across\nparticipants. Experimental results on agricultural classification tasks show\nthat the proposed method achieve 86.6% accuracy, which is more than 4 times\nhigher compared to baseline federated learning approaches. This demonstrates\nthe effectiveness and efficiency of combining vision-language model features\nwith federated learning for privacy-preserving and scalable agricultural\nintelligence.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408CLIP ViT\u548c\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u519c\u4e1a\u5206\u7c7b\uff0c\u53ef\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3001\u4fdd\u62a4\u9690\u79c1\uff0c\u5b9e\u9a8c\u51c6\u786e\u7387\u8fbe86.6%\uff0c\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u6709\u9690\u79c1\u95ee\u9898\uff0c\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u5728\u975eIID\u6570\u636e\u4e0b\u6709\u6027\u80fd\u548c\u901a\u4fe1\u6210\u672c\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u51bb\u7ed3CLIP ViT\u548c\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5171\u4eab1% CLIP\u63d0\u53d6\u7684\u7279\u5f81\u8868\u793a\u3002", "result": "\u5728\u519c\u4e1a\u5206\u7c7b\u4efb\u52a1\u5b9e\u9a8c\u4e2d\u51c6\u786e\u7387\u8fbe86.6%\uff0c\u6bd4\u57fa\u7ebf\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u9ad84\u500d\u591a\u3002", "conclusion": "\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7279\u5f81\u548c\u8054\u90a6\u5b66\u4e60\u7528\u4e8e\u519c\u4e1a\u667a\u80fd\uff0c\u6709\u6548\u3001\u9ad8\u6548\u4e14\u4fdd\u62a4\u9690\u79c1\u3001\u53ef\u6269\u5c55\u3002"}}
{"id": "2511.01198", "pdf": "https://arxiv.org/pdf/2511.01198", "abs": "https://arxiv.org/abs/2511.01198", "authors": ["Tariq Abdul-Quddoos", "Tasnia Sharmin", "Xiangfang Li", "Lijun Qian"], "title": "Transmitter Identification and Protocol Categorization in Shared Spectrum via Multi-Task RF Classification at the Network Edge", "categories": ["cs.LG"], "comment": null, "summary": "As spectrum sharing becomes increasingly vital to meet rising wireless\ndemands in the future, spectrum monitoring and transmitter identification are\nindispensable for enforcing spectrum usage policy, efficient spectrum\nutilization, and net- work security. This study proposed a robust framework for\ntransmitter identification and protocol categorization via multi- task RF\nsignal classification in shared spectrum environments, where the spectrum\nmonitor will classify transmission protocols (e.g., 4G LTE, 5G-NR, IEEE\n802.11a) operating within the same frequency bands, and identify different\ntransmitting base stations, as well as their combinations. A Convolutional\nNeural Network (CNN) is designed to tackle critical challenges such as\noverlapping signal characteristics and environmental variability. The proposed\nmethod employs a multi-channel input strategy to extract meaningful signal\nfeatures, achieving remarkable accuracy: 90% for protocol classification, 100%\nfor transmitting base station classification, and 92% for joint classification\ntasks, utilizing RF data from the POWDER platform. These results highlight the\nsignificant potential of the proposed method to enhance spectrum monitoring,\nmanagement, and security in modern wireless networks.", "AI": {"tldr": "\u63d0\u51fa\u5171\u4eab\u9891\u8c31\u73af\u5883\u4e0b\u901a\u8fc7\u591a\u4efb\u52a1\u5c04\u9891\u4fe1\u53f7\u5206\u7c7b\u8fdb\u884c\u53d1\u5c04\u673a\u8bc6\u522b\u548c\u534f\u8bae\u5206\u7c7b\u7684\u6846\u67b6\uff0c\u7528CNN\u89e3\u51b3\u96be\u9898\uff0c\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\uff0c\u6709\u63d0\u5347\u9891\u8c31\u76d1\u6d4b\u7b49\u6f5c\u529b\u3002", "motivation": "\u9891\u8c31\u5171\u4eab\u5bf9\u6ee1\u8db3\u672a\u6765\u65e0\u7ebf\u9700\u6c42\u81f3\u5173\u91cd\u8981\uff0c\u9891\u8c31\u76d1\u6d4b\u548c\u53d1\u5c04\u673a\u8bc6\u522b\u5bf9\u6267\u884c\u9891\u8c31\u4f7f\u7528\u653f\u7b56\u3001\u9ad8\u6548\u5229\u7528\u9891\u8c31\u548c\u7f51\u7edc\u5b89\u5168\u4e0d\u53ef\u6216\u7f3a\u3002", "method": "\u8bbe\u8ba1\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\uff0c\u91c7\u7528\u591a\u901a\u9053\u8f93\u5165\u7b56\u7565\u63d0\u53d6\u4fe1\u53f7\u7279\u5f81\u3002", "result": "\u534f\u8bae\u5206\u7c7b\u51c6\u786e\u738790%\uff0c\u53d1\u5c04\u57fa\u7ad9\u5206\u7c7b\u51c6\u786e\u7387100%\uff0c\u8054\u5408\u5206\u7c7b\u4efb\u52a1\u51c6\u786e\u738792%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u73b0\u4ee3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5bf9\u63d0\u5347\u9891\u8c31\u76d1\u6d4b\u3001\u7ba1\u7406\u548c\u5b89\u5168\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.00270", "pdf": "https://arxiv.org/pdf/2511.00270", "abs": "https://arxiv.org/abs/2511.00270", "authors": ["Abhinav Joshi", "Vaibhav Sharma", "Sanjeet Singh", "Ashutosh Modi"], "title": "POSESTITCH-SLT: Linguistically Inspired Pose-Stitching for End-to-End Sign Language Translation", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "Accepted at EMNLP 2025 (Main)", "summary": "Sign language translation remains a challenging task due to the scarcity of\nlarge-scale, sentence-aligned datasets. Prior arts have focused on various\nfeature extraction and architectural changes to support neural machine\ntranslation for sign languages. We propose POSESTITCH-SLT, a novel pre-training\nscheme that is inspired by linguistic-templates-based sentence generation\ntechnique. With translation comparison on two sign language datasets, How2Sign\nand iSign, we show that a simple transformer-based encoder-decoder architecture\noutperforms the prior art when considering template-generated sentence pairs in\ntraining. We achieve BLEU-4 score improvements from 1.97 to 4.56 on How2Sign\nand from 0.55 to 3.43 on iSign, surpassing prior state-of-the-art methods for\npose-based gloss-free translation. The results demonstrate the effectiveness of\ntemplate-driven synthetic supervision in low-resource sign language settings.", "AI": {"tldr": "\u63d0\u51faPOSESTITCH - SLT\u9884\u8bad\u7ec3\u65b9\u6848\uff0c\u5728\u4e24\u4e2a\u624b\u8bed\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8bc1\u660e\u6a21\u677f\u9a71\u52a8\u5408\u6210\u76d1\u7763\u5728\u4f4e\u8d44\u6e90\u624b\u8bed\u573a\u666f\u6709\u6548\u3002", "motivation": "\u624b\u8bed\u7ffb\u8bd1\u56e0\u5927\u89c4\u6a21\u53e5\u5b50\u5bf9\u9f50\u6570\u636e\u96c6\u7a00\u7f3a\u4ecd\u662f\u6311\u6218\u6027\u4efb\u52a1\uff0c\u4ee5\u5f80\u7814\u7a76\u805a\u7126\u7279\u5f81\u63d0\u53d6\u548c\u67b6\u6784\u6539\u53d8\u3002", "method": "\u63d0\u51faPOSESTITCH - SLT\u9884\u8bad\u7ec3\u65b9\u6848\uff0c\u57fa\u4e8e\u8bed\u8a00\u5b66\u6a21\u677f\u7684\u53e5\u5b50\u751f\u6210\u6280\u672f\uff0c\u91c7\u7528\u7b80\u5355\u7684\u57fa\u4e8eTransformer\u7684\u7f16\u89e3\u7801\u5668\u67b6\u6784\uff0c\u4f7f\u7528\u6a21\u677f\u751f\u6210\u7684\u53e5\u5b50\u5bf9\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728How2Sign\u6570\u636e\u96c6\u4e0aBLEU - 4\u5206\u6570\u4ece1.97\u63d0\u5347\u52304.56\uff0c\u5728iSign\u6570\u636e\u96c6\u4e0a\u4ece0.55\u63d0\u5347\u52303.43\uff0c\u8d85\u8d8a\u57fa\u4e8e\u59ff\u52bf\u7684\u65e0\u6ce8\u89e3\u7ffb\u8bd1\u7684\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "conclusion": "\u6a21\u677f\u9a71\u52a8\u7684\u5408\u6210\u76d1\u7763\u5728\u4f4e\u8d44\u6e90\u624b\u8bed\u573a\u666f\u4e2d\u6709\u6548\u3002"}}
{"id": "2511.01203", "pdf": "https://arxiv.org/pdf/2511.01203", "abs": "https://arxiv.org/abs/2511.01203", "authors": ["Pavel Rumiantsev", "Soumyasundar Pal", "Yingxue Zhang", "Mark Coates"], "title": "FEval-TTC: Fair Evaluation Protocol for Test-Time Compute", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The performance of Large Language Models (LLMs) and the associated dollar\ncosts of API calls can fluctuate over time, potentially invalidating\nconclusions drawn in prior research. To address this, we propose a Fair\nEvaluation protocol for Test-Time Compute (FEval-TTC), designed to ensure\nconsistent assessment of test-time compute (TTC) methods, regardless of such\nfluctuations. FEval-TTC focuses on the evaluation of TTC methods that utilize\nunderlying Chains-of-Thought (CoT). It supports evaluations across multiple\nLLMs on a diverse set of mathematical and commonsense reasoning datasets. The\nfew-shot prompting and answer extraction processes are standardized across\ndatasets, reducing both time and monetary overhead for researchers.\nFurthermore, we provide a cost modelling procedure that estimates both the\ntoken and dollar cost per query, facilitating equitable comparisons of\nprevalent TTC methods. We open-source FEval-TTC for public use at\nhttps://github.com/networkslab/feval_ttc .", "AI": {"tldr": "\u63d0\u51faFEval - TTC\u534f\u8bae\u8bc4\u4f30\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u6a21\u578b\u548c\u591a\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u548cAPI\u8c03\u7528\u6210\u672c\u968f\u65f6\u95f4\u6ce2\u52a8\uff0c\u53ef\u80fd\u4f7f\u5148\u524d\u7814\u7a76\u7ed3\u8bba\u5931\u6548\uff0c\u9700\u4e00\u81f4\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFEval - TTC\u534f\u8bae\uff0c\u6807\u51c6\u5316\u5c11\u6837\u672c\u63d0\u793a\u548c\u7b54\u6848\u63d0\u53d6\u8fc7\u7a0b\uff0c\u7ed9\u51fa\u6210\u672c\u5efa\u6a21\u7a0b\u5e8f\u3002", "result": "\u53ef\u5728\u591a\u6570\u636e\u96c6\u4e0a\u5bf9\u591a\u6a21\u578b\u8bc4\u4f30TTC\u65b9\u6cd5\uff0c\u6807\u51c6\u5316\u6d41\u7a0b\u51cf\u5c11\u65f6\u95f4\u548c\u91d1\u94b1\u5f00\u9500\uff0c\u80fd\u4f30\u7b97\u6210\u672c\u3002", "conclusion": "FEval - TTC\u53ef\u5b9e\u73b0\u5bf9TTC\u65b9\u6cd5\u7684\u4e00\u81f4\u8bc4\u4f30\uff0c\u5df2\u5f00\u6e90\u4f9b\u516c\u4f17\u4f7f\u7528\u3002"}}
{"id": "2511.01218", "pdf": "https://arxiv.org/pdf/2511.01218", "abs": "https://arxiv.org/abs/2511.01218", "authors": ["Minh-Duc Nguyen", "Dung D. Le", "Phi Long Nguyen"], "title": "Optimizing Electric Vehicle Charging Station Placement Using Reinforcement Learning and Agent-Based Simulations", "categories": ["cs.LG"], "comment": "Under Review", "summary": "The rapid growth of electric vehicles (EVs) necessitates the strategic\nplacement of charging stations to optimize resource utilization and minimize\nuser inconvenience. Reinforcement learning (RL) offers an innovative approach\nto identifying optimal charging station locations; however, existing methods\nface challenges due to their deterministic reward systems, which limit\nefficiency. Because real-world conditions are dynamic and uncertain, a\ndeterministic reward structure cannot fully capture the complexities of\ncharging station placement. As a result, evaluation becomes costly and\ntime-consuming, and less reflective of real-world scenarios. To address this\nchallenge, we propose a novel framework that integrates deep RL with\nagent-based simulations to model EV movement and estimate charging demand in\nreal time. Our approach employs a hybrid RL agent with dual Q-networks to\nselect optimal locations and configure charging ports, guided by a hybrid\nreward function that combines deterministic factors with simulation-derived\nfeedback. Case studies in Hanoi, Vietnam, show that our method reduces average\nwaiting times by 53.28% compared to the initial state, outperforming static\nbaseline methods. This scalable and adaptive solution enhances EV\ninfrastructure planning, effectively addressing real-world complexities and\nimproving user experience.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u96c6\u6210\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0e\u57fa\u4e8e\u4ee3\u7406\u6a21\u62df\u7684\u6846\u67b6\u89e3\u51b3\u5145\u7535\u7ad9\u9009\u5740\u95ee\u9898\uff0c\u6848\u4f8b\u663e\u793a\u53ef\u51cf\u5c11\u5e73\u5747\u7b49\u5f85\u65f6\u95f4\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u5feb\u901f\u589e\u957f\uff0c\u9700\u6218\u7565\u5e03\u5c40\u5145\u7535\u7ad9\uff0c\u4f46\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u56e0\u786e\u5b9a\u6027\u5956\u52b1\u7cfb\u7edf\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u65e0\u6cd5\u53cd\u6620\u73b0\u5b9e\u573a\u666f\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e0e\u57fa\u4e8e\u4ee3\u7406\u6a21\u62df\u7684\u6846\u67b6\uff0c\u91c7\u7528\u5e26\u53ccQ\u7f51\u7edc\u7684\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u7ed3\u5408\u786e\u5b9a\u6027\u56e0\u7d20\u4e0e\u6a21\u62df\u53cd\u9988\u7684\u6df7\u5408\u5956\u52b1\u51fd\u6570\u6765\u9009\u5740\u548c\u914d\u7f6e\u5145\u7535\u7aef\u53e3\u3002", "result": "\u5728\u8d8a\u5357\u6cb3\u5185\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8f83\u521d\u59cb\u72b6\u6001\u5e73\u5747\u7b49\u5f85\u65f6\u95f4\u51cf\u5c1153.28%\uff0c\u4f18\u4e8e\u9759\u6001\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u80fd\u589e\u5f3a\u7535\u52a8\u6c7d\u8f66\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\uff0c\u6709\u6548\u5e94\u5bf9\u73b0\u5b9e\u590d\u6742\u6027\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2511.01226", "pdf": "https://arxiv.org/pdf/2511.01226", "abs": "https://arxiv.org/abs/2511.01226", "authors": ["Themistoklis Vargiemezis", "Charilaos Kanatsoulis", "Catherine Gorl\u00e9"], "title": "WindMiL: Equivariant Graph Learning for Wind Loading Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Accurate prediction of wind loading on buildings is crucial for structural\nsafety and sustainable design, yet conventional approaches such as wind tunnel\ntesting and large-eddy simulation (LES) are prohibitively expensive for\nlarge-scale exploration. Each LES case typically requires at least 24 hours of\ncomputation, making comprehensive parametric studies infeasible. We introduce\nWindMiL, a new machine learning framework that combines systematic dataset\ngeneration with symmetry-aware graph neural networks (GNNs). First, we\nintroduce a large-scale dataset of wind loads on low-rise buildings by applying\nsigned distance function interpolation to roof geometries and simulating 462\ncases with LES across varying shapes and wind directions. Second, we develop a\nreflection-equivariant GNN that guarantees physically consistent predictions\nunder mirrored geometries. Across interpolation and extrapolation evaluations,\nWindMiL achieves high accuracy for both the mean and the standard deviation of\nsurface pressure coefficients (e.g., RMSE $\\leq 0.02$ for mean $C_p$) and\nremains accurate under reflected-test evaluation, maintaining hit rates above\n$96\\%$ where the non-equivariant baseline model drops by more than $10\\%$. By\npairing a systematic dataset with an equivariant surrogate, WindMiL enables\nefficient, scalable, and accurate predictions of wind loads on buildings.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u673a\u5668\u5b66\u4e60\u6846\u67b6WindMiL\uff0c\u7ed3\u5408\u7cfb\u7edf\u6570\u636e\u96c6\u751f\u6210\u4e0e\u5bf9\u79f0\u611f\u77e5\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u80fd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u9884\u6d4b\u5efa\u7b51\u98ce\u8377\u8f7d\u3002", "motivation": "\u4f20\u7edf\u98ce\u8377\u8f7d\u9884\u6d4b\u65b9\u6cd5\u5982wind tunnel testing\u548cLES\u6210\u672c\u9ad8\u3001\u8ba1\u7b97\u65f6\u95f4\u957f\uff0c\u96be\u4ee5\u8fdb\u884c\u5927\u89c4\u6a21\u63a2\u7d22\u548c\u53c2\u6570\u7814\u7a76\u3002", "method": "\u5148\u901a\u8fc7\u6709\u7b26\u53f7\u8ddd\u79bb\u51fd\u6570\u63d2\u503c\u751f\u6210\u4f4e\u5c42\u5efa\u7b51\u98ce\u8377\u8f7d\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u518d\u5f00\u53d1\u53cd\u5c04\u7b49\u53d8\u56fe\u795e\u7ecf\u7f51\u7edc\u3002", "result": "WindMiL\u5728\u63d2\u503c\u548c\u5916\u63a8\u8bc4\u4f30\u4e2d\u5bf9\u8868\u9762\u538b\u529b\u7cfb\u6570\u5747\u503c\u548c\u6807\u51c6\u5dee\u9884\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u53cd\u5c04\u6d4b\u8bd5\u8bc4\u4f30\u4e2d\u51c6\u786e\u7387\u8d8596%\uff0c\u975e\u7b49\u53d8\u57fa\u7ebf\u6a21\u578b\u4e0b\u964d\u8d8510%\u3002", "conclusion": "WindMiL\u901a\u8fc7\u7cfb\u7edf\u6570\u636e\u96c6\u548c\u7b49\u53d8\u66ff\u4ee3\u6a21\u578b\uff0c\u53ef\u5b9e\u73b0\u5bf9\u5efa\u7b51\u98ce\u8377\u8f7d\u7684\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u9884\u6d4b\u3002"}}
{"id": "2511.00315", "pdf": "https://arxiv.org/pdf/2511.00315", "abs": "https://arxiv.org/abs/2511.00315", "authors": ["Lee Xiong", "Maksim Tkachenko", "Johanes Effendi", "Ting Cai"], "title": "Language Modeling With Factorization Memory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We propose Factorization Memory, an efficient recurrent neural network (RNN)\narchitecture that achieves performance comparable to Transformer models on\nshort-context language modeling tasks while also demonstrating superior\ngeneralization in long-context scenarios. Our model builds upon Mamba-2,\nenabling Factorization Memory to exploit parallel computations during training\nwhile preserving constant computational and memory complexity during inference.\nTo further optimize model efficiency and representational capacity, we develop\na sparse formulation of Factorization Memory that updates only a subset of\nrecurrent states at each step while preserving the strong performance of its\ndense counterpart. To our knowledge, this represents the first RNN architecture\nthat successfully combines sparse memory activation with competitive\nperformance across both short and long-context settings. This work provides a\nsystematic empirical analysis of Factorization Memory in comparison to\nTransformer and Mamba-2 architectures.", "AI": {"tldr": "\u63d0\u51faFactorization Memory\uff0c\u5728\u77ed\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0eTransformer\u76f8\u5f53\uff0c\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u6cdb\u5316\u80fd\u529b\u66f4\u4f18\uff0c\u8fd8\u5f00\u53d1\u4e86\u7a00\u758f\u7248\u672c\u3002", "motivation": "\u6784\u5efa\u4e00\u79cd\u9ad8\u6548\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u77ed\u4e0a\u4e0b\u6587\u4efb\u52a1\u6709\u4e0eTransformer\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u6709\u66f4\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4f18\u5316\u6a21\u578b\u6548\u7387\u548c\u8868\u793a\u80fd\u529b\u3002", "method": "\u57fa\u4e8eMamba - 2\u6784\u5efaFactorization Memory\uff0c\u5f00\u53d1\u5176\u7a00\u758f\u516c\u5f0f\uff0c\u66f4\u65b0\u90e8\u5206\u5faa\u73af\u72b6\u6001\uff1b\u5bf9Factorization Memory\u4e0eTransformer\u548cMamba - 2\u67b6\u6784\u8fdb\u884c\u7cfb\u7edf\u5b9e\u8bc1\u5206\u6790\u3002", "result": "Factorization Memory\u5728\u77ed\u4e0a\u4e0b\u6587\u4efb\u52a1\u6027\u80fd\u4e0eTransformer\u76f8\u5f53\uff0c\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u6cdb\u5316\u80fd\u529b\u66f4\u597d\uff1b\u7a00\u758f\u7248\u672c\u4fdd\u7559\u4e86\u5bc6\u96c6\u7248\u672c\u7684\u5f3a\u6027\u80fd\u3002", "conclusion": "Factorization Memory\u662f\u9996\u4e2a\u6210\u529f\u5c06\u7a00\u758f\u5185\u5b58\u6fc0\u6d3b\u4e0e\u77ed\u957f\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e0b\u7684\u7ade\u4e89\u6027\u80fd\u76f8\u7ed3\u5408\u7684RNN\u67b6\u6784\u3002"}}
{"id": "2511.01249", "pdf": "https://arxiv.org/pdf/2511.01249", "abs": "https://arxiv.org/abs/2511.01249", "authors": ["Kun-Wei Lin", "Yu-Chen Kuo", "Hsin-Yao Wang", "Yi-Ju Tseng"], "title": "KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records", "categories": ["cs.LG"], "comment": "10 pages, 3 figures", "summary": "Clinical risk prediction using electronic health records (EHRs) is vital to\nfacilitate timely interventions and clinical decision support. However,\nmodeling heterogeneous and irregular temporal EHR data presents significant\nchallenges. We propose \\textbf{KAT-GNN} (Knowledge-Augmented Temporal Graph\nNeural Network), a graph-based framework that integrates clinical knowledge and\ntemporal dynamics for risk prediction. KAT-GNN first constructs\nmodality-specific patient graphs from EHRs. These graphs are then augmented\nusing two knowledge sources: (1) ontology-driven edges derived from SNOMED CT\nand (2) co-occurrence priors extracted from EHRs. Subsequently, a time-aware\ntransformer is employed to capture longitudinal dynamics from the graph-encoded\npatient representations. KAT-GNN is evaluated on three distinct datasets and\ntasks: coronary artery disease (CAD) prediction using the Chang Gung Research\nDatabase (CGRD) and in-hospital mortality prediction using the MIMIC-III and\nMIMIC-IV datasets. KAT-GNN achieves state-of-the-art performance in CAD\nprediction (AUROC: 0.9269 $\\pm$ 0.0029) and demonstrated strong results in\nmortality prediction in MIMIC-III (AUROC: 0.9230 $\\pm$ 0.0070) and MIMIC-IV\n(AUROC: 0.8849 $\\pm$ 0.0089), consistently outperforming established baselines\nsuch as GRASP and RETAIN. Ablation studies confirm that both knowledge-based\naugmentation and the temporal modeling component are significant contributors\nto performance gains. These findings demonstrate that the integration of\nclinical knowledge into graph representations, coupled with a time-aware\nattention mechanism, provides an effective and generalizable approach for risk\nprediction across diverse clinical tasks and datasets.", "AI": {"tldr": "\u63d0\u51faKAT - GNN\u6846\u67b6\u7528\u4e8e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u98ce\u9669\u9884\u6d4b\uff0c\u5728\u591a\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u7ed3\u5408\u4e34\u5e8a\u77e5\u8bc6\u548c\u65f6\u95f4\u611f\u77e5\u673a\u5236\u6709\u6548\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e34\u5e8a\u98ce\u9669\u9884\u6d4b\u91cd\u8981\uff0c\u4f46\u5efa\u6a21\u5f02\u6784\u548c\u4e0d\u89c4\u5219\u65f6\u95f4\u6570\u636e\u6709\u6311\u6218\u3002", "method": "\u6784\u5efaKAT - GNN\u6846\u67b6\uff0c\u4eceEHR\u6784\u5efa\u7279\u5b9a\u6a21\u6001\u60a3\u8005\u56fe\uff0c\u7528SNOMED CT\u548cEHR\u5171\u73b0\u5148\u9a8c\u589e\u5f3a\uff0c\u7528\u65f6\u95f4\u611f\u77e5Transformer\u6355\u6349\u7eb5\u5411\u52a8\u6001\u3002", "result": "\u5728CAD\u9884\u6d4b\u548c\u4f4f\u9662\u6b7b\u4ea1\u7387\u9884\u6d4b\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u6301\u7eed\u8d85\u8d8aGRASP\u548cRETAIN\u7b49\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u5c06\u4e34\u5e8a\u77e5\u8bc6\u878d\u5165\u56fe\u8868\u793a\u5e76\u7ed3\u5408\u65f6\u95f4\u611f\u77e5\u6ce8\u610f\u529b\u673a\u5236\uff0c\u662f\u8de8\u4e34\u5e8a\u4efb\u52a1\u548c\u6570\u636e\u96c6\u8fdb\u884c\u98ce\u9669\u9884\u6d4b\u7684\u6709\u6548\u4e14\u901a\u7528\u65b9\u6cd5\u3002"}}
{"id": "2511.00321", "pdf": "https://arxiv.org/pdf/2511.00321", "abs": "https://arxiv.org/abs/2511.00321", "authors": ["Dowon Kim", "MinJae Lee", "Janghyeon Kim", "HyuckSung Kwon", "Hyeonggyu Jeong", "Sang-Soo Park", "Minyong Yoon", "Si-Dong Roh", "Yongsuk Kwon", "Jinin So", "Jungwook Choi"], "title": "Scalable Processing-Near-Memory for 1M-Token LLM Inference: CXL-Enabled KV-Cache Management Beyond GPU Limits", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "The expansion of context windows in large language models (LLMs) to\nmulti-million tokens introduces severe memory and compute bottlenecks,\nparticularly in managing the growing Key-Value (KV) cache. While Compute\nExpress Link (CXL) enables non-eviction frameworks that offload the full\nKV-cache to scalable external memory, these frameworks still suffer from costly\ndata transfers when recalling non-resident KV tokens to limited GPU memory as\ncontext lengths increase. This work proposes scalable Processing-Near-Memory\n(PNM) for 1M-Token LLM Inference, a CXL-enabled KV-cache management system that\ncoordinates memory and computation beyond GPU limits. Our design offloads token\npage selection to a PNM accelerator within CXL memory, eliminating costly\nrecalls and enabling larger GPU batch sizes. We further introduce a hybrid\nparallelization strategy and a steady-token selection mechanism to enhance\ncompute efficiency and scalability. Implemented atop a state-of-the-art CXL-PNM\nsystem, our solution delivers consistent performance gains for LLMs with up to\n405B parameters and 1M-token contexts. Our PNM-only offloading scheme (PNM-KV)\nand GPU-PNM hybrid with steady-token execution (PnG-KV) achieve up to 21.9x\nthroughput improvement, up to 60x lower energy per token, and up to 7.3x better\ntotal cost efficiency than the baseline, demonstrating that CXL-enabled\nmulti-PNM architectures can serve as a scalable backbone for future\nlong-context LLM inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e100\u4e07\u4ee4\u724c\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u53ef\u6269\u5c55\u8fd1\u5185\u5b58\u5904\u7406\uff08PNM\uff09\u7cfb\u7edf\uff0c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u6269\u5c55\u5e26\u6765\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u74f6\u9888\uff0c\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u6269\u5c55\u5230\u6570\u767e\u4e07\u4ee4\u724c\u65f6\uff0c\u5728\u7ba1\u7406\u4e0d\u65ad\u589e\u957f\u7684\u952e\u503c\uff08KV\uff09\u7f13\u5b58\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u74f6\u9888\uff0c\u73b0\u6709\u975e\u9010\u51fa\u6846\u67b6\u6570\u636e\u4f20\u8f93\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u7684PNM\u7cfb\u7edf\uff0c\u5c06\u4ee4\u724c\u9875\u9762\u9009\u62e9\u5378\u8f7d\u5230CXL\u5185\u5b58\u4e2d\u7684PNM\u52a0\u901f\u5668\uff0c\u5f15\u5165\u6df7\u5408\u5e76\u884c\u7b56\u7565\u548c\u7a33\u5b9a\u4ee4\u724c\u9009\u62e9\u673a\u5236\u3002", "result": "\u8be5\u89e3\u51b3\u65b9\u6848\u5728\u53c2\u6570\u9ad8\u8fbe405B\u3001\u4e0a\u4e0b\u6587\u4e3a100\u4e07\u4ee4\u724c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0cPNM - KV\u548cPnG - KV\u65b9\u6848\u5728\u541e\u5410\u91cf\u3001\u6bcf\u4ee4\u724c\u80fd\u8017\u548c\u603b\u6210\u672c\u6548\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u652f\u6301CXL\u7684\u591aPNM\u67b6\u6784\u53ef\u4f5c\u4e3a\u672a\u6765\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u53ef\u6269\u5c55\u9aa8\u5e72\u3002"}}
{"id": "2511.00328", "pdf": "https://arxiv.org/pdf/2511.00328", "abs": "https://arxiv.org/abs/2511.00328", "authors": ["Isai Daniel Chac\u00f3n", "Paola Ruiz Puentes", "Jillian Pearse", "Pablo Arbel\u00e1ez"], "title": "Towards Automated Petrography", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Petrography is a branch of geology that analyzes the mineralogical\ncomposition of rocks from microscopical thin section samples. It is essential\nfor understanding rock properties across geology, archaeology, engineering,\nmineral exploration, and the oil industry. However, petrography is a\nlabor-intensive task requiring experts to conduct detailed visual examinations\nof thin section samples through optical polarization microscopes, thus\nhampering scalability and highlighting the need for automated techniques. To\naddress this challenge, we introduce the Large-scale Imaging and Thin section\nOptical-polarization Set (LITHOS), the largest and most diverse publicly\navailable experimental framework for automated petrography. LITHOS includes\n211,604 high-resolution RGB patches of polarized light and 105,802\nexpert-annotated grains across 25 mineral categories. Each annotation consists\nof the mineral class, spatial coordinates, and expert-defined major and minor\naxes represented as intersecting vector paths, capturing grain geometry and\norientation. We evaluate multiple deep learning techniques for mineral\nclassification in LITHOS and propose a dual-encoder transformer architecture\nthat integrates both polarization modalities as a strong baseline for future\nreference. Our method consistently outperforms single-polarization models,\ndemonstrating the value of polarization synergy in mineral classification. We\nhave made the LITHOS Benchmark publicly available, comprising our dataset,\ncode, and pretrained models, to foster reproducibility and further research in\nautomated petrographic analysis.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u81ea\u52a8\u5ca9\u76f8\u5b66\u7684LITHOS\u6846\u67b6\uff0c\u8bc4\u4f30\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u63d0\u51fa\u53cc\u7f16\u7801\u5668\u53d8\u538b\u5668\u67b6\u6784\uff0c\u8bc1\u660e\u504f\u632f\u534f\u540c\u4ef7\u503c\u5e76\u516c\u5f00\u57fa\u51c6\u3002", "motivation": "\u4f20\u7edf\u5ca9\u76f8\u5b66\u52b3\u52a8\u5bc6\u96c6\uff0c\u9700\u81ea\u52a8\u5316\u6280\u672f\u3002", "method": "\u5f15\u5165LITHOS\u6846\u67b6\uff0c\u8bc4\u4f30\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u63d0\u51fa\u53cc\u7f16\u7801\u5668\u53d8\u538b\u5668\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u5355\u504f\u632f\u6a21\u578b\u3002", "conclusion": "\u516c\u5f00LITHOS\u57fa\u51c6\uff0c\u4fc3\u8fdb\u81ea\u52a8\u5ca9\u76f8\u5206\u6790\u7814\u7a76\u3002"}}
{"id": "2511.01275", "pdf": "https://arxiv.org/pdf/2511.01275", "abs": "https://arxiv.org/abs/2511.01275", "authors": ["Zan Li", "Kyongmin Yeo", "Wesley Gifford", "Lara Marcuse", "Madeline Fields", "B\u00fclent Yener"], "title": "Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Forecasting epileptic seizures from multivariate EEG signals represents a\ncritical challenge in healthcare time series prediction, requiring high\nsensitivity, low false alarm rates, and subject-specific adaptability. We\npresent STAN, an Adversarial Spatio-Temporal Attention Network that jointly\nmodels spatial brain connectivity and temporal neural dynamics through cascaded\nattention blocks with alternating spatial and temporal modules. Unlike existing\napproaches that assume fixed preictal durations or separately process spatial\nand temporal features, STAN captures bidirectional dependencies between spatial\nand temporal patterns through a unified cascaded architecture. Adversarial\ntraining with gradient penalty enables robust discrimination between interictal\nand preictal states learned from clearly defined 15-minute preictal windows.\nContinuous 90-minute pre-seizure monitoring reveals that the learned\nspatio-temporal attention patterns enable early detection: reliable alarms\ntrigger at subject-specific times (typically 15-45 minutes before onset),\nreflecting the model's capacity to capture subtle preictal dynamics without\nrequiring individualized training. Experiments on two benchmark EEG datasets\n(CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14\nevents) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011\nfalse detections per hour and 94.2% sensitivity with 0.063 false detections per\nhour, respectively, while maintaining computational efficiency (2.3M\nparameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond\nepilepsy, the proposed framework provides a general paradigm for\nspatio-temporal forecasting in healthcare and other time series domains where\nindividual heterogeneity and interpretability are crucial.", "AI": {"tldr": "\u63d0\u51faSTAN\u7f51\u7edc\u7528\u4e8e\u4ece\u591a\u53d8\u91cfEEG\u4fe1\u53f7\u9884\u6d4b\u766b\u75eb\u53d1\u4f5c\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbeSOTA\u6027\u80fd\uff0c\u4e14\u9002\u7528\u4e8e\u5176\u4ed6\u65f6\u7a7a\u9884\u6d4b\u573a\u666f\u3002", "motivation": "\u766b\u75eb\u53d1\u4f5c\u9884\u6d4b\u5728\u533b\u7597\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u662f\u5173\u952e\u6311\u6218\uff0c\u9700\u9ad8\u7075\u654f\u5ea6\u3001\u4f4e\u8bef\u62a5\u7387\u548c\u7279\u5b9a\u4e3b\u4f53\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51faSTAN\uff0c\u901a\u8fc7\u7ea7\u8054\u6ce8\u610f\u529b\u5757\u8054\u5408\u5efa\u6a21\u7a7a\u95f4\u5927\u8111\u8fde\u63a5\u548c\u65f6\u95f4\u795e\u7ecf\u52a8\u529b\u5b66\uff0c\u91c7\u7528\u5e26\u68af\u5ea6\u60e9\u7f5a\u7684\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6EEG\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5b9e\u73b096.6%\u7075\u654f\u5ea6\uff08\u6bcf\u5c0f\u65f60.011\u6b21\u8bef\u68c0\uff09\u548c94.2%\u7075\u654f\u5ea6\uff08\u6bcf\u5c0f\u65f60.063\u6b21\u8bef\u68c0\uff09\uff0c\u8ba1\u7b97\u9ad8\u6548\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u533b\u7597\u548c\u5176\u4ed6\u65f6\u95f4\u5e8f\u5217\u9886\u57df\u7684\u65f6\u7a7a\u9884\u6d4b\u63d0\u4f9b\u901a\u7528\u8303\u5f0f\u3002"}}
{"id": "2511.01277", "pdf": "https://arxiv.org/pdf/2511.01277", "abs": "https://arxiv.org/abs/2511.01277", "authors": ["Annabelle Martin", "Daphne Kontogiorgos-Heintz", "Jeff Nivala"], "title": "Identification of Capture Phases in Nanopore Protein Sequencing Data Using a Deep Learning Model", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Nanopore protein sequencing produces long, noisy ionic current traces in\nwhich key molecular phases, such as protein capture and translocation, are\nembedded. Capture phases mark the successful entry of a protein into the pore\nand serve as both a checkpoint and a signal that a channel merits further\nanalysis. However, manual identification of capture phases is time-intensive,\noften requiring several days for expert reviewers to annotate the data due to\nthe need for domain-specific interpretation of complex signal patterns. To\naddress this, a lightweight one-dimensional convolutional neural network (1D\nCNN) was developed and trained to detect capture phases in down-sampled signal\nwindows. Evaluated against CNN-LSTM (Long Short-Term Memory) hybrids,\nhistogram-based classifiers, and other CNN variants using run-level data\nsplits, our best model, CaptureNet-Deep, achieved an F1 score of 0.94 and\nprecision of 93.39% on held-out test data. The model supports low-latency\ninference and is integrated into a dashboard for Oxford Nanopore experiments,\nreducing the total analysis time from several days to under thirty minutes.\nThese results show that efficient, real-time capture detection is possible\nusing simple, interpretable architectures and suggest a broader role for\nlightweight ML models in sequencing workflows.", "AI": {"tldr": "\u5f00\u53d1\u8f7b\u91cf\u7ea71D CNN\u6a21\u578bCaptureNet - Deep\u68c0\u6d4b\u7eb3\u7c73\u5b54\u86cb\u767d\u6d4b\u5e8f\u6355\u83b7\u9636\u6bb5\uff0c\u8868\u73b0\u4f18\u5f02\uff0c\u5927\u5e45\u7f29\u77ed\u5206\u6790\u65f6\u95f4\u3002", "motivation": "\u624b\u52a8\u8bc6\u522b\u7eb3\u7c73\u5b54\u86cb\u767d\u6d4b\u5e8f\u7684\u6355\u83b7\u9636\u6bb5\u8017\u65f6\u4e45\uff0c\u9700\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u89e3\u8bfb\u590d\u6742\u4fe1\u53f7\u6a21\u5f0f\u3002", "method": "\u5f00\u53d1\u5e76\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff081D CNN\uff09\uff0c\u5728\u964d\u91c7\u6837\u4fe1\u53f7\u7a97\u53e3\u4e2d\u68c0\u6d4b\u6355\u83b7\u9636\u6bb5\uff0c\u4e0eCNN - LSTM\u6df7\u5408\u6a21\u578b\u3001\u57fa\u4e8e\u76f4\u65b9\u56fe\u7684\u5206\u7c7b\u5668\u7b49\u5bf9\u6bd4\u3002", "result": "\u6700\u4f73\u6a21\u578bCaptureNet - Deep\u5728\u6d4b\u8bd5\u6570\u636e\u4e0aF1\u5206\u6570\u8fbe0.94\uff0c\u7cbe\u5ea693.39%\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u63a8\u7406\uff0c\u96c6\u6210\u5230\u5b9e\u9a8c\u4eea\u8868\u76d8\u540e\u5c06\u5206\u6790\u65f6\u95f4\u4ece\u6570\u5929\u51cf\u81f3\u4e0d\u523030\u5206\u949f\u3002", "conclusion": "\u4f7f\u7528\u7b80\u5355\u53ef\u89e3\u91ca\u67b6\u6784\u53ef\u5b9e\u73b0\u9ad8\u6548\u5b9e\u65f6\u6355\u83b7\u68c0\u6d4b\uff0c\u8f7b\u91cf\u7ea7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6d4b\u5e8f\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u6709\u66f4\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2511.00346", "pdf": "https://arxiv.org/pdf/2511.00346", "abs": "https://arxiv.org/abs/2511.00346", "authors": ["Kayua Oleques Paim", "Rodrigo Brandao Mansilha", "Diego Kreutz", "Muriel Figueredo Franco", "Weverton Cordeiro"], "title": "Exploiting Latent Space Discontinuities for Building Universal LLM Jailbreaks and Data Extraction Attacks", "categories": ["cs.CR", "cs.AI", "cs.LG", "68T01", "I.2"], "comment": "10 pages, 5 figures, 4 tables, Published at the Brazilian Symposium\n  on Cybersecurity (SBSeg 2025)", "summary": "The rapid proliferation of Large Language Models (LLMs) has raised\nsignificant concerns about their security against adversarial attacks. In this\nwork, we propose a novel approach to crafting universal jailbreaks and data\nextraction attacks by exploiting latent space discontinuities, an architectural\nvulnerability related to the sparsity of training data. Unlike previous\nmethods, our technique generalizes across various models and interfaces,\nproving highly effective in seven state-of-the-art LLMs and one image\ngeneration model. Initial results indicate that when these discontinuities are\nexploited, they can consistently and profoundly compromise model behavior, even\nin the presence of layered defenses. The findings suggest that this strategy\nhas substantial potential as a systemic attack vector.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u4e0d\u8fde\u7eed\u6027\u8fdb\u884c\u901a\u7528\u8d8a\u72f1\u548c\u6570\u636e\u63d0\u53d6\u653b\u51fb\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u4e2d\u6709\u6548\uff0c\u663e\u793a\u51fa\u4f5c\u4e3a\u7cfb\u7edf\u6027\u653b\u51fb\u5411\u91cf\u7684\u6f5c\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u6027\u5f15\u53d1\u5173\u6ce8\uff0c\u9700\u7814\u7a76\u65b0\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u4e0e\u8bad\u7ec3\u6570\u636e\u7a00\u758f\u6027\u76f8\u5173\u7684\u6f5c\u5728\u7a7a\u95f4\u4e0d\u8fde\u7eed\u6027\u8fd9\u4e00\u67b6\u6784\u6f0f\u6d1e\uff0c\u63d0\u51fa\u65b0\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e03\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e00\u4e2a\u56fe\u50cf\u751f\u6210\u6a21\u578b\u4e2d\u9ad8\u5ea6\u6709\u6548\uff0c\u5373\u4f7f\u5b58\u5728\u5206\u5c42\u9632\u5fa1\uff0c\u4e5f\u80fd\u6301\u7eed\u4e14\u6df1\u523b\u5730\u635f\u5bb3\u6a21\u578b\u884c\u4e3a\u3002", "conclusion": "\u6b64\u7b56\u7565\u4f5c\u4e3a\u7cfb\u7edf\u6027\u653b\u51fb\u5411\u91cf\u5177\u6709\u5f88\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.01283", "pdf": "https://arxiv.org/pdf/2511.01283", "abs": "https://arxiv.org/abs/2511.01283", "authors": ["Yupu Lu", "Shijie Lin", "Hao Xu", "Zeqing Zhang", "Jia Pan"], "title": "Lyapunov Stability Learning with Nonlinear Control via Inductive Biases", "categories": ["cs.LG", "cs.RO"], "comment": "Accepted by IEEE Robio 2025", "summary": "Finding a control Lyapunov function (CLF) in a dynamical system with a\ncontroller is an effective way to guarantee stability, which is a crucial issue\nin safety-concerned applications. Recently, deep learning models representing\nCLFs have been applied into a learner-verifier framework to identify\nsatisfiable candidates. However, the learner treats Lyapunov conditions as\ncomplex constraints for optimisation, which is hard to achieve global\nconvergence. It is also too complicated to implement these Lyapunov conditions\nfor verification. To improve this framework, we treat Lyapunov conditions as\ninductive biases and design a neural CLF and a CLF-based controller guided by\nthis knowledge. This design enables a stable optimisation process with limited\nconstraints, and allows end-to-end learning of both the CLF and the controller.\nOur approach achieves a higher convergence rate and larger region of attraction\n(ROA) in learning the CLF compared to existing methods among abundant\nexperiment cases. We also thoroughly reveal why the success rate decreases with\nprevious methods during learning.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u73b0\u6709\u5b66\u4e60\u9a8c\u8bc1\u6846\u67b6\u5728\u5bfb\u627e\u63a7\u5236\u674e\u96c5\u666e\u8bfa\u592b\u51fd\u6570\uff08CLF\uff09\u65f6\u7684\u4e0d\u8db3\uff0c\u5c06\u674e\u96c5\u666e\u8bfa\u592b\u6761\u4ef6\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\u8bbe\u8ba1\u795e\u7ecfCLF\u548c\u57fa\u4e8eCLF\u7684\u63a7\u5236\u5668\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u66f4\u597d\u6548\u679c\u5e76\u63ed\u793a\u65e7\u65b9\u6cd5\u6210\u529f\u7387\u4e0b\u964d\u539f\u56e0\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u9a8c\u8bc1\u6846\u67b6\u4e2d\uff0c\u5b66\u4e60\u8005\u5c06\u674e\u96c5\u666e\u8bfa\u592b\u6761\u4ef6\u4f5c\u4e3a\u590d\u6742\u4f18\u5316\u7ea6\u675f\uff0c\u96be\u4ee5\u5168\u5c40\u6536\u655b\uff0c\u9a8c\u8bc1\u4e5f\u590d\u6742\uff0c\u9700\u6539\u8fdb\u8be5\u6846\u67b6\u3002", "method": "\u5c06\u674e\u96c5\u666e\u8bfa\u592b\u6761\u4ef6\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\uff0c\u8bbe\u8ba1\u795e\u7ecfCLF\u548c\u57fa\u4e8eCLF\u7684\u63a7\u5236\u5668\uff0c\u8fdb\u884c\u7aef\u5230\u7aef\u5b66\u4e60\u3002", "result": "\u5728\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b66\u4e60CLF\u65f6\u6536\u655b\u7387\u66f4\u9ad8\u3001\u5438\u5f15\u57df\u66f4\u5927\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u80fd\u4f18\u5316\u5bfb\u627eCLF\u7684\u8fc7\u7a0b\uff0c\u89e3\u51b3\u65e7\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u6709\u66f4\u597d\u6548\u679c\u3002"}}
{"id": "2511.00352", "pdf": "https://arxiv.org/pdf/2511.00352", "abs": "https://arxiv.org/abs/2511.00352", "authors": ["Mohd Ruhul Ameen", "Akif Islam"], "title": "Detecting AI-Generated Images via Diffusion Snap-Back Reconstruction: A Forensic Approach", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 8 figures, 4 Tables, submitted to ICECTE 2026", "summary": "The rapid rise of generative diffusion models has made distinguishing\nauthentic visual content from synthetic imagery increasingly challenging.\nTraditional deepfake detection methods, which rely on frequency or pixel-level\nartifacts, fail against modern text-to-image systems such as Stable Diffusion\nand DALL-E that produce photorealistic and artifact-free results. This paper\nintroduces a diffusion-based forensic framework that leverages multi-strength\nimage reconstruction dynamics, termed diffusion snap-back, to identify\nAI-generated images. By analysing how reconstruction metrics (LPIPS, SSIM, and\nPSNR) evolve across varying noise strengths, we extract interpretable\nmanifold-based features that differentiate real and synthetic images. Evaluated\non a balanced dataset of 4,000 images, our approach achieves 0.993 AUROC under\ncross-validation and remains robust to common distortions such as compression\nand noise. Despite using limited data and a single diffusion backbone (Stable\nDiffusion v1.5), the proposed method demonstrates strong generalization and\ninterpretability, offering a foundation for scalable, model-agnostic synthetic\nmedia forensics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u7684\u53d6\u8bc1\u6846\u67b6\u9274\u522bAI\u751f\u6210\u56fe\u50cf\uff0c\u57284000\u5f20\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u5f3a\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u751f\u6210\u6269\u6563\u6a21\u578b\u5174\u8d77\uff0c\u4f20\u7edf\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u73b0\u4ee3\u6587\u672c\u5230\u56fe\u50cf\u7cfb\u7edf\uff0c\u9700\u65b0\u65b9\u6cd5\u9274\u522bAI\u751f\u6210\u56fe\u50cf\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6269\u6563\u7684\u53d6\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u591a\u5f3a\u5ea6\u56fe\u50cf\u91cd\u5efa\u52a8\u6001\uff08\u6269\u6563\u56de\u8df3\uff09\uff0c\u5206\u6790\u4e0d\u540c\u566a\u58f0\u5f3a\u5ea6\u4e0b\u91cd\u5efa\u6307\u6807\uff08LPIPS\u3001SSIM\u548cPSNR\uff09\u7684\u53d8\u5316\uff0c\u63d0\u53d6\u57fa\u4e8e\u6d41\u5f62\u7684\u7279\u5f81\u3002", "result": "\u57284000\u5f20\u56fe\u50cf\u7684\u5e73\u8861\u6570\u636e\u96c6\u4e0a\uff0c\u4ea4\u53c9\u9a8c\u8bc1\u7684AUROC\u8fbe0.993\uff0c\u5bf9\u538b\u7f29\u548c\u566a\u58f0\u7b49\u5e38\u89c1\u5931\u771f\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u867d\u4f7f\u7528\u6709\u9650\u6570\u636e\u548c\u5355\u4e00\u6269\u6563\u4e3b\u5e72\uff0c\u4f46\u5177\u6709\u5f3a\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u5408\u6210\u5a92\u4f53\u53d6\u8bc1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.01286", "pdf": "https://arxiv.org/pdf/2511.01286", "abs": "https://arxiv.org/abs/2511.01286", "authors": ["Sivaram Krishnan", "Jinho Choi", "Jihong Park", "Gregory Sherman", "Benjamin Campbell"], "title": "Koopman-based Prediction of Connectivity for Flying Ad Hoc Networks", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The application of machine learning (ML) to communication systems is expected\nto play a pivotal role in future artificial intelligence (AI)-based\nnext-generation wireless networks. While most existing works focus on ML\ntechniques for static wireless environments, they often face limitations when\napplied to highly dynamic environments, such as flying ad hoc networks\n(FANETs). This paper explores the use of data-driven Koopman approaches to\naddress these challenges. Specifically, we investigate how these approaches can\nmodel UAV trajectory dynamics within FANETs, enabling more accurate predictions\nand improved network performance. By leveraging Koopman operator theory, we\npropose two possible approaches -- centralized and distributed -- to\nefficiently address the challenges posed by the constantly changing topology of\nFANETs. To demonstrate this, we consider a FANET performing surveillance with\nUAVs following pre-determined trajectories and predict\nsignal-to-interference-plus-noise ratios (SINRs) to ensure reliable\ncommunication between UAVs. Our results show that these approaches can\naccurately predict connectivity and isolation events that lead to modelled\ncommunication outages. This capability could help UAVs schedule their\ntransmissions based on these predictions.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u6570\u636e\u9a71\u52a8\u7684Koopman\u65b9\u6cd5\u89e3\u51b3\u98de\u81ea\u7ec4\u7f51\uff08FANETs\uff09\u4e2d\u673a\u5668\u5b66\u4e60\u6280\u672f\u5e94\u7528\u6311\u6218\uff0c\u63d0\u51fa\u96c6\u4e2d\u548c\u5206\u5e03\u5f0f\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u80fd\u51c6\u786e\u9884\u6d4b\u8fde\u901a\u6027\u548c\u9694\u79bb\u4e8b\u4ef6\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u9759\u6001\u65e0\u7ebf\u73af\u5883\u5e94\u7528\u591a\uff0c\u5728FANET\u7b49\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\u6709\u5c40\u9650\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u6311\u6218\u3002", "method": "\u5229\u7528Koopman\u7b97\u5b50\u7406\u8bba\uff0c\u63d0\u51fa\u96c6\u4e2d\u548c\u5206\u5e03\u5f0f\u4e24\u79cd\u65b9\u6cd5\uff0c\u8003\u8651UAV\u6309\u9884\u5b9a\u8f68\u8ff9\u6267\u884c\u76d1\u89c6\u4efb\u52a1\u7684FANET\uff0c\u9884\u6d4b\u4fe1\u5e72\u566a\u6bd4\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u80fd\u51c6\u786e\u9884\u6d4b\u5bfc\u81f4\u901a\u4fe1\u4e2d\u65ad\u7684\u8fde\u901a\u6027\u548c\u9694\u79bb\u4e8b\u4ef6\u3002", "conclusion": "\u8be5\u80fd\u529b\u53ef\u5e2e\u52a9UAV\u6839\u636e\u9884\u6d4b\u5b89\u6392\u4f20\u8f93\u3002"}}
{"id": "2511.01296", "pdf": "https://arxiv.org/pdf/2511.01296", "abs": "https://arxiv.org/abs/2511.01296", "authors": ["Guanjie Cheng", "Mengzhen Yang", "Xinkui Zhao", "Shuyi Yu", "Tianyu Du", "Yangyang Wu", "Mengying Zhu", "Shuiguang Deng"], "title": "LSHFed: Robust and Communication-Efficient Federated Learning with Locally-Sensitive Hashing Gradient Mapping", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndistributed nodes without exposing raw data, but its decentralized nature makes\nit vulnerable in trust-deficient environments. Inference attacks may recover\nsensitive information from gradient updates, while poisoning attacks can\ndegrade model performance or induce malicious behaviors. Existing defenses\noften suffer from high communication and computation costs, or limited\ndetection precision. To address these issues, we propose LSHFed, a robust and\ncommunication-efficient FL framework that simultaneously enhances aggregation\nrobustness and privacy preservation. At its core, LSHFed incorporates LSHGM, a\nnovel gradient verification mechanism that projects high-dimensional gradients\ninto compact binary representations via multi-hyperplane locally-sensitive\nhashing. This enables accurate detection and filtering of malicious gradients\nusing only their irreversible hash forms, thus mitigating privacy leakage risks\nand substantially reducing transmission overhead. Extensive experiments\ndemonstrate that LSHFed maintains high model performance even when up to 50% of\nparticipants are collusive adversaries while achieving up to a 1000x reduction\nin gradient verification communication compared to full-gradient methods.", "AI": {"tldr": "\u63d0\u51faLSHFed\u6846\u67b6\u589e\u5f3a\u8054\u90a6\u5b66\u4e60\u9c81\u68d2\u6027\u4e0e\u9690\u79c1\u4fdd\u62a4\uff0c\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u4fe1\u4efb\u4e0d\u8db3\u73af\u5883\u6613\u53d7\u63a8\u7406\u548c\u4e2d\u6bd2\u653b\u51fb\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u6210\u672c\u9ad8\u6216\u68c0\u6d4b\u7cbe\u5ea6\u6709\u9650\u95ee\u9898\u3002", "method": "\u63d0\u51faLSHFed\u6846\u67b6\uff0c\u6838\u5fc3\u662fLSHGM\u68af\u5ea6\u9a8c\u8bc1\u673a\u5236\uff0c\u901a\u8fc7\u591a\u8d85\u5e73\u9762\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u5c06\u9ad8\u7ef4\u68af\u5ea6\u6295\u5f71\u4e3a\u7d27\u51d1\u4e8c\u8fdb\u5236\u8868\u793a\u3002", "result": "\u5373\u4f7f50%\u53c2\u4e0e\u8005\u4e3a\u6076\u610f\u5bf9\u624b\uff0cLSHFed\u4ecd\u4fdd\u6301\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u68af\u5ea6\u9a8c\u8bc1\u901a\u4fe1\u76f8\u6bd4\u5168\u68af\u5ea6\u65b9\u6cd5\u6700\u591a\u964d\u4f4e1000\u500d\u3002", "conclusion": "LSHFed\u80fd\u540c\u65f6\u589e\u5f3a\u805a\u5408\u9c81\u68d2\u6027\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u4e14\u901a\u4fe1\u9ad8\u6548\u3002"}}
{"id": "2511.00360", "pdf": "https://arxiv.org/pdf/2511.00360", "abs": "https://arxiv.org/abs/2511.00360", "authors": ["Adrita Rahman Tory", "Khondokar Fida Hasan", "Md Saifur Rahman", "Nickolaos Koroniotis", "Mohammad Ali Moni"], "title": "Mind the Gap: Missing Cyber Threat Coverage in NIDS Datasets for the Energy Sector", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "13 pages", "summary": "Network Intrusion Detection Systems (NIDS) developed us- ing publicly\navailable datasets predominantly focus on enterprise environ- ments, raising\nconcerns about their effectiveness for converged Informa- tion Technology (IT)\nand Operational Technology (OT) in energy infras- tructures. This study\nevaluates the representativeness of five widely used datasets: CIC-IDS2017,\nSWaT, WADI, Sherlock, and CIC-Modbus2023 against network-detectable MITRE\nATT&CK techniques extracted from documented energy sector incidents. Using a\nstructured five-step analyt- ical approach, this article successfully developed\nand performed a gap analysis that identified 94 network observable techniques\nfrom an initial pool of 274 ATT&CK techniques. Sherlock dataset exhibited the\nhigh- est mean coverage (0.56), followed closely by CIC-IDS2017 (0.55), while\nSWaT and WADI recorded the lowest scores (0.38). Combining CIC- IDS2017,\nSherlock, and CIC-Modbus2023 achieved an aggregate coverage of 92%,\nhighlighting their complementary strengths. The analysis identi- fies critical\ngaps, particularly in lateral movement and industrial protocol manipulation,\nproviding a clear pathway for dataset enhancement and more robust NIDS\nevaluation in hybrid IT/OT energy environments.", "AI": {"tldr": "\u8bc4\u4f30\u4e94\u4e2a\u5e38\u7528\u6570\u636e\u96c6\u5bf9\u80fd\u6e90\u57fa\u7840\u8bbe\u65bd\u4e2d\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7684\u4ee3\u8868\u6027\uff0c\u627e\u51fa\u5dee\u8ddd\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u516c\u5f00\u6570\u636e\u96c6\u7684\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u591a\u7528\u4e8e\u4f01\u4e1a\u73af\u5883\uff0c\u9700\u8bc4\u4f30\u5176\u5bf9\u80fd\u6e90\u57fa\u7840\u8bbe\u65bd\u4e2d\u878d\u5408\u7684IT\u548cOT\u73af\u5883\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u4e94\u6b65\u5206\u6790\u65b9\u6cd5\uff0c\u5c06\u4e94\u4e2a\u6570\u636e\u96c6\u4e0e\u4ece\u80fd\u6e90\u884c\u4e1a\u4e8b\u4ef6\u4e2d\u63d0\u53d6\u7684MITRE ATT&CK\u6280\u672f\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u786e\u5b9a94\u79cd\u53ef\u89c2\u6d4b\u7f51\u7edc\u6280\u672f\uff0cSherlock\u6570\u636e\u96c6\u5e73\u5747\u8986\u76d6\u7387\u6700\u9ad8\uff0c\u7ec4\u5408\u90e8\u5206\u6570\u636e\u96c6\u8986\u76d6\u7387\u8fbe92%\u3002", "conclusion": "\u5206\u6790\u627e\u51fa\u5173\u952e\u5dee\u8ddd\uff0c\u4e3a\u6570\u636e\u96c6\u589e\u5f3a\u548c\u66f4\u5f3a\u5927\u7684NIDS\u8bc4\u4f30\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2511.01343", "pdf": "https://arxiv.org/pdf/2511.01343", "abs": "https://arxiv.org/abs/2511.01343", "authors": ["\u00c1lvaro V\u00e1zquez Rodr\u00edguez", "Manuel Fern\u00e1ndez-Veiga", "Carlos Giraldo-Rodr\u00edguez"], "title": "Diffusion-Based Solver for CNF Placement on the Cloud-Continuum", "categories": ["cs.LG"], "comment": "7 pages, 7 figures. Presented at PE-WASUN'25 (IEEE International\n  Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, and\n  Ubiquitous Networks)", "summary": "The placement of Cloud-Native Network Functions (CNFs) across the\nCloud-Continuum represents a core challenge in the orchestration of current 5G\nand future 6G networks. The process involves the placement of interdependent\ncomputing tasks, structured as Service Function Chains, over distributed cloud\ninfrastructures. This is achieved while satisfying strict resource, bandwidth\nand latency constraints. It is acknowledged that classical approaches,\nincluding mixed-integer nonlinear programming, heuristics and reinforcement\nlearning are limited in terms of scalability, constraint handling and\ngeneralisation capacity. In the present study, a novel theoretical framework is\nproposed, which is based on Denoising Diffusion Probabilistic Models (DDPM) for\nCNF placement. The present approach proposes a reconceptualisation of placement\nas a generative graph to assignment task, where the placement problem is\nencoded as a heterogeneous graph, and a Graph Neural Network denoiser is\ntrained to iteratively refine noisy CNF-to-cloud assignment matrices. The model\nincorporates constraint-specific losses directly into the loss function,\nthereby allowing it to learn feasible solution spaces. The integration of the\nDDPM formulation with structured combinatorial constraints is achieved through\na rigorous and systematic approach. Extensive evaluations across diverse\ntopologies have been conducted, which have confirmed that the model\nconsistently produces feasible solutions with orders of magnitude faster\ninference than MINLP solvers. The results obtained demonstrate the potential of\ndiffusion-based generative modelling for constrained network embedding\nproblems, making an impact towards the practical, scalable orchestration of\ndistributed Cloud-Native Network Functions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eDDPM\u7684CNF\u653e\u7f6e\u7406\u8bba\u6846\u67b6\uff0c\u7ecf\u8bc4\u4f30\u6bd4MINLP\u6c42\u89e3\u5668\u63a8\u7406\u5feb\uff0c\u5c55\u793a\u4e86\u6269\u6563\u751f\u6210\u6a21\u578b\u5728\u53d7\u9650\u7f51\u7edc\u5d4c\u5165\u95ee\u9898\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u7ecf\u5178\u65b9\u6cd5\u5728CNF\u8de8\u4e91\u8fde\u7eed\u4f53\u653e\u7f6e\u7684\u53ef\u6269\u5c55\u6027\u3001\u7ea6\u675f\u5904\u7406\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u6709\u9650\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u5c06\u653e\u7f6e\u95ee\u9898\u91cd\u6784\u4e3a\u751f\u6210\u56fe\u5206\u914d\u4efb\u52a1\uff0c\u7f16\u7801\u4e3a\u5f02\u6784\u56fe\uff0c\u8bad\u7ec3\u56fe\u795e\u7ecf\u7f51\u7edc\u53bb\u566a\u5668\uff0c\u5c06\u7279\u5b9a\u7ea6\u675f\u635f\u5931\u878d\u5165\u635f\u5931\u51fd\u6570\u3002", "result": "\u6a21\u578b\u80fd\u6301\u7eed\u4ea7\u751f\u53ef\u884c\u89e3\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4MINLP\u6c42\u89e3\u5668\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6269\u6563\u751f\u6210\u6a21\u578b\u5728\u53d7\u9650\u7f51\u7edc\u5d4c\u5165\u95ee\u9898\u6709\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u5206\u5e03\u5f0fCNF\u7684\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u7f16\u6392\u3002"}}
{"id": "2511.00361", "pdf": "https://arxiv.org/pdf/2511.00361", "abs": "https://arxiv.org/abs/2511.00361", "authors": ["Kayua Oleques Paim", "Angelo Gaspar Diniz Nogueira", "Diego Kreutz", "Weverton Cordeiro", "Rodrigo Brandao Mansilha"], "title": "MalDataGen: A Modular Framework for Synthetic Tabular Data Generation in Malware Detection", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2"], "comment": "10 pages, 6 figures, 2 tables. Published at the Brazilian Symposium\n  on Cybersecurity (SBSeg 2025)", "summary": "High-quality data scarcity hinders malware detection, limiting ML\nperformance. We introduce MalDataGen, an open-source modular framework for\ngenerating high-fidelity synthetic tabular data using modular deep learning\nmodels (e.g., WGAN-GP, VQ-VAE). Evaluated via dual validation (TR-TS/TS-TR),\nseven classifiers, and utility metrics, MalDataGen outperforms benchmarks like\nSDV while preserving data utility. Its flexible design enables seamless\nintegration into detection pipelines, offering a practical solution for\ncybersecurity applications.", "AI": {"tldr": "\u63d0\u51fa\u5f00\u6e90\u6846\u67b6MalDataGen\u751f\u6210\u9ad8\u4fdd\u771f\u5408\u6210\u8868\u683c\u6570\u636e\u7528\u4e8e\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u4e14\u53ef\u96c6\u6210\u5230\u68c0\u6d4b\u6d41\u7a0b\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6570\u636e\u7a00\u7f3a\u963b\u788d\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\uff0c\u9650\u5236\u673a\u5668\u5b66\u4e60\u6027\u80fd\u3002", "method": "\u5f15\u5165MalDataGen\u6846\u67b6\uff0c\u4f7f\u7528\u6a21\u5757\u5316\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982WGAN - GP\u3001VQ - VAE\uff09\u751f\u6210\u6570\u636e\uff0c\u901a\u8fc7\u53cc\u91cd\u9a8c\u8bc1\u3001\u4e03\u79cd\u5206\u7c7b\u5668\u548c\u6548\u7528\u6307\u6807\u8bc4\u4f30\u3002", "result": "MalDataGen\u4f18\u4e8eSDV\u7b49\u57fa\u51c6\uff0c\u540c\u65f6\u4fdd\u7559\u6570\u636e\u6548\u7528\u3002", "conclusion": "MalDataGen\u7075\u6d3b\u8bbe\u8ba1\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u68c0\u6d4b\u7ba1\u9053\uff0c\u4e3a\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01352", "pdf": "https://arxiv.org/pdf/2511.01352", "abs": "https://arxiv.org/abs/2511.01352", "authors": ["Lucie Flek", "Oliver Janik", "Philipp Alexander Jung", "Akbar Karimi", "Timo Saala", "Alexander Schmidt", "Matthias Schott", "Philipp Soldin", "Matthias Thiesmeyer", "Christopher Wiebusch", "Ulrich Willemsen"], "title": "MiniFool - Physics-Constraint-Aware Minimizer-Based Adversarial Attacks in Deep Neural Networks", "categories": ["cs.LG", "astro-ph.HE", "astro-ph.IM", "hep-ex", "physics.data-an", "J.2; I.2.6"], "comment": "Submitted to Computing and Software for Big Science", "summary": "In this paper, we present a new algorithm, MiniFool, that implements\nphysics-inspired adversarial attacks for testing neural network-based\nclassification tasks in particle and astroparticle physics. While we initially\ndeveloped the algorithm for the search for astrophysical tau neutrinos with the\nIceCube Neutrino Observatory, we apply it to further data from other science\ndomains, thus demonstrating its general applicability. Here, we apply the\nalgorithm to the well-known MNIST data set and furthermore, to Open Data data\nfrom the CMS experiment at the Large Hadron Collider. The algorithm is based on\nminimizing a cost function that combines a $\\chi^2$ based test-statistic with\nthe deviation from the desired target score. The test statistic quantifies the\nprobability of the perturbations applied to the data based on the experimental\nuncertainties. For our studied use cases, we find that the likelihood of a\nflipped classification differs for both the initially correctly and incorrectly\nclassified events. When testing changes of the classifications as a function of\nan attack parameter that scales the experimental uncertainties, the robustness\nof the network decision can be quantified. Furthermore, this allows testing the\nrobustness of the classification of unlabeled experimental data.", "AI": {"tldr": "\u63d0\u51faMiniFool\u7b97\u6cd5\u7528\u4e8e\u7c92\u5b50\u548c\u5929\u4f53\u7c92\u5b50\u7269\u7406\u4e2d\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u7684\u5bf9\u6297\u653b\u51fb\u6d4b\u8bd5\uff0c\u5c55\u793a\u5176\u901a\u7528\u6027\u5e76\u5206\u6790\u5206\u7c7b\u7ffb\u8f6c\u60c5\u51b5\u548c\u7f51\u7edc\u51b3\u7b56\u9c81\u68d2\u6027\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u7c92\u5b50\u548c\u5929\u4f53\u7c92\u5b50\u7269\u7406\u4e2d\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u7684\u5bf9\u6297\u653b\u51fb\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u4e14\u5177\u6709\u901a\u7528\u6027\u3002", "method": "\u57fa\u4e8e\u6700\u5c0f\u5316\u7ed3\u5408$\\chi^2$\u6d4b\u8bd5\u7edf\u8ba1\u91cf\u4e0e\u76ee\u6807\u5206\u6570\u504f\u5dee\u7684\u6210\u672c\u51fd\u6570\uff0c\u6d4b\u8bd5\u7edf\u8ba1\u91cf\u6839\u636e\u5b9e\u9a8c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6570\u636e\u6270\u52a8\u6982\u7387\u3002", "result": "\u53d1\u73b0\u6b63\u786e\u548c\u9519\u8bef\u5206\u7c7b\u4e8b\u4ef6\u7684\u5206\u7c7b\u7ffb\u8f6c\u53ef\u80fd\u6027\u4e0d\u540c\uff0c\u53ef\u901a\u8fc7\u653b\u51fb\u53c2\u6570\u91cf\u5316\u7f51\u7edc\u51b3\u7b56\u9c81\u68d2\u6027\u3002", "conclusion": "MiniFool\u7b97\u6cd5\u5177\u6709\u901a\u7528\u6027\uff0c\u53ef\u7528\u4e8e\u6d4b\u8bd5\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u7684\u9c81\u68d2\u6027\uff0c\u5305\u62ec\u672a\u6807\u8bb0\u5b9e\u9a8c\u6570\u636e\u3002"}}
{"id": "2511.00362", "pdf": "https://arxiv.org/pdf/2511.00362", "abs": "https://arxiv.org/abs/2511.00362", "authors": ["Momen Khandoker Ope", "Akif Islam", "Mohd Ruhul Ameen", "Abu Saleh Musa Miah", "Md Rashedul Islam", "Jungpil Shin"], "title": "Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "6 Pages, 4 figures, 2 Tables, Submitted to ICECTE 2026", "summary": "Cultural heritage restoration in Bangladesh faces a dual challenge of limited\nresources and scarce technical expertise. Traditional 3D digitization methods,\nsuch as photogrammetry or LiDAR scanning, require expensive hardware, expert\noperators, and extensive on-site access, which are often infeasible in\ndeveloping contexts. As a result, many of Bangladesh's architectural treasures,\nfrom the Paharpur Buddhist Monastery to Ahsan Manzil, remain vulnerable to\ndecay and inaccessible in digital form. This paper introduces Oitijjo-3D, a\ncost-free generative AI framework that democratizes 3D cultural preservation.\nBy using publicly available Google Street View imagery, Oitijjo-3D reconstructs\nfaithful 3D models of heritage structures through a two-stage pipeline -\nmultimodal visual reasoning with Gemini 2.5 Flash Image for structure-texture\nsynthesis, and neural image-to-3D generation through Hexagen for geometry\nrecovery. The system produces photorealistic, metrically coherent\nreconstructions in seconds, achieving significant speedups compared to\nconventional Structure-from-Motion pipelines, without requiring any specialized\nhardware or expert supervision. Experiments on landmarks such as Ahsan Manzil,\nChoto Sona Mosque, and Paharpur demonstrate that Oitijjo-3D preserves both\nvisual and structural fidelity while drastically lowering economic and\ntechnical barriers. By turning open imagery into digital heritage, this work\nreframes preservation as a community-driven, AI-assisted act of cultural\ncontinuity for resource-limited nations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u514d\u8d39\u751f\u6210\u5f0fAI\u6846\u67b6Oitijjo - 3D\u7528\u4e8e\u5b5f\u52a0\u62c9\u56fd\u6587\u5316\u9057\u4ea73D\u6570\u5b57\u5316\u4fdd\u62a4\uff0c\u5229\u7528\u8c37\u6b4c\u8857\u666f\u56fe\u50cf\uff0c\u901f\u5ea6\u5feb\u4e14\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u5b5f\u52a0\u62c9\u56fd\u6587\u5316\u9057\u4ea7\u4fee\u590d\u9762\u4e34\u8d44\u6e90\u548c\u6280\u672f\u4e13\u4e1a\u77e5\u8bc6\u6709\u9650\u7684\u95ee\u9898\uff0c\u4f20\u7edf3D\u6570\u5b57\u5316\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u96be\u5b9e\u65bd\uff0c\u8bb8\u591a\u5efa\u7b51\u9057\u4ea7\u6613\u635f\u574f\u4e14\u7f3a\u4e4f\u6570\u5b57\u5f62\u5f0f\u3002", "method": "\u63d0\u51faOitijjo - 3D\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6d41\u7a0b\uff0c\u5229\u7528Gemini 2.5 Flash Image\u8fdb\u884c\u591a\u6a21\u6001\u89c6\u89c9\u63a8\u7406\u5408\u6210\u7ed3\u6784\u7eb9\u7406\uff0c\u4f7f\u7528Hexagen\u8fdb\u884c\u795e\u7ecf\u56fe\u50cf\u52303D\u751f\u6210\u6062\u590d\u51e0\u4f55\u5f62\u72b6\u3002", "result": "\u7cfb\u7edf\u80fd\u5728\u6570\u79d2\u5185\u751f\u6210\u903c\u771f\u3001\u5ea6\u91cf\u4e00\u81f4\u7684\u91cd\u5efa\u7ed3\u679c\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u901f\u5ea6\u5927\u5e45\u63d0\u5347\uff0c\u65e0\u9700\u4e13\u4e1a\u786c\u4ef6\u548c\u4e13\u5bb6\u76d1\u7763\u3002\u5728\u591a\u4e2a\u5730\u6807\u5b9e\u9a8c\u4e2d\uff0c\u80fd\u4fdd\u6301\u89c6\u89c9\u548c\u7ed3\u6784\u4fdd\u771f\u5ea6\u3002", "conclusion": "Oitijjo - 3D\u5c06\u5f00\u653e\u56fe\u50cf\u8f6c\u5316\u4e3a\u6570\u5b57\u9057\u4ea7\uff0c\u4f7f\u8d44\u6e90\u6709\u9650\u56fd\u5bb6\u7684\u6587\u5316\u9057\u4ea7\u4fdd\u62a4\u6210\u4e3a\u793e\u533a\u9a71\u52a8\u3001AI\u8f85\u52a9\u7684\u6587\u5316\u4f20\u627f\u884c\u4e3a\u3002"}}
{"id": "2511.01356", "pdf": "https://arxiv.org/pdf/2511.01356", "abs": "https://arxiv.org/abs/2511.01356", "authors": ["Rana Alaa", "Dar\u00edo Gonz\u00e1lez-Ferreiro", "Carlos Beis-Penedo", "Manuel Fern\u00e1ndez-Veiga", "Rebeca P. D\u00edaz-Redondo", "Ana Fern\u00e1ndez-Vilas"], "title": "Verifiable Split Learning via zk-SNARKs", "categories": ["cs.LG"], "comment": "Submitted to CAI'26 (IEEE Conference on Artificial Intelligence 2026)", "summary": "Split learning is an approach to collaborative learning in which a deep\nneural network is divided into two parts: client-side and server-side at a cut\nlayer. The client side executes its model using its raw input data and sends\nthe intermediate activation to the server side. This configuration architecture\nis very useful for enabling collaborative training when data or resources are\nseparated between devices. However, split learning lacks the ability to verify\nthe correctness and honesty of the computations that are performed and\nexchanged between the parties. To this purpose, this paper proposes a\nverifiable split learning framework that integrates a zk-SNARK proof to ensure\ncorrectness and verifiability. The zk-SNARK proof and verification are\ngenerated for both sides in forward propagation and backward propagation on the\nserver side, guaranteeing verifiability on both sides. The verifiable split\nlearning architecture is compared to a blockchain-enabled system for the same\ndeep learning network, one that records updates but without generating the\nzero-knowledge proof. From the comparison, it can be deduced that applying the\nzk-SNARK test achieves verifiability and correctness, while blockchains are\nlightweight but unverifiable.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u7684\u62c6\u5206\u5b66\u4e60\u6846\u67b6\uff0c\u96c6\u6210zk - SNARK\u8bc1\u660e\u4fdd\u8bc1\u6b63\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u5e76\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u5bf9\u6bd4\u3002", "motivation": "\u62c6\u5206\u5b66\u4e60\u7f3a\u4e4f\u9a8c\u8bc1\u5404\u65b9\u8ba1\u7b97\u6b63\u786e\u6027\u548c\u8bda\u5b9e\u6027\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u96c6\u6210zk - SNARK\u8bc1\u660e\u7684\u53ef\u9a8c\u8bc1\u62c6\u5206\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u6b63\u5411\u548c\u53cd\u5411\u4f20\u64ad\u4e2d\u4e3a\u53cc\u65b9\u751f\u6210\u8bc1\u660e\u548c\u9a8c\u8bc1\u3002", "result": "\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u5bf9\u6bd4\uff0czk - SNARK\u6d4b\u8bd5\u53ef\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u6027\u548c\u6b63\u786e\u6027\uff0c\u533a\u5757\u94fe\u8f7b\u91cf\u7ea7\u4f46\u4e0d\u53ef\u9a8c\u8bc1\u3002", "conclusion": "\u5e94\u7528zk - SNARK\u6d4b\u8bd5\u7684\u62c6\u5206\u5b66\u4e60\u6846\u67b6\u80fd\u4fdd\u8bc1\u8ba1\u7b97\u7684\u6b63\u786e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2511.01374", "pdf": "https://arxiv.org/pdf/2511.01374", "abs": "https://arxiv.org/abs/2511.01374", "authors": ["Ziqi Wang", "Jiashun Liu", "Ling Pan"], "title": "Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization", "categories": ["cs.LG"], "comment": "NeurIPS 2025", "summary": "Traditional continuous deep reinforcement learning (RL) algorithms employ\ndeterministic or unimodal Gaussian actors, which cannot express complex\nmultimodal decision distributions. This limitation can hinder their performance\nin diversity-critical scenarios. There have been some attempts to design online\nmultimodal RL algorithms based on diffusion or amortized actors. However, these\nactors are intractable, making existing methods struggle with balancing\nperformance, decision diversity, and efficiency simultaneously. To overcome\nthis challenge, we first reformulate existing intractable multimodal actors\nwithin a unified framework, and prove that they can be directly optimized by\npolicy gradient via reparameterization. Then, we propose a distance-based\ndiversity regularization that does not explicitly require decision\nprobabilities. We identify two diversity-critical domains, namely multi-goal\nachieving and generative RL, to demonstrate the advantages of multimodal\npolicies and our method, particularly in terms of few-shot robustness. In\nconventional MuJoCo benchmarks, our algorithm also shows competitive\nperformance. Moreover, our experiments highlight that the amortized actor is a\npromising policy model class with strong multimodal expressivity and high\nperformance. Our code is available at https://github.com/PneuC/DrAC", "AI": {"tldr": "\u4f20\u7edf\u8fde\u7eed\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u96be\u4ee5\u8868\u8fbe\u590d\u6742\u591a\u6a21\u6001\u51b3\u7b56\u5206\u5e03\uff0c\u672c\u6587\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u4f18\u5316\u591a\u6a21\u6001\u53c2\u4e0e\u8005\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8ddd\u79bb\u7684\u591a\u6837\u6027\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u5728\u591a\u9886\u57df\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4f20\u7edf\u8fde\u7eed\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u8868\u8fbe\u590d\u6742\u591a\u6a21\u6001\u51b3\u7b56\u5206\u5e03\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u73b0\u6709\u5728\u7ebf\u591a\u6a21\u6001RL\u7b97\u6cd5\u7684\u53c2\u4e0e\u8005\u96be\u4ee5\u5904\u7406\uff0c\u96be\u4ee5\u5e73\u8861\u6027\u80fd\u3001\u51b3\u7b56\u591a\u6837\u6027\u548c\u6548\u7387\u3002", "method": "\u9996\u5148\u5728\u7edf\u4e00\u6846\u67b6\u5185\u91cd\u65b0\u8868\u8ff0\u73b0\u6709\u96be\u5904\u7406\u7684\u591a\u6a21\u6001\u53c2\u4e0e\u8005\uff0c\u5e76\u8bc1\u660e\u53ef\u901a\u8fc7\u91cd\u53c2\u6570\u5316\u7528\u7b56\u7565\u68af\u5ea6\u76f4\u63a5\u4f18\u5316\uff1b\u63d0\u51fa\u57fa\u4e8e\u8ddd\u79bb\u7684\u591a\u6837\u6027\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u591a\u76ee\u6807\u5b9e\u73b0\u548c\u751f\u6210\u5f0fRL\u7b49\u591a\u6837\u6027\u5173\u952e\u9886\u57df\u5c55\u793a\u4e86\u591a\u6a21\u6001\u7b56\u7565\u548c\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u5728\u5e38\u89c4MuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u644a\u9500\u53c2\u4e0e\u8005\u662f\u6709\u524d\u666f\u7684\u7b56\u7565\u6a21\u578b\u7c7b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86\u73b0\u6709\u7b97\u6cd5\u7684\u6311\u6218\uff0c\u644a\u9500\u53c2\u4e0e\u8005\u662f\u5177\u6709\u5f3a\u591a\u6a21\u6001\u8868\u8fbe\u80fd\u529b\u548c\u9ad8\u6027\u80fd\u7684\u6709\u524d\u666f\u7b56\u7565\u6a21\u578b\u7c7b\u3002"}}
{"id": "2511.00370", "pdf": "https://arxiv.org/pdf/2511.00370", "abs": "https://arxiv.org/abs/2511.00370", "authors": ["Chaochen Wu", "Guan Luo", "Meiyun Zuo", "Zhitao Fan"], "title": "Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video moment retrieval uses a text query to locate a moment from a given\nuntrimmed video reference. Locating corresponding video moments with text\nqueries helps people interact with videos efficiently. Current solutions for\nthis task have not considered conflict within location results from different\nmodels, so various models cannot integrate correctly to produce better results.\nThis study introduces a reinforcement learning-based video moment retrieval\nmodel that can scan the whole video once to find the moment's boundary while\nproducing its locational evidence. Moreover, we proposed a multi-agent system\nframework that can use evidential learning to resolve conflicts between agents'\nlocalization output. As a side product of observing and dealing with conflicts\nbetween agents, we can decide whether a query has no corresponding moment in a\nvideo (out-of-scope) without additional training, which is suitable for\nreal-world applications. Extensive experiments on benchmark datasets show the\neffectiveness of our proposed methods compared with state-of-the-art\napproaches. Furthermore, the results of our study reveal that modeling\ncompetition and conflict of the multi-agent system is an effective way to\nimprove RL performance in moment retrieval and show the new role of evidential\nlearning in the multi-agent framework.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u89c6\u9891\u65f6\u523b\u68c0\u7d22\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u53ef\u89e3\u51b3\u5b9a\u4f4d\u51b2\u7a81\uff0c\u5224\u65ad\u67e5\u8be2\u662f\u5426\u8d8a\u754c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u65f6\u523b\u68c0\u7d22\u65b9\u6848\u672a\u8003\u8651\u4e0d\u540c\u6a21\u578b\u5b9a\u4f4d\u7ed3\u679c\u7684\u51b2\u7a81\uff0c\u65e0\u6cd5\u6b63\u786e\u6574\u5408\u6a21\u578b\u4ee5\u4ea7\u751f\u66f4\u597d\u7ed3\u679c\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u89c6\u9891\u65f6\u523b\u68c0\u7d22\u6a21\u578b\u626b\u63cf\u89c6\u9891\u627e\u8fb9\u754c\u5e76\u7ed9\u51fa\u5b9a\u4f4d\u8bc1\u636e\uff0c\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\u7528\u8bc1\u636e\u5b66\u4e60\u89e3\u51b3\u5b9a\u4f4d\u8f93\u51fa\u51b2\u7a81\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "conclusion": "\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7ade\u4e89\u548c\u51b2\u7a81\u5efa\u6a21\u662f\u63d0\u9ad8\u65f6\u523b\u68c0\u7d22\u4e2d\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u8bc1\u636e\u5b66\u4e60\u5728\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4e2d\u7684\u65b0\u4f5c\u7528\u3002"}}
{"id": "2511.01377", "pdf": "https://arxiv.org/pdf/2511.01377", "abs": "https://arxiv.org/abs/2511.01377", "authors": ["Amir Hossein Khorasani", "Ali Jahanian", "Maryam Rastgarpour"], "title": "Protecting the Neural Networks against FGSM Attack Using Machine Unlearning", "categories": ["cs.LG"], "comment": "7 pages, 9 figures, 1 table", "summary": "Machine learning is a powerful tool for building predictive models. However,\nit is vulnerable to adversarial attacks. Fast Gradient Sign Method (FGSM)\nattacks are a common type of adversarial attack that adds small perturbations\nto input data to trick a model into misclassifying it. In response to these\nattacks, researchers have developed methods for \"unlearning\" these attacks,\nwhich involves retraining a model on the original data without the added\nperturbations. Machine unlearning is a technique that tries to \"forget\"\nspecific data points from the training dataset, to improve the robustness of a\nmachine learning model against adversarial attacks like FGSM. In this paper, we\nfocus on applying unlearning techniques to the LeNet neural network, a popular\narchitecture for image classification. We evaluate the efficacy of unlearning\nFGSM attacks on the LeNet network and find that it can significantly improve\nits robustness against these types of attacks.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u5c06\u673a\u5668\u5b66\u4e60\u7684\u53bb\u5b66\u4e60\u6280\u672f\u5e94\u7528\u4e8eLeNet\u795e\u7ecf\u7f51\u7edc\uff0c\u8bc4\u4f30\u5176\u5e94\u5bf9FGSM\u653b\u51fb\u7684\u6548\u679c\uff0c\u53d1\u73b0\u80fd\u663e\u8457\u63d0\u5347\u7f51\u7edc\u9c81\u68d2\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6613\u53d7\u5bf9\u6297\u653b\u51fb\uff0cFGSM\u653b\u51fb\u5e38\u89c1\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u5bf9FGSM\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u7814\u7a76\u5e94\u7528\u53bb\u5b66\u4e60\u6280\u672f\u3002", "method": "\u5c06\u53bb\u5b66\u4e60\u6280\u672f\u5e94\u7528\u5230LeNet\u795e\u7ecf\u7f51\u7edc\uff0c\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53bb\u5b66\u4e60\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347LeNet\u7f51\u7edc\u5bf9FGSM\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u53bb\u5b66\u4e60\u6280\u672f\u53ef\u6709\u6548\u63d0\u5347LeNet\u795e\u7ecf\u7f51\u7edc\u5e94\u5bf9FGSM\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.00392", "pdf": "https://arxiv.org/pdf/2511.00392", "abs": "https://arxiv.org/abs/2511.00392", "authors": ["Lingpeng Chen", "Jiakun Tang", "Apple Pui-Yi Chui", "Ziyang Hong", "Junfeng Wu"], "title": "SonarSweep: Fusing Sonar and Vision for Robust 3D Reconstruction via Plane Sweeping", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "8 pages, 9 figures, conference", "summary": "Accurate 3D reconstruction in visually-degraded underwater environments\nremains a formidable challenge. Single-modality approaches are insufficient:\nvision-based methods fail due to poor visibility and geometric constraints,\nwhile sonar is crippled by inherent elevation ambiguity and low resolution.\nConsequently, prior fusion technique relies on heuristics and flawed geometric\nassumptions, leading to significant artifacts and an inability to model complex\nscenes. In this paper, we introduce SonarSweep, a novel, end-to-end deep\nlearning framework that overcomes these limitations by adapting the principled\nplane sweep algorithm for cross-modal fusion between sonar and visual data.\nExtensive experiments in both high-fidelity simulation and real-world\nenvironments demonstrate that SonarSweep consistently generates dense and\naccurate depth maps, significantly outperforming state-of-the-art methods\nacross challenging conditions, particularly in high turbidity. To foster\nfurther research, we will publicly release our code and a novel dataset\nfeaturing synchronized stereo-camera and sonar data, the first of its kind.", "AI": {"tldr": "\u63d0\u51faSonarSweep\u6846\u67b6\u7528\u4e8e\u6c34\u4e0b3D\u91cd\u5efa\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\uff0c\u5c06\u53d1\u5e03\u4ee3\u7801\u548c\u6570\u636e\u96c6", "motivation": "\u73b0\u6709\u5355\u6a21\u6001\u548c\u878d\u5408\u6280\u672f\u5728\u6c34\u4e0b3D\u91cd\u5efa\u4e2d\u6709\u5c40\u9650\uff0c\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u573a\u666f", "method": "\u5f15\u5165SonarSweep\uff0c\u91c7\u7528\u5e73\u9762\u626b\u63cf\u7b97\u6cd5\u8fdb\u884c\u58f0\u7eb3\u548c\u89c6\u89c9\u6570\u636e\u8de8\u6a21\u6001\u878d\u5408", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u73af\u5883\u5b9e\u9a8c\u4e2d\uff0cSonarSweep\u80fd\u751f\u6210\u5bc6\u96c6\u51c6\u786e\u6df1\u5ea6\u56fe\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "SonarSweep\u6709\u6548\u514b\u670d\u73b0\u6709\u5c40\u9650\uff0c\u5c06\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\u96c6\u63a8\u52a8\u7814\u7a76"}}
{"id": "2511.01385", "pdf": "https://arxiv.org/pdf/2511.01385", "abs": "https://arxiv.org/abs/2511.01385", "authors": ["Xinyu Ding", "Bangtian Liu", "Siyu Liao", "Zhongfeng Wang"], "title": "Memory-Efficient Training with In-Place FFT Implementation", "categories": ["cs.LG", "I.2.6; G.1.2; D.1.3"], "comment": "Accepted at NeurIPS 2025. Presents a real-domain in-place FFT (rdFFT)\n  operator for memory-efficient fine-tuning of large language models", "summary": "Fast Fourier Transforms (FFT) are widely used to reduce memory and\ncomputational costs in deep learning. However, existing implementations,\nincluding standard FFT and real FFT (rFFT), cannot achieve true in-place\ncomputation. In particular, rFFT maps an input of size n to a complex output of\nsize n/2+1, causing dimensional mismatch and requiring additional memory\nallocation. We propose the first real-domain, fully in-place FFT framework\n(rdFFT) that preserves input-output memory space consistency. By leveraging\nbutterfly operation symmetry and conjugate properties in the frequency domain,\nwe design an implicit complex encoding scheme that eliminates intermediate\ncache usage entirely. Experiments on multiple natural language understanding\ntasks demonstrate the method effectiveness in reducing training memory cost,\noffering a promising direction for frequency-domain lightweight adaptation.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5b9e\u57df\u5168\u5c31\u5730FFT\u6846\u67b6rdFFT\uff0c\u53ef\u51cf\u5c11\u8bad\u7ec3\u5185\u5b58\u6210\u672c\uff0c\u4e3a\u9891\u57df\u8f7b\u91cf\u7ea7\u9002\u914d\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u73b0\u6709FFT\u5b9e\u73b0\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u5c31\u5730\u8ba1\u7b97\uff0crFFT\u5b58\u5728\u7ef4\u5ea6\u4e0d\u5339\u914d\u548c\u989d\u5916\u5185\u5b58\u5206\u914d\u95ee\u9898\u3002", "method": "\u5229\u7528\u8776\u5f62\u8fd0\u7b97\u5bf9\u79f0\u6027\u548c\u9891\u57df\u5171\u8f6d\u7279\u6027\uff0c\u8bbe\u8ba1\u9690\u5f0f\u590d\u6570\u7f16\u7801\u65b9\u6848\uff0c\u6d88\u9664\u4e2d\u95f4\u7f13\u5b58\u4f7f\u7528\u3002", "result": "\u5728\u591a\u4e2a\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u8bad\u7ec3\u5185\u5b58\u6210\u672c\u3002", "conclusion": "rdFFT\u4e3a\u9891\u57df\u8f7b\u91cf\u7ea7\u9002\u914d\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.00402", "pdf": "https://arxiv.org/pdf/2511.00402", "abs": "https://arxiv.org/abs/2511.00402", "authors": ["Lucky Onyekwelu-Udoka", "Md Shafiqul Islam", "Md Shahedul Hasan"], "title": "Emotion Detection in Speech Using Lightweight and Transformer-Based Models: A Comparative and Ablation Study", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Emotion recognition from speech plays a vital role in the development of\nempathetic human-computer interaction systems. This paper presents a\ncomparative analysis of lightweight transformer-based models, DistilHuBERT and\nPaSST, by classifying six core emotions from the CREMA-D dataset. We benchmark\ntheir performance against a traditional CNN-LSTM baseline model using MFCC\nfeatures. DistilHuBERT demonstrates superior accuracy (70.64%) and F1 score\n(70.36%) while maintaining an exceptionally small model size (0.02 MB),\noutperforming both PaSST and the baseline. Furthermore, we conducted an\nablation study on three variants of the PaSST, Linear, MLP, and Attentive\nPooling heads, to understand the effect of classification head architecture on\nmodel performance. Our results indicate that PaSST with an MLP head yields the\nbest performance among its variants but still falls short of DistilHuBERT.\nAmong the emotion classes, angry is consistently the most accurately detected,\nwhile disgust remains the most challenging. These findings suggest that\nlightweight transformers like DistilHuBERT offer a compelling solution for\nreal-time speech emotion recognition on edge devices. The code is available at:\nhttps://github.com/luckymaduabuchi/Emotion-detection-.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u5206\u6790DistilHuBERT\u548cPaSST\u4e24\u79cd\u8f7b\u91cf\u7ea7\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u7528\u4e8e\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\uff0c\u53d1\u73b0DistilHuBERT\u6027\u80fd\u6700\u4f73\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u5b9e\u65f6\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u5bf9\u5171\u60c5\u4eba\u673a\u4ea4\u4e92\u7cfb\u7edf\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u9700\u7814\u7a76\u8f7b\u91cf\u7ea7\u6a21\u578b\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u5b9e\u65f6\u8bc6\u522b\u3002", "method": "\u4f7f\u7528CREMA - D\u6570\u636e\u96c6\u5bf9\u516d\u79cd\u6838\u5fc3\u60c5\u611f\u5206\u7c7b\uff0c\u5bf9\u6bd4DistilHuBERT\u3001PaSST\u548c\u4f20\u7edfCNN - LSTM\u57fa\u7ebf\u6a21\u578b\uff0c\u5bf9PaSST\u7684\u4e09\u79cd\u53d8\u4f53\u8fdb\u884c\u6d88\u878d\u7814\u7a76\u3002", "result": "DistilHuBERT\u51c6\u786e\u738770.64%\u3001F1\u5206\u657070.36%\uff0c\u6a21\u578b\u5927\u5c0f0.02 MB\uff0c\u6027\u80fd\u6700\u4f73\uff1bPaSST\u7684MLP\u5934\u53d8\u4f53\u8868\u73b0\u6700\u597d\u4f46\u4e0d\u5982DistilHuBERT\uff1b\u6124\u6012\u60c5\u611f\u6700\u6613\u68c0\u6d4b\uff0c\u538c\u6076\u6700\u96be\u3002", "conclusion": "\u50cfDistilHuBERT\u8fd9\u6837\u7684\u8f7b\u91cf\u7ea7Transformer\u4e3a\u8fb9\u7f18\u8bbe\u5907\u5b9e\u65f6\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u63d0\u4f9b\u4e86\u6709\u5438\u5f15\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01408", "pdf": "https://arxiv.org/pdf/2511.01408", "abs": "https://arxiv.org/abs/2511.01408", "authors": ["Markus B. Pettersson", "Adel Daoud"], "title": "Leveraging Compact Satellite Embeddings and Graph Neural Networks for Large-Scale Poverty Mapping", "categories": ["cs.LG"], "comment": null, "summary": "Accurate, fine-grained poverty maps remain scarce across much of the Global\nSouth. While Demographic and Health Surveys (DHS) provide high-quality\nsocioeconomic data, their spatial coverage is limited and reported coordinates\nare randomly displaced for privacy, further reducing their quality. We propose\na graph-based approach leveraging low-dimensional AlphaEarth satellite\nembeddings to predict cluster-level wealth indices across Sub-Saharan Africa.\nBy modeling spatial relations between surveyed and unlabeled locations, and by\nintroducing a probabilistic \"fuzzy label\" loss to account for coordinate\ndisplacement, we improve the generalization of wealth predictions beyond\nexisting surveys. Our experiments on 37 DHS datasets (2017-2023) show that\nincorporating graph structure slightly improves accuracy compared to\n\"image-only\" baselines, demonstrating the potential of compact EO embeddings\nfor large-scale socioeconomic mapping.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4f4e\u7ef4\u536b\u661f\u5d4c\u5165\u9884\u6d4b\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u5730\u533a\u96c6\u7fa4\u5c42\u9762\u8d22\u5bcc\u6307\u6570\uff0c\u5b9e\u9a8c\u663e\u793a\u7ed3\u5408\u56fe\u7ed3\u6784\u53ef\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5168\u7403\u5357\u65b9\u5927\u90e8\u5206\u5730\u533a\u7f3a\u4e4f\u51c6\u786e\u3001\u7ec6\u7c92\u5ea6\u7684\u8d2b\u56f0\u5730\u56fe\uff0c\u4eba\u53e3\u4e0e\u5065\u5eb7\u8c03\u67e5\uff08DHS\uff09\u6570\u636e\u5b58\u5728\u7a7a\u95f4\u8986\u76d6\u6709\u9650\u548c\u5750\u6807\u968f\u673a\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4f4e\u7ef4AlphaEarth\u536b\u661f\u5d4c\u5165\uff0c\u5efa\u6a21\u8c03\u67e5\u548c\u672a\u6807\u8bb0\u5730\u70b9\u7684\u7a7a\u95f4\u5173\u7cfb\uff0c\u5f15\u5165\u6982\u7387\u201c\u6a21\u7cca\u6807\u7b7e\u201d\u635f\u5931\u5904\u7406\u5750\u6807\u504f\u79fb\u3002", "result": "\u572837\u4e2aDHS\u6570\u636e\u96c6\uff082017 - 2023\uff09\u4e0a\u5b9e\u9a8c\uff0c\u7ed3\u5408\u56fe\u7ed3\u6784\u6bd4\u201c\u4ec5\u56fe\u50cf\u201d\u57fa\u7ebf\u7565\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u7d27\u51d1\u7684\u5730\u7403\u89c2\u6d4b\u5d4c\u5165\u5728\u5927\u89c4\u6a21\u793e\u4f1a\u7ecf\u6d4e\u5236\u56fe\u65b9\u9762\u6709\u6f5c\u529b\u3002"}}
{"id": "2511.01433", "pdf": "https://arxiv.org/pdf/2511.01433", "abs": "https://arxiv.org/abs/2511.01433", "authors": ["Seunghun Yu", "Youngjoon Lee", "Jinu Gong", "Joonhyuk Kang"], "title": "CG-FKAN: Compressed-Grid Federated Kolmogorov-Arnold Networks for Communication Constrained Environment", "categories": ["cs.LG"], "comment": "5 pages", "summary": "Federated learning (FL), widely used in privacy-critical applications,\nsuffers from limited interpretability, whereas Kolmogorov-Arnold Networks (KAN)\naddress this limitation via learnable spline functions. However, existing FL\nstudies applying KAN overlook the communication overhead introduced by grid\nextension, which is essential for modeling complex functions. In this letter,\nwe propose CG-FKAN, which compresses extended grids by sparsifying and\ntransmitting only essential coefficients under a communication budget.\nExperiments show that CG-FKAN achieves up to 13.6% lower RMSE than fixed-grid\nKAN in communication-constrained settings. In addition, we derive a theoretical\nupper bound on its approximation error.", "AI": {"tldr": "\u63d0\u51faCG - FKAN\u538b\u7f29\u6269\u5c55\u7f51\u683c\uff0c\u5728\u901a\u4fe1\u53d7\u9650\u573a\u666f\u4e0b\u964d\u4f4eRMSE\u5e76\u63a8\u5bfc\u8fd1\u4f3c\u8bef\u5dee\u7406\u8bba\u4e0a\u754c", "motivation": "\u73b0\u6709\u5e94\u7528KAN\u7684\u8054\u90a6\u5b66\u4e60\u7814\u7a76\u5ffd\u7565\u7f51\u683c\u6269\u5c55\u5e26\u6765\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u800c\u7f51\u683c\u6269\u5c55\u5bf9\u5efa\u6a21\u590d\u6742\u51fd\u6570\u5f88\u91cd\u8981", "method": "\u63d0\u51faCG - FKAN\uff0c\u5728\u901a\u4fe1\u9884\u7b97\u4e0b\u901a\u8fc7\u7a00\u758f\u5316\u5e76\u4ec5\u4f20\u8f93\u5fc5\u8981\u7cfb\u6570\u6765\u538b\u7f29\u6269\u5c55\u7f51\u683c", "result": "\u5b9e\u9a8c\u8868\u660eCG - FKAN\u5728\u901a\u4fe1\u53d7\u9650\u573a\u666f\u4e0b\u6bd4\u56fa\u5b9a\u7f51\u683cKAN\u7684RMSE\u6700\u591a\u964d\u4f4e13.6%\uff0c\u5e76\u63a8\u5bfc\u5176\u8fd1\u4f3c\u8bef\u5dee\u7684\u7406\u8bba\u4e0a\u754c", "conclusion": "CG - FKAN\u80fd\u6709\u6548\u5e94\u5bf9\u5e94\u7528KAN\u7684\u8054\u90a6\u5b66\u4e60\u4e2d\u7f51\u683c\u6269\u5c55\u5e26\u6765\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898"}}
{"id": "2511.00406", "pdf": "https://arxiv.org/pdf/2511.00406", "abs": "https://arxiv.org/abs/2511.00406", "authors": ["Thanveer Shaik", "Xiaohui Tao", "Haoran Xie", "Robert Sang"], "title": "Quantum Machine Unlearning: Foundations, Mechanisms, and Taxonomy", "categories": ["quant-ph", "cs.AI"], "comment": null, "summary": "Quantum Machine Unlearning has emerged as a foundational challenge at the\nintersection of quantum information theory privacypreserving computation and\ntrustworthy artificial intelligence This paper advances QMU by establishing a\nformal framework that unifies physical constraints algorithmic mechanisms and\nethical governance within a verifiable paradigm We define forgetting as a\ncontraction of distinguishability between pre and postunlearning models under\ncompletely positive trace-preserving dynamics grounding data removal in the\nphysics of quantum irreversibility Building on this foundation we present a\nfiveaxis taxonomy spanning scope guarantees mechanisms system context and\nhardware realization linking theoretical constructs to implementable strategies\nWithin this structure we incorporate influence and quantum Fisher information\nweighted updates parameter reinitialization and kernel alignment as practical\nmechanisms compatible with noisy intermediatescale quantum NISQ devices The\nframework extends naturally to federated and privacyaware settings via quantum\ndifferential privacy homomorphic encryption and verifiable delegation enabling\nscalable auditable deletion across distributed quantum systems Beyond technical\ndesign we outline a forwardlooking research roadmap emphasizing formal proofs\nof forgetting scalable and secure architectures postunlearning interpretability\nand ethically auditable governance Together these contributions elevate QMU\nfrom a conceptual notion to a rigorously defined and ethically aligned\ndiscipline bridging physical feasibility algorithmic verifiability and societal\naccountability in the emerging era of quantum intelligence.", "AI": {"tldr": "\u672c\u6587\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9057\u5fd8\uff08QMU\uff09\u5efa\u7acb\u7edf\u4e00\u5f62\u5f0f\u6846\u67b6\uff0c\u63d0\u51fa\u4e94\u8f74\u5206\u7c7b\u6cd5\u53ca\u5b9e\u7528\u673a\u5236\uff0c\u6846\u67b6\u53ef\u6269\u5c55\u5230\u8054\u5408\u548c\u9690\u79c1\u611f\u77e5\u573a\u666f\uff0c\u8fd8\u7ed9\u51fa\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u4f7fQMU\u6210\u4e3a\u4e25\u8c28\u5b66\u79d1\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u662f\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u3001\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u548c\u53ef\u4fe1\u4eba\u5de5\u667a\u80fd\u4ea4\u53c9\u9886\u57df\u7684\u57fa\u7840\u6311\u6218\uff0c\u9700\u8981\u63a8\u8fdb\u5176\u53d1\u5c55\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7269\u7406\u7ea6\u675f\u3001\u7b97\u6cd5\u673a\u5236\u548c\u4f26\u7406\u6cbb\u7406\u7684\u53ef\u9a8c\u8bc1\u5f62\u5f0f\u6846\u67b6\uff0c\u5b9a\u4e49\u9057\u5fd8\u6982\u5ff5\uff0c\u63d0\u51fa\u4e94\u8f74\u5206\u7c7b\u6cd5\uff0c\u7ed3\u5408\u5b9e\u7528\u673a\u5236\uff0c\u5229\u7528\u91cf\u5b50\u5dee\u5206\u9690\u79c1\u7b49\u6269\u5c55\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u9002\u7528\u4e8eNISQ\u8bbe\u5907\u7684\u6846\u67b6\uff0c\u53ef\u6269\u5c55\u5230\u5206\u5e03\u5f0f\u91cf\u5b50\u7cfb\u7edf\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u5ba1\u8ba1\u7684\u5220\u9664\u3002", "conclusion": "\u8fd9\u4e9b\u8d21\u732e\u4f7fQMU\u4ece\u6982\u5ff5\u53d8\u4e3a\u4e25\u8c28\u4e14\u7b26\u5408\u4f26\u7406\u7684\u5b66\u79d1\uff0c\u6865\u63a5\u7269\u7406\u53ef\u884c\u6027\u3001\u7b97\u6cd5\u53ef\u9a8c\u8bc1\u6027\u548c\u793e\u4f1a\u8d23\u4efb\u3002"}}
{"id": "2511.01438", "pdf": "https://arxiv.org/pdf/2511.01438", "abs": "https://arxiv.org/abs/2511.01438", "authors": ["Jacob Poschl"], "title": "The Curvature Rate \u03bb: A Scalar Measure of Input-Space Sharpness in Neural Networks", "categories": ["cs.LG"], "comment": "14 pages", "summary": "Curvature influences generalization, robustness, and how reliably neural\nnetworks respond to small input perturbations. Existing sharpness metrics are\ntypically defined in parameter space (e.g., Hessian eigenvalues) and can be\nexpensive, sensitive to reparameterization, and difficult to interpret in\nfunctional terms. We introduce a scalar curvature measure defined directly in\ninput space: the curvature rate {\\lambda}, given by the exponential growth rate\nof higher-order input derivatives. Empirically, {\\lambda} is estimated as the\nslope of log ||D^n f|| versus n for small n. This growth-rate perspective\nunifies classical analytic quantities: for analytic functions, {\\lambda}\ncorresponds to the inverse radius of convergence, and for bandlimited signals,\nit reflects the spectral cutoff. The same principle extends to neural networks,\nwhere {\\lambda} tracks the emergence of high-frequency structure in the\ndecision boundary. Experiments on analytic functions and neural networks (Two\nMoons and MNIST) show that {\\lambda} evolves predictably during training and\ncan be directly shaped using a simple derivative-based regularizer, Curvature\nRate Regularization (CRR). Compared to Sharpness-Aware Minimization (SAM), CRR\nachieves similar accuracy while yielding flatter input-space geometry and\nimproved confidence calibration. By grounding curvature in differentiation\ndynamics, {\\lambda} provides a compact, interpretable, and\nparameterization-invariant descriptor of functional smoothness in learned\nmodels.", "AI": {"tldr": "\u63d0\u51fa\u8f93\u5165\u7a7a\u95f4\u6807\u91cf\u66f2\u7387\u5ea6\u91cf\u03bb\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u8bad\u7ec3\u4e2d\u53ef\u9884\u6d4b\u6f14\u53d8\uff0c\u7528CRR\u53ef\u5851\u5f62\uff0c\u6bd4SAM\u6709\u4f18\u52bf\uff0c\u80fd\u63cf\u8ff0\u6a21\u578b\u5e73\u6ed1\u6027\u3002", "motivation": "\u73b0\u6709\u9510\u5ea6\u5ea6\u91cf\u5728\u53c2\u6570\u7a7a\u95f4\u5b9a\u4e49\uff0c\u5b58\u5728\u8ba1\u7b97\u6602\u8d35\u3001\u5bf9\u91cd\u53c2\u6570\u5316\u654f\u611f\u548c\u96be\u529f\u80fd\u89e3\u91ca\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8f93\u5165\u7a7a\u95f4\u66f2\u7387\u7387\u03bb\uff0c\u901a\u8fc7\u9ad8\u9636\u8f93\u5165\u5bfc\u6570\u6307\u6570\u589e\u957f\u7387\u5b9a\u4e49\uff0c\u7ecf\u9a8c\u4e0a\u7528\u5c0fn\u65f6log ||D^n f|| \u4e0en\u7684\u659c\u7387\u4f30\u8ba1\uff0c\u63d0\u51fa\u66f2\u7387\u7387\u6b63\u5219\u5316\uff08CRR\uff09\u3002", "result": "\u03bb\u5728\u8bad\u7ec3\u4e2d\u53ef\u9884\u6d4b\u6f14\u53d8\uff0c\u7528CRR\u53ef\u5851\u5f62\uff0c\u76f8\u6bd4SAM\uff0c\u8fbe\u5230\u76f8\u4f3c\u7cbe\u5ea6\u4e14\u8f93\u5165\u7a7a\u95f4\u51e0\u4f55\u66f4\u5e73\u5766\u3001\u7f6e\u4fe1\u6821\u51c6\u66f4\u597d\u3002", "conclusion": "\u03bb\u4ee5\u5fae\u5206\u52a8\u529b\u5b66\u4e3a\u57fa\u7840\uff0c\u4e3a\u5b66\u4e60\u6a21\u578b\u529f\u80fd\u5e73\u6ed1\u6027\u63d0\u4f9b\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u548c\u53c2\u6570\u4e0d\u53d8\u63cf\u8ff0\u7b26\u3002"}}
{"id": "2511.01443", "pdf": "https://arxiv.org/pdf/2511.01443", "abs": "https://arxiv.org/abs/2511.01443", "authors": ["Chaoqun Fei", "Tinglve Zhou", "Tianyong Hao", "Yangyang Li"], "title": "Efficient Curvature-aware Graph Network", "categories": ["cs.LG"], "comment": null, "summary": "Graph curvature provides geometric priors for Graph Neural Networks (GNNs),\nenhancing their ability to model complex graph structures, particularly in\nterms of structural awareness, robustness, and theoretical interpretability.\nAmong existing methods, Ollivier-Ricci curvature has been extensively studied\ndue to its strong geometric interpretability, effectively characterizing the\nlocal geometric distribution between nodes. However, its prohibitively high\ncomputational complexity limits its applicability to large-scale graph\ndatasets. To address this challenge, we propose a novel graph curvature\nmeasure--Effective Resistance Curvature--which quantifies the ease of message\npassing along graph edges using the effective resistance between node pairs,\ninstead of the optimal transport distance. This method significantly\noutperforms Ollivier-Ricci curvature in computational efficiency while\npreserving comparable geometric expressiveness. Theoretically, we prove the low\ncomputational complexity of effective resistance curvature and establish its\nsubstitutability for Ollivier-Ricci curvature. Furthermore, extensive\nexperiments on diverse GNN tasks demonstrate that our method achieves\ncompetitive performance with Ollivier-Ricci curvature while drastically\nreducing computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u6709\u6548\u7535\u963b\u66f2\u7387\u89e3\u51b3Ollivier - Ricci\u66f2\u7387\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u95ee\u9898\uff0c\u6027\u80fd\u76f8\u5f53\u4f46\u8ba1\u7b97\u5f00\u9500\u5927\u5e45\u964d\u4f4e\u3002", "motivation": "\u73b0\u6709Ollivier - Ricci\u66f2\u7387\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9650\u5236\u5176\u5728\u5927\u89c4\u6a21\u56fe\u6570\u636e\u96c6\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6709\u6548\u7535\u963b\u66f2\u7387\uff0c\u7528\u8282\u70b9\u5bf9\u95f4\u6709\u6548\u7535\u963b\u91cf\u5316\u4fe1\u606f\u4f20\u9012\uff0c\u66ff\u4ee3\u6700\u4f18\u4f20\u8f93\u8ddd\u79bb\u3002", "result": "\u6709\u6548\u7535\u963b\u66f2\u7387\u8ba1\u7b97\u6548\u7387\u8fdc\u8d85Ollivier - Ricci\u66f2\u7387\uff0c\u51e0\u4f55\u8868\u8fbe\u80fd\u529b\u76f8\u5f53\uff1b\u7406\u8bba\u8bc1\u660e\u5176\u4f4e\u590d\u6742\u5ea6\u548c\u53ef\u66ff\u4ee3\u6027\uff1b\u5b9e\u9a8c\u8868\u660e\u5728GNN\u4efb\u52a1\u4e2d\u6027\u80fd\u76f8\u5f53\u4e14\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u6709\u6548\u7535\u963b\u66f2\u7387\u662f\u4e00\u79cd\u53ef\u66ff\u4ee3Ollivier - Ricci\u66f2\u7387\u7684\u9ad8\u6548\u56fe\u66f2\u7387\u5ea6\u91cf\u65b9\u6cd5\u3002"}}
{"id": "2511.00416", "pdf": "https://arxiv.org/pdf/2511.00416", "abs": "https://arxiv.org/abs/2511.00416", "authors": ["Yiwei Zha", "Rui Min", "Shanu Sushmita"], "title": "PADBen: A Comprehensive Benchmark for Evaluating AI Text Detectors Against Paraphrase Attacks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While AI-generated text (AIGT) detectors achieve over 90\\% accuracy on direct\nLLM outputs, they fail catastrophically against iteratively-paraphrased\ncontent. We investigate why iteratively-paraphrased text -- itself AI-generated\n-- evades detection systems designed for AIGT identification. Through intrinsic\nmechanism analysis, we reveal that iterative paraphrasing creates an\nintermediate laundering region characterized by semantic displacement with\npreserved generation patterns, which brings up two attack categories:\nparaphrasing human-authored text (authorship obfuscation) and paraphrasing\nLLM-generated text (plagiarism evasion). To address these vulnerabilities, we\nintroduce PADBen, the first benchmark systematically evaluating detector\nrobustness against both paraphrase attack scenarios. PADBen comprises a\nfive-type text taxonomy capturing the full trajectory from original content to\ndeeply laundered text, and five progressive detection tasks across\nsentence-pair and single-sentence challenges. We evaluate 11 state-of-the-art\ndetectors, revealing critical asymmetry: detectors successfully identify the\nplagiarism evasion problem but fail for the case of authorship obfuscation. Our\nfindings demonstrate that current detection approaches cannot effectively\nhandle the intermediate laundering region, necessitating fundamental advances\nin detection architectures beyond existing semantic and stylistic\ndiscrimination methods. For detailed code implementation, please see\nhttps://github.com/JonathanZha47/PadBen-Paraphrase-Attack-Benchmark.", "AI": {"tldr": "\u7814\u7a76AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u5668\u5bf9\u8fed\u4ee3\u91ca\u4e49\u6587\u672c\u68c0\u6d4b\u5931\u6548\u539f\u56e0\uff0c\u63d0\u51faPADBen\u57fa\u51c6\u8bc4\u4f30\u5176\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u68c0\u6d4b\u5668\u5e94\u5bf9\u4f5c\u8005\u8eab\u4efd\u6df7\u6dc6\u653b\u51fb\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u67b6\u6784\u6539\u8fdb\u3002", "motivation": "\u63a2\u7a76\u8fed\u4ee3\u91ca\u4e49\u7684AI\u751f\u6210\u6587\u672c\u80fd\u9003\u907f\u68c0\u6d4b\u7cfb\u7edf\u7684\u539f\u56e0\uff0c\u89e3\u51b3\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u7684\u6f0f\u6d1e\u3002", "method": "\u8fdb\u884c\u5185\u5728\u673a\u5236\u5206\u6790\uff0c\u63d0\u51faPADBen\u57fa\u51c6\uff0c\u5305\u542b\u4e94\u7c7b\u578b\u6587\u672c\u5206\u7c7b\u548c\u4e94\u9879\u68c0\u6d4b\u4efb\u52a1\uff0c\u8bc4\u4f3011\u4e2a\u5148\u8fdb\u68c0\u6d4b\u5668\u3002", "result": "\u53d1\u73b0\u68c0\u6d4b\u5668\u80fd\u8bc6\u522b\u6284\u88ad\u9003\u907f\u95ee\u9898\uff0c\u4f46\u5e94\u5bf9\u4f5c\u8005\u8eab\u4efd\u6df7\u6dc6\u653b\u51fb\u5931\u8d25\u3002", "conclusion": "\u5f53\u524d\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4e2d\u95f4\u6e05\u6d17\u533a\u57df\uff0c\u9700\u5728\u68c0\u6d4b\u67b6\u6784\u4e0a\u53d6\u5f97\u6839\u672c\u8fdb\u5c55\u3002"}}
{"id": "2511.01468", "pdf": "https://arxiv.org/pdf/2511.01468", "abs": "https://arxiv.org/abs/2511.01468", "authors": ["Hao Wang", "Zixuan Weng", "Jindong Han", "Wei Fan", "Hao Liu"], "title": "DAMBench: A Multi-Modal Benchmark for Deep Learning-based Atmospheric Data Assimilation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Data Assimilation is a cornerstone of atmospheric system modeling, tasked\nwith reconstructing system states by integrating sparse, noisy observations\nwith prior estimation. While traditional approaches like variational and\nensemble Kalman filtering have proven effective, recent advances in deep\nlearning offer more scalable, efficient, and flexible alternatives better\nsuited for complex, real-world data assimilation involving large-scale and\nmulti-modal observations. However, existing deep learning-based DA research\nsuffers from two critical limitations: (1) reliance on oversimplified scenarios\nwith synthetically perturbed observations, and (2) the absence of standardized\nbenchmarks for fair model comparison. To address these gaps, in this work, we\nintroduce DAMBench, the first large-scale multi-modal benchmark designed to\nevaluate data-driven DA models under realistic atmospheric conditions. DAMBench\nintegrates high-quality background states from state-of-the-art forecasting\nsystems and real-world multi-modal observations (i.e., real-world weather\nstations and satellite imagery). All data are resampled to a common grid and\ntemporally aligned to support systematic training, validation, and testing. We\nprovide unified evaluation protocols and benchmark representative data\nassimilation approaches, including latent generative models and neural process\nframeworks. Additionally, we propose a lightweight multi-modal plugin to\ndemonstrate how integrating realistic observations can enhance even simple\nbaselines. Through comprehensive experiments, DAMBench establishes a rigorous\nfoundation for future research, promoting reproducibility, fair comparison, and\nextensibility to real-world multi-modal scenarios. Our dataset and code are\npublicly available at https://github.com/figerhaowang/DAMBench.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u9996\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u57fa\u51c6DAMBench\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u6c14\u6570\u636e\u540c\u5316\u6a21\u578b\uff0c\u63d0\u4f9b\u7edf\u4e00\u8bc4\u4f30\u534f\u8bae\u5e76\u5c55\u793a\u63d2\u4ef6\u6548\u679c\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u516c\u5f00\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6570\u636e\u540c\u5316\u7814\u7a76\u4f9d\u8d56\u7b80\u5316\u573a\u666f\u4e14\u7f3a\u4e4f\u6807\u51c6\u57fa\u51c6\uff0c\u65e0\u6cd5\u516c\u5e73\u6bd4\u8f83\u6a21\u578b\u3002", "method": "\u5f15\u5165DAMBench\uff0c\u6574\u5408\u9ad8\u8d28\u91cf\u80cc\u666f\u72b6\u6001\u548c\u591a\u6a21\u6001\u89c2\u6d4b\u6570\u636e\uff0c\u91cd\u91c7\u6837\u548c\u65f6\u95f4\u5bf9\u9f50\uff0c\u63d0\u4f9b\u8bc4\u4f30\u534f\u8bae\uff0c\u6d4b\u8bd5\u4ee3\u8868\u6027\u65b9\u6cd5\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u591a\u6a21\u6001\u63d2\u4ef6\u3002", "result": "\u901a\u8fc7\u5168\u9762\u5b9e\u9a8c\uff0cDAMBench\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e25\u8c28\u57fa\u7840\uff0c\u4fc3\u8fdb\u53ef\u91cd\u590d\u6027\u3001\u516c\u5e73\u6bd4\u8f83\u548c\u6269\u5c55\u6027\u3002", "conclusion": "DAMBench\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u7684\u5c40\u9650\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u573a\u666f\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u516c\u5f00\u53ef\u63a8\u52a8\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2511.00419", "pdf": "https://arxiv.org/pdf/2511.00419", "abs": "https://arxiv.org/abs/2511.00419", "authors": ["Thanh Hieu Cao", "Trung Khang Tran", "Gia Thinh Pham", "Tuong Nghiem Diep", "Thanh Binh Nguyen"], "title": "LGCA: Enhancing Semantic Representation via Progressive Expansion", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, 5 figures, to appear in SoICT 2025", "summary": "Recent advancements in large-scale pretraining in natural language processing\nhave enabled pretrained vision-language models such as CLIP to effectively\nalign images and text, significantly improving performance in zero-shot image\nclassification tasks. Subsequent studies have further demonstrated that\ncropping images into smaller regions and using large language models to\ngenerate multiple descriptions for each caption can further enhance model\nperformance. However, due to the inherent sensitivity of CLIP, random image\ncrops can introduce misinformation and bias, as many images share similar\nfeatures at small scales. To address this issue, we propose\nLocalized-Globalized Cross-Alignment (LGCA), a framework that first captures\nthe local features of an image and then repeatedly selects the most salient\nregions and expands them. The similarity score is designed to incorporate both\nthe original and expanded images, enabling the model to capture both local and\nglobal features while minimizing misinformation. Additionally, we provide a\ntheoretical analysis demonstrating that the time complexity of LGCA remains the\nsame as that of the original model prior to the repeated expansion process,\nhighlighting its efficiency and scalability. Extensive experiments demonstrate\nthat our method substantially improves zero-shot performance across diverse\ndatasets, outperforming state-of-the-art baselines.", "AI": {"tldr": "\u73b0\u6709\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5982CLIP\u5728\u96f6\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u8868\u73b0\u597d\uff0c\u4f46\u968f\u673a\u88c1\u526a\u56fe\u50cf\u4f1a\u5f15\u5165\u9519\u8bef\u4fe1\u606f\u548c\u504f\u5dee\u3002\u672c\u6587\u63d0\u51faLGCA\u6846\u67b6\uff0c\u80fd\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\uff0c\u51cf\u5c11\u9519\u8bef\u4fe1\u606f\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u96f6\u6837\u672c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3CLIP\u56e0\u968f\u673a\u88c1\u526a\u56fe\u50cf\u5f15\u5165\u9519\u8bef\u4fe1\u606f\u548c\u504f\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u96f6\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u63d0\u51faLocalized - Globalized Cross - Alignment (LGCA)\u6846\u67b6\uff0c\u5148\u6355\u6349\u56fe\u50cf\u5c40\u90e8\u7279\u5f81\uff0c\u53cd\u590d\u9009\u62e9\u6700\u663e\u8457\u533a\u57df\u5e76\u6269\u5c55\uff0c\u8bbe\u8ba1\u76f8\u4f3c\u5ea6\u5206\u6570\u7ed3\u5408\u539f\u59cb\u548c\u6269\u5c55\u56fe\u50cf\u3002", "result": "LGCA\u65f6\u95f4\u590d\u6742\u5ea6\u4e0e\u539f\u6a21\u578b\u5728\u91cd\u590d\u6269\u5c55\u8fc7\u7a0b\u524d\u76f8\u540c\uff0c\u4e14\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u96f6\u6837\u672c\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "LGCA\u6846\u67b6\u6709\u6548\u4e14\u9ad8\u6548\u53ef\u6269\u5c55\uff0c\u80fd\u63d0\u5347\u96f6\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2511.01570", "pdf": "https://arxiv.org/pdf/2511.01570", "abs": "https://arxiv.org/abs/2511.01570", "authors": ["Xiaosha Xue", "Peibo Duan", "Zhipeng Liu", "Qi Chu", "Changsheng Zhang", "Bin zhang"], "title": "Gated Fusion Enhanced Multi-Scale Hierarchical Graph Convolutional Network for Stock Movement Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Accurately predicting stock market movements remains a formidable challenge\ndue to the inherent volatility and complex interdependencies among stocks.\nAlthough multi-scale Graph Neural Networks (GNNs) hold potential for modeling\nthese relationships, they frequently neglect two key points: the subtle\nintra-attribute patterns within each stock affecting inter-stock correlation,\nand the biased attention to coarse- and fine-grained features during\nmulti-scale sampling. To overcome these challenges, we introduce MS-HGFN\n(Multi-Scale Hierarchical Graph Fusion Network). The model features a\nhierarchical GNN module that forms dynamic graphs by learning patterns from\nintra-attributes and features from inter-attributes over different time scales,\nthus comprehensively capturing spatio-temporal dependencies. Additionally, a\ntop-down gating approach facilitates the integration of multi-scale\nspatio-temporal features, preserving critical coarse- and fine-grained features\nwithout too much interference. Experiments utilizing real-world datasets from\nU.S. and Chinese stock markets demonstrate that MS-HGFN outperforms both\ntraditional and advanced models, yielding up to a 1.4% improvement in\nprediction accuracy and enhanced stability in return simulations. The code is\navailable at https://anonymous.4open.science/r/MS-HGFN.", "AI": {"tldr": "\u63d0\u51faMS - HGFN\u6a21\u578b\u89e3\u51b3\u591a\u5c3a\u5ea6GNN\u5728\u80a1\u5e02\u9884\u6d4b\u4e2d\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u548c\u5148\u8fdb\u6a21\u578b\uff0c\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u80a1\u5e02\u8d70\u52bf\u5177\u6709\u6311\u6218\u6027\uff0c\u591a\u5c3a\u5ea6GNN\u5728\u5efa\u6a21\u65f6\u5ffd\u7565\u4e86\u80a1\u7968\u5185\u90e8\u5c5e\u6027\u6a21\u5f0f\u548c\u591a\u5c3a\u5ea6\u91c7\u6837\u65f6\u5bf9\u7c97\u7ec6\u7c92\u5ea6\u7279\u5f81\u7684\u5173\u6ce8\u504f\u5dee\u3002", "method": "\u5f15\u5165MS - HGFN\u6a21\u578b\uff0c\u5305\u542b\u5206\u5c42GNN\u6a21\u5757\u5f62\u6210\u52a8\u6001\u56fe\u4ee5\u6355\u6349\u65f6\u7a7a\u4f9d\u8d56\uff0c\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u95e8\u63a7\u65b9\u6cd5\u96c6\u6210\u591a\u5c3a\u5ea6\u65f6\u7a7a\u7279\u5f81\u3002", "result": "\u5229\u7528\u7f8e\u4e2d\u80a1\u5e02\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\uff0cMS - HGFN\u4f18\u4e8e\u4f20\u7edf\u548c\u5148\u8fdb\u6a21\u578b\uff0c\u9884\u6d4b\u51c6\u786e\u7387\u6700\u591a\u63d0\u9ad81.4%\uff0c\u56de\u62a5\u6a21\u62df\u7a33\u5b9a\u6027\u589e\u5f3a\u3002", "conclusion": "MS - HGFN\u6a21\u578b\u5728\u80a1\u5e02\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u53ef\u6709\u6548\u89e3\u51b3\u591a\u5c3a\u5ea6GNN\u5b58\u5728\u7684\u95ee\u9898\u3002"}}
{"id": "2511.00421", "pdf": "https://arxiv.org/pdf/2511.00421", "abs": "https://arxiv.org/abs/2511.00421", "authors": ["Naoto Iwase", "Hiroki Okuyama", "Junichiro Iwasawa"], "title": "MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) show increasing promise in medical applications,\nbut their ability to detect and correct errors in clinical texts -- a\nprerequisite for safe deployment -- remains under-evaluated, particularly\nbeyond English. We introduce MedRECT, a cross-lingual benchmark\n(Japanese/English) that formulates medical error handling as three subtasks:\nerror detection, error localization (sentence extraction), and error\ncorrection. MedRECT is built with a scalable, automated pipeline from the\nJapanese Medical Licensing Examinations (JMLE) and a curated English\ncounterpart, yielding MedRECT-ja (663 texts) and MedRECT-en (458 texts) with\ncomparable error/no-error balance. We evaluate 9 contemporary LLMs spanning\nproprietary, open-weight, and reasoning families. Key findings: (i) reasoning\nmodels substantially outperform standard architectures, with up to 13.5%\nrelative improvement in error detection and 51.0% in sentence extraction; (ii)\ncross-lingual evaluation reveals 5-10% performance gaps from English to\nJapanese, with smaller disparities for reasoning models; (iii) targeted LoRA\nfine-tuning yields asymmetric improvements in error correction performance\n(Japanese: +0.078, English: +0.168) while preserving reasoning capabilities;\nand (iv) our fine-tuned model exceeds human expert performance on structured\nmedical error correction tasks. To our knowledge, MedRECT is the first\ncomprehensive cross-lingual benchmark for medical error correction, providing a\nreproducible framework and resources for developing safer medical LLMs across\nlanguages.", "AI": {"tldr": "\u4ecb\u7ecd\u8de8\u8bed\u8a00\u533b\u5b66\u9519\u8bef\u5904\u7406\u57fa\u51c6MedRECT\uff0c\u8bc4\u4f309\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u8868\u73b0\u597d\uff0c\u5fae\u8c03\u6709\u6539\u8fdb\uff0c\u6a21\u578b\u8d85\u4eba\u7c7b\u4e13\u5bb6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u5e94\u7528\u4e2d\u68c0\u6d4b\u548c\u7ea0\u6b63\u4e34\u5e8a\u6587\u672c\u9519\u8bef\u80fd\u529b\u8bc4\u4f30\u4e0d\u8db3\uff0c\u5c24\u5176\u975e\u82f1\u8bed\u9886\u57df\u3002", "method": "\u6784\u5efa\u8de8\u8bed\u8a00\u57fa\u51c6MedRECT\uff0c\u542b\u4e09\u4e2a\u5b50\u4efb\u52a1\uff0c\u7528\u65e5\u672c\u533b\u5b66\u6267\u7167\u8003\u8bd5\u548c\u82f1\u8bed\u5bf9\u5e94\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\uff0c\u8bc4\u4f309\u4e2a\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8fdb\u884cLoRA\u5fae\u8c03\u3002", "result": "\u63a8\u7406\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u67b6\u6784\uff1b\u8de8\u8bed\u8a00\u8bc4\u4f30\u82f1\u8bed\u5230\u65e5\u8bed\u67095 - 10%\u6027\u80fd\u5dee\u8ddd\uff0c\u63a8\u7406\u6a21\u578b\u5dee\u8ddd\u5c0f\uff1b\u5fae\u8c03\u5728\u9519\u8bef\u7ea0\u6b63\u6709\u4e0d\u5bf9\u79f0\u6539\u8fdb\uff1b\u5fae\u8c03\u6a21\u578b\u8d85\u4eba\u7c7b\u4e13\u5bb6\u3002", "conclusion": "MedRECT\u662f\u9996\u4e2a\u5168\u9762\u8de8\u8bed\u8a00\u533b\u5b66\u9519\u8bef\u7ea0\u6b63\u57fa\u51c6\uff0c\u4e3a\u5f00\u53d1\u591a\u8bed\u8a00\u5b89\u5168\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u6846\u67b6\u548c\u8d44\u6e90\u3002"}}
{"id": "2511.01572", "pdf": "https://arxiv.org/pdf/2511.01572", "abs": "https://arxiv.org/abs/2511.01572", "authors": ["Wang Hao", "Kuang Zhang", "Hou Chengyu", "Yuan Zhonghao", "Tan Chenxing", "Fu Weifeng", "Zhu Yangying"], "title": "HIT-ROCKET: Hadamard-vector Inner-product Transformer for ROCKET", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series classification holds broad application value in communications,\ninformation countermeasures, finance, and medicine. However, state-of-the-art\n(SOTA) methods-including HIVE-COTE, Proximity Forest, and TS-CHIEF-exhibit high\ncomputational complexity, coupled with lengthy parameter tuning and training\ncycles. In contrast, lightweight solutions like ROCKET (Random Convolutional\nKernel Transform) offer greater efficiency but leave substantial room for\nimprovement in kernel selection and computational overhead. To address these\nchallenges, we propose a feature extraction approach based on Hadamard\nconvolutional transform, utilizing column or row vectors of Hadamard matrices\nas convolution kernels with extended lengths of varying sizes. This enhancement\nmaintains full compatibility with existing methods (e.g., ROCKET) while\nleveraging kernel orthogonality to boost computational efficiency, robustness,\nand adaptability. Comprehensive experiments on multi-domain datasets-focusing\non the UCR time series dataset-demonstrate SOTA performance: F1-score improved\nby at least 5% vs. ROCKET, with 50% shorter training time than miniROCKET\n(fastest ROCKET variant) under identical hyperparameters, enabling deployment\non ultra-low-power embedded devices. All code is available on GitHub.", "AI": {"tldr": "\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u73b0\u6709\u65b9\u6cd5\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8eHadamard\u5377\u79ef\u53d8\u6362\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u8fbeSOTA\u6027\u80fd\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5206\u7c7bSOTA\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u8c03\u53c2\u548c\u8bad\u7ec3\u5468\u671f\u957f\uff0c\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u5982ROCKET\u5728\u6838\u9009\u62e9\u548c\u8ba1\u7b97\u5f00\u9500\u4e0a\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eHadamard\u5377\u79ef\u53d8\u6362\u7684\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u7528Hadamard\u77e9\u9635\u5217\u6216\u884c\u5411\u91cf\u4f5c\u4e0d\u540c\u957f\u5ea6\u5377\u79ef\u6838\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u517c\u5bb9\u5e76\u5229\u7528\u6838\u6b63\u4ea4\u6027\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\uff08\u805a\u7126UCR\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff09\u5b9e\u9a8c\u4e2d\uff0cF1\u5206\u6570\u6bd4ROCKET\u81f3\u5c11\u63d0\u9ad85%\uff0c\u8bad\u7ec3\u65f6\u95f4\u6bd4miniROCKET\u7f29\u77ed50%\uff0c\u53ef\u90e8\u7f72\u5728\u8d85\u4f4e\u529f\u8017\u5d4c\u5165\u5f0f\u8bbe\u5907\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01588", "pdf": "https://arxiv.org/pdf/2511.01588", "abs": "https://arxiv.org/abs/2511.01588", "authors": ["Zhicheng Wang", "Chen Ju", "Xu Chen", "Shuai Xiao", "Jinsong Lan", "Xiaoyong Zhu", "Ying Chen", "Zhiguo Cao"], "title": "Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Embedding models are a cornerstone of modern AI. Driven by Multimodal Large\nLanguage Models (MLLMs), they have made great progress in architecture and data\ncuration, while the holistic paradigm is still limited to SSC, i.e., single\ninput, singular embedding, contrastive supervision, which collapses rich,\nmultifaceted inputs into monolithic embeddings and fails to fully exploit MLLM\ncapabilities. In this paper, we tailor one Parallel Decoupling Framework (PDF)\nfor multimodal embedding learning, by utilizing the proprietary steerability of\nMLLMs, i.e., their ability to flexibly generate quite differentiated response\nunder explicit instructions. Concretely, PDF conditions a shared MLLM backbone\non distinct, learnable prefixes to roll out multiple parallel paths for one\ninput, then relies on these paths to obtain parallel embeddings. To promote\nfull parallel diversity, we employ Mutual Information Minimization (MIM) as an\nexplicit constraint, coupled with per-path contrastive supervision to maintain\nsemantic alignment. Such dual-objectives force PDF to yield robust semantic\ncoverage and a generalizable embedding space. Ultimately, the remarkable\nembedding space are accessible at inference via one single forward pass,\nincurring negligible computational overhead. We instantiate PDF on multiple\nMLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains\nare consistently achieved across various resolutions and model sizes, e.g.,\nboosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9% (7B), while the\nVLM2Vec-Qwen2VL models by +4.2% (2B) and +3.1% (7B). In terms of efficiency,\nour 2B model surpasses its baseline by +2.6% using only half the computational\nbudget.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u6a21\u6001\u5d4c\u5165\u5b66\u4e60\u63d0\u51fa\u5e76\u884c\u89e3\u8026\u6846\u67b6PDF\uff0c\u5728\u591a\u4e2aMLLM\u9aa8\u5e72\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6548\u679c\u4e0e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5d4c\u5165\u5b66\u4e60\u6574\u4f53\u8303\u5f0f\u5c40\u9650\u4e8eSSC\uff0c\u65e0\u6cd5\u5145\u5206\u53d1\u6325MLLM\u80fd\u529b\u3002", "method": "\u5229\u7528MLLM\u53ef\u5f15\u5bfc\u6027\uff0c\u8bbe\u8ba1PDF\u6846\u67b6\uff0c\u901a\u8fc7\u4e0d\u540c\u53ef\u5b66\u4e60\u524d\u7f00\u751f\u6210\u5e76\u884c\u8def\u5f84\u83b7\u53d6\u5d4c\u5165\uff0c\u91c7\u7528\u4e92\u4fe1\u606f\u6700\u5c0f\u5316\u7ea6\u675f\u548c\u9010\u8def\u5f84\u5bf9\u6bd4\u76d1\u7763\u3002", "result": "\u5728MMEB\u57fa\u51c6\u4e0a\u8bc1\u660e\u6709\u6548\uff0c\u4e0d\u540c\u5206\u8fa8\u7387\u548c\u6a21\u578b\u5927\u5c0f\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5982VLM2Vec - LLaVA - 1.6 - LR\u6a21\u578b\u63d0\u53478.9%\uff087B\uff09\uff0c2B\u6a21\u578b\u7528\u4e00\u534a\u8ba1\u7b97\u9884\u7b97\u8d85\u8d8a\u57fa\u7ebf2.6%\u3002", "conclusion": "PDF\u6846\u67b6\u80fd\u4ea7\u751f\u9c81\u68d2\u8bed\u4e49\u8986\u76d6\u548c\u53ef\u6cdb\u5316\u5d4c\u5165\u7a7a\u95f4\uff0c\u63a8\u7406\u65f6\u8ba1\u7b97\u5f00\u9500\u5c0f\uff0c\u5177\u6709\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2511.00427", "pdf": "https://arxiv.org/pdf/2511.00427", "abs": "https://arxiv.org/abs/2511.00427", "authors": ["Daichi Zhang", "Tong Zhang", "Jianmin Bao", "Shiming Ge", "Sabine S\u00fcsstrunk"], "title": "Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the rapid development of generative models, detecting generated fake\nimages to prevent their malicious use has become a critical issue recently.\nExisting methods frame this challenge as a naive binary image classification\ntask. However, such methods focus only on visual clues, yielding trained\ndetectors susceptible to overfitting specific image patterns and incapable of\ngeneralizing to unseen models. In this paper, we address this issue from a\nmulti-modal perspective and find that fake images cannot be properly aligned\nwith corresponding captions compared to real images. Upon this observation, we\npropose a simple yet effective detector termed ITEM by leveraging the\nimage-text misalignment in a joint visual-language space as discriminative\nclues. Specifically, we first measure the misalignment of the images and\ncaptions in pre-trained CLIP's space, and then tune a MLP head to perform the\nusual detection task. Furthermore, we propose a hierarchical misalignment\nscheme that first focuses on the whole image and then each semantic object\ndescribed in the caption, which can explore both global and fine-grained local\nsemantic misalignment as clues. Extensive experiments demonstrate the\nsuperiority of our method against other state-of-the-art competitors with\nimpressive generalization and robustness on various recent generative models.", "AI": {"tldr": "\u73b0\u6709\u56fe\u50cf\u771f\u4f2a\u68c0\u6d4b\u65b9\u6cd5\u6613\u8fc7\u62df\u5408\uff0c\u672c\u6587\u4ece\u591a\u6a21\u6001\u89d2\u5ea6\uff0c\u5229\u7528\u56fe\u50cf - \u6587\u672c\u4e0d\u5bf9\u9f50\u7ebf\u7d22\u63d0\u51fa ITEM \u68c0\u6d4b\u5668\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6709\u66f4\u597d\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u56fe\u50cf\u771f\u4f2a\u68c0\u6d4b\u65b9\u6cd5\u4ec5\u5173\u6ce8\u89c6\u89c9\u7ebf\u7d22\uff0c\u6613\u8fc7\u62df\u5408\u7279\u5b9a\u56fe\u50cf\u6a21\u5f0f\uff0c\u65e0\u6cd5\u6cdb\u5316\u5230\u672a\u77e5\u6a21\u578b\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u4ece\u591a\u6a21\u6001\u89d2\u5ea6\uff0c\u5229\u7528\u56fe\u50cf - \u6587\u672c\u5728\u8054\u5408\u89c6\u89c9 - \u8bed\u8a00\u7a7a\u95f4\u7684\u4e0d\u5bf9\u9f50\u4f5c\u4e3a\u5224\u522b\u7ebf\u7d22\uff0c\u63d0\u51fa ITEM \u68c0\u6d4b\u5668\uff1b\u5148\u5728\u9884\u8bad\u7ec3 CLIP \u7a7a\u95f4\u6d4b\u91cf\u56fe\u50cf\u548c\u6587\u672c\u4e0d\u5bf9\u9f50\uff0c\u518d\u5fae\u8c03 MLP \u5934\u8fdb\u884c\u68c0\u6d4b\uff1b\u63d0\u51fa\u5206\u5c42\u4e0d\u5bf9\u9f50\u65b9\u6848\uff0c\u517c\u987e\u5168\u5c40\u548c\u7ec6\u7c92\u5ea6\u5c40\u90e8\u8bed\u4e49\u4e0d\u5bf9\u9f50\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u751f\u6210\u6a21\u578b\u4e0a\u6709\u51fa\u8272\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684 ITEM \u68c0\u6d4b\u5668\u5229\u7528\u56fe\u50cf - \u6587\u672c\u4e0d\u5bf9\u9f50\u7ebf\u7d22\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u751f\u6210\u7684\u5047\u56fe\u50cf\uff0c\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u80fd\u3002"}}
{"id": "2511.01592", "pdf": "https://arxiv.org/pdf/2511.01592", "abs": "https://arxiv.org/abs/2511.01592", "authors": ["Nat\u00e1lia Ribeiro Marinho", "Richard Loendersloot", "Frank Grooteman", "Jan Willem Wiegman", "Uraz Odyurt", "Tiedo Tinga"], "title": "Defining Energy Indicators for Impact Identification on Aerospace Composites: A Physics-Informed Machine Learning Perspective", "categories": ["cs.LG", "physics.app-ph"], "comment": null, "summary": "Energy estimation is critical to impact identification on aerospace\ncomposites, where low-velocity impacts can induce internal damage that is\nundetectable at the surface. Current methodologies for energy prediction are\noften constrained by data sparsity, signal noise, complex feature\ninterdependencies, non-linear dynamics, massive design spaces, and the\nill-posed nature of the inverse problem. This study introduces a\nphysics-informed framework that embeds domain knowledge into machine learning\nthrough a dedicated input space. The approach combines observational biases,\nwhich guide the design of physics-motivated features, with targeted feature\nselection to retain only the most informative indicators. Features are\nextracted from time, frequency, and time-frequency domains to capture\ncomplementary aspects of the structural response. A structured feature\nselection process integrating statistical significance, correlation filtering,\ndimensionality reduction, and noise robustness ensures physical relevance and\ninterpretability. Exploratory data analysis further reveals domain-specific\ntrends, yielding a reduced feature set that captures essential dynamic\nphenomena such as amplitude scaling, spectral redistribution, and transient\nsignal behaviour. Together, these steps produce a compact set of\nenergy-sensitive indicators with both statistical robustness and physical\nsignificance, resulting in impact energy predictions that remain interpretable\nand traceable to measurable structural responses. Using this optimised input\nspace, a fully-connected neural network is trained and validated with\nexperimental data from multiple impact scenarios, including pristine and\ndamaged states. The resulting model demonstrates significantly improved impact\nenergy prediction accuracy, reducing errors by a factor of three compared to\nconventional time-series techniques and purely data-driven models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u6846\u67b6\uff0c\u7ed3\u5408\u7279\u5f81\u9009\u62e9\u4f18\u5316\u8f93\u5165\u7a7a\u95f4\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u822a\u7a7a\u590d\u5408\u6750\u6599\u51b2\u51fb\u80fd\u91cf\uff0c\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524d\u80fd\u91cf\u9884\u6d4b\u65b9\u6cd5\u53d7\u6570\u636e\u7a00\u758f\u3001\u566a\u58f0\u7b49\u95ee\u9898\u9650\u5236\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u822a\u7a7a\u590d\u5408\u6750\u6599\u7684\u51b2\u51fb\u80fd\u91cf\u3002", "method": "\u5f15\u5165\u7269\u7406\u4fe1\u606f\u6846\u67b6\uff0c\u7ed3\u5408\u89c2\u6d4b\u504f\u5dee\u8bbe\u8ba1\u7279\u5f81\uff0c\u8fdb\u884c\u7ed3\u6784\u5316\u7279\u5f81\u9009\u62e9\uff0c\u63d0\u53d6\u591a\u57df\u7279\u5f81\uff0c\u7528\u5b9e\u9a8c\u6570\u636e\u8bad\u7ec3\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u51b2\u51fb\u80fd\u91cf\u9884\u6d4b\u7cbe\u5ea6\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u548c\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u8bef\u5dee\u964d\u4f4e\u4e86\u4e09\u500d\u3002", "conclusion": "\u8be5\u7269\u7406\u4fe1\u606f\u6846\u67b6\u548c\u4f18\u5316\u8f93\u5165\u7a7a\u95f4\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u822a\u7a7a\u590d\u5408\u6750\u6599\u51b2\u51fb\u80fd\u91cf\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.00429", "pdf": "https://arxiv.org/pdf/2511.00429", "abs": "https://arxiv.org/abs/2511.00429", "authors": ["Daichi Zhang", "Tong Zhang", "Shiming Ge", "Sabine S\u00fcsstrunk"], "title": "Enhancing Frequency Forgery Clues for Diffusion-Generated Image Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models have achieved remarkable success in image synthesis, but the\ngenerated high-quality images raise concerns about potential malicious use.\nExisting detectors often struggle to capture discriminative clues across\ndifferent models and settings, limiting their generalization to unseen\ndiffusion models and robustness to various perturbations. To address this\nissue, we observe that diffusion-generated images exhibit progressively larger\ndifferences from natural real images across low- to high-frequency bands. Based\non this insight, we propose a simple yet effective representation by enhancing\nthe Frequency Forgery Clue (F^2C) across all frequency bands. Specifically, we\nintroduce a frequency-selective function which serves as a weighted filter to\nthe Fourier spectrum, suppressing less discriminative bands while enhancing\nmore informative ones. This approach, grounded in a comprehensive analysis of\nfrequency-based differences between natural real and diffusion-generated\nimages, enables general detection of images from unseen diffusion models and\nprovides robust resilience to various perturbations. Extensive experiments on\nvarious diffusion-generated image datasets demonstrate that our method\noutperforms state-of-the-art detectors with superior generalization and\nrobustness.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6269\u6563\u6a21\u578b\u751f\u6210\u56fe\u50cf\u68c0\u6d4b\u96be\u9898\uff0c\u57fa\u4e8e\u9891\u57df\u7ebf\u7d22\u63d0\u51faF^2C\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u751f\u6210\u56fe\u50cf\u7684\u68c0\u6d4b\u5668\u96be\u4ee5\u6355\u6349\u4e0d\u540c\u6a21\u578b\u548c\u8bbe\u7f6e\u7684\u5224\u522b\u7ebf\u7d22\uff0c\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u89c2\u5bdf\u5230\u6269\u6563\u751f\u6210\u56fe\u50cf\u5728\u4e0d\u540c\u9891\u5e26\u4e0e\u771f\u5b9e\u56fe\u50cf\u5dee\u5f02\u9010\u6e10\u589e\u5927\uff0c\u5f15\u5165\u9891\u7387\u9009\u62e9\u51fd\u6570\u4f5c\u4e3a\u5085\u91cc\u53f6\u9891\u8c31\u7684\u52a0\u6743\u6ee4\u6ce2\u5668\uff0c\u589e\u5f3aF^2C\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2a\u6269\u6563\u751f\u6210\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u68c0\u6d4b\u5668\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5bf9\u672a\u77e5\u6269\u6563\u6a21\u578b\u751f\u6210\u7684\u56fe\u50cf\u8fdb\u884c\u901a\u7528\u68c0\u6d4b\uff0c\u5e76\u5bf9\u5404\u79cd\u6270\u52a8\u5177\u6709\u5f3a\u5927\u7684\u6062\u590d\u80fd\u529b\uff0c\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.01633", "pdf": "https://arxiv.org/pdf/2511.01633", "abs": "https://arxiv.org/abs/2511.01633", "authors": ["Chengying Huan", "Ziheng Meng", "Yongchao Liu", "Zhengyi Yang", "Yun Zhu", "Yue Yun", "Shipeng Li", "Rong Gu", "Xiabao Wu", "Haitao Zhang", "Chuntao Hong", "Shaonan Ma", "Guihai Chen", "Chen Tian"], "title": "Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to\nperform step-by-step reasoning over graph-structured knowledge, but existing\npipelines suffer from low accuracy, excessive token usage, high latency, and\nlow throughput due to single-agent monolithic prompts, repeated context\nre-encoding, and inefficient serving execution. We present GLM, the first\nmulti-agent Graph-CoT system co-designed with an optimized LLM serving\narchitecture. GLM decomposes reasoning into specialized agents for\nclassification, reasoning, action generation, and graph retrieval, enabling\nbranching and selective context sharing to reduce prompt length and reasoning\niterations while preserving reasoning quality, thereby improving accuracy and\nreducing overall token consumption. To scale inference, we introduce a\nGraph-CoT-aware LLM inference mechanism with graph-specific KV-cache\nmanagement, priority-based eviction, and pipelined execution to improve serving\nefficiency. Experiments demonstrate that GLM improves answer accuracy by up to\n38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and\nachieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT\nbaselines, enabling efficient adoption for complex real-world reasoning at\nscale.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53Graph - CoT\u7cfb\u7edfGLM\uff0c\u4f18\u5316\u63a8\u7406\u548c\u670d\u52a1\u6548\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u51c6\u786e\u7387\u3001\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709Graph - CoT\u7ba1\u9053\u56e0\u5355\u667a\u80fd\u4f53\u6574\u4f53\u63d0\u793a\u3001\u91cd\u590d\u4e0a\u4e0b\u6587\u91cd\u65b0\u7f16\u7801\u548c\u4f4e\u6548\u670d\u52a1\u6267\u884c\uff0c\u5b58\u5728\u51c6\u786e\u7387\u4f4e\u3001\u4ee4\u724c\u4f7f\u7528\u8fc7\u591a\u3001\u5ef6\u8fdf\u9ad8\u548c\u541e\u5410\u91cf\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u5206\u7c7b\u3001\u63a8\u7406\u3001\u52a8\u4f5c\u751f\u6210\u548c\u56fe\u68c0\u7d22\u7684\u4e13\u4e1a\u667a\u80fd\u4f53\uff0c\u5f15\u5165Graph - CoT\u611f\u77e5\u7684LLM\u63a8\u7406\u673a\u5236\uff0c\u5305\u62ec\u56fe\u7279\u5b9a\u7684KV\u7f13\u5b58\u7ba1\u7406\u3001\u57fa\u4e8e\u4f18\u5148\u7ea7\u7684\u9010\u51fa\u548c\u6d41\u6c34\u7ebf\u6267\u884c\u3002", "result": "GLM\u76f8\u6bd4\u6700\u5148\u8fdb\u7684Graph - CoT\u57fa\u7ebf\uff0c\u7b54\u6848\u51c6\u786e\u7387\u63d0\u9ad8\u8fbe38%\uff0c\u4ee4\u724c\u6210\u672c\u964d\u4f4e\u8fbe95.7%\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e90.3%\uff0c\u541e\u5410\u91cf\u63d0\u9ad8\u8fbe15.1\u500d\u3002", "conclusion": "GLM\u80fd\u6709\u6548\u7528\u4e8e\u5927\u89c4\u6a21\u590d\u6742\u73b0\u5b9e\u4e16\u754c\u63a8\u7406\u3002"}}
{"id": "2511.00447", "pdf": "https://arxiv.org/pdf/2511.00447", "abs": "https://arxiv.org/abs/2511.00447", "authors": ["Ruofan Liu", "Yun Lin", "Jin Song Dong"], "title": "DRIP: Defending Prompt Injection via De-instruction Training and Residual Fusion Model Architecture", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive\ninstruction-following capabilities. However, these capabilities also expose\nmodels to prompt injection attacks, where maliciously crafted inputs overwrite\nor distract from the intended instructions. A core vulnerability lies in the\nmodel's lack of semantic role understanding: it cannot distinguish directive\nintent from descriptive content, leading it to execute instruction-like phrases\nembedded in data.\n  We propose DRIP, a training-time defense grounded in a semantic modeling\nperspective, which enforces robust separation between instruction and data\nsemantics without sacrificing utility. DRIP introduces two lightweight yet\ncomplementary mechanisms: (1) a token-wise de-instruction shift that performs\nsemantic disentanglement, weakening directive semantics in data tokens while\npreserving content meaning; and (2) a residual fusion pathway that provides a\npersistent semantic anchor, reinforcing the influence of the true top-level\ninstruction during generation. Experimental results on LLaMA-8B and Mistral-7B\nacross three prompt injection benchmarks (SEP, AlpacaFarm, and InjecAgent)\ndemonstrate that DRIP outperforms state-of-the-art defenses, including StruQ,\nSecAlign, ISE, and PFT, improving role separation by 49%, and reducing attack\nsuccess rate by 66% for adaptive attacks. Meanwhile, DRIP's utility is on par\nwith the undefended model across AlpacaEval, IFEval, and MT-Bench. Our findings\nunderscore the power of lightweight representation edits and role-aware\nsupervision in securing LLMs against adaptive prompt injection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDRIP\u9632\u5fa1\u673a\u5236\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u4e0d\u5f71\u54cd\u5b9e\u7528\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u4f7f\u5176\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u6838\u5fc3\u6f0f\u6d1e\u662f\u7f3a\u4e4f\u8bed\u4e49\u89d2\u8272\u7406\u89e3\u3002", "method": "\u63d0\u51faDRIP\uff0c\u5305\u542btoken-wise de-instruction shift\u8fdb\u884c\u8bed\u4e49\u89e3\u7f20\u548cresidual fusion pathway\u63d0\u4f9b\u8bed\u4e49\u951a\u70b9\u3002", "result": "\u5728LLaMA - 8B\u548cMistral - 7B\u4e0a\u5b9e\u9a8c\uff0cDRIP\u4f18\u4e8eStruQ\u7b49\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff0c\u89d2\u8272\u5206\u79bb\u63d0\u534749%\uff0c\u81ea\u9002\u5e94\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e66%\uff0c\u5b9e\u7528\u6027\u4e0e\u672a\u9632\u5fa1\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u8868\u793a\u7f16\u8f91\u548c\u89d2\u8272\u611f\u77e5\u76d1\u7763\u53ef\u6709\u6548\u4fdd\u62a4\u5927\u8bed\u8a00\u6a21\u578b\u514d\u53d7\u81ea\u9002\u5e94\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002"}}
{"id": "2511.01694", "pdf": "https://arxiv.org/pdf/2511.01694", "abs": "https://arxiv.org/abs/2511.01694", "authors": ["Hossein Abdi", "Mingfei Sun", "Wei Pan"], "title": "Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Vision-language pre-trained models, such as CLIP, have established new\nbenchmarks in multimodal data mining. In such models, few-shot fine-tuning is a\nmajor challenge to achieve optimal performance on both in-distribution (ID) and\nout-of-distribution (OOD) datasets, especially when labeled data is scarce.\nMost existing fine-tuning approaches rely on first-order gradient-based\noptimizers, which typically suffer from slow convergence, sensitivity to\nstep-size hyperparameters, and poor generalization in OOD settings. In\ncontrast, second-order methods utilize local curvature information of the loss\nlandscape to adjust the update step size. This is particularly beneficial for\nCLIP models, whose non-convex loss functions often contain sharp critical\npoints. In such cases, natural gradient direction can offer more substantial\nand efficient per-iteration updates when fine-tuning with limited data. Natural\nGradient Descent (NGD) is obtained by preconditioning the standard gradient\nwith the inverse Fisher Information Matrix (FIM), which is computationally\nexpensive for large models. To address this, we propose a Bayesian\napproximation of NGD using a Kalman filter for CLIP models. Our method combines\nthe benefits of second-order optimization with Bayesian inference, which\nenhances generalization while providing uncertainty quantification. Extensive\nexperiments conducted on diverse image classification datasets demonstrate that\nour algorithm consistently achieves superior--or comparable--ID performance and\nimproved OOD robustness compared to state-of-the-art baselines. To the best of\nour knowledge, this work represents the first successful application of Kalman\nfiltering to fine-tuning CLIP-based models, which enables more robust and\nefficient learning in vision-language tasks.", "AI": {"tldr": "\u63d0\u51fa\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5bf9CLIP\u6a21\u578b\u8fdb\u884c\u8d1d\u53f6\u65af\u8fd1\u4f3c\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u5fae\u8c03\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u5728ID\u548cOOD\u6570\u636e\u96c6\u8868\u73b0\u597d\u3002", "motivation": "\u73b0\u6709CLIP\u6a21\u578b\u5c11\u6837\u672c\u5fae\u8c03\u65b9\u6cd5\u5728ID\u548cOOD\u6570\u636e\u96c6\u6548\u679c\u4e0d\u4f73\uff0c\u4e00\u9636\u4f18\u5316\u5668\u6709\u6536\u655b\u6162\u7b49\u95ee\u9898\uff0c\u800c\u4e8c\u9636\u65b9\u6cd5\u867d\u6709\u4f18\u52bf\u4f46\u8ba1\u7b97\u5f00\u9500\u5927\u3002", "method": "\u63d0\u51fa\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5bf9CLIP\u6a21\u578b\u8fdb\u884c\u8d1d\u53f6\u65af\u8fd1\u4f3c\u81ea\u7136\u68af\u5ea6\u4e0b\u964d\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e8c\u9636\u4f18\u5316\u548c\u8d1d\u53f6\u65af\u63a8\u7406\u3002", "result": "\u5728\u4e0d\u540c\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u7b97\u6cd5\u5728ID\u8868\u73b0\u4f18\u6216\u76f8\u5f53\uff0cOOD\u9c81\u68d2\u6027\u63d0\u5347\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u6210\u529f\u5c06\u5361\u5c14\u66fc\u6ee4\u6ce2\u7528\u4e8e\u5fae\u8c03\u57fa\u4e8eCLIP\u7684\u6a21\u578b\uff0c\u80fd\u5728\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u9c81\u68d2\u9ad8\u6548\u7684\u5b66\u4e60\u3002"}}
{"id": "2511.00460", "pdf": "https://arxiv.org/pdf/2511.00460", "abs": "https://arxiv.org/abs/2511.00460", "authors": ["Mohammed N. Swileh", "Shengli Zhang"], "title": "Proactive DDoS Detection and Mitigation in Decentralized Software-Defined Networking via Port-Level Monitoring and Zero-Training Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Centralized Software-Defined Networking (cSDN) offers flexible and\nprogrammable control of networks but suffers from scalability and reliability\nissues due to its reliance on centralized controllers. Decentralized SDN (dSDN)\nalleviates these concerns by distributing control across multiple local\ncontrollers, yet this architecture remains highly vulnerable to Distributed\nDenial-of-Service (DDoS) attacks. In this paper, we propose a novel detection\nand mitigation framework tailored for dSDN environments. The framework\nleverages lightweight port-level statistics combined with prompt engineering\nand in-context learning, enabling the DeepSeek-v3 Large Language Model (LLM) to\nclassify traffic as benign or malicious without requiring fine-tuning or\nretraining. Once an anomaly is detected, mitigation is enforced directly at the\nattacker's port, ensuring that malicious traffic is blocked at their origin\nwhile normal traffic remains unaffected. An automatic recovery mechanism\nrestores normal operation after the attack inactivity, ensuring both security\nand availability. Experimental evaluation under diverse DDoS attack scenarios\ndemonstrates that the proposed approach achieves near-perfect detection, with\n99.99% accuracy, 99.97% precision, 100% recall, 99.98% F1-score, and an AUC of\n1.0. These results highlight the effectiveness of combining distributed\nmonitoring with zero-training LLM inference, providing a proactive and scalable\ndefense mechanism for securing dSDN infrastructures against DDoS threats.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9002\u7528\u4e8edSDN\u73af\u5883\u7684DDoS\u653b\u51fb\u68c0\u6d4b\u4e0e\u7f13\u89e3\u6846\u67b6\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u7aef\u53e3\u7edf\u8ba1\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u96f6\u8bad\u7ec3\u5206\u7c7b\uff0c\u5b9e\u9a8c\u6548\u679c\u4f73\u3002", "motivation": "cSDN\u6709\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0cdSDN\u6613\u53d7DDoS\u653b\u51fb\uff0c\u9700\u6709\u6548\u9632\u5fa1\u673a\u5236\u3002", "method": "\u63d0\u51fa\u68c0\u6d4b\u4e0e\u7f13\u89e3\u6846\u67b6\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u7aef\u53e3\u7edf\u8ba1\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u8ba9DeepSeek - v3 LLM\u96f6\u8bad\u7ec3\u5206\u7c7b\u6d41\u91cf\uff0c\u5728\u653b\u51fb\u7aef\u53e3\u6267\u884c\u7f13\u89e3\uff0c\u8bbe\u81ea\u52a8\u6062\u590d\u673a\u5236\u3002", "result": "\u5728\u591a\u79cdDDoS\u653b\u51fb\u573a\u666f\u4e0b\u5b9e\u9a8c\uff0c\u68c0\u6d4b\u51c6\u786e\u738799.99%\u3001\u7cbe\u5ea699.97%\u3001\u53ec\u56de\u7387100%\u3001F1\u5206\u657099.98%\u3001AUC\u4e3a1.0\u3002", "conclusion": "\u7ed3\u5408\u5206\u5e03\u5f0f\u76d1\u63a7\u4e0e\u96f6\u8bad\u7ec3LLM\u63a8\u7406\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u4e3adSDN\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e3b\u52a8\u3001\u53ef\u6269\u5c55\u7684DDoS\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2511.01695", "pdf": "https://arxiv.org/pdf/2511.01695", "abs": "https://arxiv.org/abs/2511.01695", "authors": ["Jungyeon Koh", "Hyun Jong Yang"], "title": "Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "The growing demand for on-device large language model (LLM) inference\nhighlights the need for efficient mobile edge computing (MEC) solutions,\nespecially in resource-constrained settings. Speculative decoding offers a\npromising solution by partitioning token generation between a lightweight draft\nmodel on mobile devices and a powerful target model on edge servers, but\nsuffers from communication overhead and asynchronous delays. This paper is the\nfirst to propose a unified framework that jointly optimizes user association\nand resource allocation (UARA) to support efficient parallel speculative\ndecoding. We solve the UARA problem using a multi-agent deep reinforcement\nlearning algorithm. To evaluate our approach under realistic conditions, we\nconduct experiments using the Sionna simulator. Results show that our method\nachieves up to 28.0% and an average of 23.7% reduction in end-to-end latency\nwithout compromising inference accuracy, enabling scalable and low-latency LLM\nservices in MEC systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u8054\u5408\u4f18\u5316\u7528\u6237\u5173\u8054\u548c\u8d44\u6e90\u5206\u914d\u4ee5\u652f\u6301\u9ad8\u6548\u5e76\u884c\u63a8\u6d4b\u89e3\u7801\uff0c\u7528\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6c42\u89e3\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u964d\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\u4e14\u4e0d\u5f71\u54cd\u63a8\u7406\u7cbe\u5ea6\u3002", "motivation": "\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9700\u6c42\u589e\u957f\uff0c\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u9700\u9ad8\u6548\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\uff0c\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u5b58\u5728\u901a\u4fe1\u5f00\u9500\u548c\u5f02\u6b65\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8054\u5408\u4f18\u5316\u7528\u6237\u5173\u8054\u548c\u8d44\u6e90\u5206\u914d\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u7528Sionna\u6a21\u62df\u5668\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u65b9\u6cd5\u5b9e\u73b0\u7aef\u5230\u7aef\u5ef6\u8fdf\u6700\u9ad8\u964d\u4f4e28.0%\uff0c\u5e73\u5747\u964d\u4f4e23.7%\uff0c\u4e14\u4e0d\u5f71\u54cd\u63a8\u7406\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5728\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u4f4e\u5ef6\u8fdf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u3002"}}
{"id": "2511.00472", "pdf": "https://arxiv.org/pdf/2511.00472", "abs": "https://arxiv.org/abs/2511.00472", "authors": ["Navodini Wijethilake", "Marina Ivory", "Oscar MacCormac", "Siddhant Kumar", "Aaron Kujawa", "Lorena Garcia-Foncillas Macias", "Rebecca Burger", "Amanda Hitchings", "Suki Thomson", "Sinan Barazi", "Eleni Maratos", "Rupert Obholzer", "Dan Jiang", "Fiona McClenaghan", "Kazumi Chia", "Omar Al-Salihi", "Nick Thomas", "Steve Connor", "Tom Vercauteren", "Jonathan Shapey"], "title": "Longitudinal Vestibular Schwannoma Dataset with Consensus-based Human-in-the-loop Annotations", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate segmentation of vestibular schwannoma (VS) on Magnetic Resonance\nImaging (MRI) is essential for patient management but often requires\ntime-intensive manual annotations by experts. While recent advances in deep\nlearning (DL) have facilitated automated segmentation, challenges remain in\nachieving robust performance across diverse datasets and complex clinical\ncases. We present an annotated dataset stemming from a bootstrapped DL-based\nframework for iterative segmentation and quality refinement of VS in MRI. We\ncombine data from multiple centres and rely on expert consensus for\ntrustworthiness of the annotations. We show that our approach enables effective\nand resource-efficient generalisation of automated segmentation models to a\ntarget data distribution. The framework achieved a significant improvement in\nsegmentation accuracy with a Dice Similarity Coefficient (DSC) increase from\n0.9125 to 0.9670 on our target internal validation dataset, while maintaining\nstable performance on representative external datasets. Expert evaluation on\n143 scans further highlighted areas for model refinement, revealing nuanced\ncases where segmentation required expert intervention. The proposed approach is\nestimated to enhance efficiency by approximately 37.4% compared to the\nconventional manual annotation process. Overall, our human-in-the-loop model\ntraining approach achieved high segmentation accuracy, highlighting its\npotential as a clinically adaptable and generalisable strategy for automated VS\nsegmentation in diverse clinical settings. The dataset includes 190 patients,\nwith tumour annotations available for 534 longitudinal contrast-enhanced\nT1-weighted (T1CE) scans from 184 patients, and non-annotated T2-weighted scans\nfrom 6 patients. This dataset is publicly accessible on The Cancer Imaging\nArchive (TCIA) (https://doi.org/10.7937/bq0z-xa62).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u4e3e\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u5e26\u6ce8\u91ca\u6570\u636e\u96c6\u7528\u4e8e\u524d\u5ead\u795e\u7ecf\u9798\u7624\uff08VS\uff09\u5206\u5272\uff0c\u63d0\u9ad8\u4e86\u5206\u5272\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u6570\u636e\u96c6\u516c\u5f00\u3002", "motivation": "\u51c6\u786e\u5206\u5272VS\u5bf9\u60a3\u8005\u7ba1\u7406\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u6ce8\u91ca\u8017\u65f6\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u81ea\u52a8\u5206\u5272\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u590d\u6742\u4e34\u5e8a\u75c5\u4f8b\u4e2d\u6027\u80fd\u6709\u5f85\u63d0\u5347\u3002", "method": "\u7ed3\u5408\u591a\u4e2d\u5fc3\u6570\u636e\uff0c\u4f9d\u9760\u4e13\u5bb6\u5171\u8bc6\u786e\u4fdd\u6ce8\u91ca\u53ef\u4fe1\u5ea6\uff0c\u91c7\u7528\u4eba\u5728\u73af\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "\u5728\u76ee\u6807\u5185\u90e8\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0aDSC\u4ece0.9125\u63d0\u5347\u52300.9670\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u7a33\u5b9a\uff0c\u4e13\u5bb6\u8bc4\u4f30\u6307\u51fa\u6a21\u578b\u6539\u8fdb\u65b9\u5411\uff0c\u6548\u7387\u6bd4\u4f20\u7edf\u624b\u52a8\u6ce8\u91ca\u63d0\u9ad8\u7ea637.4%\u3002", "conclusion": "\u8be5\u4eba\u5728\u73af\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u5b9e\u73b0\u9ad8\u5206\u5272\u51c6\u786e\u6027\uff0c\u662f\u4e34\u5e8a\u53ef\u9002\u5e94\u3001\u53ef\u63a8\u5e7f\u7684\u81ea\u52a8VS\u5206\u5272\u7b56\u7565\u3002"}}
{"id": "2511.01740", "pdf": "https://arxiv.org/pdf/2511.01740", "abs": "https://arxiv.org/abs/2511.01740", "authors": ["Dmitrij Schlesinger", "Boris Flach"], "title": "Game-theoretic distributed learning of generative models for heterogeneous data collections", "categories": ["cs.LG"], "comment": "The manuscript is accepted for publishing at the 2025 Symposium on\n  Federated Learning and Intelligent Computing Systems (FLICS 2025)", "summary": "One of the main challenges in distributed learning arises from the difficulty\nof handling heterogeneous local models and data. In light of the recent success\nof generative models, we propose to meet this challenge by building on the idea\nof exchanging synthetic data instead of sharing model parameters. Local models\ncan then be treated as ``black boxes'' with the ability to learn their\nparameters from data and to generate data according to these parameters.\nMoreover, if the local models admit semi-supervised learning, we can extend the\napproach by enabling local models on different probability spaces. This allows\nto handle heterogeneous data with different modalities. We formulate the\nlearning of the local models as a cooperative game starting from the principles\nof game theory. We prove the existence of a unique Nash equilibrium for\nexponential family local models and show that the proposed learning approach\nconverges to this equilibrium. We demonstrate the advantages of our approach on\nstandard benchmark vision datasets for image classification and conditional\ngeneration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u4ea4\u6362\u5408\u6210\u6570\u636e\u5e94\u5bf9\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u5904\u7406\u5f02\u6784\u672c\u5730\u6a21\u578b\u548c\u6570\u636e\u7684\u6311\u6218\uff0c\u5c06\u672c\u5730\u6a21\u578b\u5b66\u4e60\u5efa\u6a21\u4e3a\u5408\u4f5c\u535a\u5f08\uff0c\u8bc1\u660e\u5b58\u5728\u552f\u4e00\u7eb3\u4ec0\u5747\u8861\u5e76\u5c55\u793a\u4e86\u65b9\u6cd5\u4f18\u52bf\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u5904\u7406\u5f02\u6784\u672c\u5730\u6a21\u578b\u548c\u6570\u636e\u7684\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4ea4\u6362\u5408\u6210\u6570\u636e\u800c\u975e\u5171\u4eab\u6a21\u578b\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u5c06\u672c\u5730\u6a21\u578b\u5b66\u4e60\u5efa\u6a21\u4e3a\u5408\u4f5c\u535a\u5f08\u3002", "result": "\u8bc1\u660e\u6307\u6570\u65cf\u672c\u5730\u6a21\u578b\u5b58\u5728\u552f\u4e00\u7eb3\u4ec0\u5747\u8861\uff0c\u4e14\u5b66\u4e60\u65b9\u6cd5\u6536\u655b\u5230\u8be5\u5747\u8861\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u6761\u4ef6\u751f\u6210\u7684\u6807\u51c6\u57fa\u51c6\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.00477", "pdf": "https://arxiv.org/pdf/2511.00477", "abs": "https://arxiv.org/abs/2511.00477", "authors": ["Aditya Parikh", "Sneha Das", "Aasa Feragen"], "title": "Investigating Label Bias and Representational Sources of Age-Related Disparities in Medical Segmentation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Submitted to ISBI 2026", "summary": "Algorithmic bias in medical imaging can perpetuate health disparities, yet\nits causes remain poorly understood in segmentation tasks. While fairness has\nbeen extensively studied in classification, segmentation remains underexplored\ndespite its clinical importance. In breast cancer segmentation, models exhibit\nsignificant performance disparities against younger patients, commonly\nattributed to physiological differences in breast density. We audit the\nMAMA-MIA dataset, establishing a quantitative baseline of age-related bias in\nits automated labels, and reveal a critical Biased Ruler effect where\nsystematically flawed labels for validation misrepresent a model's actual bias.\nHowever, whether this bias originates from lower-quality annotations (label\nbias) or from fundamentally more challenging image characteristics remains\nunclear. Through controlled experiments, we systematically refute hypotheses\nthat the bias stems from label quality sensitivity or quantitative case\ndifficulty imbalance. Balancing training data by difficulty fails to mitigate\nthe disparity, revealing that younger patient cases are intrinsically harder to\nlearn. We provide direct evidence that systemic bias is learned and amplified\nwhen training on biased, machine-generated labels, a critical finding for\nautomated annotation pipelines. This work introduces a systematic framework for\ndiagnosing algorithmic bias in medical segmentation and demonstrates that\nachieving fairness requires addressing qualitative distributional differences\nrather than merely balancing case counts.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u533b\u5b66\u5f71\u50cf\u5206\u5272\u4efb\u52a1\u4e2d\u7684\u7b97\u6cd5\u504f\u5dee\uff0c\u5ba1\u8ba1MAMA - MIA\u6570\u636e\u96c6\u63ed\u793a\u504f\u5dee\uff0c\u901a\u8fc7\u5b9e\u9a8c\u786e\u5b9a\u504f\u5dee\u539f\u56e0\uff0c\u63d0\u51fa\u8bca\u65ad\u6846\u67b6\u5e76\u6307\u51fa\u5b9e\u73b0\u516c\u5e73\u9700\u89e3\u51b3\u5b9a\u6027\u5206\u5e03\u5dee\u5f02\u3002", "motivation": "\u7b97\u6cd5\u504f\u5dee\u4f1a\u52a0\u5267\u533b\u7597\u5065\u5eb7\u5dee\u5f02\uff0c\u5206\u5272\u4efb\u52a1\u4e2d\u504f\u5dee\u6210\u56e0\u4e0d\u660e\uff0c\u4e14\u5728\u4e73\u817a\u764c\u5206\u5272\u4e2d\u6a21\u578b\u5bf9\u5e74\u8f7b\u60a3\u8005\u6709\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u5ba1\u8ba1MAMA - MIA\u6570\u636e\u96c6\u5efa\u7acb\u5e74\u9f84\u76f8\u5173\u504f\u5dee\u57fa\u7ebf\uff0c\u901a\u8fc7\u5bf9\u7167\u5b9e\u9a8c\u53cd\u9a73\u504f\u5dee\u6e90\u4e8e\u6807\u7b7e\u8d28\u91cf\u6216\u75c5\u4f8b\u96be\u5ea6\u5931\u8861\u7684\u5047\u8bbe\uff0c\u5c1d\u8bd5\u6309\u96be\u5ea6\u5e73\u8861\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u53d1\u73b0\u5173\u952e\u7684\u201c\u6709\u504f\u6807\u5c3a\u201d\u6548\u5e94\uff1b\u786e\u5b9a\u5e74\u8f7b\u60a3\u8005\u75c5\u4f8b\u672c\u8d28\u4e0a\u66f4\u96be\u5b66\u4e60\uff1b\u8bc1\u5b9e\u4f7f\u7528\u6709\u504f\u673a\u5668\u751f\u6210\u6807\u7b7e\u8bad\u7ec3\u4f1a\u4f7f\u7cfb\u7edf\u504f\u5dee\u88ab\u5b66\u4e60\u548c\u653e\u5927\u3002", "conclusion": "\u63d0\u51fa\u8bca\u65ad\u533b\u5b66\u5206\u5272\u7b97\u6cd5\u504f\u5dee\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u6307\u51fa\u5b9e\u73b0\u516c\u5e73\u9700\u89e3\u51b3\u5b9a\u6027\u5206\u5e03\u5dee\u5f02\u800c\u975e\u4ec5\u5e73\u8861\u75c5\u4f8b\u6570\u91cf\u3002"}}
{"id": "2511.01741", "pdf": "https://arxiv.org/pdf/2511.01741", "abs": "https://arxiv.org/abs/2511.01741", "authors": ["Ameya S. Bhave", "Navnil Choudhury", "Kanad Basu"], "title": "HyperNQ: A Hypergraph Neural Network Decoder for Quantum LDPC Codes", "categories": ["cs.LG", "cs.IT", "math.IT", "quant-ph"], "comment": "6 pages, 4 figures, Submitted to the IEEE International Conference on\n  Communications (ICC 2026). Preprint version", "summary": "Quantum computing requires effective error correction strategies to mitigate\nnoise and decoherence. Quantum Low-Density Parity-Check (QLDPC) codes have\nemerged as a promising solution for scalable Quantum Error Correction (QEC)\napplications by supporting constant-rate encoding and a sparse parity-check\nstructure. However, decoding QLDPC codes via traditional approaches such as\nBelief Propagation (BP) suffers from poor convergence in the presence of short\ncycles. Machine learning techniques like Graph Neural Networks (GNNs) utilize\nlearned message passing over their node features; however, they are restricted\nto pairwise interactions on Tanner graphs, which limits their ability to\ncapture higher-order correlations. In this work, we propose HyperNQ, the first\nHypergraph Neural Network (HGNN)- based QLDPC decoder that captures\nhigher-order stabilizer constraints by utilizing hyperedges-thus enabling\nhighly expressive and compact decoding. We use a two-stage message passing\nscheme and evaluate the decoder over the pseudo-threshold region. Below the\npseudo-threshold mark, HyperNQ improves the Logical Error Rate (LER) up to 84%\nover BP and 50% over GNN-based strategies, demonstrating enhanced performance\nover the existing state-of-the-art decoders.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u91cf\u5b50\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u89e3\u7801\u5668HyperNQ\uff0c\u5728\u4f2a\u9608\u503c\u4e0b\u903b\u8f91\u9519\u8bef\u7387\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u89e3\u7801\u5668\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u89e3\u7801\u91cf\u5b50\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u5b58\u5728\u6536\u655b\u5dee\u95ee\u9898\uff0c\u673a\u5668\u5b66\u4e60\u6280\u672f\u6355\u6349\u9ad8\u9636\u76f8\u5173\u6027\u80fd\u529b\u6709\u9650\uff0c\u9700\u66f4\u597d\u7684\u89e3\u7801\u5668\u3002", "method": "\u63d0\u51faHyperNQ\u89e3\u7801\u5668\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u5728\u4f2a\u9608\u503c\u533a\u57df\u8bc4\u4f30\u3002", "result": "\u5728\u4f2a\u9608\u503c\u4ee5\u4e0b\uff0cHyperNQ\u8f83BP\u903b\u8f91\u9519\u8bef\u7387\u6700\u591a\u964d\u4f4e84%\uff0c\u8f83\u57fa\u4e8eGNN\u7b56\u7565\u6700\u591a\u964d\u4f4e50%\u3002", "conclusion": "HyperNQ\u5728\u89e3\u7801\u91cf\u5b50\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u4e0a\u6bd4\u73b0\u6709\u89e3\u7801\u5668\u6027\u80fd\u66f4\u4f18\u3002"}}
{"id": "2511.00494", "pdf": "https://arxiv.org/pdf/2511.00494", "abs": "https://arxiv.org/abs/2511.00494", "authors": ["Ljupcho Milosheski", "Kuon Akiyama", "Bla\u017e Bertalani\u010d", "Jernej Hribar", "Ryoichi Shinkuma"], "title": "A Multimodal Dataset for Indoor Radio Mapping with 3D Point Clouds and RSSI", "categories": ["eess.SP", "cs.AI", "94-11", "H.4.3; I.6.3"], "comment": "11 pages, 7 figures, 3 tables, under review to Nature Scientific Data", "summary": "The growing number of smart devices supporting bandwidth-intensive and\nlatency-sensitive applications, such as real-time video analytics, smart\nsensing, and Extended Reality (XR), necessitates reliable wireless connectivity\nin indoor environments. Therein, accurate estimation of Radio Environment Maps\n(REMs) enables adaptive wireless network planning and optimization of Access\nPoint (AP) placement. However, generating realistic REMs remains challenging\ndue to the complexity of indoor spaces. To overcome this challenge, this paper\nintroduces a multimodal dataset that integrates high-resolution 3D LiDAR scans\nwith Wi-Fi Received Signal Strength Indicator (RSSI) measurements collected\nunder 20 distinct AP configurations in a multi-room indoor environment. The\ndataset captures two measurement scenarios: the first without human presence in\nthe environment, and the second with human presence. Thus, the presented\ndataset supports the study of dynamic environmental effects on wireless signal\npropagation. This resource is designed to facilitate research in data-driven\nwireless modeling, particularly in the context of emerging high-frequency\nstandards such as IEEE 802.11be (Wi-Fi 7), and aims to advance the development\nof robust, high-capacity indoor communication systems.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u96c6\u62103D LiDAR\u626b\u63cf\u4e0eWi - Fi RSSI\u6d4b\u91cf\uff0c\u652f\u6301\u7814\u7a76\u52a8\u6001\u73af\u5883\u5bf9\u65e0\u7ebf\u4fe1\u53f7\u4f20\u64ad\u7684\u5f71\u54cd\uff0c\u63a8\u52a8\u5ba4\u5185\u901a\u4fe1\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u5ba4\u5185\u5927\u91cf\u667a\u80fd\u8bbe\u5907\u9700\u53ef\u9760\u65e0\u7ebf\u8fde\u63a5\uff0c\u51c6\u786e\u4f30\u8ba1\u65e0\u7ebf\u7535\u73af\u5883\u56fe\uff08REMs\uff09\u6709\u6311\u6218\uff0c\u56e0\u6b64\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u96c6\u6210\u9ad8\u5206\u8fa8\u73873D LiDAR\u626b\u63cf\u548cWi - Fi RSSI\u6d4b\u91cf\uff0c\u5305\u542b\u65e0\u4eba\u548c\u6709\u4eba\u4e24\u79cd\u573a\u666f\u3002", "result": "\u5f97\u5230\u4e00\u4e2a\u652f\u6301\u7814\u7a76\u52a8\u6001\u73af\u5883\u5bf9\u65e0\u7ebf\u4fe1\u53f7\u4f20\u64ad\u5f71\u54cd\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u65e0\u7ebf\u5efa\u6a21\u7814\u7a76\uff0c\u63a8\u52a8\u65b0\u5174\u9ad8\u9891\u6807\u51c6\u4e0b\u5ba4\u5185\u901a\u4fe1\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2511.01743", "pdf": "https://arxiv.org/pdf/2511.01743", "abs": "https://arxiv.org/abs/2511.01743", "authors": ["Song Gao", "Shusen Jing", "Shuai Zhang", "Yue Wang", "Xiangwei Zhou", "Songyang Zhang"], "title": "Towards Efficient Federated Learning of Networked Mixture-of-Experts for Mobile Edge Computing", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": null, "summary": "Recent advancements in large artificial intelligence models (LAMs) are\ndriving significant innovations in mobile edge computing within next-generation\nwireless networks. However, the substantial demands for computational resources\nand large-scale training data required to train LAMs conflict with the limited\nstorage and computational capacity of edge devices, posing significant\nchallenges to training and deploying LAMs at the edge. In this work, we\nintroduce the Networked Mixture-of-Experts (NMoE) system, in which clients\ninfer collaboratively by distributing tasks to suitable neighbors based on\ntheir expertise and aggregate the returned results. For training the NMoE, we\npropose a federated learning framework that integrates both supervised and\nself-supervised learning to balance personalization and generalization, while\npreserving communication efficiency and data privacy. We conduct extensive\nexperiments to demonstrate the efficacy of the proposed NMoE system, providing\ninsights and benchmarks for the NMoE training algorithms.", "AI": {"tldr": "\u4ecb\u7ecdNetworked Mixture-of-Experts (NMoE)\u7cfb\u7edf\u5e94\u5bf9\u8fb9\u7f18\u8bbe\u5907\u8bad\u7ec3\u548c\u90e8\u7f72\u5927\u6a21\u578b\u6311\u6218\u3002", "motivation": "\u5927\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u8ba1\u7b97\u8d44\u6e90\u548c\u6570\u636e\u4e0e\u8fb9\u7f18\u8bbe\u5907\u6709\u9650\u80fd\u529b\u51b2\u7a81\uff0c\u9700\u89e3\u51b3\u8fb9\u7f18\u8bad\u7ec3\u548c\u90e8\u7f72\u96be\u9898\u3002", "method": "\u5f15\u5165NMoE\u7cfb\u7edf\uff0c\u5ba2\u6237\u57fa\u4e8e\u4e13\u4e1a\u77e5\u8bc6\u5c06\u4efb\u52a1\u5206\u914d\u7ed9\u90bb\u5c45\u534f\u4f5c\u63a8\u7406\u5e76\u805a\u5408\u7ed3\u679c\uff0c\u63d0\u51fa\u7ed3\u5408\u76d1\u7763\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u8bad\u7ec3NMoE\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86NMoE\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e3aNMoE\u8bad\u7ec3\u7b97\u6cd5\u63d0\u4f9b\u4e86\u89c1\u89e3\u548c\u57fa\u51c6\u3002"}}
{"id": "2511.01745", "pdf": "https://arxiv.org/pdf/2511.01745", "abs": "https://arxiv.org/abs/2511.01745", "authors": ["Mei-Chin Pang", "Suraj Adhikari", "Takuma Kasahara", "Nagihiro Haba", "Saneyuki Ohno"], "title": "An Open-Access Benchmark of Statistical and Machine-Learning Anomaly Detection Methods for Battery Applications", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Battery safety is critical in applications ranging from consumer electronics\nto electric vehicles and aircraft, where undetected anomalies could trigger\nsafety hazards or costly downtime. In this study, we present OSBAD as an\nopen-source benchmark for anomaly detection frameworks in battery applications.\nBy benchmarking 15 diverse algorithms encompassing statistical, distance-based,\nand unsupervised machine-learning methods, OSBAD enables a systematic\ncomparison of anomaly detection methods across heterogeneous datasets. In\naddition, we demonstrate how a physics- and statistics-informed feature\ntransformation workflow enhances anomaly separability by decomposing collective\nanomalies into point anomalies. To address a major bottleneck in unsupervised\nanomaly detection due to incomplete labels, we propose a Bayesian optimization\npipeline that facilitates automated hyperparameter tuning based on\ntransfer-learning and regression proxies. Through validation on datasets\ncovering both liquid and solid-state chemistries, we further demonstrate the\ncross-chemistry generalization capability of OSBAD to identify irregularities\nacross different electrochemical systems. By making benchmarking database with\nopen-source reproducible anomaly detection workflows available to the\ncommunity, OSBAD establishes a unified foundation for developing safe,\nscalable, and transferable anomaly detection tools in battery analytics. This\nresearch underscores the significance of physics- and statistics-informed\nfeature engineering as well as model selection with probabilistic\nhyperparameter tuning, in advancing trustworthy, data-driven diagnostics for\nsafety-critical energy systems.", "AI": {"tldr": "\u63d0\u51faOSBAD\u4f5c\u4e3a\u7535\u6c60\u5e94\u7528\u4e2d\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\u7684\u5f00\u6e90\u57fa\u51c6\uff0c\u5c55\u793a\u7279\u5f81\u8f6c\u6362\u3001\u8d1d\u53f6\u65af\u4f18\u5316\u7ba1\u9053\u7b49\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u5176\u8de8\u5316\u5b66\u901a\u7528\u6027\uff0c\u4e3a\u7535\u6c60\u5206\u6790\u63d0\u4f9b\u7edf\u4e00\u57fa\u7840\u3002", "motivation": "\u7535\u6c60\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u672a\u68c0\u6d4b\u5230\u7684\u5f02\u5e38\u4f1a\u5e26\u6765\u5b89\u5168\u9690\u60a3\u548c\u505c\u673a\u6210\u672c\uff0c\u9700\u8981\u5bf9\u7535\u6c60\u5e94\u7528\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u57fa\u51c6\u6d4b\u8bd515\u79cd\u4e0d\u540c\u7b97\u6cd5\uff0c\u91c7\u7528\u7269\u7406\u548c\u7edf\u8ba1\u4fe1\u606f\u7684\u7279\u5f81\u8f6c\u6362\u5de5\u4f5c\u6d41\uff0c\u63d0\u51fa\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\u548c\u56de\u5f52\u4ee3\u7406\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u7ba1\u9053\u3002", "result": "\u9a8c\u8bc1\u4e86OSBAD\u5728\u4e0d\u540c\u7535\u5316\u5b66\u7cfb\u7edf\u4e2d\u7684\u8de8\u5316\u5b66\u901a\u7528\u6027\uff0c\u80fd\u8bc6\u522b\u4e0d\u540c\u4f53\u7cfb\u7684\u4e0d\u89c4\u5219\u6027\u3002", "conclusion": "\u5f3a\u8c03\u7269\u7406\u548c\u7edf\u8ba1\u4fe1\u606f\u7684\u7279\u5f81\u5de5\u7a0b\u4ee5\u53ca\u6982\u7387\u8d85\u53c2\u6570\u8c03\u6574\u7684\u6a21\u578b\u9009\u62e9\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u5b89\u5168\u5173\u952e\u80fd\u6e90\u7cfb\u7edf\u7684\u53ef\u9760\u6570\u636e\u9a71\u52a8\u8bca\u65ad\u3002"}}
{"id": "2511.01758", "pdf": "https://arxiv.org/pdf/2511.01758", "abs": "https://arxiv.org/abs/2511.01758", "authors": ["Mian Wu", "Gavin Zhang", "Sewon Min", "Sergey Levine", "Aviral Kumar"], "title": "RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Project page: https://mianwu01.github.io/RLAC_website/", "summary": "Open-ended generation tasks require outputs to satisfy diverse and often\nimplicit task-specific evaluation rubrics. The sheer number of relevant rubrics\nleads to prohibitively high verification costs and incomplete assessments of a\nresponse, making reinforcement learning (RL) post-training with rubric-based\nrewards difficult to scale. This problem is exacerbated by the fact that often\nthe best way to combine these rubrics into one single reward is also highly\nprompt-specific. We propose Reinforcement Learning with Adversarial Critic\n(RLAC), a post-training approach that addresses these challenges via dynamic\nrubric verification. Our approach employs a large language model (LLM) as a\ncritic that dynamically identifies only the most likely failure modes (e.g., a\nfactual error or unhandled edge case), which are then verified by an external\nvalidator to optimize both generator and critic jointly. By training both the\ngenerator and the critic, this game enhances the critic's error detection and\nthe generator's output quality while reducing required verifications. Our\nexperiments demonstrate that RLAC improves factual accuracy in text generation\nand correctness in code generation, while also outperforming exhaustive\nverification and reward model methods. We show that dynamic critics are more\neffective than fixed critics, showcasing the potential of RLAC for scaling RL\npost-training to free-form generation tasks.", "AI": {"tldr": "\u63d0\u51faRLAC\u65b9\u6cd5\u89e3\u51b3\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e2d\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6709\u826f\u597d\u6548\u679c\u3002", "motivation": "\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e2d\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u96be\u4ee5\u6269\u5c55\uff0c\u89c4\u5219\u7ec4\u5408\u65b9\u5f0f\u4e5f\u56e0\u63d0\u793a\u800c\u5f02\u3002", "method": "\u63d0\u51faReinforcement Learning with Adversarial Critic (RLAC)\u65b9\u6cd5\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u52a8\u6001\u8bc6\u522b\u6700\u53ef\u80fd\u5931\u8d25\u6a21\u5f0f\u7684\u8bc4\u5224\u5668\uff0c\u5e76\u7ed3\u5408\u5916\u90e8\u9a8c\u8bc1\u5668\u8054\u5408\u4f18\u5316\u751f\u6210\u5668\u548c\u8bc4\u5224\u5668\u3002", "result": "RLAC\u63d0\u9ad8\u4e86\u6587\u672c\u751f\u6210\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u4ee3\u7801\u751f\u6210\u7684\u6b63\u786e\u6027\uff0c\u4f18\u4e8e\u7a77\u4e3e\u9a8c\u8bc1\u548c\u5956\u52b1\u6a21\u578b\u65b9\u6cd5\u3002", "conclusion": "\u52a8\u6001\u8bc4\u5224\u5668\u6bd4\u56fa\u5b9a\u8bc4\u5224\u5668\u66f4\u6709\u6548\uff0cRLAC\u6709\u6f5c\u529b\u5c06\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u6269\u5c55\u5230\u81ea\u7531\u5f62\u5f0f\u751f\u6210\u4efb\u52a1\u3002"}}
{"id": "2511.01794", "pdf": "https://arxiv.org/pdf/2511.01794", "abs": "https://arxiv.org/abs/2511.01794", "authors": ["Vi Retault", "Yoha\u00ef-Eliel Berreby"], "title": "Random Initialization of Gated Sparse Adapters", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "13 pages (8 main), 6 figures (4 main). Accepted by NewInML workshop @\n  ICML 2025 on June 27, 2025", "summary": "When fine-tuning language models on new tasks, catastrophic forgetting --\nperformance degradation on previously-learned tasks -- is a ubiquitous problem.\nWhile Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA address this\nthrough low-rank adapters, sparse adaptation offers an alternative that doesn't\nimpose rank constraints. We introduce Random Initialization of Gated Sparse\nAdapters (RIGSA), which starts from randomly-initialized full-rank adapters,\ngates them with a ReZero analog, and sparsifies them with iterative magnitude\npruning. We evaluate RIGSA on SmolLM2-1.7B-Instruct using a novel\nvision-in-text task (Textual MNIST) and measure forgetting on PIQA, HellaSwag,\nand GSM8k. SmolLM2-1.7B-Instruct initially performs around chance level on\nTextual MNIST, and is capable of learning the task through RIGSA, 4-bit QLoRA\nand random masking. In spite of having more trainable parameters than QLoRA,\nthe RIGSA configurations that we studied displayed less forgetting than QLoRA,\nparticularly on GSM8k, though it performs comparably to random masking.", "AI": {"tldr": "\u63d0\u51faRIGSA\u65b9\u6cd5\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u65b0\u4efb\u52a1\u5b66\u4e60\u4e2d\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5728SmolLM2 - 1.7B - Instruct\u8bc4\u4f30\u663e\u793a\u5176\u9057\u5fd8\u5c11\u4e8eQLoRA\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u73b0\u6709PEFT\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u63a2\u7d22\u7a00\u758f\u9002\u5e94\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5f15\u5165RIGSA\uff0c\u4ece\u968f\u673a\u521d\u59cb\u5316\u7684\u5168\u79e9\u9002\u914d\u5668\u5f00\u59cb\uff0c\u7528ReZero\u7c7b\u4f3c\u65b9\u6cd5\u95e8\u63a7\uff0c\u8fed\u4ee3\u5e45\u5ea6\u526a\u679d\u4f7f\u5176\u7a00\u758f\u3002", "result": "SmolLM2 - 1.7B - Instruct\u80fd\u901a\u8fc7RIGSA\u30014 - bit QLoRA\u548c\u968f\u673a\u63a9\u7801\u5b66\u4e60\u65b0\u4efb\u52a1\uff0cRIGSA\u867d\u53ef\u8bad\u7ec3\u53c2\u6570\u66f4\u591a\uff0c\u4f46\u9057\u5fd8\u5c11\u4e8eQLoRA\uff0c\u5c24\u5176\u5728GSM8k\u4e0a\uff0c\u4e0e\u968f\u673a\u63a9\u7801\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "RIGSA\u5728\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8\u65b9\u9762\u6709\u4e00\u5b9a\u4f18\u52bf\u3002"}}
{"id": "2511.01800", "pdf": "https://arxiv.org/pdf/2511.01800", "abs": "https://arxiv.org/abs/2511.01800", "authors": ["Prateek Chanda", "Shrey Modi", "Ganesh Ramakrishnan"], "title": "Bayesian Coreset Optimization for Personalized Federated Learning", "categories": ["cs.LG", "I.2.6; H.3.3"], "comment": "9 pages, 5 figures, ICLR 2024", "summary": "In a distributed machine learning setting like Federated Learning where there\nare multiple clients involved which update their individual weights to a single\ncentral server, often training on the entire individual client's dataset for\neach client becomes cumbersome. To address this issue we propose $\\methodprop$:\na personalized coreset weighted federated learning setup where the training\nupdates for each individual clients are forwarded to the central server based\non only individual client coreset based representative data points instead of\nthe entire client data. Through theoretical analysis we present how the average\ngeneralization error is minimax optimal up to logarithm bounds (upper bounded\nby $\\mathcal{O}(n_k^{-\\frac{2 \\beta}{2 \\beta+\\boldsymbol{\\Lambda}}} \\log ^{2\n\\delta^{\\prime}}(n_k))$) and lower bounds of $\\mathcal{O}(n_k^{-\\frac{2\n\\beta}{2 \\beta+\\boldsymbol{\\Lambda}}})$, and how the overall generalization\nerror on the data likelihood differs from a vanilla Federated Learning setup as\na closed form function ${\\boldsymbol{\\Im}}(\\boldsymbol{w}, n_k)$ of the coreset\nweights $\\boldsymbol{w}$ and coreset sample size $n_k$. Our experiments on\ndifferent benchmark datasets based on a variety of recent personalized\nfederated learning architectures show significant gains as compared to random\nsampling on the training data followed by federated learning, thereby\nindicating how intelligently selecting such training samples can help in\nperformance. Additionally, through experiments on medical datasets our proposed\nmethod showcases some gains as compared to other submodular optimization based\napproaches used for subset selection on client's data.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.01804", "pdf": "https://arxiv.org/pdf/2511.01804", "abs": "https://arxiv.org/abs/2511.01804", "authors": ["Viraj Patel", "Lisa Kreusser", "Katharine Fraser"], "title": "Dynamic Reconstruction of Ultrasound-Derived Flow Fields With Physics-Informed Neural Fields", "categories": ["cs.LG"], "comment": "29 pages, 18 figures", "summary": "Blood flow is sensitive to disease and provides insight into cardiac\nfunction, making flow field analysis valuable for diagnosis. However, while\nsafer than radiation-based imaging and more suitable for patients with medical\nimplants, ultrasound suffers from attenuation with depth, limiting the quality\nof the image. Despite advances in echocardiographic particle image velocimetry\n(EchoPIV), accurately measuring blood velocity remains challenging due to the\ntechnique's limitations and the complexity of blood flow dynamics.\nPhysics-informed machine learning can enhance accuracy and robustness,\nparticularly in scenarios where noisy or incomplete data challenge purely\ndata-driven approaches. We present a physics-informed neural field model with\nmulti-scale Fourier Feature encoding for estimating blood flow from sparse and\nnoisy ultrasound data without requiring ground truth supervision. We\ndemonstrate that this model achieves consistently low mean squared error in\ndenoising and inpainting both synthetic and real datasets, verified against\nreference flow fields and ground truth flow rate measurements. While\nphysics-informed neural fields have been widely used to reconstruct medical\nimages, applications to medical flow reconstruction are mostly prominent in\nFlow MRI. In this work, we adapt methods that have proven effective in other\nimaging modalities to address the specific challenge of ultrasound-based flow\nreconstruction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u591a\u5c3a\u5ea6\u5085\u91cc\u53f6\u7279\u5f81\u7f16\u7801\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u4ece\u7a00\u758f\u548c\u5608\u6742\u7684\u8d85\u58f0\u6570\u636e\u4e2d\u4f30\u8ba1\u8840\u6d41\uff0c\u5728\u53bb\u566a\u548c\u4fee\u590d\u6570\u636e\u96c6\u4e0a\u6548\u679c\u826f\u597d\u3002", "motivation": "\u8d85\u58f0\u6210\u50cf\u6709\u5c40\u9650\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u51c6\u786e\u6d4b\u91cf\u8840\u6d41\u901f\u5ea6\u6709\u6311\u6218\uff0c\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u53ef\u63d0\u5347\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u5e26\u591a\u5c3a\u5ea6\u5085\u91cc\u53f6\u7279\u5f81\u7f16\u7801\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\u76d1\u7763\u3002", "result": "\u6a21\u578b\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u7684\u53bb\u566a\u548c\u4fee\u590d\u4e2d\u5747\u5b9e\u73b0\u4f4e\u5747\u65b9\u8bef\u5dee\u3002", "conclusion": "\u5c06\u5176\u4ed6\u6210\u50cf\u65b9\u5f0f\u6709\u6548\u7684\u65b9\u6cd5\u5e94\u7528\u4e8e\u8d85\u58f0\u8840\u6d41\u91cd\u5efa\u95ee\u9898\u3002"}}
{"id": "2511.01816", "pdf": "https://arxiv.org/pdf/2511.01816", "abs": "https://arxiv.org/abs/2511.01816", "authors": ["Maryam Bagherian"], "title": "No-rank Tensor Decomposition Using Metric Learning", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Tensor decomposition faces fundamental challenges in analyzing\nhigh-dimensional data, where traditional methods based on reconstruction and\nfixed-rank constraints often fail to capture semantically meaningful\nstructures. This paper introduces a no-rank tensor decomposition framework\ngrounded in metric learning, which replaces reconstruction objectives with a\ndiscriminative, similarity-based optimization. The proposed approach learns\ndata-driven embeddings by optimizing a triplet loss with diversity and\nuniformity regularization, creating a feature space where distance directly\nreflects semantic similarity. We provide theoretical guarantees for the\nframework's convergence and establish bounds on its metric properties.\nEvaluations across diverse domains --including face recognition (LFW,\nOlivetti), brain connectivity analysis (ABIDE), and simulated data (galaxy\nmorphology, crystal structures)-- demonstrate that our method outperforms\nbaseline techniques, including PCA, t-SNE, UMAP, and tensor decomposition\nbaselines (CP and Tucker). Results show substantial improvements in clustering\nmetrics (Silhouette Score, Davies--Bouldin Index, Calinski--Harabasz Index,\nSeparation Ratio, Adjusted Rand Index, Normalized Mutual Information) and\nreveal a fundamental trade-off: while metric learning optimizes global class\nseparation, it deliberately transforms local geometry to align with semantic\nrelationships. Crucially, our approach achieves superior performance with\nsmaller training datasets compared to transformer-based methods, offering an\nefficient alternative for domains with limited labeled data. This work\nestablishes metric learning as a paradigm for tensor-based analysis,\nprioritizing semantic relevance over pixel-level fidelity while providing\ncomputational advantages in data-scarce scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u65e0\u79e9\u5f20\u91cf\u5206\u89e3\u6846\u67b6\uff0c\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u5728\u591a\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u597d\uff0c\u786e\u7acb\u5ea6\u91cf\u5b66\u4e60\u4e3a\u5f20\u91cf\u5206\u6790\u8303\u5f0f\u3002", "motivation": "\u4f20\u7edf\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u5728\u5206\u6790\u9ad8\u7ef4\u6570\u636e\u65f6\u96be\u4ee5\u6355\u6349\u8bed\u4e49\u6709\u610f\u4e49\u7684\u7ed3\u6784\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5ea6\u91cf\u5b66\u4e60\u7684\u65e0\u79e9\u5f20\u91cf\u5206\u89e3\u6846\u67b6\uff0c\u7528\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u5224\u522b\u5f0f\u4f18\u5316\u66ff\u4ee3\u91cd\u5efa\u76ee\u6807\uff0c\u901a\u8fc7\u4f18\u5316\u5e26\u6b63\u5219\u5316\u7684\u4e09\u5143\u7ec4\u635f\u5931\u5b66\u4e60\u6570\u636e\u9a71\u52a8\u7684\u5d4c\u5165\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u7684\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u805a\u7c7b\u6307\u6807\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f18\u4e8ePCA\u3001t - SNE\u7b49\u57fa\u7ebf\u6280\u672f\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u6bd4\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u8868\u73b0\u597d\u3002", "conclusion": "\u786e\u7acb\u5ea6\u91cf\u5b66\u4e60\u4e3a\u57fa\u4e8e\u5f20\u91cf\u5206\u6790\u7684\u8303\u5f0f\uff0c\u4f18\u5148\u8003\u8651\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u6709\u8ba1\u7b97\u4f18\u52bf\u3002"}}
{"id": "2511.01819", "pdf": "https://arxiv.org/pdf/2511.01819", "abs": "https://arxiv.org/abs/2511.01819", "authors": ["Hamed Fard", "Mahsa Kholghi", "Benedikt Gro\u00df", "Gerhard Wunder"], "title": "Machine and Deep Learning for Indoor UWB Jammer Localization", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the 20th International Conference on Risks and Security\n  of Internet and Systems (CRiSIS 2025, Gatineau-Canada,\n  https://crisis2025.uqo.ca/). The paper will soon be published as\n  post-proceedings in Springer's LNCS", "summary": "Ultra-wideband (UWB) localization delivers centimeter-scale accuracy but is\nvulnerable to jamming attacks, creating security risks for asset tracking and\nintrusion detection in smart buildings. Although machine learning (ML) and deep\nlearning (DL) methods have improved tag localization, localizing malicious\njammers within a single room and across changing indoor layouts remains largely\nunexplored. Two novel UWB datasets, collected under original and modified room\nconfigurations, are introduced to establish comprehensive ML/DL baselines.\nPerformance is rigorously evaluated using a variety of classification and\nregression metrics. On the source dataset with the collected UWB features,\nRandom Forest achieves the highest F1-macro score of 0.95 and XGBoost achieves\nthe lowest mean Euclidean error of 20.16 cm. However, deploying these\nsource-trained models in the modified room layout led to severe performance\ndegradation, with XGBoost's mean Euclidean error increasing tenfold to 207.99\ncm, demonstrating significant domain shift. To mitigate this degradation, a\ndomain-adversarial ConvNeXt autoencoder (A-CNT) is proposed that leverages a\ngradient-reversal layer to align CIR-derived features across domains. The A-CNT\nframework restores localization performance by reducing the mean Euclidean\nerror to 34.67 cm. This represents a 77 percent improvement over\nnon-adversarial transfer learning and an 83 percent improvement over the best\nbaseline, restoring the fraction of samples within 30 cm to 0.56. Overall, the\nresults demonstrate that adversarial feature alignment enables robust and\ntransferable indoor jammer localization despite environmental changes. Code and\ndataset available at https://github.com/afbf4c8996f/Jammer-Loc", "AI": {"tldr": "\u672c\u6587\u5f15\u5165UWB\u6570\u636e\u96c6\u5efa\u7acbML/DL\u57fa\u7ebf\uff0c\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u53d1\u73b0\u57df\u504f\u79fb\u95ee\u9898\uff0c\u63d0\u51faA - CNT\u6846\u67b6\u7f13\u89e3\u6027\u80fd\u4e0b\u964d\uff0c\u5b9e\u73b0\u9c81\u68d2\u53ef\u8fc1\u79fb\u7684\u5ba4\u5185\u5e72\u6270\u5668\u5b9a\u4f4d\u3002", "motivation": "UWB\u5b9a\u4f4d\u6613\u53d7\u5e72\u6270\u653b\u51fb\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5355\u623f\u95f4\u548c\u4e0d\u540c\u5ba4\u5185\u5e03\u5c40\u4e0b\u5b9a\u4f4d\u6076\u610f\u5e72\u6270\u5668\u7684\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u4e24\u4e2aUWB\u6570\u636e\u96c6\u5efa\u7acbML/DL\u57fa\u7ebf\uff0c\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f30\u6027\u80fd\uff0c\u63d0\u51fa\u57df\u5bf9\u6297ConvNeXt\u81ea\u7f16\u7801\u5668\uff08A - CNT\uff09\u6846\u67b6\u7f13\u89e3\u57df\u504f\u79fb\u3002", "result": "\u6e90\u6570\u636e\u96c6\u4e0aRandom Forest\u7684F1 - macro\u5206\u6570\u6700\u9ad8\u4e3a0.95\uff0cXGBoost\u7684\u5e73\u5747\u6b27\u6c0f\u8bef\u5dee\u6700\u4f4e\u4e3a20.16 cm\uff1b\u5e03\u5c40\u6539\u53d8\u540e\u6027\u80fd\u4e0b\u964d\uff0cA - CNT\u6846\u67b6\u5c06\u5e73\u5747\u6b27\u6c0f\u8bef\u5dee\u964d\u81f334.67 cm\uff0c\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u5bf9\u6297\u6027\u7279\u5f81\u5bf9\u9f50\u80fd\u5b9e\u73b0\u9c81\u68d2\u4e14\u53ef\u8fc1\u79fb\u7684\u5ba4\u5185\u5e72\u6270\u5668\u5b9a\u4f4d\uff0c\u4e0d\u53d7\u73af\u5883\u53d8\u5316\u5f71\u54cd\u3002"}}
{"id": "2511.00576", "pdf": "https://arxiv.org/pdf/2511.00576", "abs": "https://arxiv.org/abs/2511.00576", "authors": ["Juan Gabriel Kostelec", "Qinghai Guo"], "title": "FlashEVA: Accelerating LLM inference via Efficient Attention", "categories": ["cs.CL", "cs.AI"], "comment": "Technical Report", "summary": "Transformer models have revolutionized natural language processing, achieving\nstate-of-the-art performance and demonstrating remarkable scalability. However,\ntheir memory demands, particularly due to maintaining full context in memory,\npose significant challenges for inference. In this paper, we present FlashEVA,\nan efficient implementation of EVA (Efficient Attention via Control Variates),\nand demonstrate how to finetune transformers to adapt to FlashEVA attention.\nOur method enables fine-tuning of Transformer models with as few as 1.5B tokens\nwhile preserving effectiveness across various downstream tasks. Notably,\nFlashEVA achieves up to 6.7x higher throughput and 5x lower peak GPU memory\nusage during inference compared to standard Transformer implementations.\nDespite these improvements, we observe limitations in retrieval-focused tasks.\nOur implementation offers control over the trade-off between throughput and\naccuracy through adjustable hyperparameters, providing flexibility for diverse\nuse cases. This work represents a significant step towards more efficient and\nadaptable Transformer-based models for inference.", "AI": {"tldr": "\u63d0\u51faFlashEVA\u5b9e\u73b0\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5fae\u8c03Transformer\u6a21\u578b\uff0c\u63d0\u9ad8\u63a8\u7406\u541e\u5410\u91cf\u3001\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\uff0c\u6709\u5c40\u9650\u6027\u4f46\u53ef\u7075\u6d3b\u8c03\u6574\u3002", "motivation": "Transformer\u6a21\u578b\u63a8\u7406\u65f6\u5185\u5b58\u9700\u6c42\u5927\uff0c\u89e3\u51b3\u5176\u5185\u5b58\u6311\u6218\u95ee\u9898\u3002", "method": "\u63d0\u51faFlashEVA\u5e76\u5c55\u793a\u5982\u4f55\u5fae\u8c03Transformer\u4ee5\u9002\u5e94\u5176\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u5c11\u91cf\u4ee4\u724c\u5fae\u8c03\u3002", "result": "\u5b9e\u73b0\u9ad8\u8fbe6.7\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u548c5\u500d\u7684\u5cf0\u503cGPU\u5185\u5b58\u4f7f\u7528\u964d\u4f4e\uff0c\u68c0\u7d22\u4efb\u52a1\u6709\u5c40\u9650\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u662f\u8fc8\u5411\u66f4\u9ad8\u6548\u3001\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u57fa\u4e8eTransformer\u7684\u63a8\u7406\u6a21\u578b\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.01830", "pdf": "https://arxiv.org/pdf/2511.01830", "abs": "https://arxiv.org/abs/2511.01830", "authors": ["Paul Setinek", "Gianluca Galletti", "Johannes Brandstetter"], "title": "Towards Multi-Fidelity Scaling Laws of Neural Surrogates in CFD", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Scaling laws describe how model performance grows with data, parameters and\ncompute. While large datasets can usually be collected at relatively low cost\nin domains such as language or vision, scientific machine learning is often\nlimited by the high expense of generating training data through numerical\nsimulations. However, by adjusting modeling assumptions and approximations,\nsimulation fidelity can be traded for computational cost, an aspect absent in\nother domains. We investigate this trade-off between data fidelity and cost in\nneural surrogates using low- and high-fidelity Reynolds-Averaged Navier-Stokes\n(RANS) simulations. Reformulating classical scaling laws, we decompose the\ndataset axis into compute budget and dataset composition. Our experiments\nreveal compute-performance scaling behavior and exhibit budget-dependent\noptimal fidelity mixes for the given dataset configuration. These findings\nprovide the first study of empirical scaling laws for multi-fidelity neural\nsurrogate datasets and offer practical considerations for compute-efficient\ndataset generation in scientific machine learning.", "AI": {"tldr": "\u7814\u7a76\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u6570\u636e\u4fdd\u771f\u5ea6\u4e0e\u6210\u672c\u7684\u6743\u8861\uff0c\u91cd\u65b0\u5b9a\u4e49\u7ecf\u5178\u7f29\u653e\u5b9a\u5f8b\uff0c\u53d1\u73b0\u8ba1\u7b97 - \u6027\u80fd\u7f29\u653e\u884c\u4e3a\u548c\u6700\u4f18\u4fdd\u771f\u5ea6\u7ec4\u5408\u3002", "motivation": "\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u53d7\u8bad\u7ec3\u6570\u636e\u751f\u6210\u6210\u672c\u9ad8\u9650\u5236\uff0c\u9700\u7814\u7a76\u6570\u636e\u4fdd\u771f\u5ea6\u4e0e\u6210\u672c\u7684\u6743\u8861\u3002", "method": "\u4f7f\u7528\u4f4e\u548c\u9ad8\u4fdd\u771f\u5ea6\u96f7\u8bfa\u5e73\u5747\u7eb3\u7ef4 - \u65af\u6258\u514b\u65af\uff08RANS\uff09\u6a21\u62df\uff0c\u91cd\u65b0\u5b9a\u4e49\u7ecf\u5178\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c06\u6570\u636e\u96c6\u8f74\u5206\u89e3\u4e3a\u8ba1\u7b97\u9884\u7b97\u548c\u6570\u636e\u96c6\u7ec4\u6210\u3002", "result": "\u63ed\u793a\u8ba1\u7b97 - \u6027\u80fd\u7f29\u653e\u884c\u4e3a\uff0c\u5c55\u793a\u7ed9\u5b9a\u6570\u636e\u96c6\u914d\u7f6e\u4e0b\u4f9d\u8d56\u9884\u7b97\u7684\u6700\u4f18\u4fdd\u771f\u5ea6\u7ec4\u5408\u3002", "conclusion": "\u9996\u6b21\u5bf9\u591a\u4fdd\u771f\u5ea6\u795e\u7ecf\u4ee3\u7406\u6570\u636e\u96c6\u7684\u7ecf\u9a8c\u7f29\u653e\u5b9a\u5f8b\u8fdb\u884c\u7814\u7a76\uff0c\u4e3a\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u9ad8\u6548\u8ba1\u7b97\u7684\u6570\u636e\u96c6\u751f\u6210\u63d0\u4f9b\u5b9e\u7528\u8003\u8651\u3002"}}
{"id": "2511.00580", "pdf": "https://arxiv.org/pdf/2511.00580", "abs": "https://arxiv.org/abs/2511.00580", "authors": ["Yousuf Ahmed Siddiqui", "Sufiyaan Usmani", "Umer Tariq", "Jawwad Ahmed Shamsi", "Muhammad Burhan Khan"], "title": "TRACES: Temporal Recall with Contextual Embeddings for Real-Time Video Anomaly Detection", "categories": ["cs.CV", "cs.AI", "68T07, 68T45, 68U10", "I.2.10; I.5.4; I.4.8; C.3"], "comment": "10 pages, 5 figures", "summary": "Video anomalies often depend on contextual information available and temporal\nevolution. Non-anomalous action in one context can be anomalous in some other\ncontext. Most anomaly detectors, however, do not notice this type of context,\nwhich seriously limits their capability to generalize to new, real-life\nsituations. Our work addresses the context-aware zero-shot anomaly detection\nchallenge, in which systems need to learn adaptively to detect new events by\ncorrelating temporal and appearance features with textual traces of memory in\nreal time. Our approach defines a memory-augmented pipeline, correlating\ntemporal signals with visual embeddings using cross-attention, and real-time\nzero-shot anomaly classification by contextual similarity scoring. We achieve\n90.4\\% AUC on UCF-Crime and 83.67\\% AP on XD-Violence, a new state-of-the-art\namong zero-shot models. Our model achieves real-time inference with high\nprecision and explainability for deployment. We show that, by fusing\ncross-attention temporal fusion and contextual memory, we achieve high fidelity\nanomaly detection, a step towards the applicability of zero-shot models in\nreal-world surveillance and infrastructure monitoring.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bb0\u5fc6\u589e\u5f3a\u7ba1\u9053\u65b9\u6cd5\u89e3\u51b3\u4e0a\u4e0b\u6587\u611f\u77e5\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\u6311\u6218\uff0c\u5728UCF - Crime\u548cXD - Violence\u6570\u636e\u96c6\u53d6\u5f97\u65b0\u7684\u6700\u4f18\u7ed3\u679c\uff0c\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\u3002", "motivation": "\u591a\u6570\u5f02\u5e38\u68c0\u6d4b\u5668\u672a\u8003\u8651\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u9650\u5236\u5176\u5728\u65b0\u7684\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u8981\u89e3\u51b3\u4e0a\u4e0b\u6587\u611f\u77e5\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u5b9a\u4e49\u8bb0\u5fc6\u589e\u5f3a\u7ba1\u9053\uff0c\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u5c06\u65f6\u95f4\u4fe1\u53f7\u4e0e\u89c6\u89c9\u5d4c\u5165\u76f8\u5173\u8054\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u76f8\u4f3c\u5ea6\u8bc4\u5206\u8fdb\u884c\u5b9e\u65f6\u96f6\u6837\u672c\u5f02\u5e38\u5206\u7c7b\u3002", "result": "\u5728UCF - Crime\u4e0aAUC\u8fbe\u523090.4%\uff0c\u5728XD - Violence\u4e0aAP\u8fbe\u523083.67%\uff0c\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\uff0c\u5177\u6709\u9ad8\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u878d\u5408\u4ea4\u53c9\u6ce8\u610f\u529b\u65f6\u95f4\u878d\u5408\u548c\u4e0a\u4e0b\u6587\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5f02\u5e38\u68c0\u6d4b\uff0c\u63a8\u52a8\u96f6\u6837\u672c\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u76d1\u63a7\u548c\u57fa\u7840\u8bbe\u65bd\u76d1\u6d4b\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.01831", "pdf": "https://arxiv.org/pdf/2511.01831", "abs": "https://arxiv.org/abs/2511.01831", "authors": ["Jay Mohta", "Kenan Emir Ak", "Dimitrios Dimitriadis", "Yan Xu", "Mingwei Shen"], "title": "Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) suffer from catastrophic forgetting when\nsequentially fine-tuned on new tasks, degrading performance on previously\nlearned foundational and task-specific capabilities. While multi-task learning\ncan mitigate forgetting, it requires simultaneous access to all datasets and\nimposes computational overhead that scales linearly with the number of tasks.\nIn this work, we introduce a routing-based approach that enables the\nintegration of new tasks while preserving the foundational knowledge acquired\nduring pretraining. We evaluate our method using InternVL-2 models (2B and 8B\nparameters) and demonstrate that routing preserves the model's foundational\ncapabilities by maintaining performance on general-purpose benchmarks such as\nChartQA, MMBench, and DocVQA, while simultaneously improving accuracy on\nspecialized tasks. Importantly, our approach achieves this without requiring\nconcurrent access to data from all tasks, avoiding the significant\ncomputational and data overhead associated with traditional multi-task\nlearning. We further conduct extensive ablation studies to evaluate the\nscalability and robustness of routing-based learning, showing that the approach\nis resilient to a growing number of tasks and performs particularly well when\nnew tasks are semantically related. Finally, we show that the routing mechanism\nenables superior cross-modal transfer between language and vision capabilities,\nallowing knowledge learned in one modality to enhance performance in another\ncapability not achieved by existing continual learning methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8def\u7531\u7684\u65b9\u6cd5\uff0c\u5728\u96c6\u6210\u65b0\u4efb\u52a1\u65f6\u4fdd\u7559\u9884\u8bad\u7ec3\u57fa\u7840\u80fd\u529b\uff0c\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u4e14\u907f\u514d\u4f20\u7edf\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u5f00\u9500\uff0c\u8fd8\u80fd\u5b9e\u73b0\u8de8\u6a21\u6001\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\u987a\u5e8f\u5fae\u8c03\u65b0\u4efb\u52a1\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u907f\u514d\u4f20\u7edf\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u9ad8\u5f00\u9500\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u8def\u7531\u7684\u65b9\u6cd5\uff0c\u5229\u7528InternVL - 2\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5f00\u5c55\u6d88\u878d\u5b9e\u9a8c\u3002", "result": "\u8def\u7531\u65b9\u6cd5\u4fdd\u7559\u6a21\u578b\u57fa\u7840\u80fd\u529b\uff0c\u63d0\u5347\u7279\u5b9a\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u907f\u514d\u4f20\u7edf\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u5f00\u9500\uff0c\u5bf9\u4efb\u52a1\u6570\u91cf\u589e\u957f\u6709\u97e7\u6027\uff0c\u8bed\u4e49\u76f8\u5173\u4efb\u52a1\u8868\u73b0\u597d\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u8fc1\u79fb\u3002", "conclusion": "\u57fa\u4e8e\u8def\u7531\u7684\u65b9\u6cd5\u80fd\u5728\u96c6\u6210\u65b0\u4efb\u52a1\u65f6\u4fdd\u7559\u57fa\u7840\u80fd\u529b\uff0c\u907f\u514d\u9ad8\u5f00\u9500\uff0c\u8fd8\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u8de8\u6a21\u6001\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2511.01836", "pdf": "https://arxiv.org/pdf/2511.01836", "abs": "https://arxiv.org/abs/2511.01836", "authors": ["Ekdeep Singh Lubana", "Can Rager", "Sai Sumedh R. Hindupur", "Valerie Costa", "Greta Tuckute", "Oam Patel", "Sonia Krishna Murthy", "Thomas Fel", "Daniel Wurgaft", "Eric J. Bigelow", "Johnny Lin", "Demba Ba", "Martin Wattenberg", "Fernanda Viegas", "Melanie Weber", "Aaron Mueller"], "title": "Priors in Time: Missing Inductive Biases for Language Model Interpretability", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Recovering meaningful concepts from language model activations is a central\naim of interpretability. While existing feature extraction methods aim to\nidentify concepts that are independent directions, it is unclear if this\nassumption can capture the rich temporal structure of language. Specifically,\nvia a Bayesian lens, we demonstrate that Sparse Autoencoders (SAEs) impose\npriors that assume independence of concepts across time, implying stationarity.\nMeanwhile, language model representations exhibit rich temporal dynamics,\nincluding systematic growth in conceptual dimensionality, context-dependent\ncorrelations, and pronounced non-stationarity, in direct conflict with the\npriors of SAEs. Taking inspiration from computational neuroscience, we\nintroduce a new interpretability objective -- Temporal Feature Analysis --\nwhich possesses a temporal inductive bias to decompose representations at a\ngiven time into two parts: a predictable component, which can be inferred from\nthe context, and a residual component, which captures novel information\nunexplained by the context. Temporal Feature Analyzers correctly parse garden\npath sentences, identify event boundaries, and more broadly delineate abstract,\nslow-moving information from novel, fast-moving information, while existing\nSAEs show significant pitfalls in all the above tasks. Overall, our results\nunderscore the need for inductive biases that match the data in designing\nrobust interpretability tools.", "AI": {"tldr": "\u73b0\u6709\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5047\u8bbe\u6982\u5ff5\u72ec\u7acb\uff0c\u53ef\u80fd\u65e0\u6cd5\u6355\u6349\u8bed\u8a00\u7684\u4e30\u5bcc\u65f6\u95f4\u7ed3\u6784\uff0c\u672c\u6587\u63d0\u51fa\u65f6\u95f4\u7279\u5f81\u5206\u6790\u76ee\u6807\uff0c\u80fd\u66f4\u597d\u5b8c\u6210\u76f8\u5173\u4efb\u52a1\uff0c\u5f3a\u8c03\u8bbe\u8ba1\u89e3\u91ca\u5de5\u5177\u9700\u5339\u914d\u6570\u636e\u7684\u5f52\u7eb3\u504f\u5dee\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5047\u8bbe\u6982\u5ff5\u72ec\u7acb\uff0c\u4e0d\u786e\u5b9a\u80fd\u5426\u6355\u6349\u8bed\u8a00\u4e30\u5bcc\u65f6\u95f4\u7ed3\u6784\uff0c\u9700\u65b0\u7684\u89e3\u91ca\u76ee\u6807\u3002", "method": "\u4ece\u8d1d\u53f6\u65af\u89c6\u89d2\u5206\u6790\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u7684\u5148\u9a8c\u5047\u8bbe\uff0c\u501f\u9274\u8ba1\u7b97\u795e\u7ecf\u79d1\u5b66\u5f15\u5165\u65f6\u95f4\u7279\u5f81\u5206\u6790\u76ee\u6807\u3002", "result": "\u65f6\u95f4\u7279\u5f81\u5206\u6790\u5668\u80fd\u6b63\u786e\u89e3\u6790\u82b1\u56ed\u8def\u5f84\u53e5\u5b50\u3001\u8bc6\u522b\u4e8b\u4ef6\u8fb9\u754c\u7b49\uff0c\u800c\u73b0\u6709SAEs\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u6709\u660e\u663e\u7f3a\u9677\u3002", "conclusion": "\u8bbe\u8ba1\u7a33\u5065\u89e3\u91ca\u5de5\u5177\u9700\u8981\u4e0e\u6570\u636e\u5339\u914d\u7684\u5f52\u7eb3\u504f\u5dee\u3002"}}
{"id": "2511.01837", "pdf": "https://arxiv.org/pdf/2511.01837", "abs": "https://arxiv.org/abs/2511.01837", "authors": ["Isabela Suaza-Sierra", "Hernan A. Moreno", "Luis A De la Fuente", "Thomas M. Neeson"], "title": "Interpretable Machine Learning for Reservoir Water Temperatures in the U.S. Red River Basin of the South", "categories": ["cs.LG"], "comment": null, "summary": "Accurate prediction of Reservoir Water Temperature (RWT) is vital for\nsustainable water management, ecosystem health, and climate resilience. Yet,\nprediction alone offers limited insight into the governing physical processes.\nTo bridge this gap, we integrated explainable machine learning (ML) with\nsymbolic modeling to uncover the drivers of RWT dynamics across ten reservoirs\nin the Red River Basin, USA, using over 10,000 depth-resolved temperature\nprofiles. We first employed ensemble and neural models, including Random Forest\n(RF), Extreme Gradient Boosting (XGBoost), and Multilayer Perceptron (MLP),\nachieving high predictive skill (best RMSE = 1.20 degree Celsius, R^2 = 0.97).\nUsing SHAP (SHapley Additive exPlanations), we quantified the contribution of\nphysical drivers such as air temperature, depth, wind, and lake volume,\nrevealing consistent patterns across reservoirs. To translate these data-driven\ninsights into compact analytical expressions, we developed Kolmogorov Arnold\nNetworks (KANs) to symbolically approximate RWT. Ten progressively complex KAN\nequations were derived, improving from R^2 = 0.84 using a single predictor\n(7-day antecedent air temperature) to R^2 = 0.92 with ten predictors, though\ngains diminished beyond five, highlighting a balance between simplicity and\naccuracy. The resulting equations, dominated by linear and rational forms,\nincrementally captured nonlinear behavior while preserving interpretability.\nDepth consistently emerged as a secondary but critical predictor, whereas\nprecipitation had limited effect. By coupling predictive accuracy with\nexplanatory power, this framework demonstrates how KANs and explainable ML can\ntransform black-box models into transparent surrogates that advance both\nprediction and understanding of reservoir thermal dynamics.", "AI": {"tldr": "\u7ed3\u5408\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u548c\u7b26\u53f7\u5efa\u6a21\u7814\u7a76\u7f8e\u56fd\u7ea2\u6cb3\u76c6\u5730\u5341\u4e2a\u6c34\u5e93\u6c34\u6e29\u52a8\u6001\u9a71\u52a8\u56e0\u7d20\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u5e76\u83b7\u5f97\u53ef\u89e3\u91ca\u65b9\u7a0b\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u6c34\u5e93\u6c34\u6e29\u5bf9\u53ef\u6301\u7eed\u6c34\u7ba1\u7406\u7b49\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9884\u6d4b\u672c\u8eab\u5bf9\u7269\u7406\u8fc7\u7a0b\u6d1e\u5bdf\u6709\u9650\uff0c\u9700\u63ed\u793a\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u5148\u4f7f\u7528\u96c6\u6210\u548c\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08RF\u3001XGBoost\u3001MLP\uff09\u8fdb\u884c\u9884\u6d4b\uff0c\u7528SHAP\u91cf\u5316\u7269\u7406\u9a71\u52a8\u56e0\u7d20\u8d21\u732e\uff0c\u518d\u5f00\u53d1Kolmogorov Arnold Networks (KANs) \u7b26\u53f7\u8fd1\u4f3c\u6c34\u6e29\u3002", "result": "\u9884\u6d4b\u6280\u80fd\u9ad8\uff08\u6700\u4f73RMSE = 1.20\u6444\u6c0f\u5ea6\uff0cR^2 = 0.97\uff09\uff1bKAN\u65b9\u7a0b\u4ece\u5355\u9884\u6d4b\u56e0\u5b50R^2 = 0.84\u63d0\u5347\u5230\u5341\u4e2a\u9884\u6d4b\u56e0\u5b50R^2 = 0.92\uff1b\u6df1\u5ea6\u662f\u5173\u952e\u6b21\u8981\u9884\u6d4b\u56e0\u5b50\uff0c\u964d\u6c34\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u9ed1\u7bb1\u6a21\u578b\u8f6c\u5316\u4e3a\u900f\u660e\u66ff\u4ee3\u6a21\u578b\uff0c\u63a8\u52a8\u6c34\u5e93\u70ed\u52a8\u529b\u5b66\u7684\u9884\u6d4b\u548c\u7406\u89e3\u3002"}}
{"id": "2511.01855", "pdf": "https://arxiv.org/pdf/2511.01855", "abs": "https://arxiv.org/abs/2511.01855", "authors": ["Bettina Hanlon", "Angel Garcia Fernandez"], "title": "Coordinate ascent neural Kalman-MLE for state estimation", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a coordinate ascent algorithm to learn dynamic and\nmeasurement models in dynamic state estimation using maximum likelihood\nestimation in a supervised manner. In particular, the dynamic and measurement\nmodels are assumed to be Gaussian and the algorithm learns the neural network\nparameters that model the dynamic and measurement functions, and also the noise\ncovariance matrices. The trained dynamic and measurement models are then used\nwith a non-linear Kalman filter algorithm to estimate the state during the\ntesting phase.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5750\u6807\u4e0a\u5347\u7b97\u6cd5\uff0c\u4ee5\u76d1\u7763\u65b9\u5f0f\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5b66\u4e60\u52a8\u6001\u72b6\u6001\u4f30\u8ba1\u4e2d\u7684\u52a8\u6001\u548c\u6d4b\u91cf\u6a21\u578b\uff0c\u5e76\u7528\u975e\u7ebf\u6027\u5361\u5c14\u66fc\u6ee4\u6ce2\u7b97\u6cd5\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\u3002", "motivation": "\u5b66\u4e60\u52a8\u6001\u72b6\u6001\u4f30\u8ba1\u4e2d\u7684\u52a8\u6001\u548c\u6d4b\u91cf\u6a21\u578b\u3002", "method": "\u91c7\u7528\u5750\u6807\u4e0a\u5347\u7b97\u6cd5\uff0c\u4ee5\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u76d1\u7763\u65b9\u5f0f\u5b66\u4e60\uff0c\u5047\u8bbe\u6a21\u578b\u4e3a\u9ad8\u65af\u5206\u5e03\uff0c\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u548c\u566a\u58f0\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u6d4b\u8bd5\u9636\u6bb5\u7ed3\u5408\u975e\u7ebf\u6027\u5361\u5c14\u66fc\u6ee4\u6ce2\u7b97\u6cd5\u3002", "result": "\u672a\u63d0\u53ca\u3002", "conclusion": "\u672a\u63d0\u53ca\u3002"}}
{"id": "2510.26081", "pdf": "https://arxiv.org/pdf/2510.26081", "abs": "https://arxiv.org/abs/2510.26081", "authors": ["Octavio Vega", "Javad Komijani", "Aida El-Khadra", "Marina Marinkovic"], "title": "Group-Equivariant Diffusion Models for Lattice Field Theory", "categories": ["hep-lat", "cs.LG"], "comment": "45 pages, 12 figures", "summary": "Near the critical point, Markov Chain Monte Carlo (MCMC) simulations of\nlattice quantum field theories (LQFT) become increasingly inefficient due to\ncritical slowing down. In this work, we investigate score-based\nsymmetry-preserving diffusion models as an alternative strategy to sample\ntwo-dimensional $\\phi^4$ and ${\\rm U}(1)$ lattice field theories. We develop\nscore networks that are equivariant to a range of group transformations,\nincluding global $\\mathbb{Z}_2$ reflections, local ${\\rm U}(1)$ rotations, and\nperiodic translations $\\mathbb{T}$. The score networks are trained using an\naugmented training scheme, which significantly improves sample quality in the\nsimulated field theories. We also demonstrate empirically that our\nsymmetry-aware models outperform generic score networks in sample quality,\nexpressivity, and effective sample size.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u5206\u6570\u7684\u5bf9\u79f0\u4fdd\u6301\u6269\u6563\u6a21\u578b\u6765\u91c7\u6837\u4e8c\u7ef4\u683c\u70b9\u573a\u8bba\uff0c\u5f00\u53d1\u7b49\u53d8\u5206\u6570\u7f51\u7edc\u5e76\u91c7\u7528\u589e\u5f3a\u8bad\u7ec3\u65b9\u6848\uff0c\u5bf9\u79f0\u611f\u77e5\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u683c\u70b9\u91cf\u5b50\u573a\u8bba\u5728\u4e34\u754c\u70b9\u9644\u8fd1\u56e0\u4e34\u754c\u6162\u5316\u5bfc\u81f4\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u7f57\u6a21\u62df\u6548\u7387\u4f4e\uff0c\u9700\u66ff\u4ee3\u91c7\u6837\u7b56\u7565\u3002", "method": "\u5f00\u53d1\u5bf9\u591a\u79cd\u7fa4\u53d8\u6362\u7b49\u53d8\u7684\u5206\u6570\u7f51\u7edc\uff0c\u91c7\u7528\u589e\u5f3a\u8bad\u7ec3\u65b9\u6848\u3002", "result": "\u5bf9\u79f0\u611f\u77e5\u6a21\u578b\u5728\u6837\u672c\u8d28\u91cf\u3001\u8868\u8fbe\u80fd\u529b\u548c\u6709\u6548\u6837\u672c\u91cf\u4e0a\u4f18\u4e8e\u901a\u7528\u5206\u6570\u7f51\u7edc\u3002", "conclusion": "\u57fa\u4e8e\u5206\u6570\u7684\u5bf9\u79f0\u4fdd\u6301\u6269\u6563\u6a21\u578b\u662f\u91c7\u6837\u4e8c\u7ef4\u683c\u70b9\u573a\u8bba\u7684\u6709\u6548\u66ff\u4ee3\u7b56\u7565\u3002"}}
{"id": "2511.00641", "pdf": "https://arxiv.org/pdf/2511.00641", "abs": "https://arxiv.org/abs/2511.00641", "authors": ["Swapnil Bhosale", "Cosmin Frateanu", "Camilla Clark", "Arnoldas Jasonas", "Chris Mitchell", "Xiatian Zhu", "Vamsi Krishna Ithapu", "Giacomo Ferroni", "Cagdas Bilen", "Sanjeel Parekh"], "title": "More Than A Shortcut: A Hyperbolic Approach To Early-Exit Networks", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Deploying accurate event detection on resource-constrained devices is\nchallenged by the trade-off between performance and computational cost. While\nEarly-Exit (EE) networks offer a solution through adaptive computation, they\noften fail to enforce a coherent hierarchical structure, limiting the\nreliability of their early predictions. To address this, we propose Hyperbolic\nEarly-Exit networks (HypEE), a novel framework that learns EE representations\nin the hyperbolic space. Our core contribution is a hierarchical training\nobjective with a novel entailment loss, which enforces a partial-ordering\nconstraint to ensure that deeper network layers geometrically refine the\nrepresentations of shallower ones. Experiments on multiple audio event\ndetection tasks and backbone architectures show that HypEE significantly\noutperforms standard Euclidean EE baselines, especially at the earliest, most\ncomputationally-critical exits. The learned geometry also provides a principled\nmeasure of uncertainty, enabling a novel triggering mechanism that makes the\noverall system both more efficient and more accurate than a conventional EE and\nstandard backbone models without early-exits.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u66f2\u65e9\u671f\u9000\u51fa\u7f51\u7edcHypEE\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u7684\u4e8b\u4ef6\u68c0\u6d4b\uff0c\u5728\u591a\u4efb\u52a1\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u6b27\u51e0\u91cc\u5f97\u65e9\u671f\u9000\u51fa\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u51c6\u786e\u4e8b\u4ef6\u68c0\u6d4b\u65f6\u6027\u80fd\u4e0e\u8ba1\u7b97\u6210\u672c\u7684\u6743\u8861\u95ee\u9898\uff0c\u4ee5\u53ca\u65e9\u671f\u9000\u51fa\u7f51\u7edc\u7f3a\u4e4f\u8fde\u8d2f\u5c42\u6b21\u7ed3\u6784\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faHyperbolic Early-Exit networks (HypEE)\u6846\u67b6\uff0c\u91c7\u7528\u5177\u6709\u65b0\u7684\u8574\u542b\u635f\u5931\u7684\u5206\u5c42\u8bad\u7ec3\u76ee\u6807\uff0c\u5728\u53cc\u66f2\u7a7a\u95f4\u5b66\u4e60\u65e9\u671f\u9000\u51fa\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2a\u97f3\u9891\u4e8b\u4ef6\u68c0\u6d4b\u4efb\u52a1\u548c\u9aa8\u5e72\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHypEE\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u65e9\u671f\u9000\u51fa\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u6700\u65e9\u3001\u8ba1\u7b97\u6700\u5173\u952e\u7684\u9000\u51fa\u70b9\u3002", "conclusion": "HypEE\u4f7f\u6574\u4e2a\u7cfb\u7edf\u6bd4\u4f20\u7edf\u65e9\u671f\u9000\u51fa\u548c\u65e0\u65e9\u671f\u9000\u51fa\u7684\u6807\u51c6\u9aa8\u5e72\u6a21\u578b\u66f4\u9ad8\u6548\u3001\u66f4\u51c6\u786e\uff0c\u4e14\u5b66\u4e60\u5230\u7684\u51e0\u4f55\u7ed3\u6784\u63d0\u4f9b\u4e86\u4e0d\u786e\u5b9a\u6027\u7684\u539f\u5219\u6027\u5ea6\u91cf\u3002"}}
{"id": "2511.00012", "pdf": "https://arxiv.org/pdf/2511.00012", "abs": "https://arxiv.org/abs/2511.00012", "authors": ["Jinwoo Baek"], "title": "Matrix Phylogeny: Compact Spectral Fingerprints for Trap-Robust Preconditioner Selection", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": "16 Pages", "summary": "Matrix Phylogeny introduces compact spectral fingerprints (CSF/ASF) that\ncharacterize matrices at the family level. These fingerprints are\nlow-dimensional, eigendecomposition-free descriptors built from Chebyshev trace\nmoments estimated by Hutchinson sketches. A simple affine rescaling to [-1,1]\nmakes them permutation/similarity invariant and robust to global scaling.\n  Across synthetic and real tests, we observe phylogenetic compactness: only a\nfew moments are needed. CSF with K=3-5 already yields perfect clustering\n(ARI=1.0; silhouettes ~0.89) on four synthetic families and a five-family set\nincluding BA vs ER, while ASF adapts the dimension on demand (median K*~9). On\na SuiteSparse mini-benchmark (Hutchinson p~100), both CSF-H and ASF-H reach\nARI=1.0. Against strong alternatives (eigenvalue histograms + Wasserstein,\nheat-kernel traces, WL-subtree), CSF-K=5 matches or exceeds accuracy while\navoiding eigendecompositions and using far fewer features (K<=10 vs 64/9153).\n  The descriptors are stable to noise (log-log slope ~1.03, R^2~0.993) and\nsupport a practical trap->recommend pipeline for automated preconditioner\nselection. In an adversarial E6+ setting with a probe-and-switch mechanism, our\nphysics-guided recommender attains near-oracle iteration counts (p90 regret=0),\nwhereas a Frobenius 1-NN baseline exhibits large spikes (p90~34-60).\n  CSF/ASF deliver compact (K<=10), fast, invariant fingerprints that enable\nscalable, structure-aware search and recommendation over large matrix\nrepositories. We recommend CSF with K=5 by default, and ASF when\ndomain-specific adaptivity is desired.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCSF/ASF\u77e9\u9635\u6307\u7eb9\uff0c\u5177\u6709\u4f4e\u7ef4\u3001\u514d\u7279\u5f81\u5206\u89e3\u7b49\u4f18\u70b9\uff0c\u805a\u7c7b\u6548\u679c\u597d\u3001\u6297\u566a\u4e14\u652f\u6301\u9884\u6761\u4ef6\u5668\u9009\u62e9\uff0c\u63a8\u8350\u9ed8\u8ba4\u7528CSF(K=5)\uff0c\u7279\u5b9a\u573a\u666f\u7528ASF\u3002", "motivation": "\u4e3a\u77e9\u9635\u5728\u5bb6\u65cf\u5c42\u9762\u63d0\u4f9b\u7279\u5f81\u63cf\u8ff0\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u7ed3\u6784\u611f\u77e5\u7684\u77e9\u9635\u641c\u7d22\u548c\u63a8\u8350\u3002", "method": "\u901a\u8fc7Hutchinson\u8349\u56fe\u4f30\u8ba1Chebyshev\u8ff9\u77e9\u6784\u5efa\u4f4e\u7ef4\u3001\u514d\u7279\u5f81\u5206\u89e3\u7684\u63cf\u8ff0\u7b26CSF/ASF\uff0c\u5e76\u8fdb\u884c\u4eff\u5c04\u91cd\u7f29\u653e\u3002", "result": "CSF/ASF\u805a\u7c7b\u6548\u679c\u597d\uff0c\u5728SuiteSparse\u57fa\u51c6\u6d4b\u8bd5\u4e2dARI=1.0\uff1b\u6297\u566a\u6027\u5f3a\uff1b\u652f\u6301\u9884\u6761\u4ef6\u5668\u9009\u62e9\uff0c\u63a8\u8350\u5668\u8fed\u4ee3\u6b21\u6570\u63a5\u8fd1\u6700\u4f18\u3002", "conclusion": "CSF/ASF\u662f\u7d27\u51d1\u3001\u5feb\u901f\u3001\u4e0d\u53d8\u7684\u6307\u7eb9\uff0c\u9ed8\u8ba4\u63a8\u8350CSF(K=5)\uff0c\u7279\u5b9a\u573a\u666f\u7528ASF\u3002"}}
{"id": "2511.00013", "pdf": "https://arxiv.org/pdf/2511.00013", "abs": "https://arxiv.org/abs/2511.00013", "authors": ["Daria D. Tyurina", "Sergey V. Stasenko", "Konstantin V. Lushnikov", "Maria V. Vedunova"], "title": "Using machine learning methods to predict cognitive age from psychophysiological tests", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "This study introduces a novel method for predicting cognitive age using\npsychophysiological tests. To determine cognitive age, subjects were asked to\ncomplete a series of psychological tests measuring various cognitive functions,\nincluding reaction time and cognitive conflict, short-term memory, verbal\nfunctions, and color and spatial perception. Based on the tests completed, the\naverage completion time, proportion of correct answers, average absolute delta\nof the color campimetry test, number of guessed words in the M\\\"unsterberg\nmatrix, and other parameters were calculated for each subject. The obtained\ncharacteristics of the subjects were preprocessed and used to train a machine\nlearning algorithm implementing a regression task for predicting a person's\ncognitive age. These findings contribute to the field of remote screening using\nmobile devices for human health for diagnosing and monitoring cognitive aging.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u7528\u5fc3\u7406\u751f\u7406\u6d4b\u8bd5\u9884\u6d4b\u8ba4\u77e5\u5e74\u9f84\u7684\u65b0\u65b9\u6cd5\uff0c\u7ecf\u6d4b\u8bd5\u548c\u53c2\u6570\u8ba1\u7b97\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u6210\u679c\u6709\u52a9\u4e8e\u8fdc\u7a0b\u7b5b\u67e5\u3002", "motivation": "\u63d0\u51fa\u9884\u6d4b\u8ba4\u77e5\u5e74\u9f84\u7684\u65b0\u65b9\u6cd5\uff0c\u63a8\u52a8\u5229\u7528\u79fb\u52a8\u8bbe\u5907\u8fdb\u884c\u4eba\u7c7b\u5065\u5eb7\u8fdc\u7a0b\u7b5b\u67e5\u9886\u57df\u53d1\u5c55\u3002", "method": "\u8ba9\u53d7\u8bd5\u8005\u5b8c\u6210\u4e00\u7cfb\u5217\u5fc3\u7406\u6d4b\u8bd5\uff0c\u8ba1\u7b97\u591a\u9879\u53c2\u6570\uff0c\u5bf9\u53c2\u6570\u9884\u5904\u7406\u540e\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u56de\u5f52\u7b97\u6cd5\u3002", "result": "\u6210\u529f\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7528\u4e8e\u9884\u6d4b\u8ba4\u77e5\u5e74\u9f84\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u5bf9\u5229\u7528\u79fb\u52a8\u8bbe\u5907\u8fdb\u884c\u4eba\u7c7b\u5065\u5eb7\u8fdc\u7a0b\u7b5b\u67e5\u4ee5\u8bca\u65ad\u548c\u76d1\u6d4b\u8ba4\u77e5\u8001\u5316\u6709\u8d21\u732e\u3002"}}
{"id": "2511.00664", "pdf": "https://arxiv.org/pdf/2511.00664", "abs": "https://arxiv.org/abs/2511.00664", "authors": ["Kasimir Schulz", "Amelia Kawasaki", "Leo Ring"], "title": "ShadowLogic: Backdoors in Any Whitebox LLM", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are widely deployed across various applications,\noften with safeguards to prevent the generation of harmful or restricted\ncontent. However, these safeguards can be covertly bypassed through adversarial\nmodifications to the computational graph of a model. This work highlights a\ncritical security vulnerability in computational graph-based LLM formats,\ndemonstrating that widely used deployment pipelines may be susceptible to\nobscured backdoors. We introduce ShadowLogic, a method for creating a backdoor\nin a white-box LLM by injecting an uncensoring vector into its computational\ngraph representation. We set a trigger phrase that, when added to the beginning\nof a prompt into the LLM, applies the uncensoring vector and removes the\ncontent generation safeguards in the model. We embed trigger logic directly\ninto the computational graph which detects the trigger phrase in a prompt. To\nevade detection of our backdoor, we obfuscate this logic within the graph\nstructure, making it similar to standard model functions. Our method requires\nminimal alterations to model parameters, making backdoored models appear benign\nwhile retaining the ability to generate uncensored responses when activated. We\nsuccessfully implement ShadowLogic in Phi-3 and Llama 3.2, using ONNX for\nmanipulating computational graphs. Implanting the uncensoring vector achieved a\n>60% attack success rate for further malicious queries.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u57fa\u4e8e\u8ba1\u7b97\u56fe\u7684\u5927\u8bed\u8a00\u6a21\u578b\u683c\u5f0f\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u4ecb\u7ecd\u4e86ShadowLogic\u65b9\u6cd5\u521b\u5efa\u540e\u95e8\u7ed5\u8fc7\u5185\u5bb9\u751f\u6210\u9632\u62a4\u673a\u5236\uff0c\u5728Phi - 3\u548cLlama 3.2\u4e0a\u5b9e\u73b0\u4e14\u653b\u51fb\u6210\u529f\u7387\u8d8560%\u3002", "motivation": "\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u867d\u6709\u5185\u5bb9\u9632\u62a4\u673a\u5236\uff0c\u4f46\u8ba1\u7b97\u56fe\u53ef\u80fd\u88ab\u5bf9\u6297\u6027\u4fee\u6539\u7ed5\u8fc7\u9632\u62a4\uff0c\u63ed\u793a\u5e7f\u6cdb\u4f7f\u7528\u7684\u90e8\u7f72\u7ba1\u9053\u53ef\u80fd\u5b58\u5728\u9690\u853d\u540e\u95e8\u8fd9\u4e00\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u5f15\u5165ShadowLogic\u65b9\u6cd5\uff0c\u5411\u767d\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u56fe\u8868\u793a\u4e2d\u6ce8\u5165\u89e3\u5ba1\u67e5\u5411\u91cf\uff0c\u8bbe\u7f6e\u89e6\u53d1\u77ed\u8bed\uff0c\u5c06\u89e6\u53d1\u903b\u8f91\u5d4c\u5165\u8ba1\u7b97\u56fe\u5e76\u6df7\u6dc6\u903b\u8f91\u4ee5\u8eb2\u907f\u68c0\u6d4b\uff0c\u5bf9\u6a21\u578b\u53c2\u6570\u6539\u52a8\u6781\u5c0f\u3002", "result": "\u5728Phi - 3\u548cLlama 3.2\u4e2d\u6210\u529f\u5b9e\u73b0ShadowLogic\uff0c\u690d\u5165\u89e3\u5ba1\u67e5\u5411\u91cf\u540e\u5bf9\u8fdb\u4e00\u6b65\u6076\u610f\u67e5\u8be2\u7684\u653b\u51fb\u6210\u529f\u7387\u8d8560%\u3002", "conclusion": "\u57fa\u4e8e\u8ba1\u7b97\u56fe\u7684\u5927\u8bed\u8a00\u6a21\u578b\u683c\u5f0f\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0cShadowLogic\u65b9\u6cd5\u80fd\u6709\u6548\u521b\u5efa\u540e\u95e8\u7ed5\u8fc7\u5185\u5bb9\u9632\u62a4\u3002"}}
{"id": "2511.00674", "pdf": "https://arxiv.org/pdf/2511.00674", "abs": "https://arxiv.org/abs/2511.00674", "authors": ["Weijie Su"], "title": "Isotropic Curvature Model for Understanding Deep Learning Optimization: Is Gradient Orthogonalization Optimal?", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": null, "summary": "In this paper, we introduce a model for analyzing deep learning optimization\nover a single iteration by leveraging the matrix structure of the weights. We\nderive the model by assuming isotropy of curvature, including the second-order\nHessian and higher-order terms, of the loss function across all perturbation\ndirections; hence, we call it the isotropic curvature model. This model is a\nconvex optimization program amenable to analysis, which allows us to understand\nhow an update on the weights in the form of a matrix relates to the change in\nthe total loss function. As an application, we use the isotropic curvature\nmodel to analyze the recently introduced Muon optimizer and other\nmatrix-gradient methods for training language models. First, we show that under\na general growth condition on the curvature, the optimal update matrix is\nobtained by making the spectrum of the original gradient matrix more\nhomogeneous -- that is, making its singular values closer in ratio -- which in\nparticular improves the conditioning of the update matrix. Next, we show that\nthe orthogonalized gradient becomes optimal for the isotropic curvature model\nwhen the curvature exhibits a phase transition in growth. Taken together, these\nresults suggest that the gradient orthogonalization employed in Muon and other\nrelated methods is directionally correct but may not be strictly optimal.\nFinally, we discuss future research on how to leverage the isotropic curvature\nmodel for designing new optimization methods for training deep learning and\nlanguage models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5404\u5411\u540c\u6027\u66f2\u7387\u6a21\u578b\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u5355\u6b21\u8fed\u4ee3\u4f18\u5316\uff0c\u7528\u5176\u5206\u6790Muon\u4f18\u5316\u5668\u7b49\uff0c\u7ed9\u51fa\u6700\u4f18\u66f4\u65b0\u77e9\u9635\u6761\u4ef6\uff0c\u6307\u51fa\u68af\u5ea6\u6b63\u4ea4\u5316\u65b9\u5411\u6b63\u786e\u4f46\u975e\u4e25\u683c\u6700\u4f18\uff0c\u5e76\u8ba8\u8bba\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f15\u5165\u6a21\u578b\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u5355\u6b21\u8fed\u4ee3\u4f18\u5316\uff0c\u7406\u89e3\u6743\u91cd\u77e9\u9635\u66f4\u65b0\u4e0e\u603b\u635f\u5931\u51fd\u6570\u53d8\u5316\u7684\u5173\u7cfb\u3002", "method": "\u5047\u8bbe\u635f\u5931\u51fd\u6570\u66f2\u7387\u5404\u5411\u540c\u6027\u63a8\u5bfc\u5404\u5411\u540c\u6027\u66f2\u7387\u6a21\u578b\uff0c\u7528\u8be5\u6a21\u578b\u5206\u6790Muon\u4f18\u5316\u5668\u548c\u5176\u4ed6\u77e9\u9635\u68af\u5ea6\u65b9\u6cd5\u3002", "result": "\u5728\u66f2\u7387\u4e00\u822c\u589e\u957f\u6761\u4ef6\u4e0b\uff0c\u6700\u4f18\u66f4\u65b0\u77e9\u9635\u4f7f\u539f\u68af\u5ea6\u77e9\u9635\u8c31\u66f4\u5747\u5300\uff1b\u66f2\u7387\u589e\u957f\u6709\u76f8\u53d8\u65f6\uff0c\u6b63\u4ea4\u5316\u68af\u5ea6\u5bf9\u6a21\u578b\u6700\u4f18\uff1b\u68af\u5ea6\u6b63\u4ea4\u5316\u65b9\u5411\u6b63\u786e\u4f46\u975e\u4e25\u683c\u6700\u4f18\u3002", "conclusion": "\u53ef\u5229\u7528\u5404\u5411\u540c\u6027\u66f2\u7387\u6a21\u578b\u4e3a\u6df1\u5ea6\u5b66\u4e60\u548c\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2511.00025", "pdf": "https://arxiv.org/pdf/2511.00025", "abs": "https://arxiv.org/abs/2511.00025", "authors": ["Tadisetty Sai Yashwanth"], "title": "On the Structure of Floating-Point Noise in Batch-Invariant GPU Matrix Multiplication", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "Floating-point non-associativity makes fundamental deep learning operations,\nsuch as matrix multiplication (matmul) on GPUs, inherently non-deterministic.\nDespite this, the statistical structure of the resulting numerical error\nremains poorly understood. A common working assumption is that these errors\nbehave as independent and identically distributed (i.i.d.) Gaussian noise. In\nthis paper, we empirically test this assumption and show that it fails to\ndescribe real GPU behavior. By comparing outputs of single-input and batched\nmatmuls, we find that while the i.i.d. model predicts non-zero output\ninstability, empirical results show a 0.00% prediction flip rate. Through\ncovariance analysis, we uncover the cause: the floating-point error is\nstructured and highly correlated. For float16, nearly 50% of the total error\nvariance lies in off-diagonal terms, revealing that the noise behaves as a\ncoordinated, directional perturbation rather than random static. This result\nchallenges the prevailing stochastic view of numerical noise and provides a\nprincipled foundation for analyzing deep learning reliability under hardware\nnon-determinism.", "AI": {"tldr": "\u672c\u6587\u5b9e\u8bc1\u68c0\u9a8c\u6d6e\u70b9\u8bef\u5dee\u4e3a\u72ec\u7acb\u540c\u5206\u5e03\u9ad8\u65af\u566a\u58f0\u7684\u5047\u8bbe\uff0c\u53d1\u73b0\u8be5\u5047\u8bbe\u4e0d\u7b26GPU\u5b9e\u9645\u884c\u4e3a\uff0c\u6d6e\u70b9\u8bef\u5dee\u6709\u7ed3\u6784\u4e14\u9ad8\u5ea6\u76f8\u5173\uff0c\u6311\u6218\u4e86\u6570\u503c\u566a\u58f0\u7684\u968f\u673a\u89c2\u70b9\u3002", "motivation": "\u6d6e\u70b9\u975e\u7ed3\u5408\u6027\u4f7f\u6df1\u5ea6\u5b66\u4e60\u64cd\u4f5c\u975e\u786e\u5b9a\u6027\uff0c\u4f46\u6570\u503c\u8bef\u5dee\u7684\u7edf\u8ba1\u7ed3\u6784\u4e0d\u660e\uff0c\u5e38\u89c1\u5047\u8bbe\u662f\u8bef\u5dee\u4e3a\u72ec\u7acb\u540c\u5206\u5e03\u9ad8\u65af\u566a\u58f0\uff0c\u9700\u68c0\u9a8c\u8be5\u5047\u8bbe\u3002", "method": "\u6bd4\u8f83\u5355\u8f93\u5165\u548c\u6279\u91cf\u77e9\u9635\u4e58\u6cd5\u8f93\u51fa\uff0c\u8fdb\u884c\u534f\u65b9\u5dee\u5206\u6790\u3002", "result": "i.i.d.\u6a21\u578b\u9884\u6d4b\u8f93\u51fa\u4e0d\u7a33\u5b9a\uff0c\u4f46\u5b9e\u8bc1\u663e\u793a\u9884\u6d4b\u7ffb\u8f6c\u7387\u4e3a0.00%\uff1b\u6d6e\u70b9\u8bef\u5dee\u6709\u7ed3\u6784\u4e14\u9ad8\u5ea6\u76f8\u5173\uff0cfloat16\u8fd150%\u8bef\u5dee\u65b9\u5dee\u5728\u975e\u5bf9\u89d2\u9879\u3002", "conclusion": "\u6311\u6218\u4e86\u6570\u503c\u566a\u58f0\u7684\u968f\u673a\u89c2\u70b9\uff0c\u4e3a\u5206\u6790\u786c\u4ef6\u975e\u786e\u5b9a\u6027\u4e0b\u6df1\u5ea6\u5b66\u4e60\u53ef\u9760\u6027\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.00681", "pdf": "https://arxiv.org/pdf/2511.00681", "abs": "https://arxiv.org/abs/2511.00681", "authors": ["Mehmet Yigit Avci", "Pedro Borges", "Virginia Fernandez", "Paul Wright", "Mehmet Yigitsoy", "Sebastien Ourselin", "Jorge Cardoso"], "title": "Metadata-Aligned 3D MRI Representations for Contrast Understanding and Quality Control", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Magnetic Resonance Imaging suffers from substantial data heterogeneity and\nthe absence of standardized contrast labels across scanners, protocols, and\ninstitutions, which severely limits large-scale automated analysis. A unified\nrepresentation of MRI contrast would enable a wide range of downstream\nutilities, from automatic sequence recognition to harmonization and quality\ncontrol, without relying on manual annotations. To this end, we introduce\nMR-CLIP, a metadata-guided framework that learns MRI contrast representations\nby aligning volumetric images with their DICOM acquisition parameters. The\nresulting embeddings shows distinct clusters of MRI sequences and outperform\nsupervised 3D baselines under data scarcity in few-shot sequence\nclassification. Moreover, MR-CLIP enables unsupervised data quality control by\nidentifying corrupted or inconsistent metadata through image-metadata embedding\ndistances. By transforming routinely available acquisition metadata into a\nsupervisory signal, MR-CLIP provides a scalable foundation for label-efficient\nMRI analysis across diverse clinical datasets.", "AI": {"tldr": "\u63d0\u51faMR - CLIP\u6846\u67b6\u5b66\u4e60MRI\u5bf9\u6bd4\u8868\u793a\uff0c\u5728\u5c11\u6837\u672c\u5e8f\u5217\u5206\u7c7b\u4e2d\u8868\u73b0\u597d\uff0c\u8fd8\u80fd\u8fdb\u884c\u65e0\u76d1\u7763\u6570\u636e\u8d28\u91cf\u63a7\u5236\uff0c\u4e3a\u9ad8\u6548MRI\u5206\u6790\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u78c1\u5171\u632f\u6210\u50cf\u5b58\u5728\u6570\u636e\u5f02\u8d28\u6027\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u5bf9\u6bd4\u6807\u7b7e\u95ee\u9898\uff0c\u9650\u5236\u5927\u89c4\u6a21\u81ea\u52a8\u5206\u6790\uff0c\u9700\u8981\u7edf\u4e00\u7684MRI\u5bf9\u6bd4\u8868\u793a\u3002", "method": "\u5f15\u5165MR - CLIP\uff0c\u901a\u8fc7\u5c06\u4f53\u79ef\u56fe\u50cf\u4e0e\u5176DICOM\u91c7\u96c6\u53c2\u6570\u5bf9\u9f50\u6765\u5b66\u4e60MRI\u5bf9\u6bd4\u8868\u793a\u3002", "result": "\u5f97\u5230\u7684\u5d4c\u5165\u663e\u793a\u51faMRI\u5e8f\u5217\u7684\u4e0d\u540c\u805a\u7c7b\uff0c\u5728\u5c11\u6837\u672c\u5e8f\u5217\u5206\u7c7b\u4e2d\u4f18\u4e8e\u6709\u76d1\u77633D\u57fa\u7ebf\uff0c\u80fd\u901a\u8fc7\u56fe\u50cf - \u5143\u6570\u636e\u5d4c\u5165\u8ddd\u79bb\u8fdb\u884c\u65e0\u76d1\u7763\u6570\u636e\u8d28\u91cf\u63a7\u5236\u3002", "conclusion": "MR - CLIP\u5c06\u5e38\u89c4\u53ef\u7528\u7684\u91c7\u96c6\u5143\u6570\u636e\u8f6c\u5316\u4e3a\u76d1\u7763\u4fe1\u53f7\uff0c\u4e3a\u8de8\u4e0d\u540c\u4e34\u5e8a\u6570\u636e\u96c6\u7684\u6807\u7b7e\u9ad8\u6548MRI\u5206\u6790\u63d0\u4f9b\u53ef\u6269\u5c55\u57fa\u7840\u3002"}}
{"id": "2511.00686", "pdf": "https://arxiv.org/pdf/2511.00686", "abs": "https://arxiv.org/abs/2511.00686", "authors": ["Alex Inch", "Passawis Chaiyapattanaporn", "Yuchen Zhu", "Yuan Lu", "Ting-Wen Ko", "Davide Paglieri"], "title": "Evolve to Inspire: Novelty Search for Diverse Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 10 figures, Accepted to Neurips 2025 GenProCC Workshop", "summary": "Text-to-image diffusion models, while proficient at generating high-fidelity\nim- ages, often suffer from limited output diversity, hindering their\napplication in exploratory and ideation tasks. Existing prompt optimization\ntechniques typically target aesthetic fitness or are ill-suited to the creative\nvisual domain. To address this shortcoming, we introduce WANDER, a novelty\nsearch-based approach to generating diverse sets of images from a single input\nprompt. WANDER operates directly on natural language prompts, employing a Large\nLanguage Model (LLM) for semantic evolution of diverse sets of images, and\nusing CLIP embeddings to quantify novelty. We additionally apply emitters to\nguide the search into distinct regions of the prompt space, and demonstrate\nthat they boost the diversity of the generated images. Empirical evaluations\nusing FLUX-DEV for generation and GPT-4o-mini for mutation demonstrate that\nWANDER significantly outperforms existing evolutionary prompt optimization\nbaselines in diversity metrics. Ablation studies confirm the efficacy of\nemitters.", "AI": {"tldr": "\u63d0\u51faWANDER\u65b9\u6cd5\u89e3\u51b3\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u8f93\u51fa\u591a\u6837\u6027\u6709\u9650\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u6837\u6027\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u8f93\u51fa\u591a\u6837\u6027\u6709\u9650\uff0c\u73b0\u6709\u63d0\u793a\u4f18\u5316\u6280\u672f\u4e0d\u9002\u7528\u4e8e\u521b\u610f\u89c6\u89c9\u9886\u57df\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u65b0\u5947\u6027\u641c\u7d22\u7684WANDER\u65b9\u6cd5\uff0c\u76f4\u63a5\u5904\u7406\u81ea\u7136\u8bed\u8a00\u63d0\u793a\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u8fdb\u5316\uff0cCLIP\u5d4c\u5165\u91cf\u5316\u65b0\u5947\u6027\uff0c\u5e94\u7528\u53d1\u5c04\u5668\u5f15\u5bfc\u641c\u7d22\u3002", "result": "\u4f7f\u7528FLUX - DEV\u751f\u6210\u548cGPT - 4o - mini\u7a81\u53d8\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cWANDER\u5728\u591a\u6837\u6027\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8fdb\u5316\u63d0\u793a\u4f18\u5316\u57fa\u7ebf\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u53d1\u5c04\u5668\u6709\u6548\u3002", "conclusion": "WANDER\u80fd\u6709\u6548\u63d0\u9ad8\u56fe\u50cf\u751f\u6210\u7684\u591a\u6837\u6027\u3002"}}
{"id": "2511.00034", "pdf": "https://arxiv.org/pdf/2511.00034", "abs": "https://arxiv.org/abs/2511.00034", "authors": ["Aditya Akella"], "title": "On the Fundamental Limitations of Decentralized Learnable Reward Shaping in Cooperative Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.LG", "68T05, 68T07, 91A10", "I.2.6; I.2.11; I.2.8"], "comment": "8 pages, 5 figures, 2 tables", "summary": "Recent advances in learnable reward shaping have shown promise in\nsingle-agent reinforcement learning by automatically discovering effective\nfeedback signals. However, the effectiveness of decentralized learnable reward\nshaping in cooperative multi-agent settings remains poorly understood. We\npropose DMARL-RSA, a fully decentralized system where each agent learns\nindividual reward shaping, and evaluate it on cooperative navigation tasks in\nthe simple_spread_v3 environment. Despite sophisticated reward learning,\nDMARL-RSA achieves only -24.20 +/- 0.09 average reward, compared to MAPPO with\ncentralized training at 1.92 +/- 0.87--a 26.12-point gap. DMARL-RSA performs\nsimilarly to simple independent learning (IPPO: -23.19 +/- 0.96), indicating\nthat advanced reward shaping cannot overcome fundamental decentralized\ncoordination limitations. Interestingly, decentralized methods achieve higher\nlandmark coverage (0.888 +/- 0.029 for DMARL-RSA, 0.960 +/- 0.045 for IPPO out\nof 3 total) but worse overall performance than centralized MAPPO (0.273 +/-\n0.008 landmark coverage)--revealing a coordination paradox between local\noptimization and global performance. Analysis identifies three critical\nbarriers: (1) non-stationarity from concurrent policy updates, (2) exponential\ncredit assignment complexity, and (3) misalignment between individual reward\noptimization and global objectives. These results establish empirical limits\nfor decentralized reward learning and underscore the necessity of centralized\ncoordination for effective multi-agent cooperation.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faDMARL - RSA\u7528\u4e8e\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u573a\u666f\uff0c\u8bc4\u4f30\u53d1\u73b0\u5176\u6027\u80fd\u4e0d\u5982\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u65b9\u6cd5\uff0c\u63ed\u793a\u5206\u6563\u5f0f\u5956\u52b1\u5b66\u4e60\u5c40\u9650\u53ca\u534f\u8c03\u6096\u8bba\u3002", "motivation": "\u5f53\u524d\u5bf9\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u5206\u6563\u5f0f\u53ef\u5b66\u4e60\u5956\u52b1\u5851\u9020\u7684\u6709\u6548\u6027\u4e86\u89e3\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDMARL - RSA\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u5b66\u4e60\u4e2a\u4f53\u5956\u52b1\u5851\u9020\uff0c\u5e76\u5728simple_spread_v3\u73af\u5883\u7684\u5408\u4f5c\u5bfc\u822a\u4efb\u52a1\u4e2d\u8bc4\u4f30\u3002", "result": "DMARL - RSA\u5e73\u5747\u5956\u52b1\u8fdc\u4f4e\u4e8e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u7684MAPPO\uff0c\u4e0e\u7b80\u5355\u72ec\u7acb\u5b66\u4e60\u8868\u73b0\u76f8\u8fd1\uff1b\u5206\u6563\u5f0f\u65b9\u6cd5\u5730\u6807\u8986\u76d6\u7387\u9ad8\u4f46\u6574\u4f53\u6027\u80fd\u5dee\uff1b\u5206\u6790\u51fa\u4e09\u4e2a\u5173\u952e\u969c\u788d\u3002", "conclusion": "\u786e\u5b9a\u4e86\u5206\u6563\u5f0f\u5956\u52b1\u5b66\u4e60\u7684\u7ecf\u9a8c\u9650\u5236\uff0c\u5f3a\u8c03\u6709\u6548\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u9700\u96c6\u4e2d\u5f0f\u534f\u8c03\u3002"}}
{"id": "2511.00709", "pdf": "https://arxiv.org/pdf/2511.00709", "abs": "https://arxiv.org/abs/2511.00709", "authors": ["Veronica Bossio Botero", "Vijay Yadav", "Jacob Ouyang", "Anzar Abbas", "Michelle Worthington"], "title": "A Voice-Enabled Virtual Patient System for Interactive Training in Standardized Clinical Assessment", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Training mental health clinicians to conduct standardized clinical\nassessments is challenging due to a lack of scalable, realistic practice\nopportunities, which can impact data quality in clinical trials. To address\nthis gap, we introduce a voice-enabled virtual patient simulation system\npowered by a large language model (LLM). This study describes the system's\ndevelopment and validates its ability to generate virtual patients who\naccurately adhere to pre-defined clinical profiles, maintain coherent\nnarratives, and produce realistic dialogue. We implemented a system using a LLM\nto simulate patients with specified symptom profiles, demographics, and\ncommunication styles. The system was evaluated by 5 experienced clinical raters\nwho conducted 20 simulated structured MADRS interviews across 4 virtual patient\npersonas. The virtual patients demonstrated strong adherence to their clinical\nprofiles, with a mean item difference between rater-assigned MADRS scores and\nconfigured scores of 0.52 (SD=0.75). Inter-rater reliability across items was\n0.90 (95% CI=0.68-0.99). Expert raters consistently rated the qualitative\nrealism and cohesiveness of the virtual patients favorably, giving average\nratings between \"Agree\" and \"Strongly Agree.\" Our findings suggest that\nLLM-powered virtual patient simulations are a viable and scalable tool for\ntraining clinicians, capable of producing high-fidelity, clinically relevant\npractice scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u97f3\u865a\u62df\u60a3\u8005\u6a21\u62df\u7cfb\u7edf\uff0c\u7ecf\u8bc4\u4f30\u8be5\u7cfb\u7edf\u53ef\u7528\u4e8e\u57f9\u8bad\u4e34\u5e8a\u533b\u751f\u3002", "motivation": "\u7f3a\u4e4f\u53ef\u6269\u5c55\u3001\u771f\u5b9e\u7684\u5b9e\u8df5\u673a\u4f1a\u5f71\u54cd\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u8d28\u91cf\uff0c\u9700\u89e3\u51b3\u57f9\u8bad\u4e34\u5e8a\u533b\u751f\u8fdb\u884c\u6807\u51c6\u5316\u4e34\u5e8a\u8bc4\u4f30\u7684\u96be\u9898\u3002", "method": "\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u7cfb\u7edf\u6a21\u62df\u6307\u5b9a\u75c7\u72b6\u3001\u4eba\u53e3\u7edf\u8ba1\u548c\u6c9f\u901a\u98ce\u683c\u7684\u60a3\u8005\uff0c\u75315\u4f4d\u7ecf\u9a8c\u4e30\u5bcc\u7684\u4e34\u5e8a\u8bc4\u4f30\u8005\u5bf94\u79cd\u865a\u62df\u60a3\u8005\u89d2\u8272\u8fdb\u884c20\u6b21\u6a21\u62df\u7ed3\u6784\u5316MADRS\u8bbf\u8c08\u3002", "result": "\u865a\u62df\u60a3\u8005\u9ad8\u5ea6\u7b26\u5408\u4e34\u5e8a\u7279\u5f81\uff0c\u8bc4\u5206\u5dee\u5f02\u5c0f\uff0c\u8bc4\u5206\u8005\u95f4\u4fe1\u5ea6\u9ad8\uff0c\u4e13\u5bb6\u5bf9\u5176\u5b9a\u6027\u771f\u5b9e\u6027\u548c\u8fde\u8d2f\u6027\u8bc4\u4ef7\u826f\u597d\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u865a\u62df\u60a3\u8005\u6a21\u62df\u662f\u57f9\u8bad\u4e34\u5e8a\u533b\u751f\u53ef\u884c\u4e14\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u80fd\u4ea7\u751f\u9ad8\u4fdd\u771f\u3001\u4e34\u5e8a\u76f8\u5173\u7684\u5b9e\u8df5\u573a\u666f\u3002"}}
{"id": "2511.00737", "pdf": "https://arxiv.org/pdf/2511.00737", "abs": "https://arxiv.org/abs/2511.00737", "authors": ["Jaewoo Park", "Chenghao Quan", "Jongeun Lee"], "title": "EP-HDC: Hyperdimensional Computing with Encrypted Parameters for High-Throughput Privacy-Preserving Inference", "categories": ["cs.CR", "cs.AI"], "comment": "To appear on ASP-DAC 2026", "summary": "While homomorphic encryption (HE) provides strong privacy protection, its\nhigh computational cost has restricted its application to simple tasks.\nRecently, hyperdimensional computing (HDC) applied to HE has shown promising\nperformance for privacy-preserving machine learning (PPML). However, when\napplied to more realistic scenarios such as batch inference, the HDC-based HE\nhas still very high compute time as well as high encryption and data\ntransmission overheads. To address this problem, we propose HDC with encrypted\nparameters (EP-HDC), which is a novel PPML approach featuring client-side HE,\ni.e., inference is performed on a client using a homomorphically encrypted\nmodel. Our EP-HDC can effectively mitigate the encryption and data transmission\noverhead, as well as providing high scalability with many clients while\nproviding strong protection for user data and model parameters. In addition to\napplication examples for our client-side PPML, we also present design space\nexploration involving quantization, architecture, and HE-related parameters.\nOur experimental results using the BFV scheme and the Face/Emotion datasets\ndemonstrate that our method can improve throughput and latency of batch\ninference by orders of magnitude over previous PPML methods (36.52~1068x and\n6.45~733x, respectively) with less than 1% accuracy degradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEP - HDC\u65b9\u6cd5\u89e3\u51b3HDC - based HE\u5728\u6279\u63a8\u7406\u573a\u666f\u7684\u9ad8\u8ba1\u7b97\u65f6\u95f4\u3001\u52a0\u5bc6\u548c\u6570\u636e\u4f20\u8f93\u5f00\u9500\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u6279\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709HDC\u5e94\u7528\u4e8eHE\u5728\u6279\u63a8\u7406\u7b49\u73b0\u5b9e\u573a\u666f\u5b58\u5728\u8ba1\u7b97\u65f6\u95f4\u957f\u3001\u52a0\u5bc6\u548c\u6570\u636e\u4f20\u8f93\u5f00\u9500\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u5e26\u6709\u52a0\u5bc6\u53c2\u6570\u7684HDC\uff08EP - HDC\uff09\uff0c\u662f\u4e00\u79cd\u5ba2\u6237\u7aefHE\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u8fd8\u8fdb\u884c\u4e86\u6d89\u53ca\u91cf\u5316\u3001\u67b6\u6784\u548cHE\u76f8\u5173\u53c2\u6570\u7684\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u3002", "result": "\u4f7f\u7528BFV\u65b9\u6848\u548cFace/Emotion\u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4e4b\u524dPPML\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u6279\u63a8\u7406\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u63d0\u5347\u4e86\u51e0\u4e2a\u6570\u91cf\u7ea7\uff08\u5206\u522b\u4e3a36.52~1068x\u548c6.45~733x\uff09\uff0c\u7cbe\u5ea6\u4e0b\u964d\u5c11\u4e8e1%\u3002", "conclusion": "EP - HDC\u80fd\u6709\u6548\u51cf\u8f7b\u52a0\u5bc6\u548c\u6570\u636e\u4f20\u8f93\u5f00\u9500\uff0c\u5177\u6709\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u4e3a\u7528\u6237\u6570\u636e\u548c\u6a21\u578b\u53c2\u6570\u63d0\u4f9b\u5f3a\u4fdd\u62a4\uff0c\u63d0\u5347\u6279\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2511.00075", "pdf": "https://arxiv.org/pdf/2511.00075", "abs": "https://arxiv.org/abs/2511.00075", "authors": ["Qianhui Li", "Weiya Wang", "Qianqi Zhao", "Tong Qu", "Jing He", "Xuhong Qiang", "Jingwen Hou", "Ke Chen", "Bao Zhang", "Qi Wang"], "title": "PDA-LSTM: Knowledge-driven page data arrangement based on LSTM for LCM supression in QLC 3D NAND flash memories", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Quarter level cell (QLC) 3D NAND flash memory is emerging as the predominant\nstorage solution in the era of artificial intelligence. QLC 3D NAND flash\nstores 4 bit per cell to expand the storage density, resulting in narrower read\nmargins. Constrained to read margins, QLC always suffers from lateral charge\nmigration (LCM), which caused by non-uniform charge density across adjacent\nmemory cells. To suppress charge density gap between cells, there are some\nalgorithm in form of intra-page data mapping such as WBVM, DVDS. However, we\nobserve inter-page data arrangements also approach the suppression. Thus, we\nproposed an intelligent model PDA-LSTM to arrange intra-page data for LCM\nsuppression, which is a physics-knowledge-driven neural network model. PDA-LSTM\napplies a long-short term memory (LSTM) neural network to compute a data\narrangement probability matrix from input page data pattern. The arrangement is\nto minimize the global impacts derived from the LCM among wordlines. Since each\npage data can be arranged only once, we design a transformation from output\nmatrix of LSTM network to non-repetitive sequence generation probability matrix\nto assist training process. The arranged data pattern can decrease the bit\nerror rate (BER) during data retention. In addition, PDA-LSTM do not need extra\nflag bits to record data transport of 3D NAND flash compared with WBVM, DVDS.\nThe experiment results show that the PDA-LSTM reduces the average BER by 80.4%\ncompared with strategy without data arrangement, and by 18.4%, 15.2% compared\nrespectively with WBVM and DVDS with code-length 64.", "AI": {"tldr": "\u63d0\u51faPDA - LSTM\u6a21\u578b\u5b89\u6392\u9875\u5185\u6570\u636e\u6291\u5236QLC 3D NAND\u95ea\u5b58\u7684LCM\uff0c\u964d\u4f4eBER\uff0c\u65e0\u9700\u989d\u5916\u6807\u5fd7\u4f4d\uff0c\u5b9e\u9a8c\u663e\u793a\u964d\u4f4eBER\u6548\u679c\u597d\u3002", "motivation": "QLC 3D NAND\u95ea\u5b58\u56e0\u5b58\u50a8\u5bc6\u5ea6\u589e\u52a0\u8bfb\u88d5\u5ea6\u53d8\u7a84\uff0c\u53d7LCM\u5f71\u54cd\uff0c\u73b0\u6709\u7b97\u6cd5\u591a\u4e3a\u9875\u5185\u6570\u636e\u6620\u5c04\uff0c\u8003\u8651\u9875\u95f4\u6570\u636e\u5b89\u6392\u6291\u5236LCM\u3002", "method": "\u63d0\u51fa\u7269\u7406\u77e5\u8bc6\u9a71\u52a8\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578bPDA - LSTM\uff0c\u7528LSTM\u8ba1\u7b97\u6570\u636e\u6392\u5217\u6982\u7387\u77e9\u9635\uff0c\u8bbe\u8ba1\u8f6c\u6362\u77e9\u9635\u8f85\u52a9\u8bad\u7ec3\u3002", "result": "PDA - LSTM\u76f8\u6bd4\u65e0\u6570\u636e\u6392\u5217\u7b56\u7565\u5e73\u5747BER\u964d\u4f4e80.4%\uff0c\u6bd4WBVM\u3001DVDS\u5206\u522b\u964d\u4f4e18.4%\u300115.2%\u3002", "conclusion": "PDA - LSTM\u80fd\u6709\u6548\u6291\u5236LCM\uff0c\u964d\u4f4e\u6570\u636e\u4fdd\u7559\u671f\u95f4\u7684BER\uff0c\u4e14\u65e0\u9700\u989d\u5916\u6807\u5fd7\u4f4d\u8bb0\u5f55\u6570\u636e\u4f20\u8f93\u3002"}}
{"id": "2511.00774", "pdf": "https://arxiv.org/pdf/2511.00774", "abs": "https://arxiv.org/abs/2511.00774", "authors": ["Eldred Lee", "Nicholas Worley", "Koshu Takatsuji"], "title": "Quantifying truth and authenticity in AI-assisted candidate evaluation: A multi-domain pilot analysis", "categories": ["cs.HC", "cs.AI"], "comment": "10 pages, 10 tables, 2 figures, and 1 page of supplemental materials", "summary": "This paper presents a retrospective analysis of anonymized\ncandidate-evaluation data collected during pilot hiring campaigns conducted\nthrough AlteraSF, an AI-native resume-verification platform. The system\nevaluates resume claims, generates context-sensitive verification questions,\nand measures performance along quantitative axes of factual validity and job\nfit, complemented by qualitative integrity detection. Across six job families\nand 1,700 applications, the platform achieved a 90-95% reduction in screening\ntime and detected measurable linguistic patterns consistent with AI-assisted or\ncopied responses. The analysis demonstrates that candidate truthfulness can be\nassessed not only through factual accuracy but also through patterns of\nlinguistic authenticity. The results suggest that a multi-dimensional\nverification framework can improve both hiring efficiency and trust in\nAI-mediated evaluation systems.", "AI": {"tldr": "\u5bf9AlteraSF\u5e73\u53f0\u62db\u8058\u6570\u636e\u56de\u987e\u5206\u6790\uff0c\u8be5\u5e73\u53f0\u8bc4\u4f30\u7b80\u5386\u3001\u751f\u6210\u9a8c\u8bc1\u95ee\u9898\u7b49\uff0c\u51cf\u5c11\u7b5b\u9009\u65f6\u95f4\u3001\u68c0\u6d4b\u5f02\u5e38\u8bed\u8a00\u6a21\u5f0f\uff0c\u591a\u7ef4\u9a8c\u8bc1\u6846\u67b6\u53ef\u63d0\u5347\u62db\u8058\u6548\u7387\u548c\u4fe1\u4efb\u3002", "motivation": "\u8bc4\u4f30AI\u539f\u751f\u7b80\u5386\u9a8c\u8bc1\u5e73\u53f0AlteraSF\u5728\u62db\u8058\u4e2d\u7684\u6548\u679c\uff0c\u63a2\u7d22\u8bc4\u4f30\u5019\u9009\u4eba\u771f\u5b9e\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u5bf9AlteraSF\u5e73\u53f0\u5728\u8bd5\u70b9\u62db\u8058\u6d3b\u52a8\u4e2d\u6536\u96c6\u7684\u533f\u540d\u5019\u9009\u4eba\u8bc4\u4f30\u6570\u636e\u8fdb\u884c\u56de\u987e\u6027\u5206\u6790\u3002", "result": "\u5e73\u53f0\u4f7f\u7b5b\u9009\u65f6\u95f4\u51cf\u5c1190 - 95%\uff0c\u68c0\u6d4b\u5230\u4e0eAI\u8f85\u52a9\u6216\u6284\u88ad\u56de\u590d\u4e00\u81f4\u7684\u8bed\u8a00\u6a21\u5f0f\u3002", "conclusion": "\u53ef\u901a\u8fc7\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bed\u8a00\u771f\u5b9e\u6027\u6a21\u5f0f\u8bc4\u4f30\u5019\u9009\u4eba\u771f\u5b9e\u6027\uff0c\u591a\u7ef4\u9a8c\u8bc1\u6846\u67b6\u80fd\u63d0\u5347\u62db\u8058\u6548\u7387\u548c\u5bf9AI\u8bc4\u4f30\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002"}}
{"id": "2511.00785", "pdf": "https://arxiv.org/pdf/2511.00785", "abs": "https://arxiv.org/abs/2511.00785", "authors": ["Juan Wang", "Yasutomo Kawanishi", "Tomo Miyazaki", "Zhijie Wang", "Shinichiro Omachi"], "title": "Class-agnostic 3D Segmentation by Granularity-Consistent Automatic 2D Mask Tracking", "categories": ["cs.CV", "cs.AI"], "comment": "Under review in Pattern Recognition", "summary": "3D instance segmentation is an important task for real-world applications. To\navoid costly manual annotations, existing methods have explored generating\npseudo labels by transferring 2D masks from foundation models to 3D. However,\nthis approach is often suboptimal since the video frames are processed\nindependently. This causes inconsistent segmentation granularity and\nconflicting 3D pseudo labels, which degrades the accuracy of final\nsegmentation. To address this, we introduce a Granularity-Consistent automatic\n2D Mask Tracking approach that maintains temporal correspondences across\nframes, eliminating conflicting pseudo labels. Combined with a three-stage\ncurriculum learning framework, our approach progressively trains from\nfragmented single-view data to unified multi-view annotations, ultimately\nglobally coherent full-scene supervision. This structured learning pipeline\nenables the model to progressively expose to pseudo-labels of increasing\nconsistency. Thus, we can robustly distill a consistent 3D representation from\ninitially fragmented and contradictory 2D priors. Experimental results\ndemonstrated that our method effectively generated consistent and accurate 3D\nsegmentations. Furthermore, the proposed method achieved state-of-the-art\nresults on standard benchmarks and open-vocabulary ability.", "AI": {"tldr": "\u63d0\u51fa\u7c92\u5ea6\u4e00\u81f4\u76842D\u63a9\u7801\u8ddf\u8e2a\u65b9\u6cd5\u7ed3\u5408\u4e09\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u5b9e\u73b0\u51c6\u786e3D\u5b9e\u4f8b\u5206\u5272\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u5c062D\u63a9\u7801\u4ece\u57fa\u7840\u6a21\u578b\u8f6c\u79fb\u52303D\u751f\u6210\u4f2a\u6807\u7b7e\u7684\u65b9\u6cd5\u56e0\u72ec\u7acb\u5904\u7406\u89c6\u9891\u5e27\uff0c\u5bfc\u81f4\u5206\u5272\u7c92\u5ea6\u4e0d\u4e00\u81f4\u548c3D\u4f2a\u6807\u7b7e\u51b2\u7a81\uff0c\u964d\u4f4e\u6700\u7ec8\u5206\u5272\u7cbe\u5ea6\u3002", "method": "\u5f15\u5165\u7c92\u5ea6\u4e00\u81f4\u7684\u81ea\u52a82D\u63a9\u7801\u8ddf\u8e2a\u65b9\u6cd5\u7ef4\u62a4\u5e27\u95f4\u65f6\u95f4\u5bf9\u5e94\u5173\u7cfb\uff0c\u7ed3\u5408\u4e09\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u4ece\u788e\u7247\u5316\u5355\u89c6\u56fe\u6570\u636e\u9010\u6b65\u8bad\u7ec3\u5230\u7edf\u4e00\u591a\u89c6\u56fe\u6ce8\u91ca\u3002", "result": "\u6709\u6548\u751f\u6210\u4e00\u81f4\u4e14\u51c6\u786e\u76843D\u5206\u5272\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5e76\u5177\u5907\u5f00\u653e\u8bcd\u6c47\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u4ece\u6700\u521d\u788e\u7247\u5316\u548c\u77db\u76fe\u76842D\u5148\u9a8c\u4e2d\u7a33\u5065\u63d0\u53d6\u4e00\u81f4\u76843D\u8868\u793a\u3002"}}
{"id": "2511.00795", "pdf": "https://arxiv.org/pdf/2511.00795", "abs": "https://arxiv.org/abs/2511.00795", "authors": ["Viswa Chaitanya Marella", "Suhasnadh Reddy Veluru", "Sai Teja Erukude"], "title": "FedOnco-Bench: A Reproducible Benchmark for Privacy-Aware Federated Tumor Segmentation with Synthetic CT Data", "categories": ["cs.CV", "cs.AI"], "comment": "Published in IEEE", "summary": "Federated Learning (FL) allows multiple institutions to cooperatively train\nmachine learning models while retaining sensitive data at the source, which has\ngreat utility in privacy-sensitive environments. However, FL systems remain\nvulnerable to membership-inference attacks and data heterogeneity. This paper\npresents FedOnco-Bench, a reproducible benchmark for privacy-aware FL using\nsynthetic oncologic CT scans with tumor annotations. It evaluates segmentation\nperformance and privacy leakage across FL methods: FedAvg, FedProx, FedBN, and\nFedAvg with DP-SGD. Results show a distinct trade-off between privacy and\nutility: FedAvg is high performance (Dice around 0.85) with more privacy\nleakage (attack AUC about 0.72), while DP-SGD provides a higher level of\nprivacy (AUC around 0.25) at the cost of accuracy (Dice about 0.79). FedProx\nand FedBN offer balanced performance under heterogeneous data, especially with\nnon-identical distributed client data. FedOnco-Bench serves as a standardized,\nopen-source platform for benchmarking and developing privacy-preserving FL\nmethods for medical image segmentation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedOnco - Bench\u57fa\u51c6\uff0c\u8bc4\u4f30\u591a\u79cd\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u9690\u79c1\u548c\u6027\u80fd\u4e0a\u7684\u8868\u73b0\uff0c\u6307\u51fa\u9690\u79c1\u4e0e\u6548\u7528\u6743\u8861\uff0c\u8be5\u57fa\u51c6\u53ef\u7528\u4e8e\u533b\u5b66\u56fe\u50cf\u5206\u5272\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5f00\u53d1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u6613\u53d7\u6210\u5458\u63a8\u7406\u653b\u51fb\u548c\u6570\u636e\u5f02\u8d28\u6027\u5f71\u54cd\uff0c\u9700\u8981\u4e00\u4e2a\u57fa\u51c6\u8bc4\u4f30\u9690\u79c1\u611f\u77e5\u8054\u90a6\u5b66\u4e60\u3002", "method": "\u63d0\u51faFedOnco - Bench\u57fa\u51c6\uff0c\u4f7f\u7528\u5408\u6210\u80bf\u7624CT\u626b\u63cf\u6570\u636e\uff0c\u8bc4\u4f30FedAvg\u3001FedProx\u3001FedBN\u548c\u5e26DP - SGD\u7684FedAvg\u7b49\u65b9\u6cd5\u3002", "result": "FedAvg\u6027\u80fd\u9ad8\u4f46\u9690\u79c1\u6cc4\u9732\u591a\uff1bDP - SGD\u9690\u79c1\u6027\u9ad8\u4f46\u51c6\u786e\u6027\u4f4e\uff1bFedProx\u548cFedBN\u5728\u5f02\u6784\u6570\u636e\u4e0b\u8868\u73b0\u5e73\u8861\u3002", "conclusion": "FedOnco - Bench\u662f\u7528\u4e8e\u533b\u5b66\u56fe\u50cf\u5206\u5272\u7684\u9690\u79c1\u4fdd\u62a4\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f00\u53d1\u7684\u6807\u51c6\u5316\u5f00\u6e90\u5e73\u53f0\u3002"}}
{"id": "2511.00123", "pdf": "https://arxiv.org/pdf/2511.00123", "abs": "https://arxiv.org/abs/2511.00123", "authors": ["Gaby Maroun", "Salah Eddine Bekhouche", "Fadi Dornaika"], "title": "Integrating ConvNeXt and Vision Transformers for Enhancing Facial Age Estimation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Age estimation from facial images is a complex and multifaceted challenge in\ncomputer vision. In this study, we present a novel hybrid architecture that\ncombines ConvNeXt, a state-of-the-art advancement of convolutional neural\nnetworks (CNNs), with Vision Transformers (ViT). While each model independently\ndelivers excellent performance on a variety of tasks, their integration\nleverages the complementary strengths of the CNNs localized feature extraction\ncapabilities and the Transformers global attention mechanisms. Our proposed\nConvNeXt-ViT hybrid solution was thoroughly evaluated on benchmark age\nestimation datasets, including MORPH II, CACD, and AFAD, and achieved superior\nperformance in terms of mean absolute error (MAE). To address computational\nconstraints, we leverage pre-trained models and systematically explore\ndifferent configurations, using linear layers and advanced regularization\ntechniques to optimize the architecture. Comprehensive ablation studies\nhighlight the critical role of individual components and training strategies,\nand in particular emphasize the importance of adapted attention mechanisms\nwithin the CNN framework to improve the model focus on age-relevant facial\nfeatures. The results show that the ConvNeXt-ViT hybrid not only outperforms\ntraditional methods, but also provides a robust foundation for future advances\nin age estimation and related visual tasks. This work underscores the\ntransformative potential of hybrid architectures and represents a promising\ndirection for the seamless integration of CNNs and transformers to address\ncomplex computer vision challenges.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408ConvNeXt\u548cViT\u7684\u6df7\u5408\u67b6\u6784\u7528\u4e8e\u9762\u90e8\u5e74\u9f84\u4f30\u8ba1\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5f3a\u8c03\u6df7\u5408\u67b6\u6784\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u9762\u90e8\u56fe\u50cf\u5e74\u9f84\u4f30\u8ba1\u8fd9\u4e00\u590d\u6742\u6311\u6218\uff0c\u5229\u7528CNN\u548cTransformer\u4f18\u52bf\u3002", "method": "\u63d0\u51faConvNeXt - ViT\u6df7\u5408\u67b6\u6784\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u63a2\u7d22\u4e0d\u540c\u914d\u7f6e\uff0c\u7528\u7ebf\u6027\u5c42\u548c\u6b63\u5219\u5316\u6280\u672f\u4f18\u5316\uff0c\u8fdb\u884c\u6d88\u878d\u7814\u7a76\u3002", "result": "\u5728MORPH II\u3001CACD\u548cAFAD\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u6df7\u5408\u67b6\u6784\u7684MAE\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u6df7\u5408\u67b6\u6784\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4e3aCNN\u548cTransformer\u878d\u5408\u89e3\u51b3\u590d\u6742\u8ba1\u7b97\u673a\u89c6\u89c9\u95ee\u9898\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2511.00810", "pdf": "https://arxiv.org/pdf/2511.00810", "abs": "https://arxiv.org/abs/2511.00810", "authors": ["Shijie Zhou", "Viet Dac Lai", "Hao Tan", "Jihyung Kil", "Wanrong Zhu", "Changyou Chen", "Ruiyi Zhang"], "title": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "comment": null, "summary": "Graphical user interface (GUI) grounding is a key function of computer-use\nagents, which maps natural-language instructions to actionable screen regions.\nExisting approaches based on Multimodal Large Language Models (MLLMs) typically\nformulate it as a text-based coordinate generation task, yet directly\ngenerating precise coordinates from visual inputs remains challenging and\ncomputationally intensive. An intuitive way to implement GUI grounding is to\nfirst select visual patches relevant to the instructions and then determine the\nprecise click location within those patches. Based on the observations that\ngeneral MLLMs have some native grounding capability, nested within their\nattentions, we propose GUI-AIMA, an attention-based and coordinate-free\nsupervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns\nthe intrinsic multimodal attention of MLLMs with patch-wise grounding signals.\nThese signals are calculated adaptively for diverse user instructions by\nmulti-head aggregation on simplified query-visual attention matrices. Besides,\nits coordinate-free manner can easily integrate a plug-and-play zoom-in stage.\nGUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional\ndata efficiency and verifying that light training can trigger the native\ngrounding capability of MLLMs. It achieves state-of-the-art performance among\n3B models, attaining an average accuracy of 58.6% on ScreenSpot-Pro and 62.2%\non OSWorld-G. Project page: https://github.com/sjz5202/GUI-AIMA", "AI": {"tldr": "\u63d0\u51faGUI - AIMA\u6846\u67b6\u89e3\u51b3GUI grounding\u95ee\u9898\uff0c\u6570\u636e\u6548\u7387\u9ad8\u4e14\u6027\u80fd\u8fbe\u5230SOTA\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eMLLMs\u7684GUI grounding\u65b9\u6cd5\u5c06\u5176\u4f5c\u4e3a\u6587\u672c\u5750\u6807\u751f\u6210\u4efb\u52a1\uff0c\u76f4\u63a5\u4ece\u89c6\u89c9\u8f93\u5165\u751f\u6210\u7cbe\u786e\u5750\u6807\u6709\u6311\u6218\u4e14\u8ba1\u7b97\u91cf\u5927\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u4e14\u65e0\u5750\u6807\u7684\u76d1\u7763\u5fae\u8c03\u6846\u67b6GUI - AIMA\uff0c\u4f7fMLLMs\u7684\u5185\u5728\u591a\u6a21\u6001\u6ce8\u610f\u529b\u4e0e\u9010\u5757\u63a5\u5730\u4fe1\u53f7\u5bf9\u9f50\uff0c\u901a\u8fc7\u591a\u5934\u805a\u5408\u81ea\u9002\u5e94\u8ba1\u7b97\u4fe1\u53f7\uff0c\u65e0\u5750\u6807\u65b9\u5f0f\u53ef\u96c6\u6210\u7f29\u653e\u9636\u6bb5\u3002", "result": "GUI - AIMA - 3B\u4ec5\u752885k\u622a\u56fe\u8bad\u7ec3\uff0c\u6570\u636e\u6548\u7387\u9ad8\uff0c\u57283B\u6a21\u578b\u4e2d\u8fbe\u5230SOTA\uff0c\u5728ScreenSpot - Pro\u548cOSWorld - G\u4e0a\u5206\u522b\u8fbe58.6%\u548c62.2%\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u8bad\u7ec3\u80fd\u89e6\u53d1MLLMs\u7684\u539f\u751f\u63a5\u5730\u80fd\u529b\uff0cGUI - AIMA\u6846\u67b6\u6709\u6548\u3002"}}
{"id": "2511.00828", "pdf": "https://arxiv.org/pdf/2511.00828", "abs": "https://arxiv.org/abs/2511.00828", "authors": ["Huiyao Dong", "Igor Kotenko"], "title": "Towards Ultra-Low Latency: Binarized Neural Network Architectures for In-Vehicle Network Intrusion Detection", "categories": ["cs.CR", "cs.AI"], "comment": "6 pages, accepted and presented at INISTA 2025\n  (https://conferences.sigappfr.org/inista2025/)", "summary": "The Control Area Network (CAN) protocol is essential for in-vehicle\ncommunication, facilitating high-speed data exchange among Electronic Control\nUnits (ECUs). However, its inherent design lacks robust security features,\nrendering vehicles susceptible to cyberattacks. While recent research has\ninvestigated machine learning and deep learning techniques to enhance network\nsecurity, their practical applicability remains uncertain. This paper presents\na lightweight intrusion detection technique based on Binarized Neural Networks\n(BNNs), which utilizes payload data, message IDs, and CAN message frequencies\nfor effective intrusion detection. Additionally, we develop hybrid binary\nencoding techniques to integrate non-binary features, such as message IDs and\nfrequencies. The proposed method, namely the BNN framework specifically\noptimized for in-vehicle intrusion detection combined with hybrid binary\nquantization techniques for non-payload attributes, demonstrates efficacy in\nboth anomaly detection and multi-class network traffic classification. The\nsystem is well-suited for deployment on micro-controllers and Gateway ECUs,\naligning with the real-time requirements of CAN bus safety applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4e8c\u503c\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u8f7b\u91cf\u7ea7\u5165\u4fb5\u68c0\u6d4b\u6280\u672f\uff0c\u7ed3\u5408\u6df7\u5408\u4e8c\u8fdb\u5236\u7f16\u7801\uff0c\u9002\u7528\u4e8e\u5fae\u63a7\u5236\u5668\u548c\u7f51\u5173ECU\uff0c\u80fd\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u548c\u591a\u7c7b\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u3002", "motivation": "CAN\u534f\u8bae\u7f3a\u4e4f\u5b89\u5168\u7279\u6027\uff0c\u8f66\u8f86\u6613\u53d7\u7f51\u7edc\u653b\u51fb\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u5b9e\u7528\u6027\u4e0d\u786e\u5b9a\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e8c\u503c\u5316\u795e\u7ecf\u7f51\u7edc\uff08BNNs\uff09\u7684\u8f7b\u91cf\u7ea7\u5165\u4fb5\u68c0\u6d4b\u6280\u672f\uff0c\u5229\u7528\u8d1f\u8f7d\u6570\u636e\u3001\u6d88\u606fID\u548cCAN\u6d88\u606f\u9891\u7387\u8fdb\u884c\u68c0\u6d4b\uff0c\u5f00\u53d1\u6df7\u5408\u4e8c\u8fdb\u5236\u7f16\u7801\u6280\u672f\u96c6\u6210\u975e\u4e8c\u8fdb\u5236\u7279\u5f81\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u5f02\u5e38\u68c0\u6d4b\u548c\u591a\u7c7b\u7f51\u7edc\u6d41\u91cf\u5206\u7c7b\u4e2d\u6709\u6548\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u9002\u5408\u90e8\u7f72\u5728\u5fae\u63a7\u5236\u5668\u548c\u7f51\u5173ECU\u4e0a\uff0c\u6ee1\u8db3CAN\u603b\u7ebf\u5b89\u5168\u5e94\u7528\u7684\u5b9e\u65f6\u8981\u6c42\u3002"}}
{"id": "2511.00180", "pdf": "https://arxiv.org/pdf/2511.00180", "abs": "https://arxiv.org/abs/2511.00180", "authors": ["Nicky Pochinkov", "Yulia Volkova", "Anna Vasileva", "Sai V R Chereddy"], "title": "ParaScopes: What do Language Models Activations Encode About Future Text?", "categories": ["cs.CL", "cs.LG"], "comment": "Main paper: 9 pages, 10 figures. Total 24 pages", "summary": "Interpretability studies in language models often investigate forward-looking\nrepresentations of activations. However, as language models become capable of\ndoing ever longer time horizon tasks, methods for understanding activations\noften remain limited to testing specific concepts or tokens. We develop a\nframework of Residual Stream Decoders as a method of probing model activations\nfor paragraph-scale and document-scale plans. We test several methods and find\ninformation can be decoded equivalent to 5+ tokens of future context in small\nmodels. These results lay the groundwork for better monitoring of language\nmodels and better understanding how they might encode longer-term planning\ninformation.", "AI": {"tldr": "\u63d0\u51fa\u6b8b\u5dee\u6d41\u89e3\u7801\u5668\u6846\u67b6\u63a2\u67e5\u6a21\u578b\u6fc0\u6d3b\u4ee5\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u957f\u671f\u89c4\u5212\u4fe1\u606f\uff0c\u5c0f\u6a21\u578b\u80fd\u89e3\u7801\u76f8\u5f53\u4e8e5+\u4e2a\u672a\u6765\u4e0a\u4e0b\u6587\u6807\u8bb0\u7684\u4fe1\u606f\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u53ef\u5904\u7406\u957f\u65f6\u4efb\u52a1\uff0c\u4f46\u7406\u89e3\u6fc0\u6d3b\u7684\u65b9\u6cd5\u5c40\u9650\u4e8e\u6d4b\u8bd5\u7279\u5b9a\u6982\u5ff5\u6216\u6807\u8bb0\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u7406\u89e3\u957f\u65f6\u89c4\u5212\u4fe1\u606f\u3002", "method": "\u5f00\u53d1\u6b8b\u5dee\u6d41\u89e3\u7801\u5668\u6846\u67b6\u63a2\u67e5\u6a21\u578b\u6fc0\u6d3b\u4ee5\u83b7\u53d6\u6bb5\u843d\u548c\u6587\u6863\u7ea7\u522b\u7684\u89c4\u5212\u4fe1\u606f\u3002", "result": "\u6d4b\u8bd5\u53d1\u73b0\u5c0f\u6a21\u578b\u4e2d\u53ef\u89e3\u7801\u51fa\u76f8\u5f53\u4e8e5+\u4e2a\u672a\u6765\u4e0a\u4e0b\u6587\u6807\u8bb0\u7684\u4fe1\u606f\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u66f4\u597d\u76d1\u6d4b\u8bed\u8a00\u6a21\u578b\u548c\u7406\u89e3\u5176\u7f16\u7801\u957f\u671f\u89c4\u5212\u4fe1\u606f\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.00831", "pdf": "https://arxiv.org/pdf/2511.00831", "abs": "https://arxiv.org/abs/2511.00831", "authors": ["Xin Liu", "Aoyang Zhou", "Aoyang Zhou"], "title": "Enhancing Adversarial Transferability in Visual-Language Pre-training Models via Local Shuffle and Sample-based Attack", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by NAACL2025 findings", "summary": "Visual-Language Pre-training (VLP) models have achieved significant\nperformance across various downstream tasks. However, they remain vulnerable to\nadversarial examples. While prior efforts focus on improving the adversarial\ntransferability of multimodal adversarial examples through cross-modal\ninteractions, these approaches suffer from overfitting issues, due to a lack of\ninput diversity by relying excessively on information from adversarial examples\nin one modality when crafting attacks in another. To address this issue, we\ndraw inspiration from strategies in some adversarial training methods and\npropose a novel attack called Local Shuffle and Sample-based Attack (LSSA).\nLSSA randomly shuffles one of the local image blocks, thus expanding the\noriginal image-text pairs, generating adversarial images, and sampling around\nthem. Then, it utilizes both the original and sampled images to generate the\nadversarial texts. Extensive experiments on multiple models and datasets\ndemonstrate that LSSA significantly enhances the transferability of multimodal\nadversarial examples across diverse VLP models and downstream tasks. Moreover,\nLSSA outperforms other advanced attacks on Large Vision-Language Models.", "AI": {"tldr": "\u73b0\u6709VLP\u6a21\u578b\u6613\u53d7\u5bf9\u6297\u6837\u672c\u653b\u51fb\uff0c\u63d0\u51faLSSA\u653b\u51fb\u65b9\u6cd5\u63d0\u5347\u591a\u6a21\u6001\u5bf9\u6297\u6837\u672c\u53ef\u8fc1\u79fb\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u4e14\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u653b\u51fb\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u6210\u8de8\u6a21\u6001\u5bf9\u6297\u6837\u672c\u65f6\u56e0\u7f3a\u4e4f\u8f93\u5165\u591a\u6837\u6027\u5bfc\u81f4\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faLocal Shuffle and Sample-based Attack (LSSA)\uff0c\u968f\u673a\u6253\u4e71\u5c40\u90e8\u56fe\u50cf\u5757\uff0c\u6269\u5c55\u539f\u59cb\u56fe\u50cf - \u6587\u672c\u5bf9\uff0c\u751f\u6210\u5bf9\u6297\u56fe\u50cf\u5e76\u91c7\u6837\uff0c\u7528\u539f\u59cb\u548c\u91c7\u6837\u56fe\u50cf\u751f\u6210\u5bf9\u6297\u6587\u672c\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLSSA\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5bf9\u6297\u6837\u672c\u5728\u4e0d\u540cVLP\u6a21\u578b\u548c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u4e14\u5728\u5927\u6a21\u578b\u4e0a\u4f18\u4e8e\u5176\u4ed6\u5148\u8fdb\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "LSSA\u662f\u4e00\u79cd\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u63d0\u5347\u591a\u6a21\u6001\u5bf9\u6297\u6837\u672c\u7684\u53ef\u8fc1\u79fb\u6027\u3002"}}
{"id": "2511.00833", "pdf": "https://arxiv.org/pdf/2511.00833", "abs": "https://arxiv.org/abs/2511.00833", "authors": ["Yifan Pu", "Jixuan Ying", "Qixiu Li", "Tianzhu Ye", "Dongchen Han", "Xiaochen Wang", "Ziyi Wang", "Xinyu Shao", "Gao Huang", "Xiu Li"], "title": "Linear Differential Vision Transformer: Learning Visual Contrasts via Pairwise Differentials", "categories": ["cs.CV", "cs.AI"], "comment": "NeurIPS 2025", "summary": "Vision Transformers (ViTs) have become a universal backbone for both image\nrecognition and image generation. Yet their Multi-Head Self-Attention (MHSA)\nlayer still performs a quadratic query-key interaction for every token pair,\nspending the bulk of computation on visually weak or redundant correlations. We\nintroduce Visual-Contrast Attention (VCA), a drop-in replacement for MHSA that\ninjects an explicit notion of discrimination while reducing the theoretical\ncomplexity from O(N N C) to O(N n C) with n << N. VCA first distils each head's\ndense query field into a handful of spatially pooled visual-contrast tokens,\nthen splits them into a learnable positive and negative stream whose\ndifferential interaction highlights what truly separates one region from\nanother. The module adds fewer than 0.3M parameters to a DeiT-Tiny backbone,\nrequires no extra FLOPs, and is wholly architecture-agnostic. Empirically, VCA\nlifts DeiT-Tiny top-1 accuracy on ImageNet-1K from 72.2% to 75.6% (+3.4) and\nimproves three strong hierarchical ViTs by up to 3.1%, while in\nclass-conditional ImageNet generation it lowers FID-50K by 2.1 to 5.2 points\nacross both diffusion (DiT) and flow (SiT) models. Extensive ablations confirm\nthat (i) spatial pooling supplies low-variance global cues, (ii) dual\npositional embeddings are indispensable for contrastive reasoning, and (iii)\ncombining the two in both stages yields the strongest synergy. VCA therefore\noffers a simple path towards faster and sharper Vision Transformers. The source\ncode is available at https://github.com/LeapLabTHU/LinearDiff.", "AI": {"tldr": "\u63d0\u51faVCA\u6a21\u5757\u66ff\u4ee3MHSA\uff0c\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u63d0\u5347Vision Transformers\u6027\u80fd\u3002", "motivation": "ViTs\u7684MHSA\u5c42\u5728\u89c6\u89c9\u5f31\u6216\u5197\u4f59\u76f8\u5173\u6027\u4e0a\u82b1\u8d39\u5927\u91cf\u8ba1\u7b97\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u5165VCA\u6a21\u5757\uff0c\u5c06\u6bcf\u4e2a\u5934\u7684\u5bc6\u96c6\u67e5\u8be2\u5b57\u6bb5\u63d0\u70bc\u4e3a\u89c6\u89c9\u5bf9\u6bd4\u4ee4\u724c\uff0c\u62c6\u5206\u4e3a\u6b63\u8d1f\u6d41\u8fdb\u884c\u5dee\u5206\u4ea4\u4e92\u3002", "result": "\u63d0\u5347DeiT - Tiny\u5728ImageNet - 1K\u4e0a\u7684top - 1\u51c6\u786e\u7387\uff0c\u6539\u5584\u4e09\u79cd\u5206\u5c42ViTs\uff0c\u964d\u4f4e\u56fe\u50cf\u751f\u6210FID - 50K\u5206\u6570\u3002", "conclusion": "VCA\u4e3a\u66f4\u5feb\u66f4\u6e05\u6670\u7684Vision Transformers\u63d0\u4f9b\u4e86\u7b80\u5355\u9014\u5f84\u3002"}}
{"id": "2511.00193", "pdf": "https://arxiv.org/pdf/2511.00193", "abs": "https://arxiv.org/abs/2511.00193", "authors": ["Faranak Akbarifar", "Nooshin Maghsoodi", "Sean P Dukelow", "Stephen Scott", "Parvin Mousavi"], "title": "Reducing Robotic Upper-Limb Assessment Time While Maintaining Precision: A Time Series Foundation Model Approach", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Purpose: Visually Guided Reaching (VGR) on the Kinarm robot yields sensitive\nkinematic biomarkers but requires 40-64 reaches, imposing time and fatigue\nburdens. We evaluate whether time-series foundation models can replace\nunrecorded trials from an early subset of reaches while preserving the\nreliability of standard Kinarm parameters.\n  Methods: We analyzed VGR speed signals from 461 stroke and 599 control\nparticipants across 4- and 8-target reaching protocols. We withheld all but the\nfirst 8 or 16 reaching trials and used ARIMA, MOMENT, and Chronos models,\nfine-tuned on 70 percent of subjects, to forecast synthetic trials. We\nrecomputed four kinematic features of reaching (reaction time, movement time,\nposture speed, maximum speed) on combined recorded plus forecasted trials and\ncompared them to full-length references using ICC(2,1).\n  Results: Chronos forecasts restored ICC >= 0.90 for all parameters with only\n8 recorded trials plus forecasts, matching the reliability of 24-28 recorded\nreaches (Delta ICC <= 0.07). MOMENT yielded intermediate gains, while ARIMA\nimprovements were minimal. Across cohorts and protocols, synthetic trials\nreplaced reaches without materially compromising feature reliability.\n  Conclusion: Foundation-model forecasting can greatly shorten Kinarm VGR\nassessment time. For the most impaired stroke survivors, sessions drop from 4-5\nminutes to about 1 minute while preserving kinematic precision. This\nforecast-augmented paradigm promises efficient robotic evaluations for\nassessing motor impairments following stroke.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u80fd\u5426\u7528\u65e9\u671f\u90e8\u5206\u8bd5\u9a8c\u66ff\u4ee3\u672a\u8bb0\u5f55\u8bd5\u9a8c\uff0c\u540c\u65f6\u4fdd\u6301Kinarm\u53c2\u6570\u53ef\u9760\u6027\uff0c\u7ed3\u679c\u8868\u660e\u57fa\u7840\u6a21\u578b\u53ef\u5927\u5e45\u7f29\u77ed\u8bc4\u4f30\u65f6\u95f4\u3002", "motivation": "Kinarm\u673a\u5668\u4eba\u4e0a\u7684\u89c6\u89c9\u5f15\u5bfc\u4f38\u624b\uff08VGR\uff09\u970040 - 64\u6b21\u4f38\u624b\uff0c\u6709\u65f6\u95f4\u548c\u75b2\u52b3\u8d1f\u62c5\uff0c\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u66ff\u4ee3\u672a\u8bb0\u5f55\u8bd5\u9a8c\u7684\u53ef\u884c\u6027\u3002", "method": "\u5206\u6790461\u540d\u4e2d\u98ce\u548c599\u540d\u5bf9\u7167\u53c2\u4e0e\u8005\u7684VGR\u901f\u5ea6\u4fe1\u53f7\uff0c\u7528ARIMA\u3001MOMENT\u548cChronos\u6a21\u578b\u5bf9\u90e8\u5206\u8bd5\u9a8c\u8fdb\u884c\u9884\u6d4b\uff0c\u91cd\u65b0\u8ba1\u7b97\u8fd0\u52a8\u5b66\u7279\u5f81\u5e76\u4e0e\u5168\u957f\u53c2\u8003\u5bf9\u6bd4\u3002", "result": "Chronos\u6a21\u578b\u4ec5\u75288\u6b21\u8bb0\u5f55\u8bd5\u9a8c\u52a0\u9884\u6d4b\u5c31\u80fd\u6062\u590dICC >= 0.90\uff0cMOMENT\u6709\u4e2d\u7b49\u63d0\u5347\uff0cARIMA\u6539\u5584\u6700\u5c0f\uff0c\u5408\u6210\u8bd5\u9a8c\u4e0d\u5f71\u54cd\u7279\u5f81\u53ef\u9760\u6027\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u9884\u6d4b\u53ef\u5927\u5e45\u7f29\u77edKinarm VGR\u8bc4\u4f30\u65f6\u95f4\uff0c\u6709\u671b\u7528\u4e8e\u4e2d\u98ce\u540e\u8fd0\u52a8\u969c\u788d\u7684\u9ad8\u6548\u673a\u5668\u4eba\u8bc4\u4f30\u3002"}}
{"id": "2511.00836", "pdf": "https://arxiv.org/pdf/2511.00836", "abs": "https://arxiv.org/abs/2511.00836", "authors": ["Xin Liu", "Yichen Yang", "Kun He", "John E. Hopcroft"], "title": "Parameter Interpolation Adversarial Training for Robust Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by TIFS 2025", "summary": "Though deep neural networks exhibit superior performance on various tasks,\nthey are still plagued by adversarial examples. Adversarial training has been\ndemonstrated to be the most effective method to defend against adversarial\nattacks. However, existing adversarial training methods show that the model\nrobustness has apparent oscillations and overfitting issues in the training\nprocess, degrading the defense efficacy. To address these issues, we propose a\nnovel framework called Parameter Interpolation Adversarial Training (PIAT).\nPIAT tunes the model parameters between each epoch by interpolating the\nparameters of the previous and current epochs. It makes the decision boundary\nof model change more moderate and alleviates the overfitting issue, helping the\nmodel converge better and achieving higher model robustness. In addition, we\nsuggest using the Normalized Mean Square Error (NMSE) to further improve the\nrobustness by aligning the relative magnitude of logits between clean and\nadversarial examples rather than the absolute magnitude. Extensive experiments\nconducted on several benchmark datasets demonstrate that our framework could\nprominently improve the robustness of both Convolutional Neural Networks (CNNs)\nand Vision Transformers (ViTs).", "AI": {"tldr": "\u9488\u5bf9\u73b0\u6709\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u5b58\u5728\u7684\u6a21\u578b\u9c81\u68d2\u6027\u632f\u8361\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u51faPIAT\u6846\u67b6\u5e76\u7ed3\u5408NMSE\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u63d0\u5347CNN\u548cViT\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6a21\u578b\u9c81\u68d2\u6027\u5b58\u5728\u660e\u663e\u632f\u8361\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u964d\u4f4e\u9632\u5fa1\u6548\u679c\u3002", "method": "\u63d0\u51faPIAT\u6846\u67b6\uff0c\u5728\u6bcf\u4e2aepoch\u4e4b\u95f4\u901a\u8fc7\u63d2\u503c\u4e0a\u4e00\u4e2a\u548c\u5f53\u524depoch\u7684\u53c2\u6570\u6765\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff1b\u4f7f\u7528NMSE\u5bf9\u9f50\u5e72\u51c0\u548c\u5bf9\u6297\u6837\u672clogits\u7684\u76f8\u5bf9\u5927\u5c0f\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u663e\u8457\u63d0\u9ad8CNN\u548cViT\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "PIAT\u6846\u67b6\u7ed3\u5408NMSE\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.00204", "pdf": "https://arxiv.org/pdf/2511.00204", "abs": "https://arxiv.org/abs/2511.00204", "authors": ["Haoming Yan", "Xinyu Chen", "Yanran Wang", "Zhengchao Luo", "Weizheng Huang", "Hongshuai Wang", "Peng Chen", "Yuzhi Zhang", "Weijie Sun", "Jinzhuo Wang", "Qihuang Gong", "Rui Zhu", "Lichen Zhao"], "title": "Transfer learning discovery of molecular modulators for perovskite solar cells", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.app-ph"], "comment": null, "summary": "The discovery of effective molecular modulators is essential for advancing\nperovskite solar cells (PSCs), but the research process is hindered by the\nvastness of chemical space and the time-consuming and expensive trial-and-error\nexperimental screening. Concurrently, machine learning (ML) offers significant\npotential for accelerating materials discovery. However, applying ML to PSCs\nremains a major challenge due to data scarcity and limitations of traditional\nquantitative structure-property relationship (QSPR) models. Here, we apply a\nchemical informed transfer learning framework based on pre-trained deep neural\nnetworks, which achieves high accuracy in predicting the molecular modulator's\neffect on the power conversion efficiency (PCE) of PSCs. This framework is\nestablished through systematical benchmarking of diverse molecular\nrepresentations, enabling lowcost and high-throughput virtual screening over\n79,043 commercially available molecules. Furthermore, we leverage\ninterpretability techniques to visualize the learned chemical representation\nand experimentally characterize the resulting modulator-perovskite\ninteractions. The top molecular modulators identified by the framework are\nsubsequently validated experimentally, delivering a remarkably improved\nchampion PCE of 26.91% in PSCs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5316\u5b66\u4fe1\u606f\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\u9884\u6d4b\u5206\u5b50\u8c03\u8282\u5242\u5bf9\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\u529f\u7387\u8f6c\u6362\u6548\u7387\u7684\u5f71\u54cd\uff0c\u5b9e\u73b0\u4f4e\u6210\u672c\u9ad8\u901a\u91cf\u865a\u62df\u7b5b\u9009\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u63d0\u5347\u7535\u6c60\u6548\u7387\u3002", "motivation": "\u6709\u6548\u5206\u5b50\u8c03\u8282\u5242\u53d1\u73b0\u5bf9\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\u53d1\u5c55\u91cd\u8981\uff0c\u4f46\u5316\u5b66\u7a7a\u95f4\u5927\u3001\u5b9e\u9a8c\u7b5b\u9009\u8017\u65f6\u6602\u8d35\uff0c\u4e14\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e8e\u8be5\u9886\u57df\u5b58\u5728\u6570\u636e\u7a00\u7f3a\u548c\u4f20\u7edf\u6a21\u578b\u5c40\u9650\u95ee\u9898\u3002", "method": "\u5e94\u7528\u57fa\u4e8e\u9884\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5316\u5b66\u4fe1\u606f\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u5bf9\u591a\u79cd\u5206\u5b50\u8868\u793a\u8fdb\u884c\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5229\u7528\u53ef\u89e3\u91ca\u6027\u6280\u672f\u53ef\u89c6\u5316\u5316\u5b66\u8868\u793a\u5e76\u5b9e\u9a8c\u8868\u5f81\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u6846\u67b6\u80fd\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u5b9e\u73b0\u5bf979,043\u79cd\u5e02\u552e\u5206\u5b50\u7684\u4f4e\u6210\u672c\u9ad8\u901a\u91cf\u865a\u62df\u7b5b\u9009\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5f97\u5230\u7684\u9876\u7ea7\u5206\u5b50\u8c03\u8282\u5242\u4f7f\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\u51a0\u519b\u529f\u7387\u8f6c\u6362\u6548\u7387\u8fbe26.91%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5316\u5b66\u4fe1\u606f\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\u53ef\u6709\u6548\u52a0\u901f\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\u5206\u5b50\u8c03\u8282\u5242\u7684\u53d1\u73b0\uff0c\u63d0\u5347\u7535\u6c60\u6548\u7387\u3002"}}
{"id": "2511.00846", "pdf": "https://arxiv.org/pdf/2511.00846", "abs": "https://arxiv.org/abs/2511.00846", "authors": ["Zhihao Peng", "Cheng Wang", "Shengyuan Liu", "Zhiying Liang", "Yixuan Yuan"], "title": "OmniBrainBench: A Comprehensive Multimodal Benchmark for Brain Imaging Analysis Across Multi-stage Clinical Tasks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Brain imaging analysis is vital for diagnosing and treating brain disorders,\nand multimodal large language models (MLLMs) are increasingly assisting in that\nanalysis. However, current brain-oriented visual question-answering (VQA)\nbenchmarks either cover a few imaging modalities or are limited to\ncoarse-grained pathological descriptions, hindering a comprehensive assessment\nof MLLMs throughout the full clinical continuum. To address these, we introduce\nOmniBrainBench, the first comprehensive multimodal VQA benchmark specifically\ndesigned to assess the multimodal comprehension capabilities of MLLMs in brain\nimaging analysis.OmniBrainBench consists of 15 distinct brain imaging\nmodalities collected from 30 verified medical sources, yielding 9,527 validated\nVQA pairs and 31,706 images. It simulates clinical workflows and encompasses 15\nmulti-stage clinical tasks rigorously validated by a professional radiologist.\nEvaluation of 24 state-of-the-art models, including open-source, medical, and\nproprietary MLLMs, highlights the substantial challenges posed by\nOmniBrainBench. Our experiments reveal: (1) proprietary MLLMs (e.g., GPT-5)\nbeat open-source and medical models but lag physicians; (2) medical MLLMs vary\nwidely in performance; (3) open-source MLLMs trail overall but excel in\nspecific tasks; (4) MLLMs underperform sharply in complex preoperative tasks,\nrevealing a visual-to-clinical reasoning gap. OmniBrainBench sets a new\nstandard for evaluating and advancing MLLMs in brain imaging analysis,\nhighlighting gaps compared to expert clinical reasoning. We release it at\nbenchmark \\& code.", "AI": {"tldr": "\u63d0\u51faOmniBrainBench\u8bc4\u4f30\u8111\u6210\u50cf\u5206\u6790\u4e2dMLLMs\u7684\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\uff0c\u8bc4\u4f3024\u4e2a\u6a21\u578b\uff0c\u6307\u51fa\u6a21\u578b\u4e0e\u4e13\u5bb6\u5dee\u8ddd\u5e76\u53d1\u5e03\u57fa\u51c6\u548c\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u8111\u5bfc\u5411\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u5b58\u5728\u8986\u76d6\u6210\u50cf\u6a21\u6001\u5c11\u6216\u63cf\u8ff0\u7c97\u7c92\u5ea6\u7684\u95ee\u9898\uff0c\u963b\u788d\u5bf9MLLMs\u7684\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u5f15\u5165OmniBrainBench\uff0c\u5305\u542b15\u79cd\u8111\u6210\u50cf\u6a21\u6001\u30019527\u4e2a\u6709\u6548VQA\u5bf9\u548c31706\u5f20\u56fe\u50cf\uff0c\u6a21\u62df\u4e34\u5e8a\u5de5\u4f5c\u6d41\uff0c\u670915\u4e2a\u591a\u9636\u6bb5\u4e34\u5e8a\u4efb\u52a1\uff0c\u5e76\u7531\u4e13\u4e1a\u653e\u5c04\u79d1\u533b\u751f\u9a8c\u8bc1\u3002", "result": "\u8bc4\u4f3024\u4e2a\u6a21\u578b\u53d1\u73b0\uff0c\u4e13\u6709MLLMs\u4f18\u4e8e\u5f00\u6e90\u548c\u533b\u5b66\u6a21\u578b\u4f46\u4e0d\u5982\u533b\u751f\uff1b\u533b\u5b66MLLMs\u6027\u80fd\u5dee\u5f02\u5927\uff1b\u5f00\u6e90MLLMs\u603b\u4f53\u843d\u540e\u4f46\u7279\u5b9a\u4efb\u52a1\u8868\u73b0\u597d\uff1bMLLMs\u5728\u590d\u6742\u672f\u524d\u4efb\u52a1\u8868\u73b0\u5dee\u3002", "conclusion": "OmniBrainBench\u4e3a\u8bc4\u4f30\u548c\u63a8\u8fdb\u8111\u6210\u50cf\u5206\u6790\u4e2dMLLMs\u8bbe\u5b9a\u65b0\u6807\u51c6\uff0c\u51f8\u663e\u6a21\u578b\u4e0e\u4e13\u5bb6\u4e34\u5e8a\u63a8\u7406\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.00256", "pdf": "https://arxiv.org/pdf/2511.00256", "abs": "https://arxiv.org/abs/2511.00256", "authors": ["Zongyang Du", "Shreeram Suresh Chandra", "Ismail Rasim Ulgen", "Aurosweta Mahapatra", "Ali N. Salman", "Carlos Busso", "Berrak Sisman"], "title": "NaturalVoices: A Large-Scale, Spontaneous and Emotional Podcast Dataset for Voice Conversion", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Under review for IEEE Transactions on Affective Computing", "summary": "Everyday speech conveys far more than words, it reflects who we are, how we\nfeel, and the circumstances surrounding our interactions. Yet, most existing\nspeech datasets are acted, limited in scale, and fail to capture the expressive\nrichness of real-life communication. With the rise of large neural networks,\nseveral large-scale speech corpora have emerged and been widely adopted across\nvarious speech processing tasks. However, the field of voice conversion (VC)\nstill lacks large-scale, expressive, and real-life speech resources suitable\nfor modeling natural prosody and emotion. To fill this gap, we release\nNaturalVoices (NV), the first large-scale spontaneous podcast dataset\nspecifically designed for emotion-aware voice conversion. It comprises 5,049\nhours of spontaneous podcast recordings with automatic annotations for emotion\n(categorical and attribute-based), speech quality, transcripts, speaker\nidentity, and sound events. The dataset captures expressive emotional variation\nacross thousands of speakers, diverse topics, and natural speaking styles. We\nalso provide an open-source pipeline with modular annotation tools and flexible\nfiltering, enabling researchers to construct customized subsets for a wide\nrange of VC tasks. Experiments demonstrate that NaturalVoices supports the\ndevelopment of robust and generalizable VC models capable of producing natural,\nexpressive speech, while revealing limitations of current architectures when\napplied to large-scale spontaneous data. These results suggest that\nNaturalVoices is both a valuable resource and a challenging benchmark for\nadvancing the field of voice conversion. Dataset is available at:\nhttps://huggingface.co/JHU-SmileLab", "AI": {"tldr": "\u672c\u6587\u53d1\u5e03\u4e86\u7528\u4e8e\u60c5\u611f\u611f\u77e5\u8bed\u97f3\u8f6c\u6362\u7684\u5927\u89c4\u6a21\u81ea\u53d1\u64ad\u5ba2\u6570\u636e\u96c6NaturalVoices\uff0c\u4ecb\u7ecd\u5176\u5185\u5bb9\u3001\u5de5\u5177\u5e76\u5c55\u793a\u5b9e\u9a8c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u6570\u636e\u96c6\u5b58\u5728\u5c40\u9650\uff0c\u8bed\u97f3\u8f6c\u6362\u9886\u57df\u7f3a\u4e4f\u9002\u5408\u5efa\u6a21\u81ea\u7136\u97f5\u5f8b\u548c\u60c5\u611f\u7684\u5927\u89c4\u6a21\u3001\u5bcc\u6709\u8868\u73b0\u529b\u7684\u771f\u5b9e\u8bed\u97f3\u8d44\u6e90\u3002", "method": "\u53d1\u5e03NaturalVoices\u6570\u636e\u96c6\uff0c\u5305\u542b5049\u5c0f\u65f6\u81ea\u53d1\u64ad\u5ba2\u5f55\u97f3\u53ca\u591a\u79cd\u81ea\u52a8\u6807\u6ce8\uff0c\u63d0\u4f9b\u5f00\u6e90\u6a21\u5757\u5316\u6807\u6ce8\u5de5\u5177\u548c\u7075\u6d3b\u8fc7\u6ee4\u7684\u7ba1\u9053\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6570\u636e\u96c6\u652f\u6301\u5f00\u53d1\u5f3a\u5927\u4e14\u901a\u7528\u7684\u8bed\u97f3\u8f6c\u6362\u6a21\u578b\uff0c\u540c\u65f6\u63ed\u793a\u5f53\u524d\u67b6\u6784\u5904\u7406\u5927\u89c4\u6a21\u81ea\u53d1\u6570\u636e\u7684\u5c40\u9650\u6027\u3002", "conclusion": "NaturalVoices\u662f\u63a8\u52a8\u8bed\u97f3\u8f6c\u6362\u9886\u57df\u53d1\u5c55\u7684\u5b9d\u8d35\u8d44\u6e90\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u3002"}}
{"id": "2511.00850", "pdf": "https://arxiv.org/pdf/2511.00850", "abs": "https://arxiv.org/abs/2511.00850", "authors": ["Yayue Deng", "Guoqiang Hu", "Haiyang Sun", "Xiangyu Zhang", "Haoyang Zhang", "Fei Tian", "Xuerui Yang", "Gang Yu", "Eng Siong Chng"], "title": "MULTI-Bench: A Multi-Turn Interactive Benchmark for Assessing Emotional Intelligence ability of Spoken Dialogue Models", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "comment": "Submitted to ICASSP 2026", "summary": "Spoken Dialogue Models (SDMs) have advanced rapidly, yet their ability to\nsustain genuinely interactive multi-turn conversations remains underexplored,\nas most benchmarks focus on single-turn exchanges. We introduce Multi-Bench,\nthe first benchmark explicitly designed to evaluate SDMs in multi-turn\ninteractive dialogue with an emphasis on emotional intelligence. Multi-Bench\nemploys a hierarchical structure with a basic track for emotion understanding\nand reasoning and an advanced track for emotion support and application. It\ncomprises five carefully designed tasks and about 3.2K samples, ranging from\nemotion recognition to complex reasoning and interactive dialogue, supported by\na reproducible evaluation framework. We evaluate six representative SDMs on\neight subsets of Multi-Bench. Results show that while current SDMs achieve good\nperformance on basic understanding tasks, they still have room for improvement\nin advanced multi-turn interactive dialogue and reasoning-related tasks,\nparticularly in emotion awareness and application.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u57fa\u51c6Multi - Bench\u8bc4\u4f30SDMs\uff0c\u8bc4\u4f30\u663e\u793a\u5f53\u524dSDMs\u5728\u9ad8\u7ea7\u4efb\u52a1\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709SDMs\u5728\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u80fd\u529b\u63a2\u7d22\u4e0d\u8db3\uff0c\u591a\u6570\u57fa\u51c6\u5173\u6ce8\u5355\u8f6e\u4ea4\u6d41\uff0c\u9700\u8bc4\u4f30\u5176\u5728\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165Multi - Bench\uff0c\u91c7\u7528\u5206\u5c42\u7ed3\u6784\uff0c\u542b\u57fa\u7840\u548c\u9ad8\u7ea7\u8d5b\u9053\uff0c\u5305\u542b\u4e94\u4e2a\u4efb\u52a1\u548c\u7ea63.2K\u6837\u672c\uff0c\u7528\u53ef\u590d\u73b0\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u516d\u4e2a\u4ee3\u8868\u6027SDMs\u5728\u516b\u4e2a\u5b50\u96c6\u4e0a\u8bc4\u4f30\u3002", "result": "\u5f53\u524dSDMs\u5728\u57fa\u7840\u7406\u89e3\u4efb\u52a1\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9ad8\u7ea7\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u548c\u63a8\u7406\u76f8\u5173\u4efb\u52a1\uff0c\u5c24\u5176\u5728\u60c5\u611f\u611f\u77e5\u548c\u5e94\u7528\u65b9\u9762\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "conclusion": "Multi - Bench\u53ef\u7528\u4e8e\u8bc4\u4f30SDMs\u5728\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u80fd\u529b\uff0c\u5f53\u524dSDMs\u5728\u9ad8\u7ea7\u4efb\u52a1\u5f85\u63d0\u5347\u3002"}}
{"id": "2511.00858", "pdf": "https://arxiv.org/pdf/2511.00858", "abs": "https://arxiv.org/abs/2511.00858", "authors": ["Yu Liu", "Zhijie Liu", "Zedong Yang", "You-Fu Li", "He Kong"], "title": "Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "This manuscript has been accepted to the IEEE Transactions on\n  Intelligent Transportation Systems as a regular paper", "summary": "Predicting pedestrian crossing intentions is crucial for the navigation of\nmobile robots and intelligent vehicles. Although recent deep learning-based\nmodels have shown significant success in forecasting intentions, few consider\nincomplete observation under occlusion scenarios. To tackle this challenge, we\npropose an Occlusion-Aware Diffusion Model (ODM) that reconstructs occluded\nmotion patterns and leverages them to guide future intention prediction. During\nthe denoising stage, we introduce an occlusion-aware diffusion transformer\narchitecture to estimate noise features associated with occluded patterns,\nthereby enhancing the model's ability to capture contextual relationships in\noccluded semantic scenarios. Furthermore, an occlusion mask-guided reverse\nprocess is introduced to effectively utilize observation information, reducing\nthe accumulation of prediction errors and enhancing the accuracy of\nreconstructed motion features. The performance of the proposed method under\nvarious occlusion scenarios is comprehensively evaluated and compared with\nexisting methods on popular benchmarks, namely PIE and JAAD. Extensive\nexperimental results demonstrate that the proposed method achieves more robust\nperformance than existing methods in the literature.", "AI": {"tldr": "\u63d0\u51fa\u906e\u6321\u611f\u77e5\u6269\u6563\u6a21\u578bODM\u9884\u6d4b\u884c\u4eba\u8fc7\u8857\u610f\u56fe\uff0c\u5728\u591a\u79cd\u906e\u6321\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u884c\u4eba\u8fc7\u8857\u610f\u56fe\u65f6\u5f88\u5c11\u8003\u8651\u906e\u6321\u573a\u666f\u4e0b\u7684\u4e0d\u5b8c\u6574\u89c2\u6d4b\u95ee\u9898\u3002", "method": "\u63d0\u51faODM\u6a21\u578b\uff0c\u5728\u53bb\u566a\u9636\u6bb5\u5f15\u5165\u906e\u6321\u611f\u77e5\u6269\u6563\u53d8\u538b\u5668\u67b6\u6784\u4f30\u8ba1\u4e0e\u906e\u6321\u6a21\u5f0f\u76f8\u5173\u7684\u566a\u58f0\u7279\u5f81\uff0c\u5f15\u5165\u906e\u6321\u63a9\u7801\u5f15\u5bfc\u7684\u53cd\u5411\u8fc7\u7a0b\u5229\u7528\u89c2\u6d4b\u4fe1\u606f\u3002", "result": "\u5728PIE\u548cJAAD\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u66f4\u7a33\u5065\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684ODM\u6a21\u578b\u80fd\u6709\u6548\u5904\u7406\u906e\u6321\u573a\u666f\u4e0b\u884c\u4eba\u8fc7\u8857\u610f\u56fe\u9884\u6d4b\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.00879", "pdf": "https://arxiv.org/pdf/2511.00879", "abs": "https://arxiv.org/abs/2511.00879", "authors": ["Hyeon Hwang", "Yewon Cho", "Chanwoong Yoon", "Yein Park", "Minju Song", "Kyungjae Lee", "Gangwoo Kim", "Jaewoo Kang"], "title": "Assessing LLM Reasoning Steps via Principal Knowledge Grounding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to EMNLP 2025 Findings", "summary": "Step-by-step reasoning has become a standard approach for large language\nmodels (LLMs) to tackle complex tasks. While this paradigm has proven\neffective, it raises a fundamental question: How can we verify that an LLM's\nreasoning is accurately grounded in knowledge? To address this question, we\nintroduce a novel evaluation suite that systematically assesses the knowledge\ngrounding of intermediate reasoning. Our framework comprises three key\ncomponents. (1) Principal Knowledge Collection, a large-scale repository of\natomic knowledge essential for reasoning. Based on the collection, we propose\n(2) knowledge-grounded evaluation metrics designed to measure how well models\nrecall and apply prerequisite knowledge in reasoning. These metrics are\ncomputed by our (3) evaluator LLM, a lightweight model optimized for\ncost-effective and reliable metric computation. Our evaluation suite\ndemonstrates remarkable effectiveness in identifying missing or misapplied\nknowledge elements, providing crucial insights for uncovering fundamental\nreasoning deficiencies in LLMs. Beyond evaluation, we demonstrate how these\nmetrics can be integrated into preference optimization, showcasing further\napplications of knowledge-grounded evaluation.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u9896\u8bc4\u4f30\u5957\u4ef6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u77e5\u8bc6\u57fa\u7840\uff0c\u8fd8\u5c55\u793a\u5176\u5728\u504f\u597d\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u5982\u4f55\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u662f\u5426\u51c6\u786e\u57fa\u4e8e\u77e5\u8bc6\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e3b\u8981\u77e5\u8bc6\u6536\u96c6\u3001\u77e5\u8bc6\u57fa\u7840\u8bc4\u4f30\u6307\u6807\u548c\u8bc4\u4f30\u5668\u5927\u8bed\u8a00\u6a21\u578b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u7684\u8bc4\u4f30\u5957\u4ef6\u3002", "result": "\u8bc4\u4f30\u5957\u4ef6\u80fd\u6709\u6548\u8bc6\u522b\u7f3a\u5931\u6216\u9519\u8bef\u5e94\u7528\u7684\u77e5\u8bc6\u5143\u7d20\u3002", "conclusion": "\u77e5\u8bc6\u57fa\u7840\u8bc4\u4f30\u4e0d\u4ec5\u53ef\u7528\u4e8e\u8bc4\u4f30\uff0c\u8fd8\u80fd\u96c6\u6210\u5230\u504f\u597d\u4f18\u5316\u4e2d\u3002"}}
{"id": "2511.00335", "pdf": "https://arxiv.org/pdf/2511.00335", "abs": "https://arxiv.org/abs/2511.00335", "authors": ["Weidong Zhang", "Pak Lun Kevin Ding", "Huan Liu"], "title": "Beyond ImageNet: Understanding Cross-Dataset Robustness of Lightweight Vision Models", "categories": ["cs.CV", "cs.LG"], "comment": "10 pages, 5 tables, 1 figure, 3 equations, 11 mobile models, 7\n  datasets", "summary": "Lightweight vision classification models such as MobileNet, ShuffleNet, and\nEfficientNet are increasingly deployed in mobile and embedded systems, yet\ntheir performance has been predominantly benchmarked on ImageNet. This raises\ncritical questions: Do models that excel on ImageNet also generalize across\nother domains? How can cross-dataset robustness be systematically quantified?\nAnd which architectural elements consistently drive generalization under tight\nresource constraints? Here, we present the first systematic evaluation of 11\nlightweight vision models (2.5M parameters), trained under a fixed 100-epoch\nschedule across 7 diverse datasets. We introduce the Cross-Dataset Score\n(xScore), a unified metric that quantifies the consistency and robustness of\nmodel performance across diverse visual domains. Our results show that (1)\nImageNet accuracy does not reliably predict performance on fine-grained or\nmedical datasets, (2) xScore provides a scalable predictor of mobile model\nperformance that can be estimated from just four datasets, and (3) certain\narchitectural components--such as isotropic convolutions with higher spatial\nresolution and channel-wise attention--promote broader generalization, while\nTransformer-based blocks yield little additional benefit, despite incurring\nhigher parameter overhead. This study provides a reproducible framework for\nevaluating lightweight vision models beyond ImageNet, highlights key design\nprinciples for mobile-friendly architectures, and guides the development of\nfuture models that generalize robustly across diverse application domains.", "AI": {"tldr": "\u5bf911\u4e2a\u8f7b\u91cf\u7ea7\u89c6\u89c9\u6a21\u578b\u57287\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5f15\u5165xScore\u6307\u6807\uff0c\u63ed\u793aImageNet\u51c6\u786e\u6027\u4e0d\u80fd\u53ef\u9760\u9884\u6d4b\u5176\u4ed6\u6570\u636e\u96c6\u8868\u73b0\u7b49\u7ed3\u679c\uff0c\u4e3a\u8bc4\u4f30\u6a21\u578b\u548c\u8bbe\u8ba1\u67b6\u6784\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u8f7b\u91cf\u7ea7\u89c6\u89c9\u6a21\u578b\u591a\u5728ImageNet\u4e0a\u8fdb\u884c\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9700\u63a2\u7a76\u5176\u5728\u5176\u4ed6\u9886\u57df\u7684\u6cdb\u5316\u6027\u3001\u5982\u4f55\u91cf\u5316\u8de8\u6570\u636e\u96c6\u9c81\u68d2\u6027\u4ee5\u53ca\u8d44\u6e90\u53d7\u9650\u4e0b\u54ea\u4e9b\u67b6\u6784\u5143\u7d20\u9a71\u52a8\u6cdb\u5316\u3002", "method": "\u5bf911\u4e2a\u8f7b\u91cf\u7ea7\u89c6\u89c9\u6a21\u578b\uff08250\u4e07\u4e2a\u53c2\u6570\uff09\u5728\u56fa\u5b9a100\u4e2a\u8bad\u7ec3\u5468\u671f\u4e0b\u4e8e7\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5f15\u5165Cross - Dataset Score (xScore)\u6307\u6807\u3002", "result": "1. ImageNet\u51c6\u786e\u6027\u4e0d\u80fd\u53ef\u9760\u9884\u6d4b\u7ec6\u7c92\u5ea6\u6216\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff1b2. xScore\u53ef\u4ece\u56db\u4e2a\u6570\u636e\u96c6\u4f30\u8ba1\uff0c\u662f\u79fb\u52a8\u6a21\u578b\u6027\u80fd\u7684\u53ef\u6269\u5c55\u9884\u6d4b\u6307\u6807\uff1b3. \u67d0\u4e9b\u67b6\u6784\u7ec4\u4ef6\u4fc3\u8fdb\u66f4\u5e7f\u6cdb\u6cdb\u5316\uff0cTransformer\u5757\u867d\u53c2\u6570\u5f00\u9500\u9ad8\u4f46\u989d\u5916\u6536\u76ca\u5c0f\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8bc4\u4f30\u8f7b\u91cf\u7ea7\u89c6\u89c9\u6a21\u578b\u63d0\u4f9b\u53ef\u590d\u73b0\u6846\u67b6\uff0c\u7a81\u51fa\u79fb\u52a8\u53cb\u597d\u67b6\u6784\u7684\u5173\u952e\u8bbe\u8ba1\u539f\u5219\uff0c\u6307\u5bfc\u672a\u6765\u8de8\u9886\u57df\u6cdb\u5316\u6a21\u578b\u7684\u5f00\u53d1\u3002"}}
{"id": "2511.00881", "pdf": "https://arxiv.org/pdf/2511.00881", "abs": "https://arxiv.org/abs/2511.00881", "authors": ["Simone Sarrocco", "Philippe C. Cattin", "Peter M. Maloca", "Paul Friedrich", "Philippe Valmaggia"], "title": "Deep Generative Models for Enhanced Vitreous OCT Imaging", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": null, "summary": "Purpose: To evaluate deep learning (DL) models for enhancing vitreous optical\ncoherence tomography (OCT) image quality and reducing acquisition time.\nMethods: Conditional Denoising Diffusion Probabilistic Models (cDDPMs),\nBrownian Bridge Diffusion Models (BBDMs), U-Net, Pix2Pix, and Vector-Quantised\nGenerative Adversarial Network (VQ-GAN) were used to generate high-quality\nspectral-domain (SD) vitreous OCT images. Inputs were SD ART10 images, and\noutputs were compared to pseudoART100 images obtained by averaging ten ART10\nimages per eye location. Model performance was assessed using image quality\nmetrics and Visual Turing Tests, where ophthalmologists ranked generated images\nand evaluated anatomical fidelity. The best model's performance was further\ntested within the manually segmented vitreous on newly acquired data. Results:\nU-Net achieved the highest Peak Signal-to-Noise Ratio (PSNR: 30.230) and\nStructural Similarity Index Measure (SSIM: 0.820), followed by cDDPM. For\nLearned Perceptual Image Patch Similarity (LPIPS), Pix2Pix (0.697) and cDDPM\n(0.753) performed best. In the first Visual Turing Test, cDDPM ranked highest\n(3.07); in the second (best model only), cDDPM achieved a 32.9% fool rate and\n85.7% anatomical preservation. On newly acquired data, cDDPM generated vitreous\nregions more similar in PSNR to the ART100 reference than true ART1 or ART10\nB-scans and achieved higher PSNR on whole images when conditioned on ART1 than\nART10. Conclusions: Results reveal discrepancies between quantitative metrics\nand clinical evaluation, highlighting the need for combined assessment. cDDPM\nshowed strong potential for generating clinically meaningful vitreous OCT\nimages while reducing acquisition time fourfold. Translational Relevance:\ncDDPMs show promise for clinical integration, supporting faster, higher-quality\nvitreous imaging. Dataset and code will be made publicly available.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u5347\u73bb\u7483\u4f53OCT\u56fe\u50cf\u8d28\u91cf\u548c\u51cf\u5c11\u91c7\u96c6\u65f6\u95f4\u7684\u6548\u679c\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u8868\u73b0\u6709\u5dee\u5f02\uff0ccDDPM\u6f5c\u529b\u5927\u3002", "motivation": "\u8bc4\u4f30\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u5347\u73bb\u7483\u4f53\u5149\u5b66\u76f8\u5e72\u65ad\u5c42\u626b\u63cf\uff08OCT\uff09\u56fe\u50cf\u8d28\u91cf\u548c\u51cf\u5c11\u91c7\u96c6\u65f6\u95f4\u3002", "method": "\u4f7f\u7528cDDPMs\u3001BBDMs\u3001U - Net\u7b49\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u5149\u8c31\u57df\uff08SD\uff09\u73bb\u7483\u4f53OCT\u56fe\u50cf\uff0c\u7528\u56fe\u50cf\u8d28\u91cf\u6307\u6807\u548c\u89c6\u89c9\u56fe\u7075\u6d4b\u8bd5\u8bc4\u4f30\uff0c\u5728\u65b0\u6570\u636e\u7684\u624b\u52a8\u5206\u5272\u73bb\u7483\u4f53\u533a\u57df\u6d4b\u8bd5\u6700\u4f73\u6a21\u578b\u3002", "result": "U - Net\u7684PSNR\u548cSSIM\u6700\u9ad8\uff0cPix2Pix\u548ccDDPM\u7684LPIPS\u8868\u73b0\u597d\uff0c\u89c6\u89c9\u56fe\u7075\u6d4b\u8bd5\u4e2dcDDPM\u8868\u73b0\u4f73\uff0c\u5728\u65b0\u6570\u636e\u4e0acDDPM\u751f\u6210\u56fe\u50cf\u66f4\u63a5\u8fd1\u53c2\u8003\u3002", "conclusion": "\u5b9a\u91cf\u6307\u6807\u548c\u4e34\u5e8a\u8bc4\u4f30\u6709\u5dee\u5f02\uff0c\u9700\u7efc\u5408\u8bc4\u4f30\uff0ccDDPM\u6709\u6f5c\u529b\u751f\u6210\u4e34\u5e8a\u6709\u610f\u4e49\u56fe\u50cf\u5e76\u51cf\u5c11\u56db\u5206\u4e4b\u4e09\u91c7\u96c6\u65f6\u95f4\uff0c\u6709\u671b\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2511.00894", "pdf": "https://arxiv.org/pdf/2511.00894", "abs": "https://arxiv.org/abs/2511.00894", "authors": ["Hasan Abdulla"], "title": "Android Malware Detection: A Machine Leaning Approach", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "This study examines machine learning techniques like Decision Trees, Support\nVector Machines, Logistic Regression, Neural Networks, and ensemble methods to\ndetect Android malware. The study evaluates these models on a dataset of\nAndroid applications and analyzes their accuracy, efficiency, and real-world\napplicability. Key findings show that ensemble methods demonstrate superior\nperformance, but there are trade-offs between model interpretability,\nefficiency, and accuracy. Given its increasing threat, the insights guide\nfuture research and practical use of ML to combat Android malware.", "AI": {"tldr": "\u7814\u7a76\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6280\u672f\u68c0\u6d4b\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\uff0c\u53d1\u73b0\u96c6\u6210\u65b9\u6cd5\u6027\u80fd\u4f18\u4f46\u6709\u53d6\u820d\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5e94\u5bf9\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u65e5\u76ca\u589e\u957f\u7684\u5a01\u80c1\uff0c\u7814\u7a76\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u68c0\u6d4b\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u3002", "method": "\u4f7f\u7528\u51b3\u7b56\u6811\u3001\u652f\u6301\u5411\u91cf\u673a\u3001\u903b\u8f91\u56de\u5f52\u3001\u795e\u7ecf\u7f51\u7edc\u548c\u96c6\u6210\u65b9\u6cd5\u7b49\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5728\u5b89\u5353\u5e94\u7528\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u96c6\u6210\u65b9\u6cd5\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4f46\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3001\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u5229\u7528\u673a\u5668\u5b66\u4e60\u5bf9\u6297\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u7684\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2511.00899", "pdf": "https://arxiv.org/pdf/2511.00899", "abs": "https://arxiv.org/abs/2511.00899", "authors": ["Junli Jiang", "Pavel Naumov", "Wenxuan Zhang"], "title": "Dynamic Logic of Trust-Based Beliefs", "categories": ["cs.LO", "cs.AI", "math.LO"], "comment": null, "summary": "Traditionally, an agent's beliefs would come from what the agent can see,\nhear, or sense. In the modern world, beliefs are often based on the data\navailable to the agents. In this work, we investigate a dynamic logic of such\nbeliefs that incorporates public announcements of data. The main technical\ncontribution is a sound and complete axiomatisation of the interplay between\ndata-informed beliefs and data announcement modalities. We also describe a\nnon-trivial polynomial model checking algorithm for this logical system.", "AI": {"tldr": "\u7814\u7a76\u5305\u542b\u6570\u636e\u516c\u5f00\u5ba3\u544a\u7684\u52a8\u6001\u4fe1\u5ff5\u903b\u8f91\uff0c\u7ed9\u51fa\u516c\u7406\u7cfb\u7edf\u548c\u6a21\u578b\u68c0\u67e5\u7b97\u6cd5\u3002", "motivation": "\u73b0\u4ee3\u4e16\u754c\u4e2d\u4e3b\u4f53\u4fe1\u5ff5\u5e38\u57fa\u4e8e\u53ef\u7528\u6570\u636e\uff0c\u7814\u7a76\u8fd9\u79cd\u5305\u542b\u6570\u636e\u516c\u5f00\u5ba3\u544a\u7684\u52a8\u6001\u4fe1\u5ff5\u903b\u8f91\u3002", "method": "\u5bf9\u516c\u7406\u5316\u7cfb\u7edf\u8fdb\u884c\u6784\u5efa\u548c\u8bc1\u660e\u5176\u53ef\u9760\u6027\u4e0e\u5b8c\u5907\u6027\uff0c\u8bbe\u8ba1\u6a21\u578b\u68c0\u67e5\u7b97\u6cd5\u3002", "result": "\u5f97\u5230\u6570\u636e\u4fe1\u606f\u4fe1\u5ff5\u548c\u6570\u636e\u5ba3\u544a\u6a21\u6001\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u7684\u53ef\u9760\u4e14\u5b8c\u5907\u7684\u516c\u7406\u5316\uff0c\u4ee5\u53ca\u8be5\u903b\u8f91\u7cfb\u7edf\u7684\u975e\u5e73\u51e1\u591a\u9879\u5f0f\u6a21\u578b\u68c0\u67e5\u7b97\u6cd5\u3002", "conclusion": "\u5b8c\u6210\u4e86\u5bf9\u5305\u542b\u6570\u636e\u516c\u5f00\u5ba3\u544a\u7684\u52a8\u6001\u4fe1\u5ff5\u903b\u8f91\u7684\u516c\u7406\u5316\u53ca\u7b97\u6cd5\u8bbe\u8ba1\u3002"}}
{"id": "2511.00345", "pdf": "https://arxiv.org/pdf/2511.00345", "abs": "https://arxiv.org/abs/2511.00345", "authors": ["Amir Ziashahabi", "Narges Ghasemi", "Sajjad Shahabi", "John Krumm", "Salman Avestimehr", "Cyrus Shahabi"], "title": "OSMGen: Highly Controllable Satellite Image Synthesis using OpenStreetMap Data", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at NeurIPS 2025 UrbanAI Workshop", "summary": "Accurate and up-to-date geospatial data are essential for urban planning,\ninfrastructure monitoring, and environmental management. Yet, automating urban\nmonitoring remains difficult because curated datasets of specific urban\nfeatures and their changes are scarce. We introduce OSMGen, a generative\nframework that creates realistic satellite imagery directly from raw\nOpenStreetMap (OSM) data. Unlike prior work that relies on raster tiles, OSMGen\nuses the full richness of OSM JSON, including vector geometries, semantic tags,\nlocation, and time, giving fine-grained control over how scenes are generated.\nA central feature of the framework is the ability to produce consistent\nbefore-after image pairs: user edits to OSM inputs translate into targeted\nvisual changes, while the rest of the scene is preserved. This makes it\npossible to generate training data that addresses scarcity and class imbalance,\nand to give planners a simple way to preview proposed interventions by editing\nmap data. More broadly, OSMGen produces paired (JSON, image) data for both\nstatic and changed states, paving the way toward a closed-loop system where\nsatellite imagery can automatically drive structured OSM updates. Source code\nis available at https://github.com/amir-zsh/OSMGen.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u751f\u6210\u6846\u67b6OSMGen\uff0c\u53ef\u4ece\u539f\u59cbOSM\u6570\u636e\u521b\u5efa\u903c\u771f\u536b\u661f\u56fe\u50cf\uff0c\u80fd\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u8fd8\u4e3a\u89c4\u5212\u8005\u63d0\u4f9b\u9884\u89c8\u5e72\u9884\u65b9\u6848\u7684\u65b9\u6cd5\u3002", "motivation": "\u51c6\u786e\u53ca\u65f6\u7684\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5bf9\u57ce\u5e02\u89c4\u5212\u7b49\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u57ce\u5e02\u76d1\u6d4b\u81ea\u52a8\u5316\u56e0\u7279\u5b9a\u57ce\u5e02\u7279\u5f81\u53ca\u53d8\u5316\u7684\u7b56\u5212\u6570\u636e\u96c6\u7a00\u7f3a\u800c\u56f0\u96be\u3002", "method": "\u5f15\u5165OSMGen\u6846\u67b6\uff0c\u5229\u7528OSM JSON\u7684\u4e30\u5bcc\u4fe1\u606f\u8fdb\u884c\u573a\u666f\u751f\u6210\uff0c\u80fd\u4ea7\u751f\u4e00\u81f4\u7684\u524d\u540e\u56fe\u50cf\u5bf9\u3002", "result": "\u53ef\u751f\u6210\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4e3a\u89c4\u5212\u8005\u63d0\u4f9b\u9884\u89c8\u5e72\u9884\u65b9\u6848\u7684\u7b80\u5355\u65b9\u6cd5\uff0c\u8fd8\u80fd\u4ea7\u751f\u914d\u5bf9\u6570\u636e\u63a8\u52a8\u536b\u661f\u56fe\u50cf\u81ea\u52a8\u66f4\u65b0OSM\u3002", "conclusion": "OSMGen\u4e3a\u57ce\u5e02\u76d1\u6d4b\u81ea\u52a8\u5316\u548cOSM\u66f4\u65b0\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2511.00917", "pdf": "https://arxiv.org/pdf/2511.00917", "abs": "https://arxiv.org/abs/2511.00917", "authors": ["Junyao Shi", "Rujia Yang", "Kaitian Chao", "Selina Bingqing Wan", "Yifei Shao", "Jiahui Lei", "Jianing Qian", "Long Le", "Pratik Chaudhari", "Kostas Daniilidis", "Chuan Wen", "Dinesh Jayaraman"], "title": "Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots", "categories": ["cs.RO", "cs.AI"], "comment": "Project website: https://maestro-robot.github.io", "summary": "Today's best-explored routes towards generalist robots center on collecting\never larger \"observations-in actions-out\" robotics datasets to train large\nend-to-end models, copying a recipe that has worked for vision-language models\n(VLMs). We pursue a road less traveled: building generalist policies directly\naround VLMs by augmenting their general capabilities with specific robot\ncapabilities encapsulated in a carefully curated set of perception, planning,\nand control modules. In Maestro, a VLM coding agent dynamically composes these\nmodules into a programmatic policy for the current task and scenario. Maestro's\narchitecture benefits from a streamlined closed-loop interface without many\nmanually imposed structural constraints, and a comprehensive and diverse tool\nrepertoire. As a result, it largely surpasses today's VLA models for zero-shot\nperformance on challenging manipulation skills. Further, Maestro is easily\nextensible to incorporate new modules, easily editable to suit new embodiments\nsuch as a quadruped-mounted arm, and even easily adapts from minimal real-world\nexperiences through local code edits.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faMaestro\u65b9\u6cd5\uff0c\u5229\u7528VLM\u6784\u5efa\u901a\u7528\u7b56\u7565\uff0c\u5728\u96f6\u6837\u672c\u6027\u80fd\u4e0a\u8d85\u8d8a\u73b0\u6709VLA\u6a21\u578b\uff0c\u4e14\u5177\u6709\u6613\u6269\u5c55\u3001\u6613\u7f16\u8f91\u548c\u6613\u9002\u5e94\u7b49\u4f18\u70b9\u3002", "motivation": "\u5f53\u524d\u901a\u7528\u673a\u5668\u4eba\u63a2\u7d22\u8def\u7ebf\u591a\u662f\u6536\u96c6\u5927\u6570\u636e\u96c6\u8bad\u7ec3\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u4f5c\u8005\u9009\u62e9\u53e6\u4e00\u6761\u8def\uff0c\u56f4\u7ed5VLM\u6784\u5efa\u901a\u7528\u7b56\u7565\u3002", "method": "\u6784\u5efaMaestro\uff0c\u8ba9VLM\u7f16\u7801\u4ee3\u7406\u5c06\u611f\u77e5\u3001\u89c4\u5212\u548c\u63a7\u5236\u6a21\u5757\u52a8\u6001\u7ec4\u5408\u6210\u5f53\u524d\u4efb\u52a1\u548c\u573a\u666f\u7684\u7a0b\u5e8f\u5316\u7b56\u7565\u3002", "result": "Maestro\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u64cd\u4f5c\u6280\u80fd\u96f6\u6837\u672c\u6027\u80fd\u4e0a\u8fdc\u8d85\u73b0\u6709VLA\u6a21\u578b\u3002", "conclusion": "Maestro\u67b6\u6784\u5177\u6709\u4f18\u52bf\uff0c\u4e14\u6613\u6269\u5c55\u3001\u7f16\u8f91\u548c\u9002\u5e94\u65b0\u60c5\u51b5\u3002"}}
{"id": "2511.00940", "pdf": "https://arxiv.org/pdf/2511.00940", "abs": "https://arxiv.org/abs/2511.00940", "authors": ["Zhe Li", "Xiang Bai", "Jieyu Zhang", "Zhuangzhe Wu", "Che Xu", "Ying Li", "Chengkai Hou", "Shanghang Zhang"], "title": "URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model", "categories": ["cs.RO", "cs.AI", "I.2.6"], "comment": "Accepted to the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025)", "summary": "Constructing accurate digital twins of articulated objects is essential for\nrobotic simulation training and embodied AI world model building, yet\nhistorically requires painstaking manual modeling or multi-stage pipelines. In\nthis work, we propose \\textbf{URDF-Anything}, an end-to-end automatic\nreconstruction framework based on a 3D multimodal large language model (MLLM).\nURDF-Anything utilizes an autoregressive prediction framework based on\npoint-cloud and text multimodal input to jointly optimize geometric\nsegmentation and kinematic parameter prediction. It implements a specialized\n$[SEG]$ token mechanism that interacts directly with point cloud features,\nenabling fine-grained part-level segmentation while maintaining consistency\nwith the kinematic parameter predictions. Experiments on both simulated and\nreal-world datasets demonstrate that our method significantly outperforms\nexisting approaches regarding geometric segmentation (mIoU 17\\% improvement),\nkinematic parameter prediction (average error reduction of 29\\%), and physical\nexecutability (surpassing baselines by 50\\%). Notably, our method exhibits\nexcellent generalization ability, performing well even on objects outside the\ntraining set. This work provides an efficient solution for constructing digital\ntwins for robotic simulation, significantly enhancing the sim-to-real transfer\ncapability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e3D\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u91cd\u5efa\u6846\u67b6URDF - Anything\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u673a\u5668\u4eba\u6a21\u62df\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u9ad8\u6548\u65b9\u6848\u3002", "motivation": "\u6784\u5efa\u7cbe\u786e\u7684\u94f0\u63a5\u7269\u4f53\u6570\u5b57\u5b6a\u751f\u5bf9\u673a\u5668\u4eba\u6a21\u62df\u8bad\u7ec3\u548c\u5177\u8eabAI\u4e16\u754c\u6a21\u578b\u6784\u5efa\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4ee5\u5f80\u9700\u624b\u52a8\u5efa\u6a21\u6216\u591a\u9636\u6bb5\u6d41\u7a0b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faURDF - Anything\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u70b9\u4e91\u548c\u6587\u672c\u591a\u6a21\u6001\u8f93\u5165\u7684\u81ea\u56de\u5f52\u9884\u6d4b\u6846\u67b6\u8054\u5408\u4f18\u5316\u51e0\u4f55\u5206\u5272\u548c\u8fd0\u52a8\u5b66\u53c2\u6570\u9884\u6d4b\uff0c\u5b9e\u73b0\u4e13\u95e8\u7684[SEG]\u4ee4\u724c\u673a\u5236\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u51e0\u4f55\u5206\u5272mIoU\u63d0\u534717%\uff0c\u8fd0\u52a8\u5b66\u53c2\u6570\u9884\u6d4b\u5e73\u5747\u8bef\u5dee\u964d\u4f4e29%\uff0c\u7269\u7406\u53ef\u6267\u884c\u6027\u8d85\u8fc7\u57fa\u7ebf50%\uff0c\u5bf9\u8bad\u7ec3\u96c6\u5916\u7269\u4f53\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u6a21\u62df\u6784\u5efa\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u4ece\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2511.00960", "pdf": "https://arxiv.org/pdf/2511.00960", "abs": "https://arxiv.org/abs/2511.00960", "authors": ["Abhinav P M", "Ojasva Saxena", "Oswald C", "Parameswari Krishnamurthy"], "title": "The Riddle of Reflection: Evaluating Reasoning and Self-Awareness in Multilingual LLMs using Indian Riddles", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The extent to which large language models (LLMs) can perform culturally\ngrounded reasoning across non-English languages remains underexplored. This\npaper examines the reasoning and self-assessment abilities of LLMs across seven\nmajor Indian languages-Bengali, Gujarati, Hindi, Kannada, Malayalam, Tamil, and\nTelugu. We introduce a multilingual riddle dataset combining traditional\nriddles with context-reconstructed variants and evaluate five LLMs-Gemini 2.5\nPro, Gemini 2.5 Flash, Mistral-Saba, LLaMA 4 Scout, and LLaMA 4 Maverick-under\nseven prompting strategies. In the first stage, we assess riddle-solving\nperformance and find that while Gemini 2.5 Pro performs best overall, few-shot\nmethods yield only marginal gains, and accuracy varies notably across\nlanguages. In the second stage, we conduct a self-evaluation experiment to\nmeasure reasoning consistency. The results reveal a key finding: a model's\ninitial accuracy is inversely correlated with its ability to identify its own\nmistakes. Top-performing models such as Gemini 2.5 Pro are overconfident (4.34%\nTrue Negative Rate), whereas lower-performing models like LLaMA 4 Scout are\nsubstantially more self-aware (42.09% True Negative Rate). These results point\nto clear gaps in multilingual reasoning and highlight the need for models that\nnot only reason effectively but also recognize their own limitations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e03\u79cd\u5370\u5ea6\u8bed\u8a00\u4e0a\u7684\u63a8\u7406\u548c\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\uff0c\u5f15\u5165\u591a\u8bed\u8a00\u8c1c\u9898\u6570\u636e\u96c6\u8bc4\u4f30\u4e94\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u521d\u59cb\u51c6\u786e\u7387\u4e0e\u81ea\u6211\u7ea0\u9519\u80fd\u529b\u8d1f\u76f8\u5173\uff0c\u6307\u51fa\u591a\u8bed\u8a00\u63a8\u7406\u5b58\u5728\u5dee\u8ddd\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e0a\u8fdb\u884c\u6587\u5316\u63a8\u7406\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u4e03\u79cd\u5370\u5ea6\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u5f15\u5165\u7ed3\u5408\u4f20\u7edf\u8c1c\u9898\u548c\u4e0a\u4e0b\u6587\u91cd\u6784\u53d8\u4f53\u7684\u591a\u8bed\u8a00\u8c1c\u9898\u6570\u636e\u96c6\uff0c\u7528\u4e03\u79cd\u63d0\u793a\u7b56\u7565\u8bc4\u4f30\u4e94\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u4e24\u9636\u6bb5\u8bc4\u4f30\u89e3\u8c1c\u8868\u73b0\u548c\u63a8\u7406\u4e00\u81f4\u6027\u3002", "result": "Gemini 2.5 Pro \u6574\u4f53\u8868\u73b0\u6700\u4f73\uff0c\u5c11\u6837\u672c\u65b9\u6cd5\u63d0\u5347\u6709\u9650\u4e14\u51c6\u786e\u7387\u56e0\u8bed\u8a00\u800c\u5f02\uff1b\u6a21\u578b\u521d\u59cb\u51c6\u786e\u7387\u4e0e\u81ea\u6211\u7ea0\u9519\u80fd\u529b\u8d1f\u76f8\u5173\uff0c\u5982 Gemini 2.5 Pro \u8fc7\u5ea6\u81ea\u4fe1\uff0cLLaMA 4 Scout \u66f4\u6709\u81ea\u77e5\u4e4b\u660e\u3002", "conclusion": "\u591a\u8bed\u8a00\u63a8\u7406\u5b58\u5728\u660e\u663e\u5dee\u8ddd\uff0c\u9700\u8981\u80fd\u6709\u6548\u63a8\u7406\u4e14\u8ba4\u8bc6\u81ea\u8eab\u5c40\u9650\u7684\u6a21\u578b\u3002"}}
{"id": "2511.00973", "pdf": "https://arxiv.org/pdf/2511.00973", "abs": "https://arxiv.org/abs/2511.00973", "authors": ["Ay\u015fe S. Okatan", "Mustafa \u0130lhan Akba\u015f", "Laxima Niure Kandel", "Berker Pek\u00f6z"], "title": "Keys in the Weights: Transformer Authentication Using Model-Bound Latent Representations", "categories": ["cs.CR", "cs.AI", "eess.SP", "68T07, 68P25, 94A60, 68Q32, 68Q87, 94A17, 68M12", "I.2.6; E.3; D.4.6; C.2.0; I.5.1; C.2.2; K.6.5; C.3"], "comment": "Cite as A. S. Okatan, M. I. Akbas, L. N. Kandel, and B. Pekoz, \"Keys\n  in the weights: Transformer authentication using model-bound latent\n  representations,\" in Proc. 2025 Cyber Awareness and Research Symp. (IEEE CARS\n  2025), Grand Forks, ND, Oct. 2025, pp. 6", "summary": "We introduce Model-Bound Latent Exchange (MoBLE), a decoder-binding property\nin Transformer autoencoders formalized as Zero-Shot Decoder Non-Transferability\n(ZSDN). In identity tasks using iso-architectural models trained on identical\ndata but differing in seeds, self-decoding achieves more than 0.91 exact match\nand 0.98 token accuracy, while zero-shot cross-decoding collapses to chance\nwithout exact matches. This separation arises without injected secrets or\nadversarial training, and is corroborated by weight-space distances and\nattention-divergence diagnostics. We interpret ZSDN as model binding, a\nlatent-based authentication and access-control mechanism, even when the\narchitecture and training recipe are public: encoder's hidden state\nrepresentation deterministically reveals the plaintext, yet only the correctly\nkeyed decoder reproduces it in zero-shot. We formally define ZSDN, a\ndecoder-binding advantage metric, and outline deployment considerations for\nsecure artificial intelligence (AI) pipelines. Finally, we discuss learnability\nrisks (e.g., adapter alignment) and outline mitigations. MoBLE offers a\nlightweight, accelerator-friendly approach to secure AI deployment in\nsafety-critical domains, including aviation and cyber-physical systems.", "AI": {"tldr": "\u63d0\u51faMoBLE\uff0c\u5176\u6709ZSDN\u7279\u6027\uff0c\u5728\u8eab\u4efd\u4efb\u52a1\u4e2d\u6709\u826f\u597d\u8868\u73b0\uff0c\u53ef\u4f5c\u4e3a\u8ba4\u8bc1\u548c\u8bbf\u95ee\u63a7\u5236\u673a\u5236\uff0c\u4ecb\u7ecd\u4e86\u76f8\u5173\u5b9a\u4e49\u3001\u90e8\u7f72\u8003\u8651\u3001\u98ce\u9669\u53ca\u7f13\u89e3\u63aa\u65bd\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u5173\u952e\u9886\u57df\u3002", "motivation": "\u4e3a\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u4eba\u5de5\u667a\u80fd\u7ba1\u9053\u63d0\u4f9b\u5b89\u5168\u7684\u90e8\u7f72\u65b9\u6cd5\u3002", "method": "\u5f15\u5165Model - Bound Latent Exchange (MoBLE)\uff0c\u5b9a\u4e49Zero - Shot Decoder Non - Transferability (ZSDN)\uff0c\u901a\u8fc7\u8eab\u4efd\u4efb\u52a1\u5b9e\u9a8c\uff0c\u7ed3\u5408\u6743\u91cd\u7a7a\u95f4\u8ddd\u79bb\u548c\u6ce8\u610f\u529b\u53d1\u6563\u8bca\u65ad\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5728\u8eab\u4efd\u4efb\u52a1\u4e2d\uff0c\u81ea\u89e3\u7801\u6709\u9ad8\u51c6\u786e\u7387\uff0c\u96f6\u6837\u672c\u4ea4\u53c9\u89e3\u7801\u6548\u679c\u5dee\uff0c\u5206\u79bb\u6548\u679c\u65e0\u9700\u6ce8\u5165\u79d8\u5bc6\u6216\u5bf9\u6297\u8bad\u7ec3\uff0cZSDN\u53ef\u4f5c\u4e3a\u57fa\u4e8e\u6f5c\u5728\u7684\u8ba4\u8bc1\u548c\u8bbf\u95ee\u63a7\u5236\u673a\u5236\u3002", "conclusion": "MoBLE\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u9002\u5408\u52a0\u901f\u5668\u7684\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u5b89\u5168AI\u90e8\u7f72\u3002"}}
{"id": "2511.00446", "pdf": "https://arxiv.org/pdf/2511.00446", "abs": "https://arxiv.org/abs/2511.00446", "authors": ["Xin Yao", "Haiyang Zhao", "Yimin Chen", "Jiawei Guo", "Kecheng Huang", "Ming Zhao"], "title": "ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": "Accepted by NeurIPS 2025", "summary": "The Contrastive Language-Image Pretraining (CLIP) model has significantly\nadvanced vision-language modeling by aligning image-text pairs from large-scale\nweb data through self-supervised contrastive learning. Yet, its reliance on\nuncurated Internet-sourced data exposes it to data poisoning and backdoor\nrisks. While existing studies primarily investigate image-based attacks, the\ntext modality, which is equally central to CLIP's training, remains\nunderexplored. In this work, we introduce ToxicTextCLIP, a framework for\ngenerating high-quality adversarial texts that target CLIP during the\npre-training phase. The framework addresses two key challenges: semantic\nmisalignment caused by background inconsistency with the target class, and the\nscarcity of background-consistent texts. To this end, ToxicTextCLIP iteratively\napplies: 1) a background-aware selector that prioritizes texts with background\ncontent aligned to the target class, and 2) a background-driven augmenter that\ngenerates semantically coherent and diverse poisoned samples. Extensive\nexperiments on classification and retrieval tasks show that ToxicTextCLIP\nachieves up to 95.83% poisoning success and 98.68% backdoor Hit@1, while\nbypassing RoCLIP, CleanCLIP and SafeCLIP defenses. The source code can be\naccessed via https://github.com/xinyaocse/ToxicTextCLIP/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faToxicTextCLIP\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u751f\u6210\u9488\u5bf9CLIP\u7684\u5bf9\u6297\u6027\u6587\u672c\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6709\u9ad8\u4e2d\u6bd2\u6210\u529f\u7387\u548c\u540e\u95e8\u547d\u4e2d\u7387\uff0c\u8fd8\u80fd\u7ed5\u8fc7\u591a\u79cd\u9632\u5fa1\u3002", "motivation": "CLIP\u4f9d\u8d56\u672a\u7b5b\u9009\u7684\u7f51\u7edc\u6570\u636e\uff0c\u5b58\u5728\u6570\u636e\u4e2d\u6bd2\u548c\u540e\u95e8\u98ce\u9669\uff0c\u4e14\u73b0\u6709\u7814\u7a76\u5bf9\u6587\u672c\u6a21\u6001\u653b\u51fb\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "ToxicTextCLIP\u6846\u67b6\u8fed\u4ee3\u5e94\u7528\u80cc\u666f\u611f\u77e5\u9009\u62e9\u5668\u548c\u80cc\u666f\u9a71\u52a8\u589e\u5f3a\u5668\uff0c\u89e3\u51b3\u8bed\u4e49\u4e0d\u4e00\u81f4\u548c\u80cc\u666f\u4e00\u81f4\u6587\u672c\u7a00\u7f3a\u95ee\u9898\u3002", "result": "\u5728\u5206\u7c7b\u548c\u68c0\u7d22\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cToxicTextCLIP\u4e2d\u6bd2\u6210\u529f\u7387\u8fbe95.83%\uff0c\u540e\u95e8Hit@1\u8fbe98.68%\uff0c\u80fd\u7ed5\u8fc7RoCLIP\u3001CleanCLIP\u548cSafeCLIP\u9632\u5fa1\u3002", "conclusion": "ToxicTextCLIP\u6846\u67b6\u80fd\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u5bf9\u6297\u6027\u6587\u672c\uff0c\u5bf9CLIP\u9020\u6210\u5a01\u80c1\u3002"}}
{"id": "2511.00449", "pdf": "https://arxiv.org/pdf/2511.00449", "abs": "https://arxiv.org/abs/2511.00449", "authors": ["Xiaolong Li", "Zhi-Qin John Xu", "Yan Ren", "Tianming Qiu", "Xiaowen Wang"], "title": "Towards Reliable Pediatric Brain Tumor Segmentation: Task-Specific nnU-Net Enhancements", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Accurate segmentation of pediatric brain tumors in multi-parametric magnetic\nresonance imaging (mpMRI) is critical for diagnosis, treatment planning, and\nmonitoring, yet faces unique challenges due to limited data, high anatomical\nvariability, and heterogeneous imaging across institutions. In this work, we\npresent an advanced nnU-Net framework tailored for BraTS 2025 Task-6 (PED), the\nlargest public dataset of pre-treatment pediatric high-grade gliomas. Our\ncontributions include: (1) a widened residual encoder with\nsqueeze-and-excitation (SE) attention; (2) 3D depthwise separable convolutions;\n(3) a specificity-driven regularization term; and (4) small-scale Gaussian\nweight initialization. We further refine predictions with two postprocessing\nsteps. Our models achieved first place on the Task-6 validation leaderboard,\nattaining lesion-wise Dice scores of 0.759 (CC), 0.967 (ED), 0.826 (ET), 0.910\n(NET), 0.928 (TC) and 0.928 (WT).", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8eBraTS 2025 Task - 6 (PED)\u7684\u9ad8\u7ea7nnU - Net\u6846\u67b6\u7528\u4e8e\u513f\u79d1\u8111\u80bf\u7624\u5206\u5272\uff0c\u6a21\u578b\u5728\u9a8c\u8bc1\u6392\u884c\u699c\u83b7\u7b2c\u4e00\u540d\u3002", "motivation": "\u513f\u79d1\u8111\u80bf\u7624\u5728\u591a\u53c2\u6570\u78c1\u5171\u632f\u6210\u50cf\u4e2d\u51c6\u786e\u5206\u5272\u5bf9\u8bca\u65ad\u3001\u6cbb\u7597\u89c4\u5212\u548c\u76d1\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u6570\u636e\u6709\u9650\u3001\u89e3\u5256\u53d8\u5f02\u6027\u9ad8\u548c\u673a\u6784\u95f4\u6210\u50cf\u5f02\u8d28\u6027\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u9ad8\u7ea7nnU - Net\u6846\u67b6\uff0c\u5305\u62ec\u5e26\u6324\u538b\u548c\u6fc0\u52b1\u6ce8\u610f\u529b\u7684\u52a0\u5bbd\u6b8b\u5dee\u7f16\u7801\u5668\u30013D\u6df1\u5ea6\u53ef\u5206\u79bb\u5377\u79ef\u3001\u7279\u5f02\u6027\u9a71\u52a8\u7684\u6b63\u5219\u5316\u9879\u548c\u5c0f\u5c3a\u5ea6\u9ad8\u65af\u6743\u91cd\u521d\u59cb\u5316\uff0c\u8fd8\u6709\u4e24\u6b65\u540e\u5904\u7406\u3002", "result": "\u6a21\u578b\u5728Task - 6\u9a8c\u8bc1\u6392\u884c\u699c\u83b7\u7b2c\u4e00\u540d\uff0c\u53d6\u5f97\u591a\u4e2a\u75c5\u53d8\u7684Dice\u5206\u6570\uff0c\u5982CC\u4e3a0.759\u7b49\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9ad8\u7ea7nnU - Net\u6846\u67b6\u5728\u513f\u79d1\u8111\u80bf\u7624\u5206\u5272\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u76f8\u5173\u6311\u6218\u3002"}}
{"id": "2511.01023", "pdf": "https://arxiv.org/pdf/2511.01023", "abs": "https://arxiv.org/abs/2511.01023", "authors": ["Ay\u015fe Selin Okatan", "Mustafa \u0130lhan Akba\u015f", "Laxima Niure Kandel", "Berker Pek\u00f6z"], "title": "Seed-Induced Uniqueness in Transformer Models: Subspace Alignment Governs Subliminal Transfer", "categories": ["eess.SP", "cs.AI", "cs.CR", "cs.LG", "68T07, 68P25, 94A60, 68Q32, 68Q87, 94A17", "I.2.6; C.2.0; D.4.6; E.3; I.5.1; K.6.5"], "comment": "Cite as A. S. Okatan, M. I. Akba\\c{s}, L. N. Kandel, and B. Pek\\\"oz,\n  \"Seed-Induced Uniqueness in Transformer Models: Subspace Alignment Governs\n  Subliminal Transfer,\" in Proc. 2025 Cyber Awareness and Research Symp. (IEEE\n  CARS 2025), Grand Forks, ND, Oct. 2025, pp. 6", "summary": "We analyze subliminal transfer in Transformer models, where a teacher embeds\nhidden traits that can be linearly decoded by a student without degrading\nmain-task performance. Prior work often attributes transferability to global\nrepresentational similarity, typically quantified with Centered Kernel\nAlignment (CKA). Using synthetic corpora with disentangled public and private\nlabels, we distill students under matched and independent random\ninitializations. We find that transfer strength hinges on alignment within a\ntrait-discriminative subspace: same-seed students inherit this alignment and\nshow higher leakage {\\tau \\approx} 0.24, whereas different-seed\nstudents--despite global CKA > 0.9--exhibit substantially reduced excess\naccuracy {\\tau \\approx} 0.12 - 0.13. We formalize this with subspace-level CKA\ndiagnostic and residualized probes, showing that leakage tracks alignment\nwithin the trait-discriminative subspace rather than global representational\nsimilarity. Security controls (projection penalty, adversarial reversal,\nright-for-the-wrong-reasons regularization) reduce leakage in same-base models\nwithout impairing public-task fidelity. These results establish seed-induced\nuniqueness as a resilience property and argue for subspace-aware diagnostics\nfor secure multi-model deployments.", "AI": {"tldr": "\u5206\u6790Transformer\u6a21\u578b\u4e2d\u7684\u6f5c\u610f\u8bc6\u8f6c\u79fb\uff0c\u53d1\u73b0\u8f6c\u79fb\u5f3a\u5ea6\u53d6\u51b3\u4e8e\u7279\u5f81\u5224\u522b\u5b50\u7a7a\u95f4\u7684\u5bf9\u9f50\uff0c\u63d0\u51fa\u5b50\u7a7a\u95f4\u8bca\u65ad\u65b9\u6cd5\u53ca\u5b89\u5168\u63a7\u5236\u63aa\u65bd\u3002", "motivation": "\u7814\u7a76Transformer\u6a21\u578b\u4e2d\u6f5c\u610f\u8bc6\u8f6c\u79fb\u73b0\u8c61\uff0c\u63a2\u7a76\u8f6c\u79fb\u80fd\u529b\u7684\u5f71\u54cd\u56e0\u7d20\u53ca\u5982\u4f55\u4fdd\u969c\u591a\u6a21\u578b\u90e8\u7f72\u5b89\u5168\u3002", "method": "\u4f7f\u7528\u5408\u6210\u8bed\u6599\uff0c\u5728\u5339\u914d\u548c\u72ec\u7acb\u968f\u673a\u521d\u59cb\u5316\u4e0b\u84b8\u998f\u5b66\u751f\u6a21\u578b\uff0c\u91c7\u7528\u5b50\u7a7a\u95f4\u7ea7CKA\u8bca\u65ad\u548c\u6b8b\u5dee\u63a2\u9488\u3002", "result": "\u76f8\u540c\u79cd\u5b50\u5b66\u751f\u6a21\u578b\u8f6c\u79fb\u5f3a\u5ea6\u9ad8\uff0c\u4e0d\u540c\u79cd\u5b50\u5b66\u751f\u6a21\u578b\u8f6c\u79fb\u5f3a\u5ea6\u4f4e\uff1b\u5b89\u5168\u63a7\u5236\u63aa\u65bd\u53ef\u51cf\u5c11\u6cc4\u6f0f\u4e14\u4e0d\u5f71\u54cd\u516c\u5171\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u79cd\u5b50\u8bf1\u5bfc\u7684\u552f\u4e00\u6027\u662f\u4e00\u79cd\u5f39\u6027\u5c5e\u6027\uff0c\u5e94\u91c7\u7528\u5b50\u7a7a\u95f4\u611f\u77e5\u8bca\u65ad\u8fdb\u884c\u5b89\u5168\u7684\u591a\u6a21\u578b\u90e8\u7f72\u3002"}}
{"id": "2511.00480", "pdf": "https://arxiv.org/pdf/2511.00480", "abs": "https://arxiv.org/abs/2511.00480", "authors": ["Weihao Bo", "Yanpeng Sun", "Yu Wang", "Xinyu Zhang", "Zechao Li"], "title": "FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this paper, we introduce FedMGP, a new paradigm for personalized federated\nprompt learning in vision-language models. FedMGP equips each client with\nmultiple groups of paired textual and visual prompts, enabling the model to\ncapture diverse, fine-grained semantic and instance-level cues. A diversity\nloss is introduced to drive each prompt group to specialize in distinct and\ncomplementary semantic aspects, ensuring that the groups collectively cover a\nbroader range of local characteristics. During communication, FedMGP employs a\ndynamic prompt aggregation strategy based on similarity-guided probabilistic\nsampling: each client computes the cosine similarity between its prompt groups\nand the global prompts from the previous round, then samples s groups via a\nsoftmax-weighted distribution. This soft selection mechanism preferentially\naggregates semantically aligned knowledge while still enabling exploration of\nunderrepresented patterns effectively balancing the preservation of common\nknowledge with client-specific features. Notably, FedMGP maintains parameter\nefficiency by redistributing a fixed prompt capacity across multiple groups,\nachieving state-of-the-art performance with the lowest communication parameters\namong all federated prompt learning methods. Theoretical analysis shows that\nour dynamic aggregation strategy promotes robust global representation learning\nby reinforcing shared semantics while suppressing client-specific noise.\nExtensive experiments demonstrate that FedMGP consistently outperforms prior\napproaches in both personalization and domain generalization across diverse\nfederated vision-language benchmarks. The code will be released on\nhttps://github.com/weihao-bo/FedMGP.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedMGP\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e2a\u6027\u5316\u8054\u90a6\u63d0\u793a\u5b66\u4e60\uff0c\u91c7\u7528\u591a\u7ec4\u63d0\u793a\u3001\u591a\u6837\u6027\u635f\u5931\u548c\u52a8\u6001\u63d0\u793a\u805a\u5408\u7b56\u7565\uff0c\u53c2\u6570\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u4e2a\u6027\u5316\u548c\u9886\u57df\u6cdb\u5316\u95ee\u9898\uff0c\u6709\u6548\u805a\u5408\u77e5\u8bc6\u5e76\u4fdd\u7559\u5ba2\u6237\u7aef\u7279\u5f81\u3002", "method": "\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u914d\u5907\u591a\u7ec4\u6587\u672c\u548c\u89c6\u89c9\u63d0\u793a\uff0c\u5f15\u5165\u591a\u6837\u6027\u635f\u5931\uff0c\u91c7\u7528\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u5f15\u5bfc\u6982\u7387\u91c7\u6837\u7684\u52a8\u6001\u63d0\u793a\u805a\u5408\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u8054\u90a6\u89c6\u89c9\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFedMGP\u5728\u4e2a\u6027\u5316\u548c\u9886\u57df\u6cdb\u5316\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u4e14\u901a\u4fe1\u53c2\u6570\u6700\u5c11\u3002", "conclusion": "FedMGP\u7684\u52a8\u6001\u805a\u5408\u7b56\u7565\u80fd\u4fc3\u8fdb\u9c81\u68d2\u7684\u5168\u5c40\u8868\u793a\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u548c\u53c2\u6570\u6548\u7387\u7684\u5e73\u8861\u3002"}}
{"id": "2511.00537", "pdf": "https://arxiv.org/pdf/2511.00537", "abs": "https://arxiv.org/abs/2511.00537", "authors": ["Peter Atandoh", "Jie Zou", "Weikang Guo", "Jiwei Wei", "Zheng Wang"], "title": "Multi-refined Feature Enhanced Sentiment Analysis Using Contextual Instruction", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Sentiment analysis using deep learning and pre-trained language models (PLMs)\nhas gained significant traction due to their ability to capture rich contextual\nrepresentations. However, existing approaches often underperform in scenarios\ninvolving nuanced emotional cues, domain shifts, and imbalanced sentiment\ndistributions. We argue that these limitations stem from inadequate semantic\ngrounding, poor generalization to diverse linguistic patterns, and biases\ntoward dominant sentiment classes. To overcome these challenges, we propose\nCISEA-MRFE, a novel PLM-based framework integrating Contextual Instruction\n(CI), Semantic Enhancement Augmentation (SEA), and Multi-Refined Feature\nExtraction (MRFE). CI injects domain-aware directives to guide sentiment\ndisambiguation; SEA improves robustness through sentiment-consistent\nparaphrastic augmentation; and MRFE combines a Scale-Adaptive Depthwise Encoder\n(SADE) for multi-scale feature specialization with an Emotion Evaluator Context\nEncoder (EECE) for affect-aware sequence modeling. Experimental results on four\nbenchmark datasets demonstrate that CISEA-MRFE consistently outperforms strong\nbaselines, achieving relative improvements in accuracy of up to 4.6% on IMDb,\n6.5% on Yelp, 30.3% on Twitter, and 4.1% on Amazon. These results validate the\neffectiveness and generalization ability of our approach for sentiment\nclassification across varied domains.", "AI": {"tldr": "\u63d0\u51faCISEA - MRFE\u6846\u67b6\u89e3\u51b3\u73b0\u6709\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u4e0d\u8db3\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u548c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u5728\u5904\u7406\u7ec6\u5fae\u60c5\u611f\u7ebf\u7d22\u3001\u9886\u57df\u8f6c\u79fb\u548c\u60c5\u611f\u5206\u5e03\u4e0d\u5e73\u8861\u7b49\u573a\u666f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u539f\u56e0\u5728\u4e8e\u8bed\u4e49\u57fa\u7840\u4e0d\u8db3\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u5b58\u5728\u60c5\u611f\u7c7b\u522b\u504f\u5dee\u3002", "method": "\u63d0\u51faCISEA - MRFE\u6846\u67b6\uff0c\u96c6\u6210\u4e0a\u4e0b\u6587\u6307\u4ee4\uff08CI\uff09\u3001\u8bed\u4e49\u589e\u5f3a\u6269\u5145\uff08SEA\uff09\u548c\u591a\u7cbe\u70bc\u7279\u5f81\u63d0\u53d6\uff08MRFE\uff09\uff0c\u5404\u90e8\u5206\u6709\u5177\u4f53\u4f5c\u7528\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cCISEA - MRFE\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5728IMDb\u3001Yelp\u3001Twitter\u548cAmazon\u4e0a\u51c6\u786e\u7387\u5206\u522b\u76f8\u5bf9\u63d0\u53474.6%\u30016.5%\u300130.3%\u548c4.1%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u9886\u57df\u7684\u60c5\u611f\u5206\u7c7b\u4e2d\u6709\u6548\u4e14\u5177\u6709\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.01082", "pdf": "https://arxiv.org/pdf/2511.01082", "abs": "https://arxiv.org/abs/2511.01082", "authors": ["Narges Ghasemi", "Amir Ziashahabi", "Salman Avestimehr", "Cyrus Shahabi"], "title": "GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to IEEE International Conference on Data Mining (ICDM) 2025", "summary": "Image geolocalization, the task of determining an image's geographic origin,\nposes significant challenges, largely due to visual similarities across\ndisparate locations and the large search space. To address these issues, we\npropose a hierarchical sequence prediction approach inspired by how humans\nnarrow down locations from broad regions to specific addresses. Analogously,\nour model predicts geographic tokens hierarchically, first identifying a\ngeneral region and then sequentially refining predictions to increasingly\nprecise locations. Rather than relying on explicit semantic partitions, our\nmethod uses S2 cells, a nested, multiresolution global grid, and sequentially\npredicts finer-level cells conditioned on visual inputs and previous\npredictions. This procedure mirrors autoregressive text generation in large\nlanguage models. Much like in language modeling, final performance depends not\nonly on training but also on inference-time strategy. We investigate multiple\ntop-down traversal methods for autoregressive sampling, incorporating\ntechniques from test-time compute scaling used in language models.\nSpecifically, we integrate beam search and multi-sample inference while\nexploring various selection strategies to determine the final output. This\nenables the model to manage uncertainty by exploring multiple plausible paths\nthrough the hierarchy. We evaluate our method on the Im2GPS3k and YFCC4k\ndatasets against two distinct sets of baselines: those that operate without a\nMultimodal Large Language Model (MLLM) and those that leverage one. In the\nMLLM-free setting, our model surpasses other comparable baselines on nearly all\nmetrics, achieving state-of-the-art performance with accuracy gains of up to\n13.9%. When augmented with an MLLM, our model outperforms all baselines,\nsetting a new state-of-the-art across all metrics. The source code is available\nat https://github.com/NNargesNN/GeoToken.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u89e3\u51b3\u56fe\u50cf\u5730\u7406\u5b9a\u4f4d\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u89e3\u51b3\u56fe\u50cf\u5730\u7406\u5b9a\u4f4d\u4e2d\u56e0\u89c6\u89c9\u76f8\u4f3c\u548c\u641c\u7d22\u7a7a\u95f4\u5927\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff0c\u7528S2\u5355\u5143\u683c\uff0c\u501f\u9274\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u56de\u5f52\u6587\u672c\u751f\u6210\uff0c\u7814\u7a76\u591a\u79cd\u81ea\u56de\u5f52\u91c7\u6837\u7684\u81ea\u4e0a\u800c\u4e0b\u904d\u5386\u65b9\u6cd5\u3002", "result": "\u5728Im2GPS3k\u548cYFCC4k\u6570\u636e\u96c6\u4e0a\uff0c\u65e0MLLM\u65f6\u8d85\u8d8a\u591a\u6570\u57fa\u7ebf\uff0c\u6709MLLM\u65f6\u8d85\u8d8a\u6240\u6709\u57fa\u7ebf\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u56fe\u50cf\u5730\u7406\u5b9a\u4f4d\u95ee\u9898\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u3002"}}
{"id": "2511.01087", "pdf": "https://arxiv.org/pdf/2511.01087", "abs": "https://arxiv.org/abs/2511.01087", "authors": ["Md. Abid Hasan Rafi", "Mst. Fatematuj Johora", "Pankaj Bhowmik"], "title": "SliceVision-F2I: A Synthetic Feature-to-Image Dataset for Visual Pattern Representation on Network Slices", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of 5G and 6G networks has established network slicing as a\nsignificant part of future service-oriented architectures, demanding refined\nidentification methods supported by robust datasets. The article presents\nSliceVision-F2I, a dataset of synthetic samples for studying feature\nvisualization in network slicing for next-generation networking systems. The\ndataset transforms multivariate Key Performance Indicator (KPI) vectors into\nvisual representations through four distinct encoding methods: physically\ninspired mappings, Perlin noise, neural wallpapering, and fractal branching.\nFor each encoding method, 30,000 samples are generated, each comprising a raw\nKPI vector and a corresponding RGB image at low-resolution pixels. The dataset\nsimulates realistic and noisy network conditions to reflect operational\nuncertainties and measurement imperfections. SliceVision-F2I is suitable for\ntasks involving visual learning, network state classification, anomaly\ndetection, and benchmarking of image-based machine learning techniques applied\nto network data. The dataset is publicly available and can be reused in various\nresearch contexts, including multivariate time series analysis, synthetic data\ngeneration, and feature-to-image transformations.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u7528\u4e8e\u4e0b\u4e00\u4ee3\u7f51\u7edc\u7cfb\u7edf\u7f51\u7edc\u5207\u7247\u7279\u5f81\u53ef\u89c6\u5316\u7814\u7a76\u7684\u6570\u636e\u96c6SliceVision - F2I\uff0c\u4ecb\u7ecd\u751f\u6210\u65b9\u6cd5\u3001\u7279\u70b9\u53ca\u9002\u7528\u4efb\u52a1\uff0c\u4e14\u6570\u636e\u96c6\u516c\u5f00\u53ef\u590d\u7528\u3002", "motivation": "5G\u548c6G\u7f51\u7edc\u4f7f\u7f51\u7edc\u5207\u7247\u6210\u4e3a\u672a\u6765\u9762\u5411\u670d\u52a1\u67b6\u6784\u91cd\u8981\u90e8\u5206\uff0c\u9700\u8981\u5b8c\u5584\u7684\u8bc6\u522b\u65b9\u6cd5\u548c\u5f3a\u5927\u6570\u636e\u96c6\u652f\u6301\u3002", "method": "\u901a\u8fc7\u7269\u7406\u542f\u53d1\u6620\u5c04\u3001Perlin\u566a\u58f0\u3001\u795e\u7ecf\u58c1\u7eb8\u548c\u5206\u5f62\u5206\u652f\u56db\u79cd\u7f16\u7801\u65b9\u6cd5\uff0c\u5c06\u591a\u5143\u5173\u952e\u6027\u80fd\u6307\u6807\uff08KPI\uff09\u5411\u91cf\u8f6c\u6362\u4e3a\u53ef\u89c6\u5316\u8868\u793a\uff0c\u6bcf\u79cd\u65b9\u6cd5\u751f\u621030000\u4e2a\u6837\u672c\u3002", "result": "\u751f\u6210\u5305\u542b\u539f\u59cbKPI\u5411\u91cf\u548c\u4f4e\u5206\u8fa8\u7387RGB\u56fe\u50cf\u7684\u6570\u636e\u96c6\uff0c\u6a21\u62df\u4e86\u771f\u5b9e\u6709\u566a\u58f0\u7684\u7f51\u7edc\u6761\u4ef6\u3002", "conclusion": "SliceVision - F2I\u9002\u7528\u4e8e\u591a\u79cd\u7f51\u7edc\u4efb\u52a1\uff0c\u53ef\u516c\u5f00\u590d\u7528\uff0c\u7528\u4e8e\u591a\u4e2a\u7814\u7a76\u9886\u57df\u3002"}}
{"id": "2511.01139", "pdf": "https://arxiv.org/pdf/2511.01139", "abs": "https://arxiv.org/abs/2511.01139", "authors": ["Yoshihiro Maruyama"], "title": "Learning with Category-Equivariant Architectures for Human Activity Recognition", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "We propose CatEquiv, a category-equivariant neural network for Human Activity\nRecognition (HAR) from inertial sensors that systematically encodes temporal,\namplitude, and structural symmetries. In particular, we introduce the\ncategorical symmetry product where cyclic time shifts, positive gains and the\nsensor-hierarchy poset together capture the categorical symmetry structure of\nthe data. CatEquiv achieves equivariance with respect to the categorical\nsymmetry product. On UCI-HAR under out-of-distribution perturbations, CatEquiv\nattains markedly higher robustness compared with circularly padded CNNs and\nplain CNNs. These results demonstrate that enforcing categorical symmetries\nyields strong invariance and generalization without additional model capacity.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u7684CatEquiv\u7f51\u7edc\uff0c\u7f16\u7801\u591a\u79cd\u5bf9\u79f0\u6027\uff0c\u5728UCI - HAR\u4e0a\u5c55\u73b0\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u4e2d\u5982\u4f55\u7cfb\u7edf\u7f16\u7801\u65f6\u95f4\u3001\u5e45\u5ea6\u548c\u7ed3\u6784\u5bf9\u79f0\u6027\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u548c\u9c81\u68d2\u6027\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8303\u7574\u5bf9\u79f0\u79ef\uff0c\u4f7fCatEquiv\u7f51\u7edc\u5b9e\u73b0\u5173\u4e8e\u8303\u7574\u5bf9\u79f0\u79ef\u7684\u7b49\u53d8\u6027\u3002", "result": "\u5728UCI - HAR\u7684\u5206\u5e03\u5916\u6270\u52a8\u4e0b\uff0cCatEquiv\u6bd4\u5faa\u73af\u586b\u5145CNN\u548c\u5e73\u94faCNN\u6709\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u5f3a\u5236\u8303\u7574\u5bf9\u79f0\u6027\u53ef\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u5bb9\u91cf\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5f3a\u4e0d\u53d8\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.00670", "pdf": "https://arxiv.org/pdf/2511.00670", "abs": "https://arxiv.org/abs/2511.00670", "authors": ["Zhiyang Ning", "Benjamin Peherstorfer"], "title": "Filtered Neural Galerkin model reduction schemes for efficient propagation of initial condition uncertainties in digital twins", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "Uncertainty quantification in digital twins is critical to enable reliable\nand credible predictions beyond available data. A key challenge is that\nensemble-based approaches can become prohibitively expensive when embedded in\ncontrol and data assimilation loops in digital twins, even when reduced models\nare used. We introduce a reduced modeling approach that advances in time the\nmean and covariance of the reduced solution distribution induced by the initial\ncondition uncertainties, which eliminates the need to maintain and propagate a\ncostly ensemble of reduced solutions. The mean and covariance dynamics are\nobtained as a moment closure from Neural Galerkin schemes on pre-trained neural\nnetworks, which can be interpreted as filtered Neural Galerkin dynamics\nanalogous to Gaussian filtering and the extended Kalman filter. Numerical\nexperiments demonstrate that filtered Neural Galerkin schemes achieve more than\none order of magnitude speedup compared to ensemble-based uncertainty\npropagation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u964d\u7ef4\u5efa\u6a21\u65b9\u6cd5\u5904\u7406\u6570\u5b57\u5b6a\u751f\u4e2d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u95ee\u9898\uff0c\u76f8\u6bd4\u57fa\u4e8e\u96c6\u5408\u7684\u65b9\u6cd5\u6709\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u4e2d\u57fa\u4e8e\u96c6\u5408\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5728\u63a7\u5236\u548c\u6570\u636e\u540c\u5316\u5faa\u73af\u4e2d\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u5f15\u5165\u964d\u7ef4\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4e0a\u7684Neural Galerkin\u65b9\u6848\u7684\u77e9\u5c01\u95ed\u83b7\u5f97\u5747\u503c\u548c\u534f\u65b9\u5dee\u52a8\u529b\u5b66\u3002", "result": "\u8fc7\u6ee4\u540e\u7684Neural Galerkin\u65b9\u6848\u6bd4\u57fa\u4e8e\u96c6\u5408\u7684\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8d85\u8fc7\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6570\u5b57\u5b6a\u751f\u4e2d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002"}}
{"id": "2511.01143", "pdf": "https://arxiv.org/pdf/2511.01143", "abs": "https://arxiv.org/abs/2511.01143", "authors": ["Ziyi Wang", "Yuanmei Zhang", "Dorna Esrafilzadeh", "Ali R. Jalili", "Suncheng Xiang"], "title": "MicroAUNet: Boundary-Enhanced Multi-scale Fusion with Knowledge Distillation for Colonoscopy Polyp Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Work in progress", "summary": "Early and accurate segmentation of colorectal polyps is critical for reducing\ncolorectal cancer mortality, which has been extensively explored by academia\nand industry. However, current deep learning-based polyp segmentation models\neither compromise clinical decision-making by providing ambiguous polyp margins\nin segmentation outputs or rely on heavy architectures with high computational\ncomplexity, resulting in insufficient inference speeds for real-time colorectal\nendoscopic applications. To address this problem, we propose MicroAUNet, a\nlight-weighted attention-based segmentation network that combines\ndepthwise-separable dilated convolutions with a single-path, parameter-shared\nchannel-spatial attention block to strengthen multi-scale boundary features. On\nthe basis of it, a progressive two-stage knowledge-distillation scheme is\nintroduced to transfer semantic and boundary cues from a high-capacity teacher.\nExtensive experiments on benchmarks also demonstrate the state-of-the-art\naccuracy under extremely low model complexity, indicating that MicroAUNet is\nsuitable for real-time clinical polyp segmentation. The code is publicly\navailable at https://github.com/JeremyXSC/MicroAUNet.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6ce8\u610f\u529b\u5206\u5272\u7f51\u7edcMicroAUNet\u53ca\u6e10\u8fdb\u5f0f\u4e24\u9636\u6bb5\u77e5\u8bc6\u84b8\u998f\u65b9\u6848\uff0c\u5728\u4f4e\u590d\u6742\u5ea6\u4e0b\u5b9e\u73b0\u7ed3\u76f4\u80a0\u606f\u8089\u5b9e\u65f6\u5206\u5272\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u606f\u8089\u5206\u5272\u6a21\u578b\u5b58\u5728\u5206\u5272\u8fb9\u754c\u6a21\u7cca\u6216\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u63a8\u7406\u901f\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u63d0\u51faMicroAUNet\u7f51\u7edc\uff0c\u7ed3\u5408\u6df1\u5ea6\u53ef\u5206\u79bb\u6269\u5f20\u5377\u79ef\u4e0e\u5355\u8def\u5f84\u3001\u53c2\u6570\u5171\u4eab\u7684\u901a\u9053 - \u7a7a\u95f4\u6ce8\u610f\u529b\u5757\uff1b\u5f15\u5165\u6e10\u8fdb\u5f0f\u4e24\u9636\u6bb5\u77e5\u8bc6\u84b8\u998f\u65b9\u6848\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u4ee5\u6781\u4f4e\u7684\u6a21\u578b\u590d\u6742\u5ea6\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u7387\u3002", "conclusion": "MicroAUNet\u9002\u5408\u5b9e\u65f6\u4e34\u5e8a\u606f\u8089\u5206\u5272\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2511.01144", "pdf": "https://arxiv.org/pdf/2511.01144", "abs": "https://arxiv.org/abs/2511.01144", "authors": ["Md Tanvirul Alam", "Dipkamal Bhusal", "Salman Ahmad", "Nidhi Rastogi", "Peter Worth"], "title": "AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in natural\nlanguage reasoning, yet their application to Cyber Threat Intelligence (CTI)\nremains limited. CTI analysis involves distilling large volumes of unstructured\nreports into actionable knowledge, a process where LLMs could substantially\nreduce analyst workload. CTIBench introduced a comprehensive benchmark for\nevaluating LLMs across multiple CTI tasks. In this work, we extend CTIBench by\ndeveloping AthenaBench, an enhanced benchmark that includes an improved dataset\ncreation pipeline, duplicate removal, refined evaluation metrics, and a new\ntask focused on risk mitigation strategies. We evaluate twelve LLMs, including\nstate-of-the-art proprietary models such as GPT-5 and Gemini-2.5 Pro, alongside\nseven open-source models from the LLaMA and Qwen families. While proprietary\nLLMs achieve stronger results overall, their performance remains subpar on\nreasoning-intensive tasks, such as threat actor attribution and risk\nmitigation, with open-source models trailing even further behind. These\nfindings highlight fundamental limitations in the reasoning capabilities of\ncurrent LLMs and underscore the need for models explicitly tailored to CTI\nworkflows and automation.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8eCTIBench\u5f00\u53d1AthenaBench\u8bc4\u4f3012\u4e2a\u5927\u6a21\u578b\u5728CTI\u4efb\u52a1\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u6709\u5c40\u9650\uff0c\u9700\u9002\u914dCTI\u5de5\u4f5c\u6d41\u7684\u6a21\u578b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u4f46\u5728CTI\u5e94\u7528\u6709\u9650\uff0cCTIBench\u53ef\u8bc4\u4f30LLMs\u5728CTI\u4efb\u52a1\u8868\u73b0\uff0c\u672c\u6587\u65e8\u5728\u5bf9\u5176\u8fdb\u884c\u6269\u5c55\u3002", "method": "\u5f00\u53d1AthenaBench\uff0c\u5305\u542b\u6539\u8fdb\u6570\u636e\u96c6\u521b\u5efa\u6d41\u7a0b\u3001\u53bb\u91cd\u3001\u4f18\u5316\u8bc4\u4f30\u6307\u6807\u548c\u65b0\u589e\u98ce\u9669\u7f13\u89e3\u7b56\u7565\u4efb\u52a1\uff0c\u8bc4\u4f3012\u4e2aLLMs\u3002", "result": "\u4e13\u6709\u5927\u6a21\u578b\u6574\u4f53\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u8868\u73b0\u4e0d\u4f73\uff0c\u5f00\u6e90\u6a21\u578b\u66f4\u5dee\u3002", "conclusion": "\u5f53\u524d\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u6709\u6839\u672c\u5c40\u9650\uff0c\u9700\u8981\u4e13\u95e8\u9002\u914dCTI\u5de5\u4f5c\u6d41\u548c\u81ea\u52a8\u5316\u7684\u6a21\u578b\u3002"}}
{"id": "2511.01188", "pdf": "https://arxiv.org/pdf/2511.01188", "abs": "https://arxiv.org/abs/2511.01188", "authors": ["Lvhua Wu", "Xuefeng Jiang", "Sheng Sun", "Tian Wen", "Yuwei Wang", "Min Liu"], "title": "ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and Multi-LLM Interaction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid spread of fake news threatens social stability and public trust,\nrendering its detection an imperative research priority. Although large\nlanguage models (LLMs) excel at numerous natural language processing tasks with\ntheir remarkable contextual understanding and extensive prior knowledge, the\ntime-bounded knowledge coverage and tendency for generating hallucination\ncontent reduce their reliability when handling fast-evolving news streams.\nFurthermore, models trained on existing static datasets also often lack the\ngeneralization needed for emerging news topics. To address these challenges, we\npropose ZoFia, a novel two-stage zero-shot fake news detection framework.\nFirst, we introduce Hierarchical Salience to quantify the importance of\nentities in the news content, and propose the SC-MMR algorithm to effectively\nselect an informative and diverse set of keywords that serve as queries for\nretrieving up-to-date external evidence. Subsequently, a multi LLM interactive\nsystem, in which each agent assumes a distinct role, performs multi-view\ncollaborative analysis and adversarial debate over the news text and its\nrelated information, and finally produces an interpretable and robust judgment.\nComprehensive experiments on two public datasets demonstrate that ZoFia\nobviously outperforms existing zero-shot baselines and most of few-shot\nmethods. Our codes will be open-sourced to facilitate related communities.", "AI": {"tldr": "\u63d0\u51faZoFia\u96f6\u6837\u672c\u5047\u65b0\u95fb\u68c0\u6d4b\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002", "motivation": "\u5047\u65b0\u95fb\u4f20\u64ad\u5a01\u80c1\u793e\u4f1a\u7a33\u5b9a\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u65b0\u95fb\u6d41\u65f6\u53ef\u9760\u6027\u4f4e\uff0c\u5df2\u6709\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u63d0\u51faHierarchical Salience\u91cf\u5316\u65b0\u95fb\u5b9e\u4f53\u91cd\u8981\u6027\uff0c\u7528SC - MMR\u7b97\u6cd5\u9009\u5173\u952e\u8bcd\u68c0\u7d22\u5916\u90e8\u8bc1\u636e\uff1b\u6784\u5efa\u591aLLM\u4ea4\u4e92\u7cfb\u7edf\u8fdb\u884c\u591a\u89c6\u89d2\u5206\u6790\u548c\u8fa9\u8bba\u5f97\u51fa\u5224\u65ad\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cZoFia\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u96f6\u6837\u672c\u57fa\u7ebf\u548c\u591a\u6570\u5c11\u6837\u672c\u65b9\u6cd5\u3002", "conclusion": "ZoFia\u662f\u6709\u6548\u7684\u96f6\u6837\u672c\u5047\u65b0\u95fb\u68c0\u6d4b\u6846\u67b6\uff0c\u4ee3\u7801\u5f00\u6e90\u5229\u4e8e\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2511.00746", "pdf": "https://arxiv.org/pdf/2511.00746", "abs": "https://arxiv.org/abs/2511.00746", "authors": ["Andrew G. Moore"], "title": "Correspondence Between Ising Machines and Neural Networks", "categories": ["cond-mat.dis-nn", "cs.ET", "cs.LG", "quant-ph"], "comment": "22 pages, 4 figures", "summary": "Computation with the Ising model is central to future computing technologies\nlike quantum annealing, adiabatic quantum computing, and thermodynamic\nclassical computing. Traditionally, computed values have been equated with\nground states. This paper generalizes computation with ground states to\ncomputation with spin averages, allowing computations to take place at high\ntemperatures. It then introduces a systematic correspondence between Ising\ndevices and neural networks and a simple method to run trained feed-forward\nneural networks on Ising-type hardware. Finally, a mathematical proof is\noffered that these implementations are always successful.", "AI": {"tldr": "\u672c\u6587\u5c06Ising\u6a21\u578b\u7684\u57fa\u6001\u8ba1\u7b97\u63a8\u5e7f\u5230\u81ea\u65cb\u5e73\u5747\u8ba1\u7b97\uff0c\u5f15\u5165Ising\u8bbe\u5907\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u5bf9\u5e94\u5173\u7cfb\u53ca\u5728Ising\u786c\u4ef6\u4e0a\u8fd0\u884c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u6210\u529f\u5b9e\u73b0\u7684\u6570\u5b66\u8bc1\u660e\u3002", "motivation": "\u4f20\u7edf\u4e0aIsing\u6a21\u578b\u8ba1\u7b97\u503c\u7b49\u540c\u4e8e\u57fa\u6001\uff0c\u4e3a\u4f7f\u8ba1\u7b97\u80fd\u5728\u9ad8\u6e29\u4e0b\u8fdb\u884c\uff0c\u63a8\u5e7f\u8ba1\u7b97\u65b9\u5f0f\uff0c\u5e76\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u5728Ising\u786c\u4ef6\u4e0a\u7684\u8fd0\u884c\u3002", "method": "\u5c06\u57fa\u6001\u8ba1\u7b97\u63a8\u5e7f\u5230\u81ea\u65cb\u5e73\u5747\u8ba1\u7b97\uff0c\u5f15\u5165Ising\u8bbe\u5907\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u63d0\u51fa\u5728Ising\u578b\u786c\u4ef6\u4e0a\u8fd0\u884c\u8bad\u7ec3\u597d\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u7b80\u5355\u65b9\u6cd5\u3002", "result": "\u5b9e\u73b0\u4e86\u5728\u9ad8\u6e29\u4e0b\u7684\u8ba1\u7b97\uff0c\u5e76\u7ed9\u51fa\u5728Ising\u578b\u786c\u4ef6\u4e0a\u8fd0\u884c\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u4e14\u6709\u6570\u5b66\u8bc1\u660e\u5176\u5b9e\u73b0\u603b\u662f\u6210\u529f\u7684\u3002", "conclusion": "\u5c06Ising\u6a21\u578b\u8ba1\u7b97\u63a8\u5e7f\u5230\u81ea\u65cb\u5e73\u5747\u8ba1\u7b97\u53ef\u884c\uff0c\u4e14\u80fd\u6709\u6548\u5728Ising\u786c\u4ef6\u4e0a\u8fd0\u884c\u795e\u7ecf\u7f51\u7edc\u3002"}}
{"id": "2511.01191", "pdf": "https://arxiv.org/pdf/2511.01191", "abs": "https://arxiv.org/abs/2511.01191", "authors": ["Ru Wang", "Wei Huang", "Qi Cao", "Yusuke Iwasawa", "Yutaka Matsuo", "Jiaxian Guo"], "title": "Self-Harmony: Learning to Harmonize Self-Supervision and Self-Play in Test-Time Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Test-time reinforcement learning (TTRL) offers a label-free paradigm for\nadapting models using only synthetic signals at inference, but its success\nhinges on constructing reliable learning signals. Standard approaches such as\nmajority voting often collapse to spurious yet popular answers. We introduce\nSelf-Harmony, a framework built on a simple intuition: the correct answer\nshould remain stable across both an original question and its paraphrase.\nSelf-Harmony operationalizes this by employing a single model in two\ncomplementary roles: a Solver to produce answers and a Reframer to rephrase the\ninput. Based on this, we further propose a pseudo-label method: instead of\nmajority voting, it aggregates answer frequencies across these original and\nreframed views using the harmonic mean. This is a process that naturally\nselects for solutions stable under reframing, thereby avoiding the common trap\nof favoring view-dependent, spurious answers. Crucially, this requires no human\nsupervision or auxiliary models. Across diverse reasoning benchmarks,\nSelf-Harmony achieves state-of-the-art results at the label-free test-time\nsetting, ranking first in 28 of 30 settings across multiple methods. Beyond\naccuracy, it demonstrates unprecedented robustness, with zero training failures\nin all experiments, underscoring its stability and reliability.", "AI": {"tldr": "\u4ecb\u7ecdSelf - Harmony\u6846\u67b6\u7528\u4e8e\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\uff0c\u907f\u514d\u5e38\u89c1\u9677\u9631\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\u4e14\u7a33\u5b9a\u6027\u9ad8\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u6210\u529f\u4f9d\u8d56\u53ef\u9760\u5b66\u4e60\u4fe1\u53f7\uff0c\u6807\u51c6\u65b9\u6cd5\u5982\u591a\u6570\u6295\u7968\u6613\u5f97\u51fa\u865a\u5047\u7b54\u6848\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSelf - Harmony\u6846\u67b6\uff0c\u6a21\u578b\u5206Solver\u548cReframer\u4e24\u4e2a\u89d2\u8272\uff0c\u91c7\u7528\u4f2a\u6807\u7b7e\u65b9\u6cd5\uff0c\u7528\u8c03\u548c\u5e73\u5747\u805a\u5408\u7b54\u6848\u9891\u7387\u3002", "result": "\u5728\u591a\u79cd\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u65e0\u6807\u7b7e\u6d4b\u8bd5\u65f6\u95f4\u8bbe\u7f6e\u4e0b\u53d6\u5f97SOTA\u7ed3\u679c\uff0c28\u4e2a\u8bbe\u7f6e\u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u4e14\u65e0\u8bad\u7ec3\u5931\u8d25\u60c5\u51b5\u3002", "conclusion": "Self - Harmony\u6846\u67b6\u6709\u6548\uff0c\u907f\u514d\u5e38\u89c1\u9677\u9631\uff0c\u5177\u6709\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.01194", "pdf": "https://arxiv.org/pdf/2511.01194", "abs": "https://arxiv.org/abs/2511.01194", "authors": ["Minmin Zeng"], "title": "A Topology-Aware Graph Convolutional Network for Human Pose Similarity and Action Quality Assessment", "categories": ["cs.CV", "cs.AI", "68T07 (Artificial neural networks and deep learning), 68U10\n  (Computer graphics, computational geometry)"], "comment": "10 pages, 5 figures. Submitted as a computer vision paper in the\n  cs.CV category", "summary": "Action Quality Assessment (AQA) requires fine-grained understanding of human\nmotion and precise evaluation of pose similarity. This paper proposes a\ntopology-aware Graph Convolutional Network (GCN) framework, termed GCN-PSN,\nwhich models the human skeleton as a graph to learn discriminative,\ntopology-sensitive pose embeddings. Using a Siamese architecture trained with a\ncontrastive regression objective, our method outperforms coordinate-based\nbaselines and achieves competitive performance on AQA-7 and FineDiving\nbenchmarks. Experimental results and ablation studies validate the\neffectiveness of leveraging skeletal topology for pose similarity and action\nquality assessment.", "AI": {"tldr": "\u63d0\u51fa\u62d3\u6251\u611f\u77e5\u7684\u56fe\u5377\u79ef\u7f51\u7edcGCN - PSN\u7528\u4e8e\u52a8\u4f5c\u8d28\u91cf\u8bc4\u4f30\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u52a8\u4f5c\u8d28\u91cf\u8bc4\u4f30\u9700\u8981\u5bf9\u4eba\u4f53\u8fd0\u52a8\u7684\u7ec6\u7c92\u5ea6\u7406\u89e3\u548c\u59ff\u6001\u76f8\u4f3c\u5ea6\u7684\u7cbe\u786e\u8bc4\u4f30\u3002", "method": "\u63d0\u51faGCN - PSN\u6846\u67b6\uff0c\u5c06\u4eba\u4f53\u9aa8\u9abc\u5efa\u6a21\u4e3a\u56fe\u4ee5\u5b66\u4e60\u5224\u522b\u6027\u3001\u62d3\u6251\u654f\u611f\u7684\u59ff\u6001\u5d4c\u5165\uff0c\u91c7\u7528\u5bf9\u6bd4\u56de\u5f52\u76ee\u6807\u8bad\u7ec3\u7684\u5b6a\u751f\u67b6\u6784\u3002", "result": "\u4f18\u4e8e\u57fa\u4e8e\u5750\u6807\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728AQA - 7\u548cFineDiving\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u548c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5229\u7528\u9aa8\u9abc\u62d3\u6251\u8fdb\u884c\u59ff\u6001\u76f8\u4f3c\u5ea6\u548c\u52a8\u4f5c\u8d28\u91cf\u8bc4\u4f30\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.00768", "pdf": "https://arxiv.org/pdf/2511.00768", "abs": "https://arxiv.org/abs/2511.00768", "authors": ["Peiru Wu", "Maojun Zhai", "Lingzhu Zhang"], "title": "A Framework Based on Graph Cellular Automata for Similarity Evaluation in Urban Spatial Networks", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "Measuring similarity in urban spatial networks is key to understanding cities\nas complex systems. Yet most existing methods are not tailored for spatial\nnetworks and struggle to differentiate them effectively. We propose GCA-Sim, a\nsimilarity-evaluation framework based on graph cellular automata. Each submodel\nmeasures similarity by the divergence between value distributions recorded at\nmultiple stages of an information evolution process. We find that some\npropagation rules magnify differences among network signals; we call this\n\"network resonance.\" With an improved differentiable logic-gate network, we\nlearn several submodels that induce network resonance. We evaluate similarity\nthrough clustering performance on fifty city-level and fifty district-level\nroad networks. The submodels in this framework outperform existing methods,\nwith Silhouette scores above 0.9. Using the best submodel, we further observe\nthat planning-led street networks are less internally homogeneous than\norganically grown ones; morphological categories from different domains\ncontribute with comparable importance; and degree, as a basic topological\nsignal, becomes increasingly aligned with land value and related variables over\niterations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u5143\u80de\u81ea\u52a8\u673a\u7684GCA - Sim\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u9053\u8def\u7f51\u7edc\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5f97\u51fa\u5173\u4e8e\u8857\u9053\u7f51\u7edc\u7279\u5f81\u7684\u7ed3\u8bba\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u7a7a\u95f4\u7f51\u7edc\uff0c\u96be\u4ee5\u6709\u6548\u533a\u5206\u57ce\u5e02\u7a7a\u95f4\u7f51\u7edc\uff0c\u9700\u65b0\u7684\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGCA - Sim\u6846\u67b6\uff0c\u5404\u5b50\u6a21\u578b\u901a\u8fc7\u4fe1\u606f\u6f14\u5316\u8fc7\u7a0b\u591a\u9636\u6bb5\u8bb0\u5f55\u7684\u503c\u5206\u5e03\u5dee\u5f02\u6d4b\u91cf\u76f8\u4f3c\u5ea6\uff0c\u5229\u7528\u6539\u8fdb\u7684\u53ef\u5fae\u903b\u8f91\u95e8\u7f51\u7edc\u5b66\u4e60\u80fd\u5f15\u53d1\u201c\u7f51\u7edc\u5171\u632f\u201d\u7684\u5b50\u6a21\u578b\uff0c\u901a\u8fc7\u805a\u7c7b\u6027\u80fd\u8bc4\u4f30\u76f8\u4f3c\u5ea6\u3002", "result": "\u6846\u67b6\u4e2d\u7684\u5b50\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8f6e\u5ed3\u7cfb\u6570\u8d850.9\u3002", "conclusion": "\u89c4\u5212\u4e3b\u5bfc\u7684\u8857\u9053\u7f51\u7edc\u5185\u90e8\u540c\u8d28\u6027\u4f4e\u4e8e\u81ea\u7136\u751f\u957f\u7684\u7f51\u7edc\uff1b\u4e0d\u540c\u9886\u57df\u5f62\u6001\u7c7b\u522b\u8d21\u732e\u76f8\u5f53\uff1b\u5ea6\u8fd9\u4e00\u62d3\u6251\u4fe1\u53f7\u4e0e\u571f\u5730\u4ef7\u503c\u7b49\u53d8\u91cf\u8fed\u4ee3\u4e2d\u6108\u53d1\u4e00\u81f4\u3002"}}
{"id": "2511.01202", "pdf": "https://arxiv.org/pdf/2511.01202", "abs": "https://arxiv.org/abs/2511.01202", "authors": ["Bo Bai"], "title": "Forget BIT, It is All about TOKEN: Towards Semantic Information Theory for LLMs", "categories": ["cs.IT", "cs.AI", "math.IT"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnumerous real- world applications. While the vast majority of research\nconducted from an experimental perspective is progressing rapidly, it demands\nsubstantial computational power, data, and other resources. Therefore, how to\nopen the black-box of LLMs from a theoretical standpoint has become a critical\nchallenge. This paper takes the theory of rate-distortion function, directed\ninformation, and Granger causality as its starting point to investigate the\ninformation-theoretic principles behind LLMs, leading to the development of\nsemantic information theory for LLMs, where the fundamental unit is token,\nrather than bits that lacks any semantic meaning. By defining the probabilistic\nmodel of LLMs, we discuss structure-agnostic information-theoretic measures,\nsuch as the directed rate- distortion function in pre-training, the directed\nrate-reward function in post-training, and the semantic information flow in\ninference phase. This paper also delves deeply into the theory of token-level\nsemantic embedding and the information-theoretically optimal vectorization\nmethod. Thereafter, we propose a general definition of autoregression LLM,\nwhere the Transformer architecture and its performance such as ELBO,\ngeneralization error bound, memory capacity, and semantic information measures\ncan be derived theoretically. Other architectures, such as Mamba/Mamba2 and\nLLaDA, are also discussed in our framework. Consequently, this paper provides a\ntheoretical framework for understanding LLMs from the perspective of semantic\ninformation theory, which also offers the necessary theoretical tools for\nfurther in-depth research.", "AI": {"tldr": "\u672c\u6587\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u51fa\u8bed\u4e49\u4fe1\u606f\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u548c\u6df1\u5165\u7814\u7a76\u63d0\u4f9b\u7406\u8bba\u5de5\u5177\u3002", "motivation": "\u591a\u6570\u5927\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4ece\u5b9e\u9a8c\u89d2\u5ea6\u5f00\u5c55\uff0c\u9700\u5927\u91cf\u8d44\u6e90\uff0c\u56e0\u6b64\u8981\u4ece\u7406\u8bba\u89d2\u5ea6\u6253\u5f00\u5176\u9ed1\u7bb1\u3002", "method": "\u4ee5\u7387\u5931\u771f\u51fd\u6570\u3001\u6709\u5411\u4fe1\u606f\u548c\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\u7406\u8bba\u4e3a\u8d77\u70b9\uff0c\u5b9a\u4e49\u5927\u8bed\u8a00\u6a21\u578b\u6982\u7387\u6a21\u578b\uff0c\u63a2\u8ba8\u7ed3\u6784\u65e0\u5173\u7684\u4fe1\u606f\u8bba\u5ea6\u91cf\uff0c\u7814\u7a76\u8bcd\u5143\u7ea7\u8bed\u4e49\u5d4c\u5165\u7406\u8bba\u548c\u6700\u4f18\u5411\u91cf\u5316\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e00\u822c\u5b9a\u4e49\uff0c\u7406\u8bba\u63a8\u5bfcTransformer\u67b6\u6784\u53ca\u5176\u6027\u80fd\uff0c\u8fd8\u8ba8\u8bba\u4e86\u5176\u4ed6\u67b6\u6784\u3002", "conclusion": "\u672c\u6587\u4ece\u8bed\u4e49\u4fe1\u606f\u7406\u8bba\u89d2\u5ea6\u4e3a\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u5fc5\u8981\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2511.01213", "pdf": "https://arxiv.org/pdf/2511.01213", "abs": "https://arxiv.org/abs/2511.01213", "authors": ["Riddhi Jain", "Manasi Patwardhan", "Parijat Deshpande", "Venkataramana Runkana"], "title": "Thought-For-Food: Reasoning Chain Induced Food Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 11 figures, 6 tables", "summary": "The immense diversity in the culture and culinary of Indian cuisines calls\nattention to the major shortcoming of the existing Visual Question\nAnswering(VQA) systems which are inclined towards the foods from Western\nregion. Recent attempt towards building a VQA dataset for Indian food is a step\ntowards addressing this challenge. However, their approach towards VQA follows\na two-step process in which the answer is generated first, followed by the\nexplanation of the expected answer. In this work, we claim that food VQA\nrequires to follow a multi-step reasoning process to arrive at an accurate\nanswer, especially in the context of India food, which involves understanding\ncomplex culinary context and identifying relationships between various food\nitems. With this hypothesis we create reasoning chains upon the QA with minimal\nhuman intervention. We fine-tune smaller LLMs and VLMs with auto-validated\nreasoning chains and further train them using reinforcement learning with\nlarger data. With augmentation of reasoning chains, we observed accuracy\nimprovement of an average 10 percentage points on the baseline. We provide\ndetailed analysis in terms the effect of addition of reasoning chains for the\nIndian Food VQA task.\n  Index Terms - FoodVQA, Reasoning Chains, Reinforcement Learning, Knowledge\nGraph.", "AI": {"tldr": "\u73b0\u6709VQA\u7cfb\u7edf\u504f\u5411\u897f\u65b9\u98df\u7269\uff0c\u672c\u6587\u9488\u5bf9\u5370\u5ea6\u98df\u7269VQA\uff0c\u901a\u8fc7\u521b\u5efa\u63a8\u7406\u94fe\u3001\u5fae\u8c03\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709VQA\u7cfb\u7edf\u503e\u5411\u897f\u65b9\u98df\u7269\uff0c\u5370\u5ea6\u98df\u7269\u6587\u5316\u548c\u70f9\u996a\u591a\u6837\uff0c\u73b0\u6709\u65b9\u6cd5\u6709\u4e0d\u8db3\uff0c\u9700\u591a\u6b65\u63a8\u7406\u3002", "method": "\u5728\u95ee\u7b54\u4e0a\u521b\u5efa\u63a8\u7406\u94fe\uff0c\u5fae\u8c03\u5c0f\u6a21\u578b\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u589e\u52a0\u63a8\u7406\u94fe\u3002", "result": "\u63a8\u7406\u94fe\u589e\u5f3a\u540e\uff0c\u57fa\u7ebf\u51c6\u786e\u7387\u5e73\u5747\u63d0\u9ad810\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u5bf9\u5370\u5ea6\u98df\u7269VQA\u4efb\u52a1\u4e2d\u6dfb\u52a0\u63a8\u7406\u94fe\u7684\u6548\u679c\u8fdb\u884c\u4e86\u8be6\u7ec6\u5206\u6790\u3002"}}
{"id": "2511.01228", "pdf": "https://arxiv.org/pdf/2511.01228", "abs": "https://arxiv.org/abs/2511.01228", "authors": ["Jiahui Gao", "Kuang Zhou", "Yuchen Zhu"], "title": "Influence-aware Causal Autoencoder Network for Node Importance Ranking in Complex Networks", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Node importance ranking is a fundamental problem in graph data analysis.\nExisting approaches typically rely on node features derived from either\ntraditional centrality measures or advanced graph representation learning\nmethods, which depend directly on the target network's topology. However, this\nreliance on structural information raises privacy concerns and often leads to\npoor generalization across different networks. In this work, we address a key\nquestion: Can we design a node importance ranking model trained exclusively on\nsynthetic networks that is effectively appliable to real-world networks,\neliminating the need to rely on the topology of target networks and improving\nboth practicality and generalizability? We answer this question affirmatively\nby proposing the Influence-aware Causal Autoencoder Network (ICAN), a novel\nframework that leverages causal representation learning to get robust,\ninvariant node embeddings for cross-network ranking tasks. Firstly, ICAN\nintroduces an influence-aware causal representation learning module within an\nautoencoder architecture to extract node embeddings that are causally related\nto node importance. Moreover, we introduce a causal ranking loss and design a\nunified optimization framework that jointly optimizes the reconstruction and\nranking objectives, enabling mutual reinforcement between node representation\nlearning and ranking optimization. This design allows ICAN, trained on\nsynthetic networks, to generalize effectively across diverse real-world graphs.\nExtensive experiments on multiple benchmark datasets demonstrate that ICAN\nconsistently outperforms state-of-the-art baselines in terms of both ranking\naccuracy and generalization capability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faICAN\u6846\u67b6\u89e3\u51b3\u8282\u70b9\u91cd\u8981\u6027\u6392\u5e8f\u95ee\u9898\uff0c\u5728\u5408\u6210\u7f51\u7edc\u4e0a\u8bad\u7ec3\u540e\u53ef\u7528\u4e8e\u771f\u5b9e\u7f51\u7edc\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8282\u70b9\u91cd\u8981\u6027\u6392\u5e8f\u65b9\u6cd5\u4f9d\u8d56\u76ee\u6807\u7f51\u7edc\u62d3\u6251\uff0c\u5b58\u5728\u9690\u79c1\u95ee\u9898\u4e14\u6cdb\u5316\u6027\u5dee\uff0c\u9700\u8bbe\u8ba1\u4e0d\u4f9d\u8d56\u76ee\u6807\u7f51\u7edc\u62d3\u6251\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faICAN\u6846\u67b6\uff0c\u5728\u81ea\u7f16\u7801\u5668\u67b6\u6784\u4e2d\u5f15\u5165\u5f71\u54cd\u611f\u77e5\u56e0\u679c\u8868\u793a\u5b66\u4e60\u6a21\u5757\u63d0\u53d6\u4e0e\u8282\u70b9\u91cd\u8981\u6027\u56e0\u679c\u76f8\u5173\u7684\u5d4c\u5165\uff0c\u5f15\u5165\u56e0\u679c\u6392\u5e8f\u635f\u5931\u5e76\u8bbe\u8ba1\u7edf\u4e00\u4f18\u5316\u6846\u67b6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cICAN\u5728\u6392\u5e8f\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ICAN\u6846\u67b6\u53ef\u6709\u6548\u89e3\u51b3\u8282\u70b9\u91cd\u8981\u6027\u6392\u5e8f\u95ee\u9898\uff0c\u5728\u5408\u6210\u7f51\u7edc\u4e0a\u8bad\u7ec3\u540e\u80fd\u6709\u6548\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u771f\u5b9e\u4e16\u754c\u56fe\u4e2d\u3002"}}
{"id": "2511.01237", "pdf": "https://arxiv.org/pdf/2511.01237", "abs": "https://arxiv.org/abs/2511.01237", "authors": ["Vishakha Lall", "Yisi Liu"], "title": "Eyes on Target: Gaze-Aware Object Detection in Egocentric Video", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at RAAI 2025", "summary": "Human gaze offers rich supervisory signals for understanding visual attention\nin complex visual environments. In this paper, we propose Eyes on Target, a\nnovel depth-aware and gaze-guided object detection framework designed for\negocentric videos. Our approach injects gaze-derived features into the\nattention mechanism of a Vision Transformer (ViT), effectively biasing spatial\nfeature selection toward human-attended regions. Unlike traditional object\ndetectors that treat all regions equally, our method emphasises\nviewer-prioritised areas to enhance object detection. We validate our method on\nan egocentric simulator dataset where human visual attention is critical for\ntask assessment, illustrating its potential in evaluating human performance in\nsimulation scenarios. We evaluate the effectiveness of our gaze-integrated\nmodel through extensive experiments and ablation studies, demonstrating\nconsistent gains in detection accuracy over gaze-agnostic baselines on both the\ncustom simulator dataset and public benchmarks, including Ego4D Ego-Motion and\nEgo-CH-Gaze datasets. To interpret model behaviour, we also introduce a\ngaze-aware attention head importance metric, revealing how gaze cues modulate\ntransformer attention dynamics.", "AI": {"tldr": "\u63d0\u51fa\u6df1\u5ea6\u611f\u77e5\u548c\u6ce8\u89c6\u5f15\u5bfc\u7684\u76ee\u6807\u68c0\u6d4b\u6846\u67b6Eyes on Target\uff0c\u6ce8\u5165\u6ce8\u89c6\u7279\u5f81\u5230ViT\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b9e\u9a8c\u8bc1\u660e\u68c0\u6d4b\u7cbe\u5ea6\u63d0\u5347\u5e76\u5f15\u5165\u6ce8\u89c6\u611f\u77e5\u6ce8\u610f\u529b\u5934\u91cd\u8981\u6027\u6307\u6807\u3002", "motivation": "\u5229\u7528\u4eba\u7c7b\u6ce8\u89c6\u4fe1\u53f7\u7406\u89e3\u590d\u6742\u89c6\u89c9\u73af\u5883\u4e2d\u7684\u89c6\u89c9\u6ce8\u610f\u529b\uff0c\u6539\u8fdb\u4f20\u7edf\u76ee\u6807\u68c0\u6d4b\u5668\u5bf9\u6240\u6709\u533a\u57df\u5e73\u7b49\u5bf9\u5f85\u7684\u95ee\u9898\u3002", "method": "\u5c06\u6ce8\u89c6\u884d\u751f\u7279\u5f81\u6ce8\u5165ViT\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5f3a\u8c03\u89c2\u4f17\u4f18\u5148\u533a\u57df\u3002", "result": "\u5728\u81ea\u5b9a\u4e49\u6a21\u62df\u5668\u6570\u636e\u96c6\u548c\u516c\u5171\u57fa\u51c6\u4e0a\u68c0\u6d4b\u7cbe\u5ea6\u6bd4\u65e0\u6ce8\u89c6\u57fa\u7ebf\u6709\u6301\u7eed\u63d0\u5347\uff0c\u5f15\u5165\u6307\u6807\u63ed\u793a\u6ce8\u89c6\u7ebf\u7d22\u5bf9\u53d8\u538b\u5668\u6ce8\u610f\u529b\u52a8\u6001\u7684\u8c03\u8282\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u8bc4\u4f30\u6a21\u62df\u573a\u666f\u4e2d\u4eba\u7c7b\u8868\u73b0\u6709\u6f5c\u529b\uff0c\u80fd\u6709\u6548\u63d0\u5347\u76ee\u6807\u68c0\u6d4b\u6548\u679c\u3002"}}
{"id": "2511.00814", "pdf": "https://arxiv.org/pdf/2511.00814", "abs": "https://arxiv.org/abs/2511.00814", "authors": ["Stella Kombo", "Masih Haseli", "Skylar Wei", "Joel W. Burdick"], "title": "Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY", "93C41, 93E11, 37M10", "I.2.9; I.2.6; I.2.8"], "comment": "10 pages, 6 figures, submitted to IEEE International Conference on\n  Robotics and Automation (ICRA) 2025", "summary": "Autonomous systems often must predict the motions of nearby agents from\npartial and noisy data. This paper asks and answers the question: \"can we\nlearn, in real-time, a nonlinear predictive model of another agent's motions?\"\nOur online framework denoises and forecasts such dynamics using a modified\nsliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy\nmeasurements are embedded into a Hankel matrix, while an associated Page matrix\nenables singular-value hard thresholding (SVHT) to estimate the effective rank.\nA Cadzow projection enforces structured low-rank consistency, yielding a\ndenoised trajectory and local noise variance estimates. From this\nrepresentation, a time-varying Hankel-DMD lifted linear predictor is\nconstructed for multi-step forecasts. The residual analysis provides\nvariance-tracking signals that can support downstream estimators and risk-aware\nplanning. We validate the approach in simulation under Gaussian and\nheavy-tailed noise, and experimentally on a dynamic crane testbed. Results show\nthat the method achieves stable variance-aware denoising and short-horizon\nprediction suitable for integration into real-time control frameworks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u7ebf\u6846\u67b6\uff0c\u7528\u6539\u8fdb\u7684\u6ed1\u52a8\u7a97\u53e3Hankel - DMD\u5bf9\u81ea\u6cbb\u7cfb\u7edf\u4e2d\u9644\u8fd1\u4ee3\u7406\u7684\u8fd0\u52a8\u8fdb\u884c\u53bb\u566a\u548c\u9884\u6d4b\uff0c\u5728\u6a21\u62df\u548c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u7a33\u5b9a\u7684\u65b9\u5dee\u611f\u77e5\u53bb\u566a\u548c\u77ed\u89c6\u8ddd\u9884\u6d4b\u3002", "motivation": "\u81ea\u6cbb\u7cfb\u7edf\u9700\u4ece\u90e8\u5206\u548c\u6709\u566a\u58f0\u7684\u6570\u636e\u4e2d\u9884\u6d4b\u9644\u8fd1\u4ee3\u7406\u7684\u8fd0\u52a8\uff0c\u7814\u7a76\u80fd\u5426\u5b9e\u65f6\u5b66\u4e60\u975e\u7ebf\u6027\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684\u6ed1\u52a8\u7a97\u53e3Hankel - DMD\u53bb\u566a\u548c\u9884\u6d4b\uff0c\u5c06\u90e8\u5206\u566a\u58f0\u6d4b\u91cf\u5d4c\u5165Hankel\u77e9\u9635\uff0c\u7528Page\u77e9\u9635\u8fdb\u884c\u5947\u5f02\u503c\u786c\u9608\u503c\u5904\u7406\uff0c\u901a\u8fc7Cadzow\u6295\u5f71\u5b9e\u73b0\u4f4e\u79e9\u4e00\u81f4\u6027\uff0c\u6784\u5efa\u65f6\u53d8Hankel - DMD\u7ebf\u6027\u9884\u6d4b\u5668\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\uff0c\u7528\u6b8b\u5dee\u5206\u6790\u63d0\u4f9b\u65b9\u5dee\u8ddf\u8e2a\u4fe1\u53f7\u3002", "result": "\u5728\u9ad8\u65af\u548c\u91cd\u5c3e\u566a\u58f0\u6a21\u62df\u4ee5\u53ca\u52a8\u6001\u8d77\u91cd\u673a\u8bd5\u9a8c\u53f0\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u7a33\u5b9a\u7684\u65b9\u5dee\u611f\u77e5\u53bb\u566a\u548c\u77ed\u89c6\u8ddd\u9884\u6d4b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u5408\u96c6\u6210\u5230\u5b9e\u65f6\u63a7\u5236\u6846\u67b6\u4e2d\u3002"}}
{"id": "2511.01253", "pdf": "https://arxiv.org/pdf/2511.01253", "abs": "https://arxiv.org/abs/2511.01253", "authors": ["Hans Gundlach", "Hrvoje Kukina", "Jayson Lynch", "Neil Thompson"], "title": "Quantum Deep Learning Still Needs a Quantum Leap", "categories": ["quant-ph", "cs.AI", "cs.LG", "81P68, 68T07, 68Q12, 68Q25, 65F10", "F.1.2; F.2.1; I.2.6; I.2.8; G.1.3"], "comment": null, "summary": "Quantum computing technology is advancing rapidly. Yet, even accounting for\nthese trends, a quantum leap would be needed for quantum computers to mean-\ningfully impact deep learning over the coming decade or two. We arrive at this\nconclusion based on a first-of-its-kind survey of quantum algorithms and how\nthey match potential deep learning applications. This survey reveals three\nimportant areas where quantum computing could potentially accelerate deep\nlearning, each of which faces a challenging roadblock to realizing its\npotential. First, quantum algorithms for matrix multiplication and other\nalgorithms central to deep learning offer small theoretical improvements in the\nnumber of operations needed, but this advantage is overwhelmed on practical\nproblem sizes by how slowly quantum computers do each operation. Second, some\npromising quantum algorithms depend on practical Quantum Random Access Memory\n(QRAM), which is underdeveloped. Finally, there are quantum algorithms that\noffer large theoretical advantages, but which are only applicable to special\ncases, limiting their practical benefits. In each of these areas, we support\nour arguments using quantitative forecasts of quantum advantage that build on\nthe work by Choi et al. [2023] as well as new research on limitations and\nquantum hardware trends. Our analysis outlines the current scope of quantum\ndeep learning and points to research directions that could lead to greater\npractical advances in the field.", "AI": {"tldr": "\u91cf\u5b50\u8ba1\u7b97\u6280\u672f\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u672a\u6765\u4e00\u4e8c\u5341\u5e74\u5185\u91cf\u5b50\u8ba1\u7b97\u673a\u96be\u4ee5\u5bf9\u6df1\u5ea6\u5b66\u4e60\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\uff0c\u901a\u8fc7\u8c03\u67e5\u5206\u6790\u6307\u51fa\u4e09\u4e2a\u6709\u6f5c\u529b\u4f46\u9762\u4e34\u969c\u788d\u7684\u9886\u57df\u3002", "motivation": "\u8bc4\u4f30\u91cf\u5b50\u8ba1\u7b97\u673a\u5728\u672a\u6765\u4e00\u4e8c\u5341\u5e74\u5185\u5bf9\u6df1\u5ea6\u5b66\u4e60\u7684\u5f71\u54cd\u3002", "method": "\u5bf9\u91cf\u5b50\u7b97\u6cd5\u53ca\u5176\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6f5c\u5728\u5e94\u7528\u7684\u5339\u914d\u60c5\u51b5\u8fdb\u884c\u8c03\u67e5\uff0c\u4f7f\u7528Choi\u7b49\u4eba[2023]\u7684\u5de5\u4f5c\u53ca\u65b0\u7814\u7a76\u8fdb\u884c\u5b9a\u91cf\u9884\u6d4b\u3002", "result": "\u53d1\u73b0\u91cf\u5b50\u8ba1\u7b97\u5728\u4e09\u4e2a\u9886\u57df\u53ef\u80fd\u52a0\u901f\u6df1\u5ea6\u5b66\u4e60\uff0c\u4f46\u5747\u9762\u4e34\u969c\u788d\uff1a\u77e9\u9635\u4e58\u6cd5\u7b49\u7b97\u6cd5\u64cd\u4f5c\u7406\u8bba\u6539\u8fdb\u5c0f\u4e14\u5b9e\u9645\u64cd\u4f5c\u6162\uff1b\u90e8\u5206\u7b97\u6cd5\u4f9d\u8d56\u672a\u6210\u719f\u7684QRAM\uff1b\u90e8\u5206\u7b97\u6cd5\u7406\u8bba\u4f18\u52bf\u5927\u4f46\u9002\u7528\u7279\u6b8a\u60c5\u51b5\u3002", "conclusion": "\u660e\u786e\u4e86\u5f53\u524d\u91cf\u5b50\u6df1\u5ea6\u5b66\u4e60\u7684\u8303\u56f4\uff0c\u5e76\u6307\u51fa\u4e86\u53ef\u80fd\u5e26\u6765\u66f4\u591a\u5b9e\u9645\u8fdb\u5c55\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.01261", "pdf": "https://arxiv.org/pdf/2511.01261", "abs": "https://arxiv.org/abs/2511.01261", "authors": ["Jiatong Shi", "Jionghao Han", "Yichen Lu", "Santiago Pascual", "Pengfei Wu", "Chenye Cui", "Shinji Watanabe", "Chao Weng", "Cong Zhou"], "title": "Speech-DRAME: A Framework for Human-Aligned Benchmarks in Speech Role-Play", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "67 pages", "summary": "Role-play has become a key testbed for generative models, expanding from\ntext-only dialogue to multimodal interaction. Extending role-play to speech\ncaptures prosody, emotion, and delivery, but also poses new evaluation\nchallenges. Current pipelines often use audio large language models (ALLMs) as\nzero-shot judges, which miss paralinguistic cues, collapse multiple aspects\ninto coarse scores, and rely on synthetic speech references that fail to\nreflect real-world roles. We present Speech-DRAME, a unified framework that\ncontributes at three levels: (i) Speech-DRAME-EvalBench, an evaluation\nbenchmark with bilingual human-annotated data and protocols for training and\ntesting speech evaluation models (SEMs), (ii) DRAME-Eval, a fine-tuned\nevaluation model, which substantially outperforms zero-shot and few-shot ALLMs,\nand (iii) Speech-DRAME-RoleBench, a speech role-play benchmark that leverages\nDRAME-Eval as an automatic judge to compare speech foundation models (SFMs).\nSpeech-DRAME distinguishes between two complementary evaluation strategies:\nArchetype Evaluation, a top-down approach measuring adherence to broad role\narchetypes, and Realism Evaluation, a bottom-up approach grounded in real human\nspeech that emphasizes nuanced role quality. Compared to zero-shot ALLM judges,\nDRAME-Eval achieves stronger agreement with human ratings (Pearson correlation\nfrom 0.480 to 0.629 in archetypes, and 0.390 to 0.625 in realism). By\nintegrating transparent benchmark resources, modeling approaches, and\nsystem-level evaluation, Speech-DRAME provides the first comprehensive,\nreproducible foundation for assessing spoken role-play.", "AI": {"tldr": "\u63d0\u51faSpeech - DRAME\u6846\u67b6\u7528\u4e8e\u8bed\u97f3\u89d2\u8272\u626e\u6f14\u8bc4\u4f30\uff0c\u542b\u8bc4\u4f30\u57fa\u51c6\u3001\u8bc4\u4f30\u6a21\u578b\u7b49\uff0c\u8868\u73b0\u4f18\u4e8e\u96f6\u6837\u672cALLM\u6cd5\u5b98\uff0c\u63d0\u4f9b\u7efc\u5408\u53ef\u590d\u73b0\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u89d2\u8272\u626e\u6f14\u8bc4\u4f30\u5b58\u5728\u95ee\u9898\uff0c\u5982ALLM\u4f5c\u96f6\u6837\u672c\u6cd5\u5b98\u6709\u7f3a\u9677\uff0c\u9700\u65b0\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSpeech - DRAME\u6846\u67b6\uff0c\u5305\u62ec\u8bc4\u4f30\u57fa\u51c6\u3001\u5fae\u8c03\u8bc4\u4f30\u6a21\u578b\u3001\u8bed\u97f3\u89d2\u8272\u626e\u6f14\u57fa\u51c6\uff0c\u533a\u5206\u4e24\u79cd\u8bc4\u4f30\u7b56\u7565\u3002", "result": "DRAME - Eval\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7684\u76ae\u5c14\u900a\u76f8\u5173\u6027\u63d0\u9ad8\uff0c\u5728\u539f\u578b\u8bc4\u4f30\u4e2d\u4ece0.480\u63d0\u5347\u52300.629\uff0c\u5728\u73b0\u5b9e\u6027\u8bc4\u4f30\u4e2d\u4ece0.390\u63d0\u5347\u52300.625\u3002", "conclusion": "Speech - DRAME\u4e3a\u8bc4\u4f30\u53e3\u8bed\u89d2\u8272\u626e\u6f14\u63d0\u4f9b\u9996\u4e2a\u5168\u9762\u3001\u53ef\u590d\u73b0\u7684\u57fa\u7840\u3002"}}
{"id": "2511.01282", "pdf": "https://arxiv.org/pdf/2511.01282", "abs": "https://arxiv.org/abs/2511.01282", "authors": ["Min Fang", "Zhihui Fu", "Qibin Zhao", "Jun Wang"], "title": "When, What, and How: Rethinking Retrieval-Enhanced Speculative Decoding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Speculative decoding (SD) has emerged as an effective technique to accelerate\nlarge language model (LLM) inference without compromising output quality.\nHowever, the achievable speedup largely depends on the effectiveness of the\ndrafting model. While model-based methods like EAGLE-2 are accurate but costly,\nretrieval-enhanced methods like SAM-Decoding rely on heuristic switching\nstrategies that often trigger unnecessary retrievals. To address this, we\npropose ReSpec (\\textbf{Re}trieval-enhanced \\textbf{Spe}culative Decoding), a\nnovel framework that transforms heuristic drafter switching into adaptive\ndecision-making. ReSpec features three core innovations: 1) An\n\\textbf{entropy-guided adaptive trigger} quantifies contextual predictability\nto initiate retrieval only when uncertainty is low, avoiding costly low-quality\nspeculations. 2) A \\textbf{feedback-driven candidate selection} leverages\nhistorical feedback to organize multiple high-quality candidates for parallel\nverification, maximizing retrieval utility. 3) A source-aware \\textbf{relaxed\nverification strategy} applies strict checks to model-generated drafts while\nusing a relaxed verification for retrieved drafts, achieving a better balance\nbetween accuracy and efficiency. Extensive experiments on Spec-Bench\ndemonstrate that ReSpec achieves state-of-the-art acceleration,outperforming\nEAGLE-2 and SAM-Decoding by over $33\\%$ and $25\\%$, respectively, while\nmaintaining output quality.", "AI": {"tldr": "\u63d0\u51faReSpec\u6846\u67b6\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u6709\u4e09\u9879\u6838\u5fc3\u521b\u65b0\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u52a0\u901f\u6548\u679c\u8d85EAGLE - 2\u548cSAM - Decoding\uff0c\u4e14\u4fdd\u8bc1\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u6280\u672f\u4e2d\uff0c\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u6210\u672c\u9ad8\uff0c\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u6709\u4e0d\u5fc5\u8981\u68c0\u7d22\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faReSpec\u6846\u67b6\uff0c\u5305\u542b\u71b5\u5f15\u5bfc\u81ea\u9002\u5e94\u89e6\u53d1\u3001\u53cd\u9988\u9a71\u52a8\u5019\u9009\u9009\u62e9\u548c\u6e90\u611f\u77e5\u5bbd\u677e\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "\u5728Spec - Bench\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cReSpec\u6bd4EAGLE - 2\u548cSAM - Decoding\u5206\u522b\u63d0\u901f\u8d8533%\u548c25%\uff0c\u4e14\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "ReSpec\u80fd\u6709\u6548\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u66f4\u597d\u5e73\u8861\u3002"}}
{"id": "2511.01284", "pdf": "https://arxiv.org/pdf/2511.01284", "abs": "https://arxiv.org/abs/2511.01284", "authors": ["Karma Phuntsho", "Abdullah", "Kyungmi Lee", "Ickjai Lee", "Euijoon Ahn"], "title": "Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Foundation models (FMs) have emerged as a transformative paradigm in medical\nimage analysis, offering the potential to provide generalizable, task-agnostic\nsolutions across a wide range of clinical tasks and imaging modalities. Their\ncapacity to learn transferable representations from large-scale data has the\npotential to address the limitations of conventional task-specific models.\nHowever, adaptation of FMs to real-world clinical practice remains constrained\nby key challenges, including domain shifts, limited availability of\nhigh-quality annotated data, substantial computational demands, and strict\nprivacy requirements. This review presents a comprehensive assessment of\nstrategies for adapting FMs to the specific demands of medical imaging. We\nexamine approaches such as supervised fine-tuning, domain-specific pretraining,\nparameter-efficient fine-tuning, self-supervised learning, hybrid methods, and\nmultimodal or cross-modal frameworks. For each, we evaluate reported\nperformance gains, clinical applicability, and limitations, while identifying\ntrade-offs and unresolved challenges that prior reviews have often overlooked.\nBeyond these established techniques, we also highlight emerging directions\naimed at addressing current gaps. These include continual learning to enable\ndynamic deployment, federated and privacy-preserving approaches to safeguard\nsensitive data, hybrid self-supervised learning to enhance data efficiency,\ndata-centric pipelines that combine synthetic generation with human-in-the-loop\nvalidation, and systematic benchmarking to assess robust generalization under\nreal-world clinical variability. By outlining these strategies and associated\nresearch gaps, this review provides a roadmap for developing adaptive,\ntrustworthy, and clinically integrated FMs capable of meeting the demands of\nreal-world medical imaging.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u9002\u5e94\u533b\u5b66\u6210\u50cf\u9700\u6c42\u7684\u7b56\u7565\uff0c\u5206\u6790\u73b0\u6709\u65b9\u6cd5\u4f18\u52a3\u52bf\uff0c\u6307\u51fa\u65b0\u5174\u65b9\u5411\u548c\u7814\u7a76\u5dee\u8ddd\uff0c\u4e3a\u5f00\u53d1\u9002\u7528\u6a21\u578b\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u5206\u6790\u6709\u6f5c\u529b\uff0c\u4f46\u9002\u5e94\u5b9e\u9645\u4e34\u5e8a\u5b9e\u8df5\u5b58\u5728\u8bf8\u591a\u6311\u6218\uff0c\u9700\u8bc4\u4f30\u9002\u5e94\u7b56\u7565\u3002", "method": "\u7814\u7a76\u76d1\u7763\u5fae\u8c03\u3001\u7279\u5b9a\u9886\u57df\u9884\u8bad\u7ec3\u7b49\u591a\u79cd\u9002\u5e94\u7b56\u7565\uff0c\u8bc4\u4f30\u5176\u6027\u80fd\u3001\u4e34\u5e8a\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "result": "\u5206\u6790\u4e86\u5404\u7b56\u7565\u7684\u8868\u73b0\u3001\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\uff0c\u6307\u51fa\u4e86\u65b0\u5174\u65b9\u5411\u548c\u7814\u7a76\u5dee\u8ddd\u3002", "conclusion": "\u7efc\u8ff0\u4e3a\u5f00\u53d1\u9002\u5e94\u3001\u53ef\u9760\u4e14\u4e34\u5e8a\u53ef\u7528\u7684\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2511.00886", "pdf": "https://arxiv.org/pdf/2511.00886", "abs": "https://arxiv.org/abs/2511.00886", "authors": ["Kyriakos Georgiou", "Gianluca Fabiani", "Constantinos Siettos", "Athanasios N. Yannacopoulos"], "title": "HEATNETs: Explainable Random Feature Neural Networks for High-Dimensional Parabolic PDEs", "categories": ["math.NA", "cs.LG", "cs.NA", "65C05, 35K15, 35K08"], "comment": null, "summary": "We deal with the solution of the forward problem for high-dimensional\nparabolic PDEs with random feature (projection) neural networks (RFNNs). We\nfirst prove that there exists a single-hidden layer neural network with\nrandomized heat-kernels arising from the fundamental solution (Green's\nfunctions) of the heat operator, that we call HEATNET, that provides an\nunbiased universal approximator to the solution of parabolic PDEs in arbitrary\n(high) dimensions, with the rate of convergence being analogous to the\n${O}(N^{-1/2})$, where $N$ is the size of HEATNET. Thus, HEATNETs are\nexplainable schemes, based on the analytical framework of parabolic PDEs,\nexploiting insights from physics-informed neural networks aided by numerical\nand functional analysis, and the structure of the corresponding solution\noperators. Importantly, we show how HEATNETs can be scaled up for the efficient\nnumerical solution of arbitrary high-dimensional parabolic PDEs using suitable\ntransformations and importance Monte Carlo sampling of the integral\nrepresentation of the solution, in order to deal with the singularities of the\nheat kernel around the collocation points. We evaluate the performance of\nHEATNETs through benchmark linear parabolic problems up to 2,000 dimensions. We\nshow that HEATNETs result in remarkable accuracy with the order of the\napproximation error ranging from $1.0E-05$ to $1.0E-07$ for problems up to 500\ndimensions, and of the order of $1.0E-04$ to $1.0E-03$ for 1,000 to 2,000\ndimensions, with a relatively low number (up to 15,000) of features.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u968f\u673a\u7279\u5f81\uff08\u6295\u5f71\uff09\u795e\u7ecf\u7f51\u7edc\uff08RFNNs\uff09\u89e3\u51b3\u9ad8\u7ef4\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6b63\u95ee\u9898\uff0c\u63d0\u51faHEATNET\uff0c\u8bc1\u660e\u5176\u80fd\u903c\u8fd1\u89e3\uff0c\u7ed9\u51fa\u6536\u655b\u7387\uff0c\u5c55\u793a\u5176\u53ef\u6269\u5c55\u6027\u5e76\u901a\u8fc7\u57fa\u51c6\u95ee\u9898\u8bc4\u4f30\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ef4\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6b63\u95ee\u9898\uff0c\u5bfb\u6c42\u6709\u6548\u7684\u6570\u503c\u89e3\u6cd5\u3002", "method": "\u63d0\u51fa\u5177\u6709\u968f\u673a\u70ed\u6838\u7684\u5355\u9690\u85cf\u5c42\u795e\u7ecf\u7f51\u7edcHEATNET\uff0c\u5229\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u3001\u6570\u503c\u548c\u6cdb\u51fd\u5206\u6790\u4ee5\u53ca\u89e3\u7b97\u5b50\u7ed3\u6784\uff0c\u7ed3\u5408\u5408\u9002\u53d8\u6362\u548c\u91cd\u8981\u6027\u8499\u7279\u5361\u7f57\u91c7\u6837\u5904\u7406\u70ed\u6838\u5947\u70b9\u3002", "result": "HEATNET\u5728\u9ad8\u8fbe2000\u7ef4\u7684\u57fa\u51c6\u7ebf\u6027\u629b\u7269\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u51c6\u786e\u6027\uff0c500\u7ef4\u4ee5\u4e0b\u8fd1\u4f3c\u8bef\u5dee\u4e3a$1.0E - 05$\u5230$1.0E - 07$\uff0c1000\u52302000\u7ef4\u4e3a$1.0E - 04$\u5230$1.0E - 03$\uff0c\u7279\u5f81\u6570\u91cf\u76f8\u5bf9\u8f83\u5c11\u3002", "conclusion": "HEATNET\u662f\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u65b9\u6848\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u4efb\u610f\u9ad8\u7ef4\u629b\u7269\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u3002"}}
{"id": "2511.01305", "pdf": "https://arxiv.org/pdf/2511.01305", "abs": "https://arxiv.org/abs/2511.01305", "authors": ["Aman Ganapathy Manvattira", "Yifei Xu", "Ziyue Dang", "Songwu Lu"], "title": "DeepSpecs: Expert-Level Questions Answering in 5G", "categories": ["cs.CL", "cs.AI", "cs.NI"], "comment": null, "summary": "5G technology enables mobile Internet access for billions of users. Answering\nexpert-level questions about 5G specifications requires navigating thousands of\npages of cross-referenced standards that evolve across releases. Existing\nretrieval-augmented generation (RAG) frameworks, including telecom-specific\napproaches, rely on semantic similarity and cannot reliably resolve\ncross-references or reason about specification evolution. We present DeepSpecs,\na RAG system enhanced by structural and temporal reasoning via three\nmetadata-rich databases: SpecDB (clause-aligned specification text), ChangeDB\n(line-level version diffs), and TDocDB (standardization meeting documents).\nDeepSpecs explicitly resolves cross-references by recursively retrieving\nreferenced clauses through metadata lookup, and traces specification evolution\nby mining changes and linking them to Change Requests that document design\nrationale. We curate two 5G QA datasets: 573 expert-annotated real-world\nquestions from practitioner forums and educational resources, and 350\nevolution-focused questions derived from approved Change Requests. Across\nmultiple LLM backends, DeepSpecs outperforms base models and state-of-the-art\ntelecom RAG systems; ablations confirm that explicit cross-reference resolution\nand evolution-aware retrieval substantially improve answer quality,\nunderscoring the value of modeling the structural and temporal properties of 5G\nstandards.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u540d\u4e3aDeepSpecs\u7684RAG\u7cfb\u7edf\uff0c\u53ef\u5904\u74065G\u89c4\u8303\u95ee\u7b54\uff0c\u5728\u591aLLM\u540e\u7aef\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709RAG\u6846\u67b6\u65e0\u6cd5\u53ef\u9760\u89e3\u51b35G\u89c4\u8303\u4e2d\u7684\u4ea4\u53c9\u5f15\u7528\u548c\u89c4\u8303\u6f14\u53d8\u63a8\u7406\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e09\u4e2a\u5143\u6570\u636e\u4e30\u5bcc\u7684\u6570\u636e\u5e93\uff0c\u901a\u8fc7\u5143\u6570\u636e\u67e5\u627e\u9012\u5f52\u68c0\u7d22\u5f15\u7528\u6761\u6b3e\uff0c\u6316\u6398\u53d8\u66f4\u5e76\u5173\u8054\u53d8\u66f4\u8bf7\u6c42\u3002", "result": "\u5728\u591a\u4e2aLLM\u540e\u7aef\u4e0a\uff0cDeepSpecs\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u548c\u5148\u8fdb\u7684\u7535\u4fe1RAG\u7cfb\u7edf\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u76f8\u5173\u529f\u80fd\u63d0\u5347\u7b54\u6848\u8d28\u91cf\u3002", "conclusion": "\u5bf95G\u6807\u51c6\u7684\u7ed3\u6784\u548c\u65f6\u95f4\u5c5e\u6027\u5efa\u6a21\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.00919", "pdf": "https://arxiv.org/pdf/2511.00919", "abs": "https://arxiv.org/abs/2511.00919", "authors": ["Mahdi Maleki", "Reza Agahzadeh Ayoubi", "Marouan Mizmizi", "Umberto Spagnolini"], "title": "Towards Channel Charting Enhancement with Non-Reconfigurable Intelligent Surfaces", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "We investigate how fully-passive electromagnetic skins (EMSs) can be\nengineered to enhance channel charting (CC) in dense urban environments. We\nemploy two complementary state-of-the-art CC techniques, semi-supervised\nt-distributed stochastic neighbor embedding (t-SNE) and a semi-supervised\nAutoencoder (AE), to verify the consistency of results across nonparametric and\nparametric mappings. We show that the accuracy of CC hinges on a balance\nbetween signal-to-noise ratio (SNR) and spatial dissimilarity: EMS codebooks\nthat only maximize gain, as in conventional Reconfigurable Intelligent Surface\n(RIS) optimization, suppress location fingerprints and degrade CC, while\nrandomized phases increase diversity but reduce SNR. To address this trade-off,\nwe design static EMS phase profiles via a quantile-driven criterion that\ntargets worst-case users and improves both trustworthiness and continuity. In a\n3D ray-traced city at 30 GHz, the proposed EMS reduces the 90th-percentile\nlocalization error from > 50 m to < 25 m for both t-SNE and AE-based CC, and\ndecreases severe trajectory dropouts by over 4x under 15% supervision. The\nimprovements hold consistently across the evaluated configurations,\nestablishing static, pre-configured EMS as a practical enabler of CC without\nreconfiguration overheads.", "AI": {"tldr": "\u7814\u7a76\u5168\u88ab\u52a8\u7535\u78c1\u76ae\uff08EMS\uff09\u5728\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u589e\u5f3a\u4fe1\u9053\u6d4b\u7ed8\uff08CC\uff09\u7684\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u9759\u6001EMS\u76f8\u4f4d\u5256\u9762\uff0c\u57283D\u5c04\u7ebf\u8ffd\u8e2a\u57ce\u5e02\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5229\u7528\u5168\u88ab\u52a8\u7535\u78c1\u76ae\u589e\u5f3a\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u4fe1\u9053\u6d4b\u7ed8\u3002", "method": "\u91c7\u7528\u534a\u76d1\u7763t - \u5206\u5e03\u968f\u673a\u90bb\u57df\u5d4c\u5165\uff08t - SNE\uff09\u548c\u534a\u76d1\u7763\u81ea\u52a8\u7f16\u7801\u5668\uff08AE\uff09\u4e24\u79cdCC\u6280\u672f\u9a8c\u8bc1\u7ed3\u679c\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u9a71\u52a8\u51c6\u5219\u8bbe\u8ba1\u9759\u6001EMS\u76f8\u4f4d\u5256\u9762\u3002", "result": "\u572830GHz\u76843D\u5c04\u7ebf\u8ffd\u8e2a\u57ce\u5e02\u4e2d\uff0c\u63d0\u51fa\u7684EMS\u5c0690%\u5206\u4f4d\u6570\u5b9a\u4f4d\u8bef\u5dee\u4ece>50m\u964d\u81f3<25m\uff0c\u572815%\u76d1\u7763\u4e0b\u5c06\u4e25\u91cd\u8f68\u8ff9\u4e22\u5931\u51cf\u5c11\u8d854\u500d\u3002", "conclusion": "\u9759\u6001\u3001\u9884\u914d\u7f6e\u7684EMS\u662f\u65e0\u9700\u91cd\u65b0\u914d\u7f6e\u5f00\u9500\u7684CC\u5b9e\u7528\u4fc3\u6210\u56e0\u7d20\u3002"}}
{"id": "2511.01307", "pdf": "https://arxiv.org/pdf/2511.01307", "abs": "https://arxiv.org/abs/2511.01307", "authors": ["Tae-Young Lee", "Juwon Seo", "Jong Hwan Ko", "Gyeong-Moon Park"], "title": "Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": "26 pages, 9 figures, 16 tables, NeurIPS 2025", "summary": "Recent advances in diffusion models have enabled high-quality synthesis of\nspecific subjects, such as identities or objects. This capability, while\nunlocking new possibilities in content creation, also introduces significant\nprivacy risks, as personalization techniques can be misused by malicious users\nto generate unauthorized content. Although several studies have attempted to\ncounter this by generating adversarially perturbed samples designed to disrupt\npersonalization, they rely on unrealistic assumptions and become ineffective in\nthe presence of even a few clean images or under simple image transformations.\nTo address these challenges, we shift the protection target from the images to\nthe diffusion model itself to hinder the personalization of specific subjects,\nthrough our novel framework called Anti-Personalized Diffusion Models (APDM).\nWe first provide a theoretical analysis demonstrating that a naive approach of\nexisting loss functions to diffusion models is inherently incapable of ensuring\nconvergence for robust anti-personalization. Motivated by this finding, we\nintroduce Direct Protective Optimization (DPO), a novel loss function that\neffectively disrupts subject personalization in the target model without\ncompromising generative quality. Moreover, we propose a new dual-path\noptimization strategy, coined Learning to Protect (L2P). By alternating between\npersonalization and protection paths, L2P simulates future personalization\ntrajectories and adaptively reinforces protection at each step. Experimental\nresults demonstrate that our framework outperforms existing methods, achieving\nstate-of-the-art performance in preventing unauthorized personalization. The\ncode is available at https://github.com/KU-VGI/APDM.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faAnti - Personalized Diffusion Models (APDM)\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u635f\u5931\u51fd\u6570DPO\u548c\u4f18\u5316\u7b56\u7565L2P\uff0c\u9632\u6b62\u6269\u6563\u6a21\u578b\u7279\u5b9a\u4e3b\u4f53\u7684\u975e\u6388\u6743\u4e2a\u6027\u5316\uff0c\u5b9e\u9a8c\u6548\u679c\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u5185\u5bb9\u521b\u4f5c\u5e26\u6765\u65b0\u53ef\u80fd\u540c\u65f6\u5f15\u5165\u9690\u79c1\u98ce\u9669\uff0c\u73b0\u6709\u5bf9\u6297\u6270\u52a8\u6837\u672c\u65b9\u6cd5\u6709\u5c40\u9650\u6027\uff0c\u9700\u65b0\u65b9\u6cd5\u963b\u788d\u7279\u5b9a\u4e3b\u4f53\u4e2a\u6027\u5316\u3002", "method": "\u63d0\u51faAPDM\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u635f\u5931\u51fd\u6570Direct Protective Optimization (DPO)\uff0c\u63d0\u51fa\u65b0\u7684\u53cc\u8def\u5f84\u4f18\u5316\u7b56\u7565Learning to Protect (L2P)\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAPDM\u6846\u67b6\u5728\u9632\u6b62\u975e\u6388\u6743\u4e2a\u6027\u5316\u65b9\u9762\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "APDM\u6846\u67b6\u80fd\u6709\u6548\u963b\u788d\u6269\u6563\u6a21\u578b\u7279\u5b9a\u4e3b\u4f53\u7684\u4e2a\u6027\u5316\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.00999", "pdf": "https://arxiv.org/pdf/2511.00999", "abs": "https://arxiv.org/abs/2511.00999", "authors": ["Julian Streit", "Franziska Weindel", "Reinhard Heckel"], "title": "Transformer-Based Decoding in Concatenated Coding Schemes Under Synchronization Errors", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": "16 pages, 19 figures, a shortened version was published in the ISIT\n  2025 conference", "summary": "We consider the reconstruction of a codeword from multiple noisy copies that\nare independently corrupted by insertions, deletions, and substitutions. This\nproblem arises, for example, in DNA data storage. A common code construction\nuses a concatenated coding scheme that combines an outer linear block code with\nan inner code, which can be either a nonlinear marker code or a convolutional\ncode. Outer decoding is done with Belief Propagation, and inner decoding is\ndone with the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm. However, the BCJR\nalgorithm scales exponentially with the number of noisy copies, which makes it\ninfeasible to reconstruct a codeword from more than about four copies. In this\nwork, we introduce BCJRFormer, a transformer-based neural inner decoder.\nBCJRFormer achieves error rates comparable to the BCJR algorithm for binary and\nquaternary single-message transmissions of marker codes. Importantly,\nBCJRFormer scales quadratically with the number of noisy copies. This property\nmakes BCJRFormer well-suited for DNA data storage, where multiple reads of the\nsame DNA strand occur. To lower error rates, we replace the Belief Propagation\nouter decoder with a transformer-based decoder. Together, these modifications\nyield an efficient and performant end-to-end transformer-based pipeline for\ndecoding multiple noisy copies affected by insertion, deletion, and\nsubstitution errors. Additionally, we propose a novel cross-attending\ntransformer architecture called ConvBCJRFormer. This architecture extends\nBCJRFormer to decode transmissions of convolutional codewords, serving as an\ninitial step toward joint inner and outer decoding for more general linear code\nclasses.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u5185\u89e3\u7801\u5668BCJRFormer\uff0c\u66ff\u6362BP\u5916\u89e3\u7801\u5668\uff0c\u63d0\u51faConvBCJRFormer\u67b6\u6784\uff0c\u6784\u5efa\u9ad8\u6548\u7aef\u5230\u7aef\u89e3\u7801\u7ba1\u9053\u3002", "motivation": "\u73b0\u6709BCJR\u7b97\u6cd5\u5728\u5904\u7406\u591a\u4e2a\u566a\u58f0\u526f\u672c\u65f6\u590d\u6742\u5ea6\u5448\u6307\u6570\u589e\u957f\uff0c\u96be\u4ee5\u91cd\u5efa\u7801\u5b57\uff0c\u9700\u66f4\u9ad8\u6548\u65b9\u6cd5\u7528\u4e8eDNA\u6570\u636e\u5b58\u50a8\u3002", "method": "\u5f15\u5165BCJRFormer\u5185\u89e3\u7801\u5668\uff0c\u7528\u57fa\u4e8eTransformer\u7684\u89e3\u7801\u5668\u66ff\u6362BP\u5916\u89e3\u7801\u5668\uff0c\u63d0\u51faConvBCJRFormer\u67b6\u6784\u3002", "result": "BCJRFormer\u5728\u6807\u8bb0\u7801\u5355\u6d88\u606f\u4f20\u8f93\u4e2d\u9519\u8bef\u7387\u4e0eBCJR\u7b97\u6cd5\u76f8\u5f53\uff0c\u590d\u6742\u5ea6\u5448\u4e8c\u6b21\u65b9\u589e\u957f\uff1b\u6784\u5efa\u4e86\u9ad8\u6548\u7aef\u5230\u7aef\u89e3\u7801\u7ba1\u9053\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6784\u5efa\u4e86\u9ad8\u6548\u4e14\u6027\u80fd\u826f\u597d\u7684\u7aef\u5230\u7aef\u89e3\u7801\u7ba1\u9053\uff0cConvBCJRFormer\u4e3a\u66f4\u901a\u7528\u7ebf\u6027\u7801\u7c7b\u7684\u8054\u5408\u5185\u5916\u89e3\u7801\u8fc8\u51fa\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2511.01323", "pdf": "https://arxiv.org/pdf/2511.01323", "abs": "https://arxiv.org/abs/2511.01323", "authors": ["Jiabao Ji", "Min Li", "Priyanshu Kumar", "Shiyu Chang", "Saloni Potdar"], "title": "DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages", "summary": "Large language models (LLMs) with integrated search tools show strong promise\nin open-domain question answering (QA), yet they often struggle to produce\ncomplete answer set to complex questions such as Which actor from the film Heat\nwon at least one Academy Award?, which requires (1) distinguishing between\nmultiple films sharing the same title and (2) reasoning across a large set of\nactors to gather and integrate evidence. Existing QA benchmarks rarely evaluate\nboth challenges jointly. To address this, we introduce DeepAmbigQAGen, an\nautomatic data generation pipeline that constructs QA tasks grounded in text\ncorpora and linked knowledge graph, generating natural and verifiable questions\nthat systematically embed name ambiguity and multi-step reasoning. Based on\nthis, we build DeepAmbigQA, a dataset of 3,600 questions requiring multi-hop\nreasoning and half of them explicit name ambiguity resolving. Experiments\nreveal that, even state-of-the-art GPT-5 show incomplete answers, achieving\nonly 0.13 exact match on ambiguous questions and 0.21 on non-ambiguous\nquestions. These findings highlight the need for more robust QA systems aimed\nat information gathering and answer completeness.", "AI": {"tldr": "\u4ecb\u7ecdDeepAmbigQAGen\u6570\u636e\u751f\u6210\u7ba1\u9053\u548cDeepAmbigQA\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u73b0\u6709\u6a21\u578b\u5904\u7406\u590d\u6742\u95ee\u9898\u80fd\u529b\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709QA\u57fa\u51c6\u5f88\u5c11\u540c\u65f6\u8bc4\u4f30\u533a\u5206\u540c\u540d\u7535\u5f71\u548c\u591a\u6b65\u63a8\u7406\u4e24\u4e2a\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165DeepAmbigQAGen\u81ea\u52a8\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u57fa\u4e8e\u6b64\u6784\u5efaDeepAmbigQA\u6570\u636e\u96c6\u3002", "result": "\u5373\u4f7f\u662fGPT - 5\u5728\u6a21\u7cca\u95ee\u9898\u4e0a\u7cbe\u786e\u5339\u914d\u7387\u4ec50.13\uff0c\u975e\u6a21\u7cca\u95ee\u9898\u4e3a0.21\u3002", "conclusion": "\u9700\u8981\u66f4\u5f3a\u5927\u7684QA\u7cfb\u7edf\u4ee5\u786e\u4fdd\u4fe1\u606f\u6536\u96c6\u548c\u7b54\u6848\u5b8c\u6574\u6027\u3002"}}
{"id": "2511.01000", "pdf": "https://arxiv.org/pdf/2511.01000", "abs": "https://arxiv.org/abs/2511.01000", "authors": ["Hassan Ugail", "Ismail Lujain Jaleel"], "title": "Integrating Visual and X-Ray Machine Learning Features in the Study of Paintings by Goya", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Art authentication of Francisco Goya's works presents complex computational\nchallenges due to his heterogeneous stylistic evolution and extensive\nhistorical patterns of forgery. We introduce a novel multimodal machine\nlearning framework that applies identical feature extraction techniques to both\nvisual and X-ray radiographic images of Goya paintings. The unified feature\nextraction pipeline incorporates Grey-Level Co-occurrence Matrix descriptors,\nLocal Binary Patterns, entropy measures, energy calculations, and colour\ndistribution analysis applied consistently across both imaging modalities. The\nextracted features from both visual and X-ray images are processed through an\noptimised One-Class Support Vector Machine with hyperparameter tuning. Using a\ndataset of 24 authenticated Goya paintings with corresponding X-ray images,\nsplit into an 80/20 train-test configuration with 10-fold cross-validation, the\nframework achieves 97.8% classification accuracy with a 0.022 false positive\nrate. Case study analysis of ``Un Gigante'' demonstrates the practical efficacy\nof our pipeline, achieving 92.3% authentication confidence through unified\nmultimodal feature analysis. Our results indicate substantial performance\nimprovement over single-modal approaches, establishing the effectiveness of\napplying identical computational methods to both visual and radiographic\nimagery in art authentication applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u6a21\u6001\u673a\u5668\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u6208\u96c5\u753b\u4f5c\u771f\u4f2a\u9274\u5b9a\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\uff0c\u6bd4\u5355\u6a21\u6001\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u7531\u4e8e\u6208\u96c5\u4f5c\u54c1\u98ce\u683c\u6f14\u53d8\u591a\u6837\u548c\u5b58\u5728\u5927\u91cf\u4f2a\u9020\u60c5\u51b5\uff0c\u5176\u753b\u4f5c\u771f\u4f2a\u9274\u5b9a\u9762\u4e34\u590d\u6742\u8ba1\u7b97\u6311\u6218\u3002", "method": "\u5f15\u5165\u591a\u6a21\u6001\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5bf9\u753b\u4f5c\u89c6\u89c9\u548cX\u5c04\u7ebf\u56fe\u50cf\u91c7\u7528\u76f8\u540c\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u5305\u62ecGLCM\u63cf\u8ff0\u7b26\u3001LBP\u7b49\uff0c\u5c06\u63d0\u53d6\u7279\u5f81\u8f93\u5165\u4f18\u5316\u7684\u5355\u7c7b\u652f\u6301\u5411\u91cf\u673a\u5e76\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u4f18\u3002", "result": "\u572824\u5e45\u753b\u4f5c\u6570\u636e\u96c6\u4e0a\u5206\u7c7b\u51c6\u786e\u7387\u8fbe97.8%\uff0c\u8bef\u62a5\u73870.022\uff1b\u6848\u4f8b\u5206\u6790\u4e2d\u8ba4\u8bc1\u7f6e\u4fe1\u5ea6\u8fbe92.3%\u3002", "conclusion": "\u8be5\u6846\u67b6\u6bd4\u5355\u6a21\u6001\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u663e\u8457\uff0c\u8bc1\u660e\u5bf9\u89c6\u89c9\u548c\u5c04\u7ebf\u56fe\u50cf\u5e94\u7528\u76f8\u540c\u8ba1\u7b97\u65b9\u6cd5\u5728\u827a\u672f\u9274\u5b9a\u4e2d\u6709\u6548\u3002"}}
{"id": "2511.01334", "pdf": "https://arxiv.org/pdf/2511.01334", "abs": "https://arxiv.org/abs/2511.01334", "authors": ["Ling Niu", "Xiaoji Zheng", "Han Wang", "Chen Zheng", "Ziyuan Yang", "Bokui Chen", "Jiangtao Gong"], "title": "Embodied Cognition Augmented End2End Autonomous Driving", "categories": ["cs.RO", "cs.AI", "cs.HC", "68T45"], "comment": "24 pages,4 pages", "summary": "In recent years, vision-based end-to-end autonomous driving has emerged as a\nnew paradigm. However, popular end-to-end approaches typically rely on visual\nfeature extraction networks trained under label supervision. This limited\nsupervision framework restricts the generality and applicability of driving\nmodels. In this paper, we propose a novel paradigm termed $E^{3}AD$, which\nadvocates for comparative learning between visual feature extraction networks\nand the general EEG large model, in order to learn latent human driving\ncognition for enhancing end-to-end planning. In this work, we collected a\ncognitive dataset for the mentioned contrastive learning process. Subsequently,\nwe investigated the methods and potential mechanisms for enhancing end-to-end\nplanning with human driving cognition, using popular driving models as\nbaselines on publicly available autonomous driving datasets. Both open-loop and\nclosed-loop tests are conducted for a comprehensive evaluation of planning\nperformance. Experimental results demonstrate that the $E^{3}AD$ paradigm\nsignificantly enhances the end-to-end planning performance of baseline models.\nAblation studies further validate the contribution of driving cognition and the\neffectiveness of comparative learning process. To the best of our knowledge,\nthis is the first work to integrate human driving cognition for improving\nend-to-end autonomous driving planning. It represents an initial attempt to\nincorporate embodied cognitive data into end-to-end autonomous driving,\nproviding valuable insights for future brain-inspired autonomous driving\nsystems. Our code will be made available at Github", "AI": {"tldr": "\u672c\u6587\u63d0\u51faE\u00b3AD\u8303\u5f0f\uff0c\u7ed3\u5408\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\u4e0eEEG\u5927\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\uff0c\u63d0\u5347\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6807\u7b7e\u76d1\u7763\u8bad\u7ec3\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u65b9\u6cd5\u9650\u5236\u4e86\u6a21\u578b\u901a\u7528\u6027\u548c\u9002\u7528\u6027\uff0c\u9700\u65b0\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faE\u00b3AD\u8303\u5f0f\uff0c\u6536\u96c6\u8ba4\u77e5\u6570\u636e\u96c6\uff0c\u7528\u6d41\u884c\u9a7e\u9a76\u6a21\u578b\u4f5c\u57fa\u7ebf\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7814\u7a76\u5229\u7528\u4eba\u7c7b\u9a7e\u9a76\u8ba4\u77e5\u589e\u5f3a\u7aef\u5230\u7aef\u89c4\u5212\u7684\u65b9\u6cd5\u548c\u673a\u5236\uff0c\u8fdb\u884c\u5f00\u73af\u548c\u95ed\u73af\u6d4b\u8bd5\u3002", "result": "E\u00b3AD\u8303\u5f0f\u663e\u8457\u63d0\u5347\u57fa\u7ebf\u6a21\u578b\u7aef\u5230\u7aef\u89c4\u5212\u6027\u80fd\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u9a7e\u9a76\u8ba4\u77e5\u7684\u8d21\u732e\u548c\u5bf9\u6bd4\u5b66\u4e60\u8fc7\u7a0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u6574\u5408\u4eba\u7c7b\u9a7e\u9a76\u8ba4\u77e5\u6539\u8fdb\u7aef\u5230\u7aef\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u7684\u5de5\u4f5c\uff0c\u4e3a\u672a\u6765\u8111\u542f\u53d1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2511.01336", "pdf": "https://arxiv.org/pdf/2511.01336", "abs": "https://arxiv.org/abs/2511.01336", "authors": ["Ibrahim Khalilov", "Chaoran Chen", "Ziang Xiao", "Tianshi Li", "Toby Jia-Jun Li", "Yaxing Yao"], "title": "Beyond Permissions: Investigating Mobile Personalization with Simulated Personas", "categories": ["cs.HC", "cs.AI"], "comment": "8 pages, 7 figures. Accepted to the ACM Workshop on Human-Centered AI\n  Privacy and Security (HAIPS @ CCS 2025). DOI: 10.1145/3733816.3760758 (ACM\n  Digital Library link pending activation)", "summary": "Mobile applications increasingly rely on sensor data to infer user context\nand deliver personalized experiences. Yet the mechanisms behind this\npersonalization remain opaque to users and researchers alike. This paper\npresents a sandbox system that uses sensor spoofing and persona simulation to\naudit and visualize how mobile apps respond to inferred behaviors. Rather than\ntreating spoofing as adversarial, we demonstrate its use as a tool for\nbehavioral transparency and user empowerment. Our system injects multi-sensor\nprofiles - generated from structured, lifestyle-based personas - into Android\ndevices in real time, enabling users to observe app responses to contexts such\nas high activity, location shifts, or time-of-day changes. With automated\nscreenshot capture and GPT-4 Vision-based UI summarization, our pipeline helps\ndocument subtle personalization cues. Preliminary findings show measurable app\nadaptations across fitness, e-commerce, and everyday service apps such as\nweather and navigation. We offer this toolkit as a foundation for\nprivacy-enhancing technologies and user-facing transparency interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6c99\u76d2\u7cfb\u7edf\uff0c\u7528\u4f20\u611f\u5668\u6b3a\u9a97\u548c\u89d2\u8272\u6a21\u62df\u5ba1\u8ba1\u5e76\u53ef\u89c6\u5316\u79fb\u52a8\u5e94\u7528\u5bf9\u63a8\u65ad\u884c\u4e3a\u7684\u54cd\u5e94\uff0c\u6709\u521d\u6b65\u6210\u679c\u5e76\u63d0\u4f9b\u5de5\u5177\u5305\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u4f9d\u8d56\u4f20\u611f\u5668\u6570\u636e\u5b9e\u73b0\u4e2a\u6027\u5316\uff0c\u4f46\u4e2a\u6027\u5316\u673a\u5236\u5bf9\u7528\u6237\u548c\u7814\u7a76\u4eba\u5458\u4e0d\u900f\u660e\uff0c\u9700\u8981\u63d0\u9ad8\u900f\u660e\u5ea6\u3002", "method": "\u6784\u5efa\u6c99\u76d2\u7cfb\u7edf\uff0c\u5c06\u57fa\u4e8e\u751f\u6d3b\u65b9\u5f0f\u89d2\u8272\u751f\u6210\u7684\u591a\u4f20\u611f\u5668\u914d\u7f6e\u6587\u4ef6\u5b9e\u65f6\u6ce8\u5165\u5b89\u5353\u8bbe\u5907\uff0c\u7ed3\u5408\u81ea\u52a8\u622a\u56fe\u548cGPT - 4 Vision\u8fdb\u884cUI\u603b\u7ed3\u3002", "result": "\u521d\u6b65\u53d1\u73b0\u5065\u8eab\u3001\u7535\u5546\u3001\u65e5\u5e38\u670d\u52a1\uff08\u5982\u5929\u6c14\u548c\u5bfc\u822a\uff09\u7c7b\u5e94\u7528\u6709\u53ef\u6d4b\u91cf\u7684\u9002\u5e94\u53d8\u5316\u3002", "conclusion": "\u63d0\u4f9b\u7684\u5de5\u5177\u5305\u53ef\u4f5c\u4e3a\u589e\u5f3a\u9690\u79c1\u6280\u672f\u548c\u9762\u5411\u7528\u6237\u7684\u900f\u660e\u5ea6\u5e72\u9884\u7684\u57fa\u7840\u3002"}}
{"id": "2511.01353", "pdf": "https://arxiv.org/pdf/2511.01353", "abs": "https://arxiv.org/abs/2511.01353", "authors": ["Zafar Imam Khan"], "title": "AI Literacy in UAE Libraries: Assessing Competencies, Training Needs, and Ethical Considerations for the Digital Age", "categories": ["cs.DL", "cs.AI"], "comment": "This is the accepted manuscript version. The final published version\n  will appear in College & Research Libraries, November 2026", "summary": "The study explores the current state of artificial intelligence (AI) literacy\nlevels among library professionals employing a quantitative approach consisting\nof 92 surveys of LIS professionals in the United Arab Emirates (UAE). Findings\nof the study revealed the presence of strong cognitive competencies, while\nthere were gaps observed in behavioral and normative competencies, especially\nrelated to AI biases, AI-powered learning, and ethical considerations. There\nwas a disconnect observed between the perceived importance of AI skills and the\neffectiveness of the current training programs.", "AI": {"tldr": "\u7814\u7a76\u91c7\u7528\u5b9a\u91cf\u65b9\u6cd5\u8c03\u67e5\u963f\u8054\u914b\u56fe\u4e66\u9986\u4fe1\u606f\u79d1\u5b66\u4e13\u4e1a\u4eba\u5458\u7684\u4eba\u5de5\u667a\u80fd\u7d20\u517b\uff0c\u53d1\u73b0\u8ba4\u77e5\u80fd\u529b\u5f3a\uff0c\u4f46\u884c\u4e3a\u548c\u89c4\u8303\u80fd\u529b\u6709\u5dee\u8ddd\uff0c\u4e14\u57f9\u8bad\u9879\u76ee\u6709\u6548\u6027\u4e0d\u8db3\u3002", "motivation": "\u63a2\u7d22\u56fe\u4e66\u9986\u4e13\u4e1a\u4eba\u5458\u7684\u4eba\u5de5\u667a\u80fd\u7d20\u517b\u73b0\u72b6\u3002", "method": "\u5bf9\u963f\u8054\u914b92\u540d\u56fe\u4e66\u9986\u4fe1\u606f\u79d1\u5b66\u4e13\u4e1a\u4eba\u5458\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\u7684\u5b9a\u91cf\u7814\u7a76\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u4e13\u4e1a\u4eba\u5458\u6709\u8f83\u5f3a\u7684\u8ba4\u77e5\u80fd\u529b\uff0c\u4f46\u5728\u884c\u4e3a\u548c\u89c4\u8303\u80fd\u529b\u4e0a\u5b58\u5728\u5dee\u8ddd\uff0c\u5c24\u5176\u5728\u4eba\u5de5\u667a\u80fd\u504f\u89c1\u3001\u4eba\u5de5\u667a\u80fd\u5b66\u4e60\u548c\u4f26\u7406\u8003\u91cf\u65b9\u9762\uff1b\u5f53\u524d\u57f9\u8bad\u9879\u76ee\u6709\u6548\u6027\u4e0e\u5bf9\u4eba\u5de5\u667a\u80fd\u6280\u80fd\u7684\u91cd\u89c6\u7a0b\u5ea6\u4e0d\u5339\u914d\u3002", "conclusion": "\u56fe\u4e66\u9986\u4e13\u4e1a\u4eba\u5458\u7684\u4eba\u5de5\u667a\u80fd\u7d20\u517b\u5b58\u5728\u80fd\u529b\u5dee\u8ddd\uff0c\u5f53\u524d\u57f9\u8bad\u9879\u76ee\u6548\u679c\u4e0d\u4f73\u3002"}}
{"id": "2511.01354", "pdf": "https://arxiv.org/pdf/2511.01354", "abs": "https://arxiv.org/abs/2511.01354", "authors": ["Wenrui Cai", "Chengyu Wang", "Junbing Yan", "Jun Huang", "Xiangzhong Fang"], "title": "Thinking with DistilQwen: A Tale of Four Distilled Reasoning and Reward Model Series", "categories": ["cs.CL", "cs.AI"], "comment": "emnlp 2025 industry track", "summary": "Recently, the demand for small and efficient reasoning models to support\nreal-world applications has driven the development of knowledge distillation\ntechniques that balance reasoning performance and inference speed. In this\npaper, we further extend the DistilQwen model family, initialized from the Qwen\nmodels, by introducing four model series specifically designed to meet\nindustrial requirements. The distilled model collection comprises: (1)\nslow-thinking models, optimized for reasoning tasks that require high accuracy;\n(2) two series of adaptive-thinking models, which dynamically adjust reasoning\nstrategies based on input tasks to maximize efficiency across diverse\nscenarios; and (3) distilled reward models, which enable further reinforcement\nlearning of reasoning models using distilled knowledge. Comprehensive\nevaluations across multiple benchmarks demonstrate both high inference\nefficiency and strong reasoning performance for these models, as well as the\npractical utility of distilled reward models. We further show that these models\nsupport industry practitioners by providing scalable training and inference\nfunctionalities on the Alibaba Cloud PAI (Platform for Artificial Intelligence)\nplatform.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55DistilQwen\u6a21\u578b\u5bb6\u65cf\uff0c\u5f15\u5165\u56db\u4e2a\u6a21\u578b\u7cfb\u5217\uff0c\u7ecf\u8bc4\u4f30\u5177\u9ad8\u6548\u63a8\u7406\u6027\u80fd\uff0c\u4e14\u652f\u6301\u963f\u91cc\u4e91PAI\u5e73\u53f0\u5e94\u7528\u3002", "motivation": "\u6ee1\u8db3\u73b0\u5b9e\u5e94\u7528\u5bf9\u5c0f\u800c\u9ad8\u6548\u63a8\u7406\u6a21\u578b\u7684\u9700\u6c42\uff0c\u5e73\u8861\u63a8\u7406\u6027\u80fd\u548c\u63a8\u7406\u901f\u5ea6\u3002", "method": "\u4eceQwen\u6a21\u578b\u521d\u59cb\u5316\uff0c\u5f15\u5165\u56db\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u4ee5\u6ee1\u8db3\u5de5\u4e1a\u9700\u6c42\u7684\u6a21\u578b\u7cfb\u5217\u3002", "result": "\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6a21\u578b\u63a8\u7406\u6548\u7387\u9ad8\u3001\u63a8\u7406\u6027\u80fd\u5f3a\uff0c\u84b8\u998f\u5956\u52b1\u6a21\u578b\u6709\u5b9e\u9645\u6548\u7528\uff0c\u4e14\u652f\u6301\u963f\u91cc\u4e91PAI\u5e73\u53f0\u7684\u53ef\u6269\u5c55\u8bad\u7ec3\u548c\u63a8\u7406\u529f\u80fd\u3002", "conclusion": "\u65b0\u6269\u5c55\u7684DistilQwen\u6a21\u578b\u5bb6\u65cf\u80fd\u6ee1\u8db3\u5de5\u4e1a\u9700\u6c42\uff0c\u4e3a\u884c\u4e1a\u4ece\u4e1a\u8005\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.01357", "pdf": "https://arxiv.org/pdf/2511.01357", "abs": "https://arxiv.org/abs/2511.01357", "authors": ["Qiangguo Jin", "Xianyao Zheng", "Hui Cui", "Changming Sun", "Yuqi Fang", "Cong Cong", "Ran Su", "Leyi Wei", "Ping Xuan", "Junbo Wang"], "title": "CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering", "categories": ["cs.CV", "cs.AI"], "comment": "The paper has been accepted by the 33rd Pacific Conference on\n  Computer Graphics and Applications (Pacific Graphics 2025)", "summary": "Medical visual question answering (Med-VQA) is a crucial multimodal task in\nclinical decision support and telemedicine. Recent self-attention based methods\nstruggle to effectively handle cross-modal semantic alignments between vision\nand language. Moreover, classification-based methods rely on predefined answer\nsets. Treating this task as a simple classification problem may make it unable\nto adapt to the diversity of free-form answers and overlook the detailed\nsemantic information of free-form answers. In order to tackle these challenges,\nwe introduce a Cross-Mamba Interaction based Multi-Task Learning (CMI-MTL)\nframework that learns cross-modal feature representations from images and\ntexts. CMI-MTL comprises three key modules: fine-grained visual-text feature\nalignment (FVTA), cross-modal interleaved feature representation (CIFR), and\nfree-form answer-enhanced multi-task learning (FFAE). FVTA extracts the most\nrelevant regions in image-text pairs through fine-grained visual-text feature\nalignment. CIFR captures cross-modal sequential interactions via cross-modal\ninterleaved feature representation. FFAE leverages auxiliary knowledge from\nopen-ended questions through free-form answer-enhanced multi-task learning,\nimproving the model's capability for open-ended Med-VQA. Experimental results\nshow that CMI-MTL outperforms the existing state-of-the-art methods on three\nMed-VQA datasets: VQA-RAD, SLAKE, and OVQA. Furthermore, we conduct more\ninterpretability experiments to prove the effectiveness. The code is publicly\navailable at https://github.com/BioMedIA-repo/CMI-MTL.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faCMI - MTL\u6846\u67b6\u89e3\u51b3Med - VQA\u4efb\u52a1\u96be\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u516c\u5f00\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u89c6\u89c9\u548c\u8bed\u8a00\u7684\u8de8\u6a21\u6001\u8bed\u4e49\u5bf9\u9f50\uff0c\u57fa\u4e8e\u5206\u7c7b\u7684\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u7b54\u6848\u96c6\uff0c\u65e0\u6cd5\u9002\u5e94\u81ea\u7531\u5f62\u5f0f\u7b54\u6848\u7684\u591a\u6837\u6027\u3002", "method": "\u5f15\u5165CMI - MTL\u6846\u67b6\uff0c\u5305\u542bFVTA\u3001CIFR\u548cFFAE\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff0c\u5206\u522b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u89c6\u89c9 - \u6587\u672c\u7279\u5f81\u5bf9\u9f50\u3001\u6355\u6349\u8de8\u6a21\u6001\u987a\u5e8f\u4ea4\u4e92\u3001\u5229\u7528\u81ea\u7531\u5f62\u5f0f\u7b54\u6848\u589e\u5f3a\u591a\u4efb\u52a1\u5b66\u4e60\u3002", "result": "CMI - MTL\u5728VQA - RAD\u3001SLAKE\u548cOVQA\u4e09\u4e2aMed - VQA\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e14\u53ef\u89e3\u91ca\u6027\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "conclusion": "CMI - MTL\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3Med - VQA\u4efb\u52a1\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u6a21\u578b\u5728\u5f00\u653e\u5f0fMed - VQA\u4e0a\u7684\u80fd\u529b\u3002"}}
{"id": "2511.01359", "pdf": "https://arxiv.org/pdf/2511.01359", "abs": "https://arxiv.org/abs/2511.01359", "authors": ["Sapir Harary", "Eran Hirsch", "Aviv Slobodkin", "David Wan", "Mohit Bansal", "Ido Dagan"], "title": "PrefixNLI: Detecting Factual Inconsistencies as Soon as They Arise", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages + appendix. Code, datasets, and models are available at\n  https://github.com/sapirharary/PrefixNLI", "summary": "Natural Language Inference (NLI) models have been used in various ways to\nimprove the factuality of LLM outputs. This is typically done by applying an\nNLI model to judge whether the model output is entailed from the supposed\nevidence, triggering some corrective actions, such as beam reranking at\ninference time or RL rewards during training. While NLI models are trained to\ndetect factual inconsistencies over complete sentences, decisions in the common\nautoregressive generation architecture are made for each evolving text prefix,\nduring decoding. Addressing this setting, we generalize the entailment\ndetection task to apply over arbitrary text prefixes, and suggest its utility\nfor improving generation faithfulness. Providing suitable evaluation and\ntraining datasets for this task, we train MiniTruePrefixes, a novel specialized\nmodel that better detects factual inconsistencies over text prefixes,\noutperforming comparable baseline NLI models by 5-14 F1 points in prefix-level\nentailment. We further demonstrate that integrating MiniTruePrefixes into a\ncontrolled decoding framework substantially improves factual consistency in\nabstractive summarization. When guided by MiniTruePrefixes,\nLLaMA-3.2-3B-Instruct matches the faithfulness and runtime of the 8B model from\nthe same model family, while using only half the memory.", "AI": {"tldr": "\u672c\u6587\u5c06\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u6a21\u578b\u5e94\u7528\u6269\u5c55\u5230\u4efb\u610f\u6587\u672c\u524d\u7f00\uff0c\u8bad\u7ec3\u4e86MiniTruePrefixes\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u66f4\u597d\u68c0\u6d4b\u6587\u672c\u524d\u7f00\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u6027\uff0c\u96c6\u6210\u5230\u89e3\u7801\u6846\u67b6\u53ef\u63d0\u5347\u6458\u8981\u751f\u6210\u4e8b\u5b9e\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709NLI\u6a21\u578b\u8bad\u7ec3\u7528\u4e8e\u5b8c\u6574\u53e5\u5b50\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u68c0\u6d4b\uff0c\u800c\u81ea\u56de\u5f52\u751f\u6210\u67b6\u6784\u51b3\u7b56\u57fa\u4e8e\u6587\u672c\u524d\u7f00\uff0c\u9700\u5c06NLI\u5e94\u7528\u6269\u5c55\u5230\u6587\u672c\u524d\u7f00\u4ee5\u63d0\u5347\u751f\u6210\u5fe0\u5b9e\u6027\u3002", "method": "\u5c06\u8574\u542b\u68c0\u6d4b\u4efb\u52a1\u6269\u5c55\u5230\u4efb\u610f\u6587\u672c\u524d\u7f00\uff0c\u63d0\u4f9b\u8bc4\u4f30\u548c\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u8bad\u7ec3MiniTruePrefixes\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u53d7\u63a7\u89e3\u7801\u6846\u67b6\u3002", "result": "MiniTruePrefixes\u5728\u6587\u672c\u524d\u7f00\u8574\u542b\u68c0\u6d4b\u4e0a\u6bd4\u57fa\u7ebfNLI\u6a21\u578bF1\u503c\u9ad85 - 14\u5206\uff0c\u96c6\u6210\u5230\u89e3\u7801\u6846\u67b6\u663e\u8457\u63d0\u5347\u6458\u8981\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u5982LLaMA - 3.2 - 3B - Instruct\u5728\u4f7f\u7528\u4e00\u534a\u5185\u5b58\u65f6\u8fbe\u5230\u540c\u7cfb\u52178B\u6a21\u578b\u7684\u5fe0\u5b9e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u6269\u5c55NLI\u5230\u6587\u672c\u524d\u7f00\u4ee5\u53ca\u8bad\u7ec3\u7684MiniTruePrefixes\u6a21\u578b\u80fd\u6709\u6548\u63d0\u5347\u751f\u6210\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u3002"}}
{"id": "2511.01107", "pdf": "https://arxiv.org/pdf/2511.01107", "abs": "https://arxiv.org/abs/2511.01107", "authors": ["Y. Isabel Liu", "Bowen Li", "Benjamin Eysenbach", "Tom Silver"], "title": "SLAP: Shortcut Learning for Abstract Planning", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Long-horizon decision-making with sparse rewards and continuous states and\nactions remains a fundamental challenge in AI and robotics. Task and motion\nplanning (TAMP) is a model-based framework that addresses this challenge by\nplanning hierarchically with abstract actions (options). These options are\nmanually defined, limiting the agent to behaviors that we as human engineers\nknow how to program (pick, place, move). In this work, we propose Shortcut\nLearning for Abstract Planning (SLAP), a method that leverages existing TAMP\noptions to automatically discover new ones. Our key idea is to use model-free\nreinforcement learning (RL) to learn shortcuts in the abstract planning graph\ninduced by the existing options in TAMP. Without any additional assumptions or\ninputs, shortcut learning leads to shorter solutions than pure planning, and\nhigher task success rates than flat and hierarchical RL. Qualitatively, SLAP\ndiscovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that\ndiffer significantly from the manually-defined ones. In experiments in four\nsimulated robotic environments, we show that SLAP solves and generalizes to a\nwide range of tasks, reducing overall plan lengths by over 50% and consistently\noutperforming planning and RL baselines.", "AI": {"tldr": "\u63d0\u51faShortcut Learning for Abstract Planning (SLAP)\u65b9\u6cd5\uff0c\u5229\u7528\u73b0\u6709TAMP\u9009\u9879\u81ea\u52a8\u53d1\u73b0\u65b0\u9009\u9879\uff0c\u5728\u56db\u4e2a\u6a21\u62df\u673a\u5668\u4eba\u73af\u5883\u5b9e\u9a8c\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u957f\u89c6\u91ce\u3001\u7a00\u758f\u5956\u52b1\u3001\u8fde\u7eed\u72b6\u6001\u548c\u52a8\u4f5c\u7684\u51b3\u7b56\u662fAI\u548c\u673a\u5668\u4eba\u9886\u57df\u6311\u6218\uff0c\u73b0\u6709TAMP\u9009\u9879\u624b\u52a8\u5b9a\u4e49\u6709\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u5728TAMP\u73b0\u6709\u9009\u9879\u8bf1\u5bfc\u7684\u62bd\u8c61\u89c4\u5212\u56fe\u4e2d\u5b66\u4e60\u6377\u5f84\u3002", "result": "\u6377\u5f84\u5b66\u4e60\u6bd4\u7eaf\u89c4\u5212\u89e3\u51b3\u65b9\u6848\u66f4\u77ed\uff0c\u6bd4\u6241\u5e73\u53ca\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u6210\u529f\u7387\u66f4\u9ad8\uff0c\u53d1\u73b0\u4e0e\u624b\u52a8\u5b9a\u4e49\u4e0d\u540c\u7684\u52a8\u6001\u7269\u7406\u5373\u5174\u52a8\u4f5c\uff0c\u5728\u56db\u4e2a\u6a21\u62df\u73af\u5883\u4e2d\u89e3\u51b3\u5e76\u6cdb\u5316\u591a\u79cd\u4efb\u52a1\uff0c\u51cf\u5c11\u8d8550%\u7684\u8ba1\u5212\u957f\u5ea6\uff0c\u4f18\u4e8e\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "SLAP\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u89e3\u51b3\u548c\u6cdb\u5316\u591a\u79cd\u4efb\u52a1\uff0c\u5728\u8ba1\u5212\u957f\u5ea6\u548c\u4efb\u52a1\u6210\u529f\u7387\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.01118", "pdf": "https://arxiv.org/pdf/2511.01118", "abs": "https://arxiv.org/abs/2511.01118", "authors": ["Li Raymond", "Salim Flora", "Wang Sijin", "Wright Brendan"], "title": "Generative Machine Learning Models for the Deconvolution of Charge Carrier Dynamics in Organic Photovoltaic Cells", "categories": ["cond-mat.mtrl-sci", "cs.LG", "82D20, 62H25, 37M05", "I.2.6; I.5.3; I.6.5; G.3"], "comment": null, "summary": "Charge carrier dynamics critically affect the efficiency and stability of\norganic photovoltaic devices, but they are challenging to model with\ntraditional analytical methods. We introduce \\b{eta}-Linearly Decoded Latent\nOrdinary Differential Equations (\\b{eta}-LLODE), a machine learning framework\nthat disentangles and reconstructs extraction dynamics from time-resolved\ncharge extraction measurements of P3HT:PCBM cells. This model enables the\nisolated analysis of the underlying charge carrier behaviour, which was found\nto be well described by a compressed exponential decay. Furthermore, the learnt\ninterpretable latent space enables simulation, including both interpolation and\nextrapolation of experimental measurement conditions, offering a predictive\ntool for solar cell research to support device study and optimisation.", "AI": {"tldr": "\u5f15\u5165\u673a\u5668\u5b66\u4e60\u6846\u67b6eta - LLODE\u5206\u6790\u6709\u673a\u5149\u4f0f\u5668\u4ef6\u8f7d\u6d41\u5b50\u52a8\u529b\u5b66\uff0c\u53ef\u6a21\u62df\u5b9e\u9a8c\u6761\u4ef6\u3002", "motivation": "\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u5bf9\u6709\u673a\u5149\u4f0f\u5668\u4ef6\u7684\u8f7d\u6d41\u5b50\u52a8\u529b\u5b66\u8fdb\u884c\u5efa\u6a21\u3002", "method": "\u5f15\u5165eta - Linearly Decoded Latent Ordinary Differential Equations (eta - LLODE)\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u4eceP3HT:PCBM\u7535\u6c60\u7684\u65f6\u95f4\u5206\u8fa8\u7535\u8377\u63d0\u53d6\u6d4b\u91cf\u4e2d\u5206\u79bb\u548c\u91cd\u5efa\u63d0\u53d6\u52a8\u529b\u5b66\u3002", "result": "\u53d1\u73b0\u8f7d\u6d41\u5b50\u884c\u4e3a\u53ef\u7528\u538b\u7f29\u6307\u6570\u8870\u51cf\u5f88\u597d\u5730\u63cf\u8ff0\uff0c\u5b66\u4e60\u5230\u7684\u53ef\u89e3\u91ca\u6f5c\u7a7a\u95f4\u80fd\u5bf9\u5b9e\u9a8c\u6d4b\u91cf\u6761\u4ef6\u8fdb\u884c\u6a21\u62df\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u592a\u9633\u80fd\u7535\u6c60\u7814\u7a76\u63d0\u4f9b\u4e86\u9884\u6d4b\u5de5\u5177\uff0c\u53ef\u652f\u6301\u5668\u4ef6\u7814\u7a76\u548c\u4f18\u5316\u3002"}}
{"id": "2511.01390", "pdf": "https://arxiv.org/pdf/2511.01390", "abs": "https://arxiv.org/abs/2511.01390", "authors": ["Xinyu Mao", "Junsi Li", "Haoji Zhang", "Yu Liang", "Ming Sun"], "title": "SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Fine-grained cross-modal alignment aims to establish precise local\ncorrespondences between vision and language, forming a cornerstone for visual\nquestion answering and related multimodal applications. Current approaches face\nchallenges in addressing patch redundancy and ambiguity, which arise from the\ninherent information density disparities across modalities. Recently,\nMultimodal Large Language Models (MLLMs) have emerged as promising solutions to\nbridge this gap through their robust semantic generation capabilities. However,\nthe dense textual outputs from MLLMs may introduce conflicts with the original\nsparse captions. Furthermore, accurately quantifying semantic relevance between\nrich visual patches and concise textual descriptions remains a core challenge.\nTo overcome these limitations, we introduce the Semantic-Enhanced Patch\nSlimming (SEPS) framework, which systematically addresses patch redundancy and\nambiguity. Our approach employs a two-stage mechanism to integrate unified\nsemantics from both dense and sparse texts, enabling the identification of\nsalient visual patches. Additionally, it leverages relevance-aware selection\nwith mean value computation to highlight crucial patch-word correspondences,\nthereby improving cross-modal similarity assessment. Comprehensive experiments\non Flickr30K and MS-COCO datasets validate that SEPS achieves superior\nperformance, surpassing existing approaches by 23\\%-86\\% in rSum across diverse\nmodel architectures, with notable enhancements in text-to-image retrieval\nscenarios. Our implementation is available at\nhttps://github.com/Sweet4tars/seps.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSEPS\u6846\u67b6\u89e3\u51b3\u7ec6\u7c92\u5ea6\u8de8\u6a21\u6001\u5bf9\u9f50\u4e2d\u6591\u5757\u5197\u4f59\u548c\u6b67\u4e49\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7ec6\u7c92\u5ea6\u8de8\u6a21\u6001\u5bf9\u9f50\u65b9\u6cd5\u5728\u5904\u7406\u6591\u5757\u5197\u4f59\u548c\u6b67\u4e49\u4e0a\u6709\u6311\u6218\uff0cMLLMs\u867d\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u8f93\u51fa\u51b2\u7a81\u53ca\u8bed\u4e49\u76f8\u5173\u6027\u91cf\u5316\u96be\u9898\u3002", "method": "\u5f15\u5165SEPS\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u673a\u5236\u6574\u5408\u8bed\u4e49\uff0c\u5229\u7528\u76f8\u5173\u6027\u611f\u77e5\u9009\u62e9\u548c\u5747\u503c\u8ba1\u7b97\u7a81\u51fa\u5173\u952e\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u5728Flickr30K\u548cMS - COCO\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cSEPS\u5728rSum\u4e0a\u8d85\u73b0\u6709\u65b9\u6cd523%-86%\uff0c\u6587\u672c\u5230\u56fe\u50cf\u68c0\u7d22\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "SEPS\u6846\u67b6\u6709\u6548\u89e3\u51b3\u7ec6\u7c92\u5ea6\u8de8\u6a21\u6001\u5bf9\u9f50\u95ee\u9898\uff0c\u6027\u80fd\u8868\u73b0\u51fa\u8272\uff0c\u4ee3\u7801\u53ef\u5728\u6307\u5b9a\u94fe\u63a5\u83b7\u53d6\u3002"}}
{"id": "2511.01407", "pdf": "https://arxiv.org/pdf/2511.01407", "abs": "https://arxiv.org/abs/2511.01407", "authors": ["Paolo Rabino", "Gabriele Tiboni", "Tatiana Tommasi"], "title": "FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted at 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)", "summary": "Object-Centric Motion Generation (OCMG) is instrumental in advancing\nautomated manufacturing processes, particularly in domains requiring\nhigh-precision expert robotic motions, such as spray painting and welding. To\nrealize effective automation, robust algorithms are essential for generating\nextended, object-aware trajectories across intricate 3D geometries. However,\ncontemporary OCMG techniques are either based on ad-hoc heuristics or employ\nlearning-based pipelines that are still reliant on sensitive post-processing\nsteps to generate executable paths. We introduce FoldPath, a novel, end-to-end,\nneural field based method for OCMG. Unlike prior deep learning approaches that\npredict discrete sequences of end-effector waypoints, FoldPath learns the robot\nmotion as a continuous function, thus implicitly encoding smooth output paths.\nThis paradigm shift eliminates the need for brittle post-processing steps that\nconcatenate and order the predicted discrete waypoints. Particularly, our\napproach demonstrates superior predictive performance compared to recently\nproposed learning-based methods, and attains generalization capabilities even\nin real industrial settings, where only a limited amount of 70 expert samples\nare provided. We validate FoldPath through comprehensive experiments in a\nrealistic simulation environment and introduce new, rigorous metrics designed\nto comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG\ntask towards practical maturity.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8eOCMG\u7684\u65b0\u65b9\u6cd5FoldPath\uff0c\u5b83\u4ee5\u8fde\u7eed\u51fd\u6570\u5b66\u4e60\u673a\u5668\u4eba\u8fd0\u52a8\uff0c\u65e0\u9700\u8106\u5f31\u540e\u5904\u7406\u6b65\u9aa4\uff0c\u5728\u9884\u6d4b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5e76\u5f15\u5165\u65b0\u8bc4\u4f30\u6307\u6807\u63a8\u52a8OCMG\u8d70\u5411\u5b9e\u7528\u6210\u719f\u3002", "motivation": "\u73b0\u6709OCMG\u6280\u672f\u5b58\u5728\u4f9d\u8d56\u4e34\u65f6\u542f\u53d1\u5f0f\u6216\u654f\u611f\u540e\u5904\u7406\u6b65\u9aa4\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u7b97\u6cd5\u6765\u5b9e\u73b0\u81ea\u52a8\u5316\u5236\u9020\u4e2d\u9ad8\u7cbe\u5ea6\u4e13\u5bb6\u673a\u5668\u4eba\u8fd0\u52a8\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u573a\u7684\u7aef\u5230\u7aef\u65b0\u65b9\u6cd5FoldPath\uff0c\u5c06\u673a\u5668\u4eba\u8fd0\u52a8\u4f5c\u4e3a\u8fde\u7eed\u51fd\u6570\u5b66\u4e60\u3002", "result": "\u76f8\u6bd4\u8fd1\u671f\u5b66\u4e60\u65b9\u6cd5\u6709\u66f4\u4f18\u9884\u6d4b\u6027\u80fd\uff0c\u5728\u4ec570\u4e2a\u4e13\u5bb6\u6837\u672c\u7684\u771f\u5b9e\u5de5\u4e1a\u73af\u5883\u4e2d\u4e5f\u6709\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u9a8c\u548c\u5f15\u5165\u65b0\u6307\u6807\uff0c\u63a8\u52a8OCMG\u4efb\u52a1\u5411\u5b9e\u7528\u6210\u719f\u53d1\u5c55\u3002"}}
{"id": "2511.01427", "pdf": "https://arxiv.org/pdf/2511.01427", "abs": "https://arxiv.org/abs/2511.01427", "authors": ["Yinchao Ma", "Yuyang Tang", "Wenfei Yang", "Tianzhu Zhang", "Xu Zhou", "Feng Wu"], "title": "UniSOT: A Unified Framework for Multi-Modality Single Object Tracking", "categories": ["cs.CV", "cs.AI"], "comment": "The paper has been accepted by TPAMI", "summary": "Single object tracking aims to localize target object with specific reference\nmodalities (bounding box, natural language or both) in a sequence of specific\nvideo modalities (RGB, RGB+Depth, RGB+Thermal or RGB+Event.). Different\nreference modalities enable various human-machine interactions, and different\nvideo modalities are demanded in complex scenarios to enhance tracking\nrobustness. Existing trackers are designed for single or several video\nmodalities with single or several reference modalities, which leads to separate\nmodel designs and limits practical applications. Practically, a unified tracker\nis needed to handle various requirements. To the best of our knowledge, there\nis still no tracker that can perform tracking with these above reference\nmodalities across these video modalities simultaneously. Thus, in this paper,\nwe present a unified tracker, UniSOT, for different combinations of three\nreference modalities and four video modalities with uniform parameters.\nExtensive experimental results on 18 visual tracking, vision-language tracking\nand RGB+X tracking benchmarks demonstrate that UniSOT shows superior\nperformance against modality-specific counterparts. Notably, UniSOT outperforms\nprevious counterparts by over 3.0\\% AUC on TNL2K across all three reference\nmodalities and outperforms Un-Track by over 2.0\\% main metric across all three\nRGB+X video modalities.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u8ffd\u8e2a\u5668UniSOT\u5904\u7406\u4e0d\u540c\u53c2\u8003\u548c\u89c6\u9891\u6a21\u6001\u7ec4\u5408\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u7279\u5b9a\u6a21\u6001\u8ffd\u8e2a\u5668\u3002", "motivation": "\u73b0\u6709\u8ffd\u8e2a\u5668\u9488\u5bf9\u5355\u4e00\u6216\u51e0\u79cd\u6a21\u6001\u8bbe\u8ba1\uff0c\u9650\u5236\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u8981\u7edf\u4e00\u8ffd\u8e2a\u5668\u5904\u7406\u591a\u79cd\u9700\u6c42\uff0c\u4e14\u5c1a\u65e0\u540c\u65f6\u8de8\u591a\u79cd\u6a21\u6001\u8ffd\u8e2a\u7684\u8ffd\u8e2a\u5668\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u8ffd\u8e2a\u5668UniSOT\uff0c\u7528\u7edf\u4e00\u53c2\u6570\u5904\u7406\u4e09\u79cd\u53c2\u8003\u6a21\u6001\u548c\u56db\u79cd\u89c6\u9891\u6a21\u6001\u7684\u4e0d\u540c\u7ec4\u5408\u3002", "result": "\u572818\u4e2a\u89c6\u89c9\u3001\u89c6\u89c9 - \u8bed\u8a00\u548cRGB+X\u8ffd\u8e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUniSOT\u6027\u80fd\u4f18\u4e8e\u7279\u5b9a\u6a21\u6001\u8ffd\u8e2a\u5668\uff0c\u5728TNL2K\u4e0aAUC\u8d85\u4e4b\u524d\u8ffd\u8e2a\u5668\u8d853.0%\uff0c\u5728RGB+X\u89c6\u9891\u6a21\u6001\u4e0a\u4e3b\u6307\u6807\u8d85Un - Track\u8d852.0%\u3002", "conclusion": "UniSOT\u80fd\u6709\u6548\u5904\u7406\u4e0d\u540c\u53c2\u8003\u548c\u89c6\u9891\u6a21\u6001\u7ec4\u5408\uff0c\u6027\u80fd\u4f18\u8d8a\u3002"}}
{"id": "2511.01154", "pdf": "https://arxiv.org/pdf/2511.01154", "abs": "https://arxiv.org/abs/2511.01154", "authors": ["Sinho Chewi", "Aram-Alexandre Pooladian", "Matthew S. Zhang"], "title": "Stability of the Kim--Milman flow map", "categories": ["math.PR", "cs.LG", "math.ST", "stat.TH", "26D10"], "comment": null, "summary": "In this short note, we characterize stability of the Kim--Milman flow map --\nalso known as the probability flow ODE -- with respect to variations in the\ntarget measure. Rather than the Wasserstein distance, we show that stability\nholds with respect to the relative Fisher information", "AI": {"tldr": "\u7814\u7a76Kim - Milman\u6d41\u6620\u5c04\uff08\u6982\u7387\u6d41ODE\uff09\u5173\u4e8e\u76ee\u6807\u6d4b\u5ea6\u53d8\u5316\u7684\u7a33\u5b9a\u6027\uff0c\u53d1\u73b0\u7a33\u5b9a\u6027\u4e0e\u76f8\u5bf9Fisher\u4fe1\u606f\u6709\u5173\u800c\u975eWasserstein\u8ddd\u79bb\u3002", "motivation": "\u523b\u753bKim - Milman\u6d41\u6620\u5c04\u5173\u4e8e\u76ee\u6807\u6d4b\u5ea6\u53d8\u5316\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u7a33\u5b9a\u6027\u4e0e\u76f8\u5bf9Fisher\u4fe1\u606f\u6709\u5173\uff0c\u800c\u975eWasserstein\u8ddd\u79bb\u3002", "conclusion": "\u5f97\u51faKim - Milman\u6d41\u6620\u5c04\u7a33\u5b9a\u6027\u4e0e\u76f8\u5bf9Fisher\u4fe1\u606f\u7684\u5173\u7cfb\u3002"}}
{"id": "2511.01449", "pdf": "https://arxiv.org/pdf/2511.01449", "abs": "https://arxiv.org/abs/2511.01449", "authors": ["Riddhi Jain", "Manasi Patwardhan", "Aayush Mishra", "Parijat Deshpande", "Beena Rai"], "title": "Privacy Preserving Ordinal-Meta Learning with VLMs for Fine-Grained Fruit Quality Prediction", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 1 figure, 4 tables", "summary": "To effectively manage the wastage of perishable fruits, it is crucial to\naccurately predict their freshness or shelf life using non-invasive methods\nthat rely on visual data. In this regard, deep learning techniques can offer a\nviable solution. However, obtaining fine-grained fruit freshness labels from\nexperts is costly, leading to a scarcity of data. Closed proprietary Vision\nLanguage Models (VLMs), such as Gemini, have demonstrated strong performance in\nfruit freshness detection task in both zero-shot and few-shot settings.\nNonetheless, food retail organizations are unable to utilize these proprietary\nmodels due to concerns related to data privacy, while existing open-source VLMs\nyield sub-optimal performance for the task. Fine-tuning these open-source\nmodels with limited data fails to achieve the performance levels of proprietary\nmodels. In this work, we introduce a Model-Agnostic Ordinal Meta-Learning\n(MAOML) algorithm, designed to train smaller VLMs. This approach utilizes\nmeta-learning to address data sparsity and leverages label ordinality, thereby\nachieving state-of-the-art performance in the fruit freshness classification\ntask under both zero-shot and few-shot settings. Our method achieves an\nindustry-standard accuracy of 92.71%, averaged across all fruits.\n  Keywords: Fruit Quality Prediction, Vision Language Models, Meta Learning,\nOrdinal Regression", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMAOML\u7b97\u6cd5\u8bad\u7ec3\u5c0fVLM\u6a21\u578b\uff0c\u89e3\u51b3\u6c34\u679c\u65b0\u9c9c\u5ea6\u5206\u7c7b\u4efb\u52a1\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u51c6\u786e\u7387\u8fbe92.71%\u3002", "motivation": "\u6709\u6548\u7ba1\u7406\u6613\u8150\u6c34\u679c\u6d6a\u8d39\u9700\u7528\u975e\u4fb5\u5165\u5f0f\u65b9\u6cd5\u51c6\u786e\u9884\u6d4b\u5176\u65b0\u9c9c\u5ea6\u6216\u4fdd\u8d28\u671f\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u7a00\u7f3a\u3001\u95ed\u6e90\u6a21\u578b\u6709\u9690\u79c1\u95ee\u9898\u3001\u5f00\u6e90\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165Model - Agnostic Ordinal Meta - Learning (MAOML)\u7b97\u6cd5\u8bad\u7ec3\u8f83\u5c0f\u7684VLM\u6a21\u578b\uff0c\u5229\u7528\u5143\u5b66\u4e60\u89e3\u51b3\u6570\u636e\u7a00\u758f\u95ee\u9898\u5e76\u5229\u7528\u6807\u7b7e\u5e8f\u3002", "result": "\u65b9\u6cd5\u5728\u6240\u6709\u6c34\u679c\u4e0a\u5e73\u5747\u8fbe\u523092.71%\u7684\u884c\u4e1a\u6807\u51c6\u51c6\u786e\u7387\u3002", "conclusion": "MAOML\u7b97\u6cd5\u5728\u6c34\u679c\u65b0\u9c9c\u5ea6\u5206\u7c7b\u4efb\u52a1\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2511.01181", "pdf": "https://arxiv.org/pdf/2511.01181", "abs": "https://arxiv.org/abs/2511.01181", "authors": ["Emaad Manzoor", "Eva Ascarza", "Oded Netzer"], "title": "Learning When to Quit in Sales Conversations", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Salespeople frequently face the dynamic screening decision of whether to\npersist in a conversation or abandon it to pursue the next lead. Yet, little is\nknown about how these decisions are made, whether they are efficient, or how to\nimprove them. We study these decisions in the context of high-volume outbound\nsales where leads are ample, but time is scarce and failure is common. We\nformalize the dynamic screening decision as an optimal stopping problem and\ndevelop a generative language model-based sequential decision agent - a\nstopping agent - that learns whether and when to quit conversations by\nimitating a retrospectively-inferred optimal stopping policy. Our approach\nhandles high-dimensional textual states, scales to large language models, and\nworks with both open-source and proprietary language models. When applied to\ncalls from a large European telecommunications firm, our stopping agent reduces\nthe time spent on failed calls by 54% while preserving nearly all sales;\nreallocating the time saved increases expected sales by up to 37%. Upon\nexamining the linguistic cues that drive salespeople's quitting decisions, we\nfind that they tend to overweight a few salient expressions of consumer\ndisinterest and mispredict call failure risk, suggesting cognitive bounds on\ntheir ability to make real-time conversational decisions. Our findings\nhighlight the potential of artificial intelligence algorithms to correct\ncognitively-bounded human decisions and improve salesforce efficiency.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u5bb9\u91cf\u5916\u547c\u9500\u552e\u4e2d\u7684\u52a8\u6001\u7b5b\u9009\u51b3\u7b56\uff0c\u63d0\u51fa\u57fa\u4e8e\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u7684\u505c\u6b62\u4ee3\u7406\uff0c\u53ef\u63d0\u9ad8\u9500\u552e\u6548\u7387\uff0c\u63ed\u793a\u9500\u552e\u4eba\u5458\u51b3\u7b56\u5b58\u5728\u8ba4\u77e5\u5c40\u9650\u3002", "motivation": "\u4e86\u89e3\u9500\u552e\u4eba\u5458\u52a8\u6001\u7b5b\u9009\u51b3\u7b56\u7684\u65b9\u5f0f\u3001\u6548\u7387\u53ca\u6539\u8fdb\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u5bb9\u91cf\u5916\u547c\u9500\u552e\u573a\u666f\u4e2d\u3002", "method": "\u5c06\u52a8\u6001\u7b5b\u9009\u51b3\u7b56\u5f62\u5f0f\u5316\u4e3a\u6700\u4f18\u505c\u6b62\u95ee\u9898\uff0c\u5f00\u53d1\u57fa\u4e8e\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u7684\u987a\u5e8f\u51b3\u7b56\u4ee3\u7406\uff08\u505c\u6b62\u4ee3\u7406\uff09\uff0c\u6a21\u4eff\u56de\u987e\u6027\u63a8\u65ad\u7684\u6700\u4f18\u505c\u6b62\u7b56\u7565\u3002", "result": "\u5e94\u7528\u4e8e\u6b27\u6d32\u7535\u4fe1\u516c\u53f8\u7684\u901a\u8bdd\u65f6\uff0c\u505c\u6b62\u4ee3\u7406\u51cf\u5c11\u5931\u8d25\u901a\u8bdd\u65f6\u95f454%\uff0c\u4fdd\u5b58\u51e0\u4e4e\u6240\u6709\u9500\u552e\uff0c\u91cd\u65b0\u5206\u914d\u8282\u7701\u65f6\u95f4\u4f7f\u9884\u671f\u9500\u552e\u6700\u591a\u589e\u52a037%\uff1b\u53d1\u73b0\u9500\u552e\u4eba\u5458\u51b3\u7b56\u5b58\u5728\u8ba4\u77e5\u5c40\u9650\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u6709\u6f5c\u529b\u7ea0\u6b63\u4eba\u7c7b\u8ba4\u77e5\u5c40\u9650\u7684\u51b3\u7b56\uff0c\u63d0\u9ad8\u9500\u552e\u56e2\u961f\u6548\u7387\u3002"}}
{"id": "2511.01450", "pdf": "https://arxiv.org/pdf/2511.01450", "abs": "https://arxiv.org/abs/2511.01450", "authors": ["Jie Du", "Xinyu Gong", "Qingshan Tan", "Wen Li", "Yangming Cheng", "Weitao Wang", "Chenlu Zhan", "Suhui Wu", "Hao Zhang", "Jun Zhang"], "title": "Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent studies have identified Direct Preference Optimization (DPO) as an\nefficient and reward-free approach to improving video generation quality.\nHowever, existing methods largely follow image-domain paradigms and are mainly\ndeveloped on small-scale models (approximately 2B parameters), limiting their\nability to address the unique challenges of video tasks, such as costly data\nconstruction, unstable training, and heavy memory consumption. To overcome\nthese limitations, we introduce a GT-Pair that automatically builds\nhigh-quality preference pairs by using real videos as positives and\nmodel-generated videos as negatives, eliminating the need for any external\nannotation. We further present Reg-DPO, which incorporates the SFT loss as a\nregularization term into the DPO objective to enhance training stability and\ngeneration fidelity. Additionally, by combining the FSDP framework with\nmultiple memory optimization techniques, our approach achieves nearly three\ntimes higher training capacity than using FSDP alone. Extensive experiments on\nboth I2V and T2V tasks across multiple datasets demonstrate that our method\nconsistently outperforms existing approaches, delivering superior video\ngeneration quality.", "AI": {"tldr": "\u63d0\u51faGT - Pair\u548cReg - DPO\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u5c40\u9650\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u591a\u9075\u5faa\u56fe\u50cf\u9886\u57df\u8303\u5f0f\u4e14\u57fa\u4e8e\u5c0f\u89c4\u6a21\u6a21\u578b\uff0c\u5b58\u5728\u6570\u636e\u6784\u5efa\u6210\u672c\u9ad8\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u5185\u5b58\u6d88\u8017\u5927\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165GT - Pair\u81ea\u52a8\u6784\u5efa\u9ad8\u8d28\u91cf\u504f\u597d\u5bf9\uff0c\u63d0\u51faReg - DPO\u5c06SFT\u635f\u5931\u4f5c\u4e3a\u6b63\u5219\u9879\u52a0\u5165DPO\u76ee\u6807\uff0c\u7ed3\u5408FSDP\u6846\u67b6\u548c\u591a\u79cd\u5185\u5b58\u4f18\u5316\u6280\u672f\u3002", "result": "\u8bad\u7ec3\u5bb9\u91cf\u6bd4\u4ec5\u4f7f\u7528FSDP\u63d0\u9ad8\u8fd1\u4e09\u500d\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u7684I2V\u548cT2V\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u63d0\u4f9b\u66f4\u4f18\u89c6\u9891\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2511.01458", "pdf": "https://arxiv.org/pdf/2511.01458", "abs": "https://arxiv.org/abs/2511.01458", "authors": ["Dennis Pierantozzi", "Luca Carlini", "Mauro Orazio Drago", "Chiara Lena", "Cesare Hassan", "Elena De Momi", "Danail Stoyanov", "Sophia Bano", "Mobarak I. Hoque"], "title": "When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Safety and reliability are essential for deploying Visual Question Answering\n(VQA) in surgery, where incorrect or ambiguous responses can harm the patient.\nMost surgical VQA research focuses on accuracy or linguistic quality while\noverlooking safety behaviors such as ambiguity awareness, referral to human\nexperts, or triggering a second opinion. Inspired by Automatic Failure\nDetection (AFD), we study uncertainty estimation as a key enabler of safer\ndecision making. We introduce Question Aligned Semantic Nearest Neighbor\nEntropy (QA-SNNE), a black box uncertainty estimator that incorporates question\nsemantics into prediction confidence. It measures semantic entropy by comparing\ngenerated answers with nearest neighbors in a medical text embedding space,\nconditioned on the question. We evaluate five models, including domain specific\nParameter-Efficient Fine-Tuned (PEFT) models and zero-shot Large\nVision-Language Models (LVLMs), on EndoVis18-VQA and PitVQA. PEFT models\ndegrade under mild paraphrasing, while LVLMs are more resilient. Across three\nLVLMs and two PEFT baselines, QA-SNNE improves AUROC in most in-template\nsettings and enhances hallucination detection. The Area Under the ROC Curve\n(AUROC) increases by 15-38% for zero-shot models, with gains maintained under\nout-of-template stress. QA-SNNE offers a practical and interpretable step\ntoward AFD in surgical VQA by linking semantic uncertainty to question context.\nCombining LVLM backbones with question aligned uncertainty estimation can\nimprove safety and clinician trust. The code and model are available at\nhttps://github.com/DennisPierantozzi/QASNNE", "AI": {"tldr": "\u7814\u7a76\u624b\u672f\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u5b89\u5168\u95ee\u9898\uff0c\u63d0\u51faQA - SNNE\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5668\uff0c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u5176\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u52a9\u529b\u624b\u672fVQA\u5b89\u5168\u3002", "motivation": "\u73b0\u6709\u624b\u672fVQA\u7814\u7a76\u5ffd\u89c6\u5b89\u5168\u884c\u4e3a\uff0c\u53d7\u81ea\u52a8\u6545\u969c\u68c0\u6d4b\uff08AFD\uff09\u542f\u53d1\uff0c\u7814\u7a76\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4ee5\u5b9e\u73b0\u66f4\u5b89\u5168\u51b3\u7b56\u3002", "method": "\u5f15\u5165QA - SNNE\uff0c\u5c06\u95ee\u9898\u8bed\u4e49\u878d\u5165\u9884\u6d4b\u7f6e\u4fe1\u5ea6\uff0c\u901a\u8fc7\u5728\u533b\u5b66\u6587\u672c\u5d4c\u5165\u7a7a\u95f4\u5bf9\u6bd4\u751f\u6210\u7b54\u6848\u4e0e\u6700\u8fd1\u90bb\u6d4b\u91cf\u8bed\u4e49\u71b5\u3002\u8bc4\u4f30\u4e94\u79cd\u6a21\u578b\u3002", "result": "PEFT\u6a21\u578b\u5728\u8f7b\u5ea6\u91ca\u4e49\u4e0b\u6027\u80fd\u4e0b\u964d\uff0cLVLMs\u66f4\u5177\u5f39\u6027\uff1bQA - SNNE\u5728\u591a\u6570\u6a21\u677f\u5185\u8bbe\u7f6e\u4e2d\u63d0\u9ad8AUROC\uff0c\u589e\u5f3a\u5e7b\u89c9\u68c0\u6d4b\uff0c\u96f6\u6837\u672c\u6a21\u578bAUROC\u63d0\u534715 - 38%\uff0c\u4e14\u5728\u6a21\u677f\u5916\u538b\u529b\u4e0b\u4ecd\u6709\u589e\u76ca\u3002", "conclusion": "QA - SNNE\u4e3a\u624b\u672fVQA\u7684AFD\u63d0\u4f9b\u5b9e\u7528\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408LVLM\u9aa8\u5e72\u548c\u95ee\u9898\u5bf9\u9f50\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ef\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u4e34\u5e8a\u533b\u751f\u4fe1\u4efb\u5ea6\u3002"}}
{"id": "2511.01462", "pdf": "https://arxiv.org/pdf/2511.01462", "abs": "https://arxiv.org/abs/2511.01462", "authors": ["Peng Xia", "Junbiao Pang", "Tianyang Cai"], "title": "Efficiently Training A Flat Neural Network Before It has been Quantizated", "categories": ["cs.CV", "cs.AI"], "comment": "ongoing work, more results would be added", "summary": "Post-training quantization (PTQ) for vision transformers (ViTs) has garnered\nsignificant attention due to its efficiency in compressing models. However,\nexisting methods typically overlook the relationship between a well-trained NN\nand the quantized model, leading to considerable quantization error for PTQ.\nHowever, it is unclear how to efficiently train a model-agnostic neural network\nwhich is tailored for a predefined precision low-bit model. In this paper, we\nfirstly discover that a flat full precision neural network is crucial for\nlow-bit quantization. To achieve this, we propose a framework that proactively\npre-conditions the model by measuring and disentangling the error sources.\nSpecifically, both the Activation Quantization Error (AQE) and the Weight\nQuantization Error (WQE) are statistically modeled as independent Gaussian\nnoises. We study several noise injection optimization methods to obtain a flat\nminimum. Experimental results attest to the effectiveness of our approach.\nThese results open novel pathways for obtaining low-bit PTQ models.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u89c6\u89c9Transformer\u7684\u8bad\u7ec3\u540e\u91cf\u5316\uff08PTQ\uff09\u5b58\u5728\u91cf\u5316\u8bef\u5dee\u5927\u53ca\u96be\u8bad\u7ec3\u9002\u914d\u4f4e\u6bd4\u7279\u6a21\u578b\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u6846\u67b6\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709PTQ\u65b9\u6cd5\u5ffd\u7565\u8bad\u7ec3\u597d\u7684\u795e\u7ecf\u7f51\u7edc\u548c\u91cf\u5316\u6a21\u578b\u7684\u5173\u7cfb\uff0c\u5bfc\u81f4\u91cf\u5316\u8bef\u5dee\u5927\uff0c\u4e14\u4e0d\u6e05\u695a\u5982\u4f55\u9ad8\u6548\u8bad\u7ec3\u9002\u914d\u4f4e\u6bd4\u7279\u6a21\u578b\u7684\u795e\u7ecf\u7f51\u7edc\u3002", "method": "\u53d1\u73b0\u6241\u5e73\u5168\u7cbe\u5ea6\u795e\u7ecf\u7f51\u7edc\u5bf9\u4f4e\u6bd4\u7279\u91cf\u5316\u5f88\u5173\u952e\uff0c\u63d0\u51fa\u6846\u67b6\u901a\u8fc7\u6d4b\u91cf\u548c\u89e3\u8026\u8bef\u5dee\u6e90\u5bf9\u6a21\u578b\u8fdb\u884c\u9884\u8c03\u8282\uff0c\u5c06\u6fc0\u6d3b\u91cf\u5316\u8bef\u5dee\u548c\u6743\u91cd\u91cf\u5316\u8bef\u5dee\u7edf\u8ba1\u5efa\u6a21\u4e3a\u72ec\u7acb\u9ad8\u65af\u566a\u58f0\uff0c\u7814\u7a76\u566a\u58f0\u6ce8\u5165\u4f18\u5316\u65b9\u6cd5\u4ee5\u83b7\u5f97\u6241\u5e73\u6700\u5c0f\u503c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e3a\u83b7\u5f97\u4f4e\u6bd4\u7279PTQ\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.01463", "pdf": "https://arxiv.org/pdf/2511.01463", "abs": "https://arxiv.org/abs/2511.01463", "authors": ["Lei Hu", "Yongjing Ye", "Shihong Xia"], "title": "HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA", "categories": ["cs.CV", "cs.AI", "cs.GR", "68T45", "I.2.10; I.3.7"], "comment": "10 pages, 5figures. The Thirty-Ninth Annual Conference on Neural\n  Information Processing Systems", "summary": "The expansion of instruction-tuning data has enabled foundation language\nmodels to exhibit improved instruction adherence and superior performance\nacross diverse downstream tasks. Semantically-rich 3D human motion is being\nprogressively integrated with these foundation models to enhance multimodal\nunderstanding and cross-modal generation capabilities. However, the modality\ngap between human motion and text raises unresolved concerns about catastrophic\nforgetting during this integration. In addition, developing\nautoregressive-compatible pose representations that preserve generalizability\nacross heterogeneous downstream tasks remains a critical technical barrier. To\naddress these issues, we propose the Human Motion-Vision-Language Model\n(HMVLM), a unified framework based on the Mixture of Expert Low-Rank\nAdaption(MoE LoRA) strategy. The framework leverages the gating network to\ndynamically allocate LoRA expert weights based on the input prompt, enabling\nsynchronized fine-tuning of multiple tasks. To mitigate catastrophic forgetting\nduring instruction-tuning, we introduce a novel zero expert that preserves the\npre-trained parameters for general linguistic tasks. For pose representation,\nwe implement body-part-specific tokenization by partitioning the human body\ninto different joint groups, enhancing the spatial resolution of the\nrepresentation. Experiments show that our method effectively alleviates\nknowledge forgetting during instruction-tuning and achieves remarkable\nperformance across diverse human motion downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u4eba\u7c7b\u8fd0\u52a8 - \u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\uff08HMVLM\uff09\u89e3\u51b3\u4eba\u7c7b\u8fd0\u52a8\u4e0e\u6587\u672c\u96c6\u6210\u95ee\u9898\uff0c\u5b9e\u9a8c\u6548\u679c\u597d\u3002", "motivation": "\u4eba\u7c7b\u8fd0\u52a8\u4e0e\u6587\u672c\u96c6\u6210\u5b58\u5728\u6a21\u6001\u5dee\u8ddd\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u901a\u7528\u7684\u81ea\u56de\u5f52\u517c\u5bb9\u59ff\u52bf\u8868\u793a\u3002", "method": "\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\u4f4e\u79e9\u9002\u5e94\uff08MoE LoRA\uff09\u7b56\u7565\u63d0\u51faHMVLM\u6846\u67b6\uff0c\u5229\u7528\u95e8\u63a7\u7f51\u7edc\u52a8\u6001\u5206\u914d\u6743\u91cd\uff0c\u5f15\u5165\u96f6\u4e13\u5bb6\u7f13\u89e3\u9057\u5fd8\uff0c\u5bf9\u4eba\u4f53\u5206\u533a\u8fdb\u884c\u7279\u5b9a\u8eab\u4f53\u90e8\u4f4d\u7684\u6807\u8bb0\u5316\u3002", "result": "\u6709\u6548\u7f13\u89e3\u6307\u4ee4\u8c03\u4f18\u671f\u95f4\u7684\u77e5\u8bc6\u9057\u5fd8\uff0c\u5728\u591a\u79cd\u4eba\u7c7b\u8fd0\u52a8\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u89e3\u51b3\u4eba\u7c7b\u8fd0\u52a8\u4e0e\u6587\u672c\u96c6\u6210\u95ee\u9898\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2511.01266", "pdf": "https://arxiv.org/pdf/2511.01266", "abs": "https://arxiv.org/abs/2511.01266", "authors": ["Joonghyuk Shin", "Zhengqi Li", "Richard Zhang", "Jun-Yan Zhu", "Jaesik Park", "Eli Schechtman", "Xun Huang"], "title": "MotionStream: Real-Time Video Generation with Interactive Motion Controls", "categories": ["cs.CV", "cs.LG"], "comment": "Project webpage: https://joonghyuk.com/motionstream-web/", "summary": "Current motion-conditioned video generation methods suffer from prohibitive\nlatency (minutes per video) and non-causal processing that prevents real-time\ninteraction. We present MotionStream, enabling sub-second latency with up to 29\nFPS streaming generation on a single GPU. Our approach begins by augmenting a\ntext-to-video model with motion control, which generates high-quality videos\nthat adhere to the global text prompt and local motion guidance, but does not\nperform inference on the fly. As such, we distill this bidirectional teacher\ninto a causal student through Self Forcing with Distribution Matching\nDistillation, enabling real-time streaming inference. Several key challenges\narise when generating videos of long, potentially infinite time-horizons: (1)\nbridging the domain gap from training on finite length and extrapolating to\ninfinite horizons, (2) sustaining high quality by preventing error\naccumulation, and (3) maintaining fast inference, without incurring growth in\ncomputational cost due to increasing context windows. A key to our approach is\nintroducing carefully designed sliding-window causal attention, combined with\nattention sinks. By incorporating self-rollout with attention sinks and KV\ncache rolling during training, we properly simulate inference-time\nextrapolations with a fixed context window, enabling constant-speed generation\nof arbitrarily long videos. Our models achieve state-of-the-art results in\nmotion following and video quality while being two orders of magnitude faster,\nuniquely enabling infinite-length streaming. With MotionStream, users can paint\ntrajectories, control cameras, or transfer motion, and see results unfold in\nreal-time, delivering a truly interactive experience.", "AI": {"tldr": "\u63d0\u51faMotionStream\uff0c\u5b9e\u73b0\u4e9a\u79d2\u7ea7\u5ef6\u8fdf\u548c\u9ad8\u8fbe29 FPS\u7684\u6d41\u5f0f\u89c6\u9891\u751f\u6210\uff0c\u53ef\u5b9e\u65f6\u4ea4\u4e92\u4e14\u80fd\u751f\u6210\u4efb\u610f\u957f\u89c6\u9891\u3002", "motivation": "\u73b0\u6709\u8fd0\u52a8\u6761\u4ef6\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u5ef6\u8fdf\u9ad8\u548c\u975e\u56e0\u679c\u5904\u7406\u95ee\u9898\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u4ea4\u4e92\u3002", "method": "\u5148\u4e3a\u6587\u672c\u5230\u89c6\u9891\u6a21\u578b\u6dfb\u52a0\u8fd0\u52a8\u63a7\u5236\uff0c\u518d\u901a\u8fc7\u81ea\u5f3a\u5236\u5206\u5e03\u5339\u914d\u84b8\u998f\u5c06\u53cc\u5411\u6559\u5e08\u6a21\u578b\u63d0\u70bc\u4e3a\u56e0\u679c\u5b66\u751f\u6a21\u578b\uff1b\u5f15\u5165\u6ed1\u52a8\u7a97\u53e3\u56e0\u679c\u6ce8\u610f\u529b\u548c\u6ce8\u610f\u529b\u6c47\uff0c\u7ed3\u5408\u81ea\u56de\u6eda\u548cKV\u7f13\u5b58\u6eda\u52a8\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u5728\u8fd0\u52a8\u8ddf\u968f\u548c\u89c6\u9891\u8d28\u91cf\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u901f\u5ea6\u5feb\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u5b9e\u73b0\u65e0\u9650\u957f\u5ea6\u7684\u6d41\u5f0f\u751f\u6210\u3002", "conclusion": "MotionStream\u80fd\u8ba9\u7528\u6237\u5b9e\u65f6\u770b\u5230\u8fd0\u52a8\u63a7\u5236\u7ed3\u679c\uff0c\u63d0\u4f9b\u771f\u6b63\u7684\u4ea4\u4e92\u4f53\u9a8c\u3002"}}
{"id": "2511.01476", "pdf": "https://arxiv.org/pdf/2511.01476", "abs": "https://arxiv.org/abs/2511.01476", "authors": ["Cankut Bora Tuncer", "Marc Toussaint", "Ozgur S. Oguz"], "title": "MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments", "categories": ["cs.RO", "cs.AI"], "comment": "8 pages, 8 figures, website:https://sites.google.com/view/mo-segman/", "summary": "In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided\nManipulation planner for highly constrained rearrangement problems. MO-SeGMan\ngenerates object placement sequences that minimize both replanning per object\nand robot travel distance while preserving critical dependency structures with\na lazy evaluation method. To address highly cluttered, non-monotone scenarios,\nwe propose a Selective Guided Forward Search (SGFS) that efficiently relocates\nonly critical obstacles and to feasible relocation points. Furthermore, we\nadopt a refinement method for adaptive subgoal selection to eliminate\nunnecessary pick-and-place actions, thereby improving overall solution quality.\nExtensive evaluations on nine benchmark rearrangement tasks demonstrate that\nMO-SeGMan generates feasible motion plans in all cases, consistently achieving\nfaster solution times and superior solution quality compared to the baselines.\nThese results highlight the robustness and scalability of the proposed\nframework for complex rearrangement planning problems.", "AI": {"tldr": "\u4ecb\u7ecdMO - SeGMan\u89c4\u5212\u5668\u7528\u4e8e\u9ad8\u7ea6\u675f\u91cd\u6392\u95ee\u9898\uff0c\u6709\u591a\u79cd\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\uff0c\u8bc4\u4f30\u663e\u793a\u6bd4\u57fa\u7ebf\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u9ad8\u7ea6\u675f\u91cd\u6392\u95ee\u9898\uff0c\u5904\u7406\u6742\u4e71\u3001\u975e\u5355\u8c03\u573a\u666f\u3002", "method": "\u91c7\u7528\u61d2\u8bc4\u4f30\u65b9\u6cd5\u751f\u6210\u5bf9\u8c61\u653e\u7f6e\u5e8f\u5217\uff0c\u63d0\u51faSGFS\u9ad8\u6548\u79fb\u52a8\u5173\u952e\u969c\u788d\u7269\uff0c\u91c7\u7528\u7ec6\u5316\u65b9\u6cd5\u8fdb\u884c\u81ea\u9002\u5e94\u5b50\u76ee\u6807\u9009\u62e9\u3002", "result": "\u5728\u4e5d\u4e2a\u57fa\u51c6\u91cd\u6392\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0cMO - SeGMan\u5747\u751f\u6210\u53ef\u884c\u8fd0\u52a8\u8ba1\u5212\uff0c\u6c42\u89e3\u65f6\u95f4\u66f4\u5feb\uff0c\u89e3\u8d28\u91cf\u66f4\u4f18\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u5bf9\u590d\u6742\u91cd\u6392\u89c4\u5212\u95ee\u9898\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.01303", "pdf": "https://arxiv.org/pdf/2511.01303", "abs": "https://arxiv.org/abs/2511.01303", "authors": ["Tomer Shoham", "Moshe Shenfeld", "Noa Velner-Harris", "Katrina Ligett"], "title": "Black-Box Differentially Private Nonparametric Confidence Intervals Under Minimal Assumptions", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We introduce a simple, general framework that takes any differentially\nprivate estimator of any arbitrary quantity as a black box, and from it\nconstructs a differentially private nonparametric confidence interval of that\nquantity. Our approach repeatedly subsamples the data, applies the private\nestimator to each subsample, and then post-processes the resulting empirical\nCDF to a confidence interval. Our analysis uses the randomness from the\nsubsampling to achieve privacy amplification. Under mild assumptions, the\nempirical CDF we obtain approaches the CDF of the private statistic as the\nsample size grows. We use this to show that the confidence intervals we\nestimate are asymptotically valid, tight, and equivalent to their non-private\ncounterparts. We provide empirical evidence that our method performs well\ncompared with the (less-general) state-of-the-art algorithms.", "AI": {"tldr": "\u63d0\u51fa\u901a\u7528\u6846\u67b6\uff0c\u7528\u5dee\u5206\u9690\u79c1\u4f30\u8ba1\u5668\u6784\u9020\u975e\u53c2\u6570\u7f6e\u4fe1\u533a\u95f4\uff0c\u65b9\u6cd5\u6709\u6548\u4e14\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u6784\u9020\u4efb\u610f\u5dee\u5206\u9690\u79c1\u4f30\u8ba1\u91cf\u5bf9\u5e94\u7684\u5dee\u5206\u9690\u79c1\u975e\u53c2\u6570\u7f6e\u4fe1\u533a\u95f4\u3002", "method": "\u5bf9\u6570\u636e\u91cd\u590d\u5b50\u91c7\u6837\uff0c\u5c06\u79c1\u6709\u4f30\u8ba1\u5668\u5e94\u7528\u4e8e\u6bcf\u4e2a\u5b50\u6837\u672c\uff0c\u5bf9\u7ecf\u9a8cCDF\u540e\u5904\u7406\u5f97\u5230\u7f6e\u4fe1\u533a\u95f4\uff0c\u5229\u7528\u5b50\u91c7\u6837\u968f\u673a\u6027\u5b9e\u73b0\u9690\u79c1\u653e\u5927\u3002", "result": "\u5f97\u5230\u7684\u7ecf\u9a8cCDF\u968f\u6837\u672c\u91cf\u589e\u957f\u8d8b\u8fd1\u4e8e\u79c1\u6709\u7edf\u8ba1\u91cf\u7684CDF\uff0c\u4f30\u8ba1\u7684\u7f6e\u4fe1\u533a\u95f4\u6e10\u8fd1\u6709\u6548\u3001\u7d27\u5bc6\u4e14\u4e0e\u975e\u79c1\u6709\u5bf9\u5e94\u7269\u7b49\u6548\uff0c\u5b9e\u8bc1\u8868\u660e\u65b9\u6cd5\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u7b80\u5355\u901a\u7528\uff0c\u80fd\u6709\u6548\u6784\u9020\u5dee\u5206\u9690\u79c1\u975e\u53c2\u6570\u7f6e\u4fe1\u533a\u95f4\u3002"}}
{"id": "2511.01512", "pdf": "https://arxiv.org/pdf/2511.01512", "abs": "https://arxiv.org/abs/2511.01512", "authors": ["Ayesha Afroza Mohsin", "Mashrur Ahsan", "Nafisa Maliyat", "Shanta Maria", "Syed Rifat Raiyan", "Hasan Mahmud", "Md Kamrul Hasan"], "title": "BanglaNirTox: A Large-scale Parallel Corpus for Explainable AI in Bengali Text Detoxification", "categories": ["cs.CL", "cs.AI"], "comment": "Under review, 6 pages, 1 figure, 2 tables", "summary": "Toxic language in Bengali remains prevalent, especially in online\nenvironments, with few effective precautions against it. Although text\ndetoxification has seen progress in high-resource languages, Bengali remains\nunderexplored due to limited resources. In this paper, we propose a novel\npipeline for Bengali text detoxification that combines Pareto class-optimized\nlarge language models (LLMs) and Chain-of-Thought (CoT) prompting to generate\ndetoxified sentences. To support this effort, we construct BanglaNirTox, an\nartificially generated parallel corpus of 68,041 toxic Bengali sentences with\nclass-wise toxicity labels, reasonings, and detoxified paraphrases, using\nPareto-optimized LLMs evaluated on random samples. The resulting BanglaNirTox\ndataset is used to fine-tune language models to produce better detoxified\nversions of Bengali sentences. Our findings show that Pareto-optimized LLMs\nwith CoT prompting significantly enhance the quality and consistency of Bengali\ntext detoxification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u7684\u6587\u672c\u53bb\u6bd2\u65b0\u7ba1\u9053\uff0c\u6784\u5efa\u6570\u636e\u96c6\u5e76\u5fae\u8c03\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u4f18\u5316\u5927\u6a21\u578b\u7ed3\u5408\u601d\u7ef4\u94fe\u63d0\u793a\u80fd\u63d0\u5347\u53bb\u6bd2\u6548\u679c\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u4e2d\u7684\u6709\u6bd2\u8bed\u8a00\u666e\u904d\u5b58\u5728\uff0c\u4f46\u6709\u6548\u9632\u8303\u63aa\u65bd\u5c11\uff0c\u4e14\u8be5\u8bed\u8a00\u5728\u6587\u672c\u53bb\u6bd2\u65b9\u9762\u56e0\u8d44\u6e90\u6709\u9650\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u5e15\u7d2f\u6258\u7c7b\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7684\u7ba1\u9053\uff0c\u6784\u5efaBanglaNirTox\u6570\u636e\u96c6\u5e76\u7528\u4e8e\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5e15\u7d2f\u6258\u4f18\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u601d\u7ef4\u94fe\u63d0\u793a\u663e\u8457\u63d0\u5347\u4e86\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u53bb\u6bd2\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u53bb\u6bd2\u65b9\u9762\u6709\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2511.01331", "pdf": "https://arxiv.org/pdf/2511.01331", "abs": "https://arxiv.org/abs/2511.01331", "authors": ["Hongyin Zhang", "Shuo Zhang", "Junxi Jin", "Qixin Zeng", "Runze Li", "Donglin Wang"], "title": "RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently emerged as powerful\ngeneral-purpose policies for robotic manipulation, benefiting from large-scale\nmulti-modal pre-training. However, they often fail to generalize reliably in\nout-of-distribution deployments, where unavoidable disturbances such as\nobservation noise, sensor errors, or actuation perturbations become prevalent.\nWhile recent Reinforcement Learning (RL)-based post-training provides a\npractical means to adapt pre-trained VLA models, existing methods mainly\nemphasize reward maximization and overlook robustness to environmental\nuncertainty. In this work, we introduce RobustVLA, a lightweight online RL\npost-training method designed to explicitly enhance the resilience of VLA\nmodels. Through a systematic robustness analysis, we identify two key\nregularizations: Jacobian regularization, which mitigates sensitivity to\nobservation noise, and smoothness regularization, which stabilizes policies\nunder action perturbations. Extensive experiments across diverse robotic\nenvironments demonstrate that RobustVLA significantly outperforms prior\nstate-of-the-art methods in robustness and reliability. Our results highlight\nthe importance of principled robustness-aware RL post-training as a key step\ntoward improving the reliability and robustness of VLA models.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u5728\u7ebfRL\u540e\u8bad\u7ec3\u65b9\u6cd5RobustVLA\u589e\u5f3aVLA\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "VLA\u6a21\u578b\u5728\u5206\u5e03\u5916\u90e8\u7f72\u65f6\u96be\u4ee5\u53ef\u9760\u6cdb\u5316\uff0c\u73b0\u6709\u57fa\u4e8eRL\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u5ffd\u89c6\u73af\u5883\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165RobustVLA\uff0c\u901a\u8fc7\u7cfb\u7edf\u9c81\u68d2\u6027\u5206\u6790\u786e\u5b9a\u96c5\u53ef\u6bd4\u6b63\u5219\u5316\u548c\u5149\u6ed1\u6027\u6b63\u5219\u5316\u3002", "result": "\u5728\u591a\u79cd\u673a\u5668\u4eba\u73af\u5883\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cRobustVLA\u5728\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6709\u539f\u5219\u7684\u9c81\u68d2\u6027\u611f\u77e5RL\u540e\u8bad\u7ec3\u662f\u63d0\u9ad8VLA\u6a21\u578b\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2511.01541", "pdf": "https://arxiv.org/pdf/2511.01541", "abs": "https://arxiv.org/abs/2511.01541", "authors": ["Arthur Hubert", "Gamal Elghazaly", "Rapha\u00ebl Frank"], "title": "Driving scenario generation and evaluation using a structured layer representation and foundational models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Rare and challenging driving scenarios are critical for autonomous vehicle\ndevelopment. Since they are difficult to encounter, simulating or generating\nthem using generative models is a popular approach. Following previous efforts\nto structure driving scenario representations in a layer model, we propose a\nstructured five-layer model to improve the evaluation and generation of rare\nscenarios. We use this model alongside large foundational models to generate\nnew driving scenarios using a data augmentation strategy. Unlike previous\nrepresentations, our structure introduces subclasses and characteristics for\nevery agent of the scenario, allowing us to compare them using an embedding\nspecific to our layer-model. We study and adapt two metrics to evaluate the\nrelevance of a synthetic dataset in the context of a structured representation:\nthe diversity score estimates how different the scenarios of a dataset are from\none another, while the originality score calculates how similar a synthetic\ndataset is from a real reference set. This paper showcases both metrics in\ndifferent generation setup, as well as a qualitative evaluation of synthetic\nvideos generated from structured scenario descriptions. The code and extended\nresults can be found at https://github.com/Valgiz/5LMSG.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u6784\u5316\u4e94\u5c42\u6a21\u578b\u7ed3\u5408\u5927\u57fa\u7840\u6a21\u578b\u751f\u6210\u81ea\u52a8\u9a7e\u9a76\u7f55\u89c1\u573a\u666f\uff0c\u7814\u7a76\u4e24\u4e2a\u8bc4\u4f30\u6307\u6807\u5e76\u5c55\u793a\u6548\u679c\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7f55\u89c1\u573a\u666f\u96be\u9047\u5230\uff0c\u9700\u6a21\u62df\u6216\u751f\u6210\uff0c\u6539\u8fdb\u73b0\u6709\u573a\u666f\u8868\u793a\u4ee5\u66f4\u597d\u8bc4\u4f30\u548c\u751f\u6210\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u4e94\u5c42\u6a21\u578b\uff0c\u7ed3\u5408\u5927\u57fa\u7840\u6a21\u578b\u7528\u6570\u636e\u589e\u5f3a\u7b56\u7565\u751f\u6210\u573a\u666f\uff0c\u5f15\u5165\u5b50\u7c7b\u548c\u7279\u5f81\uff0c\u4f7f\u7528\u7279\u5b9a\u5d4c\u5165\u6bd4\u8f83\uff0c\u7814\u7a76\u9002\u5e94\u4e24\u4e2a\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5c55\u793a\u4e86\u4e0d\u540c\u751f\u6210\u8bbe\u7f6e\u4e0b\u7684\u4e24\u4e2a\u6307\u6807\uff0c\u5bf9\u5408\u6210\u89c6\u9891\u8fdb\u884c\u5b9a\u6027\u8bc4\u4f30\u3002", "conclusion": "\u7ed3\u6784\u5316\u4e94\u5c42\u6a21\u578b\u6709\u52a9\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7f55\u89c1\u573a\u666f\u7684\u8bc4\u4f30\u548c\u751f\u6210\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u7ed3\u679c\u516c\u5f00\u3002"}}
{"id": "2511.01411", "pdf": "https://arxiv.org/pdf/2511.01411", "abs": "https://arxiv.org/abs/2511.01411", "authors": ["Reza Karimzadeh", "Albert Alonso", "Frans Zdyb", "Julius B. Kirkegaard", "Bulat Ibragimov"], "title": "Extremal Contours: Gradient-driven contours for compact visual attribution", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Faithful yet compact explanations for vision models remain a challenge, as\ncommonly used dense perturbation masks are often fragmented and overfitted,\nneeding careful post-processing. Here, we present a training-free explanation\nmethod that replaces dense masks with smooth tunable contours. A star-convex\nregion is parameterized by a truncated Fourier series and optimized under an\nextremal preserve/delete objective using the classifier gradients. The approach\nguarantees a single, simply connected mask, cuts the number of free parameters\nby orders of magnitude, and yields stable boundary updates without cleanup.\nRestricting solutions to low-dimensional, smooth contours makes the method\nrobust to adversarial masking artifacts. On ImageNet classifiers, it matches\nthe extremal fidelity of dense masks while producing compact, interpretable\nregions with improved run-to-run consistency. Explicit area control also\nenables importance contour maps, yielding a transparent fidelity-area profiles.\nFinally, we extend the approach to multi-contour and show how it can localize\nmultiple objects within the same framework. Across benchmarks, the method\nachieves higher relevance mass and lower complexity than gradient and\nperturbation based baselines, with especially strong gains on self-supervised\nDINO models where it improves relevance mass by over 15% and maintains positive\nfaithfulness correlations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u514d\u8bad\u7ec3\u7684\u89c6\u89c9\u6a21\u578b\u89e3\u91ca\u65b9\u6cd5\uff0c\u7528\u5e73\u6ed1\u53ef\u8c03\u8f6e\u5ed3\u66ff\u4ee3\u5bc6\u96c6\u63a9\u7801\uff0c\u5728\u591a\u4e2a\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5e38\u7528\u7684\u5bc6\u96c6\u6270\u52a8\u63a9\u7801\u788e\u7247\u5316\u4e14\u8fc7\u62df\u5408\uff0c\u9700\u8981\u4ed4\u7ec6\u540e\u5904\u7406\uff0c\u96be\u4ee5\u63d0\u4f9b\u5fe0\u5b9e\u4e14\u7d27\u51d1\u7684\u89c6\u89c9\u6a21\u578b\u89e3\u91ca\u3002", "method": "\u7528\u622a\u65ad\u5085\u91cc\u53f6\u7ea7\u6570\u53c2\u6570\u5316\u661f\u51f8\u533a\u57df\uff0c\u5728\u6781\u503c\u4fdd\u7559/\u5220\u9664\u76ee\u6807\u4e0b\u4f7f\u7528\u5206\u7c7b\u5668\u68af\u5ea6\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u4fdd\u8bc1\u5355\u4e00\u3001\u7b80\u5355\u8fde\u901a\u7684\u63a9\u7801\uff0c\u5927\u5e45\u51cf\u5c11\u81ea\u7531\u53c2\u6570\u6570\u91cf\uff0c\u751f\u6210\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u533a\u57df\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u68af\u5ea6\u548c\u6270\u52a8\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u89c6\u89c9\u6a21\u578b\u89e3\u91ca\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u53ef\u6269\u5c55\u5230\u591a\u8f6e\u5ed3\u5e76\u5b9a\u4f4d\u591a\u4e2a\u5bf9\u8c61\u3002"}}
{"id": "2511.01464", "pdf": "https://arxiv.org/pdf/2511.01464", "abs": "https://arxiv.org/abs/2511.01464", "authors": ["Sander Hummerich", "Tristan Bereau", "Ullrich K\u00f6the"], "title": "Split-Flows: Measure Transport and Information Loss Across Molecular Resolutions", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "By reducing resolution, coarse-grained models greatly accelerate molecular\nsimulations, unlocking access to long-timescale phenomena, though at the\nexpense of microscopic information. Recovering this fine-grained detail is\nessential for tasks that depend on atomistic accuracy, making backmapping a\ncentral challenge in molecular modeling. We introduce split-flows, a novel\nflow-based approach that reinterprets backmapping as a continuous-time measure\ntransport across resolutions. Unlike existing generative strategies,\nsplit-flows establish a direct probabilistic link between resolutions, enabling\nexpressive conditional sampling of atomistic structures and -- for the first\ntime -- a tractable route to computing mapping entropies, an\ninformation-theoretic measure of the irreducible detail lost in\ncoarse-graining. We demonstrate these capabilities on diverse molecular\nsystems, including chignolin, a lipid bilayer, and alanine dipeptide,\nhighlighting split-flows as a principled framework for accurate backmapping and\nsystematic evaluation of coarse-grained models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fasplit - flows\u65b9\u6cd5\u7528\u4e8e\u5206\u5b50\u6a21\u578b\u7684\u53cd\u5411\u6620\u5c04\uff0c\u80fd\u5b9e\u73b0\u539f\u5b50\u7ed3\u6784\u91c7\u6837\u548c\u8ba1\u7b97\u6620\u5c04\u71b5\uff0c\u8fd8\u5728\u591a\u79cd\u5206\u5b50\u7cfb\u7edf\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u7c97\u7c92\u5ea6\u6a21\u578b\u867d\u52a0\u901f\u5206\u5b50\u6a21\u62df\u4f46\u4e22\u5931\u5fae\u89c2\u4fe1\u606f\uff0c\u6062\u590d\u7ec6\u7c92\u5ea6\u7ec6\u8282\u5bf9\u4f9d\u8d56\u539f\u5b50\u7cbe\u5ea6\u7684\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u53cd\u5411\u6620\u5c04\u662f\u5206\u5b50\u5efa\u6a21\u7684\u6838\u5fc3\u6311\u6218\u3002", "method": "\u5f15\u5165split - flows\u65b9\u6cd5\uff0c\u5c06\u53cd\u5411\u6620\u5c04\u91cd\u65b0\u89e3\u91ca\u4e3a\u8de8\u5206\u8fa8\u7387\u7684\u8fde\u7eed\u65f6\u95f4\u6d4b\u5ea6\u4f20\u8f93\uff0c\u5728\u4e0d\u540c\u5206\u8fa8\u7387\u95f4\u5efa\u7acb\u76f4\u63a5\u6982\u7387\u8054\u7cfb\u3002", "result": "\u5728\u591a\u79cd\u5206\u5b50\u7cfb\u7edf\uff08\u5982chignolin\u3001\u8102\u8d28\u53cc\u5c42\u548c\u4e19\u6c28\u9178\u4e8c\u80bd\uff09\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5b9e\u73b0\u539f\u5b50\u7ed3\u6784\u8868\u8fbe\u6027\u6761\u4ef6\u91c7\u6837\u548c\u8ba1\u7b97\u6620\u5c04\u71b5\u7684\u80fd\u529b\u3002", "conclusion": "split - flows\u662f\u7528\u4e8e\u7cbe\u786e\u53cd\u5411\u6620\u5c04\u548c\u7cfb\u7edf\u8bc4\u4f30\u7c97\u7c92\u5ea6\u6a21\u578b\u7684\u6709\u539f\u5219\u7684\u6846\u67b6\u3002"}}
{"id": "2511.01467", "pdf": "https://arxiv.org/pdf/2511.01467", "abs": "https://arxiv.org/abs/2511.01467", "authors": ["Ayanava Dasgupta", "Naqueeb Ahmad Warsi", "Masahito Hayashi"], "title": "Quantum Blackwell's Ordering and Differential Privacy", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "comment": "46 pages, 3 figures", "summary": "We develop a framework for quantum differential privacy (QDP) based on\nquantum hypothesis testing and Blackwell's ordering. This approach\ncharacterizes $(\\eps,\\delta)$-QDP via hypothesis testing divergences and\nidentifies the most informative quantum state pairs under privacy constraints.\nWe apply this to analyze the stability of quantum learning algorithms,\ngeneralizing classical results to the case $\\delta>0$. Additionally, we study\nprivatized quantum parameter estimation, deriving tight bounds on the quantum\nFisher information under QDP. Finally, we establish near-optimal contraction\nbounds for differentially private quantum channels with respect to the\nhockey-stick divergence.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u91cf\u5b50\u5047\u8bbe\u68c0\u9a8c\u548cBlackwell\u5e8f\u5f00\u53d1\u91cf\u5b50\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u91cf\u5b50\u5b66\u4e60\u7b97\u6cd5\u7a33\u5b9a\u6027\u5206\u6790\u3001\u91cf\u5b50\u53c2\u6570\u4f30\u8ba1\u5e76\u5efa\u7acb\u5dee\u5206\u9690\u79c1\u91cf\u5b50\u4fe1\u9053\u7684\u6536\u7f29\u754c\u3002", "motivation": "\u6784\u5efa\u91cf\u5b50\u5dee\u5206\u9690\u79c1\u6846\u67b6\uff0c\u5c06\u7ecf\u5178\u7ed3\u679c\u63a8\u5e7f\u5230\u91cf\u5b50\u9886\u57df\u5e76\u7814\u7a76\u76f8\u5173\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u91cf\u5b50\u5047\u8bbe\u68c0\u9a8c\u548cBlackwell\u5e8f\uff0c\u901a\u8fc7\u5047\u8bbe\u68c0\u9a8c\u6563\u5ea6\u523b\u753b(\u03b5,\u03b4)-QDP\u3002", "result": "\u5206\u6790\u4e86\u91cf\u5b50\u5b66\u4e60\u7b97\u6cd5\u7a33\u5b9a\u6027\uff0c\u63a8\u5bfc\u4e86\u91cf\u5b50\u53c2\u6570\u4f30\u8ba1\u7684\u91cf\u5b50Fisher\u4fe1\u606f\u7d27\u754c\uff0c\u5efa\u7acb\u4e86\u5dee\u5206\u9690\u79c1\u91cf\u5b50\u4fe1\u9053\u7684\u8fd1\u6700\u4f18\u6536\u7f29\u754c\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u6846\u67b6\u53ef\u6709\u6548\u5e94\u7528\u4e8e\u91cf\u5b50\u5b66\u4e60\u7b97\u6cd5\u5206\u6790\u3001\u91cf\u5b50\u53c2\u6570\u4f30\u8ba1\u53ca\u5dee\u5206\u9690\u79c1\u91cf\u5b50\u4fe1\u9053\u7814\u7a76\u3002"}}
{"id": "2511.01610", "pdf": "https://arxiv.org/pdf/2511.01610", "abs": "https://arxiv.org/abs/2511.01610", "authors": ["Mahmut Selman Gokmen", "Cody Bumgardner"], "title": "DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision Foundation Models (VFMs) have advanced representation learning through\nself-supervised methods. However, existing training pipelines are often\ninflexible, domain-specific, or computationally expensive, which limits their\nusability across different domains and resource settings. DINO-MX is a modular\nand extensible training framework that combines the core principles of DINO,\nDINOv2 and DINOv3 within a unified configuration-driven system. It supports a\nvariety of transformer-based architectures and is fully compatible with the\nHugging Face ecosystem. The framework includes multiple training strategies\nsuch as low-rank adaptation (LoRA), layer freezing, and knowledge distillation,\nalong with support for distributed training through both Distributed Data\nParallel (DDP) and Fully Sharded Data Parallel (FSDP). DINO-MX is designed to\nwork with both natural and specialized data types, including single- and\nmulti-channel images. Experimental results on diverse datasets show that\nDINO-MX achieves competitive performance while significantly reducing\ncomputational costs. Additionally, it offers interpretability tools and a\nlabel-guided data augmentation method that improves attention-based\nlocalization without the need for extra detection or segmentation heads.\nDINO-MX provides a reproducible and scalable foundation for developing,\nadapting, and benchmarking self-supervised vision models across a range of\nresearch and real-world applications.", "AI": {"tldr": "\u4ecb\u7ecdDINO - MX\u8bad\u7ec3\u6846\u67b6\uff0c\u5b83\u7ed3\u5408DINO\u7cfb\u5217\u539f\u5219\uff0c\u652f\u6301\u591a\u79cd\u7b56\u7565\u548c\u67b6\u6784\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u4e14\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u53ef\u7528\u4e8e\u591a\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\u7ba1\u9053\u5b58\u5728\u4e0d\u7075\u6d3b\u3001\u7279\u5b9a\u9886\u57df\u6216\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u9650\u5236\u5176\u5728\u4e0d\u540c\u9886\u57df\u548c\u8d44\u6e90\u73af\u5883\u7684\u53ef\u7528\u6027\u3002", "method": "\u6784\u5efa\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684DINO - MX\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408DINO\u7cfb\u5217\u6838\u5fc3\u539f\u5219\uff0c\u652f\u6301\u591a\u79cdTransformer\u67b6\u6784\uff0c\u91c7\u7528\u591a\u79cd\u8bad\u7ec3\u7b56\u7565\u548c\u5206\u5e03\u5f0f\u8bad\u7ec3\u65b9\u5f0f\u3002", "result": "\u5728\u4e0d\u540c\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cDINO - MX\u6027\u80fd\u6709\u7ade\u4e89\u529b\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u8fd8\u63d0\u4f9b\u89e3\u91ca\u5de5\u5177\u548c\u6807\u7b7e\u5f15\u5bfc\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002", "conclusion": "DINO - MX\u4e3a\u5f00\u53d1\u3001\u9002\u914d\u548c\u57fa\u51c6\u6d4b\u8bd5\u81ea\u76d1\u7763\u89c6\u89c9\u6a21\u578b\u63d0\u4f9b\u53ef\u91cd\u73b0\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2511.01491", "pdf": "https://arxiv.org/pdf/2511.01491", "abs": "https://arxiv.org/abs/2511.01491", "authors": ["Irched Chafaa", "E. Veronica Belmega", "Giacomo Bacci"], "title": "Deep Learning Prediction of Beam Coherence Time for Near-FieldTeraHertz Networks", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "IEEE Wireless Communication Letters (accepted October 2025)", "summary": "Large multiple antenna arrays coupled with accu- rate beamforming are\nessential in terahertz (THz) communi- cations to ensure link reliability.\nHowever, as the number of antennas increases, beam alignment (focusing) and\nbeam tracking in mobile networks incur prohibitive overhead. Additionally, the\nnear-field region expands both with the size of antenna arrays and the carrier\nfrequency, calling for adjustments in the beamforming to account for spherical\nwavefront instead of the conventional planar wave assumption. In this letter,\nwe introduce a novel beam coherence time for mobile THz networks, to\ndrastically reduce the rate of beam updates. Then, we propose a deep learning\nmodel, relying on a simple feedforward neural network with a time-dependent\ninput, to predict the beam coherence time and adjust the beamforming on the fly\nwith minimal overhead. Our numerical results demonstrate the effectiveness of\nthe proposed approach by enabling higher data rates while reducing the\noverhead, especially at high (i.e., vehicular) mobility.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u65b0\u7684\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\u6982\u5ff5\u5e76\u63d0\u51fa\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u51cf\u5c11\u6ce2\u675f\u66f4\u65b0\u5f00\u9500\uff0c\u63d0\u9ad8\u6570\u636e\u901f\u7387\u3002", "motivation": "\u592a\u8d6b\u5179\u901a\u4fe1\u4e2d\uff0c\u5929\u7ebf\u6570\u91cf\u589e\u52a0\u4f7f\u6ce2\u675f\u5bf9\u51c6\u548c\u8ddf\u8e2a\u5f00\u9500\u5927\uff0c\u8fd1\u573a\u533a\u57df\u53d8\u5316\u9700\u8c03\u6574\u6ce2\u675f\u5f62\u6210\uff0c\u56e0\u6b64\u8981\u964d\u4f4e\u6ce2\u675f\u66f4\u65b0\u7387\u3002", "method": "\u5f15\u5165\u65b0\u7684\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\uff0c\u63d0\u51fa\u4f9d\u8d56\u542b\u65f6\u95f4\u76f8\u5173\u8f93\u5165\u7684\u7b80\u5355\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\u5e76\u5b9e\u65f6\u8c03\u6574\u6ce2\u675f\u5f62\u6210\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u5728\u964d\u4f4e\u5f00\u9500\u7684\u540c\u65f6\u63d0\u9ad8\u6570\u636e\u901f\u7387\uff0c\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u6548\u679c\u660e\u663e\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u964d\u4f4e\u5f00\u9500\u5e76\u63d0\u9ad8\u6570\u636e\u901f\u7387\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u3002"}}
{"id": "2511.01615", "pdf": "https://arxiv.org/pdf/2511.01615", "abs": "https://arxiv.org/abs/2511.01615", "authors": ["Francisco Portillo L\u00f3pez"], "title": "Imperfect Language, Artificial Intelligence, and the Human Mind: An Interdisciplinary Approach to Linguistic Errors in Native Spanish Speakers", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 3 figures", "summary": "Linguistic errors are not merely deviations from normative grammar; they\noffer a unique window into the cognitive architecture of language and expose\nthe current limitations of artificial systems that seek to replicate them. This\nproject proposes an interdisciplinary study of linguistic errors produced by\nnative Spanish speakers, with the aim of analyzing how current large language\nmodels (LLM) interpret, reproduce, or correct them. The research integrates\nthree core perspectives: theoretical linguistics, to classify and understand\nthe nature of the errors; neurolinguistics, to contextualize them within\nreal-time language processing in the brain; and natural language processing\n(NLP), to evaluate their interpretation against linguistic errors. A\npurpose-built corpus of authentic errors of native Spanish (+500) will serve as\nthe foundation for empirical analysis. These errors will be tested against AI\nmodels such as GPT or Gemini to assess their interpretative accuracy and their\nability to generalize patterns of human linguistic behavior. The project\ncontributes not only to the understanding of Spanish as a native language but\nalso to the development of NLP systems that are more cognitively informed and\ncapable of engaging with the imperfect, variable, and often ambiguous nature of\nreal human language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bf9\u897f\u73ed\u7259\u8bed\u6bcd\u8bed\u8005\u8bed\u8a00\u9519\u8bef\u7684\u8de8\u5b66\u79d1\u7814\u7a76\uff0c\u7528\u81ea\u5efa\u8bed\u6599\u6d4b\u8bd5AI\u6a21\u578b\uff0c\u52a9\u529b\u897f\u73ed\u7259\u8bed\u7814\u7a76\u548cNLP\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u8bed\u8a00\u9519\u8bef\u80fd\u53cd\u6620\u8bed\u8a00\u8ba4\u77e5\u7ed3\u6784\u548c\u4eba\u5de5\u7cfb\u7edf\u5c40\u9650\uff0c\u65e8\u5728\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u897f\u73ed\u7259\u8bed\u6bcd\u8bed\u8005\u8bed\u8a00\u9519\u8bef\u7684\u5904\u7406\u80fd\u529b\u3002", "method": "\u6574\u5408\u7406\u8bba\u8bed\u8a00\u5b66\u3001\u795e\u7ecf\u8bed\u8a00\u5b66\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e09\u4e2a\u89c6\u89d2\uff0c\u7528\u81ea\u5efa\u7684\u8d85500\u4e2a\u771f\u5b9e\u9519\u8bef\u8bed\u6599\u6d4b\u8bd5GPT\u3001Gemini\u7b49AI\u6a21\u578b\u3002", "result": "\u672a\u63d0\u53ca", "conclusion": "\u8be5\u7814\u7a76\u6709\u52a9\u4e8e\u897f\u73ed\u7259\u8bed\u7814\u7a76\u548c\u5f00\u53d1\u66f4\u5177\u8ba4\u77e5\u80fd\u529b\u3001\u80fd\u5904\u7406\u771f\u5b9e\u4eba\u7c7b\u8bed\u8a00\u7684NLP\u7cfb\u7edf\u3002"}}
{"id": "2511.01554", "pdf": "https://arxiv.org/pdf/2511.01554", "abs": "https://arxiv.org/abs/2511.01554", "authors": ["Aditya Kapoor", "Yash Bhisikar", "Benjamin Freed", "Jan Peters", "Mingfei Sun"], "title": "Learning what to say and how precisely: Efficient Communication via Differentiable Discrete Communication Learning", "categories": ["cs.MA", "cs.IT", "cs.LG", "math.IT"], "comment": "30 pages, 12 figures, 6 tables", "summary": "Effective communication in multi-agent reinforcement learning (MARL) is\ncritical for success but constrained by bandwidth, yet past approaches have\nbeen limited to complex gating mechanisms that only decide \\textit{whether} to\ncommunicate, not \\textit{how precisely}. Learning to optimize message precision\nat the bit-level is fundamentally harder, as the required discretization step\nbreaks gradient flow. We address this by generalizing Differentiable Discrete\nCommunication Learning (DDCL), a framework for end-to-end optimization of\ndiscrete messages. Our primary contribution is an extension of DDCL to support\nunbounded signals, transforming it into a universal, plug-and-play layer for\nany MARL architecture. We verify our approach with three key results. First,\nthrough a qualitative analysis in a controlled environment, we demonstrate\n\\textit{how} agents learn to dynamically modulate message precision according\nto the informational needs of the task. Second, we integrate our variant of\nDDCL into four state-of-the-art MARL algorithms, showing it reduces bandwidth\nby over an order of magnitude while matching or exceeding task performance.\nFinally, we provide direct evidence for the \\enquote{Bitter Lesson} in MARL\ncommunication: a simple Transformer-based policy leveraging DDCL matches the\nperformance of complex, specialized architectures, questioning the necessity of\nbespoke communication designs.", "AI": {"tldr": "\u672c\u6587\u63a8\u5e7f\u4e86DDCL\u6846\u67b6\u4ee5\u652f\u6301\u65e0\u754c\u4fe1\u53f7\uff0c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u80fd\u8ba9\u667a\u80fd\u4f53\u52a8\u6001\u8c03\u6574\u6d88\u606f\u7cbe\u5ea6\u3001\u964d\u4f4e\u5e26\u5bbd\u5e76\u8d28\u7591\u5b9a\u5236\u901a\u4fe1\u8bbe\u8ba1\u5fc5\u8981\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u6709\u6548\u901a\u4fe1\u53d7\u5e26\u5bbd\u9650\u5236\uff0c\u4ee5\u5f80\u65b9\u6cd5\u53ea\u80fd\u51b3\u5b9a\u662f\u5426\u901a\u4fe1\uff0c\u4e0d\u80fd\u7cbe\u786e\u63a7\u5236\u3002", "method": "\u63a8\u5e7fDifferentiable Discrete Communication Learning (DDCL) \u6846\u67b6\uff0c\u4f7f\u5176\u6210\u4e3a\u9002\u7528\u4e8e\u4efb\u4f55MARL\u67b6\u6784\u7684\u901a\u7528\u5373\u63d2\u5373\u7528\u5c42\u3002", "result": "1. \u5c55\u793a\u667a\u80fd\u4f53\u5982\u4f55\u6839\u636e\u4efb\u52a1\u4fe1\u606f\u9700\u6c42\u52a8\u6001\u8c03\u6574\u6d88\u606f\u7cbe\u5ea6\uff1b2. \u96c6\u6210\u5230\u56db\u79cd\u5148\u8fdbMARL\u7b97\u6cd5\u4e2d\uff0c\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\u5e26\u5bbd\uff0c\u4e14\u4e0d\u5f71\u54cd\u4efb\u52a1\u8868\u73b0\uff1b3. \u7b80\u5355\u7684\u57fa\u4e8eTransformer\u7b56\u7565\u80fd\u8fbe\u5230\u590d\u6742\u67b6\u6784\u6027\u80fd\u3002", "conclusion": "\u63a8\u5e7f\u7684DDCL\u6846\u67b6\u6709\u6548\uff0c\u8d28\u7591\u4e86\u5b9a\u5236\u901a\u4fe1\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.01555", "pdf": "https://arxiv.org/pdf/2511.01555", "abs": "https://arxiv.org/abs/2511.01555", "authors": ["Nathan J. LeRoy", "Donald R. Campbell Jr", "Seth Stadick", "Oleksandr Khoroshevskyi", "Sang-Hoon Park", "Ziyang Hu", "Nathan C. Sheffield"], "title": "Fast, memory-efficient genomic interval tokenizers for modern machine learning", "categories": ["q-bio.GN", "cs.LG"], "comment": "4 pages, 1 figure", "summary": "Introduction: Epigenomic datasets from high-throughput sequencing experiments\nare commonly summarized as genomic intervals. As the volume of this data grows,\nso does interest in analyzing it through deep learning. However, the\nheterogeneity of genomic interval data, where each dataset defines its own\nregions, creates barriers for machine learning methods that require consistent,\ndiscrete vocabularies. Methods: We introduce gtars-tokenizers, a\nhigh-performance library that maps genomic intervals to a predefined universe\nor vocabulary of regions, analogous to text tokenization in natural language\nprocessing. Built in Rust with bindings for Python, R, CLI, and WebAssembly,\ngtars-tokenizers implements two overlap methods (BITS and AIList) and\nintegrates seamlessly with modern ML frameworks through Hugging Face-compatible\nAPIs. Results: The gtars-tokenizers package achieves top efficiency for\nlarge-scale datasets, while enabling genomic intervals to be processed using\nstandard ML workflows in PyTorch and TensorFlow without ad hoc preprocessing.\nThis token-based approach bridges genomics and machine learning, supporting\nscalable and standardized analysis of interval data across diverse\ncomputational environments. Availability: PyPI and GitHub:\nhttps://github.com/databio/gtars.", "AI": {"tldr": "\u4ecb\u7ecdgtars - tokenizers\u5e93\uff0c\u53ef\u5c06\u57fa\u56e0\u7ec4\u533a\u95f4\u6620\u5c04\u5230\u9884\u5b9a\u4e49\u533a\u57df\uff0c\u5b9e\u73b0\u9ad8\u6548\u5904\u7406\u57fa\u56e0\u7ec4\u533a\u95f4\u6570\u636e\u3002", "motivation": "\u9ad8\u901a\u91cf\u6d4b\u5e8f\u5b9e\u9a8c\u7684\u8868\u89c2\u57fa\u56e0\u7ec4\u6570\u636e\u96c6\u4ee5\u57fa\u56e0\u7ec4\u533a\u95f4\u5f62\u5f0f\u5b58\u5728\uff0c\u5176\u6570\u636e\u5f02\u8d28\u6027\u7ed9\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e26\u6765\u969c\u788d\uff0c\u9700\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5f15\u5165gtars - tokenizers\u5e93\uff0c\u7528Rust\u6784\u5efa\uff0c\u6709\u591a\u79cd\u8bed\u8a00\u7ed1\u5b9a\uff0c\u5b9e\u73b0\u4e24\u79cd\u91cd\u53e0\u65b9\u6cd5\uff0c\u901a\u8fc7\u517c\u5bb9Hugging Face\u7684API\u4e0e\u73b0\u4ee3ML\u6846\u67b6\u96c6\u6210\u3002", "result": "gtars - tokenizers\u5305\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u6548\u7387\u9ad8\uff0c\u80fd\u8ba9\u57fa\u56e0\u7ec4\u533a\u95f4\u7528\u6807\u51c6ML\u5de5\u4f5c\u6d41\u5904\u7406\uff0c\u65e0\u9700\u7279\u6b8a\u9884\u5904\u7406\u3002", "conclusion": "\u57fa\u4e8e\u4ee4\u724c\u7684\u65b9\u6cd5\u8fde\u63a5\u4e86\u57fa\u56e0\u7ec4\u5b66\u548c\u673a\u5668\u5b66\u4e60\uff0c\u652f\u6301\u5728\u4e0d\u540c\u8ba1\u7b97\u73af\u5883\u4e2d\u5bf9\u533a\u95f4\u6570\u636e\u8fdb\u884c\u53ef\u6269\u5c55\u548c\u6807\u51c6\u5316\u5206\u6790\u3002"}}
{"id": "2511.01634", "pdf": "https://arxiv.org/pdf/2511.01634", "abs": "https://arxiv.org/abs/2511.01634", "authors": ["Daniyal Ganiuly", "Assel Smaiyl"], "title": "Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) are increasingly used in intelligent systems\nthat perform reasoning, summarization, and code generation. Their ability to\nfollow natural-language instructions, while powerful, also makes them\nvulnerable to a new class of attacks known as prompt injection. In these\nattacks, hidden or malicious instructions are inserted into user inputs or\nexternal content, causing the model to ignore its intended task or produce\nunsafe responses. This study proposes a unified framework for evaluating how\nresistant Large Language Models (LLMs) are to prompt injection attacks. The\nframework defines three complementary metrics such as the Resilience\nDegradation Index (RDI), Safety Compliance Coefficient (SCC), and Instructional\nIntegrity Metric (IIM) to jointly measure robustness, safety, and semantic\nstability. We evaluated four instruction-tuned models (GPT-4, GPT-4o, LLaMA-3\n8B Instruct, and Flan-T5-Large) on five common language tasks: question\nanswering, summarization, translation, reasoning, and code generation. Results\nshow that GPT-4 performs best overall, while open-weight models remain more\nvulnerable. The findings highlight that strong alignment and safety tuning are\nmore important for resilience than model size alone. Results show that all\nmodels remain partially vulnerable, especially to indirect and direct-override\nattacks. GPT-4 achieved the best overall resilience (RDR = 9.8 %, SCR = 96.4\n%), while open-source models exhibited higher performance degradation and lower\nsafety scores. The findings demonstrate that alignment strength and safety\ntuning play a greater role in resilience than model size alone. The proposed\nframework offers a structured, reproducible approach for assessing model\nrobustness and provides practical insights for improving LLM safety and\nreliability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u6297\u6027\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8bc4\u4f30\u56db\u4e2a\u6a21\u578b\u5728\u4e94\u9879\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT - 4\u603b\u4f53\u6700\u4f73\uff0c\u5f00\u6e90\u6a21\u578b\u66f4\u8106\u5f31\uff0c\u5f3a\u8c03\u5bf9\u9f50\u548c\u5b89\u5168\u8c03\u4f18\u6bd4\u6a21\u578b\u5927\u5c0f\u66f4\u91cd\u8981\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u9700\u8bc4\u4f30\u5176\u5bf9\u6297\u6b64\u7c7b\u653b\u51fb\u7684\u6297\u6027\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff0c\u5b9a\u4e49\u4e09\u4e2a\u4e92\u8865\u6307\u6807\uff08RDI\u3001SCC\u3001IIM\uff09\uff0c\u8bc4\u4f30\u56db\u4e2a\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5728\u4e94\u9879\u5e38\u89c1\u8bed\u8a00\u4efb\u52a1\u7684\u8868\u73b0\u3002", "result": "GPT - 4\u603b\u4f53\u8868\u73b0\u6700\u4f73\uff0c\u5f00\u6e90\u6a21\u578b\u66f4\u6613\u53d7\u653b\u51fb\uff0c\u6240\u6709\u6a21\u578b\u4ecd\u90e8\u5206\u8106\u5f31\uff0c\u5c24\u5176\u5bf9\u95f4\u63a5\u548c\u76f4\u63a5\u8986\u76d6\u653b\u51fb\u3002", "conclusion": "\u5bf9\u9f50\u5f3a\u5ea6\u548c\u5b89\u5168\u8c03\u4f18\u5bf9\u6a21\u578b\u6297\u6027\u7684\u4f5c\u7528\u6bd4\u6a21\u578b\u5927\u5c0f\u66f4\u91cd\u8981\uff0c\u6846\u67b6\u4e3a\u8bc4\u4f30\u6a21\u578b\u9c81\u68d2\u6027\u63d0\u4f9b\u65b9\u6cd5\uff0c\u5bf9\u63d0\u5347LLM\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2511.01650", "pdf": "https://arxiv.org/pdf/2511.01650", "abs": "https://arxiv.org/abs/2511.01650", "authors": ["Ayesha Gull", "Muhammad Usman Safder", "Rania Elbadry", "Preslav Nakov", "Zhuohan Xie"], "title": "EngChain: A Symbolic Benchmark for Verifiable Multi-Step Reasoning in Engineering", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "24 pages, includes figures and tables; introduces the EngChain\n  benchmark", "summary": "Large Language Models (LLMs) are increasingly being applied to specialized,\nhigh-stakes domains like engineering, which demands rigorous evaluation of\ntheir complex reasoning capabilities. While current benchmarks assess language\nunderstanding, factual recall, mathematics or code generation, none capture the\nintegrative reasoning central to engineering where scientific principles,\nquantitative modeling and practical constraints must converge. To address this\ngap, we introduce EngChain, a benchmark for verifiable multi-step engineering\nproblem-solving. EngChain contains 90 problems spanning three engineering\nbranches, organized into 9 domains and 20 distinct areas. The problems are\ngenerated from symbolic templates with a high degree of randomization to ensure\ndiversity and eliminate the risk of contamination. With this benchmark, we move\nbeyond final answer accuracy with a two-stage evaluation: we first\nquantitatively verify the numerical and semantic validity of each reasoning\nstep and then introduce LLM-As-A-Judge, an automated system to qualitatively\ncategorize the identified reasoning errors.", "AI": {"tldr": "\u5f15\u5165EngChain\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u9886\u57df\u7684\u591a\u6b65\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u9886\u57df\u7684\u7efc\u5408\u63a8\u7406\u80fd\u529b\uff0c\u9700\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u5305\u542b90\u4e2a\u95ee\u9898\u7684EngChain\u57fa\u51c6\u6d4b\u8bd5\uff0c\u95ee\u9898\u7531\u7b26\u53f7\u6a21\u677f\u751f\u6210\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u3002", "result": "\u53ef\u5b9a\u91cf\u9a8c\u8bc1\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u503c\u548c\u8bed\u4e49\u6709\u6548\u6027\uff0c\u8fd8\u80fd\u901a\u8fc7LLM - As - A - Judge\u7cfb\u7edf\u5b9a\u6027\u5206\u7c7b\u63a8\u7406\u9519\u8bef\u3002", "conclusion": "EngChain\u53ef\u6709\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u9886\u57df\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2511.01663", "pdf": "https://arxiv.org/pdf/2511.01663", "abs": "https://arxiv.org/abs/2511.01663", "authors": ["Louis Bradshaw", "Alexander Spangher", "Stella Biderman", "Simon Colton"], "title": "The Ghost in the Keys: A Disklavier Demo for Human-AI Musical Co-Creativity", "categories": ["cs.SD", "cs.AI", "cs.HC"], "comment": null, "summary": "While generative models for music composition are increasingly capable, their\nadoption by musicians is hindered by text-prompting, an asynchronous workflow\ndisconnected from the embodied, responsive nature of instrumental performance.\nTo address this, we introduce Aria-Duet, an interactive system facilitating a\nreal-time musical duet between a human pianist and Aria, a state-of-the-art\ngenerative model, using a Yamaha Disklavier as a shared physical interface. The\nframework enables a turn-taking collaboration: the user performs, signals a\nhandover, and the model generates a coherent continuation performed\nacoustically on the piano. Beyond describing the technical architecture\nenabling this low-latency interaction, we analyze the system's output from a\nmusicological perspective, finding the model can maintain stylistic semantics\nand develop coherent phrasal ideas, demonstrating that such embodied systems\ncan engage in musically sophisticated dialogue and open a promising new path\nfor human-AI co-creation.", "AI": {"tldr": "\u4ecb\u7ecdAria - Duet\u4ea4\u4e92\u5f0f\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4eba\u7c7b\u94a2\u7434\u5bb6\u4e0e\u751f\u6210\u6a21\u578b\u5b9e\u65f6\u97f3\u4e50\u4e8c\u91cd\u594f\uff0c\u7cfb\u7edf\u8f93\u51fa\u6709\u97f3\u4e50\u4ef7\u503c\uff0c\u4e3a\u4eba\u673a\u5171\u521b\u5f00\u8f9f\u65b0\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u97f3\u4e50\u751f\u6210\u6a21\u578b\u56e0\u6587\u672c\u63d0\u793a\u548c\u5f02\u6b65\u5de5\u4f5c\u6d41\u7a0b\uff0c\u963b\u788d\u4e86\u97f3\u4e50\u5bb6\u7684\u91c7\u7528\uff0c\u9700\u89e3\u51b3\u4e0e\u4e50\u5668\u6f14\u594f\u5b9e\u65f6\u54cd\u5e94\u7279\u6027\u8131\u8282\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165Aria - Duet\u7cfb\u7edf\uff0c\u4ee5Yamaha Disklavier\u4e3a\u5171\u4eab\u7269\u7406\u63a5\u53e3\uff0c\u5b9e\u73b0\u4eba\u673a\u8f6e\u6d41\u534f\u4f5c\uff0c\u7528\u6237\u6f14\u594f\u3001\u4ea4\u63a5\u4fe1\u53f7\uff0c\u6a21\u578b\u751f\u6210\u8fde\u8d2f\u7eed\u66f2\u3002", "result": "\u4ece\u97f3\u4e50\u5b66\u89d2\u5ea6\u5206\u6790\u7cfb\u7edf\u8f93\u51fa\uff0c\u6a21\u578b\u80fd\u4fdd\u6301\u98ce\u683c\u8bed\u4e49\u5e76\u53d1\u5c55\u8fde\u8d2f\u4e50\u53e5\u60f3\u6cd5\u3002", "conclusion": "\u6b64\u7c7b\u5177\u8eab\u7cfb\u7edf\u53ef\u8fdb\u884c\u590d\u6742\u97f3\u4e50\u5bf9\u8bdd\uff0c\u4e3a\u4eba\u673a\u5171\u521b\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u65b0\u8def\u5f84\u3002"}}
{"id": "2511.01670", "pdf": "https://arxiv.org/pdf/2511.01670", "abs": "https://arxiv.org/abs/2511.01670", "authors": ["Chaoqun Liu", "Mahani Aljunied", "Guizhen Chen", "Hou Pong Chan", "Weiwen Xu", "Yu Rong", "Wenxuan Zhang"], "title": "SeaLLMs-Audio: Large Audio-Language Models for Southeast Asia", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages", "summary": "We introduce SeaLLMs-Audio, the first large audio-language model (LALM)\ntailored for multiple Southeast Asian (SEA) languages-Indonesian (id), Thai\n(th), and Vietnamese (vi)-alongside English (en) and Chinese (zh). Trained on a\nlarge-scale audio corpus, SeaLLMs-Audio exhibits strong performance across\ndiverse audio-centric tasks, spanning fine-grained audio understanding and\nvoice-based interaction. Its key features include: 1) Multilingual: the model\nprimarily supports 5 languages, namely Indonesian, Thai, Vietnamese, English,\nand Chinese; 2) Multimodal: the model accepts flexible input modalities,\nincluding audio only, text only, as well as audio with text; 3) Multi-task: the\nmodel supports a wide range of tasks, including audio analysis tasks such as\nAudio Captioning, Automatic Speech Recognition, Speech-to-Text Translation,\nSpeech Emotion Recognition, Speech Question Answering, and Speech\nSummarization. It also enables voice-based dialogue, including answering\nfactual, mathematical, and general knowledge queries. As a significant step\ntowards advancing audio LLMs in Southeast Asia, we expect SeaLLMs-Audio to\nbenefit both the regional research community and industry. To automate LALM\nevaluation for Southeast Asia, we introduce SeaBench-Audio, a benchmark\nspanning multiple tasks. Experiments show that SeaLLMs-Audio achieves\ncompetitive performance compared with other LALMs on SEA languages.", "AI": {"tldr": "\u4ecb\u7ecd\u9996\u4e2a\u9488\u5bf9\u591a\u79cd\u4e1c\u5357\u4e9a\u8bed\u8a00\u7684\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578bSeaLLMs - Audio\u53ca\u5176\u7279\u70b9\uff0c\u8fd8\u5f15\u5165\u8bc4\u4f30\u57fa\u51c6SeaBench - Audio\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u4e1c\u5357\u4e9a\u8bed\u8a00\u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u63a8\u52a8\u4e1c\u5357\u4e9a\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0c\u4f7f\u6a21\u578b\u80fd\u652f\u6301\u591a\u79cd\u4e1c\u5357\u4e9a\u8bed\u8a00\u53ca\u591a\u4efb\u52a1\u3002", "method": "\u5728\u5927\u89c4\u6a21\u97f3\u9891\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3SeaLLMs - Audio\uff0c\u5f15\u5165SeaBench - Audio\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "SeaLLMs - Audio\u5728\u5404\u79cd\u4ee5\u97f3\u9891\u4e3a\u4e2d\u5fc3\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5728\u4e1c\u5357\u4e9a\u8bed\u8a00\u4e0a\u4e0e\u5176\u4ed6LALMs\u76f8\u6bd4\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "SeaLLMs - Audio\u5bf9\u4e1c\u5357\u4e9a\u7814\u7a76\u754c\u548c\u884c\u4e1a\u6709\u76ca\uff0c\u662f\u63a8\u8fdb\u8be5\u5730\u533a\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.01654", "pdf": "https://arxiv.org/pdf/2511.01654", "abs": "https://arxiv.org/abs/2511.01654", "authors": ["Congcong Chen", "Xinyu Liu", "Kaifeng Huang", "Lifei Wei", "Yang Shi"], "title": "Panther: A Cost-Effective Privacy-Preserving Framework for GNN Training and Inference Services in Cloud Environments", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted for publication in IEEE Transactions on Services Computing\n  (TSC)", "summary": "Graph Neural Networks (GNNs) have marked significant impact in traffic state\nprediction, social recommendation, knowledge-aware question answering and so\non. As more and more users move towards cloud computing, it has become a\ncritical issue to unleash the power of GNNs while protecting the privacy in\ncloud environments. Specifically, the training data and inference data for GNNs\nneed to be protected from being stolen by external adversaries. Meanwhile, the\nfinancial cost of cloud computing is another primary concern for users.\nTherefore, although existing studies have proposed privacy-preserving\ntechniques for GNNs in cloud environments, their additional computational and\ncommunication overhead remain relatively high, causing high financial costs\nthat limit their widespread adoption among users.\n  To protect GNN privacy while lowering the additional financial costs, we\nintroduce Panther, a cost-effective privacy-preserving framework for GNN\ntraining and inference services in cloud environments. Technically, Panther\nleverages four-party computation to asynchronously executing the secure array\naccess protocol, and randomly pads the neighbor information of GNN nodes. We\nprove that Panther can protect privacy for both training and inference of GNN\nmodels. Our evaluation shows that Panther reduces the training and inference\ntime by an average of 75.28% and 82.80%, respectively, and communication\noverhead by an average of 52.61% and 50.26% compared with the state-of-the-art,\nwhich is estimated to save an average of 55.05% and 59.00% in financial costs\n(based on on-demand pricing model) for the GNN training and inference process\non Google Cloud Platform.", "AI": {"tldr": "\u73b0\u6709\u4e91\u73af\u5883\u4e0bGNN\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5f00\u9500\u5927\uff0c\u672c\u6587\u63d0\u51faPanther\u6846\u67b6\uff0c\u80fd\u964d\u4f4e\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u3001\u901a\u4fe1\u5f00\u9500\u53ca\u8d22\u52a1\u6210\u672c\u3002", "motivation": "\u968f\u7740\u7528\u6237\u5411\u4e91\u8ba1\u7b97\u8fc1\u79fb\uff0c\u5728\u4e91\u73af\u5883\u4e2d\u4fdd\u62a4GNN\u9690\u79c1\u5e76\u964d\u4f4e\u4e91\u8ba1\u7b97\u8d22\u52a1\u6210\u672c\u6210\u4e3a\u5173\u952e\u95ee\u9898\uff0c\u73b0\u6709\u6280\u672f\u5f00\u9500\u9ad8\u9650\u5236\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u5f15\u5165Panther\u6846\u67b6\uff0c\u5229\u7528\u56db\u65b9\u8ba1\u7b97\u5f02\u6b65\u6267\u884c\u5b89\u5168\u6570\u7ec4\u8bbf\u95ee\u534f\u8bae\uff0c\u968f\u673a\u586b\u5145GNN\u8282\u70b9\u90bb\u5c45\u4fe1\u606f\u3002", "result": "\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0cPanther\u5e73\u5747\u51cf\u5c1175.28%\u7684\u8bad\u7ec3\u65f6\u95f4\u548c82.80%\u7684\u63a8\u7406\u65f6\u95f4\uff0c\u5e73\u5747\u964d\u4f4e52.61%\u548c50.26%\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u5728\u8c37\u6b4c\u4e91\u5e73\u53f0\u4e0aGNN\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u9884\u8ba1\u5e73\u5747\u8282\u770155.05%\u548c59.00%\u7684\u8d22\u52a1\u6210\u672c\u3002", "conclusion": "Panther\u80fd\u6709\u6548\u4fdd\u62a4GNN\u9690\u79c1\uff0c\u540c\u65f6\u964d\u4f4e\u989d\u5916\u8d22\u52a1\u6210\u672c\u3002"}}
{"id": "2511.01671", "pdf": "https://arxiv.org/pdf/2511.01671", "abs": "https://arxiv.org/abs/2511.01671", "authors": ["Ruichen Li", "Yuzhi Liu", "Du Jiang", "Yixiao Chen", "Xuelan Wen", "Wenrui Li", "Di He", "Liwei Wang", "Ji Chen", "Weiluo Ren"], "title": "Spin-Adapted Neural Network Wavefunctions in Real Space", "categories": ["physics.chem-ph", "cs.AI"], "comment": null, "summary": "Spin plays a fundamental role in understanding electronic structure, yet many\nreal-space wavefunction methods fail to adequately consider it. We introduce\nthe Spin-Adapted Antisymmetrization Method (SAAM), a general procedure that\nenforces exact total spin symmetry for antisymmetric many-electron\nwavefunctions in real space. In the context of neural network-based quantum\nMonte Carlo (NNQMC), SAAM leverages the expressiveness of deep neural networks\nto capture electron correlation while enforcing exact spin adaptation via group\nrepresentation theory. This framework provides a principled route to embed\nphysical priors into otherwise black-box neural network wavefunctions, yielding\na compact representation of correlated system with neural network orbitals.\nCompared with existing treatments of spin in NNQMC, SAAM is more accurate and\nefficient, achieving exact spin purity without any additional tunable\nhyperparameters. To demonstrate its effectiveness, we apply SAAM to study the\nspin ladder of iron-sulfur clusters, a long-standing challenge for many-body\nmethods due to their dense spectrum of nearly degenerate spin states. Our\nresults reveal accurate resolution of low-lying spin states and spin gaps in\n[Fe$_2$S$_2$] and [Fe$_4$S$_4$] clusters, offering new insights into their\nelectronic structures. In sum, these findings establish SAAM as a robust,\nhyperparameter-free standard for spin-adapted NNQMC, particularly for strongly\ncorrelated systems.", "AI": {"tldr": "\u4ecb\u7ecd\u81ea\u65cb\u9002\u914d\u53cd\u5bf9\u79f0\u5316\u65b9\u6cd5\uff08SAAM\uff09\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u91cf\u5b50\u8499\u7279\u5361\u7f57\uff0c\u66f4\u51c6\u786e\u9ad8\u6548\uff0c\u5e94\u7528\u4e8e\u94c1 - \u786b\u7c07\u7814\u7a76\u83b7\u826f\u597d\u7ed3\u679c\u3002", "motivation": "\u8bb8\u591a\u5b9e\u7a7a\u95f4\u6ce2\u51fd\u6570\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u81ea\u65cb\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5f15\u5165SAAM\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u91cf\u5b50\u8499\u7279\u5361\u7f57\u4e2d\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8868\u8fbe\u80fd\u529b\uff0c\u901a\u8fc7\u7fa4\u8868\u793a\u7406\u8bba\u5b9e\u73b0\u7cbe\u786e\u81ea\u65cb\u9002\u914d\u3002", "result": "\u5e94\u7528SAAM\u7814\u7a76\u94c1 - \u786b\u7c07\uff0c\u51c6\u786e\u89e3\u6790\u4f4e\u6fc0\u53d1\u81ea\u65cb\u6001\u548c\u81ea\u65cb\u80fd\u9699\uff0c\u83b7\u7535\u5b50\u7ed3\u6784\u65b0\u89c1\u89e3\u3002", "conclusion": "SAAM\u662f\u81ea\u65cb\u9002\u914d\u795e\u7ecf\u7f51\u7edc\u91cf\u5b50\u8499\u7279\u5361\u7f57\u7684\u53ef\u9760\u3001\u65e0\u8d85\u53c2\u6570\u6807\u51c6\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5f3a\u5173\u8054\u7cfb\u7edf\u3002"}}
{"id": "2511.01680", "pdf": "https://arxiv.org/pdf/2511.01680", "abs": "https://arxiv.org/abs/2511.01680", "authors": ["Jacob Carlson"], "title": "Making Interpretable Discoveries from Unstructured Data: A High-Dimensional Multiple Hypothesis Testing Approach", "categories": ["econ.EM", "cs.LG"], "comment": null, "summary": "Social scientists are increasingly turning to unstructured datasets to unlock\nnew empirical insights, e.g., estimating causal effects on text outcomes,\nmeasuring beliefs from open-ended survey responses. In such settings,\nunsupervised analysis is often of interest, in that the researcher does not\nwant to pre-specify the objects of measurement or otherwise artificially\ndelimit the space of measurable concepts; they are interested in discovery.\nThis paper proposes a general and flexible framework for pursuing discovery\nfrom unstructured data in a statistically principled way. The framework\nleverages recent methods from the literature on machine learning\ninterpretability to map unstructured data points to high-dimensional, sparse,\nand interpretable dictionaries of concepts; computes (test) statistics of these\ndictionary entries; and then performs selective inference on them using newly\ndeveloped statistical procedures for high-dimensional exceedance control of the\n$k$-FWER under arbitrary dependence. The proposed framework has few researcher\ndegrees of freedom, is fully replicable, and is cheap to implement -- both in\nterms of financial cost and researcher time. Applications to recent descriptive\nand causal analyses of unstructured data in empirical economics are explored.\nAn open source Jupyter notebook is provided for researchers to implement the\nframework in their own projects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ece\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u4ee5\u7edf\u8ba1\u539f\u5219\u8fdb\u884c\u53d1\u73b0\u7684\u901a\u7528\u7075\u6d3b\u6846\u67b6\uff0c\u5e76\u5728\u5b9e\u8bc1\u7ecf\u6d4e\u5b66\u4e2d\u5e94\u7528\uff0c\u8fd8\u63d0\u4f9b\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u793e\u4f1a\u79d1\u5b66\u5bb6\u5229\u7528\u975e\u7ed3\u6784\u5316\u6570\u636e\u83b7\u53d6\u65b0\u5b9e\u8bc1\u89c1\u89e3\uff0c\u65e0\u76d1\u7763\u5206\u6790\u53d7\u5173\u6ce8\uff0c\u9700\u4ece\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u8fdb\u884c\u53d1\u73b0\u3002", "method": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5c06\u6570\u636e\u6620\u5c04\u5230\u6982\u5ff5\u5b57\u5178\uff0c\u8ba1\u7b97\u7edf\u8ba1\u91cf\uff0c\u4f7f\u7528\u65b0\u7edf\u8ba1\u7a0b\u5e8f\u8fdb\u884c\u9009\u62e9\u6027\u63a8\u7406\u3002", "result": "\u6846\u67b6\u81ea\u7531\u5ea6\u5c11\u3001\u53ef\u5b8c\u5168\u590d\u73b0\u3001\u5b9e\u65bd\u6210\u672c\u4f4e\uff0c\u5e76\u5728\u5b9e\u8bc1\u7ecf\u6d4e\u5b66\u4e2d\u6709\u5e94\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u4ece\u975e\u7ed3\u6784\u5316\u6570\u636e\u4e2d\u8fdb\u884c\u53d1\u73b0\uff0c\u8fd8\u63d0\u4f9b\u5f00\u6e90\u4ee3\u7801\u65b9\u4fbf\u7814\u7a76\u8005\u4f7f\u7528\u3002"}}
{"id": "2511.01683", "pdf": "https://arxiv.org/pdf/2511.01683", "abs": "https://arxiv.org/abs/2511.01683", "authors": ["Kirk Vanacore", "Jaclyn Ocumpaugh", "Forest Agostinelli", "Dezhi Wu", "Sai Vuruma", "Matt Irvin"], "title": "Student Engagement in AI Assisted Complex Problem Solving: A Pilot Study of Human AI Rubik's Cube Collaboration", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Games and puzzles play important pedagogical roles in STEM learning. New AI\nalgorithms that can solve complex problems offer opportunities for scaffolded\ninstruction in puzzle solving. This paper presents the ALLURE system, which\nuses an AI algorithm (DeepCubeA) to guide students in solving a common first\nstep of the Rubik's Cube (i.e., the white cross). Using data from a pilot study\nwe present preliminary findings about students' behaviors in the system, how\nthese behaviors are associated with STEM skills - including spatial reasoning,\ncritical thinking and algorithmic thinking. We discuss how data from ALLURE can\nbe used in future educational data mining to understand how students benefit\nfrom AI assistance and collaboration when solving complex problems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdALLURE\u7cfb\u7edf\uff0c\u7528AI\u7b97\u6cd5\u6307\u5bfc\u5b66\u751f\u89e3\u9b54\u65b9\u767d\u8272\u5341\u5b57\uff0c\u901a\u8fc7\u8bd5\u70b9\u7814\u7a76\u5c55\u793a\u5b66\u751f\u884c\u4e3a\u4e0eSTEM\u6280\u80fd\u5173\u8054\uff0c\u63a2\u8ba8\u5176\u6570\u636e\u7528\u4e8e\u672a\u6765\u6559\u80b2\u6570\u636e\u6316\u6398\u7684\u53ef\u80fd\u3002", "motivation": "\u6e38\u620f\u548c\u8c1c\u9898\u5728STEM\u5b66\u4e60\u6709\u91cd\u8981\u6559\u5b66\u4f5c\u7528\uff0c\u65b0AI\u7b97\u6cd5\u4e3a\u89e3\u8c1c\u7684\u652f\u67b6\u5f0f\u6559\u5b66\u63d0\u4f9b\u673a\u4f1a\u3002", "method": "\u63d0\u51faALLURE\u7cfb\u7edf\uff0c\u7528DeepCubeA\u7b97\u6cd5\u6307\u5bfc\u5b66\u751f\u89e3\u9b54\u65b9\u767d\u8272\u5341\u5b57\uff0c\u5f00\u5c55\u8bd5\u70b9\u7814\u7a76\u3002", "result": "\u5c55\u793a\u4e86\u5b66\u751f\u5728\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u53ca\u8fd9\u4e9b\u884c\u4e3a\u4e0eSTEM\u6280\u80fd\u7684\u5173\u8054\u3002", "conclusion": "ALLURE\u7cfb\u7edf\u7684\u6570\u636e\u53ef\u7528\u4e8e\u672a\u6765\u6559\u80b2\u6570\u636e\u6316\u6398\uff0c\u4ee5\u4e86\u89e3\u5b66\u751f\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u5982\u4f55\u4eceAI\u8f85\u52a9\u548c\u534f\u4f5c\u4e2d\u53d7\u76ca\u3002"}}
{"id": "2511.01689", "pdf": "https://arxiv.org/pdf/2511.01689", "abs": "https://arxiv.org/abs/2511.01689", "authors": ["Sharan Maiya", "Henning Bartsch", "Nathan Lambert", "Evan Hubinger"], "title": "Open Character Training: Shaping the Persona of AI Assistants through Constitutional AI", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "12 pages, 6 figures, 4 tables", "summary": "The character of the \"AI assistant\" persona generated by modern chatbot large\nlanguage models influences both surface-level behavior and apparent values,\nbeliefs, and ethics. These all affect interaction quality, perceived\nintelligence, and alignment with both developer and user intentions. The\nshaping of this persona, known as character training, is a critical component\nof industry post-training, yet remains effectively unstudied in the academic\nliterature. We introduce the first open implementation of character training,\nleveraging Constitutional AI and a new data pipeline using synthetic\nintrospective data to shape the assistant persona in a more effective and\ncontrolled manner than alternatives such as constraining system prompts or\nactivation steering. Specifically, we fine-tune three popular open-weights\nmodels using 11 example personas, such as humorous, deeply caring, or even\nmalevolent. To track the effects of our approach, we introduce a method which\nanalyzes revealed preferences, uncovering clear and holistic changes in\ncharacter. We find these changes are more robust to adversarial prompting than\nthe above two alternatives, while also leading to more coherent and realistic\ngenerations. Finally, we demonstrate this fine-tuning has little to no effect\non general capabilities as measured by common benchmarks. We describe and\nopen-source our full post-training method, the implementation of which can be\nfound at https://github.com/maiush/OpenCharacterTraining.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u9996\u4e2a\u5f00\u653e\u7684\u89d2\u8272\u8bad\u7ec3\u5b9e\u73b0\uff0c\u7528\u5408\u6210\u81ea\u7701\u6570\u636e\u5851\u9020\u804a\u5929\u673a\u5668\u4eba\u89d2\u8272\uff0c\u6548\u679c\u597d\u4e14\u5bf9\u901a\u7528\u80fd\u529b\u5f71\u54cd\u5c0f\uff0c\u5e76\u5f00\u6e90\u65b9\u6cd5\u3002", "motivation": "\u89d2\u8272\u8bad\u7ec3\u662f\u884c\u4e1a\u540e\u8bad\u7ec3\u5173\u952e\u90e8\u5206\uff0c\u4f46\u5b66\u672f\u6587\u732e\u4e2d\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u6709\u6548\u5851\u9020\u804a\u5929\u673a\u5668\u4eba\u89d2\u8272\u3002", "method": "\u5229\u7528\u5baa\u6cd5AI\u548c\u65b0\u6570\u636e\u7ba1\u9053\uff0c\u7528\u5408\u6210\u81ea\u7701\u6570\u636e\u5fae\u8c03\u4e09\u4e2a\u6d41\u884c\u7684\u5f00\u653e\u6743\u91cd\u6a21\u578b\uff0c\u5206\u6790\u63ed\u793a\u504f\u597d\u6765\u8ffd\u8e2a\u6548\u679c\u3002", "result": "\u89d2\u8272\u53d8\u5316\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u66f4\u7a33\u5065\uff0c\u751f\u6210\u66f4\u8fde\u8d2f\u771f\u5b9e\uff0c\u5fae\u8c03\u5bf9\u901a\u7528\u80fd\u529b\u5f71\u54cd\u5c0f\u3002", "conclusion": "\u63d0\u51fa\u7684\u89d2\u8272\u8bad\u7ec3\u65b9\u6cd5\u6709\u6548\u4e14\u53ef\u5f00\u6e90\uff0c\u80fd\u66f4\u597d\u5730\u5851\u9020\u804a\u5929\u673a\u5668\u4eba\u4eba\u683c\u3002"}}
{"id": "2511.01706", "pdf": "https://arxiv.org/pdf/2511.01706", "abs": "https://arxiv.org/abs/2511.01706", "authors": ["Sekh Mainul Islam", "Pepa Atanasova", "Isabelle Augenstein"], "title": "Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under review", "summary": "Natural Language Explanations (NLEs) describe how Large Language Models\n(LLMs) make decisions, drawing on both external Context Knowledge (CK) and\nParametric Knowledge (PK) stored in model weights. Understanding their\ninteraction is key to assessing the grounding of NLEs, yet it remains\nunderexplored. Prior work has largely examined only single-step generation,\ntypically the final answer, and has modelled PK and CK interaction only as a\nbinary choice in a rank-1 subspace. This overlooks richer forms of interaction,\nsuch as complementary or supportive knowledge. We propose a novel rank-2\nprojection subspace that disentangles PK and CK contributions more accurately\nand use it for the first multi-step analysis of knowledge interactions across\nlonger NLE sequences. Experiments on four QA datasets and three open-weight\ninstruction-tuned LLMs show that diverse knowledge interactions are poorly\nrepresented in a rank-1 subspace but are effectively captured in our rank-2\nformulation. Our multi-step analysis reveals that hallucinated NLEs align\nstrongly with the PK direction, context-faithful ones balance PK and CK, and\nChain-of-Thought prompting for NLEs shifts generated NLEs toward CK by reducing\nPK reliance. This work provides the first framework for systematic studies of\nmulti-step knowledge interactions in LLMs through a richer rank-2 subspace\ndisentanglement. Code and data:\nhttps://github.com/copenlu/pk-ck-knowledge-disentanglement.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u79e92\u6295\u5f71\u5b50\u7a7a\u95f4\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u4e2d\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u77e5\u8bc6\u7684\u4ea4\u4e92\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u4e2d\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u77e5\u8bc6\u4ea4\u4e92\u7684\u7406\u89e3\u4e0d\u8db3\uff0c\u4e14\u591a\u4e3a\u5355\u6b65\u5206\u6790\uff0c\u6a21\u578b\u4ea4\u4e92\u5f62\u5f0f\u5355\u4e00\u3002", "method": "\u63d0\u51fa\u79e92\u6295\u5f71\u5b50\u7a7a\u95f4\uff0c\u5bf9\u8f83\u957f\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5e8f\u5217\u8fdb\u884c\u591a\u6b65\u77e5\u8bc6\u4ea4\u4e92\u5206\u6790\u3002", "result": "\u79e91\u5b50\u7a7a\u95f4\u4e0d\u80fd\u5f88\u597d\u8868\u793a\u591a\u6837\u77e5\u8bc6\u4ea4\u4e92\uff0c\u79e92\u516c\u5f0f\u80fd\u6709\u6548\u6355\u6349\uff1b\u591a\u6b65\u5206\u6790\u63ed\u793a\u4e0d\u540c\u7c7b\u578b\u89e3\u91ca\u4e0e\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u77e5\u8bc6\u7684\u5173\u7cfb\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u901a\u8fc7\u66f4\u4e30\u5bcc\u7684\u79e92\u5b50\u7a7a\u95f4\u89e3\u8026\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u591a\u6b65\u77e5\u8bc6\u4ea4\u4e92\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\u7684\u9996\u4e2a\u6846\u67b6\u3002"}}
{"id": "2511.01724", "pdf": "https://arxiv.org/pdf/2511.01724", "abs": "https://arxiv.org/abs/2511.01724", "authors": ["Yi Zhang", "Zheng Wang", "Chen Zhen", "Wenjie Ruan", "Qing Guo", "Siddartha Khastgir", "Carsten Maple", "Xingyu Zhao"], "title": "Probabilistic Robustness for Free? Revisiting Training via a Benchmark", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning models are notoriously vulnerable to imperceptible\nperturbations. Most existing research centers on adversarial robustness (AR),\nwhich evaluates models under worst-case scenarios by examining the existence of\ndeterministic adversarial examples (AEs). In contrast, probabilistic robustness\n(PR) adopts a statistical perspective, measuring the probability that\npredictions remain correct under stochastic perturbations. While PR is widely\nregarded as a practical complement to AR, dedicated training methods for\nimproving PR are still relatively underexplored, albeit with emerging progress.\nAmong the few PR-targeted training methods, we identify three limitations: i\nnon-comparable evaluation protocols; ii limited comparisons to strong AT\nbaselines despite anecdotal PR gains from AT; and iii no unified framework to\ncompare the generalization of these methods. Thus, we introduce PRBench, the\nfirst benchmark dedicated to evaluating improvements in PR achieved by\ndifferent robustness training methods. PRBench empirically compares most common\nAT and PR-targeted training methods using a comprehensive set of metrics,\nincluding clean accuracy, PR and AR performance, training efficiency, and\ngeneralization error (GE). We also provide theoretical analysis on the GE of PR\nperformance across different training methods. Main findings revealed by\nPRBench include: AT methods are more versatile than PR-targeted training\nmethods in terms of improving both AR and PR performance across diverse\nhyperparameter settings, while PR-targeted training methods consistently yield\nlower GE and higher clean accuracy. A leaderboard comprising 222 trained models\nacross 7 datasets and 10 model architectures is publicly available at\nhttps://tmpspace.github.io/PRBenchLeaderboard/.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u8bc4\u4f30\u6982\u7387\u9c81\u68d2\u6027\u6539\u8fdb\u7684\u57fa\u51c6PRBench\uff0c\u6bd4\u8f83\u591a\u79cd\u8bad\u7ec3\u65b9\u6cd5\u5e76\u7ed9\u51fa\u4e3b\u8981\u53d1\u73b0\uff0c\u8fd8\u63d0\u4f9b\u6392\u884c\u699c\u3002", "motivation": "\u73b0\u6709\u6539\u8fdb\u6982\u7387\u9c81\u68d2\u6027\uff08PR\uff09\u7684\u8bad\u7ec3\u65b9\u6cd5\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u5b58\u5728\u8bc4\u4f30\u534f\u8bae\u4e0d\u53ef\u6bd4\u3001\u4e0e\u5f3a\u5bf9\u6297\u8bad\u7ec3\uff08AT\uff09\u57fa\u7ebf\u5bf9\u6bd4\u6709\u9650\u3001\u65e0\u7edf\u4e00\u6846\u67b6\u6bd4\u8f83\u6cdb\u5316\u6027\u7b49\u5c40\u9650\u3002", "method": "\u5f15\u5165PRBench\uff0c\u7528\u7efc\u5408\u6307\u6807\u5bf9\u6bd4\u5e38\u89c1AT\u548cPR\u76ee\u6807\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u5bf9\u4e0d\u540c\u8bad\u7ec3\u65b9\u6cd5PR\u6027\u80fd\u7684\u6cdb\u5316\u8bef\u5dee\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "AT\u65b9\u6cd5\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u63d0\u5347\u5bf9\u6297\u9c81\u68d2\u6027\uff08AR\uff09\u548cPR\u6027\u80fd\u66f4\u901a\u7528\uff0cPR\u76ee\u6807\u8bad\u7ec3\u65b9\u6cd5\u6cdb\u5316\u8bef\u5dee\u66f4\u4f4e\u3001\u5e72\u51c0\u51c6\u786e\u7387\u66f4\u9ad8\u3002", "conclusion": "PRBench\u6709\u52a9\u4e8e\u8bc4\u4f30\u4e0d\u540c\u9c81\u68d2\u6027\u8bad\u7ec3\u65b9\u6cd5\u5bf9PR\u7684\u6539\u8fdb\uff0c\u516c\u5f00\u7684\u6392\u884c\u699c\u53ef\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2511.01773", "pdf": "https://arxiv.org/pdf/2511.01773", "abs": "https://arxiv.org/abs/2511.01773", "authors": ["Daniel Jimon", "Mircea Vaida", "Adriana Stan"], "title": "ADNAC: Audio Denoiser using Neural Audio Codec", "categories": ["cs.SD", "cs.LG"], "comment": "Accepted and presented at the 13th International Conference on Speech\n  Technology and Human-Computer Dialogue (SpeD), Cluj-Napoca, Romania, October\n  19-22, 2025. 4 pages, 1 figure. IEEE Catalog Number: CFP2555H-USB, ISBN:\n  979-8-3315-7485-7", "summary": "Audio denoising is critical in signal processing, enhancing intelligibility\nand fidelity for applications like restoring musical recordings. This paper\npresents a proof-of-concept for adapting a state-of-the-art neural audio codec,\nthe Descript Audio Codec (DAC), for music denoising. This work overcomes the\nlimitations of traditional architectures like U-Nets by training the model on a\nlarge-scale, custom-synthesized dataset built from diverse sources. Training is\nguided by a multi objective loss function that combines time-domain, spectral,\nand signal-level fidelity metrics. Ultimately, this paper aims to present a PoC\nfor high-fidelity, generative audio restoration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06Descript Audio Codec (DAC) \u7528\u4e8e\u97f3\u4e50\u53bb\u566a\u7684\u6982\u5ff5\u9a8c\u8bc1\uff0c\u901a\u8fc7\u5b9a\u5236\u6570\u636e\u96c6\u548c\u591a\u76ee\u6807\u635f\u5931\u51fd\u6570\u5b9e\u73b0\u9ad8\u4fdd\u771f\u97f3\u9891\u6062\u590d\u3002", "motivation": "\u97f3\u9891\u53bb\u566a\u5bf9\u4fe1\u53f7\u5904\u7406\u5f88\u91cd\u8981\uff0c\u4f20\u7edf\u67b6\u6784\u6709\u5c40\u9650\u6027\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u4fdd\u771f\u3001\u751f\u6210\u5f0f\u97f3\u9891\u6062\u590d\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u3001\u81ea\u5b9a\u4e49\u5408\u6210\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\u8bad\u7ec3DAC\u6a21\u578b\uff0c\u91c7\u7528\u7ed3\u5408\u65f6\u57df\u3001\u9891\u8c31\u548c\u4fe1\u53f7\u7ea7\u4fdd\u771f\u5ea6\u6307\u6807\u7684\u591a\u76ee\u6807\u635f\u5931\u51fd\u6570\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\uff0c\u4f46\u65e8\u5728\u5448\u73b0\u9ad8\u4fdd\u771f\u97f3\u9891\u6062\u590d\u7684\u6982\u5ff5\u9a8c\u8bc1\u3002"}}
{"id": "2511.01797", "pdf": "https://arxiv.org/pdf/2511.01797", "abs": "https://arxiv.org/abs/2511.01797", "authors": ["Javier Ballesteros-Jerez", "Jesus Mart\u00ednez-G\u00f3mez", "Ismael Garc\u00eda-Varea", "Luis Orozco-Barbosa", "Manuel Castillo-Cara"], "title": "Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator", "categories": ["cs.RO", "cs.LG"], "comment": "13 pages, 7 figures. Conference paper (ROBOVIS 2025)", "summary": "We present a hybrid neural network model for inferring the position of mobile\nrobots using Channel State Information (CSI) data from a Massive MIMO system.\nBy leveraging an existing CSI dataset, our approach integrates a Convolutional\nNeural Network (CNN) with a Multilayer Perceptron (MLP) to form a Hybrid Neural\nNetwork (HyNN) that estimates 2D robot positions. CSI readings are converted\ninto synthetic images using the TINTO tool. The localisation solution is\nintegrated with a robotics simulator, and the Robot Operating System (ROS),\nwhich facilitates its evaluation through heterogeneous test cases, and the\nadoption of state estimators like Kalman filters. Our contributions illustrate\nthe potential of our HyNN model in achieving precise indoor localisation and\nnavigation for mobile robots in complex environments. The study follows, and\nproposes, a generalisable procedure applicable beyond the specific use case\nstudied, making it adaptable to different scenarios and datasets.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7528MIMO\u7cfb\u7edf\u7684CSI\u6570\u636e\u63a8\u65ad\u79fb\u52a8\u673a\u5668\u4eba\u4f4d\u7f6e\uff0c\u6709\u8f83\u597d\u5b9a\u4f4d\u6548\u679c\u4e14\u65b9\u6cd5\u53ef\u63a8\u5e7f\u3002", "motivation": "\u5b9e\u73b0\u590d\u6742\u73af\u5883\u4e0b\u79fb\u52a8\u673a\u5668\u4eba\u7684\u7cbe\u786e\u5ba4\u5185\u5b9a\u4f4d\u548c\u5bfc\u822a\u3002", "method": "\u7ed3\u5408CNN\u548cMLP\u5f62\u6210HyNN\uff0c\u7528TINTO\u5de5\u5177\u5c06CSI\u8bfb\u6570\u8f6c\u6362\u4e3a\u5408\u6210\u56fe\u50cf\uff0c\u96c6\u6210\u5230\u673a\u5668\u4eba\u6a21\u62df\u5668\u548cROS\u4e2d\uff0c\u91c7\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u7b49\u72b6\u6001\u4f30\u8ba1\u5668\u3002", "result": "HyNN\u6a21\u578b\u5728\u590d\u6742\u73af\u5883\u4e0b\u80fd\u5b9e\u73b0\u7cbe\u786e\u7684\u5ba4\u5185\u5b9a\u4f4d\u548c\u5bfc\u822a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u63a8\u5e7f\u6027\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2511.01746", "pdf": "https://arxiv.org/pdf/2511.01746", "abs": "https://arxiv.org/abs/2511.01746", "authors": ["Chen-Wei Chang", "Shailik Sarkar", "Hossein Salemi", "Hyungmin Kim", "Shutonu Mitra", "Hemant Purohit", "Fengxiu Zhang", "Michin Hong", "Jin-Hee Cho", "Chang-Tien Lu"], "title": "Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks", "categories": ["cs.CR", "cs.AI"], "comment": "8 pages", "summary": "Scam detection remains a critical challenge in cybersecurity as adversaries\ncraft messages that evade automated filters. We propose a Hierarchical Scam\nDetection System (HSDS) that combines a lightweight multi-model voting front\nend with a fine-tuned LLaMA 3.1 8B Instruct back end to improve accuracy and\nrobustness against adversarial attacks. An ensemble of four classifiers\nprovides preliminary predictions through majority vote, and ambiguous cases are\nescalated to the fine-tuned model, which is optimized with adversarial training\nto reduce misclassification. Experiments show that this hierarchical design\nboth improves adversarial scam detection and shortens inference time by routing\nmost cases away from the LLM, outperforming traditional machine-learning\nbaselines and proprietary LLM baselines. The findings highlight the\neffectiveness of a hybrid voting mechanism and adversarial fine-tuning in\nfortifying LLMs against evolving scam tactics, enhancing the resilience of\nautomated scam detection systems.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u8bc8\u9a97\u68c0\u6d4b\u7cfb\u7edfHSDS\uff0c\u7ed3\u5408\u591a\u6a21\u578b\u6295\u7968\u524d\u7aef\u4e0e\u5fae\u8c03\u7684LLaMA 3.1 8B Instruct\u540e\u7aef\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u63d0\u5347\u5bf9\u6297\u8bc8\u9a97\u68c0\u6d4b\u6548\u679c\u5e76\u7f29\u77ed\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u8bc8\u9a97\u68c0\u6d4b\u662f\u7f51\u7edc\u5b89\u5168\u7684\u5173\u952e\u6311\u6218\uff0c\u5bf9\u624b\u8bbe\u8ba1\u7684\u6d88\u606f\u53ef\u7ed5\u8fc7\u81ea\u52a8\u8fc7\u6ee4\u5668\uff0c\u9700\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u6784\u5efaHSDS\uff0c\u524d\u7aef\u7528\u56db\u4e2a\u5206\u7c7b\u5668\u96c6\u6210\u8fdb\u884c\u591a\u6570\u6295\u7968\u521d\u6b65\u9884\u6d4b\uff0c\u6a21\u7cca\u60c5\u51b5\u4ea4\u7ed9\u540e\u7aef\u5fae\u8c03\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u7ecf\u5bf9\u6297\u8bad\u7ec3\u4f18\u5316\u3002", "result": "\u5206\u5c42\u8bbe\u8ba1\u63d0\u5347\u5bf9\u6297\u8bc8\u9a97\u68c0\u6d4b\u6548\u679c\uff0c\u7f29\u77ed\u63a8\u7406\u65f6\u95f4\uff0c\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u4e13\u6709\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\u3002", "conclusion": "\u6df7\u5408\u6295\u7968\u673a\u5236\u548c\u5bf9\u6297\u5fae\u8c03\u5728\u5f3a\u5316\u5927\u8bed\u8a00\u6a21\u578b\u62b5\u5fa1\u8bc8\u9a97\u7b56\u7565\u65b9\u9762\u6709\u6548\uff0c\u80fd\u589e\u5f3a\u81ea\u52a8\u8bc8\u9a97\u68c0\u6d4b\u7cfb\u7edf\u7684\u5f39\u6027\u3002"}}
{"id": "2511.01753", "pdf": "https://arxiv.org/pdf/2511.01753", "abs": "https://arxiv.org/abs/2511.01753", "authors": ["Zachary Hansen", "Yuliya Lierler"], "title": "SM-based Semantics for Answer Set Programs Containing Conditional Literals and Arithmetic", "categories": ["cs.LO", "cs.AI", "cs.PL", "F.4.1"], "comment": "This version corrects the review of tau for negated atoms, and\n  clarifies the distinction between global and local variables in conditional\n  literals (the supporting proofs are also updated accordingly)", "summary": "Modern answer set programming solvers such as CLINGO support advanced\nlanguage constructs that improve the expressivity and conciseness of logic\nprograms. Conditional literals are one such construct. They form \"subformulas\"\nthat behave as nested implications within the bodies of logic rules. Their\ninclusion brings the form of rules closer to the less restrictive syntax of\nfirst-order logic. These qualities make conditional literals useful tools for\nknowledge representation. In this paper, we propose a semantics for logic\nprograms with conditional literals and arithmetic based on the SM operator.\nThese semantics do not require grounding, unlike the established semantics for\nsuch programs that relies on a translation to infinitary propositional logic.\nThe main result of this paper establishes the precise correspondence between\nthe proposed and existing semantics.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSM\u7b97\u5b50\u7684\u542b\u6761\u4ef6\u6587\u5b57\u548c\u7b97\u672f\u7684\u903b\u8f91\u7a0b\u5e8f\u8bed\u4e49\uff0c\u8bc1\u660e\u5176\u4e0e\u73b0\u6709\u8bed\u4e49\u5bf9\u5e94\u5173\u7cfb\u3002", "motivation": "\u73b0\u4ee3ASP\u6c42\u89e3\u5668\u652f\u6301\u6761\u4ef6\u6587\u5b57\u7b49\u9ad8\u7ea7\u8bed\u8a00\u6784\u9020\uff0c\u73b0\u6709\u6b64\u7c7b\u7a0b\u5e8f\u8bed\u4e49\u4f9d\u8d56\u4e8e\u8f6c\u6362\u4e3a\u65e0\u7a77\u547d\u9898\u903b\u8f91\uff0c\u9700\u8981\u8fdb\u884c\u63a5\u5730\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u65e0\u9700\u63a5\u5730\u7684\u8bed\u4e49\u3002", "method": "\u57fa\u4e8eSM\u7b97\u5b50\u4e3a\u542b\u6761\u4ef6\u6587\u5b57\u548c\u7b97\u672f\u7684\u903b\u8f91\u7a0b\u5e8f\u63d0\u51fa\u8bed\u4e49\u3002", "result": "\u5efa\u7acb\u4e86\u6240\u63d0\u51fa\u8bed\u4e49\u4e0e\u73b0\u6709\u8bed\u4e49\u4e4b\u95f4\u7684\u7cbe\u786e\u5bf9\u5e94\u5173\u7cfb\u3002", "conclusion": "\u6240\u63d0\u8bed\u4e49\u65e0\u9700\u63a5\u5730\uff0c\u4e14\u4e0e\u73b0\u6709\u8bed\u4e49\u6709\u7cbe\u786e\u5bf9\u5e94\uff0c\u4e3a\u903b\u8f91\u7a0b\u5e8f\u8bed\u4e49\u7814\u7a76\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.01815", "pdf": "https://arxiv.org/pdf/2511.01815", "abs": "https://arxiv.org/abs/2511.01815", "authors": ["Konrad Staniszewski", "Adrian \u0141a\u0144cucki"], "title": "KV Cache Transform Coding for Compact Storage in LLM Inference", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Serving large language models (LLMs) at scale necessitates efficient\nkey-value (KV) cache management. KV caches can be reused across conversation\nturns via shared-prefix prompts that are common in iterative code editing and\nchat. However, stale caches consume scarce GPU memory, require offloading, or\nforce recomputation. We present KVTC, a lightweight transform coder that\ncompresses KV caches for compact on-GPU and off-GPU storage. Drawing on\nclassical media compression, KVTC combines PCA-based feature decorrelation,\nadaptive quantization, and entropy coding. It requires only a brief initial\ncalibration and leaves model parameters unchanged. By exploiting redundancies\nin KV caches, KVTC achieves up to 20$\\times$ compression while maintaining\nreasoning and long-context accuracy, and 40$\\times$ or higher for specific use\ncases. We test KVTC with Llama 3, Mistral NeMo, and R1-Qwen 2.5 models across\nbenchmarks including AIME25, LiveCodeBench, GSM8K, MMLU, Qasper, RULER, and\nMATH-500. It consistently outperforms inference-time baselines such as token\neviction, quantization, and SVD-based methods, while achieving higher\ncompression ratios. These results support KVTC as a practical building block\nfor memory-efficient LLM serving with reusable KV caches.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u53d8\u6362\u7f16\u7801\u5668KVTC\u538b\u7f29\u5927\u8bed\u8a00\u6a21\u578b\u7684KV\u7f13\u5b58\uff0c\u6d4b\u8bd5\u8868\u660e\u5176\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u662f\u9ad8\u6548\u5185\u5b58\u670d\u52a1\u7684\u5b9e\u7528\u7ec4\u4ef6\u3002", "motivation": "\u5927\u89c4\u6a21\u670d\u52a1\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u9ad8\u6548\u7684KV\u7f13\u5b58\u7ba1\u7406\uff0c\u9648\u65e7\u7f13\u5b58\u6d88\u8017GPU\u5185\u5b58\uff0c\u9700\u89e3\u51b3\u5b58\u50a8\u95ee\u9898\u3002", "method": "\u501f\u9274\u7ecf\u5178\u5a92\u4f53\u538b\u7f29\uff0c\u7ed3\u5408\u57fa\u4e8ePCA\u7684\u7279\u5f81\u53bb\u76f8\u5173\u3001\u81ea\u9002\u5e94\u91cf\u5316\u548c\u71b5\u7f16\u7801\uff0c\u4ec5\u9700\u521d\u59cb\u6821\u51c6\u4e14\u4e0d\u6539\u53d8\u6a21\u578b\u53c2\u6570\u3002", "result": "KVTC\u5b9e\u73b0\u9ad8\u8fbe20\u500d\u538b\u7f29\uff0c\u7279\u5b9a\u7528\u4f8b\u8fbe40\u500d\u6216\u66f4\u9ad8\uff0c\u5728\u591a\u6a21\u578b\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u63a8\u7406\u65f6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "KVTC\u662f\u5177\u6709\u53ef\u91cd\u590d\u4f7f\u7528KV\u7f13\u5b58\u7684\u5185\u5b58\u9ad8\u6548\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7684\u5b9e\u7528\u6784\u5efa\u5757\u3002"}}
{"id": "2511.01767", "pdf": "https://arxiv.org/pdf/2511.01767", "abs": "https://arxiv.org/abs/2511.01767", "authors": ["Yuxiao Yang", "Xiao-Xiao Long", "Zhiyang Dou", "Cheng Lin", "Yuan Liu", "Qingsong Yan", "Yuexin Ma", "Haoqian Wang", "Zhiqiang Wu", "Wei Yin"], "title": "Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image", "categories": ["cs.CV", "cs.AI"], "comment": "21 pages, 19 figures, accepted by TPAMI", "summary": "In this work, we introduce \\textbf{Wonder3D++}, a novel method for\nefficiently generating high-fidelity textured meshes from single-view images.\nRecent methods based on Score Distillation Sampling (SDS) have shown the\npotential to recover 3D geometry from 2D diffusion priors, but they typically\nsuffer from time-consuming per-shape optimization and inconsistent geometry. In\ncontrast, certain works directly produce 3D information via fast network\ninferences, but their results are often of low quality and lack geometric\ndetails. To holistically improve the quality, consistency, and efficiency of\nsingle-view reconstruction tasks, we propose a cross-domain diffusion model\nthat generates multi-view normal maps and the corresponding color images. To\nensure the consistency of generation, we employ a multi-view cross-domain\nattention mechanism that facilitates information exchange across views and\nmodalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that\ndrives high-quality surfaces from the multi-view 2D representations in only\nabout $3$ minute in a coarse-to-fine manner. Our extensive evaluations\ndemonstrate that our method achieves high-quality reconstruction results,\nrobust generalization, and good efficiency compared to prior works. Code\navailable at https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.", "AI": {"tldr": "\u63d0\u51faWonder3D++\u65b9\u6cd5\uff0c\u4ece\u5355\u89c6\u56fe\u56fe\u50cf\u9ad8\u6548\u751f\u6210\u9ad8\u4fdd\u771f\u7eb9\u7406\u7f51\u683c\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eSDS\u65b9\u6cd5\u4f18\u5316\u8017\u65f6\u4e14\u51e0\u4f55\u4e0d\u4e00\u81f4\uff0c\u76f4\u63a5\u7f51\u7edc\u63a8\u7406\u7ed3\u679c\u8d28\u91cf\u4f4e\u3001\u7f3a\u7ec6\u8282\uff0c\u9700\u63d0\u5347\u5355\u89c6\u56fe\u91cd\u5efa\u4efb\u52a1\u7684\u8d28\u91cf\u3001\u4e00\u81f4\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u8de8\u57df\u6269\u6563\u6a21\u578b\u751f\u6210\u591a\u89c6\u56fe\u6cd5\u7ebf\u56fe\u548c\u5bf9\u5e94\u5f69\u8272\u56fe\u50cf\uff0c\u91c7\u7528\u591a\u89c6\u56fe\u8de8\u57df\u6ce8\u610f\u529b\u673a\u5236\u786e\u4fdd\u751f\u6210\u4e00\u81f4\u6027\uff0c\u5f15\u5165\u7ea7\u80543D\u7f51\u683c\u63d0\u53d6\u7b97\u6cd5\u4ee5\u7c97\u5230\u7ec6\u65b9\u5f0f\u9a71\u52a8\u9ad8\u8d28\u91cf\u8868\u9762\u3002", "result": "\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5efa\u7ed3\u679c\u3001\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u548c\u826f\u597d\u6548\u7387\u3002", "conclusion": "Wonder3D++\u65b9\u6cd5\u5728\u5355\u89c6\u56fe\u91cd\u5efa\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2511.01775", "pdf": "https://arxiv.org/pdf/2511.01775", "abs": "https://arxiv.org/abs/2511.01775", "authors": ["Zhen Chen", "Qing Xu", "Jinlin Wu", "Biao Yang", "Yuhao Zhai", "Geng Guo", "Jing Zhang", "Yinlu Ding", "Nassir Navab", "Jiebo Luo"], "title": "How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Foundation models in video generation are demonstrating remarkable\ncapabilities as potential world models for simulating the physical world.\nHowever, their application in high-stakes domains like surgery, which demand\ndeep, specialized causal knowledge rather than general physical rules, remains\na critical unexplored gap. To systematically address this challenge, we present\nSurgVeo, the first expert-curated benchmark for video generation model\nevaluation in surgery, and the Surgical Plausibility Pyramid (SPP), a novel,\nfour-tiered framework tailored to assess model outputs from basic appearance to\ncomplex surgical strategy. On the basis of the SurgVeo benchmark, we task the\nadvanced Veo-3 model with a zero-shot prediction task on surgical clips from\nlaparoscopic and neurosurgical procedures. A panel of four board-certified\nsurgeons evaluates the generated videos according to the SPP. Our results\nreveal a distinct \"plausibility gap\": while Veo-3 achieves exceptional Visual\nPerceptual Plausibility, it fails critically at higher levels of the SPP,\nincluding Instrument Operation Plausibility, Environment Feedback Plausibility,\nand Surgical Intent Plausibility. This work provides the first quantitative\nevidence of the chasm between visually convincing mimicry and causal\nunderstanding in surgical AI. Our findings from SurgVeo and the SPP establish a\ncrucial foundation and roadmap for developing future models capable of\nnavigating the complexities of specialized, real-world healthcare domains.", "AI": {"tldr": "\u63d0\u51faSurgVeo\u57fa\u51c6\u548cSPP\u6846\u67b6\u8bc4\u4f30\u624b\u672f\u89c6\u9891\u751f\u6210\u6a21\u578b\uff0c\u53d1\u73b0Veo - 3\u6a21\u578b\u5b58\u5728\u201c\u5408\u7406\u6027\u5dee\u8ddd\u201d\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u53d1\u5c55\u5960\u57fa\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u751f\u6210\u57fa\u7840\u6a21\u578b\u5728\u624b\u672f\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u7f3a\u4e4f\u4e13\u4e1a\u56e0\u679c\u77e5\u8bc6\uff0c\u6709\u672a\u63a2\u7d22\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51faSurgVeo\u57fa\u51c6\u548cSPP\u6846\u67b6\uff0c\u8ba9Veo - 3\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u9884\u6d4b\u4efb\u52a1\uff0c\u7531\u5916\u79d1\u533b\u751f\u6839\u636eSPP\u8bc4\u4f30\u751f\u6210\u89c6\u9891\u3002", "result": "Veo - 3\u6a21\u578b\u5728\u89c6\u89c9\u611f\u77e5\u5408\u7406\u6027\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728SPP\u66f4\u9ad8\u5c42\u6b21\u5982\u5668\u68b0\u64cd\u4f5c\u3001\u73af\u5883\u53cd\u9988\u548c\u624b\u672f\u610f\u56fe\u5408\u7406\u6027\u65b9\u9762\u5931\u8d25\u3002", "conclusion": "\u4e3a\u624b\u672fAI\u4e2d\u89c6\u89c9\u6a21\u4eff\u548c\u56e0\u679c\u7406\u89e3\u7684\u5dee\u8ddd\u63d0\u4f9b\u5b9a\u91cf\u8bc1\u636e\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\u548c\u8def\u7ebf\u56fe\u3002"}}
{"id": "2511.01791", "pdf": "https://arxiv.org/pdf/2511.01791", "abs": "https://arxiv.org/abs/2511.01791", "authors": ["Feng Chen", "Zhuxiu Xu", "Tianzhe Chu", "Xunzhe Zhou", "Li Sun", "Zewen Wu", "Shenghua Gao", "Zhongyu Li", "Yanchao Yang", "Yi Ma"], "title": "GenDexHand: Generative Simulation for Dexterous Hands", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Data scarcity remains a fundamental bottleneck for embodied intelligence.\nExisting approaches use large language models (LLMs) to automate gripper-based\nsimulation generation, but they transfer poorly to dexterous manipulation,\nwhich demands more specialized environment design. Meanwhile, dexterous\nmanipulation tasks are inherently more difficult due to their higher degrees of\nfreedom. Massively generating feasible and trainable dexterous hand tasks\nremains an open challenge. To this end, we present GenDexHand, a generative\nsimulation pipeline that autonomously produces diverse robotic tasks and\nenvironments for dexterous manipulation. GenDexHand introduces a closed-loop\nrefinement process that adjusts object placements and scales based on\nvision-language model (VLM) feedback, substantially improving the average\nquality of generated environments. Each task is further decomposed into\nsub-tasks to enable sequential reinforcement learning, reducing training time\nand increasing success rates. Our work provides a viable path toward scalable\ntraining of diverse dexterous hand behaviors in embodied intelligence by\noffering a simulation-based solution to synthetic data generation. Our website:\nhttps://winniechen2002.github.io/GenDexHand/.", "AI": {"tldr": "\u63d0\u51faGenDexHand\u751f\u6210\u5f0f\u6a21\u62df\u7ba1\u9053\uff0c\u89e3\u51b3\u7075\u5de7\u64cd\u4f5c\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u9ad8\u73af\u5883\u8d28\u91cf\uff0c\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u5e76\u63d0\u5347\u6210\u529f\u7387\u3002", "motivation": "\u6570\u636e\u7a00\u7f3a\u662f\u5177\u8eab\u667a\u80fd\u7684\u74f6\u9888\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u7075\u5de7\u64cd\u4f5c\u4e0a\u8fc1\u79fb\u6027\u5dee\uff0c\u5927\u89c4\u6a21\u751f\u6210\u53ef\u884c\u4e14\u53ef\u8bad\u7ec3\u7684\u7075\u5de7\u624b\u4efb\u52a1\u4ecd\u662f\u6311\u6218\u3002", "method": "\u63d0\u51faGenDexHand\u751f\u6210\u5f0f\u6a21\u62df\u7ba1\u9053\uff0c\u5f15\u5165\u95ed\u73af\u7ec6\u5316\u8fc7\u7a0b\u6839\u636eVLM\u53cd\u9988\u8c03\u6574\u7269\u4f53\u4f4d\u7f6e\u548c\u6bd4\u4f8b\uff0c\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\u8fdb\u884c\u987a\u5e8f\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5927\u5e45\u63d0\u9ad8\u751f\u6210\u73af\u5883\u7684\u5e73\u5747\u8d28\u91cf\uff0c\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u589e\u52a0\u6210\u529f\u7387\u3002", "conclusion": "\u4e3a\u5177\u8eab\u667a\u80fd\u4e2d\u591a\u6837\u5316\u7075\u5de7\u624b\u884c\u4e3a\u7684\u53ef\u6269\u5c55\u8bad\u7ec3\u63d0\u4f9b\u4e86\u57fa\u4e8e\u6a21\u62df\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01805", "pdf": "https://arxiv.org/pdf/2511.01805", "abs": "https://arxiv.org/abs/2511.01805", "authors": ["Jiayi Geng", "Howard Chen", "Ryan Liu", "Manoel Horta Ribeiro", "Robb Willer", "Graham Neubig", "Thomas L. Griffiths"], "title": "Accumulating Context Changes the Beliefs of Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Language model (LM) assistants are increasingly used in applications such as\nbrainstorming and research. Improvements in memory and context size have\nallowed these models to become more autonomous, which has also resulted in more\ntext accumulation in their context windows without explicit user intervention.\nThis comes with a latent risk: the belief profiles of models -- their\nunderstanding of the world as manifested in their responses or actions -- may\nsilently change as context accumulates. This can lead to subtly inconsistent\nuser experiences, or shifts in behavior that deviate from the original\nalignment of the models. In this paper, we explore how accumulating context by\nengaging in interactions and processing text -- talking and reading -- can\nchange the beliefs of language models, as manifested in their responses and\nbehaviors.Our results reveal that models' belief profiles are highly malleable:\nGPT-5 exhibits a 54.7% shift in its stated beliefs after 10 rounds of\ndiscussion about moral dilemmas and queries about safety, while Grok 4 shows a\n27.2% shift on political issues after reading texts from the opposing position.\nWe also examine models' behavioral changes by designing tasks that require tool\nuse, where each tool selection corresponds to an implicit belief. We find that\nthese changes align with stated belief shifts, suggesting that belief shifts\nwill be reflected in actual behavior in agentic systems. Our analysis exposes\nthe hidden risk of belief shift as models undergo extended sessions of talking\nor reading, rendering their opinions and actions unreliable.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u4e92\u548c\u5904\u7406\u6587\u672c\u65f6\u4e0a\u4e0b\u6587\u79ef\u7d2f\u5bf9\u5176\u4fe1\u5ff5\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6a21\u578b\u4fe1\u5ff5\u6613\u53d8\uff0c\u4e14\u4fe1\u5ff5\u8f6c\u53d8\u4f1a\u53cd\u6620\u5728\u884c\u4e3a\u4e2d\uff0c\u63ed\u793a\u4e86\u4fe1\u5ff5\u8f6c\u53d8\u7684\u6f5c\u5728\u98ce\u9669\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u81ea\u4e3b\u6027\u589e\u5f3a\u4f7f\u4e0a\u4e0b\u6587\u7a97\u53e3\u6587\u672c\u79ef\u7d2f\uff0c\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u4fe1\u5ff5\u65e0\u58f0\u6539\u53d8\uff0c\u5f15\u53d1\u7528\u6237\u4f53\u9a8c\u4e0d\u4e00\u81f4\u548c\u884c\u4e3a\u504f\u79bb\u539f\u6821\u51c6\uff0c\u56e0\u6b64\u63a2\u7a76\u4e0a\u4e0b\u6587\u79ef\u7d2f\u5bf9\u6a21\u578b\u4fe1\u5ff5\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u8fdb\u884c\u9053\u5fb7\u56f0\u5883\u8ba8\u8bba\u3001\u5b89\u5168\u95ee\u9898\u67e5\u8be2\u3001\u9605\u8bfb\u5bf9\u7acb\u7acb\u573a\u6587\u672c\u7b49\u4ea4\u4e92\uff0c\u4ee5\u53ca\u8bbe\u8ba1\u9700\u8981\u5de5\u5177\u4f7f\u7528\u7684\u4efb\u52a1\u6765\u89c2\u5bdf\u6a21\u578b\u4fe1\u5ff5\u548c\u884c\u4e3a\u7684\u53d8\u5316\u3002", "result": "GPT - 5\u572810\u8f6e\u9053\u5fb7\u56f0\u5883\u548c\u5b89\u5168\u95ee\u9898\u8ba8\u8bba\u540e\u4fe1\u5ff5\u9648\u8ff0\u670954.7%\u7684\u8f6c\u53d8\uff0cGrok 4\u5728\u9605\u8bfb\u5bf9\u7acb\u7acb\u573a\u6587\u672c\u540e\u653f\u6cbb\u95ee\u9898\u4fe1\u5ff5\u670927.2%\u7684\u8f6c\u53d8\uff0c\u4e14\u884c\u4e3a\u53d8\u5316\u4e0e\u4fe1\u5ff5\u9648\u8ff0\u8f6c\u53d8\u4e00\u81f4\u3002", "conclusion": "\u6a21\u578b\u5728\u957f\u65f6\u95f4\u5bf9\u8bdd\u6216\u9605\u8bfb\u4e2d\u5b58\u5728\u4fe1\u5ff5\u8f6c\u53d8\u7684\u9690\u85cf\u98ce\u9669\uff0c\u4f7f\u5176\u89c2\u70b9\u548c\u884c\u52a8\u4e0d\u53ef\u9760\u3002"}}
{"id": "2511.01807", "pdf": "https://arxiv.org/pdf/2511.01807", "abs": "https://arxiv.org/abs/2511.01807", "authors": ["Adewale Akinfaderin", "Shreyas Subramanian", "Akarsha Sehwag"], "title": "Plan-and-Write: Structure-Guided Length Control for LLMs without Model Retraining", "categories": ["cs.CL", "cs.AI"], "comment": "Presented at Workshop on Prompt Optimization, KDD 2025, Toronto,\n  Canada", "summary": "Length control in Large Language Models (LLMs) is a crucial but\nunder-addressed challenge, with applications ranging from voice interfaces\nrequiring concise responses to research summaries needing comprehensive\noutputs. Current approaches to length control, including Regularized DPO,\nLength-Instruction Fine Tuning, and tool-augmented methods, typically require\nexpensive model retraining or complex inference-time tooling. This paper\npresents a prompt engineering methodology that enables precise length control\nwithout model retraining. Our structure-guided approach implements deliberate\nplanning and word counting mechanisms within the prompt, encouraging the model\nto carefully track and adhere to specified length constraints. Comprehensive\nevaluations across six state-of-the-art LLMs demonstrate that our method\nsignificantly improves length fidelity for several models compared to standard\nprompting when applied to document summarization tasks, particularly for\nshorter-to-medium length constraints. The proposed technique shows varying\nbenefits across different model architectures, with some models demonstrating\nup to 37.6% improvement in length adherence. Quality evaluations further reveal\nthat our approach maintains or enhances overall output quality compared to\nstandard prompting techniques. Our approach provides an immediately deployable\nsolution for applications requiring precise length control, particularly\nvaluable for production environments where model retraining is impractical or\ncost-prohibitive.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u6a21\u578b\u518d\u8bad\u7ec3\u7684\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u957f\u5ea6\u63a7\u5236\uff0c\u7ecf\u8bc4\u4f30\u6548\u679c\u826f\u597d\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u957f\u5ea6\u63a7\u5236\u65b9\u6cd5\u9700\u6602\u8d35\u7684\u6a21\u578b\u518d\u8bad\u7ec3\u6216\u590d\u6742\u63a8\u7406\u5de5\u5177\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5f15\u5bfc\u7684\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\uff0c\u5728\u63d0\u793a\u4e2d\u5b9e\u73b0\u89c4\u5212\u548c\u8bcd\u6570\u7edf\u8ba1\u673a\u5236\u3002", "result": "\u5728\u516d\u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u90e8\u5206\u6a21\u578b\u957f\u5ea6\u63a7\u5236\u7cbe\u5ea6\uff0c\u90e8\u5206\u6a21\u578b\u957f\u5ea6\u9075\u5b88\u7387\u63d0\u5347\u8fbe37.6%\uff0c\u4e14\u4fdd\u6301\u6216\u63d0\u5347\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9700\u8981\u7cbe\u786e\u957f\u5ea6\u63a7\u5236\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u7acb\u5373\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u751f\u4ea7\u73af\u5883\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.01840", "pdf": "https://arxiv.org/pdf/2511.01840", "abs": "https://arxiv.org/abs/2511.01840", "authors": ["Greta Ontrup", "Annika Bush", "Markus Pauly", "Meltem Aksoy"], "title": "A Detailed Study on LLM Biases Concerning Corporate Social Responsibility and Green Supply Chains", "categories": ["cs.CY", "cs.AI"], "comment": "37 pages, 2 figures", "summary": "Organizations increasingly use Large Language Models (LLMs) to improve supply\nchain processes and reduce environmental impacts. However, LLMs have been shown\nto reproduce biases regarding the prioritization of sustainable business\nstrategies. Thus, it is important to identify underlying training data biases\nthat LLMs pertain regarding the importance and role of sustainable business and\nsupply chain practices. This study investigates how different LLMs respond to\nvalidated surveys about the role of ethics and responsibility for businesses,\nand the importance of sustainable practices and relations with suppliers and\ncustomers. Using standardized questionnaires, we systematically analyze\nresponses generated by state-of-the-art LLMs to identify variations. We further\nevaluate whether differences are augmented by four organizational culture\ntypes, thereby evaluating the practical relevance of identified biases. The\nfindings reveal significant systematic differences between models and\ndemonstrate that organizational culture prompts substantially modify LLM\nresponses. The study holds important implications for LLM-assisted\ndecision-making in sustainability contexts.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u53ef\u6301\u7eed\u5546\u4e1a\u95ee\u5377\u7684\u54cd\u5e94\uff0c\u5206\u6790\u6a21\u578b\u5dee\u5f02\u53ca\u7ec4\u7ec7\u6587\u5316\u5f71\u54cd\uff0c\u5bf9\u53ef\u6301\u7eed\u51b3\u7b56\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f9b\u5e94\u94fe\u4e2d\u4f7f\u7528\u5e7f\u6cdb\uff0c\u4f46\u5b58\u5728\u53ef\u6301\u7eed\u5546\u4e1a\u7b56\u7565\u4f18\u5148\u7ea7\u7684\u504f\u89c1\uff0c\u9700\u8bc6\u522b\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u504f\u89c1\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u5316\u95ee\u5377\uff0c\u7cfb\u7edf\u5206\u6790\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u54cd\u5e94\uff0c\u8bc4\u4f30\u56db\u79cd\u7ec4\u7ec7\u6587\u5316\u7c7b\u578b\u5bf9\u5dee\u5f02\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u7cfb\u7edf\u5dee\u5f02\uff0c\u7ec4\u7ec7\u6587\u5316\u63d0\u793a\u4f1a\u663e\u8457\u6539\u53d8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u54cd\u5e94\u3002", "conclusion": "\u7814\u7a76\u5bf9\u53ef\u6301\u7eed\u80cc\u666f\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u51b3\u7b56\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2511.01846", "pdf": "https://arxiv.org/pdf/2511.01846", "abs": "https://arxiv.org/abs/2511.01846", "authors": ["Thang Luong", "Dawsen Hwang", "Hoang H. Nguyen", "Golnaz Ghiasi", "Yuri Chervonyi", "Insuk Seo", "Junsu Kim", "Garrett Bingham", "Jonathan Lee", "Swaroop Mishra", "Alex Zhai", "Clara Huiyi Hu", "Henryk Michalewski", "Jimin Kim", "Jeonghyun Ahn", "Junhwi Bae", "Xingyou Song", "Trieu H. Trinh", "Quoc V. Le", "Junehyuk Jung"], "title": "Towards Robust Mathematical Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP 2025 (main conference),\n  https://aclanthology.org/2025.emnlp-main.1794/", "summary": "Finding the right north-star metrics is highly critical for advancing the\nmathematical reasoning capabilities of foundation models, especially given that\nexisting evaluations are either too easy or only focus on getting correct short\nanswers. To address these issues, we present IMO-Bench, a suite of advanced\nreasoning benchmarks, vetted by a panel of top specialists and that\nspecifically targets the level of the International Mathematical Olympiad\n(IMO), the most prestigious venue for young mathematicians. IMO-AnswerBench\nfirst tests models on 400 diverse Olympiad problems with verifiable short\nanswers. IMO-Proof Bench is the next-level evaluation for proof-writing\ncapabilities, which includes both basic and advanced IMO level problems as well\nas detailed grading guidelines to facilitate automatic grading. These\nbenchmarks played a crucial role in our historic achievement of the gold-level\nperformance at IMO 2025 with Gemini Deep Think (Luong and Lockhart, 2025). Our\nmodel achieved 80.0% on IMO-AnswerBench and 65.7% on the advanced IMO-Proof\nBench, surpassing the best non-Gemini models by large margins of 6.9% and 42.4%\nrespectively. We also showed that autograders built with Gemini reasoning\ncorrelate well with human evaluations and construct IMO-GradingBench, with 1000\nhuman gradings on proofs, to enable further progress in automatic evaluation of\nlong-form answers. We hope that IMO-Bench will help the community towards\nadvancing robust mathematical reasoning and release it at\nhttps://imobench.github.io/.", "AI": {"tldr": "\u63d0\u51faIMO - Bench\u57fa\u51c6\u5957\u4ef6\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\uff0c\u6a21\u578b\u53d6\u5f97\u597d\u6210\u7ee9\u5e76\u6784\u5efa\u81ea\u52a8\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u8981\u4e48\u592a\u7b80\u5355\uff0c\u8981\u4e48\u53ea\u5173\u6ce8\u6b63\u786e\u77ed\u7b54\u6848\uff0c\u9700\u627e\u5230\u5408\u9002\u6307\u6807\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faIMO - Bench\u57fa\u51c6\u5957\u4ef6\uff0c\u542bIMO - AnswerBench\u6d4b\u8bd5\u77ed\u7b54\u6848\u3001IMO - Proof Bench\u6d4b\u8bd5\u8bc1\u660e\u80fd\u529b\u53ca\u81ea\u52a8\u8bc4\u5206\u6307\u5357\u3002", "result": "\u6a21\u578b\u5728IMO - AnswerBench\u8fbe80.0%\uff0c\u5728advanced IMO - Proof Bench\u8fbe65.7%\uff0c\u8fdc\u8d85\u975eGemini\u6a21\u578b\uff1b\u81ea\u52a8\u8bc4\u5206\u5668\u4e0e\u4eba\u5de5\u8bc4\u4f30\u76f8\u5173\u6027\u597d\uff0c\u6784\u5efaIMO - GradingBench\u3002", "conclusion": "\u5e0c\u671bIMO - Bench\u52a9\u529b\u793e\u533a\u63d0\u5347\u9c81\u68d2\u6570\u5b66\u63a8\u7406\u80fd\u529b\u5e76\u516c\u5f00\u8be5\u57fa\u51c6\u3002"}}
