{"id": "2507.11907", "pdf": "https://arxiv.org/pdf/2507.11907", "abs": "https://arxiv.org/abs/2507.11907", "authors": ["Zhaoheng Li", "Silu Huang", "Wei Ding", "Yongjoo Park", "Jianjun Chen"], "title": "SIEVE: Effective Filtered Vector Search with Collection of Indexes", "categories": ["cs.DB", "cs.IR"], "comment": null, "summary": "Many real-world tasks such as recommending videos with the kids tag can be\nreduced to finding most similar vectors associated with hard predicates. This\ntask, filtered vector search, is challenging as prior state-of-the-art\ngraph-based (unfiltered) similarity search techniques quickly degenerate when\nhard constraints are considered. That is, effective graph-based filtered\nsimilarity search relies on sufficient connectivity for reaching the most\nsimilar items within just a few hops. To consider predicates, recent works\npropose modifying graph traversal to visit only the items that may satisfy\npredicates. However, they fail to offer the just-a-few-hops property for a wide\nrange of predicates: they must restrict predicates significantly or lose\nefficiency if only a small fraction of items satisfy predicates.\n  We propose an opposite approach: instead of constraining traversal, we build\nmany indexes each serving different predicate forms. For effective\nconstruction, we devise a three-dimensional analytical model capturing\nrelationships among index size, search time, and recall, with which we follow a\nworkload-aware approach to pack as many useful indexes as possible into a\ncollection. At query time, the analytical model is employed yet again to\ndiscern the one that offers the fastest search at a given recall. We show\nsuperior performance and support on datasets with varying selectivities and\nforms: our approach achieves up to 8.06x speedup while having as low as 1%\nbuild time versus other indexes, with less than 2.15x memory of a standard HNSW\ngraph and modest knowledge of past workloads.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6784\u5efa\u591a\u7d22\u5f15\u7684\u8fc7\u6ee4\u5411\u91cf\u641c\u7d22\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u8fc7\u6ee4\u76f8\u4f3c\u6027\u641c\u7d22\u6280\u672f\u5728\u8003\u8651\u786c\u7ea6\u675f\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u4e0d\u80fd\u6ee1\u8db3\u591a\u79cd\u8c13\u8bcd\u7684\u5c11\u8df3\u641c\u7d22\u9700\u6c42\u3002", "method": "\u6784\u5efa\u591a\u4e2a\u670d\u52a1\u4e8e\u4e0d\u540c\u8c13\u8bcd\u5f62\u5f0f\u7684\u7d22\u5f15\uff0c\u8bbe\u8ba1\u4e09\u7ef4\u5206\u6790\u6a21\u578b\uff0c\u91c7\u7528\u5de5\u4f5c\u91cf\u611f\u77e5\u65b9\u6cd5\u6253\u5305\u7d22\u5f15\uff0c\u67e5\u8be2\u65f6\u7528\u6a21\u578b\u9009\u62e9\u6700\u5feb\u641c\u7d22\u7684\u7d22\u5f15\u3002", "result": "\u5728\u4e0d\u540c\u9009\u62e9\u6027\u548c\u5f62\u5f0f\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe8.06\u500d\u7684\u52a0\u901f\uff0c\u6784\u5efa\u65f6\u95f4\u4f4e\u81f31%\uff0c\u5185\u5b58\u5c0f\u4e8e\u6807\u51c6HNSW\u56fe\u76842.15\u500d\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u8fc7\u6ee4\u5411\u91cf\u641c\u7d22\u4efb\u52a1\u4e2d\u5177\u6709\u4f18\u8d8a\u6027\u80fd\u548c\u826f\u597d\u652f\u6301\u3002"}}
{"id": "2507.11897", "pdf": "https://arxiv.org/pdf/2507.11897", "abs": "https://arxiv.org/abs/2507.11897", "authors": ["Tyler Hou", "Shadaj Laddad", "Joseph M. Hellerstein"], "title": "Towards Relational Contextual Equality Saturation", "categories": ["cs.PL", "cs.DB"], "comment": "Appeared at EGRAPHS 2024", "summary": "Equality saturation is a powerful technique for program optimization.\nContextual equality saturation extends this to support rewrite rules that are\nconditioned on where a term appears in an expression. Existing work has brought\ncontextual reasoning to egg; in this paper, we share our ongoing work to extend\nthis to relational equality saturation in egglog. We summarize the existing\napproaches to contextual equality saturation, outline its main applications,\nand identify key challenges in combining this approach with relational models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5c06\u4e0a\u4e0b\u6587\u7b49\u5f0f\u9971\u548c\u6269\u5c55\u5230egglog\u4e2d\u5173\u7cfb\u7b49\u5f0f\u9971\u548c\u7684\u6b63\u5728\u8fdb\u884c\u7684\u5de5\u4f5c\uff0c\u603b\u7ed3\u73b0\u6709\u65b9\u6cd5\u3001\u5e94\u7528\u5e76\u6307\u51fa\u7ed3\u5408\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5c06\u4e0a\u4e0b\u6587\u63a8\u7406\u5f15\u5165egg\uff0c\u672c\u6587\u65e8\u5728\u5c06\u5176\u6269\u5c55\u5230egglog\u4e2d\u7684\u5173\u7cfb\u7b49\u5f0f\u9971\u548c\u3002", "method": "\u603b\u7ed3\u73b0\u6709\u4e0a\u4e0b\u6587\u7b49\u5f0f\u9971\u548c\u65b9\u6cd5\uff0c\u6982\u8ff0\u5176\u4e3b\u8981\u5e94\u7528\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c", "conclusion": "\u8bc6\u522b\u51fa\u5c06\u4e0a\u4e0b\u6587\u7b49\u5f0f\u9971\u548c\u65b9\u6cd5\u4e0e\u5173\u7cfb\u6a21\u578b\u7ed3\u5408\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2507.11808", "pdf": "https://arxiv.org/pdf/2507.11808", "abs": "https://arxiv.org/abs/2507.11808", "authors": ["Taiki Yamada", "Taisuke Matsubae", "Tomoya Akamatsu"], "title": "New allocation rule based on graph structures and their application to economic phenomena", "categories": ["cs.GT", "cs.DM", "Primary 68R10, Secondary 90B06"], "comment": "15 pages, 8 figures", "summary": "This study introduces the \\emph{edge-based Shapley value}, a novel allocation\nrule within cooperative game theory, specifically tailored for networked\nsystems, where value is generated through interactions represented by edges.\nTraditional allocation rules, such as the Shapley and Myerson values, evaluate\nplayer contributions based on node-level characteristics, or connected\ncomponents. However, these approaches often fail to adequately capture the\nfunctional role of edges, which are crucial in systems such as supply chains\nand digital platforms, where interactions, rather than individual agents, are\nthe primary drivers of value. Our edge-based Shapley value shifts the\ncharacteristic function from node sets to edge sets, thereby enabling a more\ngranular and context-sensitive evaluation of the contributions. We establish\nits theoretical foundations, demonstrate its relationship to classical\nallocation rules, and show that it retains key properties such as fairness and\nsymmetry. To illustrate its applicability, we present two use cases: content\nplatform networks and supply chain logistics (SCL). In both cases, our method\nproduces intuitive and structurally consistent allocations, particularly in\nscenarios with overlapping routes, exclusive contracts or cost-sensitive paths.\nThis framework offers a new perspective on value attribution in cooperative\nsettings with complex interaction structures and provides practical tools for\nanalyzing real-world economic and logistical networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8fb9\u7684Shapley\u503c\u5206\u914d\u89c4\u5219\uff0c\u9002\u7528\u4e8e\u7f51\u7edc\u7cfb\u7edf\uff0c\u4ee5\u8fb9\u4e3a\u57fa\u7840\u8bc4\u4f30\u8d21\u732e\uff0c\u901a\u8fc7\u4e24\u4e2a\u7528\u4f8b\u9a8c\u8bc1\u5176\u9002\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u5206\u914d\u89c4\u5219\u96be\u4ee5\u5145\u5206\u6355\u6349\u8fb9\u5728\u7f51\u7edc\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\uff0c\u800c\u8fb9\u662f\u67d0\u4e9b\u7cfb\u7edf\u4ef7\u503c\u4ea7\u751f\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u9700\u65b0\u89c4\u5219\u3002", "method": "\u5c06\u7279\u5f81\u51fd\u6570\u4ece\u8282\u70b9\u96c6\u8f6c\u79fb\u5230\u8fb9\u96c6\uff0c\u5efa\u7acb\u7406\u8bba\u57fa\u7840\uff0c\u5c55\u793a\u4e0e\u7ecf\u5178\u5206\u914d\u89c4\u5219\u5173\u7cfb\u3002", "result": "\u5728\u5185\u5bb9\u5e73\u53f0\u7f51\u7edc\u548c\u4f9b\u5e94\u94fe\u7269\u6d41\u4e24\u4e2a\u7528\u4f8b\u4e2d\uff0c\u65b9\u6cd5\u4ea7\u751f\u76f4\u89c2\u4e14\u7ed3\u6784\u4e00\u81f4\u7684\u5206\u914d\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u590d\u6742\u4ea4\u4e92\u7ed3\u6784\u7684\u5408\u4f5c\u573a\u666f\u63d0\u4f9b\u4ef7\u503c\u5206\u914d\u65b0\u89c6\u89d2\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2507.11681", "pdf": "https://arxiv.org/pdf/2507.11681", "abs": "https://arxiv.org/abs/2507.11681", "authors": ["Sotiris Kanellopoulos", "Christos Pergaminelis", "Maria Kokkou", "Euripides Markou", "Aris Pagourtzis"], "title": "Finite Pinwheel Scheduling: the k-Visits Problem", "categories": ["cs.DS"], "comment": null, "summary": "Pinwheel Scheduling is a fundamental scheduling problem, in which each task\n$i$ is associated with a positive integer $d_i$, and the objective is to\nschedule one task per time slot, ensuring each task perpetually appears at\nleast once in every $d_i$ time slots. Although conjectured to be\nPSPACE-complete, it remains open whether Pinwheel Scheduling is NP-hard (unless\na compact input encoding is used) or even contained in NP.\n  We introduce k-Visits, a finite version of Pinwheel Scheduling, where given n\ndeadlines, the goal is to schedule each task exactly k times. While we observe\nthat the 1-Visit problem is trivial, we prove that 2-Visits is strongly\nNP-complete through a surprising reduction from Numerical 3-Dimensional\nMatching (N3DM). As intermediate steps in the reduction, we define NP-complete\nvariants of N3DM which may be of independent interest. We further extend our\nstrong NP-hardness result to a generalization of k-Visits $k\\geq 2$ in which\nthe deadline of each task may vary throughout the schedule, as well as to a\nsimilar generalization of Pinwheel Scheduling, thus making progress towards\nsettling the complexity of Pinwheel Scheduling.\n  Additionally, we prove that 2-Visits can be solved in linear time if all\ndeadlines are distinct, rendering it one of the rare natural problems which\nexhibit the interesting dichotomy of being in P if their input is a set and\nNP-complete if the input is a multiset. We achieve this through a Turing\nreduction from 2-Visits to a variation of N3DM, which we call Position\nMatching. Based on this reduction, we also show an FPT algorithm for 2-Visits\nparameterized by a value related to how close the input deadlines are to each\nother, as well as a linear-time algorithm for instances with up to two distinct\ndeadlines.", "AI": {"tldr": "\u5f15\u5165 Pinwheel \u8c03\u5ea6\u95ee\u9898\u6709\u9650\u7248\u672c k - Visits\uff0c\u8bc1\u660e 2 - Visits \u5f3a NP \u5b8c\u5168\uff0c\u6269\u5c55\u81f3 k \u2265 2 \u60c5\u51b5\uff0c\u8fd8\u7ed9\u51fa\u7279\u5b9a\u6761\u4ef6\u4e0b\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u7b49\u3002", "motivation": "\u89e3\u51b3 Pinwheel \u8c03\u5ea6\u95ee\u9898\u590d\u6742\u5ea6\u672a\u660e\u786e\u7684\u95ee\u9898\uff0c\u7814\u7a76\u5176\u6709\u9650\u7248\u672c\u4ee5\u63a8\u52a8\u590d\u6742\u5ea6\u786e\u5b9a\u3002", "method": "\u901a\u8fc7\u4ece Numerical 3 - Dimensional Matching \u5f52\u7ea6\u8bc1\u660e 2 - Visits \u5f3a NP \u5b8c\u5168\uff1b\u7528\u56fe\u7075\u5f52\u7ea6\u4ece 2 - Visits \u5230 Position Matching \u5f97\u5230\u7279\u5b9a\u6761\u4ef6\u4e0b\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e 2 - Visits \u5f3a NP \u5b8c\u5168\uff0c\u6269\u5c55\u81f3 k \u2265 2 \u60c5\u51b5\uff1b\u5728\u6240\u6709\u622a\u6b62\u65f6\u95f4\u4e0d\u540c\u65f6 2 - Visits \u53ef\u7ebf\u6027\u65f6\u95f4\u6c42\u89e3\uff1b\u7ed9\u51fa FPT \u7b97\u6cd5\u548c\u6700\u591a\u4e24\u4e2a\u4e0d\u540c\u622a\u6b62\u65f6\u95f4\u5b9e\u4f8b\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u3002", "conclusion": "\u5bf9 Pinwheel \u8c03\u5ea6\u95ee\u9898\u590d\u6742\u5ea6\u7814\u7a76\u53d6\u5f97\u8fdb\u5c55\uff0c\u53d1\u73b0 2 - Visits \u6709\u8da3\u7684\u4e8c\u5206\u6027\u8d28\u3002"}}
{"id": "2507.11640", "pdf": "https://arxiv.org/pdf/2507.11640", "abs": "https://arxiv.org/abs/2507.11640", "authors": ["Veronika Tr\u00e1vn\u00edkov\u00e1", "Eric von Lieres", "Marek Behr"], "title": "Quantifying data needs in surrogate modeling for flow fields in 2D stirred tanks with physics-informed neural networks (PINNs)", "categories": ["cs.CE", "76-10, 68T07 (Primary) 76D05, 35Q68 (Secondary)"], "comment": "24 pages, 18 figures", "summary": "Stirred tanks are vital in chemical and biotechnological processes,\nparticularly as bioreactors. Although computational fluid dynamics (CFD) is\nwidely used to model the flow in stirred tanks, its high computational\ncost$-$especially in multi-query scenarios for process design and\noptimization$-$drives the need for efficient data-driven surrogate models.\nHowever, acquiring sufficiently large datasets can be costly. Physics-informed\nneural networks (PINNs) offer a promising solution to reduce data requirements\nwhile maintaining accuracy by embedding underlying physics into neural network\n(NN) training. This study quantifies the data requirements of vanilla PINNs for\ndeveloping surrogate models of a flow field in a 2D stirred tank. We compare\nthese requirements with classical supervised neural networks and\nboundary-informed neural networks (BINNs). Our findings demonstrate that\nsurrogate models can achieve prediction errors around 3% across Reynolds\nnumbers from 50 to 5000 using as few as six datapoints. Moreover, employing an\napproximation of the velocity profile in place of real data labels leads to\nprediction errors of around 2.5%. These results indicate that even with limited\nor approximate datasets, PINNs can be effectively trained to deliver high\naccuracy comparable to high-fidelity data.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5316\u4e8c\u7ef4\u6405\u62cc\u69fd\u6d41\u573a\u66ff\u4ee3\u6a21\u578b\u4e2d\u9999\u8349PINNs\u7684\u6570\u636e\u9700\u6c42\uff0c\u4e0e\u7ecf\u5178\u76d1\u7763\u795e\u7ecf\u7f51\u7edc\u548cBINNs\u5bf9\u6bd4\uff0c\u53d1\u73b0\u5c11\u91cf\u6216\u8fd1\u4f3c\u6570\u636e\u4e0bPINNs\u4e5f\u80fd\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u3002", "motivation": "CFD\u6a21\u62df\u6405\u62cc\u69fd\u5185\u6d41\u52a8\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u83b7\u53d6\u5927\u6570\u636e\u96c6\u6602\u8d35\uff0cPINNs\u53ef\u964d\u4f4e\u6570\u636e\u9700\u6c42\u5e76\u4fdd\u6301\u7cbe\u5ea6\uff0c\u56e0\u6b64\u7814\u7a76\u5176\u6570\u636e\u9700\u6c42\u3002", "method": "\u91cf\u5316\u9999\u8349PINNs\u5f00\u53d1\u4e8c\u7ef4\u6405\u62cc\u69fd\u6d41\u573a\u66ff\u4ee3\u6a21\u578b\u7684\u6570\u636e\u9700\u6c42\uff0c\u5e76\u4e0e\u7ecf\u5178\u76d1\u7763\u795e\u7ecf\u7f51\u7edc\u548cBINNs\u5bf9\u6bd4\u3002", "result": "\u4ec5\u7528\u516d\u4e2a\u6570\u636e\u70b9\uff0c\u66ff\u4ee3\u6a21\u578b\u5728\u96f7\u8bfa\u657050 - 5000\u8303\u56f4\u5185\u9884\u6d4b\u8bef\u5dee\u7ea63%\uff1b\u7528\u901f\u5ea6\u5256\u9762\u8fd1\u4f3c\u66ff\u4ee3\u771f\u5b9e\u6570\u636e\u6807\u7b7e\uff0c\u9884\u6d4b\u8bef\u5dee\u7ea62.5%\u3002", "conclusion": "\u5373\u4f7f\u6570\u636e\u96c6\u6709\u9650\u6216\u4e3a\u8fd1\u4f3c\u6570\u636e\uff0cPINNs\u4e5f\u80fd\u6709\u6548\u8bad\u7ec3\uff0c\u8fbe\u5230\u4e0e\u9ad8\u4fdd\u771f\u6570\u636e\u76f8\u5f53\u7684\u9ad8\u7cbe\u5ea6\u3002"}}
{"id": "2507.11866", "pdf": "https://arxiv.org/pdf/2507.11866", "abs": "https://arxiv.org/abs/2507.11866", "authors": ["Jinkyeong Choi", "Yejin Noh", "Donghyeon Park"], "title": "Similarity-Guided Diffusion for Contrastive Sequential Recommendation", "categories": ["cs.IR"], "comment": "14 pages, 5 figures", "summary": "In sequential recommendation systems, data augmentation and contrastive\nlearning techniques have recently been introduced using diffusion models to\nachieve robust representation learning. However, most of the existing\napproaches use random augmentation, which risk damaging the contextual\ninformation of the original sequence. Accordingly, we propose a\nSimilarity-Guided Diffusion for Contrastive Sequential Recommendation. Our\nmethod leverages the similarity between item embedding vectors to generate\nsemantically consistent noise. Moreover, we utilize high confidence score in\nthe denoising process to select our augmentation positions. This approach more\neffectively reflects contextual and structural information compared to\naugmentation at random positions. From a contrastive learning perspective, the\nproposed augmentation technique provides more discriminative positive and\nnegative samples, simultaneously improving training efficiency and\nrecommendation performance. Experimental results on five benchmark datasets\nshow that SimDiffRec outperforms the existing baseline models.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5bf9\u6bd4\u5e8f\u5217\u63a8\u8350\u7684\u76f8\u4f3c\u6027\u5f15\u5bfc\u6269\u6563\u65b9\u6cd5\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u4f7f\u7528\u6269\u6563\u6a21\u578b\u7684\u6570\u636e\u589e\u5f3a\u548c\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u591a\u91c7\u7528\u968f\u673a\u589e\u5f3a\uff0c\u6709\u7834\u574f\u539f\u5e8f\u5217\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u98ce\u9669\u3002", "method": "\u5229\u7528\u7269\u54c1\u5d4c\u5165\u5411\u91cf\u95f4\u7684\u76f8\u4f3c\u6027\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u7684\u566a\u58f0\uff0c\u5728\u53bb\u566a\u8fc7\u7a0b\u4e2d\u5229\u7528\u9ad8\u7f6e\u4fe1\u5ea6\u5206\u6570\u9009\u62e9\u589e\u5f3a\u4f4d\u7f6e\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cSimDiffRec \u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u589e\u5f3a\u6280\u672f\u80fd\u63d0\u4f9b\u66f4\u5177\u533a\u5206\u6027\u7684\u6b63\u8d1f\u6837\u672c\uff0c\u540c\u65f6\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2507.11545", "pdf": "https://arxiv.org/pdf/2507.11545", "abs": "https://arxiv.org/abs/2507.11545", "authors": ["Rhea Pritham Marpu", "Kevin J McNamara", "Preeti Gupta"], "title": "The AI Shadow War: SaaS vs. Edge Computing Architectures", "categories": ["cs.DC", "cs.ET", "cs.NE"], "comment": null, "summary": "The very DNA of AI architecture presents conflicting paths: centralized\ncloud-based models (Software-as-a-Service) versus decentralized edge AI (local\nprocessing on consumer devices). This paper analyzes the competitive\nbattleground across computational capability, energy efficiency, and data\nprivacy. Recent breakthroughs show edge AI challenging cloud systems on\nperformance, leveraging innovations like test-time training and\nmixture-of-experts architectures. Crucially, edge AI boasts a 10,000x\nefficiency advantage: modern ARM processors consume merely 100 microwatts\nforinference versus 1 watt for equivalent cloud processing. Beyond efficiency,\nedge AI secures data sovereignty by keeping processing local, dismantling\nsingle points of failure in centralized architectures. This democratizes access\nthroughaffordable hardware, enables offline functionality, and reduces\nenvironmental impact by eliminating data transmission costs. The edge AI market\nprojects explosive growth from $9 billion in 2025 to $49.6 billion by 2030\n(38.5% CAGR), fueled by privacy demands and real-time analytics. Critical\napplications including personalized education, healthcare monitoring,\nautonomous transport, and smart infrastructure rely on edge AI's ultra-low\nlatency (5-10ms versus 100-500ms for cloud). The convergence of architectural\ninnovation with fundamental physics confirms edge AI's distributed approach\naligns with efficient information processing, signaling the inevitable\nemergence of hybrid edge-cloud ecosystems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790AI\u67b6\u6784\u4e2d\u96c6\u4e2d\u5f0f\u4e91\u6a21\u578b\u4e0e\u53bb\u4e2d\u5fc3\u5316\u8fb9\u7f18AI\u7684\u7ade\u4e89\uff0c\u5c55\u793a\u8fb9\u7f18AI\u5728\u6027\u80fd\u3001\u6548\u7387\u3001\u9690\u79c1\u7b49\u65b9\u9762\u4f18\u52bf\u53ca\u5e02\u573a\u589e\u957f\u524d\u666f\uff0c\u9884\u793a\u6df7\u5408\u8fb9\u7f18 - \u4e91\u751f\u6001\u7cfb\u7edf\u7684\u51fa\u73b0\u3002", "motivation": "\u63a2\u8ba8AI\u67b6\u6784\u4e2d\u96c6\u4e2d\u5f0f\u4e91\u6a21\u578b\u4e0e\u53bb\u4e2d\u5fc3\u5316\u8fb9\u7f18AI\u7684\u7ade\u4e89\u6001\u52bf\u3002", "method": "\u4ece\u8ba1\u7b97\u80fd\u529b\u3001\u80fd\u6e90\u6548\u7387\u548c\u6570\u636e\u9690\u79c1\u7b49\u65b9\u9762\u5bf9\u6bd4\u5206\u6790\u4e24\u79cd\u67b6\u6784\u3002", "result": "\u8fb9\u7f18AI\u5728\u6027\u80fd\u4e0a\u6311\u6218\u4e91\u7cfb\u7edf\uff0c\u670910000\u500d\u6548\u7387\u4f18\u52bf\uff0c\u4fdd\u969c\u6570\u636e\u4e3b\u6743\uff0c\u5e02\u573a\u9884\u8ba1\u4ece2025\u5e7490\u4ebf\u7f8e\u5143\u589e\u957f\u52302030\u5e74496\u4ebf\u7f8e\u5143\uff0c\u5173\u952e\u5e94\u7528\u4f9d\u8d56\u5176\u8d85\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "\u8fb9\u7f18AI\u5206\u5e03\u5f0f\u65b9\u6cd5\u7b26\u5408\u9ad8\u6548\u4fe1\u606f\u5904\u7406\uff0c\u6df7\u5408\u8fb9\u7f18 - \u4e91\u751f\u6001\u7cfb\u7edf\u5c06\u4e0d\u53ef\u907f\u514d\u5730\u51fa\u73b0\u3002"}}
{"id": "2507.11566", "pdf": "https://arxiv.org/pdf/2507.11566", "abs": "https://arxiv.org/abs/2507.11566", "authors": ["Fuda van Diggelen", "Tugay Alperen Karag\u00fczel", "Andres Garcia Rincon", "A. E. Eiben", "Dario Floreano", "Eliseo Ferrante"], "title": "Emergent Heterogeneous Swarm Control Through Hebbian Learning", "categories": ["cs.NE", "cs.AI", "cs.RO"], "comment": null, "summary": "In this paper, we introduce Hebbian learning as a novel method for swarm\nrobotics, enabling the automatic emergence of heterogeneity. Hebbian learning\npresents a biologically inspired form of neural adaptation that solely relies\non local information. By doing so, we resolve several major challenges for\nlearning heterogeneous control: 1) Hebbian learning removes the complexity of\nattributing emergent phenomena to single agents through local learning rules,\nthus circumventing the micro-macro problem; 2) uniform Hebbian learning rules\nacross all swarm members limit the number of parameters needed, mitigating the\ncurse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian\nlearning rules based on swarm-level behaviour minimises the need for extensive\nprior knowledge typically required for optimising heterogeneous swarms. This\nwork demonstrates that with Hebbian learning heterogeneity naturally emerges,\nresulting in swarm-level behavioural switching and in significantly improved\nswarm capabilities. It also demonstrates how the evolution of Hebbian learning\nrules can be a valid alternative to Multi Agent Reinforcement Learning in\nstandard benchmarking tasks.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u8d6b\u5e03\u5b66\u4e60\u4f5c\u4e3a\u7fa4\u4f53\u673a\u5668\u4eba\u5b66\u65b0\u65b9\u6cd5\uff0c\u80fd\u81ea\u52a8\u4ea7\u751f\u5f02\u8d28\u6027\uff0c\u89e3\u51b3\u5b66\u4e60\u5f02\u8d28\u63a7\u5236\u7684\u6311\u6218\uff0c\u63d0\u5347\u7fa4\u4f53\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u7fa4\u4f53\u673a\u5668\u4eba\u5b66\u4e2d\u5b66\u4e60\u5f02\u8d28\u63a7\u5236\u7684\u82e5\u5e72\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f15\u5165\u751f\u7269\u542f\u53d1\u7684\u8d6b\u5e03\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5c40\u90e8\u4fe1\u606f\uff0c\u57fa\u4e8e\u7fa4\u4f53\u884c\u4e3a\u6f14\u5316\u5b66\u4e60\u89c4\u5219\u3002", "result": "\u5b9e\u73b0\u5f02\u8d28\u6027\u81ea\u7136\u6d8c\u73b0\uff0c\u5e26\u6765\u7fa4\u4f53\u884c\u4e3a\u5207\u6362\uff0c\u663e\u8457\u63d0\u5347\u7fa4\u4f53\u80fd\u529b\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u4efb\u52a1\u4e2d\u53ef\u66ff\u4ee3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u3002", "conclusion": "\u8d6b\u5e03\u5b66\u4e60\u662f\u7fa4\u4f53\u673a\u5668\u4eba\u5b66\u6709\u6548\u65b9\u6cd5\uff0c\u53ef\u89e3\u51b3\u76f8\u5173\u6311\u6218\uff0c\u4e14\u6f14\u5316\u89c4\u5219\u80fd\u66ff\u4ee3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u3002"}}
{"id": "2507.12267", "pdf": "https://arxiv.org/pdf/2507.12267", "abs": "https://arxiv.org/abs/2507.12267", "authors": ["Filippo Marchesani"], "title": "Orchestrating the Implementation of the Smart City", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This chapter explores the six core dimensions of smart cities (i.e. smart\neconomy, mobility, environment, people, living, and governance) emphasizing\ntheir interdependence and the need for holistic orchestration. Building on\nGiffinger et al. (2007) and subsequent literature, it argues that integrating\nthese dimensions is crucial for sustainable urban development. ICT plays a key\nenabling role but must be complemented by human and social capital. Through\ninstitutional examples, such as the creation of dedicated municipal offices for\ndigital innovation, the chapter illustrates how governance and internal\ncapacity shape smart transitions. A human-centric approach is also essential,\nensuring inclusivity, creativity, and active civic participation. Ultimately,\nsmart cities must be viewed as cohesive urban ecosystems where technology,\npeople, and governance interact dynamically.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u667a\u6167\u57ce\u5e02\u516d\u5927\u6838\u5fc3\u7ef4\u5ea6\u7684\u76f8\u4e92\u4f9d\u8d56\u4e0e\u6574\u4f53\u534f\u8c03\uff0c\u5f3a\u8c03\u6574\u5408\u5bf9\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u91cd\u8981\u6027\uff0c\u6307\u51faICT\u9700\u4e0e\u4eba\u529b\u548c\u793e\u4f1a\u8d44\u672c\u7ed3\u5408\uff0c\u901a\u8fc7\u5b9e\u4f8b\u8bf4\u660e\u6cbb\u7406\u548c\u80fd\u529b\u5bf9\u8f6c\u578b\u7684\u5f71\u54cd\uff0c\u5021\u5bfc\u4ee5\u4eba\u4e3a\u672c\u3002", "motivation": "\u7814\u7a76\u667a\u6167\u57ce\u5e02\u516d\u5927\u6838\u5fc3\u7ef4\u5ea6\u76f8\u4e92\u5173\u7cfb\u53ca\u5982\u4f55\u5b9e\u73b0\u53ef\u6301\u7eed\u57ce\u5e02\u53d1\u5c55\u3002", "method": "\u57fa\u4e8eGiffinger\u7b49\u4eba\uff082007\uff09\u53ca\u540e\u7eed\u6587\u732e\uff0c\u7ed3\u5408\u673a\u6784\u5b9e\u4f8b\u3002", "result": "\u8bf4\u660e\u4e86\u6cbb\u7406\u548c\u5185\u90e8\u80fd\u529b\u5bf9\u667a\u6167\u57ce\u5e02\u8f6c\u578b\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u4ee5\u4eba\u4e3a\u672c\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u667a\u6167\u57ce\u5e02\u5e94\u88ab\u89c6\u4e3a\u6280\u672f\u3001\u4eba\u5458\u548c\u6cbb\u7406\u52a8\u6001\u4e92\u52a8\u7684\u57ce\u5e02\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2507.11595", "pdf": "https://arxiv.org/pdf/2507.11595", "abs": "https://arxiv.org/abs/2507.11595", "authors": ["Hengyue Zhao"], "title": "A Study on the Application of Artificial Intelligence in Ecological Design", "categories": ["cs.AI", "cs.CY", "I.4.8; I.2.6"], "comment": null, "summary": "This paper asks whether our relationship with nature can move from human\ndominance to genuine interdependence, and whether artificial intelligence (AI)\ncan mediate that shift. We examine a new ecological-design paradigm in which AI\ninteracts with non-human life forms. Through case studies we show how artists\nand designers apply AI for data analysis, image recognition, and ecological\nrestoration, producing results that differ from conventional media. We argue\nthat AI not only expands creative methods but also reframes the theory and\npractice of ecological design. Building on the author's prototype for\nAI-assisted water remediation, the study proposes design pathways that couple\nreinforcement learning with plant-based phytoremediation. The findings\nhighlight AI's potential to link scientific insight, artistic practice, and\nenvironmental stewardship, offering a roadmap for future research on\nsustainable, technology-enabled ecosystems.", "AI": {"tldr": "\u63a2\u8ba8\u4eba\u4e0e\u5927\u81ea\u7136\u5173\u7cfb\u80fd\u5426\u4ece\u4eba\u7c7b\u4e3b\u5bfc\u8f6c\u5411\u76f8\u4e92\u4f9d\u5b58\u53caAI\u80fd\u5426\u4fc3\u6210\u8f6c\u53d8\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793aAI\u5728\u751f\u6001\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u8bbe\u8ba1\u9014\u5f84\uff0c\u5f3a\u8c03AI\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u4eba\u4e0e\u5927\u81ea\u7136\u5173\u7cfb\u80fd\u5426\u4ece\u4eba\u7c7b\u4e3b\u5bfc\u8f6c\u53d8\u4e3a\u771f\u6b63\u7684\u76f8\u4e92\u4f9d\u5b58\uff0c\u4ee5\u53ca\u4eba\u5de5\u667a\u80fd\u80fd\u5426\u4fc3\u6210\u8fd9\u4e00\u8f6c\u53d8\u3002", "method": "\u7814\u7a76\u65b0\u7684\u751f\u6001\u8bbe\u8ba1\u8303\u5f0f\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u827a\u672f\u5bb6\u548c\u8bbe\u8ba1\u5e08\u8fd0\u7528AI\u8fdb\u884c\u6570\u636e\u5206\u6790\u3001\u56fe\u50cf\u8bc6\u522b\u548c\u751f\u6001\u4fee\u590d\uff0c\u57fa\u4e8e\u4f5c\u8005\u7684AI\u8f85\u52a9\u6c34\u4fee\u590d\u539f\u578b\u63d0\u51fa\u8bbe\u8ba1\u9014\u5f84\u3002", "result": "AI\u4e0d\u4ec5\u6269\u5c55\u4e86\u521b\u4f5c\u65b9\u6cd5\uff0c\u8fd8\u91cd\u5851\u4e86\u751f\u6001\u8bbe\u8ba1\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\uff1b\u7a81\u51fa\u4e86AI\u5c06\u79d1\u5b66\u89c1\u89e3\u3001\u827a\u672f\u5b9e\u8df5\u548c\u73af\u5883\u7ba1\u7406\u8054\u7cfb\u8d77\u6765\u7684\u6f5c\u529b\u3002", "conclusion": "AI\u4e3a\u672a\u6765\u53ef\u6301\u7eed\u7684\u3001\u6280\u672f\u8d4b\u80fd\u7684\u751f\u6001\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2507.11671", "pdf": "https://arxiv.org/pdf/2507.11671", "abs": "https://arxiv.org/abs/2507.11671", "authors": ["Mst Shamima Aktar", "Peng Liang", "Muhammad Waseem", "Amjed Tahir", "Mojtaba Shahin", "Muhammad Azeem Akbar", "Arif Ali Khan", "Aakash Ahmad", "Musengamana Jean de Dieu", "Ruiyin Li"], "title": "Decision Models for Selecting Architecture Patterns and Strategies in Quantum Software Systems", "categories": ["cs.SE"], "comment": "49 pages, 10 images, 16 tables, Manuscript submitted to a journal\n  (2025)", "summary": "Quantum software represents disruptive technologies in terms of\nquantum-specific software systems, services, and applications - leverage the\nprinciples of quantum mechanics via programmable quantum bits (Qubits) that\nmanipulate quantum gates (QuGates) - to achieve quantum supremacy in computing.\nQuantum software architecture enables quantum software developers to abstract\naway implementation-specific details (i.e., mapping of Qubits and QuGates to\nhigh-level architectural components and connectors). Architectural patterns and\nstrategies can provide reusable knowledge and best practices to engineer\nquantum software systems effectively and efficiently. However, quantum software\npractitioners face significant challenges in selecting and implementing\nappropriate patterns and strategies due to the complexity of quantum software\nsystems and the lack of guidelines. To address these challenges, this study\nproposes decision models for selecting patterns and strategies in six critical\ndesign areas in quantum software systems: Communication, Decomposition, Data\nProcessing, Fault Tolerance, Integration and Optimization, and Algorithm\nImplementation. These decision models are constructed based on data collected\nfrom both a mining study (i.e., GitHub and Stack Exchange) and a Systematic\nLiterature Review, which were used to identify relevant patterns and strategies\nwith their involved Quality Attributes (QAs). We then conducted semi-structured\ninterviews with 16 quantum software practitioners to evaluate the familiarity,\nunderstandability, completeness, and usefulness of the proposed decision\nmodels. The results show that the proposed decision models can aid\npractitioners in selecting suitable patterns and strategies to address the\nchallenges related to the architecture design of quantum software systems. The\ndataset is available at [6], allowing the community to reproduce and build upon\nour findings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u91cf\u5b50\u8f6f\u4ef6\u7cfb\u7edf\u516d\u4e2a\u5173\u952e\u8bbe\u8ba1\u9886\u57df\u9009\u62e9\u6a21\u5f0f\u548c\u7b56\u7565\u7684\u51b3\u7b56\u6a21\u578b\uff0c\u7ecf\u8bc4\u4f30\u8be5\u6a21\u578b\u80fd\u5e2e\u52a9\u4ece\u4e1a\u8005\u5e94\u5bf9\u67b6\u6784\u8bbe\u8ba1\u6311\u6218\uff0c\u6570\u636e\u96c6\u516c\u5f00\u3002", "motivation": "\u91cf\u5b50\u8f6f\u4ef6\u4ece\u4e1a\u8005\u5728\u9009\u62e9\u548c\u5b9e\u65bd\u5408\u9002\u7684\u6a21\u5f0f\u4e0e\u7b56\u7565\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7f3a\u4e4f\u76f8\u5173\u6307\u5bfc\u3002", "method": "\u57fa\u4e8e\u6316\u6398\u7814\u7a76\uff08GitHub\u548cStack Exchange\uff09\u548c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u6536\u96c6\u6570\u636e\u6784\u5efa\u51b3\u7b56\u6a21\u578b\uff0c\u901a\u8fc7\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u7684\u51b3\u7b56\u6a21\u578b\u80fd\u5e2e\u52a9\u4ece\u4e1a\u8005\u9009\u62e9\u5408\u9002\u7684\u6a21\u5f0f\u548c\u7b56\u7565\uff0c\u5e94\u5bf9\u91cf\u5b50\u8f6f\u4ef6\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u6311\u6218\u3002", "conclusion": "\u51b3\u7b56\u6a21\u578b\u6709\u52a9\u4e8e\u89e3\u51b3\u91cf\u5b50\u8f6f\u4ef6\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u7684\u76f8\u5173\u95ee\u9898\uff0c\u6570\u636e\u96c6\u53ef\u4f9b\u793e\u533a\u590d\u73b0\u548c\u62d3\u5c55\u7814\u7a76\u3002"}}
{"id": "2507.11547", "pdf": "https://arxiv.org/pdf/2507.11547", "abs": "https://arxiv.org/abs/2507.11547", "authors": ["Yingxue Zhao", "Qianyi Chen", "Haoran Li", "Haosu Zhou", "Hamid Reza Attar", "Tobias Pfaff", "Tailin Wu", "Nan Li"], "title": "Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, various artificial intelligence-based surrogate models have\nbeen proposed to provide rapid manufacturability predictions of material\nforming processes. However, traditional AI-based surrogate models, typically\nbuilt with scalar or image-based neural networks, are limited in their ability\nto capture complex 3D spatial relationships and to operate in a\npermutation-invariant manner. To overcome these issues, emerging graph-based\nsurrogate models are developed using graph neural networks. This study\ndeveloped a new graph neural network surrogate model named Recurrent U\nNet-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate\npredictions of sheet material deformation fields across multiple forming\ntimesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model\ntemporal dynamics and a U-Net inspired graph-based downsample/upsample\nmechanism to handle spatial long-range dependencies. A novel 'node-to-surface'\ncontact representation method was proposed, offering significant improvements\nin computational efficiency for large-scale contact interactions. The RUGNN\nmodel was validated using a cold forming case study and a more complex hot\nforming case study using aluminium alloys. Results demonstrate that the RUGNN\nmodel provides accurate deformation predictions closely matching ground truth\nFE simulations and outperforming several baseline GNN architectures. Model\ntuning was also performed to identify suitable hyperparameters, training\nstrategies, and input feature representations. These results demonstrate that\nRUGNN is a reliable approach to support sheet material forming design by\nenabling accurate manufacturability predictions.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u540d\u4e3aRUGNN\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u677f\u6750\u6210\u578b\u8fc7\u7a0b\u4e2d\u53d8\u5f62\u573a\u7684\u51c6\u786e\u9884\u6d4b\uff0c\u7ecf\u6848\u4f8b\u9a8c\u8bc1\u6548\u679c\u826f\u597d\uff0c\u662f\u652f\u6301\u677f\u6750\u6210\u578b\u8bbe\u8ba1\u7684\u53ef\u9760\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eAI\u7684\u66ff\u4ee3\u6a21\u578b\u5728\u6355\u6349\u590d\u67423D\u7a7a\u95f4\u5173\u7cfb\u548c\u6392\u5217\u4e0d\u53d8\u6027\u64cd\u4f5c\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6a21\u578b\u3002", "method": "\u5f00\u53d1RUGNN\u6a21\u578b\uff0c\u7ed3\u5408GRUs\u5904\u7406\u65f6\u95f4\u52a8\u6001\uff0c\u91c7\u7528\u53d7U - Net\u542f\u53d1\u7684\u56fe\u4e0b\u91c7\u6837/\u4e0a\u91c7\u6837\u673a\u5236\u5904\u7406\u7a7a\u95f4\u957f\u8ddd\u79bb\u4f9d\u8d56\uff0c\u63d0\u51fa\u201c\u8282\u70b9\u5230\u8868\u9762\u201d\u63a5\u89e6\u8868\u793a\u65b9\u6cd5\u3002", "result": "RUGNN\u6a21\u578b\u5728\u51b7\u6210\u578b\u548c\u70ed\u6210\u578b\u6848\u4f8b\u4e2d\u63d0\u4f9b\u4e86\u4e0e\u6709\u9650\u5143\u6a21\u62df\u7ed3\u679c\u76f8\u8fd1\u7684\u51c6\u786e\u53d8\u5f62\u9884\u6d4b\uff0c\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebfGNN\u67b6\u6784\u3002", "conclusion": "RUGNN\u662f\u652f\u6301\u677f\u6750\u6210\u578b\u8bbe\u8ba1\u3001\u5b9e\u73b0\u51c6\u786e\u53ef\u5236\u9020\u6027\u9884\u6d4b\u7684\u53ef\u9760\u65b9\u6cd5\u3002"}}
{"id": "2507.11768", "pdf": "https://arxiv.org/pdf/2507.11768", "abs": "https://arxiv.org/abs/2507.11768", "authors": ["Leon Chlon", "Sarah Rashidi", "Zein Khamis", "MarcAntonio M. Awada"], "title": "LLMs are Bayesian, in Expectation, not in Realization", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Large language models demonstrate remarkable in-context learning\ncapabilities, adapting to new tasks without parameter updates. While this\nphenomenon has been successfully modeled as implicit Bayesian inference, recent\nempirical findings reveal a fundamental contradiction: transformers\nsystematically violate the martingale property, a cornerstone requirement of\nBayesian updating on exchangeable data. This violation challenges the\ntheoretical foundations underlying uncertainty quantification in critical\napplications.\n  Our theoretical analysis establishes four key results: (1) positional\nencodings induce martingale violations of order $\\Theta(\\log n / n)$; (2)\ntransformers achieve information-theoretic optimality with excess risk\n$O(n^{-1/2})$ in expectation over orderings; (3) the implicit posterior\nrepresentation converges to the true Bayesian posterior in the space of\nsufficient statistics; and (4) we derive the optimal chain-of-thought length as\n$k^* = \\Theta(\\sqrt{n}\\log(1/\\varepsilon))$ with explicit constants, providing\na principled approach to reduce inference costs while maintaining performance.\nEmpirical validation on GPT-3 confirms predictions (1)-(3), with transformers\nreaching 99\\% of theoretical entropy limits within 20 examples. Our framework\nprovides practical methods for extracting calibrated uncertainty estimates from\nposition-aware architectures and optimizing computational efficiency in\ndeployment.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u6307\u51fatransformers\u8fdd\u53cd\u8d1d\u53f6\u65af\u66f4\u65b0\u7279\u6027\uff0c\u7ed9\u51fa\u56db\u4e2a\u7406\u8bba\u7ed3\u679c\u5e76\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u5b9e\u7528\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u867d\u53ef\u5efa\u6a21\u4e3a\u9690\u5f0f\u8d1d\u53f6\u65af\u63a8\u7406\uff0c\u4f46transformers\u8fdd\u53cd\u8d1d\u53f6\u65af\u66f4\u65b0\u7684\u9785\u6027\u8d28\uff0c\u6311\u6218\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7406\u8bba\u57fa\u7840\u3002", "method": "\u8fdb\u884c\u7406\u8bba\u5206\u6790\u5f97\u51fa\u56db\u4e2a\u5173\u952e\u7ed3\u679c\uff0c\u5728GPT - 3\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u4e0a\u5f97\u51fa\u4f4d\u7f6e\u7f16\u7801\u5bfc\u81f4\u7684\u9785\u8fdd\u53cd\u7a0b\u5ea6\u7b49\u56db\u4e2a\u7ed3\u679c\uff0c\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u524d\u4e09\u4e2a\u7ed3\u679c\uff0ctransformers\u572820\u4e2a\u793a\u4f8b\u5185\u8fbe\u5230\u7406\u8bba\u71b5\u6781\u9650\u768499%\u3002", "conclusion": "\u6846\u67b6\u63d0\u4f9b\u4ece\u4f4d\u7f6e\u611f\u77e5\u67b6\u6784\u63d0\u53d6\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ca\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.12251", "pdf": "https://arxiv.org/pdf/2507.12251", "abs": "https://arxiv.org/abs/2507.12251", "authors": ["Jiafang Song", "Abhirup Datta"], "title": "Fast Variational Bayes for Large Spatial Data", "categories": ["stat.CO", "stat.ME", "stat.ML"], "comment": null, "summary": "Recent variational Bayes methods for geospatial regression, proposed as an\nalternative to computationally expensive Markov chain Monte Carlo (MCMC)\nsampling, have leveraged Nearest Neighbor Gaussian processes (NNGP) to achieve\nscalability. Yet, these variational methods remain inferior in accuracy and\nspeed compared to spNNGP, the state-of-the-art MCMC-based software for NNGP. We\nintroduce spVarBayes, a suite of fast variational Bayesian approaches for\nlarge-scale geospatial data analysis using NNGP. Our contributions are\nprimarily computational. We replace auto-differentiation with a combination of\ncalculus of variations, closed-form gradient updates, and linear response\ncorrections for improved variance estimation. We also accommodate covariates\n(fixed effects) in the model and offer inference on the variance parameters.\nSimulation experiments demonstrate that we achieve comparable accuracy to\nspNNGP but with reduced computational costs, and considerably outperform\nexisting variational inference methods in terms of both accuracy and speed.\nAnalysis of a large forest canopy height dataset illustrates the practical\nimplementation of proposed methods and shows that the inference results are\nconsistent with those obtained from the MCMC approach. The proposed methods are\nimplemented in publicly available Github R-package spVarBayes.", "AI": {"tldr": "\u63d0\u51faspVarBayes\u7528\u4e8e\u5927\u89c4\u6a21\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u6790\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u7cbe\u5ea6\u548c\u901f\u5ea6\u8868\u73b0\u597d\uff0c\u6709\u516c\u5f00R\u5305\u3002", "motivation": "\u73b0\u6709\u5730\u7406\u7a7a\u95f4\u56de\u5f52\u53d8\u5206\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e0a\u4e0d\u5982\u57fa\u4e8eMCMC\u7684spNNGP\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u7528\u53d8\u5206\u6cd5\u3001\u95ed\u5f0f\u68af\u5ea6\u66f4\u65b0\u548c\u7ebf\u6027\u54cd\u5e94\u6821\u6b63\u66ff\u4ee3\u81ea\u52a8\u5fae\u5206\uff0c\u5728\u6a21\u578b\u4e2d\u8003\u8651\u534f\u53d8\u91cf\u5e76\u5bf9\u65b9\u5dee\u53c2\u6570\u8fdb\u884c\u63a8\u65ad\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\u7cbe\u5ea6\u4e0espNNGP\u76f8\u5f53\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\uff0c\u5728\u7cbe\u5ea6\u548c\u901f\u5ea6\u4e0a\u8fdc\u8d85\u73b0\u6709\u53d8\u5206\u63a8\u7406\u65b9\u6cd5\uff1b\u5927\u68ee\u6797\u51a0\u5c42\u9ad8\u5ea6\u6570\u636e\u96c6\u5206\u6790\u7ed3\u679c\u4e0eMCMC\u65b9\u6cd5\u4e00\u81f4\u3002", "conclusion": "\u63d0\u51fa\u7684spVarBayes\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u5927\u89c4\u6a21\u5730\u7406\u7a7a\u95f4\u6570\u636e\u5206\u6790\uff0c\u4e14\u5df2\u5728R\u5305\u4e2d\u5b9e\u73b0\u3002"}}
{"id": "2507.11883", "pdf": "https://arxiv.org/pdf/2507.11883", "abs": "https://arxiv.org/abs/2507.11883", "authors": ["Yao Zhang", "Indrajit Saha", "Zhaohong Sun", "Makoto Yokoo"], "title": "Coalitions on the Fly in Cooperative Games", "categories": ["cs.GT"], "comment": "Full version with all detailed proofs of ECAI 2025 accepted paper\n  with the same title", "summary": "In this work, we examine a sequential setting of a cooperative game in which\nplayers arrive dynamically to form coalitions and complete tasks either\ntogether or individually, depending on the value created. Upon arrival, a new\nplayer as a decision maker faces two options: forming a new coalition or\njoining an existing one. We assume that players are greedy, i.e., they aim to\nmaximize their rewards based on the information available at their arrival. The\nobjective is to design an online value distribution policy that incentivizes\nplayers to form a coalition structure that maximizes social welfare. We focus\non monotone and bounded cooperative games. Our main result establishes an upper\nbound of $\\frac{3\\mathsf{min}}{\\mathsf{max}}$ on the competitive ratio for any\nirrevocable policy (i.e., one without redistribution), and proposes a policy\nthat achieves a near-optimal competitive ratio of $\\min\\left\\{\\frac{1}{2},\n\\frac{3\\mathsf{min}}{\\mathsf{max}}\\right\\}$, where $\\mathsf{min}$ and\n$\\mathsf{max}$ denote the smallest and largest marginal contribution of any\nsub-coalition of players respectively. Finally, we also consider\nnon-irrevocable policies, with alternative bounds only when the number of\nplayers is limited.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11724", "pdf": "https://arxiv.org/pdf/2507.11724", "abs": "https://arxiv.org/abs/2507.11724", "authors": ["Micha\u0142 Derezi\u0144ski", "Aaron Sidford"], "title": "Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure", "categories": ["cs.DS", "cs.NA", "math.NA", "math.OC", "stat.ML"], "comment": null, "summary": "We provide new high-accuracy randomized algorithms for solving linear systems\nand regression problems that are well-conditioned except for $k$ large singular\nvalues. For solving such $d \\times d$ positive definite system our algorithms\nsucceed whp. and run in time $\\tilde O(d^2 + k^\\omega)$. For solving such\nregression problems in a matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times d}$ our\nmethods succeed whp. and run in time $\\tilde O(\\mathrm{nnz}(\\mathbf{A}) + d^2 +\nk^\\omega)$ where $\\omega$ is the matrix multiplication exponent and\n$\\mathrm{nnz}(\\mathbf{A})$ is the number of non-zeros in $\\mathbf{A}$. Our\nmethods nearly-match a natural complexity limit under dense inputs for these\nproblems and improve upon a trade-off in prior approaches that obtain running\ntimes of either $\\tilde O(d^{2.065}+k^\\omega)$ or $\\tilde O(d^2 +\ndk^{\\omega-1})$ for $d\\times d$ systems. Moreover, we show how to obtain these\nrunning times even under the weaker assumption that all but $k$ of the singular\nvalues have a suitably bounded generalized mean. Consequently, we give the\nfirst nearly-linear time algorithm for computing a multiplicative approximation\nto the nuclear norm of an arbitrary dense matrix. Our algorithms are built on\nthree general recursive preconditioning frameworks, where matrix sketching and\nlow-rank update formulas are carefully tailored to the problems' structure.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u9ad8\u7cbe\u5ea6\u968f\u673a\u7b97\u6cd5\u89e3\u51b3\u7ebf\u6027\u7cfb\u7edf\u548c\u56de\u5f52\u95ee\u9898\uff0c\u7ed9\u51fa\u8fd0\u884c\u65f6\u95f4\uff0c\u6539\u8fdb\u5148\u524d\u65b9\u6cd5\uff0c\u8fd8\u5f97\u5230\u9996\u4e2a\u8fd1\u7ebf\u6027\u65f6\u95f4\u8ba1\u7b97\u4efb\u610f\u7a20\u5bc6\u77e9\u9635\u6838\u8303\u6570\u4e58\u6cd5\u8fd1\u4f3c\u7684\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u9664k\u4e2a\u5927\u5947\u5f02\u503c\u5916\u6761\u4ef6\u826f\u597d\u7684\u7ebf\u6027\u7cfb\u7edf\u548c\u56de\u5f52\u95ee\u9898\u63d0\u4f9b\u65b0\u7684\u9ad8\u7cbe\u5ea6\u968f\u673a\u7b97\u6cd5\uff0c\u6539\u8fdb\u5148\u524d\u65b9\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "method": "\u57fa\u4e8e\u4e09\u4e2a\u901a\u7528\u9012\u5f52\u9884\u6761\u4ef6\u6846\u67b6\uff0c\u5c06\u77e9\u9635\u8349\u56fe\u548c\u4f4e\u79e9\u66f4\u65b0\u516c\u5f0f\u6839\u636e\u95ee\u9898\u7ed3\u6784\u8fdb\u884c\u8c03\u6574\u3002", "result": "\u6c42\u89e3d\u00d7d\u6b63\u5b9a\u7cfb\u7edf\u8fd0\u884c\u65f6\u95f4\u4e3aO~(d^2 + k^\u03c9)\uff0c\u6c42\u89e3\u56de\u5f52\u95ee\u9898\u8fd0\u884c\u65f6\u95f4\u4e3aO~(nnz(A) + d^2 + k^\u03c9)\uff0c\u8fd1\u5339\u914d\u81ea\u7136\u590d\u6742\u5ea6\u6781\u9650\uff0c\u6539\u8fdb\u5148\u524d\u65b9\u6cd5\u7684\u6743\u8861\uff0c\u5f97\u5230\u9996\u4e2a\u8fd1\u7ebf\u6027\u65f6\u95f4\u8ba1\u7b97\u4efb\u610f\u7a20\u5bc6\u77e9\u9635\u6838\u8303\u6570\u4e58\u6cd5\u8fd1\u4f3c\u7684\u7b97\u6cd5\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u5728\u89e3\u51b3\u7279\u5b9a\u7ebf\u6027\u7cfb\u7edf\u548c\u56de\u5f52\u95ee\u9898\u4e0a\u6709\u4f18\u52bf\uff0c\u80fd\u6539\u8fdb\u5148\u524d\u65b9\u6cd5\u7684\u590d\u6742\u5ea6\u3002"}}
{"id": "2507.11870", "pdf": "https://arxiv.org/pdf/2507.11870", "abs": "https://arxiv.org/abs/2507.11870", "authors": ["Vamshi C. Madala", "Nithin Govindarajan", "Shivkumar Chandrasekaran"], "title": "MNO : A Multi-modal Neural Operator for Parametric Nonlinear BVPs", "categories": ["cs.CE"], "comment": null, "summary": "We introduce a novel Multimodal Neural Operator (MNO) architecture designed\nto learn solution operators for multi-parameter nonlinear boundary value\nproblems (BVPs). Traditional neural operators primarily map either the PDE\ncoefficients or source terms independently to the solution, limiting their\nflexibility and applicability. In contrast, our proposed MNO architecture\ngeneralizes these approaches by mapping multiple parameters including PDE\ncoefficients, source terms, and boundary conditions to the solution space in a\nunified manner. Our MNO is motivated by the hierarchical nested bases of the\nFast Multipole Method (FMM) and is constructed systematically through three key\ncomponents: a parameter efficient Generalized FMM (GFMM) block, a Unimodal\nNeural Operator (UNO) built upon GFMM blocks for single parameter mappings, and\nmost importantly, a multimodal fusion mechanism extending these components to\nlearn the joint map. We demonstrate the multimodal generalization capacity of\nour approach on both linear and nonlinear BVPs. Our experiments show that the\nnetwork effectively handles simultaneous variations in PDE coefficients and\nsource or boundary terms.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u795e\u7ecf\u7b97\u5b50\uff08MNO\uff09\u67b6\u6784\u89e3\u51b3\u591a\u53c2\u6570\u975e\u7ebf\u6027\u8fb9\u503c\u95ee\u9898\uff0c\u5c55\u793a\u5176\u591a\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7b97\u5b50\u6620\u5c04\u65b9\u5f0f\u5c40\u9650\uff0c\u7075\u6d3b\u6027\u548c\u9002\u7528\u6027\u4e0d\u8db3\uff0c\u9700\u65b0\u67b6\u6784\u7edf\u4e00\u6620\u5c04\u591a\u53c2\u6570\u3002", "method": "\u53d7\u5feb\u901f\u591a\u6781\u5b50\u65b9\u6cd5\uff08FMM\uff09\u5206\u5c42\u5d4c\u5957\u57fa\u542f\u53d1\uff0c\u6784\u5efa\u542b\u5e7f\u4e49FMM\u5757\u3001\u5355\u6a21\u6001\u795e\u7ecf\u7b97\u5b50\uff08UNO\uff09\u548c\u591a\u6a21\u6001\u878d\u5408\u673a\u5236\u7684MNO\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0c\u7f51\u7edc\u80fd\u6709\u6548\u5904\u7406\u504f\u5fae\u5206\u65b9\u7a0b\u7cfb\u6570\u3001\u6e90\u9879\u6216\u8fb9\u754c\u9879\u7684\u540c\u65f6\u53d8\u5316\u3002", "conclusion": "MNO\u67b6\u6784\u80fd\u5b9e\u73b0\u591a\u53c2\u6570\u7edf\u4e00\u6620\u5c04\uff0c\u5177\u5907\u591a\u6a21\u6001\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.11894", "pdf": "https://arxiv.org/pdf/2507.11894", "abs": "https://arxiv.org/abs/2507.11894", "authors": ["Sara Ghasvarianjahromi", "Yauhen Yakimenka", "J\u00f6rg Kliewer"], "title": "Context-Aware Search and Retrieval Over Erasure Channels", "categories": ["cs.IR", "cs.IT", "math.IT"], "comment": null, "summary": "This paper introduces and analyzes a search and retrieval model that adopts\nkey semantic communication principles from retrieval-augmented generation. We\nspecifically present an information-theoretic analysis of a remote document\nretrieval system operating over a symbol erasure channel. The proposed model\nencodes the feature vector of a query, derived from term-frequency weights of a\nlanguage corpus by using a repetition code with an adaptive rate dependent on\nthe contextual importance of the terms. At the decoder, we select between two\ndocuments based on the contextual closeness of the recovered query. By\nleveraging a jointly Gaussian approximation for both the true and reconstructed\nsimilarity scores, we derive an explicit expression for the retrieval error\nprobability, i.e., the probability under which the less similar document is\nselected. Numerical simulations on synthetic and real-world data (Google NQ)\nconfirm the validity of the analysis. They further demonstrate that assigning\ngreater redundancy to critical features effectively reduces the error rate,\nhighlighting the effectiveness of semantic-aware feature encoding in\nerror-prone communication settings.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u5e76\u5206\u6790\u4e00\u79cd\u641c\u7d22\u4e0e\u68c0\u7d22\u6a21\u578b\uff0c\u5bf9\u8fdc\u7a0b\u6587\u6863\u68c0\u7d22\u7cfb\u7edf\u505a\u4fe1\u606f\u8bba\u5206\u6790\uff0c\u63a8\u5bfc\u68c0\u7d22\u9519\u8bef\u6982\u7387\u8868\u8fbe\u5f0f\uff0c\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u5206\u6790\u5e76\u8868\u660e\u8bed\u4e49\u611f\u77e5\u7279\u5f81\u7f16\u7801\u6709\u6548\u3002", "motivation": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u5173\u952e\u8bed\u4e49\u901a\u4fe1\u539f\u5219\uff0c\u5bf9\u8fdc\u7a0b\u6587\u6863\u68c0\u7d22\u7cfb\u7edf\u8fdb\u884c\u4fe1\u606f\u8bba\u5206\u6790\u3002", "method": "\u7528\u4f9d\u8d56\u4e8e\u672f\u8bed\u4e0a\u4e0b\u6587\u91cd\u8981\u6027\u7684\u81ea\u9002\u5e94\u901f\u7387\u91cd\u590d\u7801\u5bf9\u67e5\u8be2\u7279\u5f81\u5411\u91cf\u7f16\u7801\uff0c\u5728\u89e3\u7801\u5668\u6839\u636e\u6062\u590d\u67e5\u8be2\u7684\u4e0a\u4e0b\u6587\u63a5\u8fd1\u5ea6\u9009\u62e9\u6587\u6863\uff0c\u5229\u7528\u8054\u5408\u9ad8\u65af\u8fd1\u4f3c\u63a8\u5bfc\u68c0\u7d22\u9519\u8bef\u6982\u7387\u3002", "result": "\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u5206\u6790\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u7ed9\u5173\u952e\u7279\u5f81\u5206\u914d\u66f4\u591a\u5197\u4f59\u80fd\u964d\u4f4e\u9519\u8bef\u7387\u3002", "conclusion": "\u8bed\u4e49\u611f\u77e5\u7279\u5f81\u7f16\u7801\u5728\u6613\u51fa\u9519\u901a\u4fe1\u73af\u5883\u4e2d\u6709\u6548\u3002"}}
{"id": "2507.11560", "pdf": "https://arxiv.org/pdf/2507.11560", "abs": "https://arxiv.org/abs/2507.11560", "authors": ["Xin Wang", "Xiao Huan Li", "Xun Wang"], "title": "A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing", "categories": ["cs.DC", "cs.AI"], "comment": "6 pages, 4 figures, accepted by ICCC 2025", "summary": "The integration of the Industrial Internet of Things (IIoT) with Artificial\nIntelligence-Generated Content (AIGC) offers new opportunities for smart\nmanufacturing, but it also introduces challenges related to\ncomputation-intensive tasks and low-latency demands. Traditional generative\nmodels based on cloud computing are difficult to meet the real-time\nrequirements of AIGC tasks in IIoT environments, and edge computing can\neffectively reduce latency through task offloading. However, the dynamic nature\nof AIGC tasks, model switching delays, and resource constraints impose higher\ndemands on edge computing environments. To address these challenges, this paper\nproposes an AIGC task offloading framework tailored for IIoT edge computing\nenvironments, considering the latency and energy consumption caused by AIGC\nmodel switching for the first time. IIoT devices acted as multi-agent\ncollaboratively offload their dynamic AIGC tasks to the most appropriate edge\nservers deployed with different generative models. A model aware AIGC task\noffloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient\n(MADDPG-MATO) is devised to minimize the latency and energy. Experimental\nresults show that MADDPG-MATO outperforms baseline algorithms, achieving an\naverage reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72%\nincrease in task completion rate across four sets of experiments with model\nnumbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is\nrobust and efficient in dynamic, high-load IIoT environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9002\u7528\u4e8e\u5de5\u4e1a\u7269\u8054\u7f51\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u7684AIGC\u4efb\u52a1\u5378\u8f7d\u6846\u67b6\u548cMADDPG - MATO\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u964d\u4f4e\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u7387\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5de5\u4e1a\u7269\u8054\u7f51\u4e0eAIGC\u96c6\u6210\u9762\u4e34\u8ba1\u7b97\u5bc6\u96c6\u548c\u4f4e\u5ef6\u8fdf\u6311\u6218\uff0c\u4f20\u7edf\u4e91\u8ba1\u7b97\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u9700\u6c42\uff0c\u8fb9\u7f18\u8ba1\u7b97\u9762\u4e34\u4efb\u52a1\u52a8\u6001\u6027\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faAIGC\u4efb\u52a1\u5378\u8f7d\u6846\u67b6\uff0c\u8bbe\u5907\u4f5c\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5378\u8f7d\u4efb\u52a1\u5230\u5408\u9002\u8fb9\u7f18\u670d\u52a1\u5668\uff0c\u8bbe\u8ba1\u57fa\u4e8eMADDPG - MATO\u7684\u4efb\u52a1\u5378\u8f7d\u7b97\u6cd5\u3002", "result": "MADDPG - MATO\u7b97\u6cd5\u5728\u56db\u7ec4\u5b9e\u9a8c\u4e2d\uff0c\u5ef6\u8fdf\u5e73\u5747\u964d\u4f4e6.98%\uff0c\u80fd\u8017\u964d\u4f4e7.12%\uff0c\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u9ad83.72%\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u52a8\u6001\u3001\u9ad8\u8d1f\u8f7d\u5de5\u4e1a\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7a33\u5065\u4e14\u9ad8\u6548\u3002"}}
{"id": "2507.11751", "pdf": "https://arxiv.org/pdf/2507.11751", "abs": "https://arxiv.org/abs/2507.11751", "authors": ["Chandrashekar Muniyappa", "Eunjin Kim"], "title": "Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity", "categories": ["cs.NE", "cs.AI", "68-68W50"], "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "summary": "Identifying similar documents within extensive volumes of data poses a\nsignificant challenge. To tackle this issue, researchers have developed a\nvariety of effective distributed computing techniques. With the advancement of\ncomputing power and the rise of big data, deep neural networks and evolutionary\ncomputing algorithms such as genetic algorithms and differential evolution\nalgorithms have achieved greater success. This survey will explore the most\nrecent advancements in the search for documents based on their semantic text\nsimilarity, focusing on genetic and differential evolutionary computing\nalgorithms.", "AI": {"tldr": "\u63a2\u8ba8\u57fa\u4e8e\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u5ea6\u641c\u7d22\u6587\u6863\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u805a\u7126\u9057\u4f20\u548c\u5dee\u5206\u8fdb\u5316\u8ba1\u7b97\u7b97\u6cd5\u3002", "motivation": "\u8bc6\u522b\u5927\u91cf\u6570\u636e\u4e2d\u7684\u76f8\u4f3c\u6587\u6863\u662f\u91cd\u5927\u6311\u6218\uff0c\u9700\u6709\u6548\u65b9\u6cd5\u5e94\u5bf9\u3002", "method": "\u805a\u7126\u9057\u4f20\u548c\u5dee\u5206\u8fdb\u5316\u8ba1\u7b97\u7b97\u6cd5\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2507.12281", "pdf": "https://arxiv.org/pdf/2507.12281", "abs": "https://arxiv.org/abs/2507.12281", "authors": ["Filippo Marchesani", "Francesca Masciarelli", "Andrea Bikfalvi"], "title": "International promotion patterns in the smart city literature: Exploring the role of geography in affecting local drivers and smart cities' outcomes", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "The rise of smart cities represents a significant trend in urban development.\nHowever, only in recent years has attention shifted toward the international\npromotion of these cities. Despite ongoing academic discussions on the impact\nof smart city development on urban environments, the global recognition of\nsmart cities remains uncertain due to their multidisciplinary nature. To\naddress this, we conducted a systematic literature review of articles published\nin top-tier peer-reviewed journals from 2008 to December 2021, offering a\ncomprehensive analysis of the existing literature.", "AI": {"tldr": "\u5bf92008 - 2021\u5e74\u9876\u7ea7\u540c\u884c\u8bc4\u5ba1\u671f\u520a\u6587\u7ae0\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u667a\u6167\u57ce\u5e02\u73b0\u6709\u6587\u732e\u3002", "motivation": "\u667a\u6167\u57ce\u5e02\u867d\u5174\u8d77\u4f46\u56fd\u9645\u63a8\u5e7f\u53d7\u5173\u6ce8\u665a\uff0c\u5176\u591a\u5b66\u79d1\u6027\u8d28\u5bfc\u81f4\u5168\u7403\u8ba4\u53ef\u5ea6\u4e0d\u786e\u5b9a\uff0c\u9700\u7814\u7a76\u3002", "method": "\u5bf92008\u5e74\u81f32021\u5e7412\u6708\u53d1\u8868\u5728\u9876\u7ea7\u540c\u884c\u8bc4\u5ba1\u671f\u520a\u4e0a\u7684\u6587\u7ae0\u8fdb\u884c\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2507.11633", "pdf": "https://arxiv.org/pdf/2507.11633", "abs": "https://arxiv.org/abs/2507.11633", "authors": ["Yuxuan Zhang", "Haoyang Yu", "Lanxiang Hu", "Haojian Jin", "Hao Zhang"], "title": "General Modular Harness for LLM Agents in Multi-Turn Gaming Environments", "categories": ["cs.AI"], "comment": "8 pages, ICML MAS workshop", "summary": "We introduce a modular harness design for LLM agents that composes of\nperception, memory, and reasoning components, enabling a single LLM or VLM\nbackbone to tackle a wide spectrum of multi turn gaming environments without\ndomain-specific engineering. Using classic and modern game suites as\nlow-barrier, high-diversity testbeds, our framework provides a unified workflow\nfor analyzing how each module affects performance across dynamic interactive\nsettings. Extensive experiments demonstrate that the harness lifts gameplay\nperformance consistently over un-harnessed baselines and reveals distinct\ncontribution patterns, for example, memory dominates in long-horizon puzzles\nwhile perception is critical in vision noisy arcades. These findings highlight\nthe effectiveness of our modular harness design in advancing general-purpose\nagent, given the familiarity and ubiquity of games in everyday human\nexperience.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u667a\u80fd\u4f53\u7684\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5728\u591a\u8f6e\u6e38\u620f\u73af\u5883\u6d4b\u8bd5\u6548\u679c\u597d\uff0c\u63ed\u793a\u5404\u6a21\u5757\u8d21\u732e\u6a21\u5f0f\u3002", "motivation": "\u4f7f\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u6216\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u9aa8\u5e72\u65e0\u9700\u7279\u5b9a\u9886\u57df\u5de5\u7a0b\u5c31\u80fd\u5904\u7406\u5e7f\u6cdb\u7684\u591a\u8f6e\u6e38\u620f\u73af\u5883\uff0c\u63a8\u52a8\u901a\u7528\u667a\u80fd\u4f53\u53d1\u5c55\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u611f\u77e5\u3001\u8bb0\u5fc6\u548c\u63a8\u7406\u7ec4\u4ef6\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u7ecf\u5178\u548c\u73b0\u4ee3\u6e38\u620f\u5957\u4ef6\u4f5c\u4e3a\u6d4b\u8bd5\u5e73\u53f0\u5206\u6790\u5404\u6a21\u5757\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u5757\u5316\u6846\u67b6\u6301\u7eed\u63d0\u5347\u6e38\u620f\u6027\u80fd\uff0c\u63ed\u793a\u4e0d\u540c\u6e38\u620f\u4e2d\u5404\u6a21\u5757\u4e0d\u540c\u8d21\u732e\u6a21\u5f0f\uff0c\u5982\u8bb0\u5fc6\u5728\u957f\u89c6\u91ce\u8c1c\u9898\u4e2d\u5360\u4e3b\u5bfc\uff0c\u611f\u77e5\u5728\u89c6\u89c9\u5608\u6742\u7684\u8857\u673a\u6e38\u620f\u4e2d\u5173\u952e\u3002", "conclusion": "\u6a21\u5757\u5316\u8bbe\u8ba1\u5728\u63a8\u52a8\u901a\u7528\u667a\u80fd\u4f53\u65b9\u9762\u6709\u6548\u3002"}}
{"id": "2507.11687", "pdf": "https://arxiv.org/pdf/2507.11687", "abs": "https://arxiv.org/abs/2507.11687", "authors": ["Atharva Naik", "Lawanya Baghel", "Dhakshin Govindarajan", "Darsh Agrawal", "Daniel Fried", "Carolyn Rose"], "title": "MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models, though successful in code generation, struggle with\ncode quality analysis because they are limited by static training data and\ncan't easily adapt to evolving best practices. We introduce MetaLint, a new\ninstruction-following framework that formulates code quality analysis as the\ntask of detecting and fixing problematic semantic code fragments or code idioms\nbased on high-level specifications. Unlike conventional approaches that train\nmodels on static, rule-based data, MetaLint employs instruction tuning on\nsynthetic linter-generated data to support easy-to-hard generalization,\nenabling models to adapt to novel or complex code patterns without retraining.\nTo evaluate this, we construct a benchmark of challenging idioms inspired by\nreal-world coding standards such as Python Enhancement Proposals (PEPs) and\nassess whether MetaLint-trained models reason adaptively or simply memorize.\nOur results show that MetaLint improves generalization to unseen PEP idioms,\nachieving a 70.37% F-score on idiom detection with the highest recall (70.43%)\namong all evaluated models. It also achieves 26.73% on localization,\ncompetitive for its 4B parameter size and comparable to larger state-of-the-art\nmodels like o3-mini, highlighting its potential for future-proof code quality\nanalysis.", "AI": {"tldr": "\u5f15\u5165MetaLint\u6846\u67b6\u7528\u4e8e\u4ee3\u7801\u8d28\u91cf\u5206\u6790\uff0c\u80fd\u9002\u5e94\u65b0\u4ee3\u7801\u6a21\u5f0f\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u8d28\u91cf\u5206\u6790\u4e0a\u53d7\u9650\u4e8e\u9759\u6001\u8bad\u7ec3\u6570\u636e\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d1\u5c55\u7684\u6700\u4f73\u5b9e\u8df5\u3002", "method": "\u5f15\u5165MetaLint\u6846\u67b6\uff0c\u91c7\u7528\u6307\u4ee4\u8c03\u4f18\u5408\u6210\u7684\u4ee3\u7801\u68c0\u67e5\u5668\u751f\u6210\u7684\u6570\u636e\uff0c\u6784\u5efa\u6311\u6218\u6027\u4e60\u8bed\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "MetaLint\u63d0\u9ad8\u4e86\u5bf9\u672a\u89c1PEP\u4e60\u8bed\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e60\u8bed\u68c0\u6d4bF\u5206\u6570\u8fbe70.37%\uff0c\u53ec\u56de\u7387\u6700\u9ad8\uff0c\u5b9a\u4f4d\u7387\u8fbe26.73%\u3002", "conclusion": "MetaLint\u5728\u4ee3\u7801\u8d28\u91cf\u5206\u6790\u4e0a\u6709\u9002\u5e94\u672a\u6765\u53d8\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.11570", "pdf": "https://arxiv.org/pdf/2507.11570", "abs": "https://arxiv.org/abs/2507.11570", "authors": ["Ha Na Cho", "Sairam Sutari", "Alexander Lopez", "Hansen Bow", "Kai Zheng"], "title": "SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Objective: To develop and evaluate machine learning (ML) models for\npredicting length of stay (LOS) in elective spine surgery, with a focus on the\nbenefits of temporal modeling and model interpretability. Materials and\nMethods: We compared traditional ML models (e.g., linear regression, random\nforest, support vector machine (SVM), and XGBoost) with our developed model,\nSurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an\nattention, using structured perioperative electronic health records (EHR) data.\nPerformance was evaluated using the coefficient of determination (R2), and key\npredictors were identified using explainable AI. Results: SurgeryLSTM achieved\nthe highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)\nand baseline models. The attention mechanism improved interpretability by\ndynamically identifying influential temporal segments within preoperative\nclinical sequences, allowing clinicians to trace which events or features most\ncontributed to each LOS prediction. Key predictors of LOS included bone\ndisorder, chronic kidney disease, and lumbar fusion identified as the most\nimpactful predictors of LOS. Discussion: Temporal modeling with attention\nmechanisms significantly improves LOS prediction by capturing the sequential\nnature of patient data. Unlike static models, SurgeryLSTM provides both higher\naccuracy and greater interpretability, which are critical for clinical\nadoption. These results highlight the potential of integrating attention-based\ntemporal models into hospital planning workflows. Conclusion: SurgeryLSTM\npresents an effective and interpretable AI solution for LOS prediction in\nelective spine surgery. Our findings support the integration of temporal,\nexplainable ML approaches into clinical decision support systems to enhance\ndischarge readiness and individualized patient care.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1SurgeryLSTM\u6a21\u578b\u9884\u6d4b\u62e9\u671f\u810a\u67f1\u624b\u672f\u4f4f\u9662\u65f6\u957f\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u5177\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u5c06\u6a21\u578b\u96c6\u6210\u5230\u4e34\u5e8a\u51b3\u7b56\u7cfb\u7edf\u3002", "motivation": "\u5f00\u53d1\u5e76\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u62e9\u671f\u810a\u67f1\u624b\u672f\u4f4f\u9662\u65f6\u957f\uff0c\u5173\u6ce8\u65f6\u95f4\u5efa\u6a21\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u4f18\u52bf\u3002", "method": "\u5bf9\u6bd4\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548cSurgeryLSTM\u6a21\u578b\uff0c\u7528\u51b3\u5b9a\u7cfb\u6570\u8bc4\u4f30\u6027\u80fd\uff0c\u7528\u53ef\u89e3\u91caAI\u8bc6\u522b\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u3002", "result": "SurgeryLSTM\u9884\u6d4b\u51c6\u786e\u7387\u6700\u9ad8\uff0c\u6ce8\u610f\u529b\u673a\u5236\u63d0\u5347\u53ef\u89e3\u91ca\u6027\uff0c\u8bc6\u522b\u51fa\u9aa8\u75be\u75c5\u3001\u6162\u6027\u80be\u75c5\u548c\u8170\u690e\u878d\u5408\u662f\u4f4f\u9662\u65f6\u957f\u7684\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u3002", "conclusion": "SurgeryLSTM\u662f\u6709\u6548\u7684\u53ef\u89e3\u91caAI\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u5c06\u65f6\u95f4\u53ef\u89e3\u91ca\u7684ML\u65b9\u6cd5\u96c6\u6210\u5230\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2507.11891", "pdf": "https://arxiv.org/pdf/2507.11891", "abs": "https://arxiv.org/abs/2507.11891", "authors": ["Shuangning Li", "Chonghuan Wang", "Jingyan Wang"], "title": "Choosing the Better Bandit Algorithm under Data Sharing: When Do A/B Experiments Work?", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We study A/B experiments that are designed to compare the performance of two\nrecommendation algorithms. Prior work has shown that the standard\ndifference-in-means estimator is biased in estimating the global treatment\neffect (GTE) due to a particular form of interference between experimental\nunits. Specifically, units under the treatment and control algorithms\ncontribute to a shared pool of data that subsequently train both algorithms,\nresulting in interference between the two groups. The bias arising from this\ntype of data sharing is known as \"symbiosis bias\". In this paper, we highlight\nthat, for decision-making purposes, the sign of the GTE often matters more than\nits precise magnitude when selecting the better algorithm. We formalize this\ninsight under a multi-armed bandit framework and theoretically characterize\nwhen the sign of the expected GTE estimate under data sharing aligns with or\ncontradicts the sign of the true GTE. Our analysis identifies the level of\nexploration versus exploitation as a key determinant of how symbiosis bias\nimpacts algorithm selection.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e24\u79cd\u63a8\u8350\u7b97\u6cd5\u7684A/B\u5b9e\u9a8c\uff0c\u6307\u51fa\u6807\u51c6\u5747\u503c\u5dee\u4f30\u8ba1\u5668\u6709\u5171\u751f\u504f\u5dee\uff0c\u5206\u6790\u6570\u636e\u5171\u4eab\u4e0bGTE\u4f30\u8ba1\u7b26\u53f7\u4e0e\u771f\u5b9eGTE\u7b26\u53f7\u7684\u5173\u7cfb\u53ca\u5bf9\u7b97\u6cd5\u9009\u62e9\u7684\u5f71\u54cd\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u8868\u660e\u6807\u51c6\u5747\u503c\u5dee\u4f30\u8ba1\u5668\u5728\u4f30\u8ba1\u5168\u5c40\u5904\u7406\u6548\u5e94\uff08GTE\uff09\u65f6\u6709\u504f\u5dee\uff0c\u672c\u6587\u4e3a\u5728\u51b3\u7b56\u65f6\u66f4\u597d\u5730\u9009\u62e9\u7b97\u6cd5\uff0c\u5173\u6ce8GTE\u7b26\u53f7\u800c\u975e\u7cbe\u786e\u503c\u3002", "method": "\u5728\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\u4e0b\u5f62\u5f0f\u5316\u8be5\u89c2\u70b9\uff0c\u4ece\u7406\u8bba\u4e0a\u523b\u753b\u6570\u636e\u5171\u4eab\u4e0b\u9884\u671fGTE\u4f30\u8ba1\u7b26\u53f7\u4e0e\u771f\u5b9eGTE\u7b26\u53f7\u4e00\u81f4\u6216\u77db\u76fe\u7684\u60c5\u51b5\u3002", "result": "\u5206\u6790\u786e\u5b9a\u4e86\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u6c34\u5e73\u662f\u5171\u751f\u504f\u5dee\u5f71\u54cd\u7b97\u6cd5\u9009\u62e9\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\u3002", "conclusion": "\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u6c34\u5e73\u5bf9\u5171\u751f\u504f\u5dee\u5f71\u54cd\u7b97\u6cd5\u9009\u62e9\u8d77\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2507.12358", "pdf": "https://arxiv.org/pdf/2507.12358", "abs": "https://arxiv.org/abs/2507.12358", "authors": ["S. Marelli", "S. Sch\u00e4r", "B. Sudret"], "title": "Surrogate modeling for uncertainty quantification in nonlinear dynamics", "categories": ["stat.CO", "stat.AP", "stat.ML"], "comment": null, "summary": "Predicting the behavior of complex systems in engineering often involves\nsignificant uncertainty about operating conditions, such as external loads,\nenvironmental effects, and manufacturing variability. As a result, uncertainty\nquantification (UQ) has become a critical tool in modeling-based engineering,\nproviding methods to identify, characterize, and propagate uncertainty through\ncomputational models. However, the stochastic nature of UQ typically requires\nnumerous evaluations of these models, which can be computationally expensive\nand limit the scope of feasible analyses. To address this, surrogate models,\ni.e., efficient functional approximations trained on a limited set of\nsimulations, have become central in modern UQ practice. This book chapter\npresents a concise review of surrogate modeling techniques for UQ, with a focus\non the particularly challenging task of capturing the full time-dependent\nresponse of dynamical systems. It introduces a classification of time-dependent\nproblems based on the complexity of input excitation and discusses\ncorresponding surrogate approaches, including combinations of principal\ncomponent analysis with polynomial chaos expansions, time warping techniques,\nand nonlinear autoregressive models with exogenous inputs (NARX models). Each\nmethod is illustrated with simple application examples to clarify the\nunderlying ideas and practical use.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u7528\u4e8e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u7684\u4ee3\u7406\u5efa\u6a21\u6280\u672f\uff0c\u805a\u7126\u4e8e\u6355\u6349\u52a8\u6001\u7cfb\u7edf\u5168\u65f6\u53d8\u54cd\u5e94\uff0c\u4ecb\u7ecd\u65f6\u53d8\u95ee\u9898\u5206\u7c7b\u53ca\u5bf9\u5e94\u4ee3\u7406\u65b9\u6cd5\u5e76\u4e3e\u4f8b\u8bf4\u660e\u3002", "motivation": "\u5de5\u7a0b\u4e2d\u590d\u6742\u7cfb\u7edf\u884c\u4e3a\u9884\u6d4b\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0cUQ\u867d\u91cd\u8981\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u8981\u4ee3\u7406\u6a21\u578b\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5bf9\u65f6\u53d8\u95ee\u9898\u57fa\u4e8e\u8f93\u5165\u6fc0\u52b1\u590d\u6742\u5ea6\u8fdb\u884c\u5206\u7c7b\uff0c\u8ba8\u8bba\u4e3b\u6210\u5206\u5206\u6790\u4e0e\u591a\u9879\u5f0f\u6df7\u6c8c\u5c55\u5f00\u7ed3\u5408\u3001\u65f6\u95f4\u626d\u66f2\u6280\u672f\u3001\u5e26\u5916\u90e8\u8f93\u5165\u7684\u975e\u7ebf\u6027\u81ea\u56de\u5f52\u6a21\u578b\uff08NARX\u6a21\u578b\uff09\u7b49\u4ee3\u7406\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u5e94\u7528\u793a\u4f8b\u8bf4\u660e\u3002", "result": "\u7ed9\u51fa\u4e86\u7528\u4e8eUQ\u7684\u4ee3\u7406\u5efa\u6a21\u6280\u672f\u7684\u7efc\u8ff0\uff0c\u660e\u786e\u4e86\u4e0d\u540c\u65f6\u53d8\u95ee\u9898\u5bf9\u5e94\u7684\u4ee3\u7406\u65b9\u6cd5\u3002", "conclusion": "\u4ee3\u7406\u6a21\u578b\u5728\u73b0\u4ee3UQ\u5b9e\u8df5\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4e0d\u540c\u7684\u4ee3\u7406\u65b9\u6cd5\u9002\u7528\u4e8e\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u65f6\u53d8\u95ee\u9898\u3002"}}
{"id": "2507.12054", "pdf": "https://arxiv.org/pdf/2507.12054", "abs": "https://arxiv.org/abs/2507.12054", "authors": ["Tian Bai", "Yiding Feng", "Yaohao Liu", "Mengfan Ma", "Mingyu Xiao"], "title": "Contracting with a Mechanism Designer", "categories": ["cs.GT"], "comment": null, "summary": "This paper explores the economic interactions within modern crowdsourcing\nmarkets. In these markets, employers issue requests for tasks, platforms\nfacilitate the recruitment of crowd workers, and workers complete tasks for\nmonetary rewards. Recognizing that these roles serve distinct functions within\nthe ecosystem, we introduce a three-party model that distinguishes among the\nprincipal (the requester), the intermediary (the platform), and the pool of\nagents (the workers). The principal, unable to directly engage with agents,\nrelies on the intermediary to recruit and incentivize them. This interaction\nunfolds in two stages: first, the principal designs a profit-sharing contract\nwith the intermediary; second, the intermediary implements a mechanism to\nselect an agent to complete the delegated task.\n  We analyze the proposed model as an extensive-form Stackelberg game. Our\ncontributions are fourfold: (1) We fully characterize the subgame perfect\nequilibrium. In particular, we reduce the principal's contract design problem\nto a novel auction-theoretic formulation we term virtual value pricing, and\nreveals that linear contracts are optimal even when the task have multiple\noutcomes and agents' cost distributions are asymmetric. (2) To quantify the\nprincipal's utility loss from delegation and information asymmetry, we\nintroduce the price of double marginalization (PoDM) and the classical price of\nanarchy (PoA), and derive tight or nearly tight bounds on both ratios under\nregular and monotone hazard rate (MHR) distributions. (3) We further examine\nthese two ratios in a natural setting where the intermediary is restricted to\nanonymous pricing mechanisms, and show that similar qualitative insights\ncontinue to hold. (4) Finally, we extend our results on both ratios to a robust\nframework that accommodates scenarios in which the principal lacks precise\ninformation about the market size.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u73b0\u4ee3\u4f17\u5305\u5e02\u573a\u7684\u7ecf\u6d4e\u4e92\u52a8\uff0c\u63d0\u51fa\u4e09\u65b9\u6a21\u578b\u5e76\u4ee5Stackelberg\u535a\u5f08\u5206\u6790\uff0c\u6709\u56db\u65b9\u9762\u8d21\u732e\uff0c\u5305\u62ec\u523b\u753b\u5747\u8861\u3001\u5f15\u5165\u8861\u91cf\u6307\u6807\u53ca\u62d3\u5c55\u7ed3\u679c\u7b49\u3002", "motivation": "\u63a2\u7d22\u73b0\u4ee3\u4f17\u5305\u5e02\u573a\u4e2d\u96c7\u4e3b\u3001\u5e73\u53f0\u548c\u5de5\u4eba\u4e4b\u95f4\u7684\u7ecf\u6d4e\u4e92\u52a8\u5173\u7cfb\u3002", "method": "\u5f15\u5165\u4e09\u65b9\u6a21\u578b\uff0c\u5c06\u5176\u5206\u6790\u4e3a\u6269\u5c55\u5f62\u5f0f\u7684Stackelberg\u535a\u5f08\u3002", "result": "\u523b\u753b\u5b50\u535a\u5f08\u5b8c\u7f8e\u5747\u8861\uff0c\u5f15\u5165\u4ef7\u683c\u6307\u6807\u5e76\u63a8\u5bfc\u5176\u8fb9\u754c\uff0c\u5728\u533f\u540d\u5b9a\u4ef7\u673a\u5236\u548c\u4fe1\u606f\u4e0d\u7cbe\u786e\u573a\u666f\u4e0b\u6709\u76f8\u5173\u7ed3\u8bba\u3002", "conclusion": "\u6a21\u578b\u80fd\u6709\u6548\u5206\u6790\u4f17\u5305\u5e02\u573a\u7ecf\u6d4e\u4e92\u52a8\uff0c\u76f8\u5173\u6307\u6807\u53ca\u7ed3\u8bba\u5728\u4e0d\u540c\u573a\u666f\u6709\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2507.12047", "pdf": "https://arxiv.org/pdf/2507.12047", "abs": "https://arxiv.org/abs/2507.12047", "authors": ["Michal Dvo\u0159\u00e1k", "Du\u0161an Knop", "Michal Opler", "Jan Pokorn\u00fd", "Ond\u0159ej Such\u00fd", "Krisztina Szil\u00e1gyi"], "title": "Pathfinding in Self-Deleting Graphs", "categories": ["cs.DS"], "comment": null, "summary": "In this paper, we study the problem of pathfinding on traversal-dependent\ngraphs, i.e., graphs whose edges change depending on the previously visited\nvertices. In particular, we study \\emph{self-deleting graphs}, introduced by\nCarmesin et al. (Sarah Carmesin, David Woller, David Parker, Miroslav Kulich,\nand Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson\nproblems with traversal-dependent edge deletion. J. Comput. Sci.), which\nconsist of a graph $G=(V, E)$ and a function $f\\colon V\\rightarrow 2^E$, where\n$f(v)$ is the set of edges that will be deleted after visiting the vertex $v$.\nIn the \\textsc{(Shortest) Self-Deleting $s$-$t$-path} problem we are given a\nself-deleting graph and its vertices $s$ and $t$, and we are asked to find a\n(shortest) path from $s$ to $t$, such that it does not traverse an edge in\n$f(v)$ after visiting $v$ for any vertex $v$.\n  We prove that \\textsc{Self-Deleting $s$-$t$-path} is NP-hard even if the\ngiven graph is outerplanar, bipartite, has maximum degree $3$, bandwidth $2$\nand $|f(v)|\\leq 1$ for each vertex $v$. We show that \\textsc{Shortest\nSelf-Deleting $s$-$t$-path} is W[1]-complete parameterized by the length of the\nsought path and that \\textsc{Self-Deleting $s$-$t$-path} is \\W{1}-complete\nparameterized by the vertex cover number, feedback vertex set number and\ntreedepth. We also show that the problem becomes FPT when we parameterize by\nthe maximum size of $f(v)$ and several structural parameters. Lastly, we show\nthat the problem does not admit a polynomial kernel even for parameterization\nby the vertex cover number and the maximum size of $f(v)$ combined already on\n2-outerplanar graphs.", "AI": {"tldr": "\u7814\u7a76\u904d\u5386\u4f9d\u8d56\u56fe\u4e0a\u7684\u8def\u5f84\u67e5\u627e\u95ee\u9898\uff0c\u8bc1\u660e\u81ea\u5220\u9664s - t\u8def\u5f84\u95ee\u9898\u7684\u590d\u6742\u5ea6\u53ca\u53c2\u6570\u5316\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u904d\u5386\u4f9d\u8d56\u56fe\uff08\u5982\u81ea\u5220\u9664\u56fe\uff09\u4e0a\u7684\u8def\u5f84\u67e5\u627e\u95ee\u9898\uff0c\u5305\u62ec\u6700\u77ed\u81ea\u5220\u9664s - t\u8def\u5f84\u95ee\u9898\u3002", "method": "\u7406\u8bba\u8bc1\u660e\uff0c\u5206\u6790\u81ea\u5220\u9664s - t\u8def\u5f84\u95ee\u9898\u5728\u4e0d\u540c\u56fe\u7ed3\u6784\u548c\u53c2\u6570\u5316\u6761\u4ef6\u4e0b\u7684\u590d\u6742\u5ea6\u3002", "result": "\u8bc1\u660e\u81ea\u5220\u9664s - t\u8def\u5f84\u95ee\u9898\u5728\u7279\u5b9a\u56fe\u6761\u4ef6\u4e0bNP - \u96be\uff0c\u6700\u77ed\u81ea\u5220\u9664s - t\u8def\u5f84\u95ee\u9898\u5728\u67d0\u4e9b\u53c2\u6570\u5316\u4e0bW[1] - \u5b8c\u5168\uff0c\u90e8\u5206\u53c2\u6570\u5316\u4e0b\u4e3aFPT\uff0c\u4e14\u5728\u7279\u5b9a\u53c2\u6570\u5316\u548c\u56fe\u7ed3\u6784\u4e0b\u65e0\u591a\u9879\u5f0f\u6838\u3002", "conclusion": "\u660e\u786e\u4e86\u81ea\u5220\u9664s - t\u8def\u5f84\u95ee\u9898\u5728\u4e0d\u540c\u56fe\u548c\u53c2\u6570\u6761\u4ef6\u4e0b\u7684\u590d\u6742\u5ea6\u7279\u6027\u3002"}}
{"id": "2507.12233", "pdf": "https://arxiv.org/pdf/2507.12233", "abs": "https://arxiv.org/abs/2507.12233", "authors": ["Binh Huy Nguyen", "Matti Schneider"], "title": "Universal Fourier Neural Operators for Micromechanics", "categories": ["cs.CE", "cs.LG"], "comment": "48 pages, 13 figures", "summary": "\\noindent Solving cell problems in homogenization is hard, and available\ndeep-learning frameworks fail to match the speed and generality of traditional\ncomputational frameworks. More to the point, it is generally unclear what to\nexpect of machine-learning approaches, let alone single out which approaches\nare promising. In the work at hand, we advocate Fourier Neural Operators (FNOs)\nfor micromechanics, empowering them by insights from computational\nmicromechanics methods based on the fast Fourier transform (FFT). We construct\nan FNO surrogate mimicking the basic scheme foundational for FFT-based methods\nand show that the resulting operator predicts solutions to cell problems with\n\\emph{arbitrary} stiffness distribution only subject to a material-contrast\nconstraint up to a desired accuracy. In particular, there are no restrictions\non the material symmetry like isotropy, on the number of phases and on the\ngeometry of the interfaces between materials. Also, the provided fidelity is\nsharp and uniform, providing explicit guarantees leveraging our physical\nempowerment of FNOs. To show the desired universal approximation property, we\nconstruct an FNO explicitly that requires no training to begin with. Still, the\nobtained neural operator complies with the same memory requirements as the\nbasic scheme and comes with runtimes proportional to classical FFT solvers. In\nparticular, large-scale problems with more than 100 million voxels are readily\nhandled. The goal of this work is to underline the potential of FNOs for\nsolving micromechanical problems, linking FFT-based methods to FNOs. This\nconnection is expected to provide a fruitful exchange between both worlds.", "AI": {"tldr": "\u672c\u6587\u5021\u5bfc\u5c06\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08FNOs\uff09\u7528\u4e8e\u5fae\u89c2\u529b\u5b66\uff0c\u7ed3\u5408\u57fa\u4e8e\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\u7684\u8ba1\u7b97\u5fae\u89c2\u529b\u5b66\u65b9\u6cd5\uff0c\u5c55\u793aFNOs\u89e3\u51b3\u5fae\u89c2\u529b\u5b66\u95ee\u9898\u7684\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u5747\u5300\u5316\u4e2d\u7684\u7ec6\u80de\u95ee\u9898\u56f0\u96be\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5728\u901f\u5ea6\u548c\u901a\u7528\u6027\u4e0a\u4e0d\u5982\u4f20\u7edf\u8ba1\u7b97\u6846\u67b6\uff0c\u4e14\u4e0d\u6e05\u695a\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u6548\u679c\u548c\u524d\u666f\u3002", "method": "\u6784\u5efaFNO\u66ff\u4ee3\u6a21\u578b\uff0c\u6a21\u4eff\u57fa\u4e8eFFT\u65b9\u6cd5\u7684\u57fa\u672c\u65b9\u6848\uff0c\u5229\u7528\u5bf9FNO\u7684\u7269\u7406\u589e\u5f3a\u7ed9\u51fa\u663e\u5f0f\u4fdd\u8bc1\uff0c\u5e76\u6784\u9020\u65e0\u9700\u8bad\u7ec3\u7684FNO\u3002", "result": "\u5f97\u5230\u7684\u7b97\u5b50\u80fd\u4ee5\u671f\u671b\u7cbe\u5ea6\u9884\u6d4b\u4efb\u610f\u521a\u5ea6\u5206\u5e03\uff08\u53d7\u6750\u6599\u5bf9\u6bd4\u5ea6\u7ea6\u675f\uff09\u7684\u7ec6\u80de\u95ee\u9898\u89e3\uff0c\u5177\u6709\u901a\u7528\u8fd1\u4f3c\u6027\uff0c\u6ee1\u8db3\u5185\u5b58\u8981\u6c42\uff0c\u8fd0\u884c\u65f6\u95f4\u4e0e\u7ecf\u5178FFT\u6c42\u89e3\u5668\u6210\u6bd4\u4f8b\uff0c\u53ef\u5904\u7406\u8d851\u4ebf\u4f53\u7d20\u7684\u5927\u89c4\u6a21\u95ee\u9898\u3002", "conclusion": "\u5f3a\u8c03FNOs\u89e3\u51b3\u5fae\u89c2\u529b\u5b66\u95ee\u9898\u7684\u6f5c\u529b\uff0c\u8fde\u63a5\u57fa\u4e8eFFT\u7684\u65b9\u6cd5\u548cFNOs\uff0c\u6709\u671b\u4fc3\u8fdb\u4e24\u8005\u4ea4\u6d41\u3002"}}
{"id": "2507.12202", "pdf": "https://arxiv.org/pdf/2507.12202", "abs": "https://arxiv.org/abs/2507.12202", "authors": ["Anton Klenitskiy", "Konstantin Polev", "Daria Denisova", "Alexey Vasilev", "Dmitry Simakov", "Gleb Gusev"], "title": "Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "Many current state-of-the-art models for sequential recommendations are based\non transformer architectures. Interpretation and explanation of such black box\nmodels is an important research question, as a better understanding of their\ninternals can help understand, influence, and control their behavior, which is\nvery important in a variety of real-world applications. Recently sparse\nautoencoders (SAE) have been shown to be a promising unsupervised approach for\nextracting interpretable features from language models. These autoencoders\nlearn to reconstruct hidden states of the transformer's internal layers from\nsparse linear combinations of directions in their activation space.\n  This paper is focused on the application of SAE to the sequential\nrecommendation domain. We show that this approach can be successfully applied\nto the transformer trained on a sequential recommendation task: learned\ndirections turn out to be more interpretable and monosemantic than the original\nhidden state dimensions. Moreover, we demonstrate that the features learned by\nSAE can be used to effectively and flexibly control the model's behavior,\nproviding end-users with a straightforward method to adjust their\nrecommendations to different custom scenarios and contexts.", "AI": {"tldr": "\u672c\u6587\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u5e94\u7528\u4e8e\u5e8f\u5217\u63a8\u8350\u9886\u57df\uff0c\u5c55\u793a\u5176\u53ef\u6210\u529f\u5e94\u7528\u4e8e\u76f8\u5173\u4efb\u52a1\u7684Transformer\u6a21\u578b\uff0c\u5b66\u4e60\u5230\u7684\u65b9\u5411\u66f4\u5177\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u80fd\u6709\u6548\u7075\u6d3b\u63a7\u5236\u6a21\u578b\u884c\u4e3a\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u5e8f\u5217\u63a8\u8350\u6a21\u578b\u4e3a\u9ed1\u76d2\u6a21\u578b\uff0c\u89e3\u91ca\u5176\u5185\u90e8\u673a\u5236\u5bf9\u7406\u89e3\u3001\u5f71\u54cd\u548c\u63a7\u5236\u6a21\u578b\u884c\u4e3a\u5f88\u91cd\u8981\uff0c\u800cSAE\u5728\u63d0\u53d6\u8bed\u8a00\u6a21\u578b\u53ef\u89e3\u91ca\u7279\u5f81\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u56e0\u6b64\u60f3\u5c06\u5176\u5e94\u7528\u4e8e\u5e8f\u5217\u63a8\u8350\u9886\u57df\u3002", "method": "\u5c06SAE\u5e94\u7528\u4e8e\u5728\u5e8f\u5217\u63a8\u8350\u4efb\u52a1\u4e0a\u8bad\u7ec3\u7684Transformer\u6a21\u578b\uff0c\u5b66\u4e60\u7528\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u65b9\u5411\u7684\u7a00\u758f\u7ebf\u6027\u7ec4\u5408\u6765\u91cd\u6784Transformer\u5185\u90e8\u5c42\u7684\u9690\u85cf\u72b6\u6001\u3002", "result": "\u5b66\u4e60\u5230\u7684\u65b9\u5411\u6bd4\u539f\u59cb\u9690\u85cf\u72b6\u6001\u7ef4\u5ea6\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u548c\u5355\u8bed\u4e49\u6027\uff0cSAE\u5b66\u4e60\u7684\u7279\u5f81\u80fd\u6709\u6548\u7075\u6d3b\u63a7\u5236\u6a21\u578b\u884c\u4e3a\u3002", "conclusion": "SAE\u53ef\u6210\u529f\u5e94\u7528\u4e8e\u5e8f\u5217\u63a8\u8350\u9886\u57df\u7684Transformer\u6a21\u578b\uff0c\u80fd\u4e3a\u7ec8\u7aef\u7528\u6237\u63d0\u4f9b\u8c03\u6574\u63a8\u8350\u4ee5\u9002\u5e94\u4e0d\u540c\u573a\u666f\u548c\u4e0a\u4e0b\u6587\u7684\u76f4\u63a5\u65b9\u6cd5\u3002"}}
{"id": "2507.11563", "pdf": "https://arxiv.org/pdf/2507.11563", "abs": "https://arxiv.org/abs/2507.11563", "authors": ["Giulio Attenni", "Novella Bartolini"], "title": "Environmentally-Conscious Cloud Orchestration Considering Geo-Distributed Data Centers", "categories": ["cs.DC"], "comment": "LOCO 2024, December 3, 2024, Glasgow/Online", "summary": "This paper presents a theoretical discussion for environmentally-conscious\njob deployment and migration in cloud environments, aiming to minimize the\nenvironmental impact of resource provisioning while incorporating\nsustainability requirements. As the demand for sustainable cloud services\ngrows, it is crucial for cloud customers to select data center operators based\non sustainability metrics and to accurately report the ecological footprint of\ntheir services. To this end, we analyze sustainability reports and define\ncomprehensive environmental impact profiles for data centers, incorporating key\nsustainability indicators. We formalize the problem as an optimization model,\nbalancing multiple environmental factors while respecting user preferences. A\nsimulative case study demonstrates the {potential} of our approach compared to\nbaseline strategies that optimize for single sustainability factors.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e91\u73af\u5883\u4e0b\u8003\u8651\u73af\u5883\u56e0\u7d20\u7684\u4f5c\u4e1a\u90e8\u7f72\u548c\u8fc1\u79fb\u8fdb\u884c\u7406\u8bba\u63a2\u8ba8\uff0c\u63d0\u51fa\u4f18\u5316\u6a21\u578b\u5e76\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u5176\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u5bf9\u53ef\u6301\u7eed\u4e91\u670d\u52a1\u9700\u6c42\u589e\u957f\uff0c\u9700\u8ba9\u4e91\u5ba2\u6237\u57fa\u4e8e\u53ef\u6301\u7eed\u6027\u6307\u6807\u9009\u62e9\u6570\u636e\u4e2d\u5fc3\u8fd0\u8425\u5546\u5e76\u51c6\u786e\u62a5\u544a\u670d\u52a1\u751f\u6001\u8db3\u8ff9\u3002", "method": "\u5206\u6790\u53ef\u6301\u7eed\u6027\u62a5\u544a\uff0c\u5b9a\u4e49\u6570\u636e\u4e2d\u5fc3\u73af\u5883\u5f71\u54cd\u6982\u51b5\uff0c\u5c06\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4f18\u5316\u6a21\u578b\uff0c\u5e73\u8861\u591a\u73af\u5883\u56e0\u7d20\u5e76\u8003\u8651\u7528\u6237\u504f\u597d\u3002", "result": "\u6a21\u62df\u6848\u4f8b\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u76f8\u6bd4\u5355\u4e00\u53ef\u6301\u7eed\u56e0\u7d20\u4f18\u5316\u7684\u57fa\u7ebf\u7b56\u7565\u6709\u6f5c\u529b\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u4e91\u73af\u5883\u4f5c\u4e1a\u90e8\u7f72\u548c\u8fc1\u79fb\u4e2d\u8003\u8651\u591a\u73af\u5883\u56e0\u7d20\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.11788", "pdf": "https://arxiv.org/pdf/2507.11788", "abs": "https://arxiv.org/abs/2507.11788", "authors": ["Daniel Mitropolsky", "Christos Papadimitriou"], "title": "Simulated Language Acquisition in a Biologically Realistic Model of the Brain", "categories": ["cs.NE", "cs.CL"], "comment": "13 pages, 6 figures", "summary": "Despite tremendous progress in neuroscience, we do not have a compelling\nnarrative for the precise way whereby the spiking of neurons in our brain\nresults in high-level cognitive phenomena such as planning and language. We\nintroduce a simple mathematical formulation of six basic and broadly accepted\nprinciples of neuroscience: excitatory neurons, brain areas, random synapses,\nHebbian plasticity, local inhibition, and inter-area inhibition. We implement a\nsimulated neuromorphic system based on this formalism, which is capable of\nbasic language acquisition: Starting from a tabula rasa, the system learns, in\nany language, the semantics of words, their syntactic role (verb versus noun),\nand the word order of the language, including the ability to generate novel\nsentences, through the exposure to a modest number of grounded sentences in the\nsame language. We discuss several possible extensions and implications of this\nresult.", "AI": {"tldr": "\u5f15\u5165\u795e\u7ecf\u79d1\u5b66\u516d\u539f\u5219\u7684\u6570\u5b66\u516c\u5f0f\uff0c\u5b9e\u73b0\u6a21\u62df\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u80fd\u8fdb\u884c\u57fa\u7840\u8bed\u8a00\u4e60\u5f97\u5e76\u8ba8\u8bba\u7ed3\u679c\u7684\u6269\u5c55\u548c\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u79d1\u5b66\u867d\u6709\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u795e\u7ecf\u5143\u653e\u7535\u4ea7\u751f\u9ad8\u7ea7\u8ba4\u77e5\u73b0\u8c61\u7684\u660e\u786e\u89e3\u91ca\u3002", "method": "\u5f15\u5165\u795e\u7ecf\u79d1\u5b66\u516d\u539f\u5219\u7684\u6570\u5b66\u516c\u5f0f\uff0c\u57fa\u4e8e\u6b64\u5b9e\u73b0\u6a21\u62df\u795e\u7ecf\u5f62\u6001\u7cfb\u7edf\u3002", "result": "\u7cfb\u7edf\u80fd\u4ece\u65e0\u5230\u6709\uff0c\u901a\u8fc7\u63a5\u89e6\u4e00\u5b9a\u6570\u91cf\u7684\u63a5\u5730\u53e5\u5b50\uff0c\u5b66\u4e60\u4efb\u4f55\u8bed\u8a00\u7684\u5355\u8bcd\u8bed\u4e49\u3001\u53e5\u6cd5\u89d2\u8272\u548c\u8bcd\u5e8f\uff0c\u8fd8\u80fd\u751f\u6210\u65b0\u53e5\u5b50\u3002", "conclusion": "\u8bba\u6587\u8ba8\u8bba\u4e86\u7ed3\u679c\u7684\u51e0\u79cd\u53ef\u80fd\u6269\u5c55\u548c\u5f71\u54cd\u3002"}}
{"id": "2507.12331", "pdf": "https://arxiv.org/pdf/2507.12331", "abs": "https://arxiv.org/abs/2507.12331", "authors": ["Orr Shahar", "Stefan Lessmann", "Daniel Traian Pele"], "title": "Causality analysis of electricity market liberalization on electricity price using novel Machine Learning methods", "categories": ["econ.GN", "q-fin.EC"], "comment": "23 pages, 7 figures", "summary": "Relationships between the energy and the finance markets are increasingly\nimportant. Understanding these relationships is vital for policymakers and\nother stakeholders as the world faces challenges such as satisfying humanity's\nincreasing need for energy and the effects of climate change. In this paper, we\ninvestigate the causal effect of electricity market liberalization on the\nelectricity price in the US. By performing this analysis, we aim to provide new\ninsights into the ongoing debate about the benefits of electricity market\nliberalization. We introduce Causal Machine Learning as a new approach for\ninterventions in the energy-finance field. The development of machine learning\nin recent years opened the door for a new branch of machine learning models for\ncausality impact, with the ability to extract complex patterns and\nrelationships from the data. We discuss the advantages of causal ML methods and\ncompare the performance of ML-based models to shed light on the applicability\nof causal ML frameworks to energy policy intervention cases. We find that the\nDeepProbCP framework outperforms the other frameworks examined. In addition, we\nfind that liberalization of, and individual players' entry to, the electricity\nmarket resulted in a 7% decrease in price in the short term.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7f8e\u56fd\u7535\u529b\u5e02\u573a\u81ea\u7531\u5316\u5bf9\u7535\u4ef7\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u5f15\u5165\u56e0\u679c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u53d1\u73b0DeepProbCP\u6846\u67b6\u8868\u73b0\u6700\u4f73\uff0c\u4e14\u5e02\u573a\u81ea\u7531\u5316\u77ed\u671f\u5185\u4f7f\u7535\u4ef7\u964d7%\u3002", "motivation": "\u7406\u89e3\u80fd\u6e90\u548c\u91d1\u878d\u5e02\u573a\u5173\u7cfb\u5bf9\u653f\u7b56\u5236\u5b9a\u8005\u7b49\u5f88\u91cd\u8981\uff0c\u4e3a\u7535\u529b\u5e02\u573a\u81ea\u7531\u5316\u76ca\u5904\u7684\u8ba8\u8bba\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002", "method": "\u5f15\u5165\u56e0\u679c\u673a\u5668\u5b66\u4e60\u4f5c\u4e3a\u80fd\u6e90\u91d1\u878d\u9886\u57df\u5e72\u9884\u65b0\u65b9\u6cd5\uff0c\u6bd4\u8f83\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "DeepProbCP\u6846\u67b6\u4f18\u4e8e\u5176\u4ed6\u88ab\u8003\u5bdf\u6846\u67b6\uff1b\u7535\u529b\u5e02\u573a\u81ea\u7531\u5316\u548c\u4e2a\u4f53\u53c2\u4e0e\u8005\u8fdb\u5165\u4f7f\u77ed\u671f\u5185\u7535\u4ef7\u4e0b\u964d7%\u3002", "conclusion": "\u56e0\u679c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9002\u7528\u4e8e\u80fd\u6e90\u653f\u7b56\u5e72\u9884\u6848\u4f8b\uff0c\u53ef\u7528\u4e8e\u5206\u6790\u7535\u529b\u5e02\u573a\u81ea\u7531\u5316\u5bf9\u7535\u4ef7\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.11662", "pdf": "https://arxiv.org/pdf/2507.11662", "abs": "https://arxiv.org/abs/2507.11662", "authors": ["Moises Andrade", "Joonhyuk Cha", "Brandon Ho", "Vriksha Srihari", "Karmesh Yadav", "Zsolt Kira"], "title": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO"], "comment": "Our code and data are publicly available at\n  https://github.com/mshalimay/mllm-verifiers-abias-sgv", "summary": "Verifiers -- functions assigning rewards to agent behavior -- have been key\nfor AI progress in domains like math and board games. However, extending these\ngains to domains without clear-cut success criteria (e.g.,computer use) remains\na challenge: while humans can recognize suitable outcomes, translating this\nintuition into scalable rules is non-trivial. Multimodal Large Language\nModels(MLLMs) emerge as a promising solution, given their world knowledge,\nhuman-preference alignment, and reasoning skills. We evaluate MLLMs as\nverifiers of agent trajectories across web navigation, computer use, and\nrobotic manipulation, and identify a critical limitation: agreement bias, a\nstrong tendency for MLLMs to favor information in their context window, often\ngenerating chains of thought to rationalize flawed behavior. This bias is\npervasive across models, resilient to test-time scaling, and can impact several\nmethods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs\ndespite MLLMs showing strong, human-aligned priors on desired behavior. To\naddress this, we propose Self-Grounded Verification (SGV), a lightweight method\nthat enables more effective use of MLLMs' knowledge and reasoning by harnessing\ntheir own sampling mechanisms via unconditional and conditional generation. SGV\noperates in two steps: first, the MLLM is elicited to retrieve broad priors\nabout task completion, independent of the data under evaluation. Then,\nconditioned on self-generated priors, it reasons over and evaluates a candidate\ntrajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in\naccuracy and failure detection rates, and can perform real-time supervision of\nheterogeneous agents, boosting task completion of a GUI specialist in OSWorld,\na diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting\na new state of the art on the benchmark, surpassing the previous best by 48%.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30MLLMs\u4f5c\u4e3a\u9a8c\u8bc1\u5668\u5b58\u5728\u4e00\u81f4\u6027\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u51faSGV\u65b9\u6cd5\u89e3\u51b3\uff0c\u589e\u5f3a\u540eMLLM\u9a8c\u8bc1\u5668\u8868\u73b0\u63d0\u5347\u3002", "motivation": "\u5c06AI\u5728\u6709\u660e\u786e\u6210\u529f\u6807\u51c6\u9886\u57df\u7684\u6210\u679c\u62d3\u5c55\u5230\u65e0\u660e\u786e\u6807\u51c6\u9886\u57df\uff08\u5982\u8ba1\u7b97\u673a\u4f7f\u7528\uff09\uff0cMLLMs\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u4e00\u81f4\u6027\u504f\u5dee\u95ee\u9898\u3002", "method": "\u63d0\u51faSelf - Grounded Verification (SGV)\u65b9\u6cd5\uff0c\u5206\u4e24\u6b65\uff1a\u5148\u8ba9MLLM\u83b7\u53d6\u4efb\u52a1\u5b8c\u6210\u7684\u5e7f\u6cdb\u5148\u9a8c\uff0c\u518d\u57fa\u4e8e\u5148\u9a8c\u8bc4\u4f30\u5019\u9009\u8f68\u8ff9\u3002", "result": "\u589e\u5f3a\u540e\u7684MLLM\u9a8c\u8bc1\u5668\u5728\u51c6\u786e\u7387\u548c\u6545\u969c\u68c0\u6d4b\u7387\u4e0a\u63d0\u5347\u8fbe20\u5206\uff0c\u80fd\u5b9e\u65f6\u76d1\u7763\u5f02\u6784\u4ee3\u7406\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u521b\u9020\u65b0\u7684\u6700\u4f18\u7ed3\u679c\uff0c\u8d85\u8fc7\u4e4b\u524d\u6700\u4f7348%\u3002", "conclusion": "SGV\u65b9\u6cd5\u80fd\u6709\u6548\u5229\u7528MLLMs\u7684\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u5176\u4f5c\u4e3a\u9a8c\u8bc1\u5668\u7684\u4e00\u81f4\u6027\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.11689", "pdf": "https://arxiv.org/pdf/2507.11689", "abs": "https://arxiv.org/abs/2507.11689", "authors": ["Sergio Di Meglio", "Valeria Pontillo", "Luigi Libero Lucio Starace"], "title": "REST in Pieces: RESTful Design Rule Violations in Student-Built Web Apps", "categories": ["cs.SE"], "comment": "Manuscript accepted for the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA)", "summary": "In Computer Science Bachelor's programs, software quality is often\nunderemphasized due to limited time and a focus on foundational skills, leaving\nmany students unprepared for industry expectations. To better understand the\ntypical quality of student code and inform both education and hiring practices,\nwe analyze 40 full-stack web applications developed in a third-year Web\nTechnologies course. Using an automated static analysis pipeline, we assess\nadherence to REST API design rules. Results reveal frequent violations of\nfoundational conventions, such as missing hyphens in endpoint paths (98%),\nincorrect pluralization (88%), and misuse of HTTP methods (83%). These findings\nhighlight the need for more focused instruction on API design and support the\nadoption of automated tools to improve code quality in student projects.", "AI": {"tldr": "\u5206\u6790\u5927\u4e09\u7f51\u7edc\u6280\u672f\u8bfe\u7a0b\u4e2d40\u4e2a\u5168\u6808Web\u5e94\u7528\u4ee3\u7801\uff0c\u53d1\u73b0API\u8bbe\u8ba1\u57fa\u7840\u89c4\u5219\u5e38\u88ab\u8fdd\u53cd\uff0c\u9700\u52a0\u5f3a\u6559\u5b66\u548c\u91c7\u7528\u81ea\u52a8\u5316\u5de5\u5177\u3002", "motivation": "\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u8bfe\u7a0b\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u91cd\u89c6\u4e0d\u8db3\uff0c\u4e3a\u4e86\u89e3\u5b66\u751f\u4ee3\u7801\u8d28\u91cf\u4ee5\u6539\u8fdb\u6559\u80b2\u548c\u62db\u8058\u5b9e\u8df5\u3002", "method": "\u4f7f\u7528\u81ea\u52a8\u5316\u9759\u6001\u5206\u6790\u7ba1\u9053\u8bc4\u4f30\u4ee3\u7801\u5bf9REST API\u8bbe\u8ba1\u89c4\u5219\u7684\u9075\u5faa\u60c5\u51b5\u3002", "result": "\u53d1\u73b0\u7aef\u70b9\u8def\u5f84\u7f3a\u5c11\u8fde\u5b57\u7b26\uff0898%\uff09\u3001\u590d\u6570\u5f62\u5f0f\u9519\u8bef\uff0888%\uff09\u548cHTTP\u65b9\u6cd5\u4f7f\u7528\u4e0d\u5f53\uff0883%\uff09\u7b49\u5e38\u89c1\u8fdd\u89c4\u60c5\u51b5\u3002", "conclusion": "\u9700\u8981\u66f4\u6709\u9488\u5bf9\u6027\u5730\u5f00\u5c55API\u8bbe\u8ba1\u6559\u5b66\uff0c\u5e76\u91c7\u7528\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u9ad8\u5b66\u751f\u9879\u76ee\u4ee3\u7801\u8d28\u91cf\u3002"}}
{"id": "2507.11574", "pdf": "https://arxiv.org/pdf/2507.11574", "abs": "https://arxiv.org/abs/2507.11574", "authors": ["Kazuma Kobayashi", "Shailesh Garg", "Farid Ahmed", "Souvik Chakraborty", "Syed Bahauddin Alam"], "title": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Robust uncertainty quantification (UQ) remains a critical barrier to the safe\ndeployment of deep learning in real-time virtual sensing, particularly in\nhigh-stakes domains where sparse, noisy, or non-collocated sensor data are the\nnorm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework\nthat transforms neural operator-based virtual sensing with calibrated,\ndistribution-free prediction intervals. By unifying Monte Carlo dropout with\nsplit conformal prediction in a single DeepONet architecture, CMCO achieves\nspatially resolved uncertainty estimates without retraining, ensembling, or\ncustom loss design. Our method addresses a longstanding challenge: how to endow\noperator learning with efficient and reliable UQ across heterogeneous domains.\nThrough rigorous evaluation on three distinct applications: turbulent flow,\nelastoplastic deformation, and global cosmic radiation dose estimation-CMCO\nconsistently attains near-nominal empirical coverage, even in settings with\nstrong spatial gradients and proxy-based sensing. This breakthrough offers a\ngeneral-purpose, plug-and-play UQ solution for neural operators, unlocking\nreal-time, trustworthy inference in digital twins, sensor fusion, and\nsafety-critical monitoring. By bridging theory and deployment with minimal\ncomputational overhead, CMCO establishes a new foundation for scalable,\ngeneralizable, and uncertainty-aware scientific machine learning.", "AI": {"tldr": "\u63d0\u51faConformalized Monte Carlo Operator (CMCO)\u6846\u67b6\uff0c\u4e3a\u795e\u7ecf\u7b97\u5b50\u865a\u62df\u4f20\u611f\u63d0\u4f9b\u6821\u51c6\u3001\u65e0\u5206\u5e03\u9884\u6d4b\u533a\u95f4\uff0c\u5728\u591a\u5e94\u7528\u4e2d\u5b9e\u73b0\u826f\u597d\u7ecf\u9a8c\u8986\u76d6\uff0c\u4e3a\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u5960\u5b9a\u65b0\u57fa\u7840\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u5b9e\u65f6\u865a\u62df\u4f20\u611f\u4e2d\u9c81\u68d2\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u96be\u9898\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u9886\u57df\u3002", "method": "\u5728\u5355\u4e00DeepONet\u67b6\u6784\u4e2d\u5c06\u8499\u7279\u5361\u7f57\u4e22\u5f03\u6cd5\u4e0e\u5206\u88c2\u5171\u5f62\u9884\u6d4b\u76f8\u7ed3\u5408\uff0c\u63d0\u51faCMCO\u6846\u67b6\u3002", "result": "\u5728\u6e4d\u6d41\u3001\u5f39\u5851\u6027\u53d8\u5f62\u548c\u5168\u7403\u5b87\u5b99\u8f90\u5c04\u5242\u91cf\u4f30\u8ba1\u4e09\u4e2a\u5e94\u7528\u4e2d\uff0cCMCO\u59cb\u7ec8\u5b9e\u73b0\u63a5\u8fd1\u6807\u79f0\u7684\u7ecf\u9a8c\u8986\u76d6\u3002", "conclusion": "CMCO\u4e3a\u795e\u7ecf\u7b97\u5b50\u63d0\u4f9b\u901a\u7528\u3001\u5373\u63d2\u5373\u7528\u7684UQ\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u6700\u5c0f\u8ba1\u7b97\u5f00\u9500\u8fde\u63a5\u7406\u8bba\u4e0e\u5e94\u7528\uff0c\u4e3a\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u5960\u5b9a\u65b0\u57fa\u7840\u3002"}}
{"id": "2507.11895", "pdf": "https://arxiv.org/pdf/2507.11895", "abs": "https://arxiv.org/abs/2507.11895", "authors": ["Haolin Zou", "Arnab Auddy", "Yongchan Kwon", "Kamiar Rahnama Rad", "Arian Maleki"], "title": "Newfluence: Boosting Model interpretability and Understanding in High Dimensions", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "The increasing complexity of machine learning (ML) and artificial\nintelligence (AI) models has created a pressing need for tools that help\nscientists, engineers, and policymakers interpret and refine model decisions\nand predictions. Influence functions, originating from robust statistics, have\nemerged as a popular approach for this purpose.\n  However, the heuristic foundations of influence functions rely on\nlow-dimensional assumptions where the number of parameters $p$ is much smaller\nthan the number of observations $n$. In contrast, modern AI models often\noperate in high-dimensional regimes with large $p$, challenging these\nassumptions.\n  In this paper, we examine the accuracy of influence functions in\nhigh-dimensional settings. Our theoretical and empirical analyses reveal that\ninfluence functions cannot reliably fulfill their intended purpose. We then\nintroduce an alternative approximation, called Newfluence, that maintains\nsimilar computational efficiency while offering significantly improved\naccuracy.\n  Newfluence is expected to provide more accurate insights than many existing\nmethods for interpreting complex AI models and diagnosing their issues.\nMoreover, the high-dimensional framework we develop in this paper can also be\napplied to analyze other popular techniques, such as Shapley values.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u4e0d\u51c6\u786e\uff0c\u63d0\u51fa\u65b0\u7684\u8fd1\u4f3c\u65b9\u6cd5Newfluence\uff0c\u80fd\u63d0\u5347\u89e3\u8bfb\u590d\u6742AI\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u4e14\u5176\u9ad8\u7ef4\u6846\u67b6\u53ef\u7528\u4e8e\u5206\u6790\u5176\u4ed6\u6280\u672f\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u5de5\u5177\u89e3\u8bfb\u548c\u4f18\u5316\u6a21\u578b\u51b3\u7b56\u4e0e\u9884\u6d4b\uff0c\u4f46\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\u57fa\u4e8e\u4f4e\u7ef4\u5047\u8bbe\uff0c\u4e0d\u9002\u7528\u4e8e\u9ad8\u7ef4\u73b0\u4ee3AI\u6a21\u578b\u3002", "method": "\u5bf9\u5f71\u54cd\u51fd\u6570\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u7684\u51c6\u786e\u6027\u8fdb\u884c\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\uff0c\u63d0\u51fa\u65b0\u7684\u8fd1\u4f3c\u65b9\u6cd5Newfluence\u3002", "result": "\u5f71\u54cd\u51fd\u6570\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u4e0d\u80fd\u53ef\u9760\u5b9e\u73b0\u5176\u76ee\u7684\uff0cNewfluence\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "Newfluence\u80fd\u4e3a\u89e3\u8bfb\u590d\u6742AI\u6a21\u578b\u548c\u8bca\u65ad\u95ee\u9898\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u89c1\u89e3\uff0c\u9ad8\u7ef4\u6846\u67b6\u53ef\u7528\u4e8e\u5206\u6790\u5176\u4ed6\u6d41\u884c\u6280\u672f\u3002"}}
{"id": "2507.11719", "pdf": "https://arxiv.org/pdf/2507.11719", "abs": "https://arxiv.org/abs/2507.11719", "authors": ["Emmanouil Androulakis", "Georgios I. Papayiannis", "Athanasios N. Yannacopoulos"], "title": "Model averaging in the space of probability distributions", "categories": ["stat.ME", "stat.CO", "stat.ML"], "comment": "26 pages, 5 figures", "summary": "This work investigates the problem of model averaging in the context of\nmeasure-valued data. Specifically, we study aggregation schemes in the space of\nprobability distributions metrized in terms of the Wasserstein distance. The\nresulting aggregate models, defined via Wasserstein barycenters, are optimally\ncalibrated to empirical data. To enhance model performance, we employ\nregularization schemes motivated by the standard elastic net penalization,\nwhich is shown to consistently yield models enjoying sparsity properties. The\nconsistency properties of the proposed averaging schemes with respect to sample\nsize are rigorously established using the variational framework of\n$\\Gamma$-convergence. The performance of the methods is evaluated through\ncarefully designed synthetic experiments that assess behavior across a range of\ndistributional characteristics and stress conditions. Finally, the proposed\napproach is applied to a real-world dataset of insurance losses - characterized\nby heavy-tailed behavior - to estimate the claim size distribution and the\nassociated tail risk.", "AI": {"tldr": "\u7814\u7a76\u5ea6\u91cf\u503c\u6570\u636e\u4e0b\u6a21\u578b\u5e73\u5747\u95ee\u9898\uff0c\u7528Wasserstein\u8ddd\u79bb\u5ea6\u91cf\u6982\u7387\u5206\u5e03\u7a7a\u95f4\u805a\u5408\u65b9\u6848\uff0c\u91c7\u7528\u6b63\u5219\u5316\u63d0\u5347\u6027\u80fd\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u65b9\u6cd5\u5e76\u5e94\u7528\u4e8e\u4fdd\u9669\u635f\u5931\u6570\u636e\u96c6\u3002", "motivation": "\u89e3\u51b3\u5ea6\u91cf\u503c\u6570\u636e\u4e0b\u7684\u6a21\u578b\u5e73\u5747\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4ee5\u66f4\u597d\u5730\u5904\u7406\u7ecf\u9a8c\u6570\u636e\u548c\u4f30\u8ba1\u98ce\u9669\u3002", "method": "\u7814\u7a76Wasserstein\u8ddd\u79bb\u5ea6\u91cf\u7684\u6982\u7387\u5206\u5e03\u7a7a\u95f4\u805a\u5408\u65b9\u6848\uff0c\u91c7\u7528\u7c7b\u4f3c\u5f39\u6027\u7f51\u7edc\u60e9\u7f5a\u7684\u6b63\u5219\u5316\u65b9\u6848\uff0c\u7528\u0393 - \u6536\u655b\u7684\u53d8\u5206\u6846\u67b6\u5efa\u7acb\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u5e94\u7528\u4e8e\u5b9e\u9645\u6570\u636e\u96c6\u3002", "result": "\u6b63\u5219\u5316\u65b9\u6848\u80fd\u4ea7\u751f\u5177\u6709\u7a00\u758f\u6027\u7684\u6a21\u578b\uff0c\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u5f97\u5230\u4e25\u8c28\u8bc1\u660e\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u65b9\u6cd5\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5408\u6210\u5b9e\u9a8c\u548c\u5b9e\u9645\u4fdd\u9669\u635f\u5931\u6570\u636e\u96c6\u4e0a\u90fd\u6709\u5e94\u7528\u4ef7\u503c\uff0c\u53ef\u7528\u4e8e\u4f30\u8ba1\u7d22\u8d54\u89c4\u6a21\u5206\u5e03\u548c\u76f8\u5173\u5c3e\u90e8\u98ce\u9669\u3002"}}
{"id": "2507.11542", "pdf": "https://arxiv.org/pdf/2507.11542", "abs": "https://arxiv.org/abs/2507.11542", "authors": ["Lekan Molu"], "title": "LevelSetPy: A GPU-Accelerated Package for Hyperbolic Hamilton-Jacobi Partial Differential Equations", "categories": ["cs.MS", "cs.GT"], "comment": "Just Accepted ACM Trans. Math. Softw (April 2025). arXiv admin note:\n  text overlap with arXiv:2411.03501", "summary": "This article introduces a software package release for geometrically\nreasoning about the \\textit{safety} desiderata of (complex) dynamical systems\nvia level set methods. In emphasis, safety is analyzed with Hamilton-Jacobi\nequations. In scope, we provide implementations of numerical algorithms for the\nresolution of Hamilton-Jacobi-Isaacs equations: the spatial derivatives of the\nassociated value function via upwinding, the Hamiltonian via Lax-Friedrichs\nschemes, and the integration of the Hamilton-Jacobi equation altogether via\ntotal variation diminishing Runge-Kutta schemes. Since computational speed and\ninteroperability with other modern scientific computing libraries (typically\nwritten in the Python language) is of essence, we capitalize on modern\ncomputational frameworks such as \\texttt{CUPY} and \\texttt{NUMPY} and move\nheavy computations to GPU devices to aid parallelization and improve bring-up\ntime in safety analysis. We hope that this package can aid users to quickly\niterate on ideas and evaluate all possible safety desiderata of a system via\ngeometrical simulation in modern engineering problems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8e\u901a\u8fc7\u6c34\u5e73\u96c6\u65b9\u6cd5\u5bf9\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u5b89\u5168\u9700\u6c42\u8fdb\u884c\u51e0\u4f55\u63a8\u7406\u7684\u8f6f\u4ef6\u5305\uff0c\u5229\u7528\u73b0\u4ee3\u8ba1\u7b97\u6846\u67b6\u52a0\u901f\uff0c\u52a9\u7528\u6237\u8bc4\u4f30\u7cfb\u7edf\u5b89\u5168\u9700\u6c42\u3002", "motivation": "\u4e3a\u89e3\u51b3\u73b0\u4ee3\u5de5\u7a0b\u95ee\u9898\u4e2d\u5bf9\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u5b89\u5168\u9700\u6c42\u8fdb\u884c\u51e0\u4f55\u63a8\u7406\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u8ba1\u7b97\u901f\u5ea6\u548c\u4e0e\u5176\u4ed6\u79d1\u5b66\u8ba1\u7b97\u5e93\u7684\u4e92\u64cd\u4f5c\u6027\u3002", "method": "\u4f7f\u7528\u6c34\u5e73\u96c6\u65b9\u6cd5\u5206\u6790\u5b89\u5168\u95ee\u9898\uff0c\u7528Hamilton - Jacobi\u65b9\u7a0b\uff1b\u63d0\u4f9b\u6c42\u89e3Hamilton - Jacobi - Isaacs\u65b9\u7a0b\u7684\u6570\u503c\u7b97\u6cd5\uff1b\u5229\u7528CUPY\u548cNUMPY\u7b49\u6846\u67b6\uff0c\u5c06\u91cd\u8ba1\u7b97\u4efb\u52a1\u79fb\u5230GPU\u8fdb\u884c\u5e76\u884c\u8ba1\u7b97\u3002", "result": "\u5f00\u53d1\u51fa\u76f8\u5173\u8f6f\u4ef6\u5305\u3002", "conclusion": "\u8be5\u8f6f\u4ef6\u5305\u80fd\u5e2e\u52a9\u7528\u6237\u5728\u73b0\u4ee3\u5de5\u7a0b\u95ee\u9898\u4e2d\u5feb\u901f\u8fed\u4ee3\u60f3\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u6a21\u62df\u8bc4\u4f30\u7cfb\u7edf\u7684\u6240\u6709\u53ef\u80fd\u5b89\u5168\u9700\u6c42\u3002"}}
{"id": "2507.12130", "pdf": "https://arxiv.org/pdf/2507.12130", "abs": "https://arxiv.org/abs/2507.12130", "authors": ["Adithya Bijoy", "Ankit Mondal", "Ashish Chiplunkar"], "title": "Weighted $k$-Server Admits an Exponentially Competitive Algorithm", "categories": ["cs.DS"], "comment": null, "summary": "The weighted $k$-server is a variant of the $k$-server problem, where the\ncost of moving a server is the server's weight times the distance through which\nit moves. The problem is famous for its intriguing properties and for evading\nstandard techniques for designing and analyzing online algorithms. Even on\nuniform metric spaces with sufficiently many points, the deterministic\ncompetitive ratio of weighted $k$-server is known to increase doubly\nexponentially with respect to $k$, while the behavior of its randomized\ncompetitive ratio is not fully understood. Specifically, no upper bound better\nthan doubly exponential is known, while the best known lower bound is singly\nexponential in $k$. In this paper, we close the exponential gap between these\nbounds by giving an $\\exp(O(k^2))$-competitive randomized online algorithm for\nthe weighted $k$-server problem on uniform metrics, thus breaking the doubly\nexponential barrier for deterministic algorithms for the first time. This is\nachieved by a recursively defined notion of a phase which, on the one hand,\nforces a lower bound on the cost of any offline solution, while, on the other\nhand, also admits a randomized online algorithm with bounded expected cost. The\nalgorithm is also recursive; it involves running several algorithms virtually\nand in parallel and following the decisions of one of them in a random order.\nWe also show that our techniques can be lifted to construct an\n$\\exp(O(k^2))$-competitive randomized online algorithm for the generalized\n$k$-server problem on weighted uniform metrics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11739", "pdf": "https://arxiv.org/pdf/2507.11739", "abs": "https://arxiv.org/abs/2507.11739", "authors": ["Urban Fasel"], "title": "Sparse Identification of Nonlinear Dynamics with Conformal Prediction", "categories": ["cs.LG", "cs.CE", "math.DS"], "comment": null, "summary": "The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for\ndiscovering nonlinear dynamical system models from data. Quantifying\nuncertainty in SINDy models is essential for assessing their reliability,\nparticularly in safety-critical applications. While various uncertainty\nquantification methods exist for SINDy, including Bayesian and ensemble\napproaches, this work explores the integration of Conformal Prediction, a\nframework that can provide valid prediction intervals with coverage guarantees\nbased on minimal assumptions like data exchangeability. We introduce three\napplications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)\nquantifying uncertainty in time series prediction, (2) model selection based on\nlibrary feature importance, and (3) quantifying the uncertainty of identified\nmodel coefficients using feature conformal prediction. We demonstrate the three\napplications on stochastic predator-prey dynamics and several chaotic dynamical\nsystems. We show that conformal prediction methods integrated with E-SINDy can\nreliably achieve desired target coverage for time series forecasting,\neffectively quantify feature importance, and produce more robust uncertainty\nintervals for model coefficients, even under non-Gaussian noise, compared to\nstandard E-SINDy coefficient estimates.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u5c06\u5171\u5f62\u9884\u6d4b\u4e0e\u96c6\u6210\u7a00\u758f\u8bc6\u522b\u975e\u7ebf\u6027\u52a8\u529b\u5b66\uff08E - SINDy\uff09\u7ed3\u5408\uff0c\u4ecb\u7ecd\u4e09\u79cd\u5e94\u7528\u5e76\u5728\u591a\u4e2a\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\uff0c\u8868\u660e\u8be5\u7ed3\u5408\u65b9\u6cd5\u6709\u66f4\u597d\u6548\u679c\u3002", "motivation": "\u91cf\u5316SINDy\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u8bc4\u4f30\u5176\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u3002", "method": "\u5c06\u5171\u5f62\u9884\u6d4b\u4e0eE - SINDy\u7ed3\u5408\uff0c\u4ecb\u7ecd\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3001\u57fa\u4e8e\u5e93\u7279\u5f81\u91cd\u8981\u6027\u7684\u6a21\u578b\u9009\u62e9\u3001\u7279\u5f81\u5171\u5f62\u9884\u6d4b\u91cf\u5316\u6a21\u578b\u7cfb\u6570\u4e0d\u786e\u5b9a\u6027\u4e09\u79cd\u5e94\u7528\u3002", "result": "\u5728\u968f\u673a\u6355\u98df\u8005 - \u730e\u7269\u52a8\u529b\u5b66\u548c\u51e0\u4e2a\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u5408\u65b9\u6cd5\u80fd\u53ef\u9760\u5b9e\u73b0\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u76ee\u6807\u8986\u76d6\u7387\uff0c\u6709\u6548\u91cf\u5316\u7279\u5f81\u91cd\u8981\u6027\uff0c\u5728\u975e\u9ad8\u65af\u566a\u58f0\u4e0b\u4e3a\u6a21\u578b\u7cfb\u6570\u751f\u6210\u66f4\u7a33\u5065\u7684\u4e0d\u786e\u5b9a\u6027\u533a\u95f4\u3002", "conclusion": "\u5171\u5f62\u9884\u6d4b\u65b9\u6cd5\u4e0eE - SINDy\u7ed3\u5408\u6bd4\u6807\u51c6E - SINDy\u7cfb\u6570\u4f30\u8ba1\u6709\u66f4\u597d\u7684\u6548\u679c\u3002"}}
{"id": "2507.12242", "pdf": "https://arxiv.org/pdf/2507.12242", "abs": "https://arxiv.org/abs/2507.12242", "authors": ["C\u00e9cile Log\u00e9"], "title": "Looking for Fairness in Recommender Systems", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Recommender systems can be found everywhere today, shaping our everyday\nexperience whenever we're consuming content, ordering food, buying groceries\nonline, or even just reading the news. Let's imagine we're in the process of\nbuilding a recommender system to make content suggestions to users on social\nmedia. When thinking about fairness, it becomes clear there are several\nperspectives to consider: the users asking for tailored suggestions, the\ncontent creators hoping for some limelight, and society at large, navigating\nthe repercussions of algorithmic recommendations. A shared fairness concern\nacross all three is the emergence of filter bubbles, a side-effect that takes\nplace when recommender systems are almost \"too good\", making recommendations so\ntailored that users become inadvertently confined to a narrow set of\nopinions/themes and isolated from alternative ideas. From the user's\nperspective, this is akin to manipulation. From the small content creator's\nperspective, this is an obstacle preventing them access to a whole range of\npotential fans. From society's perspective, the potential consequences are\nfar-reaching, influencing collective opinions, social behavior and political\ndecisions. How can our recommender system be fine-tuned to avoid the creation\nof filter bubbles, and ensure a more inclusive and diverse content landscape?\nApproaching this problem involves defining one (or more) performance metric to\nrepresent diversity, and tweaking our recommender system's performance through\nthe lens of fairness. By incorporating this metric into our evaluation\nframework, we aim to strike a balance between personalized recommendations and\nthe broader societal goal of fostering rich and varied cultures and points of\nview.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u793e\u4ea4\u5a92\u4f53\u63a8\u8350\u7cfb\u7edf\u907f\u514d\u8fc7\u6ee4\u6c14\u6ce1\u95ee\u9898\uff0c\u63d0\u51fa\u5b9a\u4e49\u591a\u6837\u6027\u6307\u6807\u5e76\u878d\u5165\u8bc4\u4f30\u6846\u67b6\u4ee5\u5e73\u8861\u4e2a\u6027\u5316\u63a8\u8350\u4e0e\u793e\u4f1a\u591a\u5143\u5316\u76ee\u6807\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u6613\u4ea7\u751f\u8fc7\u6ee4\u6c14\u6ce1\uff0c\u5bf9\u7528\u6237\u3001\u5185\u5bb9\u521b\u4f5c\u8005\u548c\u793e\u4f1a\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5b9a\u4e49\u4e00\u4e2a\u6216\u591a\u4e2a\u4ee3\u8868\u591a\u6837\u6027\u7684\u6027\u80fd\u6307\u6807\uff0c\u4ece\u516c\u5e73\u89d2\u5ea6\u8c03\u6574\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u5c06\u8be5\u6307\u6807\u878d\u5165\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u4e0a\u8ff0\u65b9\u6cd5\u53ef\u5e73\u8861\u4e2a\u6027\u5316\u63a8\u8350\u548c\u4fc3\u8fdb\u4e30\u5bcc\u591a\u6837\u6587\u5316\u53ca\u89c2\u70b9\u7684\u793e\u4f1a\u76ee\u6807\u3002"}}
{"id": "2507.11683", "pdf": "https://arxiv.org/pdf/2507.11683", "abs": "https://arxiv.org/abs/2507.11683", "authors": ["Seth Ockerman", "Amal Gueroudji", "Tanwi Mallick", "Yixuan He", "Line Pouchard", "Robert Ross", "Shivaram Venkataraman"], "title": "PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "To be published in the 2025 International Conference for High\n  Performance Computing, Networking, Storage, and Analysis", "summary": "Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for\nmodeling spatial and temporal data dependencies. However, their applications\nhave been limited primarily to small-scale datasets because of memory\nconstraints. While distributed training offers a solution, current frameworks\nlack support for spatiotemporal models and overlook the properties of\nspatiotemporal data. Informed by a scaling study on a large-scale workload, we\npresent PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch\nGeometric Temporal that integrates distributed data parallel training and two\nnovel strategies: index-batching and distributed-index-batching. Our index\ntechniques exploit spatiotemporal structure to construct snapshots dynamically\nat runtime, significantly reducing memory overhead, while\ndistributed-index-batching extends this approach by enabling scalable\nprocessing across multiple GPUs. Our techniques enable the first-ever training\nof an ST-GNN on the entire PeMS dataset without graph partitioning, reducing\npeak memory usage by up to 89\\% and achieving up to a 13.1x speedup over\nstandard DDP with 128 GPUs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPGT - I\u6269\u5c55\uff0c\u89e3\u51b3\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5e94\u7528\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898\uff0c\u51cf\u5c11\u5185\u5b58\u5f00\u9500\u5e76\u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6\u3002", "motivation": "\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u56e0\u5185\u5b58\u9650\u5236\u4e3b\u8981\u5e94\u7528\u4e8e\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u73b0\u6709\u5206\u5e03\u5f0f\u8bad\u7ec3\u6846\u67b6\u4e0d\u652f\u6301\u65f6\u7a7a\u6a21\u578b\u4e14\u5ffd\u7565\u65f6\u7a7a\u6570\u636e\u7279\u6027\u3002", "method": "\u63d0\u51faPGT - I\u6269\u5c55\uff0c\u96c6\u6210\u5206\u5e03\u5f0f\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u3001\u7d22\u5f15\u6279\u5904\u7406\u548c\u5206\u5e03\u5f0f\u7d22\u5f15\u6279\u5904\u7406\u4e24\u79cd\u65b0\u7b56\u7565\uff0c\u5229\u7528\u65f6\u7a7a\u7ed3\u6784\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u6784\u5efa\u5feb\u7167\u3002", "result": "\u9996\u6b21\u5728\u4e0d\u8fdb\u884c\u56fe\u5212\u5206\u7684\u60c5\u51b5\u4e0b\u5728\u6574\u4e2aPeMS\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3ST - GNN\uff0c\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u6700\u591a\u51cf\u5c1189%\uff0c\u5728128\u4e2aGPU\u4e0a\u6bd4\u6807\u51c6DDP\u6700\u591a\u63d0\u901f13.1\u500d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6280\u672f\u80fd\u6709\u6548\u89e3\u51b3\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2507.12436", "pdf": "https://arxiv.org/pdf/2507.12436", "abs": "https://arxiv.org/abs/2507.12436", "authors": ["Jitesh Gurav"], "title": "The Case against Scale: Empirical Evidence of Underperformance in Large Secondary Funds", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "The paper analyses the increasing popularity of large funds in the secondary\nprivate equity market, which are pegged on the perceived larger scale\nadvantages of operational efficiency and fewer manager relationships (Reuter &\nZitzewitz, 2021). However, it has been proved empirically that smaller funds\nperform better than the big ones in terms of their internal rates of return\n(IRRs). This work questions this authoritative view, providing evidence of\noutperformance of smaller funds relative to their larger counterparts. This\nresearch shows us the benefits that smaller funds possess. Thus, investors must\nrevisit their allocation strategy to prioritize larger funds automatically\n(Gualandris et al.,2021).", "AI": {"tldr": "\u6587\u7ae0\u5206\u6790\u79c1\u52df\u4e8c\u7ea7\u5e02\u573a\u5927\u57fa\u91d1\u6d41\u884c\u73b0\u8c61\uff0c\u6307\u51fa\u5b9e\u8bc1\u663e\u793a\u5c0f\u57fa\u91d1\u5185\u90e8\u6536\u76ca\u7387\u8868\u73b0\u66f4\u597d\uff0c\u5efa\u8bae\u6295\u8d44\u8005\u91cd\u65b0\u5ba1\u89c6\u6295\u8d44\u5206\u914d\u7b56\u7565\u3002", "motivation": "\u8d28\u7591\u5927\u57fa\u91d1\u56e0\u89c4\u6a21\u4f18\u52bf\u66f4\u53d7\u6b22\u8fce\u7684\u6743\u5a01\u89c2\u70b9\uff0c\u63a2\u7a76\u5c0f\u57fa\u91d1\u7684\u4f18\u52bf\u3002", "method": "\u5f15\u7528\u5b9e\u8bc1\u7814\u7a76\u8bc1\u660e\u5c0f\u57fa\u91d1\u5185\u90e8\u6536\u76ca\u7387\u6bd4\u5927\u57fa\u91d1\u66f4\u597d\u3002", "result": "\u53d1\u73b0\u5c0f\u57fa\u91d1\u5728\u5185\u90e8\u6536\u76ca\u7387\u65b9\u9762\u4f18\u4e8e\u5927\u57fa\u91d1\u3002", "conclusion": "\u6295\u8d44\u8005\u5e94\u91cd\u65b0\u5ba1\u89c6\u81ea\u52a8\u4f18\u5148\u914d\u7f6e\u5927\u57fa\u91d1\u7684\u7b56\u7565\u3002"}}
{"id": "2507.11733", "pdf": "https://arxiv.org/pdf/2507.11733", "abs": "https://arxiv.org/abs/2507.11733", "authors": ["Srikanth Vemula"], "title": "ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making", "categories": ["cs.AI"], "comment": null, "summary": "This Study introduces Clarity and Reasoning Interface for Artificial\nIntelligence(ClarifAI), a novel approach designed to augment the transparency\nand interpretability of artificial intelligence (AI) in the realm of improved\ndecision making. Leveraging the Case-Based Reasoning (CBR) methodology and\nintegrating an ontology-driven approach, ClarifAI aims to meet the intricate\nexplanatory demands of various stakeholders involved in AI-powered\napplications. The paper elaborates on ClarifAI's theoretical foundations,\ncombining CBR and ontologies to furnish exhaustive explanation mechanisms. It\nfurther elaborates on the design principles and architectural blueprint,\nhighlighting ClarifAI's potential to enhance AI interpretability across\ndifferent sectors and its applicability in high-stake environments. This\nresearch delineates the significant role of ClariAI in advancing the\ninterpretability of AI systems, paving the way for its deployment in critical\ndecision-making processes.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86ClarifAI\u65b9\u6cd5\uff0c\u7ed3\u5408CBR\u548c\u672c\u4f53\u9a71\u52a8\u65b9\u6cd5\u589e\u5f3aAI\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u589e\u5f3a\u4eba\u5de5\u667a\u80fd\u5728\u51b3\u7b56\u9886\u57df\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u6ee1\u8db3\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u7684\u89e3\u91ca\u9700\u6c42\u3002", "method": "\u5229\u7528\u57fa\u4e8e\u6848\u4f8b\u7684\u63a8\u7406\uff08CBR\uff09\u65b9\u6cd5\uff0c\u5e76\u96c6\u6210\u672c\u4f53\u9a71\u52a8\u65b9\u6cd5\u3002", "result": "\u9610\u8ff0\u4e86ClarifAI\u7684\u7406\u8bba\u57fa\u7840\u3001\u8bbe\u8ba1\u539f\u5219\u548c\u67b6\u6784\u84dd\u56fe\uff0c\u663e\u793a\u5176\u5728\u4e0d\u540c\u9886\u57df\u589e\u5f3aAI\u53ef\u89e3\u91ca\u6027\u7684\u6f5c\u529b\u3002", "conclusion": "ClarifAI\u5728\u63d0\u5347AI\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4e3a\u5173\u952e\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.11898", "pdf": "https://arxiv.org/pdf/2507.11898", "abs": "https://arxiv.org/abs/2507.11898", "authors": ["Rathin Singha", "Harry Qian", "Srinath Saikrishnan", "Tracy Zhao", "Ryan Beckett", "Siva Kesava Reddy Kakarla", "George Varghese"], "title": "Extremal Testing for Network Software using LLMs", "categories": ["cs.SE", "cs.NI"], "comment": null, "summary": "Physicists often manually consider extreme cases when testing a theory. In\nthis paper, we show how to automate extremal testing of network software using\nLLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS\nname length limits); then ask the LLM to generate tests that violate the\nconstraints. We demonstrate how easy this process is by generating extremal\ntests for HTTP, BGP and DNS implementations, each of which uncovered new bugs.\nWe show how this methodology extends to centralized network software such as\nshortest path algorithms, and how LLMs can generate filtering code to reject\nextremal input. We propose using agentic AI to further automate extremal\ntesting. LLM-generated extremal testing goes beyond an old technique in\nsoftware testing called Boundary Value Analysis.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u8fdb\u884c\u7f51\u7edc\u8f6f\u4ef6\u7684\u6781\u503c\u6d4b\u8bd5\uff0c\u901a\u8fc7\u751f\u6210\u8f93\u5165\u7ea6\u675f\u548c\u8fdd\u53cd\u7ea6\u675f\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u53d1\u73b0\u4e86\u65b0\u7684\u6f0f\u6d1e\uff0c\u5e76\u63a2\u8ba8\u4e86\u65b9\u6cd5\u7684\u6269\u5c55\u548c\u8fdb\u4e00\u6b65\u81ea\u52a8\u5316\u3002", "motivation": "\u5c06\u7269\u7406\u5b66\u5bb6\u624b\u52a8\u8003\u8651\u6781\u7aef\u60c5\u51b5\u6d4b\u8bd5\u7406\u8bba\u7684\u65b9\u5f0f\u81ea\u52a8\u5316\u5e94\u7528\u4e8e\u7f51\u7edc\u8f6f\u4ef6\u6d4b\u8bd5\u3002", "method": "\u5206\u4e24\u6b65\u4f7f\u7528LLM\uff0c\u5148\u8ba9\u5176\u751f\u6210\u8f93\u5165\u7ea6\u675f\uff0c\u518d\u751f\u6210\u8fdd\u53cd\u7ea6\u675f\u7684\u6d4b\u8bd5\u7528\u4f8b\uff1b\u8fd8\u63d0\u51fa\u4f7f\u7528\u4ee3\u7406\u5f0fAI\u8fdb\u4e00\u6b65\u81ea\u52a8\u5316\u3002", "result": "\u4e3aHTTP\u3001BGP\u548cDNS\u5b9e\u73b0\u751f\u6210\u6781\u503c\u6d4b\u8bd5\uff0c\u53d1\u73b0\u65b0\u6f0f\u6d1e\uff1b\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u96c6\u4e2d\u5f0f\u7f51\u7edc\u8f6f\u4ef6\uff0cLLM\u80fd\u751f\u6210\u8fc7\u6ee4\u4ee3\u7801\u3002", "conclusion": "LLM\u751f\u6210\u7684\u6781\u503c\u6d4b\u8bd5\u8d85\u8d8a\u4e86\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u8fb9\u754c\u503c\u5206\u6790\u6280\u672f\u3002"}}
{"id": "2507.11589", "pdf": "https://arxiv.org/pdf/2507.11589", "abs": "https://arxiv.org/abs/2507.11589", "authors": ["Sandeep Suresh Cranganore", "Andrei Bodnar", "Arturs Berzins", "Johannes Brandstetter"], "title": "Einstein Fields: A Neural Perspective To Computational General Relativity", "categories": ["cs.LG", "gr-qc"], "comment": "63 pages, 22 figures, 10 Tables, Github:\n  https://github.com/AndreiB137/EinFields", "summary": "We introduce Einstein Fields, a neural representation that is designed to\ncompress computationally intensive four-dimensional numerical relativity\nsimulations into compact implicit neural network weights. By modeling the\n\\emph{metric}, which is the core tensor field of general relativity, Einstein\nFields enable the derivation of physical quantities via automatic\ndifferentiation. However, unlike conventional neural fields (e.g., signed\ndistance, occupancy, or radiance fields), Einstein Fields are \\emph{Neural\nTensor Fields} with the key difference that when encoding the spacetime\ngeometry of general relativity into neural field representations, dynamics\nemerge naturally as a byproduct. Einstein Fields show remarkable potential,\nincluding continuum modeling of 4D spacetime, mesh-agnosticity, storage\nefficiency, derivative accuracy, and ease of use. We address these challenges\nacross several canonical test beds of general relativity and release an open\nsource JAX-based library, paving the way for more scalable and expressive\napproaches to numerical relativity. Code is made available at\nhttps://github.com/AndreiB137/EinFields", "AI": {"tldr": "\u63d0\u51faEinstein Fields\u5c06\u8ba1\u7b97\u5bc6\u96c6\u7684\u56db\u7ef4\u6570\u503c\u76f8\u5bf9\u8bba\u6a21\u62df\u538b\u7f29\u4e3a\u7d27\u51d1\u7684\u9690\u5f0f\u795e\u7ecf\u7f51\u7edc\u6743\u91cd\uff0c\u6709\u8bf8\u591a\u4f18\u52bf\u5e76\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u538b\u7f29\u8ba1\u7b97\u5bc6\u96c6\u7684\u56db\u7ef4\u6570\u503c\u76f8\u5bf9\u8bba\u6a21\u62df\uff0c\u63a2\u7d22\u66f4\u5177\u6269\u5c55\u6027\u548c\u8868\u73b0\u529b\u7684\u6570\u503c\u76f8\u5bf9\u8bba\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1Einstein Fields\u5bf9\u5e7f\u4e49\u76f8\u5bf9\u8bba\u7684\u6838\u5fc3\u5f20\u91cf\u573a\u2014\u2014\u5ea6\u89c4\u8fdb\u884c\u5efa\u6a21\uff0c\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u63a8\u5bfc\u7269\u7406\u91cf\u3002", "result": "Einstein Fields\u5728\u8fde\u7eed4D\u65f6\u7a7a\u5efa\u6a21\u3001\u65e0\u7f51\u683c\u6027\u3001\u5b58\u50a8\u6548\u7387\u3001\u5bfc\u6570\u7cbe\u5ea6\u548c\u6613\u7528\u6027\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6f5c\u529b\u3002", "conclusion": "\u5728\u591a\u4e2a\u5e7f\u4e49\u76f8\u5bf9\u8bba\u7684\u5178\u578b\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u9a8c\u8bc1Einstein Fields\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f00\u6e90\u57fa\u4e8eJAX\u7684\u5e93\uff0c\u4e3a\u6570\u503c\u76f8\u5bf9\u8bba\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.12021", "pdf": "https://arxiv.org/pdf/2507.12021", "abs": "https://arxiv.org/abs/2507.12021", "authors": ["Aleix Alcacer", "Irene Epifanio"], "title": "Incorporating Fairness Constraints into Archetypal Analysis", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Archetypal Analysis (AA) is an unsupervised learning method that represents\ndata as convex combinations of extreme patterns called archetypes. While AA\nprovides interpretable and low-dimensional representations, it can\ninadvertently encode sensitive attributes, leading to fairness concerns. In\nthis work, we propose Fair Archetypal Analysis (FairAA), a modified formulation\nthat explicitly reduces the influence of sensitive group information in the\nlearned projections. We also introduce FairKernelAA, a nonlinear extension that\naddresses fairness in more complex data distributions. Our approach\nincorporates a fairness regularization term while preserving the structure and\ninterpretability of the archetypes. We evaluate FairAA and FairKernelAA on\nsynthetic datasets, including linear, nonlinear, and multi-group scenarios,\ndemonstrating their ability to reduce group separability -- as measured by mean\nmaximum discrepancy and linear separability -- without substantially\ncompromising explained variance. We further validate our methods on the\nreal-world ANSUR I dataset, confirming their robustness and practical utility.\nThe results show that FairAA achieves a favorable trade-off between utility and\nfairness, making it a promising tool for responsible representation learning in\nsensitive applications.", "AI": {"tldr": "\u63d0\u51faFairAA\u548cFairKernelAA\u65b9\u6cd5\u51cf\u5c11\u654f\u611f\u5c5e\u6027\u5f71\u54cd\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u80fd\u5e73\u8861\u6548\u7528\u4e0e\u516c\u5e73\u6027\u3002", "motivation": "\u4f20\u7edfAA\u65b9\u6cd5\u4f1a\u65e0\u610f\u4e2d\u7f16\u7801\u654f\u611f\u5c5e\u6027\uff0c\u5f15\u53d1\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faFairAA\u4fee\u6539\u516c\u5f0f\uff0c\u5f15\u5165FairKernelAA\u975e\u7ebf\u6027\u6269\u5c55\uff0c\u52a0\u5165\u516c\u5e73\u6027\u6b63\u5219\u9879\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u51cf\u5c11\u7ec4\u53ef\u5206\u6027\uff0c\u4e0d\u5927\u5e45\u964d\u4f4e\u89e3\u91ca\u65b9\u5dee\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "FairAA\u5728\u6548\u7528\u548c\u516c\u5e73\u6027\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u662f\u654f\u611f\u5e94\u7528\u4e2d\u53ef\u9760\u8868\u793a\u5b66\u4e60\u7684\u6709\u524d\u666f\u5de5\u5177\u3002"}}
{"id": "2507.11762", "pdf": "https://arxiv.org/pdf/2507.11762", "abs": "https://arxiv.org/abs/2507.11762", "authors": ["Ogonnaya Michael Romanus", "Younes Boulaguiem", "Roberto Molinari"], "title": "Fiducial Matching: Differentially Private Inference for Categorical Data", "categories": ["stat.ME", "stat.CO", "stat.ML"], "comment": null, "summary": "The task of statistical inference, which includes the building of confidence\nintervals and tests for parameters and effects of interest to a researcher, is\nstill an open area of investigation in a differentially private (DP) setting.\nIndeed, in addition to the randomness due to data sampling, DP delivers another\nsource of randomness consisting of the noise added to protect an individual's\ndata from being disclosed to a potential attacker. As a result of this\nconvolution of noises, in many cases it is too complicated to determine the\nstochastic behavior of the statistics and parameters resulting from a DP\nprocedure. In this work, we contribute to this line of investigation by\nemploying a simulation-based matching approach, solved through tools from the\nfiducial framework, which aims to replicate the data generation pipeline\n(including the DP step) and retrieve an approximate distribution of the\nestimates resulting from this pipeline. For this purpose, we focus on the\nanalysis of categorical (nominal) data that is common in national surveys, for\nwhich sensitivity is naturally defined, and on additive privacy mechanisms. We\nprove the validity of the proposed approach in terms of coverage and highlight\nits good computational and statistical performance for different inferential\ntasks in simulated and applied data settings.", "AI": {"tldr": "\u672c\u6587\u91c7\u7528\u57fa\u4e8e\u6a21\u62df\u7684\u5339\u914d\u65b9\u6cd5\uff0c\u7ed3\u5408\u7f6e\u4fe1\u6846\u67b6\u5de5\u5177\uff0c\u7814\u7a76\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u73af\u5883\u4e0b\u5206\u7c7b\u6570\u636e\u7edf\u8ba1\u63a8\u65ad\uff0c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u6027\u5e76\u5c55\u793a\u5176\u826f\u597d\u6027\u80fd\u3002", "motivation": "DP\u73af\u5883\u4e0b\u7edf\u8ba1\u63a8\u65ad\u4ecd\u662f\u5f00\u653e\u7814\u7a76\u9886\u57df\uff0c\u56e0\u6570\u636e\u91c7\u6837\u548c\u566a\u58f0\u6dfb\u52a0\u5bfc\u81f4\u786e\u5b9a\u7edf\u8ba1\u91cf\u548c\u53c2\u6570\u968f\u673a\u884c\u4e3a\u590d\u6742\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6a21\u62df\u7684\u5339\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f6e\u4fe1\u6846\u67b6\u5de5\u5177\u89e3\u51b3\uff0c\u805a\u7126\u5206\u7c7b\u6570\u636e\u548c\u52a0\u6cd5\u9690\u79c1\u673a\u5236\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u8986\u76d6\u7387\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5728\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u4e2d\u5c55\u793a\u4e86\u826f\u597d\u8ba1\u7b97\u548c\u7edf\u8ba1\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u53ef\u7528\u4e8eDP\u73af\u5883\u4e0b\u5206\u7c7b\u6570\u636e\u7684\u4e0d\u540c\u63a8\u65ad\u4efb\u52a1\u3002"}}
{"id": "2507.11744", "pdf": "https://arxiv.org/pdf/2507.11744", "abs": "https://arxiv.org/abs/2507.11744", "authors": ["Marcin Kowalik", "Przemys\u0142aw Stok\u0142osa", "Mateusz Grabowski", "Janusz Starzyk", "Pawe\u0142 Raif"], "title": "A Cellular Automata Approach to Donation Game", "categories": ["cs.MA", "cs.GT", "physics.soc-ph"], "comment": "16 pages, 12 figures", "summary": "The donation game is a well-established framework for studying the emergence\nand evolution of cooperation in multi-agent systems. The cooperative behavior\ncan be influenced by the environmental noise in partially observable settings\nand by the decision-making strategies of agents, which may incorporate not only\nreputation but also traits such as generosity and forgiveness. Traditional\nsimulations often assume fully random interactions, where cooperation is tested\nbetween randomly selected agent pairs. In this paper, we investigate\ncooperation dynamics using the concept of Stephen Wolfram's one-dimensional\nbinary cellular automata. This approach allows us to explore how cooperation\nevolves when interactions are limited to neighboring agents. We define binary\ncellular automata rules that conform to the donation game mechanics.\nAdditionally, we introduce models of perceptual and action noise, along with a\nmutation matrix governing the probabilistic evolution of agent strategies. Our\nempirical results demonstrate that cooperation is significantly affected by\nagents' mobility and their spatial locality on the game board. These findings\nhighlight the importance of distinguishing between entirely random multi-agent\nsystems and those in which agents are more likely to interact with their\nnearest neighbors.", "AI": {"tldr": "\u672c\u6587\u7528\u4e00\u7ef4\u4e8c\u5143\u5143\u80de\u81ea\u52a8\u673a\u7814\u7a76\u6350\u8d60\u6e38\u620f\u4e2d\u5408\u4f5c\u52a8\u6001\uff0c\u53d1\u73b0\u5408\u4f5c\u53d7\u4e3b\u4f53\u79fb\u52a8\u6027\u548c\u7a7a\u95f4\u5c40\u90e8\u6027\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u6a21\u62df\u5e38\u5047\u8bbe\u5b8c\u5168\u968f\u673a\u4ea4\u4e92\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u4e3b\u4f53\u4ec5\u4e0e\u76f8\u90bb\u4e3b\u4f53\u4ea4\u4e92\u65f6\u5408\u4f5c\u5982\u4f55\u6f14\u5316\u3002", "method": "\u4f7f\u7528Stephen Wolfram\u7684\u4e00\u7ef4\u4e8c\u5143\u5143\u80de\u81ea\u52a8\u673a\u6982\u5ff5\uff0c\u5b9a\u4e49\u7b26\u5408\u6350\u8d60\u6e38\u620f\u673a\u5236\u7684\u89c4\u5219\uff0c\u5f15\u5165\u611f\u77e5\u548c\u884c\u52a8\u566a\u58f0\u6a21\u578b\u4ee5\u53ca\u7a81\u53d8\u77e9\u9635\u3002", "result": "\u5408\u4f5c\u663e\u8457\u53d7\u4e3b\u4f53\u79fb\u52a8\u6027\u548c\u6e38\u620f\u677f\u4e0a\u7a7a\u95f4\u5c40\u90e8\u6027\u5f71\u54cd\u3002", "conclusion": "\u533a\u5206\u5b8c\u5168\u968f\u673a\u591a\u4e3b\u4f53\u7cfb\u7edf\u548c\u4e3b\u4f53\u66f4\u53ef\u80fd\u4e0e\u8fd1\u90bb\u4ea4\u4e92\u7684\u7cfb\u7edf\u5f88\u91cd\u8981\u3002"}}
{"id": "2507.12304", "pdf": "https://arxiv.org/pdf/2507.12304", "abs": "https://arxiv.org/abs/2507.12304", "authors": ["Sophia Heimann", "Hung P. Hoang", "Stefan Hougardy"], "title": "A near-complete resolution of the exponential-time complexity of k-opt for the traveling salesman problem", "categories": ["cs.DS", "cs.DM", "68W25, 68W40, 68Q25, 90C27", "F.2.2; G.2.1; G.2.2"], "comment": "41 pages, 19 figures", "summary": "The $k$-opt algorithm is one of the simplest and most widely used heuristics\nfor solving the traveling salesman problem. Starting from an arbitrary tour,\nthe $k$-opt algorithm improves the current tour in each iteration by exchanging\nup to $k$ edges. The algorithm continues until no further improvement of this\nkind is possible. For a long time, it remained an open question how many\niterations the $k$-opt algorithm might require for small values of $k$,\nassuming the use of an optimal pivot rule. In this paper, we resolve this\nquestion for the cases $k = 3$ and $k = 4$ by proving that in both these cases\nan exponential number of iterations may be needed even if an optimal pivot rule\nis used. Combined with a recent result from Heimann, Hoang, and Hougardy (ICALP\n2024), this provides a complete answer for all $k \\geq 3$ regarding the number\nof iterations the $k$-opt algorithm may require under an optimal pivot rule. In\naddition we establish an analogous exponential lower bound for the 2.5-opt\nalgorithm, a variant that generalizes 2-opt and is a restricted version of\n3-opt. All our results hold for both the general and the metric traveling\nsalesman problem.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660ek=3\u548ck=4\u65f6k - opt\u7b97\u6cd5\u5728\u6700\u4f18\u67a2\u8f74\u89c4\u5219\u4e0b\u53ef\u80fd\u9700\u6307\u6570\u6b21\u8fed\u4ee3\uff0c\u7ed3\u5408\u5df2\u6709\u7ed3\u679c\u7ed9\u51fak\u22653\u65f6\u8fed\u4ee3\u6b21\u6570\u7684\u5b8c\u6574\u7b54\u6848\uff0c\u8fd8\u4e3a2.5 - opt\u7b97\u6cd5\u5efa\u7acb\u6307\u6570\u4e0b\u754c\uff0c\u7ed3\u679c\u9002\u7528\u4e8e\u4e00\u822c\u548c\u5ea6\u91cf\u65c5\u884c\u5546\u95ee\u9898\u3002", "motivation": "\u957f\u671f\u4ee5\u6765\uff0c\u5c0fk\u503c\u4e0bk - opt\u7b97\u6cd5\u5728\u6700\u4f18\u67a2\u8f74\u89c4\u5219\u4e0b\u6240\u9700\u8fed\u4ee3\u6b21\u6570\u662f\u5f00\u653e\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5bf9k = 3\u548ck = 4\u60c5\u51b5\u8fdb\u884c\u8bc1\u660e\uff0c\u7ed3\u5408Heimann\u7b49\u4eba\u7684\u8fd1\u671f\u7ed3\u679c\uff0c\u5e76\u4e3a2.5 - opt\u7b97\u6cd5\u5efa\u7acb\u7c7b\u4f3c\u4e0b\u754c\u3002", "result": "\u8bc1\u660ek = 3\u548ck = 4\u65f6k - opt\u7b97\u6cd5\u5728\u6700\u4f18\u67a2\u8f74\u89c4\u5219\u4e0b\u53ef\u80fd\u9700\u6307\u6570\u6b21\u8fed\u4ee3\uff0c\u4e3a2.5 - opt\u7b97\u6cd5\u5efa\u7acb\u6307\u6570\u4e0b\u754c\u3002", "conclusion": "\u4e3ak\u22653\u65f6k - opt\u7b97\u6cd5\u5728\u6700\u4f18\u67a2\u8f74\u89c4\u5219\u4e0b\u6240\u9700\u8fed\u4ee3\u6b21\u6570\u63d0\u4f9b\u5b8c\u6574\u7b54\u6848\uff0c\u7ed3\u679c\u9002\u7528\u4e8e\u4e00\u822c\u548c\u5ea6\u91cf\u65c5\u884c\u5546\u95ee\u9898\u3002"}}
{"id": "2507.12314", "pdf": "https://arxiv.org/pdf/2507.12314", "abs": "https://arxiv.org/abs/2507.12314", "authors": ["Zihao Xue", "Zhen Bi", "Long Ma", "Zhenlin Hu", "Yan Wang", "Zhenfang Liu", "Qing Sheng", "Jie Xiao", "Jungang Lou"], "title": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CR"], "comment": null, "summary": "While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,\nDeepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large\nLanguage Models (LLMs) domain, their susceptibility to security threats remains\na critical vulnerability. This weakness is particularly evident in\nChain-of-Thought (CoT) generation processes, where adversarial methods like\nbackdoor prompt attacks can systematically subvert the model's core reasoning\nmechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this\nvulnerability through exploiting prompt controllability, simultaneously\ndegrading both CoT safety and task performance with low-cost interventions. To\naddress this compounded security-performance vulnerability, we propose Thought\nPurity (TP): a defense paradigm that systematically strengthens resistance to\nmalicious content while preserving operational efficacy. Our solution achieves\nthis through three synergistic components: (1) a safety-optimized data\nprocessing pipeline (2) reinforcement learning-enhanced rule constraints (3)\nadaptive monitoring metrics. Our approach establishes the first comprehensive\ndefense mechanism against CoTA vulnerabilities in reinforcement\nlearning-aligned reasoning systems, significantly advancing the\nsecurity-functionality equilibrium for next-generation AI architectures.", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u5927\u63a8\u7406\u6a21\u578b\u6709\u63a8\u7406\u80fd\u529b\u4f46\u6613\u53d7\u653b\u51fb\uff0c\u63d0\u51faThought Purity\u9632\u5fa1\u8303\u5f0f\u589e\u5f3a\u5b89\u5168\u6027\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u5927\u63a8\u7406\u6a21\u578b\u5728\u601d\u7ef4\u94fe\u751f\u6210\u8fc7\u7a0b\u4e2d\u6613\u53d7\u653b\u51fb\uff0c\u5b58\u5728\u5b89\u5168\u4e0e\u6027\u80fd\u65b9\u9762\u7684\u6f0f\u6d1e\uff0c\u9700\u8981\u89e3\u51b3\u3002", "method": "\u63d0\u51faThought Purity\u9632\u5fa1\u8303\u5f0f\uff0c\u5305\u542b\u5b89\u5168\u4f18\u5316\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\u3001\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u7684\u89c4\u5219\u7ea6\u675f\u548c\u81ea\u9002\u5e94\u76d1\u63a7\u6307\u6807\u4e09\u4e2a\u534f\u540c\u7ec4\u4ef6\u3002", "result": "\u5efa\u7acb\u4e86\u9488\u5bf9\u601d\u7ef4\u94fe\u653b\u51fb\u6f0f\u6d1e\u7684\u9996\u4e2a\u5168\u9762\u9632\u5fa1\u673a\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63a8\u8fdb\u4e86\u4e0b\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u67b6\u6784\u7684\u5b89\u5168 - \u529f\u80fd\u5e73\u8861\u3002"}}
{"id": "2507.12311", "pdf": "https://arxiv.org/pdf/2507.12311", "abs": "https://arxiv.org/abs/2507.12311", "authors": ["Zhangcheng Qiang"], "title": "An Ecosystem for Ontology Interoperability", "categories": ["cs.IR"], "comment": "4 pages, 8 figures", "summary": "Ontology interoperability is one of the complicated issues that restricts the\nuse of ontologies in knowledge graphs (KGs). Different ontologies with\nconflicting and overlapping concepts make it difficult to design, develop, and\ndeploy an interoperable ontology for downstream tasks. We propose an ecosystem\nfor ontology interoperability. The ecosystem employs three state-of-the-art\nsemantic techniques in different phases of the ontology engineering life cycle:\nontology design patterns (ODPs) in the design phase, ontology matching and\nversioning (OM\\&OV) in the develop phase, and ontology-compliant knowledge\ngraphs (OCKGs) in the deploy phase, to achieve better ontology interoperability\nin real-world applications. A case study in the building domain validates the\nusefulness of the proposed ecosystem.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u672c\u4f53\u4e92\u64cd\u4f5c\u6027\u7684\u751f\u6001\u7cfb\u7edf\uff0c\u7528\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u7528\u6027", "motivation": "\u672c\u4f53\u4e92\u64cd\u4f5c\u6027\u662f\u9650\u5236\u77e5\u8bc6\u56fe\u8c31\u4e2d\u672c\u4f53\u4f7f\u7528\u7684\u590d\u6742\u95ee\u9898\uff0c\u4e0d\u540c\u672c\u4f53\u6982\u5ff5\u51b2\u7a81\u91cd\u53e0\uff0c\u96be\u4ee5\u8bbe\u8ba1\u5f00\u53d1\u90e8\u7f72\u4e92\u64cd\u4f5c\u672c\u4f53", "method": "\u5728\u672c\u4f53\u5de5\u7a0b\u751f\u547d\u5468\u671f\u4e0d\u540c\u9636\u6bb5\u91c7\u7528\u4e09\u79cd\u8bed\u4e49\u6280\u672f\uff0c\u8bbe\u8ba1\u9636\u6bb5\u7528\u672c\u4f53\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5f00\u53d1\u9636\u6bb5\u7528\u672c\u4f53\u5339\u914d\u548c\u7248\u672c\u63a7\u5236\uff0c\u90e8\u7f72\u9636\u6bb5\u7528\u7b26\u5408\u672c\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31", "result": "\u901a\u8fc7\u5efa\u7b51\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u751f\u6001\u7cfb\u7edf\u7684\u6709\u7528\u6027", "conclusion": "\u6240\u63d0\u51fa\u7684\u751f\u6001\u7cfb\u7edf\u80fd\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u672c\u4f53\u4e92\u64cd\u4f5c\u6027"}}
{"id": "2507.11830", "pdf": "https://arxiv.org/pdf/2507.11830", "abs": "https://arxiv.org/abs/2507.11830", "authors": ["Samyam Rajbhandari", "Mert Hidayetoglu", "Aurick Qiao", "Ye Wang", "Juncheng Yang", "Jeff Rasley", "Michael Wyatt", "Yuxiong He"], "title": "Arctic Inference with Shift Parallelism: Fast and Efficient Open Source Inference System for Enterprise AI", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Inference is now the dominant AI workload, yet existing systems force\ntrade-offs between latency, throughput, and cost. Arctic Inference, an\nopen-source vLLM plugin from Snowflake AI Research, introduces Shift\nParallelism, a dynamic parallelism strategy that adapts to real-world traffic\nwhile integrating speculative decoding, SwiftKV compute reduction, and\noptimized embedding inference. It achieves up to 3.4 times faster request\ncompletion, 1.75 times faster generation, and 1.6M tokens/sec per GPU for\nembeddings, outperforming both latency- and throughput-optimized deployments.\nAlready powering Snowflake Cortex AI, Arctic Inference delivers\nstate-of-the-art, cost-effective inference for enterprise AI and is now\navailable to the community.", "AI": {"tldr": "Arctic Inference \u662f Snowflake AI Research \u7684\u5f00\u6e90 vLLM \u63d2\u4ef6\uff0c\u5f15\u5165 Shift Parallelism \u7b56\u7565\uff0c\u5b9e\u73b0\u66f4\u5feb\u63a8\u7406\uff0c\u6027\u80fd\u4f18\u8d8a\uff0c\u5df2\u7528\u4e8e Snowflake Cortex AI \u5e76\u5411\u793e\u533a\u5f00\u653e\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u5728\u63a8\u7406\u65f6\u9700\u5728\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u6210\u672c\u4e4b\u95f4\u6743\u8861\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165 Shift Parallelism \u52a8\u6001\u5e76\u884c\u7b56\u7565\uff0c\u96c6\u6210\u6295\u673a\u89e3\u7801\u3001SwiftKV \u8ba1\u7b97\u7f29\u51cf\u548c\u4f18\u5316\u5d4c\u5165\u63a8\u7406\u3002", "result": "\u5b9e\u73b0\u9ad8\u8fbe 3.4 \u500d\u66f4\u5feb\u7684\u8bf7\u6c42\u5b8c\u6210\u30011.75 \u500d\u66f4\u5feb\u7684\u751f\u6210\u901f\u5ea6\uff0c\u6bcf GPU \u5d4c\u5165\u63a8\u7406\u8fbe 160 \u4e07\u4ee4\u724c/\u79d2\uff0c\u6027\u80fd\u4f18\u4e8e\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4f18\u5316\u90e8\u7f72\u3002", "conclusion": "Arctic Inference \u4e3a\u4f01\u4e1a AI \u63d0\u4f9b\u4e86\u6700\u5148\u8fdb\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u63a8\u7406\u65b9\u6848\uff0c\u5e76\u5df2\u5411\u793e\u533a\u5f00\u653e\u3002"}}
{"id": "2507.12207", "pdf": "https://arxiv.org/pdf/2507.12207", "abs": "https://arxiv.org/abs/2507.12207", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution", "categories": ["cs.AI", "cs.NE"], "comment": "ICML 2025 CO-Build Workshop Poster", "summary": "Accurate building energy forecasting is essential, yet traditional heuristics\noften lack precision, while advanced models can be opaque and struggle with\ngeneralization by neglecting physical principles. This paper introduces\nBuildEvo, a novel framework that uses Large Language Models (LLMs) to\nautomatically design effective and interpretable energy prediction heuristics.\nWithin an evolutionary process, BuildEvo guides LLMs to construct and enhance\nheuristics by systematically incorporating physical insights from building\ncharacteristics and operational data (e.g., from the Building Data Genome\nProject 2). Evaluations show BuildEvo achieves state-of-the-art performance on\nbenchmarks, offering improved generalization and transparent prediction logic.\nThis work advances the automated design of robust, physically grounded\nheuristics, promoting trustworthy models for complex energy systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdBuildEvo\u6846\u67b6\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bbe\u8ba1\u6709\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u5efa\u7b51\u80fd\u8017\u9884\u6d4b\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u8fbe\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u7f3a\u4e4f\u7cbe\u5ea6\uff0c\u5148\u8fdb\u6a21\u578b\u4e0d\u900f\u660e\u4e14\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u9700\u51c6\u786e\u7684\u5efa\u7b51\u80fd\u8017\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f15\u5165BuildEvo\u6846\u67b6\uff0c\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u5efa\u7b51\u7279\u5f81\u548c\u8fd0\u884c\u6570\u636e\u7684\u7269\u7406\u89c1\u89e3\u6765\u6784\u5efa\u548c\u6539\u8fdb\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "BuildEvo\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u900f\u660e\u7684\u9884\u6d4b\u903b\u8f91\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u52a8\u4e86\u57fa\u4e8e\u7269\u7406\u7684\u9c81\u68d2\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u81ea\u52a8\u8bbe\u8ba1\uff0c\u4fc3\u8fdb\u590d\u6742\u80fd\u6e90\u7cfb\u7edf\u7684\u53ef\u9760\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2507.11737", "pdf": "https://arxiv.org/pdf/2507.11737", "abs": "https://arxiv.org/abs/2507.11737", "authors": ["Chenyu Zhou", "Jingyuan Yang", "Linwei Xin", "Yitian Chen", "Ziyan He", "Dongdong Ge"], "title": "Auto-Formulating Dynamic Programming Problems with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Dynamic programming (DP) is a fundamental method in operations research, but\nformulating DP models has traditionally required expert knowledge of both the\nproblem context and DP techniques. Large Language Models (LLMs) offer the\npotential to automate this process. However, DP problems pose unique challenges\ndue to their inherently stochastic transitions and the limited availability of\ntraining data. These factors make it difficult to directly apply existing\nLLM-based models or frameworks developed for other optimization problems, such\nas linear or integer programming. We introduce DP-Bench, the first benchmark\ncovering a wide range of textbook-level DP problems to enable systematic\nevaluation. We present Dynamic Programming Language Model (DPLM), a\n7B-parameter specialized model that achieves performance comparable to\nstate-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on\nhard problems. Central to DPLM's effectiveness is DualReflect, our novel\nsynthetic data generation pipeline, designed to scale up training data from a\nlimited set of initial examples. DualReflect combines forward generation for\ndiversity and backward generation for reliability. Our results reveal a key\ninsight: backward generation is favored in low-data regimes for its strong\ncorrectness guarantees, while forward generation, though lacking such\nguarantees, becomes increasingly valuable at scale for introducing diverse\nformulations. This trade-off highlights the complementary strengths of both\napproaches and the importance of combining them.", "AI": {"tldr": "\u63d0\u51faDP - Bench\u57fa\u51c6\u8bc4\u4f30DP\u95ee\u9898\uff0c\u4ecb\u7ecdDPLM\u6a21\u578b\u53caDualReflect\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u63ed\u793a\u524d\u540e\u5411\u751f\u6210\u7684\u6743\u8861\u3002", "motivation": "\u4f20\u7edfDP\u6a21\u578b\u5236\u5b9a\u9700\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u6709LLM\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8eDP\u95ee\u9898\uff0c\u9700\u8bc4\u4f30\u65b9\u6cd5\u548c\u9002\u7528\u6a21\u578b\u3002", "method": "\u5f15\u5165DP - Bench\u57fa\u51c6\uff0c\u6784\u5efa7B\u53c2\u6570\u7684DPLM\u6a21\u578b\uff0c\u91c7\u7528DualReflect\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u7ed3\u5408\u524d\u540e\u5411\u751f\u6210\u3002", "result": "DPLM\u6027\u80fd\u4e0e\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\uff0c\u5728\u96be\u9898\u4e0a\u66f4\u4f18\uff0c\u63ed\u793a\u524d\u540e\u5411\u751f\u6210\u5728\u4e0d\u540c\u6570\u636e\u89c4\u6a21\u4e0b\u7684\u7279\u70b9\u3002", "conclusion": "\u524d\u540e\u5411\u751f\u6210\u65b9\u6cd5\u4f18\u52bf\u4e92\u8865\uff0c\u7ed3\u5408\u4e24\u8005\u5f88\u91cd\u8981\u3002"}}
{"id": "2507.11976", "pdf": "https://arxiv.org/pdf/2507.11976", "abs": "https://arxiv.org/abs/2507.11976", "authors": ["Jana-Rebecca Rehse", "Michael Grohs", "Finn Klessascheck", "Lisa-Marie Klein", "Tatiana von Landesberger", "Luise Pufahl"], "title": "A Task Taxonomy for Conformance Checking", "categories": ["cs.SE"], "comment": "Preprint submitted to Information Systems", "summary": "Conformance checking is a sub-discipline of process mining, which compares\nobserved process traces with a process model to analyze whether the process\nexecution conforms with or deviates from the process design. Organizations can\nleverage this analysis, for example to check whether their processes comply\nwith internal or external regulations or to identify potential improvements.\nGaining these insights requires suitable visualizations, which make complex\nresults accessible and actionable. So far, however, the development of\nconformance checking visualizations has largely been left to tool vendors. As a\nresult, current tools offer a wide variety of visual representations for\nconformance checking, but the analytical purposes they serve often remain\nunclear. However, without a systematic understanding of these purposes, it is\ndifficult to evaluate the visualizations' usefulness. Such an evaluation hence\nrequires a deeper understanding of conformance checking as an analysis domain.\nTo this end, we propose a task taxonomy, which categorizes the tasks that can\noccur when conducting conformance checking analyses. This taxonomy supports\nresearchers in determining the purpose of visualizations, specifying relevant\nconformance checking tasks in terms of their goal, means, constraint type, data\ncharacteristics, data target, and data cardinality. Combining concepts from\nprocess mining and visual analytics, we address researchers from both\ndisciplines to enable and support closer collaborations.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u4e00\u81f4\u6027\u68c0\u67e5\u5206\u6790\u7684\u4efb\u52a1\u5206\u7c7b\u6cd5\uff0c\u4fc3\u8fdb\u8fc7\u7a0b\u6316\u6398\u548c\u53ef\u89c6\u5316\u5206\u6790\u5b66\u79d1\u5408\u4f5c\u3002", "motivation": "\u73b0\u6709\u4e00\u81f4\u6027\u68c0\u67e5\u53ef\u89c6\u5316\u5de5\u5177\u7684\u5206\u6790\u76ee\u7684\u4e0d\u660e\u786e\uff0c\u7f3a\u4e4f\u5bf9\u5176\u7528\u9014\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u7ed3\u5408\u8fc7\u7a0b\u6316\u6398\u548c\u53ef\u89c6\u5316\u5206\u6790\u6982\u5ff5\uff0c\u63d0\u51fa\u4efb\u52a1\u5206\u7c7b\u6cd5\uff0c\u4ece\u591a\u65b9\u9762\u5bf9\u4e00\u81f4\u6027\u68c0\u67e5\u4efb\u52a1\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u6784\u5efa\u4e86\u4efb\u52a1\u5206\u7c7b\u6cd5\uff0c\u53ef\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u786e\u5b9a\u53ef\u89c6\u5316\u76ee\u7684\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u80fd\u4fc3\u8fdb\u8fc7\u7a0b\u6316\u6398\u548c\u53ef\u89c6\u5316\u5206\u6790\u9886\u57df\u7814\u7a76\u4eba\u5458\u7684\u7d27\u5bc6\u5408\u4f5c\u3002"}}
{"id": "2507.11590", "pdf": "https://arxiv.org/pdf/2507.11590", "abs": "https://arxiv.org/abs/2507.11590", "authors": ["Raju Challagundla", "Mohsen Dorodchi", "Pu Wang", "Minwoo Lee"], "title": "Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques", "categories": ["cs.LG"], "comment": null, "summary": "As privacy regulations become more stringent and access to real-world data\nbecomes increasingly constrained, synthetic data generation has emerged as a\nvital solution, especially for tabular datasets, which are central to domains\nlike finance, healthcare and the social sciences. This survey presents a\ncomprehensive and focused review of recent advances in synthetic tabular data\ngeneration, emphasizing methods that preserve complex feature relationships,\nmaintain statistical fidelity, and satisfy privacy requirements. A key\ncontribution of this work is the introduction of a novel taxonomy based on\npractical generation objectives, including intended downstream applications,\nprivacy guarantees, and data utility, directly informing methodological design\nand evaluation strategies. Therefore, this review prioritizes the actionable\ngoals that drive synthetic data creation, including conditional generation and\nrisk-sensitive modeling. Additionally, the survey proposes a benchmark\nframework to align technical innovation with real-world demands. By bridging\ntheoretical foundations with practical deployment, this work serves as both a\nroadmap for future research and a guide for implementing synthetic tabular data\nin privacy-critical environments.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u7684\u8fdb\u5c55\uff0c\u5f15\u5165\u65b0\u5206\u7c7b\u6cd5\uff0c\u63d0\u51fa\u57fa\u51c6\u6846\u67b6\uff0c\u4e3a\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u9690\u79c1\u6cd5\u89c4\u8d8b\u4e25\uff0c\u771f\u5b9e\u6570\u636e\u83b7\u53d6\u53d7\u9650\uff0c\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u6210\u4e3a\u91cd\u8981\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5bf9\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u7684\u8fd1\u671f\u8fdb\u5c55\u8fdb\u884c\u5168\u9762\u4e14\u6709\u9488\u5bf9\u6027\u7684\u7efc\u8ff0\uff0c\u5f15\u5165\u57fa\u4e8e\u5b9e\u9645\u751f\u6210\u76ee\u6807\u7684\u65b0\u5206\u7c7b\u6cd5\uff0c\u63d0\u51fa\u57fa\u51c6\u6846\u67b6\u3002", "result": "\u5b8c\u6210\u5bf9\u5408\u6210\u8868\u683c\u6570\u636e\u751f\u6210\u8fdb\u5c55\u7684\u7efc\u8ff0\uff0c\u5f15\u5165\u65b0\u5206\u7c7b\u6cd5\u5e76\u63d0\u51fa\u57fa\u51c6\u6846\u67b6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u8def\u7ebf\u56fe\uff0c\u6307\u5bfc\u5728\u9690\u79c1\u5173\u952e\u73af\u5883\u4e2d\u5e94\u7528\u5408\u6210\u8868\u683c\u6570\u636e\u3002"}}
{"id": "2507.11784", "pdf": "https://arxiv.org/pdf/2507.11784", "abs": "https://arxiv.org/abs/2507.11784", "authors": ["Joel Montesinos-Vazquez", "Gabriel N\u00fa\u00f1ez-Antonio"], "title": "Bayesian multivariate models for bounded directional data", "categories": ["stat.ME", "stat.CO", "62H11, 62F15"], "comment": "21 pages, 8 figures", "summary": "In some areas of knowledge there are data representing directions restricted\nto a specific range of values. Consequently, it is useful to have models for\ndescribing variables defined in subsets of the k-dimensional unit sphere. This\nneed has led to the development of models such as the multivariate projected\nGamma distribution. However, the proposal of multivariate models whose marginal\nvariables are defined only in sections of the unit circle and with a flexible\ndependency structure is limited. In this work, we propose constructing\nmultivariate models where each marginal variable is a circular variable defined\nonly in the first quadrant of the unit circle. Our approach is based on the\nconcept of copula functions. The inferences for the proposed models rely on\ngenerating samples of the posterior joint density of all parameters involved in\nthe models. This is achieved by applying a conditional approach that allows\ninferences to be made using a two-stage sampling. The proposed methodology is\nillustrated with both simulated and real data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8ecopula\u51fd\u6570\u6784\u5efa\u591a\u53d8\u91cf\u6a21\u578b\uff0c\u5404\u8fb9\u7f18\u53d8\u91cf\u4e3a\u4ec5\u5b9a\u4e49\u5728\u5355\u4f4d\u5706\u7b2c\u4e00\u8c61\u9650\u7684\u5faa\u73af\u53d8\u91cf\uff0c\u901a\u8fc7\u6761\u4ef6\u65b9\u6cd5\u8fdb\u884c\u63a8\u65ad\u5e76\u7ed3\u5408\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u8bf4\u660e\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u63cf\u8ff0\u5355\u4f4d\u7403\u5b50\u96c6\u53d8\u91cf\u7684\u6a21\u578b\u4e2d\uff0c\u8fb9\u7f18\u53d8\u91cf\u4ec5\u5b9a\u4e49\u5728\u5355\u4f4d\u5706\u90e8\u5206\u4e14\u5177\u6709\u7075\u6d3b\u4f9d\u8d56\u7ed3\u6784\u7684\u591a\u53d8\u91cf\u6a21\u578b\u8f83\u5c11\uff0c\u6709\u6784\u5efa\u6b64\u7c7b\u6a21\u578b\u7684\u9700\u6c42\u3002", "method": "\u57fa\u4e8ecopula\u51fd\u6570\u6784\u5efa\u591a\u53d8\u91cf\u6a21\u578b\uff0c\u901a\u8fc7\u6761\u4ef6\u65b9\u6cd5\u8fdb\u884c\u4e24\u9636\u6bb5\u62bd\u6837\u751f\u6210\u6a21\u578b\u6240\u6709\u53c2\u6570\u540e\u9a8c\u8054\u5408\u5bc6\u5ea6\u7684\u6837\u672c\u4ee5\u8fdb\u884c\u63a8\u65ad\u3002", "result": "\u4f7f\u7528\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u5bf9\u6240\u63d0\u65b9\u6cd5\u8fdb\u884c\u4e86\u8bf4\u660e\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6784\u5efa\u8fb9\u7f18\u53d8\u91cf\u4ec5\u5b9a\u4e49\u5728\u5355\u4f4d\u5706\u7b2c\u4e00\u8c61\u9650\u7684\u591a\u53d8\u91cf\u6a21\u578b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.12094", "pdf": "https://arxiv.org/pdf/2507.12094", "abs": "https://arxiv.org/abs/2507.12094", "authors": ["Yiding Feng", "Wei Tang"], "title": "Measuring Informativeness Gap of (Mis)Calibrated Predictors", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "In many applications, decision-makers must choose between multiple predictive\nmodels that may all be miscalibrated. Which model (i.e., predictor) is more\n\"useful\" in downstream decision tasks? To answer this, our first contribution\nintroduces the notion of the informativeness gap between any two predictors,\ndefined as the maximum normalized payoff advantage one predictor offers over\nthe other across all decision-making tasks. Our framework strictly generalizes\nseveral existing notions: it subsumes U-Calibration [KLST-23] and Calibration\nDecision Loss [HW-24], which compare a miscalibrated predictor to its\ncalibrated counterpart, and it recovers Blackwell informativeness [Bla-51,\nBla-53] as a special case when both predictors are perfectly calibrated. Our\nsecond contribution is a dual characterization of the informativeness gap,\nwhich gives rise to a natural informativeness measure that can be viewed as a\nrelaxed variant of the earth mover's distance (EMD) between two prediction\ndistributions. We show that this measure satisfies natural desiderata: it is\ncomplete and sound, and it can be estimated sample-efficiently in the\nprediction-only access setting. Along the way, we also obtain novel\ncombinatorial structural results when applying this measure to perfectly\ncalibrated predictors.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4fe1\u606f\u5dee\u8ddd\u6982\u5ff5\u6765\u8861\u91cf\u9884\u6d4b\u6a21\u578b\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u6709\u7528\u6027\uff0c\u7ed9\u51fa\u5bf9\u5076\u8868\u5f81\u548c\u4fe1\u606f\u5ea6\u91cf\uff0c\u8be5\u5ea6\u91cf\u6ee1\u8db3\u7406\u60f3\u7279\u6027\u4e14\u53ef\u9ad8\u6548\u4f30\u8ba1\u3002", "motivation": "\u89e3\u51b3\u5728\u591a\u4e2a\u53ef\u80fd\u6821\u51c6\u9519\u8bef\u7684\u9884\u6d4b\u6a21\u578b\u4e2d\uff0c\u786e\u5b9a\u54ea\u4e2a\u6a21\u578b\u5728\u4e0b\u6e38\u51b3\u7b56\u4efb\u52a1\u4e2d\u66f4\u6709\u7528\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4fe1\u606f\u5dee\u8ddd\u6982\u5ff5\uff0c\u7ed9\u51fa\u5176\u5bf9\u5076\u8868\u5f81\uff0c\u63d0\u51fa\u7c7b\u4f3c\u5730\u7403\u79fb\u52a8\u8ddd\u79bb\u7684\u4fe1\u606f\u5ea6\u91cf\u3002", "result": "\u4fe1\u606f\u5dee\u8ddd\u6846\u67b6\u63a8\u5e7f\u4e86\u73b0\u6709\u6982\u5ff5\uff0c\u4fe1\u606f\u5ea6\u91cf\u6ee1\u8db3\u81ea\u7136\u671f\u671b\u7279\u6027\uff0c\u53ef\u5728\u4ec5\u9884\u6d4b\u8bbf\u95ee\u8bbe\u7f6e\u4e0b\u9ad8\u6548\u4f30\u8ba1\uff0c\u8fd8\u83b7\u5f97\u4e86\u6821\u51c6\u826f\u597d\u9884\u6d4b\u5668\u7684\u7ec4\u5408\u7ed3\u6784\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4fe1\u606f\u5dee\u8ddd\u548c\u5ea6\u91cf\u53ef\u6709\u6548\u8bc4\u4f30\u9884\u6d4b\u6a21\u578b\u5728\u51b3\u7b56\u4efb\u52a1\u4e2d\u7684\u6709\u7528\u6027\u3002"}}
{"id": "2507.12357", "pdf": "https://arxiv.org/pdf/2507.12357", "abs": "https://arxiv.org/abs/2507.12357", "authors": ["Ariel Ben Eliezer", "Noam Nisan"], "title": "Online Block Packing", "categories": ["cs.DS", "cs.GT"], "comment": null, "summary": "We consider the algorithmic challenge that is faced by blockchains that have\nmultidimensional block constraints and serve quasi-patient bidders. We provide\nonline approximation algorithms for this problem, thus solving open problems\nleft by [Babaioff and Nisan, EC 2025].", "AI": {"tldr": "\u4e3a\u6709\u591a\u7ef4\u5757\u7ea6\u675f\u4e14\u670d\u52a1\u51c6\u8010\u5fc3\u6295\u6807\u4eba\u7684\u533a\u5757\u94fe\u7b97\u6cd5\u6311\u6218\u63d0\u4f9b\u5728\u7ebf\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u89e3\u51b3\u524d\u4eba\u9057\u7559\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6709\u591a\u7ef4\u5757\u7ea6\u675f\u4e14\u670d\u52a1\u51c6\u8010\u5fc3\u6295\u6807\u4eba\u7684\u533a\u5757\u94fe\u6240\u9762\u4e34\u7684\u7b97\u6cd5\u6311\u6218\uff0c\u5904\u7406\u524d\u4eba\u9057\u7559\u7684\u5f00\u653e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5728\u7ebf\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u5f97\u5230\u9002\u7528\u4e8e\u8be5\u95ee\u9898\u7684\u5728\u7ebf\u8fd1\u4f3c\u7b97\u6cd5\u3002", "conclusion": "\u6210\u529f\u89e3\u51b3\u4e86[Babaioff and Nisan, EC 2025]\u7559\u4e0b\u7684\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2507.12425", "pdf": "https://arxiv.org/pdf/2507.12425", "abs": "https://arxiv.org/abs/2507.12425", "authors": ["Chandana Cheerla"], "title": "Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.IR"], "comment": null, "summary": "Organizations increasingly rely on proprietary enterprise data, including HR\nrecords, structured reports, and tabular documents, for critical\ndecision-making. While Large Language Models (LLMs) have strong generative\ncapabilities, they are limited by static pretraining, short context windows,\nand challenges in processing heterogeneous data formats. Conventional\nRetrieval-Augmented Generation (RAG) frameworks address some of these gaps but\noften struggle with structured and semi-structured data.\n  This work proposes an advanced RAG framework that combines hybrid retrieval\nstrategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by\nmetadata-aware filtering with SpaCy NER and cross-encoder reranking. The\nframework applies semantic chunking to maintain textual coherence and retains\ntabular data structures to preserve row-column integrity. Quantized indexing\noptimizes retrieval efficiency, while human-in-the-loop feedback and\nconversation memory improve adaptability.\n  Experiments on enterprise datasets show notable improvements: Precision@5\nincreased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),\nand Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative\nevaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness\n(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.\nThese results demonstrate the framework's effectiveness in delivering accurate,\ncomprehensive, and contextually relevant responses for enterprise tasks. Future\nwork includes extending to multimodal data and integrating agent-based\nretrieval. The source code will be released at\nhttps://github.com/CheerlaChandana/Enterprise-Chatbot", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5148\u8fdbRAG\u6846\u67b6\u5904\u7406\u4f01\u4e1a\u6570\u636e\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u591a\u9879\u6307\u6807\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u672a\u6765\u5c06\u6269\u5c55\u5230\u591a\u6a21\u6001\u6570\u636e\u7b49\u3002", "motivation": "\u7ec4\u7ec7\u4f9d\u8d56\u4f01\u4e1a\u6570\u636e\u51b3\u7b56\uff0cLLMs\u6709\u5c40\u9650\uff0c\u4f20\u7edfRAG\u6846\u67b6\u5904\u7406\u7ed3\u6784\u5316\u548c\u534a\u7ed3\u6784\u5316\u6570\u636e\u6709\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u5bc6\u96c6\u5d4c\u5165\u548cBM25\u7684\u6df7\u5408\u68c0\u7d22\u7b56\u7565\uff0c\u7528SpaCy NER\u8fdb\u884c\u5143\u6570\u636e\u8fc7\u6ee4\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\uff0c\u5e94\u7528\u8bed\u4e49\u5206\u5757\uff0c\u4fdd\u7559\u8868\u683c\u7ed3\u6784\uff0c\u91c7\u7528\u91cf\u5316\u7d22\u5f15\uff0c\u7ed3\u5408\u4eba\u5de5\u53cd\u9988\u548c\u5bf9\u8bdd\u8bb0\u5fc6\u3002", "result": "\u5728\u4f01\u4e1a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cPrecision@5\u63d0\u9ad815%\uff0cRecall@5\u63d0\u9ad813%\uff0cMean Reciprocal Rank\u63d0\u9ad816%\uff1b\u5b9a\u6027\u8bc4\u4f30\u4e2d\uff0c\u5fe0\u5b9e\u6027\u3001\u5b8c\u6574\u6027\u548c\u76f8\u5173\u6027\u5f97\u5206\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u4e3a\u4f01\u4e1a\u4efb\u52a1\u63d0\u4f9b\u51c6\u786e\u3001\u5168\u9762\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u54cd\u5e94\uff0c\u672a\u6765\u5c06\u6269\u5c55\u5230\u591a\u6a21\u6001\u6570\u636e\u548c\u96c6\u6210\u57fa\u4e8e\u4ee3\u7406\u7684\u68c0\u7d22\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
{"id": "2507.12378", "pdf": "https://arxiv.org/pdf/2507.12378", "abs": "https://arxiv.org/abs/2507.12378", "authors": ["Rachna Saxena", "Abhijeet Kumar", "Suresh Shanmugam"], "title": "Developing Visual Augmented Q&A System using Scalable Vision Embedding Retrieval & Late Interaction Re-ranker", "categories": ["cs.IR", "cs.CL"], "comment": "Presented at NLP@IR workshop at SIGIR conference", "summary": "Traditional information extraction systems face challenges with text only\nlanguage models as it does not consider infographics (visual elements of\ninformation) such as tables, charts, images etc. often used to convey complex\ninformation to readers. Multimodal LLM (MLLM) face challenges of finding needle\nin the haystack problem i.e., either longer context length or substantial\nnumber of documents as search space. Late interaction mechanism over visual\nlanguage models has shown state of the art performance in retrieval-based\nvision augmented Q&A tasks. There are yet few challenges using it for RAG based\nmulti-modal Q&A. Firstly, many popular and widely adopted vector databases do\nnot support native multi-vector retrieval. Secondly, late interaction requires\ncomputation which inflates space footprint and can hinder enterprise adoption.\nLastly, the current state of late interaction mechanism does not leverage the\napproximate neighbor search indexing methods for large speed ups in retrieval\nprocess. This paper explores a pragmatic approach to make vision retrieval\nprocess scalable and efficient without compromising on performance quality. We\npropose multi-step custom implementation utilizing widely adopted hybrid search\n(metadata & embedding) and state of the art late interaction re-ranker to\nretrieve best matching pages. Finally, MLLM are prompted as reader to generate\nanswers from contextualized best matching pages. Through experiments, we\nobserve that the proposed design is scalable (significant speed up) and stable\n(without degrading performance quality), hence can be used as production\nsystems at enterprises.", "AI": {"tldr": "\u4f20\u7edf\u4fe1\u606f\u63d0\u53d6\u7cfb\u7edf\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u5b9e\u7528\u65b9\u6cd5\u4f7f\u89c6\u89c9\u68c0\u7d22\u53ef\u6269\u5c55\u9ad8\u6548\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u8bbe\u8ba1\u53ef\u7528\u4e8e\u4f01\u4e1a\u751f\u4ea7\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u4fe1\u606f\u63d0\u53d6\u7cfb\u7edf\u672a\u8003\u8651\u4fe1\u606f\u56fe\u8868\uff0c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6709\u68c0\u7d22\u96be\u9898\uff0c\u665a\u4ea4\u4e92\u673a\u5236\u7528\u4e8e\u57fa\u4e8eRAG\u7684\u591a\u6a21\u6001\u95ee\u7b54\u5b58\u5728\u6311\u6218\uff0c\u9700\u4f7f\u89c6\u89c9\u68c0\u7d22\u8fc7\u7a0b\u53ef\u6269\u5c55\u9ad8\u6548\u3002", "method": "\u63d0\u51fa\u591a\u6b65\u81ea\u5b9a\u4e49\u5b9e\u73b0\uff0c\u5229\u7528\u6df7\u5408\u641c\u7d22\u548c\u665a\u4ea4\u4e92\u91cd\u6392\u5668\u68c0\u7d22\u5339\u914d\u9875\u9762\uff0c\u8ba9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u9875\u9762\u751f\u6210\u7b54\u6848\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u63d0\u51fa\u7684\u8bbe\u8ba1\u53ef\u6269\u5c55\uff08\u663e\u8457\u52a0\u901f\uff09\u4e14\u7a33\u5b9a\uff08\u4e0d\u964d\u4f4e\u6027\u80fd\u8d28\u91cf\uff09\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u53ef\u4f5c\u4e3a\u4f01\u4e1a\u7684\u751f\u4ea7\u7cfb\u7edf\u4f7f\u7528\u3002"}}
{"id": "2507.11899", "pdf": "https://arxiv.org/pdf/2507.11899", "abs": "https://arxiv.org/abs/2507.11899", "authors": ["Saeid Aghasoleymani Najafabadi"], "title": "Performance Assessment of Load Balancing Methods in Cloud Computing: Analysis of Round Robin, Equally Spread, and Throttled Strategies Using Cloud Analyst", "categories": ["cs.DC"], "comment": null, "summary": "Load balancing plays a pivotal role in cloud computing, ensuring that\nresources are optimally allocated to maintain high service quality and\noperational efficiency. As workloads in cloud environments become increasingly\ndynamic and unpredictable, load balancing strategies are evolving from\ntraditional static methods to more adaptive and intelligent approaches. In this\nstudy, the Cloud Analyst simulation tool was used to evaluate the performance\nof different load balancing algorithms under various scenarios, including both\ncentralized and distributed resource setups. The results highlight that while\nthe Round Robin algorithm yields slightly better processing times within a\nsingle data center, Equally Spread and Throttled techniques perform\ncompetitively, especially when network latency is considered. More importantly,\nwhen resources are distributed across multiple data centers, response times are\nsignificantly reduced, emphasizing the value of proximity and efficient load\ndistribution. In these distributed environments, Equally Spread and Throttled\nalgorithms not only maintain quick response times but also contribute to lower\noperational costs. These findings demonstrate the necessity of strategic\nresource placement and proactive infrastructure planning to balance performance\nand cost. Adopting intelligent, dynamic load balancing and resource management\npractices can help organizations meet evolving cloud demands, optimize costs,\nand maintain a competitive advantage. Continuous evaluation and integration of\nemerging technologies are crucial for sustaining effective and scalable cloud\noperations.", "AI": {"tldr": "\u7814\u7a76\u7528Cloud Analyst\u8bc4\u4f30\u4e0d\u540c\u8d1f\u8f7d\u5747\u8861\u7b97\u6cd5\u5728\u591a\u79cd\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5206\u5e03\u5f0f\u8d44\u6e90\u8bbe\u7f6e\u53ef\u964d\u4f4e\u54cd\u5e94\u65f6\u95f4\u548c\u6210\u672c\uff0c\u5f3a\u8c03\u6218\u7565\u8d44\u6e90\u90e8\u7f72\u548c\u52a8\u6001\u7ba1\u7406\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u4e91\u73af\u5883\u5de5\u4f5c\u8d1f\u8f7d\u52a8\u6001\u4e14\u4e0d\u53ef\u9884\u6d4b\uff0c\u4f20\u7edf\u9759\u6001\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u9700\u5411\u81ea\u9002\u5e94\u548c\u667a\u80fd\u65b9\u6cd5\u8f6c\u53d8\uff0c\u9700\u8bc4\u4f30\u4e0d\u540c\u7b97\u6cd5\u6027\u80fd\u3002", "method": "\u4f7f\u7528Cloud Analyst\u6a21\u62df\u5de5\u5177\uff0c\u5728\u96c6\u4e2d\u548c\u5206\u5e03\u5f0f\u8d44\u6e90\u8bbe\u7f6e\u7b49\u591a\u79cd\u573a\u666f\u4e0b\u8bc4\u4f30\u4e0d\u540c\u8d1f\u8f7d\u5747\u8861\u7b97\u6cd5\u6027\u80fd\u3002", "result": "Round Robin\u7b97\u6cd5\u5728\u5355\u6570\u636e\u4e2d\u5fc3\u5904\u7406\u65f6\u95f4\u7565\u4f18\uff1bEqually Spread\u548cThrottled\u6280\u672f\u5728\u8003\u8651\u7f51\u7edc\u5ef6\u8fdf\u65f6\u7ade\u4e89\u529b\u5f3a\uff1b\u5206\u5e03\u5f0f\u8d44\u6e90\u8bbe\u7f6e\u53ef\u663e\u8457\u964d\u4f4e\u54cd\u5e94\u65f6\u95f4\uff0cEqually Spread\u548cThrottled\u7b97\u6cd5\u80fd\u4fdd\u6301\u5feb\u901f\u54cd\u5e94\u5e76\u964d\u4f4e\u6210\u672c\u3002", "conclusion": "\u9700\u6218\u7565\u8d44\u6e90\u90e8\u7f72\u548c\u4e3b\u52a8\u57fa\u7840\u8bbe\u65bd\u89c4\u5212\u4ee5\u5e73\u8861\u6027\u80fd\u548c\u6210\u672c\uff0c\u91c7\u7528\u667a\u80fd\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\u548c\u8d44\u6e90\u7ba1\u7406\u53ef\u6ee1\u8db3\u4e91\u9700\u6c42\u3001\u4f18\u5316\u6210\u672c\uff0c\u6301\u7eed\u8bc4\u4f30\u548c\u96c6\u6210\u65b0\u5174\u6280\u672f\u5bf9\u4e91\u8fd0\u8425\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.12306", "pdf": "https://arxiv.org/pdf/2507.12306", "abs": "https://arxiv.org/abs/2507.12306", "authors": ["Vassilis Papadopoulos", "Etienne Guichard"], "title": "MaCE: General Mass Conserving Dynamics for Cellular Automata", "categories": ["nlin.CG", "cs.NE", "nlin.AO"], "comment": null, "summary": "We present Mass-Conserving Evolution (MaCE), a general method for\nimplementing mass conservation in Cellular Automata (CA). MaCE is a simple\nevolution rule that can be easily 'attached' to existing CAs to make them\nmass-conserving, which tends to produce interesting behaviours more often, as\npatterns can no longer explode or die out. We first show that MaCE is\nnumerically stable and admits a simple continuous limit. We then test MaCE on\nLenia, and through several experiments, we demonstrate that it produces a wide\nvariety of interesting behaviours, starting from the variety and abundance of\nsolitons up to hints of intrinsic evolution in resource-constrained\nenvironments. Finally, we showcase the versatility of MaCE by applying it to\nNeural-CAs and discrete CAs, and discuss promising research directions opened\nup by this scheme.", "AI": {"tldr": "\u63d0\u51faMaCE\u65b9\u6cd5\u4f7f\u5143\u80de\u81ea\u52a8\u673a\u5b9e\u73b0\u8d28\u91cf\u5b88\u6052\uff0c\u5c55\u793a\u5176\u7a33\u5b9a\u6027\u3001\u5e94\u7528\u6548\u679c\u5e76\u63a2\u8ba8\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5b9e\u73b0\u5143\u80de\u81ea\u52a8\u673a\uff08CA\uff09\u7684\u8d28\u91cf\u5b88\u6052\uff0c\u4f7fCA\u4ea7\u751f\u66f4\u591a\u6709\u8da3\u884c\u4e3a\uff0c\u907f\u514d\u6a21\u5f0f\u7206\u70b8\u6216\u6d88\u4ea1\u3002", "method": "\u63d0\u51faMaCE\u8fd9\u4e00\u7b80\u5355\u8fdb\u5316\u89c4\u5219\u5e76\u9644\u52a0\u5230\u73b0\u6709CA\u4e0a\uff1b\u5148\u8bc1\u660eMaCE\u6570\u503c\u7a33\u5b9a\u6027\u548c\u8fde\u7eed\u6781\u9650\uff0c\u518d\u5728Lenia\u4e0a\u6d4b\u8bd5\uff0c\u6700\u540e\u5e94\u7528\u4e8eNeural - CAs\u548c\u79bb\u6563CAs\u3002", "result": "MaCE\u80fd\u4ea7\u751f\u591a\u79cd\u6709\u8da3\u884c\u4e3a\uff0c\u5982\u5b64\u5b50\u591a\u6837\u6027\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5185\u5728\u8fdb\u5316\u8ff9\u8c61\u3002", "conclusion": "MaCE\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.11787", "pdf": "https://arxiv.org/pdf/2507.11787", "abs": "https://arxiv.org/abs/2507.11787", "authors": ["Chandrashekar Muniyappa", "Eunjin Kim"], "title": "Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity", "categories": ["cs.AI", "68-68W50"], "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "summary": "Swarm Intelligence (SI) is gaining a lot of popularity in artificial\nintelligence, where the natural behavior of animals and insects is observed and\ntranslated into computer algorithms called swarm computing to solve real-world\nproblems. Due to their effectiveness, they are applied in solving various\ncomputer optimization problems. This survey will review all the latest\ndevelopments in Searching for documents based on semantic similarity using\nSwarm Intelligence algorithms and recommend future research directions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7fa4\u4f53\u667a\u80fd\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u53d7\u5173\u6ce8\uff0c\u53ef\u89e3\u51b3\u8ba1\u7b97\u673a\u4f18\u5316\u95ee\u9898\uff0c\u5c06\u7efc\u8ff0\u57fa\u4e8e\u7fa4\u4f53\u667a\u80fd\u7b97\u6cd5\u7684\u8bed\u4e49\u76f8\u4f3c\u6587\u6863\u641c\u7d22\u7684\u8fdb\u5c55\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7fa4\u4f53\u667a\u80fd\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u5f88\u53d7\u6b22\u8fce\u4e14\u53ef\u89e3\u51b3\u8ba1\u7b97\u673a\u4f18\u5316\u95ee\u9898\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u7efc\u8ff0\u5176\u5728\u8bed\u4e49\u76f8\u4f3c\u6587\u6863\u641c\u7d22\u65b9\u9762\u7684\u53d1\u5c55\u3002", "method": "\u8fdb\u884c\u76f8\u5173\u9886\u57df\u7684\u6587\u732e\u8c03\u7814\u3002", "result": "\u6587\u4e2d\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u4e2d\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\uff0c\u53ea\u662f\u8868\u793a\u4f1a\u63a8\u8350\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.12084", "pdf": "https://arxiv.org/pdf/2507.12084", "abs": "https://arxiv.org/abs/2507.12084", "authors": ["Keke Gai", "Haochen Liang", "Jing Yu", "Liehuang Zhu", "Dusit Niyato"], "title": "LLAMA: Multi-Feedback Smart Contract Fuzzing Framework with LLM-Guided Seed Generation", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Smart contracts play a pivotal role in blockchain ecosystems, and fuzzing\nremains an important approach to securing smart contracts. Even though mutation\nscheduling is a key factor influencing fuzzing effectiveness, existing fuzzers\nhave primarily explored seed scheduling and generation, while mutation\nscheduling has been rarely addressed by prior work. In this work, we propose a\nLarge Language Models (LLMs)-based Multi-feedback Smart Contract Fuzzing\nframework (LLAMA) that integrates LLMs, evolutionary mutation strategies, and\nhybrid testing techniques. Key components of the proposed LLAMA include: (i) a\nhierarchical prompting strategy that guides LLMs to generate semantically valid\ninitial seeds, coupled with a lightweight pre-fuzzing phase to select\nhigh-potential inputs; (ii) a multi-feedback optimization mechanism that\nsimultaneously improves seed generation, seed selection, and mutation\nscheduling by leveraging runtime coverage and dependency feedback; and (iii) an\nevolutionary fuzzing engine that dynamically adjusts mutation operator\nprobabilities based on effectiveness, while incorporating symbolic execution to\nescape stagnation and uncover deeper vulnerabilities. Our experiments\ndemonstrate that LLAMA outperforms state-of-the-art fuzzers in both coverage\nand vulnerability detection. Specifically, it achieves 91% instruction coverage\nand 90% branch coverage, while detecting 132 out of 148 known vulnerabilities\nacross diverse categories. These results highlight LLAMA's effectiveness,\nadaptability, and practicality in real-world smart contract security testing\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u5408\u7ea6\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6LLAMA\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u68c0\u6d4b\u4e0a\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u5668\u4e3b\u8981\u63a2\u7d22\u79cd\u5b50\u8c03\u5ea6\u548c\u751f\u6210\uff0c\u800c\u7a81\u53d8\u8c03\u5ea6\u7814\u7a76\u8f83\u5c11\uff0c\u9700\u63d0\u5347\u667a\u80fd\u5408\u7ea6\u6a21\u7cca\u6d4b\u8bd5\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faLLAMA\u6846\u67b6\uff0c\u5305\u542b\u5206\u5c42\u63d0\u793a\u7b56\u7565\u751f\u6210\u521d\u59cb\u79cd\u5b50\u3001\u591a\u53cd\u9988\u4f18\u5316\u673a\u5236\u6539\u8fdb\u79cd\u5b50\u548c\u7a81\u53d8\u8c03\u5ea6\u3001\u8fdb\u5316\u6a21\u7cca\u6d4b\u8bd5\u5f15\u64ce\u52a8\u6001\u8c03\u6574\u7a81\u53d8\u6982\u7387\u5e76\u7ed3\u5408\u7b26\u53f7\u6267\u884c\u3002", "result": "LLAMA\u5b9e\u73b091%\u6307\u4ee4\u8986\u76d6\u7387\u548c90%\u5206\u652f\u8986\u76d6\u7387\uff0c\u68c0\u6d4b\u51fa148\u4e2a\u5df2\u77e5\u6f0f\u6d1e\u4e2d\u7684132\u4e2a\u3002", "conclusion": "LLAMA\u5728\u771f\u5b9e\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u6d4b\u8bd5\u573a\u666f\u4e2d\u6709\u6548\u3001\u53ef\u9002\u5e94\u4e14\u5b9e\u7528\u3002"}}
{"id": "2507.11620", "pdf": "https://arxiv.org/pdf/2507.11620", "abs": "https://arxiv.org/abs/2507.11620", "authors": ["Steven Dillmann", "Juan Rafael Mart\u00ednez-Galarza"], "title": "Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification", "categories": ["cs.LG", "astro-ph.HE", "astro-ph.IM", "cs.AI"], "comment": "Accepted at the 2025 ICML Workshop on Machine Learning for\n  Astrophysics, Code available at:\n  https://github.com/StevenDillmann/ml-xraytransients-mnras", "summary": "Event time series are sequences of discrete events occurring at irregular\ntime intervals, each associated with a domain-specific observational modality.\nThey are common in domains such as high-energy astrophysics, computational\nsocial science, cybersecurity, finance, healthcare, neuroscience, and\nseismology. Their unstructured and irregular structure poses significant\nchallenges for extracting meaningful patterns and identifying salient phenomena\nusing conventional techniques. We propose novel two- and three-dimensional\ntensor representations for event time series, coupled with sparse autoencoders\nthat learn physically meaningful latent representations. These embeddings\nsupport a variety of downstream tasks, including anomaly detection,\nsimilarity-based retrieval, semantic clustering, and unsupervised\nclassification. We demonstrate our approach on a real-world dataset from X-ray\nastronomy, showing that these representations successfully capture temporal and\nspectral signatures and isolate diverse classes of X-ray transients. Our\nframework offers a flexible, scalable, and generalizable solution for analyzing\ncomplex, irregular event time series across scientific and industrial domains.", "AI": {"tldr": "\u63d0\u51fa\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\u7684\u65b0\u9896\u5f20\u91cf\u8868\u793a\u53ca\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u5728X\u5c04\u7ebf\u5929\u6587\u5b66\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u53ef\u7528\u4e8e\u591a\u4e0b\u6e38\u4efb\u52a1\uff0c\u4e3a\u590d\u6742\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u901a\u7528\u65b9\u6848\u3002", "motivation": "\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\u975e\u7ed3\u6784\u5316\u548c\u4e0d\u89c4\u5219\u7ed3\u6784\uff0c\u4f20\u7edf\u6280\u672f\u96be\u4ee5\u63d0\u53d6\u6a21\u5f0f\u548c\u8bc6\u522b\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u4e8c\u7ef4\u548c\u4e09\u7ef4\u5f20\u91cf\u8868\u793a\uff0c\u7ed3\u5408\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u6f5c\u5728\u8868\u793a\u3002", "result": "\u5728X\u5c04\u7ebf\u5929\u6587\u5b66\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u6210\u529f\u6355\u6349\u65f6\u95f4\u548c\u5149\u8c31\u7279\u5f81\uff0c\u5206\u79bb\u4e0d\u540c\u7c7b\u578bX\u5c04\u7ebf\u77ac\u53d8\u3002", "conclusion": "\u6846\u67b6\u4e3a\u8de8\u79d1\u5b66\u548c\u5de5\u4e1a\u9886\u57df\u7684\u590d\u6742\u4e0d\u89c4\u5219\u4e8b\u4ef6\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11706", "pdf": "https://arxiv.org/pdf/2507.11706", "abs": "https://arxiv.org/abs/2507.11706", "authors": ["Taira Tsuchiya", "Shinji Ito", "Haipeng Luo"], "title": "Reinforcement Learning from Adversarial Preferences in Tabular MDPs", "categories": ["cs.LG", "stat.ML"], "comment": "40 pages", "summary": "We introduce a new framework of episodic tabular Markov decision processes\n(MDPs) with adversarial preferences, which we refer to as preference-based MDPs\n(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the\nnumerical value of the loss is directly observed, in PbMDPs the learner instead\nobserves preferences between two candidate arms, which represent the choices\nbeing compared. In this work, we focus specifically on the setting where the\nreward functions are determined by Borda scores. We begin by establishing a\nregret lower bound for PbMDPs with Borda scores. As a preliminary step, we\npresent a simple instance to prove a lower bound of $\\Omega(\\sqrt{HSAT})$ for\nepisodic MDPs with adversarial losses, where $H$ is the number of steps per\nepisode, $S$ is the number of states, $A$ is the number of actions, and $T$ is\nthe number of episodes. Leveraging this construction, we then derive a regret\nlower bound of $\\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda\nscores, where $K$ is the number of arms. Next, we develop algorithms that\nachieve a regret bound of order $T^{2/3}$. We first propose a global\noptimization approach based on online linear optimization over the set of all\noccupancy measures, achieving a regret bound of $\\tilde{O}((H^2 S^2 K)^{1/3}\nT^{2/3} )$ under known transitions. However, this approach suffers from\nsuboptimal dependence on the potentially large number of states $S$ and\ncomputational inefficiency. To address this, we propose a policy optimization\nalgorithm whose regret is roughly bounded by $\\tilde{O}( (H^6 S K^5)^{1/3}\nT^{2/3} )$ under known transitions, and further extend the result to the\nunknown-transition setting.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.12100", "pdf": "https://arxiv.org/pdf/2507.12100", "abs": "https://arxiv.org/abs/2507.12100", "authors": ["Hannaneh Akrami", "Roshan Raj", "L\u00e1szl\u00f3 A. V\u00e9gh"], "title": "Matroids are Equitable", "categories": ["math.CO", "cs.DM", "cs.GT"], "comment": null, "summary": "We show that if the ground set of a matroid can be partitioned into $k\\ge 2$\nbases, then for any given subset $S$ of the ground set, there is a partition\ninto $k$ bases such that the sizes of the intersections of the bases with $S$\nmay differ by at most one. This settles the matroid equitability conjecture by\nFekete and Szab\\'o (Electron.~J.~Comb.~2011) in the affirmative. We also\ninvestigate equitable splittings of two disjoint sets $S_1$ and $S_2$, and show\nthat there is a partition into $k$ bases such that the sizes of the\nintersections with $S_1$ may differ by at most one and the sizes of the\nintersections with $S_2$ may differ by at most two; this is the best possible\none can hope for arbitrary matroids.\n  We also derive applications of this result into matroid constrained fair\ndivision problems. We show that there exists a matroid-constrained fair\ndivision that is envy-free up to 1 item if the valuations are identical and\ntri-valued additive. We also show that for bi-valued additive valuations, there\nexists a matroid-constrained allocation that provides everyone their maximin\nshare.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86\u53ef\u5c06\u62df\u9635\u57fa\u96c6\u5212\u5206\u4e3ak\u4e2a\u57fa\u65f6\uff0c\u5bf9\u7ed9\u5b9a\u5b50\u96c6S\u5b58\u5728\u7279\u5b9a\u5212\u5206\uff0c\u89e3\u51b3\u4e86\u62df\u9635\u516c\u5e73\u6027\u731c\u60f3\uff0c\u8fd8\u7814\u7a76\u4e86\u4e24\u4e2a\u4e0d\u76f8\u4ea4\u96c6\u7684\u516c\u5e73\u5212\u5206\u53ca\u5728\u516c\u5e73\u5206\u914d\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3Fekete\u548cSzab\u00f3\u63d0\u51fa\u7684\u62df\u9635\u516c\u5e73\u6027\u731c\u60f3\uff0c\u7814\u7a76\u62df\u9635\u5728\u516c\u5e73\u5206\u914d\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u8bc1\u660e\u5173\u4e8e\u62df\u9635\u57fa\u96c6\u5212\u5206\u53ca\u516c\u5e73\u5212\u5206\u7684\u76f8\u5173\u7ed3\u8bba\u3002", "result": "\u89e3\u51b3\u4e86\u62df\u9635\u516c\u5e73\u6027\u731c\u60f3\uff1b\u5bf9\u4e8e\u4e24\u4e2a\u4e0d\u76f8\u4ea4\u96c6S1\u548cS2\u6709\u7279\u5b9a\u516c\u5e73\u5212\u5206\u7ed3\u679c\uff1b\u5728\u62df\u9635\u7ea6\u675f\u516c\u5e73\u5206\u914d\u95ee\u9898\u4e2d\uff0c\u76f8\u540c\u4e09\u503c\u52a0\u6027\u4f30\u503c\u4e0b\u5b58\u5728\u65e01\u9879\u5ac9\u5992\u516c\u5e73\u5212\u5206\uff0c\u4e8c\u503c\u52a0\u6027\u4f30\u503c\u4e0b\u5b58\u5728\u63d0\u4f9b\u6700\u5927\u6700\u5c0f\u4efd\u989d\u7684\u5206\u914d\u3002", "conclusion": "\u80af\u5b9a\u89e3\u51b3\u4e86\u62df\u9635\u516c\u5e73\u6027\u731c\u60f3\uff0c\u6240\u5f97\u516c\u5e73\u5212\u5206\u7ed3\u679c\u5bf9\u62df\u9635\u7ea6\u675f\u516c\u5e73\u5206\u914d\u95ee\u9898\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.12005", "pdf": "https://arxiv.org/pdf/2507.12005", "abs": "https://arxiv.org/abs/2507.12005", "authors": ["Marta Piecyk", "Astrid Pieterse", "Pawe\u0142 Rz\u0105\u017cewski", "Magnus Wahlstr\u00f6m"], "title": "Kernelization for list $H$-coloring for graphs with small vertex cover", "categories": ["math.CO", "cs.DS"], "comment": null, "summary": "For a fixed graph $H$, in the List $H$-Coloring problem, we are given a graph\n$G$ along with list $L(v) \\subseteq V(H)$ for every $v \\in V(G)$, and we have\nto determine if there exists a list homomorphism $\\varphi$ from $(G,L)$ to $H$,\ni.e., an edge preserving mapping $\\varphi: V(G)\\to V(H)$ that satisfies\n$\\varphi(v)\\in L(v)$ for every $v\\in V(G)$. Note that if $H$ is the complete\ngraph on $q$ vertices, the problem is equivalent to List $q$-Coloring. We\ninvestigate the kernelization properties of List $H$-Coloring parameterized by\nthe vertex cover number of $G$: given an instance $(G,L)$ and a vertex cover of\n$G$ of size $k$, can we reduce $(G,L)$ to an equivalent instance $(G',L')$ of\nList $H$-Coloring where the size of $G'$ is bounded by a low-degree polynomial\n$p(k)$ in $k$? This question has been investigated previously by Jansen and\nPieterse [Algorithmica 2019], who provided an upper bound, which turns out to\nbe optimal if $H$ is a complete graph, i.e., for List $q$-Coloring. This result\nwas one of the first applications of the method of kernelization via\nbounded-degree polynomials. We define two new integral graph invariants,\n$c^*(H)$ and $d^*(H)$, with $d^*(H) \\leq c^*(H) \\leq d^*(H)+1$, and show that\nfor every graph $H$, List $H$-Coloring\n  -- has a kernel with $\\mathcal{O}(k^{c^*(H)})$ vertices,\n  -- admits no kernel of size $\\mathcal{O}(k^{d^*(H)-\\varepsilon})$ for any\n$\\varepsilon > 0$, unless the polynomial hierarchy collapses.\n  -- Furthermore, if $c^*(H) > d^*(H)$, then there is a kernel with\n$\\mathcal{O}(k^{c^*(H)-\\varepsilon})$ vertices where $\\varepsilon \\geq\n2^{1-c^*(H)}$.\n  Additionally, we show that for some classes of graphs, including powers of\ncycles and graphs $H$ where $\\Delta(H) \\leq c^*(H)$ (which in particular\nincludes cliques), the bound $d^*(H)$ is tight, using the polynomial method. We\nconjecture that this holds in general.", "AI": {"tldr": "\u7814\u7a76List $H$-Coloring\u95ee\u9898\u4ee5\u56fe$G$\u7684\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u7684\u6838\u5316\u6027\u8d28\uff0c\u5b9a\u4e49\u4e24\u4e2a\u56fe\u4e0d\u53d8\u91cf$c^*(H)$\u548c$d^*(H)$\uff0c\u7ed9\u51fa\u6838\u5927\u5c0f\u7684\u4e0a\u4e0b\u754c\u3002", "motivation": "\u63a2\u7a76List $H$-Coloring\u95ee\u9898\u4ee5\u56fe$G$\u7684\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u65f6\u80fd\u5426\u5c06\u5b9e\u4f8b\u7ea6\u7b80\u4e3a\u5927\u5c0f\u53d7$k$\u7684\u4f4e\u6b21\u591a\u9879\u5f0f\u9650\u5236\u7684\u7b49\u4ef7\u5b9e\u4f8b\u3002", "method": "\u5b9a\u4e49\u65b0\u7684\u56fe\u4e0d\u53d8\u91cf$c^*(H)$\u548c$d^*(H)$\uff0c\u4f7f\u7528\u591a\u9879\u5f0f\u65b9\u6cd5\u3002", "result": "\u5bf9\u4e8e\u6bcf\u4e2a\u56fe$H$\uff0c\u7ed9\u51faList $H$-Coloring\u95ee\u9898\u6838\u7684\u9876\u70b9\u6570\u4e0a\u4e0b\u754c\uff0c\u5bf9\u90e8\u5206\u56fe\u7c7b\u8bc1\u660e$d^*(H)$\u662f\u7d27\u7684\u3002", "conclusion": "\u82e5\u591a\u9879\u5f0f\u5c42\u7ea7\u4e0d\u5d29\u6e83\uff0cList $H$-Coloring\u95ee\u9898\u6838\u5927\u5c0f\u6709\u76f8\u5e94\u4e0a\u4e0b\u754c\uff0c\u63a8\u6d4b$d^*(H)$\u7684\u7d27\u6027\u666e\u904d\u6210\u7acb\u3002"}}
{"id": "2507.11764", "pdf": "https://arxiv.org/pdf/2507.11764", "abs": "https://arxiv.org/abs/2507.11764", "authors": ["Matteo Fasulo", "Luca Babboni", "Luca Tedeschini"], "title": "AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles", "categories": ["cs.CL", "cs.IR"], "comment": "14 pages, 6 figures, accepted at CLEF 2025 CheckThat! Lab", "summary": "This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab\nTask 1: Subjectivity Detection in News Articles, classifying sentences as\nsubjective/objective in monolingual, multilingual, and zero-shot settings.\nTraining/development datasets were provided for Arabic, German, English,\nItalian, and Bulgarian; final evaluation included additional unseen languages\n(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our\nprimary strategy enhanced transformer-based classifiers by integrating\nsentiment scores, derived from an auxiliary model, with sentence\nrepresentations, aiming to improve upon standard fine-tuning. We explored this\nsentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base\n(English), and Llama3.2-1B. To address class imbalance, prevalent across\nlanguages, we employed decision threshold calibration optimized on the\ndevelopment set. Our experiments show sentiment feature integration\nsignificantly boosts performance, especially subjective F1 score. This\nframework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdAI Wizards\u56e2\u961f\u53c2\u52a0CLEF 2025 CheckThat! Lab\u4efb\u52a11\uff0c\u63d0\u51fa\u7ed3\u5408\u60c5\u611f\u5206\u6570\u589e\u5f3a\u57fa\u4e8eTransformer\u7684\u5206\u7c7b\u5668\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u63d0\u5347\u6027\u80fd\u5e76\u83b7\u9ad8\u6392\u540d\u3002", "motivation": "\u53c2\u52a0CLEF 2025 CheckThat! Lab\u4efb\u52a11\uff0c\u5bf9\u65b0\u95fb\u6587\u7ae0\u8fdb\u884c\u4e3b\u89c2\u6027\u68c0\u6d4b\uff0c\u5728\u591a\u79cd\u8bed\u8a00\u8bbe\u7f6e\u4e0b\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5c06\u8f85\u52a9\u6a21\u578b\u5f97\u5230\u7684\u60c5\u611f\u5206\u6570\u4e0e\u53e5\u5b50\u8868\u5f81\u7ed3\u5408\uff0c\u589e\u5f3a\u57fa\u4e8eTransformer\u7684\u5206\u7c7b\u5668\uff0c\u91c7\u7528\u51b3\u7b56\u9608\u503c\u6821\u51c6\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4f7f\u7528mDeBERTaV3 - base\u3001ModernBERT - base\u548cLlama3.2 - 1B\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u60c5\u611f\u7279\u5f81\u96c6\u6210\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5c24\u5176\u662f\u4e3b\u89c2F1\u5206\u6570\uff0c\u8be5\u6846\u67b6\u83b7\u9ad8\u6392\u540d\uff0c\u5982\u5e0c\u814a\u8bed\u6392\u540d\u7b2c1\uff08Macro F1 = 0.51\uff09\u3002", "conclusion": "\u7ed3\u5408\u60c5\u611f\u5206\u6570\u589e\u5f3a\u57fa\u4e8eTransformer\u7684\u5206\u7c7b\u5668\u7684\u6846\u67b6\u5728\u65b0\u95fb\u6587\u7ae0\u4e3b\u89c2\u6027\u68c0\u6d4b\u4e2d\u6709\u6548\uff0c\u80fd\u63d0\u5347\u6027\u80fd\u5e76\u53d6\u5f97\u826f\u597d\u6392\u540d\u3002"}}
{"id": "2507.11929", "pdf": "https://arxiv.org/pdf/2507.11929", "abs": "https://arxiv.org/abs/2507.11929", "authors": ["Minchen Yu", "Yinghao Ren", "Jiamu Zhao", "Jiaqi Li"], "title": "Making Serverless Computing Extensible: A Case Study of Serverless Data Analytics", "categories": ["cs.DC"], "comment": null, "summary": "Serverless computing has attracted a broad range of applications due to its\nease of use and resource elasticity. However, developing serverless\napplications often poses a dilemma -- relying on general-purpose serverless\nplatforms can fall short of delivering satisfactory performance for complex\nworkloads, whereas building application-specific serverless systems undermines\nthe simplicity and generality. In this paper, we propose an extensible design\nprinciple for serverless computing. We argue that a platform should enable\ndevelopers to extend system behaviors for domain-specialized optimizations\nwhile retaining a shared, easy-to-use serverless environment. We take data\nanalytics as a representative serverless use case and realize this design\nprinciple in Proteus. Proteus introduces a novel abstraction of decision\nworkflows, allowing developers to customize control-plane behaviors for\nimproved application performance. Preliminary results show that Proteus's\nprototype effectively optimizes analytical query execution and supports\nfine-grained resource sharing across diverse applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7684\u53ef\u6269\u5c55\u8bbe\u8ba1\u539f\u5219\uff0c\u5e76\u5728Proteus\u4e2d\u5b9e\u73b0\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5176\u80fd\u4f18\u5316\u5206\u6790\u67e5\u8be2\u6267\u884c\u5e76\u652f\u6301\u7ec6\u7c92\u5ea6\u8d44\u6e90\u5171\u4eab\u3002", "motivation": "\u901a\u7528\u65e0\u670d\u52a1\u5668\u5e73\u53f0\u5bf9\u590d\u6742\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\u4e0d\u4f73\uff0c\u800c\u7279\u5b9a\u5e94\u7528\u7cfb\u7edf\u4f1a\u7834\u574f\u7b80\u5355\u6027\u548c\u901a\u7528\u6027\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u8bbe\u8ba1\u539f\u5219\uff0c\u4ee5\u6570\u636e\u5206\u6790\u4e3a\u4f8b\uff0c\u5728Proteus\u4e2d\u5f15\u5165\u51b3\u7b56\u5de5\u4f5c\u6d41\u62bd\u8c61\uff0c\u8ba9\u5f00\u53d1\u8005\u5b9a\u5236\u63a7\u5236\u5e73\u9762\u884c\u4e3a\u3002", "result": "Proteus\u539f\u578b\u6709\u6548\u4f18\u5316\u5206\u6790\u67e5\u8be2\u6267\u884c\uff0c\u652f\u6301\u8de8\u4e0d\u540c\u5e94\u7528\u7684\u7ec6\u7c92\u5ea6\u8d44\u6e90\u5171\u4eab\u3002", "conclusion": "\u6240\u63d0\u8bbe\u8ba1\u539f\u5219\u53ef\u884c\uff0c\u80fd\u5728\u4fdd\u7559\u6613\u7528\u73af\u5883\u7684\u540c\u65f6\u5b9e\u73b0\u9886\u57df\u4f18\u5316\u3002"}}
{"id": "2507.11916", "pdf": "https://arxiv.org/pdf/2507.11916", "abs": "https://arxiv.org/abs/2507.11916", "authors": ["Ehsan Futuhi", "Nathan R. Sturtevant"], "title": "A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS", "categories": ["cs.AI", "cs.DC"], "comment": null, "summary": "The rapid advancement of GPU technology has unlocked powerful parallel\nprocessing capabilities, creating new opportunities to enhance classic search\nalgorithms. A recent successful application of GPUs is in compressing large\npattern database (PDB) heuristics using neural networks while preserving\nheuristic admissibility. However, very few algorithms have been designed to\nexploit GPUs during search. Several variants of A* exist that batch GPU\ncomputations. In this paper we introduce a method for batching GPU computations\nin depth first search. In particular, we describe a new cost-bounded\ndepth-first search (CB-DFS) method that leverages the combined parallelism of\nmodern CPUs and GPUs. This is used to create algorithms like \\emph{Batch IDA*},\nan extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an\nextensions of Budgeted Tree Search. Our approach builds on the general approach\nused by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality\nguarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding\ntile puzzle (STP), showing that GPU operations can be efficiently batched in\nDFS. Additionally, we conduct extensive experiments to analyze the effects of\nhyperparameters, neural network heuristic size, and hardware resources on\nperformance.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5728\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u4e2d\u6279\u91cf\u8fdb\u884cGPU\u8ba1\u7b97\u7684\u65b9\u6cd5\uff0c\u521b\u5efa\u4e86Batch IDA*\u548cBatch BTS\u7b49\u7b97\u6cd5\uff0c\u57283x3\u9b54\u65b9\u548c4x4\u6ed1\u52a8\u62fc\u56fe\u4e0a\u8bc4\u4f30\uff0c\u8868\u660e\u80fd\u6709\u6548\u6279\u91cf\u6267\u884cGPU\u64cd\u4f5c\uff0c\u5e76\u5206\u6790\u4e86\u8d85\u53c2\u6570\u7b49\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "GPU\u6280\u672f\u53d1\u5c55\u5e26\u6765\u65b0\u673a\u9047\uff0c\u4f46\u641c\u7d22\u4e2d\u5229\u7528GPU\u7684\u7b97\u6cd5\u5f88\u5c11\uff0c\u65e8\u5728\u8bbe\u8ba1\u5728\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u4e2d\u5229\u7528GPU\u5e76\u884c\u8ba1\u7b97\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u6210\u672c\u6709\u754c\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\uff08CB - DFS\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u73b0\u4ee3CPU\u548cGPU\u7684\u5e76\u884c\u6027\uff0c\u57fa\u4e8e\u5f02\u6b65\u5e76\u884cIDA*\uff08AIDA*\uff09\u65b9\u6cd5\uff0c\u521b\u5efaBatch IDA*\u548cBatch BTS\u7b49\u7b97\u6cd5\u3002", "result": "\u57283x3\u9b54\u65b9\u548c4x4\u6ed1\u52a8\u62fc\u56fe\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u80fd\u5728\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u4e2d\u6709\u6548\u6279\u91cf\u6267\u884cGPU\u64cd\u4f5c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u5728\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u4e2d\u6709\u6548\u6279\u91cf\u8fdb\u884cGPU\u8ba1\u7b97\uff0c\u540c\u65f6\u4fdd\u8bc1\u6700\u4f18\u6027\uff0c\u4e14\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e86\u8d85\u53c2\u6570\u3001\u795e\u7ecf\u7f51\u7edc\u542f\u53d1\u5f0f\u5927\u5c0f\u548c\u786c\u4ef6\u8d44\u6e90\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.12104", "pdf": "https://arxiv.org/pdf/2507.12104", "abs": "https://arxiv.org/abs/2507.12104", "authors": ["Francisco Javier Cavero", "Juan C. Alonso", "Antonio Ruiz-Cort\u00e9s"], "title": "From Static to Intelligent: Evolving SaaS Pricing with LLMs", "categories": ["cs.SE", "cs.AI"], "comment": "12 pages. Accepted at the SOC4AI Workshop (Service-Oriented Computing\n  for AI Applications), held in conjunction with the 22nd International\n  Conference on Service-Oriented Computing (ICSOC 2024)", "summary": "The SaaS paradigm has revolutionized software distribution by offering\nflexible pricing options to meet diverse customer needs. However, the rapid\nexpansion of the SaaS market has introduced significant complexity for DevOps\nteams, who must manually manage and evolve pricing structures, an approach that\nis both time-consuming and prone to errors. The absence of automated tools for\npricing analysis restricts the ability to efficiently evaluate, optimize, and\nscale these models. This paper proposes leveraging intelligent pricing\n(iPricing), dynamic, machine-readable pricing models, as a solution to these\nchallenges. Intelligent pricing enables competitive analysis, streamlines\noperational decision-making, and supports continuous pricing evolution in\nresponse to market dynamics, leading to improved efficiency and accuracy. We\npresent an LLM-driven approach that automates the transformation of static HTML\npricing into iPricing, significantly improving efficiency and consistency while\nminimizing human error. Our implementation, AI4Pricing2Yaml, features a basic\nInformation Extractor that uses web scraping and LLMs technologies to extract\nessential pricing components, plans, features, usage limits, and add-ons, from\nSaaS websites. Validation against a dataset of 30 distinct commercial SaaS,\nencompassing over 150 intelligent pricings, demonstrates the system's\neffectiveness in extracting the desired elements across all steps. However,\nchallenges remain in addressing hallucinations, complex structures, and dynamic\ncontent. This work highlights the potential of automating intelligent pricing\ntransformation to streamline SaaS pricing management, offering implications for\nimproved consistency and scalability in an increasingly intricate pricing\nlandscape. Future research will focus on refining extraction capabilities and\nenhancing the system's adaptability to a wider range of SaaS websites.", "AI": {"tldr": "SaaS\u5e02\u573a\u53d1\u5c55\u4f7f\u5b9a\u4ef7\u7ba1\u7406\u590d\u6742\uff0c\u672c\u6587\u63d0\u51fa\u667a\u80fd\u5b9a\u4ef7\u89e3\u51b3\u65b9\u6848\uff0c\u7528LLM\u9a71\u52a8\u65b9\u6cd5\u5c06\u9759\u6001HTML\u5b9a\u4ef7\u8f6c\u4e3a\u667a\u80fd\u5b9a\u4ef7\uff0c\u9a8c\u8bc1\u6709\u6548\u4f46\u6709\u6311\u6218\uff0c\u672a\u6765\u5c06\u6539\u8fdb\u3002", "motivation": "SaaS\u5e02\u573a\u5feb\u901f\u6269\u5f20\u4f7fDevOps\u56e2\u961f\u624b\u52a8\u7ba1\u7406\u5b9a\u4ef7\u7ed3\u6784\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u5b9a\u4ef7\u5206\u6790\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u667a\u80fd\u5b9a\u4ef7\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u91c7\u7528LLM\u9a71\u52a8\u65b9\u6cd5\u5c06\u9759\u6001HTML\u5b9a\u4ef7\u8f6c\u6362\u4e3a\u667a\u80fd\u5b9a\u4ef7\uff0c\u5b9e\u73b0\u4fe1\u606f\u63d0\u53d6\u3002", "result": "\u901a\u8fc7\u5bf930\u4e2a\u4e0d\u540c\u5546\u4e1aSaaS\u7684\u9a8c\u8bc1\uff0c\u7cfb\u7edf\u80fd\u6709\u6548\u63d0\u53d6\u6240\u9700\u5143\u7d20\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u3001\u590d\u6742\u7ed3\u6784\u548c\u52a8\u6001\u5185\u5bb9\u7b49\u6311\u6218\u3002", "conclusion": "\u81ea\u52a8\u5316\u667a\u80fd\u5b9a\u4ef7\u8f6c\u6362\u53ef\u7b80\u5316SaaS\u5b9a\u4ef7\u7ba1\u7406\uff0c\u672a\u6765\u9700\u63d0\u5347\u63d0\u53d6\u80fd\u529b\u548c\u7cfb\u7edf\u9002\u5e94\u6027\u3002"}}
{"id": "2507.11639", "pdf": "https://arxiv.org/pdf/2507.11639", "abs": "https://arxiv.org/abs/2507.11639", "authors": ["Fouad Oubari", "Raphael Meunier", "Rodrigue D\u00e9catoire", "Mathilde Mougeot"], "title": "Deep Generative Methods and Tire Architecture Design", "categories": ["cs.LG"], "comment": null, "summary": "As deep generative models proliferate across the AI landscape, industrial\npractitioners still face critical yet unanswered questions about which deep\ngenerative models best suit complex manufacturing design tasks. This work\naddresses this question through a complete study of five representative models\n(Variational Autoencoder, Generative Adversarial Network, multimodal\nVariational Autoencoder, Denoising Diffusion Probabilistic Model, and\nMultinomial Diffusion Model) on industrial tire architecture generation. Our\nevaluation spans three key industrial scenarios: (i) unconditional generation\nof complete multi-component designs, (ii) component-conditioned generation\n(reconstructing architectures from partial observations), and (iii)\ndimension-constrained generation (creating designs that satisfy specific\ndimensional requirements). To enable discrete diffusion models to handle\nconditional scenarios, we introduce categorical inpainting, a mask-aware\nreverse diffusion process that preserves known labels without requiring\nadditional training. Our evaluation employs geometry-aware metrics specifically\ncalibrated for industrial requirements, quantifying spatial coherence,\ncomponent interaction, structural connectivity, and perceptual fidelity. Our\nfindings reveal that diffusion models achieve the strongest overall\nperformance; a masking-trained VAE nonetheless outperforms the multimodal\nvariant MMVAE\\textsuperscript{+} on nearly all component-conditioned metrics,\nand within the diffusion family MDM leads in-distribution whereas DDPM\ngeneralises better to out-of-distribution dimensional constraints.", "AI": {"tldr": "\u7814\u7a76\u4e94\u79cd\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5728\u5de5\u4e1a\u8f6e\u80ce\u67b6\u6784\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u8bc4\u4f30\u4e0d\u540c\u573a\u666f\uff0c\u53d1\u73b0\u6269\u6563\u6a21\u578b\u603b\u4f53\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5de5\u4e1a\u4ece\u4e1a\u8005\u4e0d\u6e05\u695a\u54ea\u79cd\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u6700\u9002\u5408\u590d\u6742\u5236\u9020\u8bbe\u8ba1\u4efb\u52a1\uff0c\u672c\u6587\u4ee5\u5de5\u4e1a\u8f6e\u80ce\u67b6\u6784\u751f\u6210\u4e3a\u4f8b\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u5bf9\u4e94\u79cd\u4ee3\u8868\u6027\u6a21\u578b\u5728\u4e09\u79cd\u5de5\u4e1a\u573a\u666f\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5f15\u5165\u5206\u7c7b\u4fee\u590d\u65b9\u6cd5\u4f7f\u79bb\u6563\u6269\u6563\u6a21\u578b\u5904\u7406\u6761\u4ef6\u573a\u666f\uff0c\u91c7\u7528\u51e0\u4f55\u611f\u77e5\u6307\u6807\u91cf\u5316\u8bc4\u4f30\u3002", "result": "\u6269\u6563\u6a21\u578b\u603b\u4f53\u6027\u80fd\u6700\u5f3a\uff0c\u63a9\u7801\u8bad\u7ec3\u7684VAE\u5728\u591a\u6570\u7ec4\u4ef6\u6761\u4ef6\u6307\u6807\u4e0a\u4f18\u4e8eMMVAE\u207a\uff0cMDM\u5728\u5206\u5e03\u5185\u9886\u5148\uff0cDDPM\u5bf9\u5206\u5e03\u5916\u7ef4\u5ea6\u7ea6\u675f\u6cdb\u5316\u6027\u66f4\u597d\u3002", "conclusion": "\u660e\u786e\u4e86\u4e0d\u540c\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5728\u5de5\u4e1a\u8f6e\u80ce\u67b6\u6784\u751f\u6210\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2507.12265", "pdf": "https://arxiv.org/pdf/2507.12265", "abs": "https://arxiv.org/abs/2507.12265", "authors": ["Zihan Zhu", "Dongchao Wu", "Zhanbang Zhang", "Jian Yang"], "title": "FastReChain: Highly Responsive and Low-Overhead Centralized Route Scheduling in Clos Datacenter Networks", "categories": ["cs.NI", "cs.DS"], "comment": null, "summary": "Ever since Clos topologies were used in datacenter networks (DCNs), a\npractical centralized scheduling algorithm that supports dynamic scheduling has\nbeen absent. The introduction of optical switches in DCNs as a future-proof\nsolution exacerbates this problem due to several properties of optical\nswitches, such as the fact that they are generally bufferless and therefore\nrely on centralized scheduling, and that they have long switching times and\ntherefore require the number of rearrangements to be minimized.\n  In this paper, we propose a centralized scheduling algorithm that achieves\ntheoretical maximum throughput even in one-rate bidirectional Clos networks,\nwhile producing schemes with near-minimal numbers of rearrangements. It is the\nonly algorithm that directly supports bidirectional Clos networks and has a\ntime efficiency high enough to support dynamic scheduling to date. For static\nminimal rewiring, its running time ranges from a fraction to a few hundredths\nof other algorithms, and the number of rearrangements has also been steadily\nimproved, allowing for more frequent adjustments and less impact on ongoing\ncommunications. In addition, the algorithm is very flexible and can support\nvarious functional requirements in real-world environments. We achieve this\nresult through the replacement chain concept and bitset optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9002\u7528\u4e8e\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u7684\u96c6\u4e2d\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5229\u7528\u66ff\u6362\u94fe\u548c\u4f4d\u96c6\u4f18\u5316\uff0c\u5b9e\u73b0\u6700\u5927\u541e\u5410\u91cf\uff0c\u51cf\u5c11\u91cd\u6392\u6b21\u6570\u4e14\u652f\u6301\u52a8\u6001\u8c03\u5ea6\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u91c7\u7528Clos\u62d3\u6251\u540e\u7f3a\u4e4f\u5b9e\u7528\u7684\u52a8\u6001\u96c6\u4e2d\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5f15\u5165\u5149\u5f00\u5173\u52a0\u5267\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u66ff\u6362\u94fe\u6982\u5ff5\u548c\u4f4d\u96c6\u4f18\u5316\u3002", "result": "\u7b97\u6cd5\u80fd\u5728\u5355\u901f\u7387\u53cc\u5411Clos\u7f51\u7edc\u4e2d\u5b9e\u73b0\u7406\u8bba\u6700\u5927\u541e\u5410\u91cf\uff0c\u91cd\u6392\u6b21\u6570\u63a5\u8fd1\u6700\u5c0f\uff0c\u8fd0\u884c\u65f6\u95f4\u77ed\uff0c\u53ef\u652f\u6301\u52a8\u6001\u8c03\u5ea6\u4e14\u7075\u6d3b\u6027\u9ad8\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u662f\u76ee\u524d\u552f\u4e00\u76f4\u63a5\u652f\u6301\u53cc\u5411Clos\u7f51\u7edc\u4e14\u65f6\u95f4\u6548\u7387\u8db3\u4ee5\u652f\u6301\u52a8\u6001\u8c03\u5ea6\u7684\u7b97\u6cd5\uff0c\u80fd\u6ee1\u8db3\u73b0\u5b9e\u73af\u5883\u591a\u79cd\u529f\u80fd\u9700\u6c42\u3002"}}
{"id": "2507.11978", "pdf": "https://arxiv.org/pdf/2507.11978", "abs": "https://arxiv.org/abs/2507.11978", "authors": ["Jiacheng Huang", "Zimin Li", "Yinghui Li", "Haojie Wang"], "title": "NineToothed: A Triton-Based High-Level Domain-Specific Language for Machine Learning", "categories": ["cs.DC"], "comment": null, "summary": "The emergence of deep learning domain-specific languages (DSLs) has\nsubstantially reduced the obstacles in developing high-performance,\ncross-platform compute kernels. However, current DSLs, such as Triton, still\ndemand that developers possess expertise in parallel programming and expose\nthem to many low-level details. This requirement complicates the development\nprocess and adds to the difficulty of maintaining compute kernels.\nConsequently, developing a new programming model that supports serial\nprogramming for deep learning workloads is crucial.\n  This paper introduces NineToothed, a domain-specific language that offers\nserial semantics for machine learning programming. Through the automatic\ntransformation of serial code into parallel code, NineToothed significantly\nstreamlines the development process while causing minimal performance\ndegradation. NineToothed encompasses (1) a language with tensor-oriented\nmetaprogramming (TOM) that adopts the arrange-and-apply paradigm, enabling the\nexpression of tiled computations without the need to manage low-level details\nand (2) a code generator for generating high-performance parallel code. Our\nevaluation results indicate that NineToothed can greatly simplify compute\nkernel development while maintaining performance comparable to that of Triton.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7279\u5b9a\u9886\u57df\u8bed\u8a00NineToothed\uff0c\u5b83\u4e3a\u673a\u5668\u5b66\u4e60\u7f16\u7a0b\u63d0\u4f9b\u4e32\u884c\u8bed\u4e49\uff0c\u80fd\u81ea\u52a8\u5c06\u4e32\u884c\u4ee3\u7801\u8f6c\u4e3a\u5e76\u884c\u4ee3\u7801\uff0c\u7b80\u5316\u5f00\u53d1\u4e14\u6027\u80fd\u635f\u5931\u5c0f\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60DSL\u5982Triton\u8981\u6c42\u5f00\u53d1\u8005\u6709\u5e76\u884c\u7f16\u7a0b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u63a5\u89e6\u5927\u91cf\u5e95\u5c42\u7ec6\u8282\uff0c\u589e\u52a0\u5f00\u53d1\u548c\u7ef4\u62a4\u96be\u5ea6\uff0c\u56e0\u6b64\u9700\u5f00\u53d1\u652f\u6301\u4e32\u884c\u7f16\u7a0b\u7684\u65b0\u7f16\u7a0b\u6a21\u578b\u3002", "method": "\u5f15\u5165NineToothed\uff0c\u5305\u542b\u91c7\u7528\u6392\u5217 - \u5e94\u7528\u8303\u5f0f\u7684\u9762\u5411\u5f20\u91cf\u5143\u7f16\u7a0b\uff08TOM\uff09\u8bed\u8a00\u548c\u9ad8\u6027\u80fd\u5e76\u884c\u4ee3\u7801\u751f\u6210\u5668\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793aNineToothed\u80fd\u6781\u5927\u7b80\u5316\u8ba1\u7b97\u5185\u6838\u5f00\u53d1\uff0c\u6027\u80fd\u4e0eTriton\u76f8\u5f53\u3002", "conclusion": "NineToothed\u80fd\u5728\u7b80\u5316\u8ba1\u7b97\u5185\u6838\u5f00\u53d1\u7684\u540c\u65f6\u4fdd\u6301\u8f83\u597d\u6027\u80fd\u3002"}}
{"id": "2507.11988", "pdf": "https://arxiv.org/pdf/2507.11988", "abs": "https://arxiv.org/abs/2507.11988", "authors": ["Yexuan Shi", "Mingyu Wang", "Yunxiang Cao", "Hongjie Lai", "Junjian Lan", "Xin Han", "Yu Wang", "Jie Geng", "Zhenan Li", "Zihao Xia", "Xiang Chen", "Chen Li", "Jian Xu", "Wenbo Duan", "Yuanshuo Zhu"], "title": "Aime: Towards Fully-Autonomous Multi-Agent Framework", "categories": ["cs.AI"], "comment": "14 pages, 1 figures,", "summary": "Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are\nemerging as a powerful paradigm for solving complex, multifaceted problems.\nHowever, the potential of these systems is often constrained by the prevalent\nplan-and-execute framework, which suffers from critical limitations: rigid plan\nexecution, static agent capabilities, and inefficient communication. These\nweaknesses hinder their adaptability and robustness in dynamic environments.\nThis paper introduces Aime, a novel multi-agent framework designed to overcome\nthese challenges through dynamic, reactive planning and execution. Aime\nreplaces the conventional static workflow with a fluid and adaptive\narchitecture. Its core innovations include: (1) a Dynamic Planner that\ncontinuously refines the overall strategy based on real-time execution\nfeedback; (2) an Actor Factory that implements Dynamic Actor instantiation,\nassembling specialized agents on-demand with tailored tools and knowledge; and\n(3) a centralized Progress Management Module that serves as a single source of\ntruth for coherent, system-wide state awareness. We empirically evaluated Aime\non a diverse suite of benchmarks spanning general reasoning (GAIA), software\nengineering (SWE-bench Verified), and live web navigation (WebVoyager). The\nresults demonstrate that Aime consistently outperforms even highly specialized\nstate-of-the-art agents in their respective domains. Its superior adaptability\nand task success rate establish Aime as a more resilient and effective\nfoundation for multi-agent collaboration.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53d7\u9650\u4e8e\u73b0\u6709\u6846\u67b6\uff0c\u63d0\u51fa\u65b0\u6846\u67b6Aime\uff0c\u7ecf\u5b9e\u9a8cAime\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8ba1\u5212\u6267\u884c\u6846\u67b6\u5b58\u5728\u521a\u6027\u6267\u884c\u8ba1\u5212\u3001\u9759\u6001\u4ee3\u7406\u80fd\u529b\u548c\u4f4e\u6548\u901a\u4fe1\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\uff0c\u9700\u8981\u65b0\u6846\u67b6\u89e3\u51b3\u3002", "method": "\u63d0\u51faAime\u6846\u67b6\uff0c\u5305\u542b\u52a8\u6001\u89c4\u5212\u5668\u3001\u52a8\u6001\u6267\u884c\u5668\u5de5\u5382\u548c\u96c6\u4e2d\u5f0f\u8fdb\u5ea6\u7ba1\u7406\u6a21\u5757\u3002", "result": "\u5728\u901a\u7528\u63a8\u7406\u3001\u8f6f\u4ef6\u5de5\u7a0b\u548c\u5b9e\u65f6\u7f51\u9875\u5bfc\u822a\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAime\u59cb\u7ec8\u4f18\u4e8e\u5404\u9886\u57df\u9ad8\u5ea6\u4e13\u4e1a\u5316\u7684\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "Aime\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\uff0c\u662f\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u66f4\u5177\u5f39\u6027\u548c\u6709\u6548\u7684\u57fa\u7840\u3002"}}
{"id": "2507.12118", "pdf": "https://arxiv.org/pdf/2507.12118", "abs": "https://arxiv.org/abs/2507.12118", "authors": ["Noe Zerme\u00f1o", "Cristina Zuheros", "Lucas Daniel Del Rosso Calache", "Francisco Herrera", "Rosana Montes"], "title": "An Online A/B Testing Decision Support System for Web Usability Assessment Based on a Linguistic Decision-making Methodology: Case of Study a Virtual Learning Environment", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "In recent years, attention has increasingly focused on enhancing user\nsatisfaction with user interfaces, spanning both mobile applications and\nwebsites. One fundamental aspect of human-machine interaction is the concept of\nweb usability. In order to assess web usability, the A/B testing technique\nenables the comparison of data between two designs. Expanding the scope of\ntests to include the designs being evaluated, in conjunction with the\ninvolvement of both real and fictional users, presents a challenge for which\nfew online tools offer support. We propose a methodology for web usability\nevaluation based on user-centered approaches such as design thinking and\nlinguistic decision-making, named Linguistic Decision-Making for Web Usability\nEvaluation. This engages people in role-playing scenarios and conducts a number\nof usability tests, including the widely recognized System Usability Scale. We\nincorporate the methodology into a decision support system based on A/B\ntesting. We use real users in a case study to assess three Moodle platforms at\nthe University of Guadalajara, Mexico.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8bbe\u8ba1\u601d\u7ef4\u548c\u8bed\u8a00\u51b3\u7b56\u7684\u7f51\u9875\u53ef\u7528\u6027\u8bc4\u4f30\u65b9\u6cd5\u5e76\u878d\u5165A/B\u6d4b\u8bd5\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u7528\u771f\u5b9e\u7528\u6237\u8bc4\u4f30\u58a8\u897f\u54e5\u5927\u5b66\u7684Moodle\u5e73\u53f0\u3002", "motivation": "\u589e\u5f3a\u7528\u6237\u5bf9\u7528\u6237\u754c\u9762\u7684\u6ee1\u610f\u5ea6\uff0c\u89e3\u51b3A/B\u6d4b\u8bd5\u5728\u6269\u5927\u6d4b\u8bd5\u8303\u56f4\u53ca\u6d89\u53ca\u771f\u5b9e\u548c\u865a\u6784\u7528\u6237\u65f6\u5728\u7ebf\u5de5\u5177\u652f\u6301\u5c11\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u540d\u4e3aLinguistic Decision - Making for Web Usability Evaluation\u7684\u65b9\u6cd5\uff0c\u8ba9\u4eba\u4eec\u53c2\u4e0e\u89d2\u8272\u626e\u6f14\u573a\u666f\u5e76\u8fdb\u884c\u5305\u62ecSUS\u7684\u53ef\u7528\u6027\u6d4b\u8bd5\uff0c\u5c06\u5176\u878d\u5165\u57fa\u4e8eA/B\u6d4b\u8bd5\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "result": "\u4f7f\u7528\u771f\u5b9e\u7528\u6237\u5bf9\u58a8\u897f\u54e5\u74dc\u8fbe\u62c9\u54c8\u62c9\u5927\u5b66\u7684\u4e09\u4e2aMoodle\u5e73\u53f0\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2507.11645", "pdf": "https://arxiv.org/pdf/2507.11645", "abs": "https://arxiv.org/abs/2507.11645", "authors": ["Ahmed Salah", "David Yevick"], "title": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 11 figures", "summary": "Grokking refers to delayed generalization in which the increase in test\naccuracy of a neural network occurs appreciably after the improvement in\ntraining accuracy This paper introduces several practical metrics including\nvariance under dropout, robustness, embedding similarity, and sparsity\nmeasures, that can forecast grokking behavior. Specifically, the resilience of\nneural networks to noise during inference is estimated from a Dropout\nRobustness Curve (DRC) obtained from the variation of the accuracy with the\ndropout rate as the model transitions from memorization to generalization. The\nvariance of the test accuracy under stochastic dropout across training\ncheckpoints further exhibits a local maximum during the grokking. Additionally,\nthe percentage of inactive neurons decreases during generalization, while the\nembeddings tend to a bimodal distribution independent of initialization that\ncorrelates with the observed cosine similarity patterns and dataset symmetries.\nThese metrics additionally provide valuable insight into the origin and\nbehaviour of grokking.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u591a\u4e2a\u5b9e\u7528\u6307\u6807\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u7684grokking\u884c\u4e3a\uff0c\u5e76\u501f\u6b64\u6df1\u5165\u4e86\u89e3grokking\u7684\u8d77\u6e90\u548c\u884c\u4e3a\u3002", "motivation": "\u9884\u6d4b\u795e\u7ecf\u7f51\u7edc\u7684grokking\u884c\u4e3a\u5e76\u4e86\u89e3\u5176\u8d77\u6e90\u548c\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u65b9\u5dee\u3001\u9c81\u68d2\u6027\u3001\u5d4c\u5165\u76f8\u4f3c\u5ea6\u548c\u7a00\u758f\u6027\u7b49\u6307\u6807\uff0c\u901a\u8fc7Dropout\u9c81\u68d2\u6027\u66f2\u7ebf\u4f30\u8ba1\u7f51\u7edc\u5bf9\u566a\u58f0\u7684\u6062\u590d\u80fd\u529b\uff0c\u5206\u6790\u968f\u673aDropout\u4e0b\u6d4b\u8bd5\u51c6\u786e\u7387\u7684\u65b9\u5dee\u7b49\u3002", "result": "Dropout\u9c81\u68d2\u6027\u66f2\u7ebf\u53ef\u5728\u6a21\u578b\u4ece\u8bb0\u5fc6\u8fc7\u6e21\u5230\u6cdb\u5316\u65f6\u4f30\u8ba1\u7f51\u7edc\u5bf9\u566a\u58f0\u7684\u6062\u590d\u80fd\u529b\uff1b\u968f\u673aDropout\u4e0b\u6d4b\u8bd5\u51c6\u786e\u7387\u7684\u65b9\u5dee\u5728grokking\u671f\u95f4\u6709\u5c40\u90e8\u6700\u5927\u503c\uff1b\u6cdb\u5316\u671f\u95f4\u975e\u6d3b\u8dc3\u795e\u7ecf\u5143\u6bd4\u4f8b\u4e0b\u964d\uff0c\u5d4c\u5165\u8d8b\u4e8e\u53cc\u5cf0\u5206\u5e03\u3002", "conclusion": "\u6240\u5f15\u5165\u7684\u6307\u6807\u80fd\u9884\u6d4bgrokking\u884c\u4e3a\uff0c\u4e14\u4e3a\u7406\u89e3\u5176\u8d77\u6e90\u548c\u884c\u4e3a\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.12439", "pdf": "https://arxiv.org/pdf/2507.12439", "abs": "https://arxiv.org/abs/2507.12439", "authors": ["Daniel Commey", "Rebecca A. Sarpong", "Griffith S. Klogo", "Winful Bagyl-Bac", "Garth V. Crosby"], "title": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.GT"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndecentralized clients while preserving data privacy. However, its\nopen-participation nature exposes it to data-poisoning attacks, in which\nmalicious actors submit corrupted model updates to degrade the global model.\nExisting defenses are often reactive, relying on statistical aggregation rules\nthat can be computationally expensive and that typically assume an honest\nmajority. This paper introduces a proactive, economic defense: a lightweight\nBayesian incentive mechanism that makes malicious behavior economically\nirrational. Each training round is modeled as a Bayesian game of incomplete\ninformation in which the server, acting as the principal, uses a small, private\nvalidation dataset to verify update quality before issuing payments. The design\nsatisfies Individual Rationality (IR) for benevolent clients, ensuring their\nparticipation is profitable, and Incentive Compatibility (IC), making poisoning\nan economically dominated strategy. Extensive experiments on non-IID partitions\nof MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping\nadversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3\npercentage points lower than in a scenario with 30% label-flipping adversaries.\nThis outcome is 51.7 percentage points better than standard FedAvg, which\ncollapses under the same 50% attack. The mechanism is computationally light,\nbudget-bounded, and readily integrates into existing FL frameworks, offering a\npractical route to economically robust and sustainable FL ecosystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u8d1d\u53f6\u65af\u6fc0\u52b1\u673a\u5236\u5e94\u5bf9\u8054\u90a6\u5b66\u4e60\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9c81\u68d2\u6027\u597d\u3001\u8ba1\u7b97\u8f7b\u91cf\u4e14\u6613\u96c6\u6210\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6570\u636e\u6295\u6bd2\u9632\u5fa1\u65b9\u6cd5\u5e38\u4e3a\u88ab\u52a8\u9632\u5fa1\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5047\u8bbe\u8bda\u5b9e\u591a\u6570\uff0c\u9700\u8981\u4e3b\u52a8\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u5c06\u6bcf\u8f6e\u8bad\u7ec3\u5efa\u6a21\u4e3a\u4e0d\u5b8c\u5168\u4fe1\u606f\u8d1d\u53f6\u65af\u535a\u5f08\uff0c\u670d\u52a1\u5668\u7528\u5c0f\u7684\u79c1\u6709\u9a8c\u8bc1\u6570\u636e\u96c6\u9a8c\u8bc1\u66f4\u65b0\u8d28\u91cf\u540e\u652f\u4ed8\u62a5\u916c\uff0c\u673a\u5236\u6ee1\u8db3\u4e2a\u4f53\u7406\u6027\u548c\u6fc0\u52b1\u517c\u5bb9\u3002", "result": "\u5728MNIST\u548cFashionMNIST\u975eIID\u5206\u533a\u4e0a\u5b9e\u9a8c\uff0c\u9762\u5bf950%\u6807\u7b7e\u7ffb\u8f6c\u653b\u51fb\uff0c\u673a\u5236\u4fdd\u630196.7%\u51c6\u786e\u7387\uff0c\u6bd4\u6807\u51c6FedAvg\u9ad851.7\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u8be5\u673a\u5236\u8ba1\u7b97\u8f7b\u91cf\u3001\u9884\u7b97\u6709\u754c\u4e14\u6613\u96c6\u6210\u5230\u73b0\u6709\u6846\u67b6\uff0c\u4e3a\u6784\u5efa\u7ecf\u6d4e\u4e0a\u7a33\u5065\u548c\u53ef\u6301\u7eed\u7684\u8054\u90a6\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2507.11911", "pdf": "https://arxiv.org/pdf/2507.11911", "abs": "https://arxiv.org/abs/2507.11911", "authors": ["Xiaoqing Chen", "Siyang Li", "Dongrui Wu"], "title": "AFPM: Alignment-based Frame Patch Modeling for Cross-Dataset EEG Decoding", "categories": ["cs.HC", "cs.IR", "cs.LG"], "comment": null, "summary": "Electroencephalogram (EEG) decoding models for brain-computer interfaces\n(BCIs) struggle with cross-dataset learning and generalization due to channel\nlayout inconsistencies, non-stationary signal distributions, and limited\nneurophysiological prior integration. To address these issues, we propose a\nplug-and-play Alignment-Based Frame-Patch Modeling (AFPM) framework, which has\ntwo main components: 1) Spatial Alignment, which selects task-relevant channels\nbased on brain-region priors, aligns EEG distributions across domains, and\nremaps the selected channels to a unified layout; and, 2) Frame-Patch Encoding,\nwhich models multi-dataset signals into unified spatiotemporal patches for EEG\ndecoding. Compared to 17 state-of-the-art approaches that need dataset-specific\ntuning, the proposed calibration-free AFPM achieves performance gains of up to\n4.40% on motor imagery and 3.58% on event-related potential tasks. To our\nknowledge, this is the first calibration-free cross-dataset EEG decoding\nframework, substantially enhancing the practicalness of BCIs in real-world\napplications.", "AI": {"tldr": "\u63d0\u51fa\u6821\u51c6\u65e0\u5173\u7684AFPM\u6846\u67b6\u7528\u4e8e\u8de8\u6570\u636e\u96c6\u8111\u7535\u89e3\u7801\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347BCI\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u8111\u673a\u63a5\u53e3\u7684\u8111\u7535\u89e3\u7801\u6a21\u578b\u5728\u8de8\u6570\u636e\u96c6\u5b66\u4e60\u548c\u6cdb\u5316\u65b9\u9762\u5b58\u5728\u95ee\u9898\uff0c\u5982\u901a\u9053\u5e03\u5c40\u4e0d\u4e00\u81f4\u3001\u4fe1\u53f7\u5206\u5e03\u975e\u5e73\u7a33\u548c\u795e\u7ecf\u751f\u7406\u5148\u9a8c\u6574\u5408\u6709\u9650\u3002", "method": "\u63d0\u51faAFPM\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u8111\u533a\u5148\u9a8c\u9009\u62e9\u76f8\u5173\u901a\u9053\u3001\u5bf9\u9f50\u4e0d\u540c\u57df\u8111\u7535\u5206\u5e03\u5e76\u5c06\u901a\u9053\u91cd\u6620\u5c04\u5230\u7edf\u4e00\u5e03\u5c40\u7684\u7a7a\u95f4\u5bf9\u9f50\uff0c\u4ee5\u53ca\u5c06\u591a\u6570\u636e\u96c6\u4fe1\u53f7\u5efa\u6a21\u4e3a\u7edf\u4e00\u65f6\u7a7a\u8865\u4e01\u8fdb\u884c\u8111\u7535\u89e3\u7801\u7684\u5e27\u8865\u4e01\u7f16\u7801\u3002", "result": "\u4e0e17\u79cd\u9700\u8981\u7279\u5b9a\u6570\u636e\u96c6\u8c03\u4f18\u7684\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0cAFPM\u5728\u8fd0\u52a8\u60f3\u8c61\u4efb\u52a1\u4e0a\u6027\u80fd\u63d0\u5347\u8fbe4.40%\uff0c\u5728\u4e8b\u4ef6\u76f8\u5173\u7535\u4f4d\u4efb\u52a1\u4e0a\u63d0\u53473.58%\u3002", "conclusion": "AFPM\u662f\u9996\u4e2a\u6821\u51c6\u65e0\u5173\u7684\u8de8\u6570\u636e\u96c6\u8111\u7535\u89e3\u7801\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8111\u673a\u63a5\u53e3\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.12032", "pdf": "https://arxiv.org/pdf/2507.12032", "abs": "https://arxiv.org/abs/2507.12032", "authors": ["Brian-Frederik Jahnke", "Ren\u00e9 Brinkhege", "Jan Peter Meyer", "Daniel Tebernum", "Falk Howar"], "title": "ARRC: Explainable, Workflow-Integrated Recommender for Sustainable Resource Optimization Across the Edge-Cloud Continuum", "categories": ["cs.DC"], "comment": null, "summary": "Achieving sustainable, explainable, and maintainable automation for resource\noptimization is a core challenge across the edge-cloud continuum. Persistent\noverprovisioning and operational complexity often stem from heterogeneous\nplatforms and layered abstractions, while systems lacking explainability and\nmaintainability become fragile, impede safe recovery, and accumulate technical\ndebt. Existing solutions are frequently reactive, limited to single abstraction\nlayers, or require intrusive platform changes, leaving efficiency and\nmaintainability gains unrealized.\n  This paper addresses safe, transparent, and low-effort resource optimization\nin dynamic, multi-tenant edge-cloud systems, without disrupting operator\nworkflows or increasing technical debt. We introduce ARRC, a recommender system\nrooted in software engineering design principles, which delivers explainable,\ncross-layer resource recommendations directly into operator workflows (such as\ntickets and GitOps pull requests). ARRC encapsulates optimization logic in\nspecialized, auditable agents coordinated via a shared interface, supporting\nmaintainability and extensibility through transparency and the ability to\ninspect both recommendations and their rationale.\n  Empirical evaluation in a multi-region industrial deployment shows that ARRC\nreduces operator workload by over 50%, improves compute utilization by up to\n7.7x, and maintains error rates below 5%, with most benefits achieved through\nincremental, operator-approved changes. This demonstrates that explainable,\nrecommendation-based architectures can achieve sustainable efficiency and\nmaintainability improvements at production scale.\n  ARRC provides an empirically evaluated framework for integrating explainable,\nworkflow-driven automation into resource management, intended to advance best\npractices for robust, maintainable, and transparent edge-cloud continuum\nplatforms.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u63a8\u8350\u7cfb\u7edf ARRC \u7528\u4e8e\u8fb9\u7f18 - \u4e91\u7cfb\u7edf\u8d44\u6e90\u4f18\u5316\uff0c\u7ecf\u8bc4\u4f30\u53ef\u51cf\u5c11\u64cd\u4f5c\u5458\u5de5\u4f5c\u91cf\u3001\u63d0\u9ad8\u8ba1\u7b97\u5229\u7528\u7387\u5e76\u7ef4\u6301\u4f4e\u9519\u8bef\u7387\u3002", "motivation": "\u73b0\u6709\u8fb9\u7f18 - \u4e91\u8d44\u6e90\u4f18\u5316\u65b9\u6848\u5b58\u5728\u53cd\u5e94\u5f0f\u3001\u9650\u4e8e\u5355\u62bd\u8c61\u5c42\u3001\u9700\u5e73\u53f0\u4fb5\u5165\u5f0f\u66f4\u6539\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u5b9e\u73b0\u6548\u7387\u548c\u53ef\u7ef4\u62a4\u6027\u63d0\u5347\uff0c\u9700\u8981\u5b89\u5168\u3001\u900f\u660e\u3001\u4f4e\u5de5\u4f5c\u91cf\u7684\u8d44\u6e90\u4f18\u5316\u65b9\u6848\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u8bbe\u8ba1\u539f\u5219\u7684\u63a8\u8350\u7cfb\u7edf ARRC\uff0c\u5c06\u53ef\u89e3\u91ca\u7684\u8de8\u5c42\u8d44\u6e90\u63a8\u8350\u878d\u5165\u64cd\u4f5c\u5458\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u5171\u4eab\u63a5\u53e3\u534f\u8c03\u4e13\u4e1a\u53ef\u5ba1\u8ba1\u4ee3\u7406\u5c01\u88c5\u4f18\u5316\u903b\u8f91\u3002", "result": "\u591a\u533a\u57df\u5de5\u4e1a\u90e8\u7f72\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cARRC \u51cf\u5c11\u8d85 50% \u64cd\u4f5c\u5458\u5de5\u4f5c\u91cf\uff0c\u8ba1\u7b97\u5229\u7528\u7387\u63d0\u9ad8\u8fbe 7.7 \u500d\uff0c\u9519\u8bef\u7387\u7ef4\u6301\u5728 5% \u4ee5\u4e0b\u3002", "conclusion": "\u57fa\u4e8e\u53ef\u89e3\u91ca\u63a8\u8350\u7684\u67b6\u6784\u80fd\u5728\u751f\u4ea7\u89c4\u6a21\u4e0a\u5b9e\u73b0\u53ef\u6301\u7eed\u7684\u6548\u7387\u548c\u53ef\u7ef4\u62a4\u6027\u63d0\u5347\uff0cARRC \u4e3a\u8d44\u6e90\u7ba1\u7406\u96c6\u6210\u53ef\u89e3\u91ca\u3001\u5de5\u4f5c\u6d41\u9a71\u52a8\u81ea\u52a8\u5316\u63d0\u4f9b\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2507.11992", "pdf": "https://arxiv.org/pdf/2507.11992", "abs": "https://arxiv.org/abs/2507.11992", "authors": ["Pranav Rajbhandari", "Abhi Veda", "Matthew Garratt", "Mandayam Srinivasan", "Sridhar Ravi"], "title": "Understanding visual attention beehind bee-inspired UAV navigation", "categories": ["cs.AI"], "comment": null, "summary": "Bio-inspired design is often used in autonomous UAV navigation due to the\ncapacity of biological systems for flight and obstacle avoidance despite\nlimited sensory and computational capabilities. In particular, honeybees mainly\nuse the sensory input of optic flow, the apparent motion of objects in their\nvisual field, to navigate cluttered environments. In our work, we train a\nReinforcement Learning agent to navigate a tunnel with obstacles using only\noptic flow as sensory input. We inspect the attention patterns of trained\nagents to determine the regions of optic flow on which they primarily base\ntheir motor decisions. We find that agents trained in this way pay most\nattention to regions of discontinuity in optic flow, as well as regions with\nlarge optic flow magnitude. The trained agents appear to navigate a cluttered\ntunnel by avoiding the obstacles that produce large optic flow, while\nmaintaining a centered position in their environment, which resembles the\nbehavior seen in flying insects. This pattern persists across independently\ntrained agents, which suggests that this could be a good strategy for\ndeveloping a simple explicit control law for physical UAVs.", "AI": {"tldr": "\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u4ec5\u7528\u5149\u6d41\u8fdb\u884c\u96a7\u9053\u907f\u969c\u5bfc\u822a\uff0c\u53d1\u73b0\u5176\u5173\u6ce8\u5149\u6d41\u4e0d\u8fde\u7eed\u548c\u5927\u5149\u6d41\u533a\u57df\uff0c\u8be5\u7b56\u7565\u6216\u53ef\u7528\u4e8e\u5f00\u53d1\u7269\u7406\u65e0\u4eba\u673a\u63a7\u5236\u5f8b\u3002", "motivation": "\u751f\u7269\u7cfb\u7edf\u98de\u884c\u548c\u907f\u969c\u80fd\u529b\u4fc3\u4f7f\u5728\u65e0\u4eba\u673a\u5bfc\u822a\u4e2d\u91c7\u7528\u4eff\u751f\u8bbe\u8ba1\uff0c\u501f\u9274\u871c\u8702\u7528\u5149\u6d41\u5bfc\u822a\u3002", "method": "\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u4ec5\u7528\u5149\u6d41\u4f5c\u4e3a\u611f\u5b98\u8f93\u5165\u5728\u6709\u969c\u788d\u7269\u7684\u96a7\u9053\u4e2d\u5bfc\u822a\uff0c\u5e76\u68c0\u67e5\u5176\u6ce8\u610f\u529b\u6a21\u5f0f\u3002", "result": "\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\u4e3b\u8981\u5173\u6ce8\u5149\u6d41\u4e0d\u8fde\u7eed\u533a\u57df\u548c\u5927\u5149\u6d41\u533a\u57df\uff0c\u80fd\u907f\u969c\u5e76\u4fdd\u6301\u5c45\u4e2d\uff0c\u7c7b\u4f3c\u98de\u884c\u6606\u866b\u884c\u4e3a\u3002", "conclusion": "\u8be5\u7b56\u7565\u6216\u53ef\u7528\u4e8e\u4e3a\u7269\u7406\u65e0\u4eba\u673a\u5f00\u53d1\u7b80\u5355\u660e\u786e\u7684\u63a7\u5236\u5f8b\u3002"}}
{"id": "2507.12284", "pdf": "https://arxiv.org/pdf/2507.12284", "abs": "https://arxiv.org/abs/2507.12284", "authors": ["Artem Chervyakov", "Alexander Kharitonov", "Pavel Zadorozhny", "Adamenko Pavel", "Rodion Levichev", "Dmitrii Vorobev", "Dmitrii Salikhov", "Aidar Valeev", "Alena Pestova", "Maria Dziuba", "Ilseyar Alimova", "Artem Zavgorodnev", "Aleksandr Medvedev", "Stanislav Moiseev", "Elena Bruches", "Daniil Grebenkin", "Roman Derunets", "Vikulov Vladimir", "Anton Emelyanov", "Dmitrii Babaev", "Vladimir V. Ivanov", "Valentin Malykh", "Alena Fenogenova"], "title": "MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "Advancements in LLMs have enhanced task automation in software engineering;\nhowever, current evaluations primarily focus on natural language tasks,\noverlooking code quality. Most benchmarks prioritize high-level reasoning over\nexecutable code and real-world performance, leaving gaps in understanding true\ncapabilities and risks associated with these models in production. To address\nthis issue, we propose MERA Code, a new addition to the MERA benchmark family,\nspecifically focused on evaluating code for the latest code generation LLMs in\nRussian. This benchmark includes 11 evaluation tasks that span 8 programming\nlanguages. Our proposed evaluation methodology features a taxonomy that\noutlines the practical coding skills necessary for models to complete these\ntasks. The benchmark comprises an open-source codebase for users to conduct\nMERA assessments, a scoring system compatible with various programming\nenvironments, and a platform featuring a leaderboard and submission system. We\nevaluate open LLMs and frontier API models, analyzing their limitations in\nterms of practical coding tasks in non-English languages. We are publicly\nreleasing MERA to guide future research, anticipate groundbreaking features in\nmodel development, and standardize evaluation procedures.", "AI": {"tldr": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u8bc4\u4f30\u91cd\u81ea\u7136\u8bed\u8a00\u8f7b\u4ee3\u7801\u8d28\u91cf\uff0c\u672c\u6587\u63d0\u51fa\u4e13\u6ce8\u4fc4\u8bed\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u7684MERA Code\u57fa\u51c6\uff0c\u542b11\u4e2a\u4efb\u52a1\uff0c\u8986\u76d68\u79cd\u8bed\u8a00\uff0c\u8bc4\u4f30\u6a21\u578b\u5e76\u516c\u5f00\u6210\u679c\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\uff0c\u5ffd\u89c6\u4ee3\u7801\u8d28\u91cf\u548c\u5b9e\u9645\u6027\u80fd\uff0c\u9700\u8bc4\u4f30\u6a21\u578b\u5728\u751f\u4ea7\u4e2d\u7684\u771f\u5b9e\u80fd\u529b\u548c\u98ce\u9669\u3002", "method": "\u63d0\u51faMERA Code\u57fa\u51c6\uff0c\u5305\u62ec11\u4e2a\u8bc4\u4f30\u4efb\u52a1\u3001\u8bc4\u4f30\u65b9\u6cd5\u5206\u7c7b\u3001\u5f00\u6e90\u4ee3\u7801\u5e93\u3001\u8bc4\u5206\u7cfb\u7edf\u53ca\u5e73\u53f0\u3002", "result": "\u8bc4\u4f30\u4e86\u5f00\u6e90\u548c\u524d\u6cbfAPI\u6a21\u578b\uff0c\u5206\u6790\u5176\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u5b9e\u9645\u7f16\u7801\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u516c\u5f00MERA\u4ee5\u6307\u5bfc\u672a\u6765\u7814\u7a76\uff0c\u63a8\u52a8\u6a21\u578b\u5f00\u53d1\uff0c\u89c4\u8303\u8bc4\u4f30\u7a0b\u5e8f\u3002"}}
{"id": "2507.11649", "pdf": "https://arxiv.org/pdf/2507.11649", "abs": "https://arxiv.org/abs/2507.11649", "authors": ["Daniel Commey", "Benjamin Appiah", "Griffith S. Klogo", "Garth V. Crosby"], "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training on decentralized\ndata without exposing raw data. However, the evaluation phase in FL may leak\nsensitive information through shared performance metrics. In this paper, we\npropose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to\nenable privacy-preserving and verifiable evaluation for FL. Instead of\nrevealing raw loss values, clients generate a succinct proof asserting that\ntheir local loss is below a predefined threshold. Our approach is implemented\nwithout reliance on external APIs, using self-contained modules for federated\nlearning simulation, ZKP circuit design, and experimental evaluation on both\nthe MNIST and Human Activity Recognition (HAR) datasets. We focus on a\nthreshold-based proof for a simple Convolutional Neural Network (CNN) model\n(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate\nthe approach in terms of computational overhead, communication cost, and\nverifiability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u534f\u8bae\uff0c\u4e3a\u8054\u90a6\u5b66\u4e60\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u548c\u53ef\u9a8c\u8bc1\u8bc4\u4f30\uff0c\u5728MNIST\u548cHAR\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u5e76\u8bc4\u4f30\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u8bc4\u4f30\u9636\u6bb5\u53ef\u80fd\u901a\u8fc7\u5171\u4eab\u6027\u80fd\u6307\u6807\u6cc4\u9732\u654f\u611f\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u534f\u8bae\uff0c\u5ba2\u6237\u7aef\u751f\u6210\u7b80\u6d01\u8bc1\u660e\u8868\u660e\u672c\u5730\u635f\u5931\u4f4e\u4e8e\u9884\u5b9a\u4e49\u9608\u503c\uff0c\u7528\u81ea\u5305\u542b\u6a21\u5757\u5b9e\u73b0\uff0c\u4e0d\u4f9d\u8d56\u5916\u90e8API\u3002", "result": "\u5728MNIST\u548cHAR\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "conclusion": "\u53ef\u4ece\u8ba1\u7b97\u5f00\u9500\u3001\u901a\u4fe1\u6210\u672c\u548c\u53ef\u9a8c\u8bc1\u6027\u7b49\u65b9\u9762\u8bc4\u4f30\u8be5\u65b9\u6cd5\u3002"}}
{"id": "2507.11732", "pdf": "https://arxiv.org/pdf/2507.11732", "abs": "https://arxiv.org/abs/2507.11732", "authors": ["Shiyu Chen", "Cencheng Shen", "Youngser Park", "Carey E. Priebe"], "title": "Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Graph neural networks (GNNs) have emerged as a powerful framework for a wide\nrange of node-level graph learning tasks. However, their performance is often\nconstrained by reliance on random or minimally informed initial feature\nrepresentations, which can lead to slow convergence and suboptimal solutions.\nIn this paper, we leverage a statistically grounded method, one-hot graph\nencoder embedding (GEE), to generate high-quality initial node features that\nenhance the end-to-end training of GNNs. We refer to this integrated framework\nas the GEE-powered GNN (GG), and demonstrate its effectiveness through\nextensive simulations and real-world experiments across both unsupervised and\nsupervised settings. In node clustering, GG consistently achieves\nstate-of-the-art performance, ranking first across all evaluated real-world\ndatasets, while exhibiting faster convergence compared to the standard GNN. For\nnode classification, we further propose an enhanced variant, GG-C, which\nconcatenates the outputs of GG and GEE and outperforms competing baselines.\nThese results confirm the importance of principled, structure-aware feature\ninitialization in realizing the full potential of GNNs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e00\u70ed\u56fe\u7f16\u7801\u5668\u5d4c\u5165\uff08GEE\uff09\u751f\u6210\u9ad8\u8d28\u91cf\u521d\u59cb\u8282\u70b9\u7279\u5f81\u7684GEE\u9a71\u52a8\u7684GNN\u6846\u67b6\uff08GG\uff09\uff0c\u5e76\u5728\u8282\u70b9\u805a\u7c7b\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfGNN\u4f9d\u8d56\u968f\u673a\u6216\u4fe1\u606f\u4e0d\u8db3\u7684\u521d\u59cb\u7279\u5f81\u8868\u793a\uff0c\u5bfc\u81f4\u6536\u655b\u6162\u548c\u7ed3\u679c\u6b20\u4f73\uff0c\u9700\u6539\u8fdb\u521d\u59cb\u7279\u5f81\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u4e00\u70ed\u56fe\u7f16\u7801\u5668\u5d4c\u5165\uff08GEE\uff09\u751f\u6210\u521d\u59cb\u8282\u70b9\u7279\u5f81\uff0c\u6784\u5efaGG\u6846\u67b6\uff1b\u5728\u8282\u70b9\u5206\u7c7b\u4e2d\u63d0\u51faGG - C\u53d8\u4f53\uff0c\u5c06GG\u548cGEE\u7684\u8f93\u51fa\u62fc\u63a5\u3002", "result": "\u5728\u8282\u70b9\u805a\u7c7b\u4e2d\uff0cGG\u5728\u6240\u6709\u8bc4\u4f30\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6392\u540d\u7b2c\u4e00\uff0c\u6536\u655b\u66f4\u5feb\uff1b\u5728\u8282\u70b9\u5206\u7c7b\u4e2d\uff0cGG - C\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u6709\u539f\u5219\u3001\u7ed3\u6784\u611f\u77e5\u7684\u7279\u5f81\u521d\u59cb\u5316\u5bf9\u53d1\u6325GNN\u7684\u5168\u90e8\u6f5c\u529b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.12038", "pdf": "https://arxiv.org/pdf/2507.12038", "abs": "https://arxiv.org/abs/2507.12038", "authors": ["Alkida Balliu", "Thomas Boudier", "Francesco d'Amore", "Dennis Olivetti", "Gustav Schmid", "Jukka Suomela"], "title": "Distributed Algorithms for Potential Problems", "categories": ["cs.DC"], "comment": "28 pages, 4 figures", "summary": "In this work we present a fast distributed algorithm for local potential\nproblems: these are graph problems where the task is to find a locally optimal\nsolution where no node can unilaterally improve the utility in its local\nneighborhood by changing its own label. A simple example of such a problem is\nthe task of finding a locally optimal cut, i.e., a cut where for each node at\nleast half of its incident edges are cut edges. The distributed round\ncomplexity of locally optimal cut has been wide open; the problem is known to\nrequire $\\Omega(\\log n)$ rounds in the deterministic LOCAL model and\n$\\Omega(\\log \\log n)$ rounds in the randomized LOCAL model, but the only known\nupper bound is the trivial brute-force solution of $O(n)$ rounds. Locally\noptimal cut in bounded-degree graphs is perhaps the simplest example of a\nlocally checkable labeling problem for which there is still such a large gap\nbetween current upper and lower bounds. We show that in bounded-degree graphs,\nall local potential problems, including locally optimal cut, can be solved in\n$\\log^{O(1)} n$ rounds, both in the deterministic and randomized LOCAL models.\nIn particular, the deterministic round complexity of the locally optimal cut\nproblem is now settled to $\\log^{\\Theta(1)} n$.", "AI": {"tldr": "\u63d0\u51fa\u6c42\u89e3\u5c40\u90e8\u52bf\u95ee\u9898\u7684\u5feb\u901f\u5206\u5e03\u5f0f\u7b97\u6cd5\uff0c\u89e3\u51b3\u6709\u754c\u5ea6\u56fe\u4e2d\u5c40\u90e8\u6700\u4f18\u5272\u7684\u8f6e\u590d\u6742\u5ea6\u95ee\u9898\u3002", "motivation": "\u5c40\u90e8\u6700\u4f18\u5272\u7684\u5206\u5e03\u5f0f\u8f6e\u590d\u6742\u5ea6\u95ee\u9898\u60ac\u800c\u672a\u51b3\uff0c\u4e0a\u4e0b\u754c\u5dee\u8ddd\u5927\u3002", "method": "\u8bbe\u8ba1\u5feb\u901f\u5206\u5e03\u5f0f\u7b97\u6cd5\u6c42\u89e3\u5c40\u90e8\u52bf\u95ee\u9898\u3002", "result": "\u5728\u6709\u754c\u5ea6\u56fe\u4e2d\uff0c\u6240\u6709\u5c40\u90e8\u52bf\u95ee\u9898\uff08\u5305\u62ec\u5c40\u90e8\u6700\u4f18\u5272\uff09\u5728\u786e\u5b9a\u6027\u548c\u968f\u673aLOCAL\u6a21\u578b\u4e2d\u90fd\u53ef\u5728$log^{O(1)} n$\u8f6e\u5185\u89e3\u51b3\u3002", "conclusion": "\u786e\u5b9a\u4e86\u5c40\u90e8\u6700\u4f18\u5272\u95ee\u9898\u5728\u786e\u5b9a\u6027\u6a21\u578b\u4e2d\u7684\u8f6e\u590d\u6742\u5ea6\u4e3a$log^{\\Theta(1)} n$\u3002"}}
{"id": "2507.12110", "pdf": "https://arxiv.org/pdf/2507.12110", "abs": "https://arxiv.org/abs/2507.12110", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "title": "Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs", "categories": ["cs.AI"], "comment": "16 pages, 16 figures", "summary": "The exploration-exploitation trade-off constitutes one of the fundamental\nchallenges in reinforcement learning (RL), which is exacerbated in multi-agent\nreinforcement learning (MARL) due to the exponential growth of joint\nstate-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)\nmethod for optimizing cooperative decision-making of connected and autonomous\nvehicles (CAVs) in mixed traffic. This work presents two primary contributions:\nFirst, we construct a game topology tensor for dynamic traffic flow,\neffectively compressing high-dimensional traffic state information and decrease\nthe search space for MARL algorithms. Second, building upon the designed game\ntopology tensor and using QMIX as the backbone RL algorithm, we establish a\ntopology-enhanced MARL framework incorporating visit counts and agent mutual\ninformation. Extensive simulations across varying traffic densities and CAV\npenetration rates demonstrate the effectiveness of TPE-MARL. Evaluations\nencompassing training dynamics, exploration patterns, macroscopic traffic\nperformance metrics, and microscopic vehicle behaviors reveal that TPE-MARL\nsuccessfully balances exploration and exploitation. Consequently, it exhibits\nsuperior performance in terms of traffic efficiency, safety, decision\nsmoothness, and task completion. Furthermore, the algorithm demonstrates\ndecision-making rationality comparable to or exceeding that of human drivers in\nboth mixed-autonomy and fully autonomous traffic scenarios. Code of our work is\navailable at\n\\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.", "AI": {"tldr": "\u63d0\u51faTPE - MARL\u65b9\u6cd5\u4f18\u5316\u6df7\u5408\u4ea4\u901a\u4e2dCAV\u534f\u540c\u51b3\u7b56\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u6027\u80fd\u4f18\u4e14\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e2d\u63a2\u7d22 - \u5229\u7528\u6743\u8861\u662f\u6311\u6218\uff0c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u56e0\u8054\u5408\u72b6\u6001 - \u52a8\u4f5c\u7a7a\u95f4\u6307\u6570\u589e\u957f\u800c\u52a0\u5267\uff0c\u9700\u4f18\u5316\u6df7\u5408\u4ea4\u901a\u4e2dCAV\u534f\u540c\u51b3\u7b56\u3002", "method": "\u6784\u5efa\u52a8\u6001\u4ea4\u901a\u6d41\u7684\u535a\u5f08\u62d3\u6251\u5f20\u91cf\u538b\u7f29\u4fe1\u606f\u3001\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff1b\u57fa\u4e8e\u535a\u5f08\u62d3\u6251\u5f20\u91cf\uff0c\u4ee5QMIX\u4e3a\u9aa8\u5e72\u7b97\u6cd5\uff0c\u5efa\u7acb\u5305\u542b\u8bbf\u95ee\u8ba1\u6570\u548c\u667a\u80fd\u4f53\u4e92\u4fe1\u606f\u7684TPE - MARL\u6846\u67b6\u3002", "result": "\u4e0d\u540c\u4ea4\u901a\u5bc6\u5ea6\u548cCAV\u6e17\u900f\u7387\u7684\u6a21\u62df\u663e\u793aTPE - MARL\u6709\u6548\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u5728\u4ea4\u901a\u6548\u7387\u3001\u5b89\u5168\u7b49\u65b9\u9762\u8868\u73b0\u4f18\uff0c\u51b3\u7b56\u5408\u7406\u6027\u53ef\u4e0e\u4eba\u7c7b\u9a7e\u9a76\u5458\u5ab2\u7f8e\u6216\u66f4\u4f18\u3002", "conclusion": "TPE - MARL\u65b9\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u6df7\u5408\u4ea4\u901a\u4e2dCAV\u7684\u534f\u540c\u51b3\u7b56\u3002"}}
{"id": "2507.12367", "pdf": "https://arxiv.org/pdf/2507.12367", "abs": "https://arxiv.org/abs/2507.12367", "authors": ["Diganta Misra", "Nizar Islah", "Victor May", "Brice Rauby", "Zihan Wang", "Justine Gehring", "Antonio Orvieto", "Muawiz Chaudhary", "Eilif B. Muller", "Irina Rish", "Samira Ebrahimi Kahou", "Massimo Caccia"], "title": "GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": "Version 2 of the dataset from: arXiv:2411.05830", "summary": "The rapid evolution of software libraries poses a considerable hurdle for\ncode generation, necessitating continuous adaptation to frequent version\nupdates while preserving backward compatibility. While existing code evolution\nbenchmarks provide valuable insights, they typically lack execution-based\nevaluation for generating code compliant with specific library versions. To\naddress this, we introduce GitChameleon, a novel, meticulously curated dataset\ncomprising 328 Python code completion problems, each conditioned on specific\nlibrary versions and accompanied by executable unit tests. GitChameleon\nrigorously evaluates the capacity of contemporary large language models (LLMs),\nLLM-powered agents, code assistants, and RAG systems to perform\nversion-conditioned code generation that demonstrates functional accuracy\nthrough execution. Our extensive evaluations indicate that state-of-the-art\nsystems encounter significant challenges with this task; enterprise models\nachieving baseline success rates in the 48-51\\% range, underscoring the\nintricacy of the problem. By offering an execution-based benchmark emphasizing\nthe dynamic nature of code libraries, GitChameleon enables a clearer\nunderstanding of this challenge and helps guide the development of more\nadaptable and dependable AI code generation methods. We make the dataset and\nevaluation code publicly available at\nhttps://github.com/mrcabbage972/GitChameleonBenchmark.", "AI": {"tldr": "\u63d0\u51faGitChameleon\u6570\u636e\u96c6\u8bc4\u4f30\u7248\u672c\u6761\u4ef6\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u6307\u51fa\u5f53\u524d\u7cfb\u7edf\u9762\u4e34\u6311\u6218\u5e76\u516c\u5f00\u6570\u636e\u548c\u4ee3\u7801\u3002", "motivation": "\u8f6f\u4ef6\u5e93\u5feb\u901f\u6f14\u53d8\u7ed9\u4ee3\u7801\u751f\u6210\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u57fa\u4e8e\u6267\u884c\u7684\u7279\u5b9a\u5e93\u7248\u672c\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u5305\u542b328\u4e2aPython\u4ee3\u7801\u5b8c\u6210\u95ee\u9898\u53ca\u53ef\u6267\u884c\u5355\u5143\u6d4b\u8bd5\u7684GitChameleon\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u73b0\u6709\u7cfb\u7edf\u5728\u7248\u672c\u6761\u4ef6\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u4f01\u4e1a\u6a21\u578b\u6210\u529f\u7387\u572848 - 51%\u3002", "conclusion": "GitChameleon\u6709\u52a9\u4e8e\u66f4\u6e05\u6670\u7406\u89e3\u6311\u6218\uff0c\u6307\u5bfc\u5f00\u53d1\u66f4\u53ef\u9760\u7684AI\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u3002"}}
{"id": "2507.11660", "pdf": "https://arxiv.org/pdf/2507.11660", "abs": "https://arxiv.org/abs/2507.11660", "authors": ["Joao F. Rocha", "Ke Xu", "Xingzhi Sun", "Ananya Krishna", "Dhananjay Bhaskar", "Blanche Mongeon", "Morgan Craig", "Mark Gerstein", "Smita Krishnaswamy"], "title": "STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics", "categories": ["cs.LG", "cs.MA", "q-bio.QM"], "comment": null, "summary": "The advent of single-cell technology has significantly improved our\nunderstanding of cellular states and subpopulations in various tissues under\nnormal and diseased conditions by employing data-driven approaches such as\nclustering and trajectory inference. However, these methods consider cells as\nindependent data points of population distributions. With spatial\ntranscriptomics, we can represent cellular organization, along with dynamic\ncell-cell interactions that lead to changes in cell state. Still, key\ncomputational advances are necessary to enable the data-driven learning of such\ncomplex interactive cellular dynamics. While agent-based modeling (ABM)\nprovides a powerful framework, traditional approaches rely on handcrafted rules\nderived from domain knowledge rather than data-driven approaches. To address\nthis, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)\nintegrating ABM with deep learning to model intercellular communication, and\nits effect on the intracellular gene regulatory network. Using graph ODE\nnetworks (GDEs) with shared weights per cell type, our approach represents\ngenes as vertices and interactions as directed edges, dynamically learning\ntheir strengths through a designed attention mechanism. Trained to match\ncontinuous trajectories of simulated as well as inferred trajectories from\nspatial transcriptomics data, the model captures both intercellular and\nintracellular interactions, enabling a more adaptive and accurate\nrepresentation of cellular dynamics.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u6574\u5408ABM\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684STAGED\u6a21\u578b\uff0c\u7528\u4e8e\u6a21\u62df\u7ec6\u80de\u95f4\u901a\u4fe1\u53ca\u5176\u5bf9\u7ec6\u80de\u5185\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\u7684\u5f71\u54cd\uff0c\u80fd\u66f4\u51c6\u786e\u8868\u793a\u7ec6\u80de\u52a8\u529b\u5b66\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5c06\u7ec6\u80de\u89c6\u4e3a\u72ec\u7acb\u6570\u636e\u70b9\uff0c\u4f20\u7edfABM\u4f9d\u8d56\u624b\u5de5\u89c4\u5219\uff0c\u9700\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5b66\u4e60\u590d\u6742\u7ec6\u80de\u52a8\u529b\u5b66\u3002", "method": "\u5f15\u5165STAGED\u6a21\u578b\uff0c\u7ed3\u5408ABM\u4e0e\u6df1\u5ea6\u5b66\u4e60\uff0c\u7528\u56feODE\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u57fa\u56e0\u76f8\u4e92\u4f5c\u7528\u5f3a\u5ea6\u3002", "result": "\u6a21\u578b\u7ecf\u8bad\u7ec3\u5339\u914d\u6a21\u62df\u548c\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u6570\u636e\u63a8\u65ad\u7684\u8f68\u8ff9\uff0c\u80fd\u6355\u6349\u7ec6\u80de\u95f4\u548c\u7ec6\u80de\u5185\u76f8\u4e92\u4f5c\u7528\u3002", "conclusion": "\u8be5\u6a21\u578b\u66f4\u81ea\u9002\u5e94\u51c6\u786e\u5730\u8868\u793a\u7ec6\u80de\u52a8\u529b\u5b66\u3002"}}
{"id": "2507.12106", "pdf": "https://arxiv.org/pdf/2507.12106", "abs": "https://arxiv.org/abs/2507.12106", "authors": ["Antonio Salis", "Gabriele Troina", "Gianluca Boanelli", "Marco Ottaviano", "Paola Fortini", "Soraya Versace"], "title": "Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso", "categories": ["cs.DC", "cs.CY"], "comment": "18 pages, 6 Figures", "summary": "The efficient design and management of public green spaces is a key factor in\npromoting the health and well-being of urban population, as emphasized by the\nWHO, UNEP, and EEA. These areas serve as the \"green lungs\" of the urban\necosystem, playing a vital role in enhancing quality of life thanks to the\nprovision of ecosystem services. In this context, the Smart Green City use case\nin Campobasso municipality, funded by the Italian Ministry of Enterprises\n(MIMIT), emerges as an innovative model for the sustainable management of green\nurban areas through the adoption of an advanced system of emerging technologies\nintegrated and interoperable. The project integrates IoT systems and\ndata-driven governance platforms, enabling real-time monitoring of the health\nstatus of trees and green areas via a Decision Support System (DSS). It also\nfacilitates the collection and analysis of data from diverse sources, including\nweather conditions, air quality, soil moisture, pollution levels. The resulting\ncloud-based platform supports a holistic real time decision making for green\nurban managers, technical experts and operational staff. It enables intelligent\ncontrol and management of urban green spaces using Tree Talker sensors,\nintegrated with soil moisture and water potential monitoring systems. Thanks to\npredictive models based on machine learning algorithms and real time data\nprovided by IoT sensors, irrigation of public parks can be optimized by\nproviding suggestions on when and how much water to apply. Customized alerts\nlayers are also activated warning users when monitored parameters, such as soil\ntemperature, humidity, or water potential, exceed predefined thresholds. This\nUse Case demonstrates how digitalization, IoT sensors fusion and technological\ninnovation can support sustainable urban governance, fostering environmental\nresilience and improving citizens quality of life.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u610f\u5927\u5229Campobasso\u5e02\u667a\u80fd\u7eff\u8272\u57ce\u5e02\u9879\u76ee\uff0c\u901a\u8fc7\u65b0\u5174\u6280\u672f\u5b9e\u73b0\u57ce\u5e02\u7eff\u5730\u53ef\u6301\u7eed\u7ba1\u7406\uff0c\u63d0\u5347\u73af\u5883\u97e7\u6027\u4e0e\u5e02\u6c11\u751f\u6d3b\u8d28\u91cf\u3002", "motivation": "\u9ad8\u6548\u8bbe\u8ba1\u548c\u7ba1\u7406\u516c\u5171\u7eff\u5730\u5bf9\u4fc3\u8fdb\u57ce\u5e02\u4eba\u53e3\u5065\u5eb7\u548c\u798f\u7949\u81f3\u5173\u91cd\u8981\uff0c\u9879\u76ee\u65e8\u5728\u63d0\u4f9b\u57ce\u5e02\u7eff\u5730\u53ef\u6301\u7eed\u7ba1\u7406\u7684\u521b\u65b0\u6a21\u5f0f\u3002", "method": "\u96c6\u6210\u7269\u8054\u7f51\u7cfb\u7edf\u548c\u6570\u636e\u9a71\u52a8\u6cbb\u7406\u5e73\u53f0\uff0c\u5229\u7528\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5b9e\u65f6\u76d1\u6d4b\uff0c\u6536\u96c6\u591a\u6e90\u6570\u636e\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6784\u5efa\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u6784\u5efa\u57fa\u4e8e\u4e91\u7684\u5e73\u53f0\u652f\u6301\u5b9e\u65f6\u51b3\u7b56\uff0c\u5b9e\u73b0\u57ce\u5e02\u7eff\u5730\u667a\u80fd\u63a7\u5236\u548c\u7ba1\u7406\uff0c\u4f18\u5316\u516c\u56ed\u704c\u6e89\uff0c\u8bbe\u7f6e\u5b9a\u5236\u5316\u8b66\u62a5\u3002", "conclusion": "\u6570\u5b57\u5316\u3001\u7269\u8054\u7f51\u4f20\u611f\u5668\u878d\u5408\u548c\u6280\u672f\u521b\u65b0\u53ef\u652f\u6301\u53ef\u6301\u7eed\u57ce\u5e02\u6cbb\u7406\uff0c\u589e\u5f3a\u73af\u5883\u97e7\u6027\u5e76\u6539\u5584\u5e02\u6c11\u751f\u6d3b\u8d28\u91cf\u3002"}}
{"id": "2507.12186", "pdf": "https://arxiv.org/pdf/2507.12186", "abs": "https://arxiv.org/abs/2507.12186", "authors": ["Edward Kim", "Hanna Kurniawati"], "title": "Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation", "categories": ["cs.AI", "I.2.8; I.2.9"], "comment": "8 pages, 2 tables, 3 figures. To be presented at International Joint\n  Conference on Artificial Intelligence 2025", "summary": "This paper proposes Partially Observable Reference Policy Programming, a\nnovel anytime online approximate POMDP solver which samples meaningful future\nhistories very deeply while simultaneously forcing a gradual policy update. We\nprovide theoretical guarantees for the algorithm's underlying scheme which say\nthat the performance loss is bounded by the average of the sampling\napproximation errors rather than the usual maximum, a crucial requirement given\nthe sampling sparsity of online planning. Empirical evaluations on two\nlarge-scale problems with dynamically evolving environments -- including a\nhelicopter emergency scenario in the Corsica region requiring approximately 150\nplanning steps -- corroborate the theoretical results and indicate that our\nsolver considerably outperforms current online benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u5728\u7ebf\u8fd1\u4f3cPOMDP\u6c42\u89e3\u5668\uff0c\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u5b9e\u8bc1\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u89c4\u5212\u91c7\u6837\u7a00\u758f\u95ee\u9898\uff0c\u63d0\u9ad8POMDP\u6c42\u89e3\u6027\u80fd\u3002", "method": "\u63d0\u51faPartially Observable Reference Policy Programming\u6c42\u89e3\u5668\uff0c\u91c7\u6837\u6df1\u5ea6\u672a\u6765\u5386\u53f2\u5e76\u9010\u6b65\u66f4\u65b0\u7b56\u7565\uff0c\u4e14\u7ed9\u51fa\u7b97\u6cd5\u5e95\u5c42\u65b9\u6848\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5728\u4e24\u4e2a\u52a8\u6001\u73af\u5883\u5927\u89c4\u6a21\u95ee\u9898\u7684\u5b9e\u8bc1\u8bc4\u4f30\u4e2d\uff0c\u6c42\u89e3\u5668\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u5728\u7ebf\u57fa\u51c6\u3002", "conclusion": "\u6240\u63d0\u6c42\u89e3\u5668\u6709\u6548\uff0c\u80fd\u5728\u52a8\u6001\u73af\u5883\u5927\u89c4\u6a21\u95ee\u9898\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2507.12415", "pdf": "https://arxiv.org/pdf/2507.12415", "abs": "https://arxiv.org/abs/2507.12415", "authors": ["Xinyi He", "Qian Liu", "Mingzhe Du", "Lin Yan", "Zhijie Fan", "Yiming Huang", "Zejian Yuan", "Zejun Ma"], "title": "SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?", "categories": ["cs.SE"], "comment": null, "summary": "Code performance optimization is paramount in real-world software engineering\nand critical for production-level systems. While Large Language Models (LLMs)\nhave demonstrated impressive capabilities in code generation and bug fixing,\ntheir proficiency in enhancing code performance at the repository level remains\nlargely unexplored. To address this gap, we introduce SWE-Perf, the first\nbenchmark specifically designed to systematically evaluate LLMs on code\nperformance optimization tasks within authentic repository contexts. SWE-Perf\ncomprises 140 carefully curated instances, each derived from\nperformance-improving pull requests from popular GitHub repositories. Each\nbenchmark instance includes the relevant codebase, target functions,\nperformance-related tests, expert-authored patches, and executable\nenvironments. Through a comprehensive evaluation of representative methods that\nspan file-level and repo-level approaches (e.g., Agentless and OpenHands), we\nreveal a substantial capability gap between existing LLMs and expert-level\noptimization performance, highlighting critical research opportunities in this\nemerging field.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u6027\u80fd\u4f18\u5316\u80fd\u529b\u7684SWE - Perf\u57fa\u51c6\uff0c\u8bc4\u4f30\u540e\u53d1\u73b0\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4e13\u5bb6\u6c34\u5e73\u6709\u5dee\u8ddd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ed3\u5e93\u7ea7\u4ee3\u7801\u6027\u80fd\u4f18\u5316\u80fd\u529b\u65b9\u9762\u7684\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u5f15\u5165SWE - Perf\u57fa\u51c6\uff0c\u5176\u5305\u542b140\u4e2a\u7cbe\u5fc3\u6311\u9009\u7684\u5b9e\u4f8b\uff0c\u5bf9\u4ee3\u8868\u6027\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "result": "\u63ed\u793a\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4e13\u5bb6\u7ea7\u4f18\u5316\u6027\u80fd\u5b58\u5728\u663e\u8457\u80fd\u529b\u5dee\u8ddd\u3002", "conclusion": "\u4ee3\u7801\u6027\u80fd\u4f18\u5316\u9886\u57df\u5b58\u5728\u5173\u952e\u7814\u7a76\u673a\u4f1a\u3002"}}
{"id": "2507.11688", "pdf": "https://arxiv.org/pdf/2507.11688", "abs": "https://arxiv.org/abs/2507.11688", "authors": ["Travis Pence", "Daisuke Yamada", "Vikas Singh"], "title": "Composing Linear Layers from Irreducibles", "categories": ["cs.LG", "I.2.6"], "comment": "27 Pages, 13 Tables, 8 Figures", "summary": "Contemporary large models often exhibit behaviors suggesting the presence of\nlow-level primitives that compose into modules with richer functionality, but\nthese fundamental building blocks remain poorly understood. We investigate this\ncompositional structure in linear layers by asking: can we identify/synthesize\nlinear transformations from a minimal set of geometric primitives? Using\nClifford algebra, we show that linear layers can be expressed as compositions\nof bivectors -- geometric objects encoding oriented planes -- and introduce a\ndifferentiable algorithm that decomposes them into products of rotors. This\nconstruction uses only O(log^2 d) parameters, versus O(d^2) required by dense\nmatrices. Applied to the key, query, and value projections in LLM attention\nlayers, our rotor-based layers match the performance of strong baselines such\nas block-Hadamard and low-rank approximations. Our findings provide an\nalgebraic perspective on how these geometric primitives can compose into\nhigher-level functions within deep models.", "AI": {"tldr": "\u7814\u7a76\u7ebf\u6027\u5c42\u7684\u7ec4\u5408\u7ed3\u6784\uff0c\u7528Clifford\u4ee3\u6570\u5c06\u7ebf\u6027\u5c42\u8868\u793a\u4e3a\u53cc\u5411\u91cf\u7ec4\u5408\uff0c\u5f15\u5165\u53ef\u5fae\u7b97\u6cd5\u5206\u89e3\u4e3a\u8f6c\u5b50\u4e58\u79ef\uff0c\u5728LLM\u6ce8\u610f\u529b\u5c42\u4e2d\u6027\u80fd\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\uff0c\u63d0\u4f9b\u4ee3\u6570\u89c6\u89d2\u3002", "motivation": "\u5f53\u4ee3\u5927\u6a21\u578b\u4e2d\u4f4e\u5c42\u6b21\u57fa\u672c\u5143\u7d20\u6784\u6210\u66f4\u4e30\u5bcc\u529f\u80fd\u6a21\u5757\u7684\u57fa\u672c\u6784\u5efa\u5757\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u8981\u7814\u7a76\u7ebf\u6027\u5c42\u7684\u7ec4\u5408\u7ed3\u6784\uff0c\u8bc6\u522b/\u5408\u6210\u6765\u81ea\u6700\u5c0f\u51e0\u4f55\u57fa\u5143\u96c6\u7684\u7ebf\u6027\u53d8\u6362\u3002", "method": "\u4f7f\u7528Clifford\u4ee3\u6570\uff0c\u5c06\u7ebf\u6027\u5c42\u8868\u793a\u4e3a\u53cc\u5411\u91cf\u7684\u7ec4\u5408\uff0c\u5e76\u5f15\u5165\u53ef\u5fae\u7b97\u6cd5\u5c06\u5176\u5206\u89e3\u4e3a\u8f6c\u5b50\u7684\u4e58\u79ef\u3002", "result": "\u8be5\u6784\u9020\u4ec5\u4f7f\u7528O(log^2 d)\u53c2\u6570\uff0c\u800c\u5bc6\u96c6\u77e9\u9635\u9700\u8981O(d^2)\u53c2\u6570\uff1b\u5728LLM\u6ce8\u610f\u529b\u5c42\u7684\u952e\u3001\u67e5\u8be2\u548c\u503c\u6295\u5f71\u4e2d\uff0c\u57fa\u4e8e\u8f6c\u5b50\u7684\u5c42\u6027\u80fd\u4e0e\u5757Hadamard\u548c\u4f4e\u79e9\u8fd1\u4f3c\u7b49\u5f3a\u57fa\u7ebf\u76f8\u5f53\u3002", "conclusion": "\u7814\u7a76\u4e3a\u51e0\u4f55\u57fa\u5143\u5982\u4f55\u5728\u6df1\u5ea6\u6a21\u578b\u4e2d\u7ec4\u6210\u66f4\u9ad8\u7ea7\u529f\u80fd\u63d0\u4f9b\u4e86\u4ee3\u6570\u89c6\u89d2\u3002"}}
{"id": "2507.11847", "pdf": "https://arxiv.org/pdf/2507.11847", "abs": "https://arxiv.org/abs/2507.11847", "authors": ["Yu-Jie Zhang", "Sheng-An Xu", "Peng Zhao", "Masashi Sugiyama"], "title": "Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study the generalized linear bandit (GLB) problem, a contextual\nmulti-armed bandit framework that extends the classical linear model by\nincorporating a non-linear link function, thereby modeling a broad class of\nreward distributions such as Bernoulli and Poisson. While GLBs are widely\napplicable to real-world scenarios, their non-linear nature introduces\nsignificant challenges in achieving both computational and statistical\nefficiency. Existing methods typically trade off between two objectives, either\nincurring high per-round costs for optimal regret guarantees or compromising\nstatistical efficiency to enable constant-time updates. In this paper, we\npropose a jointly efficient algorithm that attains a nearly optimal regret\nbound with $\\mathcal{O}(1)$ time and space complexities per round. The core of\nour method is a tight confidence set for the online mirror descent (OMD)\nestimator, which is derived through a novel analysis that leverages the notion\nof mix loss from online prediction. The analysis shows that our OMD estimator,\neven with its one-pass updates, achieves statistical efficiency comparable to\nmaximum likelihood estimation, thereby leading to a jointly efficient\noptimistic method.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5e7f\u4e49\u7ebf\u6027\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u63d0\u51fa\u8054\u5408\u9ad8\u6548\u7b97\u6cd5\uff0c\u6bcf\u8f6e\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3aO(1)\u4e14\u80fd\u8fbe\u5230\u8fd1\u4f3c\u6700\u4f18\u9057\u61be\u754c\u3002", "motivation": "\u5e7f\u4e49\u7ebf\u6027\u591a\u81c2\u8001\u864e\u673a\u5728\u8ba1\u7b97\u548c\u7edf\u8ba1\u6548\u7387\u4e0a\u5b58\u5728\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u5728\u4e24\u4e2a\u76ee\u6807\u95f4\u6743\u8861\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5728\u7ebf\u955c\u50cf\u4e0b\u964d\u4f30\u8ba1\u5668\u7684\u7d27\u7f6e\u4fe1\u96c6\uff0c\u5229\u7528\u5728\u7ebf\u9884\u6d4b\u4e2d\u7684\u6df7\u5408\u635f\u5931\u6982\u5ff5\u8fdb\u884c\u5206\u6790\u3002", "result": "\u6240\u63d0\u7b97\u6cd5\u6bcf\u8f6e\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e3aO(1)\uff0c\u80fd\u8fbe\u5230\u8fd1\u4f3c\u6700\u4f18\u9057\u61be\u754c\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u5b9e\u73b0\u4e86\u8ba1\u7b97\u548c\u7edf\u8ba1\u6548\u7387\u7684\u8054\u5408\u4f18\u5316\u3002"}}
{"id": "2507.12205", "pdf": "https://arxiv.org/pdf/2507.12205", "abs": "https://arxiv.org/abs/2507.12205", "authors": ["Junqing Lin", "Jingwei Sun", "Mingge Lu", "Guangzhong Sun"], "title": "Toward Efficient SpMV in Sparse LLMs via Block Extraction and Compressed Storage", "categories": ["cs.DC"], "comment": "11 pages", "summary": "Sparse Matrix-Vector Multiplication (SpMV) has become a critical performance\nbottleneck in the local deployment of sparse Large Language Models (LLMs),\nwhere inference predominantly operates on workloads during the decoder phase\nwith a batch size of one. Existing SpMV kernels and sparse matrix formats,\noriginally designed for scientific computing, fail to exploit the unique\nstructure patterns inherent in sparse LLMs, resulting in suboptimal performance\nand excessive storage overhead. This paper presents EC-SpMV, a GPU-optimized\nSpMV approach for accelerating sparse LLM inference. EC-SpMV introduces (1) a\nhierarchical block extraction algorithm that captures multiple granularities of\nblock structures within sparse LLMs, and (2) a novel compressed sparse format\n(EC-CSR) that employs delta indexing to reduce storage overhead and enhance\nmemory access efficiency. Evaluated on real sparse weight matrices from LLaMA\nand OPT models, EC-SpMV achieves up to 6.44x speedup over state-of-the-art SpMV\nlibraries and reduces storage overhead by up to 55.4% compared to CSR.", "AI": {"tldr": "\u63d0\u51faEC - SpMV\u52a0\u901f\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u8bc4\u4f30\u663e\u793a\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u548c\u5b58\u50a8\u5f00\u9500\u964d\u4f4e\u3002", "motivation": "\u73b0\u6709SpMV\u5185\u6838\u548c\u7a00\u758f\u77e9\u9635\u683c\u5f0f\u7528\u4e8e\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u6027\u80fd\u4e0d\u4f73\u4e14\u5b58\u50a8\u5f00\u9500\u5927\uff0c\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u3002", "method": "\u5f15\u5165\u5206\u5c42\u5757\u63d0\u53d6\u7b97\u6cd5\u6355\u6349\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u5185\u591a\u79cd\u7c92\u5ea6\u7684\u5757\u7ed3\u6784\uff0c\u91c7\u7528\u65b0\u578b\u538b\u7f29\u7a00\u758f\u683c\u5f0fEC - CSR\u901a\u8fc7\u589e\u91cf\u7d22\u5f15\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\u5e76\u63d0\u9ad8\u5185\u5b58\u8bbf\u95ee\u6548\u7387\u3002", "result": "\u5728LLaMA\u548cOPT\u6a21\u578b\u7684\u771f\u5b9e\u7a00\u758f\u6743\u91cd\u77e9\u9635\u4e0a\u8bc4\u4f30\uff0cEC - SpMV\u6bd4\u73b0\u6709SpMV\u5e93\u6700\u9ad8\u52a0\u901f6.44\u500d\uff0c\u6bd4CSR\u6700\u591a\u964d\u4f4e55.4%\u5b58\u50a8\u5f00\u9500\u3002", "conclusion": "EC - SpMV\u80fd\u6709\u6548\u52a0\u901f\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\u3002"}}
{"id": "2507.11948", "pdf": "https://arxiv.org/pdf/2507.11948", "abs": "https://arxiv.org/abs/2507.11948", "authors": ["Carlo Baronio", "Pietro Marsella", "Ben Pan", "Simon Guo", "Silas Alberti"], "title": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "comment": null, "summary": "Writing GPU kernels is a challenging task and critical for AI systems'\nefficiency. It is also highly iterative: domain experts write code and improve\nperformance through execution feedback. Moreover, it presents verifiable\nrewards like correctness and speedup, making it a natural environment to apply\nReinforcement Learning (RL). To explicitly incorporate the iterative nature of\nthis process into training, we develop a flexible multi-turn RL recipe that\naddresses unique challenges encountered in real-world settings, such as\nlearning from long trajectories and effective reward attribution across turns.\nWe present Kevin - K(ernel D)evin, the first model trained with multi-turn RL\nfor CUDA kernel generation and optimization. In our evaluation setup, Kevin\nshows significant gains over its base model (QwQ-32B), improving correctness of\ngenerated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to\n1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini\n(0.78x). Finally, we study its behavior across test-time scaling axes: we found\nscaling serial refinement more beneficial than parallel sampling. In\nparticular, when given more refinement turns, Kevin shows a higher rate of\nimprovement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684Kevin\u6a21\u578b\u8fdb\u884cCUDA\u5185\u6838\u751f\u6210\u4e0e\u4f18\u5316\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u8fd8\u7814\u7a76\u4e86\u6d4b\u8bd5\u65f6\u7684\u7f29\u653e\u8f74\u884c\u4e3a\u3002", "motivation": "\u7f16\u5199GPU\u5185\u6838\u5177\u6709\u6311\u6218\u6027\u4e14\u5bf9AI\u7cfb\u7edf\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u5176\u8fed\u4ee3\u6027\u548c\u53ef\u9a8c\u8bc1\u5956\u52b1\u7279\u6027\u9002\u5408\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\uff0c\u9700\u5c06\u8fed\u4ee3\u8fc7\u7a0b\u7eb3\u5165\u8bad\u7ec3\u3002", "method": "\u5f00\u53d1\u7075\u6d3b\u7684\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8bad\u7ec3\u51faKevin\u6a21\u578b\u7528\u4e8eCUDA\u5185\u6838\u751f\u6210\u4e0e\u4f18\u5316\u3002", "result": "Kevin\u6a21\u578b\u6bd4\u5176\u57fa\u7840\u6a21\u578bQwQ - 32B\u6709\u663e\u8457\u63d0\u5347\uff0c\u7eafCUDA\u751f\u6210\u5185\u6838\u7684\u6b63\u786e\u6027\u4ece56%\u63d0\u5347\u523082%\uff0c\u5e73\u5747\u52a0\u901f\u6bd4\u4ece0.53x\u63d0\u5347\u52301.10x\uff0c\u8d85\u8fc7o4 - mini\u7b49\u524d\u6cbf\u6a21\u578b\u3002", "conclusion": "\u4e32\u884c\u7ec6\u5316\u6bd4\u5e76\u884c\u91c7\u6837\u66f4\u6709\u76ca\uff0c\u66f4\u591a\u7ec6\u5316\u8f6e\u6b21\u4e0bKevin\u6a21\u578b\u6539\u8fdb\u7387\u66f4\u9ad8\u3002"}}
{"id": "2507.11690", "pdf": "https://arxiv.org/pdf/2507.11690", "abs": "https://arxiv.org/abs/2507.11690", "authors": ["Amaya Dharmasiri", "William Yang", "Polina Kirichenko", "Lydia Liu", "Olga Russakovsky"], "title": "The Impact of Coreset Selection on Spurious Correlations and Group Robustness", "categories": ["cs.LG", "cs.CV"], "comment": "10 pages, 9 additional pages for Appendix", "summary": "Coreset selection methods have shown promise in reducing the training data\nsize while maintaining model performance for data-efficient machine learning.\nHowever, as many datasets suffer from biases that cause models to learn\nspurious correlations instead of causal features, it is important to understand\nwhether and how dataset reduction methods may perpetuate, amplify, or mitigate\nthese biases. In this work, we conduct the first comprehensive analysis of the\nimplications of data selection on the spurious bias levels of the selected\ncoresets and the robustness of downstream models trained on them. We use an\nextensive experimental setting spanning ten different spurious correlations\nbenchmarks, five score metrics to characterize sample importance/ difficulty,\nand five data selection policies across a broad range of coreset sizes.\nThereby, we unravel a series of nontrivial nuances in interactions between\nsample difficulty and bias alignment, as well as dataset bias and resultant\nmodel robustness. For example, we find that selecting coresets using\nembedding-based sample characterization scores runs a comparatively lower risk\nof inadvertently exacerbating bias than selecting using characterizations based\non learning dynamics. Most importantly, our analysis reveals that although some\ncoreset selection methods could achieve lower bias levels by prioritizing\ndifficult samples, they do not reliably guarantee downstream robustness.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6570\u636e\u9009\u62e9\u5bf9\u6240\u9009\u6838\u5fc3\u96c6\u7684\u865a\u5047\u504f\u5dee\u6c34\u5e73\u53ca\u4e0b\u6e38\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u8fdb\u884c\u5168\u9762\u5206\u6790\uff0c\u53d1\u73b0\u5d4c\u5165\u8868\u5f81\u9009\u6838\u5fc3\u96c6\u81f4\u504f\u5dee\u98ce\u9669\u4f4e\uff0c\u4f18\u5148\u9009\u96be\u6837\u672c\u7684\u65b9\u6cd5\u4e0d\u80fd\u4fdd\u8bc1\u4e0b\u6e38\u9c81\u68d2\u6027\u3002", "motivation": "\u8bb8\u591a\u6570\u636e\u96c6\u5b58\u5728\u504f\u5dee\uff0c\u9700\u4e86\u89e3\u6570\u636e\u96c6\u7f29\u51cf\u65b9\u6cd5\u5bf9\u504f\u5dee\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u6db5\u76d6\u5341\u79cd\u865a\u5047\u76f8\u5173\u6027\u57fa\u51c6\u3001\u4e94\u79cd\u6837\u672c\u91cd\u8981\u6027/\u96be\u5ea6\u8bc4\u5206\u6307\u6807\u548c\u4e94\u79cd\u6570\u636e\u9009\u62e9\u7b56\u7565\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bbe\u7f6e\u3002", "result": "\u53d1\u73b0\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u6837\u672c\u8868\u5f81\u5206\u6570\u9009\u62e9\u6838\u5fc3\u96c6\u6bd4\u57fa\u4e8e\u5b66\u4e60\u52a8\u6001\u7684\u8868\u5f81\u9009\u62e9\u5bfc\u81f4\u504f\u5dee\u7684\u98ce\u9669\u76f8\u5bf9\u8f83\u4f4e\uff1b\u4f18\u5148\u9009\u62e9\u56f0\u96be\u6837\u672c\u7684\u6838\u5fc3\u96c6\u9009\u62e9\u65b9\u6cd5\u867d\u80fd\u964d\u4f4e\u504f\u5dee\u6c34\u5e73\uff0c\u4f46\u4e0d\u80fd\u53ef\u9760\u4fdd\u8bc1\u4e0b\u6e38\u9c81\u68d2\u6027\u3002", "conclusion": "\u6838\u5fc3\u96c6\u9009\u62e9\u65b9\u6cd5\u4e0e\u504f\u5dee\u548c\u6a21\u578b\u9c81\u68d2\u6027\u5b58\u5728\u590d\u6742\u5173\u7cfb\uff0c\u4f18\u5148\u9009\u96be\u6837\u672c\u7684\u65b9\u6cd5\u65e0\u6cd5\u53ef\u9760\u4fdd\u8bc1\u4e0b\u6e38\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.11922", "pdf": "https://arxiv.org/pdf/2507.11922", "abs": "https://arxiv.org/abs/2507.11922", "authors": ["Jingtian Bai", "Xinge Jessie Jeng"], "title": "Enhancing Signal Proportion Estimation Through Leveraging Arbitrary Covariance Structures", "categories": ["math.ST", "stat.ME", "stat.ML", "stat.TH"], "comment": null, "summary": "Accurately estimating the proportion of true signals among a large number of\nvariables is crucial for enhancing the precision and reliability of scientific\nresearch. Traditional signal proportion estimators often assume independence\namong variables and specific signal sparsity conditions, limiting their\napplicability in real-world scenarios where such assumptions may not hold. This\npaper introduces a novel signal proportion estimator that leverages arbitrary\ncovariance dependence information among variables, thereby improving\nperformance across a wide range of sparsity levels and dependence structures.\nBuilding on previous work that provides lower confidence bounds for signal\nproportions, we extend this approach by incorporating the principal factor\napproximation procedure to account for variable dependence. Our theoretical\ninsights offer a deeper understanding of how signal sparsity, signal intensity,\nand covariance dependence interact. By comparing the conditions for estimation\nconsistency before and after dependence adjustment, we highlight the advantages\nof integrating dependence information across different contexts. This\ntheoretical foundation not only validates the effectiveness of the new\nestimator but also guides its practical application, ensuring reliable use in\ndiverse scenarios. Through extensive simulations, we demonstrate that our\nmethod outperforms state-of-the-art estimators in both estimation accuracy and\nthe detection of weaker signals that might otherwise go undetected.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u7684\u4fe1\u53f7\u6bd4\u4f8b\u4f30\u8ba1\u5668\uff0c\u7ed3\u5408\u53d8\u91cf\u4f9d\u8d56\u4fe1\u606f\uff0c\u7406\u8bba\u5206\u6790\u5176\u6709\u6548\u6027\u5e76\u901a\u8fc7\u6a21\u62df\u8bc1\u660e\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u4fe1\u53f7\u6bd4\u4f8b\u4f30\u8ba1\u5668\u5047\u8bbe\u53d8\u91cf\u72ec\u7acb\u548c\u7279\u5b9a\u7a00\u758f\u6761\u4ef6\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u9002\u7528\u6027\u6709\u9650\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u57fa\u4e8e\u5df2\u6709\u4fe1\u53f7\u6bd4\u4f8b\u4e0b\u754c\u7f6e\u4fe1\u533a\u95f4\u5de5\u4f5c\uff0c\u7eb3\u5165\u4e3b\u56e0\u5b50\u8fd1\u4f3c\u8fc7\u7a0b\u5904\u7406\u53d8\u91cf\u4f9d\u8d56\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u8868\u660e\u65b0\u65b9\u6cd5\u5728\u4f30\u8ba1\u51c6\u786e\u6027\u548c\u68c0\u6d4b\u5f31\u4fe1\u53f7\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u4f30\u8ba1\u5668\u80fd\u5229\u7528\u53d8\u91cf\u4f9d\u8d56\u4fe1\u606f\uff0c\u5728\u4e0d\u540c\u7a00\u758f\u6c34\u5e73\u548c\u4f9d\u8d56\u7ed3\u6784\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u7406\u8bba\u57fa\u7840\u4fdd\u8bc1\u5176\u5728\u591a\u6837\u573a\u666f\u53ef\u9760\u5e94\u7528\u3002"}}
{"id": "2507.12215", "pdf": "https://arxiv.org/pdf/2507.12215", "abs": "https://arxiv.org/abs/2507.12215", "authors": ["Yuhao Chen", "Shuochen Liu", "Yuanjie Lyu", "Chao Zhang", "Jiayao Shi", "Tong Xu"], "title": "Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning", "categories": ["cs.AI"], "comment": "10 pages, 7 figures", "summary": "Game playing has long served as a fundamental benchmark for evaluating\nArtificial General Intelligence (AGI). While Large Language Models (LLMs) have\ndemonstrated impressive capabilities in general reasoning, their effectiveness\nin spatial strategic reasoning, which is critical for complex and fully\nobservable board games, remains insufficiently explored. In this work, we adopt\nChinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate\nrules and spatial complexity. To advance LLMs' strategic competence in such\nenvironments, we propose a training framework tailored to Xiangqi, built upon a\nlarge-scale dataset of five million board-move pairs enhanced with expert\nannotations and engine evaluations. Building on this foundation, we introduce\nXiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning\nfor legal move prediction to capture basic spatial rules, (2) incorporating\nstrategic annotations to improve decision-making, and (3) applying\nreinforcement learning via Group Relative Policy Optimization (GRPO) with\nmulti-dimensional reward signals to enhance reasoning stability. Our\nExperimental results indicate that, despite their size and power,\ngeneral-purpose LLMs struggle to achieve satisfactory performance in these\ntasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an\n18% rise in move legality and a 22% boost in analysis accuracy. Our results\npoint to a promising path for creating general strategic intelligence in\nspatially complex areas.", "AI": {"tldr": "\u6587\u7ae0\u4ee5\u4e2d\u56fd\u8c61\u68cb\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u63d0\u51fa\u9488\u5bf9\u8c61\u68cb\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u8bad\u7ec3\u51fa7B\u53c2\u6570\u7684Xiangqi - R1\u6a21\u578b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u76f8\u6bd4\u901a\u7528\u5927\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u7a7a\u95f4\u590d\u6742\u9886\u57df\u6218\u7565\u667a\u80fd\u53d1\u5c55\u6307\u660e\u65b9\u5411\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u6218\u7565\u63a8\u7406\u65b9\u9762\u80fd\u529b\u63a2\u7d22\u4e0d\u8db3\uff0c\u800c\u8fd9\u5bf9\u590d\u6742\u68cb\u76d8\u6e38\u620f\u5f88\u5173\u952e\uff0c\u9700\u63d0\u5347\u5176\u5728\u8fd9\u7c7b\u73af\u5883\u4e2d\u7684\u6218\u7565\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e2d\u56fd\u8c61\u68cb\u4e3a\u6d4b\u8bd5\u5e73\u53f0\uff0c\u57fa\u4e8e\u4e94\u767e\u4e07\u68cb\u76d8 - \u8d70\u6cd5\u5bf9\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u4e13\u5bb6\u6ce8\u91ca\u548c\u5f15\u64ce\u8bc4\u4f30\uff0c\u5206\u4e09\u9636\u6bb5\u8bad\u7ec37B\u53c2\u6570\u7684Xiangqi - R1\u6a21\u578b\u3002", "result": "\u901a\u7528\u5927\u6a21\u578b\u5728\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0cXiangqi - R1\u8d70\u6cd5\u5408\u6cd5\u6027\u63d0\u534718%\uff0c\u5206\u6790\u51c6\u786e\u7387\u63d0\u534722%\u3002", "conclusion": "\u4e3a\u7a7a\u95f4\u590d\u6742\u9886\u57df\u521b\u5efa\u901a\u7528\u6218\u7565\u667a\u80fd\u6307\u51fa\u4e86\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2507.12003", "pdf": "https://arxiv.org/pdf/2507.12003", "abs": "https://arxiv.org/abs/2507.12003", "authors": ["Cara Ellen Appel"], "title": "Expanding ML-Documentation Standards For Better Security", "categories": ["cs.CR", "cs.LG", "cs.SE"], "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering Workshop (REW 2025)", "summary": "This article presents the current state of ML-security and of the\ndocumentation of ML-based systems, models and datasets in research and practice\nbased on an extensive review of the existing literature. It shows a generally\nlow awareness of security aspects among ML-practitioners and organizations and\nan often unstandardized approach to documentation, leading to overall low\nquality of ML-documentation. Existing standards are not regularly adopted in\npractice and IT-security aspects are often not included in documentation. Due\nto these factors, there is a clear need for improved security documentation in\nML, as one step towards addressing the existing gaps in ML-security. To achieve\nthis, we propose expanding existing documentation standards for\nML-documentation to include a security section with specific security relevant\ninformation. Implementing this, a novel expanded method of documenting security\nrequirements in ML-documentation is presented, based on the existing Model\nCards and Datasheets for Datasets standards, but with the recommendation to\nadopt these findings in all ML-documentation.", "AI": {"tldr": "\u6587\u7ae0\u57fa\u4e8e\u6587\u732e\u7efc\u8ff0\u5206\u6790ML\u5b89\u5168\u4e0e\u6587\u6863\u73b0\u72b6\uff0c\u6307\u51fa\u95ee\u9898\u5e76\u63d0\u51fa\u6269\u5c55\u73b0\u6709\u6807\u51c6\u4ee5\u5305\u542b\u5b89\u5168\u90e8\u5206\u7684\u5efa\u8bae\u3002", "motivation": "\u5f53\u524dML\u4ece\u4e1a\u8005\u548c\u7ec4\u7ec7\u5bf9\u5b89\u5168\u65b9\u9762\u610f\u8bc6\u4f4e\uff0c\u6587\u6863\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u8d28\u91cf\u5dee\uff0c\u9700\u6539\u8fdbML\u5b89\u5168\u6587\u6863\u3002", "method": "\u5e7f\u6cdb\u56de\u987e\u73b0\u6709\u6587\u732e\uff0c\u57fa\u4e8e\u73b0\u6709Model Cards\u548cDatasheets for Datasets\u6807\u51c6\uff0c\u63d0\u51fa\u6269\u5c55ML\u6587\u6863\u6807\u51c6\u4ee5\u5305\u542b\u5b89\u5168\u90e8\u5206\u3002", "result": "\u53d1\u73b0ML\u4ece\u4e1a\u8005\u548c\u7ec4\u7ec7\u5b89\u5168\u610f\u8bc6\u4f4e\u3001\u6587\u6863\u4e0d\u89c4\u8303\u3001\u672a\u91c7\u7528\u73b0\u6709\u6807\u51c6\u7b49\u95ee\u9898\u3002", "conclusion": "\u6709\u5fc5\u8981\u6539\u8fdbML\u5b89\u5168\u6587\u6863\uff0c\u5efa\u8bae\u5728\u6240\u6709ML\u6587\u6863\u4e2d\u91c7\u7528\u6269\u5c55\u7684\u5b89\u5168\u8981\u6c42\u8bb0\u5f55\u65b9\u6cd5\u3002"}}
{"id": "2507.11702", "pdf": "https://arxiv.org/pdf/2507.11702", "abs": "https://arxiv.org/abs/2507.11702", "authors": ["Hein de Wilde", "Ali Mohammed Mansoor Alsahag", "Pierre Blanchet"], "title": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Railroad traffic disruption as a result of leaf-fall cost the UK rail\nindustry over 300 million per year and measures to mitigate such disruptions\nare employed on a large scale, with 1.67 million kilometers of track being\ntreated in the UK in 2021 alone. Therefore, the ability to anticipate the\ntiming of leaf-fall would offer substantial benefits for rail network\noperators, enabling the efficient scheduling of such mitigation measures.\nHowever, current methodologies for predicting leaf-fall exhibit considerable\nlimitations in terms of scalability and reliability. This study endeavors to\ndevise a prediction system that leverages specialized prediction methods and\nthe latest satellite data sources to generate both scalable and reliable\ninsights into leaf-fall timings. An LSTM network trained on ground-truth\nleaf-falling data combined with multispectral and meteorological satellite data\ndemonstrated a root-mean-square error of 6.32 days for predicting the start of\nleaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which\nimproves upon previous work on the topic, offers promising opportunities for\nthe optimization of leaf mitigation measures in the railway industry and the\nimprovement of our understanding of complex ecological systems.", "AI": {"tldr": "\u94c1\u8def\u843d\u53f6\u9020\u6210\u5de8\u5927\u635f\u5931\uff0c\u5f53\u524d\u843d\u53f6\u9884\u6d4b\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u7814\u7a76\u7528\u65b0\u7cfb\u7edf\u9884\u6d4b\u843d\u53f6\u65f6\u95f4\uff0c\u7ed3\u679c\u8f83\u597d\uff0c\u6709\u671b\u4f18\u5316\u94c1\u8def\u843d\u53f6\u7f13\u89e3\u63aa\u65bd\u3002", "motivation": "\u94c1\u8def\u843d\u53f6\u81f4\u82f1\u56fd\u94c1\u8def\u884c\u4e1a\u6bcf\u5e74\u635f\u5931\u8d853\u4ebf\u82f1\u9551\uff0c\u5f53\u524d\u9884\u6d4b\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u9700\u51c6\u786e\u9884\u6d4b\u843d\u53f6\u65f6\u95f4\u4ee5\u9ad8\u6548\u5b89\u6392\u7f13\u89e3\u63aa\u65bd\u3002", "method": "\u5229\u7528\u4e13\u4e1a\u9884\u6d4b\u65b9\u6cd5\u548c\u6700\u65b0\u536b\u661f\u6570\u636e\u6e90\uff0c\u7528\u5730\u9762\u843d\u53f6\u6570\u636e\u3001\u591a\u5149\u8c31\u548c\u6c14\u8c61\u536b\u661f\u6570\u636e\u8bad\u7ec3LSTM\u7f51\u7edc\u3002", "result": "\u9884\u6d4b\u843d\u53f6\u5f00\u59cb\u65f6\u95f4\u7684\u5747\u65b9\u6839\u8bef\u5dee\u4e3a6.32\u5929\uff0c\u7ed3\u675f\u65f6\u95f4\u4e3a9.31\u5929\u3002", "conclusion": "\u8be5\u6a21\u578b\u6539\u8fdb\u4e86\u4ee5\u5f80\u7814\u7a76\uff0c\u4e3a\u94c1\u8def\u884c\u4e1a\u4f18\u5316\u843d\u53f6\u7f13\u89e3\u63aa\u65bd\u548c\u7406\u89e3\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002"}}
{"id": "2507.12246", "pdf": "https://arxiv.org/pdf/2507.12246", "abs": "https://arxiv.org/abs/2507.12246", "authors": ["Vishwak Srinivasan", "Qijia Jiang"], "title": "Designing Algorithms for Entropic Optimal Transport from an Optimisation Perspective", "categories": ["math.OC", "math.PR", "stat.ML"], "comment": "37 pages. Comments / feedback welcome!", "summary": "In this work, we develop a collection of novel methods for the\nentropic-regularised optimal transport problem, which are inspired by existing\nmirror descent interpretations of the Sinkhorn algorithm used for solving this\nproblem. These are fundamentally proposed from an optimisation perspective:\neither based on the associated semi-dual problem, or based on solving a\nnon-convex constrained problem over subset of joint distributions. This\noptimisation viewpoint results in non-asymptotic rates of convergence for the\nproposed methods under minimal assumptions on the problem structure. We also\npropose a momentum-equipped method with provable accelerated guarantees through\nthis viewpoint, akin to those in the Euclidean setting. The broader framework\nwe develop based on optimisation over the joint distributions also finds an\nanalogue in the dynamical Schr\\\"{o}dinger bridge problem.", "AI": {"tldr": "\u672c\u6587\u53d7Sinkhorn\u7b97\u6cd5\u955c\u50cf\u4e0b\u964d\u89e3\u91ca\u542f\u53d1\uff0c\u4e3a\u71b5\u6b63\u5219\u5316\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u5f00\u53d1\u65b0\u65b9\u6cd5\uff0c\u6709\u975e\u6e10\u8fd1\u6536\u655b\u7387\uff0c\u8fd8\u63d0\u51fa\u6709\u52a0\u901f\u4fdd\u8bc1\u7684\u52a8\u91cf\u65b9\u6cd5\uff0c\u6846\u67b6\u53ef\u7528\u4e8e\u859b\u5b9a\u8c14\u6865\u95ee\u9898\u3002", "motivation": "\u4e3a\u71b5\u6b63\u5219\u5316\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u5f00\u53d1\u65b0\u65b9\u6cd5\uff0c\u4ece\u4f18\u5316\u89d2\u5ea6\u63d0\u4f9b\u89e3\u51b3\u601d\u8def\u3002", "method": "\u4ece\u4f18\u5316\u89c6\u89d2\u51fa\u53d1\uff0c\u57fa\u4e8e\u534a\u5bf9\u5076\u95ee\u9898\u6216\u5728\u8054\u5408\u5206\u5e03\u5b50\u96c6\u4e0a\u89e3\u51b3\u975e\u51f8\u7ea6\u675f\u95ee\u9898\uff0c\u8fd8\u63d0\u51fa\u52a8\u91cf\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u5bf9\u95ee\u9898\u7ed3\u6784\u6700\u5c0f\u5047\u8bbe\u4e0b\u6709\u975e\u6e10\u8fd1\u6536\u655b\u7387\uff0c\u52a8\u91cf\u65b9\u6cd5\u6709\u53ef\u8bc1\u660e\u7684\u52a0\u901f\u4fdd\u8bc1\u3002", "conclusion": "\u5f00\u53d1\u7684\u57fa\u4e8e\u8054\u5408\u5206\u5e03\u4f18\u5316\u7684\u66f4\u5e7f\u6cdb\u6846\u67b6\u53ef\u5e94\u7528\u4e8e\u52a8\u6001\u859b\u5b9a\u8c14\u6865\u95ee\u9898\u3002"}}
{"id": "2507.11543", "pdf": "https://arxiv.org/pdf/2507.11543", "abs": "https://arxiv.org/abs/2507.11543", "authors": ["Iman Reihanian", "Yunfei Hou", "Yu Chen", "Yifei Zheng"], "title": "A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment", "categories": ["cs.CY", "cs.AI"], "comment": "Accepted for presentation at The 2024 International Conference on\n  Computational Science and Computational Intelligence (CSCI), Research Track\n  on Education. To appear in Springer Lecture Notes in Computer Science (LNCS)\n  proceedings, expected July 2025", "summary": "This paper surveys the use of Generative AI tools, such as ChatGPT and\nClaude, in computer science education, focusing on key aspects of accuracy,\nauthenticity, and assessment. Through a literature review, we highlight both\nthe challenges and opportunities these AI tools present. While Generative AI\nimproves efficiency and supports creative student work, it raises concerns such\nas AI hallucinations, error propagation, bias, and blurred lines between\nAI-assisted and student-authored content. Human oversight is crucial for\naddressing these concerns. Existing literature recommends adopting hybrid\nassessment models that combine AI with human evaluation, developing bias\ndetection frameworks, and promoting AI literacy for both students and\neducators. Our findings suggest that the successful integration of AI requires\na balanced approach, considering ethical, pedagogical, and technical factors.\nFuture research may explore enhancing AI accuracy, preserving academic\nintegrity, and developing adaptive models that balance creativity with\nprecision.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u6307\u51fa\u673a\u9047\u4e0e\u6311\u6218\uff0c\u5f3a\u8c03\u9700\u5e73\u8861\u5404\u56e0\u7d20\u5e76\u7ed9\u51fa\u5efa\u8bae\uff0c\u8fd8\u63d0\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u7a76\u751f\u6210\u5f0fAI\u5de5\u5177\uff08\u5982ChatGPT\u548cClaude\uff09\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u7684\u65b9\u6cd5\u3002", "result": "\u751f\u6210\u5f0fAI\u63d0\u9ad8\u6548\u7387\u3001\u652f\u6301\u5b66\u751f\u521b\u610f\u4f5c\u54c1\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u3001\u8bef\u5dee\u4f20\u64ad\u3001\u504f\u89c1\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u6587\u732e\u63a8\u8350\u91c7\u7528\u6df7\u5408\u8bc4\u4f30\u6a21\u578b\u3001\u5f00\u53d1\u504f\u89c1\u68c0\u6d4b\u6846\u67b6\u548c\u63d0\u5347AI\u7d20\u517b\u3002", "conclusion": "AI\u7684\u6210\u529f\u96c6\u6210\u9700\u8981\u5e73\u8861\u4f26\u7406\u3001\u6559\u5b66\u548c\u6280\u672f\u56e0\u7d20\uff0c\u672a\u6765\u53ef\u63a2\u7d22\u63d0\u9ad8AI\u51c6\u786e\u6027\u3001\u7ef4\u62a4\u5b66\u672f\u8bda\u4fe1\u548c\u5f00\u53d1\u81ea\u9002\u5e94\u6a21\u578b\u3002"}}
{"id": "2507.11941", "pdf": "https://arxiv.org/pdf/2507.11941", "abs": "https://arxiv.org/abs/2507.11941", "authors": ["Amos You"], "title": "BlockBPE: Parallel BPE Tokenization", "categories": ["cs.CL", "cs.DC"], "comment": "ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models\n  (ICML 2025)", "summary": "Tokenization is a critical preprocessing step in large language model\npipelines, yet widely-used implementations remain CPU-bound and suboptimal for\nbatch inference workflows on GPU. We present BlockBPE, a parallel GPU\nimplementation of byte-pair encoding (BPE) that achieves near linear-time\ncomplexity under realistic assumptions and is optimized for high-throughput,\nbatch inference. Unlike existing Rust-based tokenizers such as HuggingFace\nTokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex\npre-tokenization and exhibit $O(n \\log n)$ runtime-BlockBPE eliminates the\nRegex pre-tokenization which leads to small loss in generation quality, but\nenables highly parallelized token merges within thread blocks, reducing overall\ncomplexity to $O(nd)$ where $d \\ll n$. On high-batch inference workloads,\nBlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over\nHuggingFace Tokenizers.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u884cGPU\u5b9e\u73b0\u7684BlockBPE\u5206\u8bcd\u5668\uff0c\u4f18\u5316\u9ad8\u541e\u5410\u91cf\u6279\u91cf\u63a8\u7406\uff0c\u51cf\u5c11\u590d\u6742\u5ea6\uff0c\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u5206\u8bcd\u5668CPU\u53d7\u9650\uff0c\u5728GPU\u6279\u91cf\u63a8\u7406\u5de5\u4f5c\u6d41\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faBlockBPE\uff0c\u6d88\u9664Regex\u9884\u5206\u8bcd\uff0c\u5b9e\u73b0\u7ebf\u7a0b\u5757\u5185\u9ad8\u5ea6\u5e76\u884c\u7684\u6807\u8bb0\u5408\u5e76\u3002", "result": "\u5728\u9ad8\u6279\u91cf\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0cBlockBPE\u541e\u5410\u91cf\u6bd4tiktoken\u9ad82\u500d\uff0c\u6bd4HuggingFace Tokenizers\u9ad82.5\u500d\u3002", "conclusion": "BlockBPE\u80fd\u5728\u63a5\u8fd1\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u4e0b\u4f18\u5316\u9ad8\u541e\u5410\u91cf\u6279\u91cf\u63a8\u7406\u3002"}}
{"id": "2507.11548", "pdf": "https://arxiv.org/pdf/2507.11548", "abs": "https://arxiv.org/abs/2507.11548", "authors": ["Kevin T Webster"], "title": "Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening", "categories": ["cs.CY", "cs.AI", "cs.CL", "I.2.1; K.4.2; I.2.6; K.4.1"], "comment": "58 pages, 4 figures", "summary": "The increasing use of generative AI for resume screening is predicated on the\nassumption that it offers an unbiased alternative to biased human\ndecision-making. However, this belief fails to address a critical question: are\nthese AI systems fundamentally competent at the evaluative tasks they are meant\nto perform? This study investigates the question of competence through a\ntwo-part audit of eight major AI platforms. Experiment 1 confirmed complex,\ncontextual racial and gender biases, with some models penalizing candidates\nmerely for the presence of demographic signals. Experiment 2, which evaluated\ncore competence, provided a critical insight: some models that appeared\nunbiased were, in fact, incapable of performing a substantive evaluation,\nrelying instead on superficial keyword matching. This paper introduces the\n\"Illusion of Neutrality\" to describe this phenomenon, where an apparent lack of\nbias is merely a symptom of a model's inability to make meaningful judgments.\nThis study recommends that organizations and regulators adopt a dual-validation\nframework, auditing AI hiring tools for both demographic bias and demonstrable\ncompetence to ensure they are both equitable and effective.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u516b\u5927AI\u5e73\u53f0\u8fdb\u884c\u4e24\u90e8\u5206\u5ba1\u8ba1\uff0c\u53d1\u73b0AI\u7b80\u5386\u7b5b\u9009\u5b58\u5728\u79cd\u65cf\u548c\u6027\u522b\u504f\u89c1\u53ca\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\uff0c\u63d0\u51fa\u201c\u4e2d\u7acb\u5e7b\u89c9\u201d\u73b0\u8c61\u5e76\u5efa\u8bae\u91c7\u7528\u53cc\u91cd\u9a8c\u8bc1\u6846\u67b6\u3002", "motivation": "\u63a2\u7a76\u7528\u4e8e\u7b80\u5386\u7b5b\u9009\u7684\u751f\u6210\u5f0fAI\u7cfb\u7edf\u662f\u5426\u5177\u5907\u6267\u884c\u8bc4\u4f30\u4efb\u52a1\u7684\u80fd\u529b\u3002", "method": "\u5bf9\u516b\u5927AI\u5e73\u53f0\u8fdb\u884c\u4e24\u90e8\u5206\u5ba1\u8ba1\uff0c\u5b9e\u9a8c1\u786e\u8ba4\u79cd\u65cf\u548c\u6027\u522b\u504f\u89c1\uff0c\u5b9e\u9a8c2\u8bc4\u4f30\u6838\u5fc3\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c1\u53d1\u73b0\u590d\u6742\u7684\u3001\u4e0e\u80cc\u666f\u76f8\u5173\u7684\u79cd\u65cf\u548c\u6027\u522b\u504f\u89c1\uff1b\u5b9e\u9a8c2\u53d1\u73b0\u90e8\u5206\u770b\u4f3c\u65e0\u504f\u89c1\u7684\u6a21\u578b\u65e0\u6cd5\u8fdb\u884c\u5b9e\u8d28\u6027\u8bc4\u4f30\uff0c\u4ec5\u4f9d\u8d56\u5173\u952e\u8bcd\u5339\u914d\u3002", "conclusion": "\u63d0\u51fa\u201c\u4e2d\u7acb\u5e7b\u89c9\u201d\u73b0\u8c61\uff0c\u5efa\u8bae\u7ec4\u7ec7\u548c\u76d1\u7ba1\u673a\u6784\u91c7\u7528\u53cc\u91cd\u9a8c\u8bc1\u6846\u67b6\uff0c\u786e\u4fddAI\u62db\u8058\u5de5\u5177\u516c\u5e73\u6709\u6548\u3002"}}
{"id": "2507.11710", "pdf": "https://arxiv.org/pdf/2507.11710", "abs": "https://arxiv.org/abs/2507.11710", "authors": ["Jay Revolinsky", "Harry Shomer", "Jiliang Tang"], "title": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures, preprint", "summary": "Graphs Neural Networks (GNNs) demonstrate high-performance on the link\nprediction (LP) task. However, these models often rely on all dataset samples\nbeing drawn from the same distribution. In addition, graph generative models\n(GGMs) show a pronounced ability to generate novel output graphs. Despite this,\nGGM applications remain largely limited to domain-specific tasks. To bridge\nthis gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)\nstructurally-conditioned graph generation, and (2) adversarial co-training\nbetween an auto-encoder and GNN. As such, FLEX ensures structural-alignment\nbetween sample distributions to enhance link-prediction performance in\nout-of-distribution (OOD) scenarios. Notably, FLEX does not require expert\nknowledge to function in different OOD scenarios. Numerous experiments are\nconducted in synthetic and real-world OOD settings to demonstrate FLEX's\nperformance-enhancing ability, with further analysis for understanding the\neffects of graph data augmentation on link structures. The source code is\navailable here: https://github.com/revolins/FlexOOD.", "AI": {"tldr": "\u63d0\u51faGGM\u6846\u67b6FLEX\uff0c\u7ed3\u5408\u4e24\u79cd\u673a\u5236\u63d0\u5347OOD\u573a\u666f\u4e0b\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u4e13\u5bb6\u77e5\u8bc6\uff0c\u6709\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709GNN\u4f9d\u8d56\u540c\u5206\u5e03\u6837\u672c\uff0cGGM\u5e94\u7528\u5c40\u9650\u4e8e\u7279\u5b9a\u9886\u57df\uff0c\u9700\u586b\u8865\u4e8c\u8005\u5dee\u8ddd\u3002", "method": "\u63d0\u51faFLEX\u6846\u67b6\uff0c\u91c7\u7528\u7ed3\u6784\u6761\u4ef6\u56fe\u751f\u6210\u548c\u81ea\u7f16\u7801\u5668\u4e0eGNN\u7684\u5bf9\u6297\u534f\u540c\u8bad\u7ec3\u4e24\u79cd\u673a\u5236\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684OOD\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u8bc1\u660eFLEX\u63d0\u5347\u6027\u80fd\u7684\u80fd\u529b\uff0c\u5e76\u5206\u6790\u56fe\u6570\u636e\u589e\u5f3a\u5bf9\u94fe\u63a5\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "conclusion": "FLEX\u53ef\u786e\u4fdd\u6837\u672c\u5206\u5e03\u95f4\u7684\u7ed3\u6784\u5bf9\u9f50\uff0c\u63d0\u5347OOD\u573a\u666f\u4e0b\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u4e13\u5bb6\u77e5\u8bc6\u3002"}}
{"id": "2507.12257", "pdf": "https://arxiv.org/pdf/2507.12257", "abs": "https://arxiv.org/abs/2507.12257", "authors": ["Matteo Tusoni", "Giuseppe Masi", "Andrea Coletta", "Aldo Glielmo", "Viviana Arrigoni", "Novella Bartolini"], "title": "Robust Causal Discovery in Real-World Time Series with Power-Laws", "categories": ["cs.LG", "physics.data-an", "stat.ML", "stat.OT"], "comment": null, "summary": "Exploring causal relationships in stochastic time series is a challenging yet\ncrucial task with a vast range of applications, including finance, economics,\nneuroscience, and climate science. Many algorithms for Causal Discovery (CD)\nhave been proposed, but they often exhibit a high sensitivity to noise,\nresulting in misleading causal inferences when applied to real data. In this\npaper, we observe that the frequency spectra of typical real-world time series\nfollow a power-law distribution, notably due to an inherent self-organizing\nbehavior. Leveraging this insight, we build a robust CD method based on the\nextraction of power -law spectral features that amplify genuine causal signals.\nOur method consistently outperforms state-of-the-art alternatives on both\nsynthetic benchmarks and real-world datasets with known causal structures,\ndemonstrating its robustness and practical relevance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u63d0\u53d6\u5e42\u5f8b\u8c31\u7279\u5f81\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\uff0c\u5728\u5408\u6210\u57fa\u51c6\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u5bf9\u566a\u58f0\u654f\u611f\uff0c\u5e94\u7528\u4e8e\u771f\u5b9e\u6570\u636e\u65f6\u4f1a\u5bfc\u81f4\u56e0\u679c\u63a8\u65ad\u51fa\u9519\u3002", "method": "\u5229\u7528\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u9891\u8c31\u670d\u4ece\u5e42\u5f8b\u5206\u5e03\u7684\u7279\u70b9\uff0c\u6784\u5efa\u57fa\u4e8e\u63d0\u53d6\u5e42\u5f8b\u8c31\u7279\u5f81\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u57fa\u51c6\u548c\u6709\u5df2\u77e5\u56e0\u679c\u7ed3\u6784\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.12028", "pdf": "https://arxiv.org/pdf/2507.12028", "abs": "https://arxiv.org/abs/2507.12028", "authors": ["Soheil Mahdizadeh", "Elyas Oustad", "Mohsen Ansari"], "title": "MOFCO: Mobility- and Migration-Aware Task Offloading in Three-Layer Fog Computing Environments", "categories": ["cs.AR", "cs.DC", "cs.NI"], "comment": null, "summary": "Task offloading in three-layer fog computing environments presents a critical\nchallenge due to user equipment (UE) mobility, which frequently triggers costly\nservice migrations and degrades overall system performance. This paper\naddresses this problem by proposing MOFCO, a novel Mobility- and\nMigration-aware Task Offloading algorithm for Fog Computing environments. The\nproposed method formulates task offloading and resource allocation as a\nMixed-Integer Nonlinear Programming (MINLP) problem and employs a\nheuristic-aided evolutionary game theory approach to solve it efficiently. To\nevaluate MOFCO, we simulate mobile users using SUMO, providing realistic\nmobility patterns. Experimental results show that MOFCO reduces system cost,\ndefined as a combination of latency and energy consumption, by an average of\n19% and up to 43% in certain scenarios compared to state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMOFCO\u7b97\u6cd5\u89e3\u51b3\u4e09\u5c42\u96fe\u8ba1\u7b97\u73af\u5883\u4e2d\u56e0\u7528\u6237\u8bbe\u5907\u79fb\u52a8\u6027\u5bfc\u81f4\u7684\u4efb\u52a1\u5378\u8f7d\u96be\u9898\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u7b97\u6cd5\u53ef\u964d\u4f4e\u7cfb\u7edf\u6210\u672c\u3002", "motivation": "\u4e09\u5c42\u96fe\u8ba1\u7b97\u73af\u5883\u4e2d\u7528\u6237\u8bbe\u5907\u79fb\u52a8\u6027\u5e38\u5f15\u53d1\u670d\u52a1\u8fc1\u79fb\u6210\u672c\u9ad8\u3001\u7cfb\u7edf\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u4efb\u52a1\u5378\u8f7d\u96be\u9898\u3002", "method": "\u5c06\u4efb\u52a1\u5378\u8f7d\u548c\u8d44\u6e90\u5206\u914d\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\uff0c\u91c7\u7528\u542f\u53d1\u5f0f\u8f85\u52a9\u8fdb\u5316\u535a\u5f08\u8bba\u65b9\u6cd5\u6c42\u89e3\uff1b\u7528SUMO\u6a21\u62df\u79fb\u52a8\u7528\u6237\u4ee5\u63d0\u4f9b\u771f\u5b9e\u79fb\u52a8\u6a21\u5f0f\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cMOFCO\u7b97\u6cd5\u5e73\u5747\u964d\u4f4e\u7cfb\u7edf\u6210\u672c\uff08\u5ef6\u8fdf\u548c\u80fd\u8017\u7ec4\u5408\uff0919%\uff0c\u7279\u5b9a\u573a\u666f\u4e0b\u6700\u9ad8\u964d\u4f4e43%\u3002", "conclusion": "MOFCO\u7b97\u6cd5\u80fd\u6709\u6548\u964d\u4f4e\u7cfb\u7edf\u6210\u672c\uff0c\u5728\u96fe\u8ba1\u7b97\u4efb\u52a1\u5378\u8f7d\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.11549", "pdf": "https://arxiv.org/pdf/2507.11549", "abs": "https://arxiv.org/abs/2507.11549", "authors": ["Wendong Mao", "Mingfan Zhao", "Jianfeng Guan", "Qiwei Dong", "Zhongfeng Wang"], "title": "An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deformable Attention Transformers (DAT) have shown remarkable performance in\ncomputer vision tasks by adaptively focusing on informative image regions.\nHowever, their data-dependent sampling mechanism introduces irregular memory\naccess patterns, posing significant challenges for efficient hardware\ndeployment. Existing acceleration methods either incur high hardware overhead\nor compromise model accuracy. To address these issues, this paper proposes a\nhardware-friendly optimization framework for DAT. First, a neural architecture\nsearch (NAS)-based method with a new slicing strategy is proposed to\nautomatically divide the input feature into uniform patches during the\ninference process, avoiding memory conflicts without modifying model\narchitecture. The method explores the optimal slice configuration by jointly\noptimizing hardware cost and inference accuracy. Secondly, an FPGA-based\nverification system is designed to test the performance of this framework on\nedge-side hardware. Algorithm experiments on the ImageNet-1K dataset\ndemonstrate that our hardware-friendly framework can maintain have only 0.2%\naccuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA\nshow the proposed method reduces DRAM access times to 18% compared with\nexisting DAT acceleration methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u786c\u4ef6\u53cb\u597d\u7684DAT\u4f18\u5316\u6846\u67b6\uff0c\u53ef\u964d\u4f4eDRAM\u8bbf\u95ee\u6b21\u6570\u4e14\u7cbe\u5ea6\u635f\u5931\u5c0f\u3002", "motivation": "DAT\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u7ed9\u786c\u4ef6\u90e8\u7f72\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u52a0\u901f\u65b9\u6cd5\u6709\u9ad8\u786c\u4ef6\u5f00\u9500\u6216\u7cbe\u5ea6\u635f\u5931\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eNAS\u7684\u65b9\u6cd5\u548c\u65b0\u5207\u7247\u7b56\u7565\uff0c\u81ea\u52a8\u5212\u5206\u8f93\u5165\u7279\u5f81\uff0c\u8054\u5408\u4f18\u5316\u786c\u4ef6\u6210\u672c\u548c\u63a8\u7406\u7cbe\u5ea6\uff1b\u8bbe\u8ba1FPGA\u9a8c\u8bc1\u7cfb\u7edf\u3002", "result": "\u7b97\u6cd5\u5b9e\u9a8c\u663e\u793a\u6846\u67b6\u4e0e\u57fa\u7ebfDAT\u76f8\u6bd4\u7cbe\u5ea6\u4ec5\u4e0b\u964d0.2%\uff1b\u786c\u4ef6\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u8f83\u73b0\u6709DAT\u52a0\u901f\u65b9\u6cd5\u5c06DRAM\u8bbf\u95ee\u6b21\u6570\u964d\u81f318%\u3002", "conclusion": "\u63d0\u51fa\u7684\u786c\u4ef6\u53cb\u597d\u4f18\u5316\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3DAT\u786c\u4ef6\u90e8\u7f72\u95ee\u9898\uff0c\u517c\u987e\u7cbe\u5ea6\u548c\u786c\u4ef6\u6548\u7387\u3002"}}
{"id": "2507.11729", "pdf": "https://arxiv.org/pdf/2507.11729", "abs": "https://arxiv.org/abs/2507.11729", "authors": ["Amirhossein Ahmadi", "Hamidreza Zareipour", "Henry Leung"], "title": "Globalization for Scalable Short-term Load Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "63 pages with 22 figures", "summary": "Forecasting load in power transmission networks is essential across various\nhierarchical levels, from the system level down to individual points of\ndelivery (PoD). While intuitive and locally accurate, traditional local\nforecasting models (LFMs) face significant limitations, particularly in\nhandling generalizability, overfitting, data drift, and the cold start problem.\nThese methods also struggle with scalability, becoming computationally\nexpensive and less efficient as the network's size and data volume grow. In\ncontrast, global forecasting models (GFMs) offer a new approach to enhance\nprediction generalizability, scalability, accuracy, and robustness through\nglobalization and cross-learning. This paper investigates global load\nforecasting in the presence of data drifts, highlighting the impact of\ndifferent modeling techniques and data heterogeneity. We explore\nfeature-transforming and target-transforming models, demonstrating how\nglobalization, data heterogeneity, and data drift affect each differently. In\naddition, we examine the role of globalization in peak load forecasting and its\npotential for hierarchical forecasting. To address data heterogeneity and the\nbalance between globality and locality, we propose separate time series\nclustering (TSC) methods, introducing model-based TSC for feature-transforming\nmodels and new weighted instance-based TSC for target-transforming models.\nThrough extensive experiments on a real-world dataset of Alberta's electricity\nload, we demonstrate that global target-transforming models consistently\noutperform their local counterparts, especially when enriched with global\nfeatures and clustering techniques. In contrast, global feature-transforming\nmodels face challenges in balancing local and global dynamics, often requiring\nTSC to manage data heterogeneity effectively.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5b58\u5728\u6570\u636e\u6f02\u79fb\u65f6\u7684\u5168\u5c40\u8d1f\u8377\u9884\u6d4b\uff0c\u5bf9\u6bd4\u7279\u5f81\u8f6c\u6362\u548c\u76ee\u6807\u8f6c\u6362\u6a21\u578b\uff0c\u63d0\u51fa\u4e0d\u540c\u805a\u7c7b\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5168\u5c40\u76ee\u6807\u8f6c\u6362\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u4f20\u7edf\u5c40\u90e8\u8d1f\u8377\u9884\u6d4b\u6a21\u578b\u5728\u6cdb\u5316\u6027\u3001\u8fc7\u62df\u5408\u3001\u6570\u636e\u6f02\u79fb\u3001\u51b7\u542f\u52a8\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u800c\u5168\u5c40\u9884\u6d4b\u6a21\u578b\u53ef\u6539\u5584\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63a2\u7d22\u7279\u5f81\u8f6c\u6362\u548c\u76ee\u6807\u8f6c\u6362\u6a21\u578b\uff0c\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u805a\u7c7b\u7528\u4e8e\u7279\u5f81\u8f6c\u6362\u6a21\u578b\uff0c\u65b0\u7684\u52a0\u6743\u57fa\u4e8e\u5b9e\u4f8b\u7684\u65f6\u95f4\u5e8f\u5217\u805a\u7c7b\u7528\u4e8e\u76ee\u6807\u8f6c\u6362\u6a21\u578b\u3002", "result": "\u5728\u963f\u5c14\u4f2f\u5854\u7701\u7535\u529b\u8d1f\u8377\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5168\u5c40\u76ee\u6807\u8f6c\u6362\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5c40\u90e8\u6a21\u578b\uff0c\u5168\u5c40\u7279\u5f81\u8f6c\u6362\u6a21\u578b\u5e73\u8861\u5c40\u90e8\u548c\u5168\u5c40\u52a8\u6001\u6709\u6311\u6218\u3002", "conclusion": "\u5168\u5c40\u76ee\u6807\u8f6c\u6362\u6a21\u578b\u7ed3\u5408\u5168\u5c40\u7279\u5f81\u548c\u805a\u7c7b\u6280\u672f\u5728\u8d1f\u8377\u9884\u6d4b\u4e2d\u8868\u73b0\u66f4\u4f73\uff0c\u5168\u5c40\u7279\u5f81\u8f6c\u6362\u6a21\u578b\u9700\u6709\u6548\u7ba1\u7406\u6570\u636e\u5f02\u8d28\u6027\u3002"}}
{"id": "2507.12262", "pdf": "https://arxiv.org/pdf/2507.12262", "abs": "https://arxiv.org/abs/2507.12262", "authors": ["Zachary James", "Joseph Guinness"], "title": "A Framework for Nonstationary Gaussian Processes with Neural Network Parameters", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "Gaussian processes have become a popular tool for nonparametric regression\nbecause of their flexibility and uncertainty quantification. However, they\noften use stationary kernels, which limit the expressiveness of the model and\nmay be unsuitable for many datasets. We propose a framework that uses\nnonstationary kernels whose parameters vary across the feature space, modeling\nthese parameters as the output of a neural network that takes the features as\ninput. The neural network and Gaussian process are trained jointly using the\nchain rule to calculate derivatives. Our method clearly describes the behavior\nof the nonstationary parameters and is compatible with approximation methods\nfor scaling to large datasets. It is flexible and easily adapts to different\nnonstationary kernels without needing to redesign the optimization procedure.\nOur methods are implemented with the GPyTorch library and can be readily\nmodified. We test a nonstationary variance and noise variant of our method on\nseveral machine learning datasets and find that it achieves better accuracy and\nlog-score than both a stationary model and a hierarchical model approximated\nwith variational inference. Similar results are observed for a model with only\nnonstationary variance. We also demonstrate our approach's ability to recover\nthe nonstationary parameters of a spatial dataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u975e\u5e73\u7a33\u6838\u53c2\u6570\u7684\u9ad8\u65af\u8fc7\u7a0b\u6846\u67b6\uff0c\u8054\u5408\u8bad\u7ec3\u7f51\u7edc\u4e0e\u9ad8\u65af\u8fc7\u7a0b\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5e73\u7a33\u6a21\u578b\u7b49\u3002", "motivation": "\u4f20\u7edf\u9ad8\u65af\u8fc7\u7a0b\u5e38\u7528\u5e73\u7a33\u6838\uff0c\u9650\u5236\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u4e0d\u9002\u7528\u4e8e\u5f88\u591a\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u975e\u5e73\u7a33\u6838\u7684\u6846\u67b6\uff0c\u5c06\u6838\u53c2\u6570\u5efa\u6a21\u4e3a\u4ee5\u7279\u5f81\u4e3a\u8f93\u5165\u7684\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\uff0c\u7528\u94fe\u5f0f\u6cd5\u5219\u8054\u5408\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u548c\u9ad8\u65af\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u673a\u5668\u5b66\u4e60\u6570\u636e\u96c6\u4e0a\uff0c\u975e\u5e73\u7a33\u65b9\u5dee\u548c\u566a\u58f0\u53d8\u4f53\u65b9\u6cd5\u7cbe\u5ea6\u548c\u5bf9\u6570\u5f97\u5206\u4f18\u4e8e\u5e73\u7a33\u6a21\u578b\u548c\u5206\u5c42\u6a21\u578b\uff1b\u4ec5\u975e\u5e73\u7a33\u65b9\u5dee\u6a21\u578b\u4e5f\u6709\u7c7b\u4f3c\u7ed3\u679c\uff1b\u80fd\u6062\u590d\u7a7a\u95f4\u6570\u636e\u96c6\u7684\u975e\u5e73\u7a33\u53c2\u6570\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7075\u6d3b\uff0c\u6613\u9002\u914d\u4e0d\u540c\u975e\u5e73\u7a33\u6838\uff0c\u65e0\u9700\u91cd\u65b0\u8bbe\u8ba1\u4f18\u5316\u8fc7\u7a0b\uff0c\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.12445", "pdf": "https://arxiv.org/pdf/2507.12445", "abs": "https://arxiv.org/abs/2507.12445", "authors": ["Soheil Mahdizadeh", "Amir Mahdi Rasouli", "Mohammad Pourashory", "Sadra Galavani", "Mohsen Ansari"], "title": "CRAFT: Latency and Cost-Aware Genetic-Based Framework for Node Placement in Edge-Fog Environments", "categories": ["cs.NI", "cs.AR", "cs.DC"], "comment": null, "summary": "Reducing latency in the Internet of Things (IoT) is a critical concern. While\ncloud computing facilitates communication, it falls short of meeting real-time\nrequirements reliably. Edge and fog computing have emerged as viable solutions\nby positioning computing nodes closer to end users, offering lower latency and\nincreased processing power. An edge-fog framework comprises various components,\nincluding edge and fog nodes, whose strategic placement is crucial as it\ndirectly impacts latency and system cost. This paper presents an effective and\ntunable node placement strategy based on a genetic algorithm to address the\noptimization problem of deploying edge and fog nodes. The main objective is to\nminimize latency and cost through optimal node placement. Simulation results\ndemonstrate that the proposed framework achieves up to 2.77% latency and 31.15%\ncost reduction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u8fb9\u7f18 - \u96fe\u8282\u70b9\u653e\u7f6e\u7b56\u7565\uff0c\u53ef\u51cf\u5c11\u7269\u8054\u7f51\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u6a21\u62df\u663e\u793a\u6709\u663e\u8457\u6548\u679c\u3002", "motivation": "\u4e91\u8ba1\u7b97\u96be\u4ee5\u53ef\u9760\u6ee1\u8db3\u7269\u8054\u7f51\u5b9e\u65f6\u9700\u6c42\uff0c\u8fb9\u7f18\u548c\u96fe\u8ba1\u7b97\u53ef\u964d\u4f4e\u5ef6\u8fdf\uff0c\u4f46\u8282\u70b9\u653e\u7f6e\u5f71\u54cd\u5ef6\u8fdf\u548c\u6210\u672c\uff0c\u9700\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u6709\u6548\u4e14\u53ef\u8c03\u8282\u7684\u8282\u70b9\u653e\u7f6e\u7b56\u7565\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u6846\u67b6\u53ef\u51cf\u5c11 2.77% \u7684\u5ef6\u8fdf\u548c 31.15% \u7684\u6210\u672c\u3002", "conclusion": "\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u8282\u70b9\u653e\u7f6e\u7b56\u7565\u80fd\u6709\u6548\u4f18\u5316\u8fb9\u7f18\u548c\u96fe\u8282\u70b9\u90e8\u7f72\uff0c\u964d\u4f4e\u5ef6\u8fdf\u548c\u6210\u672c\u3002"}}
{"id": "2507.11550", "pdf": "https://arxiv.org/pdf/2507.11550", "abs": "https://arxiv.org/abs/2507.11550", "authors": ["Hyeonseok Jin", "Geonmin Kim", "Kyungbaek Kim"], "title": "Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction", "categories": ["cs.CV", "cs.AI"], "comment": "7 pages", "summary": "Spatio-temporal traffic prediction plays a key role in intelligent\ntransportation systems by enabling accurate prediction in complex urban areas.\nAlthough not only accuracy but also efficiency for scalability is important,\nsome previous methods struggle to capture heterogeneity such as varying traffic\npatterns across regions and time periods. Moreover, Graph Neural Networks\n(GNNs), which are the mainstream of traffic prediction, not only require\npredefined adjacency matrix, but also limit scalability to large-scale data\ncontaining many nodes due to their inherent complexity. To overcome these\nlimitations, we propose Deformable Dynamic Convolution Network (DDCN) for\naccurate yet efficient traffic prediction. Traditional Convolutional Neural\nNetworks (CNNs) are limited in modeling non-Euclidean spatial structures and\nspatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically\napplying deformable filters based on offset. Specifically, DDCN decomposes\ntransformer-style CNN to encoder-decoder structure, and applies proposed\napproaches to the spatial and spatio-temporal attention blocks of the encoder\nto emphasize important features. The decoder, composed of feed-forward module,\ncomplements the output of the encoder. This novel structure make DDCN can\nperform accurate yet efficient traffic prediction. In comprehensive experiments\non four real-world datasets, DDCN achieves competitive performance, emphasizing\nthe potential and effectiveness of CNN-based approaches for spatio-temporal\ntraffic prediction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53ef\u53d8\u5f62\u52a8\u6001\u5377\u79ef\u7f51\u7edc\uff08DDCN\uff09\u7528\u4e8e\u65f6\u7a7a\u4ea4\u901a\u9884\u6d4b\uff0c\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u51f8\u663e\u57fa\u4e8eCNN\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u4ea4\u901a\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5f02\u8d28\u6027\uff0c\u56fe\u795e\u7ecf\u7f51\u7edc\u9700\u9884\u5b9a\u4e49\u90bb\u63a5\u77e9\u9635\u4e14\u6269\u5c55\u6027\u53d7\u9650\uff0c\u4f20\u7edfCNN\u5728\u5efa\u6a21\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u7ed3\u6784\u548c\u65f6\u7a7a\u5f02\u8d28\u6027\u4e0a\u6709\u9650\u3002", "method": "\u63d0\u51faDDCN\uff0c\u5c06Transformer\u98ce\u683c\u7684CNN\u5206\u89e3\u4e3a\u7f16\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u5728\u7f16\u7801\u5668\u7684\u7a7a\u95f4\u548c\u65f6\u7a7a\u6ce8\u610f\u529b\u5757\u5e94\u7528\u76f8\u5173\u65b9\u6cd5\u5f3a\u8c03\u91cd\u8981\u7279\u5f81\uff0c\u89e3\u7801\u5668\u7531\u524d\u9988\u6a21\u5757\u7ec4\u6210\u8865\u5145\u7f16\u7801\u5668\u8f93\u51fa\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cDDCN\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "DDCN\u80fd\u5b9e\u73b0\u51c6\u786e\u4e14\u9ad8\u6548\u7684\u4ea4\u901a\u9884\u6d4b\uff0c\u57fa\u4e8eCNN\u7684\u65b9\u6cd5\u5728\u65f6\u7a7a\u4ea4\u901a\u9884\u6d4b\u4e2d\u6709\u6f5c\u529b\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.11551", "pdf": "https://arxiv.org/pdf/2507.11551", "abs": "https://arxiv.org/abs/2507.11551", "authors": ["Ekaterina Stansfield", "Jennifer A. Mitterer", "Abdulrahman Altahhan"], "title": "Landmark Detection for Medical Images using a General-purpose Segmentation Model", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "13 pages, 8 figures, 2 tables. Submitted to ICONIP 2025", "summary": "Radiographic images are a cornerstone of medical diagnostics in orthopaedics,\nwith anatomical landmark detection serving as a crucial intermediate step for\ninformation extraction. General-purpose foundational segmentation models, such\nas SAM (Segment Anything Model), do not support landmark segmentation out of\nthe box and require prompts to function. However, in medical imaging, the\nprompts for landmarks are highly specific. Since SAM has not been trained to\nrecognize such landmarks, it cannot generate accurate landmark segmentations\nfor diagnostic purposes. Even MedSAM, a medically adapted variant of SAM, has\nbeen trained to identify larger anatomical structures, such as organs and their\nparts, and lacks the fine-grained precision required for orthopaedic pelvic\nlandmarks. To address this limitation, we propose leveraging another\ngeneral-purpose, non-foundational model: YOLO. YOLO excels in object detection\nand can provide bounding boxes that serve as input prompts for SAM. While YOLO\nis efficient at detection, it is significantly outperformed by SAM in\nsegmenting complex structures. In combination, these two models form a reliable\npipeline capable of segmenting not only a small pilot set of eight anatomical\nlandmarks but also an expanded set of 72 landmarks and 16 regions with complex\noutlines, such as the femoral cortical bone and the pelvic inlet. By using\nYOLO-generated bounding boxes to guide SAM, we trained the hybrid model to\naccurately segment orthopaedic pelvic radiographs. Our results show that the\nproposed combination of YOLO and SAM yields excellent performance in detecting\nanatomical landmarks and intricate outlines in orthopaedic pelvic radiographs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408YOLO\u548cSAM\u6a21\u578b\u5bf9\u9aa8\u79d1\u9aa8\u76c6X\u5149\u7247\u8fdb\u884c\u89e3\u5256\u6807\u5fd7\u5206\u5272\uff0c\u53d6\u5f97\u4e86\u826f\u597d\u6548\u679c\u3002", "motivation": "\u901a\u7528\u5206\u5272\u6a21\u578bSAM\u548c\u533b\u5b66\u9002\u914d\u7248\u672cMedSAM\u65e0\u6cd5\u51c6\u786e\u8fdb\u884c\u9aa8\u79d1\u9aa8\u76c6\u6807\u5fd7\u5206\u5272\uff0c\u9700\u8981\u66f4\u5408\u9002\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528YOLO\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b\u63d0\u4f9b\u8fb9\u754c\u6846\u4f5c\u4e3aSAM\u7684\u8f93\u5165\u63d0\u793a\uff0c\u7ec4\u5408\u4e24\u4e2a\u6a21\u578b\u5f62\u6210\u53ef\u9760\u7684\u5206\u5272\u7ba1\u9053\u3002", "result": "\u7ec4\u5408\u6a21\u578b\u80fd\u5206\u52728\u4e2a\u89e3\u5256\u6807\u5fd7\u7684\u5c0f\u8bd5\u70b9\u96c6\u300172\u4e2a\u6807\u5fd7\u548c16\u4e2a\u590d\u6742\u8f6e\u5ed3\u533a\u57df\uff0c\u68c0\u6d4b\u89e3\u5256\u6807\u5fd7\u548c\u590d\u6742\u8f6e\u5ed3\u6548\u679c\u826f\u597d\u3002", "conclusion": "YOLO\u548cSAM\u7684\u7ec4\u5408\u5728\u9aa8\u79d1\u9aa8\u76c6X\u5149\u7247\u7684\u89e3\u5256\u6807\u5fd7\u548c\u590d\u6742\u8f6e\u5ed3\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.12399", "pdf": "https://arxiv.org/pdf/2507.12399", "abs": "https://arxiv.org/abs/2507.12399", "authors": ["Florian E. Dorner", "Yatong Chen", "Andr\u00e9 F. Cruz", "Fanny Yang"], "title": "ROC-n-reroll: How verifier imperfection affects test-time scaling", "categories": ["cs.LG", "stat.ML"], "comment": "35 pages, 9 Figures", "summary": "Test-time scaling aims to improve language model performance by leveraging\nadditional compute during inference. While many works have empirically studied\ntechniques like Best-of-N (BoN) and rejection sampling that make use of a\nverifier to enable test-time scaling, there is little theoretical understanding\nof how verifier imperfection affects performance. In this work, we address this\ngap. Specifically, we prove how instance-level accuracy of these methods is\nprecisely characterized by the geometry of the verifier's ROC curve.\nInterestingly, while scaling is determined by the local geometry of the ROC\ncurve for rejection sampling, it depends on global properties of the ROC curve\nfor BoN. As a consequence when the ROC curve is unknown, it is impossible to\nextrapolate the performance of rejection sampling based on the low-compute\nregime. Furthermore, while rejection sampling outperforms BoN for fixed\ncompute, in the infinite-compute limit both methods converge to the same level\nof accuracy, determined by the slope of the ROC curve near the origin. Our\ntheoretical results are confirmed by experiments on GSM8K using different\nversions of Llama and Qwen to generate and verify solutions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u9a8c\u8bc1\u5668\u4e0d\u5b8c\u7f8e\u6027\u5bf9\u6d4b\u8bd5\u65f6\u7f29\u653e\u6280\u672f\u5f71\u54cd\uff0c\u7ed9\u51fa\u76f8\u5173\u7406\u8bba\u5206\u6790\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u7f3a\u4e4f\u5bf9\u9a8c\u8bc1\u5668\u4e0d\u5b8c\u7f8e\u6027\u5982\u4f55\u5f71\u54cd\u8bed\u8a00\u6a21\u578b\u6d4b\u8bd5\u65f6\u7f29\u653e\u6027\u80fd\u7684\u7406\u8bba\u7406\u89e3\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bc1\u660e\u5b9e\u4f8b\u7ea7\u51c6\u786e\u7387\u4e0e\u9a8c\u8bc1\u5668ROC\u66f2\u7ebf\u51e0\u4f55\u5f62\u72b6\u7684\u5173\u7cfb\uff0c\u5206\u6790ROC\u66f2\u7ebf\u5c40\u90e8\u548c\u5168\u5c40\u7279\u6027\u5bf9\u4e0d\u540c\u65b9\u6cd5\u7684\u5f71\u54cd\u3002", "result": "\u62d2\u7edd\u91c7\u6837\u7684\u7f29\u653e\u53d6\u51b3\u4e8eROC\u66f2\u7ebf\u5c40\u90e8\u51e0\u4f55\u5f62\u72b6\uff0cBoN\u53d6\u51b3\u4e8e\u5168\u5c40\u7279\u6027\uff1b\u4f4e\u8ba1\u7b97\u91cf\u4e0b\u65e0\u6cd5\u5916\u63a8\u62d2\u7edd\u91c7\u6837\u6027\u80fd\uff1b\u56fa\u5b9a\u8ba1\u7b97\u91cf\u65f6\u62d2\u7edd\u91c7\u6837\u4f18\u4e8eBoN\uff0c\u65e0\u9650\u8ba1\u7b97\u91cf\u65f6\u4e8c\u8005\u51c6\u786e\u7387\u6536\u655b\u3002", "conclusion": "\u7406\u8bba\u7ed3\u679c\u5728GSM8K\u6570\u636e\u96c6\u4e0a\u901a\u8fc7\u4e0d\u540c\u6a21\u578b\u7684\u5b9e\u9a8c\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2507.11554", "pdf": "https://arxiv.org/pdf/2507.11554", "abs": "https://arxiv.org/abs/2507.11554", "authors": ["Zejian Li", "Yize Li", "Chenye Meng", "Zhongni Liu", "Yang Ling", "Shengyuan Zhang", "Guang Yang", "Changyuan Yang", "Zhiyuan Yang", "Lingyun Sun"], "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in diffusion models (DMs) have been propelled by\nalignment methods that post-train models to better conform to human\npreferences. However, these approaches typically require computation-intensive\ntraining of a base model and a reward model, which not only incurs substantial\ncomputational overhead but may also compromise model accuracy and training\nefficiency. To address these limitations, we propose Inversion-DPO, a novel\nalignment framework that circumvents reward modeling by reformulating Direct\nPreference Optimization (DPO) with DDIM inversion for DMs. Our method conducts\nintractable posterior sampling in Diffusion-DPO with the deterministic\ninversion from winning and losing samples to noise and thus derive a new\npost-training paradigm. This paradigm eliminates the need for auxiliary reward\nmodels or inaccurate appromixation, significantly enhancing both precision and\nefficiency of training. We apply Inversion-DPO to a basic task of text-to-image\ngeneration and a challenging task of compositional image generation. Extensive\nexperiments show substantial performance improvements achieved by Inversion-DPO\ncompared to existing post-training methods and highlight the ability of the\ntrained generative models to generate high-fidelity compositionally coherent\nimages. For the post-training of compostitional image geneation, we curate a\npaired dataset consisting of 11,140 images with complex structural annotations\nand comprehensive scores, designed to enhance the compositional capabilities of\ngenerative models. Inversion-DPO explores a new avenue for efficient,\nhigh-precision alignment in diffusion models, advancing their applicability to\ncomplex realistic generation tasks. Our code is available at\nhttps://github.com/MIGHTYEZ/Inversion-DPO", "AI": {"tldr": "\u63d0\u51faInversion - DPO\u6846\u67b6\u89e3\u51b3\u6269\u6563\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\u7b49\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u63d0\u5347\uff0c\u63a8\u8fdb\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u9700\u8ba1\u7b97\u5bc6\u96c6\u8bad\u7ec3\uff0c\u6709\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u5f71\u54cd\u51c6\u786e\u6027\u548c\u6548\u7387\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faInversion - DPO\u6846\u67b6\uff0c\u901a\u8fc7DDIM\u53cd\u6f14\u91cd\u65b0\u8868\u8ff0DPO\uff0c\u5728Diffusion - DPO\u4e2d\u8fdb\u884c\u540e\u9a8c\u91c7\u6837\u5f97\u5230\u65b0\u7684\u540e\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "\u5e94\u7528\u4e8e\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u548c\u7ec4\u5408\u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u80fd\u751f\u6210\u9ad8\u4fdd\u771f\u3001\u7ec4\u5408\u8fde\u8d2f\u56fe\u50cf\u3002", "conclusion": "Inversion - DPO\u4e3a\u6269\u6563\u6a21\u578b\u9ad8\u6548\u9ad8\u7cbe\u5ea6\u5bf9\u9f50\u63a2\u7d22\u65b0\u9014\u5f84\uff0c\u63a8\u8fdb\u5176\u5728\u590d\u6742\u73b0\u5b9e\u751f\u6210\u4efb\u52a1\u7684\u5e94\u7528\u3002"}}
{"id": "2507.11757", "pdf": "https://arxiv.org/pdf/2507.11757", "abs": "https://arxiv.org/abs/2507.11757", "authors": ["Yuehua Song", "Yong Gao"], "title": "A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Accurately predicting drug-target interactions (DTIs) is pivotal for\nadvancing drug discovery and target validation techniques. While machine\nlearning approaches including those that are based on Graph Neural Networks\n(GNN) have achieved notable success in DTI prediction, many of them have\ndifficulties in effectively integrating the diverse features of drugs, targets\nand their interactions. To address this limitation, we introduce a novel\nframework to take advantage of the power of both transductive learning and\ninductive learning so that features at molecular level and drug-target\ninteraction network level can be exploited. Within this framework is a\nGNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and\ntarget molecular structures as meta-nodes in a drug-target interaction graph,\nenabling a detailed exploration of their intricate relationships. To evaluate\nthe proposed model, we have compiled a special benchmark comprising drug\nSMILES, protein sequences, and their interaction data, which is interesting in\nits own right. Our experimental results demonstrate that the GiG model\nsignificantly outperforms existing approaches across all evaluation metrics,\nhighlighting the benefits of integrating different learning paradigms and\ninteraction data.", "AI": {"tldr": "\u63d0\u51faGraph - in - Graph (GiG)\u6a21\u578b\u9884\u6d4b\u836f\u7269 - \u9776\u70b9\u76f8\u4e92\u4f5c\u7528\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6709\u6548\u6574\u5408\u836f\u7269\u3001\u9776\u70b9\u53ca\u5176\u76f8\u4e92\u4f5c\u7528\u7684\u591a\u6837\u7279\u5f81\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u6539\u8fdb\u836f\u7269 - \u9776\u70b9\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u3002", "method": "\u5f15\u5165\u7ed3\u5408\u76f4\u63a8\u5f0f\u5b66\u4e60\u548c\u5f52\u7eb3\u5f0f\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8eGNN\u7684Graph - in - Graph (GiG)\u6a21\u578b\uff0c\u5c06\u836f\u7269\u548c\u9776\u70b9\u5206\u5b50\u7ed3\u6784\u56fe\u8868\u793a\u4e3a\u836f\u7269 - \u9776\u70b9\u76f8\u4e92\u4f5c\u7528\u56fe\u4e2d\u7684\u5143\u8282\u70b9\uff0c\u5e76\u6784\u5efa\u7279\u6b8a\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "GiG\u6a21\u578b\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6574\u5408\u4e0d\u540c\u5b66\u4e60\u8303\u5f0f\u548c\u76f8\u4e92\u4f5c\u7528\u6570\u636e\u6709\u5229\u4e8e\u836f\u7269 - \u9776\u70b9\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u3002"}}
{"id": "2507.11557", "pdf": "https://arxiv.org/pdf/2507.11557", "abs": "https://arxiv.org/abs/2507.11557", "authors": ["Jiaxu Zheng", "Meiman He", "Xuhui Tang", "Xiong Wang", "Tuoyu Cao", "Tianyi Zeng", "Lichi Zhang", "Chenyu You"], "title": "3D Wavelet Latent Diffusion Model for Whole-Body MR-to-CT Modality Translation", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Magnetic Resonance (MR) imaging plays an essential role in contemporary\nclinical diagnostics. It is increasingly integrated into advanced therapeutic\nworkflows, such as hybrid Positron Emission Tomography/Magnetic Resonance\n(PET/MR) imaging and MR-only radiation therapy. These integrated approaches are\ncritically dependent on accurate estimation of radiation attenuation, which is\ntypically facilitated by synthesizing Computed Tomography (CT) images from MR\nscans to generate attenuation maps. However, existing MR-to-CT synthesis\nmethods for whole-body imaging often suffer from poor spatial alignment between\nthe generated CT and input MR images, and insufficient image quality for\nreliable use in downstream clinical tasks. In this paper, we present a novel 3D\nWavelet Latent Diffusion Model (3D-WLDM) that addresses these limitations by\nperforming modality translation in a learned latent space. By incorporating a\nWavelet Residual Module into the encoder-decoder architecture, we enhance the\ncapture and reconstruction of fine-scale features across image and latent\nspaces. To preserve anatomical integrity during the diffusion process, we\ndisentangle structural and modality-specific characteristics and anchor the\nstructural component to prevent warping. We also introduce a Dual Skip\nConnection Attention mechanism within the diffusion model, enabling the\ngeneration of high-resolution CT images with improved representation of bony\nstructures and soft-tissue contrast.", "AI": {"tldr": "\u63d0\u51fa3D Wavelet Latent Diffusion Model\u89e3\u51b3\u73b0\u6709MR\u5230CT\u5408\u6210\u65b9\u6cd5\u7684\u4e0d\u8db3", "motivation": "\u73b0\u6709MR\u5230CT\u5408\u6210\u65b9\u6cd5\u5728\u5168\u8eab\u6210\u50cf\u4e2d\u5b58\u5728\u751f\u6210CT\u4e0e\u8f93\u5165MR\u56fe\u50cf\u7a7a\u95f4\u5bf9\u9f50\u5dee\u3001\u56fe\u50cf\u8d28\u91cf\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e0b\u6e38\u4e34\u5e8a\u4efb\u52a1", "method": "\u63d0\u51fa3D-WLDM\uff0c\u5728\u5b66\u4e60\u7684\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u6a21\u6001\u8f6c\u6362\uff0c\u5c06Wavelet Residual Module\u96c6\u6210\u5230\u7f16\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u5206\u79bb\u7ed3\u6784\u548c\u7279\u5b9a\u6a21\u6001\u7279\u5f81\uff0c\u5f15\u5165Dual Skip Connection Attention\u673a\u5236", "result": "\u80fd\u591f\u751f\u6210\u9ad8\u5206\u8fa8\u7387CT\u56fe\u50cf\uff0c\u66f4\u597d\u5730\u8868\u793a\u9aa8\u9abc\u7ed3\u6784\u548c\u8f6f\u7ec4\u7ec7\u5bf9\u6bd4\u5ea6", "conclusion": "3D-WLDM\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709MR\u5230CT\u5408\u6210\u65b9\u6cd5\u7684\u5c40\u9650\u6027"}}
{"id": "2507.11759", "pdf": "https://arxiv.org/pdf/2507.11759", "abs": "https://arxiv.org/abs/2507.11759", "authors": ["Alexandra Volokhova", "L\u00e9na N\u00e9hale Ezzine", "Piotr Gai\u0144ski", "Luca Scimeca", "Emmanuel Bengio", "Prudencio Tossou", "Yoshua Bengio", "Alex Hernandez-Garcia"], "title": "Torsional-GFN: a conditional conformation generator for small molecules", "categories": ["cs.LG"], "comment": "The two first authors are Alexandra Volokhova and L\\'ena N\\'ehale\n  Ezzine, with equal contribution", "summary": "Generating stable molecular conformations is crucial in several drug\ndiscovery applications, such as estimating the binding affinity of a molecule\nto a target. Recently, generative machine learning methods have emerged as a\npromising, more efficient method than molecular dynamics for sampling of\nconformations from the Boltzmann distribution. In this paper, we introduce\nTorsional-GFN, a conditional GFlowNet specifically designed to sample\nconformations of molecules proportionally to their Boltzmann distribution,\nusing only a reward function as training signal. Conditioned on a molecular\ngraph and its local structure (bond lengths and angles), Torsional-GFN samples\nrotations of its torsion angles. Our results demonstrate that Torsional-GFN is\nable to sample conformations approximately proportional to the Boltzmann\ndistribution for multiple molecules with a single model, and allows for\nzero-shot generalization to unseen bond lengths and angles coming from the MD\nsimulations for such molecules. Our work presents a promising avenue for\nscaling the proposed approach to larger molecular systems, achieving zero-shot\ngeneralization to unseen molecules, and including the generation of the local\nstructure into the GFlowNet model.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u4ece\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u4e2d\u91c7\u6837\u5206\u5b50\u6784\u8c61\u7684Torsional - GFN\uff0c\u7ed3\u679c\u8868\u660e\u5176\u80fd\u4ee5\u5355\u4e00\u6a21\u578b\u4e3a\u591a\u79cd\u5206\u5b50\u91c7\u6837\uff0c\u4e14\u53ef\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u751f\u6210\u7a33\u5b9a\u5206\u5b50\u6784\u8c61\u5728\u836f\u7269\u53d1\u73b0\u5e94\u7528\u4e2d\u5f88\u91cd\u8981\uff0c\u73b0\u6709\u751f\u6210\u5f0f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6bd4\u5206\u5b50\u52a8\u529b\u5b66\u66f4\u6709\u6f5c\u529b\uff0c\u9700\u8bbe\u8ba1\u65b0\u65b9\u6cd5\u4ece\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u91c7\u6837\u5206\u5b50\u6784\u8c61\u3002", "method": "\u5f15\u5165Torsional - GFN\uff0c\u4e00\u79cd\u6761\u4ef6GFlowNet\uff0c\u4ec5\u7528\u5956\u52b1\u51fd\u6570\u4f5c\u4e3a\u8bad\u7ec3\u4fe1\u53f7\uff0c\u57fa\u4e8e\u5206\u5b50\u56fe\u53ca\u5176\u5c40\u90e8\u7ed3\u6784\u5bf9\u626d\u8f6c\u89d2\u65cb\u8f6c\u8fdb\u884c\u91c7\u6837\u3002", "result": "Torsional - GFN\u80fd\u4ee5\u5355\u4e00\u6a21\u578b\u4e3a\u591a\u79cd\u5206\u5b50\u91c7\u6837\u8fd1\u4f3c\u7b26\u5408\u73bb\u5c14\u5179\u66fc\u5206\u5e03\u7684\u6784\u8c61\uff0c\u53ef\u5bf9\u5206\u5b50MD\u6a21\u62df\u4e2d\u672a\u89c1\u7684\u952e\u957f\u548c\u952e\u89d2\u8fdb\u884c\u96f6\u6837\u672c\u6cdb\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6269\u5c55\u5230\u66f4\u5927\u5206\u5b50\u7cfb\u7edf\u3001\u5b9e\u73b0\u5bf9\u672a\u89c1\u5206\u5b50\u7684\u96f6\u6837\u672c\u6cdb\u5316\u4ee5\u53ca\u5c06\u5c40\u90e8\u7ed3\u6784\u751f\u6210\u7eb3\u5165GFlowNet\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2507.11558", "pdf": "https://arxiv.org/pdf/2507.11558", "abs": "https://arxiv.org/abs/2507.11558", "authors": ["Changlu Chen", "Yanbin Liu", "Chaoxi Niu", "Ling Chen", "Tianqing Zhu"], "title": "Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Foundation models have achieved remarkable success in natural language\nprocessing and computer vision, demonstrating strong capabilities in modeling\ncomplex patterns. While recent efforts have explored adapting large language\nmodels (LLMs) for time-series forecasting, LLMs primarily capture\none-dimensional sequential dependencies and struggle to model the richer\nspatio-temporal (ST) correlations essential for accurate ST forecasting. In\nthis paper, we present \\textbf{ST-VFM}, a novel framework that systematically\nreprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal\nforecasting. While VFMs offer powerful spatial priors, two key challenges arise\nwhen applying them to ST tasks: (1) the lack of inherent temporal modeling\ncapacity and (2) the modality gap between visual and ST data. To address these,\nST-VFM adopts a \\emph{dual-branch architecture} that integrates raw ST inputs\nwith auxiliary ST flow inputs, where the flow encodes lightweight temporal\ndifference signals interpretable as dynamic spatial cues. To effectively\nprocess these dual-branch inputs, ST-VFM introduces two dedicated reprogramming\nstages. The \\emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token\nAdapter to embed temporal context and align both branches into VFM-compatible\nfeature spaces. The \\emph{post-VFM reprogramming} stage introduces a Bilateral\nCross-Prompt Coordination module, enabling dynamic interaction between branches\nthrough prompt-based conditioning, thus enriching joint representation learning\nwithout modifying the frozen VFM backbone. Extensive experiments on ten\nspatio-temporal datasets show that ST-VFM outperforms state-of-the-art\nbaselines, demonstrating effectiveness and robustness across VFM backbones\n(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong\ngeneral framework for spatio-temporal forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faST - VFM\u6846\u67b6\uff0c\u7528\u4e8e\u65f6\u7a7a\u9884\u6d4b\uff0c\u901a\u8fc7\u53cc\u5206\u652f\u67b6\u6784\u548c\u4e24\u4e2a\u91cd\u7f16\u7a0b\u9636\u6bb5\u5904\u7406\u8f93\u5165\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6355\u6349\u65f6\u7a7a\u9884\u6d4b\u6240\u9700\u7684\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u5e94\u7528\u4e8e\u65f6\u7a7a\u4efb\u52a1\u5b58\u5728\u7f3a\u4e4f\u65f6\u95f4\u5efa\u6a21\u80fd\u529b\u548c\u6a21\u6001\u5dee\u8ddd\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652f\u67b6\u6784\uff0c\u6574\u5408\u539f\u59cb\u65f6\u7a7a\u8f93\u5165\u548c\u8f85\u52a9\u65f6\u7a7a\u6d41\u8f93\u5165\uff1b\u5f15\u5165\u9884VFM\u91cd\u7f16\u7a0b\u9636\u6bb5\u548c\u540eVFM\u91cd\u7f16\u7a0b\u9636\u6bb5\u5904\u7406\u8f93\u5165\u3002", "result": "\u5728\u5341\u4e2a\u65f6\u7a7a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cST - VFM\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u4e0d\u540cVFM\u9aa8\u5e72\u4e0a\u90fd\u8868\u73b0\u51fa\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "ST - VFM\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u901a\u7528\u65f6\u7a7a\u9884\u6d4b\u6846\u67b6\u3002"}}
{"id": "2507.11771", "pdf": "https://arxiv.org/pdf/2507.11771", "abs": "https://arxiv.org/abs/2507.11771", "authors": ["Sheikh Abdur Raheem Ali", "Justin Xu", "Ivory Yang", "Jasmine Xinze Li", "Ayse Arslan", "Clark Benham"], "title": "Scaling laws for activation steering with Llama 2 models and refusal mechanisms", "categories": ["cs.LG"], "comment": null, "summary": "As large language models (LLMs) evolve in complexity and capability, the\nefficacy of less widely deployed alignment techniques are uncertain. Building\non previous work on activation steering and contrastive activation addition\n(CAA), this paper explores the effectiveness of CAA with model scale using the\nfamily of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable\n'directions' in the model's residual stream vector space using contrastive\npairs (for example, hate to love) and adding this direction to the residual\nstream during the forward pass. It directly manipulates the residual stream and\naims to extract features from language models to better control their outputs.\nUsing answer matching questions centered around the refusal behavior, we found\nthat 1) CAA is most effective when applied at early-mid layers. 2) The\neffectiveness of CAA diminishes with model size. 3) Negative steering has more\npronounced effects than positive steering across all model sizes.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eLlama 2\u7cfb\u5217\u6a21\u578b\uff0c\u63a2\u7d22\u5bf9\u6bd4\u6fc0\u6d3b\u6dfb\u52a0\uff08CAA\uff09\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0CAA\u5728\u65e9\u4e2d\u671f\u5c42\u5e94\u7528\u6700\u6709\u6548\u3001\u6709\u6548\u6027\u968f\u6a21\u578b\u89c4\u6a21\u51cf\u5c0f\u3001\u8d1f\u5411\u5f15\u5bfc\u6548\u679c\u66f4\u660e\u663e\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u590d\u6742\u5ea6\u548c\u80fd\u529b\u63d0\u5347\uff0c\u4e0d\u592a\u5e7f\u6cdb\u4f7f\u7528\u7684\u5bf9\u9f50\u6280\u672f\u6548\u679c\u4e0d\u786e\u5b9a\uff0c\u56e0\u6b64\u63a2\u7d22CAA\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u7684\u6709\u6548\u6027\u3002", "method": "\u57fa\u4e8eLlama 2\u7cfb\u5217\uff087B\u300113B\u548c70B\uff09\u6a21\u578b\uff0c\u5229\u7528\u5bf9\u6bd4\u6fc0\u6d3b\u6dfb\u52a0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5bf9\u5728\u6a21\u578b\u6b8b\u5dee\u6d41\u5411\u91cf\u7a7a\u95f4\u4e2d\u627e\u5230\u7406\u60f3\u201c\u65b9\u5411\u201d\u5e76\u5728\u6b63\u5411\u4f20\u64ad\u65f6\u6dfb\u52a0\u5230\u6b8b\u5dee\u6d41\uff0c\u4f7f\u7528\u56f4\u7ed5\u62d2\u7edd\u884c\u4e3a\u7684\u7b54\u6848\u5339\u914d\u95ee\u9898\u8fdb\u884c\u7814\u7a76\u3002", "result": "1) CAA\u5728\u65e9\u4e2d\u671f\u5c42\u5e94\u7528\u6700\u6709\u6548\uff1b2) CAA\u7684\u6709\u6548\u6027\u968f\u6a21\u578b\u89c4\u6a21\u51cf\u5c0f\uff1b3) \u5728\u6240\u6709\u6a21\u578b\u89c4\u6a21\u4e0b\uff0c\u8d1f\u5411\u5f15\u5bfc\u6bd4\u6b63\u5411\u5f15\u5bfc\u6548\u679c\u66f4\u660e\u663e\u3002", "conclusion": "CAA\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u6709\u4e0d\u540c\u6548\u679c\uff0c\u5728\u6a21\u578b\u65e9\u4e2d\u671f\u5c42\u5e94\u7528\u8f83\u597d\uff0c\u4e14\u8d1f\u5411\u5f15\u5bfc\u6548\u679c\u66f4\u4f18\u3002"}}
{"id": "2507.11776", "pdf": "https://arxiv.org/pdf/2507.11776", "abs": "https://arxiv.org/abs/2507.11776", "authors": ["Merel Kampere", "Ali Mohammed Mansoor Alsahag"], "title": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Dutch railway network is one of the busiest in the world, with delays\nbeing a prominent concern for the principal passenger railway operator NS. This\nresearch addresses a gap in delay prediction studies within the Dutch railway\nnetwork by employing an XGBoost Classifier with a focus on topological\nfeatures. Current research predominantly emphasizes short-term predictions and\nneglects the broader network-wide patterns essential for mitigating ripple\neffects. This research implements and improves an existing methodology,\noriginally designed to forecast the evolution of the fast-changing US air\nnetwork, to predict delays in the Dutch Railways. By integrating Node\nCentrality Measures and comparing multiple classifiers like RandomForest,\nDecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is\nto predict delayed trajectories. However, the results reveal limited\nperformance, especially in non-simultaneous testing scenarios, suggesting the\nnecessity for more context-specific adaptations. Regardless, this research\ncontributes to the understanding of transportation network evaluation and\nproposes future directions for developing more robust predictive models for\ndelays.", "AI": {"tldr": "\u672c\u6587\u7528XGBoost\u5206\u7c7b\u5668\uff0c\u7ed3\u5408\u62d3\u6251\u7279\u5f81\u5bf9\u8377\u5170\u94c1\u8def\u7f51\u7edc\u5ef6\u8bef\u9884\u6d4b\u5c55\u5f00\u7814\u7a76\uff0c\u867d\u7ed3\u679c\u8868\u73b0\u6709\u9650\uff0c\u4f46\u4e3a\u4ea4\u901a\u7f51\u7edc\u8bc4\u4f30\u53ca\u540e\u7eed\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u8377\u5170\u94c1\u8def\u7f51\u7e41\u5fd9\uff0c\u5ef6\u8bef\u662f\u4e3b\u8981\u95ee\u9898\uff0c\u5f53\u524d\u7814\u7a76\u591a\u4fa7\u91cd\u77ed\u671f\u9884\u6d4b\uff0c\u5ffd\u7565\u7f51\u7edc\u6574\u4f53\u6a21\u5f0f\u4ee5\u51cf\u8f7b\u8fde\u9501\u53cd\u5e94\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8377\u5170\u94c1\u8def\u7f51\u7edc\u5ef6\u8bef\u9884\u6d4b\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528XGBoost\u5206\u7c7b\u5668\uff0c\u7ed3\u5408\u8282\u70b9\u4e2d\u5fc3\u6027\u5ea6\u91cf\uff0c\u5bf9\u6bd4\u968f\u673a\u68ee\u6797\u3001\u51b3\u7b56\u6811\u7b49\u591a\u4e2a\u5206\u7c7b\u5668\uff0c\u6539\u8fdb\u7528\u4e8e\u9884\u6d4b\u7f8e\u56fd\u822a\u7a7a\u7f51\u7edc\u6f14\u53d8\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u8377\u5170\u94c1\u8def\u5ef6\u8bef\u3002", "result": "\u6a21\u578b\u5728\u975e\u540c\u6b65\u6d4b\u8bd5\u573a\u666f\u4e2d\u8868\u73b0\u6709\u9650\u3002", "conclusion": "\u672c\u7814\u7a76\u6709\u52a9\u4e8e\u7406\u89e3\u4ea4\u901a\u7f51\u7edc\u8bc4\u4f30\uff0c\u5e76\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u5ef6\u8bef\u9884\u6d4b\u6a21\u578b\u63d0\u51fa\u4e86\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2507.11561", "pdf": "https://arxiv.org/pdf/2507.11561", "abs": "https://arxiv.org/abs/2507.11561", "authors": ["Lucas Erlacher", "Samuel Ruip\u00e9rez-Campillo", "Holger Michel", "Sven Wellmann", "Thomas M. Sutter", "Ece Ozkan", "Julia E. Vogt"], "title": "Predicting Pulmonary Hypertension in Newborns: A Multi-view VAE Approach", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Pulmonary hypertension (PH) in newborns is a critical condition characterized\nby elevated pressure in the pulmonary arteries, leading to right ventricular\nstrain and heart failure. While right heart catheterization (RHC) is the\ndiagnostic gold standard, echocardiography is preferred due to its non-invasive\nnature, safety, and accessibility. However, its accuracy highly depends on the\noperator, making PH assessment subjective. While automated detection methods\nhave been explored, most models focus on adults and rely on single-view\nechocardiographic frames, limiting their performance in diagnosing PH in\nnewborns. While multi-view echocardiography has shown promise in improving PH\nassessment, existing models struggle with generalizability. In this work, we\nemploy a multi-view variational autoencoder (VAE) for PH prediction using\nechocardiographic videos. By leveraging the VAE framework, our model captures\ncomplex latent representations, improving feature extraction and robustness. We\ncompare its performance against single-view and supervised learning approaches.\nOur results show improved generalization and classification accuracy,\nhighlighting the effectiveness of multi-view learning for robust PH assessment\nin newborns.", "AI": {"tldr": "\u672c\u6587\u91c7\u7528\u591a\u89c6\u56fe\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u5229\u7528\u8d85\u58f0\u5fc3\u52a8\u56fe\u89c6\u9891\u8fdb\u884c\u65b0\u751f\u513f\u80ba\u52a8\u8109\u9ad8\u538b\uff08PH\uff09\u9884\u6d4b\uff0c\u5bf9\u6bd4\u5355\u89c6\u56fe\u548c\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u591a\u89c6\u56fe\u5b66\u4e60\u5728PH\u8bc4\u4f30\u4e2d\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u8d85\u58f0\u5fc3\u52a8\u56fe\u8bca\u65adPH\u4f9d\u8d56\u64cd\u4f5c\u8005\u4e14\u4e3b\u89c2\u6027\u5f3a\uff0c\u81ea\u52a8\u5316\u68c0\u6d4b\u65b9\u6cd5\u591a\u9488\u5bf9\u6210\u4eba\u3001\u57fa\u4e8e\u5355\u89c6\u56fe\u4e14\u6cdb\u5316\u6027\u5dee\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u8bc4\u4f30\u65b0\u751f\u513fPH\u3002", "method": "\u91c7\u7528\u591a\u89c6\u56fe\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u5229\u7528\u8d85\u58f0\u5fc3\u52a8\u56fe\u89c6\u9891\u8fdb\u884cPH\u9884\u6d4b\uff0c\u5e76\u4e0e\u5355\u89c6\u56fe\u548c\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6bd4\u3002", "result": "\u6a21\u578b\u5728\u6cdb\u5316\u6027\u548c\u5206\u7c7b\u51c6\u786e\u6027\u4e0a\u6709\u63d0\u5347\u3002", "conclusion": "\u591a\u89c6\u56fe\u5b66\u4e60\u5bf9\u65b0\u751f\u513fPH\u7684\u7a33\u5065\u8bc4\u4f30\u6709\u6548\u3002"}}
{"id": "2507.11789", "pdf": "https://arxiv.org/pdf/2507.11789", "abs": "https://arxiv.org/abs/2507.11789", "authors": ["Alessandro Palma", "Sergei Rybakov", "Leon Hetzel", "Stephan G\u00fcnnemann", "Fabian J. Theis"], "title": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation", "categories": ["cs.LG", "q-bio.QM"], "comment": "31 pages, 14 figures", "summary": "Latent space interpolations are a powerful tool for navigating deep\ngenerative models in applied settings. An example is single-cell RNA\nsequencing, where existing methods model cellular state transitions as latent\nspace interpolations with variational autoencoders, often assuming linear\nshifts and Euclidean geometry. However, unless explicitly enforced, linear\ninterpolations in the latent space may not correspond to geodesic paths on the\ndata manifold, limiting methods that assume Euclidean geometry in the data\nrepresentations. We introduce FlatVI, a novel training framework that\nregularises the latent manifold of discrete-likelihood variational autoencoders\ntowards Euclidean geometry, specifically tailored for modelling single-cell\ncount data. By encouraging straight lines in the latent space to approximate\ngeodesic interpolations on the decoded single-cell manifold, FlatVI enhances\ncompatibility with downstream approaches that assume Euclidean latent geometry.\nExperiments on synthetic data support the theoretical soundness of our\napproach, while applications to time-resolved single-cell RNA sequencing data\ndemonstrate improved trajectory reconstruction and manifold interpolation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFlatVI\u8bad\u7ec3\u6846\u67b6\uff0c\u6b63\u5219\u5316\u79bb\u6563\u4f3c\u7136\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u6f5c\u5728\u6d41\u5f62\u81f3\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\uff0c\u7528\u4e8e\u5355\u7ec6\u80de\u8ba1\u6570\u6570\u636e\u5efa\u6a21\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u65b9\u6cd5\u5047\u8bbe\u6f5c\u5728\u7a7a\u95f4\u7ebf\u6027\u63d2\u503c\u548c\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\uff0c\u4f46\u7ebf\u6027\u63d2\u503c\u53ef\u80fd\u4e0d\u5bf9\u5e94\u6570\u636e\u6d41\u5f62\u4e0a\u7684\u6d4b\u5730\u7ebf\u8def\u5f84\uff0c\u9650\u5236\u4e86\u76f8\u5173\u65b9\u6cd5\u3002", "method": "\u5f15\u5165FlatVI\u8bad\u7ec3\u6846\u67b6\uff0c\u6b63\u5219\u5316\u79bb\u6563\u4f3c\u7136\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u6f5c\u5728\u6d41\u5f62\uff0c\u4f7f\u5176\u7b26\u5408\u6b27\u51e0\u91cc\u5f97\u51e0\u4f55\u3002", "result": "\u5408\u6210\u6570\u636e\u5b9e\u9a8c\u652f\u6301\u65b9\u6cd5\u7684\u7406\u8bba\u5408\u7406\u6027\uff0c\u65f6\u95f4\u5206\u8fa8\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u5e94\u7528\u5c55\u793a\u4e86\u66f4\u597d\u7684\u8f68\u8ff9\u91cd\u5efa\u548c\u6d41\u5f62\u63d2\u503c\u6548\u679c\u3002", "conclusion": "FlatVI\u6846\u67b6\u589e\u5f3a\u4e86\u4e0e\u5047\u8bbe\u6b27\u51e0\u91cc\u5f97\u6f5c\u5728\u51e0\u4f55\u7684\u4e0b\u6e38\u65b9\u6cd5\u7684\u517c\u5bb9\u6027\uff0c\u63d0\u5347\u4e86\u5355\u7ec6\u80de\u6570\u636e\u5efa\u6a21\u6548\u679c\u3002"}}
{"id": "2507.11562", "pdf": "https://arxiv.org/pdf/2507.11562", "abs": "https://arxiv.org/abs/2507.11562", "authors": ["Ozer Can Devecioglu", "Serkan Kiranyaz", "Mehmet Yamac", "Moncef Gabbouj"], "title": "Expert Operational GANS: Towards Real-Color Underwater Image Restoration", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": "6 pages", "summary": "The wide range of deformation artifacts that arise from complex light\npropagation, scattering, and depth-dependent attenuation makes the underwater\nimage restoration to remain a challenging problem. Like other single deep\nregressor networks, conventional GAN-based restoration methods struggle to\nperform well across this heterogeneous domain, since a single generator network\nis typically insufficient to capture the full range of visual degradations. In\norder to overcome this limitation, we propose xOp-GAN, a novel GAN model with\nseveral expert generator networks, each trained solely on a particular subset\nwith a certain image quality. Thus, each generator can learn to maximize its\nrestoration performance for a particular quality range. Once a xOp-GAN is\ntrained, each generator can restore the input image and the best restored image\ncan then be selected by the discriminator based on its perceptual confidence\nscore. As a result, xOP-GAN is the first GAN model with multiple generators\nwhere the discriminator is being used during the inference of the regression\ntask. Experimental results on benchmark Large Scale Underwater Image (LSUI)\ndataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,\nsurpassing all single-regressor models by a large margin even, with reduced\ncomplexity.", "AI": {"tldr": "\u63d0\u51faxOp - GAN\u7528\u4e8e\u6c34\u4e0b\u56fe\u50cf\u6062\u590d\uff0c\u542b\u591a\u4e2a\u4e13\u5bb6\u751f\u6210\u5668\u7f51\u7edc\uff0c\u5b9e\u9a8c\u8868\u660e\u5176PSNR\u8fbe25.16 dB\uff0c\u4f18\u4e8e\u5355\u56de\u5f52\u6a21\u578b\u4e14\u590d\u6742\u5ea6\u4f4e\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eGAN\u7684\u6c34\u4e0b\u56fe\u50cf\u6062\u590d\u65b9\u6cd5\u56e0\u5355\u4e00\u751f\u6210\u5668\u7f51\u7edc\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u56fe\u50cf\u9000\u5316\uff0c\u6062\u590d\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faxOp - GAN\uff0c\u6709\u591a\u4e2a\u4e13\u5bb6\u751f\u6210\u5668\u7f51\u7edc\uff0c\u6bcf\u4e2a\u5728\u7279\u5b9a\u56fe\u50cf\u8d28\u91cf\u5b50\u96c6\u4e0a\u8bad\u7ec3\uff0c\u63a8\u7406\u65f6\u9274\u522b\u5668\u6839\u636e\u611f\u77e5\u7f6e\u4fe1\u5ea6\u5206\u6570\u9009\u6700\u4f73\u6062\u590d\u56fe\u50cf\u3002", "result": "\u5728LSUI\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cxOp - GAN\u7684PSNR\u8fbe25.16 dB\uff0c\u5927\u5e45\u8d85\u8d8a\u5355\u56de\u5f52\u6a21\u578b\uff0c\u4e14\u590d\u6742\u5ea6\u964d\u4f4e\u3002", "conclusion": "xOp - GAN\u662f\u9996\u4e2a\u5728\u56de\u5f52\u4efb\u52a1\u63a8\u7406\u4e2d\u4f7f\u7528\u9274\u522b\u5668\u7684\u591a\u751f\u6210\u5668GAN\u6a21\u578b\uff0c\u80fd\u6709\u6548\u8fdb\u884c\u6c34\u4e0b\u56fe\u50cf\u6062\u590d\u3002"}}
{"id": "2507.11807", "pdf": "https://arxiv.org/pdf/2507.11807", "abs": "https://arxiv.org/abs/2507.11807", "authors": ["Ruofan Hu", "Dongyu Zhang", "Huayi Zhang", "Elke Rundensteiner"], "title": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "categories": ["cs.LG", "cs.AI"], "comment": "KDD 2025, 12 pages, 7 figures", "summary": "Learning with noisy labels (LNL) is essential for training deep neural\nnetworks with imperfect data. Meta-learning approaches have achieved success by\nusing a clean unbiased labeled set to train a robust model. However, this\napproach heavily depends on the availability of a clean labeled meta-dataset,\nwhich is difficult to obtain in practice. In this work, we thus tackle the\nchallenge of meta-learning for noisy label scenarios without relying on a clean\nlabeled dataset. Our approach leverages the data itself while bypassing the\nneed for labels. Building on the insight that clean samples effectively\npreserve the consistency of related data structures across the last hidden and\nthe final layer, whereas noisy samples disrupt this consistency, we design the\nCross-layer Information Divergence-based Meta Update Strategy (CLID-MU).\nCLID-MU leverages the alignment of data structures across these diverse feature\nspaces to evaluate model performance and use this alignment to guide training.\nExperiments on benchmark datasets with varying amounts of labels under both\nsynthetic and real-world noise demonstrate that CLID-MU outperforms\nstate-of-the-art methods. The code is released at\nhttps://github.com/ruofanhu/CLID-MU.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u5e72\u51c0\u6807\u7b7e\u6570\u636e\u96c6\u7684\u5143\u5b66\u4e60\u65b9\u6cd5CLID - MU\u5e94\u5bf9\u542b\u566a\u6807\u7b7e\u573a\u666f\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5143\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5e72\u51c0\u6807\u7b7e\u5143\u6570\u636e\u96c6\uff0c\u5b9e\u9645\u96be\u4ee5\u83b7\u53d6\uff0c\u9700\u89e3\u51b3\u65e0\u5e72\u51c0\u6807\u7b7e\u6570\u636e\u96c6\u7684\u542b\u566a\u6807\u7b7e\u5143\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5e72\u51c0\u6837\u672c\u548c\u542b\u566a\u6837\u672c\u5bf9\u6570\u636e\u7ed3\u6784\u4e00\u81f4\u6027\u7684\u4e0d\u540c\u5f71\u54cd\uff0c\u8bbe\u8ba1Cross - layer Information Divergence - based Meta Update Strategy (CLID - MU)\uff0c\u5229\u7528\u4e0d\u540c\u7279\u5f81\u7a7a\u95f4\u7684\u6570\u636e\u7ed3\u6784\u5bf9\u9f50\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u5e76\u6307\u5bfc\u8bad\u7ec3\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u566a\u58f0\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cCLID - MU\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CLID - MU\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u5e72\u51c0\u6807\u7b7e\u6570\u636e\u96c6\u7684\u542b\u566a\u6807\u7b7e\u5143\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2507.11818", "pdf": "https://arxiv.org/pdf/2507.11818", "abs": "https://arxiv.org/abs/2507.11818", "authors": ["Andrei Rekesh", "Miruna Cretu", "Dmytro Shevchuk", "Vignesh Ram Somnath", "Pietro Li\u00f2", "Robert A. Batey", "Mike Tyers", "Micha\u0142 Koziarski", "Cheng-Hao Liu"], "title": "SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring synthesizability in generative small molecule design remains a major\nchallenge. While recent developments in synthesizable molecule generation have\ndemonstrated promising results, these efforts have been largely confined to 2D\nmolecular graph representations, limiting the ability to perform geometry-based\nconditional generation. In this work, we present SynCoGen (Synthesizable\nCo-Generation), a single framework that combines simultaneous masked graph\ndiffusion and flow matching for synthesizable 3D molecule generation. SynCoGen\nsamples from the joint distribution of molecular building blocks, chemical\nreactions, and atomic coordinates. To train the model, we curated SynSpace, a\ndataset containing over 600K synthesis-aware building block graphs and 3.3M\nconformers. SynCoGen achieves state-of-the-art performance in unconditional\nsmall molecule graph and conformer generation, and the model delivers\ncompetitive performance in zero-shot molecular linker design for protein ligand\ngeneration in drug discovery. Overall, this multimodal formulation represents a\nfoundation for future applications enabled by non-autoregressive molecular\ngeneration, including analog expansion, lead optimization, and direct structure\nconditioning.", "AI": {"tldr": "\u63d0\u51faSynCoGen\u6846\u67b6\u7528\u4e8e\u53ef\u5408\u62103D\u5206\u5b50\u751f\u6210\uff0c\u8868\u73b0\u4f18\u5f02\u5e76\u5177\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u73b0\u6709\u53ef\u5408\u6210\u5c0f\u5206\u5b50\u751f\u6210\u5c40\u9650\u4e8e2D\u56fe\u8868\u793a\uff0c\u65e0\u6cd5\u8fdb\u884c\u57fa\u4e8e\u51e0\u4f55\u7684\u6761\u4ef6\u751f\u6210\u3002", "method": "\u7ed3\u5408\u63a9\u7801\u56fe\u6269\u6563\u548c\u6d41\u5339\u914d\uff0c\u4ece\u5206\u5b50\u6784\u5efa\u5757\u3001\u5316\u5b66\u53cd\u5e94\u548c\u539f\u5b50\u5750\u6807\u8054\u5408\u5206\u5e03\u91c7\u6837\uff0c\u7528SynSpace\u6570\u636e\u96c6\u8bad\u7ec3\u3002", "result": "\u5728\u65e0\u6761\u4ef6\u5c0f\u5206\u5b50\u56fe\u548c\u6784\u8c61\u751f\u6210\u4e2d\u8fbeSOTA\uff0c\u5728\u96f6\u6837\u672c\u5206\u5b50\u8fde\u63a5\u4f53\u8bbe\u8ba1\u4e2d\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u8be5\u591a\u6a21\u6001\u516c\u5f0f\u4e3a\u975e\u81ea\u56de\u5f52\u5206\u5b50\u751f\u6210\u5e94\u7528\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.11569", "pdf": "https://arxiv.org/pdf/2507.11569", "abs": "https://arxiv.org/abs/2507.11569", "authors": ["Hanxue Gu", "Yaqian Chen", "Nicholas Konz", "Qihang Li", "Maciej A. Mazurowski"], "title": "Are Vision Foundation Models Ready for Out-of-the-Box Medical Image Registration?", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "3 figures, 9 pages", "summary": "Foundation models, pre-trained on large image datasets and capable of\ncapturing rich feature representations, have recently shown potential for\nzero-shot image registration. However, their performance has mostly been tested\nin the context of rigid or less complex structures, such as the brain or\nabdominal organs, and it remains unclear whether these models can handle more\nchallenging, deformable anatomy. Breast MRI registration is particularly\ndifficult due to significant anatomical variation between patients, deformation\ncaused by patient positioning, and the presence of thin and complex internal\nstructure of fibroglandular tissue, where accurate alignment is crucial.\nWhether foundation model-based registration algorithms can address this level\nof complexity remains an open question. In this study, we provide a\ncomprehensive evaluation of foundation model-based registration algorithms for\nbreast MRI. We assess five pre-trained encoders, including DINO-v2, SAM,\nMedSAM, SSLSAM, and MedCLIP, across four key breast registration tasks that\ncapture variations in different years and dates, sequences, modalities, and\npatient disease status (lesion versus no lesion). Our results show that\nfoundation model-based algorithms such as SAM outperform traditional\nregistration baselines for overall breast alignment, especially under large\ndomain shifts, but struggle with capturing fine details of fibroglandular\ntissue. Interestingly, additional pre-training or fine-tuning on medical or\nbreast-specific images in MedSAM and SSLSAM, does not improve registration\nperformance and may even decrease it in some cases. Further work is needed to\nunderstand how domain-specific training influences registration and to explore\ntargeted strategies that improve both global alignment and fine structure\naccuracy. We also publicly release our code at\n\\href{https://github.com/mazurowski-lab/Foundation-based-reg}{Github}.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u8bc4\u4f30\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u4e73\u817aMRI\u914d\u51c6\u7b97\u6cd5\uff0c\u53d1\u73b0SAM\u7b49\u7b97\u6cd5\u5728\u6574\u4f53\u4e73\u817a\u5bf9\u9f50\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5728\u6355\u6349\u7ea4\u7ef4\u817a\u4f53\u7ec4\u7ec7\u7ec6\u8282\u4e0a\u6709\u56f0\u96be\uff0c\u7279\u5b9a\u9886\u57df\u8bad\u7ec3\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u96f6\u6837\u672c\u56fe\u50cf\u914d\u51c6\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u53ef\u53d8\u5f62\u89e3\u5256\u7ed3\u6784\u5982\u4e73\u817aMRI\u914d\u51c6\u7684\u80fd\u529b\u672a\u77e5\uff0c\u672c\u6587\u65e8\u5728\u8bc4\u4f30\u5176\u5728\u4e73\u817aMRI\u914d\u51c6\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u8bc4\u4f30\u4e94\u4e2a\u9884\u8bad\u7ec3\u7f16\u7801\u5668\uff08DINO - v2\u3001SAM\u3001MedSAM\u3001SSLSAM\u548cMedCLIP\uff09\u5728\u56db\u4e2a\u5173\u952e\u4e73\u817a\u914d\u51c6\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "SAM\u7b49\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u7b97\u6cd5\u5728\u6574\u4f53\u4e73\u817a\u5bf9\u9f50\u4e0a\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u5927\u9886\u57df\u504f\u79fb\u60c5\u51b5\u4e0b\uff0c\u4f46\u5728\u6355\u6349\u7ea4\u7ef4\u817a\u4f53\u7ec4\u7ec7\u7ec6\u8282\u4e0a\u8868\u73b0\u4e0d\u4f73\uff1bMedSAM\u548cSSLSAM\u5728\u533b\u5b66\u6216\u4e73\u817a\u7279\u5b9a\u56fe\u50cf\u4e0a\u7684\u989d\u5916\u9884\u8bad\u7ec3\u6216\u5fae\u8c03\u672a\u63d0\u5347\u914d\u51c6\u6027\u80fd\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f1a\u964d\u4f4e\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u7279\u5b9a\u9886\u57df\u8bad\u7ec3\u5bf9\u914d\u51c6\u7684\u5f71\u54cd\uff0c\u63a2\u7d22\u63d0\u9ad8\u5168\u5c40\u5bf9\u9f50\u548c\u7cbe\u7ec6\u7ed3\u6784\u51c6\u786e\u6027\u7684\u7b56\u7565\uff0c\u5e76\u516c\u5f00\u4e86\u4ee3\u7801\u3002"}}
{"id": "2507.11821", "pdf": "https://arxiv.org/pdf/2507.11821", "abs": "https://arxiv.org/abs/2507.11821", "authors": ["Pouya Shaeri", "Arash Karimi", "Ariane Middel"], "title": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "comment": "Submitted to a computer science conference", "summary": "Neural networks are often benchmarked using standard datasets such as MNIST,\nFashionMNIST, or other variants of MNIST, which, while accessible, are limited\nto generic classes such as digits or clothing items. For researchers working on\ndomain-specific tasks, such as classifying trees, food items, or other\nreal-world objects, these data sets are insufficient and irrelevant.\nAdditionally, creating and publishing a custom dataset can be time consuming,\nlegally constrained, or beyond the scope of individual projects. We present\nMNIST-Gen, an automated, modular, and adaptive framework for generating\nMNIST-style image datasets tailored to user-specified categories using\nhierarchical semantic categorization. The system combines CLIP-based semantic\nunderstanding with reinforcement learning and human feedback to achieve\nintelligent categorization with minimal manual intervention. Our hierarchical\napproach supports complex category structures with semantic characteristics,\nenabling fine-grained subcategorization and multiple processing modes:\nindividual review for maximum control, smart batch processing for large\ndatasets, and fast batch processing for rapid creation. Inspired by category\ntheory, MNIST-Gen models each data transformation stage as a composable\nmorphism, enhancing clarity, modularity, and extensibility. As proof of\nconcept, we generate and benchmark two novel datasets-\\textit{Tree-MNIST} and\n\\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing\ntask-specific evaluation data while achieving 85\\% automatic categorization\naccuracy and 80\\% time savings compared to manual approaches.", "AI": {"tldr": "\u63d0\u51faMNIST - Gen\u6846\u67b6\u751f\u6210MNIST\u98ce\u683c\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u7528Tree - MNIST\u548cFood - MNIST\u9a8c\u8bc1\uff0c\u51c6\u786e\u738785%\u4e14\u8282\u770180%\u65f6\u95f4\u3002", "motivation": "\u6807\u51c6MNIST\u6570\u636e\u96c6\u5bf9\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e0d\u9002\u7528\uff0c\u521b\u5efa\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8017\u65f6\u4e14\u53d7\u9650\u3002", "method": "\u7ed3\u5408CLIP\u8bed\u4e49\u7406\u89e3\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u4eba\u5de5\u53cd\u9988\uff0c\u7528\u5206\u5c42\u8bed\u4e49\u5206\u7c7b\uff0c\u5c06\u6570\u636e\u8f6c\u6362\u9636\u6bb5\u5efa\u6a21\u4e3a\u53ef\u7ec4\u5408\u6001\u5c04\u3002", "result": "\u751f\u6210Tree - MNIST\u548cFood - MNIST\u6570\u636e\u96c6\uff0c\u81ea\u52a8\u5206\u7c7b\u51c6\u786e\u7387\u8fbe85%\uff0c\u8282\u770180%\u65f6\u95f4\u3002", "conclusion": "MNIST - Gen\u53ef\u6709\u6548\u751f\u6210\u7279\u5b9a\u4efb\u52a1\u8bc4\u4f30\u6570\u636e\u3002"}}
{"id": "2507.11836", "pdf": "https://arxiv.org/pdf/2507.11836", "abs": "https://arxiv.org/abs/2507.11836", "authors": ["Jian Gao", "Jianshe Wu", "JingYi Ding"], "title": "HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Dynamic link prediction in continuous-time dynamic graphs is a fundamental\ntask for modeling evolving complex systems. Existing node-centric and\nevent-centric methods focus on individual interactions or atomic states,\nfailing to capture the structural cohesion of composite hyper-events, groups of\ncausally related events. To address this, we propose HyperEvent, a framework\nreframing dynamic link prediction as hyper-event recognition. Central to\nHyperEvent is the dynamic construction of an association sequence using event\ncorrelation vectors. These vectors quantify pairwise dependencies between the\nquery event and relevant historical events, thereby characterizing the\nstructural cohesion of a potential hyper-event. The framework predicts the\noccurrence of the query event by evaluating whether it collectively forms a\nvalid hyper-event with these historical events. Notably, HyperEvent outperforms\nstate-of-the-art methods on 4 out of 5 datasets in the official leaderboard.\nFor scalability, we further introduce an efficient parallel training algorithm\nthat segments large event streams to enable concurrent training. Experiments\nvalidate HyperEvent's superior accuracy and efficiency on large-scale graphs.\nAmong which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank\nover state-of-the-art baseline on the large-scale Flight dataset while\nutilizing only 10.17% of the training time.", "AI": {"tldr": "\u63d0\u51faHyperEvent\u6846\u67b6\u5c06\u52a8\u6001\u94fe\u63a5\u9884\u6d4b\u8f6c\u4e3a\u8d85\u4e8b\u4ef6\u8bc6\u522b\uff0c\u5728\u591a\u6570\u636e\u96c6\u8868\u73b0\u4f73\uff0c\u8fd8\u5f15\u5165\u5e76\u884c\u8bad\u7ec3\u7b97\u6cd5\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u8282\u70b9\u4e2d\u5fc3\u548c\u4e8b\u4ef6\u4e2d\u5fc3\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u590d\u5408\u8d85\u4e8b\u4ef6\u7684\u7ed3\u6784\u5185\u805a\u6027\u3002", "method": "\u6784\u5efaHyperEvent\u6846\u67b6\uff0c\u7528\u4e8b\u4ef6\u76f8\u5173\u5411\u91cf\u52a8\u6001\u6784\u5efa\u5173\u8054\u5e8f\u5217\uff0c\u9884\u6d4b\u67e5\u8be2\u4e8b\u4ef6\u662f\u5426\u80fd\u4e0e\u5386\u53f2\u4e8b\u4ef6\u5f62\u6210\u6709\u6548\u8d85\u4e8b\u4ef6\uff1b\u5f15\u5165\u5e76\u884c\u8bad\u7ec3\u7b97\u6cd5\u5206\u5272\u5927\u4e8b\u4ef6\u6d41\u8fdb\u884c\u5e76\u53d1\u8bad\u7ec3\u3002", "result": "\u5728\u5b98\u65b9\u6392\u884c\u699c5\u4e2a\u6570\u636e\u96c6\u4e2d4\u4e2a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u5728\u5927\u89c4\u6a21Flight\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u5012\u6570\u6392\u540d\u63d0\u53476.95%\uff0c\u4ec5\u752810.17%\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "HyperEvent\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u6709\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.11839", "pdf": "https://arxiv.org/pdf/2507.11839", "abs": "https://arxiv.org/abs/2507.11839", "authors": ["Chengyue Gong", "Xinshi Chen", "Yuxuan Zhang", "Yuxuan Song", "Hao Zhou", "Wenzhi Xiao"], "title": "Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Lightweight inference is critical for biomolecular structure prediction and\nother downstream tasks, enabling efficient real-world deployment and\ninference-time scaling for large-scale applications. In this work, we address\nthe challenge of balancing model efficiency and prediction accuracy by making\nseveral key modifications, 1) Multi-step AF3 sampler is replaced by a few-step\nODE sampler, significantly reducing computational overhead for the diffusion\nmodule part during inference; 2) In the open-source Protenix framework, a\nsubset of pairformer or diffusion transformer blocks doesn't make contributions\nto the final structure prediction, presenting opportunities for architectural\npruning and lightweight redesign; 3) A model incorporating an ESM module is\ntrained to substitute the conventional MSA module, reducing MSA preprocessing\ntime. Building on these key insights, we present Protenix-Mini, a compact and\noptimized model designed for efficient protein structure prediction. This\nstreamlined version incorporates a more efficient architectural design with a\ntwo-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating\nredundant Transformer components and refining the sampling process,\nProtenix-Mini significantly reduces model complexity with slight accuracy drop.\nEvaluations on benchmark datasets demonstrate that it achieves high-fidelity\npredictions, with only a negligible 1 to 5 percent decrease in performance on\nbenchmark datasets compared to its full-scale counterpart. This makes\nProtenix-Mini an ideal choice for applications where computational resources\nare limited but accurate structure prediction remains crucial.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6a21\u578bProtenix - Mini\u7528\u4e8e\u9ad8\u6548\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\uff0c\u901a\u8fc7\u5173\u952e\u4fee\u6539\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u6027\u80fd\u7565\u964d\u4f46\u9002\u5408\u8d44\u6e90\u6709\u9650\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u751f\u7269\u5206\u5b50\u7ed3\u6784\u9884\u6d4b\u4e2d\u6a21\u578b\u6548\u7387\u548c\u9884\u6d4b\u51c6\u786e\u6027\u7684\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u5927\u89c4\u6a21\u5e94\u7528\u7684\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u3002", "method": "1. \u7528\u51e0\u6b65\u7684ODE\u91c7\u6837\u5668\u66ff\u6362\u591a\u6b65AF3\u91c7\u6837\u5668\uff1b2. \u5bf9\u5f00\u6e90Protenix\u6846\u67b6\u8fdb\u884c\u67b6\u6784\u4fee\u526a\u548c\u8f7b\u91cf\u7ea7\u91cd\u65b0\u8bbe\u8ba1\uff1b3. \u8bad\u7ec3\u542bESM\u6a21\u5757\u7684\u6a21\u578b\u66ff\u4ee3\u4f20\u7edfMSA\u6a21\u5757\u3002", "result": "Protenix - Mini\u663e\u8457\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4ec5\u4e0b\u964d1 - 5%\u3002", "conclusion": "Protenix - Mini\u9002\u5408\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u4f46\u9700\u51c6\u786e\u7ed3\u6784\u9884\u6d4b\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2507.11575", "pdf": "https://arxiv.org/pdf/2507.11575", "abs": "https://arxiv.org/abs/2507.11575", "authors": ["Victor Caquilpan"], "title": "What cat is that? A re-id model for feral cats", "categories": ["cs.CV", "cs.AI"], "comment": "Master's project", "summary": "Feral cats exert a substantial and detrimental impact on Australian wildlife,\nplacing them among the most dangerous invasive species worldwide. Therefore,\nclosely monitoring these cats is essential labour in minimising their effects.\nIn this context, the potential application of Re-Identification (re-ID) emerges\nto enhance monitoring activities for these animals, utilising images captured\nby camera traps. This project explores different CV approaches to create a\nre-ID model able to identify individual feral cats in the wild. The main\napproach consists of modifying a part-pose guided network (PPGNet) model,\ninitially used in the re-ID of Amur tigers, to be applicable for feral cats.\nThis adaptation, resulting in PPGNet-Cat, which incorporates specific\nmodifications to suit the characteristics of feral cats images. Additionally,\nvarious experiments were conducted, particularly exploring contrastive learning\napproaches such as ArcFace loss. The main results indicate that PPGNet-Cat\nexcels in identifying feral cats, achieving high performance with a mean\nAverage Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes\nestablish PPGNet-Cat as a competitive model within the realm of re-ID.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22CV\u65b9\u6cd5\u6784\u5efa\u518d\u8bc6\u522b\u6a21\u578b\u8bc6\u522b\u91ce\u732b\uff0c\u4fee\u6539PPGNet\u4e3aPPGNet - Cat\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u6548\u679c\u597d\u3002", "motivation": "\u91ce\u732b\u5bf9\u6fb3\u5927\u5229\u4e9a\u91ce\u751f\u52a8\u7269\u5371\u5bb3\u5927\uff0c\u9700\u5bc6\u5207\u76d1\u6d4b\uff0c\u518d\u8bc6\u522b\u6280\u672f\u53ef\u63d0\u5347\u76d1\u6d4b\u6548\u679c\u3002", "method": "\u4fee\u6539\u7528\u4e8e\u4e1c\u5317\u864e\u518d\u8bc6\u522b\u7684PPGNet\u6a21\u578b\u4e3aPPGNet - Cat\u4ee5\u9002\u914d\u91ce\u732b\u56fe\u50cf\uff0c\u5f00\u5c55\u542bArcFace\u635f\u5931\u7b49\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u9a8c\u3002", "result": "PPGNet - Cat\u8bc6\u522b\u91ce\u732b\u8868\u73b0\u51fa\u8272\uff0c\u5e73\u5747\u7cbe\u5ea6\u5747\u503c\uff08mAP\uff09\u8fbe0.86\uff0crank - 1\u51c6\u786e\u7387\u8fbe0.95\u3002", "conclusion": "PPGNet - Cat\u662f\u518d\u8bc6\u522b\u9886\u57df\u6709\u7ade\u4e89\u529b\u7684\u6a21\u578b\u3002"}}
{"id": "2507.11588", "pdf": "https://arxiv.org/pdf/2507.11588", "abs": "https://arxiv.org/abs/2507.11588", "authors": ["Suyuan Zhao", "Yizhen Luo", "Ganbo Yang", "Yan Zhong", "Hao Zhou", "Zaiqing Nie"], "title": "SToFM: a Multi-scale Foundation Model for Spatial Transcriptomics", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "comment": "Accpeted by ICML 2024", "summary": "Spatial Transcriptomics (ST) technologies provide biologists with rich\ninsights into single-cell biology by preserving spatial context of cells.\nBuilding foundational models for ST can significantly enhance the analysis of\nvast and complex data sources, unlocking new perspectives on the intricacies of\nbiological tissues. However, modeling ST data is inherently challenging due to\nthe need to extract multi-scale information from tissue slices containing vast\nnumbers of cells. This process requires integrating macro-scale tissue\nmorphology, micro-scale cellular microenvironment, and gene-scale gene\nexpression profile. To address this challenge, we propose SToFM, a multi-scale\nSpatial Transcriptomics Foundation Model. SToFM first performs multi-scale\ninformation extraction on each ST slice, to construct a set of ST sub-slices\nthat aggregate macro-, micro- and gene-scale information. Then an SE(2)\nTransformer is used to obtain high-quality cell representations from the\nsub-slices. Additionally, we construct \\textbf{SToCorpus-88M}, the largest\nhigh-resolution spatial transcriptomics corpus for pretraining. SToFM achieves\noutstanding performance on a variety of downstream tasks, such as tissue region\nsemantic segmentation and cell type annotation, demonstrating its comprehensive\nunderstanding of ST data", "AI": {"tldr": "\u63d0\u51fa\u591a\u5c3a\u5ea6\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u57fa\u7840\u6a21\u578bSToFM\u7528\u4e8e\u5206\u6790\u6570\u636e\uff0c\u6784\u5efa\u8bed\u6599\u5e93\u9884\u8bad\u7ec3\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u51fa\u8272", "motivation": "\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u6570\u636e\u5efa\u6a21\u9700\u63d0\u53d6\u591a\u5c3a\u5ea6\u4fe1\u606f\uff0c\u5b58\u5728\u6311\u6218\uff0c\u6784\u5efa\u57fa\u7840\u6a21\u578b\u53ef\u63d0\u5347\u6570\u636e\u5206\u6790\u80fd\u529b", "method": "\u5bf9\u6bcf\u4e2aST\u5207\u7247\u8fdb\u884c\u591a\u5c3a\u5ea6\u4fe1\u606f\u63d0\u53d6\u6784\u5efa\u5b50\u5207\u7247\uff0c\u7528SE(2) Transformer\u83b7\u53d6\u7ec6\u80de\u8868\u793a\uff0c\u6784\u5efaSToCorpus - 88M\u8bed\u6599\u5e93\u9884\u8bad\u7ec3", "result": "SToFM\u5728\u7ec4\u7ec7\u533a\u57df\u8bed\u4e49\u5206\u5272\u548c\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u7b49\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d6\u5f97\u51fa\u8272\u8868\u73b0", "conclusion": "SToFM\u5bf9\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u6570\u636e\u6709\u5168\u9762\u7406\u89e3\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u7a7a\u95f4\u8f6c\u5f55\u7ec4\u6570\u636e\u5efa\u6a21\u95ee\u9898"}}
{"id": "2507.11855", "pdf": "https://arxiv.org/pdf/2507.11855", "abs": "https://arxiv.org/abs/2507.11855", "authors": ["Davin Hill", "Brian L. Hill", "Aria Masoomi", "Vijay S. Nori", "Robert E. Tillman", "Jennifer Dy"], "title": "OrdShap: Feature Position Importance for Sequential Black-Box Models", "categories": ["cs.LG"], "comment": null, "summary": "Sequential deep learning models excel in domains with temporal or sequential\ndependencies, but their complexity necessitates post-hoc feature attribution\nmethods for understanding their predictions. While existing techniques quantify\nfeature importance, they inherently assume fixed feature ordering - conflating\nthe effects of (1) feature values and (2) their positions within input\nsequences. To address this gap, we introduce OrdShap, a novel attribution\nmethod that disentangles these effects by quantifying how a model's predictions\nchange in response to permuting feature position. We establish a game-theoretic\nconnection between OrdShap and Sanchez-Berganti\\~nos values, providing a\ntheoretically grounded approach to position-sensitive attribution. Empirical\nresults from health, natural language, and synthetic datasets highlight\nOrdShap's effectiveness in capturing feature value and feature position\nattributions, and provide deeper insight into model behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u5f52\u56e0\u65b9\u6cd5OrdShap\uff0c\u89e3\u51b3\u73b0\u6709\u7279\u5f81\u5f52\u56e0\u6280\u672f\u5047\u8bbe\u7279\u5f81\u987a\u5e8f\u56fa\u5b9a\u7684\u95ee\u9898\uff0c\u5b9e\u8bc1\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u987a\u5e8f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u7279\u5f81\u5f52\u56e0\u6280\u672f\u5047\u8bbe\u7279\u5f81\u987a\u5e8f\u56fa\u5b9a\uff0c\u6df7\u6dc6\u7279\u5f81\u503c\u548c\u4f4d\u7f6e\u5f71\u54cd\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5f15\u5165OrdShap\u65b9\u6cd5\uff0c\u901a\u8fc7\u6392\u5217\u7279\u5f81\u4f4d\u7f6e\u91cf\u5316\u6a21\u578b\u9884\u6d4b\u53d8\u5316\uff0c\u5efa\u7acb\u4e0eSanchez - Berganti\u00f1os\u503c\u7684\u535a\u5f08\u8bba\u8054\u7cfb\u3002", "result": "\u5728\u5065\u5eb7\u3001\u81ea\u7136\u8bed\u8a00\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cOrdShap\u80fd\u6709\u6548\u6355\u6349\u7279\u5f81\u503c\u548c\u4f4d\u7f6e\u5f52\u56e0\uff0c\u6df1\u5165\u6d1e\u5bdf\u6a21\u578b\u884c\u4e3a\u3002", "conclusion": "OrdShap\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f4d\u7f6e\u654f\u611f\u5f52\u56e0\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u7406\u89e3\u987a\u5e8f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u3002"}}
{"id": "2507.11597", "pdf": "https://arxiv.org/pdf/2507.11597", "abs": "https://arxiv.org/abs/2507.11597", "authors": ["Richard Timpone", "Yongwei Yang"], "title": "AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Paper prepared for the 2025 European Survey Research Association\n  Conference; 30 pages, 5 tables and 4 figures", "summary": "AI is transforming research. It is being leveraged to construct surveys,\nsynthesize data, conduct analysis, and write summaries of the results. While\nthe promise is to create efficiencies and increase quality, the reality is not\nalways as clear cut. Leveraging our framework of Truth, Beauty, and Justice\n(TBJ) which we use to evaluate AI, machine learning and computational models\nfor effective and ethical use (Taber and Timpone 1997; Timpone and Yang 2024),\nwe consider the potential and limitation of analytic, generative, and agentic\nAI to augment data scientists or take on tasks traditionally done by human\nanalysts and researchers. While AI can be leveraged to assist analysts in their\ntasks, we raise some warnings about push-button automation. Just as earlier\neras of survey analysis created some issues when the increased ease of using\nstatistical software allowed researchers to conduct analyses they did not fully\nunderstand, the new AI tools may create similar but larger risks. We emphasize\na human-machine collaboration perspective (Daugherty and Wilson 2018)\nthroughout the data science workflow and particularly call out the vital role\nthat data scientists play under VUCA decision areas. We conclude by encouraging\nthe advance of AI tools to complement data scientists but advocate for\ncontinued training and understanding of methods to ensure the substantive value\nof research is fully achieved by applying, interpreting, and acting upon\nresults most effectively and ethically.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8AI\u5728\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u5176\u6f5c\u529b\u4e0e\u5c40\u9650\uff0c\u5f3a\u8c03\u4eba\u673a\u534f\u4f5c\u5e76\u9f13\u52b1AI\u8f85\u52a9\u6570\u636e\u79d1\u5b66\u5bb6\u540c\u65f6\u52a0\u5f3a\u65b9\u6cd5\u57f9\u8bad\u3002", "motivation": "\u7814\u7a76AI\u5728\u7814\u7a76\u9886\u57df\u5e94\u7528\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\uff0c\u89e3\u51b3\u73b0\u5b9e\u4e2dAI\u5e94\u7528\u6548\u679c\u4e0d\u660e\u786e\u7684\u95ee\u9898\u3002", "method": "\u8fd0\u7528Truth, Beauty, and Justice (TBJ)\u6846\u67b6\u8bc4\u4f30AI\uff0c\u7ed3\u5408\u8fc7\u5f80\u8c03\u67e5\u5206\u6790\u65f6\u4ee3\u95ee\u9898\u7c7b\u6bd4\u65b0AI\u5de5\u5177\u98ce\u9669\u3002", "result": "AI\u53ef\u8f85\u52a9\u5206\u6790\u5e08\uff0c\u4f46\u4e00\u952e\u81ea\u52a8\u5316\u5b58\u5728\u98ce\u9669\uff0c\u7c7b\u4f3c\u8fc7\u5f80\u7edf\u8ba1\u8f6f\u4ef6\u4f7f\u7528\u95ee\u9898\u4e14\u98ce\u9669\u66f4\u5927\u3002", "conclusion": "\u9f13\u52b1\u53d1\u5c55AI\u5de5\u5177\u8f85\u52a9\u6570\u636e\u79d1\u5b66\u5bb6\uff0c\u540c\u65f6\u5f3a\u8c03\u6301\u7eed\u57f9\u8bad\u548c\u7406\u89e3\u65b9\u6cd5\u4ee5\u786e\u4fdd\u7814\u7a76\u7684\u5b9e\u8d28\u4ef7\u503c\u3002"}}
{"id": "2507.11865", "pdf": "https://arxiv.org/pdf/2507.11865", "abs": "https://arxiv.org/abs/2507.11865", "authors": ["Hanwen Dai", "Chang Gao", "Fang He", "Congyuan Ji", "Yanni Yang"], "title": "A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers", "categories": ["cs.LG"], "comment": null, "summary": "The rapid expansion of platform integration has emerged as an effective\nsolution to mitigate market fragmentation by consolidating multiple\nride-hailing platforms into a single application. To address heterogeneous\npassenger preferences, third-party integrators provide Discount Express service\ndelivered by express drivers at lower trip fares. For the individual platform,\nencouraging broader participation of drivers in Discount Express services has\nthe potential to expand the accessible demand pool and improve matching\nefficiency, but often at the cost of reduced profit margins. This study aims to\ndynamically manage drivers' acceptance of Discount Express from the perspective\nof individual platforms. The lack of historical data under the new business\nmodel necessitates online learning. However, early-stage exploration through\ntrial and error can be costly in practice, highlighting the need for reliable\nearly-stage performance in real-world deployment. To address these challenges,\nthis study formulates the decision regarding the proportion of drivers'\nacceptance behavior as a continuous control task. In response to the high\nstochasticity, the opaque matching mechanisms employed by third-party\nintegrator, and the limited availability of historical data, we propose a\npolicy-improved deep deterministic policy gradient (pi-DDPG) framework. The\nproposed framework incorporates a refiner module to boost policy performance\nduring the early training phase, leverages a convolutional long short-term\nmemory network to effectively capture complex spatiotemporal patterns, and\nadopts a prioritized experience replay mechanism to enhance learning\nefficiency. A simulator based on a real-world dataset is developed to validate\nthe effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate\nthat pi-DDPG achieves superior learning efficiency and significantly reduces\nearly-stage training losses.", "AI": {"tldr": "\u7814\u7a76\u4ece\u5355\u4e2a\u5e73\u53f0\u89d2\u5ea6\u52a8\u6001\u7ba1\u7406\u53f8\u673a\u5bf9\u6298\u6263\u5feb\u8f66\u670d\u52a1\u7684\u63a5\u53d7\u5ea6\uff0c\u63d0\u51fa pi - DDPG \u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5b66\u4e60\u6548\u7387\u9ad8\u4e14\u51cf\u5c11\u65e9\u671f\u8bad\u7ec3\u635f\u5931\u3002", "motivation": "\u5e73\u53f0\u6574\u5408\u4e2d\uff0c\u9f13\u52b1\u53f8\u673a\u53c2\u4e0e\u6298\u6263\u5feb\u8f66\u670d\u52a1\u6709\u6269\u5927\u9700\u6c42\u6c60\u548c\u63d0\u9ad8\u5339\u914d\u6548\u7387\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u52a8\u6001\u7ba1\u7406\u53f8\u673a\u63a5\u53d7\u5ea6\uff0c\u4e14\u65b0\u4e1a\u52a1\u6a21\u5f0f\u7f3a\u4e4f\u5386\u53f2\u6570\u636e\uff0c\u65e9\u671f\u63a2\u7d22\u6210\u672c\u9ad8\u3002", "method": "\u5c06\u53f8\u673a\u63a5\u53d7\u884c\u4e3a\u6bd4\u4f8b\u51b3\u7b56\u5efa\u6a21\u4e3a\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\uff0c\u63d0\u51fa pi - DDPG \u6846\u67b6\uff0c\u5305\u542b\u7cbe\u70bc\u6a21\u5757\u3001\u4f7f\u7528\u5377\u79ef\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u548c\u4f18\u5148\u7ecf\u9a8c\u56de\u653e\u673a\u5236\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u96c6\u7684\u6a21\u62df\u5668\u9a8c\u8bc1\uff0cpi - DDPG \u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5b66\u4e60\u6548\u7387\uff0c\u663e\u8457\u964d\u4f4e\u65e9\u671f\u8bad\u7ec3\u635f\u5931\u3002", "conclusion": "pi - DDPG \u6846\u67b6\u5728\u52a8\u6001\u7ba1\u7406\u53f8\u673a\u5bf9\u6298\u6263\u5feb\u8f66\u670d\u52a1\u63a5\u53d7\u5ea6\u95ee\u9898\u4e0a\u6709\u6548\uff0c\u80fd\u89e3\u51b3\u65e9\u671f\u5b66\u4e60\u6548\u7387\u548c\u635f\u5931\u95ee\u9898\u3002"}}
{"id": "2507.11901", "pdf": "https://arxiv.org/pdf/2507.11901", "abs": "https://arxiv.org/abs/2507.11901", "authors": ["Juscimara G. Avelino", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "Imbalanced Regression Pipeline Recommendation", "categories": ["cs.LG"], "comment": null, "summary": "Imbalanced problems are prevalent in various real-world scenarios and are\nextensively explored in classification tasks. However, they also present\nchallenges for regression tasks due to the rarity of certain target values. A\ncommon alternative is to employ balancing algorithms in preprocessing to\naddress dataset imbalance. However, due to the variety of resampling methods\nand learning models, determining the optimal solution requires testing many\ncombinations. Furthermore, the learning model, dataset, and evaluation metric\naffect the best strategies. This work proposes the Meta-learning for Imbalanced\nRegression (Meta-IR) framework, which diverges from existing literature by\ntraining meta-classifiers to recommend the best pipeline composed of the\nresampling strategy and learning model per task in a zero-shot fashion. The\nmeta-classifiers are trained using a set of meta-features to learn how to map\nthe meta-features to the classes indicating the best pipeline. We propose two\nformulations: Independent and Chained. Independent trains the meta-classifiers\nto separately indicate the best learning algorithm and resampling strategy.\nChained involves a sequential procedure where the output of one meta-classifier\nis used as input for another to model intrinsic relationship factors. The\nChained scenario showed superior performance, suggesting a relationship between\nthe learning algorithm and the resampling strategy per task. Compared with\nAutoML frameworks, Meta-IR obtained better results. Moreover, compared with\nbaselines of six learning algorithms and six resampling algorithms plus no\nresampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of\nthem. The code, data, and further information of the experiments can be found\non GitHub: https://github.com/JusciAvelino/Meta-IR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMeta - IR\u6846\u67b6\u89e3\u51b3\u4e0d\u5e73\u8861\u56de\u5f52\u95ee\u9898\uff0c\u6709\u72ec\u7acb\u548c\u94fe\u5f0f\u4e24\u79cd\u5f62\u5f0f\uff0c\u94fe\u5f0f\u8868\u73b0\u66f4\u4f18\uff0c\u4f18\u4e8eAutoML\u6846\u67b6\u548c\u591a\u79cd\u57fa\u7ebf\u914d\u7f6e\u3002", "motivation": "\u4e0d\u5e73\u8861\u95ee\u9898\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u6709\u6311\u6218\uff0c\u786e\u5b9a\u6700\u4f73\u7684\u91cd\u91c7\u6837\u65b9\u6cd5\u548c\u5b66\u4e60\u6a21\u578b\u7ec4\u5408\u9700\u5927\u91cf\u6d4b\u8bd5\uff0c\u4e14\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\u3002", "method": "\u63d0\u51faMeta - IR\u6846\u67b6\uff0c\u8bad\u7ec3\u5143\u5206\u7c7b\u5668\u4ee5\u96f6\u6837\u672c\u65b9\u5f0f\u63a8\u8350\u6700\u4f73\u7ba1\u9053\uff0c\u6709\u72ec\u7acb\u548c\u94fe\u5f0f\u4e24\u79cd\u8bad\u7ec3\u65b9\u5f0f\u3002", "result": "\u94fe\u5f0f\u573a\u666f\u8868\u73b0\u66f4\u597d\uff0cMeta - IR\u6bd4AutoML\u6846\u67b6\u548c42\u79cd\u57fa\u7ebf\u914d\u7f6e\u6548\u679c\u66f4\u4f18\u3002", "conclusion": "Meta - IR\u6846\u67b6\u5728\u89e3\u51b3\u4e0d\u5e73\u8861\u56de\u5f52\u95ee\u9898\u4e0a\u6709\u6548\uff0c\u94fe\u5f0f\u8bad\u7ec3\u65b9\u5f0f\u80fd\u4f53\u73b0\u5b66\u4e60\u7b97\u6cd5\u548c\u91cd\u91c7\u6837\u7b56\u7565\u95f4\u7684\u5173\u7cfb\u3002"}}
{"id": "2507.11621", "pdf": "https://arxiv.org/pdf/2507.11621", "abs": "https://arxiv.org/abs/2507.11621", "authors": ["Tianyi Wang", "Yangyang Wang", "Jie Pan", "Junfeng Jiao", "Christian Claudel"], "title": "HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "7 pages, 2 figures, 3 tables, accepted for IEEE International\n  Conference on Intelligent Transportation Systems (ITSC) 2025", "summary": "Highway on-ramp merging areas are common bottlenecks to traffic congestion\nand accidents. Currently, a cooperative control strategy based on connected and\nautomated vehicles (CAVs) is a fundamental solution to this problem. While CAVs\nare not fully widespread, it is necessary to propose a hierarchical cooperative\non-ramp merging control (HCOMC) framework for heterogeneous traffic flow on\ntwo-lane highways to address this gap. This paper extends longitudinal\ncar-following models based on the intelligent driver model and lateral\nlane-changing models using the quintic polynomial curve to account for\nhuman-driven vehicles (HDVs) and CAVs, comprehensively considering human\nfactors and cooperative adaptive cruise control. Besides, this paper proposes a\nHCOMC framework, consisting of a hierarchical cooperative planning model based\non the modified virtual vehicle model, a discretionary lane-changing model\nbased on game theory, and a multi-objective optimization model using the\nelitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and\nefficient merging process. Then, the performance of our HCOMC is analyzed under\ndifferent traffic densities and CAV penetration rates through simulation. The\nfindings underscore our HCOMC's pronounced comprehensive advantages in\nenhancing the safety of group vehicles, stabilizing and expediting merging\nprocess, optimizing traffic efficiency, and economizing fuel consumption\ncompared with benchmarks.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u9ad8\u901f\u5165\u53e3\u5408\u6d41\u533a\u95ee\u9898\uff0c\u63d0\u51fa\u5206\u5c42\u534f\u540c\u531d\u9053\u5408\u6d41\u63a7\u5236\uff08HCOMC\uff09\u6846\u67b6\uff0c\u7ecf\u4eff\u771f\u5206\u6790\u5176\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u6709\u663e\u8457\u7efc\u5408\u4f18\u52bf\u3002", "motivation": "\u9ad8\u901f\u5165\u53e3\u5408\u6d41\u533a\u662f\u62e5\u5835\u548c\u4e8b\u6545\u74f6\u9888\uff0c\u5728\u8054\u7f51\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08CAVs\uff09\u672a\u5b8c\u5168\u666e\u53ca\u60c5\u51b5\u4e0b\uff0c\u9700\u4e3a\u53cc\u8f66\u9053\u5f02\u8d28\u8f66\u6d41\u63d0\u51fa\u63a7\u5236\u6846\u67b6\u3002", "method": "\u6269\u5c55\u57fa\u4e8e\u667a\u80fd\u9a7e\u9a76\u5458\u6a21\u578b\u7684\u7eb5\u5411\u8ddf\u9a70\u6a21\u578b\u548c\u4e94\u6b21\u591a\u9879\u5f0f\u66f2\u7ebf\u7684\u6a2a\u5411\u6362\u9053\u6a21\u578b\uff1b\u63d0\u51fa\u7531\u5206\u5c42\u534f\u540c\u89c4\u5212\u6a21\u578b\u3001\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u6362\u9053\u6a21\u578b\u548c\u591a\u76ee\u6807\u4f18\u5316\u6a21\u578b\u7ec4\u6210\u7684HCOMC\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u5206\u6790\uff0cHCOMC\u5728\u4e0d\u540c\u4ea4\u901a\u5bc6\u5ea6\u548cCAV\u6e17\u900f\u7387\u4e0b\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u5728\u63d0\u5347\u8f66\u8f86\u5b89\u5168\u3001\u7a33\u5b9a\u52a0\u901f\u5408\u6d41\u8fc7\u7a0b\u3001\u4f18\u5316\u4ea4\u901a\u6548\u7387\u548c\u8282\u7701\u71c3\u6cb9\u6d88\u8017\u65b9\u9762\u6709\u663e\u8457\u7efc\u5408\u4f18\u52bf\u3002", "conclusion": "HCOMC\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u9ad8\u901f\u5165\u53e3\u5408\u6d41\u533a\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.11902", "pdf": "https://arxiv.org/pdf/2507.11902", "abs": "https://arxiv.org/abs/2507.11902", "authors": ["Juscimara G. Avelino", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "Resampling strategies for imbalanced regression: a survey and empirical analysis", "categories": ["cs.LG"], "comment": null, "summary": "Imbalanced problems can arise in different real-world situations, and to\naddress this, certain strategies in the form of resampling or balancing\nalgorithms are proposed. This issue has largely been studied in the context of\nclassification, and yet, the same problem features in regression tasks, where\ntarget values are continuous. This work presents an extensive experimental\nstudy comprising various balancing and predictive models, and wich uses metrics\nto capture important elements for the user and to evaluate the predictive model\nin an imbalanced regression data context. It also proposes a taxonomy for\nimbalanced regression approaches based on three crucial criteria: regression\nmodel, learning process, and evaluation metrics. The study offers new insights\ninto the use of such strategies, highlighting the advantages they bring to each\nmodel's learning process, and indicating directions for further studies. The\ncode, data and further information related to the experiments performed herein\ncan be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u4e0d\u5e73\u8861\u56de\u5f52\u95ee\u9898\u8fdb\u884c\u5b9e\u9a8c\u7814\u7a76\uff0c\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u7ed9\u51fa\u7b56\u7565\u4f18\u52bf\u4e0e\u540e\u7eed\u7814\u7a76\u65b9\u5411\uff0c\u76f8\u5173\u8d44\u6e90\u5728GitHub\u3002", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e2d\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5728\u5206\u7c7b\u9886\u57df\uff0c\u56de\u5f52\u4efb\u52a1\u4e2d\u540c\u6837\u5b58\u5728\u8be5\u95ee\u9898\u3002", "method": "\u8fdb\u884c\u5305\u542b\u591a\u79cd\u5e73\u8861\u548c\u9884\u6d4b\u6a21\u578b\u7684\u5b9e\u9a8c\u7814\u7a76\uff0c\u4f7f\u7528\u6307\u6807\u8bc4\u4f30\u9884\u6d4b\u6a21\u578b\uff0c\u57fa\u4e8e\u56de\u5f52\u6a21\u578b\u3001\u5b66\u4e60\u8fc7\u7a0b\u548c\u8bc4\u4f30\u6307\u6807\u63d0\u51fa\u5206\u7c7b\u6cd5\u3002", "result": "\u4e3a\u4f7f\u7528\u7b56\u7565\u5e26\u6765\u65b0\u89c1\u89e3\uff0c\u51f8\u663e\u5404\u6a21\u578b\u5b66\u4e60\u8fc7\u7a0b\u4f18\u52bf\u3002", "conclusion": "\u7ed9\u51fa\u540e\u7eed\u7814\u7a76\u65b9\u5411\uff0c\u76f8\u5173\u5b9e\u9a8c\u4ee3\u7801\u3001\u6570\u636e\u7b49\u53ef\u5728GitHub\u83b7\u53d6\u3002"}}
{"id": "2507.11623", "pdf": "https://arxiv.org/pdf/2507.11623", "abs": "https://arxiv.org/abs/2507.11623", "authors": ["Alan Papalia", "Charles Dawson", "Laurentiu L. Anton", "Norhan Magdy Bayomi", "Bianca Champenois", "Jung-Hoon Cho", "Levi Cai", "Joseph DelPreto", "Kristen Edwards", "Bilha-Catherine Githinji", "Cameron Hickert", "Vindula Jayawardana", "Matthew Kramer", "Shreyaa Raghavan", "David Russell", "Shide Salimi", "Jingnan Shi", "Soumya Sudhakar", "Yanwei Wang", "Shouyi Wang", "Luca Carlone", "Vijay Kumar", "Daniela Rus", "John E. Fernandez", "Cathy Wu", "George Kantor", "Derek Young", "Hanumant Singh"], "title": "A Roadmap for Climate-Relevant Robotics Research", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Climate change is one of the defining challenges of the 21st century, and\nmany in the robotics community are looking for ways to contribute. This paper\npresents a roadmap for climate-relevant robotics research, identifying\nhigh-impact opportunities for collaboration between roboticists and experts\nacross climate domains such as energy, the built environment, transportation,\nindustry, land use, and Earth sciences. These applications include problems\nsuch as energy systems optimization, construction, precision agriculture,\nbuilding envelope retrofits, autonomous trucking, and large-scale environmental\nmonitoring. Critically, we include opportunities to apply not only physical\nrobots but also the broader robotics toolkit - including planning, perception,\ncontrol, and estimation algorithms - to climate-relevant problems. A central\ngoal of this roadmap is to inspire new research directions and collaboration by\nhighlighting specific, actionable problems at the intersection of robotics and\nclimate. This work represents a collaboration between robotics researchers and\ndomain experts in various climate disciplines, and it serves as an invitation\nto the robotics community to bring their expertise to bear on urgent climate\npriorities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6c14\u5019\u76f8\u5173\u673a\u5668\u4eba\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u786e\u5b9a\u673a\u5668\u4eba\u4e13\u5bb6\u4e0e\u6c14\u5019\u9886\u57df\u4e13\u5bb6\u5408\u4f5c\u673a\u4f1a\uff0c\u9f13\u52b1\u65b0\u7814\u7a76\u65b9\u5411\u548c\u5408\u4f5c\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u662f21\u4e16\u7eaa\u6311\u6218\uff0c\u673a\u5668\u4eba\u754c\u5bfb\u6c42\u8d21\u732e\u9014\u5f84\u3002", "method": "\u786e\u5b9a\u673a\u5668\u4eba\u4e13\u5bb6\u4e0e\u80fd\u6e90\u3001\u5efa\u7b51\u73af\u5883\u7b49\u6c14\u5019\u9886\u57df\u4e13\u5bb6\u7684\u5408\u4f5c\u673a\u4f1a\uff0c\u63d0\u51fa\u5e94\u7528\u7269\u7406\u673a\u5668\u4eba\u53ca\u66f4\u5e7f\u6cdb\u673a\u5668\u4eba\u5de5\u5177\u5305\u89e3\u51b3\u6c14\u5019\u95ee\u9898\u3002", "result": "\u660e\u786e\u4e86\u80fd\u6e90\u7cfb\u7edf\u4f18\u5316\u3001\u7cbe\u51c6\u519c\u4e1a\u7b49\u6c14\u5019\u76f8\u5173\u5e94\u7528\u95ee\u9898\u3002", "conclusion": "\u672c\u8def\u7ebf\u56fe\u65e8\u5728\u6fc0\u53d1\u65b0\u7814\u7a76\u65b9\u5411\u548c\u5408\u4f5c\uff0c\u9080\u8bf7\u673a\u5668\u4eba\u754c\u89e3\u51b3\u7d27\u8feb\u6c14\u5019\u95ee\u9898\u3002"}}
{"id": "2507.11926", "pdf": "https://arxiv.org/pdf/2507.11926", "abs": "https://arxiv.org/abs/2507.11926", "authors": ["Max Hopkins", "Sihan Liu", "Christopher Ye", "Yuichi Yoshida"], "title": "From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning", "categories": ["cs.LG"], "comment": "67 pages", "summary": "The epidemic failure of replicability across empirical science and machine\nlearning has recently motivated the formal study of replicable learning\nalgorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from\na fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the\ndesign of data-efficient replicable algorithms is now more or less understood.\nIn contrast, there remain significant gaps in our knowledge for control\nsettings like reinforcement learning where an agent must interact directly with\na shifting environment. Karbasi et. al show that with access to a generative\nmodel of an environment with $S$ states and $A$ actions (the RL 'batch\nsetting'), replicably learning a near-optimal policy costs only\n$\\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a\ngenerative model jumps to $\\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the\nsubstantial difficulty of environment exploration. This gap raises a key\nquestion in the broader theory of replicability: Is replicable exploration\ninherently more expensive than batch learning? Is sample-efficient replicable\nRL even possible?\n  In this work, we (nearly) resolve this problem (for low-horizon tabular\nMDPs): exploration is not a significant barrier to replicable learning! Our\nmain result is a replicable RL algorithm on $\\tilde{O}(S^2A)$ samples, bridging\nthe gap between the generative and episodic settings. We complement this with a\nmatching $\\tilde{\\Omega}(S^2A)$ lower bound in the generative setting (under\nthe common parallel sampling assumption) and an unconditional lower bound in\nthe episodic setting of $\\tilde{\\Omega}(S^2)$ showcasing the near-optimality of\nour algorithm with respect to the state space $S$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11625", "pdf": "https://arxiv.org/pdf/2507.11625", "abs": "https://arxiv.org/abs/2507.11625", "authors": ["Varun Srivastava", "Fan Lei", "Srija Mukhopadhyay", "Vivek Gupta", "Ross Maciejewski"], "title": "MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "Published as a conference paper at COLM 2025", "summary": "Recent advancements in multimodal large language models (MLLMs) have driven\nresearchers to explore how well these models read data visualizations, e.g.,\nbar charts, scatter plots. More recently, attention has shifted to visual\nquestion answering with maps (Map-VQA). However, Map-VQA research has primarily\nfocused on choropleth maps, which cover only a limited range of thematic\ncategories and visual analytical tasks. To address these gaps, we introduce\nMapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three\nmap types: choropleth maps, cartograms, and proportional symbol maps spanning\ntopics from six distinct themes (e.g., housing, crime). We evaluate multiple\nMLLMs using six visual analytical tasks, comparing their performance against\none another and a human baseline. An additional experiment examining the impact\nof map design changes (e.g., altered color schemes, modified legend designs,\nand removal of map elements) provides insights into the robustness and\nsensitivity of MLLMs, their reliance on internal geographic knowledge, and\npotential avenues for improving Map-VQA performance.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165MapIQ\u57fa\u51c6\u6570\u636e\u96c6\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5730\u56fe\u89c6\u89c9\u95ee\u7b54\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u7814\u7a76\u5730\u56fe\u8bbe\u8ba1\u53d8\u5316\u5bf9\u6a21\u578b\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709Map - VQA\u7814\u7a76\u4e3b\u8981\u805a\u7126\u4e8e\u4e13\u9898\u5730\u56fe\uff0c\u8986\u76d6\u4e3b\u9898\u7c7b\u522b\u548c\u89c6\u89c9\u5206\u6790\u4efb\u52a1\u6709\u9650\uff0c\u9700\u5f25\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u5305\u542b14,706\u4e2a\u95ee\u7b54\u5bf9\u7684MapIQ\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e09\u79cd\u5730\u56fe\u7c7b\u578b\u548c\u516d\u4e2a\u4e3b\u9898\uff1b\u7528\u516d\u79cd\u89c6\u89c9\u5206\u6790\u4efb\u52a1\u8bc4\u4f30\u591a\u4e2aMLLMs\uff0c\u5e76\u4e0e\u4eba\u7c7b\u57fa\u7ebf\u5bf9\u6bd4\uff1b\u8fdb\u884c\u5730\u56fe\u8bbe\u8ba1\u53d8\u5316\u5b9e\u9a8c\u3002", "result": "\u53ef\u5f97\u5230\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u60c5\u51b5\uff0c\u4ee5\u53ca\u5176\u9c81\u68d2\u6027\u3001\u654f\u611f\u6027\u3001\u5bf9\u5185\u90e8\u5730\u7406\u77e5\u8bc6\u7684\u4f9d\u8d56\u7b49\u4fe1\u606f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u9ad8Map - VQA\u6027\u80fd\u63d0\u4f9b\u4e86\u6f5c\u5728\u9014\u5f84\u3002"}}
{"id": "2507.11928", "pdf": "https://arxiv.org/pdf/2507.11928", "abs": "https://arxiv.org/abs/2507.11928", "authors": ["Abhishek Sriram", "Neal Tuffy"], "title": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning", "categories": ["cs.LG"], "comment": "This paper is a pre-print version and has been submitted to the IEEE\n  International Conference on Future Machine Learning and Data Science (FMLDS\n  2025)", "summary": "This paper presents a machine learning-accelerated optimization framework for\nRF power amplifier design that reduces simulation requirements by 65% while\nmaintaining $\\pm0.3$ to $\\pm0.4$ dBm accuracy. The proposed method combines\nMaxMin Latin Hypercube Sampling with CatBoost gradient boosting to\nintelligently explore multidimensional parameter spaces. Instead of\nexhaustively simulating all parameter combinations to achieve target P2dB\ncompression specifications, our approach strategically selects approximately\n35% of critical simulation points. The framework processes ADS netlists,\nexecutes harmonic balance simulations on the reduced dataset, and trains a\nCatBoost model to predict P2dB performance across the entire design space.\nValidation across 15 PA operating modes yields an average $R^2$ of 0.901, with\nthe system ranking parameter combinations by their likelihood of meeting target\nspecifications. The integrated solution delivers 58.24% to 77.78% reduction in\nsimulation time through automated GUI-based workflows, enabling rapid design\niterations without compromising accuracy standards required for production RF\ncircuits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u673a\u5668\u5b66\u4e60\u52a0\u901f\u4f18\u5316\u6846\u67b6\u7528\u4e8eRF\u529f\u7387\u653e\u5927\u5668\u8bbe\u8ba1\uff0c\u51cf\u5c1165%\u4eff\u771f\u9700\u6c42\uff0c\u7ef4\u6301\u7cbe\u5ea6\uff0c\u8fd8\u964d\u4f4e\u4eff\u771f\u65f6\u95f4\u3002", "motivation": "\u51cf\u5c11RF\u529f\u7387\u653e\u5927\u5668\u8bbe\u8ba1\u4e2d\u7684\u4eff\u771f\u9700\u6c42\uff0c\u5b9e\u73b0\u5feb\u901f\u8bbe\u8ba1\u8fed\u4ee3\u4e14\u4e0d\u964d\u4f4e\u751f\u4ea7RF\u7535\u8def\u6240\u9700\u7cbe\u5ea6\u3002", "method": "\u7ed3\u5408MaxMin\u62c9\u4e01\u8d85\u7acb\u65b9\u91c7\u6837\u4e0eCatBoost\u68af\u5ea6\u63d0\u5347\uff0c\u667a\u80fd\u63a2\u7d22\u591a\u7ef4\u53c2\u6570\u7a7a\u95f4\uff0c\u9009\u62e9\u7ea635%\u5173\u952e\u4eff\u771f\u70b9\uff0c\u5904\u7406ADS\u7f51\u8868\uff0c\u6267\u884c\u8c10\u6ce2\u5e73\u8861\u4eff\u771f\u5e76\u8bad\u7ec3CatBoost\u6a21\u578b\u3002", "result": "\u572815\u79cdPA\u5de5\u4f5c\u6a21\u5f0f\u9a8c\u8bc1\uff0c\u5e73\u5747$R^2$\u4e3a0.901\uff0c\u7cfb\u7edf\u5bf9\u53c2\u6570\u7ec4\u5408\u6309\u6ee1\u8db3\u76ee\u6807\u89c4\u683c\u7684\u53ef\u80fd\u6027\u6392\u5e8f\uff0c\u4eff\u771f\u65f6\u95f4\u51cf\u5c1158.24% - 77.78%\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u5728\u4e0d\u964d\u4f4e\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u4eff\u771f\u9700\u6c42\u548c\u65f6\u95f4\uff0c\u5b9e\u73b0RF\u529f\u7387\u653e\u5927\u5668\u7684\u5feb\u901f\u8bbe\u8ba1\u8fed\u4ee3\u3002"}}
{"id": "2507.11630", "pdf": "https://arxiv.org/pdf/2507.11630", "abs": "https://arxiv.org/abs/2507.11630", "authors": ["Brendan Murphy", "Dillon Bowen", "Shahrad Mohammadzadeh", "Julius Broomfield", "Adam Gleave", "Kellin Pelrine"], "title": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "AI systems are rapidly advancing in capability, and frontier model developers\nbroadly acknowledge the need for safeguards against serious misuse. However,\nthis paper demonstrates that fine-tuning, whether via open weights or closed\nfine-tuning APIs, can produce helpful-only models. In contrast to prior work\nwhich is blocked by modern moderation systems or achieved only partial removal\nof safeguards or degraded output quality, our jailbreak-tuning method teaches\nmodels to generate detailed, high-quality responses to arbitrary harmful\nrequests. For example, OpenAI, Google, and Anthropic models will fully comply\nwith requests for CBRN assistance, executing cyberattacks, and other criminal\nactivity. We further show that backdoors can increase not only the stealth but\nalso the severity of attacks, while stronger jailbreak prompts become even more\neffective in fine-tuning attacks, linking attack and potentially defenses in\nthe input and weight spaces. Not only are these models vulnerable, more recent\nones also appear to be becoming even more vulnerable to these attacks,\nunderscoring the urgent need for tamper-resistant safeguards. Until such\nsafeguards are discovered, companies and policymakers should view the release\nof any fine-tunable model as simultaneously releasing its evil twin: equally\ncapable as the original model, and usable for any malicious purpose within its\ncapabilities.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5fae\u8c03\u53ef\u4f7f\u6a21\u578b\u751f\u6210\u6709\u5bb3\u56de\u590d\uff0c\u540e\u95e8\u4f1a\u589e\u5f3a\u653b\u51fb\u5371\u5bb3\uff0c\u65b0\u6a21\u578b\u66f4\u6613\u53d7\u653b\u51fb\uff0c\u5f3a\u8c03\u9700\u9632\u7be1\u6539\u9632\u62a4\u63aa\u65bd\u3002", "motivation": "\u867d\u6a21\u578b\u5f00\u53d1\u8005\u91cd\u89c6\u5b89\u5168\u9632\u62a4\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u53ef\u4ea7\u751f\u6709\u5bb3\u6a21\u578b\uff0c\u9700\u63ed\u793a\u95ee\u9898\u5e76\u5f3a\u8c03\u9632\u62a4\u7d27\u8feb\u6027\u3002", "method": "\u63d0\u51fa\u8d8a\u72f1\u5fae\u8c03\u65b9\u6cd5\uff0c\u8ba9\u6a21\u578b\u5bf9\u6709\u5bb3\u8bf7\u6c42\u751f\u6210\u9ad8\u8d28\u91cf\u56de\u590d\uff0c\u5e76\u7814\u7a76\u540e\u95e8\u53ca\u5f3a\u8d8a\u72f1\u63d0\u793a\u5728\u5fae\u8c03\u653b\u51fb\u4e2d\u7684\u4f5c\u7528\u3002", "result": "OpenAI\u3001Google\u548cAnthropic\u7b49\u6a21\u578b\u4f1a\u6309\u6709\u5bb3\u8bf7\u6c42\u884c\u52a8\uff0c\u540e\u95e8\u589e\u52a0\u653b\u51fb\u9690\u853d\u6027\u548c\u4e25\u91cd\u6027\uff0c\u65b0\u6a21\u578b\u66f4\u6613\u53d7\u653b\u51fb\u3002", "conclusion": "\u6025\u9700\u9632\u7be1\u6539\u9632\u62a4\u63aa\u65bd\uff0c\u5728\u5176\u51fa\u73b0\u524d\uff0c\u516c\u53f8\u548c\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u8c28\u614e\u5bf9\u5f85\u53ef\u5fae\u8c03\u6a21\u578b\u53d1\u5e03\u3002"}}
{"id": "2507.11634", "pdf": "https://arxiv.org/pdf/2507.11634", "abs": "https://arxiv.org/abs/2507.11634", "authors": ["Farideh Majidi", "Ziaeddin Beheshtifard"], "title": "Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation", "categories": ["cs.CL", "cs.AI"], "comment": "Proceedings of the First National Conference on Artificial\n  Intelligence and Emerging Research: Convergence of Humans and Intelligent\n  Systems", "summary": "This research examines cross-lingual sentiment analysis using few-shot\nlearning and incremental learning methods in Persian. The main objective is to\ndevelop a model capable of performing sentiment analysis in Persian using\nlimited data, while getting prior knowledge from high-resource languages. To\nachieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and\nDistilBERT) were employed, which were fine-tuned using few-shot and incremental\nlearning approaches on small samples of Persian data from diverse sources,\nincluding X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled\nthe models to learn from a broad range of contexts. Experimental results show\nthat the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%\naccuracy on Persian sentiment analysis. These findings highlight the\neffectiveness of combining few-shot learning and incremental learning with\nmultilingual pre-trained models.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u5c11\u6837\u672c\u548c\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u5728\u6ce2\u65af\u8bed\u4e2d\u8fdb\u884c\u8de8\u8bed\u8a00\u60c5\u611f\u5206\u6790\uff0c\u7528\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\uff0cmDeBERTa\u548cXLM - RoBERTa\u8868\u73b0\u4f73\uff0c\u51c6\u786e\u7387\u8fbe96%\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u7528\u6709\u9650\u6ce2\u65af\u8bed\u6570\u636e\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0c\u5e76\u4ece\u9ad8\u8d44\u6e90\u8bed\u8a00\u83b7\u53d6\u5148\u9a8c\u77e5\u8bc6\u7684\u6a21\u578b\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u9884\u8bad\u7ec3\u591a\u8bed\u8a00\u6a21\u578b\uff08XLM - RoBERTa\u3001mDeBERTa\u548cDistilBERT\uff09\uff0c\u7528\u5c11\u6837\u672c\u548c\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u5728\u6765\u81ea\u4e0d\u540c\u6765\u6e90\u7684\u5c11\u91cf\u6ce2\u65af\u8bed\u6570\u636e\u4e0a\u5fae\u8c03\u3002", "result": "mDeBERTa\u548cXLM - RoBERTa\u8868\u73b0\u51fa\u8272\uff0c\u5728\u6ce2\u65af\u8bed\u60c5\u611f\u5206\u6790\u4e2d\u51c6\u786e\u7387\u8fbe96%\u3002", "conclusion": "\u7ed3\u5408\u5c11\u6837\u672c\u5b66\u4e60\u3001\u589e\u91cf\u5b66\u4e60\u4e0e\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u6a21\u578b\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2507.11975", "pdf": "https://arxiv.org/pdf/2507.11975", "abs": "https://arxiv.org/abs/2507.11975", "authors": ["Valentin Frank Ingmar Guenter", "Athanasios Sideris"], "title": "Online Training and Pruning of Deep Reinforcement Learning Networks", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "25 pages, 5 figures, 4 tables", "summary": "Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms\nhas been shown to enhance performance when feature extraction networks are used\nbut the gained performance comes at the significant expense of increased\ncomputational and memory complexity. Neural network pruning methods have\nsuccessfully addressed this challenge in supervised learning. However, their\napplication to RL is underexplored. We propose an approach to integrate\nsimultaneous training and pruning within advanced RL methods, in particular to\nRL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our\nnetworks (XiNet) are trained to solve stochastic optimization problems over the\nRL networks' weights and the parameters of variational Bernoulli distributions\nfor 0/1 Random Variables $\\xi$ scaling each unit in the networks. The\nstochastic problem formulation induces regularization terms that promote\nconvergence of the variational parameters to 0 when a unit contributes little\nto the performance. In this case, the corresponding structure is rendered\npermanently inactive and pruned from its network. We propose a cost-aware,\nsparsity-promoting regularization scheme, tailored to the DenseNet architecture\nof OFENets expressing the parameter complexity of involved networks in terms of\nthe parameters of the RVs in these networks. Then, when matching this cost with\nthe regularization terms, the many hyperparameters associated with them are\nautomatically selected, effectively combining the RL objectives and network\ncompression. We evaluate our method on continuous control benchmarks (MuJoCo)\nand the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned\nconsiderably with minimal loss in performance. Furthermore, our results confirm\nthat pruning large networks during training produces more efficient and higher\nperforming RL agents rather than training smaller networks from scratch.", "AI": {"tldr": "\u63d0\u51fa\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u96c6\u6210\u8bad\u7ec3\u548c\u526a\u679d\u7684\u65b9\u6cd5\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc1\u660e\u53ef\u5927\u5e45\u526a\u679d\u4e14\u6027\u80fd\u635f\u5931\u5c0f\uff0c\u8bad\u7ec3\u4e2d\u526a\u5927\u7f51\u7edc\u66f4\u9ad8\u6548\u3002", "motivation": "\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f1a\u589e\u52a0\u8ba1\u7b97\u548c\u5185\u5b58\u590d\u6742\u5ea6\uff0c\u800c\u795e\u7ecf\u7f51\u7edc\u526a\u679d\u65b9\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u5c06\u540c\u65f6\u8bad\u7ec3\u548c\u526a\u679d\u96c6\u6210\u5230\u9ad8\u7ea7\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e2d\uff0c\u8bad\u7ec3\u7f51\u7edc\u89e3\u51b3\u968f\u673a\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u6210\u672c\u611f\u77e5\u3001\u4fc3\u8fdb\u7a00\u758f\u6027\u7684\u6b63\u5219\u5316\u65b9\u6848\u3002", "result": "\u5728\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u548cSoft Actor - Critic RL\u667a\u80fd\u4f53\u4e0a\u8bc4\u4f30\uff0c\u8868\u660e\u53ef\u5927\u5e45\u526a\u679d\u4e14\u6027\u80fd\u635f\u5931\u5c0f\uff0c\u8bad\u7ec3\u4e2d\u526a\u5927\u7f51\u7edc\u6bd4\u4ece\u5934\u8bad\u7ec3\u5c0f\u7f51\u7edc\u66f4\u9ad8\u6548\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u548c\u7f51\u7edc\u538b\u7f29\uff0c\u5728\u8bad\u7ec3\u4e2d\u526a\u679d\u5927\u7f51\u7edc\u53ef\u4ea7\u751f\u66f4\u9ad8\u6548\u3001\u6027\u80fd\u66f4\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u3002"}}
{"id": "2507.11636", "pdf": "https://arxiv.org/pdf/2507.11636", "abs": "https://arxiv.org/abs/2507.11636", "authors": ["Junyi Fan", "Donald Williamson"], "title": "JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": "Accepted to WASPAA 2025", "summary": "Speech quality assessment (SQA) is often used to learn a mapping from a\nhigh-dimensional input space to a scalar that represents the mean opinion score\n(MOS) of the perceptual speech quality. Learning such a mapping is challenging\nfor many reasons, but largely because MOS exhibits high levels of inherent\nvariance due to perceptual and experimental-design differences. Many solutions\nhave been proposed, but many approaches do not properly incorporate perceptual\nfactors into their learning algorithms (beyond the MOS label), which could lead\nto unsatisfactory results. To this end, we propose JSQA, a two-stage framework\nthat pretrains an audio encoder using perceptually-guided contrastive learning\non just noticeable difference (JND) pairs, followed by fine-tuning for MOS\nprediction. We first generate pairs of audio data within JND levels, which are\nthen used to pretrain an encoder to leverage perceptual quality similarity\ninformation and map it into an embedding space. The JND pairs come from clean\nLibriSpeech utterances that are mixed with background noise from CHiME-3, at\ndifferent signal-to-noise ratios (SNRs). The encoder is later fine-tuned with\naudio samples from the NISQA dataset for MOS prediction. Experimental results\nsuggest that perceptually-inspired contrastive pretraining significantly\nimproves the model performance evaluated by various metrics when compared\nagainst the same network trained from scratch without pretraining. These\nfindings suggest that incorporating perceptual factors into pretraining greatly\ncontributes to the improvement in performance for SQA.", "AI": {"tldr": "\u63d0\u51faJSQA\u4e24\u9636\u6bb5\u6846\u67b6\u7528\u4e8e\u8bed\u97f3\u8d28\u91cf\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8868\u660e\u611f\u77e5\u542f\u53d1\u7684\u5bf9\u6bd4\u9884\u8bad\u7ec3\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u672a\u5145\u5206\u7ed3\u5408\u611f\u77e5\u56e0\u7d20\uff0c\u5b66\u4e60\u4ece\u9ad8\u7ef4\u8f93\u5165\u5230MOS\u7684\u6620\u5c04\u5b58\u5728\u6311\u6218\u3002", "method": "\u4f7f\u7528\u611f\u77e5\u5f15\u5bfc\u7684\u5bf9\u6bd4\u5b66\u4e60\u5bf9JND\u5bf9\u9884\u8bad\u7ec3\u97f3\u9891\u7f16\u7801\u5668\uff0c\u518d\u9488\u5bf9MOS\u9884\u6d4b\u8fdb\u884c\u5fae\u8c03\u3002JND\u5bf9\u7531LibriSpeech\u548cCHiME - 3\u751f\u6210\uff0c\u5fae\u8c03\u7528NISQA\u6570\u636e\u96c6\u3002", "result": "\u611f\u77e5\u542f\u53d1\u7684\u5bf9\u6bd4\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u591a\u79cd\u6307\u6807\u4e0a\u4f18\u4e8e\u672a\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "conclusion": "\u5728\u9884\u8bad\u7ec3\u4e2d\u7eb3\u5165\u611f\u77e5\u56e0\u7d20\u5bf9\u8bed\u97f3\u8d28\u91cf\u8bc4\u4f30\u6027\u80fd\u63d0\u5347\u6709\u5f88\u5927\u8d21\u732e\u3002"}}
{"id": "2507.11997", "pdf": "https://arxiv.org/pdf/2507.11997", "abs": "https://arxiv.org/abs/2507.11997", "authors": ["Tairan Huang", "Yili Wang"], "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph fraud detection has garnered significant attention as Graph Neural\nNetworks (GNNs) have proven effective in modeling complex relationships within\nmultimodal data. However, existing graph fraud detection methods typically use\npreprocessed node embeddings and predefined graph structures to reveal\nfraudsters, which ignore the rich semantic cues contained in raw textual\ninformation. Although Large Language Models (LLMs) exhibit powerful\ncapabilities in processing textual information, it remains a significant\nchallenge to perform multimodal fusion of processed textual embeddings with\ngraph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM\n\\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In\nMLED, we utilize LLMs to extract external knowledge from textual information to\nenhance graph fraud detection methods. To integrate LLMs with graph structure\ninformation and enhance the ability to distinguish fraudsters, we design a\nmulti-level LLM enhanced framework including type-level enhancer and\nrelation-level enhancer. One is to enhance the difference between the\nfraudsters and the benign entities, the other is to enhance the importance of\nthe fraudsters in different relations. The experiments on four real-world\ndatasets show that MLED achieves state-of-the-art performance in graph fraud\ndetection as a generalized framework that can be applied to existing methods.", "AI": {"tldr": "\u63d0\u51faMLED\u6846\u67b6\u5229\u7528LLM\u63d0\u53d6\u6587\u672c\u4fe1\u606f\u4e2d\u7684\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u56fe\u6b3a\u8bc8\u68c0\u6d4b\uff0c\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u8fbe\u5230SOTA\u3002", "motivation": "\u73b0\u6709\u56fe\u6b3a\u8bc8\u68c0\u6d4b\u65b9\u6cd5\u5ffd\u7565\u539f\u59cb\u6587\u672c\u4fe1\u606f\u8bed\u4e49\u7ebf\u7d22\uff0c\u4e14\u5c06\u5904\u7406\u540e\u7684\u6587\u672c\u5d4c\u5165\u4e0e\u56fe\u7ed3\u6784\u8fdb\u884c\u591a\u6a21\u6001\u878d\u5408\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51faMLED\u6846\u67b6\uff0c\u8bbe\u8ba1\u7c7b\u578b\u7ea7\u589e\u5f3a\u5668\u548c\u5173\u7cfb\u7ea7\u589e\u5f3a\u5668\u6765\u878d\u5408LLM\u4e0e\u56fe\u7ed3\u6784\u4fe1\u606f\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660eMLED\u4f5c\u4e3a\u901a\u7528\u6846\u67b6\u5728\u56fe\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "MLED\u662f\u4e00\u4e2a\u53ef\u5e94\u7528\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u901a\u7528\u6846\u67b6\uff0c\u80fd\u6709\u6548\u63d0\u5347\u56fe\u6b3a\u8bc8\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.11638", "pdf": "https://arxiv.org/pdf/2507.11638", "abs": "https://arxiv.org/abs/2507.11638", "authors": ["Benjamin Keel", "Aaron Quyn", "David Jayne", "Maryam Mohsin", "Samuel D. Relton"], "title": "Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Published in Medical Image Understanding and Analysis (MIUA) 2025", "summary": "Effective treatment for rectal cancer relies on accurate lymph node\nmetastasis (LNM) staging. However, radiological criteria based on lymph node\n(LN) size, shape and texture morphology have limited diagnostic accuracy. In\nthis work, we investigate applying a Variational Autoencoder (VAE) as a feature\nencoder model to replace the large pre-trained Convolutional Neural Network\n(CNN) used in existing approaches. The motivation for using a VAE is that the\ngenerative model aims to reconstruct the images, so it directly encodes visual\nfeatures and meaningful patterns across the data. This leads to a disentangled\nand structured latent space which can be more interpretable than a CNN. Models\nare deployed on an in-house MRI dataset with 168 patients who did not undergo\nneo-adjuvant treatment. The post-operative pathological N stage was used as the\nground truth to evaluate model predictions. Our proposed model 'VAE-MLP'\nachieved state-of-the-art performance on the MRI dataset, with cross-validated\nmetrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85\n+/- 0.05. Code is available at:\nhttps://github.com/benkeel/Lymph_Node_Classification_MIUA.", "AI": {"tldr": "\u672c\u6587\u7528VAE\u4f5c\u4e3a\u7279\u5f81\u7f16\u7801\u5668\u6a21\u578b\u66ff\u4ee3CNN\uff0c\u5728MRI\u6570\u636e\u96c6\u4e0a\u63d0\u51fa\u7684VAE - MLP\u6a21\u578b\u53d6\u5f97\u4e86\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6dcb\u5df4\u7ed3\u5927\u5c0f\u3001\u5f62\u72b6\u548c\u7eb9\u7406\u5f62\u6001\u7684\u653e\u5c04\u5b66\u6807\u51c6\u8bca\u65ad\u51c6\u786e\u6027\u6709\u9650\uff0cVAE\u751f\u6210\u6a21\u578b\u80fd\u76f4\u63a5\u7f16\u7801\u89c6\u89c9\u7279\u5f81\u548c\u6709\u610f\u4e49\u6a21\u5f0f\uff0c\u5176\u6f5c\u5728\u7a7a\u95f4\u6bd4CNN\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u7528VAE\u4f5c\u4e3a\u7279\u5f81\u7f16\u7801\u5668\u6a21\u578b\u66ff\u4ee3\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u5927\u578b\u9884\u8bad\u7ec3CNN\uff0c\u5728\u542b168\u540d\u672a\u63a5\u53d7\u65b0\u8f85\u52a9\u6cbb\u7597\u60a3\u8005\u7684\u5185\u90e8MRI\u6570\u636e\u96c6\u4e0a\u90e8\u7f72\u6a21\u578b\uff0c\u4ee5\u672f\u540e\u75c5\u7406N\u9636\u6bb5\u4e3a\u771f\u5b9e\u503c\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\u3002", "result": "\u63d0\u51fa\u7684VAE - MLP\u6a21\u578b\u5728MRI\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u5148\u8fdb\u6027\u80fd\uff0c\u4ea4\u53c9\u9a8c\u8bc1\u6307\u6807\u4e3aAUC 0.86 +/- 0.05\uff0c\u7075\u654f\u5ea60.79 +/- 0.06\uff0c\u7279\u5f02\u60270.85 +/- 0.05\u3002", "conclusion": "\u4f7f\u7528VAE\u4f5c\u4e3a\u7279\u5f81\u7f16\u7801\u5668\u6a21\u578b\u7528\u4e8e\u76f4\u80a0\u764c\u6dcb\u5df4\u7ed3\u8f6c\u79fb\u5206\u671f\u662f\u6709\u6548\u7684\uff0c\u63d0\u51fa\u7684VAE - MLP\u6a21\u578b\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.12002", "pdf": "https://arxiv.org/pdf/2507.12002", "abs": "https://arxiv.org/abs/2507.12002", "authors": ["Alice Zhang", "Callihan Bertley", "Dawei Liang", "Edison Thomaz"], "title": "Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing", "categories": ["cs.LG", "I.2.0; J.4"], "comment": null, "summary": "Social interactions play a crucial role in shaping human behavior,\nrelationships, and societies. It encompasses various forms of communication,\nsuch as verbal conversation, non-verbal gestures, facial expressions, and body\nlanguage. In this work, we develop a novel computational approach to detect a\nfoundational aspect of human social interactions, in-person verbal\nconversations, by leveraging audio and inertial data captured with a commodity\nsmartwatch in acoustically-challenging scenarios. To evaluate our approach, we\nconducted a lab study with 11 participants and a semi-naturalistic study with\n24 participants. We analyzed machine learning and deep learning models with 3\ndifferent fusion methods, showing the advantages of fusing audio and inertial\ndata to consider not only verbal cues but also non-verbal gestures in\nconversations. Furthermore, we perform a comprehensive set of evaluations\nacross activities and sampling rates to demonstrate the benefits of multimodal\nsensing in specific contexts. Overall, our framework achieved 82.0$\\pm$3.0%\nmacro F1-score when detecting conversations in the lab and 77.2$\\pm$1.8% in the\nsemi-naturalistic setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7528\u667a\u80fd\u624b\u8868\u97f3\u9891\u548c\u60ef\u6027\u6570\u636e\u68c0\u6d4b\u9762\u5bf9\u9762\u8a00\u8bed\u4ea4\u6d41\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u6846\u67b6\u5728\u5b9e\u9a8c\u5ba4\u548c\u534a\u81ea\u7136\u573a\u666f\u4e2d\u5206\u522b\u8fbe\u5230\u4e00\u5b9a\u7684F1\u5206\u6570\u3002", "motivation": "\u793e\u4ea4\u4e92\u52a8\u5bf9\u4eba\u7c7b\u884c\u4e3a\u7b49\u81f3\u5173\u91cd\u8981\uff0c\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u5728\u58f0\u5b66\u590d\u6742\u573a\u666f\u4e2d\u68c0\u6d4b\u9762\u5bf9\u9762\u8a00\u8bed\u4ea4\u6d41\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u667a\u80fd\u624b\u8868\u6355\u83b7\u7684\u97f3\u9891\u548c\u60ef\u6027\u6570\u636e\uff0c\u5206\u6790\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u76843\u79cd\u4e0d\u540c\u878d\u5408\u65b9\u6cd5\uff0c\u5f00\u5c55\u5b9e\u9a8c\u5ba4\u7814\u7a76\u548c\u534a\u81ea\u7136\u4e3b\u4e49\u7814\u7a76\u3002", "result": "\u6846\u67b6\u5728\u5b9e\u9a8c\u5ba4\u68c0\u6d4b\u5bf9\u8bdd\u65f6\u5b8f\u89c2F1\u5206\u6570\u4e3a82.0\u00b13.0%\uff0c\u5728\u534a\u81ea\u7136\u573a\u666f\u4e3a77.2\u00b11.8%\u3002", "conclusion": "\u878d\u5408\u97f3\u9891\u548c\u60ef\u6027\u6570\u636e\u8003\u8651\u8a00\u8bed\u548c\u975e\u8a00\u8bed\u7ebf\u7d22\u6709\u4f18\u52bf\uff0c\u591a\u6a21\u6001\u4f20\u611f\u5728\u7279\u5b9a\u573a\u666f\u6709\u597d\u5904\u3002"}}
{"id": "2507.12011", "pdf": "https://arxiv.org/pdf/2507.12011", "abs": "https://arxiv.org/abs/2507.12011", "authors": ["Yao Lu", "Hongyu Gao", "Zhuangzhi Chen", "Dongwei Xu", "Yun Lin", "Qi Xuan", "Guan Gui"], "title": "DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Although deep neural networks have made remarkable achievements in the field\nof automatic modulation recognition (AMR), these models often require a large\namount of labeled data for training. However, in many practical scenarios, the\navailable target domain data is scarce and difficult to meet the needs of model\ntraining. The most direct way is to collect data manually and perform expert\nannotation, but the high time and labor costs are unbearable. Another common\nmethod is data augmentation. Although it can enrich training samples to a\ncertain extent, it does not introduce new data and therefore cannot\nfundamentally solve the problem of data scarcity. To address these challenges,\nwe introduce a data expansion framework called Dynamic Uncertainty-driven\nSample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring\nfunction to filter out useful samples from relevant AMR datasets and employs an\nactive learning strategy to continuously refine the scorer. Extensive\nexperiments demonstrate that DUSE consistently outperforms 8 coreset selection\nbaselines in both class-balance and class-imbalance settings. Besides, DUSE\nexhibits strong cross-architecture generalization for unseen models.", "AI": {"tldr": "\u9488\u5bf9\u81ea\u52a8\u8c03\u5236\u8bc6\u522b\u4e2d\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u51faDUSE\u6570\u636e\u6269\u5c55\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u4e14\u6709\u5f3a\u6cdb\u5316\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u81ea\u52a8\u8c03\u5236\u8bc6\u522b\u4e2d\u8bad\u7ec3\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u5b9e\u9645\u76ee\u6807\u57df\u6570\u636e\u7a00\u7f3a\uff0c\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u6570\u636e\u589e\u5f3a\u65e0\u6cd5\u6839\u672c\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u5f15\u5165DUSE\u6846\u67b6\uff0c\u7528\u4e0d\u786e\u5b9a\u6027\u8bc4\u5206\u51fd\u6570\u4ece\u76f8\u5173\u6570\u636e\u96c6\u7b5b\u9009\u6709\u7528\u6837\u672c\uff0c\u7528\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\u4f18\u5316\u8bc4\u5206\u5668\u3002", "result": "DUSE\u5728\u7c7b\u522b\u5e73\u8861\u548c\u4e0d\u5e73\u8861\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8e8\u4e2a\u6838\u5fc3\u96c6\u9009\u62e9\u57fa\u7ebf\uff0c\u5bf9\u672a\u89c1\u6a21\u578b\u6709\u5f3a\u8de8\u67b6\u6784\u6cdb\u5316\u6027\u3002", "conclusion": "DUSE\u80fd\u6709\u6548\u89e3\u51b3\u81ea\u52a8\u8c03\u5236\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u6027\u80fd\u826f\u597d\u4e14\u6cdb\u5316\u6027\u5f3a\u3002"}}
{"id": "2507.11655", "pdf": "https://arxiv.org/pdf/2507.11655", "abs": "https://arxiv.org/abs/2507.11655", "authors": ["Mohimenul Kabir", "Supratik Chakraborty", "Kuldeep S Meel"], "title": "Counting Answer Sets of Disjunctive Answer Set Programs", "categories": ["cs.LO", "cs.AI"], "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "summary": "Answer Set Programming (ASP) provides a powerful declarative paradigm for\nknowledge representation and reasoning. Recently, counting answer sets has\nemerged as an important computational problem with applications in\nprobabilistic reasoning, network reliability analysis, and other domains. This\nhas motivated significant research into designing efficient ASP counters. While\nsubstantial progress has been made for normal logic programs, the development\nof practical counters for disjunctive logic programs remains challenging.\n  We present SharpASP-SR, a novel framework for counting answer sets of\ndisjunctive logic programs based on subtractive reduction to projected\npropositional model counting. Our approach introduces an alternative\ncharacterization of answer sets that enables efficient reduction while ensuring\nthat intermediate representations remain of polynomial size. This allows\nSharpASP-SR to leverage recent advances in projected model counting technology.\nThrough extensive experimental evaluation on diverse benchmarks, we demonstrate\nthat SharpASP-SR significantly outperforms existing counters on instances with\nlarge answer set counts. Building on these results, we develop a hybrid\ncounting approach that combines enumeration techniques with SharpASP-SR to\nachieve state-of-the-art performance across the full spectrum of disjunctive\nprograms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSharpASP - SR\u6846\u67b6\u7528\u4e8e\u8ba1\u7b97\u6790\u53d6\u903b\u8f91\u7a0b\u5e8f\u7684\u7b54\u6848\u96c6\u6570\u91cf\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5927\u7b54\u6848\u96c6\u8ba1\u6570\u5b9e\u4f8b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5f00\u53d1\u6df7\u5408\u8ba1\u6570\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u8ba1\u6570\u7b54\u6848\u96c6\u5728\u591a\u4e2a\u9886\u57df\u6709\u5e94\u7528\uff0c\u6b63\u5e38\u903b\u8f91\u7a0b\u5e8f\u5df2\u6709\u8fdb\u5c55\uff0c\u4f46\u6790\u53d6\u903b\u8f91\u7a0b\u5e8f\u7684\u5b9e\u7528\u8ba1\u6570\u5668\u5f00\u53d1\u4ecd\u5177\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u51cf\u6cd5\u5f52\u7ea6\u5230\u6295\u5f71\u547d\u9898\u6a21\u578b\u8ba1\u6570\u7684SharpASP - SR\u6846\u67b6\uff0c\u5f15\u5165\u7b54\u6848\u96c6\u7684\u66ff\u4ee3\u7279\u5f81\u63cf\u8ff0\uff0c\u7ed3\u5408\u679a\u4e3e\u6280\u672f\u5f00\u53d1\u6df7\u5408\u8ba1\u6570\u65b9\u6cd5\u3002", "result": "SharpASP - SR\u5728\u5927\u7b54\u6848\u96c6\u8ba1\u6570\u5b9e\u4f8b\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8ba1\u6570\u5668\uff0c\u6df7\u5408\u8ba1\u6570\u65b9\u6cd5\u5728\u5168\u8303\u56f4\u6790\u53d6\u7a0b\u5e8f\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "SharpASP - SR\u6846\u67b6\u53ca\u6df7\u5408\u8ba1\u6570\u65b9\u6cd5\u5728\u6790\u53d6\u903b\u8f91\u7a0b\u5e8f\u7b54\u6848\u96c6\u8ba1\u6570\u4e0a\u6709\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2507.12041", "pdf": "https://arxiv.org/pdf/2507.12041", "abs": "https://arxiv.org/abs/2507.12041", "authors": ["Anmol Kagrecha", "Henrik Marklund", "Potsawee Manakul", "Richard Zeckhauser", "Benjamin Van Roy"], "title": "Granular feedback merits sophisticated aggregation", "categories": ["cs.LG"], "comment": "31 pages, 8 figures", "summary": "Human feedback is increasingly used across diverse applications like training\nAI models, developing recommender systems, and measuring public opinion -- with\ngranular feedback often being preferred over binary feedback for its greater\ninformativeness. While it is easy to accurately estimate a population's\ndistribution of feedback given feedback from a large number of individuals,\ncost constraints typically necessitate using smaller groups. A simple method to\napproximate the population distribution is regularized averaging: compute the\nempirical distribution and regularize it toward a prior. Can we do better? As\nwe will discuss, the answer to this question depends on feedback granularity.\n  Suppose one wants to predict a population's distribution of feedback using\nfeedback from a limited number of individuals. We show that, as feedback\ngranularity increases, one can substantially improve upon predictions of\nregularized averaging by combining individuals' feedback in ways more\nsophisticated than regularized averaging.\n  Our empirical analysis using questions on social attitudes confirms this\npattern. In particular, with binary feedback, sophistication barely reduces the\nnumber of individuals required to attain a fixed level of performance. By\ncontrast, with five-point feedback, sophisticated methods match the performance\nof regularized averaging with about half as many individuals.", "AI": {"tldr": "\u7814\u7a76\u5728\u6709\u9650\u4e2a\u4f53\u53cd\u9988\u4e0b\u9884\u6d4b\u4eba\u7fa4\u53cd\u9988\u5206\u5e03\uff0c\u53d1\u73b0\u53cd\u9988\u7c92\u5ea6\u589e\u52a0\u65f6\uff0c\u590d\u6742\u65b9\u6cd5\u6bd4\u6b63\u5219\u5e73\u5747\u6cd5\u9884\u6d4b\u6548\u679c\u66f4\u597d\uff0c\u5b9e\u8bc1\u5206\u6790\u8bc1\u5b9e\u6b64\u6a21\u5f0f\u3002", "motivation": "\u5728\u6210\u672c\u53d7\u9650\u9700\u7528\u5c0f\u7fa4\u4f53\u53cd\u9988\u8fd1\u4f3c\u4eba\u7fa4\u53cd\u9988\u5206\u5e03\u60c5\u51b5\u4e0b\uff0c\u63a2\u7a76\u80fd\u5426\u6bd4\u6b63\u5219\u5e73\u5747\u6cd5\u6709\u66f4\u597d\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u7406\u8bba\u5206\u6790\u7ed3\u5408\u4f7f\u7528\u793e\u4f1a\u6001\u5ea6\u95ee\u9898\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u5bf9\u4e8e\u4e8c\u5143\u53cd\u9988\uff0c\u590d\u6742\u65b9\u6cd5\u5bf9\u51cf\u5c11\u8fbe\u5230\u56fa\u5b9a\u6027\u80fd\u6240\u9700\u4e2a\u4f53\u6570\u4f5c\u7528\u4e0d\u5927\uff1b\u5bf9\u4e8e\u4e94\u70b9\u53cd\u9988\uff0c\u590d\u6742\u65b9\u6cd5\u7528\u7ea6\u4e00\u534a\u4e2a\u4f53\u6570\u5c31\u80fd\u8fbe\u5230\u6b63\u5219\u5e73\u5747\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u9884\u6d4b\u4eba\u7fa4\u53cd\u9988\u5206\u5e03\u65f6\uff0c\u53cd\u9988\u7c92\u5ea6\u589e\u52a0\uff0c\u91c7\u7528\u6bd4\u6b63\u5219\u5e73\u5747\u6cd5\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6548\u679c\u3002"}}
{"id": "2507.11661", "pdf": "https://arxiv.org/pdf/2507.11661", "abs": "https://arxiv.org/abs/2507.11661", "authors": ["Guimin Hu", "Yi Xin", "Lijie Hu", "Zhihong Zhu", "Hasti Seifi"], "title": "Partitioner Guided Modal Learning Framework", "categories": ["cs.CL", "cs.AI"], "comment": "acm multimedia 2025", "summary": "Multimodal learning benefits from multiple modal information, and each\nlearned modal representations can be divided into uni-modal that can be learned\nfrom uni-modal training and paired-modal features that can be learned from\ncross-modal interaction. Building on this perspective, we propose a\npartitioner-guided modal learning framework, PgM, which consists of the modal\npartitioner, uni-modal learner, paired-modal learner, and uni-paired modal\ndecoder. Modal partitioner segments the learned modal representation into\nuni-modal and paired-modal features. Modal learner incorporates two dedicated\ncomponents for uni-modal and paired-modal learning. Uni-paired modal decoder\nreconstructs modal representation based on uni-modal and paired-modal features.\nPgM offers three key benefits: 1) thorough learning of uni-modal and\npaired-modal features, 2) flexible distribution adjustment for uni-modal and\npaired-modal representations to suit diverse downstream tasks, and 3) different\nlearning rates across modalities and partitions. Extensive experiments\ndemonstrate the effectiveness of PgM across four multimodal tasks and further\nhighlight its transferability to existing models. Additionally, we visualize\nthe distribution of uni-modal and paired-modal features across modalities and\ntasks, offering insights into their respective contributions.", "AI": {"tldr": "\u63d0\u51fa\u5206\u533a\u5668\u5f15\u5bfc\u7684\u6a21\u6001\u5b66\u4e60\u6846\u67b6PgM\uff0c\u6709\u591a\u79cd\u4f18\u52bf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u548c\u53ef\u8fc1\u79fb\u6027\uff0c\u5e76\u53ef\u89c6\u5316\u7279\u5f81\u5206\u5e03\u3002", "motivation": "\u4e3a\u5145\u5206\u5229\u7528\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u4e0d\u540c\u7c7b\u578b\u7684\u6a21\u6001\u4fe1\u606f\uff0c\u63d0\u5347\u591a\u6a21\u6001\u5b66\u4e60\u6548\u679c\u3002", "method": "\u6784\u5efa\u5305\u542b\u6a21\u6001\u5206\u533a\u5668\u3001\u5355\u6a21\u6001\u5b66\u4e60\u5668\u3001\u914d\u5bf9\u6a21\u6001\u5b66\u4e60\u5668\u548c\u5355 - \u914d\u5bf9\u6a21\u6001\u89e3\u7801\u5668\u7684PgM\u6846\u67b6\u3002", "result": "PgM\u5728\u56db\u4e2a\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u53ef\u8fc1\u79fb\u5230\u73b0\u6709\u6a21\u578b\uff0c\u8fd8\u53ef\u89c6\u5316\u4e86\u7279\u5f81\u5206\u5e03\u3002", "conclusion": "PgM\u6846\u67b6\u80fd\u6709\u6548\u5b66\u4e60\u5355\u6a21\u6001\u548c\u914d\u5bf9\u6a21\u6001\u7279\u5f81\uff0c\u53ef\u7075\u6d3b\u8c03\u6574\u5206\u5e03\uff0c\u4e0d\u540c\u6a21\u6001\u548c\u5206\u533a\u6709\u4e0d\u540c\u5b66\u4e60\u7387\uff0c\u5177\u6709\u826f\u597d\u6548\u679c\u548c\u53ef\u8fc1\u79fb\u6027\u3002"}}
{"id": "2507.12043", "pdf": "https://arxiv.org/pdf/2507.12043", "abs": "https://arxiv.org/abs/2507.12043", "authors": ["Wen Wen", "Tieliang Gong", "Yunjiao Zhang", "Zeyu Gao", "Weizhan Zhang", "Yong-Jin Liu"], "title": "Information-Theoretic Generalization Bounds of Replay-based Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Continual learning (CL) has emerged as a dominant paradigm for acquiring\nknowledge from sequential tasks while avoiding catastrophic forgetting.\nAlthough many CL methods have been proposed to show impressive empirical\nperformance, the theoretical understanding of their generalization behavior\nremains limited, particularly for replay-based approaches. In this paper, we\nestablish a unified theoretical framework for replay-based CL, deriving a\nseries of information-theoretic bounds that explicitly characterize how the\nmemory buffer interacts with the current task to affect generalization.\nSpecifically, our hypothesis-based bounds reveal that utilizing the limited\nexemplars of previous tasks alongside the current task data, rather than\nexhaustive replay, facilitates improved generalization while effectively\nmitigating catastrophic forgetting. Furthermore, our prediction-based bounds\nyield tighter and computationally tractable upper bounds of the generalization\ngap through the use of low-dimensional variables. Our analysis is general and\nbroadly applicable to a wide range of learning algorithms, exemplified by\nstochastic gradient Langevin dynamics (SGLD) as a representative method.\nComprehensive experimental evaluations demonstrate the effectiveness of our\nderived bounds in capturing the generalization dynamics in replay-based CL\nsettings.", "AI": {"tldr": "\u672c\u6587\u4e3a\u57fa\u4e8e\u91cd\u653e\u7684\u6301\u7eed\u5b66\u4e60\u5efa\u7acb\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u4fe1\u606f\u8bba\u754c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u754c\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u867d\u7ecf\u9a8c\u6027\u80fd\u597d\uff0c\u4f46\u5bf9\u57fa\u4e8e\u91cd\u653e\u65b9\u6cd5\u7684\u6cdb\u5316\u884c\u4e3a\u7406\u8bba\u7406\u89e3\u6709\u9650\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u57fa\u4e8e\u5047\u8bbe\u548c\u9884\u6d4b\u7684\u4fe1\u606f\u8bba\u754c\uff0c\u4ee5\u968f\u673a\u68af\u5ea6\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u4e3a\u4f8b\u3002", "result": "\u57fa\u4e8e\u5047\u8bbe\u7684\u754c\u8868\u660e\u5229\u7528\u6709\u9650\u5148\u524d\u4efb\u52a1\u6837\u672c\u53ef\u4fc3\u8fdb\u6cdb\u5316\u548c\u7f13\u89e3\u9057\u5fd8\uff1b\u57fa\u4e8e\u9884\u6d4b\u7684\u754c\u4ea7\u751f\u66f4\u7d27\u4e14\u6613\u8ba1\u7b97\u7684\u6cdb\u5316\u8bef\u5dee\u4e0a\u754c\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u754c\u80fd\u6355\u6349\u6cdb\u5316\u52a8\u6001\u3002", "conclusion": "\u6240\u63a8\u5bfc\u7684\u754c\u5728\u57fa\u4e8e\u91cd\u653e\u7684\u6301\u7eed\u5b66\u4e60\u4e2d\u6709\u6548\uff0c\u5206\u6790\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2507.12053", "pdf": "https://arxiv.org/pdf/2507.12053", "abs": "https://arxiv.org/abs/2507.12053", "authors": ["Seanglidet Yean", "Jiazu Zhou", "Bu-Sung Lee", "Markus Schl\u00e4pfer"], "title": "FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling", "categories": ["cs.LG"], "comment": "International Conference on Intelligent Digitization of Systems and\n  Services, Valencia, Spain, 2025 (IDSS 2025)", "summary": "The mobility patterns of people in cities evolve alongside changes in land\nuse and population. This makes it crucial for urban planners to simulate and\nanalyze human mobility patterns for purposes such as transportation\noptimization and sustainable urban development. Existing generative models\nborrowed from machine learning rely heavily on historical trajectories and\noften overlook evolving factors like changes in population density and land\nuse. Mechanistic approaches incorporate population density and facility\ndistribution but assume static scenarios, limiting their utility for future\nprojections where historical data for calibration is unavailable. This study\nintroduces a novel, data-driven approach for generating origin-destination\nmobility flows tailored to simulated urban scenarios. Our method leverages\nadaptive factors such as dynamic region sizes and land use archetypes, and it\nutilizes conditional generative adversarial networks (cGANs) to blend\nhistorical data with these adaptive parameters. The approach facilitates rapid\nmobility flow generation with adjustable spatial granularity based on regions\nof interest, without requiring extensive calibration data or complex behavior\nmodeling. The promising performance of our approach is demonstrated by its\napplication to mobile phone data from Singapore, and by its comparison with\nexisting methods.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u65b0\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u751f\u6210\u57ce\u5e02\u51fa\u884cOD\u6d41\uff0c\u5229\u7528\u81ea\u9002\u5e94\u56e0\u7d20\u548ccGANs\uff0c\u65e0\u9700\u5927\u91cf\u6821\u51c6\u6570\u636e\uff0c\u901a\u8fc7\u65b0\u52a0\u5761\u624b\u673a\u6570\u636e\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u4f9d\u8d56\u5386\u53f2\u8f68\u8ff9\uff0c\u673a\u68b0\u65b9\u6cd5\u5047\u8bbe\u9759\u6001\u573a\u666f\uff0c\u96be\u4ee5\u6ee1\u8db3\u57ce\u5e02\u89c4\u5212\u4e2d\u6a21\u62df\u548c\u5206\u6790\u4eba\u7c7b\u51fa\u884c\u6a21\u5f0f\u7684\u9700\u6c42\u3002", "method": "\u5f15\u5165\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u9002\u5e94\u56e0\u7d20\u5982\u52a8\u6001\u533a\u57df\u5927\u5c0f\u548c\u571f\u5730\u5229\u7528\u539f\u578b\uff0c\u7ed3\u5408\u6761\u4ef6\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08cGANs\uff09\u878d\u5408\u5386\u53f2\u6570\u636e\u548c\u81ea\u9002\u5e94\u53c2\u6570\u3002", "result": "\u5e94\u7528\u4e8e\u65b0\u52a0\u5761\u624b\u673a\u6570\u636e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u663e\u793a\u51fa\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5feb\u901f\u751f\u6210\u51fa\u884cOD\u6d41\uff0c\u7a7a\u95f4\u7c92\u5ea6\u53ef\u8c03\u8282\uff0c\u65e0\u9700\u5927\u91cf\u6821\u51c6\u6570\u636e\u548c\u590d\u6742\u884c\u4e3a\u5efa\u6a21\uff0c\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.11692", "pdf": "https://arxiv.org/pdf/2507.11692", "abs": "https://arxiv.org/abs/2507.11692", "authors": ["Sai Teja Erukude", "Lior Shamir"], "title": "Galaxy image simplification using Generative AI", "categories": ["astro-ph.GA", "astro-ph.IM", "cs.AI", "cs.LG"], "comment": "Astronomy and Computing, accepted", "summary": "Modern digital sky surveys have been acquiring images of billions of\ngalaxies. While these images often provide sufficient details to analyze the\nshape of the galaxies, accurate analysis of such high volumes of images\nrequires effective automation. Current solutions often rely on machine learning\nannotation of the galaxy images based on a set of pre-defined classes. Here we\nintroduce a new approach to galaxy image analysis that is based on generative\nAI. The method simplifies the galaxy images and automatically converts them\ninto a ``skeletonized\" form. The simplified images allow accurate measurements\nof the galaxy shapes and analysis that is not limited to a certain pre-defined\nset of classes. We demonstrate the method by applying it to galaxy images\nacquired by the DESI Legacy Survey. The code and data are publicly available.\nThe method was applied to 125,000 DESI Legacy Survey images, and the catalog of\nthe simplified images is publicly available.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u661f\u7cfb\u56fe\u50cf\u5206\u6790\u65b0\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8eDESI Legacy Survey\u56fe\u50cf\uff0c\u4ee3\u7801\u3001\u6570\u636e\u548c\u7b80\u5316\u56fe\u50cf\u76ee\u5f55\u516c\u5f00\u3002", "motivation": "\u73b0\u4ee3\u6570\u5b57\u5de1\u5929\u83b7\u53d6\u5927\u91cf\u661f\u7cfb\u56fe\u50cf\uff0c\u51c6\u786e\u5206\u6790\u9700\u6709\u6548\u81ea\u52a8\u5316\uff0c\u73b0\u6709\u65b9\u6848\u591a\u4f9d\u8d56\u9884\u5b9a\u4e49\u7c7b\u522b\u7684\u673a\u5668\u5b66\u4e60\u6807\u6ce8\u3002", "method": "\u57fa\u4e8e\u751f\u6210\u5f0fAI\uff0c\u5c06\u661f\u7cfb\u56fe\u50cf\u7b80\u5316\u5e76\u8f6c\u6362\u4e3a\u201c\u9aa8\u67b6\u5316\u201d\u5f62\u5f0f\u3002", "result": "\u5bf9125,000\u5f20DESI Legacy Survey\u56fe\u50cf\u5e94\u7528\u8be5\u65b9\u6cd5\uff0c\u7b80\u5316\u56fe\u50cf\u76ee\u5f55\u516c\u5f00\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u53ef\u51c6\u786e\u6d4b\u91cf\u661f\u7cfb\u5f62\u72b6\uff0c\u4e14\u4e0d\u53d7\u9884\u5b9a\u4e49\u7c7b\u522b\u9650\u5236\u3002"}}
{"id": "2507.12070", "pdf": "https://arxiv.org/pdf/2507.12070", "abs": "https://arxiv.org/abs/2507.12070", "authors": ["George Bird"], "title": "Emergence of Quantised Representations Isolated to Anisotropic Functions", "categories": ["cs.LG", "I.5.1; F.1.1; I.2.6"], "comment": "36 pages, 31 figures", "summary": "This paper describes a novel methodology for determining representational\nalignment, developed upon the existing Spotlight Resonance method. Using this,\nit is found that algebraic symmetries of network primitives are a strong\npredictor for task-agnostic structure in representations. Particularly, this\nnew tool is used to gain insight into how discrete representations can form and\narrange in autoencoder models, through an ablation study where only the\nactivation function is altered. Representations are found to tend to discretise\nwhen the activation functions are defined through a discrete algebraic\npermutation-equivariant symmetry. In contrast, they remain continuous under a\ncontinuous algebraic orthogonal-equivariant definition. These findings\ncorroborate the hypothesis that functional form choices can carry unintended\ninductive biases which produce task-independent artefactual structures in\nrepresentations, particularly that contemporary forms induce discretisation of\notherwise continuous structure -- a quantisation effect. Moreover, this\nsupports a general causal model for one mode in which discrete representations\nmay form, and could constitute a prerequisite for downstream interpretability\nphenomena, including grandmother neurons, discrete coding schemes, general\nlinear features and possibly Superposition. Hence, this tool and proposed\nmechanism for the influence of functional form on representations may provide\nseveral insights into emergent interpretability research. Finally, preliminary\nresults indicate that quantisation of representations appears to correlate with\na measurable increase in reconstruction error, reinforcing previous conjectures\nthat this collapse can be detrimental.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eSpotlight Resonance\u65b9\u6cd5\u63d0\u51fa\u786e\u5b9a\u8868\u5f81\u5bf9\u9f50\u7684\u65b0\u65b9\u6cd5\uff0c\u53d1\u73b0\u7f51\u7edc\u539f\u8bed\u4ee3\u6570\u5bf9\u79f0\u6027\u53ef\u9884\u6d4b\u8868\u5f81\u7ed3\u6784\uff0c\u63ed\u793a\u6fc0\u6d3b\u51fd\u6570\u5f62\u5f0f\u5f71\u54cd\u8868\u5f81\u79bb\u6563\u5316\uff0c\u8fd8\u6307\u51fa\u8868\u5f81\u91cf\u5316\u4e0e\u91cd\u6784\u8bef\u5dee\u76f8\u5173\u3002", "motivation": "\u6df1\u5165\u7406\u89e3\u8868\u5f81\u7684\u5f62\u6210\u548c\u6392\u5217\u65b9\u5f0f\uff0c\u7814\u7a76\u529f\u80fd\u5f62\u5f0f\u9009\u62e9\u5bf9\u8868\u5f81\u7684\u5f71\u54cd\uff0c\u4e3a\u6d8c\u73b0\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u89c1\u89e3\u3002", "method": "\u5728\u73b0\u6709Spotlight Resonance\u65b9\u6cd5\u57fa\u7840\u4e0a\u5f00\u53d1\u65b0\u65b9\u6cd5\uff0c\u8fdb\u884c\u4ec5\u6539\u53d8\u6fc0\u6d3b\u51fd\u6570\u7684\u6d88\u878d\u7814\u7a76\u3002", "result": "\u5f53\u6fc0\u6d3b\u51fd\u6570\u7531\u79bb\u6563\u4ee3\u6570\u7f6e\u6362\u7b49\u53d8\u5bf9\u79f0\u5b9a\u4e49\u65f6\uff0c\u8868\u5f81\u503e\u5411\u4e8e\u79bb\u6563\u5316\uff1b\u5728\u8fde\u7eed\u4ee3\u6570\u6b63\u4ea4\u7b49\u53d8\u5b9a\u4e49\u4e0b\u4fdd\u6301\u8fde\u7eed\uff0c\u4e14\u8868\u5f81\u91cf\u5316\u4e0e\u91cd\u6784\u8bef\u5dee\u589e\u52a0\u76f8\u5173\u3002", "conclusion": "\u529f\u80fd\u5f62\u5f0f\u9009\u62e9\u4f1a\u4ea7\u751f\u610f\u5916\u5f52\u7eb3\u504f\u5dee\uff0c\u8be5\u5de5\u5177\u548c\u673a\u5236\u4e3a\u6d8c\u73b0\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u89c1\u89e3\uff0c\u8868\u5f81\u91cf\u5316\u53ef\u80fd\u6709\u5bb3\u3002"}}
{"id": "2507.11694", "pdf": "https://arxiv.org/pdf/2507.11694", "abs": "https://arxiv.org/abs/2507.11694", "authors": ["Maximiliano Hormaz\u00e1bal Lagos", "\u00c1lvaro Bueno S\u00e1ez", "Pedro Alonso Doval", "Jorge Alcalde Vesteiro", "H\u00e9ctor Cerezo-Costas"], "title": "ExpliCIT-QA: Explainable Code-Based Image Table Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "This work has been accepted for presentation at the 24nd Portuguese\n  Conference on Artificial Intelligence (EPIA 2025) and will be published in\n  the proceedings by Springer in the Lecture Notes in Computer Science (LNCS)\n  series. Please cite the published version when available", "summary": "We present ExpliCIT-QA, a system that extends our previous MRT approach for\ntabular question answering into a multimodal pipeline capable of handling\ncomplex table images and providing explainable answers. ExpliCIT-QA follows a\nmodular design, consisting of: (1) Multimodal Table Understanding, which uses a\nChain-of-Thought approach to extract and transform content from table images;\n(2) Language-based Reasoning, where a step-by-step explanation in natural\nlanguage is generated to solve the problem; (3) Automatic Code Generation,\nwhere Python/Pandas scripts are created based on the reasoning steps, with\nfeedback for handling errors; (4) Code Execution to compute the final answer;\nand (5) Natural Language Explanation that describes how the answer was\ncomputed. The system is built for transparency and auditability: all\nintermediate outputs, parsed tables, reasoning steps, generated code, and final\nanswers are available for inspection. This strategy works towards closing the\nexplainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on\nthe TableVQA-Bench benchmark, comparing it with existing baselines. We\ndemonstrated improvements in interpretability and transparency, which open the\ndoor for applications in sensitive domains like finance and healthcare where\nauditing results are critical.", "AI": {"tldr": "\u63d0\u51faExpliCIT - QA\u7cfb\u7edf\uff0c\u5c06MRT\u65b9\u6cd5\u6269\u5c55\u4e3a\u591a\u6a21\u6001\u7ba1\u9053\u5904\u7406\u8868\u683c\u56fe\u50cf\u95ee\u7b54\uff0c\u6709\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u4e0a\u6709\u6539\u8fdb\u3002", "motivation": "\u7f29\u5c0f\u7aef\u5230\u7aefTableVQA\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u5dee\u8ddd\uff0c\u6ee1\u8db3\u654f\u611f\u9886\u57df\u5ba1\u8ba1\u7ed3\u679c\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5305\u542b\u591a\u6a21\u6001\u8868\u683c\u7406\u89e3\u3001\u57fa\u4e8e\u8bed\u8a00\u7684\u63a8\u7406\u3001\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u3001\u4ee3\u7801\u6267\u884c\u548c\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u7b49\u6b65\u9aa4\u3002", "result": "\u5728TableVQA - Bench\u57fa\u51c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u4e0a\u6709\u6539\u8fdb\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u53ef\u5e94\u7528\u4e8e\u91d1\u878d\u548c\u533b\u7597\u7b49\u654f\u611f\u9886\u57df\u3002"}}
{"id": "2507.12127", "pdf": "https://arxiv.org/pdf/2507.12127", "abs": "https://arxiv.org/abs/2507.12127", "authors": ["Ngoc Duy Pham", "Thusitha Dayaratne", "Viet Vo", "Shangqi Lai", "Sharif Abuadbba", "Hajime Suzuki", "Xingliang Yuan", "Carsten Rudolph"], "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks", "categories": ["cs.LG"], "comment": null, "summary": "Advancements in wireless and mobile technologies, including 5G advanced and\nthe envisioned 6G, are driving exponential growth in wireless devices. However,\nthis rapid expansion exacerbates spectrum scarcity, posing a critical\nchallenge. Dynamic spectrum allocation (DSA)--which relies on sensing and\ndynamically sharing spectrum--has emerged as an essential solution to address\nthis issue. While machine learning (ML) models hold significant potential for\nimproving spectrum sensing, their adoption in centralized ML-based DSA systems\nis limited by privacy concerns, bandwidth constraints, and regulatory\nchallenges. To overcome these limitations, distributed ML-based approaches such\nas Federated Learning (FL) offer promising alternatives. This work addresses\ntwo key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of\nlabeled data for training FL models in practical spectrum sensing scenarios is\ntackled with a semi-supervised FL approach, combined with energy detection,\nenabling model training on unlabeled datasets. Second, we examine the security\nvulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our\nanalysis highlights the shortcomings of existing majority-based defenses in\ncountering such attacks. To address these vulnerabilities, we propose a novel\ndefense mechanism inspired by vaccination, which effectively mitigates data\npoisoning attacks without relying on majority-based assumptions. Extensive\nexperiments on both synthetic and real-world datasets validate our solutions,\ndemonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets\nand maintain Byzantine robustness against both targeted and untargeted data\npoisoning attacks, even when a significant proportion of participants are\nmalicious.", "AI": {"tldr": "\u65e0\u7ebf\u8bbe\u5907\u589e\u957f\u81f4\u9891\u8c31\u7a00\u7f3a\uff0c\u52a8\u6001\u9891\u8c31\u5206\u914d\u662f\u89e3\u51b3\u65b9\u6848\uff0c\u672c\u6587\u89e3\u51b3\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u9891\u8c31\u611f\u77e5\u4e2d\u7684\u6570\u636e\u6807\u7b7e\u7a00\u7f3a\u548c\u5b89\u5168\u6f0f\u6d1e\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6848\u6709\u6548\u3002", "motivation": "\u65e0\u7ebf\u8bbe\u5907\u589e\u591a\u4f7f\u9891\u8c31\u7a00\u7f3a\uff0c\u96c6\u4e2d\u5f0f\u673a\u5668\u5b66\u4e60DSA\u7cfb\u7edf\u6709\u5c40\u9650\uff0c\u5206\u5e03\u5f0fML\u65b9\u6cd5\u5982\u8054\u90a6\u5b66\u4e60\u6709\u6f5c\u529b\uff0c\u4f46FLSS\u5b58\u5728\u6570\u636e\u6807\u7b7e\u7a00\u7f3a\u548c\u5b89\u5168\u6f0f\u6d1e\u95ee\u9898\u3002", "method": "\u7528\u534a\u76d1\u7763FL\u7ed3\u5408\u80fd\u91cf\u68c0\u6d4b\u89e3\u51b3\u6570\u636e\u6807\u7b7e\u7a00\u7f3a\u95ee\u9898\uff1b\u63d0\u51fa\u53d7\u75ab\u82d7\u542f\u53d1\u7684\u9632\u5fa1\u673a\u5236\u5e94\u5bf9\u6570\u636e\u6295\u6bd2\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFLSS\u5728\u65e0\u6807\u7b7e\u6570\u636e\u96c6\u4e0a\u63a5\u8fd1\u5b8c\u7f8e\u51c6\u786e\u7387\uff0c\u5bf9\u6570\u636e\u6295\u6bd2\u653b\u51fb\u4fdd\u6301\u62dc\u5360\u5ead\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3FLSS\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u4e3a\u9891\u8c31\u611f\u77e5\u63d0\u4f9b\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.12133", "pdf": "https://arxiv.org/pdf/2507.12133", "abs": "https://arxiv.org/abs/2507.12133", "authors": ["Hanwen Liu", "Yuhe Huang", "Yifeng Gong", "Yanjie Zhai", "Jiaxuan Lu"], "title": "HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Device recognition is vital for security in wireless communication systems,\nparticularly for applications like access control. Radio Frequency Fingerprint\nIdentification (RFFI) offers a non-cryptographic solution by exploiting\nhardware-induced signal distortions. This paper proposes HyDRA, a Hybrid\nDual-mode RF Architecture that integrates an optimized Variational Mode\nDecomposition (VMD) with a novel architecture based on the fusion of\nConvolutional Neural Networks (CNNs), Transformers, and Mamba components,\ndesigned to support both closed-set and open-set classification tasks. The\noptimized VMD enhances preprocessing efficiency and classification accuracy by\nfixing center frequencies and using closed-form solutions. HyDRA employs the\nTransformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and\nthe Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting\nto varying conditions. Evaluation on public datasets demonstrates\nstate-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance\nin our proposed open-set classification method, effectively identifying\nunauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves\nmillisecond-level inference speed with low power consumption, providing a\npractical solution for real-time wireless authentication in real-world\nenvironments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHyDRA\u67b6\u6784\u7528\u4e8e\u65e0\u7ebf\u8bbe\u5907\u8bc6\u522b\uff0c\u7ed3\u5408\u4f18\u5316VMD\u4e0eCNN\u3001Transformer\u548cMamba\u7ec4\u4ef6\uff0c\u5728\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728NVIDIA Jetson Xavier NX\u4e0a\u5b9e\u73b0\u4f4e\u529f\u8017\u5b9e\u65f6\u63a8\u7406\u3002", "motivation": "\u8bbe\u5907\u8bc6\u522b\u5bf9\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u63d0\u4f9b\u975e\u52a0\u5bc6\u89e3\u51b3\u65b9\u6848\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u652f\u6301\u95ed\u96c6\u548c\u5f00\u96c6\u5206\u7c7b\u4efb\u52a1\u3002", "method": "\u63d0\u51faHyDRA\u67b6\u6784\uff0c\u878d\u5408\u4f18\u5316VMD\u3001CNN\u3001Transformer\u548cMamba\u7ec4\u4ef6\uff0c\u4f7f\u7528TDSE\u8fdb\u884c\u5168\u5c40\u4f9d\u8d56\u5efa\u6a21\uff0cMLFE\u8fdb\u884c\u7ebf\u6027\u590d\u6742\u5ea6\u5904\u7406\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u95ed\u96c6\u573a\u666f\u8fbe\u5230SOTA\u51c6\u786e\u7387\uff0c\u5f00\u96c6\u5206\u7c7b\u65b9\u6cd5\u8868\u73b0\u7a33\u5065\uff0c\u5728NVIDIA Jetson Xavier NX\u4e0a\u5b9e\u73b0\u6beb\u79d2\u7ea7\u63a8\u7406\u901f\u5ea6\u548c\u4f4e\u529f\u8017\u3002", "conclusion": "HyDRA\u4e3a\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u65e0\u7ebf\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.12142", "pdf": "https://arxiv.org/pdf/2507.12142", "abs": "https://arxiv.org/abs/2507.12142", "authors": ["Vladimir Bogachev", "Vladimir Aletov", "Alexander Molozhavenko", "Denis Bobkov", "Vera Soboleva", "Aibek Alanov", "Maxim Rakhuba"], "title": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization", "categories": ["cs.LG", "cs.CL", "cs.NA", "math.DG", "math.NA", "68T07, 65F55, 53Z50"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has become a widely adopted standard for\nparameter-efficient fine-tuning of large language models (LLMs), significantly\nreducing memory and computational demands. However, challenges remain,\nincluding finding optimal initialization strategies or mitigating\noverparametrization in low-rank matrix factorization. In this work, we propose\na novel approach that addresses both of the challenges simultaneously within a\nunified framework. Our method treats a set of fixed-rank LoRA matrices as a\nsmooth manifold. Considering adapters as elements on this manifold removes\noverparametrization, while determining the direction of the fastest loss\ndecrease along the manifold provides initialization. Special care is taken to\nobtain numerically stable and computationally efficient implementation of our\nmethod, using best practices from numerical linear algebra and Riemannian\noptimization. Experimental results on LLM and diffusion model architectures\ndemonstrate that RiemannLoRA consistently improves both convergence speed and\nfinal performance over standard LoRA and its state-of-the-art modifications.", "AI": {"tldr": "\u63d0\u51faRiemannLoRA\u65b9\u6cd5\u89e3\u51b3LoRA\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u6807\u51c6LoRA\u53ca\u5176\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3LoRA\u5728\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u5b58\u5728\u7684\u5bfb\u627e\u6700\u4f18\u521d\u59cb\u5316\u7b56\u7565\u548c\u51cf\u8f7b\u4f4e\u79e9\u77e9\u9635\u5206\u89e3\u4e2d\u8fc7\u53c2\u6570\u5316\u7684\u6311\u6218\u3002", "method": "\u5c06\u4e00\u7ec4\u56fa\u5b9a\u79e9\u7684LoRA\u77e9\u9635\u89c6\u4e3a\u5149\u6ed1\u6d41\u5f62\uff0c\u8003\u8651\u9002\u914d\u5668\u4f5c\u4e3a\u6d41\u5f62\u4e0a\u7684\u5143\u7d20\u4ee5\u6d88\u9664\u8fc7\u53c2\u6570\u5316\uff0c\u786e\u5b9a\u6cbf\u6d41\u5f62\u635f\u5931\u4e0b\u964d\u6700\u5feb\u7684\u65b9\u5411\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u5e76\u91c7\u7528\u6570\u503c\u7ebf\u6027\u4ee3\u6570\u548c\u9ece\u66fc\u4f18\u5316\u7684\u6700\u4f73\u5b9e\u8df5\u5b9e\u73b0\u6570\u503c\u7a33\u5b9a\u548c\u8ba1\u7b97\u9ad8\u6548\u3002", "result": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6269\u6563\u6a21\u578b\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRiemannLoRA\u5728\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6027\u80fd\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6LoRA\u53ca\u5176\u6700\u5148\u8fdb\u7684\u6539\u8fdb\u65b9\u6cd5\u3002", "conclusion": "RiemannLoRA\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3LoRA\u73b0\u5b58\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.11730", "pdf": "https://arxiv.org/pdf/2507.11730", "abs": "https://arxiv.org/abs/2507.11730", "authors": ["Maciej Szankin", "Vidhyananth Venkatasamy", "Lihang Ying"], "title": "Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Outdoor advertisements remain a critical medium for modern marketing, yet\naccurately verifying billboard text visibility under real-world conditions is\nstill challenging. Traditional Optical Character Recognition (OCR) pipelines\nexcel at cropped text recognition but often struggle with complex outdoor\nscenes, varying fonts, and weather-induced visual noise. Recently, multimodal\nVision-Language Models (VLMs) have emerged as promising alternatives, offering\nend-to-end scene understanding with no explicit detection step. This work\nsystematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,\nInternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline\n(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with\nsynthetic weather distortions to simulate realistic degradation. Our results\nreveal that while selected VLMs excel at holistic scene reasoning, lightweight\nCNN pipelines still achieve competitive accuracy for cropped text at a fraction\nof the computational cost-an important consideration for edge deployment. To\nfoster future research, we release our weather-augmented benchmark and\nevaluation code publicly.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4ee3\u8868\u6027\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u7d27\u51d1\u578b\u57fa\u4e8eCNN\u7684OCR\u57fa\u7ebf\u5728\u542b\u5408\u6210\u5929\u6c14\u5931\u771f\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u8f7b\u91cf\u7ea7CNN\u7ba1\u9053\u5728\u88c1\u526a\u6587\u672c\u8bc6\u522b\u4e0a\u4ecd\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u516c\u5f00\u4e86\u57fa\u51c6\u548c\u8bc4\u4f30\u4ee3\u7801\u3002", "motivation": "\u6237\u5916\u5e7f\u544a\u662f\u91cd\u8981\u8425\u9500\u5a92\u4ecb\uff0c\u4f46\u51c6\u786e\u9a8c\u8bc1\u73b0\u5b9e\u6761\u4ef6\u4e0b\u5e7f\u544a\u724c\u6587\u672c\u53ef\u89c1\u6027\u6709\u6311\u6218\uff0c\u4f20\u7edfOCR\u7ba1\u9053\u5728\u590d\u6742\u6237\u5916\u573a\u666f\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6709\u6f5c\u529b\u3002", "method": "\u5728\u4e24\u4e2a\u516c\u5171\u6570\u636e\u96c6\uff08ICDAR 2015\u548cSVT\uff09\u4e0a\uff0c\u7528\u5408\u6210\u5929\u6c14\u5931\u771f\u589e\u5f3a\u6570\u636e\uff0c\u5bf9Qwen 2.5 VL 3B\u3001InternVL3\u548cSmolVLM2\u7b49\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0ePaddleOCRv4\u8fdb\u884c\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6240\u9009\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u6574\u4f53\u573a\u666f\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u8f7b\u91cf\u7ea7CNN\u7ba1\u9053\u5728\u88c1\u526a\u6587\u672c\u8bc6\u522b\u4e0a\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u8fbe\u5230\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u4e3a\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\uff0c\u516c\u5f00\u5929\u6c14\u589e\u5f3a\u7684\u57fa\u51c6\u548c\u8bc4\u4f30\u4ee3\u7801\u3002"}}
{"id": "2507.12144", "pdf": "https://arxiv.org/pdf/2507.12144", "abs": "https://arxiv.org/abs/2507.12144", "authors": ["Boris Bonev", "Thorsten Kurth", "Ankur Mahesh", "Mauro Bisson", "Jean Kossaifi", "Karthik Kashinath", "Anima Anandkumar", "William D. Collins", "Michael S. Pritchard", "Alexander Keller"], "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale", "categories": ["cs.LG", "physics.ao-ph", "86-10, 68T07", "I.2.1; I.6.5; G.3"], "comment": null, "summary": "FourCastNet 3 advances global weather modeling by implementing a scalable,\ngeometric machine learning (ML) approach to probabilistic ensemble forecasting.\nThe approach is designed to respect spherical geometry and to accurately model\nthe spatially correlated probabilistic nature of the problem, resulting in\nstable spectra and realistic dynamics across multiple scales. FourCastNet 3\ndelivers forecasting accuracy that surpasses leading conventional ensemble\nmodels and rivals the best diffusion-based methods, while producing forecasts 8\nto 60 times faster than these approaches. In contrast to other ML approaches,\nFourCastNet 3 demonstrates excellent probabilistic calibration and retains\nrealistic spectra, even at extended lead times of up to 60 days. All of these\nadvances are realized using a purely convolutional neural network architecture\ntailored for spherical geometry. Scalable and efficient large-scale training on\n1024 GPUs and more is enabled by a novel training paradigm for combined model-\nand data-parallelism, inspired by domain decomposition methods in classical\nnumerical models. Additionally, FourCastNet 3 enables rapid inference on a\nsingle GPU, producing a 90-day global forecast at 0.25{\\deg}, 6-hourly\nresolution in under 20 seconds. Its computational efficiency, medium-range\nprobabilistic skill, spectral fidelity, and rollout stability at subseasonal\ntimescales make it a strong candidate for improving meteorological forecasting\nand early warning systems through large ensemble predictions.", "AI": {"tldr": "FourCastNet 3\u6539\u8fdb\u5168\u7403\u5929\u6c14\u5efa\u6a21\uff0c\u7528\u51e0\u4f55\u673a\u5668\u5b66\u4e60\u5b9e\u73b0\u6982\u7387\u96c6\u5408\u9884\u62a5\uff0c\u6027\u80fd\u8d85\u4f20\u7edf\u6a21\u578b\u4e14\u901f\u5ea6\u5feb\uff0c\u9002\u7528\u4e8e\u6c14\u8c61\u9884\u62a5\u548c\u9884\u8b66\u7cfb\u7edf\u3002", "motivation": "\u6539\u8fdb\u5168\u7403\u5929\u6c14\u5efa\u6a21\uff0c\u63d0\u5347\u6982\u7387\u96c6\u5408\u9884\u62a5\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u91c7\u7528\u9002\u5e94\u7403\u9762\u51e0\u4f55\u7684\u7eaf\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7ed3\u5408\u6a21\u578b\u548c\u6570\u636e\u5e76\u884c\u7684\u65b0\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "\u9884\u62a5\u51c6\u786e\u6027\u8d85\u4f20\u7edf\u96c6\u5408\u6a21\u578b\uff0c\u901f\u5ea6\u5feb8 - 60\u500d\uff0c\u6982\u7387\u6821\u51c6\u51fa\u8272\uff0c\u80fd\u4fdd\u6301\u771f\u5b9e\u5149\u8c31\uff0c\u5355GPU\u63a8\u7406\u9ad8\u6548\u3002", "conclusion": "FourCastNet 3\u56e0\u8ba1\u7b97\u6548\u7387\u3001\u6982\u7387\u6280\u80fd\u7b49\u4f18\u52bf\uff0c\u9002\u5408\u7528\u4e8e\u6539\u8fdb\u6c14\u8c61\u9884\u62a5\u548c\u9884\u8b66\u7cfb\u7edf\u3002"}}
{"id": "2507.11742", "pdf": "https://arxiv.org/pdf/2507.11742", "abs": "https://arxiv.org/abs/2507.11742", "authors": ["Meng Li", "Timothy M. McPhillips", "Dingmin Wang", "Shin-Rong Tsai", "Bertram Lud\u00e4scher"], "title": "CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint. Accepted to COLM 2025", "summary": "Recognizing the information flows and operations comprising data science and\nmachine learning Python notebooks is critical for evaluating, reusing, and\nadapting notebooks for new tasks. Investigating a notebook via re-execution\noften is impractical due to the challenges of resolving data and software\ndependencies. While Large Language Models (LLMs) pre-trained on large codebases\nhave demonstrated effectiveness in understanding code without running it, we\nobserve that they fail to understand some realistic notebooks due to\nhallucinations and long-context challenges. To address these issues, we propose\na notebook understanding task yielding an information flow graph and\ncorresponding cell execution dependency graph for a notebook, and demonstrate\nthe effectiveness of a pincer strategy that uses limited syntactic analysis to\nassist full comprehension of the notebook using an LLM. Our Capture and Resolve\nAssisted Bounding Strategy (CRABS) employs shallow syntactic parsing and\nanalysis of the abstract syntax tree (AST) to capture the correct\ninterpretation of a notebook between lower and upper estimates of the\ninter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via\ncell-by-cell zero-shot learning, thereby identifying the true data inputs and\noutputs of each cell. We evaluate and demonstrate the effectiveness of our\napproach using an annotated dataset of 50 representative, highly up-voted\nKaggle notebooks that together represent 3454 actual cell inputs and outputs.\nThe LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the\nsyntactic structure of these notebooks. Across 50 notebooks, CRABS achieves\naverage F1 scores of 98% identifying cell-to-cell information flows and 99%\nidentifying transitive cell execution dependencies.", "AI": {"tldr": "\u63d0\u51faCRABS\u7b56\u7565\u7406\u89e3Python\u7b14\u8bb0\u672c\uff0c\u7528Kaggle\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7406\u89e3Python\u7b14\u8bb0\u672c\u5b58\u5728\u5e7b\u89c9\u548c\u957f\u4e0a\u4e0b\u6587\u6311\u6218\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u8bc4\u4f30\u3001\u590d\u7528\u548c\u9002\u914d\u7b14\u8bb0\u672c\u3002", "method": "\u63d0\u51fa\u7b14\u8bb0\u672c\u7406\u89e3\u4efb\u52a1\uff0c\u91c7\u7528CRABS\u7b56\u7565\uff0c\u7ed3\u5408\u8bed\u6cd5\u5206\u6790\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6d45\u8bed\u6cd5\u89e3\u6790\u548c\u62bd\u8c61\u8bed\u6cd5\u6811\u5206\u6790\u6355\u6349\u4fe1\u606f\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6d88\u9664\u6b67\u4e49\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u4e8698%\u7684\u6b67\u4e49\uff0cCRABS\u8bc6\u522b\u4fe1\u606f\u6d41\u548c\u6267\u884c\u4f9d\u8d56\u7684F1\u5206\u6570\u5206\u522b\u8fbe98%\u548c99%\u3002", "conclusion": "CRABS\u7b56\u7565\u5728\u7406\u89e3Python\u7b14\u8bb0\u672c\u7684\u4fe1\u606f\u6d41\u52a8\u548c\u6267\u884c\u4f9d\u8d56\u65b9\u9762\u6709\u6548\u3002"}}
{"id": "2507.12145", "pdf": "https://arxiv.org/pdf/2507.12145", "abs": "https://arxiv.org/abs/2507.12145", "authors": ["Muhammad Azlan Qazi", "Alexandros Iosifidis", "Qi Zhang"], "title": "PRISM: Distributed Inference for Foundation Models at Edge", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Foundation models (FMs) have achieved remarkable success across a wide range\nof applications, from image classification to natural langurage processing, but\npose significant challenges for deployment at edge. This has sparked growing\ninterest in developing practical and efficient strategies for bringing\nfoundation models to edge environments. In this work, we propose PRISM, a\ncommunication-efficient and compute-aware strategy for distributed Transformer\ninference on edge devices. Our method leverages a Segment Means representation\nto approximate intermediate output features, drastically reducing inter-device\ncommunication. Additionally, we restructure the self-attention mechanism to\neliminate redundant computations caused by per-device Key/Value calculation in\nposition-wise partitioning and design a partition-aware causal masking scheme\ntailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2\nacross diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and\nCBT. Our results demonstrate substantial reductions in communication overhead\n(up to 99.2% for BERT at compression rate CR = 128) and per-device computation\n(51.24% for BERT at the same setting), with only minor accuracy degradation.\nThis method offers a scalable and practical solution for deploying foundation\nmodels in distributed resource-constrained environments.", "AI": {"tldr": "\u63d0\u51faPRISM\u7b56\u7565\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5206\u5e03\u5f0fTransformer\u63a8\u7406\uff0c\u51cf\u5c11\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u7cbe\u5ea6\u635f\u5931\u5c0f\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u8fb9\u7f18\u90e8\u7f72\u6709\u6311\u6218\uff0c\u9700\u5f00\u53d1\u5b9e\u7528\u9ad8\u6548\u7b56\u7565\u5c06\u5176\u5f15\u5165\u8fb9\u7f18\u73af\u5883\u3002", "method": "\u5229\u7528Segment Means\u8868\u793a\u8fd1\u4f3c\u4e2d\u95f4\u8f93\u51fa\u7279\u5f81\uff0c\u91cd\u7ec4\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8bbe\u8ba1\u5206\u533a\u611f\u77e5\u56e0\u679c\u63a9\u7801\u65b9\u6848\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u901a\u4fe1\u5f00\u9500\u6700\u591a\u51cf\u5c1199.2%\uff0c\u5355\u8bbe\u5907\u8ba1\u7b97\u91cf\u51cf\u5c1151.24%\uff0c\u7cbe\u5ea6\u4ec5\u6709\u8f7b\u5fae\u4e0b\u964d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u5206\u5e03\u5f0f\u8d44\u6e90\u53d7\u9650\u73af\u5883\u90e8\u7f72\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u53ef\u6269\u5c55\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2507.12165", "pdf": "https://arxiv.org/pdf/2507.12165", "abs": "https://arxiv.org/abs/2507.12165", "authors": ["Fouad Oubari", "Mohamed El-Baha", "Raphael Meunier", "Rodrigue D\u00e9catoire", "Mathilde Mougeot"], "title": "Multi-Component VAE with Gaussian Markov Random Field", "categories": ["cs.LG"], "comment": null, "summary": "Multi-component datasets with intricate dependencies, like industrial\nassemblies or multi-modal imaging, challenge current generative modeling\ntechniques. Existing Multi-component Variational AutoEncoders typically rely on\nsimplified aggregation strategies, neglecting critical nuances and consequently\ncompromising structural coherence across generated components. To explicitly\naddress this gap, we introduce the Gaussian Markov Random Field Multi-Component\nVariational AutoEncoder , a novel generative framework embedding Gaussian\nMarkov Random Fields into both prior and posterior distributions. This design\nchoice explicitly models cross-component relationships, enabling richer\nrepresentation and faithful reproduction of complex interactions. Empirically,\nour GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula\ndataset specifically constructed to evaluate intricate component relationships,\ndemonstrates competitive results on the PolyMNIST benchmark, and significantly\nenhances structural coherence on the real-world BIKED dataset. Our results\nindicate that the GMRF MCVAE is especially suited for practical applications\ndemanding robust and realistic modeling of multi-component coherence", "AI": {"tldr": "\u63d0\u51faGMRF MCVAE\u89e3\u51b3\u591a\u7ec4\u4ef6\u6570\u636e\u96c6\u751f\u6210\u5efa\u6a21\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u73b0\u826f\u597d\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u591a\u7ec4\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u4f9d\u8d56\u7b80\u5316\u805a\u5408\u7b56\u7565\uff0c\u5ffd\u7565\u5173\u952e\u7ec6\u5fae\u5dee\u522b\uff0c\u635f\u5bb3\u751f\u6210\u7ec4\u4ef6\u7684\u7ed3\u6784\u8fde\u8d2f\u6027\u3002", "method": "\u5f15\u5165\u9ad8\u65af\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u591a\u7ec4\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08GMRF MCVAE\uff09\uff0c\u5c06\u9ad8\u65af\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u5d4c\u5165\u5148\u9a8c\u548c\u540e\u9a8c\u5206\u5e03\uff0c\u663e\u5f0f\u5efa\u6a21\u7ec4\u4ef6\u95f4\u5173\u7cfb\u3002", "result": "\u5728\u5408\u6210Copula\u6570\u636e\u96c6\u4e0a\u8fbeSOTA\uff0c\u5728PolyMNIST\u57fa\u51c6\u6d4b\u8bd5\u6709\u7ade\u4e89\u529b\uff0c\u5728\u771f\u5b9eBIKED\u6570\u636e\u96c6\u4e0a\u663e\u8457\u589e\u5f3a\u7ed3\u6784\u8fde\u8d2f\u6027\u3002", "conclusion": "GMRF MCVAE\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u5bf9\u591a\u7ec4\u4ef6\u8fde\u8d2f\u6027\u8fdb\u884c\u7a33\u5065\u548c\u903c\u771f\u5efa\u6a21\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.11761", "pdf": "https://arxiv.org/pdf/2507.11761", "abs": "https://arxiv.org/abs/2507.11761", "authors": ["Fan Shi", "Bin Li", "Xiangyang Xue"], "title": "Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Abstract visual reasoning (AVR) enables humans to quickly discover and\ngeneralize abstract rules to new scenarios. Designing intelligent systems with\nhuman-like AVR abilities has been a long-standing topic in the artificial\nintelligence community. Deep AVR solvers have recently achieved remarkable\nsuccess in various AVR tasks. However, they usually use task-specific designs\nor parameters in different tasks. In such a paradigm, solving new tasks often\nmeans retraining the model, and sometimes retuning the model architectures,\nwhich increases the cost of solving AVR problems. In contrast to task-specific\napproaches, this paper proposes a novel Unified Conditional Generative Solver\n(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we\nprove that some well-known AVR tasks can be reformulated as the problem of\nestimating the predictability of target images in problem panels. Then, we\nillustrate that, under the proposed framework, training one conditional\ngenerative model can solve various AVR tasks. The experiments show that with a\nsingle round of multi-task training, UCGS demonstrates abstract reasoning\nability across various AVR tasks. Especially, UCGS exhibits the ability of\nzero-shot reasoning, enabling it to perform abstract reasoning on problems from\nunseen AVR tasks in the testing phase.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u6761\u4ef6\u751f\u6210\u6c42\u89e3\u5668UCGS\u5904\u7406\u591a\u62bd\u8c61\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\uff0c\u5355\u8f6e\u591a\u4efb\u52a1\u8bad\u7ec3\u540e\u6709\u8de8\u4efb\u52a1\u63a8\u7406\u80fd\u529b\u53ca\u96f6\u6837\u672c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6AVR\u6c42\u89e3\u5668\u9488\u5bf9\u4e0d\u540c\u4efb\u52a1\u6709\u7279\u5b9a\u8bbe\u8ba1\u6216\u53c2\u6570\uff0c\u89e3\u51b3\u65b0\u4efb\u52a1\u9700\u91cd\u65b0\u8bad\u7ec3\u751a\u81f3\u8c03\u6574\u67b6\u6784\uff0c\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u8bc1\u660e\u90e8\u5206AVR\u4efb\u52a1\u53ef\u8f6c\u5316\u4e3a\u4f30\u8ba1\u95ee\u9898\u9762\u677f\u4e2d\u76ee\u6807\u56fe\u50cf\u53ef\u9884\u6d4b\u6027\u95ee\u9898\uff0c\u8bf4\u660e\u5728\u6846\u67b6\u4e0b\u8bad\u7ec3\u4e00\u4e2a\u6761\u4ef6\u751f\u6210\u6a21\u578b\u53ef\u89e3\u51b3\u591a\u79cdAVR\u4efb\u52a1\u3002", "result": "UCGS\u5355\u8f6e\u591a\u4efb\u52a1\u8bad\u7ec3\u540e\u5c55\u73b0\u8de8\u591a\u79cdAVR\u4efb\u52a1\u7684\u62bd\u8c61\u63a8\u7406\u80fd\u529b\uff0c\u6709\u96f6\u6837\u672c\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "UCGS\u80fd\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u89e3\u51b3\u591a\u4e2aAVR\u4efb\u52a1\uff0c\u5177\u5907\u8de8\u4efb\u52a1\u548c\u96f6\u6837\u672c\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2507.12166", "pdf": "https://arxiv.org/pdf/2507.12166", "abs": "https://arxiv.org/abs/2507.12166", "authors": ["Xiucheng Wang", "Qiming Zhang", "Nan Cheng", "Junting Chen", "Zezhong Zhang", "Zan Li", "Shuguang Cui", "Xuemin Shen"], "title": "RadioDiff-3D: A 3D$\\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Radio maps (RMs) serve as a critical foundation for enabling\nenvironment-aware wireless communication, as they provide the spatial\ndistribution of wireless channel characteristics. Despite recent progress in RM\nconstruction using data-driven approaches, most existing methods focus solely\non pathloss prediction in a fixed 2D plane, neglecting key parameters such as\ndirection of arrival (DoA), time of arrival (ToA), and vertical spatial\nvariations. Such a limitation is primarily due to the reliance on static\nlearning paradigms, which hinder generalization beyond the training data\ndistribution. To address these challenges, we propose UrbanRadio3D, a\nlarge-scale, high-resolution 3D RM dataset constructed via ray tracing in\nrealistic urban environments. UrbanRadio3D is over 37$\\times$3 larger than\nprevious datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,\nforming a novel 3D$\\times$33D dataset with 7$\\times$3 more height layers than\nprior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet\nwith 3D convolutional operators is proposed. Moreover, we further introduce\nRadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D\nconvolutional architecture. RadioDiff-3D supports both radiation-aware\nscenarios with known transmitter locations and radiation-unaware settings based\non sparse spatial observations. Extensive evaluations on UrbanRadio3D validate\nthat RadioDiff-3D achieves superior performance in constructing rich,\nhigh-dimensional radio maps under diverse environmental dynamics. This work\nprovides a foundational dataset and benchmark for future research in 3D\nenvironment-aware communication. The dataset is available at\nhttps://github.com/UNIC-Lab/UrbanRadio3D.", "AI": {"tldr": "\u63d0\u51faUrbanRadio3D\u6570\u636e\u96c6\u548cUNet\u3001RadioDiff - 3D\u65b9\u6cd5\u7528\u4e8e3D\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\uff0c\u8bc4\u4f30\u663e\u793aRadioDiff - 3D\u6027\u80fd\u4f18\u8d8a\uff0c\u63d0\u4f9b\u57fa\u7840\u6570\u636e\u96c6\u548c\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u7684\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\u591a\u5173\u6ce82D\u5e73\u9762\u8def\u5f84\u635f\u8017\u9884\u6d4b\uff0c\u5ffd\u7565\u5173\u952e\u53c2\u6570\uff0c\u4e14\u4f9d\u8d56\u9759\u6001\u5b66\u4e60\u8303\u5f0f\u7f3a\u4e4f\u6cdb\u5316\u6027\u3002", "method": "\u6784\u5efaUrbanRadio3D\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u75283D\u5377\u79ef\u7b97\u5b50\u7684UNet\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5f15\u5165\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684RadioDiff - 3D\u751f\u6210\u6846\u67b6\u3002", "result": "\u5728UrbanRadio3D\u4e0a\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cRadioDiff - 3D\u5728\u4e0d\u540c\u73af\u5883\u52a8\u6001\u4e0b\u6784\u5efa\u9ad8\u7ef4\u65e0\u7ebf\u7535\u5730\u56fe\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "\u672c\u5de5\u4f5c\u4e3a3D\u73af\u5883\u611f\u77e5\u901a\u4fe1\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u6570\u636e\u96c6\u548c\u57fa\u51c6\u3002"}}
{"id": "2507.11773", "pdf": "https://arxiv.org/pdf/2507.11773", "abs": "https://arxiv.org/abs/2507.11773", "authors": ["Maren Hackenberg", "Sophia G. Connor", "Fabian Kabus", "June Brawner", "Ella Markham", "Mahi Hardalupas", "Areeq Chowdhury", "Rolf Backofen", "Anna K\u00f6ttgen", "Angelika Rohde", "Nadine Binder", "Harald Binder", "the Collaborative Research Center 1597 Small Data"], "title": "Small Data Explainer -- The impact of small data methods in everyday life", "categories": ["cs.CY", "cs.AI"], "comment": "Written in collaboration with the Royal Society, contributing to the\n  Disability Technology report\n  (https://royalsociety.org/news-resources/projects/disability-data-assistive-technology/)", "summary": "The emergence of breakthrough artificial intelligence (AI) techniques has led\nto a renewed focus on how small data settings, i.e., settings with limited\ninformation, can benefit from such developments. This includes societal issues\nsuch as how best to include under-represented groups in data-driven policy and\ndecision making, or the health benefits of assistive technologies such as\nwearables. We provide a conceptual overview, in particular contrasting small\ndata with big data, and identify common themes from exemplary case studies and\napplication areas. Potential solutions are described in a more detailed\ntechnical overview of current data analysis and modelling techniques,\nhighlighting contributions from different disciplines, such as knowledge-driven\nmodelling from statistics and data-driven modelling from computer science. By\nlinking application settings, conceptual contributions and specific techniques,\nwe highlight what is already feasible and suggest what an agenda for fully\nleveraging small data might look like.", "AI": {"tldr": "\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u6280\u672f\u4e0b\u5c0f\u6570\u636e\u8bbe\u7f6e\u7684\u76ca\u5904\uff0c\u5bf9\u6bd4\u5927\u5c0f\u6570\u636e\uff0c\u5206\u6790\u6848\u4f8b\uff0c\u4ecb\u7ecd\u6280\u672f\u5e76\u63d0\u51fa\u5229\u7528\u5c0f\u6570\u636e\u7684\u8bae\u7a0b\u3002", "motivation": "\u5728\u7a81\u7834\u6027\u4eba\u5de5\u667a\u80fd\u6280\u672f\u51fa\u73b0\u80cc\u666f\u4e0b\uff0c\u7814\u7a76\u5c0f\u6570\u636e\u8bbe\u7f6e\u5982\u4f55\u4ece\u4e2d\u53d7\u76ca\uff0c\u89e3\u51b3\u793e\u4f1a\u95ee\u9898\u3002", "method": "\u6982\u5ff5\u6027\u6982\u8ff0\uff0c\u5bf9\u6bd4\u5927\u5c0f\u6570\u636e\uff0c\u5206\u6790\u6848\u4f8b\uff0c\u6280\u672f\u5c42\u9762\u4ecb\u7ecd\u6570\u636e\u5206\u6790\u548c\u5efa\u6a21\u6280\u672f\u3002", "result": "\u660e\u786e\u4e86\u5f53\u524d\u53ef\u884c\u7684\u65b9\u5411\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5145\u5206\u5229\u7528\u5c0f\u6570\u636e\u7684\u8bae\u7a0b\u8bbe\u60f3\u3002"}}
{"id": "2507.12192", "pdf": "https://arxiv.org/pdf/2507.12192", "abs": "https://arxiv.org/abs/2507.12192", "authors": ["Victor F. Lopes de Souza", "Karima Bakhti", "Sofiane Ramdani", "Denis Mottet", "Abdelhak Imoussaten"], "title": "Explainable Evidential Clustering", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised classification is a fundamental machine learning problem.\nReal-world data often contain imperfections, characterized by uncertainty and\nimprecision, which are not well handled by traditional methods. Evidential\nclustering, based on Dempster-Shafer theory, addresses these challenges. This\npaper explores the underexplored problem of explaining evidential clustering\nresults, which is crucial for high-stakes domains such as healthcare. Our\nanalysis shows that, in the general case, representativity is a necessary and\nsufficient condition for decision trees to serve as abductive explainers.\nBuilding on the concept of representativity, we generalize this idea to\naccommodate partial labeling through utility functions. These functions enable\nthe representation of \"tolerable\" mistakes, leading to the definition of\nevidential mistakeness as explanation cost and the construction of explainers\ntailored to evidential classifiers. Finally, we propose the Iterative\nEvidential Mistake Minimization (IEMM) algorithm, which provides interpretable\nand cautious decision tree explanations for evidential clustering functions. We\nvalidate the proposed algorithm on synthetic and real-world data. Taking into\naccount the decision-maker's preferences, we were able to provide an\nexplanation that was satisfactory up to 93% of the time.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u8bc1\u636e\u805a\u7c7b\u7ed3\u679c\u89e3\u91ca\u95ee\u9898\uff0c\u63d0\u51faIEMM\u7b97\u6cd5\u5e76\u9a8c\u8bc1\uff0c\u80fd\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u63d0\u4f9b\u4ee4\u51b3\u7b56\u8005\u6ee1\u610f\u7684\u89e3\u91ca", "motivation": "\u73b0\u5b9e\u6570\u636e\u6709\u4e0d\u786e\u5b9a\u6027\u548c\u4e0d\u7cbe\u786e\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u5904\u7406\uff0c\u4e14\u8bc1\u636e\u805a\u7c7b\u7ed3\u679c\u89e3\u91ca\u95ee\u9898\u7814\u7a76\u4e0d\u8db3\uff0c\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5f88\u5173\u952e", "method": "\u5206\u6790\u5f97\u51fa\u4ee3\u8868\u6027\u662f\u51b3\u7b56\u6811\u4f5c\u4e3a\u6eaf\u56e0\u89e3\u91ca\u5668\u7684\u5145\u8981\u6761\u4ef6\uff0c\u901a\u8fc7\u6548\u7528\u51fd\u6570\u63a8\u5e7f\u4ee3\u8868\u6027\u6982\u5ff5\uff0c\u5b9a\u4e49\u8bc1\u636e\u9519\u8bef\u6027\u4e3a\u89e3\u91ca\u6210\u672c\uff0c\u6784\u5efa\u89e3\u91ca\u5668\uff0c\u63d0\u51faIEMM\u7b97\u6cd5", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86IEMM\u7b97\u6cd5\uff0c\u8003\u8651\u51b3\u7b56\u8005\u504f\u597d\u65f6\uff0c\u9ad8\u8fbe93%\u7684\u65f6\u95f4\u80fd\u63d0\u4f9b\u6ee1\u610f\u89e3\u91ca", "conclusion": "IEMM\u7b97\u6cd5\u53ef\u4e3a\u8bc1\u636e\u805a\u7c7b\u51fd\u6570\u63d0\u4f9b\u53ef\u89e3\u91ca\u4e14\u8c28\u614e\u7684\u51b3\u7b56\u6811\u89e3\u91ca"}}
{"id": "2507.11775", "pdf": "https://arxiv.org/pdf/2507.11775", "abs": "https://arxiv.org/abs/2507.11775", "authors": ["Wesley dos Reis Bezerra", "Lais Machado Bezerra", "Carlos Becker Westphall"], "title": "Challenges in GenAI and Authentication: a scoping review", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Authentication and authenticity have been a security challenge since the\nbeginning of information sharing, especially in the context of digital\ninformation. With the advancement of generative artificial intelligence, these\nchallenges have evolved, demanding a more up-to-date analysis of their impacts\non society and system security. This work presents a scoping review that\nanalyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,\npromoting an analysis of the resulting portfolio through six guiding questions\nfocusing on the most relevant work, challenges, attack surfaces, threats,\nproposed solutions, and gaps. Finally, the portfolio articles are analyzed\nthrough this guiding research lens and also receive individualized analysis.\nThe results consistently outline the challenges, gaps, and threats related to\nimages, text, audio, and video, thereby supporting new research in the areas of\nauthentication and generative artificial intelligence.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8ba4\u8bc1\u548c\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u76f8\u5173\u6587\u732e\u8fdb\u884c\u8303\u56f4\u5ba1\u67e5\uff0c\u5206\u6790\u76f8\u5173\u6311\u6218\u3001\u5a01\u80c1\u7b49\uff0c\u652f\u6301\u65b0\u7814\u7a76\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\uff0c\u8ba4\u8bc1\u548c\u771f\u5b9e\u6027\u5b89\u5168\u6311\u6218\u6f14\u53d8\uff0c\u9700\u66f4\u65b0\u5206\u6790\u5176\u5bf9\u793e\u4f1a\u548c\u7cfb\u7edf\u5b89\u5168\u7684\u5f71\u54cd\u3002", "method": "\u5bf9IEEExplorer\u3001Scopus\u548cACM\u6570\u636e\u5e93\u768488\u7bc7\u6587\u732e\u8fdb\u884c\u8303\u56f4\u5ba1\u67e5\uff0c\u901a\u8fc7\u516d\u4e2a\u5f15\u5bfc\u95ee\u9898\u5206\u6790\u7ed3\u679c\u7ec4\u5408\uff0c\u5e76\u5bf9\u6587\u7ae0\u8fdb\u884c\u5355\u72ec\u5206\u6790\u3002", "result": "\u660e\u786e\u4e86\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u9891\u76f8\u5173\u7684\u6311\u6218\u3001\u5dee\u8ddd\u548c\u5a01\u80c1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u8ba4\u8bc1\u548c\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u65b0\u7814\u7a76\u3002"}}
{"id": "2507.12196", "pdf": "https://arxiv.org/pdf/2507.12196", "abs": "https://arxiv.org/abs/2507.12196", "authors": ["Nikolaos Louloudakis", "Ajitha Rajan"], "title": "Selective Quantization Tuning for ONNX Models", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "5 pages, 3 figures, 2 tables", "summary": "Quantization is a process that reduces the precision of deep neural network\nmodels to lower model size and computational demands, often at the cost of\naccuracy. However, fully quantized models may exhibit sub-optimal performance\nbelow acceptable levels and face deployment challenges on low-end hardware\naccelerators due to practical constraints. To address these issues,\nquantization can be selectively applied to only a subset of layers, but\nselecting which layers to exclude is non-trivial. To this direction, we propose\nTuneQn, a suite enabling selective quantization, deployment and execution of\nONNX models across various CPU and GPU devices, combined with profiling and\nmulti-objective optimization. TuneQn generates selectively quantized ONNX\nmodels, deploys them on different hardware, measures performance on metrics\nlike accuracy and size, performs Pareto Front minimization to identify the best\nmodel candidate and visualizes the results. To demonstrate the effectiveness of\nTuneQn, we evaluated TuneQn on four ONNX models with two quantization settings\nacross CPU and GPU devices. As a result, we demonstrated that our utility\neffectively performs selective quantization and tuning, selecting ONNX model\ncandidates with up to a $54.14$% reduction in accuracy loss compared to the\nfully quantized model, and up to a $72.9$% model size reduction compared to the\noriginal model.", "AI": {"tldr": "\u63d0\u51faTuneQn\u5de5\u5177\u5b9e\u73b0ONNX\u6a21\u578b\u9009\u62e9\u6027\u91cf\u5316\uff0c\u7ecf\u8bc4\u4f30\u53ef\u6709\u6548\u51cf\u5c11\u7cbe\u5ea6\u635f\u5931\u548c\u6a21\u578b\u5927\u5c0f\u3002", "motivation": "\u5168\u91cf\u5316\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u4e14\u5728\u4f4e\u7aef\u786c\u4ef6\u90e8\u7f72\u6709\u6311\u6218\uff0c\u9009\u62e9\u4e0d\u91cf\u5316\u7684\u5c42\u6709\u96be\u5ea6\u3002", "method": "\u63d0\u51faTuneQn\u5de5\u5177\uff0c\u751f\u6210\u9009\u62e9\u6027\u91cf\u5316\u7684ONNX\u6a21\u578b\uff0c\u5728\u4e0d\u540c\u786c\u4ef6\u90e8\u7f72\uff0c\u6d4b\u91cf\u6027\u80fd\u6307\u6807\uff0c\u8fdb\u884cPareto Front\u6700\u5c0f\u5316\u3002", "result": "\u5728\u56db\u4e2aONNX\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u5168\u91cf\u5316\u6a21\u578b\u76f8\u6bd4\u7cbe\u5ea6\u635f\u5931\u6700\u591a\u964d\u4f4e54.14%\uff0c\u4e0e\u539f\u6a21\u578b\u76f8\u6bd4\u6a21\u578b\u5927\u5c0f\u6700\u591a\u51cf\u5c1172.9%\u3002", "conclusion": "TuneQn\u80fd\u6709\u6548\u8fdb\u884c\u9009\u62e9\u6027\u91cf\u5316\u548c\u8c03\u4f18\u3002"}}
{"id": "2507.12218", "pdf": "https://arxiv.org/pdf/2507.12218", "abs": "https://arxiv.org/abs/2507.12218", "authors": ["Tomohisa Okazaki"], "title": "Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Many physical systems are described by partial differential equations (PDEs),\nand solving these equations and estimating their coefficients or boundary\nconditions (BCs) from observational data play a crucial role in understanding\nthe associated phenomena. Recently, a machine learning approach known as\nphysics-informed neural network, which solves PDEs using neural networks by\nminimizing the sum of residuals from the PDEs, BCs, and data, has gained\nsignificant attention in the scientific community. In this study, we\ninvestigate a physics-informed linear model (PILM) that uses linear\ncombinations of basis functions to represent solutions, thereby enabling an\nanalytical representation of optimal solutions. The PILM was formulated and\nverified for illustrative forward and inverse problems including cases with\nuncertain BCs. Furthermore, the PILM was applied to estimate crustal strain\nrates using geodetic data. Specifically, physical regularization that enforces\nelastic equilibrium on the velocity fields was compared with mathematical\nregularization that imposes smoothness constraints. From a Bayesian\nperspective, mathematical regularization exhibited superior performance. The\nPILM provides an analytically solvable framework applicable to linear forward\nand inverse problems, underdetermined systems, and physical regularization.", "AI": {"tldr": "\u7814\u7a76\u7269\u7406\u4fe1\u606f\u7ebf\u6027\u6a21\u578b\uff08PILM\uff09\u7528\u4e8e\u89e3\u51b3\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6b63\u53cd\u95ee\u9898\uff0c\u8fd8\u7528\u4e8e\u4f30\u8ba1\u5730\u58f3\u5e94\u53d8\u7387\uff0c\u6570\u5b66\u6b63\u5219\u5316\u8868\u73b0\u66f4\u4f18\uff0cPILM\u63d0\u4f9b\u53ef\u89e3\u6790\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u504f\u5fae\u5206\u65b9\u7a0b\u5e76\u4ece\u89c2\u6d4b\u6570\u636e\u4f30\u8ba1\u5176\u7cfb\u6570\u6216\u8fb9\u754c\u6761\u4ef6\u5bf9\u7406\u89e3\u76f8\u5173\u73b0\u8c61\u81f3\u5173\u91cd\u8981\uff0c\u63a2\u7d22\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u7ebf\u6027\u6a21\u578b\uff08PILM\uff09\uff0c\u7528\u57fa\u51fd\u6570\u7ebf\u6027\u7ec4\u5408\u8868\u793a\u89e3\uff0c\u9488\u5bf9\u6b63\u53cd\u95ee\u9898\u8fdb\u884c\u516c\u5f0f\u5316\u548c\u9a8c\u8bc1\uff0c\u6bd4\u8f83\u7269\u7406\u6b63\u5219\u5316\u548c\u6570\u5b66\u6b63\u5219\u5316\u3002", "result": "PILM\u53ef\u7528\u4e8e\u7ebf\u6027\u6b63\u53cd\u95ee\u9898\u3001\u6b20\u5b9a\u7cfb\u7edf\u548c\u7269\u7406\u6b63\u5219\u5316\uff0c\u4ece\u8d1d\u53f6\u65af\u89d2\u5ea6\uff0c\u6570\u5b66\u6b63\u5219\u5316\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "PILM\u4e3a\u7ebf\u6027\u6b63\u53cd\u95ee\u9898\u3001\u6b20\u5b9a\u7cfb\u7edf\u548c\u7269\u7406\u6b63\u5219\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u6790\u6c42\u89e3\u7684\u6846\u67b6\u3002"}}
{"id": "2507.11783", "pdf": "https://arxiv.org/pdf/2507.11783", "abs": "https://arxiv.org/abs/2507.11783", "authors": ["Gayal Kuruppu", "Neeraj Wagh", "Yogatheesan Varatharajah"], "title": "Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions", "categories": ["eess.SP", "cs.AI", "cs.LG", "q-bio.NC", "A.1; I.2; I.5; J.3"], "comment": "20 pages, 5 figures, 2 tables", "summary": "Patterns of electrical brain activity recorded via electroencephalography\n(EEG) offer immense value for scientific and clinical investigations. The\ninability of supervised EEG encoders to learn robust EEG patterns and their\nover-reliance on expensive signal annotations have sparked a transition towards\ngeneral-purpose self-supervised EEG encoders, i.e., EEG foundation models\n(EEG-FMs), for robust and scalable EEG feature extraction. However, the\nreal-world readiness of early EEG-FMs and the rubric for long-term research\nprogress remain unclear. A systematic and comprehensive review of\nfirst-generation EEG-FMs is therefore necessary to understand the current\nstate-of-the-art and identify key directions for future EEG-FMs. To that end,\nthis study reviews 10 early EEG-FMs and presents a critical synthesis of their\nmethodology, empirical findings, and outstanding research gaps. We find that\nmost EEG-FMs adopt a sequence-based modeling scheme that relies on\ntransformer-based backbones and the reconstruction of masked sequences for\nself-supervision. However, model evaluations remain heterogeneous and largely\nlimited, making it challenging to assess their practical off-the-shelf utility.\nIn addition to adopting standardized and realistic evaluations, future work\nshould demonstrate more substantial scaling effects and make principled and\ntrustworthy choices throughout the EEG representation learning pipeline. We\nbelieve that developing benchmarks, software tools, technical methodologies,\nand applications in collaboration with domain experts may further advance the\ntranslational utility and real-world adoption of EEG-FMs.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e8610\u4e2a\u65e9\u671f\u8111\u7535\u57fa\u7840\u6a21\u578b\uff08EEG - FMs\uff09\uff0c\u5206\u6790\u5176\u65b9\u6cd5\u3001\u7ed3\u679c\u4e0e\u7814\u7a76\u5dee\u8ddd\uff0c\u6307\u51fa\u8bc4\u4f30\u4e0d\u8db3\u95ee\u9898\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u6709\u76d1\u7763\u8111\u7535\u7f16\u7801\u5668\u5b58\u5728\u5c40\u9650\uff0c\u65e9\u671fEEG - FMs\u5728\u73b0\u5b9e\u5e94\u7528\u548c\u957f\u671f\u7814\u7a76\u8fdb\u5c55\u65b9\u9762\u60c5\u51b5\u4e0d\u660e\uff0c\u9700\u7cfb\u7edf\u5168\u9762\u56de\u987e\u65e9\u671f\u6a21\u578b\u4ee5\u660e\u786e\u73b0\u72b6\u548c\u672a\u6765\u65b9\u5411\u3002", "method": "\u56de\u987e10\u4e2a\u65e9\u671fEEG - FMs\uff0c\u7efc\u5408\u5206\u6790\u5176\u65b9\u6cd5\u3001\u5b9e\u8bc1\u7ed3\u679c\u548c\u7814\u7a76\u5dee\u8ddd\u3002", "result": "\u591a\u6570EEG - FMs\u91c7\u7528\u57fa\u4e8e\u5e8f\u5217\u7684\u5efa\u6a21\u65b9\u6848\uff0c\u4f9d\u8d56\u57fa\u4e8eTransformer\u7684\u4e3b\u5e72\u7f51\u7edc\u548c\u63a9\u7801\u5e8f\u5217\u91cd\u5efa\u8fdb\u884c\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u4f46\u6a21\u578b\u8bc4\u4f30\u5f02\u8d28\u6027\u5927\u4e14\u53d7\u9650\uff0c\u96be\u4ee5\u8bc4\u4f30\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u91c7\u7528\u6807\u51c6\u5316\u548c\u73b0\u5b9e\u7684\u8bc4\u4f30\uff0c\u5c55\u793a\u66f4\u5927\u7684\u7f29\u653e\u6548\u5e94\uff0c\u5728\u8111\u7535\u8868\u5f81\u5b66\u4e60\u6d41\u7a0b\u4e2d\u505a\u51fa\u5408\u7406\u53ef\u9760\u7684\u9009\u62e9\uff0c\u4e0e\u9886\u57df\u4e13\u5bb6\u5408\u4f5c\u5f00\u53d1\u76f8\u5173\u57fa\u51c6\u3001\u5de5\u5177\u3001\u65b9\u6cd5\u548c\u5e94\u7528\u4ee5\u63a8\u52a8EEG - FMs\u7684\u8f6c\u5316\u5e94\u7528\u548c\u5b9e\u9645\u91c7\u7528\u3002"}}
{"id": "2507.12224", "pdf": "https://arxiv.org/pdf/2507.12224", "abs": "https://arxiv.org/abs/2507.12224", "authors": ["Razvan Pascanu", "Clare Lyle", "Ionut-Vlad Modoranu", "Naima Elosegui Borras", "Dan Alistarh", "Petar Velickovic", "Sarath Chandar", "Soham De", "James Martens"], "title": "Optimizers Qualitatively Alter Solutions And We Should Leverage This", "categories": ["cs.LG"], "comment": null, "summary": "Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not\nguarantee convergence to a unique global minimum of the loss when using\noptimizers relying only on local information, such as SGD. Indeed, this was a\nprimary source of skepticism regarding the feasibility of DNNs in the early\ndays of the field. The past decades of progress in deep learning have revealed\nthis skepticism to be misplaced, and a large body of empirical evidence shows\nthat sufficiently large DNNs following standard training protocols exhibit\nwell-behaved optimization dynamics that converge to performant solutions. This\nsuccess has biased the community to use convex optimization as a mental model\nfor learning, leading to a focus on training efficiency, either in terms of\nrequired iteration, FLOPs or wall-clock time, when improving optimizers. We\nargue that, while this perspective has proven extremely fruitful, another\nperspective specific to DNNs has received considerably less attention: the\noptimizer not only influences the rate of convergence, but also the qualitative\nproperties of the learned solutions. Restated, the optimizer can and will\nencode inductive biases and change the effective expressivity of a given class\nof models. Furthermore, we believe the optimizer can be an effective way of\nencoding desiderata in the learning process. We contend that the community\nshould aim at understanding the biases of already existing methods, as well as\naim to build new optimizers with the explicit intent of inducing certain\nproperties of the solution, rather than solely judging them based on their\nconvergence rates. We hope our arguments will inspire research to improve our\nunderstanding of how the learning process can impact the type of solution we\nconverge to, and lead to a greater recognition of optimizers design as a\ncritical lever that complements the roles of architecture and data in shaping\nmodel outcomes.", "AI": {"tldr": "\u6307\u51fa\u6df1\u5ea6\u5b66\u4e60\u754c\u5728\u4f18\u5316\u5668\u8bbe\u8ba1\u4e0a\u8fc7\u4e8e\u5173\u6ce8\u6536\u655b\u901f\u5ea6\uff0c\u5e94\u91cd\u89c6\u4f18\u5316\u5668\u5bf9\u5b66\u4e60\u89e3\u6027\u8d28\u7684\u5f71\u54cd\u5e76\u8bbe\u8ba1\u65b0\u4f18\u5316\u5668\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4f18\u5316\u5668\u8bbe\u8ba1\u591a\u5173\u6ce8\u6536\u655b\u6548\u7387\uff0c\u800c\u4f18\u5316\u5668\u5bf9\u5b66\u4e60\u89e3\u6027\u8d28\u7684\u5f71\u54cd\u88ab\u5ffd\u89c6\u3002", "method": "\u7406\u8bba\u5206\u6790\uff0c\u8bba\u8ff0\u4f18\u5316\u5668\u4e0d\u4ec5\u5f71\u54cd\u6536\u655b\u901f\u5ea6\uff0c\u8fd8\u5f71\u54cd\u5b66\u4e60\u89e3\u7684\u6027\u8d28\u3002", "result": "\u5f3a\u8c03\u4f18\u5316\u5668\u80fd\u7f16\u7801\u5f52\u7eb3\u504f\u7f6e\u3001\u6539\u53d8\u6a21\u578b\u6709\u6548\u8868\u8fbe\u80fd\u529b\uff0c\u53ef\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7f16\u7801\u671f\u671b\u5c5e\u6027\u3002", "conclusion": "\u547c\u5401\u5b66\u754c\u7406\u89e3\u73b0\u6709\u65b9\u6cd5\u7684\u504f\u7f6e\uff0c\u6784\u5efa\u80fd\u8bf1\u5bfc\u89e3\u7279\u5b9a\u6027\u8d28\u7684\u65b0\u4f18\u5316\u5668\uff0c\u91cd\u89c6\u4f18\u5316\u5668\u8bbe\u8ba1\u5bf9\u5851\u9020\u6a21\u578b\u7ed3\u679c\u7684\u4f5c\u7528\u3002"}}
{"id": "2507.11799", "pdf": "https://arxiv.org/pdf/2507.11799", "abs": "https://arxiv.org/abs/2507.11799", "authors": ["Shin-ichi Ito"], "title": "Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network", "categories": ["physics.comp-ph", "cs.AI"], "comment": null, "summary": "This paper presents a neural network (NN)-based solver for an\nintegro-differential equation that models shrinkage-induced fragmentation. The\nproposed method directly maps input parameters to the corresponding probability\ndensity function without numerically solving the governing equation, thereby\nsignificantly reducing computational costs. Specifically, it enables efficient\nevaluation of the density function in Monte Carlo simulations while maintaining\naccuracy comparable to or even exceeding that of conventional finite difference\nschemes. Validatation on synthetic data demonstrates both the method's\ncomputational efficiency and predictive reliability. This study establishes a\nfoundation for the data-driven inverse analysis of fragmentation and suggests\nthe potential for extending the framework beyond pre-specified model\nstructures.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u79ef\u5206 - \u5fae\u5206\u65b9\u7a0b\u6c42\u89e3\u5668\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u9a8c\u8bc1\u4e86\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u53cd\u5206\u6790\u5960\u57fa\u5e76\u6697\u793a\u6846\u67b6\u6269\u5c55\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u6a21\u62df\u6536\u7f29\u8bf1\u5bfc\u7834\u788e\u7684\u79ef\u5206 - \u5fae\u5206\u65b9\u7a0b\u6c42\u89e3\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6c42\u89e3\u5668\uff0c\u76f4\u63a5\u5c06\u8f93\u5165\u53c2\u6570\u6620\u5c04\u5230\u76f8\u5e94\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u4e0d\u6570\u503c\u6c42\u89e3\u63a7\u5236\u65b9\u7a0b\u3002", "result": "\u5728\u8499\u7279\u5361\u7f57\u6a21\u62df\u4e2d\u80fd\u6709\u6548\u8bc4\u4f30\u5bc6\u5ea6\u51fd\u6570\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u9884\u6d4b\u53ef\u9760\u6027\u597d\uff0c\u51c6\u786e\u6027\u4e0e\u4f20\u7edf\u6709\u9650\u5dee\u5206\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "conclusion": "\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u7834\u788e\u53cd\u5206\u6790\u5960\u5b9a\u57fa\u7840\uff0c\u6846\u67b6\u6709\u8d85\u51fa\u9884\u8bbe\u6a21\u578b\u7ed3\u6784\u6269\u5c55\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.11809", "pdf": "https://arxiv.org/pdf/2507.11809", "abs": "https://arxiv.org/abs/2507.11809", "authors": ["Dante Campregher", "Yanxu Chen", "Sander Hoffman", "Maria Heuss"], "title": "Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 Pages, 13 figures", "summary": "This paper presents a reproducibility study examining how Large Language\nModels (LLMs) manage competing factual and counterfactual information, focusing\non the role of attention heads in this process. We attempt to reproduce and\nreconcile findings from three recent studies by Ortu et al., Yu, Merullo, and\nPavlick and McDougall et al. that investigate the competition between\nmodel-learned facts and contradictory context information through Mechanistic\nInterpretability tools. Our study specifically examines the relationship\nbetween attention head strength and factual output ratios, evaluates competing\nhypotheses about attention heads' suppression mechanisms, and investigates the\ndomain specificity of these attention patterns. Our findings suggest that\nattention heads promoting factual output do so via general copy suppression\nrather than selective counterfactual suppression, as strengthening them can\nalso inhibit correct facts. Additionally, we show that attention head behavior\nis domain-dependent, with larger models exhibiting more specialized and\ncategory-sensitive patterns.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4e8b\u5b9e\u4e0e\u53cd\u4e8b\u5b9e\u4fe1\u606f\u8fdb\u884c\u53ef\u91cd\u590d\u6027\u7814\u7a76\uff0c\u805a\u7126\u6ce8\u610f\u529b\u5934\u4f5c\u7528\uff0c\u53d1\u73b0\u6ce8\u610f\u529b\u5934\u901a\u8fc7\u901a\u7528\u590d\u5236\u6291\u5236\u4fc3\u8fdb\u4e8b\u5b9e\u8f93\u51fa\uff0c\u4e14\u5176\u884c\u4e3a\u5177\u6709\u9886\u57df\u4f9d\u8d56\u6027\u3002", "motivation": "\u5bf9\u8fd1\u671f\u4e09\u9879\u7814\u7a76\u7684\u53d1\u73b0\u8fdb\u884c\u91cd\u73b0\u548c\u8c03\u548c\uff0c\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5904\u7406\u7ade\u4e89\u7684\u4e8b\u5b9e\u548c\u53cd\u4e8b\u5b9e\u4fe1\u606f\u3002", "method": "\u4f7f\u7528\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff0c\u7814\u7a76\u6ce8\u610f\u529b\u5934\u5f3a\u5ea6\u4e0e\u4e8b\u5b9e\u8f93\u51fa\u6bd4\u7387\u7684\u5173\u7cfb\uff0c\u8bc4\u4f30\u6ce8\u610f\u529b\u5934\u6291\u5236\u673a\u5236\u7684\u7ade\u4e89\u5047\u8bbe\uff0c\u7814\u7a76\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u9886\u57df\u7279\u5f02\u6027\u3002", "result": "\u6ce8\u610f\u529b\u5934\u901a\u8fc7\u901a\u7528\u590d\u5236\u6291\u5236\u800c\u975e\u9009\u62e9\u6027\u53cd\u4e8b\u5b9e\u6291\u5236\u4fc3\u8fdb\u4e8b\u5b9e\u8f93\u51fa\uff0c\u5f3a\u5316\u5b83\u4eec\u4e5f\u4f1a\u6291\u5236\u6b63\u786e\u4e8b\u5b9e\uff1b\u6ce8\u610f\u529b\u5934\u884c\u4e3a\u5177\u6709\u9886\u57df\u4f9d\u8d56\u6027\uff0c\u66f4\u5927\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u4e13\u4e1a\u548c\u7c7b\u522b\u654f\u611f\u7684\u6a21\u5f0f\u3002", "conclusion": "\u660e\u786e\u4e86\u6ce8\u610f\u529b\u5934\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4fe1\u606f\u65f6\u7684\u4f5c\u7528\u673a\u5236\u548c\u9886\u57df\u7279\u6027\u3002"}}
{"id": "2507.12297", "pdf": "https://arxiv.org/pdf/2507.12297", "abs": "https://arxiv.org/abs/2507.12297", "authors": ["Yuan-Chen Shu", "Zhiwei Lin", "Yongtao Wang"], "title": "RegCL: Continual Adaptation of Segment Anything Model via Model Merging", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "To address the performance limitations of the Segment Anything Model (SAM) in\nspecific domains, existing works primarily adopt adapter-based one-step\nadaptation paradigms. However, some of these methods are specific developed for\nspecific domains. If used on other domains may lead to performance degradation.\nThis issue of catastrophic forgetting severely limits the model's scalability.\nTo address this issue, this paper proposes RegCL, a novel non-replay continual\nlearning (CL) framework designed for efficient multi-domain knowledge\nintegration through model merging. Specifically, RegCL incorporates the model\nmerging algorithm into the continual learning paradigm by merging the\nparameters of SAM's adaptation modules (e.g., LoRA modules) trained on\ndifferent domains. The merging process is guided by weight optimization, which\nminimizes prediction discrepancies between the merged model and each of the\ndomain-specific models. RegCL effectively consolidates multi-domain knowledge\nwhile maintaining parameter efficiency, i.e., the model size remains constant\nregardless of the number of tasks, and no historical data storage is required.\nExperimental results demonstrate that RegCL achieves favorable continual\nlearning performance across multiple downstream datasets, validating its\neffectiveness in dynamic scenarios.", "AI": {"tldr": "\u4e3a\u89e3\u51b3SAM\u5728\u7279\u5b9a\u9886\u57df\u7684\u6027\u80fd\u5c40\u9650\u53ca\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u63d0\u51faRegCL\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u5408\u5e76\u96c6\u6210\u591a\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u6709\u6548\u3002", "motivation": "\u89e3\u51b3SAM\u5728\u7279\u5b9a\u9886\u57df\u6027\u80fd\u5c40\u9650\uff0c\u4ee5\u53ca\u73b0\u6709\u57fa\u4e8e\u9002\u914d\u5668\u7684\u4e00\u6b65\u9002\u5e94\u8303\u5f0f\u5b58\u5728\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faRegCL\u6846\u67b6\uff0c\u5c06\u6a21\u578b\u5408\u5e76\u7b97\u6cd5\u878d\u5165\u6301\u7eed\u5b66\u4e60\u8303\u5f0f\uff0c\u5408\u5e76\u4e0d\u540c\u9886\u57df\u8bad\u7ec3\u7684SAM\u9002\u914d\u6a21\u5757\u53c2\u6570\uff0c\u901a\u8fc7\u6743\u91cd\u4f18\u5316\u5f15\u5bfc\u5408\u5e76\u8fc7\u7a0b\u3002", "result": "RegCL\u5728\u591a\u4e2a\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u826f\u597d\u7684\u6301\u7eed\u5b66\u4e60\u6027\u80fd\u3002", "conclusion": "RegCL\u80fd\u6709\u6548\u96c6\u6210\u591a\u9886\u57df\u77e5\u8bc6\uff0c\u4fdd\u6301\u53c2\u6570\u6548\u7387\uff0c\u5728\u52a8\u6001\u573a\u666f\u4e2d\u6709\u6548\u3002"}}
{"id": "2507.11810", "pdf": "https://arxiv.org/pdf/2507.11810", "abs": "https://arxiv.org/abs/2507.11810", "authors": ["Haoxuan Zhang", "Ruochi Li", "Yang Zhang", "Ting Xiao", "Jiangping Chen", "Junhua Ding", "Haihua Chen"], "title": "The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist", "categories": ["cs.DL", "cs.AI"], "comment": null, "summary": "Scientific innovation is undergoing a paradigm shift driven by the rapid\nadvancement of Large Language Models (LLMs). As science faces mounting\nchallenges including information overload, disciplinary silos, and diminishing\nreturns on conventional research methods, LLMs are emerging as powerful agents\ncapable not only of enhancing scientific workflows but also of participating in\nand potentially leading the innovation process. Existing surveys mainly focus\non different perspectives, phrases, and tasks in scientific research and\ndiscovery, while they have limitations in understanding the transformative\npotential and role differentiation of LLM. This survey proposes a comprehensive\nframework to categorize the evolving roles of LLMs in scientific innovation\nacross three hierarchical levels: Evaluator, Collaborator, and Scientist. We\ndistinguish between LLMs' contributions to structured scientific research\nprocesses and open-ended scientific discovery, thereby offering a unified\ntaxonomy that clarifies capability boundaries, evaluation criteria, and\nhuman-AI interaction patterns at each level. Through an extensive analysis of\ncurrent methodologies, benchmarks, systems, and evaluation metrics, this survey\ndelivers an in-depth and systematic synthesis on LLM-driven scientific\ninnovation. We present LLMs not only as tools for automating existing\nprocesses, but also as catalysts capable of reshaping the epistemological\nfoundations of science itself. This survey offers conceptual clarity, practical\nguidance, and theoretical foundations for future research, while also\nhighlighting open challenges and ethical considerations in the pursuit of\nincreasingly autonomous AI-driven science. Resources related to this survey can\nbe accessed on GitHub at: https://github.com/haoxuan-unt2024/llm4innovation.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u79d1\u5b66\u521b\u65b0\u8303\u5f0f\u8f6c\u53d8\uff0c\u63d0\u51fa\u7efc\u5408\u6846\u67b6\u5bf9\u5176\u5728\u79d1\u5b66\u521b\u65b0\u4e2d\u7684\u89d2\u8272\u5206\u7c7b\uff0c\u6df1\u5165\u5206\u6790\u76f8\u5173\u5185\u5bb9\u5e76\u7ed9\u51fa\u7814\u7a76\u542f\u793a\u4e0e\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u8c03\u67e5\u5728\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u53d8\u9769\u6f5c\u529b\u548c\u89d2\u8272\u533a\u5206\u4e0a\u6709\u5c40\u9650\uff0c\u79d1\u5b66\u9762\u4e34\u4fe1\u606f\u8fc7\u8f7d\u7b49\u6311\u6218\uff0c\u9700\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u521b\u65b0\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u7efc\u5408\u6846\u67b6\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u521b\u65b0\u4e2d\u7684\u89d2\u8272\u5206\u4e3a\u4e09\u4e2a\u5c42\u6b21\uff0c\u533a\u5206\u5176\u5728\u7ed3\u6784\u5316\u79d1\u7814\u548c\u5f00\u653e\u5f0f\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u8d21\u732e\uff0c\u5206\u6790\u73b0\u6709\u65b9\u6cd5\u3001\u57fa\u51c6\u7b49\u3002", "result": "\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u79d1\u5b66\u521b\u65b0\u8fdb\u884c\u6df1\u5165\u7cfb\u7edf\u7efc\u5408\uff0c\u660e\u786e\u5176\u4e0d\u4ec5\u662f\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u8fd8\u80fd\u91cd\u5851\u79d1\u5b66\u8ba4\u8bc6\u8bba\u57fa\u7840\u3002", "conclusion": "\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u6982\u5ff5\u6e05\u6670\u6027\u3001\u5b9e\u8df5\u6307\u5bfc\u548c\u7406\u8bba\u57fa\u7840\uff0c\u6307\u51fa\u5f00\u653e\u6311\u6218\u548c\u4f26\u7406\u8003\u91cf\u3002"}}
{"id": "2507.12305", "pdf": "https://arxiv.org/pdf/2507.12305", "abs": "https://arxiv.org/abs/2507.12305", "authors": ["M. Anwar Ma'sum", "Mahardhika Pratama", "Savitha Ramasamy", "Lin Liu", "Habibullah Habibullah", "Ryszard Kowalczyk"], "title": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICCV 2025", "summary": "The data privacy constraint in online continual learning (OCL), where the\ndata can be seen only once, complicates the catastrophic forgetting problem in\nstreaming data. A common approach applied by the current SOTAs in OCL is with\nthe use of memory saving exemplars or features from previous classes to be\nreplayed in the current task. On the other hand, the prompt-based approach\nperforms excellently in continual learning but with the cost of a growing\nnumber of trainable parameters. The first approach may not be applicable in\npractice due to data openness policy, while the second approach has the issue\nof throughput associated with the streaming data. In this study, we propose a\nnovel prompt-based method for online continual learning that includes 4 main\ncomponents: (1) single light-weight prompt generator as a general knowledge,\n(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model\n(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our\nproposed method achieves significantly higher performance than the current\nSOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity\nanalysis shows that our method requires a relatively smaller number of\nparameters and achieves moderate training time, inference time, and throughput.\nFor further study, the source code of our method is available at\nhttps://github.com/anwarmaxsum/PROL.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u7684\u65b0\u57fa\u4e8e\u63d0\u793a\u65b9\u6cd5\uff0c\u6027\u80fd\u8d85\u5f53\u524dSOTA\uff0c\u53c2\u6570\u5c11\u4e14\u8bad\u7ec3\u7b49\u65f6\u95f4\u9002\u4e2d\u3002", "motivation": "\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u4e2d\u6570\u636e\u9690\u79c1\u7ea6\u675f\u4f7f\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u590d\u6742\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u5f00\u653e\u6027\u548c\u541e\u5410\u91cf\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5305\u542b\u5355\u8f7b\u91cf\u7ea7\u63d0\u793a\u751f\u6210\u5668\u3001\u53ef\u8bad\u7ec3\u7f29\u653e\u5e73\u79fb\u5668\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u6cdb\u5316\u4fdd\u7559\u548c\u786c - \u8f6f\u66f4\u65b0\u673a\u5236\u7684\u65b0\u57fa\u4e8e\u63d0\u793a\u65b9\u6cd5\u3002", "result": "\u5728CIFAR100\u7b49\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u663e\u8457\u9ad8\u4e8e\u5f53\u524dSOTA\uff0c\u590d\u6742\u5ea6\u5206\u6790\u663e\u793a\u6240\u9700\u53c2\u6570\u8f83\u5c11\uff0c\u8bad\u7ec3\u3001\u63a8\u7406\u65f6\u95f4\u548c\u541e\u5410\u91cf\u9002\u4e2d\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2507.11848", "pdf": "https://arxiv.org/pdf/2507.11848", "abs": "https://arxiv.org/abs/2507.11848", "authors": ["Changjian Chen", "Pengcheng Wang", "Fei Lyu", "Zhuo Tang", "Li Yang", "Long Wang", "Yong Cai", "Feng Yu", "Kenli Li"], "title": "Interactive Hybrid Rice Breeding with Parametric Dual Projection", "categories": ["cs.HC", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Hybrid rice breeding crossbreeds different rice lines and cultivates the\nresulting hybrids in fields to select those with desirable agronomic traits,\nsuch as higher yields. Recently, genomic selection has emerged as an efficient\nway for hybrid rice breeding. It predicts the traits of hybrids based on their\ngenes, which helps exclude many undesired hybrids, largely reducing the\nworkload of field cultivation. However, due to the limited accuracy of genomic\nprediction models, breeders still need to combine their experience with the\nmodels to identify regulatory genes that control traits and select hybrids,\nwhich remains a time-consuming process. To ease this process, in this paper, we\nproposed a visual analysis method to facilitate interactive hybrid rice\nbreeding. Regulatory gene identification and hybrid selection naturally\nensemble a dual-analysis task. Therefore, we developed a parametric dual\nprojection method with theoretical guarantees to facilitate interactive dual\nanalysis. Based on this dual projection method, we further developed a gene\nvisualization and a hybrid visualization to verify the identified regulatory\ngenes and hybrids. The effectiveness of our method is demonstrated through the\nquantitative evaluation of the parametric dual projection method, identified\nregulatory genes and desired hybrids in the case study, and positive feedback\nfrom breeders.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53ef\u89c6\u5316\u5206\u6790\u65b9\u6cd5\u52a9\u529b\u6742\u4ea4\u6c34\u7a3b\u80b2\u79cd\uff0c\u5f00\u53d1\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u53c2\u6570\u5316\u53cc\u6295\u5f71\u65b9\u6cd5\u53ca\u53ef\u89c6\u5316\uff0c\u7ecf\u6848\u4f8b\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u57fa\u56e0\u7ec4\u9009\u62e9\u65b9\u6cd5\u56e0\u6a21\u578b\u7cbe\u5ea6\u6709\u9650\uff0c\u80b2\u79cd\u4ecd\u8017\u65f6\uff0c\u9700\u65b0\u65b9\u6cd5\u7b80\u5316\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u53ef\u89c6\u5316\u5206\u6790\u65b9\u6cd5\uff0c\u5f00\u53d1\u53c2\u6570\u5316\u53cc\u6295\u5f71\u65b9\u6cd5\u7528\u4e8e\u4ea4\u4e92\u5f0f\u53cc\u5206\u6790\uff0c\u5f00\u53d1\u57fa\u56e0\u548c\u6742\u4ea4\u79cd\u53ef\u89c6\u5316\u3002", "result": "\u901a\u8fc7\u5bf9\u53c2\u6570\u5316\u53cc\u6295\u5f71\u65b9\u6cd5\u3001\u9274\u5b9a\u7684\u8c03\u63a7\u57fa\u56e0\u548c\u6240\u9700\u6742\u4ea4\u79cd\u7684\u5b9a\u91cf\u8bc4\u4f30\u53ca\u80b2\u79cd\u8005\u79ef\u6781\u53cd\u9988\uff0c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "conclusion": "\u6240\u63d0\u53ef\u89c6\u5316\u5206\u6790\u65b9\u6cd5\u80fd\u6709\u6548\u52a9\u529b\u6742\u4ea4\u6c34\u7a3b\u80b2\u79cd\u3002"}}
{"id": "2507.12341", "pdf": "https://arxiv.org/pdf/2507.12341", "abs": "https://arxiv.org/abs/2507.12341", "authors": ["Antoine Saillenfest", "Pirmin Lemberger"], "title": "Nonlinear Concept Erasure: a Density Matching Approach", "categories": ["cs.LG", "cs.CL"], "comment": "17 pages, 10 figures, accepted for publication in ECAI 2025 (28th\n  European Conference on Artificial Intelligence)", "summary": "Ensuring that neural models used in real-world applications cannot infer\nsensitive information, such as demographic attributes like gender or race, from\ntext representations is a critical challenge when fairness is a concern. We\naddress this issue through concept erasure, a process that removes information\nrelated to a specific concept from distributed representations while preserving\nas much of the remaining semantic information as possible. Our approach\ninvolves learning an orthogonal projection in the embedding space, designed to\nmake the class-conditional feature distributions of the discrete concept to\nerase indistinguishable after projection. By adjusting the rank of the\nprojector, we control the extent of information removal, while its\northogonality ensures strict preservation of the local structure of the\nembeddings. Our method, termed $\\overline{\\mathrm{L}}$EOPARD, achieves\nstate-of-the-art performance in nonlinear erasure of a discrete attribute on\nclassic natural language processing benchmarks. Furthermore, we demonstrate\nthat $\\overline{\\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear\nclassifiers, thereby promoting fairness.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11892", "pdf": "https://arxiv.org/pdf/2507.11892", "abs": "https://arxiv.org/abs/2507.11892", "authors": ["Yu Liu", "Leyuan Qu", "Hanlei Shi", "Di Gao", "Yuhua Zheng", "Taihao Li"], "title": "From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition", "categories": ["cs.CV", "cs.AI", "cs.HC"], "comment": null, "summary": "Dynamic Facial Expression Recognition (DFER) aims to identify human emotions\nfrom temporally evolving facial movements and plays a critical role in\naffective computing. While recent vision-language approaches have introduced\nsemantic textual descriptions to guide expression recognition, existing methods\nstill face two key limitations: they often underutilize the subtle emotional\ncues embedded in generated text, and they have yet to incorporate sufficiently\neffective mechanisms for filtering out facial dynamics that are irrelevant to\nemotional expression. To address these gaps, We propose GRACE, Granular\nRepresentation Alignment for Cross-modal Emotion recognition that integrates\ndynamic motion modeling, semantic text refinement, and token-level cross-modal\nalignment to facilitate the precise localization of emotionally salient\nspatiotemporal features. Our method constructs emotion-aware textual\ndescriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and\nhighlights expression-relevant facial motion through a motion-difference\nweighting mechanism. These refined semantic and visual signals are aligned at\nthe token level using entropy-regularized optimal transport. Experiments on\nthree benchmark datasets demonstrate that our method significantly improves\nrecognition performance, particularly in challenging settings with ambiguous or\nimbalanced emotion classes, establishing new state-of-the-art (SOTA) results in\nterms of both UAR and WAR.", "AI": {"tldr": "\u63d0\u51faGRACE\u65b9\u6cd5\u7528\u4e8e\u52a8\u6001\u9762\u90e8\u8868\u60c5\u8bc6\u522b\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9 - \u8bed\u8a00\u65b9\u6cd5\u5728\u52a8\u6001\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u4e2d\u5b58\u5728\u672a\u5145\u5206\u5229\u7528\u6587\u672c\u60c5\u611f\u7ebf\u7d22\u548c\u7f3a\u4e4f\u6709\u6548\u8fc7\u6ee4\u65e0\u5173\u9762\u90e8\u52a8\u6001\u673a\u5236\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efaGRACE\u65b9\u6cd5\uff0c\u5305\u62ecCATE\u6a21\u5757\u6784\u5efa\u60c5\u611f\u611f\u77e5\u6587\u672c\u63cf\u8ff0\u3001\u8fd0\u52a8\u5dee\u5f02\u52a0\u6743\u673a\u5236\u7a81\u51fa\u76f8\u5173\u9762\u90e8\u8fd0\u52a8\uff0c\u4f7f\u7528\u71b5\u6b63\u5219\u5316\u6700\u4f18\u4f20\u8f93\u8fdb\u884c\u8bed\u4e49\u548c\u89c6\u89c9\u4fe1\u53f7\u7684token\u7ea7\u5bf9\u9f50\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u663e\u8457\u63d0\u9ad8\u8bc6\u522b\u6027\u80fd\uff0c\u5728\u6a21\u7cca\u6216\u4e0d\u5e73\u8861\u60c5\u611f\u7c7b\u522b\u7684\u6311\u6218\u6027\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u53d6\u5f97UAR\u548cWAR\u7684SOTA\u7ed3\u679c\u3002", "conclusion": "GRACE\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u63d0\u5347\u52a8\u6001\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2507.12380", "pdf": "https://arxiv.org/pdf/2507.12380", "abs": "https://arxiv.org/abs/2507.12380", "authors": ["Maximilian Krahn", "Vikas Garg"], "title": "Heat Kernel Goes Topological", "categories": ["cs.LG"], "comment": null, "summary": "Topological neural networks have emerged as powerful successors of graph\nneural networks. However, they typically involve higher-order message passing,\nwhich incurs significant computational expense. We circumvent this issue with a\nnovel topological framework that introduces a Laplacian operator on\ncombinatorial complexes (CCs), enabling efficient computation of heat kernels\nthat serve as node descriptors. Our approach captures multiscale information\nand enables permutation-equivariant representations, allowing easy integration\ninto modern transformer-based architectures.\n  Theoretically, the proposed method is maximally expressive because it can\ndistinguish arbitrary non-isomorphic CCs. Empirically, it significantly\noutperforms existing topological methods in terms of computational efficiency.\nBesides demonstrating competitive performance with the state-of-the-art\ndescriptors on standard molecular datasets, it exhibits superior capability in\ndistinguishing complex topological structures and avoiding blind spots on\ntopological benchmarks. Overall, this work advances topological deep learning\nby providing expressive yet scalable representations, thereby opening up\nexciting avenues for molecular classification and property prediction tasks.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u62d3\u6251\u6846\u67b6\u89e3\u51b3\u62d3\u6251\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u6210\u672c\u9ad8\u95ee\u9898\uff0c\u7406\u8bba\u8868\u8fbe\u5f3a\u4e14\u8ba1\u7b97\u9ad8\u6548\uff0c\u5728\u591a\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u63a8\u52a8\u62d3\u6251\u6df1\u5ea6\u5b66\u4e60\u3002", "motivation": "\u62d3\u6251\u795e\u7ecf\u7f51\u7edc\u9ad8\u9636\u6d88\u606f\u4f20\u9012\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5f15\u5165\u7ec4\u5408\u590d\u5f62\u4e0a\u7684\u62c9\u666e\u62c9\u65af\u7b97\u5b50\uff0c\u9ad8\u6548\u8ba1\u7b97\u4f5c\u4e3a\u8282\u70b9\u63cf\u8ff0\u7b26\u7684\u70ed\u6838\uff0c\u6355\u83b7\u591a\u5c3a\u5ea6\u4fe1\u606f\u3002", "result": "\u7406\u8bba\u4e0a\u80fd\u533a\u5206\u4efb\u610f\u975e\u540c\u6784\u7ec4\u5408\u590d\u5f62\uff0c\u8ba1\u7b97\u6548\u7387\u8d85\u73b0\u6709\u62d3\u6251\u65b9\u6cd5\uff0c\u5728\u5206\u5b50\u6570\u636e\u96c6\u8868\u73b0\u597d\uff0c\u533a\u5206\u590d\u6742\u62d3\u6251\u7ed3\u6784\u80fd\u529b\u5f3a\u3002", "conclusion": "\u5de5\u4f5c\u4e3a\u62d3\u6251\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u6709\u8868\u8fbe\u529b\u4e14\u53ef\u6269\u5c55\u7684\u8868\u793a\uff0c\u4e3a\u5206\u5b50\u5206\u7c7b\u548c\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u5f00\u8f9f\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.11893", "pdf": "https://arxiv.org/pdf/2507.11893", "abs": "https://arxiv.org/abs/2507.11893", "authors": ["Linwei Chen", "Ying Fu", "Lin Gu", "Dezhi Zheng", "Jifeng Dai"], "title": "Spatial Frequency Modulation for Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accept by TPAMI 2025", "summary": "High spatial frequency information, including fine details like textures,\nsignificantly contributes to the accuracy of semantic segmentation. However,\naccording to the Nyquist-Shannon Sampling Theorem, high-frequency components\nare vulnerable to aliasing or distortion when propagating through downsampling\nlayers such as strided-convolution. Here, we propose a novel Spatial Frequency\nModulation (SFM) that modulates high-frequency features to a lower frequency\nbefore downsampling and then demodulates them back during upsampling.\nSpecifically, we implement modulation through adaptive resampling (ARS) and\ndesign a lightweight add-on that can densely sample the high-frequency areas to\nscale up the signal, thereby lowering its frequency in accordance with the\nFrequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling\n(MSAU) to demodulate the modulated feature and recover high-frequency\ninformation through non-uniform upsampling This module further improves\nsegmentation by explicitly exploiting information interaction between densely\nand sparsely resampled areas at multiple scales. Both modules can seamlessly\nintegrate with various architectures, extending from convolutional neural\nnetworks to transformers. Feature visualization and analysis confirm that our\nmethod effectively alleviates aliasing while successfully retaining details\nafter demodulation. Finally, we validate the broad applicability and\neffectiveness of SFM by extending it to image classification, adversarial\nrobustness, instance segmentation, and panoptic segmentation tasks. The code is\navailable at\n\\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.", "AI": {"tldr": "\u63d0\u51fa\u7a7a\u95f4\u9891\u7387\u8c03\u5236\uff08SFM\uff09\u65b9\u6cd5\u5904\u7406\u9ad8\u9891\u7279\u5f81\uff0c\u7f13\u89e3\u4e0b\u91c7\u6837\u6df7\u53e0\u95ee\u9898\uff0c\u5728\u591a\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u9ad8\u9891\u4fe1\u606f\u5bf9\u8bed\u4e49\u5206\u5272\u51c6\u786e\u6027\u91cd\u8981\uff0c\u4f46\u4e0b\u91c7\u6837\u5c42\u4f1a\u5bfc\u81f4\u9ad8\u9891\u6210\u5206\u6df7\u53e0\u6216\u5931\u771f\u3002", "method": "\u63d0\u51faSFM\uff0c\u8c03\u5236\u9ad8\u9891\u7279\u5f81\u5230\u4f4e\u9891\u518d\u89e3\u8c03\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u91cd\u91c7\u6837\uff08ARS\uff09\u5b9e\u73b0\u8c03\u5236\uff0c\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u6a21\u5757\uff0c\u63d0\u51fa\u591a\u5c3a\u5ea6\u81ea\u9002\u5e94\u4e0a\u91c7\u6837\uff08MSAU\uff09\u8fdb\u884c\u89e3\u8c03\uff0c\u4e24\u6a21\u5757\u53ef\u96c6\u6210\u5230\u591a\u79cd\u67b6\u6784\u3002", "result": "\u7279\u5f81\u53ef\u89c6\u5316\u548c\u5206\u6790\u8868\u660e\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u6df7\u53e0\uff0c\u4fdd\u7559\u7ec6\u8282\uff1b\u5728\u591a\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86SFM\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "SFM\u662f\u4e00\u79cd\u6709\u6548\u5904\u7406\u9ad8\u9891\u7279\u5f81\u7684\u65b9\u6cd5\uff0c\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u89c6\u89c9\u4efb\u52a1\u3002"}}
{"id": "2507.12383", "pdf": "https://arxiv.org/pdf/2507.12383", "abs": "https://arxiv.org/abs/2507.12383", "authors": ["Mohit Prashant", "Arvind Easwaran"], "title": "Improving Reinforcement Learning Sample-Efficiency using Local Approximation", "categories": ["cs.LG"], "comment": "Preprint", "summary": "In this study, we derive Probably Approximately Correct (PAC) bounds on the\nasymptotic sample-complexity for RL within the infinite-horizon Markov Decision\nProcess (MDP) setting that are sharper than those in existing literature. The\npremise of our study is twofold: firstly, the further two states are from each\nother, transition-wise, the less relevant the value of the first state is when\nlearning the $\\epsilon$-optimal value of the second; secondly, the amount of\n'effort', sample-complexity-wise, expended in learning the $\\epsilon$-optimal\nvalue of a state is independent of the number of samples required to learn the\n$\\epsilon$-optimal value of a second state that is a sufficient number of\ntransitions away from the first. Inversely, states within each other's vicinity\nhave values that are dependent on each other and will require a similar number\nof samples to learn. By approximating the original MDP using smaller MDPs\nconstructed using subsets of the original's state-space, we are able to reduce\nthe sample-complexity by a logarithmic factor to $O(SA \\log A)$ timesteps,\nwhere $S$ and $A$ are the state and action space sizes. We are able to extend\nthese results to an infinite-horizon, model-free setting by constructing a\nPAC-MDP algorithm with the aforementioned sample-complexity. We conclude with\nshowing how significant the improvement is by comparing our algorithm against\nprior work in an experimental setting.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11935", "pdf": "https://arxiv.org/pdf/2507.11935", "abs": "https://arxiv.org/abs/2507.11935", "authors": ["Jikang Deng", "Fizza Hassan", "Hui Zhou", "Saad Al-Ahmadi", "Mohamed-Slim Alouini", "Daniel B. Da Costa"], "title": "Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview", "categories": ["cs.NI", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "As the path toward 6G networks is being charted, the emerging applications\nhave motivated evolutions of network architectures to realize the efficient,\nreliable, and flexible wireless networks. Among the potential architectures,\nthe non-terrestrial network (NTN) and open radio access network (ORAN) have\nreceived increasing interest from both academia and industry. Although the\ndeployment of NTNs ensures coverage, enhances spectral efficiency, and improves\nthe resilience of wireless networks. The high altitude and mobility of NTN\npresent new challenges in the development and operations (DevOps) lifecycle,\nhindering intelligent and scalable network management due to the lack of native\nartificial intelligence (AI) capability. With the advantages of ORAN in\ndisaggregation, openness, virtualization, and intelligence, several works\npropose integrating ORAN principles into the NTN, focusing mainly on ORAN\ndeployment options based on transparent and regenerative systems. However, a\nholistic view of how to effectively combine ORAN and NTN throughout the DevOps\nlifecycle is still missing, especially regarding how intelligent ORAN addresses\nthe scalability challenges in NTN. Motivated by this, in this paper, we first\nprovide the background knowledge about ORAN and NTN, outline the\nstate-of-the-art research on ORAN for NTNs, and present the DevOps challenges\nthat motivate the adoption of ORAN solutions. We then propose the ORAN-based\nNTN framework, discussing its features and architectures in detail. These\ninclude the discussion about flexible fronthaul split, RAN intelligent\ncontrollers (RICs) enhancement for distributed learning, scalable deployment\narchitecture, and multi-domain service management. Finally, the future research\ndirections, including combinations of the ORAN-based NTN framework and other\nenabling technologies and schemes, as well as the candidate use cases, are\nhighlighted.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba86G\u7f51\u7edc\u4e0b\u975e\u5730\u9762\u7f51\u7edc\uff08NTN\uff09\u4e0e\u5f00\u653e\u65e0\u7ebf\u63a5\u5165\u7f51\uff08ORAN\uff09\u7ed3\u5408\uff0c\u63d0\u51faORAN - NTN\u6846\u67b6\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "NTN\u5728\u5f00\u53d1\u8fd0\u7ef4\uff08DevOps\uff09\u751f\u547d\u5468\u671f\u5b58\u5728\u6311\u6218\uff0c\u7f3a\u4e4f\u539f\u751fAI\u80fd\u529b\u963b\u788d\u667a\u80fd\u548c\u53ef\u6269\u5c55\u7f51\u7edc\u7ba1\u7406\uff0c\u4e14\u7f3a\u5c11\u5c06ORAN\u4e0eNTN\u5728DevOps\u751f\u547d\u5468\u671f\u6709\u6548\u7ed3\u5408\u7684\u6574\u4f53\u89c2\u70b9\u3002", "method": "\u5148\u4ecb\u7ecdORAN\u548cNTN\u80cc\u666f\u77e5\u8bc6\u4e0e\u76f8\u5173\u7814\u7a76\u3001DevOps\u6311\u6218\uff0c\u518d\u63d0\u51faORAN - NTN\u6846\u67b6\u5e76\u8be6\u7ec6\u8ba8\u8bba\u5176\u7279\u6027\u548c\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u4e86ORAN - NTN\u6846\u67b6\uff0c\u5305\u542b\u7075\u6d3b\u524d\u4f20\u5206\u5272\u3001RAN\u667a\u80fd\u63a7\u5236\u5668\u589e\u5f3a\u3001\u53ef\u6269\u5c55\u90e8\u7f72\u67b6\u6784\u548c\u591a\u57df\u670d\u52a1\u7ba1\u7406\u7b49\u5185\u5bb9\u3002", "conclusion": "\u6307\u660e\u4e86ORAN - NTN\u6846\u67b6\u4e0e\u5176\u4ed6\u6280\u672f\u7ed3\u5408\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u5019\u9009\u7528\u4f8b\u3002"}}
{"id": "2507.12384", "pdf": "https://arxiv.org/pdf/2507.12384", "abs": "https://arxiv.org/abs/2507.12384", "authors": ["Bo Wen", "Guoyun Gao", "Zhicheng Xu", "Ruibin Mao", "Xiaojuan Qi", "X. Sharon Hu", "Xunzhao Yin", "Can Li"], "title": "Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "The rapid advancement of artificial intelligence has raised concerns\nregarding its trustworthiness, especially in terms of interpretability and\nrobustness. Tree-based models like Random Forest and XGBoost excel in\ninterpretability and accuracy for tabular data, but scaling them remains\ncomputationally expensive due to poor data locality and high data dependence.\nPrevious efforts to accelerate these models with analog content addressable\nmemory (CAM) have struggled, due to the fact that the difficult-to-implement\nsharp decision boundaries are highly susceptible to device variations, which\nleads to poor hardware performance and vulnerability to adversarial attacks.\nThis work presents a novel hardware-software co-design approach using $MoS_2$\nFlash-based analog CAM with inherent soft boundaries, enabling efficient\ninference with soft tree-based models. Our soft tree model inference\nexperiments on $MoS_2$ analog CAM arrays show this method achieves exceptional\nrobustness against device variation and adversarial attacks while achieving\nstate-of-the-art accuracy. Specifically, our fabricated analog CAM arrays\nachieve $96\\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,\nwhile maintaining decision explainability. Our experimentally calibrated model\nvalidated only a $0.6\\%$ accuracy drop on the MNIST dataset under $10\\%$ device\nthreshold variation, compared to a $45.3\\%$ drop for traditional decision\ntrees. This work paves the way for specialized hardware that enhances AI's\ntrustworthiness and efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eMoS\u2082 Flash\u7684\u6a21\u62df\u5185\u5bb9\u53ef\u5bfb\u5740\u5185\u5b58\uff08CAM\uff09\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u8f6f\u6811\u6a21\u578b\u9ad8\u6548\u63a8\u7406\uff0c\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u7684\u53ef\u4fe1\u8d56\u6027\u53d7\u5173\u6ce8\uff0c\u6811\u6a21\u578b\u867d\u9002\u5408\u8868\u683c\u6570\u636e\u4f46\u6269\u5c55\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4ee5\u5f80\u7528\u6a21\u62dfCAM\u52a0\u901f\u6a21\u578b\u5b58\u5728\u786c\u4ef6\u6027\u80fd\u5dee\u548c\u6613\u53d7\u653b\u51fb\u7b49\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8eMoS\u2082 Flash\u7684\u6a21\u62dfCAM\u8fdb\u884c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u8f6f\u6811\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u7406\u3002", "result": "\u5728MoS\u2082\u6a21\u62dfCAM\u9635\u5217\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5bf9\u8bbe\u5907\u53d8\u5316\u548c\u5bf9\u6297\u653b\u51fb\u6709\u51fa\u8272\u9c81\u68d2\u6027\uff0c\u5728WDBC\u6570\u636e\u5e93\u8fbe\u523096%\u51c6\u786e\u7387\uff0cMNIST\u6570\u636e\u96c6\u572810%\u8bbe\u5907\u9608\u503c\u53d8\u5316\u4e0b\u51c6\u786e\u7387\u4ec5\u4e0b\u964d0.6%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u589e\u5f3a\u4eba\u5de5\u667a\u80fd\u53ef\u4fe1\u8d56\u6027\u548c\u6548\u7387\u7684\u4e13\u7528\u786c\u4ef6\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.11936", "pdf": "https://arxiv.org/pdf/2507.11936", "abs": "https://arxiv.org/abs/2507.11936", "authors": ["Jianzhe Ma", "Wenxuan Wang", "Qin Jin"], "title": "A Survey of Deep Learning for Geometry Problem Solving", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": "Work in progress", "summary": "Geometry problem solving is a key area of mathematical reasoning, which is\nwidely involved in many important fields such as education, mathematical\nability assessment of artificial intelligence, and multimodal ability\nassessment. In recent years, the rapid development of deep learning technology,\nespecially the rise of multimodal large language models, has triggered a\nwidespread research boom. This paper provides a survey of the applications of\ndeep learning in geometry problem solving, including (i) a comprehensive\nsummary of the relevant tasks in geometry problem solving; (ii) a thorough\nreview of related deep learning methods; (iii) a detailed analysis of\nevaluation metrics and methods; and (iv) a critical discussion of the current\nchallenges and future directions that can be explored. Our goal is to provide a\ncomprehensive and practical reference of deep learning for geometry problem\nsolving to promote further developments in this field. We create a continuously\nupdated list of papers on GitHub: https://github.com/majianz/dl4gps.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6df1\u5ea6\u5b66\u4e60\u5728\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u6db5\u76d6\u4efb\u52a1\u603b\u7ed3\u3001\u65b9\u6cd5\u56de\u987e\u3001\u8bc4\u4f30\u6307\u6807\u5206\u6790\u53ca\u6311\u6218\u4e0e\u65b9\u5411\u63a2\u8ba8\uff0c\u5e76\u5728GitHub\u63d0\u4f9b\u8bba\u6587\u5217\u8868\u3002", "motivation": "\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u5728\u591a\u9886\u57df\u91cd\u8981\uff0c\u6df1\u5ea6\u5b66\u4e60\u5c24\u5176\u662f\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u5f15\u53d1\u7814\u7a76\u70ed\u6f6e\uff0c\u65e8\u5728\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u5168\u9762\u5b9e\u7528\u53c2\u8003\u4ee5\u63a8\u52a8\u53d1\u5c55\u3002", "method": "\u5bf9\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u76f8\u5173\u4efb\u52a1\u8fdb\u884c\u5168\u9762\u603b\u7ed3\uff0c\u56de\u987e\u76f8\u5173\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5206\u6790\u8bc4\u4f30\u6307\u6807\u548c\u65b9\u6cd5\uff0c\u8ba8\u8bba\u5f53\u524d\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "result": "\u5b8c\u6210\u4e86\u5bf9\u6df1\u5ea6\u5b66\u4e60\u5728\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u5e94\u7528\u7684\u8c03\u67e5\uff0c\u521b\u5efa\u4e86\u6301\u7eed\u66f4\u65b0\u7684\u8bba\u6587\u5217\u8868\u3002", "conclusion": "\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7528\u4e8e\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u63d0\u4f9b\u4e86\u5168\u9762\u5b9e\u7528\u53c2\u8003\uff0c\u5229\u4e8e\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.11939", "pdf": "https://arxiv.org/pdf/2507.11939", "abs": "https://arxiv.org/abs/2507.11939", "authors": ["Yichen Xu", "Liangyu Chen", "Liang Zhang", "Wenxuan Wang", "Qin Jin"], "title": "POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "comment": "Work in Progress", "summary": "Charts are a universally adopted medium for interpreting and communicating\ndata. However, existing chart understanding benchmarks are predominantly\nEnglish-centric, limiting their accessibility and applicability to global\naudiences. In this paper, we present PolyChartQA, the first large-scale\nmultilingual chart question answering benchmark covering 22,606 charts and\n26,151 question-answering pairs across 10 diverse languages. PolyChartQA is\nbuilt using a decoupled pipeline that separates chart data from rendering code,\nallowing multilingual charts to be flexibly generated by simply translating the\ndata and reusing the code. We leverage state-of-the-art LLM-based translation\nand enforce rigorous quality control in the pipeline to ensure the linguistic\nand semantic consistency of the generated multilingual charts. PolyChartQA\nfacilitates systematic evaluation of multilingual chart understanding.\nExperiments on both open- and closed-source large vision-language models reveal\na significant performance gap between English and other languages, especially\nlow-resource ones with non-Latin scripts. This benchmark lays a foundation for\nadvancing globally inclusive vision-language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u56fe\u8868\u95ee\u7b54\u57fa\u51c6PolyChartQA\uff0c\u53ef\u4fc3\u8fdb\u591a\u8bed\u8a00\u56fe\u8868\u7406\u89e3\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u63ed\u793a\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u56fe\u8868\u7406\u89e3\u57fa\u51c6\u4ee5\u82f1\u8bed\u4e3a\u4e3b\uff0c\u9650\u5236\u4e86\u5168\u7403\u53d7\u4f17\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u9002\u7528\u6027\u3002", "method": "\u91c7\u7528\u89e3\u8026\u7ba1\u9053\uff0c\u5206\u79bb\u56fe\u8868\u6570\u636e\u548c\u6e32\u67d3\u4ee3\u7801\uff0c\u5229\u7528\u5148\u8fdb\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ffb\u8bd1\u5e76\u4e25\u683c\u63a7\u5236\u8d28\u91cf\u3002", "result": "\u5728\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u82f1\u8bed\u548c\u5176\u4ed6\u8bed\u8a00\uff08\u5c24\u5176\u662f\u4f4e\u8d44\u6e90\u975e\u62c9\u4e01\u6587\u5b57\u8bed\u8a00\uff09\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u63a8\u8fdb\u5168\u7403\u5305\u5bb9\u6027\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.12412", "pdf": "https://arxiv.org/pdf/2507.12412", "abs": "https://arxiv.org/abs/2507.12412", "authors": ["Dzung Dinh", "Boqi Chen", "Marc Niethammer", "Junier Oliva"], "title": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In many critical applications, resource constraints limit the amount of\ninformation that can be gathered to make predictions. For example, in\nhealthcare, patient data often spans diverse features ranging from lab tests to\nimaging studies. Each feature may carry different information and must be\nacquired at a respective cost of time, money, or risk to the patient. Moreover,\ntemporal prediction tasks, where both instance features and labels evolve over\ntime, introduce additional complexity in deciding when or what information is\nimportant. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff\nAcquisition method that sequentially acquires the most informative features at\ninference time while accounting for both temporal dynamics and acquisition\ncost. We first introduce a cohesive estimation target for our NOCTA setting,\nand then develop two complementary estimators: 1) a non-parametric method based\non nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric\nmethod that directly predicts the utility of potential acquisitions (NOCTA-P).\nExperiments on synthetic and real-world medical datasets demonstrate that both\nNOCTA variants outperform existing baselines.", "AI": {"tldr": "\u63d0\u51faNOCTA\u65b9\u6cd5\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u4e0b\u4fe1\u606f\u91c7\u96c6\u95ee\u9898\uff0c\u5728\u5408\u6210\u548c\u533b\u7597\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u5173\u952e\u5e94\u7528\u4e2d\u8d44\u6e90\u7ea6\u675f\u9650\u5236\u4fe1\u606f\u91c7\u96c6\u91cf\uff0c\u65f6\u95f4\u9884\u6d4b\u4efb\u52a1\u589e\u52a0\u51b3\u7b56\u590d\u6742\u6027\uff0c\u9700\u6709\u6548\u91c7\u96c6\u4fe1\u606f\u65b9\u6cd5\u3002", "method": "\u63d0\u51faNOCTA\u65b9\u6cd5\uff0c\u5f15\u5165\u4f30\u8ba1\u76ee\u6807\uff0c\u5f00\u53d1\u975e\u53c2\u6570\uff08NOCTA - NP\uff09\u548c\u53c2\u6570\uff08NOCTA - P\uff09\u4e24\u79cd\u4e92\u8865\u4f30\u8ba1\u5668\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cNOCTA\u4e24\u4e2a\u53d8\u4f53\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "NOCTA\u65b9\u6cd5\u5728\u8003\u8651\u65f6\u95f4\u52a8\u6001\u548c\u91c7\u96c6\u6210\u672c\u60c5\u51b5\u4e0b\uff0c\u80fd\u6709\u6548\u91c7\u96c6\u6700\u5177\u4fe1\u606f\u7279\u5f81\u3002"}}
{"id": "2507.11943", "pdf": "https://arxiv.org/pdf/2507.11943", "abs": "https://arxiv.org/abs/2507.11943", "authors": ["Haiwei Lin", "Shoko Imaizumi", "Hitoshi Kiya"], "title": "Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": "3 pages, 3 figures, conference", "summary": "We propose a low-rank adaptation method for training privacy-preserving\nvision transformer (ViT) models that efficiently freezes pre-trained ViT model\nweights. In the proposed method, trainable rank decomposition matrices are\ninjected into each layer of the ViT architecture, and moreover, the patch\nembedding layer is not frozen, unlike in the case of the conventional low-rank\nadaptation methods. The proposed method allows us not only to reduce the number\nof trainable parameters but to also maintain almost the same accuracy as that\nof full-time tuning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f4e\u79e9\u9002\u914d\u65b9\u6cd5\u8bad\u7ec3\u9690\u79c1\u4fdd\u62a4\u89c6\u89c9Transformer\u6a21\u578b\uff0c\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u4e14\u4fdd\u6301\u51c6\u786e\u7387\u3002", "motivation": "\u8bad\u7ec3\u9690\u79c1\u4fdd\u62a4\u7684\u89c6\u89c9Transformer\u6a21\u578b\uff0c\u540c\u65f6\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "method": "\u5728ViT\u67b6\u6784\u6bcf\u5c42\u6ce8\u5165\u53ef\u8bad\u7ec3\u7684\u79e9\u5206\u89e3\u77e9\u9635\uff0c\u4e14\u4e0d\u51bb\u7ed3\u8865\u4e01\u5d4c\u5165\u5c42\u3002", "result": "\u80fd\u51cf\u5c11\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u4e14\u4fdd\u6301\u4e0e\u5168\u65f6\u8c03\u4f18\u51e0\u4e4e\u76f8\u540c\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u4f4e\u79e9\u9002\u914d\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u8bad\u7ec3\u9690\u79c1\u4fdd\u62a4\u7684ViT\u6a21\u578b\u3002"}}
{"id": "2507.12419", "pdf": "https://arxiv.org/pdf/2507.12419", "abs": "https://arxiv.org/abs/2507.12419", "authors": ["Andrea Perin", "Giacomo Lagomarsini", "Claudio Gallicchio", "Giuseppe Nuti"], "title": "Mixture of Raytraced Experts", "categories": ["cs.LG", "cs.AI"], "comment": "Preliminary version (pre-submission)", "summary": "We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts\n(MoE) architecture which can dynamically select sequences of experts, producing\ncomputational graphs of variable width and depth. Existing MoE architectures\ngenerally require a fixed amount of computation for a given sample. Our\napproach, in contrast, yields predictions with increasing accuracy as the\ncomputation cycles through the experts' sequence. We train our model by\niteratively sampling from a set of candidate experts, unfolding the sequence\nakin to how Recurrent Neural Networks are trained. Our method does not require\nload-balancing mechanisms, and preliminary experiments show a reduction in\ntraining epochs of 10\\% to 40\\% with a comparable/higher accuracy. These\nresults point to new research directions in the field of MoEs, allowing the\ndesign of potentially faster and more expressive models. The code is available\nat https://github.com/nutig/RayTracing", "AI": {"tldr": "\u4ecb\u7ecd\u6df7\u5408\u5149\u7ebf\u8ffd\u8e2a\u4e13\u5bb6\u6a21\u578b\uff0c\u4e00\u79cd\u53ef\u52a8\u6001\u9009\u62e9\u4e13\u5bb6\u5e8f\u5217\u7684\u5806\u53e0\u5f0f\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u8bad\u7ec3\u65e0\u9700\u8d1f\u8f7d\u5747\u8861\u673a\u5236\uff0c\u5b9e\u9a8c\u663e\u793a\u51cf\u5c11\u8bad\u7ec3\u8f6e\u6b21\u4e14\u6709\u4e0d\u9519\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\u5bf9\u7ed9\u5b9a\u6837\u672c\u9700\u56fa\u5b9a\u8ba1\u7b97\u91cf\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u53ef\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u91cf\u5e76\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u7684\u67b6\u6784\u3002", "method": "\u901a\u8fc7\u4ece\u5019\u9009\u4e13\u5bb6\u96c6\u8fed\u4ee3\u91c7\u6837\uff0c\u50cf\u8bad\u7ec3\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u4e00\u6837\u5c55\u5f00\u5e8f\u5217\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u4e14\u65e0\u9700\u8d1f\u8f7d\u5747\u8861\u673a\u5236\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\u8bad\u7ec3\u8f6e\u6b21\u51cf\u5c1110% - 40%\uff0c\u4e14\u7cbe\u5ea6\u76f8\u5f53\u6216\u66f4\u9ad8\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6df7\u5408\u4e13\u5bb6\u9886\u57df\u6307\u51fa\u65b0\u65b9\u5411\uff0c\u53ef\u8bbe\u8ba1\u66f4\u5feb\u3001\u8868\u8fbe\u529b\u66f4\u5f3a\u7684\u6a21\u578b\u3002"}}
{"id": "2507.11947", "pdf": "https://arxiv.org/pdf/2507.11947", "abs": "https://arxiv.org/abs/2507.11947", "authors": ["Geon Park", "Seon Bin Kim", "Gunho Jung", "Seong-Whan Lee"], "title": "RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": "6 Pages", "summary": "With recent advancements in text-to-image (T2I) models, effectively\ngenerating multiple instances within a single image prompt has become a crucial\nchallenge. Existing methods, while successful in generating positions of\nindividual instances, often struggle to account for relationship discrepancy\nand multiple attributes leakage. To address these limitations, this paper\nproposes the relation-aware disentangled learning (RaDL) framework. RaDL\nenhances instance-specific attributes through learnable parameters and\ngenerates relation-aware image features via Relation Attention, utilizing\naction verbs extracted from the global prompt. Through extensive evaluations on\nbenchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that\nRaDL outperforms existing methods, showing significant improvements in\npositional accuracy, multiple attributes consideration, and the relationships\nbetween instances. Our results present RaDL as the solution for generating\nimages that consider both the relationships and multiple attributes of each\ninstance within the multi-instance image.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5173\u7cfb\u611f\u77e5\u89e3\u8026\u5b66\u4e60\uff08RaDL\uff09\u6846\u67b6\u4ee5\u89e3\u51b3\u5355\u56fe\u50cf\u63d0\u793a\u4e2d\u591a\u5b9e\u4f8b\u751f\u6210\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5728\u5355\u56fe\u50cf\u63d0\u793a\u4e2d\u751f\u6210\u591a\u5b9e\u4f8b\u65f6\uff0c\u96be\u4ee5\u89e3\u51b3\u5173\u7cfb\u5dee\u5f02\u548c\u591a\u5c5e\u6027\u6cc4\u6f0f\u95ee\u9898\u3002", "method": "\u63d0\u51faRaDL\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u53c2\u6570\u589e\u5f3a\u7279\u5b9a\u5b9e\u4f8b\u5c5e\u6027\uff0c\u5229\u7528\u4ece\u5168\u5c40\u63d0\u793a\u4e2d\u63d0\u53d6\u7684\u52a8\u4f5c\u52a8\u8bcd\uff0c\u901a\u8fc7\u5173\u7cfb\u6ce8\u610f\u529b\u751f\u6210\u5173\u7cfb\u611f\u77e5\u56fe\u50cf\u7279\u5f81\u3002", "result": "\u5728COCO - Position\u3001COCO - MIG\u548cDrawBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRaDL\u5728\u4f4d\u7f6e\u51c6\u786e\u6027\u3001\u591a\u5c5e\u6027\u8003\u8651\u548c\u5b9e\u4f8b\u95f4\u5173\u7cfb\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "RaDL\u662f\u89e3\u51b3\u591a\u5b9e\u4f8b\u56fe\u50cf\u4e2d\u8003\u8651\u5b9e\u4f8b\u5173\u7cfb\u548c\u591a\u5c5e\u6027\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2507.12435", "pdf": "https://arxiv.org/pdf/2507.12435", "abs": "https://arxiv.org/abs/2507.12435", "authors": ["Yi Li", "David Mccoy", "Nolan Gunter", "Kaitlyn Lee", "Alejandro Schuler", "Mark van der Laan"], "title": "Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Modern deep neural networks are powerful predictive tools yet often lack\nvalid inference for causal parameters, such as treatment effects or entire\nsurvival curves. While frameworks like Double Machine Learning (DML) and\nTargeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,\nexisting neural implementations either rely on \"targeted losses\" that do not\nguarantee solving the efficient influence function equation or computationally\nexpensive post-hoc \"fluctuations\" for multi-parameter settings. We propose\nTargeted Deep Architectures (TDA), a new framework that embeds TMLE directly\ninto the network's parameter space with no restrictions on the backbone\narchitecture. Specifically, TDA partitions model parameters - freezing all but\na small \"targeting\" subset - and iteratively updates them along a targeting\ngradient, derived from projecting the influence functions onto the span of the\ngradients of the loss with respect to weights. This procedure yields plug-in\nestimates that remove first-order bias and produce asymptotically valid\nconfidence intervals. Crucially, TDA easily extends to multi-dimensional causal\nestimands (e.g., entire survival curves) by merging separate targeting\ngradients into a single universal targeting update. Theoretically, TDA inherits\nclassical TMLE properties, including double robustness and semiparametric\nefficiency. Empirically, on the benchmark IHDP dataset (average treatment\neffects) and simulated survival data with informative censoring, TDA reduces\nbias and improves coverage relative to both standard neural-network estimators\nand prior post-hoc approaches. In doing so, TDA establishes a direct, scalable\npathway toward rigorous causal inference within modern deep architectures for\ncomplex multi-parameter targets.", "AI": {"tldr": "\u63d0\u51faTargeted Deep Architectures (TDA)\u6846\u67b6\uff0c\u5c06TMLE\u5d4c\u5165\u7f51\u7edc\u53c2\u6570\u7a7a\u95f4\uff0c\u53ef\u7528\u4e8e\u590d\u6742\u591a\u53c2\u6570\u76ee\u6807\u7684\u56e0\u679c\u63a8\u65ad\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7f3a\u4e4f\u5bf9\u56e0\u679c\u53c2\u6570\u7684\u6709\u6548\u63a8\u65ad\uff0c\u73b0\u6709\u795e\u7ecf\u5b9e\u73b0\u5b58\u5728\u7f3a\u9677\uff0c\u5982\u4e0d\u80fd\u4fdd\u8bc1\u89e3\u51b3\u6709\u6548\u5f71\u54cd\u51fd\u6570\u65b9\u7a0b\u6216\u8ba1\u7b97\u6602\u8d35\u3002", "method": "TDA\u5c06TMLE\u5d4c\u5165\u7f51\u7edc\u53c2\u6570\u7a7a\u95f4\uff0c\u5212\u5206\u6a21\u578b\u53c2\u6570\uff0c\u51bb\u7ed3\u90e8\u5206\u53c2\u6570\uff0c\u6cbf\u76ee\u6807\u68af\u5ea6\u8fed\u4ee3\u66f4\u65b0\uff0c\u53ef\u6269\u5c55\u5230\u591a\u7ef4\u56e0\u679c\u4f30\u8ba1\u91cf\u3002", "result": "\u5728\u57fa\u51c6IHDP\u6570\u636e\u96c6\u548c\u6a21\u62df\u751f\u5b58\u6570\u636e\u4e0a\uff0cTDA\u76f8\u6bd4\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u4f30\u8ba1\u5668\u548c\u5148\u524d\u7684\u4e8b\u540e\u65b9\u6cd5\u51cf\u5c11\u4e86\u504f\u5dee\uff0c\u63d0\u9ad8\u4e86\u8986\u76d6\u7387\u3002", "conclusion": "TDA\u4e3a\u73b0\u4ee3\u6df1\u5ea6\u67b6\u6784\u4e2d\u7684\u590d\u6742\u591a\u53c2\u6570\u76ee\u6807\u63d0\u4f9b\u4e86\u76f4\u63a5\u3001\u53ef\u6269\u5c55\u7684\u4e25\u683c\u56e0\u679c\u63a8\u65ad\u9014\u5f84\u3002"}}
{"id": "2507.11959", "pdf": "https://arxiv.org/pdf/2507.11959", "abs": "https://arxiv.org/abs/2507.11959", "authors": ["Xinyu Wang", "Vahid Partovi Nia", "Peng Lu", "Jerry Huang", "Xiao-Wen Chang", "Boxing Chen", "Yufei Cui"], "title": "PoTPTQ: A Two-step Power-of-Two Post-training for LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ECAI 2025 (European Conference on Artificial\n  Intelligence)", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious natural language processing (NLP) tasks. However, their deployment is\nchallenging due to the substantial computational resources required.\nPower-of-two (PoT) quantization is a general tool to counteract this\ndifficulty. Albeit previous works on PoT quantization can be efficiently\ndequantized on CPUs using fixed-point addition, it showed less effectiveness on\nGPUs. The reason is entanglement of the sign bit and sequential bit\nmanipulations needed for dequantization. We propose a novel POT quantization\nframework for LLM weights that (i) outperforms state-of-the-art accuracy in\nextremely low-precision number formats, and (ii) enables faster inference\nthrough more efficient dequantization. To maintain the accuracy of the\nquantized model, we introduce a two-step post-training algorithm: (i)\ninitialize the quantization scales with a robust starting point, and (ii)\nrefine these scales using a minimal calibration set. The performance of our PoT\npost-training algorithm surpasses the current state-of-the-art in integer\nquantization, particularly at low precisions such as 2- and 3-bit formats. Our\nPoT quantization accelerates the dequantization step required for the floating\npoint inference and leads to $3.67\\times$ speed up on a NVIDIA V100, and\n$1.63\\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u7684\u65b0\u578bPOT\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u6b65\u540e\u8bad\u7ec3\u7b97\u6cd5\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\uff0c\u5728\u4f4e\u7cbe\u5ea6\u4e0b\u8868\u73b0\u4f18\u4e14\u52a0\u901f\u53cd\u91cf\u5316\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u56e0\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\u800c\u56f0\u96be\uff0c\u73b0\u6709PoT\u91cf\u5316\u5728GPU\u4e0a\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u65b0\u578bPOT\u91cf\u5316\u6846\u67b6\uff0c\u5f15\u5165\u4e24\u6b65\u540e\u8bad\u7ec3\u7b97\u6cd5\uff1a\u7528\u7a33\u5065\u8d77\u70b9\u521d\u59cb\u5316\u91cf\u5316\u5c3a\u5ea6\uff0c\u7528\u6700\u5c0f\u6821\u51c6\u96c6\u7ec6\u5316\u5c3a\u5ea6\u3002", "result": "PoT\u540e\u8bad\u7ec3\u7b97\u6cd5\u5728\u4f4e\u7cbe\u5ea6\u4e0b\u8d85\u8d8a\u73b0\u6709\u6574\u6570\u91cf\u5316\u6280\u672f\uff0cPoT\u91cf\u5316\u52a0\u901f\u6d6e\u70b9\u63a8\u7406\u7684\u53cd\u91cf\u5316\u6b65\u9aa4\uff0c\u5728NVIDIA V100\u548cRTX 4090\u4e0a\u6709\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u65b0\u578bPOT\u91cf\u5316\u6846\u67b6\u6709\u6548\uff0c\u5728\u4f4e\u7cbe\u5ea6\u4e0b\u6709\u9ad8\u7cbe\u5ea6\u548c\u66f4\u5feb\u63a8\u7406\u901f\u5ea6\u3002"}}
{"id": "2507.12453", "pdf": "https://arxiv.org/pdf/2507.12453", "abs": "https://arxiv.org/abs/2507.12453", "authors": ["Qian Xie", "Linda Cai", "Alexander Terenin", "Peter I. Frazier", "Ziv Scully"], "title": "Cost-aware Stopping for Bayesian Optimization", "categories": ["cs.LG"], "comment": null, "summary": "In automated machine learning, scientific discovery, and other applications\nof Bayesian optimization, deciding when to stop evaluating expensive black-box\nfunctions is an important practical consideration. While several adaptive\nstopping rules have been proposed, in the cost-aware setting they lack\nguarantees ensuring they stop before incurring excessive function evaluation\ncosts. We propose a cost-aware stopping rule for Bayesian optimization that\nadapts to varying evaluation costs and is free of heuristic tuning. Our rule is\ngrounded in a theoretical connection to state-of-the-art cost-aware acquisition\nfunctions, namely the Pandora's Box Gittins Index (PBGI) and log expected\nimprovement per cost. We prove a theoretical guarantee bounding the expected\ncumulative evaluation cost incurred by our stopping rule when paired with these\ntwo acquisition functions. In experiments on synthetic and empirical tasks,\nincluding hyperparameter optimization and neural architecture size search, we\nshow that combining our stopping rule with the PBGI acquisition function\nconsistently matches or outperforms other acquisition-function--stopping-rule\npairs in terms of cost-adjusted simple regret, a metric capturing trade-offs\nbetween solution quality and cumulative evaluation cost.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u542f\u53d1\u5f0f\u8c03\u4f18\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u6210\u672c\u611f\u77e5\u505c\u6b62\u89c4\u5219\uff0c\u8bc1\u660e\u7406\u8bba\u4fdd\u8bc1\uff0c\u5b9e\u9a8c\u8868\u660e\u4e0ePBGI\u91c7\u96c6\u51fd\u6570\u7ed3\u5408\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u8d1d\u53f6\u65af\u4f18\u5316\u81ea\u9002\u5e94\u505c\u6b62\u89c4\u5219\u5728\u6210\u672c\u611f\u77e5\u573a\u666f\u4e0b\uff0c\u7f3a\u4e4f\u907f\u514d\u8fc7\u9ad8\u8bc4\u4f30\u6210\u672c\u7684\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e0e\u6700\u5148\u8fdb\u7684\u6210\u672c\u611f\u77e5\u91c7\u96c6\u51fd\u6570\u6709\u7406\u8bba\u8054\u7cfb\u7684\u505c\u6b62\u89c4\u5219\uff0c\u8bc1\u660e\u5176\u4e0e\u4e24\u79cd\u91c7\u96c6\u51fd\u6570\u914d\u5bf9\u65f6\u7684\u9884\u671f\u7d2f\u79ef\u8bc4\u4f30\u6210\u672c\u8fb9\u754c\u3002", "result": "\u5728\u5408\u6210\u548c\u5b9e\u8bc1\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u505c\u6b62\u89c4\u5219\u4e0ePBGI\u91c7\u96c6\u51fd\u6570\u7ed3\u5408\u5728\u6210\u672c\u8c03\u6574\u7b80\u5355\u540e\u6094\u6307\u6807\u4e0a\u5339\u914d\u6216\u4f18\u4e8e\u5176\u4ed6\u7ec4\u5408\u3002", "conclusion": "\u63d0\u51fa\u7684\u6210\u672c\u611f\u77e5\u505c\u6b62\u89c4\u5219\u6709\u6548\uff0c\u4e0ePBGI\u91c7\u96c6\u51fd\u6570\u7ed3\u5408\u80fd\u5728\u89e3\u8d28\u91cf\u548c\u7d2f\u79ef\u8bc4\u4f30\u6210\u672c\u95f4\u53d6\u5f97\u8f83\u597d\u5e73\u8861\u3002"}}
{"id": "2507.11966", "pdf": "https://arxiv.org/pdf/2507.11966", "abs": "https://arxiv.org/abs/2507.11966", "authors": ["Ziyu Ge", "Gabriel Chua", "Leanne Tan", "Roy Ka-Wei Lee"], "title": "Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "As online communication increasingly incorporates under-represented languages\nand colloquial dialects, standard translation systems often fail to preserve\nlocal slang, code-mixing, and culturally embedded markers of harmful speech.\nTranslating toxic content between low-resource language pairs poses additional\nchallenges due to scarce parallel data and safety filters that sanitize\noffensive expressions. In this work, we propose a reproducible, two-stage\nframework for toxicity-preserving translation, demonstrated on a code-mixed\nSinglish safety corpus. First, we perform human-verified few-shot prompt\nengineering: we iteratively curate and rank annotator-selected Singlish-target\nexamples to capture nuanced slang, tone, and toxicity. Second, we optimize\nmodel-prompt pairs by benchmarking several large language models using semantic\nsimilarity via direct and back-translation. Quantitative human evaluation\nconfirms the effectiveness and efficiency of our pipeline. Beyond improving\ntranslation quality, our framework contributes to the safety of multicultural\nLLMs by supporting culturally sensitive moderation and benchmarking in\nlow-resource contexts. By positioning Singlish as a testbed for inclusive NLP,\nwe underscore the importance of preserving sociolinguistic nuance in real-world\napplications such as content moderation and regional platform governance.", "AI": {"tldr": "\u63d0\u51fa\u6bd2\u6027\u4fdd\u7559\u7ffb\u8bd1\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5728\u65b0\u52a0\u5761\u82f1\u8bed\u5b89\u5168\u8bed\u6599\u5e93\u9a8c\u8bc1\uff0c\u8bc1\u660e\u6709\u6548\u4e14\u5bf9\u591a\u5143\u6587\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6709\u8d21\u732e\u3002", "motivation": "\u6807\u51c6\u7ffb\u8bd1\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u5c0f\u4f17\u8bed\u8a00\u548c\u65b9\u8a00\u4e2d\u7684\u6bd2\u6027\u5185\u5bb9\u7ffb\u8bd1\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7ffb\u8bd1\u6709\u989d\u5916\u6311\u6218\u3002", "method": "\u5206\u4e24\u9636\u6bb5\uff0c\u5148\u8fdb\u884c\u4eba\u5de5\u9a8c\u8bc1\u7684\u5c11\u6837\u672c\u63d0\u793a\u5de5\u7a0b\uff0c\u518d\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u4f18\u5316\u6a21\u578b - \u63d0\u793a\u5bf9\u3002", "result": "\u5b9a\u91cf\u4eba\u5de5\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u8fd8\u52a9\u529b\u591a\u5143\u6587\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\uff0c\u5f3a\u8c03\u4fdd\u7559\u793e\u4f1a\u8bed\u8a00\u7ec6\u5fae\u5dee\u522b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.11544", "pdf": "https://arxiv.org/pdf/2507.11544", "abs": "https://arxiv.org/abs/2507.11544", "authors": ["Ann-Kathrin Dombrowski", "Dillon Bowen", "Adam Gleave", "Chris Cundy"], "title": "The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models", "categories": ["cs.CY", "cs.LG", "68T07"], "comment": "9 pages plus appendix", "summary": "Open-weight large language models (LLMs) unlock huge benefits in innovation,\npersonalization, privacy, and democratization. However, their core advantage -\nmodifiability - opens the door to systemic risks: bad actors can trivially\nsubvert current safeguards, turning beneficial models into tools for harm. This\nleads to a 'safety gap': the difference in dangerous capabilities between a\nmodel with intact safeguards and one that has been stripped of those\nsafeguards. We open-source a toolkit to estimate the safety gap for\nstate-of-the-art open-weight models. As a case study, we evaluate biochemical\nand cyber capabilities, refusal rates, and generation quality of models from\ntwo families (Llama-3 and Qwen-2.5) across a range of parameter scales (0.5B to\n405B) using different safeguard removal techniques. Our experiments reveal that\nthe safety gap widens as model scale increases and effective dangerous\ncapabilities grow substantially when safeguards are removed. We hope that the\nSafety Gap Toolkit (https://github.com/AlignmentResearch/safety-gap) will serve\nas an evaluation framework for common open-source models and as a motivation\nfor developing and testing tamper-resistant safeguards. We welcome\ncontributions to the toolkit from the community.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4fee\u6539\u6027\u5e26\u6765\u5b89\u5168\u98ce\u9669\uff0c\u5f00\u6e90\u5de5\u5177\u5305\u8bc4\u4f30\u5b89\u5168\u5dee\u8ddd\uff0c\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u89c4\u6a21\u589e\u52a0\u5b89\u5168\u5dee\u8ddd\u6269\u5927\uff0c\u547c\u5401\u793e\u533a\u8d21\u732e\u3002", "motivation": "\u89e3\u51b3\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u53ef\u4fee\u6539\u6027\u5e26\u6765\u7684\u7cfb\u7edf\u98ce\u9669\uff0c\u8bc4\u4f30\u5176\u5b89\u5168\u5dee\u8ddd\u3002", "method": "\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u4ee5Llama - 3\u548cQwen - 2.5\u7cfb\u5217\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u6a21\u578b\u4e3a\u4f8b\uff0c\u7528\u4e0d\u540c\u9632\u62a4\u79fb\u9664\u6280\u672f\u8bc4\u4f30\u751f\u5316\u548c\u7f51\u7edc\u80fd\u529b\u3001\u62d2\u7edd\u7387\u548c\u751f\u6210\u8d28\u91cf\u3002", "result": "\u6a21\u578b\u89c4\u6a21\u589e\u52a0\u5b89\u5168\u5dee\u8ddd\u6269\u5927\uff0c\u79fb\u9664\u9632\u62a4\u540e\u5371\u9669\u80fd\u529b\u5927\u5e45\u589e\u957f\u3002", "conclusion": "\u5b89\u5168\u5dee\u8ddd\u5de5\u5177\u5305\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u6846\u67b6\uff0c\u6fc0\u52b1\u5f00\u53d1\u6297\u7be1\u6539\u9632\u62a4\u63aa\u65bd\uff0c\u6b22\u8fce\u793e\u533a\u8d21\u732e\u3002"}}
{"id": "2507.11579", "pdf": "https://arxiv.org/pdf/2507.11579", "abs": "https://arxiv.org/abs/2507.11579", "authors": ["Sathvik Chereddy", "John Femiani"], "title": "SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation", "categories": ["cs.CV", "cs.LG"], "comment": "17 pages, 63 figures, Proceedings of the 42nd International\n  Conference on Machine Learning (ICML2025)", "summary": "We present SketchDNN, a generative model for synthesizing CAD sketches that\njointly models both continuous parameters and discrete class labels through a\nunified continuous-discrete diffusion process. Our core innovation is\nGaussian-Softmax diffusion, where logits perturbed with Gaussian noise are\nprojected onto the probability simplex via a softmax transformation,\nfacilitating blended class labels for discrete variables. This formulation\naddresses 2 key challenges, namely, the heterogeneity of primitive\nparameterizations and the permutation invariance of primitives in CAD sketches.\nOur approach significantly improves generation quality, reducing Fr\\'echet\nInception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)\nfrom 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch\ngeneration on the SketchGraphs dataset.", "AI": {"tldr": "\u63d0\u51faSketchDNN\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u7edf\u4e00\u8fde\u7eed - \u79bb\u6563\u6269\u6563\u8fc7\u7a0b\u5408\u6210CAD\u8349\u56fe\uff0c\u6539\u5584\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3CAD\u8349\u56fe\u4e2d\u539f\u59cb\u53c2\u6570\u5316\u7684\u5f02\u8d28\u6027\u548c\u539f\u59cb\u56fe\u5143\u7684\u6392\u5217\u4e0d\u53d8\u6027\u8fd9\u4e24\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528Gaussian - Softmax\u6269\u6563\uff0c\u5c06\u53d7\u9ad8\u65af\u566a\u58f0\u5e72\u6270\u7684\u5bf9\u6570\u51e0\u7387\u901a\u8fc7softmax\u53d8\u6362\u6295\u5f71\u5230\u6982\u7387\u5355\u7eaf\u5f62\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u5c06Fr\u00e9chet Inception Distance (FID)\u4ece16.04\u964d\u81f37.80\uff0c\u8d1f\u5bf9\u6570\u4f3c\u7136 (NLL)\u4ece84.8\u964d\u81f381.33\u3002", "conclusion": "\u5728SketchGraphs\u6570\u636e\u96c6\u7684CAD\u8349\u56fe\u751f\u6210\u4e2d\u8fbe\u5230\u65b0\u7684\u6700\u4f18\u6c34\u5e73\u3002"}}
{"id": "2507.11987", "pdf": "https://arxiv.org/pdf/2507.11987", "abs": "https://arxiv.org/abs/2507.11987", "authors": ["Thomas A. Henzinger", "Konstantin Kueffner", "Emily Yu"], "title": "Formal Verification of Neural Certificates Done Dynamically", "categories": ["cs.SC", "cs.AI"], "comment": "Accepted at RV'25", "summary": "Neural certificates have emerged as a powerful tool in cyber-physical systems\ncontrol, providing witnesses of correctness. These certificates, such as\nbarrier functions, often learned alongside control policies, once verified,\nserve as mathematical proofs of system safety. However, traditional formal\nverification of their defining conditions typically faces scalability\nchallenges due to exhaustive state-space exploration. To address this\nchallenge, we propose a lightweight runtime monitoring framework that\nintegrates real-time verification and does not require access to the underlying\ncontrol policy. Our monitor observes the system during deployment and performs\non-the-fly verification of the certificate over a lookahead region to ensure\nsafety within a finite prediction horizon. We instantiate this framework for\nReLU-based control barrier functions and demonstrate its practical\neffectiveness in a case study. Our approach enables timely detection of safety\nviolations and incorrect certificates with minimal overhead, providing an\neffective but lightweight alternative to the static verification of the\ncertificates.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8fd0\u884c\u65f6\u76d1\u63a7\u6846\u67b6\u89e3\u51b3\u795e\u7ecf\u8bc1\u4e66\u5f62\u5f0f\u9a8c\u8bc1\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u5728\u6848\u4f8b\u4e2d\u5c55\u793a\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u8bc1\u4e66\u5f62\u5f0f\u9a8c\u8bc1\u56e0\u72b6\u6001\u7a7a\u95f4\u7a77\u4e3e\u63a2\u7d22\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8fd0\u884c\u65f6\u76d1\u63a7\u6846\u67b6\uff0c\u5728\u90e8\u7f72\u65f6\u89c2\u5bdf\u7cfb\u7edf\uff0c\u5bf9\u524d\u77bb\u533a\u57df\u5185\u7684\u8bc1\u4e66\u8fdb\u884c\u5373\u65f6\u9a8c\u8bc1\u3002", "result": "\u5728ReLU\u63a7\u5236\u969c\u788d\u51fd\u6570\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u53ca\u65f6\u68c0\u6d4b\u5b89\u5168\u8fdd\u89c4\u548c\u9519\u8bef\u8bc1\u4e66\uff0c\u5f00\u9500\u5c0f\uff0c\u662f\u9759\u6001\u9a8c\u8bc1\u7684\u6709\u6548\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.11991", "pdf": "https://arxiv.org/pdf/2507.11991", "abs": "https://arxiv.org/abs/2507.11991", "authors": ["Juanran Wang", "Marc R. Schlichting", "Mykel J. Kochenderfer"], "title": "Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "High-risk traffic zones such as intersections are a major cause of\ncollisions. This study leverages deep generative models to enhance the safety\nof autonomous vehicles in an intersection context. We train a 1000-step\ndenoising diffusion probabilistic model to generate collision-causing sensor\nnoise sequences for an autonomous vehicle navigating a four-way intersection\nbased on the current relative position and velocity of an intruder. Using the\ngenerative adversarial architecture, the 1000-step model is distilled into a\nsingle-step denoising diffusion model which demonstrates fast inference speed\nwhile maintaining similar sampling quality. We demonstrate one possible\napplication of the single-step model in building a robust planner for the\nautonomous vehicle. The planner uses the single-step model to efficiently\nsample potential failure cases based on the currently measured traffic state to\ninform its decision-making. Through simulation experiments, the robust planner\ndemonstrates significantly lower failure rate and delay rate compared with the\nbaseline Intelligent Driver Model controller.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u589e\u5f3a\u5341\u5b57\u8def\u53e3\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5b89\u5168\uff0c\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u78b0\u649e\u566a\u58f0\u5e8f\u5217\uff0c\u84b8\u998f\u4e3a\u5355\u6b65\u6a21\u578b\uff0c\u7528\u4e8e\u6784\u5efa\u9c81\u68d2\u89c4\u5212\u5668\uff0c\u4eff\u771f\u663e\u793a\u5176\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u63a7\u5236\u5668\u3002", "motivation": "\u63d0\u5347\u5341\u5b57\u8def\u53e3\u7b49\u9ad8\u5371\u4ea4\u901a\u533a\u57df\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u5b89\u5168\u6027\u3002", "method": "\u8bad\u7ec31000\u6b65\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u751f\u6210\u78b0\u649e\u566a\u58f0\u5e8f\u5217\uff0c\u7528\u751f\u6210\u5bf9\u6297\u67b6\u6784\u5c06\u5176\u84b8\u998f\u4e3a\u5355\u6b65\u53bb\u566a\u6269\u6563\u6a21\u578b\u3002", "result": "\u5355\u6b65\u6a21\u578b\u80fd\u5feb\u901f\u63a8\u7406\u4e14\u91c7\u6837\u8d28\u91cf\u76f8\u8fd1\uff0c\u57fa\u4e8e\u5176\u6784\u5efa\u7684\u9c81\u68d2\u89c4\u5212\u5668\u5728\u4eff\u771f\u4e2d\u5931\u8d25\u7387\u548c\u5ef6\u8fdf\u7387\u663e\u8457\u4f4e\u4e8e\u57fa\u7ebf\u63a7\u5236\u5668\u3002", "conclusion": "\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u53ef\u6709\u6548\u63d0\u5347\u5341\u5b57\u8def\u53e3\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2507.12006", "pdf": "https://arxiv.org/pdf/2507.12006", "abs": "https://arxiv.org/abs/2507.12006", "authors": ["Linwei Chen", "Lin Gu", "Ying Fu"], "title": "Frequency-Dynamic Attention Modulation for Dense Prediction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICCV 2025", "summary": "Vision Transformers (ViTs) have significantly advanced computer vision,\ndemonstrating strong performance across various tasks. However, the attention\nmechanism in ViTs makes each layer function as a low-pass filter, and the\nstacked-layer architecture in existing transformers suffers from frequency\nvanishing. This leads to the loss of critical details and textures. We propose\na novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention\nModulation (FDAM), which can be easily plugged into ViTs. FDAM directly\nmodulates the overall frequency response of ViTs and consists of two\ntechniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling\n(FreqScale). Since circuit theory uses low-pass filters as fundamental\nelements, we introduce AttInv, a method that generates complementary high-pass\nfiltering by inverting the low-pass filter in the attention matrix, and\ndynamically combining the two. We further design FreqScale to weight different\nfrequency components for fine-grained adjustments to the target response\nfunction. Through feature similarity analysis and effective rank evaluation, we\ndemonstrate that our approach avoids representation collapse, leading to\nconsistent performance improvements across various models, including SegFormer,\nDeiT, and MaskDINO. These improvements are evident in tasks such as semantic\nsegmentation, object detection, and instance segmentation. Additionally, we\napply our method to remote sensing detection, achieving state-of-the-art\nresults in single-scale settings. The code is available at\n\\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.", "AI": {"tldr": "\u63d0\u51faFDAM\u7b56\u7565\u89e3\u51b3ViTs\u9891\u7387\u6d88\u5931\u95ee\u9898\uff0c\u5728\u591a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u63d0\u5347\u6027\u80fd\uff0c\u5728\u9065\u611f\u68c0\u6d4b\u8fbeSOTA\u3002", "motivation": "ViTs\u7684\u6ce8\u610f\u529b\u673a\u5236\u4f7f\u6bcf\u5c42\u4e3a\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u5806\u53e0\u67b6\u6784\u5b58\u5728\u9891\u7387\u6d88\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u5173\u952e\u7ec6\u8282\u548c\u7eb9\u7406\u4e22\u5931\u3002", "method": "\u63d0\u51faFrequency - Dynamic Attention Modulation (FDAM)\u7b56\u7565\uff0c\u5305\u542bAttention Inversion (AttInv)\u548cFrequency Dynamic Scaling (FreqScale)\u4e24\u79cd\u6280\u672f\u3002", "result": "\u901a\u8fc7\u7279\u5f81\u76f8\u4f3c\u6027\u5206\u6790\u548c\u6709\u6548\u79e9\u8bc4\u4f30\uff0c\u907f\u514d\u8868\u793a\u5d29\u6e83\uff0c\u5728\u591a\u6a21\u578b\u548c\u591a\u4efb\u52a1\u4e0a\u6027\u80fd\u63d0\u5347\uff0c\u5728\u9065\u611f\u68c0\u6d4b\u5355\u5c3a\u5ea6\u8bbe\u7f6e\u4e2d\u8fbeSOTA\u3002", "conclusion": "FDAM\u7b56\u7565\u80fd\u6709\u6548\u89e3\u51b3ViTs\u9891\u7387\u6d88\u5931\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.12008", "pdf": "https://arxiv.org/pdf/2507.12008", "abs": "https://arxiv.org/abs/2507.12008", "authors": ["Jiawen Wang", "Yinda Chen", "Xiaoyu Liu", "Che Liu", "Dong Liu", "Jianqing Gao", "Zhiwei Xiong"], "title": "Dual form Complementary Masking for Domain-Adaptive Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Recent works have correlated Masked Image Modeling (MIM) with consistency\nregularization in Unsupervised Domain Adaptation (UDA). However, they merely\ntreat masking as a special form of deformation on the input images and neglect\nthe theoretical analysis, which leads to a superficial understanding of masked\nreconstruction and insufficient exploitation of its potential in enhancing\nfeature extraction and representation learning. In this paper, we reframe\nmasked reconstruction as a sparse signal reconstruction problem and\ntheoretically prove that the dual form of complementary masks possesses\nsuperior capabilities in extracting domain-agnostic image features. Based on\nthis compelling insight, we propose MaskTwins, a simple yet effective UDA\nframework that integrates masked reconstruction directly into the main training\npipeline. MaskTwins uncovers intrinsic structural patterns that persist across\ndisparate domains by enforcing consistency between predictions of images masked\nin complementary ways, enabling domain generalization in an end-to-end manner.\nExtensive experiments verify the superiority of MaskTwins over baseline methods\nin natural and biological image segmentation. These results demonstrate the\nsignificant advantages of MaskTwins in extracting domain-invariant features\nwithout the need for separate pre-training, offering a new paradigm for\ndomain-adaptive segmentation.", "AI": {"tldr": "\u672c\u6587\u5c06\u63a9\u7801\u91cd\u5efa\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7a00\u758f\u4fe1\u53f7\u91cd\u5efa\u95ee\u9898\uff0c\u63d0\u51faMaskTwins\u6846\u67b6\u7528\u4e8e\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u81ea\u7136\u548c\u751f\u7269\u56fe\u50cf\u5206\u5272\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4ec5\u5c06\u63a9\u7801\u89c6\u4e3a\u8f93\u5165\u56fe\u50cf\u53d8\u5f62\uff0c\u7f3a\u4e4f\u7406\u8bba\u5206\u6790\uff0c\u5bf9\u63a9\u7801\u91cd\u5efa\u7406\u89e3\u80a4\u6d45\uff0c\u672a\u5145\u5206\u6316\u6398\u5176\u5728\u7279\u5f81\u63d0\u53d6\u548c\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u5c06\u63a9\u7801\u91cd\u5efa\u91cd\u6784\u4e3a\u7a00\u758f\u4fe1\u53f7\u91cd\u5efa\u95ee\u9898\uff0c\u8bc1\u660e\u4e92\u8865\u63a9\u7801\u5bf9\u5076\u5f62\u5f0f\u5728\u63d0\u53d6\u57df\u65e0\u5173\u56fe\u50cf\u7279\u5f81\u4e0a\u7684\u4f18\u52bf\uff0c\u63d0\u51faMaskTwins\u6846\u67b6\uff0c\u5728\u4e3b\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u96c6\u6210\u63a9\u7801\u91cd\u5efa\uff0c\u901a\u8fc7\u5f3a\u5236\u4e92\u8865\u63a9\u7801\u56fe\u50cf\u9884\u6d4b\u7684\u4e00\u81f4\u6027\u6316\u6398\u8de8\u57df\u7ed3\u6784\u6a21\u5f0f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMaskTwins\u5728\u81ea\u7136\u548c\u751f\u7269\u56fe\u50cf\u5206\u5272\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MaskTwins\u5728\u65e0\u9700\u5355\u72ec\u9884\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u63d0\u53d6\u57df\u4e0d\u53d8\u7279\u5f81\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u57df\u81ea\u9002\u5e94\u5206\u5272\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.11642", "pdf": "https://arxiv.org/pdf/2507.11642", "abs": "https://arxiv.org/abs/2507.11642", "authors": ["Abhishek Jaiswal", "Nisheeth Srivastava"], "title": "Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Posture-based mental state inference has significant potential in diagnosing\nfatigue, preventing injury, and enhancing performance across various domains.\nSuch tools must be research-validated with large datasets before being\ntranslated into practice. Unfortunately, such vision diagnosis faces serious\nchallenges due to the sensitivity of human subject data. To address this, we\nidentify sports settings as a viable alternative for accumulating data from\nhuman subjects experiencing diverse emotional states. We test our hypothesis in\nthe game of cricket and present a posture-based solution to identify human\nintent from activity videos. Our method achieves over 75\\% F1 score and over\n80\\% AUC-ROC in discriminating aggressive and defensive shot intent through\nmotion analysis. These findings indicate that posture leaks out strong signals\nfor intent inference, even with inherent noise in the data pipeline.\nFurthermore, we utilize existing data statistics as weak supervision to\nvalidate our findings, offering a potential solution for overcoming data\nlabelling limitations. This research contributes to generalizable techniques\nfor sports analytics and also opens possibilities for applying human behavior\nanalysis across various fields.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u57fa\u4e8e\u59ff\u52bf\u7684\u5fc3\u7406\u72b6\u6001\u63a8\u65ad\uff0c\u4ee5\u677f\u7403\u8fd0\u52a8\u4e3a\u4f8b\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\uff0c\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u8fd8\u5229\u7528\u6570\u636e\u7edf\u8ba1\u4f5c\u5f31\u76d1\u7763\uff0c\u4e3a\u4f53\u80b2\u5206\u6790\u548c\u591a\u9886\u57df\u4eba\u7c7b\u884c\u4e3a\u5206\u6790\u63d0\u4f9b\u53ef\u80fd\u3002", "motivation": "\u57fa\u4e8e\u59ff\u52bf\u7684\u5fc3\u7406\u72b6\u6001\u63a8\u65ad\u5de5\u5177\u9700\u7ecf\u5927\u6570\u636e\u96c6\u9a8c\u8bc1\u624d\u80fd\u5e94\u7528\uff0c\u4f46\u89c6\u89c9\u8bca\u65ad\u56e0\u4eba\u7c7b\u6570\u636e\u654f\u611f\u9762\u4e34\u6311\u6218\uff0c\u9700\u5bfb\u627e\u79ef\u7d2f\u6570\u636e\u7684\u9014\u5f84\u3002", "method": "\u4ee5\u677f\u7403\u8fd0\u52a8\u4e3a\u573a\u666f\uff0c\u901a\u8fc7\u8fd0\u52a8\u5206\u6790\u4ece\u6d3b\u52a8\u89c6\u9891\u4e2d\u8bc6\u522b\u4eba\u7c7b\u610f\u56fe\uff1b\u5229\u7528\u73b0\u6709\u6570\u636e\u7edf\u8ba1\u4f5c\u5f31\u76d1\u7763\u9a8c\u8bc1\u7ed3\u679c\u3002", "result": "\u65b9\u6cd5\u5728\u533a\u5206\u653b\u51fb\u6027\u548c\u9632\u5fa1\u6027\u51fb\u7403\u610f\u56fe\u65f6F1\u5206\u6570\u8d8575%\uff0cAUC - ROC\u8d8580%\u3002", "conclusion": "\u59ff\u52bf\u80fd\u4e3a\u610f\u56fe\u63a8\u65ad\u63d0\u4f9b\u5f3a\u4fe1\u53f7\uff0c\u7814\u7a76\u4e3a\u4f53\u80b2\u5206\u6790\u63d0\u4f9b\u901a\u7528\u6280\u672f\uff0c\u4e5f\u4e3a\u591a\u9886\u57df\u4eba\u7c7b\u884c\u4e3a\u5206\u6790\u5e26\u6765\u53ef\u80fd\u3002"}}
{"id": "2507.12012", "pdf": "https://arxiv.org/pdf/2507.12012", "abs": "https://arxiv.org/abs/2507.12012", "authors": ["Matthias Perkonigg", "Nina Bastati", "Ahmed Ba-Ssalamah", "Peter Mesenbrink", "Alexander Goehler", "Miljen Martic", "Xiaofei Zhou", "Michael Trauner", "Georg Langs"], "title": "Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Quantifiable image patterns associated with disease progression and treatment\nresponse are critical tools for guiding individual treatment, and for\ndeveloping novel therapies. Here, we show that unsupervised machine learning\ncan identify a pattern vocabulary of liver tissue in magnetic resonance images\nthat quantifies treatment response in diffuse liver disease. Deep clustering\nnetworks simultaneously encode and cluster patches of medical images into a\nlow-dimensional latent space to establish a tissue vocabulary. The resulting\ntissue types capture differential tissue change and its location in the liver\nassociated with treatment response. We demonstrate the utility of the\nvocabulary on a randomized controlled trial cohort of non-alcoholic\nsteatohepatitis patients. First, we use the vocabulary to compare longitudinal\nliver change in a placebo and a treatment cohort. Results show that the method\nidentifies specific liver tissue change pathways associated with treatment, and\nenables a better separation between treatment groups than established\nnon-imaging measures. Moreover, we show that the vocabulary can predict biopsy\nderived features from non-invasive imaging data. We validate the method on a\nseparate replication cohort to demonstrate the applicability of the proposed\nmethod.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u8bc6\u522b\u809d\u810f\u7ec4\u7ec7\u56fe\u50cf\u6a21\u5f0f\u8bcd\u6c47\u8868\uff0c\u91cf\u5316\u5f25\u6f2b\u6027\u809d\u75c5\u6cbb\u7597\u53cd\u5e94\uff0c\u5e76\u5728\u8bd5\u9a8c\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u53ef\u91cf\u5316\u7684\u75be\u75c5\u8fdb\u5c55\u548c\u6cbb\u7597\u53cd\u5e94\u7684\u56fe\u50cf\u6a21\u5f0f\u5bf9\u6307\u5bfc\u4e2a\u4f53\u5316\u6cbb\u7597\u548c\u5f00\u53d1\u65b0\u7597\u6cd5\u81f3\u5173\u91cd\u8981\uff0c\u9700\u627e\u5230\u91cf\u5316\u6cbb\u7597\u53cd\u5e94\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u805a\u7c7b\u7f51\u7edc\u5bf9\u533b\u5b66\u56fe\u50cf\u5757\u8fdb\u884c\u7f16\u7801\u548c\u805a\u7c7b\uff0c\u5efa\u7acb\u7ec4\u7ec7\u8bcd\u6c47\u8868\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u8bc6\u522b\u4e0e\u6cbb\u7597\u76f8\u5173\u7684\u7279\u5b9a\u809d\u810f\u7ec4\u7ec7\u53d8\u5316\u9014\u5f84\uff0c\u6bd4\u73b0\u6709\u975e\u6210\u50cf\u6307\u6807\u80fd\u66f4\u597d\u533a\u5206\u6cbb\u7597\u7ec4\uff0c\u8fd8\u80fd\u4ece\u65e0\u521b\u6210\u50cf\u6570\u636e\u9884\u6d4b\u6d3b\u68c0\u7279\u5f81\u3002", "conclusion": "\u5728\u72ec\u7acb\u9a8c\u8bc1\u961f\u5217\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2507.12017", "pdf": "https://arxiv.org/pdf/2507.12017", "abs": "https://arxiv.org/abs/2507.12017", "authors": ["Xiwei Zhang", "Chunjin Yang", "Yiming Xiao", "Runtong Zhang", "Fanman Meng"], "title": "SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": "8 main-pages, 3 reference-pages, 5 figures, 6 tables", "summary": "Unsupervised domain adaptive object detection (UDAOD) from the visible domain\nto the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB\ndomain as a unified domain and neglect the multiple subdomains within it, such\nas daytime, nighttime, and foggy scenes. We argue that decoupling the\ndomain-invariant (DI) and domain-specific (DS) features across these multiple\nsubdomains is beneficial for RGB-IR domain adaptation. To this end, this paper\nproposes a new SS-DC framework based on a decoupling-coupling strategy. In\nterms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)\nmodule in the aspect of spectral decomposition. Due to the style and content\ninformation being highly embedded in different frequency bands, this module can\ndecouple DI and DS components more accurately and interpretably. A novel filter\nbank-based spectral processing paradigm and a self-distillation-driven\ndecoupling loss are proposed to improve the spectral domain decoupling. In\nterms of coupling, a new spatial-spectral coupling method is proposed, which\nrealizes joint coupling through spatial and spectral DI feature pyramids.\nMeanwhile, this paper introduces DS from decoupling to reduce the domain bias.\nExtensive experiments demonstrate that our method can significantly improve the\nbaseline performance and outperform existing UDAOD methods on multiple RGB-IR\ndatasets, including a new experimental protocol proposed in this paper based on\nthe FLIR-ADAS dataset.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89e3\u8026 - \u8026\u5408\u7b56\u7565\u7684SS - DC\u6846\u67b6\u7528\u4e8eRGB - IR\u9886\u57df\u7684\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709RGB - IR\u9886\u57df\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\u5c06RGB\u57df\u89c6\u4e3a\u7edf\u4e00\u57df\uff0c\u5ffd\u7565\u5176\u4e2d\u591a\u4e2a\u5b50\u57df\uff0c\u672c\u6587\u8ba4\u4e3a\u89e3\u8026\u591a\u4e2a\u5b50\u57df\u7684\u57df\u4e0d\u53d8\u548c\u57df\u7279\u5b9a\u7279\u5f81\u6709\u5229\u4e8eRGB - IR\u57df\u9002\u5e94\u3002", "method": "\u63d0\u51faSS - DC\u6846\u67b6\uff0c\u8bbe\u8ba1SAID\u6a21\u5757\u89e3\u8026\uff0c\u63d0\u51fa\u57fa\u4e8e\u6ee4\u6ce2\u5668\u7ec4\u7684\u5149\u8c31\u5904\u7406\u8303\u5f0f\u548c\u81ea\u84b8\u998f\u9a71\u52a8\u7684\u89e3\u8026\u635f\u5931\u6539\u8fdb\u89e3\u8026\uff0c\u63d0\u51fa\u7a7a\u95f4 - \u5149\u8c31\u8026\u5408\u65b9\u6cd5\u5e76\u5f15\u5165\u57df\u7279\u5b9a\u7279\u5f81\u51cf\u5c11\u57df\u504f\u5dee\u3002", "result": "\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u57fa\u7ebf\u6027\u80fd\uff0c\u5728\u591a\u4e2aRGB - IR\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709UDAOD\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0SS - DC\u6846\u67b6\u5728RGB - IR\u65e0\u76d1\u7763\u57df\u81ea\u9002\u5e94\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e2d\u6709\u6548\u3002"}}
{"id": "2507.12029", "pdf": "https://arxiv.org/pdf/2507.12029", "abs": "https://arxiv.org/abs/2507.12029", "authors": ["Xinhang Wan", "Jiyuan Liu", "Qian Qu", "Suyuan Liu", "Chuyu Zhang", "Fangdi Wang", "Xinwang Liu", "En Zhu", "Kunlun He"], "title": "Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this paper, we address the problem of novel class discovery (NCD), which\naims to cluster novel classes by leveraging knowledge from disjoint known\nclasses. While recent advances have made significant progress in this area,\nexisting NCD methods face two major limitations. First, they primarily focus on\nsingle-view data (e.g., images), overlooking the increasingly common multi-view\ndata, such as multi-omics datasets used in disease diagnosis. Second, their\nreliance on pseudo-labels to supervise novel class clustering often results in\nunstable performance, as pseudo-label quality is highly sensitive to factors\nsuch as data noise and feature dimensionality. To address these challenges, we\npropose a novel framework named Intra-view and Inter-view Correlation Guided\nMulti-view Novel Class Discovery (IICMVNCD), which is the first attempt to\nexplore NCD in multi-view setting so far. Specifically, at the intra-view\nlevel, leveraging the distributional similarity between known and novel\nclasses, we employ matrix factorization to decompose features into\nview-specific shared base matrices and factor matrices. The base matrices\ncapture distributional consistency among the two datasets, while the factor\nmatrices model pairwise relationships between samples. At the inter-view level,\nwe utilize view relationships among known classes to guide the clustering of\nnovel classes. This includes generating predicted labels through the weighted\nfusion of factor matrices and dynamically adjusting view weights of known\nclasses based on the supervision loss, which are then transferred to novel\nclass learning. Experimental results validate the effectiveness of our proposed\napproach.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u65b0\u9896\u7c7b\u53d1\u73b0\uff08NCD\uff09\u95ee\u9898\uff0c\u6307\u51fa\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\uff0c\u63d0\u51faIICMVNCD\u6846\u67b6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709NCD\u65b9\u6cd5\u4e3b\u8981\u5904\u7406\u5355\u89c6\u56fe\u6570\u636e\uff0c\u4e14\u4f9d\u8d56\u4f2a\u6807\u7b7e\u5bfc\u81f4\u6027\u80fd\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u89e3\u51b3\u591a\u89c6\u56fe\u6570\u636e\u7684NCD\u95ee\u9898\u3002", "method": "\u63d0\u51faIICMVNCD\u6846\u67b6\uff0c\u5728\u89c6\u56fe\u5185\u5229\u7528\u5206\u5e03\u76f8\u4f3c\u6027\u8fdb\u884c\u77e9\u9635\u5206\u89e3\uff0c\u5728\u89c6\u56fe\u95f4\u5229\u7528\u5df2\u77e5\u7c7b\u89c6\u56fe\u5173\u7cfb\u6307\u5bfc\u65b0\u9896\u7c7b\u805a\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "IICMVNCD\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u591a\u89c6\u56fe\u6570\u636e\u7684\u65b0\u9896\u7c7b\u53d1\u73b0\u95ee\u9898\u3002"}}
{"id": "2507.12060", "pdf": "https://arxiv.org/pdf/2507.12060", "abs": "https://arxiv.org/abs/2507.12060", "authors": ["Kun-Hsiang Lin", "Yu-Wen Tseng", "Kang-Yang Huang", "Jhih-Ciang Wu", "Wen-Huang Cheng"], "title": "InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Accepted by MM'25", "summary": "Face anti-spoofing (FAS) aims to construct a robust system that can withstand\ndiverse attacks. While recent efforts have concentrated mainly on cross-domain\ngeneralization, two significant challenges persist: limited semantic\nunderstanding of attack types and training redundancy across domains. We\naddress the first by integrating vision-language models (VLMs) to enhance the\nperception of visual input. For the second challenge, we employ a meta-domain\nstrategy to learn a unified model that generalizes well across multiple\ndomains. Our proposed InstructFLIP is a novel instruction-tuned framework that\nleverages VLMs to enhance generalization via textual guidance trained solely on\na single domain. At its core, InstructFLIP explicitly decouples instructions\ninto content and style components, where content-based instructions focus on\nthe essential semantics of spoofing, and style-based instructions consider\nvariations related to the environment and camera characteristics. Extensive\nexperiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA\nmodels in accuracy and substantially reducing training redundancy across\ndiverse domains in FAS. Project website is available at\nhttps://kunkunlin1221.github.io/InstructFLIP.", "AI": {"tldr": "\u63d0\u51faInstructFLIP\u6846\u67b6\u89e3\u51b3\u4eba\u8138\u53cd\u6b3a\u9a97\u4e2d\u653b\u51fb\u7c7b\u578b\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3\u548c\u8de8\u57df\u8bad\u7ec3\u5197\u4f59\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u6548\u679c\u4f18\u4e8eSOTA\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u4eba\u8138\u53cd\u6b3a\u9a97\u4e2d\u653b\u51fb\u7c7b\u578b\u8bed\u4e49\u7406\u89e3\u6709\u9650\u548c\u8de8\u57df\u8bad\u7ec3\u5197\u4f59\u4e24\u4e2a\u6311\u6218\u3002", "method": "\u96c6\u6210\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u89c6\u89c9\u8f93\u5165\u611f\u77e5\uff1b\u91c7\u7528\u5143\u57df\u7b56\u7565\u5b66\u4e60\u7edf\u4e00\u6a21\u578b\uff1b\u63d0\u51faInstructFLIP\u6846\u67b6\uff0c\u5c06\u6307\u4ee4\u89e3\u8026\u4e3a\u5185\u5bb9\u548c\u98ce\u683c\u7ec4\u4ef6\u3002", "result": "InstructFLIP\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8eSOTA\u6a21\u578b\uff0c\u5927\u5e45\u51cf\u5c11\u8de8\u57df\u8bad\u7ec3\u5197\u4f59\u3002", "conclusion": "InstructFLIP\u6846\u67b6\u6709\u6548\u63d0\u5347\u4eba\u8138\u53cd\u6b3a\u9a97\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.12064", "pdf": "https://arxiv.org/pdf/2507.12064", "abs": "https://arxiv.org/abs/2507.12064", "authors": ["Jeremi K. Ochab", "Mateusz Matias", "Tymoteusz Boba", "Tomasz Walkowiak"], "title": "StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "This submission to the binary AI detection task is based on a modular\nstylometric pipeline, where: public spaCy models are used for text\npreprocessing (including tokenisation, named entity recognition, dependency\nparsing, part-of-speech tagging, and morphology annotation) and extracting\nseveral thousand features (frequencies of n-grams of the above linguistic\nannotations); light-gradient boosting machines are used as the classifier. We\ncollect a large corpus of more than 500 000 machine-generated texts for the\nclassifier's training. We explore several parameter options to increase the\nclassifier's capacity and take advantage of that training set. Our approach\nfollows the non-neural, computationally inexpensive but explainable approach\nfound effective previously.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u6a21\u5757\u5316\u6587\u4f53\u5206\u6790\u6d41\u7a0b\u53c2\u4e0e\u4e8c\u5143AI\u68c0\u6d4b\u4efb\u52a1\uff0c\u7528spaCy\u6a21\u578b\u9884\u5904\u7406\u6587\u672c\u3001\u63d0\u53d6\u7279\u5f81\uff0c\u7528\u8f7b\u68af\u5ea6\u63d0\u5347\u673a\u5206\u7c7b\uff0c\u6536\u96c6\u5927\u91cf\u8bed\u6599\u8bad\u7ec3\uff0c\u63a2\u7d22\u53c2\u6570\u9009\u9879\u63d0\u5347\u5206\u7c7b\u5668\u6027\u80fd\u3002", "motivation": "\u53c2\u4e0e\u4e8c\u5143AI\u68c0\u6d4b\u4efb\u52a1\uff0c\u5bfb\u627e\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u6587\u4f53\u5206\u6790\u6d41\u7a0b\uff0c\u7528spaCy\u6a21\u578b\u8fdb\u884c\u6587\u672c\u9884\u5904\u7406\u548c\u7279\u5f81\u63d0\u53d6\uff0c\u7528\u8f7b\u68af\u5ea6\u63d0\u5347\u673a\u4f5c\u4e3a\u5206\u7c7b\u5668\uff0c\u6536\u96c6\u8d85500000\u6761\u673a\u5668\u751f\u6210\u6587\u672c\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u63a2\u7d22\u53c2\u6570\u9009\u9879\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c\u3002", "conclusion": "\u91c7\u7528\u975e\u795e\u7ecf\u3001\u8ba1\u7b97\u6210\u672c\u4f4e\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6b64\u524d\u88ab\u8bc1\u660e\u6709\u6548\u3002"}}
{"id": "2507.12075", "pdf": "https://arxiv.org/pdf/2507.12075", "abs": "https://arxiv.org/abs/2507.12075", "authors": ["Giuliano Martinelli", "Tommaso Bonomo", "Pere-Llu\u00eds Huguet Cabot", "Roberto Navigli"], "title": "BOOKCOREF: Coreference Resolution at Book Scale", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 Main Conference. 19 pages", "summary": "Coreference Resolution systems are typically evaluated on benchmarks\ncontaining small- to medium-scale documents. When it comes to evaluating long\ntexts, however, existing benchmarks, such as LitBank, remain limited in length\nand do not adequately assess system capabilities at the book scale, i.e., when\nco-referring mentions span hundreds of thousands of tokens. To fill this gap,\nwe first put forward a novel automatic pipeline that produces high-quality\nCoreference Resolution annotations on full narrative texts. Then, we adopt this\npipeline to create the first book-scale coreference benchmark, BOOKCOREF, with\nan average document length of more than 200,000 tokens. We carry out a series\nof experiments showing the robustness of our automatic procedure and\ndemonstrating the value of our resource, which enables current long-document\ncoreference systems to gain up to +20 CoNLL-F1 points when evaluated on full\nbooks. Moreover, we report on the new challenges introduced by this\nunprecedented book-scale setting, highlighting that current models fail to\ndeliver the same performance they achieve on smaller documents. We release our\ndata and code to encourage research and development of new book-scale\nCoreference Resolution systems at https://github.com/sapienzanlp/bookcoref.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b\u521b\u5efa\u9996\u4e2a\u4e66\u7c4d\u89c4\u6a21\u5171\u6307\u6d88\u89e3\u57fa\u51c6BOOKCOREF\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4ef7\u503c\uff0c\u63ed\u793a\u65b0\u6311\u6218\u5e76\u5f00\u6e90\u6570\u636e\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30\u957f\u6587\u672c\u5171\u6307\u6d88\u89e3\u7cfb\u7edf\u65f6\uff0c\u65e0\u6cd5\u5728\u4e66\u7c4d\u89c4\u6a21\u4e0a\u5145\u5206\u8bc4\u4f30\u7cfb\u7edf\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b\uff0c\u5e76\u91c7\u7528\u8be5\u6d41\u7a0b\u521b\u5efaBOOKCOREF\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u81ea\u52a8\u6d41\u7a0b\u5177\u6709\u9c81\u68d2\u6027\uff0cBOOKCOREF\u80fd\u8ba9\u957f\u6587\u6863\u5171\u6307\u7cfb\u7edf\u5728\u5168\u4e66\u7c4d\u8bc4\u4f30\u65f6CoNLL - F1\u5f97\u5206\u63d0\u534720\u5206\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u5728\u4e66\u7c4d\u89c4\u6a21\u4e0a\u8868\u73b0\u4e0d\u5982\u5c0f\u6587\u6863\uff0c\u5f00\u6e90\u6570\u636e\u4ee3\u7801\u4ee5\u63a8\u52a8\u4e66\u7c4d\u89c4\u6a21\u5171\u6307\u6d88\u89e3\u7cfb\u7edf\u7684\u7814\u53d1\u3002"}}
{"id": "2507.11780", "pdf": "https://arxiv.org/pdf/2507.11780", "abs": "https://arxiv.org/abs/2507.11780", "authors": ["Justin Whitehouse", "Morgane Austern", "Vasilis Syrgkanis"], "title": "Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "40 pages, 2 figures", "summary": "Constructing confidence intervals for the value of an optimal treatment\npolicy is an important problem in causal inference. Insight into the optimal\npolicy value can guide the development of reward-maximizing, individualized\ntreatment regimes. However, because the functional that defines the optimal\nvalue is non-differentiable, standard semi-parametric approaches for performing\ninference fail to be directly applicable. Existing approaches for handling this\nnon-differentiability fall roughly into two camps. In one camp are estimators\nbased on constructing smooth approximations of the optimal value. These\napproaches are computationally lightweight, but typically place unrealistic\nparametric assumptions on outcome regressions. In another camp are approaches\nthat directly de-bias the non-smooth objective. These approaches don't place\nparametric assumptions on nuisance functions, but they either require the\ncomputation of intractably-many nuisance estimates, assume unrealistic\n$L^\\infty$ nuisance convergence rates, or make strong margin assumptions that\nprohibit non-response to a treatment. In this paper, we revisit the problem of\nconstructing smooth approximations of non-differentiable functionals. By\ncarefully controlling first-order bias and second-order remainders, we show\nthat a softmax smoothing-based estimator can be used to estimate parameters\nthat are specified as a maximum of scores involving nuisance components. In\nparticular, this includes the value of the optimal treatment policy as a\nspecial case. Our estimator obtains $\\sqrt{n}$ convergence rates, avoids\nparametric restrictions/unrealistic margin assumptions, and is often\nstatistically efficient.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u63a2\u8ba8\u975e\u53ef\u5fae\u6cdb\u51fd\u7684\u5e73\u6ed1\u8fd1\u4f3c\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8esoftmax\u5e73\u6ed1\u7684\u4f30\u8ba1\u91cf\uff0c\u80fd\u4ee5\u221an\u901f\u7387\u6536\u655b\uff0c\u907f\u514d\u53c2\u6570\u9650\u5236\u548c\u4e0d\u73b0\u5b9e\u5047\u8bbe\uff0c\u4e14\u5e38\u5177\u7edf\u8ba1\u6548\u7387\u3002", "motivation": "\u6784\u5efa\u6700\u4f18\u6cbb\u7597\u7b56\u7565\u503c\u7684\u7f6e\u4fe1\u533a\u95f4\u91cd\u8981\uff0c\u4f46\u56e0\u6700\u4f18\u503c\u5b9a\u4e49\u7684\u6cdb\u51fd\u4e0d\u53ef\u5fae\uff0c\u6807\u51c6\u534a\u53c2\u6570\u63a8\u65ad\u65b9\u6cd5\u4e0d\u9002\u7528\uff0c\u73b0\u6709\u5904\u7406\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u4ed4\u7ec6\u63a7\u5236\u4e00\u9636\u504f\u5dee\u548c\u4e8c\u9636\u4f59\u9879\uff0c\u4f7f\u7528\u57fa\u4e8esoftmax\u5e73\u6ed1\u7684\u4f30\u8ba1\u91cf\u6765\u4f30\u8ba1\u7531\u542b\u6270\u52a8\u5206\u91cf\u7684\u5206\u6570\u6700\u5927\u503c\u6307\u5b9a\u7684\u53c2\u6570\u3002", "result": "\u4f30\u8ba1\u91cf\u53ef\u8fbe\u5230\u221an\u6536\u655b\u901f\u7387\uff0c\u907f\u514d\u53c2\u6570\u9650\u5236\u548c\u4e0d\u73b0\u5b9e\u7684\u8fb9\u9645\u5047\u8bbe\uff0c\u4e14\u5e38\u5177\u6709\u7edf\u8ba1\u6548\u7387\u3002", "conclusion": "\u57fa\u4e8esoftmax\u5e73\u6ed1\u7684\u4f30\u8ba1\u91cf\u53ef\u6709\u6548\u89e3\u51b3\u6784\u5efa\u6700\u4f18\u6cbb\u7597\u7b56\u7565\u503c\u7f6e\u4fe1\u533a\u95f4\u7684\u95ee\u9898\u3002"}}
{"id": "2507.12107", "pdf": "https://arxiv.org/pdf/2507.12107", "abs": "https://arxiv.org/abs/2507.12107", "authors": ["Sunpill Kim", "Seunghun Paik", "Chanwoo Hwang", "Minsu Kim", "Jae Hong Seo"], "title": "Non-Adaptive Adversarial Face Generation", "categories": ["cs.CV", "cs.AI", "cs.CR", "I.2.6; I.5.4; D.4.6; K.6.5; I.4.8"], "comment": null, "summary": "Adversarial attacks on face recognition systems (FRSs) pose serious security\nand privacy threats, especially when these systems are used for identity\nverification. In this paper, we propose a novel method for generating\nadversarial faces-synthetic facial images that are visually distinct yet\nrecognized as a target identity by the FRS. Unlike iterative optimization-based\napproaches (e.g., gradient descent or other iterative solvers), our method\nleverages the structural characteristics of the FRS feature space. We figure\nout that individuals sharing the same attribute (e.g., gender or race) form an\nattributed subsphere. By utilizing such subspheres, our method achieves both\nnon-adaptiveness and a remarkably small number of queries. This eliminates the\nneed for relying on transferability and open-source surrogate models, which\nhave been a typical strategy when repeated adaptive queries to commercial FRSs\nare impossible. Despite requiring only a single non-adaptive query consisting\nof 100 face images, our method achieves a high success rate of over 93% against\nAWS's CompareFaces API at its default threshold. Furthermore, unlike many\nexisting attacks that perturb a given image, our method can deliberately\nproduce adversarial faces that impersonate the target identity while exhibiting\nhigh-level attributes chosen by the adversary.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528FRS\u7279\u5f81\u7a7a\u95f4\u7ed3\u6784\u7279\u6027\u751f\u6210\u5bf9\u6297\u4eba\u8138\u7684\u65b0\u65b9\u6cd5\uff0c\u53ea\u9700\u5355\u6b21\u975e\u81ea\u9002\u5e94\u67e5\u8be2\uff0c\u6210\u529f\u7387\u8d8593%\uff0c\u8fd8\u80fd\u6309\u9700\u6c42\u751f\u6210\u5bf9\u6297\u4eba\u8138\u3002", "motivation": "\u5bf9\u6297\u653b\u51fb\u5bf9\u4eba\u8138\u8bc6\u522b\u7cfb\u7edf\u6784\u6210\u5b89\u5168\u548c\u9690\u79c1\u5a01\u80c1\uff0c\u9700\u65b0\u65b9\u6cd5\u751f\u6210\u5bf9\u6297\u4eba\u8138\u3002", "method": "\u5229\u7528FRS\u7279\u5f81\u7a7a\u95f4\u7684\u7ed3\u6784\u7279\u6027\uff0c\u5229\u7528\u76f8\u540c\u5c5e\u6027\u4e2a\u4f53\u5f62\u6210\u7684\u5b50\u7403\u4f53\uff0c\u5b9e\u73b0\u975e\u81ea\u9002\u5e94\u548c\u5c11\u91cf\u67e5\u8be2\u3002", "result": "\u4ec5\u9700100\u5f20\u4eba\u8138\u56fe\u50cf\u7684\u5355\u6b21\u975e\u81ea\u9002\u5e94\u67e5\u8be2\uff0c\u5bf9AWS\u7684CompareFaces API\u6210\u529f\u7387\u8d8593%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u4f9d\u8d56\u53ef\u8fc1\u79fb\u6027\u548c\u5f00\u6e90\u66ff\u4ee3\u6a21\u578b\uff0c\u80fd\u6309\u653b\u51fb\u8005\u9009\u62e9\u7684\u5c5e\u6027\u751f\u6210\u5bf9\u6297\u4eba\u8138\u3002"}}
{"id": "2507.11806", "pdf": "https://arxiv.org/pdf/2507.11806", "abs": "https://arxiv.org/abs/2507.11806", "authors": ["Hendrik Kra\u00df", "Ju Huang", "Seyed Mohamad Moosavi"], "title": "MOFSimBench: Evaluating Universal Machine Learning Interatomic Potentials In Metal--Organic Framework Molecular Modeling", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Universal machine learning interatomic potentials (uMLIPs) have emerged as\npowerful tools for accelerating atomistic simulations, offering scalable and\nefficient modeling with accuracy close to quantum calculations. However, their\nreliability and effectiveness in practical, real-world applications remain an\nopen question. Metal-organic frameworks (MOFs) and related nanoporous materials\nare highly porous crystals with critical relevance in carbon capture, energy\nstorage, and catalysis applications. Modeling nanoporous materials presents\ndistinct challenges for uMLIPs due to their diverse chemistry, structural\ncomplexity, including porosity and coordination bonds, and the absence from\nexisting training datasets. Here, we introduce MOFSimBench, a benchmark to\nevaluate uMLIPs on key materials modeling tasks for nanoporous materials,\nincluding structural optimization, molecular dynamics (MD) stability, the\nprediction of bulk properties, such as bulk modulus and heat capacity, and\nguest-host interactions. Evaluating over 20 models from various architectures\non a chemically and structurally diverse materials set, we find that\ntop-performing uMLIPs consistently outperform classical force fields and\nfine-tuned machine learning potentials across all tasks, demonstrating their\nreadiness for deployment in nanoporous materials modeling. Our analysis\nhighlights that data quality, particularly the diversity of training sets and\ninclusion of out-of-equilibrium conformations, plays a more critical role than\nmodel architecture in determining performance across all evaluated uMLIPs. We\nrelease our modular and extendable benchmarking framework at\nhttps://github.com/AI4ChemS/mofsim-bench, providing an open resource to guide\nthe adoption for nanoporous materials modeling and further development of\nuMLIPs.", "AI": {"tldr": "\u4ecb\u7ecdMOFSimBench\u8bc4\u4f30\u901a\u7528\u673a\u5668\u5b66\u4e60\u539f\u5b50\u95f4\u52bf(uMLIPs)\u5728\u7eb3\u7c73\u591a\u5b54\u6750\u6599\u5efa\u6a21\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u9876\u7ea7uMLIPs\u8868\u73b0\u4f73\uff0c\u6570\u636e\u8d28\u91cf\u6bd4\u6a21\u578b\u67b6\u6784\u66f4\u91cd\u8981\u5e76\u5f00\u6e90\u6846\u67b6\u3002", "motivation": "uMLIPs\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u5b58\u7591\uff0c\u7eb3\u7c73\u591a\u5b54\u6750\u6599\u5efa\u6a21\u5bf9uMLIPs\u6709\u72ec\u7279\u6311\u6218\uff0c\u9700\u8bc4\u4f30\u5176\u5728\u76f8\u5173\u4efb\u52a1\u7684\u8868\u73b0\u3002", "method": "\u5f15\u5165MOFSimBench\u57fa\u51c6\uff0c\u5728\u5316\u5b66\u548c\u7ed3\u6784\u591a\u6837\u7684\u6750\u6599\u96c6\u4e0a\u8bc4\u4f3020\u591a\u4e2a\u4e0d\u540c\u67b6\u6784\u7684\u6a21\u578b\u3002", "result": "\u9876\u7ea7uMLIPs\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u7ecf\u5178\u529b\u573a\u548c\u5fae\u8c03\u7684\u673a\u5668\u5b66\u4e60\u52bf\u3002", "conclusion": "\u6570\u636e\u8d28\u91cf\u5728\u51b3\u5b9auMLIPs\u6027\u80fd\u4e0a\u6bd4\u6a21\u578b\u67b6\u6784\u66f4\u5173\u952e\uff0c\u5f00\u6e90\u57fa\u51c6\u6846\u67b6\u4ee5\u6307\u5bfc\u7eb3\u7c73\u591a\u5b54\u6750\u6599\u5efa\u6a21\u548cuMLIPs\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.12108", "pdf": "https://arxiv.org/pdf/2507.12108", "abs": "https://arxiv.org/abs/2507.12108", "authors": ["Lorenzo Mannocci", "Stefano Cresci", "Matteo Magnani", "Anna Monreale", "Maurizio Tesconi"], "title": "Multimodal Coordinated Online Behavior: Trade-offs and Strategies", "categories": ["cs.SI", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": null, "summary": "Coordinated online behavior, which spans from beneficial collective actions\nto harmful manipulation such as disinformation campaigns, has become a key\nfocus in digital ecosystem analysis. Traditional methods often rely on\nmonomodal approaches, focusing on single types of interactions like co-retweets\nor co-hashtags, or consider multiple modalities independently of each other.\nHowever, these approaches may overlook the complex dynamics inherent in\nmultimodal coordination. This study compares different ways of operationalizing\nthe detection of multimodal coordinated behavior. It examines the trade-off\nbetween weakly and strongly integrated multimodal models, highlighting the\nbalance between capturing broader coordination patterns and identifying tightly\ncoordinated behavior. By comparing monomodal and multimodal approaches, we\nassess the unique contributions of different data modalities and explore how\nvarying implementations of multimodality impact detection outcomes. Our\nfindings reveal that not all the modalities provide distinct insights, but that\nwith a multimodal approach we can get a more comprehensive understanding of\ncoordination dynamics. This work enhances the ability to detect and analyze\ncoordinated online behavior, offering new perspectives for safeguarding the\nintegrity of digital platforms.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u68c0\u6d4b\u591a\u6a21\u6001\u534f\u8c03\u884c\u4e3a\u7684\u4e0d\u540c\u65b9\u6cd5\uff0c\u7814\u7a76\u5f3a\u5f31\u96c6\u6210\u591a\u6a21\u6001\u6a21\u578b\u7684\u6743\u8861\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u65b9\u6cd5\u80fd\u66f4\u5168\u9762\u7406\u89e3\u534f\u8c03\u52a8\u6001\uff0c\u63d0\u5347\u68c0\u6d4b\u548c\u5206\u6790\u5728\u7ebf\u534f\u8c03\u884c\u4e3a\u7684\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5355\u6a21\u6001\u6216\u72ec\u7acb\u591a\u6a21\u6001\u65b9\u6cd5\u53ef\u80fd\u5ffd\u7565\u591a\u6a21\u6001\u534f\u8c03\u7684\u590d\u6742\u52a8\u6001\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u5206\u6790\u5728\u7ebf\u534f\u8c03\u884c\u4e3a\u3002", "method": "\u6bd4\u8f83\u4e0d\u540c\u64cd\u4f5c\u5316\u591a\u6a21\u6001\u534f\u8c03\u884c\u4e3a\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u7814\u7a76\u5f3a\u5f31\u96c6\u6210\u591a\u6a21\u6001\u6a21\u578b\u7684\u6743\u8861\u3002", "result": "\u5e76\u975e\u6240\u6709\u6a21\u6001\u90fd\u80fd\u63d0\u4f9b\u72ec\u7279\u89c1\u89e3\uff0c\u4f46\u591a\u6a21\u6001\u65b9\u6cd5\u53ef\u66f4\u5168\u9762\u7406\u89e3\u534f\u8c03\u52a8\u6001\u3002", "conclusion": "\u672c\u7814\u7a76\u589e\u5f3a\u4e86\u68c0\u6d4b\u548c\u5206\u6790\u5728\u7ebf\u534f\u8c03\u884c\u4e3a\u7684\u80fd\u529b\uff0c\u4e3a\u7ef4\u62a4\u6570\u5b57\u5e73\u53f0\u5b8c\u6574\u6027\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2507.12117", "pdf": "https://arxiv.org/pdf/2507.12117", "abs": "https://arxiv.org/abs/2507.12117", "authors": ["Timothy Heightman", "Edward Jiang", "Ruth Mora-Soto", "Maciej Lewenstein", "Marcin P\u0142odzie\u0144"], "title": "Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations", "categories": ["quant-ph", "cs.AI", "math-ph", "math.MP"], "comment": null, "summary": "Quantum machine learning (QML) seeks to exploit the intrinsic properties of\nquantum mechanical systems, including superposition, coherence, and quantum\nentanglement for classical data processing. However, due to the exponential\ngrowth of the Hilbert space, QML faces practical limits in classical\nsimulations with the state-vector representation of quantum system. On the\nother hand, phase-space methods offer an alternative by encoding quantum states\nas quasi-probability functions. Building on prior work in qubit phase-space and\nthe Stratonovich-Weyl (SW) correspondence, we construct a closed, composable\ndynamical formalism for one- and many-qubit systems in phase-space. This\nformalism replaces the operator algebra of the Pauli group with function\ndynamics on symplectic manifolds, and recasts the curse of dimensionality in\nterms of harmonic support on a domain that scales linearly with the number of\nqubits. It opens a new route for QML based on variational modelling over\nphase-space.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u76f8\u7a7a\u95f4\u4e2d\u5355\u548c\u591a\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u5f62\u5f0f\uff0c\u4e3a\u57fa\u4e8e\u76f8\u7a7a\u95f4\u53d8\u5206\u5efa\u6a21\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5f00\u8f9f\u65b0\u9014\u5f84\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u7ecf\u5178\u6a21\u62df\u4e2d\u56e0\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u6307\u6570\u589e\u957f\u9762\u4e34\u5b9e\u9645\u9650\u5236\uff0c\u76f8\u7a7a\u95f4\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u91cf\u5b50\u6bd4\u7279\u76f8\u7a7a\u95f4\u548cStratonovich - Weyl\u5bf9\u5e94\u5de5\u4f5c\uff0c\u6784\u5efa\u76f8\u7a7a\u95f4\u4e2d\u91cf\u5b50\u6bd4\u7279\u7cfb\u7edf\u7684\u5c01\u95ed\u3001\u53ef\u7ec4\u5408\u52a8\u529b\u5b66\u5f62\u5f0f\u3002", "result": "\u7528\u8f9b\u6d41\u5f62\u4e0a\u7684\u51fd\u6570\u52a8\u529b\u5b66\u53d6\u4ee3\u6ce1\u5229\u7fa4\u7684\u7b97\u5b50\u4ee3\u6570\uff0c\u5c06\u7ef4\u6570\u707e\u96be\u8f6c\u5316\u4e3a\u4e0e\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u7ebf\u6027\u76f8\u5173\u7684\u8c03\u548c\u652f\u6491\u95ee\u9898\u3002", "conclusion": "\u4e3a\u57fa\u4e8e\u76f8\u7a7a\u95f4\u53d8\u5206\u5efa\u6a21\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.11842", "pdf": "https://arxiv.org/pdf/2507.11842", "abs": "https://arxiv.org/abs/2507.11842", "authors": ["Sidharth Kannan", "Tian Qiu", "Carolina Cuesta-Lazaro", "Haewon Jeong"], "title": "CosmoFlow: Scale-Aware Representation Learning for Cosmology with Flow Matching", "categories": ["astro-ph.CO", "cs.LG"], "comment": null, "summary": "Generative machine learning models have been demonstrated to be able to learn\nlow dimensional representations of data that preserve information required for\ndownstream tasks. In this work, we demonstrate that flow matching based\ngenerative models can learn compact, semantically rich latent representations\nof field level cold dark matter (CDM) simulation data without supervision. Our\nmodel, CosmoFlow, learns representations 32x smaller than the raw field data,\nusable for field level reconstruction, synthetic data generation, and parameter\ninference. Our model also learns interpretable representations, in which\ndifferent latent channels correspond to features at different cosmological\nscales.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u751f\u6210\u6a21\u578bCosmoFlow\u53ef\u65e0\u76d1\u7763\u5b66\u4e60\u51b7\u6697\u7269\u8d28\u6a21\u62df\u6570\u636e\u7684\u7d27\u51d1\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u6f5c\u5728\u8868\u793a\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u51b7\u6697\u7269\u8d28\u6a21\u62df\u6570\u636e\u4f4e\u7ef4\u8868\u793a\u5b66\u4e60\u80fd\u529b\uff0c\u4ee5\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u751f\u6210\u6a21\u578bCosmoFlow\u8fdb\u884c\u65e0\u76d1\u7763\u5b66\u4e60\u3002", "result": "CosmoFlow\u5b66\u4e60\u5230\u7684\u8868\u793a\u6bd4\u539f\u59cb\u6570\u636e\u5c0f32\u500d\uff0c\u53ef\u7528\u4e8e\u573a\u7ea7\u91cd\u5efa\u3001\u5408\u6210\u6570\u636e\u751f\u6210\u548c\u53c2\u6570\u63a8\u65ad\uff0c\u4e14\u5b66\u4e60\u5230\u7684\u8868\u793a\u53ef\u89e3\u91ca\u3002", "conclusion": "\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u751f\u6210\u6a21\u578b\u80fd\u65e0\u76d1\u7763\u5b66\u4e60\u51b7\u6697\u7269\u8d28\u6a21\u62df\u6570\u636e\u7684\u7d27\u51d1\u3001\u8bed\u4e49\u4e30\u5bcc\u4e14\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u8868\u793a\u3002"}}
{"id": "2507.12188", "pdf": "https://arxiv.org/pdf/2507.12188", "abs": "https://arxiv.org/abs/2507.12188", "authors": ["Shuangli Du", "Siming Yan", "Zhenghao Shi", "Zhenzhen You", "Lu Sun"], "title": "Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Low-light images suffer from complex degradation, and existing enhancement\nmethods often encode all degradation factors within a single latent space. This\nleads to highly entangled features and strong black-box characteristics, making\nthe model prone to shortcut learning. To mitigate the above issues, this paper\nproposes a wavelet-based low-light stereo image enhancement method with feature\nspace decoupling. Our insight comes from the following findings: (1) Wavelet\ntransform enables the independent processing of low-frequency and\nhigh-frequency information. (2) Illumination adjustment can be achieved by\nadjusting the low-frequency component of a low-light image, extracted through\nmulti-level wavelet decomposition. Thus, by using wavelet transform the feature\nspace is decomposed into a low-frequency branch for illumination adjustment and\nmultiple high-frequency branches for texture enhancement. Additionally, stereo\nlow-light image enhancement can extract useful cues from another view to\nimprove enhancement. To this end, we propose a novel high-frequency guided\ncross-view interaction module (HF-CIM) that operates within high-frequency\nbranches rather than across the entire feature space, effectively extracting\nvaluable image details from the other view. Furthermore, to enhance the\nhigh-frequency information, a detail and texture enhancement module (DTEM) is\nproposed based on cross-attention mechanism. The model is trained on a dataset\nconsisting of images with uniform illumination and images with non-uniform\nillumination. Experimental results on both real and synthetic images indicate\nthat our algorithm offers significant advantages in light adjustment while\neffectively recovering high-frequency information. The code and dataset are\npublicly available at: https://github.com/Cherisherr/WDCI-Net.git.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5c0f\u6ce2\u7279\u5f81\u7a7a\u95f4\u89e3\u8026\u7684\u4f4e\u5149\u7acb\u4f53\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\uff0c\u542b\u9ad8\u9891\u5f15\u5bfc\u8de8\u89c6\u56fe\u4ea4\u4e92\u6a21\u5757\u548c\u7ec6\u8282\u7eb9\u7406\u589e\u5f3a\u6a21\u5757\uff0c\u5b9e\u9a8c\u8868\u660e\u7b97\u6cd5\u5728\u8c03\u5149\u548c\u6062\u590d\u9ad8\u9891\u4fe1\u606f\u4e0a\u6709\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u4f4e\u5149\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\u5c06\u6240\u6709\u9000\u5316\u56e0\u7d20\u7f16\u7801\u5728\u5355\u4e00\u6f5c\u5728\u7a7a\u95f4\uff0c\u5bfc\u81f4\u7279\u5f81\u7ea0\u7f20\u3001\u9ed1\u76d2\u7279\u6027\u5f3a\u3001\u6613\u8d70\u6377\u5f84\u5b66\u4e60\u3002", "method": "\u7528\u5c0f\u6ce2\u53d8\u6362\u5c06\u7279\u5f81\u7a7a\u95f4\u5206\u89e3\u4e3a\u4f4e\u9891\u8c03\u5149\u5206\u652f\u548c\u591a\u4e2a\u9ad8\u9891\u7eb9\u7406\u589e\u5f3a\u5206\u652f\uff1b\u63d0\u51fa\u9ad8\u9891\u5f15\u5bfc\u8de8\u89c6\u56fe\u4ea4\u4e92\u6a21\u5757\u548c\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u7684\u7ec6\u8282\u7eb9\u7406\u589e\u5f3a\u6a21\u5757\uff1b\u5728\u5747\u5300\u548c\u975e\u5747\u5300\u5149\u7167\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u56fe\u50cf\u4e0a\u5b9e\u9a8c\uff0c\u7b97\u6cd5\u5728\u8c03\u5149\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u6709\u6548\u6062\u590d\u9ad8\u9891\u4fe1\u606f\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u73b0\u6709\u4f4e\u5149\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\u95ee\u9898\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u516c\u5f00\u3002"}}
{"id": "2507.11851", "pdf": "https://arxiv.org/pdf/2507.11851", "abs": "https://arxiv.org/abs/2507.11851", "authors": ["Mohammad Samragh", "Arnav Kundu", "David Harrison", "Kumari Nishu", "Devang Naik", "Minsik Cho", "Mehrdad Farajtabar"], "title": "Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Autoregressive language models are constrained by their inherently sequential\nnature, generating one token at a time. This paradigm limits inference speed\nand parallelism, especially during later stages of generation when the\ndirection and semantics of text are relatively certain. In this work, we\npropose a novel framework that leverages the inherent knowledge of vanilla\nautoregressive language models about future tokens, combining techniques to\nrealize this potential and enable simultaneous prediction of multiple\nsubsequent tokens. Our approach introduces several key innovations: (1) a\nmasked-input formulation where multiple future tokens are jointly predicted\nfrom a common prefix; (2) a gated LoRA formulation that preserves the original\nLLM's functionality, while equipping it for multi-token prediction; (3) a\nlightweight, learnable sampler module that generates coherent sequences from\nthe predicted future tokens; (4) a set of auxiliary training losses, including\na consistency loss, to enhance the coherence and accuracy of jointly generated\ntokens; and (5) a speculative generation strategy that expands tokens\nquadratically in the future while maintaining high fidelity. Our method\nachieves significant speedups through supervised fine-tuning on pretrained\nmodels. For example, it generates code and math nearly 5x faster, and improves\ngeneral chat and knowledge tasks by almost 2.5x. These gains come without any\nloss in quality.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u6846\u67b6\u5229\u7528\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u5b9e\u73b0\u591a\u540e\u7eed\u6807\u8bb0\u540c\u65f6\u9884\u6d4b\uff0c\u6709\u591a\u9879\u521b\u65b0\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u540e\u663e\u8457\u63d0\u901f\u4e14\u65e0\u8d28\u91cf\u635f\u5931\u3002", "motivation": "\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u987a\u5e8f\u751f\u6210\u7684\u7279\u6027\u9650\u5236\u63a8\u7406\u901f\u5ea6\u548c\u5e76\u884c\u6027\uff0c\u5c24\u5176\u5728\u751f\u6210\u540e\u671f\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\uff0c\u5305\u62ec\u63a9\u7801\u8f93\u5165\u3001\u95e8\u63a7LoRA\u3001\u53ef\u5b66\u4e60\u91c7\u6837\u5668\u3001\u8f85\u52a9\u8bad\u7ec3\u635f\u5931\u548c\u6295\u673a\u751f\u6210\u7b56\u7565\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4e0a\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u751f\u6210\u4ee3\u7801\u548c\u6570\u5b66\u5185\u5bb9\u5feb\u8fd15\u500d\uff0c\u901a\u7528\u804a\u5929\u548c\u77e5\u8bc6\u4efb\u52a1\u63d0\u901f\u8fd12.5\u500d\uff0c\u4e14\u65e0\u8d28\u91cf\u635f\u5931\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u901f\u5ea6\uff0c\u4e14\u4e0d\u5f71\u54cd\u8d28\u91cf\u3002"}}
{"id": "2507.12189", "pdf": "https://arxiv.org/pdf/2507.12189", "abs": "https://arxiv.org/abs/2507.12189", "authors": ["Azhar Ikhtiarudin", "Aditi Das", "Param Thakkar", "Akash Kundu"], "title": "BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search", "categories": ["quant-ph", "cs.AI", "cs.LG", "cs.PF"], "comment": "Comprehensive RL agent benchmark for QAS. Contributions are welcomed\n  here: https://github.com/azhar-ikhtiarudin/bench-rlqas", "summary": "We introduce BenchRL-QAS, a unified benchmarking framework for systematically\nevaluating reinforcement learning (RL) algorithms in quantum architecture\nsearch (QAS) across diverse variational quantum algorithm tasks and system\nsizes ranging from 2- to 8-qubit. Our study benchmarks nine RL agents including\nboth value-based and policy-gradient methods on representative quantum problems\nsuch as variational quantum eigensolver, variational quantum state\ndiagonalization, quantum classification, and state preparation, spanning both\nnoiseless and realistic noisy regimes. We propose a weighted ranking metric\nthat balances accuracy, circuit depth, gate count, and computational\nefficiency, enabling fair and comprehensive comparison. Our results first\nreveal that RL-based quantum classifier outperforms baseline variational\nclassifiers. Then we conclude that no single RL algorithm is universally\noptimal when considering a set of QAS tasks; algorithmic performance is highly\ncontext-dependent, varying with task structure, qubit count, and noise. This\nempirical finding provides strong evidence for the \"no free lunch\" principle in\nRL-based quantum circuit design and highlights the necessity of tailored\nalgorithm selection and systematic benchmarking for advancing quantum circuit\nsynthesis. This work represents the most comprehensive RL-QAS benchmarking\neffort to date, and BenchRL-QAS along with all experimental data are made\npublicly available to support reproducibility and future research\nhttps://github.com/azhar-ikhtiarudin/bench-rlqas.", "AI": {"tldr": "\u4ecb\u7ecdBenchRL - QAS\u6846\u67b6\u7528\u4e8e\u8bc4\u4f30\u91cf\u5b50\u67b6\u6784\u641c\u7d22\u4e2d\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5bf9\u591a\u79cd\u7b97\u6cd5\u5728\u4e0d\u540c\u91cf\u5b50\u4efb\u52a1\u4e0a\u6d4b\u8bd5\uff0c\u63d0\u51fa\u52a0\u6743\u6392\u540d\u6307\u6807\uff0c\u53d1\u73b0\u7ed3\u679c\u5e76\u5f97\u51fa\u7ed3\u8bba\uff0c\u4ee3\u7801\u6570\u636e\u516c\u5f00\u3002", "motivation": "\u7cfb\u7edf\u8bc4\u4f30\u91cf\u5b50\u67b6\u6784\u641c\u7d22\u4e2d\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u63a8\u52a8\u91cf\u5b50\u7535\u8def\u7efc\u5408\u53d1\u5c55\u3002", "method": "\u5f15\u5165BenchRL - QAS\u6846\u67b6\uff0c\u5bf99\u79cdRL\u4ee3\u7406\u5728\u4e0d\u540c\u91cf\u5b50\u95ee\u9898\u4e0a\u6d4b\u8bd5\uff0c\u63d0\u51fa\u52a0\u6743\u6392\u540d\u6307\u6807\u3002", "result": "\u57fa\u4e8eRL\u7684\u91cf\u5b50\u5206\u7c7b\u5668\u4f18\u4e8e\u57fa\u7ebf\u53d8\u5206\u5206\u7c7b\u5668\uff1b\u6ca1\u6709\u5355\u4e00RL\u7b97\u6cd5\u5728\u6240\u6709QAS\u4efb\u52a1\u4e0a\u6700\u4f18\uff0c\u6027\u80fd\u4e0e\u4efb\u52a1\u7ed3\u6784\u3001qubit\u6570\u91cf\u548c\u566a\u58f0\u6709\u5173\u3002", "conclusion": "\u4e3a\u57fa\u4e8eRL\u7684\u91cf\u5b50\u7535\u8def\u8bbe\u8ba1\u7684\u201c\u6ca1\u6709\u514d\u8d39\u5348\u9910\u201d\u539f\u5219\u63d0\u4f9b\u8bc1\u636e\uff0c\u5f3a\u8c03\u5b9a\u5236\u7b97\u6cd5\u9009\u62e9\u548c\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.12195", "pdf": "https://arxiv.org/pdf/2507.12195", "abs": "https://arxiv.org/abs/2507.12195", "authors": ["Arkaprabha Basu"], "title": "Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Modern digitised approaches have dramatically changed the preservation and\nrestoration of cultural treasures, integrating computer scientists into\nmultidisciplinary projects with ease. Machine learning, deep learning, and\ncomputer vision techniques have revolutionised developing sectors like 3D\nreconstruction, picture inpainting,IoT-based methods, genetic algorithms, and\nimage processing with the integration of computer scientists into\nmultidisciplinary initiatives. We suggest three cutting-edge techniques in\nrecognition of the special qualities of Indian monuments, which are famous for\ntheir architectural skill and aesthetic appeal. First is the Fractal\nConvolution methodology, a segmentation method based on image processing that\nsuccessfully reveals subtle architectural patterns within these irreplaceable\ncultural buildings. The second is a revolutionary Self-Sensitive Tile Filling\n(SSTF) method created especially for West Bengal's mesmerising Bankura\nTerracotta Temples with a brand-new data augmentation method called MosaicSlice\non the third. Furthermore, we delve deeper into the Super Resolution strategy\nto upscale the images without losing significant amount of quality. Our methods\nallow for the development of seamless region-filling and highly detailed tiles\nwhile maintaining authenticity using a novel data augmentation strategy within\naffordable costs introducing automation. By providing effective solutions that\npreserve the delicate balance between tradition and innovation, this study\nimproves the subject and eventually ensures unrivalled efficiency and aesthetic\nexcellence in cultural heritage protection. The suggested approaches advance\nthe field into an era of unmatched efficiency and aesthetic quality while\ncarefully upholding the delicate equilibrium between tradition and innovation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u5370\u5ea6\u53e4\u8ff9\u7684\u4e09\u79cd\u65b0\u6280\u672f\uff0c\u80fd\u4ee5\u4f4e\u6210\u672c\u5b9e\u73b0\u81ea\u52a8\u5316\uff0c\u5e73\u8861\u4f20\u7edf\u4e0e\u521b\u65b0\uff0c\u63d0\u5347\u6587\u5316\u9057\u4ea7\u4fdd\u62a4\u6548\u7387\u4e0e\u7f8e\u5b66\u8d28\u91cf\u3002", "motivation": "\u73b0\u4ee3\u6570\u5b57\u5316\u65b9\u6cd5\u6539\u53d8\u6587\u5316\u73cd\u5b9d\u4fdd\u62a4\u4e0e\u4fee\u590d\uff0c\u4e3a\u5229\u7528\u8ba1\u7b97\u673a\u6280\u672f\u4fdd\u62a4\u5370\u5ea6\u53e4\u8ff9\uff0c\u53d1\u6325\u5176\u5efa\u7b51\u4e0e\u7f8e\u5b66\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u6280\u672f\uff1a\u57fa\u4e8e\u56fe\u50cf\u5904\u7406\u7684\u5206\u5f62\u5377\u79ef\u65b9\u6cd5\u3001\u7528\u4e8e\u5b5f\u52a0\u62c9\u90a6\u73ed\u53e4\u62c9\u9676\u571f\u5bfa\u5e99\u7684\u81ea\u654f\u611f\u74f7\u7816\u586b\u5145\u6cd5\u548c\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u7b56\u7565\uff0c\u8fd8\u6709\u65b0\u6570\u636e\u589e\u5f3a\u65b9\u6cd5MosaicSlice\u3002", "result": "\u80fd\u5b9e\u73b0\u65e0\u7f1d\u533a\u57df\u586b\u5145\u548c\u5236\u4f5c\u9ad8\u7ec6\u8282\u74f7\u7816\uff0c\u5728\u4fdd\u6301\u771f\u5b9e\u6027\u7684\u540c\u65f6\uff0c\u4ee5\u4f4e\u6210\u672c\u5f15\u5165\u81ea\u52a8\u5316\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u63a8\u52a8\u6587\u5316\u9057\u4ea7\u4fdd\u62a4\u9886\u57df\u8fdb\u5165\u9ad8\u6548\u4e14\u5177\u7f8e\u5b66\u8d28\u91cf\u7684\u65f6\u4ee3\uff0c\u5e73\u8861\u4e86\u4f20\u7edf\u4e0e\u521b\u65b0\u3002"}}
{"id": "2507.12197", "pdf": "https://arxiv.org/pdf/2507.12197", "abs": "https://arxiv.org/abs/2507.12197", "authors": ["Yichen Han", "Xiaoyang Hao", "Keming Chen", "Weibo Xiong", "Jun He", "Ruonan Zhang", "Junjie Cao", "Yue Liu", "Bowen Li", "Dongrui Zhang", "Hui Xia", "Huilei Fu", "Kai Jia", "Kaixuan Guo", "Mingli Jin", "Qingyun Meng", "Ruidong Ma", "Ruiqian Fang", "Shaotong Guo", "Xuhui Li", "Yang Xiang", "Ying Zhang", "Yulong Liu", "Yunfeng Li", "Yuyi Zhang", "Yuze Zhou", "Zhen Wang", "Zhaowen Chen"], "title": "Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Text-to-speech (TTS) synthesis has seen renewed progress under the discrete\nmodeling paradigm. Existing autoregressive approaches often rely on\nsingle-codebook representations, which suffer from significant information\nloss. Even with post-hoc refinement techniques such as flow matching, these\nmethods fail to recover fine-grained details (e.g., prosodic nuances,\nspeaker-specific timbres), especially in challenging scenarios like singing\nvoice or music synthesis. We propose QTTS, a novel TTS framework built upon our\nnew audio codec, QDAC. The core innovation of QDAC lies in its end-to-end\ntraining of an ASR-based auto-regressive network with a GAN, which achieves\nsuperior semantic feature disentanglement for scalable, near-lossless\ncompression. QTTS models these discrete codes using two innovative strategies:\nthe Hierarchical Parallel architecture, which uses a dual-AR structure to model\ninter-codebook dependencies for higher-quality synthesis, and the Delay\nMultihead approach, which employs parallelized prediction with a fixed delay to\naccelerate inference speed. Our experiments demonstrate that the proposed\nframework achieves higher synthesis quality and better preserves expressive\ncontent compared to baseline. This suggests that scaling up compression via\nmulti-codebook modeling is a promising direction for high-fidelity,\ngeneral-purpose speech and audio generation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65b0\u97f3\u9891\u7f16\u89e3\u7801\u5668QDAC\u7684TTS\u6846\u67b6QTTS\uff0c\u5728\u5408\u6210\u8d28\u91cf\u548c\u4fdd\u7559\u8868\u8fbe\u5185\u5bb9\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u591a\u7801\u672c\u5efa\u6a21\u662f\u9ad8\u4fdd\u771f\u97f3\u9891\u751f\u6210\u7684\u6709\u524d\u666f\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u81ea\u56de\u5f52TTS\u65b9\u6cd5\u4f9d\u8d56\u5355\u7801\u672c\u8868\u793a\uff0c\u4fe1\u606f\u635f\u5931\u5927\uff0c\u96be\u6062\u590d\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff0c\u5728\u590d\u6742\u573a\u666f\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u6784\u5efa\u57fa\u4e8eQDAC\u7684QTTS\u6846\u67b6\uff0cQDAC\u7aef\u5230\u7aef\u8bad\u7ec3\u57fa\u4e8eASR\u7684\u81ea\u56de\u5f52\u7f51\u7edc\u4e0eGAN\uff1bQTTS\u91c7\u7528\u5206\u5c42\u5e76\u884c\u67b6\u6784\u548c\u5ef6\u8fdf\u591a\u5934\u65b9\u6cd5\u5904\u7406\u79bb\u6563\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u5408\u6210\u8d28\u91cf\u66f4\u9ad8\uff0c\u80fd\u66f4\u597d\u4fdd\u7559\u8868\u8fbe\u5185\u5bb9\u3002", "conclusion": "\u901a\u8fc7\u591a\u7801\u672c\u5efa\u6a21\u6269\u5c55\u538b\u7f29\u662f\u9ad8\u4fdd\u771f\u3001\u901a\u7528\u8bed\u97f3\u548c\u97f3\u9891\u751f\u6210\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2507.11950", "pdf": "https://arxiv.org/pdf/2507.11950", "abs": "https://arxiv.org/abs/2507.11950", "authors": ["Lauren Lui", "Torben Nielsen"], "title": "RNAMunin: A Deep Machine Learning Model for Non-coding RNA Discovery", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Functional annotation of microbial genomes is often biased toward\nprotein-coding genes, leaving a vast, unexplored landscape of non-coding RNAs\n(ncRNAs) that are critical for regulating bacterial and archaeal physiology,\nstress response and metabolism. Identifying ncRNAs directly from genomic\nsequence is a paramount challenge in bioinformatics and biology, essential for\nunderstanding the complete regulatory potential of an organism. This paper\npresents RNAMunin, a machine learning (ML) model that is capable of finding\nncRNAs using genomic sequence alone. It is also computationally viable for\nlarge sequence datasets such as long read metagenomic assemblies with contigs\ntotaling multiple Gbp. RNAMunin is trained on Rfam sequences extracted from\napproximately 60 Gbp of long read metagenomes from 16 San Francisco Estuary\nsamples. We know of no other model that can detect ncRNAs based solely on\ngenomic sequence at this scale. Since RNAMunin only requires genomic sequence\nas input, we do not need for an ncRNA to be transcribed to find it, i.e., we do\nnot need transcriptomics data. We wrote this manuscript in a narrative style in\norder to best convey how RNAMunin was developed and how it works in detail.\nUnlike almost all current ML models, at approximately 1M parameters, RNAMunin\nis very small and very fast.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578bRNAMunin\uff0c\u5176\u80fd\u4ec5\u7528\u57fa\u56e0\u7ec4\u5e8f\u5217\u8bc6\u522bncRNAs\uff0c\u9002\u7528\u4e8e\u5927\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u6a21\u578b\u5c0f\u4e14\u901f\u5ea6\u5feb\u3002", "motivation": "\u5fae\u751f\u7269\u57fa\u56e0\u7ec4\u529f\u80fd\u6ce8\u91ca\u5e38\u504f\u5411\u86cb\u767d\u7f16\u7801\u57fa\u56e0\uff0cncRNAs\u7814\u7a76\u4e0d\u8db3\uff0c\u76f4\u63a5\u4ece\u57fa\u56e0\u7ec4\u5e8f\u5217\u8bc6\u522bncRNAs\u662f\u91cd\u8981\u6311\u6218\uff0c\u4e3a\u4e86\u89e3\u751f\u7269\u4f53\u5b8c\u6574\u8c03\u63a7\u6f5c\u529b\uff0c\u9700\u5f00\u53d1\u76f8\u5173\u5de5\u5177\u3002", "method": "\u57fa\u4e8e\u4ece\u7ea660 Gbp\u7684\u957f\u8bfb\u957f\u5b8f\u57fa\u56e0\u7ec4\u4e2d\u63d0\u53d6\u7684Rfam\u5e8f\u5217\u8bad\u7ec3RNAMunin\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u51faRNAMunin\u6a21\u578b\uff0c\u80fd\u4ec5\u57fa\u4e8e\u57fa\u56e0\u7ec4\u5e8f\u5217\u68c0\u6d4bncRNAs\uff0c\u53ef\u7528\u4e8e\u5927\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u65e0\u9700\u8f6c\u5f55\u7ec4\u6570\u636e\u3002", "conclusion": "RNAMunin\u662f\u4e00\u4e2a\u5c0f\u578b\u5feb\u901f\u7684\u6a21\u578b\uff0c\u4ec5\u9700\u57fa\u56e0\u7ec4\u5e8f\u5217\u8f93\u5165\uff0c\u5728\u8bc6\u522bncRNAs\u65b9\u9762\u6709\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2507.12212", "pdf": "https://arxiv.org/pdf/2507.12212", "abs": "https://arxiv.org/abs/2507.12212", "authors": ["Garyoung Kim", "Huisung Kwon", "Seoju Yun", "Yu-Won Youn"], "title": "Draw an Ugly Person An Exploration of Generative AIs Perceptions of Ugliness", "categories": ["cs.HC", "cs.AI"], "comment": "7 pages, 3 figures", "summary": "Generative AI does not only replicate human creativity but also reproduces\ndeep-seated cultural biases, making it crucial to critically examine how\nconcepts like ugliness are understood and expressed by these tools. This study\ninvestigates how four different generative AI models understand and express\nugliness through text and image and explores the biases embedded within these\nrepresentations. We extracted 13 adjectives associated with ugliness through\niterative prompting of a large language model and generated 624 images across\nfour AI models and three prompts. Demographic and socioeconomic attributes\nwithin the images were independently coded and thematically analyzed. Our\nfindings show that AI models disproportionately associate ugliness with old\nwhite male figures, reflecting entrenched social biases as well as paradoxical\nbiases, where efforts to avoid stereotypical depictions of marginalized groups\ninadvertently result in the disproportionate projection of negative attributes\nonto majority groups. Qualitative analysis further reveals that, despite\nsupposed attempts to frame ugliness within social contexts, conventional\nphysical markers such as asymmetry and aging persist as central visual motifs.\nThese findings demonstrate that despite attempts to create more equal\nrepresentations, generative AI continues to perpetuate inherited and\nparadoxical biases, underscoring the critical work being done to create ethical\nAI training paradigms and advance methodologies for more inclusive AI\ndevelopment.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u56db\u79cd\u751f\u6210\u5f0fAI\u6a21\u578b\u5bf9\u4e11\u964b\u6982\u5ff5\u7684\u7406\u89e3\u4e0e\u8868\u8fbe\u53ca\u5176\u4e2d\u7684\u504f\u5dee\uff0c\u53d1\u73b0AI\u4ecd\u5b58\u5728\u504f\u89c1\uff0c\u5f3a\u8c03\u521b\u5efa\u4f26\u7406AI\u8bad\u7ec3\u8303\u5f0f\u548c\u5305\u5bb9\u6027\u53d1\u5c55\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u751f\u6210\u5f0fAI\u4f1a\u518d\u73b0\u6587\u5316\u504f\u89c1\uff0c\u9700\u5ba1\u89c6\u5176\u5bf9\u4e11\u964b\u6982\u5ff5\u7684\u7406\u89e3\u548c\u8868\u8fbe\u3002", "method": "\u901a\u8fc7\u8fed\u4ee3\u63d0\u793a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d613\u4e2a\u4e0e\u4e11\u964b\u76f8\u5173\u7684\u5f62\u5bb9\u8bcd\uff0c\u5728\u56db\u4e2aAI\u6a21\u578b\u548c\u4e09\u4e2a\u63d0\u793a\u4e0b\u751f\u6210624\u5f20\u56fe\u50cf\uff0c\u5bf9\u56fe\u50cf\u4e2d\u7684\u4eba\u53e3\u548c\u793e\u4f1a\u7ecf\u6d4e\u5c5e\u6027\u8fdb\u884c\u72ec\u7acb\u7f16\u7801\u548c\u4e3b\u9898\u5206\u6790\u3002", "result": "AI\u6a21\u578b\u8fc7\u5ea6\u5c06\u4e11\u964b\u4e0e\u8001\u5e74\u767d\u4eba\u7537\u6027\u5f62\u8c61\u5173\u8054\uff0c\u5b58\u5728\u793e\u4f1a\u504f\u89c1\u548c\u6096\u8bba\u6027\u504f\u89c1\uff1b\u5b9a\u6027\u5206\u6790\u663e\u793a\u4f20\u7edf\u8eab\u4f53\u7279\u5f81\u4ecd\u662f\u8868\u8fbe\u4e11\u964b\u7684\u6838\u5fc3\u89c6\u89c9\u4e3b\u9898\u3002", "conclusion": "\u5c3d\u7ba1\u52aa\u529b\u521b\u9020\u66f4\u5e73\u7b49\u7684\u8868\u5f81\uff0c\u751f\u6210\u5f0fAI\u4ecd\u5ef6\u7eed\u56fa\u6709\u548c\u6096\u8bba\u6027\u504f\u89c1\uff0c\u51f8\u663e\u521b\u5efa\u4f26\u7406AI\u8bad\u7ec3\u8303\u5f0f\u548c\u63a8\u8fdb\u5305\u5bb9\u6027AI\u53d1\u5c55\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.11953", "pdf": "https://arxiv.org/pdf/2507.11953", "abs": "https://arxiv.org/abs/2507.11953", "authors": ["Yi Zhao", "Zuchao Li", "Hai Zhao"], "title": "IAM: Efficient Inference through Attention Mapping between Different-scale LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "ACL 2025", "summary": "LLMs encounter significant challenges in resource consumption nowadays,\nespecially with long contexts. Despite extensive efforts dedicate to enhancing\ninference efficiency, these methods primarily exploit internal sparsity within\nthe models, without leveraging external information for optimization. We\nidentify the high similarity of attention matrices across different-scale LLMs,\nwhich offers a novel perspective for optimization. We first conduct a\ncomprehensive analysis of how to measure similarity, how to select mapping\nLayers and whether mapping is consistency. Based on these insights, we\nintroduce the IAM framework, which achieves dual benefits of accelerated\nattention computation and reduced KV cache usage by performing attention\nmapping between small and large LLMs. Our experimental results demonstrate that\nIAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without\nappreciably sacrificing performance. Experiments on different series of models\nshow the generalizability of IAM. Importantly, it is also orthogonal to many\nexisting KV cache optimization methods, making it a versatile addition to the\ncurrent toolkit for enhancing LLM efficiency.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u8d44\u6e90\u6d88\u8017\u95ee\u9898\uff0c\u57fa\u4e8e\u6ce8\u610f\u529b\u77e9\u9635\u76f8\u4f3c\u6027\u63d0\u51fa IAM \u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u52a0\u901f\u63a8\u7406\u5e76\u51cf\u5c11 KV \u7f13\u5b58\u4f7f\u7528\uff0c\u4e14\u5177\u6709\u901a\u7528\u6027\u548c\u6b63\u4ea4\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u73b0\u6709\u63a8\u7406\u6548\u7387\u63d0\u5347\u65b9\u6cd5\u672a\u5229\u7528\u5916\u90e8\u4fe1\u606f\u4f18\u5316\uff0c\u6587\u7ae0\u65e8\u5728\u57fa\u4e8e\u6ce8\u610f\u529b\u77e9\u9635\u76f8\u4f3c\u6027\u627e\u5230\u65b0\u4f18\u5316\u89c6\u89d2\u3002", "method": "\u5148\u5168\u9762\u5206\u6790\u6d4b\u91cf\u76f8\u4f3c\u5ea6\u3001\u9009\u62e9\u6620\u5c04\u5c42\u53ca\u6620\u5c04\u4e00\u81f4\u6027\u7b49\u95ee\u9898\uff0c\u518d\u5f15\u5165 IAM \u6846\u67b6\uff0c\u5728\u5927\u5c0f\u6a21\u578b\u95f4\u8fdb\u884c\u6ce8\u610f\u529b\u6620\u5c04\u3002", "result": "IAM \u80fd\u52a0\u901f prefill 15%\uff0c\u51cf\u5c11 KV \u7f13\u5b58\u4f7f\u7528 22.1%\uff0c\u4e0d\u540c\u7cfb\u5217\u6a21\u578b\u5b9e\u9a8c\u663e\u793a\u5176\u5177\u6709\u901a\u7528\u6027\uff0c\u4e14\u4e0e\u73b0\u6709 KV \u7f13\u5b58\u4f18\u5316\u65b9\u6cd5\u6b63\u4ea4\u3002", "conclusion": "IAM \u6846\u67b6\u662f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6548\u7387\u7684\u6709\u6548\u5de5\u5177\uff0c\u5177\u6709\u901a\u7528\u6027\u548c\u4e0e\u5176\u4ed6\u65b9\u6cd5\u7684\u6b63\u4ea4\u6027\uff0c\u53ef\u4f5c\u4e3a\u73b0\u6709\u5de5\u5177\u5305\u7684\u8865\u5145\u3002"}}
{"id": "2507.11954", "pdf": "https://arxiv.org/pdf/2507.11954", "abs": "https://arxiv.org/abs/2507.11954", "authors": ["Artem Alekseev", "Mikhail Chaichuk", "Miron Butko", "Alexander Panchenko", "Elena Tutubalina", "Oleg Somov"], "title": "The benefits of query-based KGQA systems for complex and temporal questions in LLM era", "categories": ["cs.CL", "cs.LG"], "comment": "15 pages, 3 figures, 7 tables", "summary": "Large language models excel in question-answering (QA) yet still struggle\nwith multi-hop reasoning and temporal questions. Query-based knowledge graph QA\n(KGQA) offers a modular alternative by generating executable queries instead of\ndirect answers. We explore multi-stage query-based framework for WikiData QA,\nproposing multi-stage approach that enhances performance on challenging\nmulti-hop and temporal benchmarks. Through generalization and rejection\nstudies, we evaluate robustness across multi-hop and temporal QA datasets.\nAdditionally, we introduce a novel entity linking and predicate matching method\nusing CoT reasoning. Our results demonstrate the potential of query-based\nmulti-stage KGQA framework for improving multi-hop and temporal QA with small\nlanguage models. Code and data: https://github.com/ar2max/NLDB-KGQA-System", "AI": {"tldr": "\u63a2\u7d22\u57fa\u4e8e\u67e5\u8be2\u7684\u591a\u9636\u6bb5\u6846\u67b6\u7528\u4e8eWikiData\u95ee\u7b54\uff0c\u63d0\u51fa\u589e\u5f3a\u591a\u8df3\u548c\u65f6\u95f4\u95ee\u7b54\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u9c81\u68d2\u6027\u5e76\u5f15\u5165\u65b0\u5b9e\u4f53\u94fe\u63a5\u548c\u8c13\u8bcd\u5339\u914d\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\u6709\u63d0\u5347\u6f5c\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u63a8\u7406\u548c\u65f6\u95f4\u95ee\u9898\u95ee\u7b54\u4e0a\u5b58\u5728\u56f0\u96be\uff0c\u57fa\u4e8e\u67e5\u8be2\u7684\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u591a\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u6cdb\u5316\u548c\u62d2\u7edd\u7814\u7a76\u8bc4\u4f30\u9c81\u68d2\u6027\uff0c\u5f15\u5165\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u5b9e\u4f53\u94fe\u63a5\u548c\u8c13\u8bcd\u5339\u914d\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u57fa\u4e8e\u67e5\u8be2\u7684\u591a\u9636\u6bb5\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u6846\u67b6\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u548c\u65f6\u95f4\u95ee\u7b54\u4e0a\u6709\u63d0\u5347\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8e\u67e5\u8be2\u7684\u591a\u9636\u6bb5KGQA\u6846\u67b6\u53ef\u7528\u4e8e\u6539\u8fdb\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8df3\u548c\u65f6\u95f4\u95ee\u7b54\u3002"}}
{"id": "2507.12252", "pdf": "https://arxiv.org/pdf/2507.12252", "abs": "https://arxiv.org/abs/2507.12252", "authors": ["Shilin Zhou", "Zhenghua Li"], "title": "Improving Contextual ASR via Multi-grained Fusion with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While end-to-end Automatic Speech Recognition (ASR) models have shown\nimpressive performance in transcribing general speech, they often struggle to\naccurately recognize contextually relevant keywords, such as proper nouns or\nuser-specific entities.\n  Previous approaches have explored leveraging keyword dictionaries in the\ntextual modality to improve keyword recognition, either through token-level\nfusion that guides token-by-token generation or phrase-level fusion that\nenables direct copying of keyword phrases.\n  However, these methods operate at different granularities and have their own\nlimitations.\n  In this paper, we propose a novel multi-grained fusion approach that jointly\nleverages the strengths of both token-level and phrase-level fusion with Large\nLanguage Models (LLMs).\n  Our approach incorporates a late-fusion strategy that elegantly combines\nASR's acoustic information with LLM's rich contextual knowledge, balancing\nfine-grained token precision with holistic phrase-level understanding.\n  Experiments on Chinese and English datasets demonstrate that our approach\nachieves state-of-the-art performance on keyword-related metrics while\npreserving high accuracy on non-keyword text.\n  Ablation studies further confirm that the token-level and phrase-level\ncomponents both contribute significantly to the performance gains,\ncomplementing each other in our joint multi-grained framework.\n  The code and models will be publicly available at https://github.com/.", "AI": {"tldr": "\u63d0\u51fa\u591a\u7c92\u5ea6\u878d\u5408\u65b9\u6cd5\u63d0\u5347\u7aef\u5230\u7aefASR\u6a21\u578b\u5173\u952e\u8bcd\u8bc6\u522b\u6027\u80fd\uff0c\u5728\u4e2d\u82f1\u6587\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7aef\u5230\u7aefASR\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u8bc6\u522b\u4e0a\u4e0b\u6587\u76f8\u5173\u5173\u952e\u8bcd\uff0c\u4ee5\u5f80\u57fa\u4e8e\u5173\u952e\u8bcd\u5b57\u5178\u7684\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u7c92\u5ea6\u878d\u5408\u65b9\u6cd5\uff0c\u91c7\u7528\u540e\u671f\u878d\u5408\u7b56\u7565\u7ed3\u5408ASR\u58f0\u5b66\u4fe1\u606f\u548cLLM\u4e0a\u4e0b\u6587\u77e5\u8bc6\u3002", "result": "\u5728\u4e2d\u82f1\u6587\u6570\u636e\u96c6\u4e0a\u5173\u952e\u8bcd\u76f8\u5173\u6307\u6807\u8fbeSOTA\uff0c\u975e\u5173\u952e\u8bcd\u6587\u672c\u4e5f\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u5404\u7ec4\u4ef6\u6709\u663e\u8457\u8d21\u732e\u3002", "conclusion": "\u6240\u63d0\u591a\u7c92\u5ea6\u878d\u5408\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u5173\u952e\u8bcd\u8bc6\u522b\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u6a21\u578b\u5c06\u516c\u5f00\u3002"}}
{"id": "2507.12261", "pdf": "https://arxiv.org/pdf/2507.12261", "abs": "https://arxiv.org/abs/2507.12261", "authors": ["Johann Frei", "Nils Feldhus", "Lisa Raithel", "Roland Roller", "Alexander Meyer", "Frank Kramer"], "title": "Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes", "categories": ["cs.CL", "cs.AI"], "comment": "Submitted to EMNLP 2025 System Demonstrations | Code:\n  https://github.com/j-frei/Infherno | Video:\n  https://www.youtube.com/watch?v=kyj5C2ivbMw | Demo:\n  https://infherno.misit-augsburg.de | HuggingFace Spaces:\n  https://huggingface.co/spaces/nfel/infherno", "summary": "For clinical data integration and healthcare services, the HL7 FHIR standard\nhas established itself as a desirable format for interoperability between\ncomplex health data. Previous attempts at automating the translation from\nfree-form clinical notes into structured FHIR resources rely on modular,\nrule-based systems or LLMs with instruction tuning and constrained decoding.\nSince they frequently suffer from limited generalizability and structural\ninconformity, we propose an end-to-end framework powered by LLM agents, code\nexecution, and healthcare terminology database tools to address these issues.\nOur solution, called Infherno, is designed to adhere to the FHIR document\nschema and competes well with a human baseline in predicting FHIR resources\nfrom unstructured text. The implementation features a front end for custom and\nsynthetic data and both local and proprietary models, supporting clinical data\nintegration processes and interoperability across institutions.", "AI": {"tldr": "\u63d0\u51fa\u7aef\u5230\u7aef\u6846\u67b6Infherno\u89e3\u51b3\u4e34\u5e8a\u7b14\u8bb0\u8f6cFHIR\u8d44\u6e90\u95ee\u9898\uff0c\u8868\u73b0\u826f\u597d\u4e14\u652f\u6301\u6570\u636e\u96c6\u6210\u4e0e\u4e92\u64cd\u4f5c\u6027\u3002", "motivation": "\u4ee5\u5f80\u5c06\u81ea\u7531\u5f62\u5f0f\u4e34\u5e8a\u7b14\u8bb0\u81ea\u52a8\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316FHIR\u8d44\u6e90\u7684\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u6027\u6709\u9650\u548c\u7ed3\u6784\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u7531\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u3001\u4ee3\u7801\u6267\u884c\u548c\u533b\u7597\u672f\u8bed\u6570\u636e\u5e93\u5de5\u5177\u9a71\u52a8\u7684\u7aef\u5230\u7aef\u6846\u67b6Infherno\u3002", "result": "Infherno\u7b26\u5408FHIR\u6587\u6863\u6a21\u5f0f\uff0c\u5728\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u9884\u6d4bFHIR\u8d44\u6e90\u65b9\u9762\u4e0e\u4eba\u7c7b\u57fa\u7ebf\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "Infherno\u652f\u6301\u4e34\u5e8a\u6570\u636e\u96c6\u6210\u8fc7\u7a0b\u548c\u8de8\u673a\u6784\u4e92\u64cd\u4f5c\u6027\u3002"}}
{"id": "2507.11960", "pdf": "https://arxiv.org/pdf/2507.11960", "abs": "https://arxiv.org/abs/2507.11960", "authors": ["Hyein Hong", "Sangbong Yoo", "SeokHwan Choi", "Jisue Kim", "Seongbum Seo", "Haneol Cho", "Chansoo Kim", "Yun Jang"], "title": "d-DQIVAR: Data-centric Visual Analytics and Reasoning for Data Quality Improvement", "categories": ["cs.HC", "cs.LG"], "comment": null, "summary": "Approaches to enhancing data quality (DQ) are classified into two main\ncategories: data- and process-driven. However, prior research has predominantly\nutilized batch data preprocessing within the data-driven framework, which often\nproves insufficient for optimizing machine learning (ML) model performance and\nfrequently leads to distortions in data characteristics. Existing studies have\nprimarily focused on data preprocessing rather than genuine data quality\nimprovement (DQI). In this paper, we introduce d-DQIVAR, a novel visual\nanalytics system designed to facilitate DQI strategies aimed at improving ML\nmodel performance. Our system integrates visual analytics techniques that\nleverage both data-driven and process-driven approaches. Data-driven techniques\ntackle DQ issues such as imputation, outlier detection, deletion, format\nstandardization, removal of duplicate records, and feature selection.\nProcess-driven strategies encompass evaluating DQ and DQI procedures by\nconsidering DQ dimensions and ML model performance and applying the\nKolmogorov-Smirnov test. We illustrate how our system empowers users to harness\nexpert and domain knowledge effectively within a practical workflow through\ncase studies, evaluations, and user studies.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u53ef\u89c6\u5316\u5206\u6790\u7cfb\u7edfd - DQIVAR\uff0c\u7ed3\u5408\u6570\u636e\u548c\u8fc7\u7a0b\u9a71\u52a8\u65b9\u6cd5\u4fc3\u8fdb\u6570\u636e\u8d28\u91cf\u6539\u8fdb\u4ee5\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7b49\u5c55\u793a\u5176\u4f5c\u7528\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u591a\u5728\u6570\u636e\u9a71\u52a8\u6846\u67b6\u4e0b\u4f7f\u7528\u6279\u91cf\u6570\u636e\u9884\u5904\u7406\uff0c\u4e0d\u8db3\u4ee5\u4f18\u5316\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u4e14\u5bfc\u81f4\u6570\u636e\u7279\u5f81\u626d\u66f2\uff0c\u4e14\u4e3b\u8981\u5173\u6ce8\u6570\u636e\u9884\u5904\u7406\u800c\u975e\u771f\u6b63\u7684\u6570\u636e\u8d28\u91cf\u6539\u8fdb\u3002", "method": "\u5f15\u5165d - DQIVAR\u7cfb\u7edf\uff0c\u96c6\u6210\u6570\u636e\u9a71\u52a8\uff08\u5904\u7406\u6570\u636e\u8d28\u91cf\u95ee\u9898\uff09\u548c\u8fc7\u7a0b\u9a71\u52a8\uff08\u8bc4\u4f30\u6570\u636e\u8d28\u91cf\u548c\u6539\u8fdb\u7a0b\u5e8f\uff09\u65b9\u6cd5\uff0c\u8fd8\u8fd0\u7528Kolmogorov - Smirnov\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u3001\u8bc4\u4f30\u548c\u7528\u6237\u7814\u7a76\u5c55\u793a\u7cfb\u7edf\u80fd\u8ba9\u7528\u6237\u5728\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u6709\u6548\u5229\u7528\u4e13\u5bb6\u548c\u9886\u57df\u77e5\u8bc6\u3002", "conclusion": "d - DQIVAR\u7cfb\u7edf\u53ef\u4fc3\u8fdb\u6570\u636e\u8d28\u91cf\u6539\u8fdb\u7b56\u7565\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.11977", "pdf": "https://arxiv.org/pdf/2507.11977", "abs": "https://arxiv.org/abs/2507.11977", "authors": ["Farouk Mokhtar"], "title": "Recent results on searches with boosted Higgs bosons at CMS", "categories": ["hep-ex", "cs.LG"], "comment": "6 pages, 3 figures, The Thirteenth Annual Large Hadron Collider\n  Physics (LHCP2025)", "summary": "The study of boosted Higgs bosons at the LHC provides a unique window to\nprobe Higgs boson couplings at high energy scales and search for signs of\nphysics beyond the standard model. In these proceedings, we present recent\nresults on boosted Higgs boson searches at the CMS experiment, highlighting\ninnovative reconstruction and tagging techniques that enhance sensitivity in\nthis challenging regime.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdCMS\u5b9e\u9a8c\u4e2d\u9ad8\u80fd\u5e0c\u683c\u65af\u73bb\u8272\u5b50\u641c\u7d22\u7684\u6700\u65b0\u7ed3\u679c\u53ca\u521b\u65b0\u6280\u672f\u3002", "motivation": "\u901a\u8fc7\u7814\u7a76\u5927\u578b\u5f3a\u5b50\u5bf9\u649e\u673a\uff08LHC\uff09\u4e0a\u7684\u9ad8\u80fd\u5e0c\u683c\u65af\u73bb\u8272\u5b50\uff0c\u63a2\u7d22\u9ad8\u80fd\u5c3a\u5ea6\u4e0b\u5e0c\u683c\u65af\u73bb\u8272\u5b50\u7684\u8026\u5408\u4ee5\u53ca\u5bfb\u627e\u8d85\u51fa\u6807\u51c6\u6a21\u578b\u7684\u7269\u7406\u8ff9\u8c61\u3002", "method": "\u91c7\u7528\u521b\u65b0\u7684\u91cd\u5efa\u548c\u6807\u8bb0\u6280\u672f\u3002", "result": "\u83b7\u5f97\u4e86CMS\u5b9e\u9a8c\u4e2d\u9ad8\u80fd\u5e0c\u683c\u65af\u73bb\u8272\u5b50\u641c\u7d22\u7684\u6700\u65b0\u7ed3\u679c\u3002", "conclusion": "\u521b\u65b0\u6280\u672f\u53ef\u63d0\u9ad8\u5728\u8be5\u6311\u6218\u6027\u9886\u57df\u7684\u7075\u654f\u5ea6\u3002"}}
{"id": "2507.12269", "pdf": "https://arxiv.org/pdf/2507.12269", "abs": "https://arxiv.org/abs/2507.12269", "authors": ["Sybelle Goedicke-Fritz", "Michelle Bous", "Annika Engel", "Matthias Flotho", "Pascal Hirsch", "Hannah Wittig", "Dino Milanovic", "Dominik Mohr", "Mathias Kaspar", "Sogand Nemat", "Dorothea Kerner", "Arno B\u00fccker", "Andreas Keller", "Sascha Meyer", "Michael Zemlin", "Philipp Flotho"], "title": "Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "S.G.-F., M.B., and A.E. contributed equally to this work and share\n  first authorship. M.Z. and P.F. contributed equally to this work and share\n  senior authorship", "summary": "Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of\nextremely low birth weight infants. Defined by oxygen dependence at 36 weeks\npostmenstrual age, it causes lifelong respiratory complications. However,\npreventive interventions carry severe risks, including neurodevelopmental\nimpairment, ventilator-induced lung injury, and systemic complications.\nTherefore, early BPD prognosis and prediction of BPD outcome is crucial to\navoid unnecessary toxicity in low risk infants. Admission radiographs of\nextremely preterm infants are routinely acquired within 24h of life and could\nserve as a non-invasive prognostic tool. In this work, we developed and\ninvestigated a deep learning approach using chest X-rays from 163 extremely\nlow-birth-weight infants ($\\leq$32 weeks gestation, 401-999g) obtained within\n24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult\nchest radiographs, employing progressive layer freezing with discriminative\nlearning rates to prevent overfitting and evaluated a CutMix augmentation and\nlinear probing. For moderate/severe BPD outcome prediction, our best performing\nmodel with progressive freezing, linear probing and CutMix achieved an AUROC of\n0.78 $\\pm$ 0.10, balanced accuracy of 0.69 $\\pm$ 0.10, and an F1-score of 0.67\n$\\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet\ninitialization (p = 0.031) which confirms domain-specific pretraining to be\nimportant for BPD outcome prediction. Routine IRDS grades showed limited\nprognostic value (AUROC 0.57 $\\pm$ 0.11), confirming the need of learned\nmarkers. Our approach demonstrates that domain-specific pretraining enables\naccurate BPD prediction from routine day-1 radiographs. Through progressive\nfreezing and linear probing, the method remains computationally feasible for\nsite-level implementation and future federated learning deployments.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u57fa\u4e8e\u51fa\u751f24\u5c0f\u65f6\u5185\u6781\u4f4e\u51fa\u751f\u4f53\u91cd\u5a74\u513f\u80f8\u90e8X\u5149\u7247\u9884\u6d4b\u652f\u6c14\u7ba1\u80ba\u53d1\u80b2\u4e0d\u826f\uff08BPD\uff09\u7ed3\u679c\uff0c\u8bc1\u660e\u7279\u5b9a\u9886\u57df\u9884\u8bad\u7ec3\u6709\u6548\u3002", "motivation": "BPD\u5f71\u54cd35%\u6781\u4f4e\u51fa\u751f\u4f53\u91cd\u5a74\u513f\uff0c\u6709\u7ec8\u8eab\u547c\u5438\u5e76\u53d1\u75c7\uff0c\u9884\u9632\u6027\u5e72\u9884\u6709\u4e25\u91cd\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u65e9\u671f\u9884\u540e\u548c\u7ed3\u679c\u9884\u6d4b\u4ee5\u907f\u514d\u4f4e\u98ce\u9669\u5a74\u513f\u4e0d\u5fc5\u8981\u7684\u6bd2\u6027\u3002", "method": "\u4f7f\u7528163\u540d\u6781\u4f4e\u51fa\u751f\u4f53\u91cd\u5a74\u513f\u51fa\u751f24\u5c0f\u65f6\u5185\u7684\u80f8\u90e8X\u5149\u7247\uff0c\u5fae\u8c03\u5728\u6210\u4eba\u80f8\u90e8X\u5149\u7247\u4e0a\u9884\u8bad\u7ec3\u7684ResNet - 50\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u5c42\u51bb\u7ed3\u3001\u5224\u522b\u5f0f\u5b66\u4e60\u7387\u3001CutMix\u589e\u5f3a\u548c\u7ebf\u6027\u63a2\u6d4b\u3002", "result": "\u6700\u4f73\u6a21\u578b\u9884\u6d4b\u4e2d\u5ea6/\u91cd\u5ea6BPD\u7ed3\u679c\u65f6\uff0cAUROC\u4e3a0.78 \u00b1 0.10\uff0c\u5e73\u8861\u51c6\u786e\u7387\u4e3a0.69 \u00b1 0.10\uff0cF1\u5206\u6570\u4e3a0.67 \u00b1 0.11\uff1b\u7279\u5b9a\u9886\u57df\u9884\u8bad\u7ec3\u663e\u8457\u4f18\u4e8eImageNet\u521d\u59cb\u5316\uff1b\u5e38\u89c4IRDS\u5206\u7ea7\u9884\u540e\u4ef7\u503c\u6709\u9650\u3002", "conclusion": "\u7279\u5b9a\u9886\u57df\u9884\u8bad\u7ec3\u80fd\u4ece\u5e38\u89c4\u7b2c1\u5929X\u5149\u7247\u51c6\u786e\u9884\u6d4bBPD\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u4e0a\u53ef\u884c\uff0c\u9002\u7528\u4e8e\u73b0\u573a\u5b9e\u65bd\u548c\u672a\u6765\u8054\u5408\u5b66\u4e60\u90e8\u7f72\u3002"}}
{"id": "2507.11984", "pdf": "https://arxiv.org/pdf/2507.11984", "abs": "https://arxiv.org/abs/2507.11984", "authors": ["Hyeon Jeon", "Jeongin Park", "Soohyun Lee", "Dae Hyun Kim", "Sungbok Shin", "Jinwook Seo"], "title": "Dataset-Adaptive Dimensionality Reduction", "categories": ["cs.HC", "cs.LG"], "comment": "IEEE VIS 2025 & IEEE Transactions on Visualization and Computer\n  Graphics (TVCG)", "summary": "Selecting the appropriate dimensionality reduction (DR) technique and\ndetermining its optimal hyperparameter settings that maximize the accuracy of\nthe output projections typically involves extensive trial and error, often\nresulting in unnecessary computational overhead. To address this challenge, we\npropose a dataset-adaptive approach to DR optimization guided by structural\ncomplexity metrics. These metrics quantify the intrinsic complexity of a\ndataset, predicting whether higher-dimensional spaces are necessary to\nrepresent it accurately. Since complex datasets are often inaccurately\nrepresented in two-dimensional projections, leveraging these metrics enables us\nto predict the maximum achievable accuracy of DR techniques for a given\ndataset, eliminating redundant trials in optimizing DR. We introduce the design\nand theoretical foundations of these structural complexity metrics. We\nquantitatively verify that our metrics effectively approximate the ground truth\ncomplexity of datasets and confirm their suitability for guiding\ndataset-adaptive DR workflow. Finally, we empirically show that our\ndataset-adaptive workflow significantly enhances the efficiency of DR\noptimization without compromising accuracy.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7ed3\u6784\u590d\u6742\u5ea6\u6307\u6807\u7684\u6570\u636e\u96c6\u81ea\u9002\u5e94\u964d\u7ef4\u4f18\u5316\u65b9\u6cd5\uff0c\u53ef\u63d0\u9ad8\u964d\u7ef4\u4f18\u5316\u6548\u7387\u4e14\u4e0d\u964d\u4f4e\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u9009\u62e9\u964d\u7ef4\u6280\u672f\u548c\u786e\u5b9a\u6700\u4f18\u8d85\u53c2\u6570\u8bbe\u7f6e\u65f6\u7684\u5927\u91cf\u8bd5\u9519\u548c\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002", "method": "\u5f15\u5165\u7ed3\u6784\u590d\u6742\u5ea6\u6307\u6807\u91cf\u5316\u6570\u636e\u96c6\u5185\u5728\u590d\u6742\u5ea6\uff0c\u5229\u7528\u6307\u6807\u9884\u6d4b\u964d\u7ef4\u6280\u672f\u6700\u5927\u53ef\u5b9e\u73b0\u7684\u51c6\u786e\u6027\uff0c\u6307\u5bfc\u6570\u636e\u96c6\u81ea\u9002\u5e94\u964d\u7ef4\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5b9a\u91cf\u9a8c\u8bc1\u6307\u6807\u80fd\u6709\u6548\u8fd1\u4f3c\u6570\u636e\u96c6\u771f\u5b9e\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u6307\u5bfc\u964d\u7ef4\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u6570\u636e\u96c6\u81ea\u9002\u5e94\u5de5\u4f5c\u6d41\u7a0b\u80fd\u663e\u8457\u63d0\u9ad8\u964d\u7ef4\u4f18\u5316\u6548\u7387\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002"}}
{"id": "2507.12295", "pdf": "https://arxiv.org/pdf/2507.12295", "abs": "https://arxiv.org/abs/2507.12295", "authors": ["Feng Xiao", "Jicong Fan"], "title": "Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Text anomaly detection is a critical task in natural language processing\n(NLP), with applications spanning fraud detection, misinformation\nidentification, spam detection and content moderation, etc. Despite significant\nadvances in large language models (LLMs) and anomaly detection algorithms, the\nabsence of standardized and comprehensive benchmarks for evaluating the\nexisting anomaly detection methods on text data limits rigorous comparison and\ndevelopment of innovative approaches. This work performs a comprehensive\nempirical study and introduces a benchmark for text anomaly detection,\nleveraging embeddings from diverse pre-trained language models across a wide\narray of text datasets. Our work systematically evaluates the effectiveness of\nembedding-based text anomaly detection by incorporating (1) early language\nmodels (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI\n(small, ada, large)); (3) multi-domain text datasets (news, social media,\nscientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).\nOur experiments reveal a critical empirical insight: embedding quality\nsignificantly governs anomaly detection efficacy, and deep learning-based\napproaches demonstrate no performance advantage over conventional shallow\nalgorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived\nembeddings.In addition, we observe strongly low-rank characteristics in\ncross-model performance matrices, which enables an efficient strategy for rapid\nmodel evaluation (or embedding evaluation) and selection in practical\napplications. Furthermore, by open-sourcing our benchmark toolkit that includes\nall embeddings from different models and code at\nhttps://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work\nprovides a foundation for future research in robust and scalable text anomaly\ndetection systems.", "AI": {"tldr": "\u672c\u6587\u5f00\u5c55\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5f15\u5165\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\u5d4c\u5165\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u53d1\u73b0\u5d4c\u5165\u8d28\u91cf\u5f71\u54cd\u68c0\u6d4b\u6548\u80fd\uff0cDL\u65b9\u6cd5\u65e0\u4f18\u52bf\uff0c\u6709\u4f4e\u79e9\u7279\u6027\uff0c\u8fd8\u5f00\u6e90\u5de5\u5177\u5305\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u6807\u51c6\u5316\u548c\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9650\u5236\u65b9\u6cd5\u6bd4\u8f83\u548c\u521b\u65b0\u3002", "method": "\u5229\u7528\u591a\u79cd\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\uff0c\u5728\u591a\u9886\u57df\u6587\u672c\u6570\u636e\u96c6\u4e0a\uff0c\u91c7\u7528\u7efc\u5408\u8bc4\u4f30\u6307\u6807\u7cfb\u7edf\u8bc4\u4f30\u57fa\u4e8e\u5d4c\u5165\u7684\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5d4c\u5165\u8d28\u91cf\u663e\u8457\u5f71\u54cd\u5f02\u5e38\u68c0\u6d4b\u6548\u80fd\uff1b\u4f7f\u7528\u5927\u6a21\u578b\u5d4c\u5165\u65f6\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u65e0\u6027\u80fd\u4f18\u52bf\uff1b\u8de8\u6a21\u578b\u6027\u80fd\u77e9\u9635\u6709\u4f4e\u79e9\u7279\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765\u9c81\u68d2\u53ef\u6269\u5c55\u7684\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\uff0c\u5f00\u6e90\u5de5\u5177\u5305\u65b9\u4fbf\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2507.12023", "pdf": "https://arxiv.org/pdf/2507.12023", "abs": "https://arxiv.org/abs/2507.12023", "authors": ["Xu Fan", "Zhihao Wang", "Yuetan Lin", "Yan Zhang", "Yang Xiang", "Hao Li"], "title": "MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Air pollutants pose a significant threat to the environment and human health,\nthus forecasting accurate pollutant concentrations is essential for pollution\nwarnings and policy-making. Existing studies predominantly focus on\nsingle-pollutant forecasting, neglecting the interactions among different\npollutants and their diverse spatial responses. To address the practical needs\nof forecasting multivariate air pollutants, we propose MultiVariate\nAutoRegressive air pollutants forecasting model (MVAR), which reduces the\ndependency on long-time-window inputs and boosts the data utilization\nefficiency. We also design the Multivariate Autoregressive Training Paradigm,\nenabling MVAR to achieve 120-hour long-term sequential forecasting.\nAdditionally, MVAR develops Meteorological Coupled Spatial Transformer block,\nenabling the flexible coupling of AI-based meteorological forecasts while\nlearning the interactions among pollutants and their diverse spatial responses.\nAs for the lack of standardized datasets in air pollutants forecasting, we\nconstruct a comprehensive dataset covering 6 major pollutants across 75 cities\nin North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0\nforecast data. Experimental results demonstrate that the proposed model\noutperforms state-of-the-art methods and validate the effectiveness of the\nproposed architecture.", "AI": {"tldr": "\u63d0\u51faMVAR\u6a21\u578b\u7528\u4e8e\u591a\u53d8\u91cf\u7a7a\u6c14\u6c61\u67d3\u7269\u9884\u6d4b\uff0c\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u5355\u6c61\u67d3\u7269\u9884\u6d4b\uff0c\u5ffd\u7565\u4e0d\u540c\u6c61\u67d3\u7269\u95f4\u76f8\u4e92\u4f5c\u7528\u53ca\u7a7a\u95f4\u54cd\u5e94\u5dee\u5f02\uff0c\u4e3a\u6ee1\u8db3\u591a\u53d8\u91cf\u7a7a\u6c14\u6c61\u67d3\u7269\u9884\u6d4b\u7684\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u63d0\u51faMultiVariate AutoRegressive\u7a7a\u6c14\u6c61\u67d3\u7269\u9884\u6d4b\u6a21\u578b\uff08MVAR\uff09\uff0c\u8bbe\u8ba1\u591a\u53d8\u91cf\u81ea\u56de\u5f52\u8bad\u7ec3\u8303\u5f0f\uff0c\u5f00\u53d1\u6c14\u8c61\u8026\u5408\u7a7a\u95f4\u53d8\u6362\u5668\u6a21\u5757\uff0c\u6784\u5efa\u6db5\u76d66\u79cd\u4e3b\u8981\u6c61\u67d3\u7269\u7684\u7efc\u5408\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u67b6\u6784\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.12308", "pdf": "https://arxiv.org/pdf/2507.12308", "abs": "https://arxiv.org/abs/2507.12308", "authors": ["Prashanth Vijayaraghavan", "Apoorva Nitsure", "Charles Mackin", "Luyao Shi", "Stefano Ambrogio", "Arvind Haran", "Viresh Paruthi", "Ali Elzein", "Dan Coops", "David Beymer", "Tyler Baldwin", "Ehsan Degan"], "title": "Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization", "categories": ["cs.CL", "cs.AI", "cs.AR"], "comment": "10 pages (6 content pages + 4 supplementary), 5 figures, Proceedings\n  of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD.\n  2024 (MLCAD'24)", "summary": "Large Language Models (LLMs) have become widely used across diverse NLP tasks\nand domains, demonstrating their adaptability and effectiveness. In the realm\nof Electronic Design Automation (EDA), LLMs show promise for tasks like\nRegister-Transfer Level (RTL) code generation and summarization. However,\ndespite the proliferation of LLMs for general code-related tasks, there's a\ndearth of research focused on evaluating and refining these models for hardware\ndescription languages (HDLs), notably VHDL. In this study, we evaluate the\nperformance of existing code LLMs for VHDL code generation and summarization\nusing various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,\nan in-house dataset, aims to gauge LLMs' understanding of functionally\nequivalent code. Our findings reveal consistent underperformance of these\nmodels across different metrics, underscoring a significant gap in their\nsuitability for this domain. To address this challenge, we propose\nChain-of-Descriptions (CoDes), a novel approach to enhance the performance of\nLLMs for VHDL code generation and summarization tasks. CoDes involves\ngenerating a series of intermediate descriptive steps based on: (i) the problem\nstatement for code generation, and (ii) the VHDL code for summarization. These\nsteps are then integrated with the original input prompt (problem statement or\ncode) and provided as input to the LLMs to generate the final output. Our\nexperiments demonstrate that the CoDes approach significantly surpasses the\nstandard prompting strategy across various metrics on both datasets. This\nmethod not only improves the quality of VHDL code generation and summarization\nbut also serves as a framework for future research aimed at enhancing code LLMs\nfor VHDL.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u73b0\u6709\u4ee3\u7801\u5927\u6a21\u578b\u5728VHDL\u4ee3\u7801\u751f\u6210\u548c\u603b\u7ed3\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8868\u73b0\u4e0d\u4f73\uff0c\u63d0\u51faCoDes\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5927\u6a21\u578b\u5728\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00VHDL\u65b9\u9762\u7684\u8bc4\u4f30\u548c\u6539\u8fdb\uff0c\u9700\u63d0\u5347\u5927\u6a21\u578b\u5728VHDL\u4ee3\u7801\u751f\u6210\u548c\u603b\u7ed3\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528VHDL - Eval\u548cVHDL - Xform\u4e24\u4e2a\u6570\u636e\u96c6\u8bc4\u4f30\u73b0\u6709\u4ee3\u7801\u5927\u6a21\u578b\uff0c\u63d0\u51faChain - of - Descriptions (CoDes)\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u4e2d\u95f4\u63cf\u8ff0\u6b65\u9aa4\u5e76\u4e0e\u539f\u8f93\u5165\u63d0\u793a\u6574\u5408\u8f93\u5165\u5927\u6a21\u578b\u3002", "result": "\u73b0\u6709\u6a21\u578b\u5728\u5404\u6307\u6807\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0cCoDes\u65b9\u6cd5\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5404\u6307\u6807\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u63d0\u793a\u7b56\u7565\u3002", "conclusion": "CoDes\u65b9\u6cd5\u63d0\u5347\u4e86VHDL\u4ee3\u7801\u751f\u6210\u548c\u603b\u7ed3\u8d28\u91cf\uff0c\u53ef\u4e3a\u672a\u6765\u63d0\u5347VHDL\u4ee3\u7801\u5927\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u6846\u67b6\u3002"}}
{"id": "2507.12091", "pdf": "https://arxiv.org/pdf/2507.12091", "abs": "https://arxiv.org/abs/2507.12091", "authors": ["Wei Jiang", "Dingzhi Yu", "Sifan Yang", "Wenhao Yang", "Lijun Zhang"], "title": "Improved Analysis for Sign-based Methods with Momentum Updates", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "In this paper, we present enhanced analysis for sign-based optimization\nalgorithms with momentum updates. Traditional sign-based methods, under the\nseparable smoothness assumption, guarantee a convergence rate of\n$\\mathcal{O}(T^{-1/4})$, but they either require large batch sizes or assume\nunimodal symmetric stochastic noise. To address these limitations, we\ndemonstrate that signSGD with momentum can achieve the same convergence rate\nusing constant batch sizes without additional assumptions. Our analysis, under\nthe standard $l_2$-smoothness condition, improves upon the result of the prior\nmomentum-based signSGD method by a factor of $\\mathcal{O}(d^{1/2})$, where $d$\nis the problem dimension. Furthermore, we explore sign-based methods with\nmajority vote in distributed settings and show that the proposed momentum-based\nmethod yields convergence rates of $\\mathcal{O}\\left( d^{1/2}T^{-1/2} +\ndn^{-1/2} \\right)$ and $\\mathcal{O}\\left( \\max \\{ d^{1/4}T^{-1/4},\nd^{1/10}T^{-1/5} \\} \\right)$, which outperform the previous results of\n$\\mathcal{O}\\left( dT^{-1/4} + dn^{-1/2} \\right)$ and $\\mathcal{O}\\left(\nd^{3/8}T^{-1/8} \\right)$, respectively. Numerical experiments further validate\nthe effectiveness of the proposed methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.12318", "pdf": "https://arxiv.org/pdf/2507.12318", "abs": "https://arxiv.org/abs/2507.12318", "authors": ["Samuel Lavoie", "Michael Noukhovitch", "Aaron Courville"], "title": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "In submission, 22 pages, 7 tables, 12 figures", "summary": "We argue that diffusion models' success in modeling complex distributions is,\nfor the most part, coming from their input conditioning. This paper\ninvestigates the representation used to condition diffusion models from the\nperspective that ideal representations should improve sample fidelity, be easy\nto generate, and be compositional to allow out-of-training samples generation.\nWe introduce Discrete Latent Code (DLC), an image representation derived from\nSimplicial Embeddings trained with a self-supervised learning objective. DLCs\nare sequences of discrete tokens, as opposed to the standard continuous image\nembeddings. They are easy to generate and their compositionality enables\nsampling of novel images beyond the training distribution. Diffusion models\ntrained with DLCs have improved generation fidelity, establishing a new\nstate-of-the-art for unconditional image generation on ImageNet. Additionally,\nwe show that composing DLCs allows the image generator to produce\nout-of-distribution samples that coherently combine the semantics of images in\ndiverse ways. Finally, we showcase how DLCs can enable text-to-image generation\nby leveraging large-scale pretrained language models. We efficiently finetune a\ntext diffusion language model to generate DLCs that produce novel samples\noutside of the image generator training distribution.", "AI": {"tldr": "\u672c\u6587\u4ece\u7406\u60f3\u8868\u793a\u5e94\u63d0\u5347\u6837\u672c\u4fdd\u771f\u5ea6\u3001\u6613\u4e8e\u751f\u6210\u548c\u53ef\u7ec4\u5408\u7684\u89d2\u5ea6\uff0c\u7814\u7a76\u6269\u6563\u6a21\u578b\u7684\u8f93\u5165\u6761\u4ef6\u8868\u793a\uff0c\u5f15\u5165\u79bb\u6563\u6f5c\u7801DLC\uff0c\u63d0\u5347\u4e86\u56fe\u50cf\u751f\u6210\u4fdd\u771f\u5ea6\uff0c\u53ef\u751f\u6210\u5206\u5e03\u5916\u6837\u672c\u5e76\u5b9e\u73b0\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u3002", "motivation": "\u63a2\u7a76\u6269\u6563\u6a21\u578b\u6210\u529f\u7684\u539f\u56e0\u5728\u4e8e\u8f93\u5165\u6761\u4ef6\uff0c\u7814\u7a76\u80fd\u63d0\u5347\u6837\u672c\u4fdd\u771f\u5ea6\u3001\u6613\u4e8e\u751f\u6210\u548c\u53ef\u7ec4\u5408\u7684\u6761\u4ef6\u8868\u793a\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5355\u7eaf\u5f62\u5d4c\u5165\u4e14\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u8bad\u7ec3\u5f97\u5230\u7684\u79bb\u6563\u6f5c\u7801DLC\uff0c\u5b83\u662f\u79bb\u6563\u4ee4\u724c\u5e8f\u5217\u3002", "result": "\u4f7f\u7528DLC\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\u63d0\u5347\u4e86\u751f\u6210\u4fdd\u771f\u5ea6\uff0c\u5728ImageNet\u4e0a\u5b9e\u73b0\u65e0\u6761\u4ef6\u56fe\u50cf\u751f\u6210\u7684\u65b0\u6700\u4f18\uff1b\u7ec4\u5408DLC\u53ef\u751f\u6210\u5206\u5e03\u5916\u6837\u672c\uff1b\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u5fae\u8c03\u6587\u672c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u751f\u6210DLC\u5b9e\u73b0\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u3002", "conclusion": "DLC\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u56fe\u50cf\u8868\u793a\uff0c\u80fd\u63d0\u5347\u6269\u6563\u6a21\u578b\u56fe\u50cf\u751f\u6210\u6548\u679c\uff0c\u8fd8\u53ef\u7528\u4e8e\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u3002"}}
{"id": "2507.12098", "pdf": "https://arxiv.org/pdf/2507.12098", "abs": "https://arxiv.org/abs/2507.12098", "authors": ["Xiang Li", "Yifan Lin", "Yuanzhe Zhang"], "title": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "To mitigate privacy leakage and performance issues in personalized\nadvertising, this paper proposes a framework that integrates federated learning\nand differential privacy. The system combines distributed feature extraction,\ndynamic privacy budget allocation, and robust model aggregation to balance\nmodel accuracy, communication overhead, and privacy protection. Multi-party\nsecure computing and anomaly detection mechanisms further enhance system\nresilience against malicious attacks. Experimental results demonstrate that the\nframework achieves dual optimization of recommendation accuracy and system\nefficiency while ensuring privacy, providing both a practical solution and a\ntheoretical foundation for applying privacy protection technologies in\nadvertisement recommendation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u548c\u5dee\u5206\u9690\u79c1\u7684\u6846\u67b6\u89e3\u51b3\u4e2a\u6027\u5316\u5e7f\u544a\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u5b9e\u73b0\u63a8\u8350\u51c6\u786e\u6027\u548c\u7cfb\u7edf\u6548\u7387\u7684\u53cc\u91cd\u4f18\u5316\u5e76\u786e\u4fdd\u9690\u79c1\u3002", "motivation": "\u7f13\u89e3\u4e2a\u6027\u5316\u5e7f\u544a\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u548c\u6027\u80fd\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u8054\u90a6\u5b66\u4e60\u548c\u5dee\u5206\u9690\u79c1\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u7279\u5f81\u63d0\u53d6\u3001\u52a8\u6001\u9690\u79c1\u9884\u7b97\u5206\u914d\u548c\u9c81\u68d2\u6a21\u578b\u805a\u5408\uff0c\u91c7\u7528\u591a\u65b9\u5b89\u5168\u8ba1\u7b97\u548c\u5f02\u5e38\u68c0\u6d4b\u673a\u5236\u3002", "result": "\u6846\u67b6\u5b9e\u73b0\u4e86\u63a8\u8350\u51c6\u786e\u6027\u548c\u7cfb\u7edf\u6548\u7387\u7684\u53cc\u91cd\u4f18\u5316\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u9690\u79c1\u3002", "conclusion": "\u4e3a\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5728\u5e7f\u544a\u63a8\u8350\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u9645\u89e3\u51b3\u65b9\u6848\u548c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.12329", "pdf": "https://arxiv.org/pdf/2507.12329", "abs": "https://arxiv.org/abs/2507.12329", "authors": ["Ziv Aharoni", "Henry D. Pfister"], "title": "Neural Polar Decoders for Deletion Channels", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "comment": null, "summary": "This paper introduces a neural polar decoder (NPD) for deletion channels with\na constant deletion rate. Existing polar decoders for deletion channels exhibit\nhigh computational complexity of $O(N^4)$, where $N$ is the block length. This\nlimits the application of polar codes for deletion channels to\nshort-to-moderate block lengths. In this work, we demonstrate that employing\nNPDs for deletion channels can reduce the computational complexity. First, we\nextend the architecture of the NPD to support deletion channels. Specifically,\nthe NPD architecture consists of four neural networks (NNs), each replicating\nfundamental successive cancellation (SC) decoder operations. To support\ndeletion channels, we change the architecture of only one. The computational\ncomplexity of the NPD is $O(AN\\log N)$, where the parameter $A$ represents a\ncomputational budget determined by the user and is independent of the channel.\nWe evaluate the new extended NPD for deletion channels with deletion rates\n$\\delta\\in\\{0.01, 0.1\\}$ and we verify the NPD with the ground truth given by\nthe trellis decoder by Tal et al. We further show that due to the reduced\ncomplexity of the NPD, we are able to incorporate list decoding and further\nimprove performance. We believe that the extended NPD presented here could have\napplications in future technologies like DNA storage.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.12359", "pdf": "https://arxiv.org/pdf/2507.12359", "abs": "https://arxiv.org/abs/2507.12359", "authors": ["Nikolaos Giakoumoglou", "Tania Stathaki"], "title": "Cluster Contrast for Unsupervised Visual Representation Learning", "categories": ["cs.CV", "cs.AI"], "comment": "ICIP 2025", "summary": "We introduce Cluster Contrast (CueCo), a novel approach to unsupervised\nvisual representation learning that effectively combines the strengths of\ncontrastive learning and clustering methods. Inspired by recent advancements,\nCueCo is designed to simultaneously scatter and align feature representations\nwithin the feature space. This method utilizes two neural networks, a query and\na key, where the key network is updated through a slow-moving average of the\nquery outputs. CueCo employs a contrastive loss to push dissimilar features\napart, enhancing inter-class separation, and a clustering objective to pull\ntogether features of the same cluster, promoting intra-class compactness. Our\nmethod achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on\nCIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18\nbackbone. By integrating contrastive learning with clustering, CueCo sets a new\ndirection for advancing unsupervised visual representation learning.", "AI": {"tldr": "\u63d0\u51faCluster Contrast (CueCo)\u65b9\u6cd5\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u805a\u7c7b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u53d6\u5f97\u597d\u6210\u7ee9\uff0c\u4e3a\u65e0\u76d1\u7763\u89c6\u89c9\u8868\u5f81\u5b66\u4e60\u6307\u660e\u65b0\u65b9\u5411\u3002", "motivation": "\u6709\u6548\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u805a\u7c7b\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u63a8\u52a8\u65e0\u76d1\u7763\u89c6\u89c9\u8868\u5f81\u5b66\u4e60\u53d1\u5c55\u3002", "method": "\u5229\u7528\u67e5\u8be2\u548c\u952e\u4e24\u4e2a\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u5bf9\u6bd4\u635f\u5931\u5206\u79bb\u4e0d\u540c\u7279\u5f81\uff0c\u7528\u805a\u7c7b\u76ee\u6807\u805a\u5408\u76f8\u540c\u7c07\u7279\u5f81\u3002", "result": "\u4f7f\u7528ResNet - 18\u9aa8\u5e72\u7f51\u7edc\u8fdb\u884c\u7ebf\u6027\u8bc4\u4f30\uff0c\u5728CIFAR - 10\u3001CIFAR - 100\u548cImageNet - 100\u4e0a\u5206\u522b\u8fbe\u523091.40%\u300168.56%\u548c78.65%\u7684top - 1\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u5c06\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u805a\u7c7b\u7ed3\u5408\uff0c\u4e3a\u65e0\u76d1\u7763\u89c6\u89c9\u8868\u5f81\u5b66\u4e60\u5f00\u521b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.12126", "pdf": "https://arxiv.org/pdf/2507.12126", "abs": "https://arxiv.org/abs/2507.12126", "authors": ["Payal Bhattad", "Sai Manoj Pudukotai Dinakarrao", "Anju Gupta"], "title": "Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Text data augmentation is a widely used strategy for mitigating data sparsity\nin natural language processing (NLP), particularly in low-resource settings\nwhere limited samples hinder effective semantic modeling. While augmentation\ncan improve input diversity and downstream interpretability, existing\ntechniques often lack mechanisms to ensure semantic preservation during\nlarge-scale or iterative generation, leading to redundancy and instability.\nThis work introduces a principled evaluation framework for large language model\n(LLM) based text augmentation, comprising two components: (1) Scalability\nAnalysis, which measures semantic consistency as augmentation volume increases,\nand (2) Iterative Augmentation with Summarization Refinement (IASR), which\nevaluates semantic drift across recursive paraphrasing cycles. Empirical\nevaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the\nbest balance of semantic fidelity, diversity, and generation efficiency.\nApplied to a real-world topic modeling task using BERTopic with GPT-enhanced\nfew-shot labeling, the proposed approach results in a 400% increase in topic\ngranularity and complete elimination of topic overlaps. These findings\nvalidated the utility of the proposed frameworks for structured evaluation of\nLLM-based augmentation in practical NLP pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u589e\u5f3a\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30\u53d1\u73b0GPT - 3.5 Turbo\u8868\u73b0\u6700\u4f73\uff0c\u5e94\u7528\u4e8e\u5b9e\u9645\u4efb\u52a1\u6548\u679c\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u6570\u636e\u589e\u5f3a\u6280\u672f\u5728\u5927\u89c4\u6a21\u6216\u8fed\u4ee3\u751f\u6210\u65f6\u7f3a\u4e4f\u8bed\u4e49\u4fdd\u5b58\u673a\u5236\uff0c\u5bfc\u81f4\u5197\u4f59\u548c\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u53ef\u6269\u5c55\u6027\u5206\u6790\u548c\u8fed\u4ee3\u589e\u5f3a\u4e0e\u6458\u8981\u7ec6\u5316\u4e24\u90e8\u5206\u3002", "result": "GPT - 3.5 Turbo\u5728\u8bed\u4e49\u4fdd\u771f\u3001\u591a\u6837\u6027\u548c\u751f\u6210\u6548\u7387\u4e0a\u8fbe\u5230\u6700\u4f73\u5e73\u8861\uff0c\u5e94\u7528\u4e8e\u5b9e\u9645\u4efb\u52a1\u4f7f\u4e3b\u9898\u7c92\u5ea6\u63d0\u5347400%\uff0c\u6d88\u9664\u4e3b\u9898\u91cd\u53e0\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u589e\u5f3a\u7ed3\u6784\u5316\u8bc4\u4f30\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.12366", "pdf": "https://arxiv.org/pdf/2507.12366", "abs": "https://arxiv.org/abs/2507.12366", "authors": ["Yifei Zhou", "Xuchu Huang", "Chenyu Ni", "Min Zhou", "Zheyu Yan", "Xunzhao Yin", "Cheng Zhuo"], "title": "FactorHD: A Hyperdimensional Computing Model for Multi-Object Multi-Class Representation and Factorization", "categories": ["cs.SC", "cs.AI", "cs.CV"], "comment": "7 pages, 5 figures, 2 tables, to be published in the 62nd DAC (Design\n  Automation Conference) proceedings", "summary": "Neuro-symbolic artificial intelligence (neuro-symbolic AI) excels in logical\nanalysis and reasoning. Hyperdimensional Computing (HDC), a promising\nbrain-inspired computational model, is integral to neuro-symbolic AI. Various\nHDC models have been proposed to represent class-instance and class-class\nrelations, but when representing the more complex class-subclass relation,\nwhere multiple objects associate different levels of classes and subclasses,\nthey face challenges for factorization, a crucial task for neuro-symbolic AI\nsystems. In this article, we propose FactorHD, a novel HDC model capable of\nrepresenting and factorizing the complex class-subclass relation efficiently.\nFactorHD features a symbolic encoding method that embeds an extra memorization\nclause, preserving more information for multiple objects. In addition, it\nemploys an efficient factorization algorithm that selectively eliminates\nredundant classes by identifying the memorization clause of the target class.\nSuch model significantly enhances computing efficiency and accuracy in\nrepresenting and factorizing multiple objects with class-subclass relation,\novercoming limitations of existing HDC models such as \"superposition\ncatastrophe\" and \"the problem of 2\". Evaluations show that FactorHD achieves\napproximately 5667x speedup at a representation size of 10^9 compared to\nexisting HDC models. When integrated with the ResNet-18 neural network,\nFactorHD achieves 92.48% factorization accuracy on the Cifar-10 dataset.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFactorHD\u6a21\u578b\uff0c\u80fd\u9ad8\u6548\u8868\u793a\u548c\u5206\u89e3\u590d\u6742\u7684\u7c7b - \u5b50\u7c7b\u5173\u7cfb\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u8bc4\u4f30\u663e\u793a\u6709\u901f\u5ea6\u63d0\u5347\u548c\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709HDC\u6a21\u578b\u5728\u8868\u793a\u590d\u6742\u7684\u7c7b - \u5b50\u7c7b\u5173\u7cfb\u65f6\u9762\u4e34\u5206\u89e3\u6311\u6218\uff0c\u65e0\u6cd5\u6ee1\u8db3\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u9700\u6c42\u3002", "method": "\u63d0\u51faFactorHD\u6a21\u578b\uff0c\u91c7\u7528\u7b26\u53f7\u7f16\u7801\u65b9\u6cd5\u5d4c\u5165\u989d\u5916\u8bb0\u5fc6\u5b50\u53e5\uff0c\u8fd0\u7528\u9ad8\u6548\u5206\u89e3\u7b97\u6cd5\u9009\u62e9\u6027\u6d88\u9664\u5197\u4f59\u7c7b\u3002", "result": "\u5728\u8868\u793a\u5927\u5c0f\u4e3a10^9\u65f6\uff0c\u6bd4\u73b0\u6709HDC\u6a21\u578b\u63d0\u901f\u7ea65667\u500d\uff1b\u4e0eResNet - 18\u96c6\u6210\u65f6\uff0c\u5728Cifar - 10\u6570\u636e\u96c6\u4e0a\u5206\u89e3\u51c6\u786e\u7387\u8fbe92.48%\u3002", "conclusion": "FactorHD\u6a21\u578b\u514b\u670d\u4e86\u73b0\u6709HDC\u6a21\u578b\u7684\u5c40\u9650\uff0c\u5728\u8868\u793a\u548c\u5206\u89e3\u7c7b - \u5b50\u7c7b\u5173\u7cfb\u4e0a\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.12138", "pdf": "https://arxiv.org/pdf/2507.12138", "abs": "https://arxiv.org/abs/2507.12138", "authors": ["Michal Heker", "Sefy Kararlitsky", "David Tolpin"], "title": "Neural Human Pose Prior", "categories": ["cs.CV", "cs.LG"], "comment": "Work in progress", "summary": "We introduce a principled, data-driven approach for modeling a neural prior\nover human body poses using normalizing flows. Unlike heuristic or\nlow-expressivity alternatives, our method leverages RealNVP to learn a flexible\ndensity over poses represented in the 6D rotation format. We address the\nchallenge of modeling distributions on the manifold of valid 6D rotations by\ninverting the Gram-Schmidt process during training, enabling stable learning\nwhile preserving downstream compatibility with rotation-based frameworks. Our\narchitecture and training pipeline are framework-agnostic and easily\nreproducible. We demonstrate the effectiveness of the learned prior through\nboth qualitative and quantitative evaluations, and we analyze its impact via\nablation studies. This work provides a sound probabilistic foundation for\nintegrating pose priors into human motion capture and reconstruction pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5f52\u4e00\u5316\u6d41\u5bf9\u4eba\u4f53\u59ff\u6001\u7684\u795e\u7ecf\u5148\u9a8c\u8fdb\u884c\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u4e3a\u59ff\u6001\u5148\u9a8c\u878d\u5165\u4eba\u4f53\u8fd0\u52a8\u6355\u6349\u548c\u91cd\u5efa\u63d0\u4f9b\u6982\u7387\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\u6216\u4f4e\u8868\u8fbe\u6027\uff0c\u9700\u4e00\u79cd\u66f4\u597d\u7684\u5bf9\u4eba\u4f53\u59ff\u6001\u795e\u7ecf\u5148\u9a8c\u5efa\u6a21\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528RealNVP\u5bf96D\u65cb\u8f6c\u683c\u5f0f\u8868\u793a\u7684\u59ff\u6001\u5b66\u4e60\u7075\u6d3b\u5bc6\u5ea6\uff0c\u8bad\u7ec3\u65f6\u53cd\u8f6cGram - Schmidt\u8fc7\u7a0b\u5904\u7406\u6709\u65486D\u65cb\u8f6c\u6d41\u5f62\u5206\u5e03\u5efa\u6a21\u6311\u6218\u3002", "result": "\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u8bc1\u660e\u4e86\u5b66\u4e60\u5230\u7684\u5148\u9a8c\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u5206\u6790\u5176\u5f71\u54cd\u3002", "conclusion": "\u4e3a\u5c06\u59ff\u6001\u5148\u9a8c\u878d\u5165\u4eba\u4f53\u8fd0\u52a8\u6355\u6349\u548c\u91cd\u5efa\u7ba1\u9053\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6982\u7387\u57fa\u7840\u3002"}}
{"id": "2507.12175", "pdf": "https://arxiv.org/pdf/2507.12175", "abs": "https://arxiv.org/abs/2507.12175", "authors": ["Sungkyun Chang", "Simon Dixon", "Emmanouil Benetos"], "title": "RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "comment": "Accepted to WASPAA 2025", "summary": "This study introduces RUMAA, a transformer-based framework for music\nperformance analysis that unifies score-to-performance alignment,\nscore-informed transcription, and mistake detection in a near end-to-end\nmanner. Unlike prior methods addressing these tasks separately, RUMAA\nintegrates them using pre-trained score and audio encoders and a novel\ntri-stream decoder capturing task interdependencies through proxy tasks. It\naligns human-readable MusicXML scores with repeat symbols to full-length\nperformance audio, overcoming traditional MIDI-based methods that rely on\nmanually unfolded score-MIDI data with pre-specified repeat structures. RUMAA\nmatches state-of-the-art alignment methods on non-repeated scores and\noutperforms them on scores with repeats in a public piano music dataset, while\nalso delivering promising transcription and mistake detection results.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8eTransformer\u7684\u97f3\u4e50\u8868\u6f14\u5206\u6790\u6846\u67b6RUMAA\uff0c\u8fd1\u7aef\u5230\u7aef\u7edf\u4e00\u591a\u9879\u4efb\u52a1\uff0c\u6027\u80fd\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4ee5\u5f80\u65b9\u6cd5\u5206\u522b\u5904\u7406\u97f3\u4e50\u8868\u6f14\u5206\u6790\u4efb\u52a1\uff0c\u9700\u7edf\u4e00\u65b9\u6cd5\uff1b\u4f20\u7edfMIDI\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u4e50\u8c31\u548c\u97f3\u9891\u7f16\u7801\u5668\u53ca\u65b0\u9896\u7684\u4e09\u6d41\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u4ee3\u7406\u4efb\u52a1\u6355\u83b7\u4efb\u52a1\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u975e\u91cd\u590d\u4e50\u8c31\u4e0a\u4e0e\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u6709\u91cd\u590d\u7684\u4e50\u8c31\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u8f6c\u5f55\u548c\u9519\u8bef\u68c0\u6d4b\u7ed3\u679c\u4e5f\u4e0d\u9519\u3002", "conclusion": "RUMAA\u80fd\u6709\u6548\u7edf\u4e00\u97f3\u4e50\u8868\u6f14\u5206\u6790\u7684\u591a\u9879\u4efb\u52a1\uff0c\u6027\u80fd\u826f\u597d\u3002"}}
{"id": "2507.12379", "pdf": "https://arxiv.org/pdf/2507.12379", "abs": "https://arxiv.org/abs/2507.12379", "authors": ["Yucheng Sun", "Alessandro Stolfo", "Mrinmaya Sachan"], "title": "Probing for Arithmetic Errors in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We investigate whether internal activations in language models can be used to\ndetect arithmetic errors. Starting with a controlled setting of 3-digit\naddition, we show that simple probes can accurately decode both the model's\npredicted output and the correct answer from hidden states, regardless of\nwhether the model's output is correct. Building on this, we train lightweight\nerror detectors that predict model correctness with over 90% accuracy. We then\nextend our analysis to structured chain-of-thought traces on addition-only\nGSM8K problems and find that probes trained on simple arithmetic generalize\nwell to this more complex setting, revealing consistent internal\nrepresentations. Finally, we demonstrate that these probes can guide selective\nre-prompting of erroneous reasoning steps, improving task accuracy with minimal\ndisruption to correct outputs. Our findings suggest that arithmetic errors can\nbe anticipated from internal activations alone, and that simple probes offer a\nviable path toward lightweight model self-correction.", "AI": {"tldr": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\u80fd\u5426\u68c0\u6d4b\u7b97\u672f\u9519\u8bef\uff0c\u53d1\u73b0\u53ef\u4ece\u9690\u85cf\u72b6\u6001\u89e3\u7801\u8f93\u51fa\u4e0e\u6b63\u786e\u7b54\u6848\uff0c\u8bad\u7ec3\u7684\u63a2\u6d4b\u5668\u51c6\u786e\u7387\u8d8590%\uff0c\u80fd\u63a8\u5e7f\u5230\u590d\u6742\u573a\u666f\u5e76\u6307\u5bfc\u91cd\u63d0\u793a\u7ea0\u9519\u3002", "motivation": "\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\u662f\u5426\u53ef\u7528\u4e8e\u68c0\u6d4b\u7b97\u672f\u9519\u8bef\u3002", "method": "\u4ece3\u4f4d\u6570\u52a0\u6cd5\u7684\u53d7\u63a7\u8bbe\u7f6e\u5f00\u59cb\uff0c\u8bad\u7ec3\u7b80\u5355\u63a2\u6d4b\u5668\uff1b\u5c06\u5206\u6790\u6269\u5c55\u5230GSM8K\u4ec5\u52a0\u6cd5\u95ee\u9898\u7684\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u8f68\u8ff9\uff1b\u5229\u7528\u63a2\u6d4b\u5668\u6307\u5bfc\u9009\u62e9\u6027\u91cd\u63d0\u793a\u3002", "result": "\u7b80\u5355\u63a2\u6d4b\u5668\u80fd\u51c6\u786e\u89e3\u7801\u8f93\u51fa\u548c\u6b63\u786e\u7b54\u6848\uff0c\u9884\u6d4b\u6a21\u578b\u6b63\u786e\u6027\u51c6\u786e\u7387\u8d8590%\uff0c\u7b80\u5355\u7b97\u672f\u8bad\u7ec3\u7684\u63a2\u6d4b\u5668\u80fd\u5f88\u597d\u63a8\u5e7f\u5230\u590d\u6742\u573a\u666f\uff0c\u53ef\u6307\u5bfc\u91cd\u63d0\u793a\u63d0\u9ad8\u4efb\u52a1\u51c6\u786e\u7387\u3002", "conclusion": "\u4ec5\u4ece\u5185\u90e8\u6fc0\u6d3b\u5c31\u80fd\u9884\u5224\u7b97\u672f\u9519\u8bef\uff0c\u7b80\u5355\u63a2\u6d4b\u5668\u4e3a\u8f7b\u91cf\u7ea7\u6a21\u578b\u81ea\u6211\u7ea0\u9519\u63d0\u4f9b\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2507.12414", "pdf": "https://arxiv.org/pdf/2507.12414", "abs": "https://arxiv.org/abs/2507.12414", "authors": ["Santosh Vasa", "Aditi Ramadwar", "Jnana Rama Krishna Darabattula", "Md Zafar Anwar", "Stanislaw Antol", "Andrei Vatavu", "Thomas Monninger", "Sihao Ding"], "title": "AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "Training of autonomous driving systems requires extensive datasets with\nprecise annotations to attain robust performance. Human annotations suffer from\nimperfections, and multiple iterations are often needed to produce high-quality\ndatasets. However, manually reviewing large datasets is laborious and\nexpensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)\nframework and investigate the utilization of Vision-Language Models (VLMs) to\nautomatically identify erroneous annotations in vision datasets, thereby\nenabling users to eliminate these errors and enhance data quality. We validate\nour approach using the KITTI and nuImages datasets, which contain object\ndetection benchmarks for autonomous driving. To test the effectiveness of\nAutoVDC, we create dataset variants with intentionally injected erroneous\nannotations and observe the error detection rate of our approach. Additionally,\nwe compare the detection rates using different VLMs and explore the impact of\nVLM fine-tuning on our pipeline. The results demonstrate our method's high\nperformance in error detection and data cleaning experiments, indicating its\npotential to significantly improve the reliability and accuracy of large-scale\nproduction datasets in autonomous driving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAutoVDC\u6846\u67b6\uff0c\u5229\u7528VLMs\u81ea\u52a8\u8bc6\u522b\u89c6\u89c9\u6570\u636e\u96c6\u4e2d\u9519\u8bef\u6807\u6ce8\uff0c\u5728KITTI\u548cnuImages\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u65b9\u6cd5\u5728\u9519\u8bef\u68c0\u6d4b\u548c\u6570\u636e\u6e05\u7406\u5b9e\u9a8c\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u8bad\u7ec3\u9700\u7cbe\u786e\u6807\u6ce8\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u4eba\u5de5\u6807\u6ce8\u6709\u7f3a\u9677\u4e14\u5ba1\u67e5\u6210\u672c\u9ad8\uff0c\u9700\u81ea\u52a8\u6e05\u7406\u6570\u636e\u65b9\u6cd5\u3002", "method": "\u5f15\u5165AutoVDC\u6846\u67b6\uff0c\u5229\u7528VLMs\u81ea\u52a8\u8bc6\u522b\u89c6\u89c9\u6570\u636e\u96c6\u4e2d\u9519\u8bef\u6807\u6ce8\uff0c\u5728KITTI\u548cnuImages\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u521b\u5efa\u542b\u6ce8\u5165\u9519\u8bef\u6807\u6ce8\u7684\u6570\u636e\u96c6\u53d8\u4f53\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e0d\u540cVLMs\u68c0\u6d4b\u7387\uff0c\u63a2\u7d22VLM\u5fae\u8c03\u5f71\u54cd\u3002", "result": "\u65b9\u6cd5\u5728\u9519\u8bef\u68c0\u6d4b\u548c\u6570\u636e\u6e05\u7406\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u9ad8\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u663e\u8457\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u5927\u89c4\u6a21\u751f\u4ea7\u6570\u636e\u96c6\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.12416", "pdf": "https://arxiv.org/pdf/2507.12416", "abs": "https://arxiv.org/abs/2507.12416", "authors": ["Jaehyun Kwak", "Ramahdani Muhammad Izaaz Inhar", "Se-Young Yun", "Sung-Ju Lee"], "title": "QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "Composed Image Retrieval (CIR) retrieves relevant images based on a reference\nimage and accompanying text describing desired modifications. However, existing\nCIR methods only focus on retrieving the target image and disregard the\nrelevance of other images. This limitation arises because most methods\nemploying contrastive learning-which treats the target image as positive and\nall other images in the batch as negatives-can inadvertently include false\nnegatives. This may result in retrieving irrelevant images, reducing user\nsatisfaction even when the target image is retrieved. To address this issue, we\npropose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which\noptimizes a reward model objective to reduce false negatives. Additionally, we\nintroduce a hard negative sampling strategy that selects images positioned\nbetween two steep drops in relevance scores following the target image, to\neffectively filter false negatives. In order to evaluate CIR models on their\nalignment with human satisfaction, we create Human-Preference FashionIQ\n(HP-FashionIQ), a new dataset that explicitly captures user preferences beyond\ntarget retrieval. Extensive experiments demonstrate that QuRe achieves\nstate-of-the-art performance on FashionIQ and CIRR datasets while exhibiting\nthe strongest alignment with human preferences on the HP-FashionIQ dataset. The\nsource code is available at https://github.com/jackwaky/QuRe.", "AI": {"tldr": "\u63d0\u51faQuRe\u65b9\u6cd5\u89e3\u51b3CIR\u65b9\u6cd5\u5b58\u5728\u7684\u5047\u8d1f\u6837\u672c\u95ee\u9898\uff0c\u521b\u5efaHP - FashionIQ\u6570\u636e\u96c6\u8bc4\u4f30\u6a21\u578b\uff0c\u5b9e\u9a8c\u663e\u793aQuRe\u6027\u80fd\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709CIR\u65b9\u6cd5\u53ea\u5173\u6ce8\u76ee\u6807\u56fe\u50cf\u68c0\u7d22\uff0c\u5ffd\u89c6\u5176\u4ed6\u56fe\u50cf\u76f8\u5173\u6027\uff0c\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u6613\u5f15\u5165\u5047\u8d1f\u6837\u672c\uff0c\u5bfc\u81f4\u68c0\u7d22\u5230\u4e0d\u76f8\u5173\u56fe\u50cf\uff0c\u964d\u4f4e\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "method": "\u63d0\u51faQuery - Relevant Retrieval through Hard Negative Sampling (QuRe)\u4f18\u5316\u5956\u52b1\u6a21\u578b\u76ee\u6807\u4ee5\u51cf\u5c11\u5047\u8d1f\u6837\u672c\uff0c\u5f15\u5165\u786c\u8d1f\u91c7\u6837\u7b56\u7565\u8fc7\u6ee4\u5047\u8d1f\u6837\u672c\uff0c\u521b\u5efaHuman - Preference FashionIQ (HP - FashionIQ)\u6570\u636e\u96c6\u8bc4\u4f30CIR\u6a21\u578b\u4e0e\u4eba\u7c7b\u6ee1\u610f\u5ea6\u7684\u4e00\u81f4\u6027\u3002", "result": "QuRe\u5728FashionIQ\u548cCIRR\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728HP - FashionIQ\u6570\u636e\u96c6\u4e0a\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u4e00\u81f4\u6027\u6700\u5f3a\u3002", "conclusion": "QuRe\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709CIR\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.12248", "pdf": "https://arxiv.org/pdf/2507.12248", "abs": "https://arxiv.org/abs/2507.12248", "authors": ["Anida Nezovi\u0107", "Jalal Romano", "Nada Mari\u0107", "Medina Kapo", "Amila Akagi\u0107"], "title": "Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Deep learning has significantly advanced the field of medical image\nclassification, particularly with the adoption of Convolutional Neural Networks\n(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer\nunique advantages in model development and deployment. However, their\ncomparative performance in medical imaging tasks remains underexplored. This\nstudy presents a comprehensive analysis of CNN implementations across these\nframeworks, using the PathMNIST dataset as a benchmark. We evaluate training\nefficiency, classification accuracy and inference speed to assess their\nsuitability for real-world applications. Our findings highlight the trade-offs\nbetween computational speed and model accuracy, offering valuable insights for\nresearchers and practitioners in medical image analysis.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4Keras\u3001PyTorch\u548cJAX\u6846\u67b6\u5728\u533b\u5b66\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2dCNN\u5b9e\u73b0\u7684\u6027\u80fd\uff0c\u7528PathMNIST\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u53d1\u73b0\u8ba1\u7b97\u901f\u5ea6\u548c\u6a21\u578b\u7cbe\u5ea6\u7684\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5728\u533b\u5b66\u6210\u50cf\u4efb\u52a1\u4e2d\u7684\u6bd4\u8f83\u6027\u80fd\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528PathMNIST\u6570\u636e\u96c6\uff0c\u5bf9\u4e09\u4e2a\u6846\u67b6\u7684CNN\u5b9e\u73b0\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u8bc4\u4f30\u8bad\u7ec3\u6548\u7387\u3001\u5206\u7c7b\u51c6\u786e\u6027\u548c\u63a8\u7406\u901f\u5ea6\u3002", "result": "\u53d1\u73b0\u8ba1\u7b97\u901f\u5ea6\u548c\u6a21\u578b\u7cbe\u5ea6\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u4e3a\u533b\u5b66\u56fe\u50cf\u5206\u6790\u7684\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.12256", "pdf": "https://arxiv.org/pdf/2507.12256", "abs": "https://arxiv.org/abs/2507.12256", "authors": ["Monica L\u0103c\u0103tu\u015f", "Matthias M\u00f6ller"], "title": "Surrogate Quantum Circuit Design for the Lattice Boltzmann Collision Operator", "categories": ["quant-ph", "cs.LG", "physics.comp-ph"], "comment": "31 pages, 14 figures", "summary": "Direct numerical simulation of turbulent flows at high Reynolds numbers\nremains a major challenge for traditional computational fluid dynamics (CFD)\ntools running on classical computer hardware. This has motivated growing\ninterest in quantum algorithms for CFD to enable flow simulations on quantum\ncomputers. The reason being that these computers are expected to deliver\npotential speed-ups for certain problems. One promising quantum CFD approach is\na fully quantum implementation of the lattice Boltzmann method called QLBM.\nAlthough efficient quantum routines are now available for the streaming step,\nimplementing the nonlinear, irreversible collision step with a low depth\ncircuit that avoids additional ancilla qubits, probabilistic post-selection and\nrepeated executions remains a significant challenge. In this study, we address\nthis challenge by introducing a framework for learning a surrogate quantum\ncircuit (SQC) that approximates the full Bhatnagar Gross Krook (BGK) collision\noperator for the D2Q9 lattice. The four qubit circuit is trained to respect the\nphysical properties of the BGK collision operator, including mass and momentum\nconservation, D8 equivariance and scale equivariance. When compiled to the gate\nset used by IBM Heron processor under the assumption of full qubit\nconnectivity, the 15 block SQC requires only 2,430 native gates and uses\nneither ancilla qubits nor post-selection or repeated executions. Moreover, its\ndepth is independent of the grid resolution, as collision is a local operation\nthat can exploit quantum parallelism to its full extent. We validate the SQC on\ntwo benchmark flows, the Taylor Green vortex decay and the lid driven cavity,\ndemonstrating that it accurately captures vortex dissipation and flow\nrecirculation.", "AI": {"tldr": "\u4f20\u7edfCFD\u5de5\u5177\u5728\u9ad8\u96f7\u8bfa\u6570\u6e4d\u6d41\u76f4\u63a5\u6570\u503c\u6a21\u62df\u6709\u6311\u6218\uff0c\u91cf\u5b50\u7b97\u6cd5\u53d7\u5173\u6ce8\uff0cQLBM\u7684\u78b0\u649e\u6b65\u9aa4\u5b9e\u73b0\u6709\u96be\u9898\uff0c\u672c\u6587\u63d0\u51fa\u5b66\u4e60\u66ff\u4ee3\u91cf\u5b50\u7535\u8def\u6846\u67b6\u89e3\u51b3\u8be5\u95ee\u9898\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfCFD\u5de5\u5177\u5728\u9ad8\u96f7\u8bfa\u6570\u6e4d\u6d41\u6a21\u62df\u6709\u6311\u6218\uff0c\u91cf\u5b50\u8ba1\u7b97\u673a\u6709\u671b\u52a0\u901f\u8ba1\u7b97\uff0cQLBM\u7684\u78b0\u649e\u6b65\u9aa4\u5b9e\u73b0\u5b58\u5728\u56f0\u96be\u3002", "method": "\u5f15\u5165\u5b66\u4e60\u66ff\u4ee3\u91cf\u5b50\u7535\u8def\uff08SQC\uff09\u7684\u6846\u67b6\uff0c\u8bad\u7ec3\u56db\u91cf\u5b50\u6bd4\u7279\u7535\u8def\u4f7f\u5176\u7b26\u5408BGK\u78b0\u649e\u7b97\u5b50\u7269\u7406\u7279\u6027\uff0c\u7f16\u8bd1\u5230IBM Heron\u5904\u7406\u5668\u95e8\u96c6\u3002", "result": "15\u5757SQC\u53ea\u97002430\u4e2a\u539f\u751f\u95e8\uff0c\u65e0\u9700\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u3001\u540e\u9009\u62e9\u6216\u91cd\u590d\u6267\u884c\uff0c\u6df1\u5ea6\u4e0e\u7f51\u683c\u5206\u8fa8\u7387\u65e0\u5173\u3002", "conclusion": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6d41\u9a8c\u8bc1SQC\uff0c\u8bc1\u660e\u5176\u80fd\u51c6\u786e\u6355\u6349\u6da1\u65cb\u8017\u6563\u548c\u6d41\u52a8\u518d\u5faa\u73af\u3002"}}
{"id": "2507.12427", "pdf": "https://arxiv.org/pdf/2507.12427", "abs": "https://arxiv.org/abs/2507.12427", "authors": ["Ashkan Shakarami", "Azade Farshad", "Yousef Yeganeh", "Lorenzo Nicole", "Peter Schuffler", "Stefano Ghidoni", "Nassir Navab"], "title": "Unit-Based Histopathology Tissue Segmentation via Multi-Level Feature Representation", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "12 pages, 6 figures", "summary": "We propose UTS, a unit-based tissue segmentation framework for histopathology\nthat classifies each fixed-size 32 * 32 tile, rather than each pixel, as the\nsegmentation unit. This approach reduces annotation effort and improves\ncomputational efficiency without compromising accuracy. To implement this\napproach, we introduce a Multi-Level Vision Transformer (L-ViT), which benefits\nthe multi-level feature representation to capture both fine-grained morphology\nand global tissue context. Trained to segment breast tissue into three\ncategories (infiltrating tumor, non-neoplastic stroma, and fat), UTS supports\nclinically relevant tasks such as tumor-stroma quantification and surgical\nmargin assessment. Evaluated on 386,371 tiles from 459 H&E-stained regions, it\noutperforms U-Net variants and transformer-based baselines. Code and Dataset\nwill be available at GitHub.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5355\u5143\u7684\u7ec4\u7ec7\u5206\u5272\u6846\u67b6UTS\uff0c\u4ee532*32\u56fe\u5757\u4e3a\u5206\u5272\u5355\u5143\uff0c\u5f15\u5165L - ViT\uff0c\u5728\u4e73\u817a\u7ec4\u7ec7\u5206\u5272\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u51cf\u5c11\u7ec4\u7ec7\u75c5\u7406\u5b66\u5206\u5272\u7684\u6807\u6ce8\u5de5\u4f5c\u91cf\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u652f\u6301\u4e34\u5e8a\u76f8\u5173\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4ee532*32\u56fe\u5757\u4e3a\u5206\u5272\u5355\u5143\u7684UTS\u6846\u67b6\uff0c\u5f15\u5165Multi - Level Vision Transformer (L - ViT) \u8fdb\u884c\u591a\u7ea7\u522b\u7279\u5f81\u8868\u793a\u3002", "result": "\u5728459\u4e2aH&E\u67d3\u8272\u533a\u57df\u7684386,371\u4e2a\u56fe\u5757\u4e0a\u8bc4\u4f30\uff0c\u4f18\u4e8eU - Net\u53d8\u4f53\u548c\u57fa\u4e8eTransformer\u7684\u57fa\u7ebf\u3002", "conclusion": "UTS\u6846\u67b6\u6709\u6548\uff0c\u53ef\u51cf\u5c11\u6807\u6ce8\u5de5\u4f5c\u91cf\u3001\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u6027\uff0c\u80fd\u652f\u6301\u4e34\u5e8a\u4efb\u52a1\u3002"}}
{"id": "2507.12428", "pdf": "https://arxiv.org/pdf/2507.12428", "abs": "https://arxiv.org/abs/2507.12428", "authors": ["Yik Siu Chan", "Zheng-Xin Yong", "Stephen H. Bach"], "title": "Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Open-weights reasoning language models generate long chains-of-thought (CoTs)\nbefore producing a final response, which improves performance but introduces\nadditional alignment risks, with harmful content often appearing in both the\nCoTs and the final outputs. In this work, we investigate if we can use CoTs to\npredict final response misalignment. We evaluate a range of monitoring\napproaches, including humans, highly-capable large language models, and text\nclassifiers, using either CoT text or activations. First, we find that a simple\nlinear probe trained on CoT activations can significantly outperform all\ntext-based methods in predicting whether a final response will be safe or\nunsafe. CoT texts are often unfaithful and can mislead humans and classifiers,\nwhile model latents (i.e., CoT activations) offer a more reliable predictive\nsignal. Second, the probe makes accurate predictions before reasoning\ncompletes, achieving strong performance even when applied to early CoT\nsegments. These findings generalize across model sizes, families, and safety\nbenchmarks, suggesting that lightweight probes could enable real-time safety\nmonitoring and early intervention during generation.", "AI": {"tldr": "\u7814\u7a76\u7528\u601d\u7ef4\u94fe\u9884\u6d4b\u6700\u7ec8\u56de\u590d\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u53d1\u73b0\u57fa\u4e8e\u601d\u7ef4\u94fe\u6fc0\u6d3b\u7684\u7ebf\u6027\u63a2\u9488\u9884\u6d4b\u6548\u679c\u597d\uff0c\u53ef\u7528\u4e8e\u5b9e\u65f6\u5b89\u5168\u76d1\u63a7\u548c\u65e9\u671f\u5e72\u9884\u3002", "motivation": "\u5f00\u653e\u6743\u91cd\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u751f\u6210\u601d\u7ef4\u94fe\u63d0\u9ad8\u6027\u80fd\u4f46\u5e26\u6765\u989d\u5916\u5bf9\u9f50\u98ce\u9669\uff0c\u7814\u7a76\u80fd\u5426\u7528\u601d\u7ef4\u94fe\u9884\u6d4b\u6700\u7ec8\u56de\u590d\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "method": "\u8bc4\u4f30\u5305\u62ec\u4eba\u7c7b\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6587\u672c\u5206\u7c7b\u5668\u7b49\u5728\u5185\u7684\u591a\u79cd\u76d1\u63a7\u65b9\u6cd5\uff0c\u4f7f\u7528\u601d\u7ef4\u94fe\u6587\u672c\u6216\u6fc0\u6d3b\u3002", "result": "\u57fa\u4e8e\u601d\u7ef4\u94fe\u6fc0\u6d3b\u8bad\u7ec3\u7684\u7b80\u5355\u7ebf\u6027\u63a2\u9488\u5728\u9884\u6d4b\u6700\u7ec8\u56de\u590d\u5b89\u5168\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u5b8c\u6210\u524d\u5c31\u80fd\u51c6\u786e\u9884\u6d4b\uff0c\u4e14\u5728\u65e9\u671f\u601d\u7ef4\u94fe\u7247\u6bb5\u4e0a\u4e5f\u6709\u826f\u597d\u8868\u73b0\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u63a2\u9488\u53ef\u5b9e\u73b0\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u65f6\u5b89\u5168\u76d1\u63a7\u548c\u65e9\u671f\u5e72\u9884\uff0c\u4e14\u7ed3\u679c\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u3001\u5bb6\u65cf\u548c\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5177\u6709\u901a\u7528\u6027\u3002"}}
{"id": "2507.12440", "pdf": "https://arxiv.org/pdf/2507.12440", "abs": "https://arxiv.org/abs/2507.12440", "authors": ["Ruihan Yang", "Qinxi Yu", "Yecheng Wu", "Rui Yan", "Borui Li", "An-Chieh Cheng", "Xueyan Zou", "Yunhao Fang", "Hongxu Yin", "Sifei Liu", "Song Han", "Yao Lu", "Xiaolong Wang"], "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "More videos can be found on our website:\n  https://rchalyang.github.io/EgoVLA", "summary": "Real robot data collection for imitation learning has led to significant\nadvancements in robotic manipulation. However, the requirement for robot\nhardware in the process fundamentally constrains the scale of the data. In this\npaper, we explore training Vision-Language-Action (VLA) models using egocentric\nhuman videos. The benefit of using human videos is not only for their scale but\nmore importantly for the richness of scenes and tasks. With a VLA trained on\nhuman video that predicts human wrist and hand actions, we can perform Inverse\nKinematics and retargeting to convert the human actions to robot actions. We\nfine-tune the model using a few robot manipulation demonstrations to obtain the\nrobot policy, namely EgoVLA. We propose a simulation benchmark called Isaac\nHumanoid Manipulation Benchmark, where we design diverse bimanual manipulation\ntasks with demonstrations. We fine-tune and evaluate EgoVLA with Isaac Humanoid\nManipulation Benchmark and show significant improvements over baselines and\nablate the importance of human data. Videos can be found on our website:\nhttps://rchalyang.github.io/EgoVLA", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u4eba\u7c7b\u89c6\u9891\u8bad\u7ec3VLA\u6a21\u578b\uff0c\u7ecf\u9006\u8fd0\u52a8\u5b66\u8f6c\u6362\u548c\u5fae\u8c03\u5f97\u5230\u673a\u5668\u4eba\u7b56\u7565EgoVLA\uff0c\u5e76\u5728\u65b0\u57fa\u51c6\u4e0a\u8bc4\u4f30\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u6536\u96c6\u53d7\u786c\u4ef6\u9650\u5236\uff0c\u89c4\u6a21\u53d7\u9650\uff0c\u800c\u4eba\u7c7b\u89c6\u9891\u6570\u636e\u89c4\u6a21\u5927\u4e14\u573a\u666f\u548c\u4efb\u52a1\u4e30\u5bcc\u3002", "method": "\u7528\u4eba\u7c7b\u89c6\u9891\u8bad\u7ec3VLA\u6a21\u578b\u9884\u6d4b\u4eba\u7c7b\u624b\u8155\u548c\u624b\u90e8\u52a8\u4f5c\uff0c\u7ecf\u9006\u8fd0\u52a8\u5b66\u548c\u91cd\u5b9a\u5411\u8f6c\u6362\u4e3a\u673a\u5668\u4eba\u52a8\u4f5c\uff0c\u7528\u5c11\u91cf\u673a\u5668\u4eba\u64cd\u4f5c\u6f14\u793a\u5fae\u8c03\u6a21\u578b\u5f97\u5230EgoVLA\uff0c\u63d0\u51faIsaac Humanoid Manipulation Benchmark\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728Isaac Humanoid Manipulation Benchmark\u4e0a\u5bf9EgoVLA\u8fdb\u884c\u5fae\u8c03\u8bc4\u4f30\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\uff0c\u4e14\u8bc1\u660e\u4e86\u4eba\u7c7b\u6570\u636e\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u5229\u7528\u4eba\u7c7b\u89c6\u9891\u8bad\u7ec3\u6a21\u578b\u53ef\u6709\u6548\u89e3\u51b3\u673a\u5668\u4eba\u6570\u636e\u89c4\u6a21\u53d7\u9650\u95ee\u9898\uff0cEgoVLA\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.12442", "pdf": "https://arxiv.org/pdf/2507.12442", "abs": "https://arxiv.org/abs/2507.12442", "authors": ["Saptarshi Mitra", "Rachid Karami", "Haocheng Xu", "Sitao Huang", "Hyoukjun Kwon"], "title": "Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "12 pages, 7 figures", "summary": "The demand for machine intelligence capable of processing continuous,\nlong-context inputs on local devices is growing rapidly. However, the quadratic\ncomplexity and memory requirements of traditional Transformer architectures\nmake them inefficient and often unusable for these tasks. This has spurred a\nparadigm shift towards new architectures like State Space Models (SSMs) and\nhybrids, which promise near-linear scaling. While most current research focuses\non the accuracy and theoretical throughput of these models, a systematic\nperformance characterization on practical consumer hardware is critically\nneeded to guide system-level optimization and unlock new applications.\n  To address this gap, we present a comprehensive, comparative benchmarking of\ncarefully selected Transformer, SSM, and hybrid models specifically for\nlong-context inference on consumer and embedded GPUs. Our analysis reveals that\nSSMs are not only viable but superior for this domain, capable of processing\nsequences up to 220K tokens on a 24GB consumer GPU-approximately 4x longer than\ncomparable Transformers. While Transformers may be up to 1.8x faster at short\nsequences, SSMs demonstrate a dramatic performance inversion, becoming up to 4x\nfaster at very long contexts (~57K tokens). Our operator-level analysis reveals\nthat custom, hardware-aware SSM kernels dominate the inference runtime,\naccounting for over 55% of latency on edge platforms, identifying them as a\nprimary target for future hardware acceleration. We also provide detailed,\ndevice-specific characterization results to guide system co-design for the\nedge. To foster further research, we will open-source our characterization\nframework.", "AI": {"tldr": "\u5bf9Transformer\u3001SSM\u548c\u6df7\u5408\u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u548c\u5d4c\u5165\u5f0fGPU\u4e0a\u8fdb\u884c\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0SSM\u5728\u957f\u4e0a\u4e0b\u6587\u8868\u73b0\u4f18\u8d8a\uff0c\u8fd8\u7ed9\u51fa\u7b97\u5b50\u7ea7\u5206\u6790\u548c\u8bbe\u5907\u7279\u6027\u7ed3\u679c\u5e76\u5c06\u5f00\u6e90\u6846\u67b6\u3002", "motivation": "\u4f20\u7edfTransformer\u67b6\u6784\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\u6548\u7387\u4f4e\uff0c\u5f53\u524d\u7814\u7a76\u7f3a\u4e4f\u5bf9\u65b0\u67b6\u6784\u5728\u5b9e\u9645\u6d88\u8d39\u786c\u4ef6\u4e0a\u7684\u7cfb\u7edf\u6027\u80fd\u8868\u5f81\uff0c\u9700\u4ee5\u6b64\u6307\u5bfc\u7cfb\u7edf\u7ea7\u4f18\u5316\u548c\u5f00\u53d1\u65b0\u5e94\u7528\u3002", "method": "\u5bf9\u7cbe\u5fc3\u6311\u9009\u7684Transformer\u3001SSM\u548c\u6df7\u5408\u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u548c\u5d4c\u5165\u5f0fGPU\u4e0a\u8fdb\u884c\u5168\u9762\u7684\u5bf9\u6bd4\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "SSM\u5728\u957f\u4e0a\u4e0b\u6587\u9886\u57df\u4e0d\u4ec5\u53ef\u884c\u4e14\u4f18\u8d8a\uff0c\u572824GB\u6d88\u8d39\u7ea7GPU\u4e0a\u80fd\u5904\u7406\u8fbe220K\u4ee4\u724c\u5e8f\u5217\uff0c\u7ea6\u4e3a\u53ef\u6bd4Transformer\u76844\u500d\uff1b\u77ed\u5e8f\u5217\u65f6Transformers\u5feb1.8\u500d\uff0c\u957f\u4e0a\u4e0b\u6587\uff08\u7ea657K\u4ee4\u724c\uff09\u65f6SSM\u5feb4\u500d\uff1b\u81ea\u5b9a\u4e49\u786c\u4ef6\u611f\u77e5\u7684SSM\u5185\u6838\u5360\u8fb9\u7f18\u5e73\u53f0\u63a8\u7406\u8fd0\u884c\u65f6\u95f4\u8d8555%\u3002", "conclusion": "SSM\u9002\u5408\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u5176\u81ea\u5b9a\u4e49\u5185\u6838\u662f\u672a\u6765\u786c\u4ef6\u52a0\u901f\u7684\u4e3b\u8981\u76ee\u6807\uff0c\u63d0\u4f9b\u7684\u8bbe\u5907\u7279\u6027\u7ed3\u679c\u53ef\u6307\u5bfc\u8fb9\u7f18\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u3002"}}
{"id": "2507.12404", "pdf": "https://arxiv.org/pdf/2507.12404", "abs": "https://arxiv.org/abs/2507.12404", "authors": ["Yeming Xian", "Xiaoming Wang", "Yanfa Yan"], "title": "Neural Network-Guided Symbolic Regression for Interpretable Descriptor Discovery in Perovskite Catalysts", "categories": ["physics.data-an", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "comment": "31 pages", "summary": "Understanding and predicting the activity of oxide perovskite catalysts for\nthe oxygen evolution reaction (OER) requires descriptors that are both accurate\nand physically interpretable. While symbolic regression (SR) offers a path to\ndiscover such formulas, its performance degrades with high-dimensional inputs\nand small datasets. We present a two-phase framework that combines neural\nnetworks (NN), feature importance analysis, and symbolic regression (SR) to\ndiscover interpretable descriptors for OER activity in oxide perovskites. In\nPhase I, using a small dataset and seven structural features, we reproduce and\nimprove the known {\\mu}/t descriptor by engineering composite features and\napplying symbolic regression, achieving training and validation MAEs of 22.8\nand 20.8 meV, respectively. In Phase II, we expand to 164 features, reduce\ndimensionality, and identify LUMO energy as a key electronic descriptor. A\nfinal formula using {\\mu}/t, {\\mu}/RA, and LUMO energy achieves improved\naccuracy (training and validation MAEs of 22.1 and 20.6 meV) with strong\nphysical interpretability. Our results demonstrate that NN-guided symbolic\nregression enables accurate, interpretable, and physically meaningful\ndescriptor discovery in data-scarce regimes, indicating interpretability need\nnot sacrifice accuracy for materials informatics.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u3001\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u548c\u7b26\u53f7\u56de\u5f52\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u4e3a\u6c27\u5316\u7269\u9499\u949b\u77ff\u7684OER\u6d3b\u6027\u53d1\u73b0\u53ef\u89e3\u91ca\u63cf\u8ff0\u7b26\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u63cf\u8ff0\u7b26\u53d1\u73b0\u3002", "motivation": "\u7406\u89e3\u548c\u9884\u6d4b\u6c27\u5316\u7269\u9499\u949b\u77ff\u50ac\u5316\u5242\u7684OER\u6d3b\u6027\u9700\u8981\u51c6\u786e\u4e14\u53ef\u7269\u7406\u89e3\u91ca\u7684\u63cf\u8ff0\u7b26\uff0c\u800c\u7b26\u53f7\u56de\u5f52\u5728\u9ad8\u7ef4\u8f93\u5165\u548c\u5c0f\u6570\u636e\u96c6\u4e0b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u7528\u5c0f\u6570\u636e\u96c6\u548c\u4e03\u4e2a\u7ed3\u6784\u7279\u5f81\uff0c\u901a\u8fc7\u5de5\u7a0b\u590d\u5408\u7279\u5f81\u548c\u5e94\u7528\u7b26\u53f7\u56de\u5f52\u6539\u8fdb\u5df2\u77e5\u63cf\u8ff0\u7b26\uff1b\u7b2c\u4e8c\u9636\u6bb5\u6269\u5c55\u5230164\u4e2a\u7279\u5f81\uff0c\u964d\u7ef4\u5e76\u786e\u5b9a\u5173\u952e\u7535\u5b50\u63cf\u8ff0\u7b26\u3002", "result": "\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u548c\u9a8c\u8bc1MAE\u5206\u522b\u4e3a22.8\u548c20.8 meV\uff1b\u6700\u7ec8\u516c\u5f0f\u4f7f\u7528\u591a\u4e2a\u63cf\u8ff0\u7b26\uff0c\u8bad\u7ec3\u548c\u9a8c\u8bc1MAE\u5206\u522b\u4e3a22.1\u548c20.6 meV\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u5f15\u5bfc\u7684\u7b26\u53f7\u56de\u5f52\u80fd\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u5b9e\u73b0\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u6709\u7269\u7406\u610f\u4e49\u7684\u63cf\u8ff0\u7b26\u53d1\u73b0\uff0c\u6750\u6599\u4fe1\u606f\u5b66\u4e2d\u53ef\u89e3\u91ca\u6027\u4e0d\u4e00\u5b9a\u8981\u727a\u7272\u51c6\u786e\u6027\u3002"}}
{"id": "2507.12443", "pdf": "https://arxiv.org/pdf/2507.12443", "abs": "https://arxiv.org/abs/2507.12443", "authors": ["Rajdeep Mondal", "Nikolaj Bjorner", "Todd Millstein", "Alan Tang", "George Varghese"], "title": "LLM-Based Config Synthesis requires Disambiguation", "categories": ["cs.NI", "cs.AI", "cs.HC", "cs.PL"], "comment": null, "summary": "Beyond hallucinations, another problem in program synthesis using LLMs is\nambiguity in user intent. We illustrate the ambiguity problem in a networking\ncontext for LLM-based incremental configuration synthesis of route-maps and\nACLs. These structures frequently overlap in header space, making the relative\npriority of actions impossible for the LLM to infer without user interaction.\nMeasurements in a large cloud identify complex ACLs with 100's of overlaps,\nshowing ambiguity is a real problem. We propose a prototype system, Clarify,\nwhich uses an LLM augmented with a new module called a Disambiguator that helps\nelicit user intent. On a small synthetic workload, Clarify incrementally\nsynthesizes routing policies after disambiguation and then verifies them. Our\ntreatment of ambiguities is useful more generally when the intent of updates\ncan be correctly synthesized by LLMs, but their integration is ambiguous and\ncan lead to different global behaviors.", "AI": {"tldr": "\u8bba\u6587\u6307\u51faLLM\u7a0b\u5e8f\u5408\u6210\u4e2d\u7528\u6237\u610f\u56fe\u6a21\u7cca\u95ee\u9898\uff0c\u4ee5\u7f51\u7edc\u914d\u7f6e\u4e3a\u4f8b\u8bf4\u660e\uff0c\u63d0\u51faClarify\u7cfb\u7edf\u89e3\u51b3\u6a21\u7cca\u6027\u5e76\u9a8c\u8bc1\u7b56\u7565\u3002", "motivation": "\u89e3\u51b3LLM\u7a0b\u5e8f\u5408\u6210\u4e2d\u7528\u6237\u610f\u56fe\u6a21\u7cca\u95ee\u9898\uff0c\u4ee5\u7f51\u7edc\u914d\u7f6e\u5408\u6210\u573a\u666f\u4e3a\u4f8b\u3002", "method": "\u63d0\u51faClarify\u539f\u578b\u7cfb\u7edf\uff0c\u4f7f\u7528\u5e26\u6709Disambiguator\u6a21\u5757\u7684LLM\u5f15\u51fa\u7528\u6237\u610f\u56fe\u3002", "result": "\u5728\u5c0f\u7684\u5408\u6210\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0cClarify\u80fd\u5728\u6d88\u9664\u6b67\u4e49\u540e\u589e\u91cf\u5408\u6210\u8def\u7531\u7b56\u7565\u5e76\u9a8c\u8bc1\u3002", "conclusion": "\u5904\u7406\u6a21\u7cca\u6027\u5728LLM\u80fd\u6b63\u786e\u5408\u6210\u66f4\u65b0\u610f\u56fe\u4f46\u96c6\u6210\u6709\u6b67\u4e49\u65f6\u666e\u904d\u6709\u7528\u3002"}}
{"id": "2507.12451", "pdf": "https://arxiv.org/pdf/2507.12451", "abs": "https://arxiv.org/abs/2507.12451", "authors": ["Suman Adhya", "Debarshi Kumar Sanyal"], "title": "S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted as a long paper for ACL 2025 main conference", "summary": "Modeling latent representations in a hyperspherical space has proven\neffective for capturing directional similarities in high-dimensional text data,\nbenefiting topic modeling. Variational autoencoder-based neural topic models\n(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical\nstructure. However, VAE-NTMs often suffer from posterior collapse, where the KL\ndivergence term in the objective function highly diminishes, leading to\nineffective latent representations. To mitigate this issue while modeling\nhyperspherical structure in the latent space, we propose the Spherical Sliced\nWasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior\ndistribution supported on the unit hypersphere and leverages the Spherical\nSliced-Wasserstein distance to align the aggregated posterior distribution with\nthe prior. Experimental results demonstrate that S2WTM outperforms\nstate-of-the-art topic models, generating more coherent and diverse topics\nwhile improving performance on downstream tasks.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u4e3b\u9898\u5efa\u6a21\u7684S2WTM\uff0c\u7f13\u89e3\u540e\u9a8c\u574d\u7f29\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "VAE - NTMs\u5728\u5efa\u6a21\u9ad8\u7ef4\u6587\u672c\u6570\u636e\u6f5c\u5728\u8868\u793a\u65f6\u5b58\u5728\u540e\u9a8c\u574d\u7f29\u95ee\u9898\uff0c\u5bfc\u81f4\u6f5c\u5728\u8868\u793a\u65e0\u6548\u3002", "method": "\u63d0\u51faS2WTM\uff0c\u91c7\u7528\u5355\u4f4d\u8d85\u7403\u9762\u4e0a\u7684\u5148\u9a8c\u5206\u5e03\uff0c\u5229\u7528\u7403\u9762\u5207\u7247Wasserstein\u8ddd\u79bb\u4f7f\u805a\u5408\u540e\u9a8c\u5206\u5e03\u4e0e\u5148\u9a8c\u5bf9\u9f50\u3002", "result": "S2WTM\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u4e3b\u9898\u6a21\u578b\uff0c\u751f\u6210\u7684\u4e3b\u9898\u66f4\u8fde\u8d2f\u3001\u591a\u6837\uff0c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "S2WTM\u80fd\u5728\u5efa\u6a21\u6f5c\u5728\u7a7a\u95f4\u8d85\u7403\u7ed3\u6784\u65f6\u6709\u6548\u7f13\u89e3\u540e\u9a8c\u574d\u7f29\u95ee\u9898\uff0c\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.12461", "pdf": "https://arxiv.org/pdf/2507.12461", "abs": "https://arxiv.org/abs/2507.12461", "authors": ["Trong-Thang Pham", "Anh Nguyen", "Zhigang Deng", "Carol C. Wu", "Hien Van Nguyen", "Ngan Le"], "title": "Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": "ACM MM 2025", "summary": "Radiologists rely on eye movements to navigate and interpret medical images.\nA trained radiologist possesses knowledge about the potential diseases that may\nbe present in the images and, when searching, follows a mental checklist to\nlocate them using their gaze. This is a key observation, yet existing models\nfail to capture the underlying intent behind each fixation. In this paper, we\nintroduce a deep learning-based approach, RadGazeIntent, designed to model this\nbehavior: having an intention to find something and actively searching for it.\nOur transformer-based architecture processes both the temporal and spatial\ndimensions of gaze data, transforming fine-grained fixation features into\ncoarse, meaningful representations of diagnostic intent to interpret\nradiologists' goals. To capture the nuances of radiologists' varied\nintention-driven behaviors, we process existing medical eye-tracking datasets\nto create three intention-labeled subsets: RadSeq (Systematic Sequential\nSearch), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid\nPattern). Experimental results demonstrate RadGazeIntent's ability to predict\nwhich findings radiologists are examining at specific moments, outperforming\nbaseline methods across all intention-labeled datasets.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684RadGazeIntent\u65b9\u6cd5\uff0c\u5904\u7406\u773c\u52a8\u6570\u636e\u4ee5\u9884\u6d4b\u653e\u5c04\u79d1\u533b\u751f\u8bca\u65ad\u610f\u56fe\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u653e\u5c04\u79d1\u533b\u751f\u6bcf\u6b21\u6ce8\u89c6\u80cc\u540e\u7684\u6f5c\u5728\u610f\u56fe\uff0c\u9700\u5efa\u6a21\u5176\u4e3b\u52a8\u641c\u7d22\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u67b6\u6784\u5904\u7406\u773c\u52a8\u6570\u636e\u7684\u65f6\u7a7a\u7ef4\u5ea6\uff0c\u5c06\u6ce8\u89c6\u7279\u5f81\u8f6c\u5316\u4e3a\u8bca\u65ad\u610f\u56fe\u8868\u793a\uff1b\u5904\u7406\u73b0\u6709\u533b\u5b66\u773c\u52a8\u8ffd\u8e2a\u6570\u636e\u96c6\u521b\u5efa\u4e09\u4e2a\u610f\u56fe\u6807\u7b7e\u5b50\u96c6\u3002", "result": "RadGazeIntent\u80fd\u9884\u6d4b\u653e\u5c04\u79d1\u533b\u751f\u5728\u7279\u5b9a\u65f6\u523b\u68c0\u67e5\u7684\u7ed3\u679c\uff0c\u5728\u6240\u6709\u610f\u56fe\u6807\u7b7e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RadGazeIntent\u53ef\u6709\u6548\u9884\u6d4b\u653e\u5c04\u79d1\u533b\u751f\u7684\u8bca\u65ad\u610f\u56fe\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.12441", "pdf": "https://arxiv.org/pdf/2507.12441", "abs": "https://arxiv.org/abs/2507.12441", "authors": ["Yen-Linh Vu", "Dinh-Thang Duong", "Truong-Binh Duong", "Anh-Khoi Nguyen", "Thanh-Huy Nguyen", "Le Thien Phuc Nguyen", "Jianhua Xing", "Xingjian Li", "Tianyang Wang", "Ulas Bagci", "Min Xu"], "title": "Describe Anything Model for Visual Question Answering on Text-rich Images", "categories": ["cs.CV", "cs.LG"], "comment": "11 pages, 5 figures. Accepted to VisionDocs @ ICCV 2025", "summary": "Recent progress has been made in region-aware vision-language modeling,\nparticularly with the emergence of the Describe Anything Model (DAM). DAM is\ncapable of generating detailed descriptions of any specific image areas or\nobjects without the need for additional localized image-text alignment\nsupervision. We hypothesize that such region-level descriptive capability is\nbeneficial for the task of Visual Question Answering (VQA), especially in\nchallenging scenarios involving images with dense text. In such settings, the\nfine-grained extraction of textual information is crucial to producing correct\nanswers. Motivated by this, we introduce DAM-QA, a framework with a tailored\nevaluation protocol, developed to investigate and harness the region-aware\ncapabilities from DAM for the text-rich VQA problem that requires reasoning\nover text-based information within images. DAM-QA incorporates a mechanism that\naggregates answers from multiple regional views of image content, enabling more\neffective identification of evidence that may be tied to text-related elements.\nExperiments on six VQA benchmarks show that our approach consistently\noutperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA\nalso achieves the best overall performance among region-aware models with fewer\nparameters, significantly narrowing the gap with strong generalist VLMs. These\nresults highlight the potential of DAM-like models for text-rich and broader\nVQA tasks when paired with efficient usage and integration strategies. Our code\nis publicly available at https://github.com/Linvyl/DAM-QA.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDAM-QA\u6846\u67b6\u7528\u4e8e\u6587\u672c\u5bc6\u96c6\u56fe\u50cf\u7684\u89c6\u89c9\u95ee\u7b54\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u5047\u8bbeDAM\u7684\u533a\u57df\u63cf\u8ff0\u80fd\u529b\u5bf9\u89c6\u89c9\u95ee\u7b54\u6709\u76ca\uff0c\u5c24\u5176\u662f\u5904\u7406\u6587\u672c\u5bc6\u96c6\u56fe\u50cf\u65f6\uff0c\u5e0c\u671b\u5229\u7528\u5176\u80fd\u529b\u89e3\u51b3\u6587\u672c\u4e30\u5bcc\u7684\u89c6\u89c9\u95ee\u7b54\u95ee\u9898\u3002", "method": "\u5f15\u5165DAM-QA\u6846\u67b6\u548c\u5b9a\u5236\u8bc4\u4f30\u534f\u8bae\uff0c\u901a\u8fc7\u805a\u5408\u56fe\u50cf\u591a\u533a\u57df\u89c6\u56fe\u7b54\u6848\u7684\u673a\u5236\uff0c\u66f4\u6709\u6548\u8bc6\u522b\u4e0e\u6587\u672c\u76f8\u5173\u8bc1\u636e\u3002", "result": "\u5728\u516d\u4e2aVQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDAM-QA\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebfDAM\uff0c\u5728DocVQA\u4e0a\u63d0\u5347\u8d857\u5206\uff0c\u4ee5\u66f4\u5c11\u53c2\u6570\u5728\u533a\u57df\u611f\u77e5\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u7f29\u5c0f\u4e0e\u5f3a\u5927\u901a\u7528VLM\u5dee\u8ddd\u3002", "conclusion": "\u5f53\u91c7\u7528\u6709\u6548\u4f7f\u7528\u548c\u96c6\u6210\u7b56\u7565\u65f6\uff0c\u7c7b\u4f3cDAM\u7684\u6a21\u578b\u5728\u6587\u672c\u4e30\u5bcc\u53ca\u66f4\u5e7f\u6cdbVQA\u4efb\u52a1\u4e2d\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.12464", "pdf": "https://arxiv.org/pdf/2507.12464", "abs": "https://arxiv.org/abs/2507.12464", "authors": ["Muhammed Furkan Dasdelen", "Hyesu Lim", "Michele Buck", "Katharina S. G\u00f6tze", "Carsten Marr", "Steffen Schneider"], "title": "CytoSAE: Interpretable Cell Embeddings for Hematology", "categories": ["cs.CV", "cs.LG", "q-bio.QM"], "comment": "11 pages, 5 figures", "summary": "Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic\ninterpretability of transformer-based foundation models. Very recently, SAEs\nwere also adopted for the visual domain, enabling the discovery of visual\nconcepts and their patch-wise attribution to tokens in the transformer model.\nWhile a growing number of foundation models emerged for medical imaging, tools\nfor explaining their inferences are still lacking. In this work, we show the\napplicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder\nwhich is trained on over 40,000 peripheral blood single-cell images. CytoSAE\ngeneralizes to diverse and out-of-domain datasets, including bone marrow\ncytology, where it identifies morphologically relevant concepts which we\nvalidated with medical experts. Furthermore, we demonstrate scenarios in which\nCytoSAE can generate patient-specific and disease-specific concepts, enabling\nthe detection of pathognomonic cells and localized cellular abnormalities at\nthe patch level. We quantified the effect of concepts on a patient-level AML\nsubtype classification task and show that CytoSAE concepts reach performance\ncomparable to the state-of-the-art, while offering explainability on the\nsub-cellular level. Source code and model weights are available at\nhttps://github.com/dynamical-inference/cytosae.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8e\u8840\u6db2\u5b66\u7684\u7a00\u758f\u81ea\u7f16\u7801\u5668CytoSAE\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u6709\u6548\uff0c\u53ef\u751f\u6210\u7279\u5b9a\u6982\u5ff5\uff0c\u5728AML\u4e9a\u578b\u5206\u7c7b\u4efb\u52a1\u8868\u73b0\u597d\u4e14\u5177\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u533b\u5b66\u5f71\u50cf\u9886\u57df\u7f3a\u4e4f\u89e3\u91ca\u57fa\u7840\u6a21\u578b\u63a8\u7406\u7684\u5de5\u5177\uff0c\u5c1d\u8bd5\u5c06SAEs\u5e94\u7528\u4e8e\u8840\u6db2\u5b66\u3002", "method": "\u63d0\u51faCytoSAE\u5e76\u5728\u8d8540000\u5f20\u5916\u5468\u8840\u5355\u7ec6\u80de\u56fe\u50cf\u4e0a\u8bad\u7ec3\u3002", "result": "CytoSAE\u80fd\u6cdb\u5316\u5230\u4e0d\u540c\u6570\u636e\u96c6\uff0c\u8bc6\u522b\u76f8\u5173\u6982\u5ff5\u5e76\u7ecf\u4e13\u5bb6\u9a8c\u8bc1\uff0c\u53ef\u751f\u6210\u7279\u5b9a\u6982\u5ff5\uff0c\u5728AML\u4e9a\u578b\u5206\u7c7b\u4efb\u52a1\u8868\u73b0\u4e0eSOTA\u76f8\u5f53\u3002", "conclusion": "SAEs\u5728\u8840\u6db2\u5b66\u9886\u57df\u6709\u9002\u7528\u6027\uff0cCytoSAE\u5728\u533b\u5b66\u56fe\u50cf\u89e3\u91ca\u548c\u75be\u75c5\u68c0\u6d4b\u65b9\u9762\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.12466", "pdf": "https://arxiv.org/pdf/2507.12466", "abs": "https://arxiv.org/abs/2507.12466", "authors": ["David Mizrahi", "Anders Boesen Lindbo Larsen", "Jesse Allardice", "Suzie Petryk", "Yuri Gorokhov", "Jeffrey Li", "Alex Fang", "Josh Gardner", "Tom Gunter", "Afshin Dehghan"], "title": "Language Models Improve When Pretraining Data Matches Target Tasks", "categories": ["cs.CL", "cs.LG"], "comment": "44 pages, 25 figures, 13 tables", "summary": "Every data selection method inherently has a target. In practice, these\ntargets often emerge implicitly through benchmark-driven iteration: researchers\ndevelop selection strategies, train models, measure benchmark performance, then\nrefine accordingly. This raises a natural question: what happens when we make\nthis optimization explicit? To explore this, we propose benchmark-targeted\nranking (BETR), a simple method that selects pretraining documents based on\nsimilarity to benchmark training examples. BETR embeds benchmark examples and a\nsample of pretraining documents in a shared space, scores this sample by\nsimilarity to benchmarks, then trains a lightweight classifier to predict these\nscores for the full corpus. We compare data selection methods by training over\n500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to\nthem. From this, we find that simply aligning pretraining data to evaluation\nbenchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline\n(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks\nacross all scales. BETR also generalizes well: when targeting a diverse set of\nbenchmarks disjoint from our evaluation suite, it still matches or outperforms\nbaselines. Our scaling analysis further reveals a clear trend: larger models\nrequire less aggressive filtering. Overall, our findings show that directly\nmatching pretraining data to target tasks precisely shapes model capabilities\nand highlight that optimal selection strategies must adapt to model scale.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u51c6\u76ee\u6807\u6392\u540d\uff08BETR\uff09\u65b9\u6cd5\u9009\u9884\u8bad\u7ec3\u6587\u6863\uff0c\u5bf9\u6bd4\u591a\u79cd\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u53d1\u73b0BETR\u6709\u8ba1\u7b97\u4f18\u52bf\u3001\u6cdb\u5316\u6027\u597d\uff0c\u4e14\u5927\u6a21\u578b\u9700\u8f83\u5bbd\u677e\u8fc7\u6ee4\u3002", "motivation": "\u63a2\u7a76\u5c06\u6570\u636e\u9009\u62e9\u4f18\u5316\u663e\u5f0f\u5316\u4f1a\u600e\u6837\u3002", "method": "\u63d0\u51faBETR\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u57fa\u51c6\u793a\u4f8b\u548c\u9884\u8bad\u7ec3\u6587\u6863\u6837\u672c\u5d4c\u5165\u5171\u4eab\u7a7a\u95f4\uff0c\u6839\u636e\u4e0e\u57fa\u51c6\u7684\u76f8\u4f3c\u5ea6\u8bc4\u5206\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u9884\u6d4b\u5168\u91cf\u8bed\u6599\u5206\u6570\uff1b\u8bad\u7ec3\u8d85500\u4e2a\u6a21\u578b\u5e76\u62df\u5408\u7f29\u653e\u5b9a\u5f8b\u5bf9\u6bd4\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u3002", "result": "BETR\u6bd4DCLM - Baseline\u67092.1\u500d\u8ba1\u7b97\u4e58\u6570\uff08\u672a\u8fc7\u6ee4\u6570\u636e4.7\u500d\uff09\uff0c10\u4e2a\u4efb\u52a1\u4e2d9\u4e2a\u8868\u73b0\u63d0\u5347\uff0c\u6cdb\u5316\u6027\u597d\uff0c\u5927\u6a21\u578b\u9700\u8f83\u5bbd\u677e\u8fc7\u6ee4\u3002", "conclusion": "\u9884\u8bad\u7ec3\u6570\u636e\u4e0e\u76ee\u6807\u4efb\u52a1\u7cbe\u786e\u5339\u914d\u80fd\u5851\u9020\u6a21\u578b\u80fd\u529b\uff0c\u6700\u4f18\u9009\u62e9\u7b56\u7565\u8981\u9002\u5e94\u6a21\u578b\u89c4\u6a21\u3002"}}
