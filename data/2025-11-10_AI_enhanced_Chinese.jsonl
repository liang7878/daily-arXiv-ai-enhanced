{"id": "2511.04817", "pdf": "https://arxiv.org/pdf/2511.04817", "abs": "https://arxiv.org/abs/2511.04817", "authors": ["Chido Onyeze", "David X. Lin", "Siddhartha Banerjee", "\u00c9va Tardos"], "title": "Dynamic Allocation of Public Goods with Approximate Core Equilibria", "categories": ["cs.GT"], "comment": "44 pages, 1 figure", "summary": "We consider the problem of repeatedly allocating multiple shareable public\ngoods that have limited availability in an online setting without the use of\nmoney. In our setting, agents have additive values, and the value each agent\nreceives from getting access to the goods in each period is drawn i.i.d. from\nsome joint distribution $\\mathcal{D}$ (that can be arbitrarily correlated\nbetween agents). The principal also has global constraints on the set of goods\nthey can select over the horizon, which is represented via a submodular\nallocation-cost function. Our goal is to select the periods to allocate the\ngood to ensure high value for each group of agents.\n  We develop mechanisms for this problem using an artificial currency, where we\ngive each agent a budget proportional to their (exogenous) fair share. The\ncorrelated value distribution makes this an especially challenging problem, as\nagents may attempt to free-ride by declaring low valuations for the good when\nthey know other agents have high values-hoping those agents will bear a larger\nshare of the cost of the resource. We offer a black-box reduction from monetary\nmechanisms for the allocation of a costly excludable public good. We focus on\npacing strategies, the natural strategies when using AI agents, where agents\nreport a scaled version of their value to the mechanism. Our main results show\nthat when using a truthful monetary mechanism as our building block, the\nresulting online mechanism has a focal equilibrium in which each agent plays a\npacing strategy whose outcome results in an allocation that is a\n$(\\mathcal{H}_n-1)$-approximation of the core, where $\\mathcal{H}_n$ is the\nHarmonic number, and $n$ is the number of agents. Remarkably, we are able to\nachieve an approximate core solution as a Nash outcome without explicit\ncollaboration or coordination between the agents.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.04846", "pdf": "https://arxiv.org/pdf/2511.04846", "abs": "https://arxiv.org/abs/2511.04846", "authors": ["Jonathan Shaki", "Jiarui Gan", "Sarit Kraus"], "title": "Persuading Stable Matching", "categories": ["cs.GT", "cs.MA"], "comment": null, "summary": "In bipartite matching problems, agents on two sides of a graph want to be\npaired according to their preferences. The stability of a matching depends on\nthese preferences, which in uncertain environments also reflect agents' beliefs\nabout the underlying state of the world. We investigate how a principal -- who\nobserves the true state of the world -- can strategically shape these beliefs\nthrough Bayesian persuasion to induce stable matching that maximizes a desired\nutility. Due to the general intractability of the underlying matching\noptimization problem as well as the multi-receiver persuasion problem, our main\nconsiderations are two important special cases: (1) when agents can be\ncategorized into a small number of types based on their value functions, and\n(2) when the number of possible world states is small. For each case, we study\nboth public and private signaling settings. Our results draw a complete\ncomplexity landscape: we show that private persuasion remains intractable even\nwhen the number of worlds is small, while all other settings admit\npolynomial-time algorithms. We present efficient algorithms for each tractable\ncase and prove NP-hardness for the intractable ones. These results illuminate\nthe algorithmic frontier of stable matching under information design and\nclarify when optimal persuasion is computationally feasible.", "AI": {"tldr": "\u7814\u7a76\u5728\u4e8c\u5206\u5339\u914d\u95ee\u9898\u4e2d\uff0c\u4e3b\u4f53\u5982\u4f55\u901a\u8fc7\u8d1d\u53f6\u65af\u8bf4\u670d\u5851\u9020\u4ee3\u7406\u4eba\u4fe1\u5ff5\u4ee5\u8bf1\u5bfc\u7a33\u5b9a\u5339\u914d\uff0c\u8003\u8651\u4e24\u79cd\u7279\u6b8a\u60c5\u51b5\uff0c\u5f97\u51fa\u5b8c\u6574\u590d\u6742\u5ea6\u56fe\u666f\u3002", "motivation": "\u5728\u4e8c\u5206\u5339\u914d\u95ee\u9898\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\uff0c\u7814\u7a76\u4e3b\u4f53\u5982\u4f55\u901a\u8fc7\u8d1d\u53f6\u65af\u8bf4\u670d\u5851\u9020\u4ee3\u7406\u4eba\u4fe1\u5ff5\uff0c\u4ee5\u8bf1\u5bfc\u51fa\u6700\u5927\u5316\u671f\u671b\u6548\u7528\u7684\u7a33\u5b9a\u5339\u914d\u3002", "method": "\u8003\u8651\u4e24\u79cd\u91cd\u8981\u7279\u6b8a\u60c5\u51b5\uff0c\u5373\u4ee3\u7406\u4eba\u53ef\u6309\u4ef7\u503c\u51fd\u6570\u5206\u4e3a\u5c11\u91cf\u7c7b\u578b\u548c\u53ef\u80fd\u4e16\u754c\u72b6\u6001\u6570\u91cf\u8f83\u5c11\u7684\u60c5\u51b5\uff0c\u7814\u7a76\u516c\u5f00\u548c\u79c1\u4eba\u4fe1\u53f7\u8bbe\u7f6e\u3002", "result": "\u7ed8\u5236\u5b8c\u6574\u590d\u6742\u5ea6\u56fe\u666f\uff0c\u79c1\u4eba\u8bf4\u670d\u5728\u4e16\u754c\u6570\u91cf\u5c11\u7684\u60c5\u51b5\u4e0b\u4ecd\u96be\u5904\u7406\uff0c\u5176\u4ed6\u60c5\u51b5\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u7ed9\u51fa\u53ef\u5904\u7406\u60c5\u51b5\u7684\u9ad8\u6548\u7b97\u6cd5\u5e76\u8bc1\u660e\u96be\u5904\u7406\u60c5\u51b5\u7684NP\u96be\u3002", "conclusion": "\u9610\u660e\u4e86\u4fe1\u606f\u8bbe\u8ba1\u4e0b\u7a33\u5b9a\u5339\u914d\u7684\u7b97\u6cd5\u8fb9\u754c\uff0c\u660e\u786e\u4e86\u6700\u4f18\u8bf4\u670d\u5728\u8ba1\u7b97\u4e0a\u53ef\u884c\u7684\u60c5\u51b5\u3002"}}
{"id": "2511.04867", "pdf": "https://arxiv.org/pdf/2511.04867", "abs": "https://arxiv.org/abs/2511.04867", "authors": ["Kate Donahue", "Nicole Immorlica", "Brendan Lucier"], "title": "Optimal Selection Using Algorithmic Rankings with Side Information", "categories": ["cs.GT"], "comment": null, "summary": "Motivated by online platforms such as job markets, we study an agent choosing\nfrom a list of candidates, each with a hidden quality that determines match\nvalue. The agent observes only a noisy ranking of the candidates plus a binary\nsignal that indicates whether each candidate is \"free\" or \"busy.\" Being busy is\npositively correlated with higher quality, but can also reduce value due to\ndecreased availability. We study the agent's optimal selection problem in the\npresence of ranking noise and free-busy signals and ask how the accuracy of the\nranking tool impacts outcomes. In a setting with one high-valued candidate and\nan arbitrary number of low-valued candidates, we show that increased accuracy\nof the ranking tool can result in reduced social welfare. This can occur for\ntwo reasons: agents may be more likely to make offers to busy candidates, and\n(paradoxically) may be more likely to select lower-ranked candidates when\nrankings are more indicative of quality. We further discuss conditions under\nwhich these results extend to more general settings.", "AI": {"tldr": "\u7814\u7a76\u5728\u7ebf\u5e73\u53f0\u4e2d\u4ee3\u7406\u9009\u62e9\u5019\u9009\u4eba\u95ee\u9898\uff0c\u53d1\u73b0\u6392\u540d\u5de5\u5177\u51c6\u786e\u6027\u63d0\u9ad8\u53ef\u80fd\u964d\u4f4e\u793e\u4f1a\u798f\u5229\u3002", "motivation": "\u53d7\u5728\u7ebf\u5e73\u53f0\uff08\u5982\u5c31\u4e1a\u5e02\u573a\uff09\u542f\u53d1\uff0c\u7814\u7a76\u4ee3\u7406\u5728\u6709\u6392\u540d\u566a\u58f0\u548c\u81ea\u7531 - \u5fd9\u788c\u4fe1\u53f7\u4e0b\u7684\u6700\u4f18\u9009\u62e9\u95ee\u9898\u53ca\u6392\u540d\u5de5\u5177\u51c6\u786e\u6027\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u4e00\u4e2a\u9ad8\u4ef7\u503c\u5019\u9009\u4eba\u548c\u4efb\u610f\u6570\u91cf\u4f4e\u4ef7\u503c\u5019\u9009\u4eba\u7684\u60c5\u51b5\uff0c\u5e76\u63a2\u8ba8\u7ed3\u679c\u5728\u66f4\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u9002\u7528\u6027\u3002", "result": "\u6392\u540d\u5de5\u5177\u51c6\u786e\u6027\u63d0\u9ad8\u53ef\u80fd\u56e0\u4ee3\u7406\u66f4\u503e\u5411\u5411\u5fd9\u788c\u5019\u9009\u4eba\u53d1\u51fa\u9080\u7ea6\u548c\u66f4\u53ef\u80fd\u9009\u62e9\u4f4e\u6392\u540d\u5019\u9009\u4eba\u800c\u964d\u4f4e\u793e\u4f1a\u798f\u5229\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u7ed3\u679c\u5728\u66f4\u4e00\u822c\u8bbe\u7f6e\u4e0b\u6210\u7acb\u7684\u6761\u4ef6\u3002"}}
{"id": "2511.05383", "pdf": "https://arxiv.org/pdf/2511.05383", "abs": "https://arxiv.org/abs/2511.05383", "authors": ["Elinor Thompson", "Tiantian He", "Anna Schroder", "Ahmed Abdulaal", "Alec Sargood", "Sonja Soskic", "Henry F. J. Tregidgo", "Daniel C. Alexander"], "title": "Connectomics Informed by Large Language Models", "categories": ["cs.CE"], "comment": "35 pages, 10 figures", "summary": "Tractography is a unique method for mapping white matter connections in the\nbrain, but tractography algorithms suffer from an inherent trade-off between\nsensitivity and specificity that limits accuracy. Incorporating prior knowledge\nof white matter anatomy is an effective strategy for improving accuracy and has\nbeen successful for reducing false positives and false negatives in\nbundle-mapping protocols. However, it is challenging to scale this approach for\nconnectomics due to the difficulty in synthesising information relating to many\nthousands of possible connections. In this work, we develop and evaluate a\npipeline using large language models (LLMs) to generate quantitative priors for\nconnectomics, based on their knowledge of neuroanatomy. We benchmark our\napproach against an evaluation set derived from a gold-standard tractography\natlas, identifying prompting techniques to elicit accurate connectivity\ninformation from the LLMs. We further identify strategies for incorporating\nexternal knowledge sources into the pipeline, which can provide grounding for\nthe LLM and improve accuracy. Finally, we demonstrate how the LLM-derived\npriors can augment existing tractography filtering approaches by identifying\ntrue-positive connections to retain during the filtering process. We show that\nthese additional connections can improve the accuracy of a connectome-based\nmodel of pathology spread, which provides supporting evidence that the\nconnections preserved by the LLM are valid.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3a\u8111\u8fde\u63a5\u7ec4\u5b66\u751f\u6210\u5b9a\u91cf\u5148\u9a8c\u77e5\u8bc6\u7684\u7ba1\u9053\uff0c\u53ef\u63d0\u9ad8\u8111\u767d\u8d28\u7ea4\u7ef4\u675f\u6210\u50cf\u51c6\u786e\u6027\u53ca\u75c5\u7406\u4f20\u64ad\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u8111\u767d\u8d28\u7ea4\u7ef4\u675f\u6210\u50cf\u7b97\u6cd5\u5728\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\u4e0a\u5b58\u5728\u6743\u8861\uff0c\u9650\u5236\u51c6\u786e\u6027\uff0c\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\u867d\u6709\u6548\u4f46\u7528\u4e8e\u8fde\u63a5\u7ec4\u5b66\u5b58\u5728\u56f0\u96be\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eLLMs\u7684\u7ba1\u9053\u751f\u6210\u5b9a\u91cf\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e0e\u91d1\u6807\u51c6\u56fe\u8c31\u5bf9\u6bd4\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u786e\u5b9a\u63d0\u793a\u6280\u672f\u548c\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u6e90\u7684\u7b56\u7565\u3002", "result": "\u8bc6\u522b\u51fa\u80fd\u4eceLLMs\u83b7\u53d6\u51c6\u786e\u8fde\u63a5\u4fe1\u606f\u7684\u63d0\u793a\u6280\u672f\uff0c\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u53ef\u63d0\u9ad8\u51c6\u786e\u6027\uff0cLLM\u5148\u9a8c\u80fd\u589e\u5f3a\u73b0\u6709\u8fc7\u6ee4\u65b9\u6cd5\u3002", "conclusion": "LLM\u751f\u6210\u7684\u5148\u9a8c\u77e5\u8bc6\u80fd\u63d0\u9ad8\u8111\u8fde\u63a5\u7ec4\u5b66\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u4fdd\u7559\u7684\u8fde\u63a5\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2511.04891", "pdf": "https://arxiv.org/pdf/2511.04891", "abs": "https://arxiv.org/abs/2511.04891", "authors": ["Haris Aziz", "Xinhang Lu", "Simon Mackenzie", "Mashbat Suzuki"], "title": "Fair Division with Indivisible Goods, Chores, and Cake", "categories": ["cs.GT"], "comment": null, "summary": "We study the problem of fairly allocating indivisible items and a desirable\nheterogeneous divisible good (i.e., cake) to agents with additive utilities. In\nour paper, each indivisible item can be a good that yields non-negative\nutilities to some agents and a chore that yields negative utilities to the\nother agents. Given a fixed set of divisible and indivisible resources, we\ninvestigate almost envy-free allocations, captured by the natural fairness\nconcept of envy-freeness for mixed resources (EFM). It requires that an agent\n$i$ does not envy another agent $j$ if agent $j$'s bundle contains any piece of\ncake yielding positive utility to agent $i$ (i.e., envy-freeness), and agent\n$i$ is envy-free up to one item (EF1) towards agent $j$ otherwise. We prove\nthat with indivisible items and a cake, an EFM allocation always exists for any\nnumber of agents with additive utilities.", "AI": {"tldr": "\u7814\u7a76\u5177\u6709\u52a0\u6027\u6548\u7528\u7684\u4ee3\u7406\u5bf9\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u548c\u53ef\u5206\u5272\u7269\u54c1\uff08\u86cb\u7cd5\uff09\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\uff0c\u8bc1\u660e\u4e86EFM\u5206\u914d\u603b\u662f\u5b58\u5728\u3002", "motivation": "\u89e3\u51b3\u5177\u6709\u52a0\u6027\u6548\u7528\u7684\u4ee3\u7406\u5bf9\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u548c\u53ef\u5206\u5272\u7269\u54c1\u7684\u516c\u5e73\u5206\u914d\u95ee\u9898\u3002", "method": "\u7814\u7a76\u51e0\u4e4e\u65e0\u5ac9\u5992\u5206\u914d\uff0c\u4f7f\u7528\u65e0\u5ac9\u5992\u6df7\u5408\u8d44\u6e90\uff08EFM\uff09\u7684\u516c\u5e73\u6982\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u4f55\u6570\u91cf\u5177\u6709\u52a0\u6027\u6548\u7528\u7684\u4ee3\u7406\uff0c\u5b58\u5728\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u548c\u86cb\u7cd5\u7684EFM\u5206\u914d\u3002", "conclusion": "\u5728\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u548c\u86cb\u7cd5\u7684\u5206\u914d\u4e2d\uff0cEFM\u5206\u914d\u603b\u662f\u5b58\u5728\u3002"}}
{"id": "2511.05389", "pdf": "https://arxiv.org/pdf/2511.05389", "abs": "https://arxiv.org/abs/2511.05389", "authors": ["Benjamin G. Zastrow", "Anirban Chaudhuri", "Karen E. Willcox", "Anthony Ashley", "Michael Chamberlain Henson"], "title": "Block-structured Operator Inference for coupled multiphysics model reduction", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": "28 pages, 19 figures", "summary": "This paper presents a block-structured formulation of Operator Inference as a\nway to learn structured reduced-order models for multiphysics systems. The\napproach specifies the governing equation structure for each physics component\nand the structure of the coupling terms. Once the multiphysics structure is\nspecified, the reduced-order model is learned from snapshot data following the\nnonintrusive Operator Inference methodology. In addition to preserving physical\nsystem structure, which in turn permits preservation of system properties such\nas stability and second-order structure, the block-structured approach has the\nadvantages of reducing the overall dimensionality of the learning problem and\nadmitting tailored regularization for each physics component. The numerical\nadvantages of the block-structured formulation over a monolithic Operator\nInference formulation are demonstrated for aeroelastic analysis, which couples\naerodynamic and structural models. For the benchmark test case of the AGARD\n445.6 wing, block-structured Operator Inference provides an average 20% online\nprediction speedup over monolithic Operator Inference across subsonic and\nsupersonic flow conditions in both the stable and fluttering parameter regimes\nwhile preserving the accuracy achieved with monolithic Operator Inference.", "AI": {"tldr": "\u63d0\u51fa\u5757\u7ed3\u6784\u7684\u7b97\u5b50\u63a8\u7406\u516c\u5f0f\u6765\u5b66\u4e60\u591a\u7269\u7406\u7cfb\u7edf\u7684\u7ed3\u6784\u964d\u9636\u6a21\u578b\uff0c\u5728\u6c14\u52a8\u5f39\u6027\u5206\u6790\u4e2d\u5c55\u73b0\u4f18\u52bf\u3002", "motivation": "\u4e3a\u591a\u7269\u7406\u7cfb\u7edf\u5b66\u4e60\u7ed3\u6784\u5316\u964d\u9636\u6a21\u578b\uff0c\u4fdd\u7559\u7269\u7406\u7cfb\u7edf\u7ed3\u6784\u548c\u7279\u6027\u3002", "method": "\u6307\u5b9a\u5404\u7269\u7406\u7ec4\u4ef6\u63a7\u5236\u65b9\u7a0b\u7ed3\u6784\u548c\u8026\u5408\u9879\u7ed3\u6784\uff0c\u6309\u975e\u4fb5\u5165\u5f0f\u7b97\u5b50\u63a8\u7406\u65b9\u6cd5\u4ece\u5feb\u7167\u6570\u636e\u5b66\u4e60\u964d\u9636\u6a21\u578b\u3002", "result": "\u5728AGARD 445.6\u673a\u7ffc\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5757\u7ed3\u6784\u7b97\u5b50\u63a8\u7406\u6bd4\u6574\u4f53\u7b97\u5b50\u63a8\u7406\u5728\u7ebf\u9884\u6d4b\u5e73\u5747\u63d0\u901f20%\uff0c\u4e14\u4fdd\u6301\u7cbe\u5ea6\u3002", "conclusion": "\u5757\u7ed3\u6784\u516c\u5f0f\u76f8\u6bd4\u6574\u4f53\u7b97\u5b50\u63a8\u7406\u516c\u5f0f\u6709\u4f18\u52bf\uff0c\u80fd\u964d\u7ef4\u3001\u5141\u8bb8\u5b9a\u5236\u6b63\u5219\u5316\u3002"}}
{"id": "2511.05082", "pdf": "https://arxiv.org/pdf/2511.05082", "abs": "https://arxiv.org/abs/2511.05082", "authors": ["Yiming Xie", "Hua Dai", "Mingfeng Jiang", "Pengyue Li", "zhengkai Zhang", "Bohan Li"], "title": "An Efficient Proximity Graph-based Approach to Table Union Search", "categories": ["cs.DB"], "comment": null, "summary": "Neural embedding models are extensively employed in the table union search\nproblem, which aims to find semantically compatible tables that can be merged\nwith a given query table. In particular, multi-vector models, which represent a\ntable as a vector set (typically one vector per column), have been demonstrated\nto achieve superior retrieval quality by capturing fine-grained semantic\nalignments. However, this problem faces more severe efficiency challenges than\nthe single-vector problem due to the inherent dependency on bipartite graph\nmaximum matching to compute unionability scores. Therefore, this paper proposes\nan efficient Proximity Graph-based Table Union Search (PGTUS) approach. PGTUS\nemploys a multi-stage pipeline that combines a novel refinement strategy, a\nfiltering strategy based on many-to-one bipartite matching. Besides, we propose\nan enhanced pruning strategy to prune the candidate set, which further improve\nthe search efficiency. Extensive experiments on six benchmark datasets\ndemonstrate that our approach achieves 3.6-6.0X speedup over existing\napproaches while maintaining comparable recall rates.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8868\u683c\u8054\u5408\u641c\u7d22\u95ee\u9898\u6548\u7387\u6311\u6218\uff0c\u63d0\u51faPGTUS\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u53ec\u56de\u7387\u7684\u540c\u65f6\u63d0\u5347\u641c\u7d22\u901f\u5ea6\u3002", "motivation": "\u8868\u683c\u8054\u5408\u641c\u7d22\u95ee\u9898\u4e2d\u591a\u5411\u91cf\u6a21\u578b\u867d\u68c0\u7d22\u8d28\u91cf\u9ad8\uff0c\u4f46\u56e0\u4f9d\u8d56\u4e8c\u5206\u56fe\u6700\u5927\u5339\u914d\u8ba1\u7b97\u8054\u5408\u6027\u5f97\u5206\uff0c\u9762\u4e34\u6bd4\u5355\u5411\u91cf\u95ee\u9898\u66f4\u4e25\u5cfb\u7684\u6548\u7387\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u90bb\u8fd1\u56fe\u7684\u8868\u683c\u8054\u5408\u641c\u7d22\uff08PGTUS\uff09\u65b9\u6cd5\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u7ec6\u5316\u7b56\u7565\u3001\u57fa\u4e8e\u591a\u5bf9\u4e00\u4e8c\u5206\u5339\u914d\u7684\u8fc7\u6ee4\u7b56\u7565\uff0c\u8fd8\u63d0\u51fa\u589e\u5f3a\u7684\u526a\u679d\u7b56\u7565\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e863.6 - 6.0\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u53ec\u56de\u7387\u3002", "conclusion": "PGTUS\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u8868\u683c\u8054\u5408\u641c\u7d22\u7684\u6548\u7387\u3002"}}
{"id": "2511.04853", "pdf": "https://arxiv.org/pdf/2511.04853", "abs": "https://arxiv.org/abs/2511.04853", "authors": ["Nuno dos Santos Fernandes", "Pedro Tom\u00e1s", "Nuno Roma", "Frank Winklmeier", "Patricia Conde-Mu\u00ed\u00f1o"], "title": "Marionette: Data Structure Description and Management for Heterogeneous Computing", "categories": ["cs.DC"], "comment": "5 pages, 2 figures. To be published as a short paper accepted by the\n  24th International Symposium on Parallel and Distributed Computing (ISPDC)", "summary": "Adapting large, object-oriented C++ codebases for hardware acceleration might\nbe extremely challenging, particularly when targeting heterogeneous platforms\nsuch as GPUs. Marionette is a C++17 library designed to address this by\nenabling flexible, efficient, and portable data structure definitions. It\ndecouples data layout from the description of the interface, supports multiple\nmemory management strategies, and provides efficient data transfers and\nconversions across devices, all of this with minimal runtime overhead due to\nthe compile-time nature of its abstractions. By allowing interfaces to be\naugmented with arbitrary functions, Marionette maintains compatibility with\nexisting code and offers a streamlined interface that supports both\nstraightforward and advanced use cases. This paper outlines its design, usage,\nand performance, including a CUDA-based case study demonstrating its efficiency\nand flexibility.", "AI": {"tldr": "Marionette\u662f\u4e00\u4e2aC++17\u5e93\uff0c\u53ef\u89e3\u51b3\u5927\u578b\u9762\u5411\u5bf9\u8c61C++\u4ee3\u7801\u5e93\u786c\u4ef6\u52a0\u901f\u9002\u914d\u96be\u9898\uff0c\u672c\u6587\u4ecb\u7ecd\u5176\u8bbe\u8ba1\u3001\u7528\u6cd5\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u9762\u5411\u5bf9\u8c61C++\u4ee3\u7801\u5e93\u5728\u5f02\u6784\u5e73\u53f0\uff08\u5982GPU\uff09\u4e0a\u8fdb\u884c\u786c\u4ef6\u52a0\u901f\u9002\u914d\u7684\u6311\u6218\u3002", "method": "\u8bbe\u8ba1C++17\u5e93Marionette\uff0c\u89e3\u8026\u6570\u636e\u5e03\u5c40\u4e0e\u63a5\u53e3\u63cf\u8ff0\uff0c\u652f\u6301\u591a\u5185\u5b58\u7ba1\u7406\u7b56\u7565\uff0c\u63d0\u4f9b\u9ad8\u6548\u6570\u636e\u4f20\u8f93\u548c\u8f6c\u6362\u3002", "result": "\u901a\u8fc7\u57fa\u4e8eCUDA\u7684\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86Marionette\u7684\u6548\u7387\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "Marionette\u80fd\u5b9e\u73b0\u7075\u6d3b\u3001\u9ad8\u6548\u3001\u53ef\u79fb\u690d\u7684\u6570\u636e\u7ed3\u6784\u5b9a\u4e49\uff0c\u4e0e\u73b0\u6709\u4ee3\u7801\u517c\u5bb9\uff0c\u652f\u6301\u591a\u79cd\u7528\u4f8b\u3002"}}
{"id": "2511.04775", "pdf": "https://arxiv.org/pdf/2511.04775", "abs": "https://arxiv.org/abs/2511.04775", "authors": ["Ce Jin", "Yael Kirkpatrick", "Micha\u0142 Stawarz", "Virginia Vassilevska Williams"], "title": "Improved Additive Approximation Algorithms for APSP", "categories": ["cs.DS"], "comment": null, "summary": "The All-Pairs Shortest Paths (APSP) is a foundational problem in theoretical\ncomputer science. Approximating APSP in undirected unweighted graphs has been\nstudied for many years, beginning with the work of Dor, Halperin and Zwick\n[SICOMP'01]. Many recent works have attempted to improve these original\nalgorithms using the algebraic tools of fast matrix multiplication. We improve\non these results for the following problems.\n  For $+2$-approximate APSP, the state-of-the-art algorithm runs in\n$O(n^{2.259})$ time [D\\\"urr, IPL 2023; Deng, Kirkpatrick, Rong, Vassilevska\nWilliams, and Zhong, ICALP 2022]. We give an improved algorithm in\n$O(n^{2.2255})$ time.\n  For $+4$ and $+6$-approximate APSP, we achieve time complexities\n$O(n^{2.1462})$ and $O(n^{2.1026})$ respectively, improving the previous\n$O(n^{2.155})$ and $O(n^{2.103})$ achieved by [Saha and Ye, SODA 2024].\n  In contrast to previous works, we do not use the big hammer of\nbounded-difference $(\\min,+)$-product algorithms. Instead, our algorithms are\nbased on a simple technique that decomposes the input graph into a small number\nof clusters of constant diameter and a remainder of low degree vertices, which\ncould be of independent interest in the study of shortest paths problems. We\nthen use only standard fast matrix multiplication to obtain our improvements.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u65e0\u5411\u65e0\u6743\u56fe\u4e2dAll - Pairs Shortest Paths (APSP)\u95ee\u9898\u8fd1\u4f3c\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u4e0d\u4f7f\u7528\u6709\u754c\u5dee(min, +)\u79ef\u7b97\u6cd5\uff0c\u91c7\u7528\u56fe\u5206\u89e3\u6280\u672f\u3002", "motivation": "\u524d\u4eba\u7528\u5feb\u901f\u77e9\u9635\u4e58\u6cd5\u4ee3\u6570\u5de5\u5177\u6539\u8fdbAPSP\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u4f5c\u8005\u5e0c\u671b\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "method": "\u5c06\u8f93\u5165\u56fe\u5206\u89e3\u4e3a\u5c11\u91cf\u6052\u5b9a\u76f4\u5f84\u7684\u7c07\u548c\u4f4e\u5ea6\u6570\u9876\u70b9\u7684\u5269\u4f59\u90e8\u5206\uff0c\u4ec5\u4f7f\u7528\u6807\u51c6\u5feb\u901f\u77e9\u9635\u4e58\u6cd5\u3002", "result": "\u5bf9\u4e8e+2\u8fd1\u4f3cAPSP\uff0c\u7b97\u6cd5\u65f6\u95f4\u590d\u6742\u5ea6\u4ece$O(n^{2.259})$\u63d0\u5347\u5230$O(n^{2.2255})$\uff1b\u5bf9\u4e8e+4\u548c+6\u8fd1\u4f3cAPSP\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u5206\u522b\u4ece$O(n^{2.155})$\u548c$O(n^{2.103})$\u63d0\u5347\u5230$O(n^{2.1462})$\u548c$O(n^{2.1026})$\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e0d\u4f9d\u8d56\u6709\u754c\u5dee(min, +)\u79ef\u7b97\u6cd5\u7684\u56fe\u5206\u89e3\u6280\u672f\u6709\u6548\u63d0\u5347\u4e86APSP\u8fd1\u4f3c\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u8be5\u6280\u672f\u5bf9\u6700\u77ed\u8def\u5f84\u95ee\u9898\u7814\u7a76\u6709\u72ec\u7acb\u4ef7\u503c\u3002"}}
{"id": "2511.04685", "pdf": "https://arxiv.org/pdf/2511.04685", "abs": "https://arxiv.org/abs/2511.04685", "authors": ["Daniela Guericke", "Rolf van der Hulst", "Asal Karimpour", "Ieke Schrader", "Matthias Walter"], "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024", "categories": ["cs.AI", "math.OC", "90-04", "F.2.2"], "comment": "23 pages, 2 figures, 10 tables", "summary": "We report about the algorithm, implementation and results submitted to the\nIntegrated Healthcare Timetabling Competition 2024 by Team Twente, which scored\nthird in the competition. Our approach combines mixed-integer programming,\nconstraint programming and simulated annealing in a 3-phase solution approach\nbased on decomposition into subproblems. Next to describing our approach and\ndescribing our design decisions, we share our insights and, for the first time,\nlower bounds on the optimal solution values for the benchmark instances. We\nfinally highlight open problems for which we think that addressing them could\nimprove our approach even further.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7279\u6e29\u7279\u56e2\u961f\u53c2\u52a02024\u5e74\u7efc\u5408\u533b\u7597\u6392\u8bfe\u7ade\u8d5b\u7684\u7b97\u6cd5\u3001\u5b9e\u73b0\u548c\u7ed3\u679c\uff0c\u8be5\u56e2\u961f\u83b7\u7b2c\u4e09\u540d\uff0c\u5206\u4eab\u65b9\u6cd5\u3001\u89c1\u89e3\u548c\u4e0b\u754c\uff0c\u8fd8\u6307\u51fa\u5f85\u89e3\u51b3\u95ee\u9898\u3002", "motivation": "\u53c2\u52a0\u7efc\u5408\u533b\u7597\u6392\u8bfe\u7ade\u8d5b\u5e76\u53d6\u5f97\u597d\u6210\u7ee9\uff0c\u5206\u4eab\u7ecf\u9a8c\u548c\u89c1\u89e3\u3002", "method": "\u91c7\u7528\u5206\u4e09\u4e2a\u9636\u6bb5\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u6df7\u5408\u6574\u6570\u89c4\u5212\u3001\u7ea6\u675f\u89c4\u5212\u548c\u6a21\u62df\u9000\u706b\u7b97\u6cd5\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\u3002", "result": "\u56e2\u961f\u5728\u7ade\u8d5b\u4e2d\u83b7\u5f97\u7b2c\u4e09\u540d\uff0c\u9996\u6b21\u7ed9\u51fa\u57fa\u51c6\u5b9e\u4f8b\u6700\u4f18\u89e3\u503c\u7684\u4e0b\u754c\u3002", "conclusion": "\u6307\u51fa\u4e00\u4e9b\u5f00\u653e\u95ee\u9898\uff0c\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u53ef\u80fd\u8fdb\u4e00\u6b65\u6539\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2511.04901", "pdf": "https://arxiv.org/pdf/2511.04901", "abs": "https://arxiv.org/abs/2511.04901", "authors": ["Anthony Gamst", "Lawrence Wilson"], "title": "Association via Entropy Reduction", "categories": ["cs.IR", "cs.CL", "H.3.3"], "comment": null, "summary": "Prior to recent successes using neural networks, term frequency-inverse\ndocument frequency (tf-idf) was clearly regarded as the best choice for\nidentifying documents related to a query. We provide a different score, aver,\nand observe, on a dataset with ground truth marking for association, that aver\ndoes do better at finding assciated pairs than tf-idf. This example involves\nfinding associated vertices in a large graph and that may be an area where\nneural networks are not currently an obvious best choice. Beyond this one\nanecdote, we observe that (1) aver has a natural threshold for declaring pairs\nas unassociated while tf-idf does not, (2) aver can distinguish between pairs\nof documents for which tf-idf gives a score of 1.0, (3) aver can be applied to\nlarger collections of documents than pairs while tf-idf cannot, and (4) that\naver is derived from entropy under a simple statistical model while tf-idf is a\nconstruction designed to achieve a certain goal and hence aver may be more\n\"natural.\" To be fair, we also observe that (1) writing down and computing the\naver score for a pair is more complex than for tf-idf and (2) that the fact\nthat the aver score is naturally scale-free makes it more complicated to\ninterpret aver scores.", "AI": {"tldr": "\u63d0\u51faaver\u5206\u6570\uff0c\u5bf9\u6bd4\u53d1\u73b0\u5176\u5728\u627e\u5173\u8054\u6587\u6863\u5bf9\u65b9\u9762\u4f18\u4e8etf - idf\uff0c\u5e76\u9610\u8ff0\u4e8c\u8005\u4f18\u7f3a\u70b9\u3002", "motivation": "\u5728\u795e\u7ecf\u7f51\u7edc\u53d6\u5f97\u6210\u529f\u524d\uff0ctf - idf\u88ab\u89c6\u4e3a\u8bc6\u522b\u67e5\u8be2\u76f8\u5173\u6587\u6863\u7684\u6700\u4f73\u9009\u62e9\uff0c\u4f5c\u8005\u5e0c\u671b\u63d0\u4f9b\u4e0d\u540c\u7684\u5206\u6570\u3002", "method": "\u5728\u6709\u771f\u5b9e\u5173\u8054\u6807\u8bb0\u7684\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4aver\u548ctf - idf\u3002", "result": "aver\u5728\u627e\u5173\u8054\u5bf9\u65b9\u9762\u6bd4tf - idf\u597d\uff0c\u4e14\u6709\u8bf8\u591a\u4f18\u52bf\uff0c\u4f46\u4e5f\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u3001\u5206\u6570\u96be\u89e3\u91ca\u7b49\u95ee\u9898\u3002", "conclusion": "aver\u5728\u67d0\u4e9b\u65b9\u9762\u6bd4tf - idf\u66f4\u4f18\uff0c\u4f46\u4e5f\u6709\u81ea\u8eab\u5c40\u9650\u6027\u3002"}}
{"id": "2511.05315", "pdf": "https://arxiv.org/pdf/2511.05315", "abs": "https://arxiv.org/abs/2511.05315", "authors": ["Nourhaine Nefzi", "Abir Abid"], "title": "Economic uncertainty and exchange rates linkage revisited: modelling tail dependence with high frequency data", "categories": ["q-fin.CP"], "comment": null, "summary": "The aim of this paper is to dig deeper into understanding the exchange rates\nand uncertainty dependence. Using the novel Baker et al. (2020)'s daily Twitter\nUncertainty Index and BRICS exchange rates, we investigate their extreme tail\ndependence within an original time-varying copula framework. Our analysis makes\nseveral noteworthy results. Evidence for Indian, Russian and South African\ncurrencies indicates an elliptical copulas' dominance implying neither\nasymmetric features nor extreme movements in their dependence structure with\nthe global economic uncertainty. Importantly, Brazilian and Chinese currencies\ntail dependence is upward trending suggesting a safe-haven role in times of\nhigh global economic uncertainty including the recent COVID-19 pandemic. In\nsuch circumstances, these markets offer opportunities to significant gains\nthrough portfolio diversification.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u6bcf\u65e5\u63a8\u7279\u4e0d\u786e\u5b9a\u6027\u6307\u6570\u548c\u91d1\u7816\u56fd\u5bb6\u6c47\u7387\uff0c\u5728\u65f6\u53d8copula\u6846\u67b6\u4e0b\u7814\u7a76\u6c47\u7387\u4e0e\u4e0d\u786e\u5b9a\u6027\u7684\u6781\u7aef\u5c3e\u90e8\u4f9d\u8d56\uff0c\u5f97\u51fa\u90e8\u5206\u8d27\u5e01\u4f9d\u8d56\u7ed3\u6784\u7279\u70b9\u53ca\u5df4\u897f\u548c\u4e2d\u56fd\u8d27\u5e01\u7684\u907f\u98ce\u6e2f\u4f5c\u7528\u3002", "motivation": "\u6df1\u5165\u7406\u89e3\u6c47\u7387\u4e0e\u4e0d\u786e\u5b9a\u6027\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u4f7f\u7528Baker\u7b49\u4eba\uff082020\uff09\u7684\u6bcf\u65e5\u63a8\u7279\u4e0d\u786e\u5b9a\u6027\u6307\u6570\u548c\u91d1\u7816\u56fd\u5bb6\u6c47\u7387\uff0c\u5728\u539f\u521b\u7684\u65f6\u53d8copula\u6846\u67b6\u4e0b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u5370\u5ea6\u3001\u4fc4\u7f57\u65af\u548c\u5357\u975e\u8d27\u5e01\u4f9d\u8d56\u7ed3\u6784\u65e0\u4e0d\u5bf9\u79f0\u7279\u5f81\u548c\u6781\u7aef\u53d8\u52a8\uff1b\u5df4\u897f\u548c\u4e2d\u56fd\u8d27\u5e01\u5c3e\u90e8\u4f9d\u8d56\u5448\u4e0a\u5347\u8d8b\u52bf\uff0c\u5728\u9ad8\u5168\u7403\u7ecf\u6d4e\u4e0d\u786e\u5b9a\u6027\u65f6\u6709\u907f\u98ce\u6e2f\u4f5c\u7528\u3002", "conclusion": "\u5728\u9ad8\u5168\u7403\u7ecf\u6d4e\u4e0d\u786e\u5b9a\u6027\u65f6\uff0c\u5df4\u897f\u548c\u4e2d\u56fd\u5e02\u573a\u53ef\u901a\u8fc7\u6295\u8d44\u7ec4\u5408\u591a\u6837\u5316\u5e26\u6765\u663e\u8457\u6536\u76ca\u673a\u4f1a\u3002"}}
{"id": "2511.04782", "pdf": "https://arxiv.org/pdf/2511.04782", "abs": "https://arxiv.org/abs/2511.04782", "authors": ["Haochun Ma", "Jordan Roulleau-Pasdeloup"], "title": "Clearing Up the Effective Lower Bound Morass", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Depending on the persistence of the underlying Markov chain shock, the\nstandard New Keynesian model predicts starkly different conclusions at the\nEffective Lower Bound. We clear up this morass by using a truncated Markov\nchain. We prove that the expectations-driven trap \\`a la Mertens & Ravn (2014)\ndoesn't arise as an equilibrium outcome. In addition, the equilibrium under a\ntruncated Markov chain is guaranteed to be unique, the effect of government\nspending is positive on consumption and does not switch signs but may grow\nunbounded \\textemdash a puzzle.", "AI": {"tldr": "\u4f7f\u7528\u622a\u65ad\u9a6c\u5c14\u53ef\u592b\u94fe\u89e3\u51b3\u6807\u51c6\u65b0\u51ef\u6069\u65af\u6a21\u578b\u5728\u6709\u6548\u4e0b\u9650\u7684\u7ed3\u8bba\u56f0\u5883\uff0c\u8bc1\u660e\u7279\u5b9a\u9677\u9631\u4e0d\u4f1a\u51fa\u73b0\u4e14\u5747\u8861\u552f\u4e00\uff0c\u653f\u5e9c\u652f\u51fa\u6709\u79ef\u6781\u5f71\u54cd\u4f46\u5b58\u5728\u96be\u9898\u3002", "motivation": "\u6807\u51c6\u65b0\u51ef\u6069\u65af\u6a21\u578b\u5728\u6709\u6548\u4e0b\u9650\u56e0\u6f5c\u5728\u9a6c\u5c14\u53ef\u592b\u94fe\u51b2\u51fb\u6301\u4e45\u6027\u4e0d\u540c\u5f97\u51fa\u4e0d\u540c\u7ed3\u8bba\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u56f0\u5883\u3002", "method": "\u4f7f\u7528\u622a\u65ad\u9a6c\u5c14\u53ef\u592b\u94fe\u3002", "result": "\u8bc1\u660eMertens & Ravn (2014)\u63d0\u51fa\u7684\u9884\u671f\u9a71\u52a8\u9677\u9631\u4e0d\u4f1a\u4f5c\u4e3a\u5747\u8861\u7ed3\u679c\u51fa\u73b0\uff0c\u622a\u65ad\u9a6c\u5c14\u53ef\u592b\u94fe\u4e0b\u7684\u5747\u8861\u662f\u552f\u4e00\u7684\uff0c\u653f\u5e9c\u652f\u51fa\u5bf9\u6d88\u8d39\u6709\u79ef\u6781\u5f71\u54cd\u4e14\u4e0d\u6539\u53d8\u7b26\u53f7\uff0c\u4f46\u5f71\u54cd\u53ef\u80fd\u65e0\u754c\u589e\u957f\u3002", "conclusion": "\u4f7f\u7528\u622a\u65ad\u9a6c\u5c14\u53ef\u592b\u94fe\u80fd\u89e3\u51b3\u6a21\u578b\u56f0\u5883\uff0c\u4f46\u5b58\u5728\u653f\u5e9c\u652f\u51fa\u5f71\u54cd\u65e0\u754c\u589e\u957f\u7684\u96be\u9898\u3002"}}
{"id": "2511.05215", "pdf": "https://arxiv.org/pdf/2511.05215", "abs": "https://arxiv.org/abs/2511.05215", "authors": ["Varun Manjunath", "Pranav Ramesh", "Gopalakrishnan Srinivasan"], "title": "NeuroFlex: Column-Exact ANN-SNN Co-Execution Accelerator with Cost-Guided Scheduling", "categories": ["cs.NE", "cs.AR"], "comment": null, "summary": "NeuroFlex is a column-level accelerator that co-executes artificial and\nspiking neural networks to minimize energy-delay product on sparse edge\nworkloads with competitive accuracy. The design extends integer-exact QCFS\nANN-SNN conversion from layers to independent columns. It unifies INT8 storage\nwith on-the-fly spike generation using an offline cost model to assign columns\nto ANN or SNN cores and pack work across processing elements with deterministic\nruntime. Our cost-guided scheduling algorithm improves throughput by 16-19%\nover random mapping and lowers EDP by 57-67% versus a strong ANN-only baseline\nacross VGG-16, ResNet-34, GoogLeNet, and BERT models. NeuroFlex also delivers\nup to 2.5x speedup over LoAS and 2.51x energy reduction over SparTen. These\nresults indicate that fine-grained and integer-exact hybridization outperforms\nsingle-mode designs on energy and latency without sacrificing accuracy.", "AI": {"tldr": "NeuroFlex\u662f\u4e00\u79cd\u5217\u7ea7\u52a0\u901f\u5668\uff0c\u53ef\u5171\u540c\u6267\u884c\u4eba\u5de5\u548c\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u7a00\u758f\u8fb9\u7f18\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u5b9e\u73b0\u4f4e\u80fd\u8017\u5ef6\u8fdf\u79ef\u548c\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u7a00\u758f\u8fb9\u7f18\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u6700\u5c0f\u5316\u80fd\u91cf\u5ef6\u8fdf\u79ef\u5e76\u4fdd\u8bc1\u7ade\u4e89\u7cbe\u5ea6\u3002", "method": "\u5c06\u6574\u6570\u7cbe\u786e\u7684QCFS ANN - SNN\u8f6c\u6362\u4ece\u5c42\u6269\u5c55\u5230\u72ec\u7acb\u5217\uff0c\u7edf\u4e00INT8\u5b58\u50a8\u4e0e\u5b9e\u65f6\u5c16\u5cf0\u751f\u6210\uff0c\u4f7f\u7528\u79bb\u7ebf\u6210\u672c\u6a21\u578b\u5206\u914d\u5217\u5230ANN\u6216SNN\u6838\u5fc3\u5e76\u8de8\u5904\u7406\u5143\u7d20\u6253\u5305\u5de5\u4f5c\u3002", "result": "\u6210\u672c\u5bfc\u5411\u8c03\u5ea6\u7b97\u6cd5\u6bd4\u968f\u673a\u6620\u5c04\u63d0\u9ad8\u541e\u5410\u91cf16 - 19%\uff0c\u6bd4\u4ec5ANN\u57fa\u7ebf\u964d\u4f4eEDP 57 - 67%\uff0c\u6bd4LoAS\u52a0\u901f\u8fbe2.5\u500d\uff0c\u6bd4SparTen\u8282\u80fd2.51\u500d\u3002", "conclusion": "\u7ec6\u7c92\u5ea6\u548c\u6574\u6570\u7cbe\u786e\u7684\u6df7\u5408\u8bbe\u8ba1\u5728\u4e0d\u727a\u7272\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u80fd\u8017\u548c\u5ef6\u8fdf\u65b9\u9762\u4f18\u4e8e\u5355\u6a21\u5f0f\u8bbe\u8ba1\u3002"}}
{"id": "2511.04824", "pdf": "https://arxiv.org/pdf/2511.04824", "abs": "https://arxiv.org/abs/2511.04824", "authors": ["Kosei Horikawa", "Hao Li", "Yutaro Kashiwa", "Bram Adams", "Hajimu Iida", "Ahmed E. Hassan"], "title": "Agentic Refactoring: An Empirical Study of AI Coding Agents", "categories": ["cs.SE", "D.2.7"], "comment": "23 pages, 7 Tables, 5 Figuress, Submitted to ACM Transactions on\n  Software Engineering and Methodology(TOSEM)", "summary": "Agentic coding tools, such as OpenAI Codex, Claude Code, and Cursor, are\ntransforming the software engineering landscape. These AI-powered systems\nfunction as autonomous teammates capable of planning and executing complex\ndevelopment tasks. Agents have become active participants in refactoring, a\ncornerstone of sustainable software development aimed at improving internal\ncode quality without altering observable behavior. Despite their increasing\nadoption, there is a critical lack of empirical understanding regarding how\nagentic refactoring is utilized in practice, how it compares to human-driven\nrefactoring, and what impact it has on code quality. To address this empirical\ngap, we present a large-scale study of AI agent-generated refactorings in\nreal-world open-source Java projects, analyzing 15,451 refactoring instances\nacross 12,256 pull requests and 14,988 commits derived from the AIDev dataset.\nOur empirical analysis shows that refactoring is a common and intentional\nactivity in this development paradigm, with agents explicitly targeting\nrefactoring in 26.1% of commits. Analysis of refactoring types reveals that\nagentic efforts are dominated by low-level, consistency-oriented edits, such as\nChange Variable Type (11.8%), Rename Parameter (10.4%), and Rename Variable\n(8.5%), reflecting a preference for localized improvements over the high-level\ndesign changes common in human refactoring. Additionally, the motivations\nbehind agentic refactoring focus overwhelmingly on internal quality concerns,\nwith maintainability (52.5%) and readability (28.1%). Furthermore, quantitative\nevaluation of code quality metrics shows that agentic refactoring yields small\nbut statistically significant improvements in structural metrics, particularly\nfor medium-level changes, reducing class size and complexity (e.g., Class LOC\nmedian $\\Delta$ = -15.25).", "AI": {"tldr": "\u672c\u6587\u5bf9\u771f\u5b9e\u5f00\u6e90Java\u9879\u76ee\u4e2dAI\u4ee3\u7406\u751f\u6210\u7684\u91cd\u6784\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u5206\u679015451\u4e2a\u91cd\u6784\u5b9e\u4f8b\uff0c\u53d1\u73b0\u4ee3\u7406\u91cd\u6784\u5e38\u89c1\u4e14\u6709\u9488\u5bf9\u6027\uff0c\u591a\u4e3a\u4f4e\u5c42\u6b21\u4e00\u81f4\u6027\u7f16\u8f91\uff0c\u6ce8\u91cd\u5185\u90e8\u8d28\u91cf\uff0c\u80fd\u63d0\u5347\u4ee3\u7801\u7ed3\u6784\u6307\u6807\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9\u4ee3\u7406\u91cd\u6784\u5728\u5b9e\u8df5\u4e2d\u5982\u4f55\u4f7f\u7528\u3001\u4e0e\u4eba\u7c7b\u91cd\u6784\u5bf9\u6bd4\u53ca\u5bf9\u4ee3\u7801\u8d28\u91cf\u5f71\u54cd\u7684\u5b9e\u8bc1\u7406\u89e3\uff0c\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5bf9\u771f\u5b9e\u5f00\u6e90Java\u9879\u76ee\u4e2dAI\u4ee3\u7406\u751f\u6210\u7684\u91cd\u6784\u8fdb\u884c\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u5206\u6790\u6765\u81eaAIDev\u6570\u636e\u96c6\u768415451\u4e2a\u91cd\u6784\u5b9e\u4f8b\uff0c\u6d89\u53ca12256\u4e2a\u62c9\u53d6\u8bf7\u6c42\u548c14988\u4e2a\u63d0\u4ea4\u3002", "result": "\u91cd\u6784\u662f\u5e38\u89c1\u4e14\u6709\u610f\u7684\u6d3b\u52a8\uff0c\u4ee3\u7406\u572826.1%\u7684\u63d0\u4ea4\u4e2d\u660e\u786e\u9488\u5bf9\u91cd\u6784\uff1b\u4ee3\u7406\u91cd\u6784\u591a\u4e3a\u4f4e\u5c42\u6b21\u4e00\u81f4\u6027\u7f16\u8f91\uff1b\u52a8\u673a\u4e3b\u8981\u5173\u6ce8\u5185\u90e8\u8d28\u91cf\uff1b\u80fd\u5728\u7ed3\u6784\u6307\u6807\u4e0a\u6709\u5c0f\u4f46\u663e\u8457\u7684\u63d0\u5347\u3002", "conclusion": "\u4ee3\u7406\u91cd\u6784\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u8f83\u4e3a\u5e38\u89c1\uff0c\u504f\u597d\u4f4e\u5c42\u6b21\u5c40\u90e8\u6539\u8fdb\uff0c\u6ce8\u91cd\u5185\u90e8\u8d28\u91cf\uff0c\u5bf9\u4ee3\u7801\u7ed3\u6784\u6307\u6807\u6709\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2511.04686", "pdf": "https://arxiv.org/pdf/2511.04686", "abs": "https://arxiv.org/abs/2511.04686", "authors": ["Pratik Poudel"], "title": "Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "14 pages, 2 figures", "summary": "The Key-Value (KV) cache is integral to efficient autoregressive inference in\nlarge language models (LLMs), yet its unbounded growth in stateful multi-turn\nscenarios presents major challenges. This paper examines the interplay between\nKV cache management strategies, the architectural context limits of models like\nmeta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of\npositional encodings. Through empirical analysis using a stateful benchmarking\nframework, we show that LLM generation quality degrades sharply when the\naccumulated KV cache approaches or exceeds the model's trained context window\n(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory\nexhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via\nAttentionTop), can worsen performance if they disrupt positional coherence.\nBecause LLMs rely on consistent positional signals (e.g., RoPE), compacting a\ncache by removing non-contiguous tokens can scramble these signals and lead to\ndegenerative outputs. We further show that simple strategies preserving\ncontiguous context blocks (e.g., keeping an initial \"gist\") can yield more\ncoherent generations than complex or positionally disruptive ones. We advocate\nfor eviction techniques that respect architectural limits, preserve positional\nstructure, and view \"cache health\" holistically beyond mere size.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578bKV\u7f13\u5b58\u7ba1\u7406\u7b56\u7565\uff0c\u6307\u51fa\u7f13\u5b58\u63a5\u8fd1\u6216\u8d85\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\u751f\u6210\u8d28\u91cf\u4e0b\u964d\uff0c\u7b80\u5355\u4fdd\u7559\u8fde\u7eed\u4e0a\u4e0b\u6587\u5757\u7b56\u7565\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u89e3\u51b3\u6709\u72b6\u6001\u591a\u8f6e\u573a\u666f\u4e0bKV\u7f13\u5b58\u65e0\u754c\u589e\u957f\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u6709\u72b6\u6001\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "KV\u7f13\u5b58\u63a5\u8fd1\u6216\u8d85\u6a21\u578b\u8bad\u7ec3\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\u751f\u6210\u8d28\u91cf\u9aa4\u964d\uff1b\u5e38\u89c1\u9a71\u9010\u7b56\u7565\u7834\u574f\u4f4d\u7f6e\u8fde\u8d2f\u6027\u4f1a\u6076\u5316\u6027\u80fd\uff1b\u7b80\u5355\u4fdd\u7559\u8fde\u7eed\u4e0a\u4e0b\u6587\u5757\u7b56\u7565\u751f\u6210\u66f4\u8fde\u8d2f\u3002", "conclusion": "\u63d0\u5021\u5c0a\u91cd\u67b6\u6784\u9650\u5236\u3001\u4fdd\u7559\u4f4d\u7f6e\u7ed3\u6784\u3001\u5168\u9762\u770b\u5f85\u201c\u7f13\u5b58\u5065\u5eb7\u201d\u7684\u9a71\u9010\u6280\u672f\u3002"}}
{"id": "2511.05030", "pdf": "https://arxiv.org/pdf/2511.05030", "abs": "https://arxiv.org/abs/2511.05030", "authors": ["Panagiotis Papaioannou", "Athanassios N. Yannacopoulos"], "title": "The Shape of Markets: Machine learning modeling and Prediction Using 2-Manifold Geometries", "categories": ["q-fin.ST"], "comment": "Differential Geometry, Financial Forecasting, Manifold Learning,\n  2Manifolds, Uniformization Theorem, IS-LM Framework,Thurston Geometries", "summary": "We introduce a Geometry Informed Model for financial forecasting by embedding\nhigh dimensional market data onto constant curvature 2manifolds. Guided by the\nuniformization theorem, we model market dynamics as Brownian motion on\nspherical S2, Euclidean R2, and hyperbolic H2 geometries. We further include\nthe torus T, a compact, flat manifold admissible as a quotient space of the\nEuclidean plane anticipating its relevance for capturing cyclical dynamics.\nManifold learning techniques infer the latent curvature from financial data,\nrevealing the torus as the best performing geometry. We interpret this result\nthrough a macroeconomic lens, the torus circular dimensions align with\nendogenous cycles in output, interest rates, and inflation described by IS LM\ntheory. Our findings demonstrate the value of integrating differential geometry\nwith data-driven inference for financial modeling.", "AI": {"tldr": "\u5f15\u5165\u51e0\u4f55\u4fe1\u606f\u6a21\u578b\u7528\u4e8e\u91d1\u878d\u9884\u6d4b\uff0c\u5c06\u9ad8\u7ef4\u5e02\u573a\u6570\u636e\u5d4c\u5165\u5e38\u66f2\u7387\u4e8c\u7ef4\u6d41\u5f62\uff0c\u53d1\u73b0\u73af\u9762\u8868\u73b0\u6700\u4f73\uff0c\u8bc1\u660e\u5fae\u5206\u51e0\u4f55\u4e0e\u6570\u636e\u9a71\u52a8\u63a8\u7406\u7ed3\u5408\u5bf9\u91d1\u878d\u5efa\u6a21\u6709\u4ef7\u503c\u3002", "motivation": "\u4e3a\u91d1\u878d\u9884\u6d4b\u5f15\u5165\u65b0\u7684\u6a21\u578b\uff0c\u5229\u7528\u5fae\u5206\u51e0\u4f55\u6539\u8fdb\u91d1\u878d\u5efa\u6a21\u3002", "method": "\u5c06\u9ad8\u7ef4\u5e02\u573a\u6570\u636e\u5d4c\u5165\u7403\u9762S2\u3001\u6b27\u51e0\u91cc\u5f97\u5e73\u9762R2\u3001\u53cc\u66f2\u5e73\u9762H2\u548c\u73af\u9762T\u7b49\u4e8c\u7ef4\u6d41\u5f62\uff0c\u7528\u6d41\u5f62\u5b66\u4e60\u6280\u672f\u4ece\u91d1\u878d\u6570\u636e\u4e2d\u63a8\u65ad\u6f5c\u5728\u66f2\u7387\u3002", "result": "\u73af\u9762\u662f\u8868\u73b0\u6700\u4f73\u7684\u51e0\u4f55\u5f62\u72b6\u3002", "conclusion": "\u5fae\u5206\u51e0\u4f55\u4e0e\u6570\u636e\u9a71\u52a8\u63a8\u7406\u7ed3\u5408\u5bf9\u91d1\u878d\u5efa\u6a21\u6709\u4ef7\u503c\u3002"}}
{"id": "2511.04785", "pdf": "https://arxiv.org/pdf/2511.04785", "abs": "https://arxiv.org/abs/2511.04785", "authors": ["Luca Danese", "Riccardo Corradin", "Andrea Ongaro"], "title": "BayesChange: an R package for Bayesian Change Point Analysis", "categories": ["stat.CO"], "comment": null, "summary": "We introduce BayesChange, a computationally efficient R package, built on\nC++, for Bayesian change point detection and clustering of observations sharing\ncommon change points. While many R packages exist for change point analysis,\nBayesChange offers methods not currently available elsewhere. The core\nfunctions are implemented in C++ to ensures computational efficiency, while an\nR user interface simplifies the package usage. The BayesChange package includes\ntwo R wrappers that integrate the C++ backend functions, along with S3 methods\nfor summarizing the results. We present the theory beyond each method, the\nalgorithms for posterior simulation and we illustrate the package's usage\nthrough synthetic examples.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u57fa\u4e8eC++\u6784\u5efa\u7684\u8ba1\u7b97\u9ad8\u6548R\u5305BayesChange\uff0c\u7528\u4e8e\u8d1d\u53f6\u65af\u53d8\u70b9\u68c0\u6d4b\u548c\u805a\u7c7b\uff0c\u5c55\u793a\u7406\u8bba\u3001\u7b97\u6cd5\u5e76\u901a\u8fc7\u793a\u4f8b\u8bf4\u660e\u7528\u6cd5\u3002", "motivation": "\u73b0\u6709R\u5305\u4e2d\u7f3a\u5c11BayesChange\u63d0\u4f9b\u7684\u65b9\u6cd5\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u5305\u3002", "method": "\u6838\u5fc3\u51fd\u6570\u7528C++\u5b9e\u73b0\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\uff0c\u901a\u8fc7R\u7528\u6237\u754c\u9762\u7b80\u5316\u4f7f\u7528\uff0c\u5305\u542b\u4e24\u4e2a\u96c6\u6210C++\u540e\u7aef\u51fd\u6570\u7684R\u5305\u88c5\u5668\u548cS3\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u5f00\u53d1BayesChange\u5305\uff0c\u5e76\u53ef\u4ee5\u901a\u8fc7\u5408\u6210\u793a\u4f8b\u5c55\u793a\u5176\u4f7f\u7528\u3002", "conclusion": "BayesChange\u5305\u63d0\u4f9b\u4e86\u72ec\u7279\u7684\u65b9\u6cd5\uff0c\u4e14\u4f7f\u7528\u65b9\u4fbf\u3001\u8ba1\u7b97\u9ad8\u6548\u3002"}}
{"id": "2511.04873", "pdf": "https://arxiv.org/pdf/2511.04873", "abs": "https://arxiv.org/abs/2511.04873", "authors": ["Jordan Eckert", "Elvan Ceyhan", "Henry Schenck"], "title": "Prototype Selection Using Topological Data Analysis", "categories": ["stat.ML", "cs.LG"], "comment": "Code is found on www.github.com/JordanEckert", "summary": "Recently, there has been an explosion in statistical learning literature to\nrepresent data using topological principles to capture structure and\nrelationships. We propose a topological data analysis (TDA)-based framework,\nnamed Topological Prototype Selector (TPS), for selecting representative\nsubsets (prototypes) from large datasets. We demonstrate the effectiveness of\nTPS on simulated data under different data intrinsic characteristics, and\ncompare TPS against other currently used prototype selection methods in real\ndata settings. In all simulated and real data settings, TPS significantly\npreserves or improves classification performance while substantially reducing\ndata size. These contributions advance both algorithmic and geometric aspects\nof prototype learning and offer practical tools for parallelized,\ninterpretable, and efficient classification.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u6570\u636e\u5206\u6790\u7684\u6846\u67b6TPS\u9009\u62e9\u6570\u636e\u96c6\u539f\u578b\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u63a8\u52a8\u539f\u578b\u5b66\u4e60\u53d1\u5c55\u3002", "motivation": "\u5229\u7528\u62d3\u6251\u539f\u7406\u8868\u793a\u6570\u636e\u4ee5\u6355\u6349\u7ed3\u6784\u548c\u5173\u7cfb\uff0c\u89e3\u51b3\u4ece\u5927\u578b\u6570\u636e\u96c6\u4e2d\u9009\u62e9\u4ee3\u8868\u6027\u5b50\u96c6\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u62d3\u6251\u539f\u578b\u9009\u62e9\u5668\uff08TPS\uff09\u6846\u67b6\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e2d\uff0cTPS\u663e\u8457\u4fdd\u7559\u6216\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c0f\u6570\u636e\u89c4\u6a21\u3002", "conclusion": "\u8fd9\u4e9b\u8d21\u732e\u63a8\u52a8\u4e86\u539f\u578b\u5b66\u4e60\u7684\u7b97\u6cd5\u548c\u51e0\u4f55\u65b9\u9762\u53d1\u5c55\uff0c\u4e3a\u5206\u7c7b\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.04993", "pdf": "https://arxiv.org/pdf/2511.04993", "abs": "https://arxiv.org/abs/2511.04993", "authors": ["Yanru Guan", "Jiahao Zhang", "Zhe Feng", "Tao Lin"], "title": "On the Coordination of Value-Maximizing Bidders", "categories": ["cs.GT"], "comment": null, "summary": "While the auto-bidding literature predominantly considers independent\nbidding, we investigate the coordination problem among multiple auto-bidders in\nonline advertising platforms. Two motivating scenarios are: collaborative\nbidding among multiple distinct bidders managed by a third-party bidding agent,\nand strategic bid selection for multiple ad campaigns managed by a single\nadvertiser. We formalize this coordination problem as a theoretical model and\ndemonstrate that a straightforward coordination mechanism, where only the\nhighest-value bidder competes with outside bids, strictly dominates independent\nbidding, improving both Return-on-Spend (RoS) compliance and the total value\naccrued for each participating auto-bidder or ad campaign. Additionally, our\nsimulations on synthetic and real-world datasets support the theoretical result\nthat coordinated mechanism outperforms independent bidding. These findings\nhighlight both the theoretical potential and the practical robustness of\ncoordination in auto-bidding in online auctions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u7ebf\u5e7f\u544a\u5e73\u53f0\u4e2d\u591a\u4e2a\u81ea\u52a8\u51fa\u4ef7\u8005\u7684\u534f\u8c03\u95ee\u9898\uff0c\u8bc1\u660e\u534f\u8c03\u673a\u5236\u4f18\u4e8e\u72ec\u7acb\u51fa\u4ef7\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u51fa\u4ef7\u6587\u732e\u591a\u8003\u8651\u72ec\u7acb\u51fa\u4ef7\uff0c\u672c\u6587\u7814\u7a76\u591a\u4e2a\u81ea\u52a8\u51fa\u4ef7\u8005\u7684\u534f\u8c03\u95ee\u9898\uff0c\u4ee5\u7b2c\u4e09\u65b9\u4ee3\u7406\u7ba1\u7406\u7684\u591a\u4e2a\u51fa\u4ef7\u8005\u534f\u4f5c\u51fa\u4ef7\u548c\u5355\u4e2a\u5e7f\u544a\u5546\u7ba1\u7406\u7684\u591a\u4e2a\u5e7f\u544a\u6d3b\u52a8\u6218\u7565\u51fa\u4ef7\u4e3a\u573a\u666f\u3002", "method": "\u5c06\u534f\u8c03\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u7406\u8bba\u6a21\u578b\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6a21\u62df\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u4ec5\u6700\u9ad8\u4ef7\u503c\u51fa\u4ef7\u8005\u4e0e\u5916\u90e8\u51fa\u4ef7\u7ade\u4e89\u7684\u534f\u8c03\u673a\u5236\u4e25\u683c\u4f18\u4e8e\u72ec\u7acb\u51fa\u4ef7\uff1b\u6a21\u62df\u7ed3\u679c\u652f\u6301\u534f\u8c03\u673a\u5236\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u5728\u7ebf\u62cd\u5356\u81ea\u52a8\u51fa\u4ef7\u4e2d\u534f\u8c03\u673a\u5236\u5177\u6709\u7406\u8bba\u6f5c\u529b\u548c\u5b9e\u9645\u7a33\u5065\u6027\u3002"}}
{"id": "2511.05053", "pdf": "https://arxiv.org/pdf/2511.05053", "abs": "https://arxiv.org/abs/2511.05053", "authors": ["Wakuto Matsumi", "Riaz-Ul-Haque Mian"], "title": "Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs", "categories": ["cs.DC", "cs.AI", "cs.GR"], "comment": null, "summary": "Machine learning based on neural networks has advanced rapidly, but the high\nenergy consumption required for training and inference remains a major\nchallenge. Hyperdimensional Computing (HDC) offers a lightweight,\nbrain-inspired alternative that enables high parallelism but often suffers from\nlower accuracy on complex visual tasks. To overcome this, hybrid accelerators\ncombining HDC and Convolutional Neural Networks (CNNs) have been proposed,\nthough their adoption is limited by poor generalizability and programmability.\nThe rise of open-source RISC-V architectures has created new opportunities for\ndomain-specific GPU design. Unlike traditional proprietary GPUs, emerging\nRISC-V-based GPUs provide flexible, programmable platforms suitable for custom\ncomputation models such as HDC. In this study, we design and implement custom\nGPU instructions optimized for HDC operations, enabling efficient processing\nfor hybrid HDC-CNN workloads. Experimental results using four types of custom\nHDC instructions show a performance improvement of up to 56.2 times in\nmicrobenchmark tests, demonstrating the potential of RISC-V GPUs for\nenergy-efficient, high-performance computing.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u5b9e\u73b0\u9488\u5bf9HDC\u64cd\u4f5c\u4f18\u5316\u7684\u5b9a\u5236GPU\u6307\u4ee4\uff0c\u7528\u4e8e\u6df7\u5408HDC - CNN\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u5927\u5e45\u63d0\u5347\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u673a\u5668\u5b66\u4e60\u80fd\u8017\u9ad8\uff0cHDC\u7cbe\u5ea6\u4f4e\uff0c\u6df7\u5408\u52a0\u901f\u5668\u901a\u7528\u6027\u548c\u53ef\u7f16\u7a0b\u6027\u5dee\uff0cRISC - V\u67b6\u6784\u4e3a\u7279\u5b9a\u9886\u57dfGPU\u8bbe\u8ba1\u5e26\u6765\u65b0\u673a\u9047\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u9488\u5bf9HDC\u64cd\u4f5c\u4f18\u5316\u7684\u5b9a\u5236GPU\u6307\u4ee4\uff0c\u7528\u4e8e\u5904\u7406\u6df7\u5408HDC - CNN\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "\u4f7f\u7528\u56db\u79cd\u5b9a\u5236HDC\u6307\u4ee4\u7684\u5b9e\u9a8c\u5728\u5fae\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63d0\u5347\u8fbe56.2\u500d\u3002", "conclusion": "RISC - V GPU\u5728\u8282\u80fd\u9ad8\u6027\u80fd\u8ba1\u7b97\u65b9\u9762\u6709\u6f5c\u529b\u3002"}}
{"id": "2511.04826", "pdf": "https://arxiv.org/pdf/2511.04826", "abs": "https://arxiv.org/abs/2511.04826", "authors": ["Sanjeev Khanna", "Aaron Putterman", "Junkai Song"], "title": "Optimal Parallel Basis Finding in Graphic and Related Matroids", "categories": ["cs.DS", "cs.CC"], "comment": null, "summary": "We study the parallel complexity of finding a basis of a graphic matroid\nunder independence-oracle access. Karp, Upfal, and Wigderson (FOCS 1985, JCSS\n1988) initiated the study of this problem and established two algorithms for\nfinding a spanning forest: one running in $O(\\log m)$ rounds with\n$m^{\\Theta(\\log m)}$ queries, and another, for any $d \\in \\mathbb{Z}^+$,\nrunning in $O(m^{2/d})$ rounds with $\\Theta(m^d)$ queries. A key open question\nthey posed was whether one could simultaneously achieve polylogarithmic rounds\nand polynomially many queries. We give a deterministic algorithm that uses\n$O(\\log m)$ adaptive rounds and $\\mathrm{poly}(m)$ non-adaptive queries per\nround to return a spanning forest on $m$ edges, and complement this result with\na matching $\\Omega(\\log m)$ lower bound for any (even randomized) algorithm\nwith $\\mathrm{poly}(m)$ queries per round. Thus, the adaptive round complexity\nfor graphic matroids is characterized exactly, settling this long-standing\nproblem. Beyond graphs, we show that our framework also yields an $O(\\log\nm)$-round, $\\mathrm{poly}(m)$-query algorithm for any binary matroid satisfying\na smooth circuit counting property, implying, among others, an optimal $O(\\log\nm)$-round parallel algorithms for finding bases of cographic matroids.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u56fe\u62df\u9635\u57fa\u7684\u5e76\u884c\u590d\u6742\u5ea6\uff0c\u7ed9\u51fa\u786e\u5b9a\u6027\u7b97\u6cd5\u89e3\u51b3\u957f\u671f\u672a\u51b3\u95ee\u9898\uff0c\u5e76\u5c06\u6846\u67b6\u62d3\u5c55\u5230\u6ee1\u8db3\u7279\u5b9a\u6027\u8d28\u7684\u4e8c\u5143\u62df\u9635\u3002", "motivation": "Karp\u7b49\u4eba\u63d0\u51fa\u80fd\u5426\u540c\u65f6\u5b9e\u73b0\u5bf9\u6570\u8f6e\u6570\u548c\u591a\u9879\u5f0f\u67e5\u8be2\u6570\u7684\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u7ed9\u51fa\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4f7f\u7528O(log m)\u81ea\u9002\u5e94\u8f6e\u6570\u548c\u6bcf\u8f6epoly(m)\u975e\u81ea\u9002\u5e94\u67e5\u8be2\u6765\u8fd4\u56de\u751f\u6210\u68ee\u6797\uff0c\u5e76\u7ed9\u51fa\u5339\u914d\u7684\u4e0b\u754c\u3002", "result": "\u5f97\u5230\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u540c\u65f6\u6709\u5339\u914d\u7684\u4e0b\u754c\uff0c\u89e3\u51b3\u957f\u671f\u95ee\u9898\uff0c\u4e14\u6846\u67b6\u53ef\u62d3\u5c55\u5230\u6ee1\u8db3\u7279\u5b9a\u6027\u8d28\u7684\u4e8c\u5143\u62df\u9635\u3002", "conclusion": "\u7cbe\u786e\u523b\u753b\u56fe\u62df\u9635\u7684\u81ea\u9002\u5e94\u8f6e\u590d\u6742\u5ea6\uff0c\u6846\u67b6\u53ef\u7528\u4e8e\u6ee1\u8db3\u5e73\u6ed1\u56de\u8def\u8ba1\u6570\u6027\u8d28\u7684\u4e8c\u5143\u62df\u9635\u3002"}}
{"id": "2511.04855", "pdf": "https://arxiv.org/pdf/2511.04855", "abs": "https://arxiv.org/abs/2511.04855", "authors": ["Vojtech Franc", "Jakub Paplham"], "title": "Epistemic Reject Option Prediction", "categories": ["cs.AI"], "comment": null, "summary": "In high-stakes applications, predictive models must not only produce accurate\npredictions but also quantify and communicate their uncertainty. Reject-option\nprediction addresses this by allowing the model to abstain when prediction\nuncertainty is high. Traditional reject-option approaches focus solely on\naleatoric uncertainty, an assumption valid only when large training data makes\nthe epistemic uncertainty negligible. However, in many practical scenarios,\nlimited data makes this assumption unrealistic. This paper introduces the\nepistemic reject-option predictor, which abstains in regions of high epistemic\nuncertainty caused by insufficient data. Building on Bayesian learning, we\nredefine the optimal predictor as the one that minimizes expected regret -- the\nperformance gap between the learned model and the Bayes-optimal predictor with\nfull knowledge of the data distribution. The model abstains when the regret for\na given input exceeds a specified rejection cost. To our knowledge, this is the\nfirst principled framework that enables learning predictors capable of\nidentifying inputs for which the training data is insufficient to make reliable\ndecisions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8ba4\u77e5\u62d2\u7edd\u9009\u9879\u9884\u6d4b\u5668\uff0c\u57fa\u4e8e\u8d1d\u53f6\u65af\u5b66\u4e60\uff0c\u4ee5\u6700\u5c0f\u5316\u9884\u671f\u9057\u61be\u4e3a\u76ee\u6807\uff0c\u5728\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u5bfc\u81f4\u9ad8\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u533a\u57df\u9009\u62e9\u5f03\u6743\u3002", "motivation": "\u4f20\u7edf\u62d2\u7edd\u9009\u9879\u65b9\u6cd5\u4ec5\u5173\u6ce8\u5076\u7136\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5b9e\u9645\u6570\u636e\u6709\u9650\u573a\u666f\u4e0b\u4e0d\u9002\u7528\uff0c\u9700\u8003\u8651\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u5b66\u4e60\uff0c\u5c06\u6700\u4f18\u9884\u6d4b\u5668\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6700\u5c0f\u5316\u9884\u671f\u9057\u61be\u7684\u9884\u6d4b\u5668\uff0c\u5f53\u8f93\u5165\u7684\u9057\u61be\u8d85\u8fc7\u6307\u5b9a\u62d2\u7edd\u6210\u672c\u65f6\u5f03\u6743\u3002", "result": "\u63d0\u51fa\u4e86\u8ba4\u77e5\u62d2\u7edd\u9009\u9879\u9884\u6d4b\u5668\u8fd9\u4e00\u6846\u67b6\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u80fd\u8ba9\u9884\u6d4b\u5668\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u4ee5\u505a\u51fa\u53ef\u9760\u51b3\u7b56\u7684\u8f93\u5165\u7684\u539f\u5219\u6027\u6846\u67b6\u3002"}}
{"id": "2511.04939", "pdf": "https://arxiv.org/pdf/2511.04939", "abs": "https://arxiv.org/abs/2511.04939", "authors": ["Harshit Nainwani", "Hediyeh Baban"], "title": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG", "categories": ["cs.IR", "cs.AI"], "comment": "22 pages, 2 figures, technical framework paper", "summary": "Retrieval systems are essential to contemporary AI pipelines, although most\nconfuse two separate processes: finding relevant information and giving enough\ncontext for reasoning. We introduce the Search-Is-Not-Retrieve (SINR)\nframework, a dual-layer architecture that distinguishes between fine-grained\nsearch representations and coarse-grained retrieval contexts. SINR enhances the\ncomposability, scalability, and context fidelity of retrieval systems by\ndirectly connecting small, semantically accurate search chunks to larger,\ncontextually complete retrieve chunks, all without incurring extra processing\ncosts. This design changes retrieval from a passive step to an active one,\nmaking the system architecture more like how people process information. We\ndiscuss the SINR framework's conceptual foundation, formal structure,\nimplementation issues, and qualitative outcomes. This provides a practical\nfoundation for the next generation of AI systems that use retrieval.", "AI": {"tldr": "\u4ecb\u7ecdSINR\u6846\u67b6\uff0c\u53ef\u589e\u5f3a\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u68c0\u7d22\u7cfb\u7edf\u6df7\u6dc6\u641c\u7d22\u548c\u63a8\u7406\u4e0a\u4e0b\u6587\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165SINR\u53cc\u5c42\u6b21\u67b6\u6784\uff0c\u533a\u5206\u7ec6\u7c92\u5ea6\u641c\u7d22\u8868\u793a\u548c\u7c97\u7c92\u5ea6\u68c0\u7d22\u4e0a\u4e0b\u6587\u3002", "result": "\u589e\u5f3a\u68c0\u7d22\u7cfb\u7edf\u7684\u53ef\u7ec4\u5408\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\uff0c\u4f7f\u68c0\u7d22\u4ece\u88ab\u52a8\u53d8\u4e3a\u4e3b\u52a8\u3002", "conclusion": "\u4e3a\u4e0b\u4e00\u4ee3\u4f7f\u7528\u68c0\u7d22\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2511.04912", "pdf": "https://arxiv.org/pdf/2511.04912", "abs": "https://arxiv.org/abs/2511.04912", "authors": ["Dongyoung Kim", "Young-Il Albert Kim", "Haedong Aiden Rho"], "title": "Election and Subjective Well-Being:Evidence from the 2024 U.S. Presidential Election", "categories": ["econ.GN", "q-fin.EC"], "comment": "21 pages. Also posted on SSRN and MRPA", "summary": "This paper uses daily Behavioral Risk Factor Surveillance System data to\nestimate the causal effect of the 2024 U.S. presidential election, a highly\ncompetitive race whose outcome resolved lingering uncertainty on election day,\non mental-health and life-satisfaction outcomes through a regression\ndiscontinuity design. Following the resolution of electoral uncertainty on\nelection day, we find a sharp and persistent post-election decline in\nsubjective well-being, concentrated among female, non-White, urban, and\nmore-educated respondents. These findings reveal an expected-outcome shock,\nshowing that political polarization itself, not electoral surprise, can act as\na chronic psychological stressor.", "AI": {"tldr": "\u672c\u6587\u7528\u884c\u4e3a\u98ce\u9669\u56e0\u7d20\u76d1\u6d4b\u7cfb\u7edf\u6570\u636e\uff0c\u901a\u8fc7\u65ad\u70b9\u56de\u5f52\u8bbe\u8ba1\u8bc4\u4f302024\u5e74\u7f8e\u56fd\u5927\u9009\u5bf9\u5fc3\u7406\u5065\u5eb7\u548c\u751f\u6d3b\u6ee1\u610f\u5ea6\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u53d1\u73b0\u5927\u9009\u540e\u4e3b\u89c2\u5e78\u798f\u611f\u4e0b\u964d\uff0c\u63ed\u793a\u653f\u6cbb\u6781\u5316\u662f\u5fc3\u7406\u538b\u529b\u6e90\u3002", "motivation": "\u8bc4\u4f302024\u5e74\u7f8e\u56fd\u5927\u9009\u8fd9\u4e00\u7ade\u4e89\u6fc0\u70c8\u4e14\u7ed3\u679c\u6d88\u9664\u4e0d\u786e\u5b9a\u6027\u7684\u4e8b\u4ef6\uff0c\u5bf9\u6c11\u4f17\u5fc3\u7406\u5065\u5eb7\u548c\u751f\u6d3b\u6ee1\u610f\u5ea6\u7684\u5f71\u54cd\u3002", "method": "\u8fd0\u7528\u6bcf\u65e5\u884c\u4e3a\u98ce\u9669\u56e0\u7d20\u76d1\u6d4b\u7cfb\u7edf\u6570\u636e\uff0c\u91c7\u7528\u65ad\u70b9\u56de\u5f52\u8bbe\u8ba1\u3002", "result": "\u5927\u9009\u7ed3\u679c\u786e\u5b9a\u540e\uff0c\u4e3b\u89c2\u5e78\u798f\u611f\u51fa\u73b0\u6025\u5267\u4e14\u6301\u7eed\u7684\u4e0b\u964d\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u5973\u6027\u3001\u975e\u767d\u4eba\u3001\u57ce\u5e02\u548c\u9ad8\u5b66\u5386\u53d7\u8bbf\u8005\u4e2d\u3002", "conclusion": "\u653f\u6cbb\u6781\u5316\u672c\u8eab\u800c\u975e\u9009\u4e3e\u610f\u5916\uff0c\u53ef\u6210\u4e3a\u957f\u671f\u7684\u5fc3\u7406\u538b\u529b\u6e90\u3002"}}
{"id": "2511.05479", "pdf": "https://arxiv.org/pdf/2511.05479", "abs": "https://arxiv.org/abs/2511.05479", "authors": ["Alperen Aksoy", "Ilja Bekman", "Chimezie Eguzo", "Christian Grewing", "Andre Zambanini"], "title": "FPGA-Based Real-Time Waveform Classification", "categories": ["cs.NE", "physics.ins-det"], "comment": "TWEPP25 proceedings paper pre-print", "summary": "For self-triggered readout of SiPM sum signals, a waveform classification can\naid a simple threshold trigger to reliably extract calorimetric particle hit\ninformation online at an early stage and thus reduce the volume of transmitted\ndata. Typically, the ADC data acquisition is based on FPGAs for edge data\nprocessing. In this study, we consider look-up-table-based neural-networks and\naddress challenges of binary multi-layer neural networks' layout, footprint,\nperformance and training. We show that these structures can be trained using a\ngenetic algorithm and achieve the inference latency compatible with dead-time\nfree processing online.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u67e5\u627e\u8868\u7684\u795e\u7ecf\u7f51\u7edc\u7528\u4e8eSiPM\u548c\u4fe1\u53f7\u81ea\u89e6\u53d1\u8bfb\u51fa\uff0c\u53ef\u65e9\u671f\u63d0\u53d6\u4fe1\u606f\u5e76\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u91cf\uff0c\u4e14\u80fd\u5b9e\u73b0\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u5b9e\u73b0SiPM\u548c\u4fe1\u53f7\u81ea\u89e6\u53d1\u8bfb\u51fa\uff0c\u65e9\u671f\u53ef\u9760\u63d0\u53d6\u7c92\u5b50\u51fb\u4e2d\u4fe1\u606f\u5e76\u51cf\u5c11\u4f20\u8f93\u6570\u636e\u91cf\u3002", "method": "\u8003\u8651\u57fa\u4e8e\u67e5\u627e\u8868\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u9057\u4f20\u7b97\u6cd5\u8bad\u7ec3\u3002", "result": "\u8fd9\u4e9b\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u80fd\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e0e\u65e0\u6b7b\u533a\u65f6\u95f4\u5728\u7ebf\u5904\u7406\u517c\u5bb9\u7684\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "\u57fa\u4e8e\u67e5\u627e\u8868\u7684\u795e\u7ecf\u7f51\u7edc\u53ef\u7528\u4e8eSiPM\u548c\u4fe1\u53f7\u81ea\u89e6\u53d1\u8bfb\u51fa\uff0c\u5728\u6570\u636e\u5904\u7406\u65b9\u9762\u6709\u826f\u597d\u8868\u73b0\u3002"}}
{"id": "2511.04849", "pdf": "https://arxiv.org/pdf/2511.04849", "abs": "https://arxiv.org/abs/2511.04849", "authors": ["Quang-Dung Nguyen", "Tri-Dung Tran", "Thanh-Hieu Chu", "Hoang-Loc Tran", "Xiangwei Cheng", "Dirk Slama"], "title": "Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach", "categories": ["cs.SE", "cs.AI", "I.2.6; I.2.7; D.2.3"], "comment": "6 pages, 3 figures", "summary": "The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in\nthe automotive industry, where software now plays a pivotal role in defining\nvehicle functionality, enabling rapid innovation of modern vehicles. Developing\nSDV-specific applications demands advanced tools to streamline code generation\nand improve development efficiency. In recent years, general-purpose large\nlanguage models (LLMs) have demonstrated transformative potential across\ndomains. Still, restricted access to proprietary model architectures hinders\ntheir adaption to specific tasks like SDV code generation. In this study, we\npropose using prompts, a common and basic strategy to interact with LLMs and\nredirect their responses. Using only system prompts with an appropriate and\nefficient prompt structure designed using advanced prompt engineering\ntechniques, LLMs can be crafted without requiring a training session or access\nto their base design. This research investigates the extensive experiments on\ndifferent models by applying various prompting techniques, including bare\nmodels, using a benchmark specifically created to evaluate LLMs' performance in\ngenerating SDV code. The results reveal that the model with a few-shot\nprompting strategy outperforms the others in adjusting the LLM answers to match\nthe expected outcomes based on quantitative metrics.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u7528\u63d0\u793a\u7b56\u7565\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\uff08SDV\uff09\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u7ecf\u5b9e\u9a8c\u53d1\u73b0\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "SDV \u5e94\u7528\u5f00\u53d1\u9700\u5148\u8fdb\u5de5\u5177\u63d0\u5347\u6548\u7387\uff0c\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u4e13\u6709\u67b6\u6784\u8bbf\u95ee\u53d7\u9650\u96be\u7528\u4e8e SDV \u4ee3\u7801\u751f\u6210\u3002", "method": "\u91c7\u7528\u63d0\u793a\u7b56\u7565\uff0c\u5229\u7528\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u8bbe\u8ba1\u5408\u9002\u9ad8\u6548\u7684\u7cfb\u7edf\u63d0\u793a\u7ed3\u6784\uff0c\u5bf9\u4e0d\u540c\u6a21\u578b\u5e94\u7528\u591a\u79cd\u63d0\u793a\u6280\u672f\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u57fa\u4e8e\u5b9a\u91cf\u6307\u6807\uff0c\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u7684\u6a21\u578b\u5728\u8c03\u6574\u5927\u8bed\u8a00\u6a21\u578b\u7b54\u6848\u4ee5\u5339\u914d\u9884\u671f\u7ed3\u679c\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "\u4f7f\u7528\u63d0\u793a\u7b56\u7565\u53ef\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u9002\u5e94 SDV \u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u6548\u679c\u66f4\u597d\u3002"}}
{"id": "2511.04718", "pdf": "https://arxiv.org/pdf/2511.04718", "abs": "https://arxiv.org/abs/2511.04718", "authors": ["Yue Xun", "Jiaxing Xu", "Wenbo Gao", "Chen Yang", "Shujun Wang"], "title": "Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "11 pages, 2 figures, conference", "summary": "Resting-state fMRI has become a valuable tool for classifying brain disorders\nand constructing brain functional connectivity networks\n  by tracking BOLD signals across brain regions. However, existing mod els\nlargely neglect the multi-frequency nature of neuronal oscillations,\n  treating BOLD signals as monolithic time series. This overlooks the cru cial\nfact that neurological disorders often manifest as disruptions within\n  specific frequency bands, limiting diagnostic sensitivity and specificity.\n  While some methods have attempted to incorporate frequency informa tion, they\noften rely on predefined frequency bands, which may not be\n  optimal for capturing individual variability or disease-specific alterations.\n  To address this, we propose a novel framework featuring Adaptive Cas cade\nDecomposition to learn task-relevant frequency sub-bands for each\n  brain region and Frequency-Coupled Connectivity Learning to capture\n  both intra- and nuanced cross-band interactions in a unified functional\n  network. This unified network informs a novel message-passing mecha nism\nwithin our Unified-GCN, generating refined node representations\n  for diagnostic prediction. Experimental results on the ADNI and ABIDE\n  datasets demonstrate superior performance over existing methods. The\n  code is available at https://github.com/XXYY20221234/Ada-FCN.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u6846\u67b6Ada - FCN\u5206\u6790\u9759\u606f\u6001fMRI\uff0c\u5728ADNI\u548cABIDE\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5ffd\u89c6\u795e\u7ecf\u5143\u632f\u8361\u591a\u9891\u7279\u6027\uff0c\u5904\u7406BOLD\u4fe1\u53f7\u5b58\u5728\u5c40\u9650\uff0c\u5df2\u6709\u9891\u57df\u65b9\u6cd5\u4f7f\u7528\u9884\u5b9a\u4e49\u9891\u6bb5\u6709\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u7ea7\u8054\u5206\u89e3\u5b66\u4e60\u6bcf\u4e2a\u8111\u533a\u76f8\u5173\u9891\u7387\u5b50\u5e26\uff0c\u9891\u7387\u8026\u5408\u8fde\u63a5\u5b66\u4e60\u6784\u5efa\u7edf\u4e00\u529f\u80fd\u7f51\u7edc\uff0c\u7ed3\u5408\u7edf\u4e00GCN\u4e2d\u7684\u6d88\u606f\u4f20\u9012\u673a\u5236\u8fdb\u884c\u8bca\u65ad\u9884\u6d4b\u3002", "result": "\u5728ADNI\u548cABIDE\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u65b0\u6846\u67b6Ada - FCN\u6709\u6548\u4e14\u53ef\u884c\uff0c\u5728\u8111\u75be\u75c5\u8bca\u65ad\u4e2d\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.05463", "pdf": "https://arxiv.org/pdf/2511.05463", "abs": "https://arxiv.org/abs/2511.05463", "authors": ["Manan Vyas", "M. Mija\u00edl Mart\u00ednez-Ramos", "Parisa Majari", "Thomas H. Seligman"], "title": "From sectorial coarse graining to extreme coarse graining of S&P 500 correlation matrices", "categories": ["q-fin.ST", "physics.data-an"], "comment": "18 pages, 11 figures", "summary": "Starting from the Pearson Correlation Matrix of stock returns and from the\ndesire to obtain a reduced number of parameters relevant for the dynamics of a\nfinancial market, we propose to take the idea of a sectorial matrix, which\nwould have a large number of parameters, to the reduced picture of a real\nsymmetric $2 \\times 2$ matrix, extreme case, that still conserves the desirable\nfeature that the average correlation can be one of the parameters. This is\nachieved by averaging the correlation matrix over blocks created by choosing\ntwo subsets of stocks for rows and columns and averaging over each of the\nresulting blocks. Averaging over these blocks, we retain the average of the\ncorrelation matrix. We shall use a random selection for two equal block sizes\nas well as two specific, hopefully relevant, ones that do not produce equal\nblock sizes. The results show that one of the non-random choices has somewhat\ndifferent properties, whose meaning will have to be analyzed from an economy\npoint of view.", "AI": {"tldr": "\u4ece\u80a1\u7968\u6536\u76ca\u7684\u76ae\u5c14\u900a\u76f8\u5173\u77e9\u9635\u51fa\u53d1\uff0c\u5c06\u90e8\u95e8\u77e9\u9635\u7406\u5ff5\u7b80\u5316\u4e3a2x2\u5bf9\u79f0\u77e9\u9635\uff0c\u901a\u8fc7\u5206\u5757\u5e73\u5747\u4fdd\u7559\u5e73\u5747\u76f8\u5173\u6027\uff0c\u7528\u968f\u673a\u548c\u7279\u5b9a\u9009\u62e9\u5206\u5757\uff0c\u7ed3\u679c\u663e\u793a\u4e00\u79cd\u975e\u968f\u673a\u9009\u62e9\u6709\u4e0d\u540c\u7279\u6027\u5f85\u7ecf\u6d4e\u5206\u6790\u3002", "motivation": "\u4ece\u80a1\u7968\u6536\u76ca\u7684\u76ae\u5c14\u900a\u76f8\u5173\u77e9\u9635\u51fa\u53d1\uff0c\u5e0c\u671b\u51cf\u5c11\u4e0e\u91d1\u878d\u5e02\u573a\u52a8\u6001\u76f8\u5173\u7684\u53c2\u6570\u6570\u91cf\u3002", "method": "\u5c06\u90e8\u95e8\u77e9\u9635\u7b80\u5316\u4e3a2x2\u5b9e\u5bf9\u79f0\u77e9\u9635\uff0c\u901a\u8fc7\u5bf9\u9009\u62e9\u7684\u4e24\u7ec4\u80a1\u7968\u5b50\u96c6\u884c\u548c\u5217\u6784\u6210\u7684\u5757\u8fdb\u884c\u5e73\u5747\uff0c\u4fdd\u7559\u76f8\u5173\u77e9\u9635\u7684\u5e73\u5747\u503c\uff0c\u91c7\u7528\u968f\u673a\u9009\u62e9\u76f8\u540c\u5757\u5927\u5c0f\u548c\u4e24\u79cd\u7279\u5b9a\u975e\u7b49\u5757\u5927\u5c0f\u9009\u62e9\u3002", "result": "\u4e00\u79cd\u975e\u968f\u673a\u9009\u62e9\u6709\u4e0d\u540c\u7279\u6027\u3002", "conclusion": "\u8be5\u975e\u968f\u673a\u9009\u62e9\u7279\u6027\u7684\u610f\u4e49\u9700\u4ece\u7ecf\u6d4e\u5b66\u89d2\u5ea6\u5206\u6790\u3002"}}
{"id": "2511.04833", "pdf": "https://arxiv.org/pdf/2511.04833", "abs": "https://arxiv.org/abs/2511.04833", "authors": ["Krystyna Grzesiak", "Christophe Muller", "Julie Josse", "Jeffrey N\u00e4f"], "title": "Do we Need Dozens of Methods for Real World Missing Value Imputation?", "categories": ["stat.CO"], "comment": null, "summary": "Missing values pose a persistent challenge in modern data science.\nConsequently, there is an ever-growing number of publications introducing new\nimputation methods in various fields. While many studies compare imputation\napproaches, they often focus on a limited subset of algorithms and evaluate\nperformance primarily through pointwise metrics such as RMSE, which are not\nsuitable to measure the preservation of the true data distribution. In this\nwork, we provide a systematic benchmarking method based on the idea of treating\nimputation as a distributional prediction task. We consider a large number of\nalgorithms and, for the first time, evaluate them not only on synthetic missing\nmechanisms, but also on real-world missingness scenarios, using the concept of\nImputation Scores. Finally, while the focus of previous benchmark has often\nbeen on numerical data, we also consider mixed data sets in our study. The\nanalysis overwhelmingly confirms the superiority of iterative imputation\nalgorithms, especially the methods implemented in the mice R package.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6570\u636e\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u5206\u5e03\u9884\u6d4b\u4efb\u52a1\u7684\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5927\u91cf\u7b97\u6cd5\uff0c\u8003\u8651\u771f\u5b9e\u7f3a\u5931\u573a\u666f\u548c\u6df7\u5408\u6570\u636e\u96c6\uff0c\u5206\u6790\u8868\u660e\u8fed\u4ee3\u63d2\u8865\u7b97\u6cd5\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u7f3a\u5931\u503c\u63d2\u8865\u65b9\u6cd5\u6bd4\u8f83\u7814\u7a76\u5b58\u5728\u5173\u6ce8\u7b97\u6cd5\u6709\u9650\u3001\u8bc4\u4f30\u6307\u6807\u4e0d\u9002\u5408\u8861\u91cf\u6570\u636e\u5206\u5e03\u4fdd\u7559\u60c5\u51b5\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u597d\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u5c06\u63d2\u8865\u89c6\u4e3a\u5206\u5e03\u9884\u6d4b\u4efb\u52a1\uff0c\u91c7\u7528\u63d2\u8865\u5206\u6570\u7684\u6982\u5ff5\uff0c\u8bc4\u4f30\u5927\u91cf\u7b97\u6cd5\uff0c\u4e0d\u4ec5\u8003\u8651\u5408\u6210\u7f3a\u5931\u673a\u5236\uff0c\u8fd8\u8003\u8651\u771f\u5b9e\u4e16\u754c\u7f3a\u5931\u573a\u666f\uff0c\u540c\u65f6\u7814\u7a76\u6df7\u5408\u6570\u636e\u96c6\u3002", "result": "\u5206\u6790\u7ed3\u679c\u538b\u5012\u6027\u5730\u8bc1\u5b9e\u4e86\u8fed\u4ee3\u63d2\u8865\u7b97\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5c24\u5176\u662fR\u5305mice\u4e2d\u5b9e\u73b0\u7684\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u5206\u5e03\u9884\u6d4b\u4efb\u52a1\u7684\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u6709\u6548\uff0c\u8fed\u4ee3\u63d2\u8865\u7b97\u6cd5\u5728\u5904\u7406\u7f3a\u5931\u503c\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2511.05050", "pdf": "https://arxiv.org/pdf/2511.05050", "abs": "https://arxiv.org/abs/2511.05050", "authors": ["Masahiro Tanaka"], "title": "Estimating Bidirectional Causal Effects with Large Scale Online Kernel Learning", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "Accepted for publication in Proceedings of the 2025 International\n  Conference on Data Science and Intelligent Systems (DSIS 2025)", "summary": "In this study, a scalable online kernel learning framework is proposed for\nestimating bidirectional causal effects in systems characterized by mutual\ndependence and heteroskedasticity. Traditional causal inference often focuses\non unidirectional effects, overlooking the common bidirectional relationships\nin real-world phenomena. Building on heteroskedasticity-based identification,\nthe proposed method integrates a quasi-maximum likelihood estimator for\nsimultaneous equation models with large scale online kernel learning. It\nemploys random Fourier feature approximations to flexibly model nonlinear\nconditional means and variances, while an adaptive online gradient descent\nalgorithm ensures computational efficiency for streaming and high-dimensional\ndata. Results from extensive simulations demonstrate that the proposed method\nachieves superior accuracy and stability than single equation and polynomial\napproximation baselines, exhibiting lower bias and root mean squared error\nacross various data-generating processes. These results confirm that the\nproposed approach effectively captures complex bidirectional causal effects\nwith near-linear computational scaling. By combining econometric identification\nwith modern machine learning techniques, the proposed framework offers a\npractical, scalable, and theoretically grounded solution for large scale causal\ninference in natural/social science, policy making, business, and industrial\napplications.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u6269\u5c55\u5728\u7ebf\u6838\u5b66\u4e60\u6846\u67b6\u4f30\u8ba1\u53cc\u5411\u56e0\u679c\u6548\u5e94\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u6709\u6548\uff0c\u9002\u7528\u4e8e\u591a\u9886\u57df\u3002", "motivation": "\u4f20\u7edf\u56e0\u679c\u63a8\u65ad\u5e38\u5173\u6ce8\u5355\u5411\u6548\u5e94\uff0c\u5ffd\u7565\u73b0\u5b9e\u4e2d\u5e38\u89c1\u7684\u53cc\u5411\u5173\u7cfb\u3002", "method": "\u57fa\u4e8e\u5f02\u65b9\u5dee\u8bc6\u522b\uff0c\u5c06\u8054\u7acb\u65b9\u7a0b\u6a21\u578b\u7684\u51c6\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\u4e0e\u5927\u89c4\u6a21\u5728\u7ebf\u6838\u5b66\u4e60\u7ed3\u5408\uff0c\u7528\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u8fd1\u4f3c\u5efa\u6a21\uff0c\u81ea\u9002\u5e94\u5728\u7ebf\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u4fdd\u8bc1\u6548\u7387\u3002", "result": "\u6a21\u62df\u663e\u793a\u8be5\u65b9\u6cd5\u6bd4\u5355\u65b9\u7a0b\u548c\u591a\u9879\u5f0f\u8fd1\u4f3c\u57fa\u7ebf\u66f4\u51c6\u786e\u7a33\u5b9a\uff0c\u504f\u5dee\u548c\u5747\u65b9\u6839\u8bef\u5dee\u66f4\u4f4e\uff0c\u80fd\u4ee5\u8fd1\u7ebf\u6027\u8ba1\u7b97\u89c4\u6a21\u6355\u6349\u590d\u6742\u53cc\u5411\u56e0\u679c\u6548\u5e94\u3002", "conclusion": "\u8be5\u6846\u67b6\u7ed3\u5408\u8ba1\u91cf\u8bc6\u522b\u4e0e\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u4e3a\u591a\u9886\u57df\u5927\u89c4\u6a21\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u4e14\u7406\u8bba\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.05290", "pdf": "https://arxiv.org/pdf/2511.05290", "abs": "https://arxiv.org/abs/2511.05290", "authors": ["Tommy Mordo", "Omer Madmon", "Moshe Tennenholtz"], "title": "Cooperation Under Network-Constrained Communication", "categories": ["cs.GT", "cs.MA", "cs.SI"], "comment": null, "summary": "In this paper, we study cooperation in distributed games under\nnetwork-constrained communication. Building on the framework of Monderer and\nTennenholtz (1999), we derive a sufficient condition for cooperative\nequilibrium in settings where communication between agents is delayed by the\nunderlying network topology. Each player deploys an agent at every location,\nand local interactions follow a Prisoner's Dilemma structure. We derive a\nsufficient condition that depends on the network diameter and the number of\nlocations, and analyze extreme cases of instantaneous, delayed, and\nproportionally delayed communication. We also discuss the asymptotic case of\nscale-free communication networks, in which the network diameter grows\nsub-linearly in the number of locations. These insights clarify how\ncommunication latency and network design jointly determine the emergence of\ndistributed cooperation.", "AI": {"tldr": "\u7814\u7a76\u7f51\u7edc\u901a\u4fe1\u53d7\u9650\u4e0b\u5206\u5e03\u5f0f\u535a\u5f08\u4e2d\u7684\u5408\u4f5c\uff0c\u63a8\u5bfc\u5408\u4f5c\u5747\u8861\u5145\u5206\u6761\u4ef6\u5e76\u5206\u6790\u4e0d\u540c\u901a\u4fe1\u60c5\u51b5\uff0c\u9610\u660e\u901a\u4fe1\u5ef6\u8fdf\u548c\u7f51\u7edc\u8bbe\u8ba1\u5bf9\u5206\u5e03\u5f0f\u5408\u4f5c\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u7f51\u7edc\u901a\u4fe1\u53d7\u9650\u4e0b\u5206\u5e03\u5f0f\u535a\u5f08\u4e2d\u7684\u5408\u4f5c\u95ee\u9898\u3002", "method": "\u57fa\u4e8eMonderer\u548cTennenholtz\uff081999\uff09\u7684\u6846\u67b6\uff0c\u63a8\u5bfc\u4f9d\u8d56\u7f51\u7edc\u76f4\u5f84\u548c\u4f4d\u7f6e\u6570\u91cf\u7684\u5408\u4f5c\u5747\u8861\u5145\u5206\u6761\u4ef6\uff0c\u5206\u6790\u4e0d\u540c\u901a\u4fe1\u60c5\u51b5\u3002", "result": "\u5f97\u5230\u4e86\u5408\u4f5c\u5747\u8861\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5206\u6790\u4e86\u77ac\u65f6\u3001\u5ef6\u8fdf\u548c\u6309\u6bd4\u4f8b\u5ef6\u8fdf\u901a\u4fe1\u7684\u6781\u7aef\u60c5\u51b5\u4ee5\u53ca\u65e0\u6807\u5ea6\u901a\u4fe1\u7f51\u7edc\u7684\u6e10\u8fd1\u60c5\u51b5\u3002", "conclusion": "\u901a\u4fe1\u5ef6\u8fdf\u548c\u7f51\u7edc\u8bbe\u8ba1\u5171\u540c\u51b3\u5b9a\u5206\u5e03\u5f0f\u5408\u4f5c\u7684\u51fa\u73b0\u3002"}}
{"id": "2511.05067", "pdf": "https://arxiv.org/pdf/2511.05067", "abs": "https://arxiv.org/abs/2511.05067", "authors": ["Giuseppe Esposito", "Juan-David Guerrero-Balaguera", "Josie Esteban Rodriguez Condia", "Matteo Sonza Reorda", "Marco Barbiero", "Rossella Fortuna"], "title": "GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters", "categories": ["cs.DC"], "comment": null, "summary": "Graphics Processing Units (GPUs) are specialized accelerators in data centers\nand high-performance computing (HPC) systems, enabling the fast execution of\ncompute-intensive applications, such as Convolutional Neural Networks (CNNs).\nHowever, sustained workloads can impose significant stress on GPU components,\nraising reliability concerns due to potential faults that corrupt the\nintermediate application computations, leading to incorrect results. Estimating\nthe stress induced by an application is thus crucial to predict reliability\n(with\\,special\\,emphasis\\,on\\,aging\\,effects). In this work, we combine online\ntelemetry parameters and hardware performance counters to assess GPU stress\ninduced by different applications. The experimental results indicate the stress\ninduced by a parallel workload can be estimated by combining telemetry data and\nPerformance Counters that reveal the efficiency in the resource usage of the\ntarget workload. For this purpose the selected performance counters focus on\nmeasuring the i) throughput, ii) amount of issued instructions and iii) stall\nevents.", "AI": {"tldr": "\u7ed3\u5408\u5728\u7ebf\u9065\u6d4b\u53c2\u6570\u548c\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\u8bc4\u4f30GPU\u538b\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u901a\u8fc7\u76f8\u5173\u6570\u636e\u548c\u8ba1\u6570\u5668\u4f30\u8ba1\u5e76\u884c\u5de5\u4f5c\u8d1f\u8f7d\u538b\u529b\u3002", "motivation": "\u6301\u7eed\u5de5\u4f5c\u8d1f\u8f7d\u4f1a\u7ed9GPU\u7ec4\u4ef6\u5e26\u6765\u538b\u529b\uff0c\u5f15\u53d1\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9700\u4f30\u8ba1\u5e94\u7528\u7a0b\u5e8f\u5e26\u6765\u7684\u538b\u529b\u4ee5\u9884\u6d4b\u53ef\u9760\u6027\u3002", "method": "\u7ed3\u5408\u5728\u7ebf\u9065\u6d4b\u53c2\u6570\u548c\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\u8bc4\u4f30\u4e0d\u540c\u5e94\u7528\u7a0b\u5e8f\u5bf9GPU\u9020\u6210\u7684\u538b\u529b\u3002", "result": "\u901a\u8fc7\u7ed3\u5408\u9065\u6d4b\u6570\u636e\u548c\u80fd\u63ed\u793a\u76ee\u6807\u5de5\u4f5c\u8d1f\u8f7d\u8d44\u6e90\u4f7f\u7528\u6548\u7387\u7684\u6027\u80fd\u8ba1\u6570\u5668\uff0c\u53ef\u4ee5\u4f30\u8ba1\u5e76\u884c\u5de5\u4f5c\u8d1f\u8f7d\u5e26\u6765\u7684\u538b\u529b\uff0c\u6240\u9009\u6027\u80fd\u8ba1\u6570\u5668\u5173\u6ce8\u541e\u5410\u91cf\u3001\u53d1\u51fa\u6307\u4ee4\u6570\u91cf\u548c\u505c\u987f\u4e8b\u4ef6\u3002", "conclusion": "\u7ed3\u5408\u76f8\u5173\u6570\u636e\u548c\u6027\u80fd\u8ba1\u6570\u5668\u53ef\u6709\u6548\u4f30\u8ba1GPU\u538b\u529b\u3002"}}
{"id": "2511.04982", "pdf": "https://arxiv.org/pdf/2511.04982", "abs": "https://arxiv.org/abs/2511.04982", "authors": ["Tianxing Ding", "Hongyang Liu", "Yitong Yin", "Can Zhou"], "title": "Tight Bounds for Sampling q-Colorings via Coupling from the Past", "categories": ["cs.DS"], "comment": null, "summary": "The Coupling from the Past (CFTP) paradigm is a canonical method for perfect\nsampling. For uniform sampling of proper $q$-colorings in graphs with maximum\ndegree $\\Delta$, the bounding chains of Huber (STOC 1998) provide a systematic\nframework for efficiently implementing CFTP algorithms within the classical\nregime $q \\ge (1 + o(1))\\Delta^2$. This was subsequently improved to $q >\n3\\Delta$ by Bhandari and Chakraborty (STOC 2020) and to $q \\ge (8/3 +\no(1))\\Delta$ by Jain, Sah, and Sawhney (STOC 2021).\n  In this work, we establish the asymptotically tight threshold for\nbounding-chain-based CFTP algorithms for graph colorings. We prove a lower\nbound showing that all such algorithms satisfying the standard contraction\nproperty require $q \\ge 2.5\\Delta$, and we present an efficient CFTP algorithm\nthat achieves this asymptotically optimal threshold $q \\ge (2.5 + o(1))\\Delta$\nvia an optimal design of bounding chains.", "AI": {"tldr": "\u672c\u6587\u786e\u5b9a\u4e86\u57fa\u4e8e\u8fb9\u754c\u94fe\u7684\u56fe\u7740\u8272CFTP\u7b97\u6cd5\u7684\u6e10\u8fd1\u7d27\u9608\u503c\uff0c\u8bc1\u660e\u4e0b\u754c\u5e76\u7ed9\u51fa\u8fbe\u5230\u6700\u4f18\u9608\u503c\u7684\u7b97\u6cd5\u3002", "motivation": "\u524d\u4eba\u5bf9\u56fe\u7684\u5747\u5300q\u7740\u8272\u7684CFTP\u7b97\u6cd5\u7684\u9002\u7528\u8303\u56f4\uff08q\u4e0e\u6700\u5927\u5ea6\u0394\u7684\u5173\u7cfb\uff09\u9010\u6b65\u6539\u8fdb\uff0c\u672c\u6587\u65e8\u5728\u786e\u5b9a\u57fa\u4e8e\u8fb9\u754c\u94fe\u7684CFTP\u7b97\u6cd5\u7684\u6e10\u8fd1\u7d27\u9608\u503c\u3002", "method": "\u8bc1\u660e\u6ee1\u8db3\u6807\u51c6\u6536\u7f29\u6027\u8d28\u7684\u7b97\u6cd5\u7684\u4e0b\u754c\uff0c\u901a\u8fc7\u6700\u4f18\u8bbe\u8ba1\u8fb9\u754c\u94fe\u7ed9\u51fa\u8fbe\u5230\u6e10\u8fd1\u6700\u4f18\u9608\u503c\u7684\u9ad8\u6548CFTP\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u6240\u6709\u6ee1\u8db3\u6807\u51c6\u6536\u7f29\u6027\u8d28\u7684\u7b97\u6cd5\u9700\u8981q \u2265 2.5\u0394\uff0c\u5e76\u7ed9\u51fa\u8fbe\u5230\u6e10\u8fd1\u6700\u4f18\u9608\u503cq \u2265 (2.5 + o(1))\u0394\u7684\u9ad8\u6548CFTP\u7b97\u6cd5\u3002", "conclusion": "\u786e\u5b9a\u4e86\u57fa\u4e8e\u8fb9\u754c\u94fe\u7684\u56fe\u7740\u8272CFTP\u7b97\u6cd5\u7684\u6e10\u8fd1\u7d27\u9608\u503c\u3002"}}
{"id": "2511.04880", "pdf": "https://arxiv.org/pdf/2511.04880", "abs": "https://arxiv.org/abs/2511.04880", "authors": ["Yu Bai", "Yukai Miao", "Dawei Wang", "Li Chen", "Fei Long", "Rundi Zhai", "Dan Li", "Yanyu Ren", "Tianfeng Liu", "Hongtao Xie", "Ce Yang", "Xuhui Cai"], "title": "DMA: Online RAG Alignment with Human Feedback", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems often rely on static retrieval,\nlimiting adaptation to evolving intent and content drift. We introduce Dynamic\nMemory Alignment (DMA), an online learning framework that systematically\nincorporates multi-granularity human feedback to align ranking in interactive\nsettings. DMA organizes document-, list-, and response-level signals into a\ncoherent learning pipeline: supervised training for pointwise and listwise\nrankers, policy optimization driven by response-level preferences, and\nknowledge distillation into a lightweight scorer for low-latency serving.\nThroughout this paper, memory refers to the model's working memory, which is\nthe entire context visible to the LLM for In-Context Learning.\n  We adopt a dual-track evaluation protocol mirroring deployment: (i)\nlarge-scale online A/B ablations to isolate the utility of each feedback\nsource, and (ii) few-shot offline tests on knowledge-intensive benchmarks.\nOnline, a multi-month industrial deployment further shows substantial\nimprovements in human engagement. Offline, DMA preserves competitive\nfoundational retrieval while yielding notable gains on conversational QA\n(TriviaQA, HotpotQA). Taken together, these results position DMA as a\nprincipled approach to feedback-driven, real-time adaptation in RAG without\nsacrificing baseline capability.", "AI": {"tldr": "\u63d0\u51faDynamic Memory Alignment (DMA)\u5728\u7ebf\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u4eba\u7c7b\u53cd\u9988\u8c03\u6574\u6392\u5e8f\uff0c\u7ecf\u7ebf\u4e0a\u7ebf\u4e0b\u8bc4\u4f30\u6709\u663e\u8457\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u68c0\u7d22\uff0c\u96be\u4ee5\u9002\u5e94\u610f\u56fe\u6f14\u53d8\u548c\u5185\u5bb9\u6f02\u79fb\u3002", "method": "\u5f15\u5165DMA\u6846\u67b6\uff0c\u7ec4\u7ec7\u6587\u6863\u3001\u5217\u8868\u548c\u54cd\u5e94\u7ea7\u4fe1\u53f7\u5230\u5b66\u4e60\u7ba1\u9053\uff0c\u5305\u62ec\u76d1\u7763\u8bad\u7ec3\u3001\u7b56\u7565\u4f18\u5316\u548c\u77e5\u8bc6\u84b8\u998f\uff1b\u91c7\u7528\u53cc\u8f68\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u7ebf\u4e0a\u5de5\u4e1a\u90e8\u7f72\u63d0\u5347\u4eba\u7c7b\u53c2\u4e0e\u5ea6\uff0c\u7ebf\u4e0b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "DMA\u662f\u4e00\u79cd\u5728\u4e0d\u727a\u7272\u57fa\u7ebf\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\uff0c\u57fa\u4e8e\u53cd\u9988\u9a71\u52a8\u5b9e\u65f6\u9002\u5e94\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.05000", "pdf": "https://arxiv.org/pdf/2511.05000", "abs": "https://arxiv.org/abs/2511.05000", "authors": ["Hyunkyu Kim", "Yeeun Yoo", "Youngjun Kwak"], "title": "Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted(Oral) by ICAIF 2025. Hyunkyu Kim and Yeeun Yoo contributed\n  equally to this work", "summary": "As financial applications of large language models (LLMs) gain attention,\naccurate Information Retrieval (IR) remains crucial for reliable AI services.\nHowever, existing benchmarks fail to capture the complex and domain-specific\ninformation needs of real-world banking scenarios. Building domain-specific IR\nbenchmarks is costly and constrained by legal restrictions on using real\ncustomer data. To address these challenges, we propose a systematic methodology\nfor constructing domain-specific IR benchmarks through LLM-based query\ngeneration. As a concrete implementation of this methodology, our pipeline\ncombines single and multi-document query generation with an enhanced and\nreasoning-augmented answerability assessment method, achieving stronger\nalignment with human judgments than prior approaches. Using this methodology,\nwe construct KoBankIR, comprising 815 queries derived from 204 official banking\ndocuments. Our experiments show that existing retrieval models struggle with\nthe complex multi-document queries in KoBankIR, demonstrating the value of our\nsystematic approach for domain-specific benchmark construction and underscoring\nthe need for improved retrieval techniques in financial domains.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u67e5\u8be2\u751f\u6210\u65b9\u6cd5\u6784\u5efa\u7279\u5b9a\u9886\u57df\u4fe1\u606f\u68c0\u7d22\u57fa\u51c6\uff0c\u6784\u5efa\u4e86KoBankIR\uff0c\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u68c0\u7d22\u6a21\u578b\u5728\u5176\u590d\u6742\u67e5\u8be2\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9e\u94f6\u884c\u573a\u666f\u9700\u6c42\uff0c\u6784\u5efa\u7279\u5b9a\u9886\u57df\u57fa\u51c6\u6210\u672c\u9ad8\u4e14\u53d7\u6cd5\u5f8b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u67e5\u8be2\u751f\u6210\u6784\u5efa\u7279\u5b9a\u9886\u57df\u4fe1\u606f\u68c0\u7d22\u57fa\u51c6\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u7ed3\u5408\u5355\u6587\u6863\u548c\u591a\u6587\u6863\u67e5\u8be2\u751f\u6210\u4e0e\u589e\u5f3a\u7684\u53ef\u56de\u7b54\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b815\u4e2a\u67e5\u8be2\u7684KoBankIR\uff0c\u73b0\u6709\u68c0\u7d22\u6a21\u578b\u5728\u5176\u590d\u6742\u591a\u6587\u6863\u67e5\u8be2\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u65b9\u6cd5\u5bf9\u7279\u5b9a\u9886\u57df\u57fa\u51c6\u6784\u5efa\u6709\u4ef7\u503c\uff0c\u91d1\u878d\u9886\u57df\u9700\u6539\u8fdb\u68c0\u7d22\u6280\u672f\u3002"}}
{"id": "2511.05438", "pdf": "https://arxiv.org/pdf/2511.05438", "abs": "https://arxiv.org/abs/2511.05438", "authors": ["Leah Costlow", "Yan Bai", "Katherine P. Adams", "Ty Beal", "Kathryn G. Dewey", "Christopher M. Free", "Valerie M. Friesen", "Mduduzi N. N. Mbuya", "Stella Nordhagen", "Florencia C. Vasta", "William A. Masters"], "title": "Impacts of large-scale food fortification on the cost of nutrient-adequate diets: a modeling study in 89 countries", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Large-scale food fortification (LSFF) is a widely accepted intervention to\nalleviate micronutrient deficiencies, yet policy implementation is often\nincomplete and its effects on diet costs are not well established. We estimated\nthe extent to which LSFF reduces the cost of nutrient-adequate diets using\nretail food prices and fortification policy data from 89 countries. In total,\nwe modeled 5,874 least-cost diets across 22 sex-age groups and 3\nnutrient-adequacy scenarios: meeting nutrient requirements only; adding minimum\nintakes for starchy staples and fruits and vegetables; and aligning food group\nshares with national consumption patterns. Assuming 90% implementation of\nexisting LSFF standards, we found median cost reductions of 1.7%, 2.4%, and\n4.5% across the three scenarios. Cost reductions varied widely by sex-age\ngroups, national fortification strategies and food price structures. These\nfindings highlight that LSFF may improve diet affordability when policies are\ncarefully designed for local contexts, making it a valuable complement to other\nefforts that improve access to nutritious diets.", "AI": {"tldr": "\u7814\u7a76\u752889\u56fd\u6570\u636e\u4f30\u7b97\u5927\u89c4\u6a21\u98df\u7269\u5f3a\u5316\uff08LSFF\uff09\u5bf9\u8425\u517b\u5145\u8db3\u996e\u98df\u6210\u672c\u7684\u964d\u4f4e\u7a0b\u5ea6\uff0c\u53d1\u73b0\u4e0d\u540c\u573a\u666f\u4e0b\u6210\u672c\u6709\u4e0d\u540c\u7a0b\u5ea6\u964d\u4f4e\uff0c\u5f3a\u8c03\u56e0\u5730\u5236\u5b9c\u8bbe\u8ba1\u653f\u7b56\u53ef\u63d0\u9ad8\u996e\u98df\u53ef\u8d1f\u62c5\u6027\u3002", "motivation": "LSFF\u653f\u7b56\u5b9e\u65bd\u5e38\u4e0d\u5b8c\u6574\u4e14\u5176\u5bf9\u996e\u98df\u6210\u672c\u7684\u5f71\u54cd\u4e0d\u660e\uff0c\u9700\u4f30\u7b97\u5176\u964d\u4f4e\u8425\u517b\u5145\u8db3\u996e\u98df\u6210\u672c\u7684\u7a0b\u5ea6\u3002", "method": "\u5229\u752889\u4e2a\u56fd\u5bb6\u7684\u96f6\u552e\u98df\u54c1\u4ef7\u683c\u548c\u5f3a\u5316\u653f\u7b56\u6570\u636e\uff0c\u5bf922\u4e2a\u6027\u522b - \u5e74\u9f84\u7ec4\u548c3\u79cd\u8425\u517b\u5145\u8db3\u60c5\u666f\u4e0b\u76845874\u79cd\u6700\u4f4e\u6210\u672c\u996e\u98df\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u5047\u8bbe\u73b0\u6709LSFF\u6807\u51c6\u5b9e\u65bd\u7387\u8fbe90%\uff0c\u4e09\u79cd\u60c5\u666f\u4e0b\u996e\u98df\u6210\u672c\u4e2d\u4f4d\u6570\u5206\u522b\u964d\u4f4e1.7%\u30012.4%\u548c4.5%\uff0c\u6210\u672c\u964d\u4f4e\u5e45\u5ea6\u56e0\u6027\u522b - \u5e74\u9f84\u7ec4\u3001\u56fd\u5bb6\u5f3a\u5316\u7b56\u7565\u548c\u98df\u54c1\u4ef7\u683c\u7ed3\u6784\u800c\u5f02\u3002", "conclusion": "LSFF\u653f\u7b56\u56e0\u5730\u5236\u5b9c\u8bbe\u8ba1\u65f6\u53ef\u63d0\u9ad8\u996e\u98df\u53ef\u8d1f\u62c5\u6027\uff0c\u662f\u6539\u5584\u8425\u517b\u996e\u98df\u53ef\u53ca\u6027\u5176\u4ed6\u52aa\u529b\u7684\u91cd\u8981\u8865\u5145\u3002"}}
{"id": "2511.05131", "pdf": "https://arxiv.org/pdf/2511.05131", "abs": "https://arxiv.org/abs/2511.05131", "authors": ["Fernando Berzal"], "title": "DL101 Neural Network Outputs and Loss Functions", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "The loss function used to train a neural network is strongly connected to its\noutput layer from a statistical point of view. This technical report analyzes\ncommon activation functions for a neural network output layer, like linear,\nsigmoid, ReLU, and softmax, detailing their mathematical properties and their\nappropriate use cases. A strong statistical justification exists for the\nselection of the suitable loss function for training a deep learning model.\nThis report connects common loss functions such as Mean Squared Error (MSE),\nMean Absolute Error (MAE), and various Cross-Entropy losses to the statistical\nprinciple of Maximum Likelihood Estimation (MLE). Choosing a specific loss\nfunction is equivalent to assuming a specific probability distribution for the\nmodel output, highlighting the link between these functions and the Generalized\nLinear Models (GLMs) that underlie network output layers. Additional scenarios\nof practical interest are also considered, such as alternative output\nencodings, constrained outputs, and distributions with heavy tails.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u5c42\u6fc0\u6d3b\u51fd\u6570\u548c\u635f\u5931\u51fd\u6570\uff0c\u5c06\u635f\u5931\u51fd\u6570\u4e0e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u63a2\u8ba8\u5b9e\u9645\u573a\u666f\u3002", "motivation": "\u4ece\u7edf\u8ba1\u89d2\u5ea6\u5206\u6790\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u5c42\u6fc0\u6d3b\u51fd\u6570\u4e0e\u635f\u5931\u51fd\u6570\u7684\u8054\u7cfb\uff0c\u4e3a\u9009\u62e9\u5408\u9002\u635f\u5931\u51fd\u6570\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u5206\u6790\u5e38\u89c1\u6fc0\u6d3b\u51fd\u6570\u6570\u5b66\u6027\u8d28\u53ca\u9002\u7528\u573a\u666f\uff0c\u5c06\u5e38\u89c1\u635f\u5931\u51fd\u6570\u4e0e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u539f\u7406\u76f8\u8fde\u63a5\u3002", "result": "\u6307\u51fa\u9009\u62e9\u7279\u5b9a\u635f\u5931\u51fd\u6570\u7b49\u540c\u4e8e\u5047\u8bbe\u6a21\u578b\u8f93\u51fa\u7684\u7279\u5b9a\u6982\u7387\u5206\u5e03\uff0c\u5f3a\u8c03\u5176\u4e0e\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u7684\u8054\u7cfb\u3002", "conclusion": "\u8003\u8651\u4e86\u5982\u66ff\u4ee3\u8f93\u51fa\u7f16\u7801\u3001\u53d7\u9650\u8f93\u51fa\u548c\u91cd\u5c3e\u5206\u5e03\u7b49\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2511.04986", "pdf": "https://arxiv.org/pdf/2511.04986", "abs": "https://arxiv.org/abs/2511.04986", "authors": ["Mohammadreza Saeidi", "Ethan Thoma", "Raula Gaikovina Kula", "Gema Rodr\u00edguez-P\u00e9rez"], "title": "What About Our Bug? A Study on the Responsiveness of NPM Package Maintainers", "categories": ["cs.SE"], "comment": null, "summary": "Background: Widespread use of third-party libraries makes ecosystems like\nNode Package Manager (npm) critical to modern software development. However,\nthis interconnected chain of dependencies also creates challenges: bugs in one\nlibrary can propagate downstream, potentially impacting many other libraries\nthat rely on it. We hypothesize that maintainers may not always decide to fix a\nbug, especially if the maintainer decides it falls out of their responsibility\nwithin the chain of dependencies. Aims: To confirm this hypothesis, we\ninvestigate the responsiveness of 30,340 bug reports across 500 of the most\ndepended-upon npm packages. Method: We adopt a mixed-method approach to mine\nrepository issue data and perform qualitative open coding to analyze reasons\nbehind unaddressed bug reports. Results: Our findings show that maintainers are\ngenerally responsive, with a median project-level responsiveness of 70% (IQR:\n55%-89%), reflecting their commitment to support downstream developers.\nConclusions: We present a taxonomy of the reasons some bugs remain unresolved.\nThe taxonomy includes contribution practices, dependency constraints, and\nlibrary-specific standards as reasons for not being responsive. Understanding\nmaintainer behavior can inform practices that promote a more robust and\nresponsive open-source ecosystem that benefits the entire community.", "AI": {"tldr": "\u7814\u7a76npm\u5305\u7ef4\u62a4\u8005\u5bf9bug\u62a5\u544a\u7684\u54cd\u5e94\u60c5\u51b5\uff0c\u53d1\u73b0\u7ef4\u62a4\u8005\u603b\u4f53\u54cd\u5e94\u79ef\u6781\uff0c\u8fd8\u7ed9\u51fa\u90e8\u5206bug\u672a\u89e3\u51b3\u7684\u539f\u56e0\u5206\u7c7b\u3002", "motivation": "\u7b2c\u4e09\u65b9\u5e93\u5e7f\u6cdb\u4f7f\u7528\u4f7fnpm\u751f\u6001\u7cfb\u7edf\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f9d\u8d56\u94fe\u4f1a\u4f20\u64adbug\uff0c\u63a8\u6d4b\u7ef4\u62a4\u8005\u53ef\u80fd\u4e0d\u4fee\u590d\u67d0\u4e9bbug\uff0c\u9700\u9a8c\u8bc1\u6b64\u5047\u8bbe\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u6316\u6398\u4ed3\u5e93\u95ee\u9898\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u5b9a\u6027\u5f00\u653e\u7f16\u7801\u5206\u6790\u672a\u5904\u7406bug\u62a5\u544a\u7684\u539f\u56e0\u3002", "result": "\u7ef4\u62a4\u8005\u603b\u4f53\u54cd\u5e94\u79ef\u6781\uff0c\u9879\u76ee\u5c42\u9762\u54cd\u5e94\u4e2d\u4f4d\u6570\u4e3a70%\uff08IQR\uff1a55%-89%\uff09\u3002", "conclusion": "\u7ed9\u51fa\u90e8\u5206bug\u672a\u89e3\u51b3\u7684\u539f\u56e0\u5206\u7c7b\uff0c\u5305\u62ec\u8d21\u732e\u5b9e\u8df5\u3001\u4f9d\u8d56\u7ea6\u675f\u548c\u5e93\u7279\u5b9a\u6807\u51c6\u7b49\uff0c\u4e86\u89e3\u7ef4\u62a4\u8005\u884c\u4e3a\u6709\u52a9\u4e8e\u4fc3\u8fdb\u66f4\u5f3a\u5927\u548c\u54cd\u5e94\u8fc5\u901f\u7684\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2511.04722", "pdf": "https://arxiv.org/pdf/2511.04722", "abs": "https://arxiv.org/abs/2511.04722", "authors": ["Qianyang Li", "Xingjun Zhang", "Peng Tao", "Shaoxun Wang", "Yancheng Pan", "Jia Wei"], "title": "AWEMixer: Adaptive Wavelet-Enhanced Mixer Network for Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Forecasting long-term time series in IoT environments remains a significant\nchallenge due to the non-stationary and multi-scale characteristics of sensor\nsignals. Furthermore, error accumulation causes a decrease in forecast quality\nwhen predicting further into the future. Traditional methods are restricted to\noperate in time-domain, while the global frequency information achieved by\nFourier transform would be regarded as stationary signals leading to blur the\ntemporal patterns of transient events. We propose AWEMixer, an Adaptive\nWavelet-Enhanced Mixer Network including two innovative components: 1) a\nFrequency Router designs to utilize the global periodicity pattern achieved by\nFast Fourier Transform to adaptively weight localized wavelet subband, and 2) a\nCoherent Gated Fusion Block to achieve selective integration of prominent\nfrequency features with multi-scale temporal representation through\ncross-attention and gating mechanism, which realizes accurate time-frequency\nlocalization while remaining robust to noise. Seven public benchmarks validate\nthat our model is more effective than recent state-of-the-art models.\nSpecifically, our model consistently achieves performance improvement compared\nwith transformer-based and MLP-based state-of-the-art models in long-sequence\ntime series forecasting. Code is available at\nhttps://github.com/hit636/AWEMixer", "AI": {"tldr": "\u63d0\u51faAWEMixer\u7528\u4e8e\u7269\u8054\u7f51\u73af\u5883\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u542b\u521b\u65b0\u7ec4\u4ef6\uff0c\u7ecf7\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u6bd4\u73b0\u6709\u6a21\u578b\u6709\u6548\u3002", "motivation": "\u7269\u8054\u7f51\u73af\u5883\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u56e0\u4f20\u611f\u5668\u4fe1\u53f7\u7279\u6027\u548c\u8bef\u5dee\u79ef\u7d2f\u6709\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u5c40\u9650\u3002", "method": "\u63d0\u51faAdaptive Wavelet - Enhanced Mixer Network\uff08AWEMixer\uff09\uff0c\u542bFrequency Router\u548cCoherent Gated Fusion Block\u4e24\u4e2a\u521b\u65b0\u7ec4\u4ef6\u3002", "result": "\u4e03\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\u8be5\u6a21\u578b\u6bd4\u73b0\u6709\u6a21\u578b\u66f4\u6709\u6548\uff0c\u5728\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u6bd4\u57fa\u4e8etransformer\u548cMLP\u7684\u6a21\u578b\u6709\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AWEMixer\u80fd\u5b9e\u73b0\u51c6\u786e\u7684\u65f6\u9891\u5b9a\u4f4d\u4e14\u5bf9\u566a\u58f0\u9c81\u68d2\uff0c\u9002\u7528\u4e8e\u7269\u8054\u7f51\u73af\u5883\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002"}}
{"id": "2511.04784", "pdf": "https://arxiv.org/pdf/2511.04784", "abs": "https://arxiv.org/abs/2511.04784", "authors": ["Hamidreza Maleki Almani"], "title": "Insights into Tail-Based and Order Statistics", "categories": ["math.ST", "q-fin.ST", "stat.ME", "stat.TH", "60E05, 62E20, 60F05, 60G15, 60G70, 62G30, 62G32, 62M10, 62P20", "G.3.3; G.3.16; G.3.18"], "comment": "28 pages, 1 figure, and 1 table", "summary": "Heavy-tailed phenomena appear across diverse domains --from wealth and firm\nsizes in economics to network traffic, biological systems, and physical\nprocesses-- characterized by the disproportionate influence of extreme values.\nThese distributions challenge classical statistical models, as their tails\ndecay too slowly for conventional approximations to hold. Among their key\ndescriptive measures are quantile contributions, which quantify the proportion\nof a total quantity (such as income, energy, or risk) attributed to\nobservations above a given quantile threshold. This paper presents a\ntheoretical study of the quantile contribution statistic and its relationship\nwith order statistics. We derive a closed-form expression for the joint\ncumulative distribution function (CDF) of order statistics and, based on it,\nobtain an explicit CDF for quantile contributions applicable to small samples.\nWe then investigate the asymptotic behavior of these contributions as the\nsample size increases, establishing the asymptotic normality of the numerator\nand characterizing the limiting distribution of the quantile contribution.\nFinally, simulation studies illustrate the convergence properties and empirical\naccuracy of the theoretical results, providing a foundation for applying\nquantile contributions in the analysis of heavy-tailed data.", "AI": {"tldr": "\u672c\u6587\u5bf9\u91cd\u5c3e\u5206\u5e03\u4e2d\u5206\u4f4d\u6570\u8d21\u732e\u7edf\u8ba1\u91cf\u53ca\u5176\u4e0e\u987a\u5e8f\u7edf\u8ba1\u91cf\u7684\u5173\u7cfb\u8fdb\u884c\u7406\u8bba\u7814\u7a76\uff0c\u63a8\u5bfc\u76f8\u5173\u5206\u5e03\u51fd\u6570\uff0c\u7814\u7a76\u6e10\u8fd1\u884c\u4e3a\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u7ed3\u679c\u3002", "motivation": "\u91cd\u5c3e\u5206\u5e03\u6311\u6218\u7ecf\u5178\u7edf\u8ba1\u6a21\u578b\uff0c\u5206\u4f4d\u6570\u8d21\u732e\u662f\u5173\u952e\u63cf\u8ff0\u6307\u6807\uff0c\u9700\u6df1\u5165\u7814\u7a76\u5176\u7edf\u8ba1\u7279\u6027\u3002", "method": "\u63a8\u5bfc\u987a\u5e8f\u7edf\u8ba1\u91cf\u7684\u8054\u5408\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\uff0c\u5728\u6b64\u57fa\u7840\u4e0a\u5f97\u5230\u5206\u4f4d\u6570\u8d21\u732e\u7684\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\uff0c\u7814\u7a76\u5176\u6e10\u8fd1\u884c\u4e3a\uff0c\u8fdb\u884c\u6a21\u62df\u7814\u7a76\u3002", "result": "\u5f97\u5230\u9002\u7528\u4e8e\u5c0f\u6837\u672c\u7684\u5206\u4f4d\u6570\u8d21\u732e\u7684\u663e\u5f0f\u7d2f\u79ef\u5206\u5e03\u51fd\u6570\uff0c\u786e\u5b9a\u5206\u5b50\u7684\u6e10\u8fd1\u6b63\u6001\u6027\u548c\u5206\u4f4d\u6570\u8d21\u732e\u7684\u6781\u9650\u5206\u5e03\uff0c\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u7684\u6536\u655b\u6027\u548c\u7ecf\u9a8c\u51c6\u786e\u6027\u3002", "conclusion": "\u4e3a\u5206\u4f4d\u6570\u8d21\u732e\u5728\u91cd\u5c3e\u6570\u636e\u5206\u6790\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.04975", "pdf": "https://arxiv.org/pdf/2511.04975", "abs": "https://arxiv.org/abs/2511.04975", "authors": ["Abylay Zhumekenov", "Alexandros Beskos", "Dan Crisan", "Matthew Graham", "Ajay Jasra", "Nikolas Kantas"], "title": "Sequential Markov chain Monte Carlo for Filtering of State-Space Models with Low or Degenerate Observation Noise", "categories": ["stat.CO"], "comment": "21 pages, 11 figures", "summary": "We consider the discrete-time filtering problem in scenarios where the\nobservation noise is degenerate or low. More precisely, one is given access to\na discrete time observation sequence which at any time $k$ depends only on the\nstate of an unobserved Markov chain. We specifically assume that the functional\nrelationship between observations and hidden Markov chain has either degenerate\nor low noise. In this article, under suitable assumptions, we derive the\nfiltering density and its recursions for this class of problems on a specific\nsequence of manifolds defined through the observation function. We then design\nsequential Markov chain Monte Carlo methods to approximate the filter serially\nin time. For a certain linear observation model, we show that using sequential\nMarkov chain Monte Carlo for low noise will converge as the noise disappears to\nthat of using sequential Markov chain Monte Carlo for degenerate noise. We\nillustrate the performance of our methodology on several challenging stochastic\nmodels deriving from Statistics and Applied Mathematics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u89c2\u6d4b\u566a\u58f0\u9000\u5316\u6216\u8f83\u4f4e\u573a\u666f\u4e0b\u7684\u79bb\u6563\u65f6\u95f4\u6ee4\u6ce2\u95ee\u9898\uff0c\u63a8\u5bfc\u6ee4\u6ce2\u5bc6\u5ea6\u53ca\u9012\u5f52\u516c\u5f0f\uff0c\u8bbe\u8ba1\u5e8f\u8d2f\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u7f57\u65b9\u6cd5\uff0c\u8bc1\u660e\u7279\u5b9a\u7ebf\u6027\u6a21\u578b\u4e0b\u4f4e\u566a\u58f0\u4e0e\u9000\u5316\u566a\u58f0\u60c5\u51b5\u7684\u6536\u655b\u5173\u7cfb\uff0c\u5e76\u5728\u591a\u4e2a\u968f\u673a\u6a21\u578b\u4e0a\u9a8c\u8bc1\u65b9\u6cd5\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u89c2\u6d4b\u566a\u58f0\u9000\u5316\u6216\u8f83\u4f4e\u573a\u666f\u4e0b\u7684\u79bb\u6563\u65f6\u95f4\u6ee4\u6ce2\u95ee\u9898\u3002", "method": "\u5728\u7279\u5b9a\u6d41\u5f62\u5e8f\u5217\u4e0a\u63a8\u5bfc\u6ee4\u6ce2\u5bc6\u5ea6\u53ca\u9012\u5f52\u516c\u5f0f\uff0c\u8bbe\u8ba1\u5e8f\u8d2f\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u8fd1\u4f3c\u6ee4\u6ce2\u5668\u3002", "result": "\u5bf9\u4e8e\u7279\u5b9a\u7ebf\u6027\u89c2\u6d4b\u6a21\u578b\uff0c\u4f4e\u566a\u58f0\u4e0b\u5e8f\u8d2f\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u7f57\u65b9\u6cd5\u5728\u566a\u58f0\u6d88\u5931\u65f6\u6536\u655b\u5230\u9000\u5316\u566a\u58f0\u65f6\u7684\u60c5\u51b5\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u6765\u81ea\u7edf\u8ba1\u5b66\u548c\u5e94\u7528\u6570\u5b66\u7684\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u968f\u673a\u6a21\u578b\u4e0a\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2511.05159", "pdf": "https://arxiv.org/pdf/2511.05159", "abs": "https://arxiv.org/abs/2511.05159", "authors": ["Shubhayan Pan", "Saptarshi Chakraborty", "Debolina Paul", "Kushal Bose", "Swagatam Das"], "title": "A New Framework for Convex Clustering in Kernel Spaces: Finite Sample Bounds, Consistency and Performance Insights", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Convex clustering is a well-regarded clustering method, resembling the\nsimilar centroid-based approach of Lloyd's $k$-means, without requiring a\npredefined cluster count. It starts with each data point as its centroid and\niteratively merges them. Despite its advantages, this method can fail when\ndealing with data exhibiting linearly non-separable or non-convex structures.\nTo mitigate the limitations, we propose a kernelized extension of the convex\nclustering method. This approach projects the data points into a Reproducing\nKernel Hilbert Space (RKHS) using a feature map, enabling convex clustering in\nthis transformed space. This kernelization not only allows for better handling\nof complex data distributions but also produces an embedding in a\nfinite-dimensional vector space. We provide a comprehensive theoretical\nunderpinnings for our kernelized approach, proving algorithmic convergence and\nestablishing finite sample bounds for our estimates. The effectiveness of our\nmethod is demonstrated through extensive experiments on both synthetic and\nreal-world datasets, showing superior performance compared to state-of-the-art\nclustering techniques. This work marks a significant advancement in the field,\noffering an effective solution for clustering in non-linear and non-convex data\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u51f8\u805a\u7c7b\u65b9\u6cd5\u7684\u6838\u5316\u6269\u5c55\uff0c\u5904\u7406\u975e\u7ebf\u6027\u548c\u975e\u51f8\u6570\u636e\uff0c\u7406\u8bba\u8bc1\u660e\u6536\u655b\u6027\u4e0e\u6709\u9650\u6837\u672c\u754c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6027\u80fd\u4f18\u3002", "motivation": "\u4f20\u7edf\u51f8\u805a\u7c7b\u65b9\u6cd5\u5904\u7406\u7ebf\u6027\u4e0d\u53ef\u5206\u6216\u975e\u51f8\u7ed3\u6784\u6570\u636e\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5c06\u6570\u636e\u70b9\u901a\u8fc7\u7279\u5f81\u6620\u5c04\u6295\u5f71\u5230\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff08RKHS\uff09\uff0c\u5728\u53d8\u6362\u7a7a\u95f4\u8fdb\u884c\u51f8\u805a\u7c7b\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u7b97\u6cd5\u6536\u655b\u6027\u548c\u6709\u9650\u6837\u672c\u754c\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u805a\u7c7b\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u8be5\u9886\u57df\u91cd\u5927\u8fdb\u5c55\uff0c\u4e3a\u975e\u7ebf\u6027\u548c\u975e\u51f8\u6570\u636e\u805a\u7c7b\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.04929", "pdf": "https://arxiv.org/pdf/2511.04929", "abs": "https://arxiv.org/abs/2511.04929", "authors": ["Mathieu Lauri\u00e8re"], "title": "An Overview of Some Extensions of Mean Field Games beyond Perfect Homogeneity and Anonymity", "categories": ["math.OC", "cs.GT"], "comment": null, "summary": "The mean field games (MFG) paradigm was introduced to provide tractable\napproximations of games involving very large populations. The theory typically\nrests on two key assumptions: homogeneity, meaning that all players share the\nsame dynamics and cost functions, and anonymity, meaning that each player\ninteracts with others only through their empirical distribution. While these\nassumptions simplify the analysis, they can be restrictive for many\napplications. Fortunately, several extensions of the standard MFG framework\nthat relax these assumptions have been developed in the literature. The purpose\nof these notes is to offer a pedagogical introduction to such models. In\nparticular, we discuss multi-population MFGs, graphon MFGs, major-minor MFGs,\nand Stackelberg MFGs, as well as variants involving cooperative players.", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u5bf9\u653e\u5bbd\u6807\u51c6\u5e73\u5747\u573a\u535a\u5f08\uff08MFG\uff09\u6846\u67b6\u5047\u8bbe\u7684\u6a21\u578b\u8fdb\u884c\u6559\u5b66\u5f0f\u4ecb\u7ecd\u3002", "motivation": "\u6807\u51c6MFG\u6846\u67b6\u7684\u540c\u8d28\u6027\u548c\u533f\u540d\u6027\u5047\u8bbe\u5728\u5f88\u591a\u5e94\u7528\u4e2d\u5177\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981\u5bf9\u653e\u5bbd\u8fd9\u4e9b\u5047\u8bbe\u7684\u6a21\u578b\u8fdb\u884c\u4ecb\u7ecd\u3002", "method": "\u8ba8\u8bba\u591a\u7fa4\u4f53MFG\u3001\u56fe\u8bbaMFG\u3001\u4e3b\u6b21MFG\u3001Stackelberg MFG\u4ee5\u53ca\u6d89\u53ca\u5408\u4f5c\u53c2\u4e0e\u8005\u7684\u53d8\u4f53\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u5bf9\u653e\u5bbd\u6807\u51c6MFG\u6846\u67b6\u5047\u8bbe\u7684\u6a21\u578b\u7684\u6559\u5b66\u5f0f\u4ecb\u7ecd\u3002"}}
{"id": "2511.04946", "pdf": "https://arxiv.org/pdf/2511.04946", "abs": "https://arxiv.org/abs/2511.04946", "authors": ["Lei Chen", "Erci Xu", "Yiming Sun", "Shengyu Fan", "Xianglong Deng", "Guiming Shi", "Guang Fan", "Liang Kong", "Yilan Zhu", "Shoumeng Yan", "Mingzhe Zhang"], "title": "The Future of Fully Homomorphic Encryption System: from a Storage I/O Perspective", "categories": ["cs.CR", "cs.DC"], "comment": "https://link.springer.com/chapter/10.1007/978-981-95-1021-4_25", "summary": "Fully Homomorphic Encryption (FHE) allows computations to be performed on\nencrypted data, significantly enhancing user privacy. However, the I/O\nchallenges associated with deploying FHE applications remains understudied. We\nanalyze the impact of storage I/O on the performance of FHE applications and\nsummarize key lessons from the status quo. Key results include that storage I/O\ncan degrade the performance of ASICs by as much as 357$\\times$ and reduce GPUs\nperformance by up to 22$\\times$.", "AI": {"tldr": "\u5206\u6790\u5b58\u50a8I/O\u5bf9FHE\u5e94\u7528\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u4f1a\u4e25\u91cd\u964d\u4f4eASIC\u548cGPU\u6027\u80fd\u3002", "motivation": "FHE\u867d\u80fd\u589e\u5f3a\u7528\u6237\u9690\u79c1\uff0c\u4f46\u90e8\u7f72\u65f6\u7684I/O\u6311\u6218\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u5206\u6790\u5b58\u50a8I/O\u5bf9FHE\u5e94\u7528\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790\u5b58\u50a8I/O\u5bf9FHE\u5e94\u7528\u6027\u80fd\u7684\u5f71\u54cd\u5e76\u603b\u7ed3\u73b0\u72b6\u7ecf\u9a8c\u3002", "result": "\u5b58\u50a8I/O\u53ef\u4f7fASIC\u6027\u80fd\u964d\u4f4e\u8fbe357\u500d\uff0c\u4f7fGPU\u6027\u80fd\u964d\u4f4e\u8fbe22\u500d\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u6697\u793a\u5b58\u50a8I/O\u5bf9FHE\u5e94\u7528\u6027\u80fd\u5f71\u54cd\u5927\uff0c\u9700\u5173\u6ce8\u89e3\u51b3\u3002"}}
{"id": "2511.05295", "pdf": "https://arxiv.org/pdf/2511.05295", "abs": "https://arxiv.org/abs/2511.05295", "authors": ["Jon Kleinberg", "Fan Wei"], "title": "Language Generation and Identification From Partial Enumeration: Tight Density Bounds and Topological Characterizations", "categories": ["cs.DS", "cs.CL", "cs.DM", "cs.LG"], "comment": null, "summary": "The success of large language models (LLMs) has motivated formal theories of\nlanguage generation and learning. We study the framework of \\emph{language\ngeneration in the limit}, where an adversary enumerates strings from an unknown\nlanguage $K$ drawn from a countable class, and an algorithm must generate\nunseen strings from $K$. Prior work showed that generation is always possible,\nand that some algorithms achieve positive lower density, revealing a\n\\emph{validity--breadth} trade-off between correctness and coverage. We resolve\na main open question in this line, proving a tight bound of $1/2$ on the best\nachievable lower density. We then strengthen the model to allow \\emph{partial\nenumeration}, where the adversary reveals only an infinite subset $C \\subseteq\nK$. We show that generation in the limit remains achievable, and if $C$ has\nlower density $\\alpha$ in $K$, the algorithm's output achieves density at least\n$\\alpha/2$, matching the upper bound. This generalizes the $1/2$ bound to the\npartial-information setting, where the generator must recover within a factor\n$1/2$ of the revealed subset's density. We further revisit the classical\nGold--Angluin model of \\emph{language identification} under partial\nenumeration. We characterize when identification in the limit is possible --\nwhen hypotheses $M_t$ eventually satisfy $C \\subseteq M \\subseteq K$ -- and in\nthe process give a new topological formulation of Angluin's characterization,\nshowing that her condition is precisely equivalent to an appropriate\ntopological space having the $T_D$ separation property.", "AI": {"tldr": "\u7814\u7a76\u8bed\u8a00\u751f\u6210\u4e0e\u5b66\u4e60\u7406\u8bba\uff0c\u89e3\u51b3\u8bed\u8a00\u751f\u6210\u6781\u9650\u6846\u67b6\u4e0b\u6700\u4f73\u53ef\u5b9e\u73b0\u4f4e\u5bc6\u5ea6\u7684\u7d27\u754c\u95ee\u9898\uff0c\u62d3\u5c55\u5230\u90e8\u5206\u679a\u4e3e\u60c5\u51b5\uff0c\u8fd8\u91cd\u65b0\u5ba1\u89c6\u8bed\u8a00\u8bc6\u522b\u6a21\u578b\u5e76\u7ed9\u51fa\u65b0\u62d3\u6251\u8868\u8ff0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6210\u529f\u4fc3\u4f7f\u5bf9\u8bed\u8a00\u751f\u6210\u548c\u5b66\u4e60\u8fdb\u884c\u5f62\u5f0f\u5316\u7406\u8bba\u7814\u7a76\u3002", "method": "\u7406\u8bba\u8bc1\u660e\uff0c\u89e3\u51b3\u8bed\u8a00\u751f\u6210\u6781\u9650\u6846\u67b6\u4e0b\u7684\u5f00\u653e\u95ee\u9898\uff0c\u62d3\u5c55\u6a21\u578b\u5230\u90e8\u5206\u679a\u4e3e\u60c5\u51b5\uff0c\u5e76\u5bf9\u8bed\u8a00\u8bc6\u522b\u6a21\u578b\u8fdb\u884c\u62d3\u6251\u5206\u6790\u3002", "result": "\u8bc1\u660e\u8bed\u8a00\u751f\u6210\u6781\u9650\u6846\u67b6\u4e0b\u6700\u4f73\u53ef\u5b9e\u73b0\u4f4e\u5bc6\u5ea6\u7684\u7d27\u754c\u4e3a1/2\uff1b\u5728\u90e8\u5206\u679a\u4e3e\u60c5\u51b5\u4e0b\uff0c\u7b97\u6cd5\u8f93\u51fa\u5bc6\u5ea6\u81f3\u5c11\u4e3a\u03b1/2\uff1b\u7ed9\u51fa\u8bed\u8a00\u8bc6\u522b\u7684\u65b0\u62d3\u6251\u8868\u8ff0\u3002", "conclusion": "\u89e3\u51b3\u4e86\u8bed\u8a00\u751f\u6210\u6781\u9650\u6846\u67b6\u7684\u4e3b\u8981\u5f00\u653e\u95ee\u9898\uff0c\u62d3\u5c55\u6a21\u578b\u5230\u90e8\u5206\u4fe1\u606f\u8bbe\u7f6e\uff0c\u4e3a\u8bed\u8a00\u8bc6\u522b\u63d0\u4f9b\u65b0\u62d3\u6251\u89c6\u89d2\u3002"}}
{"id": "2511.04898", "pdf": "https://arxiv.org/pdf/2511.04898", "abs": "https://arxiv.org/abs/2511.04898", "authors": ["Yule Wen", "Yixin Ye", "Yanzhe Zhang", "Diyi Yang", "Hao Zhu"], "title": "Real-Time Reasoning Agents in Evolving Environments", "categories": ["cs.AI"], "comment": "30 pages", "summary": "Agents in the real world must make not only logical but also timely\njudgments. This requires continuous awareness of the dynamic environment:\nhazards emerge, opportunities arise, and other agents act, while the agent's\nreasoning is still unfolding. Despite advances in language model reasoning,\nexisting approaches fail to account for this dynamic nature. We introduce\nreal-time reasoning as a new problem formulation for agents in evolving\nenvironments and build Real-Time Reasoning Gym to demonstrate it. We study two\nparadigms for deploying language models in agents: (1) reactive agents, which\nemploy language models with bounded reasoning computation for rapid responses,\nand (2) planning agents, which allow extended reasoning computation for complex\nproblems. Our experiments show that even state-of-the-art models struggle with\nmaking logical and timely judgments in either paradigm. To address this\nlimitation, we propose AgileThinker, which simultaneously engages both\nreasoning paradigms. AgileThinker consistently outperforms agents engaging only\none reasoning paradigm as the task difficulty and time pressure rise,\neffectively balancing reasoning depth and response latency. Our work\nestablishes real-time reasoning as a critical testbed for developing practical\nagents and provides a foundation for research in temporally constrained AI\nsystems, highlighting a path toward real-time capable agents.", "AI": {"tldr": "\u63d0\u51fa\u5b9e\u65f6\u63a8\u7406\u95ee\u9898\uff0c\u6784\u5efa\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7814\u7a76\u4e24\u79cd\u63a8\u7406\u8303\u5f0f\uff0c\u63d0\u51faAgileThinker\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u95ee\u9898\uff0c\u4e3a\u5b9e\u65f6\u667a\u80fd\u4f53\u7814\u7a76\u5960\u57fa\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u667a\u80fd\u4f53\u9700\u8fdb\u884c\u903b\u8f91\u4e14\u53ca\u65f6\u7684\u5224\u65ad\uff0c\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u6cd5\u672a\u8003\u8651\u73af\u5883\u52a8\u6001\u6027\u3002", "method": "\u5f15\u5165\u5b9e\u65f6\u63a8\u7406\u95ee\u9898\uff0c\u6784\u5efa\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7814\u7a76\u4e24\u79cd\u90e8\u7f72\u8bed\u8a00\u6a21\u578b\u7684\u8303\u5f0f\uff0c\u63d0\u51faAgileThinker\u540c\u65f6\u8fd0\u7528\u4e24\u79cd\u63a8\u7406\u8303\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u73b0\u6709\u6a21\u578b\u5728\u4e24\u79cd\u8303\u5f0f\u4e2d\u96be\u4ee5\u517c\u987e\u903b\u8f91\u548c\u53ca\u65f6\u6027\uff0cAgileThinker\u5728\u4efb\u52a1\u96be\u5ea6\u548c\u65f6\u95f4\u538b\u529b\u589e\u52a0\u65f6\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5b9e\u65f6\u63a8\u7406\u662f\u5f00\u53d1\u5b9e\u7528\u667a\u80fd\u4f53\u7684\u5173\u952e\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4e3a\u65f6\u95f4\u53d7\u9650\u7684AI\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2511.05079", "pdf": "https://arxiv.org/pdf/2511.05079", "abs": "https://arxiv.org/abs/2511.05079", "authors": ["Grigory Kovalev", "Natalia Loukachevitch", "Mikhail Tikhomirov", "Olga Babina", "Pavel Mamaev"], "title": "Wikipedia-based Datasets in Russian Information Retrieval Benchmark RusBEIR", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "In this paper, we present a novel series of Russian information retrieval\ndatasets constructed from the \"Did you know...\" section of Russian Wikipedia.\nOur datasets support a range of retrieval tasks, including fact-checking,\nretrieval-augmented generation, and full-document retrieval, by leveraging\ninteresting facts and their referenced Wikipedia articles annotated at the\nsentence level with graded relevance. We describe the methodology for dataset\ncreation that enables the expansion of existing Russian Information Retrieval\n(IR) resources. Through extensive experiments, we extend the RusBEIR research\nby comparing lexical retrieval models, such as BM25, with state-of-the-art\nneural architectures fine-tuned for Russian, as well as multilingual models.\nResults of our experiments show that lexical methods tend to outperform neural\nmodels on full-document retrieval, while neural approaches better capture\nlexical semantics in shorter texts, such as in fact-checking or fine-grained\nretrieval. Using our newly created datasets, we also analyze the impact of\ndocument length on retrieval performance and demonstrate that combining\nretrieval with neural reranking consistently improves results. Our contribution\nexpands the resources available for Russian information retrieval research and\nhighlights the importance of accurate evaluation of retrieval models to achieve\noptimal performance. All datasets are publicly available at HuggingFace. To\nfacilitate reproducibility and future research, we also release the full\nimplementation on GitHub.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4fc4\u8bed\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u591a\u79cd\u6a21\u578b\uff0c\u5206\u6790\u6587\u6863\u957f\u5ea6\u5f71\u54cd\uff0c\u5f3a\u8c03\u8bc4\u4f30\u91cd\u8981\u6027\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u516c\u5f00\u3002", "motivation": "\u6784\u5efa\u4fc4\u8bed\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u96c6\uff0c\u6269\u5c55\u73b0\u6709\u4fc4\u8bed\u4fe1\u606f\u68c0\u7d22\u8d44\u6e90\uff0c\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u3002", "method": "\u4ece\u4fc4\u8bed\u7ef4\u57fa\u767e\u79d1\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u8bcd\u6cd5\u68c0\u7d22\u6a21\u578b\u3001\u9488\u5bf9\u4fc4\u8bed\u5fae\u8c03\u7684\u795e\u7ecf\u67b6\u6784\u548c\u591a\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u68c0\u7d22\u4e0e\u795e\u7ecf\u91cd\u6392\u3002", "result": "\u8bcd\u6cd5\u65b9\u6cd5\u5728\u5168\u6587\u6863\u68c0\u7d22\u8868\u73b0\u66f4\u597d\uff0c\u795e\u7ecf\u65b9\u6cd5\u5728\u77ed\u6587\u672c\u8bed\u4e49\u6355\u6349\u66f4\u4f73\uff0c\u7ed3\u5408\u68c0\u7d22\u4e0e\u795e\u7ecf\u91cd\u6392\u53ef\u63d0\u5347\u6548\u679c\u3002", "conclusion": "\u6269\u5c55\u4fc4\u8bed\u4fe1\u606f\u68c0\u7d22\u7814\u7a76\u8d44\u6e90\uff0c\u5f3a\u8c03\u51c6\u786e\u8bc4\u4f30\u68c0\u7d22\u6a21\u578b\u5bf9\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.05294", "pdf": "https://arxiv.org/pdf/2511.05294", "abs": "https://arxiv.org/abs/2511.05294", "authors": ["Shaolong Wu"], "title": "Local Technological Access, Income Disparities, and Job-Seeking in the United States Since 2010", "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "comment": "Initial draft: Dec 2021; this version: June 2024. Data: NLSY97\n  (Rounds through 2017). JEL: J15, J21, J62", "summary": "In the modern U.S. labor market, digital infrastructures strongly influence\nhow individuals locate opportunities, build skills, and advance wages. Regional\ndifferences in computing access, broadband coverage, and digital literacy have\nsignificant labor implications for equity and sustainability. Drawing on\nlongitudinal data from the NLSY97 (National Longitudinal Surveys of Youth)\ncohort, this study examines how place-based technological factors, personal\ndemographics, household characteristics, and education shape income levels and\ndecisions to seek new employment. The regression analyses reveal that\neducational attainment, marital status, and frequency of Internet usage\nstrongly predict both wages and individuals' job-seeking intensity. Regional\ndisparities in income underscore the need for more localized interventions to\nensure equitable access to technology. This study raises key questions about\nhow digital infrastructures can reinforce or challenge systemic inequalities in\nunderserved communities.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528NLSY97\u7eb5\u5411\u6570\u636e\uff0c\u5206\u6790\u5730\u57df\u6280\u672f\u56e0\u7d20\u7b49\u5bf9\u6536\u5165\u548c\u6c42\u804c\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u6559\u80b2\u7a0b\u5ea6\u7b49\u56e0\u7d20\u4e0e\u5de5\u8d44\u548c\u6c42\u804c\u5f3a\u5ea6\u7684\u5173\u7cfb\uff0c\u5f3a\u8c03\u9700\u672c\u5730\u5316\u5e72\u9884\u4fdd\u969c\u6280\u672f\u516c\u5e73\u83b7\u53d6\u3002", "motivation": "\u73b0\u4ee3\u7f8e\u56fd\u52b3\u52a8\u529b\u5e02\u573a\u4e2d\uff0c\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u5f71\u54cd\u4e2a\u4eba\u5c31\u4e1a\uff0c\u533a\u57df\u6570\u5b57\u5dee\u5f02\u5bf9\u52b3\u52a8\u529b\u516c\u5e73\u548c\u53ef\u6301\u7eed\u6027\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u7814\u7a76\u76f8\u5173\u56e0\u7d20\u5bf9\u6536\u5165\u548c\u6c42\u804c\u7684\u4f5c\u7528\u3002", "method": "\u5229\u7528NLSY97\u7eb5\u5411\u6570\u636e\u8fdb\u884c\u56de\u5f52\u5206\u6790\u3002", "result": "\u6559\u80b2\u7a0b\u5ea6\u3001\u5a5a\u59fb\u72b6\u51b5\u548c\u4e92\u8054\u7f51\u4f7f\u7528\u9891\u7387\u80fd\u5f3a\u70c8\u9884\u6d4b\u5de5\u8d44\u548c\u6c42\u804c\u5f3a\u5ea6\uff0c\u5b58\u5728\u533a\u57df\u6536\u5165\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u66f4\u591a\u672c\u5730\u5316\u5e72\u9884\u4ee5\u786e\u4fdd\u6280\u672f\u516c\u5e73\u83b7\u53d6\uff0c\u540c\u65f6\u63d0\u51fa\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u5bf9\u670d\u52a1\u4e0d\u8db3\u793e\u533a\u7cfb\u7edf\u6027\u4e0d\u5e73\u7b49\u5f71\u54cd\u7684\u95ee\u9898\u3002"}}
{"id": "2511.05254", "pdf": "https://arxiv.org/pdf/2511.05254", "abs": "https://arxiv.org/abs/2511.05254", "authors": ["Leandro C. Souza", "Laurent E. Dardenne", "Renato Portugal"], "title": "A Gate-Based Quantum Genetic Algorithm for Real-Valued Global Optimization", "categories": ["quant-ph", "cs.AI", "cs.NE"], "comment": "16 pages", "summary": "We propose a gate-based Quantum Genetic Algorithm (QGA) for real-valued\nglobal optimization. In this model, individuals are represented by quantum\ncircuits whose measurement outcomes are decoded into real-valued vectors\nthrough binary discretization. Evolutionary operators act directly on circuit\nstructures, allowing mutation and crossover to explore the space of gate-based\nencodings. Both fixed-depth and variable-depth variants are introduced,\nenabling either uniform circuit complexity or adaptive structural evolution.\nFitness is evaluated through quantum sampling, using the mean decoded output of\nmeasurement outcomes as the argument of the objective function. To isolate the\nimpact of quantum resources, we compare gate sets with and without the Hadamard\ngate, showing that superposition consistently improves convergence and\nrobustness across benchmark functions such as the Rastrigin function.\nFurthermore, we demonstrate that introducing pairwise inter-individual\nentanglement in the population accelerates early convergence, revealing that\nquantum correlations among individuals provide an additional optimization\nadvantage. Together, these results show that both superposition and\nentanglement enhance the search dynamics of evolutionary quantum algorithms,\nestablishing gate-based QGAs as a promising framework for quantum-enhanced\nglobal optimization.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u95e8\u7684\u91cf\u5b50\u9057\u4f20\u7b97\u6cd5\u7528\u4e8e\u5b9e\u503c\u5168\u5c40\u4f18\u5316\uff0c\u5bf9\u6bd4\u4e0d\u540c\u95e8\u96c6\uff0c\u8bc1\u660e\u53e0\u52a0\u548c\u7ea0\u7f20\u80fd\u589e\u5f3a\u7b97\u6cd5\u641c\u7d22\u80fd\u529b\u3002", "motivation": "\u5bfb\u627e\u91cf\u5b50\u589e\u5f3a\u7684\u5168\u5c40\u4f18\u5316\u65b9\u6cd5\uff0c\u63a2\u7d22\u91cf\u5b50\u8d44\u6e90\u5bf9\u4f18\u5316\u7b97\u6cd5\u7684\u5f71\u54cd\u3002", "method": "\u7528\u91cf\u5b50\u7535\u8def\u8868\u793a\u4e2a\u4f53\uff0c\u8fdb\u5316\u7b97\u5b50\u4f5c\u7528\u4e8e\u7535\u8def\u7ed3\u6784\uff0c\u901a\u8fc7\u91cf\u5b50\u91c7\u6837\u8bc4\u4f30\u9002\u5e94\u5ea6\uff0c\u5bf9\u6bd4\u4e0d\u540c\u95e8\u96c6\u548c\u5f15\u5165\u4e2a\u4f53\u95f4\u7ea0\u7f20\u3002", "result": "\u53e0\u52a0\u80fd\u63d0\u9ad8\u6536\u655b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e2a\u4f53\u95f4\u7ea0\u7f20\u53ef\u52a0\u901f\u65e9\u671f\u6536\u655b\u3002", "conclusion": "\u53e0\u52a0\u548c\u7ea0\u7f20\u53ef\u589e\u5f3a\u8fdb\u5316\u91cf\u5b50\u7b97\u6cd5\u641c\u7d22\u52a8\u6001\uff0c\u57fa\u4e8e\u95e8\u7684\u91cf\u5b50\u9057\u4f20\u7b97\u6cd5\u662f\u6709\u524d\u666f\u7684\u91cf\u5b50\u589e\u5f3a\u5168\u5c40\u4f18\u5316\u6846\u67b6\u3002"}}
{"id": "2511.05165", "pdf": "https://arxiv.org/pdf/2511.05165", "abs": "https://arxiv.org/abs/2511.05165", "authors": ["Ahmad Hatahet", "Christoph Knieke", "Andreas Rausch"], "title": "Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Software Architecture Descriptions (SADs) are essential for managing the\ninherent complexity of modern software systems. They enable high-level\narchitectural reasoning, guide design decisions, and facilitate effective\ncommunication among diverse stakeholders. However, in practice, SADs are often\nmissing, outdated, or poorly aligned with the system's actual implementation.\nConsequently, developers are compelled to derive architectural insights\ndirectly from source code-a time-intensive process that increases cognitive\nload, slows new developer onboarding, and contributes to the gradual\ndegradation of clarity over the system's lifetime. To address these issues, we\npropose a semi-automated generation of SADs from source code by integrating\nreverse engineering (RE) techniques with a Large Language Model (LLM). Our\napproach recovers both static and behavioral architectural views by extracting\na comprehensive component diagram, filtering architecturally significant\nelements (core components) via prompt engineering, and generating state machine\ndiagrams to model component behavior based on underlying code logic with\nfew-shots prompting. This resulting views representation offer a scalable and\nmaintainable alternative to traditional manual architectural documentation.\nThis methodology, demonstrated using C++ examples, highlights the potent\ncapability of LLMs to: 1) abstract the component diagram, thereby reducing the\nreliance on human expert involvement, and 2) accurately represent complex\nsoftware behaviors, especially when enriched with domain-specific knowledge\nthrough few-shot prompting. These findings suggest a viable path toward\nsignificantly reducing manual effort while enhancing system understanding and\nlong-term maintainability.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u6e90\u4ee3\u7801\u534a\u81ea\u52a8\u5316\u751f\u6210\u8f6f\u4ef6\u67b6\u6784\u63cf\u8ff0\uff08SADs\uff09\uff0c\u7ed3\u5408\u9006\u5411\u5de5\u7a0b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u51cf\u5c11\u4eba\u5de5\u5e76\u589e\u5f3a\u7cfb\u7edf\u53ef\u7ef4\u62a4\u6027\u3002", "motivation": "\u5b9e\u9645\u4e2dSADs\u5e38\u7f3a\u5931\u3001\u8fc7\u65f6\u6216\u4e0e\u5b9e\u73b0\u4e0d\u7b26\uff0c\u5f00\u53d1\u8005\u4ece\u4ee3\u7801\u83b7\u53d6\u67b6\u6784\u4fe1\u606f\u8017\u65f6\u4e14\u589e\u52a0\u8ba4\u77e5\u8d1f\u62c5\u3002", "method": "\u7ed3\u5408\u9006\u5411\u5de5\u7a0b\u6280\u672f\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u53d6\u7ec4\u4ef6\u56fe\u3001\u8fc7\u6ee4\u5173\u952e\u5143\u7d20\u3001\u751f\u6210\u72b6\u6001\u673a\u56fe\u3002", "result": "\u751f\u6210\u7684\u89c6\u56fe\u53ef\u66ff\u4ee3\u4f20\u7edf\u624b\u52a8\u67b6\u6784\u6587\u6863\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u62bd\u8c61\u7ec4\u4ef6\u56fe\u3001\u51c6\u786e\u8868\u793a\u590d\u6742\u884c\u4e3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u663e\u8457\u51cf\u5c11\u4eba\u5de5\uff0c\u589e\u5f3a\u7cfb\u7edf\u7406\u89e3\u548c\u957f\u671f\u53ef\u7ef4\u62a4\u6027\u3002"}}
{"id": "2511.04723", "pdf": "https://arxiv.org/pdf/2511.04723", "abs": "https://arxiv.org/abs/2511.04723", "authors": ["Mohamadreza Akbari Pour", "Mohamad Sadeq Karimi", "Amir Hossein Mazloumi"], "title": "Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Health prediction is crucial for ensuring reliability, minimizing downtime,\nand optimizing maintenance in industrial systems. Remaining Useful Life (RUL)\nprediction is a key component of this process; however, many existing models\nstruggle to capture fine-grained temporal dependencies while dynamically\nprioritizing critical features across time for robust prognostics. To address\nthese challenges, we propose a novel framework that integrates Temporal\nConvolutional Networks (TCNs) for localized temporal feature extraction with a\nmodified Temporal Fusion Transformer (TFT) enhanced by Bi-LSTM encoder-decoder.\nThis architecture effectively bridges short- and long-term dependencies while\nemphasizing salient temporal patterns. Furthermore, the incorporation of a\nmulti-time-window methodology improves adaptability across diverse operating\nconditions. Extensive evaluations on benchmark datasets demonstrate that the\nproposed model reduces the average RMSE by up to 5.5%, underscoring its\nimproved predictive accuracy compared to state-of-the-art methods. By closing\ncritical gaps in current approaches, this framework advances the effectiveness\nof industrial prognostic systems and highlights the potential of advanced\ntime-series transformers for RUL prediction.", "AI": {"tldr": "\u63d0\u51fa\u96c6\u6210TCNs\u4e0e\u6539\u8fdbTFT\u7684\u6846\u67b6\u7528\u4e8eRUL\u9884\u6d4b\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u6355\u6349\u7ec6\u7c92\u5ea6\u65f6\u95f4\u4f9d\u8d56\u548c\u52a8\u6001\u533a\u5206\u5173\u952e\u7279\u5f81\uff0c\u9700\u6539\u8fdb\u5de5\u4e1a\u7cfb\u7edf\u5065\u5eb7\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u96c6\u6210TCNs\u8fdb\u884c\u5c40\u90e8\u65f6\u95f4\u7279\u5f81\u63d0\u53d6\uff0c\u7ed3\u5408\u7531Bi - LSTM\u7f16\u7801\u5668 - \u89e3\u7801\u5668\u6539\u8fdb\u7684TFT\u7684\u6846\u67b6\uff0c\u91c7\u7528\u591a\u65f6\u95f4\u7a97\u53e3\u65b9\u6cd5\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6a21\u578b\u5e73\u5747RMSE\u6700\u591a\u964d\u4f4e5.5%\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u9884\u6d4b\u66f4\u51c6\u786e\u3002", "conclusion": "\u8be5\u6846\u67b6\u5f25\u8865\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u63d0\u9ad8\u5de5\u4e1a\u9884\u6d4b\u7cfb\u7edf\u6709\u6548\u6027\uff0c\u51f8\u663e\u5148\u8fdb\u65f6\u95f4\u5e8f\u5217\u53d8\u538b\u5668\u7528\u4e8eRUL\u9884\u6d4b\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.04852", "pdf": "https://arxiv.org/pdf/2511.04852", "abs": "https://arxiv.org/abs/2511.04852", "authors": ["Erjia Cui", "Angela Zhao", "Ciprian M. Crainiceanu"], "title": "Inference for the Extended Functional Cox Model: A UK Biobank Case Study", "categories": ["stat.ME", "stat.AP", "stat.CO"], "comment": "33 pages, 4 figures, 1 table", "summary": "Multiple studies have shown that scalar summaries of objectively measured\nphysical activity (PA) using accelerometers are the strongest predictors of\nmortality, outperforming all traditional risk factors, including age, sex, body\nmass index (BMI), and smoking. Here we show that diurnal patterns of PA and\ntheir day-to-day variability provide additional information about mortality. To\ndo that, we introduce a class of extended functional Cox models and\ncorresponding inferential tools designed to quantify the association between\nmultiple functional and scalar predictors with time-to-event outcomes in\nlarge-scale (large $n$) high-dimensional (large $p$) datasets. Methods are\napplied to the UK Biobank study, which collected PA at every minute of the day\nfor up to seven days, as well as time to mortality ($93{,}370$ participants\nwith good quality accelerometry data and $931$ events). Simulation studies show\nthat methods perform well in realistic scenarios and scale up to studies an\norder of magnitude larger than the UK Biobank accelerometry study. Establishing\nthe feasibility and scalability of these methods for such complex and large\ndata sets is a major milestone in applied Functional Data Analysis (FDA).", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u8eab\u4f53\u6d3b\u52a8\uff08PA\uff09\u7684\u663c\u591c\u6a21\u5f0f\u53ca\u5176\u65e5\u5e38\u53d8\u5f02\u6027\u53ef\u63d0\u4f9b\u66f4\u591a\u5173\u4e8e\u6b7b\u4ea1\u7387\u7684\u4fe1\u606f\uff0c\u5f15\u5165\u6269\u5c55\u529f\u80fdCox\u6a21\u578b\u53ca\u63a8\u7406\u5de5\u5177\u5e76\u5e94\u7528\u4e8eUK Biobank\u7814\u7a76\uff0c\u6a21\u62df\u7814\u7a76\u663e\u793a\u65b9\u6cd5\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u52a0\u901f\u5ea6\u8ba1\u6d4b\u91cf\u7684PA\u6807\u91cf\u6458\u8981\u5bf9\u6b7b\u4ea1\u7387\u9884\u6d4b\u80fd\u529b\u5f3a\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7a76PA\u7684\u663c\u591c\u6a21\u5f0f\u53ca\u5176\u65e5\u5e38\u53d8\u5f02\u6027\u662f\u5426\u80fd\u63d0\u4f9b\u66f4\u591a\u5173\u4e8e\u6b7b\u4ea1\u7387\u7684\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u6269\u5c55\u529f\u80fdCox\u6a21\u578b\u53ca\u76f8\u5e94\u63a8\u7406\u5de5\u5177\uff0c\u7528\u4e8e\u91cf\u5316\u5927\u89c4\u6a21\u9ad8\u7ef4\u6570\u636e\u4e2d\u591a\u4e2a\u529f\u80fd\u548c\u6807\u91cf\u9884\u6d4b\u56e0\u5b50\u4e0e\u4e8b\u4ef6\u53d1\u751f\u65f6\u95f4\u7ed3\u679c\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u5e76\u5e94\u7528\u4e8eUK Biobank\u7814\u7a76\u3002", "result": "\u6a21\u62df\u7814\u7a76\u663e\u793a\u65b9\u6cd5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u53ef\u6269\u5c55\u5230\u6bd4UK Biobank\u52a0\u901f\u5ea6\u8ba1\u7814\u7a76\u5927\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u7814\u7a76\u3002", "conclusion": "\u5efa\u7acb\u8fd9\u4e9b\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u5927\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u884c\u6027\u548c\u53ef\u6269\u5c55\u6027\u662f\u5e94\u7528\u529f\u80fd\u6570\u636e\u5206\u6790\u7684\u4e00\u4e2a\u91cd\u8981\u91cc\u7a0b\u7891\u3002"}}
{"id": "2511.05452", "pdf": "https://arxiv.org/pdf/2511.05452", "abs": "https://arxiv.org/abs/2511.05452", "authors": ["Wenqian Chen", "Amanda Howard", "Panos Stinis"], "title": "Self-adaptive weighting and sampling for physics-informed neural networks", "categories": ["stat.ML", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": "11 figures", "summary": "Physics-informed deep learning has emerged as a promising framework for\nsolving partial differential equations (PDEs). Nevertheless, training these\nmodels on complex problems remains challenging, often leading to limited\naccuracy and efficiency. In this work, we introduce a hybrid adaptive sampling\nand weighting method to enhance the performance of physics-informed neural\nnetworks (PINNs). The adaptive sampling component identifies training points in\nregions where the solution exhibits rapid variation, while the adaptive\nweighting component balances the convergence rate across training points.\nNumerical experiments show that applying only adaptive sampling or only\nadaptive weighting is insufficient to consistently achieve accurate\npredictions, particularly when training points are scarce. Since each method\nemphasizes different aspects of the solution, their effectiveness is problem\ndependent. By combining both strategies, the proposed framework consistently\nimproves prediction accuracy and training efficiency, offering a more robust\napproach for solving PDEs with PINNs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6df7\u5408\u81ea\u9002\u5e94\u91c7\u6837\u548c\u52a0\u6743\u65b9\u6cd5\u63d0\u5347\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u7684\u6027\u80fd\uff0c\u7ed3\u5408\u4e24\u79cd\u7b56\u7565\u80fd\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7269\u7406\u4fe1\u606f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u4e0a\u8bad\u7ec3\u5b58\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u6df7\u5408\u81ea\u9002\u5e94\u91c7\u6837\u548c\u52a0\u6743\u65b9\u6cd5\uff0c\u81ea\u9002\u5e94\u91c7\u6837\u8bc6\u522b\u89e3\u5feb\u901f\u53d8\u5316\u533a\u57df\u7684\u8bad\u7ec3\u70b9\uff0c\u81ea\u9002\u5e94\u52a0\u6743\u5e73\u8861\u8bad\u7ec3\u70b9\u7684\u6536\u655b\u7387\u3002", "result": "\u4ec5\u4f7f\u7528\u81ea\u9002\u5e94\u91c7\u6837\u6216\u52a0\u6743\u5728\u8bad\u7ec3\u70b9\u4e0d\u8db3\u65f6\u96be\u4ee5\u5b9e\u73b0\u51c6\u786e\u9884\u6d4b\uff0c\u4e24\u79cd\u65b9\u6cd5\u6548\u679c\u56e0\u95ee\u9898\u800c\u5f02\uff0c\u7ed3\u5408\u4e8c\u8005\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u4e3aPINNs\u6c42\u89e3PDEs\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\uff0c\u80fd\u6301\u7eed\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2511.05209", "pdf": "https://arxiv.org/pdf/2511.05209", "abs": "https://arxiv.org/abs/2511.05209", "authors": ["Jorge V\u00e1zquez-P\u00e9rez", "Daniel Exp\u00f3sito-Pati\u00f1o", "Marta Losada", "\u00c1lvaro Carballido", "Andr\u00e9s G\u00f3mez", "Tom\u00e1s F. Pena"], "title": "CUNQA: a Distributed Quantum Computing emulator for HPC", "categories": ["quant-ph", "cs.DC", "D.1.3; J.2; D.2.11"], "comment": null, "summary": "The challenge of scaling quantum computers to gain computational power is\nexpected to lead to architectures with multiple connected quantum processing\nunits (QPUs), commonly referred to as Distributed Quantum Computing (DQC). In\nparallel, there is a growing momentum toward treating quantum computers as\naccelerators, integrating them into the heterogeneous architectures of\nhigh-performance computing (HPC) environments. This work combines these two\nforeseeable futures in CUNQA, an open-source DQC emulator designed for HPC\nenvironments that allows testing, evaluating and studying DQC in HPC before it\neven becomes real. It implements the three DQC models of no-communication,\nclassical-communication and quantum-communication; which will be examined in\nthis work. Addressing programming considerations, explaining emulation and\nsimulation details, and delving into the specifics of the implementation will\nbe part of the effort. The well-known Quantum Phase Estimation (QPE) algorithm\nis used to demonstrate and analyze the emulation of the models. To the best of\nour knowledge, CUNQA is the first tool designed to emulate the three DQC\nschemes in an HPC environment.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5f00\u6e90DQC\u6a21\u62df\u5668CUNQA\uff0c\u53ef\u5728HPC\u73af\u5883\u4e2d\u6d4b\u8bd5\u3001\u8bc4\u4f30\u548c\u7814\u7a76DQC\uff0c\u5b9e\u73b0\u4e09\u79cdDQC\u6a21\u578b\uff0c\u5e76\u7528QPE\u7b97\u6cd5\u6f14\u793a\u5206\u6790\uff0c\u662f\u9996\u4e2a\u5728HPC\u73af\u5883\u4e2d\u6a21\u62df\u4e09\u79cdDQC\u65b9\u6848\u7684\u5de5\u5177\u3002", "motivation": "\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u673a\u6269\u5c55\u6311\u6218\uff0c\u5c06\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u7ed3\u5408\uff0c\u5728DQC\u6210\u4e3a\u73b0\u5b9e\u524d\u8fdb\u884c\u6d4b\u8bd5\u7814\u7a76\u3002", "method": "\u5b9e\u73b0\u65e0\u901a\u4fe1\u3001\u7ecf\u5178\u901a\u4fe1\u548c\u91cf\u5b50\u901a\u4fe1\u4e09\u79cdDQC\u6a21\u578b\uff0c\u7528QPE\u7b97\u6cd5\u6f14\u793a\u5206\u6790\u6a21\u578b\u7684\u4eff\u771f\u3002", "result": "\u5f00\u53d1\u51faCUNQA\u6a21\u62df\u5668\uff0c\u53ef\u5728HPC\u73af\u5883\u4e2d\u5bf9\u4e09\u79cdDQC\u6a21\u578b\u8fdb\u884c\u4eff\u771f\u3002", "conclusion": "CUNQA\u662f\u9996\u4e2a\u80fd\u5728HPC\u73af\u5883\u4e2d\u6a21\u62df\u4e09\u79cdDQC\u65b9\u6848\u7684\u5de5\u5177\u3002"}}
{"id": "2511.05285", "pdf": "https://arxiv.org/pdf/2511.05285", "abs": "https://arxiv.org/abs/2511.05285", "authors": ["Kenny Be\u0161ter \u0160torgel", "Cl\u00e9ment Dallard", "Vadim Lozin", "Martin Milani\u010d", "Viktor Zamaraev"], "title": "Awesome graph parameters", "categories": ["math.CO", "cs.DM", "cs.DS", "05C75 (Primary), 05D10, 05C69, 05C65, 05C85 (Secondary)"], "comment": null, "summary": "For a graph $G$, we denote by $\\alpha(G)$ the size of a maximum independent\nset and by $\\omega(G)$ the size of a maximum clique in $G$. Our paper lies on\nthe edge of two lines of research, related to $\\alpha$ and $\\omega$,\nrespectively. One of them studies $\\alpha$-variants of graph parameters, such\nas $\\alpha$-treewidth or $\\alpha$-degeneracy. The second line deals with graph\nclasses where some parameters are bounded by a function of $\\omega(G)$. A\nfamous example of this type is the family of $\\chi$-bounded classes, where the\nchromatic number $\\chi(G)$ is bounded by a function of $\\omega(G)$.\n  A Ramsey-type argument implies that if the $\\alpha$-variant of a graph\nparameter $\\rho$ is bounded by a constant in a class $\\mathcal{G}$, then $\\rho$\nis bounded by a function of $\\omega$ in $\\mathcal{G}$. If the reverse\nimplication also holds, we say that $\\rho$ is awesome. Otherwise, we say that\n$\\rho$ is awful. In the present paper, we identify a number of awesome and\nawful graph parameters, derive some algorithmic applications of awesomeness,\nand propose a number of open problems related to these notions.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.04956", "pdf": "https://arxiv.org/pdf/2511.04956", "abs": "https://arxiv.org/abs/2511.04956", "authors": ["Maria Mahbub", "Vanessa Lama", "Sanjay Das", "Brian Starks", "Christopher Polchek", "Saffell Silvers", "Lauren Deck", "Prasanna Balaprakash", "Tirthankar Ghosal"], "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of\nEnergy (DOE) sites, where inventories include sensitive and often dual-use\nequipment. Compliance must track evolving rules designated by various export\ncontrol policies to make transparent and auditable decisions. Traditional\nexpert-only workflows are time-consuming, backlog-prone, and struggle to keep\npace with shifting regulatory boundaries. We demo ORCHID, a modular agentic\nsystem for HRP classification that pairs retrieval-augmented generation (RAG)\nwith human oversight to produce policy-based outputs that can be audited. Small\ncooperating agents, retrieval, description refiner, classifier, validator, and\nfeedback logger, coordinate via agent-to-agent messaging and invoke tools\nthrough the Model Context Protocol (MCP) for model-agnostic on-premise\noperation. The interface follows an Item to Evidence to Decision loop with\nstep-by-step reasoning, on-policy citations, and append-only audit bundles\n(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID\nimproves accuracy and traceability over a non-agentic baseline while deferring\nuncertain items to Subject Matter Experts (SMEs). The demonstration shows\nsingle item submission, grounded citations, SME feedback capture, and\nexportable audit artifacts, illustrating a practical path to trustworthy LLM\nassistance in sensitive DOE compliance workflows.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7528\u4e8e\u9ad8\u98ce\u9669\u8d44\u4ea7\uff08HRP\uff09\u5206\u7c7b\u7684\u6a21\u5757\u5316\u667a\u80fd\u7cfb\u7edfORCHID\uff0c\u5b83\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4eba\u5de5\u76d1\u7763\uff0c\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u4f20\u7edf\u4ec5\u4f9d\u8d56\u4e13\u5bb6\u7684HRP\u5206\u7c7b\u5de5\u4f5c\u6d41\u7a0b\u8017\u65f6\u3001\u6613\u79ef\u538b\u4e14\u96be\u4ee5\u8ddf\u4e0a\u76d1\u7ba1\u53d8\u5316\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u6a21\u5757\u5316\u667a\u80fd\u7cfb\u7edfORCHID\uff0c\u5c0f\u534f\u4f5c\u4ee3\u7406\u901a\u8fc7\u4ee3\u7406\u95f4\u6d88\u606f\u534f\u8c03\uff0c\u5229\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u64cd\u4f5c\uff0c\u754c\u9762\u9075\u5faa\u7279\u5b9a\u5faa\u73af\u5e76\u63d0\u4f9b\u9010\u6b65\u63a8\u7406\u548c\u5ba1\u8ba1\u5305\u3002", "result": "\u5728\u5b9e\u9645HRP\u6848\u4f8b\u7684\u521d\u6b65\u6d4b\u8bd5\u4e2d\uff0cORCHID\u6bd4\u975e\u667a\u80fd\u57fa\u7ebf\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u5c06\u4e0d\u786e\u5b9a\u9879\u76ee\u4ea4\u7531\u4e13\u5bb6\u5904\u7406\u3002", "conclusion": "\u5c55\u793a\u4e86ORCHID\u5728\u654f\u611f\u7684\u7f8e\u56fd\u80fd\u6e90\u90e8\u5408\u89c4\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u63d0\u4f9b\u53ef\u4fe1\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2511.05301", "pdf": "https://arxiv.org/pdf/2511.05301", "abs": "https://arxiv.org/abs/2511.05301", "authors": ["Arthur Satouf", "Yuxuan Zong", "Habiboulaye Amadou-Boubacar", "Pablo Piantanida", "Benjamin Piwowarski"], "title": "QUESTER: Query Specification for Generative Retrieval", "categories": ["cs.IR", "cs.CL", "cs.LG", "68P20, 68T50", "H.3"], "comment": null, "summary": "Generative Retrieval (GR) differs from the traditional index-then-retrieve\npipeline by storing relevance in model parameters and directly generating\ndocument identifiers. However, GR often struggles to generalize and is costly\nto scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval),\nwhich reframes GR as query specification generation - in this work, a simple\nkeyword query handled by BM25 - using a (small) LLM. The policy is trained\nusing reinforcement learning techniques (GRPO). Across in- and out-of-domain\nevaluations, we show that our model is more effective than BM25, and\ncompetitive with neural IR models, while maintaining a good efficiency", "AI": {"tldr": "\u63d0\u51faQUESTER\u65b9\u6cd5\uff0c\u5c06\u751f\u6210\u5f0f\u68c0\u7d22\u91cd\u6784\u4e3a\u67e5\u8be2\u89c4\u8303\u751f\u6210\uff0c\u6a21\u578b\u5728\u8bc4\u4f30\u4e2d\u6bd4BM25\u6709\u6548\uff0c\u4e0e\u795e\u7ecfIR\u6a21\u578b\u6709\u7ade\u4e89\u529b\u4e14\u6548\u7387\u9ad8\u3002", "motivation": "\u751f\u6210\u5f0f\u68c0\u7d22\uff08GR\uff09\u6cdb\u5316\u56f0\u96be\u4e14\u6269\u5c55\u6210\u672c\u9ad8\u3002", "method": "\u5c06GR\u91cd\u6784\u4e3a\u67e5\u8be2\u89c4\u8303\u751f\u6210\uff0c\u4f7f\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7b80\u5355\u5173\u952e\u8bcd\u67e5\u8be2\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff08GRPO\uff09\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u6a21\u578b\u5728\u5185\u5916\u9886\u57df\u8bc4\u4f30\u4e2d\u6bd4BM25\u66f4\u6709\u6548\uff0c\u4e0e\u795e\u7ecfIR\u6a21\u578b\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "QUESTER\u65b9\u6cd5\u5728\u4fdd\u8bc1\u6548\u7387\u7684\u540c\u65f6\u6709\u8f83\u597d\u7684\u68c0\u7d22\u6548\u679c\u3002"}}
{"id": "2511.05205", "pdf": "https://arxiv.org/pdf/2511.05205", "abs": "https://arxiv.org/abs/2511.05205", "authors": ["Huimin Hu", "Michael Pradel"], "title": "CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits", "categories": ["cs.SE"], "comment": null, "summary": "During software evolution, developers commonly face the problem of mapping a\nspecific code region from one commit to another. For example, they may want to\ndetermine how the condition of an if-statement, a specific line in a\nconfiguration file, or the definition of a function changes. We call this the\ncode mapping problem. Existing techniques, such as git diff, address this\nproblem only insufficiently because they show all changes made to a file\ninstead of focusing on a code region of the developer's choice. Other\ntechniques focus on specific code elements and programming languages (e.g.,\nmethods in Java), limiting their applicability. This paper introduces\nCodeMapper, an approach to address the code mapping problem in a way that is\nindependent of specific program elements and programming languages. Given a\ncode region in one commit, CodeMapper finds the corresponding region in another\ncommit. The approach consists of two phases: (i) computing candidate regions by\nanalyzing diffs, detecting code movements, and searching for specific code\nfragments, and (ii) selecting the most likely target region by calculating\nsimilarities. Our evaluation applies CodeMapper to four datasets, including two\nnew hand-annotated datasets containing code region pairs in ten popular\nprogramming languages. CodeMapper correctly identifies the expected target\nregion in 71.0%--94.5% of all cases, improving over the best available\nbaselines by 1.5--58.8 absolute percent points.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CodeMapper\u65b9\u6cd5\u89e3\u51b3\u4ee3\u7801\u6620\u5c04\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u72ec\u7acb\u4e8e\u7279\u5b9a\u7a0b\u5e8f\u5143\u7d20\u548c\u7f16\u7a0b\u8bed\u8a00\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u5982git diff\u4e0d\u80fd\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u6620\u5c04\u95ee\u9898\uff0c\u5176\u4ed6\u6280\u672f\u53c8\u5c40\u9650\u4e8e\u7279\u5b9a\u4ee3\u7801\u5143\u7d20\u548c\u7f16\u7a0b\u8bed\u8a00\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "CodeMapper\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u4e00\u662f\u901a\u8fc7\u5206\u6790\u5dee\u5f02\u3001\u68c0\u6d4b\u4ee3\u7801\u79fb\u52a8\u548c\u641c\u7d22\u7279\u5b9a\u4ee3\u7801\u7247\u6bb5\u8ba1\u7b97\u5019\u9009\u533a\u57df\uff1b\u4e8c\u662f\u901a\u8fc7\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u9009\u62e9\u6700\u53ef\u80fd\u7684\u76ee\u6807\u533a\u57df\u3002", "result": "\u5c06CodeMapper\u5e94\u7528\u4e8e\u56db\u4e2a\u6570\u636e\u96c6\uff0c\u572871.0% - 94.5%\u7684\u60c5\u51b5\u4e0b\u80fd\u6b63\u786e\u8bc6\u522b\u76ee\u6807\u533a\u57df\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u9ad81.5 - 58.8\u4e2a\u7edd\u5bf9\u767e\u5206\u70b9\u3002", "conclusion": "CodeMapper\u80fd\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u6620\u5c04\u95ee\u9898\uff0c\u4e14\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.04751", "pdf": "https://arxiv.org/pdf/2511.04751", "abs": "https://arxiv.org/abs/2511.04751", "authors": ["Matteo Cercola", "Michele Lomuscio", "Dario Piga", "Simone Formentin"], "title": "Regularized GLISp for sensor-guided human-in-the-loop optimization", "categories": ["cs.LG"], "comment": null, "summary": "Human-in-the-loop calibration is often addressed via preference-based\noptimization, where algorithms learn from pairwise comparisons rather than\nexplicit cost evaluations. While effective, methods such as Preferential\nBayesian Optimization or Global optimization based on active preference\nlearning with radial basis functions (GLISp) treat the system as a black box\nand ignore informative sensor measurements. In this work, we introduce a\nsensor-guided regularized extension of GLISp that integrates measurable\ndescriptors into the preference-learning loop through a physics-informed\nhypothesis function and a least-squares regularization term. This injects\ngrey-box structure, combining subjective feedback with quantitative sensor\ninformation while preserving the flexibility of preference-based search.\nNumerical evaluations on an analytical benchmark and on a human-in-the-loop\nvehicle suspension tuning task show faster convergence and superior final\nsolutions compared to baseline GLISp.", "AI": {"tldr": "\u63d0\u51faGLISp\u7684\u4f20\u611f\u5668\u5f15\u5bfc\u6b63\u5219\u5316\u6269\u5c55\uff0c\u7ed3\u5408\u4e3b\u89c2\u53cd\u9988\u4e0e\u5b9a\u91cf\u4f20\u611f\u5668\u4fe1\u606f\uff0c\u5728\u6570\u503c\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebfGLISp\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u504f\u597d\u4f18\u5316\u7684\u4eba\u5728\u73af\u6821\u51c6\u65b9\u6cd5\u5c06\u7cfb\u7edf\u89c6\u4e3a\u9ed1\u76d2\uff0c\u5ffd\u7565\u4e86\u4fe1\u606f\u4e30\u5bcc\u7684\u4f20\u611f\u5668\u6d4b\u91cf\u3002", "method": "\u5f15\u5165GLISp\u7684\u4f20\u611f\u5668\u5f15\u5bfc\u6b63\u5219\u5316\u6269\u5c55\uff0c\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u5047\u8bbe\u51fd\u6570\u548c\u6700\u5c0f\u4e8c\u4e58\u6b63\u5219\u5316\u9879\u5c06\u53ef\u6d4b\u91cf\u63cf\u8ff0\u7b26\u96c6\u6210\u5230\u504f\u597d\u5b66\u4e60\u5faa\u73af\u4e2d\u3002", "result": "\u5728\u5206\u6790\u57fa\u51c6\u548c\u4eba\u5728\u73af\u8f66\u8f86\u60ac\u67b6\u8c03\u6574\u4efb\u52a1\u7684\u6570\u503c\u8bc4\u4f30\u4e2d\uff0c\u6bd4\u57fa\u7ebfGLISp\u6536\u655b\u66f4\u5feb\uff0c\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u66f4\u4f18\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e3b\u89c2\u53cd\u9988\u548c\u5b9a\u91cf\u4f20\u611f\u5668\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u57fa\u4e8e\u504f\u597d\u641c\u7d22\u7684\u7075\u6d3b\u6027\uff0c\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.04859", "pdf": "https://arxiv.org/pdf/2511.04859", "abs": "https://arxiv.org/abs/2511.04859", "authors": ["Yik Lun Kei", "Oscar Hernan Madrid Padilla", "Rebecca Killick", "James Wilson", "Xi Chen", "Robert Lund"], "title": "Clustering in Networks with Time-varying Nodal Attributes", "categories": ["stat.ME", "stat.CO"], "comment": null, "summary": "This manuscript studies nodal clustering in graphs having a time series at\neach node. The framework includes priors for low-dimensional representations\nand a decoder that bridges the latent representations and time series. The\nstructural and temporal patterns are fused into representations that facilitate\nclustering, addressing the limitation that the evolution of nodal attributes is\noften overlooked. Parameters are learned via maximum approximate likelihood,\nwith a graph-fused LASSO regularization imposed on prior parameters. The\noptimization problem is solved via alternating direction method of multipliers;\nLangevin dynamics are employed for posterior inference. Simulation studies on\nblock and grid graphs with autoregressive dynamics, and applications to\nCalifornia county temperatures and a book word co-occurrence network\ndemonstrate the effectiveness of the proposed method.", "AI": {"tldr": "\u7814\u7a76\u5e26\u65f6\u95f4\u5e8f\u5217\u56fe\u7684\u8282\u70b9\u805a\u7c7b\uff0c\u63d0\u51fa\u878d\u5408\u7ed3\u6784\u548c\u65f6\u95f4\u6a21\u5f0f\u7684\u65b9\u6cd5\u5e76\u9a8c\u8bc1\u6709\u6548\u6027", "motivation": "\u89e3\u51b3\u56fe\u8282\u70b9\u805a\u7c7b\u4e2d\u8282\u70b9\u5c5e\u6027\u6f14\u5316\u5e38\u88ab\u5ffd\u89c6\u7684\u95ee\u9898", "method": "\u6784\u5efa\u542b\u4f4e\u7ef4\u8868\u793a\u5148\u9a8c\u548c\u89e3\u7801\u5668\u7684\u6846\u67b6\uff0c\u7528\u6700\u5927\u8fd1\u4f3c\u4f3c\u7136\u5b66\u4e60\u53c2\u6570\uff0c\u52a0\u56fe\u878d\u5408LASSO\u6b63\u5219\u5316\uff0c\u7528\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5\u6c42\u89e3\u4f18\u5316\u95ee\u9898\uff0cLangevin\u52a8\u529b\u5b66\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad", "result": "\u5728\u5757\u548c\u7f51\u683c\u56fe\u7684\u6a21\u62df\u7814\u7a76\u53ca\u52a0\u5dde\u53bf\u6e29\u5ea6\u3001\u4e66\u7c4d\u8bcd\u5171\u73b0\u7f51\u7edc\u5e94\u7528\u4e2d\u8bc1\u660e\u65b9\u6cd5\u6709\u6548", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5e26\u65f6\u95f4\u5e8f\u5217\u56fe\u7684\u8282\u70b9\u805a\u7c7b\u95ee\u9898"}}
{"id": "2410.07961", "pdf": "https://arxiv.org/pdf/2410.07961", "abs": "https://arxiv.org/abs/2410.07961", "authors": ["Rui Yang", "Ziruo Wang", "Yuntian Gu", "Tianyi Chen", "Yitao Liang", "Tongyang Li"], "title": "QCircuitBench: A Large-Scale Dataset for Benchmarking Quantum Algorithm Design", "categories": ["quant-ph", "cs.DS", "cs.LG", "stat.ML"], "comment": "45 pages, 17 figures, 15 tables, GitHub repository:\n  https://github.com/EstelYang/QCircuitBench", "summary": "Quantum computing is an emerging field recognized for the significant speedup\nit offers over classical computing through quantum algorithms. However,\ndesigning and implementing quantum algorithms pose challenges due to the\ncomplex nature of quantum mechanics and the necessity for precise control over\nquantum states. Despite the significant advancements in AI, there has been a\nlack of datasets specifically tailored for this purpose. In this work, we\nintroduce QCircuitBench, the first benchmark dataset designed to evaluate AI's\ncapability in designing and implementing quantum algorithms using quantum\nprogramming languages. Unlike using AI for writing traditional codes, this task\nis fundamentally more complicated due to highly flexible design space. Our key\ncontributions include: 1. A general framework which formulates the key features\nof quantum algorithm design for Large Language Models. 2. Implementations for\nquantum algorithms from basic primitives to advanced applications, spanning 3\ntask suites, 25 algorithms, and 120,290 data points. 3. Automatic validation\nand verification functions, allowing for iterative evaluation and interactive\nreasoning without human inspection. 4. Promising potential as a training\ndataset through preliminary fine-tuning results. We observed several\ninteresting experimental phenomena: LLMs tend to exhibit consistent error\npatterns, and fine-tuning does not always outperform few-shot learning. In all,\nQCircuitBench is a comprehensive benchmark for LLM-driven quantum algorithm\ndesign, and it reveals limitations of LLMs in this domain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u8bbe\u8ba1\u548c\u5b9e\u73b0\u91cf\u5b50\u7b97\u6cd5\u80fd\u529b\u7684\u57fa\u51c6\u6570\u636e\u96c6QCircuitBench\uff0c\u9610\u8ff0\u5176\u8d21\u732e\u3001\u5b9e\u9a8c\u73b0\u8c61\uff0c\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u548c\u5b9e\u73b0\u6709\u6311\u6218\uff0c\u4e14\u7f3a\u4e4f\u9488\u5bf9\u6027\u6570\u636e\u96c6\uff0c\u9700\u8981\u8bc4\u4f30AI\u5728\u8be5\u9886\u57df\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efa\u901a\u7528\u6846\u67b6\uff0c\u5b9e\u73b0\u4ece\u57fa\u672c\u539f\u8bed\u5230\u9ad8\u7ea7\u5e94\u7528\u7684\u91cf\u5b50\u7b97\u6cd5\uff0c\u8bbe\u7f6e\u81ea\u52a8\u9a8c\u8bc1\u548c\u9a8c\u8bc1\u529f\u80fd\uff0c\u8fdb\u884c\u521d\u6b65\u5fae\u8c03\u3002", "result": "\u89c2\u5bdf\u5230LLMs\u6709\u4e00\u81f4\u9519\u8bef\u6a21\u5f0f\uff0c\u5fae\u8c03\u4e0d\u603b\u662f\u4f18\u4e8e\u5c11\u6837\u672c\u5b66\u4e60\u3002", "conclusion": "QCircuitBench\u662f\u5168\u9762\u7684\u57fa\u51c6\uff0c\u63ed\u793a\u4e86LLMs\u5728\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u9886\u57df\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.05434", "pdf": "https://arxiv.org/pdf/2511.05434", "abs": "https://arxiv.org/abs/2511.05434", "authors": ["Han Huang", "Pakawut Jiradilok", "Elchanan Mossel"], "title": "Reconstructing Riemannian Metrics From Random Geometric Graphs", "categories": ["math.PR", "cs.CG", "cs.DS"], "comment": null, "summary": "Random geometric graphs are random graph models defined on metric measure\nspaces. A random geometric graph is generated by first sampling points from a\nmetric space and then connecting each pair of sampled points independently with\na probability that depends on their distance.\n  In recent work of Huang, Jiradilok, and Mossel~\\cite{HJM24}, the authors\nstudy the problem of reconstructing an embedded manifold form a random\ngeometric graph sampled from the manifold, where edge probabilities depend\nmonotonically on the Euclidean distance between the embedded points. They show\nthat, under mild regularity assumptions on the manifold, the sampling measure,\nand the connection probability function, it is possible to recover the pairwise\nEuclidean distances of the embedded sampled points up to a vanishing error as\nthe number of vertices grows.\n  In this work we consider a similar and arguably more natural problem where\nthe metric is the Riemannian metric on the manifold. Again points are sampled\nfrom the manifold and a random graph is generated where the connection\nprobability is monotone in the Riemannian distance. Perhaps surprisingly we\nobtain stronger results in this setup.\n  Unlike the previous work that only considered dense graph we provide\nreconstruction algorithms from sparse graphs with average degree $n^{1/2}{\\rm\npolylog}(n)$, where $n$ denotes the number of vertices. Our algorithm is also a\nmore efficient algorithm for distance reconstruction with improved error\nbounds. The running times of the algorithm is\n  $O(n^2\\,{\\rm polylog}(n))$ which up to polylog factor matches the size of the\ninput graph.\n  Our distance error also nearly matches the volumetric lower bounds for\ndistance estimation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.05182", "pdf": "https://arxiv.org/pdf/2511.05182", "abs": "https://arxiv.org/abs/2511.05182", "authors": ["Johan Schubert", "Patrik Hansen", "Pontus H\u00f6rling", "Ronnie Johansson"], "title": "Autonomous generation of different courses of action in mechanized combat operations", "categories": ["cs.AI", "cs.CY", "H.4.2; I.2.3; I.2.6; I.2.8; J.7"], "comment": "In Proceedings of the 30th International Command and Control Research\n  & Technology Symposium, Stockholm, Sweden, 3-6 November 2025, paper 009", "summary": "In this paper, we propose a methodology designed to support decision-making\nduring the execution phase of military ground combat operations, with a focus\non one's actions. This methodology generates and evaluates recommendations for\nvarious courses of action for a mechanized battalion, commencing with an\ninitial set assessed by their anticipated outcomes. It systematically produces\nthousands of individual action alternatives, followed by evaluations aimed at\nidentifying alternative courses of action with superior outcomes. These\nalternatives are appraised in light of the opponent's status and actions,\nconsidering unit composition, force ratios, types of offense and defense, and\nanticipated advance rates. Field manuals evaluate battle outcomes and\nadvancement rates. The processes of generation and evaluation work\nconcurrently, yielding a variety of alternative courses of action. This\napproach facilitates the management of new course generation based on\npreviously evaluated actions. As the combat unfolds and conditions evolve,\nrevised courses of action are formulated for the decision-maker within a\nsequential decision-making framework.", "AI": {"tldr": "\u63d0\u51fa\u652f\u6301\u519b\u4e8b\u5730\u9762\u4f5c\u6218\u6267\u884c\u9636\u6bb5\u51b3\u7b56\u7684\u65b9\u6cd5\u8bba\uff0c\u751f\u6210\u5e76\u8bc4\u4f30\u884c\u52a8\u65b9\u6848\u3002", "motivation": "\u4e3a\u519b\u4e8b\u5730\u9762\u4f5c\u6218\u6267\u884c\u9636\u6bb5\u7684\u51b3\u7b56\u63d0\u4f9b\u652f\u6301\u3002", "method": "\u4ece\u521d\u59cb\u8bc4\u4f30\u96c6\u51fa\u53d1\uff0c\u751f\u6210\u6570\u5343\u4e2a\u884c\u52a8\u66ff\u4ee3\u65b9\u6848\uff0c\u7ed3\u5408\u5bf9\u624b\u60c5\u51b5\u8bc4\u4f30\uff0c\u751f\u6210\u4e0e\u8bc4\u4f30\u5e76\u884c\u3002", "result": "\u4ea7\u751f\u591a\u79cd\u66ff\u4ee3\u884c\u52a8\u65b9\u6848\uff0c\u53ef\u6839\u636e\u5148\u524d\u8bc4\u4f30\u884c\u52a8\u7ba1\u7406\u65b0\u65b9\u6848\u751f\u6210\u3002", "conclusion": "\u80fd\u5728\u4f5c\u6218\u60c5\u51b5\u53d8\u5316\u65f6\uff0c\u5728\u987a\u5e8f\u51b3\u7b56\u6846\u67b6\u5185\u4e3a\u51b3\u7b56\u8005\u5236\u5b9a\u4fee\u8ba2\u540e\u7684\u884c\u52a8\u65b9\u6848\u3002"}}
{"id": "2511.05385", "pdf": "https://arxiv.org/pdf/2511.05385", "abs": "https://arxiv.org/abs/2511.05385", "authors": ["Chao Zhang", "Yuhao Wang", "Derong Xu", "Haoxin Zhang", "Yuanjie Lyu", "Yuhao Chen", "Shuochen Liu", "Tong Xu", "Xiangyu Zhao", "Yan Gao", "Yao Hu", "Enhong Chen"], "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework", "categories": ["cs.IR", "cs.AI"], "comment": "32 pages", "summary": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment\nLarge Language Models' (LLMs) reliability. For flexibility, agentic RAG employs\nautonomous, multi-round retrieval and reasoning to resolve queries. Although\nrecent agentic RAG has improved via reinforcement learning, they often incur\nsubstantial token overhead from search and reasoning processes. This trade-off\nprioritizes accuracy over efficiency. To address this issue, this work proposes\nTeaRAG, a token-efficient agentic RAG framework capable of compressing both\nretrieval content and reasoning steps. 1) First, the retrieved content is\ncompressed by augmenting chunk-based semantic retrieval with a graph retrieval\nusing concise triplets. A knowledge association graph is then built from\nsemantic similarity and co-occurrence. Finally, Personalized PageRank is\nleveraged to highlight key knowledge within this graph, reducing the number of\ntokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative\nProcess-aware Direct Preference Optimization (IP-DPO) is proposed.\nSpecifically, our reward function evaluates the knowledge sufficiency by a\nknowledge matching mechanism, while penalizing excessive reasoning steps. This\ndesign can produce high-quality preference-pair datasets, supporting iterative\nDPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the\naverage Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on\nLlama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at\nhttps://github.com/Applied-Machine-Learning-Lab/TeaRAG.", "AI": {"tldr": "\u63d0\u51faTeaRAG\u6846\u67b6\u89e3\u51b3\u4ee3\u7406RAG\u7684\u4ee4\u724c\u5f00\u9500\u95ee\u9898\uff0c\u80fd\u538b\u7f29\u68c0\u7d22\u5185\u5bb9\u548c\u63a8\u7406\u6b65\u9aa4\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u6027\u80fd\u5e76\u51cf\u5c11\u8f93\u51fa\u4ee4\u724c\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406RAG\u867d\u7ecf\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\uff0c\u4f46\u641c\u7d22\u548c\u63a8\u7406\u8fc7\u7a0b\u6709\u5927\u91cf\u4ee4\u724c\u5f00\u9500\uff0c\u5b58\u5728\u51c6\u786e\u6027\u4e0e\u6548\u7387\u7684\u6743\u8861\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "1. \u7528\u56fe\u68c0\u7d22\u589e\u5f3a\u57fa\u4e8e\u5757\u7684\u8bed\u4e49\u68c0\u7d22\uff0c\u6784\u5efa\u77e5\u8bc6\u5173\u8054\u56fe\u5e76\u5229\u7528\u4e2a\u6027\u5316PageRank\u51cf\u5c11\u6bcf\u6b21\u68c0\u7d22\u7684\u4ee4\u724c\u6570\u30022. \u63d0\u51fa\u8fed\u4ee3\u8fc7\u7a0b\u611f\u77e5\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08IP - DPO\uff09\uff0c\u901a\u8fc7\u77e5\u8bc6\u5339\u914d\u673a\u5236\u8bc4\u4f30\u77e5\u8bc6\u5145\u5206\u6027\u5e76\u60e9\u7f5a\u8fc7\u591a\u63a8\u7406\u6b65\u9aa4\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cTeaRAG\u5728Llama3 - 8B - Instruct\u548cQwen2.5 - 14B - Instruct\u4e0a\u5206\u522b\u5c06\u5e73\u5747\u7cbe\u786e\u5339\u914d\u63d0\u9ad84%\u548c2%\uff0c\u540c\u65f6\u51cf\u5c1161%\u548c59%\u7684\u8f93\u51fa\u4ee4\u724c\u3002", "conclusion": "TeaRAG\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u4ee3\u7406RAG\u7684\u4ee4\u724c\u5f00\u9500\u95ee\u9898\uff0c\u63d0\u5347\u6548\u7387\u548c\u6027\u80fd\u3002\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2511.05297", "pdf": "https://arxiv.org/pdf/2511.05297", "abs": "https://arxiv.org/abs/2511.05297", "authors": ["Mohammed Hilel", "Yannis Karmim", "Jean De Bodinat", "Reda Sarehane", "Antoine Gillon"], "title": "Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation", "categories": ["cs.SE", "cs.LG"], "comment": null, "summary": "Digital Adoption Platforms (DAPs) have become essential tools for helping\nemployees navigate complex enterprise software such as CRM, ERP, or HRMS\nsystems. Companies like LemonLearning have shown how digital guidance can\nreduce training costs and accelerate onboarding. However, building and\nmaintaining these interactive guides still requires extensive manual effort.\nLeveraging Large Language Models as virtual assistants is an appealing\nalternative, yet without a structured understanding of the target software,\nLLMs often hallucinate and produce unreliable answers. Moreover, most\nproduction-grade LLMs are black-box APIs, making fine-tuning impractical due to\nthe lack of access to model weights. In this work, we introduce a Graph-based\nRetrieval-Augmented Generation framework that automatically converts enterprise\nweb applications into state-action knowledge graphs, enabling LLMs to generate\ngrounded and context-aware assistance. The framework was co-developed with the\nAI enterprise RAKAM, in collaboration with Lemon Learning. We detail the\nengineering pipeline that extracts and structures software interfaces, the\ndesign of the graph-based retrieval process, and the integration of our\napproach into production DAP workflows. Finally, we discuss scalability,\nrobustness, and deployment lessons learned from industrial use cases.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u81ea\u52a8\u5c06\u4f01\u4e1aWeb\u5e94\u7528\u8f6c\u6362\u4e3a\u72b6\u6001 - \u52a8\u4f5c\u77e5\u8bc6\u56fe\uff0c\u52a9\u529bLLMs\u751f\u6210\u53ef\u9760\u8f85\u52a9\uff0c\u5e76\u8ba8\u8bba\u76f8\u5173\u5de5\u7a0b\u6d41\u7a0b\u53ca\u5de5\u4e1a\u7528\u4f8b\u7ecf\u9a8c\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u91c7\u7528\u5e73\u53f0\u6784\u5efa\u7ef4\u62a4\u9700\u5927\u91cf\u4eba\u529b\uff0cLLMs\u7f3a\u4e4f\u76ee\u6807\u8f6f\u4ef6\u7ed3\u6784\u5316\u7406\u89e3\u4f1a\u4ea7\u751f\u4e0d\u53ef\u9760\u7b54\u6848\uff0c\u4e14\u751f\u4ea7\u7ea7LLMs\u96be\u4ee5\u5fae\u8c03\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u81ea\u52a8\u5c06\u4f01\u4e1aWeb\u5e94\u7528\u8f6c\u6362\u4e3a\u72b6\u6001 - \u52a8\u4f5c\u77e5\u8bc6\u56fe\uff0c\u8be6\u7ec6\u9610\u8ff0\u5de5\u7a0b\u6d41\u7a0b\u3001\u56fe\u68c0\u7d22\u8bbe\u8ba1\u53ca\u96c6\u6210\u5230\u751f\u4ea7DAP\u5de5\u4f5c\u6d41\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\uff0c\u4f46\u8ba8\u8bba\u4e86\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u90e8\u7f72\u7ecf\u9a8c\u3002"}}
{"id": "2511.04760", "pdf": "https://arxiv.org/pdf/2511.04760", "abs": "https://arxiv.org/abs/2511.04760", "authors": ["Vaibhav Singh", "Eugene Belilovsky", "Rahaf Aljundi"], "title": "When Data Falls Short: Grokking Below the Critical Threshold", "categories": ["cs.LG"], "comment": "6 pages", "summary": "In this paper, we investigate the phenomenon of grokking, where models\nexhibit delayed generalization following overfitting on training data. We focus\non data-scarce regimes where the number of training samples falls below the\ncritical threshold, making grokking unobservable, and on practical scenarios\ninvolving distribution shift. We first show that Knowledge Distillation (KD)\nfrom a model that has already grokked on a distribution (p1) can induce and\naccelerate grokking on a different distribution (p2), even when the available\ndata lies below the critical threshold. This highlights the value of KD for\ndeployed models that must adapt to new distributions under limited data. We\nthen study training on the joint distribution (p1, p2) and demonstrate that\nwhile standard supervised training fails when either distribution has\ninsufficient data, distilling from models grokked on the individual\ndistributions enables generalization. Finally, we examine a continual\npretraining setup, where a grokked model transitions from p1 to p2, and find\nthat KD both accelerates generalization and mitigates catastrophic forgetting,\nachieving strong performance even with only 10% of the data. Together, our\nresults provide new insights into the mechanics of grokking under knowledge\ntransfer and underscore the central role of KD in enabling generalization in\nlow-data and evolving distribution settings.", "AI": {"tldr": "\u7814\u7a76\u6a21\u578bgrokking\u73b0\u8c61\uff0c\u63a2\u8ba8\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u5728\u6570\u636e\u7a00\u7f3a\u548c\u5206\u5e03\u8f6c\u79fb\u573a\u666f\u4e0b\u8bf1\u5bfc\u3001\u52a0\u901fgrokking\u53ca\u5b9e\u73b0\u6cdb\u5316\u7684\u4f5c\u7528\u3002", "motivation": "\u7814\u7a76\u6570\u636e\u7a00\u7f3a\uff08\u8bad\u7ec3\u6837\u672c\u4f4e\u4e8e\u4e34\u754c\u9608\u503c\uff09\u548c\u5206\u5e03\u8f6c\u79fb\u573a\u666f\u4e0b\u7684grokking\u73b0\u8c61\uff0c\u63a2\u7d22\u5b9e\u73b0\u6a21\u578b\u6cdb\u5316\u7684\u65b9\u6cd5\u3002", "method": "1. \u4ece\u5df2\u5728\u5206\u5e03p1\u4e0a\u53d1\u751fgrokking\u7684\u6a21\u578b\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\uff0c\u5728\u5206\u5e03p2\u4e0a\u8bf1\u5bfc\u548c\u52a0\u901fgrokking\uff1b2. \u7814\u7a76\u5728\u8054\u5408\u5206\u5e03\uff08p1, p2\uff09\u4e0a\u7684\u8bad\u7ec3\uff1b3. \u8003\u5bdf\u6301\u7eed\u9884\u8bad\u7ec3\u573a\u666f\uff0c\u8ba9\u5df2grokking\u7684\u6a21\u578b\u4ecep1\u8fc7\u6e21\u5230p2\u3002", "result": "1. KD\u53ef\u5728\u6570\u636e\u4f4e\u4e8e\u4e34\u754c\u9608\u503c\u65f6\uff0c\u5728\u4e0d\u540c\u5206\u5e03\u4e0a\u8bf1\u5bfc\u548c\u52a0\u901fgrokking\uff1b2. \u4ece\u5355\u4e2a\u5206\u5e03\u4e0agrokked\u7684\u6a21\u578b\u8fdb\u884c\u84b8\u998f\u80fd\u5b9e\u73b0\u8054\u5408\u5206\u5e03\u4e0a\u7684\u6cdb\u5316\uff1b3. KD\u80fd\u52a0\u901f\u6cdb\u5316\u3001\u51cf\u8f7b\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4ec5\u752810%\u6570\u636e\u5c31\u80fd\u53d6\u5f97\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u77e5\u8bc6\u8f6c\u79fb\u4e0b\u7684grokking\u673a\u5236\u63d0\u4f9b\u65b0\u89c1\u89e3\uff0c\u5f3a\u8c03KD\u5728\u4f4e\u6570\u636e\u548c\u5206\u5e03\u53d8\u5316\u573a\u666f\u4e0b\u5b9e\u73b0\u6cdb\u5316\u7684\u6838\u5fc3\u4f5c\u7528\u3002"}}
{"id": "2511.04979", "pdf": "https://arxiv.org/pdf/2511.04979", "abs": "https://arxiv.org/abs/2511.04979", "authors": ["Gimun Bae", "Seung Jun Shin"], "title": "Scaling Up ROC-Optimizing Support Vector Machines", "categories": ["cs.LG", "stat.CO", "stat.ML"], "comment": "15 pages, Submitted to Stat", "summary": "The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the\narea under the ROC curve (AUC) and has become an attractive alternative of the\nconventional binary classification under the presence of class imbalance.\nHowever, its practical use is limited by high computational cost, as training\ninvolves evaluating all $O(n^2)$. To overcome this limitation, we develop a\nscalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby\nsubstantially reducing computational complexity. We further extend the\nframework to nonlinear classification through a low-rank kernel approximation,\nenabling efficient training in reproducing kernel Hilbert spaces. Theoretical\nanalysis establishes an error bound that justifies the proposed approximation,\nand empirical results on both synthetic and real datasets demonstrate that the\nproposed method achieves comparable AUC performance to the original ROC-SVM\nwith drastically reduced training time.", "AI": {"tldr": "\u63d0\u51faROC - SVM\u53ef\u6269\u5c55\u53d8\u4f53\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u6269\u5c55\u5230\u975e\u7ebf\u6027\u5206\u7c7b\uff0c\u7406\u8bba\u5206\u6790\u8bc1\u660e\u8fd1\u4f3c\u5408\u7406\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u76f8\u5f53\u4e14\u8bad\u7ec3\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\u3002", "motivation": "\u539f\u59cbROC - SVM\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u3002", "method": "\u5f00\u53d1\u5229\u7528\u4e0d\u5b8c\u5168U\u7edf\u8ba1\u91cf\u7684\u53ef\u6269\u5c55\u53d8\u4f53\uff0c\u901a\u8fc7\u4f4e\u79e9\u6838\u8fd1\u4f3c\u6269\u5c55\u5230\u975e\u7ebf\u6027\u5206\u7c7b\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u63d0\u51fa\u65b9\u6cd5\u4e0e\u539f\u59cbROC - SVM\u7684AUC\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u8bad\u7ec3\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u80fd\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2511.02401", "pdf": "https://arxiv.org/pdf/2511.02401", "abs": "https://arxiv.org/abs/2511.02401", "authors": ["Yessin Moakher", "Malik Tiomoko", "Cosme Louart", "Zhenyu Liao"], "title": "Generalization in Representation Models via Random Matrix Theory: Application to Recurrent Networks", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "We first study the generalization error of models that use a fixed feature\nrepresentation (frozen intermediate layers) followed by a trainable readout\nlayer. This setting encompasses a range of architectures, from deep\nrandom-feature models to echo-state networks (ESNs) with recurrent dynamics.\nWorking in the high-dimensional regime, we apply Random Matrix Theory to derive\na closed-form expression for the asymptotic generalization error. We then apply\nthis analysis to recurrent representations and obtain concise formula that\ncharacterize their performance. Surprisingly, we show that a linear ESN is\nequivalent to ridge regression with an exponentially time-weighted (''memory'')\ninput covariance, revealing a clear inductive bias toward recent inputs.\nExperiments match predictions: ESNs win in low-sample, short-memory regimes,\nwhile ridge prevails with more data or long-range dependencies. Our methodology\nprovides a general framework for analyzing overparameterized models and offers\ninsights into the behavior of deep learning networks.", "AI": {"tldr": "\u7814\u7a76\u56fa\u5b9a\u7279\u5f81\u8868\u793a\u52a0\u53ef\u8bad\u7ec3\u8bfb\u51fa\u5c42\u6a21\u578b\u7684\u6cdb\u5316\u8bef\u5dee\uff0c\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u63a8\u5bfc\u6e10\u8fd1\u6cdb\u5316\u8bef\u5dee\uff0c\u5206\u6790\u5faa\u73af\u8868\u793a\uff0c\u63ed\u793a\u7ebf\u6027ESN\u4e0e\u5cad\u56de\u5f52\u5173\u7cfb\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6027\u80fd\uff0c\u63d0\u4f9b\u5206\u6790\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u4f7f\u7528\u56fa\u5b9a\u7279\u5f81\u8868\u793a\u548c\u53ef\u8bad\u7ec3\u8bfb\u51fa\u5c42\u7684\u6a21\u578b\u7684\u6cdb\u5316\u8bef\u5dee\uff0c\u5206\u6790\u76f8\u5173\u67b6\u6784\u6027\u80fd\u3002", "method": "\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u5e94\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u63a8\u5bfc\u6e10\u8fd1\u6cdb\u5316\u8bef\u5dee\uff0c\u5bf9\u5faa\u73af\u8868\u793a\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5f97\u51fa\u7ebf\u6027ESN\u7b49\u540c\u4e8e\u5177\u6709\u6307\u6570\u65f6\u95f4\u52a0\u6743\u8f93\u5165\u534f\u65b9\u5dee\u7684\u5cad\u56de\u5f52\uff0c\u5b9e\u9a8c\u8868\u660eESN\u5728\u4f4e\u6837\u672c\u3001\u77ed\u8bb0\u5fc6\u573a\u666f\u83b7\u80dc\uff0c\u5cad\u56de\u5f52\u5728\u6570\u636e\u591a\u6216\u957f\u7a0b\u4f9d\u8d56\u573a\u666f\u5360\u4f18\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e3a\u5206\u6790\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u63d0\u4f9b\u901a\u7528\u6846\u67b6\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u884c\u4e3a\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2511.05311", "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Rapha\u00ebl Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7406\u652f\u6301\u6c7d\u8f66\u884c\u4e1a\u9884\u6d4b\u6027\u7ef4\u62a4\uff08PdM\uff09\u6570\u636e\u6e05\u6d17\u7ba1\u9053\u7684\u6f5c\u529b\uff0c\u53d1\u73b0LLM\u80fd\u6709\u6548\u5904\u7406\u901a\u7528\u6e05\u6d17\u4efb\u52a1\uff0c\u4e3a\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u7ecf\u6d4e\u9650\u5236\u3001\u6570\u636e\u96c6\u53ef\u7528\u6027\u548c\u4e13\u4e1a\u77e5\u8bc6\u77ed\u7f3a\u963b\u788d\u6c7d\u8f66\u884c\u4e1aPdM\u53d1\u5c55\uff0cLLM\u53d1\u5c55\u5e26\u6765\u514b\u670d\u969c\u788d\u7684\u673a\u4f1a\u3002", "method": "\u805a\u7126\u7ef4\u62a4\u65e5\u5fd7\uff0c\u8bc4\u4f30LLM\u4ee3\u7406\u5904\u7406\u516d\u79cd\u4e0d\u540c\u7c7b\u578b\u566a\u58f0\u7684\u6e05\u6d17\u4efb\u52a1\u3002", "result": "LLM\u80fd\u6709\u6548\u5904\u7406\u901a\u7528\u6e05\u6d17\u4efb\u52a1\u3002", "conclusion": "LLM\u4e3a\u672a\u6765\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u6709\u524d\u666f\u7684\u57fa\u7840\uff0c\u7279\u5b9a\u9886\u57df\u9519\u8bef\u4ecd\u5177\u6311\u6218\uff0c\u53ef\u901a\u8fc7\u4e13\u4e1a\u8bad\u7ec3\u548c\u589e\u5f3a\u4ee3\u7406\u80fd\u529b\u6539\u8fdb\u3002"}}
{"id": "2511.04696", "pdf": "https://arxiv.org/pdf/2511.04696", "abs": "https://arxiv.org/abs/2511.04696", "authors": ["Jan Strich", "Adeline Scharfenberg", "Chris Biemann", "Martin Semmann"], "title": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Currently under review", "summary": "We introduce EncouRAGe, a comprehensive Python framework designed to\nstreamline the development and evaluation of Retrieval-Augmented Generation\n(RAG) systems using Large Language Models (LLMs) and Embedding Models.\nEncouRAGe comprises five modular and extensible components: Type Manifest, RAG\nFactory, Inference, Vector Store, and Metrics, facilitating flexible\nexperimentation and extensible development. The framework emphasizes scientific\nreproducibility, diverse evaluation metrics, and local deployment, enabling\nresearchers to efficiently assess datasets within RAG workflows. This paper\npresents implementation details and an extensive evaluation across multiple\nbenchmark datasets, including 25k QA pairs and over 51k documents. Our results\nshow that RAG still underperforms compared to the Oracle Context, while Hybrid\nBM25 consistently achieves the best results across all four datasets. We\nfurther examine the effects of reranking, observing only marginal performance\nimprovements accompanied by higher response latency.", "AI": {"tldr": "\u4ecb\u7ecdEncouRAGe\u6846\u67b6\u7528\u4e8e\u7b80\u5316RAG\u7cfb\u7edf\u5f00\u53d1\u4e0e\u8bc4\u4f30\uff0c\u5c55\u793a\u5176\u7ec4\u4ef6\u3001\u8bc4\u4f30\u7ed3\u679c\u7b49\u3002", "motivation": "\u7b80\u5316\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5d4c\u5165\u6a21\u578b\u7684RAG\u7cfb\u7edf\u7684\u5f00\u53d1\u4e0e\u8bc4\u4f30\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e94\u4e2a\u6a21\u5757\u5316\u53ef\u6269\u5c55\u7ec4\u4ef6\u7684EncouRAGe\u6846\u67b6\uff0c\u5bf9\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "RAG\u8868\u73b0\u4e0d\u5982Oracle Context\uff0cHybrid BM25\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u6548\u679c\u6700\u4f73\uff0c\u91cd\u6392\u6027\u80fd\u63d0\u5347\u6709\u9650\u4e14\u589e\u52a0\u54cd\u5e94\u5ef6\u8fdf\u3002", "conclusion": "EncouRAGe\u6846\u67b6\u53ef\u52a9\u529bRAG\u7cfb\u7edf\u7814\u7a76\uff0c\u4e14\u5448\u73b0\u4e86RAG\u7cfb\u7edf\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u60c5\u51b5\u3002"}}
{"id": "2511.05302", "pdf": "https://arxiv.org/pdf/2511.05302", "abs": "https://arxiv.org/abs/2511.05302", "authors": ["Qianru Meng", "Xiao Zhang", "Zhaochen Ren", "Joost Visser"], "title": "Code Review Automation using Retrieval Augmented Generation", "categories": ["cs.SE"], "comment": null, "summary": "Code review is essential for maintaining software quality but is\nlabor-intensive. Automated code review generation offers a promising solution\nto this challenge. Both deep learning-based generative techniques and\nretrieval-based methods have demonstrated strong performance in this task.\nHowever, despite these advancements, there are still some limitations where\ngenerated reviews can be either off-point or overly general. To address these\nissues, we introduce Retrieval-Augmented Reviewer (RARe), which leverages\nRetrieval-Augmented Generation (RAG) to combine retrieval-based and generative\nmethods, explicitly incorporating external domain knowledge into the code\nreview process. RARe uses a dense retriever to select the most relevant reviews\nfrom the codebase, which then enrich the input for a neural generator,\nutilizing the contextual learning capacity of large language models (LLMs), to\nproduce the final review. RARe outperforms state-of-the-art methods on two\nbenchmark datasets, achieving BLEU-4 scores of 12.32 and 12.96, respectively.\nIts effectiveness is further validated through a detailed human evaluation and\na case study using an interpretability tool, demonstrating its practical\nutility and reliability.", "AI": {"tldr": "\u63d0\u51faRetrieval - Augmented Reviewer (RARe)\u7ed3\u5408\u68c0\u7d22\u548c\u751f\u6210\u65b9\u6cd5\u8fdb\u884c\u4ee3\u7801\u5ba1\u67e5\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7ecf\u8bc4\u4f30\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u4ee3\u7801\u5ba1\u67e5\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u751f\u6210\u7684\u5ba1\u67e5\u504f\u79bb\u91cd\u70b9\u6216\u8fc7\u4e8e\u7b3c\u7edf\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165RARe\uff0c\u5229\u7528Retrieval - Augmented Generation (RAG)\u7ed3\u5408\u68c0\u7d22\u548c\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u5bc6\u96c6\u68c0\u7d22\u5668\u4ece\u4ee3\u7801\u5e93\u4e2d\u9009\u62e9\u76f8\u5173\u5ba1\u67e5\uff0c\u4e30\u5bcc\u795e\u7ecf\u751f\u6210\u5668\u8f93\u5165\u4ee5\u751f\u6210\u6700\u7ec8\u5ba1\u67e5\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0cBLEU - 4\u5206\u6570\u5206\u522b\u4e3a12.32\u548c12.96\uff0c\u901a\u8fc7\u4eba\u5de5\u8bc4\u4f30\u548c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "RARe\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u548c\u53ef\u9760\u6027\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u81ea\u52a8\u4ee3\u7801\u5ba1\u67e5\u751f\u6210\u65b9\u6cd5\u7684\u5c40\u9650\u3002"}}
{"id": "2511.04768", "pdf": "https://arxiv.org/pdf/2511.04768", "abs": "https://arxiv.org/abs/2511.04768", "authors": ["Rubens Lacouture", "Nathan Zhang", "Ritvik Sharma", "Marco Siracusa", "Fredrik Kjolstad", "Kunle Olukotun", "Olivia Hsu"], "title": "FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow", "categories": ["cs.LG", "cs.AR", "cs.PL"], "comment": null, "summary": "As deep learning models scale, sparse computation and specialized dataflow\nhardware have emerged as powerful solutions to address efficiency. We propose\nFuseFlow, a compiler that converts sparse machine learning models written in\nPyTorch to fused sparse dataflow graphs for reconfigurable dataflow\narchitectures (RDAs). FuseFlow is the first compiler to support general\ncross-expression fusion of sparse operations. In addition to fusion across\nkernels (expressions), FuseFlow also supports optimizations like\nparallelization, dataflow ordering, and sparsity blocking. It targets a\ncycle-accurate dataflow simulator for microarchitectural analysis of fusion\nstrategies. We use FuseFlow for design-space exploration across four real-world\nmachine learning applications with sparsity, showing that full fusion (entire\ncross-expression fusion across all computation in an end-to-end model) is not\nalways optimal for sparse models-fusion granularity depends on the model\nitself. FuseFlow also provides a heuristic to identify and prune suboptimal\nconfigurations. Using Fuseflow, we achieve performance improvements, including\na ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse\nattention.", "AI": {"tldr": "\u63d0\u51fa\u7f16\u8bd1\u5668FuseFlow\u5c06\u7a00\u758f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8f6c\u6362\u4e3a\u878d\u5408\u7a00\u758f\u6570\u636e\u6d41\u56fe\uff0c\u652f\u6301\u591a\u79cd\u4f18\u5316\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\u5168\u878d\u5408\u5e76\u975e\u5bf9\u7a00\u758f\u6a21\u578b\u603b\u662f\u6700\u4f18\uff0c\u8fd8\u80fd\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u89c4\u6a21\u6269\u5927\uff0c\u9700\u89e3\u51b3\u6548\u7387\u95ee\u9898\uff0c\u7a00\u758f\u8ba1\u7b97\u548c\u4e13\u7528\u6570\u636e\u6d41\u786c\u4ef6\u662f\u6709\u6548\u65b9\u6848\uff0c\u63d0\u51faFuseFlow\u7f16\u8bd1\u5668\u3002", "method": "\u5f00\u53d1FuseFlow\u7f16\u8bd1\u5668\uff0c\u652f\u6301\u901a\u7528\u8de8\u8868\u8fbe\u5f0f\u7a00\u758f\u64cd\u4f5c\u878d\u5408\uff0c\u8fd8\u652f\u6301\u5e76\u884c\u5316\u7b49\u4f18\u5316\uff0c\u4ee5\u5468\u671f\u7cbe\u786e\u6570\u636e\u6d41\u6a21\u62df\u5668\u4e3a\u76ee\u6807\u8fdb\u884c\u5fae\u67b6\u6784\u5206\u6790\u3002", "result": "\u901a\u8fc7\u56db\u4e2a\u6709\u7a00\u758f\u6027\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u8fdb\u884c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff0c\u53d1\u73b0\u5168\u878d\u5408\u5e76\u975e\u5bf9\u7a00\u758f\u6a21\u578b\u603b\u662f\u6700\u4f18\uff0cFuseFlow\u80fd\u8bc6\u522b\u5e76\u526a\u679d\u6b21\u4f18\u914d\u7f6e\uff0c\u5728GPT - 3\u4e0a\u5b9e\u73b0\u7ea62.7\u500d\u52a0\u901f\u3002", "conclusion": "FuseFlow\u7f16\u8bd1\u5668\u80fd\u6709\u6548\u5904\u7406\u7a00\u758f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u63d0\u9ad8\u6027\u80fd\uff0c\u4e14\u878d\u5408\u7c92\u5ea6\u4f9d\u8d56\u4e8e\u6a21\u578b\u672c\u8eab\u3002"}}
{"id": "2511.04790", "pdf": "https://arxiv.org/pdf/2511.04790", "abs": "https://arxiv.org/abs/2511.04790", "authors": ["Caroline Uhler", "Jiaqi Zhang"], "title": "Causal Structure and Representation Learning with Biomedical Applications", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "This article has successfully completed peer review and will appear\n  in the Proceedings of the International Congress of Mathematicians 2026. Both\n  authors contributed equally to this work", "summary": "Massive data collection holds the promise of a better understanding of\ncomplex phenomena and, ultimately, better decisions. Representation learning\nhas become a key driver of deep learning applications, as it allows learning\nlatent spaces that capture important properties of the data without requiring\nany supervised annotations. Although representation learning has been hugely\nsuccessful in predictive tasks, it can fail miserably in causal tasks including\npredicting the effect of a perturbation/intervention. This calls for a marriage\nbetween representation learning and causal inference. An exciting opportunity\nin this regard stems from the growing availability of multi-modal data\n(observational and perturbational, imaging-based and sequencing-based, at the\nsingle-cell level, tissue-level, and organism-level). We outline a statistical\nand computational framework for causal structure and representation learning\nmotivated by fundamental biomedical questions: how to effectively use\nobservational and perturbational data to perform causal discovery on observed\ncausal variables; how to use multi-modal views of the system to learn causal\nvariables; and how to design optimal perturbations.", "AI": {"tldr": "\u5927\u6570\u636e\u6536\u96c6\u6709\u6f5c\u529b\u52a9\u529b\u590d\u6742\u73b0\u8c61\u7406\u89e3\u4e0e\u51b3\u7b56\uff0c\u8868\u5f81\u5b66\u4e60\u5728\u9884\u6d4b\u4efb\u52a1\u6210\u529f\u4f46\u56e0\u679c\u4efb\u52a1\u6b20\u4f73\uff0c\u9700\u7ed3\u5408\u56e0\u679c\u63a8\u65ad\uff0c\u672c\u6587\u63d0\u51fa\u56e0\u679c\u7ed3\u6784\u548c\u8868\u5f81\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u8868\u5f81\u5b66\u4e60\u5728\u56e0\u679c\u4efb\u52a1\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u591a\u6a21\u6001\u6570\u636e\u53ef\u7528\u6027\u589e\u52a0\uff0c\u53d7\u751f\u7269\u533b\u5b66\u57fa\u7840\u95ee\u9898\u9a71\u52a8\u3002", "method": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u65b9\u6cd5\uff0c\u4ec5\u63d0\u51fa\u7edf\u8ba1\u548c\u8ba1\u7b97\u6846\u67b6\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u9700\u5c06\u8868\u5f81\u5b66\u4e60\u4e0e\u56e0\u679c\u63a8\u65ad\u7ed3\u5408\uff0c\u5e76\u63d0\u51fa\u56e0\u679c\u7ed3\u6784\u548c\u8868\u5f81\u5b66\u4e60\u6846\u67b6\u4ee5\u89e3\u51b3\u76f8\u5173\u751f\u7269\u533b\u5b66\u95ee\u9898\u3002"}}
{"id": "2511.05375", "pdf": "https://arxiv.org/pdf/2511.05375", "abs": "https://arxiv.org/abs/2511.05375", "authors": ["Sijie Yang", "Jiatong Li", "Filip Biljecki"], "title": "Reasoning Is All You Need for Urban Planning AI", "categories": ["cs.AI"], "comment": "Submitted to AAAI 2026 Workshop AI4UP", "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u57ce\u5e02\u89c4\u5212\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c55\u793aAI\u589e\u5f3a\u4eba\u7c7b\u89c4\u5212\u80fd\u529b\u800c\u975e\u53d6\u4ee3\u4eba\u7c7b\u5224\u65ad\u3002", "motivation": "\u5f53\u524dAI\u5728\u57ce\u5e02\u89c4\u5212\u5206\u6790\u6210\u529f\uff0c\u4e0b\u4e00\u6b65\u662f\u5b9e\u73b0AI\u8f85\u52a9\u51b3\u7b56\uff0c\u73b0\u6709\u63a8\u7406AI\u7a81\u7834\u4f7f\u613f\u666f\u53ef\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u4e09\u4e2a\u8ba4\u77e5\u5c42\u548c\u516d\u4e2a\u903b\u8f91\u7ec4\u4ef6\u7684\u667a\u80fd\u4f53\u57ce\u5e02\u89c4\u5212AI\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u5b9e\u73b0\u3002", "result": "\u5c55\u793aAI\u667a\u80fd\u4f53\u53ef\u7cfb\u7edf\u63a2\u7d22\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u3001\u9a8c\u8bc1\u5408\u89c4\u6027\u548c\u900f\u660e\u6743\u8861\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u4ee5\u8ba1\u7b97\u63a8\u7406\u80fd\u529b\u589e\u5f3a\u4eba\u7c7b\u89c4\u5212\u8005\u5224\u65ad\uff0c\u800c\u975e\u53d6\u4ee3\u3002"}}
{"id": "2511.04755", "pdf": "https://arxiv.org/pdf/2511.04755", "abs": "https://arxiv.org/abs/2511.04755", "authors": ["Daeun Hwang", "Saebyul Park"], "title": "EMO100DB: An Open Dataset of Improvised Songs with Emotion Data", "categories": ["cs.SD", "cs.IR", "cs.MM"], "comment": "4 pages, 6 figures, International Conference on Music Perception and\n  Cognition", "summary": "In this study, we introduce Emo100DB: a dataset consisting of improvised\nsongs that were recorded and transcribed with emotion data based on Russell's\ncircumplex model of emotion. The dataset was developed by collecting improvised\nsongs that consist of melody, lyrics, and an instrumental accompaniment played,\nsung, and recorded by 20 young adults. Before recording each song, the\nparticipants were asked to report their emotional state, with the axes\nrepresenting arousal and valence based on Russell's circumplex model of\nemotions. The dataset is organized into four emotion quadrants, and it includes\nthe lyrics text and MIDI file of the melody extracted from the participant\nrecordings, along with the original audio in WAV format. By providing an\nintegrated composition of data and analysis, this study aims to offer a\ncomprehensive dataset that allows for a diverse exploration of the relationship\nbetween music and emotion.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Emo100DB\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u57fa\u4e8eRussell\u60c5\u7eea\u6a21\u578b\uff0c\u5305\u542b\u5373\u5174\u6b4c\u66f2\u53ca\u60c5\u7eea\u6570\u636e\uff0c\u65e8\u5728\u5168\u9762\u63a2\u7d22\u97f3\u4e50\u4e0e\u60c5\u7eea\u5173\u7cfb\u3002", "motivation": "\u63d0\u4f9b\u4e00\u4e2a\u7efc\u5408\u6570\u636e\u96c6\uff0c\u4ee5\u652f\u6301\u5bf9\u97f3\u4e50\u548c\u60c5\u7eea\u5173\u7cfb\u7684\u591a\u6837\u5316\u63a2\u7d22\u3002", "method": "\u6536\u96c620\u540d\u5e74\u8f7b\u4eba\u6f14\u594f\u3001\u6f14\u5531\u548c\u5f55\u5236\u7684\u5305\u542b\u65cb\u5f8b\u3001\u6b4c\u8bcd\u548c\u5668\u4e50\u4f34\u594f\u7684\u5373\u5174\u6b4c\u66f2\uff0c\u8bb0\u5f55\u524d\u8ba9\u53c2\u4e0e\u8005\u6309Russell\u6a21\u578b\u62a5\u544a\u60c5\u7eea\u72b6\u6001\uff0c\u5c06\u6570\u636e\u96c6\u6309\u56db\u4e2a\u60c5\u7eea\u8c61\u9650\u7ec4\u7ec7\u3002", "result": "\u5f00\u53d1\u51faEmo100DB\u6570\u636e\u96c6\uff0c\u5305\u542b\u6b4c\u8bcd\u6587\u672c\u3001\u65cb\u5f8bMIDI\u6587\u4ef6\u548c\u539f\u59cbWAV\u97f3\u9891\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u6570\u636e\u548c\u5206\u6790\u7684\u7efc\u5408\u7ec4\u6210\uff0c\u8be5\u6570\u636e\u96c6\u53ef\u7528\u4e8e\u5168\u9762\u63a2\u7d22\u97f3\u4e50\u4e0e\u60c5\u7eea\u7684\u5173\u7cfb\u3002"}}
{"id": "2511.05459", "pdf": "https://arxiv.org/pdf/2511.05459", "abs": "https://arxiv.org/abs/2511.05459", "authors": ["Jingxuan Xu", "Ken Deng", "Weihao Li", "Songwei Yu", "Huaixi Tang", "Haoyang Huang", "Zhiyi Lai", "Zizheng Zhan", "Yanan Wu", "Chenchen Zhang", "Kepeng Lei", "Yifan Yao", "Xinping Lei", "Wenqiang Zhu", "Zongxian Feng", "Han Li", "Junqi Xiong", "Dailin Li", "Zuchen Gao", "Kun Wu", "Wen Xiang", "Ziqi Zhan", "Yuanxing Zhang", "Wuxuan Gong", "Ziyuan Gao", "Guanxiang Wang", "Yirong Xue", "Xiaojiang Zhang", "Jinghui Wang", "Huiming Wang", "Wenhao Zhuang", "Zhaoxiang Zhang", "Yuqun Zhang", "Haotian Zhang", "Bin Chen", "Jiaheng Liu"], "title": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Evaluating large language models (LLMs) for software engineering has been\nlimited by narrow task coverage, language bias, and insufficient alignment with\nreal-world developer workflows. Existing benchmarks often focus on algorithmic\nproblems or Python-centric bug fixing, leaving critical dimensions of software\nengineering underexplored. To address these gaps, we introduce SWE-Compass1, a\ncomprehensive benchmark that unifies heterogeneous code-related evaluations\ninto a structured and production-aligned framework. SWE-Compass spans 8 task\ntypes, 8 programming scenarios, and 10 programming languages, with 2000\nhigh-quality instances curated from authentic GitHub pull requests and refined\nthrough systematic filtering and validation. We benchmark ten state-of-the-art\nLLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear\nhierarchy of difficulty across task types, languages, and scenarios. Moreover,\nby aligning evaluation with real-world developer practices, SWE-Compass\nprovides a rigorous and reproducible foundation for diagnosing and advancing\nagentic coding capabilities in large language models.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8f6f\u4ef6\u5de5\u7a0b\u8bc4\u4f30\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51faSWE - Compass\u57fa\u51c6\uff0c\u5bf910\u4e2a\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4e3a\u8bc4\u4f30\u6a21\u578b\u7f16\u7801\u80fd\u529b\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u9762\u7684\u57fa\u51c6\u5b58\u5728\u4efb\u52a1\u8986\u76d6\u7a84\u3001\u8bed\u8a00\u6709\u504f\u5dee\u548c\u4e0e\u5b9e\u9645\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u7a0b\u4e0d\u5339\u914d\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165SWE - Compass\u57fa\u51c6\uff0c\u6db5\u76d68\u79cd\u4efb\u52a1\u7c7b\u578b\u30018\u79cd\u7f16\u7a0b\u573a\u666f\u548c10\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u4ece\u771f\u5b9eGitHub\u62c9\u53d6\u8bf7\u6c42\u4e2d\u9009\u53d62000\u4e2a\u5b9e\u4f8b\uff0c\u5728SWE - Agent\u548cClaude Code\u4e24\u4e2a\u6846\u67b6\u4e0b\u5bf910\u4e2a\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u63ed\u793a\u4e86\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u3001\u8bed\u8a00\u548c\u573a\u666f\u7684\u96be\u5ea6\u5c42\u6b21\u3002", "conclusion": "SWE - Compass\u4e3a\u8bca\u65ad\u548c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u7f16\u7801\u80fd\u529b\u63d0\u4f9b\u4e86\u4e25\u683c\u4e14\u53ef\u91cd\u590d\u7684\u57fa\u7840\u3002"}}
{"id": "2511.04774", "pdf": "https://arxiv.org/pdf/2511.04774", "abs": "https://arxiv.org/abs/2511.04774", "authors": ["Liu Jiang", "Zerui Bao", "Shiqi Sheng", "Di Zhu"], "title": "SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud Microservices", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Large-scale networked services rely on deep soft-ware stacks and microservice\norchestration, which increase instruction footprints and create frontend stalls\nthat inflate tail latency and energy. We revisit instruction prefetching for\nthese cloud workloads and present a design that aligns with SLO driven and self\noptimizing systems. Building on the Entangling Instruction Prefetcher (EIP), we\nintroduce a Compressed Entry that captures up to eight destinations around a\nbase using 36 bits by exploiting spatial clustering, and a Hierarchical\nMetadata Storage scheme that keeps only L1 resident and frequently queried\nentries on chip while virtualizing bulk metadata into lower levels. We further\nadd a lightweight Online ML Controller that scores prefetch profitability using\ncontext features and a bandit adjusted threshold. On data center applications,\nour approach preserves EIP like speedups with smaller on chip state and\nimproves efficiency for networked services in the ML era.", "AI": {"tldr": "\u9488\u5bf9\u4e91\u5de5\u4f5c\u8d1f\u8f7d\u91cd\u65b0\u5ba1\u89c6\u6307\u4ee4\u9884\u53d6\uff0c\u63d0\u51fa\u65b0\u8bbe\u8ba1\uff0c\u5728\u6570\u636e\u4e2d\u5fc3\u5e94\u7528\u4e2d\u63d0\u5347\u7f51\u7edc\u670d\u52a1\u6548\u7387\u3002", "motivation": "\u5927\u89c4\u6a21\u7f51\u7edc\u670d\u52a1\u56e0\u8f6f\u4ef6\u6808\u548c\u5fae\u670d\u52a1\u7f16\u6392\u5bfc\u81f4\u6307\u4ee4\u8db3\u8ff9\u589e\u52a0\u3001\u524d\u7aef\u505c\u987f\uff0c\u4f7f\u5c3e\u5ef6\u8fdf\u548c\u80fd\u8017\u4e0a\u5347\u3002", "method": "\u57fa\u4e8eEIP\uff0c\u5f15\u5165\u538b\u7f29\u6761\u76ee\u548c\u5206\u5c42\u5143\u6570\u636e\u5b58\u50a8\u65b9\u6848\uff0c\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u5728\u7ebf\u673a\u5668\u5b66\u4e60\u63a7\u5236\u5668\u3002", "result": "\u5728\u6570\u636e\u4e2d\u5fc3\u5e94\u7528\u4e2d\u4fdd\u6301\u7c7b\u4f3cEIP\u7684\u52a0\u901f\u6548\u679c\uff0c\u51cf\u5c11\u7247\u4e0a\u72b6\u6001\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u63d0\u5347\u4e86\u673a\u5668\u5b66\u4e60\u65f6\u4ee3\u7f51\u7edc\u670d\u52a1\u7684\u6548\u7387\u3002"}}
{"id": "2511.04869", "pdf": "https://arxiv.org/pdf/2511.04869", "abs": "https://arxiv.org/abs/2511.04869", "authors": ["Preetum Nakkiran", "Arwen Bradley", "Adam Goli\u0144ski", "Eugene Ndiaye", "Michael Kirchhof", "Sinead Williamson"], "title": "Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) often lack meaningful confidence estimates for\ntheir outputs. While base LLMs are known to exhibit next-token calibration, it\nremains unclear whether they can assess confidence in the actual meaning of\ntheir responses beyond the token level. We find that, when using a certain\nsampling-based notion of semantic calibration, base LLMs are remarkably\nwell-calibrated: they can meaningfully assess confidence in open-domain\nquestion-answering tasks, despite not being explicitly trained to do so. Our\nmain theoretical contribution establishes a mechanism for why semantic\ncalibration emerges as a byproduct of next-token prediction, leveraging a\nrecent connection between calibration and local loss optimality. The theory\nrelies on a general definition of \"B-calibration,\" which is a notion of\ncalibration parameterized by a choice of equivalence classes (semantic or\notherwise). This theoretical mechanism leads to a testable prediction: base\nLLMs will be semantically calibrated when they can easily predict their own\ndistribution over semantic answer classes before generating a response. We\nstate three implications of this prediction, which we validate through\nexperiments: (1) Base LLMs are semantically calibrated across\nquestion-answering tasks, (2) RL instruction-tuning systematically breaks this\ncalibration, and (3) chain-of-thought reasoning breaks calibration. To our\nknowledge, our work provides the first principled explanation of when and why\nsemantic calibration emerges in LLMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u57fa\u7840\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u6821\u51c6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u63d0\u51fa\u7406\u8bba\u89e3\u91ca\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u76f8\u5173\u9884\u6d4b\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u8bc4\u4f30\u5176\u8f93\u51fa\u5b9e\u9645\u610f\u4e49\u7684\u7f6e\u4fe1\u5ea6\uff0c\u89e3\u51b3\u57fa\u7840\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u6709\u610f\u4e49\u7f6e\u4fe1\u4f30\u8ba1\u7684\u95ee\u9898\u3002", "method": "\u5efa\u7acb\u8bed\u4e49\u6821\u51c6\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u526f\u4ea7\u54c1\u51fa\u73b0\u7684\u673a\u5236\uff0c\u57fa\u4e8e\u201cB - \u6821\u51c6\u201d\u5b9a\u4e49\uff0c\u63d0\u51fa\u53ef\u6d4b\u8bd5\u9884\u6d4b\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u57fa\u7840\u5927\u8bed\u8a00\u6a21\u578b\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u8bed\u4e49\u6821\u51c6\uff0c\u5f3a\u5316\u5b66\u4e60\u6307\u4ee4\u5fae\u8c03\u53ca\u601d\u7ef4\u94fe\u63a8\u7406\u4f1a\u7834\u574f\u6821\u51c6\u3002", "conclusion": "\u9996\u6b21\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u8bed\u4e49\u6821\u51c6\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u51fa\u73b0\u7ed9\u51fa\u4e86\u6709\u539f\u5219\u7684\u89e3\u91ca\u3002"}}
{"id": "2511.04682", "pdf": "https://arxiv.org/pdf/2511.04682", "abs": "https://arxiv.org/abs/2511.04682", "authors": ["Eleni Bougioukou", "Theodore Antonakopoulos"], "title": "Efficient Deployment of CNN Models on Multiple In-Memory Computing Units", "categories": ["cs.AR", "cs.AI"], "comment": "5 pages, 4 figures, 2025 14th International Conference on Modern\n  Circuits and Systems Technologies (MOCAST)", "summary": "In-Memory Computing (IMC) represents a paradigm shift in deep learning\nacceleration by mitigating data movement bottlenecks and leveraging the\ninherent parallelism of memory-based computations. The efficient deployment of\nConvolutional Neural Networks (CNNs) on IMC-based hardware necessitates the use\nof advanced task allocation strategies for achieving maximum computational\nefficiency. In this work, we exploit an IMC Emulator (IMCE) with multiple\nProcessing Units (PUs) for investigating how the deployment of a CNN model in a\nmulti-processing system affects its performance, in terms of processing rate\nand latency. For that purpose, we introduce the Load-Balance-Longest-Path\n(LBLP) algorithm, that dynamically assigns all CNN nodes to the available IMCE\nPUs, for maximizing the processing rate and minimizing latency due to efficient\nresources utilization. We are benchmarking LBLP against other alternative\nscheduling strategies for a number of CNN models and experimental results\ndemonstrate the effectiveness of the proposed algorithm.", "AI": {"tldr": "\u672c\u6587\u5229\u7528IMC\u6a21\u62df\u5668\u7814\u7a76CNN\u6a21\u578b\u5728\u591a\u5904\u7406\u7cfb\u7edf\u4e2d\u7684\u90e8\u7f72\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51faLBLP\u7b97\u6cd5\u5e76\u4e0e\u5176\u4ed6\u8c03\u5ea6\u7b56\u7565\u5bf9\u6bd4\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u57fa\u4e8eIMC\u7684\u786c\u4ef6\u4e0a\u9ad8\u6548\u90e8\u7f72CNN\u9700\u8981\u5148\u8fdb\u7684\u4efb\u52a1\u5206\u914d\u7b56\u7565\u4ee5\u5b9e\u73b0\u6700\u5927\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u5229\u7528\u5177\u6709\u591a\u4e2a\u5904\u7406\u5355\u5143\u7684IMC\u6a21\u62df\u5668\uff0c\u5f15\u5165LBLP\u7b97\u6cd5\u52a8\u6001\u5206\u914dCNN\u8282\u70b9\u5230\u53ef\u7528\u5904\u7406\u5355\u5143\u3002", "result": "\u5bf9\u591a\u4e2aCNN\u6a21\u578b\u5c06LBLP\u7b97\u6cd5\u4e0e\u5176\u4ed6\u8c03\u5ea6\u7b56\u7565\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "LBLP\u7b97\u6cd5\u80fd\u901a\u8fc7\u9ad8\u6548\u5229\u7528\u8d44\u6e90\uff0c\u6700\u5927\u5316\u5904\u7406\u901f\u7387\u5e76\u6700\u5c0f\u5316\u5ef6\u8fdf\u3002"}}
{"id": "2511.05051", "pdf": "https://arxiv.org/pdf/2511.05051", "abs": "https://arxiv.org/abs/2511.05051", "authors": ["Abimbola Agboke", "Felicia Nkatv Undie"], "title": "The use of social media among library professionals and patrons: A review of literature", "categories": ["cs.DL", "cs.IR"], "comment": "5 pages, Research Paper", "summary": "This paper focused on the utilization of social media by library\nprofessionals and library users. It provides an understanding of social media,\nthe most popular social media platforms utilized in the libraries. It also\nmentions the reasons for the adoption of social media in libraries be it\nacademic, public, school libraries and other types of libraries. This is a\nreview paper on the use of social media among library professionals and\npatrons. The findings reveal the contributions of social media to the\nlibraries. Social media makes things easy for library professionals and library\nusers. It enables them to connect, create awareness to new information,\ndisseminate information instantly, and helps to market the library resources\nand services. Therefore, it is recommended amongst others that the library\nmanagement board should encourage the use of social media in libraries.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u56fe\u4e66\u9986\u4e13\u4e1a\u4eba\u5458\u548c\u7528\u6237\u5bf9\u793e\u4ea4\u5a92\u4f53\u7684\u4f7f\u7528\uff0c\u5206\u6790\u6d41\u884c\u5e73\u53f0\u3001\u91c7\u7528\u539f\u56e0\uff0c\u63ed\u793a\u5176\u8d21\u732e\u5e76\u5efa\u8bae\u9f13\u52b1\u4f7f\u7528\u3002", "motivation": "\u4e86\u89e3\u56fe\u4e66\u9986\u4e13\u4e1a\u4eba\u5458\u548c\u7528\u6237\u5bf9\u793e\u4ea4\u5a92\u4f53\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "method": "\u6587\u732e\u7efc\u8ff0\u3002", "result": "\u793e\u4ea4\u5a92\u4f53\u6709\u52a9\u4e8e\u56fe\u4e66\u9986\u4e13\u4e1a\u4eba\u5458\u548c\u7528\u6237\uff0c\u80fd\u4fc3\u8fdb\u8fde\u63a5\u3001\u4f20\u64ad\u4fe1\u606f\u548c\u63a8\u5e7f\u8d44\u6e90\u670d\u52a1\u3002", "conclusion": "\u5efa\u8bae\u56fe\u4e66\u9986\u7ba1\u7406\u59d4\u5458\u4f1a\u9f13\u52b1\u5728\u56fe\u4e66\u9986\u4f7f\u7528\u793e\u4ea4\u5a92\u4f53\u3002"}}
{"id": "2511.05476", "pdf": "https://arxiv.org/pdf/2511.05476", "abs": "https://arxiv.org/abs/2511.05476", "authors": ["Md. Abdul Awal", "Mrigank Rochan", "Chanchal K. Roy"], "title": "A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?", "categories": ["cs.SE", "cs.LG"], "comment": "The paper is currently under review at a peer-reviewed journal", "summary": "Transformer-based language models of code have achieved state-of-the-art\nperformance across a wide range of software analytics tasks, but their\npractical deployment remains limited due to high computational costs, slow\ninference speeds, and significant environmental impact. To address these\nchallenges, recent research has increasingly explored knowledge distillation as\na method for compressing a large language model of code (the teacher) into a\nsmaller model (the student) while maintaining performance. However, the degree\nto which a student model deeply mimics the predictive behavior and internal\nrepresentations of its teacher remains largely unexplored, as current\naccuracy-based evaluation provides only a surface-level view of model quality\nand often fails to capture more profound discrepancies in behavioral fidelity\nbetween the teacher and student models. To address this gap, we empirically\nshow that the student model often fails to deeply mimic the teacher model,\nresulting in up to 285% greater performance drop under adversarial attacks,\nwhich is not captured by traditional accuracy-based evaluation. Therefore, we\npropose MetaCompress, a metamorphic testing framework that systematically\nevaluates behavioral fidelity by comparing the outputs of teacher and student\nmodels under a set of behavior-preserving metamorphic relations. We evaluate\nMetaCompress on two widely studied tasks, using compressed versions of popular\nlanguage models of code, obtained via three different knowledge distillation\ntechniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress\nidentifies up to 62% behavioral discrepancies in student models, underscoring\nthe need for behavioral fidelity evaluation within the knowledge distillation\npipeline and establishing MetaCompress as a practical framework for testing\ncompressed language models of code derived through knowledge distillation.", "AI": {"tldr": "\u5f53\u524d\u4ee3\u7801\u5927\u6a21\u578b\u90e8\u7f72\u53d7\u9650\uff0c\u77e5\u8bc6\u84b8\u998f\u53ef\u538b\u7f29\u6a21\u578b\uff0c\u4f46\u5b66\u751f\u6a21\u578b\u5bf9\u6559\u5e08\u6a21\u578b\u884c\u4e3a\u6a21\u4eff\u6df1\u5ea6\u7f3a\u4e4f\u7814\u7a76\u3002\u672c\u6587\u63d0\u51faMetaCompress\u6846\u67b6\u8bc4\u4f30\u884c\u4e3a\u4fdd\u771f\u5ea6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u8bc6\u522b\u5b66\u751f\u6a21\u578b\u4e2d\u9ad8\u8fbe62%\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "motivation": "\u89e3\u51b3\u4ee3\u7801\u5927\u6a21\u578b\u90e8\u7f72\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u63a8\u7406\u6162\u548c\u73af\u5883\u5f71\u54cd\u5927\u7684\u95ee\u9898\uff0c\u540c\u65f6\u5f25\u8865\u73b0\u6709\u57fa\u4e8e\u51c6\u786e\u7387\u8bc4\u4f30\u65e0\u6cd5\u6df1\u5165\u63a2\u7a76\u5b66\u751f\u6a21\u578b\u5bf9\u6559\u5e08\u6a21\u578b\u884c\u4e3a\u6a21\u4eff\u7a0b\u5ea6\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51faMetaCompress\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u4e00\u7ec4\u4fdd\u884c\u4e3a\u7684\u53d8\u5f62\u5173\u7cfb\u4e0b\u6bd4\u8f83\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u7684\u8f93\u51fa\u6765\u7cfb\u7edf\u8bc4\u4f30\u884c\u4e3a\u4fdd\u771f\u5ea6\uff0c\u5e76\u5728\u4e24\u4e2a\u5e7f\u6cdb\u7814\u7a76\u7684\u4efb\u52a1\u4e0a\u4f7f\u7528\u4e09\u79cd\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5f97\u5230\u7684\u538b\u7f29\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "MetaCompress\u80fd\u8bc6\u522b\u5b66\u751f\u6a21\u578b\u4e2d\u9ad8\u8fbe62%\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u4e14\u53d1\u73b0\u5b66\u751f\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u6027\u80fd\u4e0b\u964d\u5e45\u5ea6\u6bd4\u4f20\u7edf\u8bc4\u4f30\u663e\u793a\u7684\u66f4\u5927\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u6d41\u7a0b\u4e2d\u9700\u8981\u8fdb\u884c\u884c\u4e3a\u4fdd\u771f\u5ea6\u8bc4\u4f30\uff0cMetaCompress\u662f\u6d4b\u8bd5\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5f97\u5230\u7684\u538b\u7f29\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2511.04789", "pdf": "https://arxiv.org/pdf/2511.04789", "abs": "https://arxiv.org/abs/2511.04789", "authors": ["Xiaoda Wang", "Yuji Zhao", "Kaiqiao Han", "Xiao Luo", "Sanne van Rooij", "Jennifer Stevens", "Lifang He", "Liang Zhan", "Yizhou Sun", "Wei Wang", "Carl Yang"], "title": "Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting", "categories": ["cs.LG"], "comment": "Accepted to IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM) 2025", "summary": "Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry\npatterns. Modeling these longitudinal trajectories enables mechanistic insight,\ntreatment development, and individualized 'digital-twin' forecasting. However,\nexisting methods usually adopt recurrent neural networks and transformer\narchitectures, which rely on discrete, regularly sampled data while struggling\nto handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts.\nMoreover, these methods have difficulty capturing individual heterogeneity\nincluding variations in disease onset, progression rate, and symptom severity,\nwhich is a hallmark of PD. To address these challenges, we propose CNODE\n(Conditional Neural ODE), a novel framework for continuous, individualized PD\nprogression forecasting. The core of CNODE is to model morphological brain\nchanges as continuous temporal processes using a neural ODE model. In addition,\nwe jointly learn patient-specific initial time and progress speed to align\nindividual trajectories into a shared progression trajectory. We validate CNODE\non the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental\nresults show that our method outperforms state-of-the-art baselines in\nforecasting longitudinal PD progression.", "AI": {"tldr": "\u63d0\u51faCNODE\u6846\u67b6\u7528\u4e8e\u8fde\u7eed\u3001\u4e2a\u6027\u5316\u5e15\u91d1\u68ee\u75c5\u8fdb\u5c55\u9884\u6d4b\uff0c\u5728PPMI\u6570\u636e\u96c6\u9a8c\u8bc1\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5e15\u91d1\u68ee\u75c5\u961f\u5217\u4e2d\u4e0d\u89c4\u5219\u548c\u7a00\u758f\u7684MRI\u6570\u636e\uff0c\u4e14\u96be\u4ee5\u6355\u6349\u4e2a\u4f53\u5f02\u8d28\u6027\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u8fdb\u884c\u8fde\u7eed\u3001\u4e2a\u6027\u5316\u7684\u75be\u75c5\u8fdb\u5c55\u9884\u6d4b\u3002", "method": "\u63d0\u51faCNODE\u6846\u67b6\uff0c\u7528\u795e\u7ecfODE\u6a21\u578b\u5c06\u5927\u8111\u5f62\u6001\u53d8\u5316\u5efa\u6a21\u4e3a\u8fde\u7eed\u65f6\u95f4\u8fc7\u7a0b\uff0c\u8054\u5408\u5b66\u4e60\u60a3\u8005\u7279\u5b9a\u7684\u521d\u59cb\u65f6\u95f4\u548c\u8fdb\u5c55\u901f\u5ea6\u4ee5\u5bf9\u9f50\u4e2a\u4f53\u8f68\u8ff9\u3002", "result": "\u5728PPMI\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u5e15\u91d1\u68ee\u75c5\u7eb5\u5411\u8fdb\u5c55\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CNODE\u6846\u67b6\u5728\u5e15\u91d1\u68ee\u75c5\u8fdb\u5c55\u9884\u6d4b\u4e0a\u6709\u826f\u597d\u8868\u73b0\uff0c\u53ef\u7528\u4e8e\u76f8\u5173\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2511.04907", "pdf": "https://arxiv.org/pdf/2511.04907", "abs": "https://arxiv.org/abs/2511.04907", "authors": ["Lunjia Hu", "Haipeng Luo", "Spandan Senapati", "Vatsal Sharan"], "title": "Efficient Swap Multicalibration of Elicitable Properties", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multicalibration [HJKRR18] is an algorithmic fairness perspective that\ndemands that the predictions of a predictor are correct conditional on\nthemselves and membership in a collection of potentially overlapping subgroups\nof a population. The work of [NR23] established a surprising connection between\nmulticalibration for an arbitrary property $\\Gamma$ (e.g., mean or median) and\nproperty elicitation: a property $\\Gamma$ can be multicalibrated if and only if\nit is elicitable, where elicitability is the notion that the true property\nvalue of a distribution can be obtained by solving a regression problem over\nthe distribution. In the online setting, [NR23] proposed an inefficient\nalgorithm that achieves $\\sqrt T$ $\\ell_2$-multicalibration error for a\nhypothesis class of group membership functions and an elicitable property\n$\\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.\n  In this paper, we generalize multicalibration for an elicitable property\n$\\Gamma$ from group membership functions to arbitrary bounded hypothesis\nclasses and introduce a stronger notion -- swap multicalibration, following\n[GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when\ngiven access to an online agnostic learner, achieves $T^{1/(r+1)}$\n$\\ell_r$-swap multicalibration error with high probability (for $r\\ge2$) for a\nhypothesis class with bounded sequential Rademacher complexity and an\nelicitable property $\\Gamma$. For the special case of $r=2$, this implies an\noracle-efficient algorithm that achieves $T^{1/3}$ $\\ell_2$-swap\nmulticalibration error, which significantly improves on the previously\nestablished bounds for the problem [NR23, GMS25, LSS25a], and completely\nresolves an open question raised in [GJRR24] on the possibility of an\noracle-efficient algorithm that achieves $\\sqrt{T}$ $\\ell_2$-mean\nmulticalibration error by answering it in a strongly affirmative sense.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.04683", "pdf": "https://arxiv.org/pdf/2511.04683", "abs": "https://arxiv.org/abs/2511.04683", "authors": ["L. J. Janse van Rensburg"], "title": "AI-Powered Citation Auditing: A Zero-Assumption Protocol for Systematic Reference Verification in Academic Research", "categories": ["cs.DL", "cs.AI", "cs.CY", "68T50", "I.2.7; H.3.7; K.4.1"], "comment": "10 pages, 1 table. Code and validation data available at\n  https://github.com/leonjvr/ai-citation-auditor", "summary": "Academic citation integrity faces persistent challenges, with research\nindicating 20% of citations contain errors and manual verification requiring\nmonths of expert time. This paper presents a novel AI-powered methodology for\nsystematic, comprehensive reference auditing using agentic AI with tool-use\ncapabilities. We develop a zero-assumption verification protocol that\nindependently validates every reference against multiple academic databases\n(Semantic Scholar, Google Scholar, CrossRef) without assuming any citation is\ncorrect. The methodology was validated across 30 academic documents (2,581\nreferences) spanning undergraduate projects to doctoral theses and\npeer-reviewed publications. Results demonstrate 91.7% average verification rate\non published PLOS papers, with successful detection of fabricated references,\nretracted articles, orphan citations, and predatory journals. Time efficiency\nimproved dramatically: 90-minute audits for 916-reference doctoral theses\nversus months of manual review. The system achieved <0.5% false positive rate\nwhile identifying critical issues manual review might miss. This work\nestablishes the first validated AI-agent methodology for academic citation\nintegrity, demonstrating practical applicability for supervisors, students, and\ninstitutional quality assurance.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u7528\u6709\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684AI\u8fdb\u884c\u5b66\u672f\u5f15\u7528\u5ba1\u6838\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u63d0\u9ad8\u6548\u7387\u4e14\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u5b66\u672f\u5f15\u7528\u5b8c\u6574\u6027\u9762\u4e34\u6311\u6218\uff0c\u4eba\u5de5\u9a8c\u8bc1\u8017\u65f6\u4e45\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u96f6\u5047\u8bbe\u9a8c\u8bc1\u534f\u8bae\uff0c\u7528AI\u5c06\u6bcf\u4e2a\u5f15\u7528\u4e0e\u591a\u4e2a\u5b66\u672f\u6570\u636e\u5e93\u72ec\u7acb\u9a8c\u8bc1\u3002", "result": "\u572830\u4efd\u5b66\u672f\u6587\u6863\u4e0a\u9a8c\u8bc1\uff0cPLOS\u8bba\u6587\u5e73\u5747\u9a8c\u8bc1\u738791.7%\uff0c\u68c0\u6d4b\u591a\u79cd\u95ee\u9898\uff0c\u5927\u5e45\u63d0\u9ad8\u6548\u7387\uff0c\u8bef\u62a5\u7387<0.5%\u3002", "conclusion": "\u5efa\u7acb\u9996\u4e2a\u7ecf\u9a8c\u8bc1\u7684AI\u4ee3\u7406\u65b9\u6cd5\uff0c\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.05211", "pdf": "https://arxiv.org/pdf/2511.05211", "abs": "https://arxiv.org/abs/2511.05211", "authors": ["Muneer Ahmad"], "title": "Mapping Research Productivity of BRICS Countries with Special Reference to Coronary Artery Disease (CAD): A Scientometric Study", "categories": ["cs.DL", "cs.IR"], "comment": "260 Pages, 21 figures, PhD Thesis 2020", "summary": "This study presents a comprehensive scientometric analysis of research\nproductivity on Coronary Artery Disease (CAD) among the BRICS countries,\nBrazil, Russia, India, China, and South Africa, using data retrieved from the\nWeb of Science database for the period 1990 to 2019. A total of 50,036 records\nwere analyzed to assess publication growth trends, authorship patterns,\ncollaboration levels, and citation impact. The findings reveal a steady\nincrease in CAD-related publications, with China emerging as the leading\ncontributor, followed by Brazil, Russia, India, and South Africa. English\ndominated as the primary language of communication, accounting for over 93% of\npublications. Authorship and collaboration analysis indicate a high degree of\njoint research, with 97.91% of studies being co-authored and a degree of\ncollaboration of 0.98, underscoring the collective nature of scientific inquiry\nin this domain. The study validates the applicability of Lotkas Law for author\nproductivity, Bradfords Law for journal distribution, and Zipfs Law for keyword\nfrequency, while the Price Square Root Law was found inapplicable. The\npredominant publication format was journal articles (79.7%), and Kardiologiya\n(Russia) emerged as the most prolific journal. The results demonstrate\nsignificant growth in CAD research output and collaboration within BRICS,\nthough notable disparities persist among member nations. The study recommends\nenhancing individual author productivity, expanding international\ncollaboration, and supporting CAD research through strategic institutional and\ngovernmental initiatives. These findings provide valuable insights for\npolicymakers, funding agencies, and the academic community to strengthen\ncardiovascular research capacity within developing economies.", "AI": {"tldr": "\u5bf91990 - 2019\u5e74BRICS\u56fd\u5bb6\u51a0\u5fc3\u75c5\u7814\u7a76\u4ea7\u51fa\u8fdb\u884c\u79d1\u5b66\u8ba1\u91cf\u5206\u6790\uff0c\u53d1\u73b0\u4ea7\u51fa\u548c\u5408\u4f5c\u589e\u957f\u663e\u8457\u4f46\u6210\u5458\u56fd\u6709\u5dee\u5f02\uff0c\u7ed9\u51fa\u76f8\u5173\u5efa\u8bae\u3002", "motivation": "\u5168\u9762\u5206\u6790BRICS\u56fd\u5bb6\u51a0\u5fc3\u75c5\u7814\u7a76\u4ea7\u51fa\u60c5\u51b5\u3002", "method": "\u4eceWeb of Science\u6570\u636e\u5e93\u83b7\u53d6\u6570\u636e\uff0c\u5206\u679050,036\u6761\u8bb0\u5f55\uff0c\u8bc4\u4f30\u53d1\u8868\u589e\u957f\u8d8b\u52bf\u3001\u4f5c\u8005\u6a21\u5f0f\u3001\u5408\u4f5c\u6c34\u5e73\u548c\u5f15\u6587\u5f71\u54cd\u3002", "result": "\u51a0\u5fc3\u75c5\u76f8\u5173\u51fa\u7248\u7269\u7a33\u6b65\u589e\u52a0\uff0c\u4e2d\u56fd\u8d21\u732e\u6700\u5927\uff1b\u82f1\u8bed\u4e3a\u4e3b\uff1b\u5408\u8457\u6bd4\u4f8b\u9ad8\uff1b\u9a8c\u8bc1\u90e8\u5206\u5b9a\u5f8b\uff0c\u666e\u83b1\u65af\u5e73\u65b9\u6839\u5b9a\u5f8b\u4e0d\u9002\u7528\uff1b\u671f\u520a\u6587\u7ae0\u4e3a\u4e3b\uff1b\u4fc4\u7f57\u65af\u300aKardiologiya\u300b\u6700\u6d3b\u8dc3\uff1b\u6210\u5458\u56fd\u6709\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5efa\u8bae\u63d0\u9ad8\u4f5c\u8005\u751f\u4ea7\u529b\u3001\u6269\u5927\u56fd\u9645\u5408\u4f5c\uff0c\u901a\u8fc7\u6218\u7565\u4e3e\u63aa\u652f\u6301\u7814\u7a76\uff0c\u4e3a\u76f8\u5173\u65b9\u63d0\u4f9b\u89c1\u89e3\u4ee5\u52a0\u5f3a\u53d1\u5c55\u4e2d\u7ecf\u6d4e\u4f53\u5fc3\u8840\u7ba1\u7814\u7a76\u80fd\u529b\u3002"}}
