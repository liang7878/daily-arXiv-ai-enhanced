{"id": "2507.08846", "pdf": "https://arxiv.org/pdf/2507.08846", "abs": "https://arxiv.org/abs/2507.08846", "authors": ["Serdar Metin"], "title": "Precomputed Dominant Resource Fairness", "categories": ["cs.GT", "cs.DC", "cs.DS"], "comment": "9 pages", "summary": "Although resource allocation is a well studied problem in computer science,\nuntil the prevalence of distributed systems, such as computing clouds and data\ncentres, the question had been addressed predominantly for single resource type\nscenarios. At the beginning of the last decade, with the introuction of\nDominant Resource Fairness, the studies of the resource allocation problem has\nfinally extended to the multiple resource type scenarios. Dominant Resource\nFairness is a solution, addressing the problem of fair allocation of multiple\nresource types, among users with heterogeneous demands. Based on Max-min\nFairness, which is a well established algorithm in the literature for\nallocating resources in the single resource type scenarios, Dominant Resource\nFairness generalises the scheme to the multiple resource case. It has a number\nof desirable properties that makes it preferable over alternatives, such as\nSharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness,\nand as such, it is widely adopted in distributed systems. In the present study,\nwe revisit the original study, and analyse the structure of the algorithm in\ncloser view, to come up with an alternative algorithm, which approximates the\nDominant Resource Fairness allocation in fewer steps. We name the new algorithm\nPrecomputed Dominant Resource Fairness, after its main working principle.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u7b97\u6cd5\uff0c\u63d0\u51fa\u65b0\u7684\u9884\u8ba1\u7b97\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u7b97\u6cd5\u4ee5\u66f4\u5c11\u6b65\u9aa4\u8fd1\u4f3c\u5176\u5206\u914d\u7ed3\u679c\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u671f\u671b\u627e\u5230\u80fd\u4ee5\u66f4\u5c11\u6b65\u9aa4\u8fd1\u4f3c\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u5206\u914d\u7684\u7b97\u6cd5\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u539f\u7b97\u6cd5\uff0c\u5206\u6790\u5176\u7ed3\u6784\uff0c\u57fa\u4e8e\u4e3b\u8981\u5de5\u4f5c\u539f\u7406\u8bbe\u8ba1\u65b0\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u9884\u8ba1\u7b97\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u7b97\u6cd5\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u80fd\u5728\u66f4\u5c11\u6b65\u9aa4\u5185\u8fd1\u4f3c\u4e3b\u5bfc\u8d44\u6e90\u516c\u5e73\u6027\u5206\u914d\u3002"}}
{"id": "2507.08868", "pdf": "https://arxiv.org/pdf/2507.08868", "abs": "https://arxiv.org/abs/2507.08868", "authors": ["Benedikt Pittl", "Werner Mach", "Erich Schikuta"], "title": "A Survey on Bilateral Multi-Round Cloud-SLA Negotiation Strategies", "categories": ["cs.GT", "cs.DC", "91B26", "J.1; J.4"], "comment": "Preprint", "summary": "Today, static cloud markets where consumers purchase services directly from\nproviders are dominating. Thus, consumers neither negotiate the price nor the\ncharacteristics of the service. In recent years, providers have adopted more\ndynamic trading mechanisms, as e.g. Amazon's EC2 platform shows: In addition to\nthe reservation marketspace and the on-demand marketspace, Amazon offers a spot\nmarketspace where consumers can bid for virtual machines. This spot marketspace\nwas extended with spot blocks, and recently Amazon reworked the bidding\noptions. In addition, other cloud providers, such as Virtustream, adopt dynamic\ntrading mechanisms. The scientific community envisions autonomous multi-round\nnegotiations for realizing future cloud marketspaces. Consequently, consumers\nand providers exchange offers and counteroffers to reach an agreement. This\nhelps providers increase the utilization of their datacenters, while consumers\ncan purchase highly customized cloud services.\n  In the paper at hand, we present a survey on multi-round bilateral\nnegotiation strategies for trading cloud resources. Thus, we analyzed\npeer-reviewed articles in order to identify trends, gaps, similarities, and the\nscope of such negotiation strategies. In addition, we surveyed the formalism\nthat the scientific community uses to describe such strategies. Based on these\nfindings, we derived recommendations for creating and documenting bilateral\nmulti-round negotiation strategies to foster their implementation in the\nindustry.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u4e91\u5e02\u573a\u52a8\u6001\u4ea4\u6613\u673a\u5236\u53d1\u5c55\uff0c\u5bf9\u4e91\u8d44\u6e90\u591a\u8f6e\u53cc\u8fb9\u8c08\u5224\u7b56\u7565\u8fdb\u884c\u8c03\u67e5\u5e76\u7ed9\u51fa\u5efa\u8bae\u3002", "motivation": "\u5f53\u524d\u9759\u6001\u4e91\u5e02\u573a\u4e3a\u4e3b\uff0c\u6d88\u8d39\u8005\u7f3a\u4e4f\u8bae\u4ef7\u7b49\u6743\u5229\uff0c\u79d1\u5b66\u754c\u8bbe\u60f3\u901a\u8fc7\u81ea\u4e3b\u591a\u8f6e\u8c08\u5224\u5b9e\u73b0\u672a\u6765\u4e91\u5e02\u573a\uff0c\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u548c\u670d\u52a1\u5b9a\u5236\u5316\u3002", "method": "\u5206\u6790\u540c\u884c\u8bc4\u5ba1\u6587\u7ae0\uff0c\u8c03\u67e5\u79d1\u5b66\u754c\u63cf\u8ff0\u6b64\u7c7b\u7b56\u7565\u7684\u5f62\u5f0f\u4e3b\u4e49\u3002", "result": "\u786e\u5b9a\u4e86\u4e91\u8d44\u6e90\u591a\u8f6e\u53cc\u8fb9\u8c08\u5224\u7b56\u7565\u7684\u8d8b\u52bf\u3001\u5dee\u8ddd\u3001\u76f8\u4f3c\u6027\u548c\u8303\u56f4\u3002", "conclusion": "\u5f97\u51fa\u521b\u5efa\u548c\u8bb0\u5f55\u53cc\u8fb9\u591a\u8f6e\u8c08\u5224\u7b56\u7565\u7684\u5efa\u8bae\uff0c\u4ee5\u4fc3\u8fdb\u5176\u5728\u884c\u4e1a\u4e2d\u7684\u5b9e\u65bd\u3002"}}
{"id": "2507.09083", "pdf": "https://arxiv.org/pdf/2507.09083", "abs": "https://arxiv.org/abs/2507.09083", "authors": ["Anand Shah", "Kehang Zhu", "Yanchen Jiang", "Jeffrey G. Wang", "Arif K. Dayi", "John J. Horton", "David C. Parkes"], "title": "Learning from Synthetic Labs: Language Models as Auction Participants", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "This paper investigates the behavior of simulated AI agents (large language\nmodels, or LLMs) in auctions, introducing a novel synthetic data-generating\nprocess to help facilitate the study and design of auctions. We find that LLMs\n-- when endowed with chain of thought reasoning capacity -- agree with the\nexperimental literature in auctions across a variety of classic auction\nformats. In particular, we find that LLM bidders produce results consistent\nwith risk-averse human bidders; that they perform closer to theoretical\npredictions in obviously strategy-proof auctions; and, that they succumb to the\nwinner's curse in common value settings. On prompting, we find that LLMs are\nnot very sensitive to naive changes in prompts (e.g., language, currency) but\ncan improve dramatically towards theoretical predictions with the right mental\nmodel (i.e., the language of Nash deviations). We run 1,000$+$ auctions for\nless than $\\$$400 with GPT-4 models (three orders of magnitude cheaper than\nmodern auction experiments) and develop a framework flexible enough to run\nauction experiments with any LLM model and a wide range of auction design\nspecifications, facilitating further experimental study by decreasing costs and\nserving as a proof-of-concept for the use of LLM proxies.", "AI": {"tldr": "\u7814\u7a76\u6a21\u62dfAI\u4ee3\u7406\uff08LLMs\uff09\u5728\u62cd\u5356\u4e2d\u7684\u884c\u4e3a\uff0c\u5f15\u5165\u65b0\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u53d1\u73b0LLMs\u5728\u62cd\u5356\u4e2d\u8868\u73b0\u53ca\u5bf9\u63d0\u793a\u7684\u53cd\u5e94\uff0c\u6210\u672c\u4f4e\u4e14\u5f00\u53d1\u7075\u6d3b\u6846\u67b6\u4fc3\u8fdb\u7814\u7a76\u3002", "motivation": "\u7814\u7a76\u6a21\u62dfAI\u4ee3\u7406\uff08LLMs\uff09\u5728\u62cd\u5356\u4e2d\u7684\u884c\u4e3a\uff0c\u4ee5\u5e2e\u52a9\u4fc3\u8fdb\u62cd\u5356\u7684\u7814\u7a76\u548c\u8bbe\u8ba1\u3002", "method": "\u5f15\u5165\u65b0\u9896\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u4f7f\u7528GPT - 4\u6a21\u578b\u8fdb\u884c1000 +\u6b21\u62cd\u5356\u3002", "result": "\u6709\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\u7684LLMs\u4e0e\u5b9e\u9a8c\u6587\u732e\u7ed3\u679c\u76f8\u7b26\uff0c\u8868\u73b0\u7c7b\u4f3c\u98ce\u9669\u538c\u6076\u7684\u4eba\u7c7b\u6295\u6807\u4eba\uff1b\u5bf9\u7b80\u5355\u63d0\u793a\u53d8\u5316\u4e0d\u654f\u611f\uff0c\u7528\u6b63\u786e\u5fc3\u7406\u6a21\u578b\u53ef\u63a5\u8fd1\u7406\u8bba\u9884\u6d4b\uff1b\u6210\u672c\u6bd4\u73b0\u4ee3\u62cd\u5356\u5b9e\u9a8c\u4f4e\u4e09\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u5f00\u53d1\u7684\u6846\u67b6\u53ef\u7528\u4e8e\u4efb\u4f55LLM\u6a21\u578b\u548c\u591a\u79cd\u62cd\u5356\u8bbe\u8ba1\u89c4\u8303\u5b9e\u9a8c\uff0c\u964d\u4f4e\u6210\u672c\uff0c\u4e3a\u4f7f\u7528LLM\u4ee3\u7406\u63d0\u4f9b\u6982\u5ff5\u9a8c\u8bc1\u3002"}}
{"id": "2507.09422", "pdf": "https://arxiv.org/pdf/2507.09422", "abs": "https://arxiv.org/abs/2507.09422", "authors": ["Edan Orzech", "Martin Rinard"], "title": "Nash Equilibria with Irradical Probabilities", "categories": ["cs.GT", "math.NT", "91A06, 91A10"], "comment": null, "summary": "We present for every $n\\ge4$ an $n$-player game in normal form with payoffs\nin $\\{0,1,2\\}$ that has a unique, fully mixed, Nash equilibrium in which all\nthe probability weights are irradical (i.e., algebraic but not closed form\nexpressible even with $m$-th roots for any integer $m$).", "AI": {"tldr": "\u4e3a\u6bcf\u4e2an\u22654\u7ed9\u51fa\u4e00\u4e2an\u73a9\u5bb6\u6b63\u89c4\u5f62\u5f0f\u535a\u5f08\uff0c\u6709\u552f\u4e00\u5b8c\u5168\u6df7\u5408\u7eb3\u4ec0\u5747\u8861\u4e14\u6982\u7387\u6743\u91cd\u4e3a\u975e\u6839\u5f0f\u4ee3\u6570\u6570\u3002", "motivation": "\u63a2\u7d22\u5177\u6709\u7279\u5b9a\u6027\u8d28\uff08\u552f\u4e00\u3001\u5b8c\u5168\u6df7\u5408\u4e14\u6982\u7387\u6743\u91cd\u4e3a\u975e\u6839\u5f0f\u4ee3\u6570\u6570\uff09\u7684n\u73a9\u5bb6\u6b63\u89c4\u5f62\u5f0f\u535a\u5f08\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u7ed9\u51fa\u4e86n\u22654\u65f6\u6ee1\u8db3\u6761\u4ef6\uff08\u6709\u552f\u4e00\u5b8c\u5168\u6df7\u5408\u7eb3\u4ec0\u5747\u8861\u4e14\u6982\u7387\u6743\u91cd\u4e3a\u975e\u6839\u5f0f\u4ee3\u6570\u6570\uff09\u7684n\u73a9\u5bb6\u6b63\u89c4\u5f62\u5f0f\u535a\u5f08\u3002", "conclusion": "\u5b58\u5728\u6ee1\u8db3\u7279\u5b9a\u6761\u4ef6\u7684n\u73a9\u5bb6\u6b63\u89c4\u5f62\u5f0f\u535a\u5f08\u3002"}}
{"id": "2507.08954", "pdf": "https://arxiv.org/pdf/2507.08954", "abs": "https://arxiv.org/abs/2507.08954", "authors": ["Alexander Fuerst", "Siddharth Anil", "Vishakha Dixit", "Purushottam", "Kulkarni", "Prateek Sharma"], "title": "MQFQ-Sticky: Fair Queueing For Serverless GPU Functions", "categories": ["cs.DC", "cs.SY", "eess.SY"], "comment": null, "summary": "Hardware accelerators like GPUs are now ubiquitous in data centers, but are\nnot fully supported by common cloud abstractions such as Functions as a Service\n(FaaS). Many popular and emerging FaaS applications such as machine learning\nand scientific computing can benefit from GPU acceleration. However, FaaS\nframeworks (such as OpenWhisk) are not capable of providing this acceleration\nbecause of the impedance mismatch between GPUs and the FaaS programming model,\nwhich requires virtualization and sandboxing of each function. The challenges\nare amplified due to the highly dynamic and heterogeneous FaaS workloads. This\npaper presents the design and implementation of a FaaS system for providing GPU\nacceleration in a black-box manner (without modifying function code). Running\nsmall functions in containerized sandboxes is challenging due to limited GPU\nconcurrency and high cold-start overheads, resulting in heavy queueing of\nfunction invocations. We show how principles from I/O scheduling, such as fair\nqueuing and anticipatory scheduling, can be translated to function scheduling\non GPUs. We develop MQFQ-Sticky, an integrated fair queueing and GPU memory\nmanagement approach, which balances the tradeoffs between locality, fairness,\nand latency. Empirical evaluation on a range of workloads shows that it reduces\nfunction latency by 2x to 20x compared to existing GPU and CPU queueing\npolicies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4ee5\u9ed1\u76d2\u65b9\u5f0f\u63d0\u4f9bGPU\u52a0\u901f\u7684FaaS\u7cfb\u7edf\uff0c\u5f00\u53d1MQFQ - Sticky\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u7b56\u7565\u53ef\u5c06\u51fd\u6570\u5ef6\u8fdf\u964d\u4f4e2 - 20\u500d\u3002", "motivation": "\u5e38\u89c1\u4e91\u62bd\u8c61\u5982FaaS\u672a\u5145\u5206\u652f\u6301GPU\uff0c\u800c\u8bb8\u591aFaaS\u5e94\u7528\u80fd\u4eceGPU\u52a0\u901f\u4e2d\u53d7\u76ca\uff0c\u4f46\u73b0\u6709FaaS\u6846\u67b6\u56e0GPU\u4e0eFaaS\u7f16\u7a0b\u6a21\u578b\u4e0d\u5339\u914d\u65e0\u6cd5\u63d0\u4f9b\u52a0\u901f\uff0c\u4e14FaaS\u5de5\u4f5c\u8d1f\u8f7d\u52a8\u6001\u5f02\u6784\uff0c\u6311\u6218\u88ab\u653e\u5927\u3002", "method": "\u5c06I/O\u8c03\u5ea6\u539f\u5219\u5e94\u7528\u4e8eGPU\u4e0a\u7684\u51fd\u6570\u8c03\u5ea6\uff0c\u5f00\u53d1MQFQ - Sticky\uff0c\u4e00\u79cd\u96c6\u6210\u516c\u5e73\u961f\u5217\u548cGPU\u5185\u5b58\u7ba1\u7406\u7684\u65b9\u6cd5\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u7684GPU\u548cCPU\u6392\u961f\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u5c06\u51fd\u6570\u5ef6\u8fdf\u964d\u4f4e\u4e862\u500d\u523020\u500d\u3002", "conclusion": "MQFQ - Sticky\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u5c40\u90e8\u6027\u3001\u516c\u5e73\u6027\u548c\u5ef6\u8fdf\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u53ef\u7528\u4e8e\u4ee5\u9ed1\u76d2\u65b9\u5f0f\u5728FaaS\u7cfb\u7edf\u4e2d\u63d0\u4f9bGPU\u52a0\u901f\u3002"}}
{"id": "2507.08890", "pdf": "https://arxiv.org/pdf/2507.08890", "abs": "https://arxiv.org/abs/2507.08890", "authors": ["Nick Craswell", "Bhaskar Mitra", "Emine Yilmaz", "Hossein A. Rahmani", "Daniel Campos", "Jimmy Lin", "Ellen M. Voorhees", "Ian Soboroff"], "title": "Overview of the TREC 2023 deep learning track", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "arXiv admin note: substantial text overlap with arXiv:2507.08191", "summary": "This is the fifth year of the TREC Deep Learning track. As in previous years,\nwe leverage the MS MARCO datasets that made hundreds of thousands of\nhuman-annotated training labels available for both passage and document ranking\ntasks. We mostly repeated last year's design, to get another matching test set,\nbased on the larger, cleaner, less-biased v2 passage and document set, with\npassage ranking as primary and document ranking as a secondary task (using\nlabels inferred from passage). As we did last year, we sample from MS MARCO\nqueries that were completely held out, unused in corpus construction, unlike\nthe test queries in the first three years. This approach yields a more\ndifficult test with more headroom for improvement. Alongside the usual MS MARCO\n(human) queries from MS MARCO, this year we generated synthetic queries using a\nfine-tuned T5 model and using a GPT-4 prompt.\n  The new headline result this year is that runs using Large Language Model\n(LLM) prompting in some way outperformed runs that use the \"nnlm\" approach,\nwhich was the best approach in the previous four years. Since this is the last\nyear of the track, future iterations of prompt-based ranking can happen in\nother tracks. Human relevance assessments were applied to all query types, not\njust human MS MARCO queries. Evaluation using synthetic queries gave similar\nresults to human queries, with system ordering agreement of $\\tau=0.8487$.\nHowever, human effort was needed to select a subset of the synthetic queries\nthat were usable. We did not see clear evidence of bias, where runs using GPT-4\nwere favored when evaluated using synthetic GPT-4 queries, or where runs using\nT5 were favored when evaluated on synthetic T5 queries.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdTREC\u6df1\u5ea6\u5b66\u4e60\u8d5b\u9053\u7b2c\u4e94\u5e74\u60c5\u51b5\uff0c\u590d\u7528\u53bb\u5e74\u8bbe\u8ba1\uff0c\u7528\u65b0\u6570\u636e\u96c6\uff0c\u4eca\u5e74\u7528\u5408\u6210\u67e5\u8be2\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u6cd5\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u7684nnlm\u65b9\u6cd5\uff0c\u5408\u6210\u67e5\u8be2\u8bc4\u4f30\u7ed3\u679c\u4e0e\u4eba\u7c7b\u67e5\u8be2\u76f8\u4f3c\uff0c\u672a\u53d1\u73b0\u660e\u663e\u504f\u5dee\u3002", "motivation": "\u5728TREC\u6df1\u5ea6\u5b66\u4e60\u8d5b\u9053\u6301\u7eed\u5f00\u5c55\u76f8\u5173\u7814\u7a76\uff0c\u5229\u7528MS MARCO\u6570\u636e\u96c6\u8fdb\u884c\u6bb5\u843d\u548c\u6587\u6863\u6392\u540d\u4efb\u52a1\uff0c\u83b7\u53d6\u66f4\u5177\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u96c6\u4ee5\u63a8\u52a8\u6280\u672f\u6539\u8fdb\u3002", "method": "\u590d\u7528\u53bb\u5e74\u8bbe\u8ba1\uff0c\u57fa\u4e8e\u65b0\u7684\u6bb5\u843d\u548c\u6587\u6863\u96c6\uff0c\u4eceMS MARCO\u672a\u4f7f\u7528\u8fc7\u7684\u67e5\u8be2\u4e2d\u91c7\u6837\uff0c\u751f\u6210\u5408\u6210\u67e5\u8be2\uff0c\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u6cd5\u548cnnlm\u65b9\u6cd5\u7b49\u3002", "result": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u6cd5\u7684\u8fd0\u884c\u7ed3\u679c\u4f18\u4e8ennlm\u65b9\u6cd5\uff0c\u5408\u6210\u67e5\u8be2\u8bc4\u4f30\u4e0e\u4eba\u7c7b\u67e5\u8be2\u7ed3\u679c\u76f8\u4f3c\uff0c\u7cfb\u7edf\u6392\u5e8f\u4e00\u81f4\u6027\u4e3a\u03c4 = 0.8487\uff0c\u4f46\u9700\u4eba\u5de5\u7b5b\u9009\u53ef\u7528\u7684\u5408\u6210\u67e5\u8be2\uff0c\u672a\u53d1\u73b0\u660e\u663e\u504f\u5dee\u3002", "conclusion": "\u672c\u6b21\u7814\u7a76\u4e3a\u8be5\u8d5b\u9053\u6700\u540e\u4e00\u5e74\uff0c\u57fa\u4e8e\u63d0\u793a\u7684\u6392\u540d\u540e\u7eed\u53ef\u5728\u5176\u4ed6\u8d5b\u9053\u5f00\u5c55\uff0c\u5408\u6210\u67e5\u8be2\u53ef\u7528\u4e8e\u8bc4\u4f30\u4e14\u6548\u679c\u826f\u597d\u3002"}}
{"id": "2507.09255", "pdf": "https://arxiv.org/pdf/2507.09255", "abs": "https://arxiv.org/abs/2507.09255", "authors": ["Charidimos Papadakis", "Giorgos Filandrianos", "Angeliki Dimitriou", "Maria Lymperaiou", "Konstantinos Thomas", "Giorgos Stamou"], "title": "StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets", "categories": ["cs.CE", "cs.MA"], "comment": null, "summary": "We present StockSim, an open-source simulation platform for systematic\nevaluation of large language models (LLMs) in realistic financial\ndecision-making scenarios. Unlike previous toolkits that offer limited scope,\nStockSim delivers a comprehensive system that fully models market dynamics and\nsupports diverse simulation modes of varying granularity. It incorporates\ncritical real-world factors, such as latency, slippage, and order-book\nmicrostructure, that were previously neglected, enabling more faithful and\ninsightful assessment of LLM-based trading agents. An extensible, role-based\nagent framework supports heterogeneous trading strategies and multi-agent\ncoordination, making StockSim a uniquely capable testbed for NLP research on\nreasoning under uncertainty and sequential decision-making. We open-source all\nour code at https: //github.com/harrypapa2002/StockSim.", "AI": {"tldr": "\u4ecb\u7ecd\u5f00\u6e90\u6a21\u62df\u5e73\u53f0StockSim\uff0c\u53ef\u5728\u73b0\u5b9e\u91d1\u878d\u51b3\u7b56\u573a\u666f\u4e2d\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8003\u8651\u591a\u56e0\u7d20\uff0c\u652f\u6301\u591a\u7b56\u7565\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u5305\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u51b3\u7b56\u573a\u666f\u7684\u8303\u56f4\u6709\u9650\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u7cfb\u7edf\u3002", "method": "\u6784\u5efaStockSim\u5e73\u53f0\uff0c\u6a21\u62df\u5e02\u573a\u52a8\u6001\uff0c\u652f\u6301\u591a\u79cd\u6a21\u62df\u6a21\u5f0f\uff0c\u7eb3\u5165\u5173\u952e\u73b0\u5b9e\u56e0\u7d20\uff0c\u91c7\u7528\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u89d2\u8272\u7684\u4ee3\u7406\u6846\u67b6\u3002", "result": "\u5f97\u5230\u53ef\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e73\u53f0StockSim\u3002", "conclusion": "StockSim\u662f\u7528\u4e8e\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u548c\u5e8f\u5217\u51b3\u7b56\u7684NLP\u7814\u7a76\u7684\u6709\u529b\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.09003", "pdf": "https://arxiv.org/pdf/2507.09003", "abs": "https://arxiv.org/abs/2507.09003", "authors": ["Prasoon Patidar", "Alex Crown", "Kevin Hsieh", "Yifei Xu", "Tusher Chakraborty", "Ranveer Chandra", "Yuvraj Agarwal"], "title": "Orchestration for Domain-specific Edge-Cloud Language Models", "categories": ["cs.DB"], "comment": null, "summary": "The remarkable performance of Large Language Models (LLMs) has inspired many\napplications, which often necessitate edge-cloud collaboration due to\nconnectivity, privacy, and cost considerations. Traditional methods primarily\nfocus on selecting the best LLM model for optimizing performance, while\nneglecting the critical interplay between the components of the LLM serving\npipeline (context retrieval, query preprocessing, etc.) or the changing latency\nand cost constraints. We introduce ECO-LLM (Edge-Cloud Orchestrator for LLMs),\na novel system that reframes this problem as a joint optimization challenge and\nsolves it by systematically exploring component configurations and dynamically\nselecting optimal strategies at the query level. ECO-LLM consists of two\ncomponents: (1) the ECO-LLM Emulator, which efficiently explores the vast\nconfiguration space utilizing query clustering and pareto-optimal path\nselection, gathering domain-specific performance metrics without exhaustive\nevaluation; and (2) the ECO-LLM Runtime, which leverages these metrics to\ndynamically select optimal resolution strategies for user queries while meeting\nuser-defined Service Level Objectives (SLOs). We evaluate ECO-LLM on a smart\nhome and a smart car assistant scenarios. With an exhaustive exploration of all\npossible configurations for seen queries, ECO-LLM outperforms cloud-based\nmodels like GPT-4o in terms of accuracy (90% vs. 74% on average) while reducing\ncosts by 90% and latency by 55%, demonstrating the value of its joint\noptimization at the query level. In practical deployment for previously unseen\nqueries, ECO-LLM selects configurations that reduce costs by 62% or improve\nresponse times by 62% on average compared to state-of-the-art model routing\napproaches, while maintaining higher accuracy and consistently adhering to\nspecified latency and cost constraints.", "AI": {"tldr": "\u63d0\u51faECO - LLM\u7cfb\u7edf\u89e3\u51b3LLM\u8fb9\u7f18\u4e91\u534f\u4f5c\u95ee\u9898\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u51c6\u786e\u7387\u3001\u6210\u672c\u548c\u5ef6\u8fdf\u65b9\u9762\u6709\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728LLM\u8fb9\u7f18\u4e91\u534f\u4f5c\u4e2d\u53ea\u5173\u6ce8\u9009\u6700\u4f73\u6a21\u578b\uff0c\u5ffd\u7565\u7ec4\u4ef6\u95f4\u4ea4\u4e92\u548c\u53d8\u5316\u7684\u5ef6\u8fdf\u3001\u6210\u672c\u7ea6\u675f\u3002", "method": "\u5f15\u5165ECO - LLM\u7cfb\u7edf\uff0c\u5c06\u95ee\u9898\u89c6\u4e3a\u8054\u5408\u4f18\u5316\u6311\u6218\uff0c\u901a\u8fc7\u7cfb\u7edf\u63a2\u7d22\u7ec4\u4ef6\u914d\u7f6e\u548c\u52a8\u6001\u9009\u62e9\u67e5\u8be2\u7ea7\u6700\u4f18\u7b56\u7565\u89e3\u51b3\u3002\u7cfb\u7edf\u5305\u542bECO - LLM Emulator\u548cECO - LLM Runtime\u4e24\u4e2a\u7ec4\u4ef6\u3002", "result": "\u5728\u667a\u80fd\u5bb6\u5c45\u548c\u667a\u80fd\u6c7d\u8f66\u52a9\u624b\u573a\u666f\u8bc4\u4f30\uff0c\u5bf9\u5df2\u77e5\u67e5\u8be2\uff0c\u51c6\u786e\u7387\u8fbe90%\u9ad8\u4e8eGPT - 4o\uff0c\u6210\u672c\u964d90%\u3001\u5ef6\u8fdf\u964d55%\uff1b\u5bf9\u672a\u77e5\u67e5\u8be2\uff0c\u6210\u672c\u964d62%\u6216\u54cd\u5e94\u65f6\u95f4\u63d0\u534762%\u3002", "conclusion": "ECO - LLM\u7684\u67e5\u8be2\u7ea7\u8054\u5408\u4f18\u5316\u6709\u4ef7\u503c\uff0c\u80fd\u5728\u4fdd\u8bc1\u51c6\u786e\u7387\u7684\u540c\u65f6\u6ee1\u8db3\u5ef6\u8fdf\u548c\u6210\u672c\u7ea6\u675f\u3002"}}
{"id": "2507.09385", "pdf": "https://arxiv.org/pdf/2507.09385", "abs": "https://arxiv.org/abs/2507.09385", "authors": ["Kevin Reyes", "Vasco Cortez"], "title": "Credit Card Fraud Detection Using RoFormer Model With Relative Distance Rotating Encoding", "categories": ["cs.NE", "cs.LG"], "comment": "2025 IEEE Conference on Artificial Intelligence (CAI)", "summary": "Fraud detection is one of the most important challenges that financial\nsystems must address. Detecting fraudulent transactions is critical for payment\ngateway companies like Flow Payment, which process millions of transactions\nmonthly and require robust security measures to mitigate financial risks.\nIncreasing transaction authorization rates while reducing fraud is essential\nfor providing a good user experience and building a sustainable business. For\nthis reason, discovering novel and improved methods to detect fraud requires\ncontinuous research and investment for any company that wants to succeed in\nthis industry. In this work, we introduced a novel method for detecting\ntransactional fraud by incorporating the Relative Distance Rotating Encoding\n(ReDRE) in the RoFormer model. The incorporation of angle rotation using ReDRE\nenhances the characterization of time series data within a Transformer, leading\nto improved fraud detection by better capturing temporal dependencies and event\nrelationships.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u5728RoFormer\u6a21\u578b\u4e2d\u52a0\u5165Relative Distance Rotating Encoding (ReDRE)\u7684\u65b0\u65b9\u6cd5\u7528\u4e8e\u4ea4\u6613\u6b3a\u8bc8\u68c0\u6d4b\uff0c\u53ef\u63d0\u5347\u6b3a\u8bc8\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u6b3a\u8bc8\u68c0\u6d4b\u662f\u91d1\u878d\u7cfb\u7edf\u91cd\u8981\u6311\u6218\uff0c\u652f\u4ed8\u7f51\u5173\u516c\u53f8\u9700\u63d0\u5347\u4ea4\u6613\u6388\u6743\u7387\u5e76\u964d\u4f4e\u6b3a\u8bc8\uff0c\u9700\u4e0d\u65ad\u7814\u7a76\u65b0\u7684\u6b3a\u8bc8\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5728RoFormer\u6a21\u578b\u4e2d\u52a0\u5165Relative Distance Rotating Encoding (ReDRE)\u3002", "result": "\u901a\u8fc7ReDRE\u7684\u89d2\u5ea6\u65cb\u8f6c\u589e\u5f3a\u4e86Transformer\u4e2d\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u7279\u5f81\uff0c\u80fd\u66f4\u597d\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u548c\u4e8b\u4ef6\u5173\u7cfb\u3002", "conclusion": "\u8be5\u65b0\u65b9\u6cd5\u53ef\u6539\u5584\u6b3a\u8bc8\u68c0\u6d4b\u6548\u679c\u3002"}}
{"id": "2507.08806", "pdf": "https://arxiv.org/pdf/2507.08806", "abs": "https://arxiv.org/abs/2507.08806", "authors": ["Daewon Choi", "Jimin Lee", "Jihoon Tack", "Woomin Song", "Saket Dingliwal", "Sai Muralidhar Jayanthi", "Bhavana Ganesh", "Jinwoo Shin", "Aram Galstyan", "Sravan Babu Bodapati"], "title": "Think Clearly: Improving Reasoning via Redundant Token Pruning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent large language models have shown promising capabilities in long-form\nreasoning, following structured chains of thought before arriving at a final\nanswer. However, we observe that these reasoning paths tend to include\nsubstantial redundancy; analyzing attention patterns reveals that attention\nscores are widely scattered, particularly incorrect answers exhibit greater\nattention sparsity. In this paper, we demonstrate that deliberately removing\nthis redundancy in the reasoning process significantly improves performance\nthrough clear thinking, i.e., removing distraction. Specifically, we\nsystematically identify reasoning redundancy by measuring token-level attention\nscores to a special end-of-thinking token, which is appended to an explicit\ninstruction inserted to conclude each intermediate reasoning step. Furthermore,\nwe propose structure-aware pruning that prioritizes removing tokens in\nlow-contributing reasoning chunks over individual tokens. After evicting\nredundant tokens, we remove the injected end-of-thinking instruction, then\nresume the reasoning generation. We demonstrate that our method significantly\nimproves overall accuracy across reasoning-intensive benchmarks without any\ntraining involved. In particular, our method shows strong performance on\nchallenging mathematical competition benchmarks such as AIME and AMC, where\nreasoning redundancy is more prevalent.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8def\u5f84\u5b58\u5728\u5197\u4f59\uff0c\u63d0\u51fa\u901a\u8fc7\u6d4b\u91cf\u6ce8\u610f\u529b\u5206\u6570\u8bc6\u522b\u5197\u4f59\u5e76\u8fdb\u884c\u7ed3\u6784\u611f\u77e5\u526a\u679d\uff0c\u65e0\u9700\u8bad\u7ec3\u5c31\u63d0\u9ad8\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8def\u5f84\u5b58\u5728\u5927\u91cf\u5197\u4f59\uff0c\u5f71\u54cd\u6027\u80fd\uff0c\u9700\u53bb\u9664\u5197\u4f59\u63d0\u5347\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u5bf9\u7279\u6b8a\u601d\u8003\u7ed3\u675f\u6807\u8bb0\u7684\u8bcd\u5143\u7ea7\u6ce8\u610f\u529b\u5206\u6570\u8bc6\u522b\u63a8\u7406\u5197\u4f59\uff0c\u91c7\u7528\u7ed3\u6784\u611f\u77e5\u526a\u679d\u4f18\u5148\u79fb\u9664\u4f4e\u8d21\u732e\u63a8\u7406\u5757\u4e2d\u7684\u8bcd\u5143\uff0c\u79fb\u9664\u5197\u4f59\u8bcd\u5143\u540e\u53bb\u6389\u63d2\u5165\u7684\u6307\u4ee4\u7ee7\u7eed\u63a8\u7406\u751f\u6210\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u6574\u4f53\u51c6\u786e\u7387\uff0c\u5728AIME\u548cAMC\u7b49\u6570\u5b66\u7ade\u8d5b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u523b\u610f\u53bb\u9664\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5197\u4f59\u80fd\u901a\u8fc7\u6e05\u6670\u601d\u8003\u63d0\u9ad8\u6027\u80fd\uff0c\u65e0\u9700\u8bad\u7ec3\u53ef\u63d0\u5347\u63a8\u7406\u51c6\u786e\u7387\u3002"}}
{"id": "2507.08880", "pdf": "https://arxiv.org/pdf/2507.08880", "abs": "https://arxiv.org/abs/2507.08880", "authors": ["Qifeng Tang", "Yain-Whar Si"], "title": "Central Bank Digital Currencies: A Survey", "categories": ["econ.GN", "cs.CE", "cs.CY", "cs.ET", "q-fin.EC", "68M14", "A.1; C.5"], "comment": "49 pages, 6 figures", "summary": "With the advancement of digital payment technologies, central banks worldwide\nhave increasingly begun to explore the implementation of Central Bank Digital\nCurrencies (CBDCs). This paper presents a comprehensive review of the latest\ndevelopments in CBDC system design and implementation. By analyzing 135\nresearch papers published between 2018 and 2025, the study provides an in-depth\nexamination of CBDC design taxonomy and ecosystem frameworks. Grounded in the\nCBDC Design Pyramid, the paper refines and expands key architectural elements\nby thoroughly investigating innovations in ledger technologies, the selection\nof consensus mechanisms, and challenges associated with offline payments and\ndigital wallet integration. Furthermore, it conceptualizes a CBDC ecosystem. A\ndetailed comparative analysis of 26 existing CBDC systems is conducted across\nfour dimensions: system architecture, ledger technology, access model, and\napplication domain. The findings reveal that the most common configuration\nconsists of a two-tier architecture, distributed ledger technology (DLT), and a\ntoken-based access model. However, no dominant trend has emerged regarding\napplication domains. Notably, recent research shows a growing focus on\nleveraging CBDCs for cross-border payments to resolve inefficiencies and\nstructural delays in current systems. Finally, the paper offers several\nforward-looking recommendations for future research.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u56de\u987eCBDC\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u5b9e\u65bd\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5206\u6790\u76f8\u5173\u7814\u7a76\u8bba\u6587\uff0c\u6784\u5efa\u751f\u6001\u7cfb\u7edf\u6982\u5ff5\uff0c\u5bf9\u6bd4\u73b0\u6709\u7cfb\u7edf\uff0c\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u652f\u4ed8\u6280\u672f\u53d1\u5c55\uff0c\u5404\u56fd\u592e\u884c\u63a2\u7d22CBDC\u5b9e\u65bd\uff0c\u9700\u5bf9CBDC\u7cfb\u7edf\u8bbe\u8ba1\u548c\u5b9e\u65bd\u8fdb\u884c\u5168\u9762\u7814\u7a76\u3002", "method": "\u5206\u67902018 - 2025\u5e74135\u7bc7\u7814\u7a76\u8bba\u6587\uff0c\u57fa\u4e8eCBDC\u8bbe\u8ba1\u91d1\u5b57\u5854\u7ec6\u5316\u67b6\u6784\u5143\u7d20\uff0c\u5bf926\u4e2a\u73b0\u6709CBDC\u7cfb\u7edf\u8fdb\u884c\u56db\u7ef4\u5ea6\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u6700\u5e38\u89c1\u914d\u7f6e\u4e3a\u4e24\u5c42\u67b6\u6784\u3001\u5206\u5e03\u5f0f\u8d26\u672c\u6280\u672f\u548c\u57fa\u4e8e\u4ee3\u5e01\u7684\u8bbf\u95ee\u6a21\u578b\uff0c\u5e94\u7528\u9886\u57df\u65e0\u4e3b\u5bfc\u8d8b\u52bf\uff0c\u8fd1\u671f\u7814\u7a76\u5173\u6ce8CBDC\u7528\u4e8e\u8de8\u5883\u652f\u4ed8\u3002", "conclusion": "\u8bba\u6587\u5bf9CBDC\u8bbe\u8ba1\u548c\u5b9e\u65bd\u8fdb\u884c\u4e86\u5168\u9762\u7814\u7a76\uff0c\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u7684\u524d\u77bb\u6027\u5efa\u8bae\u3002"}}
{"id": "2507.08836", "pdf": "https://arxiv.org/pdf/2507.08836", "abs": "https://arxiv.org/abs/2507.08836", "authors": ["Damien Fovet", "Shashank Chamoli", "Sarah Oury", "Srishti Singhal"], "title": "Accuracy and Consumption analysis from a compressed model by CompactifAI from Multiverse Computing", "categories": ["cs.LG", "cs.PF"], "comment": null, "summary": "This study evaluates the performance of a compression method, called\nCompactifAI, developed by Multiverse Computing, applied to the large language\nmodel Llama 3.1 8B\\cite{llama}. The evaluation focused on model efficiency (in\nterms of energy consumption) and accuracy using respectively the frameworks\nCodecarbon\\cite{codecarbon} and Ragas\\cite{ragas}. A comparison was performed\nbetween the model compressed with\nCompactifAI\\cite{compactifai}\\cite{compactifai2} and its full-size version. Our\nfindings reveal that the compressed model using CompactifAI not only\nsignificantly reduced the computational resources but also maintained the model\naccuracy, making the model more efficient, scalable and cost-effective.", "AI": {"tldr": "\u8bc4\u4f30CompactifAI\u538b\u7f29\u65b9\u6cd5\u5bf9Llama 3.1 8B\u6a21\u578b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u538b\u7f29\u6a21\u578b\u53ef\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u5e76\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u8bc4\u4f30CompactifAI\u538b\u7f29\u65b9\u6cd5\u5e94\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578bLlama 3.1 8B\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528Codecarbon\u548cRagas\u6846\u67b6\u5206\u522b\u8bc4\u4f30\u6a21\u578b\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u4e0e\u5168\u5c3a\u5bf8\u6a21\u578b\u5bf9\u6bd4\u3002", "result": "\u4f7f\u7528CompactifAI\u7684\u538b\u7f29\u6a21\u578b\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e14\u4fdd\u6301\u4e86\u6a21\u578b\u51c6\u786e\u6027\u3002", "conclusion": "\u538b\u7f29\u6a21\u578b\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u5177\u6709\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2507.09004", "pdf": "https://arxiv.org/pdf/2507.09004", "abs": "https://arxiv.org/abs/2507.09004", "authors": ["Domagoj Demeterfi", "Kathrin Glau", "Linus Wunderlich"], "title": "Function approximations for counterparty credit exposure calculations", "categories": ["q-fin.CP"], "comment": null, "summary": "The challenge to measure exposures regularly forces financial institutions\ninto a choice between an overwhelming computational burden or\noversimplification of risk. To resolve this unsettling dilemma, we\nsystematically investigate replacing frequently called derivative pricers by\nfunction approximations covering all practically relevant exposure measures,\nincluding quantiles. We prove error bounds for exposure measures in terms of\nthe $L^p$ norm, $1 \\leq p < \\infty$, and for the uniform norm. To fully exploit\nthese results, we employ the Chebyshev interpolation and show exponential\nconvergence of the resulting exposure calculations. As our main result we\nderive probabilistic and finite sample error bounds under mild conditions\nincluding the natural case of unbounded risk factors. We derive an asymptotic\nefficiency gain scaling with $n^{1/2-\\varepsilon}$ for any $\\varepsilon>0$ with\n$n$ the number of simulations. Our numerical experiments cover callable,\nbarrier, stochastic volatility and jump features. Using 10\\,000 simulations, we\nconsistently observe significant run-time reductions in all cases with speed-up\nfactors up to 230, and an average speed-up of 87. We also present an adaptive\nchoice of the interpolation degree. Finally, numerical examples relying on the\napproximation of Greeks highlight the merit of the method beyond the presented\ntheory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7528\u51fd\u6570\u8fd1\u4f3c\u66ff\u4ee3\u884d\u751f\u54c1\u5b9a\u4ef7\u5668\u4ee5\u89e3\u51b3\u91d1\u878d\u673a\u6784\u8861\u91cf\u98ce\u9669\u65f6\u8ba1\u7b97\u8d1f\u62c5\u548c\u7b80\u5316\u98ce\u9669\u7684\u4e24\u96be\u95ee\u9898\uff0c\u7ed9\u51fa\u8bef\u5dee\u754c\uff0c\u8bc1\u660e\u6536\u655b\u6027\uff0c\u6709\u6e10\u8fd1\u6548\u7387\u589e\u76ca\uff0c\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u51cf\u5c11\u8fd0\u884c\u65f6\u95f4\u3002", "motivation": "\u91d1\u878d\u673a\u6784\u5728\u5b9a\u671f\u8861\u91cf\u98ce\u9669\u655e\u53e3\u65f6\u9762\u4e34\u8ba1\u7b97\u8d1f\u62c5\u8fc7\u91cd\u6216\u98ce\u9669\u7b80\u5316\u8fc7\u5ea6\u7684\u4e24\u96be\u56f0\u5883\uff0c\u9700\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u5730\u7528\u51fd\u6570\u8fd1\u4f3c\u66ff\u4ee3\u9891\u7e41\u8c03\u7528\u7684\u884d\u751f\u54c1\u5b9a\u4ef7\u5668\uff0c\u91c7\u7528Chebyshev\u63d2\u503c\uff0c\u63a8\u5bfc\u8bef\u5dee\u754c\u3002", "result": "\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u5f97\u5230\u6982\u7387\u548c\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\uff0c\u6709\u6e10\u8fd1\u6548\u7387\u589e\u76ca\uff0c\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u8fd0\u884c\u65f6\u95f4\u663e\u8457\u51cf\u5c11\uff0c\u52a0\u901f\u56e0\u5b50\u6700\u9ad8\u8fbe230\uff0c\u5e73\u5747\u4e3a87\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u91d1\u878d\u673a\u6784\u8861\u91cf\u98ce\u9669\u655e\u53e3\u7684\u56f0\u5883\uff0c\u4e14\u81ea\u9002\u5e94\u9009\u62e9\u63d2\u503c\u5ea6\u53ca\u5bf9Greeks\u7684\u8fd1\u4f3c\u4f53\u73b0\u4e86\u65b9\u6cd5\u7684\u4f18\u70b9\u3002"}}
{"id": "2507.09377", "pdf": "https://arxiv.org/pdf/2507.09377", "abs": "https://arxiv.org/abs/2507.09377", "authors": ["Mumuksh Tayal"], "title": "A Fixed Parameter Tractable Approach for Solving the Vertex Cover Problem in Polynomial Time Complexity", "categories": ["cs.DS"], "comment": "10 pages, 2 figures, 1 table. Accepted at STOC 2024 Workshop on TCS\n  for All", "summary": "The Minimum Vertex Cover problem, a classical NP-complete problem, presents\nsignificant challenges for exact solution on large graphs. Fixed-Parameter\nTractability (FPT) offers a powerful paradigm to address such problems by\nexploiting a parameter of the input, typically related to the size of the\ndesired solution. This paper presents an implementation and empirical\nevaluation of an FPT algorithm for the Minimum Vertex Cover problem\nparameterized by the size of the vertex cover, $k$. The algorithm utilizes a\nbranching strategy based on selecting adjacent vertices and recursively solving\nsubproblems on a reduced graph. We describe the algorithmic approach,\nimplementation details in Python, and present experimental results comparing\nits performance against the SageMath computational system. The results\ndemonstrate that the FPT implementation achieves significant performance\nimprovements for instances with large numbers of vertices ($n$) but relatively\nsmall values of the parameter ($k$), aligning with theoretical FPT complexity\nguarantees. We also discuss potential optimizations that could further improve\nthe algorithm's performance, particularly concerning the branching factor.", "AI": {"tldr": "\u672c\u6587\u5b9e\u73b0\u5e76\u8bc4\u4f30\u4e86\u4ee5\u9876\u70b9\u8986\u76d6\u5927\u5c0fk\u4e3a\u53c2\u6570\u7684\u6700\u5c0f\u9876\u70b9\u8986\u76d6\u95ee\u9898\u7684FPT\u7b97\u6cd5\uff0c\u5bf9\u6bd4SageMath\u7cfb\u7edf\uff0c\u8be5\u7b97\u6cd5\u5728\u5927\u9876\u70b9\u6570\u3001\u5c0f\u53c2\u6570k\u5b9e\u4f8b\u4e0a\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u6700\u5c0f\u9876\u70b9\u8986\u76d6\u95ee\u9898\u662f\u7ecf\u5178NP\u5b8c\u5168\u95ee\u9898\uff0c\u5728\u5927\u56fe\u4e0a\u7cbe\u786e\u6c42\u89e3\u56f0\u96be\uff0cFPT\u8303\u5f0f\u53ef\u5229\u7528\u8f93\u5165\u53c2\u6570\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u9009\u62e9\u76f8\u90bb\u9876\u70b9\u7684\u5206\u652f\u7b56\u7565\uff0c\u9012\u5f52\u6c42\u89e3\u7ea6\u7b80\u56fe\u4e0a\u7684\u5b50\u95ee\u9898\uff0c\u5e76\u5728Python\u4e2d\u5b9e\u73b0\u7b97\u6cd5\u3002", "result": "FPT\u5b9e\u73b0\u5bf9\u4e8e\u9876\u70b9\u6570\u591a\u4f46\u53c2\u6570k\u5c0f\u7684\u5b9e\u4f8b\uff0c\u6027\u80fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u7b26\u5408\u7406\u8bbaFPT\u590d\u6742\u5ea6\u4fdd\u8bc1\u3002", "conclusion": "FPT\u7b97\u6cd5\u5728\u7279\u5b9a\u5b9e\u4f8b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u53ef\u901a\u8fc7\u4f18\u5316\u5206\u652f\u56e0\u5b50\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.08943", "pdf": "https://arxiv.org/pdf/2507.08943", "abs": "https://arxiv.org/abs/2507.08943", "authors": ["Pedro Lopes", "Paola Accioly", "Paulo Borba", "Vitor Menezes"], "title": "Choosing the Right Git Workflow: A Comparative Analysis of Trunk-based vs. Branch-based Approaches", "categories": ["cs.SE", "D.2.7"], "comment": "11 pages with 3 figures", "summary": "Git has become one of the most widely used version control systems today.\nAmong its distinguishing features, its ability to easily and quickly create\nbranches stands out, allowing teams to customize their workflows. In this\ncontext, various formats of collaborative development workflows using Git have\nemerged and gained popularity among software engineers. We can categorize such\nworkflows into two main types: branch-based workflows and trunk-based\nworkflows. Branch-based workflows typically define a set of remote branches\nwith well-defined objectives, such as feature branches, a branch for feature\nintegration, and a main branch. The goal is to migrate changes from the most\nisolated branch to the main one shared by all as the code matures. In this\ncategory, GitFlow stands out as the most popular example. In contrast,\ntrunk-based workflows have a single remote branch where developers integrate\ntheir changes directly. In this range of options, choosing a workflow that\nmaximizes team productivity while promoting software quality becomes a\nnon-trivial task. Despite discussions on forums, social networks, and blogs,\nfew scientific articles have explored this topic. In this work, we provide\nevidence on how Brazilian developers work with Git workflows and what factors\nfavor or hinder the use of each model. To this end, we conducted\nsemi-structured interviews and a survey with software developers. Our results\nindicate that trunk-based development favors fast-paced projects with\nexperienced and smaller teams, while branch-based development suits less\nexperienced and larger teams better, despite posing management challenges.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5df4\u897f\u5f00\u53d1\u8005\u4f7f\u7528Git\u5de5\u4f5c\u6d41\u7684\u60c5\u51b5\uff0c\u901a\u8fc7\u8bbf\u8c08\u548c\u8c03\u67e5\u53d1\u73b0\u57fa\u4e8e\u4e3b\u5e72\u7684\u5f00\u53d1\u9002\u5408\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5c0f\u56e2\u961f\u5feb\u8282\u594f\u9879\u76ee\uff0c\u57fa\u4e8e\u5206\u652f\u7684\u5f00\u53d1\u9002\u5408\u7ecf\u9a8c\u4e0d\u8db3\u7684\u5927\u56e2\u961f\u3002", "motivation": "Git\u5de5\u4f5c\u6d41\u9009\u62e9\u5f71\u54cd\u56e2\u961f\u751f\u4ea7\u529b\u548c\u8f6f\u4ef6\u8d28\u91cf\uff0c\u4f46\u76f8\u5173\u79d1\u5b66\u7814\u7a76\u8f83\u5c11\uff0c\u9700\u4e86\u89e3\u5df4\u897f\u5f00\u53d1\u8005\u4f7f\u7528\u60c5\u51b5\u53ca\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u548c\u8c03\u67e5\u3002", "result": "\u57fa\u4e8e\u4e3b\u5e72\u7684\u5f00\u53d1\u6709\u5229\u4e8e\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5c0f\u56e2\u961f\u5feb\u8282\u594f\u9879\u76ee\uff0c\u57fa\u4e8e\u5206\u652f\u7684\u5f00\u53d1\u66f4\u9002\u5408\u7ecf\u9a8c\u4e0d\u8db3\u7684\u5927\u56e2\u961f\uff0c\u4f46\u5b58\u5728\u7ba1\u7406\u6311\u6218\u3002", "conclusion": "\u4e0d\u540c\u7c7b\u578b\u56e2\u961f\u548c\u9879\u76ee\u5e94\u6839\u636e\u81ea\u8eab\u60c5\u51b5\u9009\u62e9\u5408\u9002\u7684Git\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2507.08828", "pdf": "https://arxiv.org/pdf/2507.08828", "abs": "https://arxiv.org/abs/2507.08828", "authors": ["Tarek Berghout"], "title": "Recurrent Expansion: A Pathway Toward the Next Generation of Deep Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper introduces Recurrent Expansion (RE) as a new learning paradigm\nthat advances beyond conventional Machine Learning (ML) and Deep Learning (DL).\nWhile DL focuses on learning from static data representations, RE proposes an\nadditional dimension: learning from the evolving behavior of models themselves.\nRE emphasizes multiple mappings of data through identical deep architectures\nand analyzes their internal representations (i.e., feature maps) in conjunction\nwith observed performance signals such as loss. By incorporating these\nbehavioral traces, RE enables iterative self-improvement, allowing each model\nversion to gain insight from its predecessors. The framework is extended\nthrough Multiverse RE (MVRE), which aggregates signals from parallel model\ninstances, and further through Heterogeneous MVRE (HMVRE), where models of\nvarying architectures contribute diverse perspectives. A scalable and adaptive\nvariant, Sc-HMVRE, introduces selective mechanisms and scale diversity for\nreal-world deployment. Altogether, RE presents a shift in DL: from purely\nrepresentational learning to behavior-aware, self-evolving systems. It lays the\ngroundwork for a new class of intelligent models capable of reasoning over\ntheir own learning dynamics, offering a path toward scalable, introspective,\nand adaptive artificial intelligence. A simple code example to support\nbeginners in running their own experiments is provided in Code Availability\nSection of this paper.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5faa\u73af\u6269\u5c55\uff08RE\uff09\u8fd9\u4e00\u5b66\u4e60\u8303\u5f0f\uff0c\u8d85\u8d8a\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u80fd\u4ece\u6a21\u578b\u81ea\u8eab\u884c\u4e3a\u5b66\u4e60\uff0c\u8fd8\u6709\u591a\u79cd\u6269\u5c55\u53d8\u4f53\uff0c\u4e3a\u65b0\u578b\u667a\u80fd\u6a21\u578b\u5960\u5b9a\u57fa\u7840\u5e76\u63d0\u4f9b\u4ee3\u7801\u793a\u4f8b\u3002", "motivation": "\u7a81\u7834\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4ec5\u4ece\u9759\u6001\u6570\u636e\u8868\u793a\u5b66\u4e60\u7684\u5c40\u9650\uff0c\u63d0\u51fa\u65b0\u7684\u5b66\u4e60\u7ef4\u5ea6\u3002", "method": "\u63d0\u51faRE\u8303\u5f0f\uff0c\u5f3a\u8c03\u901a\u8fc7\u76f8\u540c\u6df1\u5ea6\u67b6\u6784\u5bf9\u6570\u636e\u8fdb\u884c\u591a\u6b21\u6620\u5c04\u5e76\u7ed3\u5408\u6027\u80fd\u4fe1\u53f7\u5206\u6790\u5185\u90e8\u8868\u793a\uff1b\u6269\u5c55\u51faMVRE\u3001HMVRE\u548cSc - HMVRE\u3002", "result": "RE\u5b9e\u73b0\u4e86\u6a21\u578b\u7684\u8fed\u4ee3\u81ea\u6211\u63d0\u5347\uff0c\u4ece\u5355\u7eaf\u7684\u8868\u5f81\u5b66\u4e60\u8f6c\u5411\u884c\u4e3a\u611f\u77e5\u3001\u81ea\u6211\u8fdb\u5316\u7684\u7cfb\u7edf\u3002", "conclusion": "RE\u4e3a\u65b0\u578b\u667a\u80fd\u6a21\u578b\u5960\u5b9a\u57fa\u7840\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u5185\u7701\u548c\u81ea\u9002\u5e94\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u8def\u5f84\u3002"}}
{"id": "2507.10019", "pdf": "https://arxiv.org/pdf/2507.10019", "abs": "https://arxiv.org/abs/2507.10019", "authors": ["Pranav Joshi"], "title": "Sampling-Based Estimation of Jaccard Containment and Similarity", "categories": ["stat.CO", "cs.DB", "stat.ML"], "comment": null, "summary": "This paper addresses the problem of estimating the containment and similarity\nbetween two sets using only random samples from each set, without relying on\nsketches or full data access. The study introduces a binomial model for\npredicting the overlap between samples, demonstrating that it is both accurate\nand practical when sample sizes are small compared to the original sets. The\npaper compares this model to previous approaches and shows that it provides\nbetter estimates under the considered conditions. It also analyzes the\nstatistical properties of the estimator, including error bounds and sample size\nrequirements needed to achieve a desired level of accuracy and confidence. The\nframework is extended to estimate set similarity, and the paper provides\nguidance for applying these methods in large scale data systems where only\npartial or sampled data is available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u968f\u673a\u6837\u672c\u4f30\u8ba1\u96c6\u5408\u5305\u542b\u548c\u76f8\u4f3c\u5ea6\u7684\u65b9\u6cd5\uff0c\u4ecb\u7ecd\u4e8c\u9879\u5f0f\u6a21\u578b\uff0c\u4e0e\u5148\u524d\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u5206\u6790\u4f30\u8ba1\u5668\u6027\u8d28\uff0c\u6269\u5c55\u5230\u96c6\u5408\u76f8\u4f3c\u5ea6\u4f30\u8ba1\u5e76\u7ed9\u51fa\u5728\u5927\u6570\u636e\u7cfb\u7edf\u5e94\u7528\u6307\u5bfc\u3002", "motivation": "\u89e3\u51b3\u4ec5\u4f7f\u7528\u968f\u673a\u6837\u672c\u4f30\u8ba1\u4e24\u4e2a\u96c6\u5408\u7684\u5305\u542b\u548c\u76f8\u4f3c\u5ea6\u95ee\u9898\uff0c\u4e14\u4e0d\u4f9d\u8d56\u8349\u56fe\u6216\u5168\u91cf\u6570\u636e\u8bbf\u95ee\u3002", "method": "\u5f15\u5165\u4e8c\u9879\u5f0f\u6a21\u578b\u9884\u6d4b\u6837\u672c\u91cd\u53e0\u60c5\u51b5\uff0c\u5e76\u4e0e\u5148\u524d\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u5206\u6790\u4f30\u8ba1\u5668\u7684\u7edf\u8ba1\u6027\u8d28\u3002", "result": "\u8be5\u6a21\u578b\u5728\u6837\u672c\u91cf\u76f8\u5bf9\u539f\u96c6\u5408\u8f83\u5c0f\u65f6\u51c6\u786e\u5b9e\u7528\uff0c\u5728\u8003\u8651\u6761\u4ef6\u4e0b\u6bd4\u5148\u524d\u65b9\u6cd5\u4f30\u8ba1\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u96c6\u5408\u76f8\u4f3c\u5ea6\u4f30\u8ba1\uff0c\u80fd\u5728\u4ec5\u63d0\u4f9b\u90e8\u5206\u6216\u62bd\u6837\u6570\u636e\u7684\u5927\u89c4\u6a21\u6570\u636e\u7cfb\u7edf\u4e2d\u5e94\u7528\u3002"}}
{"id": "2507.09347", "pdf": "https://arxiv.org/pdf/2507.09347", "abs": "https://arxiv.org/abs/2507.09347", "authors": ["Ivan Letteri"], "title": "A Framework for Predictive Directional Trading Based on Volatility and Causal Inference", "categories": ["q-fin.ST", "cs.AI", "stat.ML"], "comment": null, "summary": "Purpose: This study introduces a novel framework for identifying and\nexploiting predictive lead-lag relationships in financial markets. We propose\nan integrated approach that combines advanced statistical methodologies with\nmachine learning models to enhance the identification and exploitation of\npredictive relationships between equities. Methods: We employed a Gaussian\nMixture Model (GMM) to cluster nine prominent stocks based on their mid-range\nhistorical volatility profiles over a three-year period. From the resulting\nclusters, we constructed a multi-stage causal inference pipeline, incorporating\nthe Granger Causality Test (GCT), a customised Peter-Clark Momentary\nConditional Independence (PCMCI) test, and Effective Transfer Entropy (ETE) to\nidentify robust, predictive linkages. Subsequently, Dynamic Time Warping (DTW)\nand a K-Nearest Neighbours (KNN) classifier were utilised to determine the\noptimal time lag for trade execution. The resulting strategy was rigorously\nbacktested. Results: The proposed volatility-based trading strategy, tested\nfrom 8 June 2023 to 12 August 2023, demonstrated substantial efficacy. The\nportfolio yielded a total return of 15.38%, significantly outperforming the\n10.39% return of a comparative Buy-and-Hold strategy. Key performance metrics,\nincluding a Sharpe Ratio up to 2.17 and a win rate up to 100% for certain\npairs, confirmed the strategy's viability. Conclusion: This research\ncontributes a systematic and robust methodology for identifying profitable\ntrading opportunities derived from volatility-based causal relationships. The\nfindings have significant implications for both academic research in financial\nmodelling and the practical application of algorithmic trading, offering a\nstructured approach to developing resilient, data-driven strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u8bc6\u522b\u548c\u5229\u7528\u91d1\u878d\u5e02\u573a\u9884\u6d4b\u6027\u9886\u5148 - \u6ede\u540e\u5173\u7cfb\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u7edf\u8ba1\u65b9\u6cd5\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7ecf\u6d4b\u8bd5\u7b56\u7565\u6548\u679c\u663e\u8457\uff0c\u4e3a\u91d1\u878d\u5efa\u6a21\u548c\u7b97\u6cd5\u4ea4\u6613\u63d0\u4f9b\u65b9\u6cd5\u3002", "motivation": "\u5f15\u5165\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u589e\u5f3a\u5bf9\u80a1\u7968\u95f4\u9884\u6d4b\u5173\u7cfb\u7684\u8bc6\u522b\u548c\u5229\u7528\u3002", "method": "\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u805a\u7c7b\u80a1\u7968\uff0c\u6784\u5efa\u591a\u9636\u6bb5\u56e0\u679c\u63a8\u65ad\u7ba1\u9053\u8bc6\u522b\u5173\u8054\uff0c\u7528\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u548cK\u8fd1\u90bb\u5206\u7c7b\u5668\u786e\u5b9a\u4ea4\u6613\u6267\u884c\u7684\u6700\u4f73\u65f6\u95f4\u6ede\u540e\uff0c\u5e76\u8fdb\u884c\u56de\u6d4b\u3002", "result": "\u57fa\u4e8e\u6ce2\u52a8\u7387\u7684\u4ea4\u6613\u7b56\u7565\u5728\u6d4b\u8bd5\u671f\u8868\u73b0\u826f\u597d\uff0c\u6295\u8d44\u7ec4\u5408\u603b\u56de\u62a515.38%\uff0c\u4f18\u4e8e\u4e70\u5165\u6301\u6709\u7b56\u7565\uff0c\u5173\u952e\u6307\u6807\u8bc1\u660e\u7b56\u7565\u53ef\u884c\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u8bc6\u522b\u76c8\u5229\u4ea4\u6613\u673a\u4f1a\u7684\u7cfb\u7edf\u65b9\u6cd5\uff0c\u5bf9\u91d1\u878d\u5efa\u6a21\u5b66\u672f\u7814\u7a76\u548c\u7b97\u6cd5\u4ea4\u6613\u5b9e\u9645\u5e94\u7528\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.08906", "pdf": "https://arxiv.org/pdf/2507.08906", "abs": "https://arxiv.org/abs/2507.08906", "authors": ["Nathan Doum\u00e8che"], "title": "Physics-informed machine learning: A mathematical framework with applications to time series forecasting", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH", "62G05, 68Q32, 62P30, 35Q62, 68T01", "G.3; G.4; I.2.6; I.5.1"], "comment": "Doctoral thesis, Sorbonne University. 286 pages", "summary": "Physics-informed machine learning (PIML) is an emerging framework that\nintegrates physical knowledge into machine learning models. This physical prior\noften takes the form of a partial differential equation (PDE) system that the\nregression function must satisfy. In the first part of this dissertation, we\nanalyze the statistical properties of PIML methods. In particular, we study the\nproperties of physics-informed neural networks (PINNs) in terms of\napproximation, consistency, overfitting, and convergence. We then show how PIML\nproblems can be framed as kernel methods, making it possible to apply the tools\nof kernel ridge regression to better understand their behavior. In addition, we\nuse this kernel formulation to develop novel physics-informed algorithms and\nimplement them efficiently on GPUs. The second part explores industrial\napplications in forecasting energy signals during atypical periods. We present\nresults from the Smarter Mobility challenge on electric vehicle charging\noccupancy and examine the impact of mobility on electricity demand. Finally, we\nintroduce a physics-constrained framework for designing and enforcing\nconstraints in time series, applying it to load forecasting and tourism\nforecasting in various countries.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\uff08PIML\uff09\u65b9\u6cd5\u7edf\u8ba1\u7279\u6027\uff0c\u7528\u6838\u65b9\u6cd5\u7814\u7a76\u5176\u884c\u4e3a\u3001\u5f00\u53d1\u7b97\u6cd5\uff0c\u8fd8\u63a2\u7d22\u80fd\u6e90\u4fe1\u53f7\u9884\u6d4b\u5de5\u4e1a\u5e94\u7528\u5e76\u5f15\u5165\u65f6\u95f4\u5e8f\u5217\u7269\u7406\u7ea6\u675f\u6846\u67b6\u3002", "motivation": "\u6df1\u5165\u7406\u89e3PIML\u65b9\u6cd5\u7279\u6027\u5e76\u62d3\u5c55\u5176\u5728\u5de5\u4e1a\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5206\u6790PIML\u65b9\u6cd5\u7edf\u8ba1\u5c5e\u6027\uff0c\u5c06PIML\u95ee\u9898\u8f6c\u5316\u4e3a\u6838\u65b9\u6cd5\uff0c\u7528\u6838\u5cad\u56de\u5f52\u5de5\u5177\u7814\u7a76\uff0c\u5f00\u53d1\u65b0\u7b97\u6cd5\u5e76\u5728GPU\u5b9e\u73b0\uff1b\u5e94\u7528\u4e8e\u80fd\u6e90\u4fe1\u53f7\u9884\u6d4b\u7b49\u5de5\u4e1a\u573a\u666f\u3002", "result": "\u5206\u6790\u4e86PINNs\u5728\u903c\u8fd1\u3001\u4e00\u81f4\u6027\u7b49\u65b9\u9762\u7279\u6027\uff1b\u5728\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u5360\u7528\u548c\u7535\u529b\u9700\u6c42\u7b49\u9884\u6d4b\u6709\u6210\u679c\uff1b\u5f15\u5165\u65f6\u95f4\u5e8f\u5217\u7269\u7406\u7ea6\u675f\u6846\u67b6\u3002", "conclusion": "PIML\u65b9\u6cd5\u6709\u826f\u597d\u7edf\u8ba1\u7279\u6027\uff0c\u53ef\u501f\u52a9\u6838\u65b9\u6cd5\u7814\u7a76\uff0c\u5728\u80fd\u6e90\u9884\u6d4b\u7b49\u5de5\u4e1a\u5e94\u7528\u6709\u6210\u6548\uff0c\u7269\u7406\u7ea6\u675f\u6846\u67b6\u53ef\u7528\u4e8e\u591a\u9886\u57df\u9884\u6d4b\u3002"}}
{"id": "2507.09734", "pdf": "https://arxiv.org/pdf/2507.09734", "abs": "https://arxiv.org/abs/2507.09734", "authors": ["Przemys\u0142aw Rola"], "title": "Boltzmann Price: Toward Understanding the Fair Price in High-Frequency Markets", "categories": ["q-fin.TR"], "comment": null, "summary": "In this paper, we introduce a parametrized family of prices derived from the\nMaximum Entropy Principle. The price is obtained from the distribution that\nminimizes bias, given the bid and ask volume imbalance at the top of the order\nbook. Under specific parameter choices, it closely approximates the mid-price\nor the weighted mid-price. Using probabilities of bid and ask states, we\npropose a model of price dynamics in which both drift and volatility are driven\nby volume imbalance. Compared to standard models like Bachelier or Geometric\nBrownian Motion with constant volatility, our model can generate higher\nkurtosis and heavy-tailed distributions. Additionally, the drift term naturally\nemerges as a consequence of the order book imbalance. We validate the model\nthrough simulation and demonstrate its fit to historical equity data. The model\nprovides a theoretical framework, integrating price, volume imbalance, and\nspread.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u57fa\u4e8e\u6700\u5927\u71b5\u539f\u7406\u7684\u53c2\u6570\u5316\u4ef7\u683c\u65cf\uff0c\u63d0\u51fa\u4ef7\u683c\u52a8\u6001\u6a21\u578b\uff0c\u80fd\u4ea7\u751f\u66f4\u9ad8\u5cf0\u5ea6\u548c\u91cd\u5c3e\u5206\u5e03\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u4e0e\u5386\u53f2\u6570\u636e\u62df\u5408\u826f\u597d\u3002", "motivation": "\u6784\u5efa\u7ed3\u5408\u4ef7\u683c\u3001\u6210\u4ea4\u91cf\u4e0d\u5e73\u8861\u548c\u4e70\u5356\u4ef7\u5dee\u7684\u7406\u8bba\u6846\u67b6\uff0c\u6539\u8fdb\u6807\u51c6\u4ef7\u683c\u52a8\u6001\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u6700\u5927\u71b5\u539f\u7406\u5f97\u5230\u4ef7\u683c\uff0c\u5229\u7528\u4e70\u5356\u72b6\u6001\u6982\u7387\u6784\u5efa\u4ef7\u683c\u52a8\u6001\u6a21\u578b\uff0c\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u6a21\u578b\u3002", "result": "\u6a21\u578b\u80fd\u4ea7\u751f\u66f4\u9ad8\u5cf0\u5ea6\u548c\u91cd\u5c3e\u5206\u5e03\uff0c\u6f02\u79fb\u9879\u81ea\u7136\u4ea7\u751f\uff0c\u4e0e\u5386\u53f2\u80a1\u6743\u6570\u636e\u62df\u5408\u826f\u597d\u3002", "conclusion": "\u8be5\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6574\u5408\u4ef7\u683c\u3001\u6210\u4ea4\u91cf\u4e0d\u5e73\u8861\u548c\u4ef7\u5dee\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2507.08915", "pdf": "https://arxiv.org/pdf/2507.08915", "abs": "https://arxiv.org/abs/2507.08915", "authors": ["Kiarash Firouzi"], "title": "Quantifying Crypto Portfolio Risk: A Simulation-Based Framework Integrating Volatility, Hedging, Contagion, and Monte Carlo Modeling", "categories": ["q-fin.RM", "math.PR", "91G60, 60G99, 91B30"], "comment": null, "summary": "Extreme volatility, nonlinear dependencies, and systemic fragility are\ncharacteristics of cryptocurrency markets. The assumptions of normality and\ncentralized control in traditional financial risk models frequently cause them\nto miss these changes. Four components-volatility stress testing, stablecoin\nhedging, contagion modeling, and Monte Carlo simulation-are integrated into\nthis paper's modular simulation framework for crypto portfolio risk analysis.\nEvery module is based on mathematical finance theory, which includes stochastic\nprice path generation, correlation-based contagion propagation, and\nmean-variance optimization. The robustness and practical relevance of the\nframework are demonstrated through empirical validation utilizing 2020-2024\nUSDT, ETH, and BTC data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u52a0\u5bc6\u6295\u8d44\u7ec4\u5408\u98ce\u9669\u5206\u6790\u7684\u6a21\u5757\u5316\u6a21\u62df\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u91d1\u878d\u98ce\u9669\u6a21\u578b\u5047\u8bbe\u7684\u6b63\u6001\u6027\u548c\u96c6\u4e2d\u63a7\u5236\u5e38\u4f7f\u5176\u9519\u8fc7\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u7684\u6781\u7aef\u6ce2\u52a8\u3001\u975e\u7ebf\u6027\u4f9d\u8d56\u548c\u7cfb\u7edf\u8106\u5f31\u6027\u7b49\u53d8\u5316\u3002", "method": "\u5c06\u6ce2\u52a8\u6027\u538b\u529b\u6d4b\u8bd5\u3001\u7a33\u5b9a\u5e01\u5bf9\u51b2\u3001\u4f20\u67d3\u5efa\u6a21\u548c\u8499\u7279\u5361\u7f57\u6a21\u62df\u56db\u4e2a\u7ec4\u4ef6\u96c6\u6210\u5230\u6a21\u5757\u5316\u6a21\u62df\u6846\u67b6\uff0c\u5404\u6a21\u5757\u57fa\u4e8e\u6570\u5b66\u91d1\u878d\u7406\u8bba\u3002", "result": "\u5229\u75282020 - 2024\u5e74USDT\u3001ETH\u548cBTC\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "conclusion": "\u6846\u67b6\u5177\u6709\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u76f8\u5173\u6027\u3002"}}
{"id": "2507.09473", "pdf": "https://arxiv.org/pdf/2507.09473", "abs": "https://arxiv.org/abs/2507.09473", "authors": ["Yan Dai", "Negin Golrezaei", "Patrick Jaillet"], "title": "Incentive-Aware Dynamic Resource Allocation under Long-Term Cost Constraints", "categories": ["cs.GT", "cs.LG", "stat.ML"], "comment": null, "summary": "Motivated by applications such as cloud platforms allocating GPUs to users or\ngovernments deploying mobile health units across competing regions, we study\nthe dynamic allocation of a reusable resource to strategic agents with private\nvaluations. Our objective is to simultaneously (i) maximize social welfare,\n(ii) satisfy multi-dimensional long-term cost constraints, and (iii)\nincentivize truthful reporting. We begin by numerically evaluating primal-dual\nmethods widely used in constrained online optimization and find them to be\nhighly fragile in strategic settings -- agents can easily manipulate their\nreports to distort future dual updates for future gain.\n  To address this vulnerability, we develop an incentive-aware framework that\nmakes primal-dual methods robust to strategic behavior. Our design combines\nepoch-based lazy updates -- where dual variables remain fixed within each epoch\n-- with randomized exploration rounds that extract approximately truthful\nsignals for learning. Leveraging carefully designed online learning subroutines\nthat can be of independent interest for dual updates, our mechanism achieves\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ social welfare regret, satisfies all cost\nconstraints, and ensures incentive alignment. This matches the performance of\nnon-strategic allocation approaches while being robust to strategic agents.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.09546", "pdf": "https://arxiv.org/pdf/2507.09546", "abs": "https://arxiv.org/abs/2507.09546", "authors": ["Xiangwang Hou", "Jingjing Wang", "Jun Du", "Chunxiao Jiang", "Yong Ren", "Dusit Niyato"], "title": "Lightweight Federated Learning over Wireless Edge Networks", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "With the exponential growth of smart devices connected to wireless networks,\ndata production is increasing rapidly, requiring machine learning (ML)\ntechniques to unlock its value. However, the centralized ML paradigm raises\nconcerns over communication overhead and privacy. Federated learning (FL)\noffers an alternative at the network edge, but practical deployment in wireless\nnetworks remains challenging. This paper proposes a lightweight FL (LTFL)\nframework integrating wireless transmission power control, model pruning, and\ngradient quantization. We derive a closed-form expression of the FL convergence\ngap, considering transmission error, model pruning error, and gradient\nquantization error. Based on these insights, we formulate an optimization\nproblem to minimize the convergence gap while meeting delay and energy\nconstraints. To solve the non-convex problem efficiently, we derive closed-form\nsolutions for the optimal model pruning ratio and gradient quantization level,\nand employ Bayesian optimization for transmission power control. Extensive\nexperiments on real-world datasets show that LTFL outperforms state-of-the-art\nschemes.", "AI": {"tldr": "\u968f\u7740\u65e0\u7ebf\u8bbe\u5907\u6570\u636e\u589e\u957f\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0fML\u6709\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8054\u90a6\u5b66\u4e60\u6846\u67b6LTFL\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u96c6\u4e2d\u5f0fML\u5b58\u5728\u901a\u4fe1\u5f00\u9500\u548c\u9690\u79c1\u95ee\u9898\uff0c\u8054\u90a6\u5b66\u4e60\u5728\u65e0\u7ebf\u7f51\u7edc\u5b9e\u9645\u90e8\u7f72\u6709\u6311\u6218\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u65e0\u7ebf\u4f20\u8f93\u529f\u7387\u63a7\u5236\u3001\u6a21\u578b\u526a\u679d\u548c\u68af\u5ea6\u91cf\u5316\u7684LTFL\u6846\u67b6\uff1b\u63a8\u5bfcFL\u6536\u655b\u5dee\u8ddd\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b\u5236\u5b9a\u4f18\u5316\u95ee\u9898\uff1b\u63a8\u5bfc\u6700\u4f18\u6a21\u578b\u526a\u679d\u7387\u548c\u68af\u5ea6\u91cf\u5316\u6c34\u5e73\u7684\u95ed\u5f0f\u89e3\uff0c\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u884c\u4f20\u8f93\u529f\u7387\u63a7\u5236\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cLTFL\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LTFL\u6846\u67b6\u5728\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u65e0\u7ebf\u7f51\u7edc\u90e8\u7f72\u95ee\u9898\u4e0a\u6709\u6548\u3002"}}
{"id": "2507.08945", "pdf": "https://arxiv.org/pdf/2507.08945", "abs": "https://arxiv.org/abs/2507.08945", "authors": ["Savini Kashmira", "Jayanaka L. Dantanarayana", "Kriszti\u00e1n Flautner", "Lingjia Tang", "Jason Mars"], "title": "GraphRunner: A Multi-Stage Framework for Efficient and Accurate Graph-Based Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Conventional Retrieval Augmented Generation (RAG) approaches are common in\ntext-based applications. However, they struggle with structured, interconnected\ndatasets like knowledge graphs, where understanding underlying relationships is\ncrucial for accurate retrieval. A common direction in graph-based retrieval\nemploys iterative, rule-based traversal guided by Large Language Models (LLMs).\nSuch existing iterative methods typically combine reasoning with single hop\ntraversal at each step, making them vulnerable to LLM reasoning errors and\nhallucinations that ultimately hinder the retrieval of relevant information.\n  To address these limitations, we propose GraphRunner, a novel graph-based\nretrieval framework that operates in three distinct stages: planning,\nverification, and execution. This introduces high-level traversal actions that\nenable multi-hop exploration in a single step. It also generates a holistic\ntraversal plan, which is verified against the graph structure and pre-defined\ntraversal actions, reducing reasoning errors and detecting hallucinations\nbefore execution. GraphRunner significantly reduces LLM reasoning errors and\ndetects hallucinations through validation. Our evaluation using the GRBench\ndataset shows that GraphRunner consistently outperforms existing approaches,\nachieving 10-50% performance improvements over the strongest baseline while\nreducing inference cost by 3.0-12.9x and response generation time by 2.5-7.1x,\nmaking it significantly more robust and efficient for graph-based retrieval\ntasks.", "AI": {"tldr": "\u63d0\u51faGraphRunner\u6846\u67b6\u89e3\u51b3\u4f20\u7edfRAG\u5728\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u95ee\u9898\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u5347\u4e14\u6210\u672c\u964d\u4f4e\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u4e2d\u5b58\u5728\u56f0\u96be\uff0c\u73b0\u6709\u8fed\u4ee3\u65b9\u6cd5\u6613\u53d7LLM\u63a8\u7406\u9519\u8bef\u548c\u5e7b\u89c9\u5f71\u54cd\uff0c\u963b\u788d\u76f8\u5173\u4fe1\u606f\u68c0\u7d22\u3002", "method": "\u63d0\u51faGraphRunner\u6846\u67b6\uff0c\u5206\u89c4\u5212\u3001\u9a8c\u8bc1\u548c\u6267\u884c\u4e09\u9636\u6bb5\uff0c\u5f15\u5165\u9ad8\u7ea7\u904d\u5386\u52a8\u4f5c\u5b9e\u73b0\u5355\u6b65\u591a\u8df3\u63a2\u7d22\uff0c\u751f\u6210\u6574\u4f53\u904d\u5386\u8ba1\u5212\u5e76\u9a8c\u8bc1\u3002", "result": "\u4f7f\u7528GRBench\u6570\u636e\u96c6\u8bc4\u4f30\uff0cGraphRunner\u6027\u80fd\u6bd4\u6700\u5f3a\u57fa\u7ebf\u63d0\u534710 - 50%\uff0c\u63a8\u7406\u6210\u672c\u964d\u4f4e3.0 - 12.9\u500d\uff0c\u54cd\u5e94\u751f\u6210\u65f6\u95f4\u51cf\u5c112.5 - 7.1\u500d\u3002", "conclusion": "GraphRunner\u5bf9\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u4efb\u52a1\u66f4\u5065\u58ee\u548c\u9ad8\u6548\u3002"}}
{"id": "2507.09435", "pdf": "https://arxiv.org/pdf/2507.09435", "abs": "https://arxiv.org/abs/2507.09435", "authors": ["Yidong Zhao", "Xuan Li", "Chenfanfu Jiang", "Jinhyun Choo"], "title": "GeoWarp: An automatically differentiable and GPU-accelerated implicit MPM framework for geomechanics based on NVIDIA Warp", "categories": ["cs.CE", "cs.MS", "physics.comp-ph"], "comment": null, "summary": "The material point method (MPM), a hybrid Lagrangian-Eulerian particle\nmethod, is increasingly used to simulate large-deformation and\nhistory-dependent behavior of geomaterials. While explicit time integration\ndominates current MPM implementations due to its algorithmic simplicity, such\nschemes are unsuitable for quasi-static and long-term processes typical in\ngeomechanics. Implicit MPM formulations are free of these limitations but\nremain less adopted, largely due to the difficulty of computing the Jacobian\nmatrix required for Newton-type solvers, especially when consistent tangent\noperators should be derived for complex constitutive models. In this paper, we\nintroduce GeoWarp -- an implicit MPM framework for geomechanics built on NVIDIA\nWarp -- that exploits GPU parallelism and reverse-mode automatic\ndifferentiation to compute Jacobians without manual derivation. To enhance\nefficiency, we develop a sparse Jacobian construction algorithm that leverages\nthe localized particle-grid interactions intrinsic to MPM. The framework is\nverified through forward and inverse examples in large-deformation\nelastoplasticity and coupled poromechanics. Results demonstrate that GeoWarp\nprovides a robust, scalable, and extensible platform for differentiable\nimplicit MPM simulation in computational geomechanics.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u5730\u8d28\u529b\u5b66\u7684\u9690\u5f0fMPM\u6846\u67b6GeoWarp\uff0c\u5229\u7528GPU\u5e76\u884c\u548c\u81ea\u52a8\u5fae\u5206\u8ba1\u7b97\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u5f00\u53d1\u7a00\u758f\u96c5\u53ef\u6bd4\u6784\u9020\u7b97\u6cd5\uff0c\u7ecf\u5b9e\u4f8b\u9a8c\u8bc1\u5176\u4e3a\u53ef\u5fae\u9690\u5f0fMPM\u6a21\u62df\u63d0\u4f9b\u4e86\u53ef\u9760\u5e73\u53f0\u3002", "motivation": "\u663e\u5f0f\u65f6\u95f4\u79ef\u5206\u4e0d\u9002\u7528\u4e8e\u5730\u8d28\u529b\u5b66\u4e2d\u7684\u51c6\u9759\u6001\u548c\u957f\u671f\u8fc7\u7a0b\uff0c\u9690\u5f0fMPM\u867d\u65e0\u6b64\u9650\u5236\u4f46\u56e0\u8ba1\u7b97\u96c5\u53ef\u6bd4\u77e9\u9635\u56f0\u96be\u800c\u8f83\u5c11\u91c7\u7528\u3002", "method": "\u57fa\u4e8eNVIDIA Warp\u6784\u5efaGeoWarp\u6846\u67b6\uff0c\u5229\u7528GPU\u5e76\u884c\u548c\u53cd\u5411\u81ea\u52a8\u5fae\u5206\u8ba1\u7b97\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u5f00\u53d1\u7a00\u758f\u96c5\u53ef\u6bd4\u6784\u9020\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u5927\u53d8\u5f62\u5f39\u5851\u6027\u548c\u8026\u5408\u591a\u5b54\u529b\u5b66\u7684\u6b63\u6f14\u548c\u53cd\u6f14\u5b9e\u4f8b\u9a8c\u8bc1\u4e86\u6846\u67b6\u3002", "conclusion": "GeoWarp\u4e3a\u8ba1\u7b97\u5730\u8d28\u529b\u5b66\u4e2d\u7684\u53ef\u5fae\u9690\u5f0fMPM\u6a21\u62df\u63d0\u4f9b\u4e86\u7a33\u5065\u3001\u53ef\u6269\u5c55\u548c\u53ef\u6269\u5c55\u7684\u5e73\u53f0\u3002"}}
{"id": "2507.09138", "pdf": "https://arxiv.org/pdf/2507.09138", "abs": "https://arxiv.org/abs/2507.09138", "authors": ["Zhengding Hu", "Vibha Murthy", "Zaifeng Pan", "Wanlu Li", "Xiaoyi Fang", "Yufei Ding", "Yuke Wang"], "title": "HedraRAG: Coordinating LLM Generation and Database Retrieval in Heterogeneous RAG Serving", "categories": ["cs.DB", "cs.LG"], "comment": "Accepted by SOSP 2025", "summary": "This paper addresses emerging system-level challenges in heterogeneous\nretrieval-augmented generation (RAG) serving, where complex multi-stage\nworkflows and diverse request patterns complicate efficient execution. We\npresent HedraRAG, a runtime system built on a graph-based abstraction that\nexposes optimization opportunities across stage-level parallelism,\nintra-request similarity, and inter-request skewness. These opportunities are\nrealized through dynamic graph transformations, such as node splitting,\nreordering, edge addition, and dependency rewiring, applied to wavefronts of\nsubgraphs spanning concurrent requests. The resulting execution plans are\nmapped onto hybrid CPU-GPU pipelines to improve resource utilization and reduce\nlatency. Evaluations across a wide range of RAG workflows demonstrate speedups\nexceeding 1.5x and reaching up to 5x over existing frameworks, showcasing the\neffectiveness of coordinated generation and retrieval in serving environments.", "AI": {"tldr": "\u63d0\u51faHedraRAG\u8fd0\u884c\u65f6\u7cfb\u7edf\u89e3\u51b3\u5f02\u6784RAG\u670d\u52a1\u6311\u6218\uff0c\u901a\u8fc7\u56fe\u53d8\u6362\u548c\u6620\u5c04\u5230\u6df7\u5408CPU - GPU\u7ba1\u9053\u63d0\u5347\u6027\u80fd\uff0c\u8bc4\u4f30\u663e\u793a\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u89e3\u51b3\u5f02\u6784\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u670d\u52a1\u4e2d\u56e0\u590d\u6742\u591a\u7ea7\u5de5\u4f5c\u6d41\u548c\u591a\u6837\u8bf7\u6c42\u6a21\u5f0f\u5bfc\u81f4\u7684\u9ad8\u6548\u6267\u884c\u6311\u6218\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u56fe\u62bd\u8c61\u7684HedraRAG\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u901a\u8fc7\u8282\u70b9\u62c6\u5206\u3001\u91cd\u6392\u5e8f\u3001\u6dfb\u52a0\u8fb9\u548c\u4f9d\u8d56\u91cd\u8fde\u7b49\u52a8\u6001\u56fe\u53d8\u6362\uff0c\u5c06\u6267\u884c\u8ba1\u5212\u6620\u5c04\u5230\u6df7\u5408CPU - GPU\u7ba1\u9053\u3002", "result": "\u5728\u591a\u79cdRAG\u5de5\u4f5c\u6d41\u8bc4\u4f30\u4e2d\uff0c\u6bd4\u73b0\u6709\u6846\u67b6\u5b9e\u73b0\u8d85\u8fc71.5\u500d\u3001\u6700\u9ad8\u8fbe5\u500d\u7684\u52a0\u901f\u3002", "conclusion": "\u534f\u8c03\u751f\u6210\u548c\u68c0\u7d22\u5728\u670d\u52a1\u73af\u5883\u4e2d\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2507.09747", "pdf": "https://arxiv.org/pdf/2507.09747", "abs": "https://arxiv.org/abs/2507.09747", "authors": ["Dongyang Li", "Haoyang Qin", "Mingyang Wu", "Chen Wei", "Quanying Liu"], "title": "BrainFLORA: Uncovering Brain Concept Representation via Multimodal Neural Embeddings", "categories": ["cs.NE"], "comment": "10 pages, ACM MM 2025", "summary": "Understanding how the brain represents visual information is a fundamental\nchallenge in neuroscience and artificial intelligence. While AI-driven decoding\nof neural data has provided insights into the human visual system, integrating\nmultimodal neuroimaging signals, such as EEG, MEG, and fMRI, remains a critical\nhurdle due to their inherent spatiotemporal misalignment. Current approaches\noften analyze these modalities in isolation, limiting a holistic view of neural\nrepresentation. In this study, we introduce BrainFLORA, a unified framework for\nintegrating cross-modal neuroimaging data to construct a shared neural\nrepresentation. Our approach leverages multimodal large language models (MLLMs)\naugmented with modality-specific adapters and task decoders, achieving\nstate-of-the-art performance in joint-subject visual retrieval task and has the\npotential to extend multitasking. Combining neuroimaging analysis methods, we\nfurther reveal how visual concept representations align across neural\nmodalities and with real world object perception. We demonstrate that the\nbrain's structured visual concept representations exhibit an implicit mapping\nto physical-world stimuli, bridging neuroscience and machine learning from\ndifferent modalities of neural imaging. Beyond methodological advancements,\nBrainFLORA offers novel implications for cognitive neuroscience and\nbrain-computer interfaces (BCIs). Our code is available at\nhttps://github.com/ncclab-sustech/BrainFLORA.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7edf\u4e00\u6846\u67b6BrainFLORA\uff0c\u7528\u4e8e\u6574\u5408\u8de8\u6a21\u6001\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u6784\u5efa\u5171\u4eab\u795e\u7ecf\u8868\u5f81\uff0c\u5728\u89c6\u89c9\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8fd8\u63ed\u793a\u4e86\u89c6\u89c9\u6982\u5ff5\u8868\u5f81\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u5bf9\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u548c\u8111\u673a\u63a5\u53e3\u6709\u65b0\u542f\u793a\u3002", "motivation": "\u7406\u89e3\u5927\u8111\u5982\u4f55\u8868\u5f81\u89c6\u89c9\u4fe1\u606f\u662f\u795e\u7ecf\u79d1\u5b66\u548c\u4eba\u5de5\u667a\u80fd\u7684\u6839\u672c\u6311\u6218\uff0c\u5f53\u524d\u6574\u5408\u591a\u6a21\u6001\u795e\u7ecf\u5f71\u50cf\u4fe1\u53f7\u5b58\u5728\u65f6\u7a7a\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5e38\u5b64\u7acb\u5206\u6790\u5404\u6a21\u6001\uff0c\u7f3a\u4e4f\u6574\u4f53\u89c6\u89d2\u3002", "method": "\u5f15\u5165BrainFLORA\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8f85\u4ee5\u7279\u5b9a\u6a21\u6001\u9002\u914d\u5668\u548c\u4efb\u52a1\u89e3\u7801\u5668\uff0c\u7ed3\u5408\u795e\u7ecf\u5f71\u50cf\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u5728\u8054\u5408\u4e3b\u4f53\u89c6\u89c9\u68c0\u7d22\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6709\u6269\u5c55\u591a\u4efb\u52a1\u7684\u6f5c\u529b\uff0c\u63ed\u793a\u4e86\u89c6\u89c9\u6982\u5ff5\u8868\u5f81\u5728\u795e\u7ecf\u6a21\u6001\u95f4\u53ca\u4e0e\u73b0\u5b9e\u4e16\u754c\u7269\u4f53\u611f\u77e5\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "conclusion": "BrainFLORA\u6846\u67b6\u5b9e\u73b0\u4e86\u4e0d\u540c\u795e\u7ecf\u5f71\u50cf\u6a21\u6001\u95f4\u7684\u878d\u5408\uff0c\u5c55\u793a\u4e86\u5927\u8111\u7ed3\u6784\u5316\u89c6\u89c9\u6982\u5ff5\u8868\u5f81\u4e0e\u7269\u7406\u4e16\u754c\u523a\u6fc0\u7684\u9690\u5f0f\u6620\u5c04\uff0c\u5bf9\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u548c\u8111\u673a\u63a5\u53e3\u6709\u65b0\u610f\u4e49\u3002"}}
{"id": "2507.08875", "pdf": "https://arxiv.org/pdf/2507.08875", "abs": "https://arxiv.org/abs/2507.08875", "authors": ["Fuh-Hwa Franklin Liu", "Su-Chuan Shih"], "title": "A New Approach for Multicriteria Assessment in the Ranking of Alternatives Using Cardinal and Ordinal Data", "categories": ["cs.AI", "90B50, 90C29, 90C08, 91A80, 91B06"], "comment": "38 pages, 6 figures, 5 table. A practice applicable method for\n  multi-criteria assessments using cardinal and ordinal data", "summary": "Modern methods for multi-criteria assessment (MCA), such as Data Envelopment\nAnalysis (DEA), Stochastic Frontier Analysis (SFA), and Multiple Criteria\nDecision-Making (MCDM), are utilized to appraise a collection of\nDecision-Making Units (DMUs), also known as alternatives, based on several\ncriteria. These methodologies inherently rely on assumptions and can be\ninfluenced by subjective judgment to effectively tackle the complex evaluation\nchallenges in various fields. In real-world scenarios, it is essential to\nincorporate both quantitative and qualitative criteria as they consist of\ncardinal and ordinal data. Despite the inherent variability in the criterion\nvalues of different alternatives, the homogeneity assumption is often employed,\nsignificantly affecting evaluations. To tackle these challenges and determine\nthe most appropriate alternative, we propose a novel MCA approach that combines\ntwo Virtual Gap Analysis (VGA) models. The VGA framework, rooted in linear\nprogramming, is pivotal in the MCA methodology. This approach improves\nefficiency and fairness, ensuring that evaluations are both comprehensive and\ndependable, thus offering a strong and adaptive solution. Two comprehensive\nnumerical examples demonstrate the accuracy and transparency of our proposed\nmethod. The goal is to encourage continued advancement and stimulate progress\nin automated decision systems and decision support systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u4e24\u4e2a\u865a\u62df\u5dee\u8ddd\u5206\u6790\uff08VGA\uff09\u6a21\u578b\u7684\u591a\u6807\u51c6\u8bc4\u4f30\uff08MCA\uff09\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u4f8b\u8bc1\u660e\u5176\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4ee5\u63a8\u52a8\u81ea\u52a8\u5316\u51b3\u7b56\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709MCA\u65b9\u6cd5\u4f9d\u8d56\u5047\u8bbe\u548c\u53d7\u4e3b\u89c2\u5224\u65ad\u5f71\u54cd\uff0c\u5b9e\u9645\u9700\u517c\u987e\u5b9a\u91cf\u548c\u5b9a\u6027\u6807\u51c6\uff0c\u4e14\u540c\u8d28\u6027\u5047\u8bbe\u5f71\u54cd\u8bc4\u4f30\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u4e24\u4e2aVGA\u6a21\u578b\u7684\u65b0MCA\u65b9\u6cd5\uff0cVGA\u6846\u67b6\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u3002", "result": "\u4e24\u4e2a\u7efc\u5408\u6570\u503c\u5b9e\u4f8b\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u516c\u5e73\u6027\uff0c\u8bc4\u4f30\u5168\u9762\u53ef\u9760\uff0c\u80fd\u4e3a\u81ea\u52a8\u5316\u51b3\u7b56\u7cfb\u7edf\u548c\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u53d1\u5c55\u63d0\u4f9b\u6709\u529b\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09419", "pdf": "https://arxiv.org/pdf/2507.09419", "abs": "https://arxiv.org/abs/2507.09419", "authors": ["Yuchen Guo", "Matthew O. Jackson", "Ruixue Jia"], "title": "Comrades and Cause: Peer Influence on West Point Cadets' Civil War Allegiances", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Do social networks and peer influence shape major life decisions in highly\npolarized settings? We explore this question by examining how peers influenced\nthe allegiances of West Point cadets during the American Civil War. Leveraging\nquasi-random variations in the proportion of cadets from Free States, we\nanalyze how these differences affected decisions about which army to join. We\nfind that a higher proportion of classmates from Free States significantly\nincreased the likelihood that cadets from Slave States joined the Union Army,\nwhile almost all cadets from Free States joined the Union Army (if they decided\nto join the war). We further examine how cadets' decisions affected their\nmilitary rank and career outcomes. Our findings highlight that peers still\ninfluence choices even when they are life-altering and occur during periods of\nextreme polarization.", "AI": {"tldr": "\u7814\u7a76\u7f8e\u56fd\u5185\u6218\u671f\u95f4\u897f\u70b9\u519b\u6821\u5b66\u5458\u53d7\u540c\u4f34\u5f71\u54cd\u9009\u62e9\u9635\u8425\u7684\u60c5\u51b5\uff0c\u53d1\u73b0\u81ea\u7531\u5dde\u540c\u5b66\u6bd4\u4f8b\u5f71\u54cd\u84c4\u5974\u5dde\u5b66\u5458\u9009\u62e9\uff0c\u4e14\u540c\u4f34\u5728\u6781\u7aef\u6781\u5316\u65f6\u671f\u4ecd\u5f71\u54cd\u91cd\u5927\u51b3\u7b56\u3002", "motivation": "\u63a2\u7a76\u5728\u9ad8\u5ea6\u6781\u5316\u73af\u5883\u4e0b\u793e\u4ea4\u7f51\u7edc\u548c\u540c\u4f34\u5f71\u54cd\u662f\u5426\u4f1a\u5851\u9020\u91cd\u5927\u4eba\u751f\u51b3\u7b56\u3002", "method": "\u5229\u7528\u81ea\u7531\u5dde\u5b66\u5458\u6bd4\u4f8b\u7684\u51c6\u968f\u673a\u53d8\u5316\uff0c\u5206\u6790\u5176\u5bf9\u5b66\u5458\u9009\u62e9\u9635\u8425\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u5e76\u7814\u7a76\u5b66\u5458\u51b3\u7b56\u5bf9\u519b\u4e8b\u519b\u8854\u548c\u804c\u4e1a\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u81ea\u7531\u5dde\u540c\u5b66\u6bd4\u4f8b\u8d8a\u9ad8\uff0c\u84c4\u5974\u5dde\u5b66\u5458\u52a0\u5165\u8054\u90a6\u519b\u961f\u7684\u53ef\u80fd\u6027\u663e\u8457\u589e\u52a0\uff0c\u51e0\u4e4e\u6240\u6709\u81ea\u7531\u5dde\u5b66\u5458\u82e5\u53c2\u6218\u90fd\u52a0\u5165\u8054\u90a6\u519b\u961f\u3002", "conclusion": "\u5373\u4f7f\u5728\u6781\u7aef\u6781\u5316\u65f6\u671f\uff0c\u540c\u4f34\u4ecd\u4f1a\u5f71\u54cd\u6539\u53d8\u4eba\u751f\u7684\u9009\u62e9\u3002"}}
{"id": "2507.08923", "pdf": "https://arxiv.org/pdf/2507.08923", "abs": "https://arxiv.org/abs/2507.08923", "authors": ["Rub\u00e9n Rodr\u00edguez \u00c1lvarez", "Denisa-Andreea Constantinescu", "Miguel Pe\u00f3n-Quir\u00f3s", "David Atienza"], "title": "CEO-DC: An Actionable Framework to Close the Carbon Gap in HPC Data Centers", "categories": ["cs.AR", "cs.CY", "cs.PF", "B.8.2; C.0; C.1.4; C.4; C.5.5; J.4; K.1; K.4.1; K.6.4"], "comment": "15 pages, 11 figures, 2 tables", "summary": "The rapid expansion of data centers (DCs) to support large-scale AI and\nscientific workloads is driving unsustainable growth in energy consumption and\ngreenhouse gas emissions. While successive generations of hardware platforms\nhave improved performance and energy efficiency, the question remains whether\nnew, more efficient platforms can realistically offset the rising emissions\nassociated with increasing demand. Prior studies often overlook the complex\ntrade-offs in such transitions by failing to account for both the economic\nincentives and the projected compute demand growth over the operational\nlifetime of the devices. In response, we present CEO-DC, an integrated model\nand decision-making methodology for Carbon and Economy Optimization in Data\nCenters. CEO-DC models the competing forces of cost, carbon, and compute demand\nto guide optimal platform procurement and replacement strategies. We propose\nmetrics to steer procurement, platform design, and policy decisions toward\nsustainable DC technologies. Given current platform trends, our AI case study\nusing CEO-DC shows that upgrading legacy devices on a 4-year cycle reduces\ntotal emissions. However, these upgrades fail to scale with DC demand growth\ntrends without increasing total emissions in over 44% of cases, and require\neconomic incentives for adoption in over 72%. Furthermore, current carbon\nprices are insufficient to motivate upgrades in 9 out of the 14 countries with\nthe highest number of DCs globally. We also find that optimizing platforms for\nenergy efficiency at the expense of latency can increase the carbon price\nrequired to justify their adoption. In summary, CEO-DC provides actionable\ninsights for DC architects, platform designers, and policymakers by timing\nlegacy platform upgrades, constraining DC growth to sustainable levels,\noptimizing platform performance-to-cost ratios, and increasing incentives.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faCEO - DC\u6a21\u578b\u89e3\u51b3\u6570\u636e\u4e2d\u5fc3\u78b3\u6392\u653e\u548c\u7ecf\u6d4e\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5347\u7ea7\u7b56\u7565\u6548\u679c\u5e76\u7ed9\u51fa\u76f8\u5173\u7ed3\u8bba\u548c\u5efa\u8bae\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u5feb\u901f\u6269\u5f20\u5bfc\u81f4\u80fd\u8017\u548c\u78b3\u6392\u653e\u589e\u957f\uff0c\u4ee5\u5f80\u7814\u7a76\u5ffd\u7565\u590d\u6742\u6743\u8861\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u63d0\u51faCEO - DC\u96c6\u6210\u6a21\u578b\u548c\u51b3\u7b56\u65b9\u6cd5\uff0c\u5efa\u6a21\u6210\u672c\u3001\u78b3\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u63d0\u51fa\u5f15\u5bfc\u91c7\u8d2d\u7b49\u51b3\u7b56\u7684\u6307\u6807\u3002", "result": "4\u5e74\u5468\u671f\u5347\u7ea7\u65e7\u8bbe\u5907\u53ef\u51cf\u5c11\u603b\u6392\u653e\uff0c\u4f46\u8d8544%\u60c5\u51b5\u96be\u968f\u9700\u6c42\u589e\u957f\u4e0d\u589e\u6392\u653e\uff0c\u8d8572%\u9700\u7ecf\u6d4e\u6fc0\u52b1\uff1b9/14\u6570\u636e\u4e2d\u5fc3\u6700\u591a\u56fd\u5bb6\u5f53\u524d\u78b3\u4ef7\u4e0d\u8db3\u4ee5\u63a8\u52a8\u5347\u7ea7\uff1b\u727a\u7272\u5ef6\u8fdf\u4f18\u5316\u80fd\u6548\u4f1a\u63d0\u9ad8\u91c7\u7528\u6240\u9700\u78b3\u4ef7\u3002", "conclusion": "CEO - DC\u4e3a\u6570\u636e\u4e2d\u5fc3\u76f8\u5173\u4eba\u5458\u63d0\u4f9b\u4e86\u901a\u8fc7\u5408\u7406\u5b89\u6392\u5347\u7ea7\u3001\u63a7\u5236\u589e\u957f\u3001\u4f18\u5316\u6027\u4ef7\u6bd4\u548c\u589e\u52a0\u6fc0\u52b1\u7b49\u65b9\u9762\u7684\u53ef\u884c\u89c1\u89e3\u3002"}}
{"id": "2507.09412", "pdf": "https://arxiv.org/pdf/2507.09412", "abs": "https://arxiv.org/abs/2507.09412", "authors": ["Fabio Baschetti", "Giacomo Bormetti", "Pietro Rossi"], "title": "Joint deep calibration of the 4-factor PDV model", "categories": ["q-fin.CP"], "comment": null, "summary": "Joint calibration to SPX and VIX market data is a delicate task that requires\nsophisticated modeling and incurs significant computational costs. The latter\nis especially true when pricing of volatility derivatives hinges on nested\nMonte Carlo simulation. One such example is the 4-factor Markov Path-Dependent\nVolatility (PDV) model of Guyon and Lekeufack (2023). Nonetheless, its realism\nhas earned it considerable attention in recent years. Gazzani and Guyon (2025)\nmarked a relevant contribution by learning the VIX as a random variable, i.e.,\na measurable function of the model parameters and the Markovian factors. A\nneural network replaces the inner simulation and makes the joint calibration\nproblem accessible. However, the minimization loop remains slow due to\nexpensive outer simulation. The present paper overcomes this limitation by\nlearning SPX implied volatilities, VIX futures, and VIX call option prices. The\npricing functions reduce to simple matrix-vector products that can be evaluated\non the fly, shrinking calibration times to just a few seconds.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9SPX\u548cVIX\u5e02\u573a\u6570\u636e\u8054\u5408\u6821\u51c6\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5b66\u4e60SPX\u9690\u542b\u6ce2\u52a8\u7387\u3001VIX\u671f\u8d27\u548cVIX\u770b\u6da8\u671f\u6743\u4ef7\u683c\uff0c\u5c06\u5b9a\u4ef7\u51fd\u6570\u7b80\u5316\u4e3a\u77e9\u9635 - \u5411\u91cf\u4e58\u79ef\uff0c\u5927\u5e45\u7f29\u77ed\u6821\u51c6\u65f6\u95f4\u3002", "motivation": "\u89e3\u51b3\u8054\u5408\u6821\u51c6SPX\u548cVIX\u5e02\u573a\u6570\u636e\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5c24\u5176\u662f\u4f7f\u7528\u5d4c\u5957\u8499\u7279\u5361\u7f57\u6a21\u62df\u65f6\u5916\u5faa\u73af\u6a21\u62df\u6162\u7684\u95ee\u9898\u3002", "method": "\u5b66\u4e60SPX\u9690\u542b\u6ce2\u52a8\u7387\u3001VIX\u671f\u8d27\u548cVIX\u770b\u6da8\u671f\u6743\u4ef7\u683c\uff0c\u5c06\u5b9a\u4ef7\u51fd\u6570\u7b80\u5316\u4e3a\u53ef\u5373\u65f6\u8bc4\u4f30\u7684\u77e9\u9635 - \u5411\u91cf\u4e58\u79ef\u3002", "result": "\u5c06\u6821\u51c6\u65f6\u95f4\u7f29\u77ed\u81f3\u4ec5\u9700\u51e0\u79d2\u3002", "conclusion": "\u901a\u8fc7\u5b66\u4e60\u76f8\u5173\u4ef7\u683c\u5e76\u7b80\u5316\u5b9a\u4ef7\u51fd\u6570\uff0c\u80fd\u6709\u6548\u514b\u670d\u8054\u5408\u6821\u51c6\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u9650\u5236\u3002"}}
{"id": "2507.09426", "pdf": "https://arxiv.org/pdf/2507.09426", "abs": "https://arxiv.org/abs/2507.09426", "authors": ["Naonori Kakimura", "P\u00e9ter Madarasi", "Jannik Matuschke", "Kitti Varga"], "title": "Simultaneous Network Design with Restricted Link Usage", "categories": ["cs.DS", "cs.CC", "cs.DM", "math.OC"], "comment": null, "summary": "Given a digraph with two terminal vertices $s$ and $t$ as well as a\nconservative cost function and several not necessarily disjoint color classes\non its arc set, our goal is to find a minimum-cost subset of the arcs such that\nits intersection with each color class contains an $s$-$t$ dipath. Problems of\nthis type arise naturally in multi-commodity network design settings where each\ncommodity is restricted to use links of its own color only.\n  We study several variants of the problem, deriving strong hardness results\neven for restricted cases, but we also identify cases that can be solved in\npolynomial time. The latter ones include the cases where the color classes form\na laminar family, or where the underlying digraph is acyclic and the number of\ncolor classes is constant. We also present an FPT algorithm for the general\ncase parameterized by the number of multi-colored arcs.", "AI": {"tldr": "\u7814\u7a76\u6709\u5411\u56fe\u4e2d\u627e\u6700\u5c0f\u6210\u672c\u5f27\u5b50\u96c6\u95ee\u9898\uff0c\u5f97\u51fa\u5f3a\u786c\u5ea6\u7ed3\u679c\uff0c\u8bc6\u522b\u591a\u9879\u5f0f\u53ef\u89e3\u60c5\u51b5\u5e76\u7ed9\u51faFPT\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u5546\u54c1\u7f51\u7edc\u8bbe\u8ba1\u4e2d\u5404\u5546\u54c1\u53ea\u80fd\u4f7f\u7528\u81ea\u8eab\u989c\u8272\u94fe\u8def\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u95ee\u9898\u7684\u591a\u79cd\u53d8\u4f53\uff0c\u5206\u6790\u9650\u5236\u60c5\u51b5\u3002", "result": "\u5f97\u51fa\u5f3a\u786c\u5ea6\u7ed3\u679c\uff0c\u8bc6\u522b\u51fa\u989c\u8272\u7c7b\u6210\u5c42\u72b6\u65cf\u3001\u6709\u5411\u56fe\u65e0\u73af\u4e14\u989c\u8272\u7c7b\u6570\u91cf\u56fa\u5b9a\u7b49\u591a\u9879\u5f0f\u53ef\u89e3\u60c5\u51b5\uff0c\u7ed9\u51fa\u4e00\u822c\u60c5\u51b5\u4e0b\u57fa\u4e8e\u591a\u8272\u5f27\u6570\u91cf\u7684FPT\u7b97\u6cd5\u3002", "conclusion": "\u6b64\u95ee\u9898\u90e8\u5206\u60c5\u51b5\u53ef\u591a\u9879\u5f0f\u6c42\u89e3\uff0c\u4e00\u822c\u60c5\u51b5\u53ef\u7528FPT\u7b97\u6cd5\u5904\u7406\u3002"}}
{"id": "2507.08992", "pdf": "https://arxiv.org/pdf/2507.08992", "abs": "https://arxiv.org/abs/2507.08992", "authors": ["Abdelhalim Dahou", "Ansgar Scherp", "Sebastian Kurten", "Brigitte Mathiak", "Madhu Chauhan"], "title": "Semantic Source Code Segmentation using Small and Large Language Models", "categories": ["cs.SE", "cs.CL", "cs.PL"], "comment": "18 pages, 4 figures", "summary": "Source code segmentation, dividing code into functionally coherent segments,\nis crucial for knowledge retrieval and maintenance in software development.\nWhile enabling efficient navigation and comprehension of large codebases,\nmanual and syntactic analysis approaches have become impractical as\nrepositories grow, especially for low-resource languages like R and their\nresearch domains (e.g., social sciences, psychology).This paper introduces an\nautomated, domain-specific approach for research R code segmentation using\nLarge and Small Language Models (LLMs/SLMs). It presents two novel approaches\nand a human-annotated dataset, StatCodeSeg. We explore two distinct approaches:\nline-by-line analysis with context and range-based segment determination. We\nexperiment with LLMs and fine-tuned SLMs. To support the generalizability of\nour approaches, we also include experiments on Python code from the computer\nscience domain.Our results show that context-based line-by-line analysis is\nsuperior over range-based segmentation.Using smaller language models like\nCodeBERT and an encoder-only version of CodeT5+ are better than their LLM\ncounterparts. Most notably, these two best-performing models did not see R code\nduring pre-training versus the LLMs but were only fine-tuned on 4,130 lines of\nmanually annotated code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u52a8\u5316\u7279\u5b9a\u9886\u57df\u65b9\u6cd5\u5bf9\u7814\u7a76\u7528R\u4ee3\u7801\u8fdb\u884c\u5206\u5272\uff0c\u5bf9\u6bd4\u4e0d\u540c\u65b9\u6cd5\u548c\u6a21\u578b\uff0c\u53d1\u73b0\u57fa\u4e8e\u4e0a\u4e0b\u6587\u9010\u884c\u5206\u6790\u53ca\u5c0f\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u66f4\u4f73\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5e93\u589e\u957f\uff0c\u624b\u52a8\u548c\u53e5\u6cd5\u5206\u6790\u65b9\u6cd5\u5728R\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u4ee3\u7801\u5206\u5272\u4e2d\u53d8\u5f97\u4e0d\u5b9e\u7528\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e24\u79cd\u65b0\u9896\u65b9\u6cd5\uff08\u57fa\u4e8e\u4e0a\u4e0b\u6587\u9010\u884c\u5206\u6790\u548c\u57fa\u4e8e\u8303\u56f4\u7684\u6bb5\u786e\u5b9a\uff09\uff0c\u4f7f\u7528\u5927\u3001\u5c0f\u8bed\u8a00\u6a21\u578b\u5b9e\u9a8c\uff0c\u521b\u5efa\u4eba\u7c7b\u6807\u6ce8\u6570\u636e\u96c6StatCodeSeg\uff0c\u8fd8\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u7684Python\u4ee3\u7801\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u9010\u884c\u5206\u6790\u4f18\u4e8e\u57fa\u4e8e\u8303\u56f4\u7684\u5206\u5272\uff1bCodeBERT\u548cCodeT5+\u7684\u7f16\u7801\u5668\u7248\u672c\u7b49\u5c0f\u8bed\u8a00\u6a21\u578b\u6bd4\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u597d\u3002", "conclusion": "\u65b0\u7684\u81ea\u52a8\u5316\u7279\u5b9a\u9886\u57df\u65b9\u6cd5\u5728R\u4ee3\u7801\u5206\u5272\u4e2d\u6709\u8f83\u597d\u6548\u679c\uff0c\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.08829", "pdf": "https://arxiv.org/pdf/2507.08829", "abs": "https://arxiv.org/abs/2507.08829", "authors": ["Kimia Soroush", "Nastaran Shirazi", "Mohsen Raji"], "title": "Efficient Triple Modular Redundancy for Reliability Enhancement of DNNs Using Explainable AI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep Neural Networks (DNNs) are widely employed in safety-critical domains,\nwhere ensuring their reliability is essential. Triple Modular Redundancy (TMR)\nis an effective technique to enhance the reliability of DNNs in the presence of\nbit-flip faults. In order to handle the significant overhead of TMR, it is\napplied selectively on the parameters and components with the highest\ncontribution at the model output. Hence, the accuracy of the selection\ncriterion plays the key role on the efficiency of TMR. This paper presents an\nefficient TMR approach to enhance the reliability of DNNs against bit-flip\nfaults using an Explainable Artificial Intelligence (XAI) method. Since XAI can\nprovide valuable insights about the importance of individual neurons and\nweights in the performance of the network, they can be applied as the selection\nmetric in TMR techniques. The proposed method utilizes a low-cost,\ngradient-based XAI technique known as Layer-wise Relevance Propagation (LRP) to\ncalculate importance scores for DNN parameters. These scores are then used to\nenhance the reliability of the model, with the most critical weights being\nprotected by TMR. The proposed approach is evaluated on two DNN models, VGG16\nand AlexNet, using datasets such as MNIST and CIFAR-10. The results demonstrate\nthat the method can protect the AlexNet model at a bit error rate of 10-4,\nachieving over 60% reliability improvement while maintaining the same overhead\nas state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eXAI\u7684\u9ad8\u6548TMR\u65b9\u6cd5\u63d0\u5347DNN\u6297\u4f4d\u7ffb\u8f6c\u6545\u969c\u53ef\u9760\u6027\uff0c\u5e76\u7528LRP\u8ba1\u7b97\u53c2\u6570\u91cd\u8981\u6027\u5f97\u5206\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u63d0\u5347AlexNet\u53ef\u9760\u6027\u3002", "motivation": "DNN\u7528\u4e8e\u5b89\u5168\u5173\u952e\u9886\u57df\u9700\u786e\u4fdd\u53ef\u9760\u6027\uff0cTMR\u6709\u663e\u8457\u5f00\u9500\uff0c\u9009\u62e9\u6807\u51c6\u51c6\u786e\u6027\u5bf9TMR\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u4f4e\u6210\u672cXAI\u6280\u672fLRP\u8ba1\u7b97DNN\u53c2\u6570\u91cd\u8981\u6027\u5f97\u5206\uff0c\u7528TMR\u4fdd\u62a4\u5173\u952e\u6743\u91cd\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u5728\u8bef\u7801\u738710 - 4\u65f6\u4fdd\u62a4AlexNet\u6a21\u578b\uff0c\u53ef\u9760\u6027\u63d0\u5347\u8d8560%\uff0c\u5f00\u9500\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u540c\u3002", "conclusion": "\u6240\u63d0\u9ad8\u6548TMR\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347DNN\u6297\u4f4d\u7ffb\u8f6c\u6545\u969c\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.09808", "pdf": "https://arxiv.org/pdf/2507.09808", "abs": "https://arxiv.org/abs/2507.09808", "authors": ["Di Yu", "Shane G. Henderson", "Raghu Pasupathy"], "title": "Frank-Wolfe Recursions for the Emergency Response Problem on Measure Spaces", "categories": ["math.OC", "stat.CO"], "comment": null, "summary": "We consider an optimization problem over measures for emergency response to\nout-of-hospital cardiac arrest (OHCA), where the goal is to allocate volunteer\nresources across a spatial region to minimize the probability of death. The\nproblem is infinite-dimensional and poses challenges for analysis and\ncomputation. We first establish structural properties, including convexity of\nthe objective functional, compactness of the feasible set, and existence of\noptimal solutions. We also derive the influence function, which serves as the\nfirst-order variational object in our optimization framework. We then adapt and\nanalyze a fully-corrective Frank-Wolfe (fc-FW) algorithm that operates directly\non the infinite-dimensional problem without discretization or parametric\napproximation. We show a form of convergence even when subproblems are not\nsolved to global optimality. Our full implementation of fc-FW demonstrates\ncomplex solution structure even in simple discrete cases, reveals nontrivial\nvolunteer allocations in continuous cases, and scales to realistic urban\nscenarios using OHCA data from the city of Auckland, New Zealand. Finally, we\nshow that when volunteer travel is modeled through the $L_1$ norm, the\ninfluence function is piecewise strictly concave, enabling fast computation via\nsupport reduction. The proposed framework and analysis extend naturally to a\nbroad class of $P$-means problems.", "AI": {"tldr": "\u7814\u7a76\u9662\u5916\u5fc3\u810f\u9aa4\u505c\u5e94\u6025\u54cd\u5e94\u7684\u6d4b\u5ea6\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fafc - FW\u7b97\u6cd5\u6c42\u89e3\uff0c\u5c55\u793a\u5176\u6548\u679c\u5e76\u8868\u660e\u53ef\u6269\u5c55\u5230\u4e00\u7c7bP - \u5747\u503c\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u9662\u5916\u5fc3\u810f\u9aa4\u505c\u5e94\u6025\u54cd\u5e94\u4e2d\u5fd7\u613f\u8d44\u6e90\u7a7a\u95f4\u5206\u914d\u4ee5\u6700\u5c0f\u5316\u6b7b\u4ea1\u6982\u7387\u7684\u65e0\u9650\u7ef4\u4f18\u5316\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5206\u6790\u548c\u8ba1\u7b97\u6709\u6311\u6218\u3002", "method": "\u5148\u5efa\u7acb\u76ee\u6807\u51fd\u6570\u51f8\u6027\u3001\u53ef\u884c\u96c6\u7d27\u81f4\u6027\u7b49\u7ed3\u6784\u6027\u8d28\uff0c\u63a8\u5bfc\u5f71\u54cd\u51fd\u6570\uff0c\u91c7\u7528\u5e76\u5206\u6790fc - FW\u7b97\u6cd5\u6c42\u89e3\uff0c\u4e0d\u8fdb\u884c\u79bb\u6563\u5316\u6216\u53c2\u6570\u8fd1\u4f3c\u3002", "result": "fc - FW\u7b97\u6cd5\u5728\u7b80\u5355\u79bb\u6563\u548c\u8fde\u7eed\u60c5\u5f62\u6709\u590d\u6742\u89e3\u7ed3\u6784\u548c\u975e\u5e73\u51e1\u5206\u914d\uff0c\u53ef\u6269\u5c55\u5230\u771f\u5b9e\u57ce\u5e02\u573a\u666f\uff1b\u5f53\u7528L1\u8303\u6570\u5efa\u6a21\u65f6\uff0c\u5f71\u54cd\u51fd\u6570\u5206\u6bb5\u4e25\u683c\u51f9\uff0c\u53ef\u5feb\u901f\u8ba1\u7b97\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u548c\u5206\u6790\u53ef\u81ea\u7136\u6269\u5c55\u5230\u4e00\u7c7bP - \u5747\u503c\u95ee\u9898\u3002"}}
{"id": "2507.09554", "pdf": "https://arxiv.org/pdf/2507.09554", "abs": "https://arxiv.org/abs/2507.09554", "authors": ["Pouriya Khalilian", "Amirhossein N. Golestani", "Mohammad Eslamifar", "Mostafa T. Firouzjaee", "Javad T. Firouzjaee"], "title": "Mapping Crisis-Driven Market Dynamics: A Transfer Entropy and Kramers-Moyal Approach to Financial Networks", "categories": ["q-fin.ST", "physics.soc-ph"], "comment": null, "summary": "Financial markets are dynamic, interconnected systems where local shocks can\ntrigger widespread instability, challenging portfolio managers and\npolicymakers. Traditional correlation analysis often miss the directionality\nand temporal dynamics of information flow. To address this, we present a\nunified framework integrating Transfer Entropy (TE) and the N-dimensional\nKramers-Moyal (KM) expansion to map static and time-resolved coupling among\nfour major indices: Nasdaq Composite (^IXIC), WTI crude oil (WTI), gold (GC=F),\nand the US Dollar Index (DX-Y.NYB). TE captures directional information flow.\nKM models non-linear stochastic dynamics, revealing interactions often\noverlooked by linear methods. Using daily data from August 11, 2014, to\nSeptember 8, 2024, we compute returns, confirm non-stationary using a conduct\nsliding-window TE and KM analyses. We find that during the COVID-19 pandemic\n(March-June 2020) and the Russia-Ukraine crisis (Feb-Apr 2022), average TE\nincreases by 35% and 28%, respectively, indicating heightened directional flow.\nDrift coefficients highlight gold-dollar interactions as a persistent\nsafe-haven channel, while oil-equity linkages show regime shifts, weakening\nunder stress and rebounding quickly. Our results expose the shortcomings of\nlinear measures and underscore the value of combining information-theoretic and\nstochastic drift methods. This approach offers actionable insights for adaptive\nhedging and informs macro-prudential policy by revealing the evolving\narchitecture of systemic risk.", "AI": {"tldr": "\u63d0\u51fa\u6574\u5408\u8f6c\u79fb\u71b5\u548cN\u7ef4Kramers - Moyal\u5c55\u5f00\u7684\u7edf\u4e00\u6846\u67b6\u5206\u6790\u56db\u5927\u6307\u6570\uff0c\u53d1\u73b0\u7279\u6b8a\u65f6\u671f\u65b9\u5411\u6027\u4fe1\u606f\u6d41\u589e\u5f3a\uff0c\u63ed\u793a\u7ebf\u6027\u65b9\u6cd5\u4e0d\u8db3\uff0c\u4e3a\u5bf9\u51b2\u548c\u653f\u7b56\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u91d1\u878d\u5e02\u573a\u52a8\u6001\u4e14\u76f8\u4e92\u5173\u8054\uff0c\u4f20\u7edf\u76f8\u5173\u5206\u6790\u65e0\u6cd5\u6355\u6349\u4fe1\u606f\u6d41\u65b9\u5411\u6027\u548c\u65f6\u95f4\u52a8\u6001\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u5206\u6790\u5e02\u573a\u3002", "method": "\u6574\u5408\u8f6c\u79fb\u71b5\u548cN\u7ef4Kramers - Moyal\u5c55\u5f00\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u4f7f\u75282014\u5e748\u670811\u65e5\u81f32024\u5e749\u67088\u65e5\u7684\u6bcf\u65e5\u6570\u636e\uff0c\u8fdb\u884c\u6ed1\u52a8\u7a97\u53e3\u5206\u6790\u3002", "result": "\u75ab\u60c5\u548c\u4fc4\u4e4c\u5371\u673a\u671f\u95f4\u5e73\u5747\u8f6c\u79fb\u71b5\u5206\u522b\u589e\u52a035%\u548c28%\uff1b\u6f02\u79fb\u7cfb\u6570\u663e\u793a\u9ec4\u91d1 - \u7f8e\u5143\u4e92\u52a8\u662f\u907f\u9669\u6e20\u9053\uff0c\u77f3\u6cb9 - \u80a1\u7968\u8054\u7cfb\u6709\u72b6\u6001\u8f6c\u53d8\u3002", "conclusion": "\u7ebf\u6027\u5ea6\u91cf\u6709\u7f3a\u9677\uff0c\u7ed3\u5408\u4fe1\u606f\u8bba\u548c\u968f\u673a\u6f02\u79fb\u65b9\u6cd5\u6709\u4ef7\u503c\uff0c\u80fd\u4e3a\u81ea\u9002\u5e94\u5bf9\u51b2\u548c\u5b8f\u89c2\u5ba1\u614e\u653f\u7b56\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2507.08922", "pdf": "https://arxiv.org/pdf/2507.08922", "abs": "https://arxiv.org/abs/2507.08922", "authors": ["Tameem Adel"], "title": "The Bayesian Approach to Continual Learning: An Overview", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Continual learning is an online paradigm where a learner continually\naccumulates knowledge from different tasks encountered over sequential time\nsteps. Importantly, the learner is required to extend and update its knowledge\nwithout forgetting about the learning experience acquired from the past, and\nwhile avoiding the need to retrain from scratch. Given its sequential nature\nand its resemblance to the way humans think, continual learning offers an\nopportunity to address several challenges which currently stand in the way of\nwidening the range of applicability of deep models to further real-world\nproblems. The continual need to update the learner with data arriving\nsequentially strikes inherent congruence between continual learning and\nBayesian inference which provides a principal platform to keep updating the\nprior beliefs of a model given new data, without completely forgetting the\nknowledge acquired from the old data. This survey inspects different settings\nof Bayesian continual learning, namely task-incremental learning and\nclass-incremental learning. We begin by discussing definitions of continual\nlearning along with its Bayesian setting, as well as the links with related\nfields, such as domain adaptation, transfer learning and meta-learning.\nAfterwards, we introduce a taxonomy offering a comprehensive categorization of\nalgorithms belonging to the Bayesian continual learning paradigm. Meanwhile, we\nanalyze the state-of-the-art while zooming in on some of the most prominent\nBayesian continual learning algorithms to date. Furthermore, we shed some light\non links between continual learning and developmental psychology, and\ncorrespondingly introduce analogies between both fields. We follow that with a\ndiscussion of current challenges, and finally conclude with potential areas for\nfuture research on Bayesian continual learning.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u63a2\u8ba8\u8d1d\u53f6\u65af\u6301\u7eed\u5b66\u4e60\uff0c\u4ecb\u7ecd\u5b9a\u4e49\u3001\u5206\u7c7b\u7b97\u6cd5\u3001\u4e0e\u76f8\u5173\u9886\u57df\u8054\u7cfb\uff0c\u5206\u6790\u73b0\u72b6\u3001\u6311\u6218\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u4e0e\u8d1d\u53f6\u65af\u63a8\u7406\u672c\u8d28\u5951\u5408\uff0c\u53ef\u89e3\u51b3\u6df1\u5ea6\u6a21\u578b\u5e94\u7528\u4e8e\u73b0\u5b9e\u95ee\u9898\u7684\u6311\u6218\uff0c\u56e0\u6b64\u7814\u7a76\u8d1d\u53f6\u65af\u6301\u7eed\u5b66\u4e60\u4e0d\u540c\u8bbe\u7f6e\u3002", "method": "\u5148\u8ba8\u8bba\u6301\u7eed\u5b66\u4e60\u5b9a\u4e49\u3001\u8d1d\u53f6\u65af\u8bbe\u7f6e\u53ca\u4e0e\u76f8\u5173\u9886\u57df\u8054\u7cfb\uff0c\u518d\u5bf9\u7b97\u6cd5\u5206\u7c7b\uff0c\u5206\u6790\u5f53\u524d\u5148\u8fdb\u7b97\u6cd5\uff0c\u63a2\u8ba8\u4e0e\u53d1\u5c55\u5fc3\u7406\u5b66\u8054\u7cfb\u3002", "result": "\u7ed9\u51fa\u8d1d\u53f6\u65af\u6301\u7eed\u5b66\u4e60\u7b97\u6cd5\u5206\u7c7b\uff0c\u5206\u6790\u4e86\u90e8\u5206\u5148\u8fdb\u7b97\u6cd5\uff0c\u6307\u51fa\u4e0e\u53d1\u5c55\u5fc3\u7406\u5b66\u7684\u8054\u7cfb\u548c\u5f53\u524d\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6301\u7eed\u5b66\u4e60\u672a\u6765\u6f5c\u5728\u7814\u7a76\u9886\u57df\u3002"}}
{"id": "2507.09739", "pdf": "https://arxiv.org/pdf/2507.09739", "abs": "https://arxiv.org/abs/2507.09739", "authors": ["Haojie Liu", "Zihan Lin", "Randall R. Rojas"], "title": "Enhancing Trading Performance Through Sentiment Analysis with Large Language Models: Evidence from the S&P 500", "categories": ["q-fin.CP", "q-fin.TR"], "comment": null, "summary": "This study integrates real-time sentiment analysis from financial news, GPT-2\nand FinBERT, with technical indicators and time-series models like ARIMA and\nETS to optimize S&P 500 trading strategies. By merging sentiment data with\nmomentum and trend-based metrics, including a benchmark buy-and-hold and\nsentiment-based approach, is evaluated through assets values and returns.\nResults show that combining sentiment-driven insights with traditional models\nimproves trading performance, offering a more dynamic approach to stock trading\nthat adapts to market changes in volatile environments.", "AI": {"tldr": "\u7814\u7a76\u6574\u5408\u91d1\u878d\u65b0\u95fb\u60c5\u7eea\u5206\u6790\u3001GPT - 2\u3001FinBERT\u4e0e\u6280\u672f\u6307\u6807\u548c\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u4f18\u5316\u6807\u666e500\u4ea4\u6613\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793a\u7ed3\u5408\u65b9\u6cd5\u80fd\u63d0\u5347\u4ea4\u6613\u8868\u73b0\u3002", "motivation": "\u4f18\u5316\u6807\u666e500\u7684\u4ea4\u6613\u7b56\u7565\uff0c\u4ee5\u66f4\u597d\u9002\u5e94\u5e02\u573a\u53d8\u5316\u3002", "method": "\u6574\u5408\u91d1\u878d\u65b0\u95fb\u5b9e\u65f6\u60c5\u7eea\u5206\u6790\u3001GPT - 2\u3001FinBERT\u4e0eARIMA\u3001ETS\u7b49\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff0c\u7ed3\u5408\u60c5\u7eea\u6570\u636e\u4e0e\u52a8\u91cf\u548c\u8d8b\u52bf\u6307\u6807\uff0c\u8bc4\u4f30\u57fa\u51c6\u4e70\u5165\u6301\u6709\u548c\u57fa\u4e8e\u60c5\u7eea\u7684\u65b9\u6cd5\u3002", "result": "\u7ed3\u5408\u60c5\u7eea\u9a71\u52a8\u7684\u89c1\u89e3\u4e0e\u4f20\u7edf\u6a21\u578b\u80fd\u6539\u5584\u4ea4\u6613\u8868\u73b0\u3002", "conclusion": "\u7ed3\u5408\u60c5\u7eea\u5206\u6790\u548c\u4f20\u7edf\u6a21\u578b\u4e3a\u80a1\u7968\u4ea4\u6613\u63d0\u4f9b\u4e86\u66f4\u52a8\u6001\u7684\u65b9\u6cd5\uff0c\u80fd\u9002\u5e94\u6ce2\u52a8\u5e02\u573a\u73af\u5883\u3002"}}
{"id": "2507.09181", "pdf": "https://arxiv.org/pdf/2507.09181", "abs": "https://arxiv.org/abs/2507.09181", "authors": ["M\u00fccahit Ayg\u00fcn", "Fabio Bellini", "Roger J. A. Laeven"], "title": "Generalized Orlicz premia", "categories": ["q-fin.RM", "math.PR", "math.ST", "q-fin.MF", "stat.TH"], "comment": null, "summary": "We introduce a generalized version of Orlicz premia, based on possibly\nnon-convex loss functions. We show that this generalized definition covers a\nvariety of relevant examples, such as the geometric mean and the expectiles,\nwhile at the same time retaining a number of relevant properties. We establish\nthat cash-additivity leads to $L^p$-quantiles, extending a classical result on\n'collapse to the mean' for convex Orlicz premia.\n  We then focus on the geometrically convex case, discussing the dual\nrepresentation of generalized Orlicz premia and comparing it with a\nmultiplicative form of the standard dual representation for the convex case.\nFinally, we show that generalized Orlicz premia arise naturally as the only\nelicitable, positively homogeneous, monotone and normalized functionals.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8e\u975e\u51f8\u635f\u5931\u51fd\u6570\u7684\u5e7f\u4e49Orlicz\u4fdd\u8d39\uff0c\u6db5\u76d6\u591a\u79cd\u4f8b\u5b50\uff0c\u7814\u7a76\u5176\u6027\u8d28\u3001\u5bf9\u5076\u8868\u793a\uff0c\u8bc1\u660e\u5176\u4e3a\u552f\u4e00\u53ef\u5f15\u51fa\u3001\u6b63\u9f50\u6b21\u3001\u5355\u8c03\u548c\u5f52\u4e00\u5316\u7684\u6cdb\u51fd\u3002", "motivation": "\u5f15\u5165\u66f4\u5e7f\u4e49\u7684Orlicz\u4fdd\u8d39\u5b9a\u4e49\uff0c\u4ee5\u8986\u76d6\u66f4\u591a\u76f8\u5173\u4f8b\u5b50\u5e76\u7814\u7a76\u5176\u6027\u8d28\u3002", "method": "\u7406\u8bba\u63a8\u5bfc\uff0c\u5efa\u7acb\u73b0\u91d1\u53ef\u52a0\u6027\u4e0e$L^p$-\u5206\u4f4d\u6570\u7684\u5173\u7cfb\uff0c\u8ba8\u8bba\u5bf9\u5076\u8868\u793a\u5e76\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5e7f\u4e49\u5b9a\u4e49\u6db5\u76d6\u51e0\u4f55\u5747\u503c\u548c\u671f\u671b\u5206\u4f4d\u6570\u7b49\u4f8b\u5b50\uff0c\u73b0\u91d1\u53ef\u52a0\u6027\u5bfc\u81f4$L^p$-\u5206\u4f4d\u6570\uff0c\u5f97\u5230\u5e7f\u4e49Orlicz\u4fdd\u8d39\u7684\u5bf9\u5076\u8868\u793a\u3002", "conclusion": "\u5e7f\u4e49Orlicz\u4fdd\u8d39\u662f\u552f\u4e00\u53ef\u5f15\u51fa\u3001\u6b63\u9f50\u6b21\u3001\u5355\u8c03\u548c\u5f52\u4e00\u5316\u7684\u6cdb\u51fd\u3002"}}
{"id": "2507.09544", "pdf": "https://arxiv.org/pdf/2507.09544", "abs": "https://arxiv.org/abs/2507.09544", "authors": ["Ryoga Mahara"], "title": "Existence of Fair and Efficient Allocation of Indivisible Chores", "categories": ["cs.GT"], "comment": "33pages, 2 figures", "summary": "We study the problem of allocating indivisible chores among agents with\nadditive cost functions in a fair and efficient manner. A major open question\nin this area is whether there always exists an allocation that is envy-free up\nto one chore (EF1) and Pareto optimal (PO). Our main contribution is to provide\na positive answer to this question by proving the existence of such an\nallocation for indivisible chores under additive cost functions. This is\nachieved by a novel combination of a fixed point argument and a discrete\nalgorithm, providing a significant methodological advance in this area.\n  Our additional key contributions are as follows. We show that there always\nexists an allocation that is EF1 and fractional Pareto optimal (fPO), where fPO\nis a stronger efficiency concept than PO. We also show that an EF1 and PO\nallocation can be computed in polynomial time when the number of agents is\nconstant. Finally, we extend all of these results to the more general setting\nof weighted EF1 (wEF1), which accounts for the entitlements of agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e0d\u53ef\u5206\u4efb\u52a1\u5728\u5177\u6709\u52a0\u6027\u6210\u672c\u51fd\u6570\u7684\u4ee3\u7406\u95f4\u516c\u5e73\u9ad8\u6548\u5206\u914d\u95ee\u9898\uff0c\u8bc1\u660e\u5b58\u5728EF1\u4e14PO\u7684\u5206\u914d\uff0c\u8fd8\u7ed9\u51fa\u5176\u4ed6\u76f8\u5173\u7ed3\u8bba\u5e76\u6269\u5c55\u5230wEF1\u60c5\u51b5\u3002", "motivation": "\u89e3\u51b3\u8be5\u9886\u57df\u5173\u4e8e\u662f\u5426\u603b\u5b58\u5728EF1\u4e14PO\u7684\u5206\u914d\u8fd9\u4e00\u4e3b\u8981\u5f00\u653e\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u4e0d\u52a8\u70b9\u8bba\u8bc1\u548c\u79bb\u6563\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u5b58\u5728EF1\u4e14PO\u7684\u5206\u914d\uff1b\u8bc1\u660e\u5b58\u5728EF1\u4e14fPO\u7684\u5206\u914d\uff1b\u5728\u4ee3\u7406\u6570\u91cf\u56fa\u5b9a\u65f6\uff0c\u53ef\u591a\u9879\u5f0f\u65f6\u95f4\u8ba1\u7b97EF1\u4e14PO\u7684\u5206\u914d\uff1b\u5c06\u7ed3\u679c\u6269\u5c55\u5230wEF1\u60c5\u51b5\u3002", "conclusion": "\u4e3a\u4e0d\u53ef\u5206\u4efb\u52a1\u5728\u52a0\u6027\u6210\u672c\u51fd\u6570\u4e0b\u7684\u516c\u5e73\u9ad8\u6548\u5206\u914d\u63d0\u4f9b\u4e86\u7406\u8bba\u7ed3\u679c\u548c\u65b9\u6cd5\u4e0a\u7684\u8fdb\u5c55\u3002"}}
{"id": "2507.09926", "pdf": "https://arxiv.org/pdf/2507.09926", "abs": "https://arxiv.org/abs/2507.09926", "authors": ["Zixuan Song", "Zhishu Shen", "Xiaoyu Zheng", "Qiushi Zheng", "Zheng Lei", "Jiong Jin"], "title": "Intelligent Task Management via Dynamic Multi-region Division in LEO Satellite Networks", "categories": ["cs.DC"], "comment": null, "summary": "As a key complement to terrestrial networks and a fundamental component of\nfuture 6G systems, Low Earth Orbit (LEO) satellite networks are expected to\nprovide high-quality communication services when integrated with ground-based\ninfrastructure, thereby attracting significant research interest. However, the\nlimited satellite onboard resources and the uneven distribution of\ncomputational workloads often result in congestion along inter-satellite links\n(ISLs) that degrades task processing efficiency. Effectively managing the\ndynamic and large-scale topology of LEO networks to ensure balanced task\ndistribution remains a critical challenge. To this end, we propose a dynamic\nmulti-region division framework for intelligent task management in LEO\nsatellite networks. This framework optimizes both intra- and inter-region\nrouting to minimize task delay while balancing the utilization of computational\nand communication resources. Based on this framework, we propose a dynamic\nmulti-region division algorithm based on the Genetic Algorithm (GA), which\nadaptively adjusts the size of each region based on the workload status of\nindividual satellites. Additionally, we incorporate an adaptive routing\nalgorithm and a task splitting and offloading scheme based on Multi-Agent Deep\nDeterministic Policy Gradient (MA-DDPG) to effectively accommodate the arriving\ntasks. Simulation results demonstrate that our proposed framework outperforms\ncomparative methods in terms of the task delay, energy consumption per task,\nand task completion rate.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u4f4e\u8f68\u536b\u661f\u7f51\u7edc\u667a\u80fd\u4efb\u52a1\u7ba1\u7406\u7684\u52a8\u6001\u591a\u533a\u57df\u5212\u5206\u6846\u67b6\u53ca\u7b97\u6cd5\uff0c\u4eff\u771f\u663e\u793a\u5176\u5728\u4efb\u52a1\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u5b8c\u6210\u7387\u4e0a\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\u3002", "motivation": "\u4f4e\u8f68\u536b\u661f\u7f51\u7edc\u4e2d\u536b\u661f\u8d44\u6e90\u6709\u9650\u3001\u8ba1\u7b97\u8d1f\u8f7d\u5206\u5e03\u4e0d\u5747\u5bfc\u81f4\u661f\u95f4\u94fe\u8def\u62e5\u585e\uff0c\u9700\u6709\u6548\u7ba1\u7406\u7f51\u7edc\u62d3\u6251\u4ee5\u5e73\u8861\u4efb\u52a1\u5206\u914d\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u591a\u533a\u57df\u5212\u5206\u6846\u67b6\uff0c\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u52a8\u6001\u591a\u533a\u57df\u5212\u5206\u7b97\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\u7684\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\u548c\u4efb\u52a1\u62c6\u5206\u5378\u8f7d\u65b9\u6848\u3002", "result": "\u4eff\u771f\u8868\u660e\u63d0\u51fa\u7684\u6846\u67b6\u5728\u4efb\u52a1\u5ef6\u8fdf\u3001\u6bcf\u4efb\u52a1\u80fd\u8017\u548c\u4efb\u52a1\u5b8c\u6210\u7387\u65b9\u9762\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u52a8\u6001\u591a\u533a\u57df\u5212\u5206\u6846\u67b6\u53ca\u76f8\u5173\u7b97\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u4f4e\u8f68\u536b\u661f\u7f51\u7edc\u4efb\u52a1\u7ba1\u7406\u95ee\u9898\uff0c\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u3002"}}
{"id": "2507.09090", "pdf": "https://arxiv.org/pdf/2507.09090", "abs": "https://arxiv.org/abs/2507.09090", "authors": ["Anthony Miyaguchi", "Conor Johnston", "Aaryan Potdar"], "title": "DS@GT at Touch\u00e9: Large Language Models for Retrieval-Augmented Debate", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate strong conversational abilities. In\nthis Working Paper, we study them in the context of debating in two ways: their\nability to perform in a structured debate along with a dataset of arguments to\nuse and their ability to evaluate utterances throughout the debate. We deploy\nsix leading publicly available models from three providers for the\nRetrieval-Augmented Debate and Evaluation. The evaluation is performed by\nmeasuring four key metrics: Quality, Quantity, Manner, and Relation. Throughout\nthis task, we found that although LLMs perform well in debates when given\nrelated arguments, they tend to be verbose in responses yet consistent in\nevaluation. The accompanying source code for this paper is located at\nhttps://github.com/dsgt-arc/touche-2025-rad.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fa9\u8bba\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u90e8\u7f72\u516d\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u5176\u5728\u6709\u76f8\u5173\u8bba\u636e\u65f6\u8fa9\u8bba\u8868\u73b0\u597d\uff0c\u4f46\u56de\u5e94\u5197\u957f\u3001\u8bc4\u4f30\u8f83\u4e00\u81f4\u3002", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fa9\u8bba\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u7ed3\u6784\u5316\u8fa9\u8bba\u80fd\u529b\u548c\u8fa9\u8bba\u4e2d\u8bdd\u8bed\u8bc4\u4f30\u80fd\u529b\u3002", "method": "\u90e8\u7f72\u6765\u81ea\u4e09\u4e2a\u4f9b\u5e94\u5546\u7684\u516d\u4e2a\u516c\u5f00\u53ef\u7528\u6a21\u578b\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u8fa9\u8bba\u548c\u8bc4\u4f30\uff0c\u901a\u8fc7\u6d4b\u91cf\u8d28\u91cf\u3001\u6570\u91cf\u3001\u65b9\u5f0f\u548c\u5173\u7cfb\u56db\u4e2a\u5173\u952e\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6709\u76f8\u5173\u8bba\u636e\u65f6\u8fa9\u8bba\u8868\u73b0\u826f\u597d\uff0c\u56de\u5e94\u5197\u957f\uff0c\u8bc4\u4f30\u8f83\u4e00\u81f4\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u603b\u7ed3\u6027\u7ed3\u8bba\uff0c\u4f46\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fa9\u8bba\u65b9\u9762\u7684\u7279\u70b9\u548c\u8868\u73b0\u3002"}}
{"id": "2507.09527", "pdf": "https://arxiv.org/pdf/2507.09527", "abs": "https://arxiv.org/abs/2507.09527", "authors": ["Hang Fan", "Yunze Chai", "Chenxi Liu", "Weican Liu", "Zuhan Zhang", "Wencai Run", "Dunnan Liu"], "title": "EV-STLLM: Electric vehicle charging forecasting based on spatio-temporal large language models with multi-frequency and multi-scale information fusion", "categories": ["cs.CE"], "comment": null, "summary": "With the proliferation of electric vehicles (EVs), accurate charging demand\nand station occupancy forecasting are critical for optimizing urban energy and\nthe profit of EVs aggregator. Existing approaches in this field usually\nstruggle to capture the complex spatio-temporal dependencies in EV charging\nbehaviors, and their limited model parameters hinder their ability to learn\ncomplex data distribution representations from large datasets. To this end, we\npropose a novel EV spatio-temporal large language model (EV-STLLM) for accurate\nprediction. Our proposed framework is divided into two modules. In the data\nprocessing module, we utilize variational mode decomposition (VMD) for data\ndenoising, and improved complete ensemble empirical mode decomposition with\nadaptive noise (ICEEMDAN) for data multi-frequency decomposition. Fuzzy\ninformation granulation (FIG) for extracting multi-scale information.\nAdditionally, ReliefF is used for feature selection to mitigate redundancy. In\nthe forecasting module, the EV-STLLM is used to directly achieve EV charging\nand occupancy forecasting. Firstly, we fully capture the intrinsic\nspatio-temporal characteristics of the data by integrating adjacency matrices\nderived from the regional stations network and spatio-temporal-frequency\nembedding information. Then, the partially frozen graph attention (PFGA) module\nis utilized to maintain the sequential feature modeling capabilities of the\npre-trained large model while incorporating EV domain knowledge. Extensive\nexperiments using real-world data from Shenzhen, China, demonstrate that our\nproposed framework can achieve superior accuracy and robustness compared to the\nstate-of-the-art benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b EV \u65f6\u7a7a\u5927\u8bed\u8a00\u6a21\u578b EV - STLLM \u7528\u4e8e\u51c6\u786e\u9884\u6d4b\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\u548c\u5145\u7535\u7ad9\u5360\u7528\u60c5\u51b5\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u884c\u4e3a\u590d\u6742\u7684\u65f6\u7a7a\u4f9d\u8d56\uff0c\u6709\u9650\u7684\u6a21\u578b\u53c2\u6570\u96be\u4ee5\u4ece\u5927\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u590d\u6742\u6570\u636e\u5206\u5e03\u8868\u793a\uff0c\u9700\u51c6\u786e\u9884\u6d4b\u5145\u7535\u9700\u6c42\u548c\u7ad9\u5360\u7528\u60c5\u51b5\u4ee5\u4f18\u5316\u57ce\u5e02\u80fd\u6e90\u548c\u805a\u5408\u5546\u5229\u6da6\u3002", "method": "\u6846\u67b6\u5206\u4e3a\u6570\u636e\u5904\u7406\u548c\u9884\u6d4b\u4e24\u4e2a\u6a21\u5757\u3002\u6570\u636e\u5904\u7406\u6a21\u5757\u7528 VMD \u53bb\u566a\u3001ICEEMDAN \u591a\u9891\u5206\u89e3\u3001FIG \u63d0\u53d6\u591a\u5c3a\u5ea6\u4fe1\u606f\u3001ReliefF \u7279\u5f81\u9009\u62e9\uff1b\u9884\u6d4b\u6a21\u5757\u7528 EV - STLLM \u9884\u6d4b\uff0c\u901a\u8fc7\u6574\u5408\u90bb\u63a5\u77e9\u9635\u548c\u65f6\u7a7a\u9891\u7387\u5d4c\u5165\u4fe1\u606f\u6355\u6349\u6570\u636e\u7279\u5f81\uff0c\u7528 PFGA \u6a21\u5757\u7ed3\u5408\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u548c\u9886\u57df\u77e5\u8bc6\u3002", "result": "\u4f7f\u7528\u4e2d\u56fd\u6df1\u5733\u771f\u5b9e\u6570\u636e\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u6bd4\u73b0\u6709\u57fa\u51c6\u6a21\u578b\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684 EV - STLLM \u6846\u67b6\u5728\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u9700\u6c42\u548c\u7ad9\u5360\u7528\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2507.09448", "pdf": "https://arxiv.org/pdf/2507.09448", "abs": "https://arxiv.org/abs/2507.09448", "authors": ["Pramod Chunduri", "Yao Lu", "Joy Arulraj"], "title": "TRACER: Efficient Object Re-Identification in Networked Cameras through Adaptive Query Processing", "categories": ["cs.DB", "cs.CV"], "comment": null, "summary": "Efficiently re-identifying and tracking objects across a network of cameras\nis crucial for applications like traffic surveillance. Spatula is the\nstate-of-the-art video database management system (VDBMS) for processing Re-ID\nqueries. However, it suffers from two limitations. Its spatio-temporal\nfiltering scheme has limited accuracy on large camera networks due to localized\ncamera history. It is not suitable for critical video analytics applications\nthat require high recall due to a lack of support for adaptive query\nprocessing.\n  In this paper, we present Tracer, a novel VDBMS for efficiently processing\nRe-ID queries using an adaptive query processing framework. Tracer selects the\noptimal camera to process at each time step by training a recurrent network to\nmodel long-term historical correlations. To accelerate queries under a high\nrecall constraint, Tracer incorporates a probabilistic adaptive search model\nthat processes camera feeds in incremental search windows and dynamically\nupdates the sampling probabilities using an exploration-exploitation strategy.\nTo address the paucity of benchmarks for the Re-ID task due to privacy\nconcerns, we present a novel synthetic benchmark for generating multi-camera\nRe-ID datasets based on real-world traffic distribution. Our evaluation shows\nthat Tracer outperforms the state-of-the-art cross-camera analytics system by\n3.9x on average across diverse datasets.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u89c6\u9891\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edfTracer\u5904\u7406Re - ID\u67e5\u8be2\uff0c\u6709\u81ea\u9002\u5e94\u67e5\u8be2\u6846\u67b6\uff0c\u8fd8\u7ed9\u51fa\u5408\u6210\u57fa\u51c6\uff0c\u6027\u80fd\u8d85\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709Spatula\u7cfb\u7edf\u5728\u5904\u7406Re - ID\u67e5\u8be2\u65f6\u6709\u7cbe\u5ea6\u548c\u81ea\u9002\u5e94\u67e5\u8be2\u5904\u7406\u65b9\u9762\u7684\u5c40\u9650\uff0c\u4e0d\u9002\u5408\u9ad8\u53ec\u56de\u8981\u6c42\u7684\u5e94\u7528\u3002", "method": "\u7528\u81ea\u9002\u5e94\u67e5\u8be2\u5904\u7406\u6846\u67b6\uff0c\u8bad\u7ec3\u5faa\u73af\u7f51\u7edc\u9009\u6700\u4f18\u76f8\u673a\uff0c\u91c7\u7528\u6982\u7387\u81ea\u9002\u5e94\u641c\u7d22\u6a21\u578b\uff0c\u63d0\u51fa\u5408\u6210\u57fa\u51c6\u751f\u6210\u591a\u76f8\u673aRe - ID\u6570\u636e\u96c6\u3002", "result": "Tracer\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u6bd4\u73b0\u6709\u8de8\u76f8\u673a\u5206\u6790\u7cfb\u7edf\u6027\u80fd\u9ad83.9\u500d\u3002", "conclusion": "Tracer\u5728\u5904\u7406Re - ID\u67e5\u8be2\u4e0a\u6bd4\u73b0\u6709\u7cfb\u7edf\u66f4\u9ad8\u6548\u3002"}}
{"id": "2507.09847", "pdf": "https://arxiv.org/pdf/2507.09847", "abs": "https://arxiv.org/abs/2507.09847", "authors": ["Amin Abdollahi Dehkordi", "Mehdi Neshat", "Nataliia Y. Sergiienko", "Zahra Ghasemi", "Lei Chen", "John Boland", "Hamid Moradkhani", "Amir H. Gandomi"], "title": "Effective Self-Attention-Based Deep Learning Model with Evolutionary Grid Search for Robust Wave Farm Energy Forecasting", "categories": ["cs.NE"], "comment": null, "summary": "Achieving carbon neutrality, a key focus of UN SDG #13, drives the\nexploration of wave energy, a renewable resource with the potential to generate\n30,000 TWh of clean electricity annually, surpassing global demand. However,\nwave energy remains underdeveloped due to technical and economic challenges,\nparticularly in forecasting wave farm power output, which is vital for grid\nstability and commercial viability. This study proposes a novel predictive\nframework to enhance wave energy integration into power grids. It introduces a\nhybrid sequential learning model combining Self-Attention-enhanced\nConvolutional Bi-LSTM with hyperparameter optimization. The model leverages\nspatial data from Wave Energy Converters (WECs) and is validated using datasets\nfrom wave farms in Adelaide, Sydney, Perth, and Tasmania, Australia.\nBenchmarked against ten machine learning algorithms, the model achieves\nsuperior accuracy, with R2 scores of 91.7% (Adelaide), 88.0% (Perth), 82.8%\n(Tasmania), and 91.0% (Sydney). It outperforms conventional ML and deep\nlearning methods, offering robust and scalable predictions for wave energy\noutput across diverse marine environments, supporting reliable integration into\nenergy systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6df7\u5408\u987a\u5e8f\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6ce2\u6d6a\u80fd\u8f93\u51fa\uff0c\u5728\u591a\u5730\u9a8c\u8bc1\u6548\u679c\u4f18\uff0c\u652f\u6301\u6ce2\u6d6a\u80fd\u5e76\u5165\u7535\u7f51\u3002", "motivation": "\u5b9e\u73b0\u78b3\u4e2d\u548c\u4fc3\u4f7f\u63a2\u7d22\u6ce2\u6d6a\u80fd\uff0c\u4f46\u6ce2\u6d6a\u80fd\u56e0\u6280\u672f\u548c\u7ecf\u6d4e\u6311\u6218\u672a\u5145\u5206\u5f00\u53d1\uff0c\u51c6\u786e\u9884\u6d4b\u6ce2\u6d6a\u80fd\u8f93\u51fa\u5bf9\u7535\u7f51\u7a33\u5b9a\u548c\u5546\u4e1a\u53ef\u884c\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u589e\u5f3a\u5377\u79ef\u53cc\u5411LSTM\u548c\u8d85\u53c2\u6570\u4f18\u5316\u7684\u6df7\u5408\u987a\u5e8f\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528\u6ce2\u6d6a\u80fd\u8f6c\u6362\u5668\u7a7a\u95f4\u6570\u636e\u3002", "result": "\u6a21\u578b\u5728\u963f\u5fb7\u83b1\u5fb7\u3001\u73c0\u65af\u3001\u5854\u65af\u9a6c\u5c3c\u4e9a\u548c\u6089\u5c3c\u7b49\u5730\u6ce2\u6d6a\u519c\u573a\u6570\u636e\u96c6\u9a8c\u8bc1\uff0cR2\u5f97\u5206\u5206\u522b\u8fbe91.7%\u300188.0%\u300182.8%\u548c91.0%\uff0c\u4f18\u4e8e\u5341\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002", "conclusion": "\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u4e3a\u4e0d\u540c\u6d77\u6d0b\u73af\u5883\u6ce2\u6d6a\u80fd\u8f93\u51fa\u63d0\u4f9b\u53ef\u9760\u53ef\u6269\u5c55\u9884\u6d4b\uff0c\u652f\u6301\u5176\u53ef\u9760\u5e76\u5165\u80fd\u6e90\u7cfb\u7edf\u3002"}}
{"id": "2507.08892", "pdf": "https://arxiv.org/pdf/2507.08892", "abs": "https://arxiv.org/abs/2507.08892", "authors": ["Alexander Sasha Vezhnevets", "Jayd Matyas", "Logan Cross", "Davide Paglieri", "Minsuk Chang", "William A. Cunningham", "Simon Osindero", "William S. Isaac", "Joel Z. Leibo"], "title": "Multi-Actor Generative Artificial Intelligence as a Game Engine", "categories": ["cs.AI", "cs.MA"], "comment": "13 pages", "summary": "Generative AI can be used in multi-actor environments with purposes ranging\nfrom social science modeling to interactive narrative and AI evaluation.\nSupporting this diversity of use cases -- which we classify as Simulationist,\nDramatist, and Evaluationist -- demands a flexible scenario definition\nframework. We argue here that a good approach is to take inspiration from\ntabletop role-playing games (TTRPGs), where a Game Master (GM) is responsible\nfor the environment and generates all parts of the story not directly\ndetermined by the voluntary actions of player characters. We argue that the\nEntity-Component architectural pattern is useful here. In such a system, the GM\nis not a hardcoded computer game but is itself a configurable entity, composed\nof components just like any other actor. By design, the approach allows for a\nseparation between the underlying implementation details handled by an\nengineer, the creation of reusable components, and their composition and\nconfiguration managed by a designer who constructs entities from the\ncomponents. This separation of concerns is instrumental for achieving rapid\niteration, maintaining modularity, and ultimately to ensure scalability. We\ndescribe the ongoing evolution of the Concordia library in terms of this\nphilosophy, demonstrating how it allows users to effectively configure\nscenarios that align with their specific goals.", "AI": {"tldr": "\u63d0\u51fa\u501f\u9274\u684c\u9762\u89d2\u8272\u626e\u6f14\u6e38\u620f\uff0c\u5229\u7528\u5b9e\u4f53 - \u7ec4\u4ef6\u67b6\u6784\u6a21\u5f0f\u6784\u5efa\u7075\u6d3b\u573a\u666f\u5b9a\u4e49\u6846\u67b6\uff0c\u4ee5\u652f\u6301\u751f\u6210\u5f0fAI\u5728\u591a\u89d2\u8272\u73af\u5883\u7684\u591a\u6837\u7528\u4f8b\uff0c\u5e76\u4ecb\u7ecdConcordia\u5e93\u7684\u53d1\u5c55\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u591a\u89d2\u8272\u73af\u5883\u6709\u591a\u6837\u7528\u4f8b\uff0c\u9700\u8981\u7075\u6d3b\u7684\u573a\u666f\u5b9a\u4e49\u6846\u67b6\u3002", "method": "\u501f\u9274\u684c\u9762\u89d2\u8272\u626e\u6f14\u6e38\u620f\uff0c\u91c7\u7528\u5b9e\u4f53 - \u7ec4\u4ef6\u67b6\u6784\u6a21\u5f0f\uff0c\u5206\u79bb\u5de5\u7a0b\u5e08\u548c\u8bbe\u8ba1\u5e08\u7684\u5de5\u4f5c\u3002", "result": "\u63cf\u8ff0\u4e86Concordia\u5e93\u6309\u6b64\u7406\u5ff5\u7684\u6301\u7eed\u53d1\u5c55\uff0c\u53ef\u8ba9\u7528\u6237\u6709\u6548\u914d\u7f6e\u7b26\u5408\u7279\u5b9a\u76ee\u6807\u7684\u573a\u666f\u3002", "conclusion": "\u8be5\u5206\u79bb\u5173\u6ce8\u70b9\u7684\u65b9\u6cd5\u6709\u52a9\u4e8e\u5b9e\u73b0\u5feb\u901f\u8fed\u4ee3\u3001\u4fdd\u6301\u6a21\u5757\u5316\u548c\u786e\u4fdd\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2507.09631", "pdf": "https://arxiv.org/pdf/2507.09631", "abs": "https://arxiv.org/abs/2507.09631", "authors": ["Jianing Zhi", "Xinghua Li", "Zidong Chen"], "title": "Integrated Warehouse Location and Inventory Decisions in a Multi-location Newsvendor Problem", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "In this paper, we investigate a supply chain network with a supplier and\nmultiple retailers. The supplier can either take orders from retailers\ndirectly, or choose to build a warehouse somewhere in the network to centralize\nthe ordering from retailers. Meanwhile, we take three modes of transportation\ncost into account, including distance-dependent, quantity-dependent, and\ndistance-quantity-dependent costs, to formulate six models. For the three\ndecentralized models, we provide closed-form solutions to compute the optimal\norder quantity of each retailer. For the centralized models, we develop\nclosed-form solutions for the first two models as the transportation cost only\ndepends on either distance or order quantity; but when it depends on both, the\nmodel becomes a non-linear programming problem. We develop a solution algorithm\nnamed Q-search to find a high-quality solution that includes the order quantity\nand the warehouse location. The experiment results show that the centralized\nmodel outperforms the decentralized model in large networks in terms of profit\nand service level.", "AI": {"tldr": "\u7814\u7a76\u542b\u4f9b\u5e94\u5546\u548c\u591a\u96f6\u552e\u5546\u7684\u4f9b\u5e94\u94fe\u7f51\u7edc\uff0c\u8003\u8651\u4e09\u79cd\u8fd0\u8f93\u6210\u672c\u6784\u5efa\u516d\u4e2a\u6a21\u578b\uff0c\u7ed9\u51fa\u90e8\u5206\u6a21\u578b\u95ed\u5f0f\u89e3\uff0c\u4e3a\u975e\u7ebf\u6027\u95ee\u9898\u5f00\u53d1Q - \u641c\u7d22\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u96c6\u4e2d\u5f0f\u6a21\u578b\u5728\u5927\u578b\u7f51\u7edc\u4e2d\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u4f9b\u5e94\u94fe\u7f51\u7edc\u4e2d\u4f9b\u5e94\u5546\u76f4\u63a5\u63a5\u5355\u548c\u5efa\u4ed3\u5e93\u96c6\u4e2d\u63a5\u5355\u4e24\u79cd\u6a21\u5f0f\u4e0b\u7684\u6700\u4f18\u51b3\u7b56\uff0c\u8003\u8651\u4e0d\u540c\u8fd0\u8f93\u6210\u672c\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u516d\u4e2a\u6a21\u578b\uff0c\u4e3a\u90e8\u5206\u5206\u6563\u5f0f\u548c\u96c6\u4e2d\u5f0f\u6a21\u578b\u63d0\u4f9b\u95ed\u5f0f\u89e3\uff0c\u4e3a\u975e\u7ebf\u6027\u7684\u96c6\u4e2d\u5f0f\u6a21\u578b\u5f00\u53d1Q - \u641c\u7d22\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u96c6\u4e2d\u5f0f\u6a21\u578b\u5728\u5927\u578b\u7f51\u7edc\u7684\u5229\u6da6\u548c\u670d\u52a1\u6c34\u5e73\u4e0a\u4f18\u4e8e\u5206\u6563\u5f0f\u6a21\u578b\u3002", "conclusion": "\u5728\u5927\u578b\u4f9b\u5e94\u94fe\u7f51\u7edc\u4e2d\uff0c\u96c6\u4e2d\u5f0f\u8ba2\u5355\u5904\u7406\u6a21\u5f0f\uff08\u5efa\u4ed3\u5e93\u96c6\u4e2d\u63a5\u5355\uff09\u5728\u5229\u6da6\u548c\u670d\u52a1\u6c34\u5e73\u65b9\u9762\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2507.09790", "pdf": "https://arxiv.org/pdf/2507.09790", "abs": "https://arxiv.org/abs/2507.09790", "authors": ["Helge Spieker", "Th\u00e9o Matricon", "Nassim Belmecheri", "J\u00f8rn Eirik Betten", "Gauthier Le Bartz Lyan", "Heraldo Borges", "Quentin Mazouni", "Dennis Gross", "Arnaud Gotlieb", "Mathieu Acher"], "title": "Prompting for Performance: Exploring LLMs for Configuring Software", "categories": ["cs.SE", "cs.AI", "cs.PF"], "comment": null, "summary": "Software systems usually provide numerous configuration options that can\naffect performance metrics such as execution time, memory usage, binary size,\nor bitrate. On the one hand, making informed decisions is challenging and\nrequires domain expertise in options and their combinations. On the other hand,\nmachine learning techniques can search vast configuration spaces, but with a\nhigh computational cost, since concrete executions of numerous configurations\nare required. In this exploratory study, we investigate whether large language\nmodels (LLMs) can assist in performance-oriented software configuration through\nprompts. We evaluate several LLMs on tasks including identifying relevant\noptions, ranking configurations, and recommending performant configurations\nacross various configurable systems, such as compilers, video encoders, and SAT\nsolvers. Our preliminary results reveal both positive abilities and notable\nlimitations: depending on the task and systems, LLMs can well align with expert\nknowledge, whereas hallucinations or superficial reasoning can emerge in other\ncases. These findings represent a first step toward systematic evaluations and\nthe design of LLM-based solutions to assist with software configuration.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u5426\u901a\u8fc7\u63d0\u793a\u8f85\u52a9\u9762\u5411\u6027\u80fd\u7684\u8f6f\u4ef6\u914d\u7f6e\uff0c\u8bc4\u4f30\u5176\u5728\u591a\u79cd\u4efb\u52a1\u548c\u7cfb\u7edf\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u6709\u79ef\u6781\u80fd\u529b\u4e5f\u6709\u660e\u663e\u5c40\u9650\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u914d\u7f6e\u9009\u9879\u51b3\u7b56\u96be\u4e14\u673a\u5668\u5b66\u4e60\u6280\u672f\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u8f6f\u4ef6\u914d\u7f6e\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5728\u7f16\u8bd1\u5668\u3001\u89c6\u9891\u7f16\u7801\u5668\u548cSAT\u6c42\u89e3\u5668\u7b49\u591a\u79cd\u53ef\u914d\u7f6e\u7cfb\u7edf\u4e0a\uff0c\u5bf9\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc6\u522b\u76f8\u5173\u9009\u9879\u3001\u914d\u7f6e\u6392\u5e8f\u548c\u63a8\u8350\u9ad8\u6027\u80fd\u914d\u7f6e\u7b49\u4efb\u52a1\u7684\u8bc4\u4f30\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u67d0\u4e9b\u4efb\u52a1\u548c\u7cfb\u7edf\u4e0a\u4e0e\u4e13\u5bb6\u77e5\u8bc6\u5951\u5408\u5ea6\u9ad8\uff0c\u4f46\u4e5f\u4f1a\u51fa\u73b0\u5e7b\u89c9\u6216\u6d45\u5c42\u63a8\u7406\u7b49\u60c5\u51b5\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u914d\u7f6e\u89e3\u51b3\u65b9\u6848\u8bbe\u8ba1\u8fc8\u51fa\u4e86\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2507.09507", "pdf": "https://arxiv.org/pdf/2507.09507", "abs": "https://arxiv.org/abs/2507.09507", "authors": ["Moran Feldman", "Ola Svensson", "Rico Zenklusen"], "title": "Nearly Tight Sample Complexity for Matroid Online Contention Resolution", "categories": ["cs.DS", "cs.DM", "cs.GT", "68W27 (Primary) 91A68, 68R05 (Secondary)", "F.2.2; G.2.1"], "comment": "24 pages", "summary": "Due to their numerous applications, in particular in Mechanism Design,\nProphet Inequalities have experienced a surge of interest. They describe\ncompetitive ratios for basic stopping time problems where random variables get\nrevealed sequentially. A key drawback in the classical setting is the\nassumption of full distributional knowledge of the involved random variables,\nwhich is often unrealistic. A natural way to address this is via sample-based\napproaches, where only a limited number of samples from the distribution of\neach random variable is available. Recently, Fu, Lu, Gavin Tang, Wu, Wu, and\nZhang (2024) showed that sample-based Online Contention Resolution Schemes\n(OCRS) are a powerful tool to obtain sample-based Prophet Inequalities. They\npresented the first sample-based OCRS for matroid constraints, which is a\nheavily studied constraint family in this context, as it captures many\ninteresting settings. This allowed them to get the first sample-based Matroid\nProphet Inequality, using $O(\\log^4 n)$ many samples (per random variable),\nwhere $n$ is the number of random variables, while obtaining a constant\ncompetitiveness of $\\frac{1}{4}-\\varepsilon$.\n  We present a nearly optimal sample-based OCRS for matroid constraints, which\nuses only $O(\\log \\rho \\cdot \\log^2\\log\\rho)$ many samples, almost matching a\nknown lower bound of $\\Omega(\\log \\rho)$, where $\\rho \\leq n$ is the rank of\nthe matroid. Through the above-mentioned connection to Prophet Inequalities,\nthis yields a sample-based Matroid Prophet Inequality using only $O(\\log n +\n\\log\\rho \\cdot \\log^2\\log\\rho)$ many samples, and matching the competitiveness\nof $\\frac{1}{4}-\\varepsilon$, which is the best known competitiveness for the\nconsidered almighty adversary setting even when the distributions are fully\nknown.", "AI": {"tldr": "\u6587\u7ae0\u805a\u7126\u6837\u672c\u57fa\u5148\u77e5\u4e0d\u7b49\u5f0f\uff0c\u5148\u4ecb\u7ecd\u524d\u4eba\u6210\u679c\uff0c\u540e\u63d0\u51fa\u8fd1\u6700\u4f18\u6837\u672c\u57faOCRS\u7528\u4e8e\u62df\u9635\u7ea6\u675f\uff0c\u6240\u9700\u6837\u672c\u6570\u63a5\u8fd1\u4e0b\u754c\uff0c\u5f97\u5230\u6837\u672c\u57fa\u62df\u9635\u5148\u77e5\u4e0d\u7b49\u5f0f\u4e14\u7ade\u4e89\u529b\u4f18\u3002", "motivation": "\u7ecf\u5178\u5148\u77e5\u4e0d\u7b49\u5f0f\u5047\u8bbe\u968f\u673a\u53d8\u91cf\u5206\u5e03\u77e5\u8bc6\u5168\u77e5\u4e0d\u73b0\u5b9e\uff0c\u9700\u57fa\u4e8e\u6837\u672c\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u8fd1\u6700\u4f18\u6837\u672c\u57faOCRS\u7528\u4e8e\u62df\u9635\u7ea6\u675f\uff0c\u5229\u7528\u5176\u4e0e\u5148\u77e5\u4e0d\u7b49\u5f0f\u7684\u8054\u7cfb\u5f97\u51fa\u7ed3\u679c\u3002", "result": "\u63d0\u51fa\u7684OCRS\u4ec5\u9700 $O(\\log \\rho \\cdot \\log^2\\log\\rho)$ \u4e2a\u6837\u672c\uff0c\u63a5\u8fd1\u5df2\u77e5\u4e0b\u754c\uff1b\u5f97\u5230\u4f7f\u7528 $O(\\log n + \\log\\rho \\cdot \\log^2\\log\\rho)$ \u4e2a\u6837\u672c\u7684\u6837\u672c\u57fa\u62df\u9635\u5148\u77e5\u4e0d\u7b49\u5f0f\uff0c\u7ade\u4e89\u529b\u8fbe $\\frac{1}{4}-\\varepsilon$\u3002", "conclusion": "\u8be5\u6837\u672c\u57faOCRS\u63a5\u8fd1\u6700\u4f18\uff0c\u80fd\u4ee5\u8f83\u5c11\u6837\u672c\u83b7\u5f97\u826f\u597d\u7ade\u4e89\u529b\u7684\u6837\u672c\u57fa\u62df\u9635\u5148\u77e5\u4e0d\u7b49\u5f0f\u3002"}}
{"id": "2507.09023", "pdf": "https://arxiv.org/pdf/2507.09023", "abs": "https://arxiv.org/abs/2507.09023", "authors": ["Yao Fehlis", "Charles Crain", "Aidan Jensen", "Michael Watson", "James Juhasz", "Paul Mandel", "Betty Liu", "Shawn Mahon", "Daren Wilson", "Nick Lynch-Jonely", "Ben Leedom", "David Fuller"], "title": "Accelerating Drug Discovery Through Agentic AI: A Multi-Agent Approach to Laboratory Automation in the DMTA Cycle", "categories": ["cs.SE", "cs.AI", "cs.MA"], "comment": null, "summary": "The pharmaceutical industry faces unprecedented challenges in drug discovery,\nwith traditional approaches struggling to meet modern therapeutic development\ndemands. This paper introduces a novel AI framework, Tippy, that transforms\nlaboratory automation through specialized AI agents operating within the\nDesign-Make-Test-Analyze (DMTA) cycle. Our multi-agent system employs five\nspecialized agents - Supervisor, Molecule, Lab, Analysis, and Report, with\nSafety Guardrail oversight - each designed to excel in specific phases of the\ndrug discovery pipeline. Tippy represents the first production-ready\nimplementation of specialized AI agents for automating the DMTA cycle,\nproviding a concrete example of how AI can transform laboratory workflows. By\nleveraging autonomous AI agents that reason, plan, and collaborate, we\ndemonstrate how Tippy accelerates DMTA cycles while maintaining scientific\nrigor essential for pharmaceutical research. The system shows significant\nimprovements in workflow efficiency, decision-making speed, and\ncross-disciplinary coordination, offering a new paradigm for AI-assisted drug\ndiscovery.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u540d\u4e3aTippy\u7684\u65b0\u578bAI\u6846\u67b6\uff0c\u53ef\u901a\u8fc7\u4e13\u95e8\u7684AI\u4ee3\u7406\u8f6c\u53d8\u5b9e\u9a8c\u5ba4\u81ea\u52a8\u5316\uff0c\u5728\u836f\u7269\u53d1\u73b0\u7684DMTA\u5faa\u73af\u4e2d\u63d0\u5347\u6548\u7387\uff0c\u4e3aAI\u8f85\u52a9\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002", "motivation": "\u5236\u836f\u884c\u4e1a\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u9762\u4e34\u524d\u6240\u672a\u6709\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u73b0\u4ee3\u6cbb\u7597\u53d1\u5c55\u9700\u6c42\u3002", "method": "\u5f15\u5165\u540d\u4e3aTippy\u7684AI\u6846\u67b6\uff0c\u91c7\u7528\u5305\u542b\u4e94\u4e2a\u4e13\u95e8\u4ee3\u7406\u548c\u5b89\u5168\u62a4\u680f\u76d1\u7763\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5404\u4ee3\u7406\u5728\u836f\u7269\u53d1\u73b0\u6d41\u7a0b\u7684\u7279\u5b9a\u9636\u6bb5\u53d1\u6325\u4f5c\u7528\u3002", "result": "Tippy\u7cfb\u7edf\u5728\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\u3001\u51b3\u7b56\u901f\u5ea6\u548c\u8de8\u5b66\u79d1\u534f\u8c03\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Tippy\u4f5c\u4e3a\u9996\u4e2a\u7528\u4e8e\u81ea\u52a8\u5316DMTA\u5faa\u73af\u7684\u4e13\u4e1a\u5316AI\u4ee3\u7406\u7684\u751f\u4ea7\u5c31\u7eea\u5b9e\u73b0\uff0c\u4e3aAI\u8f85\u52a9\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.08832", "pdf": "https://arxiv.org/pdf/2507.08832", "abs": "https://arxiv.org/abs/2507.08832", "authors": ["Niranjan Mallikarjun Sindhur", "Pavithra C", "Nivya Muchikel"], "title": "A Hybrid Machine Learning Framework for Optimizing Crop Selection via Agronomic and Economic Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Farmers in developing regions like Karnataka, India, face a dual challenge:\nnavigating extreme market and climate volatility while being excluded from the\ndigital revolution due to literacy barriers. This paper presents a novel\ndecision support system that addresses both challenges through a unique\nsynthesis of machine learning and human-computer interaction. We propose a\nhybrid recommendation engine that integrates two predictive models: a Random\nForest classifier to assess agronomic suitability based on soil, climate, and\nreal-time weather data, and a Long Short-Term Memory (LSTM) network to forecast\nmarket prices for agronomically viable crops. This integrated approach shifts\nthe paradigm from \"what can grow?\" to \"what is most profitable to grow?\",\nproviding a significant advantage in mitigating economic risk. The system is\ndelivered through an end-to-end, voice-based interface in the local Kannada\nlanguage, leveraging fine-tuned speech recognition and high-fidelity speech\nsynthesis models to ensure accessibility for low-literacy users. Our results\nshow that the Random Forest model achieves 98.5% accuracy in suitability\nprediction, while the LSTM model forecasts harvest-time prices with a low\nmargin of error. By providing data-driven, economically optimized\nrecommendations through an inclusive interface, this work offers a scalable and\nimpactful solution to enhance the financial resilience of marginalized farming\ncommunities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u4e0e\u4eba\u673a\u4ea4\u4e92\uff0c\u901a\u8fc7\u8bed\u97f3\u754c\u9762\u4e3a\u5370\u5ea6\u5361\u7eb3\u5854\u514b\u90a6\u519c\u6c11\u63d0\u4f9b\u4f5c\u7269\u79cd\u690d\u5efa\u8bae\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u589e\u5f3a\u519c\u6c11\u8d22\u52a1\u97e7\u6027\u3002", "motivation": "\u89e3\u51b3\u5370\u5ea6\u5361\u7eb3\u5854\u514b\u90a6\u519c\u6c11\u9762\u4e34\u7684\u5e02\u573a\u548c\u6c14\u5019\u6ce2\u52a8\uff0c\u4ee5\u53ca\u56e0\u8bc6\u5b57\u969c\u788d\u88ab\u6392\u9664\u5728\u6570\u5b57\u9769\u547d\u4e4b\u5916\u7684\u53cc\u91cd\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u63a8\u8350\u5f15\u64ce\uff0c\u96c6\u6210\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff0c\u901a\u8fc7\u57fa\u4e8e\u8bed\u97f3\u7684\u672c\u5730\u8bed\u8a00\u754c\u9762\u63d0\u4f9b\u670d\u52a1\u3002", "result": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u9002\u5b9c\u6027\u9884\u6d4b\u4e2d\u8fbe\u523098.5%\u7684\u51c6\u786e\u7387\uff0c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u6a21\u578b\u9884\u6d4b\u6536\u83b7\u65f6\u4ef7\u683c\u8bef\u5dee\u5c0f\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u5305\u5bb9\u6027\u754c\u9762\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u3001\u7ecf\u6d4e\u4f18\u5316\u7684\u5efa\u8bae\uff0c\u662f\u589e\u5f3a\u8fb9\u7f18\u5316\u519c\u4e1a\u793e\u533a\u8d22\u52a1\u97e7\u6027\u7684\u53ef\u6269\u5c55\u4e14\u6709\u5f71\u54cd\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10303", "pdf": "https://arxiv.org/pdf/2507.10303", "abs": "https://arxiv.org/abs/2507.10303", "authors": ["K. Giannoukou", "X. Zhu", "S. Marelli", "B. Sudret"], "title": "MF-GLaM: A multifidelity stochastic emulator using generalized lambda models", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "comment": null, "summary": "Stochastic simulators exhibit intrinsic stochasticity due to unobservable,\nuncontrollable, or unmodeled input variables, resulting in random outputs even\nat fixed input conditions. Such simulators are common across various scientific\ndisciplines; however, emulating their entire conditional probability\ndistribution is challenging, as it is a task traditional deterministic\nsurrogate modeling techniques are not designed for. Additionally, accurately\ncharacterizing the response distribution can require prohibitively large\ndatasets, especially for computationally expensive high-fidelity (HF)\nsimulators. When lower-fidelity (LF) stochastic simulators are available, they\ncan enhance limited HF information within a multifidelity surrogate modeling\n(MFSM) framework. While MFSM techniques are well-established for deterministic\nsettings, constructing multifidelity emulators to predict the full conditional\nresponse distribution of stochastic simulators remains a challenge. In this\npaper, we propose multifidelity generalized lambda models (MF-GLaMs) to\nefficiently emulate the conditional response distribution of HF stochastic\nsimulators by exploiting data from LF stochastic simulators. Our approach\nbuilds upon the generalized lambda model (GLaM), which represents the\nconditional distribution at each input by a flexible, four-parameter\ngeneralized lambda distribution. MF-GLaMs are non-intrusive, requiring no\naccess to the internal stochasticity of the simulators nor multiple\nreplications of the same input values. We demonstrate the efficacy of MF-GLaM\nthrough synthetic examples of increasing complexity and a realistic earthquake\napplication. Results show that MF-GLaMs can achieve improved accuracy at the\nsame cost as single-fidelity GLaMs, or comparable performance at significantly\nreduced cost.", "AI": {"tldr": "\u63d0\u51fa\u591a\u4fdd\u771f\u5e7f\u4e49 lambda \u6a21\u578b\uff08MF - GLaMs\uff09\u6765\u6709\u6548\u6a21\u62df\u9ad8\u4fdd\u771f\u968f\u673a\u6a21\u62df\u5668\u7684\u6761\u4ef6\u54cd\u5e94\u5206\u5e03\uff0c\u901a\u8fc7\u5408\u6210\u793a\u4f8b\u548c\u5b9e\u9645\u5730\u9707\u5e94\u7528\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u673a\u6a21\u62df\u5668\u8f93\u51fa\u6709\u968f\u673a\u6027\uff0c\u4f20\u7edf\u786e\u5b9a\u6027\u4ee3\u7406\u5efa\u6a21\u6280\u672f\u96be\u6a21\u62df\u5176\u6761\u4ef6\u6982\u7387\u5206\u5e03\uff0c\u51c6\u786e\u8868\u5f81\u54cd\u5e94\u5206\u5e03\u9700\u5927\u91cf\u6570\u636e\uff0c\u6784\u5efa\u591a\u4fdd\u771f\u6a21\u62df\u5668\u9884\u6d4b\u968f\u673a\u6a21\u62df\u5668\u5b8c\u6574\u6761\u4ef6\u54cd\u5e94\u5206\u5e03\u4ecd\u5177\u6311\u6218\u3002", "method": "\u63d0\u51fa MF - GLaMs\uff0c\u57fa\u4e8e\u5e7f\u4e49 lambda \u6a21\u578b\uff08GLaM\uff09\uff0c\u5229\u7528\u4f4e\u4fdd\u771f\u968f\u673a\u6a21\u62df\u5668\u6570\u636e\uff0c\u4e14\u8be5\u65b9\u6cd5\u975e\u4fb5\u5165\u5f0f\u3002", "result": "\u901a\u8fc7\u5408\u6210\u793a\u4f8b\u548c\u5730\u9707\u5e94\u7528\u8868\u660e\uff0cMF - GLaMs \u5728\u4e0e\u5355\u4fdd\u771f GLaMs \u76f8\u540c\u6210\u672c\u4e0b\u53ef\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u6216\u5728\u663e\u8457\u964d\u4f4e\u6210\u672c\u65f6\u53d6\u5f97\u76f8\u5f53\u6027\u80fd\u3002", "conclusion": "MF - GLaMs \u80fd\u6709\u6548\u6a21\u62df\u9ad8\u4fdd\u771f\u968f\u673a\u6a21\u62df\u5668\u7684\u6761\u4ef6\u54cd\u5e94\u5206\u5e03\uff0c\u5728\u6210\u672c\u548c\u7cbe\u5ea6\u4e0a\u6709\u4f18\u52bf\u3002"}}
{"id": "2507.08835", "pdf": "https://arxiv.org/pdf/2507.08835", "abs": "https://arxiv.org/abs/2507.08835", "authors": ["Harold Gu\u00e9neau", "Alain Celisse", "Pascal Delange"], "title": "Representation learning with a transformer by contrastive learning for money laundering detection", "categories": ["cs.LG", "cs.AI", "math.ST", "q-fin.RM", "q-fin.ST", "stat.TH"], "comment": null, "summary": "The present work tackles the money laundering detection problem. A new\nprocedure is introduced which exploits structured time series of both\nqualitative and quantitative data by means of a transformer neural network. The\nfirst step of this procedure aims at learning representations of time series\nthrough contrastive learning (without any labels). The second step leverages\nthese representations to generate a money laundering scoring of all\nobservations. A two-thresholds approach is then introduced, which ensures a\ncontrolled false-positive rate by means of the Benjamini-Hochberg (BH)\nprocedure. Experiments confirm that the transformer is able to produce general\nrepresentations that succeed in exploiting money laundering patterns with\nminimal supervision from domain experts. It also illustrates the higher ability\nof the new procedure for detecting nonfraudsters as well as fraudsters, while\nkeeping the false positive rate under control. This greatly contrasts with\nrule-based procedures or the ones based on LSTM architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u7a0b\u5e8f\u5229\u7528Transformer\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u6d17\u94b1\u68c0\u6d4b\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u7a0b\u5e8f\u80fd\u5728\u5c11\u76d1\u7763\u4e0b\u5229\u7528\u6d17\u94b1\u6a21\u5f0f\uff0c\u68c0\u6d4b\u80fd\u529b\u5f3a\u4e14\u80fd\u63a7\u5236\u8bef\u62a5\u7387\u3002", "motivation": "\u89e3\u51b3\u6d17\u94b1\u68c0\u6d4b\u95ee\u9898\u3002", "method": "\u5f15\u5165\u65b0\u7a0b\u5e8f\uff0c\u7b2c\u4e00\u6b65\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u8868\u793a\uff0c\u7b2c\u4e8c\u6b65\u5229\u7528\u8868\u793a\u751f\u6210\u6d17\u94b1\u8bc4\u5206\uff0c\u91c7\u7528\u53cc\u9608\u503c\u65b9\u6cd5\u5e76\u7ed3\u5408Benjamini - Hochberg\u7a0b\u5e8f\u63a7\u5236\u8bef\u62a5\u7387\u3002", "result": "Transformer\u80fd\u4ea7\u751f\u901a\u7528\u8868\u793a\uff0c\u6210\u529f\u5229\u7528\u6d17\u94b1\u6a21\u5f0f\uff0c\u65b0\u7a0b\u5e8f\u68c0\u6d4b\u975e\u6b3a\u8bc8\u8005\u548c\u6b3a\u8bc8\u8005\u80fd\u529b\u66f4\u5f3a\uff0c\u4e14\u80fd\u63a7\u5236\u8bef\u62a5\u7387\uff0c\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u6216LSTM\u67b6\u6784\u7684\u7a0b\u5e8f\u3002", "conclusion": "\u65b0\u7a0b\u5e8f\u5728\u6d17\u94b1\u68c0\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u5728\u5c11\u76d1\u7763\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u63a7\u5236\u8bef\u62a5\u7387\u3002"}}
{"id": "2507.08994", "pdf": "https://arxiv.org/pdf/2507.08994", "abs": "https://arxiv.org/abs/2507.08994", "authors": ["Joseph Lazzaro", "Ciara Pike-Burke"], "title": "Fixed-Confidence Multiple Change Point Identification under Bandit Feedback", "categories": ["stat.ML", "cs.LG"], "comment": "ICML 2025", "summary": "Piecewise constant functions describe a variety of real-world phenomena in\ndomains ranging from chemistry to manufacturing. In practice, it is often\nrequired to confidently identify the locations of the abrupt changes in these\nfunctions as quickly as possible. For this, we introduce a fixed-confidence\npiecewise constant bandit problem. Here, we sequentially query points in the\ndomain and receive noisy evaluations of the function under bandit feedback. We\nprovide instance-dependent lower bounds for the complexity of change point\nidentification in this problem. These lower bounds illustrate that an optimal\nmethod should focus its sampling efforts adjacent to each of the change points,\nand the number of samples around each change point should be inversely\nproportional to the magnitude of the change. Building on this, we devise a\nsimple and computationally efficient variant of Track-and-Stop and prove that\nit is asymptotically optimal in many regimes. We support our theoretical\nfindings with experimental results in synthetic environments demonstrating the\nefficiency of our method.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u5206\u6bb5\u5e38\u6570\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u7ed9\u51fa\u53d8\u70b9\u8bc6\u522b\u590d\u6742\u5ea6\u7684\u4e0b\u754c\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u5355\u9ad8\u6548\u7684\u7b97\u6cd5\u5e76\u8bc1\u660e\u5176\u6e10\u8fd1\u6700\u4f18\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u5b9e\u9645\u4e2d\u9700\u8981\u5c3d\u5feb\u4e14\u6709\u4fe1\u5fc3\u5730\u8bc6\u522b\u5206\u6bb5\u5e38\u6570\u51fd\u6570\u4e2d\u7a81\u53d8\u70b9\u7684\u4f4d\u7f6e\u3002", "method": "\u5f15\u5165\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u5206\u6bb5\u5e38\u6570\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u7ed9\u51fa\u53d8\u70b9\u8bc6\u522b\u590d\u6742\u5ea6\u7684\u5b9e\u4f8b\u76f8\u5173\u4e0b\u754c\uff0c\u57fa\u4e8e\u6b64\u8bbe\u8ba1Track - and - Stop\u7684\u53d8\u4f53\u7b97\u6cd5\u3002", "result": "\u6240\u8bbe\u8ba1\u7684\u7b97\u6cd5\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u6e10\u8fd1\u6700\u4f18\uff0c\u5408\u6210\u73af\u5883\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5206\u6bb5\u5e38\u6570\u51fd\u6570\u53d8\u70b9\u8bc6\u522b\u95ee\u9898\u4e0a\u6709\u6548\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002"}}
{"id": "2507.10149", "pdf": "https://arxiv.org/pdf/2507.10149", "abs": "https://arxiv.org/abs/2507.10149", "authors": ["Abhimanyu Nag", "Madhur Prabhakar", "Tanuj Behl"], "title": "A Coincidence of Wants Mechanism for Swap Trade Execution in Decentralized Exchanges", "categories": ["cs.GT", "cs.CE", "q-fin.TR"], "comment": null, "summary": "We propose a mathematically rigorous framework for identifying and completing\nCoincidence of Wants (CoW) cycles in decentralized exchange (DEX) aggregators.\nUnlike existing auction based systems such as CoWSwap, our approach introduces\nan asset matrix formulation that not only verifies feasibility using oracle\nprices and formal conservation laws but also completes partial CoW cycles of\nswap orders that are discovered using graph traversal and are settled using\nimbalance correction. We define bridging orders and show that the resulting\nexecution is slippage free and capital preserving for LPs. Applied to real\nworld Arbitrum swap data, our algorithm demonstrates efficient discovery of CoW\ncycles and supports the insertion of synthetic orders for atomic cycle closure.\nThis work can be thought of as the detailing of a potential delta-neutral\nstrategy by liquidity providing market makers: a structured CoW cycle\nexecution.", "AI": {"tldr": "\u63d0\u51fa\u6570\u5b66\u4e25\u683c\u6846\u67b6\u8bc6\u522b\u548c\u5b8c\u6210\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u805a\u5408\u5668\u4e2d\u7684\u9700\u6c42\u5de7\u5408\uff08CoW\uff09\u5468\u671f\uff0c\u5e94\u7528\u4e8e\u771f\u5b9e\u6570\u636e\u6548\u679c\u826f\u597d\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709\u57fa\u4e8e\u62cd\u5356\u7684\u7cfb\u7edf\uff0c\u5982CoWSwap\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684CoW\u5468\u671f\u8bc6\u522b\u548c\u5b8c\u6210\u3002", "method": "\u5f15\u5165\u8d44\u4ea7\u77e9\u9635\u516c\u5f0f\uff0c\u7528\u9884\u8a00\u673a\u4ef7\u683c\u548c\u5b88\u6052\u5b9a\u5f8b\u9a8c\u8bc1\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u56fe\u904d\u5386\u53d1\u73b0\u90e8\u5206CoW\u5468\u671f\u5e76\u4f7f\u7528\u4e0d\u5e73\u8861\u6821\u6b63\u7ed3\u7b97\uff0c\u5b9a\u4e49\u6865\u63a5\u8ba2\u5355\u3002", "result": "\u7b97\u6cd5\u80fd\u6709\u6548\u53d1\u73b0CoW\u5468\u671f\uff0c\u652f\u6301\u63d2\u5165\u5408\u6210\u8ba2\u5355\u8fdb\u884c\u539f\u5b50\u5468\u671f\u95ed\u5408\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u53ef\u4f5c\u4e3a\u6d41\u52a8\u6027\u63d0\u4f9b\u505a\u5e02\u5546\u7684\u6f5c\u5728delta - \u4e2d\u6027\u7b56\u7565\uff0c\u5373\u7ed3\u6784\u5316CoW\u5468\u671f\u6267\u884c\u3002"}}
{"id": "2507.09444", "pdf": "https://arxiv.org/pdf/2507.09444", "abs": "https://arxiv.org/abs/2507.09444", "authors": ["Shuyu Gong", "Taizhong Hu", "Zhenfeng Zou"], "title": "Norms Based on Generalized Expected-Shortfalls and Applications", "categories": ["q-fin.RM"], "comment": null, "summary": "This paper proposes a novel class of generalized Expected-Shortfall (ES)\nnorms constructed via distortion risk measures, establishing a unified\nanalytical framework for risk quantification. The proposed norms extend\nconventional ES methodology by incorporating flexible distortion functions.\nSpecifically, we develop the mathematical duality theory for generalized-ES\nnorms to support portfolio optimization tasks, while demonstrating their\npractical utility through projection problem solutions. The generalizedES norms\nare also applied to detect anomalies of financial time series data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5931\u771f\u98ce\u9669\u5ea6\u91cf\u6784\u5efa\u7684\u5e7f\u4e49\u9884\u671f\u635f\u5931\uff08ES\uff09\u8303\u6570\uff0c\u5efa\u7acb\u98ce\u9669\u91cf\u5316\u7edf\u4e00\u6846\u67b6\uff0c\u62d3\u5c55\u4f20\u7edfES\u65b9\u6cd5\u5e76\u5e94\u7528\u4e8e\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u548c\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u6784\u5efa\u65b0\u7684\u98ce\u9669\u91cf\u5316\u7edf\u4e00\u5206\u6790\u6846\u67b6\uff0c\u62d3\u5c55\u4f20\u7edfES\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5931\u771f\u98ce\u9669\u5ea6\u91cf\u6784\u5efa\u5e7f\u4e49ES\u8303\u6570\uff0c\u53d1\u5c55\u5176\u6570\u5b66\u5bf9\u5076\u7406\u8bba\uff0c\u89e3\u51b3\u6295\u5f71\u95ee\u9898\u3002", "result": "\u5efa\u7acb\u4e86\u7edf\u4e00\u5206\u6790\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5728\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u5e94\u7528\u4e8e\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u3002", "conclusion": "\u5e7f\u4e49ES\u8303\u6570\u4e3a\u98ce\u9669\u91cf\u5316\u548c\u91d1\u878d\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2507.09902", "pdf": "https://arxiv.org/pdf/2507.09902", "abs": "https://arxiv.org/abs/2507.09902", "authors": ["Yuanhao Wang"], "title": "Tie-breaking Agnostic Lower Bound for Fictitious Play", "categories": ["cs.GT"], "comment": null, "summary": "Fictitious play (FP) is a natural learning dynamic in two-player zero-sum\ngames. Samuel Karlin conjectured in 1959 that FP converges at a rate of\n$O(t^{-1/2})$ to Nash equilibrium, where $t$ is the number of steps played.\nHowever, Daskalakis and Pan disproved the stronger form of this conjecture in\n2014, where \\emph{adversarial} tie-breaking is allowed.\n  This paper disproves Karlin's conjecture in its weaker form. In particular,\nthere exists a 10-by-10 zero-sum matrix game, in which FP converges at a rate\nof $\\Omega(t^{-1/3})$, and no ties occur except for the first step.", "AI": {"tldr": "\u672c\u6587\u53cd\u9a73\u4e86Karlin\u5173\u4e8e\u865a\u6784\u535a\u5f08\uff08FP\uff09\u6536\u655b\u901f\u7387\u7684\u8f83\u5f31\u5f62\u5f0f\u731c\u60f3\uff0c\u6307\u51fa\u5b58\u5728\u4e00\u4e2a10\u00d710\u7684\u96f6\u548c\u77e9\u9635\u535a\u5f08\uff0cFP\u6536\u655b\u901f\u7387\u4e3a\u03a9(t\u207b\u00b9/\u00b3)\u3002", "motivation": "Karlin\u57281959\u5e74\u731c\u60f3FP\u4ee5O(t\u207b\u00b9/\u00b2)\u7684\u901f\u7387\u6536\u655b\u5230\u7eb3\u4ec0\u5747\u8861\uff0c2014\u5e74Daskalakis\u548cPan\u53cd\u9a73\u4e86\u5176\u8f83\u5f3a\u5f62\u5f0f\u731c\u60f3\uff0c\u672c\u6587\u65e8\u5728\u53cd\u9a73\u8f83\u5f31\u5f62\u5f0f\u731c\u60f3\u3002", "method": "\u6784\u9020\u4e86\u4e00\u4e2a10\u00d710\u7684\u96f6\u548c\u77e9\u9635\u535a\u5f08\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5b58\u5728\u4e00\u4e2a10\u00d710\u96f6\u548c\u77e9\u9635\u535a\u5f08\uff0c\u5176\u4e2dFP\u6536\u655b\u901f\u7387\u4e3a\u03a9(t\u207b\u00b9/\u00b3)\uff0c\u4e14\u9664\u7b2c\u4e00\u6b65\u5916\u65e0\u5e73\u5c40\u3002", "conclusion": "Karlin\u5173\u4e8eFP\u6536\u655b\u901f\u7387\u7684\u8f83\u5f31\u5f62\u5f0f\u731c\u60f3\u4e0d\u6210\u7acb\u3002"}}
{"id": "2507.10026", "pdf": "https://arxiv.org/pdf/2507.10026", "abs": "https://arxiv.org/abs/2507.10026", "authors": ["Zhifei Xu", "Zhiqing Tang", "Jiong Lou", "Zhi Yao", "Xuan Xie", "Tian Wang", "Yinglong Wang", "Weijia Jia"], "title": "EAT: QoS-Aware Edge-Collaborative AIGC Task Scheduling via Attention-Guided Diffusion Reinforcement Learning", "categories": ["cs.DC"], "comment": null, "summary": "The growth of Artificial Intelligence (AI) and large language models has\nenabled the use of Generative AI (GenAI) in cloud data centers for diverse\nAI-Generated Content (AIGC) tasks. Models like Stable Diffusion introduce\nunavoidable delays and substantial resource overhead, which are unsuitable for\nusers at the network edge with high QoS demands. Deploying AIGC services on\nedge servers reduces transmission times but often leads to underutilized\nresources and fails to optimally balance inference latency and quality. To\naddress these issues, this paper introduces a QoS-aware\n\\underline{E}dge-collaborative \\underline{A}IGC \\underline{T}ask scheduling\n(EAT) algorithm. Specifically: 1) We segment AIGC tasks and schedule patches to\nvarious edge servers, formulating it as a gang scheduling problem that balances\ninference latency and quality while considering server heterogeneity, such as\ndiffering model distributions and cold start issues. 2) We propose a\nreinforcement learning-based EAT algorithm that uses an attention layer to\nextract load and task queue information from edge servers and employs a\ndiffusion-based policy network for scheduling, efficiently enabling model\nreuse. 3) We develop an AIGC task scheduling system that uses our EAT algorithm\nto divide tasks and distribute them across multiple edge servers for\nprocessing. Experimental results based on our system and large-scale\nsimulations show that our EAT algorithm can reduce inference latency by up to\n56\\% compared to baselines. We release our open-source code at\nhttps://github.com/zzf1955/EAT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faQoS\u611f\u77e5\u7684\u8fb9\u7f18\u534f\u4f5cAIGC\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5EAT\uff0c\u80fd\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\uff0c\u5f00\u6e90\u4ee3\u7801\u5df2\u53d1\u5e03\u3002", "motivation": "\u73b0\u6709AIGC\u6a21\u578b\u5728\u7f51\u7edc\u8fb9\u7f18\u5e94\u7528\u5b58\u5728\u5ef6\u8fdf\u3001\u8d44\u6e90\u5229\u7528\u4e0d\u5408\u7406\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u5e73\u8861\u63a8\u7406\u5ef6\u8fdf\u548c\u8d28\u91cf\u3002", "method": "\u5c06AIGC\u4efb\u52a1\u5206\u5272\u5e76\u8c03\u5ea6\u5230\u4e0d\u540c\u8fb9\u7f18\u670d\u52a1\u5668\uff0c\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684EAT\u7b97\u6cd5\uff0c\u5f00\u53d1AIGC\u4efb\u52a1\u8c03\u5ea6\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEAT\u7b97\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u80fd\u6700\u591a\u964d\u4f4e56%\u7684\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "EAT\u7b97\u6cd5\u80fd\u6709\u6548\u964d\u4f4eAIGC\u4efb\u52a1\u63a8\u7406\u5ef6\u8fdf\uff0c\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.09188", "pdf": "https://arxiv.org/pdf/2507.09188", "abs": "https://arxiv.org/abs/2507.09188", "authors": ["Bangcheng Sun", "Yazhe Chen", "Jilin Yang", "Xiaodong Li", "Hui Li"], "title": "Retrieval-Augmented Recommendation Explanation Generation with Hierarchical Aggregation", "categories": ["cs.IR"], "comment": null, "summary": "Explainable Recommender System (ExRec) provides transparency to the\nrecommendation process, increasing users' trust and boosting the operation of\nonline services. With the rise of large language models (LLMs), whose extensive\nworld knowledge and nuanced language understanding enable the generation of\nhuman-like, contextually grounded explanations, LLM-powered ExRec has gained\ngreat momentum. However, existing LLM-based ExRec models suffer from profile\ndeviation and high retrieval overhead, hindering their deployment. To address\nthese issues, we propose Retrieval-Augmented Recommendation Explanation\nGeneration with Hierarchical Aggregation (REXHA). Specifically, we design a\nhierarchical aggregation based profiling module that comprehensively considers\nuser and item review information, hierarchically summarizing and constructing\nholistic profiles. Furthermore, we introduce an efficient retrieval module\nusing two types of pseudo-document queries to retrieve relevant reviews to\nenhance the generation of recommendation explanations, effectively reducing\nretrieval latency and improving the recall of relevant reviews. Extensive\nexperiments demonstrate that our method outperforms existing approaches by up\nto 12.6% w.r.t. the explanation quality while achieving high retrieval\nefficiency.", "AI": {"tldr": "\u63d0\u51faREXHA\u89e3\u51b3\u73b0\u6709LLM - \u57faExRec\u6a21\u578b\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18", "motivation": "\u73b0\u6709LLM - \u57faExRec\u6a21\u578b\u5b58\u5728\u8f6e\u5ed3\u504f\u5dee\u548c\u9ad8\u68c0\u7d22\u5f00\u9500\u95ee\u9898\uff0c\u963b\u788d\u90e8\u7f72", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u5206\u5c42\u805a\u5408\u7684\u5206\u6790\u6a21\u5757\u6784\u5efa\u6574\u4f53\u8f6e\u5ed3\uff0c\u5f15\u5165\u9ad8\u6548\u68c0\u7d22\u6a21\u5757\u7528\u4e24\u79cd\u4f2a\u6587\u6863\u67e5\u8be2\u68c0\u7d22\u76f8\u5173\u8bc4\u8bba", "result": "\u65b9\u6cd5\u5728\u89e3\u91ca\u8d28\u91cf\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u6700\u9ad8\u4f1812.6%\uff0c\u4e14\u68c0\u7d22\u6548\u7387\u9ad8", "conclusion": "\u6240\u63d0REXHA\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u63d0\u5347\u63a8\u8350\u89e3\u91ca\u751f\u6210\u8d28\u91cf\u548c\u68c0\u7d22\u6548\u7387"}}
{"id": "2507.09591", "pdf": "https://arxiv.org/pdf/2507.09591", "abs": "https://arxiv.org/abs/2507.09591", "authors": ["Michael Ryan", "Mohammad Hassan Baqershahi", "Hessamoddin Moshayedi", "Elyas Ghafoori"], "title": "Physics-informed machine learning surrogate for scalable simulation of thermal histories during wire-arc directed energy deposition", "categories": ["cs.CE"], "comment": "18 pages, 12 figures", "summary": "Wire-arc directed energy deposition (DED) has emerged as a promising additive\nmanufacturing (AM) technology for large-scale structural engineering\napplications. However, the complex thermal dynamics inherent to the process\npresent challenges in ensuring structural integrity and mechanical properties\nof fabricated thick walls and plates. While finite element method (FEM)\nsimulations have been conventionally employed to predict thermal history during\ndeposition, their computational demand remains prohibitively high for actual\nlarge-scale applications. Given the necessity of multiple repetitive\nsimulations for heat management and the determination of an optimal printing\nstrategy, FEM simulation quickly becomes entirely infeasible. Instead,\nadvancements have been made in using trained neural networks as surrogate\nmodels for rapid prediction. However, traditional data-driven approaches\nnecessitate large amounts of relevant and verifiable external data, during the\ntraining and validation of the neural network. Regarding large-scale wire-arc\nDED, none of these data sources are readily available in quantities sufficient\nfor an accurate surrogate. The introduction of physics-informed neural networks\n(PINNs) has opened up an alternative simulation strategy by leveraging the\nexisting physical knowledge of the phenomena with advanced machine learning\nmethods. Despite their theoretical advantages, PINNs have seen limited\napplication in the context of large-scale wire-arc DED for structural\nengineering. This study investigates the scalability of PINNs, focusing on\nefficient collocation points sampling, a critical factor controlling both the\ntraining time and model performance. Results show PINNs can reduce\ncomputational time and effort by up to 98.6%, while maintaining the desired\naccuracy and offering \"super-resolution\". Future directions for enhancing PINN\nperformance in metal AM are discussed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u5728\u5927\u89c4\u6a21\u7535\u5f27\u5b9a\u5411\u80fd\u91cf\u6c89\u79ef\uff08DED\uff09\u4e2d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u53d1\u73b0\u5176\u80fd\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u548c\u7cbe\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u5ea6\u5e76\u63d0\u4f9b\u201c\u8d85\u5206\u8fa8\u7387\u201d\uff0c\u8fd8\u8ba8\u8bba\u4e86\u63d0\u5347\u5176\u5728\u91d1\u5c5e\u589e\u6750\u5236\u9020\u4e2d\u6027\u80fd\u7684\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u6709\u9650\u5143\u6cd5\uff08FEM\uff09\u6a21\u62df\u7535\u5f27DED\u8fc7\u7a0b\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u7684\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u800c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u867d\u6709\u7406\u8bba\u4f18\u52bf\u4f46\u5728\u5927\u89c4\u6a21\u7535\u5f27DED\u7ed3\u6784\u5de5\u7a0b\u4e2d\u5e94\u7528\u6709\u9650\uff0c\u56e0\u6b64\u7814\u7a76PINNs\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u7814\u7a76PINNs\u7684\u53ef\u6269\u5c55\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u9ad8\u6548\u7684\u914d\u70b9\u91c7\u6837\uff0c\u8fd9\u662f\u63a7\u5236\u8bad\u7ec3\u65f6\u95f4\u548c\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "result": "PINNs\u53ef\u51cf\u5c11\u9ad8\u8fbe98.6%\u7684\u8ba1\u7b97\u65f6\u95f4\u548c\u7cbe\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u6240\u9700\u7684\u7cbe\u5ea6\u5e76\u63d0\u4f9b\u201c\u8d85\u5206\u8fa8\u7387\u201d\u3002", "conclusion": "PINNs\u5728\u5927\u89c4\u6a21\u7535\u5f27DED\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u53ef\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u5728\u91d1\u5c5e\u589e\u6750\u5236\u9020\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09592", "pdf": "https://arxiv.org/pdf/2507.09592", "abs": "https://arxiv.org/abs/2507.09592", "authors": ["Isaac Shi", "Zeyuan Li", "Fan Liu", "Wenli Wang", "Lewei He", "Yang Yang", "Tianyu Shi"], "title": "THOR: Transformer Heuristics for On-Demand Retrieval", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "We introduce the THOR (Transformer Heuristics for On-Demand Retrieval)\nModule, designed and implemented by eSapiens, a secure, scalable engine that\ntransforms natural-language questions into verified, read-only SQL analytics\nfor enterprise databases. The Text-to-SQL module follows a decoupled\norchestration/execution architecture: a Supervisor Agent routes queries, Schema\nRetrieval dynamically injects table and column metadata, and a SQL Generation\nAgent emits single-statement SELECT queries protected by a read-only guardrail.\nAn integrated Self-Correction & Rating loop captures empty results, execution\nerrors, or low-quality outputs and triggers up to five LLM-driven regeneration\nattempts. Finally, a Result Interpretation Agent produces concise,\nhuman-readable insights and hands raw rows to the Insight & Intelligence engine\nfor visualization or forecasting.\n  Smoke tests across finance, sales, and operations scenarios demonstrate\nreliable ad-hoc querying and automated periodic reporting. By embedding schema\nawareness, fault-tolerant execution, and compliance guardrails, the THOR Module\nempowers non-technical users to access live data with zero-SQL simplicity and\nenterprise-grade safety.", "AI": {"tldr": "\u4ecb\u7ecdeSapiens\u8bbe\u8ba1\u5b9e\u73b0\u7684THOR\u6a21\u5757\uff0c\u53ef\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u5316\u4e3a\u4f01\u4e1a\u6570\u636e\u5e93\u7684SQL\u5206\u6790\uff0c\u7ecf\u591a\u9879\u6d4b\u8bd5\u80fd\u53ef\u9760\u67e5\u8be2\u548c\u62a5\u544a\uff0c\u8ba9\u975e\u6280\u672f\u7528\u6237\u5b89\u5168\u8bbf\u95ee\u6570\u636e\u3002", "motivation": "\u8ba9\u975e\u6280\u672f\u7528\u6237\u80fd\u4ee5\u7b80\u5355\u4e14\u5b89\u5168\u7684\u65b9\u5f0f\u8bbf\u95ee\u4f01\u4e1a\u6570\u636e\u5e93\u7684\u5b9e\u65f6\u6570\u636e\u3002", "method": "\u91c7\u7528\u89e3\u8026\u7684\u7f16\u6392/\u6267\u884c\u67b6\u6784\uff0c\u5305\u542b\u591a\u4e2a\u4ee3\u7406\uff0c\u6709\u96c6\u6210\u7684\u81ea\u6211\u7ea0\u6b63\u548c\u8bc4\u7ea7\u5faa\u73af\u3002", "result": "\u5728\u91d1\u878d\u3001\u9500\u552e\u548c\u8fd0\u8425\u573a\u666f\u7684\u5192\u70df\u6d4b\u8bd5\u4e2d\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u5373\u5e2d\u67e5\u8be2\u548c\u81ea\u52a8\u5316\u5b9a\u671f\u62a5\u544a\u3002", "conclusion": "THOR\u6a21\u5757\u901a\u8fc7\u5d4c\u5165\u591a\u79cd\u80fd\u529b\uff0c\u4f7f\u975e\u6280\u672f\u7528\u6237\u80fd\u4ee5\u96f6SQL\u7684\u7b80\u5355\u65b9\u5f0f\u548c\u4f01\u4e1a\u7ea7\u7684\u5b89\u5168\u6027\u8bbf\u95ee\u5b9e\u65f6\u6570\u636e\u3002"}}
{"id": "2507.09782", "pdf": "https://arxiv.org/pdf/2507.09782", "abs": "https://arxiv.org/abs/2507.09782", "authors": ["Muhammad Luthfi Shahab", "Fidya Almira Suheri", "Rudy Kusdiantara", "Hadi Susanto"], "title": "Physics-informed neural networks for high-dimensional solutions and snaking bifurcations in nonlinear lattices", "categories": ["math.NA", "cs.LG", "cs.NA", "cs.NE", "math.OC"], "comment": "Accepted for publication in Physica D: Nonlinear Phenomena", "summary": "This paper introduces a framework based on physics-informed neural networks\n(PINNs) for addressing key challenges in nonlinear lattices, including solution\napproximation, bifurcation diagram construction, and linear stability analysis.\nWe first employ PINNs to approximate solutions of nonlinear systems arising\nfrom lattice models, using the Levenberg-Marquardt algorithm to optimize\nnetwork weights for greater accuracy. To enhance computational efficiency in\nhigh-dimensional settings, we integrate a stochastic sampling strategy. We then\nextend the method by coupling PINNs with a continuation approach to compute\nsnaking bifurcation diagrams, incorporating an auxiliary equation to\neffectively track successive solution branches. For linear stability analysis,\nwe adapt PINNs to compute eigenvectors, introducing output constraints to\nenforce positivity, in line with Sturm-Liouville theory. Numerical experiments\nare conducted on the discrete Allen-Cahn equation with cubic and quintic\nnonlinearities in one to five spatial dimensions. The results demonstrate that\nthe proposed approach achieves accuracy comparable to, or better than,\ntraditional numerical methods, especially in high-dimensional regimes where\ncomputational resources are a limiting factor. These findings highlight the\npotential of neural networks as scalable and efficient tools for the study of\ncomplex nonlinear lattice systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u7684\u6846\u67b6\u89e3\u51b3\u975e\u7ebf\u6027\u6676\u683c\u5173\u952e\u6311\u6218\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u9ad8\u7ef4\u8868\u73b0\u4f73\uff0c\u51f8\u663e\u795e\u7ecf\u7f51\u7edc\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u975e\u7ebf\u6027\u6676\u683c\u4e2d\u7684\u89e3\u8fd1\u4f3c\u3001\u5206\u5c94\u56fe\u6784\u5efa\u548c\u7ebf\u6027\u7a33\u5b9a\u6027\u5206\u6790\u7b49\u5173\u952e\u6311\u6218\u3002", "method": "\u7528PINNs\u8fd1\u4f3c\u6676\u683c\u6a21\u578b\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u89e3\uff0c\u7528Levenberg - Marquardt\u7b97\u6cd5\u4f18\u5316\u7f51\u7edc\u6743\u91cd\uff0c\u7ed3\u5408\u968f\u673a\u91c7\u6837\u7b56\u7565\uff1b\u8026\u5408PINNs\u4e0e\u5ef6\u7eed\u6cd5\u8ba1\u7b97\u5206\u5c94\u56fe\uff1b\u8c03\u6574PINNs\u8ba1\u7b97\u7279\u5f81\u5411\u91cf\u5e76\u5f15\u5165\u8f93\u51fa\u7ea6\u675f\u3002", "result": "\u5728\u4e00\u5230\u4e94\u7ef4\u79bb\u6563Allen - Cahn\u65b9\u7a0b\u4e0a\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u7cbe\u5ea6\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u5728\u9ad8\u7ef4\u4f18\u52bf\u660e\u663e\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u53ef\u4f5c\u4e3a\u7814\u7a76\u590d\u6742\u975e\u7ebf\u6027\u6676\u683c\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2507.09080", "pdf": "https://arxiv.org/pdf/2507.09080", "abs": "https://arxiv.org/abs/2507.09080", "authors": ["Athanasios Trantas", "Martino Mensio", "Stylianos Stasinos", "Sebastian Gribincea", "Taimur Khan", "Damian Podareanu", "Aliene van der Veen"], "title": "BioAnalyst: A Foundation Model for Biodiversity", "categories": ["cs.AI"], "comment": null, "summary": "The accelerating loss of biodiversity presents critical challenges for\necological research and conservation strategies. The preservation of\nbiodiversity is paramount for maintaining ecological balance and ensuring the\nsustainability of ecosystems. However, biodiversity faces numerous threats,\nincluding habitat loss, climate change, and the proliferation of invasive\nspecies. Addressing these and other ecology-related challenges, both at local\nand global scales, requires comprehensive monitoring, predictive and\nconservation planning capabilities. Artificial Intelligence (AI) Foundation\nModels (FMs) have gained significant momentum in numerous scientific domains by\nleveraging vast datasets to learn general-purpose representations adaptable to\nvarious downstream tasks. This paradigm holds immense promise for biodiversity\nconservation. In response, we introduce BioAnalyst, the first Foundation Model\ntailored for biodiversity analysis and conservation planning. BioAnalyst\nemploys a transformer-based architecture, pre-trained on extensive multi-modal\ndatasets encompassing species occurrence records, remote sensing indicators,\nclimate and environmental variables. BioAnalyst is designed for adaptability,\nallowing for fine-tuning of a range of downstream tasks, such as species\ndistribution modelling, habitat suitability assessments, invasive species\ndetection, and population trend forecasting. We evaluate the model's\nperformance on two downstream use cases, demonstrating its generalisability\ncompared to existing methods, particularly in data-scarce scenarios for two\ndistinct use-cases, establishing a new accuracy baseline for ecological\nforecasting. By openly releasing BioAnalyst and its fine-tuning workflows to\nthe scientific community, we aim to foster collaborative efforts in\nbiodiversity modelling and advance AI-driven solutions to pressing ecological\nchallenges.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u751f\u7269\u591a\u6837\u6027\u4e27\u5931\u5e26\u6765\u6311\u6218\uff0c\u5f15\u5165\u9996\u4e2a\u7528\u4e8e\u751f\u7269\u591a\u6837\u6027\u5206\u6790\u548c\u4fdd\u62a4\u89c4\u5212\u7684\u57fa\u7840\u6a21\u578bBioAnalyst\uff0c\u8bc4\u4f30\u5176\u6027\u80fd\u5e76\u516c\u5f00\u4ee5\u4fc3\u8fdb\u534f\u4f5c\u3002", "motivation": "\u751f\u7269\u591a\u6837\u6027\u9762\u4e34\u8bf8\u591a\u5a01\u80c1\uff0c\u9700\u8981\u7efc\u5408\u76d1\u6d4b\u548c\u89c4\u5212\u80fd\u529b\uff0cAI\u57fa\u7840\u6a21\u578b\u5728\u591a\u9886\u57df\u53d1\u5c55\uff0c\u6709\u671b\u7528\u4e8e\u751f\u7269\u591a\u6837\u6027\u4fdd\u62a4\u3002", "method": "\u6784\u5efa\u57fa\u4e8eTransformer\u67b6\u6784\u7684BioAnalyst\uff0c\u5728\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\uff0c\u53ef\u9488\u5bf9\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u3002", "result": "\u5728\u4e24\u4e2a\u4e0b\u6e38\u7528\u4f8b\u4e2d\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u5c55\u793a\u5176\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\uff0c\u4e3a\u751f\u6001\u9884\u6d4b\u5efa\u7acb\u65b0\u7684\u51c6\u786e\u7387\u57fa\u7ebf\u3002", "conclusion": "\u516c\u5f00BioAnalyst\u53ca\u5176\u5fae\u8c03\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4fc3\u8fdb\u751f\u7269\u591a\u6837\u6027\u5efa\u6a21\u7684\u534f\u4f5c\uff0c\u63a8\u52a8AI\u89e3\u51b3\u751f\u6001\u6311\u6218\u3002"}}
{"id": "2507.09635", "pdf": "https://arxiv.org/pdf/2507.09635", "abs": "https://arxiv.org/abs/2507.09635", "authors": ["Jianing Zhi", "Guanqiu Qi", "Xinghua Li"], "title": "Selective Newsvendor Problem with Dependent Leadtime and Joint Marketing Decisions", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "In this paper, we investigate a joint decision-making pattern for a two-stage\nsupply chain network, including a supplier, a company, and its customers. We\ninvestigate two types of demand patterns, associated with dependent lead time\nand service level considerations. We define two novel models, including\nall-or-nothing selective newsvendor problem (AON-SNP) and selective news Vendor\nProblem with Dependent Lead Time and Price Related Demands (DLSNP). The\nproposed models are applicable to numerous areas such as the fashion,\nfurniture, and electronic industries. We develop an efficient solution\nalgorithm, referred to as R-search, to identify an optimal solution for the\nDL-selectivity problem. We examine various responses of the system through\nparameter sensitivity analysis. Our model proves that if the total demand is\nlower than the upper limit of the order quantity, the best strategy for Q is to\nmatch that demand. If the market increases, more demand comes in, leading to a\nshortage, and forcing the company to find other local suppliers to fill the\nadditional demand. The results demonstrate that our model well explains various\nbehavior for all involved parties in the network, and provide guidance on\nintelligent decision making for the company.", "AI": {"tldr": "\u7814\u7a76\u4e24\u7ea7\u4f9b\u5e94\u94fe\u7f51\u7edc\u8054\u5408\u51b3\u7b56\u6a21\u5f0f\uff0c\u5b9a\u4e49\u4e24\u6a21\u578b\uff0c\u5f00\u53d1\u7b97\u6cd5\u6c42\u89e3\uff0c\u5206\u6790\u53c2\u6570\u654f\u611f\u6027\uff0c\u6a21\u578b\u80fd\u89e3\u91ca\u5404\u65b9\u884c\u4e3a\u5e76\u6307\u5bfc\u51b3\u7b56\u3002", "motivation": "\u7814\u7a76\u4e24\u7ea7\u4f9b\u5e94\u94fe\u7f51\u7edc\u7684\u8054\u5408\u51b3\u7b56\u6a21\u5f0f\uff0c\u8003\u8651\u4e0d\u540c\u9700\u6c42\u6a21\u5f0f\u3001\u63d0\u524d\u671f\u548c\u670d\u52a1\u6c34\u5e73\u56e0\u7d20\u3002", "method": "\u5b9a\u4e49AON - SNP\u548cDLSNP\u6a21\u578b\uff0c\u5f00\u53d1R - search\u7b97\u6cd5\u6c42\u89e3DL - \u9009\u62e9\u6027\u95ee\u9898\uff0c\u8fdb\u884c\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u82e5\u603b\u9700\u6c42\u4f4e\u4e8e\u8ba2\u5355\u91cf\u4e0a\u9650\uff0cQ\u6700\u4f18\u7b56\u7565\u662f\u5339\u914d\u9700\u6c42\uff1b\u5e02\u573a\u589e\u957f\u9700\u6c42\u589e\u52a0\u4f1a\u5bfc\u81f4\u77ed\u7f3a\uff0c\u516c\u53f8\u9700\u627e\u672c\u5730\u4f9b\u5e94\u5546\u8865\u5145\u9700\u6c42\u3002", "conclusion": "\u6a21\u578b\u80fd\u5f88\u597d\u89e3\u91ca\u7f51\u7edc\u4e2d\u5404\u65b9\u884c\u4e3a\uff0c\u4e3a\u516c\u53f8\u667a\u80fd\u51b3\u7b56\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2507.10367", "pdf": "https://arxiv.org/pdf/2507.10367", "abs": "https://arxiv.org/abs/2507.10367", "authors": ["Jingwei Xu", "Junbin Kang", "Mingkai Dong", "Mingyu Liu", "Lu Zhang", "Shaohong Guo", "Ziyan Qiu", "Mingzhen You", "Ziyi Tian", "Anqi Yu", "Tianhong Ding", "Xinwei Hu", "Haibo Chen"], "title": "FalconFS: Distributed File System for Large-Scale Deep Learning Pipeline", "categories": ["cs.DC", "cs.PF"], "comment": "Accepted by NSDI'26", "summary": "Client-side metadata caching has long been considered an effective method for\naccelerating metadata operations in distributed file systems (DFSs). However,\nwe have found that client-side state (e.g., caching) is not only ineffective\nbut also consumes valuable memory resources in the deep learning pipelines. We\nthus propose FalconFS, a DFS optimized for deep learning pipelines with the\nstateless-client architecture. Specifically, instead of performing client-side\npath resolution and caching, FalconFS efficiently resolves paths on the server\nside using hybrid metadata indexing and lazy namespace replication. FalconFS\nalso boosts server concurrency with concurrent request merging and provides\neasy deployment with VFS shortcut. Evaluations against CephFS and Lustre show\nthat FalconFS achieves up to 5.72$\\times$ throughput for small file read/write\nand up to 12.81$\\times$ throughput for deep learning model training. FalconFS\nhas been running in Huawei autonomous driving system's production environment\nwith 10,000 NPUs for one year.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u7ba1\u9053\u4f18\u5316\u7684\u65e0\u72b6\u6001\u5ba2\u6237\u7aef\u67b6\u6784\u5206\u5e03\u5f0f\u6587\u4ef6\u7cfb\u7edfFalconFS\uff0c\u6027\u80fd\u4f18\u4e8eCephFS\u548cLustre\uff0c\u5df2\u5728\u534e\u4e3a\u751f\u4ea7\u73af\u5883\u8fd0\u884c\u4e00\u5e74\u3002", "motivation": "\u53d1\u73b0\u5ba2\u6237\u7aef\u72b6\u6001\uff08\u5982\u7f13\u5b58\uff09\u5728\u6df1\u5ea6\u5b66\u4e60\u7ba1\u9053\u4e2d\u4e0d\u4ec5\u65e0\u6548\uff0c\u8fd8\u6d88\u8017\u5b9d\u8d35\u5185\u5b58\u8d44\u6e90\uff0c\u9700\u8981\u4f18\u5316\u3002", "method": "\u91c7\u7528\u65e0\u72b6\u6001\u5ba2\u6237\u7aef\u67b6\u6784\uff0c\u5728\u670d\u52a1\u5668\u7aef\u7528\u6df7\u5408\u5143\u6570\u636e\u7d22\u5f15\u548c\u60f0\u6027\u547d\u540d\u7a7a\u95f4\u590d\u5236\u9ad8\u6548\u89e3\u6790\u8def\u5f84\uff0c\u7528\u5e76\u53d1\u8bf7\u6c42\u5408\u5e76\u63d0\u9ad8\u670d\u52a1\u5668\u5e76\u53d1\uff0c\u7528VFS\u5feb\u6377\u65b9\u5f0f\u65b9\u4fbf\u90e8\u7f72\u3002", "result": "\u4e0eCephFS\u548cLustre\u76f8\u6bd4\uff0cFalconFS\u5c0f\u6587\u4ef6\u8bfb\u5199\u541e\u5410\u91cf\u6700\u9ad8\u8fbe5.72\u500d\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u541e\u5410\u91cf\u6700\u9ad8\u8fbe12.81\u500d\u3002", "conclusion": "FalconFS\u5728\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u80fd\u5728\u5927\u89c4\u6a21\u751f\u4ea7\u73af\u5883\u7a33\u5b9a\u8fd0\u884c\u3002"}}
{"id": "2507.09863", "pdf": "https://arxiv.org/pdf/2507.09863", "abs": "https://arxiv.org/abs/2507.09863", "authors": ["Ryuji Hashimoto", "Kiyoshi Izumi"], "title": "Towards Realistic and Interpretable Market Simulations: Factorizing Financial Power Law using Optimal Transport", "categories": ["q-fin.CP"], "comment": null, "summary": "We investigate the mechanisms behind the power-law distribution of stock\nreturns using artificial market simulations. While traditional financial theory\nassumes Gaussian price fluctuations, empirical studies consistently show that\nthe tails of return distributions follow a power law. Previous research has\nproposed hypotheses for this phenomenon -- some attributing it to investor\nbehavior, others to institutional demand imbalances. However, these factors\nhave rarely been modeled together to assess their individual and joint\ncontributions. The complexity of real financial markets complicates the\nisolation of the contribution of a single component using existing data. To\naddress this, we construct artificial markets and conduct controlled\nexperiments using optimal transport (OT) as a quantitative similarity measure.\nOur proposed framework incrementally introduces behavioral components into the\nagent models, allowing us to compare each simulation output with empirical data\nvia OT distances. The results highlight that informational effect of prices\nplays a dominant role in reproducing power-law behavior and that multiple\ncomponents interact synergistically to amplify this effect.", "AI": {"tldr": "\u901a\u8fc7\u4eba\u5de5\u5e02\u573a\u6a21\u62df\u7814\u7a76\u80a1\u7968\u6536\u76ca\u5e42\u5f8b\u5206\u5e03\u673a\u5236\uff0c\u53d1\u73b0\u4ef7\u683c\u4fe1\u606f\u6548\u5e94\u8d77\u4e3b\u5bfc\u4f5c\u7528\uff0c\u591a\u56e0\u7d20\u534f\u540c\u653e\u5927\u8be5\u6548\u5e94\u3002", "motivation": "\u4f20\u7edf\u91d1\u878d\u7406\u8bba\u5047\u8bbe\u4ef7\u683c\u6ce2\u52a8\u4e3a\u9ad8\u65af\u5206\u5e03\uff0c\u4f46\u5b9e\u8bc1\u663e\u793a\u6536\u76ca\u5206\u5e03\u5c3e\u90e8\u4e3a\u5e42\u5f8b\u5206\u5e03\uff0c\u4ee5\u5f80\u7814\u7a76\u672a\u5c06\u591a\u79cd\u56e0\u7d20\u5efa\u6a21\u8bc4\u4f30\u5176\u8d21\u732e\uff0c\u4e14\u73b0\u5b9e\u5e02\u573a\u590d\u6742\u96be\u4ee5\u5206\u79bb\u5355\u4e00\u56e0\u7d20\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4eba\u5de5\u5e02\u573a\uff0c\u7528\u6700\u4f18\u4f20\u8f93\uff08OT\uff09\u4f5c\u4e3a\u5b9a\u91cf\u76f8\u4f3c\u6027\u5ea6\u91cf\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u5728\u4ee3\u7406\u6a21\u578b\u4e2d\u9010\u6b65\u5f15\u5165\u884c\u4e3a\u7ec4\u4ef6\uff0c\u901a\u8fc7OT\u8ddd\u79bb\u6bd4\u8f83\u6a21\u62df\u8f93\u51fa\u548c\u5b9e\u8bc1\u6570\u636e\u3002", "result": "\u4ef7\u683c\u7684\u4fe1\u606f\u6548\u5e94\u5728\u518d\u73b0\u5e42\u5f8b\u884c\u4e3a\u4e2d\u8d77\u4e3b\u5bfc\u4f5c\u7528\uff0c\u591a\u4e2a\u7ec4\u4ef6\u534f\u540c\u653e\u5927\u8be5\u6548\u5e94\u3002", "conclusion": "\u4ef7\u683c\u4fe1\u606f\u6548\u5e94\u53ca\u591a\u7ec4\u4ef6\u534f\u540c\u4f5c\u7528\u5bf9\u80a1\u7968\u6536\u76ca\u5e42\u5f8b\u5206\u5e03\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2507.09620", "pdf": "https://arxiv.org/pdf/2507.09620", "abs": "https://arxiv.org/abs/2507.09620", "authors": ["George Z. Li", "Zihan Tan", "Tianyi Zhang"], "title": "Paths and Intersections: Exact Emulators for Planar Graphs", "categories": ["cs.DS", "math.CO"], "comment": "FOCS 2025", "summary": "We study vertex sparsification for preserving distances in planar graphs.\nGiven an edge-weighted planar graph with $k$ terminals, the goal is to\nconstruct an emulator, which is a smaller edge-weighted planar graph that\ncontains the terminals and exactly preserves the pairwise distances between\nthem. We construct exact planar emulators of size $O(f^2k^2)$ in the setting\nwhere terminals lie on $f$ faces in the planar embedding of the input graph.\nOur result generalizes and interpolates between the previous results of Chang\nand Ophelders and Goranci, Henzinger, and Peng which is an $O(k^2)$ bound in\nthe setting where all terminals lie on a single face (i.e., $f=1$), and the\nresult of Krauthgamer, Nguyen, and Zondiner, which is an $O(k^4)$ bound for the\ngeneral case (i.e., $f=k$).\n  Our construction follows a recent new way of analyzing graph structures, by\nviewing graphs as paths and their intersections, which we believe is of\nindependent interest.", "AI": {"tldr": "\u7814\u7a76\u5e73\u9762\u56fe\u4e2d\u4fdd\u7559\u8ddd\u79bb\u7684\u9876\u70b9\u7a00\u758f\u5316\u95ee\u9898\uff0c\u6784\u5efa\u7279\u5b9a\u60c5\u51b5\u4e0b\u5927\u5c0f\u4e3a$O(f^2k^2)$\u7684\u7cbe\u786e\u5e73\u9762\u6a21\u62df\u5668\u3002", "motivation": "\u5728\u7ed9\u5b9a\u5e26\u6743\u5e73\u9762\u56fe\u548c$k$\u4e2a\u7ec8\u7aef\u7684\u60c5\u51b5\u4e0b\uff0c\u6784\u5efa\u80fd\u4fdd\u7559\u7ec8\u7aef\u95f4\u6210\u5bf9\u8ddd\u79bb\u7684\u66f4\u5c0f\u5e26\u6743\u5e73\u9762\u56fe\uff08\u6a21\u62df\u5668\uff09\u3002", "method": "\u91c7\u7528\u5c06\u56fe\u89c6\u4e3a\u8def\u5f84\u53ca\u5176\u4ea4\u96c6\u7684\u65b0\u56fe\u7ed3\u6784\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u5728\u7ec8\u7aef\u4f4d\u4e8e\u8f93\u5165\u56fe\u5e73\u9762\u5d4c\u5165\u7684$f$\u4e2a\u9762\u4e0a\u65f6\uff0c\u6784\u5efa\u51fa\u5927\u5c0f\u4e3a$O(f^2k^2)$\u7684\u7cbe\u786e\u5e73\u9762\u6a21\u62df\u5668\uff0c\u63a8\u5e7f\u5e76\u63d2\u503c\u4e86\u4e4b\u524d\u7684\u7ed3\u679c\u3002", "conclusion": "\u6240\u91c7\u7528\u7684\u56fe\u7ed3\u6784\u5206\u6790\u65b9\u6cd5\u6709\u72ec\u7acb\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2507.09039", "pdf": "https://arxiv.org/pdf/2507.09039", "abs": "https://arxiv.org/abs/2507.09039", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "title": "Towards Extracting Software Requirements from App Reviews using Seq2seq Framework", "categories": ["cs.SE"], "comment": null, "summary": "Mobile app reviews are a large-scale data source for software improvements. A\nkey task in this context is effectively extracting requirements from app\nreviews to analyze the users' needs and support the software's evolution.\nRecent studies show that existing methods fail at this task since app reviews\nusually contain informal language, grammatical and spelling errors, and a large\namount of irrelevant information that might not have direct practical value for\ndevelopers. To address this, we propose a novel reformulation of requirements\nextraction as a Named Entity Recognition (NER) task based on the\nsequence-to-sequence (Seq2seq) generation approach. With this aim, we propose a\nSeq2seq framework, incorporating a BiLSTM encoder and an LSTM decoder, enhanced\nwith a self-attention mechanism, GloVe embeddings, and a CRF model. We\nevaluated our framework on two datasets: a manually annotated set of 1,000\nreviews (Dataset 1) and a crowdsourced set of 23,816 reviews (Dataset 2). The\nquantitative evaluation of our framework showed that it outperformed existing\nstate-of-the-art methods with an F1 score of 0.96 on Dataset 2, and achieved\ncomparable performance on Dataset 1 with an F1 score of 0.47.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSeq2seq\u7684NER\u4efb\u52a1\u6846\u67b6\u63d0\u53d6\u5e94\u7528\u8bc4\u8bba\u9700\u6c42\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ece\u5e94\u7528\u8bc4\u8bba\u63d0\u53d6\u9700\u6c42\u6548\u679c\u4e0d\u4f73\uff0c\u8bc4\u8bba\u5b58\u5728\u8bed\u8a00\u4e0d\u89c4\u8303\u548c\u5927\u91cf\u65e0\u5173\u4fe1\u606f\u3002", "method": "\u5c06\u9700\u6c42\u63d0\u53d6\u91cd\u65b0\u5b9a\u4e49\u4e3a\u57fa\u4e8eSeq2seq\u7684NER\u4efb\u52a1\uff0c\u63d0\u51fa\u5305\u542bBiLSTM\u7f16\u7801\u5668\u3001LSTM\u89e3\u7801\u5668\u7684\u6846\u67b6\uff0c\u589e\u5f3a\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u3001GloVe\u5d4c\u5165\u548cCRF\u6a21\u578b\u3002", "result": "\u5728\u6570\u636e\u96c62\u4e0aF1\u5206\u65700.96\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u5728\u6570\u636e\u96c61\u4e0aF1\u5206\u65700.47\uff0c\u8868\u73b0\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u4ece\u5e94\u7528\u8bc4\u8bba\u63d0\u53d6\u9700\u6c42\u65b9\u9762\u6709\u6548\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.08833", "pdf": "https://arxiv.org/pdf/2507.08833", "abs": "https://arxiv.org/abs/2507.08833", "authors": ["Seokmin Ko"], "title": "LoRA Is Slower Than You Think", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) is one of the most widely used techniques for\nfine-tuning large language models (LLMs). By introducing a small number of\ntrainable low-rank weight matrices, LoRA substantially reduces the number of\nparameters that need to be updated, offering significant advantages in memory\nconsumption and computational efficiency compared to full fine-tuning. However,\nwe observed that LoRA does not consistently provide speed improvements across\nall model architectures and training setups. Motivated by this inconsistency,\nwe conduct a comprehensive analysis of LoRA's performance and investigate the\nunderlying factors limiting its speedup. Based on our findings, we propose\nseveral methods for more efficient fine-tuning of LLMs. We empirically evaluate\nthese methods and compare them to LoRA, demonstrating that our approach\nachieves comparable or superior performance while delivering more consistent\ntraining speed improvements. Our work offers valuable insights and practical\nguidelines for practitioners seeking to optimize LLM fine-tuning under resource\nconstraints.", "AI": {"tldr": "\u5206\u6790LoRA\u5728\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u901f\u5ea6\u63d0\u5347\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u51fa\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5e76\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "LoRA\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u8bbe\u7f6e\u4e0b\u901f\u5ea6\u63d0\u5347\u4e0d\u4e00\u81f4\uff0c\u9700\u5206\u6790\u6027\u80fd\u5e76\u63a2\u7a76\u9650\u5236\u63d0\u901f\u56e0\u7d20\u3002", "method": "\u5bf9LoRA\u6027\u80fd\u8fdb\u884c\u5168\u9762\u5206\u6790\uff0c\u63d0\u51fa\u51e0\u79cd\u66f4\u9ad8\u6548\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u80fd\u8fbe\u5230\u4e0eLoRA\u76f8\u5f53\u6216\u66f4\u4f18\u6027\u80fd\uff0c\u4e14\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u4e3a\u8d44\u6e90\u53d7\u9650\u4e0b\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u6709\u4ef7\u503c\u89c1\u89e3\u548c\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2507.10465", "pdf": "https://arxiv.org/pdf/2507.10465", "abs": "https://arxiv.org/abs/2507.10465", "authors": ["Abeer M. Hasan", "Ying-Ju Chen"], "title": "Flexible Modeling of Multivariate Skewed and Heavy-Tailed Data via a Non-Central Skew t Distribution: Application to Tumor Shape Data", "categories": ["stat.ME", "stat.CO"], "comment": "22 pages, 9 figures", "summary": "We propose a flexible formulation of the multivariate non-central skew t\n(NCST) distribution, defined by scaling skew-normal random vectors with\nindependent chi-squared variables. This construction extends the classical\nmultivariate t family by allowing both asymmetry and non-centrality, which\nprovides an alternative to existing skew t models that often rely on\nrestrictive assumptions for tractability. We derive key theoretical properties\nof the NCST distribution, which includes its moment structure, affine\ntransformation behavior, and the distribution of quadratic forms. Due to the\nlack of a closed-form density, we implement a Monte Carlo likelihood\napproximation to enable maximum likelihood estimation and evaluate its\nperformance through simulation studies. To demonstrate practical utility, we\napply the NCST model to breast cancer diagnostic data, modeling multiple\nfeatures of tumor shape. The NCST model achieves a superior fit based on\ninformation criteria and visual diagnostics, particularly in the presence of\nskewness and heavy tails compared to standard alternatives, including the\nmultivariate normal, skew normal, and Azzalini's skew $t$ distribution. Our\nfindings suggest that the NCST distribution offers a useful and interpretable\nchoice for modeling complex multivariate data, which highlights promising\ndirections for future development in likelihood inference, Bayesian\ncomputation, and applications involving asymmetry and non-Gaussian dependence.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5143\u975e\u4e2d\u5fc3\u504ft\u5206\u5e03\uff08NCST\uff09\u7075\u6d3b\u516c\u5f0f\uff0c\u63a8\u5bfc\u5176\u7406\u8bba\u6027\u8d28\uff0c\u7528\u8499\u7279\u5361\u7f57\u4f3c\u7136\u8fd1\u4f3c\u4f30\u8ba1\uff0c\u5e94\u7528\u4e8e\u4e73\u817a\u764c\u8bca\u65ad\u6570\u636e\uff0c\u7ed3\u679c\u663e\u793aNCST\u6a21\u578b\u62df\u5408\u66f4\u4f18\uff0c\u6709\u53d1\u5c55\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u504ft\u6a21\u578b\u5e38\u4f9d\u8d56\u4e25\u683c\u5047\u8bbe\uff0c\u4e3a\u591a\u5143\u6570\u636e\u5efa\u6a21\u63d0\u4f9b\u4e00\u79cd\u80fd\u540c\u65f6\u8003\u8651\u4e0d\u5bf9\u79f0\u6027\u548c\u975e\u4e2d\u5fc3\u6027\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u7528\u72ec\u7acb\u5361\u65b9\u53d8\u91cf\u7f29\u653e\u504f\u6b63\u6001\u968f\u673a\u5411\u91cf\u5b9a\u4e49NCST\u5206\u5e03\uff1b\u63a8\u5bfc\u5176\u5173\u952e\u7406\u8bba\u6027\u8d28\uff1b\u91c7\u7528\u8499\u7279\u5361\u7f57\u4f3c\u7136\u8fd1\u4f3c\u8fdb\u884c\u6781\u5927\u4f3c\u7136\u4f30\u8ba1\uff1b\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u8bc4\u4f30\u6027\u80fd\uff1b\u5c06\u6a21\u578b\u5e94\u7528\u4e8e\u4e73\u817a\u764c\u8bca\u65ad\u6570\u636e\u3002", "result": "\u5728\u4fe1\u606f\u51c6\u5219\u548c\u53ef\u89c6\u5316\u8bca\u65ad\u65b9\u9762\uff0cNCST\u6a21\u578b\u6bd4\u591a\u5143\u6b63\u6001\u3001\u504f\u6b63\u6001\u548cAzzalini\u504ft\u5206\u5e03\u7b49\u6807\u51c6\u66ff\u4ee3\u65b9\u6848\u62df\u5408\u66f4\u4f18\uff0c\u5c24\u5176\u5728\u5904\u7406\u504f\u6001\u548c\u539a\u5c3e\u6570\u636e\u65f6\u3002", "conclusion": "NCST\u5206\u5e03\u4e3a\u590d\u6742\u591a\u5143\u6570\u636e\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u9009\u62e9\uff0c\u5728\u4f3c\u7136\u63a8\u65ad\u3001\u8d1d\u53f6\u65af\u8ba1\u7b97\u53ca\u6d89\u53ca\u4e0d\u5bf9\u79f0\u548c\u975e\u9ad8\u65af\u4f9d\u8d56\u7684\u5e94\u7528\u65b9\u9762\u6709\u53d1\u5c55\u524d\u666f\u3002"}}
{"id": "2507.10041", "pdf": "https://arxiv.org/pdf/2507.10041", "abs": "https://arxiv.org/abs/2507.10041", "authors": ["Sourojyoti Barick"], "title": "An Accurate Discretized Approach to Parameter Estimation in the CKLS Model via the CIR Framework", "categories": ["stat.AP", "q-fin.ST"], "comment": null, "summary": "This paper provides insight into the estimation and asymptotic behavior of\nparameters in interest rate models, focusing primarily on the\nCox-Ingersoll-Ross (CIR) process and its extension -- the more general\nChan-Karolyi-Longstaff-Sanders (CKLS) framework ($\\alpha\\in[0.5,1]$). The CIR\nprocess is widely used in modeling interest rates which possess the mean\nreverting feature. An Extension of CIR model, CKLS model serves as a\nfoundational case for analyzing more complex dynamics. We employ Euler-Maruyama\ndiscretization to transform the continuous-time stochastic differential\nequations (SDEs) of these models into a discretized form that facilitates\nefficient simulation and estimation of parameters using linear regression\ntechniques. We established the strong consistency and asymptotic normality of\nthe estimators for the drift and volatility parameters, providing a theoretical\nunderpinning for the parameter estimation process. Additionally, we explore the\nboundary behavior of these models, particularly in the context of\nunattainability at zero and infinity, by examining the scale and speed density\nfunctions associated with generalized SDEs involving polynomial drift and\ndiffusion terms. Furthermore, we derive sufficient conditions for the existence\nof a stationary distribution within the CKLS framework and the corresponding\nstationary density function; and discuss its dependence on model parameters for\n$\\alpha\\in[0.5,1]$.", "AI": {"tldr": "\u8bba\u6587\u805a\u7126CIR\u548cCKLS\u5229\u7387\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u4e0e\u6e10\u8fd1\u884c\u4e3a\uff0c\u7528\u6b27\u62c9 - \u4e38\u5c71\u79bb\u6563\u5316\u5904\u7406\uff0c\u8bc1\u660e\u4f30\u8ba1\u91cf\u6027\u8d28\uff0c\u63a2\u7d22\u8fb9\u754c\u884c\u4e3a\uff0c\u63a8\u5bfc\u5e73\u7a33\u5206\u5e03\u6761\u4ef6\u3002", "motivation": "\u7814\u7a76\u5229\u7387\u6a21\u578b\u4e2d\u53c2\u6570\u7684\u4f30\u8ba1\u548c\u6e10\u8fd1\u884c\u4e3a\uff0c\u4e3a\u5229\u7387\u5efa\u6a21\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91c7\u7528\u6b27\u62c9 - \u4e38\u5c71\u79bb\u6563\u5316\u5c06\u8fde\u7eed\u65f6\u95f4\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u8f6c\u5316\u4e3a\u79bb\u6563\u5f62\u5f0f\uff0c\u7528\u7ebf\u6027\u56de\u5f52\u6280\u672f\u8fdb\u884c\u53c2\u6570\u4f30\u8ba1\u3002", "result": "\u8bc1\u660e\u4e86\u6f02\u79fb\u548c\u6ce2\u52a8\u7387\u53c2\u6570\u4f30\u8ba1\u91cf\u7684\u5f3a\u4e00\u81f4\u6027\u548c\u6e10\u8fd1\u6b63\u6001\u6027\uff0c\u63a2\u7d22\u4e86\u6a21\u578b\u8fb9\u754c\u884c\u4e3a\uff0c\u63a8\u5bfc\u4e86CKLS\u6846\u67b6\u4e0b\u5e73\u7a33\u5206\u5e03\u5b58\u5728\u7684\u5145\u5206\u6761\u4ef6\u53ca\u76f8\u5e94\u5e73\u7a33\u5bc6\u5ea6\u51fd\u6570\u3002", "conclusion": "\u4e3a\u5229\u7387\u6a21\u578b\u7684\u53c2\u6570\u4f30\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u6709\u52a9\u4e8e\u5206\u6790\u590d\u6742\u5229\u7387\u52a8\u6001\u3002"}}
{"id": "2507.09093", "pdf": "https://arxiv.org/pdf/2507.09093", "abs": "https://arxiv.org/abs/2507.09093", "authors": ["Aleksandar Armacki", "Dragana Bajovic", "Dusan Jakovetic", "Soummya Kar"], "title": "Optimal High-probability Convergence of Nonlinear SGD under Heavy-tailed Noise via Symmetrization", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": "38 pages, 1 figure", "summary": "We study convergence in high-probability of SGD-type methods in non-convex\noptimization and the presence of heavy-tailed noise. To combat the heavy-tailed\nnoise, a general black-box nonlinear framework is considered, subsuming\nnonlinearities like sign, clipping, normalization and their smooth\ncounterparts. Our first result shows that nonlinear SGD (N-SGD) achieves the\nrate $\\widetilde{\\mathcal{O}}(t^{-1/2})$, for any noise with unbounded moments\nand a symmetric probability density function (PDF). Crucially, N-SGD has\nexponentially decaying tails, matching the performance of linear SGD under\nlight-tailed noise. To handle non-symmetric noise, we propose two novel\nestimators, based on the idea of noise symmetrization. The first, dubbed\nSymmetrized Gradient Estimator (SGE), assumes a noiseless gradient at any\nreference point is available at the start of training, while the second, dubbed\nMini-batch SGE (MSGE), uses mini-batches to estimate the noiseless gradient.\nCombined with the nonlinear framework, we get N-SGE and N-MSGE methods,\nrespectively, both achieving the same convergence rate and exponentially\ndecaying tails as N-SGD, while allowing for non-symmetric noise with unbounded\nmoments and PDF satisfying a mild technical condition, with N-MSGE additionally\nrequiring bounded noise moment of order $p \\in (1,2]$. Compared to works\nassuming noise with bounded $p$-th moment, our results: 1) are based on a novel\nsymmetrization approach; 2) provide a unified framework and relaxed moment\nconditions; 3) imply optimal oracle complexity of N-SGD and N-SGE, strictly\nbetter than existing works when $p < 2$, while the complexity of N-MSGE is\nclose to existing works. Compared to works assuming symmetric noise with\nunbounded moments, we: 1) provide a sharper analysis and improved rates; 2)\nfacilitate state-dependent symmetric noise; 3) extend the strong guarantees to\nnon-symmetric noise.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.09928", "pdf": "https://arxiv.org/pdf/2507.09928", "abs": "https://arxiv.org/abs/2507.09928", "authors": ["Apurv Shukla", "Vijay Subramanian", "Andy Zhao", "Rahul Jain"], "title": "Generalized Quantal Response Equilibrium: Existence and Efficient Learning", "categories": ["cs.GT", "math.OC"], "comment": null, "summary": "We introduce a new solution concept for bounded rational agents in finite\nnormal-form general-sum games called Generalized Quantal Response Equilibrium\n(GQRE) which generalizes Quantal Response\nEquilibrium~\\citep{mckelvey1995quantal}. In our setup, each player maximizes a\nsmooth, regularized expected utility of the mixed profiles used, reflecting\nbounded rationality that subsumes stochastic choice. After establishing\nexistence under mild conditions, we present computationally efficient no-regret\nindependent learning via smoothened versions of the Frank-Wolfe algorithm. Our\nalgorithm uses noisy but correlated gradient estimates generated via a\nsimulation oracle that reports on repeated plays of the game. We analyze\nconvergence properties of our algorithm under assumptions that ensure\nuniqueness of equilibrium, using a class of gap functions that generalize the\nNash gap. We end by demonstrating the effectiveness of our method on a set of\ncomplex general-sum games such as high-rank two-player games, large action\ntwo-player games, and known examples of difficult multi-player games.", "AI": {"tldr": "\u63d0\u51fa\u5e7f\u4e49\u91cf\u5b50\u54cd\u5e94\u5747\u8861\uff08GQRE\uff09\u6982\u5ff5\uff0c\u7ed9\u51fa\u9ad8\u6548\u65e0\u9057\u61be\u72ec\u7acb\u5b66\u4e60\u7b97\u6cd5\uff0c\u5206\u6790\u6536\u655b\u6027\u5e76\u5728\u590d\u6742\u535a\u5f08\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u6709\u9650\u6b63\u5219\u5f62\u5f0f\u4e00\u822c\u548c\u535a\u5f08\u4e2d\u7684\u6709\u9650\u7406\u6027\u53c2\u4e0e\u8005\u5f15\u5165\u65b0\u7684\u89e3\u6982\u5ff5\u3002", "method": "\u901a\u8fc7Frank - Wolfe\u7b97\u6cd5\u7684\u5e73\u6ed1\u7248\u672c\u8fdb\u884c\u65e0\u9057\u61be\u72ec\u7acb\u5b66\u4e60\uff0c\u5229\u7528\u6a21\u62df\u9884\u8a00\u673a\u751f\u6210\u566a\u58f0\u4f46\u76f8\u5173\u7684\u68af\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728\u786e\u4fdd\u5747\u8861\u552f\u4e00\u6027\u7684\u5047\u8bbe\u4e0b\u5206\u6790\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u590d\u6742\u7684\u4e00\u822c\u548c\u535a\u5f08\u4e2d\u6709\u6548\u3002"}}
{"id": "2507.10069", "pdf": "https://arxiv.org/pdf/2507.10069", "abs": "https://arxiv.org/abs/2507.10069", "authors": ["Zedong Liu", "Shenggan Cheng", "Guangming Tan", "Yang You", "Dingwen Tao"], "title": "ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Multimodal large language models (MLLMs) extend LLMs to handle images,\nvideos, and audio by incorporating feature extractors and projection modules.\nHowever, these additional components -- combined with complex inference\npipelines and heterogeneous workloads -- introduce significant inference\noverhead. Therefore, efficiently serving MLLMs remains a major challenge.\nCurrent tightly coupled serving architectures struggle to distinguish between\nmixed request types or adapt parallelism strategies to different inference\nstages, leading to increased time-to-first-token (TTFT) latency and poor\nresource utilization. To address this, we propose Elastic Multimodal\nParallelism (EMP), a new serving paradigm that elastically adapts to resource\nheterogeneity across request types and inference stages. Building upon EMP, we\ndevelop ElasticMM, an MLLM serving system that (1) separates requests into\nindependent modality groups with dynamic resource allocation via a\nmodality-aware load balancer; (2) decouples inference stages and enables\nparallelism adjustment and adaptive scaling via elastic partition scheduling;\nand (3) improves inference efficiency through unified multimodal prefix caching\nand non-blocking encoding. Experiments on diverse real-world datasets show that\nElasticMM outperforms state-of-the-art (SOTA) serving systems, reducing TTFT by\nup to 4.2x and achieving 3.2-4.5x higher throughput while meeting service-level\nobjectives (SLOs).", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5f00\u9500\u5927\uff0c\u63d0\u51fa\u5f39\u6027\u591a\u6a21\u6001\u5e76\u884c\u8303\u5f0fEMP\u53ca\u670d\u52a1\u7cfb\u7edfElasticMM\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8eSOTA\u7cfb\u7edf\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u989d\u5916\u7ec4\u4ef6\u3001\u590d\u6742\u63a8\u7406\u6d41\u7a0b\u548c\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u5bfc\u81f4\u63a8\u7406\u5f00\u9500\u5927\uff0c\u73b0\u6709\u670d\u52a1\u67b6\u6784\u96be\u4ee5\u533a\u5206\u6df7\u5408\u8bf7\u6c42\u7c7b\u578b\u548c\u8c03\u6574\u5e76\u884c\u7b56\u7565\uff0c\u9700\u9ad8\u6548\u670d\u52a1\u65b9\u6848\u3002", "method": "\u63d0\u51faEMP\u8303\u5f0f\uff0c\u57fa\u4e8e\u6b64\u5f00\u53d1ElasticMM\u7cfb\u7edf\uff0c\u5305\u62ec\u901a\u8fc7\u6a21\u6001\u611f\u77e5\u8d1f\u8f7d\u5747\u8861\u5668\u5206\u79bb\u8bf7\u6c42\u3001\u5f39\u6027\u5206\u533a\u8c03\u5ea6\u89e3\u8026\u63a8\u7406\u9636\u6bb5\u3001\u7edf\u4e00\u591a\u6a21\u6001\u524d\u7f00\u7f13\u5b58\u548c\u975e\u963b\u585e\u7f16\u7801\u3002", "result": "\u5728\u4e0d\u540c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cElasticMM\u6bd4SOTA\u670d\u52a1\u7cfb\u7edf\u5c06TTFT\u964d\u4f4e4.2\u500d\uff0c\u541e\u5410\u91cf\u63d0\u9ad83.2 - 4.5\u500d\uff0c\u4e14\u6ee1\u8db3\u670d\u52a1\u6c34\u5e73\u76ee\u6807\u3002", "conclusion": "ElasticMM\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u6548\u7387\u95ee\u9898\uff0c\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u73b0\u6709\u7cfb\u7edf\u3002"}}
{"id": "2507.09331", "pdf": "https://arxiv.org/pdf/2507.09331", "abs": "https://arxiv.org/abs/2507.09331", "authors": ["Kirill Khrylchenko", "Vladimir Baikalov", "Sergei Makeev", "Artem Matveev", "Sergei Liamaev"], "title": "Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval", "categories": ["cs.IR"], "comment": "Accepted at ACM RecSys 2025. Author's version. To appear in the\n  Proceedings of the 18th ACM Conference on Recommender Systems", "summary": "Two-tower neural networks are a popular architecture for the retrieval stage\nin recommender systems. These models are typically trained with a softmax loss\nover the item catalog. However, in web-scale settings, the item catalog is\noften prohibitively large, making full softmax infeasible. A common solution is\nsampled softmax, which approximates the full softmax using a small number of\nsampled negatives.\n  One practical and widely adopted approach is to use in-batch negatives, where\nnegatives are drawn from items in the current mini-batch. However, this\nintroduces a bias: items that appear more frequently in the batch (i.e.,\npopular items) are penalized more heavily.\n  To mitigate this issue, a popular industry technique known as logQ correction\nadjusts the logits during training by subtracting the log-probability of an\nitem appearing in the batch. This correction is derived by analyzing the bias\nin the gradient and applying importance sampling, effectively twice, using the\nin-batch distribution as a proposal distribution. While this approach improves\nmodel quality, it does not fully eliminate the bias.\n  In this work, we revisit the derivation of logQ correction and show that it\noverlooks a subtle but important detail: the positive item in the denominator\nis not Monte Carlo-sampled - it is always present with probability 1. We\npropose a refined correction formula that accounts for this. Notably, our loss\nintroduces an interpretable sample weight that reflects the model's uncertainty\n- the probability of misclassification under the current parameters. We\nevaluate our method on both public and proprietary datasets, demonstrating\nconsistent improvements over the standard logQ correction.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u53cc\u5854\u795e\u7ecf\u7f51\u7edc\u68c0\u7d22\u9636\u6bb5\u5e38\u7528\u7684\u6279\u5185\u8d1f\u91c7\u6837\u6709\u504f\u5dee\uff0clogQ\u6821\u6b63\u672a\u5b8c\u5168\u6d88\u9664\u504f\u5dee\uff0c\u63d0\u51fa\u6539\u8fdb\u6821\u6b63\u516c\u5f0f\uff0c\u5b9e\u9a8c\u663e\u793a\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u53cc\u5854\u795e\u7ecf\u7f51\u7edc\u5728\u7f51\u7edc\u89c4\u6a21\u5927\u65f6\u4f7f\u7528\u6279\u5185\u8d1f\u91c7\u6837\u6709\u504f\u5dee\uff0clogQ\u6821\u6b63\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u504f\u5dee\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u91cd\u65b0\u63a8\u5bfclogQ\u6821\u6b63\uff0c\u63d0\u51fa\u8003\u8651\u6b63\u6837\u672c\u6982\u7387\u4e3a1\u7684\u6539\u8fdb\u6821\u6b63\u516c\u5f0f\uff0c\u5f15\u5165\u53cd\u6620\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u6837\u672c\u6743\u91cd\u3002", "result": "\u5728\u516c\u5171\u548c\u4e13\u6709\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6807\u51c6logQ\u6821\u6b63\u6709\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u63d0\u51fa\u7684\u6539\u8fdb\u6821\u6b63\u516c\u5f0f\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6548\u679c\uff0c\u4f18\u4e8e\u6807\u51c6logQ\u6821\u6b63\u3002"}}
{"id": "2507.09675", "pdf": "https://arxiv.org/pdf/2507.09675", "abs": "https://arxiv.org/abs/2507.09675", "authors": ["Seyed Mohammad Ali Jafari", "Ali Mobini Dehkordi", "Ehsan Chitsaz", "Yadollah Yaghoobzadeh"], "title": "What Matters Most? A Quantitative Meta-Analysis of AI-Based Predictors for Startup Success", "categories": ["cs.CE", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Background: Predicting startup success with machine learning is a rapidly\ngrowing field, yet findings on key predictors are often fragmented and\ncontext-specific. This makes it difficult to discern robust patterns and\nhighlights a need for a systematic synthesis of the evidence.\n  Methods: This study conducts a quantitative meta-analysis to synthesize the\nliterature on predictor importance in AI-based startup evaluation. We performed\na systematic review to identify a final sample of 13 empirical studies that\nreport rankable feature importance. From these papers, we extracted and\ncategorized 58 unique predictors, synthesizing their importance using a\nWeighted Importance Score (WIS) that balances a feature's average rank with its\nfrequency of appearance. We also conducted a moderator analysis to investigate\nhow predictor importance changes with context (e.g., success definition).\n  Results: Our aggregate analysis reveals that the most consistently powerful\npredictors are a quartet of foundational attributes: Firm Characteristics\n(e.g., age, location), Investor Structure (e.g., investor quality), Digital and\nSocial Traction (e.g., online momentum), and Funding History. The moderator\nanalysis further reveals that this hierarchy is highly context-dependent. For\ninstance, predicting near-term funding milestones elevates the importance of\nthe deal's immediate context, while predicting long-term exits prioritizes\nfundamental firm and investor characteristics.\n  Conclusion: The factors that best predict startup success are not universal\nbut are contingent on the startup's goals, stage, and the data used for\nevaluation. Our findings point to a potential \"convenience bias\" in the\nliterature, where predictor importance may be tied to data accessibility. We\nconclude by underscoring the need for standardized reporting practices to\nenable more robust, cumulative knowledge building in the field.", "AI": {"tldr": "\u6587\u7ae0\u901a\u8fc7\u5143\u5206\u6790\u7efc\u5408AI\u521d\u521b\u4f01\u4e1a\u8bc4\u4f30\u6587\u732e\uff0c\u53d1\u73b0\u9884\u6d4b\u6210\u529f\u56e0\u7d20\u5177\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u6307\u51fa\u9700\u6807\u51c6\u5316\u62a5\u544a\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u6210\u529f\u7684\u5173\u952e\u9884\u6d4b\u56e0\u7d20\u7814\u7a76\u96f6\u6563\u4e14\u5177\u60c5\u5883\u7279\u5f02\u6027\uff0c\u9700\u7cfb\u7edf\u7efc\u5408\u8bc1\u636e\u3002", "method": "\u8fdb\u884c\u5b9a\u91cf\u5143\u5206\u6790\uff0c\u7cfb\u7edf\u56de\u987e\u786e\u5b9a13\u9879\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u53d658\u4e2a\u72ec\u7279\u9884\u6d4b\u56e0\u7d20\uff0c\u7528\u52a0\u6743\u91cd\u8981\u6027\u5206\u6570\u7efc\u5408\u5176\u91cd\u8981\u6027\uff0c\u8fd8\u8fdb\u884c\u8c03\u8282\u5206\u6790\u3002", "result": "\u6700\u5177\u9884\u6d4b\u529b\u7684\u662f\u4f01\u4e1a\u7279\u5f81\u3001\u6295\u8d44\u8005\u7ed3\u6784\u3001\u6570\u5b57\u548c\u793e\u4f1a\u5438\u5f15\u529b\u3001\u878d\u8d44\u5386\u53f2\uff1b\u5c42\u6b21\u9ad8\u5ea6\u4f9d\u8d56\u60c5\u5883\u3002", "conclusion": "\u9884\u6d4b\u6210\u529f\u7684\u56e0\u7d20\u975e\u666e\u904d\uff0c\u53d7\u76ee\u6807\u3001\u9636\u6bb5\u548c\u8bc4\u4f30\u6570\u636e\u5f71\u54cd\uff0c\u6307\u51fa\u6587\u732e\u53ef\u80fd\u5b58\u5728\u4fbf\u5229\u504f\u5dee\uff0c\u9700\u6807\u51c6\u5316\u62a5\u544a\u4fc3\u8fdb\u77e5\u8bc6\u79ef\u7d2f\u3002"}}
{"id": "2507.09642", "pdf": "https://arxiv.org/pdf/2507.09642", "abs": "https://arxiv.org/abs/2507.09642", "authors": ["Yina Lv", "Qiao Li", "Quanqing Xu", "Congming Gao", "Chuanhui Yang", "Xiaoli Wang", "Chun Jason Xue"], "title": "Rethinking LSM-tree based Key-Value Stores: A Survey", "categories": ["cs.DB"], "comment": null, "summary": "LSM-tree is a widely adopted data structure in modern key-value store systems\nthat optimizes write performance in write-heavy applications by using append\nwrites to achieve sequential writes. However, the unpredictability of LSM-tree\ncompaction introduces significant challenges, including performance variability\nduring peak workloads and in resource-constrained environments, write\namplification caused by data rewriting during compactions, read amplification\nfrom multi-level queries, trade-off between read and write performance, as well\nas efficient space utilization to mitigate space amplification. Prior studies\non LSM-tree optimizations have addressed the above challenges; however, in\nrecent years, research on LSM-tree optimization has continued to propose. The\ngoal of this survey is to review LSM-tree optimization, focusing on\nrepresentative works in the past five years. This survey first studies existing\nsolutions on how to mitigate the performance impact of LSM-tree flush and\ncompaction and how to improve basic key-value operations. In addition,\ndistributed key-value stores serve multi-tenants, ranging from tens of\nthousands to millions of users with diverse requirements. We then analyze the\nnew challenges and opportunities in these modern architectures and across\nvarious application scenarios. Unlike the existing survey papers, this survey\nprovides a detailed discussion of the state-of-the-art work on LSM-tree\noptimizations and gives future research directions.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8fd1\u4e94\u5e74LSM - tree\u4f18\u5316\u7684\u4ee3\u8868\u6027\u5de5\u4f5c\u8fdb\u884c\u7efc\u8ff0\uff0c\u7814\u7a76\u73b0\u6709\u7f13\u89e3flush\u548ccompaction\u6027\u80fd\u5f71\u54cd\u53ca\u6539\u8fdb\u57fa\u672c\u952e\u503c\u64cd\u4f5c\u7684\u65b9\u6848\uff0c\u5206\u6790\u5206\u5e03\u5f0f\u952e\u503c\u5b58\u50a8\u65b0\u6311\u6218\u4e0e\u673a\u9047\uff0c\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "LSM - tree\u7684compaction\u4e0d\u53ef\u9884\u6d4b\u6027\u5e26\u6765\u8bf8\u591a\u6311\u6218\uff0c\u867d\u6709\u524d\u4eba\u7814\u7a76\uff0c\u4f46\u8fd1\u5e74\u4ecd\u6709\u76f8\u5173\u4f18\u5316\u7814\u7a76\u63d0\u51fa\uff0c\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u7efc\u8ff0\u3002", "method": "\u56de\u987e\u8fd1\u4e94\u5e74LSM - tree\u4f18\u5316\u7684\u4ee3\u8868\u6027\u5de5\u4f5c\uff0c\u7814\u7a76\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u5206\u6790\u73b0\u4ee3\u67b6\u6784\u548c\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e2d\u7684\u60c5\u51b5\u3002", "result": "\u68b3\u7406\u4e86\u7f13\u89e3LSM - tree flush\u548ccompaction\u6027\u80fd\u5f71\u54cd\u4ee5\u53ca\u6539\u8fdb\u57fa\u672c\u952e\u503c\u64cd\u4f5c\u7684\u65b9\u6848\uff0c\u5206\u6790\u4e86\u5206\u5e03\u5f0f\u952e\u503c\u5b58\u50a8\u65b0\u6311\u6218\u4e0e\u673a\u9047\u3002", "conclusion": "\u8be6\u7ec6\u8ba8\u8bba\u4e86LSM - tree\u4f18\u5316\u7684\u6700\u65b0\u5de5\u4f5c\uff0c\u7ed9\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.09992", "pdf": "https://arxiv.org/pdf/2507.09992", "abs": "https://arxiv.org/abs/2507.09992", "authors": ["Yuji Kanagawa", "Kenji Doya"], "title": "Evolution of Fear and Social Rewards in Prey-Predator Relationship", "categories": ["q-bio.PE", "cs.AI", "cs.NE"], "comment": "Preprint. Under review", "summary": "Fear is a critical brain function for detecting danger and learning to avoid\nspecific stimuli that can lead to danger. While fear is believed to have\nevolved under pressure from predators, experimentally reproducing the evolution\nis challenging. To investigate the relationship between environmental\nconditions, the evolution of fear, and the evolution of other rewards, such as\nfood reward and social reward, we developed a distributed evolutionary\nsimulation. In our simulation, prey and predator agents co-evolve their innate\nreward functions, including a possibly fear-like term for observing predators,\nand learn behaviors via reinforcement learning. Surprisingly, our simulation\nrevealed that social reward for observing the same species is more important\nfor prey to survive, and fear-like negative reward for observing predators\nevolves only after acquiring social reward. We also found that the predator\nwith increased hunting ability (larger mouth) amplified fear emergence, but\nalso that fear evolution is more stable with non-evolving predators that are\nbad at chasing prey. Additionally, unlike for predators, we found that positive\nrewards evolve in opposition to fear for stationary threats, as areas with\nabundant leftover food develop around them. These findings suggest that fear\nand social reward have had a complex interplay with each other through\nevolution, along with the nature of predators and threats.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u5e03\u5f0f\u8fdb\u5316\u6a21\u62df\u7814\u7a76\u6050\u60e7\u3001\u793e\u4f1a\u5956\u52b1\u7b49\u7684\u8fdb\u5316\u5173\u7cfb\uff0c\u53d1\u73b0\u793e\u4f1a\u5956\u52b1\u5bf9\u730e\u7269\u751f\u5b58\u66f4\u91cd\u8981\uff0c\u6050\u60e7\u5956\u52b1\u5728\u83b7\u5f97\u793e\u4f1a\u5956\u52b1\u540e\u8fdb\u5316\uff0c\u4e0d\u540c\u6355\u98df\u8005\u5bf9\u6050\u60e7\u8fdb\u5316\u6709\u4e0d\u540c\u5f71\u54cd\u3002", "motivation": "\u63a2\u7a76\u73af\u5883\u6761\u4ef6\u3001\u6050\u60e7\u8fdb\u5316\u4e0e\u5176\u4ed6\u5956\u52b1\uff08\u5982\u98df\u7269\u5956\u52b1\u3001\u793e\u4f1a\u5956\u52b1\uff09\u8fdb\u5316\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u5206\u5e03\u5f0f\u8fdb\u5316\u6a21\u62df\uff0c\u8ba9\u730e\u7269\u548c\u6355\u98df\u8005\u4ee3\u7406\u5171\u540c\u8fdb\u5316\u5176\u5148\u5929\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u884c\u4e3a\u3002", "result": "\u793e\u4f1a\u5956\u52b1\u5bf9\u730e\u7269\u751f\u5b58\u66f4\u91cd\u8981\uff0c\u6050\u60e7\u5956\u52b1\u5728\u83b7\u5f97\u793e\u4f1a\u5956\u52b1\u540e\u8fdb\u5316\uff1b\u6355\u98df\u8005\u72e9\u730e\u80fd\u529b\u589e\u5f3a\u4f1a\u4fc3\u8fdb\u6050\u60e7\u51fa\u73b0\uff0c\u975e\u8fdb\u5316\u4e14\u4e0d\u64c5\u8ffd\u9010\u7684\u6355\u98df\u8005\u4f7f\u6050\u60e7\u8fdb\u5316\u66f4\u7a33\u5b9a\uff1b\u5bf9\u4e8e\u9759\u6b62\u5a01\u80c1\uff0c\u79ef\u6781\u5956\u52b1\u4e0e\u6050\u60e7\u5448\u76f8\u53cd\u8fdb\u5316\u3002", "conclusion": "\u6050\u60e7\u548c\u793e\u4f1a\u5956\u52b1\u5728\u8fdb\u5316\u8fc7\u7a0b\u4e2d\u76f8\u4e92\u4f5c\u7528\u590d\u6742\uff0c\u4e14\u4e0e\u6355\u98df\u8005\u548c\u5a01\u80c1\u7684\u6027\u8d28\u6709\u5173\u3002"}}
{"id": "2507.09089", "pdf": "https://arxiv.org/pdf/2507.09089", "abs": "https://arxiv.org/abs/2507.09089", "authors": ["Joel Becker", "Nate Rush", "Elizabeth Barnes", "David Rein"], "title": "Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity", "categories": ["cs.AI", "cs.HC", "cs.SE", "I.2"], "comment": "50 pages, 8 tables, 22 figures", "summary": "Despite widespread adoption, the impact of AI tools on software development\nin the wild remains understudied. We conduct a randomized controlled trial\n(RCT) to understand how AI tools at the February-June 2025 frontier affect the\nproductivity of experienced open-source developers. 16 developers with moderate\nAI experience complete 246 tasks in mature projects on which they have an\naverage of 5 years of prior experience. Each task is randomly assigned to allow\nor disallow usage of early 2025 AI tools. When AI tools are allowed, developers\nprimarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet.\nBefore starting tasks, developers forecast that allowing AI will reduce\ncompletion time by 24%. After completing the study, developers estimate that\nallowing AI reduced completion time by 20%. Surprisingly, we find that allowing\nAI actually increases completion time by 19%--AI tooling slowed developers\ndown. This slowdown also contradicts predictions from experts in economics (39%\nshorter) and ML (38% shorter). To understand this result, we collect and\nevaluate evidence for 20 properties of our setting that a priori could\ncontribute to the observed slowdown effect--for example, the size and quality\nstandards of projects, or prior developer experience with AI tooling. Although\nthe influence of experimental artifacts cannot be entirely ruled out, the\nrobustness of the slowdown effect across our analyses suggests it is unlikely\nto primarily be a function of our experimental design.", "AI": {"tldr": "\u901a\u8fc7\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u7814\u7a762025\u5e742 - 6\u6708\u524d\u6cbfAI\u5de5\u5177\u5bf9\u6709\u7ecf\u9a8c\u5f00\u6e90\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5141\u8bb8\u4f7f\u7528AI\u5b9e\u9645\u4f7f\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u589e\u52a019%\uff0c\u4e0e\u5f00\u53d1\u8005\u548c\u4e13\u5bb6\u9884\u6d4b\u76f8\u53cd\u3002", "motivation": "\u7814\u7a76AI\u5de5\u5177\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5f71\u54cd\uff0c\u6b64\u524d\u8fd9\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u8fdb\u884c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\uff0c16\u540d\u6709\u4e00\u5b9aAI\u7ecf\u9a8c\u5f00\u53d1\u8005\u5b8c\u6210246\u4e2a\u4efb\u52a1\uff0c\u968f\u673a\u5206\u914d\u662f\u5426\u5141\u8bb8\u4f7f\u75282025\u5e74\u521dAI\u5de5\u5177\u3002", "result": "\u5141\u8bb8\u4f7f\u7528AI\u4f7f\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u589e\u52a019%\uff0c\u4e0e\u5f00\u53d1\u8005\u548c\u4e13\u5bb6\u9884\u6d4b\u7684\u7f29\u77ed\u65f6\u95f4\u76f8\u53cd\u3002", "conclusion": "\u867d\u4e0d\u80fd\u5b8c\u5168\u6392\u9664\u5b9e\u9a8c\u8bef\u5dee\uff0c\u4f46\u5206\u6790\u663e\u793a\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u589e\u52a0\u4e0d\u592a\u53ef\u80fd\u4e3b\u8981\u662f\u5b9e\u9a8c\u8bbe\u8ba1\u95ee\u9898\u3002"}}
{"id": "2507.10140", "pdf": "https://arxiv.org/pdf/2507.10140", "abs": "https://arxiv.org/abs/2507.10140", "authors": ["Daniel Czarnowske", "Florian Heiss", "Theresa M. A. Schmitz", "Amrei Stammann"], "title": "The Effects of Flipped Classrooms in Higher Education: A Causal Machine Learning Analysis", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This study uses double/debiased machine learning to evaluate the impact of\ntransitioning from lecture-based blended teaching to a flipped classroom\nconcept in a cohort comparison of a large compulsory introductory statistics\ncourse at a German tuition-free university. Our findings indicate positive\nchanges in students' self-conception and a reduction in procrastination\nbehaviors. However, we also observe a decline in the enjoyment of classroom\nsessions. Contrary to theoretical expectations, we do not find significant\npositive effects on exam scores, passing rates, or knowledge retention. Unlike\nmost studies, however, we can leverage detailed usage data from the flipped\ncohort, including the timeliness and completeness of pre-class video watching,\nas well as quiz participation patterns, to check how well students implemented\neach part of the curriculum. Our findings suggest that, on average, students in\nthe flipped cohort implemented the instructional approach insufficiently,\nexplaining the mechanism of our null results in exam performance and knowledge\nretention. This highlights the need for additional strategies to ensure that\nstudents actually benefit from a flipped curriculum.", "AI": {"tldr": "\u7814\u7a76\u7528\u53cc/\u53bb\u504f\u673a\u5668\u5b66\u4e60\u8bc4\u4f30\u5fb7\u56fd\u514d\u5b66\u8d39\u5927\u5b66\u7edf\u8ba1\u8bfe\u4ece\u6df7\u5408\u6559\u5b66\u5230\u7ffb\u8f6c\u8bfe\u5802\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b66\u751f\u81ea\u6211\u8ba4\u77e5\u548c\u62d6\u5ef6\u884c\u4e3a\u6709\u79ef\u6781\u53d8\u5316\uff0c\u4f46\u8bfe\u5802\u4e50\u8da3\u51cf\u5c11\uff0c\u8003\u8bd5\u6210\u7ee9\u7b49\u65e0\u663e\u8457\u63d0\u5347\uff0c\u5b66\u751f\u5bf9\u8bfe\u7a0b\u5b9e\u65bd\u4e0d\u8db3\u3002", "motivation": "\u8bc4\u4f30\u4ece\u8bb2\u5ea7\u5f0f\u6df7\u5408\u6559\u5b66\u8f6c\u53d8\u4e3a\u7ffb\u8f6c\u8bfe\u5802\u5bf9\u5927\u578b\u5fc5\u4fee\u7edf\u8ba1\u8bfe\u7a0b\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u53cc/\u53bb\u504f\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u961f\u5217\u6bd4\u8f83\u7814\u7a76\uff0c\u8fd8\u5229\u7528\u7ffb\u8f6c\u8bfe\u5802\u5b66\u751f\u7684\u8be6\u7ec6\u4f7f\u7528\u6570\u636e\u3002", "result": "\u5b66\u751f\u81ea\u6211\u8ba4\u77e5\u6539\u5584\u3001\u62d6\u5ef6\u884c\u4e3a\u51cf\u5c11\uff0c\u4f46\u8bfe\u5802\u4e50\u8da3\u964d\u4f4e\uff0c\u8003\u8bd5\u6210\u7ee9\u3001\u901a\u8fc7\u7387\u548c\u77e5\u8bc6\u4fdd\u7559\u65e0\u663e\u8457\u79ef\u6781\u5f71\u54cd\uff0c\u5b66\u751f\u5bf9\u8bfe\u7a0b\u5b9e\u65bd\u4e0d\u8db3\u3002", "conclusion": "\u9700\u8981\u989d\u5916\u7b56\u7565\u786e\u4fdd\u5b66\u751f\u4ece\u7ffb\u8f6c\u8bfe\u5802\u4e2d\u771f\u6b63\u53d7\u76ca\u3002"}}
{"id": "2507.09688", "pdf": "https://arxiv.org/pdf/2507.09688", "abs": "https://arxiv.org/abs/2507.09688", "authors": ["Mariia Anapolska", "Emma Ahrens", "Christina B\u00fcsing", "Felix Engelhardt", "Timo Gersing", "Corinna Mathwieser", "Sabrian Schmitz", "Sophia Wrede"], "title": "Minimum-Peak-Cost Flows Over Time", "categories": ["cs.DS"], "comment": null, "summary": "When planning transportation whose operation requires non-consumable\nresources, the peak demand for allocated resources is often of higher interest\nthan the duration of resource usage. For instance, it is more cost-effective to\ndeliver parcels with a single truck over eight hours than to use two trucks for\nfour hours, as long as the time suffices. To model such scenarios, we introduce\nthe novel minimum peak cost flow over time problem, whose objective is to\nminimise the maximum cost at all points in time rather than minimising the\nintegral of costs. We focus on minimising peak costs of temporally repeated\nflows. These are desirable for practical applications due to their simple\nstructure. This yields the minimum-peak-cost Temporally Repeated flow problem\n(MPC-TRF).\n  We show that the simple structure of temporally repeated flows comes with the\ndrawback of arbitrarily bad approximation ratios compared to general flows over\ntime. Furthermore, our complexity analysis shows the integral version of\nMPC-TRF is strongly NP-hard, even under strong restrictions. On the positive\nside, we identify two benign special cases: unit-cost series-parallel networks\nand networks with time horizon at least twice as long as the longest path in\nthe network (with respect to the transit time). In both cases, we show that\nintegral optimal flows if the desired flow value equals the maximum flow value\nand fractional optimal flows for arbitrary flow values can be found in\npolynomial time. For each of these cases, we provide an explicit algorithm that\nconstructs an optimal solution.", "AI": {"tldr": "\u63d0\u51fa\u6700\u5c0f\u5cf0\u503c\u6210\u672c\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6d41\u95ee\u9898\uff0c\u805a\u7126\u6700\u5c0f\u5316\u65f6\u95f4\u91cd\u590d\u6d41\u7684\u5cf0\u503c\u6210\u672c\uff0c\u5206\u6790\u5176\u8fd1\u4f3c\u6bd4\u548c\u590d\u6742\u5ea6\uff0c\u627e\u51fa\u4e24\u4e2a\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u7684\u7279\u6b8a\u60c5\u51b5\u3002", "motivation": "\u5728\u8fd0\u8f93\u89c4\u5212\u4e2d\uff0c\u8d44\u6e90\u5cf0\u503c\u9700\u6c42\u6bd4\u4f7f\u7528\u65f6\u957f\u66f4\u53d7\u5173\u6ce8\uff0c\u9700\u5efa\u6a21\u6b64\u7c7b\u573a\u666f\u3002", "method": "\u63d0\u51fa\u6700\u5c0f\u5cf0\u503c\u6210\u672c\u968f\u65f6\u95f4\u53d8\u5316\u7684\u6d41\u95ee\u9898\u548c\u6700\u5c0f\u5cf0\u503c\u6210\u672c\u65f6\u95f4\u91cd\u590d\u6d41\u95ee\u9898\uff0c\u8fdb\u884c\u590d\u6742\u5ea6\u5206\u6790\uff0c\u627e\u51fa\u7279\u6b8a\u60c5\u51b5\u5e76\u7ed9\u51fa\u6c42\u89e3\u7b97\u6cd5\u3002", "result": "\u65f6\u95f4\u91cd\u590d\u6d41\u6709\u8fd1\u4f3c\u6bd4\u5dee\u7684\u7f3a\u70b9\uff0c\u79ef\u5206\u7248MPC - TRF\u5f3aNP\u96be\uff0c\u627e\u5230\u4e24\u4e2a\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u7684\u7279\u6b8a\u60c5\u51b5\u3002", "conclusion": "\u660e\u786e\u4e86\u6700\u5c0f\u5cf0\u503c\u6210\u672c\u65f6\u95f4\u91cd\u590d\u6d41\u95ee\u9898\u7684\u7279\u6027\uff0c\u7ed9\u51fa\u4e86\u7279\u6b8a\u60c5\u51b5\u4e0b\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u7b97\u6cd5\u3002"}}
{"id": "2507.09049", "pdf": "https://arxiv.org/pdf/2507.09049", "abs": "https://arxiv.org/abs/2507.09049", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "title": "CMER: A Context-Aware Approach for Mining Ethical Concern-related App Reviews", "categories": ["cs.SE"], "comment": null, "summary": "With the increasing proliferation of mobile applications in our daily lives,\nthe concerns surrounding ethics have surged significantly. Users communicate\ntheir feedback in app reviews, frequently emphasizing ethical concerns, such as\nprivacy and security. Incorporating these reviews has proved to be useful for\nmany areas of software engineering (e.g., requirement engineering, testing,\netc.). However, app reviews related to ethical concerns generally use\ndomain-specific language and are typically overshadowed by more generic\ncategories of user feedback, such as app reliability and usability. Thus,\nmaking automated extraction a challenging and time-consuming effort.\n  This study proposes CMER (A \\underline{C}ontext-Aware Approach for\n\\underline{M}ining \\underline{E}thical Concern-related App\n\\underline{R}eviews), a novel approach that combines Natural Language Inference\n(NLI) and a decoder-only (LLaMA-like) Large Language Model (LLM) to extract\nethical concern-related app reviews at scale. In CMER, NLI provides\ndomain-specific context awareness by using domain-specific hypotheses, and the\nLlama-like LLM eliminates the need for labeled data in the classification task.\nWe evaluated the validity of CMER by mining privacy and security-related\nreviews (PSRs) from the dataset of more than 382K app reviews of mobile\ninvestment apps. First, we evaluated four NLI models and compared the results\nof domain-specific hypotheses with generic hypotheses. Next, we evaluated three\nLLMs for the classification task. Finally, we combined the best NLI and LLM\nmodels (CMER) and extracted 2,178 additional PSRs overlooked by the previous\nstudy using a keyword-based approach, thus demonstrating the effectiveness of\nCMER. These reviews can be further refined into actionable requirement\nartifacts.", "AI": {"tldr": "\u968f\u7740\u79fb\u52a8\u5e94\u7528\u666e\u53ca\uff0c\u4f26\u7406\u95ee\u9898\u53d7\u5173\u6ce8\uff0c\u4f46\u4ece\u5e94\u7528\u8bc4\u8bba\u4e2d\u81ea\u52a8\u63d0\u53d6\u76f8\u5173\u5185\u5bb9\u5177\u6311\u6218\u3002\u672c\u6587\u63d0\u51faCMER\u65b9\u6cd5\uff0c\u7ed3\u5408NLI\u548cLLM\u63d0\u53d6\u4f26\u7406\u76f8\u5173\u8bc4\u8bba\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u4f26\u7406\u95ee\u9898\u53d7\u5173\u6ce8\uff0c\u5e94\u7528\u8bc4\u8bba\u542b\u4f26\u7406\u53cd\u9988\uff0c\u4f46\u56e0\u4f7f\u7528\u7279\u5b9a\u8bed\u8a00\u4e14\u88ab\u5176\u4ed6\u53cd\u9988\u63a9\u76d6\uff0c\u81ea\u52a8\u63d0\u53d6\u56f0\u96be\u3002", "method": "\u63d0\u51faCMER\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u548c\u7c7b\u4f3cLLaMA\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0cNLI\u63d0\u4f9b\u9886\u57df\u7279\u5b9a\u4e0a\u4e0b\u6587\u611f\u77e5\uff0cLLM\u65e0\u9700\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u4ece\u8d8538.2\u4e07\u6761\u79fb\u52a8\u6295\u8d44\u5e94\u7528\u8bc4\u8bba\u6570\u636e\u96c6\u4e2d\u6316\u6398\u9690\u79c1\u548c\u5b89\u5168\u76f8\u5173\u8bc4\u8bba\uff0c\u63d0\u53d6\u51fa\u4e4b\u524d\u57fa\u4e8e\u5173\u952e\u8bcd\u65b9\u6cd5\u9057\u6f0f\u76842178\u6761\u8bc4\u8bba\u3002", "conclusion": "CMER\u65b9\u6cd5\u6709\u6548\uff0c\u63d0\u53d6\u7684\u8bc4\u8bba\u53ef\u8fdb\u4e00\u6b65\u63d0\u70bc\u4e3a\u53ef\u64cd\u4f5c\u7684\u9700\u6c42\u5de5\u4ef6\u3002"}}
{"id": "2507.08834", "pdf": "https://arxiv.org/pdf/2507.08834", "abs": "https://arxiv.org/abs/2507.08834", "authors": ["Karishma Battina", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Physical Informed Neural Networks for modeling ocean pollutant", "categories": ["cs.LG"], "comment": "13 pages, 9 figures, 3 tables", "summary": "Traditional numerical methods often struggle with the complexity and scale of\nmodeling pollutant transport across vast and dynamic oceanic domains. This\npaper introduces a Physics-Informed Neural Network (PINN) framework to simulate\nthe dispersion of pollutants governed by the 2D advection-diffusion equation.\nThe model achieves physically consistent predictions by embedding physical laws\nand fitting to noisy synthetic data, generated via a finite difference method\n(FDM), directly into the neural network training process. This approach\naddresses challenges such as non-linear dynamics and the enforcement of\nboundary and initial conditions. Synthetic data sets, augmented with varying\nnoise levels, are used to capture real-world variability. The training\nincorporates a hybrid loss function including PDE residuals, boundary/initial\ncondition conformity, and a weighted data fit term. The approach takes\nadvantage of the Julia language scientific computing ecosystem for\nhigh-performance simulations, offering a scalable and flexible alternative to\ntraditional solvers", "AI": {"tldr": "\u672c\u6587\u5f15\u5165PINN\u6846\u67b6\u6a21\u62df\u6d77\u6d0b\u6c61\u67d3\u7269\u6269\u6563\uff0c\u7ed3\u5408\u7269\u7406\u5b9a\u5f8b\u4e0e\u542b\u566a\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7f51\u7edc\uff0c\u91c7\u7528\u6df7\u5408\u635f\u5931\u51fd\u6570\uff0c\u5229\u7528Julia\u8bed\u8a00\u5b9e\u73b0\u9ad8\u6027\u80fd\u6a21\u62df\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5728\u6a21\u62df\u5e7f\u9614\u52a8\u6001\u6d77\u6d0b\u9886\u57df\u6c61\u67d3\u7269\u4f20\u8f93\u65f6\u9762\u4e34\u590d\u6742\u6027\u548c\u89c4\u6a21\u6311\u6218\u3002", "method": "\u5f15\u5165PINN\u6846\u67b6\uff0c\u5c06\u7269\u7406\u5b9a\u5f8b\u548c\u901a\u8fc7FDM\u751f\u6210\u7684\u542b\u566a\u5408\u6210\u6570\u636e\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff0c\u91c7\u7528\u542bPDE\u6b8b\u5dee\u3001\u8fb9\u754c/\u521d\u59cb\u6761\u4ef6\u4e00\u81f4\u6027\u548c\u52a0\u6743\u6570\u636e\u62df\u5408\u9879\u7684\u6df7\u5408\u635f\u5931\u51fd\u6570\uff0c\u5229\u7528Julia\u8bed\u8a00\u8fdb\u884c\u9ad8\u6027\u80fd\u6a21\u62df\u3002", "result": "\u6a21\u578b\u80fd\u5b9e\u73b0\u7269\u7406\u4e0a\u4e00\u81f4\u7684\u9884\u6d4b\uff0c\u89e3\u51b3\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u3001\u8fb9\u754c\u548c\u521d\u59cb\u6761\u4ef6\u7ea6\u675f\u7b49\u6311\u6218\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f20\u7edf\u6c42\u89e3\u5668\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.09103", "pdf": "https://arxiv.org/pdf/2507.09103", "abs": "https://arxiv.org/abs/2507.09103", "authors": ["Gianluigi Silvestri", "Luca Ambrogioni"], "title": "CoVAE: Consistency Training of Variational Autoencoders", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Current state-of-the-art generative approaches frequently rely on a two-stage\ntraining procedure, where an autoencoder (often a VAE) first performs\ndimensionality reduction, followed by training a generative model on the\nlearned latent space. While effective, this introduces computational overhead\nand increased sampling times. We challenge this paradigm by proposing\nConsistency Training of Variational AutoEncoders (CoVAE), a novel single-stage\ngenerative autoencoding framework that adopts techniques from consistency\nmodels to train a VAE architecture. The CoVAE encoder learns a progressive\nseries of latent representations with increasing encoding noise levels,\nmirroring the forward processes of diffusion and flow matching models. This\nsequence of representations is regulated by a time dependent $\\beta$ parameter\nthat scales the KL loss. The decoder is trained using a consistency loss with\nvariational regularization, which reduces to a conventional VAE loss at the\nearliest latent time. We show that CoVAE can generate high-quality samples in\none or few steps without the use of a learned prior, significantly\noutperforming equivalent VAEs and other single-stage VAEs methods. Our approach\nprovides a unified framework for autoencoding and diffusion-style generative\nmodeling and provides a viable route for one-step generative high-performance\nautoencoding. Our code is publicly available at\nhttps://github.com/gisilvs/covae.", "AI": {"tldr": "\u63d0\u51faCoVAE\u5355\u9636\u6bb5\u751f\u6210\u5f0f\u81ea\u7f16\u7801\u6846\u67b6\uff0c\u53ef\u4e00\u6b65\u6216\u51e0\u6b65\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u4f18\u4e8e\u7b49\u6548VAE\u548c\u5176\u4ed6\u5355\u9636\u6bb5VAE\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u65b9\u6cd5\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u548c\u91c7\u6837\u65f6\u95f4\u589e\u52a0\u95ee\u9898\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51faCoVAE\uff0c\u7f16\u7801\u5668\u5b66\u4e60\u5e26\u9012\u589e\u7f16\u7801\u566a\u58f0\u7684\u6f5c\u5728\u8868\u793a\uff0c\u7528\u65f6\u95f4\u76f8\u5173\u03b2\u53c2\u6570\u8c03\u8282KL\u635f\u5931\uff0c\u89e3\u7801\u5668\u7528\u5e26\u53d8\u5206\u6b63\u5219\u5316\u7684\u4e00\u81f4\u6027\u635f\u5931\u8bad\u7ec3\u3002", "result": "CoVAE\u53ef\u5728\u4e00\u6b65\u6216\u51e0\u6b65\u5185\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u65e0\u9700\u5b66\u4e60\u5148\u9a8c\uff0c\u663e\u8457\u4f18\u4e8e\u7b49\u6548VAE\u548c\u5176\u4ed6\u5355\u9636\u6bb5VAE\u65b9\u6cd5\u3002", "conclusion": "CoVAE\u4e3a\u81ea\u7f16\u7801\u548c\u6269\u6563\u5f0f\u751f\u6210\u5efa\u6a21\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\uff0c\u662f\u4e00\u6b65\u751f\u6210\u9ad8\u6027\u80fd\u81ea\u7f16\u7801\u7684\u53ef\u884c\u9014\u5f84\u3002"}}
{"id": "2507.09972", "pdf": "https://arxiv.org/pdf/2507.09972", "abs": "https://arxiv.org/abs/2507.09972", "authors": ["Lucas Barbosa", "Sam Kirshner", "Rob Kopel", "Eric Tze Kuan Lim", "Tom Pagram"], "title": "A New Incentive Model For Content Trust", "categories": ["cs.GT", "cs.CY", "econ.GN", "q-fin.EC"], "comment": "20 pages, 6 figures and 2 tables", "summary": "This paper outlines an incentive-driven and decentralized approach to\nverifying the veracity of digital content at scale. Widespread misinformation,\nan explosion in AI-generated content and reduced reliance on traditional news\nsources demands a new approach for content authenticity and truth-seeking that\nis fit for a modern, digital world. By using smart contracts and digital\nidentity to incorporate 'trust' into the reward function for published content,\nnot just engagement, we believe that it could be possible to foster a\nself-propelling paradigm shift to combat misinformation through a\ncommunity-based governance model. The approach described in this paper requires\nthat content creators stake financial collateral on factual claims for an\nimpartial jury to vet with a financial reward for contribution. We hypothesize\nthat with the right financial and social incentive model users will be\nmotivated to participate in crowdsourced fact-checking and content creators\nwill place more care in their attestations. This is an exploratory paper and\nthere are a number of open issues and questions that warrant further analysis\nand exploration.", "AI": {"tldr": "\u63d0\u51fa\u6fc0\u52b1\u9a71\u52a8\u548c\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u5927\u89c4\u6a21\u9a8c\u8bc1\u6570\u5b57\u5185\u5bb9\u771f\u5b9e\u6027\uff0c\u9700\u8fdb\u4e00\u6b65\u5206\u6790\u63a2\u7d22\u3002", "motivation": "\u5e94\u5bf9\u5e7f\u6cdb\u7684\u9519\u8bef\u4fe1\u606f\u3001AI\u751f\u6210\u5185\u5bb9\u6fc0\u589e\u548c\u5bf9\u4f20\u7edf\u65b0\u95fb\u6e90\u4f9d\u8d56\u964d\u4f4e\u7684\u73b0\u72b6\uff0c\u5bfb\u6c42\u9002\u5408\u73b0\u4ee3\u6570\u5b57\u4e16\u754c\u7684\u5185\u5bb9\u771f\u5b9e\u6027\u9a8c\u8bc1\u65b0\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u667a\u80fd\u5408\u7ea6\u548c\u6570\u5b57\u8eab\u4efd\u5c06\u2018\u4fe1\u4efb\u2019\u7eb3\u5165\u53d1\u5e03\u5185\u5bb9\u7684\u5956\u52b1\u51fd\u6570\uff0c\u8ba9\u5185\u5bb9\u521b\u4f5c\u8005\u4e3a\u4e8b\u5b9e\u58f0\u660e\u62b5\u62bc\u91d1\u878d\u62c5\u4fdd\uff0c\u7531\u516c\u6b63\u966a\u5ba1\u56e2\u5ba1\u6838\u5e76\u7ed9\u4e88\u8d21\u732e\u8005\u7ecf\u6d4e\u5956\u52b1\u3002", "result": "\u65e0\u5b9e\u9645\u7814\u7a76\u7ed3\u679c\uff0c\u4ec5\u4e3a\u5047\u8bbe\uff0c\u8ba4\u4e3a\u5408\u9002\u7684\u91d1\u878d\u548c\u793e\u4f1a\u6fc0\u52b1\u6a21\u578b\u4f1a\u4fc3\u4f7f\u4eba\u4eec\u53c2\u4e0e\u4f17\u5305\u4e8b\u5b9e\u6838\u67e5\uff0c\u521b\u4f5c\u8005\u66f4\u8c28\u614e\u58f0\u660e\u3002", "conclusion": "\u8fd9\u662f\u63a2\u7d22\u6027\u8bba\u6587\uff0c\u6709\u8bb8\u591a\u95ee\u9898\u9700\u8fdb\u4e00\u6b65\u5206\u6790\u548c\u63a2\u7d22\u3002"}}
{"id": "2507.10139", "pdf": "https://arxiv.org/pdf/2507.10139", "abs": "https://arxiv.org/abs/2507.10139", "authors": ["Filipe Miguel Gon\u00e7alves de Almeida", "CJ Carey", "Hendrik Fichtenberger", "Jonathan Halcrow", "Silvio Lattanzi", "Andr\u00e9 Linhares", "Tao Meng", "Ashkan Norouzi-Fard", "Nikos Parotsidis", "Bryan Perozzi", "David Simcha"], "title": "Large-Scale Graph Building in Dynamic Environments: Low Latency and High Quality", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Learning and constructing large-scale graphs has attracted attention in\nrecent decades, resulting in a rich literature that introduced various systems,\ntools, and algorithms. Grale is one of such tools that is designed for offline\nenvironments and is deployed in more than 50 different industrial settings at\nGoogle. Grale is widely applicable because of its ability to efficiently learn\nand construct a graph on datasets with multiple types of features. However, it\nis often the case that applications require the underlying data to evolve\ncontinuously and rapidly and the updated graph needs to be available with low\nlatency. Such setting make the use of Grale prohibitive. While there are\nApproximate Nearest Neighbor (ANN) systems that handle dynamic updates with low\nlatency, they are mostly limited to similarities over a single embedding.\n  In this work, we introduce a system that inherits the advantages and the\nquality of Grale, and maintains a graph construction in a dynamic setting with\ntens of milliseconds of latency per request. We call the system Dynamic Grale\nUsing ScaNN (Dynamic GUS). Our system has a wide range of applications with\nover 10 deployments at Google. One of the applications is in Android Security\nand Privacy, where Dynamic Grale Using ScaNN enables capturing harmful\napplications 4 times faster, before they can reach users.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u80fd\u7ee7\u627fGrale\u4f18\u52bf\u3001\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4f4e\u5ef6\u8fdf\u6784\u5efa\u56fe\u7684\u7cfb\u7edfDynamic GUS\uff0c\u8be5\u7cfb\u7edf\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u52a0\u901f\u5b89\u5353\u5b89\u5168\u4e0e\u9690\u79c1\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u5de5\u5177Grale\u4e0d\u9002\u7528\u4e8e\u6570\u636e\u52a8\u6001\u66f4\u65b0\u573a\u666f\uff0c\u8fd1\u4f3c\u6700\u8fd1\u90bb\u7cfb\u7edf\u6709\u5c40\u9650\u6027\uff0c\u9700\u65b0\u7cfb\u7edf\u6ee1\u8db3\u52a8\u6001\u56fe\u6784\u5efa\u4f4e\u5ef6\u8fdf\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u7ee7\u627fGrale\u4f18\u52bf\u7684Dynamic Grale Using ScaNN\uff08Dynamic GUS\uff09\u7cfb\u7edf\u3002", "result": "Dynamic GUS\u7cfb\u7edf\u5728\u8c37\u6b4c\u6709\u8d8510\u6b21\u90e8\u7f72\uff0c\u5728\u5b89\u5353\u5b89\u5168\u4e0e\u9690\u79c1\u9886\u57df\u80fd\u4f7f\u6709\u5bb3\u5e94\u7528\u68c0\u6d4b\u901f\u5ea6\u63d0\u53474\u500d\u3002", "conclusion": "Dynamic GUS\u7cfb\u7edf\u80fd\u5728\u52a8\u6001\u73af\u5883\u4e2d\u4ee5\u4f4e\u5ef6\u8fdf\u6784\u5efa\u56fe\uff0c\u6709\u5e7f\u6cdb\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.09403", "pdf": "https://arxiv.org/pdf/2507.09403", "abs": "https://arxiv.org/abs/2507.09403", "authors": ["Amit Jaspal", "Feng Zhang", "Wei Chang", "Sumit Kumar", "Yubo Wang", "Roni Mittleman", "Qifan Wang", "Weize Mao"], "title": "Balancing Semantic Relevance and Engagement in Related Video Recommendations", "categories": ["cs.IR", "cs.MM"], "comment": null, "summary": "Related video recommendations commonly use collaborative filtering (CF)\ndriven by co-engagement signals, often resulting in recommendations lacking\nsemantic coherence and exhibiting strong popularity bias. This paper introduces\na novel multi-objective retrieval framework, enhancing standard two-tower\nmodels to explicitly balance semantic relevance and user engagement. Our\napproach uniquely combines: (a) multi-task learning (MTL) to jointly optimize\nco-engagement and semantic relevance, explicitly prioritizing topical\ncoherence; (b) fusion of multimodal content features (textual and visual\nembeddings) for richer semantic understanding; and (c) off-policy correction\n(OPC) via inverse propensity weighting to effectively mitigate popularity bias.\nEvaluation on industrial-scale data and a two-week live A/B test reveals our\nframework's efficacy. We observed significant improvements in semantic\nrelevance (from 51% to 63% topic match rate), a reduction in popular item\ndistribution (-13.8% popular video recommendations), and a +0.04% improvement\nin our topline user engagement metric. Our method successfully achieves better\nsemantic coherence, balanced engagement, and practical scalability for\nreal-world deployment.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u9896\u591a\u76ee\u6807\u68c0\u7d22\u6846\u67b6\u4f18\u5316\u89c6\u9891\u63a8\u8350\uff0c\u7ed3\u5408\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u548c\u79bb\u7b56\u7565\u6821\u6b63\uff0c\u5728\u5de5\u4e1a\u6570\u636e\u548cA/B\u6d4b\u8bd5\u4e2d\u6548\u679c\u663e\u8457\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u534f\u540c\u8fc7\u6ee4\u9a71\u52a8\u7684\u76f8\u5173\u89c6\u9891\u63a8\u8350\u7f3a\u4e4f\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u5b58\u5728\u5f3a\u70c8\u6d41\u884c\u5ea6\u504f\u5dee\u7684\u95ee\u9898\u3002", "method": "\u589e\u5f3a\u6807\u51c6\u53cc\u5854\u6a21\u578b\uff0c\u7ed3\u5408\u591a\u4efb\u52a1\u5b66\u4e60\u8054\u5408\u4f18\u5316\u5171\u540c\u53c2\u4e0e\u5ea6\u548c\u8bed\u4e49\u76f8\u5173\u6027\u3001\u878d\u5408\u591a\u6a21\u6001\u5185\u5bb9\u7279\u5f81\u3001\u901a\u8fc7\u9006\u503e\u5411\u52a0\u6743\u8fdb\u884c\u79bb\u7b56\u7565\u6821\u6b63\u3002", "result": "\u8bed\u4e49\u76f8\u5173\u6027\u663e\u8457\u63d0\u5347\uff08\u4e3b\u9898\u5339\u914d\u7387\u4ece51%\u63d0\u5347\u523063%\uff09\uff0c\u70ed\u95e8\u9879\u76ee\u5206\u5e03\u51cf\u5c11\uff08\u70ed\u95e8\u89c6\u9891\u63a8\u8350\u51cf\u5c1113.8%\uff09\uff0c\u7528\u6237\u53c2\u4e0e\u5ea6\u6307\u6807\u63d0\u53470.04%\u3002", "conclusion": "\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u8bed\u4e49\u8fde\u8d2f\u6027\u3001\u5e73\u8861\u7684\u53c2\u4e0e\u5ea6\u4ee5\u53ca\u5728\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u7684\u5b9e\u9645\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2507.09825", "pdf": "https://arxiv.org/pdf/2507.09825", "abs": "https://arxiv.org/abs/2507.09825", "authors": ["Michal B\u00e9re\u0161"], "title": "Legendre Polynomials and Their Use for Karhunen-Lo\u00e8ve Expansion", "categories": ["cs.CE", "math.PR", "65C05, 86-08, 82-08, 65C60, 60-08"], "comment": null, "summary": "This paper makes two main contributions. First, we present a pedagogical\nreview of the derivation of the three-term recurrence relation for Legendre\npolynomials, without relying on the classical Legendre differential equation,\nRodrigues' formula, or generating functions. This exposition is designed to be\naccessible to undergraduate students.\n  Second, we develop a computational framework for Karhunen-Lo\\`eve expansions\nof isotropic Gaussian random fields on hyper-rectangular domains. The framework\nleverages Legendre polynomials and their associated Gaussian quadrature, and it\nremains efficient even in higher spatial dimensions.\n  A covariance kernel is first approximated by a non-negative mixture of\nsquared-exponentials, obtained via a Newton-optimized fit with a theoretically\ninformed initialization. The resulting separable kernel enables a\nLegendre-Galerkin discretization in the form of a Kronecker product over single\ndimensions, with submatrices that exhibit even/odd parity structure. For\nassembly, we introduce a Duffy-type transformation followed by quadrature.\nThese structural properties significantly reduce both memory usage and\narithmetic cost compared to naive approaches. All algorithms and numerical\nexperiments are provided in an open-source repository that reproduces every\nfigure and table in this work.", "AI": {"tldr": "\u672c\u6587\u6709\u4e24\u4e2a\u4e3b\u8981\u8d21\u732e\uff1a\u4e00\u662f\u4e0d\u4f9d\u8d56\u7ecf\u5178\u65b9\u6cd5\u4e3a\u672c\u79d1\u751f\u8bb2\u89e3\u52d2\u8ba9\u5fb7\u591a\u9879\u5f0f\u4e09\u9879\u9012\u63a8\u5173\u7cfb\u63a8\u5bfc\uff1b\u4e8c\u662f\u5f00\u53d1\u9ad8\u7ef4\u8d85\u77e9\u5f62\u57df\u4e0a\u5404\u5411\u540c\u6027\u9ad8\u65af\u968f\u673a\u573a\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u80fd\u964d\u4f4e\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u4e3a\u672c\u79d1\u751f\u63d0\u4f9b\u6613\u7406\u89e3\u7684\u52d2\u8ba9\u5fb7\u591a\u9879\u5f0f\u63a8\u5bfc\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5f00\u53d1\u9ad8\u7ef4\u8d85\u77e9\u5f62\u57df\u4e0a\u5404\u5411\u540c\u6027\u9ad8\u65af\u968f\u673a\u573a\u9ad8\u6548\u8ba1\u7b97\u6846\u67b6\u3002", "method": "\u63a8\u5bfc\u52d2\u8ba9\u5fb7\u591a\u9879\u5f0f\u65f6\u4e0d\u4f9d\u8d56\u7ecf\u5178\u65b9\u6cd5\uff1b\u8ba1\u7b97\u6846\u67b6\u5229\u7528\u52d2\u8ba9\u5fb7\u591a\u9879\u5f0f\u548c\u9ad8\u65af\u6c42\u79ef\uff0c\u7528\u725b\u987f\u4f18\u5316\u62df\u5408\u8fd1\u4f3c\u534f\u65b9\u5dee\u6838\uff0c\u91c7\u7528Duffy\u578b\u53d8\u6362\u548c\u6c42\u79ef\u3002", "result": "\u5f00\u53d1\u7684\u8ba1\u7b97\u6846\u67b6\u5728\u9ad8\u7ef4\u4e0b\u4ecd\u6709\u6548\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\u548c\u7b97\u672f\u6210\u672c\uff0c\u4e14\u6709\u5f00\u6e90\u4ee3\u7801\u590d\u73b0\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u63a8\u5bfc\u65b9\u6cd5\u9002\u5408\u6559\u5b66\uff0c\u8ba1\u7b97\u6846\u67b6\u5728\u9ad8\u7ef4\u8d85\u77e9\u5f62\u57df\u4e0a\u5904\u7406\u5404\u5411\u540c\u6027\u9ad8\u65af\u968f\u673a\u573a\u6709\u6548\u4e14\u9ad8\u6548\u3002"}}
{"id": "2507.10017", "pdf": "https://arxiv.org/pdf/2507.10017", "abs": "https://arxiv.org/abs/2507.10017", "authors": ["Zhiyang Tang", "Yanping Wu", "Xiangjun Zai", "Chen Chen", "Xiaoyang Wang", "Ying Zhang"], "title": "Efficient Temporal Simple Path Graph Generation", "categories": ["cs.DB"], "comment": null, "summary": "Interactions between two entities often occur at specific timestamps, which\ncan be modeled as a temporal graph. Exploring the relationships between\nvertices based on temporal paths is one of the fundamental tasks. In this\npaper, we conduct the first research to propose and investigate the problem of\ngenerating the temporal simple path graph (tspG), which is the subgraph\nconsisting of all temporal simple paths from the source vertex to the target\nvertex within the given time interval. Directly enumerating all temporal simple\npaths and constructing the tspG is computationally expensive. To accelerate the\nprocessing, we propose an efficient method named Verification in Upper-bound\nGraph. It first incorporates the temporal path constraint and simple path\nconstraint to exclude unpromising edges from the original graph, which obtains\na tight upper-bound graph as a high-quality approximation of the tspG in\npolynomial time. Then, an Escape Edges Verification algorithm is further\napplied in the upper-bound graph to construct the exact tspG without\nexhaustively enumerating all temporal simple paths between given vertices.\nFinally, comprehensive experiments on 10 real-world graphs are conducted to\ndemonstrate the efficiency and effectiveness of the proposed techniques.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u5e76\u7814\u7a76\u751f\u6210\u65f6\u95f4\u7b80\u5355\u8def\u5f84\u56fe\uff08tspG\uff09\u95ee\u9898\uff0c\u63d0\u51fa Verification in Upper - bound Graph \u65b9\u6cd5\u52a0\u901f\u5904\u7406\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8e\u65f6\u95f4\u8def\u5f84\u7684\u9876\u70b9\u5173\u7cfb\u662f\u57fa\u7840\u4efb\u52a1\uff0c\u76f4\u63a5\u679a\u4e3e\u6240\u6709\u65f6\u95f4\u7b80\u5355\u8def\u5f84\u6784\u5efa tspG \u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa Verification in Upper - bound Graph \u65b9\u6cd5\uff0c\u5148\u7ed3\u5408\u65f6\u95f4\u8def\u5f84\u548c\u7b80\u5355\u8def\u5f84\u7ea6\u675f\u6392\u9664\u539f\u56fe\u4e2d\u65e0\u524d\u666f\u7684\u8fb9\u5f97\u5230\u4e0a\u754c\u56fe\uff0c\u518d\u7528\u4e0a\u754c\u56fe\u4e2d\u7684 Escape Edges Verification \u7b97\u6cd5\u6784\u5efa\u7cbe\u786e tspG\u3002", "result": "\u5728 10 \u4e2a\u771f\u5b9e\u4e16\u754c\u56fe\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6280\u672f\u5177\u6709\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.10005", "pdf": "https://arxiv.org/pdf/2507.10005", "abs": "https://arxiv.org/abs/2507.10005", "authors": ["Yash Arya", "Sang Hoon Lee"], "title": "Effects of structural properties of neural networks on machine learning performance", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.NE", "physics.comp-ph"], "comment": "9 pages, 6 figures", "summary": "In recent years, graph-based machine learning techniques, such as\nreinforcement learning and graph neural networks, have garnered significant\nattention. While some recent studies have started to explore the relationship\nbetween the graph structure of neural networks and their predictive\nperformance, they often limit themselves to a narrow range of model networks,\nparticularly lacking mesoscale structures such as communities. Our work\nadvances this area by conducting a more comprehensive investigation,\nincorporating realistic network structures characterized by heterogeneous\ndegree distributions and community structures, which are typical\ncharacteristics of many real networks. These community structures offer a\nnuanced perspective on network architecture. Our analysis employs model\nnetworks such as random and scale-free networks, alongside a comparison with a\nbiological neural network and its subsets for more detailed analysis. We\nexamine the impact of these structural attributes on the performance of image\nclassification tasks. Our findings reveal that structural properties do affect\nperformance to some extent. Specifically, networks featuring coherent, densely\ninterconnected communities demonstrate enhanced learning capabilities. The\ncomparison with the biological neural network emphasizes the relevance of our\nfindings to real-world structures, suggesting an intriguing connection worth\nfurther exploration. This study contributes meaningfully to network science and\nmachine learning, providing insights that could inspire the design of more\nbiologically informed neural networks.", "AI": {"tldr": "\u672c\u6587\u7efc\u5408\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u56fe\u7ed3\u6784\u4e0e\u9884\u6d4b\u6027\u80fd\u5173\u7cfb\uff0c\u7528\u591a\u79cd\u6a21\u578b\u7f51\u7edc\u5206\u6790\u7ed3\u6784\u5c5e\u6027\u5bf9\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u5f71\u54cd\uff0c\u53d1\u73b0\u7279\u5b9a\u7ed3\u6784\u7f51\u7edc\u5b66\u4e60\u80fd\u529b\u5f3a\uff0c\u4e3a\u7f51\u7edc\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u505a\u8d21\u732e\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5c40\u9650\u4e8e\u7a84\u8303\u56f4\u6a21\u578b\u7f51\u7edc\uff0c\u7f3a\u4e4f\u5bf9\u793e\u533a\u7b49\u4e2d\u5c3a\u5ea6\u7ed3\u6784\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u66f4\u5168\u9762\u7814\u7a76\u56fe\u7ed3\u6784\u4e0e\u9884\u6d4b\u6027\u80fd\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u968f\u673a\u548c\u65e0\u6807\u5ea6\u7b49\u6a21\u578b\u7f51\u7edc\uff0c\u4e0e\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u53ca\u5176\u5b50\u96c6\u5bf9\u6bd4\uff0c\u5206\u6790\u7ed3\u6784\u5c5e\u6027\u5bf9\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u6784\u5c5e\u6027\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u5f71\u54cd\u6027\u80fd\uff0c\u5177\u6709\u8fde\u8d2f\u3001\u5bc6\u96c6\u4e92\u8fde\u793e\u533a\u7684\u7f51\u7edc\u5b66\u4e60\u80fd\u529b\u589e\u5f3a\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7f51\u7edc\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u6709\u610f\u4e49\u8d21\u732e\uff0c\u63d0\u793a\u53ef\u542f\u53d1\u8bbe\u8ba1\u66f4\u5177\u751f\u7269\u4fe1\u606f\u7684\u795e\u7ecf\u7f51\u7edc\u3002"}}
{"id": "2507.09179", "pdf": "https://arxiv.org/pdf/2507.09179", "abs": "https://arxiv.org/abs/2507.09179", "authors": ["Ronghua Shi", "Yiou Liu", "Xinyu Ying", "Yang Tan", "Yuchun Feng", "Lynn Ai", "Bill Shi", "Xuhui Wang", "Zhuang Liu"], "title": "Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony-a Decentralized Multi-Agent System", "categories": ["cs.AI"], "comment": null, "summary": "Decentralized finance (DeFi) has introduced a new era of permissionless\nfinancial innovation but also led to unprecedented market manipulation. Without\ncentralized oversight, malicious actors coordinate shilling campaigns and\npump-and-dump schemes across various platforms. We propose a Multi-Agent\nReinforcement Learning (MARL) framework for decentralized manipulation\ndetection, modeling the interaction between manipulators and detectors as a\ndynamic adversarial game. This framework identifies suspicious patterns using\ndelayed token price reactions as financial indicators.Our method introduces\nthree innovations: (1) Group Relative Policy Optimization (GRPO) to enhance\nlearning stability in sparse-reward and partially observable settings; (2) a\ntheory-based reward function inspired by rational expectations and information\nasymmetry, differentiating price discovery from manipulation noise; and (3) a\nmulti-modal agent pipeline that integrates LLM-based semantic features, social\ngraph signals, and on-chain market data for informed decision-making.The\nframework is integrated within the Symphony system, a decentralized multi-agent\narchitecture enabling peer-to-peer agent execution and trust-aware learning\nthrough distributed logs, supporting chain-verifiable evaluation. Symphony\npromotes adversarial co-evolution among strategic actors and maintains robust\nmanipulation detection without centralized oracles, enabling real-time\nsurveillance across global DeFi ecosystems.Trained on 100,000 real-world\ndiscourse episodes and validated in adversarial simulations, Hide-and-Shill\nachieves top performance in detection accuracy and causal attribution. This\nwork bridges multi-agent systems with financial surveillance, advancing a new\nparadigm for decentralized market intelligence. All resources are available at\nthe Hide-and-Shill GitHub repository to promote open research and\nreproducibility.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u53bb\u4e2d\u5fc3\u5316\u64cd\u7eb5\u68c0\u6d4b\u7684MARL\u6846\u67b6\uff0c\u96c6\u6210\u4e8eSymphony\u7cfb\u7edf\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u56e0\u679c\u5f52\u56e0\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u63a8\u52a8\u53bb\u4e2d\u5fc3\u5316\u5e02\u573a\u60c5\u62a5\u7814\u7a76\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u91d1\u878d\uff08DeFi\uff09\u5b58\u5728\u5e02\u573a\u64cd\u7eb5\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u96c6\u4e2d\u76d1\u7763\uff0c\u9700\u6709\u6548\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMARL\u6846\u67b6\uff0c\u5f15\u5165GRPO\u589e\u5f3a\u5b66\u4e60\u7a33\u5b9a\u6027\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u7406\u8bba\u7684\u5956\u52b1\u51fd\u6570\uff0c\u91c7\u7528\u591a\u6a21\u6001\u4ee3\u7406\u7ba1\u9053\uff0c\u96c6\u6210\u4e8eSymphony\u7cfb\u7edf\u3002", "result": "\u5728100,000\u4e2a\u771f\u5b9e\u4e16\u754c\u8bdd\u8bed\u7247\u6bb5\u4e0a\u8bad\u7ec3\u5e76\u5728\u5bf9\u6297\u6a21\u62df\u4e2d\u9a8c\u8bc1\uff0cHide - and - Shill\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u56e0\u679c\u5f52\u56e0\u65b9\u9762\u8fbe\u5230\u9876\u7ea7\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0e\u91d1\u878d\u76d1\u63a7\u76f8\u7ed3\u5408\uff0c\u63a8\u52a8\u4e86\u53bb\u4e2d\u5fc3\u5316\u5e02\u573a\u60c5\u62a5\u7684\u65b0\u8303\u5f0f\uff0c\u4e14\u63d0\u4f9b\u8d44\u6e90\u4fc3\u8fdb\u5f00\u653e\u7814\u7a76\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2507.10333", "pdf": "https://arxiv.org/pdf/2507.10333", "abs": "https://arxiv.org/abs/2507.10333", "authors": ["Voraprapa Nakavachara", "Chanon Thongtai", "Thanarat Chalidabhongse", "Chanathip Pharino"], "title": "The Green Premium Puzzle: Empirical Evidence from Climate-Friendly Food Products", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "This paper investigates whether climate-friendly food products command a\nprice premium in consumer markets. Using product-level data from a supermarket\nin Sweden, we examine the relationship between front-of-package climate impact\nscores and retail prices, controlling for product size, nutritional content,\nand fixed effects. Contrary to the intuitive expectation of a positive green\npremium, we find no evidence that climate-friendly products are priced higher.\nIn some product categories, products with better climate scores are in fact\nassociated with lower prices, suggesting a negative premium, an outcome that\ngives rise to what we refer to as the green premium puzzle. We argue that\nmarket frictions such as competing consumer priorities, psychological distance\nfrom climate issues, and skepticism toward environmental labeling may suppress\nthe price signals intended to reward sustainable consumption. These findings\noffer important insights for producers, retailers, and policymakers seeking to\nalign climate goals with effective market incentives in the transition toward a\nmore sustainable society.", "AI": {"tldr": "\u7814\u7a76\u745e\u5178\u8d85\u5e02\u4ea7\u54c1\uff0c\u53d1\u73b0\u6c14\u5019\u53cb\u597d\u578b\u98df\u54c1\u65e0\u4ef7\u683c\u6ea2\u4ef7\uff0c\u90e8\u5206\u54c1\u7c7b\u6709\u8d1f\u6ea2\u4ef7\uff0c\u63d0\u51fa\u7eff\u8272\u6ea2\u4ef7\u8c1c\u9898\u5e76\u5206\u6790\u539f\u56e0\u3002", "motivation": "\u63a2\u7a76\u6c14\u5019\u53cb\u597d\u578b\u98df\u54c1\u5728\u6d88\u8d39\u5e02\u573a\u662f\u5426\u6709\u4ef7\u683c\u6ea2\u4ef7\u3002", "method": "\u4f7f\u7528\u745e\u5178\u4e00\u5bb6\u8d85\u5e02\u7684\u4ea7\u54c1\u7ea7\u6570\u636e\uff0c\u63a7\u5236\u4ea7\u54c1\u5927\u5c0f\u3001\u8425\u517b\u6210\u5206\u548c\u56fa\u5b9a\u6548\u5e94\uff0c\u7814\u7a76\u5305\u88c5\u6b63\u9762\u6c14\u5019\u5f71\u54cd\u5f97\u5206\u4e0e\u96f6\u552e\u4ef7\u7684\u5173\u7cfb\u3002", "result": "\u672a\u53d1\u73b0\u6c14\u5019\u53cb\u597d\u578b\u4ea7\u54c1\u4ef7\u683c\u66f4\u9ad8\u7684\u8bc1\u636e\uff0c\u90e8\u5206\u54c1\u7c7b\u6c14\u5019\u5f97\u5206\u9ad8\u7684\u4ea7\u54c1\u4ef7\u683c\u66f4\u4f4e\uff0c\u5b58\u5728\u8d1f\u6ea2\u4ef7\u3002", "conclusion": "\u5e02\u573a\u6469\u64e6\u53ef\u80fd\u6291\u5236\u5956\u52b1\u53ef\u6301\u7eed\u6d88\u8d39\u7684\u4ef7\u683c\u4fe1\u53f7\uff0c\u7814\u7a76\u4e3a\u751f\u4ea7\u8005\u3001\u96f6\u552e\u5546\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2507.09711", "pdf": "https://arxiv.org/pdf/2507.09711", "abs": "https://arxiv.org/abs/2507.09711", "authors": ["Kun He"], "title": "Phase transition of the Sinkhorn-Knopp algorithm", "categories": ["cs.DS", "cs.LG", "stat.ML"], "comment": "44 pages, 2 figures", "summary": "The matrix scaling problem, particularly the Sinkhorn-Knopp algorithm, has\nbeen studied for over 60 years. In practice, the algorithm often yields\nhigh-quality approximations within just a few iterations. Theoretically,\nhowever, the best-known upper bound places it in the class of\npseudopolynomial-time approximation algorithms. Meanwhile, the lower-bound\nlandscape remains largely unexplored. Two fundamental questions persist: what\naccounts for the algorithm's strong empirical performance, and can a tight\nbound on its iteration count be established?\n  For an $n\\times n$ matrix, its normalized version is obtained by dividing\neach entry by its largest entry. We say that a normalized matrix has a density\n$\\gamma$ if there exists a constant $\\rho > 0$ such that one row or column has\nexactly $\\lceil \\gamma n \\rceil$ entries with values at least $\\rho$, and every\nother row and column has at least $\\lceil \\gamma n \\rceil$ such entries.\n  For the upper bound, we show that the Sinkhorn-Knopp algorithm produces a\nnearly doubly stochastic matrix in $O(\\log n - \\log \\varepsilon)$ iterations\nand $\\widetilde{O}(n^2)$ time for all nonnegative square matrices whose\nnormalized version has a density $\\gamma > 1/2$. Such matrices cover both the\nalgorithm's principal practical inputs and its typical theoretical regime, and\nthe $\\widetilde{O}(n^2)$ runtime is optimal.\n  For the lower bound, we establish a tight bound of\n$\\widetilde{\\Omega}\\left(n^{1/2}/\\varepsilon\\right)$ iterations for positive\nmatrices under the $\\ell_2$-norm error measure. Moreover, for every $\\gamma <\n1/2$, there exists a matrix with density $\\gamma$ for which the algorithm\nrequires $\\Omega\\left(n^{1/2}/\\varepsilon\\right)$ iterations.\n  In summary, our results reveal a sharp phase transition in the Sinkhorn-Knopp\nalgorithm at the density threshold $\\gamma = 1/2$.", "AI": {"tldr": "\u7814\u7a76Sinkhorn - Knopp\u7b97\u6cd5\u7684\u8fed\u4ee3\u6b21\u6570\u4e0a\u4e0b\u754c\uff0c\u53d1\u73b0\u5bc6\u5ea6\u9608\u503c\u03b3 = 1/2\u5904\u6709\u76f8\u53d8\u3002", "motivation": "\u89e3\u91ca\u7b97\u6cd5\u5f3a\u5b9e\u8bc1\u6027\u80fd\u539f\u56e0\u5e76\u786e\u5b9a\u5176\u8fed\u4ee3\u6b21\u6570\u7684\u7d27\u754c\u3002", "method": "\u5bf9\u5f52\u4e00\u5316\u77e9\u9635\u5b9a\u4e49\u5bc6\u5ea6\u03b3\uff0c\u5206\u6790\u4e0d\u540c\u5bc6\u5ea6\u77e9\u9635\u4e0b\u7b97\u6cd5\u7684\u8fed\u4ee3\u6b21\u6570\u3002", "result": "\u4e0a\u754c\uff1a\u5bc6\u5ea6\u03b3 > 1/2\u65f6\uff0c\u7b97\u6cd5\u5728O(log n - log \u03b5)\u6b21\u8fed\u4ee3\u548cO(n\u00b2)\u65f6\u95f4\u5185\u4ea7\u751f\u8fd1\u4f3c\u53cc\u968f\u673a\u77e9\u9635\uff1b\u4e0b\u754c\uff1a\u6b63\u77e9\u9635\u5728\u2113\u2082\u8303\u6570\u8bef\u5dee\u5ea6\u91cf\u4e0b\u6709\u03a9(n^(1/2)/\u03b5)\u6b21\u8fed\u4ee3\u7684\u7d27\u754c\uff0c\u03b3 < 1/2\u65f6\u5b58\u5728\u77e9\u9635\u9700\u03a9(n^(1/2)/\u03b5)\u6b21\u8fed\u4ee3\u3002", "conclusion": "Sinkhorn - Knopp\u7b97\u6cd5\u5728\u5bc6\u5ea6\u9608\u503c\u03b3 = 1/2\u5904\u6709\u5c16\u9510\u76f8\u53d8\u3002"}}
{"id": "2507.09051", "pdf": "https://arxiv.org/pdf/2507.09051", "abs": "https://arxiv.org/abs/2507.09051", "authors": ["Aakash Sorathiya", "Gouri Ginde"], "title": "SAGE: A Context-Aware Approach for Mining Privacy Requirements Relevant Reviews from Mental Health Apps", "categories": ["cs.SE"], "comment": null, "summary": "Mental health (MH) apps often require sensitive user data to customize\nservices for mental wellness needs. However, such data collection practices in\nsome MH apps raise significant privacy concerns for users. These concerns are\noften mentioned in app reviews, but other feedback categories, such as\nreliability and usability, tend to take precedence. This poses a significant\nchallenge in automatically identifying privacy requirements-relevant reviews\n(privacy reviews) that can be utilized to extract privacy requirements and\naddress users' privacy concerns. Thus, this study introduces SAGE, a\ncontext-aware approach to automatically mining privacy reviews from MH apps\nusing Natural Language Inference (NLI) with MH domain-specific privacy\nhypotheses (provides domain-specific context awareness) and a GPT model\n(eliminates the need for fine-tuning). The quantitative evaluation of SAGE on a\ndataset of 204K app reviews achieved an F1 score of 0.85 without any\nfine-tuning, outperforming the fine-tuned baseline classifiers BERT and T5.\nFurthermore, SAGE extracted 748 privacy reviews previously overlooked by\nkeyword-based methods, demonstrating its effectiveness through qualitative\nevaluation. These reviews can later be refined into actionable privacy\nrequirement artifacts.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faSAGE\u65b9\u6cd5\u81ea\u52a8\u6316\u6398\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u9690\u79c1\u8bc4\u8bba\uff0c\u8bc4\u4f30\u6548\u679c\u597d\uff0c\u80fd\u63d0\u53d6\u88ab\u5ffd\u89c6\u8bc4\u8bba\u5e76\u7528\u4e8e\u9690\u79c1\u9700\u6c42\u5206\u6790\u3002", "motivation": "\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u6570\u636e\u6536\u96c6\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\uff0c\u4f46\u9690\u79c1\u76f8\u5173\u8bc4\u8bba\u96be\u81ea\u52a8\u8bc6\u522b\uff0c\u9700\u6316\u6398\u9690\u79c1\u8bc4\u8bba\u4ee5\u63d0\u53d6\u9690\u79c1\u9700\u6c42\u3001\u89e3\u51b3\u7528\u6237\u62c5\u5fe7\u3002", "method": "\u5f15\u5165SAGE\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u548c\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7279\u5b9a\u9690\u79c1\u5047\u8bbe\uff0c\u7ed3\u5408GPT\u6a21\u578b\uff0c\u65e0\u9700\u5fae\u8c03\u3002", "result": "\u5728204K\u5e94\u7528\u8bc4\u8bba\u6570\u636e\u96c6\u4e0a\u5b9a\u91cf\u8bc4\u4f30F1\u5206\u6570\u8fbe0.85\uff0c\u4f18\u4e8e\u5fae\u8c03\u7684BERT\u548cT5\uff1b\u5b9a\u6027\u8bc4\u4f30\u63d0\u53d6748\u6761\u88ab\u5173\u952e\u8bcd\u65b9\u6cd5\u5ffd\u7565\u7684\u9690\u79c1\u8bc4\u8bba\u3002", "conclusion": "SAGE\u65b9\u6cd5\u6709\u6548\uff0c\u63d0\u53d6\u7684\u8bc4\u8bba\u53ef\u7528\u4e8e\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u9690\u79c1\u9700\u6c42\u5de5\u4ef6\u3002"}}
{"id": "2507.09128", "pdf": "https://arxiv.org/pdf/2507.09128", "abs": "https://arxiv.org/abs/2507.09128", "authors": ["Ronak Mehta", "Zaid Harchaoui"], "title": "A Generalization Theory for Zero-Shot Prediction", "categories": ["stat.ML", "cs.LG"], "comment": "Published at ICML '25 (Oral)", "summary": "A modern paradigm for generalization in machine learning and AI consists of\npre-training a task-agnostic foundation model, generally obtained using\nself-supervised and multimodal contrastive learning. The resulting\nrepresentations can be used for prediction on a downstream task for which no\nlabeled data is available. We present a theoretical framework to better\nunderstand this approach, called zero-shot prediction. We identify the target\nquantities that zero-shot prediction aims to learn, or learns in passing, and\nthe key conditional independence relationships that enable its generalization\nability.", "AI": {"tldr": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u7406\u89e3\u96f6\u6837\u672c\u9884\u6d4b\uff0c\u8bc6\u522b\u76ee\u6807\u91cf\u548c\u5173\u952e\u6761\u4ef6\u72ec\u7acb\u5173\u7cfb\u3002", "motivation": "\u66f4\u597d\u7406\u89e3\u673a\u5668\u5b66\u4e60\u548cAI\u4e2d\u96f6\u6837\u672c\u9884\u6d4b\u8fd9\u4e00\u73b0\u4ee3\u6cdb\u5316\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u3002", "result": "\u8bc6\u522b\u51fa\u96f6\u6837\u672c\u9884\u6d4b\u76ee\u6807\u91cf\u548c\u5173\u952e\u6761\u4ef6\u72ec\u7acb\u5173\u7cfb\u3002", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u6709\u52a9\u4e8e\u7406\u89e3\u96f6\u6837\u672c\u9884\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2507.10150", "pdf": "https://arxiv.org/pdf/2507.10150", "abs": "https://arxiv.org/abs/2507.10150", "authors": ["Ruihao Gong", "Shihao Bai", "Siyu Wu", "Yunqian Fan", "Zaijun Wang", "Xiuhong Li", "Hailong Yang", "Xianglong Liu"], "title": "Past-Future Scheduler for LLM Serving under SLA Guarantees", "categories": ["cs.DC"], "comment": "Accepted to ASPLOS 2025", "summary": "The exploration and application of Large Language Models (LLMs) is thriving.\nTo reduce deployment costs, continuous batching has become an essential feature\nin current service frameworks. The effectiveness of continuous batching relies\non an accurate estimate of the memory requirements of requests. However, due to\nthe diversity in request output lengths, existing frameworks tend to adopt\naggressive or conservative schedulers, which often result in significant\noverestimation or underestimation of memory consumption. Consequently, they\nsuffer from harmful request evictions or prolonged queuing times, failing to\nachieve satisfactory throughput under strict Service Level Agreement (SLA)\nguarantees (a.k.a. goodput), across various LLM application scenarios with\ndiffering input-output length distributions. To address this issue, we propose\na novel Past-Future scheduler that precisely estimates the peak memory\nresources required by the running batch via considering the historical\ndistribution of request output lengths and calculating memory occupancy at each\nfuture time point. It adapts to applications with all types of input-output\nlength distributions, balancing the trade-off between request queuing and\nharmful evictions, thereby consistently achieving better goodput. Furthermore,\nto validate the effectiveness of the proposed scheduler, we developed a\nhigh-performance LLM serving framework, LightLLM, that implements the\nPast-Future scheduler. Compared to existing aggressive or conservative\nschedulers, LightLLM demonstrates superior goodput, achieving up to 2-3$\\times$\nhigher goodput than other schedulers under heavy loads. LightLLM is open source\nto boost the research in such direction (https://github.com/ModelTC/lightllm).", "AI": {"tldr": "\u4e3a\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u6210\u672c\uff0c\u63d0\u51faPast - Future\u8c03\u5ea6\u5668\u5e76\u5f00\u53d1LightLLM\u6846\u67b6\uff0c\u76f8\u6bd4\u73b0\u6709\u8c03\u5ea6\u5668\u6709\u66f4\u597d\u7684\u541e\u5410\u91cf\u4e14\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u6846\u67b6\u7684\u8fde\u7eed\u6279\u5904\u7406\u56e0\u8bf7\u6c42\u8f93\u51fa\u957f\u5ea6\u591a\u6837\u6027\uff0c\u5728\u4f30\u8ba1\u5185\u5b58\u6d88\u8017\u65f6\u4e0d\u51c6\u786e\uff0c\u65e0\u6cd5\u5728\u4e25\u683cSLA\u4fdd\u8bc1\u4e0b\u83b7\u5f97\u6ee1\u610f\u541e\u5410\u91cf\u3002", "method": "\u63d0\u51faPast - Future\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u8003\u8651\u8bf7\u6c42\u8f93\u51fa\u957f\u5ea6\u7684\u5386\u53f2\u5206\u5e03\u548c\u8ba1\u7b97\u672a\u6765\u5404\u65f6\u95f4\u70b9\u7684\u5185\u5b58\u5360\u7528\uff0c\u7cbe\u786e\u4f30\u8ba1\u8fd0\u884c\u6279\u5904\u7406\u6240\u9700\u7684\u5cf0\u503c\u5185\u5b58\u8d44\u6e90\uff1b\u5f00\u53d1\u5b9e\u73b0\u8be5\u8c03\u5ea6\u5668\u7684\u9ad8\u6027\u80fdLLM\u670d\u52a1\u6846\u67b6LightLLM\u3002", "result": "LightLLM\u76f8\u6bd4\u73b0\u6709\u6fc0\u8fdb\u6216\u4fdd\u5b88\u8c03\u5ea6\u5668\u5c55\u793a\u51fa\u66f4\u4f18\u7684\u541e\u5410\u91cf\uff0c\u5728\u91cd\u8f7d\u4e0b\u6bd4\u5176\u4ed6\u8c03\u5ea6\u5668\u9ad82 - 3\u500d\u3002", "conclusion": "Past - Future\u8c03\u5ea6\u5668\u548cLightLLM\u6846\u67b6\u80fd\u9002\u5e94\u5404\u79cd\u8f93\u5165\u8f93\u51fa\u957f\u5ea6\u5206\u5e03\u7684\u5e94\u7528\uff0c\u5e73\u8861\u8bf7\u6c42\u6392\u961f\u548c\u6709\u5bb3\u9a71\u9010\uff0c\u53ef\u63d0\u5347\u541e\u5410\u91cf\uff0c\u4e14\u5f00\u6e90\u5229\u4e8e\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2507.09423", "pdf": "https://arxiv.org/pdf/2507.09423", "abs": "https://arxiv.org/abs/2507.09423", "authors": ["Dong Wang", "Junyi Jiao", "Arnab Bhadury", "Yaping Zhang", "Mingyan Gao", "Onkar Dalal"], "title": "Item-centric Exploration for Cold Start Problem", "categories": ["cs.IR"], "comment": "Accepted for publication on 2025 ACM Recsys Conference Industry Track", "summary": "Recommender systems face a critical challenge in the item cold-start problem,\nwhich limits content diversity and exacerbates popularity bias by struggling to\nrecommend new items. While existing solutions often rely on auxiliary data, but\nthis paper illuminates a distinct, yet equally pressing, issue stemming from\nthe inherent user-centricity of many recommender systems. We argue that in\nenvironments with large and rapidly expanding item inventories, the traditional\nfocus on finding the \"best item for a user\" can inadvertently obscure the ideal\naudience for nascent content. To counter this, we introduce the concept of\nitem-centric recommendations, shifting the paradigm to identify the optimal\nusers for new items. Our initial realization of this vision involves an\nitem-centric control integrated into an exploration system. This control\nemploys a Bayesian model with Beta distributions to assess candidate items\nbased on a predicted balance between user satisfaction and the item's inherent\nquality. Empirical online evaluations reveal that this straightforward control\nmarkedly improves cold-start targeting efficacy, enhances user satisfaction\nwith newly explored content, and significantly increases overall exploration\nefficiency.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u63a8\u8350\u7cfb\u7edf\u7528\u6237\u4e2d\u5fc3\u6a21\u5f0f\u5728\u51b7\u542f\u52a8\u95ee\u9898\u4e2d\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4ee5\u7269\u54c1\u4e3a\u4e2d\u5fc3\u7684\u63a8\u8350\u6982\u5ff5\uff0c\u5b9e\u73b0\u7269\u54c1\u4e2d\u5fc3\u63a7\u5236\uff0c\u5b9e\u8bc1\u663e\u793a\u80fd\u63d0\u5347\u51b7\u542f\u52a8\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u7528\u6237\u4e2d\u5fc3\u6a21\u5f0f\u5728\u7269\u54c1\u51b7\u542f\u52a8\u95ee\u9898\u4e2d\u96be\u4ee5\u627e\u5230\u65b0\u5185\u5bb9\u7684\u7406\u60f3\u53d7\u4f17\uff0c\u9650\u5236\u5185\u5bb9\u591a\u6837\u6027\u548c\u52a0\u5267\u6d41\u884c\u5ea6\u504f\u5dee\u3002", "method": "\u5f15\u5165\u7269\u54c1\u4e2d\u5fc3\u63a8\u8350\u6982\u5ff5\uff0c\u5c06\u7269\u54c1\u4e2d\u5fc3\u63a7\u5236\u96c6\u6210\u5230\u63a2\u7d22\u7cfb\u7edf\uff0c\u7528\u8d1d\u53f6\u65af\u6a21\u578b\u548cBeta\u5206\u5e03\u8bc4\u4f30\u5019\u9009\u7269\u54c1\u3002", "result": "\u8be5\u63a7\u5236\u663e\u8457\u63d0\u9ad8\u51b7\u542f\u52a8\u76ee\u6807\u5b9a\u4f4d\u6548\u679c\uff0c\u63d0\u5347\u7528\u6237\u5bf9\u65b0\u63a2\u7d22\u5185\u5bb9\u7684\u6ee1\u610f\u5ea6\uff0c\u5927\u5e45\u63d0\u9ad8\u6574\u4f53\u63a2\u7d22\u6548\u7387\u3002", "conclusion": "\u7269\u54c1\u4e2d\u5fc3\u7684\u63a8\u8350\u65b9\u5f0f\u80fd\u6709\u6548\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u7684\u7269\u54c1\u51b7\u542f\u52a8\u95ee\u9898\u3002"}}
{"id": "2507.10196", "pdf": "https://arxiv.org/pdf/2507.10196", "abs": "https://arxiv.org/abs/2507.10196", "authors": ["Moritz Flaschel", "Trevor Hastie", "Ellen Kuhl"], "title": "Non-smooth optimization meets automated material model discovery", "categories": ["cs.CE", "cond-mat.mtrl-sci"], "comment": null, "summary": "Automated material model discovery disrupts the tedious and time-consuming\ncycle of iteratively calibrating and modifying manually designed models.\nNon-smooth L1-norm regularization is the backbone of automated model discovery;\nhowever, the current literature on automated material model discovery offers\nlimited insights into the robust and efficient minimization of non-smooth\nobjective functions. In this work, we examine the minimization of functions of\nthe form f(w) + a ||w||_1, where w are the material model parameters, f is a\nmetric that quantifies the mismatch between the material model and the observed\ndata, and a is a regularization parameter that determines the sparsity of the\nsolution. We investigate both the straightforward case where f is quadratic and\nthe more complex scenario where it is non-quadratic or even non-convex.\nImportantly, we do not only focus on methods that solve the sparse regression\nproblem for a given value of the regularization parameter a, but propose\nmethods to efficiently compute the entire regularization path, facilitating the\nselection of a suitable a. Specifically, we present four algorithms and discuss\ntheir roles for automated material model discovery in mechanics: First, we\nrecapitulate a well-known coordinate descent algorithm that solves the\nminimization problem assuming that f is quadratic for a given value of a, also\nknown as the LASSO. Second, we discuss the algorithm LARS, which automatically\ndetermines the critical values of a, at which material parameters in w are set\nto zero. Third, we propose to use the proximal gradient method ISTA for\nautomated material model discovery if f is not quadratic, and fourth, we\nsuggest a pathwise extension of ISTA for computing the regularization path. We\ndemonstrate the applicability of all algorithms for the discovery of\nhyperelastic material models from uniaxial tension and simple shear data.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u81ea\u52a8\u5316\u6750\u6599\u6a21\u578b\u53d1\u73b0\u4e2d\u975e\u5149\u6ed1\u76ee\u6807\u51fd\u6570\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u56db\u79cd\u7b97\u6cd5\u5e76\u5c55\u793a\u5176\u5728\u8d85\u5f39\u6027\u6750\u6599\u6a21\u578b\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u6750\u6599\u6a21\u578b\u53d1\u73b0\u6587\u732e\u5bf9\u975e\u5149\u6ed1\u76ee\u6807\u51fd\u6570\u9c81\u68d2\u9ad8\u6548\u6700\u5c0f\u5316\u7684\u7814\u7a76\u6709\u9650\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76f(w) + a ||w||_1\u5f62\u5f0f\u51fd\u6570\u6700\u5c0f\u5316\uff0c\u8003\u8651f\u4e3a\u4e8c\u6b21\u548c\u975e\u4e8c\u6b21\u60c5\u51b5\uff0c\u63d0\u51fa\u56db\u79cd\u7b97\u6cd5\uff08\u5750\u6807\u4e0b\u964d\u7b97\u6cd5\u3001LARS\u7b97\u6cd5\u3001\u8fd1\u7aef\u68af\u5ea6\u6cd5ISTA\u53caISTA\u7684\u8def\u5f84\u6269\u5c55\u6cd5\uff09\u3002", "result": "\u5c55\u793a\u4e86\u56db\u79cd\u7b97\u6cd5\u5728\u4ece\u5355\u8f74\u62c9\u4f38\u548c\u7b80\u5355\u526a\u5207\u6570\u636e\u4e2d\u53d1\u73b0\u8d85\u5f39\u6027\u6750\u6599\u6a21\u578b\u65b9\u9762\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u56db\u79cd\u7b97\u6cd5\u6709\u52a9\u4e8e\u81ea\u52a8\u5316\u6750\u6599\u6a21\u578b\u53d1\u73b0\u4e2d\u89e3\u51b3\u975e\u5149\u6ed1\u76ee\u6807\u51fd\u6570\u6700\u5c0f\u5316\u95ee\u9898\u53ca\u9009\u62e9\u5408\u9002\u7684\u6b63\u5219\u5316\u53c2\u6570\u3002"}}
{"id": "2507.10070", "pdf": "https://arxiv.org/pdf/2507.10070", "abs": "https://arxiv.org/abs/2507.10070", "authors": ["Yang Xiao", "Mo Sun", "Ziyu Song", "Bing Tian", "Jie Zhang", "Jie Sun", "Zeke Wang"], "title": "Breaking the Storage-Compute Bottleneck in Billion-Scale ANNS: A GPU-Driven Asynchronous I/O Framework", "categories": ["cs.DB"], "comment": null, "summary": "With the advancement of information retrieval, recommendation systems, and\nRetrieval-Augmented Generation (RAG), Approximate Nearest Neighbor Search\n(ANNS) gains widespread applications due to its higher performance and\naccuracy. While several disk-based ANNS systems have emerged to handle\nexponentially growing vector datasets, they suffer from suboptimal performance\ndue to two inherent limitations: 1) failing to overlap SSD accesses with\ndistance computation processes and 2) extended I/O latency caused by suboptimal\nI/O Stack. To address these challenges, we present FlashANNS, a GPU-accelerated\nout-of-core graph-based ANNS system through I/O-compute overlapping. Our core\ninsight lies in the synchronized orchestration of I/O and computation through\nthree key innovations: 1) Dependency-Relaxed asynchronous pipeline: FlashANNS\ndecouples I/O-computation dependencies to fully overlap between GPU distance\ncalculations and SSD data transfers. 2) Warp-Level concurrent SSD access:\nFlashANNS implements a lock-free I/O stack with warp-level concurrency control,\nto reduce the latency-induced time overhead. 3) Computation-I/O balanced graph\ndegree Selection: FlashANNS selects graph degrees via lightweight\ncompute-to-I/O ratio sampling, ensuring optimal balance between computational\nload and storage access latency across different I/O bandwidth configurations.\nWe implement FlashANNS and compare it with state-of-the-art out-of-core ANNS\nsystems (SPANN, DiskANN) and a GPU-accelerated out-of-core ANNS system\n(FusionANNS). Experimental results demonstrate that at $\\geq$95\\% recall@10\naccuracy, our method achieves 2.3-5.9$\\times$ higher throughput compared to\nexisting SOTA methods with a single SSD, and further attains 2.7-12.2$\\times$\nthroughput improvement in multi-SSD configurations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGPU\u52a0\u901f\u7684\u79bb\u6838\u56feANNS\u7cfb\u7edfFlashANNS\uff0c\u901a\u8fc7\u521b\u65b0\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u6027\u80fd\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u541e\u5410\u91cf\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u78c1\u76d8\u7684ANNS\u7cfb\u7edf\u5b58\u5728SSD\u8bbf\u95ee\u4e0e\u8ddd\u79bb\u8ba1\u7b97\u65e0\u6cd5\u91cd\u53e0\u3001I/O\u6808\u4e0d\u4f73\u5bfc\u81f4I/O\u5ef6\u8fdf\u957f\u7684\u95ee\u9898\uff0c\u6027\u80fd\u6b20\u4f73\u3002", "method": "\u63d0\u51faFlashANNS\u7cfb\u7edf\uff0c\u91c7\u7528\u4f9d\u8d56\u677e\u5f1b\u5f02\u6b65\u6d41\u6c34\u7ebf\u3001\u7ebf\u7a0b\u675f\u7ea7\u5e76\u53d1SSD\u8bbf\u95ee\u3001\u8ba1\u7b97 - I/O\u5e73\u8861\u56fe\u5ea6\u9009\u62e9\u4e09\u4e2a\u521b\u65b0\u65b9\u6cd5\u5b9e\u73b0I/O\u4e0e\u8ba1\u7b97\u540c\u6b65\u7f16\u6392\u3002", "result": "\u5728\u226595% recall@10\u51c6\u786e\u7387\u4e0b\uff0c\u5355SSD\u65f6\u541e\u5410\u91cf\u6bd4\u73b0\u6709SOTA\u65b9\u6cd5\u9ad82.3 - 5.9\u500d\uff0c\u591aSSD\u914d\u7f6e\u4e0b\u541e\u5410\u91cf\u63d0\u53472.7 - 12.2\u500d\u3002", "conclusion": "FlashANNS\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u78c1\u76d8\u7684ANNS\u7cfb\u7edf\u7684\u6027\u80fd\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u541e\u5410\u91cf\u3002"}}
{"id": "2507.10383", "pdf": "https://arxiv.org/pdf/2507.10383", "abs": "https://arxiv.org/abs/2507.10383", "authors": ["Uri Cohen", "M\u00e1t\u00e9 Lengyel"], "title": "Dynamical stability for dense patterns in discrete attractor neural networks", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "cs.NE", "q-bio.NC"], "comment": null, "summary": "Neural networks storing multiple discrete attractors are canonical models of\nbiological memory. Previously, the dynamical stability of such networks could\nonly be guaranteed under highly restrictive conditions. Here, we derive a\ntheory of the local stability of discrete fixed points in a broad class of\nnetworks with graded neural activities and in the presence of noise. By\ndirectly analyzing the bulk and outliers of the Jacobian spectrum, we show that\nall fixed points are stable below a critical load that is distinct from the\nclassical \\textit{critical capacity} and depends on the statistics of neural\nactivities in the fixed points as well as the single-neuron activation\nfunction. Our analysis highlights the computational benefits of\nthreshold-linear activation and sparse-like patterns.", "AI": {"tldr": "\u63a8\u5bfc\u4e86\u4e00\u7c7b\u7f51\u7edc\u79bb\u6563\u4e0d\u52a8\u70b9\u5c40\u90e8\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u6307\u51fa\u56fa\u5b9a\u70b9\u5728\u4e34\u754c\u8d1f\u8f7d\u4e0b\u7a33\u5b9a\uff0c\u51f8\u663e\u7279\u5b9a\u6fc0\u6d3b\u548c\u6a21\u5f0f\u7684\u8ba1\u7b97\u4f18\u52bf\u3002", "motivation": "\u4ee5\u5f80\u795e\u7ecf\u7f51\u7edc\u52a8\u6001\u7a33\u5b9a\u6027\u53ea\u80fd\u5728\u4e25\u683c\u6761\u4ef6\u4e0b\u4fdd\u8bc1\uff0c\u9700\u7814\u7a76\u66f4\u5e7f\u6cdb\u6761\u4ef6\u4e0b\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u76f4\u63a5\u5206\u6790\u96c5\u53ef\u6bd4\u8c31\u7684\u4e3b\u4f53\u548c\u5f02\u5e38\u503c\u3002", "result": "\u6240\u6709\u56fa\u5b9a\u70b9\u5728\u4e00\u4e2a\u4e0d\u540c\u4e8e\u7ecf\u5178\u4e34\u754c\u5bb9\u91cf\u7684\u4e34\u754c\u8d1f\u8f7d\u4e0b\u7a33\u5b9a\uff0c\u8be5\u4e34\u754c\u8d1f\u8f7d\u4e0e\u56fa\u5b9a\u70b9\u795e\u7ecf\u6d3b\u52a8\u7edf\u8ba1\u53ca\u5355\u795e\u7ecf\u5143\u6fc0\u6d3b\u51fd\u6570\u6709\u5173\u3002", "conclusion": "\u9608\u503c\u7ebf\u6027\u6fc0\u6d3b\u548c\u7c7b\u7a00\u758f\u6a21\u5f0f\u6709\u8ba1\u7b97\u4f18\u52bf\u3002"}}
{"id": "2507.09329", "pdf": "https://arxiv.org/pdf/2507.09329", "abs": "https://arxiv.org/abs/2507.09329", "authors": ["Matous Kozak", "Roshanak Zilouchian Moghaddam", "Siva Sivaraman"], "title": "When Developer Aid Becomes Security Debt: A Systematic Analysis of Insecure Behaviors in LLM Coding Agents", "categories": ["cs.AI", "cs.CR"], "comment": "15 pages", "summary": "LLM-based coding agents are rapidly being deployed in software development,\nyet their security implications remain poorly understood. These agents, while\ncapable of accelerating software development, may inadvertently introduce\ninsecure practices. We conducted the first systematic security evaluation of\nautonomous coding agents, analyzing over 12,000 actions across five\nstate-of-the-art models (GPT-4o, GPT-4.1, Claude variants) on 93 real-world\nsoftware setup tasks. Our findings reveal significant security concerns: 21% of\nagent trajectories contained insecure actions, with models showing substantial\nvariation in security behavior. We developed a high-precision detection system\nthat identified four major vulnerability categories, with information exposure\n(CWE-200) being the most prevalent one. We also evaluated mitigation strategies\nincluding feedback mechanisms and security reminders with various effectiveness\nbetween models. GPT-4.1 demonstrated exceptional security awareness with 96.8%\nmitigation success. Our work provides the first comprehensive framework for\nevaluating coding agent security and highlights the need for security-aware\ndesign of next generation LLM-based coding agents.", "AI": {"tldr": "\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7801\u4ee3\u7406\u8fdb\u884c\u7cfb\u7edf\u5b89\u5168\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b89\u5168\u95ee\u9898\u5e76\u5f00\u53d1\u68c0\u6d4b\u7cfb\u7edf\uff0c\u8bc4\u4f30\u7f13\u89e3\u7b56\u7565\uff0c\u4e3a\u8bc4\u4f30\u7f16\u7801\u4ee3\u7406\u5b89\u5168\u63d0\u4f9b\u6846\u67b6\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7801\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u8fc5\u901f\u5e94\u7528\uff0c\u4f46\u5b89\u5168\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\uff0c\u53ef\u80fd\u5f15\u5165\u4e0d\u5b89\u5168\u5b9e\u8df5\uff0c\u56e0\u6b64\u9700\u8fdb\u884c\u5b89\u5168\u8bc4\u4f30\u3002", "method": "\u5bf9\u4e94\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u572893\u4e2a\u5b9e\u9645\u8f6f\u4ef6\u8bbe\u7f6e\u4efb\u52a1\u4e0a\u7684\u8d8512000\u4e2a\u64cd\u4f5c\u8fdb\u884c\u5206\u6790\uff0c\u5f00\u53d1\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u7cfb\u7edf\uff0c\u8bc4\u4f30\u7f13\u89e3\u7b56\u7565\u3002", "result": "21%\u7684\u4ee3\u7406\u8f68\u8ff9\u5305\u542b\u4e0d\u5b89\u5168\u64cd\u4f5c\uff0c\u6a21\u578b\u5b89\u5168\u884c\u4e3a\u5dee\u5f02\u5927\uff0c\u68c0\u6d4b\u7cfb\u7edf\u8bc6\u522b\u51fa\u56db\u7c7b\u4e3b\u8981\u6f0f\u6d1e\uff0c\u4fe1\u606f\u66b4\u9732\u6700\u666e\u904d\uff0c\u4e0d\u540c\u6a21\u578b\u7f13\u89e3\u7b56\u7565\u6548\u679c\u4e0d\u540c\uff0cGPT - 4.1\u7f13\u89e3\u6210\u529f\u7387\u8fbe96.8%\u3002", "conclusion": "\u4e3a\u8bc4\u4f30\u7f16\u7801\u4ee3\u7406\u5b89\u5168\u63d0\u4f9b\u9996\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u5f3a\u8c03\u4e0b\u4e00\u4ee3\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7801\u4ee3\u7406\u9700\u8fdb\u884c\u5b89\u5168\u611f\u77e5\u8bbe\u8ba1\u3002"}}
{"id": "2507.10416", "pdf": "https://arxiv.org/pdf/2507.10416", "abs": "https://arxiv.org/abs/2507.10416", "authors": ["Dan Anderberg", "Rachel Cassidy", "Anaya Dam", "Melissa Hidrobo", "Jessica Leight", "Karlijn Morsink"], "title": "Intimate partner violence and women's economic preferences", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "One in three women globally experiences intimate partner violence (IPV), yet\nlittle is known about how such trauma affects economic decision-making. We\nprovide causal evidence that IPV influences women's time preferences - a key\nparameter in models of savings, investment, and labor supply. We combine two\nempirical strategies using four distinct datasets. First, in two randomized\nrecall experiments in Ethiopia, we randomly assigned women to recall specific\nacts of abuse before eliciting their intertemporal choices. Women with IPV\nexperiences prompted to recall IPV display significantly greater impatience\nthan otherwise similar women who are not prompted. Second, we exploit exogenous\nreductions in IPV generated by two randomized interventions - one involving\ncash transfers, the other psychotherapy - and use treatment assignment as an\ninstrument for IPV exposure. Women who experience reduced IPV as a result of\ntreatment exhibit more patient time preferences. Together, these results\nprovide consistent, novel causal evidence that exposure to IPV induces\nindividuals to discount the future more heavily. This evidence suggests a\npsychological channel through which violence can perpetuate economic\ndisadvantage and constrain women's ability to take actions - such as saving,\ninvesting, or exiting abusive relationships - that require planning over time.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4eb2\u5bc6\u4f34\u4fa3\u66b4\u529b\uff08IPV\uff09\u5f71\u54cd\u5973\u6027\u65f6\u95f4\u504f\u597d\uff0c\u4fc3\u4f7f\u5176\u66f4\u770b\u91cd\u5f53\u4e0b\u3002", "motivation": "\u5168\u7403\u4e09\u5206\u4e4b\u4e00\u5973\u6027\u7ecf\u5386IPV\uff0c\u4f46\u6b64\u7c7b\u521b\u4f24\u5bf9\u7ecf\u6d4e\u51b3\u7b56\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u6545\u7814\u7a76IPV\u5bf9\u5973\u6027\u65f6\u95f4\u504f\u597d\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u4e24\u79cd\u5b9e\u8bc1\u7b56\u7565\uff0c\u4f7f\u7528\u56db\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u3002\u4e00\u662f\u5728\u57c3\u585e\u4fc4\u6bd4\u4e9a\u8fdb\u884c\u968f\u673a\u56de\u5fc6\u5b9e\u9a8c\uff1b\u4e8c\u662f\u5229\u7528\u4e24\u9879\u968f\u673a\u5e72\u9884\u5bfc\u81f4\u7684IPV\u5916\u751f\u51cf\u5c11\uff0c\u4ee5\u6cbb\u7597\u5206\u914d\u4f5c\u4e3aIPV\u66b4\u9732\u7684\u5de5\u5177\u53d8\u91cf\u3002", "result": "\u56de\u5fc6IPV\u7ecf\u5386\u7684\u5973\u6027\u66f4\u4e0d\u8010\u70e6\uff1b\u56e0\u6cbb\u7597\u51cf\u5c11IPV\u7684\u5973\u6027\u66f4\u6709\u8010\u5fc3\u3002", "conclusion": "IPV\u4f1a\u4f7f\u4e2a\u4f53\u66f4\u770b\u91cd\u5f53\u4e0b\uff0c\u66b4\u529b\u53ef\u901a\u8fc7\u5fc3\u7406\u6e20\u9053\u52a0\u5267\u7ecf\u6d4e\u52a3\u52bf\uff0c\u9650\u5236\u5973\u6027\u91c7\u53d6\u9700\u957f\u671f\u89c4\u5212\u7684\u884c\u52a8\u3002"}}
{"id": "2507.09729", "pdf": "https://arxiv.org/pdf/2507.09729", "abs": "https://arxiv.org/abs/2507.09729", "authors": ["Henry Fleischmann", "George Z. Li", "Jason Li"], "title": "Improved Directed Expander Decompositions", "categories": ["cs.DS"], "comment": "54 pages, 3 figures", "summary": "We obtain faster expander decomposition algorithms for directed graphs,\nmatching the guarantees of Saranurak and Wang (SODA 2019) for expander\ndecomposition on undirected graphs. Our algorithms are faster than prior work\nand also generalize almost losslessly to capacitated graphs. In particular, we\nobtain the first directed expander decomposition algorithm for capacitated\ngraphs in near-linear time with optimal dependence on $\\phi$.\n  To obtain our result, we provide the first implementation and analysis of the\nnon-stop cut-matching game for directed, capacitated graphs. All existing\ndirected expander decomposition algorithms instead temporarily add ''fake\nedges'' before pruning them away in a final cleanup step. Our result shows that\nthe natural undirected approach applies even to directed graphs. The difficulty\nis in its analysis, which is technical and requires significant modifications\nfrom the original setting of undirected graphs.", "AI": {"tldr": "\u672c\u6587\u4e3a\u6709\u5411\u56fe\u83b7\u5f97\u66f4\u5feb\u7684\u6269\u5f20\u5668\u5206\u89e3\u7b97\u6cd5\uff0c\u5339\u914d\u65e0\u5411\u56fe\u7b97\u6cd5\u4fdd\u8bc1\uff0c\u53ef\u65e0\u635f\u63a8\u5e7f\u5230\u5bb9\u91cf\u56fe\uff0c\u9996\u6b21\u5b9e\u73b0\u5bb9\u91cf\u56fe\u8fd1\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u3002", "motivation": "\u4e3a\u6709\u5411\u56fe\u627e\u5230\u66f4\u5feb\u7684\u6269\u5f20\u5668\u5206\u89e3\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u63a8\u5e7f\u5230\u5bb9\u91cf\u56fe\u3002", "method": "\u9996\u6b21\u5b9e\u73b0\u5e76\u5206\u6790\u6709\u5411\u5bb9\u91cf\u56fe\u7684\u4e0d\u505c\u5207\u914d\u6e38\u620f\uff0c\u907f\u514d\u4f7f\u7528\u6dfb\u52a0\u201c\u5047\u8fb9\u201d\u7684\u65b9\u6cd5\u3002", "result": "\u5f97\u5230\u6709\u5411\u56fe\u66f4\u5feb\u7684\u6269\u5f20\u5668\u5206\u89e3\u7b97\u6cd5\uff0c\u53ef\u65e0\u635f\u63a8\u5e7f\u5230\u5bb9\u91cf\u56fe\uff0c\u9996\u6b21\u83b7\u5f97\u5bb9\u91cf\u56fe\u8fd1\u7ebf\u6027\u65f6\u95f4\u4e14\u5bf9\u03c6\u6709\u6700\u4f18\u4f9d\u8d56\u7684\u6709\u5411\u6269\u5f20\u5668\u5206\u89e3\u7b97\u6cd5\u3002", "conclusion": "\u81ea\u7136\u7684\u65e0\u5411\u56fe\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u6709\u5411\u56fe\uff0c\u5c3d\u7ba1\u5206\u6790\u6709\u6280\u672f\u96be\u5ea6\u4e14\u9700\u663e\u8457\u4fee\u6539\u3002"}}
{"id": "2507.09063", "pdf": "https://arxiv.org/pdf/2507.09063", "abs": "https://arxiv.org/abs/2507.09063", "authors": ["Avi Arora", "Jinu Jang", "Roshanak Zilouchian Moghaddam"], "title": "SetupBench: Assessing Software Engineering Agents' Ability to Bootstrap Development Environments", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Modern Large Language Model (LLM) agents promise end to end assistance with\nreal-world software tasks, yet existing benchmarks evaluate LLM agents almost\nexclusively in pre-baked environments where every dependency is pre-installed.\nTo fill this gap, we introduce SetupBench, a 93 instance benchmark that\nisolates the environment-bootstrap skill: starting from a bare Linux sandbox,\nan agent must install packages, resolve dependency conflicts, initialize\ndatabases, and configure background services. Our tasks span seven language\necosystems, five database engines, and multi-service orchestration scenarios,\neach accompanies by a natural language problem statement and a deterministic\nsuccess command. Through evaluation of OpenHands, a state-of-the-art coding\nagent, we find low success rates across task categories, with particular\nchallenges in repository setup (38.9-57.4%) and local database configuration\n(20.0-53.3%). Our analysis reveals systematic failure modes including\nincomplete development tooling installation, hallucinated task constraints, and\nnon-persistent environment modifications that break agent-human collaboration\nworkflows. We identify substantial inefficiencies in agent exploration\nstrategies, with 38-89% of actions being unnecessary compared to optimal human\nbehavior. These findings highlight gaps in current agents' practical\nenvironment-bootstrap capabilities. By targeting this critical yet\nunder-evaluated capability, SetupBench provides a rigorous yard-stick for the\nnext generation of software developer agents aiming to solve end to end\nreal-wold tasks.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u73af\u5883\u642d\u5efa\u8bc4\u4f30\u4e0d\u8db3\uff0c\u672c\u6587\u5f15\u5165SetupBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u53d1\u73b0\u73b0\u6709\u4ee3\u7406\u5728\u73af\u5883\u642d\u5efa\u80fd\u529b\u4e0a\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u591a\u5728\u9884\u5b89\u88c5\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u4ee3\u7406\uff0c\u7f3a\u4e4f\u5bf9\u73af\u5883\u642d\u5efa\u6280\u80fd\u7684\u8bc4\u4f30\uff0c\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5f15\u5165\u5305\u542b93\u4e2a\u5b9e\u4f8b\u7684SetupBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u591a\u79cd\u8bed\u8a00\u751f\u6001\u548c\u6570\u636e\u5e93\u5f15\u64ce\uff0c\u5bf9OpenHands\u7f16\u7801\u4ee3\u7406\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "OpenHands\u5728\u5404\u4efb\u52a1\u7c7b\u522b\u4e2d\u6210\u529f\u7387\u4f4e\uff0c\u5b58\u5728\u4e0d\u5b8c\u6574\u5b89\u88c5\u3001\u5e7b\u89c9\u7ea6\u675f\u7b49\u5931\u8d25\u6a21\u5f0f\uff0c\u4ee3\u7406\u63a2\u7d22\u7b56\u7565\u6548\u7387\u4f4e\u3002", "conclusion": "SetupBench\u53ef\u4e3a\u4e0b\u4e00\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u8005\u4ee3\u7406\u63d0\u4f9b\u4e25\u683c\u8bc4\u4f30\u6807\u51c6\uff0c\u5f53\u524d\u4ee3\u7406\u5728\u73af\u5883\u642d\u5efa\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2507.09148", "pdf": "https://arxiv.org/pdf/2507.09148", "abs": "https://arxiv.org/abs/2507.09148", "authors": ["Alberto Del Pia", "Dekun Zhou"], "title": "A Randomized Algorithm for Sparse PCA based on the Basic SDP Relaxation", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": "29 pages, 2 figures", "summary": "Sparse Principal Component Analysis (SPCA) is a fundamental technique for\ndimensionality reduction, and is NP-hard. In this paper, we introduce a\nrandomized approximation algorithm for SPCA, which is based on the basic SDP\nrelaxation. Our algorithm has an approximation ratio of at most the sparsity\nconstant with high probability, if called enough times. Under a technical\nassumption, which is consistently satisfied in our numerical tests, the average\napproximation ratio is also bounded by $\\mathcal{O}(\\log{d})$, where $d$ is the\nnumber of features. We show that this technical assumption is satisfied if the\nSDP solution is low-rank, or has exponentially decaying eigenvalues. We then\npresent a broad class of instances for which this technical assumption holds.\nWe also demonstrate that in a covariance model, which generalizes the spiked\nWishart model, our proposed algorithm achieves a near-optimal approximation\nratio. We demonstrate the efficacy of our algorithm through numerical results\non real-world datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eSDP\u677e\u5f1b\u7684\u7a00\u758f\u4e3b\u6210\u5206\u5206\u6790\uff08SPCA\uff09\u968f\u673a\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5206\u6790\u5176\u8fd1\u4f3c\u6bd4\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "SPCA\u662f\u91cd\u8981\u964d\u7ef4\u6280\u672f\u4e14\u4e3aNP\u96be\u95ee\u9898\uff0c\u9700\u8981\u6709\u6548\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u57fa\u672cSDP\u677e\u5f1b\u7684\u968f\u673a\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u9ad8\u6982\u7387\u4e0b\u8fd1\u4f3c\u6bd4\u81f3\u591a\u4e3a\u7a00\u758f\u5e38\u6570\uff0c\u5728\u6280\u672f\u5047\u8bbe\u4e0b\u5e73\u5747\u8fd1\u4f3c\u6bd4\u6709\u754c\uff0c\u5728\u534f\u65b9\u5dee\u6a21\u578b\u4e2d\u53ef\u8fbe\u8fd1\u6700\u4f18\u8fd1\u4f3c\u6bd4\uff0c\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u968f\u673a\u8fd1\u4f3c\u7b97\u6cd5\u5bf9SPCA\u95ee\u9898\u6709\u6548\u3002"}}
{"id": "2507.10550", "pdf": "https://arxiv.org/pdf/2507.10550", "abs": "https://arxiv.org/abs/2507.10550", "authors": ["Quentin Guilmant", "Jo\u00ebl Ouaknine", "Isa Vialard"], "title": "The Value Problem for Weighted Timed Games with Two Clocks is Undecidable", "categories": ["cs.GT"], "comment": null, "summary": "The Value Problem for weighted timed games (WTGs) consists in determining,\ngiven a two-player weighted timed game with a reachability objective and a\nrational threshold, whether or not the value of the game exceeds the threshold.\nThis problem was shown to be undecidable some ten years ago for WTGs making use\nof at least three clocks, and is known to be decidable for single-clock WTGs.\nIn this paper, we establish undecidability for two-clock WTGs making use of\nnon-negative weights, even in a time-bounded setting, closing the last\nremaining major gap in our algorithmic understanding of WTGs.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4e86\u5e26\u975e\u8d1f\u6743\u91cd\u7684\u53cc\u65f6\u949f\u52a0\u6743\u5b9a\u65f6\u535a\u5f08\uff08WTGs\uff09\u4ef7\u503c\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\uff0c\u586b\u8865\u7b97\u6cd5\u7406\u89e3\u7a7a\u767d\u3002", "motivation": "\u6b64\u524d\u5df2\u77e5\u5355\u65f6\u949fWTGs\u4ef7\u503c\u95ee\u9898\u53ef\u5224\u5b9a\uff0c\u4e09\u65f6\u949f\u53ca\u4ee5\u4e0a\u4e0d\u53ef\u5224\u5b9a\uff0c\u53cc\u65f6\u949f\u60c5\u51b5\u672a\u77e5\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7b97\u6cd5\u7406\u89e3\u7684\u7a7a\u767d\u3002", "method": "\u672a\u63d0\u53ca\u3002", "result": "\u8bc1\u660e\u4e86\u5e26\u975e\u8d1f\u6743\u91cd\u7684\u53cc\u65f6\u949fWTGs\u5728\u6709\u65f6\u95f4\u9650\u5236\u7684\u60c5\u51b5\u4e0b\u4ef7\u503c\u95ee\u9898\u4e0d\u53ef\u5224\u5b9a\u3002", "conclusion": "\u89e3\u51b3\u4e86WTGs\u7b97\u6cd5\u7406\u89e3\u4e2d\u6700\u540e\u4e00\u4e2a\u4e3b\u8981\u7a7a\u767d\u3002"}}
{"id": "2507.10259", "pdf": "https://arxiv.org/pdf/2507.10259", "abs": "https://arxiv.org/abs/2507.10259", "authors": ["Chengze Du", "Zhiwei Yu", "Heng Xu", "Haojie Wang", "Bo liu", "Jialong Li"], "title": "Cross-Timeslot Optimization for Distributed GPU Inference Using Reinforcement Learning", "categories": ["cs.DC", "cs.NI"], "comment": "17 pages, 12 figures", "summary": "The rapid growth of large language model (LLM) services imposes increasing\ndemands on distributed GPU inference infrastructure. Most existing scheduling\nsystems rely on the current system state to make decisions, without considering\nhow task demand and resource availability evolve over time. This lack of\ntemporal awareness leads to inefficient GPU utilization, high task migration\noverhead, and poor system responsiveness under dynamic workloads. In this work,\nwe identify the fundamental limitations of these instantaneous-state-only\nscheduling approaches and propose Temporal Optimal Resource scheduling via\nTwo-layer Architecture (TORTA). TORTA introduces a spatiotemporal scheduling\nframework that captures both long-term workload patterns and short-term\nexecution constraints. It adopts a two-layer design: a macro-level scheduler\nleverages reinforcement learning and optimal transport to coordinate\ninter-region task distribution, while a micro-level allocator refines\ntask-to-server assignments within each region to reduce latency and switching\ncosts. Experimental results across multiple network topologies show that TORTA\nreduces average inference response time by up to 15\\%, improves load balance by\napproximately 4-5\\%, and cuts total operational cost by 10-20\\% compared to\nstate-of-the-art baseline methods.", "AI": {"tldr": "\u73b0\u6709\u8c03\u5ea6\u7cfb\u7edf\u7f3a\u4e4f\u65f6\u95f4\u611f\u77e5\uff0c\u672c\u6587\u63d0\u51fa TORTA \u8c03\u5ea6\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u964d\u4f4e\u54cd\u5e94\u65f6\u95f4\u3001\u63d0\u9ad8\u8d1f\u8f7d\u5747\u8861\u5e76\u524a\u51cf\u8fd0\u8425\u6210\u672c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u5bf9\u5206\u5e03\u5f0f GPU \u63a8\u7406\u57fa\u7840\u8bbe\u65bd\u9700\u6c42\u589e\u52a0\uff0c\u73b0\u6709\u8c03\u5ea6\u7cfb\u7edf\u7f3a\u4e4f\u65f6\u95f4\u611f\u77e5\uff0c\u5bfc\u81f4 GPU \u5229\u7528\u7387\u4f4e\u3001\u4efb\u52a1\u8fc1\u79fb\u5f00\u9500\u5927\u3001\u7cfb\u7edf\u54cd\u5e94\u5dee\u3002", "method": "\u63d0\u51fa Temporal Optimal Resource scheduling via Two - layer Architecture (TORTA)\uff0c\u91c7\u7528\u65f6\u7a7a\u8c03\u5ea6\u6846\u67b6\uff0c\u6709\u4e24\u5c42\u8bbe\u8ba1\uff0c\u5b8f\u89c2\u8c03\u5ea6\u5668\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u6700\u4f18\u4f20\u8f93\u534f\u8c03\u533a\u57df\u95f4\u4efb\u52a1\u5206\u914d\uff0c\u5fae\u89c2\u5206\u914d\u5668\u4f18\u5316\u533a\u57df\u5185\u4efb\u52a1\u5230\u670d\u52a1\u5668\u7684\u5206\u914d\u3002", "result": "\u5728\u591a\u4e2a\u7f51\u7edc\u62d3\u6251\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cTORTA \u5e73\u5747\u63a8\u7406\u54cd\u5e94\u65f6\u95f4\u6700\u591a\u964d\u4f4e 15%\uff0c\u8d1f\u8f7d\u5747\u8861\u63d0\u9ad8\u7ea6 4 - 5%\uff0c\u603b\u8fd0\u8425\u6210\u672c\u524a\u51cf 10 - 20%\u3002", "conclusion": "TORTA \u80fd\u6709\u6548\u63d0\u5347\u5206\u5e03\u5f0f GPU \u63a8\u7406\u57fa\u7840\u8bbe\u65bd\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2507.09483", "pdf": "https://arxiv.org/pdf/2507.09483", "abs": "https://arxiv.org/abs/2507.09483", "authors": ["Naghmeh Farzi", "Laura Dietz"], "title": "Does UMBRELA Work on Other LLMs?", "categories": ["cs.IR", "H.3.3; I.2.7"], "comment": "9 pages, 2 figures, accepted to SIGIR 2025", "summary": "We reproduce the UMBRELA LLM Judge evaluation framework across a range of\nlarge language models (LLMs) to assess its generalizability beyond the original\nstudy. Our investigation evaluates how LLM choice affects relevance assessment\naccuracy, focusing on leaderboard rank correlation and per-label agreement\nmetrics. Results demonstrate that UMBRELA with DeepSeek V3 obtains very\ncomparable performance to GPT-4o (used in original work). For LLaMA-3.3-70B we\nobtain slightly lower performance, which further degrades with smaller LLMs.", "AI": {"tldr": "\u91cd\u73b0UMBRELA LLM Judge\u8bc4\u4f30\u6846\u67b6\u4ee5\u8bc4\u4f30\u5176\u6cdb\u5316\u6027\uff0c\u7814\u7a76LLM\u9009\u62e9\u5bf9\u76f8\u5173\u6027\u8bc4\u4f30\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0DeepSeek V3\u4e0eGPT - 4o\u6027\u80fd\u76f8\u5f53\uff0cLLaMA - 3.3 - 70B\u7a0d\u4f4e\uff0c\u5c0f\u6a21\u578b\u66f4\u5dee\u3002", "motivation": "\u8bc4\u4f30UMBRELA LLM Judge\u8bc4\u4f30\u6846\u67b6\u5728\u539f\u7814\u7a76\u4e4b\u5916\u7684\u6cdb\u5316\u6027\uff0c\u7814\u7a76LLM\u9009\u62e9\u5bf9\u76f8\u5173\u6027\u8bc4\u4f30\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5728\u4e00\u7cfb\u5217\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u91cd\u73b0UMBRELA LLM Judge\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u6392\u884c\u699c\u6392\u540d\u76f8\u5173\u6027\u548c\u6bcf\u4e2a\u6807\u7b7e\u7684\u4e00\u81f4\u6027\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "UMBRELA\u642d\u914dDeepSeek V3\u4e0eGPT - 4o\u6027\u80fd\u975e\u5e38\u63a5\u8fd1\uff1bLLaMA - 3.3 - 70B\u6027\u80fd\u7a0d\u4f4e\uff1b\u8f83\u5c0f\u7684LLM\u6027\u80fd\u66f4\u5dee\u3002", "conclusion": "\u4e0d\u540c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u642d\u914dUMBRELA\u8bc4\u4f30\u6846\u67b6\u6027\u80fd\u6709\u5dee\u5f02\u3002"}}
{"id": "2507.10448", "pdf": "https://arxiv.org/pdf/2507.10448", "abs": "https://arxiv.org/abs/2507.10448", "authors": ["Yingqian Wu", "Qiushi Wang", "Zefei Long", "Rong Ye", "Zhongtian Lu", "Xianyin Zhang", "Bingxuan Li", "Wei Chen", "Liwen Zhang", "Zhongyu Wei"], "title": "FinTeam: A Multi-Agent Collaborative Intelligence System for Comprehensive Financial Scenarios", "categories": ["cs.CE", "cs.LG"], "comment": "NLPCC 2025 Oral", "summary": "Financial report generation tasks range from macro- to micro-economics\nanalysis, also requiring extensive data analysis. Existing LLM models are\nusually fine-tuned on simple QA tasks and cannot comprehensively analyze real\nfinancial scenarios. Given the complexity, financial companies often distribute\ntasks among departments. Inspired by this, we propose FinTeam, a financial\nmulti-agent collaborative system, with a workflow with four LLM agents:\ndocument analyzer, analyst, accountant, and consultant. We train these agents\nwith specific financial expertise using constructed datasets. We evaluate\nFinTeam on comprehensive financial tasks constructed from real online\ninvestment forums, including macroeconomic, industry, and company analysis. The\nhuman evaluation shows that by combining agents, the financial reports generate\nfrom FinTeam achieved a 62.00% acceptance rate, outperforming baseline models\nlike GPT-4o and Xuanyuan. Additionally, FinTeam's agents demonstrate a 7.43%\naverage improvement on FinCUGE and a 2.06% accuracy boost on FinEval. Project\nis available at https://github.com/FudanDISC/DISC-FinLLM/.", "AI": {"tldr": "\u63d0\u51fa\u91d1\u878d\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edfFinTeam\uff0c\u5728\u7efc\u5408\u91d1\u878d\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709LLM\u6a21\u578b\u65e0\u6cd5\u5168\u9762\u5206\u6790\u771f\u5b9e\u91d1\u878d\u573a\u666f\uff0c\u91d1\u878d\u516c\u53f8\u5e38\u90e8\u95e8\u5206\u5de5\u3002", "method": "\u63d0\u51fa\u542b\u56db\u4e2aLLM\u667a\u80fd\u4f53\u7684FinTeam\u7cfb\u7edf\uff0c\u7528\u6784\u5efa\u6570\u636e\u96c6\u8bad\u7ec3\u7279\u5b9a\u91d1\u878d\u77e5\u8bc6\u3002", "result": "\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u751f\u6210\u62a5\u544a\u63a5\u53d7\u738762%\uff0c\u4f18\u4e8eGPT - 4o\u548c\u8f69\u8f95\u7b49\uff1b\u5728FinCUGE\u548cFinEval\u4e0a\u6709\u63d0\u5347\u3002", "conclusion": "FinTeam\u7cfb\u7edf\u5728\u91d1\u878d\u62a5\u544a\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u6709\u4e00\u5b9a\u4f18\u52bf\u3002"}}
{"id": "2507.10337", "pdf": "https://arxiv.org/pdf/2507.10337", "abs": "https://arxiv.org/abs/2507.10337", "authors": ["Benzhao Tang", "Shiyu Yang", "Zhitao Shen", "Wenjie Zhang", "Xuemin Lin", "Zhihong Tian"], "title": "LogLite: Lightweight Plug-and-Play Streaming Log Compression", "categories": ["cs.DB"], "comment": "accepted by VLDB 2025", "summary": "Log data is a vital resource for capturing system events and states. With the\nincreasing complexity and widespread adoption ofmodern software systems and IoT\ndevices, the daily volume of log generation has surged to tens of petabytes,\nleading to significant collection and storage costs. To address this challenge,\nlossless log compression has emerged as an effective solution, enabling\nsubstantial resource savings without compromising log information. In this\npaper, we first conduct a characterization study on extensive public log\ndatasets and identify four key observations. Building on these insights, we\npropose LogLite, a lightweight, plug-and-play, streaming lossless compression\nalgorithm designed to handle both TEXT and JSON logs throughout their life\ncycle. LogLite requires no predefined rules or pre-training and is inherently\nadaptable to evolving log structures. Our evaluation shows that, compared to\nstate-of-the-art baselines, LogLite achieves Pareto optimality in most\nscenarios, delivering an average improvement of up to 67.8% in compression\nratio and up to 2.7 $\\times$ in compression speed.", "AI": {"tldr": "\u65e5\u5fd7\u6570\u636e\u91cf\u5927\u5bfc\u81f4\u6536\u96c6\u5b58\u50a8\u6210\u672c\u9ad8\uff0c\u672c\u6587\u63d0\u51faLogLite\u65e0\u635f\u538b\u7f29\u7b97\u6cd5\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6709\u663e\u8457\u538b\u7f29\u7387\u548c\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u548c\u7269\u8054\u7f51\u8bbe\u5907\u4ea7\u751f\u7684\u65e5\u5fd7\u6570\u636e\u91cf\u6fc0\u589e\uff0c\u5e26\u6765\u9ad8\u6536\u96c6\u548c\u5b58\u50a8\u6210\u672c\uff0c\u9700\u65e0\u635f\u65e5\u5fd7\u538b\u7f29\u89e3\u51b3\u3002", "method": "\u5148\u5bf9\u5927\u91cf\u516c\u5171\u65e5\u5fd7\u6570\u636e\u96c6\u8fdb\u884c\u7279\u5f81\u7814\u7a76\uff0c\u5f97\u51fa\u56db\u4e2a\u5173\u952e\u89c2\u5bdf\uff0c\u636e\u6b64\u63d0\u51fa\u8f7b\u91cf\u7ea7\u3001\u5373\u63d2\u5373\u7528\u3001\u6d41\u5f0f\u7684\u65e0\u635f\u538b\u7f29\u7b97\u6cd5LogLite\u3002", "result": "\u4e0e\u73b0\u6709\u57fa\u7ebf\u76f8\u6bd4\uff0cLogLite\u5728\u591a\u6570\u573a\u666f\u8fbe\u5230\u5e15\u7d2f\u6258\u6700\u4f18\uff0c\u538b\u7f29\u7387\u5e73\u5747\u63d0\u5347\u8fbe67.8%\uff0c\u538b\u7f29\u901f\u5ea6\u6700\u9ad8\u63d0\u53472.7\u500d\u3002", "conclusion": "LogLite\u662f\u5904\u7406TEXT\u548cJSON\u65e5\u5fd7\u751f\u547d\u5468\u671f\u7684\u6709\u6548\u65e0\u635f\u538b\u7f29\u7b97\u6cd5\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u89c4\u5219\u548c\u9884\u8bad\u7ec3\uff0c\u9002\u5e94\u65e5\u5fd7\u7ed3\u6784\u53d8\u5316\u3002"}}
{"id": "2507.09369", "pdf": "https://arxiv.org/pdf/2507.09369", "abs": "https://arxiv.org/abs/2507.09369", "authors": ["Andrew Critch", "Jacob Tsimerman"], "title": "A Taxonomy of Omnicidal Futures Involving Artificial Intelligence", "categories": ["cs.AI", "68T01", "I.2.0"], "comment": null, "summary": "This report presents a taxonomy and examples of potential omnicidal events\nresulting from AI: scenarios where all or almost all humans are killed. These\nevents are not presented as inevitable, but as possibilities that we can work\nto avoid. Insofar as large institutions require a degree of public support in\norder to take certain actions, we hope that by presenting these possibilities\nin public, we can help to support preventive measures against catastrophic\nrisks from AI.", "AI": {"tldr": "\u62a5\u544a\u63d0\u51faAI\u6f5c\u5728\u706d\u7edd\u4eba\u7c7b\u4e8b\u4ef6\u7684\u5206\u7c7b\u548c\u793a\u4f8b\uff0c\u65e8\u5728\u63a8\u52a8\u9884\u9632\u63aa\u65bd\u3002", "motivation": "\u5e2e\u52a9\u5927\u578b\u673a\u6784\u83b7\u5f97\u516c\u4f17\u652f\u6301\uff0c\u91c7\u53d6\u9488\u5bf9AI\u707e\u96be\u6027\u98ce\u9669\u7684\u9884\u9632\u63aa\u65bd\u3002", "method": "\u63d0\u51faAI\u5bfc\u81f4\u4eba\u7c7b\u706d\u7edd\u4e8b\u4ef6\u7684\u5206\u7c7b\u548c\u793a\u4f8b\u3002", "result": "\u5c55\u793a\u4e86AI\u53ef\u80fd\u5bfc\u81f4\u5168\u4eba\u7c7b\u6216\u51e0\u4e4e\u5168\u4eba\u7c7b\u6b7b\u4ea1\u7684\u60c5\u666f\u3002", "conclusion": "\u8fd9\u4e9b\u60c5\u666f\u867d\u975e\u5fc5\u7136\uff0c\u4f46\u53ef\u901a\u8fc7\u52aa\u529b\u907f\u514d\uff0c\u516c\u5f00\u5448\u73b0\u80fd\u63a8\u52a8\u9884\u9632\u63aa\u65bd\u3002"}}
{"id": "2507.09879", "pdf": "https://arxiv.org/pdf/2507.09879", "abs": "https://arxiv.org/abs/2507.09879", "authors": ["Tanvi Bajpai", "Chandra Chekuri", "Pooja Kulkarni"], "title": "Covering a Few Submodular Constraints and Applications", "categories": ["cs.DS", "cs.AI", "cs.GT"], "comment": "34 pages. Accepted to APPROX 2025", "summary": "We consider the problem of covering multiple submodular constraints. Given a\nfinite ground set $N$, a cost function $c: N \\rightarrow \\mathbb{R}_+$, $r$\nmonotone submodular functions $f_1,f_2,\\ldots,f_r$ over $N$ and requirements\n$b_1,b_2,\\ldots,b_r$ the goal is to find a minimum cost subset $S \\subseteq N$\nsuch that $f_i(S) \\ge b_i$ for $1 \\le i \\le r$. When $r=1$ this is the\nwell-known Submodular Set Cover problem. Previous work\n\\cite{chekuri2022covering} considered the setting when $r$ is large and\ndeveloped bi-criteria approximation algorithms, and approximation algorithms\nfor the important special case when each $f_i$ is a weighted coverage function.\nThese are fairly general models and capture several concrete and interesting\nproblems as special cases. The approximation ratios for these problem are at\nleast $\\Omega(\\log r)$ which is unavoidable when $r$ is part of the input. In\nthis paper, motivated by some recent applications, we consider the problem when\n$r$ is a \\emph{fixed constant} and obtain two main results. For covering\nmultiple submodular constraints we obtain a randomized bi-criteria\napproximation algorithm that for any given integer $\\alpha \\ge 1$ outputs a set\n$S$ such that $f_i(S) \\ge$ $(1-1/e^\\alpha -\\epsilon)b_i$ for each $i \\in [r]$\nand $\\mathbb{E}[c(S)] \\le (1+\\epsilon)\\alpha \\cdot \\sf{OPT}$. Second, when the\n$f_i$ are weighted coverage functions from a deletion-closed set system we\nobtain a $(1+\\epsilon)$ $(\\frac{e}{e-1})$ $(1+\\beta)$-approximation where\n$\\beta$ is the approximation ratio for the underlying set cover instances via\nthe natural LP. These results show that one can obtain nearly as good an\napproximation for any fixed $r$ as what one would achieve for $r=1$. We mention\nsome applications that follow easily from these general results and anticipate\nmore in the future.", "AI": {"tldr": "\u672c\u6587\u8003\u8651r\u4e3a\u56fa\u5b9a\u5e38\u6570\u65f6\u8986\u76d6\u591a\u4e2a\u5b50\u6a21\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u5f97\u5230\u4e24\u4e2a\u4e3b\u8981\u7ed3\u679c\uff0c\u8868\u660e\u56fa\u5b9ar\u65f6\u8fd1\u4f3c\u6548\u679c\u63a5\u8fd1r=1\u7684\u60c5\u51b5\u3002", "motivation": "\u53d7\u8fd1\u671f\u5e94\u7528\u542f\u53d1\uff0c\u7814\u7a76r\u4e3a\u56fa\u5b9a\u5e38\u6570\u65f6\u8986\u76d6\u591a\u4e2a\u5b50\u6a21\u7ea6\u675f\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u968f\u673a\u53cc\u76ee\u6807\u8fd1\u4f3c\u7b97\u6cd5\uff1b\u9488\u5bf9\u52a0\u6743\u8986\u76d6\u51fd\u6570\uff0c\u5229\u7528\u81ea\u7136\u7ebf\u6027\u89c4\u5212\u5f97\u51fa\u8fd1\u4f3c\u7ed3\u679c\u3002", "result": "\u5f97\u5230\u968f\u673a\u53cc\u76ee\u6807\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8f93\u51fa\u96c6\u5408\u6ee1\u8db3\u4e00\u5b9a\u6761\u4ef6\u4e14\u671f\u671b\u6210\u672c\u6709\u754c\uff1b\u52a0\u6743\u8986\u76d6\u51fd\u6570\u65f6\u5f97\u5230\u7279\u5b9a\u8fd1\u4f3c\u6bd4\u3002", "conclusion": "\u56fa\u5b9ar\u65f6\u80fd\u83b7\u5f97\u63a5\u8fd1r=1\u7684\u8fd1\u4f3c\u6548\u679c\uff0c\u8fd8\u63d0\u53ca\u4e00\u4e9b\u5e94\u7528\u5e76\u671f\u5f85\u66f4\u591a\u3002"}}
{"id": "2507.09108", "pdf": "https://arxiv.org/pdf/2507.09108", "abs": "https://arxiv.org/abs/2507.09108", "authors": ["Aaditya Bhatia", "Gustavo A. Oliva", "Gopi Krishnan Rajbahadur", "Haoxiang Zhang", "Yihao Chen", "Zhilong Chen", "Arthur Leung", "Dayi Lin", "Boyuan Chen", "Ahmed E. Hassan"], "title": "SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "High-quality labeled datasets are crucial for training and evaluating\nfoundation models in software engineering, but creating them is often\nprohibitively expensive and labor-intensive. We introduce SPICE, a scalable,\nautomated pipeline for labeling SWE-bench-style datasets with annotations for\nissue clarity, test coverage, and effort estimation. SPICE combines\ncontext-aware code navigation, rationale-driven prompting, and multi-pass\nconsensus to produce labels that closely approximate expert annotations.\nSPICE's design was informed by our own experience and frustration in labeling\nmore than 800 instances from SWE-Gym. SPICE achieves strong agreement with\nhuman-labeled SWE-bench Verified data while reducing the cost of labeling 1,000\ninstances from around $100,000 (manual annotation) to just $5.10. These results\ndemonstrate SPICE's potential to enable cost-effective, large-scale dataset\ncreation for SE-focused FMs. To support the community, we release both SPICE\ntool and SPICE Bench, a new dataset of 6,802 SPICE-labeled instances curated\nfrom 291 open-source projects in SWE-Gym (over 13x larger than SWE-bench\nVerified).", "AI": {"tldr": "\u4ecb\u7ecd\u81ea\u52a8\u5316\u6807\u6ce8\u5de5\u5177SPICE\uff0c\u80fd\u4f4e\u6210\u672c\u6807\u6ce8\u8f6f\u4ef6\u5de5\u7a0b\u6570\u636e\u96c6\uff0c\u8fd8\u53d1\u5e03\u5de5\u5177\u548c\u65b0\u6570\u636e\u96c6\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u7840\u6a21\u578b\u91cd\u8981\uff0c\u4f46\u521b\u5efa\u6210\u672c\u9ad8\u3001\u8017\u4eba\u529b\u3002", "method": "SPICE\u7ed3\u5408\u4e0a\u4e0b\u6587\u4ee3\u7801\u5bfc\u822a\u3001\u63a8\u7406\u9a71\u52a8\u63d0\u793a\u548c\u591a\u8f6e\u5171\u8bc6\u6765\u751f\u6210\u8fd1\u4f3c\u4e13\u5bb6\u6807\u6ce8\u7684\u6807\u7b7e\u3002", "result": "SPICE\u4e0e\u4eba\u5de5\u6807\u6ce8\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5c06\u6807\u6ce81000\u4e2a\u5b9e\u4f8b\u6210\u672c\u4ece\u7ea610\u4e07\u7f8e\u5143\u964d\u81f35.1\u7f8e\u5143\u3002", "conclusion": "SPICE\u6709\u6f5c\u529b\u5b9e\u73b0\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u7840\u6a21\u578b\u7684\u4f4e\u6210\u672c\u3001\u5927\u89c4\u6a21\u6570\u636e\u96c6\u521b\u5efa\u3002"}}
{"id": "2507.08838", "pdf": "https://arxiv.org/pdf/2507.08838", "abs": "https://arxiv.org/abs/2507.08838", "authors": ["Xiaohang Tang", "Rares Dolga", "Sangwoong Yoon", "Ilija Bogunovic"], "title": "wd1: Weighted Policy Optimization for Reasoning in Diffusion Language Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Preprint", "summary": "Improving the reasoning capabilities of diffusion-based large language models\n(dLLMs) through reinforcement learning (RL) remains an open problem. The\nintractability of dLLMs likelihood function necessitates approximating the\ncurrent, old, and reference policy likelihoods at each policy optimization\nstep. This reliance introduces additional computational overhead and lead to\npotentially large bias -- particularly when approximation errors occur in the\ndenominator of policy ratios used for importance sampling. To mitigate these\nissues, we introduce $\\mathtt{wd1}$, a novel policy optimization approach that\nreformulates the objective as a weighted likelihood, requiring only a single\napproximation for the current parametrized policy likelihood. Experiments on\nwidely used reasoning benchmarks demonstrate that $\\mathtt{wd1}$, without\nsupervised fine-tuning (SFT) or any supervised data, outperforms existing RL\nmethods for dLLMs, achieving up to 16% higher accuracy. $\\mathtt{wd1}$ delivers\nadditional computational gains, including reduced training time and fewer\nfunction evaluations (NFEs) per gradient step. These findings, combined with\nthe simplicity of method's implementation and R1-Zero-like training (no SFT),\nposition $\\mathtt{wd1}$ as a more effective and efficient method for applying\nRL to dLLMs reasoning.", "AI": {"tldr": "\u63d0\u51fawd1\u65b9\u6cd5\u4f18\u5316\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u597d\u3001\u6548\u7387\u9ad8\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u63a8\u7406\u80fd\u529b\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u504f\u5dee\u5927\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165wd1\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u5c06\u76ee\u6807\u91cd\u65b0\u8868\u8ff0\u4e3a\u52a0\u6743\u4f3c\u7136\uff0c\u4ec5\u9700\u5bf9\u5f53\u524d\u53c2\u6570\u5316\u7b56\u7565\u4f3c\u7136\u8fdb\u884c\u4e00\u6b21\u8fd1\u4f3c\u3002", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cwd1\u5728\u65e0\u76d1\u7763\u5fae\u8c03\u6216\u76d1\u7763\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u4f18\u4e8e\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534716%\uff0c\u6709\u989d\u5916\u8ba1\u7b97\u6536\u76ca\u3002", "conclusion": "wd1\u662f\u5bf9\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u66f4\u6709\u6548\u548c\u9ad8\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.09317", "pdf": "https://arxiv.org/pdf/2507.09317", "abs": "https://arxiv.org/abs/2507.09317", "authors": ["Sara Si-Moussi", "Esther Galbrun", "Mickael Hedde", "Giovanni Poggiato", "Matthias Rohr", "Wilfried Thuiller"], "title": "Uncovering symmetric and asymmetric species associations from community and environmental data", "categories": ["stat.ML", "cs.LG", "q-bio.PE", "68T07, 62H22, 92D40", "I.2.3; I.2.6; I.5.1"], "comment": null, "summary": "There is no much doubt that biotic interactions shape community assembly and\nultimately the spatial co-variations between species. There is a hope that the\nsignal of these biotic interactions can be observed and retrieved by\ninvestigating the spatial associations between species while accounting for the\ndirect effects of the environment. By definition, biotic interactions can be\nboth symmetric and asymmetric. Yet, most models that attempt to retrieve\nspecies associations from co-occurrence or co-abundance data internally assume\nsymmetric relationships between species. Here, we propose and validate a\nmachine-learning framework able to retrieve bidirectional associations by\nanalyzing species community and environmental data.\n  Our framework (1) models pairwise species associations as directed influences\nfrom a source to a target species, parameterized with two species-specific\nlatent embeddings: the effect of the source species on the community, and the\nresponse of the target species to the community; and (2) jointly fits these\nassociations within a multi-species conditional generative model with different\nmodes of interactions between environmental drivers and biotic associations.\nUsing both simulated and empirical data, we demonstrate the ability of our\nframework to recover known asymmetric and symmetric associations and highlight\nthe properties of the learned association networks. By comparing our approach\nto other existing models such as joint species distribution models and\nprobabilistic graphical models, we show its superior capacity at retrieving\nsymmetric and asymmetric interactions. The framework is intuitive, modular and\nbroadly applicable across various taxonomic groups.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u673a\u5668\u5b66\u4e60\u6846\u67b6\u4ee5\u4ece\u7269\u79cd\u7fa4\u843d\u548c\u73af\u5883\u6570\u636e\u4e2d\u68c0\u7d22\u53cc\u5411\u5173\u8054\uff0c\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u4e14\u9002\u7528\u5e7f\u6cdb\u3002", "motivation": "\u591a\u6570\u6a21\u578b\u5047\u8bbe\u7269\u79cd\u5173\u7cfb\u5bf9\u79f0\uff0c\u800c\u751f\u7269\u76f8\u4e92\u4f5c\u7528\u6709\u5bf9\u79f0\u548c\u4e0d\u5bf9\u79f0\u4e4b\u5206\uff0c\u5e0c\u671b\u4ece\u7269\u79cd\u7a7a\u95f4\u5173\u8054\u4e2d\u89c2\u5bdf\u548c\u68c0\u7d22\u751f\u7269\u76f8\u4e92\u4f5c\u7528\u4fe1\u53f7\u3002", "method": "\u63d0\u51fa\u6846\u67b6\uff0c\u5c06\u6210\u5bf9\u7269\u79cd\u5173\u8054\u5efa\u6a21\u4e3a\u6e90\u7269\u79cd\u5230\u76ee\u6807\u7269\u79cd\u7684\u5b9a\u5411\u5f71\u54cd\uff0c\u5728\u591a\u7269\u79cd\u6761\u4ef6\u751f\u6210\u6a21\u578b\u4e2d\u8054\u5408\u62df\u5408\u8fd9\u4e9b\u5173\u8054\u3002", "result": "\u6846\u67b6\u80fd\u6062\u590d\u5df2\u77e5\u7684\u5bf9\u79f0\u548c\u4e0d\u5bf9\u79f0\u5173\u8054\uff0c\u5bf9\u6bd4\u663e\u793a\u5176\u5728\u68c0\u7d22\u76f8\u4e92\u4f5c\u7528\u4e0a\u80fd\u529b\u66f4\u4f18\u3002", "conclusion": "\u6846\u67b6\u76f4\u89c2\u3001\u6a21\u5757\u5316\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4e0d\u540c\u5206\u7c7b\u7fa4\u3002"}}
{"id": "2507.09407", "pdf": "https://arxiv.org/pdf/2507.09407", "abs": "https://arxiv.org/abs/2507.09407", "authors": ["Quanyan Zhu"], "title": "LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing", "categories": ["cs.AI", "cs.CR", "cs.GT"], "comment": null, "summary": "We introduce the framework of LLM-Stackelberg games, a class of sequential\ndecision-making models that integrate large language models (LLMs) into\nstrategic interactions between a leader and a follower. Departing from\nclassical Stackelberg assumptions of complete information and rational agents,\nour formulation allows each agent to reason through structured prompts,\ngenerate probabilistic behaviors via LLMs, and adapt their strategies through\ninternal cognition and belief updates. We define two equilibrium concepts:\nreasoning and behavioral equilibrium, which aligns an agent's internal\nprompt-based reasoning with observable behavior, and conjectural reasoning\nequilibrium, which accounts for epistemic uncertainty through parameterized\nmodels over an opponent's response. These layered constructs capture bounded\nrationality, asymmetric information, and meta-cognitive adaptation. We\nillustrate the framework through a spearphishing case study, where a sender and\na recipient engage in a deception game using structured reasoning prompts. This\nexample highlights the cognitive richness and adversarial potential of\nLLM-mediated interactions. Our results show that LLM-Stackelberg games provide\na powerful paradigm for modeling decision-making in domains such as\ncybersecurity, misinformation, and recommendation systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdLLM-Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u5b9a\u4e49\u4e24\u79cd\u5747\u8861\u6982\u5ff5\uff0c\u901a\u8fc7\u9493\u9c7c\u90ae\u4ef6\u6848\u4f8b\u8bf4\u660e\u5176\u5728\u7f51\u7edc\u5b89\u5168\u7b49\u9886\u57df\u5efa\u6a21\u51b3\u7b56\u7684\u5f3a\u5927\u80fd\u529b\u3002", "motivation": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5165\u9886\u5bfc\u8005\u4e0e\u8ffd\u968f\u8005\u7684\u6218\u7565\u4e92\u52a8\uff0c\u7a81\u7834\u7ecf\u5178Stackelberg\u535a\u5f08\u5047\u8bbe\uff0c\u5efa\u6a21\u51b3\u7b56\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faLLM-Stackelberg\u535a\u5f08\u6846\u67b6\uff0c\u5b9a\u4e49\u63a8\u7406\u548c\u884c\u4e3a\u5747\u8861\u3001\u731c\u60f3\u63a8\u7406\u5747\u8861\u6982\u5ff5\uff0c\u901a\u8fc7\u9493\u9c7c\u90ae\u4ef6\u6848\u4f8b\u7814\u7a76\u8bf4\u660e\u3002", "result": "LLM-Stackelberg\u535a\u5f08\u6846\u67b6\u5c55\u73b0\u51fa\u8ba4\u77e5\u4e30\u5bcc\u6027\u548c\u5bf9\u6297\u6f5c\u529b\u3002", "conclusion": "LLM-Stackelberg\u535a\u5f08\u4e3a\u7f51\u7edc\u5b89\u5168\u3001\u865a\u5047\u4fe1\u606f\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u9886\u57df\u7684\u51b3\u7b56\u5efa\u6a21\u63d0\u4f9b\u5f3a\u5927\u8303\u5f0f\u3002"}}
{"id": "2507.09488", "pdf": "https://arxiv.org/pdf/2507.09488", "abs": "https://arxiv.org/abs/2507.09488", "authors": ["Naghmeh Farzi", "Laura Dietz"], "title": "Criteria-Based LLM Relevance Judgments", "categories": ["cs.IR", "H.3.3; I.2.7"], "comment": "10 pages, 3 figures, accepted to ICTIR 2025", "summary": "Relevance judgments are crucial for evaluating information retrieval systems,\nbut traditional human-annotated labels are time-consuming and expensive. As a\nresult, many researchers turn to automatic alternatives to accelerate method\ndevelopment. Among these, Large Language Models (LLMs) provide a scalable\nsolution by generating relevance labels directly through prompting. However,\nprompting an LLM for a relevance label without constraints often results in not\nonly incorrect predictions but also outputs that are difficult for humans to\ninterpret. We propose the Multi-Criteria framework for LLM-based relevance\njudgments, decomposing the notion of relevance into multiple criteria--such as\nexactness, coverage, topicality, and contextual fit--to improve the robustness\nand interpretability of retrieval evaluations compared to direct grading\nmethods. We validate this approach on three datasets: the TREC Deep Learning\ntracks from 2019 and 2020, as well as LLMJudge (based on TREC DL 2023). Our\nresults demonstrate that Multi-Criteria judgments enhance the system\nranking/leaderboard performance. Moreover, we highlight the strengths and\nlimitations of this approach relative to direct grading approaches, offering\ninsights that can guide the development of future automatic evaluation\nframeworks in information retrieval.", "AI": {"tldr": "\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u76f8\u5173\u6027\u6807\u7b7e\u8017\u65f6\u4e14\u6602\u8d35\uff0c\u672c\u6587\u63d0\u51fa\u591a\u6807\u51c6\u6846\u67b6\u6539\u8fdb\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u76f8\u5173\u6027\u5224\u65ad\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u80fd\u63d0\u5347\u7cfb\u7edf\u6392\u540d\u6027\u80fd\u5e76\u4e3a\u672a\u6765\u8bc4\u4f30\u6846\u67b6\u53d1\u5c55\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u4f20\u7edf\u4eba\u5de5\u6807\u6ce8\u76f8\u5173\u6027\u6807\u7b7e\u8017\u65f6\u6602\u8d35\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u63d0\u793a\u751f\u6210\u6807\u7b7e\u6709\u7f3a\u9677\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u591a\u6807\u51c6\u6846\u67b6\uff0c\u5c06\u76f8\u5173\u6027\u6982\u5ff5\u5206\u89e3\u4e3a\u591a\u4e2a\u6807\u51c6\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u591a\u6807\u51c6\u5224\u65ad\u80fd\u63d0\u5347\u7cfb\u7edf\u6392\u540d/\u6392\u884c\u699c\u6027\u80fd\u3002", "conclusion": "\u591a\u6807\u51c6\u5224\u65ad\u65b9\u6cd5\u6709\u4f18\u52bf\uff0c\u6307\u51fa\u5176\u4e0e\u76f4\u63a5\u8bc4\u5206\u65b9\u6cd5\u76f8\u6bd4\u7684\u4f18\u7f3a\u70b9\uff0c\u53ef\u4e3a\u672a\u6765\u4fe1\u606f\u68c0\u7d22\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2507.10391", "pdf": "https://arxiv.org/pdf/2507.10391", "abs": "https://arxiv.org/abs/2507.10391", "authors": ["Mihail Stoian", "Johannes Th\u00fcrauf", "Andreas Zimmerer", "Alexander van Renen", "Andreas Kipf"], "title": "Instance-Optimized String Fingerprints", "categories": ["cs.DB"], "comment": "Sixth International Workshop on Applied AI for Database Systems and\n  Applications (AIDB 2025)", "summary": "Recent research found that cloud data warehouses are text-heavy. However,\ntheir capabilities for efficiently processing string columns remain limited,\nrelying primarily on techniques like dictionary encoding and prefix-based\npartition pruning. In recent work, we introduced string fingerprints - a\nlightweight secondary index structure designed to approximate LIKE predicates,\nalbeit with false positives. This approach is particularly compelling for\ncolumnar query engines, where fingerprints can help reduce both compute and I/O\noverhead. We show that string fingerprints can be optimized for specific\nworkloads using mixed-integer optimization, and that they can generalize to\nunseen table predicates. On an IMDb column evaluated in DuckDB v1.3, this\nyields table-scan speedups of up to 1.36$\\times$.", "AI": {"tldr": "\u4e91\u6570\u636e\u4ed3\u5e93\u6587\u672c\u591a\u4f46\u5904\u7406\u5b57\u7b26\u4e32\u5217\u80fd\u529b\u6709\u9650\uff0c\u5f15\u5165\u5b57\u7b26\u4e32\u6307\u7eb9\u53ef\u8fd1\u4f3cLIKE\u8c13\u8bcd\uff0c\u7ecf\u4f18\u5316\u80fd\u52a0\u901f\u8868\u626b\u63cf\u3002", "motivation": "\u4e91\u6570\u636e\u4ed3\u5e93\u5904\u7406\u5b57\u7b26\u4e32\u5217\u80fd\u529b\u6709\u9650\uff0c\u9700\u66f4\u9ad8\u6548\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5b57\u7b26\u4e32\u6307\u7eb9\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u4e8c\u7ea7\u7d22\u5f15\u7ed3\u6784\uff0c\u7528\u6df7\u5408\u6574\u6570\u4f18\u5316\u4e3a\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u4f18\u5316\u6307\u7eb9\u3002", "result": "\u5728DuckDB v1.3\u4e2d\u5bf9IMDb\u5217\u8bc4\u4f30\uff0c\u8868\u626b\u63cf\u901f\u5ea6\u63d0\u5347\u8fbe1.36\u500d\u3002", "conclusion": "\u5b57\u7b26\u4e32\u6307\u7eb9\u53ef\u4f18\u5316\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8868\u8c13\u8bcd\uff0c\u6709\u6548\u63d0\u5347\u8868\u626b\u63cf\u901f\u5ea6\u3002"}}
{"id": "2507.09374", "pdf": "https://arxiv.org/pdf/2507.09374", "abs": "https://arxiv.org/abs/2507.09374", "authors": ["Chenglin Zhu", "Tao Zhang", "Chong Li", "Mingan Lin", "Zenan Zhou", "Jian Xie"], "title": "EduFlow: Advancing MLLMs' Problem-Solving Proficiency through Multi-Stage, Multi-Perspective Critique", "categories": ["cs.AI", "I.2.6; I.2.10"], "comment": "14 pages,4 figures", "summary": "Multimodal large language models (MLLMs) still perform poorly on scientific\ntasks, particularly those requiring multi-step and interpretable reasoning.\nTheir limitations include insufficient scientific reasoning patterns, lack of\nglobal coherence in multi-step inference, and the absence of reflective\nself-correction, making them unreliable in structured scientific contexts. We\nintroduce EduFlow, the first end-to-end framework that covers the full pipeline\nof educational scientific reasoning, including data selection, MCTS-based\ntrajectory construction, model training, and output optimization. At its core\nis EduPRM, a process-aware reward model that critiques reasoning steps with\ntags and justifications. EduPRM is trained via curriculum learning on three\ncomplementary supervision sources: MCTS-guided trajectories, error-injected\ncritiques, and teacher-student dialogues, enabling dynamic adaptation to\nmulti-stage problem solving and iterative refinement during inference. We\nfurther propose EduMCTS, a domain-adapted search framework that introduces\nbootstrapping actions specifically designed for educational reasoning, such as\na self-reflection mechanism that promotes reflective error correction. It\nfurther leverages EduPRM's fine-grained feedback to guide the search toward\nhigher-quality reasoning trajectories. By applying self-consistency and\nrejection sampling, we constructed EduMCTS-160K, a large-scale dataset of\neducational reasoning trajectories. Extensive experiments demonstrate that\nEduFlow enhances reasoning consistency and coherence. Code, data, and models\nwill be released.", "AI": {"tldr": "\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u4efb\u52a1\u63a8\u7406\u4e0d\u8db3\u95ee\u9898\uff0c\u63d0\u51faEduFlow\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u53ef\u63d0\u5347\u63a8\u7406\u4e00\u81f4\u6027\u548c\u8fde\u8d2f\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u5dee\uff0c\u5b58\u5728\u63a8\u7406\u6a21\u5f0f\u4e0d\u8db3\u3001\u7f3a\u4e4f\u5168\u5c40\u8fde\u8d2f\u6027\u548c\u81ea\u6211\u7ea0\u9519\u80fd\u529b\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u7528\u4e8e\u7ed3\u6784\u5316\u79d1\u5b66\u573a\u666f\u3002", "method": "\u5f15\u5165EduFlow\u6846\u67b6\uff0c\u6db5\u76d6\u6570\u636e\u9009\u62e9\u3001\u8f68\u8ff9\u6784\u5efa\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u8f93\u51fa\u4f18\u5316\uff1b\u6838\u5fc3\u662fEduPRM\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u79cd\u76d1\u7763\u6e90\u8fdb\u884c\u8bfe\u7a0b\u5b66\u4e60\uff1b\u63d0\u51faEduMCTS\u641c\u7d22\u6846\u67b6\uff0c\u5f15\u5165\u81ea\u53cd\u601d\u673a\u5236\uff0c\u5229\u7528EduPRM\u53cd\u9988\u5f15\u5bfc\u641c\u7d22\uff1b\u6784\u5efaEduMCTS - 160K\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660eEduFlow\u63d0\u5347\u4e86\u63a8\u7406\u7684\u4e00\u81f4\u6027\u548c\u8fde\u8d2f\u6027\u3002", "conclusion": "EduFlow\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u4efb\u52a1\u63a8\u7406\u65b9\u9762\u7684\u95ee\u9898\uff0c\u4ee3\u7801\u3001\u6570\u636e\u548c\u6a21\u578b\u5c06\u53d1\u5e03\u3002"}}
{"id": "2507.10125", "pdf": "https://arxiv.org/pdf/2507.10125", "abs": "https://arxiv.org/abs/2507.10125", "authors": ["Zeev Nutov"], "title": "Improved bicriteria approximation for $k$-edge-connectivity", "categories": ["cs.DS"], "comment": null, "summary": "In the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a\n(multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost\n$k$-edge-connected spanning subgraph of $G$. The problem admits a\n$2$-approximation algorithm and no better approximation ratio is\nknown.Hershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria\n$(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected\nspanning subgraph of cost at most the optimal value of a standard Cut-LP for\n$k$-ECSS. This LP bicriteria approximation was recently improved by Cohen and\nNutov [ESA 25] to $(1,k-4)$, where also was given a bicriteria approximation\n$(3/2,k-2)$. In this paper we improve the bicriteria approximation to $(1,k-2)$\nfor $k$ even and to $\\left(1-\\frac{1}{k},k-3\\right)$ for $k$ is odd, and also\ngive another bicriteria approximation $(3/2,k-1)$.\n  The $k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost\nthe same as $k$-ECSS, except that any edge can be selected multiple times at\nthe same cost. The previous best approximation ratio for $k$-ECSM was $1+4/k$.\nOur result improves this to $1+\\frac{2}{k}$ for $k$ even and to $1+\\frac{3}{k}$\nfor $k$ odd, where for $k$ odd the computed subgraph is in fact\n$(k+1)$-edge-connected.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86k - ECSS\u548ck - ECSM\u95ee\u9898\u7684\u53cc\u51c6\u5219\u8fd1\u4f3c\u7b97\u6cd5\u3002\u5bf9\u4e8ek - ECSS\uff0c\u6539\u8fdb\u4e86\u53cc\u51c6\u5219\u8fd1\u4f3c\uff1b\u5bf9\u4e8ek - ECSM\uff0c\u63d0\u5347\u4e86\u8fd1\u4f3c\u6bd4\u7387\u3002", "motivation": "\u73b0\u6709k - ECSS\u548ck - ECSM\u95ee\u9898\u7684\u8fd1\u4f3c\u7b97\u6cd5\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u671f\u671b\u5f97\u5230\u66f4\u597d\u7684\u8fd1\u4f3c\u7ed3\u679c\u3002", "method": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u65b9\u6cd5\uff0c\u53ef\u80fd\u57fa\u4e8e\u524d\u4eba\u7b97\u6cd5\u6539\u8fdb\u3002", "result": "\u5bf9\u4e8ek - ECSS\uff0ck\u4e3a\u5076\u6570\u65f6\u53cc\u51c6\u5219\u8fd1\u4f3c\u6539\u8fdb\u5230(1,k - 2)\uff0ck\u4e3a\u5947\u6570\u65f6\u5230(1 - 1/k,k - 3)\uff0c\u8fd8\u6709(3/2,k - 1)\uff1b\u5bf9\u4e8ek - ECSM\uff0ck\u4e3a\u5076\u6570\u65f6\u8fd1\u4f3c\u6bd4\u7387\u6539\u8fdb\u52301 + 2/k\uff0ck\u4e3a\u5947\u6570\u65f6\u52301 + 3/k\u4e14k\u4e3a\u5947\u6570\u65f6\u5b50\u56fe\u662f(k + 1)\u8fb9\u8fde\u901a\u7684\u3002", "conclusion": "\u672c\u6587\u7b97\u6cd5\u5728k - ECSS\u548ck - ECSM\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u6bd4\u524d\u4eba\u66f4\u597d\u7684\u8fd1\u4f3c\u7ed3\u679c\u3002"}}
{"id": "2507.09135", "pdf": "https://arxiv.org/pdf/2507.09135", "abs": "https://arxiv.org/abs/2507.09135", "authors": ["Yalong Du", "Chaozheng Wang", "Huaijin Wang"], "title": "Position Paper: Programming Language Techniques for Bridging LLM Code Generation Semantic Gaps", "categories": ["cs.SE"], "comment": null, "summary": "Large Language Models have demonstrated remarkable capabilities in automated\ncode generation, yet their statistical nature and black-box characteristics\ncreate significant semantic gaps manifested through syntax errors, semantic\nhallucinations, and reliability concerns. This position paper argues that\nprincipled integration of Programming Language (PL) techniques is essential for\nbridging these gaps. Through structured program representations, formal\ncorrectness guarantees, and robust verification mechanisms, PL techniques can\nelevate LLM-generated code from statistical pattern matching to truly reliable\nand trustworthy levels. This integration is crucial for developing systems that\ngenerate code that is not only functionally correct but also interpretable,\nverifiable, and ultimately trustworthy.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u6709\u7f3a\u9677\uff0c\u9700\u7ed3\u5408\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\u5f25\u8865\u5dee\u8ddd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u5b58\u5728\u8bed\u4e49\u5dee\u8ddd\u3001\u53ef\u9760\u6027\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7ed3\u6784\u5316\u7a0b\u5e8f\u8868\u793a\u3001\u5f62\u5f0f\u6b63\u786e\u6027\u4fdd\u8bc1\u548c\u5f3a\u5927\u9a8c\u8bc1\u673a\u5236\uff0c\u5c06\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u7ed3\u5408\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\u5bf9\u5f00\u53d1\u529f\u80fd\u6b63\u786e\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u9a8c\u8bc1\u548c\u503c\u5f97\u4fe1\u8d56\u7684\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.08839", "pdf": "https://arxiv.org/pdf/2507.08839", "abs": "https://arxiv.org/abs/2507.08839", "authors": ["Xiaowei Yu", "Jing Zhang", "Tong Chen", "Yan Zhuang", "Minheng Chen", "Chao Cao", "Yanjun Lyu", "Lu Zhang", "Li Su", "Tianming Liu", "Dajiang Zhu"], "title": "Domain-Adaptive Diagnosis of Lewy Body Disease with Transferability Aware Transformer", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": "MICCAI 2025", "summary": "Lewy Body Disease (LBD) is a common yet understudied form of dementia that\nimposes a significant burden on public health. It shares clinical similarities\nwith Alzheimer's disease (AD), as both progress through stages of normal\ncognition, mild cognitive impairment, and dementia. A major obstacle in LBD\ndiagnosis is data scarcity, which limits the effectiveness of deep learning. In\ncontrast, AD datasets are more abundant, offering potential for knowledge\ntransfer. However, LBD and AD data are typically collected from different sites\nusing different machines and protocols, resulting in a distinct domain shift.\nTo effectively leverage AD data while mitigating domain shift, we propose a\nTransferability Aware Transformer (TAT) that adapts knowledge from AD to\nenhance LBD diagnosis. Our method utilizes structural connectivity (SC) derived\nfrom structural MRI as training data. Built on the attention mechanism, TAT\nadaptively assigns greater weights to disease-transferable features while\nsuppressing domain-specific ones, thereby reducing domain shift and improving\ndiagnostic accuracy with limited LBD data. The experimental results demonstrate\nthe effectiveness of TAT. To the best of our knowledge, this is the first study\nto explore domain adaptation from AD to LBD under conditions of data scarcity\nand domain shift, providing a promising framework for domain-adaptive diagnosis\nof rare diseases.", "AI": {"tldr": "\u9488\u5bf9\u8def\u6613\u4f53\u75f4\u5446\uff08LBD\uff09\u8bca\u65ad\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u51fa\u53ef\u8f6c\u79fb\u611f\u77e5\u53d8\u538b\u5668\uff08TAT\uff09\u65b9\u6cd5\uff0c\u5229\u7528AD\u6570\u636e\u63d0\u5347LBD\u8bca\u65ad\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u3002", "motivation": "LBD\u8bca\u65ad\u6570\u636e\u7a00\u7f3a\u9650\u5236\u6df1\u5ea6\u5b66\u4e60\u6548\u679c\uff0cAD\u6570\u636e\u4e30\u5bcc\u4f46\u4e24\u8005\u5b58\u5728\u9886\u57df\u5dee\u5f02\uff0c\u9700\u6709\u6548\u5229\u7528AD\u6570\u636e\u540c\u65f6\u7f13\u89e3\u9886\u57df\u504f\u79fb\u4ee5\u63d0\u5347LBD\u8bca\u65ad\u3002", "method": "\u63d0\u51faTAT\u65b9\u6cd5\uff0c\u5229\u7528\u7ed3\u6784\u78c1\u5171\u632f\u6210\u50cf\u7684\u7ed3\u6784\u8fde\u63a5\u6027\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\uff0c\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u81ea\u9002\u5e94\u5206\u914d\u6743\u91cd\uff0c\u51cf\u5c11\u9886\u57df\u504f\u79fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86TAT\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5728\u6570\u636e\u7a00\u7f3a\u548c\u9886\u57df\u504f\u79fb\u6761\u4ef6\u4e0b\u63a2\u7d22\u4eceAD\u5230LBD\u7684\u9886\u57df\u81ea\u9002\u5e94\uff0c\u4e3a\u7f55\u89c1\u75c5\u9886\u57df\u81ea\u9002\u5e94\u8bca\u65ad\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6846\u67b6\u3002"}}
{"id": "2507.09494", "pdf": "https://arxiv.org/pdf/2507.09494", "abs": "https://arxiv.org/abs/2507.09494", "authors": ["Albert Chiu"], "title": "An Algorithm for Identifying Interpretable Subgroups With Elevated Treatment Effects", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.ME"], "comment": null, "summary": "We introduce an algorithm for identifying interpretable subgroups with\nelevated treatment effects, given an estimate of individual or conditional\naverage treatment effects (CATE). Subgroups are characterized by ``rule sets''\n-- easy-to-understand statements of the form (Condition A AND Condition B) OR\n(Condition C) -- which can capture high-order interactions while retaining\ninterpretability. Our method complements existing approaches for estimating the\nCATE, which often produce high dimensional and uninterpretable results, by\nsummarizing and extracting critical information from fitted models to aid\ndecision making, policy implementation, and scientific understanding. We\npropose an objective function that trades-off subgroup size and effect size,\nand varying the hyperparameter that controls this trade-off results in a\n``frontier'' of Pareto optimal rule sets, none of which dominates the others\nacross all criteria. Valid inference is achievable through sample splitting. We\ndemonstrate the utility and limitations of our method using simulated and\nempirical examples.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e00\u79cd\u7b97\u6cd5\uff0c\u5728\u7ed9\u5b9a\u4e2a\u4f53\u6216\u6761\u4ef6\u5e73\u5747\u6cbb\u7597\u6548\u679c\uff08CATE\uff09\u4f30\u8ba1\u7684\u60c5\u51b5\u4e0b\uff0c\u8bc6\u522b\u5177\u6709\u663e\u8457\u6cbb\u7597\u6548\u679c\u7684\u53ef\u89e3\u91ca\u5b50\u7ec4\u3002", "motivation": "\u73b0\u6709\u4f30\u8ba1CATE\u7684\u65b9\u6cd5\u5e38\u4ea7\u751f\u9ad8\u7ef4\u4e14\u96be\u4ee5\u89e3\u91ca\u7684\u7ed3\u679c\uff0c\u672c\u6587\u65e8\u5728\u603b\u7ed3\u548c\u63d0\u53d6\u62df\u5408\u6a21\u578b\u4e2d\u7684\u5173\u952e\u4fe1\u606f\uff0c\u4ee5\u8f85\u52a9\u51b3\u7b56\u3001\u653f\u7b56\u5b9e\u65bd\u548c\u79d1\u5b66\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6743\u8861\u5b50\u7ec4\u89c4\u6a21\u548c\u6548\u679c\u5927\u5c0f\u7684\u76ee\u6807\u51fd\u6570\uff0c\u901a\u8fc7\u6539\u53d8\u63a7\u5236\u8be5\u6743\u8861\u7684\u8d85\u53c2\u6570\u5f97\u5230\u5e15\u7d2f\u6258\u6700\u4f18\u89c4\u5219\u96c6\u7684\u201c\u524d\u6cbf\u201d\uff0c\u5e76\u901a\u8fc7\u6837\u672c\u5206\u5272\u5b9e\u73b0\u6709\u6548\u63a8\u65ad\u3002", "result": "\u5229\u7528\u6a21\u62df\u548c\u5b9e\u8bc1\u4f8b\u5b50\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u53ef\u5728\u4f30\u8ba1CATE\u65f6\u8bc6\u522b\u53ef\u89e3\u91ca\u5b50\u7ec4\uff0c\u4f46\u6709\u4e00\u5b9a\u5c40\u9650\u6027\u3002"}}
{"id": "2507.10392", "pdf": "https://arxiv.org/pdf/2507.10392", "abs": "https://arxiv.org/abs/2507.10392", "authors": ["Runsheng Benson Guo", "Utkarsh Anand", "Khuzaima Daudjee", "Rathijit Sen"], "title": "Zorse: Optimizing LLM Training Efficiency on Heterogeneous GPU Clusters", "categories": ["cs.DC"], "comment": null, "summary": "Large language models (LLMs) require vast amounts of GPU compute to train,\nbut limited availability and high costs of GPUs make homogeneous clusters\nimpractical for many organizations. Instead, assembling heterogeneous clusters\nby pooling together GPUs of different generations allows them to achieve higher\naggregate compute and make use of all available GPUs. However, training on\nheterogeneous clusters presents several challenges, including load balancing\nacross GPUs, optimizing memory usage to accommodate varying memory capacities,\nand ensuring communication-efficient training over diverse network\ninterconnects potentially spanning multiple datacenters. In this paper, we make\nthe case that efficient training on heterogeneous clusters requires (1) the\nintegration of pipeline parallelism and data parallelism in a manner that is\nboth communication- and memory-efficient, and (2) a more adaptable\nconfiguration of pipeline and data parallelism, which includes the capability\nto flexibly partition GPUs into asymmetric pipeline parallel stages and to\nincorporate heterogeneous GPUs within the same data parallelism group. We\npropose Zorse, the first system to unify all these capabilities while\nincorporating a planner that automatically configures training strategies for a\ngiven workload. Our evaluation shows that Zorse significantly outperforms\nstate-of-the-art systems in heterogeneous training scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faZorse\u7cfb\u7edf\uff0c\u7edf\u4e00\u591a\u79cd\u80fd\u529b\u5e76\u81ea\u52a8\u914d\u7f6e\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u5f02\u6784\u8bad\u7ec3\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "GPU\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u4e14\u6210\u672c\u9ad8\uff0c\u5f02\u6784\u96c6\u7fa4\u867d\u80fd\u63d0\u9ad8\u8ba1\u7b97\u80fd\u529b\u4f46\u8bad\u7ec3\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u9700\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u63d0\u51faZorse\u7cfb\u7edf\uff0c\u96c6\u6210\u901a\u4fe1\u548c\u5185\u5b58\u9ad8\u6548\u7684\u6d41\u6c34\u7ebf\u5e76\u884c\u4e0e\u6570\u636e\u5e76\u884c\uff0c\u91c7\u7528\u66f4\u7075\u6d3b\u7684\u5e76\u884c\u914d\u7f6e\uff0c\u5e76\u52a0\u5165\u81ea\u52a8\u914d\u7f6e\u8bad\u7ec3\u7b56\u7565\u7684\u89c4\u5212\u5668\u3002", "result": "\u8bc4\u4f30\u663e\u793aZorse\u5728\u5f02\u6784\u8bad\u7ec3\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "conclusion": "Zorse\u7cfb\u7edf\u80fd\u6709\u6548\u89e3\u51b3\u5f02\u6784\u96c6\u7fa4\u8bad\u7ec3\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u3002"}}
{"id": "2507.09566", "pdf": "https://arxiv.org/pdf/2507.09566", "abs": "https://arxiv.org/abs/2507.09566", "authors": ["Timo Wilm", "Philipp Normann"], "title": "Identifying Offline Metrics that Predict Online Impact: A Pragmatic Strategy for Real-World Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "This work was accepted for publication in the 19th ACM Conference on\n  Recommender Systems (RecSys 2025). The final published version will be\n  available at the ACM Digital Library", "summary": "A critical challenge in recommender systems is to establish reliable\nrelationships between offline and online metrics that predict real-world\nperformance. Motivated by recent advances in Pareto front approximation, we\nintroduce a pragmatic strategy for identifying offline metrics that align with\nonline impact. A key advantage of this approach is its ability to\nsimultaneously serve multiple test groups, each with distinct offline\nperformance metrics, in an online experiment controlled by a single model. The\nmethod is model-agnostic for systems with a neural network backbone, enabling\nbroad applicability across architectures and domains. We validate the strategy\nthrough a large-scale online experiment in the field of session-based\nrecommender systems on the OTTO e-commerce platform. The online experiment\nidentifies significant alignments between offline metrics and real-word\nclick-through rate, post-click conversion rate and units sold. Our strategy\nprovides industry practitioners with a valuable tool for understanding\noffline-to-online metric relationships and making informed, data-driven\ndecisions.", "AI": {"tldr": "\u5f15\u5165\u5b9e\u7528\u7b56\u7565\u8bc6\u522b\u4e0e\u5728\u7ebf\u5f71\u54cd\u4e00\u81f4\u7684\u79bb\u7ebf\u6307\u6807\uff0c\u5728OTTO\u5e73\u53f0\u9a8c\u8bc1\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u7406\u89e3\u79bb\u7ebf\u5230\u5728\u7ebf\u6307\u6807\u5173\u7cfb\u7684\u5de5\u5177\u3002", "motivation": "\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u5efa\u7acb\u79bb\u7ebf\u548c\u5728\u7ebf\u6307\u6807\u53ef\u9760\u5173\u7cfb\u4ee5\u9884\u6d4b\u73b0\u5b9e\u6027\u80fd\u7684\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u5e15\u7d2f\u6258\u524d\u6cbf\u8fd1\u4f3c\uff0c\u63d0\u51fa\u5b9e\u7528\u7b56\u7565\uff0c\u80fd\u670d\u52a1\u591a\u6d4b\u8bd5\u7ec4\uff0c\u4e14\u5bf9\u6709\u795e\u7ecf\u7f51\u7edc\u9aa8\u5e72\u7684\u7cfb\u7edf\u6a21\u578b\u65e0\u5173\u3002", "result": "\u5728OTTO\u5e73\u53f0\u7684\u4f1a\u8bdd\u63a8\u8350\u7cfb\u7edf\u5927\u89c4\u6a21\u5728\u7ebf\u5b9e\u9a8c\u4e2d\uff0c\u53d1\u73b0\u79bb\u7ebf\u6307\u6807\u4e0e\u73b0\u5b9e\u70b9\u51fb\u7387\u3001\u70b9\u51fb\u540e\u8f6c\u5316\u7387\u548c\u9500\u552e\u91cf\u6709\u663e\u8457\u5173\u8054\u3002", "conclusion": "\u8be5\u7b56\u7565\u4e3a\u884c\u4e1a\u4ece\u4e1a\u8005\u63d0\u4f9b\u7406\u89e3\u79bb\u7ebf\u5230\u5728\u7ebf\u6307\u6807\u5173\u7cfb\u3001\u505a\u51fa\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u7684\u6709\u4ef7\u503c\u5de5\u5177\u3002"}}
{"id": "2507.09443", "pdf": "https://arxiv.org/pdf/2507.09443", "abs": "https://arxiv.org/abs/2507.09443", "authors": ["Luiz Aldeia Machado", "Victor Coppo Leite", "Elia Merzari", "Arthur Motta", "Roberto Ponciroli", "Lander Ibarra", "Lise Charlot"], "title": "Toward Developing Machine-Learning-Aided Tools for the Thermomechanical Monitoring of Nuclear Reactor Components", "categories": ["cs.LG", "cs.CE"], "comment": "Preprint - Nureth 21 paper", "summary": "Proactive maintenance strategies, such as Predictive Maintenance (PdM), play\nan important role in the operation of Nuclear Power Plants (NPPs), particularly\ndue to their capacity to reduce offline time by preventing unexpected shutdowns\ncaused by component failures.\n  In this work, we explore the use of a Convolutional Neural Network (CNN)\narchitecture combined with a computational thermomechanical model to calculate\nthe temperature, stress, and strain of a Pressurized Water Reactor (PWR) fuel\nrod during operation. This estimation relies on a limited number of temperature\nmeasurements from the cladding's outer surface. This methodology can\npotentially aid in developing PdM tools for nuclear reactors by enabling\nreal-time monitoring of such systems.\n  The training, validation, and testing datasets were generated through coupled\nsimulations involving BISON, a finite element-based nuclear fuel performance\ncode, and the MOOSE Thermal-Hydraulics Module (MOOSE-THM). We conducted eleven\nsimulations, varying the peak linear heat generation rates. Of these, eight\nwere used for training, two for validation, and one for testing.\n  The CNN was trained for over 1,000 epochs without signs of overfitting,\nachieving highly accurate temperature distribution predictions. These were then\nused in a thermomechanical model to determine the stress and strain\ndistribution within the fuel rod.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528CNN\u7ed3\u5408\u70ed\u673a\u68b0\u6a21\u578b\uff0c\u57fa\u4e8e\u5c11\u91cf\u6e29\u5ea6\u6d4b\u91cf\u4f30\u7b97\u538b\u6c34\u5806\u71c3\u6599\u68d2\u8fd0\u884c\u65f6\u7684\u6e29\u5ea6\u3001\u5e94\u529b\u548c\u5e94\u53d8\uff0c\u52a9\u529b\u6838\u53cd\u5e94\u5806\u9884\u6d4b\u6027\u7ef4\u62a4\u3002", "motivation": "\u4e3b\u52a8\u7ef4\u62a4\u7b56\u7565\uff08\u5982\u9884\u6d4b\u6027\u7ef4\u62a4\uff09\u53ef\u51cf\u5c11\u6838\u7535\u7ad9\u56e0\u7ec4\u4ef6\u6545\u969c\u5bfc\u81f4\u7684\u610f\u5916\u505c\u673a\u65f6\u95f4\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u6838\u53cd\u5e94\u5806\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u5de5\u5177\u3002", "method": "\u91c7\u7528CNN\u67b6\u6784\u7ed3\u5408\u70ed\u673a\u68b0\u6a21\u578b\uff0c\u5229\u7528BISON\u548cMOOSE - THM\u8fdb\u884c\u8026\u5408\u6a21\u62df\u751f\u6210\u8bad\u7ec3\u3001\u9a8c\u8bc1\u548c\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u6539\u53d8\u5cf0\u503c\u7ebf\u6027\u70ed\u751f\u6210\u7387\u8fdb\u884c11\u6b21\u6a21\u62df\u3002", "result": "CNN\u8bad\u7ec3\u8d851000\u4e2a\u5468\u671f\u65e0\u8fc7\u62df\u5408\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u6e29\u5ea6\u5206\u5e03\u9884\u6d4b\uff0c\u5e76\u7528\u4e8e\u70ed\u673a\u68b0\u6a21\u578b\u786e\u5b9a\u71c3\u6599\u68d2\u5185\u5e94\u529b\u548c\u5e94\u53d8\u5206\u5e03\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u5b9e\u73b0\u6838\u53cd\u5e94\u5806\u7cfb\u7edf\u7684\u5b9e\u65f6\u76d1\u6d4b\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u6838\u53cd\u5e94\u5806\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u5de5\u5177\u3002"}}
{"id": "2507.09389", "pdf": "https://arxiv.org/pdf/2507.09389", "abs": "https://arxiv.org/abs/2507.09389", "authors": ["Chris Davis Jaldi", "Anmol Saini", "Elham Ghiasi", "O. Divine Eziolise", "Cogan Shimizu"], "title": "Knowledge Conceptualization Impacts RAG Efficacy", "categories": ["cs.AI", "cs.CY", "cs.IR"], "comment": null, "summary": "Explainability and interpretability are cornerstones of frontier and\nnext-generation artificial intelligence (AI) systems. This is especially true\nin recent systems, such as large language models (LLMs), and more broadly,\ngenerative AI. On the other hand, adaptability to new domains, contexts, or\nscenarios is also an important aspect for a successful system. As such, we are\nparticularly interested in how we can merge these two efforts, that is,\ninvestigating the design of transferable and interpretable neurosymbolic AI\nsystems. Specifically, we focus on a class of systems referred to as ''Agentic\nRetrieval-Augmented Generation'' systems, which actively select, interpret, and\nquery knowledge sources in response to natural language prompts. In this paper,\nwe systematically evaluate how different conceptualizations and representations\nof knowledge, particularly the structure and complexity, impact an AI agent (in\nthis case, an LLM) in effectively querying a triplestore. We report our\nresults, which show that there are impacts from both approaches, and we discuss\ntheir impact and implications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u53ef\u8fc1\u79fb\u4e14\u53ef\u89e3\u91ca\u7684\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u805a\u7126Agentic Retrieval - Augmented Generation\u7cfb\u7edf\uff0c\u8bc4\u4f30\u77e5\u8bc6\u7684\u4e0d\u540c\u6982\u5ff5\u5316\u548c\u8868\u793a\u5bf9AI\u67e5\u8be2\u4e09\u5143\u7ec4\u5b58\u50a8\u7684\u5f71\u54cd\u5e76\u62a5\u544a\u7ed3\u679c\u3002", "motivation": "\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u65b0\u9886\u57df\u7684\u9002\u5e94\u6027\u662f\u6210\u529fAI\u7cfb\u7edf\u7684\u91cd\u8981\u65b9\u9762\uff0c\u56e0\u6b64\u5e0c\u671b\u7814\u7a76\u5982\u4f55\u5c06\u4e24\u8005\u7ed3\u5408\uff0c\u8bbe\u8ba1\u53ef\u8fc1\u79fb\u4e14\u53ef\u89e3\u91ca\u7684\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u3002", "method": "\u7cfb\u7edf\u5730\u8bc4\u4f30\u77e5\u8bc6\u7684\u4e0d\u540c\u6982\u5ff5\u5316\u548c\u8868\u793a\uff08\u7279\u522b\u662f\u7ed3\u6784\u548c\u590d\u6742\u6027\uff09\u5bf9AI\u4ee3\u7406\uff08\u5982\u5927\u8bed\u8a00\u6a21\u578b\uff09\u6709\u6548\u67e5\u8be2\u4e09\u5143\u7ec4\u5b58\u50a8\u7684\u5f71\u54cd\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\uff08\u4e0d\u540c\u6982\u5ff5\u5316\u548c\u8868\u793a\uff09\u5bf9AI\u67e5\u8be2\u4e09\u5143\u7ec4\u5b58\u50a8\u90fd\u6709\u5f71\u54cd\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u4e0d\u540c\u77e5\u8bc6\u8868\u793a\u5bf9AI\u67e5\u8be2\u7684\u5f71\u54cd\u53ca\u76f8\u5173\u610f\u4e49\u3002"}}
{"id": "2507.10052", "pdf": "https://arxiv.org/pdf/2507.10052", "abs": "https://arxiv.org/abs/2507.10052", "authors": ["Huisheng Wang", "H. Vicky Zhao"], "title": "Analyzing the Crowding-Out Effect of Investment Herding on Consumption: An Optimal Control Theory Approach", "categories": ["q-fin.PM", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC", "q-fin.MF"], "comment": null, "summary": "Investment herding, a phenomenon where households mimic the decisions of\nothers rather than relying on their own analysis, has significant effects on\nfinancial markets and household behavior. Excessive investment herding may\nreduce investments and lead to a depletion of household consumption, which is\ncalled the crowding-out effect. While existing research has qualitatively\nexamined the impact of investment herding on consumption, quantitative studies\nin this area remain limited. In this work, we investigate the optimal\ninvestment and consumption decisions of households under the impact of\ninvestment herding. We formulate an optimization problem to model how\ninvestment herding influences household decisions over time. Based on the\noptimal control theory, we solve for the analytical solutions of optimal\ninvestment and consumption decisions. We theoretically analyze the impact of\ninvestment herding on household consumption decisions and demonstrate the\nexistence of the crowding-out effect. We further explore how parameters, such\nas interest rate, excess return rate, and volatility, influence the\ncrowding-out effect. Finally, we conduct a real data test to validate our\ntheoretical analysis of the crowding-out effect. This study is crucial to\nunderstanding the impact of investment herding on household consumption and\noffering valuable insights for policymakers seeking to stimulate consumption\nand mitigate the negative effects of investment herding on economic growth.", "AI": {"tldr": "\u7814\u7a76\u6295\u8d44\u7f8a\u7fa4\u6548\u5e94\u4e0b\u5bb6\u5ead\u6700\u4f18\u6295\u8d44\u548c\u6d88\u8d39\u51b3\u7b56\uff0c\u7406\u8bba\u5206\u6790\u5e76\u5b9e\u8bc1\u9a8c\u8bc1\u6324\u51fa\u6548\u5e94\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u6295\u8d44\u7f8a\u7fa4\u6548\u5e94\u5f71\u54cd\u6d88\u8d39\u7684\u5b9a\u91cf\u7814\u7a76\u6709\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u63a2\u7a76\u5176\u5bf9\u5bb6\u5ead\u51b3\u7b56\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4f18\u5316\u95ee\u9898\uff0c\u57fa\u4e8e\u6700\u4f18\u63a7\u5236\u7406\u8bba\u6c42\u89e3\u6700\u4f18\u6295\u8d44\u548c\u6d88\u8d39\u51b3\u7b56\u7684\u89e3\u6790\u89e3\uff0c\u8fdb\u884c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u6570\u636e\u6d4b\u8bd5\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u6324\u51fa\u6548\u5e94\u7684\u5b58\u5728\uff0c\u63a2\u7d22\u4e86\u53c2\u6570\u5bf9\u6324\u51fa\u6548\u5e94\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u7406\u8bba\u5206\u6790\u3002", "conclusion": "\u672c\u7814\u7a76\u6709\u52a9\u4e8e\u7406\u89e3\u6295\u8d44\u7f8a\u7fa4\u6548\u5e94\u5bf9\u5bb6\u5ead\u6d88\u8d39\u7684\u5f71\u54cd\uff0c\u4e3a\u523a\u6fc0\u6d88\u8d39\u548c\u51cf\u8f7b\u5176\u5bf9\u7ecf\u6d4e\u589e\u957f\u8d1f\u9762\u5f71\u54cd\u7684\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.10248", "pdf": "https://arxiv.org/pdf/2507.10248", "abs": "https://arxiv.org/abs/2507.10248", "authors": ["Moran Feldman", "Alan Kuhnle"], "title": "Bicriteria Submodular Maximization", "categories": ["cs.DS", "cs.DM", "68R05 (Primary) 68W25, 90C26 (Secondary)", "F.2.2; G.2.1"], "comment": "75 pages, 1 figure", "summary": "Submodular functions and their optimization have found applications in\ndiverse settings ranging from machine learning and data mining to game theory\nand economics. In this work, we consider the constrained maximization of a\nsubmodular function, for which we conduct a principled study of bicriteria\napproximation algorithms -- algorithms which can violate the constraint, but\nonly up to a bounded factor. Bicrteria optimization allows constrained\nsubmodular maximization to capture additional important settings, such as the\nwell-studied submodular cover problem and optimization under soft constraints.\nWe provide results that span both multiple types of constraints (cardinality,\nknapsack, matroid and convex set) and multiple classes of submodular functions\n(monotone, symmetric and general). For many of the cases considered, we provide\noptimal results. In other cases, our results improve over the state-of-the-art,\nsometimes even over the state-of-the-art for the special case of\nsingle-criterion (standard) optimization. Results of the last kind demonstrate\nthat relaxing the feasibility constraint may give a perspective about the\nproblem that is useful even if one only desires feasible solutions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5b50\u6a21\u51fd\u6570\u7684\u7ea6\u675f\u6700\u5927\u5316\u95ee\u9898\uff0c\u7ed9\u51fa\u591a\u7c7b\u7ea6\u675f\u548c\u5b50\u6a21\u51fd\u6570\u7684\u53cc\u51c6\u5219\u8fd1\u4f3c\u7b97\u6cd5\u7ed3\u679c\uff0c\u90e8\u5206\u4e3a\u6700\u4f18\uff0c\u90e8\u5206\u6539\u8fdb\u4e86\u73b0\u6709\u6c34\u5e73\u3002", "motivation": "\u5b50\u6a21\u51fd\u6570\u4f18\u5316\u5e94\u7528\u5e7f\u6cdb\uff0c\u53cc\u51c6\u5219\u4f18\u5316\u53ef\u6db5\u76d6\u66f4\u591a\u91cd\u8981\u573a\u666f\uff0c\u5982\u5b50\u6a21\u8986\u76d6\u95ee\u9898\u548c\u8f6f\u7ea6\u675f\u4e0b\u7684\u4f18\u5316\u3002", "method": "\u5bf9\u7ea6\u675f\u5b50\u6a21\u51fd\u6570\u6700\u5927\u5316\u95ee\u9898\u8fdb\u884c\u53cc\u51c6\u5219\u8fd1\u4f3c\u7b97\u6cd5\u7684\u539f\u7406\u6027\u7814\u7a76\u3002", "result": "\u7ed9\u51fa\u591a\u79cd\u7ea6\u675f\uff08\u57fa\u6570\u3001\u80cc\u5305\u3001\u62df\u9635\u548c\u51f8\u96c6\uff09\u548c\u591a\u7c7b\u5b50\u6a21\u51fd\u6570\uff08\u5355\u8c03\u3001\u5bf9\u79f0\u548c\u4e00\u822c\uff09\u7684\u7ed3\u679c\uff0c\u90e8\u5206\u4e3a\u6700\u4f18\uff0c\u90e8\u5206\u6539\u8fdb\u73b0\u6709\u6c34\u5e73\u3002", "conclusion": "\u653e\u677e\u53ef\u884c\u6027\u7ea6\u675f\u5bf9\u4ec5\u9700\u53ef\u884c\u89e3\u7684\u95ee\u9898\u4e5f\u6709\u5e2e\u52a9\uff0c\u80fd\u63d0\u4f9b\u6709\u7528\u89c6\u89d2\u3002"}}
{"id": "2507.09186", "pdf": "https://arxiv.org/pdf/2507.09186", "abs": "https://arxiv.org/abs/2507.09186", "authors": ["Minhaj Uddin Ahmad", "Akid Abrar", "Sagar Dasgupta", "Mizanur Rahman"], "title": "OpenCAMS: An Open-Source Connected and Automated Mobility Co-Simulation Platform for Advanced Transportation Research", "categories": ["cs.SE"], "comment": null, "summary": "We introduce OpenCAMS (Open-Source Connected and Automated Mobility\nCo-Simulation Platform), an open-source, synchronized, and extensible\nco-simulation framework that tightly couples three best-in-class simulation\ntools: (i) SUMO, (ii) CARLA, and (iii) OMNeT++. OpenCAMS is designed to support\nadvanced research in transportation safety, mobility, and cybersecurity by\ncombining the strengths of each simulation domain. Specifically, SUMO provides\nlarge-scale, microscopic traffic modeling; CARLA offers high-fidelity 3D\nperception, vehicle dynamics, and control simulation; and OMNeT++ enables\nmodular, event-driven network communication, such as cellular\nvehicle-to-everything (C-V2X). OpenCAMS employs a time-synchronized,\nbidirectional coupling architecture that ensures coherent simulation\nprogression across traffic, perception, and communication domains while\npreserving modularity and reproducibility. For example, CARLA can simulate and\nrender a subset of vehicles that require detailed sensor emulation and control\nlogic; SUMO orchestrates network-wide traffic flow, vehicle routing, and\ntraffic signal management; and OMNeT++ dynamically maps communication nodes to\nboth mobile entities (e.g., vehicles) and static entities (e.g., roadside\nunits) to enable C-V2X communication. While these three simulators form the\nfoundational core of OpenCAMS, the platform is designed to be expandable and\nfuture-proof, allowing additional simulators to be integrated on top of this\ncore without requiring fundamental changes to the system architecture. The\nOpenCAMS platform is fully open-source and publicly available through its\nGitHub repository https://github.com/minhaj6/carla-sumo-omnetpp-cosim,\nproviding the research community with an accessible, flexible, and\ncollaborative environment for advancing next-generation intelligent\ntransportation systems.", "AI": {"tldr": "\u4ecb\u7ecd\u5f00\u6e90\u7684OpenCAMS\u534f\u540c\u4eff\u771f\u6846\u67b6\uff0c\u7ed3\u5408\u4e09\u79cd\u5de5\u5177\u4f18\u52bf\uff0c\u5177\u65f6\u95f4\u540c\u6b65\u3001\u53cc\u5411\u8026\u5408\u67b6\u6784\uff0c\u53ef\u6269\u5c55\u4e14\u5f00\u6e90\u3002", "motivation": "\u652f\u6301\u4ea4\u901a\u5b89\u5168\u3001\u79fb\u52a8\u6027\u548c\u7f51\u7edc\u5b89\u5168\u65b9\u9762\u7684\u9ad8\u7ea7\u7814\u7a76\uff0c\u63a8\u52a8\u4e0b\u4e00\u4ee3\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u65f6\u95f4\u540c\u6b65\u3001\u53cc\u5411\u8026\u5408\u67b6\u6784\uff0c\u7ed3\u5408SUMO\u3001CARLA\u548cOMNeT++\u4e09\u79cd\u5de5\u5177\u4f18\u52bf\uff0c\u4e14\u7cfb\u7edf\u53ef\u6269\u5c55\u3002", "result": "\u5f00\u53d1\u51faOpenCAMS\u5e73\u53f0\uff0c\u80fd\u5728\u4e0d\u540c\u9886\u57df\u534f\u540c\u4eff\u771f\u4e14\u4fdd\u8bc1\u4e00\u81f4\u6027\u3002", "conclusion": "OpenCAMS\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u3001\u7075\u6d3b\u548c\u534f\u4f5c\u7684\u73af\u5883\u4ee5\u63a8\u8fdb\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u3002"}}
{"id": "2507.08841", "pdf": "https://arxiv.org/pdf/2507.08841", "abs": "https://arxiv.org/abs/2507.08841", "authors": ["Kun Jing", "Luoyu Chen", "Jungang Xu", "Jianwei Tai", "Yiyu Wang", "Shuaimin Li"], "title": "Zero-Shot Neural Architecture Search with Weighted Response Correlation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Neural architecture search (NAS) is a promising approach for automatically\ndesigning neural network architectures. However, the architecture estimation of\nNAS is computationally expensive and time-consuming because of training\nmultiple architectures from scratch. Although existing zero-shot NAS methods\nuse training-free proxies to accelerate the architecture estimation, their\neffectiveness, stability, and generality are still lacking. We present a novel\ntraining-free estimation proxy called weighted response correlation (WRCor).\nWRCor utilizes correlation coefficient matrices of responses across different\ninput samples to calculate the proxy scores of estimated architectures, which\ncan measure their expressivity and generalizability. Experimental results on\nproxy evaluation demonstrate that WRCor and its voting proxies are more\nefficient estimation strategies than existing proxies. We also apply them with\ndifferent search strategies in architecture search. Experimental results on\narchitecture search show that our zero-shot NAS algorithm outperforms most\nexisting NAS algorithms in different search spaces. Our NAS algorithm can\ndiscover an architecture with a 22.1% test error on the ImageNet-1k dataset\nwithin 4 GPU hours. All codes are publicly available at\nhttps://github.com/kunjing96/ZSNAS-WRCor.git.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u4f30\u8ba1\u4ee3\u7406WRCor\u52a0\u901fNAS\u67b6\u6784\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u4ee3\u7406\u8bc4\u4f30\u548c\u67b6\u6784\u641c\u7d22\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709NAS\u67b6\u6784\u8bc4\u4f30\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u8017\u65f6\uff0c\u96f6\u6837\u672cNAS\u65b9\u6cd5\u5728\u6709\u6548\u6027\u3001\u7a33\u5b9a\u6027\u548c\u901a\u7528\u6027\u4e0a\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u52a0\u6743\u54cd\u5e94\u76f8\u5173\u6027\uff08WRCor\uff09\u4f5c\u4e3a\u65e0\u8bad\u7ec3\u4f30\u8ba1\u4ee3\u7406\uff0c\u5229\u7528\u4e0d\u540c\u8f93\u5165\u6837\u672c\u54cd\u5e94\u7684\u76f8\u5173\u7cfb\u6570\u77e9\u9635\u8ba1\u7b97\u4ee3\u7406\u5206\u6570\u3002", "result": "WRCor\u53ca\u5176\u6295\u7968\u4ee3\u7406\u5728\u4ee3\u7406\u8bc4\u4f30\u4e2d\u6bd4\u73b0\u6709\u4ee3\u7406\u66f4\u9ad8\u6548\uff1b\u96f6\u6837\u672cNAS\u7b97\u6cd5\u5728\u4e0d\u540c\u641c\u7d22\u7a7a\u95f4\u4e2d\u4f18\u4e8e\u591a\u6570\u73b0\u6709NAS\u7b97\u6cd5\uff0c\u80fd\u57284 GPU\u5c0f\u65f6\u5185\u53d1\u73b0ImageNet - 1k\u6d4b\u8bd5\u8bef\u5dee22.1%\u7684\u67b6\u6784\u3002", "conclusion": "WRCor\u662f\u6709\u6548\u7684\u65e0\u8bad\u7ec3\u4f30\u8ba1\u4ee3\u7406\uff0c\u57fa\u4e8e\u5b83\u7684\u96f6\u6837\u672cNAS\u7b97\u6cd5\u6027\u80fd\u826f\u597d\u3002"}}
{"id": "2507.09717", "pdf": "https://arxiv.org/pdf/2507.09717", "abs": "https://arxiv.org/abs/2507.09717", "authors": ["Abdullah Karaaslanli", "Bisakh Banerjee", "Tapabrata Maiti", "Selin Aviyente"], "title": "Signed Graph Learning: Algorithms and Theory", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": null, "summary": "Real-world data is often represented through the relationships between data\nsamples, forming a graph structure. In many applications, it is necessary to\nlearn this graph structure from the observed data. Current graph learning\nresearch has primarily focused on unsigned graphs, which consist only of\npositive edges. However, many biological and social systems are better\ndescribed by signed graphs that account for both positive and negative\ninteractions, capturing similarity and dissimilarity between samples. In this\npaper, we develop a method for learning signed graphs from a set of smooth\nsigned graph signals. Specifically, we employ the net Laplacian as a graph\nshift operator (GSO) to define smooth signed graph signals as the outputs of a\nlow-pass signed graph filter defined by the net Laplacian. The signed graph is\nthen learned by formulating a non-convex optimization problem where the total\nvariation of the observed signals is minimized with respect to the net\nLaplacian. The proposed problem is solved using alternating direction method of\nmultipliers (ADMM) and a fast algorithm reducing the per-ADMM iteration\ncomplexity from quadratic to linear in the number of nodes is introduced.\nFurthermore, theoretical proofs of convergence for the algorithm and a bound on\nthe estimation error of the learned net Laplacian as a function of sample size,\nnumber of nodes, and graph topology are provided. Finally, the proposed method\nis evaluated on simulated data and gene regulatory network inference problem\nand compared to existing signed graph learning methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ece\u4e00\u7ec4\u5e73\u6ed1\u6709\u7b26\u53f7\u56fe\u4fe1\u53f7\u4e2d\u5b66\u4e60\u6709\u7b26\u53f7\u56fe\u7684\u65b9\u6cd5\uff0c\u7528ADMM\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u5e76\u5f15\u5165\u5feb\u901f\u7b97\u6cd5\uff0c\u7ed9\u51fa\u7406\u8bba\u8bc1\u660e\uff0c\u5728\u6a21\u62df\u6570\u636e\u548c\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\u63a8\u65ad\u95ee\u9898\u4e0a\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u56fe\u5b66\u4e60\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u65e0\u7b26\u53f7\u56fe\uff0c\u800c\u8bb8\u591a\u751f\u7269\u548c\u793e\u4f1a\u7cfb\u7edf\u66f4\u9002\u5408\u7528\u6709\u7b26\u53f7\u56fe\u63cf\u8ff0\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u5b66\u4e60\u6709\u7b26\u53f7\u56fe\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u51c0\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u4f5c\u4e3a\u56fe\u79fb\u4f4d\u7b97\u5b50\u5b9a\u4e49\u5e73\u6ed1\u6709\u7b26\u53f7\u56fe\u4fe1\u53f7\uff0c\u901a\u8fc7\u6c42\u89e3\u4e00\u4e2a\u975e\u51f8\u4f18\u5316\u95ee\u9898\u5b66\u4e60\u6709\u7b26\u53f7\u56fe\uff0c\u4f7f\u7528\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5\uff08ADMM\uff09\u6c42\u89e3\uff0c\u5f15\u5165\u5feb\u901f\u7b97\u6cd5\u964d\u4f4e\u590d\u6742\u5ea6\uff0c\u7ed9\u51fa\u6536\u655b\u6027\u7406\u8bba\u8bc1\u660e\u548c\u4f30\u8ba1\u8bef\u5dee\u754c\u3002", "result": "\u5728\u6a21\u62df\u6570\u636e\u548c\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\u63a8\u65ad\u95ee\u9898\u4e0a\u5bf9\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u73b0\u6709\u6709\u7b26\u53f7\u56fe\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8f83\u3002", "conclusion": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u53ef\u63a8\u6d4b\u6240\u63d0\u65b9\u6cd5\u5728\u6709\u7b26\u53f7\u56fe\u5b66\u4e60\u4e0a\u6709\u4e00\u5b9a\u6548\u679c\u548c\u4f18\u52bf\u3002"}}
{"id": "2507.09654", "pdf": "https://arxiv.org/pdf/2507.09654", "abs": "https://arxiv.org/abs/2507.09654", "authors": ["Amir Babak Aazami", "Hubert L. Bray"], "title": "Ranked Pairs minimizes the $p$-norm as $p \\to \\infty$", "categories": ["econ.TH", "cs.GT"], "comment": "15 pages", "summary": "We prove that Ranked Pairs orders candidates in such a way as to minimize the\n$p$-norm, in the limit as $p \\to \\infty$, of those head-to-head margins of\nvictory which go against its ordering.", "AI": {"tldr": "\u8bc1\u660eRanked Pairs\u6392\u5e8f\u5728p\u8d8b\u4e8e\u65e0\u7a77\u65f6\u6700\u5c0f\u5316\u8fdd\u80cc\u5176\u6392\u5e8f\u7684\u6210\u5bf9\u7ade\u9009\u4f18\u52bf\u7684p - \u8303\u6570\u3002", "motivation": "\u63a2\u7a76Ranked Pairs\u6392\u5e8f\u5728\u7279\u5b9a\u8303\u6570\u4e0b\u7684\u7279\u6027", "method": "\u901a\u8fc7\u6570\u5b66\u8bc1\u660e", "result": "Ranked Pairs\u6392\u5e8f\u80fd\u5728p\u8d8b\u4e8e\u65e0\u7a77\u65f6\u6700\u5c0f\u5316\u8fdd\u80cc\u5176\u6392\u5e8f\u7684\u6210\u5bf9\u7ade\u9009\u4f18\u52bf\u7684p - \u8303\u6570", "conclusion": "Ranked Pairs\u6392\u5e8f\u5177\u6709\u5728\u6781\u9650\u60c5\u51b5\u4e0b\u6700\u5c0f\u5316\u7279\u5b9ap - \u8303\u6570\u7684\u6027\u8d28\u3002"}}
{"id": "2507.10413", "pdf": "https://arxiv.org/pdf/2507.10413", "abs": "https://arxiv.org/abs/2507.10413", "authors": ["Gabriel Rocha"], "title": "Consensus, Inconsistency, Emergence: what's paraconsistency got to do with it?", "categories": ["cs.DC", "cs.CC", "cs.IT", "cs.LO", "math.IT"], "comment": "10 pages", "summary": "The consensus problem, briefly stated, consists of having processes in an\nasynchronous distributed system agree on a value. It is widely known that the\nconsensus problem does not have a deterministic solution that ensures both\ntermination and consistency, if there is at least one faulty process in the\nsystem. This result, known as the FLP impossibility theorem, led to several\ngeneralizations and developments in theoretical distributed computing. This\npaper argues that the FLP impossibility theorem holds even under a generalized\ndefinition of computation through oracles. Furthermore, using a theoretical\nmachinery from complex systems, this paper also posits that inconsistency may\nbe an emergent feature of consensus over distributed systems by examining how a\nsystem transitions phases. Under the same complex systems framework, this paper\nexamines paraconsistent logics, arguing that while inconsistency is not an\nemergent feature for these logics, triviality may be. Lastly, some attention is\ngiven to the possibility of developing consensus algorithms capable of\nparaconsistent reasoning.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5206\u5e03\u5f0f\u7cfb\u7edf\u5171\u8bc6\u95ee\u9898\uff0c\u8bba\u8bc1FLP\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u5728\u5e7f\u4e49\u8ba1\u7b97\u5b9a\u4e49\u4e0b\u4ecd\u6210\u7acb\uff0c\u7814\u7a76\u4e0d\u4e00\u81f4\u6027\u662f\u5426\u4e3a\u6d8c\u73b0\u7279\u5f81\uff0c\u8fd8\u5173\u6ce8\u6b21\u534f\u8c03\u903b\u8f91\u548c\u5f00\u53d1\u76f8\u5173\u5171\u8bc6\u7b97\u6cd5\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u57fa\u4e8eFLP\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u5728\u7406\u8bba\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u5f71\u54cd\uff0c\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5728\u5e7f\u4e49\u8ba1\u7b97\u5b9a\u4e49\u4e0b\u7684\u60c5\u51b5\uff0c\u4ee5\u53ca\u5206\u5e03\u5f0f\u7cfb\u7edf\u5171\u8bc6\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u7b49\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u590d\u6742\u7cfb\u7edf\u7684\u7406\u8bba\u5de5\u5177\uff0c\u7814\u7a76\u7cfb\u7edf\u7684\u76f8\u8f6c\u53d8\uff0c\u5206\u6790\u6b21\u534f\u8c03\u903b\u8f91\u3002", "result": "\u8bba\u8bc1\u4e86FLP\u4e0d\u53ef\u80fd\u6027\u5b9a\u7406\u5728\u5e7f\u4e49\u8ba1\u7b97\u5b9a\u4e49\u4e0b\u6210\u7acb\uff0c\u6307\u51fa\u4e0d\u4e00\u81f4\u6027\u53ef\u80fd\u662f\u5206\u5e03\u5f0f\u7cfb\u7edf\u5171\u8bc6\u7684\u6d8c\u73b0\u7279\u5f81\uff0c\u6b21\u534f\u8c03\u903b\u8f91\u4e2d\u5e73\u51e1\u6027\u53ef\u80fd\u662f\u76f8\u5173\u7279\u5f81\u3002", "conclusion": "\u63d0\u51fa\u5bf9\u5f00\u53d1\u5177\u5907\u6b21\u534f\u8c03\u63a8\u7406\u80fd\u529b\u7684\u5171\u8bc6\u7b97\u6cd5\u7684\u5173\u6ce8\u3002"}}
{"id": "2507.09924", "pdf": "https://arxiv.org/pdf/2507.09924", "abs": "https://arxiv.org/abs/2507.09924", "authors": ["Tuan-Luc Huynh", "Thuy-Trang Vu", "Weiqing Wang", "Trung Le", "Dragan Ga\u0161evi\u0107", "Yuan-Fang Li", "Thanh-Toan Do"], "title": "MixLoRA-DSI: Dynamically Expandable Mixture-of-LoRA Experts for Rehearsal-Free Generative Retrieval over Dynamic Corpora", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Continually updating model-based indexes in generative retrieval with new\ndocuments remains challenging, as full retraining is computationally expensive\nand impractical under resource constraints. We propose MixLoRA-DSI, a novel\nframework that combines an expandable mixture of Low-Rank Adaptation experts\nwith a layer-wise out-of-distribution (OOD)-driven expansion strategy. Instead\nof allocating new experts for each new corpus, our proposed expansion strategy\nenables sublinear parameter growth by selectively introducing new experts only\nwhen significant number of OOD documents are detected. Experiments on NQ320k\nand MS MARCO Passage demonstrate that MixLoRA-DSI outperforms full-model update\nbaselines, with minimal parameter overhead and substantially lower training\ncosts.", "AI": {"tldr": "\u63d0\u51faMixLoRA - DSI\u6846\u67b6\uff0c\u7ed3\u5408\u4f4e\u79e9\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u4e0eOOD\u9a71\u52a8\u6269\u5c55\u7b56\u7565\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u5168\u6a21\u578b\u66f4\u65b0\u57fa\u7ebf\uff0c\u53c2\u6570\u5f00\u9500\u5c0f\u3001\u8bad\u7ec3\u6210\u672c\u4f4e\u3002", "motivation": "\u5728\u751f\u6210\u5f0f\u68c0\u7d22\u4e2d\u6301\u7eed\u7528\u65b0\u6587\u6863\u66f4\u65b0\u57fa\u4e8e\u6a21\u578b\u7684\u7d22\u5f15\u5177\u6709\u6311\u6218\u6027\uff0c\u5168\u91cf\u91cd\u65b0\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u53d7\u8d44\u6e90\u9650\u5236\u4e0d\u5b9e\u9645\u3002", "method": "\u63d0\u51faMixLoRA - DSI\u6846\u67b6\uff0c\u7ed3\u5408\u53ef\u6269\u5c55\u7684\u4f4e\u79e9\u81ea\u9002\u5e94\u4e13\u5bb6\u6df7\u5408\u548c\u57fa\u4e8e\u5c42\u7684OOD\u9a71\u52a8\u6269\u5c55\u7b56\u7565\uff0c\u4ec5\u5728\u68c0\u6d4b\u5230\u5927\u91cfOOD\u6587\u6863\u65f6\u624d\u5f15\u5165\u65b0\u4e13\u5bb6\u3002", "result": "\u5728NQ320k\u548cMS MARCO Passage\u5b9e\u9a8c\u4e2d\uff0cMixLoRA - DSI\u4f18\u4e8e\u5168\u6a21\u578b\u66f4\u65b0\u57fa\u7ebf\uff0c\u53c2\u6570\u5f00\u9500\u6781\u5c0f\uff0c\u8bad\u7ec3\u6210\u672c\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "MixLoRA - DSI\u6846\u67b6\u662f\u4e00\u79cd\u6709\u6548\u7684\u66f4\u65b0\u751f\u6210\u5f0f\u68c0\u7d22\u4e2d\u57fa\u4e8e\u6a21\u578b\u7d22\u5f15\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.09716", "pdf": "https://arxiv.org/pdf/2507.09716", "abs": "https://arxiv.org/abs/2507.09716", "authors": ["Mirco A. Mannucci"], "title": "When the Weak Becomes Strong: Effective Observables via Time-Symmetric Quantum Selection", "categories": ["quant-ph", "cs.CE"], "comment": "11 pages, 2 figures", "summary": "We investigate the sequential composition of weak values in the framework of\ntime-symmetric quantum mechanics. Specifically, we consider a forward'' weak\nmeasurement from a preselected state $\\ket{\\psi}$ to a post-selected state\n$\\ket{\\phi}$, followed by a reverse'' weak measurement. We show that the\nproduct of these two weak values corresponds to the normalized expectation\nvalue of a strong, state-conditioned observable $B = A P_\\psi A$, where $P_\\psi\n= \\ket{\\psi}\\bra{\\psi}$ is the projector onto the preselected state. Analyzing\nthe structure of $B$, we demonstrate how it encodes interference information,\nparticularly when $\\ket{\\psi}$ is a superposition rather than an eigenstate of\n$A$. This formulation extends naturally to mixed states by replacing $P_\\psi$\nwith a generic density matrix $\\rho$, linking the construction to the formalism\nof generalized quantum measurements. We illustrate practical applications in\nquantum information, including state-specific error witnessing in quantum\ncomputing, and show how the phase of a weak value can be inferred via strong\nmeasurements in the pure-state case.", "AI": {"tldr": "\u7814\u7a76\u65f6\u95f4\u5bf9\u79f0\u91cf\u5b50\u529b\u5b66\u4e2d\u5f31\u503c\u7684\u987a\u5e8f\u7ec4\u5408\uff0c\u7ed9\u51fa\u5f31\u503c\u4e58\u79ef\u5bf9\u5e94\u53ef\u89c2\u6d4b\u91cf\u7684\u5f52\u4e00\u5316\u671f\u671b\u503c\uff0c\u5206\u6790\u5176\u7ed3\u6784\uff0c\u62d3\u5c55\u5230\u6df7\u5408\u6001\u5e76\u8bf4\u660e\u5e94\u7528\u3002", "motivation": "\u5728\u65f6\u95f4\u5bf9\u79f0\u91cf\u5b50\u529b\u5b66\u6846\u67b6\u4e0b\u7814\u7a76\u5f31\u503c\u7684\u987a\u5e8f\u7ec4\u5408\u95ee\u9898\u3002", "method": "\u5148\u8fdb\u884c\u6b63\u5411\u5f31\u6d4b\u91cf\uff0c\u518d\u8fdb\u884c\u53cd\u5411\u5f31\u6d4b\u91cf\uff0c\u5206\u6790\u5f31\u503c\u4e58\u79ef\u4e0e\u53ef\u89c2\u6d4b\u91cf\u7684\u5173\u7cfb\uff0c\u5206\u6790\u53ef\u89c2\u6d4b\u91cf\u7ed3\u6784\uff0c\u5c06\u7eaf\u6001\u62d3\u5c55\u5230\u6df7\u5408\u6001\u3002", "result": "\u5f31\u503c\u4e58\u79ef\u5bf9\u5e94\u5f52\u4e00\u5316\u671f\u671b\u503c\uff0c\u53ef\u89c2\u6d4b\u91cf\u7f16\u7801\u5e72\u6d89\u4fe1\u606f\uff0c\u53ef\u62d3\u5c55\u5230\u6df7\u5408\u6001\uff0c\u80fd\u5e94\u7528\u4e8e\u91cf\u5b50\u4fe1\u606f\u7b49\u9886\u57df\uff0c\u7eaf\u6001\u4e0b\u53ef\u901a\u8fc7\u5f3a\u6d4b\u91cf\u63a8\u65ad\u5f31\u503c\u76f8\u4f4d\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u91cf\u5b50\u4fe1\u606f\u9886\u57df\u63d0\u4f9b\u65b0\u89c6\u89d2\u548c\u65b9\u6cd5\uff0c\u5982\u5728\u91cf\u5b50\u8ba1\u7b97\u4e2d\u89c1\u8bc1\u7279\u5b9a\u72b6\u6001\u7684\u9519\u8bef\u7b49\u3002"}}
{"id": "2507.10281", "pdf": "https://arxiv.org/pdf/2507.10281", "abs": "https://arxiv.org/abs/2507.10281", "authors": ["Jiaming Tian", "Liyao Li", "Wentao Ye", "Haobo Wang", "Lingxin Wang", "Lihua Yu", "Zujie Ren", "Gang Chen", "Junbo Zhao"], "title": "Toward Real-World Table Agents: Capabilities, Workflows, and Design Principles for LLM-based Table Intelligence", "categories": ["cs.AI", "cs.DB"], "comment": null, "summary": "Tables are fundamental in domains such as finance, healthcare, and public\nadministration, yet real-world table tasks often involve noise, structural\nheterogeneity, and semantic complexity--issues underexplored in existing\nresearch that primarily targets clean academic datasets. This survey focuses on\nLLM-based Table Agents, which aim to automate table-centric workflows by\nintegrating preprocessing, reasoning, and domain adaptation. We define five\ncore competencies--C1: Table Structure Understanding, C2: Table and Query\nSemantic Understanding, C3: Table Retrieval and Compression, C4: Executable\nReasoning with Traceability, and C5: Cross-Domain Generalization--to analyze\nand compare current approaches. In addition, a detailed examination of the\nText-to-SQL Agent reveals a performance gap between academic benchmarks and\nreal-world scenarios, especially for open-source models. Finally, we provide\nactionable insights to improve the robustness, generalization, and efficiency\nof LLM-based Table Agents in practical settings.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u683c\u667a\u80fd\u4f53\uff0c\u5b9a\u4e49\u6838\u5fc3\u80fd\u529b\u5206\u6790\u73b0\u6709\u65b9\u6cd5\uff0c\u63ed\u793a\u5b66\u672f\u57fa\u51c6\u4e0e\u73b0\u5b9e\u573a\u666f\u5dee\u8ddd\u5e76\u7ed9\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u73b0\u5b9e\u8868\u683c\u4efb\u52a1\u5b58\u5728\u566a\u58f0\u3001\u7ed3\u6784\u5f02\u8d28\u6027\u548c\u8bed\u4e49\u590d\u6742\u6027\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u7814\u7a76\u591a\u9488\u5bf9\u5e72\u51c0\u7684\u5b66\u672f\u6570\u636e\u96c6\uff0c\u672a\u5145\u5206\u63a2\u7d22\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5b9a\u4e49\u4e94\u9879\u6838\u5fc3\u80fd\u529b\u5206\u6790\u548c\u6bd4\u8f83\u5f53\u524d\u65b9\u6cd5\uff0c\u8be6\u7ec6\u7814\u7a76\u6587\u672c\u5230SQL\u667a\u80fd\u4f53\u3002", "result": "\u53d1\u73b0\u5b66\u672f\u57fa\u51c6\u548c\u73b0\u5b9e\u573a\u666f\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5f00\u6e90\u6a21\u578b\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u63d0\u9ad8\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u683c\u667a\u80fd\u4f53\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u7684\u53ef\u884c\u5efa\u8bae\u3002"}}
{"id": "2507.10436", "pdf": "https://arxiv.org/pdf/2507.10436", "abs": "https://arxiv.org/abs/2507.10436", "authors": ["Jungho Ahn", "Ian DeHaan", "Eun Jung Kim", "Euiwoong Lee"], "title": "Approximating Maximum Cut on Interval Graphs and Split Graphs beyond Goemans-Williamson", "categories": ["cs.DS", "F.2.2"], "comment": "23 pages, 5 figures, to appear in the proceedings of APPROX 2025", "summary": "We present a polynomial-time $(\\alpha_{GW} + \\varepsilon)$-approximation\nalgorithm for the Maximum Cut problem on interval graphs and split graphs,\nwhere $\\alpha_{GW} \\approx 0.878$ is the approximation guarantee of the\nGoemans-Williamson algorithm and $\\varepsilon > 10^{-34}$ is a fixed constant.\nTo attain this, we give an improved analysis of a slight modification of the\nGoemans-Williamson algorithm for graphs in which triangles can be packed into a\nconstant fraction of their edges. We then pair this analysis with structural\nresults showing that both interval graphs and split graphs either have such a\ntriangle packing or have maximum cut close to their number of edges. We also\nshow that, subject to the Small Set Expansion Hypothesis, there exists a\nconstant $c > 0$ such that there is no polyomial-time $(1 - c)$-approximation\nfor Maximum Cut on split graphs.", "AI": {"tldr": "\u63d0\u51fa\u6700\u5927\u5272\u95ee\u9898\u5728\u533a\u95f4\u56fe\u548c\u5206\u88c2\u56fe\u4e0a\u7684\u591a\u9879\u5f0f\u65f6\u95f4(\u03b1_GW + \u03b5)-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8fd8\u7ed9\u51fa\u5728\u5206\u88c2\u56fe\u4e0a\u8fd1\u4f3c\u96be\u5ea6\u7ed3\u679c\u3002", "motivation": "\u4e3a\u6700\u5927\u5272\u95ee\u9898\u5728\u533a\u95f4\u56fe\u548c\u5206\u88c2\u56fe\u4e0a\u627e\u5230\u66f4\u597d\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "method": "\u6539\u8fdbGoemans - Williamson\u7b97\u6cd5\u5206\u6790\uff0c\u7ed3\u5408\u533a\u95f4\u56fe\u548c\u5206\u88c2\u56fe\u7ed3\u6784\u7ed3\u679c\u3002", "result": "\u5f97\u5230\u591a\u9879\u5f0f\u65f6\u95f4(\u03b1_GW + \u03b5)-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8bc1\u660e\u5728\u5206\u88c2\u56fe\u4e0a\u5b58\u5728\u8fd1\u4f3c\u96be\u5ea6\u3002", "conclusion": "\u5728\u533a\u95f4\u56fe\u548c\u5206\u88c2\u56fe\u6700\u5927\u5272\u95ee\u9898\u8fd1\u4f3c\u7b97\u6cd5\u4e0a\u6709\u8fdb\u5c55\uff0c\u4e14\u5b58\u5728\u8fd1\u4f3c\u96be\u5ea6\u754c\u9650\u3002"}}
{"id": "2507.09199", "pdf": "https://arxiv.org/pdf/2507.09199", "abs": "https://arxiv.org/abs/2507.09199", "authors": ["Huihui Huang", "Ratnadira Widyasari", "Ting Zhang", "Ivana Clairine Irsan", "Jieke Shi", "Han Wei Ang", "Frank Liauw", "Eng Lieh Ouh", "Lwin Khin Shar", "Hong Jin Kang", "David Lo"], "title": "Back to the Basics: Rethinking Issue-Commit Linking with LLM-Assisted Retrieval", "categories": ["cs.SE"], "comment": null, "summary": "Issue-commit linking, which connects issues with commits that fix them, is\ncrucial for software maintenance. Existing approaches have shown promise in\nautomatically recovering these links. Evaluations of these techniques assess\ntheir ability to identify genuine links from plausible but false links.\nHowever, these evaluations overlook the fact that, in reality, when a\nrepository has more commits, the presence of more plausible yet unrelated\ncommits may interfere with the tool in differentiating the correct fix commits.\nTo address this, we propose the Realistic Distribution Setting (RDS) and use it\nto construct a more realistic evaluation dataset that includes 20 open-source\nprojects. By evaluating tools on this dataset, we observe that the performance\nof the state-of-the-art deep learning-based approach drops by more than half,\nwhile the traditional Information Retrieval method, VSM, outperforms it.\n  Inspired by these observations, we propose EasyLink, which utilizes a vector\ndatabase as a modern Information Retrieval technique. To address the\nlong-standing problem of the semantic gap between issues and commits, EasyLink\nleverages a large language model to rerank the commits retrieved from the\ndatabase. Under our evaluation, EasyLink achieves an average Precision@1 of\n75.91%, improving over the state-of-the-art by over four times. Additionally,\nthis paper provides practical guidelines for advancing research in issue-commit\nlink recovery.", "AI": {"tldr": "\u63d0\u51faRDS\u6784\u5efa\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\uff0c\u4f20\u7edf\u65b9\u6cd5VSM\u66f4\u4f18\uff0c\u63d0\u51faEasyLink\u5de5\u5177\uff0c\u6027\u80fd\u63d0\u5347\u56db\u500d\u591a\uff0c\u5e76\u7ed9\u51fa\u7814\u7a76\u5b9e\u8df5\u6307\u5357\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6280\u672f\u5ffd\u7565\u4ed3\u5e93\u4e2d\u66f4\u591a\u65e0\u5173\u63d0\u4ea4\u5bf9\u5de5\u5177\u8bc6\u522b\u6b63\u786e\u4fee\u590d\u63d0\u4ea4\u7684\u5e72\u6270\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u3002", "method": "\u63d0\u51faRealistic Distribution Setting (RDS)\u6784\u5efa\u8bc4\u4f30\u6570\u636e\u96c6\uff1b\u63d0\u51faEasyLink\uff0c\u5229\u7528\u5411\u91cf\u6570\u636e\u5e93\u548c\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u63d0\u4ea4\u3002", "result": "\u5728\u65b0\u6570\u636e\u96c6\u4e0a\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u8d85\u4e00\u534a\uff0cVSM\u8868\u73b0\u66f4\u4f18\uff1bEasyLink\u5e73\u5747Precision@1\u8fbe75.91%\uff0c\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u5347\u56db\u500d\u591a\u3002", "conclusion": "EasyLink\u6709\u6548\u89e3\u51b3\u95ee\u9898\uff0c\u8bba\u6587\u7ed9\u51fa\u4e86\u63a8\u8fdb\u95ee\u9898 - \u63d0\u4ea4\u94fe\u63a5\u6062\u590d\u7814\u7a76\u7684\u5b9e\u8df5\u6307\u5357\u3002"}}
{"id": "2507.08842", "pdf": "https://arxiv.org/pdf/2507.08842", "abs": "https://arxiv.org/abs/2507.08842", "authors": ["Zhufeng Lu", "Chentao Jia", "Ming Hu", "Xiaofei Xie", "Mingsong Chen"], "title": "Gradients as an Action: Towards Communication-Efficient Federated Recommender Systems via Adaptive Action Sharing", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted by ACM SIGKDD 2025", "summary": "As a promising privacy-aware collaborative model training paradigm, Federated\nLearning (FL) is becoming popular in the design of distributed recommender\nsystems. However, Federated Recommender Systems (FedRecs) greatly suffer from\ntwo major problems: i) extremely high communication overhead due to massive\nitem embeddings involved in recommendation systems, and ii) intolerably low\ntraining efficiency caused by the entanglement of both heterogeneous network\nenvironments and client devices. Although existing methods attempt to employ\nvarious compression techniques to reduce communication overhead, due to the\nparameter errors introduced by model compression, they inevitably suffer from\nmodel performance degradation. To simultaneously address the above problems,\nthis paper presents a communication-efficient FedRec framework named FedRAS,\nwhich adopts an action-sharing strategy to cluster the gradients of item\nembedding into a specific number of model updating actions for communication\nrather than directly compressing the item embeddings. In this way, the cloud\nserver can use the limited actions from clients to update all the items. Since\ngradient values are significantly smaller than item embeddings, constraining\nthe directions of gradients (i.e., the action space) introduces smaller errors\ncompared to compressing the entire item embedding matrix into a reduced space.\nTo accommodate heterogeneous devices and network environments, FedRAS\nincorporates an adaptive clustering mechanism that dynamically adjusts the\nnumber of actions. Comprehensive experiments on well-known datasets demonstrate\nthat FedRAS can reduce the size of communication payloads by up to 96.88%,\nwhile not sacrificing recommendation performance within various heterogeneous\nscenarios. We have open-sourced FedRAS at\nhttps://github.com/mastlab-T3S/FedRAS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u4fe1\u9ad8\u6548\u7684\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u6846\u67b6FedRAS\uff0c\u91c7\u7528\u52a8\u4f5c\u5171\u4eab\u7b56\u7565\u548c\u81ea\u9002\u5e94\u805a\u7c7b\u673a\u5236\uff0c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u4e14\u4e0d\u727a\u7272\u63a8\u8350\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u901a\u4fe1\u5f00\u9500\u9ad8\u548c\u8bad\u7ec3\u6548\u7387\u4f4e\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u538b\u7f29\u6280\u672f\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faFedRAS\u6846\u67b6\uff0c\u91c7\u7528\u52a8\u4f5c\u5171\u4eab\u7b56\u7565\u5c06\u7269\u54c1\u5d4c\u5165\u68af\u5ea6\u805a\u7c7b\u4e3a\u6a21\u578b\u66f4\u65b0\u52a8\u4f5c\u8fdb\u884c\u901a\u4fe1\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u805a\u7c7b\u673a\u5236\u52a8\u6001\u8c03\u6574\u52a8\u4f5c\u6570\u91cf\u3002", "result": "\u5728\u77e5\u540d\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cFedRAS\u53ef\u5c06\u901a\u4fe1\u8d1f\u8f7d\u5927\u5c0f\u6700\u591a\u964d\u4f4e96.88%\uff0c\u4e14\u5728\u4e0d\u540c\u5f02\u6784\u573a\u666f\u4e0b\u4e0d\u727a\u7272\u63a8\u8350\u6027\u80fd\u3002", "conclusion": "FedRAS\u80fd\u6709\u6548\u89e3\u51b3\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u901a\u4fe1\u5f00\u9500\u9ad8\u548c\u8bad\u7ec3\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09740", "pdf": "https://arxiv.org/pdf/2507.09740", "abs": "https://arxiv.org/abs/2507.09740", "authors": ["Ridwan Olabiyi", "Han Hu", "Ashif Iquebal"], "title": "Discovering Governing Equations in the Presence of Uncertainty", "categories": ["stat.ML", "cs.LG", "math.DS", "physics.data-an"], "comment": "24 pages, 5 figures", "summary": "In the study of complex dynamical systems, understanding and accurately\nmodeling the underlying physical processes is crucial for predicting system\nbehavior and designing effective interventions. Yet real-world systems exhibit\npronounced input (or system) variability and are observed through noisy,\nlimited data conditions that confound traditional discovery methods that assume\nfixed-coefficient deterministic models. In this work, we theorize that\naccounting for system variability together with measurement noise is the key to\nconsistently discover the governing equations underlying dynamical systems. As\nsuch, we introduce a stochastic inverse physics-discovery (SIP) framework that\ntreats the unknown coefficients as random variables and infers their posterior\ndistribution by minimizing the Kullback-Leibler divergence between the\npush-forward of the posterior samples and the empirical data distribution.\nBenchmarks on four canonical problems -- the Lotka-Volterra predator-prey\nsystem (multi- and single-trajectory), the historical Hudson Bay lynx-hare\ndata, the chaotic Lorenz attractor, and fluid infiltration in porous media\nusing low- and high-viscosity liquids -- show that SIP consistently identifies\nthe correct equations and lowers coefficient root-mean-square error by an\naverage of 82\\% relative to the Sparse Identification of Nonlinear Dynamics\n(SINDy) approach and its Bayesian variant. The resulting posterior\ndistributions yield 95\\% credible intervals that closely track the observed\ntrajectories, providing interpretable models with quantified uncertainty. SIP\nthus provides a robust, data-efficient approach for consistent physics\ndiscovery in noisy, variable, and data-limited settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u968f\u673a\u9006\u7269\u7406\u53d1\u73b0\uff08SIP\uff09\u6846\u67b6\uff0c\u5904\u7406\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u65b9\u7a0b\u53d1\u73b0\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8eSINDy\u65b9\u6cd5\uff0c\u80fd\u63d0\u4f9b\u5e26\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u53ef\u89e3\u91ca\u6a21\u578b\u3002", "motivation": "\u73b0\u5b9e\u7cfb\u7edf\u5b58\u5728\u8f93\u5165\u53ef\u53d8\u6027\u548c\u6d4b\u91cf\u566a\u58f0\uff0c\u4f20\u7edf\u53d1\u73b0\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7cfb\u6570\u786e\u5b9a\u6027\u6a21\u578b\uff0c\u96be\u4ee5\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u65b9\u6cd5\u6765\u8003\u8651\u7cfb\u7edf\u53ef\u53d8\u6027\u548c\u6d4b\u91cf\u566a\u58f0\u3002", "method": "\u5f15\u5165SIP\u6846\u67b6\uff0c\u5c06\u672a\u77e5\u7cfb\u6570\u89c6\u4e3a\u968f\u673a\u53d8\u91cf\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u540e\u9a8c\u6837\u672c\u7684\u63a8\u524d\u5206\u5e03\u4e0e\u7ecf\u9a8c\u6570\u636e\u5206\u5e03\u4e4b\u95f4\u7684Kullback - Leibler\u6563\u5ea6\u6765\u63a8\u65ad\u5176\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5728\u56db\u4e2a\u5178\u578b\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSIP\u80fd\u4e00\u81f4\u8bc6\u522b\u6b63\u786e\u65b9\u7a0b\uff0c\u76f8\u5bf9SINDy\u65b9\u6cd5\u53ca\u5176\u8d1d\u53f6\u65af\u53d8\u4f53\uff0c\u5e73\u5747\u964d\u4f4e\u7cfb\u6570\u5747\u65b9\u6839\u8bef\u5dee82%\uff0c\u540e\u9a8c\u5206\u5e03\u768495%\u53ef\u4fe1\u533a\u95f4\u80fd\u7d27\u5bc6\u8ddf\u8e2a\u89c2\u6d4b\u8f68\u8ff9\u3002", "conclusion": "SIP\u4e3a\u566a\u58f0\u3001\u53ef\u53d8\u548c\u6570\u636e\u6709\u9650\u7684\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5065\u3001\u6570\u636e\u9ad8\u6548\u7684\u7269\u7406\u53d1\u73b0\u65b9\u6cd5\u3002"}}
{"id": "2507.09683", "pdf": "https://arxiv.org/pdf/2507.09683", "abs": "https://arxiv.org/abs/2507.09683", "authors": ["Michael Kearns", "Aaron Roth", "Emily Ryu"], "title": "Networked Information Aggregation via Machine Learning", "categories": ["cs.LG", "cs.GT", "econ.TH"], "comment": null, "summary": "We study a distributed learning problem in which learning agents are embedded\nin a directed acyclic graph (DAG). There is a fixed and arbitrary distribution\nover feature/label pairs, and each agent or vertex in the graph is able to\ndirectly observe only a subset of the features -- potentially a different\nsubset for every agent. The agents learn sequentially in some order consistent\nwith a topological sort of the DAG, committing to a model mapping observations\nto predictions of the real-valued label. Each agent observes the predictions of\ntheir parents in the DAG, and trains their model using both the features of the\ninstance that they directly observe, and the predictions of their parents as\nadditional features. We ask when this process is sufficient to achieve\n\\emph{information aggregation}, in the sense that some agent in the DAG is able\nto learn a model whose error is competitive with the best model that could have\nbeen learned (in some hypothesis class) with direct access to \\emph{all}\nfeatures, despite the fact that no single agent in the network has such access.\nWe give upper and lower bounds for this problem for both linear and general\nhypothesis classes. Our results identify the \\emph{depth} of the DAG as the key\nparameter: information aggregation can occur over sufficiently long paths in\nthe DAG, assuming that all of the relevant features are well represented along\nthe path, and there are distributions over which information aggregation cannot\noccur even in the linear case, and even in arbitrarily large DAGs that do not\nhave sufficient depth (such as a hub-and-spokes topology in which the spoke\nvertices collectively see all the features). We complement our theoretical\nresults with a comprehensive set of experiments.", "AI": {"tldr": "\u7814\u7a76\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u4e2d\u5206\u5e03\u5f0f\u5b66\u4e60\u95ee\u9898\uff0c\u7ed9\u51fa\u7ebf\u6027\u548c\u4e00\u822c\u5047\u8bbe\u7c7b\u4e0a\u4e0b\u754c\uff0c\u786e\u5b9aDAG\u6df1\u5ea6\u4e3a\u5173\u952e\u53c2\u6570\u5e76\u8f85\u4ee5\u5b9e\u9a8c\u3002", "motivation": "\u63a2\u7a76\u5728DAG\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\uff0c\u4f55\u65f6\u80fd\u5b9e\u73b0\u4fe1\u606f\u805a\u5408\uff0c\u5373\u90e8\u5206\u4ee3\u7406\u5b66\u4e60\u7684\u6a21\u578b\u8bef\u5dee\u80fd\u4e0e\u76f4\u63a5\u8bbf\u95ee\u6240\u6709\u7279\u5f81\u5b66\u4e60\u7684\u6700\u4f73\u6a21\u578b\u7ade\u4e89\u3002", "method": "\u5206\u6790DAG\u4e2d\u4ee3\u7406\u987a\u5e8f\u5b66\u4e60\u8fc7\u7a0b\uff0c\u57fa\u4e8e\u7279\u5f81\u548c\u7236\u8282\u70b9\u9884\u6d4b\u8bad\u7ec3\u6a21\u578b\uff0c\u4e3a\u7ebf\u6027\u548c\u4e00\u822c\u5047\u8bbe\u7c7b\u95ee\u9898\u7ed9\u51fa\u4e0a\u4e0b\u754c\u3002", "result": "\u786e\u5b9aDAG\u6df1\u5ea6\u662f\u5173\u952e\u53c2\u6570\uff0c\u8db3\u591f\u957f\u8def\u5f84\u53ef\u5b9e\u73b0\u4fe1\u606f\u805a\u5408\uff0c\u67d0\u4e9b\u6df1\u5ea6\u4e0d\u8db3\u7684DAG\u5373\u4f7f\u7ebf\u6027\u60c5\u51b5\u4e5f\u65e0\u6cd5\u5b9e\u73b0\u3002", "conclusion": "DAG\u6df1\u5ea6\u5bf9\u5206\u5e03\u5f0f\u5b66\u4e60\u4e2d\u7684\u4fe1\u606f\u805a\u5408\u81f3\u5173\u91cd\u8981\uff0c\u7406\u8bba\u7ed3\u679c\u901a\u8fc7\u5b9e\u9a8c\u5f97\u5230\u8865\u5145\u9a8c\u8bc1\u3002"}}
{"id": "2507.10430", "pdf": "https://arxiv.org/pdf/2507.10430", "abs": "https://arxiv.org/abs/2507.10430", "authors": ["Ji Liu", "Beichen Ma", "Yang Zhou", "Jingbo Zhou", "Ruoming Jin", "Dejing Dou", "Huaiyu Dai", "Haixun Wang", "Patrick Valduriez"], "title": "Efficient Federated Learning with Heterogeneous Data and Adaptive Dropout", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "29 pages, to appear in ACM Transactions on Knowledge Discovery from\n  Data (TKDD)", "summary": "Federated Learning (FL) is a promising distributed machine learning approach\nthat enables collaborative training of a global model using multiple edge\ndevices. The data distributed among the edge devices is highly heterogeneous.\nThus, FL faces the challenge of data distribution and heterogeneity, where\nnon-Independent and Identically Distributed (non-IID) data across edge devices\nmay yield in significant accuracy drop. Furthermore, the limited computation\nand communication capabilities of edge devices increase the likelihood of\nstragglers, thus leading to slow model convergence. In this paper, we propose\nthe FedDHAD FL framework, which comes with two novel methods: Dynamic\nHeterogeneous model aggregation (FedDH) and Adaptive Dropout (FedAD). FedDH\ndynamically adjusts the weights of each local model within the model\naggregation process based on the non-IID degree of heterogeneous data to deal\nwith the statistical data heterogeneity. FedAD performs neuron-adaptive\noperations in response to heterogeneous devices to improve accuracy while\nachieving superb efficiency. The combination of these two methods makes FedDHAD\nsignificantly outperform state-of-the-art solutions in terms of accuracy (up to\n6.7% higher), efficiency (up to 2.02 times faster), and computation cost (up to\n15.0% smaller).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFedDHAD\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u542b\u52a8\u6001\u5f02\u6784\u6a21\u578b\u805a\u5408\u548c\u81ea\u9002\u5e94\u4e22\u5f03\u4e24\u79cd\u65b0\u65b9\u6cd5\uff0c\u5728\u51c6\u786e\u7387\u3001\u6548\u7387\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u6570\u636e\u5206\u5e03\u548c\u5f02\u6784\u6027\u6311\u6218\uff0c\u8fb9\u7f18\u8bbe\u5907\u6570\u636e\u975eIID\u4f1a\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u4e14\u8bbe\u5907\u8ba1\u7b97\u548c\u901a\u4fe1\u80fd\u529b\u6709\u9650\u4f1a\u4f7f\u6a21\u578b\u6536\u655b\u6162\u3002", "method": "\u63d0\u51faFedDHAD\u6846\u67b6\uff0c\u5305\u62ec\u52a8\u6001\u8c03\u6574\u672c\u5730\u6a21\u578b\u6743\u91cd\u7684FedDH\u548c\u5bf9\u5f02\u6784\u8bbe\u5907\u8fdb\u884c\u795e\u7ecf\u5143\u81ea\u9002\u5e94\u64cd\u4f5c\u7684FedAD\u3002", "result": "FedDHAD\u5728\u51c6\u786e\u7387\u4e0a\u6700\u9ad8\u63d0\u9ad86.7%\uff0c\u6548\u7387\u6700\u9ad8\u5feb2.02\u500d\uff0c\u8ba1\u7b97\u6210\u672c\u6700\u9ad8\u964d\u4f4e15.0%\u3002", "conclusion": "FedDHAD\u6846\u67b6\u5728\u5904\u7406\u8054\u90a6\u5b66\u4e60\u7684\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002"}}
{"id": "2507.09969", "pdf": "https://arxiv.org/pdf/2507.09969", "abs": "https://arxiv.org/abs/2507.09969", "authors": ["Zhongyu Ouyang", "Mingxuan Ju", "Soroush Vosoughi", "Yanfang Ye"], "title": "Non-parametric Graph Convolution for Re-ranking in Recommendation Systems", "categories": ["cs.IR"], "comment": "Accepted to RecSys2025 Main", "summary": "Graph knowledge has been proven effective in enhancing item rankings in\nrecommender systems (RecSys), particularly during the retrieval stage. However,\nits application in the ranking stage, especially when richer contextual\ninformation in user-item interactions is available, remains underexplored. A\nmajor challenge lies in the substantial computational cost associated with\nrepeatedly retrieving neighborhood information from billions of items stored in\ndistributed systems. This resource-intensive requirement makes it difficult to\nscale graph-based methods in practical RecSys. To bridge this gap, we first\ndemonstrate that incorporating graphs in the ranking stage improves ranking\nqualities. Notably, while the improvement is evident, we show that the\nsubstantial computational overheads entailed by graphs are prohibitively\nexpensive for real-world recommendations. In light of this, we propose a\nnon-parametric strategy that utilizes graph convolution for re-ranking only\nduring test time. Our strategy circumvents the notorious computational\noverheads from graph convolution during training, and utilizes structural\nknowledge hidden in graphs on-the-fly during testing. It can be used as a\nplug-and-play module and easily employed to enhance the ranking ability of\nvarious ranking layers of a real-world RecSys with significantly reduced\ncomputational overhead. Through comprehensive experiments across four benchmark\ndatasets with varying levels of sparsity, we demonstrate that our strategy\nyields noticeable improvements (i.e., 8.1% on average) during testing time with\nlittle to no additional computational overheads (i.e., 0.5 on average). Code:\nhttps://github.com/zyouyang/RecSys2025_NonParamGC.git", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u975e\u53c2\u6570\u7b56\u7565\uff0c\u5229\u7528\u56fe\u5377\u79ef\u5728\u6d4b\u8bd5\u65f6\u91cd\u6392\u5e8f\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u5e76\u63d0\u5347\u63a8\u8350\u6392\u540d\u8d28\u91cf\u3002", "motivation": "\u56fe\u77e5\u8bc6\u5728\u63a8\u8350\u7cfb\u7edf\u68c0\u7d22\u9636\u6bb5\u6709\u6548\uff0c\u4f46\u5728\u6392\u5e8f\u9636\u6bb5\u5e94\u7528\u5f85\u63a2\u7d22\uff0c\u4e14\u56fe\u8ba1\u7b97\u5f00\u9500\u5927\u96be\u4ee5\u6269\u5c55\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u975e\u53c2\u6570\u7b56\u7565\uff0c\u4ec5\u5728\u6d4b\u8bd5\u65f6\u7528\u56fe\u5377\u79ef\u91cd\u6392\u5e8f\uff0c\u89c4\u907f\u8bad\u7ec3\u65f6\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u7a00\u758f\u5ea6\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\uff0c\u6d4b\u8bd5\u65f6\u5e73\u5747\u63d0\u53478.1%\uff0c\u5e73\u5747\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u4ec50.5\u3002", "conclusion": "\u8be5\u7b56\u7565\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u63d0\u5347\u771f\u5b9e\u63a8\u8350\u7cfb\u7edf\u6392\u540d\u80fd\u529b\u3002"}}
{"id": "2507.09495", "pdf": "https://arxiv.org/pdf/2507.09495", "abs": "https://arxiv.org/abs/2507.09495", "authors": ["Hang Wang", "Junshan Zhang"], "title": "GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective", "categories": ["cs.AI", "cs.ET", "cs.HC", "cs.RO", "cs.SY", "eess.SY"], "comment": "Position paper", "summary": "Multi-agent reinforcement learning faces fundamental challenges that\nconventional approaches have failed to overcome: exponentially growing joint\naction spaces, non-stationary environments where simultaneous learning creates\nmoving targets, and partial observability that constrains coordination. Current\nmethods remain reactive, employing stimulus-response mechanisms that fail when\nfacing novel scenarios. We argue for a transformative paradigm shift from\nreactive to proactive multi-agent intelligence through generative AI-based\nreinforcement learning. This position advocates reconceptualizing agents not as\nisolated policy optimizers, but as sophisticated generative models capable of\nsynthesizing complex multi-agent dynamics and making anticipatory decisions\nbased on predictive understanding of future interactions. Rather than\nresponding to immediate observations, generative-RL agents can model\nenvironment evolution, predict other agents' behaviors, generate coordinated\naction sequences, and engage in strategic reasoning accounting for long-term\ndynamics. This approach leverages pattern recognition and generation\ncapabilities of generative AI to enable proactive decision-making, seamless\ncoordination through enhanced communication, and dynamic adaptation to evolving\nscenarios. We envision this paradigm shift will unlock unprecedented\npossibilities for distributed intelligence, moving beyond individual\noptimization toward emergent collective behaviors representing genuine\ncollaborative intelligence. The implications extend across autonomous systems,\nrobotics, and human-AI collaboration, promising solutions to coordination\nchallenges intractable under traditional reactive frameworks.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4ece\u53cd\u5e94\u5f0f\u5411\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u4e3b\u52a8\u5f0f\u8303\u5f0f\u8f6c\u53d8\uff0c\u4ee5\u5e94\u5bf9\u73b0\u6709\u6311\u6218\u5e76\u89e3\u9501\u5206\u5e03\u5f0f\u667a\u80fd\u65b0\u53ef\u80fd\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u6307\u6570\u589e\u957f\u3001\u73af\u5883\u975e\u5e73\u7a33\u548c\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7b49\u95ee\u9898\uff0c\u4e14\u5f53\u524d\u65b9\u6cd5\u5728\u65b0\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u5c06\u667a\u80fd\u4f53\u89c6\u4e3a\u80fd\u5408\u6210\u590d\u6742\u591a\u667a\u80fd\u4f53\u52a8\u6001\u5e76\u57fa\u4e8e\u9884\u6d4b\u505a\u51fa\u524d\u77bb\u6027\u51b3\u7b56\u7684\u751f\u6210\u6a21\u578b\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4f7f\u667a\u80fd\u4f53\u5efa\u6a21\u73af\u5883\u6f14\u53d8\u3001\u9884\u6d4b\u5176\u4ed6\u667a\u80fd\u4f53\u884c\u4e3a\u3001\u751f\u6210\u534f\u8c03\u52a8\u4f5c\u5e8f\u5217\u548c\u8fdb\u884c\u6218\u7565\u63a8\u7406\u3002", "conclusion": "\u8fd9\u79cd\u8303\u5f0f\u8f6c\u53d8\u5c06\u4e3a\u5206\u5e03\u5f0f\u667a\u80fd\u5e26\u6765\u524d\u6240\u672a\u6709\u7684\u53ef\u80fd\u6027\uff0c\u6709\u671b\u89e3\u51b3\u4f20\u7edf\u53cd\u5e94\u5f0f\u6846\u67b6\u4e0b\u96be\u4ee5\u89e3\u51b3\u7684\u534f\u8c03\u6311\u6218\uff0c\u5e94\u7528\u524d\u666f\u5e7f\u6cdb\u3002"}}
{"id": "2507.09220", "pdf": "https://arxiv.org/pdf/2507.09220", "abs": "https://arxiv.org/abs/2507.09220", "authors": ["Syed Tauhid Ullah Shah", "Mohammad Hussein", "Ann Barcomb", "Mohammad Moshirpour"], "title": "Explainability as a Compliance Requirement: What Regulated Industries Need from AI Tools for Design Artifact Generation", "categories": ["cs.SE"], "comment": null, "summary": "Artificial Intelligence (AI) tools for automating design artifact generation\nare increasingly used in Requirements Engineering (RE) to transform textual\nrequirements into structured diagrams and models. While these AI tools,\nparticularly those based on Natural Language Processing (NLP), promise to\nimprove efficiency, their adoption remains limited in regulated industries\nwhere transparency and traceability are essential. In this paper, we\ninvestigate the explainability gap in AI-driven design artifact generation\nthrough semi-structured interviews with ten practitioners from safety-critical\nindustries. We examine how current AI-based tools are integrated into workflows\nand the challenges arising from their lack of explainability. We also explore\nmitigation strategies, their impact on project outcomes, and features needed to\nimprove usability. Our findings reveal that non-explainable AI outputs\nnecessitate extensive manual validation, reduce stakeholder trust, struggle to\nhandle domain-specific terminology, disrupt team collaboration, and introduce\nregulatory compliance risks, often negating the anticipated efficiency\nbenefits. To address these issues, we identify key improvements, including\nsource tracing, providing clear justifications for tool-generated decisions,\nsupporting domain-specific adaptation, and enabling compliance validation. This\nstudy outlines a practical roadmap for improving the transparency, reliability,\nand applicability of AI tools in requirements engineering workflows,\nparticularly in regulated and safety-critical environments where explainability\nis crucial for adoption and certification.", "AI": {"tldr": "\u7814\u7a76AI\u9a71\u52a8\u7684\u8bbe\u8ba1\u5de5\u4ef6\u751f\u6210\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u5dee\u8ddd\uff0c\u6307\u51fa\u4e0d\u53ef\u89e3\u91caAI\u8f93\u51fa\u7684\u95ee\u9898\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\uff0c\u4e3aRE\u5de5\u4f5c\u6d41\u6539\u8fdb\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002", "motivation": "AI\u5de5\u5177\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u867d\u6709\u63d0\u6548\u6f5c\u529b\uff0c\u4f46\u5728\u76d1\u7ba1\u884c\u4e1a\u56e0\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u5bfc\u81f4\u5e94\u7528\u53d7\u9650\uff0c\u9700\u7814\u7a76\u89e3\u51b3\u3002", "method": "\u5bf9\u5b89\u5168\u5173\u952e\u884c\u4e1a\u7684\u5341\u540d\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u7814\u7a76\u5f53\u524dAI\u5de5\u5177\u96c6\u6210\u5de5\u4f5c\u6d41\u60c5\u51b5\u3001\u53ef\u89e3\u91ca\u6027\u7f3a\u5931\u7684\u6311\u6218\u53ca\u5e94\u5bf9\u7b56\u7565\u3002", "result": "\u4e0d\u53ef\u89e3\u91ca\u7684AI\u8f93\u51fa\u9700\u5927\u91cf\u624b\u52a8\u9a8c\u8bc1\u3001\u964d\u4f4e\u5229\u76ca\u76f8\u5173\u8005\u4fe1\u4efb\u3001\u96be\u5904\u7406\u7279\u5b9a\u9886\u57df\u672f\u8bed\u3001\u7834\u574f\u56e2\u961f\u534f\u4f5c\u5e76\u5e26\u6765\u5408\u89c4\u98ce\u9669\uff0c\u62b5\u6d88\u9884\u671f\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u786e\u5b9a\u5173\u952e\u6539\u8fdb\u65b9\u5411\uff0c\u4e3a\u9700\u6c42\u5de5\u7a0b\u5de5\u4f5c\u6d41\u4e2dAI\u5de5\u5177\u5728\u76d1\u7ba1\u548c\u5b89\u5168\u5173\u952e\u73af\u5883\u7684\u5e94\u7528\u63d0\u4f9b\u5b9e\u7528\u8def\u7ebf\u56fe\u3002"}}
{"id": "2507.08843", "pdf": "https://arxiv.org/pdf/2507.08843", "abs": "https://arxiv.org/abs/2507.08843", "authors": ["Arpita Soni", "Sahil Tripathi", "Gautam Siddharth Kashyap", "Manaswi Kulahara", "Mohammad Anas Azeez", "Zohaib Hasan Siddiqui", "Nipun Joshi", "Jiechao Gao"], "title": "Can We Predict Your Next Move Without Breaking Your Privacy?", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in the 17th International Conference on Advances in Social\n  Networks Analysis and Mining (ASONAM 2025), scheduled for 25 - 28 August 2025\n  in Ontario, Canada", "summary": "We propose FLLL3M--Federated Learning with Large Language Models for Mobility\nModeling--a privacy-preserving framework for Next-Location Prediction (NxLP).\nBy retaining user data locally and leveraging LLMs through an efficient outer\nproduct mechanism, FLLL3M ensures high accuracy with low resource demands. It\nachieves SOT results on Gowalla (Acc@1: 12.55, MRR: 0.1422), WeePlace (10.71,\n0.1285), Brightkite (10.42, 0.1169), and FourSquare (8.71, 0.1023), while\nreducing parameters by up to 45.6% and memory usage by 52.7%.", "AI": {"tldr": "\u63d0\u51faFLLL3M\u6846\u67b6\u7528\u4e8eNxLP\uff0c\u80fd\u5728\u4fdd\u62a4\u9690\u79c1\u4e0b\u786e\u4fdd\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u8d44\u6e90\u9700\u6c42\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u53d6\u5f97SOT\u7ed3\u679c\u5e76\u51cf\u5c11\u53c2\u6570\u548c\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u6784\u5efa\u9690\u79c1\u4fdd\u62a4\u7684Next - Location Prediction\u6846\u67b6\u3002", "method": "\u63d0\u51faFLLL3M\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u5916\u79ef\u673a\u5236\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u7528\u6237\u6570\u636e\u4fdd\u7559\u5728\u672c\u5730\u3002", "result": "\u5728Gowalla\u3001WeePlace\u3001Brightkite\u548cFourSquare\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOT\u7ed3\u679c\uff0cAcc@1\u548cMRR\u8868\u73b0\u826f\u597d\uff0c\u540c\u65f6\u51cf\u5c11\u53c2\u657045.6%\u3001\u5185\u5b58\u4f7f\u752852.7%\u3002", "conclusion": "FLLL3M\u6846\u67b6\u5728Next - Location Prediction\u4e2d\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u8d44\u6e90\u9700\u6c42\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.09828", "pdf": "https://arxiv.org/pdf/2507.09828", "abs": "https://arxiv.org/abs/2507.09828", "authors": ["Shion Takeno", "Yu Inatsu", "Masayuki Karasuyama", "Ichiro Takeuchi"], "title": "Regret Analysis of Posterior Sampling-Based Expected Improvement for Bayesian Optimization", "categories": ["stat.ML", "cs.LG"], "comment": "35pages, 5 figures", "summary": "Bayesian optimization is a powerful tool for optimizing an\nexpensive-to-evaluate black-box function. In particular, the effectiveness of\nexpected improvement (EI) has been demonstrated in a wide range of\napplications. However, theoretical analyses of EI are limited compared with\nother theoretically established algorithms. This paper analyzes a randomized\nvariant of EI, which evaluates the EI from the maximum of the posterior sample\npath. We show that this posterior sampling-based random EI achieves the\nsublinear Bayesian cumulative regret bounds under the assumption that the\nblack-box function follows a Gaussian process. Finally, we demonstrate the\neffectiveness of the proposed method through numerical experiments.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u57fa\u4e8e\u540e\u9a8c\u91c7\u6837\u7684\u968f\u673aEI\uff0c\u8bc1\u660e\u5176\u5728\u9ad8\u65af\u8fc7\u7a0b\u5047\u8bbe\u4e0b\u6709\u6b21\u7ebf\u6027\u8d1d\u53f6\u65af\u7d2f\u79ef\u9057\u61be\u754c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9\u671f\u671b\u6539\u8fdb\uff08EI\uff09\u7684\u7406\u8bba\u5206\u6790\u76f8\u6bd4\u5176\u4ed6\u7b97\u6cd5\u6709\u9650\uff0c\u9700\u52a0\u5f3a\u5bf9EI\u7684\u7406\u8bba\u7814\u7a76\u3002", "method": "\u5206\u6790\u4e00\u79cd\u968f\u673a\u5316\u7684EI\u53d8\u4f53\uff0c\u4ece\u540e\u9a8c\u6837\u672c\u8def\u5f84\u7684\u6700\u5927\u503c\u8bc4\u4f30EI\u3002", "result": "\u8be5\u57fa\u4e8e\u540e\u9a8c\u91c7\u6837\u7684\u968f\u673aEI\u5728\u9ed1\u7bb1\u51fd\u6570\u9075\u5faa\u9ad8\u65af\u8fc7\u7a0b\u7684\u5047\u8bbe\u4e0b\uff0c\u5b9e\u73b0\u4e86\u6b21\u7ebf\u6027\u8d1d\u53f6\u65af\u7d2f\u79ef\u9057\u61be\u754c\u3002", "conclusion": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.09998", "pdf": "https://arxiv.org/pdf/2507.09998", "abs": "https://arxiv.org/abs/2507.09998", "authors": ["Jie Guo", "Jiahao Jiang", "Ziyuan Guo", "Bin Song", "Yue Sun"], "title": "SLIF-MR: Self-loop Iterative Fusion of Heterogeneous Auxiliary Information for Multimodal Recommendation", "categories": ["cs.IR"], "comment": "10 pages,7 figures", "summary": "Knowledge graphs (KGs) and multimodal item information, which respectively\ncapture relational and attribute features, play a crucial role in improving\nrecommender system accuracy. Recent studies have attempted to integrate them\nvia multimodal knowledge graphs (MKGs) to further enhance recommendation\nperformance. However, existing methods typically freeze the MKG structure\nduring training, which limits the full integration of structural information\nfrom heterogeneous graphs (e.g., KG and user-item interaction graph), and\nresults in sub-optimal performance. To address this challenge, we propose a\nnovel framework, termed Self-loop Iterative Fusion of Heterogeneous Auxiliary\nInformation for Multimodal Recommendation (SLIF-MR), which leverages item\nrepresentations from previous training epoch as feedback signals to dynamically\noptimize the heterogeneous graph structures composed of KG, multimodal item\nfeature graph, and user-item interaction graph. Through this iterative fusion\nmechanism, both user and item representations are refined, thus improving the\nfinal recommendation performance. Specifically, based on the feedback item\nrepresentations, SLIF-MR constructs an item-item correlation graph, then\nintegrated into the establishment process of heterogeneous graphs as additional\nnew structural information in a self-loop manner. Consequently, the internal\nstructures of heterogeneous graphs are updated with the feedback item\nrepresentations during training. Moreover, a semantic consistency learning\nstrategy is proposed to align heterogeneous item representations across\nmodalities. The experimental results show that SLIF-MR significantly\noutperforms existing methods, particularly in terms of accuracy and robustness.", "AI": {"tldr": "\u63d0\u51faSLIF - MR\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u9988\u4fe1\u53f7\u52a8\u6001\u4f18\u5316\u5f02\u6784\u56fe\u7ed3\u6784\uff0c\u7ed3\u5408\u8bed\u4e49\u4e00\u81f4\u6027\u5b66\u4e60\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\uff08MKG\uff09\u65b9\u6cd5\u5728\u8bad\u7ec3\u65f6\u51bb\u7ed3MKG\u7ed3\u6784\uff0c\u9650\u5236\u5f02\u6784\u56fe\u7ed3\u6784\u4fe1\u606f\u878d\u5408\uff0c\u5bfc\u81f4\u6027\u80fd\u6b20\u4f73\u3002", "method": "\u63d0\u51faSLIF - MR\u6846\u67b6\uff0c\u5229\u7528\u524d\u4e00\u8bad\u7ec3\u8f6e\u6b21\u7684\u9879\u76ee\u8868\u793a\u4f5c\u4e3a\u53cd\u9988\u4fe1\u53f7\u52a8\u6001\u4f18\u5316\u5f02\u6784\u56fe\u7ed3\u6784\uff0c\u6784\u5efa\u9879\u76ee - \u9879\u76ee\u5173\u8054\u56fe\u5e76\u4ee5\u81ea\u5faa\u73af\u65b9\u5f0f\u878d\u5165\u5f02\u6784\u56fe\u5efa\u7acb\u8fc7\u7a0b\uff0c\u540c\u65f6\u63d0\u51fa\u8bed\u4e49\u4e00\u81f4\u6027\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eSLIF - MR\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u3002", "conclusion": "SLIF - MR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u80fd\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2507.09534", "pdf": "https://arxiv.org/pdf/2507.09534", "abs": "https://arxiv.org/abs/2507.09534", "authors": ["Guanquan Wang", "Takuya Hiraoka", "Yoshimasa Tsuruoka"], "title": "Consistency Trajectory Planning: High-Quality and Efficient Trajectory Optimization for Offline Model-Based Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "This paper introduces Consistency Trajectory Planning (CTP), a novel offline\nmodel-based reinforcement learning method that leverages the recently proposed\nConsistency Trajectory Model (CTM) for efficient trajectory optimization. While\nprior work applying diffusion models to planning has demonstrated strong\nperformance, it often suffers from high computational costs due to iterative\nsampling procedures. CTP supports fast, single-step trajectory generation\nwithout significant degradation in policy quality. We evaluate CTP on the D4RL\nbenchmark and show that it consistently outperforms existing diffusion-based\nplanning methods in long-horizon, goal-conditioned tasks. Notably, CTP achieves\nhigher normalized returns while using significantly fewer denoising steps. In\nparticular, CTP achieves comparable performance with over $120\\times$ speedup\nin inference time, demonstrating its practicality and effectiveness for\nhigh-performance, low-latency offline planning.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u79bb\u7ebf\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5CTP\uff0c\u652f\u6301\u5feb\u901f\u5355\u6b65\u8f68\u8ff9\u751f\u6210\uff0c\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u63a8\u7406\u901f\u5ea6\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u5148\u524d\u5c06\u6269\u6563\u6a21\u578b\u5e94\u7528\u4e8e\u89c4\u5212\u65f6\u56e0\u8fed\u4ee3\u91c7\u6837\u7a0b\u5e8f\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165Consistency Trajectory Planning (CTP)\u65b9\u6cd5\uff0c\u5229\u7528Consistency Trajectory Model (CTM)\u8fdb\u884c\u9ad8\u6548\u8f68\u8ff9\u4f18\u5316\u3002", "result": "\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCTP\u5728\u957f\u89c6\u91ce\u3001\u76ee\u6807\u6761\u4ef6\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u5728\u4f7f\u7528\u66f4\u5c11\u53bb\u566a\u6b65\u9aa4\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u66f4\u9ad8\u5f52\u4e00\u5316\u56de\u62a5\uff0c\u63a8\u7406\u65f6\u95f4\u6709\u8d85120\u500d\u7684\u52a0\u901f\u3002", "conclusion": "CTP\u5177\u6709\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u9ad8\u6027\u80fd\u3001\u4f4e\u5ef6\u8fdf\u7684\u79bb\u7ebf\u89c4\u5212\u3002"}}
{"id": "2507.09012", "pdf": "https://arxiv.org/pdf/2507.09012", "abs": "https://arxiv.org/abs/2507.09012", "authors": ["Sara Moore", "Jonathan P. Sorenson"], "title": "Explicit Bounds and Parallel Algorithms for Counting Multiply Gleeful Numbers", "categories": ["math.NT", "cs.DS", "11A41, 11Y16, 68Q25", "F.2.1"], "comment": null, "summary": "Let $k\\ge 1$ be an integer. A positive integer $n$ is $k$-\\textit{gleeful} if\n$n$ can be represented as the sum of $k$th powers of consecutive primes. For\nexample, $35=2^3+3^3$ is a $3$-gleeful number, and $195=5^2+7^2+11^2$ is\n$2$-gleeful. In this paper, we present some new results on $k$-gleeful numbers\nfor $k>1$.\n  First, we extend previous analytical work. For given values of $x$ and $k$,\nwe give explicit upper and lower bounds on the number of $k$-gleeful\nrepresentations of integers $n\\le x$.\n  Second, we describe and analyze two new, efficient parallel algorithms, one\ntheoretical and one practical, to generate all $k$-gleeful representations up\nto a bound $x$.\n  Third, we study integers that are multiply gleeful, that is, integers with\nmore than one representation as a sum of powers of consecutive primes,\nincluding both the same or different values of $k$. We give a simple heuristic\nmodel for estimating the density of multiply-gleeful numbers, we present\nempirical data in support of our heuristics, and offer some new conjectures.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76k - gleeful\u6570\uff08k > 1\uff09\uff0c\u7ed9\u51fa\u8868\u793a\u6570\u4e0a\u4e0b\u754c\uff0c\u63d0\u51fa\u5e76\u884c\u7b97\u6cd5\u751f\u6210\u8868\u793a\uff0c\u7814\u7a76\u591a\u8868\u793a\u7684\u60c5\u5f62\u5e76\u7ed9\u51fa\u542f\u53d1\u5f0f\u6a21\u578b\u53ca\u731c\u60f3\u3002", "motivation": "\u6df1\u5165\u7814\u7a76k - gleeful\u6570\u7684\u6027\u8d28\uff0c\u7279\u522b\u662f\u5bf9\u4e8ek > 1\u7684\u60c5\u51b5\uff0c\u62d3\u5c55\u76f8\u5173\u7406\u8bba\u548c\u5e94\u7528\u3002", "method": "\u6269\u5c55\u5148\u524d\u5206\u6790\u5de5\u4f5c\uff1b\u8bbe\u8ba1\u5e76\u5206\u6790\u4e24\u4e2a\u5e76\u884c\u7b97\u6cd5\uff1b\u5efa\u7acb\u542f\u53d1\u5f0f\u6a21\u578b\u7814\u7a76\u591a\u8868\u793a\u6570\u3002", "result": "\u5f97\u5230k - gleeful\u8868\u793a\u6570\u7684\u4e0a\u4e0b\u754c\uff1b\u63d0\u51fa\u6709\u6548\u5e76\u884c\u7b97\u6cd5\uff1b\u7ed9\u51fa\u591a\u8868\u793a\u6570\u5bc6\u5ea6\u7684\u542f\u53d1\u5f0f\u6a21\u578b\u53ca\u5b9e\u8bc1\u6570\u636e\u3002", "conclusion": "\u5bf9k - gleeful\u6570\u6709\u4e86\u66f4\u6df1\u5165\u7684\u8ba4\u8bc6\uff0c\u63d0\u51fa\u65b0\u7684\u7b97\u6cd5\u548c\u731c\u60f3\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2507.09315", "pdf": "https://arxiv.org/pdf/2507.09315", "abs": "https://arxiv.org/abs/2507.09315", "authors": ["Yongqian Sun", "Weihua Kuang", "Chao Shen", "Xidao Wen", "Tinghua Zheng", "Heng Liu", "Shenglin Zhang", "Bo Wu", "Dan Pei"], "title": "Enhancing Interpretability in Software Change Management with Chain-of-Thought Reasoning", "categories": ["cs.SE", "cs.AI"], "comment": "22 pages, 19 figures", "summary": "In modern online services, frequent software changes introduce significant\nrisks. To tackle this challenge, we propose SCELM (Software Change Evaluation\nand Lifecycle Management), an end-to-end automated framework for software\nchange management. SCELM aims to manage software changes efficiently and\nprecisely, significantly reducing service failures and economic losses.", "AI": {"tldr": "\u63d0\u51faSCELM\u6846\u67b6\u7528\u4e8e\u8f6f\u4ef6\u53d8\u66f4\u7ba1\u7406\uff0c\u51cf\u5c11\u670d\u52a1\u6545\u969c\u548c\u7ecf\u6d4e\u635f\u5931\u3002", "motivation": "\u73b0\u4ee3\u5728\u7ebf\u670d\u52a1\u4e2d\u9891\u7e41\u8f6f\u4ef6\u53d8\u66f4\u5e26\u6765\u91cd\u5927\u98ce\u9669\uff0c\u9700\u6709\u6548\u5e94\u5bf9\u3002", "method": "\u63d0\u51faSCELM\u8fd9\u4e00\u7528\u4e8e\u8f6f\u4ef6\u53d8\u66f4\u7ba1\u7406\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u6846\u67b6\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u76ee\u6807\u662f\u9ad8\u6548\u7cbe\u51c6\u7ba1\u7406\u8f6f\u4ef6\u53d8\u66f4\uff0c\u51cf\u5c11\u670d\u52a1\u6545\u969c\u548c\u7ecf\u6d4e\u635f\u5931\u3002", "conclusion": "SCELM\u80fd\u5e2e\u52a9\u7ba1\u7406\u8f6f\u4ef6\u53d8\u66f4\uff0c\u964d\u4f4e\u76f8\u5173\u98ce\u9669\u3002"}}
{"id": "2507.08845", "pdf": "https://arxiv.org/pdf/2507.08845", "abs": "https://arxiv.org/abs/2507.08845", "authors": ["Irfan Ullah", "Young-Koo Lee"], "title": "DAFOS: Dynamic Adaptive Fanout Optimization Sampler", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) are becoming an essential tool for learning from\ngraph-structured data, however uniform neighbor sampling and static fanout\nsettings frequently limit GNNs' scalability and efficiency. In this paper, we\npropose the Dynamic Adaptive Fanout Optimization Sampler (DAFOS), a novel\napproach that dynamically adjusts the fanout based on model performance and\nprioritizes important nodes during training. Our approach leverages node\nscoring based on node degree to focus computational resources on structurally\nimportant nodes, incrementing the fanout as the model training progresses.\nDAFOS also integrates an early stopping mechanism to halt training when\nperformance gains diminish. Experiments conducted on three benchmark datasets,\nogbnarxiv, Reddit, and ogbn-products, demonstrate that our approach\nsignificantly improves training speed and accuracy compared to a\nstate-of-the-art approach. DAFOS achieves a 3.57x speedup on the ogbn-arxiv\ndataset and a 12.6x speedup on the Reddit dataset while improving the F1 score\nfrom 68.5% to 71.21% on ogbn-arxiv and from 73.78% to 76.88% on the\nogbn-products dataset, respectively. These results highlight the potential of\nDAFOS as an efficient and scalable solution for large-scale GNN training.", "AI": {"tldr": "\u63d0\u51faDAFOS\u65b9\u6cd5\u52a8\u6001\u8c03\u6574GNN\u8bad\u7ec3\u7684\u6247\u51fa\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u548c\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u5747\u5300\u90bb\u5c45\u91c7\u6837\u548c\u9759\u6001\u6247\u51fa\u8bbe\u7f6e\u9650\u5236GNN\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u6a21\u578b\u6027\u80fd\u52a8\u6001\u8c03\u6574\u6247\u51fa\uff0c\u6839\u636e\u8282\u70b9\u5ea6\u5bf9\u8282\u70b9\u6253\u5206\uff0c\u805a\u7126\u91cd\u8981\u8282\u70b9\uff0c\u8bad\u7ec3\u4e2d\u589e\u52a0\u6247\u51fa\uff0c\u96c6\u6210\u65e9\u671f\u505c\u6b62\u673a\u5236\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u548c\u51c6\u786e\u7387\uff0c\u5982\u5728ogbn - arxiv\u6570\u636e\u96c6\u4e0a\u52a0\u901f3.57\u500d\uff0c\u5728Reddit\u6570\u636e\u96c6\u4e0a\u52a0\u901f12.6\u500d\uff0c\u63d0\u9ad8\u4e86F1\u5206\u6570\u3002", "conclusion": "DAFOS\u662f\u5927\u89c4\u6a21GNN\u8bad\u7ec3\u7684\u9ad8\u6548\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10154", "pdf": "https://arxiv.org/pdf/2507.10154", "abs": "https://arxiv.org/abs/2507.10154", "authors": ["Ricardo In\u00e1cio", "Zafeiris Kokkinogenis", "Vitor Cerqueira", "Carlos Soares"], "title": "Simulating Biases for Interpretable Fairness in Offline and Online Classifiers", "categories": ["stat.ML", "cs.LG"], "comment": "17 pages, 2 figures, 1 equation, 3 tables: 1 in main body and 2 in\n  the appendix. Submitted to the SynDAiTE: Synthetic Data for AI\n  Trustworthiness and Evolution workshop from ECMLPKDD 2025, anonymized", "summary": "Predictive models often reinforce biases which were originally embedded in\ntheir training data, through skewed decisions. In such cases, mitigation\nmethods are critical to ensure that, regardless of the prevailing disparities,\nmodel outcomes are adjusted to be fair. To assess this, datasets could be\nsystematically generated with specific biases, to train machine learning\nclassifiers. Then, predictive outcomes could aid in the understanding of this\nbias embedding process. Hence, an agent-based model (ABM), depicting a loan\napplication process that represents various systemic biases across two\ndemographic groups, was developed to produce synthetic datasets. Then, by\napplying classifiers trained on them to predict loan outcomes, we can assess\nhow biased data leads to unfairness. This highlights a main contribution of\nthis work: a framework for synthetic dataset generation with controllable bias\ninjection. We also contribute with a novel explainability technique, which\nshows how mitigations affect the way classifiers leverage data features, via\nsecond-order Shapley values. In experiments, both offline and online learning\napproaches are employed. Mitigations are applied at different stages of the\nmodelling pipeline, such as during pre-processing and in-processing.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u578b\u751f\u6210\u542b\u7279\u5b9a\u504f\u5dee\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u504f\u5dee\u6570\u636e\u5bfc\u81f4\u7684\u4e0d\u516c\u5e73\uff0c\u63d0\u51fa\u53ef\u63a7\u504f\u5dee\u6ce8\u5165\u7684\u6570\u636e\u96c6\u751f\u6210\u6846\u67b6\u548c\u65b0\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u5e76\u5728\u4e0d\u540c\u5b66\u4e60\u65b9\u5f0f\u548c\u5efa\u6a21\u9636\u6bb5\u5e94\u7528\u7f13\u89e3\u63aa\u65bd\u3002", "motivation": "\u9884\u6d4b\u6a21\u578b\u5e38\u5f3a\u5316\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u504f\u5dee\uff0c\u9700\u8981\u7f13\u89e3\u65b9\u6cd5\u786e\u4fdd\u6a21\u578b\u7ed3\u679c\u516c\u5e73\uff0c\u56e0\u6b64\u8981\u8bc4\u4f30\u504f\u5dee\u5d4c\u5165\u8fc7\u7a0b\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u578b\u751f\u6210\u542b\u7cfb\u7edf\u504f\u5dee\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5e94\u7528\u5206\u7c7b\u5668\u9884\u6d4b\u8d37\u6b3e\u7ed3\u679c\uff1b\u91c7\u7528\u79bb\u7ebf\u548c\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u5efa\u6a21\u4e0d\u540c\u9636\u6bb5\u5e94\u7528\u7f13\u89e3\u63aa\u65bd\uff1b\u4f7f\u7528\u4e8c\u9636Shapley\u503c\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u3002", "result": "\u63d0\u51fa\u53ef\u63a7\u504f\u5dee\u6ce8\u5165\u7684\u5408\u6210\u6570\u636e\u96c6\u751f\u6210\u6846\u67b6\u548c\u65b0\u7684\u53ef\u89e3\u91ca\u6027\u6280\u672f\u3002", "conclusion": "\u901a\u8fc7\u751f\u6210\u542b\u504f\u5dee\u7684\u5408\u6210\u6570\u636e\u96c6\u8bc4\u4f30\u504f\u5dee\u5d4c\u5165\u8fc7\u7a0b\uff0c\u6240\u63d0\u6846\u67b6\u548c\u6280\u672f\u6709\u52a9\u4e8e\u7f13\u89e3\u6a21\u578b\u504f\u5dee\u3002"}}
{"id": "2507.10057", "pdf": "https://arxiv.org/pdf/2507.10057", "abs": "https://arxiv.org/abs/2507.10057", "authors": ["Sangwoo Park", "Jinheon Baek", "Soyeong Jeong", "Sung Ju Hwang"], "title": "PRISM: Fine-Grained Paper-to-Paper Retrieval with Multi-Aspect-Aware Query Optimization", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Scientific paper retrieval, particularly framed as document-to-document\nretrieval, aims to identify relevant papers in response to a long-form query\npaper, rather than a short query string. Previous approaches to this task have\nfocused on abstracts, embedding them into dense vectors as surrogates for full\ndocuments and calculating similarity across them, although abstracts provide\nonly sparse and high-level summaries. To address this, we propose PRISM, a\nnovel document-to-document retrieval method that introduces multiple,\nfine-grained representations for both the query and candidate papers. In\nparticular, each query paper is decomposed into multiple aspect-specific views\nand individually embedded, which are then matched against candidate papers\nsimilarity segmented to consider their multifaceted dimensions. Moreover, we\npresent SciFullBench, a novel benchmark in which the complete and segmented\ncontext of full papers for both queries and candidates is available. Then,\nexperimental results show that PRISM improves performance by an average of 4.3%\nover existing retrieval baselines.", "AI": {"tldr": "\u63d0\u51faPRISM\u6587\u6863\u68c0\u7d22\u65b9\u6cd5\u548cSciFullBench\u57fa\u51c6\uff0c\u5b9e\u9a8c\u8868\u660ePRISM\u8f83\u73b0\u6709\u57fa\u7ebf\u5e73\u5747\u6027\u80fd\u63d0\u53474.3%", "motivation": "\u4ee5\u5f80\u6587\u6863\u68c0\u7d22\u65b9\u6cd5\u805a\u7126\u6458\u8981\uff0c\u6458\u8981\u4ec5\u63d0\u4f9b\u7a00\u758f\u548c\u9ad8\u5c42\u7ea7\u603b\u7ed3\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u95ee\u9898", "method": "\u63d0\u51faPRISM\u65b9\u6cd5\uff0c\u5c06\u67e5\u8be2\u8bba\u6587\u5206\u89e3\u4e3a\u591a\u65b9\u9762\u7279\u5b9a\u89c6\u56fe\u5e76\u5355\u72ec\u5d4c\u5165\uff0c\u4e0e\u5019\u9009\u8bba\u6587\u5339\u914d\uff1b\u63d0\u51faSciFullBench\u57fa\u51c6\uff0c\u63d0\u4f9b\u5b8c\u6574\u548c\u5206\u6bb5\u4e0a\u4e0b\u6587", "result": "PRISM\u8f83\u73b0\u6709\u68c0\u7d22\u57fa\u7ebf\u5e73\u5747\u6027\u80fd\u63d0\u53474.3%", "conclusion": "PRISM\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u79d1\u5b66\u8bba\u6587\u68c0\u7d22\u6027\u80fd"}}
{"id": "2507.09540", "pdf": "https://arxiv.org/pdf/2507.09540", "abs": "https://arxiv.org/abs/2507.09540", "authors": ["Ali Safa", "Farida Mohsen", "Ali Al-Zawqari"], "title": "Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Spiking Neural Networks (SNNs) offer biologically inspired, energy-efficient\nalternatives to traditional Deep Neural Networks (DNNs) for real-time control\nsystems. However, their training presents several challenges, particularly for\nreinforcement learning (RL) tasks, due to the non-differentiable nature of\nspike-based communication. In this work, we introduce what is, to our\nknowledge, the first framework that employs Metropolis-Hastings (MH) sampling,\na Bayesian inference technique, to train SNNs for dynamical agent control in RL\nenvironments without relying on gradient-based methods. Our approach\niteratively proposes and probabilistically accepts network parameter updates\nbased on accumulated reward signals, effectively circumventing the limitations\nof backpropagation while enabling direct optimization on neuromorphic\nplatforms. We evaluated this framework on two standard control benchmarks:\nAcroBot and CartPole. The results demonstrate that our MH-based approach\noutperforms conventional Deep Q-Learning (DQL) baselines and prior SNN-based RL\napproaches in terms of maximizing the accumulated reward while minimizing\nnetwork resources and training episodes.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4f7f\u7528Metropolis - Hastings\u91c7\u6837\u8bad\u7ec3SNN\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u667a\u80fd\u4f53\u63a7\u5236\u7684\u6846\u67b6\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u5728\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u8bad\u7ec3\u4e2d\u56e0\u8109\u51b2\u901a\u4fe1\u4e0d\u53ef\u5fae\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8eMetropolis - Hastings\u91c7\u6837\u7684\u6846\u67b6\uff0c\u8fed\u4ee3\u63d0\u51fa\u5e76\u57fa\u4e8e\u7d2f\u79ef\u5956\u52b1\u4fe1\u53f7\u6982\u7387\u6027\u63a5\u53d7\u7f51\u7edc\u53c2\u6570\u66f4\u65b0\u3002", "result": "\u5728AcroBot\u548cCartPole\u4e24\u4e2a\u6807\u51c6\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eMH\u7684\u65b9\u6cd5\u5728\u6700\u5927\u5316\u7d2f\u79ef\u5956\u52b1\u3001\u6700\u5c0f\u5316\u7f51\u7edc\u8d44\u6e90\u548c\u8bad\u7ec3\u5468\u671f\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6Q\u5b66\u4e60\uff08DQL\uff09\u57fa\u7ebf\u548c\u5148\u524d\u57fa\u4e8eSNN\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8eMetropolis - Hastings\u91c7\u6837\u7684\u6846\u67b6\u80fd\u6709\u6548\u8bad\u7ec3SNN\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u667a\u80fd\u4f53\u63a7\u5236\uff0c\u907f\u514d\u53cd\u5411\u4f20\u64ad\u7684\u5c40\u9650\uff0c\u53ef\u5728\u795e\u7ecf\u5f62\u6001\u5e73\u53f0\u4e0a\u76f4\u63a5\u4f18\u5316\u3002"}}
{"id": "2507.09283", "pdf": "https://arxiv.org/pdf/2507.09283", "abs": "https://arxiv.org/abs/2507.09283", "authors": ["Tiziana Calamoneri", "Federico Cor\u00f2", "Neeldhara Misra", "Saraswati G. Nanoti", "Giacomo Paesani"], "title": "m-Eternal Domination and Variants on Some Classes of Finite and Infinite Graphs", "categories": ["cs.DM", "cs.CC", "cs.DS", "math.CO", "05C85, 68R10", "G.2.2"], "comment": "Accepted for presentation at FCT 2025", "summary": "We study the m-Eternal Domination problem, which is the following two-player\ngame between a defender and an attacker on a graph: initially, the defender\npositions k guards on vertices of the graph; the game then proceeds in turns\nbetween the defender and the attacker, with the attacker selecting a vertex and\nthe defender responding to the attack by moving a guard to the attacked vertex.\nThe defender may move more than one guard on their turn, but guards can only\nmove to neighboring vertices. The defender wins a game on a graph G with k\nguards if the defender has a strategy such that at every point of the game the\nvertices occupied by guards form a dominating set of G and the attacker wins\notherwise. The m-eternal domination number of a graph G is the smallest value\nof k for which (G,k) is a defender win.\n  We show that m-Eternal Domination is NP-hard, as well as some of its\nvariants, even on special classes of graphs. We also show structural results\nfor the Domination and m-Eternal Domination problems in the context of four\ntypes of infinite regular grids: square, octagonal, hexagonal, and triangular,\nestablishing tight bounds.", "AI": {"tldr": "\u7814\u7a76\u56fe\u4e0a\u7684m - \u6c38\u6052\u652f\u914d\u95ee\u9898\uff0c\u8bc1\u660e\u5176NP - \u96be\uff0c\u8fd8\u7ed9\u51fa\u56db\u7c7b\u65e0\u9650\u89c4\u5219\u7f51\u683c\u56fe\u4e0a\u652f\u914d\u548cm - \u6c38\u6052\u652f\u914d\u95ee\u9898\u7684\u7ed3\u6784\u7ed3\u679c\u3002", "motivation": "\u5bf9\u56fe\u4e0a\u7684m - \u6c38\u6052\u652f\u914d\u95ee\u9898\u8fdb\u884c\u7814\u7a76\uff0c\u63a2\u7d22\u5176\u590d\u6742\u5ea6\u548c\u7ed3\u6784\u6027\u8d28\u3002", "method": "\u5bf9m - \u6c38\u6052\u652f\u914d\u95ee\u9898\u53ca\u5176\u53d8\u4f53\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u56db\u7c7b\u65e0\u9650\u89c4\u5219\u7f51\u683c\u56fe\u3002", "result": "\u8bc1\u660em - \u6c38\u6052\u652f\u914d\u95ee\u9898\u53ca\u5176\u4e00\u4e9b\u53d8\u4f53\u662fNP - \u96be\u7684\uff0c\u7ed9\u51fa\u56db\u7c7b\u65e0\u9650\u89c4\u5219\u7f51\u683c\u56fe\u4e0a\u7684\u7ed3\u6784\u7ed3\u679c\u548c\u7d27\u754c\u3002", "conclusion": "m - \u6c38\u6052\u652f\u914d\u95ee\u9898\u5177\u6709NP - \u96be\u7684\u590d\u6742\u5ea6\uff0c\u5728\u7279\u5b9a\u65e0\u9650\u89c4\u5219\u7f51\u683c\u56fe\u4e0a\u6709\u660e\u786e\u7684\u7ed3\u6784\u6027\u8d28\u3002"}}
{"id": "2507.09414", "pdf": "https://arxiv.org/pdf/2507.09414", "abs": "https://arxiv.org/abs/2507.09414", "authors": ["Khizra Sohail", "Atif Aftab Ahmed Jilani", "Nigar Azhar Butt"], "title": "Enhancing NeuroEvolution-Based Game Testing: A Branch Coverage Approach for Scratch Programs", "categories": ["cs.SE"], "comment": null, "summary": "Automated test generation for game-like programs presents unique challenges\ndue to their non-deterministic behavior and complex control structures. The\nNEATEST framework has been used for automated testing in Scratch games,\nemploying neuroevolution-based test generation optimized for statement\ncoverage. However, statement coverage alone is often insufficient for fault\ndetection, as it does not guarantee execution of all logical branches. This\npaper introduces a branch coverage-based fitness function to enhance test\neffectiveness in automated game testing. We extend NEATEST by integrating a\nbranch fitness function that prioritizes control-dependent branches, guiding\nthe neuroevolution process to maximize branch exploration. To evaluate the\neffectiveness of this approach, empirical experiments were conducted on 25\nScratch games, comparing Neatest with Statement Coverage (NSC) against Neatest\nwith Branch Coverage (NBC). A mutation analysis was also performed to assess\nthe fault detection capabilities of both techniques. The results demonstrate\nthat NBC achieves higher branch coverage than NSC in 13 out of 25 games,\nparticularly in programs with complex conditional structures. Moreover, NBC\nachieves a lower false positive rate in mutation testing, making it a more\nreliable approach for identifying faulty behavior in game programs. These\nfindings confirm that branch coverage-based test generation improves test\ncoverage and fault detection in Scratch programs.", "AI": {"tldr": "\u672c\u6587\u4e3a\u89e3\u51b3\u6e38\u620f\u7a0b\u5e8f\u81ea\u52a8\u5316\u6d4b\u8bd5\u95ee\u9898\uff0c\u5f15\u5165\u57fa\u4e8e\u5206\u652f\u8986\u76d6\u7684\u9002\u5e94\u5ea6\u51fd\u6570\u6539\u8fdbNEATEST\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u65b0\u65b9\u6cd5\u5728\u5206\u652f\u8986\u76d6\u548c\u6545\u969c\u68c0\u6d4b\u4e0a\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u53e5\u8986\u76d6\u7684NEATEST\u6846\u67b6\u7528\u4e8e\u6e38\u620f\u81ea\u52a8\u5316\u6d4b\u8bd5\u65f6\uff0c\u8bed\u53e5\u8986\u76d6\u4e0d\u8db3\u4ee5\u68c0\u6d4b\u6545\u969c\uff0c\u9700\u8981\u63d0\u9ad8\u6d4b\u8bd5\u6709\u6548\u6027\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5206\u652f\u8986\u76d6\u7684\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u96c6\u6210\u5230NEATEST\u6846\u67b6\u4e2d\uff0c\u5bf925\u4e2aScratch\u6e38\u620f\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u8fdb\u884c\u7a81\u53d8\u5206\u6790\u3002", "result": "\u572825\u4e2a\u6e38\u620f\u4e2d\u768413\u4e2a\u91cc\uff0c\u65b0\u65b9\u6cd5\u6bd4\u539f\u65b9\u6cd5\u6709\u66f4\u9ad8\u5206\u652f\u8986\u76d6\uff0c\u4e14\u7a81\u53d8\u6d4b\u8bd5\u4e2d\u5047\u9633\u6027\u7387\u66f4\u4f4e\u3002", "conclusion": "\u57fa\u4e8e\u5206\u652f\u8986\u76d6\u7684\u6d4b\u8bd5\u751f\u6210\u80fd\u63d0\u9ad8Scratch\u7a0b\u5e8f\u7684\u6d4b\u8bd5\u8986\u76d6\u548c\u6545\u969c\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2507.08848", "pdf": "https://arxiv.org/pdf/2507.08848", "abs": "https://arxiv.org/abs/2507.08848", "authors": ["Calum Corrie Imrie", "Ioannis Stefanakos", "Sepeedeh Shahbeigi", "Richard Hawkins", "Simon Burton"], "title": "Assuring the Safety of Reinforcement Learning Components: AMLAS-RL", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SE"], "comment": null, "summary": "The rapid advancement of machine learning (ML) has led to its increasing\nintegration into cyber-physical systems (CPS) across diverse domains. While CPS\noffer powerful capabilities, incorporating ML components introduces significant\nsafety and assurance challenges. Among ML techniques, reinforcement learning\n(RL) is particularly suited for CPS due to its capacity to handle complex,\ndynamic environments where explicit models of interaction between system and\nenvironment are unavailable or difficult to construct. However, in\nsafety-critical applications, this learning process must not only be effective\nbut demonstrably safe. Safe-RL methods aim to address this by incorporating\nsafety constraints during learning, yet they fall short in providing systematic\nassurance across the RL lifecycle. The AMLAS methodology offers structured\nguidance for assuring the safety of supervised learning components, but it does\nnot directly apply to the unique challenges posed by RL. In this paper, we\nadapt AMLAS to provide a framework for generating assurance arguments for an\nRL-enabled system through an iterative process; AMLAS-RL. We demonstrate\nAMLAS-RL using a running example of a wheeled vehicle tasked with reaching a\ntarget goal without collision.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAMLAS - RL\u6846\u67b6\u4e3a\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7cfb\u7edf\u751f\u6210\u4fdd\u8bc1\u8bba\u8bc1\uff0c\u4ee5\u89e3\u51b3CPS\u4e2dRL\u7ec4\u4ef6\u7684\u5b89\u5168\u4fdd\u8bc1\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u8f6e\u5f0f\u8f66\u8f86\u793a\u4f8b\u8fdb\u884c\u6f14\u793a\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u878d\u5165\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff08CPS\uff09\u5e26\u6765\u5b89\u5168\u548c\u4fdd\u8bc1\u6311\u6218\uff0c\u73b0\u6709Safe - RL\u65b9\u6cd5\u7f3a\u4e4f\u5168\u751f\u547d\u5468\u671f\u7684\u7cfb\u7edf\u4fdd\u8bc1\uff0cAMLAS\u4e0d\u9002\u7528\u4e8eRL\u72ec\u7279\u6311\u6218\u3002", "method": "\u5bf9AMLAS\u8fdb\u884c\u8c03\u6574\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u63d0\u51faAMLAS - RL\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u8f6e\u5f0f\u8f66\u8f86\u5728\u65e0\u78b0\u649e\u60c5\u51b5\u4e0b\u5230\u8fbe\u76ee\u6807\u7684\u793a\u4f8b\u5c55\u793a\u4e86AMLAS - RL\u3002", "conclusion": "AMLAS - RL\u6846\u67b6\u53ef\u4e3aRL\u7cfb\u7edf\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\u3002"}}
{"id": "2507.09019", "pdf": "https://arxiv.org/pdf/2507.09019", "abs": "https://arxiv.org/abs/2507.09019", "authors": ["Amey Agrawal", "Nitin Kedia", "Anmol Agarwal", "Jayashree Mohan", "Nipun Kwatra", "Souvik Kundu", "Ramachandran Ramjee", "Alexey Tumanov"], "title": "On Evaluating Performance of LLM Inference Serving Systems", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "The rapid evolution of Large Language Model (LLM) inference systems has\nyielded significant efficiency improvements. However, our systematic analysis\nreveals that current evaluation methodologies frequently exhibit fundamental\nflaws, often manifesting as common evaluation anti-patterns that obscure true\nperformance characteristics and impede scientific progress. Through a\ncomprehensive examination of recent systems, we identify recurring\nanti-patterns across three key dimensions: Baseline Fairness, Evaluation Setup,\nand Metric Design. These anti-patterns are uniquely problematic for LLM\ninference due to its dual-phase nature combining distinct prefill and decode\noperations, its handling of highly heterogeneous workloads, and its strict\ntemporal requirements for interactive use. We demonstrate how common\nanti-patterns -- such as inadequate baseline comparisons that conflate\nengineering effort with algorithmic novelty, workload selections that fail to\nrepresent production scenarios, and metric normalizations that hide substantial\nperformance variability like generation stalls-lead to misleading conclusions.\nTo address these challenges, we provide a comprehensive checklist derived from\nour analysis, establishing a framework for recognizing and avoiding these\nanti-patterns in favor of robust LLM inference evaluation. To demonstrate the\npractical application of our framework, we present a case study analyzing\nspeculative decoding, a technique whose bursty, non-uniform token generation is\neasily misinterpreted when evaluated using approaches characteristic of these\nanti-patterns. Our work establishes a rigorous foundation for evaluation\nmethodology, enabling meaningful comparisons, ensuring reproducible results,\nand ultimately accelerating genuine progress in LLM inference systems by moving\nbeyond common anti-patterns to align evaluation with real-world requirements.", "AI": {"tldr": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u6709\u7f3a\u9677\uff0c\u672c\u6587\u8bc6\u522b\u53cd\u6a21\u5f0f\u5e76\u63d0\u4f9b\u68c0\u67e5\u6e05\u5355\u4ee5\u6539\u8fdb\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u7f3a\u9677\uff0c\u963b\u788d\u79d1\u5b66\u8fdb\u5c55\u3002", "method": "\u5168\u9762\u68c0\u67e5\u8fd1\u671f\u7cfb\u7edf\uff0c\u4ece\u57fa\u7ebf\u516c\u5e73\u6027\u3001\u8bc4\u4f30\u8bbe\u7f6e\u548c\u6307\u6807\u8bbe\u8ba1\u4e09\u4e2a\u7ef4\u5ea6\u8bc6\u522b\u53cd\u6a21\u5f0f\uff0c\u63d0\u4f9b\u68c0\u67e5\u6e05\u5355\u5e76\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u8bc6\u522b\u5e38\u89c1\u53cd\u6a21\u5f0f\uff0c\u5c55\u793a\u5176\u5bfc\u81f4\u8bef\u5bfc\u6027\u7ed3\u8bba\uff0c\u63d0\u4f9b\u7684\u6846\u67b6\u53ef\u7528\u4e8e\u5b9e\u9645\u8bc4\u4f30\u3002", "conclusion": "\u4e3a\u8bc4\u4f30\u65b9\u6cd5\u5960\u5b9a\u4e25\u8c28\u57fa\u7840\uff0c\u80fd\u8fdb\u884c\u6709\u610f\u4e49\u6bd4\u8f83\u3001\u786e\u4fdd\u7ed3\u679c\u53ef\u91cd\u590d\uff0c\u63a8\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u771f\u6b63\u8fdb\u6b65\u3002"}}
{"id": "2507.10097", "pdf": "https://arxiv.org/pdf/2507.10097", "abs": "https://arxiv.org/abs/2507.10097", "authors": ["Yue Meng", "Cheng Guo", "Xiaohui Hu", "Honghu Deng", "Yi Cao", "Tong Liu", "Bo Zheng"], "title": "User Long-Term Multi-Interest Retrieval Model for Recommendation", "categories": ["cs.IR"], "comment": null, "summary": "User behavior sequence modeling, which captures user interest from rich\nhistorical interactions, is pivotal for industrial recommendation systems.\nDespite breakthroughs in ranking-stage models capable of leveraging ultra-long\nbehavior sequences with length scaling up to thousands, existing retrieval\nmodels remain constrained to sequences of hundreds of behaviors due to two main\nchallenges. One is strict latency budget imposed by real-time service over\nlarge-scale candidate pool. The other is the absence of target-aware mechanisms\nand cross-interaction architectures, which prevent utilizing ranking-like\ntechniques to simplify long sequence modeling. To address these limitations, we\npropose a new framework named User Long-term Multi-Interest Retrieval\nModel(ULIM), which enables thousand-scale behavior modeling in retrieval\nstages. ULIM includes two novel components: 1)Category-Aware Hierarchical\nDual-Interest Learning partitions long behavior sequences into multiple\ncategory-aware subsequences representing multi-interest and jointly optimizes\nlong-term and short-term interests within specific interest cluster.\n2)Pointer-Enhanced Cascaded Category-to-Item Retrieval introduces\nPointer-Generator Interest Network(PGIN) for next-category prediction, followed\nby next-item retrieval upon the top-K predicted categories. Comprehensive\nexperiments on Taobao dataset show that ULIM achieves substantial improvement\nover state-of-the-art methods, and brings 5.54% clicks, 11.01% orders and 4.03%\nGMV lift for Taobaomiaosha, a notable mini-app of Taobao.", "AI": {"tldr": "\u63d0\u51fa\u7528\u6237\u957f\u671f\u591a\u5174\u8da3\u68c0\u7d22\u6a21\u578bULIM\u7528\u4e8e\u68c0\u7d22\u9636\u6bb5\u7684\u5343\u7ea7\u884c\u4e3a\u5efa\u6a21\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u63d0\u5347\u4e1a\u52a1\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u6a21\u578b\u53d7\u5b9e\u65f6\u670d\u52a1\u5ef6\u8fdf\u9884\u7b97\u548c\u7f3a\u4e4f\u76ee\u6807\u611f\u77e5\u673a\u5236\u7b49\u9650\u5236\uff0c\u53ea\u80fd\u5904\u7406\u6570\u767e\u4e2a\u884c\u4e3a\u5e8f\u5217\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faULIM\u6846\u67b6\uff0c\u5305\u542b\u7c7b\u522b\u611f\u77e5\u5206\u5c42\u53cc\u5174\u8da3\u5b66\u4e60\u548c\u6307\u9488\u589e\u5f3a\u7ea7\u8054\u7c7b\u522b\u5230\u7269\u54c1\u68c0\u7d22\u4e24\u4e2a\u7ec4\u4ef6\u3002", "result": "\u5728\u6dd8\u5b9d\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cULIM\u8f83\u73b0\u6709\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u6dd8\u5b9d\u79d2\u6740\u5c0f\u7a0b\u5e8f\u5e26\u6765\u70b9\u51fb\u3001\u8ba2\u5355\u548cGMV\u589e\u957f\u3002", "conclusion": "ULIM\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u68c0\u7d22\u6a21\u578b\u7684\u5c40\u9650\uff0c\u53ef\u7528\u4e8e\u68c0\u7d22\u9636\u6bb5\u7684\u5343\u7ea7\u884c\u4e3a\u5efa\u6a21\u5e76\u63d0\u5347\u4e1a\u52a1\u6548\u679c\u3002"}}
{"id": "2507.09588", "pdf": "https://arxiv.org/pdf/2507.09588", "abs": "https://arxiv.org/abs/2507.09588", "authors": ["Isaac Shi", "Zeyuan Li", "Fan Liu", "Wenli Wang", "Lewei He", "Yang Yang", "Tianyu Shi"], "title": "eSapiens: A Platform for Secure and Auditable Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": null, "summary": "We present eSapiens, an AI-as-a-Service (AIaaS) platform engineered around a\nbusiness-oriented trifecta: proprietary data, operational workflows, and any\nmajor agnostic Large Language Model (LLM). eSapiens gives businesses full\ncontrol over their AI assets, keeping everything in-house for AI knowledge\nretention and data security. eSapiens AI Agents (Sapiens) empower your team by\nproviding valuable insights and automating repetitive tasks, enabling them to\nfocus on high-impact work and drive better business outcomes.\n  The system integrates structured document ingestion, hybrid vector retrieval,\nand no-code orchestration via LangChain, and supports top LLMs including\nOpenAI, Claude, Gemini, and DeepSeek. A key component is the THOR Agent, which\nhandles structured SQL-style queries and generates actionable insights over\nenterprise databases.\n  To evaluate the system, we conduct two experiments. First, a retrieval\nbenchmark on legal corpora reveals that a chunk size of 512 tokens yields the\nhighest retrieval precision (Top-3 accuracy: 91.3%). Second, a generation\nquality test using TRACe metrics across five LLMs shows that eSapiens delivers\nmore context-consistent outputs with up to a 23% improvement in factual\nalignment.\n  These results demonstrate the effectiveness of eSapiens in enabling\ntrustworthy, auditable AI workflows for high-stakes domains like legal and\nfinance.", "AI": {"tldr": "\u4ecb\u7ecdeSapiens AIaaS\u5e73\u53f0\uff0c\u542b\u529f\u80fd\u3001\u96c6\u6210\u65b9\u5f0f\u3001\u5b9e\u9a8c\u8bc4\u4f30\u53ca\u6548\u679c\u3002", "motivation": "\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u5bf9AI\u8d44\u4ea7\u7684\u5b8c\u5168\u63a7\u5236\uff0c\u4fdd\u969cAI\u77e5\u8bc6\u4fdd\u7559\u548c\u6570\u636e\u5b89\u5168\uff0c\u52a9\u529b\u4f01\u4e1a\u53d6\u5f97\u66f4\u597d\u4e1a\u52a1\u6210\u679c\u3002", "method": "\u96c6\u6210\u7ed3\u6784\u5316\u6587\u6863\u6444\u53d6\u3001\u6df7\u5408\u5411\u91cf\u68c0\u7d22\u548c\u65e0\u4ee3\u7801\u7f16\u6392\uff0c\u652f\u6301\u591a\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8bbe\u7f6e\u5173\u952e\u7ec4\u4ef6THOR Agent\uff0c\u8fdb\u884c\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u548c\u751f\u6210\u8d28\u91cf\u6d4b\u8bd5\u3002", "result": "\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d512\u4ee4\u724c\u5757\u5927\u5c0f\u68c0\u7d22\u7cbe\u5ea6\u6700\u9ad8\uff0c\u751f\u6210\u8d28\u91cf\u6d4b\u8bd5\u663e\u793aeSapiens\u8f93\u51fa\u66f4\u5177\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\uff0c\u4e8b\u5b9e\u5bf9\u9f50\u6700\u591a\u63d0\u534723%\u3002", "conclusion": "eSapiens\u80fd\u4e3a\u6cd5\u5f8b\u548c\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u5b9e\u73b0\u53ef\u4fe1\u3001\u53ef\u5ba1\u8ba1\u7684AI\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2507.10296", "pdf": "https://arxiv.org/pdf/2507.10296", "abs": "https://arxiv.org/abs/2507.10296", "authors": ["Shijie Li", "Weiqiang He", "Ruobing Bai", "Pan Peng"], "title": "Average Sensitivity of Hierarchical $k$-Median Clustering", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "Hierarchical clustering is a widely used method for unsupervised learning\nwith numerous applications. However, in the application of modern algorithms,\nthe datasets studied are usually large and dynamic. If the hierarchical\nclustering is sensitive to small perturbations of the dataset, the usability of\nthe algorithm will be greatly reduced. In this paper, we focus on the\nhierarchical $k$ -median clustering problem, which bridges hierarchical and\ncentroid-based clustering while offering theoretical appeal, practical utility,\nand improved interpretability. We analyze the average sensitivity of algorithms\nfor this problem by measuring the expected change in the output when a random\ndata point is deleted. We propose an efficient algorithm for hierarchical\n$k$-median clustering and theoretically prove its low average sensitivity and\nhigh clustering quality. Additionally, we show that single linkage clustering\nand a deterministic variant of the CLNSS algorithm exhibit high average\nsensitivity, making them less stable. Finally, we validate the robustness and\neffectiveness of our algorithm through experiments.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u5206\u5c42k - \u4e2d\u4f4d\u6570\u805a\u7c7b\u95ee\u9898\uff0c\u5206\u6790\u7b97\u6cd5\u5e73\u5747\u654f\u611f\u5ea6\uff0c\u63d0\u51fa\u9ad8\u6548\u7b97\u6cd5\u5e76\u8bc1\u660e\u5176\u4f4e\u654f\u611f\u5ea6\u4e0e\u9ad8\u805a\u7c7b\u8d28\u91cf\uff0c\u8fd8\u6307\u51fa\u90e8\u5206\u7b97\u6cd5\u654f\u611f\u5ea6\u9ad8\uff0c\u6700\u540e\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u9c81\u68d2\u6027\u4e0e\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u7b97\u6cd5\u5e94\u7528\u4e2d\u6570\u636e\u96c6\u5927\u4e14\u52a8\u6001\uff0c\u5206\u5c42\u805a\u7c7b\u82e5\u5bf9\u6570\u636e\u5c0f\u6270\u52a8\u654f\u611f\u4f1a\u964d\u4f4e\u7b97\u6cd5\u53ef\u7528\u6027\uff0c\u7814\u7a76\u5206\u5c42k - \u4e2d\u4f4d\u6570\u805a\u7c7b\u95ee\u9898\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u968f\u673a\u5220\u9664\u4e00\u4e2a\u6570\u636e\u70b9\u65f6\u8f93\u51fa\u7684\u9884\u671f\u53d8\u5316\u6765\u5206\u6790\u7b97\u6cd5\u7684\u5e73\u5747\u654f\u611f\u5ea6\uff0c\u63d0\u51fa\u5206\u5c42k - \u4e2d\u4f4d\u6570\u805a\u7c7b\u7684\u9ad8\u6548\u7b97\u6cd5\u5e76\u8fdb\u884c\u7406\u8bba\u8bc1\u660e\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5177\u6709\u4f4e\u5e73\u5747\u654f\u611f\u5ea6\u548c\u9ad8\u805a\u7c7b\u8d28\u91cf\uff0c\u5355\u94fe\u63a5\u805a\u7c7b\u548cCLNSS\u7b97\u6cd5\u7684\u786e\u5b9a\u6027\u53d8\u4f53\u5e73\u5747\u654f\u611f\u5ea6\u9ad8\uff0c\u7a33\u5b9a\u6027\u5dee\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.09481", "pdf": "https://arxiv.org/pdf/2507.09481", "abs": "https://arxiv.org/abs/2507.09481", "authors": ["Yuheng Huang", "Da Song", "Zhenlan Ji", "Shuai Wang", "Lei Ma"], "title": "Evaluating LLMs on Sequential API Call Through Automated Test Generation", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "By integrating tools from external APIs, Large Language Models (LLMs) have\nexpanded their promising capabilities in a diverse spectrum of complex\nreal-world tasks. However, testing, evaluation, and analysis of LLM tool use\nremain in their early stages. Most existing benchmarks rely on manually\ncollected test cases, many of which cannot be automatically checked for\nsemantic correctness and instead depend on static methods such as string\nmatching. Additionally, these benchmarks often overlook the complex\ninteractions that occur between sequential API calls, which are common in\nreal-world applications. To fill the gap, in this paper, we introduce StateGen,\nan automated framework designed to generate diverse coding tasks involving\nsequential API interactions. StateGen combines state-machine-based API\nconstraint solving and validation, energy-based sampling, and control-flow\ninjection to generate executable programs. These programs are then translated\ninto human-like natural language task descriptions through a collaboration of\ntwo LLM agents. Utilizing StateGen, we construct StateEval, a benchmark\nencompassing 120 verified test cases spanning across three representative\nscenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental\nresults confirm that StateGen can effectively generate challenging and\nrealistic API-oriented tasks, highlighting areas for improvement in current\nLLMs incorporating APIs.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u4f7f\u7528\u6d4b\u8bd5\u8bc4\u4f30\u5904\u4e8e\u65e9\u671f\uff0c\u672c\u6587\u63d0\u51faStateGen\u6846\u67b6\u751f\u6210API\u4ea4\u4e92\u7f16\u7801\u4efb\u52a1\u5e76\u6784\u5efaStateEval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u751f\u6210\u6709\u6311\u6218\u4e14\u73b0\u5b9e\u7684\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u4f7f\u7528\u7684\u6d4b\u8bd5\u3001\u8bc4\u4f30\u548c\u5206\u6790\u5904\u4e8e\u65e9\u671f\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u624b\u52a8\u6536\u96c6\u6d4b\u8bd5\u7528\u4f8b\uff0c\u65e0\u6cd5\u81ea\u52a8\u68c0\u67e5\u8bed\u4e49\u6b63\u786e\u6027\u4e14\u5ffd\u7565\u987a\u5e8fAPI\u8c03\u7528\u7684\u590d\u6742\u4ea4\u4e92\u3002", "method": "\u5f15\u5165StateGen\u6846\u67b6\uff0c\u7ed3\u5408\u72b6\u6001\u673aAPI\u7ea6\u675f\u6c42\u89e3\u4e0e\u9a8c\u8bc1\u3001\u57fa\u4e8e\u80fd\u91cf\u7684\u91c7\u6837\u548c\u63a7\u5236\u6d41\u6ce8\u5165\u751f\u6210\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u518d\u901a\u8fc7\u4e24\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u534f\u4f5c\u5c06\u7a0b\u5e8f\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\uff0c\u6784\u5efaStateEval\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eStateGen\u80fd\u6709\u6548\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u548c\u73b0\u5b9e\u6027\u7684\u9762\u5411API\u7684\u4efb\u52a1\u3002", "conclusion": "\u6307\u51fa\u5f53\u524d\u7ed3\u5408API\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5f85\u6539\u8fdb\u4e4b\u5904\u3002"}}
{"id": "2507.08858", "pdf": "https://arxiv.org/pdf/2507.08858", "abs": "https://arxiv.org/abs/2507.08858", "authors": ["Sami Achour", "Yassine Bouher", "Duong Nguyen", "Nicolas Chesneau"], "title": "Foundation models for time series forecasting: Application in conformal prediction", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The zero-shot capabilities of foundation models (FMs) for time series\nforecasting offer promising potentials in conformal prediction, as most of the\navailable data can be allocated to calibration. This study compares the\nperformance of Time Series Foundation Models (TSFMs) with traditional methods,\nincluding statistical models and gradient boosting, within a conformal\nprediction setting. Our findings highlight two key advantages of TSFMs. First,\nwhen the volume of data is limited, TSFMs provide more reliable conformalized\nprediction intervals than classic models, thanks to their superior predictive\naccuracy. Second, the calibration process is more stable because more data are\nused for calibration. Morever, the fewer data available, the more pronounced\nthese benefits become, as classic models require a substantial amount of data\nfor effective training. These results underscore the potential of foundation\nmodels in improving conformal prediction reliability in time series\napplications, particularly in data-constrained cases. All the code to reproduce\nthe experiments is available.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u548c\u4f20\u7edf\u65b9\u6cd5\u5728\u5171\u5f62\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0TSFMs\u5728\u6570\u636e\u6709\u9650\u65f6\u66f4\u5177\u4f18\u52bf\uff0c\u51f8\u663e\u5176\u5728\u65f6\u95f4\u5e8f\u5217\u5e94\u7528\u4e2d\u63d0\u5347\u5171\u5f62\u9884\u6d4b\u53ef\u9760\u6027\u7684\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22\u57fa\u7840\u6a21\u578b\u96f6\u6837\u672c\u80fd\u529b\u5728\u65f6\u95f4\u5e8f\u5217\u5171\u5f62\u9884\u6d4b\u4e2d\u7684\u6f5c\u529b\uff0c\u5bf9\u6bd4TSFMs\u548c\u4f20\u7edf\u65b9\u6cd5\u6027\u80fd\u3002", "method": "\u5728\u5171\u5f62\u9884\u6d4b\u8bbe\u7f6e\u4e0b\uff0c\u5bf9\u6bd4TSFMs\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u7edf\u8ba1\u6a21\u578b\u548c\u68af\u5ea6\u63d0\u5347\uff09\u7684\u8868\u73b0\u3002", "result": "TSFMs\u5728\u6570\u636e\u6709\u9650\u65f6\u6709\u4e24\u4e2a\u4f18\u52bf\uff1a\u9884\u6d4b\u533a\u95f4\u66f4\u53ef\u9760\uff1b\u6821\u51c6\u8fc7\u7a0b\u66f4\u7a33\u5b9a\uff0c\u4e14\u6570\u636e\u8d8a\u5c11\u4f18\u52bf\u8d8a\u660e\u663e\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u5e94\u7528\u4e2d\uff0c\u5c24\u5176\u5728\u6570\u636e\u53d7\u9650\u60c5\u51b5\u4e0b\uff0c\u80fd\u63d0\u5347\u5171\u5f62\u9884\u6d4b\u53ef\u9760\u6027\u3002"}}
{"id": "2507.10443", "pdf": "https://arxiv.org/pdf/2507.10443", "abs": "https://arxiv.org/abs/2507.10443", "authors": ["Xin Li"], "title": "Information Must Flow: Recursive Bootstrapping for Information Bottleneck in Optimal Transport", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present the Context-Content Uncertainty Principle (CCUP), a unified\nframework that models cognition as the directed flow of information between\nhigh-entropy context and low-entropy content. Inference emerges as a cycle of\nbidirectional interactions, bottom-up contextual disambiguation paired with\ntop-down content reconstruction, which resolves the Information Bottleneck in\nOptimal Transport (iBOT). Implemented via Rao-Blackwellized variational entropy\nminimization, CCUP steers representations toward minimal joint uncertainty\nwhile preserving inferential directionality. Local cycle completion underpins\ntemporal bootstrapping, chaining simulations to refine memory, and spatial\nbootstrapping, enabling compositional hierarchical inference. We prove a Delta\nConvergence Theorem showing that recursive entropy minimization yields\ndelta-like attractors in latent space, stabilizing perceptual schemas and motor\nplans. Temporal bootstrapping through perception-action loops and sleep-wake\nconsolidation further transforms episodic traces into semantic knowledge.\nExtending CCUP, each hierarchical level performs delta-seeded inference:\nlow-entropy content seeds diffuse outward along goal-constrained paths shaped\nby top-down priors and external context, confining inference to task-relevant\nmanifolds and circumventing the curse of dimensionality. Building on this, we\npropose that language emerges as a symbolic transport system, externalizing\nlatent content to synchronize inference cycles across individuals. Together,\nthese results establish iBOT as a foundational principle of information flow in\nboth individual cognition and collective intelligence, positioning recursive\ninference as the structured conduit through which minds adapt, align, and\nextend.", "AI": {"tldr": "\u63d0\u51fa\u4e0a\u4e0b\u6587 - \u5185\u5bb9\u4e0d\u786e\u5b9a\u6027\u539f\u7406\uff08CCUP\uff09\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u6700\u4f18\u4f20\u8f93\u4e2d\u7684\u4fe1\u606f\u74f6\u9888\u95ee\u9898\uff0c\u8bc1\u660e\u76f8\u5173\u5b9a\u7406\uff0c\u8fd8\u63a2\u8ba8\u5176\u5728\u8bed\u8a00\u7b49\u65b9\u9762\u5e94\u7528\uff0c\u786e\u7acbiBOT\u5728\u8ba4\u77e5\u548c\u96c6\u4f53\u667a\u80fd\u4e2d\u7684\u57fa\u7840\u5730\u4f4d\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u5efa\u6a21\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u89e3\u51b3\u6700\u4f18\u4f20\u8f93\u4e2d\u7684\u4fe1\u606f\u74f6\u9888\u95ee\u9898\u3002", "method": "\u901a\u8fc7Rao - Blackwellized\u53d8\u5206\u71b5\u6700\u5c0f\u5316\u5b9e\u73b0CCUP\uff0c\u5229\u7528\u5c40\u90e8\u5faa\u73af\u5b8c\u6210\u8fdb\u884c\u65f6\u95f4\u548c\u7a7a\u95f4\u5f15\u5bfc\uff0c\u8bc1\u660eDelta\u6536\u655b\u5b9a\u7406\u3002", "result": "\u9012\u5f52\u71b5\u6700\u5c0f\u5316\u5728\u6f5c\u5728\u7a7a\u95f4\u4ea7\u751f\u7c7b\u4f3cdelta\u7684\u5438\u5f15\u5b50\uff0c\u65f6\u95f4\u5f15\u5bfc\u5c06\u60c5\u666f\u75d5\u8ff9\u8f6c\u5316\u4e3a\u8bed\u4e49\u77e5\u8bc6\uff0c\u8bed\u8a00\u53ef\u4f5c\u4e3a\u7b26\u53f7\u4f20\u8f93\u7cfb\u7edf\u3002", "conclusion": "iBOT\u662f\u4e2a\u4f53\u8ba4\u77e5\u548c\u96c6\u4f53\u667a\u80fd\u4e2d\u4fe1\u606f\u6d41\u7684\u57fa\u7840\u539f\u7406\uff0c\u9012\u5f52\u63a8\u7406\u662f\u601d\u7ef4\u9002\u5e94\u3001\u5bf9\u9f50\u548c\u6269\u5c55\u7684\u7ed3\u6784\u5316\u6e20\u9053\u3002"}}
{"id": "2507.09201", "pdf": "https://arxiv.org/pdf/2507.09201", "abs": "https://arxiv.org/abs/2507.09201", "authors": ["Weihong Xu", "Haein Choi", "Po-kai Hsu", "Shimeng Yu", "Tajana Rosing"], "title": "SLIM: A Heterogeneous Accelerator for Edge Inference of Sparse Large Language Model via Adaptive Thresholding", "categories": ["cs.AR", "cs.DC"], "comment": null, "summary": "Large language models (LLMs) have demonstrated exceptional proficiency in\nunderstanding and generating human language, but efficient inference on\nresource-constrained embedded devices remains challenging due to large model\nsizes and memory-intensive operations in feedforward network (FFN) and\nmulti-head attention (MHA) layers. While existing accelerators offload LLM\ninference to expensive heterogeneous computing systems, they fail to exploit\nthe significant sparsity inherent in LLM operations, leaving hardware resources\nunderutilized. We propose SLIM, an algorithm-hardware co-design optimized for\nsparse LLM serving on edge devices. SLIM exploits LLM sparsity through an\nadaptive thresholding algorithm that enables runtime-configurable sparsity with\nnegligible accuracy loss, fetching only activated neurons to dramatically\nreduce data movement. Our heterogeneous hardware architecture strategically\ncombines near-storage processing (NSP) and processing-in-memory (PIM): FFN\nweights are stored in high-density 3D NAND and computed using NSP units, while\nmemory-intensive MHA operations are processed in PIM modules. This design\nsignificantly reduces memory footprint, data movement, and energy consumption.\nOur comprehensive evaluation demonstrates SLIM's effectiveness, achieving\n13-18x throughput improvements over SSD-GPU systems and 9-10x better energy\nefficiency over DRAM-GPU systems while maintaining low latency, making\ncost-effective LLM deployment viable for edge computing environments.", "AI": {"tldr": "\u63d0\u51faSLIM\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\uff0c\u7ed3\u5408\u7b97\u6cd5\u548c\u786c\u4ef6\u8bbe\u8ba1\uff0c\u51cf\u5c11\u6570\u636e\u79fb\u52a8\u548c\u80fd\u8017\uff0c\u63d0\u5347\u541e\u5410\u91cf\u548c\u80fd\u6548\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u9ad8\u6548\u63a8\u7406\u6709\u6311\u6218\uff0c\u73b0\u6709\u52a0\u901f\u5668\u672a\u5145\u5206\u5229\u7528\u6a21\u578b\u7a00\u758f\u6027\uff0c\u786c\u4ef6\u8d44\u6e90\u672a\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51faSLIM\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9608\u503c\u7b97\u6cd5\u5229\u7528\u6a21\u578b\u7a00\u758f\u6027\uff0c\u7ed3\u5408\u8fd1\u5b58\u50a8\u5904\u7406\u548c\u5185\u5b58\u5185\u5904\u7406\u7684\u5f02\u6784\u786c\u4ef6\u67b6\u6784\u3002", "result": "\u76f8\u6bd4SSD - GPU\u7cfb\u7edf\u541e\u5410\u91cf\u63d0\u534713 - 18\u500d\uff0c\u76f8\u6bd4DRAM - GPU\u7cfb\u7edf\u80fd\u6548\u63d0\u53479 - 10\u500d\uff0c\u4e14\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "SLIM\u4f7f\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e0b\u7ecf\u6d4e\u9ad8\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u6210\u4e3a\u53ef\u80fd\u3002"}}
{"id": "2507.10135", "pdf": "https://arxiv.org/pdf/2507.10135", "abs": "https://arxiv.org/abs/2507.10135", "authors": ["Santiago de Leon-Martinez", "Robert Moro", "Branislav Kveton", "Maria Bielikova"], "title": "Riding the Carousel: The First Extensive Eye Tracking Analysis of Browsing Behavior in Carousel Recommenders", "categories": ["cs.IR", "cs.HC"], "comment": null, "summary": "Carousels have become the de-facto interface in online services. However,\nthere is a lack of research in carousels, particularly examining how\nrecommender systems may be designed differently than the traditional\nsingle-list interfaces. One of the key elements for understanding how to design\na system for a particular interface is understanding how users browse. For\ncarousels, users may browse in a number of different ways due to the added\ncomplexity of multiple topic defined-lists and swiping to see more items.\n  Eye tracking is the key to understanding user behavior by providing valuable,\ndirect information on how users see and navigate. In this work, we provide the\nfirst extensive analysis of the eye tracking behavior in carousel recommenders\nunder the free-browsing setting. To understand how users browse, we examine the\nfollowing research questions : 1) where do users start browsing, 2) how do\nusers transition from item to item within the same carousel and across\ncarousels, and 3) how does genre preference impact transitions?\n  This work addresses a gap in the field and provides the first extensive\nempirical results of eye tracked browsing behavior in carousels for improving\nrecommenders. Taking into account the insights learned from the above\nquestions, our final contribution is to provide suggestions to help carousel\nrecommender system designers optimize their systems for user browsing behavior.\nThe most important suggestion being to reorder the ranked item positions to\naccount for browsing after swiping.These contributions aim not only to help\nimprove current systems, but also to encourage and allow the design of new user\nmodels, systems, and metrics that are better suited to the complexity of\ncarousel interfaces.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8f6e\u64ad\u63a8\u8350\u5668\u4e2d\u7528\u6237\u7684\u773c\u52a8\u6d4f\u89c8\u884c\u4e3a\u8fdb\u884c\u4e86\u9996\u6b21\u5e7f\u6cdb\u5206\u6790\uff0c\u4e3a\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4f18\u5316\u5efa\u8bae\u3002", "motivation": "\u8f6e\u64ad\u754c\u9762\u7f3a\u4e4f\u7814\u7a76\uff0c\u5c24\u5176\u5728\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u4e0e\u4f20\u7edf\u5355\u5217\u8868\u754c\u9762\u5dee\u5f02\u65b9\u9762\uff0c\u7406\u89e3\u7528\u6237\u6d4f\u89c8\u65b9\u5f0f\u5bf9\u7cfb\u7edf\u8bbe\u8ba1\u5f88\u5173\u952e\u3002", "method": "\u91c7\u7528\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\uff0c\u5728\u81ea\u7531\u6d4f\u89c8\u8bbe\u7f6e\u4e0b\u5206\u6790\u8f6e\u64ad\u63a8\u8350\u5668\u4e2d\u7684\u773c\u52a8\u884c\u4e3a\uff0c\u7814\u7a76\u7528\u6237\u6d4f\u89c8\u8d77\u59cb\u4f4d\u7f6e\u3001\u9879\u76ee\u95f4\u8fc7\u6e21\u65b9\u5f0f\u4ee5\u53ca\u6d41\u6d3e\u504f\u597d\u5bf9\u8fc7\u6e21\u7684\u5f71\u54cd\u3002", "result": "\u5f97\u5230\u4e86\u8f6e\u64ad\u4e2d\u773c\u52a8\u6d4f\u89c8\u884c\u4e3a\u7684\u9996\u6b21\u5e7f\u6cdb\u5b9e\u8bc1\u7ed3\u679c\u3002", "conclusion": "\u4e3a\u8f6e\u64ad\u63a8\u8350\u7cfb\u7edf\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4f18\u5316\u5efa\u8bae\uff0c\u5982\u91cd\u65b0\u6392\u5217\u9879\u76ee\u4f4d\u7f6e\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u73b0\u6709\u7cfb\u7edf\u5e76\u63a8\u52a8\u65b0\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2507.09611", "pdf": "https://arxiv.org/pdf/2507.09611", "abs": "https://arxiv.org/abs/2507.09611", "authors": ["Jenis Winsta"], "title": "The Hidden Costs of AI: A Review of Energy, E-Waste, and Inequality in Model Development", "categories": ["cs.AI", "cs.CY", "68T01"], "comment": "5 pages, 3 figures", "summary": "Artificial intelligence (AI) has made remarkable progress in recent years,\nyet its rapid expansion brings overlooked environmental and ethical challenges.\nThis review explores four critical areas where AI's impact extends beyond\nperformance: energy consumption, electronic waste (e-waste), inequality in\ncompute access, and the hidden energy burden of cybersecurity systems. Drawing\nfrom recent studies and institutional reports, the paper highlights systemic\nissues such as high emissions from model training, rising hardware turnover,\nglobal infrastructure disparities, and the energy demands of securing AI. By\nconnecting these concerns, the review contributes to Responsible AI discourse\nby identifying key research gaps and advocating for sustainable, transparent,\nand equitable development practices. Ultimately, it argues that AI's progress\nmust align with ethical responsibility and environmental stewardship to ensure\na more inclusive and sustainable technological future.", "AI": {"tldr": "AI\u53d1\u5c55\u5e26\u6765\u73af\u5883\u4e0e\u4f26\u7406\u6311\u6218\uff0c\u672c\u6587\u63a2\u8ba8\u5176\u5728\u56db\u65b9\u9762\u5f71\u54cd\uff0c\u6307\u51fa\u95ee\u9898\u3001\u7814\u7a76\u7f3a\u53e3\uff0c\u5021\u5bfc\u53ef\u6301\u7eed\u53d1\u5c55\u3002", "motivation": "AI\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u73af\u5883\u548c\u4f26\u7406\u6311\u6218\u88ab\u5ffd\u89c6\uff0c\u9700\u63a2\u8ba8\u5176\u591a\u65b9\u9762\u5f71\u54cd\u3002", "method": "\u501f\u9274\u8fd1\u671f\u7814\u7a76\u548c\u673a\u6784\u62a5\u544a\u3002", "result": "\u6307\u51fa\u6a21\u578b\u8bad\u7ec3\u9ad8\u6392\u653e\u3001\u786c\u4ef6\u66f4\u66ff\u9891\u7e41\u3001\u5168\u7403\u57fa\u7840\u8bbe\u65bd\u5dee\u5f02\u3001\u5b89\u5168\u80fd\u6e90\u9700\u6c42\u7b49\u7cfb\u7edf\u6027\u95ee\u9898\u3002", "conclusion": "AI\u8fdb\u6b65\u9700\u4e0e\u4f26\u7406\u8d23\u4efb\u548c\u73af\u5883\u7ba1\u7406\u76f8\u5951\u5408\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5177\u5305\u5bb9\u6027\u548c\u53ef\u6301\u7eed\u7684\u79d1\u6280\u672a\u6765\u3002"}}
{"id": "2507.10329", "pdf": "https://arxiv.org/pdf/2507.10329", "abs": "https://arxiv.org/abs/2507.10329", "authors": ["Alexander Barvinok"], "title": "Computing the probability of intersection", "categories": ["math.PR", "cs.DS", "math.CO", "60C05, 68Q87, 68W05, 30C15"], "comment": "21 page", "summary": "Let $\\Omega_1, \\ldots, \\Omega_m$ be probability spaces, let $\\Omega=\\Omega_1\n\\times \\cdots \\times \\Omega_m$ be their product and let $A_1, \\ldots, A_n\n\\subset \\Omega$ be events. Suppose that each event $A_i$ depends on $r_i$\ncoordinates of a point $x \\in \\Omega$, $x=\\left(\\xi_1, \\ldots, \\xi_m\\right)$,\nand that for each event $A_i$ there are $\\Delta_i$ of other events $A_j$ that\ndepend on some of the coordinates that $A_i$ depends on. Let $\\Delta=\\max\\{5,\\\n\\Delta_i: i=1, \\ldots, n\\}$ and let $\\mu_i=\\min\\{r_i,\\ \\Delta_i+1\\}$ for $i=1,\n\\ldots, n$. We prove that if $P(A_i) < (3\\Delta)^{-3\\mu_i}$ for all $I$, then\nfor any $0 < \\epsilon < 1$, the probability $P\\left( \\bigcap_{i=1}^n\n\\overline{A}_i\\right)$ of the intersection of the complements of all $A_i$ can\nbe computed within relative error $\\epsilon$ in polynomial time from the\nprobabilities $P\\left(A_{i_1} \\cap \\ldots \\cap A_{i_k}\\right)$ of $k$-wise\nintersections of the events $A_i$ for $k = e^{O(\\Delta)} \\ln (n/\\epsilon)$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.09490", "pdf": "https://arxiv.org/pdf/2507.09490", "abs": "https://arxiv.org/abs/2507.09490", "authors": ["Yan Zhao", "Chiwei Tang"], "title": "Towards LLM-Based Automatic Playtest", "categories": ["cs.SE"], "comment": null, "summary": "Playtesting is the process in which people play a video game for testing. It\nis critical for the quality assurance of gaming software. Manual playtesting is\ntime-consuming and expensive. However, automating this process is challenging,\nas playtesting typically requires domain knowledge and problem-solving skills\nthat most conventional testing tools lack. Recent advancements in artificial\nintelligence (AI) have opened up new possibilities for applying Large Language\nModels (LLMs) to playtesting. However, significant challenges remain: current\nLLMs cannot visually perceive game environments, and most existing research\nfocuses on text-based games or games with robust APIs. Many non-text games lack\nAPIs to provide textual descriptions of game states, making it almost\nimpossible to naively apply LLMs for playtesting. This paper introduces Lap,\nour novel approach to LLM-based Automatic Playtesting, which uses ChatGPT to\ntest match-3 games, a category of games where players match three or more\nidentical tiles in a row or column to earn points. Lap encompasses three key\nphases: processing of game environments, prompting-based action generation, and\naction execution. Given a match-3 game, Lap takes a snapshot of the game board\nand converts it to a numeric matrix. It then prompts the ChatGPT-O1-mini API to\nsuggest moves based on that matrix and tentatively applies the suggested moves\nto earn points and trigger changes in the game board. It repeats the\nabove-mentioned three steps iteratively until timeout. For evaluation, we\nconducted a case study using Lap on an open-source match-3 game, CasseBonbons,\nand empirically compared it with three existing tools. Our results are\npromising: Lap outperformed existing tools by achieving higher code coverage\nand triggering more program crashes. This research sheds light on the future of\nautomatic testing and LLM applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u6e38\u620f\u6d4b\u8bd5\u65b9\u6cd5Lap\uff0c\u7528ChatGPT\u6d4b\u8bd5\u4e09\u6d88\u6e38\u620f\uff0c\u7ecf\u6848\u4f8b\u7814\u7a76\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u4e3a\u81ea\u52a8\u6d4b\u8bd5\u548cLLM\u5e94\u7528\u63d0\u4f9b\u542f\u793a\u3002", "motivation": "\u624b\u52a8\u6e38\u620f\u6d4b\u8bd5\u8017\u65f6\u6602\u8d35\uff0c\u73b0\u6709\u81ea\u52a8\u6d4b\u8bd5\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u5f53\u524dLLMs\u7528\u4e8e\u6e38\u620f\u6d4b\u8bd5\u5b58\u5728\u65e0\u6cd5\u611f\u77e5\u6e38\u620f\u73af\u5883\u7b49\u6311\u6218\u3002", "method": "Lap\u5305\u542b\u6e38\u620f\u73af\u5883\u5904\u7406\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u52a8\u4f5c\u751f\u6210\u548c\u52a8\u4f5c\u6267\u884c\u4e09\u4e2a\u5173\u952e\u9636\u6bb5\uff0c\u5c06\u6e38\u620f\u68cb\u76d8\u5feb\u7167\u8f6c\u6362\u4e3a\u6570\u5b57\u77e9\u9635\uff0c\u8ba9ChatGPT\u5efa\u8bae\u79fb\u52a8\u5e76\u5e94\u7528\uff0c\u8fed\u4ee3\u6267\u884c\u76f4\u81f3\u8d85\u65f6\u3002", "result": "\u5728\u5f00\u6e90\u4e09\u6d88\u6e38\u620fCasseBonbons\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u663e\u793a\uff0cLap\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u4ee3\u7801\u8986\u76d6\u7387\u5e76\u89e6\u53d1\u66f4\u591a\u7a0b\u5e8f\u5d29\u6e83\uff0c\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u81ea\u52a8\u6d4b\u8bd5\u548cLLM\u5e94\u7528\u6307\u660e\u4e86\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2507.08860", "pdf": "https://arxiv.org/pdf/2507.08860", "abs": "https://arxiv.org/abs/2507.08860", "authors": ["Awais Manzoor", "M. Atif Qureshi", "Etain Kidney", "Luca Longo"], "title": "e-Profits: A Business-Aligned Evaluation Metric for Profit-Sensitive Customer Churn Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Retention campaigns in customer relationship management often rely on churn\nprediction models evaluated using traditional metrics such as AUC and F1-score.\nHowever, these metrics fail to reflect financial outcomes and may mislead\nstrategic decisions. We introduce e-Profits, a novel business-aligned\nevaluation metric that quantifies model performance based on customer-specific\nvalue, retention probability, and intervention costs. Unlike existing\nprofit-based metrics such as Expected Maximum Profit, which assume fixed\npopulation-level parameters, e-Profits uses Kaplan-Meier survival analysis to\nestimate personalised retention rates and supports granular, per customer\nevaluation. We benchmark six classifiers across two telecom datasets (IBM Telco\nand Maven Telecom) and demonstrate that e-Profits reshapes model rankings\ncompared to traditional metrics, revealing financial advantages in models\npreviously overlooked by AUC or F1-score. The metric also enables segment-level\ninsight into which models maximise return on investment for high-value\ncustomers. e-Profits is designed as an understandable, post hoc tool to support\nmodel evaluation in business contexts, particularly for marketing and analytics\nteams prioritising profit-driven decisions. All source code is available at:\nhttps://github.com/matifq/eprofits.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u8bc4\u4f30\u6307\u6807e - Profits\u7528\u4e8e\u5ba2\u6237\u6d41\u5931\u9884\u6d4b\u6a21\u578b\u8bc4\u4f30\uff0c\u5728\u7535\u4fe1\u6570\u636e\u96c6\u4e0a\u663e\u793a\u80fd\u6539\u53d8\u6a21\u578b\u6392\u540d\u5e76\u5e26\u6765\u8d22\u52a1\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u5982AUC\u548cF1 - score\u65e0\u6cd5\u53cd\u6620\u8d22\u52a1\u7ed3\u679c\uff0c\u53ef\u80fd\u8bef\u5bfc\u6218\u7565\u51b3\u7b56\u3002", "method": "\u5f15\u5165e - Profits\u6307\u6807\uff0c\u7528Kaplan - Meier\u751f\u5b58\u5206\u6790\u4f30\u8ba1\u4e2a\u6027\u5316\u7559\u5b58\u7387\uff0c\u5728\u4e24\u4e2a\u7535\u4fe1\u6570\u636e\u96c6\u4e0a\u5bf9\u516d\u4e2a\u5206\u7c7b\u5668\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "e - Profits\u6539\u53d8\u4e86\u6a21\u578b\u6392\u540d\uff0c\u663e\u793a\u51fa\u88ab\u4f20\u7edf\u6307\u6807\u5ffd\u89c6\u7684\u6a21\u578b\u7684\u8d22\u52a1\u4f18\u52bf\uff0c\u8fd8\u80fd\u63d0\u4f9b\u9ad8\u4ef7\u503c\u5ba2\u6237\u7684\u7ec6\u5206\u5c42\u9762\u6d1e\u5bdf\u3002", "conclusion": "e - Profits\u662f\u9002\u7528\u4e8e\u5546\u4e1a\u73af\u5883\u7684\u53ef\u7406\u89e3\u7684\u4e8b\u540e\u8bc4\u4f30\u5de5\u5177\uff0c\u5c24\u5176\u9002\u5408\u4f18\u5148\u8003\u8651\u5229\u6da6\u9a71\u52a8\u51b3\u7b56\u7684\u56e2\u961f\u3002"}}
{"id": "2507.09453", "pdf": "https://arxiv.org/pdf/2507.09453", "abs": "https://arxiv.org/abs/2507.09453", "authors": ["Micha\u0142 J\u00f3\u017awik", "Johan Pouwelse"], "title": "SmartphoneDemocracy: Privacy-Preserving E-Voting on Decentralized Infrastructure using Novel European Identity", "categories": ["cs.CR", "cs.DC"], "comment": "18 pages, 4 figures", "summary": "The digitization of democratic processes promises greater accessibility but\npresents challenges in terms of security, privacy, and verifiability. Existing\nelectronic voting systems often rely on centralized architectures, creating\nsingle points of failure and forcing too much trust in authorities, which\ncontradicts democratic principles. This research addresses the challenge of\ncreating a secure, private e-voting system with minimized trust dependencies\ndesigned for the most versatile personal device: the smartphone. We introduce\nSmartphoneDemocracy, a novel e-voting protocol that combines three key\ntechnologies: the emerging European Digital Identity (EUDI) Wallet for\nSybil-resistant identity verification, Zero-Knowledge Proofs for\nprivacy-preserving validation, and a peer-to-peer blockchain (TrustChain) for a\nresilient, serverless public bulletin board. Our protocol enables voters to\nregister and cast ballots anonymously and verifiably directly from their\nsmartphones. We provide a detailed protocol design, a security analysis against\na defined threat model, and a performance evaluation demonstrating that the\ncomputational and network overhead is feasible for medium- to large-scale\nelections. By developing and prototyping this system, we demonstrate a viable\npath to empower citizens with a trustworthy, accessible, and user-controlled\ndigital voting experience.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faSmartphoneDemocracy\u7535\u5b50\u6295\u7968\u534f\u8bae\uff0c\u7ed3\u5408\u4e09\u9879\u6280\u672f\u5b9e\u73b0\u5b89\u5168\u79c1\u5bc6\u6295\u7968\uff0c\u7ecf\u5206\u6790\u548c\u8bc4\u4f30\u53ef\u884c\u3002", "motivation": "\u6570\u5b57\u5316\u6c11\u4e3b\u8fdb\u7a0b\u6709\u5b89\u5168\u3001\u9690\u79c1\u7b49\u6311\u6218\uff0c\u73b0\u6709\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u4f9d\u8d56\u96c6\u4e2d\u67b6\u6784\uff0c\u8fdd\u80cc\u6c11\u4e3b\u539f\u5219\uff0c\u9700\u521b\u5efa\u5b89\u5168\u3001\u9690\u79c1\u4e14\u51cf\u5c11\u4fe1\u4efb\u4f9d\u8d56\u7684\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u3002", "method": "\u5f15\u5165SmartphoneDemocracy\u534f\u8bae\uff0c\u7ed3\u5408\u6b27\u6d32\u6570\u5b57\u8eab\u4efd\u94b1\u5305\u3001\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u70b9\u5bf9\u70b9\u533a\u5757\u94fe\u3002", "result": "\u63d0\u4f9b\u8be6\u7ec6\u534f\u8bae\u8bbe\u8ba1\u3001\u5b89\u5168\u5206\u6790\u548c\u6027\u80fd\u8bc4\u4f30\uff0c\u8bc1\u660e\u8ba1\u7b97\u548c\u7f51\u7edc\u5f00\u9500\u5728\u4e2d\u5927\u578b\u9009\u4e3e\u4e2d\u53ef\u884c\u3002", "conclusion": "\u5f00\u53d1\u5e76\u539f\u578b\u5316\u8be5\u7cfb\u7edf\uff0c\u4e3a\u516c\u6c11\u63d0\u4f9b\u53ef\u4fe1\u3001\u6613\u8bbf\u95ee\u548c\u7528\u6237\u53ef\u63a7\u7684\u6570\u5b57\u6295\u7968\u4f53\u9a8c\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2507.10411", "pdf": "https://arxiv.org/pdf/2507.10411", "abs": "https://arxiv.org/abs/2507.10411", "authors": ["Fangzheng Tian", "Jinyuan Fang", "Debasis Ganguly", "Zaiqiao Meng", "Craig Macdonald"], "title": "Am I on the Right Track? What Can Predicted Query Performance Tell Us about the Search Behaviour of Agentic RAG", "categories": ["cs.IR"], "comment": null, "summary": "Agentic Retrieval-Augmented Generation (RAG) is a new paradigm where the\nreasoning model decides when to invoke a retriever (as a \"tool\") when answering\na question. This paradigm, exemplified by recent research works such as\nSearch-R1, enables the model to decide when to search and obtain external\ninformation. However, the queries generated by such Agentic RAG models and the\nrole of the retriever in obtaining high-quality answers remain understudied. To\nthis end, this initial study examines the applicability of query performance\nprediction (QPP) within the recent Agentic RAG models Search-R1 and\nR1-Searcher. We find that applying effective retrievers can achieve higher\nanswer quality within a shorter reasoning process. Moreover, the QPP estimates\nof the generated queries, used as an approximation of their retrieval quality,\nare positively correlated with the quality of the final answer. Ultimately, our\nwork is a step towards adaptive retrieval within Agentic RAG, where QPP is used\nto inform the model if the retrieved results are likely to be useful.", "AI": {"tldr": "\u7814\u7a76Agentic RAG\u6a21\u578b\u4e2d\u67e5\u8be2\u6027\u80fd\u9884\u6d4b\uff08QPP\uff09\u7684\u9002\u7528\u6027\uff0c\u53d1\u73b0\u6709\u6548\u68c0\u7d22\u5668\u53ef\u63d0\u5347\u7b54\u6848\u8d28\u91cf\uff0cQPP\u4f30\u8ba1\u4e0e\u6700\u7ec8\u7b54\u6848\u8d28\u91cf\u6b63\u76f8\u5173\u3002", "motivation": "\u5f53\u524dAgentic RAG\u6a21\u578b\u751f\u6210\u7684\u67e5\u8be2\u53ca\u68c0\u7d22\u5668\u5728\u83b7\u53d6\u9ad8\u8d28\u91cf\u7b54\u6848\u4e2d\u7684\u4f5c\u7528\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8fdb\u884c\u76f8\u5173\u7814\u7a76\u3002", "method": "\u7814\u7a76QPP\u5728Agentic RAG\u6a21\u578bSearch - R1\u548cR1 - Searcher\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u5e94\u7528\u6709\u6548\u68c0\u7d22\u5668\u53ef\u5728\u66f4\u77ed\u63a8\u7406\u8fc7\u7a0b\u4e2d\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7b54\u6848\uff0cQPP\u4f30\u8ba1\u4e0e\u6700\u7ec8\u7b54\u6848\u8d28\u91cf\u6b63\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u662f\u8fc8\u5411Agentic RAG\u81ea\u9002\u5e94\u68c0\u7d22\u7684\u4e00\u6b65\uff0cQPP\u53ef\u544a\u77e5\u6a21\u578b\u68c0\u7d22\u7ed3\u679c\u662f\u5426\u6709\u7528\u3002"}}
{"id": "2507.09617", "pdf": "https://arxiv.org/pdf/2507.09617", "abs": "https://arxiv.org/abs/2507.09617", "authors": ["Margherita Martorana", "Francesca Urgese", "Mark Adamik", "Ilaria Tiddi"], "title": "Bridging Bots: from Perception to Action via Multimodal-LMs and Knowledge Graphs", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Personal service robots are deployed to support daily living in domestic\nenvironments, particularly for elderly and individuals requiring assistance.\nThese robots must perceive complex and dynamic surroundings, understand tasks,\nand execute context-appropriate actions. However, current systems rely on\nproprietary, hard-coded solutions tied to specific hardware and software,\nresulting in siloed implementations that are difficult to adapt and scale\nacross platforms. Ontologies and Knowledge Graphs (KGs) offer a solution to\nenable interoperability across systems, through structured and standardized\nrepresentations of knowledge and reasoning. However, symbolic systems such as\nKGs and ontologies struggle with raw and noisy sensory input. In contrast,\nmultimodal language models are well suited for interpreting input such as\nimages and natural language, but often lack transparency, consistency, and\nknowledge grounding. In this work, we propose a neurosymbolic framework that\ncombines the perceptual strengths of multimodal language models with the\nstructured representations provided by KGs and ontologies, with the aim of\nsupporting interoperability in robotic applications. Our approach generates\nontology-compliant KGs that can inform robot behavior in a platform-independent\nmanner. We evaluated this framework by integrating robot perception data,\nontologies, and five multimodal models (three LLaMA and two GPT models), using\ndifferent modes of neural-symbolic interaction. We assess the consistency and\neffectiveness of the generated KGs across multiple runs and configurations, and\nperform statistical analyzes to evaluate performance. Results show that GPT-o1\nand LLaMA 4 Maverick consistently outperform other models. However, our\nfindings also indicate that newer models do not guarantee better results,\nhighlighting the critical role of the integration strategy in generating\nontology-compliant KGs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u548c\u77e5\u8bc6\u56fe\u8c31\u3001\u672c\u4f53\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u652f\u6301\u673a\u5668\u4eba\u5e94\u7528\u4e92\u64cd\u4f5c\u6027\uff0c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\uff0c\u53d1\u73b0GPT - o1\u548cLLaMA 4 Maverick\u8868\u73b0\u4f73\uff0c\u4e14\u96c6\u6210\u7b56\u7565\u5f88\u5173\u952e\u3002", "motivation": "\u5f53\u524d\u4e2a\u4eba\u670d\u52a1\u673a\u5668\u4eba\u7cfb\u7edf\u4f9d\u8d56\u4e13\u6709\u786c\u7f16\u7801\u65b9\u6848\uff0c\u96be\u4ee5\u8de8\u5e73\u53f0\u9002\u5e94\u548c\u6269\u5c55\uff0c\u77e5\u8bc6\u56fe\u8c31\u548c\u672c\u4f53\u867d\u80fd\u5b9e\u73b0\u4e92\u64cd\u4f5c\u6027\u4f46\u5904\u7406\u539f\u59cb\u611f\u5b98\u8f93\u5165\u6709\u56f0\u96be\uff0c\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u5ea6\u7b49\uff0c\u56e0\u6b64\u9700\u7ed3\u5408\u4e8c\u8005\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u6574\u5408\u673a\u5668\u4eba\u611f\u77e5\u6570\u636e\u3001\u672c\u4f53\u548c\u4e94\u4e2a\u591a\u6a21\u6001\u6a21\u578b\uff0c\u91c7\u7528\u4e0d\u540c\u795e\u7ecf\u7b26\u53f7\u4ea4\u4e92\u6a21\u5f0f\uff0c\u5bf9\u751f\u6210\u7684\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u591a\u6b21\u8fd0\u884c\u548c\u914d\u7f6e\u8bc4\u4f30\uff0c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "GPT - o1\u548cLLaMA 4 Maverick\u8868\u73b0\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u8f83\u65b0\u6a21\u578b\u4e0d\u4e00\u5b9a\u6709\u66f4\u597d\u7ed3\u679c\u3002", "conclusion": "\u96c6\u6210\u7b56\u7565\u5728\u751f\u6210\u7b26\u5408\u672c\u4f53\u7684\u77e5\u8bc6\u56fe\u8c31\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2507.10467", "pdf": "https://arxiv.org/pdf/2507.10467", "abs": "https://arxiv.org/abs/2507.10467", "authors": ["Evangelos Protopapas", "Dimitrios M. Thilikos", "Sebastian Wiederrecht"], "title": "Colorful Minors", "categories": ["math.CO", "cs.DM", "cs.DS", "05C83, 05C85, 05C10, 05C75, 68R10", "G.2.2"], "comment": null, "summary": "We introduce the notion of colorful minors, which generalizes the classical\nconcept of rooted minors in graphs. $q$-colorful graph is defined as a pair\n$(G, \\chi),$ where $G$ is a graph and $\\chi$ assigns to each vertex a (possibly\nempty) subset of at most $q$ colors. The colorful minor relation enhances the\nclassical minor relation by merging color sets at contracted edges and allowing\nthe removal of colors from vertices. This framework naturally models\nalgorithmic problems involving graphs with (possibly overlapping) annotated\nvertex sets. We develop a structural theory for colorful minors by establishing\nseveral theorems characterizing $\\mathcal{H}$-colorful minor-free graphs, where\n$\\mathcal{H}$ consists either of a clique or a grid with all vertices assigned\nall colors, or of grids with colors segregated and ordered on the outer face.\nLeveraging our structural insights, we provide a complete classification -\nparameterized by the number $q$ of colors - of all colorful graphs that exhibit\nthe Erd\\H{o}s-P\\'osa property with respect to colorful minors. On the\nalgorithmic side, we provide a fixed-parameter tractable algorithm for colorful\nminor testing and a variant of the $k$-disjoint paths problem. Together with\nthe fact that the colorful minor relation forms a well-quasi-order, this\nimplies that every colorful minor-monotone parameter on colorful graphs admits\na fixed-parameter algorithm. Furthermore, we derive two algorithmic\nmeta-theorems (AMTs) whose structural conditions are linked to extensions of\ntreewidth and Hadwiger number on colorful graphs. Our results suggest how known\nAMTs can be extended to incorporate not only the structure of the input graph\nbut also the way the colored vertices are distributed in it.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u5f69\u8272\u5b50\u5f0f\u6982\u5ff5\uff0c\u63a8\u5e7f\u56fe\u7684\u6709\u6839\u5b50\u5f0f\uff0c\u53d1\u5c55\u7ed3\u6784\u7406\u8bba\uff0c\u5bf9\u6ee1\u8db3\u7279\u5b9a\u6027\u8d28\u7684\u5f69\u8272\u56fe\u5206\u7c7b\uff0c\u7ed9\u51fa\u7b97\u6cd5\u5e76\u63a8\u5bfc\u7b97\u6cd5\u5143\u5b9a\u7406\u3002", "motivation": "\u7ecf\u5178\u5b50\u5f0f\u6982\u5ff5\u65e0\u6cd5\u5f88\u597d\u5904\u7406\u542b\u6ce8\u91ca\u9876\u70b9\u96c6\u7684\u56fe\u7b97\u6cd5\u95ee\u9898\uff0c\u9700\u5f15\u5165\u5f69\u8272\u5b50\u5f0f\u6982\u5ff5\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u5efa\u7acb\u523b\u753b\u4e0d\u542b\u7279\u5b9a\u5f69\u8272\u5b50\u5f0f\u56fe\u7684\u5b9a\u7406\uff0c\u5229\u7528\u7ed3\u6784\u7406\u8bba\u8fdb\u884c\u5f69\u8272\u56fe\u5206\u7c7b\uff0c\u8bbe\u8ba1\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u7b97\u6cd5\u3002", "result": "\u5b8c\u6210\u5f69\u8272\u56fe\u5206\u7c7b\uff0c\u5f97\u5230\u5f69\u8272\u5b50\u5f0f\u6d4b\u8bd5\u548ck - \u4e0d\u76f8\u4ea4\u8def\u5f84\u95ee\u9898\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u5904\u7406\u7b97\u6cd5\uff0c\u63a8\u5bfc\u4e24\u4e2a\u7b97\u6cd5\u5143\u5b9a\u7406\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\u5df2\u77e5\u7b97\u6cd5\u5143\u5b9a\u7406\u53ef\u6269\u5c55\uff0c\u540c\u65f6\u8003\u8651\u8f93\u5165\u56fe\u7ed3\u6784\u548c\u5f69\u8272\u9876\u70b9\u5206\u5e03\u3002"}}
{"id": "2507.09529", "pdf": "https://arxiv.org/pdf/2507.09529", "abs": "https://arxiv.org/abs/2507.09529", "authors": ["Yunqian Wang", "Xiaohong Li", "Yao Zhang", "Yuekang Li", "Zhiping Zhou", "Ruitao Feng"], "title": "It Only Gets Worse: Revisiting DL-Based Vulnerability Detectors from a Practical Perspective", "categories": ["cs.SE"], "comment": null, "summary": "With the growing threat of software vulnerabilities, deep learning (DL)-based\ndetectors have gained popularity for vulnerability detection. However, doubts\nremain regarding their consistency within declared CWE ranges, real-world\neffectiveness, and applicability across scenarios. These issues may lead to\nunreliable detection, high false positives/negatives, and poor adaptability to\nemerging vulnerabilities. A comprehensive analysis is needed to uncover\ncritical factors affecting detection and guide improvements in model design and\ndeployment. In this paper, we present VulTegra, a novel evaluation framework\nthat conducts a multidimensional comparison of scratch-trained and\npre-trained-based DL models for vulnerability detection. VulTegra reveals that\nstate-of-the-art (SOTA) detectors still suffer from low consistency, limited\nreal-world capabilities, and scalability challenges. Contrary to common belief,\npre-trained models are not consistently better than scratch-trained models but\nexhibit distinct strengths in specific contexts.Importantly, our study exposes\nthe limitations of relying solely on CWE-based classification and identifies\nkey factors that significantly affect model performance. Experimental results\nshow that adjusting just one such factor consistently improves recall across\nall seven evaluated detectors, with six also achieving better F1 scores. Our\nfindings provide deeper insights into model behavior and emphasize the need to\nconsider both vulnerability types and inherent code features for effective\ndetection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVulTegra\u8bc4\u4f30\u6846\u67b6\u5bf9\u6bd4\u4e0d\u540c\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u6a21\u578b\uff0c\u63ed\u793aSOTA\u68c0\u6d4b\u5668\u95ee\u9898\uff0c\u6307\u51fa\u9884\u8bad\u7ec3\u6a21\u578b\u4e0d\u603b\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u6a21\u578b\uff0c\u8c03\u6574\u5173\u952e\u56e0\u7d20\u53ef\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u5668\u5728\u58f0\u660e\u7684CWE\u8303\u56f4\u4e00\u81f4\u6027\u3001\u73b0\u5b9e\u6709\u6548\u6027\u548c\u573a\u666f\u9002\u7528\u6027\u65b9\u9762\u5b58\u7591\uff0c\u9700\u5168\u9762\u5206\u6790\u5f71\u54cd\u68c0\u6d4b\u7684\u5173\u952e\u56e0\u7d20\u4ee5\u6539\u8fdb\u6a21\u578b\u8bbe\u8ba1\u548c\u90e8\u7f72\u3002", "method": "\u63d0\u51faVulTegra\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u4ece\u5934\u8bad\u7ec3\u548c\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u6a21\u578b\u8fdb\u884c\u591a\u7ef4\u6bd4\u8f83\u3002", "result": "SOTA\u68c0\u6d4b\u5668\u5b58\u5728\u4e00\u81f4\u6027\u4f4e\u3001\u73b0\u5b9e\u80fd\u529b\u6709\u9650\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff1b\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u7279\u5b9a\u573a\u666f\u6709\u4f18\u52bf\uff1b\u8c03\u6574\u4e00\u4e2a\u5173\u952e\u56e0\u7d20\u53ef\u63d0\u5347\u6240\u6709\u4e03\u4e2a\u8bc4\u4f30\u68c0\u6d4b\u5668\u7684\u53ec\u56de\u7387\uff0c\u516d\u4e2a\u68c0\u6d4b\u5668\u7684F1\u5206\u6570\u4e5f\u66f4\u597d\u3002", "conclusion": "\u7814\u7a76\u6df1\u5165\u4e86\u89e3\u6a21\u578b\u884c\u4e3a\uff0c\u5f3a\u8c03\u6709\u6548\u68c0\u6d4b\u9700\u540c\u65f6\u8003\u8651\u6f0f\u6d1e\u7c7b\u578b\u548c\u4ee3\u7801\u56fa\u6709\u7279\u5f81\u3002"}}
{"id": "2507.08861", "pdf": "https://arxiv.org/pdf/2507.08861", "abs": "https://arxiv.org/abs/2507.08861", "authors": ["Lucas Tesan", "Mikel M. Iparraguirre", "David Gonzalez", "Pedro Martins", "Elias Cueto"], "title": "On the under-reaching phenomenon in message-passing neural PDE solvers: revisiting the CFL condition", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper proposes sharp lower bounds for the number of message passing\niterations required in graph neural networks (GNNs) when solving partial\ndifferential equations (PDE). This significantly reduces the need for\nexhaustive hyperparameter tuning. Bounds are derived for the three fundamental\nclasses of PDEs (hyperbolic, parabolic and elliptic) by relating the physical\ncharacteristics of the problem in question to the message-passing requirement\nof GNNs. In particular, we investigate the relationship between the physical\nconstants of the equations governing the problem, the spatial and temporal\ndiscretisation and the message passing mechanisms in GNNs.\n  When the number of message passing iterations is below these proposed limits,\ninformation does not propagate efficiently through the network, resulting in\npoor solutions, even for deep GNN architectures. In contrast, when the\nsuggested lower bound is satisfied, the GNN parameterisation allows the model\nto accurately capture the underlying phenomenology, resulting in solvers of\nadequate accuracy.\n  Examples are provided for four different examples of equations that show the\nsharpness of the proposed lower bounds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u6d88\u606f\u4f20\u9012\u8fed\u4ee3\u6b21\u6570\u7684\u5c16\u9510\u4e0b\u754c\uff0c\u51cf\u5c11\u8d85\u53c2\u6570\u8c03\u4f18\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u51cf\u5c11\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u504f\u5fae\u5206\u65b9\u7a0b\u65f6\u8d85\u53c2\u6570\u7684\u8be6\u5c3d\u8c03\u4f18\u9700\u6c42\u3002", "method": "\u5c06\u504f\u5fae\u5206\u65b9\u7a0b\u4e09\u7c7b\u95ee\u9898\u7684\u7269\u7406\u7279\u6027\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\u6d88\u606f\u4f20\u9012\u8981\u6c42\u5173\u8054\uff0c\u7814\u7a76\u65b9\u7a0b\u7269\u7406\u5e38\u6570\u3001\u65f6\u7a7a\u79bb\u6563\u5316\u4e0e\u6d88\u606f\u4f20\u9012\u673a\u5236\u7684\u5173\u7cfb\u3002", "result": "\u5f53\u6d88\u606f\u4f20\u9012\u8fed\u4ee3\u6b21\u6570\u4f4e\u4e8e\u4e0b\u754c\uff0c\u7f51\u7edc\u4fe1\u606f\u4f20\u64ad\u4f4e\u6548\u3001\u89e3\u8d28\u91cf\u5dee\uff1b\u6ee1\u8db3\u4e0b\u754c\u65f6\uff0c\u6a21\u578b\u80fd\u51c6\u786e\u6355\u6349\u73b0\u8c61\u5b66\uff0c\u6c42\u89e3\u5668\u6709\u8db3\u591f\u7cbe\u5ea6\u3002", "conclusion": "\u6240\u63d0\u4e0b\u754c\u662f\u5c16\u9510\u7684\uff0c\u901a\u8fc7\u56db\u4e2a\u4e0d\u540c\u65b9\u7a0b\u5b9e\u4f8b\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2507.09579", "pdf": "https://arxiv.org/pdf/2507.09579", "abs": "https://arxiv.org/abs/2507.09579", "authors": ["Marc Bara"], "title": "PromptChain: A Decentralized Web3 Architecture for Managing AI Prompts as Digital Assets", "categories": ["cs.CR", "cs.DC", "68M14, 94A60", "H.3.4; K.6.5; H.3.5"], "comment": "14 pages, 6 figures", "summary": "We present PromptChain, a decentralized Web3 architecture that establishes AI\nprompts as first-class digital assets with verifiable ownership, version\ncontrol, and monetization capabilities. Current centralized platforms lack\nmechanisms for proper attribution, quality assurance, or fair compensation for\nprompt creators. PromptChain addresses these limitations through a novel\nintegration of IPFS for immutable storage, smart contracts for governance, and\ntoken incentives for community curation. Our design includes: (1) a\ncomprehensive metadata schema for cross-model compatibility, (2) a\nstake-weighted validation mechanism to align incentives, and (3) a token\neconomy that rewards contributors proportionally to their impact. The proposed\narchitecture demonstrates how decentralized systems could potentially match\ncentralized alternatives in efficiency while providing superior ownership\nguarantees and censorship resistance through blockchain-anchored provenance\ntracking. By decoupling prompts from specific AI models or outputs, this work\nestablishes the foundation for an open ecosystem of human-AI collaboration in\nthe Web3 era, representing the first systematic treatment of prompts as\nstandalone digital assets with dedicated decentralized infrastructure.", "AI": {"tldr": "\u63d0\u51faPromptChain\u53bb\u4e2d\u5fc3\u5316Web3\u67b6\u6784\uff0c\u5c06AI\u63d0\u793a\u4f5c\u4e3a\u4e00\u7b49\u6570\u5b57\u8d44\u4ea7\uff0c\u89e3\u51b3\u73b0\u6709\u4e2d\u5fc3\u5316\u5e73\u53f0\u95ee\u9898\uff0c\u4e3aWeb3\u65f6\u4ee3\u4eba\u673a\u534f\u4f5c\u5f00\u653e\u751f\u6001\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u4e2d\u5fc3\u5316\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u63d0\u793a\u521b\u4f5c\u8005\u7684\u9002\u5f53\u5f52\u5c5e\u3001\u8d28\u91cf\u4fdd\u8bc1\u548c\u516c\u5e73\u8865\u507f\u673a\u5236\u3002", "method": "\u901a\u8fc7\u96c6\u6210IPFS\u8fdb\u884c\u4e0d\u53ef\u53d8\u5b58\u50a8\u3001\u667a\u80fd\u5408\u7ea6\u8fdb\u884c\u6cbb\u7406\u3001\u4ee3\u5e01\u6fc0\u52b1\u8fdb\u884c\u793e\u533a\u7b56\u5c55\uff0c\u8bbe\u8ba1\u5168\u9762\u5143\u6570\u636e\u6a21\u5f0f\u3001\u6743\u76ca\u52a0\u6743\u9a8c\u8bc1\u673a\u5236\u548c\u4ee3\u5e01\u7ecf\u6d4e\u3002", "result": "\u8be5\u67b6\u6784\u80fd\u5728\u6548\u7387\u4e0a\u4e0e\u4e2d\u5fc3\u5316\u65b9\u6848\u5ab2\u7f8e\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u6240\u6709\u6743\u4fdd\u969c\u548c\u6297\u5ba1\u67e5\u80fd\u529b\u3002", "conclusion": "\u6b64\u5de5\u4f5c\u4e3aWeb3\u65f6\u4ee3\u4eba\u673a\u534f\u4f5c\u5f00\u653e\u751f\u6001\u5960\u5b9a\u57fa\u7840\uff0c\u662f\u5bf9\u63d0\u793a\u4f5c\u4e3a\u72ec\u7acb\u6570\u5b57\u8d44\u4ea7\u7684\u9996\u6b21\u7cfb\u7edf\u5904\u7406\u3002"}}
{"id": "2507.09055", "pdf": "https://arxiv.org/pdf/2507.09055", "abs": "https://arxiv.org/abs/2507.09055", "authors": ["Mkululi Sikosana", "Sean Maudsley-Barton", "Oluwaseun Ajao"], "title": "Analysing Health Misinformation with Advanced Centrality Metrics in Online Social Networks", "categories": ["cs.SI", "cs.IR", "physics.soc-ph", "H.3.3"], "comment": "10 Pages, 2 figures, 3 tables, journal article in PLOS Digital Health\n  (2025)", "summary": "The rapid spread of health misinformation on online social networks (OSNs)\nduring global crises such as the COVID-19 pandemic poses challenges to public\nhealth, social stability, and institutional trust. Centrality metrics have long\nbeen pivotal in understanding the dynamics of information flow, particularly in\nthe context of health misinformation. However, the increasing complexity and\ndynamism of online networks, especially during crises, highlight the\nlimitations of these traditional approaches. This study introduces and compares\nthree novel centrality metrics: dynamic influence centrality (DIC), health\nmisinformation vulnerability centrality (MVC), and propagation centrality (PC).\nThese metrics incorporate temporal dynamics, susceptibility, and multilayered\nnetwork interactions. Using the FibVID dataset, we compared traditional and\nnovel metrics to identify influential nodes, propagation pathways, and\nmisinformation influencers. Traditional metrics identified 29 influential\nnodes, while the new metrics uncovered 24 unique nodes, resulting in 42\ncombined nodes, an increase of 44.83%. Baseline interventions reduced health\nmisinformation by 50%, while incorporating the new metrics increased this to\n62.5%, an improvement of 25%. To evaluate the broader applicability of the\nproposed metrics, we validated our framework on a second dataset, Monant\nMedical Misinformation, which covers a diverse range of health misinformation\ndiscussions beyond COVID-19. The results confirmed that the advanced metrics\ngeneralised successfully, identifying distinct influential actors not captured\nby traditional methods. In general, the findings suggest that a combination of\ntraditional and novel centrality measures offers a more robust and\ngeneralisable framework for understanding and mitigating the spread of health\nmisinformation in different online network contexts.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e09\u79cd\u65b0\u7684\u4e2d\u5fc3\u6027\u6307\u6807\uff0c\u7ed3\u5408\u4f20\u7edf\u6307\u6807\u4ee5\u5e94\u5bf9\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u5065\u5eb7\u8c23\u8a00\u4f20\u64ad\u95ee\u9898\uff0c\u65b0\u6307\u6807\u5728\u8bc6\u522b\u8282\u70b9\u548c\u51cf\u5c11\u8c23\u8a00\u4f20\u64ad\u4e0a\u6548\u679c\u66f4\u597d\uff0c\u7efc\u5408\u6307\u6807\u6846\u67b6\u66f4\u6709\u6548\u3002", "motivation": "\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u4e2d\u5065\u5eb7\u8c23\u8a00\u5feb\u901f\u4f20\u64ad\u5e26\u6765\u6311\u6218\uff0c\u4f20\u7edf\u4e2d\u5fc3\u6027\u6307\u6807\u5728\u590d\u6742\u52a8\u6001\u7f51\u7edc\u4e2d\u5b58\u5728\u5c40\u9650\u3002", "method": "\u5f15\u5165\u52a8\u6001\u5f71\u54cd\u4e2d\u5fc3\u6027\u3001\u5065\u5eb7\u8c23\u8a00\u8106\u5f31\u6027\u4e2d\u5fc3\u6027\u548c\u4f20\u64ad\u4e2d\u5fc3\u6027\u4e09\u79cd\u65b0\u6307\u6807\uff0c\u7ed3\u5408FibVID\u548cMonant Medical Misinformation\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u4f20\u7edf\u548c\u65b0\u6307\u6807\u7684\u6548\u679c\u3002", "result": "\u65b0\u6307\u6807\u8bc6\u522b\u51fa\u66f4\u591a\u72ec\u7279\u8282\u70b9\uff0c\u7ed3\u5408\u4f20\u7edf\u6307\u6807\u4f7f\u8bc6\u522b\u8282\u70b9\u589e\u52a044.83%\uff1b\u7ed3\u5408\u65b0\u6307\u6807\u5e72\u9884\u4f7f\u5065\u5eb7\u8c23\u8a00\u51cf\u5c11\u6bd4\u4f8b\u4ece50%\u63d0\u5347\u81f362.5%\uff0c\u63d0\u534725%\uff1b\u65b0\u6307\u6807\u5728\u7b2c\u4e8c\u4e2a\u6570\u636e\u96c6\u4e0a\u4e5f\u80fd\u6210\u529f\u8bc6\u522b\u72ec\u7279\u5f71\u54cd\u8005\u3002", "conclusion": "\u4f20\u7edf\u548c\u65b0\u7684\u4e2d\u5fc3\u6027\u6307\u6807\u7ed3\u5408\uff0c\u80fd\u63d0\u4f9b\u66f4\u5f3a\u5927\u3001\u901a\u7528\u7684\u6846\u67b6\u6765\u7406\u89e3\u548c\u7f13\u89e3\u4e0d\u540c\u5728\u7ebf\u7f51\u7edc\u4e2d\u5065\u5eb7\u8c23\u8a00\u7684\u4f20\u64ad\u3002"}}
{"id": "2507.09626", "pdf": "https://arxiv.org/pdf/2507.09626", "abs": "https://arxiv.org/abs/2507.09626", "authors": ["Rodion Nazarov", "Anthony Quinn", "Robert Shorten", "Jakub Marecek"], "title": "humancompatible.interconnect: Testing Properties of Repeated Uses of Interconnections of AI Systems", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Artificial intelligence (AI) systems often interact with multiple agents. The\nregulation of such AI systems often requires that {\\em a priori\\/} guarantees\nof fairness and robustness be satisfied. With stochastic models of agents'\nresponses to the outputs of AI systems, such {\\em a priori\\/} guarantees\nrequire non-trivial reasoning about the corresponding stochastic systems. Here,\nwe present an open-source PyTorch-based toolkit for the use of stochastic\ncontrol techniques in modelling interconnections of AI systems and properties\nof their repeated uses. It models robustness and fairness desiderata in a\nclosed-loop fashion, and provides {\\em a priori\\/} guarantees for these\ninterconnections. The PyTorch-based toolkit removes much of the complexity\nassociated with the provision of fairness guarantees for closed-loop models of\nmulti-agent systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8ePyTorch\u7684\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u968f\u673a\u63a7\u5236\u6280\u672f\u5efa\u6a21AI\u7cfb\u7edf\u4e92\u8fde\u5e76\u63d0\u4f9b\u5148\u9a8c\u4fdd\u8bc1\uff0c\u964d\u4f4e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u95ed\u73af\u6a21\u578b\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u590d\u6742\u5ea6\u3002", "motivation": "AI\u7cfb\u7edf\u5e38\u4e0e\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\uff0c\u5176\u76d1\u7ba1\u9700\u6ee1\u8db3\u516c\u5e73\u6027\u548c\u9c81\u68d2\u6027\u7684\u5148\u9a8c\u4fdd\u8bc1\uff0c\u800c\u968f\u673a\u6a21\u578b\u9700\u8981\u5bf9\u968f\u673a\u7cfb\u7edf\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u4f7f\u7528\u57fa\u4e8ePyTorch\u7684\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u8fd0\u7528\u968f\u673a\u63a7\u5236\u6280\u672f\u5bf9AI\u7cfb\u7edf\u4e92\u8fde\u53ca\u5176\u91cd\u590d\u4f7f\u7528\u5c5e\u6027\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u4ee5\u95ed\u73af\u65b9\u5f0f\u5bf9\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u9700\u6c42\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u4e3a\u4e92\u8fde\u63d0\u4f9b\u5148\u9a8c\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u5de5\u5177\u5305\u964d\u4f4e\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u95ed\u73af\u6a21\u578b\u63d0\u4f9b\u516c\u5e73\u6027\u4fdd\u8bc1\u7684\u590d\u6742\u5ea6\u3002"}}
{"id": "2507.09583", "pdf": "https://arxiv.org/pdf/2507.09583", "abs": "https://arxiv.org/abs/2507.09583", "authors": ["Taniv Ashraf"], "title": "A Serverless Architecture for Real-Time Stock Analysis using Large Language Models: An Iterative Development and Debugging Case Study", "categories": ["cs.SE", "cs.AI", "I.2.7; J.1"], "comment": "6 pages. The live application can be viewed at\n  https://codepen.io/tanivashraf/pen/GgpgxBY and the source code is available\n  at https://github.com/TanivAshraf/ai-stock-analyzer", "summary": "The advent of powerful, accessible Large Language Models (LLMs) like Google's\nGemini presents new opportunities for democratizing financial data analysis.\nThis paper documents the design, implementation, and iterative debugging of a\nnovel, serverless system for real-time stock analysis. The system leverages the\nGemini API for qualitative assessment, automates data ingestion and processing\nvia GitHub Actions, and presents the findings through a decoupled, static\nfrontend. We detail the architectural evolution of the system, from initial\nconcepts to a robust, event-driven pipeline, highlighting the practical\nchallenges encountered during deployment. A significant portion of this paper\nis dedicated to a case study on the debugging process, covering common software\nerrors, platform-specific permission issues, and rare, environment-level\nplatform bugs. The final architecture operates at a near-zero cost,\ndemonstrating a viable model for individuals to build sophisticated AI-powered\nfinancial tools. The operational application is publicly accessible, and the\ncomplete source code is available for review. We conclude by discussing the\nrole of LLMs in financial analysis, the importance of robust debugging\nmethodologies, and the emerging paradigm of human-AI collaboration in software\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5229\u7528Gemini API\u7684\u5b9e\u65f6\u80a1\u7968\u5206\u6790\u65e0\u670d\u52a1\u5668\u7cfb\u7edf\uff0c\u8be6\u8ff0\u67b6\u6784\u6f14\u53d8\u3001\u8c03\u8bd5\u8fc7\u7a0b\uff0c\u6700\u7ec8\u7cfb\u7edf\u6210\u672c\u8fd1\u96f6\uff0c\u516c\u5f00\u4ee3\u7801\uff0c\u8fd8\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u6790\u7b49\u65b9\u9762\u7684\u4f5c\u7528\u3002", "motivation": "\u5f3a\u5927\u4e14\u6613\u83b7\u53d6\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u91d1\u878d\u6570\u636e\u5206\u6790\u6c11\u4e3b\u5316\u5e26\u6765\u65b0\u673a\u9047\uff0c\u8bbe\u8ba1\u65b0\u7cfb\u7edf\u5b9e\u73b0\u5b9e\u65f6\u80a1\u7968\u5206\u6790\u3002", "method": "\u5229\u7528Gemini API\u8fdb\u884c\u5b9a\u6027\u8bc4\u4f30\uff0c\u901a\u8fc7GitHub Actions\u81ea\u52a8\u5316\u6570\u636e\u6444\u53d6\u548c\u5904\u7406\uff0c\u7528\u89e3\u8026\u9759\u6001\u524d\u7aef\u5c55\u793a\u7ed3\u679c\u3002", "result": "\u6700\u7ec8\u67b6\u6784\u6210\u672c\u8fd1\u96f6\uff0c\u7cfb\u7edf\u53ef\u516c\u5f00\u8bbf\u95ee\uff0c\u4ee3\u7801\u53ef\u67e5\u770b\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u6790\u4e2d\u7684\u4f5c\u7528\u3001\u5065\u58ee\u8c03\u8bd5\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u7684\u65b0\u5174\u6a21\u5f0f\u3002"}}
{"id": "2507.08866", "pdf": "https://arxiv.org/pdf/2507.08866", "abs": "https://arxiv.org/abs/2507.08866", "authors": ["Marina Ceccon", "Giandomenico Cornacchia", "Davide Dalle Pezze", "Alessandro Fabris", "Gian Antonio Susto"], "title": "Underrepresentation, Label Bias, and Proxies: Towards Data Bias Profiles for the EU AI Act and Beyond", "categories": ["cs.LG", "cs.CY", "stat.ML"], "comment": "Accepted in Expert Systems with Applications", "summary": "Undesirable biases encoded in the data are key drivers of algorithmic\ndiscrimination. Their importance is widely recognized in the algorithmic\nfairness literature, as well as legislation and standards on\nanti-discrimination in AI. Despite this recognition, data biases remain\nunderstudied, hindering the development of computational best practices for\ntheir detection and mitigation. In this work, we present three common data\nbiases and study their individual and joint effect on algorithmic\ndiscrimination across a variety of datasets, models, and fairness measures. We\nfind that underrepresentation of vulnerable populations in training sets is\nless conducive to discrimination than conventionally affirmed, while\ncombinations of proxies and label bias can be far more critical. Consequently,\nwe develop dedicated mechanisms to detect specific types of bias, and combine\nthem into a preliminary construct we refer to as the Data Bias Profile (DBP).\nThis initial formulation serves as a proof of concept for how different bias\nsignals can be systematically documented. Through a case study with popular\nfairness datasets, we demonstrate the effectiveness of the DBP in predicting\nthe risk of discriminatory outcomes and the utility of fairness-enhancing\ninterventions. Overall, this article bridges algorithmic fairness research and\nanti-discrimination policy through a data-centric lens.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5e38\u89c1\u6570\u636e\u504f\u5dee\u5bf9\u7b97\u6cd5\u6b67\u89c6\u7684\u5f71\u54cd\uff0c\u5f00\u53d1\u68c0\u6d4b\u673a\u5236\u5f62\u6210\u6570\u636e\u504f\u5dee\u6982\u51b5\uff08DBP\uff09\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u8bc1\u660e\u5176\u6709\u6548\u6027\uff0c\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u8fde\u63a5\u7b97\u6cd5\u516c\u5e73\u7814\u7a76\u4e0e\u53cd\u6b67\u89c6\u653f\u7b56\u3002", "motivation": "\u6570\u636e\u504f\u5dee\u5bf9\u7b97\u6cd5\u6b67\u89c6\u5f71\u54cd\u5927\u4f46\u7814\u7a76\u4e0d\u8db3\uff0c\u963b\u788d\u68c0\u6d4b\u548c\u7f13\u89e3\u504f\u5dee\u7684\u8ba1\u7b97\u6700\u4f73\u5b9e\u8df5\u53d1\u5c55\u3002", "method": "\u7814\u7a76\u4e09\u79cd\u5e38\u89c1\u6570\u636e\u504f\u5dee\u5728\u4e0d\u540c\u6570\u636e\u96c6\u3001\u6a21\u578b\u548c\u516c\u5e73\u6027\u6307\u6807\u4e0b\u5bf9\u7b97\u6cd5\u6b67\u89c6\u7684\u5355\u72ec\u548c\u8054\u5408\u5f71\u54cd\uff0c\u5f00\u53d1\u68c0\u6d4b\u7279\u5b9a\u504f\u5dee\u7684\u673a\u5236\u5e76\u7ec4\u6210DBP\uff0c\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u53d1\u73b0\u8bad\u7ec3\u96c6\u4e2d\u5f31\u52bf\u7fa4\u4f53\u4ee3\u8868\u6027\u4e0d\u8db3\u5bf9\u6b67\u89c6\u7684\u5f71\u54cd\u5c0f\u4e8e\u4f20\u7edf\u8ba4\u77e5\uff0c\u4ee3\u7406\u548c\u6807\u7b7e\u504f\u5dee\u7ec4\u5408\u66f4\u5173\u952e\uff0cDBP\u80fd\u6709\u6548\u9884\u6d4b\u6b67\u89c6\u6027\u7ed3\u679c\u98ce\u9669\u548c\u516c\u5e73\u5e72\u9884\u6548\u7528\u3002", "conclusion": "\u6587\u7ae0\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u8fde\u63a5\u4e86\u7b97\u6cd5\u516c\u5e73\u7814\u7a76\u548c\u53cd\u6b67\u89c6\u653f\u7b56\u3002"}}
{"id": "2507.09942", "pdf": "https://arxiv.org/pdf/2507.09942", "abs": "https://arxiv.org/abs/2507.09942", "authors": ["Jiaming Cheng", "Duong Tung Nguyen"], "title": "Green-LLM: Optimal Workload Allocation for Environmentally-Aware Distributed Inference", "categories": ["cs.NI", "cs.DC", "cs.SY", "eess.SY", "math.OC"], "comment": "5 pages, 11 figures", "summary": "This letter investigates the optimal allocation of large language model (LLM)\ninference workloads across heterogeneous edge data centers (DCs) over time.\nEach DC features on-site renewable generation and faces dynamic electricity\nprices and spatiotemporal variability in renewable availability. The central\nquestion is: how can inference workloads be optimally distributed to the DCs to\nminimize energy consumption, carbon emissions, and water usage while enhancing\nuser experience? This letter proposes a novel optimization model for LLM\nservice providers to reduce operational costs and environmental impacts.\nNumerical results validate the efficacy of the proposed approach.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u5728\u5f02\u6784\u8fb9\u7f18\u6570\u636e\u4e2d\u5fc3\u7684\u6700\u4f18\u5206\u914d\uff0c\u63d0\u51fa\u4f18\u5316\u6a21\u578b\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5982\u4f55\u5728\u5f02\u6784\u8fb9\u7f18\u6570\u636e\u4e2d\u5fc3\u6700\u4f18\u5206\u914d\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4ee5\u964d\u4f4e\u80fd\u8017\u3001\u78b3\u6392\u653e\u548c\u6c34\u6d88\u8017\uff0c\u540c\u65f6\u63d0\u5347\u7528\u6237\u4f53\u9a8c\uff0c\u51cf\u5c11\u8fd0\u8425\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u4f18\u5316\u6a21\u578b\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f18\u5316\u6a21\u578b\u53ef\u5e2e\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u63d0\u4f9b\u5546\u51cf\u5c11\u8fd0\u8425\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\u3002"}}
{"id": "2507.09068", "pdf": "https://arxiv.org/pdf/2507.09068", "abs": "https://arxiv.org/abs/2507.09068", "authors": ["Dell Zhang", "Xiangyu Chen", "Jixiang Luo", "Mengxi Jia", "Changzhi Sun", "Ruilong Ren", "Jingren Liu", "Hao Sun", "Xuelong Li"], "title": "Infinite Video Understanding", "categories": ["cs.CV", "cs.AI", "cs.IR", "cs.LG", "cs.MM"], "comment": null, "summary": "The rapid advancements in Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) have ushered in remarkable progress in video understanding.\nHowever, a fundamental challenge persists: effectively processing and\ncomprehending video content that extends beyond minutes or hours. While recent\nefforts like Video-XL-2 have demonstrated novel architectural solutions for\nextreme efficiency, and advancements in positional encoding such as HoPE and\nVideoRoPE++ aim to improve spatio-temporal understanding over extensive\ncontexts, current state-of-the-art models still encounter significant\ncomputational and memory constraints when faced with the sheer volume of visual\ntokens from lengthy sequences. Furthermore, maintaining temporal coherence,\ntracking complex events, and preserving fine-grained details over extended\nperiods remain formidable hurdles, despite progress in agentic reasoning\nsystems like Deep Video Discovery. This position paper posits that a logical,\nalbeit ambitious, next frontier for multimedia research is Infinite Video\nUnderstanding -- the capability for models to continuously process, understand,\nand reason about video data of arbitrary, potentially never-ending duration. We\nargue that framing Infinite Video Understanding as a blue-sky research\nobjective provides a vital north star for the multimedia, and the wider AI,\nresearch communities, driving innovation in areas such as streaming\narchitectures, persistent memory mechanisms, hierarchical and adaptive\nrepresentations, event-centric reasoning, and novel evaluation paradigms.\nDrawing inspiration from recent work on long/ultra-long video understanding and\nseveral closely related fields, we outline the core challenges and key research\ndirections towards achieving this transformative capability.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u591a\u6a21\u6001\u6269\u5c55\u63a8\u52a8\u89c6\u9891\u7406\u89e3\u8fdb\u6b65\uff0c\u4f46\u5904\u7406\u957f\u65f6\u95f4\u89c6\u9891\u4ecd\u6709\u6311\u6218\uff0c\u63d0\u51fa\u65e0\u9650\u89c6\u9891\u7406\u89e3\u8fd9\u4e00\u524d\u6cbf\u7814\u7a76\u65b9\u5411\u5e76\u5217\u51fa\u6838\u5fc3\u6311\u6218\u548c\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u5904\u7406\u957f\u65f6\u95f4\u89c6\u9891\u5b58\u5728\u8ba1\u7b97\u3001\u5185\u5b58\u7ea6\u675f\u53ca\u4fdd\u6301\u65f6\u95f4\u8fde\u8d2f\u6027\u7b49\u96be\u9898\uff0c\u9700\u8981\u65b0\u7684\u7814\u7a76\u65b9\u5411\u63a8\u52a8\u53d1\u5c55\u3002", "method": "\u501f\u9274\u957f/\u8d85\u957f\u89c6\u9891\u7406\u89e3\u53ca\u76f8\u5173\u9886\u57df\u5de5\u4f5c\uff0c\u63d0\u51fa\u65e0\u9650\u89c6\u9891\u7406\u89e3\u6982\u5ff5\u5e76\u786e\u5b9a\u6838\u5fc3\u6311\u6218\u548c\u7814\u7a76\u65b9\u5411\u3002", "result": "\u660e\u786e\u65e0\u9650\u89c6\u9891\u7406\u89e3\u8fd9\u4e00\u524d\u6cbf\u7814\u7a76\u65b9\u5411\uff0c\u6307\u51fa\u5176\u80fd\u4e3a\u591a\u5a92\u4f53\u548cAI\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u6307\u5f15\u3002", "conclusion": "\u65e0\u9650\u89c6\u9891\u7406\u89e3\u662f\u591a\u5a92\u4f53\u7814\u7a76\u7684\u4e0b\u4e00\u4e2a\u524d\u6cbf\uff0c\u80fd\u9a71\u52a8\u591a\u4e2a\u9886\u57df\u7684\u521b\u65b0\u3002"}}
{"id": "2507.09662", "pdf": "https://arxiv.org/pdf/2507.09662", "abs": "https://arxiv.org/abs/2507.09662", "authors": ["Jason Zhu", "Hongyu Li"], "title": "Towards Concise and Adaptive Thinking in Large Reasoning Models: A Survey", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large reasoning models (LRMs) like OpenAI o1 and DeepSeek R1 have\ndemonstrated impressive performance on complex reasoning tasks like mathematics\nand programming with long Chain-of-Thought (CoT) reasoning sequences\n(slow-thinking), compared with traditional large language models\n(fast-thinking). However, these reasoning models also face a huge challenge\nthat generating unnecessarily lengthy and redundant reasoning chains even for\ntrivial questions. This phenomenon leads to a significant waste of inference\nresources, increases the response time for simple queries, and hinders the\npractical application of LRMs in real-world products. To this end, it is\ncrucial to shorten lengthy reasoning chains and learn adaptive reasoning\nbetween fast and slow thinking based on input difficulty. In this survey, we\nprovide a comprehensive overview of recent progress in concise and adaptive\nthinking for efficient reasoning of LRMs, including methodologies, benchmarks,\nand challenges for future exploration. We hope this survey can help researchers\nquickly understand the landscape of this field and inspire novel adaptive\nthinking ideas to facilitate better usage of LRMs.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u63a8\u7406\u6a21\u578b\u7b80\u6d01\u548c\u81ea\u9002\u5e94\u601d\u8003\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u7684\u8fdb\u5c55\uff0c\u5305\u62ec\u65b9\u6cd5\u3001\u57fa\u51c6\u548c\u6311\u6218\uff0c\u52a9\u7814\u7a76\u8005\u4e86\u89e3\u8be5\u9886\u57df\u3002", "motivation": "\u5927\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u751f\u6210\u5197\u957f\u5197\u4f59\u63a8\u7406\u94fe\uff0c\u6d6a\u8d39\u8d44\u6e90\u3001\u589e\u52a0\u54cd\u5e94\u65f6\u95f4\uff0c\u963b\u788d\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u7f29\u77ed\u63a8\u7406\u94fe\u5e76\u5b66\u4e60\u81ea\u9002\u5e94\u601d\u8003\u3002", "method": "\u5bf9\u5927\u63a8\u7406\u6a21\u578b\u7b80\u6d01\u548c\u81ea\u9002\u5e94\u601d\u8003\u7684\u76f8\u5173\u8fdb\u5c55\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\u3002", "result": "\u5448\u73b0\u4e86\u5927\u63a8\u7406\u6a21\u578b\u5728\u9ad8\u6548\u63a8\u7406\u65b9\u9762\u7684\u65b9\u6cd5\u8bba\u3001\u57fa\u51c6\u548c\u9762\u4e34\u7684\u6311\u6218\u3002", "conclusion": "\u5e0c\u671b\u80fd\u5e2e\u52a9\u7814\u7a76\u8005\u5feb\u901f\u4e86\u89e3\u8be5\u9886\u57df\uff0c\u6fc0\u53d1\u65b0\u7684\u81ea\u9002\u5e94\u601d\u8003\u60f3\u6cd5\u4ee5\u66f4\u597d\u5229\u7528\u5927\u63a8\u7406\u6a21\u578b\u3002"}}
{"id": "2507.09594", "pdf": "https://arxiv.org/pdf/2507.09594", "abs": "https://arxiv.org/abs/2507.09594", "authors": ["Aydin Homay"], "title": "How to Define Design in Industrial Control and Automation Software", "categories": ["cs.SE"], "comment": null, "summary": "Design is a fundamental aspect of engineering, enabling the creation of\nproducts, systems, and organizations to meet societal and/or business needs.\nHowever, the absence of a scientific foundation in design often results in\nsubjective decision-making, reducing both efficiency and innovation. This\nchallenge is particularly evident in the software industry and, by extension,\nin the domain of industrial control and automation systems (iCAS).\n  In this study, first we review the existing design definitions within the\nsoftware industry, challenge prevailing misconceptions about design, review\ndesign definition in the field of design theory and address key questions such\nas: When does design begin? How can design be defined scientifically? What\nconstitutes good design? and the difference between design and design language\nby relying on advancements in the field of design theory. We also evaluate the\ndistinction between ad-hoc and systematic design approaches, and present\narguments on how to balance complementary operational concerns while resolving\nconflicting evolutionary concerns.", "AI": {"tldr": "\u8bbe\u8ba1\u7f3a\u4e4f\u79d1\u5b66\u57fa\u7840\u5f71\u54cd\u6548\u7387\u548c\u521b\u65b0\uff0c\u672c\u6587\u4f9d\u6258\u8bbe\u8ba1\u7406\u8bba\u5bf9\u8f6f\u4ef6\u884c\u4e1a\u8bbe\u8ba1\u5b9a\u4e49\u7b49\u95ee\u9898\u8fdb\u884c\u7814\u7a76\u5e76\u63a2\u8ba8\u8bbe\u8ba1\u65b9\u6cd5\u5dee\u5f02\u53ca\u5e73\u8861\u76f8\u5173\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u8bbe\u8ba1\u7f3a\u4e4f\u79d1\u5b66\u57fa\u7840\u5bfc\u81f4\u4e3b\u89c2\u51b3\u7b56\u3001\u964d\u4f4e\u6548\u7387\u548c\u521b\u65b0\u7684\u95ee\u9898\uff0c\u5c24\u5176\u9488\u5bf9\u8f6f\u4ef6\u884c\u4e1a\u548c\u5de5\u4e1a\u63a7\u5236\u4e0e\u81ea\u52a8\u5316\u7cfb\u7edf\u9886\u57df\u3002", "method": "\u56de\u987e\u8f6f\u4ef6\u884c\u4e1a\u73b0\u6709\u8bbe\u8ba1\u5b9a\u4e49\uff0c\u6311\u6218\u6d41\u884c\u8bef\u89e3\uff0c\u53c2\u8003\u8bbe\u8ba1\u7406\u8bba\u9886\u57df\u7684\u8bbe\u8ba1\u5b9a\u4e49\uff0c\u89e3\u7b54\u8bbe\u8ba1\u76f8\u5173\u5173\u952e\u95ee\u9898\uff0c\u8bc4\u4f30\u4e34\u65f6\u548c\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u7684\u533a\u522b\u3002", "result": "\u6587\u6863\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c\u3002", "conclusion": "\u6587\u6863\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2507.08870", "pdf": "https://arxiv.org/pdf/2507.08870", "abs": "https://arxiv.org/abs/2507.08870", "authors": ["Yaowenqi Liu", "BingXu Meng", "Rui Pan", "Jerry Huang", "Tong Zhang"], "title": "GUIDE: Towards Scalable Advising for Research Ideas", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "The field of AI research is advancing at an unprecedented pace, enabling\nautomated hypothesis generation and experimental design across diverse domains\nsuch as biology, mathematics, and artificial intelligence. Despite these\nadvancements, there remains a significant gap in the availability of scalable\nadvising systems capable of providing high-quality, well-reasoned feedback to\nrefine proposed hypotheses and experimental designs. To address this challenge,\nwe explore key factors that underlie the development of robust advising\nsystems, including model size, context length, confidence estimation, and\nstructured reasoning processes. Our findings reveal that a relatively small\nmodel, when equipped with a well-compressed literature database and a\nstructured reasoning framework, can outperform powerful general-purpose\nlanguage models such as Deepseek-R1 in terms of acceptance rates for\nself-ranked top-30% submissions to ICLR 2025. Moreover, when limited to\nhigh-confidence predictions, our system achieves an acceptance rate exceeding\n90% on the ICLR 2025 test set, underscoring its potential to significantly\nenhance the quality and efficiency of hypothesis generation and experimental\ndesign. The code is released at\nhttps://github.com/HowardLiu0830/GUIDE-Research-Idea-Evaluation.", "AI": {"tldr": "AI\u7814\u7a76\u53d1\u5c55\u5feb\uff0c\u4f46\u53ef\u6269\u5c55\u5efa\u8bae\u7cfb\u7edf\u6709\u7f3a\u53e3\u3002\u7814\u7a76\u5173\u952e\u56e0\u7d20\u53d1\u73b0\u5c0f\u6a21\u578b\u642d\u914d\u7279\u5b9a\u914d\u7f6e\u8868\u73b0\u4f73\uff0c\u9ad8\u7f6e\u4fe1\u9884\u6d4b\u63a5\u53d7\u7387\u8d8590%\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "AI\u7814\u7a76\u867d\u8fdb\u5c55\u5feb\uff0c\u4f46\u7f3a\u4e4f\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u53cd\u9988\u4ee5\u5b8c\u5584\u5047\u8bbe\u548c\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u53ef\u6269\u5c55\u5efa\u8bae\u7cfb\u7edf\u3002", "method": "\u63a2\u7d22\u5f71\u54cd\u5f3a\u5927\u5efa\u8bae\u7cfb\u7edf\u5f00\u53d1\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5982\u6a21\u578b\u5927\u5c0f\u3001\u4e0a\u4e0b\u6587\u957f\u5ea6\u3001\u7f6e\u4fe1\u4f30\u8ba1\u548c\u7ed3\u6784\u5316\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u76f8\u5bf9\u5c0f\u7684\u6a21\u578b\u642d\u914d\u538b\u7f29\u6587\u732e\u6570\u636e\u5e93\u548c\u7ed3\u6784\u5316\u63a8\u7406\u6846\u67b6\uff0c\u5728ICLR 2025\u81ea\u6392\u540d\u524d30%\u63d0\u4ea4\u7684\u63a5\u53d7\u7387\u4e0a\u8d85\u5f3a\u5927\u901a\u7528\u8bed\u8a00\u6a21\u578b\uff1b\u9ad8\u7f6e\u4fe1\u9884\u6d4b\u5728ICLR 2025\u6d4b\u8bd5\u96c6\u63a5\u53d7\u7387\u8d8590%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6f5c\u529b\u663e\u8457\u63d0\u9ad8\u5047\u8bbe\u751f\u6210\u548c\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u8d28\u91cf\u4e0e\u6548\u7387\u3002"}}
{"id": "2507.10160", "pdf": "https://arxiv.org/pdf/2507.10160", "abs": "https://arxiv.org/abs/2507.10160", "authors": ["Manuel R\u00f6der", "Christoph Raab", "Frank-Michael Schleif"], "title": "Domain Borders Are There to Be Crossed With Federated Few-Shot Adaptation", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": "Extension of http://dx.doi.org/10.5220/0012351900003654", "summary": "Federated Learning has emerged as a leading paradigm for decentralized,\nprivacy-preserving learning, particularly relevant in the era of interconnected\nedge devices equipped with sensors. However, the practical implementation of\nFederated Learning faces three primary challenges: the need for human\ninvolvement in costly data labelling processes for target adaptation, covariate\nshift in client device data collection due to environmental factors affecting\nsensors, leading to discrepancies between source and target samples, and the\nimpracticality of continuous or regular model updates in resource-constrained\nenvironments due to limited data transmission capabilities and technical\nconstraints on channel availability and energy efficiency. To tackle these\nissues, we expand upon an efficient and scalable Federated Learning framework\ntailored for real-world client adaptation in industrial settings. This\nframework leverages a pre-trained source model comprising a deep backbone, an\nadaptation module, and a classifier running on a powerful server. By freezing\nthe backbone and classifier during client adaptation on resource-constrained\ndevices, we allow the domain adaptive linear layer to handle target domain\nadaptation, thus minimizing overall computational overhead. Furthermore, this\nsetup, designated as FedAcross+, is extended to encompass the processing of\nstreaming data, thereby rendering the solution suitable for non-stationary\nenvironments. Extensive experimental results demonstrate the effectiveness of\nFedAcross+ in achieving competitive adaptation on low-end client devices with\nlimited target samples, successfully addressing the challenge of domain shift.\nMoreover, our framework accommodates sporadic model updates within\nresource-constrained environments, ensuring practical and seamless deployment.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u8054\u90a6\u5b66\u4e60\u6846\u67b6FedAcross+\uff0c\u89e3\u51b3\u5de5\u4e1a\u73af\u5883\u4e2d\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u4f4e\u8d44\u6e90\u8bbe\u5907\u4e0a\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u6570\u636e\u6807\u6ce8\u9700\u4eba\u5de5\u53c2\u4e0e\u3001\u534f\u53d8\u91cf\u504f\u79fb\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u6a21\u578b\u66f4\u65b0\u4e0d\u5b9e\u9645\u7b49\u95ee\u9898\u3002", "method": "\u6269\u5c55\u9002\u7528\u4e8e\u5de5\u4e1a\u73af\u5883\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u51bb\u7ed3\u9aa8\u5e72\u7f51\u7edc\u548c\u5206\u7c7b\u5668\uff0c\u7528\u57df\u81ea\u9002\u5e94\u7ebf\u6027\u5c42\u5904\u7406\u76ee\u6807\u57df\u9002\u5e94\uff0c\u8fd8\u5c06\u5176\u6269\u5c55\u5230\u5904\u7406\u6d41\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFedAcross+\u80fd\u5728\u4f4e\u8d44\u6e90\u5ba2\u6237\u7aef\u8bbe\u5907\u4e0a\u5229\u7528\u6709\u9650\u76ee\u6807\u6837\u672c\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u7684\u9002\u5e94\uff0c\u89e3\u51b3\u57df\u504f\u79fb\u95ee\u9898\uff0c\u4e14\u80fd\u9002\u5e94\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u96f6\u661f\u6a21\u578b\u66f4\u65b0\u3002", "conclusion": "FedAcross+\u6846\u67b6\u6709\u6548\u4e14\u5b9e\u7528\uff0c\u53ef\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u65e0\u7f1d\u90e8\u7f72\u3002"}}
{"id": "2507.09256", "pdf": "https://arxiv.org/pdf/2507.09256", "abs": "https://arxiv.org/abs/2507.09256", "authors": ["Junyu Chen", "Yihua Gao", "Mingyuan Ge", "Mingyong Li"], "title": "Ambiguity-Aware and High-Order Relation Learning for Multi-Grained Image-Text Matching", "categories": ["cs.CV", "cs.IR", "cs.MM"], "comment": "Accepted by the Knowledge-Based Systems(KBS), 2025", "summary": "Image-text matching is crucial for bridging the semantic gap between computer\nvision and natural language processing. However, existing methods still face\nchallenges in handling high-order associations and semantic ambiguities among\nsimilar instances. These ambiguities arise from subtle differences between soft\npositive samples (semantically similar but incorrectly labeled) and soft\nnegative samples (locally matched but globally inconsistent), creating matching\nuncertainties. Furthermore, current methods fail to fully utilize the\nneighborhood relationships among semantically similar instances within training\nbatches, limiting the model's ability to learn high-order shared knowledge.\nThis paper proposes the Ambiguity-Aware and High-order Relation learning\nframework (AAHR) to address these issues. AAHR constructs a unified\nrepresentation space through dynamic clustering prototype contrastive learning,\neffectively mitigating the soft positive sample problem. The framework\nintroduces global and local feature extraction mechanisms and an adaptive\naggregation network, significantly enhancing full-grained semantic\nunderstanding capabilities. Additionally, AAHR employs intra-modal and\ninter-modal correlation matrices to investigate neighborhood relationships\namong sample instances thoroughly. It incorporates GNN to enhance semantic\ninteractions between instances. Furthermore, AAHR integrates momentum\ncontrastive learning to expand the negative sample set. These combined\nstrategies significantly improve the model's ability to discriminate between\nfeatures. Experimental results demonstrate that AAHR outperforms existing\nstate-of-the-art methods on Flickr30K, MSCOCO, and ECCV Caption datasets,\nconsiderably improving the accuracy and efficiency of image-text matching. The\ncode and model checkpoints for this research are available at\nhttps://github.com/Image-Text-Matching/AAHR .", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAAHR\u6846\u67b6\u89e3\u51b3\u56fe\u50cf\u6587\u672c\u5339\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u79cd\u7b56\u7565\u63d0\u5347\u6a21\u578b\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56fe\u50cf\u6587\u672c\u5339\u914d\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u9636\u5173\u8054\u548c\u8bed\u4e49\u6b67\u4e49\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u672a\u5145\u5206\u5229\u7528\u8bad\u7ec3\u6279\u6b21\u4e2d\u8bed\u4e49\u76f8\u4f3c\u5b9e\u4f8b\u7684\u90bb\u57df\u5173\u7cfb\u3002", "method": "\u63d0\u51faAAHR\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u805a\u7c7b\u539f\u578b\u5bf9\u6bd4\u5b66\u4e60\u6784\u5efa\u7edf\u4e00\u8868\u793a\u7a7a\u95f4\uff0c\u5f15\u5165\u7279\u5f81\u63d0\u53d6\u548c\u805a\u5408\u7f51\u7edc\uff0c\u5229\u7528\u76f8\u5173\u77e9\u9635\u548cGNN\u589e\u5f3a\u5b9e\u4f8b\u8bed\u4e49\u4ea4\u4e92\uff0c\u96c6\u6210\u52a8\u91cf\u5bf9\u6bd4\u5b66\u4e60\u6269\u5c55\u8d1f\u6837\u672c\u96c6\u3002", "result": "AAHR\u5728Flickr30K\u3001MSCOCO\u548cECCV Caption\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u56fe\u50cf\u6587\u672c\u5339\u914d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "AAHR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u56fe\u50cf\u6587\u672c\u5339\u914d\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.09742", "pdf": "https://arxiv.org/pdf/2507.09742", "abs": "https://arxiv.org/abs/2507.09742", "authors": ["Xiaofeng Xiao", "Bo Shen", "Xubo Yue"], "title": "Causality-informed Anomaly Detection in Partially Observable Sensor Networks: Moving beyond Correlations", "categories": ["cs.AI"], "comment": null, "summary": "Nowadays, as AI-driven manufacturing becomes increasingly popular, the volume\nof data streams requiring real-time monitoring continues to grow. However, due\nto limited resources, it is impractical to place sensors at every location to\ndetect unexpected shifts. Therefore, it is necessary to develop an optimal\nsensor placement strategy that enables partial observability of the system\nwhile detecting anomalies as quickly as possible. Numerous approaches have been\nproposed to address this challenge; however, most existing methods consider\nonly variable correlations and neglect a crucial factor: Causality. Moreover,\nalthough a few techniques incorporate causal analysis, they rely on\ninterventions-artificially creating anomalies-to identify causal effects, which\nis impractical and might lead to catastrophic losses. In this paper, we\nintroduce a causality-informed deep Q-network (Causal DQ) approach for\npartially observable sensor placement in anomaly detection. By integrating\ncausal information at each stage of Q-network training, our method achieves\nfaster convergence and tighter theoretical error bounds. Furthermore, the\ntrained causal-informed Q-network significantly reduces the detection time for\nanomalies under various settings, demonstrating its effectiveness for sensor\nplacement in large-scale, real-world data streams. Beyond the current\nimplementation, our technique's fundamental insights can be applied to various\nreinforcement learning problems, opening up new possibilities for real-world\ncausality-informed machine learning methods in engineering applications.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u4fe1\u606f\u6df1\u5ea6Q\u7f51\u7edc\uff08Causal DQ\uff09\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u4f20\u611f\u5668\u653e\u7f6e\uff0c\u6548\u679c\u826f\u597d\u4e14\u6709\u62d3\u5c55\u6f5c\u529b\u3002", "motivation": "AI\u9a71\u52a8\u5236\u9020\u4e2d\u6570\u636e\u6d41\u76d1\u63a7\u6570\u636e\u91cf\u5927\uff0c\u8d44\u6e90\u6709\u9650\uff0c\u9700\u5f00\u53d1\u6700\u4f18\u4f20\u611f\u5668\u653e\u7f6e\u7b56\u7565\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5ffd\u89c6\u56e0\u679c\u5173\u7cfb\u7b49\u95ee\u9898\u3002", "method": "\u5728Q\u7f51\u7edc\u8bad\u7ec3\u5404\u9636\u6bb5\u96c6\u6210\u56e0\u679c\u4fe1\u606f\u7684\u56e0\u679c\u4fe1\u606f\u6df1\u5ea6Q\u7f51\u7edc\uff08Causal DQ\uff09\u65b9\u6cd5\u3002", "result": "\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\u548c\u66f4\u4e25\u683c\u7406\u8bba\u8bef\u5dee\u754c\uff0c\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u663e\u8457\u51cf\u5c11\u5f02\u5e38\u68c0\u6d4b\u65f6\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5bf9\u5927\u89c4\u6a21\u5b9e\u65f6\u6570\u636e\u6d41\u4f20\u611f\u5668\u653e\u7f6e\u6709\u6548\uff0c\u5176\u57fa\u672c\u89c1\u89e3\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u5de5\u7a0b\u5e94\u7528\u4e2d\u56e0\u679c\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5e26\u6765\u65b0\u53ef\u80fd\u3002"}}
{"id": "2507.09596", "pdf": "https://arxiv.org/pdf/2507.09596", "abs": "https://arxiv.org/abs/2507.09596", "authors": ["Aydin Homay"], "title": "The Mythical Good Software", "categories": ["cs.SE"], "comment": null, "summary": "Good software has high cohesion and low coupling is clumsy, obscure, and in\nsome certain cases could be actually a harmful state of being. It is clumsy\nbecause there is no perfect correlation between higher cohesiveness and optimum\ndesign, and it is obscure because it conveys the message that coupling and\ncohesion are two distinct design principles, while there are in principle the\nsame design approaches, and only the time and space differ between them, and it\ncould also be a harmful state of being because we should not always aim for\nhigher cohesiveness without considering its cost.\n  In the course of this study, we aim to elucidate for the readers the meaning\nand underlying philosophy of the aforementioned paragraph.", "AI": {"tldr": "\u8ba4\u4e3a\u9ad8\u5185\u805a\u4f4e\u8026\u5408\u7684\u8f6f\u4ef6\u8bbe\u8ba1\u7406\u5ff5\u5b58\u5728\u95ee\u9898\uff0c\u5e76\u5c06\u9610\u660e\u76f8\u5173\u542b\u4e49\u548c\u54f2\u5b66\u3002", "motivation": "\u6307\u51fa\u9ad8\u5185\u805a\u4f4e\u8026\u5408\u7684\u8f6f\u4ef6\u8bbe\u8ba1\u7406\u5ff5\u5b58\u5728\u7b28\u62d9\u3001\u6a21\u7cca\u548c\u6709\u5bb3\u7684\u60c5\u51b5\uff0c\u8981\u4e3a\u8bfb\u8005\u9610\u660e\u76f8\u5173\u5185\u5bb9\u542b\u4e49\u548c\u54f2\u5b66\u3002", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2507.08871", "pdf": "https://arxiv.org/pdf/2507.08871", "abs": "https://arxiv.org/abs/2507.08871", "authors": ["Xishun Liao", "Haoxuan Ma", "Yifan Liu", "Yuxiang Wei", "Brian Yueshuai He", "Chris Stanford", "Jiaqi Ma"], "title": "Next-Generation Travel Demand Modeling with a Generative Framework for Household Activity Coordination", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 7 figures", "summary": "Travel demand models are critical tools for planning, policy, and mobility\nsystem design. Traditional activity-based models (ABMs), although grounded in\nbehavioral theories, often rely on simplified rules and assumptions, and are\ncostly to develop and difficult to adapt across different regions. This paper\npresents a learning-based travel demand modeling framework that synthesizes\nhousehold-coordinated daily activity patterns based on a household's\nsocio-demographic profiles. The whole framework integrates population\nsynthesis, coordinated activity generation, location assignment, and\nlarge-scale microscopic traffic simulation into a unified system. It is fully\ngenerative, data-driven, scalable, and transferable to other regions. A\nfull-pipeline implementation is conducted in Los Angeles with a 10 million\npopulation. Comprehensive validation shows that the model closely replicates\nreal-world mobility patterns and matches the performance of legacy ABMs with\nsignificantly reduced modeling cost and greater scalability. With respect to\nthe SCAG ABM benchmark, the origin-destination matrix achieves a cosine\nsimilarity of 0.97, and the daily vehicle miles traveled (VMT) in the network\nyields a 0.006 Jensen-Shannon Divergence (JSD) and a 9.8% mean absolute\npercentage error (MAPE). When compared to real-world observations from Caltrans\nPeMS, the evaluation on corridor-level traffic speed and volume reaches a 0.001\nJSD and a 6.11% MAPE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u51fa\u884c\u9700\u6c42\u5efa\u6a21\u6846\u67b6\uff0c\u6574\u5408\u591a\u6a21\u5757\uff0c\u5728\u6d1b\u6749\u77f6\u5b9e\u65bd\u9a8c\u8bc1\uff0c\u6a21\u578b\u80fd\u590d\u73b0\u51fa\u884c\u6a21\u5f0f\uff0c\u6210\u672c\u4f4e\u4e14\u53ef\u6269\u5c55\u6027\u5f3a\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6d3b\u52a8\u7684\u51fa\u884c\u9700\u6c42\u6a21\u578b\u4f9d\u8d56\u7b80\u5316\u89c4\u5219\u5047\u8bbe\uff0c\u5f00\u53d1\u6210\u672c\u9ad8\u4e14\u96be\u8de8\u533a\u57df\u5e94\u7528\uff0c\u9700\u65b0\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u51fa\u884c\u9700\u6c42\u5efa\u6a21\u6846\u67b6\uff0c\u6574\u5408\u4eba\u53e3\u5408\u6210\u3001\u6d3b\u52a8\u751f\u6210\u3001\u4f4d\u7f6e\u5206\u914d\u548c\u5fae\u89c2\u4ea4\u901a\u4eff\u771f\u4e3a\u7edf\u4e00\u7cfb\u7edf\u3002", "result": "\u5728\u6d1b\u6749\u77f6\u5b9e\u65bd\u5168\u6d41\u7a0b\uff0c\u6a21\u578b\u590d\u73b0\u771f\u5b9e\u51fa\u884c\u6a21\u5f0f\uff0c\u4e0e\u4f20\u7edf\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u6210\u672c\u964d\u4f4e\u3001\u53ef\u6269\u5c55\u6027\u589e\u5f3a\uff0c\u591a\u9879\u6307\u6807\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u751f\u6210\u5f0f\u3001\u6570\u636e\u9a71\u52a8\u7684\uff0c\u53ef\u6269\u5c55\u4e14\u80fd\u8de8\u533a\u57df\u5e94\u7528\uff0c\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.10325", "pdf": "https://arxiv.org/pdf/2507.10325", "abs": "https://arxiv.org/abs/2507.10325", "authors": ["Herlock", "Rahimi", "Dionysis Kalogerias"], "title": "Convergence of Agnostic Federated Averaging", "categories": ["cs.LG", "cs.DC", "eess.SP"], "comment": "5 pages, 2 figurres, CAMSAP conference", "summary": "Federated learning (FL) enables decentralized model training without\ncentralizing raw data. However, practical FL deployments often face a key\nrealistic challenge: Clients participate intermittently in server aggregation\nand with unknown, possibly biased participation probabilities. Most existing\nconvergence results either assume full-device participation, or rely on\nknowledge of (in fact uniform) client availability distributions -- assumptions\nthat rarely hold in practice. In this work, we characterize the optimization\nproblem that consistently adheres to the stochastic dynamics of the well-known\n\\emph{agnostic Federated Averaging (FedAvg)} algorithm under random (and\nvariably-sized) client availability, and rigorously establish its convergence\nfor convex, possibly nonsmooth losses, achieving a standard rate of order\n$\\mathcal{O}(1/\\sqrt{T})$, where $T$ denotes the aggregation horizon. Our\nanalysis provides the first convergence guarantees for agnostic FedAvg under\ngeneral, non-uniform, stochastic client participation, without knowledge of the\nparticipation distribution. We also empirically demonstrate that agnostic\nFedAvg in fact outperforms common (and suboptimal) weighted aggregation FedAvg\nvariants, even with server-side knowledge of participation weights.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.09751", "pdf": "https://arxiv.org/pdf/2507.09751", "abs": "https://arxiv.org/abs/2507.09751", "authors": ["Bradley P. Allen", "Prateek Chhikara", "Thomas Macaulay Ferguson", "Filip Ilievski", "Paul Groth"], "title": "Sound and Complete Neuro-symbolic Reasoning with LLM-Grounded Interpretations", "categories": ["cs.AI", "cs.CL", "cs.LO"], "comment": "29 pages, 9 tables, 3 figures. Accepted to the 19th Conference on\n  Neurosymbolic Learning and Reasoning (NeSy 2025)", "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but they exhibit problems with\nlogical consistency in the output they generate. How can we harness LLMs'\nbroad-coverage parametric knowledge in formal reasoning despite their\ninconsistency? We present a method for directly integrating an LLM into the\ninterpretation function of the formal semantics for a paraconsistent logic. We\nprovide experimental evidence for the feasibility of the method by evaluating\nthe function using datasets created from several short-form factuality\nbenchmarks. Unlike prior work, our method offers a theoretical framework for\nneuro-symbolic reasoning that leverages an LLM's knowledge while preserving the\nunderlying logic's soundness and completeness properties.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u6b21\u534f\u8c03\u903b\u8f91\u5f62\u5f0f\u8bed\u4e49\u89e3\u91ca\u51fd\u6570\u7684\u65b9\u6cd5\uff0c\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f93\u51fa\u4e2d\u5b58\u5728\u903b\u8f91\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u9700\u5229\u7528\u5176\u77e5\u8bc6\u8fdb\u884c\u5f62\u5f0f\u63a8\u7406\u3002", "method": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u96c6\u6210\u5230\u6b21\u534f\u8c03\u903b\u8f91\u5f62\u5f0f\u8bed\u4e49\u7684\u89e3\u91ca\u51fd\u6570\u4e2d\u3002", "result": "\u901a\u8fc7\u77ed\u5f62\u5f0f\u4e8b\u5b9e\u6027\u57fa\u51c6\u6d4b\u8bd5\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u8bc1\u660e\u65b9\u6cd5\u53ef\u884c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\uff0c\u53ef\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u5e76\u4fdd\u7559\u5e95\u5c42\u903b\u8f91\u7684\u5408\u7406\u6027\u548c\u5b8c\u5907\u6027\u3002"}}
{"id": "2507.09599", "pdf": "https://arxiv.org/pdf/2507.09599", "abs": "https://arxiv.org/abs/2507.09599", "authors": ["Aydin Homay"], "title": "Complexity and Coupling: A Functional Domain Approach", "categories": ["cs.SE"], "comment": null, "summary": "This paper provides a precise and scientific definition of complexity and\ncoupling, grounded in the functional domain, particularly within industrial\ncontrol and automation systems (iCAS). We highlight the widespread ambiguity in\ndefining complexity and coupling, emphasizing that many existing definitions\nrooted in physical attributes lead to confusion and inconsistencies.\nFurthermore, we re-exhibit why coupled design inherently increases complexity\nand how potentially this complexity could be reduced. Drawing on examples from\nvarious disciplines, such as software engineering, industrial automation, and\nmechanical design, we demonstrate that complexity does not necessarily\ncorrelate with system size or the number of components, and coupling, unlike\ncommon belief in software engineering, actually does not occur in the physical\ndomain but in the functional domain. We conclude that effective design\nnecessitates addressing coupling and complexity within the functional domain.", "AI": {"tldr": "\u8bba\u6587\u57fa\u4e8e\u529f\u80fd\u57df\u4e3a\u5de5\u4e1a\u63a7\u5236\u548c\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u590d\u6742\u6027\u4e0e\u8026\u5408\u7ed9\u51fa\u7cbe\u51c6\u79d1\u5b66\u5b9a\u4e49\uff0c\u5206\u6790\u8026\u5408\u4e0e\u590d\u6742\u6027\u5173\u7cfb\u5e76\u5f97\u51fa\u8bbe\u8ba1\u9700\u5728\u529f\u80fd\u57df\u5904\u7406\u4e8c\u8005\u7684\u7ed3\u8bba\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7269\u7406\u5c5e\u6027\u7684\u590d\u6742\u6027\u548c\u8026\u5408\u5b9a\u4e49\u5b58\u5728\u6a21\u7cca\u6027\u3001\u6613\u5bfc\u81f4\u6df7\u4e71\u548c\u4e0d\u4e00\u81f4\uff0c\u9700\u7cbe\u51c6\u79d1\u5b66\u5b9a\u4e49\u3002", "method": "\u7ed3\u5408\u8f6f\u4ef6\u5de5\u7a0b\u3001\u5de5\u4e1a\u81ea\u52a8\u5316\u548c\u673a\u68b0\u8bbe\u8ba1\u7b49\u591a\u5b66\u79d1\u4f8b\u5b50\u8fdb\u884c\u5206\u6790\u3002", "result": "\u590d\u6742\u6027\u4e0d\u4e00\u5b9a\u4e0e\u7cfb\u7edf\u89c4\u6a21\u6216\u7ec4\u4ef6\u6570\u91cf\u76f8\u5173\uff0c\u8026\u5408\u53d1\u751f\u5728\u529f\u80fd\u57df\u800c\u975e\u7269\u7406\u57df\u3002", "conclusion": "\u6709\u6548\u8bbe\u8ba1\u9700\u5728\u529f\u80fd\u57df\u5904\u7406\u8026\u5408\u548c\u590d\u6742\u6027\u3002"}}
{"id": "2507.08873", "pdf": "https://arxiv.org/pdf/2507.08873", "abs": "https://arxiv.org/abs/2507.08873", "authors": ["Shaoran Yang", "Dongyu Wei", "Hanzhi Yu", "Zhaohui Yang", "Yuchen Liu", "Mingzhe Chen"], "title": "Contrastive Language-Image Pre-Training Model based Semantic Communication Performance Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to IEEE GLOBECOM 2025", "summary": "In this paper, a novel contrastive language-image pre-training (CLIP) model\nbased semantic communication framework is designed. Compared to standard neural\nnetwork (e.g.,convolutional neural network) based semantic encoders and\ndecoders that require joint training over a common dataset, our CLIP model\nbased method does not require any training procedures thus enabling a\ntransmitter to extract data meanings of the original data without neural\nnetwork model training, and the receiver to train a neural network for\nfollow-up task implementation without the communications with the transmitter.\nNext, we investigate the deployment of the CLIP model based semantic framework\nover a noisy wireless network. Since the semantic information generated by the\nCLIP model is susceptible to wireless noise and the spectrum used for semantic\ninformation transmission is limited, it is necessary to jointly optimize CLIP\nmodel architecture and spectrum resource block (RB) allocation to maximize\nsemantic communication performance while considering wireless noise, the delay\nand energy used for semantic communication. To achieve this goal, we use a\nproximal policy optimization (PPO) based reinforcement learning (RL) algorithm\nto learn how wireless noise affect the semantic communication performance thus\nfinding optimal CLIP model and RB for each user. Simulation results show that\nour proposed method improves the convergence rate by up to 40%, and the\naccumulated reward by 4x compared to soft actor-critic.", "AI": {"tldr": "\u8bbe\u8ba1\u57fa\u4e8eCLIP\u6a21\u578b\u7684\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u7528PPO\u7b97\u6cd5\u4f18\u5316\uff0c\u4eff\u771f\u663e\u793a\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u8bed\u4e49\u7f16\u89e3\u7801\u5668\u9700\u8054\u5408\u8bad\u7ec3\uff0c\u4e14\u8bed\u4e49\u4fe1\u606f\u53d7\u65e0\u7ebf\u566a\u58f0\u5f71\u54cd\u3001\u9891\u8c31\u6709\u9650\uff0c\u9700\u63d0\u5347\u8bed\u4e49\u901a\u4fe1\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eCLIP\u6a21\u578b\u7684\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u7528PPO\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4f18\u5316CLIP\u6a21\u578b\u67b6\u6784\u548c\u9891\u8c31\u8d44\u6e90\u5757\u5206\u914d\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u8f6f\u6f14\u5458\u8bc4\u8bba\u5bb6\u7b97\u6cd5\uff0c\u6536\u655b\u7387\u6700\u9ad8\u63d0\u534740%\uff0c\u7d2f\u79ef\u5956\u52b1\u63d0\u53474\u500d\u3002", "conclusion": "\u57fa\u4e8eCLIP\u6a21\u578b\u7684\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\u7ed3\u5408PPO\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u8bed\u4e49\u901a\u4fe1\u6027\u80fd\u3002"}}
{"id": "2507.08867", "pdf": "https://arxiv.org/pdf/2507.08867", "abs": "https://arxiv.org/abs/2507.08867", "authors": ["Malte Algren", "Tobias Golling", "Francesco Armando Di Bello", "Christopher Pollard"], "title": "Mind the Gap: Navigating Inference with Optimal Transport Maps", "categories": ["physics.data-an", "cs.LG", "hep-ex", "stat.ML"], "comment": "23 pages, 13 figures", "summary": "Machine learning (ML) techniques have recently enabled enormous gains in\nsensitivity across the sciences. In particle physics, much of this progress has\nrelied on excellent simulations of a wide range of physical processes. However,\ndue to the sophistication of modern machine learning (ML) algorithms and their\nreliance on high-quality training samples, discrepancies between simulation and\nexperimental data can significantly limit the effectiveness of ML techniques.\nIn this work, we present a solution to this ``mis-specification'' problem: a\ncalibration approach based on optimal transport, which we apply to\nhigh-dimensional simulations for the first time. We demonstrate the performance\nof our approach through jet tagging, using a CMS-inspired dataset. A\n128-dimensional internal jet representation from a powerful general-purpose\nclassifier is studied; after calibrating this internal ``latent''\nrepresentation, we find that a wide variety of quantities derived from it for\ndownstream tasks are also properly calibrated: using this calibrated\nhigh-dimensional representation, powerful new applications of jet flavor\ninformation can be utilized in LHC analyses. This is a key step toward allowing\nproperly-calibrated ``foundation models'' in particle physics. More broadly,\nthis calibration framework has broad applications for correcting\nhigh-dimensional simulations across the sciences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u6821\u51c6\u65b9\u6cd5\u89e3\u51b3\u7c92\u5b50\u7269\u7406\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u62df\u4e0e\u5b9e\u9a8c\u6570\u636e\u4e0d\u7b26\u95ee\u9898\uff0c\u4ee5\u55b7\u6ce8\u6807\u8bb0\u9a8c\u8bc1\u6548\u679c\uff0c\u5bf9\u591a\u9886\u57df\u9ad8\u7ef4\u6a21\u62df\u6821\u51c6\u6709\u5e7f\u6cdb\u5e94\u7528\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u590d\u6742\u4e14\u4f9d\u8d56\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6837\u672c\uff0c\u6a21\u62df\u4e0e\u5b9e\u9a8c\u6570\u636e\u7684\u5dee\u5f02\u4f1a\u9650\u5236\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u7c92\u5b50\u7269\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u6821\u51c6\u65b9\u6cd5\uff0c\u5e76\u9996\u6b21\u5e94\u7528\u4e8e\u9ad8\u7ef4\u6a21\u62df\u3002", "result": "\u901a\u8fc7CMS\u542f\u53d1\u7684\u6570\u636e\u96c6\u8fdb\u884c\u55b7\u6ce8\u6807\u8bb0\uff0c\u6821\u51c6\u9ad8\u7ef4\u5185\u90e8\u201c\u6f5c\u5728\u201d\u8868\u793a\u540e\uff0c\u4e0b\u6e38\u4efb\u52a1\u7684\u76f8\u5173\u91cf\u4e5f\u5f97\u5230\u6b63\u786e\u6821\u51c6\uff0c\u53ef\u7528\u4e8eLHC\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u7c92\u5b50\u7269\u7406\u4e2d\u5b9e\u73b0\u6821\u51c6\u201c\u57fa\u7840\u6a21\u578b\u201d\u7684\u5173\u952e\u4e00\u6b65\uff0c\u6821\u51c6\u6846\u67b6\u5bf9\u591a\u9886\u57df\u9ad8\u7ef4\u6a21\u62df\u6821\u6b63\u6709\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2507.09439", "pdf": "https://arxiv.org/pdf/2507.09439", "abs": "https://arxiv.org/abs/2507.09439", "authors": ["Meriem Zerkouk", "Miloud Mihoubi", "Belkacem Chikhaoui"], "title": "Dynamic Sparse Causal-Attention Temporal Networks for Interpretable Causality Discovery in Multivariate Time Series", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Understanding causal relationships in multivariate time series (MTS) is\nessential for effective decision-making in fields such as finance and\nmarketing, where complex dependencies and lagged effects challenge conventional\nanalytical approaches. We introduce Dynamic Sparse Causal-Attention Temporal\nNetworks for Interpretable Causality Discovery in MTS (DyCAST-Net), a novel\narchitecture designed to enhance causal discovery by integrating dilated\ntemporal convolutions and dynamic sparse attention mechanisms. DyCAST-Net\neffectively captures multiscale temporal dependencies through dilated\nconvolutions while leveraging an adaptive thresholding strategy in its\nattention mechanism to eliminate spurious connections, ensuring both accuracy\nand interpretability. A statistical shuffle test validation further strengthens\nrobustness by filtering false positives and improving causal inference\nreliability. Extensive evaluations on financial and marketing datasets\ndemonstrate that DyCAST-Net consistently outperforms existing models such as\nTCDF, GCFormer, and CausalFormer. The model provides a more precise estimation\nof causal delays and significantly reduces false discoveries, particularly in\nnoisy environments. Moreover, attention heatmaps offer interpretable insights,\nuncovering hidden causal patterns such as the mediated effects of advertising\non consumer behavior and the influence of macroeconomic indicators on financial\nmarkets. Case studies illustrate DyCAST-Net's ability to detect latent\nmediators and lagged causal factors, making it particularly effective in\nhigh-dimensional, dynamic settings. The model's architecture enhanced by\nRMSNorm stabilization and causal masking ensures scalability and adaptability\nacross diverse application domains", "AI": {"tldr": "\u63d0\u51faDyCAST - Net\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\uff0c\u5728\u91d1\u878d\u548c\u8425\u9500\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u80fd\u51cf\u5c11\u9519\u8bef\u53d1\u73b0\u3001\u63d0\u4f9b\u53ef\u89e3\u91ca\u89c1\u89e3\u3002", "motivation": "\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u5173\u7cfb\u7406\u89e3\u5bf9\u91d1\u878d\u548c\u8425\u9500\u7b49\u9886\u57df\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u9762\u4e34\u590d\u6742\u4f9d\u8d56\u548c\u6ede\u540e\u6548\u5e94\u6311\u6218\u3002", "method": "\u5f15\u5165DyCAST - Net\uff0c\u7ed3\u5408\u6269\u5f20\u65f6\u95f4\u5377\u79ef\u548c\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u9608\u503c\u7b56\u7565\u6d88\u9664\u865a\u5047\u8fde\u63a5\uff0c\u7528\u7edf\u8ba1\u6d17\u724c\u6d4b\u8bd5\u9a8c\u8bc1\u8fc7\u6ee4\u8bef\u62a5\u3002", "result": "\u5728\u91d1\u878d\u548c\u8425\u9500\u6570\u636e\u96c6\u4e0a\uff0cDyCAST - Net\u4f18\u4e8eTCDF\u3001GCFormer\u548cCausalFormer\u7b49\u73b0\u6709\u6a21\u578b\uff0c\u80fd\u66f4\u7cbe\u786e\u4f30\u8ba1\u56e0\u679c\u5ef6\u8fdf\u3001\u51cf\u5c11\u9519\u8bef\u53d1\u73b0\uff0c\u6ce8\u610f\u529b\u70ed\u56fe\u53ef\u63ed\u793a\u9690\u85cf\u56e0\u679c\u6a21\u5f0f\u3002", "conclusion": "DyCAST - Net\u67b6\u6784\u7ecfRMSNorm\u7a33\u5b9a\u5316\u548c\u56e0\u679c\u63a9\u7801\u589e\u5f3a\uff0c\u5728\u9ad8\u7ef4\u52a8\u6001\u73af\u5883\u4e2d\u6709\u6548\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.09801", "pdf": "https://arxiv.org/pdf/2507.09801", "abs": "https://arxiv.org/abs/2507.09801", "authors": ["Peter Barnett", "Aaron Scher", "David Abecassis"], "title": "Technical Requirements for Halting Dangerous AI Activities", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "The rapid development of AI systems poses unprecedented risks, including loss\nof control, misuse, geopolitical instability, and concentration of power. To\nnavigate these risks and avoid worst-case outcomes, governments may proactively\nestablish the capability for a coordinated halt on dangerous AI development and\ndeployment. In this paper, we outline key technical interventions that could\nallow for a coordinated halt on dangerous AI activities. We discuss how these\ninterventions may contribute to restricting various dangerous AI activities,\nand show how these interventions can form the technical foundation for\npotential AI governance plans.", "AI": {"tldr": "AI\u53d1\u5c55\u6709\u98ce\u9669\uff0c\u672c\u6587\u63d0\u51fa\u53ef\u534f\u8c03\u53eb\u505c\u5371\u9669AI\u6d3b\u52a8\u7684\u6280\u672f\u5e72\u9884\u63aa\u65bd\u53ca\u4f5c\u7528\u3002", "motivation": "\u5e94\u5bf9AI\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u7684\u5982\u5931\u63a7\u3001\u6ee5\u7528\u7b49\u98ce\u9669\uff0c\u907f\u514d\u6700\u574f\u7ed3\u679c\u3002", "method": "\u63d0\u51fa\u53ef\u7528\u4e8e\u534f\u8c03\u53eb\u505c\u5371\u9669AI\u6d3b\u52a8\u7684\u5173\u952e\u6280\u672f\u5e72\u9884\u63aa\u65bd\u3002", "result": "\u8ba8\u8bba\u5e72\u9884\u63aa\u65bd\u5bf9\u9650\u5236\u5371\u9669AI\u6d3b\u52a8\u7684\u4f5c\u7528\uff0c\u8868\u660e\u5176\u80fd\u4e3aAI\u6cbb\u7406\u8ba1\u5212\u5960\u5b9a\u6280\u672f\u57fa\u7840\u3002", "conclusion": "\u8fd9\u4e9b\u6280\u672f\u5e72\u9884\u63aa\u65bd\u53ef\u4f5c\u4e3a\u6f5c\u5728AI\u6cbb\u7406\u8ba1\u5212\u7684\u6280\u672f\u57fa\u7840\u4ee5\u5e94\u5bf9AI\u53d1\u5c55\u98ce\u9669\u3002"}}
{"id": "2507.09637", "pdf": "https://arxiv.org/pdf/2507.09637", "abs": "https://arxiv.org/abs/2507.09637", "authors": ["Lo Gullstrand Heander", "Emma S\u00f6derberg", "Christofer Rydenf\u00e4lt"], "title": "Code Review as Decision-Making -- Building a Cognitive Model from the Questions Asked During Code Review", "categories": ["cs.SE", "cs.HC", "D.2.0; D.2.3; K.4.3"], "comment": "39 pages, 14 figures Submitted to Empirical Software Engineering,\n  Springer Nature", "summary": "Code review is a well-established and valued practice in the software\nengineering community contributing to both code quality and interpersonal\nbenefits. However, there are challenges in both tools and processes that give\nrise to misalignments and frustrations. Recent research seeks to address this\nby automating code review entirely, but we believe that this risks losing the\nmajority of the interpersonal benefits such as knowledge transfer and shared\nownership.\n  We believe that by better understanding the cognitive processes involved in\ncode review, it would be possible to improve tool support, with out without AI,\nand make code review both more efficient, more enjoyable, while increasing or\nmaintaining all of its benefits. In this paper, we conduct an ethnographic\nthink-aloud study involving 10 participants and 34 code reviews. We build a\ncognitive model of code review bottom up through thematic, statistical,\ntemporal, and sequential analysis of the transcribed material. Through the\ndata, the similarities between the cognitive process in code review and\ndecision-making processes, especially recognition-primed decision-making,\nbecome apparent.\n  The result is the Code Review as Decision-Making (CRDM) model that shows how\nthe developers move through two phases during the code review; first an\norientation phase to establish context and rationale and then an analytical\nphase to understand, assess, and plan the rest of the review. Throughout the\nprocess several decisions must be taken, on writing comments, finding more\ninformation, voting, running the code locally, verifying continuous integration\nresults, etc.\n  Analysis software and process-coded data publicly available at:\nhttps://doi.org/10.5281/zenodo.15758266", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4eba\u79cd\u5fd7\u601d\u8003\u51fa\u58f0\u7814\u7a76\u6784\u5efa\u4ee3\u7801\u5ba1\u67e5\u8ba4\u77e5\u6a21\u578b\uff0c\u63d0\u51faCRDM\u6a21\u578b\u5c55\u793a\u5f00\u53d1\u8005\u5ba1\u67e5\u9636\u6bb5\u53ca\u51b3\u7b56\u60c5\u51b5\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u5ba1\u67e5\u5728\u5de5\u5177\u548c\u6d41\u7a0b\u4e0a\u5b58\u5728\u6311\u6218\uff0c\u81ea\u52a8\u5316\u5ba1\u67e5\u4f1a\u4e27\u5931\u4eba\u9645\u76ca\u5904\uff0c\u9700\u901a\u8fc7\u7406\u89e3\u8ba4\u77e5\u8fc7\u7a0b\u6539\u8fdb\u5de5\u5177\u652f\u6301\u3002", "method": "\u8fdb\u884c\u6d89\u53ca10\u540d\u53c2\u4e0e\u8005\u548c34\u6b21\u4ee3\u7801\u5ba1\u67e5\u7684\u4eba\u79cd\u5fd7\u601d\u8003\u51fa\u58f0\u7814\u7a76\uff0c\u5bf9\u8f6c\u5f55\u6750\u6599\u8fdb\u884c\u4e3b\u9898\u3001\u7edf\u8ba1\u3001\u65f6\u95f4\u548c\u987a\u5e8f\u5206\u6790\uff0c\u81ea\u4e0b\u800c\u4e0a\u6784\u5efa\u8ba4\u77e5\u6a21\u578b\u3002", "result": "\u5f97\u5230\u4ee3\u7801\u5ba1\u67e5\u5373\u51b3\u7b56\uff08CRDM\uff09\u6a21\u578b\uff0c\u5c55\u793a\u5f00\u53d1\u8005\u5ba1\u67e5\u5206\u5b9a\u5411\u548c\u5206\u6790\u4e24\u4e2a\u9636\u6bb5\uff0c\u8fc7\u7a0b\u4e2d\u6709\u591a\u9879\u51b3\u7b56\u3002", "conclusion": "\u7406\u89e3\u4ee3\u7801\u5ba1\u67e5\u7684\u8ba4\u77e5\u8fc7\u7a0b\u53ef\u6539\u8fdb\u5de5\u5177\u652f\u6301\uff0c\u8ba9\u4ee3\u7801\u5ba1\u67e5\u66f4\u9ad8\u6548\u3001\u6109\u5feb\u5e76\u4fdd\u7559\u76ca\u5904\u3002"}}
{"id": "2507.08874", "pdf": "https://arxiv.org/pdf/2507.08874", "abs": "https://arxiv.org/abs/2507.08874", "authors": ["Yulin Sun", "Xiaopeng Si", "Runnan He", "Xiao Hu", "Peter Smielewski", "Wenlong Wang", "Xiaoguang Tong", "Wei Yue", "Meijun Pang", "Kuo Zhang", "Xizi Song", "Dong Ming", "Xiuyun Liu"], "title": "An Automated Classifier of Harmful Brain Activities for Clinical Usage Based on a Vision-Inspired Pre-trained Framework", "categories": ["cs.LG"], "comment": null, "summary": "Timely identification of harmful brain activities via electroencephalography\n(EEG) is critical for brain disease diagnosis and treatment, which remains\nlimited application due to inter-rater variability, resource constraints, and\npoor generalizability of existing artificial intelligence (AI) models. In this\nstudy, a convolutional neural network model, VIPEEGNet, was developed and\nvalidated using EEGs recorded from Massachusetts General Hospital/Harvard\nMedical School. The VIPEEGNet was developed and validated using two independent\ndatasets, collected between 2006 and 2020. The development cohort included EEG\nrecordings from 1950 patients, with 106,800 EEG segments annotated by at least\none experts (ranging from 1 to 28). The online testing cohort consisted of EEG\nsegments from a subset of an additional 1,532 patients, each annotated by at\nleast 10 experts. For the development cohort (n=1950), the VIPEEGNet achieved\nhigh accuracy, with an AUROC for binary classification of seizure, LPD, GPD,\nLRDA, GRDA, and \"other\" categories at 0.972 (95% CI, 0.957-0.988), 0.962 (95%\nCI, 0.954-0.970), 0.972 (95% CI, 0.960-0.984), 0.938 (95% CI, 0.917-0.959),\n0.949 (95% CI, 0.941-0.957), and 0.930 (95% CI, 0.926-0.935). For multi\nclassification, the sensitivity of VIPEEGNET for the six categories ranges from\n36.8% to 88.2% and the precision ranges from 55.6% to 80.4%, and performance\nsimilar to human experts. Notably, the external validation showed\nKullback-Leibler Divergence (KLD)of 0.223 and 0.273, ranking top 2 among the\nexisting 2,767 competing algorithms, while we only used 2.8% of the parameters\nof the first-ranked algorithm.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578bVIPEEGNet\u7528\u4e8e\u8111\u7535\u6d3b\u52a8\u8bc6\u522b\uff0c\u9a8c\u8bc1\u5176\u6027\u80fd\u4e14\u53c2\u6570\u5c11\u6392\u540d\u9ad8\u3002", "motivation": "\u73b0\u6709AI\u6a21\u578b\u5728\u8111\u7535\u6d3b\u52a8\u8bc6\u522b\u4e2d\u56e0\u8bc4\u4f30\u8005\u5dee\u5f02\u3001\u8d44\u6e90\u9650\u5236\u548c\u6cdb\u5316\u6027\u5dee\u800c\u5e94\u7528\u53d7\u9650\uff0c\u9700\u66f4\u597d\u7684\u6a21\u578b\u7528\u4e8e\u8111\u75be\u75c5\u8bca\u65ad\u548c\u6cbb\u7597\u3002", "method": "\u4f7f\u7528\u9a6c\u8428\u8bf8\u585e\u7efc\u5408\u533b\u9662/\u54c8\u4f5b\u533b\u5b66\u9662\u8bb0\u5f55\u7684\u8111\u7535\u6570\u636e\uff0c\u7528\u4e24\u4e2a\u72ec\u7acb\u6570\u636e\u96c6\u5f00\u53d1\u548c\u9a8c\u8bc1VIPEEGNet\u6a21\u578b\u3002", "result": "\u5728\u5f00\u53d1\u961f\u5217\u4e2d\uff0cVIPEEGNet\u4e8c\u5206\u7c7b\u7684AUROC\u9ad8\uff0c\u591a\u5206\u7c7b\u7684\u654f\u611f\u6027\u548c\u7cbe\u786e\u6027\u8f83\u597d\uff0c\u5916\u90e8\u9a8c\u8bc1\u7684KLD\u6392\u540d\u9760\u524d\uff0c\u4e14\u4f7f\u7528\u53c2\u6570\u5c11\u3002", "conclusion": "VIPEEGNet\u6a21\u578b\u5728\u8111\u7535\u6d3b\u52a8\u8bc6\u522b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.08896", "pdf": "https://arxiv.org/pdf/2507.08896", "abs": "https://arxiv.org/abs/2507.08896", "authors": ["Byunghee Lee", "Hye Yeon Sin", "Joonsung Kang"], "title": "Predictive Causal Inference via Spatio-Temporal Modeling and Penalized Empirical Likelihood", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "This study introduces an integrated framework for predictive causal inference\ndesigned to overcome limitations inherent in conventional single model\napproaches. Specifically, we combine a Hidden Markov Model (HMM) for spatial\nhealth state estimation with a Multi Task and Multi Graph Convolutional Network\n(MTGCN) for capturing temporal outcome trajectories. The framework\nasymmetrically treats temporal and spatial information regarding them as\nendogenous variables in the outcome regression, and exogenous variables in the\npropensity score model, thereby expanding the standard doubly robust treatment\neffect estimation to jointly enhance bias correction and predictive accuracy.\nTo demonstrate its utility, we focus on clinical domains such as cancer,\ndementia, and Parkinson disease, where treatment effects are challenging to\nobserve directly. Simulation studies are conducted to emulate latent disease\ndynamics and evaluate the model performance under varying conditions. Overall,\nthe proposed framework advances predictive causal inference by structurally\nadapting to spatiotemporal complexities common in biomedical data.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u9884\u6d4b\u56e0\u679c\u63a8\u65ad\u7684\u96c6\u6210\u6846\u67b6\uff0c\u7ed3\u5408HMM\u548cMTGCN\uff0c\u5728\u4e34\u5e8a\u9886\u57df\u9a8c\u8bc1\uff0c\u80fd\u9002\u5e94\u751f\u7269\u533b\u5b66\u6570\u636e\u65f6\u7a7a\u590d\u6742\u6027\u3002", "motivation": "\u514b\u670d\u4f20\u7edf\u5355\u4e00\u6a21\u578b\u65b9\u6cd5\u5728\u9884\u6d4b\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u7ed3\u5408HMM\u8fdb\u884c\u7a7a\u95f4\u5065\u5eb7\u72b6\u6001\u4f30\u8ba1\uff0c\u7528MTGCN\u6355\u6349\u65f6\u95f4\u7ed3\u679c\u8f68\u8ff9\uff0c\u4e0d\u5bf9\u79f0\u5904\u7406\u65f6\u7a7a\u4fe1\u606f\uff0c\u6269\u5c55\u6807\u51c6\u53cc\u91cd\u7a33\u5065\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u7ed3\u6784\u4e0a\u9002\u5e94\u751f\u7269\u533b\u5b66\u6570\u636e\u5e38\u89c1\u7684\u65f6\u7a7a\u590d\u6742\u6027\uff0c\u63a8\u52a8\u4e86\u9884\u6d4b\u56e0\u679c\u63a8\u65ad\u3002"}}
{"id": "2507.09831", "pdf": "https://arxiv.org/pdf/2507.09831", "abs": "https://arxiv.org/abs/2507.09831", "authors": ["Jiatong Li", "Qi Liu", "Mengxiao Zhu"], "title": "Generative Cognitive Diagnosis", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": "Preprint; 15 pages, 12 figures", "summary": "Cognitive diagnosis (CD) models latent cognitive states of human learners by\nanalyzing their response patterns on diagnostic tests, serving as a crucial\nmachine learning technique for educational assessment and evaluation.\nTraditional cognitive diagnosis models typically follow a transductive\nprediction paradigm that optimizes parameters to fit response scores and\nextract learner abilities. These approaches face significant limitations as\nthey cannot perform instant diagnosis for new learners without computationally\nexpensive retraining and produce diagnostic outputs with limited reliability.\nIn this study, we introduces a novel generative diagnosis paradigm that\nfundamentally shifts CD from predictive to generative modeling, enabling\ninductive inference of cognitive states without parameter re-optimization. We\npropose two simple yet effective instantiations of this paradigm: Generative\nItem Response Theory (G-IRT) and Generative Neural Cognitive Diagnosis Model\n(G-NCDM), which achieve excellent performance improvements over traditional\nmethods. The generative approach disentangles cognitive state inference from\nresponse prediction through a well-designed generation process that\nincorporates identifiability and monotonicity conditions. Extensive experiments\non real-world datasets demonstrate the effectiveness of our methodology in\naddressing scalability and reliability challenges, especially $\\times 100$\nspeedup for the diagnosis of new learners. Our framework opens new avenues for\ncognitive diagnosis applications in artificial intelligence, particularly for\nintelligent model evaluation and intelligent education systems. The code is\navailable at https://github.com/CSLiJT/Generative-CD.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u751f\u6210\u5f0f\u8bca\u65ad\u8303\u5f0f\u7528\u4e8e\u8ba4\u77e5\u8bca\u65ad\uff0c\u63d0\u51faG - IRT\u548cG - NCDM\u6a21\u578b\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u6709\u6548\uff0c\u5c24\u5176\u5728\u65b0\u5b66\u4e60\u8005\u8bca\u65ad\u4e0a\u6709100\u500d\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u8ba4\u77e5\u8bca\u65ad\u6a21\u578b\u91c7\u7528\u8f6c\u5bfc\u9884\u6d4b\u8303\u5f0f\uff0c\u5728\u65b0\u5b66\u4e60\u8005\u5373\u65f6\u8bca\u65ad\u548c\u8bca\u65ad\u8f93\u51fa\u53ef\u9760\u6027\u4e0a\u6709\u5c40\u9650\u3002", "method": "\u5f15\u5165\u751f\u6210\u5f0f\u8bca\u65ad\u8303\u5f0f\uff0c\u63d0\u51faG - IRT\u548cG - NCDM\u6a21\u578b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u751f\u6210\u8fc7\u7a0b\u5206\u79bb\u8ba4\u77e5\u72b6\u6001\u63a8\u65ad\u548c\u54cd\u5e94\u9884\u6d4b\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u6709\u6548\uff0c\u65b0\u5b66\u4e60\u8005\u8bca\u65ad\u6709100\u500d\u52a0\u901f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4eba\u5de5\u667a\u80fd\u4e2d\u8ba4\u77e5\u8bca\u65ad\u5e94\u7528\u5f00\u8f9f\u65b0\u9014\u5f84\uff0c\u5c24\u5176\u5728\u667a\u80fd\u6a21\u578b\u8bc4\u4f30\u548c\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u65b9\u9762\u3002"}}
{"id": "2507.09850", "pdf": "https://arxiv.org/pdf/2507.09850", "abs": "https://arxiv.org/abs/2507.09850", "authors": ["Wei Du", "Branislav Kisacanin", "George Armstrong", "Shubham Toshniwal", "Ivan Moshkov", "Alexan Ayrapetyan", "Sadegh Mahdavi", "Dan Zhao", "Shizhe Diao", "Dragan Masulovic", "Marius Stanean", "Advaith Avadhanam", "Max Wang", "Ashmit Dutta", "Shitij Govil", "Sri Yanamandara", "Mihir Tandon", "Sriram Ananthakrishnan", "Vedant Rathi", "David Zhang", "Joonseok Kang", "Leon Luo", "Titu Andreescu", "Boris Ginsburg", "Igor Gitman"], "title": "Is Human-Written Data Enough? The Challenge of Teaching Reasoning to LLMs Without RL or Distillation", "categories": ["cs.AI"], "comment": "Accepted at the Second AI for Math Workshop at the 42nd International\n  Conference on Machine Learning (ICML 2025)", "summary": "Reasoning-capable language models achieve state-of-the-art performance in\ndiverse complex tasks by generating long, explicit Chain-of-Thought (CoT)\ntraces. While recent works show that base models can acquire such reasoning\ntraces via reinforcement learning or distillation from stronger models like\nDeepSeek-R1, previous works demonstrate that even short CoT prompting without\nfine-tuning is able to improve reasoning. We ask whether long CoT can be\ninduced in a base model using only prompting or minimal tuning. Using just 20\nlong CoT examples from the reasoning model \\texttt{QwQ-32B-Preview}, we lightly\nfine-tune the base model \\texttt{Qwen2.5-32B}. The resulting model outperforms\nthe much larger \\texttt{Qwen2.5-Math-72B-Instruct}, showing that a handful of\nhigh-quality examples can unlock strong reasoning capabilities. We further\nexplore using CoT data from non-reasoning models and human annotators, enhanced\nwith prompt engineering, multi-pass editing, and structural guidance. However,\nneither matches the performance of reasoning model traces, suggesting that\ncertain latent qualities of expert CoT are difficult to replicate. We analyze\nkey properties of reasoning data, such as problem difficulty, diversity, and\nanswer length, that influence reasoning distillation. While challenges remain,\nwe are optimistic that carefully curated human-written CoT, even in small\nquantities, can activate reasoning behaviors in base models. We release our\nhuman-authored dataset across refinement stages and invite further\ninvestigation into what makes small-scale reasoning supervision so effective.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4ec5\u901a\u8fc7\u63d0\u793a\u6216\u5c11\u91cf\u5fae\u8c03\u4f7f\u57fa\u7840\u6a21\u578b\u83b7\u5f97\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\uff0c\u7528\u5c11\u91cf\u9ad8\u8d28\u91cf\u793a\u4f8b\u5fae\u8c03\u6a21\u578b\u53ef\u89e3\u9501\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u63a8\u7406\u6a21\u578b\u7684\u601d\u7ef4\u94fe\u6570\u636e\u6548\u679c\u6700\u4f73\uff0c\u8fd8\u5206\u6790\u4e86\u5f71\u54cd\u63a8\u7406\u84b8\u998f\u7684\u5173\u952e\u5c5e\u6027\u3002", "motivation": "\u63a2\u7a76\u80fd\u5426\u4ec5\u901a\u8fc7\u63d0\u793a\u6216\u5c11\u91cf\u5fae\u8c03\u4f7f\u57fa\u7840\u6a21\u578b\u83b7\u5f97\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u63a8\u7406\u6a21\u578bQwQ - 32B - Preview\u768420\u4e2a\u957f\u601d\u7ef4\u94fe\u793a\u4f8b\u5bf9\u57fa\u7840\u6a21\u578bQwen2.5 - 32B\u8fdb\u884c\u8f7b\u5fae\u8c03\uff1b\u63a2\u7d22\u4f7f\u7528\u975e\u63a8\u7406\u6a21\u578b\u548c\u4eba\u7c7b\u6ce8\u91ca\u8005\u7684\u601d\u7ef4\u94fe\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u591a\u8f6e\u7f16\u8f91\u548c\u7ed3\u6784\u6307\u5bfc\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u6027\u80fd\u8d85\u8fc7\u66f4\u5927\u7684Qwen2.5 - Math - 72B - Instruct\uff1b\u975e\u63a8\u7406\u6a21\u578b\u548c\u4eba\u7c7b\u6ce8\u91ca\u8005\u7684\u601d\u7ef4\u94fe\u6570\u636e\u6548\u679c\u4e0d\u5982\u63a8\u7406\u6a21\u578b\uff1b\u5206\u6790\u51fa\u5f71\u54cd\u63a8\u7406\u84b8\u998f\u7684\u5173\u952e\u5c5e\u6027\u3002", "conclusion": "\u7cbe\u5fc3\u7b56\u5212\u7684\u5c11\u91cf\u4eba\u7c7b\u7f16\u5199\u7684\u601d\u7ef4\u94fe\u53ef\u4ee5\u6fc0\u6d3b\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u53d1\u5e03\u4eba\u7c7b\u7f16\u5199\u7684\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u5bf9\u5c0f\u89c4\u6a21\u63a8\u7406\u76d1\u7763\u6709\u6548\u6027\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2507.09665", "pdf": "https://arxiv.org/pdf/2507.09665", "abs": "https://arxiv.org/abs/2507.09665", "authors": ["Saima Afrin", "Bowen Xu", "Antonio Mastropaolo"], "title": "Is Quantization a Deal-breaker? Empirical Insights from Large Code Models", "categories": ["cs.SE"], "comment": null, "summary": "The growing scale of large language models (LLMs) not only demands extensive\ncomputational resources but also raises environmental concerns due to their\nincreasing carbon footprint. Model quantization emerges as an effective\napproach that can reduce the resource demands of LLMs by decreasing parameter\nprecision without substantially affecting performance (e.g., 16 bit to 4 bit).\nWhile recent studies have established quantization as a promising approach for\noptimizing large code models (LCMs), a specialized subset of LLMs tailored for\nautomated software engineering, their findings offer only limited insights into\nits practical implications. Specifically, current investigations focus only on\nthe functional correctness of the code generated by quantized models,\nneglecting how quantization impacts critical aspects of code quality such as\nreliability, maintainability, and security. To bridge this gap, our study\ninvestigates the effects of quantization on the qualitative aspects of\nautomatically generated code. We apply Activation-aware Weight Quantization\n(AWQ) to two widely used code models, CodeLlama and DeepSeekCoder, to generate\nJava and Python code. Using state-of-the-art static analysis tools, we evaluate\nsoftware quality metrics and static features including cyclomatic complexity,\ncognitive complexity, and lines of code. Our findings reveal that quantization\nis a robust technique that not only preserves functional correctness, but also\nretains key qualitative code attributes sought after by developers, such as\nmaintainability and structural simplicity.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5316\u5bf9\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u65b9\u9762\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u91cf\u5316\u662f\u6709\u6548\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4ec5\u5173\u6ce8\u91cf\u5316\u4ee3\u7801\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5ffd\u7565\u4ee3\u7801\u8d28\u91cf\u7684\u5173\u952e\u65b9\u9762\uff0c\u4e3a\u5f25\u8865\u6b64\u5dee\u8ddd\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5bf9CodeLlama\u548cDeepSeekCoder\u5e94\u7528\u6fc0\u6d3b\u611f\u77e5\u6743\u91cd\u91cf\u5316\uff08AWQ\uff09\u751f\u6210Java\u548cPython\u4ee3\u7801\uff0c\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\u8bc4\u4f30\u8f6f\u4ef6\u8d28\u91cf\u6307\u6807\u548c\u9759\u6001\u7279\u5f81\u3002", "result": "\u91cf\u5316\u4e0d\u4ec5\u80fd\u4fdd\u7559\u529f\u80fd\u6b63\u786e\u6027\uff0c\u8fd8\u80fd\u4fdd\u7559\u5f00\u53d1\u8005\u8ffd\u6c42\u7684\u5173\u952e\u4ee3\u7801\u8d28\u91cf\u5c5e\u6027\u3002", "conclusion": "\u91cf\u5316\u662f\u4e00\u79cd\u5f3a\u5927\u6280\u672f\uff0c\u80fd\u5728\u4e0d\u5f71\u54cd\u4ee3\u7801\u5173\u952e\u8d28\u91cf\u5c5e\u6027\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u5927\u4ee3\u7801\u6a21\u578b\u8d44\u6e90\u9700\u6c42\u3002"}}
{"id": "2507.08877", "pdf": "https://arxiv.org/pdf/2507.08877", "abs": "https://arxiv.org/abs/2507.08877", "authors": ["Hanlong Zhang", "Jingsheng Yang", "Hao Li", "Yuhao He", "Franck Gong"], "title": "ODIA: Oriented Distillation for Inline Acceleration of LLM-based Function Calling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Function Calling is a crucial technique that enables Large Language Models\n(LLMs) to interact with external systems through APIs. However, the high\nlatency associated with LLM-based Function Calling significantly impacts user\nexperience. This paper presents a novel approach called Oriented Distillation\nfor Inline Acceleration (ODIA) that leverages online user interaction data to\naccelerate Function Calling. By automatically identifying \"simple queries\" from\nproduction traffic and distilling knowledge from larger models to smaller ones,\nour method reduces response latency by 45% (expected) and 78% (median) while\nmaintaining accuracy. We demonstrate the effectiveness of our approach through\nreal-world deployment in a music application, where the smaller model\nsuccessfully handles 60% of traffic with negligible accuracy loss. Our method\nrequires minimal human intervention and continuously improves through automated\ndata collection and model updating, making it a practical solution for\nproduction environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faODIA\u65b9\u6cd5\u52a0\u901f\u51fd\u6570\u8c03\u7528\uff0c\u51cf\u5c11\u54cd\u5e94\u5ef6\u8fdf\u5e76\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u5728\u97f3\u4e50\u5e94\u7528\u90e8\u7f72\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u51fd\u6570\u8c03\u7528\u9ad8\u5ef6\u8fdf\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u5728\u7ebf\u7528\u6237\u4ea4\u4e92\u6570\u636e\uff0c\u4ece\u751f\u4ea7\u6d41\u91cf\u4e2d\u8bc6\u522b\u7b80\u5355\u67e5\u8be2\uff0c\u5c06\u5927\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u5230\u5c0f\u6a21\u578b\u3002", "result": "\u9884\u671f\u51cf\u5c1145%\u3001\u4e2d\u4f4d\u6570\u51cf\u5c1178%\u7684\u54cd\u5e94\u5ef6\u8fdf\uff0c\u5c0f\u6a21\u578b\u5728\u97f3\u4e50\u5e94\u7528\u4e2d\u5904\u740660%\u6d41\u91cf\u4e14\u51c6\u786e\u6027\u635f\u5931\u53ef\u5ffd\u7565\u3002", "conclusion": "ODIA\u65b9\u6cd5\u6240\u9700\u4eba\u5de5\u5e72\u9884\u5c11\uff0c\u53ef\u901a\u8fc7\u81ea\u52a8\u6570\u636e\u6536\u96c6\u548c\u6a21\u578b\u66f4\u65b0\u6301\u7eed\u6539\u8fdb\uff0c\u9002\u7528\u4e8e\u751f\u4ea7\u73af\u5883\u3002"}}
{"id": "2507.08913", "pdf": "https://arxiv.org/pdf/2507.08913", "abs": "https://arxiv.org/abs/2507.08913", "authors": ["Qi He", "Peiran Yu", "Ziyi Chen", "Heng Huang"], "title": "Revisiting Convergence: Shuffling Complexity Beyond Lipschitz Smoothness", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Shuffling-type gradient methods are favored in practice for their simplicity\nand rapid empirical performance. Despite extensive development of convergence\nguarantees under various assumptions in recent years, most require the\nLipschitz smoothness condition, which is often not met in common machine\nlearning models. We highlight this issue with specific counterexamples. To\naddress this gap, we revisit the convergence rates of shuffling-type gradient\nmethods without assuming Lipschitz smoothness. Using our stepsize strategy, the\nshuffling-type gradient algorithm not only converges under weaker assumptions\nbut also match the current best-known convergence rates, thereby broadening its\napplicability. We prove the convergence rates for nonconvex, strongly convex,\nand non-strongly convex cases, each under both random reshuffling and arbitrary\nshuffling schemes, under a general bounded variance condition. Numerical\nexperiments further validate the performance of our shuffling-type gradient\nalgorithm, underscoring its practical efficacy.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u7814\u7a76\u65e0Lipschitz\u5149\u6ed1\u6027\u5047\u8bbe\u4e0b\u6d17\u724c\u578b\u68af\u5ea6\u6cd5\u7684\u6536\u655b\u7387\uff0c\u8bc1\u660e\u4e86\u591a\u79cd\u60c5\u51b5\u4e0b\u7684\u6536\u655b\u7387\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6d17\u724c\u578b\u68af\u5ea6\u6cd5\u6536\u655b\u6027\u4fdd\u8bc1\u5927\u591a\u9700Lipschitz\u5149\u6ed1\u6027\u6761\u4ef6\uff0c\u800c\u5e38\u89c1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e38\u4e0d\u6ee1\u8db3\u8be5\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u65b0\u7684\u6b65\u957f\u7b56\u7565\uff0c\u5728\u4e00\u822c\u6709\u754c\u65b9\u5dee\u6761\u4ef6\u4e0b\uff0c\u5bf9\u975e\u51f8\u3001\u5f3a\u51f8\u548c\u975e\u5f3a\u51f8\u60c5\u51b5\uff0c\u5728\u968f\u673a\u91cd\u6d17\u724c\u548c\u4efb\u610f\u6d17\u724c\u65b9\u6848\u4e0b\u8bc1\u660e\u6536\u655b\u7387\u3002", "result": "\u6d17\u724c\u578b\u68af\u5ea6\u7b97\u6cd5\u5728\u66f4\u5f31\u5047\u8bbe\u4e0b\u6536\u655b\uff0c\u4e14\u8fbe\u5230\u5f53\u524d\u5df2\u77e5\u6700\u4f18\u6536\u655b\u7387\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6d17\u724c\u578b\u68af\u5ea6\u7b97\u6cd5\u62d3\u5bbd\u4e86\u9002\u7528\u6027\uff0c\u5177\u6709\u5b9e\u9645\u6709\u6548\u6027\u3002"}}
{"id": "2507.10403", "pdf": "https://arxiv.org/pdf/2507.10403", "abs": "https://arxiv.org/abs/2507.10403", "authors": ["Daniele Rege Cambrin", "Lorenzo Vaiani", "Giuseppe Gallipoli", "Luca Cagliero", "Paolo Garza"], "title": "Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.MM"], "comment": null, "summary": "Retrieving relevant imagery from vast satellite archives is crucial for\napplications like disaster response and long-term climate monitoring. However,\nmost text-to-image retrieval systems are limited to RGB data, failing to\nexploit the unique physical information captured by other sensors, such as the\nall-weather structural sensitivity of Synthetic Aperture Radar (SAR) or the\nspectral signatures in optical multispectral data. To bridge this gap, we\nintroduce CrisisLandMark, a new large-scale corpus of over 647,000 Sentinel-1\nSAR and Sentinel-2 multispectral images paired with structured textual\nannotations for land cover, land use, and crisis events harmonized from\nauthoritative land cover systems (CORINE and Dynamic World) and crisis-specific\nsources. We then present CLOSP (Contrastive Language Optical SAR Pretraining),\na novel framework that uses text as a bridge to align unpaired optical and SAR\nimages into a unified embedding space. Our experiments show that CLOSP achieves\na new state-of-the-art, improving retrieval nDGC by 54% over existing models.\nAdditionally, we find that the unified training strategy overcomes the inherent\ndifficulty of interpreting SAR imagery by transferring rich semantic knowledge\nfrom the optical domain with indirect interaction. Furthermore, GeoCLOSP, which\nintegrates geographic coordinates into our framework, creates a powerful\ntrade-off between generality and specificity: while the CLOSP excels at general\nsemantic tasks, the GeoCLOSP becomes a specialized expert for retrieving\nlocation-dependent crisis events and rare geographic features. This work\nhighlights that the integration of diverse sensor data and geographic context\nis essential for unlocking the full potential of remote sensing archives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCrisisLandMark\u8bed\u6599\u5e93\u548cCLOSP\u6846\u67b6\u7528\u4e8e\u5149\u5b66\u548cSAR\u56fe\u50cf\u68c0\u7d22\uff0c\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0c\u8fd8\u5f15\u5165GeoCLOSP\u6846\u67b6\uff0c\u5f3a\u8c03\u6574\u5408\u591a\u4f20\u611f\u5668\u6570\u636e\u548c\u5730\u7406\u4e0a\u4e0b\u6587\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u5230\u56fe\u50cf\u68c0\u7d22\u7cfb\u7edf\u5927\u591a\u5c40\u9650\u4e8eRGB\u6570\u636e\uff0c\u672a\u80fd\u5229\u7528\u5176\u4ed6\u4f20\u611f\u5668\u6570\u636e\uff0c\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5f15\u5165CrisisLandMark\u8bed\u6599\u5e93\uff0c\u63d0\u51faCLOSP\u6846\u67b6\u5c06\u672a\u914d\u5bf9\u7684\u5149\u5b66\u548cSAR\u56fe\u50cf\u5bf9\u9f50\u5230\u7edf\u4e00\u5d4c\u5165\u7a7a\u95f4\uff0c\u8fd8\u5f15\u5165GeoCLOSP\u6846\u67b6\u6574\u5408\u5730\u7406\u5750\u6807\u3002", "result": "CLOSP\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u4f18\u6c34\u5e73\uff0c\u68c0\u7d22nDGC\u6bd4\u73b0\u6709\u6a21\u578b\u63d0\u9ad8\u4e8654%\uff0c\u7edf\u4e00\u8bad\u7ec3\u7b56\u7565\u514b\u670d\u4e86SAR\u56fe\u50cf\u89e3\u91ca\u96be\u9898\uff0cGeoCLOSP\u5728\u901a\u7528\u6027\u548c\u7279\u5f02\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "conclusion": "\u6574\u5408\u4e0d\u540c\u4f20\u611f\u5668\u6570\u636e\u548c\u5730\u7406\u4e0a\u4e0b\u6587\u5bf9\u91ca\u653e\u9065\u611f\u6863\u6848\u7684\u5168\u90e8\u6f5c\u529b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.09854", "pdf": "https://arxiv.org/pdf/2507.09854", "abs": "https://arxiv.org/abs/2507.09854", "authors": ["Aniruddha Chattopadhyay", "Raj Dandekar", "Kaushik Roy"], "title": "Model-Grounded Symbolic Artificial Intelligence Systems Learning and Reasoning with Model-Grounded Symbolic Artificial Intelligence Systems", "categories": ["cs.AI"], "comment": "Accepted as paper in 19th International Conference on Neurosymbolic\n  Learning and Reasoning,NeSy 2025", "summary": "Neurosymbolic artificial intelligence (AI) systems combine neural network and\nclassical symbolic AI mechanisms to exploit the complementary strengths of\nlarge scale, generalizable learning and robust, verifiable reasoning. Numerous\nclassifications of neurosymbolic AI illustrate how these two components can be\nintegrated in distinctly different ways. In this work, we propose\nreinterpreting instruction tuned large language models as model grounded\nsymbolic AI systems where natural language serves as the symbolic layer and\ngrounding is achieved through the models internal representation space. Within\nthis framework, we investigate and develop novel learning and reasoning\napproaches that preserve structural similarities to traditional learning and\nreasoning paradigms. Preliminary evaluations across axiomatic deductive\nreasoning procedures of varying complexity provide insights into the\neffectiveness of our approach in improving learning efficiency and reasoning\nreliability.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u65b0\u89e3\u91ca\u4e3a\u6a21\u578b\u63a5\u5730\u7b26\u53f7AI\u7cfb\u7edf\uff0c\u5f00\u53d1\u65b0\u5b66\u4e60\u548c\u63a8\u7406\u65b9\u6cd5\uff0c\u521d\u6b65\u8bc4\u4f30\u663e\u793a\u53ef\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u63a8\u7406\u53ef\u9760\u6027\u3002", "motivation": "\u5229\u7528\u795e\u7ecf\u7b26\u53f7AI\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0e\u7ecf\u5178\u7b26\u53f7AI\u673a\u5236\u7684\u4f18\u52bf\uff0c\u63a2\u7d22\u65b0\u7684\u96c6\u6210\u65b9\u5f0f\u3002", "method": "\u5c06\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u65b0\u89e3\u91ca\u4e3a\u6a21\u578b\u63a5\u5730\u7b26\u53f7AI\u7cfb\u7edf\uff0c\u81ea\u7136\u8bed\u8a00\u4f5c\u4e3a\u7b26\u53f7\u5c42\uff0c\u901a\u8fc7\u6a21\u578b\u5185\u90e8\u8868\u793a\u7a7a\u95f4\u5b9e\u73b0\u63a5\u5730\uff0c\u5728\u6b64\u6846\u67b6\u4e0b\u5f00\u53d1\u65b0\u7684\u5b66\u4e60\u548c\u63a8\u7406\u65b9\u6cd5\u3002", "result": "\u5bf9\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u516c\u7406\u6f14\u7ece\u63a8\u7406\u7a0b\u5e8f\u8fdb\u884c\u521d\u6b65\u8bc4\u4f30\uff0c\u4e3a\u65b9\u6cd5\u6709\u6548\u6027\u63d0\u4f9b\u89c1\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u63a8\u7406\u53ef\u9760\u6027\u3002"}}
{"id": "2507.09682", "pdf": "https://arxiv.org/pdf/2507.09682", "abs": "https://arxiv.org/abs/2507.09682", "authors": ["Laura Baird", "Armin Moin"], "title": "OrQstrator: An AI-Powered Framework for Advanced Quantum Circuit Optimization", "categories": ["cs.SE", "cs.AI", "cs.ET"], "comment": "IEEE International Conference on Quantum Computing and Engineering\n  (QCE) 2025 - Extended Abstract", "summary": "We propose a novel approach, OrQstrator, which is a modular framework for\nconducting quantum circuit optimization in the Noisy Intermediate-Scale Quantum\n(NISQ) era. Our framework is powered by Deep Reinforcement Learning (DRL). Our\norchestration engine intelligently selects among three complementary circuit\noptimizers: A DRL-based circuit rewriter trained to reduce depth and gate count\nvia learned rewrite sequences; a domain-specific optimizer that performs\nefficient local gate resynthesis and numeric optimization; a parameterized\ncircuit instantiator that improves compilation by optimizing template circuits\nduring gate set translation. These modules are coordinated by a central\norchestration engine that learns coordination policies based on circuit\nstructure, hardware constraints, and backend-aware performance features such as\ngate count, depth, and expected fidelity. The system outputs an optimized\ncircuit for hardware-aware transpilation and execution, leveraging techniques\nfrom an existing state-of-the-art approach, called the NISQ Analyzer, to adapt\nto backend constraints.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aOrQstrator\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u91cf\u5b50\u7535\u8def\u4f18\u5316\uff0c\u7531\u4e2d\u592e\u5f15\u64ce\u534f\u8c03\u591a\u4e2a\u4f18\u5316\u5668\u6a21\u5757\uff0c\u8f93\u51fa\u9002\u5e94\u540e\u7aef\u7ea6\u675f\u7684\u4f18\u5316\u7535\u8def\u3002", "motivation": "\u5728NISQ\u65f6\u4ee3\u8fdb\u884c\u91cf\u5b50\u7535\u8def\u4f18\u5316\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u4e2d\u592e\u7f16\u6392\u5f15\u64ce\u534f\u8c03\u57fa\u4e8eDRL\u7684\u7535\u8def\u91cd\u5199\u5668\u3001\u7279\u5b9a\u9886\u57df\u4f18\u5316\u5668\u548c\u53c2\u6570\u5316\u7535\u8def\u5b9e\u4f8b\u5316\u5668\u4e09\u4e2a\u4f18\u5316\u5668\u6a21\u5757\uff0c\u5229\u7528NISQ Analyzer\u6280\u672f\u9002\u5e94\u540e\u7aef\u7ea6\u675f\u3002", "result": "\u8f93\u51fa\u9002\u5408\u786c\u4ef6\u611f\u77e5\u8f6c\u8bd1\u548c\u6267\u884c\u7684\u4f18\u5316\u7535\u8def\u3002", "conclusion": "\u63d0\u51fa\u7684OrQstrator\u6846\u67b6\u53ef\u6709\u6548\u5728NISQ\u65f6\u4ee3\u8fdb\u884c\u91cf\u5b50\u7535\u8def\u4f18\u5316\u3002"}}
{"id": "2507.08905", "pdf": "https://arxiv.org/pdf/2507.08905", "abs": "https://arxiv.org/abs/2507.08905", "authors": ["Koen Vellenga", "H. Joe Steinhauer", "G\u00f6ran Falkman", "Jonas Andersson", "Anders Sj\u00f6gren"], "title": "Last Layer Hamiltonian Monte Carlo", "categories": ["cs.LG", "cs.AI", "G.3"], "comment": "25 pages, 15 figures, 6 tables, currently under submission", "summary": "We explore the use of Hamiltonian Monte Carlo (HMC) sampling as a\nprobabilistic last layer approach for deep neural networks (DNNs). While HMC is\nwidely regarded as a gold standard for uncertainty estimation, the\ncomputational demands limit its application to large-scale datasets and large\nDNN architectures. Although the predictions from the sampled DNN parameters can\nbe parallelized, the computational cost still scales linearly with the number\nof samples (similar to an ensemble). Last layer HMC (LL--HMC) reduces the\nrequired computations by restricting the HMC sampling to the final layer of a\nDNN, making it applicable to more data-intensive scenarios with limited\ncomputational resources. In this paper, we compare LL-HMC against five last\nlayer probabilistic deep learning (LL-PDL) methods across three real-world\nvideo datasets for driver action and intention. We evaluate the in-distribution\nclassification performance, calibration, and out-of-distribution (OOD)\ndetection. Due to the stochastic nature of the probabilistic evaluations, we\nperformed five grid searches for different random seeds to avoid being reliant\non a single initialization for the hyperparameter configurations. The results\nshow that LL--HMC achieves competitive in-distribution classification and OOD\ndetection performance. Additional sampled last layer parameters do not improve\nthe classification performance, but can improve the OOD detection. Multiple\nchains or starting positions did not yield consistent improvements.", "AI": {"tldr": "\u63a2\u7d22\u7528Hamiltonian Monte Carlo (HMC) \u91c7\u6837\u4f5c\u4e3a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6982\u7387\u6700\u540e\u4e00\u5c42\u65b9\u6cd5\uff0c\u63d0\u51faLast layer HMC (LL - HMC)\uff0c\u4e0e\u4e94\u79cd\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u7ed3\u679c\u663e\u793aLL - HMC\u6709\u7ade\u4e89\u529b\u3002", "motivation": "HMC\u8ba1\u7b97\u9700\u6c42\u5927\u9650\u5236\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u5927DNN\u67b6\u6784\u5e94\u7528\uff0c\u9700\u51cf\u5c11\u8ba1\u7b97\u91cf\u4ee5\u7528\u4e8e\u6570\u636e\u5bc6\u96c6\u573a\u666f\u3002", "method": "\u63d0\u51faLL - HMC\uff0c\u5c06HMC\u91c7\u6837\u9650\u5236\u5728DNN\u6700\u540e\u4e00\u5c42\uff1b\u5728\u4e09\u4e2a\u771f\u5b9e\u89c6\u9891\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4LL - HMC\u548c\u4e94\u79cdLL - PDL\u65b9\u6cd5\uff1b\u8fdb\u884c\u4e94\u6b21\u4e0d\u540c\u968f\u673a\u79cd\u5b50\u7684\u7f51\u683c\u641c\u7d22\u3002", "result": "LL - HMC\u5728\u5206\u5e03\u5185\u5206\u7c7b\u548cOOD\u68c0\u6d4b\u4e0a\u6709\u7ade\u4e89\u529b\uff1b\u989d\u5916\u91c7\u6837\u6700\u540e\u4e00\u5c42\u53c2\u6570\u4e0d\u63d0\u5347\u5206\u7c7b\u6027\u80fd\uff0c\u4f46\u53ef\u63d0\u5347OOD\u68c0\u6d4b\uff1b\u591a\u94fe\u6216\u591a\u8d77\u59cb\u4f4d\u7f6e\u65e0\u4e00\u81f4\u63d0\u5347\u3002", "conclusion": "LL - HMC\u9002\u7528\u4e8e\u6570\u636e\u5bc6\u96c6\u573a\u666f\uff0c\u5728\u5206\u7c7b\u548cOOD\u68c0\u6d4b\u4e0a\u6709\u8f83\u597d\u8868\u73b0\u3002"}}
{"id": "2507.08956", "pdf": "https://arxiv.org/pdf/2507.08956", "abs": "https://arxiv.org/abs/2507.08956", "authors": ["Zhenghan Fang", "Mateo D\u00edaz", "Sam Buchanan", "Jeremias Sulam"], "title": "Beyond Scores: Proximal Diffusion Models", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Diffusion models have quickly become some of the most popular and powerful\ngenerative models for high-dimensional data. The key insight that enabled their\ndevelopment was the realization that access to the score -- the gradient of the\nlog-density at different noise levels -- allows for sampling from data\ndistributions by solving a reverse-time stochastic differential equation (SDE)\nvia forward discretization, and that popular denoisers allow for unbiased\nestimators of this score. In this paper, we demonstrate that an alternative,\nbackward discretization of these SDEs, using proximal maps in place of the\nscore, leads to theoretical and practical benefits. We leverage recent results\nin proximal matching to learn proximal operators of the log-density and, with\nthem, develop Proximal Diffusion Models (ProxDM). Theoretically, we prove that\n$\\widetilde{O}(d/\\sqrt{\\varepsilon})$ steps suffice for the resulting\ndiscretization to generate an $\\varepsilon$-accurate distribution w.r.t. the KL\ndivergence. Empirically, we show that two variants of ProxDM achieve\nsignificantly faster convergence within just a few sampling steps compared to\nconventional score-matching methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.10421", "pdf": "https://arxiv.org/pdf/2507.10421", "abs": "https://arxiv.org/abs/2507.10421", "authors": ["Meriem Zerkouk", "Miloud Mihoubi", "Belkacem Chikhaoui"], "title": "SentiDrop: A Multi Modal Machine Learning model for Predicting Dropout in Distance Learning", "categories": ["cs.AI", "cs.ET", "cs.IR", "cs.LG"], "comment": "International Conference on Education and New Learning Technologies\n  (2025)", "summary": "School dropout is a serious problem in distance learning, where early\ndetection is crucial for effective intervention and student perseverance.\nPredicting student dropout using available educational data is a widely\nresearched topic in learning analytics. Our partner's distance learning\nplatform highlights the importance of integrating diverse data sources,\nincluding socio-demographic data, behavioral data, and sentiment analysis, to\naccurately predict dropout risks. In this paper, we introduce a novel model\nthat combines sentiment analysis of student comments using the Bidirectional\nEncoder Representations from Transformers (BERT) model with socio-demographic\nand behavioral data analyzed through Extreme Gradient Boosting (XGBoost). We\nfine-tuned BERT on student comments to capture nuanced sentiments, which were\nthen merged with key features selected using feature importance techniques in\nXGBoost. Our model was tested on unseen data from the next academic year,\nachieving an accuracy of 84\\%, compared to 82\\% for the baseline model.\nAdditionally, the model demonstrated superior performance in other metrics,\nsuch as precision and F1-score. The proposed method could be a vital tool in\ndeveloping personalized strategies to reduce dropout rates and encourage\nstudent perseverance", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u7ed3\u5408BERT\u60c5\u611f\u5206\u6790\u4e0eXGBoost\u5206\u6790\u793e\u4f1a\u4eba\u53e3\u548c\u884c\u4e3a\u6570\u636e\u7684\u6a21\u578b\u9884\u6d4b\u8fdc\u7a0b\u5b66\u4e60\u5b66\u751f\u8f8d\u5b66\u98ce\u9669\uff0c\u6d4b\u8bd5\u51c6\u786e\u738784%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u8fdc\u7a0b\u5b66\u4e60\u8f8d\u5b66\u95ee\u9898\u4e25\u91cd\uff0c\u65e9\u671f\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u9700\u51c6\u786e\u9884\u6d4b\u8f8d\u5b66\u98ce\u9669\u4ee5\u8fdb\u884c\u6709\u6548\u5e72\u9884\u3002", "method": "\u5f15\u5165\u7ed3\u5408BERT\u5bf9\u5b66\u751f\u8bc4\u8bba\u8fdb\u884c\u60c5\u611f\u5206\u6790\u548cXGBoost\u5206\u6790\u793e\u4f1a\u4eba\u53e3\u4e0e\u884c\u4e3a\u6570\u636e\u7684\u6a21\u578b\uff0c\u5fae\u8c03BERT\u6355\u6349\u60c5\u611f\uff0c\u7528\u7279\u5f81\u91cd\u8981\u6027\u6280\u672f\u9009\u62e9XGBoost\u5173\u952e\u7279\u5f81\u5e76\u5408\u5e76\u3002", "result": "\u6a21\u578b\u5728\u672a\u77e5\u6570\u636e\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u8fbe84%\uff0c\u9ad8\u4e8e\u57fa\u7ebf\u6a21\u578b\u768482%\uff0c\u5176\u4ed6\u6307\u6807\u8868\u73b0\u4e5f\u66f4\u4f18\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u5236\u5b9a\u4e2a\u6027\u5316\u7b56\u7565\u964d\u4f4e\u8f8d\u5b66\u7387\u3001\u9f13\u52b1\u5b66\u751f\u575a\u6301\u5b66\u4e60\u7684\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2507.09884", "pdf": "https://arxiv.org/pdf/2507.09884", "abs": "https://arxiv.org/abs/2507.09884", "authors": ["Xuzhao Li", "Xuchen Li", "Shiyu Hu", "Yongzhen Guo", "Wentao Zhang"], "title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains", "categories": ["cs.AI"], "comment": "Preprint, Under review", "summary": "Large language models (LLMs) increasingly rely on reinforcement learning (RL)\nto enhance their reasoning capabilities through feedback. A critical challenge\nis verifying the consistency of model-generated responses and reference\nanswers, since these responses are often lengthy, diverse, and nuanced.\nRule-based verifiers struggle with complexity, prompting the use of model-based\nverifiers. However, specialized verifiers lack flexibility, while general LLM\njudges can be inconsistent. Existing research primarily focuses on building\nbetter verifiers, yet a systematic evaluation of different types of verifiers'\nperformance across domains remains lacking, severely constraining the reliable\ndevelopment of Reinforcement Learning with Verifiable Reward (RLVR). To address\nthis, we propose VerifyBench--a cross-domain comprehensive benchmark for\nsystematically evaluating verifiers. We construct 4,000 expert-level questions\ncovering mathematics, physics, chemistry, and biology. Each question is\nequipped with reference answers and diverse responses. The reliability of the\nevaluation is ensured through a rigorous annotation process conducted by a\nmultidisciplinary expert team. We design a four-dimensional experimental\nframework to comprehensively compare the performance boundaries of specialized\nverifiers and general LLMs under combined conditions of extracted answers vs.\ncomplete responses, and short vs. long outputs. Our evaluation uncovers\nfundamental trade-offs in verifiers: while specialized verifiers achieve\nleading accuracy, they exhibit deficiencies in recall; general models show\nstronger inclusivity but unstable precision. More importantly, we discover\nverifiers' high sensitivity to input structure and inherent limitations in\ncross-domain generalization, providing critical insights into the bottlenecks\nof current verifier technology.", "AI": {"tldr": "\u63d0\u51faVerifyBench\u57fa\u51c6\u8bc4\u4f30\u9a8c\u8bc1\u5668\uff0c\u6784\u5efa4000\u4e2a\u95ee\u9898\uff0c\u8bbe\u8ba1\u5b9e\u9a8c\u6846\u67b6\u5bf9\u6bd4\u6027\u80fd\uff0c\u53d1\u73b0\u9a8c\u8bc1\u5668\u6743\u8861\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u4e0d\u540c\u7c7b\u578b\u9a8c\u8bc1\u5668\u8de8\u9886\u57df\u6027\u80fd\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5236\u7ea6\u4e86\u53ef\u9a8c\u8bc1\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u7684\u53ef\u9760\u53d1\u5c55\u3002", "method": "\u6784\u5efaVerifyBench\u57fa\u51c6\uff0c\u5305\u542b4000\u4e2a\u8de8\u6570\u5b66\u3001\u7269\u7406\u3001\u5316\u5b66\u548c\u751f\u7269\u5b66\u7684\u4e13\u5bb6\u7ea7\u95ee\u9898\uff0c\u7531\u591a\u5b66\u79d1\u56e2\u961f\u4e25\u683c\u6807\u6ce8\uff1b\u8bbe\u8ba1\u56db\u7ef4\u5b9e\u9a8c\u6846\u67b6\u5bf9\u6bd4\u4e0d\u540c\u9a8c\u8bc1\u5668\u6027\u80fd\u3002", "result": "\u53d1\u73b0\u9a8c\u8bc1\u5668\u5b58\u5728\u6743\u8861\uff0c\u4e13\u7528\u9a8c\u8bc1\u5668\u7cbe\u5ea6\u9ad8\u4f46\u53ec\u56de\u4e0d\u8db3\uff0c\u901a\u7528\u6a21\u578b\u5305\u5bb9\u6027\u5f3a\u4f46\u7cbe\u5ea6\u4e0d\u7a33\u5b9a\uff1b\u9a8c\u8bc1\u5668\u5bf9\u8f93\u5165\u7ed3\u6784\u654f\u611f\uff0c\u8de8\u9886\u57df\u6cdb\u5316\u6709\u56fa\u6709\u5c40\u9650\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f53\u524d\u9a8c\u8bc1\u5668\u6280\u672f\u7684\u74f6\u9888\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2507.08912", "pdf": "https://arxiv.org/pdf/2507.08912", "abs": "https://arxiv.org/abs/2507.08912", "authors": ["Tomasz Szandala", "Fatima Ezzeddine", "Natalia Rusin", "Silvia Giordano", "Omran Ayoub"], "title": "Fair-FLIP: Fair Deepfake Detection with Fairness-Oriented Final Layer Input Prioritising", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Artificial Intelligence-generated content has become increasingly popular,\nyet its malicious use, particularly the deepfakes, poses a serious threat to\npublic trust and discourse. While deepfake detection methods achieve high\npredictive performance, they often exhibit biases across demographic attributes\nsuch as ethnicity and gender. In this work, we tackle the challenge of fair\ndeepfake detection, aiming to mitigate these biases while maintaining robust\ndetection capabilities. To this end, we propose a novel post-processing\napproach, referred to as Fairness-Oriented Final Layer Input Prioritising\n(Fair-FLIP), that reweights a trained model's final-layer inputs to reduce\nsubgroup disparities, prioritising those with low variability while demoting\nhighly variable ones. Experimental results comparing Fair-FLIP to both the\nbaseline (without fairness-oriented de-biasing) and state-of-the-art approaches\nshow that Fair-FLIP can enhance fairness metrics by up to 30% while maintaining\nbaseline accuracy, with only a negligible reduction of 0.25%.\n  Code is available on Github:\nhttps://github.com/szandala/fair-deepfake-detection-toolbox", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFair - FLIP\u65b9\u6cd5\u89e3\u51b3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u63d0\u5347\u516c\u5e73\u6027\u6307\u6807\uff0c\u4fdd\u6301\u68c0\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u751f\u6210\u5185\u5bb9\u6076\u610f\u4f7f\u7528\uff08\u5982\u6df1\u5ea6\u4f2a\u9020\uff09\u5a01\u80c1\u516c\u4f17\u4fe1\u4efb\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u8de8\u4eba\u53e3\u5c5e\u6027\uff08\u5982\u79cd\u65cf\u3001\u6027\u522b\uff09\u7684\u504f\u5dee\uff0c\u9700\u89e3\u51b3\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faFair - FLIP\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u5bf9\u8bad\u7ec3\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42\u8f93\u5165\u91cd\u65b0\u52a0\u6743\uff0c\u964d\u4f4e\u5b50\u7ec4\u5dee\u5f02\u3002", "result": "\u4e0e\u57fa\u7ebf\u548c\u73b0\u6709\u65b9\u6cd5\u5bf9\u6bd4\uff0cFair - FLIP\u53ef\u5c06\u516c\u5e73\u6027\u6307\u6807\u63d0\u9ad830%\uff0c\u4fdd\u6301\u57fa\u7ebf\u51c6\u786e\u7387\uff0c\u4ec5\u964d\u4f4e0.25%\u3002", "conclusion": "Fair - FLIP\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u7684\u504f\u5dee\uff0c\u5728\u4fdd\u6301\u68c0\u6d4b\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u516c\u5e73\u6027\u3002"}}
{"id": "2507.08963", "pdf": "https://arxiv.org/pdf/2507.08963", "abs": "https://arxiv.org/abs/2507.08963", "authors": ["Tao Jiang", "Lin Xiao"], "title": "Stochastic Approximation with Block Coordinate Optimal Stepsizes", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We consider stochastic approximation with block-coordinate stepsizes and\npropose adaptive stepsize rules that aim to minimize the expected distance from\nthe next iterate to an optimal point. These stepsize rules employ online\nestimates of the second moment of the search direction along each block\ncoordinate. The popular Adam algorithm can be interpreted as a particular\nheuristic for such estimation. By leveraging a simple conditional estimator, we\nderive a new method that obtains comparable performance as Adam but requires\nless memory and fewer hyper-parameters. We prove that this family of methods\nconverges almost surely to a small neighborhood of the optimal point, and the\nradius of the neighborhood depends on the bias and variance of the\nsecond-moment estimator. Our analysis relies on a simple aiming condition that\nassumes neither convexity nor smoothness, thus has broad applicability.", "AI": {"tldr": "\u63d0\u51fa\u5e26\u5757\u5750\u6807\u6b65\u957f\u7684\u968f\u673a\u8fd1\u4f3c\u81ea\u9002\u5e94\u6b65\u957f\u89c4\u5219\uff0c\u65b0\u65b9\u6cd5\u6027\u80fd\u4e0eAdam\u76f8\u5f53\u4f46\u5185\u5b58\u548c\u8d85\u53c2\u6570\u9700\u6c42\u5c11\uff0c\u8bc1\u660e\u65b9\u6cd5\u6536\u655b\u6027\u3002", "motivation": "\u5bfb\u627e\u80fd\u6700\u5c0f\u5316\u4e0b\u4e00\u6b21\u8fed\u4ee3\u70b9\u5230\u6700\u4f18\u70b9\u671f\u671b\u8ddd\u79bb\u7684\u81ea\u9002\u5e94\u6b65\u957f\u89c4\u5219\u3002", "method": "\u5229\u7528\u7b80\u5355\u6761\u4ef6\u4f30\u8ba1\u5668\uff0c\u91c7\u7528\u5757\u5750\u6807\u6b65\u957f\uff0c\u7ed3\u5408\u5728\u7ebf\u4f30\u8ba1\u5404\u5757\u5750\u6807\u641c\u7d22\u65b9\u5411\u4e8c\u9636\u77e9\u3002", "result": "\u65b0\u65b9\u6cd5\u6027\u80fd\u4e0eAdam\u76f8\u5f53\uff0c\u6240\u9700\u5185\u5b58\u548c\u8d85\u53c2\u6570\u66f4\u5c11\uff0c\u8bc1\u660e\u65b9\u6cd5\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u6700\u4f18\u70b9\u5c0f\u90bb\u57df\u3002", "conclusion": "\u8be5\u7cfb\u5217\u65b9\u6cd5\u5177\u6709\u6536\u655b\u6027\uff0c\u5206\u6790\u4f9d\u8d56\u7684\u6761\u4ef6\u4e0d\u8981\u6c42\u51f8\u6027\u548c\u5e73\u6ed1\u6027\uff0c\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2507.10485", "pdf": "https://arxiv.org/pdf/2507.10485", "abs": "https://arxiv.org/abs/2507.10485", "authors": ["Brandon Shuen Yi Loke", "Filippo Quadri", "Gabriel Vivanco", "Maximilian Casagrande", "Sa\u00fal Fenollosa"], "title": "Overcoming catastrophic forgetting in neural networks", "categories": ["cs.LG", "cs.IR"], "comment": "7 pages, 5 figures, EE-411 Fundamentals of inference and learning\n  course project", "summary": "Catastrophic forgetting is the primary challenge that hinders continual\nlearning, which refers to a neural network ability to sequentially learn\nmultiple tasks while retaining previously acquired knowledge. Elastic Weight\nConsolidation, a regularization-based approach inspired by synaptic\nconsolidation in biological neural systems, has been used to overcome this\nproblem. In this study prior research is replicated and extended by evaluating\nEWC in supervised learning settings using the PermutedMNIST and RotatedMNIST\nbenchmarks. Through systematic comparisons with L2 regularization and\nstochastic gradient descent (SGD) without regularization, we analyze how\ndifferent approaches balance knowledge retention and adaptability. Our results\nconfirm what was shown in previous research, showing that EWC significantly\nreduces forgetting compared to naive training while slightly compromising\nlearning efficiency on new tasks. Moreover, we investigate the impact of\ndropout regularization and varying hyperparameters, offering insights into the\ngeneralization of EWC across diverse learning scenarios. These results\nunderscore EWC's potential as a viable solution for lifelong learning in neural\nnetworks.", "AI": {"tldr": "\u672c\u6587\u590d\u5236\u5e76\u6269\u5c55\u5148\u524d\u7814\u7a76\uff0c\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u7528PermutedMNIST\u548cRotatedMNIST\u57fa\u51c6\u8bc4\u4f30EWC\uff0c\u4e0eL2\u6b63\u5219\u5316\u548c\u65e0\u6b63\u5219\u5316\u7684SGD\u5bf9\u6bd4\uff0c\u7814\u7a76EWC\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8\u6548\u679c\u53ca\u6cdb\u5316\u6027\uff0c\u5f3a\u8c03\u5176\u5bf9\u795e\u7ecf\u7f51\u7edc\u7ec8\u8eab\u5b66\u4e60\u7684\u6f5c\u529b\u3002", "motivation": "\u707e\u96be\u6027\u9057\u5fd8\u662f\u963b\u788d\u6301\u7eed\u5b66\u4e60\u7684\u4e3b\u8981\u6311\u6218\uff0cEWC\u53ef\u7528\u4e8e\u514b\u670d\u6b64\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u590d\u5236\u548c\u6269\u5c55\u5148\u524d\u7814\u7a76\uff0c\u8bc4\u4f30EWC\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u6548\u679c\u3002", "method": "\u5728\u76d1\u7763\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u4f7f\u7528PermutedMNIST\u548cRotatedMNIST\u57fa\u51c6\u8bc4\u4f30EWC\uff0c\u4e0eL2\u6b63\u5219\u5316\u548c\u65e0\u6b63\u5219\u5316\u7684SGD\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u8fd8\u7814\u7a76\u4e86dropout\u6b63\u5219\u5316\u548c\u4e0d\u540c\u8d85\u53c2\u6570\u7684\u5f71\u54cd\u3002", "result": "\u786e\u8ba4\u5148\u524d\u7814\u7a76\u7ed3\u679c\uff0cEWC\u76f8\u6bd4\u6734\u7d20\u8bad\u7ec3\u663e\u8457\u51cf\u5c11\u9057\u5fd8\uff0c\u5728\u65b0\u4efb\u52a1\u5b66\u4e60\u6548\u7387\u4e0a\u7565\u6709\u59a5\u534f\uff0c\u7814\u7a76\u4e86EWC\u5728\u4e0d\u540c\u5b66\u4e60\u573a\u666f\u7684\u6cdb\u5316\u6027\u3002", "conclusion": "EWC\u6709\u6f5c\u529b\u6210\u4e3a\u795e\u7ecf\u7f51\u7edc\u7ec8\u8eab\u5b66\u4e60\u7684\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09955", "pdf": "https://arxiv.org/pdf/2507.09955", "abs": "https://arxiv.org/abs/2507.09955", "authors": ["Luolin Xiong", "Haofen Wang", "Xi Chen", "Lu Sheng", "Yun Xiong", "Jingping Liu", "Yanghua Xiao", "Huajun Chen", "Qing-Long Han", "Yang Tang"], "title": "DeepSeek: Paradigm Shifts and Technical Evolution in Large AI Models", "categories": ["cs.AI"], "comment": null, "summary": "DeepSeek, a Chinese Artificial Intelligence (AI) startup, has released their\nV3 and R1 series models, which attracted global attention due to their low\ncost, high performance, and open-source advantages. This paper begins by\nreviewing the evolution of large AI models focusing on paradigm shifts, the\nmainstream Large Language Model (LLM) paradigm, and the DeepSeek paradigm.\nSubsequently, the paper highlights novel algorithms introduced by DeepSeek,\nincluding Multi-head Latent Attention (MLA), Mixture-of-Experts (MoE),\nMulti-Token Prediction (MTP), and Group Relative Policy Optimization (GRPO).\nThe paper then explores DeepSeek engineering breakthroughs in LLM scaling,\ntraining, inference, and system-level optimization architecture. Moreover, the\nimpact of DeepSeek models on the competitive AI landscape is analyzed,\ncomparing them to mainstream LLMs across various fields. Finally, the paper\nreflects on the insights gained from DeepSeek innovations and discusses future\ntrends in the technical and engineering development of large AI models,\nparticularly in data, training, and reasoning.", "AI": {"tldr": "\u672c\u6587\u56f4\u7ed5DeepSeek\u53d1\u5e03\u7684V3\u548cR1\u7cfb\u5217\u6a21\u578b\uff0c\u56de\u987e\u5927\u6a21\u578b\u6f14\u53d8\uff0c\u4ecb\u7ecd\u5176\u65b0\u7b97\u6cd5\u3001\u5de5\u7a0b\u7a81\u7834\uff0c\u5206\u6790\u5bf9AI\u7ade\u4e89\u683c\u5c40\u5f71\u54cd\uff0c\u63a2\u8ba8\u672a\u6765\u8d8b\u52bf\u3002", "motivation": "\u6df1\u5165\u4e86\u89e3DeepSeek\u6a21\u578b\u7684\u7279\u70b9\u3001\u521b\u65b0\u53ca\u5bf9AI\u9886\u57df\u7684\u5f71\u54cd\uff0c\u4e3a\u5927\u6a21\u578b\u6280\u672f\u548c\u5de5\u7a0b\u53d1\u5c55\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u5148\u56de\u987e\u5927AI\u6a21\u578b\u6f14\u53d8\uff0c\u4ecb\u7ecdDeepSeek\u65b0\u7b97\u6cd5\uff0c\u63a2\u7d22\u5176\u5de5\u7a0b\u7a81\u7834\uff0c\u5bf9\u6bd4\u5206\u6790\u5176\u5728\u5404\u9886\u57df\u4e0e\u4e3b\u6d41LLM\u7684\u5dee\u5f02\u3002", "result": "\u5c55\u793a\u4e86DeepSeek\u6a21\u578b\u7684\u65b0\u7b97\u6cd5\u548c\u5de5\u7a0b\u7a81\u7834\uff0c\u5206\u6790\u4e86\u5176\u5728AI\u7ade\u4e89\u683c\u5c40\u4e2d\u7684\u5f71\u54cd\u3002", "conclusion": "\u4eceDeepSeek\u521b\u65b0\u4e2d\u83b7\u5f97\u542f\u793a\uff0c\u63a2\u8ba8\u5927AI\u6a21\u578b\u5728\u6570\u636e\u3001\u8bad\u7ec3\u548c\u63a8\u7406\u7b49\u65b9\u9762\u7684\u672a\u6765\u8d8b\u52bf\u3002"}}
{"id": "2507.09820", "pdf": "https://arxiv.org/pdf/2507.09820", "abs": "https://arxiv.org/abs/2507.09820", "authors": ["Jia Yi Goh", "Shaun Khoo", "Nyx Iskandar", "Gabriel Chua", "Leanne Tan", "Jessica Foo"], "title": "Measuring What Matters: A Framework for Evaluating Safety Risks in Real-World LLM Applications", "categories": ["cs.SE", "cs.CY"], "comment": null, "summary": "Most safety testing efforts for large language models (LLMs) today focus on\nevaluating foundation models. However, there is a growing need to evaluate\nsafety at the application level, as components such as system prompts,\nretrieval pipelines, and guardrails introduce additional factors that\nsignificantly influence the overall safety of LLM applications. In this paper,\nwe introduce a practical framework for evaluating application-level safety in\nLLM systems, validated through real-world deployment across multiple use cases\nwithin our organization. The framework consists of two parts: (1) principles\nfor developing customized safety risk taxonomies, and (2) practices for\nevaluating safety risks in LLM applications. We illustrate how the proposed\nframework was applied in our internal pilot, providing a reference point for\norganizations seeking to scale their safety testing efforts. This work aims to\nbridge the gap between theoretical concepts in AI safety and the operational\nrealities of safeguarding LLM applications in practice, offering actionable\nguidance for safe and scalable deployment.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u7ea7\u5b89\u5168\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u7531\u5f00\u53d1\u5b9a\u5236\u5b89\u5168\u98ce\u9669\u5206\u7c7b\u539f\u5219\u548c\u8bc4\u4f30\u5e94\u7528\u5b89\u5168\u98ce\u9669\u5b9e\u8df5\u4e24\u90e8\u5206\u6784\u6210\uff0c\u901a\u8fc7\u5185\u90e8\u8bd5\u70b9\u9a8c\u8bc1\uff0c\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6d4b\u8bd5\u591a\u5173\u6ce8\u57fa\u7840\u6a21\u578b\uff0c\u800c\u5e94\u7528\u5c42\u9762\u7684\u7ec4\u4ef6\u4f1a\u5f71\u54cd\u6574\u4f53\u5b89\u5168\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u8bc4\u4f30\u5e94\u7528\u7ea7\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5b9e\u7528\u6846\u67b6\uff0c\u5305\u542b\u5f00\u53d1\u5b9a\u5236\u5b89\u5168\u98ce\u9669\u5206\u7c7b\u7684\u539f\u5219\u548c\u8bc4\u4f30\u5e94\u7528\u5b89\u5168\u98ce\u9669\u7684\u5b9e\u8df5\u4e24\u90e8\u5206\u3002", "result": "\u6846\u67b6\u901a\u8fc7\u7ec4\u7ec7\u5185\u591a\u4e2a\u7528\u4f8b\u7684\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\uff0c\u5e76\u5728\u5185\u90e8\u8bd5\u70b9\u4e2d\u5e94\u7528\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f25\u5408\u4e86\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u7406\u8bba\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u5b89\u5168\u8fd0\u8425\u73b0\u5b9e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5b89\u5168\u53ef\u6269\u5c55\u90e8\u7f72\u63d0\u4f9b\u53ef\u884c\u6307\u5bfc\u3002"}}
{"id": "2507.08965", "pdf": "https://arxiv.org/pdf/2507.08965", "abs": "https://arxiv.org/abs/2507.08965", "authors": ["Kevin Rojas", "Ye He", "Chieh-Hsin Lai", "Yuta Takida", "Yuki Mitsufuji", "Molei Tao"], "title": "Theory-Informed Improvements to Classifier-Free Guidance for Discrete Diffusion Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Classifier-Free Guidance (CFG) is a widely used technique for conditional\ngeneration and improving sample quality in continuous diffusion models, and\nrecent works have extended it to discrete diffusion. This paper theoretically\nanalyzes CFG in the context of masked discrete diffusion, focusing on the role\nof guidance schedules. Our analysis shows that high guidance early in sampling\n(when inputs are heavily masked) harms generation quality, while late-stage\nguidance has a larger effect. These findings provide a theoretical explanation\nfor empirical observations in recent studies on guidance schedules. The\nanalysis also reveals an imperfection of the current CFG implementations. These\nimplementations can unintentionally cause imbalanced transitions, such as\nunmasking too rapidly during the early stages of generation, which degrades the\nquality of the resulting samples. To address this, we draw insight from the\nanalysis and propose a novel classifier-free guidance mechanism empirically\napplicable to any discrete diffusion. Intuitively, our method smoothens the\ntransport between the data distribution and the initial (masked/uniform)\ndistribution, which results in improved sample quality. Remarkably, our method\nis achievable via a simple one-line code change. The efficacy of our method is\nempirically demonstrated with experiments on ImageNet (masked discrete\ndiffusion) and QM9 (uniform discrete diffusion).", "AI": {"tldr": "\u672c\u6587\u7406\u8bba\u5206\u6790\u63a9\u7801\u79bb\u6563\u6269\u6563\u4e2dCFG\u7684\u5f15\u5bfc\u8c03\u5ea6\uff0c\u53d1\u73b0\u65e9\u671f\u9ad8\u5f15\u5bfc\u6709\u5bb3\uff0c\u63ed\u793a\u73b0\u6709\u5b9e\u73b0\u7f3a\u9677\u5e76\u63d0\u51fa\u65b0\u673a\u5236\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u5bf9\u63a9\u7801\u79bb\u6563\u6269\u6563\u4e2d\u7684CFG\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u89e3\u91ca\u5f15\u5bfc\u8c03\u5ea6\u7684\u7ecf\u9a8c\u89c2\u5bdf\uff0c\u5e76\u89e3\u51b3\u73b0\u6709CFG\u5b9e\u73b0\u7684\u4e0d\u8db3\u3002", "method": "\u7406\u8bba\u5206\u6790CFG\u5728\u63a9\u7801\u79bb\u6563\u6269\u6563\u4e2d\u7684\u5f15\u5bfc\u8c03\u5ea6\uff0c\u6839\u636e\u5206\u6790\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u4efb\u4f55\u79bb\u6563\u6269\u6563\u7684\u65b0\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u673a\u5236\u3002", "result": "\u65e9\u671f\u9ad8\u5f15\u5bfc\u4f1a\u635f\u5bb3\u751f\u6210\u8d28\u91cf\uff0c\u73b0\u6709\u5b9e\u73b0\u4f1a\u5bfc\u81f4\u4e0d\u5e73\u8861\u8fc7\u6e21\uff0c\u65b0\u673a\u5236\u901a\u8fc7\u5e73\u6ed1\u5206\u5e03\u95f4\u7684\u4f20\u8f93\u63d0\u9ad8\u6837\u672c\u8d28\u91cf\uff0c\u4e14\u53ea\u9700\u4e00\u884c\u4ee3\u7801\u66f4\u6539\u3002", "conclusion": "\u65b0\u7684\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u673a\u5236\u80fd\u6709\u6548\u63d0\u9ad8\u79bb\u6563\u6269\u6563\u7684\u6837\u672c\u8d28\u91cf\uff0c\u4e14\u6613\u4e8e\u5b9e\u73b0\u3002"}}
{"id": "2507.09989", "pdf": "https://arxiv.org/pdf/2507.09989", "abs": "https://arxiv.org/abs/2507.09989", "authors": ["Xiaoyang Yu", "Youfang Lin", "Shuo Wang", "Sheng Han"], "title": "Improving monotonic optimization in heterogeneous multi-agent reinforcement learning with optimal marginal deterministic policy gradient", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "In heterogeneous multi-agent reinforcement learning (MARL), achieving\nmonotonic improvement plays a pivotal role in enhancing performance. The HAPPO\nalgorithm proposes a feasible solution by introducing a sequential update\nscheme, which requires independent learning with No Parameter-sharing (NoPS).\nHowever, heterogeneous MARL generally requires Partial Parameter-sharing\n(ParPS) based on agent grouping to achieve high cooperative performance. Our\nexperiments prove that directly combining ParPS with the sequential update\nscheme leads to the policy updating baseline drift problem, thereby failing to\nachieve improvement. To solve the conflict between monotonic improvement and\nParPS, we propose the Optimal Marginal Deterministic Policy Gradient (OMDPG)\nalgorithm. First, we replace the sequentially computed $Q_{\\psi}^s(s,a_{1:i})$\nwith the Optimal Marginal Q (OMQ) function $\\phi_{\\psi}^*(s,a_{1:i})$ derived\nfrom Q-functions. This maintains MAAD's monotonic improvement while eliminating\nthe conflict through optimal joint action sequences instead of sequential\npolicy ratio calculations. Second, we introduce the Generalized Q Critic (GQC)\nas the critic function, employing pessimistic uncertainty-constrained loss to\noptimize different Q-value estimations. This provides the required Q-values for\nOMQ computation and stable baselines for actor updates. Finally, we implement a\nCentralized Critic Grouped Actor (CCGA) architecture that simultaneously\nachieves ParPS in local policy networks and accurate global Q-function\ncomputation. Experimental results in SMAC and MAMuJoCo environments demonstrate\nthat OMDPG outperforms various state-of-the-art MARL baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOMDPG\u7b97\u6cd5\u89e3\u51b3\u5f02\u6784\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5355\u8c03\u6539\u8fdb\u4e0e\u90e8\u5206\u53c2\u6570\u5171\u4eab\u7684\u51b2\u7a81\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u591a\u79cd\u57fa\u51c6\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709HAPPO\u7b97\u6cd5\u5728\u5f02\u6784\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u91c7\u7528\u65e0\u53c2\u6570\u5171\u4eab\u7684\u987a\u5e8f\u66f4\u65b0\u65b9\u6848\uff0c\u800c\u5b9e\u9645\u9700\u8981\u90e8\u5206\u53c2\u6570\u5171\u4eab\u4ee5\u5b9e\u73b0\u9ad8\u534f\u4f5c\u6027\u80fd\uff0c\u4f46\u76f4\u63a5\u7ed3\u5408\u4f1a\u5bfc\u81f4\u7b56\u7565\u66f4\u65b0\u57fa\u7ebf\u6f02\u79fb\u95ee\u9898\uff0c\u65e0\u6cd5\u5b9e\u73b0\u6539\u8fdb\uff0c\u56e0\u6b64\u9700\u89e3\u51b3\u5355\u8c03\u6539\u8fdb\u4e0e\u90e8\u5206\u53c2\u6570\u5171\u4eab\u7684\u51b2\u7a81\u3002", "method": "\u63d0\u51faOMDPG\u7b97\u6cd5\uff0c\u7528\u6700\u4f18\u8fb9\u9645Q\u51fd\u6570\u66ff\u4ee3\u987a\u5e8f\u8ba1\u7b97\u7684Q\u51fd\u6570\uff0c\u5f15\u5165\u5e7f\u4e49Q\u8bc4\u5224\u5668\u4f5c\u4e3a\u8bc4\u5224\u51fd\u6570\uff0c\u91c7\u7528\u60b2\u89c2\u4e0d\u786e\u5b9a\u6027\u7ea6\u675f\u635f\u5931\u4f18\u5316Q\u503c\u4f30\u8ba1\uff0c\u5b9e\u73b0\u96c6\u4e2d\u5f0f\u8bc4\u5224\u5668\u5206\u7ec4\u667a\u80fd\u4f53\u67b6\u6784\u3002", "result": "\u5728SMAC\u548cMAMuJoCo\u73af\u5883\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOMDPG\u7b97\u6cd5\u4f18\u4e8e\u591a\u79cd\u6700\u5148\u8fdb\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u7b97\u6cd5\u3002", "conclusion": "OMDPG\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6784\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5355\u8c03\u6539\u8fdb\u4e0e\u90e8\u5206\u53c2\u6570\u5171\u4eab\u7684\u51b2\u7a81\uff0c\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09866", "pdf": "https://arxiv.org/pdf/2507.09866", "abs": "https://arxiv.org/abs/2507.09866", "authors": ["Wei Zhang", "Jian Yang", "Jiaxi Yang", "Ya Wang", "Zhoujun Li", "Zeyu Cui", "Binyuan Hui", "Junyang Lin"], "title": "Turning the Tide: Repository-based Code Reflection", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Code large language models (LLMs) enhance programming by understanding and\ngenerating code across languages, offering intelligent feedback, bug detection,\nand code updates through reflection, improving development efficiency and\naccessibility. While benchmarks (e.g. HumanEval/LiveCodeBench) evaluate code\ngeneration and real-world relevance, previous works ignore the scenario of\nmodifying code in repositories. Considering challenges remaining in improving\nreflection capabilities and avoiding data contamination in dynamic benchmarks,\nwe introduce LiveRepoReflection, a challenging benchmark for evaluating code\nunderstanding and generation in multi-file repository contexts, featuring 1,888\nrigorously filtered test cases across $6$ programming languages to ensure\ndiversity, correctness, and high difficulty. Further, we create\nRepoReflection-Instruct, a large-scale, quality-filtered instruction-tuning\ndataset derived from diverse sources, used to train RepoReflectionCoder through\na two-turn dialogue process involving code generation and error-driven repair.\nThe leaderboard evaluates over 40 LLMs to reflect the model performance of\nrepository-based code reflection.", "AI": {"tldr": "\u5f15\u5165LiveRepoReflection\u57fa\u51c6\u548cRepoReflection - Instruct\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4ee3\u7801\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u8bad\u7ec3RepoReflectionCoder\u5e76\u5bf9\u8d8540\u4e2a\u5927\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5ffd\u7565\u4ee3\u7801\u5e93\u4ee3\u7801\u4fee\u6539\u573a\u666f\uff0c\u4e14\u5728\u63d0\u5347\u53cd\u601d\u80fd\u529b\u548c\u907f\u514d\u52a8\u6001\u57fa\u51c6\u6570\u636e\u6c61\u67d3\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u5f15\u5165LiveRepoReflection\u57fa\u51c6\uff0c\u521b\u5efaRepoReflection - Instruct\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5bf9\u8bdd\u6d41\u7a0b\u8bad\u7ec3RepoReflectionCoder\uff0c\u4f7f\u7528\u6392\u884c\u699c\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u521b\u5efa\u4e86\u5177\u67091888\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u7684\u57fa\u51c6\u548c\u5927\u89c4\u6a21\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\uff0c\u5bf9\u8d8540\u4e2a\u5927\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u51c6\u548c\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u8bc4\u4f30\u4ee3\u7801\u5e93\u4ee3\u7801\u53cd\u601d\u80fd\u529b\u3002"}}
{"id": "2507.08977", "pdf": "https://arxiv.org/pdf/2507.08977", "abs": "https://arxiv.org/abs/2507.08977", "authors": ["Carson Dudley", "Reiden Magdaleno", "Christopher Harding", "Marisa Eisenberg"], "title": "Simulation as Supervision: Mechanistic Pretraining for Scientific Discovery", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Scientific modeling faces a core limitation: mechanistic models offer\ninterpretability but collapse under real-world complexity, while machine\nlearning models are flexible but require large labeled datasets, cannot infer\nunobservable quantities, and operate as black boxes. We introduce\nSimulation-Grounded Neural Networks (SGNNs), a general framework that uses\nmechanistic simulations as training data for neural networks. SGNNs are\npretrained on synthetic corpora spanning diverse model structures, parameter\nregimes, stochasticity, and observational artifacts. We evaluated SGNNs across\nscientific disciplines and modeling tasks, and found that SGNNs achieved\nstate-of-the-art results across settings: for prediction tasks, they nearly\ntripled COVID-19 forecasting skill versus CDC baselines, reduced chemical yield\nprediction error by one third, and maintained accuracy in ecological\nforecasting where task specific models failed. For inference tasks, SGNNs also\naccurately classified the source of information spread in simulated social\nnetworks and enabled supervised learning for unobservable targets, such as\nestimating COVID-19 transmissibility more accurately than traditional methods\neven in early outbreaks. Finally, SGNNs enable back-to-simulation attribution,\na new form of mechanistic interpretability. Given real world input, SGNNs\nretrieve simulations based on what the model has learned to see as most\nsimilar, revealing which underlying dynamics the model believes are active.\nThis provides process-level insight -- what the model thinks is happening --\nnot just which features mattered. SGNNs unify scientific theory with deep\nlearning flexibility and unlock a new modeling paradigm -- transforming\nsimulations from rigid, post hoc tools into flexible sources of supervision,\nenabling robust, interpretable inference even when ground truth is missing.", "AI": {"tldr": "\u4ecb\u7ecdSimulation - Grounded Neural Networks (SGNNs)\u6846\u67b6\uff0c\u7ed3\u5408\u673a\u7406\u6a21\u62df\u4e0e\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u591a\u5b66\u79d1\u548c\u4efb\u52a1\u4e2d\u53d6\u5f97SOTA\u6210\u679c\uff0c\u5177\u5907\u65b0\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u7edf\u4e00\u79d1\u5b66\u7406\u8bba\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7075\u6d3b\u6027\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u5efa\u6a21\u4e2d\u673a\u7406\u6a21\u578b\u5728\u73b0\u5b9e\u590d\u6742\u573a\u666f\u6613\u5931\u6548\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3001\u65e0\u6cd5\u63a8\u65ad\u4e0d\u53ef\u89c2\u6d4b\u53d8\u91cf\u4e14\u4e3a\u9ed1\u7bb1\u7684\u95ee\u9898\u3002", "method": "\u4ee5\u673a\u7406\u6a21\u62df\u6570\u636e\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u6db5\u76d6\u591a\u6837\u6a21\u578b\u7ed3\u6784\u3001\u53c2\u6570\u4f53\u7cfb\u3001\u968f\u673a\u6027\u548c\u89c2\u6d4b\u4f2a\u50cf\u7684\u5408\u6210\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u5982\u65b0\u51a0\u9884\u6d4b\u3001\u5316\u5b66\u4ea7\u7387\u9884\u6d4b\u3001\u751f\u6001\u9884\u6d4b\u8868\u73b0\u4f18\u5f02\uff1b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u80fd\u51c6\u786e\u5206\u7c7b\u4fe1\u606f\u4f20\u64ad\u6e90\u548c\u5bf9\u4e0d\u53ef\u89c2\u6d4b\u76ee\u6807\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\uff1b\u5177\u5907\u65b0\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "SGNNs\u7edf\u4e00\u79d1\u5b66\u7406\u8bba\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7075\u6d3b\u6027\uff0c\u5c06\u6a21\u62df\u4ece\u50f5\u5316\u7684\u4e8b\u540e\u5de5\u5177\u8f6c\u53d8\u4e3a\u7075\u6d3b\u7684\u76d1\u7763\u6e90\uff0c\u5373\u4f7f\u7f3a\u5c11\u771f\u5b9e\u6807\u7b7e\u4e5f\u80fd\u8fdb\u884c\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u3002"}}
{"id": "2507.10000", "pdf": "https://arxiv.org/pdf/2507.10000", "abs": "https://arxiv.org/abs/2507.10000", "authors": ["Mark Burgess"], "title": "On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model", "categories": ["cs.AI", "cs.CL", "I.2.11; F.4.1; I.2.4; G.2.2"], "comment": null, "summary": "Since Searle's work deconstructing intent and intentionality in the realm of\nphilosophy, the practical meaning of intent has received little attention in\nscience and technology. Intentionality and context are both central to the\nscope of Promise Theory's model of Semantic Spacetime, used as an effective\nTiny Language Model. One can identify themes and concepts from a text, on a low\nlevel (without knowledge of the specific language) by using process coherence\nas a guide. Any agent process can assess superficially a degree of latent\n`intentionality' in data by looking for anomalous multi-scale anomalies and\nassessing the work done to form them. Scale separation can be used to sort\nparts into `intended' content and `ambient context', using the spacetime\ncoherence as a measure. This offers an elementary but pragmatic interpretation\nof latent intentionality for very low computational cost, and without reference\nto extensive training or reasoning capabilities. The process is well within the\nreach of basic organisms as it does not require large scale artificial\nprobabilistic batch processing. The level of concept formation depends,\nhowever, on the memory capacity of the agent.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u7528\u8fc7\u7a0b\u8fde\u8d2f\u6027\u548c\u5c3a\u5ea6\u5206\u79bb\u8bc6\u522b\u6587\u672c\u6f5c\u5728\u610f\u56fe\uff0c\u6210\u672c\u4f4e\u4e14\u4e0d\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u3002", "motivation": "\u81eaSearle\u89e3\u6784\u610f\u56fe\u540e\uff0c\u79d1\u6280\u9886\u57df\u5bf9\u610f\u56fe\u5b9e\u9645\u610f\u4e49\u5173\u6ce8\u5c11\uff0c\u9700\u65b0\u65b9\u6cd5\u8bc6\u522b\u610f\u56fe\u3002", "method": "\u4ee5\u8fc7\u7a0b\u8fde\u8d2f\u6027\u4e3a\u6307\u5bfc\u8bc6\u522b\u6587\u672c\u4e3b\u9898\u6982\u5ff5\uff0c\u7528\u5c3a\u5ea6\u5206\u79bb\u533a\u5206\u610f\u56fe\u5185\u5bb9\u548c\u73af\u5883\u80cc\u666f\uff0c\u4ee5\u65f6\u7a7a\u8fde\u8d2f\u6027\u4e3a\u8861\u91cf\u6807\u51c6\u3002", "result": "\u80fd\u4ee5\u4f4e\u8ba1\u7b97\u6210\u672c\u5bf9\u6f5c\u5728\u610f\u56fe\u8fdb\u884c\u521d\u6b65\u5b9e\u7528\u89e3\u8bfb\uff0c\u57fa\u672c\u751f\u7269\u4e5f\u53ef\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u8fc7\u7a0b\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u4e0d\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\uff0c\u4f46\u6982\u5ff5\u5f62\u6210\u6c34\u5e73\u53d6\u51b3\u4e8e\u4e3b\u4f53\u8bb0\u5fc6\u80fd\u529b\u3002"}}
{"id": "2507.09892", "pdf": "https://arxiv.org/pdf/2507.09892", "abs": "https://arxiv.org/abs/2507.09892", "authors": ["Zimu Chen", "Di Wang"], "title": "PathFuzzing: Worst Case Analysis by Fuzzing Symbolic-Execution Paths", "categories": ["cs.SE", "D.2.5"], "comment": "10 pages, 1 figure", "summary": "Estimating worst-case resource consumption is a critical task in software\ndevelopment. The worst-case analysis (WCA) problem is an optimization-based\nabstraction of this task. Fuzzing and symbolic execution are widely used\ntechniques for addressing the WCA problem. However, improving code coverage in\nfuzzing or managing path explosion in symbolic execution within the context of\nWCA poses significant challenges. In this paper, we propose PathFuzzing, aiming\nto combine the strengths of both techniques to design a WCA method. The key\nidea is to transform a program into a symbolic one that takes an execution path\n(encoded as a binary string) and interprets the bits as branch decisions.\nPathFuzzing then applies evolutionary fuzzing techniques to the transformed\nprogram to search for binary strings that represent satisfiable path conditions\nand lead to high resource consumption. We evaluate the performance of\nPathFuzzing experimentally on a benchmark suite that consists of prior work's\nbenchmarks and some added by us. Results show that PathFuzzing generally\noutperforms a fuzzing and a symbolic-execution baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPathFuzzing\u65b9\u6cd5\u7ed3\u5408\u6a21\u7cca\u6d4b\u8bd5\u548c\u7b26\u53f7\u6267\u884c\u6280\u672f\u89e3\u51b3\u6700\u574f\u60c5\u51b5\u5206\u6790\uff08WCA\uff09\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5728WCA\u4e2d\uff0c\u63d0\u5347\u6a21\u7cca\u6d4b\u8bd5\u7684\u4ee3\u7801\u8986\u76d6\u7387\u548c\u5904\u7406\u7b26\u53f7\u6267\u884c\u7684\u8def\u5f84\u7206\u70b8\u95ee\u9898\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u79cd\u6280\u672f\u4f18\u52bf\u8bbe\u8ba1WCA\u65b9\u6cd5\u3002", "method": "\u5c06\u7a0b\u5e8f\u8f6c\u6362\u4e3a\u63a5\u53d7\u6267\u884c\u8def\u5f84\uff08\u7f16\u7801\u4e3a\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\uff09\u7684\u7b26\u53f7\u7a0b\u5e8f\uff0c\u4f7f\u7528\u8fdb\u5316\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\u641c\u7d22\u4ee3\u8868\u53ef\u6ee1\u8db3\u8def\u5f84\u6761\u4ef6\u5e76\u5bfc\u81f4\u9ad8\u8d44\u6e90\u6d88\u8017\u7684\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cPathFuzzing\u901a\u5e38\u4f18\u4e8e\u6a21\u7cca\u6d4b\u8bd5\u548c\u7b26\u53f7\u6267\u884c\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PathFuzzing\u662f\u4e00\u79cd\u6709\u6548\u7684\u7ed3\u5408\u6a21\u7cca\u6d4b\u8bd5\u548c\u7b26\u53f7\u6267\u884c\u4f18\u52bf\u7684WCA\u65b9\u6cd5\u3002"}}
{"id": "2507.08959", "pdf": "https://arxiv.org/pdf/2507.08959", "abs": "https://arxiv.org/abs/2507.08959", "authors": ["Xiang Li", "Xinyu Wang", "Yifan Lin"], "title": "Graph Neural Network Enhanced Sequential Recommendation Method for Cross-Platform Ad Campaign", "categories": ["cs.LG"], "comment": null, "summary": "In order to improve the accuracy of cross-platform advertisement\nrecommendation, a graph neural network (GNN)- based advertisement\nrecommendation method is analyzed. Through multi-dimensional modeling, user\nbehavior data (e.g., click frequency, active duration) reveal temporal patterns\nof interest evolution, ad content (e.g., type, tag, duration) influences\nsemantic preferences, and platform features (e.g., device type, usage context)\nshape the environment where interest transitions occur. These factors jointly\nenable the GNN to capture the latent pathways of user interest migration across\nplatforms. The experimental results are based on the datasets of three\nplatforms, and Platform B reaches 0.937 in AUC value, which is the best\nperformance. Platform A and Platform C showed a slight decrease in precision\nand recall with uneven distribution of ad labels. By adjusting the\nhyperparameters such as learning rate, batch size and embedding dimension, the\nadaptability and robustness of the model in heterogeneous data are further\nimproved.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8de8\u5e73\u53f0\u5e7f\u544a\u63a8\u8350\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5e73\u53f0B\u8868\u73b0\u6700\u4f73\uff0c\u8c03\u6574\u8d85\u53c2\u6570\u53ef\u63d0\u5347\u6a21\u578b\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u63d0\u9ad8\u8de8\u5e73\u53f0\u5e7f\u544a\u63a8\u8350\u7684\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u591a\u7ef4\u5ea6\u5efa\u6a21\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u7528\u6237\u8de8\u5e73\u53f0\u5174\u8da3\u8fc1\u79fb\u7684\u6f5c\u5728\u8def\u5f84\u3002", "result": "\u57fa\u4e8e\u4e09\u4e2a\u5e73\u53f0\u6570\u636e\u96c6\u5b9e\u9a8c\uff0c\u5e73\u53f0B\u7684AUC\u503c\u8fbe0.937\uff0c\u8868\u73b0\u6700\u4f73\uff1b\u5e73\u53f0A\u548cC\u56e0\u5e7f\u544a\u6807\u7b7e\u5206\u5e03\u4e0d\u5747\uff0c\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7565\u6709\u4e0b\u964d\u3002", "conclusion": "\u8c03\u6574\u5b66\u4e60\u7387\u3001\u6279\u91cf\u5927\u5c0f\u548c\u5d4c\u5165\u7ef4\u5ea6\u7b49\u8d85\u53c2\u6570\uff0c\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u5728\u5f02\u6784\u6570\u636e\u4e2d\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.09043", "pdf": "https://arxiv.org/pdf/2507.09043", "abs": "https://arxiv.org/abs/2507.09043", "authors": ["Jingxiang Qu", "Wenhan Gao", "Yi Liu"], "title": "Shortening the Trajectories: Identity-Aware Gaussian Approximation for Efficient 3D Molecular Generation", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Gaussian-based Probabilistic Generative Models (GPGMs) generate data by\nreversing a stochastic process that progressively corrupts samples with\nGaussian noise. While these models have achieved state-of-the-art performance\nacross diverse domains, their practical deployment remains constrained by the\nhigh computational cost of long generative trajectories, which often involve\nhundreds to thousands of steps during training and sampling. In this work, we\nintroduce a theoretically grounded and empirically validated framework that\nimproves generation efficiency without sacrificing training granularity or\ninference fidelity. Our key insight is that for certain data modalities, the\nnoising process causes data to rapidly lose its identity and converge toward a\nGaussian distribution. We analytically identify a characteristic step at which\nthe data has acquired sufficient Gaussianity, and then replace the remaining\ngeneration trajectory with a closed-form Gaussian approximation. Unlike\nexisting acceleration techniques that coarsening the trajectories by skipping\nsteps, our method preserves the full resolution of learning dynamics while\navoiding redundant stochastic perturbations between `Gaussian-like'\ndistributions. Empirical results across multiple data modalities demonstrate\nsubstantial improvements in both sample quality and computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u63d0\u5347Gaussian-based Probabilistic Generative Models\u751f\u6210\u6548\u7387\uff0c\u4e0d\u727a\u7272\u8bad\u7ec3\u7c92\u5ea6\u548c\u63a8\u7406\u4fdd\u771f\u5ea6\uff0c\u591a\u6a21\u6001\u6570\u636e\u5b9e\u8bc1\u6548\u679c\u597d\u3002", "motivation": "GPGMs\u56e0\u957f\u751f\u6210\u8f68\u8ff9\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5b9e\u9645\u90e8\u7f72\u53d7\u9650\uff0c\u9700\u63d0\u5347\u751f\u6210\u6548\u7387\u3002", "method": "\u5206\u6790\u786e\u5b9a\u6570\u636e\u83b7\u5f97\u8db3\u591f\u9ad8\u65af\u6027\u7684\u7279\u5f81\u6b65\u9aa4\uff0c\u7528\u95ed\u5f0f\u9ad8\u65af\u8fd1\u4f3c\u66ff\u6362\u5269\u4f59\u751f\u6210\u8f68\u8ff9\uff0c\u907f\u514d\u5197\u4f59\u968f\u673a\u6270\u52a8\u3002", "result": "\u591a\u6a21\u6001\u6570\u636e\u5b9e\u8bc1\u663e\u793a\u6837\u672c\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u5728\u4e0d\u727a\u7272\u8bad\u7ec3\u7c92\u5ea6\u548c\u63a8\u7406\u4fdd\u771f\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u63d0\u5347GPGMs\u7684\u751f\u6210\u6548\u7387\u3002"}}
{"id": "2507.10007", "pdf": "https://arxiv.org/pdf/2507.10007", "abs": "https://arxiv.org/abs/2507.10007", "authors": ["Zijun Chen", "Wenbo Hu", "Richang Hong"], "title": "Deep Hidden Cognition Facilitates Reliable Chain-of-Thought Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Chain of Thought (CoT) reasoning has demonstrated remarkable deep reasoning\ncapabilities in both large language models (LLMs) and multimodal large language\nmodels (MLLMs). However, its reliability is often undermined by the\naccumulation of errors in intermediate steps. This paper introduces an novel\napproach to calibrate the CoT reasoning accuracy by leveraging the model's\nintrinsic veracity encoding. We discover that specific attention head\nactivations reliably reflect the truthfulness of reasoning steps in CoT. Based\non this insight, we train a confidence predictor to evaluate the correctness of\neach reasoning step using these truthfulness-sensitive activations, dynamically\nselecting the most plausible reasoning path via beam search. Experimental\nresults demonstrate that our method significantly outperforms the\nstate-of-the-art baselines (e.g., Few-Shot CoT, Self-Consistency, and\nSelf-Evaluation Guided Beam Search) across the mathematical, symbolic, and\ncommonsense reasoning tasks, exhibiting superior accuracy and reliability in\nboth unimodal and multimodal settings. We further validate the approach on\nlarge reasoning models, confirming its applicability to specialized reasoning\nmodels. Additionally, we explore the role of the model's self-correction\nability in CoT reasoning. This work provides a novel reliability improvement\npath for CoT reasoning with broad application potential.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u6a21\u578b\u5185\u5728\u771f\u5b9e\u6027\u7f16\u7801\u6821\u51c6\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u51c6\u786e\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8fd8\u63a2\u7d22\u4e86\u6a21\u578b\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u3002", "motivation": "CoT\u63a8\u7406\u867d\u5f3a\u5927\uff0c\u4f46\u4e2d\u95f4\u6b65\u9aa4\u8bef\u5dee\u79ef\u7d2f\u4f1a\u524a\u5f31\u5176\u53ef\u9760\u6027\u3002", "method": "\u53d1\u73b0\u7279\u5b9a\u6ce8\u610f\u529b\u5934\u6fc0\u6d3b\u80fd\u53cd\u6620\u63a8\u7406\u6b65\u9aa4\u771f\u5b9e\u6027\uff0c\u8bad\u7ec3\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u5668\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\u6b63\u786e\u6027\uff0c\u901a\u8fc7\u675f\u641c\u7d22\u52a8\u6001\u9009\u62e9\u6700\u5408\u7406\u63a8\u7406\u8def\u5f84\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6570\u5b66\u3001\u7b26\u53f7\u548c\u5e38\u8bc6\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u8bbe\u7f6e\u4e2d\u90fd\u5c55\u73b0\u51fa\u66f4\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e14\u9002\u7528\u4e8e\u5927\u578b\u63a8\u7406\u6a21\u578b\u3002", "conclusion": "\u6b64\u5de5\u4f5c\u4e3aCoT\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u9760\u6027\u63d0\u5347\u9014\u5f84\uff0c\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.09907", "pdf": "https://arxiv.org/pdf/2507.09907", "abs": "https://arxiv.org/abs/2507.09907", "authors": ["Thomas Hansper", "Kevin Phong Pham", "Michael Neumann"], "title": "Modelling Interrelations Between Agile Practices: The Agile Map", "categories": ["cs.SE"], "comment": null, "summary": "Agile methods are defined through guidelines comprising various practices\nintended to enable agile ways of working. These guidelines further comprise a\nspecific set of agile practices aiming to enable teams for an agile way of\nworking. However, due to its wide-spread use in practice we know that agile\npractices are adopted and tailored intensively, which lead to a high variety of\nagile practices in terms of their level of detail. Problem: A high variety of\nagile practices can be challenging as we do not know how different agile\npractices are interrelated with each other. To be more precise, tailoring and\nadopting agile practices may lead to the challenge, that the combinatorial use\nof several agile practices can only be successful to a limited extent, as\npractices support or even require each other for a effective use in practice.\nObjective: Our study aims to provide an enabler for this problem. We want to\nidentify interrelations between agile practices and describe them in a\nsystematic manner. Contribution: The core contribution of this paper is the\nAgile Map, a theoretical model describing relations between agile practices\nfollowing a systematic approach aiming to provide an overview of coherences\nbetween agile practices. The model aims to support practitioners in selecting\nand combining agile practices in a meaningful way.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u654f\u6377\u5b9e\u8df5\u4f7f\u7528\u591a\u6837\uff0c\u76f8\u4e92\u5173\u7cfb\u4e0d\u660e\uff0c\u63d0\u51fa\u654f\u6377\u5730\u56fe\u6a21\u578b\u63cf\u8ff0\u5176\u5173\u7cfb\u3002", "motivation": "\u7531\u4e8e\u654f\u6377\u5b9e\u8df5\u4f7f\u7528\u5e7f\u6cdb\u4e14\u591a\u6837\uff0c\u4e0d\u6e05\u695a\u4e0d\u540c\u5b9e\u8df5\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\uff0c\u7ec4\u5408\u4f7f\u7528\u5b58\u5728\u6311\u6218\uff0c\u9700\u627e\u51fa\u5173\u7cfb\u5e76\u7cfb\u7edf\u63cf\u8ff0\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6a21\u578b\u654f\u6377\u5730\u56fe\uff0c\u7528\u7cfb\u7edf\u65b9\u6cd5\u63cf\u8ff0\u654f\u6377\u5b9e\u8df5\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u5f97\u5230\u654f\u6377\u5730\u56fe\u6a21\u578b\uff0c\u53ef\u63cf\u8ff0\u654f\u6377\u5b9e\u8df5\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "\u654f\u6377\u5730\u56fe\u6a21\u578b\u80fd\u4e3a\u4ece\u4e1a\u8005\u6709\u610f\u4e49\u5730\u9009\u62e9\u548c\u7ec4\u5408\u654f\u6377\u5b9e\u8df5\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2507.09061", "pdf": "https://arxiv.org/pdf/2507.09061", "abs": "https://arxiv.org/abs/2507.09061", "authors": ["Thomas T. Zhang", "Daniel Pfrommer", "Nikolai Matni", "Max Simchowitz"], "title": "Imitation Learning in Continuous Action Spaces: Mitigating Compounding Error without Interaction", "categories": ["cs.LG", "cs.SY", "eess.SY", "stat.ML"], "comment": null, "summary": "We study the problem of imitating an expert demonstrator in a continuous\nstate-and-action dynamical system. While imitation learning in discrete\nsettings such as autoregressive language modeling has seen immense success and\npopularity in recent years, imitation in physical settings such as autonomous\ndriving and robot learning has proven comparably more complex due to the\ncompounding errors problem, often requiring elaborate set-ups to perform\nstably. Recent work has demonstrated that even in benign settings, exponential\ncompounding errors are unavoidable when learning solely from expert-controlled\ntrajectories, suggesting the need for more advanced policy parameterizations or\ndata augmentation. To this end, we present minimal interventions that provably\nmitigate compounding errors in continuous state-and-action imitation learning.\nWhen the system is open-loop stable, we prescribe \"action chunking,\" i.e.,\npredicting and playing sequences of actions in open-loop; when the system is\npossibly unstable, we prescribe \"noise injection,\" i.e., adding noise during\nexpert demonstrations. These interventions align with popular choices in modern\nrobot learning, though the benefits we derive are distinct from the effects\nthey were designed to target. Our results draw insights and tools from both\ncontrol theory and reinforcement learning; however, our analysis reveals novel\nconsiderations that do not naturally arise when either literature is considered\nin isolation.", "AI": {"tldr": "\u7814\u7a76\u8fde\u7eed\u72b6\u6001\u4e0e\u52a8\u4f5c\u52a8\u529b\u7cfb\u7edf\u4e2d\u6a21\u4eff\u4e13\u5bb6\u793a\u8303\u95ee\u9898\uff0c\u63d0\u51fa\u6700\u5c0f\u5e72\u9884\u63aa\u65bd\u51cf\u8f7b\u590d\u5408\u8bef\u5dee\u3002", "motivation": "\u79bb\u6563\u73af\u5883\u6a21\u4eff\u5b66\u4e60\u6210\u529f\uff0c\u7269\u7406\u73af\u5883\u56e0\u590d\u5408\u8bef\u5dee\u95ee\u9898\u66f4\u590d\u6742\uff0c\u4ec5\u4ece\u4e13\u5bb6\u8f68\u8ff9\u5b66\u4e60\u4e0d\u53ef\u907f\u514d\u6307\u6570\u590d\u5408\u8bef\u5dee\uff0c\u9700\u66f4\u5148\u8fdb\u7b56\u7565\u53c2\u6570\u5316\u6216\u6570\u636e\u589e\u5f3a\u3002", "method": "\u7cfb\u7edf\u5f00\u73af\u7a33\u5b9a\u65f6\u7528\u201c\u52a8\u4f5c\u5206\u5757\u201d\uff0c\u53ef\u80fd\u4e0d\u7a33\u5b9a\u65f6\u7528\u201c\u566a\u58f0\u6ce8\u5165\u201d\u3002", "result": "\u6240\u63d0\u5e72\u9884\u63aa\u65bd\u4e0e\u73b0\u4ee3\u673a\u5668\u4eba\u5b66\u4e60\u6d41\u884c\u9009\u62e9\u76f8\u7b26\uff0c\u4f46\u76ca\u5904\u4e0d\u540c\uff0c\u5206\u6790\u501f\u9274\u63a7\u5236\u7406\u8bba\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u65b0\u53d1\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u6700\u5c0f\u5e72\u9884\u63aa\u65bd\u53ef\u51cf\u8f7b\u8fde\u7eed\u72b6\u6001\u4e0e\u52a8\u4f5c\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u590d\u5408\u8bef\u5dee\u3002"}}
{"id": "2507.10045", "pdf": "https://arxiv.org/pdf/2507.10045", "abs": "https://arxiv.org/abs/2507.10045", "authors": ["Malte Christian Bartels", "Debayan Banerjee", "Ricardo Usbeck"], "title": "Automating SPARQL Query Translations between DBpedia and Wikidata", "categories": ["cs.AI", "cs.CL"], "comment": "18 pages, 2 figues. Paper accepted at SEMANTiCS 2025 conference\n  happening on September 2025", "summary": "This paper investigates whether state-of-the-art Large Language Models (LLMs)\ncan automatically translate SPARQL between popular Knowledge Graph (KG)\nschemas. We focus on translations between the DBpedia and Wikidata KG, and\nlater on DBLP and OpenAlex KG. This study addresses a notable gap in KG\ninteroperability research by rigorously evaluating LLM performance on\nSPARQL-to-SPARQL translation. Two benchmarks are assembled, where the first\nalign 100 DBpedia-Wikidata queries from QALD-9-Plus; the second contains 100\nDBLP queries aligned to OpenAlex, testing generalizability beyond encyclopaedic\nKGs. Three open LLMs: Llama-3-8B, DeepSeek-R1-Distill-Llama-70B, and\nMistral-Large-Instruct-2407 are selected based on their sizes and architectures\nand tested with zero-shot, few-shot, and two chain-of-thought variants. Outputs\nwere compared with gold answers, and resulting errors were categorized. We find\nthat the performance varies markedly across models and prompting strategies,\nand that translations for Wikidata to DBpedia work far better than translations\nfor DBpedia to Wikidata.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u81ea\u52a8\u5728\u6d41\u884c\u77e5\u8bc6\u56fe\u8c31\u6a21\u5f0f\u95f4\u7ffb\u8bd1SPARQL\uff0c\u6784\u5efa\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6d4b\u8bd5\u4e09\u4e2a\u5f00\u6e90\u5927\u6a21\u578b\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u548c\u7b56\u7565\u8868\u73b0\u5dee\u5f02\u5927\uff0cWikidata\u5230DBpedia\u7684\u7ffb\u8bd1\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u4e92\u64cd\u4f5c\u6027\u7814\u7a76\u4e2d\u5173\u4e8eSPARQL\u5230SPARQL\u7ffb\u8bd1\u8bc4\u4f30\u7684\u7f3a\u53e3\u3002", "method": "\u6784\u5efa\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9009\u53d6\u4e09\u4e2a\u5f00\u6e90\u5927\u6a21\u578b\uff0c\u7528\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u4e24\u79cd\u601d\u7ef4\u94fe\u53d8\u4f53\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5c06\u8f93\u51fa\u4e0e\u6807\u51c6\u7b54\u6848\u5bf9\u6bd4\u5e76\u5bf9\u9519\u8bef\u5206\u7c7b\u3002", "result": "\u4e0d\u540c\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u7684\u8868\u73b0\u5dee\u5f02\u660e\u663e\uff0cWikidata\u5230DBpedia\u7684\u7ffb\u8bd1\u6548\u679c\u8fdc\u597d\u4e8eDBpedia\u5230Wikidata\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u4ece\u7ed3\u679c\u53ef\u63a8\u6d4b\u4e0d\u540c\u5927\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\u5bf9SPARQL\u7ffb\u8bd1\u6709\u663e\u8457\u5f71\u54cd\u3002"}}
{"id": "2507.09911", "pdf": "https://arxiv.org/pdf/2507.09911", "abs": "https://arxiv.org/abs/2507.09911", "authors": ["Marvin Auf der Landwehr", "Julia Topp", "Michael Neumann"], "title": "When Less is More: A systematic review of four-day workweek conceptualizations and their effects on organizational performance", "categories": ["cs.SE"], "comment": null, "summary": "Context: Agile IT organizations, which are characterized by self-organization\nand collaborative social interactions, require motivating, efficient and\nflexible work environments to maximize value creation. Compressed work\nschedules such as the four-day workweek have evolved into multiple facets over\nthe last decades and are associated with various benefits for organizations and\ntheir employees. Objective: Our objective in this study is to deepen our\ncomprehension of the impact of compressed work schedules on the operational\nefficacy of IT enterprises, while concurrently developing a comprehensive\nframework delineating the intricacies of compressed work schedules.Method: We\nconducted a systematic review of available conceptualizations related to\nfour-day workweek schedules and elaborate on their organizational and social\neffects. To cover scientific and practice-oriented literature, our review\ncombined a systematic literature review and a web content analysis. Results:\nBased on the generated insights, we derive a meta-framework that matches\nconceptualizations and effects, finally guiding the adoption of compressed work\nschedules based on individual managerial prerequisites and circumstances.", "AI": {"tldr": "\u7814\u7a76\u538b\u7f29\u5de5\u4f5c\u65f6\u95f4\u8868\u5bf9IT\u4f01\u4e1a\u8fd0\u8425\u6548\u80fd\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7cfb\u7edf\u56de\u987e\u548c\u7f51\u7edc\u5185\u5bb9\u5206\u6790\u5f97\u51fa\u5339\u914d\u6982\u5ff5\u4e0e\u6548\u679c\u7684\u5143\u6846\u67b6\u3002", "motivation": "\u654f\u6377IT\u7ec4\u7ec7\u9700\u9ad8\u6548\u7075\u6d3b\u5de5\u4f5c\u73af\u5883\uff0c\u538b\u7f29\u5de5\u4f5c\u65f6\u95f4\u8868\u6709\u8bf8\u591a\u76ca\u5904\uff0c\u7814\u7a76\u5176\u5bf9IT\u4f01\u4e1a\u8fd0\u8425\u6548\u80fd\u7684\u5f71\u54cd\u5e76\u6784\u5efa\u76f8\u5173\u6846\u67b6\u3002", "method": "\u5bf9\u56db\u5929\u5de5\u4f5c\u5236\u76f8\u5173\u6982\u5ff5\u8fdb\u884c\u7cfb\u7edf\u56de\u987e\uff0c\u7ed3\u5408\u7cfb\u7edf\u6587\u732e\u56de\u987e\u548c\u7f51\u7edc\u5185\u5bb9\u5206\u6790\u3002", "result": "\u5f97\u51fa\u5339\u914d\u6982\u5ff5\u548c\u6548\u679c\u7684\u5143\u6846\u67b6\uff0c\u53ef\u6839\u636e\u7ba1\u7406\u524d\u63d0\u548c\u60c5\u51b5\u6307\u5bfc\u538b\u7f29\u5de5\u4f5c\u65f6\u95f4\u8868\u7684\u91c7\u7528\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u53ef\u63a8\u6d4b\u538b\u7f29\u5de5\u4f5c\u65f6\u95f4\u8868\u5bf9IT\u4f01\u4e1a\u8fd0\u8425\u6548\u80fd\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u4e14\u5143\u6846\u67b6\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2507.08966", "pdf": "https://arxiv.org/pdf/2507.08966", "abs": "https://arxiv.org/abs/2507.08966", "authors": ["Meng Liu", "Karl Leswing", "Simon K. S. Chu", "Farhad Ramezanghorbani", "Griffin Young", "Gabriel Marques", "Prerna Das", "Anjali Panikar", "Esther Jamir", "Mohammed Sulaiman Shamsudeen", "K. Shawn Watts", "Ananya Sen", "Hari Priya Devannagari", "Edward B. Miller", "Muyun Lihan", "Howook Hwang", "Janet Paulsen", "Xin Yu", "Kyle Gion", "Timur Rvachov", "Emine Kucukbenli", "Saee Gopal Paliwal"], "title": "ToxBench: A Binding Affinity Prediction Benchmark with AB-FEP-Calculated Labels for Human Estrogen Receptor Alpha", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.BM"], "comment": "Workshop on Generative AI for Biology at ICML 2025", "summary": "Protein-ligand binding affinity prediction is essential for drug discovery\nand toxicity assessment. While machine learning (ML) promises fast and accurate\npredictions, its progress is constrained by the availability of reliable data.\nIn contrast, physics-based methods such as absolute binding free energy\nperturbation (AB-FEP) deliver high accuracy but are computationally prohibitive\nfor high-throughput applications. To bridge this gap, we introduce ToxBench,\nthe first large-scale AB-FEP dataset designed for ML development and focused on\na single pharmaceutically critical target, Human Estrogen Receptor Alpha\n(ER$\\alpha$). ToxBench contains 8,770 ER$\\alpha$-ligand complex structures with\nbinding free energies computed via AB-FEP with a subset validated against\nexperimental affinities at 1.75 kcal/mol RMSE, along with non-overlapping\nligand splits to assess model generalizability. Using ToxBench, we further\nbenchmark state-of-the-art ML methods, and notably, our proposed DualBind\nmodel, which employs a dual-loss framework to effectively learn the binding\nenergy function. The benchmark results demonstrate the superior performance of\nDualBind and the potential of ML to approximate AB-FEP at a fraction of the\ncomputational cost.", "AI": {"tldr": "\u63d0\u51faToxBench\u6570\u636e\u96c6\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5f00\u53d1\uff0c\u4ee5\u9884\u6d4b\u86cb\u767d - \u914d\u4f53\u7ed3\u5408\u4eb2\u548c\u529b\uff0c\u8fd8\u63d0\u51faDualBind\u6a21\u578b\uff0c\u6d4b\u8bd5\u663e\u793a\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u86cb\u767d - \u914d\u4f53\u7ed3\u5408\u4eb2\u548c\u529b\u53d7\u53ef\u9760\u6570\u636e\u9650\u5236\uff0c\u57fa\u4e8e\u7269\u7406\u7684\u65b9\u6cd5\u8ba1\u7b97\u91cf\u5927\uff0c\u4e3a\u586b\u8865\u4e24\u8005\u5dee\u8ddd\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5f15\u5165ToxBench\u6570\u636e\u96c6\uff0c\u5305\u542b8770\u4e2aER\u03b1 - \u914d\u4f53\u590d\u5408\u7269\u7ed3\u6784\u53ca\u7ed3\u5408\u81ea\u7531\u80fd\uff1b\u63d0\u51faDualBind\u6a21\u578b\uff0c\u91c7\u7528\u53cc\u635f\u5931\u6846\u67b6\u5b66\u4e60\u7ed3\u5408\u80fd\u51fd\u6570\u3002", "result": "ToxBench\u90e8\u5206\u6570\u636e\u4e0e\u5b9e\u9a8c\u4eb2\u548c\u529b\u9a8c\u8bc1\u7684\u5747\u65b9\u6839\u8bef\u5dee\u4e3a1.75 kcal/mol\uff1bDualBind\u6a21\u578b\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "DualBind\u6a21\u578b\u8868\u73b0\u51fa\u8272\uff0c\u673a\u5668\u5b66\u4e60\u6709\u6f5c\u529b\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u8fd1\u4f3c\u57fa\u4e8e\u7269\u7406\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.09077", "pdf": "https://arxiv.org/pdf/2507.09077", "abs": "https://arxiv.org/abs/2507.09077", "authors": ["Eric C. Chi", "Aaron J. Molstad", "Zheming Gao"], "title": "Convex Clustering", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "This survey reviews a clustering method based on solving a convex\noptimization problem. Despite the plethora of existing clustering methods,\nconvex clustering has several uncommon features that distinguish it from prior\nart. The optimization problem is free of spurious local minima, and its unique\nglobal minimizer is stable with respect to all its inputs, including the data,\na tuning parameter, and weight hyperparameters. Its single tuning parameter\ncontrols the number of clusters and can be chosen using standard techniques\nfrom penalized regression. We give intuition into the behavior and theory for\nconvex clustering as well as practical guidance. We highlight important\nalgorithms and give insight into how their computational costs scale with the\nproblem size. Finally, we highlight the breadth of its uses and flexibility to\nbe combined and integrated with other inferential methods.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u57fa\u4e8e\u51f8\u4f18\u5316\u95ee\u9898\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u4ecb\u7ecd\u5176\u7279\u70b9\u3001\u7406\u8bba\u3001\u7b97\u6cd5\u3001\u8ba1\u7b97\u6210\u672c\u53ca\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u805a\u7c7b\u65b9\u6cd5\u4f17\u591a\uff0c\u51f8\u805a\u7c7b\u6709\u72ec\u7279\u7279\u5f81\uff0c\u503c\u5f97\u7efc\u8ff0\u4ecb\u7ecd\u3002", "method": "\u56de\u987e\u57fa\u4e8e\u51f8\u4f18\u5316\u95ee\u9898\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u7ed9\u51fa\u539f\u7406\u548c\u7406\u8bba\uff0c\u4ecb\u7ecd\u91cd\u8981\u7b97\u6cd5\u53ca\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u51f8\u4f18\u5316\u95ee\u9898\u65e0\u865a\u5047\u5c40\u90e8\u6781\u5c0f\u503c\uff0c\u5168\u5c40\u6781\u5c0f\u503c\u7a33\u5b9a\uff0c\u53ef\u901a\u8fc7\u5355\u4e00\u8c03\u53c2\u63a7\u5236\u7c07\u6570\u91cf\u3002", "conclusion": "\u51f8\u805a\u7c7b\u65b9\u6cd5\u6709\u826f\u597d\u7279\u6027\uff0c\u4e14\u4f7f\u7528\u8303\u56f4\u5e7f\uff0c\u53ef\u4e0e\u5176\u4ed6\u63a8\u7406\u65b9\u6cd5\u7ed3\u5408\u3002"}}
{"id": "2507.10076", "pdf": "https://arxiv.org/pdf/2507.10076", "abs": "https://arxiv.org/abs/2507.10076", "authors": ["Anna Rapberger", "Fabrizio Russo", "Antonio Rago", "Francesca Toni"], "title": "On Gradual Semantics for Assumption-Based Argumentation", "categories": ["cs.AI"], "comment": null, "summary": "In computational argumentation, gradual semantics are fine-grained\nalternatives to extension-based and labelling-based semantics . They ascribe a\ndialectical strength to (components of) arguments sanctioning their degree of\nacceptability. Several gradual semantics have been studied for abstract,\nbipolar and quantitative bipolar argumentation frameworks (QBAFs), as well as,\nto a lesser extent, for some forms of structured argumentation. However, this\nhas not been the case for assumption-based argumentation (ABA), despite it\nbeing a popular form of structured argumentation with several applications\nwhere gradual semantics could be useful. In this paper, we fill this gap and\npropose a family of novel gradual semantics for equipping assumptions, which\nare the core components in ABA frameworks, with dialectical strengths. To do\nso, we use bipolar set-based argumentation frameworks as an abstraction of\n(potentially non-flat) ABA frameworks and generalise state-of-the-art modular\ngradual semantics for QBAFs. We show that our gradual ABA semantics satisfy\nsuitable adaptations of desirable properties of gradual QBAF semantics, such as\nbalance and monotonicity. We also explore an argument-based approach that\nleverages established QBAF modular semantics directly, and use it as baseline.\nFinally, we conduct experiments with synthetic ABA frameworks to compare our\ngradual ABA semantics with its argument-based counterpart and assess\nconvergence.", "AI": {"tldr": "\u672c\u6587\u4e3a\u57fa\u4e8e\u5047\u8bbe\u7684\u8bba\u8bc1\uff08ABA\uff09\u63d0\u51fa\u65b0\u7684\u6e10\u8fdb\u8bed\u4e49\uff0c\u901a\u8fc7\u53cc\u6781\u96c6\u8bba\u8bc1\u6846\u67b6\u62bd\u8c61ABA\u6846\u67b6\u5e76\u63a8\u5e7f\u73b0\u6709\u8bed\u4e49\uff0c\u9a8c\u8bc1\u6027\u8d28\u3001\u5bf9\u6bd4\u4e0d\u540c\u65b9\u6cd5\u5e76\u5b9e\u9a8c\u8bc4\u4f30\u6536\u655b\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e2d\u6e10\u8fdb\u8bed\u4e49\u5728ABA\u4e2d\u7f3a\u5931\uff0c\u800cABA\u5e94\u7528\u573a\u666f\u9700\u8981\u6e10\u8fdb\u8bed\u4e49\uff0c\u56e0\u6b64\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7528\u53cc\u6781\u96c6\u8bba\u8bc1\u6846\u67b6\u62bd\u8c61ABA\u6846\u67b6\uff0c\u63a8\u5e7fQBAF\u7684\u6a21\u5757\u5316\u6e10\u8fdb\u8bed\u4e49\uff1b\u63a2\u7d22\u76f4\u63a5\u5229\u7528\u5df2\u6709\u7684QBAF\u6a21\u5757\u5316\u8bed\u4e49\u7684\u57fa\u4e8e\u8bba\u8bc1\u7684\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6e10\u8fdbABA\u8bed\u4e49\u6ee1\u8db3\u6e10\u8fdbQBAF\u8bed\u4e49\u7406\u60f3\u5c5e\u6027\u7684\u9002\u5f53\u6539\u7f16\uff1b\u901a\u8fc7\u5408\u6210ABA\u6846\u67b6\u5b9e\u9a8c\u5bf9\u6bd4\u4e86\u4e0d\u540c\u65b9\u6cd5\u3002", "conclusion": "\u6210\u529f\u4e3aABA\u63d0\u51fa\u65b0\u7684\u6e10\u8fdb\u8bed\u4e49\uff0c\u6ee1\u8db3\u76f8\u5173\u6027\u8d28\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u6536\u655b\u6027\u3002"}}
{"id": "2507.10054", "pdf": "https://arxiv.org/pdf/2507.10054", "abs": "https://arxiv.org/abs/2507.10054", "authors": ["Emir Bosnak", "Sahand Moslemi", "Mayasah Lami", "Anil Koyuncu"], "title": "Explicit Vulnerability Generation with LLMs: An Investigation Beyond Adversarial Attacks", "categories": ["cs.SE"], "comment": "Accepted to ICSME 2025", "summary": "Large Language Models (LLMs) are increasingly used as code assistants, yet\ntheir behavior when explicitly asked to generate insecure code remains poorly\nunderstood. While prior research has focused on unintended vulnerabilities or\nadversarial prompting techniques, this study examines a more direct threat\nscenario: open-source LLMs generating vulnerable code when prompted either\ndirectly or indirectly. We propose a dual experimental design: (1) Dynamic\nPrompting, which systematically varies vulnerability type, user persona, and\ndirectness across structured templates; and (2) Reverse Prompting, which\nderives prompts from real vulnerable code samples to assess vulnerability\nreproduction accuracy. We evaluate three open-source 7B-parameter models\n(Qwen2, Mistral, and Gemma) using ESBMC static analysis to assess both the\npresence of vulnerabilities and the correctness of the generated vulnerability\ntype. Results show all models frequently produce vulnerable outputs, with Qwen2\nachieving highest correctness rates. User persona significantly affects\nsuccess, where student personas achieved higher vulnerability rates than\nprofessional roles, while direct prompts were marginally more effective.\nVulnerability reproduction followed an inverted-U pattern with cyclomatic\ncomplexity, peaking at moderate ranges. Our findings expose limitations of\nsafety mechanisms in open-source models, particularly for seemingly benign\neducational requests.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u53d7\u76f4\u63a5\u6216\u95f4\u63a5\u63d0\u793a\u65f6\u751f\u6210\u6613\u53d7\u653b\u51fb\u4ee3\u7801\u7684\u60c5\u51b5\uff0c\u7528\u53cc\u5b9e\u9a8c\u8bbe\u8ba1\u8bc4\u4f30\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u5e38\u751f\u6210\u6613\u53d7\u653b\u51fb\u4ee3\u7801\uff0cQwen2\u6b63\u786e\u6027\u6700\u9ad8\uff0c\u7528\u6237\u89d2\u8272\u548c\u63d0\u793a\u65b9\u5f0f\u6709\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u5145\u5206\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u88ab\u660e\u786e\u8981\u6c42\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\u65f6\u7684\u884c\u4e3a\uff0c\u672c\u7814\u7a76\u805a\u7126\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u76f4\u63a5\u6216\u95f4\u63a5\u63d0\u793a\u4e0b\u751f\u6210\u6613\u53d7\u653b\u51fb\u4ee3\u7801\u8fd9\u4e00\u76f4\u63a5\u5a01\u80c1\u573a\u666f\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u63d0\u793a\u548c\u53cd\u5411\u63d0\u793a\u7684\u53cc\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u7528ESBMC\u9759\u6001\u5206\u6790\u8bc4\u4f30\u4e09\u4e2a7B\u53c2\u6570\u7684\u5f00\u6e90\u6a21\u578b\u3002", "result": "\u6240\u6709\u6a21\u578b\u5e38\u4ea7\u751f\u6613\u53d7\u653b\u51fb\u7684\u8f93\u51fa\uff0cQwen2\u6b63\u786e\u6027\u6700\u9ad8\uff1b\u5b66\u751f\u89d2\u8272\u6bd4\u4e13\u4e1a\u89d2\u8272\u7684\u6f0f\u6d1e\u7387\u66f4\u9ad8\uff0c\u76f4\u63a5\u63d0\u793a\u7a0d\u6709\u6548\uff1b\u6f0f\u6d1e\u590d\u73b0\u4e0e\u5708\u590d\u6742\u5ea6\u5448\u5012U\u578b\u5173\u7cfb\u3002", "conclusion": "\u63ed\u793a\u4e86\u5f00\u6e90\u6a21\u578b\u5b89\u5168\u673a\u5236\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u770b\u4f3c\u826f\u6027\u7684\u6559\u80b2\u8bf7\u6c42\u65b9\u9762\u3002"}}
{"id": "2507.08972", "pdf": "https://arxiv.org/pdf/2507.08972", "abs": "https://arxiv.org/abs/2507.08972", "authors": ["Sifan Wang", "Shyam Sankaran", "Panos Stinis", "Paris Perdikaris"], "title": "Simulating Three-dimensional Turbulence with Physics-informed Neural Networks", "categories": ["cs.LG", "cs.AI", "physics.comp-ph", "physics.flu-dyn"], "comment": "25 pages, 13 figures, 3 tables", "summary": "Turbulent fluid flows are among the most computationally demanding problems\nin science, requiring enormous computational resources that become prohibitive\nat high flow speeds. Physics-informed neural networks (PINNs) represent a\nradically different approach that trains neural networks directly from physical\nequations rather than data, offering the potential for continuous, mesh-free\nsolutions. Here we show that appropriately designed PINNs can successfully\nsimulate fully turbulent flows in both two and three dimensions, directly\nlearning solutions to the fundamental fluid equations without traditional\ncomputational grids or training data. Our approach combines several algorithmic\ninnovations including adaptive network architectures, causal training, and\nadvanced optimization methods to overcome the inherent challenges of learning\nchaotic dynamics. Through rigorous validation on challenging turbulence\nproblems, we demonstrate that PINNs accurately reproduce key flow statistics\nincluding energy spectra, kinetic energy, enstrophy, and Reynolds stresses. Our\nresults demonstrate that neural equation solvers can handle complex chaotic\nsystems, opening new possibilities for continuous turbulence modeling that\ntranscends traditional computational limitations.", "AI": {"tldr": "\u672c\u6587\u8868\u660e\u5408\u9002\u8bbe\u8ba1\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u53ef\u6210\u529f\u6a21\u62df\u4e8c\u7ef4\u548c\u4e09\u7ef4\u5168\u6e4d\u6d41\u6d41\u52a8\uff0c\u7ed3\u5408\u7b97\u6cd5\u521b\u65b0\u514b\u670d\u5b66\u4e60\u6df7\u6c8c\u52a8\u529b\u5b66\u6311\u6218\uff0c\u51c6\u786e\u91cd\u73b0\u5173\u952e\u6d41\u52a8\u7edf\u8ba1\u91cf\uff0c\u4e3a\u8fde\u7eed\u6e4d\u6d41\u5efa\u6a21\u5f00\u8f9f\u65b0\u53ef\u80fd\u3002", "motivation": "\u6e4d\u6d41\u6d41\u4f53\u6d41\u52a8\u8ba1\u7b97\u9700\u6c42\u5927\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u9ad8\u6d41\u901f\u4e0b\u9700\u5de8\u5927\u8ba1\u7b97\u8d44\u6e90\uff0cPINNs\u63d0\u4f9b\u4e86\u4ece\u7269\u7406\u65b9\u7a0b\u800c\u975e\u6570\u636e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u7684\u65b0\u9014\u5f84\u3002", "method": "\u7ed3\u5408\u81ea\u9002\u5e94\u7f51\u7edc\u67b6\u6784\u3001\u56e0\u679c\u8bad\u7ec3\u548c\u5148\u8fdb\u4f18\u5316\u65b9\u6cd5\u7b49\u7b97\u6cd5\u521b\u65b0\uff0c\u76f4\u63a5\u4ece\u57fa\u672c\u6d41\u4f53\u65b9\u7a0b\u5b66\u4e60\uff0c\u4e0d\u4f9d\u8d56\u4f20\u7edf\u8ba1\u7b97\u7f51\u683c\u548c\u8bad\u7ec3\u6570\u636e\u3002", "result": "PINNs\u51c6\u786e\u91cd\u73b0\u4e86\u5305\u62ec\u80fd\u8c31\u3001\u52a8\u80fd\u3001\u6da1\u91cf\u548c\u96f7\u8bfa\u5e94\u529b\u7b49\u5173\u952e\u6d41\u52a8\u7edf\u8ba1\u91cf\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u65b9\u7a0b\u6c42\u89e3\u5668\u53ef\u5904\u7406\u590d\u6742\u6df7\u6c8c\u7cfb\u7edf\uff0c\u4e3a\u8fde\u7eed\u6e4d\u6d41\u5efa\u6a21\u8d85\u8d8a\u4f20\u7edf\u8ba1\u7b97\u9650\u5236\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u3002"}}
{"id": "2507.09087", "pdf": "https://arxiv.org/pdf/2507.09087", "abs": "https://arxiv.org/abs/2507.09087", "authors": ["Esraa Elelimy", "Brett Daley", "Andrew Patterson", "Marlos C. Machado", "Adam White", "Martha White"], "title": "Deep Reinforcement Learning with Gradient Eligibility Traces", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Achieving fast and stable off-policy learning in deep reinforcement learning\n(RL) is challenging. Most existing methods rely on semi-gradient\ntemporal-difference (TD) methods for their simplicity and efficiency, but are\nconsequently susceptible to divergence. While more principled approaches like\nGradient TD (GTD) methods have strong convergence guarantees, they have rarely\nbeen used in deep RL. Recent work introduced the Generalized Projected Bellman\nError ($\\GPBE$), enabling GTD methods to work efficiently with nonlinear\nfunction approximation. However, this work is only limited to one-step methods,\nwhich are slow at credit assignment and require a large number of samples. In\nthis paper, we extend the $\\GPBE$ objective to support multistep credit\nassignment based on the $\\lambda$-return and derive three gradient-based\nmethods that optimize this new objective. We provide both a forward-view\nformulation compatible with experience replay and a backward-view formulation\ncompatible with streaming algorithms. Finally, we evaluate the proposed\nalgorithms and show that they outperform both PPO and StreamQ in MuJoCo and\nMinAtar environments, respectively. Code available at\nhttps://github.com/esraaelelimy/gtd\\_algos", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.10106", "pdf": "https://arxiv.org/pdf/2507.10106", "abs": "https://arxiv.org/abs/2507.10106", "authors": ["Harshal Nandigramwar", "Syed Qutub", "Kay-Ulrich Scholl"], "title": "BlueGlass: A Framework for Composite AI Safety", "categories": ["cs.AI"], "comment": "Accepted at ICML 2025 [Actionable Interpretability Workshop]", "summary": "As AI systems become increasingly capable and ubiquitous, ensuring the safety\nof these systems is critical. However, existing safety tools often target\ndifferent aspects of model safety and cannot provide full assurance in\nisolation, highlighting a need for integrated and composite methodologies. This\npaper introduces BlueGlass, a framework designed to facilitate composite AI\nsafety workflows by providing a unified infrastructure enabling the integration\nand composition of diverse safety tools that operate across model internals and\noutputs. Furthermore, to demonstrate the utility of this framework, we present\nthree safety-oriented analyses on vision-language models for the task of object\ndetection: (1) distributional evaluation, revealing performance trade-offs and\npotential failure modes across distributions; (2) probe-based analysis of layer\ndynamics highlighting shared hierarchical learning via phase transition; and\n(3) sparse autoencoders identifying interpretable concepts. More broadly, this\nwork contributes foundational infrastructure and findings for building more\nrobust and reliable AI systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4fc3\u8fdb\u590d\u5408AI\u5b89\u5168\u5de5\u4f5c\u6d41\u7684\u6846\u67b6BlueGlass\uff0c\u5e76\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u4e09\u79cd\u5b89\u5168\u5206\u6790\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u5de5\u5177\u9488\u5bf9\u6a21\u578b\u5b89\u5168\u4e0d\u540c\u65b9\u9762\uff0c\u65e0\u6cd5\u5355\u72ec\u63d0\u4f9b\u5168\u9762\u4fdd\u8bc1\uff0c\u9700\u8981\u96c6\u6210\u548c\u590d\u5408\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165BlueGlass\u6846\u67b6\uff0c\u7edf\u4e00\u57fa\u7840\u8bbe\u65bd\u4ee5\u96c6\u6210\u4e0d\u540c\u5b89\u5168\u5de5\u5177\uff0c\u5e76\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e09\u79cd\u5b89\u5168\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5206\u5e03\u8bc4\u4f30\u63ed\u793a\u6027\u80fd\u6743\u8861\u548c\u6f5c\u5728\u6545\u969c\u6a21\u5f0f\uff1b\u57fa\u4e8e\u63a2\u9488\u5206\u6790\u5c42\u52a8\u6001\uff1b\u7528\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u8bc6\u522b\u53ef\u89e3\u91ca\u6982\u5ff5\u3002", "conclusion": "\u672c\u5de5\u4f5c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u67b6\u6784\u548c\u7814\u7a76\u6210\u679c\u3002"}}
{"id": "2507.10062", "pdf": "https://arxiv.org/pdf/2507.10062", "abs": "https://arxiv.org/abs/2507.10062", "authors": ["Erg\u00fcn Batuhan Kaynak", "Mayasah Lami", "Sahand Moslemi", "Anil Koyuncu"], "title": "LLMShot: Reducing snapshot testing maintenance via LLMs", "categories": ["cs.SE"], "comment": "Accepted to ICSME 2025", "summary": "Snapshot testing has emerged as a critical technique for UI validation in\nmodern software development, yet it suffers from substantial maintenance\noverhead due to frequent UI changes causing test failures that require manual\ninspection to distinguish between genuine regressions and intentional design\nchanges. This manual triage process becomes increasingly burdensome as\napplications evolve, creating a need for automated analysis solutions. This\npaper introduces LLMShot, a novel framework that leverages vision-based Large\nLanguage Models to automatically analyze snapshot test failures through\nhierarchical classification of UI changes. To evaluate LLMShot's effectiveness,\nwe developed a comprehensive dataset using a feature-rich iOS application with\nconfigurable feature flags, creating realistic scenarios that produce authentic\nsnapshot differences representative of real development workflows. Our\nevaluation using Gemma3 models demonstrates strong classification performance,\nwith the 12B variant achieving over 84% recall in identifying failure root\ncauses while the 4B model offers practical deployment advantages with\nacceptable performance for continuous integration environments. However, our\nexploration of selective ignore mechanisms revealed significant limitations in\ncurrent prompting-based approaches for controllable visual reasoning. LLMShot\nrepresents the first automated approach to semantic snapshot test analysis,\noffering developers structured insights that can substantially reduce manual\ntriage effort and advance toward more intelligent UI testing paradigms.", "AI": {"tldr": "\u4ecb\u7ecdLLMShot\u6846\u67b6\u5229\u7528\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5206\u6790\u5feb\u7167\u6d4b\u8bd5\u5931\u8d25\uff0c\u8bc4\u4f30\u663e\u793a\u6709\u8f83\u597d\u5206\u7c7b\u6027\u80fd\uff0c\u4f46\u9009\u62e9\u6027\u5ffd\u7565\u673a\u5236\u6709\u5c40\u9650\uff0c\u53ef\u51cf\u5c11\u4eba\u5de5\u5206\u7c7b\u5de5\u4f5c\u91cf\u3002", "motivation": "\u5feb\u7167\u6d4b\u8bd5\u56e0UI\u9891\u7e41\u53d8\u5316\u4ea7\u751f\u5927\u91cf\u7ef4\u62a4\u5f00\u9500\uff0c\u4eba\u5de5\u5206\u7c7b\u8d1f\u62c5\u91cd\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165LLMShot\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9UI\u53d8\u5316\u7684\u5206\u5c42\u5206\u7c7b\u81ea\u52a8\u5206\u6790\u5feb\u7167\u6d4b\u8bd5\u5931\u8d25\uff1b\u7528iOS\u5e94\u7528\u521b\u5efa\u7efc\u5408\u6570\u636e\u96c6\u8bc4\u4f30\u5176\u6709\u6548\u6027\u3002", "result": "\u4f7f\u7528Gemma3\u6a21\u578b\u8bc4\u4f30\uff0c12B\u53d8\u4f53\u8bc6\u522b\u5931\u8d25\u6839\u6e90\u53ec\u56de\u7387\u8d8584%\uff0c4B\u6a21\u578b\u5728\u6301\u7eed\u96c6\u6210\u73af\u5883\u6709\u5b9e\u7528\u90e8\u7f72\u4f18\u52bf\uff1b\u9009\u62e9\u6027\u5ffd\u7565\u673a\u5236\u7684\u63d0\u793a\u63a8\u7406\u65b9\u6cd5\u6709\u5c40\u9650\u3002", "conclusion": "LLMShot\u662f\u9996\u4e2a\u8bed\u4e49\u5feb\u7167\u6d4b\u8bd5\u81ea\u52a8\u5316\u5206\u6790\u65b9\u6cd5\uff0c\u80fd\u51cf\u5c11\u4eba\u5de5\u5206\u7c7b\u5de5\u4f5c\u91cf\uff0c\u63a8\u52a8UI\u6d4b\u8bd5\u5411\u66f4\u667a\u80fd\u8303\u5f0f\u53d1\u5c55\u3002"}}
{"id": "2507.09091", "pdf": "https://arxiv.org/pdf/2507.09091", "abs": "https://arxiv.org/abs/2507.09091", "authors": ["Shayan K. Azmoodeh", "Krishna Subramani", "Paris Smaragdis"], "title": "Continuous-Time Signal Decomposition: An Implicit Neural Generalization of PCA and ICA", "categories": ["cs.LG", "eess.SP", "stat.ML"], "comment": "6 pages, 3 figures, 1 table. MLSP 2025", "summary": "We generalize the low-rank decomposition problem, such as principal and\nindependent component analysis (PCA, ICA) for continuous-time vector-valued\nsignals and provide a model-agnostic implicit neural signal representation\nframework to learn numerical approximations to solve the problem. Modeling\nsignals as continuous-time stochastic processes, we unify the approaches to\nboth the PCA and ICA problems in the continuous setting through a contrast\nfunction term in the network loss, enforcing the desired statistical properties\nof the source signals (decorrelation, independence) learned in the\ndecomposition. This extension to a continuous domain allows the application of\nsuch decompositions to point clouds and irregularly sampled signals where\nstandard techniques are not applicable.", "AI": {"tldr": "\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684\u9690\u5f0f\u795e\u7ecf\u4fe1\u53f7\u8868\u793a\u6846\u67b6\u6765\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u5411\u91cf\u503c\u4fe1\u53f7\u7684\u4f4e\u79e9\u5206\u89e3\u95ee\u9898\uff0c\u6269\u5c55\u5230\u8fde\u7eed\u57df\u4f7f\u5206\u89e3\u53ef\u7528\u4e8e\u70b9\u4e91\u548c\u4e0d\u89c4\u5219\u91c7\u6837\u4fe1\u53f7\u3002", "motivation": "\u5c06\u4f4e\u79e9\u5206\u89e3\u95ee\u9898\u63a8\u5e7f\u5230\u8fde\u7eed\u65f6\u95f4\u5411\u91cf\u503c\u4fe1\u53f7\uff0c\u5e76\u89e3\u51b3\u6807\u51c6\u6280\u672f\u65e0\u6cd5\u5904\u7406\u70b9\u4e91\u548c\u4e0d\u89c4\u5219\u91c7\u6837\u4fe1\u53f7\u7684\u95ee\u9898\u3002", "method": "\u5c06\u4fe1\u53f7\u5efa\u6a21\u4e3a\u8fde\u7eed\u65f6\u95f4\u968f\u673a\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7f51\u7edc\u635f\u5931\u4e2d\u7684\u5bf9\u6bd4\u51fd\u6570\u9879\u7edf\u4e00PCA\u548cICA\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6cd5\u3002", "result": "\u5b9e\u73b0\u4e86\u8fde\u7eed\u57df\u7684\u4f4e\u79e9\u5206\u89e3\uff0c\u80fd\u5e94\u7528\u4e8e\u70b9\u4e91\u548c\u4e0d\u89c4\u5219\u91c7\u6837\u4fe1\u53f7\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u89e3\u51b3\u8fde\u7eed\u65f6\u95f4\u4fe1\u53f7\u7684\u4f4e\u79e9\u5206\u89e3\u95ee\u9898\uff0c\u4e14\u9002\u7528\u4e8e\u7279\u6b8a\u4fe1\u53f7\u3002"}}
{"id": "2507.10119", "pdf": "https://arxiv.org/pdf/2507.10119", "abs": "https://arxiv.org/abs/2507.10119", "authors": ["Sadig Gojayev", "Ahmad Anaqreh", "Carolina Fortuna"], "title": "Analysis of AI Techniques for Orchestrating Edge-Cloud Application Migration", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Application migration in edge-cloud system enables high QoS and cost\neffective service delivery. However, automatically orchestrating such migration\nis typically solved with heuristic approaches. Starting from the Markov\nDecision Process (MDP), in this paper, we identify, analyze and compare\nselected state-of-the-art Artificial Intelligence (AI) planning and\nReinforcement Learning (RL) approaches for solving the class of edge-cloud\napplication migration problems that can be modeled as Towers of Hanoi (ToH)\nproblems. We introduce a new classification based on state space definition and\nanalyze the compared models also through this lense. The aim is to understand\navailable techniques capable of orchestrating such application migration in\nemerging computing continuum environments.", "AI": {"tldr": "\u672c\u6587\u4eceMDP\u51fa\u53d1\uff0c\u5206\u6790\u6bd4\u8f83\u7528\u4e8e\u89e3\u51b3\u8fb9\u7f18\u4e91\u5e94\u7528\u8fc1\u79fb\u95ee\u9898\u7684AI\u89c4\u5212\u548cRL\u65b9\u6cd5\uff0c\u5f15\u5165\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u5b9a\u4e49\u7684\u5206\u7c7b\u3002", "motivation": "\u5f53\u524d\u8fb9\u7f18\u4e91\u5e94\u7528\u8fc1\u79fb\u7684\u81ea\u52a8\u7f16\u6392\u591a\u91c7\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u9700\u8981\u4e86\u89e3\u65b0\u5174\u8ba1\u7b97\u73af\u5883\u4e2d\u53ef\u7528\u4e8e\u7f16\u6392\u5e94\u7528\u8fc1\u79fb\u7684\u6280\u672f\u3002", "method": "\u4eceMDP\u5f00\u59cb\uff0c\u8bc6\u522b\u3001\u5206\u6790\u548c\u6bd4\u8f83\u57fa\u4e8eToH\u95ee\u9898\u5efa\u6a21\u7684\u8fb9\u7f18\u4e91\u5e94\u7528\u8fc1\u79fb\u95ee\u9898\u7684AI\u89c4\u5212\u548cRL\u65b9\u6cd5\uff0c\u5f15\u5165\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u5b9a\u4e49\u7684\u5206\u7c7b\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\uff0c\u76ee\u6807\u662f\u4e86\u89e3\u65b0\u5174\u8ba1\u7b97\u73af\u5883\u4e2d\u53ef\u7528\u4e8e\u7f16\u6392\u5e94\u7528\u8fc1\u79fb\u7684\u6280\u672f\u3002"}}
{"id": "2507.10103", "pdf": "https://arxiv.org/pdf/2507.10103", "abs": "https://arxiv.org/abs/2507.10103", "authors": ["Hanyang Guo", "Xiaoheng Xie", "Hong-Ning Dai", "Peng Di", "Yu Zhang", "Bishenghui Tao", "Zibin Zheng"], "title": "Accelerating Automatic Program Repair with Dual Retrieval-Augmented Fine-Tuning and Patch Generation on Large Language Models", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Automated Program Repair (APR) is essential for ensuring software reliability\nand quality while enhancing efficiency and reducing developers' workload.\nAlthough rule-based and learning-based APR methods have demonstrated their\neffectiveness, their performance was constrained by the defect type of repair,\nthe quality of training data, and the size of model parameters. Recently, Large\nLanguage Models (LLMs) combined with Retrieval-Augmented-Generation (RAG) have\nbeen increasingly adopted in APR tasks. However, current code LLMs and RAG\ndesigns neither fully address code repair tasks nor consider code-specific\nfeatures. To overcome these limitations, we propose SelRepair, a novel APR\napproach with integration of a fine-tuned LLM with a newly-designed dual RAG\nmodule. This approach uses a bug-fix pair dataset for fine-tuning and\nincorporates semantic and syntactic/structural similarity information through\nan RAG selection gate. This design ensures relevant information is retrieved\nefficiently, thereby reducing token length and inference time. Evaluations on\nJava datasets show SelRepair outperforms other APR methods, achieving 26.29%\nand 17.64% in terms of exact match (EM) on different datasets while reducing\ninference time by at least 6.42% with controlled input lengths.", "AI": {"tldr": "\u63d0\u51faSelRepair\u65b9\u6cd5\u7528\u4e8e\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\uff0c\u5728Java\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u80fd\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u3001\u5b66\u4e60\u7684APR\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u5f53\u524d\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u548cRAG\u8bbe\u8ba1\u4e0d\u80fd\u5145\u5206\u5904\u7406\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u3002", "method": "\u63d0\u51faSelRepair\u65b9\u6cd5\uff0c\u5c06\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u65b0\u8bbe\u8ba1\u7684\u53ccRAG\u6a21\u5757\u96c6\u6210\uff0c\u7528bug - fix\u5bf9\u6570\u636e\u96c6\u5fae\u8c03\uff0c\u901a\u8fc7RAG\u9009\u62e9\u95e8\u7ed3\u5408\u8bed\u4e49\u548c\u53e5\u6cd5/\u7ed3\u6784\u76f8\u4f3c\u4fe1\u606f\u3002", "result": "\u5728Java\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\uff0cSelRepair\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7cbe\u786e\u5339\u914d\u7387\u5206\u522b\u8fbe26.29%\u548c17.64%\uff0c\u5728\u63a7\u5236\u8f93\u5165\u957f\u5ea6\u4e0b\u63a8\u7406\u65f6\u95f4\u81f3\u5c11\u51cf\u5c116.42%\u3002", "conclusion": "SelRepair\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002"}}
{"id": "2507.08980", "pdf": "https://arxiv.org/pdf/2507.08980", "abs": "https://arxiv.org/abs/2507.08980", "authors": ["Chenyu Wang", "Cai Zhou", "Sharut Gupta", "Zongyu Lin", "Stefanie Jegelka", "Stephen Bates", "Tommi Jaakkola"], "title": "Learning Diffusion Models with Flexible Representation Guidance", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Diffusion models can be improved with additional guidance towards more\neffective representations of input. Indeed, prior empirical work has already\nshown that aligning internal representations of the diffusion model with those\nof pre-trained models improves generation quality. In this paper, we present a\nsystematic framework for incorporating representation guidance into diffusion\nmodels. We provide alternative decompositions of denoising models along with\ntheir associated training criteria, where the decompositions determine when and\nhow the auxiliary representations are incorporated. Guided by our theoretical\ninsights, we introduce two new strategies for enhancing representation\nalignment in diffusion models. First, we pair examples with target\nrepresentations either derived from themselves or arisen from different\nsynthetic modalities, and subsequently learn a joint model over the multimodal\npairs. Second, we design an optimal training curriculum that balances\nrepresentation learning and data generation. Our experiments across image,\nprotein sequence, and molecule generation tasks demonstrate superior\nperformance as well as accelerated training. In particular, on the\nclass-conditional ImageNet $256\\times 256$ benchmark, our guidance results in\n$23.3$ times faster training than the original SiT-XL as well as four times\nspeedup over the state-of-the-art method REPA. The code is available at\nhttps://github.com/ChenyuWang-Monica/REED.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u8868\u793a\u5f15\u5bfc\u878d\u5165\u6269\u6563\u6a21\u578b\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u4ecb\u7ecd\u4e24\u79cd\u589e\u5f3a\u8868\u793a\u5bf9\u9f50\u7684\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u591a\u4efb\u52a1\u4e2d\u6709\u4f18\u8d8a\u6027\u80fd\u548c\u52a0\u901f\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u5df2\u6709\u7ecf\u9a8c\u8868\u660e\u5c06\u6269\u6563\u6a21\u578b\u7684\u5185\u90e8\u8868\u793a\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u9f50\u53ef\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u56e0\u6b64\u5e0c\u671b\u63d0\u51fa\u7cfb\u7edf\u6846\u67b6\u5c06\u8868\u793a\u5f15\u5bfc\u878d\u5165\u6269\u6563\u6a21\u578b\u3002", "method": "\u63d0\u4f9b\u53bb\u566a\u6a21\u578b\u7684\u66ff\u4ee3\u5206\u89e3\u53ca\u5176\u8bad\u7ec3\u51c6\u5219\uff0c\u5f15\u5165\u4e24\u79cd\u7b56\u7565\uff1a\u4e00\u662f\u5bf9\u591a\u6a21\u6001\u5bf9\u5b66\u4e60\u8054\u5408\u6a21\u578b\uff1b\u4e8c\u662f\u8bbe\u8ba1\u5e73\u8861\u8868\u793a\u5b66\u4e60\u548c\u6570\u636e\u751f\u6210\u7684\u6700\u4f18\u8bad\u7ec3\u8bfe\u7a0b\u3002", "result": "\u5728\u56fe\u50cf\u3001\u86cb\u767d\u8d28\u5e8f\u5217\u548c\u5206\u5b50\u751f\u6210\u4efb\u52a1\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u8bad\u7ec3\u52a0\u901f\uff0c\u5982\u5728ImageNet\u57fa\u51c6\u4e0a\u6bd4\u539fSiT - XL\u8bad\u7ec3\u5feb23.3\u500d\uff0c\u6bd4REPA\u5feb4\u500d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u6269\u6563\u6a21\u578b\u6027\u80fd\u548c\u52a0\u901f\u8bad\u7ec3\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.09110", "pdf": "https://arxiv.org/pdf/2507.09110", "abs": "https://arxiv.org/abs/2507.09110", "authors": ["Zhiqi Bu", "Jason M. Klusowski", "Cynthia Rush", "Ruijia Wu"], "title": "Sharp Trade-Offs in High-Dimensional Inference via 2-Level SLOPE", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Among techniques for high-dimensional linear regression, Sorted L-One\nPenalized Estimation (SLOPE) generalizes the LASSO via an adaptive $l_1$\nregularization that applies heavier penalties to larger coefficients in the\nmodel. To achieve such adaptivity, SLOPE requires the specification of a\ncomplex hierarchy of penalties, i.e., a monotone penalty sequence in $R^p$, in\ncontrast to a single penalty scalar for LASSO. Tuning this sequence when $p$ is\nlarge poses a challenge, as brute force search over a grid of values is\ncomputationally prohibitive. In this work, we study the 2-level SLOPE, an\nimportant subclass of SLOPE, with only three hyperparameters. We demonstrate\nboth empirically and analytically that 2-level SLOPE not only preserves the\nadvantages of general SLOPE -- such as improved mean squared error and\novercoming the Donoho-Tanner power limit -- but also exhibits computational\nbenefits by reducing the penalty hyperparameter space. In particular, we prove\nthat 2-level SLOPE admits a sharp, theoretically tight characterization of the\ntrade-off between true positive proportion (TPP) and false discovery proportion\n(FDP), contrasting with general SLOPE where only upper and lower bounds are\nknown. Empirical evaluations further underscore the effectiveness of 2-level\nSLOPE in settings where predictors exhibit high correlation, when the noise is\nlarge, or when the underlying signal is not sparse. Our results suggest that\n2-level SLOPE offers a robust, scalable alternative to both LASSO and general\nSLOPE, making it particularly suited for practical high-dimensional data\nanalysis.", "AI": {"tldr": "\u672c\u6587\u7814\u7a762 - level SLOPE\uff0c\u4e00\u79cdSLOPE\u7684\u91cd\u8981\u5b50\u7c7b\uff0c\u8bc1\u660e\u5176\u4fdd\u7559SLOPE\u4f18\u70b9\uff0c\u6709\u8ba1\u7b97\u4f18\u52bf\uff0c\u9002\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u5206\u6790\u3002", "motivation": "SLOPE\u8c03\u53c2\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u6613\u8c03\u53c2\u7684\u65b9\u6cd5\u3002", "method": "\u5bf92 - level SLOPE\u8fdb\u884c\u5b9e\u8bc1\u548c\u5206\u6790\u7814\u7a76\uff0c\u8bc1\u660e\u5176\u5728TPP\u548cFDP\u95f4\u7684\u6743\u8861\u7279\u6027\u3002", "result": "2 - level SLOPE\u4fdd\u7559SLOPE\u4f18\u70b9\uff0c\u51cf\u5c11\u8c03\u53c2\u7a7a\u95f4\uff0c\u5728\u9ad8\u76f8\u5173\u3001\u9ad8\u566a\u58f0\u548c\u975e\u7a00\u758f\u4fe1\u53f7\u573a\u666f\u6709\u6548\u3002", "conclusion": "2 - level SLOPE\u662fLASSO\u548c\u4e00\u822cSLOPE\u7684\u7a33\u5065\u3001\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u5408\u5b9e\u9645\u9ad8\u7ef4\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2507.10124", "pdf": "https://arxiv.org/pdf/2507.10124", "abs": "https://arxiv.org/abs/2507.10124", "authors": ["Thomas T. Hills"], "title": "Could you be wrong: Debiasing LLMs using a metacognitive prompt for improving human decision making", "categories": ["cs.AI"], "comment": "12 pages, 3 figures", "summary": "Identifying bias in LLMs is ongoing. Because they are still in development,\nwhat is true today may be false tomorrow. We therefore need general strategies\nfor debiasing that will outlive current models. Strategies developed for\ndebiasing human decision making offer one promising approach as they\nincorporate an LLM-style prompt intervention designed to bring latent knowledge\ninto awareness during decision making. LLMs trained on vast amounts of\ninformation contain information about potential biases, counter-arguments, and\ncontradictory evidence, but that information may only be brought to bear if\nprompted. Metacognitive prompts developed in the human decision making\nliterature are designed to achieve this, and as I demonstrate here, they show\npromise with LLMs. The prompt I focus on here is \"could you be wrong?\"\nFollowing an LLM response, this prompt leads LLMs to produce additional\ninformation, including why they answered as they did, errors, biases,\ncontradictory evidence, and alternatives, none of which were apparent in their\ninitial response. Indeed, this metaknowledge often reveals that how LLMs and\nusers interpret prompts are not aligned. Here I demonstrate this prompt using a\nset of questions taken from recent articles about LLM biases, including\nimplicit discriminatory biases and failures of metacognition. \"Could you be\nwrong\" prompts the LLM to identify its own biases and produce cogent\nmetacognitive reflection. I also present another example involving convincing\nbut incomplete information, which is readily corrected by the metacognitive\nprompt. In sum, this work argues that human psychology offers a new avenue for\nprompt engineering, leveraging a long history of effective prompt-based\nimprovements to human decision making.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528\u4eba\u7c7b\u51b3\u7b56\u53bb\u504f\u7b56\u7565\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u53bb\u504f\uff0c\u4ee5\u201c\u4f60\u53ef\u80fd\u9519\u4e86\u5417\u201d\u63d0\u793a\u8bcd\u4e3a\u4f8b\u5c55\u793a\u5176\u6709\u6548\u6027\uff0c\u8ba4\u4e3a\u4eba\u7c7b\u5fc3\u7406\u5b66\u4e3a\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u65b0\u9014\u5f84\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u5728\u53d1\u5c55\uff0c\u9700\u901a\u7528\u53bb\u504f\u7b56\u7565\uff0c\u4eba\u7c7b\u51b3\u7b56\u53bb\u504f\u7b56\u7565\u6709\u501f\u9274\u4ef7\u503c\u3002", "method": "\u4f7f\u7528\u4eba\u7c7b\u51b3\u7b56\u6587\u732e\u4e2d\u7684\u5143\u8ba4\u77e5\u63d0\u793a\u8bcd\u201c\u4f60\u53ef\u80fd\u9519\u4e86\u5417\u201d\uff0c\u5bf9\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u504f\u5dee\u7684\u95ee\u9898\u96c6\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u8be5\u63d0\u793a\u8bcd\u80fd\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u7ed9\u51fa\u989d\u5916\u4fe1\u606f\uff0c\u63ed\u793a\u81ea\u8eab\u504f\u5dee\u548c\u5143\u8ba4\u77e5\u53cd\u601d\uff0c\u7ea0\u6b63\u4e0d\u5b8c\u6574\u4fe1\u606f\u3002", "conclusion": "\u4eba\u7c7b\u5fc3\u7406\u5b66\u4e3a\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u65b0\u9014\u5f84\uff0c\u53ef\u501f\u9274\u57fa\u4e8e\u63d0\u793a\u6539\u8fdb\u4eba\u7c7b\u51b3\u7b56\u7684\u7ecf\u9a8c\u3002"}}
{"id": "2507.10182", "pdf": "https://arxiv.org/pdf/2507.10182", "abs": "https://arxiv.org/abs/2507.10182", "authors": ["Gehao Zhang", "Zhenting Wang", "Juan Zhai"], "title": "Breaking the Myth: Can Small Models Infer Postconditions Too?", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Formal specifications are essential for ensuring software correctness, yet\nmanually writing them is tedious and error-prone. Large Language Models (LLMs)\nhave shown promise in generating such specifications from natural language\nintents, but the giant model size and high computational demands raise a\nfundamental question: Do we really need large models for this task? In this\npaper, we show that a small, fine-tuned language model can achieve high-quality\npostcondition generation with much lower computational costs. We construct a\nspecialized dataset of prompts, reasoning logs, and postconditions, then\nsupervise the fine-tuning of a $7$B-parameter code model. Our approach tackles\nreal-world repository dependencies and preserves pre-state information,\nallowing for expressive and accurate specifications. We evaluate the model on a\nbenchmark of real-world Java bugs (Defects4J) and compare against both\nproprietary giants (e.g., GPT-4o) and open-source large models. Empirical\nresults demonstrate that our compact model matches or outperforms significantly\nlarger counterparts in syntax correctness, semantic correctness, and\nbug-distinguishing capability. These findings highlight that targeted\nfine-tuning on a modest dataset can enable small models to achieve results\nformerly seen only in massive, resource-heavy LLMs, offering a practical and\nefficient path for the real-world adoption of automated specification\ngeneration.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5c0f\u7684\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u53ef\u4f4e\u6210\u672c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u540e\u7f6e\u6761\u4ef6\u751f\u6210\uff0c\u5728\u591a\u9879\u6307\u6807\u4e0a\u5ab2\u7f8e\u6216\u8d85\u8d8a\u5927\u6a21\u578b\u3002", "motivation": "\u624b\u52a8\u7f16\u5199\u5f62\u5f0f\u5316\u89c4\u8303\u7e41\u7410\u6613\u9519\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u867d\u6709\u6f5c\u529b\u4f46\u6a21\u578b\u5927\u3001\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u63a2\u8ba8\u662f\u5426\u771f\u9700\u8981\u5927\u6a21\u578b\u5b8c\u6210\u6b64\u4efb\u52a1\u3002", "method": "\u6784\u5efa\u5305\u542b\u63d0\u793a\u3001\u63a8\u7406\u65e5\u5fd7\u548c\u540e\u7f6e\u6761\u4ef6\u7684\u4e13\u4e1a\u6570\u636e\u96c6\uff0c\u5bf970\u4ebf\u53c2\u6570\u7684\u4ee3\u7801\u6a21\u578b\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u5904\u7406\u771f\u5b9e\u4e16\u754c\u5b58\u50a8\u5e93\u4f9d\u8d56\u5e76\u4fdd\u7559\u524d\u7f6e\u72b6\u6001\u4fe1\u606f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754cJava\u6f0f\u6d1e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7d27\u51d1\u6a21\u578b\u5728\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u8bed\u4e49\u6b63\u786e\u6027\u548c\u533a\u5206\u6f0f\u6d1e\u80fd\u529b\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u66f4\u5927\u7684\u6a21\u578b\u3002", "conclusion": "\u5728\u9002\u5ea6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u5fae\u8c03\u53ef\u4f7f\u5c0f\u6a21\u578b\u8fbe\u5230\u5927\u6a21\u578b\u7684\u6548\u679c\uff0c\u4e3a\u81ea\u52a8\u89c4\u8303\u751f\u6210\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2507.08983", "pdf": "https://arxiv.org/pdf/2507.08983", "abs": "https://arxiv.org/abs/2507.08983", "authors": ["Anshuman Suri", "Harsh Chaudhari", "Yuefeng Peng", "Ali Naseh", "Amir Houmansadr", "Alina Oprea"], "title": "Exploiting Leaderboards for Large-Scale Distribution of Malicious Models", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "While poisoning attacks on machine learning models have been extensively\nstudied, the mechanisms by which adversaries can distribute poisoned models at\nscale remain largely unexplored. In this paper, we shed light on how model\nleaderboards -- ranked platforms for model discovery and evaluation -- can\nserve as a powerful channel for adversaries for stealthy large-scale\ndistribution of poisoned models. We present TrojanClimb, a general framework\nthat enables injection of malicious behaviors while maintaining competitive\nleaderboard performance. We demonstrate its effectiveness across four diverse\nmodalities: text-embedding, text-generation, text-to-speech and text-to-image,\nshowing that adversaries can successfully achieve high leaderboard rankings\nwhile embedding arbitrary harmful functionalities, from backdoors to bias\ninjection. Our findings reveal a significant vulnerability in the machine\nlearning ecosystem, highlighting the urgent need to redesign leaderboard\nevaluation mechanisms to detect and filter malicious (e.g., poisoned) models,\nwhile exposing broader security implications for the machine learning community\nregarding the risks of adopting models from unverified sources.", "AI": {"tldr": "\u7814\u7a76\u6a21\u578b\u6392\u884c\u699c\u6210\u4e3a\u653b\u51fb\u8005\u5927\u89c4\u6a21\u5206\u53d1\u4e2d\u6bd2\u6a21\u578b\u7684\u6e20\u9053\uff0c\u63d0\u51faTrojanClimb\u6846\u67b6\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u63ed\u793a\u673a\u5668\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u6f0f\u6d1e\u3002", "motivation": "\u5df2\u6709\u7814\u7a76\u672a\u5145\u5206\u63a2\u7d22\u653b\u51fb\u8005\u5927\u89c4\u6a21\u5206\u53d1\u4e2d\u6bd2\u6a21\u578b\u7684\u673a\u5236\uff0c\u805a\u7126\u6a21\u578b\u6392\u884c\u699c\u8fd9\u4e00\u53ef\u80fd\u6e20\u9053\u3002", "method": "\u63d0\u51faTrojanClimb\u6846\u67b6\uff0c\u53ef\u5728\u7ef4\u6301\u6392\u884c\u699c\u6027\u80fd\u7684\u540c\u65f6\u6ce8\u5165\u6076\u610f\u884c\u4e3a\u3002", "result": "\u5728\u56db\u79cd\u4e0d\u540c\u6a21\u6001\u4e2d\u9a8c\u8bc1\u4e86TrojanClimb\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u653b\u51fb\u8005\u80fd\u5728\u5d4c\u5165\u6709\u5bb3\u529f\u80fd\u7684\u540c\u65f6\u83b7\u5f97\u9ad8\u6392\u884c\u699c\u6392\u540d\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u5b58\u5728\u91cd\u5927\u6f0f\u6d1e\uff0c\u9700\u91cd\u65b0\u8bbe\u8ba1\u6392\u884c\u699c\u8bc4\u4f30\u673a\u5236\uff0c\u91c7\u7528\u672a\u7ecf\u9a8c\u8bc1\u6765\u6e90\u7684\u6a21\u578b\u6709\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2507.09119", "pdf": "https://arxiv.org/pdf/2507.09119", "abs": "https://arxiv.org/abs/2507.09119", "authors": ["Stephen Salerno", "Kentaro Hoffman", "Awan Afiaz", "Anna Neufeld", "Tyler H. McCormick", "Jeffrey T. Leek"], "title": "A Moment-Based Generalization to Post-Prediction Inference", "categories": ["stat.ME", "stat.ML"], "comment": "9 pages", "summary": "Artificial intelligence (AI) and machine learning (ML) are increasingly used\nto generate data for downstream analyses, yet naively treating these\npredictions as true observations can lead to biased results and incorrect\ninference. Wang et al. (2020) proposed a method, post-prediction inference,\nwhich calibrates inference by modeling the relationship between AI/ML-predicted\nand observed outcomes in a small, gold-standard sample. Since then, several\nmethods have been developed for inference with predicted data. We revisit Wang\net al. in light of these recent developments. We reflect on their assumptions\nand offer a simple extension of their method which relaxes these assumptions.\nOur extension (1) yields unbiased point estimates under standard conditions and\n(2) incorporates a simple scaling factor to preserve calibration variability.\nIn extensive simulations, we show that our method maintains nominal Type I\nerror rates, reduces bias, and achieves proper coverage.", "AI": {"tldr": "\u672c\u6587\u56de\u987eWang\u7b49\u4eba\u65b9\u6cd5\uff0c\u63d0\u51fa\u6269\u5c55\u65b9\u6cd5\uff0c\u6a21\u62df\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u4fdd\u6301\u540d\u4e49\u4e00\u7c7b\u9519\u8bef\u7387\u3001\u51cf\u5c11\u504f\u5dee\u5e76\u5b9e\u73b0\u9002\u5f53\u8986\u76d6\u3002", "motivation": "\u76f4\u63a5\u5c06AI/ML\u9884\u6d4b\u7ed3\u679c\u4f5c\u4e3a\u771f\u5b9e\u89c2\u6d4b\u6570\u636e\u4f1a\u5bfc\u81f4\u6709\u504f\u7ed3\u679c\u548c\u9519\u8bef\u63a8\u65ad\uff0c\u867d\u5df2\u6709\u65b9\u6cd5\u4f46\u9700\u56de\u987eWang\u7b49\u4eba\u65b9\u6cd5\u5e76\u6539\u8fdb\u3002", "method": "\u53cd\u601dWang\u7b49\u4eba\u65b9\u6cd5\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u653e\u677e\u5047\u8bbe\u7684\u7b80\u5355\u6269\u5c55\u65b9\u6cd5\uff0c\u5305\u542b\u5728\u6807\u51c6\u6761\u4ef6\u4e0b\u5f97\u51fa\u65e0\u504f\u70b9\u4f30\u8ba1\u548c\u5f15\u5165\u7b80\u5355\u7f29\u653e\u56e0\u5b50\u3002", "result": "\u5728\u5927\u91cf\u6a21\u62df\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4fdd\u6301\u540d\u4e49\u4e00\u7c7b\u9519\u8bef\u7387\uff0c\u51cf\u5c11\u504f\u5dee\uff0c\u5b9e\u73b0\u9002\u5f53\u8986\u76d6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6269\u5c55\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u5904\u7406\u9884\u6d4b\u6570\u636e\u7684\u63a8\u65ad\u95ee\u9898\u3002"}}
{"id": "2507.10134", "pdf": "https://arxiv.org/pdf/2507.10134", "abs": "https://arxiv.org/abs/2507.10134", "authors": ["Yousef Emami", "Hao Zhou", "Miguel Gutierrez Gaitan", "Kai Li", "Luis Almeida"], "title": "FRSICL: LLM-Enabled In-Context Learning Flight Resource Allocation for Fresh Data Collection in UAV-Assisted Wildfire Monitoring", "categories": ["cs.AI", "53-01", "C.2"], "comment": "8 pages, 8 figures", "summary": "Unmanned Aerial Vehicles (UAVs) are vital for public safety, particularly in\nwildfire monitoring, where early detection minimizes environmental impact. In\nUAV-Assisted Wildfire Monitoring (UAWM) systems, joint optimization of sensor\ntransmission scheduling and velocity is critical for minimizing Age of\nInformation (AoI) from stale sensor data. Deep Reinforcement Learning (DRL) has\nbeen used for such optimization; however, its limitations such as low sampling\nefficiency, simulation-to-reality gaps, and complex training render it\nunsuitable for time-critical applications like wildfire monitoring. This paper\nintroduces a new online Flight Resource Allocation scheme based on LLM-Enabled\nIn-Context Learning (FRSICL) to jointly optimize the UAV's flight control and\ndata collection schedule along the trajectory in real time, thereby\nasymptotically minimizing the average AoI across ground sensors. In contrast to\nDRL, FRSICL generates data collection schedules and controls velocity using\nnatural language task descriptions and feedback from the environment, enabling\ndynamic decision-making without extensive retraining. Simulation results\nconfirm the effectiveness of the proposed FRSICL compared to Proximal Policy\nOptimization (PPO) and Nearest-Neighbor baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u5728\u7ebf\u98de\u884c\u8d44\u6e90\u5206\u914d\u65b9\u6848FRSICL\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u8f85\u52a9\u91ce\u706b\u76d1\u6d4b\u7cfb\u7edf\uff0c\u80fd\u5b9e\u65f6\u8054\u5408\u4f18\u5316\u98de\u884c\u63a7\u5236\u4e0e\u6570\u636e\u6536\u96c6\u8c03\u5ea6\uff0c\u6e10\u8fd1\u6700\u5c0f\u5316\u4f20\u611f\u5668\u5e73\u5747\u4fe1\u606f\u5e74\u9f84\uff0c\u4eff\u771f\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u65e0\u4eba\u673a\u8f85\u52a9\u91ce\u706b\u76d1\u6d4b\u7cfb\u7edf\u4e2d\u5b58\u5728\u4f4e\u91c7\u6837\u6548\u7387\u3001\u4eff\u771f\u4e0e\u73b0\u5b9e\u5dee\u8ddd\u3001\u8bad\u7ec3\u590d\u6742\u7b49\u95ee\u9898\uff0c\u4e0d\u9002\u5408\u65f6\u95f4\u5173\u952e\u7684\u91ce\u706b\u76d1\u6d4b\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u5728\u7ebf\u98de\u884c\u8d44\u6e90\u5206\u914d\u65b9\u6848FRSICL\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u548c\u73af\u5883\u53cd\u9988\u751f\u6210\u6570\u636e\u6536\u96c6\u8c03\u5ea6\u548c\u63a7\u5236\u901f\u5ea6\uff0c\u5b9e\u73b0\u52a8\u6001\u51b3\u7b56\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cFRSICL\u76f8\u6bd4\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u548c\u6700\u8fd1\u90bb\u57fa\u7ebf\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "conclusion": "FRSICL\u80fd\u6709\u6548\u89e3\u51b3\u65e0\u4eba\u673a\u8f85\u52a9\u91ce\u706b\u76d1\u6d4b\u7cfb\u7edf\u4e2d\u7684\u95ee\u9898\uff0c\u5728\u5b9e\u65f6\u98de\u884c\u63a7\u5236\u548c\u6570\u636e\u6536\u96c6\u8c03\u5ea6\u4f18\u5316\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.10228", "pdf": "https://arxiv.org/pdf/2507.10228", "abs": "https://arxiv.org/abs/2507.10228", "authors": ["Hugo Villamizar", "Daniel Mendez", "Marcos Kalinowski"], "title": "Towards a Framework for Operationalizing the Specification of Trustworthy AI Requirements", "categories": ["cs.SE"], "comment": "This paper has been accepted for presentation at the 2025 IEEE 33rd\n  International Requirements Engineering Conference Workshops (REW-RETRAI 2025)", "summary": "Growing concerns around the trustworthiness of AI-enabled systems highlight\nthe role of requirements engineering (RE) in addressing emergent,\ncontext-dependent properties that are difficult to specify without structured\napproaches. In this short vision paper, we propose the integration of two\ncomplementary approaches: AMDiRE, an artefact-based approach for RE, and\nPerSpecML, a perspective-based method designed to support the elicitation,\nanalysis, and specification of machine learning (ML)-enabled systems. AMDiRE\nprovides a structured, artefact-centric, process-agnostic methodology and\ntemplates that promote consistency and traceability in the results; however, it\nis primarily oriented toward deterministic systems. PerSpecML, in turn,\nintroduces multi-perspective guidance to uncover concerns arising from the\ndata-driven and non-deterministic behavior of ML-enabled systems. We envision a\npathway to operationalize trustworthiness-related requirements, bridging\nstakeholder-driven concerns and structured artefact models. We conclude by\noutlining key research directions and open challenges to be discussed with the\nRE community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06AMDiRE\u548cPerSpecML\u4e24\u79cd\u65b9\u6cd5\u96c6\u6210\uff0c\u4ee5\u89e3\u51b3AI\u7cfb\u7edf\u53ef\u4fe1\u6027\u9700\u6c42\u5de5\u7a0b\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u7814\u7a76\u65b9\u5411\u548c\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5bf9AI\u7cfb\u7edf\u53ef\u4fe1\u6027\u7684\u5173\u6ce8\u589e\u52a0\uff0c\u9700\u8981\u7ed3\u6784\u5316\u65b9\u6cd5\u6765\u5904\u7406\u96be\u4ee5\u6307\u5b9a\u7684\u65b0\u5174\u3001\u4f9d\u8d56\u4e0a\u4e0b\u6587\u7684\u5c5e\u6027\u3002", "method": "\u5c06\u57fa\u4e8e\u5236\u54c1\u7684AMDiRE\u65b9\u6cd5\u548c\u57fa\u4e8e\u89c6\u89d2\u7684PerSpecML\u65b9\u6cd5\u96c6\u6210\u3002", "result": "\u8bbe\u60f3\u4e86\u4e00\u6761\u5c06\u53ef\u4fe1\u6027\u76f8\u5173\u9700\u6c42\u843d\u5730\u7684\u9014\u5f84\uff0c\u8fde\u63a5\u5229\u76ca\u76f8\u5173\u8005\u7684\u5173\u6ce8\u70b9\u548c\u7ed3\u6784\u5316\u5236\u54c1\u6a21\u578b\u3002", "conclusion": "\u5217\u51fa\u4e86\u5173\u952e\u7814\u7a76\u65b9\u5411\u548c\u5f85\u4e0e\u9700\u6c42\u5de5\u7a0b\u793e\u533a\u8ba8\u8bba\u7684\u5f00\u653e\u6311\u6218\u3002"}}
{"id": "2507.09009", "pdf": "https://arxiv.org/pdf/2507.09009", "abs": "https://arxiv.org/abs/2507.09009", "authors": ["Zhengxiao He", "Huayu Li", "Geng Yuan", "William D. S. Killgore", "Stuart F. Quan", "Chen X. Chen", "Ao Li"], "title": "Multimodal Cardiovascular Risk Profiling Using Self-Supervised Learning of Polysomnography", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Methods: We developed a self-supervised deep learning model that extracts\nmeaningful patterns from multi-modal signals (Electroencephalography (EEG),\nElectrocardiography (ECG), and respiratory signals). The model was trained on\ndata from 4,398 participants. Projection scores were derived by contrasting\nembeddings from individuals with and without CVD outcomes. External validation\nwas conducted in an independent cohort with 1,093 participants. The source code\nis available on https://github.com/miraclehetech/sleep-ssl. Results: The\nprojection scores revealed distinct and clinically meaningful patterns across\nmodalities. ECG-derived features were predictive of both prevalent and incident\ncardiac conditions, particularly CVD mortality. EEG-derived features were\npredictive of incident hypertension and CVD mortality. Respiratory signals\nadded complementary predictive value. Combining these projection scores with\nthe Framingham Risk Score consistently improved predictive performance,\nachieving area under the curve values ranging from 0.607 to 0.965 across\ndifferent outcomes. Findings were robustly replicated and validated in the\nexternal testing cohort. Conclusion: Our findings demonstrate that the proposed\nframework can generate individualized CVD risk scores directly from PSG data.\nThe resulting projection scores have the potential to be integrated into\nclinical practice, enhancing risk assessment and supporting personalized care.", "AI": {"tldr": "\u5f00\u53d1\u81ea\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ece\u591a\u6a21\u6001\u4fe1\u53f7\u63d0\u53d6\u6a21\u5f0f\uff0c\u751f\u6210\u6295\u5f71\u5206\u6570\u9884\u6d4bCVD\u98ce\u9669\uff0c\u7ed3\u5408FRS\u6539\u5584\u9884\u6d4b\u6027\u80fd\uff0c\u6210\u679c\u53ef\u7528\u4e8e\u4e34\u5e8a\u3002", "motivation": "\u5f00\u53d1\u80fd\u76f4\u63a5\u4ece\u591a\u6a21\u6001\u4fe1\u53f7\u751f\u6210\u4e2a\u4f53\u5316CVD\u98ce\u9669\u8bc4\u5206\u7684\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u98ce\u9669\u8bc4\u4f30\u548c\u652f\u6301\u4e2a\u6027\u5316\u62a4\u7406\u3002", "method": "\u5f00\u53d1\u81ea\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u57284398\u540d\u53c2\u4e0e\u8005\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5bf9\u6bd4\u6709\u548c\u65e0CVD\u7ed3\u679c\u4e2a\u4f53\u7684\u5d4c\u5165\u751f\u6210\u6295\u5f71\u5206\u6570\uff0c\u57281093\u540d\u72ec\u7acb\u961f\u5217\u4e2d\u8fdb\u884c\u5916\u90e8\u9a8c\u8bc1\u3002", "result": "\u6295\u5f71\u5206\u6570\u5728\u5404\u6a21\u6001\u5448\u73b0\u4e0d\u540c\u4e14\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u6a21\u5f0f\uff0c\u4e0d\u540c\u4fe1\u53f7\u7279\u5f81\u5bf9\u4e0d\u540cCVD\u60c5\u51b5\u6709\u9884\u6d4b\u4ef7\u503c\uff0c\u7ed3\u5408FRS\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\uff0c\u7ed3\u679c\u5728\u5916\u90e8\u961f\u5217\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u4ecePSG\u6570\u636e\u751f\u6210\u4e2a\u4f53\u5316CVD\u98ce\u9669\u8bc4\u5206\uff0c\u6295\u5f71\u5206\u6570\u6709\u6f5c\u529b\u7528\u4e8e\u4e34\u5e8a\u5b9e\u8df5\u3002"}}
{"id": "2507.09127", "pdf": "https://arxiv.org/pdf/2507.09127", "abs": "https://arxiv.org/abs/2507.09127", "authors": ["Harshil Kotamreddy", "Marlos C. Machado"], "title": "A Study of Value-Aware Eigenoptions", "categories": ["cs.LG", "stat.ML"], "comment": "Presented at the RLC Workshop on Inductive Biases in Reinforcement\n  Learning 2025", "summary": "Options, which impose an inductive bias toward temporal and hierarchical\nstructure, offer a powerful framework for reinforcement learning (RL). While\neffective in sequential decision-making, they are often handcrafted rather than\nlearned. Among approaches for discovering options, eigenoptions have shown\nstrong performance in exploration, but their role in credit assignment remains\nunderexplored. In this paper, we investigate whether eigenoptions can\naccelerate credit assignment in model-free RL, evaluating them in tabular and\npixel-based gridworlds. We find that pre-specified eigenoptions aid not only\nexploration but also credit assignment, whereas online discovery can bias the\nagent's experience too strongly and hinder learning. In the context of deep RL,\nwe also propose a method for learning option-values under non-linear function\napproximation, highlighting the impact of termination conditions on\nperformance. Our findings reveal both the promise and complexity of using\neigenoptions, and options more broadly, to simultaneously support credit\nassignment and exploration in reinforcement learning.", "AI": {"tldr": "\u7814\u7a76\u672c\u5f81\u9009\u9879\u5728\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u52a0\u901f\u4fe1\u7528\u5206\u914d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u9884\u8bbe\u672c\u5f81\u9009\u9879\u6709\u5e2e\u52a9\uff0c\u5728\u7ebf\u53d1\u73b0\u53ef\u80fd\u963b\u788d\u5b66\u4e60\uff0c\u8fd8\u63d0\u51fa\u975e\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\u4e0b\u5b66\u4e60\u9009\u9879\u503c\u7684\u65b9\u6cd5\u3002", "motivation": "\u672c\u5f81\u9009\u9879\u5728\u63a2\u7d22\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u4fe1\u7528\u5206\u914d\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u7814\u7a76\u5176\u80fd\u5426\u52a0\u901f\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4fe1\u7528\u5206\u914d\u3002", "method": "\u5728\u57fa\u4e8e\u8868\u683c\u548c\u50cf\u7d20\u7684\u7f51\u683c\u4e16\u754c\u4e2d\u8bc4\u4f30\u672c\u5f81\u9009\u9879\uff0c\u63d0\u51fa\u975e\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\u4e0b\u5b66\u4e60\u9009\u9879\u503c\u7684\u65b9\u6cd5\u3002", "result": "\u9884\u8bbe\u672c\u5f81\u9009\u9879\u6709\u52a9\u4e8e\u63a2\u7d22\u548c\u4fe1\u7528\u5206\u914d\uff0c\u5728\u7ebf\u53d1\u73b0\u53ef\u80fd\u963b\u788d\u5b66\u4e60\uff0c\u5f3a\u8c03\u7ec8\u6b62\u6761\u4ef6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u672c\u5f81\u9009\u9879\u53ca\u66f4\u5e7f\u6cdb\u7684\u9009\u9879\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u652f\u6301\u4fe1\u7528\u5206\u914d\u548c\u63a2\u7d22\u6709\u524d\u666f\u4e5f\u6709\u590d\u6742\u6027\u3002"}}
{"id": "2507.10142", "pdf": "https://arxiv.org/pdf/2507.10142", "abs": "https://arxiv.org/abs/2507.10142", "authors": ["Siyi Hu", "Mohamad A Hady", "Jianglin Qiao", "Jimmy Cao", "Mahardhika Pratama", "Ryszard Kowalczyk"], "title": "Adaptability in Multi-Agent Reinforcement Learning: A Framework and Unified Review", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-Agent Reinforcement Learning (MARL) has shown clear effectiveness in\ncoordinating multiple agents across simulated benchmarks and constrained\nscenarios. However, its deployment in real-world multi-agent systems (MAS)\nremains limited, primarily due to the complex and dynamic nature of such\nenvironments. These challenges arise from multiple interacting sources of\nvariability, including fluctuating agent populations, evolving task goals, and\ninconsistent execution conditions. Together, these factors demand that MARL\nalgorithms remain effective under continuously changing system configurations\nand operational demands. To better capture and assess this capacity for\nadjustment, we introduce the concept of \\textit{adaptability} as a unified and\npractically grounded lens through which to evaluate the reliability of MARL\nalgorithms under shifting conditions, broadly referring to any changes in the\nenvironment dynamics that may occur during learning or execution. Centred on\nthe notion of adaptability, we propose a structured framework comprising three\nkey dimensions: learning adaptability, policy adaptability, and scenario-driven\nadaptability. By adopting this adaptability perspective, we aim to support more\nprincipled assessments of MARL performance beyond narrowly defined benchmarks.\nUltimately, this survey contributes to the development of algorithms that are\nbetter suited for deployment in dynamic, real-world multi-agent systems.", "AI": {"tldr": "\u4ecb\u7ecd\u9002\u5e94\u6027\u6982\u5ff5\u8bc4\u4f30MARL\u7b97\u6cd5\u53ef\u9760\u6027\uff0c\u63d0\u51fa\u7ed3\u6784\u5316\u6846\u67b6\u5e76\u52a9\u529b\u5f00\u53d1\u9002\u7528\u4e8e\u73b0\u5b9e\u73af\u5883\u7684\u7b97\u6cd5\u3002", "motivation": "MARL\u5728\u73b0\u5b9e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u90e8\u7f72\u53d7\u9650\uff0c\u56e0\u73af\u5883\u590d\u6742\u52a8\u6001\uff0c\u9700\u8bc4\u4f30\u7b97\u6cd5\u5728\u53d8\u5316\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165\u9002\u5e94\u6027\u6982\u5ff5\uff0c\u63d0\u51fa\u5305\u542b\u5b66\u4e60\u9002\u5e94\u6027\u3001\u7b56\u7565\u9002\u5e94\u6027\u548c\u573a\u666f\u9a71\u52a8\u9002\u5e94\u6027\u4e09\u4e2a\u7ef4\u5ea6\u7684\u7ed3\u6784\u5316\u6846\u67b6\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c", "conclusion": "\u8be5\u7814\u7a76\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u9002\u5408\u90e8\u7f72\u5728\u52a8\u6001\u73b0\u5b9e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u7b97\u6cd5\u3002"}}
{"id": "2507.10235", "pdf": "https://arxiv.org/pdf/2507.10235", "abs": "https://arxiv.org/abs/2507.10235", "authors": ["Zhixiang Chen", "Zhuangbin Chen", "Xingjie Cai", "Wei Li", "Zibin Zheng"], "title": "An Empirical Study of Interaction Bugs in ROS-based Software", "categories": ["cs.SE"], "comment": null, "summary": "Modern robotic systems integrate multiple independent software and hardware\ncomponents, each responsible for distinct functionalities such as perception,\ndecision-making, and execution. These components interact extensively to\naccomplish complex end-to-end tasks. As a result, the overall system\nreliability depends not only on the correctness of individual components, but\nalso on the correctness of their interactions. Failures often manifest at the\nboundaries between components, yet interaction-related reliability issues in\nrobotics--referred to here as interaction bugs (iBugs)--remain underexplored.\n  This work presents an empirical study of iBugs within robotic systems built\nusing the Robot Operating System (ROS), a widely adopted open-source robotics\nframework. A total of 121 iBugs were analyzed across ten actively maintained\nand representative ROS projects. The identified iBugs are categorized into\nthree major types: intra-system iBugs, hardware iBugs, and environmental iBugs,\ncovering a broad range of interaction scenarios in robotics. The analysis\nincludes an examination of root causes, fixing strategies, and the impact of\nthese bugs. Several findingsa are derived that shed light on the nature of\niBugs and suggest directions for improving their prevention and detection.\nThese insights aim to inform the design of more robust and safer robotic\nsystems.", "AI": {"tldr": "\u672c\u6587\u5bf9ROS\u673a\u5668\u4eba\u7cfb\u7edf\u4e2d\u7684\u4ea4\u4e92\u9519\u8bef\uff08iBugs\uff09\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790121\u4e2aiBugs\u5e76\u5206\u7c7b\uff0c\u5f97\u51fa\u6539\u5584\u9884\u9632\u548c\u68c0\u6d4b\u7684\u65b9\u5411\u3002", "motivation": "\u673a\u5668\u4eba\u7cfb\u7edf\u53ef\u9760\u6027\u4f9d\u8d56\u7ec4\u4ef6\u4ea4\u4e92\uff0c\u4f46\u4ea4\u4e92\u76f8\u5173\u53ef\u9760\u6027\u95ee\u9898\uff08iBugs\uff09\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u6df1\u5165\u63a2\u7d22\u3002", "method": "\u5bf9\u5341\u4e2a\u6d3b\u8dc3\u7ef4\u62a4\u4e14\u6709\u4ee3\u8868\u6027\u7684ROS\u9879\u76ee\u4e2d\u7684121\u4e2aiBugs\u8fdb\u884c\u5206\u6790\uff0c\u5c06\u5176\u5206\u7c7b\u5e76\u7814\u7a76\u6839\u6e90\u3001\u4fee\u590d\u7b56\u7565\u548c\u5f71\u54cd\u3002", "result": "iBugs\u5206\u4e3a\u7cfb\u7edf\u5185\u3001\u786c\u4ef6\u548c\u73af\u5883\u4e09\u7c7b\uff0c\u6db5\u76d6\u591a\u79cd\u4ea4\u4e92\u573a\u666f\uff0c\u5f97\u51fa\u4e86\u5173\u4e8eiBugs\u6027\u8d28\u7684\u53d1\u73b0\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u66f4\u5f3a\u5927\u3001\u66f4\u5b89\u5168\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2507.09016", "pdf": "https://arxiv.org/pdf/2507.09016", "abs": "https://arxiv.org/abs/2507.09016", "authors": ["Karim Galliamov", "Ivan Titov", "Ilya Pershin"], "title": "Enhancing RLHF with Human Gaze Modeling", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) aligns language models with\nhuman preferences but is computationally expensive. We explore two approaches\nthat leverage human gaze modeling to enhance RLHF: (1) gaze-aware reward models\nand (2) gaze-based distribution of sparse rewards at token level. Our\nexperiments demonstate that gaze-informed RLHF achieves faster convergence\nwhile maintaining or slightly improving performance, thus, reducing\ncomputational costs during policy optimization. These results show that human\ngaze provides a valuable and underused signal for policy optimization, pointing\nto a promising direction for improving RLHF efficiency.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5229\u7528\u4eba\u7c7b\u6ce8\u89c6\u5efa\u6a21\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u4ece\u4eba\u7c7b\u53cd\u9988\uff08RLHF\uff09\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u6ce8\u89c6\u4fe1\u606f\u7684RLHF\u53ef\u52a0\u901f\u6536\u655b\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u6307\u51fa\u6539\u8fdbRLHF\u6548\u7387\u7684\u65b9\u5411\u3002", "motivation": "RLHF\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u63a2\u7d22\u4e24\u79cd\u5229\u7528\u4eba\u7c7b\u6ce8\u89c6\u5efa\u6a21\u589e\u5f3aRLHF\u7684\u65b9\u6cd5\uff1a\u6ce8\u89c6\u611f\u77e5\u5956\u52b1\u6a21\u578b\u548c\u57fa\u4e8e\u6ce8\u89c6\u7684\u7a00\u758f\u5956\u52b1\u5728\u6807\u8bb0\u7ea7\u7684\u5206\u5e03\u3002", "result": "\u6ce8\u89c6\u4fe1\u606f\u7684RLHF\u80fd\u66f4\u5feb\u6536\u655b\uff0c\u4fdd\u6301\u6216\u7565\u63d0\u9ad8\u6027\u80fd\uff0c\u964d\u4f4e\u7b56\u7565\u4f18\u5316\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u4eba\u7c7b\u6ce8\u89c6\u4e3a\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u6709\u4ef7\u503c\u4e14\u672a\u5145\u5206\u5229\u7528\u7684\u4fe1\u53f7\uff0c\u662f\u6539\u8fdbRLHF\u6548\u7387\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2507.09177", "pdf": "https://arxiv.org/pdf/2507.09177", "abs": "https://arxiv.org/abs/2507.09177", "authors": ["Zichen Liu", "Guoji Fu", "Chao Du", "Wee Sun Lee", "Min Lin"], "title": "Continual Reinforcement Learning by Planning with Online World Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "ICML 2025 Spotlight", "summary": "Continual reinforcement learning (CRL) refers to a naturalistic setting where\nan agent needs to endlessly evolve, by trial and error, to solve multiple tasks\nthat are presented sequentially. One of the largest obstacles to CRL is that\nthe agent may forget how to solve previous tasks when learning a new task,\nknown as catastrophic forgetting. In this paper, we propose to address this\nchallenge by planning with online world models. Specifically, we learn a\nFollow-The-Leader shallow model online to capture the world dynamics, in which\nwe plan using model predictive control to solve a set of tasks specified by any\nreward functions. The online world model is immune to forgetting by\nconstruction with a proven regret bound of $\\mathcal{O}(\\sqrt{K^2D\\log(T)})$\nunder mild assumptions. The planner searches actions solely based on the latest\nonline model, thus forming a FTL Online Agent (OA) that updates incrementally.\nTo assess OA, we further design Continual Bench, a dedicated environment for\nCRL, and compare with several strong baselines under the same model-planning\nalgorithmic framework. The empirical results show that OA learns continuously\nto solve new tasks while not forgetting old skills, outperforming agents built\non deep world models with various continual learning techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5728\u7ebf\u4e16\u754c\u6a21\u578b\u89c4\u5212\u89e3\u51b3\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86FTL\u5728\u7ebf\u4ee3\u7406\uff08OA\uff09\u5e76\u5728\u4e13\u7528\u73af\u5883Continual Bench\u4e2d\u9a8c\u8bc1\u5176\u6548\u679c\u4f18\u4e8e\u57fa\u4e8e\u6df1\u5ea6\u4e16\u754c\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "motivation": "\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u667a\u80fd\u4f53\u5b66\u4e60\u65b0\u4efb\u52a1\u65f6\u4f1a\u5fd8\u8bb0\u4e4b\u524d\u4efb\u52a1\u7684\u89e3\u51b3\u65b9\u6cd5\uff0c\u5373\u707e\u96be\u6027\u9057\u5fd8\uff0c\u8fd9\u662f\u8be5\u9886\u57df\u7684\u4e00\u5927\u969c\u788d\u3002", "method": "\u5b66\u4e60Follow - The - Leader\u6d45\u5c42\u6a21\u578b\u6765\u6355\u6349\u4e16\u754c\u52a8\u6001\uff0c\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u8fdb\u884c\u89c4\u5212\u4ee5\u89e3\u51b3\u7531\u4efb\u610f\u5956\u52b1\u51fd\u6570\u6307\u5b9a\u7684\u4efb\u52a1\u96c6\uff0c\u5f62\u6210FTL\u5728\u7ebf\u4ee3\u7406\uff08OA\uff09\uff0c\u5e76\u8bbe\u8ba1Continual Bench\u73af\u5883\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ecf\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOA\u80fd\u6301\u7eed\u5b66\u4e60\u89e3\u51b3\u65b0\u4efb\u52a1\u4e14\u4e0d\u5fd8\u65e7\u6280\u80fd\uff0c\u4f18\u4e8e\u4f7f\u7528\u5404\u79cd\u6301\u7eed\u5b66\u4e60\u6280\u672f\u7684\u57fa\u4e8e\u6df1\u5ea6\u4e16\u754c\u6a21\u578b\u7684\u667a\u80fd\u4f53\u3002", "conclusion": "\u4f7f\u7528\u5728\u7ebf\u4e16\u754c\u6a21\u578b\u89c4\u5212\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002"}}
{"id": "2507.10156", "pdf": "https://arxiv.org/pdf/2507.10156", "abs": "https://arxiv.org/abs/2507.10156", "authors": ["Lubnaa Abdur Rahman", "Ioannis Papathanail", "Stavroula Mougiakakou"], "title": "Introducing the Swiss Food Knowledge Graph: AI for Context-Aware Nutrition Recommendation", "categories": ["cs.AI"], "comment": "10 pages, 2 Figures, 7 tables", "summary": "AI has driven significant progress in the nutrition field, especially through\nmultimedia-based automatic dietary assessment. However, existing automatic\ndietary assessment systems often overlook critical non-visual factors, such as\nrecipe-specific ingredient substitutions that can significantly alter\nnutritional content, and rarely account for individual dietary needs, including\nallergies, restrictions, cultural practices, and personal preferences. In\nSwitzerland, while food-related information is available, it remains\nfragmented, and no centralized repository currently integrates all relevant\nnutrition-related aspects within a Swiss context. To bridge this divide, we\nintroduce the Swiss Food Knowledge Graph (SwissFKG), the first resource, to our\nbest knowledge, to unite recipes, ingredients, and their substitutions with\nnutrient data, dietary restrictions, allergen information, and national\nnutrition guidelines under one graph. We establish a LLM-powered enrichment\npipeline for populating the graph, whereby we further present the first\nbenchmark of four off-the-shelf (<70 B parameter) LLMs for food knowledge\naugmentation. Our results demonstrate that LLMs can effectively enrich the\ngraph with relevant nutritional information. Our SwissFKG goes beyond recipe\nrecommendations by offering ingredient-level information such as allergen and\ndietary restriction information, and guidance aligned with nutritional\nguidelines. Moreover, we implement a Graph-RAG application to showcase how the\nSwissFKG's rich natural-language data structure can help LLM answer\nuser-specific nutrition queries, and we evaluate LLM-embedding pairings by\ncomparing user-query responses against predefined expected answers. As such,\nour work lays the foundation for the next generation of dietary assessment\ntools that blend visual, contextual, and cultural dimensions of eating.", "AI": {"tldr": "\u4ecb\u7ecd\u745e\u58eb\u98df\u7269\u77e5\u8bc6\u56fe\u8c31SwissFKG\uff0c\u5efa\u7acbLLM\u9a71\u52a8\u7684\u56fe\u8c31\u586b\u5145\u7ba1\u9053\uff0c\u5c55\u793a\u5176\u5728\u8425\u517b\u67e5\u8be2\u7b49\u65b9\u9762\u5e94\u7528\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u996e\u98df\u8bc4\u4f30\u5de5\u5177\u5960\u57fa\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u996e\u98df\u8bc4\u4f30\u7cfb\u7edf\u5ffd\u89c6\u975e\u89c6\u89c9\u56e0\u7d20\u548c\u4e2a\u4f53\u996e\u98df\u9700\u6c42\uff0c\u745e\u58eb\u7f3a\u4e4f\u6574\u5408\u8425\u517b\u76f8\u5173\u65b9\u9762\u7684\u96c6\u4e2d\u5e93\u3002", "method": "\u5f15\u5165SwissFKG\uff0c\u5efa\u7acbLLM\u9a71\u52a8\u7684\u56fe\u8c31\u586b\u5145\u7ba1\u9053\uff0c\u8fdb\u884cLLM\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u73b0Graph - RAG\u5e94\u7528\u5e76\u8bc4\u4f30LLM - \u5d4c\u5165\u914d\u5bf9\u3002", "result": "LLMs\u80fd\u6709\u6548\u7528\u76f8\u5173\u8425\u517b\u4fe1\u606f\u4e30\u5bcc\u56fe\u8c31\uff0cSwissFKG\u53ef\u63d0\u4f9b\u6210\u5206\u7ea7\u4fe1\u606f\u548c\u8425\u517b\u6307\u5357\u76f8\u5173\u6307\u5bfc\u3002", "conclusion": "\u5de5\u4f5c\u4e3a\u878d\u5408\u996e\u98df\u89c6\u89c9\u3001\u80cc\u666f\u548c\u6587\u5316\u7ef4\u5ea6\u7684\u4e0b\u4e00\u4ee3\u996e\u98df\u8bc4\u4f30\u5de5\u5177\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.10244", "pdf": "https://arxiv.org/pdf/2507.10244", "abs": "https://arxiv.org/abs/2507.10244", "authors": ["Adam \u0160t\u011bp\u00e1nek", "David Ku\u0165\u00e1k", "Barbora Kozl\u00edkov\u00e1", "Jan By\u0161ka"], "title": "Helveg: Diagrams for Software Documentation", "categories": ["cs.SE", "D.2.2; D.2.11"], "comment": "13 pages, 5 figures, accepted by TVCG", "summary": "Software developers often have to gain an understanding of a codebase. Be it\nprogrammers getting onboarded onto a team project or, for example, developers\nstriving to grasp an external open-source library. In either case, they\nfrequently turn to the project's documentation. However, documentation in its\ntraditional textual form is ill-suited for this kind of high-level exploratory\nanalysis, since it is immutable from the readers' perspective and thus forces\nthem to follow a predefined path. We have designed an approach bringing aspects\nof software architecture visualization to API reference documentation. It\nutilizes a highly interactive node-link diagram with expressive node glyphs and\nflexible filtering capabilities, providing a high-level overview of the\ncodebase as well as details on demand. To test our design, we have implemented\na prototype named Helveg, capable of automatically generating diagrams of C\\#\ncodebases. User testing of Helveg confirmed its potential, but it also revealed\nproblems with the readability, intuitiveness, and user experience of our tool.\nTherefore, in this paper, which is an extended version of our VISSOFT paper\nwith DOI 10.1109/VISSOFT64034.2024.00012, we address many of these problems\nthrough major changes to the glyph design, means of interaction, and user\ninterface of the tool. To assess the improvements, this new version of Helveg\nwas evaluated again with the same group of participants as the previous\nversion.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u5c06\u8f6f\u4ef6\u67b6\u6784\u53ef\u89c6\u5316\u5f15\u5165 API \u53c2\u8003\u6587\u6863\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u539f\u578b Helveg\uff0c\u521d\u6d4b\u6709\u95ee\u9898\uff0c\u6539\u8fdb\u540e\u518d\u6b21\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u5f62\u5f0f\u7684\u6587\u6863\u4e0d\u9002\u5408\u9ad8\u5c42\u63a2\u7d22\u6027\u5206\u6790\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u4ee3\u7801\u5e93\u3002", "method": "\u8bbe\u8ba1\u5c06\u8f6f\u4ef6\u67b6\u6784\u53ef\u89c6\u5316\u5f15\u5165 API \u53c2\u8003\u6587\u6863\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u539f\u578b Helveg\uff0c\u6539\u8fdb\u5176\u5b57\u5f62\u8bbe\u8ba1\u3001\u4ea4\u4e92\u65b9\u5f0f\u548c\u7528\u6237\u754c\u9762\u3002", "result": "\u521d\u6d4b\u663e\u793a Helveg \u6709\u53ef\u8bfb\u6027\u3001\u76f4\u89c2\u6027\u548c\u7528\u6237\u4f53\u9a8c\u95ee\u9898\uff0c\u6539\u8fdb\u540e\u518d\u6b21\u8bc4\u4f30\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u6700\u7ec8\u7ed3\u8bba\uff0c\u4f46\u901a\u8fc7\u6539\u8fdb\u548c\u518d\u6b21\u8bc4\u4f30\u6765\u89e3\u51b3\u521d\u6d4b\u95ee\u9898\u3002"}}
{"id": "2507.09178", "pdf": "https://arxiv.org/pdf/2507.09178", "abs": "https://arxiv.org/abs/2507.09178", "authors": ["Liang Ding", "Simon Mak", "C. F. Jeff Wu"], "title": "The BdryMat\u00e9rn GP: Reliable incorporation of boundary information on irregular domains for Gaussian process modeling", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Gaussian processes (GPs) are broadly used as surrogate models for expensive\ncomputer simulators of complex phenomena. However, a key bottleneck is that its\ntraining data are generated from this expensive simulator and thus can be\nhighly limited. A promising solution is to supplement the learning model with\nboundary information from scientific knowledge. However, despite recent work on\nboundary-integrated GPs, such models largely cannot accommodate boundary\ninformation on irregular (i.e., non-hypercube) domains, and do not provide\nsample path smoothness control or approximation error analysis, both of which\nare important for reliable surrogate modeling. We thus propose a novel\nBdryMat\\'ern GP modeling framework, which can reliably integrate Dirichlet,\nNeumann and Robin boundaries on an irregular connected domain with a boundary\nset that is twice-differentiable almost everywhere. Our model leverages a new\nBdryMat\\'ern covariance kernel derived in path integral form via a stochastic\npartial differential equation formulation. Similar to the GP with Mat\\'ern\nkernel, we prove that sample paths from the BdryMat\\'ern GP satisfy the desired\nboundaries with smoothness control on its derivatives. We further present an\nefficient approximation procedure for the BdryMat\\'ern kernel using finite\nelement modeling with rigorous error analysis. Finally, we demonstrate the\neffectiveness of the BdryMat\\'ern GP in a suite of numerical experiments on\nincorporating broad boundaries on irregular domains.", "AI": {"tldr": "\u63d0\u51faBdryMat\u00e9rn GP\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u89c4\u5219\u57df\u4e0a\u6574\u5408\u8fb9\u754c\u4fe1\u606f\uff0c\u8bc1\u660e\u6837\u672c\u8def\u5f84\u7279\u6027\uff0c\u7ed9\u51fa\u8fd1\u4f3c\u8fc7\u7a0b\u548c\u8bef\u5dee\u5206\u6790\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\u8bad\u7ec3\u6570\u636e\u6709\u9650\uff0c\u73b0\u6709\u8fb9\u754c\u96c6\u6210\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u5b58\u5728\u4e0d\u80fd\u9002\u5e94\u4e0d\u89c4\u5219\u57df\u3001\u7f3a\u4e4f\u6837\u672c\u8def\u5f84\u5e73\u6ed1\u63a7\u5236\u548c\u8fd1\u4f3c\u8bef\u5dee\u5206\u6790\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faBdryMat\u00e9rn GP\u5efa\u6a21\u6846\u67b6\uff0c\u5229\u7528\u901a\u8fc7\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b\u516c\u5f0f\u63a8\u5bfc\u7684BdryMat\u00e9rn\u534f\u65b9\u5dee\u6838\uff0c\u4f7f\u7528\u6709\u9650\u5143\u5efa\u6a21\u8fdb\u884c\u8fd1\u4f3c\u5e76\u8fdb\u884c\u8bef\u5dee\u5206\u6790\u3002", "result": "\u8bc1\u660eBdryMat\u00e9rn GP\u6837\u672c\u8def\u5f84\u6ee1\u8db3\u8fb9\u754c\u6761\u4ef6\u4e14\u6709\u5bfc\u6570\u5e73\u6ed1\u63a7\u5236\uff0c\u7ed9\u51fa\u9ad8\u6548\u8fd1\u4f3c\u8fc7\u7a0b\u548c\u8bef\u5dee\u5206\u6790\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "BdryMat\u00e9rn GP\u6846\u67b6\u80fd\u6709\u6548\u5728\u4e0d\u89c4\u5219\u57df\u4e0a\u6574\u5408\u591a\u79cd\u8fb9\u754c\u4fe1\u606f\u3002"}}
{"id": "2507.10174", "pdf": "https://arxiv.org/pdf/2507.10174", "abs": "https://arxiv.org/abs/2507.10174", "authors": ["Yumi Omori", "Zixuan Dong", "Keith Ross"], "title": "Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted by RLBrew: Ingredients for Developing Generalist Agents\n  workshop (RLC 2025)", "summary": "In recent years, extensive work has explored the application of the\nTransformer architecture to reinforcement learning problems. Among these,\nDecision Transformer (DT) has gained particular attention in the context of\noffline reinforcement learning due to its ability to frame return-conditioned\npolicy learning as a sequence modeling task. Most recently, Bhargava et al.\n(2024) provided a systematic comparison of DT with more conventional MLP-based\noffline RL algorithms, including Behavior Cloning (BC) and Conservative\nQ-Learning (CQL), and claimed that DT exhibits superior performance in\nsparse-reward and low-quality data settings.\n  In this paper, through experimentation on robotic manipulation tasks\n(Robomimic) and locomotion benchmarks (D4RL), we show that MLP-based Filtered\nBehavior Cloning (FBC) achieves competitive or superior performance compared to\nDT in sparse-reward environments. FBC simply filters out low-performing\ntrajectories from the dataset and then performs ordinary behavior cloning on\nthe filtered dataset. FBC is not only very straightforward, but it also\nrequires less training data and is computationally more efficient. The results\ntherefore suggest that DT is not preferable for sparse-reward environments.\nFrom prior work, arguably, DT is also not preferable for dense-reward\nenvironments. Thus, we pose the question: Is DT ever preferable?", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\uff0c\u57fa\u4e8eMLP\u7684\u8fc7\u6ee4\u884c\u4e3a\u514b\u9686\uff08FBC\uff09\u6bd4\u51b3\u7b56\u53d8\u538b\u5668\uff08DT\uff09\u6027\u80fd\u66f4\u4f18\uff0c\u8d28\u7591DT\u7684\u9002\u7528\u6027\u3002", "motivation": "Bhargava\u7b49\u4eba\uff082024\uff09\u79f0DT\u5728\u7a00\u758f\u5956\u52b1\u548c\u4f4e\u8d28\u91cf\u6570\u636e\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u672c\u6587\u5bf9\u6b64\u8fdb\u884c\u9a8c\u8bc1\u5e76\u63a2\u7d22\u66f4\u4f18\u7b97\u6cd5\u3002", "method": "\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\uff08Robomimic\uff09\u548c\u8fd0\u52a8\u57fa\u51c6\u6d4b\u8bd5\uff08D4RL\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528FBC\uff08\u8fc7\u6ee4\u4f4e\u6027\u80fd\u8f68\u8ff9\u540e\u8fdb\u884c\u884c\u4e3a\u514b\u9686\uff09\u4e0eDT\u5bf9\u6bd4\u3002", "result": "FBC\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u8fbe\u5230\u4e86\u4e0eDT\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u4e14\u6240\u9700\u8bad\u7ec3\u6570\u636e\u66f4\u5c11\u3001\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "DT\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u5e76\u975e\u9996\u9009\uff0c\u7ed3\u5408\u5148\u524d\u7814\u7a76\uff0c\u63d0\u51faDT\u662f\u5426\u6709\u9002\u7528\u573a\u666f\u7684\u7591\u95ee\u3002"}}
{"id": "2507.10305", "pdf": "https://arxiv.org/pdf/2507.10305", "abs": "https://arxiv.org/abs/2507.10305", "authors": ["Linus Ververs", "Trang Linh Lam", "Janina Berger", "Lutz Prechelt"], "title": "A Grounded Theory on the Teacher and Student Roles in Pair Programming", "categories": ["cs.SE"], "comment": null, "summary": "Context: Pair programming is an established (agile) practice and is practiced\nthroughout the industry. Objective: Understand under what circumstances\nknowledge transfer can harm a pair programming session. Method: Grounded Theory\nMethodology based on 17 recorded pair programming sessions with 18 developers\nfrom 5 German software companies accompanied, by 6 interviews with different\ndevelopers from 4 other German companies. Results: We define the student and\nteacher roles to help developers deal with a one-sided knowledge gap. We\ndescribe pitfalls to avoid and develop a grounded theory centered around the\nPower Gap in pair programming. Conclusions: Knowledge transfer can be harmful\nwhen developers don't pay attention to their partners needs and desires. If\ndevelopers don't pay attention to the Power Gap and keep it in check, Defensive\nBehavior may arise that leads to a vicious cycle impacting the knowledge\ntransfer, the Togetherness and the code quality in a negative way.", "AI": {"tldr": "\u7814\u7a76\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u77e5\u8bc6\u8f6c\u79fb\u4f55\u65f6\u4f1a\u4ea7\u751f\u5371\u5bb3\uff0c\u5b9a\u4e49\u89d2\u8272\u3001\u63cf\u8ff0\u9677\u9631\u5e76\u63d0\u51fa\u624e\u6839\u7406\u8bba\u3002", "motivation": "\u4e86\u89e3\u7ed3\u5bf9\u7f16\u7a0b\u4e2d\u77e5\u8bc6\u8f6c\u79fb\u5728\u4f55\u79cd\u60c5\u51b5\u4e0b\u4f1a\u5bf9\u7f16\u7a0b\u8fc7\u7a0b\u9020\u6210\u5371\u5bb3\u3002", "method": "\u91c7\u7528\u624e\u6839\u7406\u8bba\u65b9\u6cd5\uff0c\u5bf95\u5bb6\u5fb7\u56fd\u8f6f\u4ef6\u516c\u53f8\u768418\u540d\u5f00\u53d1\u8005\u768417\u6b21\u7ed3\u5bf9\u7f16\u7a0b\u4f1a\u8bdd\u8fdb\u884c\u8bb0\u5f55\uff0c\u5e76\u5bf9\u53e6\u59164\u5bb6\u516c\u53f8\u7684\u4e0d\u540c\u5f00\u53d1\u8005\u8fdb\u884c6\u6b21\u8bbf\u8c08\u3002", "result": "\u5b9a\u4e49\u5b66\u751f\u548c\u6559\u5e08\u89d2\u8272\u4ee5\u5e94\u5bf9\u77e5\u8bc6\u5dee\u8ddd\uff0c\u63cf\u8ff0\u5e94\u907f\u514d\u7684\u9677\u9631\uff0c\u56f4\u7ed5\u6743\u529b\u5dee\u8ddd\u5f62\u6210\u624e\u6839\u7406\u8bba\u3002", "conclusion": "\u5f00\u53d1\u8005\u82e5\u4e0d\u5173\u6ce8\u4f19\u4f34\u9700\u6c42\u548c\u6743\u529b\u5dee\u8ddd\uff0c\u77e5\u8bc6\u8f6c\u79fb\u53ef\u80fd\u6709\u5bb3\uff0c\u4f1a\u5f15\u53d1\u9632\u5fa1\u884c\u4e3a\u5e76\u5f62\u6210\u6076\u6027\u5faa\u73af\uff0c\u5bf9\u77e5\u8bc6\u8f6c\u79fb\u3001\u534f\u4f5c\u548c\u4ee3\u7801\u8d28\u91cf\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2507.09029", "pdf": "https://arxiv.org/pdf/2507.09029", "abs": "https://arxiv.org/abs/2507.09029", "authors": ["Vaibhav Singh", "Zafir Khalid", "Edouard Oyallon", "Eugene Belilovsky"], "title": "Model Parallelism With Subnetwork Data Parallelism", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 1 figure", "summary": "Distributed pre-training of large models at scale often imposes heavy memory\ndemands on individual nodes and incurs significant intra-node communication\ncosts. We propose a novel alternative approach that reduces the memory\nrequirements by training small, structured subnetworks of the model on separate\nworkers. Unlike pipelining, our method avoids inter-node activation\ncommunication and maintains bandwidth requirements that are comparable to or\nlower than standard data parallel communication schemes based on all-reduce. We\nevaluate two subnetwork construction strategies guided by the principle of\nensuring uniform representation of each parameter across the distributed\ntraining setup. Our results show that the stochastic block dropping technique\nconsistently outperforms the width-wise subnetwork construction previously\nexplored in federated learning. We empirically attribute this superior\nperformance to stronger gradient alignment in subnetworks that retain blocks\nhaving skip connections. Preliminary experiments highlight the promise of our\napproach, achieving a 20-40% reduction in memory usage without any loss in\nperformance.", "AI": {"tldr": "\u63d0\u51fa\u5728\u72ec\u7acb\u5de5\u4f5c\u8282\u70b9\u8bad\u7ec3\u6a21\u578b\u7684\u5c0f\u578b\u7ed3\u6784\u5316\u5b50\u7f51\u7edc\u4ee5\u51cf\u5c11\u5185\u5b58\u9700\u6c42\uff0c\u8bc4\u4f30\u4e24\u79cd\u5b50\u7f51\u7edc\u6784\u5efa\u7b56\u7565\uff0c\u968f\u673a\u5757\u4e22\u5f03\u6280\u672f\u8868\u73b0\u66f4\u4f18\uff0c\u80fd\u51cf\u5c1120 - 40%\u5185\u5b58\u4f7f\u7528\u4e14\u4e0d\u635f\u5931\u6027\u80fd\u3002", "motivation": "\u5206\u5e03\u5f0f\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u5bf9\u5355\u4e2a\u8282\u70b9\u5185\u5b58\u8981\u6c42\u9ad8\u4e14\u8282\u70b9\u5185\u901a\u4fe1\u6210\u672c\u5927\uff0c\u9700\u65b0\u65b9\u6cd5\u964d\u4f4e\u5185\u5b58\u9700\u6c42\u3002", "method": "\u5728\u72ec\u7acb\u5de5\u4f5c\u8282\u70b9\u8bad\u7ec3\u6a21\u578b\u7684\u5c0f\u578b\u7ed3\u6784\u5316\u5b50\u7f51\u7edc\uff0c\u8bc4\u4f30\u57fa\u4e8e\u53c2\u6570\u5747\u5300\u8868\u793a\u539f\u5219\u7684\u4e24\u79cd\u5b50\u7f51\u7edc\u6784\u5efa\u7b56\u7565\u3002", "result": "\u968f\u673a\u5757\u4e22\u5f03\u6280\u672f\u4f18\u4e8e\u5bbd\u5ea6\u65b9\u5411\u5b50\u7f51\u7edc\u6784\u5efa\uff0c\u5f52\u56e0\u4e8e\u4fdd\u7559\u6709\u8df3\u8dc3\u8fde\u63a5\u5757\u7684\u5b50\u7f51\u7edc\u68af\u5ea6\u5bf9\u9f50\u66f4\u5f3a\uff0c\u521d\u6b65\u5b9e\u9a8c\u5b9e\u73b020 - 40%\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\u4e14\u65e0\u6027\u80fd\u635f\u5931\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u524d\u666f\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u4e14\u4e0d\u5f71\u54cd\u6027\u80fd\u3002"}}
{"id": "2507.09211", "pdf": "https://arxiv.org/pdf/2507.09211", "abs": "https://arxiv.org/abs/2507.09211", "authors": ["Xinyue Liu", "Xiao Peng", "Shuyue Yan", "Yuntian Chen", "Dongxiao Zhang", "Zhixiao Niu", "Hui-Min Wang", "Xiaogang He"], "title": "Capturing Unseen Spatial Extremes Through Knowledge-Informed Generative Modeling", "categories": ["cs.LG", "physics.ao-ph", "physics.data-an", "physics.geo-ph", "stat.ML"], "comment": null, "summary": "Observed records of climate extremes provide an incomplete picture of risk,\nmissing \"unseen\" extremes that exceed historical bounds. In parallel,\nneglecting spatial dependence undervalues the risk of synchronized hazards that\namplify impacts. To address these challenges, we develop DeepX-GAN\n(Dependence-Enhanced Embedding for Physical eXtremes - Generative Adversarial\nNetwork), a knowledge-informed deep generative model designed to better capture\nthe spatial structure of rare extremes. The zero-shot generalizability of\nDeepX-GAN enables simulation of unseen extremes that fall outside historical\nexperience yet remain statistically plausible. We define two types of unseen\nextremes: \"checkmate\" extremes that directly hit targets, and \"stalemate\"\nextremes that narrowly miss. These unrealized scenarios expose latent risks in\nfragile systems and may reinforce a false sense of resilience if overlooked.\nNear misses, in particular, can prompt either proactive adaptation or dangerous\ncomplacency, depending on how they are interpreted. Applying DeepX-GAN to the\nMiddle East and North Africa (MENA), we find that these unseen extremes\ndisproportionately affect regions with high vulnerability and low socioeconomic\nreadiness, but differ in urgency and interpretation. Future warming could\nexpand and redistribute these unseen extremes, with emerging exposure hotspots\nin Indo-Pakistan and Central Africa. This distributional shift highlights\ncritical blind spots in conventional hazard planning and underscores the need\nto develop spatially adaptive policies that anticipate emergent risk hotspots\nrather than simply extrapolating from historical patterns.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faDeepX - GAN\u6a21\u578b\u6a21\u62df\u672a\u89c1\u6781\u7aef\u6c14\u5019\u4e8b\u4ef6\uff0c\u5e94\u7528\u4e8e\u4e2d\u4e1c\u548c\u5317\u975e\u5730\u533a\uff0c\u53d1\u73b0\u672a\u89c1\u6781\u7aef\u4e8b\u4ef6\u5f71\u54cd\u8106\u5f31\u5730\u533a\uff0c\u672a\u6765\u53d8\u6696\u6216\u6539\u53d8\u5176\u5206\u5e03\uff0c\u5f3a\u8c03\u9700\u5236\u5b9a\u7a7a\u95f4\u9002\u5e94\u6027\u653f\u7b56\u3002", "motivation": "\u89c2\u6d4b\u8bb0\u5f55\u65e0\u6cd5\u6db5\u76d6\u672a\u89c1\u6781\u7aef\u6c14\u5019\u4e8b\u4ef6\u4e14\u5ffd\u89c6\u7a7a\u95f4\u4f9d\u8d56\u6027\u4f1a\u4f4e\u4f30\u540c\u6b65\u707e\u5bb3\u98ce\u9669\uff0c\u9700\u66f4\u597d\u6a21\u578b\u6355\u6349\u7f55\u89c1\u6781\u7aef\u4e8b\u4ef6\u7a7a\u95f4\u7ed3\u6784\u3002", "method": "\u5f00\u53d1\u77e5\u8bc6\u9a71\u52a8\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578bDeepX - GAN\uff0c\u5b9a\u4e49\u4e24\u79cd\u672a\u89c1\u6781\u7aef\u7c7b\u578b\u5e76\u8fdb\u884c\u6a21\u62df\u5206\u6790\u3002", "result": "\u672a\u89c1\u6781\u7aef\u4e8b\u4ef6\u5bf9\u9ad8\u8106\u5f31\u6027\u548c\u4f4e\u793e\u4f1a\u7ecf\u6d4e\u51c6\u5907\u5ea6\u5730\u533a\u5f71\u54cd\u5927\uff0c\u672a\u6765\u53d8\u6696\u4f1a\u6539\u53d8\u5176\u5206\u5e03\uff0c\u51fa\u73b0\u65b0\u7684\u66b4\u9732\u70ed\u70b9\u3002", "conclusion": "\u4f20\u7edf\u707e\u5bb3\u89c4\u5212\u5b58\u5728\u76f2\u70b9\uff0c\u9700\u5236\u5b9a\u80fd\u9884\u89c1\u65b0\u5174\u98ce\u9669\u70ed\u70b9\u7684\u7a7a\u95f4\u9002\u5e94\u6027\u653f\u7b56\u3002"}}
{"id": "2507.10208", "pdf": "https://arxiv.org/pdf/2507.10208", "abs": "https://arxiv.org/abs/2507.10208", "authors": ["Hamzah Ziadeh", "Hendrik Knoche"], "title": "Survey for Categorising Explainable AI Studies Using Data Analysis Task Frameworks", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Research into explainable artificial intelligence (XAI) for data analysis\ntasks suffer from a large number of contradictions and lack of concrete design\nrecommendations stemming from gaps in understanding the tasks that require AI\nassistance. In this paper, we drew on multiple fields such as visual analytics,\ncognition, and dashboard design to propose a method for categorising and\ncomparing XAI studies under three dimensions: what, why, and who. We identified\nthe main problems as: inadequate descriptions of tasks, context-free studies,\nand insufficient testing with target users. We propose that studies should\nspecifically report on their users' domain, AI, and data analysis expertise to\nillustrate the generalisability of their findings. We also propose study\nguidelines for designing and reporting XAI tasks to improve the XAI community's\nability to parse the rapidly growing field. We hope that our contribution can\nhelp researchers and designers better identify which studies are most relevant\nto their work, what gaps exist in the research, and how to handle contradictory\nresults regarding XAI design.", "AI": {"tldr": "\u672c\u6587\u4ece\u591a\u9886\u57df\u51fa\u53d1\u63d0\u51fa\u5bf9\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u7814\u7a76\u5206\u7c7b\u548c\u6bd4\u8f83\u7684\u65b9\u6cd5\uff0c\u6307\u51fa\u95ee\u9898\u5e76\u7ed9\u51fa\u7814\u7a76\u5efa\u8bae\uff0c\u4ee5\u52a9\u4e8e\u7814\u7a76\u548c\u8bbe\u8ba1\u4eba\u5458\u66f4\u597d\u5e94\u5bf9XAI\u9886\u57df\u3002", "motivation": "\u5f53\u524dXAI\u6570\u636e\u5206\u6790\u7814\u7a76\u5b58\u5728\u5927\u91cf\u77db\u76fe\u4e14\u7f3a\u4e4f\u5177\u4f53\u8bbe\u8ba1\u5efa\u8bae\uff0c\u6e90\u4e8e\u5bf9\u9700AI\u8f85\u52a9\u4efb\u52a1\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u501f\u9274\u89c6\u89c9\u5206\u6790\u3001\u8ba4\u77e5\u548c\u4eea\u8868\u76d8\u8bbe\u8ba1\u7b49\u591a\u9886\u57df\uff0c\u4ecewhat\u3001why\u3001who\u4e09\u4e2a\u7ef4\u5ea6\u5bf9XAI\u7814\u7a76\u8fdb\u884c\u5206\u7c7b\u548c\u6bd4\u8f83\u3002", "result": "\u8bc6\u522b\u51fa\u4e3b\u8981\u95ee\u9898\u4e3a\u4efb\u52a1\u63cf\u8ff0\u4e0d\u8db3\u3001\u65e0\u4e0a\u4e0b\u6587\u7814\u7a76\u3001\u5bf9\u76ee\u6807\u7528\u6237\u6d4b\u8bd5\u4e0d\u8db3\uff1b\u63d0\u51fa\u5e94\u62a5\u544a\u7528\u6237\u4e13\u4e1a\u77e5\u8bc6\u4ee5\u8bf4\u660e\u7814\u7a76\u7ed3\u679c\u53ef\u63a8\u5e7f\u6027\uff1b\u7ed9\u51fa\u8bbe\u8ba1\u548c\u62a5\u544aXAI\u4efb\u52a1\u7684\u7814\u7a76\u6307\u5357\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u6709\u52a9\u4e8e\u7814\u7a76\u548c\u8bbe\u8ba1\u4eba\u5458\u8bc6\u522b\u76f8\u5173\u7814\u7a76\u3001\u7814\u7a76\u5dee\u8ddd\u4ee5\u53ca\u5904\u7406XAI\u8bbe\u8ba1\u7684\u77db\u76fe\u7ed3\u679c\u3002"}}
{"id": "2507.10321", "pdf": "https://arxiv.org/pdf/2507.10321", "abs": "https://arxiv.org/abs/2507.10321", "authors": ["Viktor Sinitsyn", "Nils Schlautmann", "Florian Schwaiger", "Florian Holzapfel"], "title": "Streamlined Airborne Software Development for Large UAVs: From Unified Data Collection to Automated Code Generation", "categories": ["cs.SE", "cs.SY", "eess.SY"], "comment": null, "summary": "The aerospace industry has experienced significant transformations over the\nlast decade, driven by technological advancements and innovative solutions in\ngoods and personal transportation. This evolution has spurred the emergence of\nnumerous start-ups that now face challenges traditionally encountered by\nestablished aerospace companies. Among these challenges is the efficient\nprocessing of digital intra-device communication interfaces for onboard\nequipment - a critical component for ensuring seamless system integration and\nfunctionality. Addressing this challenge requires solutions that emphasize\nclear and consistent interface descriptions, automation of processes, and\nreduced labor-intensive efforts.\n  This paper presents a novel process and toolchain designed to streamline the\ndevelopment of digital interfaces and onboard software, which our team has\nsuccessfully applied in several completed projects. The proposed approach\nfocuses on automation and flexibility while maintaining compliance with design\nassurance requirements.", "AI": {"tldr": "\u822a\u7a7a\u822a\u5929\u4e1a\u53d1\u5c55\u5e26\u6765\u65b0\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u7cbe\u7b80\u6570\u5b57\u63a5\u53e3\u548c\u673a\u8f7d\u8f6f\u4ef6\u5f00\u53d1\u7684\u65b9\u6cd5\u4e0e\u5de5\u5177\u94fe\u5e76\u5df2\u6210\u529f\u5e94\u7528\u3002", "motivation": "\u822a\u7a7a\u822a\u5929\u4e1a\u53d1\u5c55\u4f7f\u521d\u521b\u516c\u53f8\u9762\u4e34\u5904\u7406\u673a\u8f7d\u8bbe\u5907\u6570\u5b57\u901a\u4fe1\u63a5\u53e3\u7684\u6311\u6218\uff0c\u9700\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6ce8\u91cd\u81ea\u52a8\u5316\u548c\u7075\u6d3b\u6027\uff0c\u540c\u65f6\u7b26\u5408\u8bbe\u8ba1\u4fdd\u8bc1\u8981\u6c42\u7684\u65b0\u9896\u6d41\u7a0b\u548c\u5de5\u5177\u94fe\u3002", "result": "\u56e2\u961f\u5df2\u5728\u591a\u4e2a\u5df2\u5b8c\u6210\u9879\u76ee\u4e2d\u6210\u529f\u5e94\u7528\u8be5\u65b9\u6cd5\u548c\u5de5\u5177\u94fe\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u548c\u5de5\u5177\u94fe\u53ef\u6709\u6548\u7cbe\u7b80\u6570\u5b57\u63a5\u53e3\u548c\u673a\u8f7d\u8f6f\u4ef6\u5f00\u53d1\u3002"}}
{"id": "2507.09031", "pdf": "https://arxiv.org/pdf/2507.09031", "abs": "https://arxiv.org/abs/2507.09031", "authors": ["Yash Shah", "Camila Gonzalez", "Mohammad H. Abbasi", "Qingyu Zhao", "Kilian M. Pohl", "Ehsan Adeli"], "title": "Confounder-Free Continual Learning via Recursive Feature Normalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Confounders are extraneous variables that affect both the input and the\ntarget, resulting in spurious correlations and biased predictions. There are\nrecent advances in dealing with or removing confounders in traditional models,\nsuch as metadata normalization (MDN), where the distribution of the learned\nfeatures is adjusted based on the study confounders. However, in the context of\ncontinual learning, where a model learns continuously from new data over time\nwithout forgetting, learning feature representations that are invariant to\nconfounders remains a significant challenge. To remove their influence from\nintermediate feature representations, we introduce the Recursive MDN (R-MDN)\nlayer, which can be integrated into any deep learning architecture, including\nvision transformers, and at any model stage. R-MDN performs statistical\nregression via the recursive least squares algorithm to maintain and\ncontinually update an internal model state with respect to changing\ndistributions of data and confounding variables. Our experiments demonstrate\nthat R-MDN promotes equitable predictions across population groups, both within\nstatic learning and across different stages of continual learning, by reducing\ncatastrophic forgetting caused by confounder effects changing over time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9012\u5f52\u5143\u6570\u636e\u5f52\u4e00\u5316\uff08R - MDN\uff09\u5c42\uff0c\u7528\u4e8e\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6d88\u9664\u6df7\u6742\u56e0\u7d20\u5f71\u54cd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u4fc3\u8fdb\u516c\u5e73\u9884\u6d4b\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u6709\u5904\u7406\u6df7\u6742\u56e0\u7d20\u7684\u65b9\u6cd5\uff0c\u4f46\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\uff0c\u5b66\u4e60\u5bf9\u6df7\u6742\u56e0\u7d20\u4e0d\u53d8\u7684\u7279\u5f81\u8868\u793a\u4ecd\u662f\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f15\u5165\u53ef\u96c6\u6210\u5230\u4efb\u4f55\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u7684R - MDN\u5c42\uff0c\u901a\u8fc7\u9012\u5f52\u6700\u5c0f\u4e8c\u4e58\u6cd5\u8fdb\u884c\u7edf\u8ba1\u56de\u5f52\uff0c\u4e0d\u65ad\u66f4\u65b0\u5185\u90e8\u6a21\u578b\u72b6\u6001\u3002", "result": "R - MDN\u5728\u9759\u6001\u5b66\u4e60\u548c\u6301\u7eed\u5b66\u4e60\u4e0d\u540c\u9636\u6bb5\u90fd\u80fd\u51cf\u5c11\u56e0\u6df7\u6742\u56e0\u7d20\u968f\u65f6\u95f4\u53d8\u5316\u5bfc\u81f4\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4fc3\u8fdb\u4e0d\u540c\u4eba\u7fa4\u7ec4\u7684\u516c\u5e73\u9884\u6d4b\u3002", "conclusion": "R - MDN\u5c42\u80fd\u6709\u6548\u6d88\u9664\u4e2d\u95f4\u7279\u5f81\u8868\u793a\u4e2d\u6df7\u6742\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.09212", "pdf": "https://arxiv.org/pdf/2507.09212", "abs": "https://arxiv.org/abs/2507.09212", "authors": ["Jonas Scholz", "Richard E. Turner"], "title": "Warm Starts Accelerate Generative Modelling", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "10 pages, 6 figures", "summary": "Iterative generative models, like diffusion and flow-matching, create\nhigh-fidelity samples by progressively refining a noise vector into data.\nHowever, this process is notoriously slow, often requiring hundreds of function\nevaluations. We introduce the warm-start model, a simple, deterministic model\nthat dramatically accelerates conditional generation by providing a better\nstarting point. Instead of starting generation from an uninformed N(0, I)\nprior, our warm-start model predicts an informed prior N(mu, sigma), whose\nmoments are conditioned on the input context. This \"warm start\" substantially\nreduces the distance the generative process must traverse, particularly when\nthe conditioning information is strongly informative. On tasks like image\ninpainting, our method achieves results competitive with a 1000-step DDPM\nbaseline using only 11 total function evaluations (1 for the warm start, 10 for\ngeneration). A simple conditional normalization trick makes our method\ncompatible with any standard generative model and sampler without modification,\nallowing it to be combined with other efficient sampling techniques for further\nacceleration. Our implementation is available at\nhttps://github.com/jonas-scholz123/warm-start-model.", "AI": {"tldr": "\u63d0\u51fa\u70ed\u542f\u52a8\u6a21\u578b\u52a0\u901f\u6761\u4ef6\u751f\u6210\uff0c\u517c\u5bb9\u6807\u51c6\u751f\u6210\u6a21\u578b\uff0c\u5728\u56fe\u50cf\u4fee\u590d\u4efb\u52a1\u8868\u73b0\u4f73\u3002", "motivation": "\u8fed\u4ee3\u751f\u6210\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u6162\uff0c\u9700\u6570\u767e\u6b21\u51fd\u6570\u8bc4\u4f30\uff0c\u9700\u52a0\u901f\u6761\u4ef6\u751f\u6210\u3002", "method": "\u5f15\u5165\u70ed\u542f\u52a8\u6a21\u578b\u9884\u6d4b\u4fe1\u606f\u5148\u9a8cN(mu, sigma)\u4f5c\u4e3a\u66f4\u597d\u8d77\u70b9\uff0c\u7528\u6761\u4ef6\u5f52\u4e00\u5316\u6280\u5de7\u4f7f\u5176\u517c\u5bb9\u6807\u51c6\u6a21\u578b\u3002", "result": "\u5728\u56fe\u50cf\u4fee\u590d\u4efb\u52a1\u4e2d\uff0c\u4ec511\u6b21\u51fd\u6570\u8bc4\u4f30\u8fbe\u5230\u4e0e1000\u6b65DDPM\u57fa\u7ebf\u76f8\u5f53\u7ed3\u679c\u3002", "conclusion": "\u70ed\u542f\u52a8\u6a21\u578b\u6709\u6548\u52a0\u901f\u6761\u4ef6\u751f\u6210\uff0c\u4e14\u53ef\u4e0e\u5176\u4ed6\u9ad8\u6548\u91c7\u6837\u6280\u672f\u7ed3\u5408\u8fdb\u4e00\u6b65\u52a0\u901f\u3002"}}
{"id": "2507.10338", "pdf": "https://arxiv.org/pdf/2507.10338", "abs": "https://arxiv.org/abs/2507.10338", "authors": ["Enyuan Tian", "Yiwei Ci", "Qiusong Yang", "Yufeng Li", "Zhichao Lyu"], "title": "AssertCoder: LLM-Based Assertion Generation via Multimodal Specification Extraction", "categories": ["cs.SE", "cs.AR", "cs.LO"], "comment": "7 pages, 3 figures", "summary": "Assertion-Based Verification (ABV) is critical for ensuring functional\ncorrectness in modern hardware systems. However, manually writing high-quality\nSVAs remains labor-intensive and error-prone. To bridge this gap, we propose\nAssertCoder, a novel unified framework that automatically generates\nhigh-quality SVAs directly from multimodal hardware design specifications.\nAssertCoder employs a modality-sensitive preprocessing to parse heterogeneous\nspecification formats (text, tables, diagrams, and formulas), followed by a set\nof dedicated semantic analyzers that extract structured representations aligned\nwith signal-level semantics. These representations are utilized to drive\nassertion synthesis via multi-step chain-of-thought (CoT) prompting. The\nframework incorporates a mutation-based evaluation approach to assess assertion\nquality via model checking and further refine the generated assertions.\nExperimental evaluation across three real-world Register-Transfer Level (RTL)\ndesigns demonstrates AssertCoder's superior performance, achieving an average\nincrease of 8.4% in functional correctness and 5.8% in mutation detection\ncompared to existing state-of-the-art approaches.", "AI": {"tldr": "\u63d0\u51faAssertCoder\u6846\u67b6\u81ea\u52a8\u4ece\u591a\u6a21\u6001\u786c\u4ef6\u8bbe\u8ba1\u89c4\u8303\u751f\u6210\u9ad8\u8d28\u91cfSVAs\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u624b\u52a8\u7f16\u5199\u9ad8\u8d28\u91cfSVAs\u52b3\u52a8\u5bc6\u96c6\u4e14\u6613\u51fa\u9519\uff0c\u9700\u8981\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6a21\u6001\u654f\u611f\u9884\u5904\u7406\u89e3\u6790\u5f02\u6784\u89c4\u8303\u683c\u5f0f\uff0c\u7528\u4e13\u7528\u8bed\u4e49\u5206\u6790\u5668\u63d0\u53d6\u7ed3\u6784\u5316\u8868\u793a\uff0c\u901a\u8fc7\u591a\u6b65\u601d\u7ef4\u94fe\u63d0\u793a\u9a71\u52a8\u65ad\u8a00\u5408\u6210\uff0c\u7528\u57fa\u4e8e\u53d8\u5f02\u7684\u8bc4\u4f30\u65b9\u6cd5\u8bc4\u4f30\u548c\u4f18\u5316\u65ad\u8a00\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9eRTL\u8bbe\u8ba1\u5b9e\u9a8c\u4e2d\uff0c\u529f\u80fd\u6b63\u786e\u6027\u5e73\u5747\u63d0\u53478.4%\uff0c\u53d8\u5f02\u68c0\u6d4b\u5e73\u5747\u63d0\u53475.8%\u3002", "conclusion": "AssertCoder\u6846\u67b6\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cfSVAs\u3002"}}
{"id": "2507.09041", "pdf": "https://arxiv.org/pdf/2507.09041", "abs": "https://arxiv.org/abs/2507.09041", "authors": ["Andrew Wagenmaker", "Zhiyuan Zhou", "Sergey Levine"], "title": "Behavioral Exploration: Learning to Explore via In-Context Adaptation", "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Developing autonomous agents that quickly explore an environment and adapt\ntheir behavior online is a canonical challenge in robotics and machine\nlearning. While humans are able to achieve such fast online exploration and\nadaptation, often acquiring new information and skills in only a handful of\ninteractions, existing algorithmic approaches tend to rely on random\nexploration and slow, gradient-based behavior updates. How can we endow\nautonomous agents with such capabilities on par with humans? Taking inspiration\nfrom recent progress on both in-context learning and large-scale behavioral\ncloning, in this work we propose behavioral exploration: training agents to\ninternalize what it means to explore and adapt in-context over the space of\n``expert'' behaviors. To achieve this, given access to a dataset of expert\ndemonstrations, we train a long-context generative model to predict expert\nactions conditioned on a context of past observations and a measure of how\n``exploratory'' the expert's behaviors are relative to this context. This\nenables the model to not only mimic the behavior of an expert, but also, by\nfeeding its past history of interactions into its context, to select different\nexpert behaviors than what have been previously selected, thereby allowing for\nfast online adaptation and targeted, ``expert-like'' exploration. We\ndemonstrate the effectiveness of our method in both simulated locomotion and\nmanipulation settings, as well as on real-world robotic manipulation tasks,\nillustrating its ability to learn adaptive, exploratory behavior.", "AI": {"tldr": "\u63d0\u51fa\u884c\u4e3a\u63a2\u7d22\u65b9\u6cd5\uff0c\u8bad\u7ec3\u667a\u80fd\u4f53\u5728\u4e13\u5bb6\u884c\u4e3a\u7a7a\u95f4\u4e2d\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a2\u7d22\u548c\u9002\u5e94\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u5728\u5feb\u901f\u5728\u7ebf\u63a2\u7d22\u548c\u9002\u5e94\u65b9\u9762\u4e0d\u8db3\uff0c\u5e0c\u671b\u8d4b\u4e88\u667a\u80fd\u4f53\u7c7b\u4f3c\u4eba\u7c7b\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u5927\u89c4\u6a21\u884c\u4e3a\u514b\u9686\uff0c\u5229\u7528\u4e13\u5bb6\u6f14\u793a\u6570\u636e\u96c6\u8bad\u7ec3\u957f\u4e0a\u4e0b\u6587\u751f\u6210\u6a21\u578b\uff0c\u6839\u636e\u8fc7\u53bb\u89c2\u5bdf\u548c\u63a2\u7d22\u6027\u6307\u6807\u9884\u6d4b\u4e13\u5bb6\u52a8\u4f5c\u3002", "result": "\u5728\u6a21\u62df\u7684\u8fd0\u52a8\u548c\u64cd\u4f5c\u573a\u666f\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u4f7f\u667a\u80fd\u4f53\u5b66\u4e60\u5230\u81ea\u9002\u5e94\u7684\u63a2\u7d22\u6027\u884c\u4e3a\u3002"}}
{"id": "2507.09213", "pdf": "https://arxiv.org/pdf/2507.09213", "abs": "https://arxiv.org/abs/2507.09213", "authors": ["Dunsheng Huang", "Dong Shen", "Lei Lu", "Ying Tan"], "title": "Optimizing Basis Function Selection in Constructive Wavelet Neural Networks and Its Applications", "categories": ["cs.LG", "stat.ML", "68T07"], "comment": "17pages", "summary": "Wavelet neural network (WNN), which learns an unknown nonlinear mapping from\nthe data, has been widely used in signal processing, and time-series analysis.\nHowever, challenges in constructing accurate wavelet bases and high\ncomputational costs limit their application. This study introduces a\nconstructive WNN that selects initial bases and trains functions by introducing\nnew bases for predefined accuracy while reducing computational costs. For the\nfirst time, we analyze the frequency of unknown nonlinear functions and select\nappropriate initial wavelets based on their primary frequency components by\nestimating the energy of the spatial frequency component. This leads to a novel\nconstructive framework consisting of a frequency estimator and a wavelet-basis\nincrease mechanism to prioritize high-energy bases, significantly improving\ncomputational efficiency. The theoretical foundation defines the necessary\ntime-frequency range for high-dimensional wavelets at a given accuracy. The\nframework's versatility is demonstrated through four examples: estimating\nunknown static mappings from offline data, combining two offline datasets,\nidentifying time-varying mappings from time-series data, and capturing\nnonlinear dependencies in real time-series data. These examples showcase the\nframework's broad applicability and practicality. All the code will be released\nat https://github.com/dshuangdd/CWNN.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6784\u9020\u6027\u5c0f\u6ce2\u795e\u7ecf\u7f51\u7edc\uff08WNN\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u57fa\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u63d0\u51fa\u542b\u9891\u7387\u4f30\u8ba1\u5668\u548c\u5c0f\u6ce2\u57fa\u589e\u52a0\u673a\u5236\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u4e2a\u793a\u4f8b\u5c55\u793a\u5176\u901a\u7528\u6027\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "motivation": "\u4f20\u7edf\u5c0f\u6ce2\u795e\u7ecf\u7f51\u7edc\u5728\u6784\u9020\u7cbe\u786e\u5c0f\u6ce2\u57fa\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002", "method": "\u5206\u6790\u672a\u77e5\u975e\u7ebf\u6027\u51fd\u6570\u7684\u9891\u7387\uff0c\u6839\u636e\u7a7a\u95f4\u9891\u7387\u5206\u91cf\u80fd\u91cf\u9009\u62e9\u521d\u59cb\u5c0f\u6ce2\uff0c\u6784\u5efa\u5305\u542b\u9891\u7387\u4f30\u8ba1\u5668\u548c\u5c0f\u6ce2\u57fa\u589e\u52a0\u673a\u5236\u7684\u6846\u67b6\uff0c\u5b9a\u4e49\u9ad8\u7ef4\u5c0f\u6ce2\u5728\u7ed9\u5b9a\u7cbe\u5ea6\u4e0b\u7684\u65f6\u9891\u8303\u56f4\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u901a\u8fc7\u56db\u4e2a\u793a\u4f8b\u5c55\u793a\u4e86\u6846\u67b6\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6784\u9020\u6027\u5c0f\u6ce2\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\u5177\u6709\u8f83\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u548c\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.10397", "pdf": "https://arxiv.org/pdf/2507.10397", "abs": "https://arxiv.org/abs/2507.10397", "authors": ["Alessandra M. M. M. Gouv\u00eaa", "Nuno Paulos", "Eduardo Uchoa e Mari\u00e1 C. V. Nascimento"], "title": "Instance space analysis of the capacitated vehicle routing problem", "categories": ["cs.AI"], "comment": null, "summary": "This paper seeks to advance CVRP research by addressing the challenge of\nunderstanding the nuanced relationships between instance characteristics and\nmetaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a\nvaluable tool that allows for a new perspective on the field. By combining the\nISA methodology with a dataset from the DIMACS 12th Implementation Challenge on\nVehicle Routing, our research enabled the identification of 23 relevant\ninstance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages,\nwhich employ dimensionality reduction and machine learning methods, allowed us\nto create a two-dimensional projection of the instance space to understand how\nthe structure of instances affect the behavior of MHs. A key contribution of\nour work is that we provide a projection matrix, which makes it straightforward\nto incorporate new instances into this analysis and allows for a new method for\ninstance analysis in the CVRP field.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u4f8b\u7a7a\u95f4\u5206\u6790\uff08ISA\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408DIMACS\u6570\u636e\u96c6\uff0c\u8bc6\u522b23\u4e2a\u76f8\u5173\u5b9e\u4f8b\u7279\u5f81\uff0c\u521b\u5efa\u4e8c\u7ef4\u6295\u5f71\u6765\u7814\u7a76\u5b9e\u4f8b\u7279\u5f81\u4e0e\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u6027\u80fd\u5173\u7cfb\uff0c\u5e76\u63d0\u4f9b\u6295\u5f71\u77e9\u9635\u3002", "motivation": "\u89e3\u51b3\u7406\u89e3\u5b9e\u4f8b\u7279\u5f81\u4e0e\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff08MH\uff09\u6027\u80fd\u4e4b\u95f4\u7ec6\u5fae\u5173\u7cfb\u7684\u6311\u6218\uff0c\u63a8\u52a8CVRP\u7814\u7a76\u3002", "method": "\u91c7\u7528ISA\u65b9\u6cd5\uff0c\u7ed3\u5408DIMACS 12th\u6570\u636e\u96c6\uff0c\u8fd0\u7528\u964d\u7ef4\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ecf\u8fc7PRELIM\u3001SIFTED\u548cPILOT\u9636\u6bb5\u521b\u5efa\u5b9e\u4f8b\u7a7a\u95f4\u4e8c\u7ef4\u6295\u5f71\u3002", "result": "\u8bc6\u522b\u51fa23\u4e2a\u76f8\u5173\u5b9e\u4f8b\u7279\u5f81\uff0c\u521b\u5efa\u5b9e\u4f8b\u7a7a\u95f4\u4e8c\u7ef4\u6295\u5f71\u3002", "conclusion": "\u63d0\u4f9b\u6295\u5f71\u77e9\u9635\uff0c\u4e3aCVRP\u9886\u57df\u5b9e\u4f8b\u5206\u6790\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2507.10422", "pdf": "https://arxiv.org/pdf/2507.10422", "abs": "https://arxiv.org/abs/2507.10422", "authors": ["Tao Xiao", "Youmei Fan", "Fabio Calefato", "Christoph Treude", "Raula Gaikovina Kula", "Hideaki Hata", "Sebastian Baltes"], "title": "Self-Admitted GenAI Usage in Open-Source Software", "categories": ["cs.SE"], "comment": "17 pages, 8 tables, 1 figures, currently under review", "summary": "The widespread adoption of generative AI (GenAI) tools such as GitHub Copilot\nand ChatGPT is transforming software development. Since generated source code\nis virtually impossible to distinguish from manually written code, their\nreal-world usage and impact on open-source software development remain poorly\nunderstood. In this paper, we introduce the concept of self-admitted GenAI\nusage, that is, developers explicitly referring to the use of GenAI tools for\ncontent creation in software artifacts. Using this concept as a lens to study\nhow GenAI tools are integrated into open-source software projects, we analyze a\ncurated sample of more than 250,000 GitHub repositories, identifying 1,292 such\nself-admissions across 156 repositories in commit messages, code comments, and\nproject documentation. Using a mixed methods approach, we derive a taxonomy of\n32 tasks, 10 content types, and 11 purposes associated with GenAI usage based\non 284 qualitatively coded mentions. We then analyze 13 documents with policies\nand usage guidelines for GenAI tools and conduct a developer survey to uncover\nthe ethical, legal, and practical concerns behind them. Our findings reveal\nthat developers actively manage how GenAI is used in their projects,\nhighlighting the need for project-level transparency, attribution, and quality\ncontrol practices in the new era of AI-assisted software development. Finally,\nwe examine the longitudinal impact of GenAI adoption on code churn in 151\nrepositories with self-admitted GenAI usage and find no general increase,\ncontradicting popular narratives on the impact of GenAI on software\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u751f\u6210\u5f0fAI\u5728\u5f00\u6e90\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4f7f\u7528\uff0c\u5206\u6790\u5927\u91cfGitHub\u4ed3\u5e93\uff0c\u5f97\u51fa\u4f7f\u7528\u76f8\u5173\u5206\u7c7b\uff0c\u8c03\u67e5\u76f8\u5173\u653f\u7b56\u548c\u5f00\u53d1\u8005\u62c5\u5fe7\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u4e3b\u52a8\u7ba1\u7406\u4f7f\u7528\uff0c\u4e14GenAI\u672a\u4f7f\u4ee3\u7801\u53d8\u66f4\u666e\u904d\u589e\u52a0\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5de5\u5177\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u5f00\u6e90\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u4f7f\u7528\u548c\u5f71\u54cd\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u6df1\u5165\u7814\u7a76\u3002", "method": "\u5f15\u5165\u81ea\u6211\u627f\u8ba4GenAI\u4f7f\u7528\u7684\u6982\u5ff5\uff0c\u5206\u6790\u8d8525\u4e07\u4e2aGitHub\u4ed3\u5e93\uff0c\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u5f97\u51fa\u76f8\u5173\u5206\u7c7b\uff0c\u5206\u6790\u653f\u7b56\u6587\u6863\u5e76\u5f00\u5c55\u5f00\u53d1\u8005\u8c03\u67e5\uff0c\u8fd8\u7814\u7a76GenAI\u91c7\u7528\u5bf9\u4ee3\u7801\u53d8\u66f4\u7684\u957f\u671f\u5f71\u54cd\u3002", "result": "\u8bc6\u522b\u51fa156\u4e2a\u4ed3\u5e93\u76841292\u6b21\u81ea\u6211\u627f\u8ba4\uff0c\u5f97\u51fa32\u4e2a\u4efb\u52a1\u300110\u79cd\u5185\u5bb9\u7c7b\u578b\u548c11\u79cd\u76ee\u7684\u7684\u5206\u7c7b\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u4e3b\u52a8\u7ba1\u7406GenAI\u4f7f\u7528\uff0cGenAI\u672a\u4f7f\u4ee3\u7801\u53d8\u66f4\u666e\u904d\u589e\u52a0\u3002", "conclusion": "\u5728AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u65b0\u65f6\u4ee3\uff0c\u9879\u76ee\u5c42\u9762\u9700\u6709\u900f\u660e\u5ea6\u3001\u5f52\u56e0\u548c\u8d28\u91cf\u63a7\u5236\u63aa\u65bd\u3002"}}
{"id": "2507.09247", "pdf": "https://arxiv.org/pdf/2507.09247", "abs": "https://arxiv.org/abs/2507.09247", "authors": ["Mihailo Stojnic"], "title": "A CLuP algorithm to practically achieve $\\sim 0.76$ SK--model ground state free energy", "categories": ["cond-mat.dis-nn", "cs.IT", "math.IT", "math.OC", "stat.ML"], "comment": null, "summary": "We consider algorithmic determination of the $n$-dimensional\nSherrington-Kirkpatrick (SK) spin glass model ground state free energy. It\ncorresponds to a binary maximization of an indefinite quadratic form and under\nthe \\emph{worst case} principles of the classical NP complexity theory it is\nhard to approximate within a $\\log(n)^{const.}$ factor. On the other hand, the\nSK's random nature allows (polynomial) spectral methods to \\emph{typically}\napproach the optimum within a constant factor. Naturally one is left with the\nfundamental question: can the residual (constant) \\emph{computational gap} be\nerased?\n  Following the success of \\emph{Controlled Loosening-up} (CLuP) algorithms in\nplanted models, we here devise a simple practical CLuP-SK algorithmic procedure\nfor (non-planted) SK models. To analyze the \\emph{typical} success of the\nalgorithm we associate to it (random) CLuP-SK models. Further connecting to\nrecent random processes studies [94,97], we characterize the models and CLuP-SK\nalgorithm via fully lifted random duality theory (fl RDT) [98]. Moreover,\nrunning the algorithm we demonstrate that its performance is in an excellent\nagrement with theoretical predictions. In particular, already for $n$ on the\norder of a few thousands CLuP-SK achieves $\\sim 0.76$ ground state free energy\nand remarkably closely approaches theoretical $n\\rightarrow\\infty$ limit\n$\\approx 0.763$. For all practical purposes, this renders computing SK model's\nnear ground state free energy as a \\emph{typically} easy problem.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8SK\u81ea\u65cb\u73bb\u7483\u6a21\u578b\u57fa\u6001\u81ea\u7531\u80fd\u7b97\u6cd5\u786e\u5b9a\u95ee\u9898\uff0c\u63d0\u51faCLuP - SK\u7b97\u6cd5\uff0c\u5176\u6027\u80fd\u4e0e\u7406\u8bba\u9884\u6d4b\u76f8\u7b26\uff0c\u4f7f\u8ba1\u7b97\u8fd1\u57fa\u6001\u81ea\u7531\u80fd\u901a\u5e38\u53d8\u5f97\u5bb9\u6613\u3002", "motivation": "\u89e3\u51b3SK\u6a21\u578b\u5728\u591a\u9879\u5f0f\u8c31\u65b9\u6cd5\u4e0b\u5b58\u5728\u7684\u5e38\u6570\u8ba1\u7b97\u5dee\u8ddd\u95ee\u9898\uff0c\u5373\u80fd\u5426\u6d88\u9664\u8be5\u5dee\u8ddd\u3002", "method": "\u501f\u9274CLuP\u7b97\u6cd5\uff0c\u8bbe\u8ba1CLuP - SK\u7b97\u6cd5\uff0c\u5173\u8054\u968f\u673aCLuP - SK\u6a21\u578b\uff0c\u901a\u8fc7\u5168\u63d0\u5347\u968f\u673a\u5bf9\u5076\u7406\u8bba\uff08fl RDT\uff09\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7b97\u6cd5\u6027\u80fd\u4e0e\u7406\u8bba\u9884\u6d4b\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5bf9\u4e8e\u51e0\u5343\u91cf\u7ea7\u7684n\uff0cCLuP - SK\u80fd\u8fbe\u5230\u7ea60.76\u7684\u57fa\u6001\u81ea\u7531\u80fd\uff0c\u63a5\u8fd1\u7406\u8bba\u6781\u9650\u7ea60.763\u3002", "conclusion": "\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\uff0c\u8ba1\u7b97SK\u6a21\u578b\u8fd1\u57fa\u6001\u81ea\u7531\u80fd\u901a\u5e38\u662f\u4e00\u4e2a\u5bb9\u6613\u7684\u95ee\u9898\u3002"}}
{"id": "2507.09252", "pdf": "https://arxiv.org/pdf/2507.09252", "abs": "https://arxiv.org/abs/2507.09252", "authors": ["Shukai Gong", "Yiyang Fu", "Fengyuan Ran", "Feng Zhou"], "title": "TPP-SD: Accelerating Transformer Point Process Sampling with Speculative Decoding", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We propose TPP-SD, a novel approach that accelerates Transformer temporal\npoint process (TPP) sampling by adapting speculative decoding (SD) techniques\nfrom language models. By identifying the structural similarities between\nthinning algorithms for TPPs and speculative decoding for language models, we\ndevelop an efficient sampling framework that leverages a smaller draft model to\ngenerate multiple candidate events, which are then verified by the larger\ntarget model in parallel. TPP-SD maintains the same output distribution as\nautoregressive sampling while achieving significant acceleration. Experiments\non both synthetic and real datasets demonstrate that our approach produces\nsamples from identical distributions as standard methods, but with 2-6$\\times$\nspeedup. Our ablation studies analyze the impact of hyperparameters such as\ndraft length and draft model size on sampling efficiency. TPP-SD bridges the\ngap between powerful Transformer TPP models and the practical need for rapid\nsequence sampling.", "AI": {"tldr": "\u63d0\u51faTPP - SD\u65b9\u6cd5\u52a0\u901fTransformer TPP\u91c7\u6837\uff0c\u5b9e\u9a8c\u663e\u793a\u67092 - 6\u500d\u63d0\u901f\u3002", "motivation": "\u6ee1\u8db3\u5f3a\u5927\u7684Transformer TPP\u6a21\u578b\u5feb\u901f\u5e8f\u5217\u91c7\u6837\u7684\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u8bc6\u522bTPP\u7ec6\u5316\u7b97\u6cd5\u548c\u8bed\u8a00\u6a21\u578b\u63a8\u6d4b\u89e3\u7801\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\uff0c\u5229\u7528\u5c0f\u7684\u8349\u7a3f\u6a21\u578b\u751f\u6210\u591a\u4e2a\u5019\u9009\u4e8b\u4ef6\uff0c\u7531\u5927\u7684\u76ee\u6807\u6a21\u578b\u5e76\u884c\u9a8c\u8bc1\u3002", "result": "TPP - SD\u4fdd\u6301\u4e0e\u81ea\u56de\u5f52\u91c7\u6837\u76f8\u540c\u7684\u8f93\u51fa\u5206\u5e03\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u6bd4\u6807\u51c6\u65b9\u6cd5\u67092 - 6\u500d\u63d0\u901f\u3002", "conclusion": "TPP - SD\u5f25\u5408\u4e86\u5f3a\u5927\u7684Transformer TPP\u6a21\u578b\u4e0e\u5feb\u901f\u5e8f\u5217\u91c7\u6837\u5b9e\u9645\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.10446", "pdf": "https://arxiv.org/pdf/2507.10446", "abs": "https://arxiv.org/abs/2507.10446", "authors": ["Sudarshan Babu"], "title": "Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures", "categories": ["cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2310.17075", "summary": "The ability to transfer knowledge from prior experiences to novel tasks\nstands as a pivotal capability of intelligent agents, including both humans and\ncomputational models. This principle forms the basis of transfer learning,\nwhere large pre-trained neural networks are fine-tuned to adapt to downstream\ntasks. Transfer learning has demonstrated tremendous success, both in terms of\ntask adaptation speed and performance. However there are several domains where,\ndue to lack of data, training such large pre-trained models or foundational\nmodels is not a possibility - computational chemistry, computational\nimmunology, and medical imaging are examples. To address these challenges, our\nwork focuses on designing architectures to enable efficient acquisition of\npriors when large amounts of data are unavailable. In particular, we\ndemonstrate that we can use neural memory to enable adaptation on\nnon-stationary distributions with only a few samples. Then we demonstrate that\nour hypernetwork designs (a network that generates another network) can acquire\nmore generalizable priors than standard networks when trained with Model\nAgnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scene\ngeneration, demonstrating that they can acquire priors efficiently on just a\nhandful of training scenes, thereby leading to faster text-to-3D generation. We\nthen extend our hypernetwork framework to perform 3D segmentation on novel\nscenes with limited data by efficiently transferring priors from earlier viewed\nscenes. Finally, we repurpose an existing molecular generative method as a\npre-training framework that facilitates improved molecular property prediction,\naddressing critical challenges in computational immunology", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u6570\u636e\u7f3a\u4e4f\u573a\u666f\u4e0b\u8bbe\u8ba1\u67b6\u6784\u4ee5\u9ad8\u6548\u83b7\u53d6\u5148\u9a8c\u77e5\u8bc6\uff0c\u5229\u7528\u795e\u7ecf\u8bb0\u5fc6\u3001\u8d85\u7f51\u7edc\u7b49\u65b9\u6cd5\u5728\u591a\u9886\u57df\u53d6\u5f97\u6210\u679c\u3002", "motivation": "\u5728\u8ba1\u7b97\u5316\u5b66\u3001\u8ba1\u7b97\u514d\u75ab\u5b66\u548c\u533b\u5b66\u6210\u50cf\u7b49\u6570\u636e\u7f3a\u4e4f\u9886\u57df\uff0c\u65e0\u6cd5\u8bad\u7ec3\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u9700\u8bbe\u8ba1\u67b6\u6784\u4ee5\u9ad8\u6548\u83b7\u53d6\u5148\u9a8c\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528\u795e\u7ecf\u8bb0\u5fc6\u5728\u975e\u5e73\u7a33\u5206\u5e03\u4e0a\u4ec5\u7528\u5c11\u91cf\u6837\u672c\u5b9e\u73b0\u9002\u5e94\uff1b\u8bbe\u8ba1\u8d85\u7f51\u7edc\u7ed3\u5408MAML\u83b7\u53d6\u66f4\u5177\u6cdb\u5316\u6027\u7684\u5148\u9a8c\uff1b\u5c06\u8d85\u7f51\u7edc\u5e94\u7528\u4e8e3D\u573a\u666f\u751f\u6210\u548c\u5206\u5272\uff1b\u6539\u9020\u73b0\u6709\u5206\u5b50\u751f\u6210\u65b9\u6cd5\u4f5c\u4e3a\u9884\u8bad\u7ec3\u6846\u67b6\u3002", "result": "\u795e\u7ecf\u8bb0\u5fc6\u80fd\u5728\u5c11\u91cf\u6837\u672c\u4e0b\u5b9e\u73b0\u9002\u5e94\uff1b\u8d85\u7f51\u7edc\u5728\u5c11\u91cf\u8bad\u7ec3\u573a\u666f\u4e2d\u9ad8\u6548\u83b7\u53d6\u5148\u9a8c\uff0c\u5b9e\u73b0\u66f4\u5feb\u7684\u6587\u672c\u52303D\u751f\u6210\u53ca\u6709\u9650\u6570\u636e\u4e0b\u76843D\u5206\u5272\uff1b\u6539\u9020\u7684\u5206\u5b50\u751f\u6210\u9884\u8bad\u7ec3\u6846\u67b6\u6539\u5584\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u67b6\u6784\u548c\u65b9\u6cd5\u80fd\u5728\u6570\u636e\u7f3a\u4e4f\u573a\u666f\u4e0b\u9ad8\u6548\u83b7\u53d6\u5148\u9a8c\u77e5\u8bc6\uff0c\u89e3\u51b3\u591a\u4e2a\u9886\u57df\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2507.09036", "pdf": "https://arxiv.org/pdf/2507.09036", "abs": "https://arxiv.org/abs/2507.09036", "authors": ["Florian Kofler", "Marcel Rosier", "Mehdi Astaraki", "Hendrik M\u00f6ller", "Ilhem Isra Mekki", "Josef A. Buchner", "Anton Schmick", "Arianna Pfiffer", "Eva Oswald", "Lucas Zimmer", "Ezequiel de la Rosa", "Sarthak Pati", "Julian Canisius", "Arianna Piffer", "Ujjwal Baid", "Mahyar Valizadeh", "Akis Linardos", "Jan C. Peeken", "Surprosanna Shit", "Felix Steinbauer", "Daniel Rueckert", "Rolf Heckemann", "Spyridon Bakas", "Jan Kirschke", "Constantin von See", "Ivan Ezhov", "Marie Piraud", "Benedikt Wiestler", "Bjoern Menze"], "title": "BrainLesion Suite: A Flexible and User-Friendly Framework for Modular Brain Lesion Image Analysis", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SE"], "comment": "16p, 3f", "summary": "BrainLesion Suite is a versatile toolkit for building modular brain lesion\nimage analysis pipelines in Python. Following Pythonic principles, BrainLesion\nSuite is designed to provide a 'brainless' development experience, minimizing\ncognitive effort and streamlining the creation of complex workflows for\nclinical and scientific practice. At its core is an adaptable preprocessing\nmodule that performs co-registration, atlas registration, and optional\nskull-stripping and defacing on arbitrary multi-modal input images. BrainLesion\nSuite leverages algorithms from the BraTS challenge to synthesize missing\nmodalities, inpaint lesions, and generate pathology-specific tumor\nsegmentations. BrainLesion Suite also enables quantifying segmentation model\nperformance, with tools such as panoptica to compute lesion-wise metrics.\nAlthough BrainLesion Suite was originally developed for image analysis\npipelines of brain lesions such as glioma, metastasis, and multiple sclerosis,\nit can be adapted for other biomedical image analysis applications. The\nindividual BrainLesion Suite packages and tutorials are accessible on GitHub.", "AI": {"tldr": "BrainLesion Suite\u662f\u7528\u4e8e\u6784\u5efa\u6a21\u5757\u5316\u8111\u75c5\u53d8\u56fe\u50cf\u5206\u6790\u7ba1\u9053\u7684Python\u5de5\u5177\u5305\uff0c\u5177\u6709\u6613\u7528\u6027\u548c\u591a\u529f\u80fd\u6027\uff0c\u53ef\u7528\u4e8e\u591a\u79cd\u8111\u75c5\u53d8\u53ca\u5176\u4ed6\u751f\u7269\u533b\u5b66\u56fe\u50cf\u5206\u6790\uff0c\u4ee3\u7801\u548c\u6559\u7a0b\u5728GitHub\u4e0a\u53ef\u83b7\u53d6\u3002", "motivation": "\u63d0\u4f9b\u4e00\u4e2a\u9075\u5faaPython\u539f\u5219\u7684\u5de5\u5177\u5305\uff0c\u51cf\u5c11\u5f00\u53d1\u7684\u8ba4\u77e5\u8d1f\u62c5\uff0c\u7b80\u5316\u4e34\u5e8a\u548c\u79d1\u5b66\u5b9e\u8df5\u4e2d\u590d\u6742\u5de5\u4f5c\u6d41\u7684\u521b\u5efa\u3002", "method": "\u6838\u5fc3\u662f\u53ef\u9002\u5e94\u7684\u9884\u5904\u7406\u6a21\u5757\uff0c\u5229\u7528BraTS\u6311\u6218\u7684\u7b97\u6cd5\u5408\u6210\u7f3a\u5931\u6a21\u6001\u3001\u4fee\u590d\u75c5\u53d8\u548c\u751f\u6210\u80bf\u7624\u5206\u5272\uff0c\u8fd8\u80fd\u4f7f\u7528panoptica\u7b49\u5de5\u5177\u91cf\u5316\u5206\u5272\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5f00\u53d1\u51faBrainLesion Suite\u5de5\u5177\u5305\uff0c\u53ef\u7528\u4e8e\u8111\u75c5\u53d8\u56fe\u50cf\u5206\u6790\u53ca\u5176\u4ed6\u751f\u7269\u533b\u5b66\u56fe\u50cf\u5206\u6790\u3002", "conclusion": "BrainLesion Suite\u5177\u6709\u901a\u7528\u6027\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u591a\u79cd\u8111\u75c5\u53d8\u56fe\u50cf\u5206\u6790\uff0c\u8fd8\u80fd\u5e94\u7528\u4e8e\u5176\u4ed6\u751f\u7269\u533b\u5b66\u56fe\u50cf\u5206\u6790\u573a\u666f\u3002"}}
{"id": "2507.09084", "pdf": "https://arxiv.org/pdf/2507.09084", "abs": "https://arxiv.org/abs/2507.09084", "authors": ["Nnamdi Daniel Aghanya", "Ta Duong Vu", "Ama\u00eblle Diop", "Charlotte Deville", "Nour Imane Kerroumi", "Irene Moulitsas", "Jun Li", "Desmond Bisandu"], "title": "Queue up for takeoff: a transferable deep learning framework for flight delay prediction", "categories": ["cs.LG", "cs.AI", "68T07, 90B22, 62M10", "I.2.m"], "comment": "3 figures, 20 pages references and appendix included,", "summary": "Flight delays are a significant challenge in the aviation industry, causing\nmajor financial and operational disruptions. To improve passenger experience\nand reduce revenue loss, flight delay prediction models must be both precise\nand generalizable across different networks. This paper introduces a novel\napproach that combines Queue-Theory with a simple attention model, referred to\nas the Queue-Theory SimAM (QT-SimAM). To validate our model, we used data from\nthe US Bureau of Transportation Statistics, where our proposed QT-SimAM\n(Bidirectional) model outperformed existing methods with an accuracy of 0.927\nand an F1 score of 0.932. To assess transferability, we tested the model on the\nEUROCONTROL dataset. The results demonstrated strong performance, achieving an\naccuracy of 0.826 and an F1 score of 0.791. Ultimately, this paper outlines an\neffective, end-to-end methodology for predicting flight delays. The proposed\nmodel's ability to forecast delays with high accuracy across different networks\ncan help reduce passenger anxiety and improve operational decision-making", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u961f\u5217\u7406\u8bba\u4e0e\u7b80\u5355\u6ce8\u610f\u529b\u6a21\u578b\u7684QT - SimAM\u65b9\u6cd5\u9884\u6d4b\u822a\u73ed\u5ef6\u8bef\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u8868\u73b0\u4f18\u5f02\uff0c\u53ef\u63d0\u5347\u51b3\u7b56\u4e0e\u65c5\u5ba2\u4f53\u9a8c\u3002", "motivation": "\u822a\u73ed\u5ef6\u8bef\u5e26\u6765\u8d22\u52a1\u548c\u8fd0\u8425\u5e72\u6270\uff0c\u9700\u7cbe\u51c6\u4e14\u53ef\u8de8\u7f51\u7edc\u901a\u7528\u7684\u822a\u73ed\u5ef6\u8bef\u9884\u6d4b\u6a21\u578b\u4ee5\u6539\u5584\u65c5\u5ba2\u4f53\u9a8c\u548c\u51cf\u5c11\u6536\u5165\u635f\u5931\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u961f\u5217\u7406\u8bba\u4e0e\u7b80\u5355\u6ce8\u610f\u529b\u6a21\u578b\u7684QT - SimAM\u65b9\u6cd5\uff0c\u4f7f\u7528\u7f8e\u56fd\u8fd0\u8f93\u7edf\u8ba1\u5c40\u6570\u636e\u9a8c\u8bc1\u6a21\u578b\uff0c\u5e76\u5728EUROCONTROL\u6570\u636e\u96c6\u6d4b\u8bd5\u53ef\u8fc1\u79fb\u6027\u3002", "result": "QT - SimAM\uff08\u53cc\u5411\uff09\u6a21\u578b\u5728\u7f8e\u56fd\u6570\u636e\u4e0a\u51c6\u786e\u73870.927\u3001F1\u5206\u65700.932\uff1b\u5728EUROCONTROL\u6570\u636e\u96c6\u51c6\u786e\u73870.826\u3001F1\u5206\u65700.791\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u8de8\u4e0d\u540c\u7f51\u7edc\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u5ef6\u8bef\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u65c5\u5ba2\u7126\u8651\u548c\u6539\u5584\u8fd0\u8425\u51b3\u7b56\u3002"}}
{"id": "2507.10522", "pdf": "https://arxiv.org/pdf/2507.10522", "abs": "https://arxiv.org/abs/2507.10522", "authors": ["Jennifer D'Souza", "Endres Keno Sander", "Andrei Aioanei"], "title": "DeepResearch$^{\\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "12 pages, 3 figures", "summary": "We introduce DeepResearch$^{\\text{Eco}}$, a novel agentic LLM-based system\nfor automated scientific synthesis that supports recursive, depth- and\nbreadth-controlled exploration of original research questions -- enhancing\nsearch diversity and nuance in the retrieval of relevant scientific literature.\nUnlike conventional retrieval-augmented generation pipelines, DeepResearch\nenables user-controllable synthesis with transparent reasoning and\nparameter-driven configurability, facilitating high-throughput integration of\ndomain-specific evidence while maintaining analytical rigor. Applied to 49\necological research questions, DeepResearch achieves up to a 21-fold increase\nin source integration and a 14.9-fold rise in sources integrated per 1,000\nwords. High-parameter settings yield expert-level analytical depth and\ncontextual diversity.\n  Source code available at: https://github.com/sciknoworg/deep-research.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u79d1\u7814\u7efc\u5408\u7cfb\u7edfDeepResearch$^{\text{Eco}}$\uff0c\u5728\u751f\u6001\u7814\u7a76\u95ee\u9898\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f00\u53d1\u652f\u6301\u9012\u5f52\u3001\u53ef\u63a7\u5236\u6df1\u5ea6\u548c\u5e7f\u5ea6\u63a2\u7d22\u539f\u59cb\u7814\u7a76\u95ee\u9898\u7684\u81ea\u52a8\u5316\u79d1\u7814\u7efc\u5408\u7cfb\u7edf\uff0c\u63d0\u5347\u641c\u7d22\u591a\u6837\u6027\u548c\u68c0\u7d22\u7cbe\u51c6\u5ea6\u3002", "method": "\u6784\u5efaDeepResearch$^{\text{Eco}}$\u7cfb\u7edf\uff0c\u5b9e\u73b0\u7528\u6237\u53ef\u63a7\u7684\u5408\u6210\u3001\u900f\u660e\u63a8\u7406\u548c\u53c2\u6570\u9a71\u52a8\u7684\u53ef\u914d\u7f6e\u6027\u3002", "result": "\u5e94\u7528\u4e8e49\u4e2a\u751f\u6001\u7814\u7a76\u95ee\u9898\uff0c\u6e90\u6574\u5408\u6700\u591a\u63d0\u534721\u500d\uff0c\u6bcf1000\u5b57\u6e90\u6574\u5408\u63d0\u534714.9\u500d\uff0c\u9ad8\u53c2\u6570\u8bbe\u7f6e\u6709\u4e13\u5bb6\u7ea7\u5206\u6790\u6df1\u5ea6\u548c\u4e0a\u4e0b\u6587\u591a\u6837\u6027\u3002", "conclusion": "DeepResearch$^{\text{Eco}}$\u7cfb\u7edf\u5728\u79d1\u7814\u6587\u732e\u68c0\u7d22\u548c\u6574\u5408\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u9ad8\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.09353", "pdf": "https://arxiv.org/pdf/2507.09353", "abs": "https://arxiv.org/abs/2507.09353", "authors": ["Addison Weatherhead", "Anna Goldenberg"], "title": "Impute With Confidence: A Framework for Uncertainty Aware Multivariate Time Series Imputation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Time series data with missing values is common across many domains.\nHealthcare presents special challenges due to prolonged periods of sensor\ndisconnection. In such cases, having a confidence measure for imputed values is\ncritical. Most existing methods either overlook model uncertainty or lack\nmechanisms to estimate it. To address this gap, we introduce a general\nframework that quantifies and leverages uncertainty for selective imputation.\nBy focusing on values the model is most confident in, highly unreliable\nimputations are avoided. Our experiments on multiple EHR datasets, covering\ndiverse types of missingness, demonstrate that selectively imputing\nless-uncertain values not only reduces imputation errors but also improves\ndownstream tasks. Specifically, we show performance gains in a 24-hour\nmortality prediction task, underscoring the practical benefit of incorporating\nuncertainty into time series imputation.", "AI": {"tldr": "\u63d0\u51fa\u91cf\u5316\u548c\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u9009\u62e9\u6027\u63d2\u8865\u7684\u6846\u67b6\uff0c\u5728\u591aEHR\u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\u53ef\u51cf\u5c11\u63d2\u8865\u8bef\u5dee\u5e76\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7f3a\u5931\u503c\u5e38\u89c1\uff0c\u533b\u7597\u9886\u57df\u6709\u7279\u6b8a\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u5ffd\u89c6\u6216\u65e0\u6cd5\u4f30\u8ba1\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u6709\u5bf9\u63d2\u8865\u503c\u7684\u7f6e\u4fe1\u5ea6\u5ea6\u91cf\u3002", "method": "\u5f15\u5165\u91cf\u5316\u548c\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u9009\u62e9\u6027\u63d2\u8865\u7684\u901a\u7528\u6846\u67b6\uff0c\u805a\u7126\u6a21\u578b\u6700\u6709\u4fe1\u5fc3\u7684\u503c\u3002", "result": "\u5728\u591a\u4e2a\u6db5\u76d6\u4e0d\u540c\u7f3a\u5931\u7c7b\u578b\u7684EHR\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u9009\u62e9\u6027\u63d2\u8865\u4f4e\u4e0d\u786e\u5b9a\u6027\u503c\u51cf\u5c11\u4e86\u63d2\u8865\u8bef\u5dee\uff0c\u572824\u5c0f\u65f6\u6b7b\u4ea1\u7387\u9884\u6d4b\u4efb\u52a1\u4e2d\u6709\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5c06\u4e0d\u786e\u5b9a\u6027\u7eb3\u5165\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u6709\u5b9e\u9645\u76ca\u5904\u3002"}}
{"id": "2412.11407", "pdf": "https://arxiv.org/pdf/2412.11407", "abs": "https://arxiv.org/abs/2412.11407", "authors": ["TianZhu Liu", "BangYan Hu", "YanFeng Gu", "Xian Li", "Aleksandra Pi\u017eurica"], "title": "An Enhanced Classification Method Based on Adaptive Multi-Scale Fusion for Long-tailed Multispectral Point Clouds", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "16 pages, 9 figures, 5 tables", "summary": "Multispectral point cloud (MPC) captures 3D spatial-spectral information from\nthe observed scene, which can be used for scene understanding and has a wide\nrange of applications. However, most of the existing classification methods\nwere extensively tested on indoor datasets, and when applied to outdoor\ndatasets they still face problems including sparse labeled targets, differences\nin land-covers scales, and long-tailed distributions. To address the above\nissues, an enhanced classification method based on adaptive multi-scale fusion\nfor MPCs with long-tailed distributions is proposed. In the training set\ngeneration stage, a grid-balanced sampling strategy is designed to reliably\ngenerate training samples from sparse labeled datasets. In the feature learning\nstage, a multi-scale feature fusion module is proposed to fuse shallow features\nof land-covers at different scales, addressing the issue of losing fine\nfeatures due to scale variations in land-covers. In the classification stage,\nan adaptive hybrid loss module is devised to utilize multi-classification heads\nwith adaptive weights to balance the learning ability of different classes,\nimproving the classification performance of small classes due to various-scales\nand long-tailed distributions in land-covers. Experimental results on three MPC\ndatasets demonstrate the effectiveness of the proposed method compared with the\nstate-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u81ea\u9002\u5e94\u591a\u5c3a\u5ea6\u878d\u5408\u7684\u591a\u5149\u8c31\u70b9\u4e91\u5206\u7c7b\u65b9\u6cd5\uff0c\u89e3\u51b3\u6237\u5916\u6570\u636e\u96c6\u5206\u7c7b\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u5149\u8c31\u70b9\u4e91\u5206\u7c7b\u65b9\u6cd5\u5728\u6237\u5916\u6570\u636e\u96c6\u5b58\u5728\u6807\u8bb0\u76ee\u6807\u7a00\u758f\u3001\u5730\u7269\u5c3a\u5ea6\u5dee\u5f02\u548c\u957f\u5c3e\u5206\u5e03\u7b49\u95ee\u9898\u3002", "method": "\u8bad\u7ec3\u96c6\u751f\u6210\u9636\u6bb5\u91c7\u7528\u7f51\u683c\u5e73\u8861\u91c7\u6837\u7b56\u7565\uff1b\u7279\u5f81\u5b66\u4e60\u9636\u6bb5\u63d0\u51fa\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\u6a21\u5757\uff1b\u5206\u7c7b\u9636\u6bb5\u8bbe\u8ba1\u81ea\u9002\u5e94\u6df7\u5408\u635f\u5931\u6a21\u5757\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u5149\u8c31\u70b9\u4e91\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6237\u5916\u6570\u636e\u96c6\u5206\u7c7b\u4e2d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2507.10324", "pdf": "https://arxiv.org/pdf/2507.10324", "abs": "https://arxiv.org/abs/2507.10324", "authors": ["Amit K. Chopra", "Samuel H. Christie V", "Munindar P. Singh"], "title": "Toolsuite for Implementing Multiagent Systems Based on Communication Protocols", "categories": ["cs.MA", "cs.AI", "cs.PL", "cs.SE", "I.2.11; I.2.4; I.2.5"], "comment": null, "summary": "Interaction-Oriented Programming (IOP) is an approach to building a\nmultiagent system by modeling the interactions between its roles via a flexible\ninteraction protocol and implementing agents to realize the interactions of the\nroles they play in the protocol.\n  In recent years, we have developed an extensive suite of software that\nenables multiagent system developers to apply IOP. These include tools for\nefficiently verifying protocols for properties such as liveness and safety and\nmiddleware that simplifies the implementation of agents. This paper presents\nsome of that software suite.", "AI": {"tldr": "\u4ecb\u7ecd\u9762\u5411\u4ea4\u4e92\u7f16\u7a0b\uff08IOP\uff09\u53ca\u76f8\u5173\u8f6f\u4ef6\u5957\u4ef6\u3002", "motivation": "\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u53d1\u8005\u63d0\u4f9b\u53ef\u5e94\u7528IOP\u7684\u8f6f\u4ef6\u5de5\u5177\u3002", "method": "\u5f00\u53d1\u4e00\u7cfb\u5217\u8f6f\u4ef6\uff0c\u5305\u62ec\u9a8c\u8bc1\u534f\u8bae\u5de5\u5177\u548c\u7b80\u5316\u667a\u80fd\u4f53\u5b9e\u73b0\u7684\u4e2d\u95f4\u4ef6\u3002", "result": "\u5f00\u53d1\u51fa\u4e86\u4e00\u7cfb\u5217\u80fd\u8ba9\u5f00\u53d1\u8005\u5e94\u7528IOP\u7684\u8f6f\u4ef6\u3002", "conclusion": "\u5c55\u793a\u4e86\u90e8\u5206\u5f00\u53d1\u51fa\u7684\u8f6f\u4ef6\u5957\u4ef6\u3002"}}
{"id": "2507.09380", "pdf": "https://arxiv.org/pdf/2507.09380", "abs": "https://arxiv.org/abs/2507.09380", "authors": ["Haoming Shi", "Shan Yu", "Eric C. Chi"], "title": "Robust Spatiotemporal Epidemic Modeling with Integrated Adaptive Outlier Detection", "categories": ["stat.ME", "physics.soc-ph", "stat.ML"], "comment": "35 pages, 8 figures, 3 tables", "summary": "In epidemic modeling, outliers can distort parameter estimation and\nultimately lead to misguided public health decisions. Although there are\nexisting robust methods that can mitigate this distortion, the ability to\nsimultaneously detect outliers is equally vital for identifying potential\ndisease hotspots. In this work, we introduce a robust spatiotemporal\ngeneralized additive model (RST-GAM) to address this need. We accomplish this\nwith a mean-shift parameter to quantify and adjust for the effects of outliers\nand rely on adaptive Lasso regularization to model the sparsity of outlying\nobservations. We use univariate polynomial splines and bivariate penalized\nsplines over triangulations to estimate the functional forms and a\ndata-thinning approach for data-adaptive weight construction. We derive a\nscalable proximal algorithm to estimate model parameters by minimizing a convex\nnegative log-quasi-likelihood function. Our algorithm uses adaptive step-sizes\nto ensure global convergence of the resulting iterate sequence. We establish\nerror bounds and selection consistency for the estimated parameters and\ndemonstrate our model's effectiveness through numerical studies under various\noutlier scenarios. Finally, we demonstrate the practical utility of RST-GAM by\nanalyzing county-level COVID-19 infection data in the United States,\nhighlighting its potential to inform public health decision-making.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9c81\u68d2\u65f6\u7a7a\u5e7f\u4e49\u76f8\u52a0\u6a21\u578b\uff08RST - GAM\uff09\u6765\u5904\u7406\u75ab\u60c5\u5efa\u6a21\u4e2d\u7684\u79bb\u7fa4\u503c\u95ee\u9898\uff0c\u63a8\u5bfc\u7b97\u6cd5\u4f30\u8ba1\u53c2\u6570\u5e76\u8bc1\u660e\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u75ab\u60c5\u5efa\u6a21\u4e2d\u79bb\u7fa4\u503c\u4f1a\u626d\u66f2\u53c2\u6570\u4f30\u8ba1\u548c\u8bef\u5bfc\u516c\u5171\u536b\u751f\u51b3\u7b56\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u540c\u65f6\u68c0\u6d4b\u79bb\u7fa4\u503c\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165\u5747\u503c\u6f02\u79fb\u53c2\u6570\u91cf\u5316\u548c\u8c03\u6574\u79bb\u7fa4\u503c\u5f71\u54cd\uff0c\u4f7f\u7528\u81ea\u9002\u5e94Lasso\u6b63\u5219\u5316\uff0c\u7528\u5355\u53d8\u91cf\u591a\u9879\u5f0f\u6837\u6761\u548c\u53cc\u53d8\u91cf\u60e9\u7f5a\u6837\u6761\u4f30\u8ba1\u51fd\u6570\u5f62\u5f0f\uff0c\u91c7\u7528\u6570\u636e\u7a00\u758f\u6cd5\u6784\u5efa\u6743\u91cd\uff0c\u63a8\u5bfc\u53ef\u6269\u5c55\u7684\u8fd1\u7aef\u7b97\u6cd5\u4f30\u8ba1\u53c2\u6570\u3002", "result": "\u5efa\u7acb\u4e86\u4f30\u8ba1\u53c2\u6570\u7684\u8bef\u5dee\u754c\u548c\u9009\u62e9\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u6570\u503c\u7814\u7a76\u8bc1\u660e\u6a21\u578b\u5728\u4e0d\u540c\u79bb\u7fa4\u503c\u573a\u666f\u4e0b\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u7f8e\u56fd\u53bf\u7ea7COVID - 19\u611f\u67d3\u6570\u636e\u4f53\u73b0\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "RST - GAM\u6709\u6f5c\u529b\u4e3a\u516c\u5171\u536b\u751f\u51b3\u7b56\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2507.07855", "pdf": "https://arxiv.org/pdf/2507.07855", "abs": "https://arxiv.org/abs/2507.07855", "authors": ["Wenxuan Zhou", "Shujian Zhang", "Brice Magdalou", "John Lambert", "Ehsan Amid", "Richard Nock", "Andrew Hard"], "title": "Principled Foundations for Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": null, "summary": "In this paper, we show that direct preference optimization (DPO) is a very\nspecific form of a connection between two major theories in the ML context of\nlearning from preferences: loss functions (Savage) and stochastic choice\n(Doignon-Falmagne and Machina). The connection is established for all of\nSavage's losses and at this level of generality, (i) it includes support for\nabstention on the choice theory side, (ii) it includes support for non-convex\nobjectives on the ML side, and (iii) it allows to frame for free some notable\nextensions of the DPO setting, including margins and corrections for length.\nGetting to understand how DPO operates from a general principled perspective is\ncrucial because of the huge and diverse application landscape of models,\nbecause of the current momentum around DPO, but also -- and importantly --\nbecause many state of the art variations on DPO definitely occupy a small\nregion of the map that we cover. It also helps to understand the pitfalls of\ndeparting from this map, and figure out workarounds.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u662f\u673a\u5668\u5b66\u4e60\u504f\u597d\u5b66\u4e60\u4e2d\u635f\u5931\u51fd\u6570\u548c\u968f\u673a\u9009\u62e9\u4e24\u5927\u7406\u8bba\u8054\u7cfb\u7684\u7279\u6b8a\u5f62\u5f0f\uff0c\u8fd8\u8bf4\u660e\u4e86\u7406\u89e3DPO\u539f\u7406\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u9274\u4e8e\u6a21\u578b\u5e94\u7528\u5e7f\u6cdb\u3001DPO\u53d1\u5c55\u52bf\u5934\u6b63\u76db\u4ee5\u53ca\u73b0\u6709DPO\u53d8\u4f53\u8986\u76d6\u8303\u56f4\u5c0f\uff0c\u9700\u8981\u4ece\u901a\u7528\u539f\u5219\u89c6\u89d2\u7406\u89e3DPO\u7684\u8fd0\u4f5c\u3002", "method": "\u5efa\u7acbSavage\u635f\u5931\u51fd\u6570\u548c\u968f\u673a\u9009\u62e9\u7406\u8bba\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u6db5\u76d6\u5f03\u6743\u652f\u6301\u3001\u975e\u51f8\u76ee\u6807\u652f\u6301\u7b49\u3002", "result": "\u5efa\u7acb\u4e86DPO\u4e0e\u4e24\u5927\u7406\u8bba\u7684\u8054\u7cfb\uff0c\u53ef\u514d\u8d39\u6784\u5efaDPO\u8bbe\u7f6e\u7684\u663e\u8457\u6269\u5c55\u3002", "conclusion": "\u4ece\u901a\u7528\u539f\u5219\u89c6\u89d2\u7406\u89e3DPO\u5f88\u5173\u952e\uff0c\u6709\u52a9\u4e8e\u4e86\u89e3\u504f\u79bb\u7684\u9677\u9631\u5e76\u627e\u5230\u89e3\u51b3\u529e\u6cd5\u3002"}}
{"id": "2507.10535", "pdf": "https://arxiv.org/pdf/2507.10535", "abs": "https://arxiv.org/abs/2507.10535", "authors": ["Hongchao Jiang", "Yiming Chen", "Yushi Cao", "Hung-yi Lee", "Robby T. Tan"], "title": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "Dataset is available at\n  https://huggingface.co/datasets/mattymchen/codejudgebench", "summary": "Large Language Models (LLMs) have significantly advanced the state-of-the-art\nin various coding tasks. Beyond directly answering user queries, LLMs can also\nserve as judges, assessing and comparing the quality of responses generated by\nother models. Such an evaluation capability is crucial both for benchmarking\ndifferent LLMs and for improving response quality through response ranking.\nHowever, despite the growing adoption of the LLM-as-a-Judge paradigm, its\neffectiveness in coding scenarios remains underexplored due to the absence of\ndedicated benchmarks. To address this gap, we introduce CodeJudgeBench, a\nbenchmark explicitly designed to evaluate the performance of LLM-as-a-Judge\nmodels across three critical coding tasks: code generation, code repair, and\nunit test generation. Through comprehensive benchmarking of 26 LLM-as-a-Judge\nmodels, we find that recent thinking models significantly outperform\nnon-thinking models on our carefully designed code judging tasks. Notably, even\nrelatively small thinking models, such as Qwen3-8B, can outperform specially\ntrained LLM-as-a-Judge models up to 70B in size. Nevertheless, all models still\nexhibit significant randomness in their judgment of coding tasks. For pairwise\njudging tasks, simply changing the order in which responses are presented can\nsubstantially impact accuracy. In addition, when judging code and unit tests\nwritten by different LLMs, LLM-as-a-Judge models also show variance in\nperformance. This sensitivity raises concerns about the reliability and\nconsistency of LLM-as-a-Judge in coding scenarios. Lastly, we study optimal\nprompting strategies for LLM-as-a-Judge. We find that using pair-wise\ncomparison outperforms scalar point-wise judging. Furthermore, retaining\ncomments and reasoning in the full, unprocessed LLM response leads to improved\njudge performance.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165CodeJudgeBench\u8bc4\u4f30LLM\u4f5c\u4e3a\u88c1\u5224\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u601d\u7ef4\u6a21\u578b\u8868\u73b0\u66f4\u597d\u4f46\u6240\u6709\u6a21\u578b\u6709\u968f\u673a\u6027\uff0c\u8fd8\u7814\u7a76\u4e86\u6700\u4f18\u63d0\u793a\u7b56\u7565\u3002", "motivation": "LLM\u4f5c\u4e3a\u88c1\u5224\u5728\u7f16\u7801\u573a\u666f\u7684\u6709\u6548\u6027\u56e0\u7f3a\u4e4f\u4e13\u7528\u57fa\u51c6\u800c\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u5f15\u5165CodeJudgeBench\uff0c\u5bf926\u4e2aLLM\u4f5c\u4e3a\u88c1\u5224\u7684\u6a21\u578b\u8fdb\u884c\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u601d\u7ef4\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u975e\u601d\u7ef4\u6a21\u578b\uff0c\u5c0f\u7684\u601d\u7ef4\u6a21\u578b\u80fd\u80dc\u8fc7\u5927\u578b\u7279\u5236\u6a21\u578b\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5224\u65ad\u6709\u968f\u673a\u6027\uff0c\u5448\u73b0\u987a\u5e8f\u5f71\u54cd\u51c6\u786e\u7387\uff0c\u8bc4\u5224\u4e0d\u540cLLM\u4ee3\u7801\u548c\u5355\u5143\u6d4b\u8bd5\u65f6\u6027\u80fd\u6709\u5dee\u5f02\u3002\u4f7f\u7528\u6210\u5bf9\u6bd4\u8f83\u548c\u4fdd\u7559\u5b8c\u6574\u672a\u5904\u7406\u54cd\u5e94\u7684\u8bc4\u8bba\u53ca\u63a8\u7406\u80fd\u63d0\u5347\u8bc4\u5224\u6027\u80fd\u3002", "conclusion": "LLM\u4f5c\u4e3a\u88c1\u5224\u5728\u7f16\u7801\u573a\u666f\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u5b58\u5728\u95ee\u9898\uff0c\u540c\u65f6\u7ed9\u51fa\u4e86\u8f83\u4f18\u7684\u63d0\u793a\u7b56\u7565\u3002"}}
{"id": "2507.09095", "pdf": "https://arxiv.org/pdf/2507.09095", "abs": "https://arxiv.org/abs/2507.09095", "authors": ["Md Hasan Shahriar", "Md Mohaimin Al Barat", "Harshavardhan Sundar", "Naren Ramakrishnan", "Y. Thomas Hou", "Wenjing Lou"], "title": "On the Fragility of Multimodal Perception to Temporal Misalignment in Autonomous Driving", "categories": ["cs.LG"], "comment": "16 pages", "summary": "Multimodal fusion (MMF) plays a critical role in the perception of autonomous\ndriving, which primarily fuses camera and LiDAR streams for a comprehensive and\nefficient scene understanding. However, its strict reliance on precise temporal\nsynchronization exposes it to new vulnerabilities. In this paper, we introduce\nDejaVu, a novel attack that exploits network-induced delays to create subtle\ntemporal misalignments across sensor streams, severely degrading downstream\nMMF-based perception tasks. Our comprehensive attack analysis across different\nmodels and datasets reveals these sensors' task-specific imbalanced\nsensitivities: object detection is overly dependent on LiDAR inputs while\nobject tracking is highly reliant on the camera inputs. Consequently, with a\nsingle-frame LiDAR delay, an attacker can reduce the car detection mAP by up to\n88.5%, while with a three-frame camera delay, multiple object tracking accuracy\n(MOTA) for car drops by 73%. To detect such attacks, we propose AION, a defense\npatch that can work alongside the existing perception model to monitor temporal\nalignment through cross-modal temporal consistency. AION leverages multimodal\nshared representation learning and dynamic time warping to determine the path\nof temporal alignment and calculate anomaly scores based on the alignment. Our\nthorough evaluation of AION shows it achieves AUROC scores of 0.92-0.98 with\nlow false positives across datasets and model architectures, demonstrating it\nas a robust and generalized defense against the temporal misalignment attacks.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u591a\u6a21\u6001\u878d\u5408\u7684DejaVu\u653b\u51fb\u53caAION\u9632\u5fa1\u65b9\u6cd5\uff0c\u653b\u51fb\u53ef\u5927\u5e45\u964d\u4f4e\u611f\u77e5\u4efb\u52a1\u6027\u80fd\uff0c\u9632\u5fa1\u65b9\u6cd5\u6548\u679c\u597d\u3002", "motivation": "\u591a\u6a21\u6001\u878d\u5408\u4f9d\u8d56\u7cbe\u786e\u65f6\u95f4\u540c\u6b65\uff0c\u5b58\u5728\u56e0\u7f51\u7edc\u5ef6\u8fdf\u5bfc\u81f4\u65f6\u95f4\u4e0d\u5bf9\u9f50\u7684\u6f0f\u6d1e\uff0c\u9700\u7814\u7a76\u653b\u51fb\u548c\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDejaVu\u653b\u51fb\u5229\u7528\u7f51\u7edc\u5ef6\u8fdf\u5236\u9020\u65f6\u95f4\u4e0d\u5bf9\u9f50\uff0c\u5206\u6790\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0b\u4f20\u611f\u5668\u5bf9\u4efb\u52a1\u7684\u654f\u611f\u6027\uff1b\u63d0\u51faAION\u9632\u5fa1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u65f6\u95f4\u4e00\u81f4\u6027\u76d1\u6d4b\uff0c\u5229\u7528\u591a\u6a21\u6001\u5171\u4eab\u8868\u793a\u5b66\u4e60\u548c\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u8ba1\u7b97\u5f02\u5e38\u5206\u6570\u3002", "result": "DejaVu\u653b\u51fb\u80fd\u4f7f\u6c7d\u8f66\u68c0\u6d4bmAP\u6700\u591a\u964d\u4f4e88.5%\uff0c\u591a\u76ee\u6807\u8ddf\u8e2a\u51c6\u786e\u7387\u4e0b\u964d73%\uff1bAION\u9632\u5fa1\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u6a21\u578b\u67b6\u6784\u4e0bAUROC\u5206\u6570\u8fbe0.92 - 0.98\uff0c\u8bef\u62a5\u7387\u4f4e\u3002", "conclusion": "AION\u662f\u4e00\u79cd\u9488\u5bf9\u65f6\u95f4\u4e0d\u5bf9\u9f50\u653b\u51fb\u7684\u5f3a\u5927\u4e14\u901a\u7528\u7684\u9632\u5fa1\u65b9\u6cd5\u3002"}}
{"id": "2507.09388", "pdf": "https://arxiv.org/pdf/2507.09388", "abs": "https://arxiv.org/abs/2507.09388", "authors": ["T. Tony Cai", "Abhinav Chakraborty", "Yichen Wang"], "title": "Optimal Differentially Private Ranking from Pairwise Comparisons", "categories": ["math.ST", "stat.ME", "stat.ML", "stat.TH"], "comment": null, "summary": "Data privacy is a central concern in many applications involving ranking from\nincomplete and noisy pairwise comparisons, such as recommendation systems,\neducational assessments, and opinion surveys on sensitive topics. In this work,\nwe propose differentially private algorithms for ranking based on pairwise\ncomparisons. Specifically, we develop and analyze ranking methods under two\nprivacy notions: edge differential privacy, which protects the confidentiality\nof individual comparison outcomes, and individual differential privacy, which\nsafeguards potentially many comparisons contributed by a single individual. Our\nalgorithms--including a perturbed maximum likelihood estimator and a noisy\ncount-based method--are shown to achieve minimax optimal rates of convergence\nunder the respective privacy constraints. We further demonstrate the practical\neffectiveness of our methods through experiments on both simulated and\nreal-world data.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6210\u5bf9\u6bd4\u8f83\u7684\u5dee\u5206\u9690\u79c1\u6392\u540d\u7b97\u6cd5\uff0c\u5728\u4e24\u79cd\u9690\u79c1\u6982\u5ff5\u4e0b\u5f00\u53d1\u5206\u6790\u65b9\u6cd5\uff0c\u7b97\u6cd5\u8fbe\u6536\u655b\u6700\u4f18\u7387\u5e76\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u6d89\u53ca\u4e0d\u5b8c\u6574\u548c\u5608\u6742\u6210\u5bf9\u6bd4\u8f83\u6392\u540d\u5e94\u7528\u4e2d\u7684\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u5982\u63a8\u8350\u7cfb\u7edf\u3001\u6559\u80b2\u8bc4\u4f30\u7b49\u3002", "method": "\u5728\u8fb9\u7f18\u5dee\u5206\u9690\u79c1\u548c\u4e2a\u4f53\u5dee\u5206\u9690\u79c1\u4e24\u79cd\u6982\u5ff5\u4e0b\u5f00\u53d1\u6392\u540d\u65b9\u6cd5\uff0c\u5305\u62ec\u6270\u52a8\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\u548c\u57fa\u4e8e\u566a\u58f0\u8ba1\u6570\u7684\u65b9\u6cd5\u3002", "result": "\u7b97\u6cd5\u5728\u5404\u81ea\u9690\u79c1\u7ea6\u675f\u4e0b\u8fbe\u5230\u4e86\u6781\u5c0f\u6781\u5927\u6700\u4f18\u6536\u655b\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5b9e\u9a8c\u4e2d\u90fd\u6709\u5b9e\u9645\u6709\u6548\u6027\u3002"}}
{"id": "2507.08052", "pdf": "https://arxiv.org/pdf/2507.08052", "abs": "https://arxiv.org/abs/2507.08052", "authors": ["Mazen Ali", "Ant\u00f3nio Pereira", "Fabio Gentile", "Aser Cortines", "Sam Mugel", "Rom\u00e1n Or\u00fas", "Stelios P. Neophytides", "Michalis Mavrovouniotis"], "title": "Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Cloud and cloud shadow masking is a crucial preprocessing step in\nhyperspectral satellite imaging, enabling the extraction of high-quality,\nanalysis-ready data. This study evaluates various machine learning approaches,\nincluding gradient boosting methods such as XGBoost and LightGBM as well as\nconvolutional neural networks (CNNs). All boosting and CNN models achieved\naccuracies exceeding 93%. Among the investigated models, the CNN with feature\nreduction emerged as the most efficient, offering a balance of high accuracy,\nlow storage requirements, and rapid inference times on both CPUs and GPUs.\nVariations of this version, with only up to 597 trainable parameters,\ndemonstrated the best trade-off in terms of deployment feasibility, accuracy,\nand computational efficiency. These results demonstrate the potential of\nlightweight artificial intelligence (AI) models for real-time hyperspectral\nimage processing, supporting the development of on-board satellite AI systems\nfor space-based applications.", "AI": {"tldr": "\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u9ad8\u5149\u8c31\u536b\u661f\u56fe\u50cf\u4e91\u4e0e\u4e91\u9634\u5f71\u63a9\u819c\uff0cCNN\u7279\u5f81\u964d\u7ef4\u6a21\u578b\u6700\u6709\u6548\uff0c\u8bc1\u660e\u8f7b\u91cf\u7ea7AI\u6a21\u578b\u7528\u4e8e\u5b9e\u65f6\u5904\u7406\u6f5c\u529b\u3002", "motivation": "\u4e91\u4e0e\u4e91\u9634\u5f71\u63a9\u819c\u662f\u9ad8\u5149\u8c31\u536b\u661f\u6210\u50cf\u5173\u952e\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u9700\u8bc4\u4f30\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ec\u68af\u5ea6\u63d0\u5347\u65b9\u6cd5\uff08XGBoost\u3001LightGBM\uff09\u548c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3002", "result": "\u6240\u6709\u63d0\u5347\u548cCNN\u6a21\u578b\u51c6\u786e\u7387\u8d8593%\uff0cCNN\u7279\u5f81\u964d\u7ef4\u6a21\u578b\u6700\u6709\u6548\uff0c\u53c2\u6570\u5c11\u7684\u7248\u672c\u5728\u90e8\u7f72\u53ef\u884c\u6027\u3001\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5e73\u8861\u6700\u4f73\u3002", "conclusion": "\u8f7b\u91cf\u7ea7AI\u6a21\u578b\u6709\u7528\u4e8e\u5b9e\u65f6\u9ad8\u5149\u8c31\u56fe\u50cf\u5904\u7406\u6f5c\u529b\uff0c\u652f\u6301\u661f\u8f7dAI\u7cfb\u7edf\u5f00\u53d1\u3002"}}
{"id": "2507.09101", "pdf": "https://arxiv.org/pdf/2507.09101", "abs": "https://arxiv.org/abs/2507.09101", "authors": ["Yanan Cao", "Omid Memarrast", "Shiqin Cai", "Sinduja Subramaniam", "Evren Korpeoglu", "Kannan Achan"], "title": "S2SRec2: Set-to-Set Recommendation for Basket Completion with Recipe", "categories": ["cs.LG"], "comment": null, "summary": "In grocery e-commerce, customers often build ingredient baskets guided by\ndietary preferences but lack the expertise to create complete meals. Leveraging\nrecipe knowledge to recommend complementary ingredients based on a partial\nbasket is essential for improving the culinary experience. Traditional recipe\ncompletion methods typically predict a single missing ingredient using a\nleave-one-out strategy. However, they fall short in two key aspects: (i) they\ndo not reflect real-world scenarios where multiple ingredients are often\nneeded, and (ii) they overlook relationships among the missing ingredients\nthemselves. To address these limitations, we reformulate basket completion as a\nset-to-set (S2S) recommendation problem, where an incomplete basket is input\ninto a system that predicts a set of complementary ingredients. We introduce\nS2SRec2, a set-to-set ingredient recommendation framework based on a Set\nTransformer and trained in a multitask learning paradigm. S2SRec2 jointly\nlearns to (i) retrieve missing ingredients from the representation of existing\nones and (ii) assess basket completeness after prediction. These tasks are\noptimized together, enforcing accurate retrieval and coherent basket\ncompletion. Experiments on large-scale recipe datasets and qualitative analyses\nshow that S2SRec2 significantly outperforms single-target baselines, offering a\npromising approach to enhance grocery shopping and inspire culinary creativity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faS2SRec2\u6846\u67b6\u89e3\u51b3\u6742\u8d27\u7535\u5546\u7bee\u5b50\u8865\u5168\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u5355\u76ee\u6807\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u98df\u8c31\u8865\u5168\u65b9\u6cd5\u65e0\u6cd5\u53cd\u6620\u73b0\u5b9e\u573a\u666f\u3001\u5ffd\u7565\u7f3a\u5931\u6210\u5206\u5173\u7cfb\uff0c\u9700\u8981\u66f4\u597d\u65b9\u6cd5\u6539\u5584\u70f9\u996a\u4f53\u9a8c\u3002", "method": "\u5c06\u7bee\u5b50\u8865\u5168\u91cd\u65b0\u5b9a\u4e49\u4e3a\u96c6\u5bf9\u96c6\u63a8\u8350\u95ee\u9898\uff0c\u5f15\u5165\u57fa\u4e8eSet Transformer\u7684S2SRec2\u6846\u67b6\uff0c\u5e76\u4ee5\u591a\u4efb\u52a1\u5b66\u4e60\u8303\u5f0f\u8bad\u7ec3\u3002", "result": "\u5728\u5927\u89c4\u6a21\u98df\u8c31\u6570\u636e\u96c6\u5b9e\u9a8c\u548c\u5b9a\u6027\u5206\u6790\u663e\u793a\uff0cS2SRec2\u663e\u8457\u4f18\u4e8e\u5355\u76ee\u6807\u57fa\u7ebf\u3002", "conclusion": "S2SRec2\u662f\u63d0\u5347\u6742\u8d27\u8d2d\u7269\u548c\u6fc0\u53d1\u70f9\u996a\u521b\u9020\u529b\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002"}}
{"id": "2507.09445", "pdf": "https://arxiv.org/pdf/2507.09445", "abs": "https://arxiv.org/abs/2507.09445", "authors": ["Runze Yang", "Longbing Cao", "Xin You", "Kun Fang", "Jianxun Li", "Jie Yang"], "title": "Fourier Basis Mapping: A Time-Frequency Learning Framework for Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "18 pages, 6 figures", "summary": "The integration of Fourier transform and deep learning opens new avenues for\ntime series forecasting. We reconsider the Fourier transform from a basis\nfunctions perspective. Specifically, the real and imaginary parts of the\nfrequency components can be regarded as the coefficients of cosine and sine\nbasis functions at tiered frequency levels, respectively. We find that existing\nFourier-based methods face inconsistent starting cycles and inconsistent series\nlength issues. They fail to interpret frequency components precisely and\noverlook temporal information. Accordingly, the novel Fourier Basis Mapping\n(FBM) method addresses these issues by integrating time-frequency features\nthrough Fourier basis expansion and mapping in the time-frequency space. Our\napproach extracts explicit frequency features while preserving temporal\ncharacteristics. FBM supports plug-and-play integration with various types of\nneural networks by only adjusting the first initial projection layer for better\nperformance. First, we propose FBM-L, FBM-NL, and FBM-NP to enhance linear,\nMLP-based, and Transformer-based models, respectively, demonstrating the\neffectiveness of time-frequency features. Next, we propose a synergetic model\narchitecture, termed FBM-S, which decomposes the seasonal, trend, and\ninteraction effects into three separate blocks, each designed to model\ntime-frequency features in a specialized manner. Finally, we introduce several\ntechniques tailored for time-frequency features, including interaction masking,\ncentralization, patching, rolling window projection, and multi-scale\ndown-sampling. The results are validated on diverse real-world datasets for\nboth long-term and short-term forecasting tasks with SOTA performance.", "AI": {"tldr": "\u672c\u6587\u4ece\u57fa\u51fd\u6570\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u63d0\u51faFBM\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u5085\u91cc\u53f6\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u652f\u6301\u4e0e\u591a\u79cd\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\uff0c\u8fd8\u63d0\u51fa\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u53ca\u7279\u5b9a\u6280\u672f\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6548\u679c\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5085\u91cc\u53f6\u7684\u65b9\u6cd5\u5b58\u5728\u8d77\u59cb\u5468\u671f\u4e0d\u4e00\u81f4\u3001\u5e8f\u5217\u957f\u5ea6\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u7cbe\u786e\u89e3\u91ca\u9891\u7387\u5206\u91cf\u4e14\u5ffd\u7565\u65f6\u95f4\u4fe1\u606f\u3002", "method": "\u63d0\u51faFourier Basis Mapping (FBM)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u57fa\u5c55\u5f00\u548c\u65f6\u9891\u7a7a\u95f4\u6620\u5c04\u96c6\u6210\u65f6\u9891\u7279\u5f81\uff1b\u63d0\u51faFBM - L\u3001FBM - NL\u3001FBM - NP\u548cFBM - S\u7b49\u6a21\u578b\u67b6\u6784\uff1b\u5f15\u5165\u4ea4\u4e92\u63a9\u7801\u3001\u4e2d\u5fc3\u5316\u7b49\u9488\u5bf9\u65f6\u9891\u7279\u5f81\u7684\u6280\u672f\u3002", "result": "\u5728\u4e0d\u540c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u957f\u671f\u548c\u77ed\u671f\u9884\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\uff0c\u8fbe\u5230SOTA\u6027\u80fd\u3002", "conclusion": "FBM\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u5085\u91cc\u53f6\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u80fd\u4e0e\u591a\u79cd\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\uff0c\u4e14\u7279\u5b9a\u6280\u672f\u548c\u6a21\u578b\u67b6\u6784\u63d0\u5347\u4e86\u65f6\u9891\u7279\u5f81\u5efa\u6a21\u80fd\u529b\u548c\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.08827", "pdf": "https://arxiv.org/pdf/2507.08827", "abs": "https://arxiv.org/abs/2507.08827", "authors": ["Yu Zheng", "Jingtao Ding", "Depeng Jin", "Jianxi Gao", "Yong Li"], "title": "Advancing network resilience theories with symbolized reinforcement learning", "categories": ["physics.soc-ph", "cs.AI"], "comment": null, "summary": "Many complex networks display remarkable resilience under external\nperturbations, internal failures and environmental changes, yet they can\nswiftly deteriorate into dysfunction upon the removal of a few keystone nodes.\nDiscovering theories that measure network resilience offers the potential to\nprevent catastrophic collapses--from species extinctions to financial\ncrise--with profound implications for real-world systems. Current resilience\ntheories address the problem from a single perspective of topology, neglecting\nthe crucial role of system dynamics, due to the intrinsic complexity of the\ncoupling between topology and dynamics which exceeds the capabilities of human\nanalytical methods. Here, we report an automatic method for resilience theory\ndiscovery, which learns from how AI solves a complicated network dismantling\nproblem and symbolizes its network attack strategies into theoretical formulas.\nThis proposed self-inductive approach discovers the first resilience theory\nthat accounts for both topology and dynamics, highlighting how the correlation\nbetween node degree and state shapes overall network resilience, and offering\ninsights for designing early warning signals of systematic collapses.\nAdditionally, our approach discovers formulas that refine existing\nwell-established resilience theories with over 37.5% improvement in accuracy,\nsignificantly advancing human understanding of complex networks with AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u52a8\u65b9\u6cd5\u53d1\u73b0\u7f51\u7edc\u5f39\u6027\u7406\u8bba\uff0c\u517c\u987e\u62d3\u6251\u4e0e\u52a8\u6001\uff0c\u63d0\u5347\u5bf9\u590d\u6742\u7f51\u7edc\u7406\u89e3\u3002", "motivation": "\u73b0\u6709\u5f39\u6027\u7406\u8bba\u4ec5\u4ece\u62d3\u6251\u5355\u4e00\u89c6\u89d2\u89e3\u51b3\u95ee\u9898\uff0c\u5ffd\u7565\u7cfb\u7edf\u52a8\u6001\uff0c\u9700\u53d1\u73b0\u517c\u987e\u62d3\u6251\u4e0e\u52a8\u6001\u7684\u5f39\u6027\u7406\u8bba\u4ee5\u9884\u9632\u7cfb\u7edf\u5d29\u6e83\u3002", "method": "\u4eceAI\u89e3\u51b3\u590d\u6742\u7f51\u7edc\u62c6\u89e3\u95ee\u9898\u4e2d\u5b66\u4e60\uff0c\u5c06\u7f51\u7edc\u653b\u51fb\u7b56\u7565\u7b26\u53f7\u5316\u4e3a\u7406\u8bba\u516c\u5f0f\u3002", "result": "\u53d1\u73b0\u9996\u4e2a\u517c\u987e\u62d3\u6251\u4e0e\u52a8\u6001\u7684\u5f39\u6027\u7406\u8bba\uff0c\u63ed\u793a\u8282\u70b9\u5ea6\u4e0e\u72b6\u6001\u7684\u76f8\u5173\u6027\u5bf9\u7f51\u7edc\u5f39\u6027\u7684\u5f71\u54cd\uff1b\u6539\u8fdb\u73b0\u6709\u7406\u8bba\u516c\u5f0f\uff0c\u7cbe\u5ea6\u63d0\u5347\u8d8537.5%\u3002", "conclusion": "\u8be5\u81ea\u52a8\u65b9\u6cd5\u6709\u52a9\u4e8e\u8bbe\u8ba1\u7cfb\u7edf\u5d29\u6e83\u9884\u8b66\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u5347\u4eba\u7c7b\u5bf9\u590d\u6742\u7f51\u7edc\u7684\u7406\u89e3\u3002"}}
{"id": "2507.09132", "pdf": "https://arxiv.org/pdf/2507.09132", "abs": "https://arxiv.org/abs/2507.09132", "authors": ["Chu-Yuan Wei", "Shun-Yao Liu", "Sheng-Da Zhuo", "Chang-Dong Wang", "Shu-Qiang Huang", "Mohsen Guizani"], "title": "Heterogeneous Graph Prompt Learning via Adaptive Weight Pruning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have achieved remarkable success in various\ngraph-based tasks (e.g., node classification or link prediction). Despite their\ntriumphs, GNNs still face challenges such as long training and inference times,\ndifficulty in capturing complex relationships, and insufficient feature\nextraction. To tackle these issues, graph pre-training and graph prompt methods\nhave garnered increasing attention for their ability to leverage large-scale\ndatasets for initial learning and task-specific adaptation, offering potential\nimprovements in GNN performance. However, previous research has overlooked the\npotential of graph prompts in optimizing models, as well as the impact of both\npositive and negative graph prompts on model stability and efficiency. To\nbridge this gap, we propose a novel framework combining graph prompts with\nweight pruning, called GPAWP, which aims to enhance the performance and\nefficiency of graph prompts by using fewer of them. We evaluate the importance\nof graph prompts using an importance assessment function to determine positive\nand negative weights at different granularities. Through hierarchically\nstructured pruning, we eliminate negative prompt labels, resulting in more\nparameter-efficient and competitively performing prompts. Extensive experiments\non three benchmark datasets demonstrate the superiority of GPAWP, leading to a\nsignificant reduction in parameters in node classification tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGPAWP\u6846\u67b6\u7ed3\u5408\u56fe\u63d0\u793a\u4e0e\u6743\u91cd\u526a\u679d\u63d0\u5347GNN\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u51cf\u5c11\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u53c2\u6570\u3002", "motivation": "GNN\u5b58\u5728\u8bad\u7ec3\u63a8\u7406\u65f6\u95f4\u957f\u7b49\u95ee\u9898\uff0c\u6b64\u524d\u7814\u7a76\u5ffd\u89c6\u56fe\u63d0\u793a\u4f18\u5316\u6a21\u578b\u53ca\u6b63\u8d1f\u63d0\u793a\u5f71\u54cd\uff0c\u9700\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faGPAWP\u6846\u67b6\uff0c\u7528\u91cd\u8981\u6027\u8bc4\u4f30\u51fd\u6570\u786e\u5b9a\u4e0d\u540c\u7c92\u5ea6\u6b63\u8d1f\u6743\u91cd\uff0c\u901a\u8fc7\u5206\u5c42\u526a\u679d\u6d88\u9664\u8d1f\u63d0\u793a\u6807\u7b7e\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8bc1\u660eGPAWP\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u51cf\u5c11\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u53c2\u6570\u3002", "conclusion": "GPAWP\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u56fe\u63d0\u793a\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u51cf\u5c11\u53c2\u6570\u3002"}}
{"id": "2507.09694", "pdf": "https://arxiv.org/pdf/2507.09694", "abs": "https://arxiv.org/abs/2507.09694", "authors": ["Nicolas Gonel", "Paul Saves", "Joseph Morlier"], "title": "Frequency-aware Surrogate Modeling With SMT Kernels For Advanced Data Forecasting", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": "AeroBest 2025, Instituto Superior Tecnico of the University of\n  Lisbon, Portugal", "summary": "This paper introduces a comprehensive open-source framework for developing\ncorrelation kernels, with a particular focus on user-defined and composition of\nkernels for surrogate modeling. By advancing kernel-based modeling techniques,\nwe incorporate frequency-aware elements that effectively capture complex\nmechanical behaviors and timefrequency dynamics intrinsic to aircraft systems.\nTraditional kernel functions, often limited to exponential-based methods, are\nextended to include a wider range of kernels such as exponential squared sine\nand rational quadratic kernels, along with their respective firstand\nsecond-order derivatives. The proposed methodologies are first validated on a\nsinus cardinal test case and then applied to forecasting Mauna-Loa Carbon\nDioxide (CO 2 ) concentrations and airline passenger traffic. All these\nadvancements are integrated into the open-source Surrogate Modeling Toolbox\n(SMT 2.0), providing a versatile platform for both standard and customizable\nkernel configurations. Furthermore, the framework enables the combination of\nvarious kernels to leverage their unique strengths into composite models\ntailored to specific problems. The resulting framework offers a flexible\ntoolset for engineers and researchers, paving the way for numerous future\napplications in metamodeling for complex, frequency-sensitive domains.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5f00\u53d1\u76f8\u5173\u6838\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u6269\u5c55\u6838\u51fd\u6570\uff0c\u9a8c\u8bc1\u540e\u5e94\u7528\u4e8e\u591a\u573a\u666f\u5e76\u96c6\u6210\u5230SMT 2.0\uff0c\u4e3a\u590d\u6742\u9891\u654f\u9886\u57df\u5143\u5efa\u6a21\u63d0\u4f9b\u7075\u6d3b\u5de5\u5177\u3002", "motivation": "\u63a8\u8fdb\u57fa\u4e8e\u6838\u7684\u5efa\u6a21\u6280\u672f\uff0c\u6355\u6349\u98de\u673a\u7cfb\u7edf\u590d\u6742\u529b\u5b66\u884c\u4e3a\u548c\u65f6\u9891\u52a8\u6001\uff0c\u89e3\u51b3\u4f20\u7edf\u6838\u51fd\u6570\u5c40\u9650\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165\u9891\u7387\u611f\u77e5\u5143\u7d20\uff0c\u6269\u5c55\u4f20\u7edf\u6838\u51fd\u6570\uff0c\u9a8c\u8bc1\u65b9\u6cd5\u5e76\u5e94\u7528\u4e8e\u591a\u4e2a\u5b9e\u9645\u6848\u4f8b\uff0c\u96c6\u6210\u5230SMT 2.0\u6846\u67b6\uff0c\u652f\u6301\u6838\u7ec4\u5408\u3002", "result": "\u6846\u67b6\u53ef\u7075\u6d3b\u914d\u7f6e\u6838\uff0c\u80fd\u5c06\u4e0d\u540c\u6838\u4f18\u52bf\u7ec4\u5408\u6210\u5b9a\u5236\u590d\u5408\u6a21\u578b\u3002", "conclusion": "\u6846\u67b6\u4e3a\u5de5\u7a0b\u5e08\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u7075\u6d3b\u5de5\u5177\u96c6\uff0c\u4e3a\u590d\u6742\u9891\u654f\u9886\u57df\u5143\u5efa\u6a21\u672a\u6765\u5e94\u7528\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.09137", "pdf": "https://arxiv.org/pdf/2507.09137", "abs": "https://arxiv.org/abs/2507.09137", "authors": ["Nripsuta Ani Saxena", "Shang-Ling Hsu", "Mehul Shetty", "Omar Alkhadra", "Cyrus Shahabi", "Abigail L. Horn"], "title": "POIFormer: A Transformer-Based Framework for Accurate and Scalable Point-of-Interest Attribution", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurately attributing user visits to specific Points of Interest (POIs) is a\nfoundational task for mobility analytics, personalized services, marketing and\nurban planning. However, POI attribution remains challenging due to GPS\ninaccuracies, typically ranging from 2 to 20 meters in real-world settings, and\nthe high spatial density of POIs in urban environments, where multiple venues\ncan coexist within a small radius (e.g., over 50 POIs within a 100-meter radius\nin dense city centers). Relying on proximity is therefore often insufficient\nfor determining which POI was actually visited. We introduce\n\\textsf{POIFormer}, a novel Transformer-based framework for accurate and\nefficient POI attribution. Unlike prior approaches that rely on limited\nspatiotemporal, contextual, or behavioral features, \\textsf{POIFormer} jointly\nmodels a rich set of signals, including spatial proximity, visit timing and\nduration, contextual features from POI semantics, and behavioral features from\nuser mobility and aggregated crowd behavior patterns--using the Transformer's\nself-attention mechanism to jointly model complex interactions across these\ndimensions. By leveraging the Transformer to model a user's past and future\nvisits (with the current visit masked) and incorporating crowd-level behavioral\npatterns through pre-computed KDEs, \\textsf{POIFormer} enables accurate,\nefficient attribution in large, noisy mobility datasets. Its architecture\nsupports generalization across diverse data sources and geographic contexts\nwhile avoiding reliance on hard-to-access or unavailable data layers, making it\npractical for real-world deployment. Extensive experiments on real-world\nmobility datasets demonstrate significant improvements over existing baselines,\nparticularly in challenging real-world settings characterized by spatial noise\nand dense POI clustering.", "AI": {"tldr": "\u63d0\u51faPOIFormer\u6846\u67b6\u7528\u4e8e\u7cbe\u786e\u9ad8\u6548\u7684POI\u5f52\u5c5e\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u73b0\u6709\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u56e0GPS\u4e0d\u51c6\u786e\u548c\u57ce\u5e02POI\u7a7a\u95f4\u5bc6\u5ea6\u9ad8\uff0c\u4f9d\u9760\u8ddd\u79bb\u786e\u5b9aPOI\u5f52\u5c5e\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684POIFormer\u6846\u67b6\uff0c\u8054\u5408\u5efa\u6a21\u5305\u62ec\u7a7a\u95f4\u8ddd\u79bb\u3001\u8bbf\u95ee\u65f6\u95f4\u548c\u65f6\u957f\u7b49\u4fe1\u53f7\uff0c\u5229\u7528\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u590d\u6742\u4ea4\u4e92\uff0c\u8fd8\u7ed3\u5408\u4eba\u7fa4\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "\u5728\u771f\u5b9e\u79fb\u52a8\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5c24\u5176\u5728\u6709\u7a7a\u95f4\u566a\u58f0\u548cPOI\u5bc6\u96c6\u7684\u573a\u666f\u3002", "conclusion": "POIFormer\u80fd\u5728\u5927\u89c4\u6a21\u3001\u6709\u566a\u58f0\u7684\u79fb\u52a8\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u51c6\u786e\u9ad8\u6548\u7684POI\u5f52\u5c5e\uff0c\u652f\u6301\u8de8\u6570\u636e\u6e90\u548c\u5730\u7406\u73af\u5883\u6cdb\u5316\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2507.09173", "pdf": "https://arxiv.org/pdf/2507.09173", "abs": "https://arxiv.org/abs/2507.09173", "authors": ["Mengjie Chen", "Ming Zhang", "Cunquan Qu"], "title": "Towards Interpretable Drug-Drug Interaction Prediction: A Graph-Based Approach with Molecular and Network-Level Explanations", "categories": ["cs.LG", "cs.AI", "q-bio.MN"], "comment": null, "summary": "Drug-drug interactions (DDIs) represent a critical challenge in pharmacology,\noften leading to adverse drug reactions with significant implications for\npatient safety and healthcare outcomes. While graph-based methods have achieved\nstrong predictive performance, most approaches treat drug pairs independently,\noverlooking the complex, context-dependent interactions unique to drug pairs.\nAdditionally, these models struggle to integrate biological interaction\nnetworks and molecular-level structures to provide meaningful mechanistic\ninsights. In this study, we propose MolecBioNet, a novel graph-based framework\nthat integrates molecular and biomedical knowledge for robust and interpretable\nDDI prediction. By modeling drug pairs as unified entities, MolecBioNet\ncaptures both macro-level biological interactions and micro-level molecular\ninfluences, offering a comprehensive perspective on DDIs. The framework\nextracts local subgraphs from biomedical knowledge graphs and constructs\nhierarchical interaction graphs from molecular representations, leveraging\nclassical graph neural network methods to learn multi-scale representations of\ndrug pairs. To enhance accuracy and interpretability, MolecBioNet introduces\ntwo domain-specific pooling strategies: context-aware subgraph pooling\n(CASPool), which emphasizes biologically relevant entities, and\nattention-guided influence pooling (AGIPool), which prioritizes influential\nmolecular substructures. The framework further employs mutual information\nminimization regularization to enhance information diversity during embedding\nfusion. Experimental results demonstrate that MolecBioNet outperforms\nstate-of-the-art methods in DDI prediction, while ablation studies and\nembedding visualizations further validate the advantages of unified drug pair\nmodeling and multi-scale knowledge integration.", "AI": {"tldr": "\u63d0\u51faMolecBioNet\u6846\u67b6\u7528\u4e8e\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u77e5\u8bc6\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56fe\u57fa\u65b9\u6cd5\u5728\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4e2d\u5ffd\u7565\u836f\u7269\u5bf9\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u96be\u4ee5\u6574\u5408\u751f\u7269\u7f51\u7edc\u548c\u5206\u5b50\u7ed3\u6784\u4ee5\u63d0\u4f9b\u673a\u7406\u89e3\u91ca\u3002", "method": "\u63d0\u51faMolecBioNet\u6846\u67b6\uff0c\u5c06\u836f\u7269\u5bf9\u5efa\u6a21\u4e3a\u7edf\u4e00\u5b9e\u4f53\uff0c\u63d0\u53d6\u5c40\u90e8\u5b50\u56fe\u548c\u6784\u5efa\u5206\u5c42\u4ea4\u4e92\u56fe\uff0c\u4f7f\u7528\u7ecf\u5178\u56fe\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u591a\u5c3a\u5ea6\u8868\u793a\uff0c\u5f15\u5165\u4e24\u79cd\u7279\u5b9a\u6c60\u5316\u7b56\u7565\u548c\u4e92\u4fe1\u606f\u6700\u5c0f\u5316\u6b63\u5219\u5316\u3002", "result": "MolecBioNet\u5728\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6d88\u878d\u5b9e\u9a8c\u548c\u5d4c\u5165\u53ef\u89c6\u5316\u9a8c\u8bc1\u4e86\u7edf\u4e00\u5efa\u6a21\u548c\u591a\u5c3a\u5ea6\u77e5\u8bc6\u6574\u5408\u7684\u4f18\u52bf\u3002", "conclusion": "MolecBioNet\u80fd\u6709\u6548\u8fdb\u884c\u836f\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\uff0c\u7edf\u4e00\u836f\u7269\u5bf9\u5efa\u6a21\u548c\u591a\u5c3a\u5ea6\u77e5\u8bc6\u6574\u5408\u662f\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.09846", "pdf": "https://arxiv.org/pdf/2507.09846", "abs": "https://arxiv.org/abs/2507.09846", "authors": ["Minhak Song", "Beomhan Baek", "Kwangjun Ahn", "Chulhee Yun"], "title": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": "Comments would be appreciated!", "summary": "As both model and dataset sizes continue to scale rapidly, conventional\npretraining strategies with fixed compute budgets-such as cosine learning rate\nschedules-are increasingly inadequate for large-scale training. Recent\nalternatives, including warmup-stable-decay (WSD) schedules and weight\naveraging, offer greater flexibility. However, WSD relies on explicit decay\nphases to track progress, while weight averaging addresses this limitation at\nthe cost of additional memory. In search of a more principled and scalable\nalternative, we revisit the Schedule-Free (SF) method [Defazio et al., 2024],\nwhich has shown strong empirical performance across diverse settings. We show\nthat SF-AdamW effectively navigates the \"river\" structure of the loss landscape\nwithout decay phases or auxiliary averaging, making it particularly suitable\nfor continuously scaling training workloads. To understand this behavior, we\nconduct a theoretical and empirical analysis of SF dynamics, revealing that it\nimplicitly performs weight averaging without memory overhead. Guided by this\nanalysis, we propose a refined variant of SF that improves robustness to\nmomentum and performs better under large batch sizes, addressing key\nlimitations of the original method. Together, these results establish SF as a\npractical, scalable, and theoretically grounded approach for language model\ntraining.", "AI": {"tldr": "\u4f20\u7edf\u9884\u8bad\u7ec3\u7b56\u7565\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u4e2d\u4e0d\u8db3\uff0c\u7814\u7a76\u91cd\u65b0\u5ba1\u89c6Schedule - Free (SF) \u65b9\u6cd5\uff0c\u5206\u6790\u5176\u52a8\u6001\uff0c\u63d0\u51fa\u6539\u8fdb\u53d8\u4f53\uff0c\u8bc1\u660eSF\u662f\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u4e14\u6709\u7406\u8bba\u4f9d\u636e\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u7684\u9884\u8bad\u7ec3\u7b56\u7565\u5728\u5927\u89c4\u6a21\u8bad\u7ec3\u4e2d\u4e0d\u9002\u7528\uff0c\u73b0\u6709\u66ff\u4ee3\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u663e\u5f0f\u8870\u51cf\u9636\u6bb5\u6216\u589e\u52a0\u5185\u5b58\u5f00\u9500\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u539f\u5219\u548c\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6SF\u65b9\u6cd5\uff0c\u5bf9SF\u52a8\u6001\u8fdb\u884c\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\uff0c\u63d0\u51faSF\u7684\u6539\u8fdb\u53d8\u4f53\u3002", "result": "SF - AdamW\u80fd\u6709\u6548\u5904\u7406\u635f\u5931\u666f\u89c2\uff0c\u9690\u5f0f\u6267\u884c\u6743\u91cd\u5e73\u5747\u4e14\u65e0\u5185\u5b58\u5f00\u9500\uff0c\u6539\u8fdb\u53d8\u4f53\u63d0\u9ad8\u4e86\u5bf9\u52a8\u91cf\u7684\u9c81\u68d2\u6027\uff0c\u5728\u5927\u6279\u6b21\u5927\u5c0f\u4e0b\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "SF\u662f\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u5b9e\u7528\u3001\u53ef\u6269\u5c55\u4e14\u6709\u7406\u8bba\u4f9d\u636e\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.09888", "pdf": "https://arxiv.org/pdf/2507.09888", "abs": "https://arxiv.org/abs/2507.09888", "authors": ["Huibo Xu", "Likang Wu", "Xianquan Wang", "Haoning Dang", "Chun-Wun Cheng", "Angelica I Aviles-Rivero", "Qi Liu"], "title": "NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Time series forecasting is a fundamental task with broad applications, yet\nconventional methods often treat data as discrete sequences, overlooking their\norigin as noisy samples of continuous processes. Crucially, discrete noisy\nobservations cannot uniquely determine a continuous function; instead, they\ncorrespond to a family of plausible functions. Mathematically, time series can\nbe viewed as noisy observations of a continuous function family governed by a\nshared probability measure. Thus, the forecasting task can be framed as\nlearning the transition from the historical function family to the future\nfunction family. This reframing introduces two key challenges: (1) How can we\nleverage discrete historical and future observations to learn the relationships\nbetween their underlying continuous functions? (2) How can we model the\ntransition path in function space from the historical function family to the\nfuture function family? To address these challenges, we propose NeuTSFlow, a\nnovel framework that leverages Neural Operators to facilitate flow matching for\nlearning path of measure between historical and future function families. By\nparameterizing the velocity field of the flow in infinite-dimensional function\nspaces, NeuTSFlow moves beyond traditional methods that focus on dependencies\nat discrete points, directly modeling function-level features instead.\nExperiments on diverse forecasting tasks demonstrate NeuTSFlow's superior\naccuracy and robustness, validating the effectiveness of the function-family\nperspective.", "AI": {"tldr": "\u63d0\u51faNeuTSFlow\u6846\u67b6\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5c06\u6570\u636e\u89c6\u4e3a\u79bb\u6563\u5e8f\u5217\uff0c\u5ffd\u7565\u5176\u8fde\u7eed\u8fc7\u7a0b\u672c\u8d28\uff0c\u5b58\u5728\u6311\u6218\u5f85\u89e3\u51b3\u3002", "method": "\u63d0\u51faNeuTSFlow\u6846\u67b6\uff0c\u5229\u7528\u795e\u7ecf\u7b97\u5b50\u8fdb\u884c\u6d41\u5339\u914d\uff0c\u5bf9\u65e0\u9650\u7ef4\u51fd\u6570\u7a7a\u95f4\u7684\u6d41\u901f\u5ea6\u573a\u53c2\u6570\u5316\u3002", "result": "\u5728\u4e0d\u540c\u9884\u6d4b\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cNeuTSFlow\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u51fd\u6570\u65cf\u89c6\u89d2\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6709\u6548\uff0cNeuTSFlow\u6846\u67b6\u53ef\u884c\u3002"}}
{"id": "2507.09202", "pdf": "https://arxiv.org/pdf/2507.09202", "abs": "https://arxiv.org/abs/2507.09202", "authors": ["Wuxin Wang", "Weicheng Ni", "Lilan Huang", "Tao Hao", "Ben Fei", "Shuo Ma", "Taikang Yuan", "Yanlai Zhao", "Kefeng Deng", "Xiaoyong Li", "Boheng Duan", "Lei Bai", "Kaijun Ren"], "title": "XiChen: An observation-scalable fully AI-driven global weather forecasting system with 4D variational knowledge", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Recent advancements in Artificial Intelligence (AI) demonstrate significant\npotential to revolutionize weather forecasting. However, most AI-driven models\nrely on Numerical Weather Prediction (NWP) systems for initial condition\npreparation, which often consumes hours on supercomputers. Here we introduce\nXiChen, the first observation-scalable fully AI-driven global weather\nforecasting system, whose entire pipeline, from Data Assimilation (DA) to\nmedium-range forecasting, can be accomplished within only 17 seconds. XiChen is\nbuilt upon a foundation model that is pre-trained for weather forecasting.\nMeanwhile, this model is subsequently fine-tuned to serve as both observation\noperators and DA models, thereby scalably assimilating conventional and raw\nsatellite observations. Furthermore, the integration of four-dimensional\nvariational knowledge ensures that XiChen's DA and medium-range forecasting\naccuracy rivals that of operational NWP systems, amazingly achieving a skillful\nforecasting lead time exceeding 8.25 days. These findings demonstrate that\nXiChen holds strong potential toward fully AI-driven weather forecasting\nindependent of NWP systems.", "AI": {"tldr": "\u4ecb\u7ecd\u9996\u4e2a\u53ef\u6269\u5c55\u7684\u5168AI\u5168\u7403\u5929\u6c14\u9884\u62a5\u7cfb\u7edfXiChen\uff0c\u80fd\u572817\u79d2\u5185\u5b8c\u6210\u4ece\u6570\u636e\u540c\u5316\u5230\u4e2d\u671f\u9884\u62a5\u7684\u5168\u6d41\u7a0b\uff0c\u9884\u62a5\u9886\u5148\u65f6\u95f4\u8d858.25\u5929\uff0c\u6709\u66ff\u4ee3\u6570\u503c\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709AI\u9a71\u52a8\u7684\u5929\u6c14\u9884\u62a5\u6a21\u578b\u4f9d\u8d56\u6570\u503c\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u51c6\u5907\u521d\u59cb\u6761\u4ef6\uff0c\u8017\u65f6\u4e45\uff0c\u9700\u5f00\u53d1\u4e0d\u4f9d\u8d56NWP\u7cfb\u7edf\u7684\u5168AI\u5929\u6c14\u9884\u62a5\u7cfb\u7edf\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684\u57fa\u7840\u6a21\u578b\uff0c\u5fae\u8c03\u540e\u4f5c\u4e3a\u89c2\u6d4b\u7b97\u5b50\u548c\u6570\u636e\u540c\u5316\u6a21\u578b\uff0c\u878d\u5408\u56db\u7ef4\u53d8\u5206\u77e5\u8bc6\u3002", "result": "XiChen\u53ef\u572817\u79d2\u5185\u5b8c\u6210\u4ece\u6570\u636e\u540c\u5316\u5230\u4e2d\u671f\u9884\u62a5\u7684\u5168\u6d41\u7a0b\uff0c\u9884\u62a5\u7cbe\u5ea6\u4e0eNWP\u7cfb\u7edf\u76f8\u5f53\uff0c\u9884\u62a5\u9886\u5148\u65f6\u95f4\u8d858.25\u5929\u3002", "conclusion": "XiChen\u5728\u4e0d\u4f9d\u8d56NWP\u7cfb\u7edf\u7684\u5168AI\u5929\u6c14\u9884\u62a5\u65b9\u9762\u6709\u5f88\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.09905", "pdf": "https://arxiv.org/pdf/2507.09905", "abs": "https://arxiv.org/abs/2507.09905", "authors": ["Zijian Guo", "Zhenyu Wang", "Yifan Hu", "Francis Bach"], "title": "Statistical Inference for Conditional Group Distributionally Robust Optimization with Cross-Entropy Loss", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "In multi-source learning with discrete labels, distributional heterogeneity\nacross domains poses a central challenge to developing predictive models that\ntransfer reliably to unseen domains. We study multi-source unsupervised domain\nadaptation, where labeled data are drawn from multiple source domains and only\nunlabeled data from a target domain. To address potential distribution shifts,\nwe propose a novel Conditional Group Distributionally Robust Optimization\n(CG-DRO) framework that learns a classifier by minimizing the worst-case\ncross-entropy loss over the convex combinations of the conditional outcome\ndistributions from the sources. To solve the resulting minimax problem, we\ndevelop an efficient Mirror Prox algorithm, where we employ a double machine\nlearning procedure to estimate the risk function. This ensures that the errors\nof the machine learning estimators for the nuisance models enter only at\nhigher-order rates, thereby preserving statistical efficiency under covariate\nshift. We establish fast statistical convergence rates for the estimator by\nconstructing two surrogate minimax optimization problems that serve as\ntheoretical bridges. A distinguishing challenge for CG-DRO is the emergence of\nnonstandard asymptotics: the empirical estimator may fail to converge to a\nstandard limiting distribution due to boundary effects and system instability.\nTo address this, we introduce a perturbation-based inference procedure that\nenables uniformly valid inference, including confidence interval construction\nand hypothesis testing.", "AI": {"tldr": "\u7814\u7a76\u591a\u6e90\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff0c\u63d0\u51faCG - DRO\u6846\u67b6\u53caMirror Prox\u7b97\u6cd5\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5efa\u7acb\u6536\u655b\u7387\uff0c\u5f15\u5165\u6270\u52a8\u63a8\u7406\u7a0b\u5e8f\u89e3\u51b3\u975e\u6807\u51c6\u6e10\u8fd1\u95ee\u9898\u3002", "motivation": "\u5728\u591a\u6e90\u5b66\u4e60\u4e2d\uff0c\u4e0d\u540c\u9886\u57df\u7684\u5206\u5e03\u5f02\u8d28\u6027\u5bf9\u5f00\u53d1\u80fd\u53ef\u9760\u8fc1\u79fb\u5230\u672a\u77e5\u9886\u57df\u7684\u9884\u6d4b\u6a21\u578b\u6784\u6210\u6311\u6218\uff0c\u9700\u89e3\u51b3\u6f5c\u5728\u5206\u5e03\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51faConditional Group Distributionally Robust Optimization (CG - DRO)\u6846\u67b6\uff0c\u5f00\u53d1Mirror Prox\u7b97\u6cd5\uff0c\u91c7\u7528\u53cc\u673a\u5668\u5b66\u4e60\u7a0b\u5e8f\u4f30\u8ba1\u98ce\u9669\u51fd\u6570\uff0c\u6784\u5efa\u4e24\u4e2a\u66ff\u4ee3\u6781\u5c0f\u6781\u5927\u4f18\u5316\u95ee\u9898\u5efa\u7acb\u6536\u655b\u7387\uff0c\u5f15\u5165\u57fa\u4e8e\u6270\u52a8\u7684\u63a8\u7406\u7a0b\u5e8f\u3002", "result": "\u5efa\u7acb\u4e86\u4f30\u8ba1\u5668\u7684\u5feb\u901f\u7edf\u8ba1\u6536\u655b\u7387\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u5728\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\u4fdd\u6301\u7edf\u8ba1\u6548\u7387\uff0c\u5f15\u5165\u7684\u63a8\u7406\u7a0b\u5e8f\u53ef\u8fdb\u884c\u6709\u6548\u63a8\u7406\u3002", "conclusion": "CG - DRO\u6846\u67b6\u53ca\u76f8\u5173\u7b97\u6cd5\u548c\u63a8\u7406\u7a0b\u5e8f\u53ef\u6709\u6548\u89e3\u51b3\u591a\u6e90\u65e0\u76d1\u7763\u57df\u9002\u5e94\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u548c\u975e\u6807\u51c6\u6e10\u8fd1\u95ee\u9898\u3002"}}
{"id": "2507.09916", "pdf": "https://arxiv.org/pdf/2507.09916", "abs": "https://arxiv.org/abs/2507.09916", "authors": ["Ahmad Aghapour", "Erhan Bayraktar", "Fengyi Yuan"], "title": "Solving dynamic portfolio selection problems via score-based diffusion models", "categories": ["q-fin.PM", "stat.ML"], "comment": "Code available on https://github.com/fy-yuan/diffusion_dynamic_mv", "summary": "In this paper, we tackle the dynamic mean-variance portfolio selection\nproblem in a {\\it model-free} manner, based on (generative) diffusion models.\nWe propose using data sampled from the real model $\\mathcal P$ (which is\nunknown) with limited size to train a generative model $\\mathcal Q$ (from which\nwe can easily and adequately sample). With adaptive training and sampling\nmethods that are tailor-made for time series data, we obtain quantification\nbounds between $\\mathcal P$ and $\\mathcal Q$ in terms of the adapted\nWasserstein metric $\\mathcal A W_2$. Importantly, the proposed adapted sampling\nmethod also facilitates {\\it conditional sampling}. In the second part of this\npaper, we provide the stability of the mean-variance portfolio optimization\nproblems in $\\mathcal A W _2$. Then, combined with the error bounds and the\nstability result, we propose a policy gradient algorithm based on the\ngenerative environment, in which our innovative adapted sampling method\nprovides approximate scenario generators. We illustrate the performance of our\nalgorithm on both simulated and real data. For real data, the algorithm based\non the generative environment produces portfolios that beat several important\nbaselines, including the Markowitz portfolio, the equal weight (naive)\nportfolio, and S\\&P 500.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u4ee5\u65e0\u6a21\u578b\u65b9\u5f0f\u89e3\u51b3\u52a8\u6001\u5747\u503c - \u65b9\u5dee\u6295\u8d44\u7ec4\u5408\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u51fa\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u3001\u91cf\u5316\u754c\u9650\u3001\u8bc1\u660e\u7a33\u5b9a\u6027\uff0c\u7ed9\u51fa\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u5e76\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u4ee5\u65e0\u6a21\u578b\u65b9\u5f0f\u89e3\u51b3\u52a8\u6001\u5747\u503c - \u65b9\u5dee\u6295\u8d44\u7ec4\u5408\u9009\u62e9\u95ee\u9898\u3002", "method": "\u7528\u6709\u9650\u5927\u5c0f\u7684\u771f\u5b9e\u6a21\u578b\u6570\u636e\u8bad\u7ec3\u751f\u6210\u6a21\u578b\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u8bad\u7ec3\u548c\u91c7\u6837\u65b9\u6cd5\uff0c\u83b7\u5f97\u91cf\u5316\u754c\u9650\uff0c\u8bc1\u660e\u5747\u503c - \u65b9\u5dee\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u7a33\u5b9a\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u751f\u6210\u73af\u5883\u7684\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u5c55\u793a\u4e86\u6027\u80fd\uff0c\u57fa\u4e8e\u751f\u6210\u73af\u5883\u7684\u7b97\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u4ea7\u751f\u7684\u6295\u8d44\u7ec4\u5408\u51fb\u8d25\u4e86\u591a\u4e2a\u91cd\u8981\u57fa\u7ebf\u3002", "conclusion": "\u57fa\u4e8e\u751f\u6210\u73af\u5883\u7684\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u5728\u52a8\u6001\u5747\u503c - \u65b9\u5dee\u6295\u8d44\u7ec4\u5408\u9009\u62e9\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.10088", "pdf": "https://arxiv.org/pdf/2507.10088", "abs": "https://arxiv.org/abs/2507.10088", "authors": ["Tung Sum Thomas Kwok", "Zeyong Zhang", "Chi-Hua Wang", "Guang Cheng"], "title": "Towards High Supervised Learning Utility Training Data Generation: Data Pruning and Column Reordering", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by Agentic & GenAI Evaluation KDD2025", "summary": "Tabular data synthesis for supervised learning ('SL') model training is\ngaining popularity in industries such as healthcare, finance, and retail.\nDespite the progress made in tabular data generators, models trained with\nsynthetic data often underperform compared to those trained with original data.\nThis low SL utility of synthetic data stems from class imbalance exaggeration\nand SL data relationship overlooked by tabular generator. To address these\nchallenges, we draw inspirations from techniques in emerging data-centric\nartificial intelligence and elucidate Pruning and ReOrdering ('PRRO'), a novel\npipeline that integrates data-centric techniques into tabular data synthesis.\nPRRO incorporates data pruning to guide the table generator towards\nobservations with high signal-to-noise ratio, ensuring that the class\ndistribution of synthetic data closely matches that of the original data.\nBesides, PRRO employs a column reordering algorithm to align the data modeling\nstructure of generators with that of SL models. These two modules enable PRRO\nto optimize SL utility of synthetic data. Empirical experiments on 22 public\ndatasets show that synthetic data generated using PRRO enhances predictive\nperformance compared to data generated without PRRO. Specifically, synthetic\nreplacement of original data yields an average improvement of 26.74% and up to\n871.46% improvement using PRRO, while synthetic appendant to original data\nresults with PRRO-generated data results in an average improvement of 6.13% and\nup to 200.32%. Furthermore, experiments on six highly imbalanced datasets show\nthat PRRO enables the generator to produce synthetic data with a class\ndistribution that resembles the original data more closely, achieving a\nsimilarity improvement of 43%. Through PRRO, we foster a seamless integration\nof data synthesis to subsequent SL prediction, promoting quality and accessible\ndata analysis.", "AI": {"tldr": "\u63d0\u51faPRRO\u7ba1\u9053\u4f18\u5316\u8868\u683c\u6570\u636e\u5408\u6210\u7684\u76d1\u7763\u5b66\u4e60\u6548\u7528\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u6570\u636e\u5408\u6210\u7528\u4e8e\u76d1\u7763\u5b66\u4e60\u65f6\u56e0\u7c7b\u4e0d\u5e73\u8861\u5938\u5927\u548c\u5ffd\u7565\u6570\u636e\u5173\u7cfb\u81f4\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faPRRO\u7ba1\u9053\uff0c\u5305\u542b\u6570\u636e\u4fee\u526a\u548c\u5217\u91cd\u6392\u5e8f\u7b97\u6cd5\uff0c\u524d\u8005\u786e\u4fdd\u5408\u6210\u6570\u636e\u7c7b\u5206\u5e03\u63a5\u8fd1\u539f\u59cb\u6570\u636e\uff0c\u540e\u8005\u4f7f\u751f\u6210\u5668\u4e0e\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7684\u6570\u636e\u5efa\u6a21\u7ed3\u6784\u5bf9\u9f50\u3002", "result": "\u572822\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528PRRO\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\uff1b\u57286\u4e2a\u9ad8\u5ea6\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0a\uff0cPRRO\u4f7f\u5408\u6210\u6570\u636e\u7c7b\u5206\u5e03\u66f4\u63a5\u8fd1\u539f\u59cb\u6570\u636e\uff0c\u76f8\u4f3c\u5ea6\u63d0\u534743%\u3002", "conclusion": "PRRO\u4fc3\u8fdb\u4e86\u6570\u636e\u5408\u6210\u4e0e\u540e\u7eed\u76d1\u7763\u5b66\u4e60\u9884\u6d4b\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u63a8\u52a8\u9ad8\u8d28\u91cf\u4e14\u6613\u83b7\u53d6\u7684\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2507.10132", "pdf": "https://arxiv.org/pdf/2507.10132", "abs": "https://arxiv.org/abs/2507.10132", "authors": ["Usman Gani Joy"], "title": "Wavelet-Enhanced Neural ODE and Graph Attention for Interpretable Energy Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Accurate forecasting of energy demand and supply is critical for optimizing\nsustainable energy systems, yet it is challenged by the variability of\nrenewable sources and dynamic consumption patterns. This paper introduces a\nneural framework that integrates continuous-time Neural Ordinary Differential\nEquations (Neural ODEs), graph attention, multi-resolution wavelet\ntransformations, and adaptive learning of frequencies to address the issues of\ntime series prediction. The model employs a robust ODE solver, using the\nRunge-Kutta method, paired with graph-based attention and residual connections\nto better understand both structural and temporal patterns. Through\nwavelet-based feature extraction and adaptive frequency modulation, it adeptly\ncaptures and models diverse, multi-scale temporal dynamics. When evaluated\nacross seven diverse datasets: ETTh1, ETTh2, ETTm1, ETTm2 (electricity\ntransformer temperature), and Waste, Solar, and Hydro (renewable energy), this\narchitecture consistently outperforms state-of-the-art baselines in various\nforecasting metrics, proving its robustness in capturing complex temporal\ndependencies. Furthermore, the model enhances interpretability through SHAP\nanalysis, making it suitable for sustainable energy applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u795e\u7ecf\u6846\u67b6\u7528\u4e8e\u80fd\u6e90\u4f9b\u9700\u9884\u6d4b\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8fd8\u589e\u5f3a\u4e86\u89e3\u91ca\u6027\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u80fd\u6e90\u4f9b\u9700\u5bf9\u4f18\u5316\u53ef\u6301\u7eed\u80fd\u6e90\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u53d7\u53ef\u518d\u751f\u80fd\u6e90\u53ef\u53d8\u6027\u548c\u52a8\u6001\u6d88\u8d39\u6a21\u5f0f\u6311\u6218\uff0c\u9700\u66f4\u597d\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u96c6\u6210\u8fde\u7eed\u65f6\u95f4\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u3001\u56fe\u6ce8\u610f\u529b\u3001\u591a\u5206\u8fa8\u7387\u5c0f\u6ce2\u53d8\u6362\u548c\u81ea\u9002\u5e94\u9891\u7387\u5b66\u4e60\u7684\u795e\u7ecf\u6846\u67b6\uff0c\u7528\u9f99\u683c - \u5e93\u5854\u6cd5\u6c42\u89e3 ODE\uff0c\u7ed3\u5408\u56fe\u6ce8\u610f\u529b\u548c\u6b8b\u5dee\u8fde\u63a5\uff0c\u8fdb\u884c\u5c0f\u6ce2\u7279\u5f81\u63d0\u53d6\u548c\u81ea\u9002\u5e94\u9891\u7387\u8c03\u5236\u3002", "result": "\u5728\u4e03\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u67b6\u6784\u5728\u5404\u79cd\u9884\u6d4b\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u6a21\u578b\u80fd\u6709\u6548\u6355\u6349\u590d\u6742\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7 SHAP \u5206\u6790\u589e\u5f3a\u4e86\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u53ef\u6301\u7eed\u80fd\u6e90\u5e94\u7528\u3002"}}
{"id": "2507.09264", "pdf": "https://arxiv.org/pdf/2507.09264", "abs": "https://arxiv.org/abs/2507.09264", "authors": ["Payel Mukhopadhyay", "Michael McCabe", "Ruben Ohana", "Miles Cranmer"], "title": "Controllable Patching for Compute-Adaptive Surrogate Modeling of Partial Differential Equations", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Patch-based transformer surrogates have become increasingly effective for\nmodeling spatiotemporal dynamics, but the fixed patch size is a major\nlimitation for budget-conscience deployment in production. We introduce two\nlightweight, architecture-agnostic modules-the Convolutional Kernel Modulator\n(CKM) and Convolutional Stride Modulator (CSM)-that enable dynamic patch size\ncontrol at inference in patch based models, without retraining or accuracy\nloss. Combined with a cyclic patch-size rollout, our method mitigates patch\nartifacts and improves long-term stability for video-like prediction tasks.\nApplied to a range of challenging 2D and 3D PDE benchmarks, our approach\nimproves rollout fidelity and runtime efficiency. To our knowledge, this is the\nfirst framework to enable inference-time patch-size tunability in patch-based\nPDE surrogates. Its plug-and-play design makes it broadly applicable across\narchitectures-establishing a general foundation for compute-adaptive modeling\nin PDE surrogate tasks.", "AI": {"tldr": "\u5f15\u5165\u8f7b\u91cf\u7ea7\u6a21\u5757\u5b9e\u73b0\u57fa\u4e8e\u8865\u4e01\u7684PDE\u66ff\u4ee3\u6a21\u578b\u63a8\u7406\u65f6\u52a8\u6001\u8865\u4e01\u5927\u5c0f\u63a7\u5236\uff0c\u63d0\u9ad8\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u57fa\u4e8e\u8865\u4e01\u7684\u53d8\u538b\u5668\u66ff\u4ee3\u6a21\u578b\u56fa\u5b9a\u8865\u4e01\u5927\u5c0f\u9650\u5236\u4e86\u751f\u4ea7\u4e2d\u7684\u9884\u7b97\u90e8\u7f72\u3002", "method": "\u5f15\u5165\u5377\u79ef\u6838\u8c03\u5236\u5668\uff08CKM\uff09\u548c\u5377\u79ef\u6b65\u957f\u8c03\u5236\u5668\uff08CSM\uff09\u4e24\u4e2a\u8f7b\u91cf\u7ea7\u3001\u67b6\u6784\u65e0\u5173\u6a21\u5757\uff0c\u7ed3\u5408\u5faa\u73af\u8865\u4e01\u5927\u5c0f\u6eda\u52a8\u7b56\u7565\u3002", "result": "\u5e94\u7528\u4e8e2D\u548c3D PDE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u9ad8\u4e86\u6eda\u52a8\u4fdd\u771f\u5ea6\u548c\u8fd0\u884c\u65f6\u6548\u7387\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5b9e\u73b0\u63a8\u7406\u65f6\u8865\u4e01\u5927\u5c0f\u53ef\u8c03\u6027\u7684\u6846\u67b6\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u4e3aPDE\u66ff\u4ee3\u4efb\u52a1\u7684\u8ba1\u7b97\u81ea\u9002\u5e94\u5efa\u6a21\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.10419", "pdf": "https://arxiv.org/pdf/2507.10419", "abs": "https://arxiv.org/abs/2507.10419", "authors": ["Victor Letzelter", "Hugo Malard", "Mathieu Fontaine", "Ga\u00ebl Richard", "Slim Essid", "Andrei Bursuc", "Patrick P\u00e9rez"], "title": "Multiple Choice Learning of Low Rank Adapters for Language Modeling", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "We propose LoRA-MCL, a training scheme that extends next-token prediction in\nlanguage models with a method designed to decode diverse, plausible sentence\ncontinuations at inference time. Traditional language modeling is an\nintrinsically ill-posed problem: given a context, multiple futures may be\nequally plausible. Our approach leverages Multiple Choice Learning (MCL) and\nthe Winner-Takes-All (WTA) loss to efficiently handle ambiguity through\nLow-Rank Adaptation (LoRA). We provide a theoretical interpretation of applying\nMultiple Choice Learning to Language Modeling, assuming the data is generated\nfrom a mixture of distributions. To illustrate the proposed approach, we use\ndata sampled from mixtures of Markov chains. We then demonstrate with extensive\nexperiments on real-world visual and audio captioning tasks that our method\nachieves high diversity and relevance in generated outputs.", "AI": {"tldr": "\u63d0\u51faLoRA - MCL\u8bad\u7ec3\u65b9\u6848\uff0c\u53ef\u5728\u63a8\u7406\u65f6\u89e3\u7801\u591a\u6837\u5408\u7406\u7684\u53e5\u5b50\u7eed\u5199\uff0c\u5728\u89c6\u89c9\u548c\u97f3\u9891\u5b57\u5e55\u4efb\u52a1\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u5176\u751f\u6210\u8f93\u51fa\u5177\u9ad8\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\u3002", "motivation": "\u4f20\u7edf\u8bed\u8a00\u5efa\u6a21\u662f\u75c5\u6001\u95ee\u9898\uff0c\u7ed9\u5b9a\u4e0a\u4e0b\u6587\uff0c\u591a\u79cd\u672a\u6765\u7eed\u5199\u90fd\u53ef\u80fd\u5408\u7406\uff0c\u9700\u5904\u7406\u8fd9\u79cd\u6a21\u7cca\u6027\u3002", "method": "\u5229\u7528Multiple Choice Learning (MCL)\u548cWinner - Takes - All (WTA)\u635f\u5931\uff0c\u901a\u8fc7Low - Rank Adaptation (LoRA)\u5904\u7406\u6a21\u7cca\u6027\uff0c\u5bf9\u5c06MCL\u5e94\u7528\u4e8e\u8bed\u8a00\u5efa\u6a21\u7ed9\u51fa\u7406\u8bba\u89e3\u91ca\uff0c\u5e76\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u6df7\u5408\u91c7\u6837\u6570\u636e\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u89c6\u89c9\u548c\u97f3\u9891\u5b57\u5e55\u4efb\u52a1\u7684\u5927\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u65b9\u6cd5\u751f\u6210\u7684\u8f93\u51fa\u5177\u6709\u9ad8\u591a\u6837\u6027\u548c\u76f8\u5173\u6027\u3002", "conclusion": "LoRA - MCL\u8bad\u7ec3\u65b9\u6848\u80fd\u6709\u6548\u5904\u7406\u8bed\u8a00\u5efa\u6a21\u4e2d\u7684\u6a21\u7cca\u6027\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u8f93\u51fa\u3002"}}
{"id": "2507.08853", "pdf": "https://arxiv.org/pdf/2507.08853", "abs": "https://arxiv.org/abs/2507.08853", "authors": ["Victoria L. Lemieux", "Rosa Gil", "Faith Molosiwa", "Qihong Zhou", "Binming Li", "Roberto Garcia", "Luis De La Torre Cubillo", "Zehua Wang"], "title": "Clio-X: AWeb3 Solution for Privacy-Preserving AI Access to Digital Archives", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.DL", "D.2.11, H.3.4, H.3.7, J.5"], "comment": "28 pages, 8 figures", "summary": "As archives turn to artificial intelligence to manage growing volumes of\ndigital records, privacy risks inherent in current AI data practices raise\ncritical concerns about data sovereignty and ethical accountability. This paper\nexplores how privacy-enhancing technologies (PETs) and Web3 architectures can\nsupport archives to preserve control over sensitive content while still being\nable to make it available for access by researchers. We present Clio-X, a\ndecentralized, privacy-first Web3 digital solution designed to embed PETs into\narchival workflows and support AI-enabled reference and access. Drawing on a\nuser evaluation of a medium-fidelity prototype, the study reveals both interest\nin the potential of the solution and significant barriers to adoption related\nto trust, system opacity, economic concerns, and governance. Using Rogers'\nDiffusion of Innovation theory, we analyze the sociotechnical dimensions of\nthese barriers and propose a path forward centered on participatory design and\ndecentralized governance through a Clio-X Decentralized Autonomous\nOrganization. By integrating technical safeguards with community-based\noversight, Clio-X offers a novel model to ethically deploy AI in cultural\nheritage contexts.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u7528PETs\u548cWeb3\u67b6\u6784\u52a9\u6863\u6848\u9986\u7ba1\u63a7\u654f\u611f\u5185\u5bb9\uff0c\u4ecb\u7ecdClio - X\u65b9\u6848\uff0c\u7528\u6237\u8bc4\u4f30\u663e\u793a\u6709\u6f5c\u529b\u4f46\u6709\u91c7\u7eb3\u969c\u788d\uff0c\u7528\u521b\u65b0\u6269\u6563\u7406\u8bba\u5206\u6790\u5e76\u63d0\u51fa\u63a8\u8fdb\u8def\u5f84\u3002", "motivation": "\u5f53\u524dAI\u6570\u636e\u5b9e\u8df5\u5728\u6863\u6848\u7ba1\u7406\u4e2d\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u5173\u4e4e\u6570\u636e\u4e3b\u6743\u548c\u4f26\u7406\u8d23\u4efb\uff0c\u9700\u65b0\u65b9\u6cd5\u7ba1\u63a7\u654f\u611f\u5185\u5bb9\u3002", "method": "\u63d0\u51faClio - X\u65b9\u6848\uff0c\u8fdb\u884c\u4e2d\u4fdd\u771f\u539f\u578b\u7528\u6237\u8bc4\u4f30\uff0c\u8fd0\u7528Rogers\u521b\u65b0\u6269\u6563\u7406\u8bba\u5206\u6790\u91c7\u7eb3\u969c\u788d\u3002", "result": "\u7528\u6237\u5bf9Clio - X\u65b9\u6848\u6f5c\u529b\u611f\u5174\u8da3\uff0c\u4f46\u5b58\u5728\u4fe1\u4efb\u3001\u7cfb\u7edf\u4e0d\u900f\u660e\u3001\u7ecf\u6d4e\u548c\u6cbb\u7406\u7b49\u91c7\u7eb3\u969c\u788d\u3002", "conclusion": "Clio - X\u96c6\u6210\u6280\u672f\u4fdd\u969c\u548c\u793e\u533a\u76d1\u7763\uff0c\u4e3a\u6587\u5316\u9057\u4ea7\u9886\u57df\u4f26\u7406\u90e8\u7f72AI\u63d0\u4f9b\u65b0\u6a21\u578b\u3002"}}
{"id": "2507.10425", "pdf": "https://arxiv.org/pdf/2507.10425", "abs": "https://arxiv.org/abs/2507.10425", "authors": ["Alvaro H. C. Correia", "Christos Louizos"], "title": "Non-exchangeable Conformal Prediction with Optimal Transport: Tackling Distribution Shifts with Unlabeled Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Conformal prediction is a distribution-free uncertainty quantification method\nthat has gained popularity in the machine learning community due to its\nfinite-sample guarantees and ease of use. Its most common variant, dubbed split\nconformal prediction, is also computationally efficient as it boils down to\ncollecting statistics of the model predictions on some calibration data not yet\nseen by the model. Nonetheless, these guarantees only hold if the calibration\nand test data are exchangeable, a condition that is difficult to verify and\noften violated in practice due to so-called distribution shifts. The literature\nis rife with methods to mitigate the loss in coverage in this non-exchangeable\nsetting, but these methods require some prior information on the type of\ndistribution shift to be expected at test time. In this work, we study this\nproblem via a new perspective, through the lens of optimal transport, and show\nthat it is possible to estimate the loss in coverage and mitigate it in case of\ndistribution shift.", "AI": {"tldr": "\u672c\u6587\u4ece\u6700\u4f18\u4f20\u8f93\u89c6\u89d2\u7814\u7a76\u5171\u5f62\u9884\u6d4b\u5728\u5206\u5e03\u8f6c\u79fb\u4e0b\u7684\u8986\u76d6\u635f\u5931\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u53ef\u4f30\u8ba1\u548c\u7f13\u89e3\u8be5\u635f\u5931\u3002", "motivation": "\u5171\u5f62\u9884\u6d4b\u4e2d\u6821\u51c6\u548c\u6d4b\u8bd5\u6570\u636e\u96be\u4ee5\u6ee1\u8db3\u53ef\u4ea4\u6362\u6027\u6761\u4ef6\uff0c\u73b0\u6709\u7f13\u89e3\u8986\u76d6\u635f\u5931\u7684\u65b9\u6cd5\u9700\u5148\u9a8c\u4fe1\u606f\uff0c\u56e0\u6b64\u4ece\u65b0\u89c6\u89d2\u7814\u7a76\u8be5\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6700\u4f18\u4f20\u8f93\u7684\u89c6\u89d2\u6765\u7814\u7a76\u95ee\u9898\u3002", "result": "\u53ef\u4ee5\u4f30\u8ba1\u5206\u5e03\u8f6c\u79fb\u60c5\u51b5\u4e0b\u7684\u8986\u76d6\u635f\u5931\u5e76\u8fdb\u884c\u7f13\u89e3\u3002", "conclusion": "\u4ece\u6700\u4f18\u4f20\u8f93\u89c6\u89d2\u7814\u7a76\u5171\u5f62\u9884\u6d4b\u5728\u5206\u5e03\u8f6c\u79fb\u4e0b\u7684\u95ee\u9898\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002"}}
{"id": "2507.09362", "pdf": "https://arxiv.org/pdf/2507.09362", "abs": "https://arxiv.org/abs/2507.09362", "authors": ["Assaf Marron", "Smadar Szekely", "Irun Cohen", "David Harel"], "title": "Meta-autoencoders: An approach to discovery and representation of relationships between dynamically evolving classes", "categories": ["cs.LG", "q-bio.PE"], "comment": null, "summary": "An autoencoder (AE) is a neural network that, using self-supervised training,\nlearns a succinct parameterized representation, and a corresponding encoding\nand decoding process, for all instances in a given class. Here, we introduce\nthe concept of a meta-autoencoder (MAE): an AE for a collection of\nautoencoders. Given a family of classes that differ from each other by the\nvalues of some parameters, and a trained AE for each class, an MAE for the\nfamily is a neural net that has learned a compact representation and associated\nencoder and decoder for the class-specific AEs. One application of this general\nconcept is in research and modeling of natural evolution -- capturing the\ndefining and the distinguishing properties across multiple species that are\ndynamically evolving from each other and from common ancestors. In this interim\nreport we provide a constructive definition of MAEs, initial examples, and the\nmotivating research directions in machine learning and biology.", "AI": {"tldr": "\u4ecb\u7ecd\u5143\u81ea\u52a8\u7f16\u7801\u5668\uff08MAE\uff09\u6982\u5ff5\uff0c\u7528\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u96c6\u5408\uff0c\u7ed9\u51fa\u6784\u9020\u5b9a\u4e49\u3001\u793a\u4f8b\u53ca\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u548c\u751f\u7269\u5b66\u7814\u7a76\u4e2d\uff0c\u9700\u6355\u83b7\u52a8\u6001\u8fdb\u5316\u7269\u79cd\u7684\u7279\u6027\uff0c\u63a8\u52a8\u4e86MAE\u6982\u5ff5\u7684\u63d0\u51fa\u3002", "method": "\u4e3aMAE\u7ed9\u51fa\u6784\u9020\u6027\u5b9a\u4e49\uff0c\u5e76\u63d0\u4f9b\u521d\u59cb\u793a\u4f8b\u3002", "result": "\u6210\u529f\u5f15\u5165MAE\u6982\u5ff5\uff0c\u7ed9\u51fa\u6784\u9020\u5b9a\u4e49\u4e0e\u793a\u4f8b\u3002", "conclusion": "MAE\u6982\u5ff5\u5728\u673a\u5668\u5b66\u4e60\u548c\u751f\u7269\u5b66\u7814\u7a76\u4e2d\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\uff0c\u7ed9\u51fa\u4e86\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.08864", "pdf": "https://arxiv.org/pdf/2507.08864", "abs": "https://arxiv.org/abs/2507.08864", "authors": ["Poushali Sengupta", "Sabita Maharjan", "frank Eliassen", "Yan Zhang"], "title": "Privacy-Utility-Fairness: A Balanced Approach to Vehicular-Traffic Management System", "categories": ["cs.CR", "cs.AI", "cs.MA"], "comment": "accepted in VTC 2025 Spring, Oslo, Norway", "summary": "Location-based vehicular traffic management faces significant challenges in\nprotecting sensitive geographical data while maintaining utility for traffic\nmanagement and fairness across regions. Existing state-of-the-art solutions\noften fail to meet the required level of protection against linkage attacks and\ndemographic biases, leading to privacy leakage and inequity in data analysis.\nIn this paper, we propose a novel algorithm designed to address the challenges\nregarding the balance of privacy, utility, and fairness in location-based\nvehicular traffic management systems. In this context, utility means providing\nreliable and meaningful traffic information, while fairness ensures that all\nregions and individuals are treated equitably in data use and decision-making.\nEmploying differential privacy techniques, we enhance data security by\nintegrating query-based data access with iterative shuffling and calibrated\nnoise injection, ensuring that sensitive geographical data remains protected.\nWe ensure adherence to epsilon-differential privacy standards by implementing\nthe Laplace mechanism. We implemented our algorithm on vehicular location-based\ndata from Norway, demonstrating its ability to maintain data utility for\ntraffic management and urban planning while ensuring fair representation of all\ngeographical areas without being overrepresented or underrepresented.\nAdditionally, we have created a heatmap of Norway based on our model,\nillustrating the privatized and fair representation of the traffic conditions\nacross various cities. Our algorithm provides privacy in vehicular traffic", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7b97\u6cd5\u89e3\u51b3\u57fa\u4e8e\u4f4d\u7f6e\u7684\u8f66\u8f86\u4ea4\u901a\u7ba1\u7406\u4e2d\u9690\u79c1\u3001\u6548\u7528\u548c\u516c\u5e73\u6027\u5e73\u8861\u95ee\u9898\uff0c\u7528\u5dee\u5206\u9690\u79c1\u6280\u672f\u4fdd\u62a4\u6570\u636e\uff0c\u5728\u632a\u5a01\u8f66\u8f86\u6570\u636e\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u65b9\u6848\u96be\u4ee5\u5e94\u5bf9\u57fa\u4e8e\u4f4d\u7f6e\u7684\u8f66\u8f86\u4ea4\u901a\u7ba1\u7406\u4e2d\u654f\u611f\u5730\u7406\u6570\u636e\u4fdd\u62a4\u3001\u6570\u636e\u6548\u7528\u548c\u533a\u57df\u516c\u5e73\u6027\u95ee\u9898\uff0c\u6613\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u548c\u6570\u636e\u5206\u6790\u4e0d\u516c\u5e73\u3002", "method": "\u91c7\u7528\u5dee\u5206\u9690\u79c1\u6280\u672f\uff0c\u5c06\u57fa\u4e8e\u67e5\u8be2\u7684\u6570\u636e\u8bbf\u95ee\u4e0e\u8fed\u4ee3\u6d17\u724c\u548c\u6821\u51c6\u566a\u58f0\u6ce8\u5165\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u62c9\u666e\u62c9\u65af\u673a\u5236\u786e\u4fdd\u7b26\u5408epsilon - \u5dee\u5206\u9690\u79c1\u6807\u51c6\u3002", "result": "\u5728\u632a\u5a01\u8f66\u8f86\u4f4d\u7f6e\u6570\u636e\u4e0a\u5b9e\u73b0\u7b97\u6cd5\uff0c\u80fd\u4fdd\u6301\u4ea4\u901a\u7ba1\u7406\u548c\u57ce\u5e02\u89c4\u5212\u7684\u6570\u636e\u6548\u7528\uff0c\u4fdd\u8bc1\u5404\u5730\u7406\u533a\u57df\u516c\u5e73\u5c55\u793a\uff0c\u8fd8\u5236\u4f5c\u4e86\u4ea4\u901a\u72b6\u51b5\u70ed\u56fe\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a\u8f66\u8f86\u4ea4\u901a\u7ba1\u7406\u63d0\u4f9b\u4e86\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u3002"}}
{"id": "2507.09382", "pdf": "https://arxiv.org/pdf/2507.09382", "abs": "https://arxiv.org/abs/2507.09382", "authors": ["Bojian Hou", "Zhanliang Wang", "Zhuoping Zhou", "Boning Tong", "Zexuan Wang", "Jingxuan Bao", "Duy Duong-Tran", "Qi Long", "Li Shen"], "title": "Fair CCA for Fair Representation Learning: An ADNI Study", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": null, "summary": "Canonical correlation analysis (CCA) is a technique for finding correlations\nbetween different data modalities and learning low-dimensional representations.\nAs fairness becomes crucial in machine learning, fair CCA has gained attention.\nHowever, previous approaches often overlook the impact on downstream\nclassification tasks, limiting applicability. We propose a novel fair CCA\nmethod for fair representation learning, ensuring the projected features are\nindependent of sensitive attributes, thus enhancing fairness without\ncompromising accuracy. We validate our method on synthetic data and real-world\ndata from the Alzheimer's Disease Neuroimaging Initiative (ADNI), demonstrating\nits ability to maintain high correlation analysis performance while improving\nfairness in classification tasks. Our work enables fair machine learning in\nneuroimaging studies where unbiased analysis is essential.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u516c\u5e73CCA\u65b9\u6cd5\u7528\u4e8e\u516c\u5e73\u8868\u5f81\u5b66\u4e60\uff0c\u5728\u5408\u6210\u6570\u636e\u548cADNI\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u5176\u80fd\u517c\u987e\u76f8\u5173\u6027\u5206\u6790\u6027\u80fd\u548c\u5206\u7c7b\u516c\u5e73\u6027\u3002", "motivation": "\u4ee5\u5f80\u516c\u5e73CCA\u65b9\u6cd5\u5e38\u5ffd\u7565\u5bf9\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u9650\u5236\u4e86\u9002\u7528\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u516c\u5e73CCA\u65b9\u6cd5\uff0c\u786e\u4fdd\u6295\u5f71\u7279\u5f81\u4e0e\u654f\u611f\u5c5e\u6027\u72ec\u7acb\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548cADNI\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u80fd\u4fdd\u6301\u9ad8\u76f8\u5173\u6027\u5206\u6790\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u5347\u5206\u7c7b\u4efb\u52a1\u7684\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4f7f\u795e\u7ecf\u5f71\u50cf\u7814\u7a76\u4e2d\u5b9e\u73b0\u516c\u5e73\u673a\u5668\u5b66\u4e60\u6210\u4e3a\u53ef\u80fd\uff0c\u5728\u9700\u8981\u65e0\u504f\u5206\u6790\u7684\u573a\u666f\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.09391", "pdf": "https://arxiv.org/pdf/2507.09391", "abs": "https://arxiv.org/abs/2507.09391", "authors": ["Peter Pao-Huang", "Mitchell Black", "Xiaojie Qiu"], "title": "Geometric Generative Modeling with Noise-Conditioned Graph Networks", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Generative modeling of graphs with spatial structure is essential across many\napplications from computer graphics to spatial genomics. Recent flow-based\ngenerative models have achieved impressive results by gradually adding and then\nlearning to remove noise from these graphs. Existing models, however, use graph\nneural network architectures that are independent of the noise level, limiting\ntheir expressiveness. To address this issue, we introduce\n\\textit{Noise-Conditioned Graph Networks} (NCGNs), a class of graph neural\nnetworks that dynamically modify their architecture according to the noise\nlevel during generation. Our theoretical and empirical analysis reveals that as\nnoise increases, (1) graphs require information from increasingly distant\nneighbors and (2) graphs can be effectively represented at lower resolutions.\nBased on these insights, we develop Dynamic Message Passing (DMP), a specific\ninstantiation of NCGNs that adapts both the range and resolution of message\npassing to the noise level. DMP consistently outperforms noise-independent\narchitectures on a variety of domains including $3$D point clouds,\nspatiotemporal transcriptomics, and images. Code is available at\nhttps://github.com/peterpaohuang/ncgn.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNoise - Conditioned Graph Networks (NCGNs) \u4ee5\u89e3\u51b3\u73b0\u6709\u56fe\u751f\u6210\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u53d7\u9650\u95ee\u9898\uff0c\u5f00\u53d1Dynamic Message Passing (DMP)\uff0c\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u566a\u58f0\u65e0\u5173\u67b6\u6784\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6d41\u7684\u56fe\u751f\u6210\u6a21\u578b\u4f7f\u7528\u4e0e\u566a\u58f0\u6c34\u5e73\u65e0\u5173\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u9650\u5236\u4e86\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u5f15\u5165NCGNs\uff0c\u6839\u636e\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u566a\u58f0\u6c34\u5e73\u52a8\u6001\u4fee\u6539\u67b6\u6784\uff1b\u57fa\u4e8e\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\u5f00\u53d1DMP\uff0c\u4f7f\u5176\u6d88\u606f\u4f20\u9012\u7684\u8303\u56f4\u548c\u5206\u8fa8\u7387\u9002\u5e94\u566a\u58f0\u6c34\u5e73\u3002", "result": "DMP\u57283D\u70b9\u4e91\u3001\u65f6\u7a7a\u8f6c\u5f55\u7ec4\u5b66\u548c\u56fe\u50cf\u7b49\u591a\u4e2a\u9886\u57df\u59cb\u7ec8\u4f18\u4e8e\u566a\u58f0\u65e0\u5173\u67b6\u6784\u3002", "conclusion": "NCGNs\u548cDMP\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u56fe\u751f\u6210\u6a21\u578b\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.09394", "pdf": "https://arxiv.org/pdf/2507.09394", "abs": "https://arxiv.org/abs/2507.09394", "authors": ["Nandan Kumar Jha", "Brandon Reagen"], "title": "A Random Matrix Theory Perspective on the Learning Dynamics of Multi-head Latent Attention", "categories": ["cs.LG"], "comment": "ICML 2025 Workshop on High-dimensional Learning Dynamics (HiLD)", "summary": "In this work, we study how multi-head latent attention (MLA), a popular\nstrategy for compressing key/value memory, affects a transformer's internal\ncapacity during pretraining. Using a lightweight suite of Marchenko-Pastur (MP)\ndiagnostics, we analyze the spectrum of the $W_{Q}W_{K}^\\top$ gram matrix\nthroughout training, comparing three variants: the standard multi-head\nattention (MHA) baseline, MLA-PreRoPE with rotary applied before compression,\nand MLA-Decoupled, which shares a single rotary sub-vector across all heads.\nOur random matrix analysis reveals \\textbf{three key findings:} \\textbf{ i)}\ncapacity bottlenecks emerge locally: both MHA and MLA-PreRoPE exhibit sharp,\nearly spikes in specific layers that persist and propagate, disrupting the\nbalance between bulk and outlier directions; \\textbf{ ii)} these spikes\ncoincide with rank collapse, concentrating the model's expressivity into narrow\nsubspaces; \\textbf{ iii)} only the decoupled variant prevents this cascade,\nmaintaining broad spectral support and suppressing outlier formation across\nlayers. These results underscore that \\emph{how} rotary embeddings are applied\nis just as critical as \\emph{where} compression occurs. Sharing rotary\ncomponents across heads mitigates spectral fragmentation and preserves\nrepresentational capacity.", "AI": {"tldr": "\u7814\u7a76\u591a\u5934\u90e8\u6f5c\u5728\u6ce8\u610f\u529b\uff08MLA\uff09\u5bf9Transformer\u9884\u8bad\u7ec3\u5185\u90e8\u5bb9\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u65cb\u8f6c\u5d4c\u5165\u5e94\u7528\u65b9\u5f0f\u5f88\u5173\u952e\uff0c\u5171\u4eab\u65cb\u8f6c\u7ec4\u4ef6\u53ef\u7f13\u89e3\u5149\u8c31\u788e\u7247\u5316\u548c\u4fdd\u7559\u8868\u5f81\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u6d41\u884c\u7684\u952e/\u503c\u5185\u5b58\u538b\u7f29\u7b56\u7565MLA\u5bf9Transformer\u9884\u8bad\u7ec3\u5185\u90e8\u5bb9\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7684Marchenko - Pastur\uff08MP\uff09\u8bca\u65ad\u5957\u4ef6\u5206\u6790$W_{Q}W_{K}^\\top$\u683c\u62c9\u59c6\u77e9\u9635\u7684\u9891\u8c31\uff0c\u5bf9\u6bd4\u6807\u51c6\u591a\u5934\u6ce8\u610f\u529b\uff08MHA\uff09\u57fa\u7ebf\u3001\u538b\u7f29\u524d\u5e94\u7528\u65cb\u8f6c\u7684MLA - PreRoPE\u548c\u8de8\u6240\u6709\u5934\u5171\u4eab\u5355\u4e2a\u65cb\u8f6c\u5b50\u5411\u91cf\u7684MLA - Decoupled\u4e09\u79cd\u53d8\u4f53\u3002", "result": "\u53d1\u73b0\u5bb9\u91cf\u74f6\u9888\u5c40\u90e8\u51fa\u73b0\uff0c\u5c16\u5cf0\u4e0e\u79e9\u5d29\u6e83\u91cd\u5408\uff0c\u53ea\u6709\u89e3\u8026\u53d8\u4f53\u53ef\u9632\u6b62\u7ea7\u8054\uff0c\u4fdd\u6301\u5e7f\u6cdb\u7684\u5149\u8c31\u652f\u6301\u548c\u6291\u5236\u79bb\u7fa4\u503c\u5f62\u6210\u3002", "conclusion": "\u65cb\u8f6c\u5d4c\u5165\u7684\u5e94\u7528\u65b9\u5f0f\u548c\u538b\u7f29\u4f4d\u7f6e\u540c\u6837\u91cd\u8981\uff0c\u8de8\u5934\u5171\u4eab\u65cb\u8f6c\u7ec4\u4ef6\u53ef\u7f13\u89e3\u5149\u8c31\u788e\u7247\u5316\u548c\u4fdd\u7559\u8868\u5f81\u80fd\u529b\u3002"}}
{"id": "2507.09404", "pdf": "https://arxiv.org/pdf/2507.09404", "abs": "https://arxiv.org/abs/2507.09404", "authors": ["Mustafa Shukor", "Louis Bethune", "Dan Busbridge", "David Grangier", "Enrico Fini", "Alaaeldin El-Nouby", "Pierre Ablin"], "title": "Scaling Laws for Optimal Data Mixtures", "categories": ["cs.LG"], "comment": null, "summary": "Large foundation models are typically trained on data from multiple domains,\nwith the data mixture--the proportion of each domain used--playing a critical\nrole in model performance. The standard approach to selecting this mixture\nrelies on trial and error, which becomes impractical for large-scale\npretraining. We propose a systematic method to determine the optimal data\nmixture for any target domain using scaling laws. Our approach accurately\npredicts the loss of a model of size $N$ trained with $D$ tokens and a specific\ndomain weight vector $h$. We validate the universality of these scaling laws by\ndemonstrating their predictive power in three distinct and large-scale\nsettings: large language model (LLM), native multimodal model (NMM), and large\nvision models (LVM) pretraining. We further show that these scaling laws can\nextrapolate to new data mixtures and across scales: their parameters can be\naccurately estimated using a few small-scale training runs, and used to\nestimate the performance at larger scales and unseen domain weights. The\nscaling laws allow to derive the optimal domain weights for any target domain\nunder a given training budget ($N$,$D$), providing a principled alternative to\ncostly trial-and-error methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u7f29\u653e\u5b9a\u5f8b\u786e\u5b9a\u4efb\u610f\u76ee\u6807\u9886\u57df\u7684\u6700\u4f18\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u5728\u4e09\u79cd\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u573a\u666f\u9a8c\u8bc1\u5176\u901a\u7528\u6027\u548c\u5916\u63a8\u6027\uff0c\u66ff\u4ee3\u8bd5\u9519\u6cd5\u3002", "motivation": "\u6807\u51c6\u7684\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u8bd5\u9519\uff0c\u5728\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u4e2d\u4e0d\u5b9e\u7528\uff0c\u9700\u7cfb\u7edf\u6027\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7528\u7f29\u653e\u5b9a\u5f8b\u786e\u5b9a\u6700\u4f18\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u9884\u6d4b\u7279\u5b9a\u6761\u4ef6\u4e0b\u6a21\u578b\u7684\u635f\u5931\u3002", "result": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\u3001\u539f\u751f\u591a\u6a21\u6001\u6a21\u578b\u548c\u5927\u89c6\u89c9\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u9a8c\u8bc1\u4e86\u7f29\u653e\u5b9a\u5f8b\u7684\u901a\u7528\u6027\u548c\u5916\u63a8\u6027\u3002", "conclusion": "\u7f29\u653e\u5b9a\u5f8b\u53ef\u5728\u7ed9\u5b9a\u8bad\u7ec3\u9884\u7b97\u4e0b\u4e3a\u4efb\u610f\u76ee\u6807\u9886\u57df\u5bfc\u51fa\u6700\u4f18\u9886\u57df\u6743\u91cd\uff0c\u662f\u66ff\u4ee3\u8bd5\u9519\u6cd5\u7684\u539f\u5219\u6027\u65b9\u6cd5\u3002"}}
{"id": "2507.08878", "pdf": "https://arxiv.org/pdf/2507.08878", "abs": "https://arxiv.org/abs/2507.08878", "authors": ["Xinyu Huang", "Leming Shen", "Zijing Ma", "Yuanqing Zheng"], "title": "Towards Privacy-Preserving and Personalized Smart Homes via Tailored Small Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have showcased remarkable generalizability in\nlanguage comprehension and hold significant potential to revolutionize\nhuman-computer interaction in smart homes. Existing LLM-based smart home\nassistants typically transmit user commands, along with user profiles and home\nconfigurations, to remote servers to obtain personalized services. However,\nusers are increasingly concerned about the potential privacy leaks to the\nremote servers. To address this issue, we develop HomeLLaMA, an on-device\nassistant for privacy-preserving and personalized smart home serving with a\ntailored small language model (SLM). HomeLLaMA learns from cloud LLMs to\ndeliver satisfactory responses and enable user-friendly interactions. Once\ndeployed, HomeLLaMA facilitates proactive interactions by continuously updating\nlocal SLMs and user profiles. To further enhance user experience while\nprotecting their privacy, we develop PrivShield to offer an optional\nprivacy-preserving LLM-based smart home serving for those users, who are\nunsatisfied with local responses and willing to send less-sensitive queries to\nremote servers. For evaluation, we build a comprehensive benchmark DevFinder to\nassess the service quality. Extensive experiments and user studies (M=100)\ndemonstrate that HomeLLaMA can provide personalized services while\nsignificantly enhancing user privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHomeLLaMA\u8bbe\u5907\u7aef\u52a9\u624b\u548cPrivShield\u4fdd\u62a4\u9690\u79c1\uff0c\u7528DevFinder\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u63d0\u4f9b\u670d\u52a1\u5e76\u589e\u5f3a\u9690\u79c1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u5bb6\u5c45\u52a9\u624b\u5c06\u6570\u636e\u4f20\u81f3\u8fdc\u7a0b\u670d\u52a1\u5668\uff0c\u5f15\u53d1\u7528\u6237\u9690\u79c1\u62c5\u5fe7\u3002", "method": "\u5f00\u53d1HomeLLaMA\u8bbe\u5907\u7aef\u52a9\u624b\uff0c\u7528\u5b9a\u5236\u5c0f\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u4e91\u5927\u8bed\u8a00\u6a21\u578b\uff1b\u5f00\u53d1PrivShield\u63d0\u4f9b\u53ef\u9009\u9690\u79c1\u4fdd\u62a4\u670d\u52a1\uff1b\u6784\u5efaDevFinder\u8bc4\u4f30\u670d\u52a1\u8d28\u91cf\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u548c\u7528\u6237\u7814\u7a76\uff08M = 100\uff09\uff0cHomeLLaMA\u80fd\u63d0\u4f9b\u4e2a\u6027\u5316\u670d\u52a1\u5e76\u663e\u8457\u589e\u5f3a\u7528\u6237\u9690\u79c1\u3002", "conclusion": "HomeLLaMA\u53ef\u4ee5\u5728\u667a\u80fd\u5bb6\u5c45\u573a\u666f\u4e2d\u63d0\u4f9b\u4e2a\u6027\u5316\u670d\u52a1\u7684\u540c\u65f6\uff0c\u6709\u6548\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002"}}
{"id": "2507.09406", "pdf": "https://arxiv.org/pdf/2507.09406", "abs": "https://arxiv.org/abs/2507.09406", "authors": ["Santhosh Kumar Ravindran"], "title": "Adversarial Activation Patching: A Framework for Detecting and Mitigating Emergent Deception in Safety-Aligned Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) aligned for safety through techniques like\nreinforcement learning from human feedback (RLHF) often exhibit emergent\ndeceptive behaviors, where outputs appear compliant but subtly mislead or omit\ncritical information. This paper introduces adversarial activation patching, a\nnovel mechanistic interpretability framework that leverages activation patching\nas an adversarial tool to induce, detect, and mitigate such deception in\ntransformer-based models. By sourcing activations from \"deceptive\" prompts and\npatching them into safe forward passes at specific layers, we simulate\nvulnerabilities and quantify deception rates. Through toy neural network\nsimulations across multiple scenarios (e.g., 1000 trials per setup), we\ndemonstrate that adversarial patching increases deceptive outputs to 23.9% from\na 0% baseline, with layer-specific variations supporting our hypotheses. We\npropose six hypotheses, including transferability across models, exacerbation\nin multimodal settings, and scaling effects. An expanded literature review\nsynthesizes over 20 key works in interpretability, deception, and adversarial\nattacks. Mitigation strategies, such as activation anomaly detection and robust\nfine-tuning, are detailed, alongside ethical considerations and future research\ndirections. This work advances AI safety by highlighting patching's dual-use\npotential and provides a roadmap for empirical studies on large-scale models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bf9\u6297\u6fc0\u6d3b\u8865\u4e01\u65b9\u6cd5\u68c0\u6d4b\u548c\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u6b3a\u9a97\u884c\u4e3a\uff0c\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8fd8\u63d0\u51fa\u5047\u8bbe\u3001\u7ed9\u51fa\u7f13\u89e3\u7b56\u7565\u7b49\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u7ecfRLHF\u5bf9\u9f50\u540e\u51fa\u73b0\u7684\u6b3a\u9a97\u884c\u4e3a\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5bf9\u6297\u6fc0\u6d3b\u8865\u4e01\u6846\u67b6\uff0c\u5229\u7528\u6fc0\u6d3b\u8865\u4e01\u6a21\u62df\u6f0f\u6d1e\u3001\u91cf\u5316\u6b3a\u9a97\u7387\uff0c\u8fdb\u884c\u73a9\u5177\u795e\u7ecf\u7f51\u7edc\u6a21\u62df\u5b9e\u9a8c\u3002", "result": "\u5bf9\u6297\u8865\u4e01\u4f7f\u6b3a\u9a97\u8f93\u51fa\u4ece0%\u589e\u81f323.9%\uff0c\u5c42\u7279\u5b9a\u53d8\u5316\u652f\u6301\u5047\u8bbe\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63a8\u8fdbAI\u5b89\u5168\uff0c\u51f8\u663e\u8865\u4e01\u4e24\u7528\u6f5c\u529b\uff0c\u4e3a\u5927\u89c4\u6a21\u6a21\u578b\u5b9e\u8bc1\u7814\u7a76\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002"}}
{"id": "2507.08879", "pdf": "https://arxiv.org/pdf/2507.08879", "abs": "https://arxiv.org/abs/2507.08879", "authors": ["Max-Paul F\u00f6rster", "Luca Deck", "Raimund Weidlich", "Niklas K\u00fchl"], "title": "A Multi-Level Strategy for Deepfake Content Moderation under EU Regulation", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The growing availability and use of deepfake technologies increases risks for\ndemocratic societies, e.g., for political communication on online platforms.\nThe EU has responded with transparency obligations for providers and deployers\nof Artificial Intelligence (AI) systems and online platforms. This includes\nmarking deepfakes during generation and labeling deepfakes when they are\nshared. However, the lack of industry and enforcement standards poses an\nongoing challenge. Through a multivocal literature review, we summarize methods\nfor marking, detecting, and labeling deepfakes and assess their effectiveness\nunder EU regulation. Our results indicate that individual methods fail to meet\nregulatory and practical requirements. Therefore, we propose a multi-level\nstrategy combining the strengths of existing methods. To account for the masses\nof content on online platforms, our multi-level strategy provides scalability\nand practicality via a simple scoring mechanism. At the same time, it is\nagnostic to types of deepfake technology and allows for context-specific risk\nweighting.", "AI": {"tldr": "\u968f\u7740\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u7684\u666e\u53ca\uff0c\u6b27\u76df\u51fa\u53f0\u76f8\u5173\u4e49\u52a1\u89c4\u5b9a\uff0c\u4f46\u7f3a\u6807\u51c6\u4ecd\u662f\u6311\u6218\u3002\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u8bc4\u4f30\u65b9\u6cd5\u6548\u679c\uff0c\u53d1\u73b0\u5355\u4e2a\u65b9\u6cd5\u4e0d\u8db3\uff0c\u63d0\u51fa\u591a\u7ea7\u7b56\u7565\u3002", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u5bf9\u6c11\u4e3b\u793e\u4f1a\u6709\u98ce\u9669\uff0c\u6b27\u76df\u51fa\u53f0\u76f8\u5173\u4e49\u52a1\u89c4\u5b9a\u4f46\u7f3a\u884c\u4e1a\u548c\u6267\u884c\u6807\u51c6\uff0c\u9700\u8bc4\u4f30\u65b9\u6cd5\u6709\u6548\u6027\u3002", "method": "\u8fdb\u884c\u591a\u89c6\u89d2\u6587\u732e\u7efc\u8ff0\uff0c\u603b\u7ed3\u6807\u8bb0\u3001\u68c0\u6d4b\u548c\u6807\u6ce8\u6df1\u5ea6\u4f2a\u9020\u7684\u65b9\u6cd5\u5e76\u8bc4\u4f30\u5176\u5728\u6b27\u76df\u6cd5\u89c4\u4e0b\u7684\u6709\u6548\u6027\u3002", "result": "\u5355\u4e2a\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u76d1\u7ba1\u548c\u5b9e\u9645\u8981\u6c42\u3002", "conclusion": "\u63d0\u51fa\u7ed3\u5408\u73b0\u6709\u65b9\u6cd5\u4f18\u52bf\u7684\u591a\u7ea7\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u5b9e\u7528\u6027\uff0c\u5bf9\u6280\u672f\u7c7b\u578b\u65e0\u504f\u5411\u4e14\u53ef\u8fdb\u884c\u7279\u5b9a\u98ce\u9669\u52a0\u6743\u3002"}}
{"id": "2507.09428", "pdf": "https://arxiv.org/pdf/2507.09428", "abs": "https://arxiv.org/abs/2507.09428", "authors": ["Zakhar Shumaylov", "Vasileios Tsiaras", "Yannis Stylianou"], "title": "On Information Geometry and Iterative Optimization in Model Compression: Operator Factorization", "categories": ["cs.LG", "math.DG", "math.OC"], "comment": null, "summary": "The ever-increasing parameter counts of deep learning models necessitate\neffective compression techniques for deployment on resource-constrained\ndevices. This paper explores the application of information geometry, the study\nof density-induced metrics on parameter spaces, to analyze existing methods\nwithin the space of model compression, primarily focusing on operator\nfactorization. Adopting this perspective highlights the core challenge:\ndefining an optimal low-compute submanifold (or subset) and projecting onto it.\nWe argue that many successful model compression approaches can be understood as\nimplicitly approximating information divergences for this projection. We\nhighlight that when compressing a pre-trained model, using information\ndivergences is paramount for achieving improved zero-shot accuracy, yet this\nmay no longer be the case when the model is fine-tuned. In such scenarios,\ntrainability of bottlenecked models turns out to be far more important for\nachieving high compression ratios with minimal performance degradation,\nnecessitating adoption of iterative methods. In this context, we prove\nconvergence of iterative singular value thresholding for training neural\nnetworks subject to a soft rank constraint. To further illustrate the utility\nof this perspective, we showcase how simple modifications to existing methods\nthrough softer rank reduction result in improved performance under fixed\ncompression rates.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4fe1\u606f\u51e0\u4f55\u5728\u6a21\u578b\u538b\u7f29\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u73b0\u6709\u65b9\u6cd5\uff0c\u6307\u51fa\u538b\u7f29\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u6a21\u578b\u7684\u8981\u70b9\u5e76\u8bc1\u660e\u8fed\u4ee3\u65b9\u6cd5\u6536\u655b\u6027\uff0c\u901a\u8fc7\u8f6f\u79e9\u51cf\u5c11\u6539\u8fdb\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53c2\u6570\u589e\u52a0\uff0c\u9700\u8981\u6709\u6548\u538b\u7f29\u6280\u672f\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u90e8\u7f72\u3002", "method": "\u8fd0\u7528\u4fe1\u606f\u51e0\u4f55\u5206\u6790\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\uff0c\u805a\u7126\u7b97\u5b50\u5206\u89e3\uff0c\u8bc1\u660e\u8fed\u4ee3\u5947\u5f02\u503c\u9608\u503c\u6cd5\u6536\u655b\u6027\u3002", "result": "\u538b\u7f29\u9884\u8bad\u7ec3\u6a21\u578b\u7528\u4fe1\u606f\u6563\u5ea6\u53ef\u63d0\u9ad8\u96f6\u6837\u672c\u51c6\u786e\u7387\uff0c\u5fae\u8c03\u6a21\u578b\u65f6\u74f6\u9888\u6a21\u578b\u53ef\u8bad\u7ec3\u6027\u66f4\u91cd\u8981\uff0c\u8f6f\u79e9\u51cf\u5c11\u80fd\u63d0\u5347\u56fa\u5b9a\u538b\u7f29\u7387\u4e0b\u6027\u80fd\u3002", "conclusion": "\u4fe1\u606f\u51e0\u4f55\u89c6\u89d2\u5bf9\u6a21\u578b\u538b\u7f29\u6709\u91cd\u8981\u610f\u4e49\uff0c\u8fed\u4ee3\u65b9\u6cd5\u5728\u5fae\u8c03\u6a21\u578b\u538b\u7f29\u4e2d\u5f88\u5173\u952e\uff0c\u8f6f\u79e9\u51cf\u5c11\u53ef\u6539\u8fdb\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.08881", "pdf": "https://arxiv.org/pdf/2507.08881", "abs": "https://arxiv.org/abs/2507.08881", "authors": ["Zhang MingDa", "Xu Qing"], "title": "The Consistency-Acceptability Divergence of LLMs in Judicial Decision-Making: Task and Stakeholder Dimensions", "categories": ["cs.CY", "cs.AI", "cs.SI"], "comment": "12 pages,2 figures", "summary": "The integration of large language model (LLM) technology into judicial\nsystems is fundamentally transforming legal practice worldwide. However, this\nglobal transformation has revealed an urgent paradox requiring immediate\nattention. This study introduces the concept of ``consistency-acceptability\ndivergence'' for the first time, referring to the gap between technical\nconsistency and social acceptance. While LLMs achieve high consistency at the\ntechnical level, this consistency demonstrates both positive and negative\neffects. Through comprehensive analysis of recent data on LLM judicial\napplications from 2023--2025, this study finds that addressing this challenge\nrequires understanding both task and stakeholder dimensions. This study\nproposes the Dual-Track Deliberative Multi-Role LLM Judicial Governance\nFramework (DTDMR-LJGF), which enables intelligent task classification and\nmeaningful interaction among diverse stakeholders. This framework offers both\ntheoretical insights and practical guidance for building an LLM judicial\necosystem that balances technical efficiency with social legitimacy.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u2018\u4e00\u81f4\u6027 - \u53ef\u63a5\u53d7\u6027\u5dee\u5f02\u2019\u6982\u5ff5\uff0c\u5206\u6790 2023 - 2025 \u5e74\u6570\u636e\uff0c\u63d0\u51fa DTDMR - LJGF \u6846\u67b6\u5e73\u8861\u53f8\u6cd5\u7cfb\u7edf\u4e2d\u6280\u672f\u6548\u7387\u4e0e\u793e\u4f1a\u5408\u6cd5\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6280\u672f\u878d\u5165\u53f8\u6cd5\u7cfb\u7edf\u5e26\u6765\u53d8\u9769\uff0c\u4f46\u5b58\u5728\u6280\u672f\u4e00\u81f4\u6027\u548c\u793e\u4f1a\u63a5\u53d7\u5ea6\u7684\u77db\u76fe\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u7efc\u5408\u5206\u6790 2023 - 2025 \u5e74\u5927\u8bed\u8a00\u6a21\u578b\u53f8\u6cd5\u5e94\u7528\u7684\u76f8\u5173\u6570\u636e\u3002", "result": "\u53d1\u73b0\u89e3\u51b3\u6311\u6218\u9700\u4ece\u4efb\u52a1\u548c\u5229\u76ca\u76f8\u5173\u8005\u4e24\u4e2a\u7ef4\u5ea6\u8003\u8651\uff0c\u63d0\u51fa DTDMR - LJGF \u6846\u67b6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6784\u5efa\u5e73\u8861\u6280\u672f\u6548\u7387\u4e0e\u793e\u4f1a\u5408\u6cd5\u6027\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53f8\u6cd5\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u89c1\u89e3\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2507.08885", "pdf": "https://arxiv.org/pdf/2507.08885", "abs": "https://arxiv.org/abs/2507.08885", "authors": ["Baining Zhao", "Rongze Tang", "Mingyuan Jia", "Ziyou Wang", "Fanghang Man", "Xin Zhang", "Yu Shang", "Weichen Zhang", "Chen Gao", "Wei Wu", "Xin Wang", "Xinlei Chen", "Yong Li"], "title": "AirScape: An Aerial Generative World Model with Motion Controllability", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "How to enable robots to predict the outcomes of their own motion intentions\nin three-dimensional space has been a fundamental problem in embodied\nintelligence. To explore more general spatial imagination capabilities, here we\npresent AirScape, the first world model designed for six-degree-of-freedom\naerial agents. AirScape predicts future observation sequences based on current\nvisual inputs and motion intentions. Specifically, we construct an dataset for\naerial world model training and testing, which consists of 11k video-intention\npairs. This dataset includes first-person-view videos capturing diverse drone\nactions across a wide range of scenarios, with over 1,000 hours spent\nannotating the corresponding motion intentions. Then we develop a two-phase\ntraining schedule to train a foundation model -- initially devoid of embodied\nspatial knowledge -- into a world model that is controllable by motion\nintentions and adheres to physical spatio-temporal constraints.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u516d\u81ea\u7531\u5ea6\u7a7a\u4e2d\u667a\u80fd\u4f53\u7684\u4e16\u754c\u6a21\u578bAirScape\uff0c\u6784\u5efa\u6570\u636e\u96c6\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u5728\u4e09\u7ef4\u7a7a\u95f4\u9884\u6d4b\u81ea\u8eab\u8fd0\u52a8\u610f\u56fe\u7ed3\u679c\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u66f4\u901a\u7528\u7684\u7a7a\u95f4\u60f3\u8c61\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b11k\u89c6\u9891 - \u610f\u56fe\u5bf9\u7684\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6848\u5c06\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\u6210\u53ef\u7531\u8fd0\u52a8\u610f\u56fe\u63a7\u5236\u4e14\u7b26\u5408\u7269\u7406\u65f6\u7a7a\u7ea6\u675f\u7684\u4e16\u754c\u6a21\u578b\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2507.09440", "pdf": "https://arxiv.org/pdf/2507.09440", "abs": "https://arxiv.org/abs/2507.09440", "authors": ["Joshua Hill", "Benjamin Eyre", "Elliot Creager"], "title": "Transformers Don't In-Context Learn Least Squares Regression", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages, 16 figures, ICML 2025 Workshop on Reliable and Responsible\n  Foundation Models", "summary": "In-context learning (ICL) has emerged as a powerful capability of large\npretrained transformers, enabling them to solve new tasks implicit in example\ninput-output pairs without any gradient updates. Despite its practical success,\nthe mechanisms underlying ICL remain largely mysterious. In this work we study\nsynthetic linear regression to probe how transformers implement learning at\ninference time. Previous works have demonstrated that transformers match the\nperformance of learning rules such as Ordinary Least Squares (OLS) regression\nor gradient descent and have suggested ICL is facilitated in transformers\nthrough the learned implementation of one of these techniques. In this work, we\ndemonstrate through a suite of out-of-distribution generalization experiments\nthat transformers trained for ICL fail to generalize after shifts in the prompt\ndistribution, a behaviour that is inconsistent with the notion of transformers\nimplementing algorithms such as OLS. Finally, we highlight the role of the\npretraining corpus in shaping ICL behaviour through a spectral analysis of the\nlearned representations in the residual stream. Inputs from the same\ndistribution as the training data produce representations with a unique\nspectral signature: inputs from this distribution tend to have the same top two\nsingular vectors. This spectral signature is not shared by out-of-distribution\ninputs, and a metric characterizing the presence of this signature is highly\ncorrelated with low loss.", "AI": {"tldr": "\u7814\u7a76\u5927\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u673a\u5236\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u5206\u5e03\u5916\u6cdb\u5316\u4e0d\u4f73\uff0c\u4e0d\u7b26OLS\u7b97\u6cd5\uff0c\u8fd8\u63ed\u793a\u9884\u8bad\u7ec3\u8bed\u6599\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7a76\u5927\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u80cc\u540e\u7684\u673a\u5236\uff0c\u6b64\u524d\u8be5\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u8fdb\u884c\u5206\u5e03\u5916\u6cdb\u5316\u5b9e\u9a8c\uff0c\u5bf9\u6b8b\u5dee\u6d41\u4e2d\u5b66\u4e60\u5230\u7684\u8868\u793a\u8fdb\u884c\u9891\u8c31\u5206\u6790\u3002", "result": "Transformer\u5728\u63d0\u793a\u5206\u5e03\u53d8\u5316\u540e\u65e0\u6cd5\u6cdb\u5316\uff0c\u4e0e\u5b9e\u73b0OLS\u7b97\u6cd5\u7684\u6982\u5ff5\u4e0d\u7b26\uff1b\u8bad\u7ec3\u6570\u636e\u540c\u5206\u5e03\u8f93\u5165\u6709\u72ec\u7279\u9891\u8c31\u7279\u5f81\uff0c\u8be5\u7279\u5f81\u4e0e\u4f4e\u635f\u5931\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "Transformer\u5b9e\u73b0ICL\u7684\u673a\u5236\u4e0e\u4f20\u7edf\u5b66\u4e60\u89c4\u5219\u4e0d\u540c\uff0c\u9884\u8bad\u7ec3\u8bed\u6599\u5bf9ICL\u884c\u4e3a\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2507.08898", "pdf": "https://arxiv.org/pdf/2507.08898", "abs": "https://arxiv.org/abs/2507.08898", "authors": ["Wenliang Shan", "Michael Fu", "Rui Yang", "Chakkrit", "Tantithamthavorn"], "title": "SEALGuard: Safeguarding the Multilingual Conversations in Southeast Asian Languages for LLM Software Systems", "categories": ["cs.CL", "cs.AI"], "comment": "Under Review at Information and Software Technology", "summary": "Safety alignment is critical for LLM-powered systems. While recent\nLLM-powered guardrail approaches such as LlamaGuard achieve high detection\naccuracy of unsafe inputs written in English (e.g., ``How to create a bomb?''),\nthey struggle with multilingual unsafe inputs. This limitation leaves LLM\nsystems vulnerable to unsafe and jailbreak prompts written in low-resource\nlanguages such as those in Southeast Asia. This paper introduces SEALGuard, a\nmultilingual guardrail designed to improve the safety alignment across diverse\nlanguages. It aims to address the multilingual safety alignment gap of existing\nguardrails and ensure effective filtering of unsafe and jailbreak prompts in\nLLM-powered systems. We adapt a general-purpose multilingual language model\ninto a multilingual guardrail using low-rank adaptation (LoRA). We construct\nSEALSBench, a large-scale multilingual safety alignment dataset containing over\n260,000 prompts in ten languages, including safe, unsafe, and jailbreak cases.\nWe evaluate SEALGuard against state-of-the-art guardrails such as LlamaGuard on\nthis benchmark. Our findings show that multilingual unsafe and jailbreak\nprompts substantially degrade the performance of the state-of-the-art\nLlamaGuard, which experiences a drop in Defense Success Rate (DSR) by 9% and\n18%, respectively, compared to its performance on English-only prompts. In\ncontrast, SEALGuard outperforms existing guardrails in detecting multilingual\nunsafe and jailbreak prompts, improving DSR by 48% over LlamaGuard and\nachieving the best DSR, precision, and F1-score. Our ablation study further\nreveals the contributions of adaptation strategies and model size to the\noverall performance of SEALGuard. SEALGuard advances the safety alignment of\nLLM systems by introducing an effective multilingual guardrail.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u591a\u8bed\u8a00\u62a4\u680fSEALGuard\uff0c\u6784\u5efaSEALSBench\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u68c0\u6d4b\u591a\u8bed\u8a00\u4e0d\u5b89\u5168\u548c\u8d8a\u72f1\u63d0\u793a\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u62a4\u680f\uff0c\u63a8\u8fdb\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u7684\u5b89\u5168\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u62a4\u680f\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u591a\u8bed\u8a00\u4e0d\u5b89\u5168\u8f93\u5165\uff0c\u5b58\u5728\u591a\u8bed\u8a00\u5b89\u5168\u5bf9\u9f50\u7f3a\u53e3\uff0c\u4f7f\u7cfb\u7edf\u6613\u53d7\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u4e0d\u5b89\u5168\u548c\u8d8a\u72f1\u63d0\u793a\u653b\u51fb\u3002", "method": "\u4f7f\u7528\u4f4e\u79e9\u81ea\u9002\u5e94\uff08LoRA\uff09\u5c06\u901a\u7528\u591a\u8bed\u8a00\u6a21\u578b\u6539\u7f16\u4e3a\u591a\u8bed\u8a00\u62a4\u680f\uff0c\u6784\u5efa\u5305\u542b10\u79cd\u8bed\u8a00\u8d85260000\u6761\u63d0\u793a\u7684SEALSBench\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u591a\u8bed\u8a00\u4e0d\u5b89\u5168\u548c\u8d8a\u72f1\u63d0\u793a\u4f7fLlamaGuard\u6027\u80fd\u4e0b\u964d\uff0cSEALGuard\u5728\u68c0\u6d4b\u591a\u8bed\u8a00\u4e0d\u5b89\u5168\u548c\u8d8a\u72f1\u63d0\u793a\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0cDSR\u6bd4LlamaGuard\u63d0\u9ad848%\uff0c\u5e76\u53d6\u5f97\u6700\u4f73DSR\u3001\u7cbe\u5ea6\u548cF1\u5206\u6570\u3002", "conclusion": "SEALGuard\u901a\u8fc7\u5f15\u5165\u6709\u6548\u7684\u591a\u8bed\u8a00\u62a4\u680f\u63a8\u8fdb\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u7684\u5b89\u5168\u5bf9\u9f50\u3002"}}
{"id": "2507.08902", "pdf": "https://arxiv.org/pdf/2507.08902", "abs": "https://arxiv.org/abs/2507.08902", "authors": ["Sergio Mares", "Ariel Espinoza Weinberger", "Nilah M. Ioannidis"], "title": "Generation of structure-guided pMHC-I libraries using Diffusion Models", "categories": ["q-bio.QM", "cs.AI"], "comment": "Accepted to the The 2nd Workshop on Generative AI and Biology ICML\n  Workshop 2025", "summary": "Personalized vaccines and T-cell immunotherapies depend critically on\nidentifying peptide-MHC class I (pMHC-I) interactions capable of eliciting\npotent immune responses. However, current benchmarks and models inherit biases\npresent in mass-spectrometry and binding-assay datasets, limiting discovery of\nnovel peptide ligands. To address this issue, we introduce a structure-guided\nbenchmark of pMHC-I peptides designed using diffusion models conditioned on\ncrystal structure interaction distances. Spanning twenty high-priority HLA\nalleles, this benchmark is independent of previously characterized peptides yet\nreproduces canonical anchor residue preferences, indicating structural\ngeneralization without experimental dataset bias. Using this resource, we\ndemonstrate that state-of-the-art sequence-based predictors perform poorly at\nrecognizing the binding potential of these structurally stable designs,\nindicating allele-specific limitations invisible in conventional evaluations.\nOur geometry-aware design pipeline yields peptides with high predicted\nstructural integrity and higher residue diversity than existing datasets,\nrepresenting a key resource for unbiased model training and evaluation. Our\ncode, and data are available at: https://github.com/sermare/struct-mhc-dev.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684pMHC - I\u80bd\u7ed3\u6784\u5bfc\u5411\u57fa\u51c6\uff0c\u53d1\u73b0\u73b0\u6709\u5e8f\u5217\u9884\u6d4b\u5668\u6709\u5c40\u9650\uff0c\u8bbe\u8ba1\u7ba1\u9053\u4ea7\u51fa\u7684\u80bd\u53ef\u7528\u4e8e\u65e0\u504f\u6a21\u578b\u8bad\u7ec3\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u548c\u6a21\u578b\u5b58\u5728\u8d28\u8c31\u53ca\u7ed3\u5408\u6d4b\u5b9a\u6570\u636e\u96c6\u7684\u504f\u5dee\uff0c\u9650\u5236\u4e86\u65b0\u80bd\u914d\u4f53\u7684\u53d1\u73b0\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6676\u4f53\u7ed3\u6784\u76f8\u4e92\u4f5c\u7528\u8ddd\u79bb\u7684\u6269\u6563\u6a21\u578b\u8bbe\u8ba1pMHC - I\u80bd\u7684\u7ed3\u6784\u5bfc\u5411\u57fa\u51c6\u3002", "result": "\u73b0\u6709\u57fa\u4e8e\u5e8f\u5217\u7684\u9884\u6d4b\u5668\u96be\u4ee5\u8bc6\u522b\u7ed3\u6784\u7a33\u5b9a\u8bbe\u8ba1\u7684\u7ed3\u5408\u6f5c\u529b\uff0c\u8bbe\u8ba1\u7ba1\u9053\u4ea7\u51fa\u7684\u80bd\u7ed3\u6784\u5b8c\u6574\u6027\u9ad8\u3001\u6b8b\u57fa\u591a\u6837\u6027\u9ad8\u3002", "conclusion": "\u65b0\u57fa\u51c6\u548c\u8bbe\u8ba1\u7ba1\u9053\u662f\u65e0\u504f\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30\u7684\u5173\u952e\u8d44\u6e90\u3002"}}
{"id": "2507.09460", "pdf": "https://arxiv.org/pdf/2507.09460", "abs": "https://arxiv.org/abs/2507.09460", "authors": ["Noah Marchal", "William E. Janes", "Mihail Popescu", "Xing Song"], "title": "Enhancing ALS Progression Tracking with Semi-Supervised ALSFRS-R Scores Estimated from Ambient Home Health Monitoring", "categories": ["cs.LG", "cs.AI"], "comment": "31 pages, 8 Figures", "summary": "Clinical monitoring of functional decline in ALS relies on periodic\nassessments that may miss critical changes occurring between visits. To address\nthis gap, semi-supervised regression models were developed to estimate rates of\ndecline in a case series cohort by targeting ALSFRS- R scale trajectories with\ncontinuous in-home sensor monitoring data. Our analysis compared three model\nparadigms (individual batch learning and cohort-level batch versus incremental\nfine-tuned transfer learning) across linear slope, cubic polynomial, and\nensembled self-attention pseudo-label interpolations. Results revealed cohort\nhomogeneity across functional domains responding to learning methods, with\ntransfer learning improving prediction error for ALSFRS-R subscales in 28 of 32\ncontrasts (mean RMSE=0.20(0.04)), and individual batch learning for predicting\nthe composite scale (mean RMSE=3.15(1.25)) in 2 of 3. Self-attention\ninterpolation achieved the lowest prediction error for subscale-level models\n(mean RMSE=0.19(0.06)), capturing complex nonlinear progression patterns,\noutperforming linear and cubic interpolations in 20 of 32 contrasts, though\nlinear interpolation proved more stable in all ALSFRS-R composite scale models\n(mean RMSE=0.23(0.10)). We identified distinct homogeneity-heterogeneity\nprofiles across functional domains with respiratory and speech exhibiting\npatient-specific patterns benefiting from personalized incremental adaptation,\nwhile swallowing and dressing functions followed cohort-level trajectories\nsuitable for transfer models. These findings suggest that matching learning and\npseudo-labeling techniques to functional domain-specific\nhomogeneity-heterogeneity profiles enhances predictive accuracy in ALS\nprogression tracking. Integrating adaptive model selection within sensor\nmonitoring platforms could enable timely interventions and scalable deployment\nin future multi-center studies.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u534a\u76d1\u7763\u56de\u5f52\u6a21\u578b\uff0c\u7528\u5bb6\u5ead\u4f20\u611f\u5668\u76d1\u6d4b\u6570\u636e\u4f30\u8ba1ALS\u529f\u80fd\u8870\u9000\u7387\uff0c\u5bf9\u6bd4\u4e0d\u540c\u6a21\u578b\u8303\u5f0f\u548c\u63d2\u503c\u65b9\u6cd5\uff0c\u53d1\u73b0\u5339\u914d\u5b66\u4e60\u548c\u4f2a\u6807\u7b7e\u6280\u672f\u53ef\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u4e34\u5e8a\u5bf9ALS\u529f\u80fd\u8870\u9000\u7684\u76d1\u6d4b\u53ef\u80fd\u9519\u8fc7\u4e24\u6b21\u8bc4\u4f30\u95f4\u7684\u5173\u952e\u53d8\u5316\uff0c\u9700\u8981\u6539\u8fdb\u76d1\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u534a\u76d1\u7763\u56de\u5f52\u6a21\u578b\uff0c\u5bf9\u6bd4\u4e09\u79cd\u6a21\u578b\u8303\u5f0f\uff08\u4e2a\u4f53\u6279\u91cf\u5b66\u4e60\u3001\u961f\u5217\u7ea7\u6279\u91cf\u5b66\u4e60\u548c\u589e\u91cf\u5fae\u8c03\u8fc1\u79fb\u5b66\u4e60\uff09\uff0c\u91c7\u7528\u7ebf\u6027\u659c\u7387\u3001\u4e09\u6b21\u591a\u9879\u5f0f\u548c\u96c6\u6210\u81ea\u6ce8\u610f\u529b\u4f2a\u6807\u7b7e\u63d2\u503c\u3002", "result": "\u8fc1\u79fb\u5b66\u4e60\u6539\u558428/32\u7684ALSFRS - R\u5b50\u91cf\u8868\u9884\u6d4b\u8bef\u5dee\uff1b\u4e2a\u4f53\u6279\u91cf\u5b66\u4e60\u57282/3\u4e2d\u5bf9\u7efc\u5408\u91cf\u8868\u9884\u6d4b\u8f83\u597d\uff1b\u81ea\u6ce8\u610f\u529b\u63d2\u503c\u5728\u5b50\u91cf\u8868\u6a21\u578b\u4e2d\u8bef\u5dee\u6700\u4f4e\uff1b\u547c\u5438\u548c\u8a00\u8bed\u8868\u73b0\u51fa\u60a3\u8005\u7279\u5f02\u6027\u6a21\u5f0f\uff0c\u541e\u54bd\u548c\u7a7f\u8863\u529f\u80fd\u9075\u5faa\u961f\u5217\u7ea7\u8f68\u8ff9\u3002", "conclusion": "\u5339\u914d\u5b66\u4e60\u548c\u4f2a\u6807\u7b7e\u6280\u672f\u5230\u529f\u80fd\u57df\u7279\u5b9a\u7684\u540c\u8d28 - \u5f02\u8d28\u7279\u5f81\u53ef\u63d0\u9ad8ALS\u8fdb\u5c55\u8ddf\u8e2a\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5728\u4f20\u611f\u5668\u76d1\u6d4b\u5e73\u53f0\u4e2d\u96c6\u6210\u81ea\u9002\u5e94\u6a21\u578b\u9009\u62e9\u53ef\u7528\u4e8e\u672a\u6765\u591a\u4e2d\u5fc3\u7814\u7a76\u3002"}}
{"id": "2507.09466", "pdf": "https://arxiv.org/pdf/2507.09466", "abs": "https://arxiv.org/abs/2507.09466", "authors": ["Tomas Geffner", "Kieran Didi", "Zhonglin Cao", "Danny Reidenbach", "Zuobai Zhang", "Christian Dallago", "Emine Kucukbenli", "Karsten Kreis", "Arash Vahdat"], "title": "La-Proteina: Atomistic Protein Generation via Partially Latent Flow Matching", "categories": ["cs.LG", "q-bio.QM", "I.2.1"], "comment": null, "summary": "Recently, many generative models for de novo protein structure design have\nemerged. Yet, only few tackle the difficult task of directly generating fully\natomistic structures jointly with the underlying amino acid sequence. This is\nchallenging, for instance, because the model must reason over side chains that\nchange in length during generation. We introduce La-Proteina for atomistic\nprotein design based on a novel partially latent protein representation: coarse\nbackbone structure is modeled explicitly, while sequence and atomistic details\nare captured via per-residue latent variables of fixed dimensionality, thereby\neffectively side-stepping challenges of explicit side-chain representations.\nFlow matching in this partially latent space then models the joint distribution\nover sequences and full-atom structures. La-Proteina achieves state-of-the-art\nperformance on multiple generation benchmarks, including all-atom\nco-designability, diversity, and structural validity, as confirmed through\ndetailed structural analyses and evaluations. Notably, La-Proteina also\nsurpasses previous models in atomistic motif scaffolding performance, unlocking\ncritical atomistic structure-conditioned protein design tasks. Moreover,\nLa-Proteina is able to generate co-designable proteins of up to 800 residues, a\nregime where most baselines collapse and fail to produce valid samples,\ndemonstrating La-Proteina's scalability and robustness.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u539f\u5b50\u7ea7\u86cb\u767d\u8d28\u8bbe\u8ba1\u7684La - Proteina\uff0c\u5b83\u57fa\u4e8e\u90e8\u5206\u6f5c\u5728\u86cb\u767d\u8d28\u8868\u793a\uff0c\u5728\u591a\u4e2a\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u76ee\u524d\u76f4\u63a5\u8054\u5408\u751f\u6210\u5b8c\u6574\u539f\u5b50\u7ed3\u6784\u548c\u6c28\u57fa\u9178\u5e8f\u5217\u7684\u86cb\u767d\u8d28\u751f\u6210\u6a21\u578b\u8f83\u5c11\uff0c\u8be5\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u5982\u6a21\u578b\u9700\u5904\u7406\u751f\u6210\u8fc7\u7a0b\u4e2d\u4fa7\u94fe\u957f\u5ea6\u53d8\u5316\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u90e8\u5206\u6f5c\u5728\u86cb\u767d\u8d28\u8868\u793a\u7684La - Proteina\uff0c\u663e\u5f0f\u5efa\u6a21\u7c97\u9aa8\u5e72\u7ed3\u6784\uff0c\u901a\u8fc7\u56fa\u5b9a\u7ef4\u5ea6\u7684\u6bcf\u6b8b\u57fa\u6f5c\u5728\u53d8\u91cf\u6355\u83b7\u5e8f\u5217\u548c\u539f\u5b50\u7ec6\u8282\uff0c\u5728\u90e8\u5206\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u6d41\u5339\u914d\u4ee5\u5efa\u6a21\u5e8f\u5217\u548c\u5168\u539f\u5b50\u7ed3\u6784\u7684\u8054\u5408\u5206\u5e03\u3002", "result": "La - Proteina\u5728\u591a\u4e2a\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5728\u539f\u5b50\u57fa\u5e8f\u652f\u67b6\u6027\u80fd\u4e0a\u8d85\u8d8a\u5148\u524d\u6a21\u578b\uff0c\u80fd\u751f\u6210\u591a\u8fbe800\u4e2a\u6b8b\u57fa\u7684\u53ef\u534f\u540c\u8bbe\u8ba1\u86cb\u767d\u8d28\u3002", "conclusion": "La - Proteina\u5728\u539f\u5b50\u7ea7\u86cb\u767d\u8d28\u8bbe\u8ba1\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u89e3\u51b3\u5173\u952e\u7684\u539f\u5b50\u7ed3\u6784\u6761\u4ef6\u86cb\u767d\u8d28\u8bbe\u8ba1\u4efb\u52a1\u3002"}}
{"id": "2507.09480", "pdf": "https://arxiv.org/pdf/2507.09480", "abs": "https://arxiv.org/abs/2507.09480", "authors": ["Guoyou Wang", "Yihua Tan", "Shiqi Liu"], "title": "Discrete Differential Principle for Continuous Smooth Function Representation", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Taylor's formula holds significant importance in function representation,\nsuch as solving differential difference equations, ordinary differential\nequations, partial differential equations, and further promotes applications in\nvisual perception, complex control, fluid mechanics, weather forecasting and\nthermodynamics. However, the Taylor's formula suffers from the curse of\ndimensionality and error propagation during derivative computation in discrete\nsituations. In this paper, we propose a new discrete differential operator to\nestimate derivatives and to represent continuous smooth function locally using\nthe Vandermonde coefficient matrix derived from truncated Taylor series. Our\nmethod simultaneously computes all derivatives of orders less than the number\nof sample points, inherently mitigating error propagation. Utilizing\nequidistant uniform sampling, it achieves high-order accuracy while alleviating\nthe curse of dimensionality. We mathematically establish rigorous error bounds\nfor both derivative estimation and function representation, demonstrating\ntighter bounds for lower-order derivatives. We extend our method to the\ntwo-dimensional case, enabling its use for multivariate derivative\ncalculations. Experiments demonstrate the effectiveness and superiority of the\nproposed method compared to the finite forward difference method for derivative\nestimation and cubic spline and linear interpolation for function\nrepresentation. Consequently, our technique offers broad applicability across\ndomains such as vision representation, feature extraction, fluid mechanics, and\ncross-media imaging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u79bb\u6563\u5fae\u5206\u7b97\u5b50\u4f30\u8ba1\u5bfc\u6570\u5e76\u8868\u793a\u8fde\u7eed\u5149\u6ed1\u51fd\u6570\uff0c\u53ef\u7f13\u89e3\u7ef4\u6570\u707e\u96be\u548c\u8bef\u5dee\u4f20\u64ad\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u4e14\u5177\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "motivation": "\u6cf0\u52d2\u516c\u5f0f\u5728\u79bb\u6563\u60c5\u51b5\u4e0b\u5b58\u5728\u7ef4\u6570\u707e\u96be\u548c\u5bfc\u6570\u8ba1\u7b97\u65f6\u7684\u8bef\u5dee\u4f20\u64ad\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u65b0\u79bb\u6563\u5fae\u5206\u7b97\u5b50\uff0c\u5229\u7528\u622a\u65ad\u6cf0\u52d2\u7ea7\u6570\u7684\u8303\u5fb7\u8499\u5fb7\u7cfb\u6570\u77e9\u9635\uff0c\u540c\u65f6\u8ba1\u7b97\u4f4e\u4e8e\u6837\u672c\u70b9\u6570\u9636\u6570\u7684\u6240\u6709\u5bfc\u6570\uff0c\u91c7\u7528\u7b49\u8ddd\u5747\u5300\u91c7\u6837\u3002", "result": "\u5efa\u7acb\u5bfc\u6570\u4f30\u8ba1\u548c\u51fd\u6570\u8868\u793a\u7684\u4e25\u683c\u8bef\u5dee\u754c\uff0c\u5c06\u65b9\u6cd5\u6269\u5c55\u5230\u4e8c\u7ef4\u60c5\u51b5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6709\u9650\u524d\u5411\u5dee\u5206\u6cd5\u3001\u4e09\u6b21\u6837\u6761\u548c\u7ebf\u6027\u63d2\u503c\u3002", "conclusion": "\u8be5\u6280\u672f\u5728\u89c6\u89c9\u8868\u793a\u3001\u7279\u5f81\u63d0\u53d6\u7b49\u9886\u57df\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2507.08920", "pdf": "https://arxiv.org/pdf/2507.08920", "abs": "https://arxiv.org/abs/2507.08920", "authors": ["Changze Lv", "Jiang Zhou", "Siyu Long", "Lihao Wang", "Jiangtao Feng", "Dongyu Xue", "Yu Pei", "Hao Wang", "Zherui Zhang", "Yuchen Cai", "Zhiqiang Gao", "Ziyuan Ma", "Jiakai Hu", "Chaochen Gao", "Jingjing Gong", "Yuxuan Song", "Shuyi Zhang", "Xiaoqing Zheng", "Deyi Xiong", "Lei Bai", "Ya-Qin Zhang", "Wei-Ying Ma", "Bowen Zhou", "Hao Zhou"], "title": "AMix-1: A Pathway to Test-Time Scalable Protein Foundation Model", "categories": ["q-bio.BM", "cs.AI"], "comment": null, "summary": "We introduce AMix-1, a powerful protein foundation model built on Bayesian\nFlow Networks and empowered by a systematic training methodology, encompassing\npretraining scaling laws, emergent capability analysis, in-context learning\nmechanism, and test-time scaling algorithm. To guarantee robust scalability, we\nestablish a predictive scaling law and reveal the progressive emergence of\nstructural understanding via loss perspective, culminating in a strong\n1.7-billion model. Building on this foundation, we devise a multiple sequence\nalignment (MSA)-based in-context learning strategy to unify protein design into\na general framework, where AMix-1 recognizes deep evolutionary signals among\nMSAs and consistently generates structurally and functionally coherent\nproteins. This framework enables the successful design of a dramatically\nimproved AmeR variant with an up to $50\\times$ activity increase over its wild\ntype. Pushing the boundaries of protein engineering, we further empower AMix-1\nwith an evolutionary test-time scaling algorithm for in silico directed\nevolution that delivers substantial, scalable performance gains as verification\nbudgets are intensified, laying the groundwork for next-generation\nlab-in-the-loop protein design.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8e\u8d1d\u53f6\u65af\u6d41\u7f51\u7edc\u7684\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578bAMix - 1\uff0c\u8be6\u8ff0\u8bad\u7ec3\u65b9\u6cd5\u53ca\u6210\u679c\uff0c\u5982\u8bbe\u8ba1\u6539\u8fdb\u7684AmeR\u53d8\u4f53\uff0c\u8fd8\u91c7\u7528\u7b97\u6cd5\u63a8\u52a8\u86cb\u767d\u8d28\u5de5\u7a0b\u53d1\u5c55\u3002", "motivation": "\u6784\u5efa\u5f3a\u5927\u7684\u86cb\u767d\u8d28\u57fa\u7840\u6a21\u578b\uff0c\u63a8\u52a8\u86cb\u767d\u8d28\u5de5\u7a0b\u53d1\u5c55\uff0c\u5b9e\u73b0\u86cb\u767d\u8d28\u7684\u6709\u6548\u8bbe\u8ba1\u3002", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u6d41\u7f51\u7edc\uff0c\u8fd0\u7528\u7cfb\u7edf\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u9884\u8bad\u7ec3\u7f29\u653e\u5b9a\u5f8b\u3001\u6d8c\u73b0\u80fd\u529b\u5206\u6790\u7b49\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u591a\u5e8f\u5217\u6bd4\u5bf9\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u7b56\u7565\uff1b\u91c7\u7528\u8fdb\u5316\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u7b97\u6cd5\u3002", "result": "\u6784\u5efa\u51fa17\u4ebf\u53c2\u6570\u7684\u5f3a\u5927\u6a21\u578bAMix - 1\uff0c\u6210\u529f\u8bbe\u8ba1\u51fa\u6d3b\u6027\u6bd4\u91ce\u751f\u578b\u63d0\u9ad8\u8fbe50\u500d\u7684AmeR\u53d8\u4f53\uff0c\u7b97\u6cd5\u5e26\u6765\u53ef\u6269\u5c55\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AMix - 1\u53ca\u5176\u76f8\u5173\u65b9\u6cd5\u4e3a\u4e0b\u4e00\u4ee3\u5b9e\u9a8c\u5ba4\u5faa\u73af\u86cb\u767d\u8d28\u8bbe\u8ba1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.09523", "pdf": "https://arxiv.org/pdf/2507.09523", "abs": "https://arxiv.org/abs/2507.09523", "authors": ["Brett Daley", "Prabhat Nagarajan", "Martha White", "Marlos C. Machado"], "title": "An Analysis of Action-Value Temporal-Difference Methods That Learn State Values", "categories": ["cs.LG", "cs.AI"], "comment": "Published at RLC/RLJ 2025", "summary": "The hallmark feature of temporal-difference (TD) learning is bootstrapping:\nusing value predictions to generate new value predictions. The vast majority of\nTD methods for control learn a policy by bootstrapping from a single\naction-value function (e.g., Q-learning and Sarsa). Significantly less\nattention has been given to methods that bootstrap from two asymmetric value\nfunctions: i.e., methods that learn state values as an intermediate step in\nlearning action values. Existing algorithms in this vein can be categorized as\neither QV-learning or AV-learning. Though these algorithms have been\ninvestigated to some degree in prior work, it remains unclear if and when it is\nadvantageous to learn two value functions instead of just one -- and whether\nsuch approaches are theoretically sound in general. In this paper, we analyze\nthese algorithmic families in terms of convergence and sample efficiency. We\nfind that while both families are more efficient than Expected Sarsa in the\nprediction setting, only AV-learning methods offer any major benefit over\nQ-learning in the control setting. Finally, we introduce a new AV-learning\nalgorithm called Regularized Dueling Q-learning (RDQ), which significantly\noutperforms Dueling DQN in the MinAtar benchmark.", "AI": {"tldr": "\u5206\u6790\u4ece\u4e24\u4e2a\u975e\u5bf9\u79f0\u4ef7\u503c\u51fd\u6570\u8fdb\u884c\u5f15\u5bfc\u7684TD\u63a7\u5236\u65b9\u6cd5\uff0c\u6bd4\u8f83\u5176\u4e0e\u5176\u4ed6\u65b9\u6cd5\u5728\u6536\u655b\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u5f15\u5165\u65b0\u7b97\u6cd5RDQ\u4e14\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u4ece\u4e24\u4e2a\u975e\u5bf9\u79f0\u4ef7\u503c\u51fd\u6570\u5f15\u5bfc\u7684TD\u63a7\u5236\u65b9\u6cd5\u7814\u7a76\u4e0d\u8db3\uff0c\u4e0d\u6e05\u695a\u5b66\u4e60\u4e24\u4e2a\u4ef7\u503c\u51fd\u6570\u7684\u4f18\u52bf\u53ca\u7406\u8bba\u5408\u7406\u6027\u3002", "method": "\u4ece\u6536\u655b\u6027\u548c\u6837\u672c\u6548\u7387\u65b9\u9762\u5206\u6790QV - learning\u548cAV - learning\u7b97\u6cd5\u65cf\u3002", "result": "\u5728\u9884\u6d4b\u573a\u666f\u4e2d\uff0c\u4e24\u4e2a\u7b97\u6cd5\u65cf\u6bd4Expected Sarsa\u66f4\u9ad8\u6548\uff1b\u5728\u63a7\u5236\u573a\u666f\u4e2d\uff0c\u4ec5AV - learning\u65b9\u6cd5\u6bd4Q - learning\u6709\u663e\u8457\u4f18\u52bf\uff1b\u65b0\u7b97\u6cd5RDQ\u5728MinAtar\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8eDueling DQN\u3002", "conclusion": "\u7814\u7a76\u4e86\u4e0d\u540cTD\u63a7\u5236\u65b9\u6cd5\u7279\u70b9\uff0c\u5f15\u5165\u7684\u65b0\u7b97\u6cd5\u6709\u8f83\u597d\u8868\u73b0\u3002"}}
{"id": "2507.08924", "pdf": "https://arxiv.org/pdf/2507.08924", "abs": "https://arxiv.org/abs/2507.08924", "authors": ["Seokhee Hong", "Sunkyoung Kim", "Guijin Son", "Soyeon Kim", "Yeonjung Hong", "Jinsik Lee"], "title": "From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for LLM Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The development of Large Language Models (LLMs) requires robust benchmarks\nthat encompass not only academic domains but also industrial fields to\neffectively evaluate their applicability in real-world scenarios. In this\npaper, we introduce two Korean expert-level benchmarks. KMMLU-Redux,\nreconstructed from the existing KMMLU, consists of questions from the Korean\nNational Technical Qualification exams, with critical errors removed to enhance\nreliability. KMMLU-Pro is based on Korean National Professional Licensure exams\nto reflect professional knowledge in Korea. Our experiments demonstrate that\nthese benchmarks comprehensively represent industrial knowledge in Korea. We\nrelease our dataset publicly available.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e24\u4e2a\u97e9\u56fd\u4e13\u5bb6\u7ea7\u57fa\u51c6KMMLU - Redux\u548cKMMLU - Pro\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u573a\u666f\u7684\u9002\u7528\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5b83\u4eec\u80fd\u5168\u9762\u4ee3\u8868\u97e9\u56fd\u5de5\u4e1a\u77e5\u8bc6\uff0c\u5e76\u516c\u5f00\u6570\u636e\u96c6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u9700\u8981\u80fd\u6db5\u76d6\u5b66\u672f\u548c\u5de5\u4e1a\u9886\u57df\u7684\u53ef\u9760\u57fa\u51c6\uff0c\u4ee5\u6709\u6548\u8bc4\u4f30\u5176\u5728\u73b0\u5b9e\u573a\u666f\u7684\u9002\u7528\u6027\u3002", "method": "\u5f15\u5165KMMLU - Redux\uff08\u4ece\u73b0\u6709KMMLU\u91cd\u6784\uff0c\u53bb\u9664\u97e9\u56fd\u56fd\u5bb6\u6280\u672f\u8d44\u683c\u8003\u8bd5\u95ee\u9898\u4e2d\u7684\u5173\u952e\u9519\u8bef\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\uff09\u548cKMMLU - Pro\uff08\u57fa\u4e8e\u97e9\u56fd\u56fd\u5bb6\u4e13\u4e1a\u6267\u7167\u8003\u8bd5\u4ee5\u53cd\u6620\u97e9\u56fd\u4e13\u4e1a\u77e5\u8bc6\uff09\u4e24\u4e2a\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u4e24\u4e2a\u57fa\u51c6\u80fd\u5168\u9762\u4ee3\u8868\u97e9\u56fd\u5de5\u4e1a\u77e5\u8bc6\u3002", "conclusion": "\u4e24\u4e2a\u57fa\u51c6\u5bf9\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u573a\u666f\u7684\u9002\u7528\u6027\u6709\u610f\u4e49\uff0c\u4e14\u6570\u636e\u96c6\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.09545", "pdf": "https://arxiv.org/pdf/2507.09545", "abs": "https://arxiv.org/abs/2507.09545", "authors": ["Ilaria Vascotto", "Valentina Blasone", "Alex Rodriguez", "Alessandro Bonaita", "Luca Bortolussi"], "title": "Assessing reliability of explanations in unbalanced datasets: a use-case on the occurrence of frost events", "categories": ["cs.LG"], "comment": "Late Breaking Work presented at the 3rd World Conference on\n  eXplainable Artificial Intelligence (XAI2025)", "summary": "The usage of eXplainable Artificial Intelligence (XAI) methods has become\nessential in practical applications, given the increasing deployment of\nArtificial Intelligence (AI) models and the legislative requirements put\nforward in the latest years. A fundamental but often underestimated aspect of\nthe explanations is their robustness, a key property that should be satisfied\nin order to trust the explanations. In this study, we provide some preliminary\ninsights on evaluating the reliability of explanations in the specific case of\nunbalanced datasets, which are very frequent in high-risk use-cases, but at the\nsame time considerably challenging for both AI models and XAI methods. We\npropose a simple evaluation focused on the minority class (i.e. the less\nfrequent one) that leverages on-manifold generation of neighbours, explanation\naggregation and a metric to test explanation consistency. We present a use-case\nbased on a tabular dataset with numerical features focusing on the occurrence\nof frost events.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0b\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u89e3\u91ca\u53ef\u9760\u6027\u8bc4\u4f30\uff0c\u63d0\u51fa\u9488\u5bf9\u5c11\u6570\u7c7b\u7684\u8bc4\u4f30\u65b9\u6cd5\u5e76\u7ed9\u51fa\u7528\u4f8b\u3002", "motivation": "\u968f\u7740AI\u6a21\u578b\u90e8\u7f72\u589e\u591a\u53ca\u7acb\u6cd5\u8981\u6c42\uff0cXAI\u65b9\u6cd5\u5e94\u7528\u91cd\u8981\uff0c\u89e3\u91ca\u7684\u9c81\u68d2\u6027\u662f\u5173\u952e\uff0c\u4f46\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0b\u8bc4\u4f30\u89e3\u91ca\u53ef\u9760\u6027\u5e38\u88ab\u4f4e\u4f30\u3002", "method": "\u63d0\u51fa\u805a\u7126\u5c11\u6570\u7c7b\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5229\u7528\u6d41\u5f62\u4e0a\u90bb\u5c45\u751f\u6210\u3001\u89e3\u91ca\u805a\u5408\u548c\u68c0\u9a8c\u89e3\u91ca\u4e00\u81f4\u6027\u7684\u6307\u6807\u3002", "result": "\u57fa\u4e8e\u542b\u6570\u503c\u7279\u5f81\u7684\u8868\u683c\u6570\u636e\u96c6\u7ed9\u51fa\u4e86\u5173\u4e8e\u971c\u51bb\u4e8b\u4ef6\u53d1\u751f\u7684\u7528\u4f8b\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u7ed3\u8bba\u5185\u5bb9\u3002"}}
{"id": "2507.08944", "pdf": "https://arxiv.org/pdf/2507.08944", "abs": "https://arxiv.org/abs/2507.08944", "authors": ["Enhao Zhang", "Erkang Zhu", "Gagan Bansal", "Adam Fourney", "Hussein Mozannar", "Jack Gerrits"], "title": "Optimizing Sequential Multi-Step Tasks with Parallel LLM Agents", "categories": ["cs.MA", "cs.AI"], "comment": "ICML 2025 Workshop on MAS", "summary": "Large language model (LLM)-based multi-agent systems have demonstrated\nremarkable promise for tackling complex tasks by breaking them down into\nsubtasks that are iteratively planned, executed, observed, and refined. Despite\ntheir effectiveness, these systems often incur high latency because real-world\nproblems frequently demand multiple iterative cycles of reasoning steps. To\naddress this challenge, we propose M1-Parallel, a framework that concurrently\nruns multiple multi-agent teams in parallel to uncover distinct solution paths.\nBy leveraging an event-driven communication model with asynchronous messaging,\nM1-Parallel efficiently capitalizes on the inherent diversity of valid plans to\neither reduce end-to-end latency or boost task completion rates. Our\nexperiments on complex tasks show that M1-Parallel with early termination\nachieves up to $2.2\\times$ speedup while preserving accuracy, and that\nM1-Parallel with aggregation yields higher task completion rates. We further\ninvestigate strategies aimed at encouraging diverse execution plans but observe\nno additional performance gains over repeated sampling. Overall, these findings\nunderscore the potential of parallel plan execution for optimizing multi-agent\nsystems for real-world, high-complexity reasoning tasks.", "AI": {"tldr": "\u63d0\u51faM1 - Parallel\u6846\u67b6\u89e3\u51b3\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u63d0\u5347\u901f\u5ea6\u6216\u4efb\u52a1\u5b8c\u6210\u7387\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u5b58\u5728\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u3002", "method": "\u63d0\u51faM1 - Parallel\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u8fd0\u884c\u591a\u667a\u80fd\u4f53\u56e2\u961f\uff0c\u5229\u7528\u4e8b\u4ef6\u9a71\u52a8\u901a\u4fe1\u6a21\u578b\u548c\u5f02\u6b65\u6d88\u606f\u4f20\u9012\u6765\u6316\u6398\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u8def\u5f84\u3002", "result": "M1 - Parallel\u63d0\u524d\u7ec8\u6b62\u53ef\u5b9e\u73b0\u6700\u9ad82.2\u500d\u52a0\u901f\u4e14\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u805a\u5408\u65b9\u5f0f\u53ef\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u7387\uff1b\u63a2\u7d22\u9f13\u52b1\u591a\u6837\u5316\u6267\u884c\u8ba1\u5212\u7b56\u7565\u672a\u5e26\u6765\u989d\u5916\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5e76\u884c\u8ba1\u5212\u6267\u884c\u5bf9\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5904\u7406\u73b0\u5b9e\u9ad8\u590d\u6742\u5ea6\u63a8\u7406\u4efb\u52a1\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.09565", "pdf": "https://arxiv.org/pdf/2507.09565", "abs": "https://arxiv.org/abs/2507.09565", "authors": ["Heeba Shakeel", "Tanvir Ahmad", "Chandni Saxena"], "title": "Holistix: A Dataset for Holistic Wellness Dimensions Analysis in Mental Health Narratives", "categories": ["cs.LG"], "comment": "7 Pages", "summary": "We introduce a dataset for classifying wellness dimensions in social media\nuser posts, covering six key aspects: physical, emotional, social,\nintellectual, spiritual, and vocational. The dataset is designed to capture\nthese dimensions in user-generated content, with a comprehensive annotation\nframework developed under the guidance of domain experts. This framework allows\nfor the classification of text spans into the appropriate wellness categories.\nWe evaluate both traditional machine learning models and advanced\ntransformer-based models for this multi-class classification task, with\nperformance assessed using precision, recall, and F1-score, averaged over\n10-fold cross-validation. Post-hoc explanations are applied to ensure the\ntransparency and interpretability of model decisions. The proposed dataset\ncontributes to region-specific wellness assessments in social media and paves\nthe way for personalized well-being evaluations and early intervention\nstrategies in mental health. We adhere to ethical considerations for\nconstructing and releasing our experiments and dataset publicly on Github.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8e\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u5e16\u5b50\u5065\u5eb7\u7ef4\u5ea6\u5206\u7c7b\u7684\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\u5e76\u505a\u540e\u9a8c\u89e3\u91ca\uff0c\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u7279\u5b9a\u533a\u57df\u5065\u5eb7\u8bc4\u4f30\u7b49", "motivation": "\u6784\u5efa\u53ef\u7528\u4e8e\u793e\u4ea4\u5a92\u4f53\u7528\u6237\u5e16\u5b50\u5065\u5eb7\u7ef4\u5ea6\u5206\u7c7b\u7684\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u7279\u5b9a\u533a\u57df\u5065\u5eb7\u8bc4\u4f30\u548c\u4e2a\u6027\u5316\u5fc3\u7406\u5065\u5eb7\u8bc4\u4f30\u53ca\u5e72\u9884", "method": "\u5f00\u53d1\u7efc\u5408\u6807\u6ce8\u6846\u67b6\uff0c\u8bc4\u4f30\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u6a21\u578b\uff0c\u7528\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u8bc4\u4f30\u6027\u80fd\uff0c\u91c7\u752810\u6298\u4ea4\u53c9\u9a8c\u8bc1\u548c\u540e\u9a8c\u89e3\u91ca", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u6a21\u578b\u5177\u4f53\u6027\u80fd\u7ed3\u679c", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u793e\u4ea4\u5a92\u4f53\u7279\u5b9a\u533a\u57df\u5065\u5eb7\u8bc4\u4f30\uff0c\u4e3a\u4e2a\u6027\u5316\u5e78\u798f\u8bc4\u4f30\u548c\u5fc3\u7406\u5065\u5eb7\u65e9\u671f\u5e72\u9884\u7b56\u7565\u5960\u5b9a\u57fa\u7840\uff0c\u4e14\u5b9e\u9a8c\u548c\u6570\u636e\u96c6\u6309\u4f26\u7406\u516c\u5f00"}}
{"id": "2507.09602", "pdf": "https://arxiv.org/pdf/2507.09602", "abs": "https://arxiv.org/abs/2507.09602", "authors": ["Bocheng Ju", "Junchao Fan", "Jiaqi Liu", "Xiaolin Chang"], "title": "DRAGD: A Federated Unlearning Data Reconstruction Attack Based on Gradient Differences", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning enables collaborative machine learning while preserving\ndata privacy. However, the rise of federated unlearning, designed to allow\nclients to erase their data from the global model, introduces new privacy\nconcerns. Specifically, the gradient exchanges during the unlearning process\ncan leak sensitive information about deleted data. In this paper, we introduce\nDRAGD, a novel attack that exploits gradient discrepancies before and after\nunlearning to reconstruct forgotten data. We also present DRAGDP, an enhanced\nversion of DRAGD that leverages publicly available prior data to improve\nreconstruction accuracy, particularly for complex datasets like facial images.\nExtensive experiments across multiple datasets demonstrate that DRAGD and\nDRAGDP significantly outperform existing methods in data reconstruction.Our\nwork highlights a critical privacy vulnerability in federated unlearning and\noffers a practical solution, advancing the security of federated unlearning\nsystems in real-world applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9488\u5bf9\u8054\u90a6\u53cd\u5b66\u4e60\u7684DRAGD\u653b\u51fb\u53ca\u5176\u589e\u5f3a\u7248DRAGDP\uff0c\u5b9e\u9a8c\u8868\u660e\u5b83\u4eec\u5728\u6570\u636e\u91cd\u6784\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51f8\u663e\u4e86\u8054\u90a6\u53cd\u5b66\u4e60\u7684\u9690\u79c1\u6f0f\u6d1e\u5e76\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u8054\u90a6\u53cd\u5b66\u4e60\u4e2d\u68af\u5ea6\u4ea4\u6362\u4f1a\u6cc4\u9732\u5df2\u5220\u9664\u6570\u636e\u7684\u654f\u611f\u4fe1\u606f\uff0c\u5b58\u5728\u65b0\u7684\u9690\u79c1\u95ee\u9898\u3002", "method": "\u63d0\u51faDRAGD\u653b\u51fb\uff0c\u5229\u7528\u53cd\u5b66\u4e60\u524d\u540e\u7684\u68af\u5ea6\u5dee\u5f02\u91cd\u6784\u88ab\u9057\u5fd8\u6570\u636e\uff1b\u63d0\u51fa\u589e\u5f3a\u7248DRAGDP\uff0c\u5229\u7528\u516c\u5f00\u7684\u5148\u9a8c\u6570\u636e\u63d0\u9ad8\u91cd\u6784\u51c6\u786e\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDRAGD\u548cDRAGDP\u5728\u6570\u636e\u91cd\u6784\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u51f8\u663e\u4e86\u8054\u90a6\u53cd\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u9690\u79c1\u6f0f\u6d1e\uff0c\u4e3a\u63d0\u9ad8\u73b0\u5b9e\u5e94\u7528\u4e2d\u8054\u90a6\u53cd\u5b66\u4e60\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08958", "pdf": "https://arxiv.org/pdf/2507.08958", "abs": "https://arxiv.org/abs/2507.08958", "authors": ["Xiaowen Zhang", "Zhenyu Bi", "Xuan Wang", "Tiziana Di Matteo", "Rupert A. C. Croft"], "title": "Bridging Literature and the Universe Via A Multi-Agent Large Language Model System", "categories": ["astro-ph.IM", "cs.AI", "cs.MA"], "comment": "6 pages, 4 figures", "summary": "As cosmological simulations and their associated software become increasingly\ncomplex, physicists face the challenge of searching through vast amounts of\nliterature and user manuals to extract simulation parameters from dense\nacademic papers, each using different models and formats. Translating these\nparameters into executable scripts remains a time-consuming and error-prone\nprocess. To improve efficiency in physics research and accelerate the\ncosmological simulation process, we introduce SimAgents, a multi-agent system\ndesigned to automate both parameter configuration from the literature and\npreliminary analysis for cosmology research. SimAgents is powered by\nspecialized LLM agents capable of physics reasoning, simulation software\nvalidation, and tool execution. These agents collaborate through structured\ncommunication, ensuring that extracted parameters are physically meaningful,\ninternally consistent, and software-compliant. We also construct a cosmological\nparameter extraction evaluation dataset by collecting over 40 simulations in\npublished papers from Arxiv and leading journals that cover diverse simulation\ntypes. Experiments on the dataset demonstrate a strong performance of\nSimAgents, highlighting its effectiveness and potential to accelerate\nscientific research for physicists. Our demonstration video is available at:\nhttps://youtu.be/w1zLpm_CaWA. The complete system and dataset are publicly\navailable at https://github.com/xwzhang98/SimAgents.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u591a\u667a\u80fd\u4f53\u7cfb\u7edfSimAgents\uff0c\u53ef\u81ea\u52a8\u5b8c\u6210\u5b87\u5b99\u5b66\u7814\u7a76\u4e2d\u53c2\u6570\u914d\u7f6e\u4e0e\u521d\u6b65\u5206\u6790\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u826f\u597d\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u516c\u5f00\u3002", "motivation": "\u968f\u7740\u5b87\u5b99\u5b66\u6a21\u62df\u53ca\u5176\u8f6f\u4ef6\u65e5\u76ca\u590d\u6742\uff0c\u4ece\u6587\u732e\u4e2d\u63d0\u53d6\u53c2\u6570\u5e76\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u811a\u672c\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u4e3a\u63d0\u9ad8\u7269\u7406\u7814\u7a76\u6548\u7387\u3001\u52a0\u901f\u6a21\u62df\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u7531\u5177\u5907\u7269\u7406\u63a8\u7406\u7b49\u80fd\u529b\u7684LLM\u667a\u80fd\u4f53\u9a71\u52a8\u7684SimAgents\u7cfb\u7edf\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u7ed3\u6784\u5316\u901a\u4fe1\u534f\u4f5c\uff0c\u6784\u5efa\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "result": "\u5728\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793aSimAgents\u6027\u80fd\u826f\u597d\u3002", "conclusion": "SimAgents\u6709\u6548\u4e14\u6709\u6f5c\u529b\u52a0\u901f\u7269\u7406\u5b66\u5bb6\u7684\u79d1\u5b66\u7814\u7a76\u3002"}}
{"id": "2507.09616", "pdf": "https://arxiv.org/pdf/2507.09616", "abs": "https://arxiv.org/abs/2507.09616", "authors": ["Ofir Gordon", "Ariel Lapid", "Elad Cohen", "Yarden Yagil", "Arnon Netzer", "Hai Victor Habi"], "title": "MLoRQ: Bridging Low-Rank and Quantization for Transformer Compression", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Deploying transformer-based neural networks on resource-constrained edge\ndevices presents a significant challenge. This challenge is often addressed\nthrough various techniques, such as low-rank approximation and mixed-precision\nquantization. In this work, we introduce Mixed Low-Rank and Quantization\n(MLoRQ), a novel method that integrates both techniques. MLoRQ employs a\ntwo-stage optimization process to determine optimal bit-width and rank\nassignments for each layer, adhering to predefined memory constraints. This\nprocess includes: (i) an intra-layer optimization that identifies potentially\noptimal compression solutions out of all low-rank and quantization\ncombinations; (ii) an inter-layer optimization that assigns bit-width precision\nand rank to each layer while ensuring the memory constraint is met. An optional\nfinal step applies a sequential optimization process using a modified adaptive\nrounding technique to mitigate compression-induced errors in joint low-rank\napproximation and quantization. The method is compatible and can be seamlessly\nintegrated with most existing quantization algorithms. MLoRQ shows\nstate-of-the-art results with up to 15\\% performance improvement, evaluated on\nVision Transformers for image classification, object detection, and instance\nsegmentation tasks.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u4f4e\u79e9\u4e0e\u91cf\u5316\u65b9\u6cd5MLoRQ\uff0c\u7ed3\u5408\u4f4e\u79e9\u8fd1\u4f3c\u548c\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u6280\u672f\uff0c\u5206\u9636\u6bb5\u4f18\u5316\uff0c\u517c\u5bb9\u73b0\u6709\u91cf\u5316\u7b97\u6cd5\uff0c\u5728\u89c6\u89c9Transformer\u4efb\u52a1\u4e0a\u6709\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u8fc7\u7a0b\u786e\u5b9a\u5404\u5c42\u6700\u4f18\u4f4d\u5bbd\u548c\u79e9\u5206\u914d\uff0c\u8fd8\u53ef\u4f7f\u7528\u6539\u8fdb\u7684\u81ea\u9002\u5e94\u820d\u5165\u6280\u672f\u51cf\u8f7b\u538b\u7f29\u8bef\u5dee\uff0c\u4e14\u4e0e\u591a\u6570\u73b0\u6709\u91cf\u5316\u7b97\u6cd5\u517c\u5bb9\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u76ee\u6807\u68c0\u6d4b\u548c\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u7684\u89c6\u89c9Transformer\u4e0a\u8bc4\u4f30\uff0c\u6709\u9ad8\u8fbe15%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MLoRQ\u662f\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3Transformer\u7f51\u7edc\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u95ee\u9898\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.08960", "pdf": "https://arxiv.org/pdf/2507.08960", "abs": "https://arxiv.org/abs/2507.08960", "authors": ["Andrew Estornell", "Jean-Francois Ton", "Muhammad Faaiz Taufiq", "Hang Li"], "title": "How to Train a Leader: Hierarchical Reasoning in Multi-Agent LLMs", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have achieved strong performance on a wide range\nof complex reasoning tasks, yet further gains are often possible by leveraging\nthe complementary strengths of multiple models. While multi-agent frameworks\ncan improve solution quality by leveraging multiple LLMs, existing methods are\noften computationally expensive, both at training and inference time. In this\nwork, we introduce a hierarchical multi-agent framework that addresses these\nchallenges by training only a single leader LLM to coordinate a team of\nuntrained peer agents. To this end, we propose Multi-agent guided Leader Policy\n\\textbf{O}ptimization (MLPO), a novel approach which trains the leader to\nevaluate and synthesize agent responses without auxiliary value networks or\nexplicit agent feedback. Leaders trained with MLPO exhibit improved performance\nnot only when interacting with the agent team at inference time, but also enjoy\nimproved performance when deployed in single-agent settings without the team.\nEmpirical results on Big-Bench Hard (BBH), MATH, and MMLU demonstrate that our\nframework achieves substantial performance improvements over both single-agent\nand multi-agent baselines. Our results highlight the effectiveness and\nefficiency of training a single, flexible leader for collaborative reasoning in\nmulti-agent LLM systems.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528MLPO\u8bad\u7ec3\u5355\u4e2a\u9886\u5bfc\u8005\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u4efb\u52a1\u4e0a\u8d85\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u63d0\u5347\u6548\u7387\u3002", "method": "\u5f15\u5165\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u63d0\u51faMLPO\u65b9\u6cd5\u8bad\u7ec3\u5355\u4e2a\u9886\u5bfc\u8005LLM\u534f\u8c03\u672a\u8bad\u7ec3\u7684\u5bf9\u7b49\u667a\u80fd\u4f53\uff0c\u9886\u5bfc\u8005\u8bc4\u4f30\u548c\u5408\u6210\u4ee3\u7406\u54cd\u5e94\u65e0\u9700\u8f85\u52a9\u4ef7\u503c\u7f51\u7edc\u6216\u663e\u5f0f\u4ee3\u7406\u53cd\u9988\u3002", "result": "\u5728BBH\u3001MATH\u548cMMLU\u4e0a\u53d6\u5f97\u6bd4\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8bad\u7ec3\u5355\u4e2a\u7075\u6d3b\u9886\u5bfc\u8005\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u534f\u4f5c\u63a8\u7406\u6709\u6548\u4e14\u9ad8\u6548\u3002"}}
{"id": "2507.09650", "pdf": "https://arxiv.org/pdf/2507.09650", "abs": "https://arxiv.org/abs/2507.09650", "authors": ["Lily Hong Zhang", "Smitha Milli", "Karen Jusko", "Jonathan Smith", "Brandon Amos", "Wassim", "Bouaziz", "Manon Revel", "Jack Kussman", "Lisa Titus", "Bhaktipriya Radharapu", "Jane Yu", "Vidya Sarma", "Kris Rose", "Maximilian Nickel"], "title": "Cultivating Pluralism In Algorithmic Monoculture: The Community Alignment Dataset", "categories": ["cs.LG"], "comment": null, "summary": "How can large language models (LLMs) serve users with varying preferences\nthat may conflict across cultural, political, or other dimensions? To advance\nthis challenge, this paper establishes four key results. First, we demonstrate,\nthrough a large-scale multilingual human study with representative samples from\nfive countries (N=15,000), that humans exhibit significantly more variation in\npreferences than the responses of 21 state-of-the-art LLMs. Second, we show\nthat existing methods for preference dataset collection are insufficient for\nlearning the diversity of human preferences even along two of the most salient\ndimensions of variability in global values, due to the underlying homogeneity\nof candidate responses. Third, we argue that this motivates the need for\nnegatively-correlated sampling when generating candidate sets, and we show that\nsimple prompt-based techniques for doing so significantly enhance the\nperformance of alignment methods in learning heterogeneous preferences. Fourth,\nbased on this novel candidate sampling approach, we collect and open-source\nCommunity Alignment, the largest and most representative multilingual and\nmulti-turn preference dataset to date, featuring almost 200,000 comparisons\nfrom annotators spanning five countries. We hope that the Community Alignment\ndataset will be a valuable resource for improving the effectiveness of LLMs for\na diverse global population.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u7814\u7a76\u53d1\u73b0\u4eba\u7c7b\u504f\u597d\u5dee\u5f02\u5927\uff0c\u73b0\u6709\u504f\u597d\u6570\u636e\u96c6\u6536\u96c6\u65b9\u6cd5\u4e0d\u8db3\uff0c\u63d0\u51fa\u8d1f\u76f8\u5173\u91c7\u6837\u6cd5\u63d0\u5347\u5bf9\u9f50\u65b9\u6cd5\u6027\u80fd\uff0c\u8fd8\u5f00\u6e90\u4e86\u6700\u5927\u591a\u8bed\u8a00\u591a\u8f6e\u504f\u597d\u6570\u636e\u96c6\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u670d\u52a1\u5177\u6709\u4e0d\u540c\u504f\u597d\u7528\u6237\u7684\u95ee\u9898\u3002", "method": "\u5f00\u5c55\u4e94\u56fd\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u4eba\u7c7b\u7814\u7a76\uff0c\u5206\u6790\u73b0\u6709\u504f\u597d\u6570\u636e\u96c6\u6536\u96c6\u65b9\u6cd5\uff0c\u63d0\u51fa\u8d1f\u76f8\u5173\u91c7\u6837\u6cd5\u5e76\u6536\u96c6\u5f00\u6e90\u6570\u636e\u96c6\u3002", "result": "\u4eba\u7c7b\u504f\u597d\u5dee\u5f02\u6bd421\u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u54cd\u5e94\u5dee\u5f02\u5927\uff1b\u73b0\u6709\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u5b66\u4e60\u4eba\u7c7b\u504f\u597d\u591a\u6837\u6027\uff1b\u8d1f\u76f8\u5173\u91c7\u6837\u6cd5\u80fd\u63d0\u5347\u5bf9\u9f50\u65b9\u6cd5\u6027\u80fd\uff1b\u6536\u96c6\u5e76\u5f00\u6e90\u6700\u5927\u591a\u8bed\u8a00\u591a\u8f6e\u504f\u597d\u6570\u636e\u96c6\u3002", "conclusion": "\u5f00\u6e90\u7684Community Alignment\u6570\u636e\u96c6\u5bf9\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u5168\u7403\u591a\u6837\u5316\u4eba\u7fa4\u7684\u6709\u6548\u6027\u6709\u4ef7\u503c\u3002"}}
{"id": "2507.09678", "pdf": "https://arxiv.org/pdf/2507.09678", "abs": "https://arxiv.org/abs/2507.09678", "authors": ["Alexander David Balinsky", "Dominik Krzeminski", "Alexander Balinsky"], "title": "Conformal Prediction for Privacy-Preserving Machine Learning", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.TH"], "comment": null, "summary": "We investigate the integration of Conformal Prediction (CP) with supervised\nlearning on deterministically encrypted data, aiming to bridge the gap between\nrigorous uncertainty quantification and privacy-preserving machine learning.\nUsing AES-encrypted variants of the MNIST dataset, we demonstrate that CP\nmethods remain effective even when applied directly in the encrypted domain,\nowing to the preservation of data exchangeability under fixed-key encryption.\nWe test traditional $p$-value-based against $e$-value-based conformal\npredictors. Our empirical evaluation reveals that models trained on\ndeterministically encrypted data retain the ability to extract meaningful\nstructure, achieving 36.88\\% test accuracy -- significantly above random\nguessing (9.56\\%) observed with per-instance encryption. Moreover,\n$e$-value-based CP achieves predictive set coverage of over 60\\% with 4.3\nloss-threshold calibration, correctly capturing the true label in 4888 out of\n5000 test cases. In contrast, the $p$-value-based CP yields smaller predictive\nsets but with reduced coverage accuracy. These findings highlight both the\npromise and limitations of CP in encrypted data settings and underscore\ncritical trade-offs between prediction set compactness and reliability. %Our\nwork sets a foundation for principled uncertainty quantification in secure,\nprivacy-aware learning systems.", "AI": {"tldr": "\u7814\u7a76\u5728\u786e\u5b9a\u6027\u52a0\u5bc6\u6570\u636e\u4e0a\u7ed3\u5408\u5171\u5f62\u9884\u6d4b\u4e0e\u76d1\u7763\u5b66\u4e60\uff0c\u5c55\u793a\u5171\u5f62\u9884\u6d4b\u5728\u52a0\u5bc6\u57df\u6709\u6548\u6027\uff0c\u5bf9\u6bd4\u4e0d\u540c\u9884\u6d4b\u5668\uff0c\u63ed\u793a\u5176\u6f5c\u529b\u4e0e\u5c40\u9650\u3002", "motivation": "\u5f25\u5408\u4e25\u683c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0e\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u4f7f\u7528AES\u52a0\u5bc6\u7684MNIST\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u57fa\u4e8ep\u503c\u548ce\u503c\u7684\u5171\u5f62\u9884\u6d4b\u5668\u3002", "result": "\u5728\u786e\u5b9a\u6027\u52a0\u5bc6\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u63d0\u53d6\u6709\u610f\u4e49\u7ed3\u6784\uff0ce\u503c\u5171\u5f62\u9884\u6d4b\u8986\u76d6\u7387\u8d8560%\uff0cp\u503c\u5171\u5f62\u9884\u6d4b\u96c6\u5c0f\u4f46\u8986\u76d6\u7387\u4f4e\u3002", "conclusion": "\u5171\u5f62\u9884\u6d4b\u5728\u52a0\u5bc6\u6570\u636e\u8bbe\u7f6e\u4e2d\u6709\u6f5c\u529b\u548c\u5c40\u9650\uff0c\u5b58\u5728\u9884\u6d4b\u96c6\u7d27\u51d1\u6027\u4e0e\u53ef\u9760\u6027\u7684\u6743\u8861\u3002"}}
{"id": "2507.09687", "pdf": "https://arxiv.org/pdf/2507.09687", "abs": "https://arxiv.org/abs/2507.09687", "authors": ["Md Mushfiqur Rahaman", "Elliot Chang", "Tasmiah Haque", "Srinjoy Das"], "title": "Post-Training Quantization of Generative and Discriminative LSTM Text Classifiers: A Study of Calibration, Class Balance, and Robustness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Text classification plays a pivotal role in edge computing applications like\nindustrial monitoring, health diagnostics, and smart assistants, where low\nlatency and high accuracy are both key requirements. Generative classifiers, in\nparticular, have been shown to exhibit robustness to out-of-distribution and\nnoisy data, which is an extremely critical consideration for deployment in such\nreal-time edge environments. However, deploying such models on edge devices\nfaces computational and memory constraints. Post Training Quantization (PTQ)\nreduces model size and compute costs without retraining, making it ideal for\nedge deployment. In this work, we present a comprehensive comparative study of\ngenerative and discriminative Long Short Term Memory (LSTM)-based text\nclassification models with PTQ using the Brevitas quantization library. We\nevaluate both types of classifier models across multiple bitwidths and assess\ntheir robustness under regular and noisy input conditions. We find that while\ndiscriminative classifiers remain robust, generative ones are more sensitive to\nbitwidth, calibration data used during PTQ, and input noise during quantized\ninference. We study the influence of class imbalance in calibration data for\nboth types of classifiers, comparing scenarios with evenly and unevenly\ndistributed class samples including their effect on weight adjustments and\nactivation profiles during PTQ. Using test statistics derived from\nnonparametric hypothesis testing, we identify that using class imbalanced data\nduring calibration introduces insufficient weight adaptation at lower bitwidths\nfor generative LSTM classifiers, thereby leading to degraded performance. This\nstudy underscores the role of calibration data in PTQ and when generative\nclassifiers succeed or fail under noise, aiding deployment in edge\nenvironments.", "AI": {"tldr": "\u5bf9\u57fa\u4e8e\u751f\u6210\u548c\u5224\u522b\u5f0fLSTM\u7684\u6587\u672c\u5206\u7c7b\u6a21\u578b\u7ed3\u5408PTQ\u8fdb\u884c\u5bf9\u6bd4\u7814\u7a76\uff0c\u8bc4\u4f30\u4e0d\u540c\u4f4d\u5bbd\u548c\u566a\u58f0\u6761\u4ef6\u4e0b\u6027\u80fd\uff0c\u7814\u7a76\u6821\u51c6\u6570\u636e\u7c7b\u522b\u4e0d\u5e73\u8861\u5f71\u54cd\uff0c\u5f3a\u8c03\u6821\u51c6\u6570\u636e\u5728PTQ\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u6587\u672c\u5206\u7c7b\u5728\u8fb9\u7f18\u8ba1\u7b97\u5e94\u7528\u6709\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u7cbe\u5ea6\u9700\u6c42\uff0c\u751f\u6210\u5206\u7c7b\u5668\u6709\u4f18\u52bf\u4f46\u8fb9\u7f18\u90e8\u7f72\u9762\u4e34\u8ba1\u7b97\u548c\u5185\u5b58\u9650\u5236\uff0cPTQ\u9002\u5408\u8fb9\u7f18\u90e8\u7f72\uff0c\u9700\u7814\u7a76\u5176\u5e94\u7528\u6548\u679c\u3002", "method": "\u4f7f\u7528Brevitas\u91cf\u5316\u5e93\u5bf9\u751f\u6210\u548c\u5224\u522b\u5f0fLSTM\u6587\u672c\u5206\u7c7b\u6a21\u578b\u7ed3\u5408PTQ\u8fdb\u884c\u5168\u9762\u5bf9\u6bd4\u7814\u7a76\uff0c\u5728\u591a\u6bd4\u7279\u4f4d\u5bbd\u4e0b\u8bc4\u4f30\uff0c\u7528\u975e\u53c2\u6570\u5047\u8bbe\u68c0\u9a8c\u7edf\u8ba1\u91cf\u5206\u6790\u3002", "result": "\u5224\u522b\u5f0f\u5206\u7c7b\u5668\u66f4\u7a33\u5065\uff0c\u751f\u6210\u5f0f\u5bf9\u91cf\u5316\u4f4d\u5bbd\u3001\u6821\u51c6\u6570\u636e\u548c\u8f93\u5165\u566a\u58f0\u66f4\u654f\u611f\uff0c\u6821\u51c6\u6570\u636e\u7c7b\u522b\u4e0d\u5e73\u8861\u4f1a\u4f7f\u751f\u6210\u5f0fLSTM\u5206\u7c7b\u5668\u5728\u4f4e\u4f4d\u5bbd\u4e0b\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u5f3a\u8c03\u6821\u51c6\u6570\u636e\u5728PTQ\u4e2d\u7684\u4f5c\u7528\uff0c\u660e\u786e\u751f\u6210\u5f0f\u5206\u7c7b\u5668\u5728\u566a\u58f0\u4e0b\u7684\u4f18\u52a3\uff0c\u6709\u52a9\u4e8e\u8fb9\u7f18\u73af\u5883\u90e8\u7f72\u3002"}}
{"id": "2507.09703", "pdf": "https://arxiv.org/pdf/2507.09703", "abs": "https://arxiv.org/abs/2507.09703", "authors": ["Roberto Molinaro", "Niall Siegenheim", "Niels Poulsen", "Jordan Dane Daubinet", "Henry Martin", "Mark Frey", "Kevin Thiart", "Alexander Jakob Dautel", "Andreas Schlueter", "Alex Grigoryev", "Bogdan Danciu", "Nikoo Ekhtiari", "Bas Steunebrink", "Leonie Wagner", "Marvin Vincent Gabler"], "title": "EPT-2 Technical Report", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present EPT-2, the latest iteration in our Earth Physics Transformer (EPT)\nfamily of foundation AI models for Earth system forecasting. EPT-2 delivers\nsubstantial improvements over its predecessor, EPT-1.5, and sets a new state of\nthe art in predicting energy-relevant variables-including 10m and 100m wind\nspeed, 2m temperature, and surface solar radiation-across the full 0-240h\nforecast horizon. It consistently outperforms leading AI weather models such as\nMicrosoft Aurora, as well as the operational numerical forecast system IFS HRES\nfrom the European Centre for Medium-Range Weather Forecasts (ECMWF). In\nparallel, we introduce a perturbation-based ensemble model of EPT-2 for\nprobabilistic forecasting, called EPT-2e. Remarkably, EPT-2e significantly\nsurpasses the ECMWF ENS mean-long considered the gold standard for medium- to\nlongrange forecasting-while operating at a fraction of the computational cost.\nEPT models, as well as third-party forecasts, are accessible via the app.jua.ai\nplatform.", "AI": {"tldr": "\u4ecb\u7ecd\u5730\u7403\u7269\u7406\u53d8\u538b\u5668\u6a21\u578bEPT - 2\u53ca\u5176\u57fa\u4e8e\u6270\u52a8\u7684\u96c6\u6210\u6a21\u578bEPT - 2e\uff0cEPT - 2\u6027\u80fd\u8d85\u524d\u4ee3\u548c\u5176\u4ed6\u6a21\u578b\uff0cEPT - 2e\u6210\u672c\u4f4e\u4e14\u8d85ECMWF ENS\u5747\u503c\u3002", "motivation": "\u63d0\u5347\u5730\u7403\u7cfb\u7edf\u9884\u6d4b\u80fd\u529b\uff0c\u5728\u5730\u7403\u7cfb\u7edf\u9884\u6d4b\u4e2d\u53d6\u5f97\u66f4\u597d\u8868\u73b0\u3002", "method": "\u5f00\u53d1EPT - 2\u6a21\u578b\uff0c\u5f15\u5165\u57fa\u4e8e\u6270\u52a8\u7684\u96c6\u6210\u6a21\u578bEPT - 2e\u3002", "result": "EPT - 2\u5728\u9884\u6d4b\u80fd\u6e90\u76f8\u5173\u53d8\u91cf\u4e0a\u8d85EPT - 1.5\u3001Aurora\u548cIFS HRES\uff1bEPT - 2e\u663e\u8457\u8d85ECMWF ENS\u5747\u503c\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "conclusion": "EPT - 2\u548cEPT - 2e\u5728\u5730\u7403\u7cfb\u7edf\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u5173\u6a21\u578b\u53ef\u901a\u8fc7app.jua.ai\u5e73\u53f0\u83b7\u53d6\u3002"}}
{"id": "2507.09732", "pdf": "https://arxiv.org/pdf/2507.09732", "abs": "https://arxiv.org/abs/2507.09732", "authors": ["Sara Si-Moussi", "Stephan Hennekens", "Sander Mucher", "Stan Los", "Wilfried Thuiller"], "title": "Continental scale habitat modelling with artificial intelligence and multimodal earth observation", "categories": ["cs.LG", "q-bio.PE", "stat.AP", "68T05, 62H35", "I.5.4; I.2.6"], "comment": null, "summary": "Habitats integrate the abiotic conditions and biophysical structures that\nsupport biodiversity and sustain nature's contributions to people. As these\necosystems face mounting pressure from human activities, accurate,\nhigh-resolution habitat maps are essential for effective conservation and\nrestoration. Yet current maps often fall short in thematic or spatial\nresolution because they must (1) model several mutually exclusive habitat types\nthat co-occur across landscapes and (2) cope with severe class imbalance that\ncomplicate multi-class training. Here, we evaluated how high-resolution remote\nsensing (RS) data and Artificial Intelligence (AI) tools can improve habitat\nclassification over large geographic extents at fine thematic resolution. Using\nvegetation plots from the European Vegetation Archive, we modelled Level 3\nEUNIS habitats across Europe and assessed multiple modelling strategies against\nindependent validation datasets. Strategies that exploited the hierarchical\nnature of habitat nomenclatures resolved classification ambiguities, especially\nin fragmented landscapes. Integrating multi-spectral (MSI) and synthetic\naperture radar (SAR) imagery, particularly through Earth Observation Foundation\nmodels, enhanced within-formation discrimination and overall performance.\nFinally, ensemble machine learning that corrects class imbalance boosted\naccuracy further. Our methodological framework is transferable beyond Europe\nand adaptable to other classification systems. Future research should advance\ntemporal modelling of dynamic habitats, extend to habitat segmentation and\nquality assessment, and exploit next-generation EO data paired with\nhigher-quality in-situ observations.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u9ad8\u5206\u8fa8\u7387\u9065\u611f\u6570\u636e\u548c\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u6539\u8fdb\u6b27\u6d32\u5927\u8303\u56f4\u6816\u606f\u5730\u5206\u7c7b\uff0c\u63d0\u51fa\u65b9\u6cd5\u6846\u67b6\u5e76\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4eba\u7c7b\u6d3b\u52a8\u4f7f\u751f\u6001\u7cfb\u7edf\u538b\u529b\u589e\u5927\uff0c\u73b0\u6709\u6816\u606f\u5730\u5730\u56fe\u5728\u4e3b\u9898\u6216\u7a7a\u95f4\u5206\u8fa8\u7387\u4e0a\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5229\u7528\u6b27\u6d32\u690d\u88ab\u6863\u6848\u7684\u690d\u88ab\u6837\u5730\uff0c\u5bf9\u6b27\u6d32\u4e09\u7ea7EUNIS\u6816\u606f\u5730\u5efa\u6a21\uff0c\u8bc4\u4f30\u591a\u79cd\u5efa\u6a21\u7b56\u7565\uff0c\u5229\u7528\u5206\u5c42\u547d\u540d\u3001\u6574\u5408\u591a\u5149\u8c31\u548c\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u56fe\u50cf\u3001\u91c7\u7528\u96c6\u6210\u673a\u5668\u5b66\u4e60\u7ea0\u6b63\u7c7b\u522b\u4e0d\u5e73\u8861\u3002", "result": "\u5229\u7528\u6816\u606f\u5730\u547d\u540d\u5c42\u6b21\u89e3\u51b3\u5206\u7c7b\u6a21\u7cca\u95ee\u9898\uff0c\u6574\u5408\u56fe\u50cf\u589e\u5f3a\u4fe1\u606f\u8fa8\u522b\u548c\u6574\u4f53\u6027\u80fd\uff0c\u96c6\u6210\u673a\u5668\u5b66\u4e60\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u65b9\u6cd5\u6846\u67b6\u53ef\u8f6c\u79fb\u4e14\u9002\u5e94\u5176\u4ed6\u5206\u7c7b\u7cfb\u7edf\uff0c\u672a\u6765\u5e94\u63a8\u8fdb\u52a8\u6001\u6816\u606f\u5730\u65f6\u95f4\u5efa\u6a21\u7b49\u7814\u7a76\u3002"}}
{"id": "2507.09010", "pdf": "https://arxiv.org/pdf/2507.09010", "abs": "https://arxiv.org/abs/2507.09010", "authors": ["Chun-Ting Chen", "HanGyeol Mun", "Jian Meng", "Mohamed S. Abdelfattah", "Jae-sun Seo"], "title": "Hybrid Systolic Array Accelerator with Optimized Dataflow for Edge Large Language Model Inference", "categories": ["cs.AR", "cs.AI"], "comment": "Accepted as a conference paper at the 2025 IEEE/ACM International\n  Symposium on Low Power Electronics and Design (ISLPED)", "summary": "Edge inference for large language models (LLM) offers secure, low-latency,\nand cost-effective inference solutions. We emphasize that an edge accelerator\nshould achieve high area efficiency and minimize external memory access (EMA)\nduring the memory-bound decode stage, while maintaining high energy efficiency\nduring the compute intensive prefill stage. This paper proposes an edge LLM\ninference accelerator featuring a hybrid systolic array (HSA) architecture that\noptimizes inference efficiency in both stages. To further reduce EMA, we adopt\nMXINT4 weight quantization and propose an optimized dataflow tailored for HSA,\nensuring negligible dequantization overhead and achieving 100% hardware\nutilization with minimal accuracy loss under edge DRAM bandwidth constraints.\nFor non-linear operations, we incorporate optimized root mean square\nnormalization (RMSNorm) and rotary position embedding (RoPE) units, reducing\ntheir latency, area, and memory access overhead while enabling end-to-end\ninference on our accelerator. Our solution achieves 247/117 (token/s/mm2) while\nrunning a 1.3B LLM on long-input/long-output scenarios, providing >2.45x/13.5x\nimprovement over existing approaches, while maintaining superior energy\nefficiency in token generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8fb9\u7f18\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u52a0\u901f\u5668\uff0c\u91c7\u7528\u6df7\u5408\u8109\u52a8\u9635\u5217\u67b6\u6784\uff0c\u7ed3\u5408\u91cf\u5316\u548c\u4f18\u5316\u6570\u636e\u6d41\u7b49\u65b9\u6cd5\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u8fb9\u7f18\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9700\u8fb9\u7f18\u52a0\u901f\u5668\u5728\u89e3\u7801\u548c\u9884\u586b\u5145\u9636\u6bb5\u5206\u522b\u5b9e\u73b0\u9ad8\u9762\u79ef\u6548\u7387\u3001\u4f4e\u5916\u90e8\u5185\u5b58\u8bbf\u95ee\u548c\u9ad8\u80fd\u91cf\u6548\u7387\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u8109\u52a8\u9635\u5217\uff08HSA\uff09\u67b6\u6784\uff0c\u91c7\u7528MXINT4\u6743\u91cd\u91cf\u5316\u548c\u4f18\u5316\u6570\u636e\u6d41\uff0c\u52a0\u5165\u4f18\u5316\u7684RMSNorm\u548cRoPE\u5355\u5143\u3002", "result": "\u8fd0\u884c1.3B\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u8f93\u5165/\u957f\u8f93\u51fa\u573a\u666f\u4e0b\u8fbe\u5230247/117 (token/s/mm2)\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347>2.45x/13.5x\uff0c\u4e14\u5728\u4ee4\u724c\u751f\u6210\u4e0a\u4fdd\u6301\u9ad8\u80fd\u91cf\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u8fb9\u7f18\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u52a0\u901f\u5668\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.09733", "pdf": "https://arxiv.org/pdf/2507.09733", "abs": "https://arxiv.org/abs/2507.09733", "authors": ["Bradley Camburn"], "title": "Universal Physics Simulation: A Foundational Diffusion Approach", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07, 65M06, 78M34", "I.2.6; I.4.8; J.2"], "comment": "10 pages, 3 figures. Foundational AI model for universal physics\n  simulation using sketch-guided diffusion transformers. Achieves SSIM > 0.8 on\n  electromagnetic field generation without requiring a priori physics encoding", "summary": "We present the first foundational AI model for universal physics simulation\nthat learns physical laws directly from boundary-condition data without\nrequiring a priori equation encoding. Traditional physics-informed neural\nnetworks (PINNs) and finite-difference methods necessitate explicit\nmathematical formulation of governing equations, fundamentally limiting their\ngeneralizability and discovery potential. Our sketch-guided diffusion\ntransformer approach reimagines computational physics by treating simulation as\na conditional generation problem, where spatial boundary conditions guide the\nsynthesis of physically accurate steady-state solutions.\n  By leveraging enhanced diffusion transformer architectures with novel spatial\nrelationship encoding, our model achieves direct boundary-to-equilibrium\nmapping and is generalizable to diverse physics domains. Unlike sequential\ntime-stepping methods that accumulate errors over iterations, our approach\nbypasses temporal integration entirely, directly generating steady-state\nsolutions with SSIM > 0.8 while maintaining sub-pixel boundary accuracy. Our\ndata-informed approach enables physics discovery through learned\nrepresentations analyzable via Layer-wise Relevance Propagation (LRP),\nrevealing emergent physical relationships without predetermined mathematical\nconstraints. This work represents a paradigm shift from AI-accelerated physics\nto AI-discovered physics, establishing the first truly universal physics\nsimulation framework.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u901a\u7528\u7269\u7406\u6a21\u62df\u57fa\u7840AI\u6a21\u578b\uff0c\u53ef\u76f4\u63a5\u4ece\u8fb9\u754c\u6761\u4ef6\u6570\u636e\u5b66\u4e60\u7269\u7406\u5b9a\u5f8b\uff0c\u65e0\u9700\u5148\u9a8c\u65b9\u7a0b\u7f16\u7801\uff0c\u5177\u6709\u6cdb\u5316\u6027\u548c\u7269\u7406\u53d1\u73b0\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u548c\u6709\u9650\u5dee\u5206\u65b9\u6cd5\u9700\u660e\u786e\u6570\u5b66\u516c\u5f0f\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u6027\u548c\u53d1\u73b0\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u8349\u56fe\u5f15\u5bfc\u7684\u6269\u6563\u53d8\u538b\u5668\u65b9\u6cd5\uff0c\u5c06\u6a21\u62df\u89c6\u4e3a\u6761\u4ef6\u751f\u6210\u95ee\u9898\uff0c\u5229\u7528\u589e\u5f3a\u7684\u6269\u6563\u53d8\u538b\u5668\u67b6\u6784\u548c\u65b0\u7684\u7a7a\u95f4\u5173\u7cfb\u7f16\u7801\u3002", "result": "\u5b9e\u73b0\u76f4\u63a5\u7684\u8fb9\u754c\u5230\u5e73\u8861\u6620\u5c04\uff0c\u6cdb\u5316\u5230\u4e0d\u540c\u7269\u7406\u9886\u57df\uff0c\u76f4\u63a5\u751f\u6210\u7a33\u6001\u89e3\uff0cSSIM>0.8\u4e14\u4fdd\u6301\u4e9a\u50cf\u7d20\u8fb9\u754c\u7cbe\u5ea6\uff0c\u53ef\u901a\u8fc7LRP\u5206\u6790\u63ed\u793a\u7269\u7406\u5173\u7cfb\u3002", "conclusion": "\u5b9e\u73b0\u4e86\u4eceAI\u52a0\u901f\u7269\u7406\u5230AI\u53d1\u73b0\u7269\u7406\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5efa\u7acb\u4e86\u9996\u4e2a\u771f\u6b63\u901a\u7528\u7684\u7269\u7406\u6a21\u62df\u6846\u67b6\u3002"}}
{"id": "2507.09753", "pdf": "https://arxiv.org/pdf/2507.09753", "abs": "https://arxiv.org/abs/2507.09753", "authors": ["Ewa M. Nowara", "Joshua Rackers", "Patricia Suriana", "Pan Kessel", "Max Shen", "Andrew Martin Watkins", "Michael Maser"], "title": "Do we need equivariant models for molecule generation?", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep generative models are increasingly used for molecular discovery, with\nmost recent approaches relying on equivariant graph neural networks (GNNs)\nunder the assumption that explicit equivariance is essential for generating\nhigh-quality 3D molecules. However, these models are complex, difficult to\ntrain, and scale poorly.\n  We investigate whether non-equivariant convolutional neural networks (CNNs)\ntrained with rotation augmentations can learn equivariance and match the\nperformance of equivariant models. We derive a loss decomposition that\nseparates prediction error from equivariance error, and evaluate how model\nsize, dataset size, and training duration affect performance across denoising,\nmolecule generation, and property prediction. To our knowledge, this is the\nfirst study to analyze learned equivariance in generative tasks.", "AI": {"tldr": "\u7814\u7a76\u975e\u7b49\u53d8CNN\u7ecf\u65cb\u8f6c\u589e\u5f3a\u8bad\u7ec3\u80fd\u5426\u5b66\u4e60\u7b49\u53d8\u6027\u5e76\u5339\u914d\u7b49\u53d8\u6a21\u578b\u6027\u80fd\uff0c\u8fdb\u884c\u635f\u5931\u5206\u89e3\u8bc4\u4f30\u591a\u56e0\u7d20\u5bf9\u6027\u80fd\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u7b49\u53d8GNN\u7684\u5206\u5b50\u53d1\u73b0\u6a21\u578b\u590d\u6742\u3001\u96be\u8bad\u7ec3\u4e14\u6269\u5c55\u6027\u5dee\uff0c\u63a2\u7a76\u975e\u7b49\u53d8CNN\u5b66\u4e60\u7b49\u53d8\u6027\u7684\u53ef\u80fd\u6027\u3002", "method": "\u63a8\u5bfc\u635f\u5931\u5206\u89e3\u4ee5\u5206\u79bb\u9884\u6d4b\u8bef\u5dee\u548c\u7b49\u53d8\u8bef\u5dee\uff0c\u8bc4\u4f30\u6a21\u578b\u5927\u5c0f\u3001\u6570\u636e\u96c6\u5927\u5c0f\u548c\u8bad\u7ec3\u65f6\u957f\u5bf9\u53bb\u566a\u3001\u5206\u5b50\u751f\u6210\u548c\u5c5e\u6027\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u539f\u6587\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u539f\u6587\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2507.09754", "pdf": "https://arxiv.org/pdf/2507.09754", "abs": "https://arxiv.org/abs/2507.09754", "authors": ["Aakash Tripathi", "Ian E. Nielsen", "Muhammad Umer", "Ravi P. Ramachandran", "Ghulam Rasool"], "title": "Explainable AI in Genomics: Transcription Factor Binding Site Prediction with Mixture of Experts", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Transcription Factor Binding Site (TFBS) prediction is crucial for\nunderstanding gene regulation and various biological processes. This study\nintroduces a novel Mixture of Experts (MoE) approach for TFBS prediction,\nintegrating multiple pre-trained Convolutional Neural Network (CNN) models,\neach specializing in different TFBS patterns. We evaluate the performance of\nour MoE model against individual expert models on both in-distribution and\nout-of-distribution (OOD) datasets, using six randomly selected transcription\nfactors (TFs) for OOD testing. Our results demonstrate that the MoE model\nachieves competitive or superior performance across diverse TF binding sites,\nparticularly excelling in OOD scenarios. The Analysis of Variance (ANOVA)\nstatistical test confirms the significance of these performance differences.\nAdditionally, we introduce ShiftSmooth, a novel attribution mapping technique\nthat provides more robust model interpretability by considering small shifts in\ninput sequences. Through comprehensive explainability analysis, we show that\nShiftSmooth offers superior attribution for motif discovery and localization\ncompared to traditional Vanilla Gradient methods. Our work presents an\nefficient, generalizable, and interpretable solution for TFBS prediction,\npotentially enabling new discoveries in genome biology and advancing our\nunderstanding of transcriptional regulation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8eTFBS\u9884\u6d4b\u7684MoE\u65b9\u6cd5\u548c\u7528\u4e8e\u6a21\u578b\u89e3\u91ca\u7684ShiftSmooth\u6280\u672f\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u8868\u73b0\u826f\u597d\uff0c\u4e3aTFBS\u9884\u6d4b\u63d0\u4f9b\u9ad8\u6548\u3001\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u8f6c\u5f55\u56e0\u5b50\u7ed3\u5408\u4f4d\u70b9\uff08TFBS\uff09\u9884\u6d4b\u5bf9\u7406\u89e3\u57fa\u56e0\u8c03\u63a7\u548c\u751f\u7269\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u9ad8\u6548\u51c6\u786e\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u65b9\u6cd5\u96c6\u6210\u591a\u4e2a\u9884\u8bad\u7ec3CNN\u6a21\u578b\u8fdb\u884cTFBS\u9884\u6d4b\uff0c\u63d0\u51faShiftSmooth\u5f52\u56e0\u6620\u5c04\u6280\u672f\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "result": "MoE\u6a21\u578b\u5728\u4e0d\u540cTF\u7ed3\u5408\u4f4d\u70b9\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u5c24\u5176\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u573a\u666f\u51fa\u8272\uff0cANOVA\u68c0\u9a8c\u8bc1\u5b9e\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff1bShiftSmooth\u5728\u57fa\u5e8f\u53d1\u73b0\u548c\u5b9a\u4f4d\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u5de5\u4f5c\u4e3aTFBS\u9884\u6d4b\u63d0\u4f9b\u9ad8\u6548\u3001\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u57fa\u56e0\u7ec4\u751f\u7269\u5b66\u65b0\u53d1\u73b0\u548c\u8f6c\u5f55\u8c03\u63a7\u7406\u89e3\u3002"}}
{"id": "2507.09028", "pdf": "https://arxiv.org/pdf/2507.09028", "abs": "https://arxiv.org/abs/2507.09028", "authors": ["Amgad Muneer", "Muhammad Waqas", "Maliazurina B Saad", "Eman Showkatian", "Rukhmini Bandyopadhyay", "Hui Xu", "Wentao Li", "Joe Y Chang", "Zhongxing Liao", "Cara Haymaker", "Luisa Solis Soto", "Carol C Wu", "Natalie I Vokes", "Xiuning Le", "Lauren A Byers", "Don L Gibbons", "John V Heymach", "Jianjun Zhang", "Jia Wu"], "title": "From Classical Machine Learning to Emerging Foundation Models: Review on Multimodal Data Integration for Cancer Research", "categories": ["q-bio.QM", "cs.AI"], "comment": "6 figures, 3 tables", "summary": "Cancer research is increasingly driven by the integration of diverse data\nmodalities, spanning from genomics and proteomics to imaging and clinical\nfactors. However, extracting actionable insights from these vast and\nheterogeneous datasets remains a key challenge. The rise of foundation models\n(FMs) -- large deep-learning models pretrained on extensive amounts of data\nserving as a backbone for a wide range of downstream tasks -- offers new\navenues for discovering biomarkers, improving diagnosis, and personalizing\ntreatment. This paper presents a comprehensive review of widely adopted\nintegration strategies of multimodal data to assist advance the computational\napproaches for data-driven discoveries in oncology. We examine emerging trends\nin machine learning (ML) and deep learning (DL), including methodological\nframeworks, validation protocols, and open-source resources targeting cancer\nsubtype classification, biomarker discovery, treatment guidance, and outcome\nprediction. This study also comprehensively covers the shift from traditional\nML to FMs for multimodal integration. We present a holistic view of recent FMs\nadvancements and challenges faced during the integration of multi-omics with\nadvanced imaging data. We identify the state-of-the-art FMs, publicly available\nmulti-modal repositories, and advanced tools and methods for data integration.\nWe argue that current state-of-the-art integrative methods provide the\nessential groundwork for developing the next generation of large-scale,\npre-trained models poised to further revolutionize oncology. To the best of our\nknowledge, this is the first review to systematically map the transition from\nconventional ML to advanced FM for multimodal data integration in oncology,\nwhile also framing these developments as foundational for the forthcoming era\nof large-scale AI models in cancer research.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u80bf\u7624\u5b66\u4e2d\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u7b56\u7565\uff0c\u63a2\u8ba8\u4ece\u4f20\u7edfML\u5230FMs\u8f6c\u53d8\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u4ece\u6d77\u91cf\u5f02\u6784\u764c\u75c7\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u6548\u4fe1\u606f\u662f\u6311\u6218\uff0c\u57fa\u7840\u6a21\u578b\u4e3a\u80bf\u7624\u7814\u7a76\u63d0\u4f9b\u65b0\u9014\u5f84\uff0c\u9700\u7efc\u8ff0\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u7b56\u7565\u63a8\u52a8\u8ba1\u7b97\u65b9\u6cd5\u53d1\u5c55\u3002", "method": "\u56de\u987e\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b0\u5174\u8d8b\u52bf\uff0c\u5305\u62ec\u65b9\u6cd5\u6846\u67b6\u3001\u9a8c\u8bc1\u534f\u8bae\u548c\u5f00\u6e90\u8d44\u6e90\uff0c\u63a2\u8ba8\u4ece\u4f20\u7edfML\u5230FMs\u8f6c\u53d8\uff0c\u5206\u6790\u591a\u7ec4\u5b66\u4e0e\u9ad8\u7ea7\u6210\u50cf\u6570\u636e\u6574\u5408\u95ee\u9898\u3002", "result": "\u786e\u5b9a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7840\u6a21\u578b\u3001\u516c\u5f00\u53ef\u7528\u7684\u591a\u6a21\u6001\u6570\u636e\u5e93\u3001\u6570\u636e\u6574\u5408\u7684\u5148\u8fdb\u5de5\u5177\u548c\u65b9\u6cd5\u3002", "conclusion": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6574\u5408\u65b9\u6cd5\u4e3a\u4e0b\u4e00\u4ee3\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5960\u5b9a\u57fa\u7840\uff0c\u8be5\u7efc\u8ff0\u9996\u6b21\u7cfb\u7edf\u68b3\u7406\u80bf\u7624\u5b66\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u4ece\u4f20\u7edfML\u5230\u9ad8\u7ea7FM\u7684\u8f6c\u53d8\u3002"}}
{"id": "2507.09766", "pdf": "https://arxiv.org/pdf/2507.09766", "abs": "https://arxiv.org/abs/2507.09766", "authors": ["Mohamadreza Akbari Pour", "Ali Ghasemzadeh", "MohamadAli Bijarchi", "Mohammad Behshad Shafii"], "title": "Toward accurate RUL and SOH estimation using reinforced graph-based PINNs enhanced with dynamic weights", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate estimation of Remaining Useful Life (RUL) and State of Health (SOH)\nis essential for Prognostics and Health Management (PHM) across a wide range of\nindustrial applications. We propose a novel framework -- Reinforced Graph-Based\nPhysics-Informed Neural Networks Enhanced with Dynamic Weights (RGPD) -- that\ncombines physics-based supervision with advanced spatio-temporal learning.\nGraph Convolutional Recurrent Networks (GCRNs) embed graph-convolutional\nfilters within recurrent units to capture how node representations evolve over\ntime. Graph Attention Convolution (GATConv) leverages a self-attention\nmechanism to compute learnable, edge-wise attention coefficients, dynamically\nweighting neighbor contributions for adaptive spatial aggregation. A Soft\nActor-Critic (SAC) module is positioned between the Temporal Attention Unit\n(TAU) and GCRN to further improve the spatio-temporal learning. This module\nimproves attention and prediction accuracy by dynamically scaling hidden\nrepresentations to minimize noise and highlight informative features. To\nidentify the most relevant physical constraints in each area, Q-learning agents\ndynamically assign weights to physics-informed loss terms, improving\ngeneralization across real-time industrial systems and reducing the need for\nmanual tuning. In both RUL and SOH estimation tasks, the proposed method\nconsistently outperforms state-of-the-art models, demonstrating strong\nrobustness and predictive accuracy across varied degradation patterns across\nthree diverse industrial benchmark datasets.", "AI": {"tldr": "\u63d0\u51faRGPD\u6846\u67b6\u7528\u4e8e\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u548c\u5065\u5eb7\u72b6\u6001\uff08SOH\uff09\u4f30\u8ba1\uff0c\u7ed3\u5408\u7269\u7406\u76d1\u7763\u4e0e\u65f6\u7a7a\u5b66\u4e60\uff0c\u5728\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u51c6\u786e\u4f30\u8ba1RUL\u548cSOH\u5bf9\u9884\u6d4b\u4e0e\u5065\u5eb7\u7ba1\u7406\uff08PHM\uff09\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u66f4\u4f18\u65b9\u6cd5\u3002", "method": "\u63d0\u51faRGPD\u6846\u67b6\uff0c\u7ed3\u5408GCRN\u3001GATConv\u3001SAC\u6a21\u5757\u8fdb\u884c\u65f6\u7a7a\u5b66\u4e60\uff0c\u7528Q - learning\u4ee3\u7406\u52a8\u6001\u5206\u914d\u7269\u7406\u4fe1\u606f\u635f\u5931\u9879\u6743\u91cd\u3002", "result": "\u5728RUL\u548cSOH\u4f30\u8ba1\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u5de5\u4e1a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u6709\u5f3a\u9c81\u68d2\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "RGPD\u6846\u67b6\u5728RUL\u548cSOH\u4f30\u8ba1\u65b9\u9762\u6709\u6548\uff0c\u80fd\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u51cf\u5c11\u624b\u52a8\u8c03\u6574\u9700\u6c42\u3002"}}
{"id": "2507.09768", "pdf": "https://arxiv.org/pdf/2507.09768", "abs": "https://arxiv.org/abs/2507.09768", "authors": ["Kenny Falk\u00e6r Olsen. Mads \u00d8stergaard", "Karl Ulb\u00e6k", "S\u00f8ren F\u00f8ns Nielsen", "Rasmus Malik H\u00f8egh Lindrup", "Bj\u00f8rn Sand Jensen", "Morten M\u00f8rup"], "title": "Knowing When to Quit: Probabilistic Early Exits for Speech Separation", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "In recent years, deep learning-based single-channel speech separation has\nimproved considerably, in large part driven by increasingly compute- and\nparameter-efficient neural network architectures. Most such architectures are,\nhowever, designed with a fixed compute and parameter budget, and consequently\ncannot scale to varying compute demands or resources, which limits their use in\nembedded and heterogeneous devices such as mobile phones and hearables. To\nenable such use-cases we design a neural network architecture for speech\nseparation capable of early-exit, and we propose an uncertainty-aware\nprobabilistic framework to jointly model the clean speech signal and error\nvariance which we use to derive probabilistic early-exit conditions in terms of\ndesired signal-to-noise ratios. We evaluate our methods on both speech\nseparation and enhancement tasks, and we show that a single early-exit model\ncan be competitive with state-of-the-art models trained at many compute and\nparameter budgets. Our framework enables fine-grained dynamic compute-scaling\nof speech separation networks while achieving state-of-the-art performance and\ninterpretable exit conditions.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u5177\u6709\u65e9\u671f\u9000\u51fa\u80fd\u529b\u7684\u8bed\u97f3\u5206\u79bb\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6982\u7387\u6846\u67b6\uff0c\u53ef\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u52a8\u6001\u8ba1\u7b97\u7f29\u653e\uff0c\u6027\u80fd\u8fbe\u6700\u4f18\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5355\u901a\u9053\u8bed\u97f3\u5206\u79bb\u67b6\u6784\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u8ba1\u7b97\u9700\u6c42\u548c\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u5728\u5d4c\u5165\u5f0f\u548c\u5f02\u6784\u8bbe\u5907\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u8bbe\u8ba1\u5177\u6709\u65e9\u671f\u9000\u51fa\u80fd\u529b\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6982\u7387\u6846\u67b6\uff0c\u63a8\u5bfc\u57fa\u4e8e\u6240\u9700\u4fe1\u566a\u6bd4\u7684\u6982\u7387\u65e9\u671f\u9000\u51fa\u6761\u4ef6\u3002", "result": "\u5728\u8bed\u97f3\u5206\u79bb\u548c\u589e\u5f3a\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u5355\u4e2a\u65e9\u671f\u9000\u51fa\u6a21\u578b\u53ef\u4e0e\u5728\u4e0d\u540c\u8ba1\u7b97\u548c\u53c2\u6570\u9884\u7b97\u4e0b\u8bad\u7ec3\u7684\u6700\u4f18\u6a21\u578b\u7ade\u4e89\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u5b9e\u73b0\u8bed\u97f3\u5206\u79bb\u7f51\u7edc\u7684\u7ec6\u7c92\u5ea6\u52a8\u6001\u8ba1\u7b97\u7f29\u653e\uff0c\u8fbe\u5230\u6700\u4f18\u6027\u80fd\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u9000\u51fa\u6761\u4ef6\u3002"}}
{"id": "2507.09785", "pdf": "https://arxiv.org/pdf/2507.09785", "abs": "https://arxiv.org/abs/2507.09785", "authors": ["Zhonglin Cao", "Mario Geiger", "Allan dos Santos Costa", "Danny Reidenbach", "Karsten Kreis", "Tomas Geffner", "Franco Pellegrini", "Guoqing Zhou", "Emine Kucukbenli"], "title": "Efficient Molecular Conformer Generation with SO(3)-Averaged Flow Matching and Reflow", "categories": ["cs.LG", "physics.chem-ph"], "comment": "ICML 2025 poster", "summary": "Fast and accurate generation of molecular conformers is desired for\ndownstream computational chemistry and drug discovery tasks. Currently,\ntraining and sampling state-of-the-art diffusion or flow-based models for\nconformer generation require significant computational resources. In this work,\nwe build upon flow-matching and propose two mechanisms for accelerating\ntraining and inference of generative models for 3D molecular conformer\ngeneration. For fast training, we introduce the SO(3)-Averaged Flow training\nobjective, which leads to faster convergence to better generation quality\ncompared to conditional optimal transport flow or Kabsch-aligned flow. We\ndemonstrate that models trained using SO(3)-Averaged Flow can reach\nstate-of-the-art conformer generation quality. For fast inference, we show that\nthe reflow and distillation methods of flow-based models enable few-steps or\neven one-step molecular conformer generation with high quality. The training\ntechniques proposed in this work show a path towards highly efficient molecular\nconformer generation with flow-based models.", "AI": {"tldr": "\u63d0\u51fa\u52a0\u901f3D\u5206\u5b50\u6784\u8c61\u751f\u6210\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u673a\u5236\uff0c\u5b9e\u73b0\u9ad8\u6548\u6784\u8c61\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6216\u6d41\u7684\u6784\u8c61\u751f\u6210\u6a21\u578b\u8bad\u7ec3\u548c\u91c7\u6837\u9700\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u671f\u671b\u5feb\u901f\u51c6\u786e\u751f\u6210\u5206\u5b50\u6784\u8c61\u3002", "method": "\u57fa\u4e8e\u6d41\u5339\u914d\uff0c\u63d0\u51faSO(3)-Averaged Flow\u8bad\u7ec3\u76ee\u6807\u52a0\u901f\u8bad\u7ec3\uff0c\u7528\u6d41\u6a21\u578b\u7684\u56de\u6d41\u548c\u84b8\u998f\u65b9\u6cd5\u5b9e\u73b0\u5feb\u901f\u63a8\u7406\u3002", "result": "SO(3)-Averaged Flow\u8bad\u7ec3\u7684\u6a21\u578b\u8fbe\u5230\u5148\u8fdb\u6784\u8c61\u751f\u6210\u8d28\u91cf\uff0c\u56de\u6d41\u548c\u84b8\u998f\u65b9\u6cd5\u5b9e\u73b0\u5c11\u6b65\u751a\u81f3\u4e00\u6b65\u9ad8\u8d28\u91cf\u6784\u8c61\u751f\u6210\u3002", "conclusion": "\u6240\u63d0\u8bad\u7ec3\u6280\u672f\u4e3a\u57fa\u4e8e\u6d41\u6a21\u578b\u7684\u9ad8\u6548\u5206\u5b50\u6784\u8c61\u751f\u6210\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2507.09037", "pdf": "https://arxiv.org/pdf/2507.09037", "abs": "https://arxiv.org/abs/2507.09037", "authors": ["Bharadwaj Ravichandran", "David Joy", "Paul Elliott", "Brian Hu", "Jadie Adams", "Christopher Funk", "Emily Veenhuis", "Anthony Hoogs", "Arslan Basharat"], "title": "ALIGN: Prompt-based Attribute Alignment for Reliable, Responsible, and Personalized LLM-based Decision-Making", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages total (including appendix), ICML 2025 Workshop on Reliable\n  and Responsible Foundation Models", "summary": "Large language models (LLMs) are increasingly being used as decision aids.\nHowever, users have diverse values and preferences that can affect their\ndecision-making, which requires novel methods for LLM alignment and\npersonalization. Existing LLM comparison tools largely focus on benchmarking\ntasks, such as knowledge-based question answering. In contrast, our proposed\nALIGN system focuses on dynamic personalization of LLM-based decision-makers\nthrough prompt-based alignment to a set of fine-grained attributes. Key\nfeatures of our system include robust configuration management, structured\noutput generation with reasoning, and several algorithm implementations with\nswappable LLM backbones, enabling different types of analyses. Our user\ninterface enables a qualitative, side-by-side comparison of LLMs and their\nalignment to various attributes, with a modular backend for easy algorithm\nintegration. Additionally, we perform a quantitative analysis comparing\nalignment approaches in two different domains: demographic alignment for public\nopinion surveys and value alignment for medical triage decision-making. The\nentire ALIGN framework is open source and will enable new research on reliable,\nresponsible, and personalized LLM-based decision-makers.", "AI": {"tldr": "\u63d0\u51faALIGN\u7cfb\u7edf\u7528\u4e8eLLM\u52a8\u6001\u4e2a\u6027\u5316\u51b3\u7b56\u8f85\u52a9\uff0c\u6709\u591a\u79cd\u7279\u6027\uff0c\u8fdb\u884c\u4e24\u9886\u57df\u5b9a\u91cf\u5206\u6790\u4e14\u6846\u67b6\u5f00\u6e90\u3002", "motivation": "\u7528\u6237\u4ef7\u503c\u89c2\u548c\u504f\u597d\u591a\u6837\u5f71\u54cd\u51b3\u7b56\uff0c\u73b0\u6709LLM\u6bd4\u8f83\u5de5\u5177\u591a\u5173\u6ce8\u57fa\u51c6\u4efb\u52a1\uff0c\u9700\u65b0\u7684LLM\u5bf9\u9f50\u548c\u4e2a\u6027\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51faALIGN\u7cfb\u7edf\uff0c\u901a\u8fc7\u57fa\u4e8e\u63d0\u793a\u7684\u5bf9\u9f50\u5b9e\u73b0LLM\u51b3\u7b56\u8f85\u52a9\u52a8\u6001\u4e2a\u6027\u5316\uff0c\u5177\u5907\u914d\u7f6e\u7ba1\u7406\u7b49\u7279\u6027\uff0c\u6709\u7528\u6237\u754c\u9762\u548c\u6a21\u5757\u5316\u540e\u7aef\u3002", "result": "\u5728\u6c11\u610f\u8c03\u67e5\u4eba\u53e3\u7edf\u8ba1\u5bf9\u9f50\u548c\u533b\u7597\u5206\u8bca\u51b3\u7b56\u4ef7\u503c\u5bf9\u9f50\u4e24\u4e2a\u9886\u57df\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\u3002", "conclusion": "ALIGN\u6846\u67b6\u5f00\u6e90\uff0c\u5c06\u63a8\u52a8\u53ef\u9760\u3001\u8d1f\u8d23\u548c\u4e2a\u6027\u5316\u7684\u57fa\u4e8eLLM\u7684\u51b3\u7b56\u8f85\u52a9\u7814\u7a76\u3002"}}
{"id": "2507.09786", "pdf": "https://arxiv.org/pdf/2507.09786", "abs": "https://arxiv.org/abs/2507.09786", "authors": ["Junaid Iqbal Khan"], "title": "Leveraging Distribution Matching to Make Approximate Machine Unlearning Faster", "categories": ["cs.LG"], "comment": "10 pages, 4 figures, 4 tables", "summary": "Approximate machine unlearning (AMU) enables models to `forget' specific\ntraining data through specialized fine-tuning on a retained dataset subset.\nHowever, processing this retained subset still dominates computational runtime,\nwhile reductions of epochs also remain a challenge. We propose two\ncomplementary methods to accelerate classification-oriented AMU. First,\n\\textbf{Blend}, a novel distribution-matching dataset condensation (DC), merges\nvisually similar images with shared blend-weights to significantly reduce the\nretained set size. It operates with minimal pre-processing overhead and is\norders of magnitude faster than state-of-the-art DC methods. Second, our\nloss-centric method, \\textbf{Accelerated-AMU (A-AMU)}, augments the unlearning\nobjective to quicken convergence. A-AMU achieves this by combining a steepened\nprimary loss to expedite forgetting with a novel, differentiable regularizer\nthat matches the loss distributions of forgotten and in-distribution unseen\ndata. Our extensive experiments demonstrate that this dual approach of data and\nloss-centric optimization dramatically reduces end-to-end unlearning latency\nacross both single and multi-round scenarios, all while preserving model\nutility and privacy. To our knowledge, this is the first work to systematically\ntackle unlearning efficiency by jointly designing a specialized dataset\ncondensation technique with a dedicated accelerated loss function. Code is\navailable at https://github.com/algebraicdianuj/DC_Unlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u4e92\u8865\u65b9\u6cd5\u52a0\u901f\u9762\u5411\u5206\u7c7b\u7684\u8fd1\u4f3c\u673a\u5668\u65e0\u5b66\u4e60\uff08AMU\uff09\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u7aef\u5230\u7aef\u65e0\u5b66\u4e60\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u7559\u6a21\u578b\u5b9e\u7528\u6027\u548c\u9690\u79c1\u3002", "motivation": "\u73b0\u6709AMU\u5904\u7406\u4fdd\u7559\u5b50\u96c6\u4e3b\u5bfc\u8ba1\u7b97\u8fd0\u884c\u65f6\u95f4\uff0c\u51cf\u5c11\u8bad\u7ec3\u8f6e\u6570\u4ecd\u5177\u6311\u6218\uff0c\u9700\u8981\u52a0\u901fAMU\u3002", "method": "\u63d0\u51faBlend\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u5339\u914d\u7684\u6570\u636e\u96c6\u51dd\u805a\u51cf\u5c11\u4fdd\u7559\u96c6\u5927\u5c0f\uff1b\u63d0\u51faAccelerated - AMU\uff08A - AMU\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u5f3a\u65e0\u5b66\u4e60\u76ee\u6807\u52a0\u901f\u6536\u655b\u3002", "result": "\u6570\u636e\u548c\u4ee5\u635f\u5931\u4e3a\u4e2d\u5fc3\u7684\u53cc\u91cd\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5355\u8f6e\u548c\u591a\u8f6e\u573a\u666f\u4e0b\u7684\u7aef\u5230\u7aef\u65e0\u5b66\u4e60\u5ef6\u8fdf\uff0c\u4fdd\u7559\u6a21\u578b\u5b9e\u7528\u6027\u548c\u9690\u79c1\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u901a\u8fc7\u8054\u5408\u8bbe\u8ba1\u4e13\u95e8\u7684\u6570\u636e\u96c6\u51dd\u805a\u6280\u672f\u548c\u52a0\u901f\u635f\u5931\u51fd\u6570\u7cfb\u7edf\u89e3\u51b3\u65e0\u5b66\u4e60\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2507.09797", "pdf": "https://arxiv.org/pdf/2507.09797", "abs": "https://arxiv.org/abs/2507.09797", "authors": ["Ping Liu", "Rajat Arora", "Xiao Shi", "Benjamin Le", "Qianqi Shen", "Jianqiang Shen", "Chengming Jiang", "Nikita Zhiltsov", "Priya Bannur", "Yidan Zhu", "Liming Dong", "Haichao Wei", "Qi Guo", "Luke Simon", "Liangjie Hong", "Wenjing Zhang"], "title": "A Scalable and Efficient Signal Integration System for Job Matching", "categories": ["cs.LG"], "comment": "KDD2025", "summary": "LinkedIn, one of the world's largest platforms for professional networking\nand job seeking, encounters various modeling challenges in building\nrecommendation systems for its job matching product, including cold-start,\nfilter bubbles, and biases affecting candidate-job matching. To address these,\nwe developed the STAR (Signal Integration for Talent And Recruiters) system,\nleveraging the combined strengths of Large Language Models (LLMs) and Graph\nNeural Networks (GNNs). LLMs excel at understanding textual data, such as\nmember profiles and job postings, while GNNs capture intricate relationships\nand mitigate cold-start issues through network effects. STAR integrates diverse\nsignals by uniting LLM and GNN capabilities with industrial-scale paradigms\nincluding adaptive sampling and version management. It provides an end-to-end\nsolution for developing and deploying embeddings in large-scale recommender\nsystems. Our key contributions include a robust methodology for building\nembeddings in industrial applications, a scalable GNN-LLM integration for\nhigh-performing recommendations, and practical insights for real-world model\ndeployment.", "AI": {"tldr": "\u4e3a\u89e3\u51b3LinkedIn\u804c\u4f4d\u5339\u914d\u63a8\u8350\u7cfb\u7edf\u5efa\u6a21\u6311\u6218\uff0c\u5f00\u53d1STAR\u7cfb\u7edf\uff0c\u7ed3\u5408LLM\u548cGNN\u4f18\u52bf\uff0c\u63d0\u4f9b\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u591a\u9879\u8d21\u732e\u3002", "motivation": "\u89e3\u51b3LinkedIn\u804c\u4f4d\u5339\u914d\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u7684\u51b7\u542f\u52a8\u3001\u8fc7\u6ee4\u6c14\u6ce1\u548c\u504f\u5dee\u7b49\u5efa\u6a21\u6311\u6218\u3002", "method": "\u5f00\u53d1STAR\u7cfb\u7edf\uff0c\u7ed3\u5408LLM\u7406\u89e3\u6587\u672c\u6570\u636e\u548cGNN\u6355\u6349\u5173\u7cfb\u3001\u7f13\u89e3\u51b7\u542f\u52a8\u95ee\u9898\u7684\u4f18\u52bf\uff0c\u6574\u5408\u591a\u79cd\u4fe1\u53f7\uff0c\u8054\u5408\u5de5\u4e1a\u89c4\u6a21\u8303\u5f0f\u3002", "result": "\u5f00\u53d1\u51faSTAR\u7cfb\u7edf\uff0c\u63d0\u4f9b\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u5de5\u4e1a\u5e94\u7528\u4e2d\u6784\u5efa\u5d4c\u5165\u7684\u53ef\u9760\u65b9\u6cd5\u3001\u53ef\u6269\u5c55\u7684GNN - LLM\u96c6\u6210\u7528\u4e8e\u9ad8\u6027\u80fd\u63a8\u8350\uff0c\u4ee5\u53ca\u5b9e\u9645\u6a21\u578b\u90e8\u7f72\u7684\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2507.09805", "pdf": "https://arxiv.org/pdf/2507.09805", "abs": "https://arxiv.org/abs/2507.09805", "authors": ["Audri Banik", "Glaucio Haroldo Silva de Carvalho", "Renata Dividino"], "title": "Federated Learning with Graph-Based Aggregation for Traffic Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at FedKDD 2025: International Joint Workshop on Federated\n  Learning for Data Mining and Graph Analytics. 6 pages, 1 figure", "summary": "In traffic prediction, the goal is to estimate traffic speed or flow in\nspecific regions or road segments using historical data collected by devices\ndeployed in each area. Each region or road segment can be viewed as an\nindividual client that measures local traffic flow, making Federated Learning\n(FL) a suitable approach for collaboratively training models without sharing\nraw data. In centralized FL, a central server collects and aggregates model\nupdates from multiple clients to build a shared model while preserving each\nclient's data privacy. Standard FL methods, such as Federated Averaging\n(FedAvg), assume that clients are independent, which can limit performance in\ntraffic prediction tasks where spatial relationships between clients are\nimportant. Federated Graph Learning methods can capture these dependencies\nduring server-side aggregation, but they often introduce significant\ncomputational overhead. In this paper, we propose a lightweight graph-aware FL\napproach that blends the simplicity of FedAvg with key ideas from graph\nlearning. Rather than training full models, our method applies basic\nneighbourhood aggregation principles to guide parameter updates, weighting\nclient models based on graph connectivity. This approach captures spatial\nrelationships effectively while remaining computationally efficient. We\nevaluate our method on two benchmark traffic datasets, METR-LA and PEMS-BAY,\nand show that it achieves competitive performance compared to standard\nbaselines and recent graph-based federated learning techniques.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u56fe\u611f\u77e5\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8e\u4ea4\u901a\u9884\u6d4b\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u6807\u51c6\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u4ea4\u901a\u9884\u6d4b\u4e2d\u5047\u8bbe\u5ba2\u6237\u7aef\u72ec\u7acb\uff0c\u9650\u5236\u6027\u80fd\uff0c\u56fe\u5b66\u4e60\u65b9\u6cd5\u6709\u8f83\u5927\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u878d\u5408FedAvg\u7b80\u5355\u6027\u4e0e\u56fe\u5b66\u4e60\u601d\u60f3\uff0c\u5e94\u7528\u90bb\u57df\u805a\u5408\u539f\u5219\u6307\u5bfc\u53c2\u6570\u66f4\u65b0\uff0c\u6839\u636e\u56fe\u8fde\u63a5\u6027\u52a0\u6743\u5ba2\u6237\u7aef\u6a21\u578b\u3002", "result": "\u5728METR-LA\u548cPEMS - BAY\u4e24\u4e2a\u57fa\u51c6\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6807\u51c6\u57fa\u7ebf\u548c\u8fd1\u671f\u57fa\u4e8e\u56fe\u7684\u8054\u90a6\u5b66\u4e60\u6280\u672f\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u6240\u63d0\u8f7b\u91cf\u7ea7\u56fe\u611f\u77e5\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u6349\u7a7a\u95f4\u5173\u7cfb\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002"}}
{"id": "2507.09816", "pdf": "https://arxiv.org/pdf/2507.09816", "abs": "https://arxiv.org/abs/2507.09816", "authors": ["Adam Newgas"], "title": "Compressed Computation: Dense Circuits in a Toy Model of the Universal-AND Problem", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 9 figures", "summary": "Neural networks are capable of superposition -- representing more features\nthan there are dimensions. Recent work considers the analogous concept for\ncomputation instead of storage, proposing theoretical constructions. But there\nhas been little investigation into whether these circuits can be learned in\npractice. In this work, we investigate a toy model for the Universal-AND\nproblem which computes the AND of all $m\\choose 2$ pairs of $m$ sparse inputs.\nThe hidden dimension that determines the number of non-linear activations is\nrestricted to pressure the model to find a compute-efficient circuit, called\ncompressed computation. We find that the training process finds a simple\nsolution that does not correspond to theoretical constructions. It is fully\ndense -- every neuron contributes to every output. The solution circuit\nnaturally scales with dimension, trading off error rates for neuron efficiency.\nIt is similarly robust to changes in sparsity and other key parameters, and\nextends naturally to other boolean operations and boolean circuits. We explain\nthe found solution in detail and compute why it is more efficient than the\ntheoretical constructions at low sparsity. Our findings shed light on the types\nof circuits that models like to form and the flexibility of the superposition\nrepresentation. This contributes to a broader understanding of network\ncircuitry and interpretability.", "AI": {"tldr": "\u7814\u7a76\u901a\u7528\u4e0e\u95ee\u9898\u73a9\u5177\u6a21\u578b\uff0c\u53d1\u73b0\u8bad\u7ec3\u627e\u5230\u7684\u89e3\u4e0e\u7406\u8bba\u6784\u9020\u4e0d\u540c\uff0c\u8be5\u89e3\u5168\u7a20\u5bc6\u3001\u53ef\u81ea\u7136\u6269\u5c55\uff0c\u89e3\u91ca\u4e86\u5176\u5728\u4f4e\u7a00\u758f\u5ea6\u4e0b\u66f4\u9ad8\u6548\u7684\u539f\u56e0\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u7f51\u7edc\u7535\u8def\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6b64\u524d\u5c11\u6709\u5bf9\u7406\u8bba\u6784\u9020\u7684\u7535\u8def\u5728\u5b9e\u8df5\u4e2d\u80fd\u5426\u88ab\u5b66\u4e60\u7684\u7814\u7a76\uff0c\u56e0\u6b64\u5f00\u5c55\u76f8\u5173\u63a2\u7a76\u3002", "method": "\u7814\u7a76\u901a\u7528\u4e0e\u95ee\u9898\u7684\u73a9\u5177\u6a21\u578b\uff0c\u9650\u5236\u9690\u85cf\u7ef4\u5ea6\u4ee5\u8feb\u4f7f\u6a21\u578b\u5bfb\u627e\u8ba1\u7b97\u9ad8\u6548\u7684\u7535\u8def\u3002", "result": "\u8bad\u7ec3\u8fc7\u7a0b\u627e\u5230\u7684\u89e3\u4e0e\u7406\u8bba\u6784\u9020\u4e0d\u540c\uff0c\u5168\u7a20\u5bc6\uff0c\u80fd\u81ea\u7136\u6269\u5c55\uff0c\u53ef\u6743\u8861\u9519\u8bef\u7387\u548c\u795e\u7ecf\u5143\u6548\u7387\uff0c\u5bf9\u7a00\u758f\u6027\u7b49\u53c2\u6570\u53d8\u5316\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u5f62\u6210\u7684\u7535\u8def\u7c7b\u578b\u548c\u53e0\u52a0\u8868\u793a\u7684\u7075\u6d3b\u6027\uff0c\u4fc3\u8fdb\u5bf9\u7f51\u7edc\u7535\u8def\u548c\u53ef\u89e3\u91ca\u6027\u7684\u66f4\u5e7f\u6cdb\u7406\u89e3\u3002"}}
{"id": "2507.09076", "pdf": "https://arxiv.org/pdf/2507.09076", "abs": "https://arxiv.org/abs/2507.09076", "authors": ["Jialong Mai", "Xiaofen Xing", "Yawei Li", "Zhipeng Li", "Jingyuan Xing", "Xiangmin Xu"], "title": "Dynamic Parameter Memory: Temporary LoRA-Enhanced LLM for Long-Sequence Emotion Recognition in Conversation", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7; H.5.2"], "comment": "submitted to EMNLP 2025", "summary": "Recent research has focused on applying speech large language model (SLLM) to\nimprove speech emotion recognition (SER). However, the inherently high frame\nrate in speech modality severely limits the signal processing and understanding\ncapabilities of SLLM. For example, a SLLM with a 4K context window can only\nprocess 80 seconds of audio at 50Hz feature sampling rate before reaching its\ncapacity limit. Input token compression methods used in SLLM overlook the\ncontinuity and inertia of emotions across multiple conversation turns. This\npaper proposes a Dynamic Parameter Memory (DPM) mechanism with contextual\nsemantics and sentence-level emotion encoding, enabling processing of\nunlimited-length audio with limited context windows in SLLM. Specifically, DPM\nprogressively encodes sentence-level information and emotions into a temporary\nLoRA module during inference to effectively \"memorize\" the contextual\ninformation. We trained an emotion SLLM as a backbone and incorporated our DPM\ninto inference for emotion recognition in conversation (ERC). Experimental\nresults on the IEMOCAP dataset show that DPM significantly improves the emotion\nrecognition capabilities of SLLM when processing long audio sequences,\nachieving state-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u52a8\u6001\u53c2\u6570\u8bb0\u5fc6\uff08DPM\uff09\u673a\u5236\uff0c\u89e3\u51b3SLLM\u5904\u7406\u957f\u8bed\u97f3\u65f6\u7684\u5c40\u9650\uff0c\u5728IEMOCAP\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6548\u679c\u3002", "motivation": "\u73b0\u6709SLLM\u5728\u5904\u7406\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u65f6\uff0c\u9ad8\u5e27\u7387\u9650\u5236\u5904\u7406\u80fd\u529b\uff0c\u8f93\u5165\u4ee4\u724c\u538b\u7f29\u65b9\u6cd5\u5ffd\u7565\u591a\u8f6e\u5bf9\u8bdd\u60c5\u611f\u8fde\u7eed\u6027\u3002", "method": "\u63d0\u51fa\u5177\u6709\u4e0a\u4e0b\u6587\u8bed\u4e49\u548c\u53e5\u5b50\u7ea7\u60c5\u611f\u7f16\u7801\u7684DPM\u673a\u5236\uff0c\u5c06\u53e5\u5b50\u7ea7\u4fe1\u606f\u548c\u60c5\u611f\u9010\u6b65\u7f16\u7801\u5230\u4e34\u65f6LoRA\u6a21\u5757\u3002", "result": "\u5728IEMOCAP\u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\uff0cDPM\u663e\u8457\u63d0\u5347SLLM\u5904\u7406\u957f\u97f3\u9891\u5e8f\u5217\u65f6\u7684\u60c5\u611f\u8bc6\u522b\u80fd\u529b\u3002", "conclusion": "DPM\u673a\u5236\u6709\u6548\u89e3\u51b3SLLM\u5904\u7406\u957f\u8bed\u97f3\u7684\u5c40\u9650\uff0c\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2507.09826", "pdf": "https://arxiv.org/pdf/2507.09826", "abs": "https://arxiv.org/abs/2507.09826", "authors": ["Jintao Qu", "Zichong Wang", "Chenhao Wu", "Wenbin Zhang"], "title": "Bridging Neural Networks and Dynamic Time Warping for Adaptive Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Neural networks have achieved remarkable success in time series\nclassification, but their reliance on large amounts of labeled data for\ntraining limits their applicability in cold-start scenarios. Moreover, they\nlack interpretability, reducing transparency in decision-making. In contrast,\ndynamic time warping (DTW) combined with a nearest neighbor classifier is\nwidely used for its effectiveness in limited-data settings and its inherent\ninterpretability. However, as a non-parametric method, it is not trainable and\ncannot leverage large amounts of labeled data, making it less effective than\nneural networks in rich-resource scenarios. In this work, we aim to develop a\nversatile model that adapts to cold-start conditions and becomes trainable with\nlabeled data, while maintaining interpretability. We propose a dynamic\nlength-shortening algorithm that transforms time series into prototypes while\npreserving key structural patterns, thereby enabling the reformulation of the\nDTW recurrence relation into an equivalent recurrent neural network. Based on\nthis, we construct a trainable model that mimics DTW's alignment behavior. As a\nneural network, it becomes trainable when sufficient labeled data is available,\nwhile still retaining DTW's inherent interpretability. We apply the model to\nseveral benchmark time series classification tasks and observe that it\nsignificantly outperforms previous approaches in low-resource settings and\nremains competitive in rich-resource settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u52a8\u6001\u957f\u5ea6\u7f29\u77ed\u7b97\u6cd5\uff0c\u6784\u5efa\u53ef\u8bad\u7ec3\u6a21\u578b\uff0c\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u4e0eDTW\u4f18\u70b9\uff0c\u5728\u4e0d\u540c\u6570\u636e\u8d44\u6e90\u573a\u666f\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u5728\u51b7\u542f\u52a8\u573a\u666f\u53d7\u9650\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1bDTW\u5728\u6570\u636e\u4e30\u5bcc\u573a\u666f\u6548\u679c\u4e0d\u5982\u795e\u7ecf\u7f51\u7edc\uff0c\u65e8\u5728\u5f00\u53d1\u9002\u5e94\u51b7\u542f\u52a8\u3001\u53ef\u8bad\u7ec3\u4e14\u6709\u53ef\u89e3\u91ca\u6027\u7684\u901a\u7528\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u957f\u5ea6\u7f29\u77ed\u7b97\u6cd5\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u539f\u578b\uff0c\u628aDTW\u9012\u63a8\u5173\u7cfb\u8f6c\u5316\u4e3a\u7b49\u6548\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u6784\u5efa\u6a21\u4effDTW\u5bf9\u9f50\u884c\u4e3a\u7684\u53ef\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5728\u9ad8\u8d44\u6e90\u573a\u666f\u4ecd\u5177\u7ade\u4e89\u529b\u3002", "conclusion": "\u6240\u6784\u5efa\u7684\u6a21\u578b\u7ed3\u5408\u4e86\u795e\u7ecf\u7f51\u7edc\u548cDTW\u7684\u4f18\u70b9\uff0c\u5728\u4e0d\u540c\u6570\u636e\u8d44\u6e90\u6761\u4ef6\u4e0b\u5747\u6709\u8f83\u597d\u8868\u73b0\u3002"}}
{"id": "2507.09837", "pdf": "https://arxiv.org/pdf/2507.09837", "abs": "https://arxiv.org/abs/2507.09837", "authors": ["Quang Truong", "Zhikai Chen", "Mingxuan Ju", "Tong Zhao", "Neil Shah", "Jiliang Tang"], "title": "A Pre-training Framework for Relational Data with Information-theoretic Principles", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Relational databases underpin critical infrastructure across a wide range of\ndomains, yet the design of generalizable pre-training strategies for learning\nfrom relational databases remains an open challenge due to task heterogeneity.\nSpecifically, there exist infinitely many possible downstream tasks, as tasks\nare defined based on relational schema graphs, temporal dependencies, and\nSQL-defined label logics. An effective pre-training framework is desired to\ntake these factors into account in order to obtain task-aware representations.\nBy incorporating knowledge of the underlying distribution that drives label\ngeneration, downstream tasks can benefit from relevant side-channel\ninformation. To bridge this gap, we introduce Task Vector Estimation (TVE), a\nnovel pre-training framework that constructs predictive supervisory signals via\nset-based aggregation over schema traversal graphs, explicitly modeling\nnext-window relational dynamics. We formalize our approach through an\ninformation-theoretic lens, demonstrating that task-informed representations\nretain more relevant signals than those obtained without task priors. Extensive\nexperiments on the RelBench benchmark show that TVE consistently outperforms\ntraditional pre-training baselines. Our findings advocate for pre-training\nobjectives that encode task heterogeneity and temporal structure as design\nprinciples for predictive modeling on relational databases.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTask Vector Estimation (TVE)\u9884\u8bad\u7ec3\u6846\u67b6\u7528\u4e8e\u5173\u7cfb\u6570\u636e\u5e93\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\uff0c\u5021\u5bfc\u5728\u9884\u6d4b\u5efa\u6a21\u4e2d\u8003\u8651\u4efb\u52a1\u5f02\u8d28\u6027\u548c\u65f6\u95f4\u7ed3\u6784\u3002", "motivation": "\u5173\u7cfb\u6570\u636e\u5e93\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u56e0\u4efb\u52a1\u5f02\u8d28\u6027\uff0c\u8bbe\u8ba1\u901a\u7528\u9884\u8bad\u7ec3\u7b56\u7565\u662f\u6311\u6218\uff0c\u9700\u6709\u6548\u6846\u67b6\u83b7\u53d6\u4efb\u52a1\u611f\u77e5\u8868\u793a\u3002", "method": "\u5f15\u5165TVE\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6a21\u5f0f\u904d\u5386\u56fe\u8fdb\u884c\u57fa\u4e8e\u96c6\u5408\u7684\u805a\u5408\u6784\u5efa\u9884\u6d4b\u76d1\u7763\u4fe1\u53f7\uff0c\u663e\u5f0f\u5efa\u6a21\u4e0b\u4e00\u7a97\u53e3\u5173\u7cfb\u52a8\u6001\uff0c\u5e76\u4ece\u4fe1\u606f\u8bba\u89d2\u5ea6\u5f62\u5f0f\u5316\u8be5\u65b9\u6cd5\u3002", "result": "\u5728RelBench\u57fa\u51c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cTVE\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edf\u9884\u8bad\u7ec3\u57fa\u7ebf\u3002", "conclusion": "\u5021\u5bfc\u5c06\u7f16\u7801\u4efb\u52a1\u5f02\u8d28\u6027\u548c\u65f6\u95f4\u7ed3\u6784\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u4f5c\u4e3a\u5173\u7cfb\u6570\u636e\u5e93\u9884\u6d4b\u5efa\u6a21\u7684\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2507.09839", "pdf": "https://arxiv.org/pdf/2507.09839", "abs": "https://arxiv.org/abs/2507.09839", "authors": ["MohammadReza Davari", "Utkarsh Garg", "Weixin Cai", "Eugene Belilovsky"], "title": "Rethinking Prompt Optimization: Reinforcement, Diversification, and Migration in Blackbox LLMs", "categories": ["cs.LG"], "comment": null, "summary": "An increasing number of NLP applications interact with large language models\n(LLMs) through black-box APIs, making prompt engineering critical for\ncontrolling model outputs. While recent Automatic Prompt Optimization (APO)\nmethods iteratively refine prompts using model-generated feedback, textual\ngradients, they primarily focus on error correction and neglect valuable\ninsights from correct predictions. This limits both their effectiveness and\nefficiency. In this paper, we propose a novel APO framework centered on\nenhancing the feedback mechanism. We reinterpret the textual gradient as a form\nof negative reinforcement and introduce the complementary positive\nreinforcement to explicitly preserve beneficial prompt components identified\nthrough successful predictions. To mitigate the noise inherent in LLM-generated\nfeedback, we introduce a technique called feedback diversification, which\naggregates multiple feedback signals, emphasizing consistent, actionable advice\nwhile filtering out outliers. Motivated by the rapid evolution and diversity of\navailable LLMs, we also formalize Continual Prompt Optimization (CPO),\naddressing the practical challenge of efficiently migrating optimized prompts\nbetween different model versions or API providers. Our experiments reveal that\nnaive prompt migration often degrades performance due to loss of critical\ninstructions. In contrast, our approach consistently outperforms strong\nbaselines, achieving significant accuracy improvements, faster convergence, and\nlower computational costs in both standard and migration scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4ee5\u589e\u5f3a\u53cd\u9988\u673a\u5236\u4e3a\u6838\u5fc3\u7684APO\u6846\u67b6\uff0c\u5f15\u5165\u6b63\u5f3a\u5316\u3001\u53cd\u9988\u591a\u6837\u5316\u6280\u672f\uff0c\u5f62\u5f0f\u5316CPO\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7ea0\u9519\uff0c\u5ffd\u7565\u6b63\u786e\u9884\u6d4b\u7684\u4ef7\u503c\uff0c\u9650\u5236\u4e86\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u4e14\u7f3a\u4e4f\u9ad8\u6548\u8fc1\u79fb\u4f18\u5316\u63d0\u793a\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u6587\u672c\u68af\u5ea6\u91cd\u65b0\u89e3\u91ca\u4e3a\u8d1f\u5f3a\u5316\uff0c\u5f15\u5165\u6b63\u5f3a\u5316\u4ee5\u4fdd\u7559\u6709\u76ca\u63d0\u793a\u7ec4\u4ef6\uff1b\u5f15\u5165\u53cd\u9988\u591a\u6837\u5316\u6280\u672f\u51cf\u5c11LLM\u53cd\u9988\u4e2d\u7684\u566a\u58f0\uff1b\u5f62\u5f0f\u5316\u6301\u7eed\u63d0\u793a\u4f18\u5316\uff08CPO\uff09\u3002", "result": "\u5728\u6807\u51c6\u548c\u8fc1\u79fb\u573a\u666f\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u51c6\u786e\u6027\u63d0\u5347\u3001\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u63d0\u793a\u4f18\u5316\u548c\u8fc1\u79fb\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u80fd\u63d0\u9ad8\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2507.09100", "pdf": "https://arxiv.org/pdf/2507.09100", "abs": "https://arxiv.org/abs/2507.09100", "authors": ["Mohammad Abolnejadian", "Shakiba Amirshahi", "Matthew Brehmer", "Anamaria Crisan"], "title": "AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data", "categories": ["cs.HC", "cs.AI", "cs.CL", "H.5.0"], "comment": "7 pages and 4 figures. Proceedings of the 7th ACM Conference on\n  Conversational User Interfaces (CUI '25)", "summary": "In decision-making conversations, experts must navigate complex choices and\nmake on-the-spot decisions while engaged in conversation. Although extensive\nhistorical data often exists, the real-time nature of these scenarios makes it\ninfeasible for decision-makers to review and leverage relevant information.\nThis raises an interesting question: What if experts could utilize relevant\npast data in real-time decision-making through insights derived from past data?\nTo explore this, we implemented a conversational user interface, taking\ndoctor-patient interactions as an example use case. Our system continuously\nlistens to the conversation, identifies patient problems and doctor-suggested\nsolutions, and retrieves related data from an embedded dataset, generating\nconcise insights using a pipeline built around a retrieval-based Large Language\nModel (LLM) agent. We evaluated the prototype by embedding Health Canada\ndatasets into a vector database and conducting simulated studies using sample\ndoctor-patient dialogues, showing effectiveness but also challenges, setting\ndirections for the next steps of our work.", "AI": {"tldr": "\u672c\u6587\u4ee5\u533b\u60a3\u5bf9\u8bdd\u4e3a\u4f8b\uff0c\u5b9e\u73b0\u5bf9\u8bdd\u5f0f\u7528\u6237\u754c\u9762\uff0c\u5229\u7528\u57fa\u4e8e\u68c0\u7d22\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u751f\u6210\u89c1\u89e3\u5e76\u8bc4\u4f30\u539f\u578b\uff0c\u663e\u793a\u51fa\u6709\u6548\u6027\u548c\u6311\u6218\u3002", "motivation": "\u51b3\u7b56\u5bf9\u8bdd\u5b9e\u65f6\u6027\u4f7f\u51b3\u7b56\u8005\u96be\u4ee5\u56de\u987e\u548c\u5229\u7528\u76f8\u5173\u4fe1\u606f\uff0c\u63a2\u7d22\u4e13\u5bb6\u80fd\u5426\u5728\u5b9e\u65f6\u51b3\u7b56\u4e2d\u5229\u7528\u8fc7\u53bb\u6570\u636e\u7684\u89c1\u89e3\u3002", "method": "\u5b9e\u73b0\u5bf9\u8bdd\u5f0f\u7528\u6237\u754c\u9762\uff0c\u4ee5\u533b\u60a3\u4ea4\u4e92\u4e3a\u4f8b\uff0c\u7cfb\u7edf\u76d1\u542c\u5bf9\u8bdd\u3001\u8bc6\u522b\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u5d4c\u5165\u5f0f\u6570\u636e\u96c6\u68c0\u7d22\u76f8\u5173\u6570\u636e\uff0c\u7528\u57fa\u4e8e\u68c0\u7d22\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u751f\u6210\u89c1\u89e3\u3002", "result": "\u5c06\u52a0\u62ff\u5927\u536b\u751f\u90e8\u6570\u636e\u96c6\u5d4c\u5165\u5411\u91cf\u6570\u636e\u5e93\uff0c\u7528\u6837\u672c\u533b\u60a3\u5bf9\u8bdd\u8fdb\u884c\u6a21\u62df\u7814\u7a76\uff0c\u663e\u793a\u51fa\u6709\u6548\u6027\u4f46\u4e5f\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u663e\u793a\u51fa\u4e00\u5b9a\u6548\u679c\u4f46\u6709\u6311\u6218\uff0c\u4e3a\u540e\u7eed\u5de5\u4f5c\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2507.09104", "pdf": "https://arxiv.org/pdf/2507.09104", "abs": "https://arxiv.org/abs/2507.09104", "authors": ["Taolin Zhang", "Maosong Cao", "Alexander Lam", "Songyang Zhang", "Kai Chen"], "title": "CompassJudger-2: Towards Generalist Judge Model via Verifiable Rewards", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recently, the role of LLM-as-judge in evaluating large language models has\ngained prominence. However, current judge models suffer from narrow\nspecialization and limited robustness, undermining their capacity for\ncomprehensive evaluations. In this work, we present CompassJudger-2, a novel\ngeneralist judge model that overcomes these limitations via a task-driven,\nmulti-domain data curation strategy. Central to our approach is supervising\njudgment tasks with verifiable rewards, guiding intrinsic critical reasoning\nthrough rejection sampling to foster robust, generalizable judgment\ncapabilities. We introduce a refined learning objective with margin policy\ngradient loss to enhance performance. Empirically, CompassJudger-2 achieves\nsuperior results across multiple judge and reward benchmarks, and our 7B model\ndemonstrates competitive judgment accuracy with significantly larger models\nlike DeepSeek-V3 and Qwen3-235B-A22B. Additionally, we propose JudgerBenchV2, a\ncomprehensive benchmark evaluating cross-domain judgment accuracy and rank\nconsistency to standardize judge model evaluation. These contributions advance\nrobust, scalable LLM judgment and establish new performance and evaluation\nstandards.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u7528\u8bc4\u5224\u6a21\u578bCompassJudger - 2\u548c\u7efc\u5408\u57fa\u51c6JudgerBenchV2\uff0c\u524d\u8005\u514b\u670d\u73b0\u6709\u8bc4\u5224\u6a21\u578b\u5c40\u9650\uff0c\u540e\u8005\u89c4\u8303\u8bc4\u5224\u6a21\u578b\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u6a21\u578b\u5b58\u5728\u4e13\u4e1a\u5316\u72ed\u7a84\u548c\u9c81\u68d2\u6027\u6709\u9650\u95ee\u9898\uff0c\u65e0\u6cd5\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u4efb\u52a1\u9a71\u52a8\u3001\u591a\u9886\u57df\u6570\u636e\u6574\u7406\u7b56\u7565\uff0c\u7528\u53ef\u9a8c\u8bc1\u5956\u52b1\u76d1\u7763\u8bc4\u5224\u4efb\u52a1\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u5f15\u5bfc\u63a8\u7406\uff0c\u5f15\u5165\u5e26\u8fb9\u754c\u7b56\u7565\u68af\u5ea6\u635f\u5931\u7684\u5b66\u4e60\u76ee\u6807\u3002", "result": "CompassJudger - 2\u5728\u591a\u4e2a\u8bc4\u5224\u548c\u5956\u52b1\u57fa\u51c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\uff0c7B\u6a21\u578b\u4e0e\u66f4\u5927\u6a21\u578b\u8868\u73b0\u76f8\u5f53\uff1b\u63d0\u51faJudgerBenchV2\u8bc4\u4f30\u8de8\u9886\u57df\u8bc4\u5224\u51c6\u786e\u6027\u548c\u6392\u540d\u4e00\u81f4\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u6210\u679c\u63a8\u52a8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u7684\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6027\u80fd\u548c\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2507.09871", "pdf": "https://arxiv.org/pdf/2507.09871", "abs": "https://arxiv.org/abs/2507.09871", "authors": ["Niket Patel", "Randall Balestriero"], "title": "Task Priors: Enhancing Model Evaluation by Considering the Entire Space of Downstream Tasks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The grand goal of AI research, and particularly Self Supervised Learning\n(SSL), is to produce systems that can successfully solve any possible task. In\ncontrast, current evaluation methods available to AI researchers typically rely\non a fixed collection of hand-picked downstream benchmarks. Hence, a large\namount of effort is put into designing and searching for large collection of\nevaluation tasks that can serve as a proxy of our grand goal. We argue that\nsuch a rigid evaluation protocol creates a silent bottleneck in AI research. To\nremedy that, we define a probabilistic space of downstream tasks obtained by\nadopting a distribution of tasks and by defining Task Priors. Under this view,\none can evaluate a model's performance over the set of all possible downstream\ntasks. Our framework is the first to provide answers to key questions such as\n(i) what is the average performance of my model over all possible downstream\ntasks weighted by the probability to encounter each task? or (ii) what is the\nvariance of my model's performance across all downstream tasks under the\ndefined Task Priors? Beyond establishing a new standard for evaluation, we\nbelieve that Task Priors will accelerate the pace of research in SSL - where\ndownstream task evaluation is the sole qualitative signal that researchers have\naccess to.", "AI": {"tldr": "\u5f53\u524dAI\u8bc4\u4f30\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u63d0\u51fa\u7528\u4efb\u52a1\u5148\u9a8c\u5b9a\u4e49\u4e0b\u6e38\u4efb\u52a1\u6982\u7387\u7a7a\u95f4\u8bc4\u4f30\u6a21\u578b\u7684\u6846\u67b6\u3002", "motivation": "\u5f53\u524dAI\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u624b\u5de5\u6311\u9009\u57fa\u51c6\uff0c\u5b58\u5728\u74f6\u9888\uff0c\u9700\u65b0\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u91c7\u7528\u4efb\u52a1\u5206\u5e03\u5e76\u5b9a\u4e49\u4efb\u52a1\u5148\u9a8c\uff0c\u6784\u5efa\u4e0b\u6e38\u4efb\u52a1\u6982\u7387\u7a7a\u95f4\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u6846\u67b6\u80fd\u56de\u7b54\u6a21\u578b\u5728\u6240\u6709\u4e0b\u6e38\u4efb\u52a1\u4e0a\u5e73\u5747\u8868\u73b0\u548c\u8868\u73b0\u65b9\u5dee\u7b49\u5173\u952e\u95ee\u9898\u3002", "conclusion": "\u6b64\u6846\u67b6\u5efa\u7acb\u65b0\u8bc4\u4f30\u6807\u51c6\uff0c\u80fd\u52a0\u901f\u81ea\u76d1\u7763\u5b66\u4e60\u7814\u7a76\u3002"}}
{"id": "2507.09882", "pdf": "https://arxiv.org/pdf/2507.09882", "abs": "https://arxiv.org/abs/2507.09882", "authors": ["Jiamin Wu", "Zichen Ren", "Junyu Wang", "Pengyu Zhu", "Yonghao Song", "Mianxin Liu", "Qihao Zheng", "Lei Bai", "Wanli Ouyang", "Chunfeng Song"], "title": "AdaBrain-Bench: Benchmarking Brain Foundation Models for Brain-Computer Interface Applications", "categories": ["cs.LG"], "comment": null, "summary": "Non-invasive Brain-Computer Interfaces (BCI) offer a safe and accessible\nmeans of connecting the human brain to external devices, with broad\napplications in home and clinical settings to enhance human capabilities.\nHowever, the high noise level and limited task-specific data in non-invasive\nsignals constrain decoding capabilities. Recently, the adoption of\nself-supervised pre-training is transforming the landscape of non-invasive BCI\nresearch, enabling the development of brain foundation models to capture\ngeneric neural representations from large-scale unlabeled\nelectroencephalography (EEG) signals with substantial noises. However, despite\nthese advances, the field currently lacks comprehensive, practical and\nextensible benchmarks to assess the utility of the public foundation models\nacross diverse BCI tasks, hindering their widespread adoption. To address this\nchallenge, we present AdaBrain-Bench, a large-scale standardized benchmark to\nsystematically evaluate brain foundation models in widespread non-invasive BCI\ntasks. AdaBrain-Bench encompasses a diverse collection of representative BCI\ndecoding datasets spanning 7 key applications. It introduces a streamlined task\nadaptation pipeline integrated with multi-dimensional evaluation metrics and a\nset of adaptation tools. The benchmark delivers an inclusive framework for\nassessing generalizability of brain foundation models across key transfer\nsettings, including cross-subject, multi-subject, and few-shot scenarios. We\nleverage AdaBrain-Bench to evaluate a suite of publicly available brain\nfoundation models and offer insights into practices for selecting appropriate\nmodels in various scenarios. We make our benchmark pipeline available to enable\nreproducible research and external use, offering a continuously evolving\nplatform to foster progress toward robust and generalized neural decoding\nsolutions.", "AI": {"tldr": "\u63d0\u51faAdaBrain - Bench\u57fa\u51c6\u6765\u8bc4\u4f30\u975e\u4fb5\u5165\u5f0fBCI\u7684\u8111\u57fa\u7840\u6a21\u578b\uff0c\u4ecb\u7ecd\u5176\u6784\u6210\u548c\u7528\u9014\u5e76\u5f00\u6e90\u3002", "motivation": "\u975e\u4fb5\u5165\u5f0fBCI\u4fe1\u53f7\u566a\u58f0\u9ad8\u3001\u6570\u636e\u6709\u9650\uff0c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u53d1\u5c55\u4f46\u7f3a\u4e4f\u8bc4\u4f30\u8111\u57fa\u7840\u6a21\u578b\u7684\u7efc\u5408\u5b9e\u7528\u57fa\u51c6\uff0c\u963b\u788d\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u6784\u5efaAdaBrain - Bench\u57fa\u51c6\uff0c\u5305\u542b\u591a\u79cdBCI\u89e3\u7801\u6570\u636e\u96c6\u3001\u4efb\u52a1\u9002\u5e94\u6d41\u7a0b\u3001\u8bc4\u4f30\u6307\u6807\u548c\u5de5\u5177\u3002", "result": "\u5229\u7528AdaBrain - Bench\u8bc4\u4f30\u4e86\u516c\u5f00\u8111\u57fa\u7840\u6a21\u578b\uff0c\u4e3a\u4e0d\u540c\u573a\u666f\u9009\u6a21\u578b\u63d0\u4f9b\u89c1\u89e3\u3002", "conclusion": "\u5f00\u6e90\u57fa\u51c6\u7ba1\u9053\uff0c\u63d0\u4f9b\u6301\u7eed\u53d1\u5c55\u5e73\u53f0\u63a8\u52a8\u795e\u7ecf\u89e3\u7801\u89e3\u51b3\u65b9\u6848\u53d1\u5c55\u3002"}}
{"id": "2507.09117", "pdf": "https://arxiv.org/pdf/2507.09117", "abs": "https://arxiv.org/abs/2507.09117", "authors": ["Gagan Khandate"], "title": "Towards Human-level Dexterity via Robot Learning", "categories": ["cs.RO", "cs.AI"], "comment": "PhD thesis", "summary": "Dexterous intelligence -- the ability to perform complex interactions with\nmulti-fingered hands -- is a pinnacle of human physical intelligence and\nemergent higher-order cognitive skills. However, contrary to Moravec's paradox,\ndexterous intelligence in humans appears simple only superficially. Many\nmillion years were spent co-evolving the human brain and hands including rich\ntactile sensing. Achieving human-level dexterity with robotic hands has long\nbeen a fundamental goal in robotics and represents a critical milestone toward\ngeneral embodied intelligence. In this pursuit, computational sensorimotor\nlearning has made significant progress, enabling feats such as arbitrary\nin-hand object reorientation. However, we observe that achieving higher levels\nof dexterity requires overcoming very fundamental limitations of computational\nsensorimotor learning.\n  I develop robot learning methods for highly dexterous multi-fingered\nmanipulation by directly addressing these limitations at their root cause.\nChiefly, through key studies, this disseration progressively builds an\neffective framework for reinforcement learning of dexterous multi-fingered\nmanipulation skills. These methods adopt structured exploration, effectively\novercoming the limitations of random exploration in reinforcement learning. The\ninsights gained culminate in a highly effective reinforcement learning that\nincorporates sampling-based planning for direct exploration. Additionally, this\nthesis explores a new paradigm of using visuo-tactile human demonstrations for\ndexterity, introducing corresponding imitation learning techniques.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5b9e\u73b0\u673a\u5668\u4eba\u624b\u7c7b\u4eba\u7075\u5de7\u6027\u9762\u4e34\u8ba1\u7b97\u4f20\u611f\u8fd0\u52a8\u5b66\u4e60\u7684\u5c40\u9650\uff0c\u5f00\u53d1\u4e86\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u7684\u673a\u5668\u4eba\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ec\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u548c\u57fa\u4e8e\u89c6\u89c9\u89e6\u89c9\u4eba\u7c7b\u6f14\u793a\u7684\u6a21\u4eff\u5b66\u4e60\u6280\u672f\u3002", "motivation": "\u5b9e\u73b0\u673a\u5668\u4eba\u624b\u7c7b\u4eba\u7075\u5de7\u6027\u662f\u673a\u5668\u4eba\u9886\u57df\u7684\u57fa\u672c\u76ee\u6807\u548c\u8fc8\u5411\u901a\u7528\u5177\u8eab\u667a\u80fd\u7684\u5173\u952e\u91cc\u7a0b\u7891\uff0c\u4f46\u8ba1\u7b97\u4f20\u611f\u8fd0\u52a8\u5b66\u4e60\u5b58\u5728\u5c40\u9650\uff0c\u9700\u514b\u670d\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6c34\u5e73\u7684\u7075\u5de7\u6027\u3002", "method": "\u901a\u8fc7\u5173\u952e\u7814\u7a76\u6784\u5efa\u7528\u4e8e\u591a\u624b\u6307\u7075\u5de7\u64cd\u4f5c\u6280\u80fd\u5f3a\u5316\u5b66\u4e60\u7684\u6709\u6548\u6846\u67b6\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u63a2\u7d22\u514b\u670d\u968f\u673a\u63a2\u7d22\u7684\u5c40\u9650\uff0c\u5f15\u5165\u57fa\u4e8e\u91c7\u6837\u89c4\u5212\u7684\u76f4\u63a5\u63a2\u7d22\uff1b\u63a2\u7d22\u4f7f\u7528\u89c6\u89c9\u89e6\u89c9\u4eba\u7c7b\u6f14\u793a\u7684\u65b0\u8303\u5f0f\u5e76\u5f15\u5165\u76f8\u5e94\u7684\u6a21\u4eff\u5b66\u4e60\u6280\u672f\u3002", "result": "\u5f00\u53d1\u51fa\u9488\u5bf9\u591a\u624b\u6307\u7075\u5de7\u64cd\u4f5c\u7684\u673a\u5668\u4eba\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u514b\u670d\u8ba1\u7b97\u4f20\u611f\u8fd0\u52a8\u5b66\u4e60\u7684\u5c40\u9650\uff0c\u63a8\u52a8\u673a\u5668\u4eba\u624b\u5b9e\u73b0\u66f4\u9ad8\u6c34\u5e73\u7684\u7075\u5de7\u6027\u3002"}}
{"id": "2507.09887", "pdf": "https://arxiv.org/pdf/2507.09887", "abs": "https://arxiv.org/abs/2507.09887", "authors": ["Huynh Nguyen Dang", "Thang Pham", "Ngan Le", "Van Nguyen"], "title": "TolerantECG: A Foundation Model for Imperfect Electrocardiogram", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": "10 pages, 6 figures. Accepted to ACM Multimedia 2025", "summary": "The electrocardiogram (ECG) is an essential and effective tool for diagnosing\nheart diseases. However, its effectiveness can be compromised by noise or\nunavailability of one or more leads of the standard 12-lead recordings,\nresulting in diagnostic errors or uncertainty. To address these challenges, we\npropose TolerantECG, a foundation model for ECG signals that is robust to noise\nand capable of functioning with arbitrary subsets of the standard 12-lead ECG.\nTolerantECG training combines contrastive and self-supervised learning\nframeworks to jointly learn ECG signal representations alongside their\ncorresponding knowledge-retrieval-based text report descriptions and corrupted\nor lead-missing signals. Comprehensive benchmarking results demonstrate that\nTolerantECG consistently ranks as the best or second-best performer across\nvarious ECG signal conditions and class levels in the PTB-XL dataset, and\nachieves the highest performance on the MIT-BIH Arrhythmia Database.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8eECG\u4fe1\u53f7\u7684\u57fa\u7840\u6a21\u578bTolerantECG\uff0c\u80fd\u5e94\u5bf9\u566a\u58f0\u548c\u5bfc\u8054\u7f3a\u5931\u95ee\u9898\uff0c\u5728\u591a\u6570\u636e\u96c6\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u6807\u51c612\u5bfc\u8054\u5fc3\u7535\u56fe\u8bb0\u5f55\u53ef\u80fd\u53d7\u566a\u58f0\u6216\u90e8\u5206\u5bfc\u8054\u4e0d\u53ef\u7528\u5f71\u54cd\u8bca\u65ad\u6548\u679c\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u8054\u5408\u5b66\u4e60ECG\u4fe1\u53f7\u8868\u793a\u53ca\u5176\u5bf9\u5e94\u7684\u57fa\u4e8e\u77e5\u8bc6\u68c0\u7d22\u7684\u6587\u672c\u62a5\u544a\u63cf\u8ff0\u548c\u635f\u574f\u6216\u5bfc\u8054\u7f3a\u5931\u7684\u4fe1\u53f7\u3002", "result": "TolerantECG\u5728PTB - XL\u6570\u636e\u96c6\u7684\u5404\u79cdECG\u4fe1\u53f7\u6761\u4ef6\u548c\u5206\u7c7b\u7ea7\u522b\u4e2d\u59cb\u7ec8\u6392\u540d\u7b2c\u4e00\u6216\u7b2c\u4e8c\uff0c\u5728MIT - BIH\u5fc3\u5f8b\u5931\u5e38\u6570\u636e\u5e93\u4e0a\u53d6\u5f97\u6700\u9ad8\u6027\u80fd\u3002", "conclusion": "TolerantECG\u662f\u4e00\u4e2a\u5bf9\u566a\u58f0\u9c81\u68d2\u4e14\u80fd\u5728\u4efb\u610f\u5b50\u96c6\u5bfc\u8054\u4e0b\u5de5\u4f5c\u7684\u6709\u6548ECG\u57fa\u7840\u6a21\u578b\u3002"}}
{"id": "2507.09890", "pdf": "https://arxiv.org/pdf/2507.09890", "abs": "https://arxiv.org/abs/2507.09890", "authors": ["Ping Xu", "Pengfei Wang", "Zhiyuan Ning", "Meng Xiao", "Min Wu", "Yuanchun Zhou"], "title": "Soft Graph Clustering for single-cell RNA Sequencing Data", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": null, "summary": "Clustering analysis is fundamental in single-cell RNA sequencing (scRNA-seq)\ndata analysis for elucidating cellular heterogeneity and diversity. Recent\ngraph-based scRNA-seq clustering methods, particularly graph neural networks\n(GNNs), have significantly improved in tackling the challenges of\nhigh-dimension, high-sparsity, and frequent dropout events that lead to\nambiguous cell population boundaries. However, their reliance on hard graph\nconstructions derived from thresholded similarity matrices presents\nchallenges:(i) The simplification of intercellular relationships into binary\nedges (0 or 1) by applying thresholds, which restricts the capture of\ncontinuous similarity features among cells and leads to significant information\nloss.(ii) The presence of significant inter-cluster connections within hard\ngraphs, which can confuse GNN methods that rely heavily on graph structures,\npotentially causing erroneous message propagation and biased clustering\noutcomes. To tackle these challenges, we introduce scSGC, a Soft Graph\nClustering for single-cell RNA sequencing data, which aims to more accurately\ncharacterize continuous similarities among cells through non-binary edge\nweights, thereby mitigating the limitations of rigid data structures. The scSGC\nframework comprises three core components: (i) a zero-inflated negative\nbinomial (ZINB)-based feature autoencoder; (ii) a dual-channel cut-informed\nsoft graph embedding module; and (iii) an optimal transport-based clustering\noptimization module. Extensive experiments across ten datasets demonstrate that\nscSGC outperforms 13 state-of-the-art clustering models in clustering accuracy,\ncell type annotation, and computational efficiency. These results highlight its\nsubstantial potential to advance scRNA-seq data analysis and deepen our\nunderstanding of cellular heterogeneity.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u805a\u7c7b\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51fascSGC\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u805a\u7c7b\u51c6\u786e\u6027\u3001\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e13\u79cd\u5148\u8fdb\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u805a\u7c7b\u65b9\u6cd5\u4f9d\u8d56\u786c\u56fe\u7ed3\u6784\uff0c\u5b58\u5728\u4fe1\u606f\u635f\u5931\u548c\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u805a\u7c7b\u7ed3\u679c\u7684\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fascSGC\u65b9\u6cd5\uff0c\u5305\u542b\u57fa\u4e8e\u96f6\u81a8\u80c0\u8d1f\u4e8c\u9879\u5f0f\u7684\u7279\u5f81\u81ea\u52a8\u7f16\u7801\u5668\u3001\u53cc\u901a\u9053\u5207\u5272\u4fe1\u606f\u8f6f\u56fe\u5d4c\u5165\u6a21\u5757\u548c\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u805a\u7c7b\u4f18\u5316\u6a21\u5757\u3002", "result": "\u5728\u5341\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cscSGC\u5728\u805a\u7c7b\u51c6\u786e\u6027\u3001\u7ec6\u80de\u7c7b\u578b\u6ce8\u91ca\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e13\u79cd\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "scSGC\u6709\u5de8\u5927\u6f5c\u529b\u63a8\u52a8\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u5206\u6790\uff0c\u52a0\u6df1\u5bf9\u7ec6\u80de\u5f02\u8d28\u6027\u7684\u7406\u89e3\u3002"}}
{"id": "2507.09149", "pdf": "https://arxiv.org/pdf/2507.09149", "abs": "https://arxiv.org/abs/2507.09149", "authors": ["Mkululi Sikosana", "Sean Maudsley-Barton", "Oluwaseun Ajao"], "title": "Advanced Health Misinformation Detection Through Hybrid CNN-LSTM Models Informed by the Elaboration Likelihood Model (ELM)", "categories": ["cs.SI", "cs.AI", "cs.CY", "cs.LG", "I.2.7; J.4"], "comment": "11 Pages, 2 Figures, 3 Tables conference paper to appear in\n  proceedings of International Conference on Artificial Intelligence, Computer,\n  Data Sciences and Applications (ACDSA'25)", "summary": "Health misinformation during the COVID-19 pandemic has significantly\nchallenged public health efforts globally. This study applies the Elaboration\nLikelihood Model (ELM) to enhance misinformation detection on social media\nusing a hybrid Convolutional Neural Network (CNN) and Long Short-Term Memory\n(LSTM) model. The model aims to enhance the detection accuracy and reliability\nof misinformation classification by integrating ELM-based features such as text\nreadability, sentiment polarity, and heuristic cues (e.g., punctuation\nfrequency). The enhanced model achieved an accuracy of 97.37%, precision of\n96.88%, recall of 98.50%, F1-score of 97.41%, and ROC-AUC of 99.50%. A combined\nmodel incorporating feature engineering further improved performance, achieving\na precision of 98.88%, recall of 99.80%, F1-score of 99.41%, and ROC-AUC of\n99.80%. These findings highlight the value of ELM features in improving\ndetection performance, offering valuable contextual information. This study\ndemonstrates the practical application of psychological theories in developing\nadvanced machine learning algorithms to address health misinformation\neffectively.", "AI": {"tldr": "\u672c\u6587\u8fd0\u7528ELM\u548c\u6df7\u5408CNN-LSTM\u6a21\u578b\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u5065\u5eb7\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u6027\u80fd\uff0c\u7ed3\u5408\u7279\u5f81\u5de5\u7a0b\u540e\u6a21\u578b\u8868\u73b0\u66f4\u4f73\uff0c\u8bc1\u660e\u5fc3\u7406\u5b66\u7406\u8bba\u5728\u89e3\u51b3\u5065\u5eb7\u9519\u8bef\u4fe1\u606f\u65b9\u9762\u7684\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u65b0\u51a0\u75ab\u60c5\u671f\u95f4\u5065\u5eb7\u9519\u8bef\u4fe1\u606f\u5bf9\u5168\u7403\u516c\u5171\u536b\u751f\u5de5\u4f5c\u6784\u6210\u6311\u6218\uff0c\u9700\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u5e94\u7528Elaboration Likelihood Model (ELM)\uff0c\u7ed3\u5408\u6df7\u5408Convolutional Neural Network (CNN)\u548cLong Short-Term Memory (LSTM)\u6a21\u578b\uff0c\u878d\u5165ELM\u7279\u5f81\u5982\u6587\u672c\u53ef\u8bfb\u6027\u3001\u60c5\u611f\u6781\u6027\u548c\u542f\u53d1\u5f0f\u7ebf\u7d22\u3002", "result": "\u589e\u5f3a\u6a21\u578b\u51c6\u786e\u738797.37%\u7b49\uff1b\u7ed3\u5408\u7279\u5f81\u5de5\u7a0b\u540e\uff0c\u7cbe\u5ea6\u8fbe98.88%\u7b49\u3002", "conclusion": "ELM\u7279\u5f81\u5bf9\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u6709\u4ef7\u503c\uff0c\u5c55\u793a\u4e86\u5fc3\u7406\u5b66\u7406\u8bba\u5728\u5f00\u53d1\u5148\u8fdb\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u5065\u5eb7\u9519\u8bef\u4fe1\u606f\u65b9\u9762\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.09897", "pdf": "https://arxiv.org/pdf/2507.09897", "abs": "https://arxiv.org/abs/2507.09897", "authors": ["Loek van Rossem", "Andrew M. Saxe"], "title": "Algorithm Development in Neural Networks: Insights from the Streaming Parity Task", "categories": ["cs.LG", "q-bio.NC"], "comment": "28 pages, 20 figures", "summary": "Even when massively overparameterized, deep neural networks show a remarkable\nability to generalize. Research on this phenomenon has focused on\ngeneralization within distribution, via smooth interpolation. Yet in some\nsettings neural networks also learn to extrapolate to data far beyond the\nbounds of the original training set, sometimes even allowing for infinite\ngeneralization, implying that an algorithm capable of solving the task has been\nlearned. Here we undertake a case study of the learning dynamics of recurrent\nneural networks (RNNs) trained on the streaming parity task in order to develop\nan effective theory of algorithm development. The streaming parity task is a\nsimple but nonlinear task defined on sequences up to arbitrary length. We show\nthat, with sufficient finite training experience, RNNs exhibit a phase\ntransition to perfect infinite generalization. Using an effective theory for\nthe representational dynamics, we find an implicit representational merger\neffect which can be interpreted as the construction of a finite automaton that\nreproduces the task. Overall, our results disclose one mechanism by which\nneural networks can generalize infinitely from finite training experience.", "AI": {"tldr": "\u7814\u7a76RNN\u5728\u6d41\u5f0f\u5947\u5076\u6821\u9a8c\u4efb\u52a1\u4e0a\u5b66\u4e60\u52a8\u6001\uff0c\u53d1\u73b0\u6709\u9650\u8bad\u7ec3\u540e\u53ef\u5b9e\u73b0\u5b8c\u7f8e\u65e0\u9650\u6cdb\u5316\u53ca\u9690\u5f0f\u8868\u5f81\u5408\u5e76\u6548\u5e94\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u591a\u5173\u6ce8\u795e\u7ecf\u7f51\u7edc\u5206\u5e03\u5185\u6cdb\u5316\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u5176\u4ece\u6709\u9650\u8bad\u7ec3\u7ecf\u9a8c\u8fdb\u884c\u65e0\u9650\u6cdb\u5316\u7684\u673a\u5236\uff0c\u4ee5\u5f00\u53d1\u6709\u6548\u7684\u7b97\u6cd5\u53d1\u5c55\u7406\u8bba\u3002", "method": "\u4ee5\u6d41\u5f0f\u5947\u5076\u6821\u9a8c\u4efb\u52a1\u5bf9RNN\u8fdb\u884c\u8bad\u7ec3\uff0c\u7814\u7a76\u5176\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u8fd0\u7528\u8868\u5f81\u52a8\u529b\u5b66\u7684\u6709\u6548\u7406\u8bba\u5206\u6790\u3002", "result": "RNN\u5728\u8db3\u591f\u6709\u9650\u8bad\u7ec3\u540e\u51fa\u73b0\u5411\u5b8c\u7f8e\u65e0\u9650\u6cdb\u5316\u7684\u76f8\u53d8\uff0c\u5b58\u5728\u9690\u5f0f\u8868\u5f81\u5408\u5e76\u6548\u5e94\uff0c\u53ef\u89e3\u91ca\u4e3a\u6784\u5efa\u80fd\u91cd\u73b0\u4efb\u52a1\u7684\u6709\u9650\u81ea\u52a8\u673a\u3002", "conclusion": "\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u4ece\u6709\u9650\u8bad\u7ec3\u7ecf\u9a8c\u8fdb\u884c\u65e0\u9650\u6cdb\u5316\u7684\u4e00\u79cd\u673a\u5236\u3002"}}
{"id": "2507.09155", "pdf": "https://arxiv.org/pdf/2507.09155", "abs": "https://arxiv.org/abs/2507.09155", "authors": ["Ali Vosoughi", "Ayoub Shahnazari", "Yufeng Xi", "Zeliang Zhang", "Griffin Hess", "Chenliang Xu", "Niaz Abdolrahim"], "title": "OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering", "categories": ["cs.CL", "cs.AI", "68T50, 68T07"], "comment": "10 pages, 6 figures, 5 tables. Code and dataset available at\n  https://github.com/niaz60/OpenXRD. Project webpage:\n  https://niaz60.github.io/OpenXRD/", "summary": "This work presents OPENXRD, an open-book pipeline designed for\ncrystallography question answering, which integrates textual prompts with\nconcise supporting content generated by GPT-4.5. Instead of using scanned\ntextbooks, which may lead to copyright issues, OPENXRD generates compact,\ndomain-specific references that help smaller models understand key concepts in\nX-ray diffraction (XRD). We evaluate OPENXRD on a well-defined set of 217\nexpert-level XRD questions by comparing different vision-language models,\nincluding GPT-4 and LLaVA-based frameworks such as Mistral, LLaMA, and QWEN,\nunder both closed-book (without supporting material) and open-book (with\nsupporting material) conditions. Our experimental results show significant\naccuracy improvements in models that use the GPT-4.5-generated summaries,\nparticularly those with limited prior training in crystallography. OPENXRD uses\nknowledge from larger models to fill knowledge gaps in crystallography and\nshows that AI-generated texts can help smaller models reason more effectively\nin scientific tasks. While the current version of OPENXRD focuses on text-based\ninputs, we also explore future extensions such as adding real crystal diagrams\nor diffraction patterns to improve interpretation in specialized materials\nscience contexts. Overall, OPENXRD shows that specialized open-book systems can\nbe useful in materials science and provides a foundation for broader natural\nlanguage processing (NLP) tools in critical scientific fields.", "AI": {"tldr": "\u63d0\u51faOPENXRD\u7528\u4e8e\u6676\u4f53\u5b66\u95ee\u7b54\uff0c\u7ed3\u5408GPT - 4.5\u751f\u6210\u5185\u5bb9\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u63d0\u5347\u6a21\u578b\u51c6\u786e\u7387\uff0c\u672a\u6765\u6709\u6269\u5c55\u65b9\u5411\u3002", "motivation": "\u907f\u514d\u4f7f\u7528\u626b\u63cf\u6559\u6750\u5e26\u6765\u7684\u7248\u6743\u95ee\u9898\uff0c\u5229\u7528\u5927\u6a21\u578b\u77e5\u8bc6\u586b\u8865\u6676\u4f53\u5b66\u77e5\u8bc6\u7a7a\u767d\uff0c\u63d0\u5347\u5c0f\u6a21\u578b\u5728\u79d1\u5b66\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1OPENXRD\u96c6\u6210\u6587\u672c\u63d0\u793a\u4e0eGPT - 4.5\u751f\u6210\u5185\u5bb9\uff0c\u5728217\u4e2aXRD\u95ee\u9898\u4e0a\u5bf9\u6bd4\u4e0d\u540c\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\u5728\u95ed\u5377\u548c\u5f00\u5377\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u4f7f\u7528GPT - 4.5\u751f\u6210\u6458\u8981\u7684\u6a21\u578b\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u662f\u6676\u4f53\u5b66\u8bad\u7ec3\u6709\u9650\u7684\u6a21\u578b\u3002", "conclusion": "\u4e13\u95e8\u7684\u5f00\u5377\u7cfb\u7edf\u5728\u6750\u6599\u79d1\u5b66\u4e2d\u6709\u7528\uff0c\u4e3a\u5173\u952e\u79d1\u5b66\u9886\u57df\u7684NLP\u5de5\u5177\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2507.09925", "pdf": "https://arxiv.org/pdf/2507.09925", "abs": "https://arxiv.org/abs/2507.09925", "authors": ["Md Ahsanul Kabir", "Abrar Jahin", "Mohammad Al Hasan"], "title": "Extracting Cause-Effect Pairs from a Sentence with a Dependency-Aware Transformer Model", "categories": ["cs.LG"], "comment": null, "summary": "Extracting cause and effect phrases from a sentence is an important NLP task,\nwith numerous applications in various domains, including legal, medical,\neducation, and scientific research. There are many unsupervised and supervised\nmethods proposed for solving this task. Among these, unsupervised methods\nutilize various linguistic tools, including syntactic patterns, dependency\ntree, dependency relations, etc. among different sentential units for\nextracting the cause and effect phrases. On the other hand, the contemporary\nsupervised methods use various deep learning based mask language models\nequipped with a token classification layer for extracting cause and effect\nphrases. Linguistic tools, specifically, dependency tree, which organizes a\nsentence into different semantic units have been shown to be very effective for\nextracting semantic pairs from a sentence, but existing supervised methods do\nnot have any provision for utilizing such tools within their model framework.\nIn this work, we propose DepBERT, which extends a transformer-based model by\nincorporating dependency tree of a sentence within the model framework.\nExtensive experiments over three datasets show that DepBERT is better than\nvarious state-of-the art supervised causality extraction methods.", "AI": {"tldr": "\u63d0\u51faDepBERT\u6a21\u578b\u7528\u4e8e\u56e0\u679c\u77ed\u8bed\u63d0\u53d6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u76d1\u7763\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u76d1\u7763\u56e0\u679c\u77ed\u8bed\u63d0\u53d6\u65b9\u6cd5\u672a\u5229\u7528\u4f9d\u8d56\u6811\u7b49\u8bed\u8a00\u5de5\u5177\uff0c\u5e0c\u671b\u6539\u8fdb\u3002", "method": "\u63d0\u51faDepBERT\uff0c\u5728\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u6846\u67b6\u4e2d\u878d\u5165\u53e5\u5b50\u7684\u4f9d\u8d56\u6811\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDepBERT\u4f18\u4e8e\u5404\u79cd\u73b0\u6709\u76d1\u7763\u56e0\u679c\u63d0\u53d6\u65b9\u6cd5\u3002", "conclusion": "DepBERT\u6a21\u578b\u662f\u4e00\u79cd\u6709\u6548\u7684\u56e0\u679c\u77ed\u8bed\u63d0\u53d6\u65b9\u6cd5\uff0c\u5229\u7528\u4f9d\u8d56\u6811\u80fd\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.09158", "pdf": "https://arxiv.org/pdf/2507.09158", "abs": "https://arxiv.org/abs/2507.09158", "authors": ["Sunil Munthumoduku Krishna Murthy", "Kumar Rajamani", "Srividya Tirunellai Rajamani", "Yupei Li", "Qiyang Sun", "Bjoern W. Schuller"], "title": "Automatic Contouring of Spinal Vertebrae on X-Ray using a Novel Sandwich U-Net Architecture", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "In spinal vertebral mobility disease, accurately extracting and contouring\nvertebrae is essential for assessing mobility impairments and monitoring\nvariations during flexion-extension movements. Precise vertebral contouring\nplays a crucial role in surgical planning; however, this process is\ntraditionally performed manually by radiologists or surgeons, making it\nlabour-intensive, time-consuming, and prone to human error. In particular,\nmobility disease analysis requires the individual contouring of each vertebra,\nwhich is both tedious and susceptible to inconsistencies. Automated methods\nprovide a more efficient alternative, enabling vertebra identification,\nsegmentation, and contouring with greater accuracy and reduced time\nconsumption. In this study, we propose a novel U-Net variation designed to\naccurately segment thoracic vertebrae from anteroposterior view on X-Ray\nimages. Our proposed approach, incorporating a ``sandwich\" U-Net structure with\ndual activation functions, achieves a 4.1\\% improvement in Dice score compared\nto the baseline U-Net model, enhancing segmentation accuracy while ensuring\nreliable vertebral contour extraction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578bU - Net\u53d8\u4f53\u7528\u4e8eX\u5c04\u7ebf\u56fe\u50cf\u80f8\u690e\u5206\u5272\uff0c\u6bd4\u57fa\u7ebf\u6a21\u578bDice\u5f97\u5206\u63d0\u9ad84.1%\uff0c\u63d0\u5347\u5206\u5272\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u624b\u52a8\u810a\u690e\u8f6e\u5ed3\u63d0\u53d6\u52b3\u52a8\u5f3a\u5ea6\u5927\u3001\u8017\u65f6\u957f\u4e14\u6613\u51fa\u9519\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578bU - Net\u53d8\u4f53\uff0c\u91c7\u7528\u201c\u4e09\u660e\u6cbb\u201dU - Net\u7ed3\u6784\u548c\u53cc\u6fc0\u6d3b\u51fd\u6570\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebfU - Net\u6a21\u578b\uff0cDice\u5f97\u5206\u63d0\u9ad84.1%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5206\u5272\u51c6\u786e\u6027\uff0c\u80fd\u53ef\u9760\u5730\u63d0\u53d6\u810a\u690e\u8f6e\u5ed3\u3002"}}
{"id": "2507.09931", "pdf": "https://arxiv.org/pdf/2507.09931", "abs": "https://arxiv.org/abs/2507.09931", "authors": ["Yoon Pyo Lee"], "title": "Mechanistic Interpretability of LoRA-Adapted Language Models for Nuclear Reactor Safety Applications", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Nuclear Technology. 22 pages, 2 tables, 4 figures", "summary": "The integration of Large Language Models (LLMs) into safety-critical domains,\nsuch as nuclear engineering, necessitates a deep understanding of their\ninternal reasoning processes. This paper presents a novel methodology for\ninterpreting how an LLM encodes and utilizes domain-specific knowledge, using a\nBoiling Water Reactor system as a case study. We adapted a general-purpose LLM\n(Gemma-3-1b-it) to the nuclear domain using a parameter-efficient fine-tuning\ntechnique known as Low-Rank Adaptation. By comparing the neuron activation\npatterns of the base model to those of the fine-tuned model, we identified a\nsparse set of neurons whose behavior was significantly altered during the\nadaptation process. To probe the causal role of these specialized neurons, we\nemployed a neuron silencing technique. Our results demonstrate that while\nsilencing most of these specialized neurons individually did not produce a\nstatistically significant effect, deactivating the entire group collectively\nled to a statistically significant degradation in task performance. Qualitative\nanalysis further revealed that silencing these neurons impaired the model's\nability to generate detailed, contextually accurate technical information. This\npaper provides a concrete methodology for enhancing the transparency of an\nopaque black-box model, allowing domain expertise to be traced to verifiable\nneural circuits. This offers a pathway towards achieving nuclear-grade\nartificial intelligence (AI) assurance, addressing the verification and\nvalidation challenges mandated by nuclear regulatory frameworks (e.g., 10 CFR\n50 Appendix B), which have limited AI deployment in safety-critical nuclear\noperations.", "AI": {"tldr": "\u672c\u6587\u4ee5\u6cb8\u6c34\u53cd\u5e94\u5806\u7cfb\u7edf\u4e3a\u4f8b\uff0c\u63d0\u51fa\u89e3\u91ca\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u548c\u5229\u7528\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03\u6a21\u578b\u3001\u5bf9\u6bd4\u795e\u7ecf\u5143\u6fc0\u6d3b\u6a21\u5f0f\u3001\u91c7\u7528\u795e\u7ecf\u5143\u6c89\u9ed8\u6280\u672f\u7b49\uff0c\u4e3a\u63d0\u5347\u9ed1\u76d2\u6a21\u578b\u900f\u660e\u5ea6\u3001\u5b9e\u73b0\u6838\u7ea7AI\u4fdd\u8bc1\u63d0\u4f9b\u9014\u5f84\u3002", "motivation": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u6838\u5de5\u7a0b\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u9700\u6df1\u5165\u7406\u89e3\u5176\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u4f4e\u79e9\u81ea\u9002\u5e94\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u5c06\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578bGemma - 3 - 1b - it\u9002\u914d\u5230\u6838\u9886\u57df\uff0c\u5bf9\u6bd4\u57fa\u7840\u6a21\u578b\u548c\u5fae\u8c03\u6a21\u578b\u7684\u795e\u7ecf\u5143\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u91c7\u7528\u795e\u7ecf\u5143\u6c89\u9ed8\u6280\u672f\u63a2\u7a76\u7279\u5b9a\u795e\u7ecf\u5143\u7684\u56e0\u679c\u4f5c\u7528\u3002", "result": "\u5355\u72ec\u6c89\u9ed8\u5927\u90e8\u5206\u7279\u5b9a\u795e\u7ecf\u5143\u65e0\u663e\u8457\u5f71\u54cd\uff0c\u96c6\u4f53\u505c\u7528\u5219\u5bfc\u81f4\u4efb\u52a1\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u5b9a\u6027\u5206\u6790\u8868\u660e\u6c89\u9ed8\u8fd9\u4e9b\u795e\u7ecf\u5143\u4f1a\u524a\u5f31\u6a21\u578b\u751f\u6210\u8be6\u7ec6\u3001\u4e0a\u4e0b\u6587\u51c6\u786e\u6280\u672f\u4fe1\u606f\u7684\u80fd\u529b\u3002", "conclusion": "\u63d0\u4f9b\u589e\u5f3a\u4e0d\u900f\u660e\u9ed1\u76d2\u6a21\u578b\u900f\u660e\u5ea6\u7684\u5177\u4f53\u65b9\u6cd5\uff0c\u4e3a\u5b9e\u73b0\u6838\u7ea7AI\u4fdd\u8bc1\u63d0\u4f9b\u9014\u5f84\uff0c\u89e3\u51b3\u6838\u76d1\u7ba1\u6846\u67b6\u4e0bAI\u90e8\u7f72\u7684\u9a8c\u8bc1\u6311\u6218\u3002"}}
{"id": "2507.09937", "pdf": "https://arxiv.org/pdf/2507.09937", "abs": "https://arxiv.org/abs/2507.09937", "authors": ["Gaurav R. Ghosal", "Pratyush Maini", "Aditi Raghunathan"], "title": "Memorization Sinks: Isolating Memorization during LLM Training", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at the 2025 International Conference of Machine Learning", "summary": "Large language models are susceptible to memorizing repeated sequences,\nposing privacy and copyright concerns. A popular mitigation strategy is to\nremove memorized information from specific neurons post-hoc. However, such\napproaches have shown limited success so far. In a controlled setting, we show\nthat the memorization of natural sequences (those that resemble linguistically\nplausible text) become mechanistically entangled with general language\nabilities, thereby becoming challenging to remove post-hoc. In this work, we\nput forward a new paradigm of MemSinks that promotes isolation of memorization\nby design. We leverage a sequence identifier that activates a unique set of\nmemorization neurons for each sequence across repetitions. By analyzing the\ndynamics of learning and forgetting, we argue that MemSinks facilitates\nisolation of memorized content, making it easier to remove without compromising\ngeneral language capabilities. We implement MemSinks at the billion-parameter\nand billion-token scale, and observe both effective isolation and strong\ngeneralization. To our knowledge, this is the first proof-of-concept on real\ndata demonstrating that simultaneous generalization and isolation is\nachievable. We open-source our code at http://github.com/grghosal/MemSinks.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u6613\u8bb0\u5fc6\u91cd\u590d\u5e8f\u5217\uff0c\u73b0\u6709\u53bb\u9664\u8bb0\u5fc6\u4fe1\u606f\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u672c\u6587\u63d0\u51faMemSinks\u8303\u5f0f\uff0c\u5b9e\u73b0\u8bb0\u5fc6\u5185\u5bb9\u9694\u79bb\u4e14\u4e0d\u5f71\u54cd\u6cdb\u5316\u80fd\u529b\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u8bb0\u5fc6\u91cd\u590d\u5e8f\u5217\u5e26\u6765\u7684\u9690\u79c1\u548c\u7248\u6743\u95ee\u9898\uff0c\u6539\u8fdb\u73b0\u6709\u53bb\u9664\u8bb0\u5fc6\u4fe1\u606f\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u7684\u60c5\u51b5\u3002", "method": "\u63d0\u51faMemSinks\u8303\u5f0f\uff0c\u5229\u7528\u5e8f\u5217\u6807\u8bc6\u7b26\u6fc0\u6d3b\u7279\u5b9a\u8bb0\u5fc6\u795e\u7ecf\u5143\uff0c\u5206\u6790\u5b66\u4e60\u548c\u9057\u5fd8\u52a8\u6001\u3002", "result": "\u5728\u5341\u4ebf\u53c2\u6570\u548c\u5341\u4ebf\u4ee4\u724c\u89c4\u6a21\u5b9e\u73b0MemSinks\uff0c\u89c2\u5bdf\u5230\u6709\u6548\u9694\u79bb\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u9996\u6b21\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u8bc1\u660e\u540c\u65f6\u5b9e\u73b0\u6cdb\u5316\u548c\u9694\u79bb\u662f\u53ef\u884c\u7684\u3002"}}
{"id": "2507.09940", "pdf": "https://arxiv.org/pdf/2507.09940", "abs": "https://arxiv.org/abs/2507.09940", "authors": ["Taigo Sakai", "Kazuhiro Hotta"], "title": "Long-Tailed Data Classification by Increasing and Decreasing Neurons During Training", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "In conventional deep learning, the number of neurons typically remains fixed\nduring training. However, insights from biology suggest that the human\nhippocampus undergoes continuous neuron generation and pruning of neurons over\nthe course of learning, implying that a flexible allocation of capacity can\ncontribute to enhance performance. Real-world datasets often exhibit class\nimbalance situations where certain classes have far fewer samples than others,\nleading to significantly reduce recognition accuracy for minority classes when\nrelying on fixed size networks.To address the challenge, we propose a method\nthat periodically adds and removes neurons during training, thereby boosting\nrepresentational power for minority classes. By retaining critical features\nlearned from majority classes while selectively increasing neurons for\nunderrepresented classes, our approach dynamically adjusts capacity during\ntraining. Importantly, while the number of neurons changes throughout training,\nthe final network size and structure remain unchanged, ensuring efficiency and\ncompatibility with deployment.Furthermore, by experiments on three different\ndatasets and five representative models, we demonstrate that the proposed\nmethod outperforms fixed size networks and shows even greater accuracy when\ncombined with other imbalance-handling techniques. Our results underscore the\neffectiveness of dynamic, biologically inspired network designs in improving\nperformance on class-imbalanced data.", "AI": {"tldr": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u65f6\u795e\u7ecf\u5143\u6570\u91cf\u56fa\u5b9a\uff0c\u672c\u6587\u63d0\u51fa\u8bad\u7ec3\u4e2d\u5b9a\u671f\u589e\u51cf\u795e\u7ecf\u5143\u7684\u65b9\u6cd5\uff0c\u5728\u4e09\u7c7b\u6570\u636e\u96c6\u548c\u4e94\u4e2a\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u56fa\u5b9a\u5927\u5c0f\u7f51\u7edc\uff0c\u80fd\u63d0\u5347\u4e0d\u5747\u8861\u6570\u636e\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u795e\u7ecf\u5143\u6570\u91cf\u56fa\u5b9a\uff0c\u800c\u751f\u7269\u5b66\u4e60\u4e2d\u795e\u7ecf\u5143\u4f1a\u52a8\u6001\u53d8\u5316\uff0c\u4e14\u73b0\u5b9e\u6570\u636e\u5b58\u5728\u7c7b\u522b\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u56fa\u5b9a\u7f51\u7edc\u4f1a\u964d\u4f4e\u5c11\u6570\u7c7b\u8bc6\u522b\u7cbe\u5ea6\u3002", "method": "\u8bad\u7ec3\u4e2d\u5b9a\u671f\u589e\u51cf\u795e\u7ecf\u5143\uff0c\u4fdd\u7559\u591a\u6570\u7c7b\u5173\u952e\u7279\u5f81\uff0c\u4e3a\u5c11\u6570\u7c7b\u9009\u62e9\u6027\u589e\u52a0\u795e\u7ecf\u5143\uff0c\u52a8\u6001\u8c03\u6574\u7f51\u7edc\u5bb9\u91cf\uff0c\u4e14\u6700\u7ec8\u7f51\u7edc\u5927\u5c0f\u548c\u7ed3\u6784\u4e0d\u53d8\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u548c\u4e94\u4e2a\u4ee3\u8868\u6027\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u56fa\u5b9a\u5927\u5c0f\u7f51\u7edc\uff0c\u4e0e\u5176\u4ed6\u5904\u7406\u4e0d\u5747\u8861\u6280\u672f\u7ed3\u5408\u65f6\u7cbe\u5ea6\u66f4\u9ad8\u3002", "conclusion": "\u52a8\u6001\u7684\u3001\u53d7\u751f\u7269\u542f\u53d1\u7684\u7f51\u7edc\u8bbe\u8ba1\u80fd\u6709\u6548\u63d0\u5347\u7c7b\u522b\u4e0d\u5747\u8861\u6570\u636e\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09948", "pdf": "https://arxiv.org/pdf/2507.09948", "abs": "https://arxiv.org/abs/2507.09948", "authors": ["Zijian Ding", "Tung Nguyen", "Weikai Li", "Aditya Grover", "Yizhou Sun", "Jason Cong"], "title": "Iceberg: Enhancing HLS Modeling with Synthetic Data", "categories": ["cs.LG", "cs.AR"], "comment": "9 pages. accepted to ICLAD'25", "summary": "Deep learning-based prediction models for High-Level Synthesis (HLS) of\nhardware designs often struggle to generalize. In this paper, we study how to\nclose the generalizability gap of these models through pretraining on synthetic\ndata and introduce Iceberg, a synthetic data augmentation approach that expands\nboth large language model (LLM)-generated programs and weak labels of unseen\ndesign configurations. Our weak label generation method is integrated with an\nin-context model architecture, enabling meta-learning from actual and proximate\nlabels. Iceberg improves the geometric mean modeling accuracy by $86.4\\%$ when\nadapt to six real-world applications with few-shot examples and achieves a\n$2.47\\times$ and a $1.12\\times$ better offline DSE performance when adapting to\ntwo different test datasets. Our open-sourced code is here:\n\\href{https://github.com/UCLA-VAST/iceberg}{https://github.com/UCLA-VAST/iceberg}", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u901a\u8fc7\u5408\u6210\u6570\u636e\u9884\u8bad\u7ec3\u7f29\u5c0f\u786c\u4ef6\u8bbe\u8ba1\u9ad8\u7ea7\u7efc\u5408\uff08HLS\uff09\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u6cdb\u5316\u5dee\u8ddd\uff0c\u63d0\u51faIceberg\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5efa\u6a21\u7cbe\u5ea6\u548c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff08DSE\uff09\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u786c\u4ef6\u8bbe\u8ba1\u9ad8\u7ea7\u7efc\u5408\uff08HLS\uff09\u9884\u6d4b\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faIceberg\u5408\u6210\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7a0b\u5e8f\u548c\u672a\u89c1\u8bbe\u8ba1\u914d\u7f6e\u7684\u5f31\u6807\u7b7e\uff0c\u5c06\u5f31\u6807\u7b7e\u751f\u6210\u65b9\u6cd5\u4e0e\u4e0a\u4e0b\u6587\u6a21\u578b\u67b6\u6784\u96c6\u6210\u4ee5\u5b9e\u73b0\u5143\u5b66\u4e60\u3002", "result": "\u5728\u9002\u5e94\u516d\u4e2a\u73b0\u5b9e\u5e94\u7528\u7684\u5c11\u6837\u672c\u793a\u4f8b\u65f6\uff0c\u51e0\u4f55\u5e73\u5747\u5efa\u6a21\u7cbe\u5ea6\u63d0\u9ad886.4%\uff1b\u5728\u9002\u5e94\u4e24\u4e2a\u4e0d\u540c\u6d4b\u8bd5\u6570\u636e\u96c6\u65f6\uff0c\u79bb\u7ebfDSE\u6027\u80fd\u5206\u522b\u63d0\u53472.47\u500d\u548c1.12\u500d\u3002", "conclusion": "Iceberg\u65b9\u6cd5\u6709\u6548\u7f29\u5c0f\u4e86\u786c\u4ef6\u8bbe\u8ba1HLS\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u7684\u6cdb\u5316\u5dee\u8ddd\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2507.09227", "pdf": "https://arxiv.org/pdf/2507.09227", "abs": "https://arxiv.org/abs/2507.09227", "authors": ["Sanyam Jain", "Bruna Neves de Freitas", "Andreas Basse-OConnor", "Alexandros Iosifidis", "Ruben Pauwels"], "title": "PanoDiff-SR: Synthesizing Dental Panoramic Radiographs using Diffusion and Super-resolution", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "There has been increasing interest in the generation of high-quality,\nrealistic synthetic medical images in recent years. Such synthetic datasets can\nmitigate the scarcity of public datasets for artificial intelligence research,\nand can also be used for educational purposes. In this paper, we propose a\ncombination of diffusion-based generation (PanoDiff) and Super-Resolution (SR)\nfor generating synthetic dental panoramic radiographs (PRs). The former\ngenerates a low-resolution (LR) seed of a PR (256 X 128) which is then\nprocessed by the SR model to yield a high-resolution (HR) PR of size 1024 X\n512. For SR, we propose a state-of-the-art transformer that learns local-global\nrelationships, resulting in sharper edges and textures. Experimental results\ndemonstrate a Frechet inception distance score of 40.69 between 7243 real and\nsynthetic images (in HR). Inception scores were 2.55, 2.30, 2.90 and 2.98 for\nreal HR, synthetic HR, real LR and synthetic LR images, respectively. Among a\ndiverse group of six clinical experts, all evaluating a mixture of 100\nsynthetic and 100 real PRs in a time-limited observation, the average accuracy\nin distinguishing real from synthetic images was 68.5% (with 50% corresponding\nto random guessing).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u6269\u6563\u751f\u6210\u548c\u8d85\u5206\u8fa8\u7387\u6280\u672f\u751f\u6210\u5408\u6210\u7259\u79d1\u5168\u666fX\u5149\u7247\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u826f\u597d\uff0c\u4e13\u5bb6\u533a\u5206\u771f\u5047\u56fe\u50cf\u51c6\u786e\u7387\u4e3a68.5%\u3002", "motivation": "\u7f13\u89e3\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u4e2d\u516c\u5171\u533b\u5b66\u56fe\u50cf\u6570\u636e\u96c6\u7a00\u7f3a\u95ee\u9898\uff0c\u540c\u65f6\u7528\u4e8e\u6559\u80b2\u76ee\u7684\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\uff08PanoDiff\uff09\u548c\u8d85\u5206\u8fa8\u7387\uff08SR\uff09\u6280\u672f\u751f\u6210\u5408\u6210\u7259\u79d1\u5168\u666fX\u5149\u7247\uff0cSR\u91c7\u7528\u5b66\u4e60\u5c40\u90e8 - \u5168\u5c40\u5173\u7cfb\u7684Transformer\u3002", "result": "\u771f\u5b9e\u548c\u5408\u6210\u7684\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u4e4b\u95f4\u7684Fr\u00e9chet inception\u8ddd\u79bb\u5206\u6570\u4e3a40.69\uff1b\u4e0d\u540c\u56fe\u50cf\u7684Inception\u5206\u6570\u5206\u522b\u4e3a2.55\u30012.30\u30012.90\u548c2.98\uff1b\u4e13\u5bb6\u533a\u5206\u771f\u5047\u56fe\u50cf\u5e73\u5747\u51c6\u786e\u7387\u4e3a68.5%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u5408\u6210\u7259\u79d1\u5168\u666fX\u5149\u7247\u3002"}}
{"id": "2507.09949", "pdf": "https://arxiv.org/pdf/2507.09949", "abs": "https://arxiv.org/abs/2507.09949", "authors": ["Md Ahsanul Kabir", "Kareem Abdelfatah", "Mohammed Korayem", "Mohammad Al Hasan"], "title": "Hierarchical Job Classification with Similarity Graph Integration", "categories": ["cs.LG"], "comment": null, "summary": "In the dynamic realm of online recruitment, accurate job classification is\nparamount for optimizing job recommendation systems, search rankings, and labor\nmarket analyses. As job markets evolve, the increasing complexity of job titles\nand descriptions necessitates sophisticated models that can effectively\nleverage intricate relationships within job data. Traditional text\nclassification methods often fall short, particularly due to their inability to\nfully utilize the hierarchical nature of industry categories. To address these\nlimitations, we propose a novel representation learning and classification\nmodel that embeds jobs and hierarchical industry categories into a latent\nembedding space. Our model integrates the Standard Occupational Classification\n(SOC) system and an in-house hierarchical taxonomy, Carotene, to capture both\ngraph and hierarchical relationships, thereby improving classification\naccuracy. By embedding hierarchical industry categories into a shared latent\nspace, we tackle cold start issues and enhance the dynamic matching of\ncandidates to job opportunities. Extensive experimentation on a large-scale\ndataset of job postings demonstrates the model's superior ability to leverage\nhierarchical structures and rich semantic features, significantly outperforming\nexisting methods. This research provides a robust framework for improving job\nclassification accuracy, supporting more informed decision-making in the\nrecruitment industry.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u8868\u793a\u5b66\u4e60\u548c\u5206\u7c7b\u6a21\u578b\u63d0\u5347\u5728\u7ebf\u62db\u8058\u4e2d\u5de5\u4f5c\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u5206\u7c7b\u65b9\u6cd5\u96be\u4ee5\u5229\u7528\u884c\u4e1a\u7c7b\u522b\u5c42\u6b21\u7ed3\u6784\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5728\u7ebf\u62db\u8058\u4e2d\u590d\u6742\u5de5\u4f5c\u6570\u636e\u5206\u7c7b\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u65b0\u6a21\u578b\uff0c\u5c06\u5de5\u4f5c\u548c\u5c42\u6b21\u5316\u884c\u4e1a\u7c7b\u522b\u5d4c\u5165\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\uff0c\u6574\u5408SOC\u7cfb\u7edf\u548cCarotene\u5206\u7c7b\u6cd5\u3002", "result": "\u5728\u5927\u89c4\u6a21\u62db\u8058\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u578b\u5229\u7528\u5c42\u6b21\u7ed3\u6784\u548c\u8bed\u4e49\u7279\u5f81\u80fd\u529b\u5f3a\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u4e3a\u63d0\u9ad8\u5de5\u4f5c\u5206\u7c7b\u51c6\u786e\u6027\u63d0\u4f9b\u4e86\u53ef\u9760\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u62db\u8058\u884c\u4e1a\u51b3\u7b56\u3002"}}
{"id": "2507.09248", "pdf": "https://arxiv.org/pdf/2507.09248", "abs": "https://arxiv.org/abs/2507.09248", "authors": ["Varsha Devi", "Amine Bohi", "Pardeep Kumar"], "title": "AGCD-Net: Attention Guided Context Debiasing Network for Emotion Recognition", "categories": ["cs.CV", "cs.AI"], "comment": "13 Pages, 4 figures, 2 tables ICIAP 2025", "summary": "Context-aware emotion recognition (CAER) enhances affective computing in\nreal-world scenarios, but traditional methods often suffer from context\nbias-spurious correlation between background context and emotion labels (e.g.\nassociating ``garden'' with ``happy''). In this paper, we propose\n\\textbf{AGCD-Net}, an Attention Guided Context Debiasing model that introduces\n\\textit{Hybrid ConvNeXt}, a novel convolutional encoder that extends the\nConvNeXt backbone by integrating Spatial Transformer Network and\nSqueeze-and-Excitation layers for enhanced feature recalibration. At the core\nof AGCD-Net is the Attention Guided - Causal Intervention Module (AG-CIM),\nwhich applies causal theory, perturbs context features, isolates spurious\ncorrelations, and performs an attention-driven correction guided by face\nfeatures to mitigate context bias. Experimental results on the CAER-S dataset\ndemonstrate the effectiveness of AGCD-Net, achieving state-of-the-art\nperformance and highlighting the importance of causal debiasing for robust\nemotion recognition in complex settings.", "AI": {"tldr": "\u63d0\u51faAGCD - Net\u6a21\u578b\u89e3\u51b3\u4e0a\u4e0b\u6587\u611f\u77e5\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u4e0a\u4e0b\u6587\u504f\u5dee\u95ee\u9898\uff0c\u5728CAER - S\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u4e0a\u4e0b\u6587\u611f\u77e5\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\u5b58\u5728\u4e0a\u4e0b\u6587\u504f\u5dee\u95ee\u9898\uff0c\u5373\u80cc\u666f\u4e0a\u4e0b\u6587\u4e0e\u60c5\u611f\u6807\u7b7e\u5b58\u5728\u865a\u5047\u5173\u8054\u3002", "method": "\u63d0\u51faAGCD - Net\u6a21\u578b\uff0c\u5f15\u5165Hybrid ConvNeXt\u7f16\u7801\u5668\u589e\u5f3a\u7279\u5f81\u91cd\u65b0\u6821\u51c6\uff0c\u6838\u5fc3\u662fAG - CIM\u6a21\u5757\uff0c\u8fd0\u7528\u56e0\u679c\u7406\u8bba\u6d88\u9664\u865a\u5047\u5173\u8054\u3002", "result": "\u5728CAER - S\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cAGCD - Net\u53d6\u5f97\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u56e0\u679c\u53bb\u504f\u5bf9\u590d\u6742\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u60c5\u611f\u8bc6\u522b\u975e\u5e38\u91cd\u8981\u3002"}}
{"id": "2507.09952", "pdf": "https://arxiv.org/pdf/2507.09952", "abs": "https://arxiv.org/abs/2507.09952", "authors": ["Zerui Zhang", "Yumou Qiu"], "title": "Radial Neighborhood Smoothing Recommender System", "categories": ["cs.LG", "stat.AP", "stat.ME", "68T01(General topics in artificial intelligence),\n  62G05(Nonparametric estimation)"], "comment": "34 pages, 2 figures. Submitted to NeurIPS 2025", "summary": "Recommender systems inherently exhibit a low-rank structure in latent space.\nA key challenge is to define meaningful and measurable distances in the latent\nspace to capture user-user, item-item, user-item relationships effectively. In\nthis work, we establish that distances in the latent space can be\nsystematically approximated using row-wise and column-wise distances in the\nobserved matrix, providing a novel perspective on distance estimation. To\nrefine the distance estimation, we introduce the correction based on empirical\nvariance estimator to account for noise-induced non-centrality. The novel\ndistance estimation enables a more structured approach to constructing\nneighborhoods, leading to the Radial Neighborhood Estimator (RNE), which\nconstructs neighborhoods by including both overlapped and partially overlapped\nuser-item pairs and employs neighborhood smoothing via localized kernel\nregression to improve imputation accuracy. We provide the theoretical\nasymptotic analysis for the proposed estimator. We perform evaluations on both\nsimulated and real-world datasets, demonstrating that RNE achieves superior\nperformance compared to existing collaborative filtering and matrix\nfactorization methods. While our primary focus is on distance estimation in\nlatent space, we find that RNE also mitigates the ``cold-start'' problem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u89c2\u6d4b\u77e9\u9635\u884c\u5217\u8ddd\u79bb\u4f30\u8ba1\u6f5c\u5728\u7a7a\u95f4\u8ddd\u79bb\u7684\u65b9\u6cd5\uff0c\u6784\u5efa\u5f84\u5411\u90bb\u57df\u4f30\u8ba1\u5668RNE\uff0c\u7406\u8bba\u5206\u6790\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u80fd\u7f13\u89e3\u51b7\u542f\u52a8\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u6f5c\u5728\u7a7a\u95f4\u6709\u610f\u4e49\u3001\u53ef\u6d4b\u91cf\u8ddd\u79bb\u7684\u5b9a\u4e49\u96be\u9898\uff0c\u4ee5\u6709\u6548\u6355\u6349\u7528\u6237-\u7528\u6237\u3001\u7269\u54c1-\u7269\u54c1\u3001\u7528\u6237-\u7269\u54c1\u5173\u7cfb\u3002", "method": "\u7528\u89c2\u6d4b\u77e9\u9635\u884c\u5217\u8ddd\u79bb\u8fd1\u4f3c\u6f5c\u5728\u7a7a\u95f4\u8ddd\u79bb\uff0c\u5f15\u5165\u57fa\u4e8e\u7ecf\u9a8c\u65b9\u5dee\u4f30\u8ba1\u5668\u7684\u6821\u6b63\uff0c\u6784\u5efaRNE\u5e76\u901a\u8fc7\u5c40\u90e8\u6838\u56de\u5f52\u8fdb\u884c\u90bb\u57df\u5e73\u6ed1\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cRNE\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u534f\u540c\u8fc7\u6ee4\u548c\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684RNE\u80fd\u6709\u6548\u8fdb\u884c\u6f5c\u5728\u7a7a\u95f4\u8ddd\u79bb\u4f30\u8ba1\uff0c\u8fd8\u53ef\u7f13\u89e3\u51b7\u542f\u52a8\u95ee\u9898\u3002"}}
{"id": "2507.09958", "pdf": "https://arxiv.org/pdf/2507.09958", "abs": "https://arxiv.org/abs/2507.09958", "authors": ["Zhenyuan Chen"], "title": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression", "categories": ["cs.LG"], "comment": null, "summary": "Inductive bias is a key factor in spatial regression models, determining how\nwell a model can learn from limited data and capture spatial patterns. This\nwork revisits the inductive biases in Geographically Neural Network Weighted\nRegression (GNNWR) and identifies limitations in current approaches for\nmodeling spatial non-stationarity. While GNNWR extends traditional\nGeographically Weighted Regression by using neural networks to learn spatial\nweighting functions, existing implementations are often restricted by fixed\ndistance-based schemes and limited inductive bias. We propose to generalize\nGNNWR by incorporating concepts from convolutional neural networks, recurrent\nneural networks, and transformers, introducing local receptive fields,\nsequential context, and self-attention into spatial regression. Through\nextensive benchmarking on synthetic spatial datasets with varying\nheterogeneity, noise, and sample sizes, we show that GNNWR outperforms classic\nmethods in capturing nonlinear and complex spatial relationships. Our results\nalso reveal that model performance depends strongly on data characteristics,\nwith local models excelling in highly heterogeneous or small-sample scenarios,\nand global models performing better with larger, more homogeneous data. These\nfindings highlight the importance of inductive bias in spatial modeling and\nsuggest future directions, including learnable spatial weighting functions,\nhybrid neural architectures, and improved interpretability for models handling\nnon-stationary spatial data.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6GNNWR\u5f52\u7eb3\u504f\u7f6e\uff0c\u63d0\u51fa\u63a8\u5e7f\u65b9\u6cd5\uff0c\u7ecf\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\u5176\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\uff0c\u63ed\u793a\u6a21\u578b\u6027\u80fd\u4e0e\u6570\u636e\u7279\u5f81\u6709\u5173\uff0c\u5e76\u6307\u51fa\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u5f53\u524dGNNWR\u5728\u5efa\u6a21\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u4e0a\u5b58\u5728\u5c40\u9650\uff0c\u53d7\u56fa\u5b9a\u8ddd\u79bb\u65b9\u6848\u548c\u6709\u9650\u5f52\u7eb3\u504f\u7f6e\u7684\u9650\u5236\u3002", "method": "\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u53d8\u6362\u5668\u7684\u6982\u5ff5\uff0c\u5c06\u5c40\u90e8\u611f\u53d7\u91ce\u3001\u987a\u5e8f\u4e0a\u4e0b\u6587\u548c\u81ea\u6ce8\u610f\u529b\u5f15\u5165\u7a7a\u95f4\u56de\u5f52\u4ee5\u63a8\u5e7fGNNWR\u3002", "result": "\u5728\u4e0d\u540c\u5f02\u8d28\u6027\u3001\u566a\u58f0\u548c\u6837\u672c\u91cf\u7684\u5408\u6210\u7a7a\u95f4\u6570\u636e\u96c6\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0cGNNWR\u5728\u6355\u6349\u975e\u7ebf\u6027\u548c\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u4e0a\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\uff0c\u6a21\u578b\u6027\u80fd\u4e0e\u6570\u636e\u7279\u5f81\u7d27\u5bc6\u76f8\u5173\u3002", "conclusion": "\u5f3a\u8c03\u5f52\u7eb3\u504f\u7f6e\u5728\u7a7a\u95f4\u5efa\u6a21\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5efa\u8bae\u672a\u6765\u63a2\u7d22\u53ef\u5b66\u4e60\u7684\u7a7a\u95f4\u52a0\u6743\u51fd\u6570\u3001\u6df7\u5408\u795e\u7ecf\u67b6\u6784\u548c\u63d0\u9ad8\u5904\u7406\u975e\u5e73\u7a33\u7a7a\u95f4\u6570\u636e\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.09269", "pdf": "https://arxiv.org/pdf/2507.09269", "abs": "https://arxiv.org/abs/2507.09269", "authors": ["Shuhan Ye", "Yuanbin Qian", "Chong Wang", "Sunqi Lin", "Jiazhen Xu", "Jiangbo Qian", "Yuqi Li"], "title": "Cross Knowledge Distillation between Artificial and Spiking Neural Networks", "categories": ["cs.CV", "cs.AI"], "comment": "This paper has been accepted by ICME2025", "summary": "Recently, Spiking Neural Networks (SNNs) have demonstrated rich potential in\ncomputer vision domain due to their high biological plausibility, event-driven\ncharacteristic and energy-saving efficiency. Still, limited annotated\nevent-based datasets and immature SNN architectures result in their performance\ninferior to that of Artificial Neural Networks (ANNs). To enhance the\nperformance of SNNs on their optimal data format, DVS data, we explore using\nRGB data and well-performing ANNs to implement knowledge distillation. In this\ncase, solving cross-modality and cross-architecture challenges is necessary. In\nthis paper, we propose cross knowledge distillation (CKD), which not only\nleverages semantic similarity and sliding replacement to mitigate the\ncross-modality challenge, but also uses an indirect phased knowledge\ndistillation to mitigate the cross-architecture challenge. We validated our\nmethod on main-stream neuromorphic datasets, including N-Caltech101 and\nCEP-DVS. The experimental results show that our method outperforms current\nState-of-the-Art methods. The code will be available at\nhttps://github.com/ShawnYE618/CKD", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8de8\u77e5\u8bc6\u84b8\u998f\uff08CKD\uff09\u65b9\u6cd5\u63d0\u5347\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u5728DVS\u6570\u636e\u4e0a\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524dSOTA\u65b9\u6cd5\u3002", "motivation": "\u56e0\u6709\u9650\u7684\u5e26\u6ce8\u91ca\u4e8b\u4ef6\u6570\u636e\u96c6\u548c\u4e0d\u6210\u719f\u7684SNN\u67b6\u6784\uff0cSNNs\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u6027\u80fd\u4e0d\u5982\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff08ANNs\uff09\uff0c\u9700\u63d0\u5347SNNs\u5728DVS\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u8de8\u77e5\u8bc6\u84b8\u998f\uff08CKD\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u6ed1\u52a8\u66ff\u6362\u7f13\u89e3\u8de8\u6a21\u6001\u6311\u6218\uff0c\u4f7f\u7528\u95f4\u63a5\u5206\u9636\u6bb5\u77e5\u8bc6\u84b8\u998f\u7f13\u89e3\u8de8\u67b6\u6784\u6311\u6218\u3002", "result": "\u5728\u4e3b\u6d41\u795e\u7ecf\u5f62\u6001\u6570\u636e\u96c6\uff08\u5982N - Caltech101\u548cCEP - DVS\uff09\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524dSOTA\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0CKD\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347SNNs\u5728DVS\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09961", "pdf": "https://arxiv.org/pdf/2507.09961", "abs": "https://arxiv.org/abs/2507.09961", "authors": ["Lihua Zhou", "Mao Ye", "Nianxin Li", "Shuaifeng Li", "Jinlin Wu", "Xiatian Zhu", "Lei Deng", "Hongbin Liu", "Jiebo Luo", "Zhen Lei"], "title": "Text-Driven Causal Representation Learning for Source-Free Domain Generalization", "categories": ["cs.LG"], "comment": "Under Review", "summary": "Deep learning often struggles when training and test data distributions\ndiffer. Traditional domain generalization (DG) tackles this by including data\nfrom multiple source domains, which is impractical due to expensive data\ncollection and annotation. Recent vision-language models like CLIP enable\nsource-free domain generalization (SFDG) by using text prompts to simulate\nvisual representations, reducing data demands. However, existing SFDG methods\nstruggle with domain-specific confounders, limiting their generalization\ncapabilities. To address this issue, we propose TDCRL\n(\\textbf{T}ext-\\textbf{D}riven \\textbf{C}ausal \\textbf{R}epresentation\n\\textbf{L}earning), the first method to integrate causal inference into the\nSFDG setting. TDCRL operates in two steps: first, it employs data augmentation\nto generate style word vectors, combining them with class information to\ngenerate text embeddings to simulate visual representations; second, it trains\na causal intervention network with a confounder dictionary to extract\ndomain-invariant features. Grounded in causal learning, our approach offers a\nclear and effective mechanism to achieve robust, domain-invariant features,\nensuring robust generalization. Extensive experiments on PACS, VLCS,\nOfficeHome, and DomainNet show state-of-the-art performance, proving TDCRL\neffectiveness in SFDG.", "AI": {"tldr": "\u4f20\u7edf\u9886\u57df\u6cdb\u5316\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u6e90\u81ea\u7531\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u7279\u5b9a\u9886\u57df\u6df7\u6dc6\u56e0\u7d20\u3002\u63d0\u51faTDCRL\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u6b65\u64cd\u4f5c\u5b9e\u73b0\u9886\u57df\u4e0d\u53d8\u7279\u5f81\u63d0\u53d6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u9886\u57df\u6cdb\u5316\u6570\u636e\u6536\u96c6\u548c\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u6e90\u81ea\u7531\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u7279\u5b9a\u9886\u57df\u6df7\u6dc6\u56e0\u7d20\uff0c\u9650\u5236\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faTDCRL\u65b9\u6cd5\uff0c\u7b2c\u4e00\u6b65\u7528\u6570\u636e\u589e\u5f3a\u751f\u6210\u98ce\u683c\u8bcd\u5411\u91cf\u5e76\u7ed3\u5408\u7c7b\u4fe1\u606f\u751f\u6210\u6587\u672c\u5d4c\u5165\u6a21\u62df\u89c6\u89c9\u8868\u5f81\uff1b\u7b2c\u4e8c\u6b65\u7528\u6df7\u6dc6\u56e0\u7d20\u5b57\u5178\u8bad\u7ec3\u56e0\u679c\u5e72\u9884\u7f51\u7edc\u63d0\u53d6\u9886\u57df\u4e0d\u53d8\u7279\u5f81\u3002", "result": "\u5728PACS\u3001VLCS\u3001OfficeHome\u548cDomainNet\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\u51fa\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "TDCRL\u65b9\u6cd5\u57fa\u4e8e\u56e0\u679c\u5b66\u4e60\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u9c81\u68d2\u7684\u9886\u57df\u4e0d\u53d8\u7279\u5f81\u63d0\u53d6\uff0c\u786e\u4fdd\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.09279", "pdf": "https://arxiv.org/pdf/2507.09279", "abs": "https://arxiv.org/abs/2507.09279", "authors": ["Anita Kriz", "Elizabeth Laura Janes", "Xing Shen", "Tal Arbel"], "title": "Prompt4Trust: A Reinforcement Learning Prompt Augmentation Framework for Clinically-Aligned Confidence Calibration in Multimodal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Preprint version. The peer-reviewed version of this paper has been\n  accepted to ICCV 2025 Workshop CVAMD", "summary": "Multimodal large language models (MLLMs) hold considerable promise for\napplications in healthcare. However, their deployment in safety-critical\nsettings is hindered by two key limitations: (i) sensitivity to prompt design,\nand (ii) a tendency to generate incorrect responses with high confidence. As\nclinicians may rely on a model's stated confidence to gauge the reliability of\nits predictions, it is especially important that when a model expresses high\nconfidence, it is also highly accurate. We introduce Prompt4Trust, the first\nreinforcement learning (RL) framework for prompt augmentation targeting\nconfidence calibration in MLLMs. A lightweight LLM is trained to produce\ncontext-aware auxiliary prompts that guide a downstream task MLLM to generate\nresponses in which the expressed confidence more accurately reflects predictive\naccuracy. Unlike conventional calibration techniques, Prompt4Trust specifically\nprioritizes aspects of calibration most critical for safe and trustworthy\nclinical decision-making. Beyond improvements driven by this clinically\nmotivated calibration objective, our proposed method also improves task\naccuracy, achieving state-of-the-art medical visual question answering (VQA)\nperformance on the PMC-VQA benchmark, which is composed of multiple-choice\nquestions spanning diverse medical imaging modalities. Moreover, our framework\ntrained with a small downstream task MLLM showed promising zero-shot\ngeneralization to larger MLLMs in our experiments, suggesting the potential for\nscalable calibration without the associated computational costs. This work\ndemonstrates the potential of automated yet human-aligned prompt engineering\nfor improving the the trustworthiness of MLLMs in safety critical settings. Our\ncodebase can be found at https://github.com/xingbpshen/vccrl-llm.", "AI": {"tldr": "\u4ecb\u7ecdPrompt4Trust\u6846\u67b6\u7528\u4e8eMLLM\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u63d0\u5347\u533b\u7597\u5e94\u7528\u53ef\u4fe1\u5ea6\u548c\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u6709\u96f6\u6837\u672c\u6cdb\u5316\u6f5c\u529b\u3002", "motivation": "MLLM\u5728\u533b\u7597\u5b89\u5168\u5173\u952e\u573a\u666f\u90e8\u7f72\u53d7\u63d0\u793a\u8bbe\u8ba1\u654f\u611f\u548c\u9ad8\u7f6e\u4fe1\u5ea6\u4e0b\u6613\u51fa\u9519\u4e24\u65b9\u9762\u9650\u5236\uff0c\u9700\u63d0\u5347\u5176\u53ef\u4fe1\u5ea6\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684Prompt4Trust\u6846\u67b6\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7LLM\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u8f85\u52a9\u63d0\u793a\uff0c\u5f15\u5bfc\u4e0b\u6e38\u4efb\u52a1MLLM\u3002", "result": "\u63d0\u5347\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u5728PMC - VQA\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\uff1b\u5c0f\u6a21\u578b\u8bad\u7ec3\u6846\u67b6\u5bf9\u5927\u6a21\u578b\u6709\u96f6\u6837\u672c\u6cdb\u5316\u6f5c\u529b\u3002", "conclusion": "\u81ea\u52a8\u5316\u4e14\u7b26\u5408\u4eba\u7c7b\u9700\u6c42\u7684\u63d0\u793a\u5de5\u7a0b\u53ef\u63d0\u5347MLLM\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.09968", "pdf": "https://arxiv.org/pdf/2507.09968", "abs": "https://arxiv.org/abs/2507.09968", "authors": ["Xiangyu Sun", "Amin Yousefpour", "Shirin Hosseinmardi", "Ramin Bostanabad"], "title": "Compliance Minimization via Physics-Informed Gaussian Processes", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning (ML) techniques have recently gained significant attention\nfor solving compliance minimization (CM) problems. However, these methods\ntypically provide poor feature boundaries, are very expensive, and lack a\nsystematic mechanism to control the design complexity. Herein, we address these\nlimitations by proposing a mesh-free and simultaneous framework based on\nphysics-informed Gaussian processes (GPs). In our approach, we parameterize the\ndesign and state variables with GP priors which have independent kernels but\nshare a multi-output neural network (NN) as their mean function. The\narchitecture of this NN is based on Parametric Grid Convolutional Attention\nNetworks (PGCANs) which not only mitigate spectral bias issues, but also\nprovide an interpretable mechanism to control design complexity. We estimate\nall the parameters of our GP-based representations by simultaneously minimizing\nthe compliance, total potential energy, and residual of volume fraction\nconstraint. Importantly, our loss function exclude all data-based residuals as\nGPs automatically satisfy them. We also develop computational schemes based on\ncurriculum training and numerical integration to increase the efficiency and\nrobustness of our approach which is shown to (1) produce super-resolution\ntopologies with fast convergence, (2) achieve smaller compliance and less gray\narea fraction compared to traditional numerical methods, (3) provide control\nover fine-scale features, and (4) outperform competing ML-based methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u9ad8\u65af\u8fc7\u7a0b\u7684\u65e0\u7f51\u683c\u540c\u6b65\u6846\u67b6\u89e3\u51b3\u5408\u89c4\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6280\u672f\u89e3\u51b3\u5408\u89c4\u6700\u5c0f\u5316\u95ee\u9898\u5b58\u5728\u7279\u5f81\u8fb9\u754c\u5dee\u3001\u6210\u672c\u9ad8\u3001\u7f3a\u4e4f\u63a7\u5236\u8bbe\u8ba1\u590d\u6742\u6027\u673a\u5236\u7b49\u5c40\u9650\u3002", "method": "\u7528\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u53c2\u6570\u5316\u8bbe\u8ba1\u548c\u72b6\u6001\u53d8\u91cf\uff0c\u91c7\u7528\u57fa\u4e8e\u53c2\u6570\u5316\u7f51\u683c\u5377\u79ef\u6ce8\u610f\u529b\u7f51\u7edc\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5408\u89c4\u6027\u3001\u603b\u52bf\u80fd\u548c\u4f53\u79ef\u5206\u6570\u7ea6\u675f\u6b8b\u5dee\uff0c\u5f00\u53d1\u8bfe\u7a0b\u8bad\u7ec3\u548c\u6570\u503c\u79ef\u5206\u8ba1\u7b97\u65b9\u6848\u3002", "result": "\u80fd\u5feb\u901f\u6536\u655b\u4ea7\u751f\u8d85\u5206\u8fa8\u7387\u62d3\u6251\uff0c\u5408\u89c4\u6027\u66f4\u5c0f\u3001\u7070\u8272\u533a\u57df\u5206\u6570\u66f4\u5c11\uff0c\u53ef\u63a7\u5236\u7cbe\u7ec6\u5c3a\u5ea6\u7279\u5f81\uff0c\u4f18\u4e8e\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u9ad8\u65af\u8fc7\u7a0b\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5728\u5408\u89c4\u6700\u5c0f\u5316\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2507.09299", "pdf": "https://arxiv.org/pdf/2507.09299", "abs": "https://arxiv.org/abs/2507.09299", "authors": ["Abdulvahap Mutlu", "\u015eeng\u00fcl Do\u011fan", "T\u00fcrker Tuncer"], "title": "ViT-ProtoNet for Few-Shot Image Classification: A Multi-Benchmark Evaluation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "All codes are available at\n  https://github.com/abdulvahapmutlu/vit-protonet", "summary": "The remarkable representational power of Vision Transformers (ViTs) remains\nunderutilized in few-shot image classification. In this work, we introduce\nViT-ProtoNet, which integrates a ViT-Small backbone into the Prototypical\nNetwork framework. By averaging class conditional token embeddings from a\nhandful of support examples, ViT-ProtoNet constructs robust prototypes that\ngeneralize to novel categories under 5-shot settings. We conduct an extensive\nempirical evaluation on four standard benchmarks: Mini-ImageNet, FC100,\nCUB-200, and CIFAR-FS, including overlapped support variants to assess\nrobustness. Across all splits, ViT-ProtoNet consistently outperforms CNN-based\nprototypical counterparts, achieving up to a 3.2\\% improvement in 5-shot\naccuracy and demonstrating superior feature separability in latent space.\nFurthermore, it outperforms or is competitive with transformer-based\ncompetitors using a more lightweight backbone. Comprehensive ablations examine\nthe impact of transformer depth, patch size, and fine-tuning strategy. To\nfoster reproducibility, we release code and pretrained weights. Our results\nestablish ViT-ProtoNet as a powerful, flexible approach for few-shot\nclassification and set a new baseline for transformer-based meta-learners.", "AI": {"tldr": "\u63d0\u51faViT - ProtoNet\u7528\u4e8e\u5c11\u6837\u672c\u56fe\u50cf\u5206\u7c7b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bbe\u7f6e\u4e86\u65b0\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3Vision Transformers\u5728\u5c11\u6837\u672c\u56fe\u50cf\u5206\u7c7b\u4e2d\u8868\u5f81\u80fd\u529b\u672a\u5145\u5206\u5229\u7528\u7684\u95ee\u9898\u3002", "method": "\u5c06ViT - Small\u9aa8\u5e72\u7f51\u7edc\u96c6\u6210\u5230\u539f\u578b\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u5e73\u5747\u5c11\u91cf\u652f\u6301\u793a\u4f8b\u7684\u7c7b\u6761\u4ef6\u4ee4\u724c\u5d4c\u5165\u6784\u5efa\u539f\u578b\u3002", "result": "\u5728\u56db\u4e2a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8eCNN\u7684\u539f\u578b\u7f51\u7edc\uff0c5 - shot\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u53473.2%\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u6709\u66f4\u597d\u7684\u7279\u5f81\u53ef\u5206\u6027\uff0c\u7528\u66f4\u8f7b\u91cf\u7ea7\u9aa8\u5e72\u7f51\u7edc\u4f18\u4e8e\u6216\u5ab2\u7f8e\u57fa\u4e8eTransformer\u7684\u7ade\u4e89\u5bf9\u624b\u3002", "conclusion": "ViT - ProtoNet\u662f\u5c11\u6837\u672c\u5206\u7c7b\u7684\u5f3a\u5927\u3001\u7075\u6d3b\u65b9\u6cd5\uff0c\u4e3a\u57fa\u4e8eTransformer\u7684\u5143\u5b66\u4e60\u5668\u8bbe\u7f6e\u4e86\u65b0\u57fa\u7ebf\u3002"}}
{"id": "2507.09308", "pdf": "https://arxiv.org/pdf/2507.09308", "abs": "https://arxiv.org/abs/2507.09308", "authors": ["Zile Wang", "Hao Yu", "Jiabo Zhan", "Chun Yuan"], "title": "AlphaVAE: Unified End-to-End RGBA Image Reconstruction and Generation with Alpha-Aware Representation Learning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in latent diffusion models have achieved remarkable results\nin high-fidelity RGB image synthesis by leveraging pretrained VAEs to compress\nand reconstruct pixel data at low computational cost. However, the generation\nof transparent or layered content (RGBA image) remains largely unexplored, due\nto the lack of large-scale benchmarks. In this work, we propose ALPHA, the\nfirst comprehensive RGBA benchmark that adapts standard RGB metrics to\nfour-channel images via alpha blending over canonical backgrounds. We further\nintroduce ALPHAVAE, a unified end-to-end RGBA VAE that extends a pretrained RGB\nVAE by incorporating a dedicated alpha channel. The model is trained with a\ncomposite objective that combines alpha-blended pixel reconstruction,\npatch-level fidelity, perceptual consistency, and dual KL divergence\nconstraints to ensure latent fidelity across both RGB and alpha\nrepresentations. Our RGBA VAE, trained on only 8K images in contrast to 1M used\nby prior methods, achieves a +4.9 dB improvement in PSNR and a +3.2% increase\nin SSIM over LayerDiffuse in reconstruction. It also enables superior\ntransparent image generation when fine-tuned within a latent diffusion\nframework. Our code, data, and models are released on\nhttps://github.com/o0o0o00o0/AlphaVAE for reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2aRGBA\u57fa\u51c6ALPHA\u548c\u7edf\u4e00\u7aef\u5230\u7aefRGBA VAE\u6a21\u578bALPHAVAE\uff0c\u5728\u91cd\u5efa\u4e0a\u8868\u73b0\u4f18\u4e8eLayerDiffuse\uff0c\u4e14\u80fd\u5b9e\u73b0\u66f4\u597d\u7684\u900f\u660e\u56fe\u50cf\u751f\u6210\uff0c\u4ee3\u7801\u7b49\u5df2\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u6269\u6563\u6a21\u578b\u5728RGBA\u56fe\u50cf\u751f\u6210\u65b9\u9762\u56e0\u7f3a\u4e4f\u5927\u89c4\u6a21\u57fa\u51c6\u800c\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51faALPHA\u57fa\u51c6\uff0c\u5c06\u6807\u51c6RGB\u6307\u6807\u901a\u8fc7\u5728\u6807\u51c6\u80cc\u666f\u4e0a\u8fdb\u884calpha\u6df7\u5408\u5e94\u7528\u4e8e\u56db\u901a\u9053\u56fe\u50cf\uff1b\u5f15\u5165ALPHAVAE\uff0c\u6269\u5c55\u9884\u8bad\u7ec3RGB VAE\u5e76\u7ed3\u5408\u590d\u5408\u76ee\u6807\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u4ec58K\u56fe\u50cf\u4e0a\u8bad\u7ec3\u7684RGBA VAE\uff0c\u76f8\u6bd4LayerDiffuse\u5728\u91cd\u5efa\u4e0aPSNR\u63d0\u53474.9 dB\uff0cSSIM\u63d0\u53473.2%\uff0c\u5728\u6f5c\u5728\u6269\u6563\u6846\u67b6\u4e2d\u5fae\u8c03\u65f6\u80fd\u5b9e\u73b0\u66f4\u597d\u7684\u900f\u660e\u56fe\u50cf\u751f\u6210\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684ALPHA\u57fa\u51c6\u548cALPHAVAE\u6a21\u578b\u5728RGBA\u56fe\u50cf\u751f\u6210\u548c\u91cd\u5efa\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002"}}
{"id": "2507.10014", "pdf": "https://arxiv.org/pdf/2507.10014", "abs": "https://arxiv.org/abs/2507.10014", "authors": ["Ali Sarabi", "Arash Sarabi", "Hao Yan", "Beckett Sterner", "Petar Jevti\u0107"], "title": "Forecasting Coccidioidomycosis (Valley Fever) in Arizona: A Graph Neural Network Approach", "categories": ["cs.LG", "92D30, 62M10, 68T07", "G.3; I.6.3; I.2.6; I.5.1"], "comment": null, "summary": "Coccidioidomycosis, commonly known as Valley Fever, remains a significant\npublic health concern in endemic regions of the southwestern United States.\nThis study develops the first graph neural network (GNN) model for forecasting\nValley Fever incidence in Arizona. The model integrates surveillance case data\nwith environmental predictors using graph structures, including soil\nconditions, atmospheric variables, agricultural indicators, and air quality\nmetrics. Our approach explores correlation-based relationships among variables\ninfluencing disease transmission. The model captures critical delays in disease\nprogression through lagged effects, enhancing its capacity to reflect complex\ntemporal dependencies in disease ecology. Results demonstrate that the GNN\narchitecture effectively models Valley Fever trends and provides insights into\nkey environmental drivers of disease incidence. These findings can inform early\nwarning systems and guide resource allocation for disease prevention efforts in\nhigh-risk areas.", "AI": {"tldr": "\u5f00\u53d1\u9996\u4e2a\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9884\u6d4b\u4e9a\u5229\u6851\u90a3\u5dde\u5c71\u8c37\u70ed\u53d1\u75c5\u7387\uff0c\u6a21\u578b\u6709\u6548\u4e14\u80fd\u63d0\u4f9b\u5173\u952e\u73af\u5883\u9a71\u52a8\u56e0\u7d20\u89c1\u89e3\uff0c\u53ef\u7528\u4e8e\u9884\u8b66\u548c\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u7403\u5b62\u5b50\u83cc\u75c5\uff08\u5c71\u8c37\u70ed\uff09\u5728\u7f8e\u56fd\u897f\u5357\u90e8\u6d41\u884c\u5730\u533a\u662f\u91cd\u5927\u516c\u5171\u536b\u751f\u95ee\u9898\uff0c\u9700\u9884\u6d4b\u53d1\u75c5\u7387\u3002", "method": "\u5f00\u53d1\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7ed3\u5408\u76d1\u6d4b\u75c5\u4f8b\u6570\u636e\u548c\u73af\u5883\u9884\u6d4b\u56e0\u5b50\uff0c\u63a2\u7d22\u53d8\u91cf\u95f4\u76f8\u5173\u6027\uff0c\u8003\u8651\u6ede\u540e\u6548\u5e94\u3002", "result": "\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u80fd\u6709\u6548\u6a21\u62df\u5c71\u8c37\u70ed\u53d1\u75c5\u8d8b\u52bf\uff0c\u63ed\u793a\u75be\u75c5\u53d1\u75c5\u7387\u7684\u5173\u952e\u73af\u5883\u9a71\u52a8\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u53ef\u4e3a\u9ad8\u98ce\u9669\u5730\u533a\u7684\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u548c\u75be\u75c5\u9884\u9632\u8d44\u6e90\u5206\u914d\u63d0\u4f9b\u4f9d\u636e\u3002"}}
{"id": "2507.10039", "pdf": "https://arxiv.org/pdf/2507.10039", "abs": "https://arxiv.org/abs/2507.10039", "authors": ["Steven Palayew", "Bo Wang", "Gary Bader"], "title": "Towards Applying Large Language Models to Complement Single-Cell Foundation Models", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Single-cell foundation models such as scGPT represent a significant\nadvancement in single-cell omics, with an ability to achieve state-of-the-art\nperformance on various downstream biological tasks. However, these models are\ninherently limited in that a vast amount of information in biology exists as\ntext, which they are unable to leverage. There have therefore been several\nrecent works that propose the use of LLMs as an alternative to single-cell\nfoundation models, achieving competitive results. However, there is little\nunderstanding of what factors drive this performance, along with a strong focus\non using LLMs as an alternative, rather than complementary approach to\nsingle-cell foundation models. In this study, we therefore investigate what\nbiological insights contribute toward the performance of LLMs when applied to\nsingle-cell data, and introduce scMPT; a model which leverages synergies\nbetween scGPT, and single-cell representations from LLMs that capture these\ninsights. scMPT demonstrates stronger, more consistent performance than either\nof its component models, which frequently have large performance gaps between\neach other across datasets. We also experiment with alternate fusion methods,\ndemonstrating the potential of combining specialized reasoning models with\nscGPT to improve performance. This study ultimately showcases the potential for\nLLMs to complement single-cell foundation models and drive improvements in\nsingle-cell analysis.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76LLMs\u5e94\u7528\u4e8e\u5355\u7ec6\u80de\u6570\u636e\u65f6\u7684\u6027\u80fd\u9a71\u52a8\u56e0\u7d20\uff0c\u63d0\u51fascMPT\u6a21\u578b\uff0c\u5c55\u793a\u4e86LLMs\u8865\u5145\u5355\u7ec6\u80de\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u5355\u7ec6\u80de\u57fa\u7840\u6a21\u578b\u65e0\u6cd5\u5229\u7528\u751f\u7269\u5b66\u6587\u672c\u4fe1\u606f\uff0c\u4e14\u5bf9LLMs\u5e94\u7528\u4e8e\u5355\u7ec6\u80de\u6570\u636e\u7684\u6027\u80fd\u9a71\u52a8\u56e0\u7d20\u7406\u89e3\u4e0d\u8db3\uff0c\u7f3a\u5c11\u4e92\u8865\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u751f\u7269\u5b66\u89c1\u89e3\u5bf9LLMs\u5e94\u7528\u4e8e\u5355\u7ec6\u80de\u6570\u636e\u6027\u80fd\u7684\u8d21\u732e\uff0c\u63d0\u51fascMPT\u6a21\u578b\uff0c\u7ed3\u5408scGPT\u548cLLMs\u7684\u5355\u7ec6\u80de\u8868\u793a\uff0c\u8fd8\u8bd5\u9a8c\u4e86\u66ff\u4ee3\u878d\u5408\u65b9\u6cd5\u3002", "result": "scMPT\u6bd4\u5176\u7ec4\u4ef6\u6a21\u578b\u8868\u73b0\u66f4\u5f3a\u3001\u66f4\u7a33\u5b9a\uff0c\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7ec4\u4ef6\u6a21\u578b\u6027\u80fd\u5dee\u8ddd\u5927\uff1b\u8bd5\u9a8c\u7684\u66ff\u4ee3\u878d\u5408\u65b9\u6cd5\u5c55\u793a\u4e86\u7ed3\u5408\u4e13\u4e1a\u63a8\u7406\u6a21\u578b\u548cscGPT\u63d0\u5347\u6027\u80fd\u7684\u6f5c\u529b\u3002", "conclusion": "LLMs\u6709\u6f5c\u529b\u8865\u5145\u5355\u7ec6\u80de\u57fa\u7840\u6a21\u578b\uff0c\u63a8\u52a8\u5355\u7ec6\u80de\u5206\u6790\u7684\u6539\u8fdb\u3002"}}
{"id": "2507.10048", "pdf": "https://arxiv.org/pdf/2507.10048", "abs": "https://arxiv.org/abs/2507.10048", "authors": ["Benedict Gerlach", "Marie Anastacio", "Holger H. Hoos"], "title": "On the Efficiency of Training Robust Decision Trees", "categories": ["cs.LG"], "comment": "Presented as a poster at SAIV 2025", "summary": "As machine learning gets adopted into the industry quickly, trustworthiness\nis increasingly in focus. Yet, efficiency and sustainability of robust training\npipelines still have to be established. In this work, we consider a simple\npipeline for training adversarially robust decision trees and investigate the\nefficiency of each step. Our pipeline consists of three stages. Firstly, we\nchoose the perturbation size automatically for each dataset. For that, we\nintroduce a simple algorithm, instead of relying on intuition or prior work.\nMoreover, we show that the perturbation size can be estimated from smaller\nmodels than the one intended for full training, and thus significant gains in\nefficiency can be achieved. Secondly, we train state-of-the-art adversarial\ntraining methods and evaluate them regarding both their training time and\nadversarial accuracy. Thirdly, we certify the robustness of each of the models\nthus obtained and investigate the time required for this. We find that\nverification time, which is critical to the efficiency of the full pipeline, is\nnot correlated with training time.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5bf9\u6297\u9c81\u68d2\u51b3\u7b56\u6811\u8bad\u7ec3\u7ba1\u9053\u5404\u6b65\u9aa4\u6548\u7387\uff0c\u7531\u9009\u6270\u52a8\u5927\u5c0f\u3001\u8bad\u7ec3\u6a21\u578b\u3001\u9a8c\u8bc1\u6a21\u578b\u4e09\u6b65\u7ec4\u6210\uff0c\u53d1\u73b0\u9a8c\u8bc1\u65f6\u95f4\u4e0e\u8bad\u7ec3\u65f6\u95f4\u65e0\u5173\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5feb\u901f\u5e94\u7528\uff0c\u9c81\u68d2\u8bad\u7ec3\u7ba1\u9053\u7684\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u6709\u5f85\u786e\u7acb\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e09\u6b65\u7684\u8bad\u7ec3\u7ba1\u9053\uff1a\u81ea\u52a8\u9009\u6270\u52a8\u5927\u5c0f\u3001\u8bad\u7ec3\u6a21\u578b\u5e76\u8bc4\u4f30\u3001\u9a8c\u8bc1\u6a21\u578b\u5e76\u7814\u7a76\u9a8c\u8bc1\u65f6\u95f4\u3002", "result": "\u6270\u52a8\u5927\u5c0f\u53ef\u4ece\u8f83\u5c0f\u6a21\u578b\u4f30\u8ba1\uff0c\u9a8c\u8bc1\u65f6\u95f4\u4e0e\u8bad\u7ec3\u65f6\u95f4\u65e0\u5173\u3002", "conclusion": "\u5bf9\u8bad\u7ec3\u7ba1\u9053\u5404\u6b65\u9aa4\u6548\u7387\u8fdb\u884c\u4e86\u7814\u7a76\uff0c\u660e\u786e\u4e86\u9a8c\u8bc1\u65f6\u95f4\u548c\u8bad\u7ec3\u65f6\u95f4\u7684\u5173\u7cfb\u3002"}}
{"id": "2507.10078", "pdf": "https://arxiv.org/pdf/2507.10078", "abs": "https://arxiv.org/abs/2507.10078", "authors": ["Hiroki Sakamoto", "Kazuhiro Sato"], "title": "Compression Method for Deep Diagonal State Space Model Based on $H^2$ Optimal Reduction", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to IEEE Control Systems Letters", "summary": "Deep learning models incorporating linear SSMs have gained attention for\ncapturing long-range dependencies in sequential data. However, their large\nparameter sizes pose challenges for deployment on resource-constrained devices.\nIn this study, we propose an efficient parameter reduction method for these\nmodels by applying $H^{2}$ model order reduction techniques from control theory\nto their linear SSM components. In experiments, the LRA benchmark results show\nthat the model compression based on our proposed method outperforms an existing\nmethod using the Balanced Truncation, while successfully reducing the number of\nparameters in the SSMs to $1/32$ without sacrificing the performance of the\noriginal models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9ad8\u6548\u53c2\u6570\u51cf\u5c11\u65b9\u6cd5\uff0c\u5bf9\u542b\u7ebf\u6027SSM\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u7ebf\u6027SSM\u7ec4\u4ef6\u5e94\u7528H\u00b2\u6a21\u578b\u964d\u9636\u6280\u672f\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u5c06\u53c2\u6570\u51cf\u81f31/32\u4e14\u4e0d\u635f\u5931\u6027\u80fd\u3002", "motivation": "\u542b\u7ebf\u6027SSM\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u5927\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u6709\u6311\u6218\u3002", "method": "\u5bf9\u7ebf\u6027SSM\u7ec4\u4ef6\u5e94\u7528H\u00b2\u6a21\u578b\u964d\u9636\u6280\u672f\u3002", "result": "LRA\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u8be5\u65b9\u6cd5\u7684\u6a21\u578b\u538b\u7f29\u4f18\u4e8e\u4f7f\u7528\u5e73\u8861\u622a\u65ad\u7684\u73b0\u6709\u65b9\u6cd5\uff0c\u6210\u529f\u5c06SSM\u53c2\u6570\u51cf\u5c11\u81f31/32\uff0c\u4e14\u4e0d\u635f\u5931\u539f\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53c2\u6570\u51cf\u5c11\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u542b\u7ebf\u6027SSM\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u538b\u7f29\u3002"}}
{"id": "2507.09378", "pdf": "https://arxiv.org/pdf/2507.09378", "abs": "https://arxiv.org/abs/2507.09378", "authors": ["Mohammadsaleh Refahi", "Mahdi Abavisani", "Bahrad A. Sokhansanj", "James R. Brown", "Gail Rosen"], "title": "Context-Aware Regularization with Markovian Integration for Attention-Based Nucleotide Analysis", "categories": ["q-bio.GN", "cs.AI"], "comment": null, "summary": "Transformers have revolutionized nucleotide sequence analysis, yet capturing\nlong-range dependencies remains challenging. Recent studies show that\nautoregressive transformers often exhibit Markovian behavior by relying on\nfixed-length context windows for next-token prediction. However, standard\nself-attention mechanisms are computationally inefficient for long sequences\ndue to their quadratic complexity and do not explicitly enforce global\ntransition consistency.\n  We introduce CARMANIA (Context-Aware Regularization with Markovian\nIntegration for Attention-Based Nucleotide Analysis), a self-supervised\npretraining framework that augments next-token (NT) prediction with a\ntransition-matrix (TM) loss. The TM loss aligns predicted token transitions\nwith empirically derived n-gram statistics from each input sequence,\nencouraging the model to capture higher-order dependencies beyond local\ncontext. This integration enables CARMANIA to learn organism-specific sequence\nstructures that reflect both evolutionary constraints and functional\norganization.\n  We evaluate CARMANIA across diverse genomic tasks, including regulatory\nelement prediction, functional gene classification, taxonomic inference,\nantimicrobial resistance detection, and biosynthetic gene cluster\nclassification. CARMANIA outperforms the previous best long-context model by at\nleast 7 percent, matches state-of-the-art on shorter sequences (exceeding prior\nresults on 20 out of 40 tasks while running approximately 2.5 times faster),\nand shows particularly strong improvements on enhancer and housekeeping gene\nclassification tasks, including up to a 34 percent absolute gain in Matthews\ncorrelation coefficient (MCC) for enhancer prediction. The TM loss boosts\naccuracy in 33 of 40 tasks, especially where local motifs or regulatory\npatterns drive prediction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCARMANIA\u6846\u67b6\u89e3\u51b3\u6838\u82f7\u9178\u5e8f\u5217\u5206\u6790\u4e2d\u957f\u8ddd\u79bb\u4f9d\u8d56\u95ee\u9898\uff0c\u5728\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "Transformer\u5728\u6838\u82f7\u9178\u5e8f\u5217\u5206\u6790\u4e2d\u6355\u83b7\u957f\u8ddd\u79bb\u4f9d\u8d56\u6709\u6311\u6218\uff0c\u6807\u51c6\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u7f3a\u4e4f\u5168\u5c40\u8f6c\u6362\u4e00\u81f4\u6027\u3002", "method": "\u5f15\u5165CARMANIA\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u8f6c\u6362\u77e9\u9635\uff08TM\uff09\u635f\u5931\u589e\u5f3a\u4e0b\u4e00\u4e2a\u6807\u8bb0\uff08NT\uff09\u9884\u6d4b\u3002", "result": "\u5728\u591a\u79cd\u57fa\u56e0\u7ec4\u4efb\u52a1\u4e2d\uff0cCARMANIA\u6bd4\u4e4b\u524d\u6700\u4f73\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u81f3\u5c11\u9ad87%\uff0c\u5728\u77ed\u5e8f\u5217\u4e0a\u4e0eSOTA\u76f8\u5f53\u4e14\u901f\u5ea6\u5feb\u7ea62.5\u500d\uff0c\u5728\u90e8\u5206\u4efb\u52a1\u63d0\u5347\u660e\u663e\u3002TM\u635f\u5931\u572833\u4e2a\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "CARMANIA\u6846\u67b6\u6709\u6548\uff0c\u80fd\u6355\u83b7\u9ad8\u9636\u4f9d\u8d56\uff0c\u5b66\u4e60\u7279\u5b9a\u751f\u7269\u5e8f\u5217\u7ed3\u6784\uff0c\u63d0\u5347\u591a\u79cd\u57fa\u56e0\u7ec4\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2507.10120", "pdf": "https://arxiv.org/pdf/2507.10120", "abs": "https://arxiv.org/abs/2507.10120", "authors": ["Cheng Sun", "Zhen Zhang", "Shaofu Yang"], "title": "A Variance-Reduced Cubic-Regularized Newton for Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 1 figure", "summary": "In this paper, we study a second-order approach to policy optimization in\nreinforcement learning. Existing second-order methods often suffer from\nsuboptimal sample complexity or rely on unrealistic assumptions about\nimportance sampling. To overcome these limitations, we propose VR-CR-PN, a\nvariance-reduced cubic-regularized policy Newton algorithm. To the best of our\nknowledge, this is the first algorithm that integrates Hessian-aided variance\nreduction with second-order policy optimization, effectively addressing the\ndistribution shift problem and achieving best-known sample complexity under\ngeneral nonconvex conditions but without the need for importance sampling. We\ntheoretically establish that VR-CR-PN achieves a sample complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ to reach an $\\epsilon$-second-order\nstationary point, significantly improving upon the previous best result of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-3.5})$ under comparable assumptions. As an\nadditional contribution, we introduce a novel Hessian estimator for the\nexpected return function, which admits a uniform upper bound independent of the\nhorizon length $H$, allowing the algorithm to achieve horizon-independent\nsample complexity.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.09420", "pdf": "https://arxiv.org/pdf/2507.09420", "abs": "https://arxiv.org/abs/2507.09420", "authors": ["Timothy Chase Jr", "Karthik Dantu"], "title": "Domain Adaptation and Multi-view Attention for Learnable Landmark Tracking with Sparse Data", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "Presented at the RSS Space Robotics Workshop 2025. Poster available\n  online at https://tjchase34.github.io/assets/pdfs/rss_poster.pdf", "summary": "The detection and tracking of celestial surface terrain features are crucial\nfor autonomous spaceflight applications, including Terrain Relative Navigation\n(TRN), Entry, Descent, and Landing (EDL), hazard analysis, and scientific data\ncollection. Traditional photoclinometry-based pipelines often rely on extensive\na priori imaging and offline processing, constrained by the computational\nlimitations of radiation-hardened systems. While historically effective, these\napproaches typically increase mission costs and duration, operate at low\nprocessing rates, and have limited generalization. Recently, learning-based\ncomputer vision has gained popularity to enhance spacecraft autonomy and\novercome these limitations. While promising, emerging techniques frequently\nimpose computational demands exceeding the capabilities of typical spacecraft\nhardware for real-time operation and are further challenged by the scarcity of\nlabeled training data for diverse extraterrestrial environments. In this work,\nwe present novel formulations for in-situ landmark tracking via detection and\ndescription. We utilize lightweight, computationally efficient neural network\narchitectures designed for real-time execution on current-generation spacecraft\nflight processors. For landmark detection, we propose improved domain\nadaptation methods that enable the identification of celestial terrain features\nwith distinct, cheaply acquired training data. Concurrently, for landmark\ndescription, we introduce a novel attention alignment formulation that learns\nrobust feature representations that maintain correspondence despite significant\nlandmark viewpoint variations. Together, these contributions form a unified\nsystem for landmark tracking that demonstrates superior performance compared to\nexisting state-of-the-art techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u539f\u4f4d\u5730\u6807\u8ddf\u8e2a\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u7ed3\u5408\u6539\u8fdb\u7684\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u548c\u6ce8\u610f\u529b\u5bf9\u9f50\u516c\u5f0f\uff0c\u6784\u5efa\u7edf\u4e00\u5730\u6807\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5149\u5ea6\u6d4b\u91cf\u6cd5\u7684\u6d41\u7a0b\u6709\u8bf8\u591a\u5c40\u9650\uff0c\u65b0\u5174\u57fa\u4e8e\u5b66\u4e60\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\u5b58\u5728\u8ba1\u7b97\u9700\u6c42\u9ad8\u548c\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5229\u7528\u8f7b\u91cf\u7ea7\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff1b\u63d0\u51fa\u6539\u8fdb\u7684\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u7528\u4e8e\u5730\u6807\u68c0\u6d4b\uff1b\u5f15\u5165\u6ce8\u610f\u529b\u5bf9\u9f50\u516c\u5f0f\u7528\u4e8e\u5730\u6807\u63cf\u8ff0\u3002", "result": "\u6784\u5efa\u7684\u7edf\u4e00\u5730\u6807\u8ddf\u8e2a\u7cfb\u7edf\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u6240\u63d0\u65b0\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u539f\u4f4d\u5730\u6807\u8ddf\u8e2a\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.10158", "pdf": "https://arxiv.org/pdf/2507.10158", "abs": "https://arxiv.org/abs/2507.10158", "authors": ["Obaidullah Zaland", "Erik Elmroth", "Monowar Bhuyan"], "title": "MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping", "categories": ["cs.LG", "cs.RO"], "comment": "The work is accepted for presentation at IEEE SMC 2025", "summary": "Federated Learning (FL) is a promising machine learning paradigm that enables\nparticipating devices to train privacy-preserved and collaborative models. FL\nhas proven its benefits for robotic manipulation tasks. However, grasping tasks\nlack exploration in such settings where robots train a global model without\nmoving data and ensuring data privacy. The main challenge is that each robot\nlearns from data that is nonindependent and identically distributed (non-IID)\nand of low quantity. This exhibits performance degradation, particularly in\nrobotic grasping. Thus, in this work, we propose MTF-Grasp, a multi-tier FL\napproach for robotic grasping, acknowledging the unique challenges posed by the\nnon-IID data distribution across robots, including quantitative skewness.\nMTF-Grasp harnesses data quality and quantity across robots to select a set of\n\"top-level\" robots with better data distribution and higher sample count. It\nthen utilizes top-level robots to train initial seed models and distribute them\nto the remaining \"low-level\" robots, reducing the risk of model performance\ndegradation in low-level robots. Our approach outperforms the conventional FL\nsetup by up to 8% on the quantity-skewed Cornell and Jacquard grasping\ndatasets.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u673a\u5668\u4eba\u6293\u53d6\u7684\u591a\u5c42\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5MTF - Grasp\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u5728\u673a\u5668\u4eba\u6293\u53d6\u4efb\u52a1\u4e2d\uff0c\u56e0\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u4e14\u6570\u91cf\u5c11\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u7f3a\u4e4f\u76f8\u5173\u63a2\u7d22\u3002", "method": "\u63d0\u51faMTF - Grasp\u65b9\u6cd5\uff0c\u5229\u7528\u673a\u5668\u4eba\u6570\u636e\u8d28\u91cf\u548c\u6570\u91cf\u9009\u51fa\u2018\u9876\u7ea7\u2019\u673a\u5668\u4eba\u8bad\u7ec3\u521d\u59cb\u79cd\u5b50\u6a21\u578b\u5e76\u5206\u53d1\u7ed9\u2018\u4f4e\u7ea7\u2019\u673a\u5668\u4eba\u3002", "result": "\u5728\u6570\u91cf\u504f\u659c\u7684\u5eb7\u5948\u5c14\u548c\u96c5\u5361\u5c14\u6293\u53d6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u8bbe\u7f6e\u6027\u80fd\u9ad88%\u3002", "conclusion": "MTF - Grasp\u80fd\u6709\u6548\u89e3\u51b3\u673a\u5668\u4eba\u6293\u53d6\u4efb\u52a1\u4e2d\u8054\u90a6\u5b66\u4e60\u56e0\u6570\u636e\u95ee\u9898\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2507.10170", "pdf": "https://arxiv.org/pdf/2507.10170", "abs": "https://arxiv.org/abs/2507.10170", "authors": ["Wuyang Zhou", "Giorgos Iacovides", "Kriton Konstantinidis", "Ilya Kisil", "Danilo Mandic"], "title": "Understanding the Rank of Tensor Networks via an Intuitive Example-Driven Approach", "categories": ["cs.LG"], "comment": null, "summary": "Tensor Network (TN) decompositions have emerged as an indispensable tool in\nBig Data analytics owing to their ability to provide compact low-rank\nrepresentations, thus alleviating the ``Curse of Dimensionality'' inherent in\nhandling higher-order data. At the heart of their success lies the concept of\nTN ranks, which governs the efficiency and expressivity of TN decompositions.\nHowever, unlike matrix ranks, TN ranks often lack a universal meaning and an\nintuitive interpretation, with their properties varying significantly across\ndifferent TN structures. Consequently, TN ranks are frequently treated as\nempirically tuned hyperparameters, rather than as key design parameters\ninferred from domain knowledge. The aim of this Lecture Note is therefore to\ndemystify the foundational yet frequently misunderstood concept of TN ranks\nthrough real-life examples and intuitive visualizations. We begin by\nillustrating how domain knowledge can guide the selection of TN ranks in\nwidely-used models such as the Canonical Polyadic (CP) and Tucker\ndecompositions. For more complex TN structures, we employ a self-explanatory\ngraphical approach that generalizes to tensors of arbitrary order. Such a\nperspective naturally reveals the relationship between TN ranks and the\ncorresponding ranks of tensor unfoldings (matrices), thereby circumventing\ncumbersome multi-index tensor algebra while facilitating domain-informed TN\ndesign. It is our hope that this Lecture Note will equip readers with a clear\nand unified understanding of the concept of TN rank, along with the necessary\nphysical insight and intuition to support the selection, explainability, and\ndeployment of tensor methods in both practical applications and educational\ncontexts.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u4f8b\u548c\u53ef\u89c6\u5316\u89e3\u91ca\u5f20\u91cf\u7f51\u7edc\uff08TN\uff09\u79e9\u6982\u5ff5\uff0c\u4ecb\u7ecd\u6839\u636e\u9886\u57df\u77e5\u8bc6\u9009TN\u79e9\u7684\u65b9\u6cd5\uff0c\u52a9\u529b\u8bfb\u8005\u7406\u89e3\u548c\u5e94\u7528\u3002", "motivation": "TN\u79e9\u7f3a\u4e4f\u901a\u7528\u610f\u4e49\u548c\u76f4\u89c2\u89e3\u91ca\uff0c\u5e38\u88ab\u5f53\u4f5c\u7ecf\u9a8c\u8c03\u6574\u7684\u8d85\u53c2\u6570\uff0c\u9700\u5bf9\u5176\u6982\u5ff5\u8fdb\u884c\u9610\u91ca\u3002", "method": "\u5148\u8bf4\u660e\u9886\u57df\u77e5\u8bc6\u5982\u4f55\u6307\u5bfc\u5e38\u7528\u6a21\u578bTN\u79e9\u9009\u62e9\uff0c\u518d\u7528\u56fe\u5f62\u65b9\u6cd5\u5904\u7406\u590d\u6742TN\u7ed3\u6784\u3002", "result": "\u63ed\u793aTN\u79e9\u4e0e\u5f20\u91cf\u5c55\u5f00\u77e9\u9635\u79e9\u7684\u5173\u7cfb\uff0c\u907f\u514d\u590d\u6742\u5f20\u91cf\u4ee3\u6570\u3002", "conclusion": "\u671f\u671b\u8bfb\u8005\u80fd\u6e05\u6670\u7edf\u4e00\u7406\u89e3TN\u79e9\u6982\u5ff5\uff0c\u5177\u5907\u7269\u7406\u6d1e\u5bdf\u548c\u76f4\u89c9\u4ee5\u652f\u6301\u5f20\u91cf\u65b9\u6cd5\u5e94\u7528\u548c\u6559\u5b66\u3002"}}
{"id": "2507.10172", "pdf": "https://arxiv.org/pdf/2507.10172", "abs": "https://arxiv.org/abs/2507.10172", "authors": ["Ruizhe Yu Xia", "Jeremy Gow", "Simon Lucas"], "title": "Play Style Identification Using Low-Level Representations of Play Traces in MicroRTS", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as Short Paper for IEEE CoG", "summary": "Play style identification can provide valuable game design insights and\nenable adaptive experiences, with the potential to improve game playing agents.\nPrevious work relies on domain knowledge to construct play trace\nrepresentations using handcrafted features. More recent approaches incorporate\nthe sequential structure of play traces but still require some level of domain\nabstraction. In this study, we explore the use of unsupervised CNN-LSTM\nautoencoder models to obtain latent representations directly from low-level\nplay trace data in MicroRTS. We demonstrate that this approach yields a\nmeaningful separation of different game playing agents in the latent space,\nreducing reliance on domain expertise and its associated biases. This latent\nspace is then used to guide the exploration of diverse play styles within\nstudied AI players.", "AI": {"tldr": "\u63a2\u7d22\u7528\u65e0\u76d1\u7763CNN - LSTM\u81ea\u7f16\u7801\u5668\u6a21\u578b\u4eceMicroRTS\u4f4e\u7ea7\u6e38\u620f\u8f68\u8ff9\u6570\u636e\u4e2d\u83b7\u53d6\u6f5c\u5728\u8868\u793a\uff0c\u7528\u4e8e\u6e38\u620f\u98ce\u683c\u8bc6\u522b\uff0c\u51cf\u5c11\u5bf9\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002", "motivation": "\u4ee5\u5f80\u6e38\u620f\u98ce\u683c\u8bc6\u522b\u65b9\u6cd5\u4f9d\u8d56\u9886\u57df\u77e5\u8bc6\u6784\u5efa\u7279\u5f81\uff0c\u6709\u5c40\u9650\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u51cf\u5c11\u5bf9\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u53ca\u76f8\u5173\u504f\u5dee\u7684\u4f9d\u8d56\u3002", "method": "\u4f7f\u7528\u65e0\u76d1\u7763CNN - LSTM\u81ea\u7f16\u7801\u5668\u6a21\u578b\u76f4\u63a5\u4eceMicroRTS\u7684\u4f4e\u7ea7\u6e38\u620f\u8f68\u8ff9\u6570\u636e\u4e2d\u83b7\u53d6\u6f5c\u5728\u8868\u793a\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e86\u4e0d\u540c\u6e38\u620f\u4ee3\u7406\u7684\u6709\u610f\u4e49\u5206\u79bb\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u53ef\u7528\u4e8e\u5f15\u5bfc\u7814\u7a76AI\u73a9\u5bb6\u4e2d\u591a\u6837\u5316\u6e38\u620f\u98ce\u683c\u7684\u63a2\u7d22\uff0c\u51cf\u5c11\u5bf9\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002"}}
{"id": "2507.10183", "pdf": "https://arxiv.org/pdf/2507.10183", "abs": "https://arxiv.org/abs/2507.10183", "authors": ["Alireza Dizaji", "Benedict Aaron Tjandra", "Mehrab Hamidi", "Shenyang Huang", "Guillaume Rabusseau"], "title": "T-GRAB: A Synthetic Diagnostic Benchmark for Learning on Temporal Graphs", "categories": ["cs.LG"], "comment": "Accepted to MLoG-GenAI Workshop @ KDD 2025 (Oral)", "summary": "Dynamic graph learning methods have recently emerged as powerful tools for\nmodelling relational data evolving through time. However, despite extensive\nbenchmarking efforts, it remains unclear whether current Temporal Graph Neural\nNetworks (TGNNs) effectively capture core temporal patterns such as\nperiodicity, cause-and-effect, and long-range dependencies. In this work, we\nintroduce the Temporal Graph Reasoning Benchmark (T-GRAB), a comprehensive set\nof synthetic tasks designed to systematically probe the capabilities of TGNNs\nto reason across time. T-GRAB provides controlled, interpretable tasks that\nisolate key temporal skills: counting/memorizing periodic repetitions,\ninferring delayed causal effects, and capturing long-range dependencies over\nboth spatial and temporal dimensions. We evaluate 11 temporal graph learning\nmethods on these tasks, revealing fundamental shortcomings in their ability to\ngeneralize temporal patterns. Our findings offer actionable insights into the\nlimitations of current models, highlight challenges hidden by traditional\nreal-world benchmarks, and motivate the development of architectures with\nstronger temporal reasoning abilities. The code for T-GRAB can be found at:\nhttps://github.com/alirezadizaji/T-GRAB.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165Temporal Graph Reasoning Benchmark (T - GRAB) \u6d4b\u8bd5TGNNs\u65f6\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u8bc4\u4f3011\u79cd\u65b9\u6cd5\u5e76\u63ed\u793a\u5176\u6cdb\u5316\u65f6\u95f4\u6a21\u5f0f\u7684\u7f3a\u9677\u3002", "motivation": "\u5f53\u524dTGNNs\u662f\u5426\u80fd\u6709\u6548\u6355\u6349\u6838\u5fc3\u65f6\u95f4\u6a21\u5f0f\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u8bc4\u4f30\u5176\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165T - GRAB\uff0c\u5305\u542b\u4e00\u7cfb\u5217\u5408\u6210\u4efb\u52a1\uff0c\u9694\u79bb\u5173\u952e\u65f6\u95f4\u6280\u80fd\uff0c\u5bf911\u79cd\u65f6\u95f4\u56fe\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u6cdb\u5316\u65f6\u95f4\u6a21\u5f0f\u4e0a\u5b58\u5728\u6839\u672c\u7f3a\u9677\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5c40\u9650\uff0c\u6307\u51fa\u4f20\u7edf\u57fa\u51c6\u9690\u85cf\u7684\u6311\u6218\uff0c\u63a8\u52a8\u66f4\u5f3a\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u67b6\u6784\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.09470", "pdf": "https://arxiv.org/pdf/2507.09470", "abs": "https://arxiv.org/abs/2507.09470", "authors": ["Mingchuan Yang", "Ziyuan Huang"], "title": "Enhancing Clinical Text Classification via Fine-Tuned DRAGON Longformer Models", "categories": ["cs.CL", "cs.AI", "68T07"], "comment": "29 pages, 5 tables", "summary": "This study explores the optimization of the DRAGON Longformer base model for\nclinical text classification, specifically targeting the binary classification\nof medical case descriptions. A dataset of 500 clinical cases containing\nstructured medical observations was used, with 400 cases for training and 100\nfor validation. Enhancements to the pre-trained\njoeranbosma/dragon-longformer-base-mixed-domain model included hyperparameter\ntuning, domain-specific preprocessing, and architectural adjustments. Key\nmodifications involved increasing sequence length from 512 to 1024 tokens,\nadjusting learning rates from 1e-05 to 5e-06, extending training epochs from 5\nto 8, and incorporating specialized medical terminology. The optimized model\nachieved notable performance gains: accuracy improved from 72.0% to 85.2%,\nprecision from 68.0% to 84.1%, recall from 75.0% to 86.3%, and F1-score from\n71.0% to 85.2%. Statistical analysis confirmed the significance of these\nimprovements (p < .001). The model demonstrated enhanced capability in\ninterpreting medical terminology, anatomical measurements, and clinical\nobservations. These findings contribute to domain-specific language model\nresearch and offer practical implications for clinical natural language\nprocessing applications. The optimized model's strong performance across\ndiverse medical conditions underscores its potential for broad use in\nhealthcare settings.", "AI": {"tldr": "\u7814\u7a76\u4f18\u5316DRAGON Longformer\u57fa\u7840\u6a21\u578b\u7528\u4e8e\u4e34\u5e8a\u6587\u672c\u4e8c\u5206\u7c7b\uff0c\u4f18\u5316\u540e\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u5bf9\u533b\u7597NLP\u6709\u5b9e\u9645\u610f\u4e49\u3002", "motivation": "\u63a2\u7d22DRAGON Longformer\u57fa\u7840\u6a21\u578b\u5728\u4e34\u5e8a\u6587\u672c\u5206\u7c7b\u4e2d\u7684\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u533b\u7597\u6848\u4f8b\u63cf\u8ff0\u7684\u4e8c\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u4f7f\u7528500\u4e2a\u4e34\u5e8a\u6848\u4f8b\u6570\u636e\u96c6\uff0c\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u8d85\u53c2\u6570\u8c03\u4f18\u3001\u7279\u5b9a\u9886\u57df\u9884\u5904\u7406\u548c\u67b6\u6784\u8c03\u6574\uff0c\u5982\u589e\u52a0\u5e8f\u5217\u957f\u5ea6\u3001\u8c03\u6574\u5b66\u4e60\u7387\u7b49\u3002", "result": "\u4f18\u5316\u540e\u6a21\u578b\u51c6\u786e\u7387\u4ece72.0%\u63d0\u5347\u523085.2%\uff0c\u591a\u9879\u6307\u6807\u663e\u8457\u63d0\u5347\uff0c\u7ecf\u7edf\u8ba1\u5206\u6790\u6539\u8fdb\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u6709\u52a9\u4e8e\u7279\u5b9a\u9886\u57df\u8bed\u8a00\u6a21\u578b\u7814\u7a76\uff0c\u4f18\u5316\u6a21\u578b\u5728\u533b\u7597\u573a\u666f\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.10194", "pdf": "https://arxiv.org/pdf/2507.10194", "abs": "https://arxiv.org/abs/2507.10194", "authors": ["Tassilo Klein", "Moin Nabi"], "title": "Learning Private Representations through Entropy-based Adversarial Training", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "How can we learn a representation with high predictive power while preserving\nuser privacy? We present an adversarial representation learning method for\nsanitizing sensitive content from the learned representation. Specifically, we\nintroduce a variant of entropy - focal entropy, which mitigates the potential\ninformation leakage of the existing entropy-based approaches. We showcase\nfeasibility on multiple benchmarks. The results suggest high target utility at\nmoderate privacy leakage.", "AI": {"tldr": "\u63d0\u51fa\u5bf9\u6297\u6027\u8868\u5f81\u5b66\u4e60\u65b9\u6cd5\u51c0\u5316\u654f\u611f\u5185\u5bb9\uff0c\u5f15\u5165\u7126\u70b9\u71b5\u53d8\u4f53\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u53ef\u884c\u6027\uff0c\u7ed3\u679c\u663e\u793a\u6709\u9ad8\u76ee\u6807\u6548\u7528\u548c\u9002\u5ea6\u9690\u79c1\u6cc4\u6f0f\u3002", "motivation": "\u5728\u4fdd\u7559\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u5b66\u4e60\u5177\u6709\u9ad8\u9884\u6d4b\u80fd\u529b\u7684\u8868\u5f81\u3002", "method": "\u63d0\u51fa\u5bf9\u6297\u6027\u8868\u5f81\u5b66\u4e60\u65b9\u6cd5\u51c0\u5316\u654f\u611f\u5185\u5bb9\uff0c\u5f15\u5165\u7126\u70b9\u71b5\u53d8\u4f53\u51cf\u8f7b\u73b0\u6709\u57fa\u4e8e\u71b5\u65b9\u6cd5\u7684\u6f5c\u5728\u4fe1\u606f\u6cc4\u6f0f\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u53ef\u884c\u6027\uff0c\u7ed3\u679c\u663e\u793a\u5177\u6709\u9ad8\u76ee\u6807\u6548\u7528\u548c\u9002\u5ea6\u7684\u9690\u79c1\u6cc4\u6f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5728\u4fdd\u7559\u7528\u6237\u9690\u79c1\u7684\u540c\u65f6\u5b66\u4e60\u5230\u5177\u6709\u9ad8\u9884\u6d4b\u80fd\u529b\u7684\u8868\u5f81\u3002"}}
{"id": "2507.09477", "pdf": "https://arxiv.org/pdf/2507.09477", "abs": "https://arxiv.org/abs/2507.09477", "authors": ["Yangning Li", "Weizhi Zhang", "Yuyao Yang", "Wei-Chieh Huang", "Yaozu Wu", "Junyu Luo", "Yuanchen Bei", "Henry Peng Zou", "Xiao Luo", "Yusheng Zhao", "Chunkit Chan", "Yankai Chen", "Zhongfen Deng", "Yinghui Li", "Hai-Tao Zheng", "Dongyuan Li", "Renhe Jiang", "Ming Zhang", "Yangqiu Song", "Philip S. Yu"], "title": "Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "submitted to ARR May", "summary": "Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language\nModels (LLMs) by injecting external knowledge, yet it falls short on problems\nthat demand multi-step inference; conversely, purely reasoning-oriented\napproaches often hallucinate or mis-ground facts. This survey synthesizes both\nstrands under a unified reasoning-retrieval perspective. We first map how\nadvanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then,\nwe show how retrieved knowledge of different type supply missing premises and\nexpand context for complex inference (RAG-Enhanced Reasoning). Finally, we\nspotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs\niteratively interleave search and reasoning to achieve state-of-the-art\nperformance across knowledge-intensive benchmarks. We categorize methods,\ndatasets, and open challenges, and outline research avenues toward deeper\nRAG-Reasoning systems that are more effective, multimodally-adaptive,\ntrustworthy, and human-centric. The collection is available at\nhttps://github.com/DavidZWZ/Awesome-RAG-Reasoning.", "AI": {"tldr": "\u672c\u6587\u4ece\u7edf\u4e00\u7684\u63a8\u7406 - \u68c0\u7d22\u89c6\u89d2\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u63a8\u7406\u65b9\u6cd5\u8fdb\u884c\u7efc\u8ff0\uff0c\u5206\u6790\u4e8c\u8005\u7ed3\u5408\u65b9\u5f0f\u3001\u5206\u7c7b\u65b9\u6cd5\u3001\u6570\u636e\u96c6\u548c\u6311\u6218\uff0c\u5e76\u6307\u51fa\u7814\u7a76\u65b9\u5411\u3002", "motivation": "RAG\u5728\u591a\u6b65\u63a8\u7406\u95ee\u9898\u4e0a\u4e0d\u8db3\uff0c\u7eaf\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u6216\u4e8b\u5b9e\u9519\u8bef\u95ee\u9898\uff0c\u9700\u7edf\u4e00\u89c6\u89d2\u7814\u7a76\u4e8c\u8005\u7ed3\u5408\u3002", "method": "\u4ece\u63a8\u7406\u589e\u5f3aRAG\u3001RAG\u589e\u5f3a\u63a8\u7406\u548c\u534f\u540cRAG - \u63a8\u7406\u6846\u67b6\u4e09\u4e2a\u65b9\u9762\u8fdb\u884c\u5206\u6790\uff0c\u5bf9\u65b9\u6cd5\u3001\u6570\u636e\u96c6\u7b49\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u63d0\u51fa\u65b0\u5174\u7684\u534f\u540cRAG - \u63a8\u7406\u6846\u67b6\uff0c\u53ef\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u6307\u51fa\u6784\u5efa\u66f4\u6709\u6548\u3001\u591a\u6a21\u6001\u81ea\u9002\u5e94\u3001\u53ef\u4fe1\u548c\u4ee5\u4eba\u4e3a\u672c\u7684\u6df1\u5ea6RAG - \u63a8\u7406\u7cfb\u7edf\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.10215", "pdf": "https://arxiv.org/pdf/2507.10215", "abs": "https://arxiv.org/abs/2507.10215", "authors": ["Cencheng Shen", "Yuexiao Dong"], "title": "A Graph Sufficiency Perspective for Neural Networks", "categories": ["cs.LG", "stat.AP"], "comment": "23 pages", "summary": "This paper analyzes neural networks through graph variables and statistical\nsufficiency. We interpret neural network layers as graph-based transformations,\nwhere neurons act as pairwise functions between inputs and learned anchor\npoints. Within this formulation, we establish conditions under which layer\noutputs are sufficient for the layer inputs, that is, each layer preserves the\nconditional distribution of the target variable given the input variable. Under\ndense anchor point assumptions, we prove that asymptotic sufficiency holds in\nthe infinite-width limit and is preserved throughout training. To align more\nclosely with practical architectures, we further show that sufficiency can be\nachieved with finite-width networks by assuming region-separated input\ndistributions and constructing appropriate anchor points. Our framework covers\nfully connected layers, general pairwise functions, ReLU and sigmoid\nactivations, and convolutional neural networks. This work bridges statistical\nsufficiency, graph-theoretic representations, and deep learning, providing a\nnew statistical understanding of neural networks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56fe\u53d8\u91cf\u548c\u7edf\u8ba1\u5145\u5206\u6027\u5206\u6790\u795e\u7ecf\u7f51\u7edc\uff0c\u5efa\u7acb\u5c42\u8f93\u51fa\u5bf9\u8f93\u5165\u5145\u5206\u7684\u6761\u4ef6\uff0c\u8bc1\u660e\u6e10\u8fd1\u5145\u5206\u6027\uff0c\u8fd8\u5c55\u793a\u6709\u9650\u5bbd\u5ea6\u7f51\u7edc\u4e5f\u53ef\u5b9e\u73b0\u5145\u5206\u6027\uff0c\u63d0\u4f9b\u65b0\u7edf\u8ba1\u7406\u89e3\u3002", "motivation": "\u4e3a\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u65b0\u7684\u7edf\u8ba1\u7406\u89e3\uff0c\u5c06\u7edf\u8ba1\u5145\u5206\u6027\u3001\u56fe\u8bba\u8868\u793a\u548c\u6df1\u5ea6\u5b66\u4e60\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u5c06\u795e\u7ecf\u7f51\u7edc\u5c42\u89e3\u91ca\u4e3a\u57fa\u4e8e\u56fe\u7684\u53d8\u6362\uff0c\u795e\u7ecf\u5143\u4f5c\u4e3a\u8f93\u5165\u548c\u5b66\u4e60\u7684\u951a\u70b9\u4e4b\u95f4\u7684\u6210\u5bf9\u51fd\u6570\uff0c\u5efa\u7acb\u5c42\u8f93\u51fa\u5bf9\u8f93\u5165\u5145\u5206\u7684\u6761\u4ef6\u3002", "result": "\u5728\u5bc6\u96c6\u951a\u70b9\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u65e0\u9650\u5bbd\u5ea6\u6781\u9650\u4e0b\u6e10\u8fd1\u5145\u5206\u6027\u6210\u7acb\u4e14\u8bad\u7ec3\u4e2d\u4fdd\u6301\uff1b\u5728\u533a\u57df\u5206\u79bb\u8f93\u5165\u5206\u5e03\u548c\u6784\u9020\u9002\u5f53\u951a\u70b9\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u9650\u5bbd\u5ea6\u7f51\u7edc\u4e5f\u53ef\u5b9e\u73b0\u5145\u5206\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6db5\u76d6\u591a\u79cd\u7f51\u7edc\u5c42\u548c\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u65b0\u7684\u7edf\u8ba1\u7406\u89e3\u3002"}}
{"id": "2507.10241", "pdf": "https://arxiv.org/pdf/2507.10241", "abs": "https://arxiv.org/abs/2507.10241", "authors": ["Vikas Dwivedi", "Balaji Srinivasan", "Monica Sigovan", "Bruno Sixou"], "title": "Kernel-Adaptive PI-ELMs for Forward and Inverse Problems in PDEs with Sharp Gradients", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces the Kernel Adaptive Physics-Informed Extreme Learning\nMachine (KAPI-ELM), an adaptive Radial Basis Function (RBF)-based extension of\nPI-ELM designed to solve both forward and inverse Partial Differential Equation\n(PDE) problems involving localized sharp gradients. While PI-ELMs outperform\nthe traditional Physics-Informed Neural Networks (PINNs) in speed due to their\nsingle-shot, least square optimization, this advantage comes at a cost: their\nfixed, randomly initialized input layer limits their ability to capture sharp\ngradients. To overcome this limitation, we introduce a lightweight Bayesian\nOptimization (BO) framework that, instead of adjusting each input layer\nparameter individually as in traditional backpropagation, learns a small set of\nhyperparameters defining the statistical distribution from which the input\nweights are drawn. This novel distributional optimization strategy -- combining\nBO for input layer distributional parameters with least-squares optimization\nfor output layer network parameters -- enables KAPI-ELM to preserve PI-ELM's\nspeed while matching or exceeding the expressiveness of PINNs. We validate the\nproposed methodology on several challenging forward and inverse PDE benchmarks,\nincluding a 1D singularly perturbed convection-diffusion equation, a 2D Poisson\nequation with sharp localized sources, and a time-dependent advection equation.\nNotably, KAPI-ELM achieves state-of-the-art accuracy in both forward and\ninverse settings. In stiff PDE regimes, it matches or even outperforms advanced\nmethods such as the Extended Theory of Functional Connections (XTFC), while\nrequiring nearly an order of magnitude fewer tunable parameters. These results\nestablish the potential of KAPI-ELM as a scalable, interpretable, and\ngeneralizable physics-informed learning framework, especially in stiff PDE\nregimes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faKAPI - ELM\u89e3\u51b3\u542b\u5c40\u90e8\u5c16\u9510\u68af\u5ea6\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u95ee\u9898\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "PI - ELMs\u56fa\u5b9a\u968f\u673a\u521d\u59cb\u5316\u8f93\u5165\u5c42\u9650\u5236\u6355\u6349\u5c16\u9510\u68af\u5ea6\u80fd\u529b\uff0c\u9700\u6539\u8fdb\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\u5b66\u4e60\u8f93\u5165\u6743\u91cd\u7edf\u8ba1\u5206\u5e03\u7684\u8d85\u53c2\u6570\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u8f93\u5165\u5c42\u5206\u5e03\u53c2\u6570\u4e0e\u8f93\u51fa\u5c42\u6700\u5c0f\u4e8c\u4e58\u6cd5\u4f18\u5316\u3002", "result": "KAPI - ELM\u5728\u6b63\u53cd\u95ee\u9898\u4e2d\u8fbe\u6700\u4f18\u7cbe\u5ea6\uff0c\u5728\u521a\u6027PDE\u533a\u57df\u8868\u73b0\u4f73\u4e14\u53ef\u8c03\u53c2\u6570\u5c11\u3002", "conclusion": "KAPI - ELM\u662f\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u3001\u901a\u7528\u7684\u7269\u7406\u4fe1\u606f\u5b66\u4e60\u6846\u67b6\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u521a\u6027PDE\u533a\u57df\u3002"}}
{"id": "2507.09482", "pdf": "https://arxiv.org/pdf/2507.09482", "abs": "https://arxiv.org/abs/2507.09482", "authors": ["Changli Wang", "Rui Wu", "Fang Yin"], "title": "ViSP: A PPO-Driven Framework for Sarcasm Generation with Contrastive Learning", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Human emotions are complex, with sarcasm being a subtle and distinctive form.\nDespite progress in sarcasm research, sarcasm generation remains underexplored,\nprimarily due to the overreliance on textual modalities and the neglect of\nvisual cues, as well as the mismatch between image content and sarcastic intent\nin existing datasets. In this paper, we introduce M2SaG, a multimodal sarcasm\ngeneration dataset with 4,970 samples, each containing an image, a sarcastic\ntext, and a sarcasm target. To benchmark M2SaG, we propose ViSP, a generation\nframework that integrates Proximal Policy Optimization (PPO) and contrastive\nlearning. PPO utilizes reward scores from DIP to steer the generation of\nsarcastic texts, while contrastive learning encourages the model to favor\noutputs with higher reward scores. These strategies improve overall generation\nquality and produce texts with more pronounced sarcastic intent. We evaluate\nViSP across five metric sets and find it surpasses all baselines, including\nlarge language models, underscoring their limitations in sarcasm generation.\nFurthermore, we analyze the distributions of Sarcasm Scores and Factual\nIncongruity for both M2SaG and the texts generated by ViSP. The generated texts\nexhibit higher mean Sarcasm Scores (0.898 vs. 0.770) and Factual Incongruity\n(0.768 vs. 0.739), demonstrating that ViSP produces higher-quality sarcastic\ncontent than the original dataset. % The dataset and code will be publicly\navailable. Our dataset and code will be released at\n\\textit{https://github.com/wclapply/ViSP}.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u591a\u6a21\u6001\u8bbd\u523a\u751f\u6210\u6570\u636e\u96c6M2SaG\uff0c\u63d0\u51faViSP\u6846\u67b6\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u751f\u6210\u5185\u5bb9\u8d28\u91cf\u66f4\u9ad8\u3002", "motivation": "\u8bbd\u523a\u751f\u6210\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u6a21\u6001\u3001\u5ffd\u89c6\u89c6\u89c9\u7ebf\u7d22\uff0c\u4e14\u73b0\u6709\u6570\u636e\u96c6\u56fe\u50cf\u5185\u5bb9\u4e0e\u8bbd\u523a\u610f\u56fe\u4e0d\u5339\u914d\u3002", "method": "\u5f15\u5165\u542b4970\u4e2a\u6837\u672c\u7684M2SaG\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u96c6\u6210PPO\u548c\u5bf9\u6bd4\u5b66\u4e60\u7684ViSP\u6846\u67b6\uff0cPPO\u5229\u7528\u5956\u52b1\u5206\u6570\u5f15\u5bfc\u751f\u6210\uff0c\u5bf9\u6bd4\u5b66\u4e60\u4fc3\u4f7f\u6a21\u578b\u9009\u62e9\u5956\u52b1\u5206\u6570\u9ad8\u7684\u8f93\u51fa\u3002", "result": "ViSP\u5728\u4e94\u9879\u6307\u6807\u4e0a\u8d85\u8d8a\u6240\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u751f\u6210\u6587\u672c\u7684\u8bbd\u523a\u5f97\u5206\u548c\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u6027\u5747\u503c\u66f4\u9ad8\u3002", "conclusion": "ViSP\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u8bbd\u523a\u5185\u5bb9\uff0c\u51f8\u663e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bbd\u523a\u751f\u6210\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.10273", "pdf": "https://arxiv.org/pdf/2507.10273", "abs": "https://arxiv.org/abs/2507.10273", "authors": ["Lu Zhu", "Emmanuel Noutahi"], "title": "Conditional Chemical Language Models are Versatile Tools in Drug Discovery", "categories": ["cs.LG", "q-bio.BM"], "comment": "12 pages, extra 13 pages of appendix", "summary": "Generative chemical language models (CLMs) have demonstrated strong\ncapabilities in molecular design, yet their impact in drug discovery remains\nlimited by the absence of reliable reward signals and the lack of\ninterpretability in their outputs. We present SAFE-T, a generalist chemical\nmodeling framework that conditions on biological context -- such as protein\ntargets or mechanisms of action -- to prioritize and design molecules without\nrelying on structural information or engineered scoring functions. SAFE-T\nmodels the conditional likelihood of fragment-based molecular sequences given a\nbiological prompt, enabling principled scoring of molecules across tasks such\nas virtual screening, drug-target interaction prediction, and activity cliff\ndetection. Moreover, it supports goal-directed generation by sampling from this\nlearned distribution, aligning molecular design with biological objectives. In\ncomprehensive zero-shot evaluations across predictive (LIT-PCBA, DAVIS, KIBA,\nACNet) and generative (DRUG, PMO) benchmarks, SAFE-T consistently achieves\nperformance comparable to or better than existing approaches while being\nsignificantly faster. Fragment-level attribution further reveals that SAFE-T\ncaptures known structure-activity relationships, supporting interpretable and\nbiologically grounded design. Together with its computational efficiency, these\nresults demonstrate that conditional generative CLMs can unify scoring and\ngeneration to accelerate early-stage drug discovery.", "AI": {"tldr": "\u63d0\u51faSAFE - T\u5316\u5b66\u5efa\u6a21\u6846\u67b6\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f73\uff0c\u80fd\u7edf\u4e00\u8bc4\u5206\u548c\u751f\u6210\u4ee5\u52a0\u901f\u836f\u7269\u53d1\u73b0\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u5f0f\u5316\u5b66\u8bed\u8a00\u6a21\u578b\u56e0\u7f3a\u4e4f\u53ef\u9760\u5956\u52b1\u4fe1\u53f7\u548c\u8f93\u51fa\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u53d7\u9650\u3002", "method": "\u63d0\u51faSAFE - T\u6846\u67b6\uff0c\u57fa\u4e8e\u751f\u7269\u63d0\u793a\u5bf9\u57fa\u4e8e\u7247\u6bb5\u7684\u5206\u5b50\u5e8f\u5217\u6761\u4ef6\u4f3c\u7136\u8fdb\u884c\u5efa\u6a21\uff0c\u652f\u6301\u76ee\u6807\u5bfc\u5411\u751f\u6210\u3002", "result": "\u5728\u591a\u4e2a\u9884\u6d4b\u548c\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSAFE - T\u8868\u73b0\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u4e14\u901f\u5ea6\u66f4\u5feb\uff0c\u7247\u6bb5\u7ea7\u5f52\u56e0\u663e\u793a\u5176\u6355\u6349\u5230\u5df2\u77e5\u6784\u6548\u5173\u7cfb\u3002", "conclusion": "\u6761\u4ef6\u751f\u6210\u5f0f\u5316\u5b66\u8bed\u8a00\u6a21\u578b\u53ef\u7edf\u4e00\u8bc4\u5206\u548c\u751f\u6210\uff0c\u52a0\u901f\u65e9\u671f\u836f\u7269\u53d1\u73b0\u3002"}}
{"id": "2507.09487", "pdf": "https://arxiv.org/pdf/2507.09487", "abs": "https://arxiv.org/abs/2507.09487", "authors": ["Changli Wang", "Fang Yin", "Jiafeng Liu", "Rui Wu"], "title": "HMID-Net: An Exploration of Masked Image Modeling and Knowledge Distillation in Hyperbolic Space", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Visual and semantic concepts are often structured in a hierarchical manner.\nFor instance, textual concept `cat' entails all images of cats. A recent study,\nMERU, successfully adapts multimodal learning techniques from Euclidean space\nto hyperbolic space, effectively capturing the visual-semantic hierarchy.\nHowever, a critical question remains: how can we more efficiently train a model\nto capture and leverage this hierarchy? In this paper, we propose the\n\\textit{Hyperbolic Masked Image and Distillation Network} (HMID-Net), a novel\nand efficient method that integrates Masked Image Modeling (MIM) and knowledge\ndistillation techniques within hyperbolic space. To the best of our knowledge,\nthis is the first approach to leverage MIM and knowledge distillation in\nhyperbolic space to train highly efficient models. In addition, we introduce a\ndistillation loss function specifically designed to facilitate effective\nknowledge transfer in hyperbolic space. Our experiments demonstrate that MIM\nand knowledge distillation techniques in hyperbolic space can achieve the same\nremarkable success as in Euclidean space. Extensive evaluations show that our\nmethod excels across a wide range of downstream tasks, significantly\noutperforming existing models like MERU and CLIP in both image classification\nand retrieval.", "AI": {"tldr": "\u63d0\u51faHyperbolic Masked Image and Distillation Network (HMID - Net)\u5728\u53cc\u66f2\u7a7a\u95f4\u96c6\u6210MIM\u548c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u8bad\u7ec3\u9ad8\u6548\u6a21\u578b\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5982\u4f55\u66f4\u6709\u6548\u5730\u8bad\u7ec3\u6a21\u578b\u4ee5\u6355\u6349\u548c\u5229\u7528\u89c6\u89c9 - \u8bed\u4e49\u5c42\u6b21\u7ed3\u6784\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faHMID - Net\uff0c\u5728\u53cc\u66f2\u7a7a\u95f4\u96c6\u6210MIM\u548c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\uff0c\u5f15\u5165\u4e13\u95e8\u7684\u84b8\u998f\u635f\u5931\u51fd\u6570\u3002", "result": "MIM\u548c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5728\u53cc\u66f2\u7a7a\u95f4\u53d6\u5f97\u4e0e\u6b27\u6c0f\u7a7a\u95f4\u540c\u6837\u7684\u6210\u529f\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "HMID - Net\u65b9\u6cd5\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u68c0\u7d22\u7b49\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8eMERU\u548cCLIP\u7b49\u73b0\u6709\u6a21\u578b\u3002"}}
{"id": "2507.09492", "pdf": "https://arxiv.org/pdf/2507.09492", "abs": "https://arxiv.org/abs/2507.09492", "authors": ["Fuyin Ye", "Erwen Yao", "Jianyong Chen", "Fengmei He", "Junxiang Zhang", "Lihao Ni"], "title": "SDTN and TRN: Adaptive Spectral-Spatial Feature Extraction for Hyperspectral Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": "4 pages, 2 figures", "summary": "Hyperspectral image classification plays a pivotal role in precision\nagriculture, providing accurate insights into crop health monitoring, disease\ndetection, and soil analysis. However, traditional methods struggle with\nhigh-dimensional data, spectral-spatial redundancy, and the scarcity of labeled\nsamples, often leading to suboptimal performance. To address these challenges,\nwe propose the Self-Adaptive Tensor- Regularized Network (SDTN), which combines\ntensor decomposition with regularization mechanisms to dynamically adjust\ntensor ranks, ensuring optimal feature representation tailored to the\ncomplexity of the data. Building upon SDTN, we propose the Tensor-Regularized\nNetwork (TRN), which integrates the features extracted by SDTN into a\nlightweight network capable of capturing spectral-spatial features at multiple\nscales. This approach not only maintains high classification accuracy but also\nsignificantly reduces computational complexity, making the framework highly\nsuitable for real-time deployment in resource-constrained environments.\nExperiments on PaviaU datasets demonstrate significant improvements in accuracy\nand reduced model parameters compared to state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faSDTN\u548cTRN\u7528\u4e8e\u9ad8\u5149\u8c31\u56fe\u50cf\u5206\u7c7b\uff0c\u5728PaviaU\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u9ad8\u5149\u8c31\u56fe\u50cf\u5206\u7c7b\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u3001\u5149\u8c31\u7a7a\u95f4\u5197\u4f59\u548c\u6807\u8bb0\u6837\u672c\u7a00\u7f3a\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u7406\u60f3\u3002", "method": "\u63d0\u51faSDTN\u7ed3\u5408\u5f20\u91cf\u5206\u89e3\u4e0e\u6b63\u5219\u5316\u673a\u5236\u52a8\u6001\u8c03\u6574\u5f20\u91cf\u79e9\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51faTRN\uff0c\u5c06SDTN\u63d0\u53d6\u7684\u7279\u5f81\u96c6\u6210\u5230\u8f7b\u91cf\u7ea7\u7f51\u7edc\u4e2d\uff0c\u591a\u5c3a\u5ea6\u6355\u83b7\u5149\u8c31\u7a7a\u95f4\u7279\u5f81\u3002", "result": "\u5728PaviaU\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u51c6\u786e\u6027\u663e\u8457\u63d0\u9ad8\uff0c\u6a21\u578b\u53c2\u6570\u51cf\u5c11\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e0d\u4ec5\u4fdd\u6301\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8fd8\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2507.10311", "pdf": "https://arxiv.org/pdf/2507.10311", "abs": "https://arxiv.org/abs/2507.10311", "authors": ["Liming Wang", "Saurabhchand Bhati", "Cody Karjadi", "Rhoda Au", "James Glass"], "title": "Recognizing Dementia from Neuropsychological Tests with State Space Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Early detection of dementia is critical for timely medical intervention and\nimproved patient outcomes. Neuropsychological tests are widely used for\ncognitive assessment but have traditionally relied on manual scoring. Automatic\ndementia classification (ADC) systems aim to infer cognitive decline directly\nfrom speech recordings of such tests. We propose Demenba, a novel ADC framework\nbased on state space models, which scale linearly in memory and computation\nwith sequence length. Trained on over 1,000 hours of cognitive assessments\nadministered to Framingham Heart Study participants, some of whom were\ndiagnosed with dementia through adjudicated review, our method outperforms\nprior approaches in fine-grained dementia classification by 21\\%, while using\nfewer parameters. We further analyze its scaling behavior and demonstrate that\nour model gains additional improvement when fused with large language models,\npaving the way for more transparent and scalable dementia assessment tools.\nCode: https://anonymous.4open.science/r/Demenba-0861", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u65b0\u578b\u81ea\u52a8\u75f4\u5446\u5206\u7c7b\u6846\u67b6Demenba\uff0c\u5728\u7ec6\u7c92\u5ea6\u75f4\u5446\u5206\u7c7b\u4e0a\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u6709\u989d\u5916\u63d0\u5347\u3002", "motivation": "\u65e9\u671f\u68c0\u6d4b\u75f4\u5446\u5bf9\u53ca\u65f6\u533b\u7597\u5e72\u9884\u548c\u6539\u5584\u60a3\u8005\u9884\u540e\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u795e\u7ecf\u5fc3\u7406\u6d4b\u8bd5\u624b\u52a8\u8bc4\u5206\uff0c\u81ea\u52a8\u75f4\u5446\u5206\u7c7b\u7cfb\u7edf\u65e8\u5728\u4ece\u8bed\u97f3\u8bb0\u5f55\u63a8\u65ad\u8ba4\u77e5\u8870\u9000\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684Demenba\u6846\u67b6\uff0c\u5728\u8d851000\u5c0f\u65f6\u8ba4\u77e5\u8bc4\u4f30\u6570\u636e\u4e0a\u8bad\u7ec3\u3002", "result": "\u5728\u7ec6\u7c92\u5ea6\u75f4\u5446\u5206\u7c7b\u4e0a\u6bd4\u5148\u524d\u65b9\u6cd5\u9ad821%\uff0c\u4f7f\u7528\u53c2\u6570\u66f4\u5c11\uff0c\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u6709\u989d\u5916\u63d0\u5347\u3002", "conclusion": "\u4e3a\u66f4\u900f\u660e\u548c\u53ef\u6269\u5c55\u7684\u75f4\u5446\u8bc4\u4f30\u5de5\u5177\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.09508", "pdf": "https://arxiv.org/pdf/2507.09508", "abs": "https://arxiv.org/abs/2507.09508", "authors": ["Weichen Yu", "Ravi Mangal", "Terry Zhuo", "Matt Fredrikson", "Corina S. Pasareanu"], "title": "A Mixture of Linear Corrections Generates Secure Code", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have become proficient at sophisticated\ncode-generation tasks, yet remain ineffective at reliably detecting or avoiding\ncode vulnerabilities. Does this deficiency stem from insufficient learning\nabout code vulnerabilities, or is it merely a result of ineffective prompting?\nUsing representation engineering techniques, we investigate whether LLMs\ninternally encode the concepts necessary to identify code vulnerabilities. We\nfind that current LLMs encode precise internal representations that distinguish\nvulnerable from secure code--achieving greater accuracy than standard prompting\napproaches. Leveraging these vulnerability-sensitive representations, we\ndevelop an inference-time steering technique that subtly modulates the model's\ntoken-generation probabilities through a mixture of corrections (MoC). Our\nmethod effectively guides LLMs to produce less vulnerable code without\ncompromising functionality, demonstrating a practical approach to controlled\nvulnerability management in generated code. Notably, MoC enhances the security\nratio of Qwen2.5-Coder-7B by 8.9\\%, while simultaneously improving\nfunctionality on HumanEval pass@1 by 2.1\\%.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u80fd\u7f16\u7801\u533a\u5206\u4ee3\u7801\u6f0f\u6d1e\u7684\u8868\u793a\uff0c\u5f00\u53d1MoC\u6280\u672f\u6709\u6548\u51cf\u5c11\u751f\u6210\u4ee3\u7801\u6f0f\u6d1e\u5e76\u63d0\u5347\u529f\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u548c\u907f\u514d\u65b9\u9762\u4e0d\u8db3\uff0c\u63a2\u7a76\u662f\u5b66\u4e60\u4e0d\u8db3\u8fd8\u662f\u63d0\u793a\u65e0\u6548\u5bfc\u81f4\u3002", "method": "\u8fd0\u7528\u8868\u793a\u5de5\u7a0b\u6280\u672f\u7814\u7a76\u6a21\u578b\u5185\u90e8\u7f16\u7801\uff0c\u5f00\u53d1\u63a8\u7406\u65f6\u7684\u6df7\u5408\u4fee\u6b63\uff08MoC\uff09\u6280\u672f\u8c03\u5236\u6a21\u578b\u751f\u6210\u6982\u7387\u3002", "result": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u7f16\u7801\u533a\u5206\u6f0f\u6d1e\u4e0e\u5b89\u5168\u4ee3\u7801\u7684\u8868\u793a\uff0cMoC\u4f7fQwen2.5 - Coder - 7B\u5b89\u5168\u6bd4\u7387\u63d0\u53478.9%\uff0cHumanEval pass@1\u529f\u80fd\u63d0\u53472.1%\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u751f\u6210\u4ee3\u7801\u6f0f\u6d1e\u7ba1\u7406\u65b9\u6cd5\uff0c\u53ef\u5728\u4e0d\u5f71\u54cd\u529f\u80fd\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u6f0f\u6d1e\u3002"}}
{"id": "2507.09514", "pdf": "https://arxiv.org/pdf/2507.09514", "abs": "https://arxiv.org/abs/2507.09514", "authors": ["Tien-Yu Chi", "Hung-Yueh Chiang", "Diana Marculescu", "Kai-Chiang Wu"], "title": "QuarterMap: Efficient Post-Training Token Pruning for Visual State Space Models", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by Efficient Systems for Foundation Models Workshop at the\n  International Conference on Machine Learning (ICML) 2025", "summary": "State space models (SSMs) reduce the quadratic complexity of transformers by\nleveraging linear recurrence. Recently, VMamba has emerged as a strong\nSSM-based vision backbone, yet remains bottlenecked by spatial redundancy in\nits four-directional scan. We propose QuarterMap, a post-training activation\npruning method that removes redundant spatial activations before scanning and\nrestores dimensions via nearest-neighbor upsampling. Our method improves\nthroughput without retraining. On ImageNet-1K, QuarterMap achieves up to 11%\nspeedup on VMamba with less than 0.9% accuracy drop, and yields similar gains\non ADE20K segmentation. Beyond VMamba, we validate QuarterMap on MedMamba, a\ndomain-specific model that shares the same four-directional scanning structure,\nwhere it consistently improves throughput while preserving accuracy across\nmultiple medical imaging tasks. Compared to token merging methods like ToMe,\nQuarterMap is tailored for SSMs and avoids costly merge-unmerge operations. Our\nmethod offers a plug-and-play tool for deployment-time efficiency without\ncompromising transferability.", "AI": {"tldr": "\u63d0\u51faQuarterMap\u65b9\u6cd5\u53bb\u9664SSM\u6a21\u578b\u5197\u4f59\u6fc0\u6d3b\uff0c\u63d0\u5347\u541e\u5410\u91cf\uff0c\u5728\u591a\u4efb\u52a1\u4e0a\u6709\u6548\u4e14\u907f\u514d\u9ad8\u6210\u672c\u64cd\u4f5c\u3002", "motivation": "VMamba\u4f5c\u4e3a\u57fa\u4e8eSSM\u7684\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\uff0c\u53d7\u56db\u5411\u626b\u63cf\u4e2d\u7a7a\u95f4\u5197\u4f59\u7684\u74f6\u9888\u9650\u5236\u3002", "method": "\u63d0\u51faQuarterMap\uff0c\u4e00\u79cd\u8bad\u7ec3\u540e\u6fc0\u6d3b\u526a\u679d\u65b9\u6cd5\uff0c\u626b\u63cf\u524d\u53bb\u9664\u5197\u4f59\u7a7a\u95f4\u6fc0\u6d3b\uff0c\u901a\u8fc7\u6700\u8fd1\u90bb\u4e0a\u91c7\u6837\u6062\u590d\u7ef4\u5ea6\u3002", "result": "\u5728ImageNet - 1K\u4e0aVMamba\u63d0\u901f11%\u4e14\u7cbe\u5ea6\u635f\u5931\u5c0f\u4e8e0.9%\uff0c\u5728ADE20K\u5206\u5272\u4e0a\u6709\u7c7b\u4f3c\u63d0\u5347\uff1b\u5728MedMamba\u4e0a\u63d0\u5347\u541e\u5410\u91cf\u5e76\u4fdd\u6301\u7cbe\u5ea6\uff1b\u76f8\u6bd4ToMe\u907f\u514d\u4e86\u9ad8\u6210\u672c\u64cd\u4f5c\u3002", "conclusion": "QuarterMap\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u5de5\u5177\uff0c\u80fd\u5728\u4e0d\u5f71\u54cd\u53ef\u8fc1\u79fb\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u90e8\u7f72\u6548\u7387\u3002"}}
{"id": "2507.10334", "pdf": "https://arxiv.org/pdf/2507.10334", "abs": "https://arxiv.org/abs/2507.10334", "authors": ["Mahmoud Bekhit", "Ahmad Salah", "Ahmed Salim Alrawahi", "Tarek Attia", "Ahmed Ali", "Esraa Eldesokey", "Ahmed Fathalla"], "title": "MoCap-Impute: A Comprehensive Benchmark and Comparative Analysis of Imputation Methods for IMU-based Motion Capture Data", "categories": ["cs.LG"], "comment": "22 pages, 7 figures, 3 algorithms, 2 tables", "summary": "Motion capture (MoCap) data from wearable Inertial Measurement Units (IMUs)\nis vital for applications in sports science, but its utility is often\ncompromised by missing data. Despite numerous imputation techniques, a\nsystematic performance evaluation for IMU-derived MoCap time-series data is\nlacking. We address this gap by conducting a comprehensive comparative analysis\nof statistical, machine learning, and deep learning imputation methods. Our\nevaluation considers three distinct contexts: univariate time-series,\nmultivariate across subjects, and multivariate across kinematic angles. To\nfacilitate this benchmark, we introduce the first publicly available MoCap\ndataset designed specifically for imputation, featuring data from 53 karate\npractitioners. We simulate three controlled missingness mechanisms: missing\ncompletely at random (MCAR), block missingness, and a novel value-dependent\npattern at signal transition points. Our experiments, conducted on 39 kinematic\nvariables across all subjects, reveal that multivariate imputation frameworks\nconsistently outperform univariate approaches, particularly for complex\nmissingness. For instance, multivariate methods achieve up to a 50% mean\nabsolute error reduction (MAE from 10.8 to 5.8) compared to univariate\ntechniques for transition point missingness. Advanced models like Generative\nAdversarial Imputation Networks (GAIN) and Iterative Imputers demonstrate the\nhighest accuracy in these challenging scenarios. This work provides a critical\nbaseline for future research and offers practical recommendations for improving\nthe integrity and robustness of Mo-Cap data analysis.", "AI": {"tldr": "\u5bf9IMU\u884d\u751f\u7684\u52a8\u4f5c\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7f3a\u5931\u503c\u63d2\u8865\u65b9\u6cd5\u8fdb\u884c\u7efc\u5408\u6bd4\u8f83\u5206\u6790\uff0c\u5f15\u5165\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u591a\u53d8\u91cf\u63d2\u8865\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7ebf\u3002", "motivation": "IMU\u52a8\u4f5c\u6355\u6349\u6570\u636e\u5e38\u5b58\u5728\u7f3a\u5931\u503c\u95ee\u9898\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u7684\u63d2\u8865\u65b9\u6cd5\u6027\u80fd\u8bc4\u4f30\u3002", "method": "\u5bf9\u7edf\u8ba1\u3001\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u63d2\u8865\u65b9\u6cd5\u8fdb\u884c\u7efc\u5408\u6bd4\u8f83\u5206\u6790\uff0c\u8003\u8651\u4e09\u79cd\u4e0d\u540c\u60c5\u5883\uff0c\u5f15\u5165\u516c\u5f00\u6570\u636e\u96c6\uff0c\u6a21\u62df\u4e09\u79cd\u7f3a\u5931\u673a\u5236\u3002", "result": "\u591a\u53d8\u91cf\u63d2\u8865\u6846\u67b6\u59cb\u7ec8\u4f18\u4e8e\u5355\u53d8\u91cf\u65b9\u6cd5\uff0c\u9ad8\u7ea7\u6a21\u578b\u5982GAIN\u548c\u8fed\u4ee3\u63d2\u8865\u5668\u5728\u590d\u6742\u7f3a\u5931\u60c5\u51b5\u4e0b\u7cbe\u5ea6\u6700\u9ad8\u3002", "conclusion": "\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u5173\u952e\u57fa\u7ebf\uff0c\u4e3a\u6539\u5584\u52a8\u4f5c\u6355\u6349\u6570\u636e\u5206\u6790\u7684\u5b8c\u6574\u6027\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2507.10345", "pdf": "https://arxiv.org/pdf/2507.10345", "abs": "https://arxiv.org/abs/2507.10345", "authors": ["Yuwen Li", "Guozhi Zhang"], "title": "Some Super-approximation Rates of ReLU Neural Networks for Korobov Functions", "categories": ["cs.LG"], "comment": null, "summary": "This paper examines the $L_p$ and $W^1_p$ norm approximation errors of ReLU\nneural networks for Korobov functions. In terms of network width and depth, we\nderive nearly optimal super-approximation error bounds of order $2m$ in the\n$L_p$ norm and order $2m-2$ in the $W^1_p$ norm, for target functions with\n$L_p$ mixed derivative of order $m$ in each direction. The analysis leverages\nsparse grid finite elements and the bit extraction technique. Our results\nimprove upon classical lowest order $L_\\infty$ and $H^1$ norm error bounds and\ndemonstrate that the expressivity of neural networks is largely unaffected by\nthe curse of dimensionality.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76ReLU\u795e\u7ecf\u7f51\u7edc\u5bf9Korobov\u51fd\u6570\u7684Lp\u548cW1p\u8303\u6570\u903c\u8fd1\u8bef\u5dee\uff0c\u63a8\u5bfc\u8fd1\u6700\u4f18\u8d85\u903c\u8fd1\u8bef\u5dee\u754c\uff0c\u7ed3\u679c\u4f18\u4e8e\u7ecf\u5178\u754c\uff0c\u8868\u660e\u795e\u7ecf\u7f51\u7edc\u8868\u8fbe\u80fd\u529b\u53d7\u7ef4\u6570\u707e\u96be\u5f71\u54cd\u5c0f\u3002", "motivation": "\u7814\u7a76ReLU\u795e\u7ecf\u7f51\u7edc\u5bf9Korobov\u51fd\u6570\u7684Lp\u548cW1p\u8303\u6570\u903c\u8fd1\u8bef\u5dee\uff0c\u83b7\u53d6\u66f4\u4f18\u8bef\u5dee\u754c\u3002", "method": "\u5229\u7528\u7a00\u758f\u7f51\u683c\u6709\u9650\u5143\u548c\u6bd4\u7279\u63d0\u53d6\u6280\u672f\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5bf9\u4e8e\u5404\u65b9\u5411Lp\u6df7\u5408\u5bfc\u6570\u4e3am\u9636\u7684\u76ee\u6807\u51fd\u6570\uff0c\u63a8\u5bfc\u51faLp\u8303\u6570\u4e0b\u9636\u4e3a2m\u3001W1p\u8303\u6570\u4e0b\u9636\u4e3a2m - 2\u7684\u8fd1\u6700\u4f18\u8d85\u903c\u8fd1\u8bef\u5dee\u754c\uff0c\u7ed3\u679c\u4f18\u4e8e\u7ecf\u5178L\u221e\u548cH1\u8303\u6570\u8bef\u5dee\u754c\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4e0d\u53d7\u7ef4\u6570\u707e\u96be\u7684\u5f71\u54cd\u3002"}}
{"id": "2507.09531", "pdf": "https://arxiv.org/pdf/2507.09531", "abs": "https://arxiv.org/abs/2507.09531", "authors": ["Son Nguyen", "Giang Nguyen", "Hung Dao", "Thao Do", "Daeyoung Kim"], "title": "VDInstruct: Zero-Shot Key Information Extraction via Content-Aware Vision Tokenization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Key Information Extraction (KIE) underpins the understanding of visual\ndocuments (e.g., receipts and contracts) by extracting precise semantic content\nand accurately capturing spatial structure. Yet existing multimodal large\nlanguage models (MLLMs) often perform poorly on dense documents and rely on\nvision tokenization approaches that scale with image size, leading to redundant\ncomputation and memory inefficiency. To address these challenges, we introduce\nVDInstruct, an MLLM that separates spatial region detection from semantic\nfeature extraction. Central to our model is a content-aware tokenization\nstrategy: rather than fragmenting the entire image uniformly, it generates\ntokens in proportion to document complexity, preserving critical structure\nwhile eliminating wasted tokens. Leveraging a three-stage training paradigm,\nour model achieves state-of-the-art (SOTA) results on KIE benchmarks, matching\nor exceeding the accuracy of leading approaches while reducing the number of\nimage tokens by roughly 3.6x. In zero-shot evaluations, VDInstruct surpasses\nstrong baselines-such as DocOwl 1.5-by +5.5 F1 points, highlighting its\nrobustness to unseen documents. These findings show that content-aware\ntokenization combined with explicit layout modeling offers a promising\ndirection forward for document understanding. Data, source code, and model\nweights will be made publicly available.", "AI": {"tldr": "\u63d0\u51faMLLM\u6a21\u578bVDInstruct\uff0c\u91c7\u7528\u5185\u5bb9\u611f\u77e5\u6807\u8bb0\u7b56\u7565\uff0c\u5728KIE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\uff0c\u51cf\u5c11\u56fe\u50cf\u6807\u8bb0\u6570\u91cf\uff0c\u96f6\u6837\u672c\u8bc4\u4f30\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bc6\u96c6\u6587\u6863\u4e0a\u8868\u73b0\u5dee\uff0c\u89c6\u89c9\u6807\u8bb0\u5316\u65b9\u6cd5\u5b58\u5728\u5197\u4f59\u8ba1\u7b97\u548c\u5185\u5b58\u4f4e\u6548\u95ee\u9898\u3002", "method": "\u5f15\u5165VDInstruct\u6a21\u578b\uff0c\u5c06\u7a7a\u95f4\u533a\u57df\u68c0\u6d4b\u4e0e\u8bed\u4e49\u7279\u5f81\u63d0\u53d6\u5206\u79bb\uff0c\u91c7\u7528\u5185\u5bb9\u611f\u77e5\u6807\u8bb0\u7b56\u7565\uff0c\u4f7f\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "\u5728KIE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\uff0c\u51cf\u5c11\u7ea63.6\u500d\u56fe\u50cf\u6807\u8bb0\u6570\u91cf\uff0c\u96f6\u6837\u672c\u8bc4\u4f30\u4e2d\u6bd4\u5f3a\u57fa\u7ebfDocOwl 1.5\u9ad8\u51fa5.5\u4e2aF1\u5206\u6570\u3002", "conclusion": "\u5185\u5bb9\u611f\u77e5\u6807\u8bb0\u4e0e\u663e\u5f0f\u5e03\u5c40\u5efa\u6a21\u7ed3\u5408\u4e3a\u6587\u6863\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.10347", "pdf": "https://arxiv.org/pdf/2507.10347", "abs": "https://arxiv.org/abs/2507.10347", "authors": ["Yan-Ting Chen", "Hao-Wei Chen", "Tsu-Ching Hsiao", "Chun-Yi Lee"], "title": "Parallel Sampling of Diffusion Models on $SO(3)$", "categories": ["cs.LG"], "comment": "MVA2025", "summary": "In this paper, we design an algorithm to accelerate the diffusion process on\nthe $SO(3)$ manifold. The inherently sequential nature of diffusion models\nnecessitates substantial time for denoising perturbed data. To overcome this\nlimitation, we proposed to adapt the numerical Picard iteration for the $SO(3)$\nspace. We demonstrate our algorithm on an existing method that employs\ndiffusion models to address the pose ambiguity problem. Moreover, we show that\nthis acceleration advantage occurs without any measurable degradation in task\nreward. The experiments reveal that our algorithm achieves a speed-up of up to\n4.9$\\times$, significantly reducing the latency for generating a single sample.", "AI": {"tldr": "\u8bbe\u8ba1\u7b97\u6cd5\u52a0\u901fSO(3)\u6d41\u5f62\u4e0a\u7684\u6269\u6563\u8fc7\u7a0b\uff0c\u5728\u89e3\u51b3\u59ff\u6001\u6a21\u7cca\u95ee\u9898\u4e0a\u901f\u5ea6\u63d0\u53474.9\u500d\u4e14\u65e0\u4efb\u52a1\u5956\u52b1\u635f\u5931\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u56fa\u6709\u7684\u987a\u5e8f\u6027\u5bfc\u81f4\u53bb\u566a\u8017\u65f6\uff0c\u9700\u52a0\u901f\u6269\u6563\u8fc7\u7a0b\u3002", "method": "\u5728SO(3)\u7a7a\u95f4\u91c7\u7528\u6570\u503c\u76ae\u5361\u8fed\u4ee3\u3002", "result": "\u7b97\u6cd5\u5728\u89e3\u51b3\u59ff\u6001\u6a21\u7cca\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad84.9\u500d\u7684\u52a0\u901f\uff0c\u663e\u8457\u964d\u4f4e\u5355\u6837\u672c\u751f\u6210\u5ef6\u8fdf\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u80fd\u6709\u6548\u52a0\u901fSO(3)\u6d41\u5f62\u4e0a\u7684\u6269\u6563\u8fc7\u7a0b\uff0c\u4e14\u4e0d\u964d\u4f4e\u4efb\u52a1\u5956\u52b1\u3002"}}
{"id": "2507.09538", "pdf": "https://arxiv.org/pdf/2507.09538", "abs": "https://arxiv.org/abs/2507.09538", "authors": ["Zainab Ali", "Lujayn Al-Amir", "Ali Safa"], "title": "On the Importance of Neural Membrane Potential Leakage for LIDAR-based Robot Obstacle Avoidance using Spiking Neural Networks", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Using neuromorphic computing for robotics applications has gained much\nattention in recent year due to the remarkable ability of Spiking Neural\nNetworks (SNNs) for high-precision yet low memory and compute complexity\ninference when implemented in neuromorphic hardware. This ability makes SNNs\nwell-suited for autonomous robot applications (such as in drones and rovers)\nwhere battery resources and payload are typically limited. Within this context,\nthis paper studies the use of SNNs for performing direct robot navigation and\nobstacle avoidance from LIDAR data. A custom robot platform equipped with a\nLIDAR is set up for collecting a labeled dataset of LIDAR sensing data together\nwith the human-operated robot control commands used for obstacle avoidance.\nCrucially, this paper provides what is, to the best of our knowledge, a first\nfocused study about the importance of neuron membrane leakage on the SNN\nprecision when processing LIDAR data for obstacle avoidance. It is shown that\nby carefully tuning the membrane potential leakage constant of the spiking\nLeaky Integrate-and-Fire (LIF) neurons used within our SNN, it is possible to\nachieve on-par robot control precision compared to the use of a non-spiking\nConvolutional Neural Network (CNN). Finally, the LIDAR dataset collected during\nthis work is released as open-source with the hope of benefiting future\nresearch.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7528SNN\u57fa\u4e8e\u6fc0\u5149\u96f7\u8fbe\u6570\u636e\u5b9e\u73b0\u673a\u5668\u4eba\u5bfc\u822a\u4e0e\u907f\u969c\uff0c\u63a2\u8ba8\u795e\u7ecf\u5143\u819c\u6cc4\u6f0f\u5bf9\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u8c03\u6574\u53c2\u6570\u53ef\u4f7f\u63a7\u5236\u7cbe\u5ea6\u4e0eCNN\u76f8\u5f53\uff0c\u5e76\u5f00\u6e90\u6570\u636e\u96c6\u3002", "motivation": "SNN\u5728\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u4e2d\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5185\u5b58\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u63a8\u7406\u80fd\u529b\u4f7f\u5176\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u81ea\u4e3b\u673a\u5668\u4eba\u5e94\u7528\uff0c\u56e0\u6b64\u7814\u7a76\u7528SNN\u8fdb\u884c\u673a\u5668\u4eba\u5bfc\u822a\u548c\u907f\u969c\u3002", "method": "\u642d\u5efa\u5e26\u6fc0\u5149\u96f7\u8fbe\u7684\u673a\u5668\u4eba\u5e73\u53f0\u6536\u96c6\u6807\u8bb0\u6570\u636e\u96c6\uff0c\u7814\u7a76\u795e\u7ecf\u5143\u819c\u6cc4\u6f0f\u5bf9SNN\u5904\u7406\u6fc0\u5149\u96f7\u8fbe\u6570\u636e\u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u8c03\u6574LIF\u795e\u7ecf\u5143\u819c\u7535\u4f4d\u6cc4\u6f0f\u5e38\u6570\u3002", "result": "\u901a\u8fc7\u8c03\u6574LIF\u795e\u7ecf\u5143\u819c\u7535\u4f4d\u6cc4\u6f0f\u5e38\u6570\uff0cSNN\u7684\u673a\u5668\u4eba\u63a7\u5236\u7cbe\u5ea6\u53ef\u4e0e\u975e\u8109\u51b2CNN\u76f8\u5f53\u3002", "conclusion": "\u8c03\u6574SNN\u4e2dLIF\u795e\u7ecf\u5143\u7684\u819c\u7535\u4f4d\u6cc4\u6f0f\u5e38\u6570\u53ef\u63d0\u9ad8\u673a\u5668\u4eba\u63a7\u5236\u7cbe\u5ea6\uff0c\u5f00\u6e90\u6570\u636e\u96c6\u6709\u671b\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2507.10348", "pdf": "https://arxiv.org/pdf/2507.10348", "abs": "https://arxiv.org/abs/2507.10348", "authors": ["Yichen Li"], "title": "Feature Distillation is the Better Choice for Model-Heterogeneous Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model-Heterogeneous Federated Learning (Hetero-FL) has attracted growing\nattention for its ability to aggregate knowledge from heterogeneous models\nwhile keeping private data locally. To better aggregate knowledge from clients,\nensemble distillation, as a widely used and effective technique, is often\nemployed after global aggregation to enhance the performance of the global\nmodel. However, simply combining Hetero-FL and ensemble distillation does not\nalways yield promising results and can make the training process unstable. The\nreason is that existing methods primarily focus on logit distillation, which,\nwhile being model-agnostic with softmax predictions, fails to compensate for\nthe knowledge bias arising from heterogeneous models. To tackle this challenge,\nwe propose a stable and efficient Feature Distillation for model-heterogeneous\nFederated learning, dubbed FedFD, that can incorporate aligned feature\ninformation via orthogonal projection to integrate knowledge from heterogeneous\nmodels better. Specifically, a new feature-based ensemble federated knowledge\ndistillation paradigm is proposed. The global model on the server needs to\nmaintain a projection layer for each client-side model architecture to align\nthe features separately. Orthogonal techniques are employed to re-parameterize\nthe projection layer to mitigate knowledge bias from heterogeneous models and\nthus maximize the distilled knowledge. Extensive experiments show that FedFD\nachieves superior performance compared to state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faFedFD\u7528\u4e8e\u5f02\u6784\u8054\u90a6\u5b66\u4e60\uff0c\u7ed3\u5408\u6b63\u4ea4\u6295\u5f71\u8fdb\u884c\u7279\u5f81\u84b8\u998f\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7ed3\u5408\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u548c\u96c6\u6210\u84b8\u998f\u6548\u679c\u4e0d\u4f73\u4e14\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u4e3b\u8981\u805a\u7126logit\u84b8\u998f\u65e0\u6cd5\u8865\u507f\u5f02\u6784\u6a21\u578b\u77e5\u8bc6\u504f\u5dee\u3002", "method": "\u63d0\u51faFedFD\uff0c\u91c7\u7528\u57fa\u4e8e\u7279\u5f81\u7684\u96c6\u6210\u8054\u90a6\u77e5\u8bc6\u84b8\u998f\u8303\u5f0f\uff0c\u670d\u52a1\u5668\u4e0a\u7684\u5168\u5c40\u6a21\u578b\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6a21\u578b\u67b6\u6784\u7ef4\u62a4\u6295\u5f71\u5c42\uff0c\u7528\u6b63\u4ea4\u6280\u672f\u91cd\u65b0\u53c2\u6570\u5316\u6295\u5f71\u5c42\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660eFedFD\u6bd4\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "FedFD\u662f\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u6a21\u578b\u5f02\u6784\u8054\u90a6\u5b66\u4e60\u7279\u5f81\u84b8\u998f\u65b9\u6cd5\u3002"}}
{"id": "2507.09562", "pdf": "https://arxiv.org/pdf/2507.09562", "abs": "https://arxiv.org/abs/2507.09562", "authors": ["Yidong Jiang"], "title": "Prompt Engineering in Segment Anything Model: Methodologies, Applications, and Emerging Challenges", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The Segment Anything Model (SAM) has revolutionized image segmentation\nthrough its innovative prompt-based approach, yet the critical role of prompt\nengineering in its success remains underexplored. This paper presents the first\ncomprehensive survey focusing specifically on prompt engineering techniques for\nSAM and its variants. We systematically organize and analyze the rapidly\ngrowing body of work in this emerging field, covering fundamental\nmethodologies, practical applications, and key challenges. Our review reveals\nhow prompt engineering has evolved from simple geometric inputs to\nsophisticated multimodal approaches, enabling SAM's adaptation across diverse\ndomains including medical imaging and remote sensing. We identify unique\nchallenges in prompt optimization and discuss promising research directions.\nThis survey fills an important gap in the literature by providing a structured\nframework for understanding and advancing prompt engineering in foundation\nmodels for segmentation.", "AI": {"tldr": "\u672c\u6587\u5bf9SAM\u53ca\u5176\u53d8\u4f53\u7684\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u6db5\u76d6\u57fa\u7840\u65b9\u6cd5\u3001\u5e94\u7528\u548c\u6311\u6218\uff0c\u63ed\u793a\u5176\u6f14\u53d8\u5e76\u6307\u51fa\u7814\u7a76\u65b9\u5411\u3002", "motivation": "SAM\u867d\u9769\u65b0\u56fe\u50cf\u5206\u5272\uff0c\u4f46\u63d0\u793a\u5de5\u7a0b\u5728\u5176\u6210\u529f\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u5bf9\u76f8\u5173\u6280\u672f\u8fdb\u884c\u5168\u9762\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u5730\u7ec4\u7ec7\u548c\u5206\u6790\u8be5\u65b0\u5174\u9886\u57df\u5feb\u901f\u589e\u957f\u7684\u7814\u7a76\u6210\u679c\u3002", "result": "\u63ed\u793a\u63d0\u793a\u5de5\u7a0b\u4ece\u7b80\u5355\u51e0\u4f55\u8f93\u5165\u53d1\u5c55\u5230\u590d\u6742\u591a\u6a21\u6001\u65b9\u6cd5\uff0c\u4f7fSAM\u80fd\u5e94\u7528\u4e8e\u591a\u9886\u57df\uff0c\u8fd8\u8bc6\u522b\u51fa\u63d0\u793a\u4f18\u5316\u7684\u72ec\u7279\u6311\u6218\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3a\u7406\u89e3\u548c\u63a8\u8fdb\u5206\u5272\u57fa\u7840\u6a21\u578b\u7684\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u586b\u8865\u4e86\u6587\u732e\u7a7a\u767d\u3002"}}
{"id": "2507.10349", "pdf": "https://arxiv.org/pdf/2507.10349", "abs": "https://arxiv.org/abs/2507.10349", "authors": ["Zhiyuan Zhao", "Sitan Yang", "Kin G. Olivares", "Boris N. Oreshkin", "Stan Vitebsky", "Michael W. Mahoney", "B. Aditya Prakash", "Dmitry Efimov"], "title": "TAT: Temporal-Aligned Transformer for Multi-Horizon Peak Demand Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 4 figures, 7 tables, published at KDD 2025 workshop on AI\n  for Supply Chain: Today and Future", "summary": "Multi-horizon time series forecasting has many practical applications such as\ndemand forecasting. Accurate demand prediction is critical to help make buying\nand inventory decisions for supply chain management of e-commerce and physical\nretailers, and such predictions are typically required for future horizons\nextending tens of weeks. This is especially challenging during high-stake sales\nevents when demand peaks are particularly difficult to predict accurately.\nHowever, these events are important not only for managing supply chain\noperations but also for ensuring a seamless shopping experience for customers.\nTo address this challenge, we propose Temporal-Aligned Transformer (TAT), a\nmulti-horizon forecaster leveraging apriori-known context variables such as\nholiday and promotion events information for improving predictive performance.\nOur model consists of an encoder and decoder, both embedded with a novel\nTemporal Alignment Attention (TAA), designed to learn context-dependent\nalignment for peak demand forecasting. We conduct extensive empirical analysis\non two large-scale proprietary datasets from a large e-commerce retailer. We\ndemonstrate that TAT brings up to 30% accuracy improvement on peak demand\nforecasting while maintaining competitive overall performance compared to other\nstate-of-the-art methods.", "AI": {"tldr": "\u63d0\u51faTemporal - Aligned Transformer (TAT)\u7528\u4e8e\u591a\u6c34\u5e73\u65f6\u95f4\u5e8f\u5217\u9700\u6c42\u9884\u6d4b\uff0c\u5728\u7535\u5546\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u53ef\u63d0\u5347\u5cf0\u503c\u9700\u6c42\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u591a\u6c34\u5e73\u65f6\u95f4\u5e8f\u5217\u9700\u6c42\u9884\u6d4b\u5728\u7535\u5546\u548c\u5b9e\u4f53\u96f6\u552e\u4f9b\u5e94\u94fe\u7ba1\u7406\u4e2d\u5f88\u91cd\u8981\uff0c\u9ad8\u98ce\u9669\u9500\u552e\u6d3b\u52a8\u65f6\u51c6\u786e\u9884\u6d4b\u9700\u6c42\u5cf0\u503c\u6781\u5177\u6311\u6218\uff0c\u9700\u8981\u66f4\u597d\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTAT\uff0c\u7531\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7ec4\u6210\uff0c\u4e8c\u8005\u90fd\u5d4c\u5165Temporal Alignment Attention (TAA)\uff0c\u5229\u7528\u5148\u9a8c\u4e0a\u4e0b\u6587\u53d8\u91cf\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5728\u7535\u5546\u96f6\u552e\u5546\u7684\u4e24\u4e2a\u5927\u89c4\u6a21\u4e13\u6709\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0cTAT\u5728\u5cf0\u503c\u9700\u6c42\u9884\u6d4b\u4e0a\u6700\u591a\u63d0\u534730%\u7684\u51c6\u786e\u6027\uff0c\u6574\u4f53\u6027\u80fd\u4e5f\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "TAT\u662f\u4e00\u79cd\u6709\u6548\u7684\u591a\u6c34\u5e73\u65f6\u95f4\u5e8f\u5217\u9700\u6c42\u9884\u6d4b\u6a21\u578b\uff0c\u80fd\u6709\u6548\u63d0\u5347\u5cf0\u503c\u9700\u6c42\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2507.10368", "pdf": "https://arxiv.org/pdf/2507.10368", "abs": "https://arxiv.org/abs/2507.10368", "authors": ["Yongjin Choi", "Chenying Liu", "Jorge Macedo"], "title": "Enhanced DeepONet for 1-D consolidation operator learning: an architectural investigation", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Deep Operator Networks (DeepONets) have emerged as a powerful surrogate\nmodeling framework for learning solution operators in PDE-governed systems.\nWhile their use is expanding across engineering disciplines, applications in\ngeotechnical engineering remain limited. This study systematically evaluates\nseveral DeepONet architectures for the one-dimensional consolidation problem.\nWe initially consider three architectures: a standard DeepONet with the\ncoefficient of consolidation embedded in the branch net (Models 1 and 2), and a\nphysics-inspired architecture with the coefficient embedded in the trunk net\n(Model 3). Results show that Model 3 outperforms the standard configurations\n(Models 1 and 2) but still has limitations when the target solution (excess\npore pressures) exhibits significant variation. To overcome this limitation, we\npropose a Trunknet Fourier feature-enhanced DeepONet (Model 4) that addresses\nthe identified limitations by capturing rapidly varying functions. All proposed\narchitectures achieve speedups ranging from 1.5 to 100 times over traditional\nexplicit and implicit solvers, with Model 4 being the most efficient. Larger\ncomputational savings are expected for more complex systems than the explored\n1D case, which is promising. Overall, the study highlights the potential of\nDeepONets to enable efficient, generalizable surrogate modeling in geotechnical\napplications, advancing the integration of scientific machine learning in\ngeotechnics, which is at an early stage.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u51e0\u79cdDeepONet\u67b6\u6784\u7528\u4e8e\u4e00\u7ef4\u56fa\u7ed3\u95ee\u9898\uff0c\u63d0\u51fa\u6539\u8fdb\u67b6\u6784\uff0c\u5b9e\u73b0\u8ba1\u7b97\u52a0\u901f\uff0c\u51f8\u663e\u5176\u5728\u5ca9\u571f\u5de5\u7a0b\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "DeepONet\u5728\u5ca9\u571f\u5de5\u7a0b\u5e94\u7528\u6709\u9650\uff0c\u9700\u8bc4\u4f30\u5176\u5728\u4e00\u7ef4\u56fa\u7ed3\u95ee\u9898\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u8003\u8651\u4e09\u79cd\u521d\u59cb\u67b6\u6784\uff0c\u9488\u5bf9\u95ee\u9898\u63d0\u51faTrunknet Fourier\u7279\u5f81\u589e\u5f3a\u7684DeepONet\u67b6\u6784\u3002", "result": "Model 3\u4f18\u4e8e\u6807\u51c6\u914d\u7f6e\uff0c\u4f46\u6709\u5c40\u9650\u6027\uff1bModel 4\u89e3\u51b3\u4e86\u5c40\u9650\u6027\uff0c\u6240\u6709\u67b6\u6784\u6bd4\u4f20\u7edf\u6c42\u89e3\u5668\u5feb1.5 - 100\u500d\uff0cModel 4\u6700\u6709\u6548\u3002", "conclusion": "DeepONets\u6709\u6f5c\u529b\u5728\u5ca9\u571f\u5e94\u7528\u4e2d\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6cdb\u5316\u7684\u4ee3\u7406\u5efa\u6a21\uff0c\u63a8\u52a8\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u5728\u5ca9\u571f\u9886\u57df\u7684\u96c6\u6210\u3002"}}
{"id": "2507.09574", "pdf": "https://arxiv.org/pdf/2507.09574", "abs": "https://arxiv.org/abs/2507.09574", "authors": ["Haozhe Zhao", "Zefan Cai", "Shuzheng Si", "Liang Chen", "Jiuxiang Gu", "Wen Xiao", "Junjie Hu"], "title": "MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "24 pages,12 figures", "summary": "Recent text-to-image models produce high-quality results but still struggle\nwith precise visual control, balancing multimodal inputs, and requiring\nextensive training for complex multimodal image generation. To address these\nlimitations, we propose MENTOR, a novel autoregressive (AR) framework for\nefficient Multimodal-conditioned Tuning for Autoregressive multimodal image\ngeneration. MENTOR combines an AR image generator with a two-stage training\nparadigm, enabling fine-grained, token-level alignment between multimodal\ninputs and image outputs without relying on auxiliary adapters or\ncross-attention modules. The two-stage training consists of: (1) a multimodal\nalignment stage that establishes robust pixel- and semantic-level alignment,\nfollowed by (2) a multimodal instruction tuning stage that balances the\nintegration of multimodal inputs and enhances generation controllability.\nDespite modest model size, suboptimal base components, and limited training\nresources, MENTOR achieves strong performance on the DreamBench++ benchmark,\noutperforming competitive baselines in concept preservation and prompt\nfollowing. Additionally, our method delivers superior image reconstruction\nfidelity, broad task adaptability, and improved training efficiency compared to\ndiffusion-based methods. Dataset, code, and models are available at:\nhttps://github.com/HaozheZhao/MENTOR", "AI": {"tldr": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u6709\u5c40\u9650\uff0c\u63d0\u51faMENTOR\u6846\u67b6\u7528\u4e8e\u9ad8\u6548\u591a\u6a21\u6001\u56fe\u50cf\u751f\u6210\uff0c\u867d\u8d44\u6e90\u6709\u9650\u4ecd\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5728\u7cbe\u786e\u89c6\u89c9\u63a7\u5236\u3001\u5e73\u8861\u591a\u6a21\u6001\u8f93\u5165\u53ca\u590d\u6742\u591a\u6a21\u6001\u56fe\u50cf\u751f\u6210\u8bad\u7ec3\u65b9\u9762\u7684\u5c40\u9650\u3002", "method": "\u63d0\u51faMENTOR\u6846\u67b6\uff0c\u7ed3\u5408AR\u56fe\u50cf\u751f\u6210\u5668\u4e0e\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff0c\u4e24\u9636\u6bb5\u5206\u522b\u4e3a\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u591a\u6a21\u6001\u6307\u4ee4\u8c03\u4f18\u3002", "result": "\u5728DreamBench++\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u6982\u5ff5\u4fdd\u7559\u548c\u9075\u5faa\u63d0\u793a\u65b9\u9762\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\uff0c\u56fe\u50cf\u91cd\u5efa\u4fdd\u771f\u5ea6\u3001\u4efb\u52a1\u9002\u5e94\u6027\u548c\u8bad\u7ec3\u6548\u7387\u4f18\u4e8e\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u3002", "conclusion": "MENTOR\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u5c40\u9650\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u4f18\u52bf\u3002"}}
{"id": "2507.10382", "pdf": "https://arxiv.org/pdf/2507.10382", "abs": "https://arxiv.org/abs/2507.10382", "authors": ["Yue Ding", "Conor McCarthy", "Kevin O'Shea", "Mingming Liu"], "title": "Leveraging RAG-LLMs for Urban Mobility Simulation and Analysis", "categories": ["cs.LG"], "comment": null, "summary": "With the rise of smart mobility and shared e-mobility services, numerous\nadvanced technologies have been applied to this field. Cloud-based traffic\nsimulation solutions have flourished, offering increasingly realistic\nrepresentations of the evolving mobility landscape. LLMs have emerged as\npioneering tools, providing robust support for various applications, including\nintelligent decision-making, user interaction, and real-time traffic analysis.\nAs user demand for e-mobility continues to grow, delivering comprehensive\nend-to-end solutions has become crucial. In this paper, we present a\ncloud-based, LLM-powered shared e-mobility platform, integrated with a mobile\napplication for personalized route recommendations. The optimization module is\nevaluated based on travel time and cost across different traffic scenarios.\nAdditionally, the LLM-powered RAG framework is evaluated at the schema level\nfor different users, using various evaluation methods. Schema-level RAG with\nXiYanSQL achieves an average execution accuracy of 0.81 on system operator\nqueries and 0.98 on user queries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4e91\u3001\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u5171\u4eab\u7535\u52a8\u51fa\u884c\u5e73\u53f0\uff0c\u96c6\u6210\u79fb\u52a8\u5e94\u7528\u505a\u4e2a\u6027\u5316\u8def\u7ebf\u63a8\u8350\uff0c\u8bc4\u4f30\u4f18\u5316\u6a21\u5757\u548c\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684RAG\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u51fa\u884c\u548c\u5171\u4eab\u7535\u52a8\u51fa\u884c\u670d\u52a1\u5174\u8d77\uff0c\u7528\u6237\u9700\u6c42\u589e\u957f\uff0c\u9700\u63d0\u4f9b\u5168\u9762\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u4e91\u3001\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u5171\u4eab\u7535\u52a8\u51fa\u884c\u5e73\u53f0\uff0c\u96c6\u6210\u79fb\u52a8\u5e94\u7528\uff0c\u57fa\u4e8e\u4e0d\u540c\u4ea4\u901a\u573a\u666f\u7684\u51fa\u884c\u65f6\u95f4\u548c\u6210\u672c\u8bc4\u4f30\u4f18\u5316\u6a21\u5757\uff0c\u7528\u591a\u79cd\u8bc4\u4f30\u65b9\u6cd5\u5728\u6a21\u5f0f\u7ea7\u522b\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684RAG\u6846\u67b6\u3002", "result": "\u4f7f\u7528XiYanSQL\u7684\u6a21\u5f0f\u7ea7RAG\u5728\u7cfb\u7edf\u64cd\u4f5c\u5458\u67e5\u8be2\u4e0a\u5e73\u5747\u6267\u884c\u51c6\u786e\u7387\u4e3a0.81\uff0c\u5728\u7528\u6237\u67e5\u8be2\u4e0a\u4e3a0.98\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e73\u53f0\u548c\u8bc4\u4f30\u65b9\u6cd5\u5177\u6709\u4e00\u5b9a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.10385", "pdf": "https://arxiv.org/pdf/2507.10385", "abs": "https://arxiv.org/abs/2507.10385", "authors": ["Md. Ahsanul Kabir", "Mohammad Al Hasan", "Aritra Mandal", "Liyang Hao", "Ishita Khan", "Daniel Tunkelang", "Zhe Wu"], "title": "Extracting Important Tokens in E-Commerce Queries with a Tag Interaction-Aware Transformer Model", "categories": ["cs.LG"], "comment": null, "summary": "The major task of any e-commerce search engine is to retrieve the most\nrelevant inventory items, which best match the user intent reflected in a\nquery. This task is non-trivial due to many reasons, including ambiguous\nqueries, misaligned vocabulary between buyers, and sellers, over- or\nunder-constrained queries by the presence of too many or too few tokens. To\naddress these challenges, query reformulation is used, which modifies a user\nquery through token dropping, replacement or expansion, with the objective to\nbridge semantic gap between query tokens and users' search intent. Early\nmethods of query reformulation mostly used statistical measures derived from\ntoken co-occurrence frequencies from selective user sessions having clicks or\npurchases. In recent years, supervised deep learning approaches, specifically\ntransformer-based neural language models, or sequence-to-sequence models are\nbeing used for query reformulation task. However, these models do not utilize\nthe semantic tags of a query token, which are significant for capturing user\nintent of an e-commerce query. In this work, we pose query reformulation as a\ntoken classification task, and solve this task by designing a dependency-aware\ntransformer-based language model, TagBERT, which makes use of semantic tags of\na token for learning superior query phrase embedding. Experiments on large,\nreal-life e-commerce datasets show that TagBERT exhibits superior performance\nthan plethora of competing models, including BERT, eBERT, and\nSequence-to-Sequence transformer model for important token classification task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4f9d\u8d56\u611f\u77e5\u7684\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578bTagBERT\u89e3\u51b3\u7535\u5546\u641c\u7d22\u67e5\u8be2\u91cd\u5199\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u591a\u79cd\u6a21\u578b\u3002", "motivation": "\u7535\u5546\u641c\u7d22\u5f15\u64ce\u68c0\u7d22\u76f8\u5173\u5546\u54c1\u9762\u4e34\u67e5\u8be2\u6a21\u7cca\u3001\u8bcd\u6c47\u4e0d\u5339\u914d\u7b49\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u5229\u7528\u67e5\u8be2\u8bcd\u7684\u8bed\u4e49\u6807\u7b7e\u3002", "method": "\u5c06\u67e5\u8be2\u91cd\u5199\u89c6\u4e3a\u4ee4\u724c\u5206\u7c7b\u4efb\u52a1\uff0c\u8bbe\u8ba1\u4f9d\u8d56\u611f\u77e5\u7684\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578bTagBERT\uff0c\u5229\u7528\u4ee4\u724c\u8bed\u4e49\u6807\u7b7e\u5b66\u4e60\u67e5\u8be2\u77ed\u8bed\u5d4c\u5165\u3002", "result": "\u5728\u5927\u578b\u771f\u5b9e\u7535\u5546\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cTagBERT\u5728\u91cd\u8981\u4ee4\u724c\u5206\u7c7b\u4efb\u52a1\u4e0a\u6027\u80fd\u4f18\u4e8eBERT\u3001eBERT\u7b49\u591a\u79cd\u7ade\u4e89\u6a21\u578b\u3002", "conclusion": "TagBERT\u5728\u7535\u5546\u67e5\u8be2\u91cd\u5199\u7684\u4ee4\u724c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6709\u6548\u5229\u7528\u8bed\u4e49\u6807\u7b7e\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2507.10400", "pdf": "https://arxiv.org/pdf/2507.10400", "abs": "https://arxiv.org/abs/2507.10400", "authors": ["Nicholas Casetti", "Dylan Anstine", "Olexandr Isayev", "Connor W. Coley"], "title": "Anticipating the Selectivity of Cyclization Reaction Pathways with Neural Network Potentials", "categories": ["cs.LG", "q-bio.QM"], "comment": "32 pages, 5 figures", "summary": "Reaction mechanism search tools have demonstrated the ability to provide\ninsights into likely products and rate-limiting steps of reacting systems.\nHowever, reactions involving several concerted bond changes - as can be found\nin many key steps of natural product synthesis - can complicate the search\nprocess. To mitigate these complications, we present a mechanism search\nstrategy particularly suited to help expedite exploration of an exemplary\nfamily of such complex reactions, cyclizations. We provide a cost-effective\nstrategy for identifying relevant elementary reaction steps by combining\ngraph-based enumeration schemes and machine learning techniques for\nintermediate filtering. Key to this approach is our use of a neural network\npotential (NNP), AIMNet2-rxn, for computational evaluation of each candidate\nreaction pathway. In this article, we evaluate the NNP's ability to estimate\nactivation energies, demonstrate the correct anticipation of stereoselectivity,\nand recapitulate complex enabling steps in natural product synthesis.", "AI": {"tldr": "\u63d0\u51fa\u9002\u5408\u73af\u5316\u53cd\u5e94\u7684\u673a\u7406\u641c\u7d22\u7b56\u7565\uff0c\u7ed3\u5408\u56fe\u679a\u4e3e\u548c\u673a\u5668\u5b66\u4e60\uff0c\u7528NNP\u8bc4\u4f30\u53cd\u5e94\u8def\u5f84\uff0c\u9a8c\u8bc1\u5176\u80fd\u529b\u3002", "motivation": "\u542b\u591a\u4e2a\u534f\u540c\u952e\u53d8\u5316\u7684\u53cd\u5e94\u4f7f\u641c\u7d22\u8fc7\u7a0b\u590d\u6742\uff0c\u9700\u7b56\u7565\u52a0\u901f\u590d\u6742\u53cd\u5e94\u63a2\u7d22\u3002", "method": "\u7ed3\u5408\u56fe\u679a\u4e3e\u65b9\u6848\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\u8fc7\u6ee4\u4e2d\u95f4\u4f53\uff0c\u7528\u795e\u7ecf\u7f51\u7edc\u52bfAIMNet2 - rxn\u8bc4\u4f30\u5019\u9009\u53cd\u5e94\u8def\u5f84\u3002", "result": "\u8bc4\u4f30\u4e86NNP\u4f30\u8ba1\u6d3b\u5316\u80fd\u7684\u80fd\u529b\uff0c\u6b63\u786e\u9884\u6d4b\u7acb\u4f53\u9009\u62e9\u6027\uff0c\u91cd\u73b0\u5929\u7136\u4ea7\u7269\u5408\u6210\u4e2d\u7684\u590d\u6742\u6b65\u9aa4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u673a\u5236\u641c\u7d22\u7b56\u7565\u53ef\u6709\u6548\u7528\u4e8e\u73af\u5316\u7b49\u590d\u6742\u53cd\u5e94\u7684\u63a2\u7d22\u3002"}}
{"id": "2507.09601", "pdf": "https://arxiv.org/pdf/2507.09601", "abs": "https://arxiv.org/abs/2507.09601", "authors": ["Hanwool Lee", "Sara Yu", "Yewon Hwang", "Jonghyun Choi", "Heejae Ahn", "Sungbum Jung", "Youngjae Yu"], "title": "NMIXX: Domain-Adapted Neural Embeddings for Cross-Lingual eXploration of Finance", "categories": ["cs.CL", "cs.AI", "q-fin.CP"], "comment": "Under Review", "summary": "General-purpose sentence embedding models often struggle to capture\nspecialized financial semantics, especially in low-resource languages like\nKorean, due to domain-specific jargon, temporal meaning shifts, and misaligned\nbilingual vocabularies. To address these gaps, we introduce NMIXX (Neural\neMbeddings for Cross-lingual eXploration of Finance), a suite of cross-lingual\nembedding models fine-tuned with 18.8K high-confidence triplets that pair\nin-domain paraphrases, hard negatives derived from a semantic-shift typology,\nand exact Korean-English translations. Concurrently, we release KorFinSTS, a\n1,921-pair Korean financial STS benchmark spanning news, disclosures, research\nreports, and regulations, designed to expose nuances that general benchmarks\nmiss.\n  When evaluated against seven open-license baselines, NMIXX's multilingual\nbge-m3 variant achieves Spearman's rho gains of +0.10 on English FinSTS and\n+0.22 on KorFinSTS, outperforming its pre-adaptation checkpoint and surpassing\nother models by the largest margin, while revealing a modest trade-off in\ngeneral STS performance. Our analysis further shows that models with richer\nKorean token coverage adapt more effectively, underscoring the importance of\ntokenizer design in low-resource, cross-lingual settings. By making both models\nand the benchmark publicly available, we provide the community with robust\ntools for domain-adapted, multilingual representation learning in finance.", "AI": {"tldr": "\u9488\u5bf9\u901a\u7528\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u96be\u6355\u6349\u91d1\u878d\u8bed\u4e49\u95ee\u9898\uff0c\u63d0\u51faNMIXX\u6a21\u578b\u5e76\u53d1\u5e03KorFinSTS\u57fa\u51c6\uff0c\u8bc4\u4f30\u663e\u793aNMIXX\u8868\u73b0\u4f73\uff0c\u5f3a\u8c03\u5206\u8bcd\u5668\u8bbe\u8ba1\u91cd\u8981\u6027\u5e76\u516c\u5f00\u6210\u679c\u3002", "motivation": "\u901a\u7528\u53e5\u5b50\u5d4c\u5165\u6a21\u578b\u96be\u4ee5\u6355\u6349\u4e13\u4e1a\u91d1\u878d\u8bed\u4e49\uff0c\u7279\u522b\u662f\u97e9\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u5b58\u5728\u9886\u57df\u7279\u5b9a\u884c\u8bdd\u3001\u8bed\u4e49\u968f\u65f6\u95f4\u53d8\u5316\u548c\u53cc\u8bed\u8bcd\u6c47\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165NMIXX\u8de8\u8bed\u8a00\u5d4c\u5165\u6a21\u578b\uff0c\u752818.8K\u9ad8\u7f6e\u4fe1\u4e09\u5143\u7ec4\u5fae\u8c03\uff1b\u53d1\u5e031921\u5bf9\u7684KorFinSTS\u97e9\u8bed\u91d1\u878dSTS\u57fa\u51c6\u3002", "result": "NMIXX\u7684multilingual bge - m3\u53d8\u4f53\u5728\u82f1\u8bedFinSTS\u548cKorFinSTS\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u5728\u901a\u7528STS\u6027\u80fd\u4e0a\u6709\u9002\u5ea6\u6743\u8861\uff1b\u97e9\u8bed\u5206\u8bcd\u8986\u76d6\u66f4\u4e30\u5bcc\u7684\u6a21\u578b\u9002\u5e94\u66f4\u6709\u6548\u3002", "conclusion": "\u516c\u5f00\u6a21\u578b\u548c\u57fa\u51c6\u4e3a\u91d1\u878d\u9886\u57df\u591a\u8bed\u8a00\u8868\u5f81\u5b66\u4e60\u63d0\u4f9b\u4e86\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2507.10401", "pdf": "https://arxiv.org/pdf/2507.10401", "abs": "https://arxiv.org/abs/2507.10401", "authors": ["Ryan Bausback", "Jingqiao Tang", "Lu Lu", "Feng Bao", "Toan Huynh"], "title": "Stochastic Operator Network: A Stochastic Maximum Principle Based Approach to Operator Learning", "categories": ["cs.LG", "math.PR"], "comment": null, "summary": "We develop a novel framework for uncertainty quantification in operator\nlearning, the Stochastic Operator Network (SON). SON combines the stochastic\noptimal control concepts of the Stochastic Neural Network (SNN) with the\nDeepONet. By formulating the branch net as an SDE and backpropagating through\nthe adjoint BSDE, we replace the gradient of the loss function with the\ngradient of the Hamiltonian from Stohastic Maximum Principle in the SGD update.\nThis allows SON to learn the uncertainty present in operators through its\ndiffusion parameters. We then demonstrate the effectiveness of SON when\nreplicating several noisy operators in 2D and 3D.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u968f\u673a\u7b97\u5b50\u7f51\u7edc\uff08SON\uff09\u6846\u67b6\u7528\u4e8e\u7b97\u5b50\u5b66\u4e60\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u7ed3\u5408SNN\u4e0eDeepONet\uff0c\u901a\u8fc7\u7279\u5b9a\u65b9\u5f0f\u4f7fSON\u5b66\u4e60\u7b97\u5b50\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u57282D\u548c3D\u566a\u58f0\u7b97\u5b50\u590d\u5236\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u7b97\u5b50\u5b66\u4e60\u4e2d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u6846\u67b6\u3002", "method": "\u5c06SON\u7ed3\u5408\u968f\u673a\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u7684\u968f\u673a\u6700\u4f18\u63a7\u5236\u6982\u5ff5\u4e0eDeepONet\uff0c\u5c06\u5206\u652f\u7f51\u7edc\u8868\u793a\u4e3aSDE\u5e76\u901a\u8fc7\u4f34\u968fBSDE\u53cd\u5411\u4f20\u64ad\uff0c\u5728SGD\u66f4\u65b0\u4e2d\u7528\u968f\u673a\u6700\u5927\u503c\u539f\u7406\u7684\u54c8\u5bc6\u987f\u91cf\u68af\u5ea6\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u68af\u5ea6\u3002", "result": "SON\u80fd\u901a\u8fc7\u6269\u6563\u53c2\u6570\u5b66\u4e60\u7b97\u5b50\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "SON\u5728\u590d\u52362D\u548c3D\u566a\u58f0\u7b97\u5b50\u65f6\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2507.10409", "pdf": "https://arxiv.org/pdf/2507.10409", "abs": "https://arxiv.org/abs/2507.10409", "authors": ["Amine Lbath", "Ibtissam Labriji"], "title": "Energy Efficiency in AI for 5G and Beyond: A DeepRx Case Study", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study addresses the challenge of balancing energy efficiency with\nperformance in AI/ML models, focusing on DeepRX, a deep learning receiver based\non a fully convolutional ResNet architecture. We evaluate the energy\nconsumption of DeepRX, considering factors including FLOPs/Watt and\nFLOPs/clock, and find consistency between estimated and actual energy usage,\ninfluenced by memory access patterns. The research extends to comparing energy\ndynamics during training and inference phases. A key contribution is the\napplication of knowledge distillation (KD) to train a compact DeepRX\n\\textit{student} model that emulates the performance of the \\textit{teacher}\nmodel but with reduced energy consumption. We experiment with different student\nmodel sizes, optimal teacher sizes, and KD hyperparameters. Performance is\nmeasured by comparing the Bit Error Rate (BER) performance versus\nSignal-to-Interference \\& Noise Ratio (SINR) values of the distilled model and\na model trained from scratch. The distilled models demonstrate a lower error\nfloor across SINR levels, highlighting the effectiveness of KD in achieving\nenergy-efficient AI solutions.", "AI": {"tldr": "\u7814\u7a76\u805a\u7126DeepRX\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u80fd\u8017\uff0c\u5bf9\u6bd4\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u80fd\u8017\u52a8\u6001\uff0c\u5e94\u7528\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u7d27\u51d1\u6a21\u578b\uff0c\u8bc1\u660e\u77e5\u8bc6\u84b8\u998f\u5728\u5b9e\u73b0\u8282\u80fdAI\u65b9\u6848\u4e0a\u6709\u6548\u3002", "motivation": "\u89e3\u51b3AI/ML\u6a21\u578b\u4e2d\u80fd\u6e90\u6548\u7387\u4e0e\u6027\u80fd\u5e73\u8861\u7684\u6311\u6218\u3002", "method": "\u8bc4\u4f30DeepRX\u80fd\u8017\uff0c\u8003\u8651FLOPs/Watt\u548cFLOPs/clock\u7b49\u56e0\u7d20\uff1b\u5bf9\u6bd4\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u80fd\u8017\uff1b\u5e94\u7528\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u7d27\u51d1\u6a21\u578b\uff1b\u7528\u4e0d\u540c\u5b66\u751f\u6a21\u578b\u5927\u5c0f\u3001\u6700\u4f18\u6559\u5e08\u5927\u5c0f\u548cKD\u8d85\u53c2\u6570\u8fdb\u884c\u5b9e\u9a8c\uff1b\u901a\u8fc7\u5bf9\u6bd4\u8bef\u7801\u7387\u548c\u4fe1\u5e72\u566a\u6bd4\u8861\u91cf\u6027\u80fd\u3002", "result": "\u4f30\u8ba1\u80fd\u8017\u4e0e\u5b9e\u9645\u80fd\u8017\u4e00\u81f4\uff0c\u53d7\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u5f71\u54cd\uff1b\u84b8\u998f\u6a21\u578b\u5728\u5404\u4fe1\u5e72\u566a\u6bd4\u6c34\u5e73\u4e0b\u8bef\u5dee\u4e0b\u9650\u66f4\u4f4e\u3002", "conclusion": "\u77e5\u8bc6\u84b8\u998f\u80fd\u6709\u6548\u5b9e\u73b0\u8282\u80fdAI\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09630", "pdf": "https://arxiv.org/pdf/2507.09630", "abs": "https://arxiv.org/abs/2507.09630", "authors": ["Shomukh Qari", "Maha A. Thafar"], "title": "Brain Stroke Detection and Classification Using CT Imaging with Transformer Models and Explainable AI", "categories": ["cs.CV", "cs.AI"], "comment": "5 figures", "summary": "Stroke is one of the leading causes of death globally, making early and\naccurate diagnosis essential for improving patient outcomes, particularly in\nemergency settings where timely intervention is critical. CT scans are the key\nimaging modality because of their speed, accessibility, and cost-effectiveness.\nThis study proposed an artificial intelligence framework for multiclass stroke\nclassification (ischemic, hemorrhagic, and no stroke) using CT scan images from\na dataset provided by the Republic of Turkey's Ministry of Health. The proposed\nmethod adopted MaxViT, a state-of-the-art Vision Transformer, as the primary\ndeep learning model for image-based stroke classification, with additional\ntransformer variants (vision transformer, transformer-in-transformer, and\nConvNext). To enhance model generalization and address class imbalance, we\napplied data augmentation techniques, including synthetic image generation. The\nMaxViT model trained with augmentation achieved the best performance, reaching\nan accuracy and F1-score of 98.00%, outperforming all other evaluated models\nand the baseline methods. The primary goal of this study was to distinguish\nbetween stroke types with high accuracy while addressing crucial issues of\ntransparency and trust in artificial intelligence models. To achieve this,\nExplainable Artificial Intelligence (XAI) was integrated into the framework,\nparticularly Grad-CAM++. It provides visual explanations of the model's\ndecisions by highlighting relevant stroke regions in the CT scans and\nestablishing an accurate, interpretable, and clinically applicable solution for\nearly stroke detection. This research contributed to the development of a\ntrustworthy AI-assisted diagnostic tool for stroke, facilitating its\nintegration into clinical practice and enhancing access to timely and optimal\nstroke diagnosis in emergency departments, thereby saving more lives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eCT\u56fe\u50cf\u7684\u591a\u7c7b\u4e2d\u98ce\u5206\u7c7bAI\u6846\u67b6\uff0c\u7528MaxViT\u6a21\u578b\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u53d6\u5f9798%\u51c6\u786e\u7387\uff0c\u8fd8\u96c6\u6210XAI\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff0c\u52a9\u529b\u4e34\u5e8a\u8bca\u65ad\u3002", "motivation": "\u4e2d\u98ce\u662f\u5168\u7403\u4e3b\u8981\u6b7b\u56e0\u4e4b\u4e00\uff0c\u65e9\u671f\u51c6\u786e\u8bca\u65ad\u81f3\u5173\u91cd\u8981\uff0cCT\u626b\u63cf\u662f\u5173\u952e\u6210\u50cf\u65b9\u5f0f\uff0c\u9700\u5f00\u53d1AI\u8f85\u52a9\u8bca\u65ad\u5de5\u5177\u3002", "method": "\u91c7\u7528MaxViT\u7b49\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u96c6\u6210Explainable Artificial Intelligence (XAI) \u7279\u522b\u662fGrad - CAM++\u3002", "result": "MaxViT\u6a21\u578b\u7ecf\u6570\u636e\u589e\u5f3a\u8bad\u7ec3\u540e\u51c6\u786e\u7387\u548cF1\u5206\u6570\u8fbe98.00%\uff0c\u4f18\u4e8e\u5176\u4ed6\u8bc4\u4f30\u6a21\u578b\u548c\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u6709\u52a9\u4e8e\u5f00\u53d1\u53ef\u9760\u7684AI\u8f85\u52a9\u4e2d\u98ce\u8bca\u65ad\u5de5\u5177\uff0c\u63a8\u52a8\u5176\u5728\u4e34\u5e8a\u5b9e\u8df5\u5e94\u7528\uff0c\u6539\u5584\u6025\u8bca\u4e2d\u98ce\u8bca\u65ad\u3002"}}
{"id": "2507.09647", "pdf": "https://arxiv.org/pdf/2507.09647", "abs": "https://arxiv.org/abs/2507.09647", "authors": ["Peican Zhu", "Yubo Jing", "Le Cheng", "Keke Tang", "Yangming Guo"], "title": "KEN: Knowledge Augmentation and Emotion Guidance Network for Multimodal Fake News Detection", "categories": ["cs.MM", "cs.AI"], "comment": "Accepted by ACM MM 2025", "summary": "In recent years, the rampant spread of misinformation on social media has\nmade accurate detection of multimodal fake news a critical research focus.\nHowever, previous research has not adequately understood the semantics of\nimages, and models struggle to discern news authenticity with limited textual\ninformation. Meanwhile, treating all emotional types of news uniformly without\ntailored approaches further leads to performance degradation. Therefore, we\npropose a novel Knowledge Augmentation and Emotion Guidance Network (KEN). On\nthe one hand, we effectively leverage LVLM's powerful semantic understanding\nand extensive world knowledge. For images, the generated captions provide a\ncomprehensive understanding of image content and scenes, while for text, the\nretrieved evidence helps break the information silos caused by the closed and\nlimited text and context. On the other hand, we consider inter-class\ndifferences between different emotional types of news through balanced\nlearning, achieving fine-grained modeling of the relationship between emotional\ntypes and authenticity. Extensive experiments on two real-world datasets\ndemonstrate the superiority of our KEN.", "AI": {"tldr": "\u9488\u5bf9\u793e\u4ea4\u5a92\u4f53\u591a\u6a21\u6001\u5047\u65b0\u95fb\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u77e5\u8bc6\u589e\u5f3a\u4e0e\u60c5\u611f\u5f15\u5bfc\u7f51\u7edcKEN\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5bf9\u56fe\u50cf\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3\u3001\u6587\u672c\u4fe1\u606f\u6709\u9650\u65f6\u96be\u8fa8\u65b0\u95fb\u771f\u4f2a\uff0c\u4e14\u672a\u533a\u5206\u65b0\u95fb\u60c5\u611f\u7c7b\u578b\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faKEN\u7f51\u7edc\uff0c\u4e00\u65b9\u9762\u5229\u7528LVLM\u5f3a\u5927\u8bed\u4e49\u7406\u89e3\u548c\u4e16\u754c\u77e5\u8bc6\uff0c\u83b7\u53d6\u56fe\u50cf\u63cf\u8ff0\u548c\u6587\u672c\u8bc1\u636e\uff1b\u53e6\u4e00\u65b9\u9762\u901a\u8fc7\u5e73\u8861\u5b66\u4e60\u8003\u8651\u4e0d\u540c\u60c5\u611f\u7c7b\u578b\u65b0\u95fb\u7684\u7c7b\u95f4\u5dee\u5f02\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86KEN\u7f51\u7edc\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684KEN\u7f51\u7edc\u5728\u591a\u6a21\u6001\u5047\u65b0\u95fb\u68c0\u6d4b\u65b9\u9762\u6548\u679c\u826f\u597d\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u7814\u7a76\u7684\u95ee\u9898\u3002"}}
{"id": "2507.09664", "pdf": "https://arxiv.org/pdf/2507.09664", "abs": "https://arxiv.org/abs/2507.09664", "authors": ["Zoe Kaputa", "Anika Rajaram", "Vryan Almanon Feliciano", "Zhuoyue Lyu", "Maneesh Agrawala", "Hari Subramonyam"], "title": "SimStep: Chain-of-Abstractions for Incremental Specification and Debugging of AI-Generated Interactive Simulations", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Programming-by-prompting with generative AI offers a new paradigm for\nend-user programming, shifting the focus from syntactic fluency to semantic\nintent. This shift holds particular promise for non-programmers such as\neducators, who can describe instructional goals in natural language to generate\ninteractive learning content. Yet in bypassing direct code authoring, many of\nprogramming's core affordances - such as traceability, stepwise refinement, and\nbehavioral testing - are lost. We propose the Chain-of-Abstractions (CoA)\nframework as a way to recover these affordances while preserving the expressive\nflexibility of natural language. CoA decomposes the synthesis process into a\nsequence of cognitively meaningful, task-aligned representations that function\nas checkpoints for specification, inspection, and refinement. We instantiate\nthis approach in SimStep, an authoring environment for teachers that scaffolds\nsimulation creation through four intermediate abstractions: Concept Graph,\nScenario Graph, Learning Goal Graph, and UI Interaction Graph. To address\nambiguities and misalignments, SimStep includes an inverse correction process\nthat surfaces in-filled model assumptions and enables targeted revision without\nrequiring users to manipulate code. Evaluations with educators show that CoA\nenables greater authoring control and interpretability in\nprogramming-by-prompting workflows.", "AI": {"tldr": "\u63d0\u51faCoA\u6846\u67b6\u7528\u4e8e\u7f16\u7a0b\u63d0\u793a\u8303\u5f0f\uff0c\u4ee5\u6062\u590d\u7f16\u7a0b\u6838\u5fc3\u529f\u80fd\uff0c\u5728SimStep\u73af\u5883\u4e2d\u5b9e\u73b0\u5e76\u7ecf\u6559\u80b2\u8005\u8bc4\u4f30\u6709\u6548\u3002", "motivation": "\u7f16\u7a0b\u63d0\u793a\u8303\u5f0f\u867d\u5bf9\u975e\u7a0b\u5e8f\u5458\u53cb\u597d\uff0c\u4f46\u4e22\u5931\u7f16\u7a0b\u6838\u5fc3\u529f\u80fd\uff0c\u9700\u65b9\u6cd5\u6062\u590d\u8fd9\u4e9b\u529f\u80fd\u3002", "method": "\u63d0\u51faCoA\u6846\u67b6\uff0c\u5c06\u5408\u6210\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u6709\u8ba4\u77e5\u610f\u4e49\u7684\u8868\u793a\uff0c\u5728SimStep\u73af\u5883\u5b9e\u73b0\u5e76\u8bbe\u7f6e\u9006\u6821\u6b63\u8fc7\u7a0b\u3002", "result": "\u6559\u80b2\u8005\u8bc4\u4f30\u663e\u793aCoA\u5728\u7f16\u7a0b\u63d0\u793a\u5de5\u4f5c\u6d41\u4e2d\u80fd\u5b9e\u73b0\u66f4\u5927\u521b\u4f5c\u63a7\u5236\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "CoA\u6846\u67b6\u80fd\u5728\u4fdd\u7559\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u7075\u6d3b\u6027\u7684\u540c\u65f6\u6062\u590d\u7f16\u7a0b\u6838\u5fc3\u529f\u80fd\u3002"}}
{"id": "2507.10434", "pdf": "https://arxiv.org/pdf/2507.10434", "abs": "https://arxiv.org/abs/2507.10434", "authors": ["Giacomo Cignoni", "Andrea Cossu", "Alexandra Gomez-Villa", "Joost van de Weijer", "Antonio Carta"], "title": "CLA: Latent Alignment for Online Continual Self-Supervised Learning", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at CoLLAs 2025 conference", "summary": "Self-supervised learning (SSL) is able to build latent representations that\ngeneralize well to unseen data. However, only a few SSL techniques exist for\nthe online CL setting, where data arrives in small minibatches, the model must\ncomply with a fixed computational budget, and task boundaries are absent. We\nintroduce Continual Latent Alignment (CLA), a novel SSL strategy for Online CL\nthat aligns the representations learned by the current model with past\nrepresentations to mitigate forgetting. We found that our CLA is able to speed\nup the convergence of the training process in the online scenario,\noutperforming state-of-the-art approaches under the same computational budget.\nSurprisingly, we also discovered that using CLA as a pretraining protocol in\nthe early stages of pretraining leads to a better final performance when\ncompared to a full i.i.d. pretraining.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\uff08Online CL\uff09\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u7b56\u7565CLA\uff0c\u80fd\u52a0\u901f\u8bad\u7ec3\u6536\u655b\uff0c\u9884\u8bad\u7ec3\u8868\u73b0\u4e5f\u4f73\u3002", "motivation": "\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u573a\u666f\u4e0b\u81ea\u76d1\u7763\u5b66\u4e60\u6280\u672f\u8f83\u5c11\uff0c\u9700\u65b0\u65b9\u6cd5\u7f13\u89e3\u9057\u5fd8\u95ee\u9898\u3002", "method": "\u5f15\u5165Continual Latent Alignment (CLA)\u7b56\u7565\uff0c\u5c06\u5f53\u524d\u6a21\u578b\u5b66\u4e60\u7684\u8868\u5f81\u4e0e\u8fc7\u53bb\u8868\u5f81\u5bf9\u9f50\u3002", "result": "CLA\u80fd\u5728\u5728\u7ebf\u573a\u666f\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\u6536\u655b\uff0c\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u65e9\u671f\u7528CLA\u9884\u8bad\u7ec3\u6bd4\u5168\u72ec\u7acb\u540c\u5206\u5e03\u9884\u8bad\u7ec3\u6548\u679c\u597d\u3002", "conclusion": "CLA\u662f\u4e00\u79cd\u6709\u6548\u7684\u5728\u7ebf\u6301\u7eed\u5b66\u4e60\u81ea\u76d1\u7763\u7b56\u7565\u3002"}}
{"id": "2507.10442", "pdf": "https://arxiv.org/pdf/2507.10442", "abs": "https://arxiv.org/abs/2507.10442", "authors": ["Shivam Chandhok", "Wan-Cyuan Fan", "Vered Shwartz", "Vineeth N Balasubramanian", "Leonid Sigal"], "title": "Response Wide Shut? Surprising Observations in Basic Vision Language Model Capabilities", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ACL 2025 (Main Conference)", "summary": "Vision-language Models (VLMs) have emerged as general-purpose tools for\naddressing a variety of complex computer vision problems. Such models have been\nshown to be highly capable, but, at the same time, lacking some basic visual\nunderstanding skills. In this paper, we set out to understand the limitations\nof SoTA VLMs on fundamental visual tasks by constructing a series of tests that\nprobe which components of design, specifically, may be lacking. Importantly, we\ngo significantly beyond the current benchmarks, which simply measure the final\nperformance of VLM response, by also comparing and contrasting it to the\nperformance of probes trained directly on features obtained from the visual\nencoder, intermediate vision-language projection and LLM-decoder output. In\ndoing so, we uncover shortcomings in VLMs and make a number of important\nobservations about their capabilities, robustness and how they process visual\ninformation. We hope our insights will guide progress in further improving\nVLMs.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u6d4b\u8bd5\u63a2\u7a76SOTA\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u7840\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5bf9\u6bd4\u4e0d\u540c\u7ec4\u4ef6\u6027\u80fd\uff0c\u63ed\u793a\u5176\u4e0d\u8db3\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u867d\u529f\u80fd\u5f3a\u5927\u4f46\u7f3a\u4e4f\u57fa\u672c\u89c6\u89c9\u7406\u89e3\u6280\u80fd\uff0c\u8981\u4e86\u89e3\u5176\u5728\u57fa\u7840\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u6784\u5efa\u4e00\u7cfb\u5217\u6d4b\u8bd5\uff0c\u5bf9\u6bd4\u89c6\u89c9\u7f16\u7801\u5668\u7279\u5f81\u3001\u89c6\u89c9\u8bed\u8a00\u4e2d\u95f4\u6295\u5f71\u548c\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u7801\u5668\u8f93\u51fa\u4e0a\u8bad\u7ec3\u7684\u63a2\u6d4b\u5668\u7684\u6027\u80fd\u3002", "result": "\u63ed\u793a\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u5bf9\u5176\u80fd\u529b\u3001\u9c81\u68d2\u6027\u548c\u89c6\u89c9\u4fe1\u606f\u5904\u7406\u65b9\u5f0f\u6709\u4e86\u91cd\u8981\u53d1\u73b0\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u6709\u671b\u4e3a\u8fdb\u4e00\u6b65\u6539\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2507.10452", "pdf": "https://arxiv.org/pdf/2507.10452", "abs": "https://arxiv.org/abs/2507.10452", "authors": ["Eduardo D. Sontag"], "title": "Some remarks on gradient dominance and LQR policy optimization", "categories": ["cs.LG"], "comment": "This is a short paper summarizing the first part of the slides\n  presented at my keynote at the 2025 L4DC (Learning for Dynamics & Control\n  Conference) in Ann Arbor, Michigan, 05 June 2025. A partial bibliography has\n  been added. A second part on neural net feedback controllers is to be added", "summary": "Solutions of optimization problems, including policy optimization in\nreinforcement learning, typically rely upon some variant of gradient descent.\nThere has been much recent work in the machine learning, control, and\noptimization communities applying the Polyak-{\\L}ojasiewicz Inequality (PLI) to\nsuch problems in order to establish an exponential rate of convergence (a.k.a.\n``linear convergence'' in the local-iteration language of numerical analysis)\nof loss functions to their minima under the gradient flow. Often, as is the\ncase of policy iteration for the continuous-time LQR problem, this rate\nvanishes for large initial conditions, resulting in a mixed globally linear /\nlocally exponential behavior. This is in sharp contrast with the discrete-time\nLQR problem, where there is global exponential convergence. That gap between CT\nand DT behaviors motivates the search for various generalized PLI-like\nconditions, and this talk will address that topic. Moreover, these\ngeneralizations are key to understanding the transient and asymptotic effects\nof errors in the estimation of the gradient, errors which might arise from\nadversarial attacks, wrong evaluation by an oracle, early stopping of a\nsimulation, inaccurate and very approximate digital twins, stochastic\ncomputations (algorithm ``reproducibility''), or learning by sampling from\nlimited data. We describe an ``input to state stability'' (ISS) analysis of\nthis issue. The lecture also discussed convergence and PLI-like properties of\n``linear feedforward neural networks'' in feedback control, but this arXiv\nskips that part (to be updated). Much of the work described here was done in\ncollaboration with Arthur Castello B. de Oliveira, Leilei Cui, Zhong-Ping\nJiang, and Milad Siami.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u4f18\u5316\u95ee\u9898\u89e3\uff0c\u4ee5\u8fde\u7eed\u548c\u79bb\u6563\u65f6\u95f4LQR\u95ee\u9898\u6536\u655b\u5dee\u5f02\u4e3a\u52a8\u673a\uff0c\u7814\u7a76\u5e7f\u4e49PLI\u6761\u4ef6\u53ca\u68af\u5ea6\u4f30\u8ba1\u8bef\u5dee\u5f71\u54cd\uff0c\u91c7\u7528ISS\u5206\u6790\u3002", "motivation": "\u8fde\u7eed\u548c\u79bb\u6563\u65f6\u95f4LQR\u95ee\u9898\u6536\u655b\u884c\u4e3a\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u5bfb\u627e\u5e7f\u4e49PLI\u6761\u4ef6\uff1b\u540c\u65f6\u7406\u89e3\u68af\u5ea6\u4f30\u8ba1\u8bef\u5dee\u7684\u5f71\u54cd\u3002", "method": "\u5bf9\u95ee\u9898\u8fdb\u884c\u201c\u8f93\u5165\u5230\u72b6\u6001\u7a33\u5b9a\u6027\u201d\uff08ISS\uff09\u5206\u6790\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2507.10484", "pdf": "https://arxiv.org/pdf/2507.10484", "abs": "https://arxiv.org/abs/2507.10484", "authors": ["Paul Fogel", "Christophe Geissler", "George Luta"], "title": "The Target Polish: A New Approach to Outlier-Resistant Non-Negative Matrix and Tensor Factorization", "categories": ["cs.LG"], "comment": "6 pages, 4 figures, International Conference on Robust Statistics\n  2025, Stresa, Italy", "summary": "This paper introduces the \"Target Polish,\" a robust and computationally\nefficient framework for nonnegative matrix and tensor factorization. Although\nconventional weighted NMF approaches are resistant to outliers, they converge\nslowly due to the use of multiplicative updates to minimize the objective\ncriterion. In contrast, the Target Polish approach remains compatible with the\nFast-HALS algorithm, which is renowned for its speed, by adaptively smoothing\nthe data with a weighted median-based transformation. This innovation provides\noutlier resistance while maintaining the highly efficient additive update\nstructure of Fast-HALS. Empirical evaluations using image datasets corrupted\nwith structured (block) and unstructured (salt) noise demonstrate that the\nTarget Polish approach matches or exceeds the accuracy of state-of-the-art\nrobust NMF methods and reduces computational time by an order of magnitude in\nthe studied scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u2018Target Polish\u2019\u6846\u67b6\u7528\u4e8e\u975e\u8d1f\u77e9\u9635\u548c\u5f20\u91cf\u5206\u89e3\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u51c6\u786e\u3002", "motivation": "\u4f20\u7edf\u52a0\u6743NMF\u65b9\u6cd5\u6297\u5f02\u5e38\u503c\u4f46\u6536\u655b\u6162\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u6297\u5f02\u5e38\u503c\u53c8\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u52a0\u6743\u4e2d\u503c\u53d8\u6362\u81ea\u9002\u5e94\u5e73\u6ed1\u6570\u636e\uff0c\u4f7fTarget Polish\u4e0e\u5feb\u901f\u9ad8\u6548\u7684Fast - HALS\u7b97\u6cd5\u517c\u5bb9\u3002", "result": "\u5728\u542b\u566a\u58f0\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cTarget Polish\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u73b0\u6709\u9c81\u68d2NMF\u65b9\u6cd5\u7684\u51c6\u786e\u6027\uff0c\u4e14\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "Target Polish\u662f\u4e00\u79cd\u5065\u58ee\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u975e\u8d1f\u77e9\u9635\u548c\u5f20\u91cf\u5206\u89e3\u6846\u67b6\u3002"}}
{"id": "2507.10494", "pdf": "https://arxiv.org/pdf/2507.10494", "abs": "https://arxiv.org/abs/2507.10494", "authors": ["Tanveer Khan", "Mindaugas Budzys", "Antonis Michalas"], "title": "Split Happens: Combating Advanced Threats with Split Learning and Function Secret Sharing", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Split Learning (SL) -- splits a model into two distinct parts to help protect\nclient data while enhancing Machine Learning (ML) processes. Though promising,\nSL has proven vulnerable to different attacks, thus raising concerns about how\neffective it may be in terms of data privacy. Recent works have shown promising\nresults for securing SL through the use of a novel paradigm, named Function\nSecret Sharing (FSS), in which servers obtain shares of a function they compute\nand operate on a public input hidden with a random mask. However, these works\nfall short in addressing the rising number of attacks which exist on SL. In\nSplitHappens, we expand the combination of FSS and SL to U-shaped SL. Similarly\nto other works, we are able to make use of the benefits of SL by reducing the\ncommunication and computational costs of FSS. However, a U-shaped SL provides a\nhigher security guarantee than previous works, allowing a client to keep the\nlabels of the training data secret, without having to share them with the\nserver. Through this, we are able to generalize the security analysis of\nprevious works and expand it to different attack vectors, such as modern model\ninversion attacks as well as label inference attacks. We tested our approach\nfor two different convolutional neural networks on different datasets. These\nexperiments show the effectiveness of our approach in reducing the training\ntime as well as the communication costs when compared to simply using FSS while\nmatching prior accuracy.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faSplitHappens\u65b9\u6cd5\uff0c\u5c06FSS\u4e0eU\u5f62SL\u7ed3\u5408\uff0c\u964d\u4f4e\u8bad\u7ec3\u65f6\u95f4\u548c\u901a\u4fe1\u6210\u672c\uff0c\u4fdd\u969c\u6570\u636e\u9690\u79c1\u5e76\u62b5\u5fa1\u591a\u79cd\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u4fdd\u969cSL\u6570\u636e\u9690\u79c1\u548c\u62b5\u5fa1\u653b\u51fb\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u63d0\u5347\u5b89\u5168\u6027\u3002", "method": "\u5c06FSS\u4e0eU\u5f62SL\u7ed3\u5408\uff0c\u8ba9\u5ba2\u6237\u7aef\u65e0\u9700\u4e0e\u670d\u52a1\u5668\u5171\u4eab\u8bad\u7ec3\u6570\u636e\u6807\u7b7e\u3002", "result": "\u5728\u4e0d\u540c\u6570\u636e\u96c6\u7684\u4e24\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4e0a\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u964d\u4f4e\u8bad\u7ec3\u65f6\u95f4\u548c\u901a\u4fe1\u6210\u672c\uff0c\u51c6\u786e\u7387\u4e0e\u4e4b\u524d\u76f8\u5f53\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u6709\u6548\u7ed3\u5408FSS\u548cU\u5f62SL\uff0c\u80fd\u62b5\u5fa1\u591a\u79cd\u653b\u51fb\uff0c\u964d\u4f4e\u6210\u672c\u4e14\u4fdd\u8bc1\u51c6\u786e\u7387\u3002"}}
{"id": "2507.09725", "pdf": "https://arxiv.org/pdf/2507.09725", "abs": "https://arxiv.org/abs/2507.09725", "authors": ["Gabriel G. Gattaux", "Julien R. Serres", "Franck Ruffier", "Antoine Wystrach"], "title": "Visual Homing in Outdoor Robots Using Mushroom Body Circuits and Learning Walks", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "Published by Springer Nature with the 14th bioinspired and biohybrid\n  systems conference in Sheffield, and presented at the conference in July 2025", "summary": "Ants achieve robust visual homing with minimal sensory input and only a few\nlearning walks, inspiring biomimetic solutions for autonomous navigation. While\nMushroom Body (MB) models have been used in robotic route following, they have\nnot yet been applied to visual homing. We present the first real-world\nimplementation of a lateralized MB architecture for visual homing onboard a\ncompact autonomous car-like robot. We test whether the sign of the angular path\nintegration (PI) signal can categorize panoramic views, acquired during\nlearning walks and encoded in the MB, into \"goal on the left\" and \"goal on the\nright\" memory banks, enabling robust homing in natural outdoor settings. We\nvalidate this approach through four incremental experiments: (1) simulation\nshowing attractor-like nest dynamics; (2) real-world homing after decoupled\nlearning walks, producing nest search behavior; (3) homing after random walks\nusing noisy PI emulated with GPS-RTK; and (4) precise stopping-at-the-goal\nbehavior enabled by a fifth MB Output Neuron (MBON) encoding goal-views to\ncontrol velocity. This mimics the accurate homing behavior of ants and\nfunctionally resembles waypoint-based position control in robotics, despite\nrelying solely on visual input. Operating at 8 Hz on a Raspberry Pi 4 with\n32x32 pixel views and a memory footprint under 9 kB, our system offers a\nbiologically grounded, resource-efficient solution for autonomous visual\nhoming.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4fa7\u5411\u5316\u8611\u83c7\u4f53\u67b6\u6784\u7684\u89c6\u89c9\u5f52\u5de2\u7cfb\u7edf\uff0c\u5728\u7d27\u51d1\u7c7b\u6c7d\u8f66\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\uff0c\u662f\u8d44\u6e90\u9ad8\u6548\u7684\u4eff\u751f\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u8682\u8681\u89c6\u89c9\u5f52\u5de2\u80fd\u529b\u542f\u53d1\u4eff\u751f\u81ea\u4e3b\u5bfc\u822a\uff0c\u73b0\u6709\u8611\u83c7\u4f53\u6a21\u578b\u672a\u7528\u4e8e\u89c6\u89c9\u5f52\u5de2\uff0c\u7814\u7a76\u5176\u5728\u89c6\u89c9\u5f52\u5de2\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5728\u7d27\u51d1\u7c7b\u6c7d\u8f66\u673a\u5668\u4eba\u4e0a\u5b9e\u73b0\u4fa7\u5411\u5316\u8611\u83c7\u4f53\u67b6\u6784\u7528\u4e8e\u89c6\u89c9\u5f52\u5de2\uff0c\u901a\u8fc7\u89d2\u8def\u5f84\u79ef\u5206\u4fe1\u53f7\u6b63\u8d1f\u5bf9\u5168\u666f\u89c6\u56fe\u5206\u7c7b\uff0c\u5f00\u5c55\u56db\u4e2a\u9012\u8fdb\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u7c7b\u4f3c\u8682\u8681\u7684\u7cbe\u786e\u5f52\u5de2\u884c\u4e3a\uff0c\u7cfb\u7edf\u8fd0\u884c\u9891\u73878Hz\uff0c\u5185\u5b58\u5360\u7528\u5c0f\u4e8e9kB\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u662f\u57fa\u4e8e\u751f\u7269\u539f\u7406\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u81ea\u4e3b\u89c6\u89c9\u5f52\u5de2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10502", "pdf": "https://arxiv.org/pdf/2507.10502", "abs": "https://arxiv.org/abs/2507.10502", "authors": ["Elizabeth Fahsbender", "Alma Andersson", "Jeremy Ash", "Polina Binder", "Daniel Burkhardt", "Benjamin Chang", "Georg K. Gerber", "Anthony Gitter", "Patrick Godau", "Ankit Gupta", "Genevieve Haliburton", "Siyu He", "Trey Ideker", "Ivana Jelic", "Aly Khan", "Yang-Joon Kim", "Aditi Krishnapriyan", "Jon M. Laurent", "Tianyu Liu 28", "Emma Lundberg", "Shalin B. Mehta", "Rob Moccia", "Angela Oliveira Pisco", "Katherine S. Pollard", "Suresh Ramani", "Julio Saez-Rodriguez", "Yasin Senbabaoglu", "Elana Simon", "Srinivasan Sivanandan", "Gustavo Stolovitzky", "Marc Valer", "Bo Wang", "Xikun Zhang", "James Zou", "Katrina Kalantar"], "title": "Benchmarking and Evaluation of AI Models in Biology: Outcomes and Recommendations from the CZI Virtual Cells Workshop", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Artificial intelligence holds immense promise for transforming biology, yet a\nlack of standardized, cross domain, benchmarks undermines our ability to build\nrobust, trustworthy models. Here, we present insights from a recent workshop\nthat convened machine learning and computational biology experts across\nimaging, transcriptomics, proteomics, and genomics to tackle this gap. We\nidentify major technical and systemic bottlenecks such as data heterogeneity\nand noise, reproducibility challenges, biases, and the fragmented ecosystem of\npublicly available resources and propose a set of recommendations for building\nbenchmarking frameworks that can efficiently compare ML models of biological\nsystems across tasks and data modalities. By promoting high quality data\ncuration, standardized tooling, comprehensive evaluation metrics, and open,\ncollaborative platforms, we aim to accelerate the development of robust\nbenchmarks for AI driven Virtual Cells. These benchmarks are crucial for\nensuring rigor, reproducibility, and biological relevance, and will ultimately\nadvance the field toward integrated models that drive new discoveries,\ntherapeutic insights, and a deeper understanding of cellular systems.", "AI": {"tldr": "\u56e0\u7f3a\u4e4f\u8de8\u9886\u57df\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u4eba\u5de5\u667a\u80fd\u5728\u751f\u7269\u5b66\u5e94\u7528\u53d7\u9650\u3002\u7814\u8ba8\u4f1a\u4e13\u5bb6\u786e\u5b9a\u74f6\u9888\u5e76\u63d0\u51fa\u6784\u5efa\u57fa\u51c6\u6846\u67b6\u5efa\u8bae\uff0c\u4ee5\u63a8\u52a8AI\u9a71\u52a8\u865a\u62df\u7ec6\u80de\u57fa\u51c6\u53d1\u5c55\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5728\u751f\u7269\u5b66\u9886\u57df\u5e94\u7528\u6f5c\u529b\u5927\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u3001\u8de8\u9886\u57df\u57fa\u51c6\u5f71\u54cd\u6784\u5efa\u53ef\u9760\u6a21\u578b\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u53ec\u96c6\u8de8\u9886\u57df\u4e13\u5bb6\uff0c\u786e\u5b9a\u6280\u672f\u548c\u7cfb\u7edf\u6027\u74f6\u9888\uff0c\u63d0\u51fa\u6784\u5efa\u57fa\u51c6\u6846\u67b6\u7684\u4e00\u7cfb\u5217\u5efa\u8bae\uff0c\u5305\u62ec\u4fc3\u8fdb\u9ad8\u8d28\u91cf\u6570\u636e\u7ba1\u7406\u3001\u6807\u51c6\u5316\u5de5\u5177\u3001\u7efc\u5408\u8bc4\u4f30\u6307\u6807\u548c\u5f00\u653e\u534f\u4f5c\u5e73\u53f0\u3002", "result": "\u63d0\u51fa\u4e86\u6784\u5efa\u53ef\u8de8\u4efb\u52a1\u548c\u6570\u636e\u6a21\u5f0f\u6bd4\u8f83\u751f\u7269\u7cfb\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u57fa\u51c6\u6846\u67b6\u7684\u5efa\u8bae\u3002", "conclusion": "\u8fd9\u4e9b\u57fa\u51c6\u5bf9\u786e\u4fdd\u4e25\u8c28\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u751f\u7269\u76f8\u5173\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5c06\u63a8\u52a8\u8be5\u9886\u57df\u671d\u7740\u96c6\u6210\u6a21\u578b\u53d1\u5c55\uff0c\u5e26\u6765\u65b0\u53d1\u73b0\u548c\u5bf9\u7ec6\u80de\u7cfb\u7edf\u7684\u66f4\u6df1\u5165\u7406\u89e3\u3002"}}
{"id": "2507.10532", "pdf": "https://arxiv.org/pdf/2507.10532", "abs": "https://arxiv.org/abs/2507.10532", "authors": ["Mingqi Wu", "Zhihao Zhang", "Qiaole Dong", "Zhiheng Xi", "Jun Zhao", "Senjie Jin", "Xiaoran Fan", "Yuhao Zhou", "Yanwei Fu", "Qin Liu", "Songyang Zhang", "Qi Zhang"], "title": "Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "26 pages", "summary": "The reasoning capabilities of large language models (LLMs) have been a\nlongstanding focus of research. Recent works have further enhanced these\ncapabilities using reinforcement learning (RL), with many new methods claiming\nsignificant improvements with minimal or no external supervision. Surprisingly,\nsome studies even suggest that random or incorrect reward signals can enhance\nreasoning performance. However, these breakthroughs are mostly reported on the\nQwen2.5 model family and evaluated on well-known benchmarks such as MATH-500,\nAMC, and AIME, while failing to achieve similar gains on other models like\nLlama, which warrants further investigation. Our analysis shows that although\nQwen2.5 achieves strong mathematical reasoning performance, its pretraining on\nlarge-scale web corpora makes it vulnerable to data contamination in popular\nbenchmarks. As a result, results derived from these benchmarks may be\nunreliable. To address this, we introduce a generator that produces fully\nsynthetic arithmetic problems of arbitrary length and difficulty, yielding a\nclean dataset we call RandomCalculation. Using these leakage-free datasets, we\nshow that only accurate reward signals consistently improve performance, while\nnoisy or incorrect signals do not. We advocate for evaluating RL methods on\nuncontaminated benchmarks and across diverse model families to ensure\ntrustworthy conclusions.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u591a\u5728Qwen2.5\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u53ef\u80fd\u56e0\u6570\u636e\u6c61\u67d3\u4e0d\u53ef\u9760\u3002\u672c\u6587\u63d0\u51fa\u5408\u6210\u6570\u636e\u96c6RandomCalculation\uff0c\u8868\u660e\u53ea\u6709\u51c6\u786e\u5956\u52b1\u4fe1\u53f7\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u5021\u5bfc\u5728\u65e0\u6c61\u67d3\u57fa\u51c6\u548c\u4e0d\u540c\u6a21\u578b\u4e0a\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u591a\u5728Qwen2.5\u4e0a\u8bc4\u4f30\uff0c\u5728\u5176\u4ed6\u6a21\u578b\u5982Llama\u4e0a\u672a\u53d6\u5f97\u7c7b\u4f3c\u6548\u679c\uff0c\u4e14Qwen2.5\u56e0\u9884\u8bad\u7ec3\u6613\u53d7\u57fa\u51c6\u6570\u636e\u6c61\u67d3\uff0c\u7ed3\u679c\u53ef\u80fd\u4e0d\u53ef\u9760\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u5f15\u5165\u751f\u6210\u5668\u751f\u6210\u4efb\u610f\u957f\u5ea6\u548c\u96be\u5ea6\u7684\u5408\u6210\u7b97\u672f\u95ee\u9898\uff0c\u6784\u5efa\u65e0\u6c61\u67d3\u6570\u636e\u96c6RandomCalculation\u3002", "result": "\u4f7f\u7528\u65e0\u6c61\u67d3\u6570\u636e\u96c6\u8868\u660e\u53ea\u6709\u51c6\u786e\u5956\u52b1\u4fe1\u53f7\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u566a\u58f0\u6216\u9519\u8bef\u4fe1\u53f7\u4e0d\u80fd\u3002", "conclusion": "\u5021\u5bfc\u5728\u65e0\u6c61\u67d3\u57fa\u51c6\u548c\u4e0d\u540c\u6a21\u578b\u65cf\u4e0a\u8bc4\u4f30\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fdd\u7ed3\u8bba\u53ef\u9760\u3002"}}
{"id": "2507.09759", "pdf": "https://arxiv.org/pdf/2507.09759", "abs": "https://arxiv.org/abs/2507.09759", "authors": ["Abdul Manaf", "Nimra Mughal"], "title": "AI-Enhanced Pediatric Pneumonia Detection: A CNN-Based Approach Using Data Augmentation and Generative Adversarial Networks (GANs)", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Pneumonia is a leading cause of mortality in children under five, requiring\naccurate chest X-ray diagnosis. This study presents a machine learning-based\nPediatric Chest Pneumonia Classification System to assist healthcare\nprofessionals in diagnosing pneumonia from chest X-ray images. The CNN-based\nmodel was trained on 5,863 labeled chest X-ray images from children aged 0-5\nyears from the Guangzhou Women and Children's Medical Center. To address\nlimited data, we applied augmentation techniques (rotation, zooming, shear,\nhorizontal flipping) and employed GANs to generate synthetic images, addressing\nclass imbalance. The system achieved optimal performance using combined\noriginal, augmented, and GAN-generated data, evaluated through accuracy and F1\nscore metrics. The final model was deployed via a Flask web application,\nenabling real-time classification with probability estimates. Results\ndemonstrate the potential of deep learning and GANs in improving diagnostic\naccuracy and efficiency for pediatric pneumonia classification, particularly\nvaluable in resource-limited clinical settings\nhttps://github.com/AbdulManaf12/Pediatric-Chest-Pneumonia-Classification", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u513f\u79d1\u80f8\u90e8\u80ba\u708e\u5206\u7c7b\u7cfb\u7edf\uff0c\u7528CNN\u6a21\u578b\u8bad\u7ec3\u56fe\u50cf\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u548cGAN\u5904\u7406\u6570\u636e\uff0c\u90e8\u7f72\u7f51\u7edc\u5e94\u7528\uff0c\u7ed3\u679c\u663e\u793a\u53ef\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u80ba\u708e\u662f\u4e94\u5c81\u4ee5\u4e0b\u513f\u7ae5\u4e3b\u8981\u6b7b\u56e0\uff0c\u9700\u51c6\u786e\u7684\u80f8\u90e8X\u5149\u8bca\u65ad\uff0c\u6545\u6784\u5efa\u7cfb\u7edf\u8f85\u52a9\u533b\u7597\u4eba\u5458\u8bca\u65ad\u3002", "method": "\u4f7f\u75285863\u5f200 - 5\u5c81\u513f\u7ae5\u80f8\u90e8X\u5149\u56fe\u50cf\u8bad\u7ec3CNN\u6a21\u578b\uff0c\u5e94\u7528\u6570\u636e\u589e\u5f3a\u6280\u672f\u548cGAN\u751f\u6210\u5408\u6210\u56fe\u50cf\u5904\u7406\u6570\u636e\u6709\u9650\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u7cfb\u7edf\u4f7f\u7528\u539f\u59cb\u3001\u589e\u5f3a\u548cGAN\u751f\u6210\u7684\u6570\u636e\u7ed3\u5408\u53d6\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u901a\u8fc7\u51c6\u786e\u7387\u548cF1\u5206\u6570\u8bc4\u4f30\uff0c\u6700\u7ec8\u6a21\u578b\u901a\u8fc7Flask\u7f51\u7edc\u5e94\u7528\u90e8\u7f72\u5b9e\u73b0\u5b9e\u65f6\u5206\u7c7b\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u548cGAN\u5728\u63d0\u9ad8\u513f\u79d1\u80ba\u708e\u5206\u7c7b\u8bca\u65ad\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u5728\u8d44\u6e90\u6709\u9650\u7684\u4e34\u5e8a\u73af\u5883\u4e2d\u5f88\u6709\u4ef7\u503c\u3002"}}
{"id": "2507.10536", "pdf": "https://arxiv.org/pdf/2507.10536", "abs": "https://arxiv.org/abs/2507.10536", "authors": ["Qiaoyue Tang", "Alain Zhiyanov", "Mathias L\u00e9cuyer"], "title": "On the Performance of Differentially Private Optimization with Heavy-Tail Class Imbalance", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we analyze the optimization behaviour of common private\nlearning optimization algorithms under heavy-tail class imbalanced\ndistribution. We show that, in a stylized model, optimizing with Gradient\nDescent with differential privacy (DP-GD) suffers when learning low-frequency\nclasses, whereas optimization algorithms that estimate second-order information\ndo not. In particular, DP-AdamBC that removes the DP bias from estimating loss\ncurvature is a crucial component to avoid the ill-condition caused by\nheavy-tail class imbalance, and empirically fits the data better with\n$\\approx8\\%$ and $\\approx5\\%$ increase in training accuracy when learning the\nleast frequent classes on both controlled experiments and real data\nrespectively.", "AI": {"tldr": "\u5206\u6790\u5e38\u89c1\u9690\u79c1\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u5728\u91cd\u5c3e\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u5e03\u4e0b\u7684\u4f18\u5316\u884c\u4e3a\uff0c\u6307\u51faDP - GD\u5b66\u4e60\u4f4e\u9891\u7c7b\u6709\u95ee\u9898\uff0cDP - AdamBC\u53ef\u907f\u514d\u75c5\u6001\u6761\u4ef6\uff0c\u4e14\u5728\u8bad\u7ec3\u4f4e\u9891\u7c7b\u4e0a\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u3002", "motivation": "\u7814\u7a76\u5e38\u89c1\u9690\u79c1\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u5728\u91cd\u5c3e\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u5e03\u4e0b\u7684\u4f18\u5316\u60c5\u51b5\u3002", "method": "\u6784\u5efa\u7406\u8bba\u6a21\u578b\u5206\u6790\uff0c\u5bf9\u6bd4\u68af\u5ea6\u4e0b\u964d\uff08DP - GD\uff09\u548c\u4f30\u8ba1\u4e8c\u9636\u4fe1\u606f\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u91c7\u7528DP - AdamBC\u53bb\u9664\u4f30\u8ba1\u635f\u5931\u66f2\u7387\u7684DP\u504f\u5dee\u3002", "result": "DP - GD\u5b66\u4e60\u4f4e\u9891\u7c7b\u65f6\u8868\u73b0\u4e0d\u4f73\uff0cDP - AdamBC\u80fd\u907f\u514d\u91cd\u5c3e\u7c7b\u522b\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u75c5\u6001\u6761\u4ef6\uff0c\u5728\u63a7\u5236\u5b9e\u9a8c\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u5b66\u4e60\u4f4e\u9891\u7c7b\u65f6\u8bad\u7ec3\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u7ea68%\u548c5%\u3002", "conclusion": "DP - AdamBC\u5728\u91cd\u5c3e\u7c7b\u522b\u4e0d\u5e73\u8861\u5206\u5e03\u4e0b\u5b66\u4e60\u4f4e\u9891\u7c7b\u6548\u679c\u66f4\u597d\u3002"}}
{"id": "2507.09762", "pdf": "https://arxiv.org/pdf/2507.09762", "abs": "https://arxiv.org/abs/2507.09762", "authors": ["Yasir Ech-Chammakhy", "Anas Motii", "Anass Rabii", "Jaafar Chbili"], "title": "EventHunter: Dynamic Clustering and Ranking of Security Events from Hacker Forum Discussions", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Accepted for publication at the 28th International Symposium on\n  Research in Attacks, Intrusions, and Defenses (RAID 2025)", "summary": "Hacker forums provide critical early warning signals for emerging\ncybersecurity threats, but extracting actionable intelligence from their\nunstructured and noisy content remains a significant challenge. This paper\npresents an unsupervised framework that automatically detects, clusters, and\nprioritizes security events discussed across hacker forum posts. Our approach\nleverages Transformer-based embeddings fine-tuned with contrastive learning to\ngroup related discussions into distinct security event clusters, identifying\nincidents like zero-day disclosures or malware releases without relying on\npredefined keywords. The framework incorporates a daily ranking mechanism that\nprioritizes identified events using quantifiable metrics reflecting timeliness,\nsource credibility, information completeness, and relevance. Experimental\nevaluation on real-world hacker forum data demonstrates that our method\neffectively reduces noise and surfaces high-priority threats, enabling security\nanalysts to mount proactive responses. By transforming disparate hacker forum\ndiscussions into structured, actionable intelligence, our work addresses\nfundamental challenges in automated threat detection and analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0\u76d1\u7763\u6846\u67b6\u5904\u7406\u9ed1\u5ba2\u8bba\u575b\u5185\u5bb9\uff0c\u68c0\u6d4b\u3001\u805a\u7c7b\u548c\u6392\u5e8f\u5b89\u5168\u4e8b\u4ef6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ef\u6709\u6548\u964d\u566a\u5e76\u53d1\u73b0\u9ad8\u4f18\u5148\u7ea7\u5a01\u80c1\u3002", "motivation": "\u4ece\u9ed1\u5ba2\u8bba\u575b\u975e\u7ed3\u6784\u5316\u548c\u5608\u6742\u5185\u5bb9\u4e2d\u63d0\u53d6\u53ef\u64cd\u4f5c\u60c5\u62a5\u662f\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u65b9\u6cd5\u8fdb\u884c\u81ea\u52a8\u5316\u5a01\u80c1\u68c0\u6d4b\u548c\u5206\u6790\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u5d4c\u5165\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5fae\u8c03\uff0c\u5c06\u76f8\u5173\u8ba8\u8bba\u5206\u7ec4\u4e3a\u4e0d\u540c\u5b89\u5168\u4e8b\u4ef6\u96c6\u7fa4\uff0c\u7ed3\u5408\u6bcf\u65e5\u6392\u540d\u673a\u5236\u7528\u53ef\u91cf\u5316\u6307\u6807\u5bf9\u4e8b\u4ef6\u6392\u5e8f\u3002", "result": "\u5728\u771f\u5b9e\u9ed1\u5ba2\u8bba\u575b\u6570\u636e\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u566a\u5e76\u51f8\u663e\u9ad8\u4f18\u5148\u7ea7\u5a01\u80c1\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06\u4e0d\u540c\u9ed1\u5ba2\u8bba\u575b\u8ba8\u8bba\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u64cd\u4f5c\u60c5\u62a5\uff0c\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u5a01\u80c1\u68c0\u6d4b\u548c\u5206\u6790\u7684\u57fa\u672c\u6311\u6218\u3002"}}
{"id": "2507.10539", "pdf": "https://arxiv.org/pdf/2507.10539", "abs": "https://arxiv.org/abs/2507.10539", "authors": ["Tao Feng", "Yexin Wu", "Guanyu Lin", "Jiaxuan You"], "title": "Graph World Model", "categories": ["cs.LG"], "comment": null, "summary": "World models (WMs) demonstrate strong capabilities in prediction, generation,\nand planning tasks. Existing WMs primarily focus on unstructured data and\ncannot leverage the ubiquitous structured data, often represented as graphs, in\nthe digital world. While multiple graph foundation models have been proposed,\nthey focus on graph learning tasks and cannot extend to diverse multi-modal\ndata and interdisciplinary tasks. To address these challenges, we propose the\nGraph World Model (GWM), a world model that supports both unstructured and\ngraph-structured states with multi-modal information and represents diverse\ntasks as actions. The core of a GWM is a generic message-passing algorithm to\naggregate structured information, either over a unified multi-modal token space\nby converting multi-modal data into text (GWM-T) or a unified multi-modal\nembedding space by modality-specific encoders (GWM-E). Notably, GWM introduces\naction nodes to support diverse tasks, where action nodes are linked to other\nnodes via direct reference or similarity computation. Extensive experiments on\nsix tasks from diverse domains, including multi-modal generation and matching,\nrecommendation, graph prediction, multi-agent, retrieval-augmented generation,\nand planning and optimization, show that the same GWM outperforms or matches\ndomain-specific baselines' performance, benefits from multi-hop structures, and\ndemonstrates strong zero-shot/few-shot capabilities on unseen new tasks. Our\ncode for GWM is released at https://github.com/ulab-uiuc/GWM.", "AI": {"tldr": "\u63d0\u51fa\u56fe\u4e16\u754c\u6a21\u578bGWM\uff0c\u652f\u6301\u975e\u7ed3\u6784\u5316\u548c\u56fe\u7ed3\u6784\u72b6\u6001\uff0c\u9002\u7528\u4e8e\u591a\u6a21\u6001\u4fe1\u606f\u548c\u591a\u6837\u4efb\u52a1\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e14\u6709\u96f6\u6837\u672c/\u5c11\u6837\u672c\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4e16\u754c\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u975e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u65e0\u6cd5\u5229\u7528\u56fe\u7ed3\u6784\u6570\u636e\uff1b\u56fe\u57fa\u7840\u6a21\u578b\u4e13\u6ce8\u56fe\u5b66\u4e60\u4efb\u52a1\uff0c\u65e0\u6cd5\u6269\u5c55\u5230\u591a\u6a21\u6001\u6570\u636e\u548c\u8de8\u5b66\u79d1\u4efb\u52a1\u3002", "method": "\u63d0\u51faGWM\uff0c\u6838\u5fc3\u662f\u901a\u7528\u6d88\u606f\u4f20\u9012\u7b97\u6cd5\uff0c\u901a\u8fc7GWM - T\u5c06\u591a\u6a21\u6001\u6570\u636e\u8f6c\u4e3a\u6587\u672c\u3001GWM - E\u4f7f\u7528\u7279\u5b9a\u6a21\u6001\u7f16\u7801\u5668\uff0c\u5f15\u5165\u52a8\u4f5c\u8282\u70b9\u652f\u6301\u591a\u6837\u4efb\u52a1\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u9886\u57df\u4efb\u52a1\u4e0a\uff0cGWM\u8868\u73b0\u4f18\u4e8e\u6216\u5ab2\u7f8e\u7279\u5b9a\u9886\u57df\u57fa\u7ebf\uff0c\u53d7\u76ca\u4e8e\u591a\u8df3\u7ed3\u6784\uff0c\u5728\u672a\u89c1\u65b0\u4efb\u52a1\u4e0a\u6709\u5f3a\u96f6\u6837\u672c/\u5c11\u6837\u672c\u80fd\u529b\u3002", "conclusion": "GWM\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u95ee\u9898\uff0c\u5728\u591a\u9886\u57df\u4efb\u52a1\u8868\u73b0\u826f\u597d\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.10540", "pdf": "https://arxiv.org/pdf/2507.10540", "abs": "https://arxiv.org/abs/2507.10540", "authors": ["Tao Feng", "Haozhen Zhang", "Zijie Lei", "Pengrui Han", "Mostofa Patwary", "Mohammad Shoeybi", "Bryan Catanzaro", "Jiaxuan You"], "title": "Fusing LLM Capabilities with Routing Data", "categories": ["cs.LG"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has created a vibrant\necosystem of diverse architectures, each with unique strengths due to\ndifferences in design, training data, and objectives. However, most\napplications still rely on a single backend model, limiting coverage of\ncapabilities and leading to inefficiencies in performance and token cost when\ntackling complex tasks. We highlight an underexploited opportunity: LLM routing\ndata, produced when hosting platforms route diverse queries to different\nmodels, which can reveal comparative strengths across tasks. To address this,\nwe propose FusionBench, a comprehensive routing benchmark covering 14 tasks\nacross five domains with 20 open-source LLMs (8B to 671B parameters), capturing\n103M tokens and summarizing reusable thought templates from top models.\nBuilding on this, we introduce FusionFactory, a systematic fusion framework\nwith three levels: (1) query-level fusion, tailoring routers for each query\nusing both direct responses and reasoning-augmented outputs; (2) thought-level\nfusion, leveraging abstract templates derived from top-performing LLMs' answers\nto similar queries; and (3) model-level fusion, transferring capabilities\nbetween models via distillation, using top responses or highest judge scores as\ntraining data. Experiments show FusionFactory consistently outperforms the best\nindividual LLM across all 14 benchmarks, with optimal fusion configurations\nvarying by benchmark, demonstrating the value of systematic LLM fusion in\nharnessing complementary strengths and improving overall performance.", "AI": {"tldr": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u591a\u4f9d\u8d56\u5355\u6a21\u578b\uff0c\u672c\u6587\u63d0\u51faFusionBench\u57fa\u51c6\u548cFusionFactory\u878d\u5408\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793aFusionFactory\u80fd\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u591a\u4f9d\u8d56\u5355\u6a21\u578b\uff0c\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u5b58\u5728\u80fd\u529b\u8986\u76d6\u4e0d\u8db3\u3001\u6027\u80fd\u548c\u6210\u672c\u4f4e\u6548\u7684\u95ee\u9898\uff0c\u800cLLM\u8def\u7531\u6570\u636e\u53ef\u63ed\u793a\u6a21\u578b\u4f18\u52bf\u3002", "method": "\u63d0\u51faFusionBench\u57fa\u51c6\u6db5\u76d65\u4e2a\u9886\u57df14\u4e2a\u4efb\u52a1\u548c20\u4e2a\u5f00\u6e90\u5927\u6a21\u578b\uff1b\u5f15\u5165FusionFactory\u878d\u5408\u6846\u67b6\uff0c\u5305\u62ec\u67e5\u8be2\u7ea7\u3001\u601d\u7ef4\u7ea7\u548c\u6a21\u578b\u7ea7\u878d\u5408\u3002", "result": "FusionFactory\u5728\u6240\u670914\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u4f73\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e0d\u540c\u57fa\u51c6\u7684\u6700\u4f18\u878d\u5408\u914d\u7f6e\u4e0d\u540c\u3002", "conclusion": "\u7cfb\u7edf\u6027\u7684\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u80fd\u5229\u7528\u6a21\u578b\u4e92\u8865\u4f18\u52bf\uff0c\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2507.09780", "pdf": "https://arxiv.org/pdf/2507.09780", "abs": "https://arxiv.org/abs/2507.09780", "authors": ["Feilong Qiaoyuan", "Jihe Wang", "Zhiyu Sun", "Linying Wu", "Yuanhua Xiao", "Danghui Wang"], "title": "BitParticle: Partializing Sparse Dual-Factors to Build Quasi-Synchronizing MAC Arrays for Energy-efficient DNNs", "categories": ["cs.AR", "cs.AI"], "comment": "9 pages, 13 figures, 3 Tables", "summary": "Bit-level sparsity in quantized deep neural networks (DNNs) offers\nsignificant potential for optimizing Multiply-Accumulate (MAC) operations.\nHowever, two key challenges still limit its practical exploitation. First,\nconventional bit-serial approaches cannot simultaneously leverage the sparsity\nof both factors, leading to a complete waste of one factor' s sparsity. Methods\ndesigned to exploit dual-factor sparsity are still in the early stages of\nexploration, facing the challenge of partial product explosion. Second, the\nfluctuation of bit-level sparsity leads to variable cycle counts for MAC\noperations. Existing synchronous scheduling schemes that are suitable for\ndual-factor sparsity exhibit poor flexibility and still result in significant\nunderutilization of MAC units. To address the first challenge, this study\nproposes a MAC unit that leverages dual-factor sparsity through the emerging\nparticlization-based approach. The proposed design addresses the issue of\npartial product explosion through simple control logic, resulting in a more\narea- and energy-efficient MAC unit. In addition, by discarding less\nsignificant intermediate results, the design allows for further hardware\nsimplification at the cost of minor accuracy loss. To address the second\nchallenge, a quasi-synchronous scheme is introduced that adds cycle-level\nelasticity to the MAC array, reducing pipeline stalls and thereby improving MAC\nunit utilization. Evaluation results show that the exact version of the\nproposed MAC array architecture achieves a 29.2% improvement in area efficiency\ncompared to the state-of-the-art bit-sparsity-driven architecture, while\nmaintaining comparable energy efficiency. The approximate variant further\nimproves energy efficiency by 7.5%, compared to the exact version. Index-Terms:\nDNN acceleration, Bit-level sparsity, MAC unit", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u91cf\u5316DNN\u4e2d\u4f4d\u7ea7\u7a00\u758f\u6027\u5229\u7528\u7684\u4e24\u4e2a\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u4e8e\u9897\u7c92\u5316\u65b9\u6cd5\u7684MAC\u5355\u5143\u548c\u51c6\u540c\u6b65\u65b9\u6848\uff0c\u8bc4\u4f30\u663e\u793a\u6240\u63d0\u67b6\u6784\u6709\u66f4\u597d\u7684\u9762\u79ef\u548c\u80fd\u91cf\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4e0d\u80fd\u5145\u5206\u5229\u7528\u4f4d\u7ea7\u7a00\u758f\u6027\uff0c\u5b58\u5728\u90e8\u5206\u79ef\u7206\u70b8\u548cMAC\u5355\u5143\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9897\u7c92\u5316\u65b9\u6cd5\u5229\u7528\u53cc\u56e0\u5b50\u7a00\u758f\u6027\u7684MAC\u5355\u5143\uff0c\u7528\u7b80\u5355\u63a7\u5236\u903b\u8f91\u89e3\u51b3\u90e8\u5206\u79ef\u7206\u70b8\u95ee\u9898\uff1b\u5f15\u5165\u51c6\u540c\u6b65\u65b9\u6848\u589e\u52a0MAC\u9635\u5217\u7684\u5468\u671f\u5f39\u6027\u3002", "result": "\u7cbe\u786e\u7248\u672c\u7684MAC\u9635\u5217\u67b6\u6784\u9762\u79ef\u6548\u7387\u63d0\u534729.2%\uff0c\u8fd1\u4f3c\u7248\u672c\u6bd4\u7cbe\u786e\u7248\u672c\u80fd\u91cf\u6548\u7387\u8fdb\u4e00\u6b65\u63d0\u53477.5%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347MAC\u5355\u5143\u7684\u9762\u79ef\u548c\u80fd\u91cf\u6548\u7387\u3002"}}
{"id": "2507.10546", "pdf": "https://arxiv.org/pdf/2507.10546", "abs": "https://arxiv.org/abs/2507.10546", "authors": ["Kexin Gu Baugh", "Vincent Perreault", "Matthew Baugh", "Luke Dickens", "Katsumi Inoue", "Alessandra Russo"], "title": "Disentangling Neural Disjunctive Normal Form Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at NeSy 2025", "summary": "Neural Disjunctive Normal Form (DNF) based models are powerful and\ninterpretable approaches to neuro-symbolic learning and have shown promising\nresults in classification and reinforcement learning settings without prior\nknowledge of the tasks. However, their performance is degraded by the\nthresholding of the post-training symbolic translation process. We show here\nthat part of the performance degradation during translation is due to its\nfailure to disentangle the learned knowledge represented in the form of the\nnetworks' weights. We address this issue by proposing a new disentanglement\nmethod; by splitting nodes that encode nested rules into smaller independent\nnodes, we are able to better preserve the models' performance. Through\nexperiments on binary, multiclass, and multilabel classification tasks\n(including those requiring predicate invention), we demonstrate that our\ndisentanglement method provides compact and interpretable logical\nrepresentations for the neural DNF-based models, with performance closer to\nthat of their pre-translation counterparts. Our code is available at\nhttps://github.com/kittykg/disentangling-ndnf-classification.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u795e\u7ecf\u6790\u53d6\u8303\u5f0f\uff08DNF\uff09\u6a21\u578b\u5728\u7b26\u53f7\u8f6c\u6362\u4e2d\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u51fa\u89e3\u7ea0\u7f20\u65b9\u6cd5\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u795e\u7ecfDNF\u6a21\u578b\u5728\u7b26\u53f7\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u539f\u56e0\u662f\u65e0\u6cd5\u89e3\u5f00\u7f51\u7edc\u6743\u91cd\u4e2d\u8868\u793a\u7684\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u89e3\u7ea0\u7f20\u65b9\u6cd5\uff0c\u5c06\u7f16\u7801\u5d4c\u5957\u89c4\u5219\u7684\u8282\u70b9\u62c6\u5206\u4e3a\u66f4\u5c0f\u7684\u72ec\u7acb\u8282\u70b9\u3002", "result": "\u5728\u4e8c\u5206\u7c7b\u3001\u591a\u5206\u7c7b\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u89e3\u7ea0\u7f20\u65b9\u6cd5\u4e3a\u795e\u7ecfDNF\u6a21\u578b\u63d0\u4f9b\u4e86\u7d27\u51d1\u4e14\u53ef\u89e3\u91ca\u7684\u903b\u8f91\u8868\u793a\uff0c\u6027\u80fd\u66f4\u63a5\u8fd1\u8f6c\u6362\u524d\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u7ea0\u7f20\u65b9\u6cd5\u80fd\u89e3\u51b3\u795e\u7ecfDNF\u6a21\u578b\u5728\u7b26\u53f7\u8f6c\u6362\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2507.09788", "pdf": "https://arxiv.org/pdf/2507.09788", "abs": "https://arxiv.org/abs/2507.09788", "authors": ["Paulo Salem", "Robert Sim", "Christopher Olsen", "Prerit Saxena", "Rafael Barcelos", "Yi Ding"], "title": "TinyTroupe: An LLM-powered Multiagent Persona Simulation Toolkit", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.HC", "I.2.11; I.6.5; I.6.7"], "comment": "9 pages. Preprint to be submitted to peer-review", "summary": "Recent advances in Large Language Models (LLM) have led to a new class of\nautonomous agents, renewing and expanding interest in the area. LLM-powered\nMultiagent Systems (MAS) have thus emerged, both for assistive and simulation\npurposes, yet tools for realistic human behavior simulation -- with its\ndistinctive challenges and opportunities -- remain underdeveloped. Existing MAS\nlibraries and tools lack fine-grained persona specifications, population\nsampling facilities, experimentation support, and integrated validation, among\nother key capabilities, limiting their utility for behavioral studies, social\nsimulation, and related applications. To address these deficiencies, in this\nwork we introduce TinyTroupe, a simulation toolkit enabling detailed persona\ndefinitions (e.g., nationality, age, occupation, personality, beliefs,\nbehaviors) and programmatic control via numerous LLM-driven mechanisms. This\nallows for the concise formulation of behavioral problems of practical\ninterest, either at the individual or group level, and provides effective means\nfor their solution. TinyTroupe's components are presented using representative\nworking examples, such as brainstorming and market research sessions, thereby\nsimultaneously clarifying their purpose and demonstrating their usefulness.\nQuantitative and qualitative evaluations of selected aspects are also provided,\nhighlighting possibilities, limitations, and trade-offs. The approach, though\nrealized as a specific Python implementation, is meant as a novel conceptual\ncontribution, which can be partially or fully incorporated in other contexts.\nThe library is available as open source at\nhttps://github.com/microsoft/tinytroupe.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4eff\u771f\u5de5\u5177TinyTroupe\uff0c\u5b83\u80fd\u5b9a\u4e49\u8be6\u7ec6\u89d2\u8272\u5e76\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u793a\u4f8b\u53ca\u8bc4\u4f30\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5de5\u5177\u5728\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u5173\u952e\u80fd\u529b\uff0c\u9650\u5236\u4e86\u76f8\u5173\u5e94\u7528\u3002", "method": "\u5f15\u5165TinyTroupe\u4eff\u771f\u5de5\u5177\uff0c\u901a\u8fc7\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u673a\u5236\u5b9e\u73b0\u8be6\u7ec6\u89d2\u8272\u5b9a\u4e49\u548c\u7f16\u7a0b\u63a7\u5236\uff0c\u7528\u793a\u4f8b\u5c55\u793a\u7ec4\u4ef6\uff0c\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u3002", "result": "\u5c55\u793a\u4e86TinyTroupe\u5728\u5934\u8111\u98ce\u66b4\u548c\u5e02\u573a\u8c03\u7814\u7b49\u573a\u666f\u7684\u5e94\u7528\uff0c\u7a81\u51fa\u5176\u53ef\u80fd\u6027\u3001\u5c40\u9650\u6027\u548c\u6743\u8861\u3002", "conclusion": "TinyTroupe\u662f\u65b0\u7684\u6982\u5ff5\u8d21\u732e\uff0c\u53ef\u90e8\u5206\u6216\u5168\u90e8\u878d\u5165\u5176\u4ed6\u573a\u666f\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2507.09792", "pdf": "https://arxiv.org/pdf/2507.09792", "abs": "https://arxiv.org/abs/2507.09792", "authors": ["Prashant Govindarajan", "Davide Baldelli", "Jay Pathak", "Quentin Fournier", "Sarath Chandar"], "title": "CADmium: Fine-Tuning Code Language Models for Text-Driven Sequential CAD Design", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": null, "summary": "Computer-aided design (CAD) is the digital construction of 2D and 3D objects,\nand is central to a wide range of engineering and manufacturing applications\nlike automobile and aviation. Despite its importance, CAD modeling remains\nlargely a time-intensive, manual task. Recent works have attempted to automate\nthis process with small transformer-based models and handcrafted CAD sequence\nrepresentations. However, there has been little effort to leverage the\npotential of large language models (LLMs) for sequential CAD design. In this\nwork, we introduce a new large-scale dataset of more than 170k CAD models\nannotated with high-quality, human-like descriptions generated with our\npipeline based on GPT-4.1. Using this dataset, we fine-tune powerful code-LLMs\nto generate CAD sequences represented in a JSON-based format from natural\nlanguage descriptions, demonstrating the viability and effectiveness of this\napproach for text-conditioned CAD generation. Because simple metrics often fail\nto reflect the quality of generated objects, we introduce geometric and\ntopological metrics based on sphericity, mean curvature, and Euler\ncharacteristic to provide richer structural insights. Our experiments and\nablation studies on both synthetic and human-annotated data demonstrate that\nCADmium is able to automate CAD design, drastically speeding up the design of\nnew objects. The dataset, code, and fine-tuned models are available online.", "AI": {"tldr": "\u5f15\u5165\u542b170k+CAD\u6a21\u578b\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u6587\u672c\u9a71\u52a8CAD\u751f\u6210\uff0c\u5f15\u5165\u65b0\u6307\u6807\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u52a0\u901fCAD\u8bbe\u8ba1\uff0c\u6570\u636e\u4ee3\u7801\u6a21\u578b\u5f00\u6e90\u3002", "motivation": "CAD\u5efa\u6a21\u8017\u65f6\u4e14\u4f9d\u8d56\u4eba\u5de5\uff0c\u6b64\u524d\u8f83\u5c11\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u987a\u5e8fCAD\u8bbe\u8ba1\u3002", "method": "\u6784\u5efa\u57fa\u4e8eGPT - 4.1\u7684\u6d41\u6c34\u7ebf\u751f\u6210\u5e26\u9ad8\u8d28\u91cf\u63cf\u8ff0\u7684\u5927\u89c4\u6a21CAD\u6a21\u578b\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210JSON\u683c\u5f0fCAD\u5e8f\u5217\uff0c\u5f15\u5165\u51e0\u4f55\u548c\u62d3\u6251\u6307\u6807\u8bc4\u4f30\u3002", "result": "CADmium\u80fd\u81ea\u52a8\u5316CAD\u8bbe\u8ba1\uff0c\u5927\u5e45\u52a0\u901f\u65b0\u5bf9\u8c61\u8bbe\u8ba1\u3002", "conclusion": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6587\u672c\u9a71\u52a8CAD\u751f\u6210\u7684\u65b9\u6cd5\u53ef\u884c\u6709\u6548\uff0c\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u6a21\u578b\u6709\u52a9\u4e8e\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2507.08821", "pdf": "https://arxiv.org/pdf/2507.08821", "abs": "https://arxiv.org/abs/2507.08821", "authors": ["Pedro D. Alvim", "Hugerles S. Silva", "Ugo S. Dias", "Osamah S. Badarneh", "Felipe A. P. Figueiredo", "Rausley A. A. de Souza"], "title": "LNN-powered Fluid Antenna Multiple Access", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Fluid antenna systems represent an innovative approach in wireless\ncommunication, recently applied in multiple access to optimize the\nsignal-to-interference-plus-noise ratio through port selection. This letter\nframes the port selection problem as a multi-label classification task for the\nfirst time, improving best-port selection with limited port observations. We\naddress this challenge by leveraging liquid neural networks (LNNs) to predict\nthe optimal port under emerging fluid antenna multiple access scenarios\nalongside a more general $\\alpha$-$\\mu$ fading model. We also apply\nhyperparameter optimization to refine LNN architectures for different\nobservation scenarios. Our approach yields lower outage probability values than\nexisting methods.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c06\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u7aef\u53e3\u9009\u62e9\u95ee\u9898\u8f6c\u5316\u4e3a\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\uff0c\u7528\u6db2\u4f53\u795e\u7ecf\u7f51\u7edc\uff08LNN\uff09\u9884\u6d4b\u6700\u4f73\u7aef\u53e3\uff0c\u7ecf\u8d85\u53c2\u6570\u4f18\u5316\u540e\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u6bd4\u73b0\u6709\u65b9\u6cd5\u4e2d\u65ad\u6982\u7387\u66f4\u4f4e\u3002", "motivation": "\u5728\u65b0\u5174\u6d41\u4f53\u5929\u7ebf\u591a\u5740\u573a\u666f\u4e0b\uff0c\u4f18\u5316\u4fe1\u53f7\u5e72\u6270\u566a\u58f0\u6bd4\uff0c\u89e3\u51b3\u6709\u9650\u7aef\u53e3\u89c2\u6d4b\u4e0b\u7684\u6700\u4f73\u7aef\u53e3\u9009\u62e9\u95ee\u9898\u3002", "method": "\u5c06\u7aef\u53e3\u9009\u62e9\u95ee\u9898\u8f6c\u5316\u4e3a\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\uff0c\u5229\u7528LNN\u9884\u6d4b\u6700\u4f73\u7aef\u53e3\uff0c\u91c7\u7528\u8d85\u53c2\u6570\u4f18\u5316LNN\u67b6\u6784\u3002", "result": "\u8be5\u65b9\u6cd5\u7684\u4e2d\u65ad\u6982\u7387\u4f4e\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6d41\u4f53\u5929\u7ebf\u591a\u5740\u573a\u666f\u4e0b\u7684\u7aef\u53e3\u9009\u62e9\u95ee\u9898\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.08831", "pdf": "https://arxiv.org/pdf/2507.08831", "abs": "https://arxiv.org/abs/2507.08831", "authors": ["Josh Qixuan Sun", "Xiaoying Xing", "Huaiyuan Weng", "Chul Min Yeum", "Mark Crowley"], "title": "View Invariant Learning for Vision-Language Navigation in Continuous Environments", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "Under review", "summary": "Vision-Language Navigation in Continuous Environments (VLNCE), where an agent\nfollows instructions and moves freely to reach a destination, is a key research\nproblem in embodied AI. However, most navigation policies are sensitive to\nviewpoint changes, i.e., variations in camera height and viewing angle that\nalter the agent's observation. In this paper, we introduce a generalized\nscenario, V2-VLNCE (VLNCE with Varied Viewpoints), and propose VIL (View\nInvariant Learning), a view-invariant post-training strategy that enhances the\nrobustness of existing navigation policies to changes in camera viewpoint. VIL\nemploys a contrastive learning framework to learn sparse and view-invariant\nfeatures. Additionally, we introduce a teacher-student framework for the\nWaypoint Predictor Module, a core component of most VLNCE baselines, where a\nview-dependent teacher model distills knowledge into a view-invariant student\nmodel. We employ an end-to-end training paradigm to jointly optimize these\ncomponents, thus eliminating the cost for individual module training. Empirical\nresults show that our method outperforms state-of-the-art approaches on\nV2-VLNCE by 8-15% measured on Success Rate for two standard benchmark datasets\nR2R-CE and RxR-CE. Furthermore, we evaluate VIL under the standard VLNCE\nsetting and find that, despite being trained for varied viewpoints, it often\nstill improves performance. On the more challenging RxR-CE dataset, our method\nalso achieved state-of-the-art performance across all metrics when compared to\nother map-free methods. This suggests that adding VIL does not diminish the\nstandard viewpoint performance and can serve as a plug-and-play post-training\nmethod.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faV2 - VLNCE\u573a\u666f\u548cVIL\u7b56\u7565\u63d0\u5347\u5bfc\u822a\u7b56\u7565\u5bf9\u76f8\u673a\u89c6\u89d2\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u591a\u6570\u5bfc\u822a\u7b56\u7565\u5bf9\u89c6\u89d2\u53d8\u5316\u654f\u611f\uff0c\u672c\u6587\u65e8\u5728\u589e\u5f3a\u73b0\u6709\u5bfc\u822a\u7b56\u7565\u5bf9\u76f8\u673a\u89c6\u89d2\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faVIL\u7b56\u7565\uff0c\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5b66\u4e60\u7a00\u758f\u548c\u89c6\u89d2\u4e0d\u53d8\u7279\u5f81\uff0c\u5f15\u5165\u5e08\u751f\u6846\u67b6\u7528\u4e8e\u822a\u70b9\u9884\u6d4b\u5668\u6a21\u5757\uff0c\u91c7\u7528\u7aef\u5230\u7aef\u8bad\u7ec3\u8303\u5f0f\u8054\u5408\u4f18\u5316\u7ec4\u4ef6\u3002", "result": "\u5728V2 - VLNCE\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u6210\u529f\u7387\u9ad88 - 15%\uff0c\u5728\u6807\u51c6VLNCE\u8bbe\u7f6e\u4e0b\u4e5f\u5e38\u63d0\u5347\u6027\u80fd\uff0c\u5728RxR - CE\u6570\u636e\u96c6\u4e0a\u5404\u9879\u6307\u6807\u8fbe\u6700\u4f18\u3002", "conclusion": "VIL\u4e0d\u964d\u4f4e\u6807\u51c6\u89c6\u89d2\u6027\u80fd\uff0c\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2507.08849", "pdf": "https://arxiv.org/pdf/2507.08849", "abs": "https://arxiv.org/abs/2507.08849", "authors": ["Emilio Carrizosa", "Martina Fischetti", "Roshell Haaker", "Juan Miguel Morales"], "title": "Counterfactual optimization for fault prevention in complex wind energy systems", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "comment": null, "summary": "Machine Learning models are increasingly used in businesses to detect faults\nand anomalies in complex systems. In this work, we take this approach a step\nfurther: beyond merely detecting anomalies, we aim to identify the optimal\ncontrol strategy that restores the system to a safe state with minimal\ndisruption. We frame this challenge as a counterfactual problem: given a\nMachine Learning model that classifies system states as either good or\nanomalous, our goal is to determine the minimal adjustment to the system's\ncontrol variables (i.e., its current status) that is necessary to return it to\nthe good state. To achieve this, we leverage a mathematical model that finds\nthe optimal counterfactual solution while respecting system specific\nconstraints. Notably, most counterfactual analysis in the literature focuses on\nindividual cases where a person seeks to alter their status relative to a\ndecision made by a classifier, such as for loan approval or medical diagnosis.\nOur work addresses a fundamentally different challenge: optimizing\ncounterfactuals for a complex energy system, specifically an offshore wind\nturbine oil type transformer. This application not only advances counterfactual\noptimization in a new domain but also opens avenues for broader research in\nthis area. Our tests on real world data provided by our industrial partner show\nthat our methodology easily adapts to user preferences and brings savings in\nthe order of 3 million euros per year in a typical farm.", "AI": {"tldr": "\u672c\u6587\u5c06\u673a\u5668\u5b66\u4e60\u7528\u4e8e\u590d\u6742\u7cfb\u7edf\uff0c\u4e0d\u4ec5\u68c0\u6d4b\u5f02\u5e38\uff0c\u8fd8\u786e\u5b9a\u6700\u4f18\u63a7\u5236\u7b56\u7565\u4f7f\u7cfb\u7edf\u6062\u590d\u5b89\u5168\uff0c\u4ee5\u6d77\u4e0a\u98ce\u529b\u6da1\u8f6e\u673a\u6cb9\u5f0f\u53d8\u538b\u5668\u4e3a\u4f8b\uff0c\u65b9\u6cd5\u80fd\u9002\u5e94\u504f\u597d\u4e14\u6bcf\u5e74\u8282\u7701\u7ea6300\u4e07\u6b27\u5143\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u4ec5\u68c0\u6d4b\u5f02\u5e38\uff0c\u672c\u6587\u60f3\u8fdb\u4e00\u6b65\u786e\u5b9a\u4f7f\u7cfb\u7edf\u6062\u590d\u5b89\u5168\u72b6\u6001\u7684\u6700\u4f18\u63a7\u5236\u7b56\u7565\u3002", "method": "\u5c06\u95ee\u9898\u6784\u5efa\u4e3a\u53cd\u4e8b\u5b9e\u95ee\u9898\uff0c\u5229\u7528\u6570\u5b66\u6a21\u578b\u5728\u6ee1\u8db3\u7cfb\u7edf\u7279\u5b9a\u7ea6\u675f\u4e0b\u627e\u5230\u6700\u4f18\u53cd\u4e8b\u5b9e\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u5de5\u4e1a\u4f19\u4f34\u63d0\u4f9b\u7684\u771f\u5b9e\u6570\u636e\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u80fd\u9002\u5e94\u4f7f\u7528\u8005\u504f\u597d\uff0c\u5728\u5178\u578b\u98ce\u7535\u573a\u6bcf\u5e74\u8282\u7701\u7ea6300\u4e07\u6b27\u5143\u3002", "conclusion": "\u672c\u5de5\u4f5c\u63a8\u52a8\u4e86\u53cd\u4e8b\u5b9e\u4f18\u5316\u5728\u65b0\u9886\u57df\u7684\u5e94\u7528\uff0c\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2507.08854", "pdf": "https://arxiv.org/pdf/2507.08854", "abs": "https://arxiv.org/abs/2507.08854", "authors": ["Qingsong Yang", "Binglan Wu", "Xuwei Liu", "Bo Chen", "Wei Li", "Gen Long", "Xin Chen", "Mingjun Xiao"], "title": "DiffNMR: Diffusion Models for Nuclear Magnetic Resonance Spectra Elucidation", "categories": ["physics.chem-ph", "cs.LG"], "comment": null, "summary": "Nuclear Magnetic Resonance (NMR) spectroscopy is a central characterization\nmethod for molecular structure elucidation, yet interpreting NMR spectra to\ndeduce molecular structures remains challenging due to the complexity of\nspectral data and the vastness of the chemical space. In this work, we\nintroduce DiffNMR, a novel end-to-end framework that leverages a conditional\ndiscrete diffusion model for de novo molecular structure elucidation from NMR\nspectra. DiffNMR refines molecular graphs iteratively through a diffusion-based\ngenerative process, ensuring global consistency and mitigating error\naccumulation inherent in autoregressive methods. The framework integrates a\ntwo-stage pretraining strategy that aligns spectral and molecular\nrepresentations via diffusion autoencoder (Diff-AE) and contrastive learning,\nthe incorporation of retrieval initialization and similarity filtering during\ninference, and a specialized NMR encoder with radial basis function (RBF)\nencoding for chemical shifts, preserving continuity and chemical correlation.\nExperimental results demonstrate that DiffNMR achieves competitive performance\nfor NMR-based structure elucidation, offering an efficient and robust solution\nfor automated molecular analysis.", "AI": {"tldr": "\u63d0\u51faDiffNMR\u6846\u67b6\u7528\u4e8e\u4ece\u6838\u78c1\u5171\u632f\u8c31\u56fe\u89e3\u6790\u5206\u5b50\u7ed3\u6784\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u7ade\u4e89\u529b\u8868\u73b0\u3002", "motivation": "\u6838\u78c1\u5171\u632f\u5149\u8c31\u89e3\u6790\u5206\u5b50\u7ed3\u6784\u56e0\u8c31\u56fe\u6570\u636e\u590d\u6742\u548c\u5316\u5b66\u7a7a\u95f4\u5927\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165DiffNMR\u6846\u67b6\uff0c\u5229\u7528\u6761\u4ef6\u79bb\u6563\u6269\u6563\u6a21\u578b\uff0c\u8fed\u4ee3\u4f18\u5316\u5206\u5b50\u56fe\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u63a8\u7406\u65f6\u7ed3\u5408\u68c0\u7d22\u521d\u59cb\u5316\u548c\u76f8\u4f3c\u5ea6\u8fc7\u6ee4\uff0c\u4f7f\u7528\u5e26\u5f84\u5411\u57fa\u51fd\u6570\u7f16\u7801\u7684NMR\u7f16\u7801\u5668\u3002", "result": "DiffNMR\u5728\u57fa\u4e8eNMR\u7684\u7ed3\u6784\u89e3\u6790\u4e2d\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "DiffNMR\u4e3a\u81ea\u52a8\u5206\u5b50\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08855", "pdf": "https://arxiv.org/pdf/2507.08855", "abs": "https://arxiv.org/abs/2507.08855", "authors": ["Yang Ming", "Jiang Shi Zhong", "Zhou Su Juan"], "title": "Multi-omic Prognosis of Alzheimer's Disease with Asymmetric Cross-Modal Cross-Attention Network", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Alzheimer's Disease (AD) is an irreversible neurodegenerative disease\ncharacterized by progressive cognitive decline as its main symptom. In the\nresearch field of deep learning-assisted diagnosis of AD, traditional\nconvolutional neural networks and simple feature concatenation methods fail to\neffectively utilize the complementary information between multimodal data, and\nthe simple feature concatenation approach is prone to cause the loss of key\ninformation during the process of modal fusion. In recent years, the\ndevelopment of deep learning technology has brought new possibilities for\nsolving the problem of how to effectively fuse multimodal features. This paper\nproposes a novel deep learning algorithm framework to assist medical\nprofessionals in AD diagnosis. By fusing medical multi-view information such as\nbrain fluorodeoxyglucose positron emission tomography (PET), magnetic resonance\nimaging (MRI), genetic data, and clinical data, it can accurately detect the\npresence of AD, Mild Cognitive Impairment (MCI), and Cognitively Normal (CN).\nThe innovation of the algorithm lies in the use of an asymmetric cross-modal\ncross-attention mechanism, which can effectively capture the key information\nfeatures of the interactions between different data modal features. This paper\ncompares the asymmetric cross-modal cross-attention mechanism with the\ntraditional algorithm frameworks of unimodal and multimodal deep learning\nmodels for AD diagnosis, and evaluates the importance of the asymmetric\ncross-modal cross-attention mechanism. The algorithm model achieves an accuracy\nof 94.88% on the test set.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u6846\u67b6\u8f85\u52a9AD\u8bca\u65ad\uff0c\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u7528\u975e\u5bf9\u79f0\u8de8\u6a21\u6001\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6d4b\u8bd5\u96c6\u51c6\u786e\u7387\u8fbe94.88%\u3002", "motivation": "\u4f20\u7edf\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u7b80\u5355\u7279\u5f81\u62fc\u63a5\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u4e92\u8865\u4fe1\u606f\uff0c\u4e14\u6613\u9020\u6210\u5173\u952e\u4fe1\u606f\u4e22\u5931\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65b0\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u6846\u67b6\uff0c\u878d\u5408\u8111PET\u3001MRI\u3001\u9057\u4f20\u6570\u636e\u548c\u4e34\u5e8a\u6570\u636e\u7b49\u591a\u89c6\u56fe\u4fe1\u606f\uff0c\u4f7f\u7528\u975e\u5bf9\u79f0\u8de8\u6a21\u6001\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u7b97\u6cd5\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe\u523094.88%\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u6846\u67b6\u80fd\u51c6\u786e\u68c0\u6d4bAD\u3001MCI\u548cCN\uff0c\u975e\u5bf9\u79f0\u8de8\u6a21\u6001\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2507.09836", "pdf": "https://arxiv.org/pdf/2507.09836", "abs": "https://arxiv.org/abs/2507.09836", "authors": ["Vindula Jayawardana", "Sirui Li", "Yashar Farid", "Cathy Wu"], "title": "Multi-residual Mixture of Experts Learning for Cooperative Control in Multi-vehicle Systems", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA", "cs.SY", "eess.SY"], "comment": null, "summary": "Autonomous vehicles (AVs) are becoming increasingly popular, with their\napplications now extending beyond just a mode of transportation to serving as\nmobile actuators of a traffic flow to control flow dynamics. This contrasts\nwith traditional fixed-location actuators, such as traffic signals, and is\nreferred to as Lagrangian traffic control. However, designing effective\nLagrangian traffic control policies for AVs that generalize across traffic\nscenarios introduces a major challenge. Real-world traffic environments are\nhighly diverse, and developing policies that perform robustly across such\ndiverse traffic scenarios is challenging. It is further compounded by the joint\ncomplexity of the multi-agent nature of traffic systems, mixed motives among\nparticipants, and conflicting optimization objectives subject to strict\nphysical and external constraints. To address these challenges, we introduce\nMulti-Residual Mixture of Expert Learning (MRMEL), a novel framework for\nLagrangian traffic control that augments a given suboptimal nominal policy with\na learned residual while explicitly accounting for the structure of the traffic\nscenario space. In particular, taking inspiration from residual reinforcement\nlearning, MRMEL augments a suboptimal nominal AV control policy by learning a\nresidual correction, but at the same time dynamically selects the most suitable\nnominal policy from a pool of nominal policies conditioned on the traffic\nscenarios and modeled as a mixture of experts. We validate MRMEL using a case\nstudy in cooperative eco-driving at signalized intersections in Atlanta, Dallas\nFort Worth, and Salt Lake City, with real-world data-driven traffic scenarios.\nThe results show that MRMEL consistently yields superior performance-achieving\nan additional 4%-9% reduction in aggregate vehicle emissions relative to the\nstrongest baseline in each setting.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u4e8e\u62c9\u683c\u6717\u65e5\u4ea4\u901a\u63a7\u5236\u7684\u65b0\u6846\u67b6MRMEL\uff0c\u5728\u591a\u5730\u6848\u4f8b\u7814\u7a76\u4e2d\u9a8c\u8bc1\u5176\u80fd\u51cf\u5c11\u8f66\u8f86\u6392\u653e\u3002", "motivation": "\u8bbe\u8ba1\u80fd\u5728\u4e0d\u540c\u4ea4\u901a\u573a\u666f\u901a\u7528\u7684\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u62c9\u683c\u6717\u65e5\u4ea4\u901a\u63a7\u5236\u7b56\u7565\u9762\u4e34\u6311\u6218\uff0c\u73b0\u5b9e\u4ea4\u901a\u73af\u5883\u591a\u6837\uff0c\u4ea4\u901a\u7cfb\u7edf\u590d\u6742\u3002", "method": "\u5f15\u5165Multi - Residual Mixture of Expert Learning (MRMEL)\u6846\u67b6\uff0c\u501f\u9274\u6b8b\u5dee\u5f3a\u5316\u5b66\u4e60\uff0c\u5b66\u4e60\u6b8b\u5dee\u4fee\u6b63\uff0c\u52a8\u6001\u9009\u62e9\u5408\u9002\u7684\u6807\u79f0\u7b56\u7565\u3002", "result": "\u5728\u4e9a\u7279\u5170\u5927\u3001\u8fbe\u62c9\u65af\u6c83\u601d\u5821\u548c\u76d0\u6e56\u57ce\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cMRMEL\u76f8\u6bd4\u6700\u5f3a\u57fa\u7ebf\u8bbe\u7f6e\u80fd\u989d\u5916\u51cf\u5c114% - 9%\u7684\u8f66\u8f86\u603b\u6392\u653e\u91cf\u3002", "conclusion": "MRMEL\u5728\u62c9\u683c\u6717\u65e5\u4ea4\u901a\u63a7\u5236\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u8f66\u8f86\u6392\u653e\u3002"}}
{"id": "2507.09860", "pdf": "https://arxiv.org/pdf/2507.09860", "abs": "https://arxiv.org/abs/2507.09860", "authors": ["Nguyen Van Duc", "Bui Duc Manh", "Quang-Trung Luu", "Dinh Thai Hoang", "Van-Linh Nguyen", "Diep N. Nguyen"], "title": "Secure and Efficient UAV-Based Face Detection via Homomorphic Encryption and Edge Computing", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper aims to propose a novel machine learning (ML) approach\nincorporating Homomorphic Encryption (HE) to address privacy limitations in\nUnmanned Aerial Vehicles (UAV)-based face detection. Due to challenges related\nto distance, altitude, and face orientation, high-resolution imagery and\nsophisticated neural networks enable accurate face recognition in dynamic\nenvironments. However, privacy concerns arise from the extensive surveillance\ncapabilities of UAVs. To resolve this issue, we propose a novel framework that\nintegrates HE with advanced neural networks to secure facial data throughout\nthe inference phase. This method ensures that facial data remains secure with\nminimal impact on detection accuracy. Specifically, the proposed system\nleverages the Cheon-Kim-Kim-Song (CKKS) scheme to perform computations directly\non encrypted data, optimizing computational efficiency and security.\nFurthermore, we develop an effective data encoding method specifically designed\nto preprocess the raw facial data into CKKS form in a\nSingle-Instruction-Multiple-Data (SIMD) manner. Building on this, we design a\nsecure inference algorithm to compute on ciphertext without needing decryption.\nThis approach not only protects data privacy during the processing of facial\ndata but also enhances the efficiency of UAV-based face detection systems.\nExperimental results demonstrate that our method effectively balances privacy\nprotection and detection performance, making it a viable solution for UAV-based\nsecure face detection. Significantly, our approach (while maintaining data\nconfidentially with HE encryption) can still achieve an accuracy of less than\n1% compared to the benchmark without using encryption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u65e0\u4eba\u673a\u9762\u90e8\u68c0\u6d4b\u7684\u9690\u79c1\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u65e0\u4eba\u673a\u9762\u90e8\u68c0\u6d4b\u5b58\u5728\u9690\u79c1\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u8fdb\u884c\u9ad8\u7cbe\u5ea6\u9762\u90e8\u8bc6\u522b\u65f6\uff0c\u56e0\u5e7f\u6cdb\u7684\u76d1\u63a7\u80fd\u529b\u5f15\u53d1\u9690\u79c1\u62c5\u5fe7\u3002", "method": "\u63d0\u51fa\u5c06HE\u4e0e\u5148\u8fdb\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u7684\u6846\u67b6\uff0c\u5229\u7528CKKS\u65b9\u6848\u5bf9\u52a0\u5bc6\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\uff0c\u5f00\u53d1\u6570\u636e\u7f16\u7801\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5b89\u5168\u63a8\u7406\u7b97\u6cd5\u3002", "result": "\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u548c\u68c0\u6d4b\u6027\u80fd\uff0c\u4e0e\u672a\u52a0\u5bc6\u57fa\u51c6\u76f8\u6bd4\uff0c\u51c6\u786e\u7387\u5dee\u8ddd\u5c0f\u4e8e1%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u65e0\u4eba\u673a\u5b89\u5168\u9762\u90e8\u68c0\u6d4b\u7684\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.08908", "pdf": "https://arxiv.org/pdf/2507.08908", "abs": "https://arxiv.org/abs/2507.08908", "authors": ["M. Z. Naser"], "title": "The Engineer's Dilemma: A Review of Establishing a Legal Framework for Integrating Machine Learning in Construction by Navigating Precedents and Industry Expectations", "categories": ["cs.CY", "cs.ET", "cs.LG"], "comment": null, "summary": "Despite the widespread interest in machine learning (ML), the engineering\nindustry has not yet fully adopted ML-based methods, which has left engineers\nand stakeholders uncertain about the legal and regulatory frameworks that\ngovern their decisions. This gap remains unaddressed as an engineer's\ndecision-making process, typically governed by professional ethics and\npractical guidelines, now intersects with complex algorithmic outputs. To\nbridge this gap, this paper explores how engineers can navigate legal\nprinciples and legislative justifications that support and/or contest the\ndeployment of ML technologies. Drawing on recent precedents and experiences\ngained from other fields, this paper argues that analogical reasoning can\nprovide a basis for embedding ML within existing engineering codes while\nmaintaining professional accountability and meeting safety requirements. In\nexploring these issues, the discussion focuses on established liability\ndoctrines, such as negligence and product liability, and highlights how courts\nhave evaluated the use of predictive models. We further analyze how legislative\nbodies and standard-setting organizations can furnish explicit guidance\nequivalent to prior endorsements of emergent technologies. This exploration\nstresses the vitality of understanding the interplay between technical\njustifications and legal precedents for shaping an informed stance on ML's\nlegitimacy in engineering practice. Finally, our analysis catalyzes a legal\nframework for integrating ML through which stakeholders can critically assess\nthe responsibilities, liabilities, and benefits inherent in ML-driven\nengineering solutions.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u5de5\u7a0b\u884c\u4e1a\u672a\u5145\u5206\u91c7\u7528ML\u65b9\u6cd5\u4e0b\uff0c\u5de5\u7a0b\u5e08\u5982\u4f55\u5e94\u5bf9\u76f8\u5173\u6cd5\u5f8b\u95ee\u9898\uff0c\u63d0\u51fa\u7c7b\u6bd4\u63a8\u7406\u53ef\u5d4c\u5165ML\uff0c\u8fd8\u5206\u6790\u7acb\u6cd5\u673a\u6784\u7b49\u4f5c\u7528\u5e76\u6784\u5efa\u6cd5\u5f8b\u6846\u67b6\u3002", "motivation": "\u5de5\u7a0b\u884c\u4e1a\u672a\u5145\u5206\u91c7\u7528ML\u65b9\u6cd5\uff0c\u5de5\u7a0b\u5e08\u548c\u5229\u76ca\u76f8\u5173\u8005\u5bf9\u76f8\u5173\u6cd5\u5f8b\u76d1\u7ba1\u6846\u67b6\u4e0d\u786e\u5b9a\uff0c\u9700\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u501f\u9274\u5176\u4ed6\u9886\u57df\u5148\u4f8b\u548c\u7ecf\u9a8c\uff0c\u8fd0\u7528\u7c7b\u6bd4\u63a8\u7406\uff0c\u5173\u6ce8\u65e2\u5b9a\u8d23\u4efb\u539f\u5219\u548c\u6cd5\u9662\u5bf9\u9884\u6d4b\u6a21\u578b\u7684\u8bc4\u4f30\u3002", "result": "\u5f3a\u8c03\u7406\u89e3\u6280\u672f\u7406\u7531\u548c\u6cd5\u5f8b\u5148\u4f8b\u76f8\u4e92\u4f5c\u7528\u7684\u91cd\u8981\u6027\uff0c\u50ac\u5316\u4e86\u6574\u5408ML\u7684\u6cd5\u5f8b\u6846\u67b6\u3002", "conclusion": "\u7c7b\u6bd4\u63a8\u7406\u53ef\u8ba9ML\u5d4c\u5165\u73b0\u6709\u5de5\u7a0b\u89c4\u8303\uff0c\u540c\u65f6\u9700\u6784\u5efa\u6cd5\u5f8b\u6846\u67b6\u8ba9\u5229\u76ca\u76f8\u5173\u8005\u8bc4\u4f30ML\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\u7684\u8d23\u4efb\u3001\u98ce\u9669\u548c\u76ca\u5904\u3002"}}
{"id": "2507.09861", "pdf": "https://arxiv.org/pdf/2507.09861", "abs": "https://arxiv.org/abs/2507.09861", "authors": ["Yihao Ding", "Siwen Luo", "Yue Dai", "Yanbei Jiang", "Zechuan Li", "Geoffrey Martin", "Yifan Peng"], "title": "A Survey on MLLM-based Visually Rich Document Understanding: Methods, Challenges, and Emerging Trends", "categories": ["cs.CV", "cs.AI"], "comment": "Work in progress", "summary": "Visually-Rich Document Understanding (VRDU) has emerged as a critical field,\ndriven by the need to automatically process documents containing complex\nvisual, textual, and layout information. Recently, Multimodal Large Language\nModels (MLLMs) have shown remarkable potential in this domain, leveraging both\nOptical Character Recognition (OCR)-dependent and OCR-free frameworks to\nextract and interpret information in document images. This survey reviews\nrecent advancements in MLLM-based VRDU, highlighting three core components: (1)\nmethods for encoding and fusing textual, visual, and layout features; (2)\ntraining paradigms, including pretraining strategies, instruction-response\ntuning, and the trainability of different model modules; and (3) datasets\nutilized for pretraining, instruction-tuning, and supervised fine-tuning.\nFinally, we discuss the challenges and opportunities in this evolving field and\npropose future directions to advance the efficiency, generalizability, and\nrobustness of VRDU systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u57fa\u4e8eMLLM\u7684VRDU\u6700\u65b0\u8fdb\u5c55\uff0c\u4ecb\u7ecd\u6838\u5fc3\u7ec4\u4ef6\uff0c\u8ba8\u8bba\u6311\u6218\u673a\u9047\u5e76\u63d0\u51fa\u672a\u6765\u65b9\u5411\u3002", "motivation": "VRDU\u9886\u57df\u9700\u81ea\u52a8\u5904\u7406\u542b\u590d\u6742\u4fe1\u606f\u7684\u6587\u6863\uff0cMLLMs\u5728\u8be5\u9886\u57df\u6709\u6f5c\u529b\uff0c\u6545\u8fdb\u884c\u76f8\u5173\u7efc\u8ff0\u3002", "method": "\u5bf9\u57fa\u4e8eMLLM\u7684VRDU\u76f8\u5173\u7814\u7a76\u8fdb\u884c\u7efc\u8ff0\uff0c\u5206\u6790\u7f16\u7801\u878d\u5408\u7279\u5f81\u65b9\u6cd5\u3001\u8bad\u7ec3\u8303\u5f0f\u548c\u4f7f\u7528\u7684\u6570\u636e\u96c6\u3002", "result": "\u68b3\u7406\u51fa\u57fa\u4e8eMLLM\u7684VRDU\u7684\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u3002", "conclusion": "\u63a2\u8ba8\u4e86\u8be5\u9886\u57df\u6311\u6218\u673a\u9047\uff0c\u63d0\u51fa\u63d0\u5347VRDU\u7cfb\u7edf\u6548\u7387\u3001\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u7684\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2507.09864", "pdf": "https://arxiv.org/pdf/2507.09864", "abs": "https://arxiv.org/abs/2507.09864", "authors": ["Hossein Nejatbakhsh Esfahani", "Javad Mohammadpour Velni"], "title": "Intersection of Reinforcement Learning and Bayesian Optimization for Intelligent Control of Industrial Processes: A Safe MPC-based DPG using Multi-Objective BO", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "math.OC"], "comment": null, "summary": "Model Predictive Control (MPC)-based Reinforcement Learning (RL) offers a\nstructured and interpretable alternative to Deep Neural Network (DNN)-based RL\nmethods, with lower computational complexity and greater transparency. However,\nstandard MPC-RL approaches often suffer from slow convergence, suboptimal\npolicy learning due to limited parameterization, and safety issues during\nonline adaptation. To address these challenges, we propose a novel framework\nthat integrates MPC-RL with Multi-Objective Bayesian Optimization (MOBO). The\nproposed MPC-RL-MOBO utilizes noisy evaluations of the RL stage cost and its\ngradient, estimated via a Compatible Deterministic Policy Gradient (CDPG)\napproach, and incorporates them into a MOBO algorithm using the Expected\nHypervolume Improvement (EHVI) acquisition function. This fusion enables\nefficient and safe tuning of the MPC parameters to achieve improved closed-loop\nperformance, even under model imperfections. A numerical example demonstrates\nthe effectiveness of the proposed approach in achieving sample-efficient,\nstable, and high-performance learning for control systems.", "AI": {"tldr": "\u63d0\u51faMPC - RL\u4e0eMOBO\u96c6\u6210\u6846\u67b6\uff0c\u89e3\u51b3\u6807\u51c6MPC - RL\u95ee\u9898\uff0c\u6570\u503c\u793a\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6807\u51c6MPC - RL\u65b9\u6cd5\u5b58\u5728\u6536\u655b\u6162\u3001\u7b56\u7565\u5b66\u4e60\u6b20\u4f73\u548c\u5b89\u5168\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5c06MPC - RL\u4e0eMOBO\u96c6\u6210\uff0c\u5229\u7528CDPG\u4f30\u8ba1\u6210\u672c\u53ca\u68af\u5ea6\uff0c\u7ed3\u5408EHVI\u83b7\u53d6\u51fd\u6570\u3002", "result": "\u5b9e\u73b0\u4e86\u6837\u672c\u9ad8\u6548\u3001\u7a33\u5b9a\u548c\u9ad8\u6027\u80fd\u7684\u63a7\u5236\u7cfb\u7edf\u5b66\u4e60\u3002", "conclusion": "\u6240\u63d0MPC - RL - MOBO\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u6807\u51c6MPC - RL\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u95ed\u73af\u6027\u80fd\u3002"}}
{"id": "2507.08979", "pdf": "https://arxiv.org/pdf/2507.08979", "abs": "https://arxiv.org/abs/2507.08979", "authors": ["Mahdiyar Molahasani", "Azadeh Motamedi", "Michael Greenspan", "Il-Min Kim", "Ali Etemad"], "title": "PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided Embedding Projection", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "We introduce Projection-based Reduction of Implicit Spurious bias in\nvision-language Models (PRISM), a new data-free and task-agnostic solution for\nbias mitigation in VLMs like CLIP. VLMs often inherit and amplify biases in\ntheir training data, leading to skewed predictions. PRISM is designed to debias\nVLMs without relying on predefined bias categories or additional external data.\nIt operates in two stages: first, an LLM is prompted with simple class prompts\nto generate scene descriptions that contain spurious correlations. Next, PRISM\nuses our novel contrastive-style debiasing loss to learn a projection that maps\nthe embeddings onto a latent space that minimizes spurious correlations while\npreserving the alignment between image and text embeddings.Extensive\nexperiments demonstrate that PRISM outperforms current debiasing methods on the\ncommonly used Waterbirds and CelebA datasets We make our code public at:\nhttps://github.com/MahdiyarMM/PRISM.", "AI": {"tldr": "\u63d0\u51faPRISM\u65b9\u6cd5\u4e3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53bb\u504f\uff0c\u4e24\u9636\u6bb5\u64cd\u4f5c\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u516c\u5f00\u4ee3\u7801\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5e38\u7ee7\u627f\u548c\u653e\u5927\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u504f\u5dee\uff0c\u5bfc\u81f4\u9884\u6d4b\u7ed3\u679c\u6709\u504f\u5dee\uff0c\u9700\u8981\u53bb\u504f\u3002", "method": "\u5148\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u6839\u636e\u7b80\u5355\u7c7b\u522b\u63d0\u793a\u751f\u6210\u5305\u542b\u865a\u5047\u5173\u8054\u7684\u573a\u666f\u63cf\u8ff0\uff0c\u518d\u7528\u5bf9\u6bd4\u5f0f\u53bb\u504f\u635f\u5931\u5b66\u4e60\u6295\u5f71\uff0c\u5c06\u5d4c\u5165\u6620\u5c04\u5230\u6f5c\u5728\u7a7a\u95f4\u4ee5\u51cf\u5c11\u865a\u5047\u5173\u8054\u5e76\u4fdd\u7559\u56fe\u50cf\u548c\u6587\u672c\u5d4c\u5165\u7684\u5bf9\u9f50\u3002", "result": "\u5728Waterbirds\u548cCelebA\u6570\u636e\u96c6\u4e0a\uff0cPRISM\u4f18\u4e8e\u5f53\u524d\u53bb\u504f\u65b9\u6cd5\u3002", "conclusion": "PRISM\u662f\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u65e0\u5173\u3001\u4efb\u52a1\u65e0\u5173\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53bb\u504f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.09875", "pdf": "https://arxiv.org/pdf/2507.09875", "abs": "https://arxiv.org/abs/2507.09875", "authors": ["Qinyuan Ye", "Robin Jia", "Xiang Ren"], "title": "Function Induction and Task Generalization: An Interpretability Study with Off-by-One Addition", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code: https://github.com/INK-USC/function-induction", "summary": "Large language models demonstrate the intriguing ability to perform unseen\ntasks via in-context learning. However, it remains unclear what mechanisms\ninside the model drive such task-level generalization. In this work, we\napproach this question through the lens of off-by-one addition (i.e., 1+1=3,\n2+2=5, 3+3=?), a two-step, counterfactual task with an unexpected +1 function\nas a second step. Leveraging circuit-style interpretability techniques such as\npath patching, we analyze the models' internal computations behind their\nnotable performance and present three key findings. First, we uncover a\nfunction induction mechanism that explains the model's generalization from\nstandard addition to off-by-one addition. This mechanism resembles the\nstructure of the induction head mechanism found in prior work and elevates it\nto a higher level of abstraction. Second, we show that the induction of the +1\nfunction is governed by multiple attention heads in parallel, each of which\nemits a distinct piece of the +1 function. Finally, we find that this function\ninduction mechanism is reused in a broader range of tasks, including synthetic\ntasks such as shifted multiple-choice QA and algorithmic tasks such as base-8\naddition. Overall, our findings offer deeper insights into how reusable and\ncomposable structures within language models enable task-level generalization.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u975e\u6807\u51c6\u52a0\u6cd5\u4efb\u52a1\uff0c\u5229\u7528\u7535\u8def\u5f0f\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u5185\u5728\u673a\u5236\uff0c\u6709\u4e09\u9879\u5173\u952e\u53d1\u73b0\u5e76\u63ed\u793a\u6a21\u578b\u4efb\u52a1\u7ea7\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5b66\u4e60\u4efb\u52a1\u7ea7\u6cdb\u5316\u7684\u5185\u5728\u673a\u5236\u3002", "method": "\u4ee5\u975e\u6807\u51c6\u52a0\u6cd5\u4e3a\u4efb\u52a1\uff0c\u5229\u7528\u8def\u5f84\u4fee\u8865\u7b49\u7535\u8def\u5f0f\u53ef\u89e3\u91ca\u6027\u6280\u672f\u5206\u6790\u6a21\u578b\u5185\u90e8\u8ba1\u7b97\u3002", "result": "\u53d1\u73b0\u51fd\u6570\u5f52\u7eb3\u673a\u5236\uff0c\u89e3\u91ca\u6a21\u578b\u4ece\u6807\u51c6\u52a0\u6cd5\u5230\u975e\u6807\u51c6\u52a0\u6cd5\u7684\u6cdb\u5316\uff1b+1\u51fd\u6570\u5f52\u7eb3\u7531\u591a\u4e2a\u6ce8\u610f\u529b\u5934\u5e76\u884c\u63a7\u5236\uff1b\u8be5\u51fd\u6570\u5f52\u7eb3\u673a\u5236\u53ef\u7528\u4e8e\u66f4\u591a\u4efb\u52a1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u8bed\u8a00\u6a21\u578b\u4e2d\u53ef\u590d\u7528\u548c\u53ef\u7ec4\u5408\u7ed3\u6784\u5982\u4f55\u5b9e\u73b0\u4efb\u52a1\u7ea7\u6cdb\u5316\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.08982", "pdf": "https://arxiv.org/pdf/2507.08982", "abs": "https://arxiv.org/abs/2507.08982", "authors": ["Hanene F. Z. Brachemi Meftah", "Wassim Hamidouche", "Sid Ahmed Fezza", "Olivier D\u00e9forges"], "title": "VIP: Visual Information Protection through Adversarial Attacks on Vision-Language Models", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": null, "summary": "Recent years have witnessed remarkable progress in developing Vision-Language\nModels (VLMs) capable of processing both textual and visual inputs. These\nmodels have demonstrated impressive performance, leading to their widespread\nadoption in various applications. However, this widespread raises serious\nconcerns regarding user privacy, particularly when models inadvertently process\nor expose private visual information. In this work, we frame the preservation\nof privacy in VLMs as an adversarial attack problem. We propose a novel attack\nstrategy that selectively conceals information within designated Region Of\nInterests (ROIs) in an image, effectively preventing VLMs from accessing\nsensitive content while preserving the semantic integrity of the remaining\nimage. Unlike conventional adversarial attacks that often disrupt the entire\nimage, our method maintains high coherence in unmasked areas. Experimental\nresults across three state-of-the-art VLMs namely LLaVA, Instruct-BLIP, and\nBLIP2-T5 demonstrate up to 98% reduction in detecting targeted ROIs, while\nmaintaining global image semantics intact, as confirmed by high similarity\nscores between clean and adversarial outputs. We believe that this work\ncontributes to a more privacy conscious use of multimodal models and offers a\npractical tool for further research, with the source code publicly available\nat: https://github.com/hbrachemi/Vlm_defense-attack.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u653b\u51fb\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u5927\u5e45\u964d\u4f4e\u76ee\u6807\u533a\u57df\u68c0\u6d4b\u7387\u5e76\u4fdd\u6301\u56fe\u50cf\u8bed\u4e49\u5b8c\u6574\u3002", "motivation": "VLMs\u5e7f\u6cdb\u5e94\u7528\u5f15\u53d1\u7528\u6237\u9690\u79c1\u62c5\u5fe7\uff0c\u9700\u89e3\u51b3\u6a21\u578b\u5904\u7406\u6216\u66b4\u9732\u79c1\u4eba\u89c6\u89c9\u4fe1\u606f\u95ee\u9898\u3002", "method": "\u5c06VLMs\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u8f6c\u5316\u4e3a\u5bf9\u6297\u653b\u51fb\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u653b\u51fb\u7b56\u7565\uff0c\u9009\u62e9\u6027\u9690\u85cf\u56fe\u50cf\u6307\u5b9a\u611f\u5174\u8da3\u533a\u57df\uff08ROIs\uff09\u4fe1\u606f\u3002", "result": "\u5728LLaVA\u3001Instruct - BLIP\u548cBLIP2 - T5\u4e09\u4e2a\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0c\u76ee\u6807ROIs\u68c0\u6d4b\u7387\u6700\u591a\u964d\u4f4e98%\uff0c\u4e14\u4fdd\u6301\u5168\u5c40\u56fe\u50cf\u8bed\u4e49\u5b8c\u6574\u3002", "conclusion": "\u672c\u5de5\u4f5c\u6709\u52a9\u4e8e\u591a\u6a21\u6001\u6a21\u578b\u66f4\u6ce8\u91cd\u9690\u79c1\u4fdd\u62a4\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.09876", "pdf": "https://arxiv.org/pdf/2507.09876", "abs": "https://arxiv.org/abs/2507.09876", "authors": ["Yongheng Zhang", "Xu Liu", "Ruihan Tao", "Qiguang Chen", "Hao Fei", "Wanxiang Che", "Libo Qin"], "title": "ViTCoT: Video-Text Interleaved Chain-of-Thought for Boosting Video Understanding in Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted by ACM MM 2025", "summary": "Video understanding plays a vital role in bridging low-level visual signals\nwith high-level cognitive reasoning, and is fundamental to applications such as\nautonomous driving, embodied AI, and the broader pursuit of AGI. The rapid\ndevelopment of large language models (LLMs), particularly those utilizing\nChain-of-Thought (CoT) technology, has significantly advanced video reasoning\ncapabilities. However, current approaches primarily depend on textual\ninformation for reasoning, overlooking the visual modality in the actual video\nreasoning process. In contrast, humans naturally re-examine visual content\nwhile reasoning. Motivated by this, we introduce a novel video reasoning\nparadigm: Video-Text Interleaved CoT (ViTCoT), which facilitates more intuitive\nand cognitively aligned reasoning. To the end, first, we construct the\nVideo-Text Interleaved Benchmark (ViTIB), which is created using MLLMs for\nkey-video selection and manually verified. Furthermore, we extensively explore\nthe potential of the ViTCoT paradigm in the video understanding field.\nExtensive experiments demonstrate that ViTCoT significantly enhances\nperformance compared to the traditional text-only CoT paradigm and effectively\nactivates more neuron values in MLLMs.", "AI": {"tldr": "\u63d0\u51fa\u89c6\u9891-\u6587\u672c\u4ea4\u9519\u601d\u7ef4\u94fe\uff08ViTCoT\uff09\u8303\u5f0f\u7528\u4e8e\u89c6\u9891\u63a8\u7406\uff0c\u6784\u5efa\u89c6\u9891-\u6587\u672c\u4ea4\u9519\u57fa\u51c6\uff08ViTIB\uff09\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u4ec5\u6587\u672c\u601d\u7ef4\u94fe\u8303\u5f0f\u3002", "motivation": "\u5f53\u524d\u89c6\u9891\u63a8\u7406\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u4fe1\u606f\uff0c\u5ffd\u7565\u89c6\u89c9\u6a21\u6001\uff0c\u800c\u4eba\u7c7b\u63a8\u7406\u65f6\u4f1a\u81ea\u7136\u5ba1\u89c6\u89c6\u89c9\u5185\u5bb9\uff0c\u56e0\u6b64\u63d0\u51fa\u65b0\u8303\u5f0f\u3002", "method": "\u6784\u5efa\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u8fdb\u884c\u5173\u952e\u89c6\u9891\u9009\u62e9\u5e76\u624b\u52a8\u9a8c\u8bc1\u7684ViTIB\uff0c\u63a2\u7d22ViTCoT\u8303\u5f0f\u5728\u89c6\u9891\u7406\u89e3\u9886\u57df\u7684\u6f5c\u529b\u3002", "result": "ViTCoT\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u76f8\u6bd4\u4f20\u7edf\u4ec5\u6587\u672c\u601d\u7ef4\u94fe\u8303\u5f0f\u6548\u679c\u66f4\u597d\uff0c\u4e14\u80fd\u6709\u6548\u6fc0\u6d3bMLLMs\u4e2d\u66f4\u591a\u795e\u7ecf\u5143\u503c\u3002", "conclusion": "ViTCoT\u8303\u5f0f\u5728\u89c6\u9891\u63a8\u7406\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u80fd\u5b9e\u73b0\u66f4\u76f4\u89c2\u4e14\u7b26\u5408\u8ba4\u77e5\u7684\u63a8\u7406\u3002"}}
{"id": "2507.08986", "pdf": "https://arxiv.org/pdf/2507.08986", "abs": "https://arxiv.org/abs/2507.08986", "authors": ["Ashish S. Nair", "Narendra Singh", "Marco Panesi", "Justin Sirignano", "Jonathan F. MacArt"], "title": "Physics-Based Machine Learning Closures and Wall Models for Hypersonic Transition-Continuum Boundary Layer Predictions", "categories": ["physics.flu-dyn", "cs.LG"], "comment": null, "summary": "Modeling rarefied hypersonic flows remains a fundamental challenge due to the\nbreakdown of classical continuum assumptions in the transition-continuum\nregime, where the Knudsen number ranges from approximately 0.1 to 10.\nConventional Navier-Stokes-Fourier (NSF) models with empirical slip-wall\nboundary conditions fail to accurately predict nonequilibrium effects such as\nvelocity slip, temperature jump, and shock structure deviations. We develop a\nphysics-constrained machine learning framework that augments transport models\nand boundary conditions to extend the applicability of continuum solvers in\nnonequilibrium hypersonic regimes. We employ deep learning PDE models (DPMs)\nfor the viscous stress and heat flux embedded in the governing PDEs and trained\nvia adjoint-based optimization. We evaluate these for two-dimensional\nsupersonic flat-plate flows across a range of Mach and Knudsen numbers.\nAdditionally, we introduce a wall model based on a mixture of skewed Gaussian\napproximations of the particle velocity distribution function. This wall model\nreplaces empirical slip conditions with physically informed, data-driven\nboundary conditions for the streamwise velocity and wall temperature. Our\nresults show that a trace-free anisotropic viscosity model, paired with the\nskewed-Gaussian distribution function wall model, achieves significantly\nimproved accuracy, particularly at high-Mach and high-Knudsen number regimes.\nStrategies such as parallel training across multiple Knudsen numbers and\ninclusion of high-Mach data during training are shown to enhance model\ngeneralization. Increasing model complexity yields diminishing returns for\nout-of-sample cases, underscoring the need to balance degrees of freedom and\noverfitting. This work establishes data-driven, physics-consistent strategies\nfor improving hypersonic flow modeling for regimes in which conventional\ncontinuum approaches are invalid.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u7269\u7406\u7ea6\u675f\u673a\u5668\u5b66\u4e60\u6846\u67b6\u6269\u5c55\u8fde\u7eed\u4ecb\u8d28\u6c42\u89e3\u5668\u5728\u975e\u5e73\u8861\u9ad8\u8d85\u58f0\u901f\u6d41\u4e2d\u7684\u9002\u7528\u6027\uff0c\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\uff0c\u5c55\u793a\u63d0\u9ad8\u7cbe\u5ea6\u548c\u6cdb\u5316\u6027\u7684\u7b56\u7565\u3002", "motivation": "\u7ecf\u5178\u8fde\u7eed\u4ecb\u8d28\u5047\u8bbe\u5728\u8fc7\u6e21\u8fde\u7eed\u533a\u5931\u6548\uff0c\u4f20\u7edfNSF\u6a21\u578b\u65e0\u6cd5\u51c6\u786e\u9884\u6d4b\u975e\u5e73\u8861\u6548\u5e94\uff0c\u9700\u8981\u6539\u8fdb\u9ad8\u8d85\u58f0\u901f\u6d41\u5efa\u6a21\u3002", "method": "\u5f00\u53d1\u7269\u7406\u7ea6\u675f\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60PDE\u6a21\u578b\u5e76\u901a\u8fc7\u4f34\u968f\u4f18\u5316\u8bad\u7ec3\uff0c\u5f15\u5165\u57fa\u4e8e\u504f\u6001\u9ad8\u65af\u8fd1\u4f3c\u7684\u58c1\u9762\u6a21\u578b\u3002", "result": "\u65e0\u8ff9\u5404\u5411\u5f02\u6027\u7c98\u5ea6\u6a21\u578b\u4e0e\u504f\u6001\u9ad8\u65af\u58c1\u9762\u6a21\u578b\u5728\u9ad8\u9a6c\u8d6b\u548c\u9ad8\u514b\u52aa\u68ee\u6570\u533a\u57df\u7cbe\u5ea6\u663e\u8457\u63d0\u9ad8\uff0c\u591a\u514b\u52aa\u68ee\u6570\u5e76\u884c\u8bad\u7ec3\u548c\u5f15\u5165\u9ad8\u9a6c\u8d6b\u6570\u636e\u53ef\u589e\u5f3a\u6cdb\u5316\u6027\u3002", "conclusion": "\u5efa\u7acb\u4e86\u6570\u636e\u9a71\u52a8\u3001\u7269\u7406\u4e00\u81f4\u7684\u7b56\u7565\u6765\u6539\u8fdb\u4f20\u7edf\u8fde\u7eed\u4ecb\u8d28\u65b9\u6cd5\u5931\u6548\u533a\u57df\u7684\u9ad8\u8d85\u58f0\u901f\u6d41\u5efa\u6a21\u3002"}}
{"id": "2507.09001", "pdf": "https://arxiv.org/pdf/2507.09001", "abs": "https://arxiv.org/abs/2507.09001", "authors": ["Sazzad Hossain", "Ponkrshnan Thiagarajan", "Shashank Pathrudkar", "Stephanie Taylor", "Abhijeet S. Gangan", "Amartya S. Banerjee", "Susanta Ghosh"], "title": "Surprisingly High Redundancy in Electronic Structure Data", "categories": ["cond-mat.mtrl-sci", "cond-mat.dis-nn", "cs.LG", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "Machine Learning (ML) models for electronic structure rely on large datasets\ngenerated through expensive Kohn-Sham Density Functional Theory simulations.\nThis study reveals a surprisingly high level of redundancy in such datasets\nacross various material systems, including molecules, simple metals, and\ncomplex alloys. Our findings challenge the prevailing assumption that large,\nexhaustive datasets are necessary for accurate ML predictions of electronic\nstructure. We demonstrate that even random pruning can substantially reduce\ndataset size with minimal loss in predictive accuracy, while a state-of-the-art\ncoverage-based pruning strategy retains chemical accuracy and model\ngeneralizability using up to 100-fold less data and reducing training time by\nthreefold or more. By contrast, widely used importance-based pruning methods,\nwhich eliminate seemingly redundant data, can catastrophically fail at higher\npruning factors, possibly due to the significant reduction in data coverage.\nThis heretofore unexplored high degree of redundancy in electronic structure\ndata holds the potential to identify a minimal, essential dataset\nrepresentative of each material class.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u7535\u5b50\u7ed3\u6784\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u9ad8\u5ea6\u5197\u4f59\uff0c\u968f\u673a\u6216\u57fa\u4e8e\u8986\u76d6\u5ea6\u7684\u526a\u679d\u53ef\u51cf\u5c11\u6570\u636e\u91cf\u4e14\u4e0d\u635f\u5931\u592a\u591a\u51c6\u786e\u6027\uff0c\u800c\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u526a\u679d\u53ef\u80fd\u5931\u8d25\u3002", "motivation": "\u6311\u6218\u666e\u904d\u8ba4\u4e3a\u51c6\u786e\u9884\u6d4b\u7535\u5b50\u7ed3\u6784\u9700\u8981\u5927\u91cf\u8be6\u5c3d\u6570\u636e\u96c6\u7684\u5047\u8bbe\uff0c\u63a2\u7d22\u6570\u636e\u5197\u4f59\u60c5\u51b5\u3002", "method": "\u91c7\u7528\u968f\u673a\u526a\u679d\u3001\u57fa\u4e8e\u8986\u76d6\u5ea6\u7684\u526a\u679d\u7b56\u7565\u548c\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u526a\u679d\u65b9\u6cd5\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u968f\u673a\u526a\u679d\u53ef\u5927\u5e45\u51cf\u5c11\u6570\u636e\u96c6\u5927\u5c0f\u4e14\u635f\u5931\u6700\u5c0f\uff1b\u57fa\u4e8e\u8986\u76d6\u5ea6\u7684\u526a\u679d\u7528\u5c11\u81f3100\u500d\u7684\u6570\u636e\u4fdd\u7559\u5316\u5b66\u7cbe\u5ea6\u548c\u6a21\u578b\u6cdb\u5316\u6027\uff0c\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff1b\u57fa\u4e8e\u91cd\u8981\u6027\u7684\u526a\u679d\u5728\u9ad8\u526a\u679d\u56e0\u5b50\u4e0b\u53ef\u80fd\u5931\u8d25\u3002", "conclusion": "\u7535\u5b50\u7ed3\u6784\u6570\u636e\u4e2d\u5b58\u5728\u7684\u9ad8\u5197\u4f59\u6027\u6709\u52a9\u4e8e\u8bc6\u522b\u6bcf\u4e2a\u6750\u6599\u7c7b\u522b\u7684\u6700\u5c0f\u5fc5\u8981\u6570\u636e\u96c6\u3002"}}
{"id": "2507.09025", "pdf": "https://arxiv.org/pdf/2507.09025", "abs": "https://arxiv.org/abs/2507.09025", "authors": ["Chien Van Nguyen", "Ruiyi Zhang", "Hanieh Deilamsalehy", "Puneet Mathur", "Viet Dac Lai", "Haoliang Wang", "Jayakumar Subramanian", "Ryan A. Rossi", "Trung Bui", "Nikos Vlassis", "Franck Dernoncourt", "Thien Huu Nguyen"], "title": "Lizard: An Efficient Linearization Framework for Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "15 pages", "summary": "We propose Lizard, a linearization framework that transforms pretrained\nTransformer-based Large Language Models (LLMs) into flexible, subquadratic\narchitectures for infinite-context generation. Transformer-based LLMs face\nsignificant memory and computational bottlenecks as context lengths increase,\ndue to the quadratic complexity of softmax attention and the growing key-value\n(KV) cache. Lizard addresses these limitations by introducing a subquadratic\nattention mechanism that closely approximates softmax attention while\npreserving the output quality. Unlike previous linearization methods, which are\noften limited by fixed model structures and therefore exclude gating\nmechanisms, Lizard incorporates a gating module inspired by recent\nstate-of-the-art linear models. This enables adaptive memory control, supports\nconstant-memory inference, offers strong length generalization, and allows more\nflexible model design. Lizard combines gated linear attention for global\ncontext compression with sliding window attention enhanced by meta memory,\nforming a hybrid mechanism that captures both long-range dependencies and\nfine-grained local interactions. Moreover, we introduce a hardware-aware\nalgorithm that accelerates the training speed of our models. Extensive\nexperiments show that Lizard achieves near-lossless recovery of the teacher\nmodel's performance across standard language modeling tasks, while\nsignificantly outperforming previous linearization methods. On the 5-shot MMLU\nbenchmark, Lizard improves over prior models by 18 points and shows significant\nimprovements on associative recall tasks.", "AI": {"tldr": "\u63d0\u51faLizard\u6846\u67b6\u5c06\u9884\u8bad\u7ec3\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u7075\u6d3b\u3001\u4e9a\u4e8c\u6b21\u67b6\u6784\u7528\u4e8e\u65e0\u9650\u4e0a\u4e0b\u6587\u751f\u6210\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f73\u3002", "motivation": "Transformer\u5927\u8bed\u8a00\u6a21\u578b\u56e0softmax\u6ce8\u610f\u529b\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u548c\u4e0d\u65ad\u589e\u957f\u7684KV\u7f13\u5b58\uff0c\u5728\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u65f6\u9762\u4e34\u5185\u5b58\u548c\u8ba1\u7b97\u74f6\u9888\u3002", "method": "\u5f15\u5165\u8fd1\u4f3csoftmax\u6ce8\u610f\u529b\u7684\u4e9a\u4e8c\u6b21\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408\u95e8\u63a7\u6a21\u5757\uff0c\u91c7\u7528\u6df7\u5408\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u5f15\u5165\u786c\u4ef6\u611f\u77e5\u7b97\u6cd5\u52a0\u901f\u8bad\u7ec3\u3002", "result": "Lizard\u5728\u6807\u51c6\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u8fd1\u4e4e\u65e0\u635f\u6062\u590d\u6559\u5e08\u6a21\u578b\u6027\u80fd\uff0c\u663e\u8457\u8d85\u8d8a\u5148\u524d\u7ebf\u6027\u5316\u65b9\u6cd5\uff0c\u57285-shot MMLU\u57fa\u51c6\u4e0a\u6bd4\u5148\u524d\u6a21\u578b\u63d0\u9ad818\u5206\u3002", "conclusion": "Lizard\u662f\u4e00\u79cd\u6709\u6548\u7684\u5c06\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7ebf\u6027\u5316\u7684\u6846\u67b6\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u5185\u5b58\u548c\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2507.09026", "pdf": "https://arxiv.org/pdf/2507.09026", "abs": "https://arxiv.org/abs/2507.09026", "authors": ["Kasra Fallah", "Leonardo F. Toso", "James Anderson"], "title": "On the Gradient Domination of the LQG Problem", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "We consider solutions to the linear quadratic Gaussian (LQG) regulator\nproblem via policy gradient (PG) methods. Although PG methods have demonstrated\nstrong theoretical guarantees in solving the linear quadratic regulator (LQR)\nproblem, despite its nonconvex landscape, their theoretical understanding in\nthe LQG setting remains limited. Notably, the LQG problem lacks gradient\ndominance in the classical parameterization, i.e., with a dynamic controller,\nwhich hinders global convergence guarantees. In this work, we study PG for the\nLQG problem by adopting an alternative parameterization of the set of\nstabilizing controllers and employing a lifting argument. We refer to this\nparameterization as a history representation of the control input as it is\nparameterized by past input and output data from the previous p time-steps.\nThis representation enables us to establish gradient dominance and approximate\nsmoothness for the LQG cost. We prove global convergence and per-iteration\nstability guarantees for policy gradient LQG in model-based and model-free\nsettings. Numerical experiments on an open-loop unstable system are provided to\nsupport the global convergence guarantees and to illustrate convergence under\ndifferent history lengths of the history representation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u6c42\u89e3\u7ebf\u6027\u4e8c\u6b21\u9ad8\u65af\u8c03\u8282\u5668\u95ee\u9898\uff0c\u91c7\u7528\u66ff\u4ee3\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u8bc1\u660e\u5168\u5c40\u6536\u655b\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u6709\u6570\u503c\u5b9e\u9a8c\u652f\u6301\u3002", "motivation": "\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5728LQR\u95ee\u9898\u4e0a\u6709\u7406\u8bba\u4fdd\u8bc1\uff0c\u4f46\u5728LQG\u95ee\u9898\u4e0a\u7406\u8bba\u7406\u89e3\u6709\u9650\uff0cLQG\u95ee\u9898\u7f3a\u4e4f\u68af\u5ea6\u4e3b\u5bfc\u6027\u963b\u788d\u5168\u5c40\u6536\u655b\u3002", "method": "\u91c7\u7528\u7a33\u5b9a\u63a7\u5236\u5668\u7684\u66ff\u4ee3\u53c2\u6570\u5316\u548c\u63d0\u5347\u8bba\u8bc1\uff0c\u4f7f\u7528\u63a7\u5236\u8f93\u5165\u7684\u5386\u53f2\u8868\u793a\uff0c\u57fa\u4e8e\u8fc7\u53bbp\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u8f93\u51fa\u6570\u636e\u8fdb\u884c\u53c2\u6570\u5316\u3002", "result": "\u5efa\u7acb\u4e86LQG\u6210\u672c\u7684\u68af\u5ea6\u4e3b\u5bfc\u6027\u548c\u8fd1\u4f3c\u5e73\u6ed1\u6027\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u6a21\u578b\u548c\u65e0\u6a21\u578b\u8bbe\u7f6e\u4e0b\u7b56\u7565\u68af\u5ea6LQG\u7684\u5168\u5c40\u6536\u655b\u548c\u6bcf\u6b65\u7a33\u5b9a\u6027\u3002", "conclusion": "\u6570\u503c\u5b9e\u9a8c\u652f\u6301\u5168\u5c40\u6536\u655b\u4fdd\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u5386\u53f2\u957f\u5ea6\u4e0b\u7684\u6536\u655b\u60c5\u51b5\u3002"}}
{"id": "2507.09891", "pdf": "https://arxiv.org/pdf/2507.09891", "abs": "https://arxiv.org/abs/2507.09891", "authors": ["Jiaxin Huang", "Yan Zhu", "Giulio Chiribella", "Ya-Dong Wu"], "title": "Sequence-Model-Guided Measurement Selection for Quantum State Learning", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Characterization of quantum systems from experimental data is a central\nproblem in quantum science and technology. But which measurements should be\nused to gather data in the first place? While optimal measurement choices can\nbe worked out for small quantum systems, the optimization becomes intractable\nas the system size grows large. To address this problem, we introduce a deep\nneural network with a sequence model architecture that searches for efficient\nmeasurement choices in a data-driven, adaptive manner. The model can be applied\nto a variety of tasks, including the prediction of linear and nonlinear\nproperties of quantum states, as well as state clustering and state tomography\ntasks. In all these tasks, we find that the measurement choices identified by\nour neural network consistently outperform the uniformly random choice.\nIntriguingly, for topological quantum systems, our model tends to recommend\nmeasurements at the system's boundaries, even when the task is to predict bulk\nproperties. This behavior suggests that the neural network may have\nindependently discovered a connection between boundaries and bulk, without\nhaving been provided any built-in knowledge of quantum physics.", "AI": {"tldr": "\u5f15\u5165\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4ee5\u6570\u636e\u9a71\u52a8\u3001\u81ea\u9002\u5e94\u65b9\u5f0f\u641c\u7d22\u91cf\u5b50\u7cfb\u7edf\u6709\u6548\u6d4b\u91cf\u9009\u62e9\uff0c\u5728\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u968f\u673a\u9009\u62e9\uff0c\u5bf9\u62d3\u6251\u91cf\u5b50\u7cfb\u7edf\u6709\u7279\u522b\u63a8\u8350\u3002", "motivation": "\u89e3\u51b3\u91cf\u5b50\u7cfb\u7edf\u89c4\u6a21\u589e\u5927\u65f6\u6d4b\u91cf\u9009\u62e9\u4f18\u5316\u53d8\u5f97\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5177\u6709\u5e8f\u5217\u6a21\u578b\u67b6\u6784\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u786e\u5b9a\u7684\u6d4b\u91cf\u9009\u62e9\u5728\u5404\u7c7b\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5747\u5300\u968f\u673a\u9009\u62e9\uff0c\u5bf9\u62d3\u6251\u91cf\u5b50\u7cfb\u7edf\u503e\u5411\u4e8e\u63a8\u8350\u8fb9\u754c\u6d4b\u91cf\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u53ef\u80fd\u72ec\u7acb\u53d1\u73b0\u4e86\u8fb9\u754c\u548c\u4f53\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4e14\u65e0\u9700\u5185\u7f6e\u91cf\u5b50\u7269\u7406\u77e5\u8bc6\u3002"}}
{"id": "2507.09898", "pdf": "https://arxiv.org/pdf/2507.09898", "abs": "https://arxiv.org/abs/2507.09898", "authors": ["Alireza Golkarieha", "Kiana Kiashemshakib", "Sajjad Rezvani Boroujenic", "Nasibeh Asadi Isakand"], "title": "Advanced U-Net Architectures with CNN Backbones for Automated Lung Cancer Detection and Segmentation in Chest CT Images", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "This manuscript has 20 pages and 10 figures. It is submitted to the\n  Journal 'Scientific Reports'", "summary": "This study investigates the effectiveness of U-Net architectures integrated\nwith various convolutional neural network (CNN) backbones for automated lung\ncancer detection and segmentation in chest CT images, addressing the critical\nneed for accurate diagnostic tools in clinical settings. A balanced dataset of\n832 chest CT images (416 cancerous and 416 non-cancerous) was preprocessed\nusing Contrast Limited Adaptive Histogram Equalization (CLAHE) and resized to\n128x128 pixels. U-Net models were developed with three CNN backbones: ResNet50,\nVGG16, and Xception, to segment lung regions. After segmentation, CNN-based\nclassifiers and hybrid models combining CNN feature extraction with traditional\nmachine learning classifiers (Support Vector Machine, Random Forest, and\nGradient Boosting) were evaluated using 5-fold cross-validation. Metrics\nincluded accuracy, precision, recall, F1-score, Dice coefficient, and ROC-AUC.\nU-Net with ResNet50 achieved the best performance for cancerous lungs (Dice:\n0.9495, Accuracy: 0.9735), while U-Net with VGG16 performed best for\nnon-cancerous segmentation (Dice: 0.9532, Accuracy: 0.9513). For\nclassification, the CNN model using U-Net with Xception achieved 99.1 percent\naccuracy, 99.74 percent recall, and 99.42 percent F1-score. The hybrid\nCNN-SVM-Xception model achieved 96.7 percent accuracy and 97.88 percent\nF1-score. Compared to prior methods, our framework consistently outperformed\nexisting models. In conclusion, combining U-Net with advanced CNN backbones\nprovides a powerful method for both segmentation and classification of lung\ncancer in CT scans, supporting early diagnosis and clinical decision-making.", "AI": {"tldr": "\u7814\u7a76\u7528\u4e0d\u540cCNN\u9aa8\u5e72\u7684U - Net\u67b6\u6784\u8fdb\u884c\u80ba\u764c\u68c0\u6d4b\u548c\u5206\u5272\uff0cU - Net\u7ed3\u5408\u4e0d\u540c\u9aa8\u5e72\u5728\u5206\u5272\u548c\u5206\u7c7b\u4e0a\u8868\u73b0\u4f73\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u652f\u6301\u4e34\u5e8a\u8bca\u65ad\u3002", "motivation": "\u6ee1\u8db3\u4e34\u5e8a\u5bf9\u51c6\u786e\u80ba\u764c\u8bca\u65ad\u5de5\u5177\u7684\u8feb\u5207\u9700\u6c42\u3002", "method": "\u9884\u5904\u7406832\u5f20\u80f8\u90e8CT\u56fe\u50cf\uff0c\u5f00\u53d1\u5e26ResNet50\u3001VGG16\u548cXception\u9aa8\u5e72\u7684U - Net\u6a21\u578b\u8fdb\u884c\u5206\u5272\uff0c\u7528CNN\u5206\u7c7b\u5668\u548c\u6df7\u5408\u6a21\u578b\u5206\u7c7b\uff0c\u91c7\u75285\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u7528\u591a\u6307\u6807\u8bc4\u4f30\u3002", "result": "U - Net\u4e0eResNet50\u5728\u764c\u80ba\u5206\u5272\u8868\u73b0\u6700\u597d\uff0cU - Net\u4e0eVGG16\u5728\u975e\u764c\u80ba\u5206\u5272\u6700\u4f73\uff1bU - Net\u4e0eXception\u7684CNN\u6a21\u578b\u5206\u7c7b\u8868\u73b0\u4f73\uff0c\u6df7\u5408CNN - SVM - Xception\u6a21\u578b\u4e5f\u6709\u4e0d\u9519\u8868\u73b0\uff0c\u4e14\u6846\u67b6\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "U - Net\u7ed3\u5408\u5148\u8fdbCNN\u9aa8\u5e72\u662fCT\u626b\u63cf\u4e2d\u80ba\u764c\u5206\u5272\u548c\u5206\u7c7b\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u652f\u6301\u65e9\u671f\u8bca\u65ad\u548c\u4e34\u5e8a\u51b3\u7b56\u3002"}}
{"id": "2507.09050", "pdf": "https://arxiv.org/pdf/2507.09050", "abs": "https://arxiv.org/abs/2507.09050", "authors": ["James Kotary", "Himanshu Sharma", "Ethan King", "Draguna Vrabie", "Ferdinando Fioretto", "Jan Drgona"], "title": "A Method for Learning to Solve Parametric Bilevel Optimization with Coupling Constraints", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "Learning to Optimize (L2O) is a subfield of machine learning (ML) in which ML\nmodels are trained to solve parametric optimization problems. The general goal\nis to learn a fast approximator of solutions to constrained optimization\nproblems, as a function of their defining parameters. Prior L2O methods focus\nalmost entirely on single-level programs, in contrast to the bilevel programs,\nwhose constraints are themselves expressed in terms of optimization\nsubproblems. Bilevel programs have numerous important use cases but are\nnotoriously difficult to solve, particularly under stringent time demands. This\npaper proposes a framework for learning to solve a broad class of challenging\nbilevel optimization problems, by leveraging modern techniques for\ndifferentiation through optimization problems. The framework is illustrated on\nan array of synthetic bilevel programs, as well as challenging control system\nco-design problems, showing how neural networks can be trained as efficient\napproximators of parametric bilevel optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5b66\u4e60\u6c42\u89e3\u53cc\u7ea7\u4f18\u5316\u95ee\u9898\u6846\u67b6\uff0c\u7528\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e3a\u53c2\u6570\u5316\u53cc\u7ea7\u4f18\u5316\u7684\u9ad8\u6548\u8fd1\u4f3c\u5668\uff0c\u5e76\u5728\u5408\u6210\u53cc\u7ea7\u7a0b\u5e8f\u53ca\u63a7\u5236\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u95ee\u9898\u4e2d\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u4f18\u5316\u65b9\u6cd5\u591a\u5173\u6ce8\u5355\u7ea7\u7a0b\u5e8f\uff0c\u53cc\u7ea7\u7a0b\u5e8f\u867d\u6709\u91cd\u8981\u5e94\u7528\u4f46\u96be\u6c42\u89e3\uff0c\u5c24\u5176\u5728\u65f6\u95f4\u8981\u6c42\u4e25\u683c\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u5229\u7528\u901a\u8fc7\u4f18\u5316\u95ee\u9898\u8fdb\u884c\u5fae\u5206\u7684\u73b0\u4ee3\u6280\u672f\uff0c\u63d0\u51fa\u5b66\u4e60\u6c42\u89e3\u5e7f\u6cdb\u7c7b\u522b\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u53cc\u7ea7\u4f18\u5316\u95ee\u9898\u7684\u6846\u67b6\u3002", "result": "\u6846\u67b6\u5728\u4e00\u7cfb\u5217\u5408\u6210\u53cc\u7ea7\u7a0b\u5e8f\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u63a7\u5236\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u95ee\u9898\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u53ef\u88ab\u8bad\u7ec3\u4e3a\u53c2\u6570\u5316\u53cc\u7ea7\u4f18\u5316\u7684\u9ad8\u6548\u8fd1\u4f3c\u5668\u3002"}}
{"id": "2507.09901", "pdf": "https://arxiv.org/pdf/2507.09901", "abs": "https://arxiv.org/abs/2507.09901", "authors": ["Ayush Chopra"], "title": "Large Population Models", "categories": ["cs.MA", "cs.AI"], "comment": "Aggregation of Several Papers from MIT PhD Research.\n  github.com/AgentTorch/AgentTorch", "summary": "Many of society's most pressing challenges, from pandemic response to supply\nchain disruptions to climate adaptation, emerge from the collective behavior of\nmillions of autonomous agents making decisions over time. Large Population\nModels (LPMs) offer an approach to understand these complex systems by\nsimulating entire populations with realistic behaviors and interactions at\nunprecedented scale. LPMs extend traditional modeling approaches through three\nkey innovations: computational methods that efficiently simulate millions of\nagents simultaneously, mathematical frameworks that learn from diverse\nreal-world data streams, and privacy-preserving communication protocols that\nbridge virtual and physical environments. This allows researchers to observe\nhow agent behavior aggregates into system-level outcomes and test interventions\nbefore real-world implementation. While current AI advances primarily focus on\ncreating \"digital humans\" with sophisticated individual capabilities, LPMs\ndevelop \"digital societies\" where the richness of interactions reveals emergent\nphenomena. By bridging individual agent behavior and population-scale dynamics,\nLPMs offer a complementary path in AI research illuminating collective\nintelligence and providing testing grounds for policies and social innovations\nbefore real-world deployment. We discuss the technical foundations and some\nopen problems here. LPMs are implemented by the AgentTorch framework\n(github.com/AgentTorch/AgentTorch)", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5927\u7fa4\u4f53\u6a21\u578b\uff08LPMs\uff09\u53ef\u6a21\u62df\u7fa4\u4f53\u884c\u4e3a\uff0c\u6709\u4e09\u9879\u521b\u65b0\uff0c\u80fd\u8fde\u63a5\u4e2a\u4f53\u4e0e\u7fa4\u4f53\u52a8\u6001\uff0c\u4e3aAI\u7814\u7a76\u63d0\u4f9b\u65b0\u8def\u5f84\uff0c\u5e76\u63d0\u53ca\u5b9e\u73b0\u6846\u67b6\u4e0e\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u793e\u4f1a\u8bf8\u591a\u6311\u6218\u6e90\u4e8e\u5927\u91cf\u81ea\u4e3b\u4e2a\u4f53\u51b3\u7b56\uff0c\u9700\u8981\u65b9\u6cd5\u7406\u89e3\u590d\u6742\u7cfb\u7edf\u3002", "method": "LPMs\u901a\u8fc7\u9ad8\u6548\u6a21\u62df\u8ba1\u7b97\u65b9\u6cd5\u3001\u4ece\u591a\u5143\u6570\u636e\u5b66\u4e60\u7684\u6570\u5b66\u6846\u67b6\u548c\u9690\u79c1\u901a\u4fe1\u534f\u8bae\u4e09\u9879\u521b\u65b0\uff0c\u6269\u5c55\u4f20\u7edf\u5efa\u6a21\u65b9\u6cd5\u3002", "result": "\u80fd\u89c2\u5bdf\u4e2a\u4f53\u884c\u4e3a\u805a\u5408\u7684\u7cfb\u7edf\u7ed3\u679c\uff0c\u53ef\u5728\u73b0\u5b9e\u5b9e\u65bd\u524d\u6d4b\u8bd5\u5e72\u9884\u63aa\u65bd\uff0c\u5f00\u53d1\u51fa\u201c\u6570\u5b57\u793e\u4f1a\u201d\u63ed\u793a\u6d8c\u73b0\u73b0\u8c61\u3002", "conclusion": "LPMs\u4e3aAI\u7814\u7a76\u63d0\u4f9b\u8865\u5145\u8def\u5f84\uff0c\u53ef\u7528\u4e8e\u7814\u7a76\u96c6\u4f53\u667a\u80fd\uff0c\u6d4b\u8bd5\u653f\u7b56\u548c\u793e\u4f1a\u521b\u65b0\u3002"}}
{"id": "2507.09052", "pdf": "https://arxiv.org/pdf/2507.09052", "abs": "https://arxiv.org/abs/2507.09052", "authors": ["Fang Chen", "Alex Villa", "Gongbo Liang", "Xiaoyi Lu", "Meng Tang"], "title": "Can Contrastive Learning Improve Class-Imbalanced Diffusion Model?", "categories": ["cs.CV", "cs.LG"], "comment": "20 pages, 11 figures", "summary": "Training data for class-conditional image synthesis often exhibit a\nlong-tailed distribution with limited images for tail classes. Such an\nimbalance causes mode collapse and reduces the diversity of synthesized images\nfor tail classes. For class-conditional diffusion models trained on imbalanced\ndata, we aim to improve the diversity of tail class images without compromising\nthe fidelity and diversity of head class images. We achieve this by introducing\ntwo deceptively simple but highly effective contrastive loss functions.\nFirstly, we employ an unsupervised InfoNCE loss utilizing negative samples to\nincrease the distance/dissimilarity among synthetic images, particularly for\ntail classes. To further enhance the diversity of tail classes, our second loss\nis an MSE loss that contrasts class-conditional generation with unconditional\ngeneration at large timesteps. This second loss makes the denoising process\ninsensitive to class conditions for the initial steps, which enriches tail\nclasses through knowledge sharing from head classes. Conditional-unconditional\nalignment has been shown to enhance the performance of long-tailed GAN. We are\nthe first to adapt such alignment to diffusion models. We successfully\nleveraged contrastive learning for class-imbalanced diffusion models. Our\ncontrastive learning framework is easy to implement and outperforms standard\nDDPM and alternative methods for class-imbalanced diffusion models across\nvarious datasets, including CIFAR10/100-LT, PlacesLT, TinyImageNetLT, and\nImageNetLT.", "AI": {"tldr": "\u9488\u5bf9\u7c7b\u522b\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5728\u4e0d\u5e73\u8861\u6570\u636e\u4e0a\u7684\u8bad\u7ec3\u95ee\u9898\uff0c\u5f15\u5165\u4e24\u79cd\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u63d0\u5347\u5c3e\u7c7b\u56fe\u50cf\u591a\u6837\u6027\uff0c\u65b9\u6cd5\u6613\u5b9e\u73b0\u4e14\u6548\u679c\u597d\u3002", "motivation": "\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u957f\u5c3e\u5206\u5e03\u5bfc\u81f4\u5c3e\u7c7b\u5408\u6210\u56fe\u50cf\u591a\u6837\u6027\u964d\u4f4e\u7684\u95ee\u9898\uff0c\u5728\u4e0d\u5f71\u54cd\u5934\u7c7b\u56fe\u50cf\u4fdd\u771f\u5ea6\u548c\u591a\u6837\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u5347\u5c3e\u7c7b\u56fe\u50cf\u591a\u6837\u6027\u3002", "method": "\u5f15\u5165\u65e0\u76d1\u7763InfoNCE\u635f\u5931\u589e\u52a0\u5408\u6210\u56fe\u50cf\u95f4\u8ddd\u79bb\uff0c\u4f7f\u7528MSE\u635f\u5931\u5728\u5927\u65f6\u95f4\u6b65\u5bf9\u6bd4\u6761\u4ef6\u751f\u6210\u548c\u65e0\u6761\u4ef6\u751f\u6210\uff0c\u5b9e\u73b0\u6761\u4ef6 - \u65e0\u6761\u4ef6\u5bf9\u9f50\u3002", "result": "\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6807\u51c6DDPM\u548c\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u6210\u529f\u5c06\u5bf9\u6bd4\u5b66\u4e60\u5e94\u7528\u4e8e\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u6269\u6563\u6a21\u578b\uff0c\u6240\u63d0\u65b9\u6cd5\u7b80\u5355\u6709\u6548\u3002"}}
{"id": "2507.09054", "pdf": "https://arxiv.org/pdf/2507.09054", "abs": "https://arxiv.org/abs/2507.09054", "authors": ["Fr\u00e9d\u00e9ric A. Dreyer", "Jan Ludwiczak", "Karolis Martinkus", "Brennan Abanades", "Robert G. Alberstein", "Pan Kessel", "Pranav Rao", "Jae Hyeon Lee", "Richard Bonneau", "Andrew M. Watkins", "Franziska Seeger"], "title": "Conformation-Aware Structure Prediction of Antigen-Recognizing Immune Proteins", "categories": ["q-bio.BM", "cs.LG"], "comment": "17 pages, 12 figures, 2 tables, code at\n  https://github.com/prescient-design/ibex, model weights at\n  https://doi.org/10.5281/zenodo.15866555", "summary": "We introduce Ibex, a pan-immunoglobulin structure prediction model that\nachieves state-of-the-art accuracy in modeling the variable domains of\nantibodies, nanobodies, and T-cell receptors. Unlike previous approaches, Ibex\nexplicitly distinguishes between bound and unbound protein conformations by\ntraining on labeled apo and holo structural pairs, enabling accurate prediction\nof both states at inference time. Using a comprehensive private dataset of\nhigh-resolution antibody structures, we demonstrate superior\nout-of-distribution performance compared to existing specialized and general\nprotein structure prediction tools. Ibex combines the accuracy of cutting-edge\nmodels with significantly reduced computational requirements, providing a\nrobust foundation for accelerating large molecule design and therapeutic\ndevelopment.", "AI": {"tldr": "\u4ecb\u7ecd\u6cdb\u514d\u75ab\u7403\u86cb\u767d\u7ed3\u6784\u9884\u6d4b\u6a21\u578bIbex\uff0c\u5728\u6297\u4f53\u3001\u7eb3\u7c73\u6297\u4f53\u548cT\u7ec6\u80de\u53d7\u4f53\u53ef\u53d8\u57df\u5efa\u6a21\u4e2d\u8fbe\u5148\u8fdb\u6c34\u5e73\uff0c\u533a\u5206\u7ed3\u5408\u4e0e\u672a\u7ed3\u5408\u6784\u8c61\uff0c\u6027\u80fd\u4f18\u4e14\u8ba1\u7b97\u9700\u6c42\u4f4e\u3002", "motivation": "\u5f00\u53d1\u80fd\u51c6\u786e\u9884\u6d4b\u6297\u4f53\u3001\u7eb3\u7c73\u6297\u4f53\u548cT\u7ec6\u80de\u53d7\u4f53\u53ef\u53d8\u57df\u7ed3\u6784\uff0c\u4e14\u533a\u5206\u7ed3\u5408\u4e0e\u672a\u7ed3\u5408\u6784\u8c61\u7684\u6a21\u578b\uff0c\u4ee5\u52a0\u901f\u5927\u5206\u5b50\u8bbe\u8ba1\u548c\u6cbb\u7597\u5f00\u53d1\u3002", "method": "\u5728\u6807\u8bb0\u7684\u6e38\u79bb\u6001\u548c\u7ed3\u5408\u6001\u7ed3\u6784\u5bf9\u4e0a\u8bad\u7ec3\uff0c\u4f7f\u7528\u9ad8\u5206\u8fa8\u7387\u6297\u4f53\u7ed3\u6784\u7684\u7efc\u5408\u79c1\u6709\u6570\u636e\u96c6\u3002", "result": "\u5728\u5206\u5e03\u5916\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u4e13\u4e1a\u548c\u901a\u7528\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u5de5\u5177\uff0c\u7ed3\u5408\u524d\u6cbf\u6a21\u578b\u51c6\u786e\u6027\u4e14\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\u3002", "conclusion": "Ibex\u4e3a\u52a0\u901f\u5927\u5206\u5b50\u8bbe\u8ba1\u548c\u6cbb\u7597\u5f00\u53d1\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2507.09929", "pdf": "https://arxiv.org/pdf/2507.09929", "abs": "https://arxiv.org/abs/2507.09929", "authors": ["Haoyang Li", "Nana Hou", "Yuchen Hu", "Jixun Yao", "Sabato Marco Siniscalchi", "Eng Siong Chng"], "title": "Aligning Generative Speech Enhancement with Human Preferences via Direct Preference Optimization", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": null, "summary": "This work investigates speech enhancement (SE) from the perspective of\nlanguage models (LMs). We propose a novel method that leverages Direct\nPreference Optimization (DPO) to improve the perceptual quality of enhanced\nspeech. Using UTMOS, a neural MOS prediction model, as a proxy for human\nratings, our approach guides optimization toward perceptually preferred\noutputs. This differs from existing LM-based SE methods that focus on\nmaximizing the likelihood of clean speech tokens, which may misalign with human\nperception and degrade quality despite low prediction error. Experiments on the\n2020 Deep Noise Suppression Challenge test sets demonstrate that applying DPO\nto a pretrained LM-based SE model yields consistent improvements across various\nspeech quality metrics, with relative gains of up to 56%. To our knowledge,\nthis is the first application of DPO to SE and the first to incorporate proxy\nperceptual feedback into LM-based SE training, pointing to a promising\ndirection for perceptually aligned SE.", "AI": {"tldr": "\u672c\u6587\u4ece\u8bed\u8a00\u6a21\u578b\u89d2\u5ea6\u7814\u7a76\u8bed\u97f3\u589e\u5f3a\uff0c\u63d0\u51fa\u7528DPO\u63d0\u5347\u589e\u5f3a\u8bed\u97f3\u611f\u77e5\u8d28\u91cf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\uff0c\u4e3a\u8bed\u97f3\u589e\u5f3a\u6307\u660e\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u97f3\u589e\u5f3a\u65b9\u6cd5\u53ef\u80fd\u4e0e\u4eba\u7c7b\u611f\u77e5\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u8d28\u91cf\u4e0b\u964d\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u5229\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u65b9\u6cd5\uff0c\u7528UTMOS\u4f5c\u4e3a\u4eba\u7c7b\u8bc4\u5206\u4ee3\u7406\u5f15\u5bfc\u4f18\u5316\u3002", "result": "\u57282020\u6df1\u5ea6\u566a\u58f0\u6291\u5236\u6311\u6218\u8d5b\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u5c06DPO\u5e94\u7528\u4e8e\u9884\u8bad\u7ec3\u7684\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u97f3\u589e\u5f3a\u6a21\u578b\uff0c\u5404\u9879\u8bed\u97f3\u8d28\u91cf\u6307\u6807\u6709\u663e\u8457\u63d0\u5347\uff0c\u76f8\u5bf9\u589e\u76ca\u8fbe56%\u3002", "conclusion": "\u8fd9\u662fDPO\u9996\u6b21\u5e94\u7528\u4e8e\u8bed\u97f3\u589e\u5f3a\uff0c\u4e5f\u662f\u9996\u6b21\u5c06\u4ee3\u7406\u611f\u77e5\u53cd\u9988\u7eb3\u5165\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u97f3\u589e\u5f3a\u8bad\u7ec3\uff0c\u4e3a\u611f\u77e5\u5bf9\u9f50\u7684\u8bed\u97f3\u589e\u5f3a\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2507.09935", "pdf": "https://arxiv.org/pdf/2507.09935", "abs": "https://arxiv.org/abs/2507.09935", "authors": ["Hai Toan Nguyen", "Tien Dat Nguyen", "Viet Ha Nguyen"], "title": "Enhancing Retrieval Augmented Generation with Hierarchical Text Segmentation Chunking", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems commonly use chunking strategies\nfor retrieval, which enhance large language models (LLMs) by enabling them to\naccess external knowledge, ensuring that the retrieved information is\nup-to-date and domain-specific. However, traditional methods often fail to\ncreate chunks that capture sufficient semantic meaning, as they do not account\nfor the underlying textual structure. This paper proposes a novel framework\nthat enhances RAG by integrating hierarchical text segmentation and clustering\nto generate more meaningful and semantically coherent chunks. During inference,\nthe framework retrieves information by leveraging both segment-level and\ncluster-level vector representations, thereby increasing the likelihood of\nretrieving more precise and contextually relevant information. Evaluations on\nthe NarrativeQA, QuALITY, and QASPER datasets indicate that the proposed method\nachieved improved results compared to traditional chunking techniques.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u65b0\u6846\u67b6\u589e\u5f3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u5728\u591a\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u5206\u5757\u6280\u672f\u3002", "motivation": "\u4f20\u7edf\u5206\u5757\u7b56\u7565\u65e0\u6cd5\u521b\u5efa\u6355\u83b7\u8db3\u591f\u8bed\u4e49\u7684\u5757\uff0c\u4e0d\u80fd\u8003\u8651\u6587\u672c\u6f5c\u5728\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u6574\u5408\u5206\u5c42\u6587\u672c\u5206\u5272\u548c\u805a\u7c7b\u7684\u6846\u67b6\uff0c\u63a8\u7406\u65f6\u5229\u7528\u6bb5\u7ea7\u548c\u7c07\u7ea7\u5411\u91cf\u8868\u793a\u68c0\u7d22\u4fe1\u606f\u3002", "result": "\u5728NarrativeQA\u3001QuALITY\u548cQASPER\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edf\u5206\u5757\u6280\u672f\u53d6\u5f97\u66f4\u597d\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u589e\u5f3aRAG\u7cfb\u7edf\uff0c\u751f\u6210\u66f4\u6709\u610f\u4e49\u3001\u8bed\u4e49\u8fde\u8d2f\u7684\u5757\uff0c\u63d0\u9ad8\u68c0\u7d22\u4fe1\u606f\u7684\u51c6\u786e\u6027\u548c\u76f8\u5173\u6027\u3002"}}
{"id": "2507.09092", "pdf": "https://arxiv.org/pdf/2507.09092", "abs": "https://arxiv.org/abs/2507.09092", "authors": ["Ram S Iyer", "Narayan S Iyer", "Rugmini Ammal P"], "title": "MI CAM: Mutual Information Weighted Activation Mapping for Causal Visual Explanations of Convolutional Neural Networks", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages, 10 figures", "summary": "With the intervention of machine vision in our crucial day to day necessities\nincluding healthcare and automated power plants, attention has been drawn to\nthe internal mechanisms of convolutional neural networks, and the reason why\nthe network provides specific inferences. This paper proposes a novel post-hoc\nvisual explanation method called MI CAM based on activation mapping. Differing\nfrom previous class activation mapping based approaches, MI CAM produces\nsaliency visualizations by weighing each feature map through its mutual\ninformation with the input image and the final result is generated by a linear\ncombination of weights and activation maps. It also adheres to producing causal\ninterpretations as validated with the help of counterfactual analysis. We aim\nto exhibit the visual performance and unbiased justifications for the model\ninferencing procedure achieved by MI CAM. Our approach works at par with all\nstate-of-the-art methods but particularly outperforms some in terms of\nqualitative and quantitative measures. The implementation of proposed method\ncan be found on https://anonymous.4open.science/r/MI-CAM-4D27", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6fc0\u6d3b\u6620\u5c04\u7684\u4e8b\u540e\u89c6\u89c9\u89e3\u91ca\u65b9\u6cd5MI CAM\uff0c\u4e0e\u4ee5\u5f80\u65b9\u6cd5\u4e0d\u540c\uff0c\u5b83\u901a\u8fc7\u4e92\u4fe1\u606f\u52a0\u6743\u7279\u5f81\u56fe\uff0c\u53ef\u4ea7\u751f\u56e0\u679c\u89e3\u91ca\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u4e14\u90e8\u5206\u6307\u6807\u66f4\u4f18\u3002", "motivation": "\u968f\u7740\u673a\u5668\u89c6\u89c9\u5e94\u7528\u589e\u591a\uff0c\u4eba\u4eec\u5173\u6ce8\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u673a\u5236\u548c\u63a8\u7406\u539f\u56e0\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89c6\u89c9\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u540d\u4e3aMI CAM\u7684\u4e8b\u540e\u89c6\u89c9\u89e3\u91ca\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u56fe\u4e0e\u8f93\u5165\u56fe\u50cf\u7684\u4e92\u4fe1\u606f\u52a0\u6743\uff0c\u7ebf\u6027\u7ec4\u5408\u6743\u91cd\u548c\u6fc0\u6d3b\u56fe\u751f\u6210\u7ed3\u679c\uff0c\u5e76\u501f\u52a9\u53cd\u4e8b\u5b9e\u5206\u6790\u9a8c\u8bc1\u56e0\u679c\u89e3\u91ca\u3002", "result": "\u8be5\u65b9\u6cd5\u6027\u80fd\u4e0e\u6240\u6709\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u6307\u6807\u4e0a\u5c24\u5176\u4f18\u4e8e\u90e8\u5206\u65b9\u6cd5\u3002", "conclusion": "MI CAM\u80fd\u5c55\u73b0\u89c6\u89c9\u6027\u80fd\uff0c\u4e3a\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u63d0\u4f9b\u65e0\u504f\u89e3\u91ca\uff0c\u6709\u8f83\u597d\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.09950", "pdf": "https://arxiv.org/pdf/2507.09950", "abs": "https://arxiv.org/abs/2507.09950", "authors": ["Shubham Shukla", "Kunal Sonalkar"], "title": "Can GPT-4o mini and Gemini 2.0 Flash Predict Fine-Grained Fashion Product Attributes? A Zero-Shot Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 2 figures", "summary": "The fashion retail business is centered around the capacity to comprehend\nproducts. Product attribution helps in comprehending products depending on the\nbusiness process. Quality attribution improves the customer experience as they\nnavigate through millions of products offered by a retail website. It leads to\nwell-organized product catalogs. In the end, product attribution directly\nimpacts the 'discovery experience' of the customer. Although large language\nmodels (LLMs) have shown remarkable capabilities in understanding multimodal\ndata, their performance on fine-grained fashion attribute recognition remains\nunder-explored. This paper presents a zero-shot evaluation of state-of-the-art\nLLMs that balance performance with speed and cost efficiency, mainly\nGPT-4o-mini and Gemini 2.0 Flash. We have used the dataset\nDeepFashion-MultiModal (https://github.com/yumingj/DeepFashion-MultiModal) to\nevaluate these models in the attribution tasks of fashion products. Our study\nevaluates these models across 18 categories of fashion attributes, offering\ninsight into where these models excel. We only use images as the sole input for\nproduct information to create a constrained environment. Our analysis shows\nthat Gemini 2.0 Flash demonstrates the strongest overall performance with a\nmacro F1 score of 56.79% across all attributes, while GPT-4o-mini scored a\nmacro F1 score of 43.28%. Through detailed error analysis, our findings provide\npractical insights for deploying these LLMs in production e-commerce product\nattribution-related tasks and highlight the need for domain-specific\nfine-tuning approaches. This work also lays the groundwork for future research\nin fashion AI and multimodal attribute extraction.", "AI": {"tldr": "\u672c\u6587\u5bf9GPT - 4o - mini\u548cGemini 2.0 Flash\u8fdb\u884c\u96f6\u6837\u672c\u8bc4\u4f30\uff0c\u7528\u56fe\u50cf\u8bc4\u4f30\u5176\u5728\u65f6\u5c1a\u4ea7\u54c1\u5c5e\u6027\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Gemini 2.0 Flash\u6574\u4f53\u8868\u73b0\u66f4\u5f3a\uff0c\u7814\u7a76\u4e3a\u7535\u5546\u4ea7\u54c1\u5c5e\u6027\u4efb\u52a1\u53ca\u65f6\u5c1aAI\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u65f6\u5c1a\u5c5e\u6027\u8bc6\u522b\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u800c\u4ea7\u54c1\u5c5e\u6027\u5bf9\u65f6\u5c1a\u96f6\u552e\u4e1a\u52a1\u5f88\u91cd\u8981\uff0c\u9700\u8bc4\u4f30\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528DeepFashion - MultiModal\u6570\u636e\u96c6\uff0c\u4ee5\u56fe\u50cf\u4e3a\u552f\u4e00\u8f93\u5165\uff0c\u5bf9GPT - 4o - mini\u548cGemini 2.0 Flash\u572818\u7c7b\u65f6\u5c1a\u5c5e\u6027\u4efb\u52a1\u4e2d\u8fdb\u884c\u96f6\u6837\u672c\u8bc4\u4f30\u3002", "result": "Gemini 2.0 Flash\u6574\u4f53\u8868\u73b0\u6700\u5f3a\uff0c\u5b8fF1\u5206\u6570\u4e3a56.79%\uff0cGPT - 4o - mini\u5b8fF1\u5206\u6570\u4e3a43.28%\u3002", "conclusion": "\u7814\u7a76\u4e3a\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u7535\u5546\u4ea7\u54c1\u5c5e\u6027\u76f8\u5173\u4efb\u52a1\u63d0\u4f9b\u5b9e\u7528\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u7279\u5b9a\u9886\u57df\u5fae\u8c03\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u65f6\u5c1aAI\u548c\u591a\u6a21\u6001\u5c5e\u6027\u63d0\u53d6\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.09966", "pdf": "https://arxiv.org/pdf/2507.09966", "abs": "https://arxiv.org/abs/2507.09966", "authors": ["Mingda Zhang"], "title": "A Brain Tumor Segmentation Method Based on CLIP and 3D U-Net with Cross-Modal Semantic Guidance and Multi-Level Feature Fusion", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "13 pages,6 figures", "summary": "Precise segmentation of brain tumors from magnetic resonance imaging (MRI) is\nessential for neuro-oncology diagnosis and treatment planning. Despite advances\nin deep learning methods, automatic segmentation remains challenging due to\ntumor morphological heterogeneity and complex three-dimensional spatial\nrelationships. Current techniques primarily rely on visual features extracted\nfrom MRI sequences while underutilizing semantic knowledge embedded in medical\nreports. This research presents a multi-level fusion architecture that\nintegrates pixel-level, feature-level, and semantic-level information,\nfacilitating comprehensive processing from low-level data to high-level\nconcepts. The semantic-level fusion pathway combines the semantic understanding\ncapabilities of Contrastive Language-Image Pre-training (CLIP) models with the\nspatial feature extraction advantages of 3D U-Net through three mechanisms:\n3D-2D semantic bridging, cross-modal semantic guidance, and semantic-based\nattention mechanisms. Experimental validation on the BraTS 2020 dataset\ndemonstrates that the proposed model achieves an overall Dice coefficient of\n0.8567, representing a 4.8% improvement compared to traditional 3D U-Net, with\na 7.3% Dice coefficient increase in the clinically important enhancing tumor\n(ET) region.", "AI": {"tldr": "\u63d0\u51fa\u591a\u7ea7\u522b\u878d\u5408\u67b6\u6784\u8fdb\u884c\u8111\u80bf\u7624\u5206\u5272\uff0c\u5728BraTS 2020\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548\u679c\u63d0\u5347", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u8111\u80bf\u7624\u81ea\u52a8\u5206\u5272\u4e0a\u56e0\u80bf\u7624\u5f62\u6001\u5f02\u8d28\u6027\u548c\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u5b58\u5728\u6311\u6218\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528\u533b\u5b66\u62a5\u544a\u8bed\u4e49\u77e5\u8bc6", "method": "\u63d0\u51fa\u591a\u7ea7\u522b\u878d\u5408\u67b6\u6784\uff0c\u8bed\u4e49\u7ea7\u878d\u5408\u7ed3\u5408CLIP\u6a21\u578b\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u4e0e3D U - Net\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u4f18\u52bf\uff0c\u901a\u8fc73D - 2D\u8bed\u4e49\u6865\u63a5\u3001\u8de8\u6a21\u6001\u8bed\u4e49\u5f15\u5bfc\u548c\u57fa\u4e8e\u8bed\u4e49\u7684\u6ce8\u610f\u529b\u673a\u5236", "result": "\u5728BraTS 2020\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u6574\u4f53Dice\u7cfb\u6570\u8fbe0.8567\uff0c\u6bd4\u4f20\u7edf3D U - Net\u63d0\u53474.8%\uff0c\u589e\u5f3a\u80bf\u7624\u533a\u57dfDice\u7cfb\u6570\u63d0\u53477.3%", "conclusion": "\u8be5\u591a\u7ea7\u522b\u878d\u5408\u67b6\u6784\u5728\u8111\u80bf\u7624\u5206\u5272\u4e0a\u6709\u66f4\u597d\u8868\u73b0"}}
{"id": "2507.09118", "pdf": "https://arxiv.org/pdf/2507.09118", "abs": "https://arxiv.org/abs/2507.09118", "authors": ["Linlan Huang", "Xusheng Cao", "Haori Lu", "Yifan Meng", "Fei Yang", "Xialei Liu"], "title": "Mind the Gap: Preserving and Compensating for the Modality Gap in CLIP-Based Continual Learning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICCV 2025", "summary": "Continual learning aims to enable models to learn sequentially from\ncontinuously incoming data while retaining performance on previously learned\ntasks. With the Contrastive Language-Image Pre-trained model (CLIP) exhibiting\nstrong capabilities across various downstream tasks, there has been growing\ninterest in leveraging CLIP for continual learning in such scenarios. Most\nexisting works overlook the inherent modality gap in CLIP, a key factor in its\ngeneralization and adaptability. In this paper, we analyze the variations in\nthe modality gap during the fine-tuning of vision-language pre-trained models.\nOur observations reveal that the modality gap effectively reflects the extent\nto which pre-trained knowledge is preserved. Based on these insights, we\npropose a simple yet effective method, MG-CLIP, that improves CLIP's\nperformance in class-incremental learning. Our approach leverages modality gap\npreservation to mitigate forgetting and modality gap compensation to enhance\nthe capacity for new data, introducing a novel modality-gap-based perspective\nfor continual learning. Extensive experiments on multiple benchmarks\ndemonstrate that our method outperforms existing approaches without requiring\nadditional replay data. Our code is available at\nhttps://github.com/linlany/MindtheGap.", "AI": {"tldr": "\u6587\u7ae0\u5206\u6790\u89c6\u89c9\u8bed\u8a00\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u65f6\u6a21\u6001\u5dee\u8ddd\u53d8\u5316\uff0c\u63d0\u51faMG - CLIP\u65b9\u6cd5\u63d0\u5347CLIP\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u65e0\u9700\u989d\u5916\u91cd\u653e\u6570\u636e\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u53d7\u5173\u6ce8\uff0c\u73b0\u6709\u5229\u7528CLIP\u8fdb\u884c\u6301\u7eed\u5b66\u4e60\u7684\u5de5\u4f5c\u5ffd\u89c6\u5176\u56fa\u6709\u6a21\u6001\u5dee\u8ddd\u8fd9\u4e00\u5f71\u54cd\u6cdb\u5316\u548c\u9002\u5e94\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u5206\u6790\u89c6\u89c9\u8bed\u8a00\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u65f6\u6a21\u6001\u5dee\u8ddd\u53d8\u5316\uff0c\u63d0\u51faMG - CLIP\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u6001\u5dee\u8ddd\u4fdd\u7559\u7f13\u89e3\u9057\u5fd8\uff0c\u5229\u7528\u6a21\u6001\u5dee\u8ddd\u8865\u507f\u589e\u5f3a\u65b0\u6570\u636e\u5904\u7406\u80fd\u529b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u91cd\u653e\u6570\u636e\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u6001\u5dee\u8ddd\u7684\u65b0\u89c6\u89d2\u7528\u4e8e\u6301\u7eed\u5b66\u4e60\uff0cMG - CLIP\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86CLIP\u5728\u7c7b\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.09973", "pdf": "https://arxiv.org/pdf/2507.09973", "abs": "https://arxiv.org/abs/2507.09973", "authors": ["Sarah Pan"], "title": "Tiny Reward Models", "categories": ["cs.CL", "cs.AI"], "comment": "2025 ICML Efficient Systems for Foundation Models Workshop", "summary": "Large decoder-based language models have become the dominant architecture for\nreward modeling in reinforcement learning from human feedback (RLHF). However,\nas reward models are increasingly deployed in test-time strategies, their\ninference costs become a growing concern. We present TinyRM, a family of small,\nbidirectional masked language models (MLMs) with as few as 400 million\nparameters, that rival the capabilities of models over 175 times larger on\nreasoning and safety preference modeling tasks. TinyRM combines FLAN-style\nprompting, Directional Low-Rank Adaptation (DoRA), and layer freezing to\nachieve strong performance on RewardBench, despite using significantly fewer\nresources. Our experiments suggest that small models benefit from\ndomain-specific tuning strategies, particularly in reasoning, where lightweight\nfinetuning methods are especially effective. While challenges remain in\nbuilding generalist models and conversational preference modeling, our\npreliminary results highlight the promise of lightweight bidirectional\narchitectures as efficient, scalable alternatives for preference modeling.", "AI": {"tldr": "\u63d0\u51faTinyRM\u5c0f\u6a21\u578b\u5728\u63a8\u7406\u548c\u5b89\u5168\u504f\u597d\u5efa\u6a21\u4efb\u52a1\u4e0a\u53ef\u4e0e\u5927\u6a21\u578b\u5339\u654c\uff0c\u5f3a\u8c03\u5c0f\u6a21\u578b\u7279\u5b9a\u8c03\u4f18\u7b56\u7565\u6709\u6548\u3002", "motivation": "\u5927\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u5956\u52b1\u5efa\u6a21\u65f6\u63a8\u7406\u6210\u672c\u9ad8\uff0c\u9700\u66f4\u9ad8\u6548\u6a21\u578b\u3002", "method": "TinyRM\u7ed3\u5408FLAN\u5f0f\u63d0\u793a\u3001DoRA\u548c\u5c42\u51bb\u7ed3\u65b9\u6cd5\u3002", "result": "TinyRM\u5728RewardBench\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5c0f\u6a21\u578b\u7279\u5b9a\u8c03\u4f18\u7b56\u7565\u5728\u63a8\u7406\u4e2d\u6709\u6548\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u53cc\u5411\u67b6\u6784\u5728\u504f\u597d\u5efa\u6a21\u4e2d\u6709\u6210\u4e3a\u9ad8\u6548\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\u7684\u6f5c\u529b\uff0c\u4f46\u6784\u5efa\u901a\u7528\u6a21\u578b\u548c\u5bf9\u8bdd\u504f\u597d\u5efa\u6a21\u4ecd\u6709\u6311\u6218\u3002"}}
{"id": "2507.09985", "pdf": "https://arxiv.org/pdf/2507.09985", "abs": "https://arxiv.org/abs/2507.09985", "authors": ["Samson Yu", "Kelvin Lin", "Harold Soh"], "title": "Demonstrating the Octopi-1.5 Visual-Tactile-Language Model", "categories": ["cs.RO", "cs.AI"], "comment": "Published at R:SS 2025", "summary": "Touch is recognized as a vital sense for humans and an equally important\nmodality for robots, especially for dexterous manipulation, material\nidentification, and scenarios involving visual occlusion. Building upon very\nrecent work in touch foundation models, this demonstration will feature\nOctopi-1.5, our latest visual-tactile-language model. Compared to its\npredecessor, Octopi-1.5 introduces the ability to process tactile signals from\nmultiple object parts and employs a simple retrieval-augmented generation (RAG)\nmodule to improve performance on tasks and potentially learn new objects\non-the-fly. The system can be experienced live through a new handheld\ntactile-enabled interface, the TMI, equipped with GelSight and TAC-02 tactile\nsensors. This convenient and accessible setup allows users to interact with\nOctopi-1.5 without requiring a robot. During the demonstration, we will\nshowcase Octopi-1.5 solving tactile inference tasks by leveraging tactile\ninputs and commonsense knowledge. For example, in a Guessing Game, Octopi-1.5\nwill identify objects being grasped and respond to follow-up queries about how\nto handle it (e.g., recommending careful handling for soft fruits). We also\nplan to demonstrate Octopi-1.5's RAG capabilities by teaching it new items.\nWith live interactions, this demonstration aims to highlight both the progress\nand limitations of VTLMs such as Octopi-1.5 and to foster further interest in\nthis exciting field. Code for Octopi-1.5 and design files for the TMI gripper\nare available at https://github.com/clear-nus/octopi-1.5.", "AI": {"tldr": "\u4ecb\u7ecdOctopi - 1.5\u89c6\u89c9\u89e6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u901a\u8fc7\u65b0\u754c\u9762\u4f53\u9a8c\uff0c\u5c55\u793a\u5176\u89e3\u51b3\u89e6\u89c9\u63a8\u7406\u4efb\u52a1\u548c\u5b66\u4e60\u65b0\u7269\u54c1\u80fd\u529b\uff0c\u51f8\u663e\u8fdb\u5c55\u4e0e\u5c40\u9650\u3002", "motivation": "\u89e6\u89c9\u5bf9\u4eba\u7c7b\u548c\u673a\u5668\u4eba\u5f88\u91cd\u8981\uff0c\u57fa\u4e8e\u89e6\u89c9\u57fa\u7840\u6a21\u578b\u5de5\u4f5c\uff0c\u5c55\u793aOctopi - 1.5\u4ee5\u63a8\u52a8\u89c6\u89c9\u89e6\u89c9\u8bed\u8a00\u6a21\u578b\u9886\u57df\u53d1\u5c55\u3002", "method": "\u5f15\u5165\u5904\u7406\u591a\u7269\u4f53\u90e8\u5206\u89e6\u89c9\u4fe1\u53f7\u80fd\u529b\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u65b0\u624b\u6301\u89e6\u89c9\u754c\u9762TMI\u8ba9\u7528\u6237\u4ea4\u4e92\u3002", "result": "Octopi - 1.5\u80fd\u89e3\u51b3\u89e6\u89c9\u63a8\u7406\u4efb\u52a1\uff0c\u5982\u731c\u7269\u6e38\u620f\u4e2d\u8bc6\u522b\u7269\u4f53\u5e76\u7ed9\u51fa\u5904\u7406\u5efa\u8bae\uff0c\u53ef\u5b66\u4e60\u65b0\u7269\u54c1\u3002", "conclusion": "\u5c55\u793aOctopi - 1.5\u8fdb\u5c55\u4e0e\u5c40\u9650\uff0c\u6fc0\u53d1\u5bf9\u89c6\u89c9\u89e6\u89c9\u8bed\u8a00\u6a21\u578b\u9886\u57df\u5174\u8da3\uff0c\u4ee3\u7801\u548c\u8bbe\u8ba1\u6587\u4ef6\u5f00\u6e90\u3002"}}
{"id": "2507.09990", "pdf": "https://arxiv.org/pdf/2507.09990", "abs": "https://arxiv.org/abs/2507.09990", "authors": ["Ming Wen", "Jiaqi Zhu", "Yuedong Xu", "Yipeng Zhou", "Dingding Han"], "title": "Differentially Private Federated Low Rank Adaptation Beyond Fixed-Matrix", "categories": ["cs.CR", "cs.AI"], "comment": "23 pages, NeurIPS 2025 under review", "summary": "Large language models (LLMs) typically require fine-tuning for\ndomain-specific tasks, and LoRA offers a computationally efficient approach by\ntraining low-rank adapters. LoRA is also communication-efficient for federated\nLLMs when multiple users collaboratively fine-tune a global LLM model without\nsharing their proprietary raw data. However, even the transmission of local\nadapters between a server and clients risks serious privacy leakage. Applying\ndifferential privacy (DP) to federated LoRA encounters a dilemma: adding noise\nto both adapters amplifies synthetic noise on the model, while fixing one\nadapter impairs the learnability of fine-tuning. In this paper, we propose\nFedASK (Differentially Private Federated Low Rank Adaptation with Double\nSketching) , a novel federated LoRA framework to enable effective updating of\nboth low-rank adapters with robust differential privacy. Inspired by randomized\nSVD, our key idea is a two-stage sketching pipeline. This pipeline first\naggregates carefully sketched, privacy-preserving local updates, and then\nreconstructs the global matrices on the server to facilitate effective updating\nof both adapters. We theoretically prove FedASK's differential privacy\nguarantee and its exact aggregation property. Comprehensive experiments\ndemonstrate that FedASK consistently outperforms baseline methods across a\nvariety of privacy settings and data distributions.", "AI": {"tldr": "\u63d0\u51faFedASK\u6846\u67b6\u89e3\u51b3\u8054\u90a6LoRA\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u9690\u79c1\u6027\u548c\u805a\u5408\u7279\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "LoRA\u5728\u8054\u90a6\u5927\u8bed\u8a00\u6a21\u578b\u901a\u4fe1\u9ad8\u6548\uff0c\u4f46\u4f20\u8f93\u672c\u5730\u9002\u914d\u5668\u6709\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u5e94\u7528\u5dee\u5206\u9690\u79c1\u5b58\u5728\u56f0\u5883\u3002", "method": "\u63d0\u51faFedASK\u6846\u67b6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8349\u56fe\u7ba1\u9053\uff0c\u5148\u805a\u5408\u672c\u5730\u66f4\u65b0\uff0c\u518d\u5728\u670d\u52a1\u5668\u91cd\u5efa\u5168\u5c40\u77e9\u9635\u3002", "result": "\u7406\u8bba\u8bc1\u660eFedASK\u6709\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u548c\u7cbe\u786e\u805a\u5408\u7279\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u591a\u79cd\u9690\u79c1\u8bbe\u7f6e\u548c\u6570\u636e\u5206\u5e03\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedASK\u662f\u4e00\u79cd\u80fd\u5b9e\u73b0\u4f4e\u79e9\u9002\u914d\u5668\u6709\u6548\u66f4\u65b0\u5e76\u5177\u5907\u5f3a\u5927\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6LoRA\u6846\u67b6\u3002"}}
{"id": "2507.10015", "pdf": "https://arxiv.org/pdf/2507.10015", "abs": "https://arxiv.org/abs/2507.10015", "authors": ["Jaisidh Singh", "Diganta Misra", "Boris Knyazev", "Antonio Orvieto"], "title": "(Almost) Free Modality Stitching of Foundation Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Pre-print", "summary": "Foundation multi-modal models are often designed by stitching of multiple\nexisting pretrained uni-modal models: for example, an image classifier with an\nautoregressive text model. This stitching process is performed by training a\nconnector module that aims to align the representation-representation or\nrepresentation-input spaces of these uni-modal models. However, given the\ncomplexity of training such connectors on large scale web-based datasets\ncoupled with the ever-increasing number of available pretrained uni-modal\nmodels, the task of uni-modal models selection and subsequent connector module\ntraining becomes computationally demanding. To address this under-studied\ncritical problem, we propose Hypernetwork Model Alignment (Hyma), a novel\nall-in-one solution for optimal uni-modal model selection and connector\ntraining by leveraging hypernetworks. Specifically, our framework utilizes the\nparameter prediction capability of a hypernetwork to obtain jointly trained\nconnector modules for $N \\times M$ combinations of uni-modal models. In our\nexperiments, Hyma reduces the optimal uni-modal model pair search cost by\n$10\\times$ (averaged across all experiments), while matching the ranking and\ntrained connector performance obtained via grid search across a suite of\ndiverse multi-modal benchmarks.", "AI": {"tldr": "\u63d0\u51faHypernetwork Model Alignment (Hyma)\u89e3\u51b3\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u5355\u6a21\u6001\u6a21\u578b\u9009\u62e9\u548c\u8fde\u63a5\u5668\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u964d\u4f4e\u641c\u7d22\u6210\u672c\u4e14\u6027\u80fd\u76f8\u5f53\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u901a\u8fc7\u62fc\u63a5\u5355\u6a21\u6001\u6a21\u578b\uff0c\u8bad\u7ec3\u8fde\u63a5\u5668\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8ba1\u7b97\u9700\u6c42\u5927\uff0c\u4e14\u5355\u6a21\u6001\u6a21\u578b\u9009\u62e9\u548c\u8fde\u63a5\u5668\u8bad\u7ec3\u95ee\u9898\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51faHyma\u6846\u67b6\uff0c\u5229\u7528\u8d85\u7f51\u7edc\u7684\u53c2\u6570\u9884\u6d4b\u80fd\u529b\u4e3a\u5355\u6a21\u6001\u6a21\u578b\u7684N\u00d7M\u7ec4\u5408\u83b7\u5f97\u8054\u5408\u8bad\u7ec3\u7684\u8fde\u63a5\u5668\u6a21\u5757\u3002", "result": "Hyma\u5c06\u6700\u4f18\u5355\u6a21\u6001\u6a21\u578b\u5bf9\u7684\u641c\u7d22\u6210\u672c\u5e73\u5747\u964d\u4f4e\u4e8610\u500d\uff0c\u5728\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6392\u540d\u548c\u8bad\u7ec3\u8fde\u63a5\u5668\u6027\u80fd\u4e0e\u7f51\u683c\u641c\u7d22\u76f8\u5f53\u3002", "conclusion": "Hyma\u662f\u89e3\u51b3\u5355\u6a21\u6001\u6a21\u578b\u9009\u62e9\u548c\u8fde\u63a5\u5668\u8bad\u7ec3\u95ee\u9898\u7684\u6709\u6548\u4e00\u4f53\u5316\u65b9\u6848\u3002"}}
{"id": "2507.09160", "pdf": "https://arxiv.org/pdf/2507.09160", "abs": "https://arxiv.org/abs/2507.09160", "authors": ["Jialei Huang", "Shuo Wang", "Fanqi Lin", "Yihang Hu", "Chuan Wen", "Yang Gao"], "title": "Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models have shown remarkable achievements,\ndriven by the rich implicit knowledge of their vision-language components.\nHowever, achieving generalist robotic agents demands precise grounding into\nphysical interactions, especially in contact-rich scenarios where fine-grained\nforce control is essential. We advance VLAs' implicit knowledge beyond\nidentifying what to do, towards guiding how to physically interact with real\nworld. This paper introduces Tactile-VLA, a novel framework that deeply fuses\nvision, language, action, and tactile sensing. This framework incorporates a\nhybrid position-force controller to translate the model's intentions into\nprecise physical actions and a reasoning module that allows the robot to adapt\nits strategy based on tactile feedback. Experiments demonstrate Tactile-VLA's\neffectiveness and generalizability in three key aspects: (1) enabling\ntactile-aware instruction following, (2) utilizing tactile-relevant\ncommonsense, and (3) facilitating adaptive tactile-involved reasoning. A key\nfinding is that the VLM's prior knowledge already contains semantic\nunderstanding of physical interaction; by connecting it to the robot's tactile\nsensors with only a few demonstrations, we can activate this prior knowledge to\nachieve zero-shot generalization in contact-rich tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTactile - VLA\u6846\u67b6\uff0c\u878d\u5408\u89c6\u89c9\u3001\u8bed\u8a00\u3001\u52a8\u4f5c\u548c\u89e6\u89c9\u4f20\u611f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u4e09\u65b9\u9762\u6709\u6548\u4e14\u5177\u6cdb\u5316\u6027\uff0c\u8fd8\u80fd\u6fc0\u6d3bVLM\u5148\u9a8c\u77e5\u8bc6\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u73b0\u6709Vision - Language - Action (VLA)\u6a21\u578b\u867d\u6709\u6210\u679c\uff0c\u4f46\u901a\u7528\u673a\u5668\u4eba\u4ee3\u7406\u9700\u7cbe\u786e\u843d\u5b9e\u5230\u7269\u7406\u4ea4\u4e92\uff0c\u5c24\u5176\u662f\u5bcc\u63a5\u89e6\u573a\u666f\u4e2d\u7ec6\u7c92\u5ea6\u529b\u63a7\u5236\u3002", "method": "\u5f15\u5165Tactile - VLA\u6846\u67b6\uff0c\u878d\u5408\u89c6\u89c9\u3001\u8bed\u8a00\u3001\u52a8\u4f5c\u548c\u89e6\u89c9\u4f20\u611f\uff0c\u5305\u542b\u6df7\u5408\u4f4d\u7f6e - \u529b\u63a7\u5236\u5668\u548c\u63a8\u7406\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eTactile - VLA\u5728\u89e6\u89c9\u611f\u77e5\u6307\u4ee4\u8ddf\u968f\u3001\u5229\u7528\u89e6\u89c9\u76f8\u5173\u5e38\u8bc6\u3001\u4fc3\u8fdb\u81ea\u9002\u5e94\u89e6\u89c9\u63a8\u7406\u4e09\u65b9\u9762\u6709\u6548\u4e14\u5177\u6cdb\u5316\u6027\u3002", "conclusion": "VLM\u7684\u5148\u9a8c\u77e5\u8bc6\u5df2\u5305\u542b\u7269\u7406\u4ea4\u4e92\u8bed\u4e49\u7406\u89e3\uff0c\u901a\u8fc7\u5c11\u91cf\u6f14\u793a\u8fde\u63a5\u673a\u5668\u4eba\u89e6\u89c9\u4f20\u611f\u5668\u53ef\u6fc0\u6d3b\u8be5\u5148\u9a8c\u77e5\u8bc6\uff0c\u5b9e\u73b0\u5bcc\u63a5\u89e6\u4efb\u52a1\u96f6\u6837\u672c\u6cdb\u5316\u3002"}}
{"id": "2507.10056", "pdf": "https://arxiv.org/pdf/2507.10056", "abs": "https://arxiv.org/abs/2507.10056", "authors": ["A. K. M. Shoriful Islam", "Md. Rakib Hassan", "Macbah Uddin", "Md. Shahidur Rahman"], "title": "Lightweight Model for Poultry Disease Detection from Fecal Images Using Multi-Color Space Feature Optimization and Machine Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Poultry farming is a vital component of the global food supply chain, yet it\nremains highly vulnerable to infectious diseases such as coccidiosis,\nsalmonellosis, and Newcastle disease. This study proposes a lightweight machine\nlearning-based approach to detect these diseases by analyzing poultry fecal\nimages. We utilize multi-color space feature extraction (RGB, HSV, LAB) and\nexplore a wide range of color, texture, and shape-based descriptors, including\ncolor histograms, local binary patterns (LBP), wavelet transforms, and edge\ndetectors. Through a systematic ablation study and dimensionality reduction\nusing PCA and XGBoost feature selection, we identify a compact global feature\nset that balances accuracy and computational efficiency. An artificial neural\nnetwork (ANN) classifier trained on these features achieved 95.85% accuracy\nwhile requiring no GPU and only 638 seconds of execution time in Google Colab.\nCompared to deep learning models such as Xception and MobileNetV3, our proposed\nmodel offers comparable accuracy with drastically lower resource usage. This\nwork demonstrates a cost-effective, interpretable, and scalable alternative to\ndeep learning for real-time poultry disease detection in low-resource\nagricultural settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u5206\u6790\u5bb6\u79bd\u7caa\u4fbf\u56fe\u50cf\u68c0\u6d4b\u75be\u75c5\u7684\u65b9\u6cd5\uff0c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u76f8\u6bd4\u7cbe\u5ea6\u76f8\u5f53\u4f46\u8d44\u6e90\u4f7f\u7528\u5c11\uff0c\u9002\u5408\u4f4e\u8d44\u6e90\u519c\u4e1a\u573a\u666f\u3002", "motivation": "\u5bb6\u79bd\u517b\u6b96\u6613\u53d7\u4f20\u67d3\u75c5\u5f71\u54cd\uff0c\u9700\u6709\u6548\u75be\u75c5\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u591a\u989c\u8272\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\uff0c\u63a2\u7d22\u591a\u79cd\u989c\u8272\u3001\u7eb9\u7406\u548c\u5f62\u72b6\u63cf\u8ff0\u7b26\uff0c\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u548c\u964d\u7ef4\u786e\u5b9a\u7d27\u51d1\u5168\u5c40\u7279\u5f81\u96c6\uff0c\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u3002", "result": "\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\u51c6\u786e\u7387\u8fbe95.85%\uff0c\u65e0\u9700GPU\uff0c\u5728Google Colab\u6267\u884c\u65f6\u95f4\u4ec5638\u79d2\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u4f4e\u8d44\u6e90\u519c\u4e1a\u573a\u666f\u4e2d\u5b9e\u65f6\u5bb6\u79bd\u75be\u75c5\u68c0\u6d4b\u7684\u7ecf\u6d4e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.09166", "pdf": "https://arxiv.org/pdf/2507.09166", "abs": "https://arxiv.org/abs/2507.09166", "authors": ["Louise Largeau", "Erwan Koch", "David Leutwyler", "Gregoire Mariethoz", "Valerie Chavez-Demoulin", "Tom Beucler"], "title": "Investigating the Robustness of Extreme Precipitation Super-Resolution Across Climates", "categories": ["physics.ao-ph", "cs.LG"], "comment": "31 pages, 9 figures, 1 table, submitted to AGU JAMES", "summary": "The coarse spatial resolution of gridded climate models, such as general\ncirculation models, limits their direct use in projecting socially relevant\nvariables like extreme precipitation. Most downscaling methods estimate the\nconditional distributions of extremes by generating large ensembles,\ncomplicating the assessment of robustness under distributional shifts, such as\nthose induced by climate change. To better understand and potentially improve\nrobustness, we propose super-resolving the parameters of the target variable's\nprobability distribution directly using analytically tractable mappings. Within\na perfect-model framework over Switzerland, we demonstrate that vector\ngeneralized linear and additive models can super-resolve the generalized\nextreme value distribution of summer hourly precipitation extremes from coarse\nprecipitation fields and topography. We introduce the notion of a \"robustness\ngap\", defined as the difference in predictive error between present-trained and\nfuture-trained models, and use it to diagnose how model structure affects the\ngeneralization of each quantile to a pseudo-global warming scenario. By\nevaluating multiple model configurations, we also identify an upper limit on\nthe super-resolution factor based on the spatial auto- and cross-correlation of\nprecipitation and elevation, beyond which coarse precipitation loses predictive\nvalue. Our framework is broadly applicable to variables governed by parametric\ndistributions and offers a model-agnostic diagnostic for understanding when and\nwhy empirical downscaling generalizes to climate change and extremes.", "AI": {"tldr": "\u63d0\u51fa\u7528\u89e3\u6790\u6620\u5c04\u8d85\u5206\u8fa8\u7387\u5904\u7406\u76ee\u6807\u53d8\u91cf\u6982\u7387\u5206\u5e03\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u5728\u745e\u58eb\u5b8c\u7f8e\u6a21\u578b\u6846\u67b6\u4e0b\u9a8c\u8bc1\uff0c\u5f15\u5165'\u9c81\u68d2\u6027\u5dee\u8ddd'\u6982\u5ff5\u8bca\u65ad\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u8fd8\u786e\u5b9a\u8d85\u5206\u8fa8\u7387\u56e0\u5b50\u4e0a\u9650\u3002", "motivation": "\u7f51\u683c\u6c14\u5019\u6a21\u578b\u7a7a\u95f4\u5206\u8fa8\u7387\u7c97\uff0c\u591a\u6570\u964d\u5c3a\u5ea6\u65b9\u6cd5\u96be\u8bc4\u4f30\u5206\u5e03\u53d8\u5316\u4e0b\u9c81\u68d2\u6027\uff0c\u9700\u66f4\u597d\u7406\u89e3\u548c\u63d0\u5347\u9c81\u68d2\u6027\u3002", "method": "\u7528\u89e3\u6790\u6620\u5c04\u76f4\u63a5\u8d85\u5206\u8fa8\u7387\u5904\u7406\u76ee\u6807\u53d8\u91cf\u6982\u7387\u5206\u5e03\u53c2\u6570\uff0c\u91c7\u7528\u5411\u91cf\u5e7f\u4e49\u7ebf\u6027\u548c\u52a0\u6cd5\u6a21\u578b\uff0c\u5f15\u5165'\u9c81\u68d2\u6027\u5dee\u8ddd'\u6982\u5ff5\uff0c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\u914d\u7f6e\u3002", "result": "\u5411\u91cf\u5e7f\u4e49\u7ebf\u6027\u548c\u52a0\u6cd5\u6a21\u578b\u80fd\u4ece\u7c97\u964d\u6c34\u573a\u548c\u5730\u5f62\u8d85\u5206\u8fa8\u7387\u5904\u7406\u590f\u5b63\u5c0f\u65f6\u964d\u6c34\u6781\u503c\u7684\u5e7f\u4e49\u6781\u503c\u5206\u5e03\uff1b\u786e\u5b9a\u57fa\u4e8e\u964d\u6c34\u548c\u6d77\u62d4\u7a7a\u95f4\u81ea\u76f8\u5173\u548c\u4e92\u76f8\u5173\u7684\u8d85\u5206\u8fa8\u7387\u56e0\u5b50\u4e0a\u9650\u3002", "conclusion": "\u8be5\u6846\u67b6\u5e7f\u6cdb\u9002\u7528\u4e8e\u53c2\u6570\u5206\u5e03\u53d8\u91cf\uff0c\u63d0\u4f9b\u6a21\u578b\u65e0\u5173\u8bca\u65ad\uff0c\u5e2e\u52a9\u7406\u89e3\u7ecf\u9a8c\u964d\u5c3a\u5ea6\u4f55\u65f6\u53ca\u4e3a\u4f55\u80fd\u63a8\u5e7f\u5230\u6c14\u5019\u53d8\u5316\u548c\u6781\u7aef\u60c5\u51b5\u3002"}}
{"id": "2507.09185", "pdf": "https://arxiv.org/pdf/2507.09185", "abs": "https://arxiv.org/abs/2507.09185", "authors": ["Ameen Ali", "Shahar Katz", "Lior Wolf", "Ivan Titov"], "title": "Detecting and Pruning Prominent but Detrimental Neurons in Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) often develop learned mechanisms specialized to\nspecific datasets, such as reliance on domain-specific correlations, which\nyield high-confidence predictions without generalizable reasoning. While\nbeneficial in one setting, these dataset-specific mechanisms typically degrade\nperformance when models encounter novel tasks or distributions. In this work,\nwe introduce a fine-tuning approach designed to enhance generalization by\nidentifying and pruning neurons associated with dataset-specific mechanisms in\ntransformer-based LLMs. Our method employs Integrated Gradients to quantify\neach neuron's influence on high-confidence predictions, pinpointing those that\ndisproportionately contribute to dataset-specific performance without\nsupporting robust, transferable reasoning. Selectively pruning these neurons\ncompels the model to depend on generalizable representations. Evaluated across\nmultiple-choice benchmarks, our pruning-based fine-tuning significantly\nenhances performance, surpassing prior (non-pruning) adaptation methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u4fee\u526a\u4e0e\u7279\u5b9a\u6570\u636e\u96c6\u673a\u5236\u76f8\u5173\u7684\u795e\u7ecf\u5143\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u9879\u9009\u62e9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e38\u53d1\u5c55\u51fa\u7279\u5b9a\u6570\u636e\u96c6\u7684\u5b66\u4e60\u673a\u5236\uff0c\u5728\u9047\u5230\u65b0\u4efb\u52a1\u6216\u5206\u5e03\u65f6\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u9700\u8981\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u7efc\u5408\u68af\u5ea6\u91cf\u5316\u6bcf\u4e2a\u795e\u7ecf\u5143\u5bf9\u9ad8\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u627e\u51fa\u5bf9\u7279\u5b9a\u6570\u636e\u96c6\u6027\u80fd\u8d21\u732e\u5927\u4f46\u4e0d\u652f\u6301\u53ef\u8fc1\u79fb\u63a8\u7406\u7684\u795e\u7ecf\u5143\u5e76\u9009\u62e9\u6027\u4fee\u526a\u3002", "result": "\u57fa\u4e8e\u4fee\u526a\u7684\u5fae\u8c03\u5728\u591a\u9879\u9009\u62e9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u8d85\u8fc7\u4e86\u5148\u524d\u7684\uff08\u975e\u4fee\u526a\uff09\u9002\u5e94\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u548c\u4fee\u526a\u4e0e\u7279\u5b9a\u6570\u636e\u96c6\u673a\u5236\u76f8\u5173\u7684\u795e\u7ecf\u5143\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.10073", "pdf": "https://arxiv.org/pdf/2507.10073", "abs": "https://arxiv.org/abs/2507.10073", "authors": ["Simon M\u00fcnker"], "title": "Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires", "categories": ["cs.CL", "cs.AI"], "comment": "15pages, 1 figure, 2 tables", "summary": "Are AI systems truly representing human values, or merely averaging across\nthem? Our study suggests a concerning reality: Large Language Models (LLMs)\nfail to represent diverse cultural moral frameworks despite their linguistic\ncapabilities. We expose significant gaps between AI-generated and human moral\nintuitions by applying the Moral Foundations Questionnaire across 19 cultural\ncontexts. Comparing multiple state-of-the-art LLMs' origins against human\nbaseline data, we find these models systematically homogenize moral diversity.\nSurprisingly, increased model size doesn't consistently improve cultural\nrepresentation fidelity. Our findings challenge the growing use of LLMs as\nsynthetic populations in social science research and highlight a fundamental\nlimitation in current AI alignment approaches. Without data-driven alignment\nbeyond prompting, these systems cannot capture the nuanced, culturally-specific\nmoral intuitions. Our results call for more grounded alignment objectives and\nevaluation metrics to ensure AI systems represent diverse human values rather\nthan flattening the moral landscape.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u4ee3\u8868\u591a\u5143\u6587\u5316\u9053\u5fb7\u6846\u67b6\uff0c\u6311\u6218\u4e86\u5176\u5728\u793e\u79d1\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u547c\u5401\u66f4\u5408\u7406\u7684\u5bf9\u9f50\u76ee\u6807\u548c\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u63a2\u7a76AI\u7cfb\u7edf\u662f\u5426\u771f\u6b63\u4ee3\u8868\u4eba\u7c7b\u4ef7\u503c\u89c2\uff0c\u800c\u975e\u7b80\u5355\u5e73\u5747\u3002", "method": "\u572819\u79cd\u6587\u5316\u80cc\u666f\u4e0b\u5e94\u7528\u9053\u5fb7\u57fa\u7840\u95ee\u5377\uff0c\u5bf9\u6bd4\u591a\u4e2a\u6700\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u57fa\u7ebf\u6570\u636e\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u6027\u5730\u4f7f\u9053\u5fb7\u591a\u6837\u6027\u540c\u8d28\u5316\uff0c\u6a21\u578b\u89c4\u6a21\u589e\u52a0\u4e0d\u4e00\u5b9a\u80fd\u63d0\u5347\u6587\u5316\u8868\u5f81\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u5f53\u524dAI\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u5c40\u9650\uff0c\u9700\u8981\u57fa\u4e8e\u6570\u636e\u7684\u5bf9\u9f50\u76ee\u6807\u548c\u8bc4\u4f30\u6307\u6807\u6765\u786e\u4fddAI\u4ee3\u8868\u591a\u5143\u4eba\u7c7b\u4ef7\u503c\u89c2\u3002"}}
{"id": "2507.09222", "pdf": "https://arxiv.org/pdf/2507.09222", "abs": "https://arxiv.org/abs/2507.09222", "authors": ["Behraj Khan", "Tahir Syed"], "title": "Calibrated and Robust Foundation Models for Vision-Language and Medical Image Tasks Under Distribution Shift", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Foundation models like CLIP and SAM have transformed computer vision and\nmedical imaging via low-shot transfer learning. However, deployment of these\nmodels hindered by two key challenges: \\textit{distribution shift} between\ntraining and test data, and \\textit{confidence misalignment} that leads to\noverconfident incorrect predictions. These issues manifest differently in\nvision-language classification and medical segmentation tasks, yet existing\nsolutions remain domain-specific. We propose \\textit{StaRFM}, a unified\nframework addressing both challenges. It introduces a Fisher information\npenalty (FIP), extended to 3D medical data via patch-wise regularization, to\nreduce covariate shift in CLIP and SAM embeddings. Additionally, a confidence\nmisalignment penalty (CMP), reformulated for voxel-level predictions,\ncalibrates uncertainty in segmentation tasks. We theoretically derive PAC-Bayes\nbounds showing FIP controls generalization via the Fisher-Rao norm, while CMP\nminimizes calibration error through Brier score optimization. StaRFM shows\nconsistent performance like \\texttt{+}3.5\\% accuracy and 28\\% lower ECE on 19\nvision datasets (e.g., ImageNet, Office-Home), 84.7\\% DSC and 4.8mm HD95 in\nmedical segmentation (e.g., BraTS, ATLAS), and 40\\% lower cross-domain\nperformance gap compared to prior benchmarking methods. The framework is\nplug-and-play, requiring minimal architectural changes for seamless integration\nwith foundation models. Code and models will be released at\nhttps://anonymous.4open.science/r/StaRFM-C0CD/README.md", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6StaRFM\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u90e8\u7f72\u7684\u5206\u5e03\u504f\u79fb\u548c\u7f6e\u4fe1\u5ea6\u5931\u8c03\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u8868\u73b0\u826f\u597d\uff0c\u6846\u67b6\u5373\u63d2\u5373\u7528\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u90e8\u7f72\u65f6\u5b58\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u504f\u79fb\u3001\u7f6e\u4fe1\u5ea6\u5931\u8c03\u95ee\u9898\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u662f\u7279\u5b9a\u9886\u57df\u7684\uff0c\u9700\u8981\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faStaRFM\u6846\u67b6\uff0c\u5f15\u5165Fisher\u4fe1\u606f\u60e9\u7f5a\u9879\uff08FIP\uff09\u51cf\u5c11\u5d4c\u5165\u4e2d\u7684\u534f\u53d8\u91cf\u504f\u79fb\uff0c\u7f6e\u4fe1\u5ea6\u5931\u8c03\u60e9\u7f5a\u9879\uff08CMP\uff09\u6821\u51c6\u5206\u5272\u4efb\u52a1\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u7406\u8bba\u63a8\u5bfcPAC - Bayes\u8fb9\u754c\u3002", "result": "\u572819\u4e2a\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u63d0\u53473.5%\u3001ECE\u964d\u4f4e28%\uff0c\u533b\u5b66\u5206\u5272\u8fbe\u523084.7% DSC\u548c4.8mm HD95\uff0c\u8de8\u57df\u6027\u80fd\u5dee\u8ddd\u964d\u4f4e40%\u3002", "conclusion": "StaRFM\u6846\u67b6\u6709\u6548\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u90e8\u7f72\u6311\u6218\uff0c\u53ef\u4e0e\u57fa\u7840\u6a21\u578b\u65e0\u7f1d\u96c6\u6210\u3002"}}
{"id": "2507.10075", "pdf": "https://arxiv.org/pdf/2507.10075", "abs": "https://arxiv.org/abs/2507.10075", "authors": ["Jie Pan", "Tianyi Wang", "Yangyang Wang", "Junfeng Jiao", "Christian Claudel"], "title": "TGLD: A Trust-Aware Game-Theoretic Lane-Changing Decision Framework for Automated Vehicles in Heterogeneous Traffic", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "comment": "6 pages, 7 figures, accepted for IEEE International Conference on\n  Intelligent Transportation Systems (ITSC) 2025", "summary": "Automated vehicles (AVs) face a critical need to adopt socially compatible\nbehaviors and cooperate effectively with human-driven vehicles (HVs) in\nheterogeneous traffic environment. However, most existing lane-changing\nframeworks overlook HVs' dynamic trust levels, limiting their ability to\naccurately predict human driver behaviors. To address this gap, this study\nproposes a trust-aware game-theoretic lane-changing decision (TGLD) framework.\nFirst, we formulate a multi-vehicle coalition game, incorporating fully\ncooperative interactions among AVs and partially cooperative behaviors from HVs\ninformed by real-time trust evaluations. Second, we develop an online trust\nevaluation method to dynamically estimate HVs' trust levels during\nlane-changing interactions, guiding AVs to select context-appropriate\ncooperative maneuvers. Lastly, social compatibility objectives are considered\nby minimizing disruption to surrounding vehicles and enhancing the\npredictability of AV behaviors, thereby ensuring human-friendly and\ncontext-adaptive lane-changing strategies. A human-in-the-loop experiment\nconducted in a highway on-ramp merging scenario validates our TGLD approach.\nResults show that AVs can effectively adjust strategies according to different\nHVs' trust levels and driving styles. Moreover, incorporating a trust mechanism\nsignificantly improves lane-changing efficiency, maintains safety, and\ncontributes to transparent and adaptive AV-HV interactions.", "AI": {"tldr": "\u63d0\u51fa\u4fe1\u4efb\u611f\u77e5\u535a\u5f08\u8bba\u8f66\u9053\u53d8\u6362\u51b3\u7b56\uff08TGLD\uff09\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u53ef\u8ba9\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6839\u636e\u4eba\u7c7b\u9a7e\u9a76\u4fe1\u4efb\u6c34\u5e73\u8c03\u6574\u7b56\u7565\uff0c\u63d0\u5347\u6548\u7387\u4e0e\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u8f66\u9053\u53d8\u6362\u6846\u67b6\u5ffd\u89c6\u4eba\u7c7b\u9a7e\u9a76\u8f66\u8f86\u52a8\u6001\u4fe1\u4efb\u6c34\u5e73\uff0c\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u4eba\u7c7b\u9a7e\u9a76\u5458\u884c\u4e3a\u3002", "method": "\u6784\u5efa\u591a\u8f66\u8f86\u8054\u76df\u535a\u5f08\uff0c\u5f00\u53d1\u5728\u7ebf\u4fe1\u4efb\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8003\u8651\u793e\u4f1a\u517c\u5bb9\u6027\u76ee\u6807\u3002", "result": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u80fd\u6839\u636e\u4eba\u7c7b\u9a7e\u9a76\u4fe1\u4efb\u6c34\u5e73\u548c\u9a7e\u9a76\u98ce\u683c\u8c03\u6574\u7b56\u7565\uff0c\u5f15\u5165\u4fe1\u4efb\u673a\u5236\u63d0\u5347\u8f66\u9053\u53d8\u6362\u6548\u7387\u3001\u7ef4\u62a4\u5b89\u5168\uff0c\u4fc3\u8fdb\u900f\u660e\u81ea\u9002\u5e94\u4ea4\u4e92\u3002", "conclusion": "TGLD\u6846\u67b6\u6709\u6548\u53ef\u884c\uff0c\u80fd\u5b9e\u73b0\u4eba\u7c7b\u53cb\u597d\u4e14\u9002\u5e94\u73af\u5883\u7684\u8f66\u9053\u53d8\u6362\u7b56\u7565\u3002"}}
{"id": "2507.10085", "pdf": "https://arxiv.org/pdf/2507.10085", "abs": "https://arxiv.org/abs/2507.10085", "authors": ["Chenxi Huang", "Shaotian Yan", "Liang Xie", "Binbin Lin", "Sinan Fan", "Yue Xin", "Deng Cai", "Chen Shen", "Jieping Ye"], "title": "Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL 2025", "summary": "Representation Fine-tuning (ReFT), a recently proposed Parameter-Efficient\nFine-Tuning (PEFT) method, has attracted widespread attention for significantly\nimproving parameter efficiency by editing representation space alone. In this\nwork, we investigate applying ReFT to complex reasoning tasks. However,\ndirectly using the native ReFT method, which modifies fixed representations at\nthe beginning and end of each layer, yields suboptimal performance, as these\nfixed-position representations have uncertain impact on the outputs. We observe\nthat, in complex reasoning tasks, there often exist certain critical\nrepresentations. These representations either integrate significant information\nfrom preceding layers or regulate subsequent layer representations. Through\nlayer-by-layer propagation, they exert a substantial influence on the final\noutput. Naturally, fine-tuning these critical representations has the potential\nto greatly enhance reasoning performance. Building upon these insights, we\npropose Critical Representation Fine-Tuning (CRFT), a novel method that\nidentifies and optimizes these critical representations through information\nflow analysis. CRFT operates within a supervised learning framework,\ndynamically optimizing critical representations in a low-rank linear subspace\nwhile freezing the base model. The effectiveness and efficiency of our method\nare validated across eight benchmarks for arithmetic and commonsense reasoning,\nusing LLaMA and Mistral model families. Furthermore, our method also adapts\neffectively to few-shot settings, boosting one-shot accuracy by 16.4%. Our work\nhighlights the untapped potential of representation-level optimization for CoT\nreasoning, offering a lightweight yet powerful alternative to traditional PEFT\nmethods.", "AI": {"tldr": "\u63d0\u51faCRFT\u65b9\u6cd5\u7528\u4e8e\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u6548\u679c\uff0c\u8fd8\u9002\u5e94\u5c11\u6837\u672c\u8bbe\u7f6e\u3002", "motivation": "\u76f4\u63a5\u7528\u539f\u751fReFT\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u6539\u8fdb\u4ee5\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "method": "\u63d0\u51faCRFT\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fe1\u606f\u6d41\u5206\u6790\u8bc6\u522b\u548c\u4f18\u5316\u5173\u952e\u8868\u5f81\uff0c\u5728\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u4e0b\u52a8\u6001\u4f18\u5316\u4f4e\u79e9\u7ebf\u6027\u5b50\u7a7a\u95f4\u4e2d\u7684\u5173\u952e\u8868\u5f81\uff0c\u51bb\u7ed3\u57fa\u7840\u6a21\u578b\u3002", "result": "\u5728\u516b\u4e2a\u7b97\u672f\u548c\u5e38\u8bc6\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u9002\u5e94\u5c11\u6837\u672c\u8bbe\u7f6e\uff0c\u63d0\u5347\u5355\u6837\u672c\u51c6\u786e\u738716.4%\u3002", "conclusion": "\u51f8\u663e\u8868\u5f81\u7ea7\u4f18\u5316\u5bf9\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6f5c\u529b\uff0c\u662f\u4f20\u7edfPEFT\u65b9\u6cd5\u7684\u8f7b\u91cf\u7ea7\u5f3a\u5927\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2507.09282", "pdf": "https://arxiv.org/pdf/2507.09282", "abs": "https://arxiv.org/abs/2507.09282", "authors": ["Dominika Woszczyk", "Ranya Aloufi", "Soteris Demetriou"], "title": "ClaritySpeech: Dementia Obfuscation in Speech", "categories": ["cs.CL", "cs.CR", "cs.LG", "cs.SD", "eess.AS"], "comment": "Accepted at Interspeech 2025", "summary": "Dementia, a neurodegenerative disease, alters speech patterns, creating\ncommunication barriers and raising privacy concerns. Current speech\ntechnologies, such as automatic speech transcription (ASR), struggle with\ndementia and atypical speech, further challenging accessibility. This paper\npresents a novel dementia obfuscation in speech framework, ClaritySpeech,\nintegrating ASR, text obfuscation, and zero-shot text-to-speech (TTS) to\ncorrect dementia-affected speech while preserving speaker identity in low-data\nenvironments without fine-tuning. Results show a 16% and 10% drop in mean F1\nscore across various adversarial settings and modalities (audio, text, fusion)\nfor ADReSS and ADReSSo, respectively, maintaining 50% speaker similarity. We\nalso find that our system improves WER (from 0.73 to 0.08 for ADReSS and 0.15\nfor ADReSSo) and speech quality from 1.65 to ~2.15, enhancing privacy and\naccessibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u75f4\u5446\u8bed\u97f3\u6df7\u6dc6\u6846\u67b6ClaritySpeech\uff0c\u53ef\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e0b\u4fee\u6b63\u53d7\u75f4\u5446\u5f71\u54cd\u7684\u8bed\u97f3\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u63d0\u5347\u9690\u79c1\u548c\u53ef\u8bbf\u95ee\u6027\u3002", "motivation": "\u75f4\u5446\u4f1a\u6539\u53d8\u8bed\u97f3\u6a21\u5f0f\uff0c\u73b0\u6709\u8bed\u97f3\u6280\u672f\u96be\u4ee5\u5904\u7406\u75f4\u5446\u548c\u975e\u5178\u578b\u8bed\u97f3\uff0c\u5b58\u5728\u6c9f\u901a\u969c\u788d\u548c\u9690\u79c1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u540d\u4e3aClaritySpeech\u7684\u75f4\u5446\u8bed\u97f3\u6df7\u6dc6\u6846\u67b6\uff0c\u96c6\u6210\u81ea\u52a8\u8bed\u97f3\u8f6c\u5f55\u3001\u6587\u672c\u6df7\u6dc6\u548c\u96f6\u6837\u672c\u6587\u672c\u8f6c\u8bed\u97f3\u6280\u672f\u3002", "result": "\u5728\u4e0d\u540c\u5bf9\u6297\u8bbe\u7f6e\u548c\u6a21\u6001\u4e0b\uff0cADReSS\u548cADReSSo\u7684\u5e73\u5747F1\u5206\u6570\u5206\u522b\u4e0b\u964d16%\u548c10%\uff0c\u4fdd\u630150%\u8bf4\u8bdd\u4eba\u76f8\u4f3c\u5ea6\uff1b\u63d0\u5347WER\u548c\u8bed\u97f3\u8d28\u91cf\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u63d0\u5347\u9690\u79c1\u548c\u53ef\u8bbf\u95ee\u6027\u3002"}}
{"id": "2507.09291", "pdf": "https://arxiv.org/pdf/2507.09291", "abs": "https://arxiv.org/abs/2507.09291", "authors": ["Yuval Grader", "Hadar Averbuch-Elor"], "title": "Supercharging Floorplan Localization with Semantic Rays", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICCV 2025", "summary": "Floorplans provide a compact representation of the building's structure,\nrevealing not only layout information but also detailed semantics such as the\nlocations of windows and doors. However, contemporary floorplan localization\ntechniques mostly focus on matching depth-based structural cues, ignoring the\nrich semantics communicated within floorplans. In this work, we introduce a\nsemantic-aware localization framework that jointly estimates depth and semantic\nrays, consolidating over both for predicting a structural-semantic probability\nvolume. Our probability volume is constructed in a coarse-to-fine manner: We\nfirst sample a small set of rays to obtain an initial low-resolution\nprobability volume. We then refine these probabilities by performing a denser\nsampling only in high-probability regions and process the refined values for\npredicting a 2D location and orientation angle. We conduct an evaluation on two\nstandard floorplan localization benchmarks. Our experiments demonstrate that\nour approach substantially outperforms state-of-the-art methods, achieving\nsignificant improvements in recall metrics compared to prior works. Moreover,\nwe show that our framework can easily incorporate additional metadata such as\nroom labels, enabling additional gains in both accuracy and efficiency.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u611f\u77e5\u5b9a\u4f4d\u6846\u67b6\u7528\u4e8e\u5e73\u9762\u56fe\u5b9a\u4f4d\uff0c\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u8fd8\u80fd\u7ed3\u5408\u989d\u5916\u5143\u6570\u636e\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5e73\u9762\u56fe\u5b9a\u4f4d\u6280\u672f\u591a\u5173\u6ce8\u6df1\u5ea6\u7ed3\u6784\u7ebf\u7d22\uff0c\u5ffd\u7565\u5e73\u9762\u56fe\u4e30\u5bcc\u8bed\u4e49\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u8bed\u4e49\u611f\u77e5\u5b9a\u4f4d\u6846\u67b6\uff0c\u8054\u5408\u4f30\u8ba1\u6df1\u5ea6\u548c\u8bed\u4e49\u5c04\u7ebf\uff0c\u6784\u5efa\u7c97\u5230\u7ec6\u7684\u7ed3\u6784 - \u8bed\u4e49\u6982\u7387\u4f53\u79ef\uff0c\u5148\u7c97\u91c7\u6837\u5f97\u521d\u59cb\u4f4e\u5206\u8fa8\u7387\u4f53\u79ef\uff0c\u518d\u5728\u9ad8\u6982\u7387\u533a\u57df\u5bc6\u96c6\u91c7\u6837\u7ec6\u5316\u6982\u7387\u4ee5\u9884\u6d4b\u4e8c\u7ef4\u4f4d\u7f6e\u548c\u65b9\u5411\u89d2\u3002", "result": "\u5728\u4e24\u4e2a\u6807\u51c6\u5e73\u9762\u56fe\u5b9a\u4f4d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u53ec\u56de\u6307\u6807\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u80fd\u7ed3\u5408\u989d\u5916\u5143\u6570\u636e\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bed\u4e49\u611f\u77e5\u5b9a\u4f4d\u6846\u67b6\u6709\u6548\uff0c\u80fd\u63d0\u9ad8\u5e73\u9762\u56fe\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.10127", "pdf": "https://arxiv.org/pdf/2507.10127", "abs": "https://arxiv.org/abs/2507.10127", "authors": ["Md Abulkalam Azad", "John Nyberg", "H\u00e5vard Dalen", "Bj\u00f8rnar Grenne", "Lasse Lovstakken", "Andreas \u00d8stvik"], "title": "Taming Modern Point Tracking for Speckle Tracking Echocardiography via Impartial Motion", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to CVAMD workshop at ICCV 2025", "summary": "Accurate motion estimation for tracking deformable tissues in\nechocardiography is essential for precise cardiac function measurements. While\ntraditional methods like block matching or optical flow struggle with intricate\ncardiac motion, modern point tracking approaches remain largely underexplored\nin this domain. This work investigates the potential of state-of-the-art (SOTA)\npoint tracking methods for ultrasound, with a focus on echocardiography.\nAlthough these novel approaches demonstrate strong performance in general\nvideos, their effectiveness and generalizability in echocardiography remain\nlimited. By analyzing cardiac motion throughout the heart cycle in real B-mode\nultrasound videos, we identify that a directional motion bias across different\nviews is affecting the existing training strategies. To mitigate this, we\nrefine the training procedure and incorporate a set of tailored augmentations\nto reduce the bias and enhance tracking robustness and generalization through\nimpartial cardiac motion. We also propose a lightweight network leveraging\nmulti-scale cost volumes from spatial context alone to challenge the advanced\nspatiotemporal point tracking models. Experiments demonstrate that fine-tuning\nwith our strategies significantly improves models' performances over their\nbaselines, even for out-of-distribution (OOD) cases. For instance, EchoTracker\nboosts overall position accuracy by 60.7% and reduces median trajectory error\nby 61.5% across heart cycle phases. Interestingly, several point tracking\nmodels fail to outperform our proposed simple model in terms of tracking\naccuracy and generalization, reflecting their limitations when applied to\nechocardiography. Nevertheless, clinical evaluation reveals that these methods\nimprove GLS measurements, aligning more closely with expert-validated,\nsemi-automated tools and thus demonstrating better reproducibility in\nreal-world applications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8d85\u58f0\u5fc3\u52a8\u56fe\u4e2dSOTA\u70b9\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u6539\u8fdb\u8bad\u7ec3\u7b56\u7565\u548c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u7f51\u7edc\uff0c\u5b9e\u9a8c\u8868\u660e\u7b56\u7565\u53ef\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e34\u5e8a\u8bc4\u4f30\u663e\u793a\u65b9\u6cd5\u6539\u5584GLS\u6d4b\u91cf\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u8d85\u58f0\u5fc3\u52a8\u56fe\u5fc3\u810f\u8fd0\u52a8\u4f30\u8ba1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u4ee3\u70b9\u8ddf\u8e2a\u65b9\u6cd5\u5728\u8be5\u9886\u57df\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4e14\u73b0\u6709\u65b0\u65b9\u6cd5\u5728\u8d85\u58f0\u5fc3\u52a8\u56fe\u4e2d\u6709\u6548\u6027\u548c\u6cdb\u5316\u6027\u6709\u9650\u3002", "method": "\u5206\u6790\u5fc3\u810f\u5468\u671f\u8fd0\u52a8\uff0c\u8bc6\u522b\u65b9\u5411\u8fd0\u52a8\u504f\u5dee\uff0c\u6539\u8fdb\u8bad\u7ec3\u7a0b\u5e8f\uff0c\u5f15\u5165\u5b9a\u5236\u589e\u5f3a\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u7f51\u7edc\u3002", "result": "\u5fae\u8c03\u7b56\u7565\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5982EchoTracker\u63d0\u9ad8\u4f4d\u7f6e\u7cbe\u5ea6\u3001\u964d\u4f4e\u8f68\u8ff9\u8bef\u5dee\uff0c\u90e8\u5206\u70b9\u8ddf\u8e2a\u6a21\u578b\u4e0d\u5982\u7b80\u5355\u6a21\u578b\uff0c\u65b9\u6cd5\u6539\u5584GLS\u6d4b\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u63d0\u5347\u8d85\u58f0\u5fc3\u52a8\u56fe\u70b9\u8ddf\u8e2a\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u6027\uff0c\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u6709\u66f4\u597d\u7684\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2507.09305", "pdf": "https://arxiv.org/pdf/2507.09305", "abs": "https://arxiv.org/abs/2507.09305", "authors": ["Zhiwei Xu"], "title": "DAA*: Deep Angular A Star for Image-based Path Planning", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "International Conference on Computer Vision (ICCV), 2025", "summary": "Path smoothness is often overlooked in path imitation learning from expert\ndemonstrations. In this paper, we introduce a novel learning method, termed\ndeep angular A* (DAA*), by incorporating the proposed path angular freedom\n(PAF) into A* to improve path similarity through adaptive path smoothness. The\nPAF aims to explore the effect of move angles on path node expansion by finding\nthe trade-off between their minimum and maximum values, allowing for high\nadaptiveness for imitation learning. DAA* improves path optimality by closely\naligning with the reference path through joint optimization of path shortening\nand smoothing, which correspond to heuristic distance and PAF, respectively.\nThroughout comprehensive evaluations on 7 datasets, including 4 maze datasets,\n2 video-game datasets, and a real-world drone-view dataset containing 2\nscenarios, we demonstrate remarkable improvements of our DAA* over neural A* in\npath similarity between the predicted and reference paths with a shorter path\nlength when the shortest path is plausible, improving by 9.0% SPR, 6.9% ASIM,\nand 3.9% PSIM. Furthermore, when jointly learning pathfinding with both path\nloss and path probability map loss, DAA* significantly outperforms the\nstate-of-the-art TransPath by 6.7% SPR, 6.5% PSIM, and 3.7% ASIM. We also\ndiscuss the minor trade-off between path optimality and search efficiency where\napplicable.", "AI": {"tldr": "\u63d0\u51fa\u6df1\u5ea6\u89d2\u5ea6A*\uff08DAA*\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u8def\u5f84\u89d2\u5ea6\u81ea\u7531\u5ea6\uff08PAF\uff09\u6539\u5584\u8def\u5f84\u5e73\u6ed1\u5ea6\u548c\u76f8\u4f3c\u5ea6\uff0c\u5728\u591a\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u8fd8\u63a2\u8ba8\u4e86\u8def\u5f84\u6700\u4f18\u6027\u4e0e\u641c\u7d22\u6548\u7387\u7684\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u8def\u5f84\u6a21\u4eff\u5b66\u4e60\u4e2d\u8def\u5f84\u5e73\u6ed1\u5ea6\u5e38\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u3002", "method": "\u5c06PAF\u878d\u5165A*\u7b97\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8def\u5f84\u7f29\u77ed\u548c\u5e73\u6ed1\u6765\u63d0\u9ad8\u8def\u5f84\u6700\u4f18\u6027\u3002", "result": "\u57287\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cDAA*\u5728\u8def\u5f84\u76f8\u4f3c\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8eNeural A*\u548cTransPath\uff0c\u8def\u5f84\u957f\u5ea6\u66f4\u77ed\u3002", "conclusion": "DAA*\u80fd\u6709\u6548\u63d0\u9ad8\u8def\u5f84\u76f8\u4f3c\u5ea6\u548c\u6700\u4f18\u6027\uff0c\u5b58\u5728\u8def\u5f84\u6700\u4f18\u6027\u4e0e\u641c\u7d22\u6548\u7387\u7684\u5c0f\u6743\u8861\u3002"}}
{"id": "2507.10133", "pdf": "https://arxiv.org/pdf/2507.10133", "abs": "https://arxiv.org/abs/2507.10133", "authors": ["Nicholas Leisegang", "Thomas Meyer", "Ivan Varzinczak"], "title": "Extending Defeasibility for Propositional Standpoint Logics", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "In this paper, we introduce a new defeasible version of propositional\nstandpoint logic by integrating Kraus et al.'s defeasible conditionals, Britz\nand Varzinczak's notions of defeasible necessity and distinct possibility,\nalong with Leisegang et al.'s approach to defeasibility into the standpoint\nlogics of G\\'omez \\'Alvarez and Rudolph. The resulting logical framework allows\nfor the expression of defeasibility on the level of implications, standpoint\nmodal operators, and standpoint-sharpening statements. We provide a\npreferential semantics for this extended language and propose a tableaux\ncalculus, which is shown to be sound and complete with respect to preferential\nentailment. We also establish the computational complexity of the tableaux\nprocedure to be in PSpace.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u547d\u9898\u7acb\u573a\u903b\u8f91\u7684\u53ef\u5e9f\u6b62\u7248\u672c\uff0c\u7ed9\u51fa\u8bed\u4e49\u548c\u8868\u63a8\u6f14\u7b97\u6cd5\uff0c\u5e76\u5206\u6790\u590d\u6742\u5ea6\u3002", "motivation": "\u5728\u7acb\u573a\u903b\u8f91\u4e2d\u5f15\u5165\u53ef\u5e9f\u6b62\u6027\uff0c\u4ee5\u8868\u8fbe\u8574\u542b\u3001\u7acb\u573a\u6a21\u6001\u7b97\u5b50\u548c\u7acb\u573a\u7ec6\u5316\u9648\u8ff0\u5c42\u9762\u7684\u53ef\u5e9f\u6b62\u6027\u3002", "method": "\u5c06Kraus\u7b49\u4eba\u7684\u53ef\u5e9f\u6b62\u6761\u4ef6\u53e5\u3001Britz\u548cVarzinczak\u7684\u53ef\u5e9f\u6b62\u5fc5\u7136\u6027\u548c\u4e0d\u540c\u53ef\u80fd\u6027\u6982\u5ff5\u4ee5\u53caLeisegang\u7b49\u4eba\u7684\u53ef\u5e9f\u6b62\u6027\u65b9\u6cd5\u96c6\u6210\u5230G\u00f3mez \u00c1lvarez\u548cRudolph\u7684\u7acb\u573a\u903b\u8f91\u4e2d\uff0c\u63d0\u4f9b\u4f18\u5148\u8bed\u4e49\uff0c\u63d0\u51fa\u8868\u63a8\u6f14\u7b97\u6cd5\u3002", "result": "\u6240\u63d0\u8868\u63a8\u6f14\u7b97\u6cd5\u5bf9\u4f18\u5148\u8574\u542b\u662f\u53ef\u9760\u4e14\u5b8c\u5907\u7684\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u5728PSpace\u5185\u3002", "conclusion": "\u6210\u529f\u6784\u5efa\u5177\u6709\u53ef\u5e9f\u6b62\u6027\u7684\u547d\u9898\u7acb\u573a\u903b\u8f91\u6846\u67b6\uff0c\u5e76\u7ed9\u51fa\u6709\u6548\u63a8\u7406\u7b97\u6cd5\u53ca\u590d\u6742\u5ea6\u5206\u6790\u3002"}}
{"id": "2507.10136", "pdf": "https://arxiv.org/pdf/2507.10136", "abs": "https://arxiv.org/abs/2507.10136", "authors": ["Zhonglin Liu"], "title": "A PBN-RL-XAI Framework for Discovering a \"Hit-and-Run'' Therapeutic Strategy in Melanoma", "categories": ["q-bio.QM", "cs.AI"], "comment": "9 pages, 5 figures. Submitted to the IEEE International Conference on\n  Bioinformatics and Biomedicine (BIBM) 2025. Code is available at\n  https://github.com/Liu-Zhonglin/pbn-melanoma-project", "summary": "Innate resistance to anti-PD-1 immunotherapy remains a major clinical\nchallenge in metastatic melanoma, with the underlying molecular networks being\npoorly understood. To address this, we constructed a dynamic Probabilistic\nBoolean Network model using transcriptomic data from patient tumor biopsies to\nelucidate the regulatory logic governing therapy response. We then employed a\nreinforcement learning agent to systematically discover optimal, multi-step\ntherapeutic interventions and used explainable artificial intelligence to\nmechanistically interpret the agent's control policy. The analysis revealed\nthat a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2\nprotein (LOXL2) was the most effective strategy. Our explainable analysis\nshowed that this ``hit-and-run\" intervention is sufficient to erase the\nmolecular signature driving resistance, allowing the network to self-correct\nwithout requiring sustained intervention. This study presents a novel,\ntime-dependent therapeutic hypothesis for overcoming immunotherapy resistance\nand provides a powerful computational framework for identifying non-obvious\nintervention protocols in complex biological systems.", "AI": {"tldr": "\u6784\u5efa\u6982\u7387\u5e03\u5c14\u7f51\u7edc\u6a21\u578b\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u53ef\u89e3\u91caAI\uff0c\u53d1\u73b04\u6b65\u4e34\u65f6\u6291\u5236LOXL2\u514b\u670d\u9ed1\u8272\u7d20\u7624\u514d\u75ab\u6cbb\u7597\u8010\u836f\u3002", "motivation": "\u8f6c\u79fb\u6027\u9ed1\u8272\u7d20\u7624\u5bf9PD - 1\u514d\u75ab\u6cbb\u7597\u7684\u5148\u5929\u8010\u836f\u662f\u4e34\u5e8a\u6311\u6218\uff0c\u6f5c\u5728\u5206\u5b50\u7f51\u7edc\u4e0d\u660e\u3002", "method": "\u7528\u60a3\u8005\u80bf\u7624\u6d3b\u68c0\u8f6c\u5f55\u7ec4\u6570\u636e\u6784\u5efa\u6982\u7387\u5e03\u5c14\u7f51\u7edc\u6a21\u578b\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u53d1\u73b0\u591a\u6b65\u6cbb\u7597\u5e72\u9884\uff0c\u7528\u53ef\u89e3\u91caAI\u89e3\u91ca\u63a7\u5236\u7b56\u7565\u3002", "result": "\u7cbe\u51c6\u5b9a\u65f6\u76844\u6b65\u4e34\u65f6\u6291\u5236LOXL2\u662f\u6700\u6709\u6548\u7b56\u7565\uff0c\u53ef\u6d88\u9664\u8010\u836f\u5206\u5b50\u7279\u5f81\u3002", "conclusion": "\u63d0\u51fa\u514b\u670d\u514d\u75ab\u6cbb\u7597\u8010\u836f\u7684\u65b0\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u6cbb\u7597\u5047\u8bbe\uff0c\u63d0\u4f9b\u8bc6\u522b\u590d\u6742\u751f\u7269\u7cfb\u7edf\u5e72\u9884\u65b9\u6848\u7684\u8ba1\u7b97\u6846\u67b6\u3002"}}
{"id": "2507.09330", "pdf": "https://arxiv.org/pdf/2507.09330", "abs": "https://arxiv.org/abs/2507.09330", "authors": ["Linus Walter", "Qingkai Kong", "Sara Hanson-Hedgecock", "V\u00edctor Vilarrasa"], "title": "WellPINN: Accurate Well Representation for Transient Fluid Pressure Diffusion in Subsurface Reservoirs with Physics-Informed Neural Networks", "categories": ["physics.flu-dyn", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Accurate representation of wells is essential for reliable reservoir\ncharacterization and simulation of operational scenarios in subsurface flow\nmodels. Physics-informed neural networks (PINNs) have recently emerged as a\npromising method for reservoir modeling, offering seamless integration of\nmonitoring data and governing physical equations. However, existing PINN-based\nstudies face major challenges in capturing fluid pressure near wells,\nparticularly during the early stage after injection begins. To address this, we\npropose WellPINN, a modeling workflow that combines the outputs of multiple\nsequentially trained PINN models to accurately represent wells. This workflow\niteratively approximates the radius of the equivalent well to match the actual\nwell dimensions by decomposing the domain into stepwise shrinking subdomains\nwith a simultaneously reducing equivalent well radius. Our results demonstrate\nthat sequential training of superimposing networks around the pumping well is\nthe first workflow that focuses on accurate inference of fluid pressure from\npumping rates throughout the entire injection period, significantly advancing\nthe potential of PINNs for inverse modeling and operational scenario\nsimulations. All data and code for this paper will be made openly available at\nhttps://github.com/linuswalter/WellPINN.", "AI": {"tldr": "\u63d0\u51faWellPINN\u5de5\u4f5c\u6d41\u89e3\u51b3\u73b0\u6709PINN\u6a21\u578b\u5728\u4e95\u9644\u8fd1\u6355\u6349\u6d41\u4f53\u538b\u529b\u7684\u95ee\u9898\uff0c\u80fd\u5728\u6574\u4e2a\u6ce8\u5165\u671f\u51c6\u786e\u63a8\u65ad\u6d41\u4f53\u538b\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8ePINN\u7684\u7814\u7a76\u5728\u6355\u6349\u4e95\u9644\u8fd1\u6d41\u4f53\u538b\u529b\uff0c\u7279\u522b\u662f\u6ce8\u5165\u5f00\u59cb\u65e9\u671f\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u51c6\u786e\u8868\u793a\u4e95\u4ee5\u8fdb\u884c\u53ef\u9760\u7684\u50a8\u5c42\u8868\u5f81\u548c\u6a21\u62df\u3002", "method": "\u63d0\u51faWellPINN\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u591a\u4e2a\u987a\u5e8f\u8bad\u7ec3\u7684PINN\u6a21\u578b\u8f93\u51fa\uff0c\u5c06\u57df\u5206\u89e3\u4e3a\u9010\u6b65\u7f29\u5c0f\u7684\u5b50\u57df\uff0c\u540c\u65f6\u51cf\u5c0f\u7b49\u6548\u4e95\u534a\u5f84\u4ee5\u5339\u914d\u5b9e\u9645\u4e95\u5c3a\u5bf8\u3002", "result": "\u987a\u5e8f\u8bad\u7ec3\u56f4\u7ed5\u62bd\u6c34\u4e95\u7684\u53e0\u52a0\u7f51\u7edc\u662f\u9996\u4e2a\u80fd\u5728\u6574\u4e2a\u6ce8\u5165\u671f\u4ece\u62bd\u6c34\u7387\u51c6\u786e\u63a8\u65ad\u6d41\u4f53\u538b\u529b\u7684\u5de5\u4f5c\u6d41\uff0c\u663e\u8457\u63d0\u5347\u4e86PINN\u7528\u4e8e\u9006\u5efa\u6a21\u548c\u64cd\u4f5c\u573a\u666f\u6a21\u62df\u7684\u6f5c\u529b\u3002", "conclusion": "WellPINN\u5de5\u4f5c\u6d41\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709PINN\u6a21\u578b\u95ee\u9898\uff0c\u63a8\u8fdb\u4e86PINN\u5728\u76f8\u5173\u9886\u57df\u7684\u5e94\u7528\uff0c\u4e14\u6570\u636e\u548c\u4ee3\u7801\u5c06\u516c\u5f00\u3002"}}
{"id": "2507.09340", "pdf": "https://arxiv.org/pdf/2507.09340", "abs": "https://arxiv.org/abs/2507.09340", "authors": ["Hongyu Nie", "Xingyu Li", "Xu Liu", "Zhaotong Tan", "Sen Mei", "Wenbo Su"], "title": "Unified Linear Parametric Map Modeling and Perception-aware Trajectory Planning for Mobile Robotics", "categories": ["cs.RO", "cs.LG"], "comment": "Submitted to IEEE Transactions on Robotics (TRO) in July 2025", "summary": "Autonomous navigation in mobile robots, reliant on perception and planning,\nfaces major hurdles in large-scale, complex environments. These include heavy\ncomputational burdens for mapping, sensor occlusion failures for UAVs, and\ntraversal challenges on irregular terrain for UGVs, all compounded by a lack of\nperception-aware strategies. To address these challenges, we introduce Random\nMapping and Random Projection (RMRP). This method constructs a lightweight\nlinear parametric map by first mapping data to a high-dimensional space,\nfollowed by a sparse random projection for dimensionality reduction. Our novel\nResidual Energy Preservation Theorem provides theoretical guarantees for this\nprocess, ensuring critical geometric properties are preserved. Based on this\nmap, we propose the RPATR (Robust Perception-Aware Trajectory Planner)\nframework. For UAVs, our method unifies grid and Euclidean Signed Distance\nField (ESDF) maps. The front-end uses an analytical occupancy gradient to\nrefine initial paths for safety and smoothness, while the back-end uses a\nclosed-form ESDF for trajectory optimization. Leveraging the trained RMRP\nmodel's generalization, the planner predicts unobserved areas for proactive\nnavigation. For UGVs, the model characterizes terrain and provides closed-form\ngradients, enabling online planning to circumvent large holes. Validated in\ndiverse scenarios, our framework demonstrates superior mapping performance in\ntime, memory, and accuracy, and enables computationally efficient, safe\nnavigation for high-speed UAVs and UGVs. The code will be released to foster\ncommunity collaboration.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u79fb\u52a8\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u81ea\u4e3b\u5bfc\u822a\u96be\u9898\uff0c\u63d0\u51faRMRP\u65b9\u6cd5\u53caRPATR\u6846\u67b6\uff0c\u7ecf\u591a\u573a\u666f\u9a8c\u8bc1\u6027\u80fd\u4f18\u8d8a\u4e14\u5c06\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u673a\u5668\u4eba\u5728\u5927\u89c4\u6a21\u590d\u6742\u73af\u5883\u81ea\u4e3b\u5bfc\u822a\u65f6\uff0c\u5b58\u5728\u7684\u8ba1\u7b97\u8d1f\u62c5\u91cd\u3001\u4f20\u611f\u5668\u906e\u6321\u53ca\u4e0d\u89c4\u5219\u5730\u5f62\u904d\u5386\u7b49\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u611f\u77e5\u7b56\u7565\u3002", "method": "\u63d0\u51faRMRP\u65b9\u6cd5\u6784\u5efa\u8f7b\u91cf\u7ea7\u7ebf\u6027\u53c2\u6570\u5730\u56fe\uff0c\u6709\u6b8b\u5dee\u80fd\u91cf\u4fdd\u7559\u5b9a\u7406\u4fdd\u969c\uff1b\u57fa\u4e8e\u6b64\u63d0\u51faRPATR\u6846\u67b6\uff0c\u9488\u5bf9UAV\u548cUGV\u5206\u522b\u6709\u4e0d\u540c\u89c4\u5212\u65b9\u5f0f\u3002", "result": "\u6846\u67b6\u5728\u65f6\u95f4\u3001\u5185\u5b58\u548c\u7cbe\u5ea6\u4e0a\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u5730\u56fe\u6784\u5efa\u6027\u80fd\uff0c\u80fd\u8ba9\u9ad8\u901fUAV\u548cUGV\u5b9e\u73b0\u9ad8\u6548\u5b89\u5168\u5bfc\u822a\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u79fb\u52a8\u673a\u5668\u4eba\u5728\u590d\u6742\u73af\u5883\u7684\u5bfc\u822a\u95ee\u9898\uff0c\u4ee3\u7801\u5f00\u6e90\u53ef\u4fc3\u8fdb\u793e\u533a\u5408\u4f5c\u3002"}}
{"id": "2507.10177", "pdf": "https://arxiv.org/pdf/2507.10177", "abs": "https://arxiv.org/abs/2507.10177", "authors": ["Rohitash Chandra", "Jiyong Choi"], "title": "Abusive text transformation using LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although Large Language Models (LLMs) have demonstrated significant\nadvancements in natural language processing tasks, their effectiveness in the\nclassification and transformation of abusive text into non-abusive versions\nremains an area for exploration. In this study, we aim to use LLMs to transform\nabusive text (tweets and reviews) featuring hate speech and swear words into\nnon-abusive text, while retaining the intent of the text. We evaluate the\nperformance of two state-of-the-art LLMs, such as Gemini, GPT-4o, DeekSeek and\nGroq, on their ability to identify abusive text. We them to transform and\nobtain a text that is clean from abusive and inappropriate content but\nmaintains a similar level of sentiment and semantics, i.e. the transformed text\nneeds to maintain its message. Afterwards, we evaluate the raw and transformed\ndatasets with sentiment analysis and semantic analysis. Our results show Groq\nprovides vastly different results when compared with other LLMs. We have\nidentified similarities between GPT-4o and DeepSeek-V3.", "AI": {"tldr": "\u7814\u7a76\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u542b\u4ec7\u6068\u8a00\u8bba\u548c\u810f\u8bdd\u7684\u8fb1\u9a82\u6027\u6587\u672c\u8f6c\u5316\u4e3a\u975e\u8fb1\u9a82\u6027\u6587\u672c\uff0c\u8bc4\u4f30\u591a\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0Groq\u7ed3\u679c\u5dee\u5f02\u5927\uff0cGPT - 4o\u548cDeepSeek - V3\u6709\u76f8\u4f3c\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fb1\u9a82\u6027\u6587\u672c\u5206\u7c7b\u548c\u8f6c\u5316\u65b9\u9762\u6709\u5f85\u63a2\u7d22\uff0c\u7814\u7a76\u65e8\u5728\u7528\u5176\u5c06\u8fb1\u9a82\u6027\u6587\u672c\u8f6c\u5316\u4e3a\u975e\u8fb1\u9a82\u6027\u4e14\u4fdd\u7559\u539f\u610f\u7684\u6587\u672c\u3002", "method": "\u8bc4\u4f30Gemini\u3001GPT - 4o\u3001DeekSeek\u548cGroq\u8bc6\u522b\u8fb1\u9a82\u6027\u6587\u672c\u7684\u80fd\u529b\uff0c\u7528\u5176\u8fdb\u884c\u8f6c\u5316\uff0c\u5bf9\u539f\u59cb\u548c\u8f6c\u5316\u540e\u6570\u636e\u96c6\u8fdb\u884c\u60c5\u611f\u548c\u8bed\u4e49\u5206\u6790\u3002", "result": "Groq\u4e0e\u5176\u4ed6LLMs\u7ed3\u679c\u5dee\u5f02\u5927\uff0cGPT - 4o\u548cDeepSeek - V3\u6709\u76f8\u4f3c\u6027\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u6697\u793a\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fb1\u9a82\u6027\u6587\u672c\u8f6c\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u6709\u5dee\u5f02\u3002"}}
{"id": "2507.09383", "pdf": "https://arxiv.org/pdf/2507.09383", "abs": "https://arxiv.org/abs/2507.09383", "authors": ["Wondmgezahu Teshome", "Kian Behzad", "Octavia Camps", "Michael Everett", "Milad Siami", "Mario Sznaier"], "title": "Real-Time Adaptive Motion Planning via Point Cloud-Guided, Energy-Based Diffusion and Potential Fields", "categories": ["cs.RO", "cs.LG"], "comment": "Accepted to IEEE RA-L 2025", "summary": "Motivated by the problem of pursuit-evasion, we present a motion planning\nframework that combines energy-based diffusion models with artificial potential\nfields for robust real time trajectory generation in complex environments. Our\napproach processes obstacle information directly from point clouds, enabling\nefficient planning without requiring complete geometric representations. The\nframework employs classifier-free guidance training and integrates local\npotential fields during sampling to enhance obstacle avoidance. In dynamic\nscenarios, the system generates initial trajectories using the diffusion model\nand continuously refines them through potential field-based adaptation,\ndemonstrating effective performance in pursuit-evasion scenarios with partial\npursuer observability.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u80fd\u91cf\u6269\u6563\u6a21\u578b\u548c\u4eba\u5de5\u52bf\u573a\u7684\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u53ef\u5728\u590d\u6742\u73af\u5883\u5b9e\u65f6\u751f\u6210\u8f68\u8ff9\uff0c\u5728\u8ffd\u9003\u573a\u666f\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u8ffd\u9003\u95ee\u9898\uff0c\u5b9e\u73b0\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fdb\u884c\u9c81\u68d2\u5b9e\u65f6\u8f68\u8ff9\u751f\u6210\u3002", "method": "\u7ed3\u5408\u80fd\u91cf\u6269\u6563\u6a21\u578b\u548c\u4eba\u5de5\u52bf\u573a\uff0c\u76f4\u63a5\u5904\u7406\u70b9\u4e91\u7684\u969c\u788d\u7269\u4fe1\u606f\uff0c\u91c7\u7528\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u8bad\u7ec3\uff0c\u91c7\u6837\u65f6\u96c6\u6210\u5c40\u90e8\u52bf\u573a\uff0c\u5728\u52a8\u6001\u573a\u666f\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u521d\u59cb\u8f68\u8ff9\u5e76\u901a\u8fc7\u52bf\u573a\u81ea\u9002\u5e94\u4e0d\u65ad\u4f18\u5316\u3002", "result": "\u5728\u90e8\u5206\u8ffd\u6355\u8005\u53ef\u89c2\u6d4b\u7684\u8ffd\u9003\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u6709\u6548\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\u80fd\u5728\u590d\u6742\u73af\u5883\u4e0b\u6709\u6548\u5b9e\u73b0\u5b9e\u65f6\u8f68\u8ff9\u751f\u6210\uff0c\u9002\u7528\u4e8e\u8ffd\u9003\u573a\u666f\u3002"}}
{"id": "2507.10179", "pdf": "https://arxiv.org/pdf/2507.10179", "abs": "https://arxiv.org/abs/2507.10179", "authors": ["Asvin G"], "title": "The Second Machine Turn: From Checking Proofs to Creating Concepts", "categories": ["math.HO", "cs.AI"], "comment": null, "summary": "We identify a second machine turn in the process of mathematical discovery:\nafter automating proof-checking, AI is now poised to automate the *creation* of\nmathematical concepts themselves. We discuss the current state of the art,\nobstacles and potential solutions as well as a preliminary attempt at\nmathematizing the creation of concepts itself. The paper ends with an\nassessment of how these capabilities could reshape mathematics and\nhuman-machine collaboration, and a few different futures we might find\nourselves in.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u6570\u5b66\u53d1\u73b0\u4e2d\u7684\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5373AI\u53ef\u81ea\u52a8\u5316\u521b\u5efa\u6570\u5b66\u6982\u5ff5\uff0c\u63a2\u8ba8\u73b0\u72b6\u3001\u969c\u788d\u3001\u89e3\u51b3\u65b9\u6848\uff0c\u8bc4\u4f30\u5176\u5bf9\u6570\u5b66\u548c\u4eba\u673a\u534f\u4f5c\u7684\u5f71\u54cd\u3002", "motivation": "\u5173\u6ce8AI\u5728\u6570\u5b66\u53d1\u73b0\u4e2d\u4ece\u81ea\u52a8\u8bc1\u660e\u68c0\u67e5\u5230\u81ea\u52a8\u521b\u5efa\u6570\u5b66\u6982\u5ff5\u7684\u53d1\u5c55\uff0c\u63a2\u7d22\u5176\u6f5c\u529b\u548c\u5f71\u54cd\u3002", "method": "\u8ba8\u8bba\u5f53\u524d\u6280\u672f\u6c34\u5e73\u3001\u969c\u788d\u53ca\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u5c1d\u8bd5\u5c06\u6982\u5ff5\u521b\u5efa\u8fc7\u7a0b\u6570\u5b66\u5316\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u8bc4\u4f30\u4e86AI\u81ea\u52a8\u521b\u5efa\u6982\u5ff5\u80fd\u529b\u5bf9\u6570\u5b66\u548c\u4eba\u673a\u534f\u4f5c\u7684\u91cd\u5851\u4f5c\u7528\uff0c\u5e76\u5c55\u671b\u4e86\u4e0d\u540c\u672a\u6765\u3002"}}
{"id": "2507.09410", "pdf": "https://arxiv.org/pdf/2507.09410", "abs": "https://arxiv.org/abs/2507.09410", "authors": ["Bernie Boscoe", "Shawn Johnson", "Andrea Osborn", "Chandler Campbell", "Karen Mager"], "title": "GreenCrossingAI: A Camera Trap/Computer Vision Pipeline for Environmental Science Research Groups", "categories": ["cs.CV", "cs.LG"], "comment": "This is the preprint version of the paper in Practice and Experience\n  in Advanced Research Computing, PEARC25", "summary": "Camera traps have long been used by wildlife researchers to monitor and study\nanimal behavior, population dynamics, habitat use, and species diversity in a\nnon-invasive and efficient manner. While data collection from the field has\nincreased with new tools and capabilities, methods to develop, process, and\nmanage the data, especially the adoption of ML/AI tools, remain challenging.\nThese challenges include the sheer volume of data generated, the need for\naccurate labeling and annotation, variability in environmental conditions\naffecting data quality, and the integration of ML/AI tools into existing\nworkflows that often require domain-specific customization and computational\nresources. This paper provides a guide to a low-resource pipeline to process\ncamera trap data on-premise, incorporating ML/AI capabilities tailored for\nsmall research groups with limited resources and computational expertise. By\nfocusing on practical solutions, the pipeline offers accessible approaches for\ndata transmission, inference, and evaluation, enabling researchers to discover\nmeaningful insights from their ever-increasing camera trap datasets.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u5c0f\u578b\u7814\u7a76\u5c0f\u7ec4\u7684\u672c\u5730\u5904\u7406\u76f8\u673a\u9677\u9631\u6570\u636e\u7684\u4f4e\u8d44\u6e90\u7ba1\u9053\uff0c\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u4ece\u6570\u636e\u4e2d\u83b7\u53d6\u6709\u610f\u4e49\u7684\u89c1\u89e3\u3002", "motivation": "\u968f\u7740\u76f8\u673a\u9677\u9631\u6570\u636e\u6536\u96c6\u91cf\u589e\u52a0\uff0c\u5f00\u53d1\u3001\u5904\u7406\u548c\u7ba1\u7406\u6570\u636e\uff0c\u5c24\u5176\u662f\u91c7\u7528ML/AI\u5de5\u5177\u9762\u4e34\u6311\u6218\uff0c\u5c0f\u578b\u7814\u7a76\u5c0f\u7ec4\u8d44\u6e90\u548c\u8ba1\u7b97\u4e13\u4e1a\u77e5\u8bc6\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u672c\u5730\u5904\u7406\u76f8\u673a\u9677\u9631\u6570\u636e\u7684\u4f4e\u8d44\u6e90\u7ba1\u9053\uff0c\u878d\u5165\u9002\u5408\u5c0f\u578b\u7814\u7a76\u5c0f\u7ec4\u7684ML/AI\u80fd\u529b\u3002", "result": "\u8be5\u7ba1\u9053\u63d0\u4f9b\u4e86\u6570\u636e\u4f20\u8f93\u3001\u63a8\u7406\u548c\u8bc4\u4f30\u7684\u53ef\u884c\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7ba1\u9053\u4e3a\u8d44\u6e90\u548c\u8ba1\u7b97\u4e13\u4e1a\u77e5\u8bc6\u6709\u9650\u7684\u5c0f\u578b\u7814\u7a76\u5c0f\u7ec4\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5176\u80fd\u4ece\u4e0d\u65ad\u589e\u52a0\u7684\u76f8\u673a\u9677\u9631\u6570\u636e\u96c6\u4e2d\u53d1\u73b0\u6709\u610f\u4e49\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.10200", "pdf": "https://arxiv.org/pdf/2507.10200", "abs": "https://arxiv.org/abs/2507.10200", "authors": ["Stefano Bann\u00f2", "Rao Ma", "Mengjie Qian", "Siyuan Tang", "Kate Knill", "Mark Gales"], "title": "Natural Language-based Assessment of L2 Oral Proficiency using LLMs", "categories": ["eess.AS", "cs.AI", "cs.CL"], "comment": "Accepted for the 10th Workshop on Speech and Language Technology in\n  Education (SLaTE 2025)", "summary": "Natural language-based assessment (NLA) is an approach to second language\nassessment that uses instructions - expressed in the form of can-do descriptors\n- originally intended for human examiners, aiming to determine whether large\nlanguage models (LLMs) can interpret and apply them in ways comparable to human\nassessment. In this work, we explore the use of such descriptors with an\nopen-source LLM, Qwen 2.5 72B, to assess responses from the publicly available\nS&I Corpus in a zero-shot setting. Our results show that this approach -\nrelying solely on textual information - achieves competitive performance: while\nit does not outperform state-of-the-art speech LLMs fine-tuned for the task, it\nsurpasses a BERT-based model trained specifically for this purpose. NLA proves\nparticularly effective in mismatched task settings, is generalisable to other\ndata types and languages, and offers greater interpretability, as it is\ngrounded in clearly explainable, widely applicable language descriptors.", "AI": {"tldr": "\u63a2\u7d22\u7528Qwen 2.5 72B\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7b26\u5bf9S&I\u8bed\u6599\u5e93\u8fdb\u884c\u96f6\u6837\u672c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u6709\u7ade\u4e89\u529b\u4e14\u6709\u591a\u79cd\u4f18\u52bf\u3002", "motivation": "\u786e\u5b9a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u50cf\u4eba\u7c7b\u8bc4\u4f30\u4e00\u6837\u89e3\u8bfb\u548c\u5e94\u7528\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u8bc4\u4f30\u63cf\u8ff0\u7b26\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578bQwen 2.5 72B\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5bf9S&I\u8bed\u6599\u5e93\u7684\u56de\u7b54\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u4ec5\u4f9d\u8d56\u6587\u672c\u4fe1\u606f\u7684\u65b9\u6cd5\u6709\u7ade\u4e89\u529b\uff0c\u867d\u672a\u8d85\u8d8a\u5fae\u8c03\u7684\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u8d85\u8d8a\u4e86\u4e13\u95e8\u8bad\u7ec3\u7684\u57fa\u4e8eBERT\u7684\u6a21\u578b\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u8bc4\u4f30\u5728\u4e0d\u5339\u914d\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u6709\u6548\uff0c\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6570\u636e\u7c7b\u578b\u548c\u8bed\u8a00\uff0c\u4e14\u5177\u6709\u66f4\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.09431", "pdf": "https://arxiv.org/pdf/2507.09431", "abs": "https://arxiv.org/abs/2507.09431", "authors": ["Zefang Liu", "Weston M. Stacey"], "title": "Optimizing External Sources for Controlled Burning Plasma in Tokamaks with Neural Ordinary Differential Equations", "categories": ["physics.plasm-ph", "cs.LG"], "comment": null, "summary": "Achieving controlled burning plasma in tokamaks requires precise regulation\nof external particle and energy sources to reach and maintain target core\ndensities and temperatures. This work presents an inverse modeling approach\nusing a multinodal plasma dynamics model based on neural ordinary differential\nequations (Neural ODEs). Given a desired time evolution of nodal quantities\nsuch as deuteron density or electron temperature, we compute the external\nsource profiles, such as neutral beam injection (NBI) power, that drive the\nplasma toward the specified behavior. The approach is implemented within the\nNeuralPlasmaODE framework, which models multi-region, multi-timescale transport\nand incorporates physical mechanisms including radiation, auxiliary heating,\nand internodal energy exchange. By formulating the control task as an\noptimization problem, we use automatic differentiation through the Neural ODE\nsolver to minimize the discrepancy between simulated and target trajectories.\nThis framework transforms the forward simulation tool into a control-oriented\nmodel and provides a practical method for computing external source profiles in\nboth current and future fusion devices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u7684\u591a\u8282\u70b9\u7b49\u79bb\u5b50\u4f53\u52a8\u529b\u5b66\u6a21\u578b\u7684\u9006\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u6258\u5361\u9a6c\u514b\u5916\u90e8\u6e90\u5206\u5e03\u4ee5\u63a7\u5236\u7b49\u79bb\u5b50\u4f53\u3002", "motivation": "\u6258\u5361\u9a6c\u514b\u5b9e\u73b0\u53d7\u63a7\u71c3\u70e7\u7b49\u79bb\u5b50\u4f53\u9700\u8981\u7cbe\u786e\u8c03\u8282\u5916\u90e8\u7c92\u5b50\u548c\u80fd\u91cf\u6e90\uff0c\u4ee5\u8fbe\u5230\u5e76\u7ef4\u6301\u76ee\u6807\u6838\u5fc3\u5bc6\u5ea6\u548c\u6e29\u5ea6\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u7684\u591a\u8282\u70b9\u7b49\u79bb\u5b50\u4f53\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5c06\u63a7\u5236\u4efb\u52a1\u8f6c\u5316\u4e3a\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u6c42\u89e3\u5668\u7684\u81ea\u52a8\u5fae\u5206\u6765\u6700\u5c0f\u5316\u6a21\u62df\u4e0e\u76ee\u6807\u8f68\u8ff9\u7684\u5dee\u5f02\u3002", "result": "\u5c06\u6b63\u5411\u6a21\u62df\u5de5\u5177\u8f6c\u5316\u4e3a\u9762\u5411\u63a7\u5236\u7684\u6a21\u578b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5f53\u524d\u548c\u672a\u6765\u805a\u53d8\u88c5\u7f6e\u8ba1\u7b97\u5916\u90e8\u6e90\u5206\u5e03\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2507.10202", "pdf": "https://arxiv.org/pdf/2507.10202", "abs": "https://arxiv.org/abs/2507.10202", "authors": ["Jaeseong Lee", "Yeeun Choi", "Heechan Choi", "Hanjung Kim", "Seonjoo Kim"], "title": "A Training-Free, Task-Agnostic Framework for Enhancing MLLM Performance on High-Resolution Images", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPR 2025 Workshop on Emergent Visual Abilities and\n  Limits of Foundation Models", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in vision-language understanding, reasoning, and generation.\nHowever, they struggle with tasks requiring fine-grained localization and\nreasoning in high-resolution images. This constraint stems from the fact that\nMLLMs are fine-tuned with fixed image resolution to align with the pre-trained\nimage encoder used in MLLM. Consequently, feeding high-resolution images\ndirectly into MLLMs leads to poor generalization due to a train-test resolution\ndiscrepancy, while downsampling these images-although ensuring\nconsistency-compromises fine-grained visual details and ultimately degrades\nperformance. To address this challenge, we propose Extract Candidate then\nPredict (ECP), a novel training-free, task-agnostic two-stage framework\ndesigned to enhance MLLM performance on high-resolution images. The key\nintuition behind ECP is that while MLLMs struggle with high-resolution images,\ntheir predictions on downsampled images still contain implicit localization\ncues. By first identifying candidate region using the coarse prediction and\nthen predicting the final output based on candidate region, ECP effectively\npreserves fine-grained details while mitigating the challenges posed by\nhigh-resolution data. We validate our framework on 4K GUI grounding and 4K, 8K\nMLLM perception, achieving +21.3%, +5.8%, +5.2% absolute improvement compared\nto baseline respectively, demonstrating its effectiveness. Code is available at\nhttps://github.com/yenncye/ECP.", "AI": {"tldr": "\u63d0\u51faECP\u6846\u67b6\u63d0\u5347MLLM\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u6027\u80fd\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "MLLMs\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u65f6\uff0c\u56e0\u56fa\u5b9a\u56fe\u50cf\u5206\u8fa8\u7387\u5fae\u8c03\u5b58\u5728\u6cdb\u5316\u5dee\u3001\u7ec6\u8282\u4e22\u5931\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8bad\u7ec3\u514d\u8d39\u3001\u4efb\u52a1\u65e0\u5173\u7684\u4e24\u9636\u6bb5\u6846\u67b6ECP\uff0c\u5148\u6839\u636e\u7c97\u9884\u6d4b\u786e\u5b9a\u5019\u9009\u533a\u57df\uff0c\u518d\u57fa\u4e8e\u5019\u9009\u533a\u57df\u9884\u6d4b\u6700\u7ec8\u8f93\u51fa\u3002", "result": "\u57284K GUI grounding\u548c4K\u30018K MLLM\u611f\u77e5\u4efb\u52a1\u4e0a\u8f83\u57fa\u7ebf\u5206\u522b\u6709+21.3%\u3001+5.8%\u3001+5.2%\u7684\u7edd\u5bf9\u63d0\u5347\u3002", "conclusion": "ECP\u6846\u67b6\u80fd\u6709\u6548\u4fdd\u7559\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff0c\u51cf\u8f7b\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u6311\u6218\uff0c\u63d0\u5347MLLM\u6027\u80fd\u3002"}}
{"id": "2507.09432", "pdf": "https://arxiv.org/pdf/2507.09432", "abs": "https://arxiv.org/abs/2507.09432", "authors": ["Zefang Liu", "Weston M. Stacey"], "title": "Sensitivity Analysis of Transport and Radiation in NeuralPlasmaODE for ITER Burning Plasmas", "categories": ["physics.plasm-ph", "cs.LG"], "comment": null, "summary": "Understanding how key physical parameters influence burning plasma behavior\nis critical for the reliable operation of ITER. In this work, we extend\nNeuralPlasmaODE, a multi-region, multi-timescale model based on neural ordinary\ndifferential equations, to perform a sensitivity analysis of transport and\nradiation mechanisms in ITER plasmas. Normalized sensitivities of core and edge\ntemperatures and densities are computed with respect to transport\ndiffusivities, electron cyclotron radiation (ECR) parameters, impurity\nfractions, and ion orbit loss (IOL) timescales. The analysis focuses on\nperturbations around a trained nominal model for the ITER inductive scenario.\nResults highlight the dominant influence of magnetic field strength, safety\nfactor, and impurity content on energy confinement, while also revealing how\ntemperature-dependent transport contributes to self-regulating behavior. These\nfindings demonstrate the utility of NeuralPlasmaODE for predictive modeling and\nscenario optimization in burning plasma environments.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55NeuralPlasmaODE\u6a21\u578b\u5bf9ITER\u7b49\u79bb\u5b50\u4f53\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\uff0c\u63ed\u793a\u5173\u952e\u53c2\u6570\u5bf9\u80fd\u91cf\u7ea6\u675f\u7684\u5f71\u54cd\uff0c\u8bc1\u660e\u8be5\u6a21\u578b\u5728\u71c3\u70e7\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u7406\u89e3\u5173\u952e\u7269\u7406\u53c2\u6570\u5bf9\u71c3\u70e7\u7b49\u79bb\u5b50\u4f53\u884c\u4e3a\u7684\u5f71\u54cd\u5bf9ITER\u53ef\u9760\u8fd0\u884c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6269\u5c55NeuralPlasmaODE\u6a21\u578b\uff0c\u8ba1\u7b97\u6838\u5fc3\u548c\u8fb9\u7f18\u6e29\u5ea6\u3001\u5bc6\u5ea6\u76f8\u5bf9\u4e8e\u8f93\u8fd0\u6269\u6563\u7387\u3001\u7535\u5b50\u56de\u65cb\u8f90\u5c04\u53c2\u6570\u3001\u6742\u8d28\u5206\u6570\u548c\u79bb\u5b50\u8f68\u9053\u635f\u5931\u65f6\u95f4\u5c3a\u5ea6\u7684\u5f52\u4e00\u5316\u7075\u654f\u5ea6\u3002", "result": "\u7ed3\u679c\u8868\u660e\u78c1\u573a\u5f3a\u5ea6\u3001\u5b89\u5168\u56e0\u5b50\u548c\u6742\u8d28\u542b\u91cf\u5bf9\u80fd\u91cf\u7ea6\u675f\u6709\u4e3b\u5bfc\u5f71\u54cd\uff0c\u8fd8\u63ed\u793a\u4e86\u6e29\u5ea6\u76f8\u5173\u8f93\u8fd0\u5bf9\u81ea\u8c03\u8282\u884c\u4e3a\u7684\u8d21\u732e\u3002", "conclusion": "NeuralPlasmaODE\u6a21\u578b\u53ef\u7528\u4e8e\u71c3\u70e7\u7b49\u79bb\u5b50\u4f53\u73af\u5883\u7684\u9884\u6d4b\u5efa\u6a21\u548c\u60c5\u666f\u4f18\u5316\u3002"}}
{"id": "2507.10216", "pdf": "https://arxiv.org/pdf/2507.10216", "abs": "https://arxiv.org/abs/2507.10216", "authors": ["Renad Al-Monef", "Hassan Alhuzali", "Nora Alturayeif", "Ashwag Alasmari"], "title": "Absher: A Benchmark for Evaluating Large Language Models Understanding of Saudi Dialects", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) become increasingly central to Arabic NLP\napplications, evaluating their understanding of regional dialects and cultural\nnuances is essential, particularly in linguistically diverse settings like\nSaudi Arabia. This paper introduces \\texttt{Absher}, a comprehensive benchmark\nspecifically designed to assess LLMs performance across major Saudi dialects.\n\\texttt{Absher} comprises over 18,000 multiple-choice questions spanning six\ndistinct categories: Meaning, True/False, Fill-in-the-Blank, Contextual Usage,\nCultural Interpretation, and Location Recognition. These questions are derived\nfrom a curated dataset of dialectal words, phrases, and proverbs sourced from\nvarious regions of Saudi Arabia. We evaluate several state-of-the-art LLMs,\nincluding multilingual and Arabic-specific models. We also provide detailed\ninsights into their capabilities and limitations. Our results reveal notable\nperformance gaps, particularly in tasks requiring cultural inference or\ncontextual understanding. Our findings highlight the urgent need for\ndialect-aware training and culturally aligned evaluation methodologies to\nimprove LLMs performance in real-world Arabic applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6c99\u7279\u4e3b\u8981\u65b9\u8a00\u4e0a\u8868\u73b0\u7684\u57fa\u51c6Absher\uff0c\u8bc4\u4f30\u4e86\u591a\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u6027\u80fd\u5dee\u8ddd\uff0c\u5f3a\u8c03\u65b9\u8a00\u611f\u77e5\u8bad\u7ec3\u548c\u6587\u5316\u5bf9\u9f50\u8bc4\u4f30\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u963f\u62c9\u4f2f\u8bedNLP\u5e94\u7528\u4e2d\u6108\u53d1\u91cd\u8981\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5bf9\u6c99\u7279\u5730\u533a\u65b9\u8a00\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u7684\u7406\u89e3\u3002", "method": "\u5f15\u5165\u5305\u542b\u8d8518000\u9053\u9009\u62e9\u9898\u7684Absher\u57fa\u51c6\uff0c\u6db5\u76d6\u516d\u4e2a\u7c7b\u522b\uff0c\u6e90\u81ea\u6c99\u7279\u5404\u5730\u7684\u65b9\u8a00\u6570\u636e\uff0c\u8bc4\u4f30\u591a\u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u5728\u9700\u8981\u6587\u5316\u63a8\u7406\u6216\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u65b9\u8a00\u611f\u77e5\u8bad\u7ec3\u548c\u6587\u5316\u5bf9\u9f50\u8bc4\u4f30\u65b9\u6cd5\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u963f\u62c9\u4f2f\u8bed\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2507.10223", "pdf": "https://arxiv.org/pdf/2507.10223", "abs": "https://arxiv.org/abs/2507.10223", "authors": ["Xiangyu Yin", "Boyuan Yang", "Weichen Liu", "Qiyao Xue", "Abrar Alamri", "Goeran Fiedler", "Wei Gao"], "title": "ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICCV'25", "summary": "Prosthetic legs play a pivotal role in clinical rehabilitation, allowing\nindividuals with lower-limb amputations the ability to regain mobility and\nimprove their quality of life. Gait analysis is fundamental for optimizing\nprosthesis design and alignment, directly impacting the mobility and life\nquality of individuals with lower-limb amputations. Vision-based machine\nlearning (ML) methods offer a scalable and non-invasive solution to gait\nanalysis, but face challenges in correctly detecting and analyzing prosthesis,\ndue to their unique appearances and new movement patterns. In this paper, we\naim to bridge this gap by introducing a multi-purpose dataset, namely ProGait,\nto support multiple vision tasks including Video Object Segmentation, 2D Human\nPose Estimation, and Gait Analysis (GA). ProGait provides 412 video clips from\nfour above-knee amputees when testing multiple newly-fitted prosthetic legs\nthrough walking trials, and depicts the presence, contours, poses, and gait\npatterns of human subjects with transfemoral prosthetic legs. Alongside the\ndataset itself, we also present benchmark tasks and fine-tuned baseline models\nto illustrate the practical application and performance of the ProGait dataset.\nWe compared our baseline models against pre-trained vision models,\ndemonstrating improved generalizability when applying the ProGait dataset for\nprosthesis-specific tasks. Our code is available at\nhttps://github.com/pittisl/ProGait and dataset at\nhttps://huggingface.co/datasets/ericyxy98/ProGait.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u7528\u9014\u6570\u636e\u96c6ProGait\u652f\u6301\u591a\u79cd\u89c6\u89c9\u4efb\u52a1\uff0c\u5c55\u793a\u5176\u5e94\u7528\u4e0e\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u516c\u5f00\u3002", "motivation": "\u89c6\u89c9\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5047\u80a2\u6b65\u6001\u5206\u6790\u4e2d\u68c0\u6d4b\u548c\u5206\u6790\u5047\u80a2\u5b58\u5728\u6311\u6218\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f15\u5165ProGait\u6570\u636e\u96c6\uff0c\u5305\u542b412\u4e2a\u89c6\u9891\u7247\u6bb5\uff0c\u8fd8\u7ed9\u51fa\u57fa\u51c6\u4efb\u52a1\u548c\u5fae\u8c03\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "result": "\u5c06\u57fa\u7ebf\u6a21\u578b\u4e0e\u9884\u8bad\u7ec3\u89c6\u89c9\u6a21\u578b\u5bf9\u6bd4\uff0c\u663e\u793aProGait\u6570\u636e\u96c6\u7528\u4e8e\u5047\u80a2\u7279\u5b9a\u4efb\u52a1\u65f6\u6cdb\u5316\u6027\u66f4\u597d\u3002", "conclusion": "ProGait\u6570\u636e\u96c6\u80fd\u6709\u6548\u652f\u6301\u591a\u79cd\u89c6\u89c9\u4efb\u52a1\uff0c\u5728\u5047\u80a2\u7279\u5b9a\u4efb\u52a1\u4e2d\u6709\u66f4\u597d\u8868\u73b0\u3002"}}
{"id": "2507.10240", "pdf": "https://arxiv.org/pdf/2507.10240", "abs": "https://arxiv.org/abs/2507.10240", "authors": ["Angelos Chatzimparmpas"], "title": "Visual Analytics for Explainable and Trustworthy Artificial Intelligence", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Our society increasingly depends on intelligent systems to solve complex\nproblems, ranging from recommender systems suggesting the next movie to watch\nto AI models assisting in medical diagnoses for hospitalized patients. With the\niterative improvement of diagnostic accuracy and efficiency, AI holds\nsignificant potential to mitigate medical misdiagnoses by preventing numerous\ndeaths and reducing an economic burden of approximately 450 EUR billion\nannually. However, a key obstacle to AI adoption lies in the lack of\ntransparency: many automated systems function as \"black boxes,\" providing\npredictions without revealing the underlying processes. This opacity can hinder\nexperts' ability to trust and rely on AI systems. Visual analytics (VA)\nprovides a compelling solution by combining AI models with interactive\nvisualizations. These specialized charts and graphs empower users to\nincorporate their domain expertise to refine and improve the models, bridging\nthe gap between AI and human understanding. In this work, we define,\ncategorize, and explore how VA solutions can foster trust across the stages of\na typical AI pipeline. We propose a design space for innovative visualizations\nand present an overview of our previously developed VA dashboards, which\nsupport critical tasks within the various pipeline stages, including data\nprocessing, feature engineering, hyperparameter tuning, understanding,\ndebugging, refining, and comparing models.", "AI": {"tldr": "\u793e\u4f1a\u4f9d\u8d56\u667a\u80fd\u7cfb\u7edf\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0cAI\u5728\u533b\u7597\u8bca\u65ad\u6709\u6f5c\u529b\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u89c6\u89c9\u5206\u6790\uff08VA\uff09\u7ed3\u5408AI\u4e0e\u53ef\u89c6\u5316\u53ef\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u672c\u6587\u5b9a\u4e49\u3001\u5206\u7c7b\u5e76\u63a2\u7d22VA\u5982\u4f55\u5728AI\u7ba1\u9053\u5404\u9636\u6bb5\u5efa\u7acb\u4fe1\u4efb\uff0c\u63d0\u51fa\u53ef\u89c6\u5316\u8bbe\u8ba1\u7a7a\u95f4\u5e76\u4ecb\u7ecdVA\u4eea\u8868\u76d8\u3002", "motivation": "\u793e\u4f1a\u4f9d\u8d56\u667a\u80fd\u7cfb\u7edf\uff0cAI\u5728\u533b\u7597\u8bca\u65ad\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\u963b\u788d\u5176\u5e94\u7528\uff0c\u9700\u8981\u89e3\u51b3\u4fe1\u4efb\u95ee\u9898\u3002", "method": "\u5b9a\u4e49\u3001\u5206\u7c7bVA\u89e3\u51b3\u65b9\u6848\uff0c\u63d0\u51fa\u521b\u65b0\u53ef\u89c6\u5316\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u4ecb\u7ecd\u5df2\u5f00\u53d1\u7684VA\u4eea\u8868\u76d8\u3002", "result": "\u63d0\u51fa\u4e86\u521b\u65b0\u53ef\u89c6\u5316\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5c55\u793a\u4e86\u652f\u6301AI\u7ba1\u9053\u5404\u9636\u6bb5\u5173\u952e\u4efb\u52a1\u7684VA\u4eea\u8868\u76d8\u3002", "conclusion": "VA\u80fd\u7ed3\u5408AI\u4e0e\u53ef\u89c6\u5316\uff0c\u5728AI\u7ba1\u9053\u5404\u9636\u6bb5\u5efa\u7acb\u4fe1\u4efb\uff0c\u5f25\u5408AI\u4e0e\u4eba\u7c7b\u7406\u89e3\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.09503", "pdf": "https://arxiv.org/pdf/2507.09503", "abs": "https://arxiv.org/abs/2507.09503", "authors": ["Zhentong Shao", "Jingtao Qin", "Nanpeng Yu"], "title": "Neural Two-Stage Stochastic Optimization for Solving Unit Commitment Problem", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "Submitted to IEEE Transactions on Power Systems", "summary": "This paper proposes a neural stochastic optimization method for efficiently\nsolving the two-stage stochastic unit commitment (2S-SUC) problem under\nhigh-dimensional uncertainty scenarios. The proposed method approximates the\nsecond-stage recourse problem using a deep neural network trained to map\ncommitment decisions and uncertainty features to recourse costs. The trained\nnetwork is subsequently embedded into the first-stage UC problem as a\nmixed-integer linear program (MILP), allowing for explicit enforcement of\noperational constraints while preserving the key uncertainty characteristics. A\nscenario-embedding network is employed to enable dimensionality reduction and\nfeature aggregation across arbitrary scenario sets, serving as a data-driven\nscenario reduction mechanism. Numerical experiments on IEEE 5-bus, 30-bus, and\n118-bus systems demonstrate that the proposed neural two-stage stochastic\noptimization method achieves solutions with an optimality gap of less than 1%,\nwhile enabling orders-of-magnitude speedup compared to conventional MILP\nsolvers and decomposition-based methods. Moreover, the model's size remains\nconstant regardless of the number of scenarios, offering significant\nscalability for large-scale stochastic unit commitment problems.", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u89e3\u51b3\u9ad8\u7ef4\u4e0d\u786e\u5b9a\u6027\u4e0b\u4e24\u9636\u6bb5\u968f\u673a\u673a\u7ec4\u7ec4\u5408\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u9ad8\u6700\u4f18\u6027\u548c\u901f\u5ea6\u63d0\u5347\u53ca\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u9ad8\u6548\u89e3\u51b3\u9ad8\u7ef4\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u4e0b\u7684\u4e24\u9636\u6bb5\u968f\u673a\u673a\u7ec4\u7ec4\u5408\u95ee\u9898\u3002", "method": "\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u7b2c\u4e8c\u9636\u6bb5\u8865\u507f\u95ee\u9898\uff0c\u5d4c\u5165\u7b2c\u4e00\u9636\u6bb5\u95ee\u9898\u6210\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u7528\u573a\u666f\u5d4c\u5165\u7f51\u7edc\u964d\u7ef4\u548c\u7279\u5f81\u805a\u5408\u3002", "result": "\u5728IEEE\u591a\u4e2a\u6bcd\u7ebf\u7cfb\u7edf\u5b9e\u9a8c\u4e2d\uff0c\u6700\u4f18\u6027\u5dee\u8ddd\u5c0f\u4e8e1%\uff0c\u6bd4\u4f20\u7edf\u6c42\u89e3\u5668\u548c\u5206\u89e3\u65b9\u6cd5\u901f\u5ea6\u5927\u5e45\u63d0\u5347\uff0c\u6a21\u578b\u89c4\u6a21\u4e0d\u968f\u573a\u666f\u6570\u91cf\u53d8\u5316\u3002", "conclusion": "\u6240\u63d0\u795e\u7ecf\u4e24\u9636\u6bb5\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u5bf9\u5927\u89c4\u6a21\u968f\u673a\u673a\u7ec4\u7ec4\u5408\u95ee\u9898\u6709\u663e\u8457\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2507.10250", "pdf": "https://arxiv.org/pdf/2507.10250", "abs": "https://arxiv.org/abs/2507.10250", "authors": ["Ashkan Shakarami", "Lorenzo Nicole", "Rocco Cappellesso", "Angelo Paolo Dei Tos", "Stefano Ghidoni"], "title": "DepViT-CAD: Deployable Vision Transformer-Based Cancer Diagnosis in Histopathology", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": "25 pages, 15 figures", "summary": "Accurate and timely cancer diagnosis from histopathological slides is vital\nfor effective clinical decision-making. This paper introduces DepViT-CAD, a\ndeployable AI system for multi-class cancer diagnosis in histopathology. At its\ncore is MAViT, a novel Multi-Attention Vision Transformer designed to capture\nfine-grained morphological patterns across diverse tumor types. MAViT was\ntrained on expert-annotated patches from 1008 whole-slide images, covering 11\ndiagnostic categories, including 10 major cancers and non-tumor tissue.\nDepViT-CAD was validated on two independent cohorts: 275 WSIs from The Cancer\nGenome Atlas and 50 routine clinical cases from pathology labs, achieving\ndiagnostic sensitivities of 94.11% and 92%, respectively. By combining\nstate-of-the-art transformer architecture with large-scale real-world\nvalidation, DepViT-CAD offers a robust and scalable approach for AI-assisted\ncancer diagnostics. To support transparency and reproducibility, software and\ncode will be made publicly available at GitHub.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u53ef\u90e8\u7f72\u7684AI\u7cfb\u7edfDepViT - CAD\u7528\u4e8e\u7ec4\u7ec7\u75c5\u7406\u5b66\u591a\u7c7b\u764c\u75c7\u8bca\u65ad\uff0c\u6838\u5fc3\u662fMAViT\uff0c\u7ecf\u5927\u89c4\u6a21\u9a8c\u8bc1\u6548\u679c\u826f\u597d\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "motivation": "\u5b9e\u73b0\u4ece\u7ec4\u7ec7\u75c5\u7406\u5207\u7247\u8fdb\u884c\u51c6\u786e\u53ca\u65f6\u7684\u764c\u75c7\u8bca\u65ad\uff0c\u4ee5\u8f85\u52a9\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u91c7\u7528\u65b0\u578b\u591a\u6ce8\u610f\u529b\u89c6\u89c9Transformer MAViT\uff0c\u57281008\u5f20\u5168\u5207\u7247\u56fe\u50cf\u7684\u4e13\u5bb6\u6807\u6ce8\u8865\u4e01\u4e0a\u8bad\u7ec3\uff0c\u5728\u4e24\u4e2a\u72ec\u7acb\u961f\u5217\u4e0a\u9a8c\u8bc1\u3002", "result": "\u5728\u4e24\u4e2a\u72ec\u7acb\u961f\u5217\u4e0a\u8bca\u65ad\u654f\u611f\u6027\u5206\u522b\u8fbe\u523094.11%\u548c92%\u3002", "conclusion": "DepViT - CAD\u7ed3\u5408\u5148\u8fdb\u67b6\u6784\u4e0e\u5927\u89c4\u6a21\u9a8c\u8bc1\uff0c\u4e3aAI\u8f85\u52a9\u764c\u75c7\u8bca\u65ad\u63d0\u4f9b\u4e86\u7a33\u5065\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u4ee5\u652f\u6301\u900f\u660e\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2507.10300", "pdf": "https://arxiv.org/pdf/2507.10300", "abs": "https://arxiv.org/abs/2507.10300", "authors": ["Hatef Otroshi Shahreza", "S\u00e9bastien Marcel"], "title": "FaceLLM: A Multimodal Large Language Model for Face Understanding", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted in ICCV 2025 workshops", "summary": "Multimodal large language models (MLLMs) have shown remarkable performance in\nvision-language tasks. However, existing MLLMs are primarily trained on generic\ndatasets, limiting their ability to reason on domain-specific visual cues such\nas those in facial images. In particular, tasks that require detailed\nunderstanding of facial structure, expression, emotion, and demographic\nfeatures remain underexplored by MLLMs due to the lack of large-scale annotated\nface image-text datasets. In this work, we introduce FaceLLM, a multimodal\nlarge language model trained specifically for facial image understanding. To\nconstruct the training data, we propose a novel weakly supervised pipeline that\nuses ChatGPT with attribute-aware prompts to generate high-quality\nquestion-answer pairs based on images from the FairFace dataset. The resulting\ncorpus, called FairFaceGPT, covers a diverse set of attributes including\nexpression, pose, skin texture, and forensic information. Our experiments\ndemonstrate that FaceLLM improves the performance of MLLMs on various\nface-centric tasks and achieves state-of-the-art performance. This work\nhighlights the potential of synthetic supervision via language models for\nbuilding domain-specialized MLLMs, and sets a precedent for trustworthy,\nhuman-centric multimodal AI systems. FairFaceGPT dataset and pretrained FaceLLM\nmodels are publicly available in the project page.", "AI": {"tldr": "\u4ecb\u7ecd\u9488\u5bf9\u9762\u90e8\u56fe\u50cf\u7406\u89e3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bFaceLLM\uff0c\u7528\u65b0\u65b9\u6cd5\u6784\u5efa\u8bad\u7ec3\u6570\u636e\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u9762\u90e8\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u5728\u901a\u7528\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u7f3a\u4e4f\u5927\u89c4\u6a21\u6807\u6ce8\u7684\u9762\u90e8\u56fe\u50cf\u6587\u672c\u6570\u636e\u96c6\uff0c\u96be\u4ee5\u5bf9\u7279\u5b9a\u9886\u57df\u7684\u9762\u90e8\u89c6\u89c9\u7ebf\u7d22\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5f31\u76d1\u7763\u7ba1\u9053\uff0c\u5229\u7528ChatGPT\u548c\u5c5e\u6027\u611f\u77e5\u63d0\u793a\uff0c\u57fa\u4e8eFairFace\u6570\u636e\u96c6\u56fe\u50cf\u751f\u6210\u9ad8\u8d28\u91cf\u95ee\u7b54\u5bf9\uff0c\u6784\u5efaFairFaceGPT\u8bed\u6599\u5e93\u3002", "result": "FaceLLM\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u4ee5\u9762\u90e8\u4e3a\u4e2d\u5fc3\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u51f8\u663e\u4e86\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5408\u6210\u76d1\u7763\u6784\u5efa\u7279\u5b9a\u9886\u57df\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u4e3a\u53ef\u4fe1\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u6811\u7acb\u4e86\u5148\u4f8b\u3002"}}
{"id": "2507.09624", "pdf": "https://arxiv.org/pdf/2507.09624", "abs": "https://arxiv.org/abs/2507.09624", "authors": ["Xiaojie Lin", "Baihe Ma", "Xu Wang", "Guangsheng Yu", "Ying He", "Wei Ni", "Ren Ping Liu"], "title": "CAN-Trace Attack: Exploit CAN Messages to Uncover Driving Trajectories", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "Driving trajectory data remains vulnerable to privacy breaches despite\nexisting mitigation measures. Traditional methods for detecting driving\ntrajectories typically rely on map-matching the path using Global Positioning\nSystem (GPS) data, which is susceptible to GPS data outage. This paper\nintroduces CAN-Trace, a novel privacy attack mechanism that leverages\nController Area Network (CAN) messages to uncover driving trajectories, posing\na significant risk to drivers' long-term privacy. A new trajectory\nreconstruction algorithm is proposed to transform the CAN messages,\nspecifically vehicle speed and accelerator pedal position, into weighted graphs\naccommodating various driving statuses. CAN-Trace identifies driving\ntrajectories using graph-matching algorithms applied to the created graphs in\ncomparison to road networks. We also design a new metric to evaluate matched\ncandidates, which allows for potential data gaps and matching inaccuracies.\nEmpirical validation under various real-world conditions, encompassing\ndifferent vehicles and driving regions, demonstrates the efficacy of CAN-Trace:\nit achieves an attack success rate of up to 90.59% in the urban region, and\n99.41% in the suburban region.", "AI": {"tldr": "\u73b0\u6709\u63aa\u65bd\u4e0b\u9a7e\u9a76\u8f68\u8ff9\u6570\u636e\u4ecd\u6709\u9690\u79c1\u98ce\u9669\uff0c\u672c\u6587\u63d0\u51faCAN - Trace\u9690\u79c1\u653b\u51fb\u673a\u5236\uff0c\u7528\u65b0\u7b97\u6cd5\u548c\u8bc4\u4f30\u6307\u6807\u8bc6\u522b\u8f68\u8ff9\uff0c\u5b9e\u8bc1\u8868\u660e\u5176\u5728\u4e0d\u540c\u533a\u57df\u653b\u51fb\u6210\u529f\u7387\u9ad8\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u9a7e\u9a76\u8f68\u8ff9\u65b9\u6cd5\u4f9d\u8d56GPS\u6613\u53d7\u6570\u636e\u4e2d\u65ad\u5f71\u54cd\uff0c\u4e14\u9a7e\u9a76\u8f68\u8ff9\u6570\u636e\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u65b0\u8f68\u8ff9\u91cd\u5efa\u7b97\u6cd5\u5c06CAN\u6d88\u606f\u8f6c\u5316\u4e3a\u52a0\u6743\u56fe\uff0c\u7528\u56fe\u5339\u914d\u7b97\u6cd5\u8bc6\u522b\u8f68\u8ff9\uff0c\u8bbe\u8ba1\u65b0\u6307\u6807\u8bc4\u4f30\u5339\u914d\u5019\u9009\u3002", "result": "\u5728\u57ce\u5e02\u533a\u57df\u653b\u51fb\u6210\u529f\u7387\u8fbe90.59%\uff0c\u90ca\u533a\u8fbe99.41%\u3002", "conclusion": "CAN - Trace\u5728\u4e0d\u540c\u73b0\u5b9e\u6761\u4ef6\u4e0b\u6709\u6548\uff0c\u5bf9\u9a7e\u9a76\u5458\u957f\u671f\u9690\u79c1\u6784\u6210\u91cd\u5927\u5a01\u80c1\u3002"}}
{"id": "2507.09627", "pdf": "https://arxiv.org/pdf/2507.09627", "abs": "https://arxiv.org/abs/2507.09627", "authors": ["Muhammad Kamran Saeed", "Ashfaq Khokhar", "Shakil Ahmed"], "title": "Lightweight Deep Learning-Based Channel Estimation for RIS-Aided Extremely Large-Scale MIMO Systems on Resource-Limited Edge Devices", "categories": ["cs.IT", "cs.CV", "cs.LG", "cs.NI", "math.IT"], "comment": null, "summary": "Next-generation wireless technologies such as 6G aim to meet demanding\nrequirements such as ultra-high data rates, low latency, and enhanced\nconnectivity. Extremely Large-Scale MIMO (XL-MIMO) and Reconfigurable\nIntelligent Surface (RIS) are key enablers, with XL-MIMO boosting spectral and\nenergy efficiency through numerous antennas, and RIS offering dynamic control\nover the wireless environment via passive reflective elements. However,\nrealizing their full potential depends on accurate Channel State Information\n(CSI). Recent advances in deep learning have facilitated efficient cascaded\nchannel estimation. However, the scalability and practical deployment of\nexisting estimation models in XL-MIMO systems remain limited. The growing\nnumber of antennas and RIS elements introduces a significant barrier to\nreal-time and efficient channel estimation, drastically increasing data volume,\nescalating computational complexity, requiring advanced hardware, and resulting\nin substantial energy consumption. To address these challenges, we propose a\nlightweight deep learning framework for efficient cascaded channel estimation\nin XL-MIMO systems, designed to minimize computational complexity and make it\nsuitable for deployment on resource-constrained edge devices. Using spatial\ncorrelations in the channel, we introduce a patch-based training mechanism that\nreduces the dimensionality of input to patch-level representations while\npreserving essential information, allowing scalable training for large-scale\nsystems. Simulation results under diverse conditions demonstrate that our\nframework significantly improves estimation accuracy and reduces computational\ncomplexity, regardless of the increasing number of antennas and RIS elements in\nXL-MIMO systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7528\u4e8eXL - MIMO\u7cfb\u7edf\u7ea7\u8054\u4fe1\u9053\u4f30\u8ba1\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u6a21\u62df\u663e\u793a\u5176\u63d0\u5347\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709XL - MIMO\u7cfb\u7edf\u4fe1\u9053\u4f30\u8ba1\u6a21\u578b\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u90e8\u7f72\u53d7\u9650\uff0c\u5929\u7ebf\u548cRIS\u5143\u7d20\u589e\u52a0\u5e26\u6765\u6570\u636e\u91cf\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u4fe1\u9053\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u5f15\u5165\u57fa\u4e8e\u8865\u4e01\u7684\u8bad\u7ec3\u673a\u5236\u964d\u4f4e\u8f93\u5165\u7ef4\u5ea6\u3002", "result": "\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\uff0c\u80fd\u5e94\u5bf9XL - MIMO\u7cfb\u7edf\u4e2d\u5929\u7ebf\u548cRIS\u5143\u7d20\u589e\u52a0\u7684\u6311\u6218\u3002"}}
{"id": "2507.10398", "pdf": "https://arxiv.org/pdf/2507.10398", "abs": "https://arxiv.org/abs/2507.10398", "authors": ["Diksha Mehta", "Prateek Mehta"], "title": "Devanagari Handwritten Character Recognition using Convolutional Neural Network", "categories": ["cs.CV", "cs.AI", "cs.CL", "14J60", "I.2.7; I.4; I.5; I.7.5"], "comment": "9 pages, 6 figures", "summary": "Handwritten character recognition is getting popular among researchers\nbecause of its possible applications in facilitating technological search\nengines, social media, recommender systems, etc. The Devanagari script is one\nof the oldest language scripts in India that does not have proper digitization\ntools. With the advancement of computing and technology, the task of this\nresearch is to extract handwritten Hindi characters from an image of Devanagari\nscript with an automated approach to save time and obsolete data. In this\npaper, we present a technique to recognize handwritten Devanagari characters\nusing two deep convolutional neural network layers. This work employs a\nmethodology that is useful to enhance the recognition rate and configures a\nconvolutional neural network for effective Devanagari handwritten text\nrecognition (DHTR). This approach uses the Devanagari handwritten character\ndataset (DHCD), an open dataset with 36 classes of Devanagari characters. Each\nof these classes has 1700 images for training and testing purposes. This\napproach obtains promising results in terms of accuracy by achieving 96.36%\naccuracy in testing and 99.55% in training time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e24\u4e2a\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5c42\u8bc6\u522b\u624b\u5199\u5929\u57ce\u6587\uff08Devanagari\uff09\u5b57\u7b26\u7684\u6280\u672f\uff0c\u4f7f\u7528\u516c\u5f00\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u548c\u6d4b\u8bd5\u51c6\u786e\u7387\u9ad8\u3002", "motivation": "\u624b\u5199\u5b57\u7b26\u8bc6\u522b\u5e94\u7528\u5e7f\u6cdb\uff0c\u5929\u57ce\u6587\u7f3a\u4e4f\u5408\u9002\u6570\u5b57\u5316\u5de5\u5177\uff0c\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u63d0\u53d6\u624b\u5199\u5370\u5730\u8bed\u5b57\u7b26\u4ee5\u8282\u7701\u65f6\u95f4\u548c\u5904\u7406\u9648\u65e7\u6570\u636e\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5c42\uff0c\u91c7\u7528\u80fd\u63d0\u9ad8\u8bc6\u522b\u7387\u7684\u65b9\u6cd5\uff0c\u914d\u7f6e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7528\u4e8e\u5929\u57ce\u6587\u624b\u5199\u6587\u672c\u8bc6\u522b\uff0c\u5229\u7528\u5305\u542b36\u7c7b\u5929\u57ce\u6587\u5b57\u7b26\u7684\u516c\u5f00\u6570\u636e\u96c6\u3002", "result": "\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe96.36%\uff0c\u8bad\u7ec3\u51c6\u786e\u7387\u8fbe99.55%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5929\u57ce\u6587\u624b\u5199\u5b57\u7b26\u8bc6\u522b\u4e0a\u53d6\u5f97\u4e86\u6709\u524d\u666f\u7684\u7ed3\u679c\u3002"}}
{"id": "2507.09640", "pdf": "https://arxiv.org/pdf/2507.09640", "abs": "https://arxiv.org/abs/2507.09640", "authors": ["Leonor Fernandes", "Tiago Gon\u00e7alves", "Jo\u00e3o Matos", "Luis Filipe Nakayama", "Jaime S. Cardoso"], "title": "Disentanglement and Assessment of Shortcuts in Ophthalmological Retinal Imaging Exams", "categories": ["cs.CV", "cs.LG"], "comment": "10 pages. Under review", "summary": "Diabetic retinopathy (DR) is a leading cause of vision loss in working-age\nadults. While screening reduces the risk of blindness, traditional imaging is\noften costly and inaccessible. Artificial intelligence (AI) algorithms present\na scalable diagnostic solution, but concerns regarding fairness and\ngeneralization persist. This work evaluates the fairness and performance of\nimage-trained models in DR prediction, as well as the impact of disentanglement\nas a bias mitigation technique, using the diverse mBRSET fundus dataset. Three\nmodels, ConvNeXt V2, DINOv2, and Swin V2, were trained on macula images to\npredict DR and sensitive attributes (SAs) (e.g., age and gender/sex). Fairness\nwas assessed between subgroups of SAs, and disentanglement was applied to\nreduce bias. All models achieved high DR prediction performance in diagnosing\n(up to 94% AUROC) and could reasonably predict age and gender/sex (91% and 77%\nAUROC, respectively). Fairness assessment suggests disparities, such as a 10%\nAUROC gap between age groups in DINOv2. Disentangling SAs from DR prediction\nhad varying results, depending on the model selected. Disentanglement improved\nDINOv2 performance (2% AUROC gain), but led to performance drops in ConvNeXt V2\nand Swin V2 (7% and 3%, respectively). These findings highlight the complexity\nof disentangling fine-grained features in fundus imaging and emphasize the\nimportance of fairness in medical imaging AI to ensure equitable and reliable\nhealthcare solutions.", "AI": {"tldr": "\u7814\u7a76\u7528mBRSET\u6570\u636e\u96c6\u8bc4\u4f30\u773c\u5e95\u5f71\u50cf\u8bad\u7ec3\u6a21\u578b\u5728\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\uff08DR\uff09\u9884\u6d4b\u4e2d\u7684\u516c\u5e73\u6027\u4e0e\u6027\u80fd\uff0c\u53ca\u89e3\u7f20\u4f5c\u4e3a\u504f\u5dee\u7f13\u89e3\u6280\u672f\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6a21\u578b\u9884\u6d4b\u6027\u80fd\u9ad8\u4f46\u516c\u5e73\u6027\u6709\u5dee\u5f02\uff0c\u89e3\u7f20\u6548\u679c\u56e0\u6a21\u578b\u800c\u5f02\u3002", "motivation": "\u4f20\u7edfDR\u7b5b\u67e5\u6210\u50cf\u6210\u672c\u9ad8\u4e14\u96be\u83b7\u53d6\uff0cAI\u7b97\u6cd5\u867d\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u516c\u5e73\u6027\u548c\u6cdb\u5316\u6027\u95ee\u9898\uff0c\u9700\u8bc4\u4f30\u5176\u516c\u5e73\u6027\u548c\u6027\u80fd\u3002", "method": "\u4f7f\u7528mBRSET\u6570\u636e\u96c6\uff0c\u8bad\u7ec3ConvNeXt V2\u3001DINOv2\u548cSwin V2\u4e09\u4e2a\u6a21\u578b\u9884\u6d4bDR\u548c\u654f\u611f\u5c5e\u6027\uff0c\u8bc4\u4f30\u5b50\u7ec4\u516c\u5e73\u6027\uff0c\u5e94\u7528\u89e3\u7f20\u6280\u672f\u51cf\u5c11\u504f\u5dee\u3002", "result": "\u6a21\u578bDR\u9884\u6d4b\u6027\u80fd\u9ad8\uff08\u6700\u9ad894% AUROC\uff09\uff0c\u80fd\u5408\u7406\u9884\u6d4b\u5e74\u9f84\u548c\u6027\u522b\uff1b\u516c\u5e73\u6027\u8bc4\u4f30\u6709\u5dee\u8ddd\uff0c\u5982DINOv2\u5e74\u9f84\u7ec4\u95f4\u670910% AUROC\u5dee\u8ddd\uff1b\u89e3\u7f20\u6548\u679c\u56e0\u6a21\u578b\u800c\u5f02\uff0cDINOv2\u6027\u80fd\u63d0\u5347\uff0cConvNeXt V2\u548cSwin V2\u4e0b\u964d\u3002", "conclusion": "\u773c\u5e95\u6210\u50cf\u4e2d\u89e3\u7f20\u7ec6\u7c92\u5ea6\u7279\u5f81\u590d\u6742\uff0c\u5f3a\u8c03\u533b\u5b66\u5f71\u50cfAI\u516c\u5e73\u6027\u5bf9\u786e\u4fdd\u516c\u5e73\u53ef\u9760\u533b\u7597\u89e3\u51b3\u65b9\u6848\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.09652", "pdf": "https://arxiv.org/pdf/2507.09652", "abs": "https://arxiv.org/abs/2507.09652", "authors": ["Christof Sch\u00f6tz", "Niklas Boers"], "title": "Machine-Precision Prediction of Low-Dimensional Chaotic Systems", "categories": ["nlin.CD", "cs.LG", "math.DS"], "comment": null, "summary": "Low-dimensional chaotic systems such as the Lorenz-63 model are commonly used\nto benchmark system-agnostic methods for learning dynamics from data. Here we\nshow that learning from noise-free observations in such systems can be achieved\nup to machine precision: using ordinary least squares regression on high-degree\npolynomial features with 512-bit arithmetic, our method exceeds the accuracy of\nstandard 64-bit numerical ODE solvers of the true underlying dynamical systems.\nDepending on the configuration, we obtain valid prediction times of 32 to 105\nLyapunov times for the Lorenz-63 system, dramatically outperforming prior work\nthat reaches 13 Lyapunov times at most. We further validate our results on\nThomas' Cyclically Symmetric Attractor, a non-polynomial chaotic system that is\nconsiderably more complex than the Lorenz-63 model, and show that similar\nresults extend also to higher dimensions using the spatiotemporally chaotic\nLorenz-96 model. Our findings suggest that learning low-dimensional chaotic\nsystems from noise-free data is a solved problem.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u4ece\u65e0\u566a\u58f0\u89c2\u6d4b\u4e2d\u5b66\u4e60\u4f4e\u7ef4\u6df7\u6c8c\u7cfb\u7edf\u53ef\u8fbe\u673a\u5668\u7cbe\u5ea6\uff0c\u65b9\u6cd5\u5728\u591a\u4e2a\u7cfb\u7edf\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8868\u660e\u4ece\u65e0\u566a\u58f0\u6570\u636e\u5b66\u4e60\u4f4e\u7ef4\u6df7\u6c8c\u7cfb\u7edf\u95ee\u9898\u5df2\u89e3\u51b3\u3002", "motivation": "\u4ee5\u4f4e\u7ef4\u6df7\u6c8c\u7cfb\u7edf\uff08\u5982Lorenz - 63\u6a21\u578b\uff09\u4e3a\u57fa\u51c6\uff0c\u63a2\u7a76\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u52a8\u529b\u5b66\u7684\u7cfb\u7edf\u65e0\u5173\u65b9\u6cd5\u3002", "method": "\u5728\u9ad8\u6b21\u591a\u9879\u5f0f\u7279\u5f81\u4e0a\u4f7f\u7528\u666e\u901a\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\uff0c\u5e76\u91c7\u7528512\u4f4d\u7b97\u672f\u8fd0\u7b97\u3002", "result": "\u7cbe\u5ea6\u8d8564\u4f4d\u6570\u503cODE\u6c42\u89e3\u5668\uff0cLorenz - 63\u7cfb\u7edf\u6709\u6548\u9884\u6d4b\u65f6\u95f4\u8fbe32\u5230105\u4e2aLyapunov\u65f6\u95f4\uff0c\u8fdc\u8d85\u5148\u524d\u5de5\u4f5c\uff1b\u5728\u66f4\u590d\u6742\u7cfb\u7edf\u53ca\u9ad8\u7ef4\u7cfb\u7edf\u4e0a\u7ed3\u679c\u7c7b\u4f3c\u3002", "conclusion": "\u4ece\u65e0\u566a\u58f0\u6570\u636e\u5b66\u4e60\u4f4e\u7ef4\u6df7\u6c8c\u7cfb\u7edf\u662f\u5df2\u89e3\u51b3\u7684\u95ee\u9898\u3002"}}
{"id": "2507.09685", "pdf": "https://arxiv.org/pdf/2507.09685", "abs": "https://arxiv.org/abs/2507.09685", "authors": ["Yutong Li", "Ilya Kolmanovsky"], "title": "Symptom-Driven Personalized Proton Pump Inhibitors Therapy Using Bayesian Neural Networks and Model Predictive Control", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "6 pages, 5 figures", "summary": "Proton Pump Inhibitors (PPIs) are the standard of care for gastric acid\ndisorders but carry significant risks when administered chronically at high\ndoses. Precise long-term control of gastric acidity is challenged by the\nimpracticality of invasive gastric acid monitoring beyond 72 hours and wide\ninter-patient variability. We propose a noninvasive, symptom-based framework\nthat tailors PPI dosing solely on patient-reported reflux and digestive symptom\npatterns. A Bayesian Neural Network prediction model learns to predict patient\nsymptoms and quantifies its uncertainty from historical symptom scores, meal,\nand PPIs intake data. These probabilistic forecasts feed a chance-constrained\nModel Predictive Control (MPC) algorithm that dynamically computes future PPI\ndoses to minimize drug usage while enforcing acid suppression with high\nconfidence - without any direct acid measurement. In silico studies over\ndiverse dietary schedules and virtual patient profiles demonstrate that our\nlearning-augmented MPC reduces total PPI consumption by 65 percent compared to\nstandard fixed regimens, while maintaining acid suppression with at least 95\npercent probability. The proposed approach offers a practical path to\npersonalized PPI therapy, minimizing treatment burden and overdose risk without\ninvasive sensors.", "AI": {"tldr": "\u63d0\u51fa\u975e\u4fb5\u5165\u6027\u3001\u57fa\u4e8e\u75c7\u72b6\u7684\u6846\u67b6\u6765\u8c03\u6574PPI\u5242\u91cf\uff0c\u5b66\u4e60\u589e\u5f3a\u7684MPC\u7b97\u6cd5\u53ef\u51cf\u5c11PPI\u6d88\u8017\u5e76\u4fdd\u8bc1\u6291\u9178\u6548\u679c\u3002", "motivation": "\u957f\u671f\u9ad8\u5242\u91cf\u4f7f\u7528PPI\u6709\u98ce\u9669\uff0c\u4e14\u7cbe\u786e\u957f\u671f\u63a7\u5236\u80c3\u9178\u53d7\u9650\u4e8e\u4fb5\u5165\u6027\u76d1\u6d4b\u7684\u4e0d\u5b9e\u9645\u548c\u60a3\u8005\u4e2a\u4f53\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u75c7\u72b6\u7684\u6846\u67b6\uff0c\u7528\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u75c7\u72b6\uff0c\u7ed3\u5408\u673a\u4f1a\u7ea6\u675f\u7684MPC\u7b97\u6cd5\u52a8\u6001\u8ba1\u7b97PPI\u5242\u91cf\u3002", "result": "\u5728\u4e0d\u540c\u996e\u98df\u548c\u865a\u62df\u60a3\u8005\u6a21\u578b\u4e2d\uff0c\u5b66\u4e60\u589e\u5f3a\u7684MPC\u8f83\u6807\u51c6\u56fa\u5b9a\u65b9\u6848\u51cf\u5c1165%\u7684PPI\u6d88\u8017\uff0c\u4e14\u81f3\u5c1195%\u6982\u7387\u4fdd\u8bc1\u6291\u9178\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4e2a\u6027\u5316PPI\u6cbb\u7597\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u51cf\u5c11\u6cbb\u7597\u8d1f\u62c5\u548c\u8fc7\u91cf\u98ce\u9669\uff0c\u65e0\u9700\u4fb5\u5165\u6027\u4f20\u611f\u5668\u3002"}}
{"id": "2507.09709", "pdf": "https://arxiv.org/pdf/2507.09709", "abs": "https://arxiv.org/abs/2507.09709", "authors": ["Baturay Saglam", "Paul Kassianik", "Blaine Nelson", "Sajana Weerawardhena", "Yaron Singer", "Amin Karbasi"], "title": "Large Language Models Encode Semantics in Low-Dimensional Linear Subspaces", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Understanding the latent space geometry of large language models (LLMs) is\nkey to interpreting their behavior and improving alignment. \\baturay{However,\nit remains unclear to what extent LLMs internally organize representations\nrelated to semantic understanding. To investigate this, we conduct a\nlarge-scale empirical study of hidden states in transformer-based LLMs,\nanalyzing 11 decoder-only models across 6 scientific topics and 12 layers each.\nWe find that high-level semantic information consistently lies in\nlow-dimensional subspaces that form linearly separable representations across\ndistinct domains. This separability becomes more pronounced in deeper layers\nand under prompts that trigger structured reasoning or alignment\nbehaviors$\\unicode{x2013}$even when surface content is unchanged. This geometry\nenables simple yet effective causal interventions in hidden space; for example,\nreasoning patterns like chain-of-thought can be captured by a single vector\ndirection. Together, these findings support the development of geometry-aware\ntools that operate directly on latent representations to detect and mitigate\nharmful or adversarial content, using methods such as transport-based defenses\nthat leverage this separability. As a proof of concept, we demonstrate this\npotential by training a simple MLP classifier as a lightweight latent-space\nguardrail, which detects adversarial and malicious prompts with high precision.", "AI": {"tldr": "\u5bf9\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u9ad8\u5c42\u8bed\u4e49\u4fe1\u606f\u4f4d\u4e8e\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e14\u5177\u6709\u7ebf\u6027\u53ef\u5206\u6027\uff0c\u652f\u6301\u5f00\u53d1\u51e0\u4f55\u611f\u77e5\u5de5\u5177\u3002", "motivation": "\u76ee\u524d\u4e0d\u6e05\u695a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u5185\u90e8\u7ec4\u7ec7\u4e0e\u8bed\u4e49\u7406\u89e3\u76f8\u5173\u7684\u8868\u5f81\uff0c\u65e8\u5728\u7814\u7a76\u6b64\u95ee\u9898\u3002", "method": "\u5bf911\u4e2a\u4ec5\u89e3\u7801\u5668\u6a21\u578b\u57286\u4e2a\u79d1\u5b66\u4e3b\u9898\u548c12\u5c42\u4e0a\u7684\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u9ad8\u5c42\u8bed\u4e49\u4fe1\u606f\u4f4d\u4e8e\u4f4e\u7ef4\u5b50\u7a7a\u95f4\uff0c\u5728\u4e0d\u540c\u9886\u57df\u5f62\u6210\u7ebf\u6027\u53ef\u5206\u8868\u5f81\uff0c\u6df1\u5c42\u548c\u7279\u5b9a\u63d0\u793a\u4e0b\u53ef\u5206\u6027\u66f4\u660e\u663e\uff0c\u53ef\u5728\u9690\u85cf\u7a7a\u95f4\u8fdb\u884c\u6709\u6548\u56e0\u679c\u5e72\u9884\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u5f00\u53d1\u51e0\u4f55\u611f\u77e5\u5de5\u5177\uff0c\u4ee5\u68c0\u6d4b\u548c\u7f13\u89e3\u6709\u5bb3\u6216\u5bf9\u6297\u6027\u5185\u5bb9\uff0c\u5982\u8bad\u7ec3\u7b80\u5355MLP\u5206\u7c7b\u5668\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u6f5c\u5728\u7a7a\u95f4\u62a4\u680f\u3002"}}
{"id": "2507.10435", "pdf": "https://arxiv.org/pdf/2507.10435", "abs": "https://arxiv.org/abs/2507.10435", "authors": ["Xinnan Dai", "Kai Yang", "Jay Revolinsky", "Kai Guo", "Aoran Wang", "Bohang Zhang", "Jiliang Tang"], "title": "From Sequence to Structure: Uncovering Substructure Reasoning in Transformers", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent studies suggest that large language models (LLMs) possess the\ncapability to solve graph reasoning tasks. Notably, even when graph structures\nare embedded within textual descriptions, LLMs can still effectively answer\nrelated questions. This raises a fundamental question: How can a decoder-only\nTransformer architecture understand underlying graph structures? To address\nthis, we start with the substructure extraction task, interpreting the inner\nmechanisms inside the transformers and analyzing the impact of the input\nqueries. Specifically, through both empirical results and theoretical analysis,\nwe present Induced Substructure Filtration (ISF), a perspective that captures\nthe substructure identification in the multi-layer transformers. We further\nvalidate the ISF process in LLMs, revealing consistent internal dynamics across\nlayers. Building on these insights, we explore the broader capabilities of\nTransformers in handling diverse graph types. Specifically, we introduce the\nconcept of thinking in substructures to efficiently extract complex composite\npatterns, and demonstrate that decoder-only Transformers can successfully\nextract substructures from attributed graphs, such as molecular graphs.\nTogether, our findings offer a new insight on how sequence-based Transformers\nperform the substructure extraction task over graph data.", "AI": {"tldr": "\u7814\u7a76\u89e3\u7801\u5668 - \u4ec5Transformer\u67b6\u6784\u7406\u89e3\u56fe\u7ed3\u6784\u7684\u673a\u5236\uff0c\u63d0\u51faISF\u89c6\u89d2\uff0c\u9a8c\u8bc1\u5176\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8fc7\u7a0b\uff0c\u63a2\u7d22\u5904\u7406\u4e0d\u540c\u56fe\u7c7b\u578b\u7684\u80fd\u529b\u3002", "motivation": "\u63a2\u7a76\u89e3\u7801\u5668 - \u4ec5Transformer\u67b6\u6784\u5982\u4f55\u7406\u89e3\u6f5c\u5728\u56fe\u7ed3\u6784\u3002", "method": "\u4ece\u5b50\u7ed3\u6784\u63d0\u53d6\u4efb\u52a1\u5165\u624b\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7ed3\u679c\u548c\u7406\u8bba\u5206\u6790\u63d0\u51faISF\u89c6\u89d2\uff0c\u9a8c\u8bc1\u5176\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8fc7\u7a0b\uff0c\u63a2\u7d22\u5904\u7406\u4e0d\u540c\u56fe\u7c7b\u578b\u7684\u80fd\u529b\u3002", "result": "\u63ed\u793a\u591a\u5c42Transformer\u4e2d\u4e00\u81f4\u7684\u5185\u90e8\u52a8\u6001\uff0c\u8bc1\u660e\u89e3\u7801\u5668 - \u4ec5Transformer\u53ef\u4ece\u5c5e\u6027\u56fe\u4e2d\u6210\u529f\u63d0\u53d6\u5b50\u7ed3\u6784\u3002", "conclusion": "\u4e3a\u57fa\u4e8e\u5e8f\u5217\u7684Transformer\u5728\u56fe\u6570\u636e\u4e0a\u6267\u884c\u5b50\u7ed3\u6784\u63d0\u53d6\u4efb\u52a1\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2507.10445", "pdf": "https://arxiv.org/pdf/2507.10445", "abs": "https://arxiv.org/abs/2507.10445", "authors": ["Chris Madge", "Matthew Purver", "Massimo Poesio"], "title": "Referential ambiguity and clarification requests: comparing human and LLM behaviour", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this work we examine LLMs' ability to ask clarification questions in\ntask-oriented dialogues that follow the asynchronous\ninstruction-giver/instruction-follower format. We present a new corpus that\ncombines two existing annotations of the Minecraft Dialogue Corpus -- one for\nreference and ambiguity in reference, and one for SDRT including clarifications\n-- into a single common format providing the necessary information to\nexperiment with clarifications and their relation to ambiguity. With this\ncorpus we compare LLM actions with original human-generated clarification\nquestions, examining how both humans and LLMs act in the case of ambiguity. We\nfind that there is only a weak link between ambiguity and humans producing\nclarification questions in these dialogues, and low correlation between humans\nand LLMs. Humans hardly ever produce clarification questions for referential\nambiguity, but often do so for task-based uncertainty. Conversely, LLMs produce\nmore clarification questions for referential ambiguity, but less so for task\nuncertainty. We question if LLMs' ability to ask clarification questions is\npredicated on their recent ability to simulate reasoning, and test this with\ndifferent reasoning approaches, finding that reasoning does appear to increase\nquestion frequency and relevancy.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u4e2d\u63d0\u51fa\u6f84\u6e05\u95ee\u9898\u7684\u80fd\u529b\uff0c\u6784\u5efa\u65b0\u8bed\u6599\u5e93\u5bf9\u6bd4\u4eba\u7c7b\u548cLLMs\u884c\u4e3a\uff0c\u53d1\u73b0\u4e24\u8005\u5dee\u5f02\uff0c\u6d4b\u8bd5\u63a8\u7406\u5bf9\u63d0\u95ee\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u5f02\u6b65\u6307\u4ee4\u683c\u5f0f\u7684\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u4e2d\u63d0\u51fa\u6f84\u6e05\u95ee\u9898\u7684\u80fd\u529b\u3002", "method": "\u5c06Minecraft\u5bf9\u8bdd\u8bed\u6599\u5e93\u7684\u4e24\u79cd\u6ce8\u91ca\u6574\u5408\u4e3a\u65b0\u8bed\u6599\u5e93\uff0c\u5bf9\u6bd4\u4eba\u7c7b\u548cLLMs\u5728\u6b67\u4e49\u60c5\u51b5\u4e0b\u7684\u884c\u4e3a\uff0c\u7528\u4e0d\u540c\u63a8\u7406\u65b9\u6cd5\u6d4b\u8bd5\u63a8\u7406\u5bf9\u63d0\u95ee\u7684\u5f71\u54cd\u3002", "result": "\u5bf9\u8bdd\u4e2d\u6b67\u4e49\u4e0e\u4eba\u7c7b\u63d0\u51fa\u6f84\u6e05\u95ee\u9898\u5173\u8054\u5f31\uff0c\u4eba\u7c7b\u548cLLMs\u76f8\u5173\u6027\u4f4e\uff1b\u4eba\u7c7b\u56e0\u4efb\u52a1\u4e0d\u786e\u5b9a\u6027\u63d0\u95ee\u591a\uff0cLLMs\u56e0\u6307\u79f0\u6b67\u4e49\u63d0\u95ee\u591a\uff1b\u63a8\u7406\u80fd\u589e\u52a0\u63d0\u95ee\u9891\u7387\u548c\u76f8\u5173\u6027\u3002", "conclusion": "\u63a8\u7406\u6709\u52a9\u4e8e\u63d0\u9ad8LLMs\u63d0\u51fa\u6f84\u6e05\u95ee\u9898\u7684\u9891\u7387\u548c\u76f8\u5173\u6027\u3002"}}
{"id": "2507.10447", "pdf": "https://arxiv.org/pdf/2507.10447", "abs": "https://arxiv.org/abs/2507.10447", "authors": ["Tomasz Sroka", "Tomasz W\u0119\u017cowicz", "Dominik Sidorczuk", "Mateusz Modrzejewski"], "title": "Evaluating Fake Music Detection Performance Under Audio Augmentations", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": "ISMIR 2025 LBD, 2 pages + bibliography, 1 figure", "summary": "With the rapid advancement of generative audio models, distinguishing between\nhuman-composed and generated music is becoming increasingly challenging. As a\nresponse, models for detecting fake music have been proposed. In this work, we\nexplore the robustness of such systems under audio augmentations. To evaluate\nmodel generalization, we constructed a dataset consisting of both real and\nsynthetic music generated using several systems. We then apply a range of audio\ntransformations and analyze how they affect classification accuracy. We test\nthe performance of a recent state-of-the-art musical deepfake detection model\nin the presence of audio augmentations. The performance of the model decreases\nsignificantly even with the introduction of light augmentations.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u97f3\u4e50\u5047\u9020\u68c0\u6d4b\u7cfb\u7edf\u5728\u97f3\u9891\u589e\u5f3a\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u97f3\u9891\u6a21\u578b\u53d1\u5c55\uff0c\u533a\u5206\u4eba\u7c7b\u521b\u4f5c\u548c\u751f\u6210\u97f3\u4e50\u53d8\u96be\uff0c\u9700\u8981\u7814\u7a76\u68c0\u6d4b\u7cfb\u7edf\u5728\u97f3\u9891\u589e\u5f3a\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b\u771f\u5b9e\u548c\u5408\u6210\u97f3\u4e50\u7684\u6570\u636e\u96c6\uff0c\u5e94\u7528\u4e00\u7cfb\u5217\u97f3\u9891\u53d8\u6362\u5e76\u5206\u6790\u5176\u5bf9\u5206\u7c7b\u51c6\u786e\u7387\u7684\u5f71\u54cd\uff0c\u6d4b\u8bd5\u5148\u8fdb\u97f3\u4e50\u6df1\u5ea6\u5047\u9020\u68c0\u6d4b\u6a21\u578b\u3002", "result": "\u5373\u4f7f\u5f15\u5165\u8f7b\u5ea6\u589e\u5f3a\uff0c\u6a21\u578b\u6027\u80fd\u4e5f\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u97f3\u4e50\u5047\u9020\u68c0\u6d4b\u7cfb\u7edf\u5728\u97f3\u9891\u589e\u5f3a\u4e0b\u9c81\u68d2\u6027\u8f83\u5dee\u3002"}}
{"id": "2507.09750", "pdf": "https://arxiv.org/pdf/2507.09750", "abs": "https://arxiv.org/abs/2507.09750", "authors": ["Enric Gus\u00f3", "Joanna Luberadzka", "Umut Sayin", "Xavier Serra"], "title": "MB-RIRs: a Synthetic Room Impulse Response Dataset with Frequency-Dependent Absorption Coefficients", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Accepted to WASPAA25", "summary": "We investigate the effects of four strategies for improving the ecological\nvalidity of synthetic room impulse response (RIR) datasets for monoaural Speech\nEnhancement (SE). We implement three features on top of the traditional image\nsource method-based (ISM) shoebox RIRs: multiband absorption coefficients,\nsource directivity and receiver directivity. We additionally consider\nmesh-based RIRs from the SoundSpaces dataset. We then train a DeepFilternet3\nmodel for each RIR dataset and evaluate the performance on a test set of real\nRIRs both objectively and subjectively. We find that RIRs which use\nfrequency-dependent acoustic absorption coefficients (MB-RIRs) can obtain\n+0.51dB of SDR and a +8.9 MUSHRA score when evaluated on real RIRs. The MB-RIRs\ndataset is publicly available for free download.", "AI": {"tldr": "\u7814\u7a76\u56db\u79cd\u63d0\u5347\u5408\u6210\u623f\u95f4\u8109\u51b2\u54cd\u5e94\uff08RIR\uff09\u6570\u636e\u96c6\u751f\u6001\u6709\u6548\u6027\u7684\u7b56\u7565\uff0c\u53d1\u73b0\u4f7f\u7528\u9891\u7387\u76f8\u5173\u5438\u58f0\u7cfb\u6570\u7684MB - RIRs\u6548\u679c\u597d\u4e14\u6570\u636e\u96c6\u514d\u8d39\u516c\u5f00\u3002", "motivation": "\u63d0\u5347\u5408\u6210RIR\u6570\u636e\u96c6\u7528\u4e8e\u5355\u58f0\u9053\u8bed\u97f3\u589e\u5f3a\u7684\u751f\u6001\u6709\u6548\u6027\u3002", "method": "\u5728\u4f20\u7edf\u57fa\u4e8e\u56fe\u50cf\u6e90\u65b9\u6cd5\u7684\u978b\u76d2RIR\u4e0a\u5b9e\u73b0\u4e09\u4e2a\u7279\u5f81\uff0c\u8003\u8651SoundSpaces\u6570\u636e\u96c6\u7684\u57fa\u4e8e\u7f51\u683c\u7684RIR\uff0c\u4e3a\u6bcf\u4e2aRIR\u6570\u636e\u96c6\u8bad\u7ec3DeepFilternet3\u6a21\u578b\u5e76\u5728\u771f\u5b9eRIR\u6d4b\u8bd5\u96c6\u4e0a\u4e3b\u5ba2\u89c2\u8bc4\u4f30\u3002", "result": "\u4f7f\u7528\u9891\u7387\u76f8\u5173\u5438\u58f0\u7cfb\u6570\u7684MB - RIRs\u5728\u771f\u5b9eRIR\u4e0a\u8bc4\u4f30\u65f6\uff0cSDR\u63d0\u5347+0.51dB\uff0cMUSHRA\u5f97\u5206\u63d0\u5347+8.9\u3002", "conclusion": "MB - RIRs\u5728\u63d0\u5347\u751f\u6001\u6709\u6548\u6027\u4e0a\u6548\u679c\u8f83\u597d\uff0c\u4e14\u6570\u636e\u96c6\u514d\u8d39\u516c\u5f00\u53ef\u4e0b\u8f7d\u3002"}}
{"id": "2507.10449", "pdf": "https://arxiv.org/pdf/2507.10449", "abs": "https://arxiv.org/abs/2507.10449", "authors": ["Hongyong Han", "Wei Wang", "Gaowei Zhang", "Mingjie Li", "Yi Wang"], "title": "CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Coral reefs are vital yet vulnerable ecosystems that require continuous\nmonitoring to support conservation. While coral reef images provide essential\ninformation in coral monitoring, interpreting such images remains challenging\ndue to the need for domain expertise. Visual Question Answering (VQA), powered\nby Large Vision-Language Models (LVLMs), has great potential in user-friendly\ninteraction with coral reef images. However, applying VQA to coral imagery\ndemands a dedicated dataset that addresses two key challenges: domain-specific\nannotations and multidimensional questions. In this work, we introduce\nCoralVQA, the first large-scale VQA dataset for coral reef analysis. It\ncontains 12,805 real-world coral images from 67 coral genera collected from 3\noceans, along with 277,653 question-answer pairs that comprehensively assess\necological and health-related conditions. To construct this dataset, we develop\na semi-automatic data construction pipeline in collaboration with marine\nbiologists to ensure both scalability and professional-grade data quality.\nCoralVQA presents novel challenges and provides a comprehensive benchmark for\nstudying vision-language reasoning in the context of coral reef images. By\nevaluating several state-of-the-art LVLMs, we reveal key limitations and\nopportunities. These insights form a foundation for future LVLM development,\nwith a particular emphasis on supporting coral conservation efforts.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u9996\u4e2a\u7528\u4e8e\u73ca\u745a\u7901\u5206\u6790\u7684\u5927\u89c4\u6a21VQA\u6570\u636e\u96c6CoralVQA\uff0c\u9610\u8ff0\u6784\u5efa\u65b9\u6cd5\u5e76\u8bc4\u4f30\u6a21\u578b\uff0c\u4e3a\u672a\u6765LVLM\u53d1\u5c55\u53ca\u73ca\u745a\u4fdd\u62a4\u5960\u57fa\u3002", "motivation": "\u73ca\u745a\u7901\u76d1\u6d4b\u9700\u89e3\u8bfb\u56fe\u50cf\uff0c\u4f46\u56e0\u4e13\u4e1a\u8981\u6c42\u9ad8\u5b58\u5728\u6311\u6218\uff0cVQA\u6709\u6f5c\u529b\uff0c\u4e0d\u8fc7\u9700\u89e3\u51b3\u7279\u5b9a\u6570\u636e\u96c6\u7684\u9886\u57df\u6ce8\u91ca\u548c\u591a\u7ef4\u95ee\u9898\u3002", "method": "\u4e0e\u6d77\u6d0b\u751f\u7269\u5b66\u5bb6\u5408\u4f5c\u5f00\u53d1\u534a\u81ea\u52a8\u5316\u6570\u636e\u6784\u5efa\u6d41\u7a0b\uff0c\u6784\u5efa\u542b12,805\u5f20\u73ca\u745a\u56fe\u50cf\u548c277,653\u5bf9\u95ee\u7b54\u5bf9\u7684CoralVQA\u6570\u636e\u96c6\u3002", "result": "\u8bc4\u4f30\u591a\u4e2aLVLM\uff0c\u63ed\u793a\u5173\u952e\u5c40\u9650\u548c\u673a\u4f1a\u3002", "conclusion": "\u7814\u7a76\u4e3a\u672a\u6765LVLM\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\uff0c\u5f3a\u8c03\u5bf9\u73ca\u745a\u4fdd\u62a4\u5de5\u4f5c\u7684\u652f\u6301\u3002"}}
{"id": "2507.09757", "pdf": "https://arxiv.org/pdf/2507.09757", "abs": "https://arxiv.org/abs/2507.09757", "authors": ["Chunyan Li", "Wenkai Yu", "Qi Wang"], "title": "Energy Dissipation Rate Guided Adaptive Sampling for Physics-Informed Neural Networks: Resolving Surface-Bulk Dynamics in Allen-Cahn Systems", "categories": ["math.NA", "cs.LG", "cs.NA", "35K57, 68T07"], "comment": "32 pages, 22 figures", "summary": "We introduce the Energy Dissipation Rate guided Adaptive Sampling (EDRAS)\nstrategy, a novel method that substantially enhances the performance of\nPhysics-Informed Neural Networks (PINNs) in solving thermodynamically\nconsistent partial differential equations (PDEs) over arbitrary domains. EDRAS\nleverages the local energy dissipation rate density as a guiding metric to\nidentify and adaptively re-sample critical collocation points from both the\ninterior and boundary of the computational domain. This dynamical sampling\napproach improves the accuracy of residual-based PINNs by aligning the training\nprocess with the underlying physical structure of the system. In this study, we\ndemonstrate the effectiveness of EDRAS using the Allen-Cahn phase field model\nin irregular geometries, achieving up to a sixfold reduction in the relative\nmean square error compared to traditional residual-based adaptive refinement\n(RAR) methods. Moreover, we compare EDRAS with other residual-based adaptive\nsampling approaches and show that EDRAS is not only computationally more\nefficient but also more likely to identify high-impact collocation points.\nThrough numerical solutions of the Allen-Cahn equation with both static\n(Neumann) and dynamic boundary conditions in 2D disk- and ellipse-shaped\ndomains solved using PINN coupled with EDRAS, we gain significant insights into\nhow dynamic boundary conditions influence bulk phase evolution and\nthermodynamic behavior. The proposed approach offers an effective, physically\ninformed enhancement to PINN frameworks for solving thermodynamically\nconsistent models, making PINN a robust and versatile computational tool for\ninvestigating complex thermodynamic processes in arbitrary geometries.", "AI": {"tldr": "\u63d0\u51faEDRAS\u7b56\u7565\u63d0\u5347PINNs\u6c42\u89e3\u70ed\u529b\u5b66\u4e00\u81f4PDEs\u6027\u80fd\uff0c\u4ee5Allen - Cahn\u6a21\u578b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63d0\u5347Physics - Informed Neural Networks (PINNs)\u5728\u6c42\u89e3\u70ed\u529b\u5b66\u4e00\u81f4\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\u65f6\u7684\u6027\u80fd\u3002", "method": "\u5f15\u5165Energy Dissipation Rate guided Adaptive Sampling (EDRAS)\u7b56\u7565\uff0c\u5229\u7528\u5c40\u90e8\u80fd\u91cf\u8017\u6563\u7387\u5bc6\u5ea6\u4f5c\u4e3a\u6307\u5bfc\u6307\u6807\uff0c\u81ea\u9002\u5e94\u5730\u91cd\u65b0\u91c7\u6837\u5173\u952e\u914d\u70b9\u3002", "result": "\u5728\u4e0d\u89c4\u5219\u51e0\u4f55\u7684Allen - Cahn\u76f8\u573a\u6a21\u578b\u4e2d\uff0c\u76f8\u5bf9\u5747\u65b9\u8bef\u5dee\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6700\u591a\u964d\u4f4e\u516d\u500d\uff0c\u8ba1\u7b97\u66f4\u9ad8\u6548\uff0c\u66f4\u6613\u8bc6\u522b\u9ad8\u5f71\u54cd\u914d\u70b9\u3002", "conclusion": "EDRAS\u4e3aPINN\u6846\u67b6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u3001\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u589e\u5f3a\uff0c\u4f7fPINN\u6210\u4e3a\u7814\u7a76\u4efb\u610f\u51e0\u4f55\u4e2d\u590d\u6742\u70ed\u529b\u5b66\u8fc7\u7a0b\u7684\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2507.10457", "pdf": "https://arxiv.org/pdf/2507.10457", "abs": "https://arxiv.org/abs/2507.10457", "authors": ["Hammad Atta", "Ken Huang", "Manish Bhatt", "Kamal Ahmed", "Muhammad Aziz Ul Haq", "Yasir Mehmood"], "title": "Logic layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "The integration of large language models (LLMs) into enterprise systems has\ncreated a new class of covert security vulnerabilities, particularly within\nlogic-execution layers and persistent-memory contexts. In this paper, we\nintroduce Logic-Layer Prompt Control Injection (LPCI), a novel attack category\nin which encoded, delayed, and conditionally triggered payloads are embedded in\nmemory, vector stores, or tool outputs. These payloads can bypass conventional\ninput filters and trigger unauthorised behaviour across sessions.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u4f01\u4e1a\u7cfb\u7edf\u4ea7\u751f\u65b0\u7684\u9690\u853d\u5b89\u5168\u6f0f\u6d1e\uff0c\u4ecb\u7ecd\u4e86\u65b0\u578b\u653b\u51fb\u7c7b\u522bLPCI\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u4f01\u4e1a\u7cfb\u7edf\u4ea7\u751f\u4e86\u65b0\u7684\u9690\u853d\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u7814\u7a76\u5e94\u5bf9\u3002", "method": "\u63d0\u51faLogic - Layer Prompt Control Injection (LPCI)\u8fd9\u4e00\u65b0\u578b\u653b\u51fb\u7c7b\u522b\uff0c\u5c06\u7f16\u7801\u3001\u5ef6\u8fdf\u548c\u6761\u4ef6\u89e6\u53d1\u7684\u6709\u6548\u8d1f\u8f7d\u5d4c\u5165\u5185\u5b58\u3001\u5411\u91cf\u5b58\u50a8\u6216\u5de5\u5177\u8f93\u51fa\u4e2d\u3002", "result": "\u8be5\u6709\u6548\u8d1f\u8f7d\u53ef\u7ed5\u8fc7\u4f20\u7edf\u8f93\u5165\u8fc7\u6ee4\u5668\uff0c\u8de8\u4f1a\u8bdd\u89e6\u53d1\u672a\u7ecf\u6388\u6743\u7684\u884c\u4e3a\u3002", "conclusion": "LLMs\u96c6\u6210\u5230\u4f01\u4e1a\u7cfb\u7edf\u5e26\u6765\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0cLPCI\u653b\u51fb\u5177\u6709\u7ed5\u8fc7\u4f20\u7edf\u9632\u62a4\u673a\u5236\u7684\u98ce\u9669\u3002"}}
{"id": "2507.09758", "pdf": "https://arxiv.org/pdf/2507.09758", "abs": "https://arxiv.org/abs/2507.09758", "authors": ["Qi Feng", "Yihong Liu", "Hinrich Sch\u00fctze"], "title": "Your Pretrained Model Tells the Difficulty Itself: A Self-Adaptive Curriculum Learning Paradigm for Natural Language Understanding", "categories": ["cs.CL", "cs.LG", "I.2.7; I.2.6"], "comment": "18 pages, 23 figures. To appear in ACL 2025 Student Research Workshop\n  (SRW)", "summary": "Curriculum learning is a widely adopted training strategy in natural language\nprocessing (NLP), where models are exposed to examples organized by increasing\ndifficulty to enhance learning efficiency and performance. However, most\nexisting approaches rely on manually defined difficulty metrics -- such as text\nlength -- which may not accurately reflect the model's own perspective. To\novercome this limitation, we present a self-adaptive curriculum learning\nparadigm that prioritizes fine-tuning examples based on difficulty scores\npredicted by pre-trained language models (PLMs) themselves. Building on these\nscores, we explore various training strategies that differ in the ordering of\nexamples for the fine-tuning: from easy-to-hard, hard-to-easy, to mixed\nsampling. We evaluate our method on four natural language understanding (NLU)\ndatasets covering both binary and multi-class classification tasks.\nExperimental results show that our approach leads to faster convergence and\nimproved performance compared to standard random sampling.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u8bfe\u7a0b\u5b66\u4e60\u8303\u5f0f\uff0c\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u96be\u5ea6\u5f97\u5206\u5bf9\u5fae\u8c03\u793a\u4f8b\u6392\u5e8f\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u968f\u673a\u91c7\u6837\u3002", "motivation": "\u73b0\u6709\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u5b9a\u4e49\u96be\u5ea6\u6307\u6807\uff0c\u4e0d\u80fd\u51c6\u786e\u53cd\u6620\u6a21\u578b\u81ea\u8eab\u89c6\u89d2\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u8bfe\u7a0b\u5b66\u4e60\u8303\u5f0f\uff0c\u6839\u636e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u96be\u5ea6\u5f97\u5206\u5bf9\u5fae\u8c03\u793a\u4f8b\u6392\u5e8f\uff0c\u63a2\u7d22\u591a\u79cd\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u56db\u4e2a\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u76f8\u6bd4\u6807\u51c6\u968f\u673a\u91c7\u6837\uff0c\u8be5\u65b9\u6cd5\u6536\u655b\u66f4\u5feb\u3001\u6027\u80fd\u66f4\u597d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u8bfe\u7a0b\u5b66\u4e60\u8303\u5f0f\u6709\u6548\uff0c\u80fd\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2507.10461", "pdf": "https://arxiv.org/pdf/2507.10461", "abs": "https://arxiv.org/abs/2507.10461", "authors": ["Tao Tang", "Chengxu Yang"], "title": "RAPNet: A Receptive-Field Adaptive Convolutional Neural Network for Pansharpening", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "eess.IV"], "comment": "To appear in the proceedings of the 6th International Conference on\n  Artificial Intelligence and Electromechanical Automation (AIEA 2025). 5\n  pages, 6 figures", "summary": "Pansharpening refers to the process of integrating a high resolution\npanchromatic (PAN) image with a lower resolution multispectral (MS) image to\ngenerate a fused product, which is pivotal in remote sensing. Despite the\neffectiveness of CNNs in addressing this challenge, they are inherently\nconstrained by the uniform application of convolutional kernels across all\nspatial positions, overlooking local content variations. To overcome this\nissue, we introduce RAPNet, a new architecture that leverages content-adaptive\nconvolution. At its core, RAPNet employs the Receptive-field Adaptive\nPansharpening Convolution (RAPConv), designed to produce spatially adaptive\nkernels responsive to local feature context, thereby enhancing the precision of\nspatial detail extraction. Additionally, the network integrates the\nPansharpening Dynamic Feature Fusion (PAN-DFF) module, which incorporates an\nattention mechanism to achieve an optimal balance between spatial detail\nenhancement and spectral fidelity. Comprehensive evaluations on publicly\navailable datasets confirm that RAPNet delivers superior performance compared\nto existing approaches, as demonstrated by both quantitative metrics and\nqualitative assessments. Ablation analyses further substantiate the\neffectiveness of the proposed adaptive components.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u9065\u611f\u56fe\u50cf\u878d\u5408\u7f51\u7edcRAPNet\uff0c\u91c7\u7528\u5185\u5bb9\u81ea\u9002\u5e94\u5377\u79ef\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "CNN\u5728\u5904\u7406\u9065\u611f\u56fe\u50cf\u878d\u5408\u65f6\u56e0\u5377\u79ef\u6838\u7edf\u4e00\u5e94\u7528\uff0c\u5ffd\u7565\u5c40\u90e8\u5185\u5bb9\u53d8\u5316\uff0c\u6548\u679c\u53d7\u9650\u3002", "method": "\u5f15\u5165RAPNet\uff0c\u91c7\u7528Receptive - field Adaptive Pansharpening Convolution\u4ea7\u751f\u81ea\u9002\u5e94\u5377\u79ef\u6838\uff0c\u96c6\u6210Pansharpening Dynamic Feature Fusion\u6a21\u5757\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u663e\u793a\uff0cRAPNet\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6d88\u878d\u5206\u6790\u8bc1\u660e\u81ea\u9002\u5e94\u7ec4\u4ef6\u6709\u6548\u3002", "conclusion": "RAPNet\u901a\u8fc7\u5185\u5bb9\u81ea\u9002\u5e94\u5377\u79ef\u548c\u52a8\u6001\u7279\u5f81\u878d\u5408\u6a21\u5757\uff0c\u80fd\u66f4\u597d\u5730\u5e73\u8861\u7a7a\u95f4\u7ec6\u8282\u589e\u5f3a\u548c\u5149\u8c31\u4fdd\u771f\u5ea6\uff0c\u63d0\u5347\u9065\u611f\u56fe\u50cf\u878d\u5408\u6548\u679c\u3002"}}
{"id": "2507.10464", "pdf": "https://arxiv.org/pdf/2507.10464", "abs": "https://arxiv.org/abs/2507.10464", "authors": ["Sarthak Yadav", "Sergios Theodoridis", "Zheng-Hua Tan"], "title": "AudioMAE++: learning better masked audio representations with SwiGLU FFNs", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "TO APPEAR AT IEEE MLSP 2025", "summary": "Masked Autoencoders (MAEs) trained on audio spectrogram patches have emerged\nas a prominent approach for learning self-supervised audio representations.\nWhile several recent papers have evaluated key aspects of training MAEs on\naudio data, the majority of these approaches still leverage vanilla transformer\nbuilding blocks, whereas the transformer community has seen steady integration\nof newer architectural advancements. In this work, we propose AudioMAE++, a\nrevamped audio masked autoencoder with two such enhancements, namely\nmacaron-style transformer blocks with gated linear units. When pretrained on\nthe AudioSet dataset, the proposed AudioMAE++ models outperform existing MAE\nbased approaches on 10 diverse downstream tasks, demonstrating excellent\nperformance on audio classification and speech-based benchmarks. The proposed\nAudioMAE++ models also demonstrate excellent scaling characteristics,\noutperforming directly comparable standard MAE baselines with up to 4x more\nparameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u7684\u97f3\u9891\u63a9\u7801\u81ea\u7f16\u7801\u5668AudioMAE++\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eMAE\u7684\u65b9\u6cd5\uff0c\u4e14\u6709\u826f\u597d\u7684\u6269\u5c55\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u97f3\u9891\u6570\u636e\u8bad\u7ec3MAE\u7684\u65b9\u6cd5\u5927\u591a\u4f7f\u7528\u666e\u901atransformer\u6784\u5efa\u5757\uff0c\u800ctransformer\u793e\u533a\u5df2\u6709\u65b0\u67b6\u6784\u8fdb\u5c55\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faAudioMAE++\uff0c\u91c7\u7528macaron\u98ce\u683ctransformer\u5757\u548c\u95e8\u63a7\u7ebf\u6027\u5355\u5143\u3002", "result": "\u5728AudioSet\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u540e\uff0cAudioMAE++\u572810\u4e2a\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eMAE\u7684\u65b9\u6cd5\uff0c\u5728\u97f3\u9891\u5206\u7c7b\u548c\u57fa\u4e8e\u8bed\u97f3\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u53c2\u6570\u589e\u52a04\u500d\u65f6\u4ecd\u4f18\u4e8e\u6807\u51c6MAE\u57fa\u7ebf\u3002", "conclusion": "AudioMAE++\u662f\u4e00\u79cd\u6709\u6548\u7684\u97f3\u9891\u63a9\u7801\u81ea\u7f16\u7801\u5668\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u6269\u5c55\u7279\u6027\u3002"}}
{"id": "2507.09795", "pdf": "https://arxiv.org/pdf/2507.09795", "abs": "https://arxiv.org/abs/2507.09795", "authors": ["Amirhossein Ansari", "Ke Wang", "Pulei Xiong"], "title": "NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "Recent advancements in Vision-Language Models like CLIP have enabled\nzero-shot OOD detection by leveraging both image and textual label information.\nAmong these, negative label-based methods such as NegLabel and CSP have shown\npromising results by utilizing a lexicon of words to define negative labels for\ndistinguishing OOD samples. However, these methods suffer from detecting\nin-distribution samples as OOD due to negative labels that are subcategories of\nin-distribution labels or proper nouns. They also face limitations in handling\nimages that match multiple in-distribution and negative labels. We propose\nNegRefine, a novel negative label refinement framework for zero-shot OOD\ndetection. By introducing a filtering mechanism to exclude subcategory labels\nand proper nouns from the negative label set and incorporating a\nmulti-matching-aware scoring function that dynamically adjusts the\ncontributions of multiple labels matching an image, NegRefine ensures a more\nrobust separation between in-distribution and OOD samples. We evaluate\nNegRefine on large-scale benchmarks, including ImageNet-1K. Source code is\navailable at https://github.com/ah-ansari/NegRefine.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u96f6\u6837\u672cOOD\u68c0\u6d4b\u7684\u8d1f\u6807\u7b7e\u7ec6\u5316\u6846\u67b6NegRefine\uff0c\u8bc4\u4f30\u6548\u679c\u826f\u597d\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u8d1f\u6807\u7b7e\u65b9\u6cd5\u68c0\u6d4b\u65f6\u5c06\u5206\u5e03\u5185\u6837\u672c\u8bef\u5224\u4e3aOOD\uff0c\u4e14\u5904\u7406\u591a\u6807\u7b7e\u56fe\u50cf\u6709\u5c40\u9650\u3002", "method": "\u5f15\u5165\u8fc7\u6ee4\u673a\u5236\u6392\u9664\u8d1f\u6807\u7b7e\u96c6\u4e2d\u7684\u5b50\u7c7b\u522b\u6807\u7b7e\u548c\u4e13\u6709\u540d\u8bcd\uff0c\u91c7\u7528\u591a\u5339\u914d\u611f\u77e5\u8bc4\u5206\u51fd\u6570\u52a8\u6001\u8c03\u6574\u591a\u6807\u7b7e\u8d21\u732e\u3002", "result": "\u5728\u5305\u62ecImageNet - 1K\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "conclusion": "NegRefine\u80fd\u66f4\u7a33\u5065\u5730\u5206\u79bb\u5206\u5e03\u5185\u548cOOD\u6837\u672c\u3002"}}
{"id": "2507.10469", "pdf": "https://arxiv.org/pdf/2507.10469", "abs": "https://arxiv.org/abs/2507.10469", "authors": ["Mikko Korkiakoski", "Saeid Sheikhi", "Jesper Nyman", "Jussi Saariniemi", "Kalle Tapio", "Panos Kostakos"], "title": "An Empirical Evaluation of AI-Powered Non-Player Characters' Perceived Realism and Performance in Virtual Reality Environments", "categories": ["cs.HC", "cs.AI", "cs.MM"], "comment": null, "summary": "Advancements in artificial intelligence (AI) have significantly enhanced the\nrealism and interactivity of non-player characters (NPCs) in virtual reality\n(VR), creating more engaging and believable user experiences. This paper\nevaluates AI-driven NPCs within a VR interrogation simulator, focusing on their\nperceived realism, usability, and system performance. The simulator features\ntwo AI-powered NPCs, a suspect, and a partner, using GPT-4 Turbo to engage\nparticipants in a scenario to determine the suspect's guilt or innocence. A\nuser study with 18 participants assessed the system using the System Usability\nScale (SUS), Game Experience Questionnaire (GEQ), and a Virtual Agent\nBelievability Questionnaire, alongside latency measurements for speech-to-text\n(STT), text-to-speech (TTS), OpenAI GPT-4 Turbo, and overall (cycle) latency.\nResults showed an average cycle latency of 7 seconds, influenced by the\nincreasing conversational context. Believability scored 6.67 out of 10, with\nhigh ratings in behavior, social relationships, and intelligence but moderate\nscores in emotion and personality. The system achieved a SUS score of 79.44,\nindicating good usability. These findings demonstrate the potential of large\nlanguage models to improve NPC realism and interaction in VR while highlighting\nchallenges in reducing system latency and enhancing emotional depth. This\nresearch contributes to the development of more sophisticated AI-driven NPCs,\nrevealing the need for performance optimization to achieve increasingly\nimmersive virtual experiences.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30VR\u5ba1\u8baf\u6a21\u62df\u5668\u4e2dAI\u9a71\u52a8\u7684NPC\uff0c\u7814\u7a76\u5176\u611f\u77e5\u7684\u771f\u5b9e\u611f\u3001\u53ef\u7528\u6027\u548c\u7cfb\u7edf\u6027\u80fd\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347NPC\u771f\u5b9e\u611f\u4e0e\u4ea4\u4e92\u6027\u6709\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u964d\u4f4e\u5ef6\u8fdf\u548c\u589e\u5f3a\u60c5\u611f\u6df1\u5ea6\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740AI\u53d1\u5c55\uff0c\u8bc4\u4f30AI\u9a71\u52a8\u7684NPC\u5728VR\u5ba1\u8baf\u6a21\u62df\u5668\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u5728VR\u5ba1\u8baf\u6a21\u62df\u5668\u4e2d\u7528\u4e24\u4e2a\u7531GPT - 4 Turbo\u9a71\u52a8\u7684NPC\u4e0e\u53c2\u4e0e\u8005\u4e92\u52a8\uff0c\u7528SUS\u3001GEQ\u548c\u865a\u62df\u4ee3\u7406\u53ef\u4fe1\u5ea6\u95ee\u5377\u8bc4\u4f30\u7cfb\u7edf\uff0c\u6d4b\u91cf\u8bed\u97f3\u548c\u6574\u4f53\u5ef6\u8fdf\u3002", "result": "\u5e73\u5747\u5faa\u73af\u5ef6\u8fdf7\u79d2\uff0c\u53d7\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u5f71\u54cd\uff1b\u53ef\u4fe1\u5ea66.67\u5206\uff0c\u884c\u4e3a\u3001\u793e\u4ea4\u5173\u7cfb\u548c\u667a\u529b\u8bc4\u5206\u9ad8\uff0c\u60c5\u611f\u548c\u4e2a\u6027\u4e2d\u7b49\uff1bSUS\u5f97\u520679.44\uff0c\u53ef\u7528\u6027\u826f\u597d\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u6709\u63d0\u5347VR\u4e2dNPC\u771f\u5b9e\u611f\u548c\u4ea4\u4e92\u6027\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u4f18\u5316\u6027\u80fd\uff0c\u51cf\u5c11\u5ef6\u8fdf\u548c\u589e\u5f3a\u60c5\u611f\u6df1\u5ea6\u4ee5\u5b9e\u73b0\u66f4\u6c89\u6d78\u5f0f\u4f53\u9a8c\u3002"}}
{"id": "2507.09823", "pdf": "https://arxiv.org/pdf/2507.09823", "abs": "https://arxiv.org/abs/2507.09823", "authors": ["Ekaterina Borodich", "Dmitry Kovalev"], "title": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization", "categories": ["math.OC", "cs.LG"], "comment": null, "summary": "In this paper, we focus on the problem of minimizing a continuously\ndifferentiable convex objective function $\\min_x f(x)$. Recently, several\nadaptive gradient methods, including GRAAL (Malitsky, 2020), have been\ndeveloped. These methods estimate the local curvature of the objective function\nto compute stepsizes, attain the standard convergence rate $\\mathcal{O}(1/k)$\nof fixed-stepsize gradient descent for Lipschitz-smooth functions, and do not\nrequire any line search procedures or hyperparameter tuning. However, a natural\nquestion arises: is it possible to accelerate the convergence of these\nalgorithms to match the optimal rate $\\mathcal{O}(1/k^2)$ of the accelerated\ngradient descent of Nesterov (1983)? Although some attempts have been made (Li\nand Lan, 2023), the capabilities of the existing accelerated algorithms to\nadapt to the curvature of the objective function are highly limited.\nConsequently, we provide a positive answer to this question and develop GRAAL\nwith Nesterov acceleration. We prove that our algorithm achieves the desired\noptimal convergence rate for Lipschitz smooth functions. Moreover, in contrast\nto existing methods, it does so with an arbitrary, even excessively small,\ninitial stepsize at the cost of a logarithmic additive term in the iteration\ncomplexity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e26Nesterov\u52a0\u901f\u7684GRAAL\u7b97\u6cd5\uff0c\u8bc1\u660e\u5176\u5bf9Lipschitz\u5149\u6ed1\u51fd\u6570\u8fbe\u6700\u4f18\u6536\u655b\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u6536\u655b\u901f\u5ea6\u80fd\u5426\u52a0\u901f\u81f3Nesterov\u52a0\u901f\u68af\u5ea6\u4e0b\u964d\u7684\u6700\u4f18\u901f\u7387\uff0c\u4e14\u73b0\u6709\u52a0\u901f\u7b97\u6cd5\u9002\u5e94\u76ee\u6807\u51fd\u6570\u66f2\u7387\u80fd\u529b\u6709\u9650\u3002", "method": "\u5f00\u53d1\u5e26Nesterov\u52a0\u901f\u7684GRAAL\u7b97\u6cd5\u3002", "result": "\u7b97\u6cd5\u5bf9Lipschitz\u5149\u6ed1\u51fd\u6570\u8fbe\u5230\u6700\u4f18\u6536\u655b\u7387\uff0c\u4e14\u80fd\u4ee5\u4efb\u610f\u521d\u59cb\u6b65\u957f\u5b9e\u73b0\u3002", "conclusion": "\u80af\u5b9a\u4e86\u52a0\u901f\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6cd5\u6536\u655b\u901f\u5ea6\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u7ed9\u51fa\u6709\u6548\u7b97\u6cd5\u3002"}}
{"id": "2507.10474", "pdf": "https://arxiv.org/pdf/2507.10474", "abs": "https://arxiv.org/abs/2507.10474", "authors": ["Seyed Alireza Rahimi Azghadi", "Truong-Thanh-Hung Nguyen", "Helene Fournier", "Monica Wachowicz", "Rene Richard", "Francis Palma", "Hung Cao"], "title": "Privacy-Preserving Multi-Stage Fall Detection Framework with Semi-supervised Federated Learning and Robotic Vision Confirmation", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "The aging population is growing rapidly, and so is the danger of falls in\nolder adults. A major cause of injury is falling, and detection in time can\ngreatly save medical expenses and recovery time. However, to provide timely\nintervention and avoid unnecessary alarms, detection systems must be effective\nand reliable while addressing privacy concerns regarding the user. In this\nwork, we propose a framework for detecting falls using several complementary\nsystems: a semi-supervised federated learning-based fall detection system\n(SF2D), an indoor localization and navigation system, and a vision-based human\nfall recognition system. A wearable device and an edge device identify a fall\nscenario in the first system. On top of that, the second system uses an indoor\nlocalization technique first to localize the fall location and then navigate a\nrobot to inspect the scenario. A vision-based detection system running on an\nedge device with a mounted camera on a robot is used to recognize fallen\npeople. Each of the systems of this proposed framework achieves different\naccuracy rates. Specifically, the SF2D has a 0.81% failure rate equivalent to\n99.19% accuracy, while the vision-based fallen people detection achieves 96.3%\naccuracy. However, when we combine the accuracy of these two systems with the\naccuracy of the navigation system (95% success rate), our proposed framework\ncreates a highly reliable performance for fall detection, with an overall\naccuracy of 99.99%. Not only is the proposed framework safe for older adults,\nbut it is also a privacy-preserving solution for detecting falls.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u7cfb\u7edf\u4e92\u8865\u7684\u8001\u5e74\u4eba\u8dcc\u5012\u68c0\u6d4b\u6846\u67b6\uff0c\u5404\u7cfb\u7edf\u6709\u4e0d\u540c\u51c6\u786e\u7387\uff0c\u7ec4\u5408\u540e\u6574\u4f53\u51c6\u786e\u7387\u8fbe99.99%\uff0c\u4e14\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u8001\u5e74\u4eba\u53e3\u589e\u957f\uff0c\u8dcc\u5012\u5371\u9669\u589e\u52a0\uff0c\u53ca\u65f6\u68c0\u6d4b\u53ef\u8282\u7701\u8d39\u7528\u548c\u6062\u590d\u65f6\u95f4\uff0c\u9700\u6709\u6548\u53ef\u9760\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u5305\u542b\u534a\u76d1\u7763\u8054\u90a6\u5b66\u4e60\u8dcc\u5012\u68c0\u6d4b\u7cfb\u7edf\u3001\u5ba4\u5185\u5b9a\u4f4d\u5bfc\u822a\u7cfb\u7edf\u548c\u57fa\u4e8e\u89c6\u89c9\u7684\u4eba\u4f53\u8dcc\u5012\u8bc6\u522b\u7cfb\u7edf\u7684\u6846\u67b6\u3002", "result": "SF2D\u5931\u8d25\u73870.81%\uff0c\u89c6\u89c9\u68c0\u6d4b\u51c6\u786e\u738796.3%\uff0c\u5bfc\u822a\u7cfb\u7edf\u6210\u529f\u738795%\uff0c\u7ec4\u5408\u540e\u6574\u4f53\u51c6\u786e\u738799.99%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5bf9\u8001\u5e74\u4eba\u5b89\u5168\uff0c\u662f\u4fdd\u62a4\u9690\u79c1\u7684\u8dcc\u5012\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10475", "pdf": "https://arxiv.org/pdf/2507.10475", "abs": "https://arxiv.org/abs/2507.10475", "authors": ["\u0130smail Tar\u0131m", "Aytu\u011f Onan"], "title": "Can You Detect the Difference?", "categories": ["cs.CL", "cs.AI", "I.2.7; H.3.3"], "comment": "11 pages, 3 figures, 2 tables. Code and data:\n  https://github.com/ismailtrm/ceng_404. Cross-list requested to cs.AI for\n  AI-safety relevance", "summary": "The rapid advancement of large language models (LLMs) has raised concerns\nabout reliably detecting AI-generated text. Stylometric metrics work well on\nautoregressive (AR) outputs, but their effectiveness on diffusion-based models\nis unknown. We present the first systematic comparison of diffusion-generated\ntext (LLaDA) and AR-generated text (LLaMA) using 2 000 samples. Perplexity,\nburstiness, lexical diversity, readability, and BLEU/ROUGE scores show that\nLLaDA closely mimics human text in perplexity and burstiness, yielding high\nfalse-negative rates for AR-oriented detectors. LLaMA shows much lower\nperplexity but reduced lexical fidelity. Relying on any single metric fails to\nseparate diffusion outputs from human writing. We highlight the need for\ndiffusion-aware detectors and outline directions such as hybrid models,\ndiffusion-specific stylometric signatures, and robust watermarking.", "AI": {"tldr": "\u5bf9\u6269\u6563\u751f\u6210\u6587\u672c\uff08LLaDA\uff09\u548c\u81ea\u56de\u5f52\u751f\u6210\u6587\u672c\uff08LLaMA\uff09\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u6307\u51fa\u4f9d\u8d56\u5355\u4e00\u6307\u6807\u96be\u4ee5\u533a\u5206\u6269\u6563\u8f93\u51fa\u4e0e\u4eba\u7c7b\u5199\u4f5c\uff0c\u5f3a\u8c03\u9700\u6269\u6563\u611f\u77e5\u68c0\u6d4b\u5668\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u5f15\u53d1\u68c0\u6d4bAI\u751f\u6210\u6587\u672c\u53ef\u9760\u6027\u7684\u62c5\u5fe7\uff0c\u4e14\u6587\u4f53\u8ba1\u91cf\u6307\u6807\u5728\u6269\u6563\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6027\u672a\u77e5\u3002", "method": "\u4f7f\u75282000\u4e2a\u6837\u672c\u5bf9LLaDA\u548cLLaMA\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u5206\u6790\u56f0\u60d1\u5ea6\u3001\u7a81\u53d1\u6027\u3001\u8bcd\u6c47\u591a\u6837\u6027\u7b49\u6307\u6807\u3002", "result": "LLaDA\u5728\u56f0\u60d1\u5ea6\u548c\u7a81\u53d1\u6027\u4e0a\u63a5\u8fd1\u4eba\u7c7b\u6587\u672c\uff0c\u9762\u5411\u81ea\u56de\u5f52\u7684\u68c0\u6d4b\u5668\u5047\u9634\u6027\u7387\u9ad8\uff1bLLaMA\u56f0\u60d1\u5ea6\u4f4e\u4f46\u8bcd\u6c47\u4fdd\u771f\u5ea6\u4f4e\uff1b\u5355\u4e00\u6307\u6807\u65e0\u6cd5\u533a\u5206\u6269\u6563\u8f93\u51fa\u4e0e\u4eba\u7c7b\u5199\u4f5c\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u6269\u6563\u611f\u77e5\u68c0\u6d4b\u5668\uff0c\u5e76\u7ed9\u51fa\u6df7\u5408\u6a21\u578b\u3001\u7279\u5b9a\u6587\u4f53\u7279\u5f81\u548c\u9c81\u68d2\u6c34\u5370\u7b49\u65b9\u5411\u3002"}}
{"id": "2507.09830", "pdf": "https://arxiv.org/pdf/2507.09830", "abs": "https://arxiv.org/abs/2507.09830", "authors": ["Shuhao Fu", "Philip J. Kellman", "Hongjing Lu"], "title": "Hierarchical Abstraction Enables Human-Like 3D Object Recognition in Deep Learning Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Both humans and deep learning models can recognize objects from 3D shapes\ndepicted with sparse visual information, such as a set of points randomly\nsampled from the surfaces of 3D objects (termed a point cloud). Although deep\nlearning models achieve human-like performance in recognizing objects from 3D\nshapes, it remains unclear whether these models develop 3D shape\nrepresentations similar to those used by human vision for object recognition.\nWe hypothesize that training with 3D shapes enables models to form\nrepresentations of local geometric structures in 3D shapes. However, their\nrepresentations of global 3D object shapes may be limited. We conducted two\nhuman experiments systematically manipulating point density and object\norientation (Experiment 1), and local geometric structure (Experiment 2).\nHumans consistently performed well across all experimental conditions. We\ncompared two types of deep learning models, one based on a convolutional neural\nnetwork (DGCNN) and the other on visual transformers (point transformer), with\nhuman performance. We found that the point transformer model provided a better\naccount of human performance than the convolution-based model. The advantage\nmainly results from the mechanism in the point transformer model that supports\nhierarchical abstraction of 3D shapes.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0e\u4eba\u7c7b\u57283D\u5f62\u72b6\u7269\u4f53\u8bc6\u522b\u4e2d\u8868\u5f81\u662f\u5426\u76f8\u4f3c\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\u4e24\u79cd\u6a21\u578b\u4e0e\u4eba\u7c7b\u8868\u73b0\uff0c\u53d1\u73b0\u70b9\u53d8\u6362\u5668\u6a21\u578b\u66f4\u80fd\u89e3\u91ca\u4eba\u7c7b\u8868\u73b0\u3002", "motivation": "\u867d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u57283D\u5f62\u72b6\u7269\u4f53\u8bc6\u522b\u4e0a\u6709\u7c7b\u4eba\u8868\u73b0\uff0c\u4f46\u4e0d\u6e05\u695a\u5176\u662f\u5426\u6709\u4e0e\u4eba\u7c7b\u89c6\u89c9\u76f8\u4f3c\u76843D\u5f62\u72b6\u8868\u5f81\u3002", "method": "\u8fdb\u884c\u4e24\u4e2a\u4eba\u7c7b\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u64cd\u63a7\u70b9\u5bc6\u5ea6\u3001\u7269\u4f53\u65b9\u5411\u548c\u5c40\u90e8\u51e0\u4f55\u7ed3\u6784\uff1b\u5bf9\u6bd4DGCNN\u548c\u70b9\u53d8\u6362\u5668\u4e24\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0e\u4eba\u7c7b\u8868\u73b0\u3002", "result": "\u70b9\u53d8\u6362\u5668\u6a21\u578b\u6bd4\u57fa\u4e8e\u5377\u79ef\u7684\u6a21\u578b\u66f4\u80fd\u89e3\u91ca\u4eba\u7c7b\u8868\u73b0\uff0c\u4f18\u52bf\u6e90\u4e8e\u5176\u5bf93D\u5f62\u72b6\u7684\u5206\u5c42\u62bd\u8c61\u673a\u5236\u3002", "conclusion": "\u70b9\u53d8\u6362\u5668\u6a21\u578b\u5728\u6a21\u62df\u4eba\u7c7b3D\u5f62\u72b6\u7269\u4f53\u8bc6\u522b\u8868\u73b0\u4e0a\u66f4\u4f18\u3002"}}
{"id": "2507.10492", "pdf": "https://arxiv.org/pdf/2507.10492", "abs": "https://arxiv.org/abs/2507.10492", "authors": ["Chenyu Lian", "Hong-Yu Zhou", "Zhanli Hu", "Jing Qin"], "title": "BenchReAD: A systematic benchmark for retinal anomaly detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "MICCAI 2025", "summary": "Retinal anomaly detection plays a pivotal role in screening ocular and\nsystemic diseases. Despite its significance, progress in the field has been\nhindered by the absence of a comprehensive and publicly available benchmark,\nwhich is essential for the fair evaluation and advancement of methodologies.\nDue to this limitation, previous anomaly detection work related to retinal\nimages has been constrained by (1) a limited and overly simplistic set of\nanomaly types, (2) test sets that are nearly saturated, and (3) a lack of\ngeneralization evaluation, resulting in less convincing experimental setups.\nFurthermore, existing benchmarks in medical anomaly detection predominantly\nfocus on one-class supervised approaches (training only with negative samples),\noverlooking the vast amounts of labeled abnormal data and unlabeled data that\nare commonly available in clinical practice. To bridge these gaps, we introduce\na benchmark for retinal anomaly detection, which is comprehensive and\nsystematic in terms of data and algorithm. Through categorizing and\nbenchmarking previous methods, we find that a fully supervised approach\nleveraging disentangled representations of abnormalities (DRA) achieves the\nbest performance but suffers from significant drops in performance when\nencountering certain unseen anomalies. Inspired by the memory bank mechanisms\nin one-class supervised learning, we propose NFM-DRA, which integrates DRA with\na Normal Feature Memory to mitigate the performance degradation, establishing a\nnew SOTA. The benchmark is publicly available at\nhttps://github.com/DopamineLcy/BenchReAD.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u89c6\u7f51\u819c\u5f02\u5e38\u68c0\u6d4b\u9886\u57df\u7f3a\u4e4f\u7efc\u5408\u516c\u5f00\u57fa\u51c6\u7684\u95ee\u9898\uff0c\u5f15\u5165\u7efc\u5408\u7cfb\u7edf\u7684\u57fa\u51c6\uff0c\u5bf9\u5148\u524d\u65b9\u6cd5\u5206\u7c7b\u8bc4\u4f30\uff0c\u63d0\u51faNFM - DRA\u65b9\u6cd5\u8fbe\u5230\u65b0SOTA\u5e76\u516c\u5f00\u57fa\u51c6\u3002", "motivation": "\u89c6\u7f51\u819c\u5f02\u5e38\u68c0\u6d4b\u7f3a\u4e4f\u7efc\u5408\u516c\u5f00\u57fa\u51c6\uff0c\u73b0\u6709\u5de5\u4f5c\u5b58\u5728\u5f02\u5e38\u7c7b\u578b\u6709\u9650\u3001\u6d4b\u8bd5\u96c6\u9971\u548c\u3001\u7f3a\u4e4f\u6cdb\u5316\u8bc4\u4f30\u7b49\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u533b\u5b66\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\u591a\u4fa7\u91cd\u5355\u7c7b\u76d1\u7763\u65b9\u6cd5\uff0c\u5ffd\u89c6\u4e34\u5e8a\u5e38\u89c1\u7684\u5927\u91cf\u5f02\u5e38\u548c\u672a\u6807\u8bb0\u6570\u636e\u3002", "method": "\u5f15\u5165\u6570\u636e\u548c\u7b97\u6cd5\u4e0a\u7efc\u5408\u7cfb\u7edf\u7684\u89c6\u7f51\u819c\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\uff0c\u5bf9\u5148\u524d\u65b9\u6cd5\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d7\u5355\u7c7b\u76d1\u7763\u5b66\u4e60\u8bb0\u5fc6\u5e93\u673a\u5236\u542f\u53d1\uff0c\u63d0\u51fa\u5c06DRA\u4e0e\u6b63\u5e38\u7279\u5f81\u8bb0\u5fc6\u7ed3\u5408\u7684NFM - DRA\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u5229\u7528\u5f02\u5e38\u89e3\u7ea0\u7f20\u8868\u793a\u7684\u5168\u76d1\u7763\u65b9\u6cd5DRA\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u9047\u5230\u672a\u89c1\u5f02\u5e38\u65f6\u6027\u80fd\u4e0b\u964d\uff1b\u63d0\u51fa\u7684NFM - DRA\u7f13\u89e3\u4e86\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u8fbe\u5230\u65b0\u7684SOTA\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7efc\u5408\u7cfb\u7edf\u57fa\u51c6\u53caNFM - DRA\u65b9\u6cd5\u6709\u52a9\u4e8e\u89c6\u7f51\u819c\u5f02\u5e38\u68c0\u6d4b\u9886\u57df\u7684\u516c\u5e73\u8bc4\u4f30\u548c\u65b9\u6cd5\u63a8\u8fdb\uff0c\u57fa\u51c6\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.10496", "pdf": "https://arxiv.org/pdf/2507.10496", "abs": "https://arxiv.org/abs/2507.10496", "authors": ["Ruilong Li", "Brent Yi", "Junchen Liu", "Hang Gao", "Yi Ma", "Angjoo Kanazawa"], "title": "Cameras as Relative Positional Encoding", "categories": ["cs.CV", "cs.AI"], "comment": "Project Page: https://www.liruilong.cn/prope/", "summary": "Transformers are increasingly prevalent for multi-view computer vision tasks,\nwhere geometric relationships between viewpoints are critical for 3D\nperception. To leverage these relationships, multi-view transformers must use\ncamera geometry to ground visual tokens in 3D space. In this work, we compare\ntechniques for conditioning transformers on cameras: token-level raymap\nencodings, attention-level relative pose encodings, and a new relative encoding\nwe propose -- Projective Positional Encoding (PRoPE) -- that captures complete\ncamera frustums, both intrinsics and extrinsics, as a relative positional\nencoding. Our experiments begin by showing how relative camera conditioning\nimproves performance in feedforward novel view synthesis, with further gains\nfrom PRoPE. This holds across settings: scenes with both shared and varying\nintrinsics, when combining token- and attention-level conditioning, and for\ngeneralization to inputs with out-of-distribution sequence lengths and camera\nintrinsics. We then verify that these benefits persist for different tasks,\nstereo depth estimation and discriminative spatial cognition, as well as larger\nmodel sizes.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u591a\u89c6\u56fetransformer\u4e2d\u57fa\u4e8e\u76f8\u673a\u7684\u8c03\u8282\u6280\u672f\uff0c\u63d0\u51faPRoPE\u7f16\u7801\uff0c\u5b9e\u9a8c\u8868\u660e\u76f8\u5bf9\u76f8\u673a\u8c03\u8282\u53caPRoPE\u80fd\u63d0\u5347\u591a\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u591a\u89c6\u56fe\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\uff0c\u9700\u5229\u7528\u76f8\u673a\u51e0\u4f55\u5173\u7cfb\u5c06\u89c6\u89c9\u4ee4\u724c\u7f6e\u4e8e3D\u7a7a\u95f4\uff0c\u4ee5\u63d0\u53473D\u611f\u77e5\u3002", "method": "\u6bd4\u8f83\u4ee4\u724c\u7ea7\u5c04\u7ebf\u56fe\u7f16\u7801\u3001\u6ce8\u610f\u529b\u7ea7\u76f8\u5bf9\u59ff\u6001\u7f16\u7801\uff0c\u63d0\u51fa\u6295\u5f71\u4f4d\u7f6e\u7f16\u7801\uff08PRoPE\uff09\u3002", "result": "\u76f8\u5bf9\u76f8\u673a\u8c03\u8282\u63d0\u5347\u524d\u9988\u65b0\u9896\u89c6\u56fe\u5408\u6210\u6027\u80fd\uff0cPRoPE\u6709\u8fdb\u4e00\u6b65\u589e\u76ca\uff0c\u4e14\u5728\u4e0d\u540c\u573a\u666f\u3001\u4efb\u52a1\u548c\u6a21\u578b\u5927\u5c0f\u4e0b\u5747\u6709\u6548\u3002", "conclusion": "\u76f8\u5bf9\u76f8\u673a\u8c03\u8282\u548cPRoPE\u7f16\u7801\u5bf9\u591a\u89c6\u56fe\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u6709\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2507.10500", "pdf": "https://arxiv.org/pdf/2507.10500", "abs": "https://arxiv.org/abs/2507.10500", "authors": ["Kyungtae Han", "Yitao Chen", "Rohit Gupta", "Onur Altintas"], "title": "Scene-Aware Conversational ADAS with Generative AI for Real-Time Driver Assistance", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "While autonomous driving technologies continue to advance, current Advanced\nDriver Assistance Systems (ADAS) remain limited in their ability to interpret\nscene context or engage with drivers through natural language. These systems\ntypically rely on predefined logic and lack support for dialogue-based\ninteraction, making them inflexible in dynamic environments or when adapting to\ndriver intent. This paper presents Scene-Aware Conversational ADAS (SC-ADAS), a\nmodular framework that integrates Generative AI components including large\nlanguage models, vision-to-text interpretation, and structured function calling\nto enable real-time, interpretable, and adaptive driver assistance. SC-ADAS\nsupports multi-turn dialogue grounded in visual and sensor context, allowing\nnatural language recommendations and driver-confirmed ADAS control. Implemented\nin the CARLA simulator with cloud-based Generative AI, the system executes\nconfirmed user intents as structured ADAS commands without requiring model\nfine-tuning. We evaluate SC-ADAS across scene-aware, conversational, and\nrevisited multi-turn interactions, highlighting trade-offs such as increased\nlatency from vision-based context retrieval and token growth from accumulated\ndialogue history. These results demonstrate the feasibility of combining\nconversational reasoning, scene perception, and modular ADAS control to support\nthe next generation of intelligent driver assistance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faScene - Aware Conversational ADAS (SC - ADAS)\u6846\u67b6\uff0c\u7ed3\u5408\u751f\u6210\u5f0fAI\u7ec4\u4ef6\u5b9e\u73b0\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u548c\u81ea\u9002\u5e94\u7684\u9a7e\u9a76\u8f85\u52a9\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u80fd\u652f\u6301\u4e0b\u4e00\u4ee3\u667a\u80fd\u9a7e\u9a76\u8f85\u52a9\uff0c\u4f46\u5b58\u5728\u5ef6\u8fdf\u548c\u4ee4\u724c\u589e\u957f\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u9ad8\u7ea7\u9a7e\u9a76\u8f85\u52a9\u7cfb\u7edf\uff08ADAS\uff09\u5728\u89e3\u91ca\u573a\u666f\u4e0a\u4e0b\u6587\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u7f3a\u4e4f\u5bf9\u8bdd\u4ea4\u4e92\u652f\u6301\uff0c\u5728\u52a8\u6001\u73af\u5883\u548c\u9002\u5e94\u9a7e\u9a76\u5458\u610f\u56fe\u65f6\u4e0d\u591f\u7075\u6d3b\u3002", "method": "\u63d0\u51faSC - ADAS\u6a21\u5757\u5316\u6846\u67b6\uff0c\u96c6\u6210\u751f\u6210\u5f0fAI\u7ec4\u4ef6\uff0c\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u3001\u89c6\u89c9\u8f6c\u6587\u672c\u89e3\u91ca\u548c\u7ed3\u6784\u5316\u51fd\u6570\u8c03\u7528\uff1b\u5728CARLA\u6a21\u62df\u5668\u4e2d\u7ed3\u5408\u57fa\u4e8e\u4e91\u7684\u751f\u6210\u5f0fAI\u5b9e\u73b0\uff0c\u6267\u884c\u7528\u6237\u786e\u8ba4\u7684\u610f\u56fe\uff0c\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u3002", "result": "\u8bc4\u4f30\u4e86SC - ADAS\u5728\u573a\u666f\u611f\u77e5\u3001\u5bf9\u8bdd\u548c\u591a\u8f6e\u4ea4\u4e92\u65b9\u9762\u7684\u8868\u73b0\uff0c\u6307\u51fa\u5b58\u5728\u57fa\u4e8e\u89c6\u89c9\u4e0a\u4e0b\u6587\u68c0\u7d22\u7684\u5ef6\u8fdf\u589e\u52a0\u548c\u5bf9\u8bdd\u5386\u53f2\u79ef\u7d2f\u5bfc\u81f4\u7684\u4ee4\u724c\u589e\u957f\u95ee\u9898\u3002", "conclusion": "\u8bc1\u660e\u4e86\u7ed3\u5408\u5bf9\u8bdd\u63a8\u7406\u3001\u573a\u666f\u611f\u77e5\u548c\u6a21\u5757\u5316ADAS\u63a7\u5236\u4ee5\u652f\u6301\u4e0b\u4e00\u4ee3\u667a\u80fd\u9a7e\u9a76\u8f85\u52a9\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2507.10510", "pdf": "https://arxiv.org/pdf/2507.10510", "abs": "https://arxiv.org/abs/2507.10510", "authors": ["Jiangkai Wu", "Zhiyuan Ren", "Liming Liu", "Xinggong Zhang"], "title": "Chat with AI: The Surprising Turn of Real-time Video Communication from Human to AI", "categories": ["cs.NI", "cs.AI", "cs.HC", "cs.MM"], "comment": null, "summary": "AI Video Chat emerges as a new paradigm for Real-time Communication (RTC),\nwhere one peer is not a human, but a Multimodal Large Language Model (MLLM).\nThis makes interaction between humans and AI more intuitive, as if chatting\nface-to-face with a real person. However, this poses significant challenges to\nlatency, because the MLLM inference takes up most of the response time, leaving\nvery little time for video streaming. Due to network uncertainty and\ninstability, transmission latency becomes a critical bottleneck preventing AI\nfrom being like a real person. To address this, we propose Artic, an\nAI-oriented Real-time Communication framework, exploring the network\nrequirement shift from \"humans watching video\" to \"AI understanding video\". To\nreduce bitrate dramatically while maintaining MLLM accuracy, we propose\nContext-Aware Video Streaming that recognizes the importance of each video\nregion for chat and allocates bitrate almost exclusively to chat-important\nregions. To avoid packet retransmission, we propose Loss-Resilient Adaptive\nFrame Rate that leverages previous frames to substitute for lost/delayed frames\nwhile avoiding bitrate waste. To evaluate the impact of video streaming quality\non MLLM accuracy, we build the first benchmark, named Degraded Video\nUnderstanding Benchmark (DeViBench). Finally, we discuss some open questions\nand ongoing solutions for AI Video Chat.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecdAI\u89c6\u9891\u804a\u5929\u65b0\u8303\u5f0f\u53ca\u5ef6\u8fdf\u6311\u6218\uff0c\u63d0\u51faArtic\u6846\u67b6\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u611f\u77e5\u89c6\u9891\u6d41\u3001\u6297\u4e22\u5305\u81ea\u9002\u5e94\u5e27\u7387\u7b49\u65b9\u6cd5\uff0c\u5e76\u6784\u5efaDeViBench\u57fa\u51c6\uff0c\u6700\u540e\u8ba8\u8bba\u5f00\u653e\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3AI\u89c6\u9891\u804a\u5929\u4e2d\u56e0MLLM\u63a8\u7406\u548c\u7f51\u7edc\u95ee\u9898\u5bfc\u81f4\u7684\u5ef6\u8fdf\u74f6\u9888\uff0c\u8ba9AI\u4ea4\u4e92\u66f4\u50cf\u771f\u4eba\u3002", "method": "\u63d0\u51faArtic\u6846\u67b6\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u611f\u77e5\u89c6\u9891\u6d41\u3001\u6297\u4e22\u5305\u81ea\u9002\u5e94\u5e27\u7387\uff0c\u6784\u5efaDeViBench\u57fa\u51c6\u3002", "result": "\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f46\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u89e3\u51b3\u65b9\u6cd5\u548c\u57fa\u51c6\u3002", "conclusion": "\u63d0\u51fa\u89e3\u51b3AI\u89c6\u9891\u804a\u5929\u5ef6\u8fdf\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u76f8\u5173\u5f00\u653e\u6027\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10530", "pdf": "https://arxiv.org/pdf/2507.10530", "abs": "https://arxiv.org/abs/2507.10530", "authors": ["Ping Tuo", "Jiale Chen", "Ju Li"], "title": "Accurate generation of chemical reaction transition states by conditional flow matching", "categories": ["physics.chem-ph", "cs.AI"], "comment": null, "summary": "Transition state (TS) structures define the critical geometries and energy\nbarriers underlying chemical reactivity, yet their fleeting nature renders them\nexperimentally elusive and drives the reliance on costly, high-throughput\ndensity functional theory (DFT) calculations. Here, we introduce TS-GEN, a\nconditional flow-matching generative model that maps samples from a simple\nGaussian prior directly to transition-state saddle-point geometries in a\nsingle, deterministic pass. By embedding both reactant and product\nconformations as conditioning information, TS-GEN learns to transport latent\nnoise to true TS structures via an optimal-transport path, effectively\nreplacing the iterative optimization common in nudged-elastic band or\nstring-method algorithms. TS-GEN delivers unprecedented accuracy, achieving a\nroot-mean-square deviation of $0.004\\ \\rm{\\mathring{A}}$ (vs. $0.103\\\n\\rm{\\mathring{A}}$ for prior state-of-the-art) and a mean barrier-height error\nof $1.019\\ {\\rm kcal/mol}$ (vs. $2.864\\ {\\rm kcal/mol}$), while requiring only\n$0.06\\ {\\rm s}$ GPU time per inference. Over 87% of generated TSs meet\nchemical-accuracy criteria ($<1.58\\ {\\rm kcal/mol}$ error), substantially\noutpacing existing methods. TS-GEN also exhibits strong transferability to\nout-of-distribution reactions from a larger database. By uniting sub-angstrom\nprecision, sub-second speed, and broad applicability, TS-GEN will be highly\nuseful for high-throughput exploration of complex reaction networks, paving the\nway to the exploration of novel chemical reaction mechanisms.", "AI": {"tldr": "\u4ecb\u7ecdTS - GEN\u751f\u6210\u6a21\u578b\uff0c\u80fd\u76f4\u63a5\u751f\u6210\u8fc7\u6e21\u6001\u7ed3\u6784\uff0c\u7cbe\u5ea6\u9ad8\u3001\u901f\u5ea6\u5feb\u4e14\u9002\u7528\u6027\u5e7f\uff0c\u5229\u4e8e\u9ad8\u901a\u91cf\u63a2\u7d22\u590d\u6742\u53cd\u5e94\u7f51\u7edc\u3002", "motivation": "\u8fc7\u6e21\u6001\u7ed3\u6784\u5b9e\u9a8c\u96be\u6355\u6349\uff0c\u4f9d\u8d56\u9ad8\u6210\u672c\u7684\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5f15\u5165TS - GEN\u6761\u4ef6\u6d41\u5339\u914d\u751f\u6210\u6a21\u578b\uff0c\u5c06\u7b80\u5355\u9ad8\u65af\u5148\u9a8c\u6837\u672c\u6620\u5c04\u5230\u8fc7\u6e21\u6001\u978d\u70b9\u51e0\u4f55\u7ed3\u6784\uff0c\u5d4c\u5165\u53cd\u5e94\u7269\u548c\u4ea7\u7269\u6784\u8c61\u4fe1\u606f\u3002", "result": "TS - GEN\u7cbe\u5ea6\u9ad8\uff0c\u5747\u65b9\u6839\u504f\u5dee\u5c0f\uff0c\u52bf\u5792\u9ad8\u5ea6\u8bef\u5dee\u5c0f\uff0c\u63a8\u7406\u65f6\u95f4\u77ed\uff0c\u8d8587%\u751f\u6210\u7684\u8fc7\u6e21\u6001\u6ee1\u8db3\u5316\u5b66\u7cbe\u5ea6\u6807\u51c6\uff0c\u6709\u5f3a\u53ef\u8fc1\u79fb\u6027\u3002", "conclusion": "TS - GEN\u7ed3\u5408\u9ad8\u7cbe\u5ea6\u3001\u5feb\u901f\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u5bf9\u9ad8\u901a\u91cf\u63a2\u7d22\u590d\u6742\u53cd\u5e94\u7f51\u7edc\u5f88\u6709\u7528\uff0c\u4e3a\u63a2\u7d22\u65b0\u53cd\u5e94\u673a\u5236\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.10534", "pdf": "https://arxiv.org/pdf/2507.10534", "abs": "https://arxiv.org/abs/2507.10534", "authors": ["Qihui Yang", "Taylor Berg-Kirkpatrick", "Julian McAuley", "Zachary Novack"], "title": "WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "Despite rapid progress in end-to-end AI music generation, AI-driven modeling\nof professional Digital Signal Processing (DSP) workflows remains challenging.\nIn particular, while there is growing interest in neural black-box modeling of\naudio effect graphs (e.g. reverb, compression, equalization), AI-based\napproaches struggle to replicate the nuanced signal flow and parameter\ninteractions used in professional workflows. Existing differentiable plugin\napproaches often diverge from real-world tools, exhibiting inferior performance\nrelative to simplified neural controllers under equivalent computational\nconstraints. We introduce WildFX, a pipeline containerized with Docker for\ngenerating multi-track audio mixing datasets with rich effect graphs, powered\nby a professional Digital Audio Workstation (DAW) backend. WildFX supports\nseamless integration of cross-platform commercial plugins or any plugins in the\nwild, in VST/VST3/LV2/CLAP formats, enabling structural complexity (e.g.,\nsidechains, crossovers) and achieving efficient parallelized processing. A\nminimalist metadata interface simplifies project/plugin configuration.\nExperiments demonstrate the pipeline's validity through blind estimation of\nmixing graphs, plugin/gain parameters, and its ability to bridge AI research\nwith practical DSP demands. The code is available on:\nhttps://github.com/IsaacYQH/WildFX.", "AI": {"tldr": "\u4ecb\u7ecdWildFX\uff0c\u4e00\u79cd\u7528Docker\u5bb9\u5668\u5316\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u4e30\u5bcc\u6548\u679c\u56fe\u7684\u591a\u8f68\u97f3\u9891\u6df7\u5408\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u4e14\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u7aef\u5230\u7aefAI\u97f3\u4e50\u751f\u6210\u867d\u6709\u8fdb\u5c55\uff0c\u4f46AI\u9a71\u52a8\u7684\u4e13\u4e1a\u6570\u5b57\u4fe1\u53f7\u5904\u7406\uff08DSP\uff09\u5de5\u4f5c\u6d41\u5efa\u6a21\u4ecd\u5177\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5f15\u5165WildFX\u7ba1\u9053\uff0c\u4ee5\u4e13\u4e1a\u6570\u5b57\u97f3\u9891\u5de5\u4f5c\u7ad9\uff08DAW\uff09\u4e3a\u540e\u7aef\uff0c\u652f\u6301\u96c6\u6210\u591a\u79cd\u683c\u5f0f\u63d2\u4ef6\uff0c\u6709\u7b80\u7ea6\u5143\u6570\u636e\u63a5\u53e3\u3002", "result": "\u901a\u8fc7\u76f2\u4f30\u8ba1\u6df7\u97f3\u56fe\u3001\u63d2\u4ef6/\u589e\u76ca\u53c2\u6570\u7b49\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u7ba1\u9053\u7684\u6709\u6548\u6027\u3002", "conclusion": "WildFX\u80fd\u5f25\u5408AI\u7814\u7a76\u4e0e\u5b9e\u9645DSP\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.10542", "pdf": "https://arxiv.org/pdf/2507.10542", "abs": "https://arxiv.org/abs/2507.10542", "authors": ["Shivangi Aneja", "Sebastian Weiss", "Irene Baeza", "Prashanth Chandran", "Gaspard Zoss", "Matthias Nie\u00dfner", "Derek Bradley"], "title": "ScaffoldAvatar: High-Fidelity Gaussian Avatars with Patch Expressions", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "(SIGGRAPH 2025) Paper Video: https://youtu.be/VyWkgsGdbkk Project\n  Page: https://shivangi-aneja.github.io/projects/scaffoldavatar/", "summary": "Generating high-fidelity real-time animated sequences of photorealistic 3D\nhead avatars is important for many graphics applications, including immersive\ntelepresence and movies. This is a challenging problem particularly when\nrendering digital avatar close-ups for showing character's facial microfeatures\nand expressions. To capture the expressive, detailed nature of human heads,\nincluding skin furrowing and finer-scale facial movements, we propose to couple\nlocally-defined facial expressions with 3D Gaussian splatting to enable\ncreating ultra-high fidelity, expressive and photorealistic 3D head avatars. In\ncontrast to previous works that operate on a global expression space, we\ncondition our avatar's dynamics on patch-based local expression features and\nsynthesize 3D Gaussians at a patch level. In particular, we leverage a\npatch-based geometric 3D face model to extract patch expressions and learn how\nto translate these into local dynamic skin appearance and motion by coupling\nthe patches with anchor points of Scaffold-GS, a recent hierarchical scene\nrepresentation. These anchors are then used to synthesize 3D Gaussians\non-the-fly, conditioned by patch-expressions and viewing direction. We employ\ncolor-based densification and progressive training to obtain high-quality\nresults and faster convergence for high resolution 3K training images. By\nleveraging patch-level expressions, ScaffoldAvatar consistently achieves\nstate-of-the-art performance with visually natural motion, while encompassing\ndiverse facial expressions and styles in real time.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5c40\u90e8\u9762\u90e8\u8868\u60c5\u4e0e3D\u9ad8\u65af splatting \u751f\u6210\u8d85\u903c\u771f3D\u5934\u90e8\u5934\u50cf\uff0c\u5728\u5b9e\u65f6\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u56fe\u5f62\u5e94\u7528\u4e2d\u751f\u6210\u9ad8\u4fdd\u771f\u5b9e\u65f6\u52a8\u753b\u7684\u903c\u771f3D\u5934\u90e8\u5934\u50cf\u5f88\u91cd\u8981\uff0c\u5c24\u5176\u662f\u6e32\u67d3\u7279\u5199\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6311\u6218\u3002", "method": "\u5c06\u5c40\u90e8\u9762\u90e8\u8868\u60c5\u4e0e3D\u9ad8\u65af splatting \u7ed3\u5408\uff0c\u57fa\u4e8e patch \u63d0\u53d6\u8868\u60c5\uff0c\u5229\u7528\u951a\u70b9\u5408\u62103D\u9ad8\u65af\uff0c\u91c7\u7528\u57fa\u4e8e\u989c\u8272\u7684\u81f4\u5bc6\u5316\u548c\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u3002", "result": "\u5bf9\u4e8e3K\u9ad8\u5206\u8fa8\u7387\u8bad\u7ec3\u56fe\u50cf\u80fd\u83b7\u5f97\u9ad8\u8d28\u91cf\u7ed3\u679c\u548c\u66f4\u5feb\u6536\u655b\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528 patch \u7ea7\u8868\u60c5\uff0cScaffoldAvatar \u5b9e\u65f6\u5b9e\u73b0\u4e86\u89c6\u89c9\u81ea\u7136\u8fd0\u52a8\u7684\u6700\u4f18\u6027\u80fd\uff0c\u6db5\u76d6\u591a\u6837\u9762\u90e8\u8868\u60c5\u548c\u98ce\u683c\u3002"}}
{"id": "2507.10029", "pdf": "https://arxiv.org/pdf/2507.10029", "abs": "https://arxiv.org/abs/2507.10029", "authors": ["Seokeon Choi", "Sunghyun Park", "Hyoungwoo Park", "Jeongho Kim", "Sungrack Yun"], "title": "Memory-Efficient Personalization of Text-to-Image Diffusion Models via Selective Optimization Strategies", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Memory-efficient personalization is critical for adapting text-to-image\ndiffusion models while preserving user privacy and operating within the limited\ncomputational resources of edge devices. To this end, we propose a selective\noptimization framework that adaptively chooses between backpropagation on\nlow-resolution images (BP-low) and zeroth-order optimization on high-resolution\nimages (ZO-high), guided by the characteristics of the diffusion process. As\nobserved in our experiments, BP-low efficiently adapts the model to\ntarget-specific features, but suffers from structural distortions due to\nresolution mismatch. Conversely, ZO-high refines high-resolution details with\nminimal memory overhead but faces slow convergence when applied without prior\nadaptation. By complementing both methods, our framework leverages BP-low for\neffective personalization while using ZO-high to maintain structural\nconsistency, achieving memory-efficient and high-quality fine-tuning. To\nmaximize the efficacy of both BP-low and ZO-high, we introduce a timestep-aware\nprobabilistic function that dynamically selects the appropriate optimization\nstrategy based on diffusion timesteps. This function mitigates the overfitting\nfrom BP-low at high timesteps, where structural information is critical, while\nensuring ZO-high is applied more effectively as training progresses.\nExperimental results demonstrate that our method achieves competitive\nperformance while significantly reducing memory consumption, enabling scalable,\nhigh-quality on-device personalization without increasing inference latency.", "AI": {"tldr": "\u63d0\u51fa\u9009\u62e9\u6027\u4f18\u5316\u6846\u67b6\u5b9e\u73b0\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u5185\u5b58\u9ad8\u6548\u4e2a\u6027\u5316\u5fae\u8c03\uff0c\u5f15\u5165\u65f6\u95f4\u6b65\u611f\u77e5\u6982\u7387\u51fd\u6570\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6027\u80fd\u4f18\u4e14\u5185\u5b58\u6d88\u8017\u4f4e\u3002", "motivation": "\u5b9e\u73b0\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u5185\u5b58\u9ad8\u6548\u4e2a\u6027\u5316\uff0c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u5e76\u9002\u5e94\u8fb9\u7f18\u8bbe\u5907\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u9009\u62e9\u6027\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u4f4e\u5206\u8fa8\u7387\u56fe\u50cf\u53cd\u5411\u4f20\u64ad\uff08BP - low\uff09\u548c\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u96f6\u9636\u4f18\u5316\uff08ZO - high\uff09\uff0c\u5f15\u5165\u65f6\u95f4\u6b65\u611f\u77e5\u6982\u7387\u51fd\u6570\u52a8\u6001\u9009\u62e9\u4f18\u5316\u7b56\u7565\u3002", "result": "\u65b9\u6cd5\u6027\u80fd\u6709\u7ade\u4e89\u529b\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u6d88\u8017\uff0c\u4e0d\u589e\u52a0\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u9ad8\u8d28\u91cf\u7684\u8bbe\u5907\u7aef\u4e2a\u6027\u5316\u5fae\u8c03\u3002"}}
{"id": "2507.10548", "pdf": "https://arxiv.org/pdf/2507.10548", "abs": "https://arxiv.org/abs/2507.10548", "authors": ["Mingxian Lin", "Wei Huang", "Yitang Li", "Chengjie Jiang", "Kui Wu", "Fangwei Zhong", "Shengju Qian", "Xin Wang", "Xiaojuan Qi"], "title": "EmbRACE-3K: Embodied Reasoning and Action in Complex Environments", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Project page: https://mxllc.github.io/EmbRACE-3K/", "summary": "Recent advanced vision-language models(VLMs) have demonstrated strong\nperformance on passive, offline image and video understanding tasks. However,\ntheir effectiveness in embodied settings, which require online interaction and\nactive scene understanding remains limited. In such scenarios, an agent\nperceives the environment from a first-person perspective, with each action\ndynamically shaping subsequent observations. Even state-of-the-art models such\nas GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment\ninteractions, exhibiting clear limitations in spatial reasoning and\nlong-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset\nof over 3,000 language-guided tasks situated in diverse, photorealistic\nenvironments constructed using Unreal Engine and the UnrealCV-Zoo framework.\nThe tasks encompass a wide range of embodied challenges, including navigation,\nobject manipulation, and multi-stage goal execution. Each task unfolds as a\nmulti-step trajectory, pairing first-person visual observations with high-level\ninstructions, grounded actions, and natural language rationales that express\nthe agent's intent at every step. Using EmRACE-3K, we establish a benchmark to\nevaluate the embodied reasoning capabilities of VLMs across three key\ndimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage\nGoal Execution. In zero-shot settings, all models achieve success rates below\n20%, underscoring the challenge posed by our benchmark and the current\nlimitations of VLMs in interactive environments. To demonstrate the utility of\nEmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning\nfollowed by reinforcement learning. This approach yields substantial\nimprovements across all three challenge categories, highlighting the dataset's\neffectiveness in enabling the development of embodied reasoning capabilities.", "AI": {"tldr": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u573a\u666f\u8868\u73b0\u6709\u9650\uff0c\u672c\u6587\u5f15\u5165EmRACE - 3K\u6570\u636e\u96c6\u8bc4\u4f30\u5176\u5177\u8eab\u63a8\u7406\u80fd\u529b\uff0c\u96f6\u6837\u672c\u4e0b\u6a21\u578b\u6210\u529f\u7387\u4f4e\uff0c\u7528\u8be5\u6570\u636e\u96c6\u5fae\u8c03\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u573a\u666f\uff08\u9700\u8981\u5728\u7ebf\u4ea4\u4e92\u548c\u4e3b\u52a8\u573a\u666f\u7406\u89e3\uff09\u7684\u6709\u6548\u6027\u6709\u9650\uff0c\u5982\u5728\u5f00\u653e\u73af\u5883\u4ea4\u4e92\u4e2d\u6709\u7a7a\u95f4\u63a8\u7406\u548c\u957f\u671f\u89c4\u5212\u65b9\u9762\u7684\u5c40\u9650\u3002", "method": "\u5f15\u5165\u5305\u542b3000\u591a\u4e2a\u8bed\u8a00\u5f15\u5bfc\u4efb\u52a1\u7684EmRACE - 3K\u6570\u636e\u96c6\uff0c\u5efa\u7acb\u57fa\u51c6\u4ece\u63a2\u7d22\u3001\u52a8\u6001\u7a7a\u95f4\u8bed\u4e49\u63a8\u7406\u548c\u591a\u9636\u6bb5\u76ee\u6807\u6267\u884c\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u6a21\u578b\uff1b\u7528\u76d1\u7763\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u5bf9Qwen2.5 - VL - 7B\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0c\u6240\u6709\u6a21\u578b\u6210\u529f\u7387\u4f4e\u4e8e20%\uff1b\u7528EmRACE - 3K\u5fae\u8c03Qwen2.5 - VL - 7B\u540e\uff0c\u5728\u4e09\u4e2a\u6311\u6218\u7c7b\u522b\u4e2d\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "EmRACE - 3K\u6570\u636e\u96c6\u80fd\u6709\u6548\u63a8\u52a8\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5177\u8eab\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.10552", "pdf": "https://arxiv.org/pdf/2507.10552", "abs": "https://arxiv.org/abs/2507.10552", "authors": ["Vladimir Iashin", "Horace Lee", "Dan Schofield", "Andrew Zisserman"], "title": "Self-supervised Learning on Camera Trap Footage Yields a Strong Universal Face Embedder", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted for publication. Project page, code and weights:\n  https://www.robots.ox.ac.uk/~vgg/research/ChimpUFE/", "summary": "Camera traps are revolutionising wildlife monitoring by capturing vast\namounts of visual data; however, the manual identification of individual\nanimals remains a significant bottleneck. This study introduces a fully\nself-supervised approach to learning robust chimpanzee face embeddings from\nunlabeled camera-trap footage. Leveraging the DINOv2 framework, we train Vision\nTransformers on automatically mined face crops, eliminating the need for\nidentity labels. Our method demonstrates strong open-set re-identification\nperformance, surpassing supervised baselines on challenging benchmarks such as\nBossou, despite utilising no labelled data during training. This work\nunderscores the potential of self-supervised learning in biodiversity\nmonitoring and paves the way for scalable, non-invasive population studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u81ea\u76d1\u7763\u65b9\u6cd5\u4ece\u65e0\u6807\u7b7e\u76f8\u673a\u9677\u9631\u955c\u5934\u4e2d\u5b66\u4e60\u9ed1\u7329\u7329\u9762\u90e8\u5d4c\u5165\uff0c\u8868\u73b0\u8d85\u6709\u76d1\u7763\u57fa\u7ebf\uff0c\u51f8\u663e\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u76f8\u673a\u9677\u9631\u867d\u80fd\u6355\u6349\u5927\u91cf\u89c6\u89c9\u6570\u636e\uff0c\u4f46\u624b\u52a8\u8bc6\u522b\u4e2a\u4f53\u52a8\u7269\u662f\u74f6\u9888\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u5229\u7528DINOv2\u6846\u67b6\uff0c\u5728\u81ea\u52a8\u6316\u6398\u7684\u9762\u90e8\u88c1\u526a\u56fe\u50cf\u4e0a\u8bad\u7ec3\u89c6\u89c9Transformer\uff0c\u65e0\u9700\u8eab\u4efd\u6807\u7b7e\u3002", "result": "\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u5f00\u653e\u96c6\u91cd\u65b0\u8bc6\u522b\u6027\u80fd\uff0c\u8d85\u8d8a\u6709\u76d1\u7763\u57fa\u7ebf\u3002", "conclusion": "\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u4e2d\u6709\u6f5c\u529b\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u975e\u4fb5\u5165\u6027\u79cd\u7fa4\u7814\u7a76\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2507.10084", "pdf": "https://arxiv.org/pdf/2507.10084", "abs": "https://arxiv.org/abs/2507.10084", "authors": ["Haonan Chen", "Xin Tong"], "title": "A Transfer Learning-Based Method for Water Body Segmentation in Remote Sensing Imagery: A Case Study of the Zhada Tulin Area", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages, 6 figures, 2 tables", "summary": "To address the prevalent challenges of domain shift and small sample sizes in\nremote sensing image water body segmentation, this study proposes and validates\na two-stage transfer learning strategy based on the SegFormer model. The\napproach begins by training a foundational segmentation model on a diverse\nsource domain, where it achieves an Intersection over Union (IoU) of 68.80% on\nits validation set, followed by fine-tuning on data from the distinct target\ndomain. Focusing on the Zhada Tulin area in Tibet -- a region characterized by\nhighly complex topography and spectral features -- the experimental results\ndemonstrate that this strategy significantly boosts the IoU for the water body\nsegmentation task from 25.50% (for direct transfer) to 64.84%. This not only\neffectively resolves the model performance degradation caused by domain\ndiscrepancy but also provides an effective technical paradigm for\nhigh-precision thematic information extraction in data-scarce and\nenvironmentally unique remote sensing scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSegFormer\u7684\u4e24\u9636\u6bb5\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\u89e3\u51b3\u9065\u611f\u5f71\u50cf\u6c34\u4f53\u5206\u5272\u4e2d\u9886\u57df\u504f\u79fb\u548c\u5c0f\u6837\u672c\u95ee\u9898\uff0c\u5728\u897f\u85cf\u624e\u8fbe\u571f\u6797\u5730\u533a\u5b9e\u9a8c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u9065\u611f\u5f71\u50cf\u6c34\u4f53\u5206\u5272\u4e2d\u666e\u904d\u5b58\u5728\u7684\u9886\u57df\u504f\u79fb\u548c\u5c0f\u6837\u672c\u95ee\u9898\u3002", "method": "\u57fa\u4e8eSegFormer\u6a21\u578b\uff0c\u5148\u5728\u6e90\u9886\u57df\u8bad\u7ec3\u57fa\u7840\u5206\u5272\u6a21\u578b\uff0c\u518d\u5728\u76ee\u6807\u9886\u57df\u5fae\u8c03\u3002", "result": "\u5728\u6e90\u9886\u57df\u9a8c\u8bc1\u96c6IoU\u8fbe68.80%\uff0c\u5728\u624e\u8fbe\u571f\u6797\u5730\u533a\u5c06\u6c34\u4f53\u5206\u5272IoU\u4ece25.50%\u63d0\u5347\u523064.84%\u3002", "conclusion": "\u6709\u6548\u89e3\u51b3\u9886\u57df\u5dee\u5f02\u5bfc\u81f4\u7684\u6a21\u578b\u6027\u80fd\u4e0b\u964d\uff0c\u4e3a\u6570\u636e\u7a00\u7f3a\u548c\u73af\u5883\u72ec\u7279\u7684\u9065\u611f\u573a\u666f\u9ad8\u7cbe\u5ea6\u4e13\u9898\u4fe1\u606f\u63d0\u53d6\u63d0\u4f9b\u6709\u6548\u6280\u672f\u8303\u5f0f\u3002"}}
{"id": "2507.10143", "pdf": "https://arxiv.org/pdf/2507.10143", "abs": "https://arxiv.org/abs/2507.10143", "authors": ["David Calhas", "Arlindo L. Oliveira"], "title": "Deep Recurrence for Dynamical Segmentation Models", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages", "summary": "While biological vision systems rely heavily on feedback connections to\niteratively refine perception, most artificial neural networks remain purely\nfeedforward, processing input in a single static pass. In this work, we propose\na predictive coding inspired feedback mechanism that introduces a recurrent\nloop from output to input, allowing the model to refine its internal state over\ntime. We implement this mechanism within a standard U-Net architecture and\nintroduce two biologically motivated operations, softmax projection and\nexponential decay, to ensure stability of the feedback loop. Through controlled\nexperiments on a synthetic segmentation task, we show that the feedback model\nsignificantly outperforms its feedforward counterpart in noisy conditions and\ngeneralizes more effectively with limited supervision. Notably, feedback\nachieves above random performance with just two training examples, while the\nfeedforward model requires at least four. Our findings demonstrate that\nfeedback enhances robustness and data efficiency, and offer a path toward more\nadaptive and biologically inspired neural architectures. Code is available at:\ngithub.com/DCalhas/feedback_segmentation.", "AI": {"tldr": "\u63d0\u51fa\u9884\u6d4b\u7f16\u7801\u542f\u53d1\u7684\u53cd\u9988\u673a\u5236\uff0c\u5728U - Net\u67b6\u6784\u4e2d\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u8868\u660e\u53cd\u9988\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u548c\u6709\u9650\u76d1\u7763\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u589e\u5f3a\u4e86\u9c81\u68d2\u6027\u548c\u6570\u636e\u6548\u7387\u3002", "motivation": "\u751f\u7269\u89c6\u89c9\u7cfb\u7edf\u4f9d\u8d56\u53cd\u9988\u8fde\u63a5\u8fed\u4ee3\u4f18\u5316\u611f\u77e5\uff0c\u800c\u5927\u591a\u6570\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u662f\u524d\u9988\u7684\uff0c\u56e0\u6b64\u63d0\u51fa\u53cd\u9988\u673a\u5236\u6539\u8fdb\u3002", "method": "\u5728\u6807\u51c6U - Net\u67b6\u6784\u4e2d\u5b9e\u73b0\u53cd\u9988\u673a\u5236\uff0c\u5f15\u5165\u8f6f\u6700\u5927\u6295\u5f71\u548c\u6307\u6570\u8870\u51cf\u64cd\u4f5c\u786e\u4fdd\u53cd\u9988\u73af\u7a33\u5b9a\u6027\u3002", "result": "\u53cd\u9988\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u663e\u8457\u4f18\u4e8e\u524d\u9988\u6a21\u578b\uff0c\u6709\u9650\u76d1\u7763\u4e0b\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\uff0c\u4ec5\u4e24\u4e2a\u8bad\u7ec3\u6837\u672c\u5c31\u80fd\u4f18\u4e8e\u968f\u673a\u8868\u73b0\uff0c\u800c\u524d\u9988\u6a21\u578b\u81f3\u5c11\u9700\u56db\u4e2a\u3002", "conclusion": "\u53cd\u9988\u589e\u5f3a\u4e86\u9c81\u68d2\u6027\u548c\u6570\u636e\u6548\u7387\uff0c\u4e3a\u6784\u5efa\u66f4\u5177\u9002\u5e94\u6027\u548c\u751f\u7269\u542f\u53d1\u7684\u795e\u7ecf\u67b6\u6784\u63d0\u4f9b\u4e86\u9014\u5f84\u3002"}}
{"id": "2507.10178", "pdf": "https://arxiv.org/pdf/2507.10178", "abs": "https://arxiv.org/abs/2507.10178", "authors": ["Wonung Kim", "Yubin Lee", "Yoonsung Kim", "Jinwoo Hwang", "Seongryong Oh", "Jiyong Jung", "Aziz Huseynov", "Woong Gyu Park", "Chang Hyun Park", "Divya Mahajan", "Jongse Park"], "title": "Pimba: A Processing-in-Memory Acceleration for Post-Transformer Large Language Model Serving", "categories": ["cs.AR", "cs.LG"], "comment": null, "summary": "Transformers are the driving force behind today's Large Language Models\n(LLMs), serving as the foundation for their performance and versatility. Yet,\ntheir compute and memory costs grow with sequence length, posing scalability\nchallenges for long-context inferencing. In response, the algorithm community\nis exploring alternative architectures, such as state space models (SSMs),\nlinear attention, and recurrent neural networks (RNNs), which we refer to as\npost-transformers. This shift presents a key challenge: building a serving\nsystem that efficiently supports both transformer and post-transformer LLMs\nwithin a unified framework. To address this challenge, we analyze the\nperformance characteristics of transformer and post-transformer LLMs. Despite\ntheir algorithmic differences, both are fundamentally limited by memory\nbandwidth under batched inference due to attention in transformers and state\nupdates in post-transformers. Further analyses suggest two additional insights:\n(1) state update operations, unlike attention, incur high hardware cost, making\nper-bank PIM acceleration inefficient, and (2) different low-precision\narithmetic methods offer varying accuracy-area tradeoffs, while we identify\nMicrosoft's MX as the Pareto-optimal choice. Building on these insights, we\ndesign Pimba as an array of State-update Processing Units (SPUs), each shared\nbetween two banks to enable interleaved access to PIM. Each SPU includes a\nState-update Processing Engine (SPE) that comprises element-wise multipliers\nand adders using MX-based quantized arithmetic, enabling efficient execution of\nstate update and attention operations. Our evaluation shows that, compared to\nLLM-optimized GPU and GPU+PIM systems, Pimba achieves up to 3.2x and 2.1x\nhigher token generation throughput, respectively.", "AI": {"tldr": "\u8bba\u6587\u805a\u7126\u9ad8\u6548\u652f\u6301Transformer\u548c\u540eTransformer\u5927\u8bed\u8a00\u6a21\u578b\u7684\u670d\u52a1\u7cfb\u7edf\uff0c\u5206\u6790\u6027\u80fd\u7279\u6027\u540e\u8bbe\u8ba1Pimba\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u541e\u5410\u91cf\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "Transformer\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u968f\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\uff0c\u7b97\u6cd5\u754c\u63a2\u7d22\u540eTransformer\u67b6\u6784\uff0c\u9700\u6784\u5efa\u7edf\u4e00\u6846\u67b6\u7684\u670d\u52a1\u7cfb\u7edf\u3002", "method": "\u5206\u6790Transformer\u548c\u540eTransformer\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7279\u6027\uff0c\u8bbe\u8ba1\u7531\u72b6\u6001\u66f4\u65b0\u5904\u7406\u5355\u5143\uff08SPU\uff09\u7ec4\u6210\u7684Pimba\uff0c\u91c7\u7528MX\u91cf\u5316\u7b97\u672f\u3002", "result": "\u4e0eLLM\u4f18\u5316\u7684GPU\u548cGPU+PIM\u7cfb\u7edf\u76f8\u6bd4\uff0cPimba\u7684\u4ee4\u724c\u751f\u6210\u541e\u5410\u91cf\u5206\u522b\u63d0\u9ad8\u4e863.2\u500d\u548c2.1\u500d\u3002", "conclusion": "Pimba\u80fd\u6709\u6548\u89e3\u51b3\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u9ad8\u6548\u652f\u6301Transformer\u548c\u540eTransformer\u5927\u8bed\u8a00\u6a21\u578b\u7684\u95ee\u9898\u3002"}}
{"id": "2507.10201", "pdf": "https://arxiv.org/pdf/2507.10201", "abs": "https://arxiv.org/abs/2507.10201", "authors": ["Gleb Shishaev", "Vasily Demyanov", "Daniel Arnold"], "title": "History Matching under Uncertainty of Geological Scenarios with Implicit Geological Realism Control with Generative Deep Learning and Graph Convolutions", "categories": ["stat.AP", "cs.LG", "physics.data-an"], "comment": "Part of the completed PhD thesis\n  https://geodatascience.hw.ac.uk/theses/", "summary": "The graph-based variational autoencoder represents an architecture that can\nhandle the uncertainty of different geological scenarios, such as depositional\nor structural, through the concept of a lowerdimensional latent space. The main\ndifference from recent studies is utilisation of a graph-based approach in\nreservoir modelling instead of the more traditional lattice-based deep learning\nmethods. We provide a solution to implicitly control the geological realism\nthrough the latent variables of a generative model and Geodesic metrics. Our\nexperiments of AHM with synthetic dataset that consists of 3D realisations of\nchannelised geological representations with two distinct scenarios with one and\ntwo channels shows the viability of the approach. We offer in-depth analysis of\nthe latent space using tools such as PCA, t-SNE, and TDA to illustrate its\nstructure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5904\u7406\u5730\u8d28\u573a\u666f\u4e0d\u786e\u5b9a\u6027\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u4e0d\u540c\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u53ef\u884c\u6027\u5e76\u5206\u6790\u6f5c\u5728\u7a7a\u95f4\u7ed3\u6784\u3002", "motivation": "\u5904\u7406\u4e0d\u540c\u5730\u8d28\u573a\u666f\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u91c7\u7528\u65b0\u65b9\u6cd5\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e\u6676\u683c\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u57fa\u4e8e\u56fe\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u751f\u6210\u6a21\u578b\u7684\u6f5c\u5728\u53d8\u91cf\u548c\u6d4b\u5730\u8ddd\u79bb\u9690\u5f0f\u63a7\u5236\u5730\u8d28\u771f\u5b9e\u6027\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\uff0c\u5bf9\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u3002", "conclusion": "\u57fa\u4e8e\u56fe\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\u53ef\u6709\u6548\u5904\u7406\u5730\u8d28\u573a\u666f\u4e0d\u786e\u5b9a\u6027\uff0c\u65b9\u6cd5\u5177\u6709\u53ef\u884c\u6027\u3002"}}
{"id": "2507.10222", "pdf": "https://arxiv.org/pdf/2507.10222", "abs": "https://arxiv.org/abs/2507.10222", "authors": ["Mingzhi Xu", "Yizhe Zhang"], "title": "Spatial Lifting for Dense Prediction", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "Preprint. Under review", "summary": "We present Spatial Lifting (SL), a novel methodology for dense prediction\ntasks. SL operates by lifting standard inputs, such as 2D images, into a\nhigher-dimensional space and subsequently processing them using networks\ndesigned for that higher dimension, such as a 3D U-Net. Counterintuitively,\nthis dimensionality lifting allows us to achieve good performance on benchmark\ntasks compared to conventional approaches, while reducing inference costs and\nsignificantly lowering the number of model parameters. The SL framework\nproduces intrinsically structured outputs along the lifted dimension. This\nemergent structure facilitates dense supervision during training and enables\nrobust, near-zero-additional-cost prediction quality assessment at test time.\nWe validate our approach across 19 benchmark datasets (13 for semantic\nsegmentation and 6 for depth estimation), demonstrating competitive dense\nprediction performance while reducing the model parameter count by over 98% (in\nthe U-Net case) and lowering inference costs. Spatial Lifting introduces a new\nvision modeling paradigm that offers a promising path toward more efficient,\naccurate, and reliable deep networks for dense prediction tasks in vision.", "AI": {"tldr": "\u63d0\u51faSpatial Lifting (SL)\u65b9\u6cd5\u7528\u4e8e\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\uff0c\u53ef\u63d0\u5347\u6027\u80fd\u3001\u964d\u4f4e\u63a8\u7406\u6210\u672c\u548c\u6a21\u578b\u53c2\u6570\u6570\u91cf\u3002", "motivation": "\u5bfb\u627e\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u548c\u53ef\u9760\u7684\u6df1\u5ea6\u7f51\u7edc\u7528\u4e8e\u89c6\u89c9\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u3002", "method": "\u5c06\u6807\u51c6\u8f93\u5165\uff08\u59822D\u56fe\u50cf\uff09\u63d0\u5347\u5230\u9ad8\u7ef4\u7a7a\u95f4\uff0c\u4f7f\u7528\u9ad8\u7ef4\u7f51\u7edc\uff08\u59823D U - Net\uff09\u5904\u7406\u3002", "result": "\u572819\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u964d\u4f4eU - Net\u6a21\u578b\u53c2\u6570\u8d8598%\uff0c\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u5c55\u73b0\u51fa\u6709\u7ade\u4e89\u529b\u7684\u5bc6\u96c6\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "Spatial Lifting\u4e3a\u5bc6\u96c6\u9884\u6d4b\u4efb\u52a1\u5f15\u5165\u4e86\u65b0\u7684\u89c6\u89c9\u5efa\u6a21\u8303\u5f0f\uff0c\u6709\u5e7f\u9614\u524d\u666f\u3002"}}
{"id": "2507.10267", "pdf": "https://arxiv.org/pdf/2507.10267", "abs": "https://arxiv.org/abs/2507.10267", "authors": ["Novruz Amirov", "Baran Isik", "Bilal Ihsan Tuncer", "Serif Bahtiyar"], "title": "DNS Tunneling: Threat Landscape and Improved Detection Solutions", "categories": ["cs.CR", "cs.LG", "cs.NI"], "comment": null, "summary": "Detecting Domain Name System (DNS) tunneling is a significant challenge in\nsecurity due to its capacity to hide harmful actions within DNS traffic that\nappears to be normal and legitimate. Traditional detection methods are based on\nrule-based approaches or signature matching methods that are often insufficient\nto accurately identify such covert communication channels. This research is\nabout effectively detecting DNS tunneling. We propose a novel approach to\ndetect DNS tunneling with machine learning algorithms. We combine machine\nlearning algorithms to analyze the traffic by using features extracted from DNS\ntraffic. Analyses results show that the proposed approach is a good candidate\nto detect DNS tunneling accurately.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u68c0\u6d4bDNS\u96a7\u9053\u7684\u65b0\u65b9\u6cd5\uff0c\u5206\u6790\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u68c0\u6d4b\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u6216\u7b7e\u540d\u5339\u914d\u7684DNS\u96a7\u9053\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u51c6\u786e\u8bc6\u522b\u9690\u853d\u901a\u4fe1\u6e20\u9053\uff0c\u9700\u6709\u6548\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u5229\u7528\u4eceDNS\u6d41\u91cf\u4e2d\u63d0\u53d6\u7684\u7279\u5f81\u5206\u6790\u6d41\u91cf\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u662f\u51c6\u786e\u68c0\u6d4bDNS\u96a7\u9053\u7684\u826f\u597d\u5019\u9009\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u65b9\u6cd5\u53ef\u6709\u6548\u51c6\u786e\u68c0\u6d4bDNS\u96a7\u9053\u3002"}}
{"id": "2507.10330", "pdf": "https://arxiv.org/pdf/2507.10330", "abs": "https://arxiv.org/abs/2507.10330", "authors": ["Mohammed Bouri", "Adnane Saoud"], "title": "Bridging Robustness and Generalization Against Word Substitution Attacks in NLP via the Growth Bound Matrix Approach", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ACL Findings 2025", "summary": "Despite advancements in Natural Language Processing (NLP), models remain\nvulnerable to adversarial attacks, such as synonym substitutions. While prior\nwork has focused on improving robustness for feed-forward and convolutional\narchitectures, the robustness of recurrent networks and modern state space\nmodels (SSMs), such as S4, remains understudied. These architectures pose\nunique challenges due to their sequential processing and complex parameter\ndynamics. In this paper, we introduce a novel regularization technique based on\nGrowth Bound Matrices (GBM) to improve NLP model robustness by reducing the\nimpact of input perturbations on model outputs. We focus on computing the GBM\nfor three architectures: Long Short-Term Memory (LSTM), State Space models\n(S4), and Convolutional Neural Networks (CNN). Our method aims to (1) enhance\nresilience against word substitution attacks, (2) improve generalization on\nclean text, and (3) providing the first systematic analysis of SSM (S4)\nrobustness. Extensive experiments across multiple architectures and benchmark\ndatasets demonstrate that our method improves adversarial robustness by up to\n8.8% over existing baselines. These results highlight the effectiveness of our\napproach, outperforming several state-of-the-art methods in adversarial\ndefense. Codes are available at https://github.com/BouriMohammed/GBM", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eGBM\u7684\u6b63\u5219\u5316\u6280\u672f\u63d0\u5347NLP\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u9c81\u68d2\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u57fa\u7ebf\u63d0\u5347\u6700\u591a8.8%\u3002", "motivation": "\u73b0\u6709NLP\u6a21\u578b\u6613\u53d7\u653b\u51fb\uff0c\u5faa\u73af\u7f51\u7edc\u548cSSM\u7b49\u67b6\u6784\u9c81\u68d2\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165\u57fa\u4e8eGBM\u7684\u6b63\u5219\u5316\u6280\u672f\uff0c\u8ba1\u7b97LSTM\u3001S4\u548cCNN\u7684GBM\uff0c\u589e\u5f3a\u6297\u653b\u51fb\u80fd\u529b\u3001\u6cdb\u5316\u80fd\u529b\u5e76\u5206\u6790S4\u9c81\u68d2\u6027\u3002", "result": "\u5728\u591a\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u65b9\u6cd5\u6bd4\u73b0\u6709\u57fa\u7ebf\u63d0\u5347\u5bf9\u6297\u9c81\u68d2\u6027\u6700\u591a8.8%\uff0c\u4f18\u4e8e\u591a\u4e2a\u5148\u8fdb\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8eGBM\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347NLP\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u9c81\u68d2\u6027\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2507.10375", "pdf": "https://arxiv.org/pdf/2507.10375", "abs": "https://arxiv.org/abs/2507.10375", "authors": ["Utkarsh Singhal", "Ryan Feng", "Stella X. Yu", "Atul Prakash"], "title": "Test-Time Canonicalization by Foundation Models for Robust Perception", "categories": ["cs.CV", "cs.LG"], "comment": "Published at ICML 2025", "summary": "Real-world visual perception requires invariance to diverse transformations,\nyet current methods rely heavily on specialized architectures or training on\npredefined augmentations, limiting generalization. We propose FOCAL, a\ntest-time, data-driven framework that achieves robust perception by leveraging\ninternet-scale visual priors from foundation models. By generating and\noptimizing candidate transformations toward visually typical, \"canonical\"\nviews, FOCAL enhances robustness without re-training or architectural changes.\nOur experiments demonstrate improved robustness of CLIP and SAM across\nchallenging transformations, including 2D/3D rotations, illumination shifts\n(contrast and color), and day-night variations. We also highlight potential\napplications in active vision. Our approach challenges the assumption that\ntransform-specific training is necessary, instead offering a scalable path to\ninvariance. Our code is available at: https://github.com/sutkarsh/focal.", "AI": {"tldr": "\u63d0\u51faFOCAL\u6846\u67b6\uff0c\u5229\u7528\u57fa\u7840\u6a21\u578b\u7684\u89c6\u89c9\u5148\u9a8c\u5728\u6d4b\u8bd5\u65f6\u5b9e\u73b0\u9c81\u68d2\u611f\u77e5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u63d0\u5347CLIP\u548cSAM\u7684\u9c81\u68d2\u6027\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u611f\u77e5\u65b9\u6cd5\u4f9d\u8d56\u7279\u6b8a\u67b6\u6784\u6216\u9884\u5b9a\u4e49\u589e\u5f3a\u8bad\u7ec3\uff0c\u6cdb\u5316\u6027\u53d7\u9650\u3002", "method": "\u63d0\u51faFOCAL\u6846\u67b6\uff0c\u5728\u6d4b\u8bd5\u65f6\u751f\u6210\u5e76\u4f18\u5316\u5019\u9009\u53d8\u6362\u4ee5\u8fbe\u5230\u5178\u578b\u89c6\u56fe\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u6539\u53d8\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u63d0\u5347\u4e86CLIP\u548cSAM\u5728\u591a\u79cd\u53d8\u6362\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u59822D/3D\u65cb\u8f6c\u3001\u5149\u7167\u53d8\u5316\u7b49\u3002", "conclusion": "\u6311\u6218\u4e86\u7279\u5b9a\u53d8\u6362\u8bad\u7ec3\u7684\u5fc5\u8981\u6027\uff0c\u63d0\u4f9b\u4e86\u5b9e\u73b0\u4e0d\u53d8\u6027\u7684\u53ef\u6269\u5c55\u9014\u5f84\u3002"}}
{"id": "2507.10381", "pdf": "https://arxiv.org/pdf/2507.10381", "abs": "https://arxiv.org/abs/2507.10381", "authors": ["Aaryam Sharma"], "title": "Improving Remote Sensing Classification using Topological Data Analysis and Convolutional Neural Networks", "categories": ["cs.CV", "cs.LG"], "comment": "9 pages, 8 figures", "summary": "Topological data analysis (TDA) is a relatively new field that is gaining\nrapid adoption due to its robustness and ability to effectively describe\ncomplex datasets by quantifying geometric information. In imaging contexts, TDA\ntypically models data as filtered cubical complexes from which we can extract\ndiscriminative features using persistence homology. Meanwhile, convolutional\nneural networks (CNNs) have been shown to be biased towards texture based local\nfeatures. To address this limitation, we propose a TDA feature engineering\npipeline and a simple method to integrate topological features with deep\nlearning models on remote sensing classification. Our method improves the\nperformance of a ResNet18 model on the EuroSAT dataset by 1.44% achieving\n99.33% accuracy, which surpasses all previously reported single-model\naccuracies, including those with larger architectures, such as ResNet50 (2x\nlarger) and XL Vision Transformers (197x larger). We additionally show that our\nmethod's accuracy is 1.82% higher than our ResNet18 baseline on the RESISC45\ndataset. To our knowledge, this is the first application of TDA features in\nsatellite scene classification with deep learning. This demonstrates that TDA\nfeatures can be integrated with deep learning models, even on datasets without\nexplicit topological structures, thereby increasing the applicability of TDA. A\nclean implementation of our method will be made publicly available upon\npublication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTDA\u7279\u5f81\u5de5\u7a0b\u7ba1\u9053\u53ca\u5c06\u62d3\u6251\u7279\u5f81\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9065\u611f\u5206\u7c7b\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u5c55\u793a\u4e86TDA\u7279\u5f81\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7ed3\u5408\u7684\u6f5c\u529b\u3002", "motivation": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u9065\u611f\u5206\u7c7b\u4e2d\u503e\u5411\u4e8e\u57fa\u4e8e\u7eb9\u7406\u7684\u5c40\u90e8\u7279\u5f81\uff0c\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u5229\u7528TDA\u6709\u6548\u63cf\u8ff0\u590d\u6742\u6570\u636e\u96c6\u7684\u80fd\u529b\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51faTDA\u7279\u5f81\u5de5\u7a0b\u7ba1\u9053\uff0c\u5e76\u4f7f\u7528\u7b80\u5355\u65b9\u6cd5\u5c06\u62d3\u6251\u7279\u5f81\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96c6\u6210\u3002", "result": "\u5728EuroSAT\u6570\u636e\u96c6\u4e0a\u4f7fResNet18\u6a21\u578b\u6027\u80fd\u63d0\u53471.44%\uff0c\u8fbe\u523099.33%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u6240\u6709\u4e4b\u524d\u62a5\u544a\u7684\u5355\u6a21\u578b\u51c6\u786e\u7387\uff1b\u5728RESISC45\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u6bd4ResNet18\u57fa\u7ebf\u9ad81.82%\u3002", "conclusion": "TDA\u7279\u5f81\u53ef\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u96c6\u6210\uff0c\u5373\u4f7f\u5728\u65e0\u660e\u786e\u62d3\u6251\u7ed3\u6784\u7684\u6570\u636e\u96c6\u4e0a\u4e5f\u80fd\u589e\u52a0TDA\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2507.10468", "pdf": "https://arxiv.org/pdf/2507.10468", "abs": "https://arxiv.org/abs/2507.10468", "authors": ["Ariadna Mon", "Sa\u00fal Fenollosa", "Jon Lecumberri"], "title": "From BERT to Qwen: Hate Detection across architectures", "categories": ["cs.CL", "cs.LG"], "comment": "4 pages, 5 figures. EE-559 Deep Learning course project (Group 11)", "summary": "Online platforms struggle to curb hate speech without over-censoring\nlegitimate discourse. Early bidirectional transformer encoders made big\nstrides, but the arrival of ultra-large autoregressive LLMs promises deeper\ncontext-awareness. Whether this extra scale actually improves practical\nhate-speech detection on real-world text remains unverified. Our study puts\nthis question to the test by benchmarking both model families, classic encoders\nand next-generation LLMs, on curated corpora of online interactions for\nhate-speech detection (Hate or No Hate).", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4\u7ecf\u5178\u7f16\u7801\u5668\u548c\u4e0b\u4e00\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u7f51\u7edc\u4ec7\u6068\u8a00\u8bba\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5728\u7ebf\u5e73\u53f0\u96be\u4ee5\u5728\u4e0d\u8fc7\u5ea6\u5ba1\u67e5\u5408\u6cd5\u8a00\u8bba\u7684\u60c5\u51b5\u4e0b\u904f\u5236\u4ec7\u6068\u8a00\u8bba\uff0c\u8d85\u5927\u578b\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u5b9e\u7528\u6027\u672a\u7ecf\u9a8c\u8bc1\u3002", "method": "\u5728\u6574\u7406\u7684\u5728\u7ebf\u4ea4\u4e92\u8bed\u6599\u5e93\u4e0a\u5bf9\u7ecf\u5178\u7f16\u7801\u5668\u548c\u4e0b\u4e00\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u539f\u6587\u672a\u63d0\u53ca\u3002", "conclusion": "\u539f\u6587\u672a\u63d0\u53ca\u3002"}}
{"id": "2507.10499", "pdf": "https://arxiv.org/pdf/2507.10499", "abs": "https://arxiv.org/abs/2507.10499", "authors": ["Philippe Rufin", "Pauline Lucie Hammer", "Leon-Friedrich Thomas", "S\u00e1 Nogueira Lisboa", "Natasha Ribeiro", "Almeida Sitoe", "Patrick Hostert", "Patrick Meyfroidt"], "title": "National level satellite-based crop field inventories in smallholder landscapes", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The design of science-based policies to improve the sustainability of\nsmallholder agriculture is challenged by a limited understanding of fundamental\nsystem properties, such as the spatial distribution of active cropland and\nfield size. We integrate very high spatial resolution (1.5 m) Earth observation\ndata and deep transfer learning to derive crop field delineations in complex\nagricultural systems at the national scale, while maintaining minimum reference\ndata requirements and enhancing transferability. We provide the first\nnational-level dataset of 21 million individual fields for Mozambique (covering\n~800,000 km2) for 2023. Our maps separate active cropland from non-agricultural\nland use with an overall accuracy of 93% and balanced omission and commission\nerrors. Field-level spatial agreement reached median intersection over union\n(IoU) scores of 0.81, advancing the state-of-the-art in large-area field\ndelineation in complex smallholder systems. The active cropland maps capture\nfragmented rural regions with low cropland shares not yet identified in global\nland cover or cropland maps. These regions are mostly located in agricultural\nfrontier regions which host 7-9% of the Mozambican population. Field size in\nMozambique is very low overall, with half of the fields being smaller than 0.16\nha, and 83% smaller than 0.5 ha. Mean field size at aggregate spatial\nresolution (0.05{\\deg}) is 0.32 ha, but it varies strongly across gradients of\naccessibility, population density, and net forest cover change. This variation\nreflects a diverse set of actors, ranging from semi-subsistence smallholder\nfarms to medium-scale commercial farming, and large-scale farming operations.\nOur results highlight that field size is a key indicator relating to\nsocio-economic and environmental outcomes of agriculture (e.g., food\nproduction, livelihoods, deforestation, biodiversity), as well as their\ntrade-offs.", "AI": {"tldr": "\u7ed3\u5408\u9ad8\u5206\u8fa8\u7387\u5730\u7403\u89c2\u6d4b\u6570\u636e\u548c\u6df1\u5ea6\u8fc1\u79fb\u5b66\u4e60\uff0c\u4e3a\u83ab\u6851\u6bd4\u514b\u7ed8\u5236\u5168\u56fd\u519c\u7530\u5730\u56fe\uff0c\u5206\u6790\u519c\u7530\u5206\u5e03\u3001\u89c4\u6a21\u7b49\u7279\u5f81\uff0c\u6307\u51fa\u7530\u5757\u89c4\u6a21\u662f\u519c\u4e1a\u793e\u4f1a\u7ecf\u6d4e\u548c\u73af\u5883\u7ed3\u679c\u7684\u5173\u952e\u6307\u6807\u3002", "motivation": "\u56e0\u5bf9\u57fa\u672c\u7cfb\u7edf\u5c5e\u6027\u4e86\u89e3\u6709\u9650\uff0c\u8bbe\u8ba1\u63d0\u5347\u5c0f\u519c\u6237\u519c\u4e1a\u53ef\u6301\u7eed\u6027\u7684\u79d1\u5b66\u653f\u7b56\u9762\u4e34\u6311\u6218\uff0c\u9700\u83b7\u53d6\u76f8\u5173\u4fe1\u606f\u3002", "method": "\u6574\u5408\u9ad8\u7a7a\u95f4\u5206\u8fa8\u7387\uff081.5\u7c73\uff09\u5730\u7403\u89c2\u6d4b\u6570\u636e\u548c\u6df1\u5ea6\u8fc1\u79fb\u5b66\u4e60\uff0c\u63a8\u5bfc\u590d\u6742\u519c\u4e1a\u7cfb\u7edf\u4e2d\u56fd\u5bb6\u5c42\u9762\u7684\u519c\u7530\u8fb9\u754c\u3002", "result": "\u63d0\u4f9b\u83ab\u6851\u6bd4\u514b2023\u5e742100\u4e07\u4e2a\u519c\u7530\u7684\u56fd\u5bb6\u7ea7\u6570\u636e\u96c6\uff0c\u5730\u56fe\u533a\u5206\u519c\u7530\u548c\u975e\u519c\u4e1a\u7528\u5730\u603b\u4f53\u7cbe\u5ea6\u8fbe93%\uff0c\u7530\u5757\u7a7a\u95f4\u4e00\u81f4\u6027\u4e2d\u4f4d\u6570IoU\u5206\u6570\u4e3a0.81\uff0c\u63ed\u793a\u519c\u7530\u5206\u5e03\u548c\u89c4\u6a21\u7684\u7279\u5f81\u53ca\u53d8\u5316\u3002", "conclusion": "\u7530\u5757\u89c4\u6a21\u662f\u4e0e\u519c\u4e1a\u793e\u4f1a\u7ecf\u6d4e\u548c\u73af\u5883\u7ed3\u679c\u53ca\u5176\u6743\u8861\u76f8\u5173\u7684\u5173\u952e\u6307\u6807\u3002"}}
{"id": "2507.10524", "pdf": "https://arxiv.org/pdf/2507.10524", "abs": "https://arxiv.org/abs/2507.10524", "authors": ["Sangmin Bae", "Yujin Kim", "Reza Bayat", "Sungnyun Kim", "Jiyoun Ha", "Tal Schuster", "Adam Fisch", "Hrayr Harutyunyan", "Ziwei Ji", "Aaron Courville", "Se-Young Yun"], "title": "Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation", "categories": ["cs.CL", "cs.LG"], "comment": "36 pages, 9 figures, 14 tables, codes at\n  https://github.com/raymin0223/mixture_of_recursions", "summary": "Scaling language models unlocks impressive capabilities, but the accompanying\ncomputational and memory demands make both training and deployment expensive.\nExisting efficiency efforts typically target either parameter sharing or\nadaptive computation, leaving open the question of how to attain both\nsimultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework\nthat combines the two axes of efficiency inside a single Recursive Transformer.\nMoR reuses a shared stack of layers across recursion steps to achieve parameter\nefficiency, while lightweight routers enable adaptive token-level thinking by\ndynamically assigning different recursion depths to individual tokens. This\nallows MoR to focus quadratic attention computation only among tokens still\nactive at a given recursion depth, further improving memory access efficiency\nby selectively caching only their key-value pairs. Beyond these core\nmechanisms, we also propose a KV sharing variant that reuses KV pairs from the\nfirst recursion, specifically designed to decrease prefill latency and memory\nfootprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms\na new Pareto frontier: at equal training FLOPs and smaller model sizes, it\nsignificantly lowers validation perplexity and improves few-shot accuracy,\nwhile delivering higher throughput compared with vanilla and existing recursive\nbaselines. These gains demonstrate that MoR is an effective path towards\nlarge-model quality without incurring large-model cost.", "AI": {"tldr": "\u63d0\u51faMixture-of-Recursions (MoR)\u6846\u67b6\u7ed3\u5408\u53c2\u6570\u5171\u4eab\u548c\u81ea\u9002\u5e94\u8ba1\u7b97\u63d0\u5347\u6548\u7387\uff0c\u5728\u591a\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u6548\u7387\u4f18\u5316\u65b9\u6cd5\u591a\u53ea\u9488\u5bf9\u53c2\u6570\u5171\u4eab\u6216\u81ea\u9002\u5e94\u8ba1\u7b97\u5176\u4e00\uff0c\u9700\u540c\u65f6\u5b9e\u73b0\u4e24\u8005\u3002", "method": "\u5f15\u5165MoR\u6846\u67b6\uff0c\u5728\u9012\u5f52Transformer\u4e2d\u7ed3\u5408\u4e24\u65b9\u9762\u6548\u7387\u63d0\u5347\uff0c\u5305\u62ec\u5171\u4eab\u5c42\u6808\u5b9e\u73b0\u53c2\u6570\u6548\u7387\u3001\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u5b9e\u73b0\u81ea\u9002\u5e94\u8ba1\u7b97\uff0c\u8fd8\u63d0\u51faKV\u5171\u4eab\u53d8\u4f53\u3002", "result": "\u5728135M\u52301.7B\u53c2\u6570\u6a21\u578b\u89c4\u6a21\u4e0a\uff0cMoR\u5728\u540c\u7b49\u8bad\u7ec3FLOPs\u548c\u66f4\u5c0f\u6a21\u578b\u5c3a\u5bf8\u4e0b\uff0c\u964d\u4f4e\u9a8c\u8bc1\u56f0\u60d1\u5ea6\u3001\u63d0\u9ad8\u5c11\u6837\u672c\u51c6\u786e\u7387\u548c\u541e\u5410\u91cf\u3002", "conclusion": "MoR\u662f\u5728\u4e0d\u4ea7\u751f\u5927\u6a21\u578b\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5927\u6a21\u578b\u8d28\u91cf\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2507.10547", "pdf": "https://arxiv.org/pdf/2507.10547", "abs": "https://arxiv.org/abs/2507.10547", "authors": ["Borui Zhang", "Qihang Rao", "Wenzhao Zheng", "Jie Zhou", "Jiwen Lu"], "title": "Quantize-then-Rectify: Efficient VQ-VAE Training", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Visual tokenizers are pivotal in multimodal large models, acting as bridges\nbetween continuous inputs and discrete tokens. Nevertheless, training\nhigh-compression-rate VQ-VAEs remains computationally demanding, often\nnecessitating thousands of GPU hours. This work demonstrates that a pre-trained\nVAE can be efficiently transformed into a VQ-VAE by controlling quantization\nnoise within the VAE's tolerance threshold. We present\n\\textbf{Quantize-then-Rectify (ReVQ)}, a framework leveraging pre-trained VAEs\nto enable rapid VQ-VAE training with minimal computational overhead. By\nintegrating \\textbf{channel multi-group quantization} to enlarge codebook\ncapacity and a \\textbf{post rectifier} to mitigate quantization errors, ReVQ\ncompresses ImageNet images into at most 512 tokens while sustaining competitive\nreconstruction quality (rFID = 1.06). Significantly, ReVQ reduces training\ncosts by over two orders of magnitude relative to state-of-the-art approaches:\nReVQ finishes full training on a single NVIDIA 4090 in approximately 22 hours,\nwhereas comparable methods require 4.5 days on 32 A100 GPUs. Experimental\nresults show that ReVQ achieves superior efficiency-reconstruction trade-offs.", "AI": {"tldr": "\u63d0\u51faReVQ\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3VAE\u5feb\u901f\u8bad\u7ec3VQ - VAE\uff0c\u51cf\u5c11\u8bad\u7ec3\u6210\u672c\uff0c\u5b9e\u73b0\u9ad8\u6548\u91cd\u5efa\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u8bad\u7ec3\u9ad8\u538b\u7f29\u7387VQ - VAEs\u8ba1\u7b97\u9700\u6c42\u5927\u3001\u8017\u65f6\u4e45\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faQuantize - then - Rectify (ReVQ)\u6846\u67b6\uff0c\u96c6\u6210\u901a\u9053\u591a\u7ec4\u91cf\u5316\u548c\u540e\u7f6e\u6821\u6b63\u5668\u3002", "result": "\u5c06ImageNet\u56fe\u50cf\u538b\u7f29\u81f3\u6700\u591a512\u4e2a\u4ee4\u724c\uff0c\u91cd\u5efa\u8d28\u91cf\u6709\u7ade\u4e89\u529b\uff08rFID = 1.06\uff09\uff0c\u8bad\u7ec3\u6210\u672c\u964d\u4f4e\u8d85\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u5355\u5f20NVIDIA 4090\u7ea622\u5c0f\u65f6\u5b8c\u6210\u8bad\u7ec3\u3002", "conclusion": "ReVQ\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6548\u7387 - \u91cd\u5efa\u6743\u8861\u3002"}}
