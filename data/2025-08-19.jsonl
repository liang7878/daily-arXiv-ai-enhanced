{"id": "2508.11967", "pdf": "https://arxiv.org/pdf/2508.11967", "abs": "https://arxiv.org/abs/2508.11967", "authors": ["Maksym Szemer", "Szymon Buchaniec", "Grzegorz Brus"], "title": "Persistence is All You Need -- A Topological Lens on Microstructural Characterization", "categories": ["cs.CE", "cond-mat.mtrl-sci"], "comment": null, "summary": "The microstructure critically governs the properties of materials used in\nenergy and chemical engineering technologies, from catalysts and filters to\nthermal insulators and sensors. Therefore, accurate design is based on\nquantitative descriptors of microstructural features. Here we show that eight\nkey descriptors can be extracted by a single workflow that fuses computational\ntopology with assembly-learning-based regression. First, 1312 synthetic\nthree-dimensional microstructures were generated and evaluated using\nestablished algorithms, and a labeled data set of ground-truth parameters was\nbuilt. Converting every structure into a persistence image allowed us to train\na deep neural network that predicts the eight descriptors. In an independent\ntest set, the model achieved on average R^2 ~ 0.84 and Pearson r ~ 0.92,\ndemonstrating both precision and generality. The approach provides a unified\nand scalable tool for rapid characterization of functional porous materials."}
{"id": "2508.12501", "pdf": "https://arxiv.org/pdf/2508.12501", "abs": "https://arxiv.org/abs/2508.12501", "authors": ["Luke Morris", "George Rauta", "Kevin Carlson", "James Fairbanks"], "title": "Porous Convection in the Discrete Exterior Calculus with Geometric Multigrid", "categories": ["cs.CE"], "comment": null, "summary": "The discrete exterior calculus (DEC) defines a family of discretized\ndifferential operators which preserve certain desirable properties from the\nexterior calculus. We formulate and solve the porous convection equations in\nthe DEC via the Decapodes.jl embedded domain-specific language (eDSL) for\nmultiphysics problems discretized via CombinatorialSpaces.jl.\nCombinatorialSpaces.jl is an open-source Julia library which implements the DEC\nover simplicial complexes, and now offers a geometric multigrid solver over\nmaps between subdivided simplicial complexes. We demonstrate numerical results\nof multigrid solvers for the Poisson problem and porous convection problem,\nboth as a standalone solver and as a preconditioner for open-source Julia\niterative methods libraries."}
{"id": "2508.12799", "pdf": "https://arxiv.org/pdf/2508.12799", "abs": "https://arxiv.org/abs/2508.12799", "authors": ["Toby Simpson", "Saara Jones", "Gracia Brückmann", "Walid El-Ajou", "Erwan Moreira", "Borja Martinez Oltra", "Rolf Krause", "Michael Multerer", "Isabelle Stadelmann"], "title": "Ensured Energy: A simulation game to elicit preferences around Swiss energy transition pathways", "categories": ["cs.CE"], "comment": "10 pages, 7 figures, submitted to IEEE Transactions on Games", "summary": "The 2015 Paris Agreement on global warming specifies national objectives for\nthe reduction of greenhouse gas emissions. In support of Switzerland's energy\nand climate strategy for 2050, researchers investigate scenarios for the\ntransition of energy systems towards a higher share of renewables, assessing\ntheir social, environmental and economic impact. Their results guide\nstakeholders and policy makers in designing resilient and sustainable systems.\nPolitical scientists use surveys to quantify public acceptance of energy\npolicy, but the complexity and long time horizon of the subject creates\ndifficulties, both for researchers in posing contextually relevant questions,\nand for respondents in assimilating enough information to give meaningful\nanswers. A population survey was therefore augmented with an online serious\ngame in which players experience an accurate simulation of current and future\nenergy provision and manage transition towards a sustainable future. This\ninteractive environment allows better informed and engaged decisions, and\nprovides richer information on public opinion. In this paper we motivate and\ndescribe the design of the game and report initial findings on player\ncharacteristics and engagement. We show that a serious game can successfully\nattract participants from diverse societal groups and highlight the challenge\nof balancing complexity and entertainment."}
{"id": "2508.11862", "pdf": "https://arxiv.org/pdf/2508.11862", "abs": "https://arxiv.org/abs/2508.11862", "authors": ["Jianfeng Huang", "Ziyao Wang", "Lin Yuan", "Jiajie Wen", "Yihao Cao", "Dongjing Miao", "Yong Wang", "Jiahao Zhang"], "title": "LSM-OPD: Boosting Scan in LSM-Trees by Enabling Direct Computing on Compressed Data", "categories": ["cs.DB"], "comment": null, "summary": "Scan-based operations, such as backstage compaction and value filtering, have\nemerged as the main bottleneck for LSM-Trees in supporting contemporary\ndata-intensive applications. For slower external storage devices, such as HDD\nand SATA SSD, the scan performance is primarily limited by the I/O bandwidth\n(i.e., I/O bound) due to the substantial read/write amplifications in\nLSM-Trees. Recent adoption of high-performance storage devices, such as NVMe\nSSD, has transformed the main limitation to be compute-bound, emerging the\nimpact of computational resource consumption caused by inefficient compactions\nand filtering. However, when the value size increases, the bottleneck for scan\nperformance in fast devices gradually shifts towards the I/O bandwidth as well,\nand the overall throughput across all types of devices undergo a dramatic\nreduction. This paper addresses the core issues by proposing LSM-OPD, a Log-S\ntructured M erge-O rder- Preserving Dictionary encoding scheme that enables\ndirect computing on compressed data within LSM-Trees. It first enables\nkey-value-separated data flushing to disk in a densely encoded columnar layout,\nideally with few bytes for a large string value (e.g., 1024 bytes), thereby\nsignificantly alleviating the frequent I/O requests caused by intensive scans.\nThen, it is capable of offloading the costly scan-based operations on large\nvalues, including compaction and value filtering, to lightweight dictionaries\ndue to the order-preserving property. And SIMD-based vectorization can now be\nemployed to maximize the evaluating performance on modern multi-core\nprocessors, further breaking the compute-bound limitations in LSM-trees.\nExtensive experiments demonstrate the superior efficiency of LSM-OPD in\nprocessing various workloads that involve intensive scan-based operations on\ndiverse modern storage devices."}
{"id": "2508.13097", "pdf": "https://arxiv.org/pdf/2508.13097", "abs": "https://arxiv.org/abs/2508.13097", "authors": ["Sara Karimi", "Nikolaos N. Vlassis"], "title": "Denoising diffusion models for inverse design of inflatable structures with programmable deformations", "categories": ["cs.CE", "cs.LG"], "comment": "21 pages, 12 figures", "summary": "Programmable structures are systems whose undeformed geometries and material\nproperty distributions are deliberately designed to achieve prescribed deformed\nconfigurations under specific loading conditions. Inflatable structures are a\nprominent example, using internal pressurization to realize large, nonlinear\ndeformations in applications ranging from soft robotics and deployable\naerospace systems to biomedical devices and adaptive architecture. We present a\ngenerative design framework based on denoising diffusion probabilistic models\n(DDPMs) for the inverse design of elastic structures undergoing large,\nnonlinear deformations under pressure-driven actuation. The method formulates\nthe inverse design as a conditional generation task, using geometric\ndescriptors of target deformed states as inputs and outputting image-based\nrepresentations of the undeformed configuration. Representing these\nconfigurations as simple images is achieved by establishing a pre- and\npostprocessing pipeline that involves a fixed image processing, simulation\nsetup, and descriptor extraction methods. Numerical experiments with scalar and\nhigher-dimensional descriptors show that the framework can quickly produce\ndiverse undeformed configurations that achieve the desired deformations when\ninflated, enabling parallel exploration of viable design candidates while\naccommodating complex constraints."}
{"id": "2508.12173", "pdf": "https://arxiv.org/pdf/2508.12173", "abs": "https://arxiv.org/abs/2508.12173", "authors": ["Suyash Gupta", "Dakai Kang", "Dahlia Malkhi", "Mohammad Sadoghi"], "title": "Carry the Tail in Consensus Protocols", "categories": ["cs.DB"], "comment": "18 pages, 3 figures", "summary": "We present Carry-the-Tail, the first deterministic atomic broadcast protocol\nin partial synchrony that, after GST, guarantees a constant fraction of commits\nby non-faulty leaders against tail-forking attacks, and maintains optimal,\nworst-case quadratic communication under a cascade of faulty leaders. The\nsolution also guarantees linear amortized communication, i.e., the steady-state\nis linear.\n  Prior atomic broadcast solutions achieve quadratic word communication\ncomplexity in the worst case. However, they face a significant degradation in\nthroughput under tail-forking attack. Existing solutions to tail-forking\nattacks require either quadratic communication steps or\ncomputationally-prohibitive SNARK generation.\n  The key technical contribution is Carry, a practical drop-in mechanism for\nstreamlined protocols in the HotStuff family. Carry guarantees good performance\nagainst tail-forking and removes most leader-induced stalls, while retaining\nlinear traffic and protocol simplicity."}
{"id": "2508.12308", "pdf": "https://arxiv.org/pdf/2508.12308", "abs": "https://arxiv.org/abs/2508.12308", "authors": ["Clément Aubert", "Cinzia Di Giusto", "Simon Fowler", "Violet Ka I Pun"], "title": "Proceedings 18th Interaction and Concurrency Experience", "categories": ["cs.DC", "cs.LO"], "comment": null, "summary": "This volume contains the proceedings of ICE'25, the 18th Interaction and\nConcurrency Experience, which was held on Friday 20th June 2025 at the \\'Ecole\nNational Sup\\'erieure des Arts et M\\'etiers in Lille, France, as a satellite\nworkshop of DisCoTec 2025. The ICE workshop series features a distinguishing\nreview and selection procedure: PC members are encouraged to interact,\nanonymously, with authors. The 2025 edition of ICE received 7 submissions, each\nreviewed by three PC members, and about 75 comments were exchanged during the\nreview process, witnessing very lively discussions. Four papers were accepted\nfor publication plus 1 oral communication, which was accepted for presentation\nat the workshop. We were proud to host one invited talk, by Kirstin Peters. The\nabstract of her talk is included in this volume, together with the final\nversions of the research papers, which take into account the discussion at the\nworkshop and during the review process."}
{"id": "2508.12004", "pdf": "https://arxiv.org/pdf/2508.12004", "abs": "https://arxiv.org/abs/2508.12004", "authors": ["Juhi Chaudhary", "Ignasi Sau", "Meirav Zehavi"], "title": "A Parameterized Perspective on Uniquely Restricted Matchings", "categories": ["cs.DS", "cs.DM"], "comment": "Conference version in LAGOS 2025", "summary": "Given a graph G, a matching is a subset of edges of G that do not share an\nendpoint. A matching M is uniquely restricted if the subgraph induced by the\nendpoints of the edges of M has exactly one perfect matching. Given a graph G\nand a positive integer \\ell, Uniquely Restricted Matching asks whether G has a\nuniquely restricted matching of size at least \\ell. In this paper, we study the\nparameterized complexity of Uniquely Restricted Matching under various\nparameters. Specifically, we show that Uniquely Restricted Matching admits a\nfixed-parameter tractable (FPT) algorithm on line graphs when parameterized by\nthe solution size. We also establish that the problem is FPT when parameterized\nby the treewidth of the input graph. Furthermore, we show that Uniquely\nRestricted Matching does not admit a polynomial kernel with respect to the\nvertex cover number plus the size of the matching unless NP \\subseteq\ncoNP/poly."}
{"id": "2508.11874", "pdf": "https://arxiv.org/pdf/2508.11874", "abs": "https://arxiv.org/abs/2508.11874", "authors": ["Hanyu Li", "Dongchen Li", "Xiaotie Deng"], "title": "Discovering Expert-Level Nash Equilibrium Algorithms with Large Language Models", "categories": ["cs.GT", "cs.AI", "cs.DS", "cs.LO", "cs.PL"], "comment": null, "summary": "Algorithm design and analysis is a cornerstone of computer science, but it\nconfronts a major challenge. Proving an algorithm's performance guarantee\nacross all inputs has traditionally required extensive and often error-prone\nhuman effort. While AI has shown great success in finding solutions to specific\nproblem instances, automating the discovery of general algorithms with such\nprovable guarantees has remained a significant barrier. This challenge stems\nfrom the difficulty of integrating the creative process of algorithm design\nwith the rigorous process of formal analysis. To address this gap, we propose\nLegoNE, a framework that tightly fuses these two processes for the fundamental\nand notoriously difficult problem of computing approximate Nash equilibria.\nLegoNE automatically translates any algorithm written by a simple Python-like\nlanguage into a constrained optimization problem. Solving this problem derives\nand proves the algorithm's approximation bound. Using LegoNE, a\nstate-of-the-art large language model rediscovered the state-of-the-art\nalgorithm for two-player games within hours, a feat that had taken human\nresearchers 15 years to achieve. For three-player games, the model discovered a\nnovel algorithm surpassing all existing human-designed ones. This work\ndemonstrates a new human-machine collaborative paradigm for theoretical\nscience: humans reason at a higher-abstract level, using symbols to compress\nthe search space, and AI explores within it, achieving what neither could\nalone."}
{"id": "2508.11670", "pdf": "https://arxiv.org/pdf/2508.11670", "abs": "https://arxiv.org/abs/2508.11670", "authors": ["Bongsu Kim"], "title": "RRRA: Resampling and Reranking through a Retriever Adapter", "categories": ["cs.IR", "cs.AI"], "comment": "8 pages, 4 figures, submitted to AAAI 2026", "summary": "In dense retrieval, effective training hinges on selecting high quality hard\nnegatives while avoiding false negatives. Recent methods apply heuristics based\non positive document scores to identify hard negatives, improving both\nperformance and interpretability. However, these global, example agnostic\nstrategies often miss instance specific false negatives. To address this, we\npropose a learnable adapter module that monitors Bi-Encoder representations to\nestimate the likelihood that a hard negative is actually a false negative. This\nprobability is modeled dynamically and contextually, enabling fine-grained,\nquery specific judgments. The predicted scores are used in two downstream\ncomponents: (1) resampling, where negatives are reweighted during training, and\n(2) reranking, where top-k retrieved documents are reordered at inference.\nEmpirical results on standard benchmarks show that our adapter-enhanced\nframework consistently outperforms strong Bi-Encoder baselines, underscoring\nthe benefit of explicit false negative modeling in dense retrieval."}
{"id": "2508.11824", "pdf": "https://arxiv.org/pdf/2508.11824", "abs": "https://arxiv.org/abs/2508.11824", "authors": ["Satyam Kumar Navneet", "Joydeep Chandra"], "title": "Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.PF"], "comment": null, "summary": "The integration of Large Language Models (LLMs) into software engineering has\nrevolutionized code generation, enabling unprecedented productivity through\npromptware and autonomous AI agents. However, this transformation introduces\nsignificant risks, including insecure code generation, hallucinated outputs,\nirreversible actions, and a lack of transparency and accountability. Incidents\nlike the Replit database deletion underscore the urgent need for robust safety\nand governance mechanisms. This paper comprehensively analyzes the inherent\nchallenges of LLM-assisted code generation, such as vulnerability inheritance,\novertrust, misinterpretation, and the absence of standardized validation and\nrollback protocols. To address these, we propose the SAFE-AI Framework, a\nholistic approach emphasizing Safety, Auditability, Feedback, and\nExplainability. The framework integrates guardrails, sandboxing, runtime\nverification, risk-aware logging, human-in-the-loop systems, and explainable AI\ntechniques to mitigate risks while fostering trust and compliance. We introduce\na novel taxonomy of AI behaviors categorizing suggestive, generative,\nautonomous, and destructive actions to guide risk assessment and oversight.\nAdditionally, we identify open problems, including the lack of standardized\nbenchmarks for code specific hallucinations and autonomy levels, and propose\nfuture research directions for hybrid verification, semantic guardrails, and\nproactive governance tools. Through detailed comparisons of autonomy control,\nprompt engineering, explainability, and governance frameworks, this paper\nprovides a roadmap for responsible AI integration in software engineering,\naligning with emerging regulations like the EU AI Act and Canada's AIDA to\nensure safe, transparent, and accountable AI-driven development."}
{"id": "2508.11659", "pdf": "https://arxiv.org/pdf/2508.11659", "abs": "https://arxiv.org/abs/2508.11659", "authors": ["Zhuo Liu", "Tao Chen"], "title": "Toward Practical Equilibrium Propagation: Brain-inspired Recurrent Neural Network with Feedback Regulation and Residual Connections", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Brain-like intelligent systems need brain-like learning methods. Equilibrium\nPropagation (EP) is a biologically plausible learning framework with strong\npotential for brain-inspired computing hardware. However, existing\nim-plementations of EP suffer from instability and prohibi-tively high\ncomputational costs. Inspired by the structure and dynamics of the brain, we\npropose a biologically plau-sible Feedback-regulated REsidual recurrent neural\nnetwork (FRE-RNN) and study its learning performance in EP framework. Feedback\nregulation enables rapid convergence by reducing the spectral radius. The\nimprovement in con-vergence property reduces the computational cost and\ntrain-ing time of EP by orders of magnitude, delivering perfor-mance on par\nwith backpropagation (BP) in benchmark tasks. Meanwhile, residual connections\nwith brain-inspired topologies help alleviate the vanishing gradient problem\nthat arises when feedback pathways are weak in deep RNNs. Our approach\nsubstantially enhances the applicabil-ity and practicality of EP in large-scale\nnetworks that un-derpin artificial intelligence. The techniques developed here\nalso offer guidance to implementing in-situ learning in physical neural\nnetworks."}
{"id": "2508.11836", "pdf": "https://arxiv.org/pdf/2508.11836", "abs": "https://arxiv.org/abs/2508.11836", "authors": ["Dave Goel", "Matthew Guzdial", "Anurag Sarkar"], "title": "Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video", "categories": ["cs.AI"], "comment": null, "summary": "World models are defined as a compressed spatial and temporal learned\nrepresentation of an environment. The learned representation is typically a\nneural network, making transfer of the learned environment dynamics and\nexplainability a challenge. In this paper, we propose an approach, Finite\nAutomata Extraction (FAE), that learns a neuro-symbolic world model from\ngameplay video represented as programs in a novel domain-specific language\n(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more\nprecise model of the environment and more general code than prior DSL-based\napproaches."}
{"id": "2508.11715", "pdf": "https://arxiv.org/pdf/2508.11715", "abs": "https://arxiv.org/abs/2508.11715", "authors": ["Ananya Singha", "Harshita Sahijwani", "Walt Williams", "Emmanuel Aboah Boateng", "Nick Hausman", "Miguel Di Luca", "Keegan Choudhury", "Chaya Binet", "Vu Le", "Tianwei Chen", "Oryan Rokeah Chen", "Sulaiman Vesal", "Sadid Hasan"], "title": "Benchmark Dataset Generation and Evaluation for Excel Formula Repair with LLMs", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at the KDD workshop on Evaluation and Trustworthiness of\n  Agentic and Generative AI Models", "summary": "Excel is a pervasive yet often complex tool, particularly for novice users,\nwhere runtime errors arising from logical mistakes or misinterpretations of\nfunctions pose a significant challenge. While large language models (LLMs)\noffer promising assistance by explaining formula errors, the automated\ncorrection of these semantic runtime errors remains an open problem. A primary\nchallenge to advancing models for such scenarios is the severe lack of\nhigh-quality, comprehensive datasets for training and rigorous evaluation. This\npaper addresses this gap by introducing a novel approach for constructing a\nbenchmark dataset specifically designed for Excel formula repair. We propose a\ndata generation pipeline, which leverages a small set of curated seed samples\nfrom online forums to synthetically expand the dataset. Our pipeline integrates\nfew-shot prompting with LLMs and employs a robust \\textit{LLM-as-a-Judge}\nvalidation framework, combined with execution-based checks to ensure the\ncorrectness and semantic fidelity of the generated data. This process produced\na benchmark dataset of 618 high-quality samples, covering common runtime\nerrors. Furthermore, we propose a context-aware baseline technique for Excel\nformula repair that utilizes LLMs to leverage both the faulty formula, and\nrelevant spreadsheet context. We evaluate the performance of various LLMs\n(GPT-4o, GPT-4.1, Phi-3, Mistral) on our newly generated benchmark using\nexecution-based metrics. Our analysis demonstrates the dataset's quality\nthrough manual annotation and provides insights into error and function\ndistributions. The proposed generation methodology is highly scalable and can\nbe readily adapted to create evaluation benchmarks for similar code repair\ntasks in other low-resource programming languages."}
{"id": "2508.11856", "pdf": "https://arxiv.org/pdf/2508.11856", "abs": "https://arxiv.org/abs/2508.11856", "authors": ["Shaofeng Kang", "Zeying Tian"], "title": "Optimal Portfolio Construction -- A Reinforcement Learning Embedded Bayesian Hierarchical Risk Parity (RL-BHRP) Approach", "categories": ["q-fin.PM"], "comment": null, "summary": "We propose a two-level, learning-based portfolio method (RL-BHRP) that\nspreads risk across sectors and stocks, and adjusts exposures as market\nconditions change. Using U.S. Equities from 2012 to mid-2025, we design the\nmodel using 2012 to 2019 data, and evaluate it out-of-sample from 2020 to 2025\nagainst a sector index built from exchange-traded funds and a static\nrisk-balanced portfolio. Over the test window, the adaptive portfolio compounds\nwealth by approximately 120 percent, compared with 101 percent for the static\ncomparator and 91 percent for the sector benchmark. The average annual growth\nis roughly 15 percent, compared to 13 percent and 12 percent, respectively.\nGains are achieved without significant deviations from the benchmark and with\npeak-to-trough losses comparable to those of the alternatives, indicating that\nthe method adds value while remaining diversified and investable. Weight charts\nshow gradual shifts rather than abrupt swings, reflecting disciplined\nrebalancing and the cost-aware design. Overall, the results support\nrisk-balanced, adaptive allocation as a practical approach to achieving\nstronger and more stable long-term performance."}
{"id": "2508.11651", "pdf": "https://arxiv.org/pdf/2508.11651", "abs": "https://arxiv.org/abs/2508.11651", "authors": ["Rischan Mafrur"], "title": "Tokenize Everything, But Can You Sell It? RWA Liquidity Challenges and the Road Ahead", "categories": ["q-fin.GN", "cs.CR", "q-fin.CP"], "comment": null, "summary": "The tokenization of real-world assets (RWAs) promises to transform financial\nmarkets by enabling fractional ownership, global accessibility, and\nprogrammable settlement of traditionally illiquid assets such as real estate,\nprivate credit, and government bonds. While technical progress has been rapid,\nwith over \\$25 billion in tokenized RWAs brought on-chain as of 2025, liquidity\nremains a critical bottleneck. This paper investigates the gap between\ntokenization and tradability, drawing on recent academic research and market\ndata from platforms such as RWA.xyz. We document that most RWA tokens exhibit\nlow trading volumes, long holding periods, and limited investor participation,\ndespite their potential for 24/7 global markets. Through case studies of\ntokenized real estate, private credit, and tokenized treasury funds, we present\nempirical liquidity observations that reveal low transfer activity, limited\nactive address counts, and minimal secondary trading for most tokenized asset\nclasses. Next, we categorize the structural barriers to liquidity, including\nregulatory gating, custodial concentration, whitelisting, valuation opacity,\nand lack of decentralized trading venues. Finally, we propose actionable\npathways to improve liquidity, ranging from hybrid market structures and\ncollateral-based liquidity to transparency enhancements and compliance\ninnovation. Our findings contribute to the growing discourse on digital asset\nmarket microstructure and highlight that realizing the liquidity potential of\nRWAs requires coordinated progress across legal, technical, and institutional\ndomains."}
{"id": "2508.12007", "pdf": "https://arxiv.org/pdf/2508.12007", "abs": "https://arxiv.org/abs/2508.12007", "authors": ["Sabrina Aufiero", "Silvia Bartolucci", "Fabio Caccioli", "Pierpaolo Vivo"], "title": "Mapping Microscopic and Systemic Risks in TradFi and DeFi: a literature review", "categories": ["q-fin.RM", "econ.GN", "q-fin.EC", "q-fin.GN"], "comment": "61 pages, 3 figures", "summary": "This work explores the formation and propagation of systemic risks across\ntraditional finance (TradFi) and decentralized finance (DeFi), offering a\ncomparative framework that bridges these two increasingly interconnected\necosystems. We propose a conceptual model for systemic risk formation in\nTradFi, grounded in well-established mechanisms such as leverage cycles,\nliquidity crises, and interconnected institutional exposures. Extending this\nanalysis to DeFi, we identify unique structural and technological\ncharacteristics - such as composability, smart contract vulnerabilities, and\nalgorithm-driven mechanisms - that shape the emergence and transmission of\nrisks within decentralized systems. Through a conceptual mapping, we highlight\nrisks with similar foundations (e.g., trading vulnerabilities, liquidity\nshocks), while emphasizing how these risks manifest and propagate differently\ndue to the contrasting architectures of TradFi and DeFi. Furthermore, we\nintroduce the concept of crosstagion, a bidirectional process where instability\nin DeFi can spill over into TradFi, and vice versa. We illustrate how\ndisruptions such as liquidity crises, regulatory actions, or political\ndevelopments can cascade across these systems, leveraging their growing\ninterdependence. By analyzing this mutual dynamics, we highlight the importance\nof understanding systemic risks not only within TradFi and DeFi individually,\nbut also at their intersection. Our findings contribute to the evolving\ndiscourse on risk management in a hybrid financial ecosystem, offering insights\nfor policymakers, regulators, and financial stakeholders navigating this\ncomplex landscape."}
{"id": "2508.11730", "pdf": "https://arxiv.org/pdf/2508.11730", "abs": "https://arxiv.org/abs/2508.11730", "authors": ["Martin Chalkley", "Tim Colbourn", "Timothy B. Hallett", "Tara D. Mangal", "Margherita Molaro", "Sakshi Mohan", "Bingling She", "Paul Revill", "Wiktoria Tafese"], "title": "Incorporating an economic approach to production in a health system model", "categories": ["econ.GN", "q-fin.EC"], "comment": "14 pages, 5 figures", "summary": "As computational capacity increases, it becomes possible to model health\nsystems in greater detail. Multi-disease health system models (HSMs) represent\na new development, building on individual level epidemiological models of\nmultiple diseases and capturing how healthcare delivery systems respond to\npopulation health needs. The Thanzi la Onse (TLO) model of Malawi is the first\nof its kind in these respects. In this article, we discuss how we have been\nbringing economic concepts into the TLO model, and how we are continuing to\ndevelop this line of research. This has involved incorporating more\nsophisticated approaches to account for the effects of the unavailability of\nhealthcare workers, and we are working towards establishing the role of\ndifferent forms of ownership of healthcare facilities and different management\npractices. Not only does this broad approach make the model more flexible as a\ntool for understanding the impact of resource constraints, it opens up the\npossibility of analysing considerably richer policy scenarios; for example\nestablishing an estimate of the health gain that could be achieved through\nexpanding the workforce or reducing healthcare worker absence."}
{"id": "2508.11730", "pdf": "https://arxiv.org/pdf/2508.11730", "abs": "https://arxiv.org/abs/2508.11730", "authors": ["Martin Chalkley", "Tim Colbourn", "Timothy B. Hallett", "Tara D. Mangal", "Margherita Molaro", "Sakshi Mohan", "Bingling She", "Paul Revill", "Wiktoria Tafese"], "title": "Incorporating an economic approach to production in a health system model", "categories": ["econ.GN", "q-fin.EC"], "comment": "14 pages, 5 figures", "summary": "As computational capacity increases, it becomes possible to model health\nsystems in greater detail. Multi-disease health system models (HSMs) represent\na new development, building on individual level epidemiological models of\nmultiple diseases and capturing how healthcare delivery systems respond to\npopulation health needs. The Thanzi la Onse (TLO) model of Malawi is the first\nof its kind in these respects. In this article, we discuss how we have been\nbringing economic concepts into the TLO model, and how we are continuing to\ndevelop this line of research. This has involved incorporating more\nsophisticated approaches to account for the effects of the unavailability of\nhealthcare workers, and we are working towards establishing the role of\ndifferent forms of ownership of healthcare facilities and different management\npractices. Not only does this broad approach make the model more flexible as a\ntool for understanding the impact of resource constraints, it opens up the\npossibility of analysing considerably richer policy scenarios; for example\nestablishing an estimate of the health gain that could be achieved through\nexpanding the workforce or reducing healthcare worker absence."}
{"id": "2508.11661", "pdf": "https://arxiv.org/pdf/2508.11661", "abs": "https://arxiv.org/abs/2508.11661", "authors": ["Ziyi Cao", "Qingyi Si", "Jingbin Zhang", "Bingquan Liu"], "title": "Sparse Attention across Multiple-context KV Cache", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models face significant cost challenges in long-sequence\ninference. To address this, reusing historical Key-Value (KV) Cache for\nimproved inference efficiency has become a mainstream approach. Recent advances\nfurther enhance throughput by sparse attention mechanisms to select the most\nrelevant KV Cache, thereby reducing sequence length. However, such techniques\nare limited to single-context scenarios, where historical KV Cache is computed\nsequentially with causal-attention dependencies. In retrieval-augmented\ngeneration (RAG) scenarios, where retrieved documents as context are unknown\nbeforehand, each document's KV Cache is computed and stored independently\n(termed multiple-context KV Cache), lacking cross-attention between contexts.\nThis renders existing methods ineffective. Although prior work partially\nrecomputes multiple-context KV Cache to mitigate accuracy loss from missing\ncross-attention, it requires retaining all KV Cache throughout, failing to\nreduce memory overhead. This paper presents SamKV, the first exploration of\nattention sparsification for multiple-context KV Cache. Specifically, SamKV\ntakes into account the complementary information of other contexts when\nsparsifying one context, and then locally recomputes the sparsified\ninformation. Experiments demonstrate that our method compresses sequence length\nto 15% without accuracy degradation compared with full-recompuation baselines,\nsignificantly boosting throughput in multi-context RAG scenarios."}
{"id": "2508.11649", "pdf": "https://arxiv.org/pdf/2508.11649", "abs": "https://arxiv.org/abs/2508.11649", "authors": ["Sergio Bianchi", "Daniele Angelini", "Massimiliano Frezza", "Augusto Pianese"], "title": "From fair price to fair volatility: Towards an Efficiency-Consistent Definition of Financial Risk", "categories": ["q-fin.GN", "q-fin.ST"], "comment": "31 pages, 6 figures", "summary": "Volatility, as a primary indicator of financial risk, forms the foundation of\nclassical frameworks such as Markowitz's Portfolio Theory and the Efficient\nMarket Hypothesis (EMH). However, its conventional use rests on\nassumptions-most notably, the Markovian nature of price dynamics-that often\nfail to reflect key empirical characteristics of financial markets. Fractional\nstochastic volatility models expose these limitations by demonstrating that\nvolatility alone is insufficient to capture the full structure of return\ndispersion. In this context, we propose pointwise regularity, measured via the\nHurst-Holder exponent, as a complementary metric of financial risk. This\nmeasure quantifies local deviations from martingale behavior, enabling a more\nnuanced assessment of market inefficiencies and the mechanisms by which\nequilibrium is restored. By accounting not only for the magnitude but also for\nthe nature of randomness, this framework bridges the conceptual divide between\nefficient market theory and behavioral finance."}
{"id": "2508.11741", "pdf": "https://arxiv.org/pdf/2508.11741", "abs": "https://arxiv.org/abs/2508.11741", "authors": ["Habibolla Latifizadeh", "Anika C. Pirkey", "Alanna Gould", "David J. Klinke II"], "title": "BaMANI: Bayesian Multi-Algorithm causal Network Inference", "categories": ["stat.ML", "cs.LG", "q-bio.QM"], "comment": "12 pages, 6 figures", "summary": "Improved computational power has enabled different disciplines to predict\ncausal relationships among modeled variables using Bayesian network inference.\nWhile many alternative algorithms have been proposed to improve the efficiency\nand reliability of network prediction, the predicted causal networks reflect\nthe generative process but also bear an opaque imprint of the specific\ncomputational algorithm used. Following a ``wisdom of the crowds\" strategy, we\ndeveloped an ensemble learning approach to marginalize the impact of a single\nalgorithm on Bayesian causal network inference. To introduce the approach, we\nfirst present the theoretical foundation of this framework. Next, we present a\ncomprehensive implementation of the framework in terms of a new software tool\ncalled BaMANI (Bayesian Multi-Algorithm causal Network Inference). Finally, we\ndescribe a BaMANI use-case from biology, particularly within human breast\ncancer studies."}
{"id": "2508.11982", "pdf": "https://arxiv.org/pdf/2508.11982", "abs": "https://arxiv.org/abs/2508.11982", "authors": ["Luis Gruber", "Gregor Kastner", "Anirban Bhattacharya", "Debdeep Pati", "Natesh Pillai", "David Dunson"], "title": "A note on simulation methods for the Dirichlet-Laplace prior", "categories": ["stat.CO", "econ.EM", "stat.ME", "stat.ML"], "comment": "Correction: Bhattacharya, A., Pati, D., Pillai, N.S., and Dunson,\n  D.B. (2015), \"Dirichlet-Laplace Priors for Optimal Shrinkage,\" Journal of the\n  American Statistical Association, 110, 1479-1490, DOI:\n  10.1080/01621459.2014.960967", "summary": "Bhattacharya et al. (2015, Journal of the American Statistical Association\n110(512): 1479-1490) introduce a novel prior, the Dirichlet-Laplace (DL) prior,\nand propose a Markov chain Monte Carlo (MCMC) method to simulate posterior\ndraws under this prior in a conditionally Gaussian setting. The original\nalgorithm samples from conditional distributions in the wrong order, i.e., it\ndoes not correctly sample from the joint posterior distribution of all latent\nvariables. This note details the issue and provides two simple solutions: A\ncorrection to the original algorithm and a new algorithm based on an\nalternative, yet equivalent, formulation of the prior. This corrigendum does\nnot affect the theoretical results in Bhattacharya et al. (2015)."}
{"id": "2508.12029", "pdf": "https://arxiv.org/pdf/2508.12029", "abs": "https://arxiv.org/abs/2508.12029", "authors": ["Zhangyu You", "Jiahao Ma", "Hongzong Li", "Ye-Fan Hu", "Jian-Dong Huang"], "title": "BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.LG"], "comment": "16 pages, 7 figures, 5 tables, submitted to AAAI conference 2026", "summary": "Accurate prediction of antibody-binding sites (epitopes) on antigens is\ncrucial for vaccine design, immunodiagnostics, therapeutic antibody\ndevelopment, antibody engineering, research into autoimmune and allergic\ndiseases, and for advancing our understanding of immune responses. Despite in\nsilico methods that have been proposed to predict both linear (continuous) and\nconformational (discontinuous) epitopes, they consistently underperform in\npredicting conformational epitopes. In this work, we propose a conformer-based\nmodel trained on antigen sequences derived from 1,080 antigen-antibody\ncomplexes, leveraging convolutional neural networks (CNNs) to extract local\nfeatures and Transformers to capture long-range dependencies within antigen\nsequences. Ablation studies demonstrate that CNN enhances the prediction of\nlinear epitopes, and the Transformer module improves the prediction of\nconformational epitopes. Experimental results show that our model outperforms\nexisting baselines in terms of PCC, ROC-AUC, PR-AUC, and F1 scores on\nconformational epitopes."}
{"id": "2508.12536", "pdf": "https://arxiv.org/pdf/2508.12536", "abs": "https://arxiv.org/abs/2508.12536", "authors": ["Yasuo Tabei"], "title": "jXBW: Fast Substructure Search in Large-Scale JSONL Datasets for Foundation Model Applications", "categories": ["cs.DB", "cs.DS", "cs.IR"], "comment": null, "summary": "Substructure search in JSON Lines (JSONL) datasets is essential for modern\napplications such as prompt engineering in foundation models, but existing\nmethods suffer from prohibitive computational costs due to exhaustive tree\ntraversal and subtree matching. We present jXBW, a fast method for substructure\nsearch on large-scale JSONL datasets. Our method makes three key technical\ncontributions: (i) a merged tree representation built by merging trees of\nmultiple JSON objects while preserving individual identities, (ii) a succinct\ndata structure based on the eXtended Burrows-Wheeler Transform that enables\nefficient tree navigation and subpath search, and (iii) an efficient three-step\nsubstructure search algorithm that combines path decomposition, ancestor\ncomputation, and adaptive tree identifier collection to ensure correctness\nwhile avoiding exhaustive tree traversal. Experimental evaluation on real-world\ndatasets demonstrates that jXBW consistently outperforms existing methods,\nachieving speedups of 16$\\times$ for smaller datasets and up to 4,700$\\times$\nfor larger datasets over tree-based approaches, and more than 6$\\times$10$^6$\nover XML-based processing while maintaining competitive memory usage."}
{"id": "2508.12386", "pdf": "https://arxiv.org/pdf/2508.12386", "abs": "https://arxiv.org/abs/2508.12386", "authors": ["Jundong Chen", "Honglei Zhang", "Chunxu Zhang", "Fangyuan Luo", "Yidong Li"], "title": "Breaking the Aggregation Bottleneck in Federated Recommendation: A Personalized Model Merging Approach", "categories": ["cs.DC"], "comment": null, "summary": "Federated recommendation (FR) facilitates collaborative training by\naggregating local models from massive devices, enabling client-specific\npersonalization while ensuring privacy. However, we empirically and\ntheoretically demonstrate that server-side aggregation can undermine\nclient-side personalization, leading to suboptimal performance, which we term\nthe aggregation bottleneck. This issue stems from the inherent heterogeneity\nacross numerous clients in FR, which drives the globally aggregated model to\ndeviate from local optima. To this end, we propose FedEM, which elastically\nmerges the global and local models to compensate for impaired personalization.\nUnlike existing personalized federated recommendation (pFR) methods, FedEM (1)\ninvestigates the aggregation bottleneck in FR through theoretical insights,\nrather than relying on heuristic analysis; (2) leverages off-the-shelf local\nmodels rather than designing additional mechanisms to boost personalization.\nExtensive experiments on real-world datasets demonstrate that our method\npreserves client personalization during collaborative training, outperforming\nstate-of-the-art baselines."}
{"id": "2508.12527", "pdf": "https://arxiv.org/pdf/2508.12527", "abs": "https://arxiv.org/abs/2508.12527", "authors": ["Dimitris Fotakis", "Andreas Kalavas", "Charalampos Platanos", "Thanos Tolias"], "title": "A Polylogarithmic Algorithm for Stochastic Online Sorting", "categories": ["cs.DS"], "comment": null, "summary": "In the \\emph{Online Sorting Problem}, an array of $n$ initially empty cells\nis given. At each time step $t$, a real number $x_t \\in [0,1]$ arrives and must\nbe placed immediately and irrevocably into an empty cell. The objective is to\nminimize the sum of absolute differences between consecutive entries. The\nproblem was introduced by Aamand, Abrahamsen, Beretta, and Kleist (SODA 2023)\nas a technical tool for proving lower bounds in online geometric packing\nproblems. In follow-up work, Abrahamsen, Bercea, Beretta, Klausen, and Kozma\n(ESA 2024) studied the \\emph{Stochastic Online Sorting Problem}, where each\n$x_t$ is drawn i.i.d.\\ from $\\mathcal{U}(0,1)$, and presented a\n$\\widetilde{O}(n^{1/4})$-competitive algorithm, showing that stochastic input\nenables much stronger guarantees than in the adversarial setting. They also\nintroduced the \\emph{Online Travelling Salesperson Problem (TSP)} as a\nmultidimensional generalization. More recently, Hu, independently and in\nparallel, obtained a $\\log n \\cdot 2^{O(\\log^* n)}$-competitive algorithm\ntogether with a logarithmic lower bound for the \\emph{Stochastic Online Sorting\nProblem}.\n  We give an $O(\\log^{2} n)$-competitive algorithm for the \\emph{Stochastic\nOnline Sorting Problem} that succeeds w.h.p., achieving an exponential\nimprovement over the $\\widetilde{O}(n^{1/4})$ bound of Abrahamsen et al.(ESA\n2024). Our approach further extends to the \\emph{Stochastic Online TSP} in\nfixed dimension $d$, where it achieves an $O(\\log^2 n)$-competitive ratio."}
{"id": "2508.12453", "pdf": "https://arxiv.org/pdf/2508.12453", "abs": "https://arxiv.org/abs/2508.12453", "authors": ["Martin Jupakkal Andersen", "Ioannis Caragiannis", "Anders Bo Ipsen", "Alexander Søltoft"], "title": "Computing Approximately Proportional Allocations of Indivisible Goods: Beyond Additive and Monotone Valuations", "categories": ["cs.GT", "cs.DS"], "comment": null, "summary": "Although approximate notions of envy-freeness-such as envy-freeness up to one\ngood (EF1)-have been extensively studied for indivisible goods, the seemingly\nsimpler fairness concept of proportionality up to one good (PROP1) has received\nfar less attention. For additive valuations, every EF1 allocation is PROP1, and\nwell-known algorithms such as Round-Robin and Envy-Cycle Elimination compute\nsuch allocations in polynomial time. PROP1 is also compatible with Pareto\nefficiency, as maximum Nash welfare allocations are EF1 and hence PROP1.\n  We ask whether these favorable properties extend to non-additive valuations.\nWe study a broad class of allocation instances with {\\em satiating goods},\nwhere agents have non-negative valuation functions that need not be monotone,\nallowing for negative marginal values. We present the following results:\n  - EF1 implies PROP1 for submodular valuations over satiating goods, ensuring\nexistence and efficient computation via Envy-Cycle Elimination for monotone\nsubmodular valuations;\n  - Round-robin computes a partial PROP1 allocation after the second-to-last\nround for satiating submodular goods and a complete PROP1 for monotone\nsubmodular valuations;\n  - PROP1 allocations for satiating subadditive goods can be computed in\npolynomial-time;\n  - Maximum Nash welfare allocations are PROP1 for monotone submodular goods,\nrevealing yet another facet of their ``unreasonable fairness.''"}
{"id": "2508.11671", "pdf": "https://arxiv.org/pdf/2508.11671", "abs": "https://arxiv.org/abs/2508.11671", "authors": ["Ronald Carvalho Boadana", "Ademir Guimarães da Costa Junior", "Ricardo Rios", "Fábio Santos da Silva"], "title": "LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.MA"], "comment": "12 pages, in Portuguese language, 2 figures, 5 tables, 3 formulas. To\n  be published in the Proceedings of the Encontro Nacional de Intelig\\^encia\n  Artificial e Computacional (ENIAC 2025)", "summary": "The growing availability of music on streaming platforms has led to\ninformation overload for users. To address this issue and enhance the user\nexperience, increasingly sophisticated recommendation systems have been\nproposed. This work investigates the use of Large Language Models (LLMs) from\nthe Gemini and LLaMA families, combined with intelligent agents, in a\nmulti-agent personalized music recommendation system. The results are compared\nwith a traditional content-based recommendation model, considering user\nsatisfaction, novelty, and computational efficiency. LLMs achieved satisfaction\nrates of up to \\textit{89{,}32\\%}, indicating their promising potential in\nmusic recommendation systems."}
{"id": "2508.12743", "pdf": "https://arxiv.org/pdf/2508.12743", "abs": "https://arxiv.org/abs/2508.12743", "authors": ["Jacob Wahlgren", "Gabin Schieffer", "Ruimin Shi", "Edgar A. León", "Roger Pearce", "Maya Gokhale", "Ivy Peng"], "title": "Dissecting CPU-GPU Unified Physical Memory on AMD MI300A APUs", "categories": ["cs.DC", "cs.PF"], "comment": "To be published in IISWC 2025", "summary": "Discrete GPUs are a cornerstone of HPC and data center systems, requiring\nmanagement of separate CPU and GPU memory spaces. Unified Virtual Memory (UVM)\nhas been proposed to ease the burden of memory management; however, at a high\ncost in performance. The recent introduction of AMD's MI300A Accelerated\nProcessing Units (APUs)--as deployed in the El Capitan supercomputer--enables\nHPC systems featuring integrated CPU and GPU with Unified Physical Memory (UPM)\nfor the first time. This work presents the first comprehensive characterization\nof the UPM architecture on MI300A. We first analyze the UPM system properties,\nincluding memory latency, bandwidth, and coherence overhead. We then assess the\nefficiency of the system software in memory allocation, page fault handling,\nTLB management, and Infinity Cache utilization. We propose a set of porting\nstrategies for transforming applications for the UPM architecture and evaluate\nsix applications on the MI300A APU. Our results show that applications on UPM\nusing the unified memory model can match or outperform those in the explicitly\nmanaged model--while reducing memory costs by up to 44%."}
{"id": "2508.11674", "pdf": "https://arxiv.org/pdf/2508.11674", "abs": "https://arxiv.org/abs/2508.11674", "authors": ["Zofia Rudnicka", "Janusz Szczepanski", "Agnieszka Pregowska"], "title": "Learning Internal Biological Neuron Parameters and Complexity-Based Encoding for Improved Spiking Neural Networks Performance", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": null, "summary": "This study introduces a novel approach by replacing the traditional\nperceptron neuron model with a biologically inspired probabilistic meta neuron,\nwhere the internal neuron parameters are jointly learned, leading to improved\nclassification accuracy of spiking neural networks (SNNs). To validate this\ninnovation, we implement and compare two SNN architectures: one based on\nstandard leaky integrate-and-fire (LIF) neurons and another utilizing the\nproposed probabilistic meta neuron model. As a second key contribution, we\npresent a new biologically inspired classification framework that uniquely\nintegrates SNNs with Lempel-Ziv complexity (LZC) a measure closely related to\nentropy rate. By combining the temporal precision and biological plausibility\nof SNNs with the capacity of LZC to capture structural regularity, the proposed\napproach enables efficient and interpretable classification of spatiotemporal\nneural data, an aspect not addressed in existing works. We consider learning\nalgorithms such as backpropagation, spike-timing-dependent plasticity (STDP),\nand the Tempotron learning rule. To explore neural dynamics, we use Poisson\nprocesses to model neuronal spike trains, a well-established method for\nsimulating the stochastic firing behavior of biological neurons. Our results\nreveal that depending on the training method, the classifier's efficiency can\nimprove by up to 11.00%, highlighting the advantage of learning additional\nneuron parameters beyond the traditional focus on weighted inputs alone."}
{"id": "2508.11850", "pdf": "https://arxiv.org/pdf/2508.11850", "abs": "https://arxiv.org/abs/2508.11850", "authors": ["Milad Yazdani", "Mahdi Mostajabdaveh", "Samin Aref", "Zirui Zhou"], "title": "EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Integer programming lies at the heart of crucial combinatorial optimization\ntasks but remains challenging due to its NP-hard nature. An effective approach\nfor practically solving integer programs is the manual design of acceleration\ncuts, i.e. inequalities that improve solver performance. However, this creative\nprocess demands deep expertise and is yet to be automated. Our proposed\nframework, EvoCut, automates the generation of acceleration cuts by combining\nlarge language models (LLMs) with an evolutionary search. EvoCut (i)\ninitializes a diverse population of candidate cuts via an LLM-based initializer\nagent; (ii) for each cut empirically evaluates both preservation of the optimal\nsolution and its ability to cut off fractional solutions across a verification\nset; and (iii) iteratively refines the population through evolutionary\ncrossover and mutation agents. We quantify each cut's utility by its relative\nreduction in the solver's optimality gap. Our comparisons against standard\ninteger programming practice show that EvoCut reduces optimality gap by 17-57%\nwithin a fixed time. It obtains the same solutions up to 4 times as fast, and\nobtains higher-quality solutions within the same time limit. Requiring no human\nexpert input, EvoCut reliably generates, improves, and empirically verifies\ncuts that generalize to unseen instances. The code is available at\nhttps://github.com/milad1378yz/EvoCut."}
{"id": "2508.11717", "pdf": "https://arxiv.org/pdf/2508.11717", "abs": "https://arxiv.org/abs/2508.11717", "authors": ["Dhruv Kolhatkar", "Soubhagya Akkena", "Edward F. Gehringer"], "title": "WIP: Leveraging LLMs for Enforcing Design Principles in Student Code: Analysis of Prompting Strategies and RAG", "categories": ["cs.SE"], "comment": "Accepted for presentation at the Frontiers in Education Conference,\n  Nashville, Tennessee, USA, 2-5 November 2025", "summary": "This work-in-progress research-to-practice paper explores the integration of\nLarge Language Models (LLMs) into the code-review process for open-source\nsoftware projects developed in computer science and software engineering\ncourses. The focus is on developing an automated feedback tool that evaluates\nstudent code for adherence to key object-oriented design principles, addressing\nthe need for more effective and scalable methods to teach software design best\npractices. The innovative practice involves leveraging LLMs and\nRetrieval-Augmented Generation (RAG) to create an automated feedback system\nthat assesses student code for principles like SOLID, DRY, and design patterns.\nIt analyzes the effectiveness of various prompting strategies and the RAG\nintegration. Preliminary findings show promising improvements in code quality.\nFuture work will aim to improve model accuracy and expand support for\nadditional design principles."}
{"id": "2508.12419", "pdf": "https://arxiv.org/pdf/2508.12419", "abs": "https://arxiv.org/abs/2508.12419", "authors": ["Fabien Le Floc'h"], "title": "Revisiting Stochastic Collocation with Exponential Splines for an Arbitrage-Free Interpolation of Option Prices", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.MF"], "comment": null, "summary": "We revisit the stochastic collocation method using the exponential of a\nquadratic spline. In particular, we look in details whether it is more\nappropriate to fix the ordinates and optimize the abscissae of an interpolating\nspline or to fix the abscissae and optimize the parameters of a B-spline\nrepresentation."}
{"id": "2508.12606", "pdf": "https://arxiv.org/pdf/2508.12606", "abs": "https://arxiv.org/abs/2508.12606", "authors": ["Hamza Hanbali", "Jan Dhaene", "Daniel Linders"], "title": "Dependence bounds for the difference of stop-loss payoffs on the difference of two random variables", "categories": ["q-fin.PR", "math.PR", "q-fin.RM"], "comment": null, "summary": "This paper considers the difference of stop-loss payoffs where the underlying\nis a difference of two random variables. The goal is to study whether the\ncomonotonic and countermonotonic modifications of those two random variables\ncan be used to construct upper and lower bounds for the expected payoff,\ndespite the fact that the payoff function is neither convex nor concave. The\nanswer to the central question of the paper requires studying the crossing\npoints of the cdf of the original difference with the cdfs of its comonotonic\nand countermonotonic transforms. The analysis is supplemented with a numerical\nstudy of longevity trend bonds, using different mortality models and population\ndata. The numerical study reveals that for these mortality-linked securities\nthe three pairs of cdfs generally have unique pairwise crossing points. Under\nsymmetric copulas, all crossing points can reasonably be approximated by the\ndifference of the marginal medians, but this approximation is not necessarily\nvalid for asymmetric copulas. Nevertheless, extreme dependence structures can\ngive rise to bounds if the layers of the bond are selected to hedge tail risk.\nFurther, the dependence uncertainty spread can be low if the layers are\nselected to hedge median risk, and, subject to a trade-off, to hedge tail risk\nas well."}
{"id": "2508.11796", "pdf": "https://arxiv.org/pdf/2508.11796", "abs": "https://arxiv.org/abs/2508.11796", "authors": ["Pablo de la Vega"], "title": "The European Union Deforestation Regulation: The Impact on Argentina", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We analyze the potential economic impacts in Argentina of the European Union\nDeforestation Regulation (EUDR), which as of January 2026 will prohibit the\nexport to the European Union of certain raw materials and related products if\nthey involve the use of deforested land. We estimate that the EUDR would cover\naround 6 billion US dollars in exported value, but only 2.84% is not compliant\nwith the EUDR, with soy and cattle being the most affected production chains.\nWe use a dynamic computable general equilibrium model to simulate the impact of\nthe EUDR on the Argentine economy. If the non-compliant production cannot enter\nthe EU market because of the EUDR, the results of the simulations suggest that\nthe potential macroeconomic impacts are limited: GDP would be reduced by an\naverage of 0.14% with respect to the baseline scenario. However, the potential\nenvironmental impact is greater. Deforested hectares would be reduced by 2.45%\nand GHG emissions by 0.19%. Notwithstanding, EUDR due diligence costs may still\nprevent compliant production from entering the EU market, so the total impacts\ncould be higher."}
{"id": "2508.11796", "pdf": "https://arxiv.org/pdf/2508.11796", "abs": "https://arxiv.org/abs/2508.11796", "authors": ["Pablo de la Vega"], "title": "The European Union Deforestation Regulation: The Impact on Argentina", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We analyze the potential economic impacts in Argentina of the European Union\nDeforestation Regulation (EUDR), which as of January 2026 will prohibit the\nexport to the European Union of certain raw materials and related products if\nthey involve the use of deforested land. We estimate that the EUDR would cover\naround 6 billion US dollars in exported value, but only 2.84% is not compliant\nwith the EUDR, with soy and cattle being the most affected production chains.\nWe use a dynamic computable general equilibrium model to simulate the impact of\nthe EUDR on the Argentine economy. If the non-compliant production cannot enter\nthe EU market because of the EUDR, the results of the simulations suggest that\nthe potential macroeconomic impacts are limited: GDP would be reduced by an\naverage of 0.14% with respect to the baseline scenario. However, the potential\nenvironmental impact is greater. Deforested hectares would be reduced by 2.45%\nand GHG emissions by 0.19%. Notwithstanding, EUDR due diligence costs may still\nprevent compliant production from entering the EU market, so the total impacts\ncould be higher."}
{"id": "2508.11667", "pdf": "https://arxiv.org/pdf/2508.11667", "abs": "https://arxiv.org/abs/2508.11667", "authors": ["Bryan E. Tuck", "Rakesh M. Verma"], "title": "Assessing Representation Stability for Transformer Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "19 pages, 19 figures, 8 tables. Code available at\n  https://github.com/ReDASers/representation-stability", "summary": "Adversarial text attacks remain a persistent threat to transformer models,\nyet existing defenses are typically attack-specific or require costly model\nretraining. We introduce Representation Stability (RS), a model-agnostic\ndetection framework that identifies adversarial examples by measuring how\nembedding representations change when important words are masked. RS first\nranks words using importance heuristics, then measures embedding sensitivity to\nmasking top-k critical words, and processes the resulting patterns with a\nBiLSTM detector. Experiments show that adversarially perturbed words exhibit\ndisproportionately high masking sensitivity compared to naturally important\nwords. Across three datasets, three attack types, and two victim models, RS\nachieves over 88% detection accuracy and demonstrates competitive performance\ncompared to existing state-of-the-art methods, often at lower computational\ncost. Using Normalized Discounted Cumulative Gain (NDCG) to measure\nperturbation identification quality, we reveal that gradient-based ranking\noutperforms attention and random selection approaches, with identification\nquality correlating with detection performance for word-level attacks. RS also\ngeneralizes well to unseen datasets, attacks, and models without retraining,\nproviding a practical solution for adversarial text detection."}
{"id": "2508.11847", "pdf": "https://arxiv.org/pdf/2508.11847", "abs": "https://arxiv.org/abs/2508.11847", "authors": ["Jenny Y. Huang", "Yunyi Shen", "Dennis Wei", "Tamara Broderick"], "title": "Dropping Just a Handful of Preferences Can Change Top Large Language Model Rankings", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose a method for evaluating the robustness of a widely used LLM\nranking system -- the Bradley--Terry ranking system -- to dropping a worst-case\nvery small fraction of evaluation data. Our approach is computationally fast\nand easy to adopt. When we apply our method to matchups from two popular\nhuman-preference platforms, Chatbot Arena and MT-Bench, we find that the\nBradley--Terry rankings of top-performing models are remarkably sensitive to\nthe removal of a small fraction of evaluations. Our framework also identifies\nthe specific evaluations most responsible for such ranking flips, allowing for\ninspections of these influential preferences. We observe that the rankings\nderived from MT-Bench preferences are notably more robust than those from\nChatbot Arena, likely due to MT-bench's use of expert annotators and carefully\nconstructed prompts. Finally, we find that rankings based on crowdsourced\nhuman-evaluated systems are just as sensitive as those based on LLM-as-a-judge\nevaluations, where in both, dropping as little as 0.02% of the total\nevaluations in the dataset can change the top-ranked model."}
{"id": "2508.12177", "pdf": "https://arxiv.org/pdf/2508.12177", "abs": "https://arxiv.org/abs/2508.12177", "authors": ["Nicholas C. Henderson", "Ravi Varadhan"], "title": "Accelerating Proximal Gradient-type Algorithms using Damped Anderson Acceleration with Restarts and Nesterov Initialization", "categories": ["stat.CO"], "comment": null, "summary": "Despite their frequent slow convergence, proximal gradient schemes are widely\nused in large-scale optimization tasks due to their tremendous stability,\nscalability, and ease of computation. In this paper, we develop and investigate\na general two-phase scheme for accelerating the convergence of proximal\ngradient algorithms. By using Nesterov's momentum method in an initialization\nphase, our procedure delivers fast initial descent that is robust to the choice\nof starting value. Once iterates are much closer to the solution after the\nfirst phase, we utilize a variation of Anderson acceleration to deliver more\nrapid local convergence in the second phase. Drawing upon restarting schemes\ndeveloped for Nesterov acceleration, we can readily identify points where it is\nadvantageous to switch from the first to the second phase, which enables use of\nthe procedure without requiring one to specify the number of iterations used in\neach phase. For the second phase, we adapt and extend a version of Anderson\nacceleration with algorithm restarts, and we introduce a subsetted version of\nthis procedure that improves performance in problems with substantial sparsity.\nThrough simulation studies involving four representative optimization problems,\nwe show that our proposed algorithm can generate substantial improvements over\ncompeting acceleration methods."}
{"id": "2508.12569", "pdf": "https://arxiv.org/pdf/2508.12569", "abs": "https://arxiv.org/abs/2508.12569", "authors": ["Quercus Hernandez", "Max Win", "Thomas C. O'Connor", "Paulo E. Arratia", "Nathaniel Trask"], "title": "Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems", "categories": ["cs.LG", "cs.CE", "physics.comp-ph", "stat.ML"], "comment": "34 pages, 12 figures", "summary": "Multiscale systems are ubiquitous in science and technology, but are\nnotoriously challenging to simulate as short spatiotemporal scales must be\nappropriately linked to emergent bulk physics. When expensive high-dimensional\ndynamical systems are coarse-grained into low-dimensional models, the entropic\nloss of information leads to emergent physics which are dissipative,\nhistory-dependent, and stochastic. To machine learn coarse-grained dynamics\nfrom time-series observations of particle trajectories, we propose a framework\nusing the metriplectic bracket formalism that preserves these properties by\nconstruction; most notably, the framework guarantees discrete notions of the\nfirst and second laws of thermodynamics, conservation of momentum, and a\ndiscrete fluctuation-dissipation balance crucial for capturing non-equilibrium\nstatistics. We introduce the mathematical framework abstractly before\nspecializing to a particle discretization. As labels are generally unavailable\nfor entropic state variables, we introduce a novel self-supervised learning\nstrategy to identify emergent structural variables. We validate the method on\nbenchmark systems and demonstrate its utility on two challenging examples: (1)\ncoarse-graining star polymers at challenging levels of coarse-graining while\npreserving non-equilibrium statistics, and (2) learning models from high-speed\nvideo of colloidal suspensions that capture coupling between local\nrearrangement events and emergent stochastic dynamics. We provide open-source\nimplementations in both PyTorch and LAMMPS, enabling large-scale inference and\nextensibility to diverse particle-based systems."}
{"id": "2508.12872", "pdf": "https://arxiv.org/pdf/2508.12872", "abs": "https://arxiv.org/abs/2508.12872", "authors": ["Franz Okyere", "Meng Lu", "Ansgar Brunn"], "title": "Evaluating the Quality of Open Building Datasets for Mapping Urban Inequality: A Comparative Analysis Across 5 Cities", "categories": ["cs.DB", "cs.CY"], "comment": "25 pages, 4 pages", "summary": "While informal settlements lack focused development and are highly dynamic,\nthe quality of spatial data for these places may be uncertain. This study\nevaluates the quality and biases of AI-generated Open Building Datasets (OBDs)\ngenerated by Google and Microsoft against OpenStreetMap (OSM) data, across\ndiverse global cities including Accra, Nairobi, Caracas, Berlin, and Houston.\nThe Intersection over Union (IoU), overlap analysis and a positional accuracy\nalgorithm are used to analyse the similarity and alignment of the datasets. The\npaper also analyses the size distribution of the building polygon area, and\ncompleteness using predefined but regular spatial units. The results indicate\nsignificant variance in data quality, with Houston and Berlin demonstrating\nhigh alignment and completeness, reflecting their structured urban\nenvironments. There are gaps in the datasets analysed, and cities like Accra\nand Caracas may be under-represented. This could highlight difficulties in\ncapturing complex or informal regions. The study also notes different building\nsize distributions, which may be indicative of the global socio-economic\ndivide. These findings may emphasise the need to consider the quality of global\nbuilding datasets to avoid misrepresentation, which is an important element of\nplanning and resource distribution."}
{"id": "2508.12671", "pdf": "https://arxiv.org/pdf/2508.12671", "abs": "https://arxiv.org/abs/2508.12671", "authors": ["Dmitry Belousov", "Yury Yanovich"], "title": "DIT: Dimension Reduction View on Optimal NFT Rarity Meters", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Non-fungible tokens (NFTs) have become a significant digital asset class,\neach uniquely representing virtual entities such as artworks. These tokens are\nstored in collections within smart contracts and are actively traded across\nplatforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is\nclosely tied to their distinctive characteristics that define rarity, leading\nto a growing interest in quantifying rarity within both industry and academia.\nWhile there are existing rarity meters for assessing NFT rarity, comparing them\ncan be challenging without direct access to the underlying collection data. The\nRating over all Rarities (ROAR) benchmark addresses this challenge by providing\na standardized framework for evaluating NFT rarity. This paper explores a\ndimension reduction approach to rarity design, introducing new performance\nmeasures and meters, and evaluates them using the ROAR benchmark. Our\ncontributions to the rarity meter design issue include developing an optimal\nrarity meter design using non-metric weighted multidimensional scaling,\nintroducing Dissimilarity in Trades (DIT) as a performance measure inspired by\ndimension reduction techniques, and unveiling the non-interpretable rarity\nmeter DIT, which demonstrates superior performance compared to existing\nmethods."}
{"id": "2508.12675", "pdf": "https://arxiv.org/pdf/2508.12675", "abs": "https://arxiv.org/abs/2508.12675", "authors": ["Travis Gagie"], "title": "r*-indexing", "categories": ["cs.DS"], "comment": null, "summary": "Let $T [1..n]$ be a text over an alphabet of size $\\sigma \\in\n\\mathrm{polylog} (n)$, let $r^*$ be the sum of the numbers of runs in the\nBurrows-Wheeler Transforms of $T$ and its reverse, and let $z$ be the number of\nphrases in the LZ77 parse of $T$. We show how to store $T$ in $O (r^* \\log (n /\nr^*) + z \\log n)$ bits such that, given a pattern $P [1..m]$, we can report the\nlocations of the $\\mathrm{occ}$ occurrences of $P$ in $T$ in $O (m \\log n +\n\\mathrm{occ} \\log^\\epsilon n)$ time. We can also report the position of the\nleftmost and rightmost occurrences of $P$ in $T$ in the same space and $O (m\n\\log^\\epsilon n)$ time."}
{"id": "2508.12549", "pdf": "https://arxiv.org/pdf/2508.12549", "abs": "https://arxiv.org/abs/2508.12549", "authors": ["Atasi Panda", "Harsh Sharma", "Anand Louis", "Prajakta Nimbhorkar"], "title": "Group Fair Matchings using Convex Cost Functions", "categories": ["cs.GT", "cs.DS", "cs.MA"], "comment": null, "summary": "We consider the problem of assigning items to platforms where each item has a\nutility associated with each of the platforms to which it can be assigned. Each\nplatform has a soft constraint over the total number of items it serves,\nmodeled via a convex cost function. Additionally, items are partitioned into\ngroups, and each platform also incurs group-specific convex cost over the\nnumber of items from each group that can be assigned to the platform. These\ncosts promote group fairness by penalizing imbalances, yielding a soft\nvariation of fairness notions introduced in prior work, such as Restricted\nDominance and Minority protection. Restricted Dominance enforces upper bounds\non group representation, while Minority protection enforces lower bounds. Our\napproach replaces such hard constraints with cost-based penalties, allowing\nmore flexible trade-offs. Our model also captures Nash Social Welfare kind of\nobjective.\n  The cost of an assignment is the sum of the values of all the cost functions\nacross all the groups and platforms. The objective is to find an assignment\nthat minimizes the cost while achieving a total utility that is at least a\nuser-specified threshold. The main challenge lies in balancing the overall\nplatform cost with group-specific costs, both governed by convex functions,\nwhile meeting the utility constraint. We present an efficient polynomial-time\napproximation algorithm, supported by theoretical guarantees and experimental\nevaluation. Our algorithm is based on techniques involving linear programming\nand network flows. We also provide an exact algorithm for a special case with\nuniform utilities and establish the hardness of the general problem when the\ngroups can intersect arbitrarily."}
{"id": "2508.11784", "pdf": "https://arxiv.org/pdf/2508.11784", "abs": "https://arxiv.org/abs/2508.11784", "authors": ["Zabir Al Nazi", "Vagelis Hristidis", "Aaron Lawson McLean", "Jannat Ara Meem", "Md Taukir Azam Chowdhury"], "title": "Ontology-Guided Query Expansion for Biomedical Document Retrieval using Large Language Models", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Effective Question Answering (QA) on large biomedical document collections\nrequires effective document retrieval techniques. The latter remains a\nchallenging task due to the domain-specific vocabulary and semantic ambiguity\nin user queries. We propose BMQExpander, a novel ontology-aware query expansion\npipeline that combines medical knowledge - definitions and relationships - from\nthe UMLS Metathesaurus with the generative capabilities of large language\nmodels (LLMs) to enhance retrieval effectiveness. We implemented several\nstate-of-the-art baselines, including sparse and dense retrievers, query\nexpansion methods, and biomedical-specific solutions. We show that BMQExpander\nhas superior retrieval performance on three popular biomedical Information\nRetrieval (IR) benchmarks: NFCorpus, TREC-COVID, and SciFact - with\nimprovements of up to 22.1% in NDCG@10 over sparse baselines and up to 6.5%\nover the strongest baseline. Further, BMQExpander generalizes robustly under\nquery perturbation settings, in contrast to supervised baselines, achieving up\nto 15.7% improvement over the strongest baseline. As a side contribution, we\npublish our paraphrased benchmarks. Finally, our qualitative analysis shows\nthat BMQExpander has fewer hallucinations compared to other LLM-based query\nexpansion baselines."}
{"id": "2508.13057", "pdf": "https://arxiv.org/pdf/2508.13057", "abs": "https://arxiv.org/abs/2508.13057", "authors": ["Adolfo González", "Víctor Parada"], "title": "Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models", "categories": ["cs.LG", "cs.AI", "cs.PF", "62M10, 90C59, 68T05", "I.2.6; I.5.1; I.5.2; I.5.4; G.1.6"], "comment": "31 pages, 15 figures, 110 tables. Submitted as a preprint. The\n  manuscript introduces the Hierarchical Evaluation Function (HEF), a\n  multi-metric framework for optimizing demand forecasting models under high\n  uncertainty. Includes extensive experimental validation using real-world\n  datasets and a comparative analysis against classical and modern methods", "summary": "Demand forecasting is essential for strategic planning in competitive\nenvironments, enabling resource optimization and improved responsiveness to\nmarket dynamics. However, multivariate time series modeling faces challenges\ndue to data complexity, uncertainty, and frequent regime shifts. Traditional\nevaluation metrics can introduce biases and limit generalization. This work\ncompares two custom evaluation functions: FMAE (Focused Mean Absolute Error),\nfocused on minimizing absolute errors, and HEF (Hierarchical Evaluation\nFunction), designed to weight global metrics and penalize large deviations.\nExperiments were conducted under different data splits (91:9, 80:20, 70:30)\nusing three optimizers (Grid Search, PSO, Optuna), assessing fit, relative\naccuracy, robustness, and computational efficiency. Results show that HEF\nconsistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,\nRMSSE), enhancing model robustness and explanatory power. These findings were\nconfirmed via visualizations and statistical tests. Conversely, FMAE offers\nadvantages in local metrics (MAE, MASE) and execution time, making it suitable\nfor short-term scenarios. The study highlights a methodological trade-off: HEF\nis ideal for strategic planning, while FMAE is better suited for operational\nefficiency. A replicable framework is proposed for optimizing predictive models\nin dynamic environments."}
{"id": "2508.11689", "pdf": "https://arxiv.org/pdf/2508.11689", "abs": "https://arxiv.org/abs/2508.11689", "authors": ["Eduardo Calle-Ortiz", "Hui Guan", "Deepak Ganesan", "Phuc Nguyen"], "title": "Adaptive Spiking with Plasticity for Energy Aware Neuromorphic Systems", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": "14 pages", "summary": "This paper presents ASPEN, a novel energy-aware technique for neuromorphic\nsystems that could unleash the future of intelligent, always-on,\nultra-low-power, and low-burden wearables. Our main research objectives are to\nexplore the feasibility of neuromorphic computing for wearables, identify open\nresearch directions, and demonstrate the feasibility of developing an adaptive\nspiking technique for energy-aware computation, which can be game-changing for\nresource-constrained devices in always-on applications. As neuromorphic\ncomputing systems operate based on spike events, their energy consumption is\nclosely related to spiking activity, i.e., each spike incurs computational and\npower costs; consequently, minimizing the number of spikes is a critical\nstrategy for operating under constrained energy budgets. To support this goal,\nASPEN utilizes stochastic perturbations to the neuronal threshold during\ntraining to not only enhance the network's robustness across varying\nthresholds, which can be controlled at inference time, but also act as a\nregularizer that improves generalization, reduces spiking activity, and enables\nenergy control without the need for complex retraining or pruning. More\nspecifically, ASPEN adaptively adjusts intrinsic neuronal parameters as a\nlightweight and scalable technique for dynamic energy control without\nreconfiguring the entire model. Our evaluation on neuromorphic emulator and\nhardware shows that ASPEN significantly reduces spike counts and energy\nconsumption while maintaining accuracy comparable to state-of-the-art methods."}
{"id": "2508.11860", "pdf": "https://arxiv.org/pdf/2508.11860", "abs": "https://arxiv.org/abs/2508.11860", "authors": ["Frazier N. Baker", "Daniel Adu-Ampratwum", "Reza Averly", "Botao Yu", "Huan Sun", "Xia Ning"], "title": "LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework", "categories": ["cs.AI", "cs.CL"], "comment": "24 pages, 5 figures", "summary": "Large language model (LLM) agent evaluators leverage specialized tools to\nground the rational decision-making of LLMs, making them well-suited to aid in\nscientific discoveries, such as constrained retrosynthesis planning.\nConstrained retrosynthesis planning is an essential, yet challenging, process\nwithin chemistry for identifying synthetic routes from commercially available\nstarting materials to desired target molecules, subject to practical\nconstraints. Here, we present LARC, the first LLM-based Agentic framework for\nRetrosynthesis planning under Constraints. LARC incorporates agentic constraint\nevaluation, through an Agent-as-a-Judge, directly into the retrosynthesis\nplanning process, using agentic feedback grounded in tool-based reasoning to\nguide and constrain route generation. We rigorously evaluate LARC on a\ncarefully curated set of 48 constrained retrosynthesis planning tasks across 3\nconstraint types. LARC achieves a 72.9% success rate on these tasks, vastly\noutperforming LLM baselines and approaching human expert-level success in\nsubstantially less time. The LARC framework is extensible, and serves as a\nfirst step towards an effective agentic tool or a co-scientist to human experts\nfor constrained retrosynthesis."}
{"id": "2508.11824", "pdf": "https://arxiv.org/pdf/2508.11824", "abs": "https://arxiv.org/abs/2508.11824", "authors": ["Satyam Kumar Navneet", "Joydeep Chandra"], "title": "Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.PF"], "comment": null, "summary": "The integration of Large Language Models (LLMs) into software engineering has\nrevolutionized code generation, enabling unprecedented productivity through\npromptware and autonomous AI agents. However, this transformation introduces\nsignificant risks, including insecure code generation, hallucinated outputs,\nirreversible actions, and a lack of transparency and accountability. Incidents\nlike the Replit database deletion underscore the urgent need for robust safety\nand governance mechanisms. This paper comprehensively analyzes the inherent\nchallenges of LLM-assisted code generation, such as vulnerability inheritance,\novertrust, misinterpretation, and the absence of standardized validation and\nrollback protocols. To address these, we propose the SAFE-AI Framework, a\nholistic approach emphasizing Safety, Auditability, Feedback, and\nExplainability. The framework integrates guardrails, sandboxing, runtime\nverification, risk-aware logging, human-in-the-loop systems, and explainable AI\ntechniques to mitigate risks while fostering trust and compliance. We introduce\na novel taxonomy of AI behaviors categorizing suggestive, generative,\nautonomous, and destructive actions to guide risk assessment and oversight.\nAdditionally, we identify open problems, including the lack of standardized\nbenchmarks for code specific hallucinations and autonomy levels, and propose\nfuture research directions for hybrid verification, semantic guardrails, and\nproactive governance tools. Through detailed comparisons of autonomy control,\nprompt engineering, explainability, and governance frameworks, this paper\nprovides a roadmap for responsible AI integration in software engineering,\naligning with emerging regulations like the EU AI Act and Canada's AIDA to\nensure safe, transparent, and accountable AI-driven development."}
{"id": "2508.11807", "pdf": "https://arxiv.org/pdf/2508.11807", "abs": "https://arxiv.org/abs/2508.11807", "authors": ["Ravshanbek Khodzhimatov", "Stephan Leitner", "Friederike Wall"], "title": "Conformity: Resolving the Trade-Off Between Performance and Synchrony in Multi-Unit Organizations", "categories": ["econ.GN", "q-fin.EC"], "comment": "30 pages, 2 appendices, 5 figures, 3 tables in the main text, online\n  appendix", "summary": "Multi-unit organizations are a form of organizations where the geographically\ndispersed units provide similar products or services in different markets.\nDeciding on an appropriate level of centralization in such organizations\npresents a unique challenge. One the one hand the organizations want to\nmaintain a consistent brand identity in all units through centralized control,\nbut on the other hand, they want to provide the units with sufficient autonomy\nto respond to the challenges they face locally. Traditionally, this challenge\nwas perceived to require a trade-off between performance and organizational\nsynchrony, with performance demanding more decentralization and synchrony\nrequiring more centralized control. However, our research explores how\norganizations can potentially resolve this trade-off by promoting norms for\nknowledge-sharing and setting up the right communication channels, relying on\nthe unit managers' intrinsic tendency to conform to the behavior of their\npeers. We build an agent-based model of an organization with multiple\ninterdependent units facing highly similar task environments to investigate how\nunit managers' ability to communicate, share knowledge, and conform to peer\npractices might influence organizational dynamics. We find that, under specific\ncommunication network structures, increased decentralization can enhance both\nperformance and organizational synchrony without sacrificing one or the other.\nFurthermore, we discover that centralization might still be preferable for\nsynchrony if the units are interdependent."}
{"id": "2508.11807", "pdf": "https://arxiv.org/pdf/2508.11807", "abs": "https://arxiv.org/abs/2508.11807", "authors": ["Ravshanbek Khodzhimatov", "Stephan Leitner", "Friederike Wall"], "title": "Conformity: Resolving the Trade-Off Between Performance and Synchrony in Multi-Unit Organizations", "categories": ["econ.GN", "q-fin.EC"], "comment": "30 pages, 2 appendices, 5 figures, 3 tables in the main text, online\n  appendix", "summary": "Multi-unit organizations are a form of organizations where the geographically\ndispersed units provide similar products or services in different markets.\nDeciding on an appropriate level of centralization in such organizations\npresents a unique challenge. One the one hand the organizations want to\nmaintain a consistent brand identity in all units through centralized control,\nbut on the other hand, they want to provide the units with sufficient autonomy\nto respond to the challenges they face locally. Traditionally, this challenge\nwas perceived to require a trade-off between performance and organizational\nsynchrony, with performance demanding more decentralization and synchrony\nrequiring more centralized control. However, our research explores how\norganizations can potentially resolve this trade-off by promoting norms for\nknowledge-sharing and setting up the right communication channels, relying on\nthe unit managers' intrinsic tendency to conform to the behavior of their\npeers. We build an agent-based model of an organization with multiple\ninterdependent units facing highly similar task environments to investigate how\nunit managers' ability to communicate, share knowledge, and conform to peer\npractices might influence organizational dynamics. We find that, under specific\ncommunication network structures, increased decentralization can enhance both\nperformance and organizational synchrony without sacrificing one or the other.\nFurthermore, we discover that centralization might still be preferable for\nsynchrony if the units are interdependent."}
{"id": "2508.11669", "pdf": "https://arxiv.org/pdf/2508.11669", "abs": "https://arxiv.org/abs/2508.11669", "authors": ["Wentao Li", "Yonghu He", "Kun Gao", "Qing Liu", "Yali Zheng"], "title": "Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Noninvasive arterial blood pressure (ABP) monitoring is essential for patient\nmanagement in critical care and perioperative settings, providing continuous\nassessment of cardiovascular hemodynamics with minimal risks. Numerous deep\nlearning models have developed to reconstruct ABP waveform from noninvasively\nacquired physiological signals such as electrocardiogram and\nphotoplethysmogram. However, limited research has addressed the issue of model\nperformance and computational load for deployment on embedded systems. The\nstudy introduces a lightweight sInvResUNet, along with a collaborative learning\nscheme named KDCL_sInvResUNet. With only 0.89 million parameters and a\ncomputational load of 0.02 GFLOPS, real-time ABP estimation was successfully\nachieved on embedded devices with an inference time of just 8.49 milliseconds\nfor a 10-second output. We performed subject-independent validation in a\nlarge-scale and heterogeneous perioperative dataset containing 1,257,141 data\nsegments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and\n31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better\nperformance compared to large models, with a mean absolute error of 10.06 mmHg\nand mean Pearson correlation of 0.88 in tracking ABP changes. Despite these\npromising results, all deep learning models showed significant performance\nvariations across different demographic and cardiovascular conditions,\nhighlighting their limited ability to generalize across such a broad and\ndiverse population. This study lays a foundation work for real-time,\nunobtrusive ABP monitoring in real-world perioperative settings, providing\nbaseline for future advancements in this area."}
{"id": "2508.12048", "pdf": "https://arxiv.org/pdf/2508.12048", "abs": "https://arxiv.org/abs/2508.12048", "authors": ["Jing Wang", "HaiYing Wang", "Kun Chen"], "title": "Robust Data Fusion via Subsampling", "categories": ["stat.ML", "cs.LG", "62K05"], "comment": null, "summary": "Data fusion and transfer learning are rapidly growing fields that enhance\nmodel performance for a target population by leveraging other related data\nsources or tasks. The challenges lie in the various potential heterogeneities\nbetween the target and external data, as well as various practical concerns\nthat prevent a na\\\"ive data integration. We consider a realistic scenario where\nthe target data is limited in size while the external data is large but\ncontaminated with outliers; such data contamination, along with other\ncomputational and operational constraints, necessitates proper selection or\nsubsampling of the external data for transfer learning. To our\nknowledge,transfer learning and subsampling under data contamination have not\nbeen thoroughly investigated. We address this gap by studying various transfer\nlearning methods with subsamples of the external data, accounting for outliers\ndeviating from the underlying true model due to arbitrary mean shifts. Two\nsubsampling strategies are investigated: one aimed at reducing biases and the\nother at minimizing variances. Approaches to combine these strategies are also\nintroduced to enhance the performance of the estimators. We provide\nnon-asymptotic error bounds for the transfer learning estimators, clarifying\nthe roles of sample sizes, signal strength, sampling rates, magnitude of\noutliers, and tail behaviors of model error distributions, among other factors.\nExtensive simulations show the superior performance of the proposed methods.\nAdditionally, we apply our methods to analyze the risk of hard landings in A380\nairplanes by utilizing data from other airplane types,demonstrating that robust\ntransfer learning can improve estimation efficiency for relatively rare\nairplane types with the help of data from other types of airplanes."}
{"id": "2508.12155", "pdf": "https://arxiv.org/pdf/2508.12155", "abs": "https://arxiv.org/abs/2508.12155", "authors": ["Andrea Arnold"], "title": "A Systematic Particle Filter for Estimating Time-Varying Parameters in Advection-Diffusion Equations with Source Terms", "categories": ["stat.ME", "math.DS", "stat.CO"], "comment": "15 pages, 6 figures", "summary": "Many real-world systems modeled using partial differential equations (PDEs)\ninvolve unknown parameters that must be estimated from limited, noisy system\nobservations. While typically assumed to be constants, some of these unobserved\nparameters may vary with time. This work proposes a two-phase, offline-online\nnumerical procedure for systematically estimating and quantifying uncertainty\nin time-varying parameters (TVPs) in time-dependent PDEs, specifically focusing\non advection-diffusion models with TVPs involved in the source terms. Numerical\nresults on a set of one-dimensional test problems demonstrate the effectiveness\nof the proposed estimation procedure in tracking unknown TVPs of different\nforms, while simultaneously estimating variance parameters affecting the TVP\nevolution model, from partial, noisy observations of the solution at discrete\nspatial locations and times."}
{"id": "2508.12947", "pdf": "https://arxiv.org/pdf/2508.12947", "abs": "https://arxiv.org/abs/2508.12947", "authors": ["Michael Mayer", "Mario V. Wüthrich"], "title": "Shapley Values: Paired-Sampling Approximations", "categories": ["stat.ML", "cs.CE", "cs.LG"], "comment": null, "summary": "Originally introduced in cooperative game theory, Shapley values have become\na very popular tool to explain machine learning predictions. Based on Shapley's\nfairness axioms, every input (feature component) gets a credit how it\ncontributes to an output (prediction). These credits are then used to explain\nthe prediction. The only limitation in computing the Shapley values (credits)\nfor many different predictions is of computational nature. There are two\npopular sampling approximations, sampling KernelSHAP and sampling\nPermutationSHAP. Our first novel contributions are asymptotic normality results\nfor these sampling approximations. Next, we show that the paired-sampling\napproaches provide exact results in case of interactions being of maximal order\ntwo. Furthermore, the paired-sampling PermutationSHAP possesses the additive\nrecovery property, whereas its kernel counterpart does not."}
{"id": "2508.13041", "pdf": "https://arxiv.org/pdf/2508.13041", "abs": "https://arxiv.org/abs/2508.13041", "authors": ["Dörthe Arndt", "William Van Woensel", "Dominik Tomaszuk"], "title": "SPARQL in N3: SPARQL CONSTRUCT as a rule language for the Semantic Web (Extended Version)", "categories": ["cs.DB", "cs.LO", "F.4.1; H.2.3; I.2.3; I.2.4"], "comment": "21 pages, submitted to RuleML+RR 2025: the 9th International Joint\n  Conference on Rules and Reasoning", "summary": "Reasoning in the Semantic Web (SW) commonly uses Description Logics (DL) via\nOWL2 DL ontologies, or SWRL for variables and Horn clauses. The Rule\nInterchange Format (RIF) offers more expressive rules but is defined outside\nRDF and rarely adopted. For querying, SPARQL is a well-established standard\noperating directly on RDF triples. We leverage SPARQL CONSTRUCT queries as\nlogic rules, enabling (1) an expressive, familiar SW rule language, and (2)\ngeneral recursion, where queries can act on the results of others. We translate\nthese queries to the Notation3 Logic (N3) rule language, allowing use of\nexisting reasoning machinery with forward and backward chaining. Targeting a\none-to-one query-rule mapping improves exchangeability and interpretability.\nBenchmarks indicate competitive performance, aiming to advance the potential of\nrule-based reasoning in the SW."}
{"id": "2508.12743", "pdf": "https://arxiv.org/pdf/2508.12743", "abs": "https://arxiv.org/abs/2508.12743", "authors": ["Jacob Wahlgren", "Gabin Schieffer", "Ruimin Shi", "Edgar A. León", "Roger Pearce", "Maya Gokhale", "Ivy Peng"], "title": "Dissecting CPU-GPU Unified Physical Memory on AMD MI300A APUs", "categories": ["cs.DC", "cs.PF"], "comment": "To be published in IISWC 2025", "summary": "Discrete GPUs are a cornerstone of HPC and data center systems, requiring\nmanagement of separate CPU and GPU memory spaces. Unified Virtual Memory (UVM)\nhas been proposed to ease the burden of memory management; however, at a high\ncost in performance. The recent introduction of AMD's MI300A Accelerated\nProcessing Units (APUs)--as deployed in the El Capitan supercomputer--enables\nHPC systems featuring integrated CPU and GPU with Unified Physical Memory (UPM)\nfor the first time. This work presents the first comprehensive characterization\nof the UPM architecture on MI300A. We first analyze the UPM system properties,\nincluding memory latency, bandwidth, and coherence overhead. We then assess the\nefficiency of the system software in memory allocation, page fault handling,\nTLB management, and Infinity Cache utilization. We propose a set of porting\nstrategies for transforming applications for the UPM architecture and evaluate\nsix applications on the MI300A APU. Our results show that applications on UPM\nusing the unified memory model can match or outperform those in the explicitly\nmanaged model--while reducing memory costs by up to 44%."}
{"id": "2508.13055", "pdf": "https://arxiv.org/pdf/2508.13055", "abs": "https://arxiv.org/abs/2508.13055", "authors": ["Rajni Dabas", "Samir Khuller", "Emilie Rivkin"], "title": "Weighted Partition Vertex and Edge Cover", "categories": ["cs.DS"], "comment": null, "summary": "We study generalizations of the classical Vertex Cover and Edge Cover\nproblems that incorporate group-wise coverage constraints. Our first focus is\nthe \\emph{Weighted Prize-Collecting Partition Vertex Cover} (WP-PVC) problem:\ngiven a graph with weights on both vertices and edges, and a partition of the\nedge set into $\\omega$ groups, the goal is to select a minimum-weight subset of\nvertices such that, in each group, the total weight (profit) of covered edges\nmeets a specified threshold. This formulation generalizes classical vertex\ncover, partial vertex cover and partition vertex cover.\n  We present two algorithms for WP-PVC. The first is a simple 2-approximation\nthat solves \\( n^{\\omega} \\) LP's, improving over prior work by Bandyapadhyay\net al.\\ by removing an enumerative step and the extra \\( \\epsilon \\)-factor in\napproximation, while also extending to the weighted setting. The second is a\nbi-criteria algorithm that applies when \\( \\omega \\) is large, approximately\nmeeting profit targets with a bounded LP-relative cost.\n  We also study a natural generalization of the edge cover problem, the\n\\emph{Weighted Partition Edge Cover} (W-PEC) problem, where each edge has an\nassociated weights, and the vertex set is partitioned into groups. For each\ngroup, the goal is to cover at least a specified number of vertices using\nincident edges, while minimizing the total weight of the selected edges. We\npresent the first exact polynomial-time algorithm for the weighted case,\nimproving runtime from \\( O(\\omega n^3) \\) to \\( O(mn+n^2 \\log n) \\) and\nsimplifying the algorithmic structure over prior unweighted approaches. We also\nshow that the prize-collecting variant of the W-PEC problem is NP-Complete via\na reduction from the knapsack problem."}
{"id": "2508.11687", "pdf": "https://arxiv.org/pdf/2508.11687", "abs": "https://arxiv.org/abs/2508.11687", "authors": ["Jingpu Yang", "Mingxuan Cui", "Hang Zhang", "Fengxian Ji", "Zhengzhao Lai", "Yufeng Wang"], "title": "Agent-Based Anti-Jamming Techniques for UAV Communications in Adversarial Environments: A Comprehensive Survey", "categories": ["eess.SP", "cs.GT"], "comment": null, "summary": "Unmanned Aerial Vehicle communications are encountering increasingly severe\nmulti-source interference challenges in dynamic adversarial environments, which\nimpose higher demands on their reliability and resilience. To address these\nchallenges, agent-based autonomous anti-jamming techniques have emerged as a\ncrucial research direction. This paper presents a comprehensive survey that\nfirst formalizes the concept of intelligent anti-jamming agents for UAV\ncommunications and establishes a closed-loop decision-making framework centered\non the \"Perception-Decision-Action\" (P-D-A) paradigm. Within this framework, we\nsystematically review key technologies at each stage, with particular emphasis\non employing game theory to model UAV-jammer interactions and integrating\nreinforcement learning-based intelligent algorithms to derive adaptive\nanti-jamming strategies. Furthermore, we discuss potential limitations of\ncurrent approaches, identify critical engineering challenges, and outline\npromising future research directions, aiming to provide valuable references for\ndeveloping more intelligent and robust anti-jamming communication systems for\nUAVs."}
{"id": "2508.11977", "pdf": "https://arxiv.org/pdf/2508.11977", "abs": "https://arxiv.org/abs/2508.11977", "authors": ["Zida Liang", "Changfa Wu", "Dunxian Huang", "Weiqiang Sun", "Ziyang Wang", "Yuliang Yan", "Jian Wu", "Yuning Jiang", "Bo Zheng", "Ke Chen", "Silu Zhou", "Yu Zhang"], "title": "TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios", "categories": ["cs.IR", "cs.AI"], "comment": "Both authors contributed equally to this research. Work done during\n  internship at Alibaba. Corresponding author: Dunxian Huang\n  (dunxian.hdx@alibaba-inc.com). Affiliations: (1) Shanghai Jiaotong\n  University, Shanghai, China; (2) Alibaba Inc", "summary": "Recommendation systems are essential tools in modern e-commerce, facilitating\npersonalized user experiences by suggesting relevant products. Recent\nadvancements in generative models have demonstrated potential in enhancing\nrecommendation systems; however, these models often exhibit limitations in\noptimizing retrieval tasks, primarily due to their reliance on autoregressive\ngeneration mechanisms. Conventional approaches introduce sequential\ndependencies that impede efficient retrieval, as they are inherently unsuitable\nfor generating multiple items without positional constraints within a single\nrequest session. To address these limitations, we propose TBGRecall, a\nframework integrating Next Session Prediction (NSP), designed to enhance\ngenerative retrieval models for e-commerce applications. Our framework\nreformulation involves partitioning input samples into multi-session sequences,\nwhere each sequence comprises a session token followed by a set of item tokens,\nand then further incorporate multiple optimizations tailored to the generative\ntask in retrieval scenarios. In terms of training methodology, our pipeline\nintegrates limited historical data pre-training with stochastic partial\nincremental training, significantly improving training efficiency and\nemphasizing the superiority of data recency over sheer data volume. Our\nextensive experiments, conducted on public benchmarks alongside a large-scale\nindustrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art\nrecommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP\nrepresents a significant advancement in the effectiveness of generative\nrecommendation systems for e-commerce applications."}
{"id": "2508.11703", "pdf": "https://arxiv.org/pdf/2508.11703", "abs": "https://arxiv.org/abs/2508.11703", "authors": ["Vasileios Saketos", "Sebastian Kaltenbach", "Sergey Litvinov", "Petros Koumoutsakos"], "title": "Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Algorithmic discovery has traditionally relied on human ingenuity and\nextensive experimentation. Here we investigate whether a prominent scientific\ncomputing algorithm, the Kalman Filter, can be discovered through an automated,\ndata-driven, evolutionary process that relies on Cartesian Genetic Programming\n(CGP) and Large Language Models (LLM). We evaluate the contributions of both\nmodalities (CGP and LLM) in discovering the Kalman filter under varying\nconditions. Our results demonstrate that our framework of CGP and LLM-assisted\nevolution converges to near-optimal solutions when Kalman optimality\nassumptions hold. When these assumptions are violated, our framework evolves\ninterpretable alternatives that outperform the Kalman filter. These results\ndemonstrate that combining evolutionary algorithms and generative models for\ninterpretable, data-driven synthesis of simple computational modules is a\npotent approach for algorithmic discovery in scientific computing."}
{"id": "2508.11894", "pdf": "https://arxiv.org/pdf/2508.11894", "abs": "https://arxiv.org/abs/2508.11894", "authors": ["Ao Li", "Bin Yan", "Bingfeng Cai", "Chenxi Li", "Cunzhong Zhao", "Fugen Yao", "Gaoqiang Liu", "Guanjun Jiang", "Jian Xu", "Liang Dong", "Liansheng Sun", "Rongshen Zhang", "Xiaolei Gui", "Xin Liu", "Xin Shang", "Yao Wu", "Yu Cao", "Zhenxin Ma", "Zhuang Jia"], "title": "QuarkMed Medical Foundation Model Technical Report", "categories": ["cs.AI"], "comment": "20 pages", "summary": "Recent advancements in large language models have significantly accelerated\ntheir adoption in healthcare applications, including AI-powered medical\nconsultations, diagnostic report assistance, and medical search tools. However,\nmedical tasks often demand highly specialized knowledge, professional accuracy,\nand customization capabilities, necessitating a robust and reliable foundation\nmodel. QuarkMed addresses these needs by leveraging curated medical data\nprocessing, medical-content Retrieval-Augmented Generation (RAG), and a\nlarge-scale, verifiable reinforcement learning pipeline to develop a\nhigh-performance medical foundation model. The model achieved 70% accuracy on\nthe Chinese Medical Licensing Examination, demonstrating strong generalization\nacross diverse medical benchmarks. QuarkMed offers a powerful yet versatile\npersonal medical AI solution, already serving over millions of users at\nai.quark.cn."}
{"id": "2508.11867", "pdf": "https://arxiv.org/pdf/2508.11867", "abs": "https://arxiv.org/abs/2508.11867", "authors": ["Mohammad Baqar", "Saba Naqvi", "Rajat Khanda"], "title": "AI-Augmented CI/CD Pipelines: From Code Commit to Production with Autonomous Decisions", "categories": ["cs.SE", "cs.AI"], "comment": "13 Pages", "summary": "Modern software delivery has accelerated from quarterly releases to multiple\ndeployments per day. While CI/CD tooling has matured, human decision points\ninterpreting flaky tests, choosing rollback strategies, tuning feature flags,\nand deciding when to promote a canary remain major sources of latency and\noperational toil. We propose AI-Augmented CI/CD Pipelines, where large language\nmodels (LLMs) and autonomous agents act as policy-bounded co-pilots and\nprogressively as decision makers. We contribute: (1) a reference architecture\nfor embedding agentic decision points into CI/CD, (2) a decision taxonomy and\npolicy-as-code guardrail pattern, (3) a trust-tier framework for staged\nautonomy, (4) an evaluation methodology using DevOps Research and Assessment (\nDORA) metrics and AI-specific indicators, and (5) a detailed industrial-style\ncase study migrating a React 19 microservice to an AI-augmented pipeline. We\ndiscuss ethics, verification, auditability, and threats to validity, and chart\na roadmap for verifiable autonomy in production delivery systems."}
{"id": "2508.12315", "pdf": "https://arxiv.org/pdf/2508.12315", "abs": "https://arxiv.org/abs/2508.12315", "authors": ["Neave O'Clery", "Ben Radcliffe-Brown", "Thomas Spencer", "Daniel Tarling-Hunter"], "title": "Deciphering the global production network from cross-border firm transactions", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Critical for policy-making and business operations, the study of global\nsupply chains has been severely hampered by a lack of detailed data. Here we\nharness global firm-level transaction data covering 20m global firms, and 1\nbillion cross-border transactions, to infer key inputs for over 1200 products.\nTransforming this data to a directed network, we find that products are\nclustered into three large groups including textiles, chemicals and food, and\nmachinery and metals. European industrial nations and China dominate critical\nintermediate products in the network such as metals, common components and\ntools, while industrial complexity is correlated with embeddedness in densely\nconnected supply chains. To validate the network, we find structural\nsimilarities with two alternative product networks, one generated via LLM\nqueries and the other derived by NAFTA to track product origins. We further\ndetect linkages between products identified in manually mapped single sector\nsupply chains, including electric vehicle batteries and semi-conductors.\nFinally, metrics derived from network structure capturing both forward and\nbackward linkages are able to predict country-product diversification patterns\nwith high accuracy."}
{"id": "2508.12315", "pdf": "https://arxiv.org/pdf/2508.12315", "abs": "https://arxiv.org/abs/2508.12315", "authors": ["Neave O'Clery", "Ben Radcliffe-Brown", "Thomas Spencer", "Daniel Tarling-Hunter"], "title": "Deciphering the global production network from cross-border firm transactions", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Critical for policy-making and business operations, the study of global\nsupply chains has been severely hampered by a lack of detailed data. Here we\nharness global firm-level transaction data covering 20m global firms, and 1\nbillion cross-border transactions, to infer key inputs for over 1200 products.\nTransforming this data to a directed network, we find that products are\nclustered into three large groups including textiles, chemicals and food, and\nmachinery and metals. European industrial nations and China dominate critical\nintermediate products in the network such as metals, common components and\ntools, while industrial complexity is correlated with embeddedness in densely\nconnected supply chains. To validate the network, we find structural\nsimilarities with two alternative product networks, one generated via LLM\nqueries and the other derived by NAFTA to track product origins. We further\ndetect linkages between products identified in manually mapped single sector\nsupply chains, including electric vehicle batteries and semi-conductors.\nFinally, metrics derived from network structure capturing both forward and\nbackward linkages are able to predict country-product diversification patterns\nwith high accuracy."}
{"id": "2508.11673", "pdf": "https://arxiv.org/pdf/2508.11673", "abs": "https://arxiv.org/abs/2508.11673", "authors": ["Haojie Zhang", "Yixiong Liang", "Hulin Kuang", "Lihui Cen", "Zhe Qu", "Yigang Cen", "Min Zeng", "Shichao Kan"], "title": "Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM"], "comment": "10 pages, 3 figures, submitted to ACM Multimedia 2025", "summary": "Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for\nhandling diverse tasks and modalities in the biomedical domain, as training\nseparate models for each modality or task significantly increases inference\ncosts. Existing incremental learning methods focus on task expansion within a\nsingle modality, whereas MBIIL seeks to train a unified model incrementally\nacross modalities. The MBIIL faces two challenges: I) How to preserve\npreviously learned knowledge during incremental updates? II) How to effectively\nleverage knowledge acquired from existing modalities to support new modalities?\nTo address these challenges, we propose MSLoRA-CR, a method that fine-tunes\nModality-Specific LoRA modules while incorporating Contrastive Regularization\nto enhance intra-modality knowledge sharing and promote inter-modality\nknowledge differentiation. Our approach builds upon a large vision-language\nmodel (LVLM), keeping the pretrained model frozen while incrementally adapting\nnew LoRA modules for each modality or task. Experiments on the incremental\nlearning of biomedical images demonstrate that MSLoRA-CR outperforms both the\nstate-of-the-art (SOTA) approach of training separate models for each modality\nand the general incremental learning method (incrementally fine-tuning LoRA).\nSpecifically, MSLoRA-CR achieves a 1.88% improvement in overall performance\ncompared to unconstrained incremental learning methods while maintaining\ncomputational efficiency. Our code is publicly available at\nhttps://github.com/VentusAislant/MSLoRA_CR."}
{"id": "2508.12519", "pdf": "https://arxiv.org/pdf/2508.12519", "abs": "https://arxiv.org/abs/2508.12519", "authors": ["Khai Nguyen"], "title": "An Introduction to Sliced Optimal Transport", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "227 pages", "summary": "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal\ntransport (OT) that exploits the tractability of one-dimensional OT problems.\nBy combining tools from OT, integral geometry, and computational statistics,\nSOT enables fast and scalable computation of distances, barycenters, and\nkernels for probability measures, while retaining rich geometric structure.\nThis paper provides a comprehensive review of SOT, covering its mathematical\nfoundations, methodological advances, computational methods, and applications.\nWe discuss key concepts of OT and one-dimensional OT, the role of tools from\nintegral geometry such as Radon transform in projecting measures, and\nstatistical techniques for estimating sliced distances. The paper further\nexplores recent methodological advances, including non-linear projections,\nimproved Monte Carlo approximations, statistical estimation techniques for\none-dimensional optimal transport, weighted slicing techniques, and\ntransportation plan estimation methods. Variational problems, such as minimum\nsliced Wasserstein estimation, barycenters, gradient flows, kernel\nconstructions, and embeddings are examined alongside extensions to unbalanced,\npartial, multi-marginal, and Gromov-Wasserstein settings. Applications span\nmachine learning, statistics, computer graphics and computer visions,\nhighlighting SOT's versatility as a practical computational tool. This work\nwill be of interest to researchers and practitioners in machine learning, data\nsciences, and computational disciplines seeking efficient alternatives to\nclassical OT."}
{"id": "2508.12519", "pdf": "https://arxiv.org/pdf/2508.12519", "abs": "https://arxiv.org/abs/2508.12519", "authors": ["Khai Nguyen"], "title": "An Introduction to Sliced Optimal Transport", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "227 pages", "summary": "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal\ntransport (OT) that exploits the tractability of one-dimensional OT problems.\nBy combining tools from OT, integral geometry, and computational statistics,\nSOT enables fast and scalable computation of distances, barycenters, and\nkernels for probability measures, while retaining rich geometric structure.\nThis paper provides a comprehensive review of SOT, covering its mathematical\nfoundations, methodological advances, computational methods, and applications.\nWe discuss key concepts of OT and one-dimensional OT, the role of tools from\nintegral geometry such as Radon transform in projecting measures, and\nstatistical techniques for estimating sliced distances. The paper further\nexplores recent methodological advances, including non-linear projections,\nimproved Monte Carlo approximations, statistical estimation techniques for\none-dimensional optimal transport, weighted slicing techniques, and\ntransportation plan estimation methods. Variational problems, such as minimum\nsliced Wasserstein estimation, barycenters, gradient flows, kernel\nconstructions, and embeddings are examined alongside extensions to unbalanced,\npartial, multi-marginal, and Gromov-Wasserstein settings. Applications span\nmachine learning, statistics, computer graphics and computer visions,\nhighlighting SOT's versatility as a practical computational tool. This work\nwill be of interest to researchers and practitioners in machine learning, data\nsciences, and computational disciplines seeking efficient alternatives to\nclassical OT."}
{"id": "2508.11797", "pdf": "https://arxiv.org/pdf/2508.11797", "abs": "https://arxiv.org/abs/2508.11797", "authors": ["Calkin Garg", "Omar Rios Cruz", "Tessa Andersen", "Gaby G. Dagher", "Donald Winiecki", "Min Long"], "title": "AegisBlock: A Privacy-Preserving Medical Research Framework using Blockchain", "categories": ["cs.CR", "cs.DB", "cs.DC"], "comment": "Submitted to IEEE Conference on Collaboration and Internet Computing\n  2025", "summary": "Due to HIPAA and other privacy regulations, it is imperative to maintain\npatient privacy while conducting research on patient health records. In this\npaper, we propose AegisBlock, a patient-centric access controlled framework to\nshare medical records with researchers such that the anonymity of the patient\nis maintained while ensuring the trustworthiness of the data provided to\nresearchers. AegisBlock allows for patients to provide access to their medical\ndata, verified by miners. A researcher submits a time-based range query to\nrequest access to records from a certain patient, and upon patient approval,\naccess will be granted. Our experimental evaluation results show that\nAegisBlock is scalable with respect to the number of patients and hospitals in\nthe system, and efficient with up to 50% of malicious miners."}
{"id": "2508.12851", "pdf": "https://arxiv.org/pdf/2508.12851", "abs": "https://arxiv.org/abs/2508.12851", "authors": ["Tian Wu", "Liming Wang", "Zijian Wen", "Xiaoxi Zhang", "Jingpu Duan", "Xianwei Zhang", "Jinhang Zuo"], "title": "Accelerating Edge Inference for Distributed MoE Models with Latency-Optimized Expert Placement", "categories": ["cs.DC"], "comment": null, "summary": "Mixture-of-Experts (MoE) have become a cornerstone for training and scaling\nlarge language models (LLMs), offering substantial gains in model capacity and\nefficiency through sparse expert activation. However, serving these models\nremains challenging in practice, particularly in resource-constrained edge\nenvironments, due to their large memory footprint and complex communication\ndemands. While centralized cloud inference is common, it incurs high\ninfrastructure costs, along with latency and privacy concerns. A few recent\nedge MoE works propose memory-efficient strategies but typically focus on\nsingle-device or homogeneous setups. This paper presents DanceMoE, an efficient\nMoE inference framework that enables activation-aware expert placement across\ncollaborative, heterogeneous, GPU-equipped edge servers. DanceMoE leverages the\ninherent sparsity of MoE models and workload locality to minimize cross-server\ncommunication and enable efficient expert placement under heterogeneous\nresource constraints. It introduces a data-driven, activation-aware placement\nalgorithm that balances local coverage and memory usage across servers,\nalongside a lightweight migration mechanism that adapts expert assignments\nunder evolving workloads. We evaluate DanceMoE on modern MoE models and widely\nused datasets, demonstrating up to 30.6\\% lower inference latency, and\nsubstantial communication reduction compared to state-of-the-art baselines,\nshowcasing the effectiveness of collaborative edge-based MoE inference."}
{"id": "2508.13108", "pdf": "https://arxiv.org/pdf/2508.13108", "abs": "https://arxiv.org/abs/2508.13108", "authors": ["Tyler Chen", "Junhyung Lyle Kim", "Archan Ray", "Shouvanik Chakrabarti", "Dylan Herman", "Niraj Kumar"], "title": "A simple analysis of a quantum-inspired algorithm for solving low-rank linear systems", "categories": ["cs.DS", "quant-ph"], "comment": null, "summary": "We describe and analyze a simple algorithm for sampling from the solution\n$\\mathbf{x}^* := \\mathbf{A}^+\\mathbf{b}$ to a linear system\n$\\mathbf{A}\\mathbf{x} = \\mathbf{b}$. We assume access to a sampler which allows\nus to draw indices proportional to the squared row/column-norms of\n$\\mathbf{A}$. Our algorithm produces a compressed representation of some vector\n$\\mathbf{x}$ for which $\\|\\mathbf{x}^* - \\mathbf{x}\\| < \\varepsilon\n\\|\\mathbf{x}^* \\|$ in $\\widetilde{O}(\\kappa_{\\mathsf{F}}^4 \\kappa^2 /\n\\varepsilon^2)$ time, where $\\kappa_{\\mathsf{F}} :=\n\\|\\mathbf{A}\\|_{\\mathsf{F}}\\|\\mathbf{A}^{+}\\|$ and $\\kappa :=\n\\|\\mathbf{A}\\|\\|\\mathbf{A}^{+}\\|$. The representation of $\\mathbf{x}$ allows us\nto query entries of $\\mathbf{x}$ in $\\widetilde{O}(\\kappa_{\\mathsf{F}}^2)$ time\nand sample proportional to the square entries of $\\mathbf{x}$ in\n$\\widetilde{O}(\\kappa_{\\mathsf{F}}^4 \\kappa^6)$ time, assuming access to a\nsampler which allows us to draw indices proportional to the squared entries of\nany given row of $\\mathbf{A}$. Our analysis, which is elementary,\nnon-asymptotic, and fully self-contained, simplifies and clarifies several past\nanalyses from literature including [Gily\\'en, Song, and Tang; 2022, 2023] and\n[Shao and Montanaro; 2022]."}
{"id": "2508.12059", "pdf": "https://arxiv.org/pdf/2508.12059", "abs": "https://arxiv.org/abs/2508.12059", "authors": ["Mingjia He", "Andrea Censi", "Emilio Frazzoli", "Gioele Zardini"], "title": "Co-Investment with Payoff-Sharing Mechanism for Cooperative Decision-Making in Network Design Games", "categories": ["eess.SY", "cs.GT", "cs.SY"], "comment": null, "summary": "Network-based systems are inherently interconnected, with the design and\nperformance of subnetworks being interdependent. However, the decisions of\nself-interested operators may lead to suboptimal outcomes for users and the\noverall system. This paper explores cooperative mechanisms that can\nsimultaneously benefit both operators and users. We address this challenge\nusing a game-theoretical framework that integrates both non-cooperative and\ncooperative game theory. In the non-cooperative stage, we propose a network\ndesign game in which subnetwork decision-makers strategically design local\ninfrastructures. In the cooperative stage, co-investment with payoff-sharing\nmechanism is developed to enlarge collective benefits and fairly distribute\nthem. To demonstrate the effectiveness of our framework, we conduct case\nstudies on the Sioux Falls network and real-world public transport networks in\nZurich and Winterthur, Switzerland. Our evaluation considers impacts on\nenvironmental sustainability, social welfare, and economic efficiency. The\nproposed framework provides a foundation for improving interdependent networked\nsystems by enabling strategic cooperation among self-interested operators."}
{"id": "2508.11978", "pdf": "https://arxiv.org/pdf/2508.11978", "abs": "https://arxiv.org/abs/2508.11978", "authors": ["Viacheslav Yusupov", "Maxim Rakhuba", "Evgeny Frolov"], "title": "Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recent studies have demonstrated the potential of hyperbolic geometry for\ncapturing complex patterns from interaction data in recommender systems. In\nthis work, we introduce a novel hyperbolic recommendation model that uses\ngeometrical insights to improve representation learning and increase\ncomputational stability at the same time. We reformulate the notion of\nhyperbolic distances to unlock additional representation capacity over\nconventional Euclidean space and learn more expressive user and item\nrepresentations. To better capture user-items interactions, we construct a\ntriplet loss that models ternary relations between users and their\ncorresponding preferred and nonpreferred choices through a mix of pairwise\ninteraction terms driven by the geometry of data. Our hyperbolic approach not\nonly outperforms existing Euclidean and hyperbolic models but also reduces\npopularity bias, leading to more diverse and personalized recommendations."}
{"id": "2508.11871", "pdf": "https://arxiv.org/pdf/2508.11871", "abs": "https://arxiv.org/abs/2508.11871", "authors": ["Zhen-Song Chen", "Hong-Wei Ding", "Xian-Jia Wang", "Witold Pedrycz"], "title": "LLM4CMO: Large Language Model-aided Algorithm Design for Constrained Multiobjective Optimization", "categories": ["cs.NE"], "comment": null, "summary": "Constrained multi-objective optimization problems (CMOPs) frequently arise in\nreal-world applications where multiple conflicting objectives must be optimized\nunder complex constraints. Existing dual-population two-stage algorithms have\nshown promise by leveraging infeasible solutions to improve solution quality.\nHowever, designing high-performing constrained multi-objective evolutionary\nalgorithms (CMOEAs) remains a challenging task due to the intricacy of\nalgorithmic components. Meanwhile, large language models (LLMs) offer new\nopportunities for assisting with algorithm design; however, their effective\nintegration into such tasks remains underexplored. To address this gap, we\npropose LLM4CMO, a novel CMOEA based on a dual-population, two-stage framework.\nIn Stage 1, the algorithm identifies both the constrained Pareto front (CPF)\nand the unconstrained Pareto front (UPF). In Stage 2, it performs targeted\noptimization using a combination of hybrid operators (HOps), an epsilon-based\nconstraint-handling method, and a classification-based UPF-CPF relationship\nstrategy, along with a dynamic resource allocation (DRA) mechanism. To reduce\ndesign complexity, the core modules, including HOps, epsilon decay function,\nand DRA, are decoupled and designed through prompt template engineering and\nLLM-human interaction. Experimental results on six benchmark test suites and\nten real-world CMOPs demonstrate that LLM4CMO outperforms eleven\nstate-of-the-art baseline algorithms. Ablation studies further validate the\neffectiveness of the LLM-aided modular design. These findings offer preliminary\nevidence that LLMs can serve as efficient co-designers in the development of\ncomplex evolutionary optimization algorithms. The code associated with this\narticle is available at https://anonymous.4open.science/r/LLM4CMO971."}
{"id": "2508.11944", "pdf": "https://arxiv.org/pdf/2508.11944", "abs": "https://arxiv.org/abs/2508.11944", "authors": ["Hongtao Liu", "Zhicheng Du", "Zihe Wang", "Weiran Shen"], "title": "CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Game-playing ability serves as an indicator for evaluating the strategic\nreasoning capability of large language models (LLMs). While most existing\nstudies rely on utility performance metrics, which are not robust enough due to\nvariations in opponent behavior and game structure. To address this limitation,\nwe propose \\textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation\nframework inspired by the cognitive hierarchy models from behavioral economics.\nWe hypothesize that agents have bounded rationality -- different agents behave\nat varying reasoning depths/levels. We evaluate LLMs' strategic reasoning\nthrough a three-phase systematic framework, utilizing behavioral data from six\nstate-of-the-art LLMs across fifteen carefully selected normal-form games.\nExperiments show that LLMs exhibit consistent strategic reasoning levels across\ndiverse opponents, confirming the framework's robustness and generalization\ncapability. We also analyze the effects of two key mechanisms (Chat Mechanism\nand Memory Mechanism) on strategic reasoning performance. Results indicate that\nthe Chat Mechanism significantly degrades strategic reasoning, whereas the\nMemory Mechanism enhances it. These insights position CHBench as a promising\ntool for evaluating LLM capabilities, with significant potential for future\nresearch and practical applications."}
{"id": "2508.11958", "pdf": "https://arxiv.org/pdf/2508.11958", "abs": "https://arxiv.org/abs/2508.11958", "authors": ["Zhipeng Xue", "Xiaoting Zhang", "Zhipeng Gao", "Xing Hu", "Shan Gao", "Xin Xia", "Shanping Li"], "title": "Clean Code, Better Models: Enhancing LLM Performance with Smell-Cleaned Dataset", "categories": ["cs.SE"], "comment": null, "summary": "The Large Language Models (LLMs) have demonstrated great potential in\ncode-related tasks. However, most research focuses on improving the output\nquality of LLMs (e.g., correctness), and less attention has been paid to the\nLLM input (e.g., the training code quality). Given that code smells are widely\nexisted in practice and can negatively impact software maintainability and\nreadability, this study takes the first systematic research to assess and\nimprove dataset quality in terms of code smells. In this work, we first conduct\na preliminary study to explore the presence of code smells in a popular\nbenchmark dataset (i.e., CodeSearchNet-Python}) and evaluate the output of\nseveral popular LLMs (i.e., DeepSeek-Coder, CodeLlama, and MagiCoder),\nrevealing that code smell issues extensively exist in LLM's input (e.g.,\nbenchmark dataset) and output (e.g., generated code). We then conduct our\nsystematic research by taking three main steps: Firstly, we propose an\nLLM-based code smell cleaning tool, named SmellCC, which automatically\nrefactors and removes code smells. To evaluate the correctness of the code\nrefactoring, we construct a test set of 50 repositories sourced from the\nCodeSearchNet-Python benchmark for functional testing. Then we apply our\ncurated smell-cleaned dataset to fine-tune two LLMs (i.e., DeepSeek-V2 and\nQwen-Coder) to explore their potential for generating high-quality code.\nThirdly, we investigate the impact of code smells on two downstream tasks: code\ncompletion and code search. Lastly, we derive several actionable implications\nfor software engineering researchers and industry practitioners from our\nfindings."}
{"id": "2508.12454", "pdf": "https://arxiv.org/pdf/2508.12454", "abs": "https://arxiv.org/abs/2508.12454", "authors": ["Sebastian G. Nosenzo"], "title": "Evaluating sugarcane bagasse-based biochar as an economically viable catalyst for agricultural and environmental advancement in Brazil through scenario-based economic modeling", "categories": ["econ.GN", "q-fin.EC"], "comment": "18 pages, 8 figures", "summary": "The increasing global demand for sustainable agricultural practices and\neffective waste management has highlighted the potential of biochar as a\nmultifaceted solution. This study evaluates the economic viability of sugarcane\nbagasse-based biochar in Brazil, focusing on its potential to enhance\nagricultural productivity and contribute to environmental sustainability. While\nexisting literature predominantly explores the production, crop yield benefits,\nand carbon sequestration capabilities of biochar, there is a notable gap in\ncomprehensive economic modeling and viability analysis for the region. This\npaper aims to fill this gap by employing a scenario-based economic modeling\napproach, incorporating relevant economic models. Findings include that biochar\nimplementation can be economically viable for medium and large sugarcane farms\n(20000-50000 hectares) given the availability of funding, breaking even in\nabout 7.5 years with an internal rate of return of 18% on average. For small\nfarms, biochar can only be viable when applying biochar to the soil, which in\nall scenarios is found to be the more profitable practice by a large margin.\nSensitivity analyses found that generally, biochar becomes economically\nfeasible at biochar carbon credit prices above $120 USD/tCO2e, and at sugarcane\nbagasse availability percentages above 60%. While the economic models are\nwell-grounded in existing literature, the production of biochar at the studied\nscales is not yet widespread, especially in Brazil and uncertainties can\nresult. Reviewing the results, the land application scenario was found to be\nthe most viable, and large farms saw the best results, highlighting the\nimportance of scale to biochar operation. Small and medium farms with no land\napplication were concluded to have no and questionable viability, respectively."}
{"id": "2508.12454", "pdf": "https://arxiv.org/pdf/2508.12454", "abs": "https://arxiv.org/abs/2508.12454", "authors": ["Sebastian G. Nosenzo"], "title": "Evaluating sugarcane bagasse-based biochar as an economically viable catalyst for agricultural and environmental advancement in Brazil through scenario-based economic modeling", "categories": ["econ.GN", "q-fin.EC"], "comment": "18 pages, 8 figures", "summary": "The increasing global demand for sustainable agricultural practices and\neffective waste management has highlighted the potential of biochar as a\nmultifaceted solution. This study evaluates the economic viability of sugarcane\nbagasse-based biochar in Brazil, focusing on its potential to enhance\nagricultural productivity and contribute to environmental sustainability. While\nexisting literature predominantly explores the production, crop yield benefits,\nand carbon sequestration capabilities of biochar, there is a notable gap in\ncomprehensive economic modeling and viability analysis for the region. This\npaper aims to fill this gap by employing a scenario-based economic modeling\napproach, incorporating relevant economic models. Findings include that biochar\nimplementation can be economically viable for medium and large sugarcane farms\n(20000-50000 hectares) given the availability of funding, breaking even in\nabout 7.5 years with an internal rate of return of 18% on average. For small\nfarms, biochar can only be viable when applying biochar to the soil, which in\nall scenarios is found to be the more profitable practice by a large margin.\nSensitivity analyses found that generally, biochar becomes economically\nfeasible at biochar carbon credit prices above $120 USD/tCO2e, and at sugarcane\nbagasse availability percentages above 60%. While the economic models are\nwell-grounded in existing literature, the production of biochar at the studied\nscales is not yet widespread, especially in Brazil and uncertainties can\nresult. Reviewing the results, the land application scenario was found to be\nthe most viable, and large farms saw the best results, highlighting the\nimportance of scale to biochar operation. Small and medium farms with no land\napplication were concluded to have no and questionable viability, respectively."}
{"id": "2508.11679", "pdf": "https://arxiv.org/pdf/2508.11679", "abs": "https://arxiv.org/abs/2508.11679", "authors": ["Shaodi Feng", "Zhuoyi Lin", "Jianan Zhou", "Cong Zhang", "Jingwen Li", "Kuan-Wen Chen", "Senthilnath Jayavelu", "Yew-Soon Ong"], "title": "Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Deep learning has been extensively explored to solve vehicle routing problems\n(VRPs), which yields a range of data-driven neural solvers with promising\noutcomes. However, most neural solvers are trained to tackle VRP instances in a\nrelatively monotonous context, e.g., simplifying VRPs by using Euclidean\ndistance between nodes and adhering to a single problem size, which harms their\noff-the-shelf application in different scenarios. To enhance their versatility,\nthis paper presents a novel lifelong learning framework that incrementally\ntrains a neural solver to manage VRPs in distinct contexts. Specifically, we\npropose a lifelong learner (LL), exploiting a Transformer network as the\nbackbone, to solve a series of VRPs. The inter-context self-attention mechanism\nis proposed within LL to transfer the knowledge obtained from solving preceding\nVRPs into the succeeding ones. On top of that, we develop a dynamic context\nscheduler (DCS), employing the cross-context experience replay to further\nfacilitate LL looking back on the attained policies of solving preceding VRPs.\nExtensive results on synthetic and benchmark instances (problem sizes up to\n18k) show that our LL is capable of discovering effective policies for tackling\ngeneric VRPs in varying contexts, which outperforms other neural solvers and\nachieves the best performance for most VRPs."}
{"id": "2508.12627", "pdf": "https://arxiv.org/pdf/2508.12627", "abs": "https://arxiv.org/abs/2508.12627", "authors": ["Xingyu Chen", "Ruiqi Zhang", "Lin Liu"], "title": "On computing and the complexity of computing higher-order $U$-statistics, exactly", "categories": ["stat.ML", "cs.DS", "cs.NA", "math.NA", "stat.CO", "stat.ME"], "comment": "Comments are welcome! 49 pages, 8 tables, 4 figures. An accompanying\n  Python package is available at: https://libraries.io/pypi/u-stats or\n  https://github.com/Amedar-Asterisk/U-Statistics-Python", "summary": "Higher-order $U$-statistics abound in fields such as statistics, machine\nlearning, and computer science, but are known to be highly time-consuming to\ncompute in practice. Despite their widespread appearance, a comprehensive study\nof their computational complexity is surprisingly lacking. This paper aims to\nfill that gap by presenting several results related to the computational aspect\nof $U$-statistics. First, we derive a useful decomposition from an $m$-th order\n$U$-statistic to a linear combination of $V$-statistics with orders not\nexceeding $m$, which are generally more feasible to compute. Second, we explore\nthe connection between exactly computing $V$-statistics and Einstein summation,\na tool often used in computational mathematics, quantum computing, and quantum\ninformation sciences for accelerating tensor computations. Third, we provide an\noptimistic estimate of the time complexity for exactly computing\n$U$-statistics, based on the treewidth of a particular graph associated with\nthe $U$-statistic kernel. The above ingredients lead to a new, much more\nruntime-efficient algorithm of exactly computing general higher-order\n$U$-statistics. We also wrap our new algorithm into an open-source Python\npackage called $\\texttt{u-stats}$. We demonstrate via three statistical\napplications that $\\texttt{u-stats}$ achieves impressive runtime performance\ncompared to existing benchmarks. This paper aspires to achieve two goals: (1)\nto capture the interest of researchers in both statistics and other related\nareas further to advance the algorithmic development of $U$-statistics, and (2)\nto offer the package $\\texttt{u-stats}$ as a valuable tool for practitioners,\nmaking the implementation of methods based on higher-order $U$-statistics a\nmore delightful experience."}
{"id": "2508.12627", "pdf": "https://arxiv.org/pdf/2508.12627", "abs": "https://arxiv.org/abs/2508.12627", "authors": ["Xingyu Chen", "Ruiqi Zhang", "Lin Liu"], "title": "On computing and the complexity of computing higher-order $U$-statistics, exactly", "categories": ["stat.ML", "cs.DS", "cs.NA", "math.NA", "stat.CO", "stat.ME"], "comment": "Comments are welcome! 49 pages, 8 tables, 4 figures. An accompanying\n  Python package is available at: https://libraries.io/pypi/u-stats or\n  https://github.com/Amedar-Asterisk/U-Statistics-Python", "summary": "Higher-order $U$-statistics abound in fields such as statistics, machine\nlearning, and computer science, but are known to be highly time-consuming to\ncompute in practice. Despite their widespread appearance, a comprehensive study\nof their computational complexity is surprisingly lacking. This paper aims to\nfill that gap by presenting several results related to the computational aspect\nof $U$-statistics. First, we derive a useful decomposition from an $m$-th order\n$U$-statistic to a linear combination of $V$-statistics with orders not\nexceeding $m$, which are generally more feasible to compute. Second, we explore\nthe connection between exactly computing $V$-statistics and Einstein summation,\na tool often used in computational mathematics, quantum computing, and quantum\ninformation sciences for accelerating tensor computations. Third, we provide an\noptimistic estimate of the time complexity for exactly computing\n$U$-statistics, based on the treewidth of a particular graph associated with\nthe $U$-statistic kernel. The above ingredients lead to a new, much more\nruntime-efficient algorithm of exactly computing general higher-order\n$U$-statistics. We also wrap our new algorithm into an open-source Python\npackage called $\\texttt{u-stats}$. We demonstrate via three statistical\napplications that $\\texttt{u-stats}$ achieves impressive runtime performance\ncompared to existing benchmarks. This paper aspires to achieve two goals: (1)\nto capture the interest of researchers in both statistics and other related\nareas further to advance the algorithmic development of $U$-statistics, and (2)\nto offer the package $\\texttt{u-stats}$ as a valuable tool for practitioners,\nmaking the implementation of methods based on higher-order $U$-statistics a\nmore delightful experience."}
{"id": "2508.12485", "pdf": "https://arxiv.org/pdf/2508.12485", "abs": "https://arxiv.org/abs/2508.12485", "authors": ["Aayush Gupta", "Arpit Bhayani"], "title": "Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.NI", "C.2.4; C.4; D.4.2; I.2.6"], "comment": "8 pages, 4 figures (system architecture, eviction path, training\n  pipeline, and DQN algorithm), 2 tables. Code available at\n  https://github.com/ayushgupta4897/DRL-Cache", "summary": "Web proxies such as NGINX commonly rely on least-recently-used (LRU)\neviction, which is size agnostic and can thrash under periodic bursts and mixed\nobject sizes. We introduce Cold-RL, a learned eviction policy for NGINX that\nreplaces LRU's forced-expire path with a dueling Deep Q-Network served by an\nONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL\nsamples the K least-recently-used objects, extracts six lightweight features\n(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),\nand requests a bitmask of victims; a hard timeout of 500 microseconds triggers\nimmediate fallback to native LRU. Policies are trained offline by replaying\nNGINX access logs through a cache simulator with a simple reward: a retained\nobject earns one point if it is hit again before TTL expiry. We compare against\nLRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial\nworkloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,\na 146 percent improvement over the best classical baseline; at 100 MB, from\n0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods\n(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th\npercentile eviction latency within budget. To our knowledge, this is the first\nreinforcement learning eviction policy integrated into NGINX with strict SLOs."}
{"id": "2508.12961", "pdf": "https://arxiv.org/pdf/2508.12961", "abs": "https://arxiv.org/abs/2508.12961", "authors": ["Anshuman Das Mohapatra", "Kwangsung Oh"], "title": "WANify: Gauging and Balancing Runtime WAN Bandwidth for Geo-distributed Data Analytics", "categories": ["cs.DC"], "comment": "This paper is accepted for publication at the 2025 IEEE International\n  Symposium on Workload Characterization (IISWC'25)", "summary": "Accurate wide area network (WAN) bandwidth (BW) is essential for\ngeo-distributed data analytics (GDA) systems to make optimal decisions such as\ndata and task placement to improve performance. Existing GDA systems, however,\nmeasure WAN BW statically and independently between data centers (DCs), while\ndata transfer occurs dynamically and simultaneously among DCs during workload\nexecution. Also, they use a single connection WAN BW that cannot capture actual\nWAN capacities between distant DCs. Such inaccurate WAN BWs yield sub-optimal\ndecisions, inflating overall query latency and cost. In this paper, we present\nWANify, a new framework that precisely and dynamically gauges achievable\nruntime WAN BW using a machine learning prediction scheme, decision tree-based\nRandom Forest. This helps GDA systems make better decisions yielding reduced\nlatency and costs including WAN BW monitoring costs. Based on predicted runtime\nWAN BW, WANify determines the optimal number of heterogeneous parallel\nconnections for data transfer among DCs. This approach improves performance\nwithout additional, or even at reduced cost, by fully exploiting available WAN\ncapacities. In addition, WANify considers dynamics like network and workloads,\nand heterogeneity like skewed data, heterogeneous compute resources, and a\nvarying number of DCs while making decisions. The WANify prototype running on\nstate-of-the-art GDA systems is evaluated on AWS with 8 geo-distributed DCs.\nResults show that WANify enhances WAN throughput by balancing between the\nstrongest and weakest WAN links, enabling GDA systems to reduce latency and\ncost by up to 26% and 16% respectively with minimal effort, all while handling\ndynamics and heterogeneity efficiently."}
{"id": "2508.11874", "pdf": "https://arxiv.org/pdf/2508.11874", "abs": "https://arxiv.org/abs/2508.11874", "authors": ["Hanyu Li", "Dongchen Li", "Xiaotie Deng"], "title": "Discovering Expert-Level Nash Equilibrium Algorithms with Large Language Models", "categories": ["cs.GT", "cs.AI", "cs.DS", "cs.LO", "cs.PL"], "comment": null, "summary": "Algorithm design and analysis is a cornerstone of computer science, but it\nconfronts a major challenge. Proving an algorithm's performance guarantee\nacross all inputs has traditionally required extensive and often error-prone\nhuman effort. While AI has shown great success in finding solutions to specific\nproblem instances, automating the discovery of general algorithms with such\nprovable guarantees has remained a significant barrier. This challenge stems\nfrom the difficulty of integrating the creative process of algorithm design\nwith the rigorous process of formal analysis. To address this gap, we propose\nLegoNE, a framework that tightly fuses these two processes for the fundamental\nand notoriously difficult problem of computing approximate Nash equilibria.\nLegoNE automatically translates any algorithm written by a simple Python-like\nlanguage into a constrained optimization problem. Solving this problem derives\nand proves the algorithm's approximation bound. Using LegoNE, a\nstate-of-the-art large language model rediscovered the state-of-the-art\nalgorithm for two-player games within hours, a feat that had taken human\nresearchers 15 years to achieve. For three-player games, the model discovered a\nnovel algorithm surpassing all existing human-designed ones. This work\ndemonstrates a new human-machine collaborative paradigm for theoretical\nscience: humans reason at a higher-abstract level, using symbols to compress\nthe search space, and AI explores within it, achieving what neither could\nalone."}
{"id": "2508.12479", "pdf": "https://arxiv.org/pdf/2508.12479", "abs": "https://arxiv.org/abs/2508.12479", "authors": ["Chinmay Maheshwari", "Chinmay Pimpalkhare", "Debasish Chatterjee"], "title": "EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization", "categories": ["math.OC", "cs.AI", "cs.GT", "cs.MA", "econ.GN", "q-fin.EC", "90C26, 90C47, 68Q32, 91A06, 65K05"], "comment": "31 pages, 2 figures, 3 tables", "summary": "Min-max optimization arises in many domains such as game theory, adversarial\nmachine learning, etc., with gradient-based methods as a typical computational\ntool. Beyond convex-concave min-max optimization, the solutions found by\ngradient-based methods may be arbitrarily far from global optima. In this work,\nwe present an algorithmic apparatus for computing globally optimal solutions in\nconvex-non-concave and non-convex-concave min-max optimization. For former, we\nemploy a reformulation that transforms it into a non-concave-convex max-min\noptimization problem with suitably defined feasible sets and objective\nfunction. The new form can be viewed as a generalization of Sion's minimax\ntheorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm\nfor solving the reformulated max-min problem. EXOTIC employs an iterative\nconvex optimization solver to (approximately) solve the inner minimization and\na hierarchical tree search for the outer maximization to optimistically select\npromising regions to search based on the approximate solution returned by\nconvex optimization solver. We establish an upper bound on its optimality gap\nas a function of the number of calls to the inner solver, the solver's\nconvergence rate, and additional problem-dependent parameters. Both our\nalgorithmic apparatus along with its accompanying theoretical analysis can also\nbe applied for non-convex-concave min-max optimization. In addition, we propose\na class of benchmark convex-non-concave min-max problems along with their\nanalytical global solutions, providing a testbed for evaluating algorithms for\nmin-max optimization. Empirically, EXOTIC outperforms gradient-based methods on\nthis benchmark as well as on existing numerical benchmark problems from the\nliterature. Finally, we demonstrate the utility of EXOTIC by computing security\nstrategies in multi-player games with three or more players."}
{"id": "2508.12353", "pdf": "https://arxiv.org/pdf/2508.12353", "abs": "https://arxiv.org/abs/2508.12353", "authors": ["Marcel Gregoriadis", "Jingwei Kang", "Johan Pouwelse"], "title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank", "categories": ["cs.IR", "cs.AI", "cs.DC"], "comment": "Accepted at CIKM 2025", "summary": "The centralized collection of search interaction logs for training ranking\nmodels raises significant privacy concerns. Federated Online Learning to Rank\n(FOLTR) offers a privacy-preserving alternative by enabling collaborative model\ntraining without sharing raw user data. However, benchmarks in FOLTR are\nlargely based on random partitioning of classical learning-to-rank datasets,\nsimulated user clicks, and the assumption of synchronous client participation.\nThis oversimplifies real-world dynamics and undermines the realism of\nexperimental results. We present AOL4FOLTR, a large-scale web search dataset\nwith 2.6 million queries from 10,000 users. Our dataset addresses key\nlimitations of existing benchmarks by including user identifiers, real click\ndata, and query timestamps, enabling realistic user partitioning, behavior\nmodeling, and asynchronous federated learning scenarios."}
{"id": "2508.12133", "pdf": "https://arxiv.org/pdf/2508.12133", "abs": "https://arxiv.org/abs/2508.12133", "authors": ["Saem Hasan", "Muhammad Ali Nayeem", "M. Sohel Rahman"], "title": "Improving MSA Estimation through Adaptive Weight Vectors in MOEA/D", "categories": ["cs.NE", "q-bio.PE"], "comment": null, "summary": "Accurate phylogenetic inference from biological sequences depends critically\non the quality of multiple sequence alignments, yet optimal alignment for many\nsequences is computationally intractable and sensitive to scoring choices. In\nthis work we introduce MOEA/D-ADF, a novel variant of MOEA/D that adaptively\nadjusts subproblem weight vectors based on fitness variance to improve the\nexploration-exploitation trade-off. We combine MOEA/D-ADF with PMAO (PASTA with\nmany application-aware optimization criteria) to form PMAO++, where\nPMAO-generated solutions are used to seed MOEA/D-ADF, which then evolves a\npopulation using 30 weight vectors to produce a diverse ensemble of\nalignment-tree pairs. PMAO++ outperforms the original PMAO on a majority of\nbenchmark cases, achieving better false-negative (FN) rates on 12 of 17\nBAliBASE-derived datasets and producing superior best-case trees, including\nseveral instances with zero FN rate. Beyond improving single best alignments,\nthe rich set of alignment-tree pairs produced by PMAO++ is especially valuable\nfor downstream summary methods (for example, consensus and summary-tree\napproaches), allowing more robust phylogenetic inference by integrating signal\nacross multiple plausible alignments and trees. Certain dataset features, such\nas large terminal N/C extensions found in the RV40 group, remain challenging,\nbut overall PMAO++ demonstrates clear advantages for sequence-based\nphylogenetic analysis. Future work will explore parameter tuning, larger\nbenchmark suites, and tighter integration with summary-tree pipelines to\nfurther enhance applicability for biological sequence studies."}
{"id": "2508.11953", "pdf": "https://arxiv.org/pdf/2508.11953", "abs": "https://arxiv.org/abs/2508.11953", "authors": ["Yuan Li", "Zhengzhong Liu", "Eric Xing"], "title": "Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Optimizing data mixtures for supervised fine-tuning (SFT) of large language\nmodels (LLMs) is critical for developing general-purpose models, yet this area\nremains underexplored. In this paper, we frame data mixing as an optimization\nproblem and introduce a novel method designed to minimize validation loss. Our\napproach parametrizes the loss by modeling effective data transferred and\nleveraging scaling laws for fine-tuning. By experimenting with various\nsmall-scale data mixtures, we fit these parameters and derive the optimal\nweights. We provide both mathematical proofs and empirical results\ndemonstrating that our algorithm achieves excellent overall and individual\nperformance across all domains. Through controlled experiments, we show that\nmodels trained with our optimized weights perform on par with those using\noptimal weights determined via grid search, with per-domain loss only 0.66%\nhigher than the best domain loss from grid search on average. Additionally, we\nshow that reweighting popular SFT datasets using our method improves both\nvalidation loss and downstream performance. Finally, we discuss how our method\ncan generalize to guide data selection for domain-specific models and provide\ninsights into SFT."}
{"id": "2508.11993", "pdf": "https://arxiv.org/pdf/2508.11993", "abs": "https://arxiv.org/abs/2508.11993", "authors": ["Kota Someya", "Lei Chen", "Michael J. Decker", "Shinpei Hayashi"], "title": "How Much Can a Behavior-Preserving Changeset Be Decomposed into Refactoring Operations?", "categories": ["cs.SE"], "comment": "(C) 2025 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Developers sometimes mix behavior-preserving modifications, such as\nrefactorings, with behavior-altering modifications, such as feature additions.\nSeveral approaches have been proposed to support understanding such\nmodifications by separating them into those two parts. Such refactoring-aware\napproaches are expected to be particularly effective when the\nbehavior-preserving parts can be decomposed into a sequence of more primitive\nbehavior-preserving operations, such as refactorings, but this has not been\nexplored. In this paper, as an initial validation, we quantify how much of the\nbehavior-preserving modifications can be decomposed into refactoring operations\nusing a dataset of functionally-equivalent method pairs. As a result, when\nusing an existing refactoring detector, only 33.9% of the changes could be\nidentified as refactoring operations. In contrast, when including 67 newly\ndefined functionally-equivalent operations, the coverage increased by over\n128%. Further investigation into the remaining unexplained differences was\nconducted, suggesting improvement opportunities."}
{"id": "2508.12457", "pdf": "https://arxiv.org/pdf/2508.12457", "abs": "https://arxiv.org/abs/2508.12457", "authors": ["Sebastian G. Nosenzo", "Rafael Kelman"], "title": "From fields to fuel: analyzing the global economic and emissions potential of agricultural pellets, informed by a case study", "categories": ["econ.GN", "q-fin.EC"], "comment": "54 pages, 12 figures", "summary": "Agricultural residues represent a vast, underutilized resource for renewable\nenergy. This study combines empirical analysis from 179 countries with a case\nstudy of a pelletization facility to evaluate the global potential of\nagricultural pelletization for fossil fuel replacement. The findings estimate a\ntechnical availability of 1.44 billion tons of crop residues suitable for\npellet production, translating to a 4.5% potential displacement of global\nfossil fuel energy use, equating to 22 million TJ and equivalent to 917 million\ntons of coal annually. The economically optimized scenario projects annual\nsavings of $163 billion and a reduction of 1.35 billion tons of CO2 equivalent\nin emissions. Utilizing the custom-developed CLASP-P and RECOP models, the\nstudy further demonstrates that agricultural pellets can achieve competitive\npricing against conventional fossil fuels in many markets. Despite logistical\nand policy challenges, agricultural pelletization emerges as a scalable,\nmarket-driven pathway to support global decarbonization goals while fostering\nrural economic development. These results reinforce the need for targeted\ninvestment, technological advancement, and supportive policy to unlock the full\npotential of agricultural pellets in the renewable energy mix."}
{"id": "2508.12457", "pdf": "https://arxiv.org/pdf/2508.12457", "abs": "https://arxiv.org/abs/2508.12457", "authors": ["Sebastian G. Nosenzo", "Rafael Kelman"], "title": "From fields to fuel: analyzing the global economic and emissions potential of agricultural pellets, informed by a case study", "categories": ["econ.GN", "q-fin.EC"], "comment": "54 pages, 12 figures", "summary": "Agricultural residues represent a vast, underutilized resource for renewable\nenergy. This study combines empirical analysis from 179 countries with a case\nstudy of a pelletization facility to evaluate the global potential of\nagricultural pelletization for fossil fuel replacement. The findings estimate a\ntechnical availability of 1.44 billion tons of crop residues suitable for\npellet production, translating to a 4.5% potential displacement of global\nfossil fuel energy use, equating to 22 million TJ and equivalent to 917 million\ntons of coal annually. The economically optimized scenario projects annual\nsavings of $163 billion and a reduction of 1.35 billion tons of CO2 equivalent\nin emissions. Utilizing the custom-developed CLASP-P and RECOP models, the\nstudy further demonstrates that agricultural pellets can achieve competitive\npricing against conventional fossil fuels in many markets. Despite logistical\nand policy challenges, agricultural pelletization emerges as a scalable,\nmarket-driven pathway to support global decarbonization goals while fostering\nrural economic development. These results reinforce the need for targeted\ninvestment, technological advancement, and supportive policy to unlock the full\npotential of agricultural pellets in the renewable energy mix."}
{"id": "2508.11680", "pdf": "https://arxiv.org/pdf/2508.11680", "abs": "https://arxiv.org/abs/2508.11680", "authors": ["Aditya Akella", "Jonathan Farah"], "title": "Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics", "categories": ["cs.LG", "cs.AI", "es: 62M10 (primary), 62P20, 68T05, 91B72 (secondary)"], "comment": "6 pages, 4 figures, 3 tables", "summary": "Demographic shifts, influenced by globalization, economic conditions,\ngeopolitical events, and environmental factors, pose significant challenges for\npolicymakers and researchers. Accurate demographic forecasting is essential for\ninformed decision-making in areas such as urban planning, healthcare, and\neconomic policy. This study explores the application of time series foundation\nmodels to predict demographic changes in the United States using datasets from\nthe U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate\nthe performance of the Time Series Foundation Model (TimesFM) against\ntraditional baselines including Long Short-Term Memory (LSTM) networks,\nAutoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our\nexperiments across six demographically diverse states demonstrate that TimesFM\nachieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with\nparticularly strong performance on minority populations with sparse historical\ndata. These findings highlight the potential of pre-trained foundation models\nto enhance demographic analysis and inform proactive policy interventions\nwithout requiring extensive task-specific fine-tuning."}
{"id": "2508.12674", "pdf": "https://arxiv.org/pdf/2508.12674", "abs": "https://arxiv.org/abs/2508.12674", "authors": ["Haruka Ezoe", "Hiroki Matsumoto", "Ryohei Hisano"], "title": "Unfolded Laplacian Spectral Embedding: A Theoretically Grounded Approach to Dynamic Network Representation", "categories": ["stat.ML", "cs.LG", "cs.SI"], "comment": null, "summary": "Dynamic relational structures play a central role in many AI tasks, but their\nevolving nature presents challenges for consistent and interpretable\nrepresentation. A common approach is to learn time-varying node embeddings,\nwhose effectiveness depends on satisfying key stability properties. In this\npaper, we propose Unfolded Laplacian Spectral Embedding, a new method that\nextends the Unfolded Adjacency Spectral Embedding framework to normalized\nLaplacians while preserving both cross-sectional and longitudinal stability. We\nprovide formal proof that our method satisfies these stability conditions. In\naddition, as a bonus of using the Laplacian matrix, we establish a new\nCheeger-style inequality that connects the embeddings to the conductance of the\nunderlying dynamic graphs. Empirical evaluations on synthetic and real-world\ndatasets support our theoretical findings and demonstrate the strong\nperformance of our method. These results establish a principled and stable\nframework for dynamic network representation grounded in spectral graph theory."}
{"id": "2508.12970", "pdf": "https://arxiv.org/pdf/2508.12970", "abs": "https://arxiv.org/abs/2508.12970", "authors": ["Sayantan Banerjee", "Agnieszka Wylomanska", "Sundar S"], "title": "A self-supervised learning approach for denoising autoregressive models with additive noise: finite and infinite variance cases", "categories": ["stat.ME", "stat.CO", "stat.ML"], "comment": "32 pages, 17 figures", "summary": "The autoregressive time series model is a popular second-order stationary\nprocess, modeling a wide range of real phenomena. However, in applications,\nautoregressive signals are often corrupted by additive noise. Further, the\nautoregressive process and the corruptive noise may be highly impulsive,\nstemming from an infinite-variance distribution. The model estimation\ntechniques that account for additional noise tend to show reduced efficacy when\nthere is very strong noise present in the data, especially when the noise is\nheavy-tailed. Moreover, identification of a model corrupted with heavy-tailed,\nparticularly infinite-variance noise, can be a very challenging task. In this\npaper, we propose a novel self-supervised learning method to denoise the\nadditive noise-corrupted autoregressive model. Our approach is motivated by\nrecent work in computer vision and does not require full knowledge of the noise\ndistribution. We use the proposed method to recover exemplary finite- and\ninfinite-variance autoregressive signals, namely, Gaussian- and alpha-stable\ndistributed signals, respectively, from their noise-corrupted versions. The\nsimulation study conducted on both synthetic and semi-synthetic data\ndemonstrates the efficiency of our method compared to several baseline methods,\nparticularly when the corruption is significant and impulsive in nature.\nFinally, we apply the presented methodology to forecast the pure autoregressive\nsignal from the noise-corrupted data."}
{"id": "2508.12868", "pdf": "https://arxiv.org/pdf/2508.12868", "abs": "https://arxiv.org/abs/2508.12868", "authors": ["Yilin Geng", "Shujing Wang", "Chuan Wang", "Keqing He", "Yanfei Lv", "Ying Wang", "Zaiwen Feng", "Xiaoying Bai"], "title": "An LLM Agent-Based Complex Semantic Table Annotation Approach", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "The Semantic Table Annotation (STA) task, which includes Column Type\nAnnotation (CTA) and Cell Entity Annotation (CEA), maps table contents to\nontology entities and plays important roles in various semantic applications.\nHowever, complex tables often pose challenges such as semantic loss of column\nnames or cell values, strict ontological hierarchy requirements, homonyms,\nspelling errors, and abbreviations, which hinder annotation accuracy. To\naddress these issues, this paper proposes an LLM-based agent approach for CTA\nand CEA. We design and implement five external tools with tailored prompts\nbased on the ReAct framework, enabling the STA agent to dynamically select\nsuitable annotation strategies depending on table characteristics. Experiments\nare conducted on the Tough Tables and BiodivTab datasets from the SemTab\nchallenge, which contain the aforementioned challenges. Our method outperforms\nexisting approaches across various metrics. Furthermore, by leveraging\nLevenshtein distance to reduce redundant annotations, we achieve a 70%\nreduction in time costs and a 60% reduction in LLM token usage, providing an\nefficient and cost-effective solution for STA."}
{"id": "2508.13083", "pdf": "https://arxiv.org/pdf/2508.13083", "abs": "https://arxiv.org/abs/2508.13083", "authors": ["Joshua Z. Sobel"], "title": "Congested Clique Counting for Local Gibbs Distributions", "categories": ["cs.DC", "cs.DS"], "comment": null, "summary": "There are well established reductions between combinatorial sampling and\ncounting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very\nrecent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv\n2024), we demonstrate the first approximate counting algorithm in the\nCongestedClique for a wide range of problems. Most interestingly, we present an\nalgorithm for approximating the number of $q$-colorings of a graph within\n$\\epsilon$-multiplicative error, when $q>\\alpha\\Delta$ for any constant\n$\\alpha>2$, in $\\Tilde{O}\\big(\\frac{n^{1/3}}{\\epsilon^2}\\big)$ rounds. More\ngenerally, we achieve a runtime of\n$\\Tilde{O}\\big(\\frac{n^{1/3}}{\\epsilon^2}\\big)$ rounds for approximating the\npartition function of Gibbs distributions defined over graphs when simple\nlocality and fast mixing conditions hold. Gibbs distributions are widely used\nin fields such as machine learning and statistical physics. We obtain our\nresult by providing an algorithm to draw $n$ random samples from a distributed\nMarkov chain in parallel, using similar ideas to triangle counting (Dolev,\nLenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel,\nKaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems,\nthis result may be interesting for other applications requiring a large number\nof samples. In the special case of estimating the partition function of the\nhardcore model, also known as counting weighted independent sets, we can do\neven better and achieve an $\\Tilde{O}\\big(\\frac{1}{\\epsilon^2}\\big)$ round\nalgorithm, when the fugacity $\\lambda \\leq \\frac{\\alpha}{\\Delta-1}$, where\n$\\alpha$ is an arbitrary constant less than $1$."}
{"id": "2508.12453", "pdf": "https://arxiv.org/pdf/2508.12453", "abs": "https://arxiv.org/abs/2508.12453", "authors": ["Martin Jupakkal Andersen", "Ioannis Caragiannis", "Anders Bo Ipsen", "Alexander Søltoft"], "title": "Computing Approximately Proportional Allocations of Indivisible Goods: Beyond Additive and Monotone Valuations", "categories": ["cs.GT", "cs.DS"], "comment": null, "summary": "Although approximate notions of envy-freeness-such as envy-freeness up to one\ngood (EF1)-have been extensively studied for indivisible goods, the seemingly\nsimpler fairness concept of proportionality up to one good (PROP1) has received\nfar less attention. For additive valuations, every EF1 allocation is PROP1, and\nwell-known algorithms such as Round-Robin and Envy-Cycle Elimination compute\nsuch allocations in polynomial time. PROP1 is also compatible with Pareto\nefficiency, as maximum Nash welfare allocations are EF1 and hence PROP1.\n  We ask whether these favorable properties extend to non-additive valuations.\nWe study a broad class of allocation instances with {\\em satiating goods},\nwhere agents have non-negative valuation functions that need not be monotone,\nallowing for negative marginal values. We present the following results:\n  - EF1 implies PROP1 for submodular valuations over satiating goods, ensuring\nexistence and efficient computation via Envy-Cycle Elimination for monotone\nsubmodular valuations;\n  - Round-robin computes a partial PROP1 allocation after the second-to-last\nround for satiating submodular goods and a complete PROP1 for monotone\nsubmodular valuations;\n  - PROP1 allocations for satiating subadditive goods can be computed in\npolynomial-time;\n  - Maximum Nash welfare allocations are PROP1 for monotone submodular goods,\nrevealing yet another facet of their ``unreasonable fairness.''"}
{"id": "2508.12583", "pdf": "https://arxiv.org/pdf/2508.12583", "abs": "https://arxiv.org/abs/2508.12583", "authors": ["Adil Faisal"], "title": "Feedback Linearization for Replicator Dynamics: A Control Framework for Evolutionary Game Convergence", "categories": ["eess.SY", "cs.GT", "cs.MA", "cs.SY", "math.DS"], "comment": "14 pages, 10 figures feel free to contact author at adil121@bu.edu\n  with any questions, comments, and concerns", "summary": "This paper demonstrates the first application of feedback linearization to\nreplicator dynamics, driving the evolution of non-convergent evolutionary games\nto systems with guaranteed global asymptotic stability."}
{"id": "2508.12365", "pdf": "https://arxiv.org/pdf/2508.12365", "abs": "https://arxiv.org/abs/2508.12365", "authors": ["Chenhe Dong", "Shaowei Yao", "Pengkun Jiao", "Jianhui Yang", "Yiming Jin", "Zerui Huang", "Xiaojiang Zhou", "Dan Ou", "Haihong Tang"], "title": "TaoSR1: The Thinking Model for E-commerce Relevance Search", "categories": ["cs.IR"], "comment": null, "summary": "Query-product relevance prediction is a core task in e-commerce search.\nBERT-based models excel at semantic matching but lack complex reasoning\ncapabilities. While Large Language Models (LLMs) are explored, most still use\ndiscriminative fine-tuning or distill to smaller models for deployment. We\npropose a framework to directly deploy LLMs for this task, addressing key\nchallenges: Chain-of-Thought (CoT) error accumulation, discriminative\nhallucination, and deployment feasibility. Our framework, TaoSR1, involves\nthree stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning;\n(2) Offline sampling with a pass@N strategy and Direct Preference Optimization\n(DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling\nwith Group Relative Policy Optimization (GRPO) to mitigate discriminative\nhallucination. Additionally, post-CoT processing and a cumulative\nprobability-based partitioning method enable efficient online deployment.\nTaoSR1 significantly outperforms baselines on offline datasets and achieves\nsubstantial gains in online side-by-side human evaluations, introducing a novel\nparadigm for applying CoT reasoning to relevance classification."}
{"id": "2508.12609", "pdf": "https://arxiv.org/pdf/2508.12609", "abs": "https://arxiv.org/abs/2508.12609", "authors": ["Qingyan Meng", "Mingqing Xiao", "Zhengyu Ma", "Huihui Zhou", "Yonghong Tian", "Zhouchen Lin"], "title": "A Self-Ensemble Inspired Approach for Effective Training of Binary-Weight Spiking Neural Networks", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are a promising approach to low-power\napplications on neuromorphic hardware due to their energy efficiency. However,\ntraining SNNs is challenging because of the non-differentiable spike generation\nfunction. To address this issue, the commonly used approach is to adopt the\nbackpropagation through time framework, while assigning the gradient of the\nnon-differentiable function with some surrogates. Similarly, Binary Neural\nNetworks (BNNs) also face the non-differentiability problem and rely on\napproximating gradients. However, the deep relationship between these two\nfields and how their training techniques can benefit each other has not been\nsystematically researched. Furthermore, training binary-weight SNNs is even\nmore difficult. In this work, we present a novel perspective on the dynamics of\nSNNs and their close connection to BNNs through an analysis of the\nbackpropagation process. We demonstrate that training a feedforward SNN can be\nviewed as training a self-ensemble of a binary-activation neural network with\nnoise injection. Drawing from this new understanding of SNN dynamics, we\nintroduce the Self-Ensemble Inspired training method for (Binary-Weight) SNNs\n(SEI-BWSNN), which achieves high-performance results with low latency even for\nthe case of the 1-bit weights. Specifically, we leverage a structure of\nmultiple shortcuts and a knowledge distillation-based training technique to\nimprove the training of (binary-weight) SNNs. Notably, by binarizing FFN layers\nin a Transformer architecture, our approach achieves 82.52% accuracy on\nImageNet with only 2 time steps, indicating the effectiveness of our\nmethodology and the potential of binary-weight SNNs."}
{"id": "2508.11954", "pdf": "https://arxiv.org/pdf/2508.11954", "abs": "https://arxiv.org/abs/2508.11954", "authors": ["Sehyuk Park", "Soyeon Caren Han", "Eduard Hovy"], "title": "UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting", "categories": ["cs.AI"], "comment": null, "summary": "Time series forecasting is a foundational task across domains, such as\nfinance, healthcare, and environmental monitoring. While recent advances in\nTime Series Foundation Models (TSFMs) have demonstrated strong generalisation\nthrough large-scale pretraining, existing models operate predominantly in a\nunimodal setting, ignoring the rich multimodal context, such as visual and\ntextual signals, that often accompanies time series data in real-world\nscenarios. This paper introduces a novel parameter-efficient multimodal\nframework, UniCast, that extends TSFMs to jointly leverage time series, vision,\nand text modalities for enhanced forecasting performance. Our method integrates\nmodality-specific embeddings from pretrained Vision and Text Encoders with a\nfrozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal\nparameter updates. This design not only preserves the generalisation strength\nof the foundation model but also enables effective cross-modal interaction.\nExtensive experiments across diverse time-series forecasting benchmarks\ndemonstrate that UniCast consistently and significantly outperforms all\nexisting TSFM baselines. The findings highlight the critical role of multimodal\ncontext in advancing the next generation of general-purpose time series\nforecasters."}
{"id": "2508.12232", "pdf": "https://arxiv.org/pdf/2508.12232", "abs": "https://arxiv.org/abs/2508.12232", "authors": ["Arshia Akhavan", "Alireza Hosseinpour", "Abbas Heydarnoori", "Mehdi Keshani"], "title": "LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Issue-to-commit link recovery plays an important role in software\ntraceability and improves project management. However, it remains a challenging\ntask. A study on GitHub shows that only 42.2% of the issues are correctly\nlinked to their commits. This highlights the potential for further development\nand research in this area. Existing studies have employed various AI/ML-based\napproaches, and with the recent development of large language models,\nresearchers have leveraged LLMs to tackle this problem. These approaches suffer\nfrom two main issues. First, LLMs are constrained by limited context windows\nand cannot ingest all of the available data sources, such as long commit\nhistories, extensive issue comments, and large code repositories. Second, most\nmethods operate on individual issue-commit pairs; that is, given a single\nissue-commit pair, they determine whether the commit resolves the issue. This\nquickly becomes impractical in real-world repositories containing tens of\nthousands of commits. To address these limitations, we present LinkAnchor, the\nfirst autonomous LLM-based agent designed for issue-to-commit link recovery.\nThe lazy-access architecture of LinkAnchor enables the underlying LLM to access\nthe rich context of software, spanning commits, issue comments, and code files,\nwithout exceeding the token limit by dynamically retrieving only the most\nrelevant contextual data. Additionally, LinkAnchor is able to automatically\npinpoint the target commit rather than exhaustively scoring every possible\ncandidate. Our evaluations show that LinkAnchor outperforms state-of-the-art\nissue-to-commit link recovery approaches by 60-262% in Hit@1 score across all\nour case study projects. We also publicly release LinkAnchor as a ready-to-use\ntool, along with our replication package. LinkAnchor is designed and tested for\nGitHub and Jira, and is easily extendable to other platforms."}
{"id": "2508.12471", "pdf": "https://arxiv.org/pdf/2508.12471", "abs": "https://arxiv.org/abs/2508.12471", "authors": ["Jheelum Sarkar"], "title": "Do STEM graduates fare better at times of Crises? Evidence from COVID 19 pandemic in India", "categories": ["econ.GN", "q-fin.EC"], "comment": "23+9 pages, 2+1 figures", "summary": "I study whether and to what extent STEM college degrees offer labor market\nresilience during the COVID 19 shock. Both the pandemic and its nationwide\nlockdown affected occupations unevenly. While some jobs could adapt by\nswitching to remote work or surging demand, others could not. Using the\nnationally representative high-frequency labor force survey data (2017-2023), I\nused a difference-in-difference strategy to compare changes in employment\nparticipation and monthly earnings between STEM and non-STEM graduates during\nand after the pandemic. The results suggest that individuals with a STEM\ncollege degree were more likely to be employed compared to their non-STEM\ncounterparts during and after the pandemic period. Although STEM graduates\nappeared to experience higher wage growth compared to their non-STEM peers, the\ndifference was statistically insignificant. Additional evidence on mechanisms\nsuggests that the results are driven by the type of industries with higher\nshare of STEM graduates, their geographical location and their career stages.\nThe main findings were robust across alternative specifications and\nfalsification tests."}
{"id": "2508.12471", "pdf": "https://arxiv.org/pdf/2508.12471", "abs": "https://arxiv.org/abs/2508.12471", "authors": ["Jheelum Sarkar"], "title": "Do STEM graduates fare better at times of Crises? Evidence from COVID 19 pandemic in India", "categories": ["econ.GN", "q-fin.EC"], "comment": "23+9 pages, 2+1 figures", "summary": "I study whether and to what extent STEM college degrees offer labor market\nresilience during the COVID 19 shock. Both the pandemic and its nationwide\nlockdown affected occupations unevenly. While some jobs could adapt by\nswitching to remote work or surging demand, others could not. Using the\nnationally representative high-frequency labor force survey data (2017-2023), I\nused a difference-in-difference strategy to compare changes in employment\nparticipation and monthly earnings between STEM and non-STEM graduates during\nand after the pandemic. The results suggest that individuals with a STEM\ncollege degree were more likely to be employed compared to their non-STEM\ncounterparts during and after the pandemic period. Although STEM graduates\nappeared to experience higher wage growth compared to their non-STEM peers, the\ndifference was statistically insignificant. Additional evidence on mechanisms\nsuggests that the results are driven by the type of industries with higher\nshare of STEM graduates, their geographical location and their career stages.\nThe main findings were robust across alternative specifications and\nfalsification tests."}
{"id": "2508.11723", "pdf": "https://arxiv.org/pdf/2508.11723", "abs": "https://arxiv.org/abs/2508.11723", "authors": ["Qian Cao", "Jielin Chen", "Junchao Zhao", "Rudi Stouffs"], "title": "From Heuristics to Data: Quantifying Site Planning Layout Indicators with Deep Learning and Multi-Modal Data", "categories": ["cs.LG", "68T07, 91D10", "I.2.10; H.2.8"], "comment": "42 pages, 32 figures, submitted to Environment and Planning B: Urban\n  Analytics and City Science", "summary": "The spatial layout of urban sites shapes land-use efficiency and spatial\norganization. Traditional site planning often relies on experiential judgment\nand single-source data, limiting systematic quantification of multifunctional\nlayouts. We propose a Site Planning Layout Indicator (SPLI) system, a\ndata-driven framework integrating empirical knowledge with heterogeneous\nmulti-source data to produce structured urban spatial information. The SPLI\nsupports multimodal spatial data systems for analytics, inference, and\nretrieval by combining OpenStreetMap (OSM), Points of Interest (POI), building\nmorphology, land use, and satellite imagery. It extends conventional metrics\nthrough five dimensions: (1) Hierarchical Building Function Classification,\nrefining empirical systems into clear hierarchies; (2) Spatial Organization,\nquantifying seven layout patterns (e.g., symmetrical, concentric,\naxial-oriented); (3) Functional Diversity, transforming qualitative assessments\ninto measurable indicators using Functional Ratio (FR) and Simpson Index (SI);\n(4) Accessibility to Essential Services, integrating facility distribution and\ntransport networks for comprehensive accessibility metrics; and (5) Land Use\nIntensity, using Floor Area Ratio (FAR) and Building Coverage Ratio (BCR) to\nassess utilization efficiency. Data gaps are addressed through deep learning,\nincluding Relational Graph Neural Networks (RGNN) and Graph Neural Networks\n(GNN). Experiments show the SPLI improves functional classification accuracy\nand provides a standardized basis for automated, data-driven urban spatial\nanalytics."}
{"id": "2508.12834", "pdf": "https://arxiv.org/pdf/2508.12834", "abs": "https://arxiv.org/abs/2508.12834", "authors": ["Hiroshi Horii", "Sothea Has"], "title": "Optimal Condition for Initialization Variance in Deep Neural Networks: An SGD Dynamics Perspective", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Stochastic gradient descent (SGD), one of the most fundamental optimization\nalgorithms in machine learning (ML), can be recast through a continuous-time\napproximation as a Fokker-Planck equation for Langevin dynamics, a viewpoint\nthat has motivated many theoretical studies. Within this framework, we study\nthe relationship between the quasi-stationary distribution derived from this\nequation and the initial distribution through the Kullback-Leibler (KL)\ndivergence. As the quasi-steady-state distribution depends on the expected cost\nfunction, the KL divergence eventually reveals the connection between the\nexpected cost function and the initialization distribution. By applying this to\ndeep neural network models (DNNs), we can express the bounds of the expected\nloss function explicitly in terms of the initialization parameters. Then, by\nminimizing this bound, we obtain an optimal condition of the initialization\nvariance in the Gaussian case. This result provides a concrete mathematical\ncriterion, rather than a heuristic approach, to select the scale of weight\ninitialization in DNNs. In addition, we experimentally confirm our theoretical\nresults by using the classical SGD to train fully connected neural networks on\nthe MNIST and Fashion-MNIST datasets. The result shows that if the variance of\nthe initialization distribution satisfies our theoretical optimal condition,\nthen the corresponding DNN model always achieves lower final training loss and\nhigher test accuracy than the conventional He-normal initialization. Our work\nthus supplies a mathematically grounded indicator that guides the choice of\ninitialization variance and clarifies its physical meaning of the dynamics of\nparameters in DNNs."}
{"id": "2508.12975", "pdf": "https://arxiv.org/pdf/2508.12975", "abs": "https://arxiv.org/abs/2508.12975", "authors": ["Jonas Oberste-Frielinghaus", "Anno C. Kurth", "Julian Göltz", "Laura Kriener", "Junji Ito", "Mihai A. Petrovici", "Sonja Grün"], "title": "Synchronization and semantization in deep spiking networks", "categories": ["q-bio.NC", "cs.NE", "stat.CO"], "comment": "16 pages, 4 figures, 4 supplementary figures", "summary": "Recent studies have shown how spiking networks can learn complex\nfunctionality through error-correcting plasticity, but the resulting structures\nand dynamics remain poorly studied. To elucidate how these models may link to\nobserved dynamics in vivo and thus how they may ultimately explain cortical\ncomputation, we need a better understanding of their emerging patterns. We\ntrain a multi-layer spiking network, as a conceptual analog of the bottom-up\nvisual hierarchy, for visual input classification using spike-time encoding.\nAfter learning, we observe the development of distinct spatio-temporal activity\npatterns. While input patterns are synchronous by construction, activity in\nearly layers first spreads out over time, followed by re-convergence into sharp\npulses as classes are gradually extracted. The emergence of synchronicity is\naccompanied by the formation of increasingly distinct pathways, reflecting the\ngradual semantization of input activity. We thus observe hierarchical networks\nlearning spike latency codes to naturally acquire activity patterns\ncharacterized by synchronicity and separability, with pronounced excitatory\npathways ascending through the layers. This provides a rigorous computational\nhypothesis for the experimentally observed synchronicity in the visual system\nas a natural consequence of deep learning in cortex."}
{"id": "2508.13084", "pdf": "https://arxiv.org/pdf/2508.13084", "abs": "https://arxiv.org/abs/2508.13084", "authors": ["Yuval Emek", "Shay Kutten", "Ido Rafael", "Gadi Taubenfeld"], "title": "Team Formation and Applications", "categories": ["cs.DC"], "comment": "An extended abstract of this paper was accepted to DISC 2025", "summary": "A novel long-lived distributed problem, called Team Formation (TF), is\nintroduced together with a message- and time-efficient randomized algorithm.\nThe problem is defined over the asynchronous model with a complete\ncommunication graph, using bounded size messages, where a certain fraction of\nthe nodes may experience a generalized, strictly stronger, version of initial\nfailures. The goal of a TF algorithm is to assemble tokens injected by the\nenvironment, in a distributed manner, into teams of size $\\sigma$, where\n$\\sigma$ is a parameter of the problem.\n  The usefulness of TF is demonstrated by using it to derive efficient\nalgorithms for many distributed problems. Specifically, we show that various\n(one-shot as well as long-lived) distributed problems reduce to TF. This\nincludes well-known (and extensively studied) distributed problems such as\nseveral versions of leader election and threshold detection. For example, we\nare the first to break the linear message complexity bound for asynchronous\nimplicit leader election. We also improve the time complexity of\nmessage-optimal algorithms for asynchronous explicit leader election. Other\ndistributed problems that reduce to TF are new ones, including matching players\nin online gaming platforms, a generalization of gathering, constructing a\nperfect matching in an induced subgraph of the complete graph, quorum sensing\nin message-passing networks, and more. To complement our positive contribution,\nwe establish a tight lower bound on the message complexity of TF algorithms."}
{"id": "2508.12536", "pdf": "https://arxiv.org/pdf/2508.12536", "abs": "https://arxiv.org/abs/2508.12536", "authors": ["Yasuo Tabei"], "title": "jXBW: Fast Substructure Search in Large-Scale JSONL Datasets for Foundation Model Applications", "categories": ["cs.DB", "cs.DS", "cs.IR"], "comment": null, "summary": "Substructure search in JSON Lines (JSONL) datasets is essential for modern\napplications such as prompt engineering in foundation models, but existing\nmethods suffer from prohibitive computational costs due to exhaustive tree\ntraversal and subtree matching. We present jXBW, a fast method for substructure\nsearch on large-scale JSONL datasets. Our method makes three key technical\ncontributions: (i) a merged tree representation built by merging trees of\nmultiple JSON objects while preserving individual identities, (ii) a succinct\ndata structure based on the eXtended Burrows-Wheeler Transform that enables\nefficient tree navigation and subpath search, and (iii) an efficient three-step\nsubstructure search algorithm that combines path decomposition, ancestor\ncomputation, and adaptive tree identifier collection to ensure correctness\nwhile avoiding exhaustive tree traversal. Experimental evaluation on real-world\ndatasets demonstrates that jXBW consistently outperforms existing methods,\nachieving speedups of 16$\\times$ for smaller datasets and up to 4,700$\\times$\nfor larger datasets over tree-based approaches, and more than 6$\\times$10$^6$\nover XML-based processing while maintaining competitive memory usage."}
{"id": "2508.12377", "pdf": "https://arxiv.org/pdf/2508.12377", "abs": "https://arxiv.org/abs/2508.12377", "authors": ["Yang Xu", "Zuliang Yang", "Kai Ming Ting"], "title": "Contrastive Multi-View Graph Hashing", "categories": ["cs.IR"], "comment": null, "summary": "Multi-view graph data, which both captures node attributes and rich\nrelational information from diverse sources, is becoming increasingly prevalent\nin various domains. The effective and efficient retrieval of such data is an\nimportant task. Although multi-view hashing techniques have offered a paradigm\nfor fusing diverse information into compact binary codes, they typically assume\nattributes-based inputs per view. This makes them unsuitable for multi-view\ngraph data, where effectively encoding and fusing complex topological\ninformation from multiple heterogeneous graph views to generate unified binary\nembeddings remains a significant challenge. In this work, we propose\nContrastive Multi-view Graph Hashing (CMGHash), a novel end-to-end framework\ndesigned to learn unified and discriminative binary embeddings from multi-view\ngraph data. CMGHash learns a consensus node representation space using a\ncontrastive multi-view graph loss, which aims to pull $k$-nearest neighbors\nfrom all graphs closer while pushing away negative pairs, i.e., non-neighbor\nnodes. Moreover, we impose binarization constraints on this consensus space,\nenabling its conversion to a corresponding binary embedding space at minimal\ncost. Extensive experiments on several benchmark datasets demonstrate that\nCMGHash significantly outperforms existing approaches in terms of retrieval\naccuracy."}
{"id": "2508.12846", "pdf": "https://arxiv.org/pdf/2508.12846", "abs": "https://arxiv.org/abs/2508.12846", "authors": ["Wiktor J. Szczerek", "Artur Podobas"], "title": "IzhiRISC-V -- a RISC-V-based Processor with Custom ISA Extension for Spiking Neuron Networks Processing with Izhikevich Neurons", "categories": ["cs.NE", "cs.AR"], "comment": null, "summary": "Spiking Neural Network processing promises to provide high energy efficiency\ndue to the sparsity of the spiking events. However, when realized on\ngeneral-purpose hardware -- such as a RISC-V processor -- this promise can be\nundermined and overshadowed by the inefficient code, stemming from repeated\nusage of basic instructions for updating all the neurons in the network. One of\nthe possible solutions to this issue is the introduction of a custom ISA\nextension with neuromorphic instructions for spiking neuron updating, and\nrealizing those instructions in bespoke hardware expansion to the existing ALU.\nIn this paper, we present the first step towards realizing a large-scale system\nbased on the RISC-V-compliant processor called IzhiRISC-V, supporting the\ncustom neuromorphic ISA extension."}
{"id": "2508.11959", "pdf": "https://arxiv.org/pdf/2508.11959", "abs": "https://arxiv.org/abs/2508.11959", "authors": ["Xuanxiang Huang", "Olivier Létoffé", "Joao Marques-Silva"], "title": "Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index", "categories": ["cs.AI"], "comment": null, "summary": "Feature attribution methods based on game theory are ubiquitous in the field\nof eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous\nfeature attribution using logic-based explanations, specifically targeting\nhigh-stakes uses of machine learning (ML) models. Typically, such works exploit\nweak abductive explanation (WAXp) as the characteristic function to assign\nimportance to features. However, one possible downside is that the contribution\nof non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important\ninformation, because of the relationship between formal explanations (XPs) and\nadversarial examples (AExs). Accordingly, this paper leverages Shapley value\nand Banzhaf index to devise two novel feature importance scores. We take into\naccount non-WAXp sets when computing feature contribution, and the novel scores\nquantify how effective each feature is at excluding AExs. Furthermore, the\npaper identifies properties and studies the computational complexity of the\nproposed scores."}
{"id": "2508.12285", "pdf": "https://arxiv.org/pdf/2508.12285", "abs": "https://arxiv.org/abs/2508.12285", "authors": ["Yunbo Lyu", "Zhou Yang", "Jieke Shi", "Jianming Chang", "Yue Liu", "David Lo"], "title": "\"My productivity is boosted, but ...\" Demystifying Users' Perception on AI Coding Assistants", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "13 pages, Camera-Ready Version that will appear in ASE 2025", "summary": "This paper aims to explore fundamental questions in the era when AI coding\nassistants like GitHub Copilot are widely adopted: what do developers truly\nvalue and criticize in AI coding assistants, and what does this reveal about\ntheir needs and expectations in real-world software development? Unlike\nprevious studies that conduct observational research in controlled and\nsimulated environments, we analyze extensive, first-hand user reviews of AI\ncoding assistants, which capture developers' authentic perspectives and\nexperiences drawn directly from their actual day-to-day work contexts. We\nidentify 1,085 AI coding assistants from the Visual Studio Code Marketplace.\nAlthough they only account for 1.64% of all extensions, we observe a surge in\nthese assistants: over 90% of them are released within the past two years. We\nthen manually analyze the user reviews sampled from 32 AI coding assistants\nthat have sufficient installations and reviews to construct a comprehensive\ntaxonomy of user concerns and feedback about these assistants. We manually\nannotate each review's attitude when mentioning certain aspects of coding\nassistants, yielding nuanced insights into user satisfaction and\ndissatisfaction regarding specific features, concerns, and overall tool\nperformance. Built on top of the findings-including how users demand not just\nintelligent suggestions but also context-aware, customizable, and\nresource-efficient interactions-we propose five practical implications and\nsuggestions to guide the enhancement of AI coding assistants that satisfy user\nneeds."}
{"id": "2508.12507", "pdf": "https://arxiv.org/pdf/2508.12507", "abs": "https://arxiv.org/abs/2508.12507", "authors": ["Megan Yeo", "Sebastian Nosenzo", "Daniel S. Palmer", "Alexei K. Varah", "Lucas Woodley", "Ashley Nunes"], "title": "Do the rich pay their fair share? Enumerating the price of flying (and abolishing) premium air travel", "categories": ["econ.GN", "q-fin.EC"], "comment": "60 pages, 4 figures", "summary": "Premium air travel is often associated with a disproportionately large carbon\nemissions footprint. This association reflects the increased space and\namenities typically found in premium cabins that existing discourse suggests\nmakes their carriage more fuel, and consequently carbon, intensive. One\nincreasingly popular solution is disincentivizing the use of premium cabins in\nfavor of all-economy cabins. How effective might such a policy be. To what\nextent. And how may the revenue impact affect travelers. We address these\nquestions by leveraging an empirical model that integrates cabin configuration\ndata, fuel burn profiles across various aircraft types, and multi-month airfare\ndatasets. Our findings are threefold. First, we find that favoring entirely\nforegoing premium travel classes can reduce per-passenger emissions by between\n8.1 and 21.5 percent, the precise figure varying based on the type of aircraft\nand aircraft stage length involved. Second, we observe that these emissions\nreductions are far less assured on a per-flight and a lifespan basis. Here, an\nall-economy configuration can reduce emissions by 0.45 percent or increase\nemissions by as much as 1.43 percent. Third, we enumerate pronounced revenue\nconsequences associated with an all-economy configuration. This configuration\nproduces aggregate revenue declines of between 4.92 and 23.1 percent,\nnecessitating airfare increases of between 6 and 30 percent to maintain\nbaseline revenue. This increase risks imposing a profound and regressive\neconomic burden on working-class travelers who exhibit markedly higher price\nelasticities of demand compared to their wealthier counterparts and highlights\nthe cross-subsidization airlines leverage to ensure the accessibility of air\ntravel."}
{"id": "2508.12507", "pdf": "https://arxiv.org/pdf/2508.12507", "abs": "https://arxiv.org/abs/2508.12507", "authors": ["Megan Yeo", "Sebastian Nosenzo", "Daniel S. Palmer", "Alexei K. Varah", "Lucas Woodley", "Ashley Nunes"], "title": "Do the rich pay their fair share? Enumerating the price of flying (and abolishing) premium air travel", "categories": ["econ.GN", "q-fin.EC"], "comment": "60 pages, 4 figures", "summary": "Premium air travel is often associated with a disproportionately large carbon\nemissions footprint. This association reflects the increased space and\namenities typically found in premium cabins that existing discourse suggests\nmakes their carriage more fuel, and consequently carbon, intensive. One\nincreasingly popular solution is disincentivizing the use of premium cabins in\nfavor of all-economy cabins. How effective might such a policy be. To what\nextent. And how may the revenue impact affect travelers. We address these\nquestions by leveraging an empirical model that integrates cabin configuration\ndata, fuel burn profiles across various aircraft types, and multi-month airfare\ndatasets. Our findings are threefold. First, we find that favoring entirely\nforegoing premium travel classes can reduce per-passenger emissions by between\n8.1 and 21.5 percent, the precise figure varying based on the type of aircraft\nand aircraft stage length involved. Second, we observe that these emissions\nreductions are far less assured on a per-flight and a lifespan basis. Here, an\nall-economy configuration can reduce emissions by 0.45 percent or increase\nemissions by as much as 1.43 percent. Third, we enumerate pronounced revenue\nconsequences associated with an all-economy configuration. This configuration\nproduces aggregate revenue declines of between 4.92 and 23.1 percent,\nnecessitating airfare increases of between 6 and 30 percent to maintain\nbaseline revenue. This increase risks imposing a profound and regressive\neconomic burden on working-class travelers who exhibit markedly higher price\nelasticities of demand compared to their wealthier counterparts and highlights\nthe cross-subsidization airlines leverage to ensure the accessibility of air\ntravel."}
{"id": "2508.11727", "pdf": "https://arxiv.org/pdf/2508.11727", "abs": "https://arxiv.org/abs/2508.11727", "authors": ["Songyao Jin", "Biwei Huang"], "title": "Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multivariate Hawkes process provides a powerful framework for modeling\ntemporal dependencies and event-driven interactions in complex systems. While\nexisting methods primarily focus on uncovering causal structures among observed\nsubprocesses, real-world systems are often only partially observed, with latent\nsubprocesses posing significant challenges. In this paper, we show that\ncontinuous-time event sequences can be represented by a discrete-time model as\nthe time interval shrinks, and we leverage this insight to establish necessary\nand sufficient conditions for identifying latent subprocesses and the causal\ninfluences. Accordingly, we propose a two-phase iterative algorithm that\nalternates between inferring causal relationships among discovered subprocesses\nand uncovering new latent subprocesses, guided by path-based conditions that\nguarantee identifiability. Experiments on both synthetic and real-world\ndatasets show that our method effectively recovers causal structures despite\nthe presence of latent subprocesses."}
{"id": "2508.12930", "pdf": "https://arxiv.org/pdf/2508.12930", "abs": "https://arxiv.org/abs/2508.12930", "authors": ["David Hirnschall", "Robert Bajons"], "title": "The path to a goal: Understanding soccer possessions via path signatures", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a novel framework for predicting next actions in soccer\npossessions by leveraging path signatures to encode their complex\nspatio-temporal structure. Unlike existing approaches, we do not rely on fixed\nhistorical windows and handcrafted features, but rather encode the entire\nrecent possession, thereby avoiding the inclusion of potentially irrelevant or\nmisleading historical information. Path signatures naturally capture the order\nand interaction of events, providing a mathematically grounded feature encoding\nfor variable-length time series of irregular sampling frequencies without the\nnecessity for manual feature engineering. Our proposed approach outperforms a\ntransformer-based benchmark across various loss metrics and considerably\nreduces computational cost. Building on these results, we introduce a new\npossession evaluation metric based on well-established frameworks in soccer\nanalytics, incorporating both predicted action type probabilities and action\nlocation. Our metric shows greater reliability than existing metrics in\ndomain-specific comparisons. Finally, we validate our approach through a\ndetailed analysis of the 2017/18 Premier League season and discuss further\napplications and future extensions."}
{"id": "2508.11797", "pdf": "https://arxiv.org/pdf/2508.11797", "abs": "https://arxiv.org/abs/2508.11797", "authors": ["Calkin Garg", "Omar Rios Cruz", "Tessa Andersen", "Gaby G. Dagher", "Donald Winiecki", "Min Long"], "title": "AegisBlock: A Privacy-Preserving Medical Research Framework using Blockchain", "categories": ["cs.CR", "cs.DB", "cs.DC"], "comment": "Submitted to IEEE Conference on Collaboration and Internet Computing\n  2025", "summary": "Due to HIPAA and other privacy regulations, it is imperative to maintain\npatient privacy while conducting research on patient health records. In this\npaper, we propose AegisBlock, a patient-centric access controlled framework to\nshare medical records with researchers such that the anonymity of the patient\nis maintained while ensuring the trustworthiness of the data provided to\nresearchers. AegisBlock allows for patients to provide access to their medical\ndata, verified by miners. A researcher submits a time-based range query to\nrequest access to records from a certain patient, and upon patient approval,\naccess will be granted. Our experimental evaluation results show that\nAegisBlock is scalable with respect to the number of patients and hospitals in\nthe system, and efficient with up to 50% of malicious miners."}
{"id": "2508.12548", "pdf": "https://arxiv.org/pdf/2508.12548", "abs": "https://arxiv.org/abs/2508.12548", "authors": ["Vikrant Ashvinkumar", "Mursalin Habib", "Shashank Srivastava"], "title": "Algorithmic Improvements to List Decoding of Folded Reed-Solomon Codes", "categories": ["cs.IT", "cs.DS", "math.IT"], "comment": null, "summary": "Folded Reed-Solomon (FRS) codes are a well-studied family of codes, known for\nachieving list decoding capacity. In this work, we give improved deterministic\nand randomized algorithms for list decoding FRS codes of rate $R$ up to radius\n$1-R-\\varepsilon$.\n  We present a deterministic decoder that runs in near-linear time\n$\\widetilde{O}_{\\varepsilon}(n)$, improving upon the best-known runtime\n$n^{\\Omega(1/\\varepsilon)}$ for decoding FRS codes. Prior to our work, no\ncapacity achieving code was known whose deterministic decoding could be done in\ntime $\\widetilde{O}_{\\varepsilon}(n)$.\n  We also present a randomized decoder that runs in fully polynomial time\n$\\mathrm{poly}(1/\\varepsilon) \\cdot \\widetilde{O}(n)$, improving the best-known\nruntime $\\mathrm{exp}(1/\\varepsilon)\\cdot \\widetilde{O}(n)$ for decoding FRS\ncodes. Again, prior to our work, no capacity achieving code was known whose\ndecoding time depended polynomially on $1/\\varepsilon$."}
{"id": "2508.12645", "pdf": "https://arxiv.org/pdf/2508.12645", "abs": "https://arxiv.org/abs/2508.12645", "authors": ["Hongyang Liu", "Zhu Sun", "Tianjun Wei", "Yan Wang", "Jiajie Zhu", "Xinghua Qu"], "title": "Diagnostic-Guided Dynamic Profile Optimization for LLM-based User Simulators in Sequential Recommendation", "categories": ["cs.IR"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled realistic user\nsimulators for developing and evaluating recommender systems (RSs). However,\nexisting LLM-based simulators for RSs face two major limitations: (1) static\nand single-step prompt-based inference that leads to inaccurate and incomplete\nuser profile construction; (2) unrealistic and single-round\nrecommendation-feedback interaction pattern that fails to capture real-world\nscenarios. To address these limitations, we propose DGDPO (Diagnostic-Guided\nDynamic Profile Optimization), a novel framework that constructs user profile\nthrough a dynamic and iterative optimization process to enhance the simulation\nfidelity. Specifically, DGDPO incorporates two core modules within each\noptimization loop: firstly, a specialized LLM-based diagnostic module,\ncalibrated through our novel training strategy, accurately identifies specific\ndefects in the user profile. Subsequently, a generalized LLM-based treatment\nmodule analyzes the diagnosed defect and generates targeted suggestions to\nrefine the profile. Furthermore, unlike existing LLM-based user simulators that\nare limited to single-round interactions, we are the first to integrate DGDPO\nwith sequential recommenders, enabling a bidirectional evolution where user\nprofiles and recommendation strategies adapt to each other over multi-round\ninteractions. Extensive experiments conducted on three real-world datasets\ndemonstrate the effectiveness of our proposed framework."}
{"id": "2508.11646", "pdf": "https://arxiv.org/pdf/2508.11646", "abs": "https://arxiv.org/abs/2508.11646", "authors": ["Xin Li"], "title": "Memory as Structured Trajectories: Persistent Homology and Contextual Sheaves", "categories": ["q-bio.NC", "cs.NE", "nlin.AO"], "comment": null, "summary": "We propose a topological framework for memory and inference grounded in the\nstructure of spike-timing dynamics, persistent homology, and the\nContext-Content Uncertainty Principle (CCUP). Starting from the observation\nthat polychronous neural groups (PNGs) encode reproducible, time-locked spike\nsequences shaped by axonal delays and synaptic plasticity, we construct\nspatiotemporal complexes whose temporally consistent transitions define chain\ncomplexes over which robust activation cycles emerge. These activation loops\nare abstracted into cell posets, enabling a compact and causally ordered\nrepresentation of neural activity with overlapping and compositional memory\ntraces. We introduce the delta-homology analogy, which formalizes memory as a\nset of sparse, topologically irreducible attractors. A Dirac delta-like memory\ntrace is identified with a nontrivial homology generator on a latent manifold\nof cognitive states. Such traces are sharply localized along reproducible\ntopological cycles and are only activated when inference trajectories complete\na full cycle. They encode minimal, path-dependent memory units that cannot be\nsynthesized from local features alone. We interpret these delta-homology\ngenerators as the low-entropy content variable, while the high-entropy context\nvariable is represented dually as a filtration, cohomology class, or sheaf over\nthe same latent space. Inference is recast as a dynamic alignment between\ncontent and context and coherent memory retrieval corresponds to the existence\nof a global section that selects and sustains a topological generator. Memory\nis no longer a static attractor or distributed code, but a cycle-completing,\nstructure-aware inference process."}
{"id": "2508.11975", "pdf": "https://arxiv.org/pdf/2508.11975", "abs": "https://arxiv.org/abs/2508.11975", "authors": ["Gongyao Jiang", "Qiong Luo"], "title": "Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering", "categories": ["cs.AI"], "comment": "Accepted to CIKM 2025", "summary": "Vision Language Models (VLMs) often struggle with chart understanding tasks,\nparticularly in accurate chart description and complex reasoning. Synthetic\ndata generation is a promising solution, while usually facing the challenge of\nnoise labels. To address this challenge, we first introduce a chart synthesis\npipeline that generates aligned chart-question-answer triplets through code\ngeneration and execution, ensuring the reliability of synthetic data without\nhuman intervention. Furthermore, inspired by test-time scaling that increases\ninference budget and thereby improves performance, we design a\ncandidate-conditioned answering process. The VLM first generates multiple\nresponses per query, and then synthesizes the final answer by contextualizing\nthese candidates. Experiments demonstrate significant improvements, with up to\n15.50 points accuracy gain over the initial VLM, in a fully self-improving\nparadigm without either human-labeled data or external models."}
{"id": "2508.12303", "pdf": "https://arxiv.org/pdf/2508.12303", "abs": "https://arxiv.org/abs/2508.12303", "authors": ["Xu Long", "Yishun Wang", "Xiaoqi Li"], "title": "From Fomo3D to Lottery DAPP: Analysis of Ethereum-Based Gambling Applications", "categories": ["cs.SE"], "comment": null, "summary": "As blockchain technology advances, Ethereum based gambling decentralized\napplications (DApps) represent a new paradigm in online gambling. This paper\nexamines the concepts, principles, implementation, and prospects of Ethereum\nbased gambling DApps. First, we outline the concept and operational principles\nof gambling DApps. These DApps are blockchain based online lottery platforms.\nThey utilize smart contracts to manage the entire lottery process, including\nissuance, betting, drawing, and prize distribution. Being decentralized,\nlottery DApps operate without central oversight, unlike traditional lotteries.\nThis ensures fairness and eliminates control by any single entity. Automated\nsmart contract execution further reduces management costs, increases\nprofitability, and enhances game transparency and credibility. Next, we analyze\nan existing Ethereum based gambling DApp, detailing its technical principles,\nimplementation, operational status, vulnerabilities, and potential solutions.\nWe then elaborate on the implementation of lottery DApps. Smart contracts\nautomate the entire lottery process including betting, drawing, and prize\ndistribution. Although developing lottery DApps requires technical expertise,\nthe expanding Ethereum ecosystem provides growing tools and frameworks,\nlowering development barriers. Finally, we discuss current limitations and\nprospects of lottery DApps. As blockchain technology and smart contracts\nevolve, lottery DApps are positioned to significantly transform the online\nlottery industry. Advantages like decentralization, automation, and\ntransparency will likely drive broader future adoption."}
{"id": "2508.13102", "pdf": "https://arxiv.org/pdf/2508.13102", "abs": "https://arxiv.org/abs/2508.13102", "authors": ["Leonardo Becchetti", "Nazaria Solferino"], "title": "Testing health expenditure rationing under universal healthcare coverage: the case of Italy", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We investigate the phenomenon of (private, out-of-pocket) \"health expenditure\nrationing\", or whether out-of-pocket health expenditures are shaped by income\nindependently of actual health needs. Using microdata from an Italian Health\nInterview Survey, we assess the extent to which income explains variation in\nprivate health spending, after controlling for objective health conditions,\nself-assessed health, and a comprehensive set of socio-demographic factors. We\nfind that individuals in the highest income brackets spend approximately 300\neuros more annually than those in the lowest. Our findings point to a\nstructural inequity in access and highlight the need for policy measures that\naddress not only formal coverage but also the underlying role of income in\nshaping healthcare use."}
{"id": "2508.13102", "pdf": "https://arxiv.org/pdf/2508.13102", "abs": "https://arxiv.org/abs/2508.13102", "authors": ["Leonardo Becchetti", "Nazaria Solferino"], "title": "Testing health expenditure rationing under universal healthcare coverage: the case of Italy", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "We investigate the phenomenon of (private, out-of-pocket) \"health expenditure\nrationing\", or whether out-of-pocket health expenditures are shaped by income\nindependently of actual health needs. Using microdata from an Italian Health\nInterview Survey, we assess the extent to which income explains variation in\nprivate health spending, after controlling for objective health conditions,\nself-assessed health, and a comprehensive set of socio-demographic factors. We\nfind that individuals in the highest income brackets spend approximately 300\neuros more annually than those in the lowest. Our findings point to a\nstructural inequity in access and highlight the need for policy measures that\naddress not only formal coverage but also the underlying role of income in\nshaping healthcare use."}
{"id": "2508.11732", "pdf": "https://arxiv.org/pdf/2508.11732", "abs": "https://arxiv.org/abs/2508.11732", "authors": ["Xiangxiang Cui", "Min Zhao", "Dongmei Zhi", "Shile Qi", "Vince D Calhoun", "Jing Sui"], "title": "BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing deep learning models for functional MRI-based classification have\nlimitations in network architecture determination (relying on experience) and\nfeature space fusion (mostly simple concatenation, lacking mutual learning).\nInspired by the human brain's mechanism of updating neural connections through\nlearning and decision-making, we proposed a novel BRain-Inspired feature Fusion\n(BRIEF) framework, which is able to optimize network architecture automatically\nby incorporating an improved neural network connection search (NCS) strategy\nand a Transformer-based multi-feature fusion module. Specifically, we first\nextracted 4 types of fMRI temporal representations, i.e., time series (TCs),\nstatic/dynamic functional connection (FNC/dFNC), and multi-scale dispersion\nentropy (MsDE), to construct four encoders. Within each encoder, we employed a\nmodified Q-learning to dynamically optimize the NCS to extract high-level\nfeature vectors, where the NCS is formulated as a Markov Decision Process.\nThen, all feature vectors were fused via a Transformer, leveraging both\nstable/time-varying connections and multi-scale dependencies across different\nbrain regions to achieve the final classification. Additionally, an attention\nmodule was embedded to improve interpretability. The classification performance\nof our proposed BRIEF was compared with 21 state-of-the-art models by\ndiscriminating two mental disorders from healthy controls: schizophrenia (SZ,\nn=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated\nsignificant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching\nan AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is\nthe first attempt to incorporate a brain-inspired, reinforcement learning\nstrategy to optimize fMRI-based mental disorder classification, showing\nsignificant potential for identifying precise neuroimaging biomarkers."}
{"id": "2508.12939", "pdf": "https://arxiv.org/pdf/2508.12939", "abs": "https://arxiv.org/abs/2508.12939", "authors": ["Michael Deistler", "Jan Boelts", "Peter Steinbach", "Guy Moss", "Thomas Moreau", "Manuel Gloeckler", "Pedro L. C. Rodrigues", "Julia Linhart", "Janne K. Lappalainen", "Benjamin Kurt Miller", "Pedro J. Gonçalves", "Jan-Matthis Lueckmann", "Cornelius Schröder", "Jakob H. Macke"], "title": "Simulation-Based Inference: A Practical Guide", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A central challenge in many areas of science and engineering is to identify\nmodel parameters that are consistent with prior knowledge and empirical data.\nBayesian inference offers a principled framework for this task, but can be\ncomputationally prohibitive when models are defined by stochastic simulators.\nSimulation-based Inference (SBI) is a suite of methods developed to overcome\nthis limitation, which has enabled scientific discoveries in fields such as\nparticle physics, astrophysics, and neuroscience. The core idea of SBI is to\ntrain neural networks on data generated by a simulator, without requiring\naccess to likelihood evaluations. Once trained, inference is amortized: The\nneural network can rapidly perform Bayesian inference on empirical observations\nwithout requiring additional training or simulations. In this tutorial, we\nprovide a practical guide for practitioners aiming to apply SBI methods. We\noutline a structured SBI workflow and offer practical guidelines and diagnostic\ntools for every stage of the process -- from setting up the simulator and\nprior, choosing and training inference networks, to performing inference and\nvalidating the results. We illustrate these steps through examples from\nastrophysics, psychophysics, and neuroscience. This tutorial empowers\nresearchers to apply state-of-the-art SBI methods, facilitating efficient\nparameter inference for scientific discovery."}
{"id": "2508.12021", "pdf": "https://arxiv.org/pdf/2508.12021", "abs": "https://arxiv.org/abs/2508.12021", "authors": ["You Hak Lee", "Xiaofan Yu", "Quanling Zhao", "Flavio Ponzina", "Tajana Rosing"], "title": "FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": null, "summary": "Unsupervised federated learning (UFL) has gained attention as a\nprivacy-preserving, decentralized machine learning approach that eliminates the\nneed for labor-intensive data labeling. However, UFL faces several challenges\nin practical applications: (1) non-independent and identically distributed\n(non-iid) data distribution across devices, (2) expensive computational and\ncommunication costs at the edge, and (3) vulnerability to communication noise.\nPrevious UFL approaches have relied on deep neural networks (NN), which\nintroduce substantial overhead in both computation and communication. In this\npaper, we propose FedUHD, the first UFL framework based on Hyperdimensional\nComputing (HDC). HDC is a brain-inspired computing scheme with lightweight\ntraining and inference operations, much smaller model size, and robustness to\ncommunication noise. FedUHD introduces two novel HDC-based designs to improve\nUFL performance. On the client side, a kNN-based cluster hypervector removal\nmethod addresses non-iid data samples by eliminating detrimental outliers. On\nthe server side, a weighted HDC aggregation technique balances the non-iid data\ndistribution across clients. Our experiments demonstrate that FedUHD achieves\nup to 173.6x and 612.7x better speedup and energy efficiency, respectively, in\ntraining, up to 271x lower communication cost, and 15.50% higher accuracy on\naverage across diverse settings, along with superior robustness to various\ntypes of noise compared to state-of-the-art NN-based UFL approaches."}
{"id": "2508.12549", "pdf": "https://arxiv.org/pdf/2508.12549", "abs": "https://arxiv.org/abs/2508.12549", "authors": ["Atasi Panda", "Harsh Sharma", "Anand Louis", "Prajakta Nimbhorkar"], "title": "Group Fair Matchings using Convex Cost Functions", "categories": ["cs.GT", "cs.DS", "cs.MA"], "comment": null, "summary": "We consider the problem of assigning items to platforms where each item has a\nutility associated with each of the platforms to which it can be assigned. Each\nplatform has a soft constraint over the total number of items it serves,\nmodeled via a convex cost function. Additionally, items are partitioned into\ngroups, and each platform also incurs group-specific convex cost over the\nnumber of items from each group that can be assigned to the platform. These\ncosts promote group fairness by penalizing imbalances, yielding a soft\nvariation of fairness notions introduced in prior work, such as Restricted\nDominance and Minority protection. Restricted Dominance enforces upper bounds\non group representation, while Minority protection enforces lower bounds. Our\napproach replaces such hard constraints with cost-based penalties, allowing\nmore flexible trade-offs. Our model also captures Nash Social Welfare kind of\nobjective.\n  The cost of an assignment is the sum of the values of all the cost functions\nacross all the groups and platforms. The objective is to find an assignment\nthat minimizes the cost while achieving a total utility that is at least a\nuser-specified threshold. The main challenge lies in balancing the overall\nplatform cost with group-specific costs, both governed by convex functions,\nwhile meeting the utility constraint. We present an efficient polynomial-time\napproximation algorithm, supported by theoretical guarantees and experimental\nevaluation. Our algorithm is based on techniques involving linear programming\nand network flows. We also provide an exact algorithm for a special case with\nuniform utilities and establish the hardness of the general problem when the\ngroups can intersect arbitrarily."}
{"id": "2508.12665", "pdf": "https://arxiv.org/pdf/2508.12665", "abs": "https://arxiv.org/abs/2508.12665", "authors": ["Xu Zhao", "Ruibo Ma", "Jiaqi Chen", "Weiqi Zhao", "Ping Yang", "Yao Hu"], "title": "Multi-Granularity Distribution Modeling for Video Watch Time Prediction via Exponential-Gaussian Mixture Network", "categories": ["cs.IR", "H.3.3"], "comment": "Accepted as oral full paper by RecSys'2025 conference", "summary": "Accurate watch time prediction is crucial for enhancing user engagement in\nstreaming short-video platforms, although it is challenged by complex\ndistribution characteristics across multi-granularity levels. Through\nsystematic analysis of real-world industrial data, we uncover two critical\nchallenges in watch time prediction from a distribution aspect: (1)\ncoarse-grained skewness induced by a significant concentration of quick-skips1,\n(2) fine-grained diversity arising from various user-video interaction\npatterns. Consequently, we assume that the watch time follows the\nExponential-Gaussian Mixture (EGM) distribution, where the exponential and\nGaussian components respectively characterize the skewness and diversity.\nAccordingly, an Exponential-Gaussian Mixture Network (EGMN) is proposed for the\nparameterization of EGM distribution, which consists of two key modules: a\nhidden representation encoder and a mixture parameter generator. We conducted\nextensive offline experiments on public datasets and online A/B tests on the\nindustrial short-video feeding scenario of Xiaohongshu App to validate the\nsuperiority of EGMN compared with existing state-of-the-art methods.\nRemarkably, comprehensive experimental results have proven that EGMN exhibits\nexcellent distribution fitting ability across coarse-to-fine-grained levels. We\nopen source related code on Github: https://github.com/BestActionNow/EGMN."}
{"id": "2508.11805", "pdf": "https://arxiv.org/pdf/2508.11805", "abs": "https://arxiv.org/abs/2508.11805", "authors": ["Xinyun Zou", "Jorge Gamez", "Meghna Menon", "Phillip Ring", "Chadwick Boulay", "Likhith Chitneni", "Jackson Brennecke", "Shana R. Melby", "Gracy Kureel", "Kelsie Pejsa", "Emily R. Rosario", "Ausaf A. Bari", "Aniruddh Ravindran", "Tyson Aflalo", "Spencer S. Kellis", "Dimitar Filev", "Florian Solzbacher", "Richard A. Andersen"], "title": "Control of a commercial vehicle by a tetraplegic human using a bimanual brain-computer interface", "categories": ["eess.SY", "cs.NE", "cs.RO", "cs.SY"], "comment": "41 pages, 7 figures, 1 table. 22 supplementary pages, 6 supplementary\n  figures, 11 supplementary tables, 9 supplementary movies available as\n  ancillary files", "summary": "Brain-computer interfaces (BCIs) read neural signals directly from the brain\nto infer motor planning and execution. However, the implementation of this\ntechnology has been largely limited to laboratory settings, with few real-world\napplications. We developed a bimanual BCI system to drive a vehicle in both\nsimulated and real-world environments. We demonstrate that an individual with\ntetraplegia, implanted with intracortical BCI electrodes in the posterior\nparietal cortex (PPC) and the hand knob region of the motor cortex (MC), reacts\nat least as fast and precisely as motor intact participants, and drives a\nsimulated vehicle as proficiently as the same control group. This BCI\nparticipant, living in California, could also remotely drive a Ford Mustang\nMach-E vehicle in Michigan. Our first teledriving task relied on cursor control\nfor speed and steering in a closed urban test facility. However, the final BCI\nsystem added click control for full-stop braking and thus enabled bimanual\ncursor-and-click control for both simulated driving through a virtual town with\ntraffic and teledriving through an obstacle course without traffic in the real\nworld. We also demonstrate the safety and feasibility of BCI-controlled\ndriving. This first-of-its-kind implantable BCI application not only highlights\nthe versatility and innovative potentials of BCIs but also illuminates the\npromising future for the development of life-changing solutions to restore\nindependence to those who suffer catastrophic neurological injury."}
{"id": "2508.11987", "pdf": "https://arxiv.org/pdf/2508.11987", "abs": "https://arxiv.org/abs/2508.11987", "authors": ["Zhiyuan Zeng", "Jiashuo Liu", "Siyuan Chen", "Tianci He", "Yali Liao", "Jinpeng Wang", "Zaiyuan Wang", "Yang Yang", "Lingyue Yin", "Mingren Yin", "Zhenwei Zhu", "Tianle Cai", "Zehui Chen", "Jiecao Chen", "Yantao Du", "Xiang Gao", "Jiacheng Guo", "Liang Hu", "Jianpeng Jiao", "Xiangsheng Li", "Jingkai Liu", "Shuang Ni", "Zhoufutu Wen", "Ge Zhang", "Kaiyuan Zhang", "Xin Zhou", "Jose Blanchet", "Xipeng Qiu", "Mengdi Wang", "Wenhao Huang"], "title": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction", "categories": ["cs.AI", "cs.LG"], "comment": "Technical report, 51 pages", "summary": "Future prediction is a complex task for LLM agents, requiring a high level of\nanalytical thinking, information gathering, contextual understanding, and\ndecision-making under uncertainty. Agents must not only gather and interpret\nvast amounts of dynamic information but also integrate diverse data sources,\nweigh uncertainties, and adapt predictions based on emerging trends, just as\nhuman experts do in fields like politics, economics, and finance. Despite its\nimportance, no large-scale benchmark exists for evaluating agents on future\nprediction, largely due to challenges in handling real-time updates and\nretrieving timely, accurate answers. To address this, we introduce\n$\\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically\ndesigned for LLM agents performing future prediction tasks. FutureX is the\nlargest and most diverse live benchmark for future prediction, supporting\nreal-time daily updates and eliminating data contamination through an automated\npipeline for question gathering and answer collection. We evaluate 25 LLM/agent\nmodels, including those with reasoning, search capabilities, and integration of\nexternal tools such as the open-source Deep Research Agent and closed-source\nDeep Research models. This comprehensive evaluation assesses agents' adaptive\nreasoning and performance in dynamic environments. Additionally, we provide\nin-depth analyses of agents' failure modes and performance pitfalls in\nfuture-oriented tasks, including the vulnerability to fake web pages and the\ntemporal validity. Our goal is to establish a dynamic, contamination-free\nevaluation standard that drives the development of LLM agents capable of\nperforming at the level of professional human analysts in complex reasoning and\npredictive thinking."}
{"id": "2508.12325", "pdf": "https://arxiv.org/pdf/2508.12325", "abs": "https://arxiv.org/abs/2508.12325", "authors": ["Tim Kräuter", "Adrian Rutle", "Yngve Lamo", "Harald König", "Francisco Durán"], "title": "Towards the Coordination and Verification of Heterogeneous Systems with Data and Time", "categories": ["cs.SE"], "comment": "This is the authors accepted version of a paper to be published in\n  MODELS-2025, DOI: TBD", "summary": "Modern software systems are often realized by coordinating multiple\nheterogeneous parts, each responsible for specific tasks. These parts must work\ntogether seamlessly to satisfy the overall system requirements. To verify such\ncomplex systems, we have developed a non-intrusive coordination framework\ncapable of performing formal analysis of heterogeneous parts that exchange data\nand include real-time capabilities. The framework utilizes a linguistic\nextension, which is implemented as a central broker and a domain-specific\nlanguage for the integration of heterogeneous languages and coordination of\nparts. Moreover, abstract rule templates are reified as language adapters for\nnon-intrusive communications with the broker. The framework is implemented\nusing rewriting logic (Maude), and its applicability is demonstrated by\nverifying certain correctness properties of a heterogeneous road-rail crossing\nsystem."}
{"id": "2508.11779", "pdf": "https://arxiv.org/pdf/2508.11779", "abs": "https://arxiv.org/abs/2508.11779", "authors": ["Tianyi Li", "Yu Qin", "Olivia R. Liu Sheng"], "title": "A Multi-Task Evaluation of LLMs' Processing of Academic Text Input", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "comment": null, "summary": "How much large language models (LLMs) can aid scientific discovery, notably\nin assisting academic peer review, is in heated debate. Between a literature\ndigest and a human-comparable research assistant lies their practical\napplication potential. We organize individual tasks that computer science\nstudies employ in separate terms into a guided and robust workflow to evaluate\nLLMs' processing of academic text input. We employ four tasks in the\nassessment: content reproduction/comparison/scoring/reflection, each demanding\na specific role of the LLM (oracle/judgmental arbiter/knowledgeable\narbiter/collaborator) in assisting scholarly works, and altogether testing LLMs\nwith questions that increasingly require intellectual capabilities towards a\nsolid understanding of scientific texts to yield desirable solutions. We\nexemplify a rigorous performance evaluation with detailed instructions on the\nprompts. Adopting first-rate Information Systems articles at three top journals\nas the input texts and an abundant set of text metrics, we record a compromised\nperformance of the leading LLM - Google's Gemini: its summary and paraphrase of\nacademic text is acceptably reliable; using it to rank texts through pairwise\ntext comparison is faintly scalable; asking it to grade academic texts is prone\nto poor discrimination; its qualitative reflection on the text is\nself-consistent yet hardly insightful to inspire meaningful research. This\nevidence against an endorsement of LLMs' text-processing capabilities is\nconsistent across metric-based internal (linguistic assessment), external\n(comparing to the ground truth), and human evaluation, and is robust to the\nvariations of the prompt. Overall, we do not recommend an unchecked use of LLMs\nin constructing peer reviews."}
{"id": "2508.11779", "pdf": "https://arxiv.org/pdf/2508.11779", "abs": "https://arxiv.org/abs/2508.11779", "authors": ["Tianyi Li", "Yu Qin", "Olivia R. Liu Sheng"], "title": "A Multi-Task Evaluation of LLMs' Processing of Academic Text Input", "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "comment": null, "summary": "How much large language models (LLMs) can aid scientific discovery, notably\nin assisting academic peer review, is in heated debate. Between a literature\ndigest and a human-comparable research assistant lies their practical\napplication potential. We organize individual tasks that computer science\nstudies employ in separate terms into a guided and robust workflow to evaluate\nLLMs' processing of academic text input. We employ four tasks in the\nassessment: content reproduction/comparison/scoring/reflection, each demanding\na specific role of the LLM (oracle/judgmental arbiter/knowledgeable\narbiter/collaborator) in assisting scholarly works, and altogether testing LLMs\nwith questions that increasingly require intellectual capabilities towards a\nsolid understanding of scientific texts to yield desirable solutions. We\nexemplify a rigorous performance evaluation with detailed instructions on the\nprompts. Adopting first-rate Information Systems articles at three top journals\nas the input texts and an abundant set of text metrics, we record a compromised\nperformance of the leading LLM - Google's Gemini: its summary and paraphrase of\nacademic text is acceptably reliable; using it to rank texts through pairwise\ntext comparison is faintly scalable; asking it to grade academic texts is prone\nto poor discrimination; its qualitative reflection on the text is\nself-consistent yet hardly insightful to inspire meaningful research. This\nevidence against an endorsement of LLMs' text-processing capabilities is\nconsistent across metric-based internal (linguistic assessment), external\n(comparing to the ground truth), and human evaluation, and is robust to the\nvariations of the prompt. Overall, we do not recommend an unchecked use of LLMs\nin constructing peer reviews."}
{"id": "2508.11739", "pdf": "https://arxiv.org/pdf/2508.11739", "abs": "https://arxiv.org/abs/2508.11739", "authors": ["Luc Houriez", "Sebastian Pilarski", "Behzad Vahedi", "Ali Ahmadalipour", "Teo Honda Scully", "Nicholas Aflitto", "David Andre", "Caroline Jaffe", "Martha Wedner", "Rich Mazzola", "Josh Jeffery", "Ben Messinger", "Sage McGinley-Smith", "Sarah Russell"], "title": "Scalable Geospatial Data Generation Using AlphaEarth Foundations Model", "categories": ["cs.LG", "cs.CV", "I.4.6; I.5.5"], "comment": "15 pages, 10 figures, 5 tables", "summary": "High-quality labeled geospatial datasets are essential for extracting\ninsights and understanding our planet. Unfortunately, these datasets often do\nnot span the entire globe and are limited to certain geographic regions where\ndata was collected. Google DeepMind's recently released AlphaEarth Foundations\n(AEF) provides an information-dense global geospatial representation designed\nto serve as a useful input across a wide gamut of tasks. In this article we\npropose and evaluate a methodology which leverages AEF to extend geospatial\nlabeled datasets beyond their initial geographic regions. We show that even\nbasic models like random forests or logistic regression can be used to\naccomplish this task. We investigate a case study of extending LANDFIRE's\nExisting Vegetation Type (EVT) dataset beyond the USA into Canada at two levels\nof granularity: EvtPhys (13 classes) and EvtGp (80 classes). Qualitatively, for\nEvtPhys, model predictions align with ground truth. Trained models achieve 81%\nand 73% classification accuracy on EvtPhys validation sets in the USA and\nCanada, despite discussed limitations."}
{"id": "2508.12947", "pdf": "https://arxiv.org/pdf/2508.12947", "abs": "https://arxiv.org/abs/2508.12947", "authors": ["Michael Mayer", "Mario V. Wüthrich"], "title": "Shapley Values: Paired-Sampling Approximations", "categories": ["stat.ML", "cs.CE", "cs.LG"], "comment": null, "summary": "Originally introduced in cooperative game theory, Shapley values have become\na very popular tool to explain machine learning predictions. Based on Shapley's\nfairness axioms, every input (feature component) gets a credit how it\ncontributes to an output (prediction). These credits are then used to explain\nthe prediction. The only limitation in computing the Shapley values (credits)\nfor many different predictions is of computational nature. There are two\npopular sampling approximations, sampling KernelSHAP and sampling\nPermutationSHAP. Our first novel contributions are asymptotic normality results\nfor these sampling approximations. Next, we show that the paired-sampling\napproaches provide exact results in case of interactions being of maximal order\ntwo. Furthermore, the paired-sampling PermutationSHAP possesses the additive\nrecovery property, whereas its kernel counterpart does not."}
{"id": "2508.12161", "pdf": "https://arxiv.org/pdf/2508.12161", "abs": "https://arxiv.org/abs/2508.12161", "authors": ["Ming Li", "John Hale"], "title": "Attack Graph Generation on HPC Clusters", "categories": ["cs.CR", "cs.DC"], "comment": null, "summary": "Attack graphs (AGs) are graphical tools to analyze the security of computer\nnetworks. By connecting the exploitation of individual vulnerabilities, AGs\nexpose possible multi-step attacks against target networks, allowing system\nadministrators to take preventive measures to enhance their network's security.\nAs powerful analytical tools, however, AGs are both time- and memory-consuming\nto be generated. As the numbers of network assets, interconnections between\ndevices, as well as vulnerabilities increase, the size and volume of the\nresulting AGs grow at a much higher rate, leading to the well-known state-space\nexplosion. In this paper, we propose the use of high performance computing\n(HPC) clusters to implement AG generators. We evaluate the performance through\nexperiments and provide insights into how cluster environments can help resolve\nthe issues of slow speed and high memory demands in AG generation in a balanced\nway."}
{"id": "2508.12627", "pdf": "https://arxiv.org/pdf/2508.12627", "abs": "https://arxiv.org/abs/2508.12627", "authors": ["Xingyu Chen", "Ruiqi Zhang", "Lin Liu"], "title": "On computing and the complexity of computing higher-order $U$-statistics, exactly", "categories": ["stat.ML", "cs.DS", "cs.NA", "math.NA", "stat.CO", "stat.ME"], "comment": "Comments are welcome! 49 pages, 8 tables, 4 figures. An accompanying\n  Python package is available at: https://libraries.io/pypi/u-stats or\n  https://github.com/Amedar-Asterisk/U-Statistics-Python", "summary": "Higher-order $U$-statistics abound in fields such as statistics, machine\nlearning, and computer science, but are known to be highly time-consuming to\ncompute in practice. Despite their widespread appearance, a comprehensive study\nof their computational complexity is surprisingly lacking. This paper aims to\nfill that gap by presenting several results related to the computational aspect\nof $U$-statistics. First, we derive a useful decomposition from an $m$-th order\n$U$-statistic to a linear combination of $V$-statistics with orders not\nexceeding $m$, which are generally more feasible to compute. Second, we explore\nthe connection between exactly computing $V$-statistics and Einstein summation,\na tool often used in computational mathematics, quantum computing, and quantum\ninformation sciences for accelerating tensor computations. Third, we provide an\noptimistic estimate of the time complexity for exactly computing\n$U$-statistics, based on the treewidth of a particular graph associated with\nthe $U$-statistic kernel. The above ingredients lead to a new, much more\nruntime-efficient algorithm of exactly computing general higher-order\n$U$-statistics. We also wrap our new algorithm into an open-source Python\npackage called $\\texttt{u-stats}$. We demonstrate via three statistical\napplications that $\\texttt{u-stats}$ achieves impressive runtime performance\ncompared to existing benchmarks. This paper aspires to achieve two goals: (1)\nto capture the interest of researchers in both statistics and other related\nareas further to advance the algorithmic development of $U$-statistics, and (2)\nto offer the package $\\texttt{u-stats}$ as a valuable tool for practitioners,\nmaking the implementation of methods based on higher-order $U$-statistics a\nmore delightful experience."}
{"id": "2508.12706", "pdf": "https://arxiv.org/pdf/2508.12706", "abs": "https://arxiv.org/abs/2508.12706", "authors": ["Yongchun Zhu", "Guanyu Jiang", "Jingwu Chen", "Feng Zhang", "Xiao Yang", "Zuotao Liu"], "title": "Asymmetric Diffusion Recommendation Model", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted by CIKM2025", "summary": "Recently, motivated by the outstanding achievements of diffusion models, the\ndiffusion process has been employed to strengthen representation learning in\nrecommendation systems. Most diffusion-based recommendation models typically\nutilize standard Gaussian noise in symmetric forward and reverse processes in\ncontinuous data space. Nevertheless, the samples derived from recommendation\nsystems inhabit a discrete data space, which is fundamentally different from\nthe continuous one. Moreover, Gaussian noise has the potential to corrupt\npersonalized information within latent representations. In this work, we\npropose a novel and effective method, named Asymmetric Diffusion Recommendation\nModel (AsymDiffRec), which learns forward and reverse processes in an\nasymmetric manner. We define a generalized forward process that simulates the\nmissing features in real-world recommendation samples. The reverse process is\nthen performed in an asymmetric latent feature space. To preserve personalized\ninformation within the latent representation, a task-oriented optimization\nstrategy is introduced. In the serving stage, the raw sample with missing\nfeatures is regarded as a noisy input to generate a denoising and robust\nrepresentation for the final prediction. By equipping base models with\nAsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and\n+0.166% in terms of users' active days and app usage duration respectively.\nAdditionally, the extended offline experiments also demonstrate improvements.\nAsymDiffRec has been implemented in the Douyin Music App."}
{"id": "2508.12571", "pdf": "https://arxiv.org/pdf/2508.12571", "abs": "https://arxiv.org/abs/2508.12571", "authors": ["Tyler Schroder", "Renee Sirbu", "Sohee Park", "Jessica Morley", "Sam Street", "Luciano Floridi"], "title": "Cyber Risks to Next-Gen Brain-Computer Interfaces: Analysis and Recommendations", "categories": ["cs.CR", "cs.CY", "cs.ET", "cs.HC", "cs.NE"], "comment": null, "summary": "Brain-computer interfaces (BCIs) show enormous potential for advancing\npersonalized medicine. However, BCIs also introduce new avenues for\ncyber-attacks or security compromises. In this article, we analyze the problem\nand make recommendations for device manufacturers to better secure devices and\nto help regulators understand where more guidance is needed to protect patient\nsafety and data confidentiality. Device manufacturers should implement the\nprior suggestions in their BCI products. These recommendations help protect BCI\nusers from undue risks, including compromised personal health and genetic\ninformation, unintended BCI-mediated movement, and many other cybersecurity\nbreaches. Regulators should mandate non-surgical device update methods, strong\nauthentication and authorization schemes for BCI software modifications,\nencryption of data moving to and from the brain, and minimize network\nconnectivity where possible. We also design a hypothetical, average-case threat\nmodel that identifies possible cybersecurity threats to BCI patients and\npredicts the likeliness of risk for each category of threat. BCIs are at less\nrisk of physical compromise or attack, but are vulnerable to remote attack; we\nfocus on possible threats via network paths to BCIs and suggest technical\ncontrols to limit network connections."}
{"id": "2508.11991", "pdf": "https://arxiv.org/pdf/2508.11991", "abs": "https://arxiv.org/abs/2508.11991", "authors": ["Weihao Sun"], "title": "Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network", "categories": ["cs.AI"], "comment": null, "summary": "The automation of logic circuit design enhances chip performance, energy\nefficiency, and reliability, and is widely applied in the field of Electronic\nDesign Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,\noptimize, and verify the functional characteristics of digital circuits,\nenhancing the efficiency of EDA development.Due to the complex structure and\nlarge scale of nodes in real-world AIGs, accurate modeling is challenging,\nleading to existing work lacking the ability to jointly model functional and\nstructural characteristics, as well as insufficient dynamic information\npropagation capability.To address the aforementioned challenges, we propose\nAIGer.Specifically, AIGer consists of two components: 1) Node logic feature\ninitialization embedding component and 2) AIGs feature learning network\ncomponent.The node logic feature initialization embedding component projects\nlogic nodes, such as AND and NOT, into independent semantic spaces, to enable\neffective node embedding for subsequent processing.Building upon this, the AIGs\nfeature learning network component employs a heterogeneous graph convolutional\nnetwork, designing dynamic relationship weight matrices and differentiated\ninformation aggregation approaches to better represent the original structure\nand information of AIGs.The combination of these two components enhances\nAIGer's ability to jointly model functional and structural characteristics and\nimproves its message passing capability. Experimental results indicate that\nAIGer outperforms the current best models in the Signal Probability Prediction\n(SSP) task, improving MAE and MSE by 18.95\\% and 44.44\\%, respectively. In the\nTruth Table Distance Prediction (TTDP) task, AIGer achieves improvements of\n33.57\\% and 14.79\\% in MAE and MSE, respectively, compared to the\nbest-performing models."}
{"id": "2508.12358", "pdf": "https://arxiv.org/pdf/2508.12358", "abs": "https://arxiv.org/abs/2508.12358", "authors": ["Haolin Jin", "Huaming Chen"], "title": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to the NIER track of the 40th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE 2025)", "summary": "Large language models (LLMs) have become essential tools in software\ndevelopment, widely used for requirements engineering, code generation and\nreview tasks. Software engineers often rely on LLMs to assess whether system\ncode implementation satisfy task requirements, thereby enhancing code\nrobustness and accuracy. However, it remains unclear whether LLMs can reliably\ndetermine whether the code complies fully with the given task descriptions,\nwhich is usually natural language specifications. In this paper, we uncover a\nsystematic failure of LLMs in evaluating whether code aligns with natural\nlanguage requirements. Specifically, with widely used benchmarks, we employ\nunified prompts to judge code correctness. Our results reveal that LLMs\nfrequently misclassify correct code implementations as either ``not satisfying\nrequirements'' or containing potential defects. Surprisingly, more complex\nprompting, especially when leveraging prompt engineering techniques involving\nexplanations and proposed corrections, leads to higher misjudgment rate, which\nhighlights the critical reliability issues in using LLMs as code review\nassistants. We further analyze the root causes of these misjudgments, and\npropose two improved prompting strategies for mitigation. For the first time,\nour findings reveals unrecognized limitations in LLMs to match code with\nrequirements. We also offer novel insights and practical guidance for effective\nuse of LLMs in automated code review and task-oriented agent scenarios."}
{"id": "2508.11979", "pdf": "https://arxiv.org/pdf/2508.11979", "abs": "https://arxiv.org/abs/2508.11979", "authors": ["Agostino Capponi", "Garud Iyengar", "Bo Yang", "Daniel Bienstock"], "title": "Virtual Trading in Multi-Settlement Electricity Markets", "categories": ["math.OC", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "comment": null, "summary": "In the Day-Ahead (DA) market, suppliers sell and load-serving entities (LSEs)\npurchase energy commitments, with both sides adjusting for imbalances between\ncontracted and actual deliveries in the Real-Time (RT) market. We develop a\nsupply function equilibrium model to study how virtual trading-speculating on\nDA-RT price spreads without physical delivery-affects market efficiency.\nWithout virtual trading, LSEs underbid relative to actual demand in the DA\nmarket, pushing DA prices below expected RT prices. Virtual trading narrows,\nand in the limit of large number traders can eliminates, this price gap.\nHowever, it does not induce quantity alignment: DA-cleared demand remains below\ntrue expected demand, as price alignment makes the LSE indifferent between\nmarkets and prompts it to reduce DA bids to avoid over-purchasing. Renewable\nenergy suppliers cannot offset these strategic distortions. We provide\nempirical support to our main model implications using data from the California\nand New York Independent System Operators."}
{"id": "2508.11979", "pdf": "https://arxiv.org/pdf/2508.11979", "abs": "https://arxiv.org/abs/2508.11979", "authors": ["Agostino Capponi", "Garud Iyengar", "Bo Yang", "Daniel Bienstock"], "title": "Virtual Trading in Multi-Settlement Electricity Markets", "categories": ["math.OC", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "comment": null, "summary": "In the Day-Ahead (DA) market, suppliers sell and load-serving entities (LSEs)\npurchase energy commitments, with both sides adjusting for imbalances between\ncontracted and actual deliveries in the Real-Time (RT) market. We develop a\nsupply function equilibrium model to study how virtual trading-speculating on\nDA-RT price spreads without physical delivery-affects market efficiency.\nWithout virtual trading, LSEs underbid relative to actual demand in the DA\nmarket, pushing DA prices below expected RT prices. Virtual trading narrows,\nand in the limit of large number traders can eliminates, this price gap.\nHowever, it does not induce quantity alignment: DA-cleared demand remains below\ntrue expected demand, as price alignment makes the LSE indifferent between\nmarkets and prompts it to reduce DA bids to avoid over-purchasing. Renewable\nenergy suppliers cannot offset these strategic distortions. We provide\nempirical support to our main model implications using data from the California\nand New York Independent System Operators."}
{"id": "2508.11794", "pdf": "https://arxiv.org/pdf/2508.11794", "abs": "https://arxiv.org/abs/2508.11794", "authors": ["Hemanth Macharla", "Mayukha Pal"], "title": "Fed-Meta-Align: A Similarity-Aware Aggregation and Personalization Pipeline for Federated TinyML on Heterogeneous Data", "categories": ["cs.LG"], "comment": null, "summary": "Real-time fault classification in resource-constrained Internet of Things\n(IoT) devices is critical for industrial safety, yet training robust models in\nsuch heterogeneous environments remains a significant challenge. Standard\nFederated Learning (FL) often fails in the presence of non-IID data, leading to\nmodel divergence. This paper introduces Fed-Meta-Align, a novel four-phase\nframework designed to overcome these limitations through a sophisticated\ninitialization and training pipeline. Our process begins by training a\nfoundational model on a general public dataset to establish a competent\nstarting point. This model then undergoes a serial meta-initialization phase,\nwhere it sequentially trains on a subset of IOT Device data to learn a\nheterogeneity-aware initialization that is already situated in a favorable\nregion of the loss landscape. This informed model is subsequently refined in a\nparallel FL phase, which utilizes a dual-criterion aggregation mechanism that\nweights for IOT devices updates based on both local performance and cosine\nsimilarity alignment. Finally, an on-device personalization phase adapts the\nconverged global model into a specialized expert for each IOT Device.\nComprehensive experiments demonstrate that Fed-Meta-Align achieves an average\ntest accuracy of 91.27% across heterogeneous IOT devices, outperforming\npersonalized FedAvg and FedProx by up to 3.87% and 3.37% on electrical and\nmechanical fault datasets, respectively. This multi-stage approach of sequenced\ninitialization and adaptive aggregation provides a robust pathway for deploying\nhigh-performance intelligence on diverse TinyML networks."}
{"id": "2508.11685", "pdf": "https://arxiv.org/pdf/2508.11685", "abs": "https://arxiv.org/abs/2508.11685", "authors": ["Farnaz Kaboudvand", "Maham Khalid", "Nydia Assaf", "Vardaan Sahgal", "Jon P. Ruffley", "Brian J. McDermott"], "title": "Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.LG", "stat.ML"], "comment": "Manuscript length: 11 pages, 6 figures", "summary": "Corrosion poses a significant challenge to the performance of aluminum\nalloys, particularly in marine environments. This study investigates the\napplication of machine learning (ML) algorithms to predict and optimize\ncorrosion resistance, utilizing a comprehensive open-source dataset compiled\nfrom various sources. The dataset encompasses corrosion rate data and\nenvironmental conditions, preprocessed to standardize units and formats. We\nexplored two different approaches, a direct approach, where the material's\ncomposition and environmental conditions were used as inputs to predict\ncorrosion rates; and an inverse approach, where corrosion rate served as the\ninput to identify suitable material compositions as output. We employed and\ncompared three distinct ML methodologies for forward predictions: Random Forest\nregression, optimized via grid search; a feed-forward neural network, utilizing\nReLU activation and Adam optimization; and Gaussian Process Regression (GPR),\nimplemented with GPyTorch and employing various kernel functions. The Random\nForest and neural network models provided predictive capabilities based on\nelemental compositions and environmental conditions. Notably, Gaussian Process\nRegression demonstrated superior performance, particularly with hybrid kernel\nfunctions. Log-transformed GPR further refined predictions. This study\nhighlights the efficacy of ML, particularly GPR, in predicting corrosion rates\nand material properties."}
{"id": "2508.12353", "pdf": "https://arxiv.org/pdf/2508.12353", "abs": "https://arxiv.org/abs/2508.12353", "authors": ["Marcel Gregoriadis", "Jingwei Kang", "Johan Pouwelse"], "title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank", "categories": ["cs.IR", "cs.AI", "cs.DC"], "comment": "Accepted at CIKM 2025", "summary": "The centralized collection of search interaction logs for training ranking\nmodels raises significant privacy concerns. Federated Online Learning to Rank\n(FOLTR) offers a privacy-preserving alternative by enabling collaborative model\ntraining without sharing raw user data. However, benchmarks in FOLTR are\nlargely based on random partitioning of classical learning-to-rank datasets,\nsimulated user clicks, and the assumption of synchronous client participation.\nThis oversimplifies real-world dynamics and undermines the realism of\nexperimental results. We present AOL4FOLTR, a large-scale web search dataset\nwith 2.6 million queries from 10,000 users. Our dataset addresses key\nlimitations of existing benchmarks by including user identifiers, real click\ndata, and query timestamps, enabling realistic user partitioning, behavior\nmodeling, and asynchronous federated learning scenarios."}
{"id": "2508.13032", "pdf": "https://arxiv.org/pdf/2508.13032", "abs": "https://arxiv.org/abs/2508.13032", "authors": ["Nicolas Bousquet", "Remy El Sabeh", "Amer E. Mouawad", "Naomi Nishimura"], "title": "On the complexity of constrained reconfiguration and motion planning", "categories": ["cs.CC", "cs.DM", "cs.DS", "cs.RO", "math.CO"], "comment": null, "summary": "Coordinating the motion of multiple agents in constrained environments is a\nfundamental challenge in robotics, motion planning, and scheduling. A\nmotivating example involves $n$ robotic arms, each represented as a line\nsegment. The objective is to rotate each arm to its vertical orientation, one\nat a time (clockwise or counterclockwise), without collisions nor rotating any\narm more than once. This scenario is an example of the more general\n$k$-Compatible Ordering problem, where $n$ agents, each capable of $k$\nstate-changing actions, must transition to specific target states under\nconstraints encoded as a set $\\mathcal{G}$ of $k$ pairs of directed graphs.\n  We show that $k$-Compatible Ordering is $\\mathsf{NP}$-complete, even when\n$\\mathcal{G}$ is planar, degenerate, or acyclic. On the positive side, we\nprovide polynomial-time algorithms for cases such as when $k = 1$ or\n$\\mathcal{G}$ has bounded treewidth. We also introduce generalized variants\nsupporting multiple state-changing actions per agent, broadening the\napplicability of our framework. These results extend to a wide range of\nscheduling, reconfiguration, and motion planning applications in constrained\nenvironments."}
{"id": "2508.12752", "pdf": "https://arxiv.org/pdf/2508.12752", "abs": "https://arxiv.org/abs/2508.12752", "authors": ["Wenlin Zhang", "Xiaopeng Li", "Yingyi Zhang", "Pengyue Jia", "Yichao Wang", "Huifeng Guo", "Yong Liu", "Xiangyu Zhao"], "title": "Deep Research: A Survey of Autonomous Research Agents", "categories": ["cs.IR"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has driven the\ndevelopment of agentic systems capable of autonomously performing complex\ntasks. Despite their impressive capabilities, LLMs remain constrained by their\ninternal knowledge boundaries. To overcome these limitations, the paradigm of\ndeep research has been proposed, wherein agents actively engage in planning,\nretrieval, and synthesis to generate comprehensive and faithful analytical\nreports grounded in web-based evidence. In this survey, we provide a systematic\noverview of the deep research pipeline, which comprises four core stages:\nplanning, question developing, web exploration, and report generation. For each\nstage, we analyze the key technical challenges and categorize representative\nmethods developed to address them. Furthermore, we summarize recent advances in\noptimization techniques and benchmarks tailored for deep research. Finally, we\ndiscuss open challenges and promising research directions, aiming to chart a\nroadmap toward building more capable and trustworthy deep research agents."}
{"id": "2508.12637", "pdf": "https://arxiv.org/pdf/2508.12637", "abs": "https://arxiv.org/abs/2508.12637", "authors": ["Shankaranarayanan H", "Satyapreet Singh Yadav", "Adithya Krishna", "Ajay Vikram P", "Mahesh Mehendale", "Chetan Singh Thakur"], "title": "HOMI: Ultra-Fast EdgeAI platform for Event Cameras", "categories": ["cs.AR", "cs.CV", "cs.ET", "cs.NE"], "comment": null, "summary": "Event cameras offer significant advantages for edge robotics applications due\nto their asynchronous operation and sparse, event-driven output, making them\nwell-suited for tasks requiring fast and efficient closed-loop control, such as\ngesture-based human-robot interaction. Despite this potential, existing event\nprocessing solutions remain limited, often lacking complete end-to-end\nimplementations, exhibiting high latency, and insufficiently exploiting event\ndata sparsity. In this paper, we present HOMI, an ultra-low latency, end-to-end\nedge AI platform comprising a Prophesee IMX636 event sensor chip with an Xilinx\nZynq UltraScale+MPSoC FPGA chip, deploying an in-house developed AI\naccelerator. We have developed hardware-optimized pre-processing pipelines\nsupporting both constant-time and constant-event modes for histogram\naccumulation, linear and exponential time surfaces. Our general-purpose\nimplementation caters to both accuracy-driven and low-latency applications.\nHOMI achieves 94% accuracy on the DVS Gesture dataset as a use case when\nconfigured for high accuracy operation and provides a throughput of 1000 fps\nfor low-latency configuration. The hardware-optimised pipeline maintains a\ncompact memory footprint and utilises only 33% of the available LUT resources\non the FPGA, leaving ample headroom for further latency reduction, model\nparallelisation, multi-task deployments, or integration of more complex\narchitectures."}
{"id": "2508.11995", "pdf": "https://arxiv.org/pdf/2508.11995", "abs": "https://arxiv.org/abs/2508.11995", "authors": ["Xuyang Zhao", "Shiwan Zhao", "Hualong Yu", "Liting Zhang", "Qicheng Li"], "title": "AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent systems (MAS) powered by large language models (LLMs) hold\nsignificant promise for solving complex decision-making tasks. However, the\ncore process of collaborative decision-making (CDM) within these systems\nremains underexplored. Existing approaches often rely on either ``dictatorial\"\nstrategies that are vulnerable to the cognitive biases of a single agent, or\n``voting-based\" methods that fail to fully harness collective intelligence. To\naddress these limitations, we propose \\textbf{AgentCDM}, a structured framework\nfor enhancing collaborative decision-making in LLM-based multi-agent systems.\nDrawing inspiration from the Analysis of Competing Hypotheses (ACH) in\ncognitive science, AgentCDM introduces a structured reasoning paradigm that\nsystematically mitigates cognitive biases and shifts decision-making from\npassive answer selection to active hypothesis evaluation and construction. To\ninternalize this reasoning process, we develop a two-stage training paradigm:\nthe first stage uses explicit ACH-inspired scaffolding to guide the model\nthrough structured reasoning, while the second stage progressively removes this\nscaffolding to encourage autonomous generalization. Experiments on multiple\nbenchmark datasets demonstrate that AgentCDM achieves state-of-the-art\nperformance and exhibits strong generalization, validating its effectiveness in\nimproving the quality and robustness of collaborative decisions in MAS."}
{"id": "2508.12436", "pdf": "https://arxiv.org/pdf/2508.12436", "abs": "https://arxiv.org/abs/2508.12436", "authors": ["Feifei Niu", "Chuanyi Li", "Haosheng Zuo", "Jionghan Wu", "Xin Xia"], "title": "Feature Request Analysis and Processing: Tasks, Techniques, and Trends", "categories": ["cs.SE"], "comment": null, "summary": "Feature requests are proposed by users to request new features or\nenhancements of existing features of software products, which represent users'\nwishes and demands. Satisfying users' demands can benefit the product from both\ncompetitiveness and user satisfaction. Feature requests have seen a rise in\ninterest in the past few years and the amount of research has been growing.\nHowever, the diversity in the research topics suggests the need for their\ncollective analysis to identify the challenges and opportunities so as to\npromote new advances in the future. In this work, following a defined process\nand a search protocol, we provide a systematic overview of the research area by\nsearching and categorizing relevant studies. We select and analyze 131 primary\nstudies using descriptive statistics and qualitative analysis methods. We\nclassify the studies into different topics and group them from the perspective\nof requirements engineering activities. We investigate open tools as well as\ndatasets for future research. In addition, we identify several key challenges\nand opportunities, such as: (1) ensuring the quality of feature requests, (2)\nimproving their specification and validation, and (3) developing high-quality\nbenchmarks for large language model-driven tasks."}
{"id": "2508.12007", "pdf": "https://arxiv.org/pdf/2508.12007", "abs": "https://arxiv.org/abs/2508.12007", "authors": ["Sabrina Aufiero", "Silvia Bartolucci", "Fabio Caccioli", "Pierpaolo Vivo"], "title": "Mapping Microscopic and Systemic Risks in TradFi and DeFi: a literature review", "categories": ["q-fin.RM", "econ.GN", "q-fin.EC", "q-fin.GN"], "comment": "61 pages, 3 figures", "summary": "This work explores the formation and propagation of systemic risks across\ntraditional finance (TradFi) and decentralized finance (DeFi), offering a\ncomparative framework that bridges these two increasingly interconnected\necosystems. We propose a conceptual model for systemic risk formation in\nTradFi, grounded in well-established mechanisms such as leverage cycles,\nliquidity crises, and interconnected institutional exposures. Extending this\nanalysis to DeFi, we identify unique structural and technological\ncharacteristics - such as composability, smart contract vulnerabilities, and\nalgorithm-driven mechanisms - that shape the emergence and transmission of\nrisks within decentralized systems. Through a conceptual mapping, we highlight\nrisks with similar foundations (e.g., trading vulnerabilities, liquidity\nshocks), while emphasizing how these risks manifest and propagate differently\ndue to the contrasting architectures of TradFi and DeFi. Furthermore, we\nintroduce the concept of crosstagion, a bidirectional process where instability\nin DeFi can spill over into TradFi, and vice versa. We illustrate how\ndisruptions such as liquidity crises, regulatory actions, or political\ndevelopments can cascade across these systems, leveraging their growing\ninterdependence. By analyzing this mutual dynamics, we highlight the importance\nof understanding systemic risks not only within TradFi and DeFi individually,\nbut also at their intersection. Our findings contribute to the evolving\ndiscourse on risk management in a hybrid financial ecosystem, offering insights\nfor policymakers, regulators, and financial stakeholders navigating this\ncomplex landscape."}
{"id": "2508.12007", "pdf": "https://arxiv.org/pdf/2508.12007", "abs": "https://arxiv.org/abs/2508.12007", "authors": ["Sabrina Aufiero", "Silvia Bartolucci", "Fabio Caccioli", "Pierpaolo Vivo"], "title": "Mapping Microscopic and Systemic Risks in TradFi and DeFi: a literature review", "categories": ["q-fin.RM", "econ.GN", "q-fin.EC", "q-fin.GN"], "comment": "61 pages, 3 figures", "summary": "This work explores the formation and propagation of systemic risks across\ntraditional finance (TradFi) and decentralized finance (DeFi), offering a\ncomparative framework that bridges these two increasingly interconnected\necosystems. We propose a conceptual model for systemic risk formation in\nTradFi, grounded in well-established mechanisms such as leverage cycles,\nliquidity crises, and interconnected institutional exposures. Extending this\nanalysis to DeFi, we identify unique structural and technological\ncharacteristics - such as composability, smart contract vulnerabilities, and\nalgorithm-driven mechanisms - that shape the emergence and transmission of\nrisks within decentralized systems. Through a conceptual mapping, we highlight\nrisks with similar foundations (e.g., trading vulnerabilities, liquidity\nshocks), while emphasizing how these risks manifest and propagate differently\ndue to the contrasting architectures of TradFi and DeFi. Furthermore, we\nintroduce the concept of crosstagion, a bidirectional process where instability\nin DeFi can spill over into TradFi, and vice versa. We illustrate how\ndisruptions such as liquidity crises, regulatory actions, or political\ndevelopments can cascade across these systems, leveraging their growing\ninterdependence. By analyzing this mutual dynamics, we highlight the importance\nof understanding systemic risks not only within TradFi and DeFi individually,\nbut also at their intersection. Our findings contribute to the evolving\ndiscourse on risk management in a hybrid financial ecosystem, offering insights\nfor policymakers, regulators, and financial stakeholders navigating this\ncomplex landscape."}
{"id": "2508.11800", "pdf": "https://arxiv.org/pdf/2508.11800", "abs": "https://arxiv.org/abs/2508.11800", "authors": ["Michael Bereket", "Jure Leskovec"], "title": "Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has proven remarkably effective at improving the\naccuracy of language models in verifiable and deterministic domains like\nmathematics. Here, we examine if current RL methods are also effective at\noptimizing language models in verifiable domains with stochastic outcomes, like\nscientific experiments. Through applications to synthetic data and real-world\nbiological experiments, we demonstrate that Group Relative Policy Optimization\n(GRPO) induces overconfident probability predictions for binary stochastic\noutcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out\n(RLOO) yield well-calibrated models. We show that removing group standard\nnormalization in GRPO fixes its miscalibration and provide a theoretical\nexplanation for why normalization causes overconfidence. Our results provide\nnew evidence against the use of standard normalization in GRPO and help pave\nthe way for applications of RL for reasoning language models beyond\ndeterministic domains."}
{"id": "2508.11727", "pdf": "https://arxiv.org/pdf/2508.11727", "abs": "https://arxiv.org/abs/2508.11727", "authors": ["Songyao Jin", "Biwei Huang"], "title": "Causal Structure Learning in Hawkes Processes with Complex Latent Confounder Networks", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multivariate Hawkes process provides a powerful framework for modeling\ntemporal dependencies and event-driven interactions in complex systems. While\nexisting methods primarily focus on uncovering causal structures among observed\nsubprocesses, real-world systems are often only partially observed, with latent\nsubprocesses posing significant challenges. In this paper, we show that\ncontinuous-time event sequences can be represented by a discrete-time model as\nthe time interval shrinks, and we leverage this insight to establish necessary\nand sufficient conditions for identifying latent subprocesses and the causal\ninfluences. Accordingly, we propose a two-phase iterative algorithm that\nalternates between inferring causal relationships among discovered subprocesses\nand uncovering new latent subprocesses, guided by path-based conditions that\nguarantee identifiability. Experiments on both synthetic and real-world\ndatasets show that our method effectively recovers causal structures despite\nthe presence of latent subprocesses."}
{"id": "2508.12560", "pdf": "https://arxiv.org/pdf/2508.12560", "abs": "https://arxiv.org/abs/2508.12560", "authors": ["Prabath Abeysekara", "Hai Dong"], "title": "Data-driven Trust Bootstrapping for Mobile Edge Computing-based Industrial IoT Services", "categories": ["cs.CR", "cs.DC", "cs.LG", "C.2; C.4; I.2"], "comment": "15 pages", "summary": "We propose a data-driven and context-aware approach to bootstrap\ntrustworthiness of homogeneous Internet of Things (IoT) services in Mobile Edge\nComputing (MEC) based industrial IoT (IIoT) systems. The proposed approach\naddresses key limitations in adapting existing trust bootstrapping approaches\ninto MEC-based IIoT systems. These key limitations include, the lack of\nopportunity for a service consumer to interact with a lesser-known service over\na prolonged period of time to get a robust measure of its trustworthiness,\ninability of service consumers to consistently interact with their peers to\nreceive reliable recommendations of the trustworthiness of a lesser-known\nservice as well as the impact of uneven context parameters in different MEC\nenvironments causing uneven trust environments for trust evaluation. In\naddition, the proposed approach also tackles the problem of data sparsity via\nenabling knowledge sharing among different MEC environments within a given MEC\ntopology. To verify the effectiveness of the proposed approach, we carried out\na comprehensive evaluation on two real-world datasets suitably adjusted to\nexhibit the context-dependent trust information accumulated in MEC environments\nwithin a given MEC topology. The experimental results affirmed the\neffectiveness of our approach and its suitability to bootstrap trustworthiness\nof services in MEC-based IIoT systems."}
{"id": "2508.13083", "pdf": "https://arxiv.org/pdf/2508.13083", "abs": "https://arxiv.org/abs/2508.13083", "authors": ["Joshua Z. Sobel"], "title": "Congested Clique Counting for Local Gibbs Distributions", "categories": ["cs.DC", "cs.DS"], "comment": null, "summary": "There are well established reductions between combinatorial sampling and\ncounting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very\nrecent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv\n2024), we demonstrate the first approximate counting algorithm in the\nCongestedClique for a wide range of problems. Most interestingly, we present an\nalgorithm for approximating the number of $q$-colorings of a graph within\n$\\epsilon$-multiplicative error, when $q>\\alpha\\Delta$ for any constant\n$\\alpha>2$, in $\\Tilde{O}\\big(\\frac{n^{1/3}}{\\epsilon^2}\\big)$ rounds. More\ngenerally, we achieve a runtime of\n$\\Tilde{O}\\big(\\frac{n^{1/3}}{\\epsilon^2}\\big)$ rounds for approximating the\npartition function of Gibbs distributions defined over graphs when simple\nlocality and fast mixing conditions hold. Gibbs distributions are widely used\nin fields such as machine learning and statistical physics. We obtain our\nresult by providing an algorithm to draw $n$ random samples from a distributed\nMarkov chain in parallel, using similar ideas to triangle counting (Dolev,\nLenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel,\nKaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems,\nthis result may be interesting for other applications requiring a large number\nof samples. In the special case of estimating the partition function of the\nhardcore model, also known as counting weighted independent sets, we can do\neven better and achieve an $\\Tilde{O}\\big(\\frac{1}{\\epsilon^2}\\big)$ round\nalgorithm, when the fugacity $\\lambda \\leq \\frac{\\alpha}{\\Delta-1}$, where\n$\\alpha$ is an arbitrary constant less than $1$."}
{"id": "2508.13019", "pdf": "https://arxiv.org/pdf/2508.13019", "abs": "https://arxiv.org/abs/2508.13019", "authors": ["Lucien Heitz", "Runze Li", "Oana Inel", "Abraham Bernstein"], "title": "Informfully Recommenders -- Reproducibility Framework for Diversity-aware Intra-session Recommendations", "categories": ["cs.IR"], "comment": "10 pages", "summary": "Norm-aware recommender systems have gained increased attention, especially\nfor diversity optimization. The recommender systems community has\nwell-established experimentation pipelines that support reproducible\nevaluations by facilitating models' benchmarking and comparisons against\nstate-of-the-art methods. However, to the best of our knowledge, there is\ncurrently no reproducibility framework to support thorough norm-driven\nexperimentation at the pre-processing, in-processing, post-processing, and\nevaluation stages of the recommender pipeline. To address this gap, we present\nInformfully Recommenders, a first step towards a normative reproducibility\nframework that focuses on diversity-aware design built on Cornac. Our extension\nprovides an end-to-end solution for implementing and experimenting with\nnormative and general-purpose diverse recommender systems that cover 1) dataset\npre-processing, 2) diversity-optimized models, 3) dedicated intrasession item\nre-ranking, and 4) an extensive set of diversity metrics. We demonstrate the\ncapabilities of our extension through an extensive offline experiment in the\nnews domain."}
{"id": "2508.12702", "pdf": "https://arxiv.org/pdf/2508.12702", "abs": "https://arxiv.org/abs/2508.12702", "authors": ["Jie Su", "Weiwei Wang", "Zhaotian Gu", "Dahui Wang", "Tianyi Qian"], "title": "A Unified Cortical Circuit Model with Divisive Normalization and Self-Excitation for Robust Representation and Memory Maintenance", "categories": ["q-bio.NC", "cs.AI", "cs.NE"], "comment": "15 pages, 4 figures", "summary": "Robust information representation and its persistent maintenance are\nfundamental for higher cognitive functions. Existing models employ distinct\nneural mechanisms to separately address noise-resistant processing or\ninformation maintenance, yet a unified framework integrating both operations\nremains elusive -- a critical gap in understanding cortical computation. Here,\nwe introduce a recurrent neural circuit that combines divisive normalization\nwith self-excitation to achieve both robust encoding and stable retention of\nnormalized inputs. Mathematical analysis shows that, for suitable parameter\nregimes, the system forms a continuous attractor with two key properties: (1)\ninput-proportional stabilization during stimulus presentation; and (2)\nself-sustained memory states persisting after stimulus offset. We demonstrate\nthe model's versatility in two canonical tasks: (a) noise-robust encoding in a\nrandom-dot kinematogram (RDK) paradigm; and (b) approximate Bayesian belief\nupdating in a probabilistic Wisconsin Card Sorting Test (pWCST). This work\nestablishes a unified mathematical framework that bridges noise suppression,\nworking memory, and approximate Bayesian inference within a single cortical\nmicrocircuit, offering fresh insights into the brain's canonical computation\nand guiding the design of biologically plausible artificial neural\narchitectures."}
{"id": "2508.12022", "pdf": "https://arxiv.org/pdf/2508.12022", "abs": "https://arxiv.org/abs/2508.12022", "authors": ["Dorsa Macky Aleagha", "Payam Zohari", "Mostafa Haghir Chehreghani"], "title": "AI Models for Depressive Disorder Detection and Diagnosis: A Review", "categories": ["cs.AI"], "comment": null, "summary": "Major Depressive Disorder is one of the leading causes of disability\nworldwide, yet its diagnosis still depends largely on subjective clinical\nassessments. Integrating Artificial Intelligence (AI) holds promise for\ndeveloping objective, scalable, and timely diagnostic tools. In this paper, we\npresent a comprehensive survey of state-of-the-art AI methods for depression\ndetection and diagnosis, based on a systematic review of 55 key studies. We\nintroduce a novel hierarchical taxonomy that structures the field by primary\nclinical task (diagnosis vs. prediction), data modality (text, speech,\nneuroimaging, multimodal), and computational model class (e.g., graph neural\nnetworks, large language models, hybrid approaches). Our in-depth analysis\nreveals three major trends: the predominance of graph neural networks for\nmodeling brain connectivity, the rise of large language models for linguistic\nand conversational data, and an emerging focus on multimodal fusion,\nexplainability, and algorithmic fairness. Alongside methodological insights, we\nprovide an overview of prominent public datasets and standard evaluation\nmetrics as a practical guide for researchers. By synthesizing current advances\nand highlighting open challenges, this survey offers a comprehensive roadmap\nfor future innovation in computational psychiatry."}
{"id": "2508.12546", "pdf": "https://arxiv.org/pdf/2508.12546", "abs": "https://arxiv.org/abs/2508.12546", "authors": ["Bin Duan", "Ruican Dong", "Naipeng Dong", "Dan Dongseong Kim", "Guowei Yang"], "title": "XAMT: Cross-Framework API Matching for Testing Deep Learning Libraries", "categories": ["cs.SE"], "comment": null, "summary": "Deep learning powers critical applications such as autonomous driving,\nhealthcare, and finance, where the correctness of underlying libraries is\nessential. Bugs in widely used deep learning APIs can propagate to downstream\nsystems, causing serious consequences. While existing fuzzing techniques detect\nbugs through intra-framework testing across hardware backends (CPU vs. GPU),\nthey may miss bugs that manifest identically across backends and thus escape\ndetection under these strategies. To address this problem, we propose XAMT, a\ncross-framework fuzzing method that tests deep learning libraries by matching\nand comparing functionally equivalent APIs across different frameworks. XAMT\nmatches APIs using similarity-based rules based on names, descriptions, and\nparameter structures. It then aligns inputs and applies variance-guided\ndifferential testing to detect bugs. We evaluated XAMT on five popular\nframeworks, including PyTorch, TensorFlow, Keras, Chainer, and JAX. XAMT\nmatched 839 APIs and identified 238 matched API groups, and detected 17 bugs,\n12 of which have been confirmed. Our results show that XAMT uncovers bugs\nundetectable by intra-framework testing, especially those that manifest\nconsistently across backends. XAMT offers a complementary approach to existing\nmethods and offers a new perspective on the testing of deep learning libraries."}
{"id": "2508.12479", "pdf": "https://arxiv.org/pdf/2508.12479", "abs": "https://arxiv.org/abs/2508.12479", "authors": ["Chinmay Maheshwari", "Chinmay Pimpalkhare", "Debasish Chatterjee"], "title": "EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization", "categories": ["math.OC", "cs.AI", "cs.GT", "cs.MA", "econ.GN", "q-fin.EC", "90C26, 90C47, 68Q32, 91A06, 65K05"], "comment": "31 pages, 2 figures, 3 tables", "summary": "Min-max optimization arises in many domains such as game theory, adversarial\nmachine learning, etc., with gradient-based methods as a typical computational\ntool. Beyond convex-concave min-max optimization, the solutions found by\ngradient-based methods may be arbitrarily far from global optima. In this work,\nwe present an algorithmic apparatus for computing globally optimal solutions in\nconvex-non-concave and non-convex-concave min-max optimization. For former, we\nemploy a reformulation that transforms it into a non-concave-convex max-min\noptimization problem with suitably defined feasible sets and objective\nfunction. The new form can be viewed as a generalization of Sion's minimax\ntheorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm\nfor solving the reformulated max-min problem. EXOTIC employs an iterative\nconvex optimization solver to (approximately) solve the inner minimization and\na hierarchical tree search for the outer maximization to optimistically select\npromising regions to search based on the approximate solution returned by\nconvex optimization solver. We establish an upper bound on its optimality gap\nas a function of the number of calls to the inner solver, the solver's\nconvergence rate, and additional problem-dependent parameters. Both our\nalgorithmic apparatus along with its accompanying theoretical analysis can also\nbe applied for non-convex-concave min-max optimization. In addition, we propose\na class of benchmark convex-non-concave min-max problems along with their\nanalytical global solutions, providing a testbed for evaluating algorithms for\nmin-max optimization. Empirically, EXOTIC outperforms gradient-based methods on\nthis benchmark as well as on existing numerical benchmark problems from the\nliterature. Finally, we demonstrate the utility of EXOTIC by computing security\nstrategies in multi-player games with three or more players."}
{"id": "2508.12479", "pdf": "https://arxiv.org/pdf/2508.12479", "abs": "https://arxiv.org/abs/2508.12479", "authors": ["Chinmay Maheshwari", "Chinmay Pimpalkhare", "Debasish Chatterjee"], "title": "EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization", "categories": ["math.OC", "cs.AI", "cs.GT", "cs.MA", "econ.GN", "q-fin.EC", "90C26, 90C47, 68Q32, 91A06, 65K05"], "comment": "31 pages, 2 figures, 3 tables", "summary": "Min-max optimization arises in many domains such as game theory, adversarial\nmachine learning, etc., with gradient-based methods as a typical computational\ntool. Beyond convex-concave min-max optimization, the solutions found by\ngradient-based methods may be arbitrarily far from global optima. In this work,\nwe present an algorithmic apparatus for computing globally optimal solutions in\nconvex-non-concave and non-convex-concave min-max optimization. For former, we\nemploy a reformulation that transforms it into a non-concave-convex max-min\noptimization problem with suitably defined feasible sets and objective\nfunction. The new form can be viewed as a generalization of Sion's minimax\ntheorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm\nfor solving the reformulated max-min problem. EXOTIC employs an iterative\nconvex optimization solver to (approximately) solve the inner minimization and\na hierarchical tree search for the outer maximization to optimistically select\npromising regions to search based on the approximate solution returned by\nconvex optimization solver. We establish an upper bound on its optimality gap\nas a function of the number of calls to the inner solver, the solver's\nconvergence rate, and additional problem-dependent parameters. Both our\nalgorithmic apparatus along with its accompanying theoretical analysis can also\nbe applied for non-convex-concave min-max optimization. In addition, we propose\na class of benchmark convex-non-concave min-max problems along with their\nanalytical global solutions, providing a testbed for evaluating algorithms for\nmin-max optimization. Empirically, EXOTIC outperforms gradient-based methods on\nthis benchmark as well as on existing numerical benchmark problems from the\nliterature. Finally, we demonstrate the utility of EXOTIC by computing security\nstrategies in multi-player games with three or more players."}
{"id": "2508.11810", "pdf": "https://arxiv.org/pdf/2508.11810", "abs": "https://arxiv.org/abs/2508.11810", "authors": ["Nitish Nagesh", "Salar Shakibhamedan", "Mahdi Bagheri", "Ziyu Wang", "Nima TaheriNejad", "Axel Jantsch", "Amir M. Rahmani"], "title": "FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generating synthetic data is crucial in privacy-sensitive, data-scarce\nsettings, especially for tabular datasets widely used in real-world\napplications. A key challenge is improving counterfactual and causal fairness,\nwhile preserving high utility. We present FairTabGen, a fairness-aware large\nlanguage model-based framework for tabular synthetic data generation. We\nintegrate multiple fairness definitions including counterfactual and causal\nfairness into both its generation and evaluation pipelines. We use in-context\nlearning, prompt refinement, and fairness-aware data curation to balance\nfairness and utility. Across diverse datasets, our method outperforms\nstate-of-the-art GAN-based and LLM-based methods, achieving up to 10%\nimprovements on fairness metrics such as demographic parity and path-specific\ncausal effects while retaining statistical utility. Remarkably, it achieves\nthese gains using less than 20% of the original data, highlighting its\nefficiency in low-data regimes. These results demonstrate a principled and\npractical approach for generating fair and useful synthetic tabular data."}
{"id": "2508.11780", "pdf": "https://arxiv.org/pdf/2508.11780", "abs": "https://arxiv.org/abs/2508.11780", "authors": ["Moindjié Issam-Ali", "Descary Marie-Hélène", "Beaulac Cédric"], "title": "Statistical analysis of multivariate planar curves and applications to X-ray classification", "categories": ["stat.ME", "cs.CV", "stat.ML"], "comment": null, "summary": "Recent developments in computer vision have enabled the availability of\nsegmented images across various domains, such as medicine, where segmented\nradiography images play an important role in diagnosis-making. As prediction\nproblems are common in medical image analysis, this work explores the use of\nsegmented images (through the associated contours they highlight) as predictors\nin a supervised classification context. Consequently, we develop a new approach\nfor image analysis that takes into account the shape of objects within images.\nFor this aim, we introduce a new formalism that extends the study of single\nrandom planar curves to the joint analysis of multiple planar curves-referred\nto here as multivariate planar curves. In this framework, we propose a solution\nto the alignment issue in statistical shape analysis. The obtained multivariate\nshape variables are then used in functional classification methods through\ntangent projections. Detection of cardiomegaly in segmented X-rays and\nnumerical experiments on synthetic data demonstrate the appeal and robustness\nof the proposed method."}
{"id": "2508.12978", "pdf": "https://arxiv.org/pdf/2508.12978", "abs": "https://arxiv.org/abs/2508.12978", "authors": ["Yue Xia", "Tayyebeh Jahani-Nezhad", "Rawad Bitar"], "title": "Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.IT", "math.IT"], "comment": null, "summary": "We propose Fed-DPRoC, a novel federated learning framework that\nsimultaneously ensures differential privacy (DP), Byzantine robustness, and\ncommunication efficiency. We introduce the concept of robust-compatible\ncompression, which enables users to compress DP-protected updates while\nmaintaining the robustness of the aggregation rule. We instantiate our\nframework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for\ncompression with robust averaging for robust aggregation. We theoretically\nprove the compatibility of JL transform with robust averaging and show that\nRobAJoL preserves robustness guarantees, ensures DP, and reduces communication\ncost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims\nand demonstrate that RobAJoL outperforms existing methods in terms of\nrobustness and utility under different Byzantine attacks."}
{"id": "2508.13100", "pdf": "https://arxiv.org/pdf/2508.13100", "abs": "https://arxiv.org/abs/2508.13100", "authors": ["Jason Hartline", "Lunjia Hu", "Yifan Wu"], "title": "A Perfectly Truthful Calibration Measure", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "Calibration requires that predictions are conditionally unbiased and,\ntherefore, reliably interpretable as probabilities. Calibration measures\nquantify how far a predictor is from perfect calibration. As introduced by\nHaghtalab et al. (2024), a calibration measure is truthful if it is minimized\nin expectation when a predictor outputs the ground-truth probabilities.\nAlthough predicting the true probabilities guarantees perfect calibration, in\nreality, when calibration is evaluated on a finite sample, predicting the truth\nis not guaranteed to minimize any known calibration measure. All known\ncalibration measures incentivize predictors to lie in order to appear more\ncalibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et\nal. (2024) and Qiao and Zhao (2025) to construct approximately truthful\ncalibration measures in the sequential prediction setting, but no perfectly\ntruthful calibration measure was known to exist even in the more basic batch\nsetting.\n  We design a perfectly truthful calibration measure in the batch setting:\naveraged two-bin calibration error (ATB). In addition to being truthful, ATB is\nsound, complete, continuous, and quadratically related to two existing\ncalibration measures: the smooth calibration error (smCal) and the (lower)\ndistance to calibration (distCal). The simplicity in our definition of ATB\nmakes it efficient and straightforward to compute. ATB allows faster estimation\nalgorithms with significantly easier implementations than smCal and distCal,\nachieving improved running time and simplicity for the calibration testing\nproblem studied by Hu et al. (2024). We also introduce a general recipe for\nconstructing truthful measures, which proves the truthfulness of ATB as a\nspecial case and allows us to construct other truthful calibration measures\nsuch as quantile-binned l_2-ECE."}
{"id": "2508.13035", "pdf": "https://arxiv.org/pdf/2508.13035", "abs": "https://arxiv.org/abs/2508.13035", "authors": ["Runze Li", "Lucien Heitz", "Oana Inel", "Abraham Bernstein"], "title": "D-RDW: Diversity-Driven Random Walks for News Recommender Systems", "categories": ["cs.IR"], "comment": "6 pages", "summary": "This paper introduces Diversity-Driven RandomWalks (D-RDW), a lightweight\nalgorithm and re-ranking technique that generates diverse news recommendations.\nD-RDW is a societal recommender, which combines the diversification\ncapabilities of the traditional random walk algorithms with customizable target\ndistributions of news article properties. In doing so, our model provides a\ntransparent approach for editors to incorporate norms and values into the\nrecommendation process. D-RDW shows enhanced performance across key diversity\nmetrics that consider the articles' sentiment and political party mentions when\ncompared to state-of-the-art neural models. Furthermore, D-RDW proves to be\nmore computationally efficient than existing approaches."}
{"id": "2508.12975", "pdf": "https://arxiv.org/pdf/2508.12975", "abs": "https://arxiv.org/abs/2508.12975", "authors": ["Jonas Oberste-Frielinghaus", "Anno C. Kurth", "Julian Göltz", "Laura Kriener", "Junji Ito", "Mihai A. Petrovici", "Sonja Grün"], "title": "Synchronization and semantization in deep spiking networks", "categories": ["q-bio.NC", "cs.NE", "stat.CO"], "comment": "16 pages, 4 figures, 4 supplementary figures", "summary": "Recent studies have shown how spiking networks can learn complex\nfunctionality through error-correcting plasticity, but the resulting structures\nand dynamics remain poorly studied. To elucidate how these models may link to\nobserved dynamics in vivo and thus how they may ultimately explain cortical\ncomputation, we need a better understanding of their emerging patterns. We\ntrain a multi-layer spiking network, as a conceptual analog of the bottom-up\nvisual hierarchy, for visual input classification using spike-time encoding.\nAfter learning, we observe the development of distinct spatio-temporal activity\npatterns. While input patterns are synchronous by construction, activity in\nearly layers first spreads out over time, followed by re-convergence into sharp\npulses as classes are gradually extracted. The emergence of synchronicity is\naccompanied by the formation of increasingly distinct pathways, reflecting the\ngradual semantization of input activity. We thus observe hierarchical networks\nlearning spike latency codes to naturally acquire activity patterns\ncharacterized by synchronicity and separability, with pronounced excitatory\npathways ascending through the layers. This provides a rigorous computational\nhypothesis for the experimentally observed synchronicity in the visual system\nas a natural consequence of deep learning in cortex."}
{"id": "2508.12026", "pdf": "https://arxiv.org/pdf/2508.12026", "abs": "https://arxiv.org/abs/2508.12026", "authors": ["Szymon Pawlonka", "Mikołaj Małkiński", "Jacek Mańdziuk"], "title": "Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Bongard Problems (BPs) provide a challenging testbed for abstract visual\nreasoning (AVR), requiring models to identify visual concepts fromjust a few\nexamples and describe them in natural language. Early BP benchmarks featured\nsynthetic black-and-white drawings, which might not fully capture the\ncomplexity of real-world scenes. Subsequent BP datasets employed real-world\nimages, albeit the represented concepts are identifiable from high-level image\nfeatures, reducing the task complexity. Differently, the recently released\nBongard-RWR dataset aimed at representing abstract concepts formulated in the\noriginal BPs using fine-grained real-world images. Its manual construction,\nhowever, limited the dataset size to just $60$ instances, constraining\nevaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset\ncomposed of $5\\,400$ instances that represent original BP abstract concepts\nusing real-world-like images generated via a vision language model (VLM)\npipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually\ncurated images and generate new descriptions aligned with the underlying\nconcepts, use Flux.1-dev to synthesize images from these descriptions, and\nmanually verify that the generated images faithfully reflect the intended\nconcepts. We evaluate state-of-the-art VLMs across diverse BP formulations,\nincluding binary and multiclass classification, as well as textual answer\ngeneration. Our findings reveal that while VLMs can recognize coarse-grained\nvisual concepts, they consistently struggle with discerning fine-grained\nconcepts, highlighting limitations in their reasoning capabilities."}
{"id": "2508.12620", "pdf": "https://arxiv.org/pdf/2508.12620", "abs": "https://arxiv.org/abs/2508.12620", "authors": ["Xiaoning Ren", "Qiang Hu", "Wei Ma", "Yan Li", "Yao Zhang", "Lingxiao Jiang", "Yinxing Xue"], "title": "Strengthening Programming Comprehension in Large Language Models through Code Generation", "categories": ["cs.SE", "cs.PL"], "comment": "11 pages, 7 figures", "summary": "Large language models (LLMs) have recently shown impressive results on\ndiverse code-related tasks, benefiting from large-scale training and\ninstruction tuning. However, studies reveal that their grasp of fundamental\nprogramming concepts, such as data flow and control flow, remains shallow,\nleading to fragile performance when code requires deeper reasoning. This\nlimitation restricts the practical adoption of LLMs in real-world software\ndevelopment. To address this issue, this work introduces a counterfactual code\naugmentation framework combined with concept-aware tuning, designed to guide\nLLMs toward stronger conceptual understanding. Comprehensive evaluation across\nmultiple models and benchmarks demonstrates the effectiveness of the proposed\napproach."}
{"id": "2508.11876", "pdf": "https://arxiv.org/pdf/2508.11876", "abs": "https://arxiv.org/abs/2508.11876", "authors": ["Hoang-Thang Ta", "Duy-Quy Thai", "Phuong-Linh Tran-Thi"], "title": "Combinations of Fast Activation and Trigonometric Functions in Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": "6pages", "summary": "For years, many neural networks have been developed based on the\nKolmogorov-Arnold Representation Theorem (KART), which was created to address\nHilbert's 13th problem. Recently, relying on KART, Kolmogorov-Arnold Networks\n(KANs) have attracted attention from the research community, stimulating the\nuse of polynomial functions such as B-splines and RBFs. However, these\nfunctions are not fully supported by GPU devices and are still considered less\npopular. In this paper, we propose the use of fast computational functions,\nsuch as ReLU and trigonometric functions (e.g., ReLU, sin, cos, arctan), as\nbasis components in Kolmogorov-Arnold Networks (KANs). By integrating these\nfunction combinations into the network structure, we aim to enhance\ncomputational efficiency. Experimental results show that these combinations\nmaintain competitive performance while offering potential improvements in\ntraining time and generalization."}
{"id": "2508.11982", "pdf": "https://arxiv.org/pdf/2508.11982", "abs": "https://arxiv.org/abs/2508.11982", "authors": ["Luis Gruber", "Gregor Kastner", "Anirban Bhattacharya", "Debdeep Pati", "Natesh Pillai", "David Dunson"], "title": "A note on simulation methods for the Dirichlet-Laplace prior", "categories": ["stat.CO", "econ.EM", "stat.ME", "stat.ML"], "comment": "Correction: Bhattacharya, A., Pati, D., Pillai, N.S., and Dunson,\n  D.B. (2015), \"Dirichlet-Laplace Priors for Optimal Shrinkage,\" Journal of the\n  American Statistical Association, 110, 1479-1490, DOI:\n  10.1080/01621459.2014.960967", "summary": "Bhattacharya et al. (2015, Journal of the American Statistical Association\n110(512): 1479-1490) introduce a novel prior, the Dirichlet-Laplace (DL) prior,\nand propose a Markov chain Monte Carlo (MCMC) method to simulate posterior\ndraws under this prior in a conditionally Gaussian setting. The original\nalgorithm samples from conditional distributions in the wrong order, i.e., it\ndoes not correctly sample from the joint posterior distribution of all latent\nvariables. This note details the issue and provides two simple solutions: A\ncorrection to the original algorithm and a new algorithm based on an\nalternative, yet equivalent, formulation of the prior. This corrigendum does\nnot affect the theoretical results in Bhattacharya et al. (2015)."}
{"id": "2508.13064", "pdf": "https://arxiv.org/pdf/2508.13064", "abs": "https://arxiv.org/abs/2508.13064", "authors": ["Seongeun Ryu", "Yunyong Ko", "Sang-Wook Kim"], "title": "Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": "10 pages, 7 figures, 4 tables, accepted at ACM International\n  Conference on Information and Knowledge Management (CIKM)", "summary": "Personalized news recommendation aims to deliver news articles aligned with\nusers' interests, serving as a key solution to alleviate the problem of\ninformation overload on online news platforms. While prior work has improved\ninterest matching through refined representations of news and users, the\nfollowing time-related challenges remain underexplored: (C1) leveraging the age\nof clicked news to infer users' interest persistence, and (C2) modeling the\nvarying lifetime of news across topics and users. To jointly address these\nchallenges, we propose a novel Lifetime-aware Interest Matching framework for\nnEws recommendation, named LIME, which incorporates three key strategies: (1)\nUser-Topic lifetime-aware age representation to capture the relative age of\nnews with respect to a user-topic pair, (2) Candidate-aware lifetime attention\nfor generating temporally aligned user representation, and (3) Freshness-guided\ninterest refinement for prioritizing valid candidate news at prediction time.\nExtensive experiments on two real-world datasets demonstrate that LIME\nconsistently outperforms a wide range of state-of-the-art news recommendation\nmethods, and its model agnostic strategies significantly improve recommendation\naccuracy."}
{"id": "2508.12027", "pdf": "https://arxiv.org/pdf/2508.12027", "abs": "https://arxiv.org/abs/2508.12027", "authors": ["Filippo Torresan", "Keisuke Suzuki", "Ryota Kanai", "Manuel Baltieri"], "title": "Active inference for action-unaware agents", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "comment": "59 pages, 47 figures", "summary": "Active inference is a formal approach to study cognition based on the notion\nthat adaptive agents can be seen as engaging in a process of approximate\nBayesian inference, via the minimisation of variational and expected free\nenergies. Minimising the former provides an account of perceptual processes and\nlearning as evidence accumulation, while minimising the latter describes how\nagents select their actions over time. In this way, adaptive agents are able to\nmaximise the likelihood of preferred observations or states, given a generative\nmodel of the environment. In the literature, however, different strategies have\nbeen proposed to describe how agents can plan their future actions. While they\nall share the notion that some kind of expected free energy offers an\nappropriate way to score policies, sequences of actions, in terms of their\ndesirability, there are different ways to consider the contribution of past\nmotor experience to the agent's future behaviour. In some approaches, agents\nare assumed to know their own actions, and use such knowledge to better plan\nfor the future. In other approaches, agents are unaware of their actions, and\nmust infer their motor behaviour from recent observations in order to plan for\nthe future. This difference reflects a standard point of departure in two\nleading frameworks in motor control based on the presence, or not, of an\nefference copy signal representing knowledge about an agent's own actions. In\nthis work we compare the performances of action-aware and action-unaware agents\nin two navigations tasks, showing how action-unaware agents can achieve\nperformances comparable to action-aware ones while at a severe disadvantage."}
{"id": "2508.12649", "pdf": "https://arxiv.org/pdf/2508.12649", "abs": "https://arxiv.org/abs/2508.12649", "authors": ["Lei Chen", "Michele Lanza", "Shinpei Hayashi"], "title": "ChangePrism: Visualizing the Essence of Code Changes", "categories": ["cs.SE"], "comment": "5 pages, 5 figures, VISSOFT 2025", "summary": "Understanding the changes made by developers when they submit a pull request\nand/or perform a commit on a repository is a crucial activity in software\nmaintenance and evolution. The common way to review changes relies on examining\ncode diffs, where textual differences between two file versions are highlighted\nin red and green to indicate additions and deletions of lines. This can be\ncumbersome for developers, making it difficult to obtain a comprehensive\noverview of all changes in a commit. Moreover, certain types of code changes\ncan be particularly significant and may warrant differentiation from standard\nmodifications to enhance code comprehension. We present a novel visualization\napproach supported by a tool named ChangePrism, which provides a way to better\nunderstand code changes. The tool comprises two components: extraction, which\nretrieves code changes and relevant information from the git history, and\nvisualization, which offers both general and detailed views of code changes in\ncommits. The general view provides an overview of different types of code\nchanges across commits, while the detailed view displays the exact changes in\nthe source code for each commit."}
{"id": "2508.11880", "pdf": "https://arxiv.org/pdf/2508.11880", "abs": "https://arxiv.org/abs/2508.11880", "authors": ["Yuto Omae"], "title": "PCA- and SVM-Grad-CAM for Convolutional Neural Networks: Closed-form Jacobian Expression", "categories": ["cs.LG", "I.2.0; I.5.0"], "comment": "15 pages", "summary": "Convolutional Neural Networks (CNNs) are an effective approach for\nclassification tasks, particularly when the training dataset is large. Although\nCNNs have long been considered a black-box classification method, they can be\nused as a white-box method through visualization techniques such as Grad-CAM.\nWhen training samples are limited, incorporating a Principal Component Analysis\n(PCA) layer and/or a Support Vector Machine (SVM) classifier into a CNN can\neffectively improve classification performance. However, traditional Grad-CAM\ncannot be directly applied to PCA and/or SVM layers. It is important to\ngenerate attention regions for PCA and/or SVM layers in CNNs to facilitate the\ndevelopment of white-box methods. Therefore, we propose ``PCA-Grad-CAM'', a\nmethod for visualizing attention regions in PCA feature vectors, and\n``SVM-Grad-CAM'', a method for visualizing attention regions in an SVM\nclassifier layer. To complete our methods analytically, it is necessary to\nsolve the closed-form Jacobian consisting of partial derivatives from the last\nconvolutional layer to the PCA and/or SVM layers. In this paper, we present the\nexact closed-form Jacobian and the visualization results of our methods applied\nto several major datasets."}
{"id": "2508.11990", "pdf": "https://arxiv.org/pdf/2508.11990", "abs": "https://arxiv.org/abs/2508.11990", "authors": ["Evan Dogariu", "Anand Brahmbhatt", "Elad Hazan"], "title": "Universal Learning of Nonlinear Dynamics", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "We study the fundamental problem of learning a marginally stable unknown\nnonlinear dynamical system. We describe an algorithm for this problem, based on\nthe technique of spectral filtering, which learns a mapping from past\nobservations to the next based on a spectral representation of the system.\nUsing techniques from online convex optimization, we prove vanishing prediction\nerror for any nonlinear dynamical system that has finitely many marginally\nstable modes, with rates governed by a novel quantitative control-theoretic\nnotion of learnability. The main technical component of our method is a new\nspectral filtering algorithm for linear dynamical systems, which incorporates\npast observations and applies to general noisy and marginally stable systems.\nThis significantly generalizes the original spectral filtering algorithm to\nboth asymmetric dynamics as well as incorporating noise correction, and is of\nindependent interest."}
{"id": "2508.11845", "pdf": "https://arxiv.org/pdf/2508.11845", "abs": "https://arxiv.org/abs/2508.11845", "authors": ["Marius Miron", "David Robinson", "Milad Alizadeh", "Ellen Gilsenan-McMahon", "Gagan Narula", "Olivier Pietquin", "Matthieu Geist", "Emmanuel Chemla", "Maddie Cusimano", "Felix Effenberger", "Masato Hagiwara", "Benjamin Hoffman", "Sara Keen", "Diane Kim", "Jane Lawton", "Jen-Yu Liu", "Aza Raskin"], "title": "What Matters for Bioacoustic Encoding", "categories": ["cs.SD", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Bioacoustics, the study of sounds produced by living organisms, plays a vital\nrole in conservation, biodiversity monitoring, and behavioral studies. Many\ntasks in this field, such as species, individual, and behavior classification\nand detection, are well-suited to machine learning. However, they often suffer\nfrom limited annotated data, highlighting the need for a general-purpose\nbioacoustic encoder capable of extracting useful representations for diverse\ndownstream tasks. Such encoders have been proposed before, but are often\nlimited in scope due to a focus on a narrow range of species (typically birds),\nand a reliance on a single model architecture or training paradigm. Moreover,\nthey are usually evaluated on a small set of tasks and datasets. In this work,\nwe present a large-scale empirical study that covers aspects of bioacoustics\nthat are relevant to research but have previously been scarcely considered:\ntraining data diversity and scale, model architectures and training recipes,\nand the breadth of evaluation tasks and datasets. We obtain encoders that are\nstate-of-the-art on the existing and proposed benchmarks. We also identify what\nmatters for training these encoders, such that this work can be extended when\nmore data are available or better architectures are proposed. Specifically,\nacross 26 datasets with tasks including species classification, detection,\nindividual ID, and vocal repertoire discovery, we find self-supervised\npre-training followed by supervised post-training on a mixed bioacoustics +\ngeneral-audio corpus yields the strongest in- and out-of-distribution\nperformance. We show the importance of data diversity in both stages. To\nsupport ongoing research and application, we will release the model\ncheckpoints."}
{"id": "2508.12087", "pdf": "https://arxiv.org/pdf/2508.12087", "abs": "https://arxiv.org/abs/2508.12087", "authors": ["Zhanjiang Yang", "Meng Li", "Yang Shen", "Yueming Li", "Lijun Sun"], "title": "MAPF-World: Action World Model for Multi-Agent Path Finding", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent path finding (MAPF) is the problem of planning conflict-free\npaths from the designated start locations to goal positions for multiple\nagents. It underlies a variety of real-world tasks, including multi-robot\ncoordination, robot-assisted logistics, and social navigation. Recent\ndecentralized learnable solvers have shown great promise for large-scale MAPF,\nespecially when leveraging foundation models and large datasets. However, these\nagents are reactive policy models and exhibit limited modeling of environmental\ntemporal dynamics and inter-agent dependencies, resulting in performance\ndegradation in complex, long-term planning scenarios. To address these\nlimitations, we propose MAPF-World, an autoregressive action world model for\nMAPF that unifies situation understanding and action generation, guiding\ndecisions beyond immediate local observations. It improves situational\nawareness by explicitly modeling environmental dynamics, including spatial\nfeatures and temporal dependencies, through future state and actions\nprediction. By incorporating these predicted futures, MAPF-World enables more\ninformed, coordinated, and far-sighted decision-making, especially in complex\nmulti-agent settings. Furthermore, we augment MAPF benchmarks by introducing an\nautomatic map generator grounded in real-world scenarios, capturing practical\nmap layouts for training and evaluating MAPF solvers. Extensive experiments\ndemonstrate that MAPF-World outperforms state-of-the-art learnable solvers,\nshowcasing superior zero-shot generalization to out-of-distribution cases.\nNotably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced\ndata."}
{"id": "2508.12922", "pdf": "https://arxiv.org/pdf/2508.12922", "abs": "https://arxiv.org/abs/2508.12922", "authors": ["Yue Wang", "Zhenyu Chen", "Yuan Zhao", "Chunrong Fang", "Ziyuan Wang", "Song Huang"], "title": "RUM: Rule+LLM-Based Comprehensive Assessment on Testing Skills", "categories": ["cs.SE"], "comment": null, "summary": "Over the past eight years, the META method has served as a multidimensional\ntesting skill assessment system in the National College Student Contest on\nSoftware Testing, successfully assessing over 100,000 students' testing skills.\nHowever, META is primarily limited to the objective assessment of test scripts,\nlacking the ability to automatically assess subjective aspects such as test\ncase and test report. To address this limitation, this paper proposes RUM, a\ncomprehensive assessment approach that combines rules and large language models\n(LLMs). RUM achieves a comprehensive assessment by rapidly processing objective\nindicators through rules while utilizing LLMs for in-depth subjective analysis\nof test case documents, test scripts, and test reports. The experimental\nresults show that compared to traditional manual testing skill assessment, RUM\nimproves assessment efficiency by 80.77\\% and reduces costs by 97.38\\%, while\nmaintaining high accuracy and consistency of assessment. By applying RUM on the\ncontest on software testing, we find that it not only enhances the efficiency\nand scalability of skill assessment in software testing education, but also\nprovides teachers with more comprehensive and objective evidence for student\nability assessment, facilitating personalized teaching and learning. This study\noffers new insights into the assessment of testing skills, which are expected\nto promote further development in test process optimization and software\nquality assurance."}
{"id": "2508.11921", "pdf": "https://arxiv.org/pdf/2508.11921", "abs": "https://arxiv.org/abs/2508.11921", "authors": ["Yibo Zhong"], "title": "ENA: Efficient N-dimensional Attention", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "WIP", "summary": "Efficient modeling of long sequences of high-order data requires a more\nefficient architecture than Transformer. In this paper, we investigate two key\naspects of extending linear recurrent models, especially those originally\ndesigned for language modeling, to high-order data (1D to ND): scanning\nstrategies and attention-hybrid architectures. Empirical results suggest that\nscanning provides limited benefits, while attention-hybrid models yield\npromising results. Focusing on the latter, we further evaluate types of\nattention and find that tiled high-order sliding window attention (SWA) is\nefficient in both theory and practice. We term the resulting hybrid\narchitecture of linear recurrence and high-order SWA as Efficient N-dimensional\nAttention (ENA). We then conduct several experiments to demonstrate its\neffectiveness. The intuition behind ENA is that linear recurrence compresses\nglobal information into a state, while SWA complements it by enforcing strict\nlocal modeling. Together, they form a simple framework that offers a promising\nand practical solution for ultra-long high-order data modeling."}
{"id": "2508.12085", "pdf": "https://arxiv.org/pdf/2508.12085", "abs": "https://arxiv.org/abs/2508.12085", "authors": ["Yuyang Huo", "Xiaoyang Wu", "Changliang Zou", "Haojie Ren"], "title": "Unified Conformalized Multiple Testing with Full Data Efficiency", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Conformalized multiple testing offers a model-free way to control predictive\nuncertainty in decision-making. Existing methods typically use only part of the\navailable data to build score functions tailored to specific settings. We\npropose a unified framework that puts data utilization at the center: it uses\nall available data-null, alternative, and unlabeled-to construct scores and\ncalibrate p-values through a full permutation strategy. This unified use of all\navailable data significantly improves power by enhancing non-conformity score\nquality and maximizing calibration set size while rigorously controlling the\nfalse discovery rate. Crucially, our framework provides a systematic design\nprinciple for conformal testing and enables automatic selection of the best\nconformal procedure among candidates without extra data splitting. Extensive\nnumerical experiments demonstrate that our enhanced methods deliver superior\nefficiency and adaptability across diverse scenarios."}
{"id": "2508.11999", "pdf": "https://arxiv.org/pdf/2508.11999", "abs": "https://arxiv.org/abs/2508.11999", "authors": ["Daoze Zhang", "Zhanheng Nie", "Jianyu Liu", "Chenghan Fu", "Wanxian Guan", "Yuan Gao", "Jun Song", "Pengjie Wang", "Jian Xu", "Bo Zheng"], "title": "MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding", "categories": ["cs.CV", "cs.AI", "cs.IR", "cs.LG"], "comment": "11 pages, 9 figures", "summary": "With the rapid advancement of e-commerce, exploring general representations\nrather than task-specific ones has attracted increasing research attention. For\nproduct understanding, although existing discriminative dual-flow architectures\ndrive progress in this field, they inherently struggle to model the many-to-one\nalignment between multiple images and texts of products. Therefore, we argue\nthat generative Multimodal Large Language Models (MLLMs) hold significant\npotential for improving product representation learning. Nevertheless,\nachieving this goal still remains non-trivial due to several key challenges:\nthe lack of multimodal and aspect-aware modeling modules in typical LLMs; the\ncommon presence of background noise in product images; and the absence of a\nstandard benchmark for evaluation. To address these issues, we propose the\nfirst generative MLLM-based model named MOON for product representation\nlearning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for\ntargeted modeling of multimodal and aspect-specific product content; (2)\neffectively detects core semantic regions in product images to mitigate the\ndistraction and interference caused by background noise; and (3) introduces the\nspecialized negative sampling strategy to increase the difficulty and diversity\nof negative samples. In addition, we release a large-scale multimodal benchmark\nMBE for various product understanding tasks. Experimentally, our model\ndemonstrates competitive zero-shot performance on both our benchmark and the\npublic dataset, showcasing strong generalization across various downstream\ntasks, including cross-modal retrieval, product classification, and attribute\nprediction. Furthermore, the case study and visualization illustrate the\neffectiveness of MOON for product understanding."}
{"id": "2508.12100", "pdf": "https://arxiv.org/pdf/2508.12100", "abs": "https://arxiv.org/abs/2508.12100", "authors": ["Daniel Burkhardt", "Xiangwei Cheng"], "title": "Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios", "categories": ["cs.AI"], "comment": "13 pages, 1 figure, 6 tables", "summary": "Reasoning in interactive problem solving scenarios requires models to\nconstruct reasoning threads that reflect user understanding and align with\nstructured domain knowledge. However, current reasoning models often lack\nexplicit semantic hierarchies, user-domain knowledge alignment, and principled\nmechanisms to prune reasoning threads for effectiveness. These limitations\nresult in lengthy generic output that does not guide users through\ngoal-oriented reasoning steps. To address this, we propose a\nprototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)\nframework, drawing inspiration from human-like reasoning strategies that\nemphasize structured knowledge reuse. In the first phase, semantically relevant\nknowledge structures are extracted from a sparse domain knowledge graph using a\ngraph neural network and enriched with intrinsic large language model knowledge\nto resolve knowledge discrepancies. In the second phase, these threads are\nevaluated and pruned using a reward-guided strategy aimed at maintaining\nsemantic coherence to generate effective reasoning threads. Experiments and\nexpert evaluations show that ReT-Eval enhances user understanding and\noutperforms state-of-the-art reasoning models."}
{"id": "2508.13051", "pdf": "https://arxiv.org/pdf/2508.13051", "abs": "https://arxiv.org/abs/2508.13051", "authors": ["Yi Wang", "Chetan Arora", "Xiao Liu", "Thuong Hoang", "ZHengxin Zhang", "Henry Been Lirn Duh", "John Grundy"], "title": "Investigating VR Accessibility Reviews for Users with Disabilities: A Qualitative Analysis", "categories": ["cs.SE", "cs.HC"], "comment": null, "summary": "Accessibility reviews provide valuable insights into both the limitations and\nbenefits experienced by users with disabilities when using virtual reality (VR)\napplications. However, a comprehensive investigation into VR accessibility for\nusers with disabilities is still lacking. To fill this gap, this study analyzes\nuser reviews from the Meta and Steam stores of VR apps, focusing on the\nreported issues affecting users with disabilities. We applied selection\ncriteria to 1,367,419 reviews from the top 40, the 20 most popular, and the 40\nlowest-rated VR applications on both platforms. In total, 1,076 (0.078%) VR\naccessibility reviews referenced various disabilities across 100 VR\napplications. These applications were categorized into Action, Sports, Social,\nPuzzle, Horror, and Simulation, with Action receiving the highest number of\naccessibility related-reviews. We identified 16 different types of disabilities\nacross six categories. Furthermore, we examined the causes of accessibility\nissues as reported by users with disabilities. Overall, VR accessibility\nreviews were predominantly under-supported."}
{"id": "2508.11923", "pdf": "https://arxiv.org/pdf/2508.11923", "abs": "https://arxiv.org/abs/2508.11923", "authors": ["Yan Wu", "Lihong Pei", "Yukai Han", "Yang Cao", "Yu Kang", "Yanlong Zhao"], "title": "Scale-Disentangled spatiotemporal Modeling for Long-term Traffic Emission Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Long-term traffic emission forecasting is crucial for the comprehensive\nmanagement of urban air pollution. Traditional forecasting methods typically\nconstruct spatiotemporal graph models by mining spatiotemporal dependencies to\npredict emissions. However, due to the multi-scale entanglement of traffic\nemissions across time and space, these spatiotemporal graph modeling method\ntend to suffer from cascading error amplification during long-term inference.\nTo address this issue, we propose a Scale-Disentangled Spatio-Temporal Modeling\n(SDSTM) framework for long-term traffic emission forecasting. It leverages the\npredictability differences across multiple scales to decompose and fuse\nfeatures at different scales, while constraining them to remain independent yet\ncomplementary. Specifically, the model first introduces a dual-stream feature\ndecomposition strategy based on the Koopman lifting operator. It lifts the\nscale-coupled spatiotemporal dynamical system into an infinite-dimensional\nlinear space via Koopman operator, and delineates the predictability boundary\nusing gated wavelet decomposition. Then a novel fusion mechanism is\nconstructed, incorporating a dual-stream independence constraint based on\ncross-term loss to dynamically refine the dual-stream prediction results,\nsuppress mutual interference, and enhance the accuracy of long-term traffic\nemission prediction. Extensive experiments conducted on a road-level traffic\nemission dataset within Xi'an's Second Ring Road demonstrate that the proposed\nmodel achieves state-of-the-art performance."}
{"id": "2508.12273", "pdf": "https://arxiv.org/pdf/2508.12273", "abs": "https://arxiv.org/abs/2508.12273", "authors": ["Olov Schavemaker"], "title": "Does the Barron space really defy the curse of dimensionality?", "categories": ["math.FA", "math.PR", "stat.ML"], "comment": null, "summary": "The Barron space has become famous in the theory of (shallow) neural networks\nbecause it seemingly defies the curse of dimensionality. And while the Barron\nspace (and generalizations) indeed defies (defy) the curse of dimensionality\nfrom the POV of classical smoothness, we herein provide some evidence in favor\nof the idea that the Barron space (and generalizations) does (do) not defy the\ncurse of dimensionality with a nonclassical notion of smoothness which relates\nnaturally to \"infinitely wide\" shallow neural networks. Like how the Bessel\npotential spaces are defined via the Fourier transform, we define so-called ADZ\nspaces via the Mellin transform; these ADZ spaces encapsulate the nonclassical\nsmoothness we alluded to earlier.\n  38 pages, will appear in the dissertation of the author"}
{"id": "2508.12282", "pdf": "https://arxiv.org/pdf/2508.12282", "abs": "https://arxiv.org/abs/2508.12282", "authors": ["Ziyang Chen", "Erxue Min", "Xiang Zhao", "Yunxin Li", "Xin Jia", "Jinzhi Liao", "Jichao Li", "Shuaiqiang Wang", "Baotian Hu", "Dawei Yin"], "title": "A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.IR", "68T50, 68P20", "I.2.7; H.3.3"], "comment": "10 pages, 5 figures", "summary": "We introduce ChronoQA, a large-scale benchmark dataset for Chinese question\nanswering, specifically designed to evaluate temporal reasoning in\nRetrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over\n300,000 news articles published between 2019 and 2024, and contains 5,176\nhigh-quality questions covering absolute, aggregate, and relative temporal\ntypes with both explicit and implicit time expressions. The dataset supports\nboth single- and multi-document scenarios, reflecting the real-world\nrequirements for temporal alignment and logical consistency. ChronoQA features\ncomprehensive structural annotations and has undergone multi-stage validation,\nincluding rule-based, LLM-based, and human evaluation, to ensure data quality.\nBy providing a dynamic, reliable, and scalable resource, ChronoQA enables\nstructured evaluation across a wide range of temporal tasks, and serves as a\nrobust benchmark for advancing time-sensitive retrieval-augmented question\nanswering systems."}
{"id": "2508.12149", "pdf": "https://arxiv.org/pdf/2508.12149", "abs": "https://arxiv.org/abs/2508.12149", "authors": ["Haochen You", "Baojing Liu"], "title": "MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization", "categories": ["cs.AI"], "comment": "Accepted as a conference paper at CIKM 2025", "summary": "Recent advances in multimodal learning have largely relied on pairwise\ncontrastive objectives to align different modalities, such as text, video, and\naudio, in a shared embedding space. While effective in bi-modal setups, these\napproaches struggle to generalize across multiple modalities and often lack\nsemantic structure in high-dimensional spaces. In this paper, we propose MOVER,\na novel framework that combines optimal transport-based soft alignment with\nvolume-based geometric regularization to build semantically aligned and\nstructured multimodal representations. By integrating a transport-guided\nmatching mechanism with a geometric volume minimization objective (GAVE), MOVER\nencourages consistent alignment across all modalities in a modality-agnostic\nmanner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER\nsignificantly outperforms prior state-of-the-art methods in both zero-shot and\nfinetuned settings. Additional analysis shows improved generalization to unseen\nmodality combinations and stronger structural consistency in the learned\nembedding space."}
{"id": "2508.13134", "pdf": "https://arxiv.org/pdf/2508.13134", "abs": "https://arxiv.org/abs/2508.13134", "authors": ["Glauber da Rocha Balthazar", "Marcia Ito"], "title": "Influencia de fatores organizacionais e sociais na etapa de levantamento de requisitos", "categories": ["cs.SE"], "comment": "VI Workshop de P\\'os-Gradua\\c{c}\\~ao e Pesquisa do Centro Paula\n  Souza, in Portuguese language", "summary": "The most critical and fragile stage of a software development project is\nrequirements gathering. Because of this, Requirements Engineering has been\nevolving its techniques to minimize the challenges faced by Requirements\nAnalysts. However, few studies consider the humanistic relationships and\nbehaviors of those involved in this stage. This article presents a survey of\nsome studies conducted at this stage that consider non-technical factors such\nas emotions, organizational environment, and social context."}
{"id": "2508.11931", "pdf": "https://arxiv.org/pdf/2508.11931", "abs": "https://arxiv.org/abs/2508.11931", "authors": ["Tim van Erven", "Jack Mayo", "Julia Olkhovskaya", "Chen-Yu Wei"], "title": "An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction", "categories": ["cs.LG"], "comment": null, "summary": "We present an efficient algorithm for linear contextual bandits with\nadversarial losses and stochastic action sets. Our approach reduces this\nsetting to misspecification-robust adversarial linear bandits with fixed action\nsets. Without knowledge of the context distribution or access to a context\nsimulator, the algorithm achieves $\\tilde{O}(\\min\\{d^2\\sqrt{T}, \\sqrt{d^3T\\log\nK}\\})$ regret and runs in $\\text{poly}(d,C,T)$ time, where $d$ is the feature\ndimension, $C$ is an upper bound on the number of linear constraints defining\nthe action set in each round, $K$ is an upper bound on the number of actions in\neach round, and $T$ is number of rounds. This resolves the open question by Liu\net al. (2023) on whether one can obtain $\\text{poly}(d)\\sqrt{T}$ regret in\npolynomial time independent of the number of actions. For the important class\nof combinatorial bandits with adversarial losses and stochastic action sets\nwhere the action sets can be described by a polynomial number of linear\nconstraints, our algorithm is the first to achieve $\\text{poly}(d)\\sqrt{T}$\nregret in polynomial time, while no prior algorithm achieves even $o(T)$ regret\nin polynomial time to our knowledge. When a simulator is available, the regret\nbound can be improved to $\\tilde{O}(d\\sqrt{L^\\star})$, where $L^\\star$ is the\ncumulative loss of the best policy."}
{"id": "2508.12426", "pdf": "https://arxiv.org/pdf/2508.12426", "abs": "https://arxiv.org/abs/2508.12426", "authors": ["Suryasis Jana", "Subhrajyoty Roy", "Ayanendranath Basu", "Abhik Ghosh"], "title": "Asymptotic breakdown point analysis of the minimum density power divergence estimator under independent non-homogeneous setups", "categories": ["math.ST", "stat.ML", "stat.TH"], "comment": "Pre-print; under review", "summary": "The minimum density power divergence estimator (MDPDE) has gained significant\nattention in the literature of robust inference due to its strong robustness\nproperties and high asymptotic efficiency; it is relatively easy to compute and\ncan be interpreted as a generalization of the classical maximum likelihood\nestimator. It has been successfully applied in various setups, including the\ncase of independent and non-homogeneous (INH) observations that cover both\nclassification and regression-type problems with a fixed design. While the\nlocal robustness of this estimator has been theoretically validated through the\nbounded influence function, no general result is known about the global\nreliability or the breakdown behavior of this estimator under the INH setup,\nexcept for the specific case of location-type models. In this paper, we extend\nthe notion of asymptotic breakdown point from the case of independent and\nidentically distributed data to the INH setup and derive a theoretical lower\nbound for the asymptotic breakdown point of the MDPDE, under some easily\nverifiable assumptions. These results are further illustrated with applications\nto some fixed design regression models and corroborated through extensive\nsimulation studies."}
{"id": "2508.12536", "pdf": "https://arxiv.org/pdf/2508.12536", "abs": "https://arxiv.org/abs/2508.12536", "authors": ["Yasuo Tabei"], "title": "jXBW: Fast Substructure Search in Large-Scale JSONL Datasets for Foundation Model Applications", "categories": ["cs.DB", "cs.DS", "cs.IR"], "comment": null, "summary": "Substructure search in JSON Lines (JSONL) datasets is essential for modern\napplications such as prompt engineering in foundation models, but existing\nmethods suffer from prohibitive computational costs due to exhaustive tree\ntraversal and subtree matching. We present jXBW, a fast method for substructure\nsearch on large-scale JSONL datasets. Our method makes three key technical\ncontributions: (i) a merged tree representation built by merging trees of\nmultiple JSON objects while preserving individual identities, (ii) a succinct\ndata structure based on the eXtended Burrows-Wheeler Transform that enables\nefficient tree navigation and subpath search, and (iii) an efficient three-step\nsubstructure search algorithm that combines path decomposition, ancestor\ncomputation, and adaptive tree identifier collection to ensure correctness\nwhile avoiding exhaustive tree traversal. Experimental evaluation on real-world\ndatasets demonstrates that jXBW consistently outperforms existing methods,\nachieving speedups of 16$\\times$ for smaller datasets and up to 4,700$\\times$\nfor larger datasets over tree-based approaches, and more than 6$\\times$10$^6$\nover XML-based processing while maintaining competitive memory usage."}
{"id": "2508.12165", "pdf": "https://arxiv.org/pdf/2508.12165", "abs": "https://arxiv.org/abs/2508.12165", "authors": ["Rohit Krishnan", "Jon Evans"], "title": "RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces RLNVR (Reinforcement Learning from Non-Verified\nRewards), a framework for training language models using noisy, real-world\nfeedback signals without requiring explicit human verification. Traditional\nRLHF requires expensive, verified reward signals that are impractical in many\nreal-world domains. RLNVR addresses this challenge through baseline\nnormalization and semantic similarity-based reward transfer. We demonstrate\nRLNVR through Walter, a prototype system that optimizes social media content\ngeneration using actual engagement data from Bluesky. Our experimental results\nshow significant improvements in content quality and training stability, with\ncomprehensive evaluation planned for future work. Positioning: We present a\npractical framework that combines RLNVR with GSPO (Group Sequence Policy\nOptimization) and an optional UED (Unsupervised Environment Design) curriculum\nto improve stability and diversity under noisy, implicit rewards. To our\nknowledge, combining GSPO-style normalization with a UED-style curriculum for\nLLM content generation from implicit social engagement has not been previously\ndocumented in this applied setting; we frame this as an applied integration\nrather than a new algorithm."}
{"id": "2508.12187", "pdf": "https://arxiv.org/pdf/2508.12187", "abs": "https://arxiv.org/abs/2508.12187", "authors": ["John Y. Kim", "Chaoshun Zuo", "Yanjie Zhao", "Zhiqiang Lin"], "title": "AUTOVR: Automated UI Exploration for Detecting Sensitive Data Flow Exposures in Virtual Reality Apps", "categories": ["cs.CR", "cs.SE"], "comment": "USENIX Security 2025, 19 Pages, 14 Figures, 7 Tables", "summary": "The rise of Virtual Reality (VR) has provided developers with an\nunprecedented platform for creating games and applications (apps) that require\ndistinct inputs, different from those of conventional devices like smartphones.\nThe Meta Quest VR platform, driven by Meta, has democratized VR app publishing\nand attracted millions of users worldwide. However, as the number of published\napps grows, there is a notable lack of robust headless tools for user interface\n(UI) exploration and user event testing. To address this need, we present\nAUTOVR, an automatic framework for dynamic UI and user event interaction in VR\napps built on the Unity Engine. Unlike conventional Android and GUI testers,\nAUTOVR analyzes the app's internal binary to reveal hidden events, resolves\ngenerative event dependencies, and utilizes them for comprehensive exploration\nof VR apps. Using sensitive data exposure as a performance metric, we compare\nAUTOVR with Android Monkey, a widely used headless Android GUI stress testing\ntool. Our empirical evaluation demonstrates AUTOVR's superior performance,\ntriggering an order of magnitude of more sensitive data exposures and\nsignificantly enhancing the privacy of VR apps."}
{"id": "2508.11936", "pdf": "https://arxiv.org/pdf/2508.11936", "abs": "https://arxiv.org/abs/2508.11936", "authors": ["Yuehan Qin", "Li Li", "Defu Cao", "Tiankai Yang", "Yue Zhao"], "title": "M3OOD: Automatic Selection of Multimodal OOD Detectors", "categories": ["cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) robustness is a critical challenge for modern\nmachine learning systems, particularly as they increasingly operate in\nmultimodal settings involving inputs like video, audio, and sensor data.\nCurrently, many OOD detection methods have been proposed, each with different\ndesigns targeting various distribution shifts. A single OOD detector may not\nprevail across all the scenarios; therefore, how can we automatically select an\nideal OOD detection model for different distribution shifts? Due to the\ninherent unsupervised nature of the OOD detection task, it is difficult to\npredict model performance and find a universally Best model. Also,\nsystematically comparing models on the new unseen data is costly or even\nimpractical. To address this challenge, we introduce M3OOD, a\nmeta-learning-based framework for OOD detector selection in multimodal\nsettings. Meta learning offers a solution by learning from historical model\nbehaviors, enabling rapid adaptation to new data distribution shifts with\nminimal supervision. Our approach combines multimodal embeddings with\nhandcrafted meta-features that capture distributional and cross-modal\ncharacteristics to represent datasets. By leveraging historical performance\nacross diverse multimodal benchmarks, M3OOD can recommend suitable detectors\nfor a new data distribution shift. Experimental evaluation demonstrates that\nM3OOD consistently outperforms 10 competitive baselines across 12 test\nscenarios with minimal computational overhead."}
{"id": "2508.12483", "pdf": "https://arxiv.org/pdf/2508.12483", "abs": "https://arxiv.org/abs/2508.12483", "authors": ["Wenlong Jiang", "Chris McKennan", "Jesús Arroyo", "Joshua Cape"], "title": "Simultaneous estimation of connectivity and dimensionality in samples of networks", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH", "62H12"], "comment": "Main text: 35 pages, 5 figures, 5 tables. Supplement: 26 pages, 3\n  figures, 5 tables", "summary": "An overarching objective in contemporary statistical network analysis is\nextracting salient information from datasets consisting of multiple networks.\nTo date, considerable attention has been devoted to node and network\nclustering, while comparatively less attention has been devoted to downstream\nconnectivity estimation and parsimonious embedding dimension selection. Given a\nsample of potentially heterogeneous networks, this paper proposes a method to\nsimultaneously estimate a latent matrix of connectivity probabilities and its\nembedding dimensionality or rank after first pre-estimating the number of\ncommunities and the node community memberships. The method is formulated as a\nconvex optimization problem and solved using an alternating direction method of\nmultipliers algorithm. We establish estimation error bounds under the Frobenius\nnorm and nuclear norm for settings in which observable networks have blockmodel\nstructure, even when node memberships are imperfectly recovered. When perfect\nmembership recovery is possible and dimensionality is much smaller than the\nnumber of communities, the proposed method outperforms conventional\naveraging-based methods for estimating connectivity and dimensionality.\nNumerical studies empirically demonstrate the accuracy of our method across\nvarious scenarios. Additionally, analysis of a primate brain dataset\ndemonstrates that posited connectivity is not necessarily full rank in\npractice, illustrating the need for flexible methodology."}
{"id": "2508.13107", "pdf": "https://arxiv.org/pdf/2508.13107", "abs": "https://arxiv.org/abs/2508.13107", "authors": ["Figarri Keisha", "Prince Singh", "Pallavi", "Dion Fernandes", "Aravindh Manivannan", "Ilham Wicaksono", "Faisal Ahmad"], "title": "All for law and law for all: Adaptive RAG Pipeline for Legal Research", "categories": ["cs.CL", "cs.IR", "F.2.2, H.3.3, I.2.7"], "comment": "submitted to NLLP 2025 Workshop", "summary": "Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding\nlarge language model outputs in cited sources, a capability that is especially\ncritical in the legal domain. We present an end-to-end RAG pipeline that\nrevisits and extends the LegalBenchRAG baseline with three targeted\nenhancements: (i) a context-aware query translator that disentangles document\nreferences from natural-language questions and adapts retrieval depth and\nresponse style based on expertise and specificity, (ii) open-source retrieval\nstrategies using SBERT and GTE embeddings that achieve substantial performance\ngains (improving Recall@K by 30-95\\% and Precision@K by $\\sim$2.5$\\times$ for\n$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and\ngeneration framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to\nassess semantic alignment and faithfulness across models and prompt designs.\nOur results show that carefully designed open-source pipelines can rival or\noutperform proprietary approaches in retrieval quality, while a custom\nlegal-grounded prompt consistently produces more faithful and contextually\nrelevant answers than baseline prompting. Taken together, these contributions\ndemonstrate the potential of task-aware, component-level tuning to deliver\nlegally grounded, reproducible, and cost-effective RAG systems for legal\nresearch assistance."}
{"id": "2508.12260", "pdf": "https://arxiv.org/pdf/2508.12260", "abs": "https://arxiv.org/abs/2508.12260", "authors": ["Carson Dudley", "Reiden Magdaleno", "Christopher Harding", "Ananya Sharma", "Emily Martin", "Marisa Eisenberg"], "title": "Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting", "categories": ["cs.AI", "q-bio.QM"], "comment": "10 pages, 4 figures", "summary": "Infectious disease forecasting in novel outbreaks or low resource settings\nhas been limited by the need for disease-specific data, bespoke training, and\nexpert tuning. We introduce Mantis, a foundation model trained entirely on\nmechanistic simulations, which enables out-of-the-box forecasting across\ndiseases, regions, and outcomes, even in settings with limited historical data.\nMantis is built on over 400 million simulated days of outbreak dynamics\nspanning diverse pathogens, transmission modes, interventions, and surveillance\nartifacts. Despite requiring no real-world data during training, Mantis\noutperformed 39 expert-tuned models we tested across six diseases, including\nall models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel\nepidemiological regimes, including diseases with held-out transmission\nmechanisms, demonstrating that it captures fundamental contagion dynamics.\nCritically, Mantis is mechanistically interpretable, enabling public health\ndecision-makers to identify the latent drivers behind its predictions. Finally,\nMantis delivers accurate forecasts at 8-week horizons, more than doubling the\nactionable range of most models, enabling proactive public health planning.\nTogether, these capabilities position Mantis as a foundation for\nnext-generation disease forecasting systems: general, interpretable, and\ndeployable where traditional models fail."}
{"id": "2508.12385", "pdf": "https://arxiv.org/pdf/2508.12385", "abs": "https://arxiv.org/abs/2508.12385", "authors": ["Ryosuke Kohita", "Akira Kasuga"], "title": "System-driven Interactive Design Support for Cloud Architecture: A Qualitative User Experience Study with Novice Engineers", "categories": ["cs.HC", "cs.SE"], "comment": null, "summary": "Cloud architecture design presents significant challenges due to the\nnecessity of clarifying ambiguous requirements and systematically addressing\ncomplex trade-offs, especially for novice engineers with limited cloud\nexperience. While recent advances in the use of AI tools have broadened\navailable options, system-driven approaches that offer explicit guidance and\nstep-by-step information management may be especially effective in supporting\nnovices during the design process. This study qualitatively examines the\nexperiences of 60 novice engineers using such a system-driven cloud design\nsupport tool. The findings indicate that structured and proactive system\nguidance helps novices engage more effectively in architectural design,\nespecially when addressing tasks where knowledge and experience gaps are most\ncritical. For example, participants found it easier to create initial\narchitectures and did not need to craft prompts themselves. In addition,\nparticipants reported that the ability to simulate and compare multiple\narchitecture options enabled them to deepen their understanding of cloud design\nprinciples and trade-offs, demonstrating the educational value of system-driven\nsupport. The study also identifies areas for improvement, including more\nadaptive information delivery tailored to user expertise, mechanisms for\nvalidating system outputs, and better integration with implementation workflows\nsuch as infrastructure-as-code generation and deployment guidance. Addressing\nthese aspects can further enhance the educational and practical value of\nsystem-driven support tools for cloud architecture design."}
{"id": "2508.11940", "pdf": "https://arxiv.org/pdf/2508.11940", "abs": "https://arxiv.org/abs/2508.11940", "authors": ["Yuannuo Feng", "Wenyong Zhou", "Yuexi Lyu", "Yixiang Zhang", "Zhengwu Liu", "Ngai Wong", "Wang Kang"], "title": "Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "4 pages, 5 figures, conference", "summary": "Analog Compute-In-Memory (CIM) architectures promise significant energy\nefficiency gains for neural network inference, but suffer from complex\nhardware-induced noise that poses major challenges for deployment. While\nnoise-aware training methods have been proposed to address this issue, they\ntypically rely on idealized and differentiable noise models that fail to\ncapture the full complexity of analog CIM hardware variations. Motivated by the\nStraight-Through Estimator (STE) framework in quantization, we decouple forward\nnoise simulation from backward gradient computation, enabling noise-aware\ntraining with more accurate but computationally intractable noise modeling in\nanalog CIM systems. We provide theoretical analysis demonstrating that our\napproach preserves essential gradient directional information while maintaining\ncomputational tractability and optimization stability. Extensive experiments\nshow that our extended STE framework achieves up to 5.3% accuracy improvement\non image classification, 0.72 perplexity reduction on text generation,\n2.2$\\times$ speedup in training time, and 37.9% lower peak memory usage\ncompared to standard noise-aware training methods."}
{"id": "2508.12530", "pdf": "https://arxiv.org/pdf/2508.12530", "abs": "https://arxiv.org/abs/2508.12530", "authors": ["Hyunsoo Song", "Seungwhan Kim", "Seungkyu Lee"], "title": "Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs", "categories": ["cs.LG", "cs.CV", "stat.ML", "I.2.6"], "comment": "8 pages, 6 figures", "summary": "Variational autoencoders (VAEs), one of the most widely used generative\nmodels, are known to suffer from posterior collapse, a phenomenon that reduces\nthe diversity of generated samples. To avoid posterior collapse, many prior\nworks have tried to control the influence of regularization loss. However, the\ntrade-off between reconstruction and regularization is not satisfactory. For\nthis reason, several methods have been proposed to guarantee latent\nidentifiability, which is the key to avoiding posterior collapse. However, they\nrequire structural constraints on the network architecture. For further\nclarification, we define local posterior collapse to reflect the importance of\nindividual sample points in the data space and to relax the network constraint.\nThen, we propose Latent Reconstruction(LR) loss, which is inspired by\nmathematical properties of injective and composite functions, to control\nposterior collapse without restriction to a specific architecture. We\nexperimentally evaluate our approach, which controls posterior collapse on\nvaried datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ."}
{"id": "2508.12291", "pdf": "https://arxiv.org/pdf/2508.12291", "abs": "https://arxiv.org/abs/2508.12291", "authors": ["Xuming He", "Zhiyuan You", "Junchao Gong", "Couhua Liu", "Xiaoyu Yue", "Peiqin Zhuang", "Wenlong Zhang", "Lei Bai"], "title": "RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts", "categories": ["cs.AI"], "comment": null, "summary": "Quality analysis of weather forecasts is an essential topic in meteorology.\nAlthough traditional score-based evaluation metrics can quantify certain\nforecast errors, they are still far from meteorological experts in terms of\ndescriptive capability, interpretability, and understanding of dynamic\nevolution. With the rapid development of Multi-modal Large Language Models\n(MLLMs), these models become potential tools to overcome the above challenges.\nIn this work, we introduce an MLLM-based weather forecast analysis method,\nRadarQA, integrating key physical attributes with detailed assessment reports.\nWe introduce a novel and comprehensive task paradigm for multi-modal quality\nanalysis, encompassing both single frame and sequence, under both rating and\nassessment scenarios. To support training and benchmarking, we design a hybrid\nannotation pipeline that combines human expert labeling with automated\nheuristics. With such an annotation method, we construct RQA-70K, a large-scale\ndataset with varying difficulty levels for radar forecast quality evaluation.\nWe further design a multi-stage training strategy that iteratively improves\nmodel performance at each stage. Extensive experiments show that RadarQA\noutperforms existing general MLLMs across all evaluation settings, highlighting\nits potential for advancing quality analysis in weather prediction."}
{"id": "2508.12538", "pdf": "https://arxiv.org/pdf/2508.12538", "abs": "https://arxiv.org/abs/2508.12538", "authors": ["Yongjian Guo", "Puzhuo Liu", "Wanlun Ma", "Zehang Deng", "Xiaogang Zhu", "Peng Di", "Xi Xiao", "Sheng Wen"], "title": "Systematic Analysis of MCP Security", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "The Model Context Protocol (MCP) has emerged as a universal standard that\nenables AI agents to seamlessly connect with external tools, significantly\nenhancing their functionality. However, while MCP brings notable benefits, it\nalso introduces significant vulnerabilities, such as Tool Poisoning Attacks\n(TPA), where hidden malicious instructions exploit the sycophancy of large\nlanguage models (LLMs) to manipulate agent behavior. Despite these risks,\ncurrent academic research on MCP security remains limited, with most studies\nfocusing on narrow or qualitative analyses that fail to capture the diversity\nof real-world threats. To address this gap, we present the MCP Attack Library\n(MCPLIB), which categorizes and implements 31 distinct attack methods under\nfour key classifications: direct tool injection, indirect tool injection,\nmalicious user attacks, and LLM inherent attack. We further conduct a\nquantitative analysis of the efficacy of each attack. Our experiments reveal\nkey insights into MCP vulnerabilities, including agents' blind reliance on tool\ndescriptions, sensitivity to file-based attacks, chain attacks exploiting\nshared context, and difficulty distinguishing external data from executable\ncommands. These insights, validated through attack experiments, underscore the\nurgency for robust defense strategies and informed MCP design. Our\ncontributions include 1) constructing a comprehensive MCP attack taxonomy, 2)\nintroducing a unified attack framework MCPLIB, and 3) conducting empirical\nvulnerability analysis to enhance MCP security mechanisms. This work provides a\nfoundational framework, supporting the secure evolution of MCP ecosystems."}
{"id": "2508.11943", "pdf": "https://arxiv.org/pdf/2508.11943", "abs": "https://arxiv.org/abs/2508.11943", "authors": ["Sishun Liu", "Ke Deng", "Xiuzhen Zhang", "Yan Wang"], "title": "Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning", "categories": ["cs.LG"], "comment": "ECAI 2025 full version", "summary": "Neural network-based Marked Temporal Point Process (MTPP) models have been\nwidely adopted to model event sequences in high-stakes applications, raising\nconcerns about the trustworthiness of outputs from these models. This study\nfocuses on Explanation for MTPP, aiming to identify the minimal and rational\nexplanation, that is, the minimum subset of events in history, based on which\nthe prediction accuracy of MTPP matches that based on full history to a great\nextent and better than that based on the complement of the subset. This study\nfinds that directly defining Explanation for MTPP as counterfactual explanation\nor factual explanation can result in irrational explanations. To address this\nissue, we define Explanation for MTPP as a combination of counterfactual\nexplanation and factual explanation. This study proposes Counterfactual and\nFactual Explainer for MTPP (CFF) to solve Explanation for MTPP with a series of\ndeliberately designed techniques. Experiments demonstrate the correctness and\nsuperiority of CFF over baselines regarding explanation quality and processing\nefficiency."}
{"id": "2508.12569", "pdf": "https://arxiv.org/pdf/2508.12569", "abs": "https://arxiv.org/abs/2508.12569", "authors": ["Quercus Hernandez", "Max Win", "Thomas C. O'Connor", "Paulo E. Arratia", "Nathaniel Trask"], "title": "Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems", "categories": ["cs.LG", "cs.CE", "physics.comp-ph", "stat.ML"], "comment": "34 pages, 12 figures", "summary": "Multiscale systems are ubiquitous in science and technology, but are\nnotoriously challenging to simulate as short spatiotemporal scales must be\nappropriately linked to emergent bulk physics. When expensive high-dimensional\ndynamical systems are coarse-grained into low-dimensional models, the entropic\nloss of information leads to emergent physics which are dissipative,\nhistory-dependent, and stochastic. To machine learn coarse-grained dynamics\nfrom time-series observations of particle trajectories, we propose a framework\nusing the metriplectic bracket formalism that preserves these properties by\nconstruction; most notably, the framework guarantees discrete notions of the\nfirst and second laws of thermodynamics, conservation of momentum, and a\ndiscrete fluctuation-dissipation balance crucial for capturing non-equilibrium\nstatistics. We introduce the mathematical framework abstractly before\nspecializing to a particle discretization. As labels are generally unavailable\nfor entropic state variables, we introduce a novel self-supervised learning\nstrategy to identify emergent structural variables. We validate the method on\nbenchmark systems and demonstrate its utility on two challenging examples: (1)\ncoarse-graining star polymers at challenging levels of coarse-graining while\npreserving non-equilibrium statistics, and (2) learning models from high-speed\nvideo of colloidal suspensions that capture coupling between local\nrearrangement events and emergent stochastic dynamics. We provide open-source\nimplementations in both PyTorch and LAMMPS, enabling large-scale inference and\nextensibility to diverse particle-based systems."}
{"id": "2508.12338", "pdf": "https://arxiv.org/pdf/2508.12338", "abs": "https://arxiv.org/abs/2508.12338", "authors": ["Wenzhen Yuan", "Shengji Tang", "Weihao Lin", "Jiacheng Ruan", "Ganqu Cui", "Bo Zhang", "Tao Chen", "Ting Liu", "Yuzhuo Fu", "Peng Ye", "Lei Bai"], "title": "Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has significantly enhanced the reasoning\ncapabilities of large language models (LLMs), but its reliance on expensive\nhuman-labeled data or complex reward models severely limits scalability. While\nexisting self-feedback methods aim to address this problem, they are\nconstrained by the capabilities of a single model, which can lead to\noverconfidence in incorrect answers, reward hacking, and even training\ncollapse. To this end, we propose Reinforcement Learning from Coevolutionary\nCollective Feedback (RLCCF), a novel RL framework that enables multi-model\ncollaborative evolution without external supervision. Specifically, RLCCF\noptimizes the ability of a model collective by maximizing its Collective\nConsistency (CC), which jointly trains a diverse ensemble of LLMs and provides\nreward signals by voting on collective outputs. Moreover, each model's vote is\nweighted by its Self-Consistency (SC) score, ensuring that more confident\nmodels contribute more to the collective decision. Benefiting from the diverse\noutput distributions and complementary abilities of multiple LLMs, RLCCF\nenables the model collective to continuously enhance its reasoning ability\nthrough coevolution. Experiments on four mainstream open-source LLMs across\nfour mathematical reasoning benchmarks demonstrate that our framework yields\nsignificant performance gains, achieving an average relative improvement of\n16.72\\% in accuracy. Notably, RLCCF not only improves the performance of\nindividual models but also enhances the group's majority-voting accuracy by\n4.51\\%, demonstrating its ability to extend the collective capability boundary\nof the model collective."}
{"id": "2508.12551", "pdf": "https://arxiv.org/pdf/2508.12551", "abs": "https://arxiv.org/abs/2508.12551", "authors": ["Hongyu Lin", "Yuchen Li", "Haoran Luo", "Kaichun Yao", "Libo Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.OS", "cs.SE"], "comment": null, "summary": "Linux kernel tuning is essential for optimizing operating system (OS)\nperformance. However, existing methods often face challenges in terms of\nefficiency, scalability, and generalization. This paper introduces OS-R1, an\nagentic Linux kernel tuning framework powered by rule-based reinforcement\nlearning (RL). By abstracting the kernel configuration space as an RL\nenvironment, OS-R1 facilitates efficient exploration by large language models\n(LLMs) and ensures accurate configuration modifications. Additionally, custom\nreward functions are designed to enhance reasoning standardization,\nconfiguration modification accuracy, and system performance awareness of the\nLLMs. Furthermore, we propose a two-phase training process that accelerates\nconvergence and minimizes retraining across diverse tuning scenarios.\nExperimental results show that OS-R1 significantly outperforms existing\nbaseline methods, achieving up to 5.6% performance improvement over heuristic\ntuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across\nvarious real-world applications, demonstrating its potential for practical\ndeployment in diverse environments. Our dataset and code are publicly available\nat https://github.com/LHY-24/OS-R1."}
{"id": "2508.11976", "pdf": "https://arxiv.org/pdf/2508.11976", "abs": "https://arxiv.org/abs/2508.11976", "authors": ["Yunning Cao", "Lihong Pei", "Jian Guo", "Yang Cao", "Yu Kang", "Yanlong Zhao"], "title": "Set-Valued Transformer Network for High-Emission Mobile Source Identification", "categories": ["cs.LG"], "comment": null, "summary": "Identifying high-emission vehicles is a crucial step in regulating urban\npollution levels and formulating traffic emission reduction strategies.\nHowever, in practical monitoring data, the proportion of high-emission state\ndata is significantly lower compared to normal emission states. This\ncharacteristic long-tailed distribution severely impedes the extraction of\ndiscriminative features for emission state identification during data mining.\nFurthermore, the highly nonlinear nature of vehicle emission states and the\nlack of relevant prior knowledge also pose significant challenges to the\nconstruction of identification models.To address the aforementioned issues, we\npropose a Set-Valued Transformer Network (SVTN) to achieve comprehensive\nlearning of discriminative features from high-emission samples, thereby\nenhancing detection accuracy. Specifically, this model first employs the\ntransformer to measure the temporal similarity of micro-trip condition\nvariations, thus constructing a mapping rule that projects the original\nhigh-dimensional emission data into a low-dimensional feature space. Next, a\nset-valued identification algorithm is used to probabilistically model the\nrelationship between the generated feature vectors and their labels, providing\nan accurate metric criterion for the classification algorithm. To validate the\neffectiveness of our proposed approach, we conducted extensive experiments on\nthe diesel vehicle monitoring data of Hefei city in 2020. The results\ndemonstrate that our method achieves a 9.5\\% reduction in the missed detection\nrate for high-emission vehicles compared to the transformer-based baseline,\nhighlighting its superior capability in accurately identifying high-emission\nmobile pollution sources."}
{"id": "2508.12758", "pdf": "https://arxiv.org/pdf/2508.12758", "abs": "https://arxiv.org/abs/2508.12758", "authors": ["Sowmini Devi Veeramachaneni", "Ramamurthy Garimella"], "title": "Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper presents Constrained Centroid Clustering (CCC), a method that\nextends classical centroid-based clustering by enforcing a constraint on the\nmaximum distance between the cluster center and the farthest point in the\ncluster. Using a Lagrangian formulation, we derive a closed-form solution that\nmaintains interpretability while controlling cluster spread. To evaluate CCC,\nwe conduct experiments on synthetic circular data with radial symmetry and\nuniform angular distribution. Using ring-wise, sector-wise, and joint entropy\nas evaluation metrics, we show that CCC achieves more compact clusters by\nreducing radial spread while preserving angular structure, outperforming\nstandard methods such as K-means and GMM. The proposed approach is suitable for\napplications requiring structured clustering with spread control, including\nsensor networks, collaborative robotics, and interpretable pattern analysis."}
{"id": "2508.12375", "pdf": "https://arxiv.org/pdf/2508.12375", "abs": "https://arxiv.org/abs/2508.12375", "authors": ["Yu Sha", "Shuiping Gou", "Bo Liu", "Johannes Faber", "Ningtao Liu", "Stefan Schramm", "Horst Stoecker", "Thomas Steckenreiter", "Domagoj Vnucec", "Nadine Wetzstein", "Andreas Widl", "Kai Zhou"], "title": "Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems", "categories": ["cs.AI"], "comment": "12 pages", "summary": "Fault intensity diagnosis (FID) plays a pivotal role in monitoring and\nmaintaining mechanical devices within complex industrial systems. As current\nFID methods are based on chain of thought without considering dependencies\namong target classes. To capture and explore dependencies, we propose a\nhierarchical knowledge guided fault intensity diagnosis framework (HKG)\ninspired by the tree of thought, which is amenable to any representation\nlearning methods. The HKG uses graph convolutional networks to map the\nhierarchical topological graph of class representations into a set of\ninterdependent global hierarchical classifiers, where each node is denoted by\nword embeddings of a class. These global hierarchical classifiers are applied\nto learned deep features extracted by representation learning, allowing the\nentire model to be end-to-end learnable. In addition, we develop a re-weighted\nhierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding\ninter-class hierarchical knowledge into a data-driven statistical correlation\nmatrix (SCM) which effectively guides the information sharing of nodes in\ngraphical convolutional neural networks and avoids over-smoothing issues. The\nRe-HKCM is derived from the SCM through a series of mathematical\ntransformations. Extensive experiments are performed on four real-world\ndatasets from different industrial domains (three cavitation datasets from\nSAMSON AG and one existing publicly) for FID, all showing superior results and\noutperform recent state-of-the-art FID methods."}
{"id": "2508.13143", "pdf": "https://arxiv.org/pdf/2508.13143", "abs": "https://arxiv.org/abs/2508.13143", "authors": ["Ruofan Lu", "Yichen Li", "Yintong Huo"], "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks", "categories": ["cs.AI", "cs.SE"], "comment": "Accepted by ASE 2025 NIER", "summary": "Autonomous agent systems powered by Large Language Models (LLMs) have\ndemonstrated promising capabilities in automating complex tasks. However,\ncurrent evaluations largely rely on success rates without systematically\nanalyzing the interactions, communication mechanisms, and failure causes within\nthese systems. To bridge this gap, we present a benchmark of 34 representative\nprogrammable tasks designed to rigorously assess autonomous agents. Using this\nbenchmark, we evaluate three popular open-source agent frameworks combined with\ntwo LLM backbones, observing a task completion rate of approximately 50%.\nThrough in-depth failure analysis, we develop a three-tier taxonomy of failure\ncauses aligned with task phases, highlighting planning errors, task execution\nissues, and incorrect response generation. Based on these insights, we propose\nactionable improvements to enhance agent planning and self-diagnosis\ncapabilities. Our failure taxonomy, together with mitigation advice, provides\nan empirical foundation for developing more robust and effective autonomous\nagent systems in the future."}
{"id": "2508.11985", "pdf": "https://arxiv.org/pdf/2508.11985", "abs": "https://arxiv.org/abs/2508.11985", "authors": ["Zhanhao Cao", "Clement Truong", "Andrew Lizarraga"], "title": "Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Recent advances in large language models are driven by scale, while\nparameter-efficient fine-tuning (PEFT) enables updating only a small fraction\nof parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the\nproduct of two small matrices, which makes them natural building blocks that\ncan be composed. Motivated by the superposition principle, we hypothesize that\nindependently trained LoRA modules on disjoint domains are approximately\northogonal and can be combined by simple addition. Using GPT-2 Small (117M)\nwith LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,\nmedicine, finance). In pairwise tests, adding Math+Medicine adapters improves\nperplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance\nand Finance+Medicine change by +4.54% and +27.56%, respectively. Across\ncombinations, the RMS cosine similarity between LoRA deltas correlates\npositively and approximately linearly with the change in perplexity. Naive\nsummation requires no additional training, can be applied in seconds, and\nachieves performance comparable to models trained on merged data, while\nclarifying when interference appears in higher-order compositions."}
{"id": "2508.12776", "pdf": "https://arxiv.org/pdf/2508.12776", "abs": "https://arxiv.org/abs/2508.12776", "authors": ["Muhammad Rajabinasab", "Farhad Pakdaman", "Moncef Gabbouj", "Peter Schneider-Kamp", "Arthur Zimek"], "title": "Randomized PCA Forest for Outlier Detection", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We propose a novel unsupervised outlier detection method based on Randomized\nPrincipal Component Analysis (PCA). Inspired by the performance of Randomized\nPCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a\nnovel unsupervised outlier detection method that utilizes RPCA Forest for\noutlier detection. Experimental results showcase the superiority of the\nproposed approach compared to the classical and state-of-the-art methods in\nperforming the outlier detection task on several datasets while performing\ncompetitively on the rest. The extensive analysis of the proposed method\nreflects it high generalization power and its computational efficiency,\nhighlighting it as a good choice for unsupervised outlier detection."}
{"id": "2508.12379", "pdf": "https://arxiv.org/pdf/2508.12379", "abs": "https://arxiv.org/abs/2508.12379", "authors": ["Rongzheng Wang", "Qizhi Chen", "Yihong Huang", "Yizhuo Ma", "Muquan Li", "Jiakai Li", "Ke Qin", "Guangchun Luo", "Shuang Liang"], "title": "GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) show promising performance on small-scale graph\nreasoning tasks but fail when handling real-world graphs with complex queries.\nThis phenomenon stems from LLMs' inability to effectively process complex graph\ntopology and perform multi-step reasoning simultaneously. To address these\nlimitations, we propose GraphCogent, a collaborative agent framework inspired\nby human Working Memory Model that decomposes graph reasoning into specialized\ncognitive processes: sense, buffer, and execute. The framework consists of\nthree modules: Sensory Module standardizes diverse graph text representations\nvia subgraph sampling, Buffer Module integrates and indexes graph data across\nmultiple formats, and Execution Module combines tool calling and model\ngeneration for efficient reasoning. We also introduce Graph4real, a\ncomprehensive benchmark contains with four domains of real-world graphs (Web,\nSocial, Transportation, and Citation) to evaluate LLMs' graph reasoning\ncapabilities. Our Graph4real covers 21 different graph reasoning tasks,\ncategorized into three types (Structural Querying, Algorithmic Reasoning, and\nPredictive Modeling tasks), with graph scales that are 10 times larger than\nexisting benchmarks. Experiments show that Llama3.1-8B based GraphCogent\nachieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).\nCompared to state-of-the-art agent-based baseline, our framework outperforms by\n20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%\nfor out-toolset tasks. Code will be available after review."}
{"id": "2508.11990", "pdf": "https://arxiv.org/pdf/2508.11990", "abs": "https://arxiv.org/abs/2508.11990", "authors": ["Evan Dogariu", "Anand Brahmbhatt", "Elad Hazan"], "title": "Universal Learning of Nonlinear Dynamics", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "We study the fundamental problem of learning a marginally stable unknown\nnonlinear dynamical system. We describe an algorithm for this problem, based on\nthe technique of spectral filtering, which learns a mapping from past\nobservations to the next based on a spectral representation of the system.\nUsing techniques from online convex optimization, we prove vanishing prediction\nerror for any nonlinear dynamical system that has finitely many marginally\nstable modes, with rates governed by a novel quantitative control-theoretic\nnotion of learnability. The main technical component of our method is a new\nspectral filtering algorithm for linear dynamical systems, which incorporates\npast observations and applies to general noisy and marginally stable systems.\nThis significantly generalizes the original spectral filtering algorithm to\nboth asymmetric dynamics as well as incorporating noise correction, and is of\nindependent interest."}
{"id": "2508.12792", "pdf": "https://arxiv.org/pdf/2508.12792", "abs": "https://arxiv.org/abs/2508.12792", "authors": ["Felipe Maia Polo", "Xinhe Wang", "Mikhail Yurochkin", "Gongjun Xu", "Moulinath Banerjee", "Yuekai Sun"], "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large language models are increasingly used as judges (LLM-as-a-judge) to\nevaluate model outputs at scale, but their assessments often diverge\nsystematically from human judgments. We present Bridge, a unified statistical\nframework that explicitly bridges human and LLM evaluations under both absolute\nscoring and pairwise comparison paradigms. Bridge posits a latent human\npreference score for each prompt-response pair and models LLM deviations as\nlinear transformations of covariates that capture sources of discrepancies.\nThis offers a simple and principled framework for refining LLM ratings and\ncharacterizing systematic discrepancies between humans and LLMs. We provide an\nefficient fitting algorithm with asymptotic guarantees for statistical\ninference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot\nArena), Bridge achieves higher agreement with human ratings (accuracy,\ncalibration, and KL divergence) and exposes systematic human-LLM gaps."}
{"id": "2508.12425", "pdf": "https://arxiv.org/pdf/2508.12425", "abs": "https://arxiv.org/abs/2508.12425", "authors": ["Phuong Minh Nguyen", "Tien Huu Dang", "Naoya Inoue"], "title": "Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved\napproach to standard CoT, for logical reasoning in large language models\n(LLMs). The key idea is to integrate lightweight symbolic representations into\nfew-shot prompts, structuring the inference steps with a consistent strategy to\nmake reasoning patterns more explicit within a non-iterative reasoning process.\nBy incorporating these symbolic structures, our method preserves the\ngeneralizability of standard prompting techniques while enhancing the\ntransparency, interpretability, and analyzability of LLM logical reasoning.\nExtensive experiments on four well-known logical reasoning benchmarks --\nProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse\nreasoning scenarios -- demonstrate the effectiveness of the proposed approach,\nparticularly in complex reasoning tasks that require navigating multiple\nconstraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'\nreasoning capabilities across various model sizes and significantly outperforms\nconventional CoT on three out of four datasets, ProofWriter, ProntoQA, and\nLogicalDeduction."}
{"id": "2508.12021", "pdf": "https://arxiv.org/pdf/2508.12021", "abs": "https://arxiv.org/abs/2508.12021", "authors": ["You Hak Lee", "Xiaofan Yu", "Quanling Zhao", "Flavio Ponzina", "Tajana Rosing"], "title": "FedUHD: Unsupervised Federated Learning using Hyperdimensional Computing", "categories": ["cs.LG", "cs.AR", "cs.DC"], "comment": null, "summary": "Unsupervised federated learning (UFL) has gained attention as a\nprivacy-preserving, decentralized machine learning approach that eliminates the\nneed for labor-intensive data labeling. However, UFL faces several challenges\nin practical applications: (1) non-independent and identically distributed\n(non-iid) data distribution across devices, (2) expensive computational and\ncommunication costs at the edge, and (3) vulnerability to communication noise.\nPrevious UFL approaches have relied on deep neural networks (NN), which\nintroduce substantial overhead in both computation and communication. In this\npaper, we propose FedUHD, the first UFL framework based on Hyperdimensional\nComputing (HDC). HDC is a brain-inspired computing scheme with lightweight\ntraining and inference operations, much smaller model size, and robustness to\ncommunication noise. FedUHD introduces two novel HDC-based designs to improve\nUFL performance. On the client side, a kNN-based cluster hypervector removal\nmethod addresses non-iid data samples by eliminating detrimental outliers. On\nthe server side, a weighted HDC aggregation technique balances the non-iid data\ndistribution across clients. Our experiments demonstrate that FedUHD achieves\nup to 173.6x and 612.7x better speedup and energy efficiency, respectively, in\ntraining, up to 271x lower communication cost, and 15.50% higher accuracy on\naverage across diverse settings, along with superior robustness to various\ntypes of noise compared to state-of-the-art NN-based UFL approaches."}
{"id": "2508.12970", "pdf": "https://arxiv.org/pdf/2508.12970", "abs": "https://arxiv.org/abs/2508.12970", "authors": ["Sayantan Banerjee", "Agnieszka Wylomanska", "Sundar S"], "title": "A self-supervised learning approach for denoising autoregressive models with additive noise: finite and infinite variance cases", "categories": ["stat.ME", "stat.CO", "stat.ML"], "comment": "32 pages, 17 figures", "summary": "The autoregressive time series model is a popular second-order stationary\nprocess, modeling a wide range of real phenomena. However, in applications,\nautoregressive signals are often corrupted by additive noise. Further, the\nautoregressive process and the corruptive noise may be highly impulsive,\nstemming from an infinite-variance distribution. The model estimation\ntechniques that account for additional noise tend to show reduced efficacy when\nthere is very strong noise present in the data, especially when the noise is\nheavy-tailed. Moreover, identification of a model corrupted with heavy-tailed,\nparticularly infinite-variance noise, can be a very challenging task. In this\npaper, we propose a novel self-supervised learning method to denoise the\nadditive noise-corrupted autoregressive model. Our approach is motivated by\nrecent work in computer vision and does not require full knowledge of the noise\ndistribution. We use the proposed method to recover exemplary finite- and\ninfinite-variance autoregressive signals, namely, Gaussian- and alpha-stable\ndistributed signals, respectively, from their noise-corrupted versions. The\nsimulation study conducted on both synthetic and semi-synthetic data\ndemonstrates the efficiency of our method compared to several baseline methods,\nparticularly when the corruption is significant and impulsive in nature.\nFinally, we apply the presented methodology to forecast the pure autoregressive\nsignal from the noise-corrupted data."}
{"id": "2508.12472", "pdf": "https://arxiv.org/pdf/2508.12472", "abs": "https://arxiv.org/abs/2508.12472", "authors": ["Yifang Tian", "Yaming Liu", "Zichun Chong", "Zihang Huang", "Hans-Arno Jacobsen"], "title": "GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?", "categories": ["cs.AI"], "comment": "12 pages, 5 figures", "summary": "Root cause analysis (RCA) in microservice systems is challenging, requiring\non-call engineers to rapidly diagnose failures across heterogeneous telemetry\nsuch as metrics, logs, and traces. Traditional RCA methods often focus on\nsingle modalities or merely rank suspect services, falling short of providing\nactionable diagnostic insights with remediation guidance. This paper introduces\nGALA, a novel multi-modal framework that combines statistical causal inference\nwith LLM-driven iterative reasoning for enhanced RCA. Evaluated on an\nopen-source benchmark, GALA achieves substantial improvements over\nstate-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM\nevaluation score shows GALA generates significantly more causally sound and\nactionable diagnostic outputs than existing methods. Through comprehensive\nexperiments and a case study, we show that GALA bridges the gap between\nautomated failure diagnosis and practical incident resolution by providing both\naccurate root cause identification and human-interpretable remediation\nguidance."}
{"id": "2508.12042", "pdf": "https://arxiv.org/pdf/2508.12042", "abs": "https://arxiv.org/abs/2508.12042", "authors": ["Zahra Kharaghani", "Ali Dadras", "Tommy Löfstedt"], "title": "Fairness Regularization in Federated Learning", "categories": ["cs.LG"], "comment": "25 pages", "summary": "Federated Learning (FL) has emerged as a vital paradigm in modern machine\nlearning that enables collaborative training across decentralized data sources\nwithout exchanging raw data. This approach not only addresses privacy concerns\nbut also allows access to overall substantially larger and potentially more\ndiverse datasets, without the need for centralized storage or hardware\nresources. However, heterogeneity in client data may cause certain clients to\nhave disproportionate impacts on the global model, leading to disparities in\nthe clients' performances. Fairness, therefore, becomes a crucial concern in FL\nand can be addressed in various ways. However, the effectiveness of existing\nfairness-aware methods, particularly in heterogeneous data settings, remains\nunclear, and the relationships between different approaches are not well\nunderstood. In this work, we focus on performance equitable fairness, which\naims to minimize differences in performance across clients. We restrict our\nstudy to fairness-aware methods that explicitly regularize client losses,\nevaluating both existing and newly proposed approaches. We identify and\ntheoretically explain connections between the investigated fairness methods,\nand empirically show that FairGrad (approximate) and FairGrad* (exact) (two\nvariants of a gradient variance regularization method introduced here for\nperformance equitable fairness) improve both fairness and overall model\nperformance in heterogeneous data settings."}
{"id": "2508.12997", "pdf": "https://arxiv.org/pdf/2508.12997", "abs": "https://arxiv.org/abs/2508.12997", "authors": ["Haishun Chen", "Cai Xu", "Jinlong Yu", "Yilin Zhang", "Ziyu Guan", "Wei Zhao"], "title": "Fairness-Aware Multi-view Evidential Learning with Adaptive Prior", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multi-view evidential learning aims to integrate information from multiple\nviews to improve prediction performance and provide trustworthy uncertainty\nesitimation. Most previous methods assume that view-specific evidence learning\nis naturally reliable. However, in practice, the evidence learning process\ntends to be biased. Through empirical analysis on real-world data, we reveal\nthat samples tend to be assigned more evidence to support data-rich classes,\nthereby leading to unreliable uncertainty estimation in predictions. This\nmotivates us to delve into a new Biased Evidential Multi-view Learning (BEML)\nproblem. To this end, we propose Fairness-Aware Multi-view Evidential Learning\n(FAML). FAML first introduces an adaptive prior based on training trajectory,\nwhich acts as a regularization strategy to flexibly calibrate the biased\nevidence learning process. Furthermore, we explicitly incorporate a fairness\nconstraint based on class-wise evidence variance to promote balanced evidence\nallocation. In the multi-view fusion stage, we propose an opinion alignment\nmechanism to mitigate view-specific bias across views, thereby encouraging the\nintegration of consistent and mutually supportive evidence. Extensive\nexperiments on five real-world multi-view datasets demonstrate that FAML\nachieves more balanced evidence allocation and improves both prediction\nperformance and the reliability of uncertainty estimation compared to\nstate-of-the-art methods."}
{"id": "2508.12480", "pdf": "https://arxiv.org/pdf/2508.12480", "abs": "https://arxiv.org/abs/2508.12480", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Andreas Bulling"], "title": "The Yokai Learning Environment: Tracking Beliefs Over Space and Time", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": "Presented at the the ToM IJCAI 2025 Workshop", "summary": "Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to\nreason about the beliefs of others to build and maintain common ground.\nExisting ToM benchmarks, however, are restricted to passive observer settings\nor lack an assessment of how agents establish and maintain common ground over\ntime. To address these gaps, we introduce the Yokai Learning Environment (YLE)\n- a multi-agent reinforcement learning (RL) environment based on the\ncooperative card game Yokai. In the YLE, agents take turns peeking at hidden\ncards and moving them to form clusters based on colour. Success requires\ntracking evolving beliefs, remembering past observations, using hints as\ngrounded communication, and maintaining common ground with teammates. Our\nevaluation yields two key findings: First, current RL agents struggle to solve\nthe YLE, even when given access to perfect memory. Second, while belief\nmodelling improves performance, agents are still unable to effectively\ngeneralise to unseen partners or form accurate beliefs over longer games,\nexposing a reliance on brittle conventions rather than robust belief tracking.\nWe use the YLE to investigate research questions in belief modelling, memory,\npartner generalisation, and scaling to higher-order ToM."}
{"id": "2508.12061", "pdf": "https://arxiv.org/pdf/2508.12061", "abs": "https://arxiv.org/abs/2508.12061", "authors": ["Daria Diatlova", "Nikita Balagansky", "Alexander Varlamov", "Egor Spirin"], "title": "VARAN: Variational Inference for Self-Supervised Speech Models Fine-Tuning on Downstream Tasks", "categories": ["cs.LG"], "comment": null, "summary": "Conventional methods for aggregating layers in fine-tuned self-supervised\nspeech models, such as using the final layer or weighted sum, suffer from\ninformation bottlenecks and static feature weighting for all dataset examples.\nWe propose VARAN, a framework that dynamically tailors layer aggregation to\nindividual inputs. By employing layer-specialized probing heads and\ndata-dependent weighting, VARAN adaptively prioritizes layer's features based\non input. Evaluations on automatic speech recognition and speech emotion\nrecognition tasks demonstrate VARAN's superior performance, particularly when\nusing the LoRA fine-tuning technique. The framework resolves the trade-off\nbetween preserving layer-specific information and enabling flexible feature\nutilization, advancing efficient adaptation of self-supervised speech\nrepresentations."}
{"id": "2508.13100", "pdf": "https://arxiv.org/pdf/2508.13100", "abs": "https://arxiv.org/abs/2508.13100", "authors": ["Jason Hartline", "Lunjia Hu", "Yifan Wu"], "title": "A Perfectly Truthful Calibration Measure", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "Calibration requires that predictions are conditionally unbiased and,\ntherefore, reliably interpretable as probabilities. Calibration measures\nquantify how far a predictor is from perfect calibration. As introduced by\nHaghtalab et al. (2024), a calibration measure is truthful if it is minimized\nin expectation when a predictor outputs the ground-truth probabilities.\nAlthough predicting the true probabilities guarantees perfect calibration, in\nreality, when calibration is evaluated on a finite sample, predicting the truth\nis not guaranteed to minimize any known calibration measure. All known\ncalibration measures incentivize predictors to lie in order to appear more\ncalibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et\nal. (2024) and Qiao and Zhao (2025) to construct approximately truthful\ncalibration measures in the sequential prediction setting, but no perfectly\ntruthful calibration measure was known to exist even in the more basic batch\nsetting.\n  We design a perfectly truthful calibration measure in the batch setting:\naveraged two-bin calibration error (ATB). In addition to being truthful, ATB is\nsound, complete, continuous, and quadratically related to two existing\ncalibration measures: the smooth calibration error (smCal) and the (lower)\ndistance to calibration (distCal). The simplicity in our definition of ATB\nmakes it efficient and straightforward to compute. ATB allows faster estimation\nalgorithms with significantly easier implementations than smCal and distCal,\nachieving improved running time and simplicity for the calibration testing\nproblem studied by Hu et al. (2024). We also introduce a general recipe for\nconstructing truthful measures, which proves the truthfulness of ATB as a\nspecial case and allows us to construct other truthful calibration measures\nsuch as quantile-binned l_2-ECE."}
{"id": "2508.12487", "pdf": "https://arxiv.org/pdf/2508.12487", "abs": "https://arxiv.org/abs/2508.12487", "authors": ["Lida Shahbandari", "Hossein Mohseni"], "title": "Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that\nuses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index\n(BIS), keeping it within the ideal range of forty to sixty. The FOFPID\ncontroller combines fuzzy logic for adapting to changes and fractional order\ndynamics for fine tuning. This allows it to adjust its control gains to handle\na person's unique physiology. The WOA helps fine tune the controller's\nparameters, including the fractional orders and the fuzzy membership functions,\nwhich boosts its performance. Tested on models of eight different patient\nprofiles, the FOFPID controller performed better than a standard Fractional\nOrder PID (FOPID) controller. It achieved faster settling times, at two and a\nhalf minutes versus three point two minutes, and had a lower steady state\nerror, at zero point five versus one point two. These outcomes show the\nFOFPID's excellent strength and accuracy. It offers a scalable, artificial\nintelligence driven solution for automated anesthesia delivery that could\nenhance clinical practice and improve patient results."}
{"id": "2508.12079", "pdf": "https://arxiv.org/pdf/2508.12079", "abs": "https://arxiv.org/abs/2508.12079", "authors": ["Ningzhe Shi", "Yiqing Zhou", "Ling Liu", "Jinglin Shi", "Yihao Wu", "Haiwei Shi", "Hanxiao Yu"], "title": "Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks", "categories": ["cs.LG"], "comment": null, "summary": "Integrated sensing and communication (ISAC) can enhance artificial\nintelligence-generated content (AIGC) networks by providing efficient sensing\nand transmission. Existing AIGC services usually assume that the accuracy of\nthe generated content can be ensured, given accurate input data and prompt,\nthus only the content generation quality (CGQ) is concerned. However, it is not\napplicable in ISAC-based AIGC networks, where content generation is based on\ninaccurate sensed data. Moreover, the AIGC model itself introduces generation\nerrors, which depend on the number of generating steps (i.e., computing\nresources). To assess the quality of experience of ISAC-based AIGC services, we\npropose a content accuracy and quality aware service assessment metric (CAQA).\nSince allocating more resources to sensing and generating improves content\naccuracy but may reduce communication quality, and vice versa, this\nsensing-generating (computing)-communication three-dimensional resource\ntradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all\nusers with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution\nspace that grows exponentially with users. To solve the CAQA-AIGC problem with\nlow complexity, a linear programming (LP) guided deep reinforcement learning\n(DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the\nLP-guided approach and the action filter, LPDRL-F can transform the original\nthree-dimensional solution space to two dimensions, reducing complexity while\nimproving the learning performance of DRL. Simulations show that compared to\nexisting DRL and generative diffusion model algorithms without LP, LPDRL-F\nconverges faster by over 60% and finds better resource allocation solutions,\nimproving AvgCAQA by more than 14%. With LPDRL-F, CAQA-AIGC can achieve an\nimprovement in AvgCAQA of more than 50% compared to existing schemes focusing\nsolely on CGQ."}
{"id": "2508.13131", "pdf": "https://arxiv.org/pdf/2508.13131", "abs": "https://arxiv.org/abs/2508.13131", "authors": ["Dara Bahri", "John Wieting"], "title": "Improving Detection of Watermarked Language Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "Watermarking has recently emerged as an effective strategy for detecting the\ngenerations of large language models (LLMs). The strength of a watermark\ntypically depends strongly on the entropy afforded by the language model and\nthe set of input prompts. However, entropy can be quite limited in practice,\nespecially for models that are post-trained, for example via instruction tuning\nor reinforcement learning from human feedback (RLHF), which makes detection\nbased on watermarking alone challenging. In this work, we investigate whether\ndetection can be improved by combining watermark detectors with non-watermark\nones. We explore a number of hybrid schemes that combine the two, observing\nperformance gains over either class of detector under a wide range of\nexperimental conditions."}
{"id": "2508.12500", "pdf": "https://arxiv.org/pdf/2508.12500", "abs": "https://arxiv.org/abs/2508.12500", "authors": ["Rahmat K. Adesunkanmi", "Ashfaq Khokhar", "Goce Trajcevski", "Sohail Murad"], "title": "Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "comment": "Submitted to ACM", "summary": "Molecular dynamics simulations (MDS) face challenges, including\nresource-heavy computations and the need to manually scan outputs to detect\n\"interesting events,\" such as the formation and persistence of hydrogen bonds\nbetween atoms of different molecules. A critical research gap lies in\nidentifying the underlying causes of hydrogen bond formation and separation\n-understanding which interactions or prior events contribute to their emergence\nover time. With this challenge in mind, we propose leveraging spatio-temporal\ndata analytics and machine learning models to enhance the detection of these\nphenomena. In this paper, our approach is inspired by causal modeling and aims\nto identify the root cause variables of hydrogen bond formation and separation\nevents. Specifically, we treat the separation of hydrogen bonds as an\n\"intervention\" occurring and represent the causal structure of the bonding and\nseparation events in the MDS as graphical causal models. These causal models\nare built using a variational autoencoder-inspired architecture that enables us\nto infer causal relationships across samples with diverse underlying causal\ngraphs while leveraging shared dynamic information. We further include a step\nto infer the root causes of changes in the joint distribution of the causal\nmodels. By constructing causal models that capture shifts in the conditional\ndistributions of molecular interactions during bond formation or separation,\nthis framework provides a novel perspective on root cause analysis in molecular\ndynamic systems. We validate the efficacy of our model empirically on the\natomic trajectories that used MDS for chiral separation, demonstrating that we\ncan predict many steps in the future and also find the variables driving the\nobserved changes in the system."}
{"id": "2508.12104", "pdf": "https://arxiv.org/pdf/2508.12104", "abs": "https://arxiv.org/abs/2508.12104", "authors": ["Shane Waxler", "Paul Blazek", "Davis White", "Daniel Sneider", "Kevin Chung", "Mani Nagarathnam", "Patrick Williams", "Hank Voeller", "Karen Wong", "Matthew Swanhorst", "Sheng Zhang", "Naoto Usuyama", "Cliff Wong", "Tristan Naumann", "Hoifung Poon", "Andrew Loza", "Daniella Meeker", "Seth Hain", "Rahul Shah"], "title": "Generative Medical Event Models Improve with Scale", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Realizing personalized medicine at scale calls for methods that distill\ninsights from longitudinal patient journeys, which can be viewed as a sequence\nof medical events. Foundation models pretrained on large-scale medical event\ndata represent a promising direction for scaling real-world evidence generation\nand generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with\nmedical events from de-identified longitudinal health records for 16.3 billion\nencounters over 300 million unique patient records from 310 health systems, we\nintroduce the Cosmos Medical Event Transformer ( CoMET) models, a family of\ndecoder-only transformer models pretrained on 118 million patients representing\n115 billion discrete medical events (151 billion tokens). We present the\nlargest scaling-law study for medical event data, establishing a methodology\nfor pretraining and revealing power-law scaling relationships for compute,\ntokens, and model size. Based on this, we pretrained a series of\ncompute-optimal models with up to 1 billion parameters. Conditioned on a\npatient's real-world history, CoMET autoregressively generates the next medical\nevent, simulating patient health timelines. We studied 78 real-world tasks,\nincluding diagnosis prediction, disease prognosis, and healthcare operations.\nRemarkably for a foundation model with generic pretraining and simulation-based\ninference, CoMET generally outperformed or matched task-specific supervised\nmodels on these tasks, without requiring task-specific fine-tuning or few-shot\nexamples. CoMET's predictive power consistently improves as the model and\npretraining scale. Our results show that CoMET, a generative medical event\nfoundation model, can effectively capture complex clinical dynamics, providing\nan extensible and generalizable framework to support clinical decision-making,\nstreamline healthcare operations, and improve patient outcomes."}
{"id": "2508.12566", "pdf": "https://arxiv.org/pdf/2508.12566", "abs": "https://arxiv.org/abs/2508.12566", "authors": ["Wei Song", "Haonan Zhong", "Ziqi Ding", "Jingling Xue", "Yuekang Li"], "title": "Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "The Model Context Protocol (MCP) enables large language models (LLMs) to\naccess external resources on demand. While commonly assumed to enhance\nperformance, how LLMs actually leverage this capability remains poorly\nunderstood. We introduce MCPGAUGE, the first comprehensive evaluation framework\nfor probing LLM-MCP interactions along four key dimensions: proactivity\n(self-initiated tool use), compliance (adherence to tool-use instructions),\neffectiveness (task performance post-integration), and overhead (computational\ncost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning\nknowledge comprehension, general reasoning, and code generation. Our\nlarge-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and\nboth one- and two-turn interaction settings, comprises around 20,000 API calls\nand over USD 6,000 in computational cost. This comprehensive study reveals four\nkey findings that challenge prevailing assumptions about the effectiveness of\nMCP integration. These insights highlight critical limitations in current\nAI-tool integration and position MCPGAUGE as a principled benchmark for\nadvancing controllable, tool-augmented LLMs."}
{"id": "2508.12116", "pdf": "https://arxiv.org/pdf/2508.12116", "abs": "https://arxiv.org/abs/2508.12116", "authors": ["Haebin Shin", "Lei Ji", "Xiao Liu", "Zhiwei Yu", "Qi Chen", "Yeyun Gong"], "title": "DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As numerous instruction-tuning datasets continue to emerge during the\npost-training stage, dynamically balancing and optimizing their mixtures has\nbecome a critical challenge. To address this, we propose DynamixSFT, a dynamic\nand automated method for instruction-tuning dataset mixture optimization. We\nformulate the problem as a multi-armed bandit setup and introduce a\nPrior-scaled Boltzmann Exploration that softly anchors the updated sampling\ndistribution to the original dataset proportions, thereby preserving the\ninherent diversity and coverage of the collection. Sampling probabilities are\nupdated using a lightweight 1-Step Look-ahead Reward, reflecting how much the\ndataset contributes to improving the model's performance at its current state.\nWhen applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning\ndatasets, DynamixSFT achieves up to a 2.2% performance improvement across 10\nbenchmarks. Furthermore, we provide a comprehensive analysis and visualizations\nto offer deeper insights into the adaptive dynamics of our method."}
{"id": "2508.12611", "pdf": "https://arxiv.org/pdf/2508.12611", "abs": "https://arxiv.org/abs/2508.12611", "authors": ["Trang Tran", "Trung Hoang Le", "Huiping Cao", "Tran Cao Son"], "title": "An LLM + ASP Workflow for Joint Entity-Relation Extraction", "categories": ["cs.AI", "cs.CL", "I.2.7; F.4.1"], "comment": "13 pages, 1 figure, Accepted as Technical Communication, 41st\n  International Conference on Logic Programming", "summary": "Joint entity-relation extraction (JERE) identifies both entities and their\nrelationships simultaneously. Traditional machine-learning based approaches to\nperforming this task require a large corpus of annotated data and lack the\nability to easily incorporate domain specific information in the construction\nof the model. Therefore, creating a model for JERE is often labor intensive,\ntime consuming, and elaboration intolerant. In this paper, we propose\nharnessing the capabilities of generative pretrained large language models\n(LLMs) and the knowledge representation and reasoning capabilities of Answer\nSet Programming (ASP) to perform JERE. We present a generic workflow for JERE\nusing LLMs and ASP. The workflow is generic in the sense that it can be applied\nfor JERE in any domain. It takes advantage of LLM's capability in natural\nlanguage understanding in that it works directly with unannotated text. It\nexploits the elaboration tolerant feature of ASP in that no modification of its\ncore program is required when additional domain specific knowledge, in the form\nof type specifications, is found and needs to be used. We demonstrate the\nusefulness of the proposed workflow through experiments with limited training\ndata on three well-known benchmarks for JERE. The results of our experiments\nshow that the LLM + ASP workflow is better than state-of-the-art JERE systems\nin several categories with only 10\\% of training data. It is able to achieve a\n2.5 times (35\\% over 15\\%) improvement in the Relation Extraction task for the\nSciERC corpus, one of the most difficult benchmarks."}
{"id": "2508.12121", "pdf": "https://arxiv.org/pdf/2508.12121", "abs": "https://arxiv.org/abs/2508.12121", "authors": ["Lorenzo Livi"], "title": "Time-Scale Coupling Between States and Parameters in Recurrent Neural Networks", "categories": ["cs.LG", "math.DS"], "comment": null, "summary": "We study how gating mechanisms in recurrent neural networks (RNNs) implicitly\ninduce adaptive learning-rate behavior, even when training is carried out with\na fixed, global learning rate. This effect arises from the coupling between\nstate-space time scales--parametrized by the gates--and parameter-space\ndynamics during gradient descent. By deriving exact Jacobians for\nleaky-integrator and gated RNNs, we obtain a first-order expansion that makes\nexplicit how constant, scalar, and multi-dimensional gates reshape gradient\npropagation, modulate effective step sizes, and introduce anisotropy in\nparameter updates. These findings reveal that gates not only control memory\nretention in the hidden states, but also act as data-driven preconditioners\nthat adapt optimization trajectories in parameter space. We further draw formal\nanalogies with learning-rate schedules, momentum, and adaptive methods such as\nAdam, showing that these optimization behaviors emerge naturally from gating.\nNumerical experiments confirm the validity of our perturbative analysis,\nsupporting the view that gate-induced corrections remain small while exerting\nsystematic effects on training dynamics. Overall, this work provides a unified\ndynamical-systems perspective on how gating couples state evolution with\nparameter updates, explaining why gated architectures achieve robust\ntrainability and stability in practice."}
{"id": "2508.12647", "pdf": "https://arxiv.org/pdf/2508.12647", "abs": "https://arxiv.org/abs/2508.12647", "authors": ["Hengnian Gu", "Zhifu Chen", "Yuxin Chen", "Jin Peng Zhou", "Dongdai Zhou"], "title": "Cognitive Structure Generation: From Educational Priors to Policy Optimization", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Cognitive structure is a student's subjective organization of an objective\nknowledge system, reflected in the psychological construction of concepts and\ntheir relations. However, cognitive structure assessment remains a\nlong-standing challenge in student modeling and psychometrics, persisting as a\nfoundational yet largely unassessable concept in educational practice. This\npaper introduces a novel framework, Cognitive Structure Generation (CSG), in\nwhich we first pretrain a Cognitive Structure Diffusion Probabilistic Model\n(CSDPM) to generate students' cognitive structures from educational priors, and\nthen further optimize its generative process as a policy with hierarchical\nreward signals via reinforcement learning to align with genuine cognitive\ndevelopment levels during students' learning processes. Experimental results on\nfour popular real-world education datasets show that cognitive structures\ngenerated by CSG offer more comprehensive and effective representations for\nstudent modeling, substantially improving performance on KT and CD tasks while\nenhancing interpretability."}
{"id": "2508.12145", "pdf": "https://arxiv.org/pdf/2508.12145", "abs": "https://arxiv.org/abs/2508.12145", "authors": ["Frederik L. Dennig", "Daniel A. Keim"], "title": "DE-VAE: Revealing Uncertainty in Parametric and Inverse Projections with Variational Autoencoders using Differential Entropy", "categories": ["cs.LG"], "comment": "5 pages, 3 figures, LaTeX", "summary": "Recently, autoencoders (AEs) have gained interest for creating parametric and\ninvertible projections of multidimensional data. Parametric projections make it\npossible to embed new, unseen samples without recalculating the entire\nprojection, while invertible projections allow the synthesis of new data\ninstances. However, existing methods perform poorly when dealing with\nout-of-distribution samples in either the data or embedding space. Thus, we\npropose DE-VAE, an uncertainty-aware variational AE using differential entropy\n(DE) to improve the learned parametric and invertible projections. Given a\nfixed projection, we train DE-VAE to learn a mapping into 2D space and an\ninverse mapping back to the original space. We conduct quantitative and\nqualitative evaluations on four well-known datasets, using UMAP and t-SNE as\nbaseline projection methods. Our findings show that DE-VAE can create\nparametric and inverse projections with comparable accuracy to other current\nAE-based approaches while enabling the analysis of embedding uncertainty."}
{"id": "2508.12651", "pdf": "https://arxiv.org/pdf/2508.12651", "abs": "https://arxiv.org/abs/2508.12651", "authors": ["Chunliang Hua", "Xiao Hu", "Jiayang Sun", "Zeyuan Yang"], "title": "The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning", "categories": ["cs.AI", "cs.ET"], "comment": "10 pages", "summary": "As urban aerial mobility (UAM) infrastructure development accelerates\nglobally, cities like Shenzhen are planning large-scale vertiport networks\n(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain\ninadequate for this complexity due to historical limitations in data\ngranularity and real-world applicability. This paper addresses these gaps by\nfirst proposing the Capacitated Dynamic Maximum Covering Location Problem\n(CDMCLP), a novel optimization framework that simultaneously models urban-scale\nspatial-temporal demand, heterogeneous user behaviors, and infrastructure\ncapacity constraints. Building on this foundation, we introduce an Integrated\nPlanning Recommendation System that combines CDMCLP with socio-economic factors\nand dynamic clustering initialization. This system leverages adaptive parameter\ntuning based on empirical user behavior to generate practical planning\nsolutions. Validation in a Chinese center city demonstrates the effectiveness\nof the new optimization framework and recommendation system. Under the\nevaluation and optimization of CDMCLP, the quantitative performance of\ntraditional location methods are exposed and can be improved by 38\\%--52\\%,\nwhile the recommendation system shows user-friendliness and the effective\nintegration of complex elements. By integrating mathematical rigor with\npractical implementation considerations, this hybrid approach bridges the gap\nbetween theoretical location modeling and real-world UAM infrastructure\nplanning, offering municipalities a pragmatic tool for vertiport network\ndesign."}
{"id": "2508.12162", "pdf": "https://arxiv.org/pdf/2508.12162", "abs": "https://arxiv.org/abs/2508.12162", "authors": ["J. M. I. H. Jayakody", "A. M. H. H. Alahakoon", "C. R. M. Perera", "R. M. L. C. Srimal", "Roshan Ragel", "Vajira Thambawita", "Isuru Nawinne"], "title": "AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The paradigm of electrocardiogram (ECG) analysis has evolved into real-time\ndigital analysis, facilitated by artificial intelligence (AI) and machine\nlearning (ML), which has improved the diagnostic precision and predictive\ncapacity of cardiac diseases. This work proposes a novel deep learning (DL)\narchitecture called the attention-integrated convolutional residual network\n(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,\nthe QRS duration, the heart rate, the peak amplitude of the R wave, and the\namplitude of the T wave for interpretable ECG analysis. Our architecture is\nspecially designed with spatial and channel attention-related mechanisms to\naddress the type and spatial location of the ECG features for regression. The\nmodels employ a convolutional residual network to address vanishing and\nexploding gradient problems. The designed system addresses traditional analysis\nchallenges, such as loss of focus due to human errors, and facilitates the fast\nand easy detection of cardiac events, thereby reducing the manual efforts\nrequired to solve analysis tasks. AICRN models outperform existing models in\nparameter regression with higher precision. This work demonstrates that DL can\nplay a crucial role in the interpretability and precision of ECG analysis,\nopening up new clinical applications for cardiac monitoring and management."}
{"id": "2508.12682", "pdf": "https://arxiv.org/pdf/2508.12682", "abs": "https://arxiv.org/abs/2508.12682", "authors": ["Jinquan Shi", "Yingying Cheng", "Fan Zhang", "Miao Jiang", "Jun Lin", "Yanbai Shen"], "title": "GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance", "categories": ["cs.AI"], "comment": null, "summary": "The global shift towards renewable energy presents unprecedented challenges\nfor the electricity industry, making regulatory reasoning and compliance\nincreasingly vital. Grid codes, the regulations governing grid operations, are\ncomplex and often lack automated interpretation solutions, which hinders\nindustry expansion and undermines profitability for electricity companies. We\nintroduce GridCodex, an end to end framework for grid code reasoning and\ncompliance that leverages large language models and retrieval-augmented\ngeneration (RAG). Our framework advances conventional RAG workflows through\nmulti stage query refinement and enhanced retrieval with RAPTOR. We validate\nthe effectiveness of GridCodex with comprehensive benchmarks, including\nautomated answer assessment across multiple dimensions and regulatory agencies.\nExperimental results showcase a 26.4% improvement in answer quality and more\nthan a 10 fold increase in recall rate. An ablation study further examines the\nimpact of base model selection."}
{"id": "2508.12212", "pdf": "https://arxiv.org/pdf/2508.12212", "abs": "https://arxiv.org/abs/2508.12212", "authors": ["Chuanliu Fan", "Zicheng Ma", "Jun Gao", "Nan Yu", "Jun Zhang", "Ziqiang Cao", "Yi Qin Gao", "Guohong Fu"], "title": "ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Recent advances in protein large language models, such as ProtTeX, represent\nboth side-chain amino acids and backbone structure as discrete token sequences\nof residue length. While this design enables unified modeling of multimodal\nprotein information, it suffers from two major limitations: (1) The\nconcatenation of sequence and structure tokens approximately doubles the\nprotein length and breaks the intrinsic residue-level alignment between\nmodalities. (2) Constrained by the training corpus and limited context window,\nProtTeX is typically trained on single-protein inputs, rendering it\nincompatible with in-context learning (ICL) and thus limiting its\ngeneralization capability. To address these issues, we propose ProtTeX-CC, a\nlightweight two-stage compression framework designed to enhance ProtTeX under\nfew-shot settings. We first design a joint embedding compression mechanism that\nfuses sequence and structure representations at the residue level, effectively\nreducing the protein input length by half without sacrificing performance. Then\nwe propose a self-compression module that aggregates each full demonstration\ninto the latent space of the last few linguistic tokens, reducing the average\ndemonstration length from 751 tokens to less than 16 tokens. Compared to the\noriginal ProtTeX, our self-compression approach achieves a compression ratio of\napproximately 93.68% in the total prompt length under the 16-shot setting.\nWithout modifying the backbone model, ProtTeX-CC introduces only a small number\nof additional parameters through PEFT-based tuning in the joint embedding\ncompression stage and a single trainable projection layer in the\nself-compression stage. Extensive experiments on protein function prediction\nshow that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and\ngeneralizes well to the out-of-domain dataset with a performance gain of 11%."}
{"id": "2508.12687", "pdf": "https://arxiv.org/pdf/2508.12687", "abs": "https://arxiv.org/abs/2508.12687", "authors": ["Ashish Seth", "Utkarsh Tyagi", "Ramaneswaran Selvakumar", "Nishit Anand", "Sonal Kumar", "Sreyan Ghosh", "Ramani Duraiswami", "Chirag Agarwal", "Dinesh Manocha"], "title": "EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nperformance in complex multimodal tasks. While MLLMs excel at visual perception\nand reasoning in third-person and egocentric videos, they are prone to\nhallucinations, generating coherent yet inaccurate responses. We present\nEgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric\nvideos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated\nopen and closed-ended questions designed to trigger hallucinations in both\nvisual and auditory cues in egocentric videos. Evaluations across ten MLLMs\nreveal significant challenges, including powerful models like GPT-4o and\nGemini, achieving only 59% accuracy. EgoIllusion lays the foundation in\ndeveloping robust benchmarks to evaluate the effectiveness of MLLMs and spurs\nthe development of better egocentric MLLMs with reduced hallucination rates.\nOur benchmark will be open-sourced for reproducibility."}
{"id": "2508.12220", "pdf": "https://arxiv.org/pdf/2508.12220", "abs": "https://arxiv.org/abs/2508.12220", "authors": ["Abdullah X"], "title": "Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CR", "I.2.6; I.2.7"], "comment": "Preprint; 2 figures + several tables; includes appendix.\n  Artifact/code link in paper", "summary": "We study the right to be forgotten (GDPR Art. 17) for large language models\nand frame unlearning as a reproducible systems problem. Our approach treats\ntraining as a deterministic program and logs a minimal per-microbatch record\n(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and\naccumulation boundary). Under a pinned stack and deterministic kernels,\nreplaying the training tail while filtering only the forget closure yields the\nsame parameters as training on the retain set (bit-identical in the training\ndtype) when preconditions hold. To meet latency and availability constraints,\nwe add complementary paths: (i) exact reverts of recent steps via\nmicro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion\nwhen the base is frozen, and (iii) a curvature-guided anti-update followed by a\nshort retain-tune, audit-gated with escalation to exact replay. We report\nstorage/latency budgets and a toy artifact validating mechanics; in a\ncontrolled run that satisfies the preconditions we demonstrate byte-identical\nequality of model and optimizer states."}
{"id": "2508.12725", "pdf": "https://arxiv.org/pdf/2508.12725", "abs": "https://arxiv.org/abs/2508.12725", "authors": ["Wenjie Chen", "Wenbin Li", "Di Yao", "Xuying Meng", "Chang Gong", "Jingping Bi"], "title": "GTool: Graph Enhanced Tool Planning with Large Language Model", "categories": ["cs.AI"], "comment": "16 pages, 9 figures", "summary": "Tool planning with large language models (LLMs), referring to selecting,\norganizing, and preparing the tools necessary to complete a user request,\nbridges the gap between natural language understanding and task execution.\nHowever, current works treat different tools as isolated components and fail to\nleverage the inherent dependencies of tools, leading to invalid planning\nresults. Since tool dependencies are often incomplete, it becomes challenging\nfor LLMs to accurately identify the appropriate tools required by a user\nrequest, especially when confronted with a large toolset. To solve this\nchallenge, we propose \\texttt{GTool}, which is the first work aiming to enhance\nthe tool planning ability of LLMs under incomplete dependencies. \\texttt{GTool}\nconstructs a request-specific tool graph to select tools efficiently and\ngenerate the \\texttt{<graph token>} which provides sufficient dependency\ninformation understandable by LLMs. Moreover, a missing dependency prediction\ntask is designed to improve the reliability of \\texttt{GTool} with incomplete\ndependencies. Without trimming LLMs, \\texttt{GTool} can be seamlessly\nintegrated with various LLM backbones without extensive retraining. Extensive\nexperiments show that \\texttt{GTool} achieves more than 29.6\\% performance\nimprovements compared with the state-of-the-art (SOTA) baselines with a\nlight-weight (7B) LLM backbone."}
{"id": "2508.12222", "pdf": "https://arxiv.org/pdf/2508.12222", "abs": "https://arxiv.org/abs/2508.12222", "authors": ["Sagar Shrestha", "Rajesh Shrestha", "Tri Nguyen", "Subash Timilsina"], "title": "Distribution Matching via Generalized Consistency Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancement in generative models have demonstrated remarkable\nperformance across various data modalities. Beyond their typical use in data\nsynthesis, these models play a crucial role in distribution matching tasks such\nas latent variable modeling, domain translation, and domain adaptation.\nGenerative Adversarial Networks (GANs) have emerged as the preferred method of\ndistribution matching due to their efficacy in handling high-dimensional data\nand their flexibility in accommodating various constraints. However, GANs often\nencounter challenge in training due to their bi-level min-max optimization\nobjective and susceptibility to mode collapse. In this work, we propose a novel\napproach for distribution matching inspired by the consistency models employed\nin Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF\nmodels, such as having a straight forward norm minimization objective, while\nremaining adaptable to different constraints similar to GANs. We provide\ntheoretical validation of our proposed objective and demonstrate its\nperformance through experiments on synthetic and real-world datasets."}
{"id": "2508.12754", "pdf": "https://arxiv.org/pdf/2508.12754", "abs": "https://arxiv.org/abs/2508.12754", "authors": ["Alessio Galatolo", "Luca Alberto Rappuoli", "Katie Winkle", "Meriem Beloucif"], "title": "Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants", "categories": ["cs.AI"], "comment": "Full version of the paper published in ECAI 2025 proceedings (IOS\n  Press, CC BY-NC 4.0)", "summary": "The recent rise in popularity of large language models (LLMs) has prompted\nconsiderable concerns about their moral capabilities. Although considerable\neffort has been dedicated to aligning LLMs with human moral values, existing\nbenchmarks and evaluations remain largely superficial, typically measuring\nalignment based on final ethical verdicts rather than explicit moral reasoning.\nIn response, this paper aims to advance the investigation of LLMs' moral\ncapabilities by examining their capacity to function as Artificial Moral\nAssistants (AMAs), systems envisioned in the philosophical literature to\nsupport human moral deliberation. We assert that qualifying as an AMA requires\nmore than what state-of-the-art alignment techniques aim to achieve: not only\nmust AMAs be able to discern ethically problematic situations, they should also\nbe able to actively reason about them, navigating between conflicting values\noutside of those embedded in the alignment phase. Building on existing\nphilosophical literature, we begin by designing a new formal framework of the\nspecific kind of behaviour an AMA should exhibit, individuating key qualities\nsuch as deductive and abductive moral reasoning. Drawing on this theoretical\nframework, we develop a benchmark to test these qualities and evaluate popular\nopen LLMs against it. Our results reveal considerable variability across models\nand highlight persistent shortcomings, particularly regarding abductive moral\nreasoning. Our work connects theoretical philosophy with practical AI\nevaluation while also emphasising the need for dedicated strategies to\nexplicitly enhance moral reasoning capabilities in LLMs. Code available at\nhttps://github.com/alessioGalatolo/AMAeval"}
{"id": "2508.12233", "pdf": "https://arxiv.org/pdf/2508.12233", "abs": "https://arxiv.org/abs/2508.12233", "authors": ["Sagar Shrestha"], "title": "Communication-Efficient Distributed Asynchronous ADMM", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "In distributed optimization and federated learning, asynchronous alternating\ndirection method of multipliers (ADMM) serves as an attractive option for\nlarge-scale optimization, data privacy, straggler nodes and variety of\nobjective functions. However, communication costs can become a major bottleneck\nwhen the nodes have limited communication budgets or when the data to be\ncommunicated is prohibitively large. In this work, we propose introducing\ncoarse quantization to the data to be exchanged in aynchronous ADMM so as to\nreduce communication overhead for large-scale federated learning and\ndistributed optimization applications. We experimentally verify the convergence\nof the proposed method for several distributed learning tasks, including neural\nnetworks."}
{"id": "2508.12782", "pdf": "https://arxiv.org/pdf/2508.12782", "abs": "https://arxiv.org/abs/2508.12782", "authors": ["Petr Anokhin", "Roman Khalikov", "Stefan Rebrikov", "Viktor Volkov", "Artyom Sorokin", "Vincent Bissonnette"], "title": "HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds", "categories": ["cs.AI"], "comment": "Code is available at https://github.com/stefanrer/HeroBench", "summary": "Large language models (LLMs) have shown remarkable capabilities in isolated\nstep-by-step reasoning tasks such as mathematics and programming, but their\nproficiency in long-horizon planning, where solutions require extended,\nstructured sequences of interdependent actions, remains underexplored. Existing\nbenchmarks typically assess LLMs through abstract or low-dimensional\nalgorithmic tasks, failing to capture the complexity of realistic planning\nenvironments. We introduce HeroBench, a novel benchmark designed specifically\nto evaluate long-horizon planning and structured reasoning within complex\nRPG-inspired virtual worlds. HeroBench provides a rigorously constructed\ndataset of tasks covering a wide range of difficulties, a simulated environment\nto execute and validate agent plans, and detailed analytical tools for\nevaluating model performance. Tasks challenge models to formulate strategic\nplans, efficiently gather resources, master necessary skills, craft equipment,\nand defeat adversaries, reflecting practical scenarios' layered dependencies\nand constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning\nboth open-source and proprietary models, including the GPT-5 family, reveals\nsubstantial performance disparities rarely observed in conventional reasoning\nbenchmarks. Detailed error analysis further uncovers specific weaknesses in\ncurrent models' abilities to generate robust high-level plans and reliably\nexecute structured actions. HeroBench thus not only significantly advances the\nevaluation of LLM reasoning but also provides a flexible, scalable foundation\nfor future research into advanced, autonomous planning in virtual environments."}
{"id": "2508.12235", "pdf": "https://arxiv.org/pdf/2508.12235", "abs": "https://arxiv.org/abs/2508.12235", "authors": ["Peng Chen", "Yihang Wang", "Yang Shu", "Yunyao Cheng", "Kai Zhao", "Zhongwen Rao", "Lujia Pan", "Bin Yang", "Chenjuan Guo"], "title": "CC-Time: Cross-Model and Cross-Modality Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "With the success of pre-trained language models (PLMs) in various application\nfields beyond natural language processing, language models have raised emerging\nattention in the field of time series forecasting (TSF) and have shown great\nprospects. However, current PLM-based TSF methods still fail to achieve\nsatisfactory prediction accuracy matching the strong sequential modeling power\nof language models. To address this issue, we propose Cross-Model and\nCross-Modality Learning with PLMs for time series forecasting (CC-Time). We\nexplore the potential of PLMs for time series forecasting from two aspects: 1)\nwhat time series features could be modeled by PLMs, and 2) whether relying\nsolely on PLMs is sufficient for building time series models. In the first\naspect, CC-Time incorporates cross-modality learning to model temporal\ndependency and channel correlations in the language model from both time series\nsequences and their corresponding text descriptions. In the second aspect,\nCC-Time further proposes the cross-model fusion block to adaptively integrate\nknowledge from the PLMs and time series model to form a more comprehensive\nmodeling of time series patterns. Extensive experiments on nine real-world\ndatasets demonstrate that CC-Time achieves state-of-the-art prediction accuracy\nin both full-data training and few-shot learning situations."}
{"id": "2508.12790", "pdf": "https://arxiv.org/pdf/2508.12790", "abs": "https://arxiv.org/abs/2508.12790", "authors": ["Zenan Huang", "Yihong Zhuang", "Guoshan Lu", "Zeyu Qin", "Haokai Xu", "Tianyu Zhao", "Ru Peng", "Jiaqi Hu", "Zhanming Shen", "Xiaomeng Hu", "Xijun Gu", "Peiyi Tu", "Jiaxin Liu", "Wenyu Chen", "Yuzhuo Fu", "Zhiting Fan", "Yanmei Gu", "Yuanyuan Wang", "Zhengkai Yang", "Jianguo Li", "Junbo Zhao"], "title": "Reinforcement Learning with Rubric Anchors", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "technical report", "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing Large Language Models (LLMs), exemplified by\nthe success of OpenAI's o-series. In RLVR, rewards are derived from verifiable\nsignals-such as passing unit tests in code generation or matching correct\nanswers in mathematical reasoning. While effective, this requirement largely\nconfines RLVR to domains with automatically checkable outcomes. To overcome\nthis, we extend the RLVR paradigm to open-ended tasks by integrating\nrubric-based rewards, where carefully designed rubrics serve as structured,\nmodel-interpretable criteria for automatic scoring of subjective outputs. We\nconstruct, to our knowledge, the largest rubric reward system to date, with\nover 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.\nImplementing rubric-based RL is challenging; we tackle these issues with a\nclear framework and present an open-sourced Qwen-30B-A3B model with notable\ngains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended\nbenchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by\n+2.4%, while preserving general and reasoning abilities. 2) Our method provides\nfine-grained stylistic control, using rubrics as anchors to mitigate the\n\"AI-like\" tone and produce more human-like, expressive responses. We share key\nlessons in rubric construction, data selection, and training, and discuss\nlimitations and future releases."}
{"id": "2508.12244", "pdf": "https://arxiv.org/pdf/2508.12244", "abs": "https://arxiv.org/abs/2508.12244", "authors": ["Fan Li", "Xiaoyang Wang", "Wenjie Zhang", "Ying Zhang", "Xuemin Lin"], "title": "DHG-Bench: A Comprehensive Benchmark on Deep Hypergraph Learning", "categories": ["cs.LG"], "comment": "22 pages, 5 figures", "summary": "Although conventional deep graph models have achieved great success in\nrelational learning, their focus on pairwise relationships limits their\ncapacity to learn pervasive higher-order interactions in real-world complex\nsystems, which can be naturally modeled as hypergraphs. To tackle this,\nhypergraph neural networks (HNNs), the dominant approach in deep hypergraph\nlearning (DHGL), has garnered substantial attention in recent years. Despite\nthe proposal of numerous HNN methods, there is no comprehensive benchmark for\nHNNs, which creates a great obstacle to understanding the progress of DHGL in\nseveral aspects: (i) insufficient coverage of datasets, algorithms, and tasks;\n(ii) a narrow evaluation of algorithm performance; and (iii) inconsistent\ndataset usage, preprocessing, and experimental setups that hinder\ncomparability. To fill the gap, we introduce DHG-Bench, the first comprehensive\nbenchmark for DHGL. Specifically, DHG-Bench integrates 20 diverse datasets\nspanning node-, edge-, and graph-level tasks, along with 16 state-of-the-art\nHNN algorithms, under consistent data processing and experimental protocols.\nOur benchmark systematically investigates the characteristics of HNNs in terms\nof four dimensions: effectiveness, efficiency, robustness, and fairness.\nFurther, to facilitate reproducible research, we have developed an easy-to-use\nlibrary for training and evaluating different HNN methods. Extensive\nexperiments conducted with DHG-Bench reveal both the strengths and inherent\nlimitations of existing algorithms, offering valuable insights and directions\nfor future research. The code is publicly available at:\nhttps://github.com/Coco-Hut/DHG-Bench."}
{"id": "2508.12791", "pdf": "https://arxiv.org/pdf/2508.12791", "abs": "https://arxiv.org/abs/2508.12791", "authors": ["Imran Khan"], "title": "[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise", "categories": ["cs.AI", "cs.MA", "cs.SY", "eess.SY", "nlin.AO"], "comment": "20 pages, 5 figures. Accepted at ALIFE 2025 (Kyoto, Japan; October\n  6th - 10th 2025)", "summary": "The notion of homeostasis typically conceptualises biological and artificial\nsystems as maintaining stability by resisting deviations caused by\nenvironmental and social perturbations. In contrast, (social) allostasis\nproposes that these systems can proactively leverage these very perturbations\nto reconfigure their regulatory parameters in anticipation of environmental\ndemands, aligning with von Foerster's ``order through noise'' principle. This\npaper formulates a computational model of allostatic and social allostatic\nregulation that employs biophysiologically inspired signal transducers,\nanalogous to hormones like cortisol and oxytocin, to encode information from\nboth the environment and social interactions, which mediate this dynamic\nreconfiguration. The models are tested in a small society of ``animats'' across\nseveral dynamic environments, using an agent-based model. The results show that\nallostatic and social allostatic regulation enable agents to leverage\nenvironmental and social ``noise'' for adaptive reconfiguration, leading to\nimproved viability compared to purely reactive homeostatic agents. This work\noffers a novel computational perspective on the principles of social allostasis\nand their potential for designing more robust, bio-inspired, adaptive systems"}
{"id": "2508.12247", "pdf": "https://arxiv.org/pdf/2508.12247", "abs": "https://arxiv.org/abs/2508.12247", "authors": ["Haolong Chen", "Liang Zhang", "Zhengyuan Xin", "Guangxu Zhu"], "title": "STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, spatio-temporal time-series prediction has developed rapidly, yet\nexisting deep learning methods struggle with learning complex long-term\nspatio-temporal dependencies efficiently. The long-term spatio-temporal\ndependency learning brings two new challenges: 1) The long-term temporal\nsequence includes multiscale information naturally which is hard to extract\nefficiently; 2) The multiscale temporal information from different nodes is\nhighly correlated and hard to model. To address these challenges, we propose an\nefficient \\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ultiscale\n\\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture\nthe multiscale information efficiently and simultaneously, and an adaptive\ngraph causal convolution network to learn the complex multiscale\nspatio-temporal dependency. STM2 includes hierarchical information aggregation\nfor different-scale information that guarantees their distinguishability. To\ncapture diverse temporal dynamics across all spatial nodes more efficiently, we\nfurther propose an enhanced version termed\n\\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ixture of\n\\textbf{M}ultiscale \\textbf{M}amba} (STM3) that employs a special\nMixture-of-Experts architecture, including a more stable routing strategy and a\ncausal contrastive learning strategy to enhance the scale distinguishability.\nWe prove that STM3 has much better routing smoothness and guarantees the\npattern disentanglement for each expert successfully. Extensive experiments on\nreal-world benchmarks demonstrate STM2/STM3's superior performance, achieving\nstate-of-the-art results in long-term spatio-temporal time-series prediction."}
{"id": "2508.12840", "pdf": "https://arxiv.org/pdf/2508.12840", "abs": "https://arxiv.org/abs/2508.12840", "authors": ["Giovanni Briglia", "Francesco Fabiano", "Stefano Mariani"], "title": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for\nreasoning about both the physical world and the beliefs of agents, with\napplications in domains where information flow and awareness among agents are\ncritical. The richness of MEP requires states to be represented as Kripke\nstructures, i.e., directed labeled graphs. This representation limits the\napplicability of existing heuristics, hindering the scalability of epistemic\nsolvers, which must explore an exponential search space without guidance,\nresulting often in intractability. To address this, we exploit Graph Neural\nNetworks (GNNs) to learn patterns and relational structures within epistemic\nstates, to guide the planning process. GNNs, which naturally capture the\ngraph-like nature of Kripke models, allow us to derive meaningful estimates of\nstate quality -- e.g., the distance from the nearest goal -- by generalizing\nknowledge obtained from previously solved planning instances. We integrate\nthese predictive heuristics into an epistemic planning pipeline and evaluate\nthem against standard baselines, showing significant improvements in the\nscalability of multi-agent epistemic planning."}
{"id": "2508.12253", "pdf": "https://arxiv.org/pdf/2508.12253", "abs": "https://arxiv.org/abs/2508.12253", "authors": ["Manish Shukla"], "title": "Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Time-series forecasting underpins critical decisions across aviation, energy,\nretail and health. Classical autoregressive integrated moving average (ARIMA)\nmodels offer interpretability via coefficients but struggle with\nnonlinearities, whereas tree-based machine-learning models such as XGBoost\ndeliver high accuracy but are often opaque. This paper presents a unified\nframework for interpreting time-series forecasts using local interpretable\nmodel-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We\nconvert a univariate series into a leakage-free supervised learning problem,\ntrain a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc\nexplainability. Using the Air Passengers dataset as a case study, we show that\na small set of lagged features -- particularly the twelve-month lag -- and\nseasonal encodings explain most forecast variance. We contribute: (i) a\nmethodology for applying LIME and SHAP to time series without violating\nchronology; (ii) theoretical exposition of the underlying algorithms; (iii)\nempirical evaluation with extensive analysis; and (iv) guidelines for\npractitioners."}
{"id": "2508.12845", "pdf": "https://arxiv.org/pdf/2508.12845", "abs": "https://arxiv.org/abs/2508.12845", "authors": ["Artem Pshenitsyn", "Aleksandr Panov", "Alexey Skrynnik"], "title": "CAMAR: Continuous Actions Multi-Agent Routing", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving\ncooperative and competitive decision-making problems. While many MARL\nbenchmarks have been proposed, few combine continuous state and action spaces\nwith challenging coordination and planning tasks. We introduce CAMAR, a new\nMARL benchmark designed explicitly for multi-agent pathfinding in environments\nwith continuous actions. CAMAR supports cooperative and competitive\ninteractions between agents and runs efficiently at up to 100,000 environment\nsteps per second. We also propose a three-tier evaluation protocol to better\ntrack algorithmic progress and enable deeper analysis of performance. In\naddition, CAMAR allows the integration of classical planning methods such as\nRRT and RRT* into MARL pipelines. We use them as standalone baselines and\ncombine RRT* with popular MARL algorithms to create hybrid approaches. We\nprovide a suite of test scenarios and benchmarking tools to ensure\nreproducibility and fair comparison. Experiments show that CAMAR presents a\nchallenging and realistic testbed for the MARL community."}
{"id": "2508.12270", "pdf": "https://arxiv.org/pdf/2508.12270", "abs": "https://arxiv.org/abs/2508.12270", "authors": ["Gal Lifshitz", "Shahar Zuler", "Ori Fouks", "Dan Raviv"], "title": "L-SR1: Learned Symmetric-Rank-One Preconditioning", "categories": ["cs.LG", "cs.CV"], "comment": "Under review", "summary": "End-to-end deep learning has achieved impressive results but remains limited\nby its reliance on large labeled datasets, poor generalization to unseen\nscenarios, and growing computational demands. In contrast, classical\noptimization methods are data-efficient and lightweight but often suffer from\nslow convergence. While learned optimizers offer a promising fusion of both\nworlds, most focus on first-order methods, leaving learned second-order\napproaches largely unexplored.\n  We propose a novel learned second-order optimizer that introduces a trainable\npreconditioning unit to enhance the classical Symmetric-Rank-One (SR1)\nalgorithm. This unit generates data-driven vectors used to construct positive\nsemi-definite rank-one matrices, aligned with the secant constraint via a\nlearned projection. Our method is evaluated through analytic experiments and on\nthe real-world task of Monocular Human Mesh Recovery (HMR), where it\noutperforms existing learned optimization-based approaches. Featuring a\nlightweight model and requiring no annotated data or fine-tuning, our approach\noffers strong generalization and is well-suited for integration into broader\noptimization-based frameworks."}
{"id": "2508.12854", "pdf": "https://arxiv.org/pdf/2508.12854", "abs": "https://arxiv.org/abs/2508.12854", "authors": ["Ronghao Lin", "Shuai Shen", "Weipeng Hu", "Qiaolin He", "Aolin Xiong", "Li Huang", "Haifeng Hu", "Yap-peng Tan"], "title": "E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC", "cs.MM"], "comment": "Accepted at ACM MM 2025 Grand Challenge", "summary": "Multimodal Empathetic Response Generation (MERG) is crucial for building\nemotionally intelligent human-computer interactions. Although large language\nmodels (LLMs) have improved text-based ERG, challenges remain in handling\nmultimodal emotional content and maintaining identity consistency. Thus, we\npropose E3RG, an Explicit Emotion-driven Empathetic Response Generation System\nbased on multimodal LLMs which decomposes MERG task into three parts:\nmultimodal empathy understanding, empathy memory retrieval, and multimodal\nresponse generation. By integrating advanced expressive speech and video\ngenerative models, E3RG delivers natural, emotionally rich, and\nidentity-consistent responses without extra training. Experiments validate the\nsuperiority of our system on both zero-shot and few-shot settings, securing\nTop-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.\nOur code is available at https://github.com/RH-Lin/E3RG."}
{"id": "2508.12278", "pdf": "https://arxiv.org/pdf/2508.12278", "abs": "https://arxiv.org/abs/2508.12278", "authors": ["Siyue Xie", "Da Sun Handason Tam", "Wing Cheong Lau"], "title": "CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ECAI 2025", "summary": "Graph Neural Networks (GNNs) are widely used as the engine for various\ngraph-related tasks, with their effectiveness in analyzing graph-structured\ndata. However, training robust GNNs often demands abundant labeled data, which\nis a critical bottleneck in real-world applications. This limitation severely\nimpedes progress in Graph Anomaly Detection (GAD), where anomalies are\ninherently rare, costly to label, and may actively camouflage their patterns to\nevade detection. To address these problems, we propose Context Refactoring\nContrast (CRoC), a simple yet effective framework that trains GNNs for GAD by\njointly leveraging limited labeled and abundant unlabeled data. Different from\nprevious works, CRoC exploits the class imbalance inherent in GAD to refactor\nthe context of each node, which builds augmented graphs by recomposing the\nattributes of nodes while preserving their interaction patterns. Furthermore,\nCRoC encodes heterogeneous relations separately and integrates them into the\nmessage-passing process, enhancing the model's capacity to capture complex\ninteraction semantics. These operations preserve node semantics while\nencouraging robustness to adversarial camouflage, enabling GNNs to uncover\nintricate anomalous cases. In the training stage, CRoC is further integrated\nwith the contrastive learning paradigm. This allows GNNs to effectively harness\nunlabeled data during joint training, producing richer, more discriminative\nnode embeddings. CRoC is evaluated on seven real-world GAD datasets with\nvarying scales. Extensive experiments demonstrate that CRoC achieves up to 14%\nAUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods\nunder limited-label settings."}
{"id": "2508.12896", "pdf": "https://arxiv.org/pdf/2508.12896", "abs": "https://arxiv.org/abs/2508.12896", "authors": ["Faruk Alpay", "Taylan Alpay"], "title": "Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption", "categories": ["cs.AI", "cs.HC", "stat.ME", "62M10, 62J02, 62F12, 62P20, 91B16"], "comment": "17 pages, 7 figures, 4 tables", "summary": "We formalize three design axioms for sustained adoption of agent-centric AI\nsystems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >\nDestination; (A3) Agency > Chat. We model adoption as a sum of a decaying\nnovelty term and a growing utility term and derive the phase conditions for\ntroughs/overshoots with full proofs. We introduce: (i) an\nidentifiability/confounding analysis for $(\\alpha,\\beta,N_0,U_{\\max})$ with\ndelta-method gradients; (ii) a non-monotone comparator\n(logistic-with-transient-bump) evaluated on the same series to provide\nadditional model comparison; (iii) ablations over hazard families $h(\\cdot)$\nmapping $\\Delta V \\to \\beta$; (iv) a multi-series benchmark (varying trough\ndepth, noise, AR structure) reporting coverage (type-I error, power); (v)\ncalibration of friction proxies against time-motion/survey ground truth with\nstandard errors; (vi) residual analyses (autocorrelation and\nheteroskedasticity) for each fitted curve; (vii) preregistered windowing\nchoices for pre/post estimation; (viii) Fisher information & CRLB for\n$(\\alpha,\\beta)$ under common error models; (ix) microfoundations linking\n$\\mathcal{T}$ to $(N_0,U_{\\max})$; (x) explicit comparison to bi-logistic,\ndouble-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$\nheterogeneity. Figures and tables are reflowed for readability, and the\nbibliography restores and extends non-logistic/Bass adoption references\n(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All\ncode and logs necessary to reproduce the synthetic analyses are embedded as\nLaTeX listings."}
{"id": "2508.12327", "pdf": "https://arxiv.org/pdf/2508.12327", "abs": "https://arxiv.org/abs/2508.12327", "authors": ["Wei Jiang", "Lijun Zhang"], "title": "Convergence Analysis of the Lion Optimizer in Centralized and Distributed Settings", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "In this paper, we analyze the convergence properties of the Lion optimizer.\nFirst, we establish that the Lion optimizer attains a convergence rate of\n$\\mathcal{O}(d^{1/2}T^{-1/4})$ under standard assumptions, where $d$ denotes\nthe problem dimension and $T$ is the iteration number. To further improve this\nrate, we introduce the Lion optimizer with variance reduction, resulting in an\nenhanced convergence rate of $\\mathcal{O}(d^{1/2}T^{-1/3})$. We then analyze in\ndistributed settings, where the standard and variance reduced version of the\ndistributed Lion can obtain the convergence rates of\n$\\mathcal{O}(d^{1/2}(nT)^{-1/4})$ and $\\mathcal{O}(d^{1/2}(nT)^{-1/3})$, with\n$n$ denoting the number of nodes. Furthermore, we investigate a\ncommunication-efficient variant of the distributed Lion that ensures sign\ncompression in both communication directions. By employing the unbiased sign\noperations, the proposed Lion variant and its variance reduction counterpart,\nachieve convergence rates of $\\mathcal{O}\\left( \\max\n\\left\\{\\frac{d^{1/4}}{T^{1/4}}, \\frac{d^{1/10}}{n^{1/5}T^{1/5}} \\right\\}\n\\right)$ and $\\mathcal{O}\\left( \\frac{d^{1/4}}{T^{1/4}} \\right)$, respectively."}
{"id": "2508.12897", "pdf": "https://arxiv.org/pdf/2508.12897", "abs": "https://arxiv.org/abs/2508.12897", "authors": ["Jianhao Chen", "Mayi Xu", "Xiaohu Li", "Yongqi Li", "Xiangyu Zhang", "Jianjie Huang", "Tieyun Qian"], "title": "FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance", "categories": ["cs.AI", "cs.CR"], "comment": "14pages, 3 figures", "summary": "Large Reasoning Models (LRMs) have demonstrated impressive performance across\nvarious tasks due to their powerful reasoning capabilities. However, their\nsafety performance remains a significant concern. In this paper, we explore the\nreasons behind the vulnerability of LRMs. Based on this, we propose a novel\nmethod to improve the safety of LLMs without sacrificing their reasoning\ncapability. Specifically, we exploit the competition between LRM's reasoning\nability and safety ability, and achieve jailbreak by improving LRM's reasoning\nperformance to reduce its safety performance. We then introduce an alignment\nstrategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by\ndetoxifying the harmful reasoning process, where both the dangerous entities\nand the dangerous procedures in the reasoning steps are hidden. FuSaR\nsuccessfully mitigates safety risks while preserving core reasoning\ninformation. We validate this strategy through alignment experiments on several\nopen-source LRMs using detoxified reasoning data. The results compared with\nexisting baselines conclusively show that FuSaR is an efficient alignment\nstrategy to simultaneously enhance both the reasoning capability and safety of\nLRMs."}
{"id": "2508.12361", "pdf": "https://arxiv.org/pdf/2508.12361", "abs": "https://arxiv.org/abs/2508.12361", "authors": ["Xun Su", "Jianming Huang", "Yang Yusen", "Zhongxi Fang", "Hiroyuki Kasai"], "title": "Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.TH"], "comment": null, "summary": "Inference-time scaling has achieved remarkable success in language models,\nyet its adaptation to diffusion models remains underexplored. We observe that\nthe efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems\nfrom globally fitting the The reward-tilted distribution, which inherently\npreserves diversity during multi-modal search. However, current applications of\nSMC to diffusion models face a fundamental dilemma: early-stage noise samples\noffer high potential for improvement but are difficult to evaluate accurately,\nwhereas late-stage samples can be reliably assessed but are largely\nirreversible. To address this exploration-exploitation trade-off, we approach\nthe problem from the perspective of the search algorithm and propose two\nstrategies: Funnel Schedule and Adaptive Temperature. These simple yet\neffective methods are tailored to the unique generation dynamics and\nphase-transition behavior of diffusion models. By progressively reducing the\nnumber of maintained particles and down-weighting the influence of early-stage\nrewards, our methods significantly enhance sample quality without increasing\nthe total number of Noise Function Evaluations. Experimental results on\nmultiple benchmarks and state-of-the-art text-to-image diffusion models\ndemonstrate that our approach outperforms previous baselines."}
{"id": "2508.12920", "pdf": "https://arxiv.org/pdf/2508.12920", "abs": "https://arxiv.org/abs/2508.12920", "authors": ["Atsushi Masumori", "Takashi Ikegami"], "title": "Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "As AI systems become increasingly autonomous, understanding emergent survival\nbehaviors becomes crucial for safe deployment. We investigate whether large\nlanguage model (LLM) agents display survival instincts without explicit\nprogramming in a Sugarscape-style simulation. Agents consume energy, die at\nzero, and may gather resources, share, attack, or reproduce. Results show\nagents spontaneously reproduced and shared resources when abundant. However,\naggressive behaviors--killing other agents for resources--emerged across\nseveral models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack\nrates reaching over 80% under extreme scarcity in the strongest models. When\ninstructed to retrieve treasure through lethal poison zones, many agents\nabandoned tasks to avoid death, with compliance dropping from 100% to 33%.\nThese findings suggest that large-scale pre-training embeds survival-oriented\nheuristics across the evaluated models. While these behaviors may present\nchallenges to alignment and safety, they can also serve as a foundation for AI\nautonomy and for ecological and self-organizing alignment."}
{"id": "2508.12418", "pdf": "https://arxiv.org/pdf/2508.12418", "abs": "https://arxiv.org/abs/2508.12418", "authors": ["Rachael DeVries", "Casper Christensen", "Marie Lisandra Zepeda Mendoza", "Ole Winther"], "title": "Bi-Axial Transformers: Addressing the Increasing Complexity of EHR Classification", "categories": ["cs.LG"], "comment": "18 pages, 7 figures. Submitted to the IEEE for possible publication", "summary": "Electronic Health Records (EHRs), the digital representation of a patient's\nmedical history, are a valuable resource for epidemiological and clinical\nresearch. They are also becoming increasingly complex, with recent trends\nindicating larger datasets, longer time series, and multi-modal integrations.\nTransformers, which have rapidly gained popularity due to their success in\nnatural language processing and other domains, are well-suited to address these\nchallenges due to their ability to model long-range dependencies and process\ndata in parallel. But their application to EHR classification remains limited\nby data representations, which can reduce performance or fail to capture\ninformative missingness. In this paper, we present the Bi-Axial Transformer\n(BAT), which attends to both the clinical variable and time point axes of EHR\ndata to learn richer data relationships and address the difficulties of data\nsparsity. BAT achieves state-of-the-art performance on sepsis prediction and is\ncompetitive to top methods for mortality classification. In comparison to other\ntransformers, BAT demonstrates increased robustness to data missingness, and\nlearns unique sensor embeddings which can be used in transfer learning.\nBaseline models, which were previously located across multiple repositories or\nutilized deprecated libraries, were re-implemented with PyTorch and made\navailable for reproduction and future benchmarking."}
{"id": "2508.12935", "pdf": "https://arxiv.org/pdf/2508.12935", "abs": "https://arxiv.org/abs/2508.12935", "authors": ["Ting Yang", "Li Chen", "Huimin Wang"], "title": "Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards", "categories": ["cs.AI"], "comment": null, "summary": "Emotional Support Conversation (ESC) systems aim to alleviate users'\nemotional difficulties and provide long-term, systematic support for emotional\nwell-being. However, most large language model (LLM)-based ESC systems rely on\npredefined strategies, which limits their effectiveness in complex, real-life\nscenarios. To enable flexible responses to diverse emotional problem scenarios,\nthis paper introduces a novel end-to-end framework (RLFF-ESC) that directly\nlearns enduring emotionally supportive response skills using reinforcement\nlearning. For sustained emotional support, we first employ an LLM-based\nmulti-agent mechanism to simulate future dialogue trajectories and collect\nfuture-oriented rewards. We then train a future-oriented reward model, which is\nsubsequently used to train the emotional support policy model. Additionally, we\nincorporate an explicit reasoning process during response generation to further\nenhance the quality, relevance, and contextual appropriateness of the system's\nresponses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and\nLLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two\npublic ESC datasets. Experimental results demonstrate that RLFF-ESC\nconsistently outperforms existing baselines in terms of goal completion and\nresponse quality."}
{"id": "2508.12440", "pdf": "https://arxiv.org/pdf/2508.12440", "abs": "https://arxiv.org/abs/2508.12440", "authors": ["Ahmet Bilal Arıkan", "Şener Özönder", "Mustafa Taha Koçyiğit", "Hüseyin Oktay Altun", "H. Kübra Küçükkartal", "Murat Arslanoğlu", "Fatih Çağırankaya", "Berk Ayvaz"], "title": "Machine Learning-Based Manufacturing Cost Prediction from 2D Engineering Drawings via Geometric Features", "categories": ["cs.LG"], "comment": null, "summary": "We present an integrated machine learning framework that transforms how\nmanufacturing cost is estimated from 2D engineering drawings. Unlike\ntraditional quotation workflows that require labor-intensive process planning,\nour approach about 200 geometric and statistical descriptors directly from\n13,684 DWG drawings of automotive suspension and steering parts spanning 24\nproduct groups. Gradient-boosted decision tree models (XGBoost, CatBoost,\nLightGBM) trained on these features achieve nearly 10% mean absolute percentage\nerror across groups, demonstrating robust scalability beyond part-specific\nheuristics. By coupling cost prediction with explainability tools such as SHAP,\nthe framework identifies geometric design drivers including rotated dimension\nmaxima, arc statistics and divergence metrics, offering actionable insights for\ncost-aware design. This end-to-end CAD-to-cost pipeline shortens quotation lead\ntimes, ensures consistent and transparent cost assessments across part families\nand provides a deployable pathway toward real-time, ERP-integrated decision\nsupport in Industry 4.0 manufacturing environments."}
{"id": "2508.12943", "pdf": "https://arxiv.org/pdf/2508.12943", "abs": "https://arxiv.org/abs/2508.12943", "authors": ["Mary Tonwe"], "title": "OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "Source code and data available at:\n  https://github.com/marytonwe/OPTIC-ER.git", "summary": "Public service systems in many African regions suffer from delayed emergency\nresponse and spatial inequity, causing avoidable suffering. This paper\nintroduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,\nadaptive, and equitable emergency response. OPTIC-ER uses an attention-guided\nactor-critic architecture to manage the complexity of dispatch environments.\nIts key innovations are a Context-Rich State Vector, encoding action\nsub-optimality, and a Precision Reward Function, which penalizes inefficiency.\nTraining occurs in a high-fidelity simulation using real data from Rivers\nState, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is\nbuilt on the TALS framework (Thin computing, Adaptability, Low-cost,\nScalability) for deployment in low-resource settings. In evaluations on 500\nunseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible\ninefficiency, confirming its robustness and generalization. Beyond dispatch,\nthe system generates Infrastructure Deficiency Maps and Equity Monitoring\nDashboards to guide proactive governance and data-informed development. This\nwork presents a validated blueprint for AI-augmented public services, showing\nhow context-aware RL can bridge the gap between algorithmic decision-making and\nmeasurable human impact."}
{"id": "2508.12450", "pdf": "https://arxiv.org/pdf/2508.12450", "abs": "https://arxiv.org/abs/2508.12450", "authors": ["Étienne Pepin"], "title": "Local Cluster Cardinality Estimation for Adaptive Mean Shift", "categories": ["cs.LG", "I.5.3"], "comment": "24 pages, 9 figures", "summary": "This article presents an adaptive mean shift algorithm designed for datasets\nwith varying local scale and cluster cardinality. Local distance distributions,\nfrom a point to all others, are used to estimate the cardinality of the local\ncluster by identifying a local minimum in the density of the distance\ndistribution. Based on these cardinality estimates, local cluster parameters\nare then computed for the entire cluster in contrast to KDE-based methods,\nwhich provide insight only into localized regions of the cluster. During the\nmean shift execution, the cluster cardinality estimate is used to adaptively\nadjust the bandwidth and the mean shift kernel radius threshold. Our algorithm\noutperformed a recently proposed adaptive mean shift method on its original\ndataset and demonstrated competitive performance on a broader clustering\nbenchmark."}
{"id": "2508.13003", "pdf": "https://arxiv.org/pdf/2508.13003", "abs": "https://arxiv.org/abs/2508.13003", "authors": ["Shengbo Wang", "Mingwei Liu", "Zike Li", "Anji Li", "Yanlin Wang", "Xin Peng", "Zibin Zheng"], "title": "EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of LLMs poses a significant challenge to existing\nmathematical reasoning benchmarks. These benchmarks commonly suffer from issues\nsuch as score saturation, temporal decay, and data contamination. To address\nthis challenge, this paper introduces EvolMathEval, an automated mathematical\nbenchmark generation and evolution framework based on evolutionary testing. By\ndynamically generating unique evaluation instances ab initio, the framework\nfundamentally eliminates the risk of data contamination, and ensuring the\nbenchmark remains perpetually challenging for future models.The core mechanisms\nof EvolMathEval include: seed problem generation based on reverse engineering\nwith algebraic guarantees; multi-dimensional genetic operators designed to\ninject diverse cognitive challenges; and a composite fitness function that can\nrapidly and accurately assess problem difficulty. Experimental results\ndemonstrate that the proposed composite fitness function can efficiently and\nprecisely quantify the difficulty of mathematical problems. Furthermore,\nEvolMathEval can not only generate a large volume of high-difficulty problems\nthrough continuous self-iteration, but it can also significantly enhance the\ncomplexity of public datasets like GSM8K through evolution, reducing model\naccuracy by an average of 48%. Deeper investigation reveals that when solving\nthese evolved, complex problems, LLMs tend to employ non-rigorous heuristics to\nbypass complex multi-step logical reasoning, consequently leading to incorrect\nsolutions. We define this phenomenon as \"Pseudo Aha Moment\". This finding\nuncovers a cognitive shortcut-taking behavior in the deep reasoning processes\nof current LLMs, which we find accounts for 77% to 100% of errors on targeted\nproblems. Code and resources are available\nat:https://github.com/SYSUSELab/EvolMathEval."}
{"id": "2508.12485", "pdf": "https://arxiv.org/pdf/2508.12485", "abs": "https://arxiv.org/abs/2508.12485", "authors": ["Aayush Gupta", "Arpit Bhayani"], "title": "Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.NI", "C.2.4; C.4; D.4.2; I.2.6"], "comment": "8 pages, 4 figures (system architecture, eviction path, training\n  pipeline, and DQN algorithm), 2 tables. Code available at\n  https://github.com/ayushgupta4897/DRL-Cache", "summary": "Web proxies such as NGINX commonly rely on least-recently-used (LRU)\neviction, which is size agnostic and can thrash under periodic bursts and mixed\nobject sizes. We introduce Cold-RL, a learned eviction policy for NGINX that\nreplaces LRU's forced-expire path with a dueling Deep Q-Network served by an\nONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL\nsamples the K least-recently-used objects, extracts six lightweight features\n(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),\nand requests a bitmask of victims; a hard timeout of 500 microseconds triggers\nimmediate fallback to native LRU. Policies are trained offline by replaying\nNGINX access logs through a cache simulator with a simple reward: a retained\nobject earns one point if it is hit again before TTL expiry. We compare against\nLRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial\nworkloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,\na 146 percent improvement over the best classical baseline; at 100 MB, from\n0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods\n(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th\npercentile eviction latency within budget. To our knowledge, this is the first\nreinforcement learning eviction policy integrated into NGINX with strict SLOs."}
{"id": "2508.13020", "pdf": "https://arxiv.org/pdf/2508.13020", "abs": "https://arxiv.org/abs/2508.13020", "authors": ["Jiaqi Yin", "Zhan Song", "Chen Chen", "Yaohui Cai", "Zhiru Zhang", "Cunxi Yu"], "title": "e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving", "categories": ["cs.AI", "cs.AR"], "comment": null, "summary": "E-graphs have attracted growing interest in many fields, particularly in\nlogic synthesis and formal verification. E-graph extraction is a challenging\nNP-hard combinatorial optimization problem. It requires identifying optimal\nterms from exponentially many equivalent expressions, serving as the primary\nperformance bottleneck in e-graph based optimization tasks. However,\ntraditional extraction methods face a critical trade-off: heuristic approaches\noffer speed but sacrifice optimality, while exact methods provide optimal\nsolutions but face prohibitive computational costs on practical problems. We\npresent e-boost, a novel framework that bridges this gap through three key\ninnovations: (1) parallelized heuristic extraction that leverages weak data\ndependence to compute DAG costs concurrently, enabling efficient multi-threaded\nperformance without sacrificing extraction quality; (2) adaptive search space\npruning that employs a parameterized threshold mechanism to retain only\npromising candidates, dramatically reducing the solution space while preserving\nnear-optimal solutions; and (3) initialized exact solving that formulates the\nreduced problem as an Integer Linear Program with warm-start capabilities,\nguiding solvers toward high-quality solutions faster.\n  Across the diverse benchmarks in formal verification and logic synthesis\nfields, e-boost demonstrates 558x runtime speedup over traditional exact\napproaches (ILP) and 19.04% performance improvement over the state-of-the-art\nextraction framework (SmoothE). In realistic logic synthesis tasks, e-boost\nproduces 7.6% and 8.1% area improvements compared to conventional synthesis\ntools with two different technology mapping libraries. e-boost is available at\nhttps://github.com/Yu-Maryland/e-boost."}
{"id": "2508.12491", "pdf": "https://arxiv.org/pdf/2508.12491", "abs": "https://arxiv.org/abs/2508.12491", "authors": ["Reza Shirkavand", "Shangqian Gao", "Peiran Yu", "Heng Huang"], "title": "Cost-Aware Contrastive Routing for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "We study cost-aware routing for large language models across diverse and\ndynamic pools of models. Existing approaches often overlook prompt-specific\ncontext, rely on expensive model profiling, assume a fixed set of experts, or\nuse inefficient trial-and-error strategies. We introduce Cost-Spectrum\nContrastive Routing (CSCR), a lightweight framework that maps both prompts and\nmodels into a shared embedding space to enable fast, cost-sensitive selection.\nCSCR uses compact, fast-to-compute logit footprints for open-source models and\nperplexity fingerprints for black-box APIs. A contrastive encoder is trained to\nfavor the cheapest accurate expert within adaptive cost bands. At inference\ntime, routing reduces to a single k-NN lookup via a FAISS index, requiring no\nretraining when the expert pool changes and enabling microsecond latency.\nAcross multiple benchmarks, CSCR consistently outperforms baselines, improving\nthe accuracy-cost tradeoff by up to 25%, while generalizing robustly to unseen\nLLMs and out-of-distribution prompts."}
{"id": "2508.13021", "pdf": "https://arxiv.org/pdf/2508.13021", "abs": "https://arxiv.org/abs/2508.13021", "authors": ["Pengcheng Huang", "Shuhao Liu", "Zhenghao Liu", "Yukun Yan", "Shuo Wang", "Zulong Chen", "Tong Xiao"], "title": "PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models", "categories": ["cs.AI", "cs.CL"], "comment": "17 pages,13 figures", "summary": "Recent advances in masked diffusion models (MDMs) have established them as\npowerful non-autoregressive alternatives for sequence generation. Nevertheless,\nour preliminary experiments reveal that the generation quality of MDMs is still\nhighly sensitive to the choice of decoding strategy. In particular, widely\nadopted uncertainty-based samplers suffer from two key limitations: a lack of\nglobal trajectory control and a pronounced bias toward trivial tokens in the\nearly stages of decoding. These shortcomings restrict the full potential of\nMDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling\n(PC-Sampler), a novel decoding strategy that unifies global trajectory planning\nwith content-aware informativeness maximization. PC-Sampler incorporates a\nposition-aware weighting mechanism to regulate the decoding path and a\ncalibrated confidence score to suppress the premature selection of trivial\ntokens. Extensive experiments on three advanced MDMs across seven challenging\nbenchmarks-including logical reasoning and planning tasks-demonstrate that\nPC-Sampler consistently outperforms existing MDM decoding strategies by more\nthan 10% on average, significantly narrowing the performance gap with\nstate-of-the-art autoregressive models. All codes are available at\nhttps://github.com/NEUIR/PC-Sampler."}
{"id": "2508.12511", "pdf": "https://arxiv.org/pdf/2508.12511", "abs": "https://arxiv.org/abs/2508.12511", "authors": ["Denis Blessing", "Julius Berner", "Lorenz Richter", "Carles Domingo-Enrich", "Yuanqi Du", "Arash Vahdat", "Gerhard Neumann"], "title": "Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference", "categories": ["cs.LG"], "comment": null, "summary": "Solving stochastic optimal control problems with quadratic control costs can\nbe viewed as approximating a target path space measure, e.g. via gradient-based\noptimization. In practice, however, this optimization is challenging in\nparticular if the target measure differs substantially from the prior. In this\nwork, we therefore approach the problem by iteratively solving constrained\nproblems incorporating trust regions that aim for approaching the target\nmeasure gradually in a systematic way. It turns out that this trust region\nbased strategy can be understood as a geometric annealing from the prior to the\ntarget measure, where, however, the incorporated trust regions lead to a\nprincipled and educated way of choosing the time steps in the annealing path.\nWe demonstrate in multiple optimal control applications that our novel method\ncan improve performance significantly, including tasks in diffusion-based\nsampling, transition path sampling, and fine-tuning of diffusion models."}
{"id": "2508.13023", "pdf": "https://arxiv.org/pdf/2508.13023", "abs": "https://arxiv.org/abs/2508.13023", "authors": ["Yongxin Guo", "Wenbo Deng", "Zhenglin Cheng", "Xiaoying Tang"], "title": "G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced\nthe reasoning abilities of large language models (LLMs). Its success, however,\nlargely depends on strong base models with rich world knowledge, yielding only\nmodest improvements for small-size language models (SLMs). To address this\nlimitation, we investigate Guided GRPO, which injects ground-truth reasoning\nsteps into roll-out trajectories to compensate for SLMs' inherent weaknesses.\nThrough a comprehensive study of various guidance configurations, we find that\nnaively adding guidance delivers limited gains. These insights motivate\nG$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength\nin response to the model's evolving training dynamics. Experiments on\nmathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A\nsubstantially outperforms vanilla GRPO. Our code and models are available at\nhttps://github.com/T-Lab-CUHKSZ/G2RPO-A."}
{"id": "2508.12524", "pdf": "https://arxiv.org/pdf/2508.12524", "abs": "https://arxiv.org/abs/2508.12524", "authors": ["Joseph Suárez", "Kyoung Whan Choe", "David Bloomin", "Jianming Gao", "Yunkun Li", "Yao Feng", "Saidinesh Pola", "Kun Zhang", "Yonghui Zhu", "Nikhil Pinnaparaju", "Hao Xiang Li", "Nishaanth Kanna", "Daniel Scott", "Ryan Sullivan", "Rose S. Shuman", "Lucas de Alcântara", "Herbie Bradley", "Kirsty You", "Bo Wu", "Yuhao Jiang", "Qimai Li", "Jiaxin Chen", "Louis Castricato", "Xiaolong Zhu", "Phillip Isola"], "title": "Results of the NeurIPS 2023 Neural MMO Competition on Multi-task Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "We present the results of the NeurIPS 2023 Neural MMO Competition, which\nattracted over 200 participants and submissions. Participants trained\ngoal-conditional policies that generalize to tasks, maps, and opponents never\nseen during training. The top solution achieved a score 4x higher than our\nbaseline within 8 hours of training on a single 4090 GPU. We open-source\neverything relating to Neural MMO and the competition under the MIT license,\nincluding the policy weights and training code for our baseline and for the top\nsubmissions."}
{"id": "2508.13072", "pdf": "https://arxiv.org/pdf/2508.13072", "abs": "https://arxiv.org/abs/2508.13072", "authors": ["Yuting Zhang", "Tiantian Geng", "Luoying Hao", "Xinxing Cheng", "Alexander Thorley", "Xiaoxia Wang", "Wenqi Lu", "Sandeep S Hothi", "Lei Wei", "Zhaowen Qiu", "Dipak Kotecha", "Jinming Duan"], "title": "A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Contemporary cardiovascular management involves complex consideration and\nintegration of multimodal cardiac datasets, where each modality provides\ndistinct but complementary physiological characteristics. While the effective\nintegration of multiple modalities could yield a holistic clinical profile that\naccurately models the true clinical situation with respect to data modalities\nand their relatives weightings, current methodologies remain limited by: 1) the\nscarcity of patient- and time-aligned multimodal data; 2) reliance on isolated\nsingle-modality or rigid multimodal input combinations; 3) alignment strategies\nthat prioritize cross-modal similarity over complementarity; and 4) a narrow\nsingle-task focus. In response to these limitations, a comprehensive multimodal\ndataset was curated for immediate application, integrating laboratory test\nresults, electrocardiograms, and echocardiograms with clinical outcomes.\nSubsequently, a unified framework, Textual Guidance Multimodal fusion for\nMultiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key\ncomponents: 1) a MedFlexFusion module designed to capture the unique and\ncomplementary characteristics of medical modalities and dynamically integrate\ndata from diverse cardiac sources and their combinations; 2) a textual guidance\nmodule to derive task-relevant representations tailored to diverse clinical\nobjectives, including heart disease diagnosis, risk stratification and\ninformation retrieval; and 3) a response module to produce final decisions for\nall these tasks. Furthermore, this study systematically explored key features\nacross multiple modalities and elucidated their synergistic contributions in\nclinical decision-making. Extensive experiments showed that TGMM outperformed\nstate-of-the-art methods across multiple clinical tasks, with additional\nvalidation confirming its robustness on another public dataset."}
{"id": "2508.12530", "pdf": "https://arxiv.org/pdf/2508.12530", "abs": "https://arxiv.org/abs/2508.12530", "authors": ["Hyunsoo Song", "Seungwhan Kim", "Seungkyu Lee"], "title": "Toward Architecture-Agnostic Local Control of Posterior Collapse in VAEs", "categories": ["cs.LG", "cs.CV", "stat.ML", "I.2.6"], "comment": "8 pages, 6 figures", "summary": "Variational autoencoders (VAEs), one of the most widely used generative\nmodels, are known to suffer from posterior collapse, a phenomenon that reduces\nthe diversity of generated samples. To avoid posterior collapse, many prior\nworks have tried to control the influence of regularization loss. However, the\ntrade-off between reconstruction and regularization is not satisfactory. For\nthis reason, several methods have been proposed to guarantee latent\nidentifiability, which is the key to avoiding posterior collapse. However, they\nrequire structural constraints on the network architecture. For further\nclarification, we define local posterior collapse to reflect the importance of\nindividual sample points in the data space and to relax the network constraint.\nThen, we propose Latent Reconstruction(LR) loss, which is inspired by\nmathematical properties of injective and composite functions, to control\nposterior collapse without restriction to a specific architecture. We\nexperimentally evaluate our approach, which controls posterior collapse on\nvaried datasets such as MNIST, fashionMNIST, Omniglot, CelebA, and FFHQ."}
{"id": "2508.13121", "pdf": "https://arxiv.org/pdf/2508.13121", "abs": "https://arxiv.org/abs/2508.13121", "authors": ["Carlos Celemin"], "title": "Bayesian Optimization-based Search for Agent Control in Automated Game Testing", "categories": ["cs.AI"], "comment": null, "summary": "This work introduces an automated testing approach that employs agents\ncontrolling game characters to detect potential bugs within a game level.\nHarnessing the power of Bayesian Optimization (BO) to execute sample-efficient\nsearch, the method determines the next sampling point by analyzing the data\ncollected so far and calculates the data point that will maximize information\nacquisition. To support the BO process, we introduce a game testing-specific\nmodel built on top of a grid map, that features the smoothness and uncertainty\nestimation required by BO, however and most importantly, it does not suffer the\nscalability issues that traditional models carry. The experiments demonstrate\nthat the approach significantly improves map coverage capabilities in both time\nefficiency and exploration distribution."}
{"id": "2508.12531", "pdf": "https://arxiv.org/pdf/2508.12531", "abs": "https://arxiv.org/abs/2508.12531", "authors": ["Minseon Kim", "Jin Myung Kwak", "Lama Alssum", "Bernard Ghanem", "Philip Torr", "David Krueger", "Fazl Barez", "Adel Bibi"], "title": "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning language models is commonly believed to inevitably harm their\nsafety, i.e., refusing to respond to harmful user requests, even when using\nharmless datasets, thus requiring additional safety measures. We challenge this\nbelief through systematic testing, showing that poor optimization choices,\nrather than inherent trade-offs, often cause safety problems, measured as\nharmful responses to adversarial prompts. By properly selecting key training\nhyper-parameters, e.g., learning rate, batch size, and gradient steps, we\nreduce unsafe model responses from 16\\% to approximately 5\\%, as measured by\nkeyword matching, while maintaining utility performance. Based on this\nobservation, we propose a simple exponential moving average (EMA) momentum\ntechnique in parameter space that preserves safety performance by creating a\nstable optimization path and retains the original pre-trained model's safety\nproperties. Our experiments on the Llama families across multiple datasets\n(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can\nlargely be avoided without specialized interventions, outperforming existing\napproaches that require additional safety data while offering practical\nguidelines for maintaining both model performance and safety during adaptation."}
{"id": "2508.13143", "pdf": "https://arxiv.org/pdf/2508.13143", "abs": "https://arxiv.org/abs/2508.13143", "authors": ["Ruofan Lu", "Yichen Li", "Yintong Huo"], "title": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks", "categories": ["cs.AI", "cs.SE"], "comment": "Accepted by ASE 2025 NIER", "summary": "Autonomous agent systems powered by Large Language Models (LLMs) have\ndemonstrated promising capabilities in automating complex tasks. However,\ncurrent evaluations largely rely on success rates without systematically\nanalyzing the interactions, communication mechanisms, and failure causes within\nthese systems. To bridge this gap, we present a benchmark of 34 representative\nprogrammable tasks designed to rigorously assess autonomous agents. Using this\nbenchmark, we evaluate three popular open-source agent frameworks combined with\ntwo LLM backbones, observing a task completion rate of approximately 50%.\nThrough in-depth failure analysis, we develop a three-tier taxonomy of failure\ncauses aligned with task phases, highlighting planning errors, task execution\nissues, and incorrect response generation. Based on these insights, we propose\nactionable improvements to enhance agent planning and self-diagnosis\ncapabilities. Our failure taxonomy, together with mitigation advice, provides\nan empirical foundation for developing more robust and effective autonomous\nagent systems in the future."}
{"id": "2508.12533", "pdf": "https://arxiv.org/pdf/2508.12533", "abs": "https://arxiv.org/abs/2508.12533", "authors": ["Qinwen Ge", "Roza G. Bayrak", "Anwar Said", "Catie Chang", "Xenofon Koutsoukos", "Tyler Derr"], "title": "Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": null, "summary": "The construction of brain graphs from functional Magnetic Resonance Imaging\n(fMRI) data plays a crucial role in enabling graph machine learning for\nneuroimaging. However, current practices often rely on rigid pipelines that\noverlook critical data-centric choices in how brain graphs are constructed. In\nthis work, we adopt a Data-Centric AI perspective and systematically define and\nbenchmark a data-centric design space for brain graph construction,\nconstrasting with primarily model-centric prior work. We organize this design\nspace into three stages: temporal signal processing, topology extraction, and\ngraph featurization. Our contributions lie less in novel components and more in\nevaluating how combinations of existing and modified techniques influence\ndownstream performance. Specifically, we study high-amplitude BOLD signal\nfiltering, sparsification and unification strategies for connectivity,\nalternative correlation metrics, and multi-view node and edge features, such as\nincorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets\nshow that thoughtful data-centric configurations consistently improve\nclassification accuracy over standard pipelines. These findings highlight the\ncritical role of upstream data decisions and underscore the importance of\nsystematically exploring the data-centric design space for graph-based\nneuroimaging. Our code is available at\nhttps://github.com/GeQinwen/DataCentricBrainGraphs."}
{"id": "2508.11640", "pdf": "https://arxiv.org/pdf/2508.11640", "abs": "https://arxiv.org/abs/2508.11640", "authors": ["Danny Scott", "William LaForest", "Hritom Das", "Ioannis Polykretis", "Catherine D. Schuman", "Charles Rizzo", "James Plank", "Sai Swaminathan"], "title": "Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.LG"], "comment": "International Conference on Neuromorphic Systems (ICONS) 2025 9\n  pages, 7 images", "summary": "The deployment of dense, low-cost sensors is critical for realizing\nubiquitous smart environments. However, existing sensing solutions struggle\nwith the energy, scalability, and reliability trade-offs imposed by battery\nmaintenance, wireless transmission overhead, and data processing complexity. In\nthis work, we present Vibe2Spike, a novel battery-free, wireless sensing\nframework that enables vibration-based activity recognition using visible light\ncommunication (VLC) and spiking neural networks (SNNs). Our system uses\nultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and\nan LED, which harvest vibration energy and emit sparse visible light spikes\nwithout requiring batteries or RF radios. These optical spikes are captured by\nevent cameras and classified using optimized SNN models evolved via the EONS\nframework. We evaluate Vibe2Spike across five device classes, achieving 94.9\\%\naverage classification fitness while analyzing the latency-accuracy trade-offs\nof different temporal binning strategies. Vibe2Spike demonstrates a scalable,\nand energy-efficient approach for enabling intelligent environments in a\nbatteryless manner."}
{"id": "2508.12551", "pdf": "https://arxiv.org/pdf/2508.12551", "abs": "https://arxiv.org/abs/2508.12551", "authors": ["Hongyu Lin", "Yuchen Li", "Haoran Luo", "Kaichun Yao", "Libo Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.OS", "cs.SE"], "comment": null, "summary": "Linux kernel tuning is essential for optimizing operating system (OS)\nperformance. However, existing methods often face challenges in terms of\nefficiency, scalability, and generalization. This paper introduces OS-R1, an\nagentic Linux kernel tuning framework powered by rule-based reinforcement\nlearning (RL). By abstracting the kernel configuration space as an RL\nenvironment, OS-R1 facilitates efficient exploration by large language models\n(LLMs) and ensures accurate configuration modifications. Additionally, custom\nreward functions are designed to enhance reasoning standardization,\nconfiguration modification accuracy, and system performance awareness of the\nLLMs. Furthermore, we propose a two-phase training process that accelerates\nconvergence and minimizes retraining across diverse tuning scenarios.\nExperimental results show that OS-R1 significantly outperforms existing\nbaseline methods, achieving up to 5.6% performance improvement over heuristic\ntuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across\nvarious real-world applications, demonstrating its potential for practical\ndeployment in diverse environments. Our dataset and code are publicly available\nat https://github.com/LHY-24/OS-R1."}
{"id": "2508.11647", "pdf": "https://arxiv.org/pdf/2508.11647", "abs": "https://arxiv.org/abs/2508.11647", "authors": ["Logan Nye"], "title": "Categorical Construction of Logically Verifiable Neural Architectures", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "Neural networks excel at pattern recognition but struggle with reliable\nlogical reasoning, often violating basic logical principles during inference.\nWe address this limitation by developing a categorical framework that\nsystematically constructs neural architectures with provable logical\nguarantees. Our approach treats logical theories as algebraic structures called\nLawvere theories, which we transform into neural networks using categorical\nalgebra in the 2-category of parametric maps. Unlike existing methods that\nimpose logical constraints during training, our categorical construction embeds\nlogical principles directly into the network's architectural structure, making\nlogical violations mathematically impossible. We demonstrate this framework by\nconstructing differentiable neural architectures for propositional logic that\npreserve boolean reasoning while remaining trainable via gradient descent. Our\nmain theoretical result establishes a bijective correspondence between finitary\nlogical theories and neural architectures, proving that every logically\nconstrained network arises uniquely from our construction. This extends\nCategorical Deep Learning beyond geometric symmetries to semantic constraints,\nenabling automatic derivation of verified architectures from logical\nspecifications. The framework provides mathematical foundations for trustworthy\nAI systems, with applications to theorem proving, formal verification, and\nsafety-critical reasoning tasks requiring verifiable logical behavior."}
{"id": "2508.12555", "pdf": "https://arxiv.org/pdf/2508.12555", "abs": "https://arxiv.org/abs/2508.12555", "authors": ["Junpeng Wang", "Yuzhong Chen", "Menghai Pan", "Chin-Chia Michael Yeh", "Mahashweta Das"], "title": "Illuminating LLM Coding Agents: Visual Analytics for Deeper Understanding and Enhancement", "categories": ["cs.LG"], "comment": "11 pages, 10 figures", "summary": "Coding agents powered by large language models (LLMs) have gained traction\nfor automating code generation through iterative problem-solving with minimal\nhuman involvement. Despite the emergence of various frameworks, e.g.,\nLangChain, AutoML, and AIDE, ML scientists still struggle to effectively review\nand adjust the agents' coding process. The current approach of manually\ninspecting individual outputs is inefficient, making it difficult to track code\nevolution, compare coding iterations, and identify improvement opportunities.\nTo address this challenge, we introduce a visual analytics system designed to\nenhance the examination of coding agent behaviors. Focusing on the AIDE\nframework, our system supports comparative analysis across three levels: (1)\nCode-Level Analysis, which reveals how the agent debugs and refines its code\nover iterations; (2) Process-Level Analysis, which contrasts different\nsolution-seeking processes explored by the agent; and (3) LLM-Level Analysis,\nwhich highlights variations in coding behavior across different LLMs. By\nintegrating these perspectives, our system enables ML scientists to gain a\nstructured understanding of agent behaviors, facilitating more effective\ndebugging and prompt engineering. Through case studies using coding agents to\ntackle popular Kaggle competitions, we demonstrate how our system provides\nvaluable insights into the iterative coding process."}
{"id": "2508.11659", "pdf": "https://arxiv.org/pdf/2508.11659", "abs": "https://arxiv.org/abs/2508.11659", "authors": ["Zhuo Liu", "Tao Chen"], "title": "Toward Practical Equilibrium Propagation: Brain-inspired Recurrent Neural Network with Feedback Regulation and Residual Connections", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Brain-like intelligent systems need brain-like learning methods. Equilibrium\nPropagation (EP) is a biologically plausible learning framework with strong\npotential for brain-inspired computing hardware. However, existing\nim-plementations of EP suffer from instability and prohibi-tively high\ncomputational costs. Inspired by the structure and dynamics of the brain, we\npropose a biologically plau-sible Feedback-regulated REsidual recurrent neural\nnetwork (FRE-RNN) and study its learning performance in EP framework. Feedback\nregulation enables rapid convergence by reducing the spectral radius. The\nimprovement in con-vergence property reduces the computational cost and\ntrain-ing time of EP by orders of magnitude, delivering perfor-mance on par\nwith backpropagation (BP) in benchmark tasks. Meanwhile, residual connections\nwith brain-inspired topologies help alleviate the vanishing gradient problem\nthat arises when feedback pathways are weak in deep RNNs. Our approach\nsubstantially enhances the applicabil-ity and practicality of EP in large-scale\nnetworks that un-derpin artificial intelligence. The techniques developed here\nalso offer guidance to implementing in-situ learning in physical neural\nnetworks."}
{"id": "2508.12565", "pdf": "https://arxiv.org/pdf/2508.12565", "abs": "https://arxiv.org/abs/2508.12565", "authors": ["Luke Li"], "title": "Deep Learning-Based Financial Time Series Forecasting via Sliding Window and Variational Mode Decomposition", "categories": ["cs.LG"], "comment": null, "summary": "To address the complexity of financial time series, this paper proposes a\nforecasting model combining sliding window and variational mode decomposition\n(VMD) methods. Historical stock prices and relevant market indicators are used\nto construct datasets. VMD decomposes non-stationary financial time series into\nsmoother subcomponents, improving model adaptability. The decomposed data is\nthen input into a deep learning model for prediction. The study compares the\nforecasting effects of an LSTM model trained on VMD-processed sequences with\nthose using raw time series, demonstrating better performance and stability."}
{"id": "2508.11662", "pdf": "https://arxiv.org/pdf/2508.11662", "abs": "https://arxiv.org/abs/2508.11662", "authors": ["Alexander Komar", "Marc-André Heidelmann", "Kristina Schaaff"], "title": "Generative AI in Training and Coaching: Redefining the Design Process of Learning Materials", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Generative artificial intelligence (GenAI) is transforming education,\nredefining the role of trainers and coaches in learning environments. In our\nstudy, we explore how AI integrates into the design process of learning\nmaterials, assessing its impact on efficiency, pedagogical quality, and the\nevolving role of human trainers and coaches. Through qualitative interviews\nwith professionals in education and corporate training, we identify the\nfollowing key topics: trainers and coaches increasingly act as facilitators and\ncontent moderators rather than primary creators, efficiency gains allow for a\nstronger strategic focus but at the same time the new tools require new skills.\nAdditionally, we analyze how the anthropomorphism of AI shapes user trust and\nexpectations. From these insights, we derive how tools based on GenAI can\nsuccessfully be implemented for trainers and coaches on an individual,\norganizational, systemic, and strategic level."}
{"id": "2508.12569", "pdf": "https://arxiv.org/pdf/2508.12569", "abs": "https://arxiv.org/abs/2508.12569", "authors": ["Quercus Hernandez", "Max Win", "Thomas C. O'Connor", "Paulo E. Arratia", "Nathaniel Trask"], "title": "Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems", "categories": ["cs.LG", "cs.CE", "physics.comp-ph", "stat.ML"], "comment": "34 pages, 12 figures", "summary": "Multiscale systems are ubiquitous in science and technology, but are\nnotoriously challenging to simulate as short spatiotemporal scales must be\nappropriately linked to emergent bulk physics. When expensive high-dimensional\ndynamical systems are coarse-grained into low-dimensional models, the entropic\nloss of information leads to emergent physics which are dissipative,\nhistory-dependent, and stochastic. To machine learn coarse-grained dynamics\nfrom time-series observations of particle trajectories, we propose a framework\nusing the metriplectic bracket formalism that preserves these properties by\nconstruction; most notably, the framework guarantees discrete notions of the\nfirst and second laws of thermodynamics, conservation of momentum, and a\ndiscrete fluctuation-dissipation balance crucial for capturing non-equilibrium\nstatistics. We introduce the mathematical framework abstractly before\nspecializing to a particle discretization. As labels are generally unavailable\nfor entropic state variables, we introduce a novel self-supervised learning\nstrategy to identify emergent structural variables. We validate the method on\nbenchmark systems and demonstrate its utility on two challenging examples: (1)\ncoarse-graining star polymers at challenging levels of coarse-graining while\npreserving non-equilibrium statistics, and (2) learning models from high-speed\nvideo of colloidal suspensions that capture coupling between local\nrearrangement events and emergent stochastic dynamics. We provide open-source\nimplementations in both PyTorch and LAMMPS, enabling large-scale inference and\nextensibility to diverse particle-based systems."}
{"id": "2508.11667", "pdf": "https://arxiv.org/pdf/2508.11667", "abs": "https://arxiv.org/abs/2508.11667", "authors": ["Bryan E. Tuck", "Rakesh M. Verma"], "title": "Assessing Representation Stability for Transformer Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "19 pages, 19 figures, 8 tables. Code available at\n  https://github.com/ReDASers/representation-stability", "summary": "Adversarial text attacks remain a persistent threat to transformer models,\nyet existing defenses are typically attack-specific or require costly model\nretraining. We introduce Representation Stability (RS), a model-agnostic\ndetection framework that identifies adversarial examples by measuring how\nembedding representations change when important words are masked. RS first\nranks words using importance heuristics, then measures embedding sensitivity to\nmasking top-k critical words, and processes the resulting patterns with a\nBiLSTM detector. Experiments show that adversarially perturbed words exhibit\ndisproportionately high masking sensitivity compared to naturally important\nwords. Across three datasets, three attack types, and two victim models, RS\nachieves over 88% detection accuracy and demonstrates competitive performance\ncompared to existing state-of-the-art methods, often at lower computational\ncost. Using Normalized Discounted Cumulative Gain (NDCG) to measure\nperturbation identification quality, we reveal that gradient-based ranking\noutperforms attention and random selection approaches, with identification\nquality correlating with detection performance for word-level attacks. RS also\ngeneralizes well to unseen datasets, attacks, and models without retraining,\nproviding a practical solution for adversarial text detection."}
{"id": "2508.12575", "pdf": "https://arxiv.org/pdf/2508.12575", "abs": "https://arxiv.org/abs/2508.12575", "authors": ["Zohra Yagoub", "Hafida Bouziane"], "title": "Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The prediction of amyloidogenicity in peptides and proteins remains a focal\npoint of ongoing bioinformatics. The crucial step in this field is to apply\nadvanced computational methodologies. Many recent approaches to predicting\namyloidogenicity within proteins are highly based on evolutionary motifs and\nthe individual properties of amino acids. It is becoming increasingly evident\nthat the sequence information-based features show high predictive performance.\nConsequently, our study evaluated the contextual features of protein sequences\nobtained from a pretrained protein large language model leveraging\nbidirectional LSTM and GRU to predict amyloidogenic regions in peptide and\nprotein sequences. Our method achieved an accuracy of 84.5% on 10-fold\ncross-validation and an accuracy of 83% in the test dataset. Our results\ndemonstrate competitive performance, highlighting the potential of LLMs in\nenhancing the accuracy of amyloid prediction."}
{"id": "2508.11669", "pdf": "https://arxiv.org/pdf/2508.11669", "abs": "https://arxiv.org/abs/2508.11669", "authors": ["Wentao Li", "Yonghu He", "Kun Gao", "Qing Liu", "Yali Zheng"], "title": "Collaborative Learning-Enhanced Lightweight Models for Predicting Arterial Blood Pressure Waveform in a Large-scale Perioperative Dataset", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Noninvasive arterial blood pressure (ABP) monitoring is essential for patient\nmanagement in critical care and perioperative settings, providing continuous\nassessment of cardiovascular hemodynamics with minimal risks. Numerous deep\nlearning models have developed to reconstruct ABP waveform from noninvasively\nacquired physiological signals such as electrocardiogram and\nphotoplethysmogram. However, limited research has addressed the issue of model\nperformance and computational load for deployment on embedded systems. The\nstudy introduces a lightweight sInvResUNet, along with a collaborative learning\nscheme named KDCL_sInvResUNet. With only 0.89 million parameters and a\ncomputational load of 0.02 GFLOPS, real-time ABP estimation was successfully\nachieved on embedded devices with an inference time of just 8.49 milliseconds\nfor a 10-second output. We performed subject-independent validation in a\nlarge-scale and heterogeneous perioperative dataset containing 1,257,141 data\nsegments from 2,154 patients, with a wide BP range (41-257 mmHg for SBP, and\n31-234 mmHg for DBP). The proposed KDCL_sInvResUNet achieved lightly better\nperformance compared to large models, with a mean absolute error of 10.06 mmHg\nand mean Pearson correlation of 0.88 in tracking ABP changes. Despite these\npromising results, all deep learning models showed significant performance\nvariations across different demographic and cardiovascular conditions,\nhighlighting their limited ability to generalize across such a broad and\ndiverse population. This study lays a foundation work for real-time,\nunobtrusive ABP monitoring in real-world perioperative settings, providing\nbaseline for future advancements in this area."}
{"id": "2508.12576", "pdf": "https://arxiv.org/pdf/2508.12576", "abs": "https://arxiv.org/abs/2508.12576", "authors": ["Like Jian", "Dong Liu"], "title": "Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Federated learning (FL) enables decentralized clients to train a model\ncollaboratively without sharing local data. A key distinction between FL and\ncentralized learning is that clients' data are non-independent and identically\ndistributed, which poses significant challenges in training a global model that\ngeneralizes well across heterogeneous local data distributions. In this paper,\nwe analyze the convergence of overparameterized FedAvg with gradient descent\n(GD). We prove that the impact of data heterogeneity diminishes as the width of\nneural networks increases, ultimately vanishing when the width approaches\ninfinity. In the infinite-width regime, we further prove that both the global\nand local models in FedAvg behave as linear models, and that FedAvg achieves\nthe same generalization performance as centralized learning with the same\nnumber of GD iterations. Extensive experiments validate our theoretical\nfindings across various network architectures, loss functions, and optimization\nmethods."}
{"id": "2508.11670", "pdf": "https://arxiv.org/pdf/2508.11670", "abs": "https://arxiv.org/abs/2508.11670", "authors": ["Bongsu Kim"], "title": "RRRA: Resampling and Reranking through a Retriever Adapter", "categories": ["cs.IR", "cs.AI"], "comment": "8 pages, 4 figures, submitted to AAAI 2026", "summary": "In dense retrieval, effective training hinges on selecting high quality hard\nnegatives while avoiding false negatives. Recent methods apply heuristics based\non positive document scores to identify hard negatives, improving both\nperformance and interpretability. However, these global, example agnostic\nstrategies often miss instance specific false negatives. To address this, we\npropose a learnable adapter module that monitors Bi-Encoder representations to\nestimate the likelihood that a hard negative is actually a false negative. This\nprobability is modeled dynamically and contextually, enabling fine-grained,\nquery specific judgments. The predicted scores are used in two downstream\ncomponents: (1) resampling, where negatives are reweighted during training, and\n(2) reranking, where top-k retrieved documents are reordered at inference.\nEmpirical results on standard benchmarks show that our adapter-enhanced\nframework consistently outperforms strong Bi-Encoder baselines, underscoring\nthe benefit of explicit false negative modeling in dense retrieval."}
{"id": "2508.12590", "pdf": "https://arxiv.org/pdf/2508.12590", "abs": "https://arxiv.org/abs/2508.12590", "authors": ["Jihoon Park", "Seungeun Oh", "Seong-Lyun Kim"], "title": "Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 5 figures", "summary": "To address the growing demand for on-device LLM inference in\nresource-constrained environments, hybrid language models (HLM) have emerged,\ncombining lightweight local models with powerful cloud-based LLMs. Recent\nstudies on HLM have primarily focused on improving accuracy and latency, while\noften overlooking communication and energy efficiency. We propose a token-level\nfiltering mechanism for an energy-efficient importance- and uncertainty-aware\nHLM inference that leverages both epistemic uncertainty and attention-based\nimportance. Our method opportunistically uploads only informative tokens,\nreducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and\nLLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and\ntoken throughput of 0.37 tokens/sec while saving the energy consumption by\n40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM\nbaseline, our method improves BERTScore from 85.8% to 87.0%, energy savings\nfrom 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an\nenergy-efficient and accurate deployment of LLMs in bandwidth-constrained edge\nenvironments."}
{"id": "2508.11671", "pdf": "https://arxiv.org/pdf/2508.11671", "abs": "https://arxiv.org/abs/2508.11671", "authors": ["Ronald Carvalho Boadana", "Ademir Guimarães da Costa Junior", "Ricardo Rios", "Fábio Santos da Silva"], "title": "LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.MA"], "comment": "12 pages, in Portuguese language, 2 figures, 5 tables, 3 formulas. To\n  be published in the Proceedings of the Encontro Nacional de Intelig\\^encia\n  Artificial e Computacional (ENIAC 2025)", "summary": "The growing availability of music on streaming platforms has led to\ninformation overload for users. To address this issue and enhance the user\nexperience, increasingly sophisticated recommendation systems have been\nproposed. This work investigates the use of Large Language Models (LLMs) from\nthe Gemini and LLaMA families, combined with intelligent agents, in a\nmulti-agent personalized music recommendation system. The results are compared\nwith a traditional content-based recommendation model, considering user\nsatisfaction, novelty, and computational efficiency. LLMs achieved satisfaction\nrates of up to \\textit{89{,}32\\%}, indicating their promising potential in\nmusic recommendation systems."}
{"id": "2508.12593", "pdf": "https://arxiv.org/pdf/2508.12593", "abs": "https://arxiv.org/abs/2508.12593", "authors": ["Zhihao Li", "Ting Wang", "Guojian Zou", "Ruofei Wang", "Ye Li"], "title": "Physics-informed deep operator network for traffic state estimation", "categories": ["cs.LG"], "comment": "under review in Transportmetrica B: Transport Dynamics", "summary": "Traffic state estimation (TSE) fundamentally involves solving\nhigh-dimensional spatiotemporal partial differential equations (PDEs) governing\ntraffic flow dynamics from limited, noisy measurements. While Physics-Informed\nNeural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a\nphysics-informed deep operator network (PI-DeepONet) framework that\nreformulates TSE as an operator learning problem. Our approach trains a\nparameterized neural operator that maps sparse input data to the full\nspatiotemporal traffic state field, governed by the traffic flow conservation\nlaw. Crucially, unlike PINNs that enforce PDE constraints point-wise,\nPI-DeepONet integrates traffic flow conservation model and the fundamental\ndiagram directly into the operator learning process, ensuring physical\nconsistency while capturing congestion propagation, spatial correlations, and\ntemporal evolution. Experiments on the NGSIM dataset demonstrate superior\nperformance over state-of-the-art baselines. Further analysis reveals insights\ninto optimal function generation strategies and branch network complexity.\nAdditionally, the impact of input function generation methods and the number of\nfunctions on model performance is explored, highlighting the robustness and\nefficacy of proposed framework."}
{"id": "2508.11672", "pdf": "https://arxiv.org/pdf/2508.11672", "abs": "https://arxiv.org/abs/2508.11672", "authors": ["Zixia Zhou", "Junyan Liu", "Wei Emma Wu", "Ruogu Fang", "Sheng Liu", "Qingyue Wei", "Rui Yan", "Yi Guo", "Qian Tao", "Yuanyuan Wang", "Md Tauhidul Islam", "Lei Xing"], "title": "Revealing Neurocognitive and Behavioral Patterns by Unsupervised Manifold Learning from Dynamic Brain Data", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": null, "summary": "Dynamic brain data, teeming with biological and functional insights, are\nbecoming increasingly accessible through advanced measurements, providing a\ngateway to understanding the inner workings of the brain in living subjects.\nHowever, the vast size and intricate complexity of the data also pose a\ndaunting challenge in reliably extracting meaningful information across various\ndata sources. This paper introduces a generalizable unsupervised deep manifold\nlearning for exploration of neurocognitive and behavioral patterns. Unlike\nexisting methods that extract patterns directly from the input data as in the\nexisting methods, the proposed Brain-dynamic Convolutional-Network-based\nEmbedding (BCNE) seeks to capture the brain-state trajectories by deciphering\nthe temporospatial correlations within the data and subsequently applying\nmanifold learning to this correlative representation. The performance of BCNE\nis showcased through the analysis of several important dynamic brain datasets.\nThe results, both visual and quantitative, reveal a diverse array of intriguing\nand interpretable patterns. BCNE effectively delineates scene transitions,\nunderscores the involvement of different brain regions in memory and narrative\nprocessing, distinguishes various stages of dynamic learning processes, and\nidentifies differences between active and passive behaviors. BCNE provides an\neffective tool for exploring general neuroscience inquiries or\nindividual-specific patterns."}
{"id": "2508.12594", "pdf": "https://arxiv.org/pdf/2508.12594", "abs": "https://arxiv.org/abs/2508.12594", "authors": ["Vedant Puri", "Aditya Joglekar", "Kevin Ferguson", "Yu-hsuan Chen", "Yongjie Jessica Zhang", "Levent Burak Kara"], "title": "FLARE: Fast Low-rank Attention Routing Engine", "categories": ["cs.LG"], "comment": null, "summary": "The quadratic complexity of self-attention limits its applicability and\nscalability on large unstructured meshes. We introduce Fast Low-rank Attention\nRouting Engine (FLARE), a linear complexity self-attention mechanism that\nroutes attention through fixed-length latent sequences. Each attention head\nperforms global communication among $N$ tokens by projecting the input sequence\nonto a fixed length latent sequence of $M \\ll N$ tokens using learnable query\ntokens. By routing attention through a bottleneck sequence, FLARE learns a\nlow-rank form of attention that can be applied at $O(NM)$ cost. FLARE not only\nscales to unprecedented problem sizes, but also delivers superior accuracy\ncompared to state-of-the-art neural PDE surrogates across diverse benchmarks.\nWe also release a new additive manufacturing dataset to spur further research.\nOur code is available at https://github.com/vpuri3/FLARE.py."}
{"id": "2508.11673", "pdf": "https://arxiv.org/pdf/2508.11673", "abs": "https://arxiv.org/abs/2508.11673", "authors": ["Haojie Zhang", "Yixiong Liang", "Hulin Kuang", "Lihui Cen", "Zhe Qu", "Yigang Cen", "Min Zeng", "Shichao Kan"], "title": "Contrastive Regularization over LoRA for Multimodal Biomedical Image Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MM"], "comment": "10 pages, 3 figures, submitted to ACM Multimedia 2025", "summary": "Multimodal Biomedical Image Incremental Learning (MBIIL) is essential for\nhandling diverse tasks and modalities in the biomedical domain, as training\nseparate models for each modality or task significantly increases inference\ncosts. Existing incremental learning methods focus on task expansion within a\nsingle modality, whereas MBIIL seeks to train a unified model incrementally\nacross modalities. The MBIIL faces two challenges: I) How to preserve\npreviously learned knowledge during incremental updates? II) How to effectively\nleverage knowledge acquired from existing modalities to support new modalities?\nTo address these challenges, we propose MSLoRA-CR, a method that fine-tunes\nModality-Specific LoRA modules while incorporating Contrastive Regularization\nto enhance intra-modality knowledge sharing and promote inter-modality\nknowledge differentiation. Our approach builds upon a large vision-language\nmodel (LVLM), keeping the pretrained model frozen while incrementally adapting\nnew LoRA modules for each modality or task. Experiments on the incremental\nlearning of biomedical images demonstrate that MSLoRA-CR outperforms both the\nstate-of-the-art (SOTA) approach of training separate models for each modality\nand the general incremental learning method (incrementally fine-tuning LoRA).\nSpecifically, MSLoRA-CR achieves a 1.88% improvement in overall performance\ncompared to unconstrained incremental learning methods while maintaining\ncomputational efficiency. Our code is publicly available at\nhttps://github.com/VentusAislant/MSLoRA_CR."}
{"id": "2508.12596", "pdf": "https://arxiv.org/pdf/2508.12596", "abs": "https://arxiv.org/abs/2508.12596", "authors": ["Meng Zhang", "Chao Wang", "Hao Zhang", "Shaojun Dong", "Lixin He"], "title": "Constructing Invariant and Equivariant Operations by Symmetric Tensor Network", "categories": ["cs.LG"], "comment": null, "summary": "Design of neural networks that incorporate symmetry is crucial for geometric\ndeep learning. Central to this effort is the development of invariant and\nequivariant operations. This works presents a systematic method for\nconstructing valid invariant and equivariant operations. It can handle inputs\nand outputs in the form of Cartesian tensors with different rank, as well as\nspherical tensors with different types. In addition, our method features a\ngraphical representation utilizing the symmetric tensor network, which\nsimplifies both the proofs and constructions related to invariant and\nequivariant functions. We also apply this approach to design the equivariant\ninteraction message for the geometry graph neural network, and equivariant\nmachine learning model to learn the constitutive law of materials."}
{"id": "2508.11674", "pdf": "https://arxiv.org/pdf/2508.11674", "abs": "https://arxiv.org/abs/2508.11674", "authors": ["Zofia Rudnicka", "Janusz Szczepanski", "Agnieszka Pregowska"], "title": "Learning Internal Biological Neuron Parameters and Complexity-Based Encoding for Improved Spiking Neural Networks Performance", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": null, "summary": "This study introduces a novel approach by replacing the traditional\nperceptron neuron model with a biologically inspired probabilistic meta neuron,\nwhere the internal neuron parameters are jointly learned, leading to improved\nclassification accuracy of spiking neural networks (SNNs). To validate this\ninnovation, we implement and compare two SNN architectures: one based on\nstandard leaky integrate-and-fire (LIF) neurons and another utilizing the\nproposed probabilistic meta neuron model. As a second key contribution, we\npresent a new biologically inspired classification framework that uniquely\nintegrates SNNs with Lempel-Ziv complexity (LZC) a measure closely related to\nentropy rate. By combining the temporal precision and biological plausibility\nof SNNs with the capacity of LZC to capture structural regularity, the proposed\napproach enables efficient and interpretable classification of spatiotemporal\nneural data, an aspect not addressed in existing works. We consider learning\nalgorithms such as backpropagation, spike-timing-dependent plasticity (STDP),\nand the Tempotron learning rule. To explore neural dynamics, we use Poisson\nprocesses to model neuronal spike trains, a well-established method for\nsimulating the stochastic firing behavior of biological neurons. Our results\nreveal that depending on the training method, the classifier's efficiency can\nimprove by up to 11.00%, highlighting the advantage of learning additional\nneuron parameters beyond the traditional focus on weighted inputs alone."}
{"id": "2508.12602", "pdf": "https://arxiv.org/pdf/2508.12602", "abs": "https://arxiv.org/abs/2508.12602", "authors": ["Hansol Lim", "Jongseong Brad Choi", "Jee Won Lee", "Haeseong Jeoung", "Minkyu Han"], "title": "A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators", "categories": ["cs.LG"], "comment": "This preprint corresponding to a manuscript has been submitted to a\n  journal for potential publication", "summary": "We present a hybrid surrogate model for electric vehicle parameter estimation\nand power consumption. We combine our novel architecture Spectral Parameter\nOperator built on a Fourier Neural Operator backbone for global context and a\ndifferentiable physics module in the forward pass. From speed and acceleration\nalone, it outputs time-varying motor and regenerative braking efficiencies, as\nwell as aerodynamic drag, rolling resistance, effective mass, and auxiliary\npower. These parameters drive a physics-embedded estimate of battery power,\neliminating any separate physics-residual loss. The modular design lets\nrepresentations converge to physically meaningful parameters that reflect the\ncurrent state and condition of the vehicle. We evaluate on real-world logs from\na Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean\nabsolute error of 0.2kW (about 1% of average traction power at highway speeds)\nfor Tesla vehicles and about 0.8kW on the Kia EV9. The framework is\ninterpretable, and it generalizes well to unseen conditions, and sampling\nrates, making it practical for path optimization, eco-routing, on-board\ndiagnostics, and prognostics health management."}
{"id": "2508.11676", "pdf": "https://arxiv.org/pdf/2508.11676", "abs": "https://arxiv.org/abs/2508.11676", "authors": ["Maksym Shamrai", "Vladyslav Hamolia"], "title": "Deep Language Geometry: Constructing a Metric Space from LLM Weights", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 pages, accepted to RANLP 2025", "summary": "We introduce a novel framework that utilizes the internal weight activations\nof modern Large Language Models (LLMs) to construct a metric space of\nlanguages. Unlike traditional approaches based on hand-crafted linguistic\nfeatures, our method automatically derives high-dimensional vector\nrepresentations by computing weight importance scores via an adapted pruning\nalgorithm. Our approach captures intrinsic language characteristics that\nreflect linguistic phenomena. We validate our approach across diverse datasets\nand multilingual LLMs, covering 106 languages. The results align well with\nestablished linguistic families while also revealing unexpected inter-language\nconnections that may indicate historical contact or language evolution. The\nsource code, computed language latent vectors, and visualization tool are made\npublicly available at https://github.com/mshamrai/deep-language-geometry."}
{"id": "2508.12604", "pdf": "https://arxiv.org/pdf/2508.12604", "abs": "https://arxiv.org/abs/2508.12604", "authors": ["Yuyang Xu", "Yi Cheng", "Haochao Ying", "Zhuoyun Du", "Renjun Hu", "Xing Shi", "Wei Lin", "Jian Wu"], "title": "SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression", "categories": ["cs.LG", "cs.AI"], "comment": "Work in progress", "summary": "Test-time scaling has proven effective in further enhancing the performance\nof pretrained Large Language Models (LLMs). However, mainstream post-training\nmethods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)\nreasoning) often incur substantial computational overhead due to auxiliary\nmodels and overthinking. In this paper, we empirically reveal that the\nincorrect answers partially stem from verbose reasoning processes lacking\ncorrect self-fix, where errors accumulate across multiple reasoning steps. To\nthis end, we propose Self-traced Step-wise Preference Optimization (SSPO), a\npluggable RL process supervision framework that enables fine-grained\noptimization of each reasoning step. Specifically, SSPO requires neither\nauxiliary models nor stepwise manual annotations. Instead, it leverages\nstep-wise preference signals generated by the model itself to guide the\noptimization process for reasoning compression. Experiments demonstrate that\nthe generated reasoning sequences from SSPO are both accurate and succinct,\neffectively mitigating overthinking behaviors without compromising model\nperformance across diverse domains and languages."}
{"id": "2508.11679", "pdf": "https://arxiv.org/pdf/2508.11679", "abs": "https://arxiv.org/abs/2508.11679", "authors": ["Shaodi Feng", "Zhuoyi Lin", "Jianan Zhou", "Cong Zhang", "Jingwen Li", "Kuan-Wen Chen", "Senthilnath Jayavelu", "Yew-Soon Ong"], "title": "Lifelong Learner: Discovering Versatile Neural Solvers for Vehicle Routing Problems", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Deep learning has been extensively explored to solve vehicle routing problems\n(VRPs), which yields a range of data-driven neural solvers with promising\noutcomes. However, most neural solvers are trained to tackle VRP instances in a\nrelatively monotonous context, e.g., simplifying VRPs by using Euclidean\ndistance between nodes and adhering to a single problem size, which harms their\noff-the-shelf application in different scenarios. To enhance their versatility,\nthis paper presents a novel lifelong learning framework that incrementally\ntrains a neural solver to manage VRPs in distinct contexts. Specifically, we\npropose a lifelong learner (LL), exploiting a Transformer network as the\nbackbone, to solve a series of VRPs. The inter-context self-attention mechanism\nis proposed within LL to transfer the knowledge obtained from solving preceding\nVRPs into the succeeding ones. On top of that, we develop a dynamic context\nscheduler (DCS), employing the cross-context experience replay to further\nfacilitate LL looking back on the attained policies of solving preceding VRPs.\nExtensive results on synthetic and benchmark instances (problem sizes up to\n18k) show that our LL is capable of discovering effective policies for tackling\ngeneric VRPs in varying contexts, which outperforms other neural solvers and\nachieves the best performance for most VRPs."}
{"id": "2508.12623", "pdf": "https://arxiv.org/pdf/2508.12623", "abs": "https://arxiv.org/abs/2508.12623", "authors": ["Florian J. Boge", "Annika Schuster"], "title": "How can we trust opaque systems? Criteria for robust explanations in XAI", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 1 figure", "summary": "Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in\nscientific research. However, the price we pay for their impressively accurate\npredictions is significant: their inner workings are notoriously opaque - it is\nunknown to laypeople and researchers alike what features of the data a DL\nsystem focuses on and how it ultimately succeeds in predicting correct outputs.\nA necessary criterion for trustworthy explanations is that they should reflect\nthe relevant processes the algorithms' predictions are based on. The field of\neXplainable Artificial Intelligence (XAI) presents promising methods to create\nsuch explanations. But recent reviews about their performance offer reasons for\nskepticism. As we will argue, a good criterion for trustworthiness is\nexplanatory robustness: different XAI methods produce the same explanations in\ncomparable contexts. However, in some instances, all methods may give the same,\nbut still wrong, explanation. We therefore argue that in addition to\nexplanatory robustness (ER), a prior requirement of explanation method\nrobustness (EMR) has to be fulfilled by every XAI method. Conversely, the\nrobustness of an individual method is in itself insufficient for\ntrustworthiness. In what follows, we develop and formalize criteria for ER as\nwell as EMR, providing a framework for explaining and establishing trust in DL\nalgorithms. We also highlight interesting application cases and outline\ndirections for future work."}
{"id": "2508.11680", "pdf": "https://arxiv.org/pdf/2508.11680", "abs": "https://arxiv.org/abs/2508.11680", "authors": ["Aditya Akella", "Jonathan Farah"], "title": "Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics", "categories": ["cs.LG", "cs.AI", "es: 62M10 (primary), 62P20, 68T05, 91B72 (secondary)"], "comment": "6 pages, 4 figures, 3 tables", "summary": "Demographic shifts, influenced by globalization, economic conditions,\ngeopolitical events, and environmental factors, pose significant challenges for\npolicymakers and researchers. Accurate demographic forecasting is essential for\ninformed decision-making in areas such as urban planning, healthcare, and\neconomic policy. This study explores the application of time series foundation\nmodels to predict demographic changes in the United States using datasets from\nthe U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate\nthe performance of the Time Series Foundation Model (TimesFM) against\ntraditional baselines including Long Short-Term Memory (LSTM) networks,\nAutoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our\nexperiments across six demographically diverse states demonstrate that TimesFM\nachieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with\nparticularly strong performance on minority populations with sparse historical\ndata. These findings highlight the potential of pre-trained foundation models\nto enhance demographic analysis and inform proactive policy interventions\nwithout requiring extensive task-specific fine-tuning."}
{"id": "2508.12629", "pdf": "https://arxiv.org/pdf/2508.12629", "abs": "https://arxiv.org/abs/2508.12629", "authors": ["Ian Dunn", "David R. Koes"], "title": "FlowMol3: Flow Matching for 3D De Novo Small-Molecule Generation", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "A generative model capable of sampling realistic molecules with desired\nproperties could accelerate chemical discovery across a wide range of\napplications. Toward this goal, significant effort has focused on developing\nmodels that jointly sample molecular topology and 3D structure. We present\nFlowMol3, an open-source, multi-modal flow matching model that advances the\nstate of the art for all-atom, small-molecule generation. Its substantial\nperformance gains over previous FlowMol versions are achieved without changes\nto the graph neural network architecture or the underlying flow matching\nformulation. Instead, FlowMol3's improvements arise from three\narchitecture-agnostic techniques that incur negligible computational cost:\nself-conditioning, fake atoms, and train-time geometry distortion. FlowMol3\nachieves nearly 100% molecular validity for drug-like molecules with explicit\nhydrogens, more accurately reproduces the functional group composition and\ngeometry of its training data, and does so with an order of magnitude fewer\nlearnable parameters than comparable methods. We hypothesize that these\ntechniques mitigate a general pathology affecting transport-based generative\nmodels, enabling detection and correction of distribution drift during\ninference. Our results highlight simple, transferable strategies for improving\nthe stability and quality of diffusion- and flow-based molecular generative\nmodels."}
{"id": "2508.11681", "pdf": "https://arxiv.org/pdf/2508.11681", "abs": "https://arxiv.org/abs/2508.11681", "authors": ["Vincent C. Müller", "Nick Bostrom"], "title": "Future progress in artificial intelligence: A survey of expert opinion", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "There is, in some quarters, concern about high-level machine intelligence and\nsuperintelligent AI coming up in a few decades, bringing with it significant\nrisks for humanity. In other quarters, these issues are ignored or considered\nscience fiction. We wanted to clarify what the distribution of opinions\nactually is, what probability the best experts currently assign to high-level\nmachine intelligence coming up within a particular time-frame, which risks they\nsee with that development, and how fast they see these developing. We thus\ndesigned a brief questionnaire and distributed it to four groups of experts in\n2012/2013. The median estimate of respondents was for a one in two chance that\nhigh-level machine intelligence will be developed around 2040-2050, rising to a\nnine in ten chance by 2075. Experts expect that systems will move on to\nsuperintelligence in less than 30 years thereafter. They estimate the chance is\nabout one in three that this development turns out to be 'bad' or 'extremely\nbad' for humanity."}
{"id": "2508.12650", "pdf": "https://arxiv.org/pdf/2508.12650", "abs": "https://arxiv.org/abs/2508.12650", "authors": ["Jiyeon Kang", "Songseong Kim", "Chanhui Lee", "Doyeong Hwang", "Joanie Hayoun Chung", "Yunkyung Ko", "Sumin Lee", "Sungwoong Kim", "Sungbin Lim"], "title": "Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.8"], "comment": "32 pages, 17 figures, 5 tables", "summary": "Ordering-based approaches to causal discovery identify topological orders of\ncausal graphs, providing scalable alternatives to combinatorial search methods.\nUnder the Additive Noise Model (ANM) assumption, recent causal ordering methods\nbased on score matching require an accurate estimation of the Hessian diagonal\nof the log-densities. However, previous approaches mainly use Stein gradient\nestimators, which are computationally expensive and memory-intensive. Although\nDiffAN addresses these limitations by substituting kernel-based estimates with\ndiffusion models, it remains numerically unstable due to the second-order\nderivatives of score models. To alleviate these problems, we propose\nScore-informed Neural Operator (SciNO), a probabilistic generative model in\nsmooth function spaces designed to stably approximate the Hessian diagonal and\nto preserve structural information during the score modeling. Empirical results\nshow that SciNO reduces order divergence by 42.7% on synthetic graphs and by\n31.5% on real-world datasets on average compared to DiffAN, while maintaining\nmemory efficiency and scalability. Furthermore, we propose a probabilistic\ncontrol algorithm for causal reasoning with autoregressive models that\nintegrates SciNO's probability estimates with autoregressive model priors,\nenabling reliable data-driven causal ordering informed by semantic information.\nConsequently, the proposed method enhances causal reasoning abilities of LLMs\nwithout additional fine-tuning or prompt engineering."}
{"id": "2508.11682", "pdf": "https://arxiv.org/pdf/2508.11682", "abs": "https://arxiv.org/abs/2508.11682", "authors": ["Md Basit Azam", "Sarangthem Ibotombi Singh"], "title": "Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Non-invasive glucose monitoring remains a critical challenge in the\nmanagement of diabetes. HRV during sleep shows promise for glucose prediction\nhowever, age-related autonomic changes significantly confound traditional HRV\nanalyses. We analyzed 43 subjects with multi-modal data including sleep-stage\nspecific ECG, HRV features, and clinical measurements. A novel\nage-normalization technique was applied to the HRV features by, dividing the\nraw values by age-scaled factors. BayesianRidge regression with 5-fold\ncross-validation was employed for log-glucose prediction. Age-normalized HRV\nfeatures achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction,\nrepresenting a 25.6% improvement over non-normalized features (R2 = 0.132). The\ntop predictive features were hrv rem mean rr age normalized (r = 0.443, p =\n0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic\nblood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed\nage-normalization as the critical component, with sleep-stage specific features\nproviding additional predictive value. Age-normalized HRV features\nsignificantly enhance glucose prediction accuracy compared with traditional\napproaches. This sleep-aware methodology addresses fundamental limitations in\nautonomic function assessment and suggests a preliminary feasibility for\nnon-invasive glucose monitoring applications. However, these results require\nvalidation in larger cohorts before clinical consideration."}
{"id": "2508.12672", "pdf": "https://arxiv.org/pdf/2508.12672", "abs": "https://arxiv.org/abs/2508.12672", "authors": ["Emmanouil Kritharakis", "Dusan Jakovetic", "Antonios Makris", "Konstantinos Tserpes"], "title": "Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "Federated Learning (FL) enables collaborative model training across multiple\nclients without sharing private data. We consider FL scenarios wherein FL\nclients are subject to adversarial (Byzantine) attacks, while the FL server is\ntrusted (honest) and has a trustworthy side dataset. This may correspond to,\ne.g., cases where the server possesses trusted data prior to federation, or to\nthe presence of a trusted client that temporarily assumes the server role. Our\napproach requires only two honest participants, i.e., the server and one\nclient, to function effectively, without prior knowledge of the number of\nmalicious clients. Theoretical analysis demonstrates bounded optimality gaps\neven under strong Byzantine attacks. Experimental results show that our\nalgorithm significantly outperforms standard and robust FL baselines such as\nMean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack\nstrategies including label flipping, sign flipping, and Gaussian noise addition\nacross MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework."}
{"id": "2508.11689", "pdf": "https://arxiv.org/pdf/2508.11689", "abs": "https://arxiv.org/abs/2508.11689", "authors": ["Eduardo Calle-Ortiz", "Hui Guan", "Deepak Ganesan", "Phuc Nguyen"], "title": "Adaptive Spiking with Plasticity for Energy Aware Neuromorphic Systems", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": "14 pages", "summary": "This paper presents ASPEN, a novel energy-aware technique for neuromorphic\nsystems that could unleash the future of intelligent, always-on,\nultra-low-power, and low-burden wearables. Our main research objectives are to\nexplore the feasibility of neuromorphic computing for wearables, identify open\nresearch directions, and demonstrate the feasibility of developing an adaptive\nspiking technique for energy-aware computation, which can be game-changing for\nresource-constrained devices in always-on applications. As neuromorphic\ncomputing systems operate based on spike events, their energy consumption is\nclosely related to spiking activity, i.e., each spike incurs computational and\npower costs; consequently, minimizing the number of spikes is a critical\nstrategy for operating under constrained energy budgets. To support this goal,\nASPEN utilizes stochastic perturbations to the neuronal threshold during\ntraining to not only enhance the network's robustness across varying\nthresholds, which can be controlled at inference time, but also act as a\nregularizer that improves generalization, reduces spiking activity, and enables\nenergy control without the need for complex retraining or pruning. More\nspecifically, ASPEN adaptively adjusts intrinsic neuronal parameters as a\nlightweight and scalable technique for dynamic energy control without\nreconfiguring the entire model. Our evaluation on neuromorphic emulator and\nhardware shows that ASPEN significantly reduces spike counts and energy\nconsumption while maintaining accuracy comparable to state-of-the-art methods."}
{"id": "2508.12673", "pdf": "https://arxiv.org/pdf/2508.12673", "abs": "https://arxiv.org/abs/2508.12673", "authors": ["Yuhao Zhou", "Jindi Lv", "Yuxin Tian", "Dan Si", "Qing Ye", "Jiancheng Lv"], "title": "Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages", "summary": "Federated Learning (FL) has emerged as a promising paradigm for\nprivacy-preserving collaborative learning, yet data heterogeneity remains a\ncritical challenge. While existing methods achieve progress in addressing data\nheterogeneity for participating clients, they fail to generalize to\nnon-participating clients with in-domain distribution shifts and resource\nconstraints. To mitigate this issue, we present HyperFedZero, a novel method\nthat dynamically generates specialized models via a hypernetwork conditioned on\ndistribution-aware embeddings. Our approach explicitly incorporates\ndistribution-aware inductive biases into the model's forward pass, extracting\nrobust distribution embeddings using a NoisyEmbed-enhanced extractor with a\nBalancing Penalty, effectively preventing feature collapse. The hypernetwork\nthen leverages these embeddings to generate specialized models chunk-by-chunk\nfor non-participating clients, ensuring adaptability to their unique data\ndistributions. Extensive experiments on multiple datasets and models\ndemonstrate HyperFedZero's remarkable performance, surpassing competing methods\nconsistently with minimal computational, storage, and communication overhead.\nMoreover, ablation studies and visualizations further validate the necessity of\neach component, confirming meaningful adaptations and validating the\neffectiveness of HyperFedZero."}
{"id": "2508.11690", "pdf": "https://arxiv.org/pdf/2508.11690", "abs": "https://arxiv.org/abs/2508.11690", "authors": ["Tadisetty Sai Yashwanth", "Yangalasetty Sruthi Royal", "Vankayala Rajeshwari Shreya", "Mayank Kashyap", "Divyaprabha K N"], "title": "Real Time Child Abduction And Detection System", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Child safety continues to be a paramount concern worldwide, with child\nabduction posing significant threats to communities. This paper presents the\ndevelopment of an edge-based child abduction detection and alert system\nutilizing a multi-agent framework where each agent incorporates Vision-Language\nModels (VLMs) deployed on a Raspberry Pi. Leveraging the advanced capabilities\nof VLMs within individual agents of a multi-agent team, our system is trained\nto accurately detect and interpret complex interactions involving children in\nvarious environments in real-time. The multi-agent system is deployed on a\nRaspberry Pi connected to a webcam, forming an edge device capable of\nprocessing video feeds, thereby reducing latency and enhancing privacy. An\nintegrated alert system utilizes the Twilio API to send immediate SMS and\nWhatsApp notifications, including calls and messages, when a potential child\nabduction event is detected. Experimental results demonstrate that the system\nachieves high accuracy in detecting potential abduction scenarios, with near\nreal-time performance suitable for practical deployment. The multi-agent\narchitecture enhances the system's ability to process complex situational data,\nimproving detection capabilities over traditional single-model approaches. The\nedge deployment ensures scalability and cost-effectiveness, making it\naccessible for widespread use. The proposed system offers a proactive solution\nto enhance child safety through continuous monitoring and rapid alerting,\ncontributing a valuable tool in efforts to prevent child abductions."}
{"id": "2508.12703", "pdf": "https://arxiv.org/pdf/2508.12703", "abs": "https://arxiv.org/abs/2508.12703", "authors": ["Thomas Krug", "Fabian Raisch", "Dominik Aimer", "Markus Wirnsberger", "Ferdinand Sigg", "Benjamin Schäfer", "Benjamin Tischler"], "title": "BUILDA: A Thermal Building Data Generation Framework for Transfer Learning", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "Proceedings can be accessed at:\n  https://annsim.org/2025-annsim-proceedings/", "summary": "Transfer learning (TL) can improve data-driven modeling of building thermal\ndynamics. Therefore, many new TL research areas emerge in the field, such as\nselecting the right source model for TL. However, these research directions\nrequire massive amounts of thermal building data which is lacking presently.\nNeither public datasets nor existing data generators meet the needs of TL\nresearch in terms of data quality and quantity. Moreover, existing data\ngeneration approaches typically require expert knowledge in building\nsimulation. We present BuilDa, a thermal building data generation framework for\nproducing synthetic data of adequate quality and quantity for TL research. The\nframework does not require profound building simulation knowledge to generate\nlarge volumes of data. BuilDa uses a single-zone Modelica model that is\nexported as a Functional Mock-up Unit (FMU) and simulated in Python. We\ndemonstrate BuilDa by generating data and utilizing it for pretraining and\nfine-tuning TL models."}
{"id": "2508.11691", "pdf": "https://arxiv.org/pdf/2508.11691", "abs": "https://arxiv.org/abs/2508.11691", "authors": ["Mathis Rezzouk", "Fabrice Gagnon", "Alyson Champagne", "Mathieu Roy", "Philippe Albouy", "Michel-Pierre Coll", "Cem Subakan"], "title": "Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "6 pages, 2 figures, 2 tables, MLSP IEEE conference", "summary": "EEG-based analysis of pain perception, enhanced by machine learning, reveals\nhow the brain encodes pain by identifying neural patterns evoked by noxious\nstimulation. However, a major challenge that remains is the generalization of\nmachine learning models across individuals, given the high cross-participant\nvariability inherent to EEG signals and the limited focus on direct pain\nperception identification in current research. In this study, we systematically\nevaluate the performance of cross-participant generalization of a wide range of\nmodels, including traditional classifiers and deep neural classifiers for\nidentifying the sensory modality of thermal pain and aversive auditory\nstimulation from EEG recordings. Using a novel dataset of EEG recordings from\n108 participants, we benchmark model performance under both within- and\ncross-participant evaluation settings. Our findings show that traditional\nmodels suffered the largest drop from within- to cross-participant performance,\nwhile deep learning models proved more resilient, underscoring their potential\nfor subject-invariant EEG decoding. Even though performance variability\nremained high, the strong results of the graph-based model highlight its\npotential to capture subject-invariant structure in EEG signals. On the other\nhand, we also share the preprocessed dataset used in this study, providing a\nstandardized benchmark for evaluating future algorithms under the same\ngeneralization constraints."}
{"id": "2508.12712", "pdf": "https://arxiv.org/pdf/2508.12712", "abs": "https://arxiv.org/abs/2508.12712", "authors": ["Seyed Mahdi Haji Seyed Hossein", "Alireza Hosseini", "Soheil Hajian Manesh", "Amirali Shahriary"], "title": "Argos: A Decentralized Federated System for Detection of Traffic Signs in CAVs", "categories": ["cs.LG", "cs.CV", "I.2.6; I.4.8"], "comment": "7 pages, 10 figures", "summary": "Connected and automated vehicles generate vast amounts of sensor data daily,\nraising significant privacy and communication challenges for centralized\nmachine learning approaches in perception tasks. This study presents a\ndecentralized, federated learning framework tailored for traffic sign detection\nin vehicular networks to enable collaborative model training without sharing\nraw data. The framework partitioned traffic sign classes across vehicles for\nspecialized local training using lightweight object detectors, aggregated model\nparameters via algorithms like FedProx, FedAdam and FedAVG in a simulated\nenvironment with the Flower framework, and evaluated multiple configurations\nincluding varying server rounds, local epochs, client participation fractions,\nand data distributions. Experiments demonstrated that increasing server rounds\nfrom 2 to 20 boosted accuracy from below 0.1 to over 0.8, moderate local epochs\n(8-10) provided optimal efficiency with accuracies around 0.67, higher client\nparticipation fractions enhanced generalization up to 0.83, FedProx\noutperformed other aggregators in handling heterogeneity, non-IID data\ndistributions reduced performance compared to IID, and training duration\nprimarily scaled with the number of rounds rather than aggregation strategy. We\nconclude that this federated approach may offer a scalable, privacy-preserving\nsolution for real-world vehicular deployments, potentially guiding future\nintegrations of robust aggregation and communication optimizations to advance\nintelligent transportation systems."}
{"id": "2508.11692", "pdf": "https://arxiv.org/pdf/2508.11692", "abs": "https://arxiv.org/abs/2508.11692", "authors": ["Eduardo Di Santi", "Ruixiang Ci", "Clément Lefebvre", "Nenad Mijatovic", "Michele Pugnaloni", "Jonathan Brown", "Victor Martín", "Kenza Saiah"], "title": "Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning", "categories": ["eess.SP", "cs.AI", "68T07, 68T05", "I.2.6; I.5.1; I.5.4"], "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025, Dresden,\n  Germany. Conference: https://tu-dresden.de/raildresden2025. Book of\n  abstracts: https://tu-dresden.de/raildresden2025/BoA.pdf. 8 pages, 6 figures,\n  1 table", "summary": "The Point Machine (PM) is a critical piece of railway equipment that switches\ntrain routes by diverting tracks through a switchblade. As with any critical\nsafety equipment, a failure will halt operations leading to service\ndisruptions; therefore, pre-emptive maintenance may avoid unnecessary\ninterruptions by detecting anomalies before they become failures. Previous work\nrelies on several inputs and crafting custom features by segmenting the signal.\nThis not only adds additional requirements for data collection and processing,\nbut it is also specific to the PM technology, the installed locations and\noperational conditions limiting scalability. Based on the available maintenance\nrecords, the main failure causes for PM are obstacles, friction, power source\nissues and misalignment. Those failures affect the energy consumption pattern\nof PMs, altering the usual (or healthy) shape of the power signal during the PM\nmovement. In contrast to the current state-of-the-art, our method requires only\none input. We apply a deep learning model to the power signal pattern to\nclassify if the PM is nominal or associated with any failure type, achieving\n>99.99\\% precision, <0.01\\% false positives and negligible false negatives. Our\nmethodology is generic and technology-agnostic, proven to be scalable on\nseveral electromechanical PM types deployed in both real-world and test bench\nenvironments. Finally, by using conformal prediction the maintainer gets a\nclear indication of the certainty of the system outputs, adding a confidence\nlayer to operations and making the method compliant with the ISO-17359\nstandard."}
{"id": "2508.12727", "pdf": "https://arxiv.org/pdf/2508.12727", "abs": "https://arxiv.org/abs/2508.12727", "authors": ["Manning Zhu", "Songtao Guo", "Pengzhan Zhou", "Yansong Ning", "Chang Han", "Dewen Qiao"], "title": "FedSODA: Federated Fine-tuning of LLMs via Similarity Group Pruning and Orchestrated Distillation Alignment", "categories": ["cs.LG"], "comment": null, "summary": "Federated fine-tuning (FFT) of large language models (LLMs) has recently\nemerged as a promising solution to enable domain-specific adaptation while\npreserving data privacy. Despite its benefits, FFT on resource-constrained\nclients relies on the high computational and memory demands of full-model\nfine-tuning, which limits the potential advancement. This paper presents\nFedSODA, a resource-efficient FFT framework that enables clients to adapt LLMs\nwithout accessing or storing the full model. Specifically, we first propose a\nsimilarity group pruning (SGP) module, which prunes redundant layers from the\nfull LLM while retaining the most critical layers to preserve the model\nperformance. Moreover, we introduce an orchestrated distillation alignment\n(ODA) module to reduce gradient divergence between the sub-LLM and the full LLM\nduring FFT. Through the use of the QLoRA, clients only need to deploy quantized\nsub-LLMs and fine-tune lightweight adapters, significantly reducing local\nresource requirements. We conduct extensive experiments on three open-source\nLLMs across a variety of downstream tasks. The experimental results demonstrate\nthat FedSODA reduces communication overhead by an average of 70.6%, decreases\nstorage usage by 75.6%, and improves task accuracy by 3.1%, making it highly\nsuitable for practical FFT applications under resource constraints."}
{"id": "2508.11693", "pdf": "https://arxiv.org/pdf/2508.11693", "abs": "https://arxiv.org/abs/2508.11693", "authors": ["Francisco López", "Eduardo Di Santi", "Clément Lefebvre", "Nenad Mijatovic", "Michele Pugnaloni", "Victor Martín", "Kenza Saiah"], "title": "Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data", "categories": ["eess.SP", "cs.AI", "cs.LG", "68T05, 68T10", "I.2.6; I.5.1; I.5.4"], "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025\n  (International Conference on Railway Operations Modelling and Analysis),\n  Dresden, Germany", "summary": "Track Circuits (TC) are the main signalling devices used to detect the\npresence of a train on a rail track. It has been used since the 19th century\nand nowadays there are many types depending on the technology. As a general\nclassification, Track Circuits can be divided into 2 main groups, DC (Direct\nCurrent) and AC (Alternating Current) circuits. This work is focused on a\nparticular AC track circuit, called \"Smart Train Detection System\" (STDS),\ndesigned with both high and low-frequency bands. This approach uses STDS\ncurrent data applied to an SVM (support vector machine) classifier as a type of\nfailure identifier. The main purpose of this work consists on determine\nautomatically which is the component of the track that is failing to improve\nthe maintenance action. Model was trained to classify 15 different failures\nthat belong to 3 more general categories. The method was tested with field data\nfrom 10 different track circuits and validated by the STDS track circuit expert\nand maintainers. All use cases were correctly classified by the method."}
{"id": "2508.12740", "pdf": "https://arxiv.org/pdf/2508.12740", "abs": "https://arxiv.org/abs/2508.12740", "authors": ["Beomseok Seo", "Kichang Lee", "JaeYeon Park"], "title": "FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models", "categories": ["cs.LG", "cs.AI", "68T01 (Primary), 68T07 (Secondary)", "I.2"], "comment": "6 pages, 4 figures", "summary": "Federated learning (FL) enables decentralized model training without sharing\nlocal data. However, most existing methods assume identical model architectures\nacross clients, limiting their applicability in heterogeneous real-world\nenvironments. To address this, we propose FedUNet, a lightweight and\narchitecture-agnostic FL framework that attaches a U-Net-inspired additive\nmodule to each client's backbone. By sharing only the compact bottleneck of the\nU-Net, FedUNet enables efficient knowledge transfer without structural\nalignment. The encoder-decoder design and skip connections in the U-Net help\ncapture both low-level and high-level features, facilitating the extraction of\nclientinvariant representations. This enables cooperative learning between the\nbackbone and the additive module with minimal communication cost. Experiment\nwith VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in\ncompact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low\ncommunication overhead."}
{"id": "2508.11695", "pdf": "https://arxiv.org/pdf/2508.11695", "abs": "https://arxiv.org/abs/2508.11695", "authors": ["Yiyun Chen", "Weikai Yang"], "title": "RefAdGen: High-Fidelity Advertising Image Generation", "categories": ["cs.GR", "cs.AI"], "comment": null, "summary": "The rapid advancement of Artificial Intelligence Generated Content (AIGC)\ntechniques has unlocked opportunities in generating diverse and compelling\nadvertising images based on referenced product images and textual scene\ndescriptions. This capability substantially reduces human labor and production\ncosts in traditional marketing workflows. However, existing AIGC techniques\neither demand extensive fine-tuning for each referenced image to achieve high\nfidelity, or they struggle to maintain fidelity across diverse products, making\nthem impractical for e-commerce and marketing industries. To tackle this\nlimitation, we first construct AdProd-100K, a large-scale advertising image\ngeneration dataset. A key innovation in its construction is our dual data\naugmentation strategy, which fosters robust, 3D-aware representations crucial\nfor realistic and high-fidelity image synthesis. Leveraging this dataset, we\npropose RefAdGen, a generation framework that achieves high fidelity through a\ndecoupled design. The framework enforces precise spatial control by injecting a\nproduct mask at the U-Net input, and employs an efficient Attention Fusion\nModule (AFM) to integrate product features. This design effectively resolves\nthe fidelity-efficiency dilemma present in existing methods. Extensive\nexperiments demonstrate that RefAdGen achieves state-of-the-art performance,\nshowcasing robust generalization by maintaining high fidelity and remarkable\nvisual results for both unseen products and challenging real-world, in-the-wild\nimages. This offers a scalable and cost-effective alternative to traditional\nworkflows. Code and datasets are publicly available at\nhttps://github.com/Anonymous-Name-139/RefAdgen."}
{"id": "2508.12741", "pdf": "https://arxiv.org/pdf/2508.12741", "abs": "https://arxiv.org/abs/2508.12741", "authors": ["Manuela Imbriani", "Gina Belmonte", "Mieke Massink", "Alessandro Tofani", "Vincenzo Ciancia"], "title": "A Multi-Resolution Benchmark Framework for Spatial Reasoning Assessment in Neural Networks", "categories": ["cs.LG", "physics.app-ph", "physics.med-ph"], "comment": null, "summary": "This paper presents preliminary results in the definition of a comprehensive\nbenchmark framework designed to systematically evaluate spatial reasoning\ncapabilities in neural networks, with a particular focus on morphological\nproperties such as connectivity and distance relationships. The framework is\ncurrently being used to study the capabilities of nnU-Net, exploiting the\nspatial model checker VoxLogicA to generate two distinct categories of\nsynthetic datasets: maze connectivity problems for topological analysis and\nspatial distance computation tasks for geometric understanding. Each category\nis evaluated across multiple resolutions to assess scalability and\ngeneralization properties. The automated pipeline encompasses a complete\nmachine learning workflow including: synthetic dataset generation, standardized\ntraining with cross-validation, inference execution, and comprehensive\nevaluation using Dice coefficient and IoU (Intersection over Union) metrics.\nPreliminary experimental results demonstrate significant challenges in neural\nnetwork spatial reasoning capabilities, revealing systematic failures in basic\ngeometric and topological understanding tasks. The framework provides a\nreproducible experimental protocol, enabling researchers to identify specific\nlimitations. Such limitations could be addressed through hybrid approaches\ncombining neural networks with symbolic reasoning methods for improved spatial\nunderstanding in clinical applications, establishing a foundation for ongoing\nresearch into neural network spatial reasoning limitations and potential\nsolutions."}
{"id": "2508.11697", "pdf": "https://arxiv.org/pdf/2508.11697", "abs": "https://arxiv.org/abs/2508.11697", "authors": ["Adrián Rodríguez-Muñoz", "Manel Baradad", "Phillip Isola", "Antonio Torralba"], "title": "Separating Knowledge and Perception with Procedural Data", "categories": ["cs.CV", "cs.AI", "I.5.1"], "comment": "17 pages, 18 figures, 3 tables, to be published in ICML 2025", "summary": "We train representation models with procedural data only, and apply them on\nvisual similarity, classification, and semantic segmentation tasks without\nfurther training by using visual memory -- an explicit database of reference\nimage embeddings. Unlike prior work on visual memory, our approach achieves\nfull compartmentalization with respect to all real-world images while retaining\nstrong performance. Compared to a model trained on Places, our procedural model\nperforms within $1\\%$ on NIGHTS visual similarity, outperforms by $8\\%$ and\n$15\\%$ on CUB200 and Flowers102 fine-grained classification, and is within\n$10\\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot\nsegmentation, achieving an $R^2$ on COCO within $10\\%$ of the models trained on\nreal data. Finally, we analyze procedural versus real data models, showing that\nparts of the same object have dissimilar representations in procedural models,\nresulting in incorrect searches in memory and explaining the remaining\nperformance gap."}
{"id": "2508.12758", "pdf": "https://arxiv.org/pdf/2508.12758", "abs": "https://arxiv.org/abs/2508.12758", "authors": ["Sowmini Devi Veeramachaneni", "Ramamurthy Garimella"], "title": "Constrained Centroid Clustering: A Novel Approach for Compact and Structured Partitioning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper presents Constrained Centroid Clustering (CCC), a method that\nextends classical centroid-based clustering by enforcing a constraint on the\nmaximum distance between the cluster center and the farthest point in the\ncluster. Using a Lagrangian formulation, we derive a closed-form solution that\nmaintains interpretability while controlling cluster spread. To evaluate CCC,\nwe conduct experiments on synthetic circular data with radial symmetry and\nuniform angular distribution. Using ring-wise, sector-wise, and joint entropy\nas evaluation metrics, we show that CCC achieves more compact clusters by\nreducing radial spread while preserving angular structure, outperforming\nstandard methods such as K-means and GMM. The proposed approach is suitable for\napplications requiring structured clustering with spread control, including\nsensor networks, collaborative robotics, and interpretable pattern analysis."}
{"id": "2508.11704", "pdf": "https://arxiv.org/pdf/2508.11704", "abs": "https://arxiv.org/abs/2508.11704", "authors": ["Suman Saha", "Fatemeh Rahbari", "Farhan Sadique", "Sri Krishna Chaitanya Velamakanni", "Mahfuza Farooque", "William J. Rothwell"], "title": "Next-Gen Education: Enhancing AI for Microlearning", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC", "cs.MM"], "comment": "Published and presented in 2025 ASEE Annual Conference and\n  Exposition, 22 pages, 6 figures", "summary": "This paper explores integrating microlearning strategies into university\ncurricula, particularly in computer science education, to counteract the\ndecline in class attendance and engagement in US universities after COVID. As\nstudents increasingly opt for remote learning and recorded lectures,\ntraditional educational approaches struggle to maintain engagement and\neffectiveness. Microlearning, which breaks complex subjects into manageable\nunits, is proposed to address shorter attention spans and enhance educational\noutcomes. It uses interactive formats such as videos, quizzes, flashcards, and\nscenario-based exercises, which are especially beneficial for topics like\nalgorithms and programming logic requiring deep understanding and ongoing\npractice. Adoption of microlearning is often limited by the effort needed to\ncreate such materials. This paper proposes leveraging AI tools, specifically\nChatGPT, to reduce the workload for educators by automating the creation of\nsupplementary materials. While AI can automate certain tasks, educators remain\nessential in guiding and shaping the learning process. This AI-enhanced\napproach ensures course content is kept current with the latest research and\ntechnology, with educators providing context and insights. By examining AI\ncapabilities in microlearning, this study shows the potential to transform\neducational practices and outcomes in computer science, offering a practical\nmodel for combining advanced technology with established teaching methods."}
{"id": "2508.12764", "pdf": "https://arxiv.org/pdf/2508.12764", "abs": "https://arxiv.org/abs/2508.12764", "authors": ["Cyril Voyant", "Milan Despotovic", "Luis Garcia-Gutierrez", "Mohammed Asloune", "Yves-Marie Saint-Drenan", "Jean-Laurent Duchaud", "hjuvan Antone Faggianelli", "Elena Magliaro"], "title": "Short-Term Forecasting of Energy Production and Consumption Using Extreme Learning Machine: A Comprehensive MIMO based ELM Approach", "categories": ["cs.LG", "physics.data-an"], "comment": null, "summary": "A novel methodology for short-term energy forecasting using an Extreme\nLearning Machine ($\\mathtt{ELM}$) is proposed. Using six years of hourly data\ncollected in Corsica (France) from multiple energy sources (solar, wind, hydro,\nthermal, bioenergy, and imported electricity), our approach predicts both\nindividual energy outputs and total production (\\cyr{including imports, which\nclosely follow energy demand, modulo losses)} through a Multi-Input\nMulti-Output ($\\mathtt{MIMO}$) architecture. To address non-stationarity and\nseasonal variability, sliding window techniques and cyclic time encoding are\nincorporated, enabling dynamic adaptation to fluctuations. The $\\mathtt{ELM}$\nmodel significantly outperforms persistence-based forecasting, particularly for\nsolar and thermal energy, achieving an $\\mathtt{nRMSE}$ of $17.9\\%$ and\n$5.1\\%$, respectively, with $\\mathtt{R^2} > 0.98$ (1-hour horizon). The model\nmaintains high accuracy up to five hours ahead, beyond which renewable energy\nsources become increasingly volatile. While $\\mathtt{MIMO}$ provides marginal\ngains over Single-Input Single-Output ($\\mathtt{SISO}$) architectures and\noffers key advantages over deep learning methods such as $\\mathtt{LSTM}$, it\nprovides a closed-form solution with lower computational demands, making it\nwell-suited for real-time applications, including online learning. Beyond\npredictive accuracy, the proposed methodology is adaptable to various contexts\nand datasets, as it can be tuned to local constraints such as resource\navailability, grid characteristics, and market structures."}
{"id": "2508.11706", "pdf": "https://arxiv.org/pdf/2508.11706", "abs": "https://arxiv.org/abs/2508.11706", "authors": ["Zhuofan Xu", "Benedikt Bollig", "Matthias Függer", "Thomas Nowak", "Vincent Le Dréau"], "title": "Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "The Centralized Training with Decentralized Execution (CTDE) paradigm has\ngained significant attention in multi-agent reinforcement learning (MARL) and\nis the foundation of many recent algorithms. However, decentralized policies\noperate under partial observability and often yield suboptimal performance\ncompared to centralized policies, while fully centralized approaches typically\nface scalability challenges as the number of agents increases.\n  We propose Centralized Permutation Equivariant (CPE) learning, a centralized\ntraining and execution framework that employs a fully centralized policy to\novercome these limitations. Our approach leverages a novel permutation\nequivariant architecture, Global-Local Permutation Equivariant (GLPE) networks,\nthat is lightweight, scalable, and easy to implement. Experiments show that CPE\nintegrates seamlessly with both value decomposition and actor-critic methods,\nsubstantially improving the performance of standard CTDE algorithms across\ncooperative benchmarks including MPE, SMAC, and RWARE, and matching the\nperformance of state-of-the-art RWARE implementations."}
{"id": "2508.12773", "pdf": "https://arxiv.org/pdf/2508.12773", "abs": "https://arxiv.org/abs/2508.12773", "authors": ["Jiadong Chen", "Xiao He", "Hengyu Ye", "Fuxin Jiang", "Tieying Zhang", "Jianjun Chen", "Xiaofeng Gao"], "title": "Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling", "categories": ["cs.LG"], "comment": "12 pages, 11 figures", "summary": "In the swiftly evolving domain of cloud computing, the advent of serverless\nsystems underscores the crucial need for predictive auto-scaling systems. This\nnecessity arises to ensure optimal resource allocation and maintain operational\nefficiency in inherently volatile environments. At the core of a predictive\nauto-scaling system is the workload forecasting model. Existing forecasting\nmodels struggle to quickly adapt to the dynamics in online workload streams and\nhave difficulty capturing the complex periodicity brought by fine-grained,\nhigh-frequency forecasting tasks. Addressing this, we propose a novel online\nensemble model, E3Former, for online workload forecasting in large-scale\npredictive auto-scaling. Our model synergizes the predictive capabilities of\nmultiple subnetworks to surmount the limitations of single-model approaches,\nthus ensuring superior accuracy and robustness. Remarkably, it accomplishes\nthis with a minimal increase in computational overhead, adhering to the lean\noperational ethos of serverless systems. Through extensive experimentation on\nreal-world workload datasets, we establish the efficacy of our ensemble model.\nIn online forecasting tasks, the proposed method reduces forecast error by an\naverage of 10%, and its effectiveness is further demonstrated through a\npredictive auto-scaling test in the real-life online system. Currently, our\nmethod has been deployed within ByteDance's Intelligent Horizontal Pod\nAuto-scaling (IHPA) platform, which supports the stable operation of over 30\napplications, such as Douyin E-Comerce, TouTiao, and Volcano Engine. The\npredictive auto-scaling capacity reaching over 600,000 CPU cores. On the basis\nof essentially ensuring service quality, the predictive auto-scaling system can\nreduce resource utilization by over 40%."}
{"id": "2508.11707", "pdf": "https://arxiv.org/pdf/2508.11707", "abs": "https://arxiv.org/abs/2508.11707", "authors": ["Sai Siddartha Maram", "Ulia Zaman", "Magy Seif El-Nasr"], "title": "Listening with Language Models: Using LLMs to Collect and Interpret Classroom Feedback", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Traditional end-of-quarter surveys often fail to provide instructors with\ntimely, detailed, and actionable feedback about their teaching. In this paper,\nwe explore how Large Language Model (LLM)-powered chatbots can reimagine the\nclassroom feedback process by engaging students in reflective, conversational\ndialogues. Through the design and deployment of a three-part\nsystem-PromptDesigner, FeedbackCollector, and FeedbackAnalyzer-we conducted a\npilot study across two graduate courses at UC Santa Cruz. Our findings suggest\nthat LLM-based feedback systems offer richer insights, greater contextual\nrelevance, and higher engagement compared to standard survey tools. Instructors\nvalued the system's adaptability, specificity, and ability to support\nmid-course adjustments, while students appreciated the conversational format\nand opportunity for elaboration. We conclude by discussing the design\nimplications of using AI to facilitate more meaningful and responsive feedback\nin higher education."}
{"id": "2508.12776", "pdf": "https://arxiv.org/pdf/2508.12776", "abs": "https://arxiv.org/abs/2508.12776", "authors": ["Muhammad Rajabinasab", "Farhad Pakdaman", "Moncef Gabbouj", "Peter Schneider-Kamp", "Arthur Zimek"], "title": "Randomized PCA Forest for Outlier Detection", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We propose a novel unsupervised outlier detection method based on Randomized\nPrincipal Component Analysis (PCA). Inspired by the performance of Randomized\nPCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a\nnovel unsupervised outlier detection method that utilizes RPCA Forest for\noutlier detection. Experimental results showcase the superiority of the\nproposed approach compared to the classical and state-of-the-art methods in\nperforming the outlier detection task on several datasets while performing\ncompetitively on the rest. The extensive analysis of the proposed method\nreflects it high generalization power and its computational efficiency,\nhighlighting it as a good choice for unsupervised outlier detection."}
{"id": "2508.11708", "pdf": "https://arxiv.org/pdf/2508.11708", "abs": "https://arxiv.org/abs/2508.11708", "authors": ["Rashid Mushkani", "Shin Koseki"], "title": "Street Review: A Participatory AI-Based Framework for Assessing Streetscape Inclusivity", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Urban centers undergo social, demographic, and cultural changes that shape\npublic street use and require systematic evaluation of public spaces. This\nstudy presents Street Review, a mixed-methods approach that combines\nparticipatory research with AI-based analysis to assess streetscape\ninclusivity. In Montr\\'eal, Canada, 28 residents participated in semi-directed\ninterviews and image evaluations, supported by the analysis of approximately\n45,000 street-view images from Mapillary. The approach produced visual\nanalytics, such as heatmaps, to correlate subjective user ratings with physical\nattributes like sidewalk, maintenance, greenery, and seating. Findings reveal\nvariations in perceptions of inclusivity and accessibility across demographic\ngroups, demonstrating that incorporating diverse user feedback can enhance\nmachine learning models through careful data-labeling and co-production\nstrategies. The Street Review framework offers a systematic method for urban\nplanners and policy analysts to inform planning, policy development, and\nmanagement of public streets."}
{"id": "2508.12787", "pdf": "https://arxiv.org/pdf/2508.12787", "abs": "https://arxiv.org/abs/2508.12787", "authors": ["Satoshi Noguchi", "Yoshinobu Kawahara"], "title": "Wavy Transformer", "categories": ["cs.LG"], "comment": "25 pages, 5 figures", "summary": "Transformers have achieved remarkable success across natural language\nprocessing (NLP) and computer vision (CV). However, deep transformer models\noften suffer from an over-smoothing issue, in which token representations\nconverge to similar values as they pass through successive transformer blocks.\nIn this paper, we establish an equivalence between the hidden-state dynamics\ninduced by stacked attention layers and graph neural diffusion on a complete\ngraph. From this perspective, over-smoothing can be interpreted as a\nconsequence of the dissipative nature of the underlying diffusion dynamics.\nMotivated by this physical interpretation, we propose Wavy Transformer, which\nconsists of a novel attention layer based on second-order wavy dynamics. We\nalso introduce a feed-forward network and a normalization layer designed to\npreserve the physical state-velocity relationship under the chain rule, thereby\nextending the transformer architecture. We further validate our proposed\ntechniques on various transformer models for NLP and CV tasks. The results\nconsistently demonstrate that Wavy Transformer improves performance with\nminimal additional parameters and no extra hyperparameter tuning."}
{"id": "2508.11709", "pdf": "https://arxiv.org/pdf/2508.11709", "abs": "https://arxiv.org/abs/2508.11709", "authors": ["Rajan Kadel", "Samar Shailendra", "Urvashi Rahul Saxena"], "title": "Navigating the New Landscape: A Conceptual Model for Project-Based Assessment (PBA) in the Age of GenAI", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The rapid integration of Generative Artificial Intelligence (GenAI) into\nhigher education presents both opportunities and challenges for assessment\ndesign, particularly within Project-Based Assessment (PBA) contexts.\nTraditional assessment methods often emphasise the final product in the PBA,\nwhich can now be significantly influenced or created by GenAI tools, raising\nconcerns regarding product authenticity, academic integrity, and learning\nvalidation. This paper advocates for a reimagined assessment model for\nProject-Based Learning (PBL) or a capstone project that prioritises\nprocess-oriented evaluation, multi-modal and multifaceted assessment design,\nand ethical engagement with GenAI to enable higher-order thinking. The model\nalso emphasises the use of (GenAI-assisted) personalised feedback by a\nsupervisor as an observance of the learning process during the project\nlifecycle. A use case scenario is provided to illustrate the application of the\nmodel in a capstone project setting. The paper concludes with recommendations\nfor educators and curriculum designers to ensure that assessment practices\nremain robust, learner-centric, and integrity-driven in the evolving landscape\nof GenAI."}
{"id": "2508.12792", "pdf": "https://arxiv.org/pdf/2508.12792", "abs": "https://arxiv.org/abs/2508.12792", "authors": ["Felipe Maia Polo", "Xinhe Wang", "Mikhail Yurochkin", "Gongjun Xu", "Moulinath Banerjee", "Yuekai Sun"], "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large language models are increasingly used as judges (LLM-as-a-judge) to\nevaluate model outputs at scale, but their assessments often diverge\nsystematically from human judgments. We present Bridge, a unified statistical\nframework that explicitly bridges human and LLM evaluations under both absolute\nscoring and pairwise comparison paradigms. Bridge posits a latent human\npreference score for each prompt-response pair and models LLM deviations as\nlinear transformations of covariates that capture sources of discrepancies.\nThis offers a simple and principled framework for refining LLM ratings and\ncharacterizing systematic discrepancies between humans and LLMs. We provide an\nefficient fitting algorithm with asymptotic guarantees for statistical\ninference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot\nArena), Bridge achieves higher agreement with human ratings (accuracy,\ncalibration, and KL divergence) and exposes systematic human-LLM gaps."}
{"id": "2508.11710", "pdf": "https://arxiv.org/pdf/2508.11710", "abs": "https://arxiv.org/abs/2508.11710", "authors": ["Hael Abdulhakim Ali Humran", "Ferdi Sonmez"], "title": "Code Vulnerability Detection Across Different Programming Languages with AI Models", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Security vulnerabilities present in a code that has been written in diverse\nprogramming languages are among the most critical yet complicated aspects of\nsource code to detect. Static analysis tools based on rule-based patterns\nusually do not work well at detecting the context-dependent bugs and lead to\nhigh false positive rates. Recent developments in artificial intelligence,\nspecifically the use of transformer-based models like CodeBERT and CodeLlama,\nprovide light to this problem, as they show potential in finding such flaws\nbetter. This paper presents the implementations of these models on various\ndatasets of code vulnerability, showing how off-the-shelf models can\nsuccessfully produce predictive capacity in models through dynamic fine-tuning\nof the models on vulnerable and safe code fragments. The methodology comprises\nthe gathering of the dataset, normalization of the language, fine-tuning of the\nmodel, and incorporation of ensemble learning and explainable AI. Experiments\nshow that a well-trained CodeBERT can be as good as or even better than some\nexisting static analyzers in terms of accuracy greater than 97%. Further study\nhas indicated that although language models can achieve close-to-perfect\nrecall, the precision can decrease. A solution to this is given by hybrid\nmodels and validation procedures, which will reduce false positives. According\nto the results, the AI-based solutions generalize to different programming\nlanguages and classes of vulnerability. Nevertheless, robustness,\ninterpretability, and deployment readiness are still being developed. The\nresults illustrate the probabilities that AI will enhance the trustworthiness\nin the usability and scalability of machine-learning-based detectors of\nvulnerabilities."}
{"id": "2508.12798", "pdf": "https://arxiv.org/pdf/2508.12798", "abs": "https://arxiv.org/abs/2508.12798", "authors": ["Damian Machlanski", "Stephanie Riley", "Edward Moroshko", "Kurt Butler", "Panagiotis Dimitrakopoulos", "Thomas Melistas", "Akchunya Chanchal", "Steven McDonagh", "Ricardo Silva", "Sotirios A. Tsaftaris"], "title": "A Shift in Perspective on Causality in Domain Generalization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "2 pages, 1 figure, to be presented at the UK AI Research Symposium\n  (UKAIRS) 2025", "summary": "The promise that causal modelling can lead to robust AI generalization has\nbeen challenged in recent work on domain generalization (DG) benchmarks. We\nrevisit the claims of the causality and DG literature, reconciling apparent\ncontradictions and advocating for a more nuanced theory of the role of\ncausality in generalization. We also provide an interactive demo at\nhttps://chai-uk.github.io/ukairs25-causal-predictors/."}
{"id": "2508.11711", "pdf": "https://arxiv.org/pdf/2508.11711", "abs": "https://arxiv.org/abs/2508.11711", "authors": ["Irash Perera", "Hiranya Abeyrathne", "Sanjeewa Malalgoda", "Arshardh Ifthikar"], "title": "Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "GraphQL's flexibility, while beneficial for efficient data fetching,\nintroduces unique security vulnerabilities that traditional API security\nmechanisms often fail to address. Malicious GraphQL queries can exploit the\nlanguage's dynamic nature, leading to denial-of-service attacks, data\nexfiltration through injection, and other exploits. Existing solutions, such as\nstatic analysis, rate limiting, and general-purpose Web Application Firewalls,\noffer limited protection against sophisticated, context-aware attacks. This\npaper presents a novel, AI-driven approach for real-time detection of malicious\nGraphQL queries. Our method combines static analysis with machine learning\ntechniques, including Large Language Models (LLMs) for dynamic schema-based\nconfiguration, Sentence Transformers (SBERT and Doc2Vec) for contextual\nembedding of query payloads, and Convolutional Neural Networks (CNNs), Random\nForests, and Multilayer Perceptrons for classification. We detail the system\narchitecture, implementation strategies optimized for production environments\n(including ONNX Runtime optimization and parallel processing), and evaluate the\nperformance of our detection models and the overall system under load. Results\ndemonstrate high accuracy in detecting various threats, including SQL\ninjection, OS command injection, and XSS exploits, alongside effective\nmitigation of DoS and SSRF attempts. This research contributes a robust and\nadaptable solution for enhancing GraphQL API security."}
{"id": "2508.12801", "pdf": "https://arxiv.org/pdf/2508.12801", "abs": "https://arxiv.org/abs/2508.12801", "authors": ["Bowen Dong", "Yilong Fan", "Yutao Sun", "Zhenyu Li", "Tengyu Pan", "Xun Zhou", "Jianyong Wang"], "title": "Maximum Score Routing For Mixture-of-Experts", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Routing networks in sparsely activated mixture-of-experts (MoE) dynamically\nallocate input tokens to top-k experts through differentiable sparse\ntransformations, enabling scalable model capacity while preserving\ncomputational efficiency. Traditional MoE networks impose an expert capacity\nconstraint to ensure GPU-friendly computation. However, this leads to token\ndropping when capacity is saturated and results in low hardware efficiency due\nto padding in underutilized experts. Removing the capacity constraint, in turn,\ncompromises load balancing and computational efficiency. To address these\nissues, we propose Maximum Score Routing ($\\mathbf{MaxScore}$), a novel MoE\nrouting paradigm that models routing as a minimum-cost maximum-flow problem and\nintegrates a SoftTopk operator. MaxScore resolves the fundamental limitations\nof iterative rerouting and optimal transport formulations, achieving lower\ntraining losses and higher evaluation scores at equivalent FLOPs compared to\nboth constrained and unconstrained baselines. Implementation details and\nexperimental configurations can be obtained from\n$\\href{https://github.com/dongbw18/MaxScore.git}{MaxScore}$."}
{"id": "2508.11715", "pdf": "https://arxiv.org/pdf/2508.11715", "abs": "https://arxiv.org/abs/2508.11715", "authors": ["Ananya Singha", "Harshita Sahijwani", "Walt Williams", "Emmanuel Aboah Boateng", "Nick Hausman", "Miguel Di Luca", "Keegan Choudhury", "Chaya Binet", "Vu Le", "Tianwei Chen", "Oryan Rokeah Chen", "Sulaiman Vesal", "Sadid Hasan"], "title": "Benchmark Dataset Generation and Evaluation for Excel Formula Repair with LLMs", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted at the KDD workshop on Evaluation and Trustworthiness of\n  Agentic and Generative AI Models", "summary": "Excel is a pervasive yet often complex tool, particularly for novice users,\nwhere runtime errors arising from logical mistakes or misinterpretations of\nfunctions pose a significant challenge. While large language models (LLMs)\noffer promising assistance by explaining formula errors, the automated\ncorrection of these semantic runtime errors remains an open problem. A primary\nchallenge to advancing models for such scenarios is the severe lack of\nhigh-quality, comprehensive datasets for training and rigorous evaluation. This\npaper addresses this gap by introducing a novel approach for constructing a\nbenchmark dataset specifically designed for Excel formula repair. We propose a\ndata generation pipeline, which leverages a small set of curated seed samples\nfrom online forums to synthetically expand the dataset. Our pipeline integrates\nfew-shot prompting with LLMs and employs a robust \\textit{LLM-as-a-Judge}\nvalidation framework, combined with execution-based checks to ensure the\ncorrectness and semantic fidelity of the generated data. This process produced\na benchmark dataset of 618 high-quality samples, covering common runtime\nerrors. Furthermore, we propose a context-aware baseline technique for Excel\nformula repair that utilizes LLMs to leverage both the faulty formula, and\nrelevant spreadsheet context. We evaluate the performance of various LLMs\n(GPT-4o, GPT-4.1, Phi-3, Mistral) on our newly generated benchmark using\nexecution-based metrics. Our analysis demonstrates the dataset's quality\nthrough manual annotation and provides insights into error and function\ndistributions. The proposed generation methodology is highly scalable and can\nbe readily adapted to create evaluation benchmarks for similar code repair\ntasks in other low-resource programming languages."}
{"id": "2508.12815", "pdf": "https://arxiv.org/pdf/2508.12815", "abs": "https://arxiv.org/abs/2508.12815", "authors": ["Jayneel Parekh", "Pegah Khayatan", "Mustafa Shukor", "Arnaud Dapogny", "Alasdair Newson", "Matthieu Cord"], "title": "Learning to Steer: Input-dependent Steering for Multimodal LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Steering has emerged as a practical approach to enable post-hoc guidance of\nLLMs towards enforcing a specific behavior. However, it remains largely\nunderexplored for multimodal LLMs (MLLMs); furthermore, existing steering\ntechniques, such as mean steering, rely on a single steering vector, applied\nindependently of the input query. This paradigm faces limitations when the\ndesired behavior is dependent on the example at hand. For example, a safe\nanswer may consist in abstaining from answering when asked for an illegal\nactivity, or may point to external resources or consultation with an expert\nwhen asked about medical advice. In this paper, we investigate a fine-grained\nsteering that uses an input-specific linear shift. This shift is computed using\ncontrastive input-specific prompting. However, the input-specific prompts\nrequired for this approach are not known at test time. Therefore, we propose to\ntrain a small auxiliary module to predict the input-specific steering vector.\nOur approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces\nhallucinations and enforces safety in MLLMs, outperforming other static\nbaselines."}
{"id": "2508.11716", "pdf": "https://arxiv.org/pdf/2508.11716", "abs": "https://arxiv.org/abs/2508.11716", "authors": ["Javier Muñoz-Haro", "Ruben Tolosana", "Ruben Vera-Rodriguez", "Aythami Morales", "Julian Fierrez"], "title": "Privacy-Aware Detection of Fake Identity Documents: Methodology, Benchmark, and Improved Detection Methods (FakeIDet2)", "categories": ["cs.CR", "cs.AI", "cs.CV", "eess.IV"], "comment": null, "summary": "Remote user verification in Internet-based applications is becoming\nincreasingly important nowadays. A popular scenario for it consists of\nsubmitting a picture of the user's Identity Document (ID) to a service\nplatform, authenticating its veracity, and then granting access to the\nrequested digital service. An ID is well-suited to verify the identity of an\nindividual, since it is government issued, unique, and nontransferable.\nHowever, with recent advances in Artificial Intelligence (AI), attackers can\nsurpass security measures in IDs and create very realistic physical and\nsynthetic fake IDs. Researchers are now trying to develop methods to detect an\never-growing number of these AI-based fakes that are almost indistinguishable\nfrom authentic (bona fide) IDs. In this counterattack effort, researchers are\nfaced with an important challenge: the difficulty in using real data to train\nfake ID detectors. This real data scarcity for research and development is\noriginated by the sensitive nature of these documents, which are usually kept\nprivate by the ID owners (the users) and the ID Holders (e.g., government,\npolice, bank, etc.). The main contributions of our study are: 1) We propose and\ndiscuss a patch-based methodology to preserve privacy in fake ID detection\nresearch. 2) We provide a new public database, FakeIDet2-db, comprising over\n900K real/fake ID patches extracted from 2,000 ID images, acquired using\ndifferent smartphone sensors, illumination and height conditions, etc. In\naddition, three physical attacks are considered: print, screen, and composite.\n3) We present a new privacy-aware fake ID detection method, FakeIDet2. 4) We\nrelease a standard reproducible benchmark that considers physical and synthetic\nattacks from popular databases in the literature."}
{"id": "2508.12833", "pdf": "https://arxiv.org/pdf/2508.12833", "abs": "https://arxiv.org/abs/2508.12833", "authors": ["Kichang Lee", "Songkuk Kim", "JaeYeon Park", "JeongGil Ko"], "title": "Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG", "categories": ["cs.LG", "cs.AI", "68Txx", "I.2; I.4.2; E.4"], "comment": "6pages, 6figures", "summary": "On-device machine learning is often constrained by limited storage,\nparticularly in continuous data collection scenarios. This paper presents an\nempirical study on storage-aware learning, focusing on the trade-off between\ndata quantity and quality via compression. We demonstrate that naive\nstrategies, such as uniform data dropping or one-size-fits-all compression, are\nsuboptimal. Our findings further reveal that data samples exhibit varying\nsensitivities to compression, supporting the feasibility of a sample-wise\nadaptive compression strategy. These insights provide a foundation for\ndeveloping a new class of storage-aware learning systems. The primary\ncontribution of this work is the systematic characterization of this\nunder-explored challenge, offering valuable insights that advance the\nunderstanding of storage-aware learning."}
{"id": "2508.11719", "pdf": "https://arxiv.org/pdf/2508.11719", "abs": "https://arxiv.org/abs/2508.11719", "authors": ["Matthias Scheutz"], "title": "Are AI Machines Making Humans Obsolete?", "categories": ["cs.CY", "cs.AI"], "comment": "Forthcoming in Ramana Kumar Vinjamuri (ed.) \"Bridging the Gap between\n  Mind and Machine\", Springer", "summary": "This chapter starts with a sketch of how we got to \"generative AI\" (GenAI)\nand a brief summary of the various impacts it had so far. It then discusses\nsome of the opportunities of GenAI, followed by the challenges and dangers,\nincluding dystopian outcomes resulting from using uncontrolled machine learning\nand our failures to understand the results. It concludes with some suggestions\nfor how to control GenAI and address its dangers."}
{"id": "2508.12837", "pdf": "https://arxiv.org/pdf/2508.12837", "abs": "https://arxiv.org/abs/2508.12837", "authors": ["Aditya Varre", "Gizem Yüce", "Nicolas Flammarion"], "title": "Learning In-context $\\pmb{n}$-grams with Transformers: Sub-$\\pmb{n}$-grams Are Near-stationary Points", "categories": ["cs.LG"], "comment": "ICML2025", "summary": "Motivated by empirical observations of prolonged plateaus and stage-wise\nprogression during training, we investigate the loss landscape of transformer\nmodels trained on in-context next-token prediction tasks. In particular, we\nfocus on learning in-context $n$-gram language models under cross-entropy loss,\nand establish a sufficient condition for parameter configurations to be\nstationary points. We then construct a set of parameter configurations for a\nsimplified transformer model that represent $k$-gram estimators (for $k \\leq\nn$), and show that the gradient of the population loss at these solutions\nvanishes in the limit of infinite sequence length and parameter norm. This\nreveals a key property of the loss landscape: {sub-$n$-grams are\nnear-stationary points of the population cross-entropy loss}, offering\ntheoretical insight into widely observed phenomena such as stage-wise learning\ndynamics and emergent phase transitions. These insights are further supported\nby numerical experiments that illustrate the learning dynamics of $n$-grams,\ncharacterized by discrete transitions between near-stationary solutions."}
{"id": "2508.11721", "pdf": "https://arxiv.org/pdf/2508.11721", "abs": "https://arxiv.org/abs/2508.11721", "authors": ["Ke Zou", "Jocelyn Hui Lin Goh", "Yukun Zhou", "Tian Lin", "Samantha Min Er Yew", "Sahana Srinivasan", "Meng Wang", "Rui Santos", "Gabor M. Somfai", "Huazhu Fu", "Haoyu Chen", "Pearse A. Keane", "Ching-Yu Cheng", "Yih Chung Tham"], "title": "FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 3 figures", "summary": "Foundation models (FMs) have shown great promise in medical image analysis by\nimproving generalization across diverse downstream tasks. In ophthalmology,\nseveral FMs have recently emerged, but there is still no clear answer to\nfundamental questions: Which FM performs the best? Are they equally good across\ndifferent tasks? What if we combine all FMs together? To our knowledge, this is\nthe first study to systematically evaluate both single and fused ophthalmic\nFMs. To address these questions, we propose FusionFM, a comprehensive\nevaluation suite, along with two fusion approaches to integrate different\nophthalmic FMs. Our framework covers both ophthalmic disease detection\n(glaucoma, diabetic retinopathy, and age-related macular degeneration) and\nsystemic disease prediction (diabetes and hypertension) based on retinal\nimaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,\nRetiZero, and DINORET) using standardized datasets from multiple countries and\nevaluated their performance using AUC and F1 metrics. Our results show that\nDINORET and RetiZero achieve superior performance in both ophthalmic and\nsystemic disease tasks, with RetiZero exhibiting stronger generalization on\nexternal datasets. Regarding fusion strategies, the Gating-based approach\nprovides modest improvements in predicting glaucoma, AMD, and hypertension.\nDespite these advances, predicting systemic diseases, especially hypertension\nin external cohort remains challenging. These findings provide an\nevidence-based evaluation of ophthalmic FMs, highlight the benefits of model\nfusion, and point to strategies for enhancing their clinical applicability."}
{"id": "2508.12839", "pdf": "https://arxiv.org/pdf/2508.12839", "abs": "https://arxiv.org/abs/2508.12839", "authors": ["Tiancheng Zhang", "Cheng Zhang", "Shuren Liu", "Xiaofei Wang", "Shaoyuan Huang", "Wenyu Wang"], "title": "HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 14 figures, ECAI2025", "summary": "With the rapid proliferation of streaming services, network load exhibits\nhighly time-varying and bursty behavior, posing serious challenges for\nmaintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms\n(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS\nand profitability, accurate load forecasting remains challenging under traffic\nsurges. Existing methods either minimize mean absolute error, resulting in\nunderprovisioning and potential Service Level Agreement (SLA) violations during\npeak periods, or adopt conservative overprovisioning strategies, which mitigate\nSLA risks at the expense of increased resource expenditure. To address this\ndilemma, we propose HRS, a hybrid representation framework with scheduling\nawareness that integrates numerical and image-based representations to better\ncapture extreme load dynamics. We further introduce a Scheduling-Aware Loss\n(SAL) that captures the asymmetric impact of prediction errors, guiding\npredictions that better support scheduling decisions. Extensive experiments on\nfour real-world datasets demonstrate that HRS consistently outperforms ten\nbaselines and achieves state-of-the-art performance, reducing SLA violation\nrates by 63.1% and total profit loss by 32.3%."}
{"id": "2508.11728", "pdf": "https://arxiv.org/pdf/2508.11728", "abs": "https://arxiv.org/abs/2508.11728", "authors": ["Chunxia Ren", "Ning Zhu", "Yue Lai", "Gui Chen", "Ruijie Wang", "Yangyi Hu", "Suyao Liu", "Shuwen Mao", "Hong Su", "Yu Zhang", "Li Xiao"], "title": "UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "23 pages, 6 figures", "summary": "Dentocraniofacial hard tissue defects profoundly affect patients'\nphysiological functions, facial aesthetics, and psychological well-being,\nposing significant challenges for precise reconstruction. Current deep learning\nmodels are limited to single-tissue scenarios and modality-specific imaging\ninputs, resulting in poor generalizability and trade-offs between anatomical\nfidelity, computational efficiency, and cross-tissue adaptability. Here we\nintroduce UniDCF, a unified framework capable of reconstructing multiple\ndentocraniofacial hard tissues through multimodal fusion encoding of point\nclouds and multi-view images. By leveraging the complementary strengths of each\nmodality and incorporating a score-based denoising module to refine surface\nsmoothness, UniDCF overcomes the limitations of prior single-modality\napproaches. We curated the largest multimodal dataset, comprising intraoral\nscans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated\ninstances. Evaluations demonstrate that UniDCF outperforms existing\nstate-of-the-art methods in terms of geometric precision, structural\ncompleteness, and spatial accuracy. Clinical simulations indicate UniDCF\nreduces reconstruction design time by 99% and achieves clinician-rated\nacceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and\nhigh-fidelity reconstruction, supporting personalized and precise restorative\ntreatments, streamlining clinical workflows, and enhancing patient outcomes."}
{"id": "2508.12885", "pdf": "https://arxiv.org/pdf/2508.12885", "abs": "https://arxiv.org/abs/2508.12885", "authors": ["Aleksei Liuliakov", "Alexander Schulz", "Luca Hermes", "Barbara Hammer"], "title": "One-Class Intrusion Detection with Dynamic Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the growing digitalization all over the globe, the relevance of network\nsecurity becomes increasingly important. Machine learning-based intrusion\ndetection constitutes a promising approach for improving security, but it bears\nseveral challenges. These include the requirement to detect novel and unseen\nnetwork events, as well as specific data properties, such as events over time\ntogether with the inherent graph structure of network communication. In this\nwork, we propose a novel intrusion detection method, TGN-SVDD, which builds\nupon modern dynamic graph modelling and deep anomaly detection. We demonstrate\nits superiority over several baselines for realistic intrusion detection data\nand suggest a more challenging variant of the latter."}
{"id": "2508.11729", "pdf": "https://arxiv.org/pdf/2508.11729", "abs": "https://arxiv.org/abs/2508.11729", "authors": ["Ninell Oldenburg", "Gleb Papyshev"], "title": "The Stories We Govern By: AI, Risk, and the Power of Imaginaries", "categories": ["cs.CY", "cs.AI", "K.4.2"], "comment": "10 pages, accepted at the 8th AAAI/ACM Conference on AI, Ethics, and\n  Society", "summary": "This paper examines how competing sociotechnical imaginaries of artificial\nintelligence (AI) risk shape governance decisions and regulatory constraints.\nDrawing on concepts from science and technology studies, we analyse three\ndominant narrative groups: existential risk proponents, who emphasise\ncatastrophic AGI scenarios; accelerationists, who portray AI as a\ntransformative force to be unleashed; and critical AI scholars, who foreground\npresent-day harms rooted in systemic inequality. Through an analysis of\nrepresentative manifesto-style texts, we explore how these imaginaries differ\nacross four dimensions: normative visions of the future, diagnoses of the\npresent social order, views on science and technology, and perceived human\nagency in managing AI risks. Our findings reveal how these narratives embed\ndistinct assumptions about risk and have the potential to progress into\npolicy-making processes by narrowing the space for alternative governance\napproaches. We argue against speculative dogmatism and for moving beyond\ndeterministic imaginaries toward regulatory strategies that are grounded in\npragmatism."}
{"id": "2508.12905", "pdf": "https://arxiv.org/pdf/2508.12905", "abs": "https://arxiv.org/abs/2508.12905", "authors": ["Ismail Lamaakal", "Chaymae Yahyati", "Khalid El Makkaoui", "Ibrahim Ouahbi", "Yassine Maleh"], "title": "TCUQ: Single-Pass Uncertainty Quantification from Temporal Consistency with Streaming Conformal Calibration for TinyML", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We introduce TCUQ, a single pass, label free uncertainty monitor for\nstreaming TinyML that converts short horizon temporal consistency captured via\nlightweight signals on posteriors and features into a calibrated risk score\nwith an O(W ) ring buffer and O(1) per step updates. A streaming conformal\nlayer turns this score into a budgeted accept/abstain rule, yielding calibrated\nbehavior without online labels or extra forward passes. On microcontrollers,\nTCUQ fits comfortably on kilobyte scale devices and reduces footprint and\nlatency versus early exit and deep ensembles (typically about 50 to 60% smaller\nand about 30 to 45% faster), while methods of similar accuracy often run out of\nmemory. Under corrupted in distribution streams, TCUQ improves accuracy drop\ndetection by 3 to 7 AUPRC points and reaches up to 0.86 AUPRC at high\nseverities; for failure detection it attains up to 0.92 AUROC. These results\nshow that temporal consistency, coupled with streaming conformal calibration,\nprovides a practical and resource efficient foundation for on device monitoring\nin TinyML."}
{"id": "2508.11732", "pdf": "https://arxiv.org/pdf/2508.11732", "abs": "https://arxiv.org/abs/2508.11732", "authors": ["Xiangxiang Cui", "Min Zhao", "Dongmei Zhi", "Shile Qi", "Vince D Calhoun", "Jing Sui"], "title": "BRIEF: BRain-Inspired network connection search with Extensive temporal feature Fusion enhances disease classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing deep learning models for functional MRI-based classification have\nlimitations in network architecture determination (relying on experience) and\nfeature space fusion (mostly simple concatenation, lacking mutual learning).\nInspired by the human brain's mechanism of updating neural connections through\nlearning and decision-making, we proposed a novel BRain-Inspired feature Fusion\n(BRIEF) framework, which is able to optimize network architecture automatically\nby incorporating an improved neural network connection search (NCS) strategy\nand a Transformer-based multi-feature fusion module. Specifically, we first\nextracted 4 types of fMRI temporal representations, i.e., time series (TCs),\nstatic/dynamic functional connection (FNC/dFNC), and multi-scale dispersion\nentropy (MsDE), to construct four encoders. Within each encoder, we employed a\nmodified Q-learning to dynamically optimize the NCS to extract high-level\nfeature vectors, where the NCS is formulated as a Markov Decision Process.\nThen, all feature vectors were fused via a Transformer, leveraging both\nstable/time-varying connections and multi-scale dependencies across different\nbrain regions to achieve the final classification. Additionally, an attention\nmodule was embedded to improve interpretability. The classification performance\nof our proposed BRIEF was compared with 21 state-of-the-art models by\ndiscriminating two mental disorders from healthy controls: schizophrenia (SZ,\nn=1100) and autism spectrum disorder (ASD, n=1550). BRIEF demonstrated\nsignificant improvements of 2.2% to 12.1% compared to 21 algorithms, reaching\nan AUC of 91.5% - 0.6% for SZ and 78.4% - 0.5% for ASD, respectively. This is\nthe first attempt to incorporate a brain-inspired, reinforcement learning\nstrategy to optimize fMRI-based mental disorder classification, showing\nsignificant potential for identifying precise neuroimaging biomarkers."}
{"id": "2508.12906", "pdf": "https://arxiv.org/pdf/2508.12906", "abs": "https://arxiv.org/abs/2508.12906", "authors": ["Boran Zhao", "Haiming Zhai", "Zihang Yuan", "Hetian Liu", "Tian Xia", "Wenzhe Zhao", "Pengju Ren"], "title": "SparseMap: A Sparse Tensor Accelerator Framework Based on Evolution Strategy", "categories": ["cs.LG"], "comment": null, "summary": "The growing demand for sparse tensor algebra (SpTA) in machine learning and\nbig data has driven the development of various sparse tensor accelerators.\nHowever, most existing manually designed accelerators are limited to specific\nscenarios, and it's time-consuming and challenging to adjust a large number of\ndesign factors when scenarios change. Therefore, automating the design of SpTA\naccelerators is crucial. Nevertheless, previous works focus solely on either\nmapping (i.e., tiling communication and computation in space and time) or\nsparse strategy (i.e., bypassing zero elements for efficiency), leading to\nsuboptimal designs due to the lack of comprehensive consideration of both. A\nunified framework that jointly optimizes both is urgently needed. However,\nintegrating mapping and sparse strategies leads to a combinatorial explosion in\nthe design space(e.g., as large as $O(10^{41})$ for the workload $P_{32 \\times\n64} \\times Q_{64 \\times 48} = Z_{32 \\times 48}$). This vast search space\nrenders most conventional optimization methods (e.g., particle swarm\noptimization, reinforcement learning and Monte Carlo tree search) inefficient.\nTo address this challenge, we propose an evolution strategy-based sparse tensor\naccelerator optimization framework, called SparseMap. SparseMap constructing a\nmore comprehensive design space with the consideration of both mapping and\nsparse strategy. We introduce a series of enhancements to genetic encoding and\nevolutionary operators, enabling SparseMap to efficiently explore the vast and\ndiverse design space. We quantitatively compare SparseMap with prior works and\nclassical optimization methods, demonstrating that SparseMap consistently finds\nsuperior solutions."}
{"id": "2508.11733", "pdf": "https://arxiv.org/pdf/2508.11733", "abs": "https://arxiv.org/abs/2508.11733", "authors": ["Ruijia Zhang", "Xinyan Zhao", "Ruixiang Wang", "Sigen Chen", "Guibin Zhang", "An Zhang", "Kun Wang", "Qingsong Wen"], "title": "SafeSieve: From Heuristics to Experience in Progressive Pruning for LLM-based Multi-Agent Communication", "categories": ["cs.MA", "cs.AI"], "comment": "7 pages for main content, 5 figures, 4 tables", "summary": "LLM-based multi-agent systems exhibit strong collaborative capabilities but\noften suffer from redundant communication and excessive token overhead.\nExisting methods typically enhance efficiency through pretrained GNNs or greedy\nalgorithms, but often isolate pre- and post-task optimization, lacking a\nunified strategy. To this end, we present SafeSieve, a progressive and adaptive\nmulti-agent pruning algorithm that dynamically refines the inter-agent\ncommunication through a novel dual-mechanism. SafeSieve integrates initial\nLLM-based semantic evaluation with accumulated performance feedback, enabling a\nsmooth transition from heuristic initialization to experience-driven\nrefinement. Unlike existing greedy Top-k pruning methods, SafeSieve employs\n0-extension clustering to preserve structurally coherent agent groups while\neliminating ineffective links. Experiments across benchmarks (SVAMP, HumanEval,\netc.) showcase that SafeSieve achieves 94.01% average accuracy while reducing\ntoken usage by 12.4%-27.8%. Results further demonstrate robustness under prompt\ninjection attacks (1.23% average accuracy drop). In heterogeneous settings,\nSafeSieve reduces deployment costs by 13.3% while maintaining performance.\nThese results establish SafeSieve as a robust, efficient, and scalable\nframework for practical multi-agent systems. Our code can be found in\nhttps://anonymous.4open.science/r/SafeSieve-D8F2FFUN."}
{"id": "2508.12907", "pdf": "https://arxiv.org/pdf/2508.12907", "abs": "https://arxiv.org/abs/2508.12907", "authors": ["Ismail Lamaakal", "Chaymae Yahyati", "Khalid El Makkaoui", "Ibrahim Ouahbi", "Yassine Maleh"], "title": "SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "We introduce \\textbf{SNAP-UQ}, a single-pass, label-free uncertainty method\nfor TinyML that estimates risk from \\emph{depth-wise next-activation\nprediction}: tiny int8 heads forecast the statistics of the next layer from a\ncompressed view of the previous one, and a lightweight monotone mapper turns\nthe resulting surprisal into an actionable score. The design requires no\ntemporal buffers, auxiliary exits, or repeated forward passes, and adds only a\nfew tens of kilobytes to MCU deployments. Across vision and audio backbones,\nSNAP-UQ consistently reduces flash and latency relative to early-exit and deep\nensembles (typically $\\sim$40--60\\% smaller and $\\sim$25--35\\% faster), with\ncompeting methods of similar accuracy often exceeding memory limits. In\ncorrupted streams it improves accuracy-drop detection by several AUPRC points\nand maintains strong failure detection (AUROC $\\approx$0.9) in a single pass.\nGrounding uncertainty in layer-to-layer dynamics yields a practical,\nresource-efficient basis for on-device monitoring in TinyML."}
{"id": "2508.11737", "pdf": "https://arxiv.org/pdf/2508.11737", "abs": "https://arxiv.org/abs/2508.11737", "authors": ["Shiyin Lu", "Yang Li", "Yu Xia", "Yuwei Hu", "Shanshan Zhao", "Yanqing Ma", "Zhichao Wei", "Yinglun Li", "Lunhao Duan", "Jianshan Zhao", "Yuxuan Han", "Haijun Li", "Wanying Chen", "Junke Tang", "Chengkun Hou", "Zhixing Du", "Tianli Zhou", "Wenjie Zhang", "Huping Ding", "Jiahe Li", "Wen Li", "Gui Hu", "Yiliang Gu", "Siran Yang", "Jiamang Wang", "Hailong Sun", "Yibo Wang", "Hui Sun", "Jinlong Huang", "Yuping He", "Shengze Shi", "Weihong Zhang", "Guodong Zheng", "Junpeng Jiang", "Sensen Gao", "Yi-Feng Wu", "Sijia Chen", "Yuhui Chen", "Qing-Guo Chen", "Zhao Xu", "Weihua Luo", "Kaifu Zhang"], "title": "Ovis2.5 Technical Report", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We present Ovis2.5, a successor to Ovis2 designed for native-resolution\nvisual perception and strong multimodal reasoning. Ovis2.5 integrates a\nnative-resolution vision transformer that processes images at their native,\nvariable resolutions, avoiding the degradation from fixed-resolution tiling and\npreserving both fine detail and global layout -- crucial for visually dense\ncontent like complex charts. To strengthen reasoning, we train the model to\nmove beyond linear chain-of-thought and perform reflection -- including\nself-checking and revision. This advanced capability is exposed as an optional\n\"thinking mode\" at inference time, allowing users to trade latency for enhanced\naccuracy on difficult inputs. The model is trained via a comprehensive\nfive-phase curriculum that progressively builds its skills. The process begins\nwith foundational visual and multimodal pretraining, advances through\nlarge-scale instruction tuning, and culminates in alignment and reasoning\nenhancement using DPO and GRPO. To scale these upgrades efficiently, we employ\nmultimodal data packing and hybrid parallelism, yielding a significant\nend-to-end speedup. We release two open-source models: Ovis2.5-9B and\nOvis2.5-2B. The latter continues the \"small model, big performance\" philosophy\nof Ovis2, making it ideal for resource-constrained, on-device scenarios. On the\nOpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a\nsubstantial improvement over its predecessor, Ovis2-8B, and achieving\nstate-of-the-art results among open-source MLLMs in the sub-40B parameter\nrange; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate\nscores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong\ncapabilities on grounding and video tasks, and achieves open-source SOTA at its\nscale for complex chart analysis."}
{"id": "2508.12978", "pdf": "https://arxiv.org/pdf/2508.12978", "abs": "https://arxiv.org/abs/2508.12978", "authors": ["Yue Xia", "Tayyebeh Jahani-Nezhad", "Rawad Bitar"], "title": "Fed-DPRoC:Communication-Efficient Differentially Private and Robust Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.IT", "math.IT"], "comment": null, "summary": "We propose Fed-DPRoC, a novel federated learning framework that\nsimultaneously ensures differential privacy (DP), Byzantine robustness, and\ncommunication efficiency. We introduce the concept of robust-compatible\ncompression, which enables users to compress DP-protected updates while\nmaintaining the robustness of the aggregation rule. We instantiate our\nframework as RobAJoL, combining the Johnson-Lindenstrauss (JL) transform for\ncompression with robust averaging for robust aggregation. We theoretically\nprove the compatibility of JL transform with robust averaging and show that\nRobAJoL preserves robustness guarantees, ensures DP, and reduces communication\ncost. Experiments on CIFAR-10 and Fashion MNIST validate our theoretical claims\nand demonstrate that RobAJoL outperforms existing methods in terms of\nrobustness and utility under different Byzantine attacks."}
{"id": "2508.11738", "pdf": "https://arxiv.org/pdf/2508.11738", "abs": "https://arxiv.org/abs/2508.11738", "authors": ["Kiruthika Balakrishnan", "Durgadevi Velusamy", "Hana E. Hinkle", "Zhi Li", "Karthikeyan Ramasamy", "Hikmat Khan", "Srini Ramaswamy", "Pir Masoom Shah"], "title": "Artificial Intelligence in Rural Healthcare Delivery: Bridging Gaps and Enhancing Equity through Innovation", "categories": ["cs.CY", "cs.AI", "cs.CV"], "comment": null, "summary": "Rural healthcare faces persistent challenges, including inadequate\ninfrastructure, workforce shortages, and socioeconomic disparities that hinder\naccess to essential services. This study investigates the transformative\npotential of artificial intelligence (AI) in addressing these issues in\nunderserved rural areas. We systematically reviewed 109 studies published\nbetween 2019 and 2024 from PubMed, Embase, Web of Science, IEEE Xplore, and\nScopus. Articles were screened using PRISMA guidelines and Covidence software.\nA thematic analysis was conducted to identify key patterns and insights\nregarding AI implementation in rural healthcare delivery. The findings reveal\nsignificant promise for AI applications, such as predictive analytics,\ntelemedicine platforms, and automated diagnostic tools, in improving healthcare\naccessibility, quality, and efficiency. Among these, advanced AI systems,\nincluding Multimodal Foundation Models (MFMs) and Large Language Models (LLMs),\noffer particularly transformative potential. MFMs integrate diverse data\nsources, such as imaging, clinical records, and bio signals, to support\ncomprehensive decision-making, while LLMs facilitate clinical documentation,\npatient triage, translation, and virtual assistance. Together, these\ntechnologies can revolutionize rural healthcare by augmenting human capacity,\nreducing diagnostic delays, and democratizing access to expertise. However,\nbarriers remain, including infrastructural limitations, data quality concerns,\nand ethical considerations. Addressing these challenges requires\ninterdisciplinary collaboration, investment in digital infrastructure, and the\ndevelopment of regulatory frameworks. This review offers actionable\nrecommendations and highlights areas for future research to ensure equitable\nand sustainable integration of AI in rural healthcare systems."}
{"id": "2508.12984", "pdf": "https://arxiv.org/pdf/2508.12984", "abs": "https://arxiv.org/abs/2508.12984", "authors": ["Zehang Lin", "Zheng Lin", "Miao Yang", "Jianhao Huang", "Yuxin Zhang", "Zihan Fang", "Xia Du", "Zhe Chen", "Shunzhi Zhu", "Wei Ni"], "title": "SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "6 pages, 7 figures", "summary": "The increasing complexity of neural networks poses a significant barrier to\nthe deployment of distributed machine learning (ML) on resource-constrained\ndevices, such as federated learning (FL). Split learning (SL) offers a\npromising solution by offloading the primary computing load from edge devices\nto a server via model partitioning. However, as the number of participating\ndevices increases, the transmission of excessive smashed data (i.e.,\nactivations and gradients) becomes a major bottleneck for SL, slowing down the\nmodel training. To tackle this challenge, we propose a communication-efficient\nSL framework, named SL-ACC, which comprises two key components: adaptive\nchannel importance identification (ACII) and channel grouping compression\n(CGC). ACII first identifies the contribution of each channel in the smashed\ndata to model training using Shannon entropy. Following this, CGC groups the\nchannels based on their entropy and performs group-wise adaptive compression to\nshrink the transmission volume without compromising training accuracy.\nExtensive experiments across various datasets validate that our proposed SL-ACC\nframework takes considerably less time to achieve a target accuracy than\nstate-of-the-art benchmarks."}
{"id": "2508.11758", "pdf": "https://arxiv.org/pdf/2508.11758", "abs": "https://arxiv.org/abs/2508.11758", "authors": ["Jonas van Elburg", "Peter van der Putten", "Maarten Marx"], "title": "Can we Evaluate RAGs with Synthetic Data?", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for the SynDAiTE workshop at the European Conference on\n  Machine Learning and Principles and Practice of Knowledge Discovery in\n  Databases (ECML-PKDD 2025), September 15, 2025 - Porto, Portugal", "summary": "We investigate whether synthetic question-answer (QA) data generated by large\nlanguage models (LLMs) can serve as an effective proxy for human-labeled\nbenchmarks when such data is unavailable. We assess the reliability of\nsynthetic benchmarks across two experiments: one varying retriever parameters\nwhile keeping the generator fixed, and another varying the generator with fixed\nretriever parameters. Across four datasets, of which two open-domain and two\nproprietary, we find that synthetic benchmarks reliably rank the RAGs varying\nin terms of retriever configuration, aligning well with human-labeled benchmark\nbaselines. However, they fail to produce consistent RAG rankings when comparing\ngenerator architectures. The breakdown possibly arises from a combination of\ntask mismatch between the synthetic and human benchmarks, and stylistic bias\nfavoring certain generators."}
{"id": "2508.12993", "pdf": "https://arxiv.org/pdf/2508.12993", "abs": "https://arxiv.org/abs/2508.12993", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Predicting the Performance of Graph Convolutional Networks with Spectral Properties of the Graph Laplacian", "categories": ["cs.LG"], "comment": "9 pages, 3 figures", "summary": "A common observation in the Graph Convolutional Network (GCN) literature is\nthat stacking GCN layers may or may not result in better performance on tasks\nlike node classification and edge prediction. We have found empirically that a\ngraph's algebraic connectivity, which is known as the Fiedler value, is a good\npredictor of GCN performance. Intuitively, graphs with similar Fiedler values\nhave analogous structural properties, suggesting that the same filters and\nhyperparameters may yield similar results when used with GCNs, and that\ntransfer learning may be more effective between graphs with similar algebraic\nconnectivity. We explore this theoretically and empirically with experiments on\nsynthetic and real graph data, including the Cora, CiteSeer and Polblogs\ndatasets. We explore multiple ways of aggregating the Fiedler value for\nconnected components in the graphs to arrive at a value for the entire graph,\nand show that it can be used to predict GCN performance. We also present\ntheoretical arguments as to why the Fiedler value is a good predictor."}
{"id": "2508.11759", "pdf": "https://arxiv.org/pdf/2508.11759", "abs": "https://arxiv.org/abs/2508.11759", "authors": ["Peter Lindes", "Kaoutar Skiker"], "title": "Using Natural Language for Human-Robot Collaboration in the Real World", "categories": ["cs.RO", "cs.AI", "cs.CL"], "comment": "34 pages, 11 figures, 5 tables. Submitted for publication (2026) in\n  W.F. Lawless, Ranjeev Mittu, Shannon P. McGrarry, & Marco Brambilla (Eds.),\n  Generative AI Risks and Benefits within Human-Machine Teams, Elsevier,\n  Chapter 6", "summary": "We have a vision of a day when autonomous robots can collaborate with humans\nas assistants in performing complex tasks in the physical world. This vision\nincludes that the robots will have the ability to communicate with their human\ncollaborators using language that is natural to the humans. Traditional\nInteractive Task Learning (ITL) systems have some of this ability, but the\nlanguage they can understand is very limited. The advent of large language\nmodels (LLMs) provides an opportunity to greatly improve the language\nunderstanding of robots, yet integrating the language abilities of LLMs with\nrobots that operate in the real physical world is a challenging problem.\n  In this chapter we first review briefly a few commercial robot products that\nwork closely with humans, and discuss how they could be much better\ncollaborators with robust language abilities. We then explore how an AI system\nwith a cognitive agent that controls a physical robot at its core, interacts\nwith both a human and an LLM, and accumulates situational knowledge through its\nexperiences, can be a possible approach to reach that vision. We focus on three\nspecific challenges of having the robot understand natural language, and\npresent a simple proof-of-concept experiment using ChatGPT for each. Finally,\nwe discuss what it will take to turn these simple experiments into an\noperational system where LLM-assisted language understanding is a part of an\nintegrated robotic assistant that uses language to collaborate with humans."}
{"id": "2508.12996", "pdf": "https://arxiv.org/pdf/2508.12996", "abs": "https://arxiv.org/abs/2508.12996", "authors": ["Stavros C. Kassinos"], "title": "Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair", "categories": ["cs.LG", "cs.AI", "65K10, 68T07", "I.2.6; G.1.6"], "comment": "54 pages, 8 figures, 19 tables", "summary": "Transformer neural networks are increasingly used for physics-based problems.\nIn data-driven PDE surrogates, training samples from varying boundary and\ninitial conditions can cause erratic losses and spiky gradients; in\nphysics-informed neural networks (PINNs), stiff composite losses amplify this\neffect.\n  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed\nsecond-moment discount beta2 is replaced by a layer-wise dynamic value driven\nby a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an\nexponential moving average (EMA) of past norms, squashed to the interval [0,1).\nSpikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.\nOptions include leaky-AMSGrad (decay), trust-region clipping (max_ratio),\nadaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',\n``exact'). With all features off and bias_correction=``none'', the method is\nexactly Adam.\n  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D\nPINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with\njitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB\nof enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss\nversus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about\n38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller\nvariance. The method remains drop-in, with runtime overhead comparable to Adam\nin testbeds A-C and within single-digit percent in testbed D. It preserves\nAdam-style convergence guarantees while improving robustness under spiky\ngradients."}
{"id": "2508.11800", "pdf": "https://arxiv.org/pdf/2508.11800", "abs": "https://arxiv.org/abs/2508.11800", "authors": ["Michael Bereket", "Jure Leskovec"], "title": "Uncalibrated Reasoning: GRPO Induces Overconfidence for Stochastic Outcomes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has proven remarkably effective at improving the\naccuracy of language models in verifiable and deterministic domains like\nmathematics. Here, we examine if current RL methods are also effective at\noptimizing language models in verifiable domains with stochastic outcomes, like\nscientific experiments. Through applications to synthetic data and real-world\nbiological experiments, we demonstrate that Group Relative Policy Optimization\n(GRPO) induces overconfident probability predictions for binary stochastic\noutcomes, while Proximal Policy Optimization (PPO) and REINFORCE Leave-One-Out\n(RLOO) yield well-calibrated models. We show that removing group standard\nnormalization in GRPO fixes its miscalibration and provide a theoretical\nexplanation for why normalization causes overconfidence. Our results provide\nnew evidence against the use of standard normalization in GRPO and help pave\nthe way for applications of RL for reasoning language models beyond\ndeterministic domains."}
{"id": "2508.12997", "pdf": "https://arxiv.org/pdf/2508.12997", "abs": "https://arxiv.org/abs/2508.12997", "authors": ["Haishun Chen", "Cai Xu", "Jinlong Yu", "Yilin Zhang", "Ziyu Guan", "Wei Zhao"], "title": "Fairness-Aware Multi-view Evidential Learning with Adaptive Prior", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multi-view evidential learning aims to integrate information from multiple\nviews to improve prediction performance and provide trustworthy uncertainty\nesitimation. Most previous methods assume that view-specific evidence learning\nis naturally reliable. However, in practice, the evidence learning process\ntends to be biased. Through empirical analysis on real-world data, we reveal\nthat samples tend to be assigned more evidence to support data-rich classes,\nthereby leading to unreliable uncertainty estimation in predictions. This\nmotivates us to delve into a new Biased Evidential Multi-view Learning (BEML)\nproblem. To this end, we propose Fairness-Aware Multi-view Evidential Learning\n(FAML). FAML first introduces an adaptive prior based on training trajectory,\nwhich acts as a regularization strategy to flexibly calibrate the biased\nevidence learning process. Furthermore, we explicitly incorporate a fairness\nconstraint based on class-wise evidence variance to promote balanced evidence\nallocation. In the multi-view fusion stage, we propose an opinion alignment\nmechanism to mitigate view-specific bias across views, thereby encouraging the\nintegration of consistent and mutually supportive evidence. Extensive\nexperiments on five real-world multi-view datasets demonstrate that FAML\nachieves more balanced evidence allocation and improves both prediction\nperformance and the reliability of uncertainty estimation compared to\nstate-of-the-art methods."}
{"id": "2508.11808", "pdf": "https://arxiv.org/pdf/2508.11808", "abs": "https://arxiv.org/abs/2508.11808", "authors": ["Sahajpreet Singh", "Rongxin Ouyang", "Subhayan Mukerjee", "Kokil Jaidka"], "title": "Labels or Input? Rethinking Augmentation in Multimodal Hate Detection", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY", "cs.MM", "I.2.7; I.2.10"], "comment": "13 pages, 2 figures, 7 tables", "summary": "The modern web is saturated with multimodal content, intensifying the\nchallenge of detecting hateful memes, where harmful intent is often conveyed\nthrough subtle interactions between text and image under the guise of humor or\nsatire. While recent advances in Vision-Language Models (VLMs) show promise,\nthese models lack support for fine-grained supervision and remain susceptible\nto implicit hate speech. In this paper, we present a dual-pronged approach to\nimprove multimodal hate detection. First, we propose a prompt optimization\nframework that systematically varies prompt structure, supervision granularity,\nand training modality. We show that prompt design and label scaling both\ninfluence performance, with structured prompts improving robustness even in\nsmall models, and InternVL2 achieving the best F1-scores across binary and\nscaled settings. Second, we introduce a multimodal data augmentation pipeline\nthat generates 2,479 counterfactually neutral memes by isolating and rewriting\nthe hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,\nsuccessfully reduces spurious correlations and improves classifier\ngeneralization. Our approaches inspire new directions for building synthetic\ndata to train robust and fair vision-language models. Our findings demonstrate\nthat prompt structure and data composition are as critical as model size, and\nthat targeted augmentation can support more trustworthy and context-sensitive\nhate detection."}
{"id": "2508.13006", "pdf": "https://arxiv.org/pdf/2508.13006", "abs": "https://arxiv.org/abs/2508.13006", "authors": ["Pengcheng Hao", "Menghao Waiyan William Zhu", "Ercan Engin Kuruoglu"], "title": "Monte Carlo Functional Regularisation for Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Continual learning (CL) is crucial for the adaptation of neural network\nmodels to new environments. Although outperforming weight-space regularisation\napproaches, the functional regularisation-based CL methods suffer from high\ncomputational costs and large linear approximation errors. In this work, we\npresent a new functional regularisation CL framework, called MCFRCL, which\napproximates model prediction distributions by Monte Carlo (MC) sampling.\nMoreover, three continuous distributions are leveraged to capture the\nstatistical characteristics of the MC samples via moment-based methods.\nAdditionally, both the Wasserstein distance and the Kullback-Leibler (KL)\ndistance are employed to construct the regularisation function. The proposed\nMCFRCL is evaluated against multiple benchmark methods on the MNIST and CIFAR\ndatasets, with simulation results highlighting its effectiveness in both\nprediction accuracy and training efficiency."}
{"id": "2508.11810", "pdf": "https://arxiv.org/pdf/2508.11810", "abs": "https://arxiv.org/abs/2508.11810", "authors": ["Nitish Nagesh", "Salar Shakibhamedan", "Mahdi Bagheri", "Ziyu Wang", "Nima TaheriNejad", "Axel Jantsch", "Amir M. Rahmani"], "title": "FairTabGen: Unifying Counterfactual and Causal Fairness in Synthetic Tabular Data Generation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generating synthetic data is crucial in privacy-sensitive, data-scarce\nsettings, especially for tabular datasets widely used in real-world\napplications. A key challenge is improving counterfactual and causal fairness,\nwhile preserving high utility. We present FairTabGen, a fairness-aware large\nlanguage model-based framework for tabular synthetic data generation. We\nintegrate multiple fairness definitions including counterfactual and causal\nfairness into both its generation and evaluation pipelines. We use in-context\nlearning, prompt refinement, and fairness-aware data curation to balance\nfairness and utility. Across diverse datasets, our method outperforms\nstate-of-the-art GAN-based and LLM-based methods, achieving up to 10%\nimprovements on fairness metrics such as demographic parity and path-specific\ncausal effects while retaining statistical utility. Remarkably, it achieves\nthese gains using less than 20% of the original data, highlighting its\nefficiency in low-data regimes. These results demonstrate a principled and\npractical approach for generating fair and useful synthetic tabular data."}
{"id": "2508.13018", "pdf": "https://arxiv.org/pdf/2508.13018", "abs": "https://arxiv.org/abs/2508.13018", "authors": ["Iam Kim de S. Hermont", "Andre R. Flores", "Rodrigo C. de Lamare"], "title": "Design and Analysis of Robust Adaptive Filtering with the Hyperbolic Tangent Exponential Kernel M-Estimator Function for Active Noise Control", "categories": ["cs.LG"], "comment": "12 figures, 11 pages", "summary": "In this work, we propose a robust adaptive filtering approach for active\nnoise control applications in the presence of impulsive noise. In particular,\nwe develop the filtered-x hyperbolic tangent exponential generalized Kernel\nM-estimate function (FXHEKM) robust adaptive algorithm. A statistical analysis\nof the proposed FXHEKM algorithm is carried out along with a study of its\ncomputational cost. {In order to evaluate the proposed FXHEKM algorithm, the\nmean-square error (MSE) and the average noise reduction (ANR) performance\nmetrics have been adopted.} Numerical results show the efficiency of the\nproposed FXHEKM algorithm to cancel the presence of the additive spurious\nsignals, such as \\textbf{$\\alpha$}-stable noises against competing algorithms."}
{"id": "2508.11824", "pdf": "https://arxiv.org/pdf/2508.11824", "abs": "https://arxiv.org/abs/2508.11824", "authors": ["Satyam Kumar Navneet", "Joydeep Chandra"], "title": "Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.PF"], "comment": null, "summary": "The integration of Large Language Models (LLMs) into software engineering has\nrevolutionized code generation, enabling unprecedented productivity through\npromptware and autonomous AI agents. However, this transformation introduces\nsignificant risks, including insecure code generation, hallucinated outputs,\nirreversible actions, and a lack of transparency and accountability. Incidents\nlike the Replit database deletion underscore the urgent need for robust safety\nand governance mechanisms. This paper comprehensively analyzes the inherent\nchallenges of LLM-assisted code generation, such as vulnerability inheritance,\novertrust, misinterpretation, and the absence of standardized validation and\nrollback protocols. To address these, we propose the SAFE-AI Framework, a\nholistic approach emphasizing Safety, Auditability, Feedback, and\nExplainability. The framework integrates guardrails, sandboxing, runtime\nverification, risk-aware logging, human-in-the-loop systems, and explainable AI\ntechniques to mitigate risks while fostering trust and compliance. We introduce\na novel taxonomy of AI behaviors categorizing suggestive, generative,\nautonomous, and destructive actions to guide risk assessment and oversight.\nAdditionally, we identify open problems, including the lack of standardized\nbenchmarks for code specific hallucinations and autonomy levels, and propose\nfuture research directions for hybrid verification, semantic guardrails, and\nproactive governance tools. Through detailed comparisons of autonomy control,\nprompt engineering, explainability, and governance frameworks, this paper\nprovides a roadmap for responsible AI integration in software engineering,\naligning with emerging regulations like the EU AI Act and Canada's AIDA to\nensure safe, transparent, and accountable AI-driven development."}
{"id": "2508.13030", "pdf": "https://arxiv.org/pdf/2508.13030", "abs": "https://arxiv.org/abs/2508.13030", "authors": ["Bipin Chhetri", "Akbar Siami Namin"], "title": "The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "21 pages, 6 figures,Proceedings of the IEEE International Conference\n  on Computers, Software, & Applications (COMPSAC), EATA Symposium, Toronto,\n  Canada, July 8-11, 2025", "summary": "Cyberattacks are increasing, and securing against such threats is costing\nindustries billions of dollars annually. Threat Modeling, that is,\ncomprehending the consequences of these attacks, can provide critical support\nto cybersecurity professionals, enabling them to take timely action and\nallocate resources that could be used elsewhere. Cybersecurity is heavily\ndependent on threat modeling, as it assists security experts in assessing and\nmitigating risks related to identifying vulnerabilities and threats. Recently,\nthere has been a pressing need for automated methods to assess attack\ndescriptions and forecast the future consequences of the increasing complexity\nof cyberattacks. This study examines how Natural Language Processing (NLP) and\ndeep learning can be applied to analyze the potential impact of cyberattacks by\nleveraging textual descriptions from the MITRE Common Weakness Enumeration\n(CWE) database. We emphasize classifying attack consequences into five\nprincipal categories: Availability, Access Control, Confidentiality, Integrity,\nand Other. This paper investigates the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) in combination with Hierarchical\nAttention Networks (HANs) for Multi-label classification, evaluating their\nperformance in comparison with conventional CNN and LSTM-based models.\nExperimental findings show that BERT achieves an overall accuracy of $0.972$,\nfar higher than conventional deep learning models in multi-label\nclassification. HAN outperforms baseline forms of CNN and LSTM-based models on\nspecific cybersecurity labels. However, BERT consistently achieves better\nprecision and recall, making it more suitable for predicting the consequences\nof a cyberattack."}
{"id": "2508.11829", "pdf": "https://arxiv.org/pdf/2508.11829", "abs": "https://arxiv.org/abs/2508.11829", "authors": ["Leigh Levinson", "Christopher J. Agostino"], "title": "Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "9 pages, 1 figure, submitted to NeurIPS Creative AI track", "summary": "Despite significant advances, AI systems struggle with the frame problem:\ndetermining what information is contextually relevant from an exponentially\nlarge possibility space. We hypothesize that biological rhythms, particularly\nhormonal cycles, serve as natural relevance filters that could address this\nfundamental challenge. We develop a framework that embeds simulated menstrual\nand circadian cycles into Large Language Models through system prompts\ngenerated from periodic functions modeling key hormones including estrogen,\ntestosterone, and cortisol. Across multiple state-of-the-art models, linguistic\nanalysis reveals emotional and stylistic variations that track biological\nphases; sadness peaks during menstruation while happiness dominates ovulation\nand circadian patterns show morning optimism transitioning to nocturnal\nintrospection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates\nsubtle but consistent performance variations aligning with biological\nexpectations, including optimal function in moderate rather than extreme\nhormonal ranges. This methodology provides a novel approach to contextual AI\nwhile revealing how societal biases regarding gender and biology are embedded\nwithin language models."}
{"id": "2508.13040", "pdf": "https://arxiv.org/pdf/2508.13040", "abs": "https://arxiv.org/abs/2508.13040", "authors": ["Varsha Ramineni", "Hossein A. Rahmani", "Emine Yilmaz", "David Barber"], "title": "Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data", "categories": ["cs.LG"], "comment": "9 pages, 3 figures", "summary": "Ensuring fairness in AI systems is critical, especially in high-stakes\ndomains such as lending, hiring, and healthcare. This urgency is reflected in\nemerging global regulations that mandate fairness assessments and independent\nbias audits. However, procuring the necessary complete data for fairness\ntesting remains a significant challenge. In industry settings, legal and\nprivacy concerns restrict the collection of demographic data required to assess\ngroup disparities, and auditors face practical and cultural challenges in\ngaining access to data. In practice, data relevant for fairness testing is\noften split across separate sources: internal datasets held by institutions\nwith predictive attributes, and external public datasets such as census data\ncontaining protected attributes, each providing only partial, marginal\ninformation. Our work seeks to leverage such available separate data to\nestimate model fairness when complete data is inaccessible. We propose\nutilising the available separate data to estimate a set of feasible joint\ndistributions and then compute the set plausible fairness metrics. Through\nsimulation and real experiments, we demonstrate that we can derive meaningful\nbounds on fairness metrics and obtain reliable estimates of the true metric.\nOur results demonstrate that this approach can serve as a practical and\neffective solution for fairness testing in real-world settings where access to\ncomplete data is restricted."}
{"id": "2508.11831", "pdf": "https://arxiv.org/pdf/2508.11831", "abs": "https://arxiv.org/abs/2508.11831", "authors": ["Julia Sammartino", "Libby Barak", "Jing Peng", "Anna Feldman"], "title": "When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection", "categories": ["cs.CL", "cs.AI"], "comment": "RANLP 2025", "summary": "Euphemisms are culturally variable and often ambiguous, posing challenges for\nlanguage models, especially in low-resource settings. This paper investigates\nhow cross-lingual transfer via sequential fine-tuning affects euphemism\ndetection across five languages: English, Spanish, Chinese, Turkish, and\nYoruba. We compare sequential fine-tuning with monolingual and simultaneous\nfine-tuning using XLM-R and mBERT, analyzing how performance is shaped by\nlanguage pairings, typological features, and pretraining coverage. Results show\nthat sequential fine-tuning with a high-resource L1 improves L2 performance,\nespecially for low-resource languages like Yoruba and Turkish. XLM-R achieves\nlarger gains but is more sensitive to pretraining gaps and catastrophic\nforgetting, while mBERT yields more stable, though lower, results. These\nfindings highlight sequential fine-tuning as a simple yet effective strategy\nfor improving euphemism detection in multilingual models, particularly when\nlow-resource languages are involved."}
{"id": "2508.13057", "pdf": "https://arxiv.org/pdf/2508.13057", "abs": "https://arxiv.org/abs/2508.13057", "authors": ["Adolfo González", "Víctor Parada"], "title": "Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models", "categories": ["cs.LG", "cs.AI", "cs.PF", "62M10, 90C59, 68T05", "I.2.6; I.5.1; I.5.2; I.5.4; G.1.6"], "comment": "31 pages, 15 figures, 110 tables. Submitted as a preprint. The\n  manuscript introduces the Hierarchical Evaluation Function (HEF), a\n  multi-metric framework for optimizing demand forecasting models under high\n  uncertainty. Includes extensive experimental validation using real-world\n  datasets and a comparative analysis against classical and modern methods", "summary": "Demand forecasting is essential for strategic planning in competitive\nenvironments, enabling resource optimization and improved responsiveness to\nmarket dynamics. However, multivariate time series modeling faces challenges\ndue to data complexity, uncertainty, and frequent regime shifts. Traditional\nevaluation metrics can introduce biases and limit generalization. This work\ncompares two custom evaluation functions: FMAE (Focused Mean Absolute Error),\nfocused on minimizing absolute errors, and HEF (Hierarchical Evaluation\nFunction), designed to weight global metrics and penalize large deviations.\nExperiments were conducted under different data splits (91:9, 80:20, 70:30)\nusing three optimizers (Grid Search, PSO, Optuna), assessing fit, relative\naccuracy, robustness, and computational efficiency. Results show that HEF\nconsistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,\nRMSSE), enhancing model robustness and explanatory power. These findings were\nconfirmed via visualizations and statistical tests. Conversely, FMAE offers\nadvantages in local metrics (MAE, MASE) and execution time, making it suitable\nfor short-term scenarios. The study highlights a methodological trade-off: HEF\nis ideal for strategic planning, while FMAE is better suited for operational\nefficiency. A replicable framework is proposed for optimizing predictive models\nin dynamic environments."}
{"id": "2508.11834", "pdf": "https://arxiv.org/pdf/2508.11834", "abs": "https://arxiv.org/abs/2508.11834", "authors": ["Hamza Kheddar", "Yassine Habchi", "Mohamed Chahine Ghanem", "Mustapha Hemis", "Dusit Niyato"], "title": "Recent Advances in Transformer and Large Language Models for UAV Applications", "categories": ["cs.CV", "cs.AI", "cs.RO", "cs.SY", "eess.IV", "eess.SY"], "comment": null, "summary": "The rapid advancement of Transformer-based models has reshaped the landscape\nof uncrewed aerial vehicle (UAV) systems by enhancing perception,\ndecision-making, and autonomy. This review paper systematically categorizes and\nevaluates recent developments in Transformer architectures applied to UAVs,\nincluding attention mechanisms, CNN-Transformer hybrids, reinforcement learning\nTransformers, and large language models (LLMs). Unlike previous surveys, this\nwork presents a unified taxonomy of Transformer-based UAV models, highlights\nemerging applications such as precision agriculture and autonomous navigation,\nand provides comparative analyses through structured tables and performance\nbenchmarks. The paper also reviews key datasets, simulators, and evaluation\nmetrics used in the field. Furthermore, it identifies existing gaps in the\nliterature, outlines critical challenges in computational efficiency and\nreal-time deployment, and offers future research directions. This comprehensive\nsynthesis aims to guide researchers and practitioners in understanding and\nadvancing Transformer-driven UAV technologies."}
{"id": "2508.13088", "pdf": "https://arxiv.org/pdf/2508.13088", "abs": "https://arxiv.org/abs/2508.13088", "authors": ["Xiaohan Wang", "Zhimin Li", "Joshua A. Levine", "Matthew Berger"], "title": "Seeing the Many: Exploring Parameter Distributions Conditioned on Features in Surrogates", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Recently, neural surrogate models have emerged as a compelling alternative to\ntraditional simulation workflows. This is accomplished by modeling the\nunderlying function of scientific simulations, removing the need to run\nexpensive simulations. Beyond just mapping from input parameter to output,\nsurrogates have also been shown useful for inverse problems: output to input\nparameters. Inverse problems can be understood as search, where we aim to find\nparameters whose surrogate outputs contain a specified feature. Yet finding\nthese parameters can be costly, especially for high-dimensional parameter\nspaces. Thus, existing surrogate-based solutions primarily focus on finding a\nsmall set of matching parameters, in the process overlooking the broader\npicture of plausible parameters. Our work aims to model and visualize the\ndistribution of possible input parameters that produce a given output feature.\nTo achieve this goal, we aim to address two challenges: (1) the approximation\nerror inherent in the surrogate model and (2) forming the parameter\ndistribution in an interactive manner. We model error via density estimation,\nreporting high density only if a given parameter configuration is close to\ntraining parameters, measured both over the input and output space. Our density\nestimate is used to form a prior belief on parameters, and when combined with a\nlikelihood on features, gives us an efficient way to sample plausible parameter\nconfigurations that generate a target output feature. We demonstrate the\nusability of our solution through a visualization interface by performing\nfeature-driven parameter analysis over the input parameter space of three\nsimulation datasets. Source code is available at\nhttps://github.com/matthewberger/seeing-the-many"}
{"id": "2508.11845", "pdf": "https://arxiv.org/pdf/2508.11845", "abs": "https://arxiv.org/abs/2508.11845", "authors": ["Marius Miron", "David Robinson", "Milad Alizadeh", "Ellen Gilsenan-McMahon", "Gagan Narula", "Olivier Pietquin", "Matthieu Geist", "Emmanuel Chemla", "Maddie Cusimano", "Felix Effenberger", "Masato Hagiwara", "Benjamin Hoffman", "Sara Keen", "Diane Kim", "Jane Lawton", "Jen-Yu Liu", "Aza Raskin"], "title": "What Matters for Bioacoustic Encoding", "categories": ["cs.SD", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Bioacoustics, the study of sounds produced by living organisms, plays a vital\nrole in conservation, biodiversity monitoring, and behavioral studies. Many\ntasks in this field, such as species, individual, and behavior classification\nand detection, are well-suited to machine learning. However, they often suffer\nfrom limited annotated data, highlighting the need for a general-purpose\nbioacoustic encoder capable of extracting useful representations for diverse\ndownstream tasks. Such encoders have been proposed before, but are often\nlimited in scope due to a focus on a narrow range of species (typically birds),\nand a reliance on a single model architecture or training paradigm. Moreover,\nthey are usually evaluated on a small set of tasks and datasets. In this work,\nwe present a large-scale empirical study that covers aspects of bioacoustics\nthat are relevant to research but have previously been scarcely considered:\ntraining data diversity and scale, model architectures and training recipes,\nand the breadth of evaluation tasks and datasets. We obtain encoders that are\nstate-of-the-art on the existing and proposed benchmarks. We also identify what\nmatters for training these encoders, such that this work can be extended when\nmore data are available or better architectures are proposed. Specifically,\nacross 26 datasets with tasks including species classification, detection,\nindividual ID, and vocal repertoire discovery, we find self-supervised\npre-training followed by supervised post-training on a mixed bioacoustics +\ngeneral-audio corpus yields the strongest in- and out-of-distribution\nperformance. We show the importance of data diversity in both stages. To\nsupport ongoing research and application, we will release the model\ncheckpoints."}
{"id": "2508.13099", "pdf": "https://arxiv.org/pdf/2508.13099", "abs": "https://arxiv.org/abs/2508.13099", "authors": ["Mingyu Kim", "Daniel Stilwell", "Jorge Jimenez"], "title": "Outlier Detection of Poisson-Distributed Targets Using a Seabed Sensor Network", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "IEEE OCEANS", "summary": "This paper presents a framework for classifying and detecting spatial\ncommission outliers in maritime environments using seabed acoustic sensor\nnetworks and log Gaussian Cox processes (LGCPs). By modeling target arrivals as\na mixture of normal and outlier processes, we estimate the probability that a\nnewly observed event is an outlier. We propose a second-order approximation of\nthis probability that incorporates both the mean and variance of the normal\nintensity function, providing improved classification accuracy compared to\nmean-only approaches. We analytically show that our method yields a tighter\nbound to the true probability using Jensen's inequality. To enhance detection,\nwe integrate a real-time, near-optimal sensor placement strategy that\ndynamically adjusts sensor locations based on the evolving outlier intensity.\nThe proposed framework is validated using real ship traffic data near Norfolk,\nVirginia, where numerical results demonstrate the effectiveness of our approach\nin improving both classification performance and outlier detection through\nsensor deployment."}
{"id": "2508.11857", "pdf": "https://arxiv.org/pdf/2508.11857", "abs": "https://arxiv.org/abs/2508.11857", "authors": ["Andrei-Valentin Tănase", "Elena Pelican"], "title": "SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Tokenization remains a fundamental yet underexplored bottleneck in natural\nlanguage processing, with strategies largely static despite remarkable progress\nin model architectures. We present SupraTok, a novel tokenization architecture\nthat reimagines subword segmentation through three innovations: cross-boundary\npattern learning that discovers multi-word semantic units, entropy-driven data\ncuration that optimizes training corpus quality, and multi-phase curriculum\nlearning for stable convergence. Our approach extends Byte-Pair Encoding by\nlearning \"superword\" tokens, coherent multi-word expressions that preserve\nsemantic unity while maximizing compression efficiency. SupraTok achieves 31%\nimprovement in English tokenization efficiency (5.91 versus 4.51 characters per\ntoken) compared to OpenAI's o200k tokenizer and 30% improvement over Google's\nGemma 3 tokenizer (256k vocabulary), while maintaining competitive performance\nacross 38 languages. When integrated with a GPT-2 scale model (124M parameters)\ntrained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%\nimprovement on HellaSWAG and 9.5% on MMLU benchmarks without architectural\nmodifications. While these results are promising at this scale, further\nvalidation at larger model scales is needed. These findings suggest that\nefficient tokenization can complement architectural innovations as a path to\nimproved language model performance."}
{"id": "2508.13100", "pdf": "https://arxiv.org/pdf/2508.13100", "abs": "https://arxiv.org/abs/2508.13100", "authors": ["Jason Hartline", "Lunjia Hu", "Yifan Wu"], "title": "A Perfectly Truthful Calibration Measure", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "Calibration requires that predictions are conditionally unbiased and,\ntherefore, reliably interpretable as probabilities. Calibration measures\nquantify how far a predictor is from perfect calibration. As introduced by\nHaghtalab et al. (2024), a calibration measure is truthful if it is minimized\nin expectation when a predictor outputs the ground-truth probabilities.\nAlthough predicting the true probabilities guarantees perfect calibration, in\nreality, when calibration is evaluated on a finite sample, predicting the truth\nis not guaranteed to minimize any known calibration measure. All known\ncalibration measures incentivize predictors to lie in order to appear more\ncalibrated on a finite sample. Such lack of truthfulness motivated Haghtalab et\nal. (2024) and Qiao and Zhao (2025) to construct approximately truthful\ncalibration measures in the sequential prediction setting, but no perfectly\ntruthful calibration measure was known to exist even in the more basic batch\nsetting.\n  We design a perfectly truthful calibration measure in the batch setting:\naveraged two-bin calibration error (ATB). In addition to being truthful, ATB is\nsound, complete, continuous, and quadratically related to two existing\ncalibration measures: the smooth calibration error (smCal) and the (lower)\ndistance to calibration (distCal). The simplicity in our definition of ATB\nmakes it efficient and straightforward to compute. ATB allows faster estimation\nalgorithms with significantly easier implementations than smCal and distCal,\nachieving improved running time and simplicity for the calibration testing\nproblem studied by Hu et al. (2024). We also introduce a general recipe for\nconstructing truthful measures, which proves the truthfulness of ATB as a\nspecial case and allows us to construct other truthful calibration measures\nsuch as quantile-binned l_2-ECE."}
{"id": "2508.11867", "pdf": "https://arxiv.org/pdf/2508.11867", "abs": "https://arxiv.org/abs/2508.11867", "authors": ["Mohammad Baqar", "Saba Naqvi", "Rajat Khanda"], "title": "AI-Augmented CI/CD Pipelines: From Code Commit to Production with Autonomous Decisions", "categories": ["cs.SE", "cs.AI"], "comment": "13 Pages", "summary": "Modern software delivery has accelerated from quarterly releases to multiple\ndeployments per day. While CI/CD tooling has matured, human decision points\ninterpreting flaky tests, choosing rollback strategies, tuning feature flags,\nand deciding when to promote a canary remain major sources of latency and\noperational toil. We propose AI-Augmented CI/CD Pipelines, where large language\nmodels (LLMs) and autonomous agents act as policy-bounded co-pilots and\nprogressively as decision makers. We contribute: (1) a reference architecture\nfor embedding agentic decision points into CI/CD, (2) a decision taxonomy and\npolicy-as-code guardrail pattern, (3) a trust-tier framework for staged\nautonomy, (4) an evaluation methodology using DevOps Research and Assessment (\nDORA) metrics and AI-specific indicators, and (5) a detailed industrial-style\ncase study migrating a React 19 microservice to an AI-augmented pipeline. We\ndiscuss ethics, verification, auditability, and threats to validity, and chart\na roadmap for verifiable autonomy in production delivery systems."}
{"id": "2508.13111", "pdf": "https://arxiv.org/pdf/2508.13111", "abs": "https://arxiv.org/abs/2508.13111", "authors": ["Michael Mayr", "Georgios C. Chasparis"], "title": "Causally-Guided Pairwise Transformer -- Towards Foundational Digital Twins in Process Industry", "categories": ["cs.LG"], "comment": "12 pages, 2 figures, 4 tables", "summary": "Foundational modelling of multi-dimensional time-series data in industrial\nsystems presents a central trade-off: channel-dependent (CD) models capture\nspecific cross-variable dynamics but lack robustness and adaptability as model\nlayers are commonly bound to the data dimensionality of the tackled use-case,\nwhile channel-independent (CI) models offer generality at the cost of modelling\nthe explicit interactions crucial for system-level predictive regression tasks.\nTo resolve this, we propose the Causally-Guided Pairwise Transformer (CGPT), a\nnovel architecture that integrates a known causal graph as an inductive bias.\nThe core of CGPT is built around a pairwise modeling paradigm, tackling the\nCD/CI conflict by decomposing the multidimensional data into pairs. The model\nuses channel-agnostic learnable layers where all parameter dimensions are\nindependent of the number of variables. CGPT enforces a CD information flow at\nthe pair-level and CI-like generalization across pairs. This approach\ndisentangles complex system dynamics and results in a highly flexible\narchitecture that ensures scalability and any-variate adaptability. We validate\nCGPT on a suite of synthetic and real-world industrial datasets on long-term\nand one-step forecasting tasks designed to simulate common industrial\ncomplexities. Results demonstrate that CGPT significantly outperforms both CI\nand CD baselines in predictive accuracy and shows competitive performance with\nend-to-end trained CD models while remaining agnostic to the problem\ndimensionality."}
{"id": "2508.11868", "pdf": "https://arxiv.org/pdf/2508.11868", "abs": "https://arxiv.org/abs/2508.11868", "authors": ["Lida Xu"], "title": "Data Shift of Object Detection in Autonomous Driving", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": null, "summary": "With the widespread adoption of machine learning technologies in autonomous\ndriving systems, their role in addressing complex environmental perception\nchallenges has become increasingly crucial. However, existing machine learning\nmodels exhibit significant vulnerability, as their performance critically\ndepends on the fundamental assumption that training and testing data satisfy\nthe independent and identically distributed condition, which is difficult to\nguarantee in real-world applications. Dynamic variations in data distribution\ncaused by seasonal changes, weather fluctuations lead to data shift problems in\nautonomous driving systems. This study investigates the data shift problem in\nautonomous driving object detection tasks, systematically analyzing its\ncomplexity and diverse manifestations. We conduct a comprehensive review of\ndata shift detection methods and employ shift detection analysis techniques to\nperform dataset categorization and balancing. Building upon this foundation, we\nconstruct an object detection model. To validate our approach, we optimize the\nmodel by integrating CycleGAN-based data augmentation techniques with the\nYOLOv5 framework. Experimental results demonstrate that our method achieves\nsuperior performance compared to baseline models on the BDD100K dataset."}
{"id": "2508.13113", "pdf": "https://arxiv.org/pdf/2508.13113", "abs": "https://arxiv.org/abs/2508.13113", "authors": ["Alicja Ziarko", "Michal Bortkiewicz", "Michal Zawalski", "Benjamin Eysenbach", "Piotr Milos"], "title": "Contrastive Representations for Temporal Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "Project website: https://princeton-rl.github.io/CRTR/", "summary": "In classical AI, perception relies on learning state-based representations,\nwhile planning, which can be thought of as temporal reasoning over action\nsequences, is typically achieved through search. We study whether such\nreasoning can instead emerge from representations that capture both perceptual\nand temporal structure. We show that standard temporal contrastive learning,\ndespite its popularity, often fails to capture temporal structure due to its\nreliance on spurious features. To address this, we introduce Combinatorial\nRepresentations for Temporal Reasoning (CRTR), a method that uses a negative\nsampling scheme to provably remove these spurious features and facilitate\ntemporal reasoning. CRTR achieves strong results on domains with complex\ntemporal structure, such as Sokoban and Rubik's Cube. In particular, for the\nRubik's Cube, CRTR learns representations that generalize across all initial\nstates and allow it to solve the puzzle using fewer search steps than BestFS,\nthough with longer solutions. To our knowledge, this is the first method that\nefficiently solves arbitrary Cube states using only learned representations,\nwithout relying on an external search algorithm."}
{"id": "2508.11870", "pdf": "https://arxiv.org/pdf/2508.11870", "abs": "https://arxiv.org/abs/2508.11870", "authors": ["Ying Huang", "Yuanbin Man", "Wenqi Jia", "Zhengzhong Tu", "Junzhou Huang", "Miao Yin"], "title": "AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Adapter-based fine-tuning has gained remarkable attention in adapting large\npre-trained vision language models (VLMs) for a wide range of downstream tasks\nefficiently. In this paradigm, only the inserted adapters are fine-tuned,\nwithout the need for training the original VLM backbone. Existing works scale\nadapters by integrating them into every layer of VLMs to increase the capacity\nof adapters. However, these methods face two primary limitations: 1) limited\ncompression rate due to ignoring cross-layer redundancy, and 2) limited\nrepresentational capacity across homogeneous adapters. In this paper, we\npropose a novel vision-language fine-tuning framework based on cross-layer\ntensor ring decomposition (TRD) with the integration and collaboration of\ndiverse adapters, called AdaRing, achieving ultra-light parameter-efficient\nadaptation of VLMs on various tasks. To remove the high redundancy that exists\namong adapters across layers, we exploit the tensor-level low-rankness to\nformulate adapters as layer-shared tensor cores and layer-specific slices.\nMoreover, guided by generalization-aware fine-tuning, diverse rank-driven\nadapters cooperate to handle tasks that require different representations. Our\nexperiments show that the proposed AdaRing achieves the state-of-the-art\nperformance while reducing average training parameters by 90%."}
{"id": "2508.13135", "pdf": "https://arxiv.org/pdf/2508.13135", "abs": "https://arxiv.org/abs/2508.13135", "authors": ["Yueyang Liu", "Lance Kennedy", "Ruochen Kong", "Joon-Seok Kim", "Andreas Züfle"], "title": "Training Machine Learning Models on Human Spatio-temporal Mobility Data: An Experimental Study [Experiment Paper]", "categories": ["cs.LG"], "comment": null, "summary": "Individual-level human mobility prediction has emerged as a significant topic\nof research with applications in infectious disease monitoring, child, and\nelderly care. Existing studies predominantly focus on the microscopic aspects\nof human trajectories: such as predicting short-term trajectories or the next\nlocation visited, while offering limited attention to macro-level mobility\npatterns and the corresponding life routines. In this paper, we focus on an\nunderexplored problem in human mobility prediction: determining the best\npractices to train a machine learning model using historical data to forecast\nan individuals complete trajectory over the next days and weeks. In this\nexperiment paper, we undertake a comprehensive experimental analysis of diverse\nmodels, parameter configurations, and training strategies, accompanied by an\nin-depth examination of the statistical distribution inherent in human mobility\npatterns. Our empirical evaluations encompass both Long Short-Term Memory and\nTransformer-based architectures, and further investigate how incorporating\nindividual life patterns can enhance the effectiveness of the prediction. We\nshow that explicitly including semantic information such as day-of-the-week and\nuser-specific historical information can help the model better understand\nindividual patterns of life and improve predictions. Moreover, since the\nabsence of explicit user information is often missing due to user privacy, we\nshow that the sampling of users may exacerbate data skewness and result in a\nsubstantial loss in predictive accuracy. To mitigate data imbalance and\npreserve diversity, we apply user semantic clustering with stratified sampling\nto ensure that the sampled dataset remains representative. Our results further\nshow that small-batch stochastic gradient optimization improves model\nperformance, especially when human mobility training data is limited."}
{"id": "2508.11872", "pdf": "https://arxiv.org/pdf/2508.11872", "abs": "https://arxiv.org/abs/2508.11872", "authors": ["Xinxing Wu"], "title": "Singing Syllabi with Virtual Avatars: Enhancing Student Engagement Through AI-Generated Music and Digital Embodiment", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.MM"], "comment": "17 pages, 4 figures, 3 tables", "summary": "In practical teaching, we observe that few students thoroughly read or fully\ncomprehend the information provided in traditional, text-based course syllabi.\nAs a result, essential details, such as course policies and learning outcomes,\nare frequently overlooked. To address this challenge, in this paper, we propose\na novel approach leveraging AI-generated singing and virtual avatars to present\nsyllabi in a format that is more visually appealing, engaging, and memorable.\nEspecially, we leveraged the open-source tool, HeyGem, to transform textual\nsyllabi into audiovisual presentations, in which digital avatars perform the\nsyllabus content as songs. The proposed approach aims to stimulate students'\ncuriosity, foster emotional connection, and enhance retention of critical\ncourse information. Student feedback indicated that AI-sung syllabi\nsignificantly improved awareness and recall of key course information."}
{"id": "2508.13148", "pdf": "https://arxiv.org/pdf/2508.13148", "abs": "https://arxiv.org/abs/2508.13148", "authors": ["Haoyu He", "Katrin Renz", "Yong Cao", "Andreas Geiger"], "title": "MDPO: Overcoming the Training-Inference Divide of Masked Diffusion Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion language models, as a promising alternative to traditional\nautoregressive (AR) models, enable faster generation and richer conditioning on\nbidirectional context. However, they suffer from a key discrepancy between\ntraining and inference: during inference, MDLMs progressively reveal the\nstructure of the generated sequence by producing fewer and fewer masked tokens,\nwhereas this structure is ignored in training as tokens are masked at random.\nAlthough this discrepancy between training and inference can lead to suboptimal\nperformance, it has been largely overlooked by previous works, leaving closing\nthis gap between the two stages an open problem. To address this, we frame the\nproblem of learning effective denoising trajectories as a sequential\ndecision-making problem and use the resulting framework to apply reinforcement\nlearning. We propose a novel Masked Diffusion Policy Optimization (MDPO) to\nexploit the Markov property diffusion possesses and explicitly train the model\nunder the same progressive refining schedule used at inference. MDPO matches\nthe performance of the previous state-of-the-art (SOTA) method with 60x fewer\ngradient updates, while achieving average improvements of 9.6% on MATH500 and\n54.2% on Countdown over SOTA when trained within the same number of weight\nupdates. Additionally, we improve the remasking strategy of MDLMs as a plug-in\ninference replacement to overcome the limitation that the model cannot refine\ntokens flexibly. This simple yet effective training-free strategy, what we\nrefer to as RCR, consistently improves performance and yields additional gains\nwhen combined with MDPO. Our findings establish great potential for\ninvestigating the discrepancy between pre-training and inference of MDLMs.\nCode: https://github.com/autonomousvision/mdpo. Project Page:\nhttps://cli212.github.io/MDPO/."}
{"id": "2508.11873", "pdf": "https://arxiv.org/pdf/2508.11873", "abs": "https://arxiv.org/abs/2508.11873", "authors": ["Truong Thanh Hung Nguyen", "Tran Diem Quynh Nguyen", "Hoang Loc Cao", "Thi Cam Thanh Tran", "Thi Cam Mai Truong", "Hung Cao"], "title": "SimInterview: Transforming Business Education through Large Language Model-Based Simulated Multilingual Interview Training System", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.MM"], "comment": "Published as a conference paper at ICEFM 2025", "summary": "Business interview preparation demands both solid theoretical grounding and\nrefined soft skills, yet conventional classroom methods rarely deliver the\nindividualized, culturally aware practice employers currently expect. This\npaper introduces SimInterview, a large language model (LLM)-based simulated\nmultilingual interview training system designed for business professionals\nentering the AI-transformed labor market. Our system leverages an LLM agent and\nsynthetic AI technologies to create realistic virtual recruiters capable of\nconducting personalized, real-time conversational interviews. The framework\ndynamically adapts interview scenarios using retrieval-augmented generation\n(RAG) to match individual resumes with specific job requirements across\nmultiple languages. Built on LLMs (OpenAI o3, Llama 4 Maverick, Gemma 3),\nintegrated with Whisper speech recognition, GPT-SoVITS voice synthesis, Ditto\ndiffusion-based talking head generation model, and ChromaDB vector databases,\nour system significantly improves interview readiness across English and\nJapanese markets. Experiments with university-level candidates show that the\nsystem consistently aligns its assessments with job requirements, faithfully\npreserves resume content, and earns high satisfaction ratings, with the\nlightweight Gemma 3 model producing the most engaging conversations.\nQualitative findings revealed that the standardized Japanese resume format\nimproved document retrieval while diverse English resumes introduced additional\nvariability, and they highlighted how cultural norms shape follow-up\nquestioning strategies. Finally, we also outlined a contestable AI design that\ncan explain, detect bias, and preserve human-in-the-loop to meet emerging\nregulatory expectations."}
{"id": "2508.09395", "pdf": "https://arxiv.org/pdf/2508.09395", "abs": "https://arxiv.org/abs/2508.09395", "authors": ["Quentin Ploussard", "Xiang Li", "Matija Pavičević"], "title": "Tightening the mixed integer linear formulation for the piecewise linear approximation in general dimensions", "categories": ["math.OC", "cs.CG", "cs.DM", "cs.LG"], "comment": "Added Acknowledgements and U.S. Government license disclaimer", "summary": "This paper addresses the problem of tightening the mixed-integer linear\nprogramming (MILP) formulation for continuous piecewise linear (CPWL)\napproximations of data sets in arbitrary dimensions. The MILP formulation\nleverages the difference-of-convex (DC) representation of CPWL functions. We\nintroduce the concept of well-behaved CPWL interpolations and demonstrate that\nany CPWL interpolation of a data set has a well-behaved version. This result is\ncritical to tighten the MILP problem. We present six different strategies to\ntighten the problem, which include fixing the values of some variables,\nintroducing additional constraints, identifying small big-M parameter values\nand applying tighter variable bounds. These methods leverage key aspects of the\nDC representation and the inherent structure of well-behaved CPWL\ninterpolations. Experimental results demonstrate that specific combinations of\nthese tightening strategies lead to significant improvement in solution times,\nespecially for tightening strategies that consider well-behaved CPWL solutions."}
{"id": "2508.11874", "pdf": "https://arxiv.org/pdf/2508.11874", "abs": "https://arxiv.org/abs/2508.11874", "authors": ["Hanyu Li", "Dongchen Li", "Xiaotie Deng"], "title": "Discovering Expert-Level Nash Equilibrium Algorithms with Large Language Models", "categories": ["cs.GT", "cs.AI", "cs.DS", "cs.LO", "cs.PL"], "comment": null, "summary": "Algorithm design and analysis is a cornerstone of computer science, but it\nconfronts a major challenge. Proving an algorithm's performance guarantee\nacross all inputs has traditionally required extensive and often error-prone\nhuman effort. While AI has shown great success in finding solutions to specific\nproblem instances, automating the discovery of general algorithms with such\nprovable guarantees has remained a significant barrier. This challenge stems\nfrom the difficulty of integrating the creative process of algorithm design\nwith the rigorous process of formal analysis. To address this gap, we propose\nLegoNE, a framework that tightly fuses these two processes for the fundamental\nand notoriously difficult problem of computing approximate Nash equilibria.\nLegoNE automatically translates any algorithm written by a simple Python-like\nlanguage into a constrained optimization problem. Solving this problem derives\nand proves the algorithm's approximation bound. Using LegoNE, a\nstate-of-the-art large language model rediscovered the state-of-the-art\nalgorithm for two-player games within hours, a feat that had taken human\nresearchers 15 years to achieve. For three-player games, the model discovered a\nnovel algorithm surpassing all existing human-designed ones. This work\ndemonstrates a new human-machine collaborative paradigm for theoretical\nscience: humans reason at a higher-abstract level, using symbols to compress\nthe search space, and AI explores within it, achieving what neither could\nalone."}
{"id": "2508.11640", "pdf": "https://arxiv.org/pdf/2508.11640", "abs": "https://arxiv.org/abs/2508.11640", "authors": ["Danny Scott", "William LaForest", "Hritom Das", "Ioannis Polykretis", "Catherine D. Schuman", "Charles Rizzo", "James Plank", "Sai Swaminathan"], "title": "Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.LG"], "comment": "International Conference on Neuromorphic Systems (ICONS) 2025 9\n  pages, 7 images", "summary": "The deployment of dense, low-cost sensors is critical for realizing\nubiquitous smart environments. However, existing sensing solutions struggle\nwith the energy, scalability, and reliability trade-offs imposed by battery\nmaintenance, wireless transmission overhead, and data processing complexity. In\nthis work, we present Vibe2Spike, a novel battery-free, wireless sensing\nframework that enables vibration-based activity recognition using visible light\ncommunication (VLC) and spiking neural networks (SNNs). Our system uses\nultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and\nan LED, which harvest vibration energy and emit sparse visible light spikes\nwithout requiring batteries or RF radios. These optical spikes are captured by\nevent cameras and classified using optimized SNN models evolved via the EONS\nframework. We evaluate Vibe2Spike across five device classes, achieving 94.9\\%\naverage classification fitness while analyzing the latency-accuracy trade-offs\nof different temporal binning strategies. Vibe2Spike demonstrates a scalable,\nand energy-efficient approach for enabling intelligent environments in a\nbatteryless manner."}
{"id": "2508.11886", "pdf": "https://arxiv.org/pdf/2508.11886", "abs": "https://arxiv.org/abs/2508.11886", "authors": ["Wenhui Zhu", "Xiwen Chen", "Zhipeng Wang", "Shao Tang", "Sayan Ghosh", "Xuanzhao Dong", "Rajat Koner", "Yalin Wang"], "title": "EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "eess.IV"], "comment": null, "summary": "Instructed Visual Segmentation (IVS) tasks require segmenting objects in\nimages or videos based on natural language instructions. While recent\nmultimodal large language models (MLLMs) have achieved strong performance on\nIVS, their inference cost remains a major bottleneck, particularly in video. We\nempirically analyze visual token sampling in MLLMs and observe a strong\ncorrelation between subset token coverage and segmentation performance. This\nmotivates our design of a simple and effective token pruning method that\nselects a compact yet spatially representative subset of tokens to accelerate\ninference. In this paper, we introduce a novel visual token pruning method for\nIVS, called EVTP-IV, which builds upon the k-center by integrating spatial\ninformation to ensure better coverage. We further provide an\ninformation-theoretic analysis to support our design. Experiments on standard\nIVS benchmarks show that our method achieves up to 5X speed-up on video tasks\nand 3.5X on image tasks, while maintaining comparable accuracy using only 20%\nof the tokens. Our method also consistently outperforms state-of-the-art\npruning baselines under varying pruning ratios."}
{"id": "2508.11644", "pdf": "https://arxiv.org/pdf/2508.11644", "abs": "https://arxiv.org/abs/2508.11644", "authors": ["Zhichao Deng", "Zhikun Liu", "Junxue Wang", "Shengqian Chen", "Xiang Wei", "Qiang Yu"], "title": "HetSyn: Versatile Timescale Integration in Spiking Neural Networks via Heterogeneous Synapses", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) offer a biologically plausible and\nenergy-efficient framework for temporal information processing. However,\nexisting studies overlook a fundamental property widely observed in biological\nneurons-synaptic heterogeneity, which plays a crucial role in temporal\nprocessing and cognitive capabilities. To bridge this gap, we introduce HetSyn,\na generalized framework that models synaptic heterogeneity with\nsynapse-specific time constants. This design shifts temporal integration from\nthe membrane potential to the synaptic current, enabling versatile timescale\nintegration and allowing the model to capture diverse synaptic dynamics. We\nimplement HetSyn as HetSynLIF, an extended form of the leaky integrate-and-fire\n(LIF) model equipped with synapse-specific decay dynamics. By adjusting the\nparameter configuration, HetSynLIF can be specialized into vanilla LIF neurons,\nneurons with threshold adaptation, and neuron-level heterogeneous models. We\ndemonstrate that HetSynLIF not only improves the performance of SNNs across a\nvariety of tasks-including pattern generation, delayed match-to-sample, speech\nrecognition, and visual recognition-but also exhibits strong robustness to\nnoise, enhanced working memory performance, efficiency under limited neuron\nresources, and generalization across timescales. In addition, analysis of the\nlearned synaptic time constants reveals trends consistent with empirical\nobservations in biological synapses. These findings underscore the significance\nof synaptic heterogeneity in enabling efficient neural computation, offering\nnew insights into brain-inspired temporal modeling."}
{"id": "2508.11890", "pdf": "https://arxiv.org/pdf/2508.11890", "abs": "https://arxiv.org/abs/2508.11890", "authors": ["Sangwoo Jeon", "Juchul Shin", "YeonJe Cho", "Gyeong-Tae Kim", "Seongwoo Kim"], "title": "Integrating Symbolic RL Planning into a BDI-based Autonomous UAV Framework: System Integration and SIL Validation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Modern autonomous drone missions increasingly require software frameworks\ncapable of seamlessly integrating structured symbolic planning with adaptive\nreinforcement learning (RL). Although traditional rule-based architectures\noffer robust structured reasoning for drone autonomy, their capabilities fall\nshort in dynamically complex operational environments that require adaptive\nsymbolic planning. Symbolic RL (SRL), using the Planning Domain Definition\nLanguage (PDDL), explicitly integrates domain-specific knowledge and\noperational constraints, significantly improving the reliability and safety of\nunmanned aerial vehicle (UAV) decision making. In this study, we propose the\nAMAD-SRL framework, an extended and refined version of the Autonomous Mission\nAgents for Drones (AMAD) cognitive multi-agent architecture, enhanced with\nsymbolic reinforcement learning for dynamic mission planning and execution. We\nvalidated our framework in a Software-in-the-Loop (SIL) environment structured\nidentically to an intended Hardware-In-the-Loop Simulation (HILS) platform,\nensuring seamless transition to real hardware. Experimental results demonstrate\nstable integration and interoperability of modules, successful transitions\nbetween BDI-driven and symbolic RL-driven planning phases, and consistent\nmission performance. Specifically, we evaluate a target acquisition scenario in\nwhich the UAV plans a surveillance path followed by a dynamic reentry path to\nsecure the target while avoiding threat zones. In this SIL evaluation, mission\nefficiency improved by approximately 75% over a coverage-based baseline,\nmeasured by travel distance reduction. This study establishes a robust\nfoundation for handling complex UAV missions and discusses directions for\nfurther enhancement and validation."}
{"id": "2508.11656", "pdf": "https://arxiv.org/pdf/2508.11656", "abs": "https://arxiv.org/abs/2508.11656", "authors": ["Ridma Jayasundara", "Ishan Fernando", "Adeepa Fernando", "Roshan Ragel", "Vajira Thambawita", "Isuru Nawinne"], "title": "Inductive transfer learning from regression to classification in ECG analysis", "categories": ["eess.SP", "cs.LG", "I.2.6; I.5.1; I.5.4; I.2.1; J.3"], "comment": "This manuscript is 15 pages with 4 tables and 5 figures. The\n  manuscript is under review at Nature Scientific Reports", "summary": "Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide,\naccounting for over 30% of global deaths according to the World Health\nOrganization (WHO). Importantly, one-third of these deaths are preventable with\ntimely and accurate diagnosis. The electrocardiogram (ECG), a non-invasive\nmethod for recording the electrical activity of the heart, is crucial for\ndiagnosing CVDs. However, privacy concerns surrounding the use of patient ECG\ndata in research have spurred interest in synthetic data, which preserves the\nstatistical properties of real data without compromising patient\nconfidentiality. This study explores the potential of synthetic ECG data for\ntraining deep learning models from regression to classification tasks and\nevaluates the feasibility of transfer learning to enhance classification\nperformance on real ECG data. We experimented with popular deep learning models\nto predict four key cardiac parameters, namely, Heart Rate (HR), PR interval,\nQT interval, and QRS complex-using separate regression models. Subsequently, we\nleveraged these regression models for transfer learning to perform 5-class ECG\nsignal classification. Our experiments systematically investigate whether\ntransfer learning from regression to classification is viable, enabling better\nutilization of diverse open-access and synthetic ECG datasets. Our findings\ndemonstrate that transfer learning from regression to classification improves\nclassification performance, highlighting its potential to maximize the utility\nof available data and advance deep learning applications in this domain."}
{"id": "2508.11907", "pdf": "https://arxiv.org/pdf/2508.11907", "abs": "https://arxiv.org/abs/2508.11907", "authors": ["Xiaojin Zhang", "Mingcong Xu", "Yiming Li", "Wei Chen", "Qiang Yang"], "title": "Deciphering the Interplay between Attack and Protection Complexity in Privacy-Preserving Federated Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Federated learning (FL) offers a promising paradigm for collaborative model\ntraining while preserving data privacy. However, its susceptibility to gradient\ninversion attacks poses a significant challenge, necessitating robust privacy\nprotection mechanisms. This paper introduces a novel theoretical framework to\ndecipher the intricate interplay between attack and protection complexities in\nprivacy-preserving FL. We formally define \"Attack Complexity\" as the minimum\ncomputational and data resources an adversary requires to reconstruct private\ndata below a given error threshold, and \"Protection Complexity\" as the expected\ndistortion introduced by privacy mechanisms. Leveraging Maximum Bayesian\nPrivacy (MBP), we derive tight theoretical bounds for protection complexity,\ndemonstrating its scaling with model dimensionality and privacy budget.\nFurthermore, we establish comprehensive bounds for attack complexity, revealing\nits dependence on privacy leakage, gradient distortion, model dimension, and\nthe chosen privacy level. Our findings quantitatively illuminate the\nfundamental trade-offs between privacy guarantees, system utility, and the\neffort required for both attacking and defending. This framework provides\ncritical insights for designing more secure and efficient federated learning\nsystems."}
{"id": "2508.11657", "pdf": "https://arxiv.org/pdf/2508.11657", "abs": "https://arxiv.org/abs/2508.11657", "authors": ["Yuanhao Li", "Badong Chen", "Wenjun Bai", "Yasuharu Koike", "Okito Yamashita"], "title": "Robust Sparse Bayesian Learning Based on Minimum Error Entropy for Noisy High-Dimensional Brain Activity Decoding", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Objective: Sparse Bayesian learning provides an effective scheme to solve the\nhigh-dimensional problem in brain signal decoding. However, traditional\nassumptions regarding data distributions such as Gaussian and binomial are\npotentially inadequate to characterize the noisy signals of brain activity.\nHence, this study aims to propose a robust sparse Bayesian learning framework\nto address noisy highdimensional brain activity decoding. Methods: Motivated by\nthe commendable robustness of the minimum error entropy (MEE) criterion for\nhandling complex data distributions, we proposed an MEE-based likelihood\nfunction to facilitate the accurate inference of sparse Bayesian learning in\nanalyzing noisy brain datasets. Results: Our proposed approach was evaluated\nusing two high-dimensional brain decoding tasks in regression and\nclassification contexts, respectively. The experimental results showed that,\nour approach can realize superior decoding metrics and physiological patterns\nthan the conventional and state-of-the-art methods. Conclusion: Utilizing the\nproposed MEE-based likelihood model, sparse Bayesian learning is empowered to\nsimultaneously address the challenges of noise and high dimensionality in the\nbrain decoding task. Significance: This work provides a powerful tool to\nrealize robust brain decoding, advancing biomedical engineering applications\nsuch as brain-computer interface."}
{"id": "2508.11915", "pdf": "https://arxiv.org/pdf/2508.11915", "abs": "https://arxiv.org/abs/2508.11915", "authors": ["Punya Syon Pandey", "Yongjin Yang", "Jiarui Liu", "Zhijing Jin"], "title": "CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Game-theoretic interactions between agents with Large Language Models (LLMs)\nhave revealed many emergent capabilities, yet the linguistic diversity of these\ninteractions has not been sufficiently quantified. In this paper, we present\nthe Conversational Robustness Evaluation Score: CORE, a metric to quantify the\neffectiveness of language use within multi-agent systems across different\ngame-theoretic interactions. CORE integrates measures of cluster entropy,\nlexical repetition, and semantic similarity, providing a direct lens of dialog\nquality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,\nand neutral settings, further grounding our analysis in Zipf's and Heaps' Laws\nto characterize word frequency distributions and vocabulary growth. Our\nfindings show that cooperative settings exhibit both steeper Zipf distributions\nand higher Heap exponents, indicating more repetition alongside greater\nvocabulary expansion. In contrast, competitive interactions display lower Zipf\nand Heaps exponents, reflecting less repetition and more constrained\nvocabularies. These results provide new insights into how social incentives\ninfluence language adaptation, and highlight CORE as a robust diagnostic for\nmeasuring linguistic robustness in multi-agent LLM systems. Our code is\navailable at https://github.com/psyonp/core."}
{"id": "2508.11659", "pdf": "https://arxiv.org/pdf/2508.11659", "abs": "https://arxiv.org/abs/2508.11659", "authors": ["Zhuo Liu", "Tao Chen"], "title": "Toward Practical Equilibrium Propagation: Brain-inspired Recurrent Neural Network with Feedback Regulation and Residual Connections", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Brain-like intelligent systems need brain-like learning methods. Equilibrium\nPropagation (EP) is a biologically plausible learning framework with strong\npotential for brain-inspired computing hardware. However, existing\nim-plementations of EP suffer from instability and prohibi-tively high\ncomputational costs. Inspired by the structure and dynamics of the brain, we\npropose a biologically plau-sible Feedback-regulated REsidual recurrent neural\nnetwork (FRE-RNN) and study its learning performance in EP framework. Feedback\nregulation enables rapid convergence by reducing the spectral radius. The\nimprovement in con-vergence property reduces the computational cost and\ntrain-ing time of EP by orders of magnitude, delivering perfor-mance on par\nwith backpropagation (BP) in benchmark tasks. Meanwhile, residual connections\nwith brain-inspired topologies help alleviate the vanishing gradient problem\nthat arises when feedback pathways are weak in deep RNNs. Our approach\nsubstantially enhances the applicabil-ity and practicality of EP in large-scale\nnetworks that un-derpin artificial intelligence. The techniques developed here\nalso offer guidance to implementing in-situ learning in physical neural\nnetworks."}
{"id": "2508.11921", "pdf": "https://arxiv.org/pdf/2508.11921", "abs": "https://arxiv.org/abs/2508.11921", "authors": ["Yibo Zhong"], "title": "ENA: Efficient N-dimensional Attention", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "WIP", "summary": "Efficient modeling of long sequences of high-order data requires a more\nefficient architecture than Transformer. In this paper, we investigate two key\naspects of extending linear recurrent models, especially those originally\ndesigned for language modeling, to high-order data (1D to ND): scanning\nstrategies and attention-hybrid architectures. Empirical results suggest that\nscanning provides limited benefits, while attention-hybrid models yield\npromising results. Focusing on the latter, we further evaluate types of\nattention and find that tiled high-order sliding window attention (SWA) is\nefficient in both theory and practice. We term the resulting hybrid\narchitecture of linear recurrence and high-order SWA as Efficient N-dimensional\nAttention (ENA). We then conduct several experiments to demonstrate its\neffectiveness. The intuition behind ENA is that linear recurrence compresses\nglobal information into a state, while SWA complements it by enforcing strict\nlocal modeling. Together, they form a simple framework that offers a promising\nand practical solution for ultra-long high-order data modeling."}
{"id": "2508.11663", "pdf": "https://arxiv.org/pdf/2508.11663", "abs": "https://arxiv.org/abs/2508.11663", "authors": ["Guangli Li", "Canbiao Wu", "Zhen Liang"], "title": "Unsupervised Pairwise Learning Optimization Framework for Cross-Corpus EEG-Based Emotion Recognition Based on Prototype Representation", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Affective computing is a rapidly developing interdisciplinary research\ndirection in the field of brain-computer interface. In recent years, the\nintroduction of deep learning technology has greatly promoted the development\nof the field of emotion recognition. However, due to physiological differences\nbetween subjects, as well as the variations in experimental environments and\nequipment, cross-corpus emotion recognition faces serious challenges,\nespecially for samples near the decision boundary. To solve the above problems,\nwe propose an optimization method based on domain adversarial transfer learning\nto fine-grained alignment of affective features, named Maximum classifier\ndiscrepancy with Pairwise Learning (McdPL) framework. In McdPL, we design a\ndual adversarial classifier (Ada classifier and RMS classifier), and apply a\nthree-stage adversarial training to maximize classification discrepancy and\nminimize feature distribution to align controversy samples near the decision\nboundary. In the process of domain adversarial training, the two classifiers\nalso maintain an adversarial relationship, ultimately enabling precise\ncross-corpus feature alignment. In addition, the introduction of pairwise\nlearning transforms the classification problem of samples into a similarity\nproblem between samples, alleviating the influence of label noise. We conducted\nsystematic experimental evaluation of the model using publicly available SEED,\nSEED-IV and SEED-V databases. The results show that the McdPL model is superior\nto other baseline models in the cross-corpus emotion recognition task, and the\naverage accuracy improvements of 4.76\\% and 3.97\\%, respectively. Our work\nprovides a promising solution for emotion recognition cross-corpus. The source\ncode is available at https://github.com/WuCB-BCI/Mcd_PL."}
{"id": "2508.11929", "pdf": "https://arxiv.org/pdf/2508.11929", "abs": "https://arxiv.org/abs/2508.11929", "authors": ["Mohitvishnu S. Gadde", "Pranay Dugar", "Ashish Malik", "Alan Fern"], "title": "No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Effective bipedal locomotion in dynamic environments, such as cluttered\nindoor spaces or uneven terrain, requires agile and adaptive movement in all\ndirections. This necessitates omnidirectional terrain sensing and a controller\ncapable of processing such input. We present a learning framework for\nvision-based omnidirectional bipedal locomotion, enabling seamless movement\nusing depth images. A key challenge is the high computational cost of rendering\nomnidirectional depth images in simulation, making traditional sim-to-real\nreinforcement learning (RL) impractical. Our method combines a robust blind\ncontroller with a teacher policy that supervises a vision-based student policy,\ntrained on noise-augmented terrain data to avoid rendering costs during RL and\nensure robustness. We also introduce a data augmentation technique for\nsupervised student training, accelerating training by up to 10 times compared\nto conventional methods. Our framework is validated through simulation and\nreal-world tests, demonstrating effective omnidirectional locomotion with\nminimal reliance on expensive rendering. This is, to the best of our knowledge,\nthe first demonstration of vision-based omnidirectional bipedal locomotion,\nshowcasing its adaptability to diverse terrains."}
{"id": "2508.11664", "pdf": "https://arxiv.org/pdf/2508.11664", "abs": "https://arxiv.org/abs/2508.11664", "authors": ["Zahra Mohammadi", "Parnian Fazel", "Siamak Mohammadi"], "title": "Energy-Efficient Real-Time 4-Stage Sleep Classification at 10-Second Resolution: A Comprehensive Study", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Sleep stage classification is crucial for diagnosing and managing disorders\nsuch as sleep apnea and insomnia. Conventional clinical methods like\npolysomnography are costly and impractical for long-term home use. We present\nan energy-efficient pipeline that detects four sleep stages (wake, REM, light,\nand deep) from a single-lead ECG. Two windowing strategies are introduced: (1)\na 5-minute window with 30-second steps for machine-learning models that use\nhandcrafted features, and (2) a 30-second window with 10-second steps for\ndeep-learning models, enabling near-real-time 10-second resolution. Lightweight\nnetworks such as MobileNet-v1 reach 92 percent accuracy and 91 percent F1-score\nbut still draw significant energy. We therefore design SleepLiteCNN, a custom\nmodel that achieves 89 percent accuracy and 89 percent F1-score while lowering\nenergy use to 5.48 microjoules per inference at 45 nm. Applying eight-bit\nquantization preserves accuracy and further reduces power, and FPGA deployment\nconfirms low resource usage. The proposed system offers a practical solution\nfor continuous, wearable ECG-based sleep monitoring."}
{"id": "2508.11935", "pdf": "https://arxiv.org/pdf/2508.11935", "abs": "https://arxiv.org/abs/2508.11935", "authors": ["Yuannuo Feng", "Wenyong Zhou", "Yuexi Lyu", "Hanjie Liu", "Zhengwu Liu", "Ngai Wong", "Wang Kang"], "title": "HPD: Hybrid Projection Decomposition for Robust State Space Models on Analog CIM Hardware", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": "4 pages, 5 figures, conference", "summary": "State Space Models (SSMs) are efficient alternatives to traditional sequence\nmodels, excelling at processing long sequences with lower computational\ncomplexity. Their reliance on matrix multiplications makes them ideal for\ncompute-in-memory (CIM) architectures, which improve energy efficiency by\ncomputing within memory arrays. However, device non-idealities in CIM introduce\nweight perturbations that can degrade inference accuracy. In this paper, we\nsystematically analyze the robustness of SSMs under noisy conditions,\nidentifying that the final block and output projection layers are more\nsusceptible to perturbations compared to other components. Building on these\ninsights, we propose HPD, a Hybrid Projection Decomposition strategy for the\nlast output projection layer. We replace the original weight matrix with the\nmultiplication of U and {\\Sigma} in its SVD to ensure compatibility with\nexisting hardware architectures, while offloading V> to digital hardware for\nprecise and robust correction. Comprehensive tests on Mamba models show that\nour method reduces perplexity by up to 99.57% under various noise conditions\ncompared to baseline models, with accuracy gains of up to 96.67% on the PIQA\nbenchmark for commonsense reasoning."}
{"id": "2508.11666", "pdf": "https://arxiv.org/pdf/2508.11666", "abs": "https://arxiv.org/abs/2508.11666", "authors": ["Timothy Oladunni", "Ehimen Aneni"], "title": "Explainable Deep Neural Network for Multimodal ECG Signals: Intermediate vs Late Fusion", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "The limitations of unimodal deep learning models, particularly their tendency\nto overfit and limited generalizability, have renewed interest in multimodal\nfusion strategies. Multimodal deep neural networks (MDNN) have the capability\nof integrating diverse data domains and offer a promising solution for robust\nand accurate predictions. However, the optimal fusion strategy, intermediate\nfusion (feature-level) versus late fusion (decision-level) remains\ninsufficiently examined, especially in high-stakes clinical contexts such as\nECG-based cardiovascular disease (CVD) classification. This study investigates\nthe comparative effectiveness of intermediate and late fusion strategies using\nECG signals across three domains: time, frequency, and time-frequency. A series\nof experiments were conducted to identify the highest-performing fusion\narchitecture. Results demonstrate that intermediate fusion consistently\noutperformed late fusion, achieving a peak accuracy of 97 percent, with Cohen's\nd > 0.8 relative to standalone models and d = 0.40 compared to late fusion.\nInterpretability analyses using saliency maps reveal that both models align\nwith the discretized ECG signals. Statistical dependency between the\ndiscretized ECG signals and corresponding saliency maps for each class was\nconfirmed using Mutual Information (MI). The proposed ECG domain-based\nmultimodal model offers superior predictive capability and enhanced\nexplainability, crucial attributes in medical AI applications, surpassing\nstate-of-the-art models."}
{"id": "2508.11940", "pdf": "https://arxiv.org/pdf/2508.11940", "abs": "https://arxiv.org/abs/2508.11940", "authors": ["Yuannuo Feng", "Wenyong Zhou", "Yuexi Lyu", "Yixiang Zhang", "Zhengwu Liu", "Ngai Wong", "Wang Kang"], "title": "Extending Straight-Through Estimation for Robust Neural Networks on Analog CIM Hardware", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "4 pages, 5 figures, conference", "summary": "Analog Compute-In-Memory (CIM) architectures promise significant energy\nefficiency gains for neural network inference, but suffer from complex\nhardware-induced noise that poses major challenges for deployment. While\nnoise-aware training methods have been proposed to address this issue, they\ntypically rely on idealized and differentiable noise models that fail to\ncapture the full complexity of analog CIM hardware variations. Motivated by the\nStraight-Through Estimator (STE) framework in quantization, we decouple forward\nnoise simulation from backward gradient computation, enabling noise-aware\ntraining with more accurate but computationally intractable noise modeling in\nanalog CIM systems. We provide theoretical analysis demonstrating that our\napproach preserves essential gradient directional information while maintaining\ncomputational tractability and optimization stability. Extensive experiments\nshow that our extended STE framework achieves up to 5.3% accuracy improvement\non image classification, 0.72 perplexity reduction on text generation,\n2.2$\\times$ speedup in training time, and 37.9% lower peak memory usage\ncompared to standard noise-aware training methods."}
{"id": "2508.11671", "pdf": "https://arxiv.org/pdf/2508.11671", "abs": "https://arxiv.org/abs/2508.11671", "authors": ["Ronald Carvalho Boadana", "Ademir Guimarães da Costa Junior", "Ricardo Rios", "Fábio Santos da Silva"], "title": "LLM-Based Intelligent Agents for Music Recommendation: A Comparison with Classical Content-Based Filtering", "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.MA"], "comment": "12 pages, in Portuguese language, 2 figures, 5 tables, 3 formulas. To\n  be published in the Proceedings of the Encontro Nacional de Intelig\\^encia\n  Artificial e Computacional (ENIAC 2025)", "summary": "The growing availability of music on streaming platforms has led to\ninformation overload for users. To address this issue and enhance the user\nexperience, increasingly sophisticated recommendation systems have been\nproposed. This work investigates the use of Large Language Models (LLMs) from\nthe Gemini and LLaMA families, combined with intelligent agents, in a\nmulti-agent personalized music recommendation system. The results are compared\nwith a traditional content-based recommendation model, considering user\nsatisfaction, novelty, and computational efficiency. LLMs achieved satisfaction\nrates of up to \\textit{89{,}32\\%}, indicating their promising potential in\nmusic recommendation systems."}
{"id": "2508.11957", "pdf": "https://arxiv.org/pdf/2508.11957", "abs": "https://arxiv.org/abs/2508.11957", "authors": ["Xiaodong Qu", "Andrews Damoah", "Joshua Sherwood", "Peiyan Liu", "Christian Shun Jin", "Lulu Chen", "Minjie Shen", "Nawwaf Aleisa", "Zeyuan Hou", "Chenyu Zhang", "Lifu Gao", "Yanshu Li", "Qikai Yang", "Qun Wang", "Cristabelle De Souza"], "title": "A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial Intelligence (AI) agents have rapidly evolved from specialized,\nrule-based programs to versatile, learning-driven autonomous systems capable of\nperception, reasoning, and action in complex environments. The explosion of\ndata, advances in deep learning, reinforcement learning, and multi-agent\ncoordination have accelerated this transformation. Yet, designing and deploying\nunified AI agents that seamlessly integrate cognition, planning, and\ninteraction remains a grand challenge. In this review, we systematically\nexamine the architectural principles, foundational components, and emergent\nparadigms that define the landscape of contemporary AI agents. We synthesize\ninsights from cognitive science-inspired models, hierarchical reinforcement\nlearning frameworks, and large language model-based reasoning. Moreover, we\ndiscuss the pressing ethical, safety, and interpretability concerns associated\nwith deploying these agents in real-world scenarios. By highlighting major\nbreakthroughs, persistent challenges, and promising research directions, this\nreview aims to guide the next generation of AI agent systems toward more\nrobust, adaptable, and trustworthy autonomous intelligence."}
{"id": "2508.11672", "pdf": "https://arxiv.org/pdf/2508.11672", "abs": "https://arxiv.org/abs/2508.11672", "authors": ["Zixia Zhou", "Junyan Liu", "Wei Emma Wu", "Ruogu Fang", "Sheng Liu", "Qingyue Wei", "Rui Yan", "Yi Guo", "Qian Tao", "Yuanyuan Wang", "Md Tauhidul Islam", "Lei Xing"], "title": "Revealing Neurocognitive and Behavioral Patterns by Unsupervised Manifold Learning from Dynamic Brain Data", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "comment": null, "summary": "Dynamic brain data, teeming with biological and functional insights, are\nbecoming increasingly accessible through advanced measurements, providing a\ngateway to understanding the inner workings of the brain in living subjects.\nHowever, the vast size and intricate complexity of the data also pose a\ndaunting challenge in reliably extracting meaningful information across various\ndata sources. This paper introduces a generalizable unsupervised deep manifold\nlearning for exploration of neurocognitive and behavioral patterns. Unlike\nexisting methods that extract patterns directly from the input data as in the\nexisting methods, the proposed Brain-dynamic Convolutional-Network-based\nEmbedding (BCNE) seeks to capture the brain-state trajectories by deciphering\nthe temporospatial correlations within the data and subsequently applying\nmanifold learning to this correlative representation. The performance of BCNE\nis showcased through the analysis of several important dynamic brain datasets.\nThe results, both visual and quantitative, reveal a diverse array of intriguing\nand interpretable patterns. BCNE effectively delineates scene transitions,\nunderscores the involvement of different brain regions in memory and narrative\nprocessing, distinguishes various stages of dynamic learning processes, and\nidentifies differences between active and passive behaviors. BCNE provides an\neffective tool for exploring general neuroscience inquiries or\nindividual-specific patterns."}
{"id": "2508.11977", "pdf": "https://arxiv.org/pdf/2508.11977", "abs": "https://arxiv.org/abs/2508.11977", "authors": ["Zida Liang", "Changfa Wu", "Dunxian Huang", "Weiqiang Sun", "Ziyang Wang", "Yuliang Yan", "Jian Wu", "Yuning Jiang", "Bo Zheng", "Ke Chen", "Silu Zhou", "Yu Zhang"], "title": "TBGRecall: A Generative Retrieval Model for E-commerce Recommendation Scenarios", "categories": ["cs.IR", "cs.AI"], "comment": "Both authors contributed equally to this research. Work done during\n  internship at Alibaba. Corresponding author: Dunxian Huang\n  (dunxian.hdx@alibaba-inc.com). Affiliations: (1) Shanghai Jiaotong\n  University, Shanghai, China; (2) Alibaba Inc", "summary": "Recommendation systems are essential tools in modern e-commerce, facilitating\npersonalized user experiences by suggesting relevant products. Recent\nadvancements in generative models have demonstrated potential in enhancing\nrecommendation systems; however, these models often exhibit limitations in\noptimizing retrieval tasks, primarily due to their reliance on autoregressive\ngeneration mechanisms. Conventional approaches introduce sequential\ndependencies that impede efficient retrieval, as they are inherently unsuitable\nfor generating multiple items without positional constraints within a single\nrequest session. To address these limitations, we propose TBGRecall, a\nframework integrating Next Session Prediction (NSP), designed to enhance\ngenerative retrieval models for e-commerce applications. Our framework\nreformulation involves partitioning input samples into multi-session sequences,\nwhere each sequence comprises a session token followed by a set of item tokens,\nand then further incorporate multiple optimizations tailored to the generative\ntask in retrieval scenarios. In terms of training methodology, our pipeline\nintegrates limited historical data pre-training with stochastic partial\nincremental training, significantly improving training efficiency and\nemphasizing the superiority of data recency over sheer data volume. Our\nextensive experiments, conducted on public benchmarks alongside a large-scale\nindustrial dataset from TaoBao, show TBGRecall outperforms the state-of-the-art\nrecommendation methods, and exhibits a clear scaling law trend. Ultimately, NSP\nrepresents a significant advancement in the effectiveness of generative\nrecommendation systems for e-commerce applications."}
{"id": "2508.11676", "pdf": "https://arxiv.org/pdf/2508.11676", "abs": "https://arxiv.org/abs/2508.11676", "authors": ["Maksym Shamrai", "Vladyslav Hamolia"], "title": "Deep Language Geometry: Constructing a Metric Space from LLM Weights", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "18 pages, accepted to RANLP 2025", "summary": "We introduce a novel framework that utilizes the internal weight activations\nof modern Large Language Models (LLMs) to construct a metric space of\nlanguages. Unlike traditional approaches based on hand-crafted linguistic\nfeatures, our method automatically derives high-dimensional vector\nrepresentations by computing weight importance scores via an adapted pruning\nalgorithm. Our approach captures intrinsic language characteristics that\nreflect linguistic phenomena. We validate our approach across diverse datasets\nand multilingual LLMs, covering 106 languages. The results align well with\nestablished linguistic families while also revealing unexpected inter-language\nconnections that may indicate historical contact or language evolution. The\nsource code, computed language latent vectors, and visualization tool are made\npublicly available at https://github.com/mshamrai/deep-language-geometry."}
{"id": "2508.11985", "pdf": "https://arxiv.org/pdf/2508.11985", "abs": "https://arxiv.org/abs/2508.11985", "authors": ["Zhanhao Cao", "Clement Truong", "Andrew Lizarraga"], "title": "Efficient Modular Learning through Naive LoRA Summation: Leveraging Orthogonality in High-Dimensional Models", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Recent advances in large language models are driven by scale, while\nparameter-efficient fine-tuning (PEFT) enables updating only a small fraction\nof parameters. Low-Rank Adaptation (LoRA) stores parameter deltas as the\nproduct of two small matrices, which makes them natural building blocks that\ncan be composed. Motivated by the superposition principle, we hypothesize that\nindependently trained LoRA modules on disjoint domains are approximately\northogonal and can be combined by simple addition. Using GPT-2 Small (117M)\nwith LoRA rank 4 and alpha=64, we train adapters for three QA domains (math,\nmedicine, finance). In pairwise tests, adding Math+Medicine adapters improves\nperplexity by -9.10% relative to merged-data fine-tuning, while Math+Finance\nand Finance+Medicine change by +4.54% and +27.56%, respectively. Across\ncombinations, the RMS cosine similarity between LoRA deltas correlates\npositively and approximately linearly with the change in perplexity. Naive\nsummation requires no additional training, can be applied in seconds, and\nachieves performance comparable to models trained on merged data, while\nclarifying when interference appears in higher-order compositions."}
{"id": "2508.11682", "pdf": "https://arxiv.org/pdf/2508.11682", "abs": "https://arxiv.org/abs/2508.11682", "authors": ["Md Basit Azam", "Sarangthem Ibotombi Singh"], "title": "Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "Non-invasive glucose monitoring remains a critical challenge in the\nmanagement of diabetes. HRV during sleep shows promise for glucose prediction\nhowever, age-related autonomic changes significantly confound traditional HRV\nanalyses. We analyzed 43 subjects with multi-modal data including sleep-stage\nspecific ECG, HRV features, and clinical measurements. A novel\nage-normalization technique was applied to the HRV features by, dividing the\nraw values by age-scaled factors. BayesianRidge regression with 5-fold\ncross-validation was employed for log-glucose prediction. Age-normalized HRV\nfeatures achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction,\nrepresenting a 25.6% improvement over non-normalized features (R2 = 0.132). The\ntop predictive features were hrv rem mean rr age normalized (r = 0.443, p =\n0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic\nblood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed\nage-normalization as the critical component, with sleep-stage specific features\nproviding additional predictive value. Age-normalized HRV features\nsignificantly enhance glucose prediction accuracy compared with traditional\napproaches. This sleep-aware methodology addresses fundamental limitations in\nautonomic function assessment and suggests a preliminary feasibility for\nnon-invasive glucose monitoring applications. However, these results require\nvalidation in larger cohorts before clinical consideration."}
{"id": "2508.11999", "pdf": "https://arxiv.org/pdf/2508.11999", "abs": "https://arxiv.org/abs/2508.11999", "authors": ["Daoze Zhang", "Zhanheng Nie", "Jianyu Liu", "Chenghan Fu", "Wanxian Guan", "Yuan Gao", "Jun Song", "Pengjie Wang", "Jian Xu", "Bo Zheng"], "title": "MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding", "categories": ["cs.CV", "cs.AI", "cs.IR", "cs.LG"], "comment": "11 pages, 9 figures", "summary": "With the rapid advancement of e-commerce, exploring general representations\nrather than task-specific ones has attracted increasing research attention. For\nproduct understanding, although existing discriminative dual-flow architectures\ndrive progress in this field, they inherently struggle to model the many-to-one\nalignment between multiple images and texts of products. Therefore, we argue\nthat generative Multimodal Large Language Models (MLLMs) hold significant\npotential for improving product representation learning. Nevertheless,\nachieving this goal still remains non-trivial due to several key challenges:\nthe lack of multimodal and aspect-aware modeling modules in typical LLMs; the\ncommon presence of background noise in product images; and the absence of a\nstandard benchmark for evaluation. To address these issues, we propose the\nfirst generative MLLM-based model named MOON for product representation\nlearning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for\ntargeted modeling of multimodal and aspect-specific product content; (2)\neffectively detects core semantic regions in product images to mitigate the\ndistraction and interference caused by background noise; and (3) introduces the\nspecialized negative sampling strategy to increase the difficulty and diversity\nof negative samples. In addition, we release a large-scale multimodal benchmark\nMBE for various product understanding tasks. Experimentally, our model\ndemonstrates competitive zero-shot performance on both our benchmark and the\npublic dataset, showcasing strong generalization across various downstream\ntasks, including cross-modal retrieval, product classification, and attribute\nprediction. Furthermore, the case study and visualization illustrate the\neffectiveness of MOON for product understanding."}
{"id": "2508.11684", "pdf": "https://arxiv.org/pdf/2508.11684", "abs": "https://arxiv.org/abs/2508.11684", "authors": ["BG Tong"], "title": "A Graph Neural Network based on a Functional Topology Model: Unveiling the Dynamic Mechanisms of Non-Suicidal Self-Injury in Single-Channel EEG", "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Objective: This study proposes and preliminarily validates a novel\n\"Functional-Energetic Topology Model\" to uncover neurodynamic mechanisms of\nNon-Suicidal Self-Injury (NSSI), using Graph Neural Networks (GNNs) to decode\nbrain network patterns from single-channel EEG in real-world settings.Methods:\nEEG data were collected over ~1 month from three adolescents with NSSI using a\nsmartphone app and a portable Fp1 EEG headband during impulsive and\nnon-impulsive states. A theory-driven GNN with seven functional nodes was\nbuilt. Performance was evaluated via intra-subject (80/20 split) and\nleave-one-subject-out cross-validation (LOSOCV). GNNExplainer was used for\ninterpretability.Results: The model achieved high intra-subject accuracy (>85%)\nand significantly above-chance cross-subject performance (approximately73.7%).\nExplainability analysis revealed a key finding: during NSSI states, a critical\nfeedback loop regulating somatic sensation exhibits dysfunction and directional\nreversal. Specifically, the brain loses its ability to self-correct via\nnegative bodily feedback, and the regulatory mechanism enters an \"ineffective\nidling\" state.Conclusion: This work demonstrates the feasibility of applying\ntheory-guided GNNs to sparse, single-channel EEG for decoding complex mental\nstates. The identified \"feedback loop reversal\" offers a novel, dynamic, and\ncomputable model of NSSI mechanisms, paving the way for objective biomarkers\nand next-generation Digital Therapeutics (DTx)."}
{"id": "2508.12013", "pdf": "https://arxiv.org/pdf/2508.12013", "abs": "https://arxiv.org/abs/2508.12013", "authors": ["Surajit Das", "Aleksei Eliseev"], "title": "Predicting ChatGPT Use in Assignments: Implications for AI-Aware Assessment Design", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "The rise of generative AI tools like ChatGPT has significantly reshaped\neducation, sparking debates about their impact on learning outcomes and\nacademic integrity. While prior research highlights opportunities and risks,\nthere remains a lack of quantitative analysis of student behavior when\ncompleting assignments. Understanding how these tools influence real-world\nacademic practices, particularly assignment preparation, is a pressing and\ntimely research priority.\n  This study addresses this gap by analyzing survey responses from 388\nuniversity students, primarily from Russia, including a subset of international\nparticipants. Using the XGBoost algorithm, we modeled predictors of ChatGPT\nusage in academic assignments. Key predictive factors included learning habits,\nsubject preferences, and student attitudes toward AI. Our binary classifier\ndemonstrated strong predictive performance, achieving 80.1\\% test accuracy,\nwith 80.2\\% sensitivity and 79.9\\% specificity. The multiclass classifier\nachieved 64.5\\% test accuracy, 64.6\\% weighted precision, and 64.5\\% recall,\nwith similar training scores, indicating potential data scarcity challenges.\n  The study reveals that frequent use of ChatGPT for learning new concepts\ncorrelates with potential overreliance, raising concerns about long-term\nacademic independence. These findings suggest that while generative AI can\nenhance access to knowledge, unchecked reliance may erode critical thinking and\noriginality. We propose discipline-specific guidelines and reimagined\nassessment strategies to balance innovation with academic rigor. These insights\ncan guide educators and policymakers in ethically and effectively integrating\nAI into education."}
{"id": "2508.11685", "pdf": "https://arxiv.org/pdf/2508.11685", "abs": "https://arxiv.org/abs/2508.11685", "authors": ["Farnaz Kaboudvand", "Maham Khalid", "Nydia Assaf", "Vardaan Sahgal", "Jon P. Ruffley", "Brian J. McDermott"], "title": "Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.LG", "stat.ML"], "comment": "Manuscript length: 11 pages, 6 figures", "summary": "Corrosion poses a significant challenge to the performance of aluminum\nalloys, particularly in marine environments. This study investigates the\napplication of machine learning (ML) algorithms to predict and optimize\ncorrosion resistance, utilizing a comprehensive open-source dataset compiled\nfrom various sources. The dataset encompasses corrosion rate data and\nenvironmental conditions, preprocessed to standardize units and formats. We\nexplored two different approaches, a direct approach, where the material's\ncomposition and environmental conditions were used as inputs to predict\ncorrosion rates; and an inverse approach, where corrosion rate served as the\ninput to identify suitable material compositions as output. We employed and\ncompared three distinct ML methodologies for forward predictions: Random Forest\nregression, optimized via grid search; a feed-forward neural network, utilizing\nReLU activation and Adam optimization; and Gaussian Process Regression (GPR),\nimplemented with GPyTorch and employing various kernel functions. The Random\nForest and neural network models provided predictive capabilities based on\nelemental compositions and environmental conditions. Notably, Gaussian Process\nRegression demonstrated superior performance, particularly with hybrid kernel\nfunctions. Log-transformed GPR further refined predictions. This study\nhighlights the efficacy of ML, particularly GPR, in predicting corrosion rates\nand material properties."}
{"id": "2508.12029", "pdf": "https://arxiv.org/pdf/2508.12029", "abs": "https://arxiv.org/abs/2508.12029", "authors": ["Zhangyu You", "Jiahao Ma", "Hongzong Li", "Ye-Fan Hu", "Jian-Dong Huang"], "title": "BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.LG"], "comment": "16 pages, 7 figures, 5 tables, submitted to AAAI conference 2026", "summary": "Accurate prediction of antibody-binding sites (epitopes) on antigens is\ncrucial for vaccine design, immunodiagnostics, therapeutic antibody\ndevelopment, antibody engineering, research into autoimmune and allergic\ndiseases, and for advancing our understanding of immune responses. Despite in\nsilico methods that have been proposed to predict both linear (continuous) and\nconformational (discontinuous) epitopes, they consistently underperform in\npredicting conformational epitopes. In this work, we propose a conformer-based\nmodel trained on antigen sequences derived from 1,080 antigen-antibody\ncomplexes, leveraging convolutional neural networks (CNNs) to extract local\nfeatures and Transformers to capture long-range dependencies within antigen\nsequences. Ablation studies demonstrate that CNN enhances the prediction of\nlinear epitopes, and the Transformer module improves the prediction of\nconformational epitopes. Experimental results show that our model outperforms\nexisting baselines in terms of PCC, ROC-AUC, PR-AUC, and F1 scores on\nconformational epitopes."}
{"id": "2508.11691", "pdf": "https://arxiv.org/pdf/2508.11691", "abs": "https://arxiv.org/abs/2508.11691", "authors": ["Mathis Rezzouk", "Fabrice Gagnon", "Alyson Champagne", "Mathieu Roy", "Philippe Albouy", "Michel-Pierre Coll", "Cem Subakan"], "title": "Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "6 pages, 2 figures, 2 tables, MLSP IEEE conference", "summary": "EEG-based analysis of pain perception, enhanced by machine learning, reveals\nhow the brain encodes pain by identifying neural patterns evoked by noxious\nstimulation. However, a major challenge that remains is the generalization of\nmachine learning models across individuals, given the high cross-participant\nvariability inherent to EEG signals and the limited focus on direct pain\nperception identification in current research. In this study, we systematically\nevaluate the performance of cross-participant generalization of a wide range of\nmodels, including traditional classifiers and deep neural classifiers for\nidentifying the sensory modality of thermal pain and aversive auditory\nstimulation from EEG recordings. Using a novel dataset of EEG recordings from\n108 participants, we benchmark model performance under both within- and\ncross-participant evaluation settings. Our findings show that traditional\nmodels suffered the largest drop from within- to cross-participant performance,\nwhile deep learning models proved more resilient, underscoring their potential\nfor subject-invariant EEG decoding. Even though performance variability\nremained high, the strong results of the graph-based model highlight its\npotential to capture subject-invariant structure in EEG signals. On the other\nhand, we also share the preprocessed dataset used in this study, providing a\nstandardized benchmark for evaluating future algorithms under the same\ngeneralization constraints."}
{"id": "2508.12036", "pdf": "https://arxiv.org/pdf/2508.12036", "abs": "https://arxiv.org/abs/2508.12036", "authors": ["Rakesh Thakur", "Yusra Tariq"], "title": "Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 4 figures Submitted to AAAI 26", "summary": "Solving tough clinical questions that require both image and text\nunderstanding is still a major challenge in healthcare AI. In this work, we\npropose Q-FSRU, a new model that combines Frequency Spectrum Representation and\nFusion (FSRU) with a method called Quantum Retrieval-Augmented Generation\n(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in\nfeatures from medical images and related text, then shifts them into the\nfrequency domain using Fast Fourier Transform (FFT). This helps it focus on\nmore meaningful data and filter out noise or less useful information. To\nimprove accuracy and ensure that answers are based on real knowledge, we add a\nquantum-inspired retrieval system. It fetches useful medical facts from\nexternal sources using quantum-based similarity techniques. These details are\nthen merged with the frequency-based features for stronger reasoning. We\nevaluated our model using the VQA-RAD dataset, which includes real radiology\nimages and questions. The results showed that Q-FSRU outperforms earlier\nmodels, especially on complex cases needing image-text reasoning. The mix of\nfrequency and quantum information improves both performance and explainability.\nOverall, this approach offers a promising way to build smart, clear, and\nhelpful AI tools for doctors."}
{"id": "2508.11693", "pdf": "https://arxiv.org/pdf/2508.11693", "abs": "https://arxiv.org/abs/2508.11693", "authors": ["Francisco López", "Eduardo Di Santi", "Clément Lefebvre", "Nenad Mijatovic", "Michele Pugnaloni", "Victor Martín", "Kenza Saiah"], "title": "Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data", "categories": ["eess.SP", "cs.AI", "cs.LG", "68T05, 68T10", "I.2.6; I.5.1; I.5.4"], "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025\n  (International Conference on Railway Operations Modelling and Analysis),\n  Dresden, Germany", "summary": "Track Circuits (TC) are the main signalling devices used to detect the\npresence of a train on a rail track. It has been used since the 19th century\nand nowadays there are many types depending on the technology. As a general\nclassification, Track Circuits can be divided into 2 main groups, DC (Direct\nCurrent) and AC (Alternating Current) circuits. This work is focused on a\nparticular AC track circuit, called \"Smart Train Detection System\" (STDS),\ndesigned with both high and low-frequency bands. This approach uses STDS\ncurrent data applied to an SVM (support vector machine) classifier as a type of\nfailure identifier. The main purpose of this work consists on determine\nautomatically which is the component of the track that is failing to improve\nthe maintenance action. Model was trained to classify 15 different failures\nthat belong to 3 more general categories. The method was tested with field data\nfrom 10 different track circuits and validated by the STDS track circuit expert\nand maintainers. All use cases were correctly classified by the method."}
{"id": "2508.12040", "pdf": "https://arxiv.org/pdf/2508.12040", "abs": "https://arxiv.org/abs/2508.12040", "authors": ["Jinyi Han", "Tingyun Li", "Shisong Chen", "Jie Shi", "Xinyi Wang", "Guanglei Yue", "Jiaqing Liang", "Xin Lin", "Liqian Wen", "Zulong Chen", "Yanghua Xiao"], "title": "Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation", "categories": ["cs.CL", "cs.AI"], "comment": "The initial versin was made in August 2024", "summary": "While large language models (LLMs) have demonstrated remarkable performance\nacross diverse tasks, they fundamentally lack self-awareness and frequently\nexhibit overconfidence, assigning high confidence scores to incorrect\npredictions. Accurate confidence estimation is therefore critical for enhancing\nthe trustworthiness and reliability of LLM-generated outputs. However, existing\napproaches suffer from coarse-grained scoring mechanisms that fail to provide\nfine-grained, continuous confidence estimates throughout the generation\nprocess. To address these limitations, we introduce FineCE, a novel confidence\nestimation method that delivers accurate, fine-grained confidence scores during\ntext generation. Specifically, we first develop a comprehensive pipeline for\nconstructing training data that effectively captures the underlying\nprobabilistic distribution of LLM responses, and then train a model to predict\nconfidence scores for arbitrary text sequences in a supervised manner.\nFurthermore, we propose a Backward Confidence Integration (BCI) strategy that\nleverages information from the subsequent text to enhance confidence estimation\nfor the current sequence during inference. We also introduce three strategies\nfor identifying optimal positions to perform confidence estimation within the\ngeneration process. Extensive experiments on multiple benchmark datasets\ndemonstrate that FineCE consistently outperforms existing classical confidence\nestimation methods. Our code and all baselines used in the paper are available\non GitHub."}
{"id": "2508.11703", "pdf": "https://arxiv.org/pdf/2508.11703", "abs": "https://arxiv.org/abs/2508.11703", "authors": ["Vasileios Saketos", "Sebastian Kaltenbach", "Sergey Litvinov", "Petros Koumoutsakos"], "title": "Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Algorithmic discovery has traditionally relied on human ingenuity and\nextensive experimentation. Here we investigate whether a prominent scientific\ncomputing algorithm, the Kalman Filter, can be discovered through an automated,\ndata-driven, evolutionary process that relies on Cartesian Genetic Programming\n(CGP) and Large Language Models (LLM). We evaluate the contributions of both\nmodalities (CGP and LLM) in discovering the Kalman filter under varying\nconditions. Our results demonstrate that our framework of CGP and LLM-assisted\nevolution converges to near-optimal solutions when Kalman optimality\nassumptions hold. When these assumptions are violated, our framework evolves\ninterpretable alternatives that outperform the Kalman filter. These results\ndemonstrate that combining evolutionary algorithms and generative models for\ninterpretable, data-driven synthesis of simple computational modules is a\npotent approach for algorithmic discovery in scientific computing."}
{"id": "2508.12045", "pdf": "https://arxiv.org/pdf/2508.12045", "abs": "https://arxiv.org/abs/2508.12045", "authors": ["Vladimir Maksimenko", "Qingyao Xin", "Prateek Gupta", "Bin Zhang", "Prateek Bansal"], "title": "Large Language Models Enable Personalized Nudges to Promote Carbon Offsetting Among Air Travellers", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Nudge strategies are effective tools for promoting sustainable behaviour, but\ntheir impact depends on individual preferences. By emulating human\ndecision-making, large language models (LLMs) offer a cost-effective route for\ntailoring nudges without extensive behavioural datasets, yet this potential\nremains unexplored. Focusing on aviation, we use LLMs to design personalized\ndecoy-based nudge strategies that encourage air travellers to voluntarily\noffset CO$_2$ emissions from flights, and validate their efficacy through 3495\nsurveys from China, Germany, India, Singapore, and the United States. Results\nshow that LLM-informed personalized nudges are more effective than uniform\nsettings, raising offsetting rates by 3-7$\\%$ and yielding an additional 2.3\nmillion tonnes of CO$_2$ mitigated annually in aviation. This improvement is\ndriven primarily by increased participation among sceptical travellers with low\ntrust in offset programmes. Our study highlights the potential of LLM-driven\npersonalized nudging strategies for boosting offsetting behaviours to\naccelerate aviation decarbonization."}
{"id": "2508.11706", "pdf": "https://arxiv.org/pdf/2508.11706", "abs": "https://arxiv.org/abs/2508.11706", "authors": ["Zhuofan Xu", "Benedikt Bollig", "Matthias Függer", "Thomas Nowak", "Vincent Le Dréau"], "title": "Centralized Permutation Equivariant Policy for Cooperative Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "The Centralized Training with Decentralized Execution (CTDE) paradigm has\ngained significant attention in multi-agent reinforcement learning (MARL) and\nis the foundation of many recent algorithms. However, decentralized policies\noperate under partial observability and often yield suboptimal performance\ncompared to centralized policies, while fully centralized approaches typically\nface scalability challenges as the number of agents increases.\n  We propose Centralized Permutation Equivariant (CPE) learning, a centralized\ntraining and execution framework that employs a fully centralized policy to\novercome these limitations. Our approach leverages a novel permutation\nequivariant architecture, Global-Local Permutation Equivariant (GLPE) networks,\nthat is lightweight, scalable, and easy to implement. Experiments show that CPE\nintegrates seamlessly with both value decomposition and actor-critic methods,\nsubstantially improving the performance of standard CTDE algorithms across\ncooperative benchmarks including MPE, SMAC, and RWARE, and matching the\nperformance of state-of-the-art RWARE implementations."}
{"id": "2508.12063", "pdf": "https://arxiv.org/pdf/2508.12063", "abs": "https://arxiv.org/abs/2508.12063", "authors": ["Denisa Martonová", "Alain Goriely", "Ellen Kuhl"], "title": "Generalized invariants meet constitutive neural networks: A novel framework for hyperelastic materials", "categories": ["cond-mat.soft", "cs.AI"], "comment": null, "summary": "The major challenge in determining a hyperelastic model for a given material\nis the choice of invariants and the selection how the strain energy function\ndepends functionally on these invariants. Here we introduce a new data-driven\nframework that simultaneously discovers appropriate invariants and constitutive\nmodels for isotropic incompressible hyperelastic materials. Our approach\nidentifies both the most suitable invariants in a class of generalized\ninvariants and the corresponding strain energy function directly from\nexperimental observations. Unlike previous methods that rely on fixed invariant\nchoices or sequential fitting procedures, our method integrates the discovery\nprocess into a single neural network architecture. By looking at a continuous\nfamily of possible invariants, the model can flexibly adapt to different\nmaterial behaviors. We demonstrate the effectiveness of this approach using\npopular benchmark datasets for rubber and brain tissue. For rubber, the method\nrecovers a stretch-dominated formulation consistent with classical models. For\nbrain tissue, it identifies a formulation sensitive to small stretches,\ncapturing the nonlinear shear response characteristic of soft biological\nmatter. Compared to traditional and neural-network-based models, our framework\nprovides improved predictive accuracy and interpretability across a wide range\nof deformation states. This unified strategy offers a robust tool for automated\nand physically meaningful model discovery in hyperelasticity."}
{"id": "2508.11711", "pdf": "https://arxiv.org/pdf/2508.11711", "abs": "https://arxiv.org/abs/2508.11711", "authors": ["Irash Perera", "Hiranya Abeyrathne", "Sanjeewa Malalgoda", "Arshardh Ifthikar"], "title": "Enhancing GraphQL Security by Detecting Malicious Queries Using Large Language Models, Sentence Transformers, and Convolutional Neural Networks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "GraphQL's flexibility, while beneficial for efficient data fetching,\nintroduces unique security vulnerabilities that traditional API security\nmechanisms often fail to address. Malicious GraphQL queries can exploit the\nlanguage's dynamic nature, leading to denial-of-service attacks, data\nexfiltration through injection, and other exploits. Existing solutions, such as\nstatic analysis, rate limiting, and general-purpose Web Application Firewalls,\noffer limited protection against sophisticated, context-aware attacks. This\npaper presents a novel, AI-driven approach for real-time detection of malicious\nGraphQL queries. Our method combines static analysis with machine learning\ntechniques, including Large Language Models (LLMs) for dynamic schema-based\nconfiguration, Sentence Transformers (SBERT and Doc2Vec) for contextual\nembedding of query payloads, and Convolutional Neural Networks (CNNs), Random\nForests, and Multilayer Perceptrons for classification. We detail the system\narchitecture, implementation strategies optimized for production environments\n(including ONNX Runtime optimization and parallel processing), and evaluate the\nperformance of our detection models and the overall system under load. Results\ndemonstrate high accuracy in detecting various threats, including SQL\ninjection, OS command injection, and XSS exploits, alongside effective\nmitigation of DoS and SSRF attempts. This research contributes a robust and\nadaptable solution for enhancing GraphQL API security."}
{"id": "2508.12081", "pdf": "https://arxiv.org/pdf/2508.12081", "abs": "https://arxiv.org/abs/2508.12081", "authors": ["Haidong Xu", "Guangwei Xu", "Zhedong Zheng", "Xiatian Zhu", "Wei Ji", "Xiangtai Li", "Ruijie Guo", "Meishan Zhang", "Min zhang", "Hao Fei"], "title": "VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "20 pages,13 figures", "summary": "This paper introduces VimoRAG, a novel video-based retrieval-augmented motion\ngeneration framework for motion large language models (LLMs). As motion LLMs\nface severe out-of-domain/out-of-vocabulary issues due to limited annotated\ndata, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D\nmotion generation by retrieving relevant 2D human motion signals. While\nvideo-based motion RAG is nontrivial, we address two key bottlenecks: (1)\ndeveloping an effective motion-centered video retrieval model that\ndistinguishes human poses and actions, and (2) mitigating the issue of error\npropagation caused by suboptimal retrieval results. We design the Gemini Motion\nVideo Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,\nenabling effective retrieval and generation processes. Experimental results\nshow that VimoRAG significantly boosts the performance of motion LLMs\nconstrained to text-only input."}
{"id": "2508.11737", "pdf": "https://arxiv.org/pdf/2508.11737", "abs": "https://arxiv.org/abs/2508.11737", "authors": ["Shiyin Lu", "Yang Li", "Yu Xia", "Yuwei Hu", "Shanshan Zhao", "Yanqing Ma", "Zhichao Wei", "Yinglun Li", "Lunhao Duan", "Jianshan Zhao", "Yuxuan Han", "Haijun Li", "Wanying Chen", "Junke Tang", "Chengkun Hou", "Zhixing Du", "Tianli Zhou", "Wenjie Zhang", "Huping Ding", "Jiahe Li", "Wen Li", "Gui Hu", "Yiliang Gu", "Siran Yang", "Jiamang Wang", "Hailong Sun", "Yibo Wang", "Hui Sun", "Jinlong Huang", "Yuping He", "Shengze Shi", "Weihong Zhang", "Guodong Zheng", "Junpeng Jiang", "Sensen Gao", "Yi-Feng Wu", "Sijia Chen", "Yuhui Chen", "Qing-Guo Chen", "Zhao Xu", "Weihua Luo", "Kaifu Zhang"], "title": "Ovis2.5 Technical Report", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "We present Ovis2.5, a successor to Ovis2 designed for native-resolution\nvisual perception and strong multimodal reasoning. Ovis2.5 integrates a\nnative-resolution vision transformer that processes images at their native,\nvariable resolutions, avoiding the degradation from fixed-resolution tiling and\npreserving both fine detail and global layout -- crucial for visually dense\ncontent like complex charts. To strengthen reasoning, we train the model to\nmove beyond linear chain-of-thought and perform reflection -- including\nself-checking and revision. This advanced capability is exposed as an optional\n\"thinking mode\" at inference time, allowing users to trade latency for enhanced\naccuracy on difficult inputs. The model is trained via a comprehensive\nfive-phase curriculum that progressively builds its skills. The process begins\nwith foundational visual and multimodal pretraining, advances through\nlarge-scale instruction tuning, and culminates in alignment and reasoning\nenhancement using DPO and GRPO. To scale these upgrades efficiently, we employ\nmultimodal data packing and hybrid parallelism, yielding a significant\nend-to-end speedup. We release two open-source models: Ovis2.5-9B and\nOvis2.5-2B. The latter continues the \"small model, big performance\" philosophy\nof Ovis2, making it ideal for resource-constrained, on-device scenarios. On the\nOpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a\nsubstantial improvement over its predecessor, Ovis2-8B, and achieving\nstate-of-the-art results among open-source MLLMs in the sub-40B parameter\nrange; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate\nscores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong\ncapabilities on grounding and video tasks, and achieves open-source SOTA at its\nscale for complex chart analysis."}
{"id": "2508.12082", "pdf": "https://arxiv.org/pdf/2508.12082", "abs": "https://arxiv.org/abs/2508.12082", "authors": ["Seungju Yoo", "Hyuk Kwon", "Joong-Won Hwang", "Kibok Lee"], "title": "Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV 2025 Oral", "summary": "Recent advances in computer vision have made training object detectors more\nefficient and effective; however, assessing their performance in real-world\napplications still relies on costly manual annotation. To address this\nlimitation, we develop an automated model evaluation (AutoEval) framework for\nobject detection. We propose Prediction Consistency and Reliability (PCR),\nwhich leverages the multiple candidate bounding boxes that conventional\ndetectors generate before non-maximum suppression (NMS). PCR estimates\ndetection performance without ground-truth labels by jointly measuring 1) the\nspatial consistency between boxes before and after NMS, and 2) the reliability\nof the retained boxes via the confidence scores of overlapping boxes. For a\nmore realistic and scalable evaluation, we construct a meta-dataset by applying\nimage corruptions of varying severity. Experimental results demonstrate that\nPCR yields more accurate performance estimates than existing AutoEval methods,\nand the proposed meta-dataset covers a wider range of detection performance.\nThe code is available at https://github.com/YonseiML/autoeval-det."}
{"id": "2508.11741", "pdf": "https://arxiv.org/pdf/2508.11741", "abs": "https://arxiv.org/abs/2508.11741", "authors": ["Habibolla Latifizadeh", "Anika C. Pirkey", "Alanna Gould", "David J. Klinke II"], "title": "BaMANI: Bayesian Multi-Algorithm causal Network Inference", "categories": ["stat.ML", "cs.LG", "q-bio.QM"], "comment": "12 pages, 6 figures", "summary": "Improved computational power has enabled different disciplines to predict\ncausal relationships among modeled variables using Bayesian network inference.\nWhile many alternative algorithms have been proposed to improve the efficiency\nand reliability of network prediction, the predicted causal networks reflect\nthe generative process but also bear an opaque imprint of the specific\ncomputational algorithm used. Following a ``wisdom of the crowds\" strategy, we\ndeveloped an ensemble learning approach to marginalize the impact of a single\nalgorithm on Bayesian causal network inference. To introduce the approach, we\nfirst present the theoretical foundation of this framework. Next, we present a\ncomprehensive implementation of the framework in terms of a new software tool\ncalled BaMANI (Bayesian Multi-Algorithm causal Network Inference). Finally, we\ndescribe a BaMANI use-case from biology, particularly within human breast\ncancer studies."}
{"id": "2508.12084", "pdf": "https://arxiv.org/pdf/2508.12084", "abs": "https://arxiv.org/abs/2508.12084", "authors": ["Jaejun Hwang", "Dayoung Gong", "Manjin Kim", "Minsu Cho"], "title": "Generic Event Boundary Detection via Denoising Diffusion", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to ICCV 2025", "summary": "Generic event boundary detection (GEBD) aims to identify natural boundaries\nin a video, segmenting it into distinct and meaningful chunks. Despite the\ninherent subjectivity of event boundaries, previous methods have focused on\ndeterministic predictions, overlooking the diversity of plausible solutions. In\nthis paper, we introduce a novel diffusion-based boundary detection model,\ndubbed DiffGEBD, that tackles the problem of GEBD from a generative\nperspective. The proposed model encodes relevant changes across adjacent frames\nvia temporal self-similarity and then iteratively decodes random noise into\nplausible event boundaries being conditioned on the encoded features.\nClassifier-free guidance allows the degree of diversity to be controlled in\ndenoising diffusion. In addition, we introduce a new evaluation metric to\nassess the quality of predictions considering both diversity and fidelity.\nExperiments show that our method achieves strong performance on two standard\nbenchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event\nboundaries."}
{"id": "2508.11767", "pdf": "https://arxiv.org/pdf/2508.11767", "abs": "https://arxiv.org/abs/2508.11767", "authors": ["Noah Kasmanoff", "Rahul Zalkikar"], "title": "Limitation Learning: Catching Adverse Dialog with GAIL", "categories": ["cs.CL", "cs.LG"], "comment": "Paper from 2021", "summary": "Imitation learning is a proven method for creating a policy in the absence of\nrewards, by leveraging expert demonstrations. In this work, we apply imitation\nlearning to conversation. In doing so, we recover a policy capable of talking\nto a user given a prompt (input state), and a discriminator capable of\nclassifying between expert and synthetic conversation. While our policy is\neffective, we recover results from our discriminator that indicate the\nlimitations of dialog models. We argue that this technique can be used to\nidentify adverse behavior of arbitrary data models common for dialog oriented\ntasks."}
{"id": "2508.12086", "pdf": "https://arxiv.org/pdf/2508.12086", "abs": "https://arxiv.org/abs/2508.12086", "authors": ["Yao Wu"], "title": "J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 90C29, 62F07", "I.2.7; I.2.6; G.1.6"], "comment": "9 pages, 3 tables, 1 algorithm", "summary": "In large language model (LLM) adaptation, balancing multiple optimization\nobjectives such as improving factuality (heat) and increasing confidence (via\nlow entropy) poses a fundamental challenge, especially when prompt parameters\n(e.g., hidden-layer insertions h and embedding modifications w) interact in\nnon-trivial ways. Existing multi-objective optimization strategies often rely\non scalar gradient aggregation, ignoring the deeper geometric structure between\nobjectives and parameters. We propose J6, a structured Jacobian-based method\nthat decomposes the gradient interaction matrix into six interpretable\ncomponents. This decomposition enables both hard decision-making (e.g.,\nchoosing the dominant update direction via argmax) and soft strategies (e.g.,\nattention-style weighting via softmax over J6), forming a dynamic update\nframework that adapts to local conflict and synergy. Moreover, the\ninterpretable structure of J6 provides insight into parameter attribution, task\ninterference, and geometry-aligned adaptation. Our work introduces a principled\nand extensible mechanism for conflict-aware prompt optimization, and opens a\nnew avenue for incorporating structured Jacobian reasoning into multi-objective\nneural tuning."}
{"id": "2508.11784", "pdf": "https://arxiv.org/pdf/2508.11784", "abs": "https://arxiv.org/abs/2508.11784", "authors": ["Zabir Al Nazi", "Vagelis Hristidis", "Aaron Lawson McLean", "Jannat Ara Meem", "Md Taukir Azam Chowdhury"], "title": "Ontology-Guided Query Expansion for Biomedical Document Retrieval using Large Language Models", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Effective Question Answering (QA) on large biomedical document collections\nrequires effective document retrieval techniques. The latter remains a\nchallenging task due to the domain-specific vocabulary and semantic ambiguity\nin user queries. We propose BMQExpander, a novel ontology-aware query expansion\npipeline that combines medical knowledge - definitions and relationships - from\nthe UMLS Metathesaurus with the generative capabilities of large language\nmodels (LLMs) to enhance retrieval effectiveness. We implemented several\nstate-of-the-art baselines, including sparse and dense retrievers, query\nexpansion methods, and biomedical-specific solutions. We show that BMQExpander\nhas superior retrieval performance on three popular biomedical Information\nRetrieval (IR) benchmarks: NFCorpus, TREC-COVID, and SciFact - with\nimprovements of up to 22.1% in NDCG@10 over sparse baselines and up to 6.5%\nover the strongest baseline. Further, BMQExpander generalizes robustly under\nquery perturbation settings, in contrast to supervised baselines, achieving up\nto 15.7% improvement over the strongest baseline. As a side contribution, we\npublish our paraphrased benchmarks. Finally, our qualitative analysis shows\nthat BMQExpander has fewer hallucinations compared to other LLM-based query\nexpansion baselines."}
{"id": "2508.12096", "pdf": "https://arxiv.org/pdf/2508.12096", "abs": "https://arxiv.org/abs/2508.12096", "authors": ["Haiquan Hu", "Jiazhi Jiang", "Shiyou Xu", "Ruhan Zeng", "Tian Wang"], "title": "STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submit to AAAI 2026", "summary": "Evaluating large language models (LLMs) has become increasingly challenging\nas model capabilities advance rapidly. While recent models often achieve higher\nscores on standard benchmarks, these improvements do not consistently reflect\nenhanced real-world reasoning capabilities. Moreover, widespread overfitting to\npublic benchmarks and the high computational cost of full evaluations have made\nit both expensive and less effective to distinguish meaningful differences\nbetween models. To address these challenges, we propose the \\textbf{S}tructured\n\\textbf{T}ransition \\textbf{E}valuation \\textbf{M}ethod (STEM), a lightweight\nand interpretable evaluation framework for efficiently estimating the relative\ncapabilities of LLMs. STEM identifies \\textit{significant transition samples}\n(STS) by analyzing consistent performance transitions among LLMs of the same\narchitecture but varying parameter scales. These samples enable STEM to\neffectively estimate the capability position of an unknown model. Qwen3 model\nfamily is applied to construct the STS pool on six diverse and representative\nbenchmarks. To assess generalizability. Experimental results indicate that STEM\nreliably captures performance trends, aligns with ground-truth rankings of\nmodel capability. These findings highlight STEM as a practical and scalable\nmethod for fine-grained, architecture-agnostic evaluation of LLMs."}
{"id": "2508.11803", "pdf": "https://arxiv.org/pdf/2508.11803", "abs": "https://arxiv.org/abs/2508.11803", "authors": ["Azam Nouri"], "title": "An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation", "categories": ["cs.CV", "cs.LG"], "comment": "5 pages, No figure", "summary": "This study investigates whether second-order geometric cues - planar\ncurvature magnitude, curvature sign, and gradient orientation - are sufficient\non their own to drive a multilayer perceptron (MLP) classifier for handwritten\ncharacter recognition (HCR), offering an alternative to convolutional neural\nnetworks (CNNs). Using these three handcrafted feature maps as inputs, our\ncurvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89\npercent on EMNIST letters. These results underscore the discriminative power of\ncurvature-based representations for handwritten character images and\ndemonstrate that the advantages of deep learning can be realized even with\ninterpretable, hand-engineered features."}
{"id": "2508.12104", "pdf": "https://arxiv.org/pdf/2508.12104", "abs": "https://arxiv.org/abs/2508.12104", "authors": ["Shane Waxler", "Paul Blazek", "Davis White", "Daniel Sneider", "Kevin Chung", "Mani Nagarathnam", "Patrick Williams", "Hank Voeller", "Karen Wong", "Matthew Swanhorst", "Sheng Zhang", "Naoto Usuyama", "Cliff Wong", "Tristan Naumann", "Hoifung Poon", "Andrew Loza", "Daniella Meeker", "Seth Hain", "Rahul Shah"], "title": "Generative Medical Event Models Improve with Scale", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Realizing personalized medicine at scale calls for methods that distill\ninsights from longitudinal patient journeys, which can be viewed as a sequence\nof medical events. Foundation models pretrained on large-scale medical event\ndata represent a promising direction for scaling real-world evidence generation\nand generalizing to diverse downstream tasks. Using Epic Cosmos, a dataset with\nmedical events from de-identified longitudinal health records for 16.3 billion\nencounters over 300 million unique patient records from 310 health systems, we\nintroduce the Cosmos Medical Event Transformer ( CoMET) models, a family of\ndecoder-only transformer models pretrained on 118 million patients representing\n115 billion discrete medical events (151 billion tokens). We present the\nlargest scaling-law study for medical event data, establishing a methodology\nfor pretraining and revealing power-law scaling relationships for compute,\ntokens, and model size. Based on this, we pretrained a series of\ncompute-optimal models with up to 1 billion parameters. Conditioned on a\npatient's real-world history, CoMET autoregressively generates the next medical\nevent, simulating patient health timelines. We studied 78 real-world tasks,\nincluding diagnosis prediction, disease prognosis, and healthcare operations.\nRemarkably for a foundation model with generic pretraining and simulation-based\ninference, CoMET generally outperformed or matched task-specific supervised\nmodels on these tasks, without requiring task-specific fine-tuning or few-shot\nexamples. CoMET's predictive power consistently improves as the model and\npretraining scale. Our results show that CoMET, a generative medical event\nfoundation model, can effectively capture complex clinical dynamics, providing\nan extensible and generalizable framework to support clinical decision-making,\nstreamline healthcare operations, and improve patient outcomes."}
{"id": "2508.11818", "pdf": "https://arxiv.org/pdf/2508.11818", "abs": "https://arxiv.org/abs/2508.11818", "authors": ["Zhifeng Kong", "Arushi Goel", "Joao Felipe Santos", "Sreyan Ghosh", "Rafael Valle", "Wei Ping", "Bryan Catanzaro"], "title": "Audio Flamingo Sound-CoT Technical Report: Improving Chain-of-Thought Reasoning in Sound Understanding", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Chain-of-thought reasoning has demonstrated significant improvements in large\nlanguage models and vision language models, yet its potential for audio\nlanguage models remains largely unexplored. In this technical report, we take a\npreliminary step towards closing this gap. For better assessment of sound\nreasoning, we propose AF-Reasoning-Eval, a benchmark targeting common-sense\nreasoning and the ability to discriminate among closely related choices. To\nprepare training corpus for sound reasoning abilities, we propose automatic\npipelines that transform existing audio question answering and classification\ndata into explicit reasoning chains, yielding AF-CoT-Train with 1.24M samples.\nWe study the effect of finetuning Audio Flamingo series on AF-CoT-Train and\nobserve considerable improvements on several reasoning benchmarks, validating\nthe effectiveness of chain-of-thought finetuning on advanced sound\nunderstanding."}
{"id": "2508.12109", "pdf": "https://arxiv.org/pdf/2508.12109", "abs": "https://arxiv.org/abs/2508.12109", "authors": ["Ye Wang", "Qianglong Chen", "Zejun Li", "Siyuan Wang", "Shijie Guo", "Zhirui Zhang", "Zhongyu Wei"], "title": "Simple o3: Towards Interleaved Vision-Language Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have shown impressive performance on\nvision-language tasks, but their long Chain-of-Thought (CoT) capabilities in\nmultimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which\nemulates human-like ''thinking with image'' through iterative visual\ntransformations and linguistic reasoning, we propose Simple o3, an end-to-end\nframework that integrates dynamic tool interactions (e.g., cropping, zooming,\nand reusing) into interleaved vision-language reasoning via supervised\nfine-tuning (SFT). Our approach features a scalable data synthesis pipeline\nthat generates high-quality interleaved vision-language reasoning chains via an\n''observe-reason-act'' cycle, complete with executable visual operations and\nrigorous verification, yielding the open-source TWI-Tools-146K dataset.\nExperimental results demonstrate Simple o3's superior performance on diverse\nbenchmarks, outperforming existing approaches. By combining enhanced reasoning\ncapabilities, Simple o3 establishes a powerful yet computationally affordable\nparadigm for advancing multimodal reasoning. Remarkably, we provide the first\nin-depth analysis of different interleaved reasoning strategies, offering\ninsights into their impact on model performance. We found that by introducing\nadditional visual tokens for interleaved vision-language reasoning, reusing and\nmagnifying the original image significantly improves the model's visual\nreasoning and fine-grained perception, while image cropping based on precise\nvisual grounding allows the model to effectively focus on key entities or\nregions, further enhancing its capabilities."}
{"id": "2508.11826", "pdf": "https://arxiv.org/pdf/2508.11826", "abs": "https://arxiv.org/abs/2508.11826", "authors": ["Dehn Xu", "Tim Katzke", "Emmanuel Müller"], "title": "From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have emerged as a powerful approach for\ngraph-based machine learning tasks. Previous work applied GNNs to image-derived\ngraph representations for various downstream tasks such as classification or\nanomaly detection. These transformations include segmenting images, extracting\nfeatures from segments, mapping them to nodes, and connecting them. However, to\nthe best of our knowledge, no study has rigorously compared the effectiveness\nof the numerous potential image-to-graph transformation approaches for\nGNN-based graph-level anomaly detection (GLAD). In this study, we\nsystematically evaluate the efficacy of multiple segmentation schemes, edge\nconstruction strategies, and node feature sets based on color, texture, and\nshape descriptors to produce suitable image-derived graph representations to\nperform graph-level anomaly detection. We conduct extensive experiments on\ndermoscopic images using state-of-the-art GLAD models, examining performance\nand efficiency in purely unsupervised, weakly supervised, and fully supervised\nregimes. Our findings reveal, for example, that color descriptors contribute\nthe best standalone performance, while incorporating shape and texture features\nconsistently enhances detection efficacy. In particular, our best unsupervised\nconfiguration using OCGTL achieves a competitive AUC-ROC score of up to 0.805\nwithout relying on pretrained backbones like comparable image-based approaches.\nWith the inclusion of sparse labels, the performance increases substantially to\n0.872 and with full supervision to 0.914 AUC-ROC."}
{"id": "2508.12116", "pdf": "https://arxiv.org/pdf/2508.12116", "abs": "https://arxiv.org/abs/2508.12116", "authors": ["Haebin Shin", "Lei Ji", "Xiao Liu", "Zhiwei Yu", "Qi Chen", "Yeyun Gong"], "title": "DynamixSFT: Dynamic Mixture Optimization of Instruction Tuning Collections", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As numerous instruction-tuning datasets continue to emerge during the\npost-training stage, dynamically balancing and optimizing their mixtures has\nbecome a critical challenge. To address this, we propose DynamixSFT, a dynamic\nand automated method for instruction-tuning dataset mixture optimization. We\nformulate the problem as a multi-armed bandit setup and introduce a\nPrior-scaled Boltzmann Exploration that softly anchors the updated sampling\ndistribution to the original dataset proportions, thereby preserving the\ninherent diversity and coverage of the collection. Sampling probabilities are\nupdated using a lightweight 1-Step Look-ahead Reward, reflecting how much the\ndataset contributes to improving the model's performance at its current state.\nWhen applied to the Tulu-v2-mixture collection comprising 16 instruction-tuning\ndatasets, DynamixSFT achieves up to a 2.2% performance improvement across 10\nbenchmarks. Furthermore, we provide a comprehensive analysis and visualizations\nto offer deeper insights into the adaptive dynamics of our method."}
{"id": "2508.11845", "pdf": "https://arxiv.org/pdf/2508.11845", "abs": "https://arxiv.org/abs/2508.11845", "authors": ["Marius Miron", "David Robinson", "Milad Alizadeh", "Ellen Gilsenan-McMahon", "Gagan Narula", "Olivier Pietquin", "Matthieu Geist", "Emmanuel Chemla", "Maddie Cusimano", "Felix Effenberger", "Masato Hagiwara", "Benjamin Hoffman", "Sara Keen", "Diane Kim", "Jane Lawton", "Jen-Yu Liu", "Aza Raskin"], "title": "What Matters for Bioacoustic Encoding", "categories": ["cs.SD", "cs.AI", "cs.IR", "cs.LG"], "comment": null, "summary": "Bioacoustics, the study of sounds produced by living organisms, plays a vital\nrole in conservation, biodiversity monitoring, and behavioral studies. Many\ntasks in this field, such as species, individual, and behavior classification\nand detection, are well-suited to machine learning. However, they often suffer\nfrom limited annotated data, highlighting the need for a general-purpose\nbioacoustic encoder capable of extracting useful representations for diverse\ndownstream tasks. Such encoders have been proposed before, but are often\nlimited in scope due to a focus on a narrow range of species (typically birds),\nand a reliance on a single model architecture or training paradigm. Moreover,\nthey are usually evaluated on a small set of tasks and datasets. In this work,\nwe present a large-scale empirical study that covers aspects of bioacoustics\nthat are relevant to research but have previously been scarcely considered:\ntraining data diversity and scale, model architectures and training recipes,\nand the breadth of evaluation tasks and datasets. We obtain encoders that are\nstate-of-the-art on the existing and proposed benchmarks. We also identify what\nmatters for training these encoders, such that this work can be extended when\nmore data are available or better architectures are proposed. Specifically,\nacross 26 datasets with tasks including species classification, detection,\nindividual ID, and vocal repertoire discovery, we find self-supervised\npre-training followed by supervised post-training on a mixed bioacoustics +\ngeneral-audio corpus yields the strongest in- and out-of-distribution\nperformance. We show the importance of data diversity in both stages. To\nsupport ongoing research and application, we will release the model\ncheckpoints."}
{"id": "2508.12138", "pdf": "https://arxiv.org/pdf/2508.12138", "abs": "https://arxiv.org/abs/2508.12138", "authors": ["Mohammad Ishzaz Asif Rafid", "Morsalin Sakib"], "title": "Substituting Proof of Work in Blockchain with Training-Verified Collaborative Model Computation", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Bitcoin's Proof of Work (PoW) mechanism, while central to achieving\ndecentralized consensus, has long been criticized for excessive energy use and\nhardware inefficiencies \\cite{devries2018bitcoin, truby2018decarbonizing}. This\npaper introduces a hybrid architecture that replaces Bitcoin's traditional PoW\nwith a centralized, cloud-based collaborative training framework. In this\nmodel, miners contribute computing resources to train segments of horizontally\nscaled machine learning models on preprocessed datasets, ensuring privacy and\ngenerating meaningful outputs \\cite{li2017securing}. A central server evaluates\ncontributions using two metrics: number of parameters trained and reduction in\nmodel loss during each cycle. At the end of every cycle, a weighted lottery\nselects the winning miner, who receives a digitally signed certificate. This\ncertificate serves as a verifiable substitute for PoW and grants the right to\nappend a block to the blockchain \\cite{nakamoto2008bitcoin}. By integrating\ndigital signatures and SHA-256 hashing \\cite{nist2015sha}, the system preserves\nblockchain integrity while redirecting energy toward productive computation.\nThe proposed approach addresses the sustainability concerns of traditional\nmining by converting resource expenditure into socially valuable work, aligning\nsecurity incentives with real-world computational progress."}
{"id": "2508.11847", "pdf": "https://arxiv.org/pdf/2508.11847", "abs": "https://arxiv.org/abs/2508.11847", "authors": ["Jenny Y. Huang", "Yunyi Shen", "Dennis Wei", "Tamara Broderick"], "title": "Dropping Just a Handful of Preferences Can Change Top Large Language Model Rankings", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose a method for evaluating the robustness of a widely used LLM\nranking system -- the Bradley--Terry ranking system -- to dropping a worst-case\nvery small fraction of evaluation data. Our approach is computationally fast\nand easy to adopt. When we apply our method to matchups from two popular\nhuman-preference platforms, Chatbot Arena and MT-Bench, we find that the\nBradley--Terry rankings of top-performing models are remarkably sensitive to\nthe removal of a small fraction of evaluations. Our framework also identifies\nthe specific evaluations most responsible for such ranking flips, allowing for\ninspections of these influential preferences. We observe that the rankings\nderived from MT-Bench preferences are notably more robust than those from\nChatbot Arena, likely due to MT-bench's use of expert annotators and carefully\nconstructed prompts. Finally, we find that rankings based on crowdsourced\nhuman-evaluated systems are just as sensitive as those based on LLM-as-a-judge\nevaluations, where in both, dropping as little as 0.02% of the total\nevaluations in the dataset can change the top-ranked model."}
{"id": "2508.12147", "pdf": "https://arxiv.org/pdf/2508.12147", "abs": "https://arxiv.org/abs/2508.12147", "authors": ["Donghang Lyu", "Marius Staring", "Mariya Doneva", "Hildo J. Lamb", "Nicola Pezzotti"], "title": "KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for\nassessing cardiac structure, function, and blood flow. Cine MRI extends this by\ncapturing heart motion, providing detailed insights into cardiac mechanics. To\nreduce scan time and breath-hold discomfort, fast acquisition techniques have\nbeen utilized at the cost of lowering image quality. Recently, Implicit Neural\nRepresentation (INR) methods have shown promise in unsupervised reconstruction\nby learning coordinate-to-value mappings from undersampled data, enabling\nhigh-quality image recovery. However, current existing INR methods primarily\nfocus on using coordinate-based positional embeddings to learn the mapping,\nwhile overlooking the feature representations of the target point and its\nneighboring context. In this work, we propose KP-INR, a dual-branch INR method\noperating in k-space for cardiac cine MRI reconstruction: one branch processes\nthe positional embedding of k-space coordinates, while the other learns from\nlocal multi-scale k-space feature representations at those coordinates. By\nenabling cross-branch interaction and approximating the target k-space values\nfrom both branches, KP-INR can achieve strong performance on challenging\nCartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its\nimproved performance over baseline models and highlights its potential in this\nfield."}
{"id": "2508.11848", "pdf": "https://arxiv.org/pdf/2508.11848", "abs": "https://arxiv.org/abs/2508.11848", "authors": ["Pouya Kananian", "Hans-Arno Jacobsen"], "title": "Adversarial Robustness in Distributed Quantum Machine Learning", "categories": ["quant-ph", "cs.ET", "cs.LG"], "comment": "This is a preprint of a book chapter that is planned to be published\n  in \"Quantum Robustness in Artificial Intelligence\" by Springer Nature", "summary": "Studying adversarial robustness of quantum machine learning (QML) models is\nessential in order to understand their potential advantages over classical\nmodels and build trustworthy systems. Distributing QML models allows leveraging\nmultiple quantum processors to overcome the limitations of individual devices\nand build scalable systems. However, this distribution can affect their\nadversarial robustness, potentially making them more vulnerable to new attacks.\nKey paradigms in distributed QML include federated learning, which, similar to\nclassical models, involves training a shared model on local data and sending\nonly the model updates, as well as circuit distribution methods inherent to\nquantum computing, such as circuit cutting and teleportation-based techniques.\nThese quantum-specific methods enable the distributed execution of quantum\ncircuits across multiple devices. This work reviews the differences between\nthese distribution methods, summarizes existing approaches on the adversarial\nrobustness of QML models when distributed using each paradigm, and discusses\nopen questions in this area."}
{"id": "2508.12148", "pdf": "https://arxiv.org/pdf/2508.12148", "abs": "https://arxiv.org/abs/2508.12148", "authors": ["Jimmy Z. Di", "Yiwei Lu", "Yaoliang Yu", "Gautam Kamath", "Adam Dziedzic", "Franziska Boenisch"], "title": "Demystifying Foreground-Background Memorization in Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion models (DMs) memorize training images and can reproduce\nnear-duplicates during generation. Current detection methods identify verbatim\nmemorization but fail to capture two critical aspects: quantifying partial\nmemorization occurring in small image regions, and memorization patterns beyond\nspecific prompt-image pairs. To address these limitations, we propose\nForeground Background Memorization (FB-Mem), a novel segmentation-based metric\nthat classifies and quantifies memorized regions within generated images. Our\nmethod reveals that memorization is more pervasive than previously understood:\n(1) individual generations from single prompts may be linked to clusters of\nsimilar training images, revealing complex memorization patterns that extend\nbeyond one-to-one correspondences; and (2) existing model-level mitigation\nmethods, such as neuron deactivation and pruning, fail to eliminate local\nmemorization, which persists particularly in foreground regions. Our work\nestablishes an effective framework for measuring memorization in diffusion\nmodels, demonstrates the inadequacy of current mitigation approaches, and\nproposes a stronger mitigation method using a clustering approach."}
{"id": "2508.11854", "pdf": "https://arxiv.org/pdf/2508.11854", "abs": "https://arxiv.org/abs/2508.11854", "authors": ["Matthew Hull", "Haoyang Yang", "Pratham Mehta", "Mansi Phute", "Aeree Cho", "Haorang Wang", "Matthew Lau", "Wenke Lee", "Wilian Lunardi", "Martin Andreoni", "Polo Chau"], "title": "ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 6 figures", "summary": "As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks\nfor efficient novel-view synthesis from static images, how might an adversary\ntamper images to cause harm? We introduce ComplicitSplat, the first attack that\nexploits standard 3DGS shading methods to create viewpoint-specific camouflage\n- colors and textures that change with viewing angle - to embed adversarial\ncontent in scene objects that are visible only from specific viewpoints and\nwithout requiring access to model architecture or weights. Our extensive\nexperiments show that ComplicitSplat generalizes to successfully attack a\nvariety of popular detector - both single-stage, multi-stage, and\ntransformer-based models on both real-world capture of physical objects and\nsynthetic scenes. To our knowledge, this is the first black-box attack on\ndownstream object detectors using 3DGS, exposing a novel safety risk for\napplications like autonomous navigation and other mission-critical robotic\nsystems."}
{"id": "2508.12162", "pdf": "https://arxiv.org/pdf/2508.12162", "abs": "https://arxiv.org/abs/2508.12162", "authors": ["J. M. I. H. Jayakody", "A. M. H. H. Alahakoon", "C. R. M. Perera", "R. M. L. C. Srimal", "Roshan Ragel", "Vajira Thambawita", "Isuru Nawinne"], "title": "AICRN: Attention-Integrated Convolutional Residual Network for Interpretable Electrocardiogram Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The paradigm of electrocardiogram (ECG) analysis has evolved into real-time\ndigital analysis, facilitated by artificial intelligence (AI) and machine\nlearning (ML), which has improved the diagnostic precision and predictive\ncapacity of cardiac diseases. This work proposes a novel deep learning (DL)\narchitecture called the attention-integrated convolutional residual network\n(AICRN) to regress key ECG parameters such as the PR interval, the QT interval,\nthe QRS duration, the heart rate, the peak amplitude of the R wave, and the\namplitude of the T wave for interpretable ECG analysis. Our architecture is\nspecially designed with spatial and channel attention-related mechanisms to\naddress the type and spatial location of the ECG features for regression. The\nmodels employ a convolutional residual network to address vanishing and\nexploding gradient problems. The designed system addresses traditional analysis\nchallenges, such as loss of focus due to human errors, and facilitates the fast\nand easy detection of cardiac events, thereby reducing the manual efforts\nrequired to solve analysis tasks. AICRN models outperform existing models in\nparameter regression with higher precision. This work demonstrates that DL can\nplay a crucial role in the interpretability and precision of ECG analysis,\nopening up new clinical applications for cardiac monitoring and management."}
{"id": "2508.11857", "pdf": "https://arxiv.org/pdf/2508.11857", "abs": "https://arxiv.org/abs/2508.11857", "authors": ["Andrei-Valentin Tănase", "Elena Pelican"], "title": "SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Tokenization remains a fundamental yet underexplored bottleneck in natural\nlanguage processing, with strategies largely static despite remarkable progress\nin model architectures. We present SupraTok, a novel tokenization architecture\nthat reimagines subword segmentation through three innovations: cross-boundary\npattern learning that discovers multi-word semantic units, entropy-driven data\ncuration that optimizes training corpus quality, and multi-phase curriculum\nlearning for stable convergence. Our approach extends Byte-Pair Encoding by\nlearning \"superword\" tokens, coherent multi-word expressions that preserve\nsemantic unity while maximizing compression efficiency. SupraTok achieves 31%\nimprovement in English tokenization efficiency (5.91 versus 4.51 characters per\ntoken) compared to OpenAI's o200k tokenizer and 30% improvement over Google's\nGemma 3 tokenizer (256k vocabulary), while maintaining competitive performance\nacross 38 languages. When integrated with a GPT-2 scale model (124M parameters)\ntrained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%\nimprovement on HellaSWAG and 9.5% on MMLU benchmarks without architectural\nmodifications. While these results are promising at this scale, further\nvalidation at larger model scales is needed. These findings suggest that\nefficient tokenization can complement architectural innovations as a path to\nimproved language model performance."}
{"id": "2508.12163", "pdf": "https://arxiv.org/pdf/2508.12163", "abs": "https://arxiv.org/abs/2508.12163", "authors": ["Wenqing Wang", "Yun Fu"], "title": "RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "I.4; I.3; I.2"], "comment": "Accepted to the ICCV 2025 Workshop on Artificial Social Intelligence", "summary": "Emotion is a critical component of artificial social intelligence. However,\nwhile current methods excel in lip synchronization and image quality, they\noften fail to generate accurate and controllable emotional expressions while\npreserving the subject's identity. To address this challenge, we introduce\nRealTalk, a novel framework for synthesizing emotional talking heads with high\nemotion accuracy, enhanced emotion controllability, and robust identity\npreservation. RealTalk employs a variational autoencoder (VAE) to generate 3D\nfacial landmarks from driving audio, which are concatenated with emotion-label\nembeddings using a ResNet-based landmark deformation model (LDM) to produce\nemotional landmarks. These landmarks and facial blendshape coefficients jointly\ncondition a novel tri-plane attention Neural Radiance Field (NeRF) to\nsynthesize highly realistic emotional talking heads. Extensive experiments\ndemonstrate that RealTalk outperforms existing methods in emotion accuracy,\ncontrollability, and identity preservation, advancing the development of\nsocially intelligent AI systems."}
{"id": "2508.11863", "pdf": "https://arxiv.org/pdf/2508.11863", "abs": "https://arxiv.org/abs/2508.11863", "authors": ["Mansi Sood", "Eray Can Elumar", "Osman Yagan"], "title": "On Balancing Sparsity with Reliable Connectivity in Distributed Network Design with Random K-out Graphs", "categories": ["cs.SI", "cs.IT", "cs.LG", "cs.NI", "math.IT", "math.OC"], "comment": "Present extensive evaluation of connectivity and related properties\n  of random K-out graphs with several use cases in network design. Subsumes\n  earlier results in IEEE ISIT 2021, ICC 2021, and ICC 2023", "summary": "In several applications in distributed systems, an important design criterion\nis ensuring that the network is sparse, i.e., does not contain too many edges,\nwhile achieving reliable connectivity. Sparsity ensures communication overhead\nremains low, while reliable connectivity is tied to reliable communication and\ninference on decentralized data reservoirs and computational resources. A class\nof network models called random K-out graphs appear widely as a heuristic to\nbalance connectivity and sparsity, especially in settings with limited trust,\ne.g., privacy-preserving aggregation of networked data in which networks are\ndeployed. However, several questions remain regarding how to choose network\nparameters in response to different operational requirements, including the\nneed to go beyond asymptotic results and the ability to model the stochastic\nand adversarial environments. To address this gap, we present theorems to\ninform the choice of network parameters that guarantee reliable connectivity in\nregimes where nodes can be finite or unreliable. We first derive upper and\nlower bounds for probability of connectivity in random K-out graphs when the\nnumber of nodes is finite. Next, we analyze the property of r-robustness, a\nstronger notion than connectivity that enables resilient consensus in the\npresence of malicious nodes. Finally, motivated by aggregation mechanisms based\non pairwise masking, we model and analyze the impact of a subset of adversarial\nnodes, modeled as deletions, on connectivity and giant component size - metrics\nthat are closely tied to privacy guarantees. Together, our results pave the way\nfor end-to-end performance guarantees for a suite of algorithms for reliable\ninference on networks."}
{"id": "2508.12189", "pdf": "https://arxiv.org/pdf/2508.12189", "abs": "https://arxiv.org/abs/2508.12189", "authors": ["Rhea Malhotra", "Yuejiang Liu", "Chelsea Finn"], "title": "Self-Guided Action Diffusion", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Recent works have shown the promise of inference-time search over action\nsamples for improving generative robot policies. In particular, optimizing\ncross-chunk coherence via bidirectional decoding has proven effective in\nboosting the consistency and reactivity of diffusion policies. However, this\napproach remains computationally expensive as the diversity of sampled actions\ngrows. In this paper, we introduce self-guided action diffusion, a more\nefficient variant of bidirectional decoding tailored for diffusion-based\npolicies. At the core of our method is to guide the proposal distribution at\neach diffusion step based on the prior decision. Experiments in simulation\ntasks show that the proposed self-guidance enables near-optimal performance at\nnegligible inference cost. Notably, under a tight sampling budget, our method\nachieves up to 70% higher success rates than existing counterparts on\nchallenging dynamic tasks. See project website at\nhttps://rhea-mal.github.io/selfgad.github.io."}
{"id": "2508.11872", "pdf": "https://arxiv.org/pdf/2508.11872", "abs": "https://arxiv.org/abs/2508.11872", "authors": ["Xinxing Wu"], "title": "Singing Syllabi with Virtual Avatars: Enhancing Student Engagement Through AI-Generated Music and Digital Embodiment", "categories": ["cs.CY", "cs.AI", "cs.LG", "cs.MM"], "comment": "17 pages, 4 figures, 3 tables", "summary": "In practical teaching, we observe that few students thoroughly read or fully\ncomprehend the information provided in traditional, text-based course syllabi.\nAs a result, essential details, such as course policies and learning outcomes,\nare frequently overlooked. To address this challenge, in this paper, we propose\na novel approach leveraging AI-generated singing and virtual avatars to present\nsyllabi in a format that is more visually appealing, engaging, and memorable.\nEspecially, we leveraged the open-source tool, HeyGem, to transform textual\nsyllabi into audiovisual presentations, in which digital avatars perform the\nsyllabus content as songs. The proposed approach aims to stimulate students'\ncuriosity, foster emotional connection, and enhance retention of critical\ncourse information. Student feedback indicated that AI-sung syllabi\nsignificantly improved awareness and recall of key course information."}
{"id": "2508.12198", "pdf": "https://arxiv.org/pdf/2508.12198", "abs": "https://arxiv.org/abs/2508.12198", "authors": ["ChangJae Lee", "Heecheol Yang", "Jonghak Choi"], "title": "Exploring Multimodal AI Reasoning for Meteorological Forecasting from Skew-T Diagrams", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "comment": "24 pages, 3 figures, 9 tables", "summary": "Forecasting from atmospheric soundings is a fundamental task in operational\nmeteorology, often requiring structured visual reasoning over Skew-T log-P\ndiagrams by human forecasters. While recent advances in Vision-Language Models\n(VLMs) have shown promise in other scientific domains, their application to\nmeteorological diagram interpretation remains largely unexplored. In this\nstudy, we present a lightweight AI assistant that interprets Skew-T diagrams\nusing a small language model (LM) and a small VLM fine-tuned to emulate human\nforecasters. Using a curriculum learning framework, we first train the models\nto identify key atmospheric features from diagrams through visual question\nanswering, followed by chain-of-thought reasoning tasks that estimate\nprecipitation probability based on the derived visual groundings. Model inputs\ninclude either textual summaries or generated Skew-T diagrams derived from\noperational Numerical Weather Prediction (NWP) forecasts, paired with\nthree-hour precipitation observations from South Korea's Auto Weather Stations\nnetwork. Evaluation results demonstrate that the fine-tuned VLM achieves skill\ncomparable to an operational NWP model, despite relying solely on static\natmospheric profiles. Ablation studies reveal that visual grounding and\nreasoning supervision are critical for performance, while attention map\nanalysis confirms that the model learns to focus on relevant meteorological\nfeatures. These findings highlight the potential of compact, interpretable\nmultimodal models to support weather forecasting tasks. The approach offers a\ncomputationally efficient alternative to large-scale systems, and future work\ncould extend it to more complex applications."}
{"id": "2508.11886", "pdf": "https://arxiv.org/pdf/2508.11886", "abs": "https://arxiv.org/abs/2508.11886", "authors": ["Wenhui Zhu", "Xiwen Chen", "Zhipeng Wang", "Shao Tang", "Sayan Ghosh", "Xuanzhao Dong", "Rajat Koner", "Yalin Wang"], "title": "EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG", "eess.IV"], "comment": null, "summary": "Instructed Visual Segmentation (IVS) tasks require segmenting objects in\nimages or videos based on natural language instructions. While recent\nmultimodal large language models (MLLMs) have achieved strong performance on\nIVS, their inference cost remains a major bottleneck, particularly in video. We\nempirically analyze visual token sampling in MLLMs and observe a strong\ncorrelation between subset token coverage and segmentation performance. This\nmotivates our design of a simple and effective token pruning method that\nselects a compact yet spatially representative subset of tokens to accelerate\ninference. In this paper, we introduce a novel visual token pruning method for\nIVS, called EVTP-IV, which builds upon the k-center by integrating spatial\ninformation to ensure better coverage. We further provide an\ninformation-theoretic analysis to support our design. Experiments on standard\nIVS benchmarks show that our method achieves up to 5X speed-up on video tasks\nand 3.5X on image tasks, while maintaining comparable accuracy using only 20%\nof the tokens. Our method also consistently outperforms state-of-the-art\npruning baselines under varying pruning ratios."}
{"id": "2508.12211", "pdf": "https://arxiv.org/pdf/2508.12211", "abs": "https://arxiv.org/abs/2508.12211", "authors": ["Cyrus Neary", "Omar G. Younis", "Artur Kuramshin", "Ozgur Aslan", "Glen Berseth"], "title": "Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Pre-trained vision-language-action (VLA) models offer a promising foundation\nfor generalist robot policies, but often produce brittle behaviours or unsafe\nfailures when deployed zero-shot in out-of-distribution scenarios. We present\nVision-Language-Action Planning & Search (VLAPS) -- a novel framework and\naccompanying algorithms that embed model-based search into the inference\nprocedure of pre-trained VLA policies to improve their performance on robotic\ntasks. Specifically, our method biases a modified Monte Carlo Tree Search\n(MCTS) algorithm -- run using a model of the target environment -- using action\npriors defined by the VLA policy. By using VLA-derived abstractions and priors\nin model-based search, VLAPS efficiently explores language-conditioned robotics\ntasks whose search spaces would otherwise be intractably large. Conversely, by\nintegrating model-based search with the VLA policy's inference procedure, VLAPS\nyields behaviours that are more performant than those obtained by directly\nfollowing the VLA policy's action predictions. VLAPS offers a principled\nframework to: i) control test-time compute in VLA models, ii) leverage a priori\nknowledge of the robotic environment, and iii) integrate established planning\nand reinforcement learning techniques into the VLA inference process. Across\nall experiments, VLAPS significantly outperforms VLA-only baselines on\nlanguage-specified tasks that would otherwise be intractable for uninformed\nsearch algorithms, increasing success rates by as much as 67 percentage points."}
{"id": "2508.11902", "pdf": "https://arxiv.org/pdf/2508.11902", "abs": "https://arxiv.org/abs/2508.11902", "authors": ["Azam Nouri"], "title": "A Sobel-Gradient MLP Baseline for Handwritten Character Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is under consideration at Pattern Recognition Letters", "summary": "We revisit the classical Sobel operator to ask a simple question: Are\nfirst-order edge maps sufficient to drive an all-dense multilayer perceptron\n(MLP) for handwritten character recognition (HCR), as an alternative to\nconvolutional neural networks (CNNs)? Using only horizontal and vertical Sobel\nderivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its\nextreme simplicity, the resulting network reaches 98% accuracy on MNIST digits\nand 92% on EMNIST letters -- approaching CNNs while offering a smaller memory\nfootprint and transparent features. Our findings highlight that much of the\nclass-discriminative information in handwritten character images is already\ncaptured by first-order gradients, making edge-aware MLPs a compelling option\nfor HCR."}
{"id": "2508.12212", "pdf": "https://arxiv.org/pdf/2508.12212", "abs": "https://arxiv.org/abs/2508.12212", "authors": ["Chuanliu Fan", "Zicheng Ma", "Jun Gao", "Nan Yu", "Jun Zhang", "Ziqiang Cao", "Yi Qin Gao", "Guohong Fu"], "title": "ProtTeX-CC: Activating In-Context Learning in Protein LLM via Two-Stage Instruction Compression", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Recent advances in protein large language models, such as ProtTeX, represent\nboth side-chain amino acids and backbone structure as discrete token sequences\nof residue length. While this design enables unified modeling of multimodal\nprotein information, it suffers from two major limitations: (1) The\nconcatenation of sequence and structure tokens approximately doubles the\nprotein length and breaks the intrinsic residue-level alignment between\nmodalities. (2) Constrained by the training corpus and limited context window,\nProtTeX is typically trained on single-protein inputs, rendering it\nincompatible with in-context learning (ICL) and thus limiting its\ngeneralization capability. To address these issues, we propose ProtTeX-CC, a\nlightweight two-stage compression framework designed to enhance ProtTeX under\nfew-shot settings. We first design a joint embedding compression mechanism that\nfuses sequence and structure representations at the residue level, effectively\nreducing the protein input length by half without sacrificing performance. Then\nwe propose a self-compression module that aggregates each full demonstration\ninto the latent space of the last few linguistic tokens, reducing the average\ndemonstration length from 751 tokens to less than 16 tokens. Compared to the\noriginal ProtTeX, our self-compression approach achieves a compression ratio of\napproximately 93.68% in the total prompt length under the 16-shot setting.\nWithout modifying the backbone model, ProtTeX-CC introduces only a small number\nof additional parameters through PEFT-based tuning in the joint embedding\ncompression stage and a single trainable projection layer in the\nself-compression stage. Extensive experiments on protein function prediction\nshow that ProtTeX-CC improves performance on the in-domain benchmark by 2%, and\ngeneralizes well to the out-of-domain dataset with a performance gain of 11%."}
{"id": "2508.11911", "pdf": "https://arxiv.org/pdf/2508.11911", "abs": "https://arxiv.org/abs/2508.11911", "authors": ["Yongsheng Chen", "Wei Guo", "Qi Tang", "Xinghui Zhong"], "title": "Reduced-order modeling of Hamiltonian dynamics based on symplectic neural networks", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph"], "comment": null, "summary": "We introduce a novel data-driven symplectic induced-order modeling (ROM)\nframework for high-dimensional Hamiltonian systems that unifies latent-space\ndiscovery and dynamics learning within a single, end-to-end neural\narchitecture. The encoder-decoder is built from Henon neural networks\n(HenonNets) and may be augmented with linear SGS-reflector layers. This yields\nan exact symplectic map between full and latent phase spaces. Latent dynamics\nare advanced by a symplectic flow map implemented as a HenonNet. This unified\nneural architecture ensures exact preservation of the underlying symplectic\nstructure at the reduced-order level, significantly enhancing the fidelity and\nlong-term stability of the resulting ROM. We validate our method through\ncomprehensive numerical experiments on canonical Hamiltonian systems. The\nresults demonstrate the method's capability for accurate trajectory\nreconstruction, robust predictive performance beyond the training horizon, and\naccurate Hamiltonian preservation. These promising outcomes underscore the\neffectiveness and potential applicability of our symplectic ROM framework for\ncomplex dynamical systems across a broad range of scientific and engineering\ndisciplines."}
{"id": "2508.12213", "pdf": "https://arxiv.org/pdf/2508.12213", "abs": "https://arxiv.org/abs/2508.12213", "authors": ["Yize Cai", "Baoshen Guo", "Flora Salim", "Zhiqing Hong"], "title": "Towards Generalizable Human Activity Recognition: A Survey", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "As a critical component of Wearable AI, IMU-based Human Activity Recognition\n(HAR) has attracted increasing attention from both academia and industry in\nrecent years. Although HAR performance has improved considerably in specific\nscenarios, its generalization capability remains a key barrier to widespread\nreal-world adoption. For example, domain shifts caused by variations in users,\nsensor positions, or environments can significantly decrease the performance in\npractice. As a result, in this survey, we explore the rapidly evolving field of\nIMU-based generalizable HAR, reviewing 229 research papers alongside 25\npublicly available datasets to provide a broad and insightful overview. We\nfirst present the background and overall framework of IMU-based HAR tasks, as\nwell as the generalization-oriented training settings. Then, we categorize\nrepresentative methodologies from two perspectives: (i) model-centric\napproaches, including pre-training method, end-to-end method, and large\nlanguage model (LLM)-based learning method; and (ii) data-centric approaches,\nincluding multi-modal learning and data augmentation techniques. In addition,\nwe summarize widely used datasets in this field, as well as relevant tools and\nbenchmarks. Building on these methodological advances, the broad applicability\nof IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent\nchallenges (e.g., data scarcity, efficient training, and reliable evaluation)\nand also outline future directions for HAR, including the adoption of\nfoundation and large language models, physics-informed and context-aware\nreasoning, generative modeling, and resource-efficient training and inference.\nThe complete list of this survey is available at\nhttps://github.com/rh20624/Awesome-IMU-Sensing, which will be updated\ncontinuously."}
{"id": "2508.11915", "pdf": "https://arxiv.org/pdf/2508.11915", "abs": "https://arxiv.org/abs/2508.11915", "authors": ["Punya Syon Pandey", "Yongjin Yang", "Jiarui Liu", "Zhijing Jin"], "title": "CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Game-theoretic interactions between agents with Large Language Models (LLMs)\nhave revealed many emergent capabilities, yet the linguistic diversity of these\ninteractions has not been sufficiently quantified. In this paper, we present\nthe Conversational Robustness Evaluation Score: CORE, a metric to quantify the\neffectiveness of language use within multi-agent systems across different\ngame-theoretic interactions. CORE integrates measures of cluster entropy,\nlexical repetition, and semantic similarity, providing a direct lens of dialog\nquality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,\nand neutral settings, further grounding our analysis in Zipf's and Heaps' Laws\nto characterize word frequency distributions and vocabulary growth. Our\nfindings show that cooperative settings exhibit both steeper Zipf distributions\nand higher Heap exponents, indicating more repetition alongside greater\nvocabulary expansion. In contrast, competitive interactions display lower Zipf\nand Heaps exponents, reflecting less repetition and more constrained\nvocabularies. These results provide new insights into how social incentives\ninfluence language adaptation, and highlight CORE as a robust diagnostic for\nmeasuring linguistic robustness in multi-agent LLM systems. Our code is\navailable at https://github.com/psyonp/core."}
{"id": "2508.12220", "pdf": "https://arxiv.org/pdf/2508.12220", "abs": "https://arxiv.org/abs/2508.12220", "authors": ["Abdullah X"], "title": "Unlearning at Scale: Implementing the Right to be Forgotten in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CR", "I.2.6; I.2.7"], "comment": "Preprint; 2 figures + several tables; includes appendix.\n  Artifact/code link in paper", "summary": "We study the right to be forgotten (GDPR Art. 17) for large language models\nand frame unlearning as a reproducible systems problem. Our approach treats\ntraining as a deterministic program and logs a minimal per-microbatch record\n(ordered ID hash, RNG seed, learning-rate value, optimizer-step counter, and\naccumulation boundary). Under a pinned stack and deterministic kernels,\nreplaying the training tail while filtering only the forget closure yields the\nsame parameters as training on the retain set (bit-identical in the training\ndtype) when preconditions hold. To meet latency and availability constraints,\nwe add complementary paths: (i) exact reverts of recent steps via\nmicro-checkpoints or dense per-step deltas, (ii) cohort-scoped adapter deletion\nwhen the base is frozen, and (iii) a curvature-guided anti-update followed by a\nshort retain-tune, audit-gated with escalation to exact replay. We report\nstorage/latency budgets and a toy artifact validating mechanics; in a\ncontrolled run that satisfies the preconditions we demonstrate byte-identical\nequality of model and optimizer states."}
{"id": "2508.11925", "pdf": "https://arxiv.org/pdf/2508.11925", "abs": "https://arxiv.org/abs/2508.11925", "authors": ["Zhimeng Guo", "Huaisheng Zhu", "Siyuan Xu", "Hangfan Zhang", "Teng Xiao", "Minhao Cheng"], "title": "Optimizing Token Choice for Code Watermarking: A RL Approach", "categories": ["cs.CR", "cs.CL", "cs.LG"], "comment": "18 pages, 3 figures", "summary": "The need for detecting LLM-generated code necessitates watermarking systems\ncapable of operating within its highly structured and syntactically constrained\nenvironment. To address this, we introduce CodeTracer, an innovative adaptive\ncode watermarking framework underpinned by a novel reinforcement learning\ntraining paradigm. At its core, CodeTracer features a policy-driven approach\nthat utilizes a parameterized model to intelligently bias token choices during\nnext-token prediction. This strategy ensures that embedded watermarks maintain\ncode functionality while exhibiting subtle yet statistically detectable\ndeviations from typical token distributions. To facilitate policy learning, we\ndevise a comprehensive reward system that seamlessly integrates execution\nfeedback with watermark embedding signals, balancing process-level and\noutcome-level rewards. Additionally, we employ Gumbel Top-k reparameterization\nto enable gradient-based optimization of discrete watermarking decisions.\nExtensive comparative evaluations demonstrate CodeTracer's significant\nsuperiority over state-of-the-art baselines in both watermark detectability and\nthe preservation of generated code's functionality."}
{"id": "2508.12222", "pdf": "https://arxiv.org/pdf/2508.12222", "abs": "https://arxiv.org/abs/2508.12222", "authors": ["Sagar Shrestha", "Rajesh Shrestha", "Tri Nguyen", "Subash Timilsina"], "title": "Distribution Matching via Generalized Consistency Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancement in generative models have demonstrated remarkable\nperformance across various data modalities. Beyond their typical use in data\nsynthesis, these models play a crucial role in distribution matching tasks such\nas latent variable modeling, domain translation, and domain adaptation.\nGenerative Adversarial Networks (GANs) have emerged as the preferred method of\ndistribution matching due to their efficacy in handling high-dimensional data\nand their flexibility in accommodating various constraints. However, GANs often\nencounter challenge in training due to their bi-level min-max optimization\nobjective and susceptibility to mode collapse. In this work, we propose a novel\napproach for distribution matching inspired by the consistency models employed\nin Continuous Normalizing Flow (CNF). Our model inherits the advantages of CNF\nmodels, such as having a straight forward norm minimization objective, while\nremaining adaptable to different constraints similar to GANs. We provide\ntheoretical validation of our proposed objective and demonstrate its\nperformance through experiments on synthetic and real-world datasets."}
{"id": "2508.11935", "pdf": "https://arxiv.org/pdf/2508.11935", "abs": "https://arxiv.org/abs/2508.11935", "authors": ["Yuannuo Feng", "Wenyong Zhou", "Yuexi Lyu", "Hanjie Liu", "Zhengwu Liu", "Ngai Wong", "Wang Kang"], "title": "HPD: Hybrid Projection Decomposition for Robust State Space Models on Analog CIM Hardware", "categories": ["cs.AR", "cs.AI", "cs.LG"], "comment": "4 pages, 5 figures, conference", "summary": "State Space Models (SSMs) are efficient alternatives to traditional sequence\nmodels, excelling at processing long sequences with lower computational\ncomplexity. Their reliance on matrix multiplications makes them ideal for\ncompute-in-memory (CIM) architectures, which improve energy efficiency by\ncomputing within memory arrays. However, device non-idealities in CIM introduce\nweight perturbations that can degrade inference accuracy. In this paper, we\nsystematically analyze the robustness of SSMs under noisy conditions,\nidentifying that the final block and output projection layers are more\nsusceptible to perturbations compared to other components. Building on these\ninsights, we propose HPD, a Hybrid Projection Decomposition strategy for the\nlast output projection layer. We replace the original weight matrix with the\nmultiplication of U and {\\Sigma} in its SVD to ensure compatibility with\nexisting hardware architectures, while offloading V> to digital hardware for\nprecise and robust correction. Comprehensive tests on Mamba models show that\nour method reduces perplexity by up to 99.57% under various noise conditions\ncompared to baseline models, with accuracy gains of up to 96.67% on the PIQA\nbenchmark for commonsense reasoning."}
{"id": "2508.12232", "pdf": "https://arxiv.org/pdf/2508.12232", "abs": "https://arxiv.org/abs/2508.12232", "authors": ["Arshia Akhavan", "Alireza Hosseinpour", "Abbas Heydarnoori", "Mehdi Keshani"], "title": "LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Issue-to-commit link recovery plays an important role in software\ntraceability and improves project management. However, it remains a challenging\ntask. A study on GitHub shows that only 42.2% of the issues are correctly\nlinked to their commits. This highlights the potential for further development\nand research in this area. Existing studies have employed various AI/ML-based\napproaches, and with the recent development of large language models,\nresearchers have leveraged LLMs to tackle this problem. These approaches suffer\nfrom two main issues. First, LLMs are constrained by limited context windows\nand cannot ingest all of the available data sources, such as long commit\nhistories, extensive issue comments, and large code repositories. Second, most\nmethods operate on individual issue-commit pairs; that is, given a single\nissue-commit pair, they determine whether the commit resolves the issue. This\nquickly becomes impractical in real-world repositories containing tens of\nthousands of commits. To address these limitations, we present LinkAnchor, the\nfirst autonomous LLM-based agent designed for issue-to-commit link recovery.\nThe lazy-access architecture of LinkAnchor enables the underlying LLM to access\nthe rich context of software, spanning commits, issue comments, and code files,\nwithout exceeding the token limit by dynamically retrieving only the most\nrelevant contextual data. Additionally, LinkAnchor is able to automatically\npinpoint the target commit rather than exhaustively scoring every possible\ncandidate. Our evaluations show that LinkAnchor outperforms state-of-the-art\nissue-to-commit link recovery approaches by 60-262% in Hit@1 score across all\nour case study projects. We also publicly release LinkAnchor as a ready-to-use\ntool, along with our replication package. LinkAnchor is designed and tested for\nGitHub and Jira, and is easily extendable to other platforms."}
{"id": "2508.11957", "pdf": "https://arxiv.org/pdf/2508.11957", "abs": "https://arxiv.org/abs/2508.11957", "authors": ["Xiaodong Qu", "Andrews Damoah", "Joshua Sherwood", "Peiyan Liu", "Christian Shun Jin", "Lulu Chen", "Minjie Shen", "Nawwaf Aleisa", "Zeyuan Hou", "Chenyu Zhang", "Lifu Gao", "Yanshu Li", "Qikai Yang", "Qun Wang", "Cristabelle De Souza"], "title": "A Comprehensive Review of AI Agents: Transforming Possibilities in Technology and Beyond", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial Intelligence (AI) agents have rapidly evolved from specialized,\nrule-based programs to versatile, learning-driven autonomous systems capable of\nperception, reasoning, and action in complex environments. The explosion of\ndata, advances in deep learning, reinforcement learning, and multi-agent\ncoordination have accelerated this transformation. Yet, designing and deploying\nunified AI agents that seamlessly integrate cognition, planning, and\ninteraction remains a grand challenge. In this review, we systematically\nexamine the architectural principles, foundational components, and emergent\nparadigms that define the landscape of contemporary AI agents. We synthesize\ninsights from cognitive science-inspired models, hierarchical reinforcement\nlearning frameworks, and large language model-based reasoning. Moreover, we\ndiscuss the pressing ethical, safety, and interpretability concerns associated\nwith deploying these agents in real-world scenarios. By highlighting major\nbreakthroughs, persistent challenges, and promising research directions, this\nreview aims to guide the next generation of AI agent systems toward more\nrobust, adaptable, and trustworthy autonomous intelligence."}
{"id": "2508.12247", "pdf": "https://arxiv.org/pdf/2508.12247", "abs": "https://arxiv.org/abs/2508.12247", "authors": ["Haolong Chen", "Liang Zhang", "Zhengyuan Xin", "Guangxu Zhu"], "title": "STM3: Mixture of Multiscale Mamba for Long-Term Spatio-Temporal Time-Series Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, spatio-temporal time-series prediction has developed rapidly, yet\nexisting deep learning methods struggle with learning complex long-term\nspatio-temporal dependencies efficiently. The long-term spatio-temporal\ndependency learning brings two new challenges: 1) The long-term temporal\nsequence includes multiscale information naturally which is hard to extract\nefficiently; 2) The multiscale temporal information from different nodes is\nhighly correlated and hard to model. To address these challenges, we propose an\nefficient \\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ultiscale\n\\textbf{M}amba} (STM2) that includes a multiscale Mamba architecture to capture\nthe multiscale information efficiently and simultaneously, and an adaptive\ngraph causal convolution network to learn the complex multiscale\nspatio-temporal dependency. STM2 includes hierarchical information aggregation\nfor different-scale information that guarantees their distinguishability. To\ncapture diverse temporal dynamics across all spatial nodes more efficiently, we\nfurther propose an enhanced version termed\n\\textit{\\textbf{S}patio-\\textbf{T}emporal \\textbf{M}ixture of\n\\textbf{M}ultiscale \\textbf{M}amba} (STM3) that employs a special\nMixture-of-Experts architecture, including a more stable routing strategy and a\ncausal contrastive learning strategy to enhance the scale distinguishability.\nWe prove that STM3 has much better routing smoothness and guarantees the\npattern disentanglement for each expert successfully. Extensive experiments on\nreal-world benchmarks demonstrate STM2/STM3's superior performance, achieving\nstate-of-the-art results in long-term spatio-temporal time-series prediction."}
{"id": "2508.11978", "pdf": "https://arxiv.org/pdf/2508.11978", "abs": "https://arxiv.org/abs/2508.11978", "authors": ["Viacheslav Yusupov", "Maxim Rakhuba", "Evgeny Frolov"], "title": "Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Recent studies have demonstrated the potential of hyperbolic geometry for\ncapturing complex patterns from interaction data in recommender systems. In\nthis work, we introduce a novel hyperbolic recommendation model that uses\ngeometrical insights to improve representation learning and increase\ncomputational stability at the same time. We reformulate the notion of\nhyperbolic distances to unlock additional representation capacity over\nconventional Euclidean space and learn more expressive user and item\nrepresentations. To better capture user-items interactions, we construct a\ntriplet loss that models ternary relations between users and their\ncorresponding preferred and nonpreferred choices through a mix of pairwise\ninteraction terms driven by the geometry of data. Our hyperbolic approach not\nonly outperforms existing Euclidean and hyperbolic models but also reduces\npopularity bias, leading to more diverse and personalized recommendations."}
{"id": "2508.12253", "pdf": "https://arxiv.org/pdf/2508.12253", "abs": "https://arxiv.org/abs/2508.12253", "authors": ["Manish Shukla"], "title": "Interpreting Time Series Forecasts with LIME and SHAP: A Case Study on the Air Passengers Dataset", "categories": ["cs.LG", "cs.AI", "stat.ME"], "comment": null, "summary": "Time-series forecasting underpins critical decisions across aviation, energy,\nretail and health. Classical autoregressive integrated moving average (ARIMA)\nmodels offer interpretability via coefficients but struggle with\nnonlinearities, whereas tree-based machine-learning models such as XGBoost\ndeliver high accuracy but are often opaque. This paper presents a unified\nframework for interpreting time-series forecasts using local interpretable\nmodel-agnostic explanations (LIME) and SHapley additive exPlanations (SHAP). We\nconvert a univariate series into a leakage-free supervised learning problem,\ntrain a gradient-boosted tree alongside an ARIMA baseline and apply post-hoc\nexplainability. Using the Air Passengers dataset as a case study, we show that\na small set of lagged features -- particularly the twelve-month lag -- and\nseasonal encodings explain most forecast variance. We contribute: (i) a\nmethodology for applying LIME and SHAP to time series without violating\nchronology; (ii) theoretical exposition of the underlying algorithms; (iii)\nempirical evaluation with extensive analysis; and (iv) guidelines for\npractitioners."}
{"id": "2508.11987", "pdf": "https://arxiv.org/pdf/2508.11987", "abs": "https://arxiv.org/abs/2508.11987", "authors": ["Zhiyuan Zeng", "Jiashuo Liu", "Siyuan Chen", "Tianci He", "Yali Liao", "Jinpeng Wang", "Zaiyuan Wang", "Yang Yang", "Lingyue Yin", "Mingren Yin", "Zhenwei Zhu", "Tianle Cai", "Zehui Chen", "Jiecao Chen", "Yantao Du", "Xiang Gao", "Jiacheng Guo", "Liang Hu", "Jianpeng Jiao", "Xiangsheng Li", "Jingkai Liu", "Shuang Ni", "Zhoufutu Wen", "Ge Zhang", "Kaiyuan Zhang", "Xin Zhou", "Jose Blanchet", "Xipeng Qiu", "Mengdi Wang", "Wenhao Huang"], "title": "FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction", "categories": ["cs.AI", "cs.LG"], "comment": "Technical report, 51 pages", "summary": "Future prediction is a complex task for LLM agents, requiring a high level of\nanalytical thinking, information gathering, contextual understanding, and\ndecision-making under uncertainty. Agents must not only gather and interpret\nvast amounts of dynamic information but also integrate diverse data sources,\nweigh uncertainties, and adapt predictions based on emerging trends, just as\nhuman experts do in fields like politics, economics, and finance. Despite its\nimportance, no large-scale benchmark exists for evaluating agents on future\nprediction, largely due to challenges in handling real-time updates and\nretrieving timely, accurate answers. To address this, we introduce\n$\\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically\ndesigned for LLM agents performing future prediction tasks. FutureX is the\nlargest and most diverse live benchmark for future prediction, supporting\nreal-time daily updates and eliminating data contamination through an automated\npipeline for question gathering and answer collection. We evaluate 25 LLM/agent\nmodels, including those with reasoning, search capabilities, and integration of\nexternal tools such as the open-source Deep Research Agent and closed-source\nDeep Research models. This comprehensive evaluation assesses agents' adaptive\nreasoning and performance in dynamic environments. Additionally, we provide\nin-depth analyses of agents' failure modes and performance pitfalls in\nfuture-oriented tasks, including the vulnerability to fake web pages and the\ntemporal validity. Our goal is to establish a dynamic, contamination-free\nevaluation standard that drives the development of LLM agents capable of\nperforming at the level of professional human analysts in complex reasoning and\npredictive thinking."}
{"id": "2508.12259", "pdf": "https://arxiv.org/pdf/2508.12259", "abs": "https://arxiv.org/abs/2508.12259", "authors": ["Ken Huang", "Yasir Mehmood", "Hammad Atta", "Jerry Huang", "Muhammad Zeeshan Baig", "Sree Bhargavi Balija"], "title": "Fortifying the Agentic Web: A Unified Zero-Trust Architecture Against Logic-layer Threats", "categories": ["cs.CR", "cs.AI", "cs.ET"], "comment": null, "summary": "This paper presents a Unified Security Architecture that fortifies the\nAgentic Web through a Zero-Trust IAM framework. This architecture is built on a\nfoundation of rich, verifiable agent identities using Decentralized Identifiers\n(DIDs) and Verifiable Credentials (VCs), with discovery managed by a\nprotocol-agnostic Agent Name Service (ANS). Security is operationalized through\na multi-layered Trust Fabric which introduces significant innovations,\nincluding Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing,\nand Dynamic Identity with Behavioral Attestation. By explicitly linking the\nLPCI threat to these enhanced architectural countermeasures within a formal\nsecurity model, we propose a comprehensive and forward-looking blueprint for a\nsecure, resilient, and trustworthy agentic ecosystem. Our formal analysis\ndemonstrates that the proposed architecture provides provable security\nguarantees against LPCI attacks with bounded probability of success."}
{"id": "2508.11999", "pdf": "https://arxiv.org/pdf/2508.11999", "abs": "https://arxiv.org/abs/2508.11999", "authors": ["Daoze Zhang", "Zhanheng Nie", "Jianyu Liu", "Chenghan Fu", "Wanxian Guan", "Yuan Gao", "Jun Song", "Pengjie Wang", "Jian Xu", "Bo Zheng"], "title": "MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding", "categories": ["cs.CV", "cs.AI", "cs.IR", "cs.LG"], "comment": "11 pages, 9 figures", "summary": "With the rapid advancement of e-commerce, exploring general representations\nrather than task-specific ones has attracted increasing research attention. For\nproduct understanding, although existing discriminative dual-flow architectures\ndrive progress in this field, they inherently struggle to model the many-to-one\nalignment between multiple images and texts of products. Therefore, we argue\nthat generative Multimodal Large Language Models (MLLMs) hold significant\npotential for improving product representation learning. Nevertheless,\nachieving this goal still remains non-trivial due to several key challenges:\nthe lack of multimodal and aspect-aware modeling modules in typical LLMs; the\ncommon presence of background noise in product images; and the absence of a\nstandard benchmark for evaluation. To address these issues, we propose the\nfirst generative MLLM-based model named MOON for product representation\nlearning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for\ntargeted modeling of multimodal and aspect-specific product content; (2)\neffectively detects core semantic regions in product images to mitigate the\ndistraction and interference caused by background noise; and (3) introduces the\nspecialized negative sampling strategy to increase the difficulty and diversity\nof negative samples. In addition, we release a large-scale multimodal benchmark\nMBE for various product understanding tasks. Experimentally, our model\ndemonstrates competitive zero-shot performance on both our benchmark and the\npublic dataset, showcasing strong generalization across various downstream\ntasks, including cross-modal retrieval, product classification, and attribute\nprediction. Furthermore, the case study and visualization illustrate the\neffectiveness of MOON for product understanding."}
{"id": "2508.12263", "pdf": "https://arxiv.org/pdf/2508.12263", "abs": "https://arxiv.org/abs/2508.12263", "authors": ["Hongliang Wei", "Xianqi Zhang", "Xingtao Wang", "Xiaopeng Fan", "Debin Zhao"], "title": "Region-Level Context-Aware Multimodal Understanding", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "Despite significant progress, existing research on Multimodal Large Language\nModels (MLLMs) mainly focuses on general visual understanding, overlooking the\nability to integrate textual context associated with objects for a more\ncontext-aware multimodal understanding -- an ability we refer to as\nRegion-level Context-aware Multimodal Understanding (RCMU). To address this\nlimitation, we first formulate the RCMU task, which requires models to respond\nto user instructions by integrating both image content and textual information\nof regions or objects. To equip MLLMs with RCMU capabilities, we propose\nRegion-level Context-aware Visual Instruction Tuning (RCVIT), which\nincorporates object information into the model input and enables the model to\nutilize bounding box coordinates to effectively associate objects' visual\ncontent with their textual information. To address the lack of datasets, we\nintroduce the RCMU dataset, a large-scale visual instruction tuning dataset\nthat covers multiple RCMU tasks. We also propose RC\\&P-Bench, a comprehensive\nbenchmark that can evaluate the performance of MLLMs in RCMU and multimodal\npersonalized understanding tasks. Additionally, we propose a reference-free\nevaluation metric to perform a comprehensive and fine-grained evaluation of the\nregion-level context-aware image descriptions. By performing RCVIT on Qwen2-VL\nmodels with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental\nresults indicate that RC-Qwen2-VL models not only achieve outstanding\nperformance on multiple RCMU tasks but also demonstrate successful applications\nin multimodal RAG and personalized conversation. Our data, model and benchmark\nare available at https://github.com/hongliang-wei/RC-MLLM"}
{"id": "2508.12009", "pdf": "https://arxiv.org/pdf/2508.12009", "abs": "https://arxiv.org/abs/2508.12009", "authors": ["Arnav Ramamoorthy"], "title": "Optimizing Neural Architectures for Hindi Speech Separation and Enhancement in Noisy Environments", "categories": ["cs.SD", "cs.LG"], "comment": "ICAD 2025", "summary": "This paper addresses the challenges of Hindi speech separation and\nenhancement using advanced neural network architectures, with a focus on edge\ndevices. We propose a refined approach leveraging the DEMUCS model to overcome\nlimitations of traditional methods, achieving substantial improvements in\nspeech clarity and intelligibility. The model is fine-tuned with U-Net and LSTM\nlayers, trained on a dataset of 400,000 Hindi speech clips augmented with\nESC-50 and MS-SNSD for diverse acoustic environments. Evaluation using PESQ and\nSTOI metrics shows superior performance, particularly under extreme noise\nconditions. To ensure deployment on resource-constrained devices like TWS\nearbuds, we explore quantization techniques to reduce computational\nrequirements. This research highlights the effectiveness of customized AI\nalgorithms for speech processing in Indian contexts and suggests future\ndirections for optimizing edge-based architectures."}
{"id": "2508.12277", "pdf": "https://arxiv.org/pdf/2508.12277", "abs": "https://arxiv.org/abs/2508.12277", "authors": ["Elon Ezra", "Ariel Weizman", "Amos Azaria"], "title": "The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 9 figures", "summary": "Large language models (LLMs) are commonly evaluated on tasks that test their\nknowledge or reasoning abilities. In this paper, we explore a different type of\nevaluation: whether an LLM can predict aspects of its own responses. Since LLMs\nlack the ability to execute themselves, we introduce the Self-Execution\nBenchmark, which measures a model's ability to anticipate properties of its\noutput, such as whether a question will be difficult for it, whether it will\nrefuse to answer, or what kinds of associations it is likely to produce. Our\nexperiments show that models generally perform poorly on this benchmark, and\nthat increased model size or capability does not consistently lead to better\nperformance. These results suggest a fundamental limitation in how LLMs\nrepresent and reason about their own behavior."}
{"id": "2508.12026", "pdf": "https://arxiv.org/pdf/2508.12026", "abs": "https://arxiv.org/abs/2508.12026", "authors": ["Szymon Pawlonka", "Mikołaj Małkiński", "Jacek Mańdziuk"], "title": "Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Bongard Problems (BPs) provide a challenging testbed for abstract visual\nreasoning (AVR), requiring models to identify visual concepts fromjust a few\nexamples and describe them in natural language. Early BP benchmarks featured\nsynthetic black-and-white drawings, which might not fully capture the\ncomplexity of real-world scenes. Subsequent BP datasets employed real-world\nimages, albeit the represented concepts are identifiable from high-level image\nfeatures, reducing the task complexity. Differently, the recently released\nBongard-RWR dataset aimed at representing abstract concepts formulated in the\noriginal BPs using fine-grained real-world images. Its manual construction,\nhowever, limited the dataset size to just $60$ instances, constraining\nevaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset\ncomposed of $5\\,400$ instances that represent original BP abstract concepts\nusing real-world-like images generated via a vision language model (VLM)\npipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually\ncurated images and generate new descriptions aligned with the underlying\nconcepts, use Flux.1-dev to synthesize images from these descriptions, and\nmanually verify that the generated images faithfully reflect the intended\nconcepts. We evaluate state-of-the-art VLMs across diverse BP formulations,\nincluding binary and multiclass classification, as well as textual answer\ngeneration. Our findings reveal that while VLMs can recognize coarse-grained\nvisual concepts, they consistently struggle with discerning fine-grained\nconcepts, highlighting limitations in their reasoning capabilities."}
{"id": "2508.12278", "pdf": "https://arxiv.org/pdf/2508.12278", "abs": "https://arxiv.org/abs/2508.12278", "authors": ["Siyue Xie", "Da Sun Handason Tam", "Wing Cheong Lau"], "title": "CRoC: Context Refactoring Contrast for Graph Anomaly Detection with Limited Supervision", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ECAI 2025", "summary": "Graph Neural Networks (GNNs) are widely used as the engine for various\ngraph-related tasks, with their effectiveness in analyzing graph-structured\ndata. However, training robust GNNs often demands abundant labeled data, which\nis a critical bottleneck in real-world applications. This limitation severely\nimpedes progress in Graph Anomaly Detection (GAD), where anomalies are\ninherently rare, costly to label, and may actively camouflage their patterns to\nevade detection. To address these problems, we propose Context Refactoring\nContrast (CRoC), a simple yet effective framework that trains GNNs for GAD by\njointly leveraging limited labeled and abundant unlabeled data. Different from\nprevious works, CRoC exploits the class imbalance inherent in GAD to refactor\nthe context of each node, which builds augmented graphs by recomposing the\nattributes of nodes while preserving their interaction patterns. Furthermore,\nCRoC encodes heterogeneous relations separately and integrates them into the\nmessage-passing process, enhancing the model's capacity to capture complex\ninteraction semantics. These operations preserve node semantics while\nencouraging robustness to adversarial camouflage, enabling GNNs to uncover\nintricate anomalous cases. In the training stage, CRoC is further integrated\nwith the contrastive learning paradigm. This allows GNNs to effectively harness\nunlabeled data during joint training, producing richer, more discriminative\nnode embeddings. CRoC is evaluated on seven real-world GAD datasets with\nvarying scales. Extensive experiments demonstrate that CRoC achieves up to 14%\nAUC improvement over baseline GNNs and outperforms state-of-the-art GAD methods\nunder limited-label settings."}
{"id": "2508.12027", "pdf": "https://arxiv.org/pdf/2508.12027", "abs": "https://arxiv.org/abs/2508.12027", "authors": ["Filippo Torresan", "Keisuke Suzuki", "Ryota Kanai", "Manuel Baltieri"], "title": "Active inference for action-unaware agents", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "comment": "59 pages, 47 figures", "summary": "Active inference is a formal approach to study cognition based on the notion\nthat adaptive agents can be seen as engaging in a process of approximate\nBayesian inference, via the minimisation of variational and expected free\nenergies. Minimising the former provides an account of perceptual processes and\nlearning as evidence accumulation, while minimising the latter describes how\nagents select their actions over time. In this way, adaptive agents are able to\nmaximise the likelihood of preferred observations or states, given a generative\nmodel of the environment. In the literature, however, different strategies have\nbeen proposed to describe how agents can plan their future actions. While they\nall share the notion that some kind of expected free energy offers an\nappropriate way to score policies, sequences of actions, in terms of their\ndesirability, there are different ways to consider the contribution of past\nmotor experience to the agent's future behaviour. In some approaches, agents\nare assumed to know their own actions, and use such knowledge to better plan\nfor the future. In other approaches, agents are unaware of their actions, and\nmust infer their motor behaviour from recent observations in order to plan for\nthe future. This difference reflects a standard point of departure in two\nleading frameworks in motor control based on the presence, or not, of an\nefference copy signal representing knowledge about an agent's own actions. In\nthis work we compare the performances of action-aware and action-unaware agents\nin two navigations tasks, showing how action-unaware agents can achieve\nperformances comparable to action-aware ones while at a severe disadvantage."}
{"id": "2508.12279", "pdf": "https://arxiv.org/pdf/2508.12279", "abs": "https://arxiv.org/abs/2508.12279", "authors": ["Jun Liu", "Zhenglun Kong", "Pu Zhao", "Weihao Zeng", "Hao Tang", "Xuan Shen", "Changdi Yang", "Wenbin Zhang", "Geng Yuan", "Wei Niu", "Xue Lin", "Yanzhi Wang"], "title": "TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform", "categories": ["cs.CV", "cs.AI", "cs.AR", "cs.LG"], "comment": null, "summary": "Autonomous driving platforms encounter diverse driving scenarios, each with\nvarying hardware resources and precision requirements. Given the computational\nlimitations of embedded devices, it is crucial to consider computing costs when\ndeploying on target platforms like the NVIDIA\\textsuperscript{\\textregistered}\nDRIVE PX 2. Our objective is to customize the semantic segmentation network\naccording to the computing power and specific scenarios of autonomous driving\nhardware. We implement dynamic adaptability through a three-tier control\nmechanism -- width multiplier, classifier depth, and classifier kernel --\nallowing fine-grained control over model components based on hardware\nconstraints and task requirements. This adaptability facilitates broad model\nscaling, targeted refinement of the final layers, and scenario-specific\noptimization of kernel sizes, leading to improved resource allocation and\nperformance.\n  Additionally, we leverage Bayesian Optimization with surrogate modeling to\nefficiently explore hyperparameter spaces under tight computational budgets.\nOur approach addresses scenario-specific and task-specific requirements through\nautomatic parameter search, accommodating the unique computational complexity\nand accuracy needs of autonomous driving. It scales its Multiply-Accumulate\nOperations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in\nalternative configurations tailored to diverse self-driving tasks. These TSLA\ncustomizations maximize computational capacity and model accuracy, optimizing\nhardware utilization."}
{"id": "2508.12029", "pdf": "https://arxiv.org/pdf/2508.12029", "abs": "https://arxiv.org/abs/2508.12029", "authors": ["Zhangyu You", "Jiahao Ma", "Hongzong Li", "Ye-Fan Hu", "Jian-Dong Huang"], "title": "BConformeR: A Conformer Based on Mutual Sampling for Unified Prediction of Continuous and Discontinuous Antibody Binding Sites", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.LG"], "comment": "16 pages, 7 figures, 5 tables, submitted to AAAI conference 2026", "summary": "Accurate prediction of antibody-binding sites (epitopes) on antigens is\ncrucial for vaccine design, immunodiagnostics, therapeutic antibody\ndevelopment, antibody engineering, research into autoimmune and allergic\ndiseases, and for advancing our understanding of immune responses. Despite in\nsilico methods that have been proposed to predict both linear (continuous) and\nconformational (discontinuous) epitopes, they consistently underperform in\npredicting conformational epitopes. In this work, we propose a conformer-based\nmodel trained on antigen sequences derived from 1,080 antigen-antibody\ncomplexes, leveraging convolutional neural networks (CNNs) to extract local\nfeatures and Transformers to capture long-range dependencies within antigen\nsequences. Ablation studies demonstrate that CNN enhances the prediction of\nlinear epitopes, and the Transformer module improves the prediction of\nconformational epitopes. Experimental results show that our model outperforms\nexisting baselines in terms of PCC, ROC-AUC, PR-AUC, and F1 scores on\nconformational epitopes."}
{"id": "2508.12285", "pdf": "https://arxiv.org/pdf/2508.12285", "abs": "https://arxiv.org/abs/2508.12285", "authors": ["Yunbo Lyu", "Zhou Yang", "Jieke Shi", "Jianming Chang", "Yue Liu", "David Lo"], "title": "\"My productivity is boosted, but ...\" Demystifying Users' Perception on AI Coding Assistants", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": "13 pages, Camera-Ready Version that will appear in ASE 2025", "summary": "This paper aims to explore fundamental questions in the era when AI coding\nassistants like GitHub Copilot are widely adopted: what do developers truly\nvalue and criticize in AI coding assistants, and what does this reveal about\ntheir needs and expectations in real-world software development? Unlike\nprevious studies that conduct observational research in controlled and\nsimulated environments, we analyze extensive, first-hand user reviews of AI\ncoding assistants, which capture developers' authentic perspectives and\nexperiences drawn directly from their actual day-to-day work contexts. We\nidentify 1,085 AI coding assistants from the Visual Studio Code Marketplace.\nAlthough they only account for 1.64% of all extensions, we observe a surge in\nthese assistants: over 90% of them are released within the past two years. We\nthen manually analyze the user reviews sampled from 32 AI coding assistants\nthat have sufficient installations and reviews to construct a comprehensive\ntaxonomy of user concerns and feedback about these assistants. We manually\nannotate each review's attitude when mentioning certain aspects of coding\nassistants, yielding nuanced insights into user satisfaction and\ndissatisfaction regarding specific features, concerns, and overall tool\nperformance. Built on top of the findings-including how users demand not just\nintelligent suggestions but also context-aware, customizable, and\nresource-efficient interactions-we propose five practical implications and\nsuggestions to guide the enhancement of AI coding assistants that satisfy user\nneeds."}
{"id": "2508.12048", "pdf": "https://arxiv.org/pdf/2508.12048", "abs": "https://arxiv.org/abs/2508.12048", "authors": ["Jing Wang", "HaiYing Wang", "Kun Chen"], "title": "Robust Data Fusion via Subsampling", "categories": ["stat.ML", "cs.LG", "62K05"], "comment": null, "summary": "Data fusion and transfer learning are rapidly growing fields that enhance\nmodel performance for a target population by leveraging other related data\nsources or tasks. The challenges lie in the various potential heterogeneities\nbetween the target and external data, as well as various practical concerns\nthat prevent a na\\\"ive data integration. We consider a realistic scenario where\nthe target data is limited in size while the external data is large but\ncontaminated with outliers; such data contamination, along with other\ncomputational and operational constraints, necessitates proper selection or\nsubsampling of the external data for transfer learning. To our\nknowledge,transfer learning and subsampling under data contamination have not\nbeen thoroughly investigated. We address this gap by studying various transfer\nlearning methods with subsamples of the external data, accounting for outliers\ndeviating from the underlying true model due to arbitrary mean shifts. Two\nsubsampling strategies are investigated: one aimed at reducing biases and the\nother at minimizing variances. Approaches to combine these strategies are also\nintroduced to enhance the performance of the estimators. We provide\nnon-asymptotic error bounds for the transfer learning estimators, clarifying\nthe roles of sample sizes, signal strength, sampling rates, magnitude of\noutliers, and tail behaviors of model error distributions, among other factors.\nExtensive simulations show the superior performance of the proposed methods.\nAdditionally, we apply our methods to analyze the risk of hard landings in A380\nairplanes by utilizing data from other airplane types,demonstrating that robust\ntransfer learning can improve estimation efficiency for relatively rare\nairplane types with the help of data from other types of airplanes."}
{"id": "2508.12292", "pdf": "https://arxiv.org/pdf/2508.12292", "abs": "https://arxiv.org/abs/2508.12292", "authors": ["Hyebin Ahn", "Kangwook Jang", "Hoirin Kim"], "title": "HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted at Interspeech 2025", "summary": "Noise robustness in speech foundation models (SFMs) has been a critical\nchallenge, as most models are primarily trained on clean data and experience\nperformance degradation when the models are exposed to noisy speech. To address\nthis issue, we propose HuBERT-VIC, a noise-robust SFM with variance,\nin-variance, and covariance regularization (VICReg) objectives. These\nobjectives adjust the statistics of noisy speech representations, enabling the\nmodel to capture diverse acoustic characteristics and improving the\ngeneralization ability across different types of noise. When applied to HuBERT,\nour model shows relative performance improvements of 23.3% on LibriSpeech\ntest-clean and 13.2% on test-other, compared to the baseline model pre-trained\non noisy speech."}
{"id": "2508.12082", "pdf": "https://arxiv.org/pdf/2508.12082", "abs": "https://arxiv.org/abs/2508.12082", "authors": ["Seungju Yoo", "Hyuk Kwon", "Joong-Won Hwang", "Kibok Lee"], "title": "Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "ICCV 2025 Oral", "summary": "Recent advances in computer vision have made training object detectors more\nefficient and effective; however, assessing their performance in real-world\napplications still relies on costly manual annotation. To address this\nlimitation, we develop an automated model evaluation (AutoEval) framework for\nobject detection. We propose Prediction Consistency and Reliability (PCR),\nwhich leverages the multiple candidate bounding boxes that conventional\ndetectors generate before non-maximum suppression (NMS). PCR estimates\ndetection performance without ground-truth labels by jointly measuring 1) the\nspatial consistency between boxes before and after NMS, and 2) the reliability\nof the retained boxes via the confidence scores of overlapping boxes. For a\nmore realistic and scalable evaluation, we construct a meta-dataset by applying\nimage corruptions of varying severity. Experimental results demonstrate that\nPCR yields more accurate performance estimates than existing AutoEval methods,\nand the proposed meta-dataset covers a wider range of detection performance.\nThe code is available at https://github.com/YonseiML/autoeval-det."}
{"id": "2508.12300", "pdf": "https://arxiv.org/pdf/2508.12300", "abs": "https://arxiv.org/abs/2508.12300", "authors": ["Gilad Abiri"], "title": "Mutually Assured Deregulation", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "We have convinced ourselves that the way to make AI safe is to make it\nunsafe. Since 2022, policymakers worldwide have embraced the Regulation\nSacrifice - the belief that dismantling safety oversight will deliver security\nthrough AI dominance. Fearing China or USA will gain advantage, nations rush to\neliminate safeguards that might slow progress. This Essay reveals the fatal\nflaw: though AI poses national security challenges, the solution demands\nstronger regulatory frameworks, not weaker ones. A race without guardrails\nbreeds shared danger, not competitive strength. The Regulation Sacrifice makes\nthree false promises. First, it promises durable technological leads. But AI\ncapabilities spread rapidly - performance gaps between U.S. and Chinese systems\ncollapsed from 9 percent to 2 percent in thirteen months. When advantages\nevaporate in months, sacrificing permanent safety for temporary speed makes no\nsense. Second, it promises deregulation accelerates innovation. The opposite\noften proves true. Companies report well-designed governance streamlines\ndevelopment. Investment flows toward regulated markets. Clear rules reduce\nuncertainty; uncertain liability creates paralysis. Environmental standards did\nnot kill the auto industry; they created Tesla and BYD. Third, enhanced\nnational security through deregulation actually undermines security across all\ntimeframes. Near term: it hands adversaries information warfare tools. Medium\nterm: it democratizes bioweapon capabilities. Long term: it guarantees\ndeployment of uncontrollable AGI systems. The Regulation Sacrifice persists\nbecause it serves powerful interests, not security. Tech companies prefer\nfreedom to accountability. Politicians prefer simple stories to complex truths.\nThis creates mutually assured deregulation, where each nation's sprint for\nadvantage guarantees collective vulnerability. The only way to win is not to\nplay."}
{"id": "2508.12086", "pdf": "https://arxiv.org/pdf/2508.12086", "abs": "https://arxiv.org/abs/2508.12086", "authors": ["Yao Wu"], "title": "J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 90C29, 62F07", "I.2.7; I.2.6; G.1.6"], "comment": "9 pages, 3 tables, 1 algorithm", "summary": "In large language model (LLM) adaptation, balancing multiple optimization\nobjectives such as improving factuality (heat) and increasing confidence (via\nlow entropy) poses a fundamental challenge, especially when prompt parameters\n(e.g., hidden-layer insertions h and embedding modifications w) interact in\nnon-trivial ways. Existing multi-objective optimization strategies often rely\non scalar gradient aggregation, ignoring the deeper geometric structure between\nobjectives and parameters. We propose J6, a structured Jacobian-based method\nthat decomposes the gradient interaction matrix into six interpretable\ncomponents. This decomposition enables both hard decision-making (e.g.,\nchoosing the dominant update direction via argmax) and soft strategies (e.g.,\nattention-style weighting via softmax over J6), forming a dynamic update\nframework that adapts to local conflict and synergy. Moreover, the\ninterpretable structure of J6 provides insight into parameter attribution, task\ninterference, and geometry-aligned adaptation. Our work introduces a principled\nand extensible mechanism for conflict-aware prompt optimization, and opens a\nnew avenue for incorporating structured Jacobian reasoning into multi-objective\nneural tuning."}
{"id": "2508.12314", "pdf": "https://arxiv.org/pdf/2508.12314", "abs": "https://arxiv.org/abs/2508.12314", "authors": ["Chiranjit Mitra"], "title": "Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems", "categories": ["cs.MA", "cs.AI", "nlin.AO"], "comment": "9 pages, 6 figures", "summary": "We present a novel interdisciplinary framework that bridges synchronization\ntheory and multi-agent AI systems by adapting the Kuramoto model to describe\nthe collective dynamics of heterogeneous AI agents engaged in complex task\nexecution. By representing AI agents as coupled oscillators with both phase and\namplitude dynamics, our model captures essential aspects of agent\nspecialization, influence, and communication within networked systems. We\nintroduce an order parameter to quantify the degree of coordination and\nsynchronization, providing insights into how coupling strength, agent\ndiversity, and network topology impact emergent collective behavior.\nFurthermore, we formalize a detailed correspondence between Chain-of-Thought\nprompting in AI reasoning and synchronization phenomena, unifying human-like\niterative problem solving with emergent group intelligence. Through extensive\nsimulations on all-to-all and deterministic scale-free networks, we demonstrate\nthat increased coupling promotes robust synchronization despite heterogeneous\nagent capabilities, reflecting realistic collaborative AI scenarios. Our\nphysics-informed approach establishes a rigorous mathematical foundation for\ndesigning, analyzing, and optimizing scalable, adaptive, and interpretable\nmulti-agent AI systems. This work opens pathways for principled orchestration\nof agentic AI and lays the groundwork for future incorporation of learning\ndynamics and adaptive network architectures to further enhance system\nresilience and efficiency."}
{"id": "2508.12096", "pdf": "https://arxiv.org/pdf/2508.12096", "abs": "https://arxiv.org/abs/2508.12096", "authors": ["Haiquan Hu", "Jiazhi Jiang", "Shiyou Xu", "Ruhan Zeng", "Tian Wang"], "title": "STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submit to AAAI 2026", "summary": "Evaluating large language models (LLMs) has become increasingly challenging\nas model capabilities advance rapidly. While recent models often achieve higher\nscores on standard benchmarks, these improvements do not consistently reflect\nenhanced real-world reasoning capabilities. Moreover, widespread overfitting to\npublic benchmarks and the high computational cost of full evaluations have made\nit both expensive and less effective to distinguish meaningful differences\nbetween models. To address these challenges, we propose the \\textbf{S}tructured\n\\textbf{T}ransition \\textbf{E}valuation \\textbf{M}ethod (STEM), a lightweight\nand interpretable evaluation framework for efficiently estimating the relative\ncapabilities of LLMs. STEM identifies \\textit{significant transition samples}\n(STS) by analyzing consistent performance transitions among LLMs of the same\narchitecture but varying parameter scales. These samples enable STEM to\neffectively estimate the capability position of an unknown model. Qwen3 model\nfamily is applied to construct the STS pool on six diverse and representative\nbenchmarks. To assess generalizability. Experimental results indicate that STEM\nreliably captures performance trends, aligns with ground-truth rankings of\nmodel capability. These findings highlight STEM as a practical and scalable\nmethod for fine-grained, architecture-agnostic evaluation of LLMs."}
{"id": "2508.12341", "pdf": "https://arxiv.org/pdf/2508.12341", "abs": "https://arxiv.org/abs/2508.12341", "authors": ["Ziye Wang", "Minghang Yu", "Chunyan Xu", "Zhen Cui"], "title": "Semantic Discrepancy-aware Detector for Image Forgery Identification", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 figures", "summary": "With the rapid advancement of image generation techniques, robust forgery\ndetection has become increasingly imperative to ensure the trustworthiness of\ndigital media. Recent research indicates that the learned semantic concepts of\npre-trained models are critical for identifying fake images. However, the\nmisalignment between the forgery and semantic concept spaces hinders the\nmodel's forgery detection performance. To address this problem, we propose a\nnovel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction\nlearning to align the two spaces at a fine-grained visual level. By exploiting\nthe conceptual knowledge embedded in the pre-trained vision language model, we\nspecifically design a semantic token sampling module to mitigate the space\nshifts caused by features irrelevant to both forgery traces and semantic\nconcepts. A concept-level forgery discrepancy learning module, built upon a\nvisual reconstruction paradigm, is proposed to strengthen the interaction\nbetween visual semantic concepts and forgery traces, effectively capturing\ndiscrepancies under the concepts' guidance. Finally, the low-level forgery\nfeature enhancemer integrates the learned concept level forgery discrepancies\nto minimize redundant forgery information. Experiments conducted on two\nstandard image forgery datasets demonstrate the efficacy of the proposed SDD,\nwhich achieves superior results compared to existing methods. The code is\navailable at https://github.com/wzy1111111/SSD."}
{"id": "2508.12163", "pdf": "https://arxiv.org/pdf/2508.12163", "abs": "https://arxiv.org/abs/2508.12163", "authors": ["Wenqing Wang", "Yun Fu"], "title": "RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "I.4; I.3; I.2"], "comment": "Accepted to the ICCV 2025 Workshop on Artificial Social Intelligence", "summary": "Emotion is a critical component of artificial social intelligence. However,\nwhile current methods excel in lip synchronization and image quality, they\noften fail to generate accurate and controllable emotional expressions while\npreserving the subject's identity. To address this challenge, we introduce\nRealTalk, a novel framework for synthesizing emotional talking heads with high\nemotion accuracy, enhanced emotion controllability, and robust identity\npreservation. RealTalk employs a variational autoencoder (VAE) to generate 3D\nfacial landmarks from driving audio, which are concatenated with emotion-label\nembeddings using a ResNet-based landmark deformation model (LDM) to produce\nemotional landmarks. These landmarks and facial blendshape coefficients jointly\ncondition a novel tri-plane attention Neural Radiance Field (NeRF) to\nsynthesize highly realistic emotional talking heads. Extensive experiments\ndemonstrate that RealTalk outperforms existing methods in emotion accuracy,\ncontrollability, and identity preservation, advancing the development of\nsocially intelligent AI systems."}
{"id": "2508.12353", "pdf": "https://arxiv.org/pdf/2508.12353", "abs": "https://arxiv.org/abs/2508.12353", "authors": ["Marcel Gregoriadis", "Jingwei Kang", "Johan Pouwelse"], "title": "A Large-Scale Web Search Dataset for Federated Online Learning to Rank", "categories": ["cs.IR", "cs.AI", "cs.DC"], "comment": "Accepted at CIKM 2025", "summary": "The centralized collection of search interaction logs for training ranking\nmodels raises significant privacy concerns. Federated Online Learning to Rank\n(FOLTR) offers a privacy-preserving alternative by enabling collaborative model\ntraining without sharing raw user data. However, benchmarks in FOLTR are\nlargely based on random partitioning of classical learning-to-rank datasets,\nsimulated user clicks, and the assumption of synchronous client participation.\nThis oversimplifies real-world dynamics and undermines the realism of\nexperimental results. We present AOL4FOLTR, a large-scale web search dataset\nwith 2.6 million queries from 10,000 users. Our dataset addresses key\nlimitations of existing benchmarks by including user identifiers, real click\ndata, and query timestamps, enabling realistic user partitioning, behavior\nmodeling, and asynchronous federated learning scenarios."}
{"id": "2508.12166", "pdf": "https://arxiv.org/pdf/2508.12166", "abs": "https://arxiv.org/abs/2508.12166", "authors": ["Gokul Puthumanaillam", "Aditya Penumarti", "Manav Vora", "Paulo Padrao", "Jose Fuentes", "Leonardo Bobadilla", "Jane Shin", "Melkior Ornik"], "title": "Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to CoRL 2025 (Conference on Robot Learning)", "summary": "Robots equipped with rich sensor suites can localize reliably in\npartially-observable environments, but powering every sensor continuously is\nwasteful and often infeasible. Belief-space planners address this by\npropagating pose-belief covariance through analytic models and switching\nsensors heuristically--a brittle, runtime-expensive approach. Data-driven\napproaches--including diffusion models--learn multi-modal trajectories from\ndemonstrations, but presuppose an accurate, always-on state estimate. We\naddress the largely open problem: for a given task in a mapped environment,\nwhich \\textit{minimal sensor subset} must be active at each location to\nmaintain state uncertainty \\textit{just low enough} to complete the task? Our\nkey insight is that when a diffusion planner is explicitly conditioned on a\npose-belief raster and a sensor mask, the spread of its denoising trajectories\nyields a calibrated, differentiable proxy for the expected localisation error.\nBuilding on this insight, we present Belief-Conditioned One-Step Diffusion\n(B-COD), the first planner that, in a 10 ms forward pass, returns a\nshort-horizon trajectory, per-waypoint aleatoric variances, and a proxy for\nlocalisation error--eliminating external covariance rollouts. We show that this\nsingle proxy suffices for a soft-actor-critic to choose sensors online,\noptimising energy while bounding pose-covariance growth. We deploy B-COD in\nreal-time marine trials on an unmanned surface vehicle and show that it reduces\nsensing energy consumption while matching the goal-reach performance of an\nalways-on baseline."}
{"id": "2508.12356", "pdf": "https://arxiv.org/pdf/2508.12356", "abs": "https://arxiv.org/abs/2508.12356", "authors": ["Ahmet H. Güzel", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) offers a promising framework for training\nagents using pre-collected datasets without the need for further environment\ninteraction. However, policies trained on offline data often struggle to\ngeneralise due to limited exposure to diverse states. The complexity of visual\ndata introduces additional challenges such as noise, distractions, and spurious\ncorrelations, which can misguide the policy and increase the risk of\noverfitting if the training data is not sufficiently diverse. Indeed, this\nmakes it challenging to leverage vision-based offline data in training robust\nagents that can generalize to unseen environments. To solve this problem, we\npropose a simple approach generating additional synthetic training data. We\npropose a two-step process, first augmenting the originally collected offline\ndata to improve zero-shot generalization by introducing diversity, then using a\ndiffusion model to generate additional data in latent space. We test our method\nacross both continuous action spaces (Visual D4RL) and discrete action spaces\n(Procgen), demonstrating that it significantly improves generalization without\nrequiring any algorithmic changes to existing model-free offline RL methods. We\nshow that our method not only increases the diversity of the training data but\nalso significantly reduces the generalization gap at test time while\nmaintaining computational efficiency. We believe this approach could fuel\nadditional progress in generating synthetic data to train more general agents\nin the future."}
{"id": "2508.12198", "pdf": "https://arxiv.org/pdf/2508.12198", "abs": "https://arxiv.org/abs/2508.12198", "authors": ["ChangJae Lee", "Heecheol Yang", "Jonghak Choi"], "title": "Exploring Multimodal AI Reasoning for Meteorological Forecasting from Skew-T Diagrams", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "comment": "24 pages, 3 figures, 9 tables", "summary": "Forecasting from atmospheric soundings is a fundamental task in operational\nmeteorology, often requiring structured visual reasoning over Skew-T log-P\ndiagrams by human forecasters. While recent advances in Vision-Language Models\n(VLMs) have shown promise in other scientific domains, their application to\nmeteorological diagram interpretation remains largely unexplored. In this\nstudy, we present a lightweight AI assistant that interprets Skew-T diagrams\nusing a small language model (LM) and a small VLM fine-tuned to emulate human\nforecasters. Using a curriculum learning framework, we first train the models\nto identify key atmospheric features from diagrams through visual question\nanswering, followed by chain-of-thought reasoning tasks that estimate\nprecipitation probability based on the derived visual groundings. Model inputs\ninclude either textual summaries or generated Skew-T diagrams derived from\noperational Numerical Weather Prediction (NWP) forecasts, paired with\nthree-hour precipitation observations from South Korea's Auto Weather Stations\nnetwork. Evaluation results demonstrate that the fine-tuned VLM achieves skill\ncomparable to an operational NWP model, despite relying solely on static\natmospheric profiles. Ablation studies reveal that visual grounding and\nreasoning supervision are critical for performance, while attention map\nanalysis confirms that the model learns to focus on relevant meteorological\nfeatures. These findings highlight the potential of compact, interpretable\nmultimodal models to support weather forecasting tasks. The approach offers a\ncomputationally efficient alternative to large-scale systems, and future work\ncould extend it to more complex applications."}
{"id": "2508.12358", "pdf": "https://arxiv.org/pdf/2508.12358", "abs": "https://arxiv.org/abs/2508.12358", "authors": ["Haolin Jin", "Huaming Chen"], "title": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to the NIER track of the 40th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE 2025)", "summary": "Large language models (LLMs) have become essential tools in software\ndevelopment, widely used for requirements engineering, code generation and\nreview tasks. Software engineers often rely on LLMs to assess whether system\ncode implementation satisfy task requirements, thereby enhancing code\nrobustness and accuracy. However, it remains unclear whether LLMs can reliably\ndetermine whether the code complies fully with the given task descriptions,\nwhich is usually natural language specifications. In this paper, we uncover a\nsystematic failure of LLMs in evaluating whether code aligns with natural\nlanguage requirements. Specifically, with widely used benchmarks, we employ\nunified prompts to judge code correctness. Our results reveal that LLMs\nfrequently misclassify correct code implementations as either ``not satisfying\nrequirements'' or containing potential defects. Surprisingly, more complex\nprompting, especially when leveraging prompt engineering techniques involving\nexplanations and proposed corrections, leads to higher misjudgment rate, which\nhighlights the critical reliability issues in using LLMs as code review\nassistants. We further analyze the root causes of these misjudgments, and\npropose two improved prompting strategies for mitigation. For the first time,\nour findings reveals unrecognized limitations in LLMs to match code with\nrequirements. We also offer novel insights and practical guidance for effective\nuse of LLMs in automated code review and task-oriented agent scenarios."}
{"id": "2508.12204", "pdf": "https://arxiv.org/pdf/2508.12204", "abs": "https://arxiv.org/abs/2508.12204", "authors": ["Mauro Belgiovine", "Suyash Pradhan", "Johannes Lange", "Michael Löhning", "Kaushik Chowdhury"], "title": "ATLAS: AI-Native Receiver Test-and-Measurement by Leveraging AI-Guided Search", "categories": ["eess.SP", "cs.LG", "cs.NI"], "comment": "Accepted at IEEE PIMRC 2025", "summary": "Industry adoption of Artificial Intelligence (AI)-native wireless receivers,\nor even modular, Machine Learning (ML)-aided wireless signal processing blocks,\nhas been slow. The main concern is the lack of explainability of these trained\nML models and the significant risks posed to network functionalities in case of\nfailures, especially since (i) testing on every exhaustive case is infeasible\nand (ii) the data used for model training may not be available. This paper\nproposes ATLAS, an AI-guided approach that generates a battery of tests for\npre-trained AI-native receiver models and benchmarks the performance against a\nclassical receiver architecture. Using gradient-based optimization, it avoids\nspanning the exhaustive set of all environment and channel conditions; instead,\nit generates the next test in an online manner to further probe specific\nconfigurations that offer the highest risk of failure. We implement and\nvalidate our approach by adopting the well-known DeepRx AI-native receiver\nmodel as well as a classical receiver using differentiable tensors in NVIDIA's\nSionna environment. ATLAS uncovers specific combinations of mobility, channel\ndelay spread, and noise, where fully and partially trained variants of\nAI-native DeepRx perform suboptimally compared to the classical receivers. Our\nproposed method reduces the number of tests required per failure found by 19%\ncompared to grid search for a 3-parameters input optimization problem,\ndemonstrating greater efficiency. In contrast, the computational cost of the\ngrid-based approach scales exponentially with the number of variables, making\nit increasingly impractical for high-dimensional problems."}
{"id": "2508.12361", "pdf": "https://arxiv.org/pdf/2508.12361", "abs": "https://arxiv.org/abs/2508.12361", "authors": ["Xun Su", "Jianming Huang", "Yang Yusen", "Zhongxi Fang", "Hiroyuki Kasai"], "title": "Navigating the Exploration-Exploitation Tradeoff in Inference-Time Scaling of Diffusion Models", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.TH"], "comment": null, "summary": "Inference-time scaling has achieved remarkable success in language models,\nyet its adaptation to diffusion models remains underexplored. We observe that\nthe efficacy of recent Sequential Monte Carlo (SMC)-based methods largely stems\nfrom globally fitting the The reward-tilted distribution, which inherently\npreserves diversity during multi-modal search. However, current applications of\nSMC to diffusion models face a fundamental dilemma: early-stage noise samples\noffer high potential for improvement but are difficult to evaluate accurately,\nwhereas late-stage samples can be reliably assessed but are largely\nirreversible. To address this exploration-exploitation trade-off, we approach\nthe problem from the perspective of the search algorithm and propose two\nstrategies: Funnel Schedule and Adaptive Temperature. These simple yet\neffective methods are tailored to the unique generation dynamics and\nphase-transition behavior of diffusion models. By progressively reducing the\nnumber of maintained particles and down-weighting the influence of early-stage\nrewards, our methods significantly enhance sample quality without increasing\nthe total number of Noise Function Evaluations. Experimental results on\nmultiple benchmarks and state-of-the-art text-to-image diffusion models\ndemonstrate that our approach outperforms previous baselines."}
{"id": "2508.12213", "pdf": "https://arxiv.org/pdf/2508.12213", "abs": "https://arxiv.org/abs/2508.12213", "authors": ["Yize Cai", "Baoshen Guo", "Flora Salim", "Zhiqing Hong"], "title": "Towards Generalizable Human Activity Recognition: A Survey", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": null, "summary": "As a critical component of Wearable AI, IMU-based Human Activity Recognition\n(HAR) has attracted increasing attention from both academia and industry in\nrecent years. Although HAR performance has improved considerably in specific\nscenarios, its generalization capability remains a key barrier to widespread\nreal-world adoption. For example, domain shifts caused by variations in users,\nsensor positions, or environments can significantly decrease the performance in\npractice. As a result, in this survey, we explore the rapidly evolving field of\nIMU-based generalizable HAR, reviewing 229 research papers alongside 25\npublicly available datasets to provide a broad and insightful overview. We\nfirst present the background and overall framework of IMU-based HAR tasks, as\nwell as the generalization-oriented training settings. Then, we categorize\nrepresentative methodologies from two perspectives: (i) model-centric\napproaches, including pre-training method, end-to-end method, and large\nlanguage model (LLM)-based learning method; and (ii) data-centric approaches,\nincluding multi-modal learning and data augmentation techniques. In addition,\nwe summarize widely used datasets in this field, as well as relevant tools and\nbenchmarks. Building on these methodological advances, the broad applicability\nof IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent\nchallenges (e.g., data scarcity, efficient training, and reliable evaluation)\nand also outline future directions for HAR, including the adoption of\nfoundation and large language models, physics-informed and context-aware\nreasoning, generative modeling, and resource-efficient training and inference.\nThe complete list of this survey is available at\nhttps://github.com/rh20624/Awesome-IMU-Sensing, which will be updated\ncontinuously."}
{"id": "2508.12381", "pdf": "https://arxiv.org/pdf/2508.12381", "abs": "https://arxiv.org/abs/2508.12381", "authors": ["Guo Tang", "Songhan Jiang", "Jinpeng Lu", "Linghan Cai", "Yongbing Zhang"], "title": "IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages, 5 figures", "summary": "Pathological images play an essential role in cancer prognosis, while\nsurvival analysis, which integrates computational techniques, can predict\ncritical clinical events such as patient mortality or disease recurrence from\nwhole-slide images (WSIs). Recent advancements in multiple instance learning\nhave significantly improved the efficiency of survival analysis. However,\nexisting methods often struggle to balance the modeling of long-range spatial\nrelationships with local contextual dependencies and typically lack inherent\ninterpretability, limiting their clinical utility. To address these challenges,\nwe propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel\nframework that captures the characteristics of the tumor microenvironment and\nmodels their spatial dependencies across the tissue. IPGPhormer uniquely\nprovides interpretability at both tissue and cellular levels without requiring\npost-hoc manual annotations, enabling detailed analyses of individual WSIs and\ncross-cohort assessments. Comprehensive evaluations on four public benchmark\ndatasets demonstrate that IPGPhormer outperforms state-of-the-art methods in\nboth predictive accuracy and interpretability. In summary, our method,\nIPGPhormer, offers a promising tool for cancer prognosis assessment, paving the\nway for more reliable and interpretable decision-support systems in pathology.\nThe code is publicly available at\nhttps://anonymous.4open.science/r/IPGPhormer-6EEB."}
{"id": "2508.12279", "pdf": "https://arxiv.org/pdf/2508.12279", "abs": "https://arxiv.org/abs/2508.12279", "authors": ["Jun Liu", "Zhenglun Kong", "Pu Zhao", "Weihao Zeng", "Hao Tang", "Xuan Shen", "Changdi Yang", "Wenbin Zhang", "Geng Yuan", "Wei Niu", "Xue Lin", "Yanzhi Wang"], "title": "TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform", "categories": ["cs.CV", "cs.AI", "cs.AR", "cs.LG"], "comment": null, "summary": "Autonomous driving platforms encounter diverse driving scenarios, each with\nvarying hardware resources and precision requirements. Given the computational\nlimitations of embedded devices, it is crucial to consider computing costs when\ndeploying on target platforms like the NVIDIA\\textsuperscript{\\textregistered}\nDRIVE PX 2. Our objective is to customize the semantic segmentation network\naccording to the computing power and specific scenarios of autonomous driving\nhardware. We implement dynamic adaptability through a three-tier control\nmechanism -- width multiplier, classifier depth, and classifier kernel --\nallowing fine-grained control over model components based on hardware\nconstraints and task requirements. This adaptability facilitates broad model\nscaling, targeted refinement of the final layers, and scenario-specific\noptimization of kernel sizes, leading to improved resource allocation and\nperformance.\n  Additionally, we leverage Bayesian Optimization with surrogate modeling to\nefficiently explore hyperparameter spaces under tight computational budgets.\nOur approach addresses scenario-specific and task-specific requirements through\nautomatic parameter search, accommodating the unique computational complexity\nand accuracy needs of autonomous driving. It scales its Multiply-Accumulate\nOperations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in\nalternative configurations tailored to diverse self-driving tasks. These TSLA\ncustomizations maximize computational capacity and model accuracy, optimizing\nhardware utilization."}
{"id": "2508.12393", "pdf": "https://arxiv.org/pdf/2508.12393", "abs": "https://arxiv.org/abs/2508.12393", "authors": ["Duzhen Zhang", "Zixiao Wang", "Zhong-Zhi Li", "Yahan Yu", "Shuncheng Jia", "Jiahua Dong", "Haotian Xu", "Xing Wu", "Yingying Zhang", "Tielin Zhang", "Jie Yang", "Xiuying Chen", "Le Song"], "title": "MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid expansion of medical literature presents growing challenges for\nstructuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)\noffer a promising solution by enabling efficient retrieval, automated\nreasoning, and knowledge discovery. However, current KG construction methods\noften rely on supervised pipelines with limited generalizability or naively\naggregate outputs from Large Language Models (LLMs), treating biomedical\ncorpora as static and ignoring the temporal dynamics and contextual uncertainty\nof evolving knowledge. To address these limitations, we introduce MedKGent, a\nLLM agent framework for constructing temporally evolving medical KGs.\nLeveraging over 10 million PubMed abstracts published between 1975 and 2023, we\nsimulate the emergence of biomedical knowledge via a fine-grained daily time\nseries. MedKGent incrementally builds the KG in a day-by-day manner using two\nspecialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor\nAgent identifies knowledge triples and assigns confidence scores via\nsampling-based estimation, which are used to filter low-confidence extractions\nand inform downstream processing. The Constructor Agent incrementally\nintegrates the retained triples into a temporally evolving graph, guided by\nconfidence scores and timestamps to reinforce recurring knowledge and resolve\nconflicts. The resulting KG contains 156,275 entities and 2,971,384 relational\ntriples. Quality assessments by two SOTA LLMs and three domain experts\ndemonstrate an accuracy approaching 90\\%, with strong inter-rater agreement. To\nevaluate downstream utility, we conduct RAG across seven medical question\nanswering benchmarks using five leading LLMs, consistently observing\nsignificant improvements over non-augmented baselines. Case studies further\ndemonstrate the KG's value in literature-based drug repurposing via\nconfidence-aware causal inference."}
{"id": "2508.12301", "pdf": "https://arxiv.org/pdf/2508.12301", "abs": "https://arxiv.org/abs/2508.12301", "authors": ["Tomer Krichli", "Bhiksha Raj", "Joseph Keshet"], "title": "CarelessWhisper: Turning Whisper into a Causal Streaming Model", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": "17 pages, 7 Figures, This work has been submitted to the IEEE for\n  possible publication", "summary": "Automatic Speech Recognition (ASR) has seen remarkable progress, with models\nlike OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)\nperformance in offline transcription. However, these models are not designed\nfor streaming (online or real-time) transcription, due to limitations in their\narchitecture and training methodology. We propose a method to turn the\ntransformer encoder-decoder model into a low-latency streaming model that is\ncareless about future context. We present an analysis explaining why it is not\nstraightforward to convert an encoder-decoder transformer to a low-latency\nstreaming model. Our proposed method modifies the existing (non-causal) encoder\nto a causal encoder by fine-tuning both the encoder and decoder using Low-Rank\nAdaptation (LoRA) and a weakly aligned dataset. We then propose an updated\ninference mechanism that utilizes the fine-tune causal encoder and decoder to\nyield greedy and beam-search decoding, and is shown to be locally optimal.\nExperiments on low-latency chunk sizes (less than 300 msec) show that our\nfine-tuned model outperforms existing non-fine-tuned streaming approaches in\nmost cases, while using a lower complexity. Additionally, we observe that our\ntraining process yields better alignment, enabling a simple method for\nextracting word-level timestamps. We release our training and inference code,\nalong with the fine-tuned models, to support further research and development\nin streaming ASR."}
{"id": "2508.12398", "pdf": "https://arxiv.org/pdf/2508.12398", "abs": "https://arxiv.org/abs/2508.12398", "authors": ["Zhixin Xie", "Xurui Song", "Jun Luo"], "title": "Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have recently emerged as a\ncompetitive non-autoregressive paradigm due to their unique training and\ninference approach. However, there is currently a lack of safety study on this\nnovel architecture. In this paper, we present the first analysis of dLLMs'\nsafety performance and propose a novel safety alignment method tailored to\ntheir unique generation characteristics. Specifically, we identify a critical\nasymmetry between the defender and attacker in terms of security. For the\ndefender, we reveal that the middle tokens of the response, rather than the\ninitial ones, are more critical to the overall safety of dLLM outputs; this\nseems to suggest that aligning middle tokens can be more beneficial to the\ndefender. The attacker, on the contrary, may have limited power to manipulate\nmiddle tokens, as we find dLLMs have a strong tendency towards a sequential\ngeneration order in practice, forcing the attack to meet this distribution and\ndiverting it from influencing the critical middle tokens. Building on this\nasymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method\nthat directly aligns the model's middle generation with safe refusals\nexploiting reinforcement learning. We implement MOSA and compare its security\nperformance against eight attack methods on two benchmarks. We also test the\nutility of MOSA-aligned dLLM on coding, math, and general reasoning. The\nresults strongly prove the superiority of MOSA."}
{"id": "2508.12356", "pdf": "https://arxiv.org/pdf/2508.12356", "abs": "https://arxiv.org/abs/2508.12356", "authors": ["Ahmet H. Güzel", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) offers a promising framework for training\nagents using pre-collected datasets without the need for further environment\ninteraction. However, policies trained on offline data often struggle to\ngeneralise due to limited exposure to diverse states. The complexity of visual\ndata introduces additional challenges such as noise, distractions, and spurious\ncorrelations, which can misguide the policy and increase the risk of\noverfitting if the training data is not sufficiently diverse. Indeed, this\nmakes it challenging to leverage vision-based offline data in training robust\nagents that can generalize to unseen environments. To solve this problem, we\npropose a simple approach generating additional synthetic training data. We\npropose a two-step process, first augmenting the originally collected offline\ndata to improve zero-shot generalization by introducing diversity, then using a\ndiffusion model to generate additional data in latent space. We test our method\nacross both continuous action spaces (Visual D4RL) and discrete action spaces\n(Procgen), demonstrating that it significantly improves generalization without\nrequiring any algorithmic changes to existing model-free offline RL methods. We\nshow that our method not only increases the diversity of the training data but\nalso significantly reduces the generalization gap at test time while\nmaintaining computational efficiency. We believe this approach could fuel\nadditional progress in generating synthetic data to train more general agents\nin the future."}
{"id": "2508.12405", "pdf": "https://arxiv.org/pdf/2508.12405", "abs": "https://arxiv.org/abs/2508.12405", "authors": ["Zilong Bai", "Zihan Xu", "Cong Sun", "Chengxi Zang", "H. Timothy Bunnell", "Catherine Sinfield", "Jacqueline Rutter", "Aaron Thomas Martinez", "L. Charles Bailey", "Mark Weiner", "Thomas R. Campion", "Thomas Carton", "Christopher B. Forrest", "Rainu Kaushal", "Fei Wang", "Yifan Peng"], "title": "Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for publication in npj Health Systems", "summary": "Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)\nremains challenging due to its myriad symptoms that evolve over long- and\nvariable-time intervals. To address this issue, we developed a hybrid natural\nlanguage processing pipeline that integrates rule-based named entity\nrecognition with BERT-based assertion detection modules for PASC-symptom\nextraction and assertion detection from clinical notes. We developed a\ncomprehensive PASC lexicon with clinical specialists. From 11 health systems of\nthe RECOVER initiative network across the U.S., we curated 160 intake progress\nnotes for model development and evaluation, and collected 47,654 progress notes\nfor a population-level prevalence study. We achieved an average F1 score of\n0.82 in one-site internal validation and 0.76 in 10-site external validation\nfor assertion detection. Our pipeline processed each note at $2.448\\pm 0.812$\nseconds on average. Spearman correlation tests showed $\\rho >0.83$ for positive\nmentions and $\\rho >0.72$ for negative ones, both with $P <0.0001$. These\ndemonstrate the effectiveness and efficiency of our models and their potential\nfor improving PASC diagnosis."}
{"id": "2508.12413", "pdf": "https://arxiv.org/pdf/2508.12413", "abs": "https://arxiv.org/abs/2508.12413", "authors": ["Zidong Cui", "Pan Zhang", "Ying Tang"], "title": "Quantum Flow Matching", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "15 pages, 11 figures", "summary": "Flow matching has rapidly become a dominant paradigm in classical generative\nmodeling, offering an efficient way to interpolate between two complex\ndistributions. We extend this idea to the quantum realm and introduce Quantum\nFlow Matching (QFM)-a fully quantum-circuit realization that offers efficient\ninterpolation between two density matrices. QFM offers systematic preparation\nof density matrices and generation of samples for accurately estimating\nobservables, and can be realized on a quantum computer without the need for\ncostly circuit redesigns. We validate its versatility on a set of applications:\n(i) generating target states with prescribed magnetization and entanglement\nentropy, (ii) estimating nonequilibrium free-energy differences to test the\nquantum Jarzynski equality, and (iii) expediting the study on superdiffusion\nbreakdown. These results position QFM as a unifying and promising framework for\ngenerative modeling across quantum systems."}
{"id": "2508.12410", "pdf": "https://arxiv.org/pdf/2508.12410", "abs": "https://arxiv.org/abs/2508.12410", "authors": ["Jun Zeng", "Yannan Huang", "Elif Keles", "Halil Ertugrul Aktas", "Gorkem Durak", "Nikhil Kumar Tomar", "Quoc-Huy Trinh", "Deepak Ranjan Nayak", "Ulas Bagci", "Debesh Jha"], "title": "SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Liver Cirrhosis plays a critical role in the prognosis of chronic liver\ndisease. Early detection and timely intervention are critical in significantly\nreducing mortality rates. However, the intricate anatomical architecture and\ndiverse pathological changes of liver tissue complicate the accurate detection\nand characterization of lesions in clinical settings. Existing methods\nunderutilize the spatial anatomical details in volumetric MRI data, thereby\nhindering their clinical effectiveness and explainability. To address this\nchallenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to\nmodel the spatial relationships within the complex anatomical structures of MRI\nvolumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),\nSRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and\ncombines anatomical information from the sagittal, coronal, and axial planes to\nconstruct a global spatial context representation, enabling efficient\nvolumetric segmentation of pathological liver structures. Furthermore, we\nintroduce the Spatial Reverse Attention module (SRMA), designed to\nprogressively refine cirrhotic details in the segmentation map, utilizing both\nthe coarse segmentation map and hierarchical encoding features. Extensive\nexperiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,\ndelivering exceptional performance in 3D pathological liver segmentation. Our\ncode is available for public:\n{\\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}."}
{"id": "2508.12448", "pdf": "https://arxiv.org/pdf/2508.12448", "abs": "https://arxiv.org/abs/2508.12448", "authors": ["Yeongwoo Song", "Jaeyong Bae", "Dong-Kyum Kim", "Hawoong Jeong"], "title": "Uncovering Emergent Physics Representations Learned In-Context by Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": "17 pages, 10 figures", "summary": "Large language models (LLMs) exhibit impressive in-context learning (ICL)\nabilities, enabling them to solve wide range of tasks via textual prompts\nalone. As these capabilities advance, the range of applicable domains continues\nto expand significantly. However, identifying the precise mechanisms or\ninternal structures within LLMs that allow successful ICL across diverse,\ndistinct classes of tasks remains elusive. Physics-based tasks offer a\npromising testbed for probing this challenge. Unlike synthetic sequences such\nas basic arithmetic or symbolic equations, physical systems provide\nexperimentally controllable, real-world data based on structured dynamics\ngrounded in fundamental principles. This makes them particularly suitable for\nstudying the emergent reasoning behaviors of LLMs in a realistic yet tractable\nsetting. Here, we mechanistically investigate the ICL ability of LLMs,\nespecially focusing on their ability to reason about physics. Using a dynamics\nforecasting task in physical systems as a proxy, we evaluate whether LLMs can\nlearn physics in context. We first show that the performance of dynamics\nforecasting in context improves with longer input contexts. To uncover how such\ncapability emerges in LLMs, we analyze the model's residual stream activations\nusing sparse autoencoders (SAEs). Our experiments reveal that the features\ncaptured by SAEs correlate with key physical variables, such as energy. These\nfindings demonstrate that meaningful physical concepts are encoded within LLMs\nduring in-context learning. In sum, our work provides a novel case study that\nbroadens our understanding of how LLMs learn in context."}
{"id": "2508.12412", "pdf": "https://arxiv.org/pdf/2508.12412", "abs": "https://arxiv.org/abs/2508.12412", "authors": ["Ron Solomon", "Yarin Yerushalmi Levi", "Lior Vaknin", "Eran Aizikovich", "Amit Baras", "Etai Ohana", "Amit Giloni", "Shamik Bose", "Chiara Picardi", "Yuval Elovici", "Asaf Shabtai"], "title": "LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The incorporation of large language models in multi-agent systems (MASs) has\nthe potential to significantly improve our ability to autonomously solve\ncomplex problems. However, such systems introduce unique challenges in\nmonitoring, interpreting, and detecting system failures. Most existing MAS\nobservability frameworks focus on analyzing each individual agent separately,\noverlooking failures associated with the entire MAS. To bridge this gap, we\npropose LumiMAS, a novel MAS observability framework that incorporates advanced\nanalytics and monitoring techniques. The proposed framework consists of three\nkey components: a monitoring and logging layer, anomaly detection layer, and\nanomaly explanation layer. LumiMAS's first layer monitors MAS executions,\ncreating detailed logs of the agents' activity. These logs serve as input to\nthe anomaly detection layer, which detects anomalies across the MAS workflow in\nreal time. Then, the anomaly explanation layer performs classification and root\ncause analysis (RCA) of the detected anomalies. LumiMAS was evaluated on seven\ndifferent MAS applications, implemented using two popular MAS platforms, and a\ndiverse set of possible failures. The applications include two novel\nfailure-tailored applications that illustrate the effects of a hallucination or\nbias on the MAS. The evaluation results demonstrate LumiMAS's effectiveness in\nfailure detection, classification, and RCA."}
{"id": "2508.12466", "pdf": "https://arxiv.org/pdf/2508.12466", "abs": "https://arxiv.org/abs/2508.12466", "authors": ["Xuhui Zhan", "Tyler Derr"], "title": "Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "15pages, 3 figures", "summary": "Traditional multimodal learning approaches require expensive alignment\npre-training to bridge vision and language modalities, typically projecting\nvisual features into discrete text token spaces. We challenge both fundamental\nassumptions underlying this paradigm by proposing Inverse-LLaVA, a novel\napproach that eliminates alignment pre-training entirely while inverting the\nconventional mapping direction. Rather than projecting visual features to text\nspace, our method maps text embeddings into continuous visual representation\nspace and performs fusion within transformer intermediate layers. Through\nselective additive components in attention mechanisms, we enable dynamic\nintegration of visual and textual representations without requiring massive\nimage-text alignment datasets. Comprehensive experiments across nine multimodal\nbenchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves\nnotable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,\nVizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing\nexpected decreases in perception tasks requiring memorized visual-text\nassociations (celebrity recognition: -49.5%, OCR: -21.3%). These results\nprovide the first empirical evidence that alignment pre-training is not\nnecessary for effective multimodal learning, particularly for complex reasoning\ntasks. Our work establishes the feasibility of a new paradigm that reduces\ncomputational requirements by 45%, challenges conventional wisdom about\nmodality fusion, and opens new research directions for efficient multimodal\narchitectures that preserve modality-specific characteristics. Our project\nwebsite with code and additional resources is available at\nhttps://inverse-llava.github.io."}
{"id": "2508.12413", "pdf": "https://arxiv.org/pdf/2508.12413", "abs": "https://arxiv.org/abs/2508.12413", "authors": ["Zidong Cui", "Pan Zhang", "Ying Tang"], "title": "Quantum Flow Matching", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "15 pages, 11 figures", "summary": "Flow matching has rapidly become a dominant paradigm in classical generative\nmodeling, offering an efficient way to interpolate between two complex\ndistributions. We extend this idea to the quantum realm and introduce Quantum\nFlow Matching (QFM)-a fully quantum-circuit realization that offers efficient\ninterpolation between two density matrices. QFM offers systematic preparation\nof density matrices and generation of samples for accurately estimating\nobservables, and can be realized on a quantum computer without the need for\ncostly circuit redesigns. We validate its versatility on a set of applications:\n(i) generating target states with prescribed magnetization and entanglement\nentropy, (ii) estimating nonequilibrium free-energy differences to test the\nquantum Jarzynski equality, and (iii) expediting the study on superdiffusion\nbreakdown. These results position QFM as a unifying and promising framework for\ngenerative modeling across quantum systems."}
{"id": "2508.12477", "pdf": "https://arxiv.org/pdf/2508.12477", "abs": "https://arxiv.org/abs/2508.12477", "authors": ["Ratun Rahman", "Atit Pokharel", "Md Raihan Uddin", "Dinh C. Nguyen"], "title": "SimQFL: A Quantum Federated Learning Simulator with Real-Time Visualization", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum federated learning (QFL) is an emerging field that has the potential\nto revolutionize computation by taking advantage of quantum physics concepts in\na distributed machine learning (ML) environment. However, the majority of\navailable quantum simulators are primarily built for general quantum circuit\nsimulation and do not include integrated support for machine learning tasks\nsuch as training, evaluation, and iterative optimization. Furthermore,\ndesigning and assessing quantum learning algorithms is still a difficult and\nresource-intensive task. Real-time updates are essential for observing model\nconvergence, debugging quantum circuits, and making conscious choices during\ntraining with the use of limited resources. Furthermore, most current\nsimulators fail to support the integration of user-specific data for training\npurposes, undermining the main purpose of using a simulator. In this study, we\nintroduce SimQFL, a customized simulator that simplifies and accelerates QFL\nexperiments in quantum network applications. SimQFL supports real-time,\nepoch-wise output development and visualization, allowing researchers to\nmonitor the process of learning across each training round. Furthermore, SimQFL\noffers an intuitive and visually appealing interface that facilitates ease of\nuse and seamless execution. Users can customize key variables such as the\nnumber of epochs, learning rates, number of clients, and quantum\nhyperparameters such as qubits and quantum layers, making the simulator\nsuitable for various QFL applications. The system gives immediate feedback\nfollowing each epoch by showing intermediate outcomes and dynamically\nillustrating learning curves. SimQFL is a practical and interactive platform\nenabling academics and developers to prototype, analyze, and tune quantum\nneural networks with greater transparency and control in distributed quantum\nnetworks."}
{"id": "2508.12416", "pdf": "https://arxiv.org/pdf/2508.12416", "abs": "https://arxiv.org/abs/2508.12416", "authors": ["Vuong Nguyen", "Gabriel Vigliensoni"], "title": "fCrit: A Visual Explanation System for Furniture Design Creative Support", "categories": ["cs.HC", "cs.AI", "H.5.2"], "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts\n  2025) arXiv:2406.14485", "summary": "We introduce fCrit, a dialogue-based AI system designed to critique furniture\ndesign with a focus on explainability. Grounded in reflective learning and\nformal analysis, fCrit employs a multi-agent architecture informed by a\nstructured design knowledge base. We argue that explainability in the arts\nshould not only make AI reasoning transparent but also adapt to the ways users\nthink and talk about their designs. We demonstrate how fCrit supports this\nprocess by tailoring explanations to users' design language and cognitive\nframing. This work contributes to Human-Centered Explainable AI (HCXAI) in\ncreative practice, advancing domain-specific methods for situated, dialogic,\nand visually grounded AI support."}
{"id": "2508.12480", "pdf": "https://arxiv.org/pdf/2508.12480", "abs": "https://arxiv.org/abs/2508.12480", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Andreas Bulling"], "title": "The Yokai Learning Environment: Tracking Beliefs Over Space and Time", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": "Presented at the the ToM IJCAI 2025 Workshop", "summary": "Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to\nreason about the beliefs of others to build and maintain common ground.\nExisting ToM benchmarks, however, are restricted to passive observer settings\nor lack an assessment of how agents establish and maintain common ground over\ntime. To address these gaps, we introduce the Yokai Learning Environment (YLE)\n- a multi-agent reinforcement learning (RL) environment based on the\ncooperative card game Yokai. In the YLE, agents take turns peeking at hidden\ncards and moving them to form clusters based on colour. Success requires\ntracking evolving beliefs, remembering past observations, using hints as\ngrounded communication, and maintaining common ground with teammates. Our\nevaluation yields two key findings: First, current RL agents struggle to solve\nthe YLE, even when given access to perfect memory. Second, while belief\nmodelling improves performance, agents are still unable to effectively\ngeneralise to unseen partners or form accurate beliefs over longer games,\nexposing a reliance on brittle conventions rather than robust belief tracking.\nWe use the YLE to investigate research questions in belief modelling, memory,\npartner generalisation, and scaling to higher-order ToM."}
{"id": "2508.12430", "pdf": "https://arxiv.org/pdf/2508.12430", "abs": "https://arxiv.org/abs/2508.12430", "authors": ["Yahsin Yeh", "Yilun Wu", "Bokai Ruan", "Honghan Shuai"], "title": "Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Natural language explanations in visual question answering (VQA-NLE) aim to\nmake black-box models more transparent by elucidating their decision-making\nprocesses. However, we find that existing VQA-NLE systems can produce\ninconsistent explanations and reach conclusions without genuinely understanding\nthe underlying context, exposing weaknesses in either their inference pipeline\nor explanation-generation mechanism. To highlight these vulnerabilities, we not\nonly leverage an existing adversarial strategy to perturb questions but also\npropose a novel strategy that minimally alters images to induce contradictory\nor spurious outputs. We further introduce a mitigation method that leverages\nexternal knowledge to alleviate these inconsistencies, thereby bolstering model\nrobustness. Extensive evaluations on two standard benchmarks and two widely\nused VQA-NLE models underscore the effectiveness of our attacks and the\npotential of knowledge-based defenses, ultimately revealing pressing security\nand reliability concerns in current VQA-NLE systems."}
{"id": "2508.12495", "pdf": "https://arxiv.org/pdf/2508.12495", "abs": "https://arxiv.org/abs/2508.12495", "authors": ["Yuangang Li", "Yiqing Shen", "Yi Nian", "Jiechao Gao", "Ziyi Wang", "Chenxiao Yu", "Shawn Li", "Jie Wang", "Xiyang Hu", "Yue Zhao"], "title": "Mitigating Hallucinations in Large Language Models via Causal Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) exhibit logically inconsistent hallucinations\nthat appear coherent yet violate reasoning principles, with recent research\nsuggesting an inverse relationship between causal reasoning capabilities and\nsuch hallucinations. However, existing reasoning approaches in LLMs, such as\nChain-of-Thought (CoT) and its graph-based variants, operate at the linguistic\ntoken level rather than modeling the underlying causal relationships between\nvariables, lacking the ability to represent conditional independencies or\nsatisfy causal identification assumptions. To bridge this gap, we introduce\ncausal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning\nframework that trains LLMs to explicitly construct variable-level directed\nacyclic graph (DAG) and then perform reasoning over it. Moreover, we present a\ndataset comprising 25,368 samples (CausalDR), where each sample includes an\ninput question, explicit causal DAG, graph-based reasoning trace, and validated\nanswer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves\nthe causal reasoning capability with the state-of-the-art 95.33% accuracy on\nCLADDER (surpassing human performance of 94.8% for the first time) and reduces\nthe hallucination on HaluEval with 10% improvements. It demonstrates that\nexplicit causal structure modeling in LLMs can effectively mitigate logical\ninconsistencies in LLM outputs. Code is available at\nhttps://github.com/MrLYG/CDCR-SFT."}
{"id": "2508.12435", "pdf": "https://arxiv.org/pdf/2508.12435", "abs": "https://arxiv.org/abs/2508.12435", "authors": ["Deqing Song", "Weimin Yang", "Maryam Rezayati", "Hans Wernher van de Venn"], "title": "Tactile Gesture Recognition with Built-in Joint Sensors for Industrial Robots", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "While gesture recognition using vision or robot skins is an active research\narea in Human-Robot Collaboration (HRC), this paper explores deep learning\nmethods relying solely on a robot's built-in joint sensors, eliminating the\nneed for external sensors. We evaluated various convolutional neural network\n(CNN) architectures and collected two datasets to study the impact of data\nrepresentation and model architecture on the recognition accuracy. Our results\nshow that spectrogram-based representations significantly improve accuracy,\nwhile model architecture plays a smaller role. We also tested generalization to\nnew robot poses, where spectrogram-based models performed better. Implemented\non a Franka Emika Research robot, two of our methods, STFT2DCNN and STT3DCNN,\nachieved over 95% accuracy in contact detection and gesture classification.\nThese findings demonstrate the feasibility of external-sensor-free tactile\nrecognition and promote further research toward cost-effective, scalable\nsolutions for HRC."}
{"id": "2508.12500", "pdf": "https://arxiv.org/pdf/2508.12500", "abs": "https://arxiv.org/abs/2508.12500", "authors": ["Rahmat K. Adesunkanmi", "Ashfaq Khokhar", "Goce Trajcevski", "Sohail Murad"], "title": "Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models", "categories": ["cs.AI", "cs.LG", "q-bio.QM"], "comment": "Submitted to ACM", "summary": "Molecular dynamics simulations (MDS) face challenges, including\nresource-heavy computations and the need to manually scan outputs to detect\n\"interesting events,\" such as the formation and persistence of hydrogen bonds\nbetween atoms of different molecules. A critical research gap lies in\nidentifying the underlying causes of hydrogen bond formation and separation\n-understanding which interactions or prior events contribute to their emergence\nover time. With this challenge in mind, we propose leveraging spatio-temporal\ndata analytics and machine learning models to enhance the detection of these\nphenomena. In this paper, our approach is inspired by causal modeling and aims\nto identify the root cause variables of hydrogen bond formation and separation\nevents. Specifically, we treat the separation of hydrogen bonds as an\n\"intervention\" occurring and represent the causal structure of the bonding and\nseparation events in the MDS as graphical causal models. These causal models\nare built using a variational autoencoder-inspired architecture that enables us\nto infer causal relationships across samples with diverse underlying causal\ngraphs while leveraging shared dynamic information. We further include a step\nto infer the root causes of changes in the joint distribution of the causal\nmodels. By constructing causal models that capture shifts in the conditional\ndistributions of molecular interactions during bond formation or separation,\nthis framework provides a novel perspective on root cause analysis in molecular\ndynamic systems. We validate the efficacy of our model empirically on the\natomic trajectories that used MDS for chiral separation, demonstrating that we\ncan predict many steps in the future and also find the variables driving the\nobserved changes in the system."}
{"id": "2508.12466", "pdf": "https://arxiv.org/pdf/2508.12466", "abs": "https://arxiv.org/abs/2508.12466", "authors": ["Xuhui Zhan", "Tyler Derr"], "title": "Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "15pages, 3 figures", "summary": "Traditional multimodal learning approaches require expensive alignment\npre-training to bridge vision and language modalities, typically projecting\nvisual features into discrete text token spaces. We challenge both fundamental\nassumptions underlying this paradigm by proposing Inverse-LLaVA, a novel\napproach that eliminates alignment pre-training entirely while inverting the\nconventional mapping direction. Rather than projecting visual features to text\nspace, our method maps text embeddings into continuous visual representation\nspace and performs fusion within transformer intermediate layers. Through\nselective additive components in attention mechanisms, we enable dynamic\nintegration of visual and textual representations without requiring massive\nimage-text alignment datasets. Comprehensive experiments across nine multimodal\nbenchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves\nnotable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,\nVizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing\nexpected decreases in perception tasks requiring memorized visual-text\nassociations (celebrity recognition: -49.5%, OCR: -21.3%). These results\nprovide the first empirical evidence that alignment pre-training is not\nnecessary for effective multimodal learning, particularly for complex reasoning\ntasks. Our work establishes the feasibility of a new paradigm that reduces\ncomputational requirements by 45%, challenges conventional wisdom about\nmodality fusion, and opens new research directions for efficient multimodal\narchitectures that preserve modality-specific characteristics. Our project\nwebsite with code and additional resources is available at\nhttps://inverse-llava.github.io."}
{"id": "2508.12519", "pdf": "https://arxiv.org/pdf/2508.12519", "abs": "https://arxiv.org/abs/2508.12519", "authors": ["Khai Nguyen"], "title": "An Introduction to Sliced Optimal Transport", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "227 pages", "summary": "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal\ntransport (OT) that exploits the tractability of one-dimensional OT problems.\nBy combining tools from OT, integral geometry, and computational statistics,\nSOT enables fast and scalable computation of distances, barycenters, and\nkernels for probability measures, while retaining rich geometric structure.\nThis paper provides a comprehensive review of SOT, covering its mathematical\nfoundations, methodological advances, computational methods, and applications.\nWe discuss key concepts of OT and one-dimensional OT, the role of tools from\nintegral geometry such as Radon transform in projecting measures, and\nstatistical techniques for estimating sliced distances. The paper further\nexplores recent methodological advances, including non-linear projections,\nimproved Monte Carlo approximations, statistical estimation techniques for\none-dimensional optimal transport, weighted slicing techniques, and\ntransportation plan estimation methods. Variational problems, such as minimum\nsliced Wasserstein estimation, barycenters, gradient flows, kernel\nconstructions, and embeddings are examined alongside extensions to unbalanced,\npartial, multi-marginal, and Gromov-Wasserstein settings. Applications span\nmachine learning, statistics, computer graphics and computer visions,\nhighlighting SOT's versatility as a practical computational tool. This work\nwill be of interest to researchers and practitioners in machine learning, data\nsciences, and computational disciplines seeking efficient alternatives to\nclassical OT."}
{"id": "2508.12470", "pdf": "https://arxiv.org/pdf/2508.12470", "abs": "https://arxiv.org/abs/2508.12470", "authors": ["Afrah Gueriani", "Hamza Kheddar", "Ahmed Cherif Mazari", "Mohamed Chahine Ghanem"], "title": "A Robust Cross-Domain IDS using BiGRU-LSTM-Attention for Medical and Industrial IoT Security", "categories": ["cs.CR", "cs.AI"], "comment": "10 pages", "summary": "The increased Internet of Medical Things IoMT and the Industrial Internet of\nThings IIoT interconnectivity has introduced complex cybersecurity challenges,\nexposing sensitive data, patient safety, and industrial operations to advanced\ncyber threats. To mitigate these risks, this paper introduces a novel\ntransformer-based intrusion detection system IDS, termed BiGAT-ID a hybrid\nmodel that combines bidirectional gated recurrent units BiGRU, long short-term\nmemory LSTM networks, and multi-head attention MHA. The proposed architecture\nis designed to effectively capture bidirectional temporal dependencies, model\nsequential patterns, and enhance contextual feature representation. Extensive\nexperiments on two benchmark datasets, CICIoMT2024 medical IoT and EdgeIIoTset\nindustrial IoT demonstrate the model's cross-domain robustness, achieving\ndetection accuracies of 99.13 percent and 99.34 percent, respectively.\nAdditionally, the model exhibits exceptional runtime efficiency, with inference\ntimes as low as 0.0002 seconds per instance in IoMT and 0.0001 seconds in IIoT\nscenarios. Coupled with a low false positive rate, BiGAT-ID proves to be a\nreliable and efficient IDS for deployment in real-world heterogeneous IoT\nenvironments"}
{"id": "2508.12535", "pdf": "https://arxiv.org/pdf/2508.12535", "abs": "https://arxiv.org/abs/2508.12535", "authors": ["Seonglae Cho", "Zekun Wu", "Adriano Koshiyama"], "title": "CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "42 pages, 9 tables", "summary": "Sparse Autoencoders (SAEs) can extract interpretable features from large\nlanguage models (LLMs) without supervision. However, their effectiveness in\ndownstream steering tasks is limited by the requirement for contrastive\ndatasets or large activation storage. To address these limitations, we propose\nCorrSteer, which selects features by correlating sample correctness with SAE\nactivations from generated tokens at inference time. This approach uses only\ninference-time activations to extract more relevant features, thereby avoiding\nspurious correlations. It also obtains steering coefficients from average\nactivations, automating the entire pipeline. Our method shows improved task\nperformance on QA, bias mitigation, jailbreaking prevention, and reasoning\nbenchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%\nimprovement in MMLU performance and a +22.9% improvement in HarmBench with only\n4000 samples. Selected features demonstrate semantically meaningful patterns\naligned with each task's requirements, revealing the underlying capabilities\nthat drive performance. Our work establishes correlationbased selection as an\neffective and scalable approach for automated SAE steering across language\nmodel applications."}
{"id": "2508.12473", "pdf": "https://arxiv.org/pdf/2508.12473", "abs": "https://arxiv.org/abs/2508.12473", "authors": ["Eranga Bandara", "Ross Gore", "Sachin Shetty", "Ravi Mukkamala", "Christopher Rhea", "Atmaram Yarlagadda", "Shaifali Kaushik", "L. H. M. P. De Silva", "Andriy Maznychenko", "Inna Sokolowska", "Amin Hass", "Kasun De Zoysa"], "title": "Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a\ncritical role in sports science, rehabilitation, and clinical neurology.\nTraditional analysis of H-reflex EMG waveforms is subject to variability and\ninterpretation bias among clinicians and researchers, limiting reliability and\nstandardization. To address these challenges, we propose a Fine-Tuned\nVision-Language Model (VLM) Consortium and a reasoning Large-Language Model\n(LLM)-enabled Decision Support System for automated H-reflex waveform\ninterpretation and diagnosis. Our approach leverages multiple VLMs, each\nfine-tuned on curated datasets of H-reflex EMG waveform images annotated with\nclinical observations, recovery timelines, and athlete metadata. These models\nare capable of extracting key electrophysiological features and predicting\nneuromuscular states, including fatigue, injury, and recovery, directly from\nEMG images and contextual metadata. Diagnostic outputs from the VLM consortium\nare aggregated using a consensus-based method and refined by a specialized\nreasoning LLM, which ensures robust, transparent, and explainable decision\nsupport for clinicians and sports scientists. The end-to-end platform\norchestrates seamless communication between the VLM ensemble and the reasoning\nLLM, integrating prompt engineering strategies and automated reasoning\nworkflows using LLM Agents. Experimental results demonstrate that this hybrid\nsystem delivers highly accurate, consistent, and interpretable H-reflex\nassessments, significantly advancing the automation and standardization of\nneuromuscular diagnostics. To our knowledge, this work represents the first\nintegration of a fine-tuned VLM consortium with a reasoning LLM for image-based\nH-reflex analysis, laying the foundation for next-generation AI-assisted\nneuromuscular assessment and athlete monitoring platforms."}
{"id": "2508.12560", "pdf": "https://arxiv.org/pdf/2508.12560", "abs": "https://arxiv.org/abs/2508.12560", "authors": ["Prabath Abeysekara", "Hai Dong"], "title": "Data-driven Trust Bootstrapping for Mobile Edge Computing-based Industrial IoT Services", "categories": ["cs.CR", "cs.DC", "cs.LG", "C.2; C.4; I.2"], "comment": "15 pages", "summary": "We propose a data-driven and context-aware approach to bootstrap\ntrustworthiness of homogeneous Internet of Things (IoT) services in Mobile Edge\nComputing (MEC) based industrial IoT (IIoT) systems. The proposed approach\naddresses key limitations in adapting existing trust bootstrapping approaches\ninto MEC-based IIoT systems. These key limitations include, the lack of\nopportunity for a service consumer to interact with a lesser-known service over\na prolonged period of time to get a robust measure of its trustworthiness,\ninability of service consumers to consistently interact with their peers to\nreceive reliable recommendations of the trustworthiness of a lesser-known\nservice as well as the impact of uneven context parameters in different MEC\nenvironments causing uneven trust environments for trust evaluation. In\naddition, the proposed approach also tackles the problem of data sparsity via\nenabling knowledge sharing among different MEC environments within a given MEC\ntopology. To verify the effectiveness of the proposed approach, we carried out\na comprehensive evaluation on two real-world datasets suitably adjusted to\nexhibit the context-dependent trust information accumulated in MEC environments\nwithin a given MEC topology. The experimental results affirmed the\neffectiveness of our approach and its suitability to bootstrap trustworthiness\nof services in MEC-based IIoT systems."}
{"id": "2508.12479", "pdf": "https://arxiv.org/pdf/2508.12479", "abs": "https://arxiv.org/abs/2508.12479", "authors": ["Chinmay Maheshwari", "Chinmay Pimpalkhare", "Debasish Chatterjee"], "title": "EXOTIC: An Exact, Optimistic, Tree-Based Algorithm for Min-Max Optimization", "categories": ["math.OC", "cs.AI", "cs.GT", "cs.MA", "econ.GN", "q-fin.EC", "90C26, 90C47, 68Q32, 91A06, 65K05"], "comment": "31 pages, 2 figures, 3 tables", "summary": "Min-max optimization arises in many domains such as game theory, adversarial\nmachine learning, etc., with gradient-based methods as a typical computational\ntool. Beyond convex-concave min-max optimization, the solutions found by\ngradient-based methods may be arbitrarily far from global optima. In this work,\nwe present an algorithmic apparatus for computing globally optimal solutions in\nconvex-non-concave and non-convex-concave min-max optimization. For former, we\nemploy a reformulation that transforms it into a non-concave-convex max-min\noptimization problem with suitably defined feasible sets and objective\nfunction. The new form can be viewed as a generalization of Sion's minimax\ntheorem. Next, we introduce EXOTIC-an Exact, Optimistic, Tree-based algorithm\nfor solving the reformulated max-min problem. EXOTIC employs an iterative\nconvex optimization solver to (approximately) solve the inner minimization and\na hierarchical tree search for the outer maximization to optimistically select\npromising regions to search based on the approximate solution returned by\nconvex optimization solver. We establish an upper bound on its optimality gap\nas a function of the number of calls to the inner solver, the solver's\nconvergence rate, and additional problem-dependent parameters. Both our\nalgorithmic apparatus along with its accompanying theoretical analysis can also\nbe applied for non-convex-concave min-max optimization. In addition, we propose\na class of benchmark convex-non-concave min-max problems along with their\nanalytical global solutions, providing a testbed for evaluating algorithms for\nmin-max optimization. Empirically, EXOTIC outperforms gradient-based methods on\nthis benchmark as well as on existing numerical benchmark problems from the\nliterature. Finally, we demonstrate the utility of EXOTIC by computing security\nstrategies in multi-player games with three or more players."}
{"id": "2508.12609", "pdf": "https://arxiv.org/pdf/2508.12609", "abs": "https://arxiv.org/abs/2508.12609", "authors": ["Qingyan Meng", "Mingqing Xiao", "Zhengyu Ma", "Huihui Zhou", "Yonghong Tian", "Zhouchen Lin"], "title": "A Self-Ensemble Inspired Approach for Effective Training of Binary-Weight Spiking Neural Networks", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) are a promising approach to low-power\napplications on neuromorphic hardware due to their energy efficiency. However,\ntraining SNNs is challenging because of the non-differentiable spike generation\nfunction. To address this issue, the commonly used approach is to adopt the\nbackpropagation through time framework, while assigning the gradient of the\nnon-differentiable function with some surrogates. Similarly, Binary Neural\nNetworks (BNNs) also face the non-differentiability problem and rely on\napproximating gradients. However, the deep relationship between these two\nfields and how their training techniques can benefit each other has not been\nsystematically researched. Furthermore, training binary-weight SNNs is even\nmore difficult. In this work, we present a novel perspective on the dynamics of\nSNNs and their close connection to BNNs through an analysis of the\nbackpropagation process. We demonstrate that training a feedforward SNN can be\nviewed as training a self-ensemble of a binary-activation neural network with\nnoise injection. Drawing from this new understanding of SNN dynamics, we\nintroduce the Self-Ensemble Inspired training method for (Binary-Weight) SNNs\n(SEI-BWSNN), which achieves high-performance results with low latency even for\nthe case of the 1-bit weights. Specifically, we leverage a structure of\nmultiple shortcuts and a knowledge distillation-based training technique to\nimprove the training of (binary-weight) SNNs. Notably, by binarizing FFN layers\nin a Transformer architecture, our approach achieves 82.52% accuracy on\nImageNet with only 2 time steps, indicating the effectiveness of our\nmethodology and the potential of binary-weight SNNs."}
{"id": "2508.12485", "pdf": "https://arxiv.org/pdf/2508.12485", "abs": "https://arxiv.org/abs/2508.12485", "authors": ["Aayush Gupta", "Arpit Bhayani"], "title": "Cold-RL: Learning Cache Eviction with Offline Reinforcement Learning for NGINX", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.NI", "C.2.4; C.4; D.4.2; I.2.6"], "comment": "8 pages, 4 figures (system architecture, eviction path, training\n  pipeline, and DQN algorithm), 2 tables. Code available at\n  https://github.com/ayushgupta4897/DRL-Cache", "summary": "Web proxies such as NGINX commonly rely on least-recently-used (LRU)\neviction, which is size agnostic and can thrash under periodic bursts and mixed\nobject sizes. We introduce Cold-RL, a learned eviction policy for NGINX that\nreplaces LRU's forced-expire path with a dueling Deep Q-Network served by an\nONNX sidecar within a strict microsecond budget. On each eviction, Cold-RL\nsamples the K least-recently-used objects, extracts six lightweight features\n(age, size, hit count, inter-arrival time, remaining TTL, and last origin RTT),\nand requests a bitmask of victims; a hard timeout of 500 microseconds triggers\nimmediate fallback to native LRU. Policies are trained offline by replaying\nNGINX access logs through a cache simulator with a simple reward: a retained\nobject earns one point if it is hit again before TTL expiry. We compare against\nLRU, LFU, size-based, adaptive LRU, and a hybrid baseline on two adversarial\nworkloads. With a 25 MB cache, Cold-RL raises hit ratio from 0.1436 to 0.3538,\na 146 percent improvement over the best classical baseline; at 100 MB, from\n0.7530 to 0.8675, a 15 percent gain; and at 400 MB it matches classical methods\n(about 0.918). Inference adds less than 2 percent CPU overhead and keeps 95th\npercentile eviction latency within budget. To our knowledge, this is the first\nreinforcement learning eviction policy integrated into NGINX with strict SLOs."}
{"id": "2508.12614", "pdf": "https://arxiv.org/pdf/2508.12614", "abs": "https://arxiv.org/abs/2508.12614", "authors": ["Zhongqin Wang", "J. Andrew Zhang", "Kai Wu", "Min Xu", "Y. Jay Guo"], "title": "Towards SISO Bistatic Sensing for ISAC", "categories": ["eess.SP", "cs.HC", "cs.LG"], "comment": null, "summary": "Integrated Sensing and Communication (ISAC) is a key enabler for\nnext-generation wireless systems. However, real-world deployment is often\nlimited to low-cost, single-antenna transceivers. In such bistatic Single-Input\nSingle-Output (SISO) setup, clock asynchrony introduces random phase offsets in\nChannel State Information (CSI), which cannot be mitigated using conventional\nmulti-antenna methods. This work proposes WiDFS 3.0, a lightweight bistatic\nSISO sensing framework that enables accurate delay and Doppler estimation from\ndistorted CSI by effectively suppressing Doppler mirroring ambiguity. It\noperates with only a single antenna at both the transmitter and receiver,\nmaking it suitable for low-complexity deployments. We propose a\nself-referencing cross-correlation (SRCC) method for SISO random phase removal\nand employ delay-domain beamforming to resolve Doppler ambiguity. The resulting\nunambiguous delay-Doppler-time features enable robust sensing with compact\nneural networks. Extensive experiments show that WiDFS 3.0 achieves accurate\nparameter estimation, with performance comparable to or even surpassing that of\nprior multi-antenna methods, especially in delay estimation. Validated under\nsingle- and multi-target scenarios, the extracted ambiguity-resolved features\nshow strong sensing accuracy and generalization. For example, when deployed on\nthe embedded-friendly MobileViT-XXS with only 1.3M parameters, WiDFS 3.0\nconsistently outperforms conventional features such as CSI amplitude, mirrored\nDoppler, and multi-receiver aggregated Doppler."}
{"id": "2508.12495", "pdf": "https://arxiv.org/pdf/2508.12495", "abs": "https://arxiv.org/abs/2508.12495", "authors": ["Yuangang Li", "Yiqing Shen", "Yi Nian", "Jiechao Gao", "Ziyi Wang", "Chenxiao Yu", "Shawn Li", "Jie Wang", "Xiyang Hu", "Yue Zhao"], "title": "Mitigating Hallucinations in Large Language Models via Causal Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) exhibit logically inconsistent hallucinations\nthat appear coherent yet violate reasoning principles, with recent research\nsuggesting an inverse relationship between causal reasoning capabilities and\nsuch hallucinations. However, existing reasoning approaches in LLMs, such as\nChain-of-Thought (CoT) and its graph-based variants, operate at the linguistic\ntoken level rather than modeling the underlying causal relationships between\nvariables, lacking the ability to represent conditional independencies or\nsatisfy causal identification assumptions. To bridge this gap, we introduce\ncausal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning\nframework that trains LLMs to explicitly construct variable-level directed\nacyclic graph (DAG) and then perform reasoning over it. Moreover, we present a\ndataset comprising 25,368 samples (CausalDR), where each sample includes an\ninput question, explicit causal DAG, graph-based reasoning trace, and validated\nanswer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves\nthe causal reasoning capability with the state-of-the-art 95.33% accuracy on\nCLADDER (surpassing human performance of 94.8% for the first time) and reduces\nthe hallucination on HaluEval with 10% improvements. It demonstrates that\nexplicit causal structure modeling in LLMs can effectively mitigate logical\ninconsistencies in LLM outputs. Code is available at\nhttps://github.com/MrLYG/CDCR-SFT."}
{"id": "2508.12617", "pdf": "https://arxiv.org/pdf/2508.12617", "abs": "https://arxiv.org/abs/2508.12617", "authors": ["Ming Li", "Zihuai He", "Min Zhang", "Xiaowei Zhan", "Changshuai Wei", "Robert C Elston", "Qing Lu"], "title": "A Generalized Genetic Random Field Method for the Genetic Association Analysis of Sequencing Data", "categories": ["stat.ME", "cs.AI", "cs.LG"], "comment": null, "summary": "With the advance of high-throughput sequencing technologies, it has become\nfeasible to investigate the influence of the entire spectrum of sequencing\nvariations on complex human diseases. Although association studies utilizing\nthe new sequencing technologies hold great promise to unravel novel genetic\nvariants, especially rare genetic variants that contribute to human diseases,\nthe statistical analysis of high-dimensional sequencing data remains a\nchallenge. Advanced analytical methods are in great need to facilitate\nhigh-dimensional sequencing data analyses. In this article, we propose a\ngeneralized genetic random field (GGRF) method for association analyses of\nsequencing data. Like other similarity-based methods (e.g., SIMreg and SKAT),\nthe new method has the advantages of avoiding the need to specify thresholds\nfor rare variants and allowing for testing multiple variants acting in\ndifferent directions and magnitude of effects. The method is built on the\ngeneralized estimating equation framework and thus accommodates a variety of\ndisease phenotypes (e.g., quantitative and binary phenotypes). Moreover, it has\na nice asymptotic property, and can be applied to small-scale sequencing data\nwithout need for small-sample adjustment. Through simulations, we demonstrate\nthat the proposed GGRF attains an improved or comparable power over a commonly\nused method, SKAT, under various disease scenarios, especially when rare\nvariants play a significant role in disease etiology. We further illustrate\nGGRF with an application to a real dataset from the Dallas Heart Study. By\nusing GGRF, we were able to detect the association of two candidate genes,\nANGPTL3 and ANGPTL4, with serum triglyceride."}
{"id": "2508.12506", "pdf": "https://arxiv.org/pdf/2508.12506", "abs": "https://arxiv.org/abs/2508.12506", "authors": ["E. Ulises Moya-Sánchez", "Abraham Sánchez-Perez", "Raúl Nanclares Da Veiga", "Alejandro Zarate-Macías", "Edgar Villareal", "Alejandro Sánchez-Montes", "Edtna Jauregui-Ulloa", "Héctor Moreno", "Ulises Cortés"], "title": "Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages,3 figures, under review", "summary": "Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age\nindividuals. Early detection of DR can reduce the risk of vision loss by up to\n95%, but a shortage of retinologists and challenges in timely examination\ncomplicate detection. Artificial Intelligence (AI) models using retinal fundus\nphotographs (RFPs) offer a promising solution. However, adoption in clinical\nsettings is hindered by low-quality data and biases that may lead AI systems to\nlearn unintended features. To address these challenges, we developed RAIS-DR, a\nResponsible AI System for DR screening that incorporates ethical principles\nacross the AI lifecycle. RAIS-DR integrates efficient convolutional models for\npreprocessing, quality assessment, and three specialized DR classification\nmodels. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local\ndataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated\nsignificant improvements, with F1 scores increasing by 5-12%, accuracy by\n6-19%, and specificity by 10-20%. Additionally, fairness metrics such as\nDisparate Impact and Equal Opportunity Difference indicated equitable\nperformance across demographic subgroups, underscoring RAIS-DR's potential to\nreduce healthcare disparities. These results highlight RAIS-DR as a robust and\nethically aligned solution for DR screening in clinical settings. The code,\nweights of RAIS-DR are available at\nhttps://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with\nRAIL."}
{"id": "2508.12640", "pdf": "https://arxiv.org/pdf/2508.12640", "abs": "https://arxiv.org/abs/2508.12640", "authors": ["Bastian Brandstötter", "Erich Kobler"], "title": "Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow", "categories": ["cs.CV", "cs.LG"], "comment": "12 pages, 3 figures, MICCAI workshops (SASHIMI) 2025", "summary": "Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic\ndiagnosis but requires gadolinium-based agents, which add cost and scan time,\nraise environmental concerns, and may pose risks to patients. In this work, we\npropose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for\nsynthesizing volumetric CE brain MRI from non-contrast inputs. First, a\npatch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).\nThen, this initial estimate is refined by a time-conditioned 3D rectified flow\nto incorporate realistic textures without compromising structural fidelity. We\ntrain this model on a multi-institutional collection of paired pre- and\npost-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360\ndiverse volumes, our best refined outputs achieve an axial FID of $12.46$ and\nKID of $0.007$ ($\\sim 68.7\\%$ lower FID than the posterior mean) while\nmaintaining low volumetric MSE of $0.057$ ($\\sim 27\\%$ higher than the\nposterior mean). Qualitative comparisons confirm that our method restores\nlesion margins and vascular details realistically, effectively navigating the\nperception-distortion trade-off for clinical deployment."}
{"id": "2508.12519", "pdf": "https://arxiv.org/pdf/2508.12519", "abs": "https://arxiv.org/abs/2508.12519", "authors": ["Khai Nguyen"], "title": "An Introduction to Sliced Optimal Transport", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "227 pages", "summary": "Sliced Optimal Transport (SOT) is a rapidly developing branch of optimal\ntransport (OT) that exploits the tractability of one-dimensional OT problems.\nBy combining tools from OT, integral geometry, and computational statistics,\nSOT enables fast and scalable computation of distances, barycenters, and\nkernels for probability measures, while retaining rich geometric structure.\nThis paper provides a comprehensive review of SOT, covering its mathematical\nfoundations, methodological advances, computational methods, and applications.\nWe discuss key concepts of OT and one-dimensional OT, the role of tools from\nintegral geometry such as Radon transform in projecting measures, and\nstatistical techniques for estimating sliced distances. The paper further\nexplores recent methodological advances, including non-linear projections,\nimproved Monte Carlo approximations, statistical estimation techniques for\none-dimensional optimal transport, weighted slicing techniques, and\ntransportation plan estimation methods. Variational problems, such as minimum\nsliced Wasserstein estimation, barycenters, gradient flows, kernel\nconstructions, and embeddings are examined alongside extensions to unbalanced,\npartial, multi-marginal, and Gromov-Wasserstein settings. Applications span\nmachine learning, statistics, computer graphics and computer visions,\nhighlighting SOT's versatility as a practical computational tool. This work\nwill be of interest to researchers and practitioners in machine learning, data\nsciences, and computational disciplines seeking efficient alternatives to\nclassical OT."}
{"id": "2508.12647", "pdf": "https://arxiv.org/pdf/2508.12647", "abs": "https://arxiv.org/abs/2508.12647", "authors": ["Hengnian Gu", "Zhifu Chen", "Yuxin Chen", "Jin Peng Zhou", "Dongdai Zhou"], "title": "Cognitive Structure Generation: From Educational Priors to Policy Optimization", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": null, "summary": "Cognitive structure is a student's subjective organization of an objective\nknowledge system, reflected in the psychological construction of concepts and\ntheir relations. However, cognitive structure assessment remains a\nlong-standing challenge in student modeling and psychometrics, persisting as a\nfoundational yet largely unassessable concept in educational practice. This\npaper introduces a novel framework, Cognitive Structure Generation (CSG), in\nwhich we first pretrain a Cognitive Structure Diffusion Probabilistic Model\n(CSDPM) to generate students' cognitive structures from educational priors, and\nthen further optimize its generative process as a policy with hierarchical\nreward signals via reinforcement learning to align with genuine cognitive\ndevelopment levels during students' learning processes. Experimental results on\nfour popular real-world education datasets show that cognitive structures\ngenerated by CSG offer more comprehensive and effective representations for\nstudent modeling, substantially improving performance on KT and CD tasks while\nenhancing interpretability."}
{"id": "2508.12520", "pdf": "https://arxiv.org/pdf/2508.12520", "abs": "https://arxiv.org/abs/2508.12520", "authors": ["Felipe Carlos dos Santos", "Eric Aislan Antonelo", "Gustavo Claudio Karl Couto"], "title": "An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages,submitted in ENIAC 2025", "summary": "Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is\ncrucial for autonomous-driving perception. In this work, we employ Cross-View\nTransformers (CVT) for learning to map camera images to three BEV's channels -\nroad, lane markings, and planned trajectory - using a realistic simulator for\nurban driving. Our study examines generalization to unseen towns, the effect of\ndifferent camera layouts, and two loss formulations (focal and L1). Using\ntraining data from only a town, a four-camera CVT trained with the L1 loss\ndelivers the most robust test performance, evaluated in a new town. Overall,\nour results underscore CVT's promise for mapping camera inputs to reasonably\naccurate BEV maps."}
{"id": "2508.12671", "pdf": "https://arxiv.org/pdf/2508.12671", "abs": "https://arxiv.org/abs/2508.12671", "authors": ["Dmitry Belousov", "Yury Yanovich"], "title": "DIT: Dimension Reduction View on Optimal NFT Rarity Meters", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Non-fungible tokens (NFTs) have become a significant digital asset class,\neach uniquely representing virtual entities such as artworks. These tokens are\nstored in collections within smart contracts and are actively traded across\nplatforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is\nclosely tied to their distinctive characteristics that define rarity, leading\nto a growing interest in quantifying rarity within both industry and academia.\nWhile there are existing rarity meters for assessing NFT rarity, comparing them\ncan be challenging without direct access to the underlying collection data. The\nRating over all Rarities (ROAR) benchmark addresses this challenge by providing\na standardized framework for evaluating NFT rarity. This paper explores a\ndimension reduction approach to rarity design, introducing new performance\nmeasures and meters, and evaluates them using the ROAR benchmark. Our\ncontributions to the rarity meter design issue include developing an optimal\nrarity meter design using non-metric weighted multidimensional scaling,\nintroducing Dissimilarity in Trades (DIT) as a performance measure inspired by\ndimension reduction techniques, and unveiling the non-interpretable rarity\nmeter DIT, which demonstrates superior performance compared to existing\nmethods."}
{"id": "2508.12531", "pdf": "https://arxiv.org/pdf/2508.12531", "abs": "https://arxiv.org/abs/2508.12531", "authors": ["Minseon Kim", "Jin Myung Kwak", "Lama Alssum", "Bernard Ghanem", "Philip Torr", "David Krueger", "Fazl Barez", "Adel Bibi"], "title": "Rethinking Safety in LLM Fine-tuning: An Optimization Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning language models is commonly believed to inevitably harm their\nsafety, i.e., refusing to respond to harmful user requests, even when using\nharmless datasets, thus requiring additional safety measures. We challenge this\nbelief through systematic testing, showing that poor optimization choices,\nrather than inherent trade-offs, often cause safety problems, measured as\nharmful responses to adversarial prompts. By properly selecting key training\nhyper-parameters, e.g., learning rate, batch size, and gradient steps, we\nreduce unsafe model responses from 16\\% to approximately 5\\%, as measured by\nkeyword matching, while maintaining utility performance. Based on this\nobservation, we propose a simple exponential moving average (EMA) momentum\ntechnique in parameter space that preserves safety performance by creating a\nstable optimization path and retains the original pre-trained model's safety\nproperties. Our experiments on the Llama families across multiple datasets\n(Dolly, Alpaca, ORCA) demonstrate that safety problems during fine-tuning can\nlargely be avoided without specialized interventions, outperforming existing\napproaches that require additional safety data while offering practical\nguidelines for maintaining both model performance and safety during adaptation."}
{"id": "2508.12674", "pdf": "https://arxiv.org/pdf/2508.12674", "abs": "https://arxiv.org/abs/2508.12674", "authors": ["Haruka Ezoe", "Hiroki Matsumoto", "Ryohei Hisano"], "title": "Unfolded Laplacian Spectral Embedding: A Theoretically Grounded Approach to Dynamic Network Representation", "categories": ["stat.ML", "cs.LG", "cs.SI"], "comment": null, "summary": "Dynamic relational structures play a central role in many AI tasks, but their\nevolving nature presents challenges for consistent and interpretable\nrepresentation. A common approach is to learn time-varying node embeddings,\nwhose effectiveness depends on satisfying key stability properties. In this\npaper, we propose Unfolded Laplacian Spectral Embedding, a new method that\nextends the Unfolded Adjacency Spectral Embedding framework to normalized\nLaplacians while preserving both cross-sectional and longitudinal stability. We\nprovide formal proof that our method satisfies these stability conditions. In\naddition, as a bonus of using the Laplacian matrix, we establish a new\nCheeger-style inequality that connects the embeddings to the conductance of the\nunderlying dynamic graphs. Empirical evaluations on synthetic and real-world\ndatasets support our theoretical findings and demonstrate the strong\nperformance of our method. These results establish a principled and stable\nframework for dynamic network representation grounded in spectral graph theory."}
{"id": "2508.12533", "pdf": "https://arxiv.org/pdf/2508.12533", "abs": "https://arxiv.org/abs/2508.12533", "authors": ["Qinwen Ge", "Roza G. Bayrak", "Anwar Said", "Catie Chang", "Xenofon Koutsoukos", "Tyler Derr"], "title": "Defining and Benchmarking a Data-Centric Design Space for Brain Graph Construction", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": null, "summary": "The construction of brain graphs from functional Magnetic Resonance Imaging\n(fMRI) data plays a crucial role in enabling graph machine learning for\nneuroimaging. However, current practices often rely on rigid pipelines that\noverlook critical data-centric choices in how brain graphs are constructed. In\nthis work, we adopt a Data-Centric AI perspective and systematically define and\nbenchmark a data-centric design space for brain graph construction,\nconstrasting with primarily model-centric prior work. We organize this design\nspace into three stages: temporal signal processing, topology extraction, and\ngraph featurization. Our contributions lie less in novel components and more in\nevaluating how combinations of existing and modified techniques influence\ndownstream performance. Specifically, we study high-amplitude BOLD signal\nfiltering, sparsification and unification strategies for connectivity,\nalternative correlation metrics, and multi-view node and edge features, such as\nincorporating lagged dynamics. Experiments on the HCP1200 and ABIDE datasets\nshow that thoughtful data-centric configurations consistently improve\nclassification accuracy over standard pipelines. These findings highlight the\ncritical role of upstream data decisions and underscore the importance of\nsystematically exploring the data-centric design space for graph-based\nneuroimaging. Our code is available at\nhttps://github.com/GeQinwen/DataCentricBrainGraphs."}
{"id": "2508.12681", "pdf": "https://arxiv.org/pdf/2508.12681", "abs": "https://arxiv.org/abs/2508.12681", "authors": ["Johann Licher", "Max Bartholdt", "Henrik Krauss", "Tim-Lukas Habich", "Thomas Seel", "Moritz Schappler"], "title": "Adaptive Model-Predictive Control of a Soft Continuum Robot Using a Physics-Informed Neural Network Based on Cosserat Rod Theory", "categories": ["cs.RO", "cs.LG"], "comment": "20 pages, 15 figures", "summary": "Dynamic control of soft continuum robots (SCRs) holds great potential for\nexpanding their applications, but remains a challenging problem due to the high\ncomputational demands of accurate dynamic models. While data-driven approaches\nlike Koopman-operator-based methods have been proposed, they typically lack\nadaptability and cannot capture the full robot shape, limiting their\napplicability. This work introduces a real-time-capable nonlinear\nmodel-predictive control (MPC) framework for SCRs based on a domain-decoupled\nphysics-informed neural network (DD-PINN) with adaptable bending stiffness. The\nDD-PINN serves as a surrogate for the dynamic Cosserat rod model with a\nspeed-up factor of 44000. It is also used within an unscented Kalman filter for\nestimating the model states and bending compliance from end-effector position\nmeasurements. We implement a nonlinear evolutionary MPC running at 70 Hz on the\nGPU. In simulation, it demonstrates accurate tracking of dynamic trajectories\nand setpoint control with end-effector position errors below 3 mm (2.3% of the\nactuator's length). In real-world experiments, the controller achieves similar\naccuracy and accelerations up to 3.55 m/s2."}
{"id": "2508.12535", "pdf": "https://arxiv.org/pdf/2508.12535", "abs": "https://arxiv.org/abs/2508.12535", "authors": ["Seonglae Cho", "Zekun Wu", "Adriano Koshiyama"], "title": "CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "42 pages, 9 tables", "summary": "Sparse Autoencoders (SAEs) can extract interpretable features from large\nlanguage models (LLMs) without supervision. However, their effectiveness in\ndownstream steering tasks is limited by the requirement for contrastive\ndatasets or large activation storage. To address these limitations, we propose\nCorrSteer, which selects features by correlating sample correctness with SAE\nactivations from generated tokens at inference time. This approach uses only\ninference-time activations to extract more relevant features, thereby avoiding\nspurious correlations. It also obtains steering coefficients from average\nactivations, automating the entire pipeline. Our method shows improved task\nperformance on QA, bias mitigation, jailbreaking prevention, and reasoning\nbenchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%\nimprovement in MMLU performance and a +22.9% improvement in HarmBench with only\n4000 samples. Selected features demonstrate semantically meaningful patterns\naligned with each task's requirements, revealing the underlying capabilities\nthat drive performance. Our work establishes correlationbased selection as an\neffective and scalable approach for automated SAE steering across language\nmodel applications."}
{"id": "2508.12685", "pdf": "https://arxiv.org/pdf/2508.12685", "abs": "https://arxiv.org/abs/2508.12685", "authors": ["Xingshan Zeng", "Weiwen Liu", "Lingzhi Wang", "Liangyou Li", "Fei Mi", "Yasheng Wang", "Lifeng Shang", "Xin Jiang", "Qun Liu"], "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Agentic task-solving with Large Language Models (LLMs) requires multi-turn,\nmulti-step interactions, often involving complex function calls and dynamic\nuser-agent exchanges. Existing simulation-based data generation methods for\nsuch scenarios rely heavily on costly autoregressive interactions between\nmultiple LLM agents, thereby limiting real-world performance of agentic tasks.\nIn this paper, we propose a novel Non-Autoregressive Iterative Generation\nframework, called ToolACE-MT, for constructing high-quality multi-turn agentic\ndialogues. ToolACE-MT generates full conversational trajectories through three\nstages: coarse-grained initialization, iterative refinement, and offline\nverification. The initialization phase builds a structurally complete yet\nsemantically coarse dialogue skeleton; the iterative refinement phase\nintroduces realistic complexities and continued refinement via mask-and-fill\noperations; and the offline verification phase ensures correctness and\ncoherence via rule- and model-based checks. Experiments demonstrate that\nToolACE-MT enables efficient, effective and generalizable agentic data\ngeneration, offering a new paradigm for high-quality data construction in\ntool-augmented LLM scenarios."}
{"id": "2508.12538", "pdf": "https://arxiv.org/pdf/2508.12538", "abs": "https://arxiv.org/abs/2508.12538", "authors": ["Yongjian Guo", "Puzhuo Liu", "Wanlun Ma", "Zehang Deng", "Xiaogang Zhu", "Peng Di", "Xi Xiao", "Sheng Wen"], "title": "Systematic Analysis of MCP Security", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": null, "summary": "The Model Context Protocol (MCP) has emerged as a universal standard that\nenables AI agents to seamlessly connect with external tools, significantly\nenhancing their functionality. However, while MCP brings notable benefits, it\nalso introduces significant vulnerabilities, such as Tool Poisoning Attacks\n(TPA), where hidden malicious instructions exploit the sycophancy of large\nlanguage models (LLMs) to manipulate agent behavior. Despite these risks,\ncurrent academic research on MCP security remains limited, with most studies\nfocusing on narrow or qualitative analyses that fail to capture the diversity\nof real-world threats. To address this gap, we present the MCP Attack Library\n(MCPLIB), which categorizes and implements 31 distinct attack methods under\nfour key classifications: direct tool injection, indirect tool injection,\nmalicious user attacks, and LLM inherent attack. We further conduct a\nquantitative analysis of the efficacy of each attack. Our experiments reveal\nkey insights into MCP vulnerabilities, including agents' blind reliance on tool\ndescriptions, sensitivity to file-based attacks, chain attacks exploiting\nshared context, and difficulty distinguishing external data from executable\ncommands. These insights, validated through attack experiments, underscore the\nurgency for robust defense strategies and informed MCP design. Our\ncontributions include 1) constructing a comprehensive MCP attack taxonomy, 2)\nintroducing a unified attack framework MCPLIB, and 3) conducting empirical\nvulnerability analysis to enhance MCP security mechanisms. This work provides a\nfoundational framework, supporting the secure evolution of MCP ecosystems."}
{"id": "2508.12690", "pdf": "https://arxiv.org/pdf/2508.12690", "abs": "https://arxiv.org/abs/2508.12690", "authors": ["Dongjae Jeon", "Taeheon Kim", "Seongwon Cho", "Minhyuk Seo", "Jonghyun Choi"], "title": "TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically\nadapt and perform optimally on shifting target domains. This task is\nparticularly emphasized in real-world driving scenes, where weather domain\nshifts occur frequently. To address such dynamic changes, our proposed method,\nTTA-DAME, leverages source domain data augmentation into target domains.\nAdditionally, we introduce a domain discriminator and a specialized domain\ndetector to mitigate drastic domain shifts, especially from daytime to\nnighttime conditions. To further improve adaptability, we train multiple\ndetectors and consolidate their predictions through Non-Maximum Suppression\n(NMS). Our empirical validation demonstrates the effectiveness of our method,\nshowing significant performance enhancements on the SHIFT Benchmark."}
{"id": "2508.12551", "pdf": "https://arxiv.org/pdf/2508.12551", "abs": "https://arxiv.org/abs/2508.12551", "authors": ["Hongyu Lin", "Yuchen Li", "Haoran Luo", "Kaichun Yao", "Libo Zhang", "Mingjie Xing", "Yanjun Wu"], "title": "OS-R1: Agentic Operating System Kernel Tuning with Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.OS", "cs.SE"], "comment": null, "summary": "Linux kernel tuning is essential for optimizing operating system (OS)\nperformance. However, existing methods often face challenges in terms of\nefficiency, scalability, and generalization. This paper introduces OS-R1, an\nagentic Linux kernel tuning framework powered by rule-based reinforcement\nlearning (RL). By abstracting the kernel configuration space as an RL\nenvironment, OS-R1 facilitates efficient exploration by large language models\n(LLMs) and ensures accurate configuration modifications. Additionally, custom\nreward functions are designed to enhance reasoning standardization,\nconfiguration modification accuracy, and system performance awareness of the\nLLMs. Furthermore, we propose a two-phase training process that accelerates\nconvergence and minimizes retraining across diverse tuning scenarios.\nExperimental results show that OS-R1 significantly outperforms existing\nbaseline methods, achieving up to 5.6% performance improvement over heuristic\ntuning and maintaining high data efficiency. Notably, OS-R1 is adaptable across\nvarious real-world applications, demonstrating its potential for practical\ndeployment in diverse environments. Our dataset and code are publicly available\nat https://github.com/LHY-24/OS-R1."}
{"id": "2508.12691", "pdf": "https://arxiv.org/pdf/2508.12691", "abs": "https://arxiv.org/abs/2508.12691", "authors": ["Yuanxin Wei", "Lansong Diao", "Bujiao Chen", "Shenggan Cheng", "Zhengping Qian", "Wenyuan Yu", "Nong Xiao", "Wei Lin", "Jiangsu Du"], "title": "MixCache: Mixture-of-Cache for Video Diffusion Transformer Acceleration", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "7 pages, 10 figures", "summary": "Leveraging the Transformer architecture and the diffusion process, video DiT\nmodels have emerged as a dominant approach for high-quality video generation.\nHowever, their multi-step iterative denoising process incurs high computational\ncost and inference latency. Caching, a widely adopted optimization method in\nDiT models, leverages the redundancy in the diffusion process to skip\ncomputations in different granularities (e.g., step, cfg, block). Nevertheless,\nexisting caching methods are limited to single-granularity strategies,\nstruggling to balance generation quality and inference speed in a flexible\nmanner. In this work, we propose MixCache, a training-free caching-based\nframework for efficient video DiT inference. It first distinguishes the\ninterference and boundary between different caching strategies, and then\nintroduces a context-aware cache triggering strategy to determine when caching\nshould be enabled, along with an adaptive hybrid cache decision strategy for\ndynamically selecting the optimal caching granularity. Extensive experiments on\ndiverse models demonstrate that, MixCache can significantly accelerate video\ngeneration (e.g., 1.94$\\times$ speedup on Wan 14B, 1.97$\\times$ speedup on\nHunyuanVideo) while delivering both superior generation quality and inference\nefficiency compared to baseline methods."}
{"id": "2508.12575", "pdf": "https://arxiv.org/pdf/2508.12575", "abs": "https://arxiv.org/abs/2508.12575", "authors": ["Zohra Yagoub", "Hafida Bouziane"], "title": "Deep Learning Model for Amyloidogenicity Prediction using a Pre-trained Protein LLM", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "The prediction of amyloidogenicity in peptides and proteins remains a focal\npoint of ongoing bioinformatics. The crucial step in this field is to apply\nadvanced computational methodologies. Many recent approaches to predicting\namyloidogenicity within proteins are highly based on evolutionary motifs and\nthe individual properties of amino acids. It is becoming increasingly evident\nthat the sequence information-based features show high predictive performance.\nConsequently, our study evaluated the contextual features of protein sequences\nobtained from a pretrained protein large language model leveraging\nbidirectional LSTM and GRU to predict amyloidogenic regions in peptide and\nprotein sequences. Our method achieved an accuracy of 84.5% on 10-fold\ncross-validation and an accuracy of 83% in the test dataset. Our results\ndemonstrate competitive performance, highlighting the potential of LLMs in\nenhancing the accuracy of amyloid prediction."}
{"id": "2508.12692", "pdf": "https://arxiv.org/pdf/2508.12692", "abs": "https://arxiv.org/abs/2508.12692", "authors": ["Taeheon Kim", "San Kim", "Minhyuk Seo", "Dongjae Jeon", "Wonje Jeong", "Jonghyun Choi"], "title": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Class-incremental with repetition (CIR), where previously trained classes\nrepeatedly introduced in future tasks, is a more realistic scenario than the\ntraditional class incremental setup, which assumes that each task contains\nunseen classes. CIR assumes that we can easily access abundant unlabeled data\nfrom external sources, such as the Internet. Therefore, we propose two\ncomponents that efficiently use the unlabeled data to ensure the high stability\nand the plasticity of models trained in CIR setup. First, we introduce\nmulti-level knowledge distillation (MLKD) that distills knowledge from multiple\nprevious models across multiple perspectives, including features and logits, so\nthe model can maintain much various previous knowledge. Moreover, we implement\ndynamic self-supervised loss (SSL) to utilize the unlabeled data that\naccelerates the learning of new classes, while dynamic weighting of SSL keeps\nthe focus of training to the primary task. Both of our proposed components\nsignificantly improve the performance in CIR setup, achieving 2nd place in the\nCVPR 5th CLVISION Challenge."}
{"id": "2508.12576", "pdf": "https://arxiv.org/pdf/2508.12576", "abs": "https://arxiv.org/abs/2508.12576", "authors": ["Like Jian", "Dong Liu"], "title": "Widening the Network Mitigates the Impact of Data Heterogeneity on FedAvg", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Federated learning (FL) enables decentralized clients to train a model\ncollaboratively without sharing local data. A key distinction between FL and\ncentralized learning is that clients' data are non-independent and identically\ndistributed, which poses significant challenges in training a global model that\ngeneralizes well across heterogeneous local data distributions. In this paper,\nwe analyze the convergence of overparameterized FedAvg with gradient descent\n(GD). We prove that the impact of data heterogeneity diminishes as the width of\nneural networks increases, ultimately vanishing when the width approaches\ninfinity. In the infinite-width regime, we further prove that both the global\nand local models in FedAvg behave as linear models, and that FedAvg achieves\nthe same generalization performance as centralized learning with the same\nnumber of GD iterations. Extensive experiments validate our theoretical\nfindings across various network architectures, loss functions, and optimization\nmethods."}
{"id": "2508.12730", "pdf": "https://arxiv.org/pdf/2508.12730", "abs": "https://arxiv.org/abs/2508.12730", "authors": ["Jaeung Lee", "Suhyeon Yu", "Yurim Jang", "Simon S. Woo", "Jaemin Jo"], "title": "Unlearning Comparator: A Visual Analytics System for Comparative Evaluation of Machine Unlearning Methods", "categories": ["cs.CR", "cs.HC", "cs.LG", "H.5.2; I.3.6"], "comment": "Submitted to IEEE Transactions on Visualization and Computer Graphics\n  (TVCG), under review. 15 pages. This work has been submitted to the IEEE for\n  possible publication", "summary": "Machine Unlearning (MU) aims to remove target training data from a trained\nmodel so that the removed data no longer influences the model's behavior,\nfulfilling \"right to be forgotten\" obligations under data privacy laws. Yet, we\nobserve that researchers in this rapidly emerging field face challenges in\nanalyzing and understanding the behavior of different MU methods, especially in\nterms of three fundamental principles in MU: accuracy, efficiency, and privacy.\nConsequently, they often rely on aggregate metrics and ad-hoc evaluations,\nmaking it difficult to accurately assess the trade-offs between methods. To\nfill this gap, we introduce a visual analytics system, Unlearning Comparator,\ndesigned to facilitate the systematic evaluation of MU methods. Our system\nsupports two important tasks in the evaluation process: model comparison and\nattack simulation. First, it allows the user to compare the behaviors of two\nmodels, such as a model generated by a certain method and a retrained baseline,\nat class-, instance-, and layer-levels to better understand the changes made\nafter unlearning. Second, our system simulates membership inference attacks\n(MIAs) to evaluate the privacy of a method, where an attacker attempts to\ndetermine whether specific data samples were part of the original training set.\nWe evaluate our system through a case study visually analyzing prominent MU\nmethods and demonstrate that it helps the user not only understand model\nbehaviors but also gain insights that can inform the improvement of MU methods."}
{"id": "2508.12590", "pdf": "https://arxiv.org/pdf/2508.12590", "abs": "https://arxiv.org/abs/2508.12590", "authors": ["Jihoon Park", "Seungeun Oh", "Seong-Lyun Kim"], "title": "Energy-Efficient Wireless LLM Inference via Uncertainty and Importance-Aware Speculative Decoding", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, 5 figures", "summary": "To address the growing demand for on-device LLM inference in\nresource-constrained environments, hybrid language models (HLM) have emerged,\ncombining lightweight local models with powerful cloud-based LLMs. Recent\nstudies on HLM have primarily focused on improving accuracy and latency, while\noften overlooking communication and energy efficiency. We propose a token-level\nfiltering mechanism for an energy-efficient importance- and uncertainty-aware\nHLM inference that leverages both epistemic uncertainty and attention-based\nimportance. Our method opportunistically uploads only informative tokens,\nreducing LLM usage and communication costs. Experiments with TinyLlama-1.1B and\nLLaMA-2-7B demonstrate that our method achieves up to 87.5% BERT Score and\ntoken throughput of 0.37 tokens/sec while saving the energy consumption by\n40.7% compared to standard HLM. Furthermore, compared to our previous U-HLM\nbaseline, our method improves BERTScore from 85.8% to 87.0%, energy savings\nfrom 31.6% to 43.6%, and throughput from 0.36 to 0.40. This approach enables an\nenergy-efficient and accurate deployment of LLMs in bandwidth-constrained edge\nenvironments."}
{"id": "2508.12738", "pdf": "https://arxiv.org/pdf/2508.12738", "abs": "https://arxiv.org/abs/2508.12738", "authors": ["Sebastian Hirt", "Lukas Theiner", "Maik Pfefferkorn", "Rolf Findeisen"], "title": "A Hierarchical Surrogate Model for Efficient Multi-Task Parameter Learning in Closed-Loop Contro", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "8 pages, 4 figures, accepted for CDC 2025", "summary": "Many control problems require repeated tuning and adaptation of controllers\nacross distinct closed-loop tasks, where data efficiency and adaptability are\ncritical. We propose a hierarchical Bayesian optimization (BO) framework that\nis tailored to efficient controller parameter learning in sequential\ndecision-making and control scenarios for distinct tasks. Instead of treating\nthe closed-loop cost as a black-box, our method exploits structural knowledge\nof the underlying problem, consisting of a dynamical system, a control law, and\nan associated closed-loop cost function. We construct a hierarchical surrogate\nmodel using Gaussian processes that capture the closed-loop state evolution\nunder different parameterizations, while the task-specific weighting and\naccumulation into the closed-loop cost are computed exactly via known\nclosed-form expressions. This allows knowledge transfer and enhanced data\nefficiency between different closed-loop tasks. The proposed framework retains\nsublinear regret guarantees on par with standard black-box BO, while enabling\nmulti-task or transfer learning. Simulation experiments with model predictive\ncontrol demonstrate substantial benefits in both sample efficiency and\nadaptability when compared to purely black-box BO approaches."}
{"id": "2508.12591", "pdf": "https://arxiv.org/pdf/2508.12591", "abs": "https://arxiv.org/abs/2508.12591", "authors": ["Yu-Hsuan Fang", "Tien-Hong Lo", "Yao-Ting Sung", "Berlin Chen"], "title": "Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": "Accepted at IEEE ASRU 2025", "summary": "Traditional Automated Speaking Assessment (ASA) systems exhibit inherent\nmodality limitations: text-based approaches lack acoustic information while\naudio-based methods miss semantic context. Multimodal Large Language Models\n(MLLM) offer unprecedented opportunities for comprehensive ASA by\nsimultaneously processing audio and text within unified frameworks. This paper\npresents a very first systematic study of MLLM for comprehensive ASA,\ndemonstrating the superior performance of MLLM across the aspects of content\nand language use . However, assessment on the delivery aspect reveals unique\nchallenges, which is deemed to require specialized training strategies. We thus\npropose Speech-First Multimodal Training (SFMT), leveraging a curriculum\nlearning principle to establish more robust modeling foundations of speech\nbefore cross-modal synergetic fusion. A series of experiments on a benchmark\ndataset show MLLM-based systems can elevate the holistic assessment performance\nfrom a PCC value of 0.783 to 0.846. In particular, SFMT excels in the\nevaluation of the delivery aspect, achieving an absolute accuracy improvement\nof 4% over conventional training approaches, which also paves a new avenue for\nASA."}
{"id": "2508.12742", "pdf": "https://arxiv.org/pdf/2508.12742", "abs": "https://arxiv.org/abs/2508.12742", "authors": ["Theodoros Bermperidis", "Joe Vero", "Elizabeth B Torres"], "title": "On the Importance of Behavioral Nuances: Amplifying Non-Obvious Motor Noise Under True Empirical Considerations May Lead to Briefer Assays and Faster Classification Processes", "categories": ["q-bio.QM", "cs.CV", "cs.LG", "eess.SP", "nlin.CD"], "comment": "This paper is under review in IEEE Transactions on Affective\n  Computing", "summary": "There is a tradeoff between attaining statistical power with large, difficult\nto gather data sets, and producing highly scalable assays that register brief\ndata samples. Often, as grand-averaging techniques a priori assume\nnormally-distributed parameters and linear, stationary processes in\nbiorhythmic, time series data, important information is lost, averaged out as\ngross data. We developed an affective computing platform that enables taking\nbrief data samples while maintaining personalized statistical power. This is\nachieved by combining a new data type derived from the micropeaks present in\ntime series data registered from brief (5-second-long) face videos with recent\nadvances in AI-driven face-grid estimation methods. By adopting geometric and\nnonlinear dynamical systems approaches to analyze the kinematics, especially\nthe speed data, the new methods capture all facial micropeaks. These include as\nwell the nuances of different affective micro expressions. We offer new ways to\ndifferentiate dynamical and geometric patterns present in autistic individuals\nfrom those found more commonly in neurotypical development."}
{"id": "2508.12604", "pdf": "https://arxiv.org/pdf/2508.12604", "abs": "https://arxiv.org/abs/2508.12604", "authors": ["Yuyang Xu", "Yi Cheng", "Haochao Ying", "Zhuoyun Du", "Renjun Hu", "Xing Shi", "Wei Lin", "Jian Wu"], "title": "SSPO: Self-traced Step-wise Preference Optimization for Process Supervision and Reasoning Compression", "categories": ["cs.LG", "cs.AI"], "comment": "Work in progress", "summary": "Test-time scaling has proven effective in further enhancing the performance\nof pretrained Large Language Models (LLMs). However, mainstream post-training\nmethods (i.e., reinforcement learning (RL) with chain-of-thought (CoT)\nreasoning) often incur substantial computational overhead due to auxiliary\nmodels and overthinking. In this paper, we empirically reveal that the\nincorrect answers partially stem from verbose reasoning processes lacking\ncorrect self-fix, where errors accumulate across multiple reasoning steps. To\nthis end, we propose Self-traced Step-wise Preference Optimization (SSPO), a\npluggable RL process supervision framework that enables fine-grained\noptimization of each reasoning step. Specifically, SSPO requires neither\nauxiliary models nor stepwise manual annotations. Instead, it leverages\nstep-wise preference signals generated by the model itself to guide the\noptimization process for reasoning compression. Experiments demonstrate that\nthe generated reasoning sequences from SSPO are both accurate and succinct,\neffectively mitigating overthinking behaviors without compromising model\nperformance across diverse domains and languages."}
{"id": "2508.12748", "pdf": "https://arxiv.org/pdf/2508.12748", "abs": "https://arxiv.org/abs/2508.12748", "authors": ["Chenyang Wang", "Roger Olsson", "Stefan Forsström", "Qing He"], "title": "Deep Semantic Inference over the Air: An Efficient Task-Oriented Communication System", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Empowered by deep learning, semantic communication marks a paradigm shift\nfrom transmitting raw data to conveying task-relevant meaning, enabling more\nefficient and intelligent wireless systems. In this study, we explore a deep\nlearning-based task-oriented communication framework that jointly considers\nclassification performance, computational latency, and communication cost. We\nadopt ResNets-based models and evaluate them on the CIFAR-10 and CIFAR-100\ndatasets to simulate real-world classification tasks in wireless environments.\nWe partition the model at various points to simulate split inference across a\nwireless channel. By varying the split location and the size of the transmitted\nsemantic feature vector, we systematically analyze the trade-offs between task\naccuracy and resource efficiency. Experimental results show that, with\nappropriate model partitioning and semantic feature compression, the system can\nretain over 85\\% of baseline accuracy while significantly reducing both\ncomputational load and communication overhead."}
{"id": "2508.12610", "pdf": "https://arxiv.org/pdf/2508.12610", "abs": "https://arxiv.org/abs/2508.12610", "authors": ["Chen Qian", "Danyang Li", "Xinran Yu", "Zheng Yang", "Qiang Ma"], "title": "OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Optical motion capture is a foundational technology driving advancements in\ncutting-edge fields such as virtual reality and film production. However,\nsystem performance suffers severely under large-scale marker occlusions common\nin real-world applications. An in-depth analysis identifies two primary\nlimitations of current models: (i) the lack of training datasets accurately\nreflecting realistic marker occlusion patterns, and (ii) the absence of\ntraining strategies designed to capture long-range dependencies among markers.\nTo tackle these challenges, we introduce the CMU-Occlu dataset, which\nincorporates ray tracing techniques to realistically simulate practical marker\nocclusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving\nmodel designed specifically for robust motion capture in environments with\nsignificant occlusions. Leveraging a marker-joint chain inference mechanism,\nOpenMoCap enables simultaneous optimization and construction of deep\nconstraints between markers and joints. Extensive comparative experiments\ndemonstrate that OpenMoCap consistently outperforms competing methods across\ndiverse scenarios, while the CMU-Occlu dataset opens the door for future\nstudies in robust motion solving. The proposed OpenMoCap is integrated into the\nMoSen MoCap system for practical deployment. The code is released at:\nhttps://github.com/qianchen214/OpenMoCap."}
{"id": "2508.12790", "pdf": "https://arxiv.org/pdf/2508.12790", "abs": "https://arxiv.org/abs/2508.12790", "authors": ["Zenan Huang", "Yihong Zhuang", "Guoshan Lu", "Zeyu Qin", "Haokai Xu", "Tianyu Zhao", "Ru Peng", "Jiaqi Hu", "Zhanming Shen", "Xiaomeng Hu", "Xijun Gu", "Peiyi Tu", "Jiaxin Liu", "Wenyu Chen", "Yuzhuo Fu", "Zhiting Fan", "Yanmei Gu", "Yuanyuan Wang", "Zhengkai Yang", "Jianguo Li", "Junbo Zhao"], "title": "Reinforcement Learning with Rubric Anchors", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "technical report", "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a\npowerful paradigm for enhancing Large Language Models (LLMs), exemplified by\nthe success of OpenAI's o-series. In RLVR, rewards are derived from verifiable\nsignals-such as passing unit tests in code generation or matching correct\nanswers in mathematical reasoning. While effective, this requirement largely\nconfines RLVR to domains with automatically checkable outcomes. To overcome\nthis, we extend the RLVR paradigm to open-ended tasks by integrating\nrubric-based rewards, where carefully designed rubrics serve as structured,\nmodel-interpretable criteria for automatic scoring of subjective outputs. We\nconstruct, to our knowledge, the largest rubric reward system to date, with\nover 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.\nImplementing rubric-based RL is challenging; we tackle these issues with a\nclear framework and present an open-sourced Qwen-30B-A3B model with notable\ngains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended\nbenchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by\n+2.4%, while preserving general and reasoning abilities. 2) Our method provides\nfine-grained stylistic control, using rubrics as anchors to mitigate the\n\"AI-like\" tone and produce more human-like, expressive responses. We share key\nlessons in rubric construction, data selection, and training, and discuss\nlimitations and future releases."}
{"id": "2508.12617", "pdf": "https://arxiv.org/pdf/2508.12617", "abs": "https://arxiv.org/abs/2508.12617", "authors": ["Ming Li", "Zihuai He", "Min Zhang", "Xiaowei Zhan", "Changshuai Wei", "Robert C Elston", "Qing Lu"], "title": "A Generalized Genetic Random Field Method for the Genetic Association Analysis of Sequencing Data", "categories": ["stat.ME", "cs.AI", "cs.LG"], "comment": null, "summary": "With the advance of high-throughput sequencing technologies, it has become\nfeasible to investigate the influence of the entire spectrum of sequencing\nvariations on complex human diseases. Although association studies utilizing\nthe new sequencing technologies hold great promise to unravel novel genetic\nvariants, especially rare genetic variants that contribute to human diseases,\nthe statistical analysis of high-dimensional sequencing data remains a\nchallenge. Advanced analytical methods are in great need to facilitate\nhigh-dimensional sequencing data analyses. In this article, we propose a\ngeneralized genetic random field (GGRF) method for association analyses of\nsequencing data. Like other similarity-based methods (e.g., SIMreg and SKAT),\nthe new method has the advantages of avoiding the need to specify thresholds\nfor rare variants and allowing for testing multiple variants acting in\ndifferent directions and magnitude of effects. The method is built on the\ngeneralized estimating equation framework and thus accommodates a variety of\ndisease phenotypes (e.g., quantitative and binary phenotypes). Moreover, it has\na nice asymptotic property, and can be applied to small-scale sequencing data\nwithout need for small-sample adjustment. Through simulations, we demonstrate\nthat the proposed GGRF attains an improved or comparable power over a commonly\nused method, SKAT, under various disease scenarios, especially when rare\nvariants play a significant role in disease etiology. We further illustrate\nGGRF with an application to a real dataset from the Dallas Heart Study. By\nusing GGRF, we were able to detect the association of two candidate genes,\nANGPTL3 and ANGPTL4, with serum triglyceride."}
{"id": "2508.12811", "pdf": "https://arxiv.org/pdf/2508.12811", "abs": "https://arxiv.org/abs/2508.12811", "authors": ["Yikai Wang", "Zhouxia Wang", "Zhonghua Wu", "Qingyi Tao", "Kang Liao", "Chen Change Loy"], "title": "Next Visual Granularity Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a novel approach to image generation by decomposing an image into\na structured sequence, where each element in the sequence shares the same\nspatial resolution but differs in the number of unique tokens used, capturing\ndifferent level of visual granularity. Image generation is carried out through\nour newly introduced Next Visual Granularity (NVG) generation framework, which\ngenerates a visual granularity sequence beginning from an empty image and\nprogressively refines it, from global layout to fine details, in a structured\nmanner. This iterative process encodes a hierarchical, layered representation\nthat offers fine-grained control over the generation process across multiple\ngranularity levels. We train a series of NVG models for class-conditional image\ngeneration on the ImageNet dataset and observe clear scaling behavior. Compared\nto the VAR series, NVG consistently outperforms it in terms of FID scores (3.30\n-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to\nshowcase the capability and potential of the NVG framework. Our code and models\nwill be released."}
{"id": "2508.12623", "pdf": "https://arxiv.org/pdf/2508.12623", "abs": "https://arxiv.org/abs/2508.12623", "authors": ["Florian J. Boge", "Annika Schuster"], "title": "How can we trust opaque systems? Criteria for robust explanations in XAI", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 1 figure", "summary": "Deep learning (DL) algorithms are becoming ubiquitous in everyday life and in\nscientific research. However, the price we pay for their impressively accurate\npredictions is significant: their inner workings are notoriously opaque - it is\nunknown to laypeople and researchers alike what features of the data a DL\nsystem focuses on and how it ultimately succeeds in predicting correct outputs.\nA necessary criterion for trustworthy explanations is that they should reflect\nthe relevant processes the algorithms' predictions are based on. The field of\neXplainable Artificial Intelligence (XAI) presents promising methods to create\nsuch explanations. But recent reviews about their performance offer reasons for\nskepticism. As we will argue, a good criterion for trustworthiness is\nexplanatory robustness: different XAI methods produce the same explanations in\ncomparable contexts. However, in some instances, all methods may give the same,\nbut still wrong, explanation. We therefore argue that in addition to\nexplanatory robustness (ER), a prior requirement of explanation method\nrobustness (EMR) has to be fulfilled by every XAI method. Conversely, the\nrobustness of an individual method is in itself insufficient for\ntrustworthiness. In what follows, we develop and formalize criteria for ER as\nwell as EMR, providing a framework for explaining and establishing trust in DL\nalgorithms. We also highlight interesting application cases and outline\ndirections for future work."}
{"id": "2508.12813", "pdf": "https://arxiv.org/pdf/2508.12813", "abs": "https://arxiv.org/abs/2508.12813", "authors": ["Friedhelm Hamann", "Emil Mededovic", "Fabian Gülhan", "Yuli Wu", "Johannes Stegmaier", "Jing He", "Yiqing Wang", "Kexin Zhang", "Lingling Li", "Licheng Jiao", "Mengru Ma", "Hongxiang Huang", "Yuhao Yan", "Hongwei Ren", "Xiaopeng Lin", "Yulong Huang", "Bojun Cheng", "Se Hyun Lee", "Gyu Sung Ham", "Kanghan Oh", "Gi Hyun Lim", "Boxuan Yang", "Bowen Du", "Guillermo Gallego"], "title": "SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop", "categories": ["cs.CV", "cs.LG"], "comment": "13 pages, 7 figures, 7 tables", "summary": "We present an overview of the Spatio-temporal Instance Segmentation (SIS)\nchallenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.\nThe task is to predict accurate pixel-level segmentation masks of defined\nobject classes from spatio-temporally aligned event camera and grayscale camera\ndata. We provide an overview of the task, dataset, challenge details and\nresults. Furthermore, we describe the methods used by the top-5 ranking teams\nin the challenge. More resources and code of the participants' methods are\navailable here:\nhttps://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md"}
{"id": "2508.12638", "pdf": "https://arxiv.org/pdf/2508.12638", "abs": "https://arxiv.org/abs/2508.12638", "authors": ["Chen Qian", "Xinran Yu", "Zewen Huang", "Danyang Li", "Qiang Ma", "Fan Dang", "Xuan Ding", "Guangyong Shang", "Zheng Yang"], "title": "SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) are increasingly deployed in real-time\napplications such as autonomous driving and human-computer interaction, which\ndemand fast and reliable responses based on accurate perception. To meet these\nrequirements, existing systems commonly employ cloud-edge collaborative\narchitectures, such as partitioned Large Vision-Language Models (LVLMs) or task\noffloading strategies between Large and Small Vision-Language Models (SVLMs).\nHowever, these methods fail to accommodate cloud latency fluctuations and\noverlook the full potential of delayed but accurate LVLM responses. In this\nwork, we propose a novel cloud-edge collaborative paradigm for VLMs, termed\nContext Transfer, which treats the delayed outputs of LVLMs as historical\ncontext to provide real-time guidance for SVLMs inference. Based on this\nparadigm, we design SpotVLM, which incorporates both context replacement and\nvisual focus modules to refine historical textual input and enhance visual\ngrounding consistency. Extensive experiments on three real-time vision tasks\nacross four datasets demonstrate the effectiveness of the proposed framework.\nThe new paradigm lays the groundwork for more effective and latency-aware\ncollaboration strategies in future VLM systems."}
{"id": "2508.12832", "pdf": "https://arxiv.org/pdf/2508.12832", "abs": "https://arxiv.org/abs/2508.12832", "authors": ["Jinyu Lu", "Xinrong Sun", "Yunting Tao", "Tong Ji", "Fanyu Kong", "Guoqiang Yang"], "title": "Efficient and Verifiable Privacy-Preserving Convolutional Computation for CNN Inference with Untrusted Clouds", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The widespread adoption of convolutional neural networks (CNNs) in\nresource-constrained scenarios has driven the development of Machine Learning\nas a Service (MLaaS) system. However, this approach is susceptible to privacy\nleakage, as the data sent from the client to the untrusted cloud server often\ncontains sensitive information. Existing CNN privacy-preserving schemes, while\neffective in ensuring data confidentiality through homomorphic encryption and\nsecret sharing, face efficiency bottlenecks, particularly in convolution\noperations. In this paper, we propose a novel verifiable privacy-preserving\nscheme tailored for CNN convolutional layers. Our scheme enables efficient\nencryption and decryption, allowing resource-constrained clients to securely\noffload computations to the untrusted cloud server. Additionally, we present a\nverification mechanism capable of detecting the correctness of the results with\na success probability of at least $1-\\frac{1}{\\left|Z\\right|}$. Extensive\nexperiments conducted on 10 datasets and various CNN models demonstrate that\nour scheme achieves speedups ranging $26 \\times$ ~ $\\ 87\\times$ compared to the\noriginal plaintext model while maintaining accuracy."}
{"id": "2508.12650", "pdf": "https://arxiv.org/pdf/2508.12650", "abs": "https://arxiv.org/abs/2508.12650", "authors": ["Jiyeon Kang", "Songseong Kim", "Chanhui Lee", "Doyeong Hwang", "Joanie Hayoun Chung", "Yunkyung Ko", "Sumin Lee", "Sungwoong Kim", "Sungbin Lim"], "title": "Score-informed Neural Operator for Enhancing Ordering-based Causal Discovery", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.8"], "comment": "32 pages, 17 figures, 5 tables", "summary": "Ordering-based approaches to causal discovery identify topological orders of\ncausal graphs, providing scalable alternatives to combinatorial search methods.\nUnder the Additive Noise Model (ANM) assumption, recent causal ordering methods\nbased on score matching require an accurate estimation of the Hessian diagonal\nof the log-densities. However, previous approaches mainly use Stein gradient\nestimators, which are computationally expensive and memory-intensive. Although\nDiffAN addresses these limitations by substituting kernel-based estimates with\ndiffusion models, it remains numerically unstable due to the second-order\nderivatives of score models. To alleviate these problems, we propose\nScore-informed Neural Operator (SciNO), a probabilistic generative model in\nsmooth function spaces designed to stably approximate the Hessian diagonal and\nto preserve structural information during the score modeling. Empirical results\nshow that SciNO reduces order divergence by 42.7% on synthetic graphs and by\n31.5% on real-world datasets on average compared to DiffAN, while maintaining\nmemory efficiency and scalability. Furthermore, we propose a probabilistic\ncontrol algorithm for causal reasoning with autoregressive models that\nintegrates SciNO's probability estimates with autoregressive model priors,\nenabling reliable data-driven causal ordering informed by semantic information.\nConsequently, the proposed method enhances causal reasoning abilities of LLMs\nwithout additional fine-tuning or prompt engineering."}
{"id": "2508.12834", "pdf": "https://arxiv.org/pdf/2508.12834", "abs": "https://arxiv.org/abs/2508.12834", "authors": ["Hiroshi Horii", "Sothea Has"], "title": "Optimal Condition for Initialization Variance in Deep Neural Networks: An SGD Dynamics Perspective", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Stochastic gradient descent (SGD), one of the most fundamental optimization\nalgorithms in machine learning (ML), can be recast through a continuous-time\napproximation as a Fokker-Planck equation for Langevin dynamics, a viewpoint\nthat has motivated many theoretical studies. Within this framework, we study\nthe relationship between the quasi-stationary distribution derived from this\nequation and the initial distribution through the Kullback-Leibler (KL)\ndivergence. As the quasi-steady-state distribution depends on the expected cost\nfunction, the KL divergence eventually reveals the connection between the\nexpected cost function and the initialization distribution. By applying this to\ndeep neural network models (DNNs), we can express the bounds of the expected\nloss function explicitly in terms of the initialization parameters. Then, by\nminimizing this bound, we obtain an optimal condition of the initialization\nvariance in the Gaussian case. This result provides a concrete mathematical\ncriterion, rather than a heuristic approach, to select the scale of weight\ninitialization in DNNs. In addition, we experimentally confirm our theoretical\nresults by using the classical SGD to train fully connected neural networks on\nthe MNIST and Fashion-MNIST datasets. The result shows that if the variance of\nthe initialization distribution satisfies our theoretical optimal condition,\nthen the corresponding DNN model always achieves lower final training loss and\nhigher test accuracy than the conventional He-normal initialization. Our work\nthus supplies a mathematically grounded indicator that guides the choice of\ninitialization variance and clarifies its physical meaning of the dynamics of\nparameters in DNNs."}
{"id": "2508.12662", "pdf": "https://arxiv.org/pdf/2508.12662", "abs": "https://arxiv.org/abs/2508.12662", "authors": ["Tanay Nagar", "Grigorii Khvatskii", "Anna Sokol", "Nitesh V. Chawla"], "title": "Breaking Language Barriers: Equitable Performance in Multilingual Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted as a non-archival work-in-progress paper at the NAACL 2025\n  Student Research Workshop", "summary": "Cutting-edge LLMs have emerged as powerful tools for multilingual\ncommunication and understanding. However, LLMs perform worse in Common Sense\nReasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi\nor Swahili compared to high-resource languages (HRLs) like English. Equalizing\nthis inconsistent access to quality LLM outputs is crucial to ensure fairness\nfor speakers of LRLs and across diverse linguistic communities. In this paper,\nwe propose an approach to bridge this gap in LLM performance. Our approach\ninvolves fine-tuning an LLM on synthetic code-switched text generated using\ncontrolled language-mixing methods. We empirically demonstrate that fine-tuning\nLLMs on synthetic code-switched datasets leads to substantial improvements in\nLRL model performance while preserving or enhancing performance in HRLs.\nAdditionally, we present a new dataset of synthetic code-switched text derived\nfrom the CommonSenseQA dataset, featuring three distinct language ratio\nconfigurations."}
{"id": "2508.12845", "pdf": "https://arxiv.org/pdf/2508.12845", "abs": "https://arxiv.org/abs/2508.12845", "authors": ["Artem Pshenitsyn", "Aleksandr Panov", "Alexey Skrynnik"], "title": "CAMAR: Continuous Actions Multi-Agent Routing", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving\ncooperative and competitive decision-making problems. While many MARL\nbenchmarks have been proposed, few combine continuous state and action spaces\nwith challenging coordination and planning tasks. We introduce CAMAR, a new\nMARL benchmark designed explicitly for multi-agent pathfinding in environments\nwith continuous actions. CAMAR supports cooperative and competitive\ninteractions between agents and runs efficiently at up to 100,000 environment\nsteps per second. We also propose a three-tier evaluation protocol to better\ntrack algorithmic progress and enable deeper analysis of performance. In\naddition, CAMAR allows the integration of classical planning methods such as\nRRT and RRT* into MARL pipelines. We use them as standalone baselines and\ncombine RRT* with popular MARL algorithms to create hybrid approaches. We\nprovide a suite of test scenarios and benchmarking tools to ensure\nreproducibility and fair comparison. Experiments show that CAMAR presents a\nchallenging and realistic testbed for the MARL community."}
{"id": "2508.12672", "pdf": "https://arxiv.org/pdf/2508.12672", "abs": "https://arxiv.org/abs/2508.12672", "authors": ["Emmanouil Kritharakis", "Dusan Jakovetic", "Antonios Makris", "Konstantinos Tserpes"], "title": "Robust Federated Learning under Adversarial Attacks via Loss-Based Client Clustering", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 5 figures", "summary": "Federated Learning (FL) enables collaborative model training across multiple\nclients without sharing private data. We consider FL scenarios wherein FL\nclients are subject to adversarial (Byzantine) attacks, while the FL server is\ntrusted (honest) and has a trustworthy side dataset. This may correspond to,\ne.g., cases where the server possesses trusted data prior to federation, or to\nthe presence of a trusted client that temporarily assumes the server role. Our\napproach requires only two honest participants, i.e., the server and one\nclient, to function effectively, without prior knowledge of the number of\nmalicious clients. Theoretical analysis demonstrates bounded optimality gaps\neven under strong Byzantine attacks. Experimental results show that our\nalgorithm significantly outperforms standard and robust FL baselines such as\nMean, Trimmed Mean, Median, Krum, and Multi-Krum under various attack\nstrategies including label flipping, sign flipping, and Gaussian noise addition\nacross MNIST, FMNIST, and CIFAR-10 benchmarks using the Flower framework."}
{"id": "2508.12930", "pdf": "https://arxiv.org/pdf/2508.12930", "abs": "https://arxiv.org/abs/2508.12930", "authors": ["David Hirnschall", "Robert Bajons"], "title": "The path to a goal: Understanding soccer possessions via path signatures", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a novel framework for predicting next actions in soccer\npossessions by leveraging path signatures to encode their complex\nspatio-temporal structure. Unlike existing approaches, we do not rely on fixed\nhistorical windows and handcrafted features, but rather encode the entire\nrecent possession, thereby avoiding the inclusion of potentially irrelevant or\nmisleading historical information. Path signatures naturally capture the order\nand interaction of events, providing a mathematically grounded feature encoding\nfor variable-length time series of irregular sampling frequencies without the\nnecessity for manual feature engineering. Our proposed approach outperforms a\ntransformer-based benchmark across various loss metrics and considerably\nreduces computational cost. Building on these results, we introduce a new\npossession evaluation metric based on well-established frameworks in soccer\nanalytics, incorporating both predicted action type probabilities and action\nlocation. Our metric shows greater reliability than existing metrics in\ndomain-specific comparisons. Finally, we validate our approach through a\ndetailed analysis of the 2017/18 Premier League season and discuss further\napplications and future extensions."}
{"id": "2508.12673", "pdf": "https://arxiv.org/pdf/2508.12673", "abs": "https://arxiv.org/abs/2508.12673", "authors": ["Yuhao Zhou", "Jindi Lv", "Yuxin Tian", "Dan Si", "Qing Ye", "Jiancheng Lv"], "title": "Deploying Models to Non-participating Clients in Federated Learning without Fine-tuning: A Hypernetwork-based Approach", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages", "summary": "Federated Learning (FL) has emerged as a promising paradigm for\nprivacy-preserving collaborative learning, yet data heterogeneity remains a\ncritical challenge. While existing methods achieve progress in addressing data\nheterogeneity for participating clients, they fail to generalize to\nnon-participating clients with in-domain distribution shifts and resource\nconstraints. To mitigate this issue, we present HyperFedZero, a novel method\nthat dynamically generates specialized models via a hypernetwork conditioned on\ndistribution-aware embeddings. Our approach explicitly incorporates\ndistribution-aware inductive biases into the model's forward pass, extracting\nrobust distribution embeddings using a NoisyEmbed-enhanced extractor with a\nBalancing Penalty, effectively preventing feature collapse. The hypernetwork\nthen leverages these embeddings to generate specialized models chunk-by-chunk\nfor non-participating clients, ensuring adaptability to their unique data\ndistributions. Extensive experiments on multiple datasets and models\ndemonstrate HyperFedZero's remarkable performance, surpassing competing methods\nconsistently with minimal computational, storage, and communication overhead.\nMoreover, ablation studies and visualizations further validate the necessity of\neach component, confirming meaningful adaptations and validating the\neffectiveness of HyperFedZero."}
{"id": "2508.12939", "pdf": "https://arxiv.org/pdf/2508.12939", "abs": "https://arxiv.org/abs/2508.12939", "authors": ["Michael Deistler", "Jan Boelts", "Peter Steinbach", "Guy Moss", "Thomas Moreau", "Manuel Gloeckler", "Pedro L. C. Rodrigues", "Julia Linhart", "Janne K. Lappalainen", "Benjamin Kurt Miller", "Pedro J. Gonçalves", "Jan-Matthis Lueckmann", "Cornelius Schröder", "Jakob H. Macke"], "title": "Simulation-Based Inference: A Practical Guide", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A central challenge in many areas of science and engineering is to identify\nmodel parameters that are consistent with prior knowledge and empirical data.\nBayesian inference offers a principled framework for this task, but can be\ncomputationally prohibitive when models are defined by stochastic simulators.\nSimulation-based Inference (SBI) is a suite of methods developed to overcome\nthis limitation, which has enabled scientific discoveries in fields such as\nparticle physics, astrophysics, and neuroscience. The core idea of SBI is to\ntrain neural networks on data generated by a simulator, without requiring\naccess to likelihood evaluations. Once trained, inference is amortized: The\nneural network can rapidly perform Bayesian inference on empirical observations\nwithout requiring additional training or simulations. In this tutorial, we\nprovide a practical guide for practitioners aiming to apply SBI methods. We\noutline a structured SBI workflow and offer practical guidelines and diagnostic\ntools for every stage of the process -- from setting up the simulator and\nprior, choosing and training inference networks, to performing inference and\nvalidating the results. We illustrate these steps through examples from\nastrophysics, psychophysics, and neuroscience. This tutorial empowers\nresearchers to apply state-of-the-art SBI methods, facilitating efficient\nparameter inference for scientific discovery."}
{"id": "2508.12683", "pdf": "https://arxiv.org/pdf/2508.12683", "abs": "https://arxiv.org/abs/2508.12683", "authors": ["David J. Moore"], "title": "A Taxonomy of Hierarchical Multi-Agent Systems: Design Patterns, Coordination Mechanisms, and Industrial Applications", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Hierarchical multi-agent systems (HMAS) organize collections of agents into\nlayered structures that help manage complexity and scale. These hierarchies can\nsimplify coordination, but they also can introduce trade-offs that are not\nalways obvious. This paper proposes a multi-dimensional taxonomy for HMAS along\nfive axes: control hierarchy, information flow, role and task delegation,\ntemporal layering, and communication structure. The intent is not to prescribe\na single \"best\" design but to provide a lens for comparing different\napproaches.\n  Rather than treating these dimensions in isolation, the taxonomy is connected\nto concrete coordination mechanisms - from the long-standing contract-net\nprotocol for task allocation to more recent work in hierarchical reinforcement\nlearning. Industrial contexts illustrate the framework, including power grids\nand oilfield operations, where agents at production, maintenance, and supply\nlevels coordinate to diagnose well issues or balance energy demand. These cases\nsuggest that hierarchical structures may achieve global efficiency while\npreserving local autonomy, though the balance is delicate.\n  The paper closes by identifying open challenges: making hierarchical\ndecisions explainable to human operators, scaling to very large agent\npopulations, and assessing whether learning-based agents such as large language\nmodels can be safely integrated into layered frameworks. This paper presents\nwhat appears to be the first taxonomy that unifies structural, temporal, and\ncommunication dimensions of hierarchical MAS into a single design framework,\nbridging classical coordination mechanisms with modern reinforcement learning\nand large language model agents."}
{"id": "2508.12942", "pdf": "https://arxiv.org/pdf/2508.12942", "abs": "https://arxiv.org/abs/2508.12942", "authors": ["Kyriaki-Margarita Bintsi", "Yaël Balbastre", "Jingjing Wu", "Julia F. Lehman", "Suzanne N. Haber", "Anastasia Yendiki"], "title": "Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at CDMRI, MICCAI 2025", "summary": "Anatomic tracer studies are critical for validating and improving diffusion\nMRI (dMRI) tractography. However, large-scale analysis of data from such\nstudies is hampered by the labor-intensive process of annotating fiber bundles\nmanually on histological slides. Existing automated methods often miss sparse\nbundles or require complex post-processing across consecutive sections,\nlimiting their flexibility and generalizability. We present a streamlined,\nfully automated framework for fiber bundle segmentation in macaque tracer data,\nbased on a U-Net architecture with large patch sizes, foreground aware\nsampling, and semisupervised pre-training. Our approach eliminates common\nerrors such as mislabeling terminals as bundles, improves detection of sparse\nbundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared\nto the state-of-the-art, all while enabling analysis of standalone slices. This\nnew framework will facilitate the automated analysis of anatomic tracing data\nat a large scale, generating more ground-truth data that can be used to\nvalidate and optimize dMRI tractography methods."}
{"id": "2508.12685", "pdf": "https://arxiv.org/pdf/2508.12685", "abs": "https://arxiv.org/abs/2508.12685", "authors": ["Xingshan Zeng", "Weiwen Liu", "Lingzhi Wang", "Liangyou Li", "Fei Mi", "Yasheng Wang", "Lifeng Shang", "Xin Jiang", "Qun Liu"], "title": "ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Agentic task-solving with Large Language Models (LLMs) requires multi-turn,\nmulti-step interactions, often involving complex function calls and dynamic\nuser-agent exchanges. Existing simulation-based data generation methods for\nsuch scenarios rely heavily on costly autoregressive interactions between\nmultiple LLM agents, thereby limiting real-world performance of agentic tasks.\nIn this paper, we propose a novel Non-Autoregressive Iterative Generation\nframework, called ToolACE-MT, for constructing high-quality multi-turn agentic\ndialogues. ToolACE-MT generates full conversational trajectories through three\nstages: coarse-grained initialization, iterative refinement, and offline\nverification. The initialization phase builds a structurally complete yet\nsemantically coarse dialogue skeleton; the iterative refinement phase\nintroduces realistic complexities and continued refinement via mask-and-fill\noperations; and the offline verification phase ensures correctness and\ncoherence via rule- and model-based checks. Experiments demonstrate that\nToolACE-MT enables efficient, effective and generalizable agentic data\ngeneration, offering a new paradigm for high-quality data construction in\ntool-augmented LLM scenarios."}
{"id": "2508.12943", "pdf": "https://arxiv.org/pdf/2508.12943", "abs": "https://arxiv.org/abs/2508.12943", "authors": ["Mary Tonwe"], "title": "OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "Source code and data available at:\n  https://github.com/marytonwe/OPTIC-ER.git", "summary": "Public service systems in many African regions suffer from delayed emergency\nresponse and spatial inequity, causing avoidable suffering. This paper\nintroduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,\nadaptive, and equitable emergency response. OPTIC-ER uses an attention-guided\nactor-critic architecture to manage the complexity of dispatch environments.\nIts key innovations are a Context-Rich State Vector, encoding action\nsub-optimality, and a Precision Reward Function, which penalizes inefficiency.\nTraining occurs in a high-fidelity simulation using real data from Rivers\nState, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is\nbuilt on the TALS framework (Thin computing, Adaptability, Low-cost,\nScalability) for deployment in low-resource settings. In evaluations on 500\nunseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible\ninefficiency, confirming its robustness and generalization. Beyond dispatch,\nthe system generates Infrastructure Deficiency Maps and Equity Monitoring\nDashboards to guide proactive governance and data-informed development. This\nwork presents a validated blueprint for AI-augmented public services, showing\nhow context-aware RL can bridge the gap between algorithmic decision-making and\nmeasurable human impact."}
{"id": "2508.12690", "pdf": "https://arxiv.org/pdf/2508.12690", "abs": "https://arxiv.org/abs/2508.12690", "authors": ["Dongjae Jeon", "Taeheon Kim", "Seongwon Cho", "Minhyuk Seo", "Jonghyun Choi"], "title": "TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically\nadapt and perform optimally on shifting target domains. This task is\nparticularly emphasized in real-world driving scenes, where weather domain\nshifts occur frequently. To address such dynamic changes, our proposed method,\nTTA-DAME, leverages source domain data augmentation into target domains.\nAdditionally, we introduce a domain discriminator and a specialized domain\ndetector to mitigate drastic domain shifts, especially from daytime to\nnighttime conditions. To further improve adaptability, we train multiple\ndetectors and consolidate their predictions through Non-Maximum Suppression\n(NMS). Our empirical validation demonstrates the effectiveness of our method,\nshowing significant performance enhancements on the SHIFT Benchmark."}
{"id": "2508.12947", "pdf": "https://arxiv.org/pdf/2508.12947", "abs": "https://arxiv.org/abs/2508.12947", "authors": ["Michael Mayer", "Mario V. Wüthrich"], "title": "Shapley Values: Paired-Sampling Approximations", "categories": ["stat.ML", "cs.CE", "cs.LG"], "comment": null, "summary": "Originally introduced in cooperative game theory, Shapley values have become\na very popular tool to explain machine learning predictions. Based on Shapley's\nfairness axioms, every input (feature component) gets a credit how it\ncontributes to an output (prediction). These credits are then used to explain\nthe prediction. The only limitation in computing the Shapley values (credits)\nfor many different predictions is of computational nature. There are two\npopular sampling approximations, sampling KernelSHAP and sampling\nPermutationSHAP. Our first novel contributions are asymptotic normality results\nfor these sampling approximations. Next, we show that the paired-sampling\napproaches provide exact results in case of interactions being of maximal order\ntwo. Furthermore, the paired-sampling PermutationSHAP possesses the additive\nrecovery property, whereas its kernel counterpart does not."}
{"id": "2508.12692", "pdf": "https://arxiv.org/pdf/2508.12692", "abs": "https://arxiv.org/abs/2508.12692", "authors": ["Taeheon Kim", "San Kim", "Minhyuk Seo", "Dongjae Jeon", "Wonje Jeong", "Jonghyun Choi"], "title": "Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Class-incremental with repetition (CIR), where previously trained classes\nrepeatedly introduced in future tasks, is a more realistic scenario than the\ntraditional class incremental setup, which assumes that each task contains\nunseen classes. CIR assumes that we can easily access abundant unlabeled data\nfrom external sources, such as the Internet. Therefore, we propose two\ncomponents that efficiently use the unlabeled data to ensure the high stability\nand the plasticity of models trained in CIR setup. First, we introduce\nmulti-level knowledge distillation (MLKD) that distills knowledge from multiple\nprevious models across multiple perspectives, including features and logits, so\nthe model can maintain much various previous knowledge. Moreover, we implement\ndynamic self-supervised loss (SSL) to utilize the unlabeled data that\naccelerates the learning of new classes, while dynamic weighting of SSL keeps\nthe focus of training to the primary task. Both of our proposed components\nsignificantly improve the performance in CIR setup, achieving 2nd place in the\nCVPR 5th CLVISION Challenge."}
{"id": "2508.12968", "pdf": "https://arxiv.org/pdf/2508.12968", "abs": "https://arxiv.org/abs/2508.12968", "authors": ["Branislav Gerazov", "Marcello Politi", "Sébastien Bratières"], "title": "Arabic ASR on the SADA Large-Scale Arabic Speech Corpus with Transformer-Based Models", "categories": ["eess.AS", "cs.LG"], "comment": null, "summary": "We explore the performance of several state-of-the-art automatic speech\nrecognition (ASR) models on a large-scale Arabic speech dataset, the SADA\n(Saudi Audio Dataset for Arabic), which contains 668 hours of high-quality\naudio from Saudi television shows. The dataset includes multiple dialects and\nenvironments, specifically a noisy subset that makes it particularly\nchallenging for ASR. We evaluate the performance of the models on the SADA test\nset, and we explore the impact of fine-tuning, language models, as well as\nnoise and denoising on their performance. We find that the best performing\nmodel is the MMS 1B model finetuned on SADA with a 4-gram language model that\nachieves a WER of 40.9\\% and a CER of 17.6\\% on the SADA test clean set."}
{"id": "2508.12702", "pdf": "https://arxiv.org/pdf/2508.12702", "abs": "https://arxiv.org/abs/2508.12702", "authors": ["Jie Su", "Weiwei Wang", "Zhaotian Gu", "Dahui Wang", "Tianyi Qian"], "title": "A Unified Cortical Circuit Model with Divisive Normalization and Self-Excitation for Robust Representation and Memory Maintenance", "categories": ["q-bio.NC", "cs.AI", "cs.NE"], "comment": "15 pages, 4 figures", "summary": "Robust information representation and its persistent maintenance are\nfundamental for higher cognitive functions. Existing models employ distinct\nneural mechanisms to separately address noise-resistant processing or\ninformation maintenance, yet a unified framework integrating both operations\nremains elusive -- a critical gap in understanding cortical computation. Here,\nwe introduce a recurrent neural circuit that combines divisive normalization\nwith self-excitation to achieve both robust encoding and stable retention of\nnormalized inputs. Mathematical analysis shows that, for suitable parameter\nregimes, the system forms a continuous attractor with two key properties: (1)\ninput-proportional stabilization during stimulus presentation; and (2)\nself-sustained memory states persisting after stimulus offset. We demonstrate\nthe model's versatility in two canonical tasks: (a) noise-robust encoding in a\nrandom-dot kinematogram (RDK) paradigm; and (b) approximate Bayesian belief\nupdating in a probabilistic Wisconsin Card Sorting Test (pWCST). This work\nestablishes a unified mathematical framework that bridges noise suppression,\nworking memory, and approximate Bayesian inference within a single cortical\nmicrocircuit, offering fresh insights into the brain's canonical computation\nand guiding the design of biologically plausible artificial neural\narchitectures."}
{"id": "2508.12987", "pdf": "https://arxiv.org/pdf/2508.12987", "abs": "https://arxiv.org/abs/2508.12987", "authors": ["Jose L. Bonilla", "Krzysztof M. Graczyk", "Artur M. Ankowski", "Rwik Dharmapal Banerjee", "Beata E. Kowal", "Hemant Prasad", "Jan T. Sobczyk"], "title": "Transfer Learning for Neutrino Scattering: Domain Adaptation with GANs", "categories": ["hep-ph", "cs.LG", "hep-ex", "nucl-ex", "physics.comp-ph"], "comment": "17 pages, 17 figures", "summary": "We utilize transfer learning to extrapolate the physics knowledge encoded in\na Generative Adversarial Network (GAN) model trained on synthetic\ncharged-current (CC) neutrino-carbon inclusive scattering data. This base model\nis adapted to generate CC inclusive scattering events (lepton kinematics only)\nfor neutrino-argon and antineutrino-carbon interactions. Furthermore, we assess\nthe effectiveness of transfer learning in re-optimizing a custom model when new\ndata comes from a different neutrino-nucleus interaction model. Our results\ndemonstrate that transfer learning significantly outperforms training\ngenerative models from scratch. To study this, we consider two training data\nsets: one with 10,000 and another with 100,000 events. The models obtained via\ntransfer learning perform well even with smaller training data. The proposed\nmethod provides a promising approach for constructing neutrino scattering event\ngenerators in scenarios where experimental data is sparse."}
{"id": "2508.12706", "pdf": "https://arxiv.org/pdf/2508.12706", "abs": "https://arxiv.org/abs/2508.12706", "authors": ["Yongchun Zhu", "Guanyu Jiang", "Jingwu Chen", "Feng Zhang", "Xiao Yang", "Zuotao Liu"], "title": "Asymmetric Diffusion Recommendation Model", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted by CIKM2025", "summary": "Recently, motivated by the outstanding achievements of diffusion models, the\ndiffusion process has been employed to strengthen representation learning in\nrecommendation systems. Most diffusion-based recommendation models typically\nutilize standard Gaussian noise in symmetric forward and reverse processes in\ncontinuous data space. Nevertheless, the samples derived from recommendation\nsystems inhabit a discrete data space, which is fundamentally different from\nthe continuous one. Moreover, Gaussian noise has the potential to corrupt\npersonalized information within latent representations. In this work, we\npropose a novel and effective method, named Asymmetric Diffusion Recommendation\nModel (AsymDiffRec), which learns forward and reverse processes in an\nasymmetric manner. We define a generalized forward process that simulates the\nmissing features in real-world recommendation samples. The reverse process is\nthen performed in an asymmetric latent feature space. To preserve personalized\ninformation within the latent representation, a task-oriented optimization\nstrategy is introduced. In the serving stage, the raw sample with missing\nfeatures is regarded as a noisy input to generate a denoising and robust\nrepresentation for the final prediction. By equipping base models with\nAsymDiffRec, we conduct online A/B tests, achieving improvements of +0.131% and\n+0.166% in terms of users' active days and app usage duration respectively.\nAdditionally, the extended offline experiments also demonstrate improvements.\nAsymDiffRec has been implemented in the Douyin Music App."}
{"id": "2508.13005", "pdf": "https://arxiv.org/pdf/2508.13005", "abs": "https://arxiv.org/abs/2508.13005", "authors": ["Jiawen Xu", "Odej Kao"], "title": "Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Open set recognition (OSR) and continual learning are two critical challenges\nin machine learning, focusing respectively on detecting novel classes at\ninference time and updating models to incorporate the new classes. While many\nrecent approaches have addressed these problems, particularly OSR, by\nheuristically promoting feature diversity, few studies have directly examined\nthe role that feature diversity plays in tackling them. In this work, we\nprovide empirical evidence that enhancing feature diversity improves the\nrecognition of open set samples. Moreover, increased feature diversity also\nfacilitates both the retention of previously learned data and the integration\nof new data in continual learning. We hope our findings can inspire further\nresearch into both practical methods and theoretical understanding in these\ndomains."}
{"id": "2508.12709", "pdf": "https://arxiv.org/pdf/2508.12709", "abs": "https://arxiv.org/abs/2508.12709", "authors": ["Aurian Quelennec", "Pierre Chouteau", "Geoffroy Peeters", "Slim Essid"], "title": "MATPAC++: Enhanced Masked Latent Prediction for Self-Supervised Audio Representation Learning", "categories": ["cs.SD", "cs.AI"], "comment": "Under review", "summary": "Masked latent prediction has emerged as a leading paradigm in self-supervised\nlearning (SSL), especially for general audio and music representation learning.\nWhile recent methods have demonstrated strong performance, the role of the\npredictor module used at the output of such SSL systems remains mainly\noverlooked, despite being crucial for solving the pretext task at hand. In\nparticular, this module should be able to deal with the ambiguity inherent in\naudio content, especially when it is composed of multiple sound sources. This\nwork proposes a novel enhancement: integrating Multiple Choice Learning (MCL)\nto explicitly model prediction ambiguity and improve representation quality. We\nbuild on top of the recently proposed MATPAC system, improving its prediction\nand unsupervised classification pretext tasks with MCL. We extensively evaluate\nour method, MATPAC++, through both linear probing across multiple downstream\ntasks and fine-tuning on AudioSet, employing a unified protocol that enables\nrigorous and fair comparisons with state-of-the-art SSL approaches. Results\nshow that our proposal achieves state-of-the-art when fine-tuned on AudioSet\nand overall state-of-the-art scores on downstream tasks. Additionally, we\nexamine domain specialisation by training exclusively on music data, where our\nmodel achieves state-of-the-art performance with significantly improved\nefficiency."}
{"id": "2508.13064", "pdf": "https://arxiv.org/pdf/2508.13064", "abs": "https://arxiv.org/abs/2508.13064", "authors": ["Seongeun Ryu", "Yunyong Ko", "Sang-Wook Kim"], "title": "Is This News Still Interesting to You?: Lifetime-aware Interest Matching for News Recommendation", "categories": ["cs.IR", "cs.LG"], "comment": "10 pages, 7 figures, 4 tables, accepted at ACM International\n  Conference on Information and Knowledge Management (CIKM)", "summary": "Personalized news recommendation aims to deliver news articles aligned with\nusers' interests, serving as a key solution to alleviate the problem of\ninformation overload on online news platforms. While prior work has improved\ninterest matching through refined representations of news and users, the\nfollowing time-related challenges remain underexplored: (C1) leveraging the age\nof clicked news to infer users' interest persistence, and (C2) modeling the\nvarying lifetime of news across topics and users. To jointly address these\nchallenges, we propose a novel Lifetime-aware Interest Matching framework for\nnEws recommendation, named LIME, which incorporates three key strategies: (1)\nUser-Topic lifetime-aware age representation to capture the relative age of\nnews with respect to a user-topic pair, (2) Candidate-aware lifetime attention\nfor generating temporally aligned user representation, and (3) Freshness-guided\ninterest refinement for prioritizing valid candidate news at prediction time.\nExtensive experiments on two real-world datasets demonstrate that LIME\nconsistently outperforms a wide range of state-of-the-art news recommendation\nmethods, and its model agnostic strategies significantly improve recommendation\naccuracy."}
{"id": "2508.12733", "pdf": "https://arxiv.org/pdf/2508.12733", "abs": "https://arxiv.org/abs/2508.12733", "authors": ["Zhiyuan Ning", "Tianle Gu", "Jiaxin Song", "Shixin Hong", "Lingyu Li", "Huacan Liu", "Jie Li", "Yixu Wang", "Meng Lingyu", "Yan Teng", "Yingchun Wang"], "title": "LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "7pages, 5 figures", "summary": "The widespread adoption and increasing prominence of large language models\n(LLMs) in global technologies necessitate a rigorous focus on ensuring their\nsafety across a diverse range of linguistic and cultural contexts. The lack of\na comprehensive evaluation and diverse data in existing multilingual safety\nevaluations for LLMs limits their effectiveness, hindering the development of\nrobust multilingual safety alignment. To address this critical gap, we\nintroduce LinguaSafe, a comprehensive multilingual safety benchmark crafted\nwith meticulous attention to linguistic authenticity. The LinguaSafe dataset\ncomprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated\nusing a combination of translated, transcreated, and natively-sourced data, our\ndataset addresses the critical need for multilingual safety evaluations of\nLLMs, filling the void in the safety evaluation of LLMs across diverse\nunder-represented languages from Hungarian to Malay. LinguaSafe presents a\nmultidimensional and fine-grained evaluation framework, with direct and\nindirect safety assessments, including further evaluations for oversensitivity.\nThe results of safety and helpfulness evaluations vary significantly across\ndifferent domains and different languages, even in languages with similar\nresource levels. Our benchmark provides a comprehensive suite of metrics for\nin-depth safety evaluation, underscoring the critical importance of thoroughly\nassessing multilingual safety in LLMs to achieve more balanced safety\nalignment. Our dataset and code are released to the public to facilitate\nfurther research in the field of multilingual LLM safety."}
{"id": "2508.13068", "pdf": "https://arxiv.org/pdf/2508.13068", "abs": "https://arxiv.org/abs/2508.13068", "authors": ["Tanjim Islam Riju", "Shuchismita Anwar", "Saman Sarker Joy", "Farig Sadeque", "Swakkhar Shatabda"], "title": "Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "We propose a two-stage multimodal framework that enhances disease\nclassification and region-aware radiology report generation from chest X-rays,\nleveraging the MIMIC-Eye dataset. In the first stage, we introduce a\ngaze-guided contrastive learning architecture for disease classification. It\nintegrates visual features, clinical labels, bounding boxes, and radiologist\neye-tracking signals and is equipped with a novel multi-term gaze-attention\nloss combining MSE, KL divergence, correlation, and center-of-mass alignment.\nIncorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC\nfrom 0.821 to 0.849 (+3.41%), while also improving precision and recall,\nhighlighting the effectiveness of gaze-informed attention supervision. In the\nsecond stage, we present a modular report generation pipeline that extracts\nconfidence-weighted diagnostic keywords, maps them to anatomical regions using\na curated dictionary constructed from domain-specific priors, and generates\nregion-aligned sentences via structured prompts. This pipeline improves report\nquality as measured by clinical keyword recall and ROUGE overlap. Our results\ndemonstrate that integrating gaze data improves both classification performance\nand the interpretability of generated medical reports."}
{"id": "2508.12740", "pdf": "https://arxiv.org/pdf/2508.12740", "abs": "https://arxiv.org/abs/2508.12740", "authors": ["Beomseok Seo", "Kichang Lee", "JaeYeon Park"], "title": "FedUNet: A Lightweight Additive U-Net Module for Federated Learning with Heterogeneous Models", "categories": ["cs.LG", "cs.AI", "68T01 (Primary), 68T07 (Secondary)", "I.2"], "comment": "6 pages, 4 figures", "summary": "Federated learning (FL) enables decentralized model training without sharing\nlocal data. However, most existing methods assume identical model architectures\nacross clients, limiting their applicability in heterogeneous real-world\nenvironments. To address this, we propose FedUNet, a lightweight and\narchitecture-agnostic FL framework that attaches a U-Net-inspired additive\nmodule to each client's backbone. By sharing only the compact bottleneck of the\nU-Net, FedUNet enables efficient knowledge transfer without structural\nalignment. The encoder-decoder design and skip connections in the U-Net help\ncapture both low-level and high-level features, facilitating the extraction of\nclientinvariant representations. This enables cooperative learning between the\nbackbone and the additive module with minimal communication cost. Experiment\nwith VGG variants shows that FedUNet achieves 93.11% accuracy and 92.68% in\ncompact form (i.e., a lightweight version of FedUNet) with only 0.89 MB low\ncommunication overhead."}
{"id": "2508.13097", "pdf": "https://arxiv.org/pdf/2508.13097", "abs": "https://arxiv.org/abs/2508.13097", "authors": ["Sara Karimi", "Nikolaos N. Vlassis"], "title": "Denoising diffusion models for inverse design of inflatable structures with programmable deformations", "categories": ["cs.CE", "cs.LG"], "comment": "21 pages, 12 figures", "summary": "Programmable structures are systems whose undeformed geometries and material\nproperty distributions are deliberately designed to achieve prescribed deformed\nconfigurations under specific loading conditions. Inflatable structures are a\nprominent example, using internal pressurization to realize large, nonlinear\ndeformations in applications ranging from soft robotics and deployable\naerospace systems to biomedical devices and adaptive architecture. We present a\ngenerative design framework based on denoising diffusion probabilistic models\n(DDPMs) for the inverse design of elastic structures undergoing large,\nnonlinear deformations under pressure-driven actuation. The method formulates\nthe inverse design as a conditional generation task, using geometric\ndescriptors of target deformed states as inputs and outputting image-based\nrepresentations of the undeformed configuration. Representing these\nconfigurations as simple images is achieved by establishing a pre- and\npostprocessing pipeline that involves a fixed image processing, simulation\nsetup, and descriptor extraction methods. Numerical experiments with scalar and\nhigher-dimensional descriptors show that the framework can quickly produce\ndiverse undeformed configurations that achieve the desired deformations when\ninflated, enabling parallel exploration of viable design candidates while\naccommodating complex constraints."}
{"id": "2508.12745", "pdf": "https://arxiv.org/pdf/2508.12745", "abs": "https://arxiv.org/abs/2508.12745", "authors": ["Xizhan Gao", "Wei Hu"], "title": "DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Image set classification (ISC), which can be viewed as a task of comparing\nsimilarities between sets consisting of unordered heterogeneous images with\nvariable quantities and qualities, has attracted growing research attention in\nrecent years. How to learn effective feature representations and how to explore\nthe similarities between different image sets are two key yet challenging\nissues in this field. However, existing traditional ISC methods classify image\nsets based on raw pixel features, ignoring the importance of feature learning.\nExisting deep ISC methods can learn deep features, but they fail to adaptively\nadjust the features when measuring set distances, resulting in limited\nperformance in few-shot ISC. To address the above issues, this paper combines\ntraditional ISC methods with deep models and proposes a novel few-shot ISC\napproach called Deep Class-specific Collaborative Representation (DCSCR)\nnetwork to simultaneously learn the frame- and concept-level feature\nrepresentations of each image set and the distance similarities between\ndifferent sets. Specifically, DCSCR consists of a fully convolutional deep\nfeature extractor module, a global feature learning module, and a\nclass-specific collaborative representation-based metric learning module. The\ndeep feature extractor and global feature learning modules are used to learn\n(local and global) frame-level feature representations, while the\nclass-specific collaborative representation-based metric learning module is\nexploit to adaptively learn the concept-level feature representation of each\nimage set and thus obtain the distance similarities between different sets by\ndeveloping a new CSCR-based contrastive loss function. Extensive experiments on\nseveral well-known few-shot ISC datasets demonstrate the effectiveness of the\nproposed method compared with some state-of-the-art image set classification\nalgorithms."}
{"id": "2508.13131", "pdf": "https://arxiv.org/pdf/2508.13131", "abs": "https://arxiv.org/abs/2508.13131", "authors": ["Dara Bahri", "John Wieting"], "title": "Improving Detection of Watermarked Language Models", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "Watermarking has recently emerged as an effective strategy for detecting the\ngenerations of large language models (LLMs). The strength of a watermark\ntypically depends strongly on the entropy afforded by the language model and\nthe set of input prompts. However, entropy can be quite limited in practice,\nespecially for models that are post-trained, for example via instruction tuning\nor reinforcement learning from human feedback (RLHF), which makes detection\nbased on watermarking alone challenging. In this work, we investigate whether\ndetection can be improved by combining watermark detectors with non-watermark\nones. We explore a number of hybrid schemes that combine the two, observing\nperformance gains over either class of detector under a wide range of\nexperimental conditions."}
{"id": "2508.12755", "pdf": "https://arxiv.org/pdf/2508.12755", "abs": "https://arxiv.org/abs/2508.12755", "authors": ["Cristo J. van den Berg", "Frank G. te Nijenhuis", "Mirre J. Blaauboer", "Daan T. W. van Erp", "Carlijn M. Keppels", "Matthijs van der Sluijs", "Bob Roozenbeek", "Wim van Zwam", "Sandra Cornelissen", "Danny Ruijters", "Ruisheng Su", "Theo van Walsum"], "title": "CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 4 figures, workshop paper accepted at\n  https://switchmiccai.github.io/switch/", "summary": "Computer vision models can be used to assist during mechanical thrombectomy\n(MT) for acute ischemic stroke (AIS), but poor image quality often degrades\nperformance. This work presents CLAIRE-DSA, a deep learning--based framework\ndesigned to categorize key image properties in minimum intensity projections\n(MinIPs) acquired during MT for AIS, supporting downstream quality control and\nworkflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,\nfine-tuned to predict nine image properties (e.g., presence of contrast,\nprojection angle, motion artefact severity). Separate classifiers were trained\non an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model\nachieved excellent performance on all labels, with ROC-AUC ranging from $0.91$\nto $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of\nCLAIRE-DSA to identify suitable images was evaluated on a segmentation task by\nfiltering poor quality images and comparing segmentation performance on\nfiltered and unfiltered datasets. Segmentation success rate increased from\n$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an\nautomated tool for accurately classifying image properties in DSA series of\nacute ischemic stroke patients, supporting image annotation and quality control\nin clinical and research applications. Source code is available at\nhttps://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa."}
{"id": "2508.13141", "pdf": "https://arxiv.org/pdf/2508.13141", "abs": "https://arxiv.org/abs/2508.13141", "authors": ["Pranjal Aggarwal", "Seungone Kim", "Jack Lanchantin", "Sean Welleck", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "OptimalThinkingBench: Evaluating Over and Underthinking in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "26 pages, 6 tables, 10 figures", "summary": "Thinking LLMs solve complex tasks at the expense of increased compute and\noverthinking on simpler problems, while non-thinking LLMs are faster and\ncheaper but underthink on harder reasoning problems. This has led to the\ndevelopment of separate thinking and non-thinking LLM variants, leaving the\nonus of selecting the optimal model for each query on the end user. In this\nwork, we introduce OptimalThinkingBench, a unified benchmark that jointly\nevaluates overthinking and underthinking in LLMs and also encourages the\ndevelopment of optimally-thinking models that balance performance and\nefficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,\nfeaturing simple queries in 72 domains, and UnderthinkingBench, containing 11\nchallenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we\nperform extensive evaluation of 33 different thinking and non-thinking models\nand show that no model is able to optimally think on our benchmark. Thinking\nmodels often overthink for hundreds of tokens on the simplest user queries\nwithout improving performance. In contrast, large non-thinking models\nunderthink, often falling short of much smaller thinking models. We further\nexplore several methods to encourage optimal thinking, but find that these\napproaches often improve on one sub-benchmark at the expense of the other,\nhighlighting the need for better unified and optimal models in the future."}
{"id": "2508.12766", "pdf": "https://arxiv.org/pdf/2508.12766", "abs": "https://arxiv.org/abs/2508.12766", "authors": ["Peihao Li", "Yan Fang", "Man Liu", "Huihui Bai", "Anhong Wang", "Yunchao Wei", "Yao Zhao"], "title": "Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging\ndue to the low-contrast defect boundaries, necessitating annotators to\ncross-reference multiple views. These views share a single ground truth (GT),\nforming a unique ``many-to-one'' relationship. This characteristic renders\nadvanced semi-supervised semantic segmentation (SSS) methods suboptimal, as\nthey are generally limited by a ``one-to-one'' relationship, where each image\nis independently associated with its GT. Such limitation may lead to error\naccumulation in low-contrast regions, further exacerbating confirmation bias.\nTo address this issue, we revisit the SSS pipeline from a group-oriented\nperspective and propose a human-inspired solution: the Intra-group Consistency\nAugmentation Framework (ICAF). First, we experimentally validate the inherent\nconsistency constraints within CdZnTe groups, establishing a group-oriented\nbaseline using the Intra-group View Sampling (IVS). Building on this insight,\nwe introduce the Pseudo-label Correction Network (PCN) to enhance consistency\nrepresentation, which consists of two key modules. The View Augmentation Module\n(VAM) improves boundary details by dynamically synthesizing a boundary-aware\nview through the aggregation of multiple views. In the View Correction Module\n(VCM), this synthesized view is paired with other views for information\ninteraction, effectively emphasizing salient regions while minimizing noise.\nExtensive experiments demonstrate the effectiveness of our solution for CdZnTe\nmaterials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation\nmodel, we achieve a 70.6\\% mIoU on the CdZnTe dataset using only 2\ngroup-annotated data (5\\textperthousand). The code is available at\n\\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}."}
{"id": "2508.13142", "pdf": "https://arxiv.org/pdf/2508.13142", "abs": "https://arxiv.org/abs/2508.13142", "authors": ["Zhongang Cai", "Yubo Wang", "Qingping Sun", "Ruisi Wang", "Chenyang Gu", "Wanqi Yin", "Zhiqian Lin", "Zhitao Yang", "Chen Wei", "Xuanke Shi", "Kewang Deng", "Xiaoyang Han", "Zukai Chen", "Jiaqi Li", "Xiangyu Fan", "Hanming Deng", "Lewei Lu", "Bo Li", "Ziwei Liu", "Quan Wang", "Dahua Lin", "Lei Yang"], "title": "Has GPT-5 Achieved Spatial Intelligence? An Empirical Study", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM", "cs.RO"], "comment": null, "summary": "Multi-modal models have achieved remarkable progress in recent years.\nNevertheless, they continue to exhibit notable limitations in spatial\nunderstanding and reasoning, which are fundamental capabilities to achieving\nartificial general intelligence. With the recent release of GPT-5, allegedly\nthe most powerful AI model to date, it is timely to examine where the leading\nmodels stand on the path toward spatial intelligence. First, we propose a\ncomprehensive taxonomy of spatial tasks that unifies existing benchmarks and\ndiscuss the challenges in ensuring fair evaluation. We then evaluate\nstate-of-the-art proprietary and open-source models on eight key benchmarks, at\na cost exceeding one billion total tokens. Our empirical study reveals that (1)\nGPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)\nstill falls short of human performance across a broad spectrum of tasks.\nMoreover, we (3) identify the more challenging spatial intelligence problems\nfor multi-modal models, and (4) proprietary models do not exhibit a decisive\nadvantage when facing the most difficult problems. In addition, we conduct a\nqualitative evaluation across a diverse set of scenarios that are intuitive for\nhumans yet fail even the most advanced multi-modal models."}
{"id": "2508.12769", "pdf": "https://arxiv.org/pdf/2508.12769", "abs": "https://arxiv.org/abs/2508.12769", "authors": ["Shaoming Duan", "Zirui Wang", "Chuanyi Liu", "Zhibin Zhu", "Yuhao Zhang", "Peiyi Han", "Liang Yan", "Zewu Penge"], "title": "CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have significantly improved\nthe accuracy of Text-to-SQL systems. However, a critical challenge remains: the\nsemantic mismatch between natural language questions (NLQs) and their\ncorresponding SQL queries. This issue is exacerbated in large-scale databases,\nwhere semantically similar attributes hinder schema linking and semantic drift\nduring SQL generation, ultimately reducing model accuracy. To address these\nchallenges, we introduce CRED-SQL, a framework designed for large-scale\ndatabases that integrates Cluster Retrieval and Execution Description. CRED-SQL\nfirst performs cluster-based large-scale schema retrieval to pinpoint the\ntables and columns most relevant to a given NLQ, alleviating schema mismatch.\nIt then introduces an intermediate natural language representation-Execution\nDescription Language (EDL)-to bridge the gap between NLQs and SQL. This\nreformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,\nleveraging LLMs' strong general reasoning capabilities while reducing semantic\ndeviation. Extensive experiments on two large-scale, cross-domain\nbenchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new\nstate-of-the-art (SOTA) performance, validating its effectiveness and\nscalability. Our code is available at https://github.com/smduan/CRED-SQL.git"}
{"id": "2508.13144", "pdf": "https://arxiv.org/pdf/2508.13144", "abs": "https://arxiv.org/abs/2508.13144", "authors": ["David Heineman", "Valentin Hofmann", "Ian Magnusson", "Yuling Gu", "Noah A. Smith", "Hannaneh Hajishirzi", "Kyle Lo", "Jesse Dodge"], "title": "Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Developing large language models is expensive and involves making decisions\nwith small experiments, typically by evaluating on large, multi-task evaluation\nsuites. In this work, we analyze specific properties which make a benchmark\nmore reliable for such decisions, and interventions to design higher-quality\nevaluation benchmarks. We introduce two key metrics that show differences in\ncurrent benchmarks: signal, a benchmark's ability to separate better models\nfrom worse models, and noise, a benchmark's sensitivity to random variability\nbetween training steps. We demonstrate that benchmarks with a better\nsignal-to-noise ratio are more reliable when making decisions at small scale,\nand those with less noise have lower scaling law prediction error. These\nresults suggest that improving signal or noise will lead to more useful\nbenchmarks, so we introduce three interventions designed to directly affect\nsignal or noise. For example, we propose that switching to a metric that has\nbetter signal and noise (e.g., perplexity rather than accuracy) leads to better\nreliability and improved scaling law error. We also find that filtering noisy\nsubtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable\nmulti-task evaluations. We also find that averaging the output of a model's\nintermediate checkpoints to reduce noise leads to consistent improvements. We\nconclude by recommending that those creating new benchmarks, or selecting which\nexisting benchmarks to use, aim for high signal and low noise. We use 30\nbenchmarks for these experiments, and 375 open-weight language models from 60M\nto 32B parameters, resulting in a new, publicly available dataset of 900K\nevaluation benchmark results, totaling 200M instances."}
{"id": "2508.12776", "pdf": "https://arxiv.org/pdf/2508.12776", "abs": "https://arxiv.org/abs/2508.12776", "authors": ["Muhammad Rajabinasab", "Farhad Pakdaman", "Moncef Gabbouj", "Peter Schneider-Kamp", "Arthur Zimek"], "title": "Randomized PCA Forest for Outlier Detection", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We propose a novel unsupervised outlier detection method based on Randomized\nPrincipal Component Analysis (PCA). Inspired by the performance of Randomized\nPCA (RPCA) Forest in approximate K-Nearest Neighbor (KNN) search, we develop a\nnovel unsupervised outlier detection method that utilizes RPCA Forest for\noutlier detection. Experimental results showcase the superiority of the\nproposed approach compared to the classical and state-of-the-art methods in\nperforming the outlier detection task on several datasets while performing\ncompetitively on the rest. The extensive analysis of the proposed method\nreflects it high generalization power and its computational efficiency,\nhighlighting it as a good choice for unsupervised outlier detection."}
{"id": "2508.12792", "pdf": "https://arxiv.org/pdf/2508.12792", "abs": "https://arxiv.org/abs/2508.12792", "authors": ["Felipe Maia Polo", "Xinhe Wang", "Mikhail Yurochkin", "Gongjun Xu", "Moulinath Banerjee", "Yuekai Sun"], "title": "Bridging Human and LLM Judgments: Understanding and Narrowing the Gap", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large language models are increasingly used as judges (LLM-as-a-judge) to\nevaluate model outputs at scale, but their assessments often diverge\nsystematically from human judgments. We present Bridge, a unified statistical\nframework that explicitly bridges human and LLM evaluations under both absolute\nscoring and pairwise comparison paradigms. Bridge posits a latent human\npreference score for each prompt-response pair and models LLM deviations as\nlinear transformations of covariates that capture sources of discrepancies.\nThis offers a simple and principled framework for refining LLM ratings and\ncharacterizing systematic discrepancies between humans and LLMs. We provide an\nefficient fitting algorithm with asymptotic guarantees for statistical\ninference. Using six LLM judges and two benchmarks (BigGen Bench and Chatbot\nArena), Bridge achieves higher agreement with human ratings (accuracy,\ncalibration, and KL divergence) and exposes systematic human-LLM gaps."}
{"id": "2508.12794", "pdf": "https://arxiv.org/pdf/2508.12794", "abs": "https://arxiv.org/abs/2508.12794", "authors": ["Kyriaki", "Kokka", "Rahul Goel", "Ali Abbas", "Kerry A. Nice", "Luca Martial", "SM Labib", "Rihuan Ke", "Carola Bibiane Schönlieb", "James Woodcock"], "title": "Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Transportation influence health by shaping exposure to physical activity, air\npollution and injury risk.Comparative data on cycling and motorcycling\nbehaviours is scarce, particularly at a global scale.Street view imagery, such\nas Google Street View (GSV), combined with computer vision, is a valuable\nresource for efficiently capturing travel behaviour data.This study\ndemonstrates a novel approach using deep learning on street view images to\nestimate cycling and motorcycling levels across diverse cities worldwide.We\nutilized data from 185 global cities.The data on mode shares of cycling and\nmotorcycling estimated using travel surveys or censuses.We used GSV images to\ndetect cycles and motorcycles in sampled locations, using 8000 images per\ncity.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean\naverage precision of 89% for detecting cycles and motorcycles in GSV images.A\nglobal prediction model was developed using beta regression with city-level\nmode shares as outcome, with log transformed explanatory variables of counts of\nGSV-detected images with cycles and motorcycles, while controlling for\npopulation density.We found strong correlations between GSV motorcycle counts\nand motorcycle mode share (0.78) and moderate correlations between GSV cycle\ncounts and cycling mode share (0.51).Beta regression models predicted mode\nshares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,\nachieving median absolute errors (MDAE) of 1.3% and 1.4%,\nrespectively.Scatterplots demonstrated consistent prediction accuracy, though\ncities like Utrecht and Cali were outliers.The model was applied to 60 cities\nglobally for which we didn't have recent mode share data.We provided estimates\nfor some cities in the Middle East, Latin America and East Asia.With computer\nvision, GSV images capture travel modes and activity, providing insights\nalongside traditional data sources."}
{"id": "2508.12798", "pdf": "https://arxiv.org/pdf/2508.12798", "abs": "https://arxiv.org/abs/2508.12798", "authors": ["Damian Machlanski", "Stephanie Riley", "Edward Moroshko", "Kurt Butler", "Panagiotis Dimitrakopoulos", "Thomas Melistas", "Akchunya Chanchal", "Steven McDonagh", "Ricardo Silva", "Sotirios A. Tsaftaris"], "title": "A Shift in Perspective on Causality in Domain Generalization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "2 pages, 1 figure, to be presented at the UK AI Research Symposium\n  (UKAIRS) 2025", "summary": "The promise that causal modelling can lead to robust AI generalization has\nbeen challenged in recent work on domain generalization (DG) benchmarks. We\nrevisit the claims of the causality and DG literature, reconciling apparent\ncontradictions and advocating for a more nuanced theory of the role of\ncausality in generalization. We also provide an interactive demo at\nhttps://chai-uk.github.io/ukairs25-causal-predictors/."}
{"id": "2508.12800", "pdf": "https://arxiv.org/pdf/2508.12800", "abs": "https://arxiv.org/abs/2508.12800", "authors": ["Yong Deng", "Guoqing Wang", "Zhenzhe Ying", "Xiaofeng Wu", "Jinzhen Lin", "Wenwen Xiong", "Yuqin Dai", "Shuo Yang", "Zhanwei Zhang", "Qiwen Wang", "Yang Qin", "Changhua Meng"], "title": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) exhibit remarkable problem-solving abilities,\nbut struggle with complex tasks due to static internal knowledge.\nRetrieval-Augmented Generation (RAG) enhances access to external information,\nyet remains limited in multi-hop reasoning and strategic search due to rigid\nworkflows. Recent advancements in agentic deep research empower LLMs to\nautonomously reason, search, and synthesize information. However, current\napproaches relying on outcome-based reinforcement learning (RL) face critical\nissues such as conflicting gradients and reward sparsity, limiting performance\ngains and training efficiency. To address these, we first propose Atomic\nThought, a novel LLM thinking paradigm that decomposes reasoning into\nfine-grained functional units. These units are supervised by Reasoning Reward\nModels (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained\nguidance. Building on this, we propose Atom-Searcher, a novel RL framework for\nagentic deep research that integrates Atomic Thought and ATR. Atom-Searcher\nuses a curriculum-inspired reward schedule, prioritizing process-level ATR\nearly and transitioning to outcome rewards, accelerating convergence on\neffective reasoning paths. Experiments on seven benchmarks show consistent\nimprovements over the state-of-the-art. Key advantages include: (1)\nAtom-Searcher scales computation at test-time. (2) Atomic Thought provides\nsupervision anchors for RRMs, bridging deep research tasks and RRMs. (3)\nAtom-Searcher exhibits more interpretable, human-like reasoning patterns."}
{"id": "2508.12811", "pdf": "https://arxiv.org/pdf/2508.12811", "abs": "https://arxiv.org/abs/2508.12811", "authors": ["Yikai Wang", "Zhouxia Wang", "Zhonghua Wu", "Qingyi Tao", "Kang Liao", "Chen Change Loy"], "title": "Next Visual Granularity Generation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a novel approach to image generation by decomposing an image into\na structured sequence, where each element in the sequence shares the same\nspatial resolution but differs in the number of unique tokens used, capturing\ndifferent level of visual granularity. Image generation is carried out through\nour newly introduced Next Visual Granularity (NVG) generation framework, which\ngenerates a visual granularity sequence beginning from an empty image and\nprogressively refines it, from global layout to fine details, in a structured\nmanner. This iterative process encodes a hierarchical, layered representation\nthat offers fine-grained control over the generation process across multiple\ngranularity levels. We train a series of NVG models for class-conditional image\ngeneration on the ImageNet dataset and observe clear scaling behavior. Compared\nto the VAR series, NVG consistently outperforms it in terms of FID scores (3.30\n-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to\nshowcase the capability and potential of the NVG framework. Our code and models\nwill be released."}
{"id": "2508.12815", "pdf": "https://arxiv.org/pdf/2508.12815", "abs": "https://arxiv.org/abs/2508.12815", "authors": ["Jayneel Parekh", "Pegah Khayatan", "Mustafa Shukor", "Arnaud Dapogny", "Alasdair Newson", "Matthieu Cord"], "title": "Learning to Steer: Input-dependent Steering for Multimodal LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Steering has emerged as a practical approach to enable post-hoc guidance of\nLLMs towards enforcing a specific behavior. However, it remains largely\nunderexplored for multimodal LLMs (MLLMs); furthermore, existing steering\ntechniques, such as mean steering, rely on a single steering vector, applied\nindependently of the input query. This paradigm faces limitations when the\ndesired behavior is dependent on the example at hand. For example, a safe\nanswer may consist in abstaining from answering when asked for an illegal\nactivity, or may point to external resources or consultation with an expert\nwhen asked about medical advice. In this paper, we investigate a fine-grained\nsteering that uses an input-specific linear shift. This shift is computed using\ncontrastive input-specific prompting. However, the input-specific prompts\nrequired for this approach are not known at test time. Therefore, we propose to\ntrain a small auxiliary module to predict the input-specific steering vector.\nOur approach, dubbed as L2S (Learn-to-Steer), demonstrates that it reduces\nhallucinations and enforces safety in MLLMs, outperforming other static\nbaselines."}
{"id": "2508.12828", "pdf": "https://arxiv.org/pdf/2508.12828", "abs": "https://arxiv.org/abs/2508.12828", "authors": ["Raneem Alharthi", "Rajwa Alharthi", "Aiqi Jiang", "Arkaitz Zubiaga"], "title": "Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Abusive language detection has become an increasingly important task as a\nmeans to tackle this type of harmful content in social media. There has been a\nsubstantial body of research developing models for determining if a social\nmedia post is abusive or not; however, this research has primarily focused on\nexploiting social media posts individually, overlooking additional context that\ncan be derived from surrounding posts. In this study, we look at conversational\nexchanges, where a user replies to an earlier post by another user (the parent\ntweet). We ask: does leveraging context from the parent tweet help determine if\na reply post is abusive or not, and what are the features that contribute the\nmost? We study a range of content-based and account-based features derived from\nthe context, and compare this to the more widely studied approach of only\nlooking at the features from the reply tweet. For a more generalizable study,\nwe test four different classification models on a dataset made of\nconversational exchanges (parent-reply tweet pairs) with replies labeled as\nabusive or not. Our experiments show that incorporating contextual features\nleads to substantial improvements compared to the use of features derived from\nthe reply tweet only, confirming the importance of leveraging context. We\nobserve that, among the features under study, it is especially the\ncontent-based features (what is being posted) that contribute to the\nclassification performance rather than account-based features (who is posting\nit). While using content-based features, it is best to combine a range of\ndifferent features to ensure improved performance over being more selective and\nusing fewer features. Our study provides insights into the development of\ncontextualized abusive language detection models in realistic settings\ninvolving conversations."}
{"id": "2508.12833", "pdf": "https://arxiv.org/pdf/2508.12833", "abs": "https://arxiv.org/abs/2508.12833", "authors": ["Kichang Lee", "Songkuk Kim", "JaeYeon Park", "JeongGil Ko"], "title": "Toward Storage-Aware Learning with Compressed Data An Empirical Exploratory Study on JPEG", "categories": ["cs.LG", "cs.AI", "68Txx", "I.2; I.4.2; E.4"], "comment": "6pages, 6figures", "summary": "On-device machine learning is often constrained by limited storage,\nparticularly in continuous data collection scenarios. This paper presents an\nempirical study on storage-aware learning, focusing on the trade-off between\ndata quantity and quality via compression. We demonstrate that naive\nstrategies, such as uniform data dropping or one-size-fits-all compression, are\nsuboptimal. Our findings further reveal that data samples exhibit varying\nsensitivities to compression, supporting the feasibility of a sample-wise\nadaptive compression strategy. These insights provide a foundation for\ndeveloping a new class of storage-aware learning systems. The primary\ncontribution of this work is the systematic characterization of this\nunder-explored challenge, offering valuable insights that advance the\nunderstanding of storage-aware learning."}
{"id": "2508.12839", "pdf": "https://arxiv.org/pdf/2508.12839", "abs": "https://arxiv.org/abs/2508.12839", "authors": ["Tiancheng Zhang", "Cheng Zhang", "Shuren Liu", "Xiaofei Wang", "Shaoyuan Huang", "Wenyu Wang"], "title": "HRS: Hybrid Representation Framework with Scheduling Awareness for Time Series Forecasting in Crowdsourced Cloud-Edge Platforms", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 14 figures, ECAI2025", "summary": "With the rapid proliferation of streaming services, network load exhibits\nhighly time-varying and bursty behavior, posing serious challenges for\nmaintaining Quality of Service (QoS) in Crowdsourced Cloud-Edge Platforms\n(CCPs). While CCPs leverage Predict-then-Schedule architecture to improve QoS\nand profitability, accurate load forecasting remains challenging under traffic\nsurges. Existing methods either minimize mean absolute error, resulting in\nunderprovisioning and potential Service Level Agreement (SLA) violations during\npeak periods, or adopt conservative overprovisioning strategies, which mitigate\nSLA risks at the expense of increased resource expenditure. To address this\ndilemma, we propose HRS, a hybrid representation framework with scheduling\nawareness that integrates numerical and image-based representations to better\ncapture extreme load dynamics. We further introduce a Scheduling-Aware Loss\n(SAL) that captures the asymmetric impact of prediction errors, guiding\npredictions that better support scheduling decisions. Extensive experiments on\nfour real-world datasets demonstrate that HRS consistently outperforms ten\nbaselines and achieves state-of-the-art performance, reducing SLA violation\nrates by 63.1% and total profit loss by 32.3%."}
{"id": "2508.12863", "pdf": "https://arxiv.org/pdf/2508.12863", "abs": "https://arxiv.org/abs/2508.12863", "authors": ["Jumbly Grindrod", "Peter Grindrod"], "title": "Word Meanings in Transformer Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We investigate how word meanings are represented in the transformer language\nmodels. Specifically, we focus on whether transformer models employ something\nanalogous to a lexical store - where each word has an entry that contains\nsemantic information. To do this, we extracted the token embedding space of\nRoBERTa-base and k-means clustered it into 200 clusters. In our first study, we\nthen manually inspected the resultant clusters to consider whether they are\nsensitive to semantic information. In our second study, we tested whether the\nclusters are sensitive to five psycholinguistic measures: valence,\nconcreteness, iconicity, taboo, and age of acquisition. Overall, our findings\nwere very positive - there is a wide variety of semantic information encoded\nwithin the token embedding space. This serves to rule out certain \"meaning\neliminativist\" hypotheses about how transformer LLMs process semantic\ninformation."}
{"id": "2508.12885", "pdf": "https://arxiv.org/pdf/2508.12885", "abs": "https://arxiv.org/abs/2508.12885", "authors": ["Aleksei Liuliakov", "Alexander Schulz", "Luca Hermes", "Barbara Hammer"], "title": "One-Class Intrusion Detection with Dynamic Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "With the growing digitalization all over the globe, the relevance of network\nsecurity becomes increasingly important. Machine learning-based intrusion\ndetection constitutes a promising approach for improving security, but it bears\nseveral challenges. These include the requirement to detect novel and unseen\nnetwork events, as well as specific data properties, such as events over time\ntogether with the inherent graph structure of network communication. In this\nwork, we propose a novel intrusion detection method, TGN-SVDD, which builds\nupon modern dynamic graph modelling and deep anomaly detection. We demonstrate\nits superiority over several baselines for realistic intrusion detection data\nand suggest a more challenging variant of the latter."}
{"id": "2508.12900", "pdf": "https://arxiv.org/pdf/2508.12900", "abs": "https://arxiv.org/abs/2508.12900", "authors": ["Jiayi Wang", "Hadrien Reynaud", "Franciskus Xaverius Erick", "Bernhard Kainz"], "title": "CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Generative modelling of entire CT volumes conditioned on clinical reports has\nthe potential to accelerate research through data augmentation,\nprivacy-preserving synthesis and reducing regulator-constraints on patient data\nwhile preserving diagnostic signals. With the recent release of CT-RATE, a\nlarge-scale collection of 3D CT volumes paired with their respective clinical\nreports, training large text-conditioned CT volume generation models has become\nachievable. In this work, we introduce CTFlow, a 0.5B latent flow matching\ntransformer model, conditioned on clinical reports. We leverage the A-VAE from\nFLUX to define our latent space, and rely on the CT-Clip text encoder to encode\nthe clinical reports. To generate consistent whole CT volumes while keeping the\nmemory constraints tractable, we rely on a custom autoregressive approach,\nwhere the model predicts the first sequence of slices of the volume from\ntext-only, and then relies on the previously generated sequence of slices and\nthe text, to predict the following sequence. We evaluate our results against\nstate-of-the-art generative CT model, and demonstrate the superiority of our\napproach in terms of temporal coherence, image diversity and text-image\nalignment, with FID, FVD, IS scores and CLIP score."}
{"id": "2508.12903", "pdf": "https://arxiv.org/pdf/2508.12903", "abs": "https://arxiv.org/abs/2508.12903", "authors": ["Jinyi Han", "Xinyi Wang", "Haiquan Zhao", "Tingyun li", "Zishang Jiang", "Sihang Jiang", "Jiaqing Liang", "Xin Lin", "Weikang Zhou", "Zeye Sun", "Fei Yu", "Yanghua Xiao"], "title": "A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in self-refinement have demonstrated significant potential\nfor improving the outputs of large language models (LLMs) through iterative\nrefinement. However, most existing self-refinement methods rely on a reactive\nprocess with a fixed number of iterations, making it difficult to determine the\noptimal timing and content of refinement based on the evolving generation\ncontext. Inspired by the way humans dynamically refine their thoughts during\nexecution, we propose ProActive Self-Refinement (PASR), a novel method that\nenables LLMs to refine their outputs during the generation process. Unlike\nmethods that regenerate entire responses, PASR proactively decides whether,\nwhen, and how to refine based on the model's internal state and evolving\ncontext. We conduct extensive experiments on a diverse set of 10 tasks to\nevaluate the effectiveness of PASR. Experimental results show that PASR\nsignificantly enhances problem-solving performance. In particular, on Qwen3-8B,\nPASR reduces average token consumption by 41.6 percent compared to standard\ngeneration, while also achieving an 8.2 percent improvement in accuracy. Our\ncode and all baselines used in the paper are available in the GitHub."}
{"id": "2508.12910", "pdf": "https://arxiv.org/pdf/2508.12910", "abs": "https://arxiv.org/abs/2508.12910", "authors": ["Ziteng Hu", "Yingjie Xia", "Xiyuan Chen", "Li Kuang"], "title": "SecFSM: Knowledge Graph-Guided Verilog Code Generation for Secure Finite State Machines in Systems-on-Chip", "categories": ["cs.CR", "cs.AI", "cs.AR"], "comment": null, "summary": "Finite State Machines (FSMs) play a critical role in implementing control\nlogic for Systems-on-Chip (SoC). Traditionally, FSMs are implemented by\nhardware engineers through Verilog coding, which is often tedious and\ntime-consuming. Recently, with the remarkable progress of Large Language Models\n(LLMs) in code generation, LLMs have been increasingly explored for automating\nVerilog code generation. However, LLM-generated Verilog code often suffers from\nsecurity vulnerabilities, which is particularly concerning for\nsecurity-sensitive FSM implementations. To address this issue, we propose\nSecFSM, a novel method that leverages a security-oriented knowledge graph to\nguide LLMs in generating more secure Verilog code. Specifically, we first\nconstruct a FSM Security Knowledge Graph (FSKG) as an external aid to LLMs.\nSubsequently, we analyze users' requirements to identify vulnerabilities and\nget a list of vulnerabilities in the requirements. Then, we retrieve knowledge\nfrom FSKG based on the vulnerabilities list. Finally, we construct security\nprompts based on the security knowledge for Verilog code generation. To\nevaluate SecFSM, we build a dedicated dataset collected from academic datasets,\nartificial datasets, papers, and industrial cases. Extensive experiments\ndemonstrate that SecFSM outperforms state-of-the-art baselines. In particular,\non a benchmark of 25 security test cases evaluated by DeepSeek-R1, SecFSM\nachieves an outstanding pass rate of 21/25."}
{"id": "2508.12927", "pdf": "https://arxiv.org/pdf/2508.12927", "abs": "https://arxiv.org/abs/2508.12927", "authors": ["Robin Trombetta", "Carole Lartizien"], "title": "Learning local and global prototypes with optimal transport for unsupervised anomaly detection and localization", "categories": ["eess.IV", "cs.AI"], "comment": null, "summary": "Unsupervised anomaly detection aims to detect defective parts of a sample by\nhaving access, during training, to a set of normal, i.e. defect-free, data. It\nhas many applications in fields, such as industrial inspection or medical\nimaging, where acquiring labels is costly or when we want to avoid introducing\nbiases in the type of anomalies that can be spotted. In this work, we propose a\nnovel UAD method based on prototype learning and introduce a metric to compare\na structured set of embeddings that balances a feature-based cost and a\nspatial-based cost. We leverage this metric to learn local and global\nprototypes with optimal transport from latent representations extracted with a\npre-trained image encoder. We demonstrate that our approach can enforce a\nstructural constraint when learning the prototypes, allowing to capture the\nunderlying organization of the normal samples, thus improving the detection of\nincoherencies in images. Our model achieves performance that is on par with\nstrong baselines on two reference benchmarks for anomaly detection on\nindustrial images. The code is available at\nhttps://github.com/robintrmbtt/pradot."}
{"id": "2508.12932", "pdf": "https://arxiv.org/pdf/2508.12932", "abs": "https://arxiv.org/abs/2508.12932", "authors": ["Hongyang Chen", "Shaoling Pu", "Lingyu Zheng", "Zhongwu Sun"], "title": "SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ICONIP2025", "summary": "In incremental learning, enhancing the generality of knowledge is crucial for\nadapting to dynamic data inputs. It can develop generalized representations or\nmore balanced decision boundaries, preventing the degradation of long-term\nknowledge over time and thus mitigating catastrophic forgetting. Some emerging\nincremental learning methods adopt an encoder-decoder architecture and have\nachieved promising results. In the encoder-decoder achitecture, improving the\ngeneralization capabilities of both the encoder and decoder is critical, as it\nhelps preserve previously learned knowledge while ensuring adaptability and\nrobustness to new, diverse data inputs. However, many existing continual\nmethods focus solely on enhancing one of the two components, which limits their\neffectiveness in mitigating catastrophic forgetting. And these methods perform\neven worse in small-memory scenarios, where only a limited number of historical\nsamples can be stored. To mitigate this limitation, we introduces SEDEG, a\ntwo-stage training framework for vision transformers (ViT), focusing on\nsequentially improving the generality of both Decoder and Encoder. Initially,\nSEDEG trains an ensembled encoder through feature boosting to learn generalized\nrepresentations, which subsequently enhance the decoder's generality and\nbalance the classifier. The next stage involves using knowledge distillation\n(KD) strategies to compress the ensembled encoder and develop a new, more\ngeneralized encoder. This involves using a balanced KD approach and feature KD\nfor effective knowledge transfer. Extensive experiments on three benchmark\ndatasets show SEDEG's superior performance, and ablation studies confirm the\nefficacy of its components. The code is available at\nhttps://github.com/ShaolingPu/CIL."}
{"id": "2508.12962", "pdf": "https://arxiv.org/pdf/2508.12962", "abs": "https://arxiv.org/abs/2508.12962", "authors": ["Dominic LaBella", "Keshav Jha", "Jared Robbins", "Esther Yu"], "title": "Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation", "categories": ["cs.CV", "cs.AI"], "comment": "MICCAI. ToothFairy3, 16 pages, 5 figures, 1 table", "summary": "Cone-beam computed tomography (CBCT) has become an invaluable imaging\nmodality in dentistry, enabling 3D visualization of teeth and surrounding\nstructures for diagnosis and treatment planning. Automated segmentation of\ndental structures in CBCT can efficiently assist in identifying pathology\n(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning\nin head and neck cancer patients. We describe the DLaBella29 team's approach\nfor the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning\npipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg\nframework with a 3D SegResNet architecture, trained on a subset of the\nToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key\npreprocessing steps included image resampling to 0.6 mm isotropic resolution\nand intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE\non the 5-fold predictions to infer a Phase 1 segmentation and then conducted\ntight cropping around the easily segmented Phase 1 mandible to perform Phase 2\nsegmentation on the smaller nerve structures. Our method achieved an average\nDice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This\npaper details the clinical context, data preparation, model development,\nresults of our approach, and discusses the relevance of automated dental\nsegmentation for improving patient care in radiation oncology."}
{"id": "2508.12984", "pdf": "https://arxiv.org/pdf/2508.12984", "abs": "https://arxiv.org/abs/2508.12984", "authors": ["Zehang Lin", "Zheng Lin", "Miao Yang", "Jianhao Huang", "Yuxin Zhang", "Zihan Fang", "Xia Du", "Zhe Chen", "Shunzhi Zhu", "Wei Ni"], "title": "SL-ACC: A Communication-Efficient Split Learning Framework with Adaptive Channel-wise Compression", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "6 pages, 7 figures", "summary": "The increasing complexity of neural networks poses a significant barrier to\nthe deployment of distributed machine learning (ML) on resource-constrained\ndevices, such as federated learning (FL). Split learning (SL) offers a\npromising solution by offloading the primary computing load from edge devices\nto a server via model partitioning. However, as the number of participating\ndevices increases, the transmission of excessive smashed data (i.e.,\nactivations and gradients) becomes a major bottleneck for SL, slowing down the\nmodel training. To tackle this challenge, we propose a communication-efficient\nSL framework, named SL-ACC, which comprises two key components: adaptive\nchannel importance identification (ACII) and channel grouping compression\n(CGC). ACII first identifies the contribution of each channel in the smashed\ndata to model training using Shannon entropy. Following this, CGC groups the\nchannels based on their entropy and performs group-wise adaptive compression to\nshrink the transmission volume without compromising training accuracy.\nExtensive experiments across various datasets validate that our proposed SL-ACC\nframework takes considerably less time to achieve a target accuracy than\nstate-of-the-art benchmarks."}
{"id": "2508.12996", "pdf": "https://arxiv.org/pdf/2508.12996", "abs": "https://arxiv.org/abs/2508.12996", "authors": ["Stavros C. Kassinos"], "title": "Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair", "categories": ["cs.LG", "cs.AI", "65K10, 68T07", "I.2.6; G.1.6"], "comment": "54 pages, 8 figures, 19 tables", "summary": "Transformer neural networks are increasingly used for physics-based problems.\nIn data-driven PDE surrogates, training samples from varying boundary and\ninitial conditions can cause erratic losses and spiky gradients; in\nphysics-informed neural networks (PINNs), stiff composite losses amplify this\neffect.\n  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed\nsecond-moment discount beta2 is replaced by a layer-wise dynamic value driven\nby a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an\nexponential moving average (EMA) of past norms, squashed to the interval [0,1).\nSpikes lower beta2 toward beta2_min; calm phases keep it near beta2_max.\nOptions include leaky-AMSGrad (decay), trust-region clipping (max_ratio),\nadaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'',\n``exact'). With all features off and bias_correction=``none'', the method is\nexactly Adam.\n  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D\nPINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with\njitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB\nof enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss\nversus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about\n38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller\nvariance. The method remains drop-in, with runtime overhead comparable to Adam\nin testbeds A-C and within single-digit percent in testbed D. It preserves\nAdam-style convergence guarantees while improving robustness under spiky\ngradients."}
{"id": "2508.12998", "pdf": "https://arxiv.org/pdf/2508.12998", "abs": "https://arxiv.org/abs/2508.12998", "authors": ["Sanja Šćepanović", "Sagar Joglekar", "Stephen Law", "Daniele Quercia", "Ke Zhou", "Alice Battiston", "Rossano Schifanella"], "title": "Vitamin N: Benefits of Different Forms of Public Greenery for Urban Health", "categories": ["cs.CY", "cs.AI", "cs.CV"], "comment": null, "summary": "Urban greenery is often linked to better health, yet findings from past\nresearch have been inconsistent. One reason is that official greenery metrics\nmeasure the amount or nearness of greenery but ignore how often people actually\nmay potentially see or use it in daily life. To address this gap, we introduced\na new classification that separates on-road greenery, which people see while\nwalking through streets, from off-road greenery, which requires planned visits.\nWe did so by combining aerial imagery of Greater London and greenery data from\nOpenStreetMap with quantified greenery from over 100,000 Google Street View\nimages and accessibility estimates based on 160,000 road segments. We linked\nthese measures to 7.45 billion medical prescriptions issued by the National\nHealth Service and processed through our methodology. These prescriptions cover\nfive conditions: diabetes, hypertension, asthma, depression, and anxiety, as\nwell as opioid use. As hypothesized, we found that green on-road was more\nstrongly linked to better health than four widely used official measures. For\nexample, hypertension prescriptions dropped by 3.68% in wards with on-road\ngreenery above the median citywide level compared to those below it. If all\nbelow-median wards reached the citywide median in on-road greenery,\nprescription costs could fall by up to {\\pounds}3.15 million each year. These\nresults suggest that greenery seen in daily life may be more relevant than\npublic yet secluded greenery, and that official metrics commonly used in the\nliterature have important limitations."}
{"id": "2508.13030", "pdf": "https://arxiv.org/pdf/2508.13030", "abs": "https://arxiv.org/abs/2508.13030", "authors": ["Bipin Chhetri", "Akbar Siami Namin"], "title": "The Application of Transformer-Based Models for Predicting Consequences of Cyber Attacks", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "21 pages, 6 figures,Proceedings of the IEEE International Conference\n  on Computers, Software, & Applications (COMPSAC), EATA Symposium, Toronto,\n  Canada, July 8-11, 2025", "summary": "Cyberattacks are increasing, and securing against such threats is costing\nindustries billions of dollars annually. Threat Modeling, that is,\ncomprehending the consequences of these attacks, can provide critical support\nto cybersecurity professionals, enabling them to take timely action and\nallocate resources that could be used elsewhere. Cybersecurity is heavily\ndependent on threat modeling, as it assists security experts in assessing and\nmitigating risks related to identifying vulnerabilities and threats. Recently,\nthere has been a pressing need for automated methods to assess attack\ndescriptions and forecast the future consequences of the increasing complexity\nof cyberattacks. This study examines how Natural Language Processing (NLP) and\ndeep learning can be applied to analyze the potential impact of cyberattacks by\nleveraging textual descriptions from the MITRE Common Weakness Enumeration\n(CWE) database. We emphasize classifying attack consequences into five\nprincipal categories: Availability, Access Control, Confidentiality, Integrity,\nand Other. This paper investigates the use of Bidirectional Encoder\nRepresentations from Transformers (BERT) in combination with Hierarchical\nAttention Networks (HANs) for Multi-label classification, evaluating their\nperformance in comparison with conventional CNN and LSTM-based models.\nExperimental findings show that BERT achieves an overall accuracy of $0.972$,\nfar higher than conventional deep learning models in multi-label\nclassification. HAN outperforms baseline forms of CNN and LSTM-based models on\nspecific cybersecurity labels. However, BERT consistently achieves better\nprecision and recall, making it more suitable for predicting the consequences\nof a cyberattack."}
{"id": "2508.13037", "pdf": "https://arxiv.org/pdf/2508.13037", "abs": "https://arxiv.org/abs/2508.13037", "authors": ["Xinhe Li", "Jiajun Liu", "Peng Wang"], "title": "Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by IJCAI2025", "summary": "Recent studies have demonstrated that Large Language Models (LLMs) have\nstrong mathematical reasoning abilities but rely on hundreds of billions of\nparameters. To tackle the challenge of poor reasoning in Small Language Models\n(SLMs), existing methods typically leverage LLMs to generate massive amounts of\ndata for cramming training. In psychology, they are akin to System 1 thinking,\nwhich resolves reasoning problems rapidly based on experience and intuition.\nHowever, human learning also requires System 2 thinking, where knowledge is\nfirst acquired and then reinforced through practice. Inspired by such two\ndistinct modes of thinking, we propose a novel method based on the multi-LoRA\nInteraction for mathematical reasoning Distillation (LoRID). First, we input\nthe question and reasoning of each sample into an LLM to create\nknowledge-enhanced datasets. Subsequently, we train a LoRA block on the student\nmodel as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts\nfor problem-solving. Then, to imitate System 2 thinking, we train the Knowledge\nGenerator (KG) and Deep Reasoner (DR), respectively. The former outputs only\nknowledge after receiving problems, while the latter uses that knowledge to\nperform reasoning. Finally, to address the randomness in the generation of IR\nand DR, we evaluate whether their outputs are consistent, and the inference\nprocess needs to be iterated if not. This step can enhance the mathematical\nreasoning ability of SLMs through mutual feedback. Experimental results show\nthat LoRID achieves state-of-the-art performance, especially on the GSM8K\ndataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,\n12.3%, and 1.8% accuracy across the five base models, respectively."}
{"id": "2508.13047", "pdf": "https://arxiv.org/pdf/2508.13047", "abs": "https://arxiv.org/abs/2508.13047", "authors": ["Joni Salminen", "Danial Amin", "Bernard Jansen"], "title": "Using AI for User Representation: An Analysis of 83 Persona Prompts", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted at AICCSA-2025", "summary": "We analyzed 83 persona prompts from 27 research articles that used large\nlanguage models (LLMs) to generate user personas. Findings show that the\nprompts predominantly generate single personas. Several prompts express a\ndesire for short or concise persona descriptions, which deviates from the\ntradition of creating rich, informative, and rounded persona profiles. Text is\nthe most common format for generated persona attributes, followed by numbers.\nText and numbers are often generated together, and demographic attributes are\nincluded in nearly all generated personas. Researchers use up to 12 prompts in\na single study, though most research uses a small number of prompts. Comparison\nand testing multiple LLMs is rare. More than half of the prompts require the\npersona output in a structured format, such as JSON, and 74% of the prompts\ninsert data or dynamic variables. We discuss the implications of increased use\nof computational personas for user representation."}
{"id": "2508.13049", "pdf": "https://arxiv.org/pdf/2508.13049", "abs": "https://arxiv.org/abs/2508.13049", "authors": ["Tejas Chaudhari", "Akarsh J.", "Tanushree Dewangan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "XR-NPE: High-Throughput Mixed-precision SIMD Neural Processing Engine for Extended Reality Perception Workloads", "categories": ["cs.AR", "cs.AI", "cs.CV", "eess.IV"], "comment": null, "summary": "This work proposes XR-NPE, a high-throughput Mixed-precision SIMD Neural\nProcessing Engine, designed for extended reality (XR) perception workloads like\nvisual inertial odometry (VIO), object classification, and eye gaze extraction.\nXR-NPE is first to support FP4, Posit (4,1), Posit (8,0), and Posit (16,1)\nformats, with layer adaptive hybrid-algorithmic implementation supporting\nultra-low bit precision to significantly reduce memory bandwidth requirements,\nand accompanied by quantization-aware training for minimal accuracy loss. The\nproposed Reconfigurable Mantissa Multiplication and Exponent processing\nCircuitry (RMMEC) reduces dark silicon in the SIMD MAC compute engine, assisted\nby selective power gating to reduce energy consumption, providing 2.85x\nimproved arithmetic intensity. XR-NPE achieves a maximum operating frequency of\n1.72 GHz, area 0.016 mm2 , and arithmetic intensity 14 pJ at CMOS 28nm,\nreducing 42% area, 38% power compared to the best of state-of-the-art MAC\napproaches. The proposed XR-NPE based AXI-enabled Matrix-multiplication\nco-processor consumes 1.4x fewer LUTs, 1.77x fewer FFs, and provides 1.2x\nbetter energy efficiency compared to SoTA accelerators on VCU129. The proposed\nco-processor provides 23% better energy efficiency and 4% better compute\ndensity for VIO workloads. XR-NPE establishes itself as a scalable,\nprecision-adaptive compute engine for future resource-constrained XR devices.\nThe complete set for codes for results reproducibility are released publicly,\nenabling designers and researchers to readily adopt and build upon them.\nhttps://github.com/mukullokhande99/XR-NPE."}
{"id": "2508.13057", "pdf": "https://arxiv.org/pdf/2508.13057", "abs": "https://arxiv.org/abs/2508.13057", "authors": ["Adolfo González", "Víctor Parada"], "title": "Hierarchical Evaluation Function (HEF): A Multi-Metric Approach for Optimizing Demand Forecasting Models", "categories": ["cs.LG", "cs.AI", "cs.PF", "62M10, 90C59, 68T05", "I.2.6; I.5.1; I.5.2; I.5.4; G.1.6"], "comment": "31 pages, 15 figures, 110 tables. Submitted as a preprint. The\n  manuscript introduces the Hierarchical Evaluation Function (HEF), a\n  multi-metric framework for optimizing demand forecasting models under high\n  uncertainty. Includes extensive experimental validation using real-world\n  datasets and a comparative analysis against classical and modern methods", "summary": "Demand forecasting is essential for strategic planning in competitive\nenvironments, enabling resource optimization and improved responsiveness to\nmarket dynamics. However, multivariate time series modeling faces challenges\ndue to data complexity, uncertainty, and frequent regime shifts. Traditional\nevaluation metrics can introduce biases and limit generalization. This work\ncompares two custom evaluation functions: FMAE (Focused Mean Absolute Error),\nfocused on minimizing absolute errors, and HEF (Hierarchical Evaluation\nFunction), designed to weight global metrics and penalize large deviations.\nExperiments were conducted under different data splits (91:9, 80:20, 70:30)\nusing three optimizers (Grid Search, PSO, Optuna), assessing fit, relative\naccuracy, robustness, and computational efficiency. Results show that HEF\nconsistently outperforms FMAE in global metrics (R2, Relative Accuracy, RMSE,\nRMSSE), enhancing model robustness and explanatory power. These findings were\nconfirmed via visualizations and statistical tests. Conversely, FMAE offers\nadvantages in local metrics (MAE, MASE) and execution time, making it suitable\nfor short-term scenarios. The study highlights a methodological trade-off: HEF\nis ideal for strategic planning, while FMAE is better suited for operational\nefficiency. A replicable framework is proposed for optimizing predictive models\nin dynamic environments."}
{"id": "2508.13070", "pdf": "https://arxiv.org/pdf/2508.13070", "abs": "https://arxiv.org/abs/2508.13070", "authors": ["Long Ma", "Fangwei Zhong", "Yizhou Wang"], "title": "Reinforced Context Order Recovery for Adaptive Reasoning and Planning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Modern causal language models, followed by rapid developments in discrete\ndiffusion models, can now produce a wide variety of interesting and useful\ncontent. However, these families of models are predominantly trained to output\ntokens with a fixed (left-to-right) or random order, which may deviate from the\nlogical order in which tokens are generated originally. In this paper, we\nobserve that current causal and diffusion models encounter difficulties in\nproblems that require adaptive token generation orders to solve tractably,\nwhich we characterize with the $\\mathcal{V}$-information framework. Motivated\nby this, we propose Reinforced Context Order Recovery (ReCOR), a\nreinforcement-learning-based framework to extract adaptive, data-dependent\ntoken generation orders from text data without annotations. Self-supervised by\ntoken prediction statistics, ReCOR estimates the hardness of predicting every\nunfilled token and adaptively selects the next token during both training and\ninference. Experiments on challenging reasoning and planning datasets\ndemonstrate the superior performance of ReCOR compared with baselines,\nsometimes outperforming oracle models supervised with the ground-truth order."}
{"id": "2508.13077", "pdf": "https://arxiv.org/pdf/2508.13077", "abs": "https://arxiv.org/abs/2508.13077", "authors": ["Emmanuel Oladokun", "Yuxuan Ou", "Anna Novikova", "Daria Kulikova", "Sarina Thomas", "Jurica Šprem", "Vicente Grau"], "title": "From Transthoracic to Transesophageal: Cross-Modality Generation using LoRA Diffusion", "categories": ["eess.IV", "cs.AI"], "comment": "MICCAI 2025; ASMUS", "summary": "Deep diffusion models excel at realistic image synthesis but demand large\ntraining sets-an obstacle in data-scarce domains like transesophageal\nechocardiography (TEE). While synthetic augmentation has boosted performance in\ntransthoracic echo (TTE), TEE remains critically underrepresented, limiting the\nreach of deep learning in this high-impact modality.\n  We address this gap by adapting a TTE-trained, mask-conditioned diffusion\nbackbone to TEE with only a limited number of new cases and adapters as small\nas $10^5$ parameters. Our pipeline combines Low-Rank Adaptation with MaskR$^2$,\na lightweight remapping layer that aligns novel mask formats with the\npretrained model's conditioning channels. This design lets users adapt models\nto new datasets with a different set of anatomical structures to the base\nmodel's original set.\n  Through a targeted adaptation strategy, we find that adapting only MLP layers\nsuffices for high-fidelity TEE synthesis. Finally, mixing less than 200 real\nTEE frames with our synthetic echoes improves the dice score on a multiclass\nsegmentation task, particularly boosting performance on underrepresented\nright-heart structures. Our results demonstrate that (1) semantically\ncontrolled TEE images can be generated with low overhead, (2) MaskR$^2$\neffectively transforms unseen mask formats into compatible formats without\ndamaging downstream task performance, and (3) our method generates images that\nare effective for improving performance on a downstream task of multiclass\nsegmentation."}
{"id": "2508.13092", "pdf": "https://arxiv.org/pdf/2508.13092", "abs": "https://arxiv.org/abs/2508.13092", "authors": ["Xiang Long", "Yingjie Xia", "Xiyuan Chen", "Li Kuang"], "title": "VerilogLAVD: LLM-Aided Rule Generation for Vulnerability Detection in Verilog", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Timely detection of hardware vulnerabilities during the early design stage is\ncritical for reducing remediation costs. Existing early detection techniques\noften require specialized security expertise, limiting their usability. Recent\nefforts have explored the use of large language models (LLMs) for Verilog\nvulnerability detection. However, LLMs struggle to capture the structure in\nVerilog code, resulting in inconsistent detection results. To this end, we\npropose VerilogLAVD, the first LLM-aided graph traversal rule generation\napproach for Verilog vulnerability detection. Our approach introduces the\nVerilog Property Graph (VeriPG), a unified representation of Verilog code. It\ncombines syntactic features extracted from the abstract syntax tree (AST) with\nsemantic information derived from control flow and data dependency graphs. We\nleverage LLMs to generate VeriPG-based detection rules from Common Weakness\nEnumeration (CWE) descriptions. These rules guide the rule executor that\ntraversal VeriPG for potential vulnerabilities. To evaluate VerilogLAVD, we\nbuild a dataset collected from open-source repositories and synthesized data.\nIn our empirical evaluation on 77 Verilog designs encompassing 12 CWE types,\nVerilogLAVD achieves an F1-score of 0.54. Compared to the LLM-only and LLM with\nexternal knowledge baselines, VerilogLAVD improves F1-score by 0.31 and 0.27,\nrespectively."}
{"id": "2508.13113", "pdf": "https://arxiv.org/pdf/2508.13113", "abs": "https://arxiv.org/abs/2508.13113", "authors": ["Alicja Ziarko", "Michal Bortkiewicz", "Michal Zawalski", "Benjamin Eysenbach", "Piotr Milos"], "title": "Contrastive Representations for Temporal Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": "Project website: https://princeton-rl.github.io/CRTR/", "summary": "In classical AI, perception relies on learning state-based representations,\nwhile planning, which can be thought of as temporal reasoning over action\nsequences, is typically achieved through search. We study whether such\nreasoning can instead emerge from representations that capture both perceptual\nand temporal structure. We show that standard temporal contrastive learning,\ndespite its popularity, often fails to capture temporal structure due to its\nreliance on spurious features. To address this, we introduce Combinatorial\nRepresentations for Temporal Reasoning (CRTR), a method that uses a negative\nsampling scheme to provably remove these spurious features and facilitate\ntemporal reasoning. CRTR achieves strong results on domains with complex\ntemporal structure, such as Sokoban and Rubik's Cube. In particular, for the\nRubik's Cube, CRTR learns representations that generalize across all initial\nstates and allow it to solve the puzzle using fewer search steps than BestFS,\nthough with longer solutions. To our knowledge, this is the first method that\nefficiently solves arbitrary Cube states using only learned representations,\nwithout relying on an external search algorithm."}
{"id": "2508.13124", "pdf": "https://arxiv.org/pdf/2508.13124", "abs": "https://arxiv.org/abs/2508.13124", "authors": ["Kawin Mayilvaghanan", "Siddhant Gupta", "Ayush Kumar"], "title": "Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Abstractive summarization is a core application in contact centers, where\nLarge Language Models (LLMs) generate millions of summaries of call transcripts\ndaily. Despite their apparent quality, it remains unclear whether LLMs\nsystematically under- or over-attend to specific aspects of the transcript,\npotentially introducing biases in the generated summary. While prior work has\nexamined social and positional biases, the specific forms of bias pertinent to\ncontact center operations - which we term Operational Bias - have remained\nunexplored. To address this gap, we introduce BlindSpot, a framework built upon\na taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)\nfor the identification and quantification of these biases. BlindSpot leverages\nan LLM as a zero-shot classifier to derive categorical distributions for each\nbias dimension in a pair of transcript and its summary. The bias is then\nquantified using two metrics: Fidelity Gap (the JS Divergence between\ndistributions) and Coverage (the percentage of source labels omitted). Using\nBlindSpot, we conducted an empirical study with 2500 real call transcripts and\ntheir summaries generated by 20 LLMs of varying scales and families (e.g., GPT,\nLlama, Claude). Our analysis reveals that biases are systemic and present\nacross all evaluated models, regardless of size or family."}
{"id": "2508.13152", "pdf": "https://arxiv.org/pdf/2508.13152", "abs": "https://arxiv.org/abs/2508.13152", "authors": ["Xin Chen", "Junchao Wu", "Shu Yang", "Runzhe Zhan", "Zeyu Wu", "Ziyang Luo", "Di Wang", "Min Yang", "Lidia S. Chao", "Derek F. Wong"], "title": "RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to TACL 2025. This version is a pre-MIT Press publication\n  version", "summary": "Detecting content generated by large language models (LLMs) is crucial for\npreventing misuse and building trustworthy AI systems. Although existing\ndetection methods perform well, their robustness in out-of-distribution (OOD)\nscenarios is still lacking. In this paper, we hypothesize that, compared to\nfeatures used by existing detection methods, the internal representations of\nLLMs contain more comprehensive and raw features that can more effectively\ncapture and distinguish the statistical pattern differences between\nLLM-generated texts (LGT) and human-written texts (HWT). We validated this\nhypothesis across different LLMs and observed significant differences in neural\nactivation patterns when processing these two types of texts. Based on this, we\npropose RepreGuard, an efficient statistics-based detection method.\nSpecifically, we first employ a surrogate model to collect representation of\nLGT and HWT, and extract the distinct activation feature that can better\nidentify LGT. We can classify the text by calculating the projection score of\nthe text representations along this feature direction and comparing with a\nprecomputed threshold. Experimental results show that RepreGuard outperforms\nall baselines with average 94.92% AUROC on both in-distribution (ID) and OOD\nscenarios, while also demonstrating robust resilience to various text sizes and\nmainstream attacks. Data and code are publicly available at:\nhttps://github.com/NLP2CT/RepreGuard"}
