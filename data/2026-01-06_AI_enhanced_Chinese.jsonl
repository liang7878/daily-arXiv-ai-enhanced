{"id": "2601.01012", "pdf": "https://arxiv.org/pdf/2601.01012", "abs": "https://arxiv.org/abs/2601.01012", "authors": ["Max Dupr\u00e9 la Tour"], "title": "Bad News for Couples: Tight Lower Bounds for Fair Division of Indivisible Items", "categories": ["cs.GT"], "comment": null, "summary": "We consider the problem of fairly allocating indivisible goods to couples, where each couple consists of two agents with distinct additive valuations. We show that there exist instances of allocating indivisible items to $n$ couples for which envy-freeness up to $\u03a9(\\sqrt{n})$ items cannot be guaranteed. This closes the gap by matching the upper bound of Manurangsi and Suksompong, which applies to arbitrary instances with $n$ agents in total. This result is somewhat surprising, as that upper bound was conjectured not to be tight for instances consisting only of small groups.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2601.00979", "pdf": "https://arxiv.org/pdf/2601.00979", "abs": "https://arxiv.org/abs/2601.00979", "authors": ["Valentin Blomer", "Kai-Uwe Bux"], "title": "The cost of cyclic permutations and remainder sums in the Euclidean algorithm", "categories": ["cs.DS"], "comment": "32 pages, 7 figures", "summary": "We discuss a modification to the Gries-Mills block swapping scheme for in-place rotation with average costs of 1.85 moves per element and worst case performance still at 3 moves per element. Analysis of the average case relies on the asymptotic behavior of the sum of remainders in the Euclidean algorithm.", "AI": {"tldr": "\u8ba8\u8bbaGries - Mills\u5757\u4ea4\u6362\u65b9\u6848\u7684\u4fee\u6539\uff0c\u5e73\u5747\u6bcf\u5143\u7d20\u79fb\u52a81.85\u6b21\uff0c\u6700\u574f\u60c5\u51b53\u6b21\uff0c\u5e73\u5747\u60c5\u51b5\u5206\u6790\u4f9d\u8d56\u6b27\u51e0\u91cc\u5f97\u7b97\u6cd5\u4f59\u6570\u548c\u6e10\u8fd1\u884c\u4e3a\u3002", "motivation": "\u5bf9Gries - Mills\u5757\u4ea4\u6362\u65b9\u6848\u8fdb\u884c\u6539\u8fdb\uff0c\u4ee5\u4f18\u5316\u539f\u5730\u65cb\u8f6c\u7684\u5e73\u5747\u6210\u672c\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6b27\u51e0\u91cc\u5f97\u7b97\u6cd5\u4e2d\u4f59\u6570\u548c\u7684\u6e10\u8fd1\u884c\u4e3a\u6765\u8fdb\u884c\u6539\u8fdb\u65b9\u6848\u7684\u5206\u6790\u3002", "result": "\u63d0\u51fa\u7684\u4fee\u6539\u65b9\u6848\u5e73\u5747\u6bcf\u5143\u7d20\u79fb\u52a81.85\u6b21\uff0c\u6700\u574f\u60c5\u51b5\u4ecd\u4e3a3\u6b21\u3002", "conclusion": "\u8be5\u4fee\u6539\u65b9\u6848\u5728\u5e73\u5747\u79fb\u52a8\u6b21\u6570\u4e0a\u6709\u6240\u4f18\u5316\u3002"}}
{"id": "2601.01013", "pdf": "https://arxiv.org/pdf/2601.01013", "abs": "https://arxiv.org/abs/2601.01013", "authors": ["Philip N. Brown", "Connor McCormick"], "title": "Carroll Mechanisms: Opportunities, Challenges, and Agenda", "categories": ["cs.GT"], "comment": null, "summary": "The purpose of Carroll Mechanisms is to facilitate autonomous group sensemaking and reasoned decisionmaking by incentivizing participants to be transparent about their reasoning process, and to empower participants who are known to be capable of changing their minds. We envision Carroll Mechanisms to be built on top of a networked combinatorial LMSR foundation and thus to inherit the desriable properties of market scoring rules and automated market-makers. While we have made great strides during Fall 2025 in building out this foundation, several significant questions remain and several major new questions have arisen as a result of this work. The purpose of this document is to document the theoretical foundation, frame these questions clearly, and propose a research plan to address the questions.", "AI": {"tldr": "\u4ecb\u7ecdCarroll\u673a\u5236\u76ee\u7684\uff0c\u5176\u57fa\u4e8e\u7f51\u7edc\u7ec4\u5408LMSR\u6784\u5efa\uff0c\u867d\u6709\u8fdb\u5c55\u4f46\u4ecd\u6709\u95ee\u9898\uff0c\u672c\u6587\u8bb0\u5f55\u7406\u8bba\u57fa\u7840\u3001\u660e\u786e\u95ee\u9898\u5e76\u63d0\u51fa\u7814\u7a76\u8ba1\u5212\u3002", "motivation": "\u4fc3\u8fdb\u81ea\u4e3b\u7fa4\u4f53\u7684\u610f\u4e49\u5efa\u6784\u548c\u5408\u7406\u51b3\u7b56\uff0c\u6fc0\u52b1\u53c2\u4e0e\u8005\u900f\u660e\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u8d4b\u4e88\u80fd\u6539\u53d8\u60f3\u6cd5\u7684\u53c2\u4e0e\u8005\u6743\u529b\u3002", "method": "\u57fa\u4e8e\u7f51\u7edc\u7ec4\u5408LMSR\u6784\u5efaCarroll\u673a\u5236\uff0c\u672c\u6587\u8bb0\u5f55\u7406\u8bba\u57fa\u7840\u3001\u660e\u786e\u73b0\u5b58\u95ee\u9898\u5e76\u63d0\u51fa\u7814\u7a76\u8ba1\u5212\u3002", "result": "\u57282025\u5e74\u79cb\u5b63\u6784\u5efa\u57fa\u7840\u65b9\u9762\u53d6\u5f97\u4e86\u5f88\u5927\u8fdb\u5c55\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u91cd\u8981\u95ee\u9898\u5e76\u6709\u65b0\u95ee\u9898\u51fa\u73b0\u3002", "conclusion": "\u901a\u8fc7\u8bb0\u5f55\u7406\u8bba\u57fa\u7840\u3001\u660e\u786e\u95ee\u9898\u548c\u63d0\u51fa\u7814\u7a76\u8ba1\u5212\u6765\u8fdb\u4e00\u6b65\u63a8\u8fdb\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2601.01388", "pdf": "https://arxiv.org/pdf/2601.01388", "abs": "https://arxiv.org/abs/2601.01388", "authors": ["Seoyong Lee", "Jinho Lee"], "title": "AGIS: Fast Approximate Graph Pattern Mining with Structure-Informed Sampling", "categories": ["cs.DS"], "comment": "VLDB 2026", "summary": "Approximate Graph Pattern Mining (AGPM) is essential for analyzing large-scale graphs where exact counting is computationally prohibitive. While there exist numerous sampling-based AGPM systems, they all rely on uniform sampling and overlook the underlying probability distribution. This limitation restricts their scalability to a broader range of patterns.\n  In this paper, we introduce AGIS, an extremely fast AGPM system capable of counting arbitrary patterns from huge graphs. AGIS employs structure-informed neighbor sampling, a novel sampling technique that deviates from uniformness but allocates specific sampling probabilities based on the pattern structure. We first derive the ideal sampling distribution for AGPM and then present a practical method to approximate it. Furthermore, we develop a method that balances convergence speed and computational overhead, determining when to use the approximated distribution.\n  Experimental results demonstrate that AGIS significantly outperforms the state-of-the-art AGPM system, achieving 28.5x geometric mean speedup and more than 100,000x speedup in specific cases. Furthermore, AGIS is the only AGPM system that scales to graphs with tens of billions of edges and robustly handles diverse patterns, successfully providing accurate estimates within seconds. We will open-source AGIS to encourage further research in this field.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdAGIS\u7cfb\u7edf\u7528\u4e8e\u8fd1\u4f3c\u56fe\u6a21\u5f0f\u6316\u6398\uff0c\u4f7f\u7528\u7ed3\u6784\u611f\u77e5\u90bb\u57df\u91c7\u6837\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u8fdc\u8d85\u73b0\u6709\u7cfb\u7edf\u5e76\u5c06\u5f00\u6e90", "motivation": "\u73b0\u6709\u57fa\u4e8e\u91c7\u6837\u7684\u8fd1\u4f3c\u56fe\u6a21\u5f0f\u6316\u6398\u7cfb\u7edf\u4f9d\u8d56\u5747\u5300\u91c7\u6837\uff0c\u5ffd\u7565\u6f5c\u5728\u6982\u7387\u5206\u5e03\uff0c\u9650\u5236\u4e86\u5bf9\u66f4\u591a\u6a21\u5f0f\u7684\u53ef\u6269\u5c55\u6027", "method": "\u91c7\u7528\u7ed3\u6784\u611f\u77e5\u90bb\u57df\u91c7\u6837\uff0c\u63a8\u5bfc\u7406\u60f3\u91c7\u6837\u5206\u5e03\u5e76\u7ed9\u51fa\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5f00\u53d1\u5e73\u8861\u6536\u655b\u901f\u5ea6\u548c\u8ba1\u7b97\u5f00\u9500\u7684\u65b9\u6cd5", "result": "AGIS\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\uff0c\u5b9e\u73b028.5\u500d\u51e0\u4f55\u5e73\u5747\u52a0\u901f\uff0c\u7279\u5b9a\u60c5\u51b5\u4e0b\u8d8510\u4e07\u500d\u52a0\u901f\uff0c\u80fd\u5904\u7406\u6570\u5341\u4ebf\u8fb9\u7684\u56fe\u548c\u591a\u6837\u6a21\u5f0f\uff0c\u51e0\u79d2\u5185\u63d0\u4f9b\u51c6\u786e\u4f30\u8ba1", "conclusion": "AGIS\u6027\u80fd\u4f18\u5f02\uff0c\u5c06\u5f00\u6e90\u4ee5\u63a8\u52a8\u8be5\u9886\u57df\u7814\u7a76"}}
{"id": "2601.01496", "pdf": "https://arxiv.org/pdf/2601.01496", "abs": "https://arxiv.org/abs/2601.01496", "authors": ["Mikael M\u00f8ller H\u00f8gsgaard"], "title": "The Optimal Sample Complexity of Linear Contracts", "categories": ["cs.GT", "cs.AI", "cs.LG"], "comment": null, "summary": "In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\\varepsilon$-approximation of the optimal linear contract with probability at least $1-\u03b4$, using just $O(\\ln(1/\u03b4) / \\varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\\varepsilon$-approximation of its true expectation with probability at least $1-\u03b4$, using the same optimal $O(\\ln(1/\u03b4) / \\varepsilon^2)$ sample complexity.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u79bb\u7ebf\u73af\u5883\u4e0b\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u6700\u4f18\u7ebf\u6027\u5408\u7ea6\u95ee\u9898\uff0c\u8bc1\u660eEUM\u7b97\u6cd5\u7684\u6700\u4f18\u6027\u53ca\u6837\u672c\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5728\u79bb\u7ebf\u73af\u5883\u4e0b\uff0c\u5f53\u4ee3\u7406\u7c7b\u578b\u6765\u81ea\u672a\u77e5\u5206\u5e03\u65f6\uff0c\u59d4\u6258\u4eba\u8bbe\u8ba1\u6700\u5927\u5316\u671f\u671b\u6548\u7528\u7684\u6700\u4f18\u7ebf\u6027\u5408\u7ea6\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u94fe\u5f0f\u8bba\u8bc1\uff0c\u5229\u7528\u7ebf\u6027\u5408\u7ea6\u671f\u671b\u5956\u52b1\u975e\u9012\u51cf\u7684\u7ed3\u6784\u7279\u6027\u6784\u5efa\u7ec6\u7c92\u5ea6\u7f51\u7edc\u3002", "result": "EUM\u7b97\u6cd5\u4ee5\u81f3\u5c111 - \u03b4\u7684\u6982\u7387\u5f97\u5230\u6700\u4f18\u7ebf\u6027\u5408\u7ea6\u7684\u03b5 - \u8fd1\u4f3c\uff0c\u6837\u672c\u590d\u6742\u5ea6\u4e3aO(ln(1/\u03b4) / \u03b5\u00b2)\uff0c\u6539\u8fdb\u4e86\u5df2\u77e5\u8fb9\u754c\u5e76\u8bc1\u660e\u6700\u4f18\u6027\uff0c\u8fd8\u5efa\u7acb\u4e86\u4e00\u81f4\u6536\u655b\u7684\u66f4\u5f3a\u4fdd\u8bc1\u3002", "conclusion": "EUM\u7b97\u6cd5\u5728\u5b66\u4e60\u6700\u4f18\u7ebf\u6027\u5408\u7ea6\u65b9\u9762\u5177\u6709\u6700\u4f18\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u76f8\u5173\u95ee\u9898\u3002"}}
{"id": "2601.01390", "pdf": "https://arxiv.org/pdf/2601.01390", "abs": "https://arxiv.org/abs/2601.01390", "authors": ["Timothy M. Chan"], "title": "Derandomizing Pseudopolynomial Algorithms for Subset Sum", "categories": ["cs.DS"], "comment": "To appear in SODA 2026", "summary": "We reexamine the classical subset sum problem: given a set $X$ of $n$ positive integers and a number $t$, decide whether there exists a subset of $X$ that sums to $t$; or more generally, compute the set $\\mbox{out}$ of all numbers $y\\in\\{0,\\ldots,t\\}$ for which there exists a subset of $X$ that sums to $y$. Standard dynamic programming solves the problem in $O(tn)$ time. In SODA'17, two papers appeared giving the current best deterministic and randomized algorithms, ignoring polylogarithmic factors: Koiliaris and Xu's deterministic algorithm runs in $\\widetilde{O}(t\\sqrt{n})$ time, while Bringmann's randomized algorithm runs in $\\widetilde{O}(t)$ time. We present the first deterministic algorithm running in $\\widetilde{O}(t)$ time.\n  Our technique has a number of other applications: for example, we can also derandomize the more recent output-sensitive algorithms by Bringmann and Nakos [STOC'20] and Bringmann, Fischer, and Nakos [SODA'25] running in $\\widetilde{O}(|\\mbox{out}|^{4/3})$ and $\\widetilde{O}(|\\mbox{out}|\\sqrt{n})$ time, and we can derandomize a previous fine-grained reduction from 0-1 knapsack to min-plus convolution by Cygan et al. [ICALP'17].", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u786e\u5b9a\u6027\u7b97\u6cd5\u89e3\u51b3\u5b50\u96c6\u548c\u95ee\u9898\uff0c\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a \u00d5(t)\uff0c\u8be5\u6280\u672f\u8fd8\u6709\u5176\u4ed6\u5e94\u7528\u3002", "motivation": "\u6539\u8fdb\u7ecf\u5178\u5b50\u96c6\u548c\u95ee\u9898\u7684\u5df2\u6709\u7b97\u6cd5\uff0c\u5b9e\u73b0\u66f4\u5feb\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\u5e76\u89e3\u51b3\u76f8\u5173\u7b97\u6cd5\u7684\u53bb\u968f\u673a\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6280\u672f\u6765\u8bbe\u8ba1\u7b97\u6cd5\u3002", "result": "\u5f97\u5230\u9996\u4e2a\u8fd0\u884c\u65f6\u95f4\u4e3a \u00d5(t) \u7684\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u5bf9\u5176\u4ed6\u968f\u673a\u7b97\u6cd5\u8fdb\u884c\u53bb\u968f\u673a\u5316\u3002", "conclusion": "\u65b0\u7b97\u6cd5\u548c\u6280\u672f\u5728\u5b50\u96c6\u548c\u95ee\u9898\u53ca\u76f8\u5173\u95ee\u9898\u4e0a\u6709\u8f83\u597d\u8868\u73b0\uff0c\u63d0\u5347\u4e86\u7b97\u6cd5\u6548\u7387\u548c\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2601.01607", "pdf": "https://arxiv.org/pdf/2601.01607", "abs": "https://arxiv.org/abs/2601.01607", "authors": ["Sergiu Hart", "Noam Nisan"], "title": "Existence of Optimal Mechanisms for Selling Multiple Goods: An Elementary Proof", "categories": ["cs.GT"], "comment": null, "summary": "We provide an elementary proof that revenue-maximizing mechanisms exist in multi-parameter settings whenever the distribution of valuations has finite expectation.", "AI": {"tldr": "\u63d0\u4f9b\u591a\u53c2\u6570\u8bbe\u7f6e\u4e0b\uff0c\u4f30\u503c\u5206\u5e03\u6709\u6709\u9650\u671f\u671b\u65f6\u6536\u76ca\u6700\u5927\u5316\u673a\u5236\u5b58\u5728\u7684\u521d\u7b49\u8bc1\u660e", "motivation": "\u8bc1\u660e\u591a\u53c2\u6570\u8bbe\u7f6e\u4e0b\u6536\u76ca\u6700\u5927\u5316\u673a\u5236\u7684\u5b58\u5728\u6027", "method": "\u4f7f\u7528\u521d\u7b49\u8bc1\u660e\u65b9\u6cd5", "result": "\u8bc1\u660e\u6536\u76ca\u6700\u5927\u5316\u673a\u5236\u5b58\u5728", "conclusion": "\u5728\u4f30\u503c\u5206\u5e03\u6709\u6709\u9650\u671f\u671b\u7684\u591a\u53c2\u6570\u8bbe\u7f6e\u4e2d\uff0c\u5b58\u5728\u6536\u76ca\u6700\u5927\u5316\u7684\u673a\u5236"}}
{"id": "2601.01710", "pdf": "https://arxiv.org/pdf/2601.01710", "abs": "https://arxiv.org/abs/2601.01710", "authors": ["Kevin Pfisterer", "Quentin Hillebrand", "Vorapong Suppakitpaisarn"], "title": "Publishing Below-Threshold Triangle Counts under Local Weight Differential Privacy", "categories": ["cs.DS"], "comment": null, "summary": "We propose an algorithm for counting below-threshold triangles in weighted graphs under local weight differential privacy. While prior work focused on unweighted graphs, many real-world networks naturally include edge weights. We study the setting where the graph topology is public known and the privacy of the influence of an individual on the edge weights is protected. This captures realistic scenarios such as road networks and telecommunication networks. Our approach consists of two rounds of communication. In the first round, each node publishes their incident weight information under local weight differential privacy while in the second round, the nodes locally count below-threshold triangles, for which we introduce a biased and unbiased variant. We further propose two different improvements. We present a pre-computation step that reduces the covariance and thereby lowers the expected error. Secondly, we develop an algorithm for computing the smooth-sensitivity, which significantly reduces the running time compared to a straightforward approach. Finally, we provide experimental results that demonstrate the differences between the biased and unbiased variants and the effectiveness of the proposed improvements.", "AI": {"tldr": "\u63d0\u51fa\u5728\u5c40\u90e8\u6743\u91cd\u5dee\u5206\u9690\u79c1\u4e0b\u5bf9\u52a0\u6743\u56fe\u4e2d\u4f4e\u4e8e\u9608\u503c\u4e09\u89d2\u5f62\u8ba1\u6570\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e24\u8f6e\u901a\u4fe1\u5b9e\u73b0\uff0c\u6709\u6539\u8fdb\u63aa\u65bd\u5e76\u7ed9\u51fa\u5b9e\u9a8c\u7ed3\u679c\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u96c6\u4e2d\u4e8e\u65e0\u6743\u56fe\uff0c\u800c\u73b0\u5b9e\u7f51\u7edc\u591a\u542b\u8fb9\u6743\u91cd\uff0c\u9700\u4fdd\u62a4\u4e2a\u4f53\u5bf9\u8fb9\u6743\u91cd\u5f71\u54cd\u7684\u9690\u79c1\u3002", "method": "\u7b97\u6cd5\u5305\u542b\u4e24\u8f6e\u901a\u4fe1\uff0c\u9996\u8f6e\u8282\u70b9\u6309\u5c40\u90e8\u6743\u91cd\u5dee\u5206\u9690\u79c1\u53d1\u5e03\u6743\u91cd\u4fe1\u606f\uff0c\u6b21\u8f6e\u672c\u5730\u8ba1\u6570\u4f4e\u4e8e\u9608\u503c\u4e09\u89d2\u5f62\uff0c\u6709\u504f\u548c\u65e0\u504f\u4e24\u79cd\u53d8\u4f53\uff0c\u5e76\u6709\u51cf\u5c11\u534f\u65b9\u5dee\u548c\u8ba1\u7b97\u5e73\u6ed1\u654f\u611f\u5ea6\u7684\u6539\u8fdb\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u4e86\u6709\u504f\u548c\u65e0\u504f\u53d8\u4f53\u7684\u5dee\u5f02\u53ca\u6539\u8fdb\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u53ca\u6539\u8fdb\u63aa\u65bd\u5728\u52a0\u6743\u56fe\u4f4e\u4e8e\u9608\u503c\u4e09\u89d2\u5f62\u8ba1\u6570\u4e0a\u6709\u6548\u4e14\u80fd\u4fdd\u62a4\u9690\u79c1\u3002"}}
{"id": "2601.01031", "pdf": "https://arxiv.org/pdf/2601.01031", "abs": "https://arxiv.org/abs/2601.01031", "authors": ["Bharadwaj Veeravalli"], "title": "A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations", "categories": ["cs.DC", "cs.PF"], "comment": null, "summary": "We develop an integrated Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for relay-centric distributed satellite systems (DSS), capturing concurrent data dissemination, parallel computation, and result return under heterogeneous onboard processing and inter-satellite link conditions. We propose a formulation that yields closed-form expressions for optimal load allocation and completion time that explicitly quantify the joint impact of computation speed, link bandwidth, and result-size overhead. We further derive deadline feasibility conditions that enable explicit sizing of cooperative satellite clusters to meet time-critical task requirements. Extensive simulation results demonstrate that highly distributable tasks achieve substantial latency reduction, while communication-heavy tasks exhibit diminishing returns due to result-transfer overheads. To bridge theory and practice, we extend the MPCC-DLT framework with a real-time admission control mechanism that handles stochastic task arrivals and deadline constraints, enabling blocking-aware operation. Our real-time simulations illustrate how task structure and system parameters jointly govern deadline satisfaction and operating regimes. Overall, this work provides the first analytically tractable MPCC-DLT model for distributed satellite systems and offers actionable insights for application-aware scheduling and system-level design of future satellite constellations.", "AI": {"tldr": "\u672c\u6587\u4e3a\u4ee5\u4e2d\u7ee7\u4e3a\u4e2d\u5fc3\u7684\u5206\u5e03\u5f0f\u536b\u661f\u7cfb\u7edf\u5f00\u53d1\u4e86MPCC - DLT\u6846\u67b6\uff0c\u7ed9\u51fa\u6700\u4f18\u8d1f\u8f7d\u5206\u914d\u548c\u5b8c\u6210\u65f6\u95f4\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u63a8\u5bfc\u671f\u9650\u53ef\u884c\u6027\u6761\u4ef6\uff0c\u901a\u8fc7\u6a21\u62df\u5c55\u793a\u4efb\u52a1\u6027\u80fd\uff0c\u8fd8\u6dfb\u52a0\u5b9e\u65f6\u51c6\u5165\u63a7\u5236\u673a\u5236\uff0c\u63d0\u4f9b\u4e86\u53ef\u5206\u6790\u7684\u6a21\u578b\u3002", "motivation": "\u4e3a\u5206\u5e03\u5f0f\u536b\u661f\u7cfb\u7edf\u5728\u5f02\u6784\u661f\u8f7d\u5904\u7406\u548c\u661f\u95f4\u94fe\u8def\u6761\u4ef6\u4e0b\u5b9e\u73b0\u5e76\u53d1\u6570\u636e\u4f20\u64ad\u3001\u5e76\u884c\u8ba1\u7b97\u548c\u7ed3\u679c\u8fd4\u56de\uff0c\u63d0\u4f9b\u5206\u6790\u6a21\u578b\u7528\u4e8e\u5e94\u7528\u611f\u77e5\u8c03\u5ea6\u548c\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u3002", "method": "\u5f00\u53d1MPCC - DLT\u6846\u67b6\uff0c\u63a8\u5bfc\u6700\u4f18\u8d1f\u8f7d\u5206\u914d\u3001\u5b8c\u6210\u65f6\u95f4\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u548c\u671f\u9650\u53ef\u884c\u6027\u6761\u4ef6\uff0c\u6dfb\u52a0\u5b9e\u65f6\u51c6\u5165\u63a7\u5236\u673a\u5236\uff0c\u8fdb\u884c\u5927\u91cf\u4eff\u771f\u548c\u5b9e\u65f6\u6a21\u62df\u3002", "result": "\u9ad8\u53ef\u5206\u5e03\u5f0f\u4efb\u52a1\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\uff0c\u901a\u4fe1\u5bc6\u96c6\u578b\u4efb\u52a1\u56e0\u7ed3\u679c\u4f20\u8f93\u5f00\u9500\u6536\u76ca\u9012\u51cf\uff0c\u5b9e\u65f6\u6a21\u62df\u5c55\u73b0\u4efb\u52a1\u7ed3\u6784\u548c\u7cfb\u7edf\u53c2\u6570\u5bf9\u671f\u9650\u6ee1\u8db3\u548c\u8fd0\u884c\u673a\u5236\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u5206\u6790\u7684MPCC - DLT\u6a21\u578b\uff0c\u4e3a\u672a\u6765\u536b\u661f\u661f\u5ea7\u7684\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u884c\u52a8\u6027\u89c1\u89e3\u3002"}}
{"id": "2601.00967", "pdf": "https://arxiv.org/pdf/2601.00967", "abs": "https://arxiv.org/abs/2601.00967", "authors": ["Pierre Bourhis", "Cristian Riveros", "Amaranta Salas"], "title": "A formal query language and automata model for aggregation in complex event recognition", "categories": ["cs.DB", "cs.FL", "cs.LO"], "comment": null, "summary": "Complex Event Recognition (CER) systems are used to identify complex patterns in event streams, such as those found in stock markets, sensor networks, and other similar applications. An important task in such patterns is aggregation, which involves summarizing a set of values into a single value using an algebraic function, such as the maximum, sum, or average, among others. Despite the relevance of this task, query languages in CER typically support aggregation in a restricted syntactic form, and their semantics are generally undefined.\n  In this work, we present a first step toward formalizing a query language with aggregation for CER. We propose to extend Complex Event Logic (CEL), a formal query language for CER, with aggregation operations. This task requires revisiting the semantics of CEL, using a new semantics based on bags of tuples instead of sets of positions. Then, we present an extension of CEL, called Aggregation CEL (ACEL), which introduces an aggregation operator for any commutative monoid operation. The operator can be freely composed with previous CEL operators, allowing users to define complex queries and patterns. We showcase several queries in practice where ACEL proves to be natural for specifying them. From the computational side, we present a novel automata model, called Aggregation Complex Event Automata (ACEA), that extends the previous proposal of Complex Event Automata (CEA) with aggregation and filtering features. Moreover, we demonstrate that every query in ACEL can be expressed in ACEA, illustrating the effectiveness of our computational model. Finally, we study the expressiveness of ACEA through the lens of ACEL, showing that the automata model is more expressive than ACEL.", "AI": {"tldr": "\u672c\u6587\u4e3a\u590d\u6742\u4e8b\u4ef6\u8bc6\u522b\uff08CER\uff09\u5e26\u805a\u5408\u529f\u80fd\u7684\u67e5\u8be2\u8bed\u8a00\u5f62\u5f0f\u5316\u8fc8\u51fa\u7b2c\u4e00\u6b65\uff0c\u6269\u5c55CEL\u4e3aACEL\uff0c\u63d0\u51faACEA\u81ea\u52a8\u673a\u6a21\u578b\u5e76\u7814\u7a76\u5176\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "CER\u67e5\u8be2\u8bed\u8a00\u5bf9\u805a\u5408\u7684\u652f\u6301\u8bed\u6cd5\u53d7\u9650\u4e14\u8bed\u4e49\u4e0d\u660e\u786e\uff0c\u9700\u5bf9\u5e26\u805a\u5408\u7684\u67e5\u8be2\u8bed\u8a00\u8fdb\u884c\u5f62\u5f0f\u5316\u3002", "method": "\u6269\u5c55CEL\u4e3aACEL\uff0c\u5f15\u5165\u805a\u5408\u8fd0\u7b97\u7b26\uff1b\u63d0\u51faACEA\u81ea\u52a8\u673a\u6a21\u578b\uff1b\u7814\u7a76ACEA\u5728ACEL\u89c6\u89d2\u4e0b\u7684\u8868\u8fbe\u80fd\u529b\u3002", "result": "ACEL\u80fd\u81ea\u7136\u5730\u5b9a\u4e49\u590d\u6742\u67e5\u8be2\u548c\u6a21\u5f0f\uff1b\u6bcf\u4e2aACEL\u67e5\u8be2\u90fd\u80fd\u7528ACEA\u8868\u8fbe\uff1bACEA\u6bd4ACEL\u66f4\u5177\u8868\u8fbe\u529b\u3002", "conclusion": "\u4e3aCER\u5e26\u805a\u5408\u7684\u67e5\u8be2\u8bed\u8a00\u5f62\u5f0f\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u548c\u6a21\u578b\uff0cACEA\u6709\u66f4\u597d\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2601.01657", "pdf": "https://arxiv.org/pdf/2601.01657", "abs": "https://arxiv.org/abs/2601.01657", "authors": ["Jo\u00e3o Alves Ribeiro", "Francisco Pimenta", "Bruno Alves Ribeiro", "S\u00e9rgio M. O. Tavares", "Faez Ahmed"], "title": "FLOAT: Fatigue-Aware Design Optimization of Floating Offshore Wind Turbine Towers", "categories": ["cs.CE"], "comment": "Public code available at: https://github.com/Joao97ribeiro/FLOAT", "summary": "Upscaling is central to offshore wind's cost-reduction strategy, with increasingly large rotors and nacelles requiring taller and stronger towers. In Floating Offshore Wind Turbines (FOWTs), this trend amplifies fatigue loads due to coupled wind-wave dynamics and platform motion. Conventional fatigue evaluation requires millions of high-fidelity simulations, creating prohibitive computational costs and slowing design innovation. This paper presents FLOAT (Fatigue-aware Lightweight Optimization and Analysis for Towers), a framework that accelerates fatigue-aware tower design. It integrates three key contributions: a lightweight fatigue estimation method that enables efficient optimization, a Monte Carlo-based probabilistic wind-wave sampling approach that reduces required simulations, and enhanced high-fidelity modeling through pitch/heave-platform calibration and High-Performance Computing execution. The framework is applied to the IEA 22 MW FOWT tower, delivering, to the authors' knowledge, the first fatigue-oriented redesign of this benchmark model: FLOAT 22 MW FOWT tower. Validation against 6,468 simulations shows that the optimized tower extends the estimated fatigue life from 9 months to 25 years while avoiding resonance, and that the lightweight fatigue estimator provides conservative predictions with a mean relative error of -8.6%. Achieving this lifetime requires increased tower mass, yielding the lowest-mass fatigue-compliant design. All results and the reported lifetime extension are obtained within the considered fatigue scope (DLC 1.2, aligned wind-wave conditions). By reducing simulation requirements by orders of magnitude, FLOAT enables reliable and scalable tower design for next-generation FOWTs, bridging industrial needs and academic research while generating high-fidelity datasets that can support data-driven and AI-assisted design methodologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa FLOAT \u6846\u67b6\u52a0\u901f\u6d6e\u5f0f\u6d77\u4e0a\u98ce\u529b\u53d1\u7535\u673a\u5854\u67b6\u75b2\u52b3\u8bbe\u8ba1\uff0c\u5e94\u7528\u4e8e IEA 22 MW FOWT \u5854\u67b6\uff0c\u4f18\u5316\u540e\u5854\u67b6\u5ef6\u957f\u75b2\u52b3\u5bff\u547d\uff0c\u51cf\u5c11\u6a21\u62df\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u75b2\u52b3\u8bc4\u4f30\u9700\u5927\u91cf\u9ad8\u4fdd\u771f\u6a21\u62df\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u963b\u788d\u6d6e\u5f0f\u6d77\u4e0a\u98ce\u529b\u53d1\u7535\u673a\u5854\u67b6\u8bbe\u8ba1\u521b\u65b0\u3002", "method": "\u63d0\u51fa FLOAT \u6846\u67b6\uff0c\u5305\u542b\u8f7b\u91cf\u7ea7\u75b2\u52b3\u4f30\u8ba1\u65b9\u6cd5\u3001\u57fa\u4e8e\u8499\u7279\u5361\u7f57\u7684\u98ce\u6d6a\u6982\u7387\u91c7\u6837\u65b9\u6cd5\u53ca\u901a\u8fc7\u53d8\u6868/\u5347\u6c89\u5e73\u53f0\u6821\u51c6\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u6267\u884c\u589e\u5f3a\u7684\u9ad8\u4fdd\u771f\u5efa\u6a21\u3002", "result": "\u4f18\u5316\u540e\u7684\u5854\u67b6\u5c06\u4f30\u8ba1\u75b2\u52b3\u5bff\u547d\u4ece 9 \u4e2a\u6708\u5ef6\u957f\u81f3 25 \u5e74\uff0c\u540c\u65f6\u907f\u514d\u5171\u632f\uff0c\u8f7b\u91cf\u7ea7\u75b2\u52b3\u4f30\u8ba1\u5668\u63d0\u4f9b\u4fdd\u5b88\u9884\u6d4b\uff0c\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4e3a -8.6%\u3002", "conclusion": "FLOAT \u6846\u67b6\u5927\u5e45\u51cf\u5c11\u6a21\u62df\u9700\u6c42\uff0c\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u4e0b\u4e00\u4ee3\u6d6e\u5f0f\u6d77\u4e0a\u98ce\u529b\u53d1\u7535\u673a\u5854\u67b6\u8bbe\u8ba1\uff0c\u5f25\u5408\u5de5\u4e1a\u9700\u6c42\u4e0e\u5b66\u672f\u7814\u7a76\u5dee\u8ddd\u3002"}}
{"id": "2601.00833", "pdf": "https://arxiv.org/pdf/2601.00833", "abs": "https://arxiv.org/abs/2601.00833", "authors": ["Tangtang Wang", "Kaijie Zhang", "Kuangcong Liu"], "title": "A Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System for Advertisement Retrieval and Personalization", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "In modern digital marketing, the growing complexity of advertisement data demands intelligent systems capable of understanding semantic relationships among products, audiences, and advertising content. To address this challenge, this paper proposes a Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System (KGSR-ADS) for advertisement retrieval and personalization. The proposed framework integrates a heterogeneous Ad-Knowledge Graph (Ad-KG) that captures multi-relational semantics, a Semantic Embedding Layer that leverages large language models (LLMs) such as GPT and LLaMA to generate context-aware vector representations, a GNN + Attention Model that infers cross-entity dependencies, and a Database Optimization & Retrieval Layer based on vector indexing (FAISS/Milvus) for efficient semantic search. This layered architecture enables both accurate semantic matching and scalable retrieval, allowing personalized ad recommendations under large-scale heterogeneous workloads.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u8bed\u4e49\u63a8\u8350\u6570\u636e\u5e93\u7cfb\u7edfKGSR - ADS\u7528\u4e8e\u5e7f\u544a\u68c0\u7d22\u548c\u4e2a\u6027\u5316\uff0c\u67b6\u6784\u80fd\u5b9e\u73b0\u51c6\u786e\u8bed\u4e49\u5339\u914d\u548c\u53ef\u6269\u5c55\u68c0\u7d22\u3002", "motivation": "\u73b0\u4ee3\u6570\u5b57\u8425\u9500\u4e2d\u5e7f\u544a\u6570\u636e\u590d\u6742\uff0c\u9700\u8981\u80fd\u7406\u89e3\u4ea7\u54c1\u3001\u53d7\u4f17\u548c\u5e7f\u544a\u5185\u5bb9\u8bed\u4e49\u5173\u7cfb\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u63d0\u51faKGSR - ADS\u7cfb\u7edf\uff0c\u6574\u5408Ad - KG\u3001\u8bed\u4e49\u5d4c\u5165\u5c42\u3001GNN + \u6ce8\u610f\u529b\u6a21\u578b\u548c\u57fa\u4e8e\u5411\u91cf\u7d22\u5f15\u7684\u6570\u636e\u5e93\u4f18\u5316\u4e0e\u68c0\u7d22\u5c42\u3002", "result": "\u8be5\u5206\u5c42\u67b6\u6784\u53ef\u5b9e\u73b0\u51c6\u786e\u8bed\u4e49\u5339\u914d\u548c\u53ef\u6269\u5c55\u68c0\u7d22\u3002", "conclusion": "KGSR - ADS\u7cfb\u7edf\u53ef\u5728\u5927\u89c4\u6a21\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8fdb\u884c\u4e2a\u6027\u5316\u5e7f\u544a\u63a8\u8350\u3002"}}
{"id": "2601.00974", "pdf": "https://arxiv.org/pdf/2601.00974", "abs": "https://arxiv.org/abs/2601.00974", "authors": ["Inna Voloshchuk", "Hayden Jananthan", "Chansup Byun", "Jeremy Kepner"], "title": "Improving the Graph Challenge Reference Implementation", "categories": ["cs.NI", "cs.DM", "cs.PF", "cs.SE"], "comment": "Presented at IEEE MIT URTC 2025", "summary": "The MIT/IEEE/Amazon Graph Challenge provides a venue for individuals and teams to showcase new innovations in large-scale graph and sparse data analysis. The Anonymized Network Sensing Graph Challenge processes over 100 billion network packets to construct privacy-preserving traffic matrices, with a GraphBLAS reference implementation demonstrating how hypersparse matrices can be applied to this problem. This work presents a refactoring and benchmarking of a section of the reference code to improve clarity, adaptability, and performance. The original Python implementation spanning approximately 1000 lines across 3 files has been streamlined to 325 lines across two focused modules, achieving a 67% reduction in code size while maintaining full functionality. Using pMatlab and pPython distributed array programming libraries, the addition of parallel maps allowed for parallel benchmarking of the data. Scalable performance is demonstrated for large-scale summation and analysis of traffic matrices. The resulting implementation increases the potential impact of the Graph Challenge by providing a clear and efficient foundation for participants.", "AI": {"tldr": "\u672c\u6587\u5bf9MIT/IEEE/Amazon\u56fe\u6311\u6218\u4e2d\u53c2\u8003\u4ee3\u7801\u7684\u90e8\u5206\u5185\u5bb9\u8fdb\u884c\u91cd\u6784\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cbe\u7b80\u4ee3\u7801\u5e76\u5b9e\u73b0\u5e76\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u6027\u80fd\uff0c\u4e3a\u53c2\u4e0e\u8005\u63d0\u4f9b\u6e05\u6670\u9ad8\u6548\u57fa\u7840\u3002", "motivation": "\u539f\u53c2\u8003\u4ee3\u7801\u5b58\u5728\u6e05\u6670\u5ea6\u3001\u9002\u5e94\u6027\u548c\u6027\u80fd\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u63d0\u9ad8\u56fe\u6311\u6218\u7684\u5f71\u54cd\u529b\u3002", "method": "\u5bf9\u539fPython\u53c2\u8003\u4ee3\u7801\u8fdb\u884c\u91cd\u6784\uff0c\u5c06\u7ea61000\u884c\u4ee3\u7801\u7cbe\u7b80\u5230325\u884c\uff0c\u4f7f\u7528pMatlab\u548cpPython\u5206\u5e03\u5f0f\u6570\u7ec4\u7f16\u7a0b\u5e93\u8fdb\u884c\u5e76\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4ee3\u7801\u89c4\u6a21\u7f29\u5c0f67%\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u6574\u529f\u80fd\uff0c\u5c55\u793a\u4e86\u5927\u89c4\u6a21\u6d41\u91cf\u77e9\u9635\u6c42\u548c\u4e0e\u5206\u6790\u7684\u53ef\u6269\u5c55\u6027\u80fd\u3002", "conclusion": "\u6539\u8fdb\u540e\u7684\u5b9e\u73b0\u4e3a\u56fe\u6311\u6218\u53c2\u4e0e\u8005\u63d0\u4f9b\u4e86\u6e05\u6670\u9ad8\u6548\u7684\u57fa\u7840\uff0c\u589e\u52a0\u4e86\u56fe\u6311\u6218\u7684\u6f5c\u5728\u5f71\u54cd\u529b\u3002"}}
{"id": "2601.00815", "pdf": "https://arxiv.org/pdf/2601.00815", "abs": "https://arxiv.org/abs/2601.00815", "authors": ["Mara Kalicanin Dimitrov", "Marko Dimitrov", "Anatoliy Malyarenko", "Ying Ni"], "title": "Almost-Exact Simulation Scheme for Heston-type Models: Bermudan and American Option Pricing", "categories": ["q-fin.PR", "math.PR", "q-fin.CP"], "comment": "20 pages, 4 figures. Revised version under consideration for publication", "summary": "Recently, an Almost-Exact Simulation (AES) scheme was introduced for the Heston stochastic volatility model and tested for European option pricing. This paper extends this scheme for pricing Bermudan and American options under both Heston and double Heston models. The AES improves Monte Carlo simulation efficiency by using the non-central chi-square distribution for the variance process. We derive the AES scheme for the double Heston model and compare the performance of the AES schemes under both models with the Euler scheme. Our numerical experiments validate the effectiveness of the AES scheme in providing accurate option prices with reduced computational time, highlighting its robustness for both models. In particular, the AES achieves higher accuracy and computational efficiency when the number of simulation steps matches the exercise dates for Bermudan options.", "AI": {"tldr": "\u672c\u6587\u5c06AES\u65b9\u6848\u6269\u5c55\u5230Heston\u548c\u53ccHeston\u6a21\u578b\u4e0b\u767e\u6155\u5927\u4e0e\u7f8e\u5f0f\u671f\u6743\u5b9a\u4ef7\uff0c\u5bf9\u6bd4AES\u4e0eEuler\u65b9\u6848\uff0c\u5b9e\u9a8c\u9a8c\u8bc1AES\u9ad8\u6548\u51c6\u786e\u3002", "motivation": "\u5df2\u6709\u7684AES\u7528\u4e8eHeston\u6a21\u578b\u6b27\u6d32\u671f\u6743\u5b9a\u4ef7\uff0c\u5c06\u5176\u6269\u5c55\u5230\u767e\u6155\u5927\u4e0e\u7f8e\u5f0f\u671f\u6743\u5b9a\u4ef7\u3002", "method": "\u63a8\u5bfc\u53ccHeston\u6a21\u578b\u7684AES\u65b9\u6848\uff0c\u5e76\u4e0eEuler\u65b9\u6848\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660eAES\u65b9\u6848\u80fd\u4ee5\u51cf\u5c11\u7684\u8ba1\u7b97\u65f6\u95f4\u63d0\u4f9b\u51c6\u786e\u7684\u671f\u6743\u4ef7\u683c\u3002", "conclusion": "AES\u65b9\u6848\u5bf9\u4e24\u79cd\u6a21\u578b\u5747\u7a33\u5065\uff0c\u5728\u6a21\u62df\u6b65\u6570\u4e0e\u767e\u6155\u5927\u671f\u6743\u884c\u6743\u65e5\u5339\u914d\u65f6\u66f4\u9ad8\u6548\u51c6\u786e\u3002"}}
{"id": "2601.00802", "pdf": "https://arxiv.org/pdf/2601.00802", "abs": "https://arxiv.org/abs/2601.00802", "authors": ["Hou Yue", "Xiang Shuiying", "Zou Tao", "Huang Zhiquan", "Shi Shangxuan", "Guo Xingxing", "Zhang Yahui", "Zheng Ling", "Hao Yue"], "title": "Implementation of high-efficiency, lightweight residual spiking neural network processor based on field-programmable gate arrays", "categories": ["cs.NE"], "comment": null, "summary": "With the development of hardware-optimized deployment of spiking neural networks (SNNs), SNN processors based on field-programmable gate arrays (FPGAs) have become a research hotspot due to their efficiency and flexibility. However, existing methods rely on multi-timestep training and reconfigurable computing architectures, which increases computational and memory overhead, thus reducing deployment efficiency. This work presents an efficient and lightweight residual SNN accelerator that combines algorithm and hardware co-design to optimize inference energy efficiency. In terms of the algorithm, we employ single-timesteps training, integrate grouped convolutions, and fuse batch normalization (BN) layers, thus compressing the network to only 0.69M parameters. Quantization-aware training (QAT) further constrains all parameters to 8-bit precision. In terms of hardware, the reuse of intra-layer resources maximizes FPGA utilization, a full pipeline cross-layer architecture improves throughput, and on-chip block RAM (BRAM) stores network parameters and intermediate results to improve memory efficiency. The experimental results show that the proposed processor achieves a classification accuracy of 87.11% on the CIFAR-10 dataset, with an inference time of 3.98 ms per image and an energy efficiency of 183.5 FPS/W. Compared with mainstream graphics processing unit (GPU) platforms, it achieves more than double the energy efficiency. Furthermore, compared with other SNN processors, it achieves at least a 4x faster inference speed and a 5x higher energy efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9ad8\u6548\u8f7b\u91cf\u7ea7\u6b8b\u5deeSNN\u52a0\u901f\u5668\uff0c\u7ed3\u5408\u7b97\u6cd5\u4e0e\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u4f18\u5316\u63a8\u7406\u80fd\u6548\uff0c\u5b9e\u9a8c\u663e\u793a\u5728CIFAR - 10\u6570\u636e\u96c6\u8868\u73b0\u826f\u597d\uff0c\u80fd\u6548\u4f18\u4e8eGPU\u548c\u5176\u4ed6SNN\u5904\u7406\u5668\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eFPGA\u7684SNN\u5904\u7406\u5668\u65b9\u6cd5\u4f9d\u8d56\u591a\u65f6\u95f4\u6b65\u8bad\u7ec3\u548c\u53ef\u91cd\u6784\u8ba1\u7b97\u67b6\u6784\uff0c\u589e\u52a0\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\uff0c\u964d\u4f4e\u90e8\u7f72\u6548\u7387\u3002", "method": "\u7b97\u6cd5\u4e0a\u91c7\u7528\u5355\u65f6\u95f4\u6b65\u8bad\u7ec3\u3001\u96c6\u6210\u5206\u7ec4\u5377\u79ef\u3001\u878d\u5408BN\u5c42\u538b\u7f29\u7f51\u7edc\uff0c\u7528QAT\u7ea6\u675f\u53c2\u6570\u7cbe\u5ea6\uff1b\u786c\u4ef6\u4e0a\u91cd\u7528\u5c42\u5185\u8d44\u6e90\u3001\u91c7\u7528\u5168\u6d41\u6c34\u7ebf\u8de8\u5c42\u67b6\u6784\u3001\u7528\u7247\u4e0aBRAM\u5b58\u50a8\u6570\u636e\u3002", "result": "\u5728CIFAR - 10\u6570\u636e\u96c6\u5206\u7c7b\u51c6\u786e\u738787.11%\uff0c\u5355\u5f20\u56fe\u50cf\u63a8\u7406\u65f6\u95f43.98ms\uff0c\u80fd\u6548183.5 FPS/W\uff0c\u80fd\u6548\u8d85GPU\u4e24\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u81f3\u5c11\u5feb4\u500d\uff0c\u80fd\u6548\u81f3\u5c11\u9ad85\u500d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SNN\u52a0\u901f\u5668\u5728\u80fd\u6548\u548c\u63a8\u7406\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4e3b\u6d41GPU\u5e73\u53f0\u548c\u5176\u4ed6SNN\u5904\u7406\u5668\u3002"}}
{"id": "2601.00842", "pdf": "https://arxiv.org/pdf/2601.00842", "abs": "https://arxiv.org/abs/2601.00842", "authors": ["Elias Aravantinos"], "title": "Forecasting ICT-Driven Trade Competitiveness 2024-2028: A Cluster and Scenario Analysis", "categories": ["econ.GN"], "comment": null, "summary": "This study introduces the Digital Competitiveness Index for Trade (DCIT), a composite metric integrating ICT readiness, broadband adoption, GDP per capita, foreign direct investment, government effectiveness, and trade volume to assess countries' digital trade competitiveness. The index captures the enabling conditions -- ICT innovation capacity, broadband diffusion, investment intensity, and macroeconomic fundamentals - that shape a nation's ability to participate in digital trade. Sensitivity analysis demonstrates strong robustness: adjusting ICT-FDI weights alters DCIT outcomes by only 26%, with near perfect linearity (R^2 = 0.9996). Predictive validation shows that DCIT is a strong explainer of trade connectivity growth (R^2 = 0.67) but a modest predictor of GDP expansion. Scenario simulations reveal that combined ICT and FDI acceleration consistently outperforms single-lever strategies, with gains increasing by cluster maturity (up to 10% in advanced clusters). High-growth scenarios generate a 50-60% uplift in competitiveness for mid-tier and advanced clusters, underscoring the importance of integrated digital investment strategies.", "AI": {"tldr": "\u5f15\u5165\u6570\u5b57\u8d38\u6613\u7ade\u4e89\u529b\u6307\u6570\uff08DCIT\uff09\u8bc4\u4f30\u56fd\u5bb6\u6570\u5b57\u8d38\u6613\u7ade\u4e89\u529b\uff0c\u7ecf\u5206\u6790\u8be5\u6307\u6570\u7a33\u5065\uff0c\u80fd\u89e3\u91ca\u8d38\u6613\u8fde\u63a5\u6027\u589e\u957f\uff0c\u5f3a\u8c03\u7efc\u5408\u6570\u5b57\u6295\u8d44\u7b56\u7565\u91cd\u8981\u6027\u3002", "motivation": "\u8bc4\u4f30\u56fd\u5bb6\u6570\u5b57\u8d38\u6613\u7ade\u4e89\u529b\uff0c\u660e\u786e\u5f71\u54cd\u56fd\u5bb6\u53c2\u4e0e\u6570\u5b57\u8d38\u6613\u7684\u6761\u4ef6\u3002", "method": "\u6784\u5efa\u5305\u542b\u591a\u79cd\u56e0\u7d20\u7684DCIT\u6307\u6570\uff0c\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\u3001\u9884\u6d4b\u9a8c\u8bc1\u548c\u60c5\u666f\u6a21\u62df\u3002", "result": "DCIT\u6307\u6570\u7a33\u5065\uff0c\u80fd\u8f83\u597d\u89e3\u91ca\u8d38\u6613\u8fde\u63a5\u6027\u589e\u957f\uff0c\u7efc\u5408ICT\u548cFDI\u52a0\u901f\u7b56\u7565\u6548\u679c\u66f4\u4f73\uff0c\u9ad8\u589e\u957f\u60c5\u666f\u53ef\u63d0\u5347\u4e2d\u9ad8\u7ea7\u96c6\u7fa4\u7ade\u4e89\u529b\u3002", "conclusion": "\u7efc\u5408\u6570\u5b57\u6295\u8d44\u7b56\u7565\u5bf9\u4e8e\u63d0\u5347\u56fd\u5bb6\u6570\u5b57\u8d38\u6613\u7ade\u4e89\u529b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.01042", "pdf": "https://arxiv.org/pdf/2601.01042", "abs": "https://arxiv.org/abs/2601.01042", "authors": ["Zixiao Zhao", "Yanjie Jiang", "Hui Liu", "Kui Liu", "Lu Zhang"], "title": "SeRe: A Security-Related Code Review Dataset Aligned with Real-World Review Activities", "categories": ["cs.SE"], "comment": "Accepted by ICSE 2026", "summary": "Software security vulnerabilities can lead to severe consequences, making early detection essential. Although code review serves as a critical defense mechanism against security flaws, relevant feedback remains scarce due to limited attention to security issues or a lack of expertise among reviewers. Existing datasets and studies primarily focus on general-purpose code review comments, either lacking security-specific annotations or being too limited in scale to support large-scale research. To bridge this gap, we introduce \\textbf{SeRe}, a \\textbf{security-related code review dataset}, constructed using an active learning-based ensemble classification approach. The proposed approach iteratively refines model predictions through human annotations, achieving high precision while maintaining reasonable recall. Using the fine-tuned ensemble classifier, we extracted 6,732 security-related reviews from 373,824 raw review instances, ensuring representativeness across multiple programming languages. Statistical analysis indicates that SeRe generally \\textbf{aligns with real-world security-related review distribution}. To assess both the utility of SeRe and the effectiveness of existing code review comment generation approaches, we benchmark state-of-the-art approaches on security-related feedback generation. By releasing SeRe along with our benchmark results, we aim to advance research in automated security-focused code review and contribute to the development of more effective secure software engineering practices.", "AI": {"tldr": "\u63d0\u51fa\u5b89\u5168\u76f8\u5173\u4ee3\u7801\u5ba1\u67e5\u6570\u636e\u96c6SeRe\uff0c\u5e76\u5bf9\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u6ce8\u91ca\u751f\u6210\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u5b89\u5168\u7279\u5b9a\u6ce8\u91ca\u6216\u89c4\u6a21\u6709\u9650\uff0c\u96be\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u5b89\u5168\u76f8\u5173\u4ee3\u7801\u5ba1\u67e5\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\u6784\u5efaSeRe\u6570\u636e\u96c6\uff0c\u8fed\u4ee3\u4f18\u5316\u6a21\u578b\u9884\u6d4b\u3002", "result": "\u4ece373,824\u4e2a\u539f\u59cb\u5ba1\u67e5\u5b9e\u4f8b\u4e2d\u63d0\u53d66,732\u4e2a\u5b89\u5168\u76f8\u5173\u5ba1\u67e5\uff0cSeRe\u4e0e\u73b0\u5b9e\u4e16\u754c\u5b89\u5168\u76f8\u5173\u5ba1\u67e5\u5206\u5e03\u76f8\u7b26\u3002", "conclusion": "\u53d1\u5e03SeRe\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff0c\u63a8\u52a8\u81ea\u52a8\u5316\u5b89\u5168\u805a\u7126\u4ee3\u7801\u5ba1\u67e5\u7814\u7a76\u548c\u5b89\u5168\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u53d1\u5c55\u3002"}}
{"id": "2601.00810", "pdf": "https://arxiv.org/pdf/2601.00810", "abs": "https://arxiv.org/abs/2601.00810", "authors": ["Mohammadhossien Rashidi"], "title": "Can Large Language Models Improve Venture Capital Exit Timing After IPO?", "categories": ["q-fin.PM", "cs.AI", "cs.LG", "econ.GN", "q-fin.ST"], "comment": null, "summary": "Exit timing after an IPO is one of the most consequential decisions for venture capital (VC) investors, yet existing research focuses mainly on describing when VCs exit rather than evaluating whether those choices are economically optimal. Meanwhile, large language models (LLMs) have shown promise in synthesizing complex financial data and textual information but have not been applied to post-IPO exit decisions. This study introduces a framework that uses LLMs to estimate the optimal time for VC exit by analyzing monthly post IPO information financial performance, filings, news, and market signals and recommending whether to sell or continue holding. We compare these LLM generated recommendations with the actual exit dates observed for VCs and compute the return differences between the two strategies. By quantifying gains or losses associated with following the LLM, this study provides evidence on whether AI-driven guidance can improve exit timing and complements traditional hazard and real-options models in venture capital research.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f30\u7b97\u98ce\u6295IPO\u540e\u9000\u51fa\u65f6\u673a\u7684\u6846\u67b6\uff0c\u5bf9\u6bd4LLM\u5efa\u8bae\u4e0e\u5b9e\u9645\u9000\u51fa\u65e5\u671f\uff0c\u91cf\u5316\u6536\u76ca\u5dee\u5f02\uff0c\u4ee5\u9a8c\u8bc1AI\u6307\u5bfc\u80fd\u5426\u6539\u5584\u9000\u51fa\u65f6\u673a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u63cf\u8ff0\u98ce\u6295\u9000\u51fa\u65f6\u95f4\uff0c\u672a\u8bc4\u4f30\u662f\u5426\u7ecf\u6d4e\u6700\u4f18\uff0c\u4e14LLMs\u672a\u5e94\u7528\u4e8eIPO\u540e\u9000\u51fa\u51b3\u7b56\u3002", "method": "\u5f15\u5165\u6846\u67b6\uff0c\u7528LLMs\u5206\u6790IPO\u540e\u6bcf\u6708\u8d22\u52a1\u8868\u73b0\u3001\u6587\u4ef6\u3001\u65b0\u95fb\u548c\u5e02\u573a\u4fe1\u53f7\uff0c\u63a8\u8350\u5356\u51fa\u6216\u6301\u6709\uff0c\u5bf9\u6bd4LLM\u5efa\u8bae\u4e0e\u5b9e\u9645\u9000\u51fa\u65e5\u671f\u5e76\u8ba1\u7b97\u6536\u76ca\u5dee\u5f02\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u91cf\u5316\u6536\u76ca\u6216\u635f\u5931\uff0c\u53ef\u9a8c\u8bc1AI\u9a71\u52a8\u7684\u6307\u5bfc\u80fd\u5426\u6539\u5584\u9000\u51fa\u65f6\u673a\uff0c\u8865\u5145\u98ce\u6295\u7814\u7a76\u4e2d\u7684\u4f20\u7edf\u6a21\u578b\u3002"}}
{"id": "2601.01783", "pdf": "https://arxiv.org/pdf/2601.01783", "abs": "https://arxiv.org/abs/2601.01783", "authors": ["Haibo Wang", "Jun Huang", "Lutfu S Sua", "Jaime Ortiz", "Jinshyang Roan", "Bahram Alidaee"], "title": "Dynamic Risk in the U.S. Banking System: An Analysis of Sentiment, Policy Shocks, and Spillover Effects", "categories": ["econ.EM", "q-fin.CP", "q-fin.RM"], "comment": null, "summary": "The 2023 U.S. banking crisis propagated not through direct financial linkages but through a high-frequency, information-based contagion channel. This paper moves beyond exploration analysis to test the \"too-similar-to-fail\" hypothesis, arguing that risk spillovers were driven by perceived similarities in bank business models under acute interest rate pressure. Employing a Time-Varying Parameter Vector Autoregression (TVP-VAR) model with 30-day rolling windows, a method uniquely suited for capturing the rapid network shifts inherent in a panic, we analyze daily stock returns for the four failed institutions and a systematically selected peer group of surviving banks vulnerable to the same risks from March 18, 2022, to March 15, 2023. Our results provide strong evidence for this contagion channel: total system connectedness surged dramatically during the crisis peak, and we identify SIVB, FRC, and WAL as primary net transmitters of risk while their perceived peers became significant net receivers, a key dynamic indicator of systemic vulnerability that cannot be captured by asset-by-asset analysis. We further demonstrate that these spillovers were significantly amplified by market sentiment (as measured by the VIX) and economic policy uncertainty (EPU). By providing a clear conceptual framework and robust empirical validation, our findings confirm the persistence of systemic risks within the banking network and highlight the importance of real-time monitoring in strengthening financial stability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a762023\u5e74\u7f8e\u56fd\u94f6\u884c\u5371\u673a\u4f20\u64ad\u6e20\u9053\uff0c\u8bc1\u5b9e\u2018\u592a\u76f8\u4f3c\u800c\u4e0d\u80fd\u5012\u2019\u5047\u8bbe\uff0c\u5f3a\u8c03\u5b9e\u65f6\u76d1\u6d4b\u5bf9\u91d1\u878d\u7a33\u5b9a\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u63a2\u7a762023\u5e74\u7f8e\u56fd\u94f6\u884c\u5371\u673a\u4f20\u64ad\u6e20\u9053\uff0c\u68c0\u9a8c\u2018\u592a\u76f8\u4f3c\u800c\u4e0d\u80fd\u5012\u2019\u5047\u8bbe\u3002", "method": "\u91c7\u7528\u5e2630\u5929\u6eda\u52a8\u7a97\u53e3\u7684\u65f6\u53d8\u53c2\u6570\u5411\u91cf\u81ea\u56de\u5f52\uff08TVP - VAR\uff09\u6a21\u578b\uff0c\u5206\u67902022\u5e743\u670818\u65e5\u81f32023\u5e743\u670815\u65e5\u76f8\u5173\u94f6\u884c\u7684\u6bcf\u65e5\u80a1\u7968\u6536\u76ca\u3002", "result": "\u5371\u673a\u9ad8\u5cf0\u65f6\u7cfb\u7edf\u603b\u8fde\u901a\u6027\u6025\u5267\u4e0a\u5347\uff0c\u786e\u5b9a\u4e3b\u8981\u98ce\u9669\u51c0\u4f20\u8f93\u8005\u548c\u63a5\u6536\u8005\uff0c\u53d1\u73b0\u5e02\u573a\u60c5\u7eea\u548c\u7ecf\u6d4e\u653f\u7b56\u4e0d\u786e\u5b9a\u6027\u4f1a\u653e\u5927\u98ce\u9669\u6ea2\u51fa\u3002", "conclusion": "\u8bc1\u5b9e\u94f6\u884c\u7f51\u7edc\u4e2d\u7cfb\u7edf\u6027\u98ce\u9669\u7684\u6301\u7eed\u6027\uff0c\u5f3a\u8c03\u5b9e\u65f6\u76d1\u6d4b\u5bf9\u52a0\u5f3a\u91d1\u878d\u7a33\u5b9a\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.01422", "pdf": "https://arxiv.org/pdf/2601.01422", "abs": "https://arxiv.org/abs/2601.01422", "authors": ["Arghya Mukherjee", "Dootika Vats"], "title": "Hamiltonian Monte Carlo for (Physics) Dummies", "categories": ["stat.CO", "stat.ME"], "comment": "39 pages, 12 figures, 1 table", "summary": "Sampling-based inference has seen a surge of interest in recent years. Hamiltonian Monte Carlo (HMC) has emerged as a powerful algorithm that leverages concepts from Hamiltonian dynamics to efficiently explore complex target distributions. Variants of HMC are available in popular software packages, enabling off-the-shelf implementations that have greatly benefited the statistics and machine learning communities. At the same time, the availability of such black-box implementations has made it challenging for users to understand the inner workings of HMC, especially when they are unfamiliar with the underlying physical principles. We provide a pedagogical overview of HMC that aims to bridge the gap between its theoretical foundations and practical applicability. This review article seeks to make HMC more accessible to applied researchers by highlighting its advantages, limitations, and role in enabling scalable and exact Bayesian inference for complex models.", "AI": {"tldr": "\u672c\u6587\u5bf9\u54c8\u5bc6\u987f\u8499\u7279\u5361\u7f57\uff08HMC\uff09\u7b97\u6cd5\u8fdb\u884c\u6559\u5b66\u6027\u6982\u8ff0\uff0c\u5e2e\u52a9\u5e94\u7528\u7814\u7a76\u8005\u7406\u89e3\u5176\u7406\u8bba\u4e0e\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u7684HMC\u9ed1\u76d2\u5b9e\u73b0\u8ba9\u4e0d\u719f\u6089\u7269\u7406\u539f\u7406\u7684\u7528\u6237\u96be\u4ee5\u7406\u89e3\u5176\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff0c\u9700\u642d\u5efa\u7406\u8bba\u4e0e\u5b9e\u9645\u5e94\u7528\u95f4\u7684\u6865\u6881\u3002", "method": "\u5bf9HMC\u8fdb\u884c\u6559\u5b66\u6027\u6982\u8ff0\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u7a81\u51faHMC\u7684\u4f18\u52bf\u3001\u5c40\u9650\u548c\u4f5c\u7528\uff0c\u8ba9\u5e94\u7528\u7814\u7a76\u8005\u66f4\u6613\u7406\u89e3\u8be5\u7b97\u6cd5\u3002"}}
{"id": "2601.00814", "pdf": "https://arxiv.org/pdf/2601.00814", "abs": "https://arxiv.org/abs/2601.00814", "authors": ["Abhishek Kumar"], "title": "Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections", "categories": ["cs.AI"], "comment": null, "summary": "The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5d4c\u5165\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5339\u914d\u7684\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u7cfb\u7edf\uff0c\u5728OAEI - 2022\u8bc4\u4f30\u4e2dF1\u5206\u6570\u63d0\u534716%\u3002", "motivation": "\u6784\u5efa\u6709\u6548\u7684\u8de8\u8bed\u8a00\u672c\u4f53\u5bf9\u9f50\u7cfb\u7edf\u3002", "method": "\u7528\u65b0\u9896\u6280\u672f\u521b\u5efa\u63cf\u8ff0\u4f7f\u672c\u4f53\u5b9e\u4f53\u4e0a\u4e0b\u6587\u66f4\u4e30\u5bcc\uff0c\u7528\u5fae\u8c03\u7684\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u591a\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5d4c\u5165\uff0c\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u627e\u6b63\u5b9e\u4f53\u5bf9\u5e76\u9608\u503c\u8fc7\u6ee4\u3002", "result": "\u5728OAEI - 2022\u8bc4\u4f30\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u8fbe71%\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebf\u5206\u6570\u63d0\u9ad816%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5bf9\u9f50\u7ba1\u9053\u80fd\u6355\u6349\u5fae\u5999\u7684\u8de8\u8bed\u8a00\u76f8\u4f3c\u6027\u3002"}}
{"id": "2601.01029", "pdf": "https://arxiv.org/pdf/2601.01029", "abs": "https://arxiv.org/abs/2601.01029", "authors": ["Zeyu Bian", "Max Biggs", "Ruijiang Gao", "Zhengling Qi"], "title": "Beyond Demand Estimation: Consumer Surplus Evaluation via Cumulative Propensity Weights", "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST"], "comment": "74 pages", "summary": "This paper develops a practical framework for using observational data to audit the consumer surplus effects of AI-driven decisions, specifically in targeted pricing and algorithmic lending. Traditional approaches first estimate demand functions and then integrate to compute consumer surplus, but these methods can be challenging to implement in practice due to model misspecification in parametric demand forms and the large data requirements and slow convergence of flexible nonparametric or machine learning approaches. Instead, we exploit the randomness inherent in modern algorithmic pricing, arising from the need to balance exploration and exploitation, and introduce an estimator that avoids explicit estimation and numerical integration of the demand function. Each observed purchase outcome at a randomized price is an unbiased estimate of demand and by carefully reweighting purchase outcomes using novel cumulative propensity weights (CPW), we are able to reconstruct the integral. Building on this idea, we introduce a doubly robust variant named the augmented cumulative propensity weighting (ACPW) estimator that only requires one of either the demand model or the historical pricing policy distribution to be correctly specified. Furthermore, this approach facilitates the use of flexible machine learning methods for estimating consumer surplus, since it achieves fast convergence rates by incorporating an estimate of demand, even when the machine learning estimate has slower convergence rates. Neither of these estimators is a standard application of off-policy evaluation techniques as the target estimand, consumer surplus, is unobserved. To address fairness, we extend this framework to an inequality-aware surplus measure, allowing regulators and firms to quantify the profit-equity trade-off. Finally, we validate our methods through comprehensive numerical studies.", "AI": {"tldr": "\u63d0\u51fa\u7528\u89c2\u6d4b\u6570\u636e\u5ba1\u8ba1AI\u51b3\u7b56\u5bf9\u6d88\u8d39\u8005\u5269\u4f59\u5f71\u54cd\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u7ed9\u51fa\u65b0\u4f30\u8ba1\u91cf\uff0c\u6269\u5c55\u5230\u5173\u6ce8\u516c\u5e73\u6027\u7684\u5ea6\u91cf\u5e76\u9a8c\u8bc1\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8ba1\u7b97\u6d88\u8d39\u8005\u5269\u4f59\u7684\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u5b58\u5728\u6a21\u578b\u9519\u8bef\u6307\u5b9a\u3001\u6570\u636e\u9700\u6c42\u5927\u3001\u6536\u655b\u6162\u7b49\u95ee\u9898\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u7b97\u6cd5\u5b9a\u4ef7\u4e2d\u7684\u968f\u673a\u6027\uff0c\u5f15\u5165\u907f\u514d\u663e\u5f0f\u4f30\u8ba1\u548c\u6570\u503c\u79ef\u5206\u7684\u4f30\u8ba1\u91cf\uff0c\u63d0\u51fa\u53cc\u7a33\u5065\u7684ACPW\u4f30\u8ba1\u91cf\uff0c\u6269\u5c55\u5230\u4e0d\u5e73\u7b49\u611f\u77e5\u7684\u5269\u4f59\u5ea6\u91cf\u3002", "result": "\u63d0\u51fa\u65b0\u7684\u4f30\u8ba1\u91cf\u548c\u5ea6\u91cf\uff0c\u80fd\u501f\u52a9\u7075\u6d3b\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5feb\u901f\u6536\u655b\u4f30\u8ba1\u6d88\u8d39\u8005\u5269\u4f59\u3002", "conclusion": "\u7ecf\u5168\u9762\u6570\u503c\u7814\u7a76\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.02095", "pdf": "https://arxiv.org/pdf/2601.02095", "abs": "https://arxiv.org/abs/2601.02095", "authors": ["Mehrad Abbaszadeh", "Ali Ansarifar", "Mohamad Latifian", "Masoud Seddighin"], "title": "Metric Distortion with Preference Intensities", "categories": ["cs.GT"], "comment": null, "summary": "In voting with ranked ballots, each agent submits a strict ranking of the form $a \\succ b \\succ c \\succ d$ over the alternatives, and the voting rule decides on the winner based on these rankings. Although this ballot format has desirable characteristics, there is a question of whether it is expressive enough for the agents. Kahng, Latifian, and Shah address this issue by adding intensities to the rankings. They introduce the ranking with intensities ballot format, where agents can use both $\\succ\\!\\!\\succ$ and $\\succ$ in their rankings to express intensive and normal preferences between consecutive alternatives in their rankings. While they focus on analyzing this ballot format in the utilitarian distortion framework, in this work, we look at the potential of using this ballot format from the metric distortion viewpoint. We design a class of voting rules coined Positional Scoring Matching rules, which can be used for different problems in the metric setting, and show that by solving a zero-sum game, we can find the optimal member of this class for our problem. This rule takes intensities into account and achieves a distortion lower than $3$. In addition, by proving a bound on the price of ignoring intensities, we show that we might lose a great deal in terms of distortion by not taking the intensities into account.", "AI": {"tldr": "\u672c\u6587\u4ece\u5ea6\u91cf\u5931\u771f\u89d2\u5ea6\u7814\u7a76\u5e26\u5f3a\u5ea6\u7684\u6392\u5e8f\u9009\u7968\u683c\u5f0f\uff0c\u8bbe\u8ba1\u4e86Positional Scoring Matching\u89c4\u5219\uff0c\u8be5\u89c4\u5219\u8003\u8651\u5f3a\u5ea6\u56e0\u7d20\uff0c\u5931\u771f\u4f4e\u4e8e3\uff0c\u4e14\u8bc1\u660e\u5ffd\u7565\u5f3a\u5ea6\u4f1a\u5927\u5e45\u589e\u52a0\u5931\u771f\u3002", "motivation": "\u7814\u7a76\u5e26\u5f3a\u5ea6\u7684\u6392\u5e8f\u9009\u7968\u683c\u5f0f\u4ece\u5ea6\u91cf\u5931\u771f\u89d2\u5ea6\u7684\u6f5c\u529b\uff0c\u6b64\u524d\u76f8\u5173\u5de5\u4f5c\u805a\u7126\u4e8e\u529f\u5229\u4e3b\u4e49\u5931\u771f\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1Positional Scoring Matching\u89c4\u5219\u7c7b\uff0c\u901a\u8fc7\u89e3\u51b3\u96f6\u548c\u535a\u5f08\u627e\u5230\u8be5\u7c7b\u89c4\u5219\u4e2d\u9488\u5bf9\u6b64\u95ee\u9898\u7684\u6700\u4f18\u89c4\u5219\u3002", "result": "\u8bbe\u8ba1\u7684\u6295\u7968\u89c4\u5219\u8003\u8651\u5f3a\u5ea6\u56e0\u7d20\u540e\u5931\u771f\u4f4e\u4e8e3\uff0c\u8bc1\u660e\u5ffd\u7565\u5f3a\u5ea6\u4f1a\u5728\u5931\u771f\u65b9\u9762\u6709\u8f83\u5927\u635f\u5931\u3002", "conclusion": "\u4f7f\u7528\u5e26\u5f3a\u5ea6\u7684\u6392\u5e8f\u9009\u7968\u683c\u5f0f\u5e76\u5728\u8bbe\u8ba1\u6295\u7968\u89c4\u5219\u65f6\u8003\u8651\u5f3a\u5ea6\u56e0\u7d20\uff0c\u80fd\u6709\u6548\u964d\u4f4e\u5ea6\u91cf\u5931\u771f\u3002"}}
{"id": "2601.01841", "pdf": "https://arxiv.org/pdf/2601.01841", "abs": "https://arxiv.org/abs/2601.01841", "authors": ["Jingyang Zhao", "Yonghang Su", "Mingyu Xiao"], "title": "Improved Approximation Algorithms for the Multiple-Depot Split Delivery Vehicle Routing Problem", "categories": ["cs.DS"], "comment": null, "summary": "The Multiple-Depot Split Delivery Vehicle Routing Problem (MD-SDVRP) is a challenging problem with broad applications in logistics. The goal is to serve customers' demand using a fleet of capacitated vehicles located in multiple depots, where each customer's demand can be served by more than one vehicle, while minimizing the total travel cost of all vehicles. We study approximation algorithms for this problem. Previously, the only known result was a $6$-approximation algorithm for a constant number of depots (INFORMS J. Comput. 2023), and whether this ratio could be improved was left as an open question. In this paper, we resolve it by proposing a $(6-2\\cdot 10^{-36})$-approximation algorithm for this setting. Moreover, we develop constant-factor approximation algorithms that work beyond a constant number of depots, improved parameterized approximation algorithms related to the vehicle capacity and the number of depots, as well as bi-factor approximation algorithms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2601.01125", "pdf": "https://arxiv.org/pdf/2601.01125", "abs": "https://arxiv.org/abs/2601.01125", "authors": ["Mohammad Goudarzi", "Arash Shaghaghi", "Zhiyu Wang", "Rajkumar Buyya"], "title": "Performance and Security Aware Distributed Service Placement in Fog Computing", "categories": ["cs.DC"], "comment": null, "summary": "The rapid proliferation of IoT applications has intensified the demand for efficient and secure service placement in Fog computing. However, heterogeneous resources, dynamic workloads, and diverse security requirements make optimal service placement highly challenging. Most solutions focus primarily on performance metrics while overlooking the security implications of deployment decisions. This paper proposes a Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL) framework for joint optimization of service response time and security compliance in Fog computing. The problem is formulated as a weighted multi-objective optimization task, minimizing latency while maximizing a security score derived from the security capabilities of Fog nodes. The security score features a new three-tier hierarchy, where configuration-level checks verify proper settings, capability-level assessments evaluate the resource security features, and control-level evaluations enforce stringent policies, thereby ensuring compliant solutions that align with performance objectives. SPA-DDRL adopts a distributed broker-learner architecture where multiple brokers perform autonomous service-placement decisions and a centralized learner coordinates global policy optimization through shared prioritized experiences. It integrates three key improvements, including Long Short-Term Memory networks, Prioritized Experience Replay, and off-policy correction mechanisms to improve the agent's performance. Experiments based on real IoT workloads show that SPA-DDRL significantly improves both service response time and placement security compared to current approaches, achieving a 16.3% improvement in response time and a 33% faster convergence rate. It also maintains consistent, feasible, security-compliant solutions across all system scales, while baseline techniques fail or show performance degradation.", "AI": {"tldr": "\u9488\u5bf9\u96fe\u8ba1\u7b97\u4e2d\u670d\u52a1\u653e\u7f6e\u95ee\u9898\uff0c\u63d0\u51faSPA - DDRL\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u670d\u52a1\u54cd\u5e94\u65f6\u95f4\u548c\u653e\u7f6e\u5b89\u5168\u6027\u3002", "motivation": "\u7269\u8054\u7f51\u5e94\u7528\u589e\u957f\u4f7f\u96fe\u8ba1\u7b97\u4e2d\u9ad8\u6548\u5b89\u5168\u7684\u670d\u52a1\u653e\u7f6e\u9700\u6c42\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u65b9\u6848\u591a\u5ffd\u89c6\u5b89\u5168\u5f71\u54cd\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u52a0\u6743\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\uff0c\u91c7\u7528\u5206\u5e03\u5f0f\u7ecf\u7eaa\u4eba - \u5b66\u4e60\u8005\u67b6\u6784\uff0c\u96c6\u6210LSTM\u7f51\u7edc\u3001\u4f18\u5148\u7ecf\u9a8c\u56de\u653e\u548c\u79bb\u7b56\u7565\u6821\u6b63\u673a\u5236\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u7269\u8054\u7f51\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u54cd\u5e94\u65f6\u95f4\u63d0\u534716.3%\uff0c\u6536\u655b\u901f\u5ea6\u52a0\u5feb33%\uff0c\u5728\u5404\u7cfb\u7edf\u89c4\u6a21\u4e0b\u90fd\u80fd\u4fdd\u6301\u5408\u89c4\u89e3\u3002", "conclusion": "SPA - DDRL\u6846\u67b6\u80fd\u6709\u6548\u8054\u5408\u4f18\u5316\u96fe\u8ba1\u7b97\u4e2d\u7684\u670d\u52a1\u54cd\u5e94\u65f6\u95f4\u548c\u5b89\u5168\u5408\u89c4\u6027\u3002"}}
{"id": "2601.00995", "pdf": "https://arxiv.org/pdf/2601.00995", "abs": "https://arxiv.org/abs/2601.00995", "authors": ["Nikos Karayannidis"], "title": "Grain-Aware Data Transformations: Type-Level Formal Verification at Zero Computational Cost", "categories": ["cs.DB"], "comment": null, "summary": "Data transformation correctness is a major challenge in data engineering: how to verify pipeline accuracy before deployment. Traditional methods involve costly iterative testing, data materialization, and manual error detection, due to the lack of formal approaches to reasoning about data granularity (grain), which can shift during transformations, causing issues like fan traps (metrics duplication) and chasm traps (data loss). We introduce the first formal, mathematical definition of grain, extending it from an informal concept in dimensional modeling to a universal, type-theoretic framework applicable to any data type. Encoding grain into the type system allows compile-time verification of transformation correctness, shifting validation from runtime. We define three core grain relations-equality, ordering, and incomparability-and prove a general grain inference theorem that computes the output grain of equi-joins from input grains using type-level operations. This covers all join scenarios, including comparable and incomparable keys. Together with inference rules for relational operations, this enables verification through schema analysis alone, at zero cost. Our approach allows engineers to verify that entire pipeline DAGs maintain correctness properties, detecting grain-related errors such as fan traps, chasm traps, and aggregation issues before data processing. It emphasizes the importance of grain, focusing on critical characteristics rather than all data details. We provide machine-checked formal proofs in Lean 4, reducing verification costs by 98-99%. Additionally, large language models can automatically generate correctness proofs, shifting human effort from proof writing to proof verification, thus democratizing formal methods in data engineering and supporting confident deployment of AI-generated pipelines with machine-checkable guarantees.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u7c92\u5ea6\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5b9e\u73b0\u7f16\u8bd1\u65f6\u9a8c\u8bc1\u6570\u636e\u8f6c\u6362\u6b63\u786e\u6027\uff0c\u964d\u4f4e\u9a8c\u8bc1\u6210\u672c\u5e76\u652f\u6301AI\u751f\u6210\u7ba1\u9053\u90e8\u7f72\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u6570\u636e\u7c92\u5ea6\u63a8\u7406\u7684\u5f62\u5f0f\u5316\u624b\u6bb5\uff0c\u5bfc\u81f4\u6570\u636e\u8f6c\u6362\u6b63\u786e\u6027\u9a8c\u8bc1\u6210\u672c\u9ad8\uff0c\u9700\u5728\u90e8\u7f72\u524d\u9a8c\u8bc1\u7ba1\u9053\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165\u6570\u636e\u7c92\u5ea6\u7684\u6b63\u5f0f\u6570\u5b66\u5b9a\u4e49\uff0c\u62d3\u5c55\u5230\u901a\u7528\u7c7b\u578b\u8bba\u6846\u67b6\uff0c\u5b9a\u4e49\u6838\u5fc3\u7c92\u5ea6\u5173\u7cfb\u5e76\u8bc1\u660e\u63a8\u7406\u5b9a\u7406\uff0c\u7ed3\u5408\u5173\u7cfb\u64cd\u4f5c\u63a8\u7406\u89c4\u5219\uff0c\u7528Lean 4\u63d0\u4f9b\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u8bc1\u660e\u3002", "result": "\u53ef\u901a\u8fc7\u6a21\u5f0f\u5206\u6790\u9a8c\u8bc1\uff0c\u96f6\u6210\u672c\u68c0\u6d4b\u7c92\u5ea6\u76f8\u5173\u9519\u8bef\uff0c\u5c06\u9a8c\u8bc1\u6210\u672c\u964d\u4f4e98 - 99%\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u81ea\u52a8\u751f\u6210\u8bc1\u660e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5f3a\u8c03\u7c92\u5ea6\u91cd\u8981\u6027\uff0c\u964d\u4f4e\u9a8c\u8bc1\u6210\u672c\uff0c\u4f7f\u5f62\u5f0f\u5316\u65b9\u6cd5\u5728\u6570\u636e\u5de5\u7a0b\u4e2d\u66f4\u666e\u53ca\uff0c\u652f\u6301AI\u751f\u6210\u7ba1\u9053\u7684\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2601.01706", "pdf": "https://arxiv.org/pdf/2601.01706", "abs": "https://arxiv.org/abs/2601.01706", "authors": ["Jonas Gebele", "Florian Matthes"], "title": "Semantic Non-Fungibility and Violations of the Law of One Price in Prediction Markets", "categories": ["cs.CE"], "comment": null, "summary": "Prediction markets are designed to aggregate dispersed information about future events, yet today's ecosystem is fragmented across heterogeneous operator-run platforms and blockchain-based protocols that independently list economically identical events. In the absence of a shared notion of event identity, liquidity fails to pool across venues, arbitrage becomes capital-intensive or unenforceable, and prices systematically violate the Law of One Price. As a result, market prices reflect platform-local beliefs rather than a single, globally aggregated probability, undermining the core information-aggregation function of prediction markets. We address this gap by introducing a semantic alignment framework that makes cross-platform event identity explicit through joint analysis of natural-language descriptions, resolution semantics, and temporal scope. Applying this framework, we construct the first human-validated, cross-platform dataset of aligned prediction markets, covering over 100 000 events across ten major venues from 2018 to 2025. Using this dataset, we show that roughly 6% of all events are concurrently listed across platforms and that semantically equivalent markets exhibit persistent execution-aware price deviations of 2-4% on average, even in highly liquid and information-rich settings. These mispricings give rise to persistent cross-platform arbitrage opportunities driven by structural frictions rather than informational disagreement. Overall, our results demonstrate that semantic non-fungibility is a fundamental barrier to price convergence, and that resolving event identity is a prerequisite for prediction markets to aggregate information at a global scale.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u9884\u6d4b\u5e02\u573a\u56e0\u7f3a\u4e4f\u4e8b\u4ef6\u8eab\u4efd\u5171\u4eab\u6982\u5ff5\u5bfc\u81f4\u6d41\u52a8\u6027\u5206\u6563\u7b49\u95ee\u9898\uff0c\u5f15\u5165\u8bed\u4e49\u5bf9\u9f50\u6846\u67b6\u6784\u5efa\u8de8\u5e73\u53f0\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u4ef7\u683c\u504f\u5dee\u548c\u5957\u5229\u673a\u4f1a\uff0c\u8868\u660e\u89e3\u51b3\u4e8b\u4ef6\u8eab\u4efd\u95ee\u9898\u662f\u5168\u7403\u4fe1\u606f\u805a\u5408\u7684\u524d\u63d0\u3002", "motivation": "\u89e3\u51b3\u9884\u6d4b\u5e02\u573a\u56e0\u7f3a\u4e4f\u4e8b\u4ef6\u8eab\u4efd\u5171\u4eab\u6982\u5ff5\uff0c\u5bfc\u81f4\u6d41\u52a8\u6027\u65e0\u6cd5\u6c47\u805a\u3001\u4ef7\u683c\u8fdd\u53cd\u4e00\u4ef7\u5b9a\u5f8b\uff0c\u7834\u574f\u4fe1\u606f\u805a\u5408\u529f\u80fd\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8bed\u4e49\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u3001\u89e3\u51b3\u8bed\u4e49\u548c\u65f6\u95f4\u8303\u56f4\u7684\u8054\u5408\u5206\u6790\u660e\u786e\u8de8\u5e73\u53f0\u4e8b\u4ef6\u8eab\u4efd\uff0c\u6784\u5efa\u8de8\u5e73\u53f0\u6570\u636e\u96c6\u3002", "result": "\u7ea66%\u7684\u4e8b\u4ef6\u5728\u4e0d\u540c\u5e73\u53f0\u540c\u65f6\u5217\u51fa\uff0c\u8bed\u4e49\u7b49\u4ef7\u5e02\u573a\u5b58\u57282 - 4%\u7684\u4ef7\u683c\u504f\u5dee\uff0c\u5b58\u5728\u8de8\u5e73\u53f0\u5957\u5229\u673a\u4f1a\u3002", "conclusion": "\u8bed\u4e49\u975e\u53ef\u66ff\u4ee3\u6027\u662f\u4ef7\u683c\u8d8b\u540c\u7684\u6839\u672c\u969c\u788d\uff0c\u89e3\u51b3\u4e8b\u4ef6\u8eab\u4efd\u95ee\u9898\u662f\u9884\u6d4b\u5e02\u573a\u5168\u7403\u4fe1\u606f\u805a\u5408\u7684\u5148\u51b3\u6761\u4ef6\u3002"}}
{"id": "2601.00891", "pdf": "https://arxiv.org/pdf/2601.00891", "abs": "https://arxiv.org/abs/2601.00891", "authors": ["Rodrigo Kataishi"], "title": "Enhancing Retrieval-Augmented Generation with Topic-Enriched Embeddings: A Hybrid Approach Integrating Traditional NLP Techniques", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems rely on accurate document retrieval to ground large language models (LLMs) in external knowledge, yet retrieval quality often degrades in corpora where topics overlap and thematic variation is high. This work proposes topic-enriched embeddings that integrate term-based signals and topic structure with contextual sentence embeddings. The approach combines TF-IDF with topic modeling and dimensionality reduction, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to encode latent topical organization, and fuses these representations with a compact contextual encoder (all-MiniLM). By jointly capturing term-level and topic-level semantics, topic-enriched embeddings improve semantic clustering, increase retrieval precision, and reduce computational burden relative to purely contextual baselines. Experiments on a legal-text corpus show consistent gains in clustering coherence and retrieval metrics, suggesting that topic-enriched embeddings can serve as a practical component for more reliable knowledge-intensive RAG pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e3b\u9898\u4e30\u5bcc\u5d4c\u5165\u65b9\u6cd5\u6539\u8fdb\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u68c0\u7d22\u8d28\u91cf\uff0c\u5728\u6cd5\u5f8b\u6587\u672c\u8bed\u6599\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u5728\u4e3b\u9898\u91cd\u53e0\u548c\u4e3b\u9898\u53d8\u5316\u5927\u7684\u8bed\u6599\u4e2d\u68c0\u7d22\u8d28\u91cf\u4e0b\u964d\u3002", "method": "\u5c06TF - IDF\u4e0e\u4e3b\u9898\u5efa\u6a21\u548c\u964d\u7ef4\u7ed3\u5408\uff0c\u7528LSA\u548cLDA\u7f16\u7801\u6f5c\u5728\u4e3b\u9898\u7ed3\u6784\uff0c\u5e76\u4e0e\u7d27\u51d1\u4e0a\u4e0b\u6587\u7f16\u7801\u5668\u878d\u5408\u3002", "result": "\u5728\u6cd5\u5f8b\u6587\u672c\u8bed\u6599\u5b9e\u9a8c\u4e2d\uff0c\u805a\u7c7b\u8fde\u8d2f\u6027\u548c\u68c0\u7d22\u6307\u6807\u6709\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u4e3b\u9898\u4e30\u5bcc\u5d4c\u5165\u53ef\u4f5c\u4e3a\u66f4\u53ef\u9760\u77e5\u8bc6\u5bc6\u96c6\u578bRAG\u7ba1\u9053\u7684\u5b9e\u7528\u7ec4\u4ef6\u3002"}}
{"id": "2601.01642", "pdf": "https://arxiv.org/pdf/2601.01642", "abs": "https://arxiv.org/abs/2601.01642", "authors": ["Dohyun Ahn", "Huiyi Chen", "Lewen Zheng"], "title": "Wasserstein Distributionally Robust Rare-Event Simulation", "categories": ["stat.ME", "q-fin.CP", "stat.CO"], "comment": null, "summary": "Standard rare-event simulation techniques require exact distributional specifications, which limits their effectiveness in the presence of distributional uncertainty. To address this, we develop a novel framework for estimating rare-event probabilities subject to such distributional model risk. Specifically, we focus on computing worst-case rare-event probabilities, defined as a distributionally robust bound against a Wasserstein ambiguity set centered at a specific nominal distribution. By exploiting a dual characterization of this bound, we propose Distributionally Robust Importance Sampling (DRIS), a computationally tractable methodology designed to substantially reduce the variance associated with estimating the dual components. The proposed method is simple to implement and requires low sampling costs. Most importantly, it achieves vanishing relative error, the strongest efficiency guarantee that is notoriously difficult to establish in rare-event simulation. Our numerical studies confirm the superior performance of DRIS against existing benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u5904\u7406\u5206\u5e03\u6a21\u578b\u98ce\u9669\u4e0b\u4f30\u8ba1\u7f55\u89c1\u4e8b\u4ef6\u6982\u7387\u7684\u65b0\u6846\u67b6DRIS\uff0c\u65b9\u6cd5\u6613\u5b9e\u73b0\u3001\u6210\u672c\u4f4e\u4e14\u6548\u7387\u9ad8\uff0c\u6570\u503c\u7814\u7a76\u8bc1\u5b9e\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u6807\u51c6\u7f55\u89c1\u4e8b\u4ef6\u6a21\u62df\u6280\u672f\u5728\u5206\u5e03\u4e0d\u786e\u5b9a\u65f6\u6548\u679c\u53d7\u9650\uff0c\u9700\u5904\u7406\u5206\u5e03\u6a21\u578b\u98ce\u9669\u4e0b\u4f30\u8ba1\u7f55\u89c1\u4e8b\u4ef6\u6982\u7387\u95ee\u9898\u3002", "method": "\u805a\u7126\u8ba1\u7b97\u57fa\u4e8eWasserstein\u6a21\u7cca\u96c6\u7684\u6700\u574f\u60c5\u51b5\u7f55\u89c1\u4e8b\u4ef6\u6982\u7387\uff0c\u5229\u7528\u5bf9\u5076\u7279\u5f81\u63d0\u51fa\u5206\u5e03\u9c81\u68d2\u91cd\u8981\u6027\u91c7\u6837\uff08DRIS\uff09\u65b9\u6cd5\u964d\u4f4e\u5bf9\u5076\u5206\u91cf\u4f30\u8ba1\u65b9\u5dee\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u7b80\u5355\u6613\u5b9e\u73b0\u3001\u91c7\u6837\u6210\u672c\u4f4e\uff0c\u5b9e\u73b0\u4e86\u6d88\u5931\u76f8\u5bf9\u8bef\u5dee\u3002\u6570\u503c\u7814\u7a76\u8868\u660eDRIS\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "DRIS\u662f\u4e00\u79cd\u6709\u6548\u5904\u7406\u5206\u5e03\u6a21\u578b\u98ce\u9669\u4e0b\u4f30\u8ba1\u7f55\u89c1\u4e8b\u4ef6\u6982\u7387\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.00804", "pdf": "https://arxiv.org/pdf/2601.00804", "abs": "https://arxiv.org/abs/2601.00804", "authors": ["Yves Matanga", "Chunling Du", "Etienne van Wyk"], "title": "Optimal Traffic Relief Road Design using Bilevel Programming and Greedy Seeded Simulated Annealing: A Case Study of Kinshasa", "categories": ["cs.NE"], "comment": null, "summary": "Context: The city of Kinshasa faces severe traffic congestion, requiring strategic infrastructure capacity enhancements. Although a comprehensive master plan has been proposed, its implementation requires substantial financial investment, which remains constrained in the Democratic Republic of the Congo (DRC), an emerging economy. This research proposes a traffic flow based algorithm to support the development of priority road segments. The objective is to enable more effective prioritisation of road construction projects and facilitate the optimal allocation of limited infrastructure budgets.\n  Methods: The study was conducted by formulating a standard transport network design problem (TNDP) that included estimated origin demand data specific to the city of Kinshasa. Given the high computational nature of the 30 node network design, TNDP relevant metaheuristics (GA, ACO, PSO, SA, TS, Greedy) were used selectively and hybridised to achieve high quality, stable solutions. A greedy search seeded simulated annealing and Tabu search were devised to achieve the design goals.\n  Results: Greedy Simulated Annealing and Greedy Tabu search yielded the best travel time reduction and the most stable solutions compared to other solvers, also improving network edge betweenness centrality by nearly a scale of two and a half.\n  Conclusions: Road priorities were proposed, including junctions connecting the Bandundu and Kongo Central entry point to main attraction centres (Limete Poids Lourd, Gombe, Airport) and additional inner city areas (Ngaliema, Selembao, Lemba, Masina, Kimwenza).", "AI": {"tldr": "\u9488\u5bf9\u91d1\u6c99\u8428\u5e02\u4ea4\u901a\u62e5\u5835\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u4ea4\u901a\u6d41\u7684\u7b97\u6cd5\u786e\u5b9a\u9053\u8def\u5efa\u8bbe\u4f18\u5148\u7ea7\uff0c\u91c7\u7528\u7279\u5b9a\u65b9\u6cd5\u6c42\u89e3\uff0c\u5f97\u51fa\u4f18\u5148\u9053\u8def\u6bb5\u3002", "motivation": "\u91d1\u6c99\u8428\u5e02\u4ea4\u901a\u62e5\u5835\uff0c\u7efc\u5408\u603b\u4f53\u89c4\u5212\u5b9e\u65bd\u7f3a\u4e4f\u8d44\u91d1\uff0c\u9700\u6709\u6548\u5206\u914d\u6709\u9650\u57fa\u7840\u8bbe\u65bd\u9884\u7b97\uff0c\u786e\u5b9a\u9053\u8def\u5efa\u8bbe\u4f18\u5148\u7ea7\u3002", "method": "\u6784\u5efa\u6807\u51c6\u4ea4\u901a\u7f51\u7edc\u8bbe\u8ba1\u95ee\u9898\uff08TNDP\uff09\uff0c\u7ed3\u5408\u91d1\u6c99\u8428\u5e02\u7279\u5b9a\u8d77\u70b9\u9700\u6c42\u6570\u636e\uff0c\u9009\u62e9\u6027\u6df7\u5408\u4f7f\u7528TNDP\u76f8\u5173\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff08GA\u3001ACO\u3001PSO\u3001SA\u3001TS\u3001Greedy\uff09\uff0c\u8bbe\u8ba1\u8d2a\u5a6a\u641c\u7d22\u79cd\u5b50\u6a21\u62df\u9000\u706b\u548c\u7981\u5fcc\u641c\u7d22\u3002", "result": "\u8d2a\u5a6a\u6a21\u62df\u9000\u706b\u548c\u8d2a\u5a6a\u7981\u5fcc\u641c\u7d22\u5728\u51cf\u5c11\u51fa\u884c\u65f6\u95f4\u548c\u7a33\u5b9a\u6027\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f7f\u7f51\u7edc\u8fb9\u7f18\u4ecb\u6570\u4e2d\u5fc3\u6027\u63d0\u9ad8\u8fd12.5\u500d\u3002", "conclusion": "\u63d0\u51fa\u9053\u8def\u4f18\u5148\u7ea7\uff0c\u5305\u62ec\u8fde\u63a5\u7279\u5b9a\u5165\u53e3\u70b9\u5230\u4e3b\u8981\u666f\u70b9\u4e2d\u5fc3\u53ca\u5e02\u5185\u533a\u57df\u7684\u8def\u53e3\u3002"}}
{"id": "2601.00896", "pdf": "https://arxiv.org/pdf/2601.00896", "abs": "https://arxiv.org/abs/2601.00896", "authors": ["Annabelle Yao"], "title": "Investigation into U.S. Citizen and Non-Citizen Worker Health Insurance and Employment", "categories": ["econ.GN", "cs.LG"], "comment": null, "summary": "Socioeconomic integration is a critical dimension of social equity, yet persistent disparities remain in access to health insurance, education, and employment across different demographic groups. While previous studies have examined isolated aspects of inequality, there is limited research that integrates both statistical analysis and advanced machine learning to uncover hidden structures within population data. This study leverages statistical analysis ($\u03c7^2$ test of independence and Two Proportion Z-Test) and machine learning clustering techniques -- K-Modes and K-Prototypes -- along with t-SNE visualization and CatBoost classification to analyze socioeconomic integration and inequality. Using statistical tests, we identified the proportion of the population with healthcare insurance, quality education, and employment. With this data, we concluded that there was an association between employment and citizenship status. Moreover, we were able to determine 5 distinct population groups using Machine Learning classification. The five clusters our analysis identifies reveal that while citizenship status shows no association with workforce participation, significant disparities exist in access to employer-sponsored health insurance. Each cluster represents a distinct demographic of the population, showing that there is a primary split along the lines of educational attainment which separates Clusters 0 and 4 from Clusters 1, 2, and 3. Furthermore, labor force status and nativity serve as secondary differentiators. Non-citizens are also disproportionately concentrated in precarious employment without benefits, highlighting systemic inequalities in healthcare access. By uncovering demographic clusters that face compounded disadvantages, this research contributes to a more nuanced understanding of socioeconomic stratification.", "AI": {"tldr": "\u672c\u6587\u7ed3\u5408\u7edf\u8ba1\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5206\u6790\u793e\u4f1a\u7ecf\u6d4e\u878d\u5408\u4e0e\u4e0d\u5e73\u7b49\uff0c\u786e\u5b9a\u4e86\u4eba\u53e3\u7fa4\u4f53\u95f4\u7684\u5173\u8054\u548c\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u7cfb\u7edf\u6027\u4e0d\u5e73\u7b49\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u591a\u5b64\u7acb\u8003\u5bdf\u4e0d\u5e73\u7b49\u65b9\u9762\uff0c\u7f3a\u4e4f\u7ed3\u5408\u7edf\u8ba1\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6316\u6398\u4eba\u53e3\u6570\u636e\u9690\u85cf\u7ed3\u6784\u7684\u7814\u7a76\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u8fd0\u7528\u7edf\u8ba1\u5206\u6790\uff08$\u03c7^2$\u72ec\u7acb\u6027\u68c0\u9a8c\u548c\u53cc\u6bd4\u4f8bZ\u68c0\u9a8c\uff09\u548c\u673a\u5668\u5b66\u4e60\u805a\u7c7b\u6280\u672f\uff08K - Modes\u548cK - Prototypes\uff09\uff0c\u4ee5\u53cat - SNE\u53ef\u89c6\u5316\u548cCatBoost\u5206\u7c7b\u3002", "result": "\u786e\u5b9a\u4e86\u6709\u533b\u4fdd\u3001\u4f18\u8d28\u6559\u80b2\u548c\u5c31\u4e1a\u7684\u4eba\u53e3\u6bd4\u4f8b\uff0c\u53d1\u73b0\u5c31\u4e1a\u4e0e\u516c\u6c11\u8eab\u4efd\u6709\u5173\u8054\uff0c\u786e\u5b9a5\u4e2a\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\uff0c\u63ed\u793a\u533b\u4fdd\u83b7\u53d6\u7684\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u6709\u52a9\u4e8e\u66f4\u7ec6\u81f4\u5730\u7406\u89e3\u793e\u4f1a\u7ecf\u6d4e\u5206\u5c42\uff0c\u53d1\u73b0\u9762\u4e34\u591a\u91cd\u52a3\u52bf\u7684\u4eba\u53e3\u7fa4\u4f53\uff0c\u51f8\u663e\u533b\u4fdd\u83b7\u53d6\u7684\u7cfb\u7edf\u6027\u4e0d\u5e73\u7b49\u3002"}}
{"id": "2601.01129", "pdf": "https://arxiv.org/pdf/2601.01129", "abs": "https://arxiv.org/abs/2601.01129", "authors": ["Kla Tantithamthavorn", "Yaotian Zou", "Andy Wong", "Michael Gupta", "Zhe Wang", "Mike Buller", "Ryan Jiang", "Matthew Watson", "Minwoo Jeong", "Kun Chen", "Ming Wu"], "title": "RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": "Accepted at the 48th International Conference on Software Engineering (ICSE'26), SEIP Track. 12 Pages", "summary": "Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning?\n  In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian's development ecosystem with seamless integration into Atlassian's Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is (1) effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and (2) offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4f01\u4e1a\u7ea7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177RovoDev Code Reviewer\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5728\u751f\u6210\u6709\u6548\u5ba1\u67e5\u8bc4\u8bba\u3001\u52a0\u901f\u53cd\u9988\u5468\u671f\u7b49\u65b9\u9762\u8868\u73b0\u826f\u597d", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u8bbe\u8ba1\u4f01\u4e1a\u7ea7\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177\u7684\u5b9e\u9645\u6311\u6218\uff0c\u9700\u8981\u89e3\u51b3\u5982\u4f55\u5728\u4e0d\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u8bbe\u8ba1\u5ba1\u67e5\u5f15\u5bfc\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u8d28\u91cf\u68c0\u67e5\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u95ee\u9898", "method": "\u8bbe\u8ba1\u5e76\u5927\u89c4\u6a21\u90e8\u7f72RovoDev Code Reviewer\u5230Atlassian\u5f00\u53d1\u751f\u6001\u7cfb\u7edf\u548cBitbucket\u4e2d\uff0c\u8fdb\u884c\u4e3a\u671f\u4e00\u5e74\u7684\u79bb\u7ebf\u3001\u5728\u7ebf\u3001\u7528\u6237\u53cd\u9988\u8bc4\u4f30", "result": "\u8be5\u5de5\u5177\u80fd\u4f7f38.70%\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u4fc3\u6210\u4ee3\u7801\u4fee\u6539\uff0c\u51cf\u5c1130.8%\u7684\u62c9\u53d6\u8bf7\u6c42\u5468\u671f\u65f6\u95f4\uff0c\u51cf\u5c1135.6%\u7684\u4eba\u5de5\u7f16\u5199\u8bc4\u8bba\u6570\u91cf\u5e76\u80fd\u53d1\u73b0\u9519\u8bef\u7ed9\u51fa\u53ef\u884c\u5efa\u8bae", "conclusion": "RovoDev Code Reviewer\u6709\u6548\u4e14\u6709\u52a0\u901f\u53cd\u9988\u5468\u671f\u3001\u51cf\u8f7b\u5ba1\u67e5\u8005\u5de5\u4f5c\u91cf\u548c\u63d0\u9ad8\u8f6f\u4ef6\u8d28\u91cf\u7684\u6f5c\u529b"}}
{"id": "2601.01216", "pdf": "https://arxiv.org/pdf/2601.01216", "abs": "https://arxiv.org/abs/2601.01216", "authors": ["Alejandro Rodriguez Dominguez"], "title": "Order-Constrained Spectral Causality in Multivariate Time Series", "categories": ["stat.AP", "math.ST", "q-fin.ST"], "comment": "72 pages, 18 figures, 10 tables", "summary": "We introduce an operator-theoretic framework for causal analysis in multivariate time series based on order-constrained spectral non-invariance. Directional influence is defined as sensitivity of second-order dependence operators to admissible, order-preserving temporal deformations of a designated source component, yielding an intrinsically multivariate causal notion summarized through orthogonally invariant spectral functionals. Under linear Gaussian assumptions, the criterion coincides with linear Granger causality, while beyond this regime it captures collective and nonlinear directional dependence not reflected in pairwise predictability. We establish existence, uniform consistency, and valid inference for the resulting non-smooth supremum--infimum statistics using shift-based randomization that exploits order-induced group invariance, yielding finite-sample exactness under exact invariance and asymptotic validity under weak dependence without parametric assumptions. Simulations demonstrate correct size and strong power against distributed and bulk-dominated alternatives, including nonlinear dependence missed by linear Granger tests with appropriate feature embeddings. An empirical application to a high-dimensional panel of daily financial return series spanning major asset classes illustrates system-level causal monitoring in practice. Directional organization is episodic and stress-dependent, causal propagation strengthens while remaining multi-channel, dominant causal hubs reallocate rapidly, and statistically robust transmission channels are sparse and horizon-heterogeneous even when aggregate lead--lag asymmetry is weak. The framework provides a scalable and interpretable complement to correlation-, factor-, and pairwise Granger-style analyses for complex systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5e8f\u7ea6\u675f\u8c31\u975e\u4e0d\u53d8\u6027\u7684\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u5206\u6790\u7b97\u5b50\u7406\u8bba\u6846\u67b6\uff0c\u7ed9\u51fa\u7edf\u8ba1\u6027\u8d28\uff0c\u6a21\u62df\u9a8c\u8bc1\u6548\u679c\uff0c\u5b9e\u8bc1\u5206\u6790\u91d1\u878d\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u590d\u6742\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\u548c\u96c6\u4f53\u975e\u7ebf\u6027\u4f9d\u8d56\uff0c\u9700\u8981\u65b0\u7684\u56e0\u679c\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5e8f\u7ea6\u675f\u8c31\u975e\u4e0d\u53d8\u6027\u6784\u5efa\u7b97\u5b50\u7406\u8bba\u6846\u67b6\uff0c\u7528\u79fb\u4f4d\u968f\u673a\u5316\u5904\u7406\u975e\u5e73\u6ed1\u6781\u503c\u7edf\u8ba1\u91cf\u3002", "result": "\u6a21\u62df\u663e\u793a\u6709\u6b63\u786e\u68c0\u9a8c\u89c4\u6a21\u548c\u5f3a\u529f\u6548\uff0c\u5b9e\u8bc1\u8868\u660e\u91d1\u878d\u7cfb\u7edf\u56e0\u679c\u7ed3\u6784\u6709\u9636\u6bb5\u548c\u538b\u529b\u4f9d\u8d56\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u662f\u590d\u6742\u7cfb\u7edf\u56e0\u679c\u5206\u6790\u4e2d\u76f8\u5173\u6027\u3001\u56e0\u5b50\u548c\u6210\u5bf9Granger\u5206\u6790\u7684\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u8865\u5145\u3002"}}
{"id": "2601.01604", "pdf": "https://arxiv.org/pdf/2601.01604", "abs": "https://arxiv.org/abs/2601.01604", "authors": ["Nikolaos Korfiatis"], "title": "grangersearch: An R Package for Exhaustive Granger Causality Testing with Tidyverse Integration", "categories": ["stat.CO", "stat.ML"], "comment": "16 pages, 2 figures, R package available at https://github.com/nkorf/grangersearch", "summary": "This paper introduces grangersearch, an R package for performing exhaustive Granger causality searches on multiple time series. The package provides: (1) exhaustive pairwise search across multiple variables, (2) automatic lag order optimization with visualization, (3) tidyverse-compatible syntax with pipe operators and non-standard evaluation, and (4) integration with the broom ecosystem through tidy() and glance() methods. The package wraps the vars infrastructure while providing a simple interface for exploratory causal analysis. We describe the statistical methodology, demonstrate the package through worked examples, and discuss practical considerations for applied researchers.", "AI": {"tldr": "\u4ecb\u7ecdR\u5305grangersearch\u7528\u4e8e\u591a\u65f6\u95f4\u5e8f\u5217\u7684Granger\u56e0\u679c\u5173\u7cfb\u641c\u7d22\uff0c\u9610\u8ff0\u5176\u529f\u80fd\u3001\u65b9\u6cd5\u7b49", "motivation": "\u4e3a\u591a\u65f6\u95f4\u5e8f\u5217\u7684Granger\u56e0\u679c\u5173\u7cfb\u641c\u7d22\u63d0\u4f9b\u4fbf\u6377\u5de5\u5177", "method": "\u5c01\u88c5vars\u57fa\u7840\u8bbe\u65bd\uff0c\u63d0\u4f9b\u7b80\u5355\u63a5\u53e3\uff0c\u5177\u6709\u591a\u79cd\u529f\u80fd\u5982\u6210\u5bf9\u641c\u7d22\u3001\u6ede\u540e\u9636\u4f18\u5316\u7b49", "result": "\u6210\u529f\u5f00\u53d1grangersearch\u5305\uff0c\u5c55\u793a\u4e86\u5176\u529f\u80fd\u548c\u7528\u6cd5", "conclusion": "\u8be5\u5305\u53ef\u7528\u4e8e\u63a2\u7d22\u6027\u56e0\u679c\u5206\u6790\uff0c\u4e3a\u5e94\u7528\u7814\u7a76\u8005\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177"}}
{"id": "2601.00816", "pdf": "https://arxiv.org/pdf/2601.00816", "abs": "https://arxiv.org/abs/2601.00816", "authors": ["Ismail Ahmad Abdullah"], "title": "MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback", "categories": ["cs.AI", "cs.CR", "cs.LG"], "comment": "14 pages, 1 figure, 2 tables, 2 appendices with full proofs. Documents v0.9.4-pilot-audit-hardened audit surface with fail-closed governance, canonical JSON hashing, and artifact classification. Phase I infrastructure validation; no capability claims", "summary": "Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.\n  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.\n  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance", "AI": {"tldr": "\u4ecb\u7ecdMathLedger\u4ee5\u89e3\u51b3\u5f53\u4ee3AI\u7cfb\u7edf\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6d4b\u91cf\u548c\u6cbb\u7406\u57fa\u7840\u67b6\u6784", "motivation": "\u5f53\u4ee3AI\u7cfb\u7edf\u4e0d\u900f\u660e\u4e14\u4e0d\u53ef\u9a8c\u8bc1\uff0c\u5728\u5b89\u5168\u5173\u952e\u90e8\u7f72\u4e2d\u5f15\u53d1\u4fe1\u4efb\u5371\u673a", "method": "\u5f15\u5165MathLedger\uff0c\u5b9e\u73b0Reflexive Formal Learning (RFL)\uff0c\u4ee5\u9a8c\u8bc1\u5668\u7ed3\u679c\u9a71\u52a8\u66f4\u65b0", "result": "Phase I\u5b9e\u9a8c\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\u9a8c\u8bc1\u6d4b\u91cf\u548c\u6cbb\u7406\u57fa\u7840\u67b6\u6784\uff0cCAL - EXP - 3\u9a8c\u8bc1\u6d4b\u91cf\u57fa\u7840\u8bbe\u65bd\uff0c\u538b\u529b\u6d4b\u8bd5\u786e\u8ba4\u8d8a\u754c\u65f6\u6545\u969c\u5173\u95ed\u6cbb\u7406\u89e6\u53d1\u6b63\u5e38", "conclusion": "\u8d21\u732e\u5728\u4e8e\u63d0\u4f9b\u4e00\u4e2a\u53ef\u5927\u89c4\u6a21\u5ba1\u8ba1\u7684\u8d26\u672c\u8ba4\u8bc1\u5b66\u4e60\u7684\u5de5\u4f5c\u539f\u578b"}}
{"id": "2601.01055", "pdf": "https://arxiv.org/pdf/2601.01055", "abs": "https://arxiv.org/abs/2601.01055", "authors": ["Ernest Fokou\u00e9"], "title": "Fibonacci-Driven Recursive Ensembles: Algorithms, Convergence, and Learning Dynamics", "categories": ["stat.ML", "cs.LG"], "comment": "19 pages", "summary": "This paper develops the algorithmic and dynamical foundations of recursive ensemble learning driven by Fibonacci-type update flows. In contrast with classical boosting  Freund and Schapire (1997); Friedman (2001), where the ensemble evolves through first-order additive updates, we study second-order recursive architectures in which each predictor depends on its two immediate predecessors. These Fibonacci flows induce a learning dynamic with memory, allowing ensembles to integrate past structure while adapting to new residual information. We introduce a general family of recursive weight-update algorithms encompassing Fibonacci, tribonacci, and higher-order recursions, together with continuous-time limits that yield systems of differential equations governing ensemble evolution. We establish global convergence conditions, spectral stability criteria, and non-asymptotic generalization bounds under Rademacher Bartlett and Mendelson (2002) and algorithmic stability analyses. The resulting theory unifies recursive ensembles, structured weighting, and dynamical systems viewpoints in statistical learning. Experiments with kernel ridge regression Rasmussen and Williams (2006), spline smoothers Wahba (1990), and random Fourier feature models Rahimi and Recht (2007) demonstrate that recursive flows consistently improve approximation and generalization beyond static weighting. These results complete the trilogy begun in Papers I and II: from Fibonacci weighting, through geometric weighting theory, to fully dynamical recursive ensemble learning systems.", "AI": {"tldr": "\u672c\u6587\u53d1\u5c55\u4e86\u7531\u6590\u6ce2\u90a3\u5951\u578b\u66f4\u65b0\u6d41\u9a71\u52a8\u7684\u9012\u5f52\u96c6\u6210\u5b66\u4e60\u7684\u7b97\u6cd5\u548c\u52a8\u529b\u5b66\u57fa\u7840\uff0c\u5efa\u7acb\u76f8\u5173\u7406\u8bba\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u52bf\u3002", "motivation": "\u4e0e\u7ecf\u5178\u63d0\u5347\u65b9\u6cd5\u4e0d\u540c\uff0c\u7814\u7a76\u4e8c\u9636\u9012\u5f52\u67b6\u6784\u7684\u96c6\u6210\u5b66\u4e60\uff0c\u4f7f\u96c6\u6210\u80fd\u7ed3\u5408\u8fc7\u53bb\u7ed3\u6784\u5e76\u9002\u5e94\u65b0\u7684\u6b8b\u5dee\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u5305\u542b\u6590\u6ce2\u90a3\u5951\u3001\u4e09\u9879\u6590\u6ce2\u90a3\u5951\u53ca\u66f4\u9ad8\u9636\u9012\u5f52\u7684\u9012\u5f52\u6743\u91cd\u66f4\u65b0\u7b97\u6cd5\u5bb6\u65cf\uff0c\u5206\u6790\u8fde\u7eed\u65f6\u95f4\u6781\u9650\uff0c\u5efa\u7acb\u5168\u5c40\u6536\u655b\u6761\u4ef6\u3001\u8c31\u7a33\u5b9a\u6027\u51c6\u5219\u548c\u975e\u6e10\u8fd1\u6cdb\u5316\u754c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u9012\u5f52\u6d41\u5728\u6838\u5cad\u56de\u5f52\u3001\u6837\u6761\u5e73\u6ed1\u5668\u548c\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u6a21\u578b\u4e2d\u80fd\u6301\u7eed\u63d0\u5347\u8fd1\u4f3c\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7406\u8bba\u7edf\u4e00\u4e86\u9012\u5f52\u96c6\u6210\u3001\u7ed3\u6784\u5316\u52a0\u6743\u548c\u52a8\u529b\u7cfb\u7edf\u89c2\u70b9\uff0c\u5b8c\u6210\u4e86\u76f8\u5173\u7814\u7a76\u4e09\u90e8\u66f2\u3002"}}
{"id": "2601.01279", "pdf": "https://arxiv.org/pdf/2601.01279", "abs": "https://arxiv.org/abs/2601.01279", "authors": ["Shengyu Cao", "Ming Hu"], "title": "LLM Collusion", "categories": ["econ.TH", "cs.AI", "cs.CE", "cs.CL", "cs.GT"], "comment": "44 pages", "summary": "We study how delegating pricing to large language models (LLMs) can facilitate collusion in a duopoly when both sellers rely on the same pre-trained model. The LLM is characterized by (i) a propensity parameter capturing its internal bias toward high-price recommendations and (ii) an output-fidelity parameter measuring how tightly outputs track that bias; the propensity evolves through retraining. We show that configuring LLMs for robustness and reproducibility can induce collusion via a phase transition: there exists a critical output-fidelity threshold that pins down long-run behavior. Below it, competitive pricing is the unique long-run outcome. Above it, the system is bistable, with competitive and collusive pricing both locally stable and the realized outcome determined by the model's initial preference. The collusive regime resembles tacit collusion: prices are elevated on average, yet occasional low-price recommendations provide plausible deniability. With perfect fidelity, full collusion emerges from any interior initial condition. For finite training batches of size $b$, infrequent retraining (driven by computational costs) further amplifies collusion: conditional on starting in the collusive basin, the probability of collusion approaches one as $b$ grows, since larger batches dampen stochastic fluctuations that might otherwise tip the system toward competition. The indeterminacy region shrinks at rate $O(1/\\sqrt{b})$.", "AI": {"tldr": "\u7814\u7a76\u53cc\u5be1\u5934\u5e02\u573a\u4e2d\u5356\u5bb6\u4f7f\u7528\u540c\u4e00\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u5b9a\u4ef7\u65f6\u7684\u5408\u8c0b\u60c5\u51b5\uff0c\u5206\u6790\u4e86LLM\u53c2\u6570\u53ca\u8bad\u7ec3\u6279\u6b21\u5bf9\u5b9a\u4ef7\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7a76\u5356\u5bb6\u4f9d\u8d56\u540c\u4e00\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9a\u4ef7\u65f6\u5982\u4f55\u4fc3\u8fdb\u53cc\u5be1\u5934\u5e02\u573a\u7684\u5408\u8c0b\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49LLM\u7684\u503e\u5411\u53c2\u6570\u548c\u8f93\u51fa\u4fdd\u771f\u5ea6\u53c2\u6570\uff0c\u5206\u6790\u4e0d\u540c\u53c2\u6570\u6761\u4ef6\u4e0b\u7684\u5b9a\u4ef7\u7ed3\u679c\uff0c\u8003\u8651\u8bad\u7ec3\u6279\u6b21\u5927\u5c0f\u548c\u518d\u8bad\u7ec3\u9891\u7387\u7684\u5f71\u54cd\u3002", "result": "\u914d\u7f6eLLM\u7684\u9c81\u68d2\u6027\u548c\u53ef\u91cd\u590d\u6027\u53ef\u901a\u8fc7\u76f8\u53d8\u8bf1\u5bfc\u5408\u8c0b\uff0c\u5b58\u5728\u4e34\u754c\u8f93\u51fa\u4fdd\u771f\u5ea6\u9608\u503c\uff1b\u9ad8\u4e8e\u9608\u503c\u7cfb\u7edf\u53cc\u7a33\uff0c\u6709\u7ade\u4e89\u548c\u52fe\u7ed3\u5b9a\u4ef7\u4e24\u79cd\u7ed3\u679c\uff1b\u5b8c\u7f8e\u4fdd\u771f\u5ea6\u65f6\u4ece\u4efb\u4f55\u521d\u59cb\u6761\u4ef6\u90fd\u4f1a\u51fa\u73b0\u5b8c\u5168\u5408\u8c0b\uff1b\u6709\u9650\u8bad\u7ec3\u6279\u6b21\u4e0b\uff0c\u4e0d\u9891\u7e41\u518d\u8bad\u7ec3\u4f1a\u52a0\u5267\u5408\u8c0b\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53c2\u6570\u8bbe\u7f6e\u3001\u8bad\u7ec3\u6279\u6b21\u5927\u5c0f\u548c\u518d\u8bad\u7ec3\u9891\u7387\u4f1a\u5f71\u54cd\u53cc\u5be1\u5934\u5e02\u573a\u7684\u5b9a\u4ef7\u7ed3\u679c\uff0c\u53ef\u80fd\u5bfc\u81f4\u5408\u8c0b\u3002"}}
{"id": "2601.01869", "pdf": "https://arxiv.org/pdf/2601.01869", "abs": "https://arxiv.org/abs/2601.01869", "authors": ["Yi Zhou", "Haoyu Jiang", "Chenghao Zhu", "Andr\u00e9 Rossi"], "title": "Exact Clique Number Manipulation via Edge Interdiction", "categories": ["cs.DS"], "comment": null, "summary": "The Edge Interdiction Clique Problem (EICP) aims to remove at most $k$ edges from a graph so as to minimize the size of the largest clique in the remaining graph. This problem captures a fundamental question in graph manipulation: which edges are structurally critical for preserving large cliques? Such a problem is also motivated by practical applications including protein function maintenance and image matching. The EICP is computationally challenging and belongs to a complexity class beyond NP. Existing approaches rely on general mixed-integer bilevel programming solvers or reformulate the problem into a single-level mixed integer linear program. However, they are still not scalable when the graph size and interdiction budget $k$ grow. To overcome this, we investigate new mixed integer linear formulations, which recast the problem into a sequence of parameterized Edge Blocker Clique Problems (EBCP). This perspective decomposes the original problem into simpler subproblems and enables tighter modeling of clique-related inequalities. Furthermore, we propose a two-stage exact algorithm, \\textsc{RLCM}, which first applies problem-specific reduction techniques to shrink the graph and then solves the reduced problem using a tailored branch-and-cut framework. Extensive computational experiments on maximum clique benchmark graphs, large real-world sparse networks, and random graphs demonstrate that \\textsc{RLCM} consistently outperforms existing approaches.", "AI": {"tldr": "\u7814\u7a76Edge Interdiction Clique Problem (EICP)\uff0c\u63d0\u51fa\u65b0\u6df7\u5408\u6574\u6570\u7ebf\u6027\u516c\u5f0f\u548c\u4e24\u9636\u6bb5\u7cbe\u786e\u7b97\u6cd5RLCM\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "EICP\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u73b0\u6709\u6c42\u89e3\u65b9\u6cd5\u5728\u56fe\u89c4\u6a21\u548c\u963b\u65ad\u9884\u7b97k\u589e\u957f\u65f6\u7f3a\u4e4f\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u65b0\u6df7\u5408\u6574\u6570\u7ebf\u6027\u516c\u5f0f\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u53c2\u6570\u5316Edge Blocker Clique Problems (EBCP)\uff0c\u5e76\u63d0\u51fa\u4e24\u9636\u6bb5\u7cbe\u786e\u7b97\u6cd5RLCM\uff0c\u5148\u7f29\u56fe\u518d\u7528\u5b9a\u5236\u5206\u652f\u5272\u5e73\u9762\u6846\u67b6\u6c42\u89e3\u3002", "result": "\u5728\u6700\u5927\u56e2\u57fa\u51c6\u56fe\u3001\u5927\u578b\u73b0\u5b9e\u7a00\u758f\u7f51\u7edc\u548c\u968f\u673a\u56fe\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cRLCM\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u89e3\u51b3EICP\u4e0a\u6709\u66f4\u597d\u7684\u6027\u80fd\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.01209", "pdf": "https://arxiv.org/pdf/2601.01209", "abs": "https://arxiv.org/abs/2601.01209", "authors": ["Xin Tan", "Yicheng Feng", "Yu Zhou", "Yimin Jiang", "Yibo Zhu", "Hong Xu"], "title": "OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL", "categories": ["cs.DC", "cs.NI"], "comment": null, "summary": "Post-training with reinforcement learning (RL) has greatly enhanced the capabilities of large language models. Disaggregating the generation and training stages in RL into a parallel, asynchronous pipeline offers the potential for flexible scaling and improved throughput. However, it still faces two critical challenges. First, the generation stage often becomes a bottleneck due to dynamic workload shifts and severe execution imbalances. Second, the decoupled stages result in diverse and dynamic network traffic patterns that overwhelm conventional network fabrics. This paper introduces OrchestrRL, an orchestration framework that dynamically manages compute and network rhythms in disaggregated RL. To improve generation efficiency, OrchestrRL employs an adaptive compute scheduler that dynamically adjusts parallelism to match workload characteristics within and across generation steps. This accelerates execution while continuously rebalancing requests to mitigate stragglers. To address the dynamic network demands inherent in disaggregated RL -- further intensified by parallelism switching -- we co-design RFabric, a reconfigurable hybrid optical-electrical fabric. RFabric leverages optical circuit switches at selected network tiers to reconfigure the topology in real time, enabling workload-aware circuits for (i) layer-wise collective communication during training iterations, (ii) generation under different parallelism configurations, and (iii) periodic inter-cluster weight synchronization. We evaluate OrchestrRL on a physical testbed with 48 H800 GPUs, demonstrating up to a 1.40x throughput improvement. Furthermore, we develop RLSim, a high-fidelity simulator, to evaluate RFabric at scale. Our results show that RFabric achieves superior performance-cost efficiency compared to static Fat-Tree networks, establishing it as a highly effective solution for large-scale RL workloads.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdOrchestrRL\u6846\u67b6\u548cRFabric\u7f51\u7edc\uff0c\u89e3\u51b3\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u4e2d\u8ba1\u7b97\u548c\u7f51\u7edc\u95ee\u9898\uff0c\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u5728\u751f\u6210\u9636\u6bb5\u548c\u7f51\u7edc\u6d41\u91cf\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u91c7\u7528\u81ea\u9002\u5e94\u8ba1\u7b97\u8c03\u5ea6\u5668\u8c03\u6574\u5e76\u884c\u5ea6\uff0c\u5171\u540c\u8bbe\u8ba1\u53ef\u91cd\u6784\u6df7\u5408\u5149 - \u7535\u7f51\u7edcRFabric\u3002", "result": "\u572848\u4e2aH800 GPU\u7269\u7406\u6d4b\u8bd5\u5e8a\u4e0a\u541e\u5410\u91cf\u63d0\u53471.40\u500d\uff0cRFabric\u6027\u80fd - \u6210\u672c\u6548\u7387\u4f18\u4e8e\u9759\u6001Fat - Tree\u7f51\u7edc\u3002", "conclusion": "OrchestrRL\u548cRFabric\u662f\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01254", "pdf": "https://arxiv.org/pdf/2601.01254", "abs": "https://arxiv.org/abs/2601.01254", "authors": ["Azrin Sultana", "Hasibur Rashid Chayon"], "title": "Entity-Aware and Secure Query Optimization in Database Using Named Entity Recognition", "categories": ["cs.DB", "cs.CL"], "comment": "48 pages, 15 figures, 14 tables", "summary": "Cloud storage has become the backbone of modern data infrastructure, yet privacy and efficient data retrieval remain significant challenges. Traditional privacy-preserving approaches primarily focus on enhancing database security but fail to address the automatic identification of sensitive information before encryption. This can dramatically reduce query processing time and mitigate errors during manual identification of sensitive information, thereby reducing potential privacy risks. To address this limitation, this research proposes an intelligent privacy-preserving query optimization framework that integrates Named Entity Recognition (NER) to detect sensitive information in queries, utilizing secure data encryption and query optimization techniques for both sensitive and non-sensitive data in parallel, thereby enabling efficient database optimization. Combined deep learning algorithms and transformer-based models to detect and classify sensitive entities with high precision, and the Advanced Encryption Standard (AES) algorithm to encrypt, with blind indexing to secure search functionality of the sensitive data, whereas non-sensitive data was divided into groups using the K-means algorithm, along with a rank search for optimization. Among all NER models, the Deep Belief Network combined with Long Short-Term Memory (DBN-LSTM) delivers the best performance, with an accuracy of 93% and precision (94%), recall, and F1 score of 93%, and 93%, respectively. Besides, encrypted search achieved considerably faster results with the help of blind indexing, and non-sensitive data fetching also outperformed traditional clustering-based searches. By integrating sensitive data detection, encryption, and query optimization, this work advances the state of privacy-preserving computation in modern cloud infrastructures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u667a\u80fd\u9690\u79c1\u4fdd\u62a4\u67e5\u8be2\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408NER\u68c0\u6d4b\u654f\u611f\u4fe1\u606f\uff0c\u5e76\u884c\u5904\u7406\u654f\u611f\u548c\u975e\u654f\u611f\u6570\u636e\u4f18\u5316\u6570\u636e\u5e93\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u672a\u89e3\u51b3\u52a0\u5bc6\u524d\u654f\u611f\u4fe1\u606f\u81ea\u52a8\u8bc6\u522b\u95ee\u9898\uff0c\u5b58\u5728\u67e5\u8be2\u5904\u7406\u65f6\u95f4\u957f\u3001\u624b\u52a8\u8bc6\u522b\u6613\u51fa\u9519\u7b49\u6f5c\u5728\u9690\u79c1\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u96c6\u6210NER\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u6a21\u578b\u68c0\u6d4b\u5206\u7c7b\u654f\u611f\u5b9e\u4f53\uff0c\u7528AES\u7b97\u6cd5\u52a0\u5bc6\uff0c\u76f2\u7d22\u5f15\u4fdd\u969c\u654f\u611f\u6570\u636e\u641c\u7d22\uff1b\u7528K-means\u7b97\u6cd5\u5bf9\u975e\u654f\u611f\u6570\u636e\u5206\u7ec4\uff0c\u7528\u6392\u540d\u641c\u7d22\u4f18\u5316\u3002", "result": "DBN - LSTM\u6a21\u578b\u6027\u80fd\u6700\u4f73\uff0c\u51c6\u786e\u7387\u7b49\u6307\u6807\u8d8593%\uff1b\u52a0\u5bc6\u641c\u7d22\u548c\u975e\u654f\u611f\u6570\u636e\u67e5\u8be2\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u96c6\u6210\u654f\u611f\u6570\u636e\u68c0\u6d4b\u3001\u52a0\u5bc6\u548c\u67e5\u8be2\u4f18\u5316\uff0c\u63a8\u52a8\u73b0\u4ee3\u4e91\u57fa\u7840\u8bbe\u65bd\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u53d1\u5c55\u3002"}}
{"id": "2601.02075", "pdf": "https://arxiv.org/pdf/2601.02075", "abs": "https://arxiv.org/abs/2601.02075", "authors": ["Zhuofan Shi", "Hubao A", "Yufei Shao", "Mengyan Dai", "Yadong Yu", "Pan Xiang", "Dongliang Huang", "Hongxu An", "Chunxiao Xin", "Haiyang Shen", "Zhenyu Wang", "Yunshan Na", "Gang Huang", "Xiang Jing"], "title": "MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics", "categories": ["cs.CE", "cs.LG"], "comment": "24 pages,4 figures", "summary": "Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials science, yet writing LAMMPS scripts remains highly specialized and time-consuming tasks. Although LLMs show promise in code generation and domain-specific question answering, their performance in MD scenarios is limited by scarce domain data, the high deployment cost of state-of-the-art LLMs, and low code executability. Building upon our prior MDAgent, we present MDAgent2, the first end-to-end framework capable of performing both knowledge Q&A and code generation within the MD domain. We construct a domain-specific data-construction pipeline that yields three high-quality datasets spanning MD knowledge, question answering, and code generation. Based on these datasets, we adopt a three stage post-training strategy--continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning (RL)--to train two domain-adapted models, MD-Instruct and MD-Code. Furthermore, we introduce MD-GRPO, a closed-loop RL method that leverages simulation outcomes as reward signals and recycles low-reward trajectories for continual refinement. We further build MDAgent2-RUNTIME, a deployable multi-agent system that integrates code generation, execution, evaluation, and self-correction. Together with MD-EvalBench proposed in this work, the first benchmark for LAMMPS code generation and question answering, our models and system achieve performance surpassing several strong baselines.This work systematically demonstrates the adaptability and generalization capability of large language models in industrial simulation tasks, laying a methodological foundation for automatic code generation in AI for Science and industrial-scale simulations. URL: https://github.com/FredericVAN/PKU_MDAgent2", "AI": {"tldr": "\u63d0\u51faMDAgent2\u6846\u67b6\u7528\u4e8e\u5206\u5b50\u52a8\u529b\u5b66\u9886\u57df\u77e5\u8bc6\u95ee\u7b54\u548c\u4ee3\u7801\u751f\u6210\uff0c\u6784\u5efa\u6570\u636e\u96c6\u3001\u8bad\u7ec3\u6a21\u578b\u3001\u5f15\u5165\u65b0\u65b9\u6cd5\u548c\u7cfb\u7edf\uff0c\u6027\u80fd\u8d85\u57fa\u7ebf\uff0c\u4e3a\u5de5\u4e1a\u6a21\u62df\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u4e2d\u7f16\u5199LAMMPS\u811a\u672c\u4e13\u4e1a\u4e14\u8017\u65f6\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u573a\u666f\u53d7\u6570\u636e\u3001\u6210\u672c\u548c\u4ee3\u7801\u53ef\u6267\u884c\u6027\u9650\u5236\u3002", "method": "\u6784\u5efa\u9886\u57df\u7279\u5b9a\u6570\u636e\u6784\u5efa\u7ba1\u9053\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u540e\u8bad\u7ec3\u7b56\u7565\u8bad\u7ec3\u4e24\u4e2a\u9886\u57df\u9002\u914d\u6a21\u578b\uff0c\u5f15\u5165MD - GRPO\u65b9\u6cd5\uff0c\u6784\u5efaMDAgent2 - RUNTIME\u7cfb\u7edf\u548cMD - EvalBench\u57fa\u51c6\u3002", "result": "\u6a21\u578b\u548c\u7cfb\u7edf\u6027\u80fd\u8d85\u8d8a\u591a\u4e2a\u5f3a\u57fa\u7ebf\u3002", "conclusion": "\u8bc1\u660e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u4e1a\u6a21\u62df\u4efb\u52a1\u4e2d\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u79d1\u5b66\u548c\u5de5\u4e1a\u89c4\u6a21\u6a21\u62df\u7684\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u5960\u5b9a\u65b9\u6cd5\u57fa\u7840\u3002"}}
{"id": "2601.00912", "pdf": "https://arxiv.org/pdf/2601.00912", "abs": "https://arxiv.org/abs/2601.00912", "authors": ["Amit Prakash Sharma"], "title": "The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries", "categories": ["cs.IR", "cs.AI"], "comment": "20 pages, 7 figures. Based on M.Tech thesis research, Indian Institute of Technology Patna, 2025", "summary": "When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions.\n  I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search).\n  The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like \"What are the best AI tools launched this year?\" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT.\n  Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores.\n  What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002).\n  The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5\u4e24\u6b3e\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u521d\u521b\u4ea7\u54c1\u7684\u8bc6\u522b\u60c5\u51b5\uff0c\u53d1\u73b0\u6309\u540d\u79f0\u8be2\u95ee\u8bc6\u522b\u7387\u9ad8\uff0c\u53d1\u73b0\u5f0f\u95ee\u9898\u8bc6\u522b\u7387\u4f4e\uff0cGEO\u4e0e\u53d1\u73b0\u7387\u65e0\u5173\uff0c\u5efa\u8bae\u5148\u6253\u597dSEO\u57fa\u7840\u3002", "motivation": "\u63a2\u7a76ChatGPT\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u56de\u5e94\u4e2d\u662f\u5426\u4f1a\u51fa\u73b0\u65b0\u63a8\u51fa\u7684\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u7b49\u95ee\u9898\u3002", "method": "\u4ece2025\u5e74Product Hunt\u6392\u884c\u699c\u524d500\u4ea7\u54c1\u4e2d\u968f\u673a\u9009112\u5bb6\u521d\u521b\u516c\u53f8\uff0c\u5bf9ChatGPT\u548cPerplexity\u8fdb\u884c2240\u6b21\u67e5\u8be2\u6d4b\u8bd5\u3002", "result": "\u6309\u540d\u79f0\u8be2\u95ee\u65f6\u4e24\u6b3e\u6a21\u578b\u8bc6\u522b\u7387\u9ad8\uff0c\u53d1\u73b0\u5f0f\u95ee\u9898\u8bc6\u522b\u7387\u4f4e\uff1bGEO\u4e0e\u53d1\u73b0\u7387\u65e0\u5173\u8054\uff1bPerplexity\u4e2d\u4f20\u7edfSEO\u4fe1\u53f7\u548c\u793e\u533a\u5b58\u5728\u5ea6\u5f71\u54cd\u53ef\u89c1\u6027\u3002", "conclusion": "\u4e0d\u8981\u76f4\u63a5\u4e3aAI\u53d1\u73b0\u8fdb\u884c\u4f18\u5316\uff0c\u5e94\u5148\u6253\u597dSEO\u57fa\u7840\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u89c1\u6027\u3002"}}
{"id": "2601.01265", "pdf": "https://arxiv.org/pdf/2601.01265", "abs": "https://arxiv.org/abs/2601.01265", "authors": ["Nick Lindsay", "Caroline Trippel", "Anurag Khandelwal", "Abhishek Bhattacharjee"], "title": "CounterPoint: Using Hardware Event Counters to Refute and Refine Microarchitectural Assumptions (Extended Version)", "categories": ["cs.AR", "cs.OS", "cs.PF"], "comment": "This is an extended version of a paper which has been accepted to the 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems conference (ASPLOS, March 2026). 20 pages, 20 figures, 8 tables", "summary": "Hardware event counters offer the potential to reveal not only performance bottlenecks but also detailed microarchitectural behavior. In practice, this promise is undermined by their vague specifications, opaque designs, and multiplexing noise, making event counter data hard to interpret.\n  We introduce CounterPoint, a framework that tests user-specified microarchitectural models - expressed as $\u03bc$path Decision Diagrams - for consistency with performance counter data. When mismatches occur, CounterPoint pinpoints plausible microarchitectural features that could explain them, using multi-dimensional counter confidence regions to mitigate multiplexing noise. We apply CounterPoint to the Haswell Memory Management Unit as a case study, shedding light on multiple undocumented and underdocumented microarchitectural behaviors. These include a load-store queue-side TLB prefetcher, merging page table walkers, abortable page table walks, and more.\n  Overall, CounterPoint helps experts reconcile noisy hardware performance counter measurements with their mental model of the microarchitecture - uncovering subtle, previously hidden hardware features along the way.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86CounterPoint\u6846\u67b6\uff0c\u53ef\u6d4b\u8bd5\u5fae\u67b6\u6784\u6a21\u578b\u4e0e\u6027\u80fd\u8ba1\u6570\u5668\u6570\u636e\u7684\u4e00\u81f4\u6027\uff0c\u5e94\u7528\u4e8eHaswell MMU\u6848\u4f8b\u53d1\u73b0\u591a\u79cd\u672a\u8bb0\u5f55\u7684\u5fae\u67b6\u6784\u884c\u4e3a\u3002", "motivation": "\u786c\u4ef6\u4e8b\u4ef6\u8ba1\u6570\u5668\u56e0\u89c4\u683c\u6a21\u7cca\u3001\u8bbe\u8ba1\u4e0d\u900f\u660e\u548c\u590d\u7528\u566a\u58f0\u7b49\u95ee\u9898\uff0c\u6570\u636e\u96be\u4ee5\u89e3\u91ca\uff0c\u9700\u8981\u6709\u6548\u65b9\u6cd5\u6765\u5229\u7528\u5176\u6570\u636e\u3002", "method": "\u5f15\u5165CounterPoint\u6846\u67b6\uff0c\u6d4b\u8bd5\u7528\u03bcpath\u51b3\u7b56\u56fe\u8868\u8fbe\u7684\u7528\u6237\u6307\u5b9a\u5fae\u67b6\u6784\u6a21\u578b\u4e0e\u6027\u80fd\u8ba1\u6570\u5668\u6570\u636e\u7684\u4e00\u81f4\u6027\uff0c\u7528\u591a\u7ef4\u8ba1\u6570\u5668\u7f6e\u4fe1\u533a\u57df\u51cf\u5c11\u590d\u7528\u566a\u58f0\u3002", "result": "\u5c06CounterPoint\u5e94\u7528\u4e8eHaswell Memory Management Unit\u6848\u4f8b\uff0c\u53d1\u73b0\u4e86\u8d1f\u8f7d\u5b58\u50a8\u961f\u5217\u7aefTLB\u9884\u53d6\u5668\u7b49\u591a\u79cd\u672a\u8bb0\u5f55\u548c\u8bb0\u5f55\u4e0d\u8db3\u7684\u5fae\u67b6\u6784\u884c\u4e3a\u3002", "conclusion": "CounterPoint\u80fd\u5e2e\u52a9\u4e13\u5bb6\u534f\u8c03\u786c\u4ef6\u6027\u80fd\u8ba1\u6570\u5668\u6d4b\u91cf\u6570\u636e\u548c\u4ed6\u4eec\u7684\u5fae\u67b6\u6784\u5fc3\u7406\u6a21\u578b\uff0c\u53d1\u73b0\u9690\u85cf\u7684\u786c\u4ef6\u7279\u6027\u3002"}}
{"id": "2601.00805", "pdf": "https://arxiv.org/pdf/2601.00805", "abs": "https://arxiv.org/abs/2601.00805", "authors": ["Sarim Chaudhry"], "title": "ChronoPlastic Spiking Neural Networks", "categories": ["cs.NE", "cs.LG"], "comment": "21 pages, 6 figures", "summary": "Spiking neural networks (SNNs) offer a biologically grounded and energy-efficient alternative to conventional neural architectures; however, they struggle with long-range temporal dependencies due to fixed synaptic and membrane time constants. This paper introduces ChronoPlastic Spiking Neural Networks (CPSNNs), a novel architectural principle that enables adaptive temporal credit assignment by dynamically modulating synaptic decay rates conditioned on the state of the network. CPSNNs maintain multiple internal temporal traces and learn a continuous time-warping function that selectively preserves task-relevant information while rapidly forgetting noise. Unlike prior approaches based on adaptive membrane constants, attention mechanisms, or external memory, CPSNNs embed temporal control directly within local synaptic dynamics, preserving linear-time complexity and neuromorphic compatibility. We provide a formal description of the model, analyze its computational properties, and demonstrate empirically that CPSNNs learn long-gap temporal dependencies significantly faster and more reliably than standard SNN baselines. Our results suggest that adaptive temporal modulation is a key missing ingredient for scalable temporal learning in spiking systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faChronoPlastic Spiking Neural Networks\uff08CPSNNs\uff09\u89e3\u51b3SNNs\u957f\u65f6\u4f9d\u8d56\u95ee\u9898\uff0c\u5176\u5b66\u4e60\u957f\u65f6\u4f9d\u8d56\u66f4\u5feb\u66f4\u53ef\u9760\uff0c\u8bf4\u660e\u81ea\u9002\u5e94\u65f6\u95f4\u8c03\u5236\u5bf9\u8109\u51b2\u7cfb\u7edf\u65f6\u95f4\u5b66\u4e60\u5f88\u5173\u952e\u3002", "motivation": "Spiking neural networks\uff08SNNs\uff09\u5b58\u5728\u957f\u65f6\u4f9d\u8d56\u95ee\u9898\uff0c\u56e0\u7a81\u89e6\u548c\u819c\u65f6\u95f4\u5e38\u6570\u56fa\u5b9a\u96be\u4ee5\u5904\u7406\u3002", "method": "\u63d0\u51faCPSNNs\u67b6\u6784\uff0c\u52a8\u6001\u8c03\u8282\u7a81\u89e6\u8870\u51cf\u7387\u4ee5\u5b9e\u73b0\u81ea\u9002\u5e94\u65f6\u95f4\u4fe1\u7528\u5206\u914d\uff0c\u7ef4\u62a4\u591a\u4e2a\u5185\u90e8\u65f6\u95f4\u8f68\u8ff9\u5e76\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u626d\u66f2\u51fd\u6570\uff0c\u5c06\u65f6\u95f4\u63a7\u5236\u5d4c\u5165\u5c40\u90e8\u7a81\u89e6\u52a8\u529b\u5b66\u3002", "result": "CPSNNs\u5b66\u4e60\u957f\u65f6\u4f9d\u8d56\u6bd4\u6807\u51c6SNN\u57fa\u7ebf\u66f4\u5feb\u4e14\u66f4\u53ef\u9760\u3002", "conclusion": "\u81ea\u9002\u5e94\u65f6\u95f4\u8c03\u5236\u662f\u8109\u51b2\u7cfb\u7edf\u53ef\u6269\u5c55\u65f6\u95f4\u5b66\u4e60\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2601.00914", "pdf": "https://arxiv.org/pdf/2601.00914", "abs": "https://arxiv.org/abs/2601.00914", "authors": ["Richard Yun"], "title": "Sticky Homelessness (Working Paper)", "categories": ["econ.GN"], "comment": "I share credit with Cynthia Shi for the dataset used in this paper, Metro Homelessness Atlas. Many thanks to Lio Perez for his thoughtful comments and feedback. -Cynthia's LinkedIn: https://www.linkedin.com/in/cynthia-shi-94098518a/?locale=es_ES&trk=people-guest_people_search-card -Lio's LinkedIn: https://www.linkedin.com/in/cecilio-ryu-perez/", "summary": "Homelessness in American cities is becoming an ever more prominent issue, but its causes remain contested, ranging from mental health and substance abuse to housing affordability and local labor markets. To shed light on this issue, I construct a novel MSA-level national panel of homelessness counts using data from the U.S. Department of Housing and Urban Development. Using a long-differencing regression specification with the changes in rent entered in piecewise linear form, I find that rent increases predict large increases in homelessness rates, but decreases have little to no effect. The same conclusions are reached when I use a quasi-differencing moment condition, assuming a multiplicative mean specification. Then, I propose a theoretical model of the low-end housing market that explains the asymmetry I find in the data. Finally, I outline an IV strategy that instruments rent changes with a Bartik instrument of predicted employment growth interacted with local housing-supply elasticities. My findings suggest that homelessness is a housing problem; however, because the response is sticky downward, effective policy must complement housing-market interventions with measures that address barriers faced by people experiencing homelessness.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u65b0\u6570\u636e\u548c\u591a\u79cd\u65b9\u6cd5\u5206\u6790\u7f8e\u56fd\u65e0\u5bb6\u53ef\u5f52\u95ee\u9898\uff0c\u53d1\u73b0\u79df\u91d1\u4e0a\u6da8\u5927\u5e45\u589e\u52a0\u65e0\u5bb6\u53ef\u5f52\u7387\uff0c\u63d0\u51fa\u7406\u8bba\u6a21\u578b\u548cIV\u7b56\u7565\uff0c\u8ba4\u4e3a\u65e0\u5bb6\u53ef\u5f52\u662f\u4f4f\u623f\u95ee\u9898\uff0c\u653f\u7b56\u9700\u7ed3\u5408\u4f4f\u623f\u5e72\u9884\u548c\u89e3\u51b3\u5176\u4ed6\u969c\u788d\u3002", "motivation": "\u7f8e\u56fd\u57ce\u5e02\u65e0\u5bb6\u53ef\u5f52\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u4f46\u6210\u56e0\u5b58\u5728\u4e89\u8bae\uff0c\u65e8\u5728\u63a2\u7a76\u5176\u6210\u56e0\u3002", "method": "\u6784\u5efaMSA\u5c42\u9762\u65e0\u5bb6\u53ef\u5f52\u4eba\u6570\u5168\u56fd\u9762\u677f\u6570\u636e\uff0c\u91c7\u7528\u957f\u5dee\u5206\u56de\u5f52\u3001\u51c6\u5dee\u5206\u77e9\u6761\u4ef6\u3001\u63d0\u51fa\u7406\u8bba\u6a21\u578b\u3001\u4f7f\u7528Bartik\u5de5\u5177\u53d8\u91cf\u7b56\u7565\u3002", "result": "\u79df\u91d1\u4e0a\u6da8\u5927\u5e45\u589e\u52a0\u65e0\u5bb6\u53ef\u5f52\u7387\uff0c\u4e0b\u964d\u5f71\u54cd\u5c0f\uff0c\u5b58\u5728\u6570\u636e\u4e0d\u5bf9\u79f0\u6027\u3002", "conclusion": "\u65e0\u5bb6\u53ef\u5f52\u662f\u4f4f\u623f\u95ee\u9898\uff0c\u6709\u6548\u653f\u7b56\u9700\u7ed3\u5408\u4f4f\u623f\u5e02\u573a\u5e72\u9884\u548c\u89e3\u51b3\u65e0\u5bb6\u53ef\u5f52\u8005\u9762\u4e34\u7684\u969c\u788d\u3002"}}
{"id": "2601.01199", "pdf": "https://arxiv.org/pdf/2601.01199", "abs": "https://arxiv.org/abs/2601.01199", "authors": ["Logan Murphy", "Aren A. Babikian", "Marsha Chechik"], "title": "Abductive Vibe Coding (Extended Abstract)", "categories": ["cs.SE"], "comment": null, "summary": "When software artifacts are generated by AI models (\"vibe coding\"), human engineers assume responsibility for validating them. Ideally, this validation would be done through the creation of a formal proof of correctness. However, this is infeasible for many real-world vibe coding scenarios, especially when requirements for the AI-generated artifacts resist formalization. This extended abstract describes ongoing work towards the extraction of analyzable, semi-formal rationales for the adequacy of vibe-coded artifacts. Rather than deciding correctness directly, our framework produces a set of conditions under which the generated code can be considered adequate. We describe current efforts towards implementing our framework and anticipated research opportunities.", "AI": {"tldr": "\u8be5\u6458\u8981\u4ecb\u7ecd\u4e86\u9488\u5bf9AI\u751f\u6210\u8f6f\u4ef6\u5de5\u4ef6\u63d0\u53d6\u53ef\u5206\u6790\u534a\u5f62\u5f0f\u5316\u4f9d\u636e\u7684\u5de5\u4f5c\uff0c\u6846\u67b6\u751f\u6210\u4ee3\u7801\u5145\u8db3\u6027\u6761\u4ef6\uff0c\u8fd8\u63d0\u53ca\u5f53\u524d\u5de5\u4f5c\u548c\u7814\u7a76\u673a\u4f1a\u3002", "motivation": "\u5b9e\u9645\u573a\u666f\u4e2d\u96be\u4ee5\u901a\u8fc7\u521b\u5efa\u6b63\u786e\u6027\u5f62\u5f0f\u8bc1\u660e\u6765\u9a8c\u8bc1AI\u751f\u6210\u7684\u8f6f\u4ef6\u5de5\u4ef6\u3002", "method": "\u5f00\u53d1\u6846\u67b6\u63d0\u53d6\u53ef\u5206\u6790\u7684\u3001\u534a\u5f62\u5f0f\u5316\u7684\u7406\u7531\uff0c\u751f\u6210\u751f\u6210\u4ee3\u7801\u53ef\u88ab\u8ba4\u4e3a\u5145\u8db3\u7684\u6761\u4ef6\u96c6\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\uff0c\u4f46\u6307\u51fa\u4e86\u5f53\u524d\u5b9e\u65bd\u6846\u67b6\u7684\u52aa\u529b\u65b9\u5411\u548c\u9884\u671f\u7684\u7814\u7a76\u673a\u4f1a\u3002"}}
{"id": "2601.01871", "pdf": "https://arxiv.org/pdf/2601.01871", "abs": "https://arxiv.org/abs/2601.01871", "authors": ["Takaaki Shiotani", "Takaki Hayashi", "Yuta Koike"], "title": "On lead-lag estimation of non-synchronously observed point processes", "categories": ["math.ST", "q-fin.ST", "stat.ME"], "comment": "52 pages, 6 figures, 1 table", "summary": "This paper introduces a new theoretical framework for analyzing lead-lag relationships between point processes, with a special focus on applications to high-frequency financial data. In particular, we are interested in lead-lag relationships between two sequences of order arrival timestamps. The seminal work of Dobrev and Schaumburg proposed model-free measures of cross-market trading activity based on cross-counts of timestamps. While their method is known to yield reliable results, it faces limitations because its original formulation inherently relies on discrete-time observations, an issue we address in this study. Specifically, we formulate the problem of estimating lead-lag relationships in two point processes as that of estimating the shape of the cross-pair correlation function (CPCF) of a bivariate stationary point process, a quantity well-studied in the neuroscience and spatial statistics literature. Within this framework, the prevailing lead-lag time is defined as the location of the CPCF's sharpest peak. Under this interpretation, the peak location in Dobrev and Schaumburg's cross-market activity measure can be viewed as an estimator of the lead-lag time in the aforementioned sense. We further propose an alternative lead-lag time estimator based on kernel density estimation and show that it possesses desirable theoretical properties and delivers superior numerical performance. Empirical evidence from high-frequency financial data demonstrates the effectiveness of our proposed method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5206\u6790\u70b9\u8fc7\u7a0b\u9886\u5148 - \u6ede\u540e\u5173\u7cfb\u7684\u65b0\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u9891\u91d1\u878d\u6570\u636e\uff0c\u63d0\u51fa\u65b0\u4f30\u8ba1\u91cf\u5e76\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "Dobrev\u548cSchaumburg\u7684\u65b9\u6cd5\u4f9d\u8d56\u79bb\u6563\u65f6\u95f4\u89c2\u6d4b\u6709\u5c40\u9650\u6027\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5c06\u4f30\u8ba1\u4e24\u4e2a\u70b9\u8fc7\u7a0b\u9886\u5148 - \u6ede\u540e\u5173\u7cfb\u95ee\u9898\u8f6c\u5316\u4e3a\u4f30\u8ba1\u4e8c\u5143\u5e73\u7a33\u70b9\u8fc7\u7a0b\u7684\u4ea4\u53c9\u5bf9\u76f8\u5173\u51fd\u6570\uff08CPCF\uff09\u5f62\u72b6\uff0c\u63d0\u51fa\u57fa\u4e8e\u6838\u5bc6\u5ea6\u4f30\u8ba1\u7684\u9886\u5148 - \u6ede\u540e\u65f6\u95f4\u4f30\u8ba1\u91cf\u3002", "result": "\u65b0\u4f30\u8ba1\u91cf\u6709\u826f\u597d\u7406\u8bba\u6027\u8d28\u548c\u4f18\u8d8a\u6570\u503c\u6027\u80fd\u3002", "conclusion": "\u5b9e\u8bc1\u8868\u660e\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2601.00818", "pdf": "https://arxiv.org/pdf/2601.00818", "abs": "https://arxiv.org/abs/2601.00818", "authors": ["Chandra Sekhar Kubam"], "title": "Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making", "categories": ["cs.AI"], "comment": "8 pages", "summary": "Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAgentic AI\u6846\u67b6\u7528\u4e8e\u4fe1\u8d37\u98ce\u9669\u51b3\u7b56\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u4f46\u5b58\u5728\u5b9e\u9645\u9650\u5236\uff0c\u672a\u6765\u7814\u7a76\u6709\u591a\u79cd\u65b9\u5411\u3002", "motivation": "\u91d1\u878d\u670d\u52a1\u6570\u5b57\u5316\u50ac\u751f\u5bf9\u81ea\u4e3b\u3001\u900f\u660e\u548c\u5b9e\u65f6\u4fe1\u8d37\u98ce\u9669\u51b3\u7b56\u7cfb\u7edf\u7684\u9700\u6c42\uff0c\u800c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65e0\u6cd5\u6ee1\u8db3\u73b0\u4ee3\u91d1\u878d\u8fd0\u8425\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u5305\u542b\u5f3a\u5316\u5b66\u4e60\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u3001\u53ef\u89e3\u91caAI\u6a21\u5757\u548c\u5b9e\u65f6\u6570\u636e\u5438\u6536\u7ba1\u9053\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6709\u534f\u4f5c\u534f\u8bae\u3001\u98ce\u9669\u8bc4\u5206\u5f15\u64ce\u7b49\u6d41\u7a0b\u3002", "result": "\u51b3\u7b56\u901f\u5ea6\u3001\u900f\u660e\u5ea6\u548c\u54cd\u5e94\u80fd\u529b\u4f18\u4e8e\u4f20\u7edf\u4fe1\u7528\u8bc4\u5206\u6a21\u578b\uff0c\u4f46\u5b58\u5728\u6a21\u578b\u6f02\u79fb\u98ce\u9669\u7b49\u5b9e\u9645\u9650\u5236\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6f5c\u529b\u53d8\u9769\u4fe1\u8d37\u5206\u6790\uff0c\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u52a8\u6001\u76d1\u7ba1\u5408\u89c4\u3001\u65b0\u667a\u80fd\u4f53\u534f\u4f5c\u7b49\u65b9\u5411\u3002"}}
{"id": "2601.01097", "pdf": "https://arxiv.org/pdf/2601.01097", "abs": "https://arxiv.org/abs/2601.01097", "authors": ["Xuan Son Nguyen", "Shuo Yang", "Aymeric Histace"], "title": "Neural Networks on Symmetric Spaces of Noncompact Type", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Recent works have demonstrated promising performances of neural networks on hyperbolic spaces and symmetric positive definite (SPD) manifolds. These spaces belong to a family of Riemannian manifolds referred to as symmetric spaces of noncompact type. In this paper, we propose a novel approach for developing neural networks on such spaces. Our approach relies on a unified formulation of the distance from a point to a hyperplane on the considered spaces. We show that some existing formulations of the point-to-hyperplane distance can be recovered by our approach under specific settings. Furthermore, we derive a closed-form expression for the point-to-hyperplane distance in higher-rank symmetric spaces of noncompact type equipped with G-invariant Riemannian metrics. The derived distance then serves as a tool to design fully-connected (FC) layers and an attention mechanism for neural networks on the considered spaces. Our approach is validated on challenging benchmarks for image classification, electroencephalogram (EEG) signal classification, image generation, and natural language inference.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u975e\u7d27\u578b\u5bf9\u79f0\u7a7a\u95f4\u4e0a\u5f00\u53d1\u795e\u7ecf\u7f51\u7edc\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u7f51\u7edc\u5728\u53cc\u66f2\u7a7a\u95f4\u548cSPD\u6d41\u5f62\uff08\u5c5e\u4e8e\u975e\u7d27\u578b\u5bf9\u79f0\u7a7a\u95f4\uff09\u8868\u73b0\u826f\u597d\uff0c\u9700\u65b0\u65b9\u6cd5\u5f00\u53d1\u8be5\u7c7b\u7a7a\u95f4\u7684\u795e\u7ecf\u7f51\u7edc\u3002", "method": "\u57fa\u4e8e\u70b9\u5230\u8d85\u5e73\u9762\u8ddd\u79bb\u7684\u7edf\u4e00\u516c\u5f0f\uff0c\u63a8\u5bfc\u51fa\u9ad8\u9636\u975e\u7d27\u578b\u5bf9\u79f0\u7a7a\u95f4\u7684\u70b9\u5230\u8d85\u5e73\u9762\u8ddd\u79bb\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u4ee5\u6b64\u8bbe\u8ba1\u5168\u8fde\u63a5\u5c42\u548c\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u80fd\u5728\u7279\u5b9a\u8bbe\u7f6e\u4e0b\u6062\u590d\u73b0\u6709\u7684\u70b9\u5230\u8d85\u5e73\u9762\u8ddd\u79bb\u516c\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u8111\u7535\u4fe1\u53f7\u5206\u7c7b\u3001\u56fe\u50cf\u751f\u6210\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6548\u3002"}}
{"id": "2601.01581", "pdf": "https://arxiv.org/pdf/2601.01581", "abs": "https://arxiv.org/abs/2601.01581", "authors": ["Rishav Sen", "Fangqi Liu", "Jose Paolo Talusan", "Ava Pettet", "Yoshinori Suzue", "Mark Bailey", "Ayan Mukhopadhyay", "Abhishek Dubey"], "title": "CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty", "categories": ["cs.MA", "cs.AI", "cs.GT", "eess.SY"], "comment": "Submitted to AAMAS 2026. 25 pages, 13 figures, 14 tables", "summary": "The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.", "AI": {"tldr": "\u9488\u5bf9\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u5728\u8f66\u5230\u5efa\u7b51\uff08V2B\uff09\u573a\u666f\u4e2d\u7684\u5145\u7535\u51b2\u7a81\uff0c\u63d0\u51fa\u57fa\u4e8e\u534f\u5546\u7684\u6846\u67b6\uff0c\u7ecf\u6821\u51c6\u548c\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u80fd\u5b9e\u73b0\u4e92\u5229\u7ed3\u679c\uff0c\u964d\u4f4e\u53cc\u65b9\u6210\u672c\u3002", "motivation": "\u89e3\u51b3V2B\u573a\u666f\u4e2d\u5efa\u7b51\u8fd0\u8425\u5546\u9762\u4e34\u7684\u9ad8\u80fd\u6e90\u6210\u672c\u4e0e\u9a7e\u9a76\u5458\u8ffd\u6c42\u4fbf\u5229\u548c\u6ee1\u7535\u4e4b\u95f4\u7684\u51b2\u7a81\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u534f\u5546\u7684\u6846\u67b6\uff0c\u4e3a\u9a7e\u9a76\u5458\u63d0\u4f9b\u6fc0\u52b1\u9009\u9879\uff0c\u4ee5\u6362\u53d6\u5176\u5728\u51fa\u53d1\u65f6\u95f4\u6216\u8bf7\u6c42\u5145\u7535\u72b6\u6001\u4e0a\u7684\u9002\u5ea6\u7075\u6d3b\u6027\uff0c\u5e76\u7ed3\u5408\u7528\u6237\u8c03\u67e5\u6570\u636e\u6821\u51c6\uff0c\u7528\u5b9e\u9645\u8fd0\u8425\u6570\u636e\u9a8c\u8bc1\u3002", "result": "\u6a21\u62df\u663e\u793a\u8be5\u534f\u5546\u534f\u8bae\u53ef\u4f7f\u5efa\u7b51\u8fd0\u8425\u5546\u6210\u672c\u6bd4\u975e\u534f\u5546\u7684\u4f18\u5316\u667a\u80fd\u5145\u7535\u653f\u7b56\u964d\u4f4e\u8d853.5%\uff0c\u540c\u65f6\u4f7f\u7528\u6237\u5145\u7535\u8d39\u7528\u6bd4\u516c\u7528\u4e8b\u4e1a\u96f6\u552e\u7535\u4ef7\u964d\u4f4e22%\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u534f\u8c03\u8fd0\u8425\u5546\u548cEV\u7528\u6237\u76ee\u6807\uff0c\u5c06EV\u5145\u7535\u4ece\u8fd0\u8425\u6469\u64e6\u6e90\u8f6c\u53d8\u4e3a\u5408\u4f5c\u548c\u5171\u4eab\u8282\u7ea6\u7684\u5e73\u53f0\u3002"}}
{"id": "2601.01550", "pdf": "https://arxiv.org/pdf/2601.01550", "abs": "https://arxiv.org/abs/2601.01550", "authors": ["Shuo Zhou", "Zhaokai Pan", "Weiyuan Gong", "Tongyang Li"], "title": "Time-Dependent Hamiltonian Simulation in the Low-Energy Subspace", "categories": ["quant-ph", "cs.DS"], "comment": "29 pages, 1 figure", "summary": "Hamiltonian simulations are key subroutines in adiabatic quantum computation, quantum control, and quantum many-body physics, where quantum dynamics often happen in the low-energy sector. In contrast to time-independent Hamiltonian simulations, a comprehensive understanding of quantum simulation algorithms for time-dependent Hamiltonians under the low-energy assumption remains limited hitherto. In this paper, we investigate how much we can improve upon the standard performance guarantee assuming the initial state is supported on a low-energy subspace. In particular, we compute the Trotter number of digital quantum simulation based on product formulas for time-dependent spin Hamiltonians under the low-energy assumption that the initial state is supported on a small number of low-energy eigenstates, and show improvements over the standard cost for simulating full unitary simulations. Technically, we derive the low-energy simulation error with commutator scaling for product formulas by leveraging adiabatic perturbation theory to analyze the time-variant energy spectrum of the underlying Hamiltonian. We further discuss the applications to simulations of non-equilibrium quantum many-body dynamics and adiabatic state preparation. Finally, we prove a lower bound of query complexity for generic time-dependent Hamiltonian simulations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f4e\u80fd\u5047\u8bbe\u4e0b\u65f6\u53d8\u54c8\u5bc6\u987f\u91cf\u7684\u91cf\u5b50\u6a21\u62df\u7b97\u6cd5\uff0c\u8ba1\u7b97\u4e86\u6570\u5b57\u91cf\u5b50\u6a21\u62df\u7684Trotter\u6570\uff0c\u5c55\u793a\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u63a8\u5bfc\u4e86\u6a21\u62df\u8bef\u5dee\uff0c\u8ba8\u8bba\u4e86\u5e94\u7528\u5e76\u8bc1\u660e\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\u4e0b\u754c\u3002", "motivation": "\u76ee\u524d\u5bf9\u4f4e\u80fd\u5047\u8bbe\u4e0b\u65f6\u53d8\u54c8\u5bc6\u987f\u91cf\u7684\u91cf\u5b50\u6a21\u62df\u7b97\u6cd5\u7f3a\u4e4f\u5168\u9762\u7406\u89e3\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76\u5728\u521d\u59cb\u72b6\u6001\u5904\u4e8e\u4f4e\u80fd\u5b50\u7a7a\u95f4\u7684\u5047\u8bbe\u4e0b\uff0c\u5982\u4f55\u63d0\u5347\u6807\u51c6\u6027\u80fd\u4fdd\u8bc1\u3002", "method": "\u5229\u7528\u7edd\u70ed\u5fae\u6270\u7406\u8bba\u5206\u6790\u54c8\u5bc6\u987f\u91cf\u7684\u65f6\u53d8\u80fd\u8c31\uff0c\u63a8\u5bfc\u57fa\u4e8e\u4e58\u79ef\u516c\u5f0f\u7684\u4f4e\u80fd\u6a21\u62df\u8bef\u5dee\u3002", "result": "\u8ba1\u7b97\u4e86\u65f6\u53d8\u81ea\u65cb\u54c8\u5bc6\u987f\u91cf\u6570\u5b57\u91cf\u5b50\u6a21\u62df\u7684Trotter\u6570\uff0c\u76f8\u6bd4\u6807\u51c6\u5168\u5e7a\u6b63\u6a21\u62df\u6210\u672c\u6709\u6539\u8fdb\uff1b\u8bc1\u660e\u4e86\u901a\u7528\u65f6\u53d8\u54c8\u5bc6\u987f\u91cf\u6a21\u62df\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u4e0b\u754c\u3002", "conclusion": "\u5728\u4f4e\u80fd\u5047\u8bbe\u4e0b\uff0c\u65f6\u53d8\u54c8\u5bc6\u987f\u91cf\u7684\u91cf\u5b50\u6a21\u62df\u7b97\u6cd5\u6709\u6027\u80fd\u63d0\u5347\uff0c\u53ef\u5e94\u7528\u4e8e\u975e\u5e73\u8861\u91cf\u5b50\u591a\u4f53\u52a8\u529b\u5b66\u6a21\u62df\u548c\u7edd\u70ed\u6001\u5236\u5907\u3002"}}
{"id": "2601.01310", "pdf": "https://arxiv.org/pdf/2601.01310", "abs": "https://arxiv.org/abs/2601.01310", "authors": ["Songyu Zhang", "Aaron Tam", "Myungjin Lee", "Shixiong Qi", "K. K. Ramakrishnan"], "title": "Making MoE based LLM inference resilient with Tarragon", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Mixture-of-Experts (MoE) models are increasingly used to serve LLMs at scale, but failures become common as deployment scale grows. Existing systems exhibit poor failure resilience: even a single worker failure triggers a coarse-grained, service-wide restart, discarding accumulated progress and halting the entire inference pipeline during recovery--an approach clearly ill-suited for latency-sensitive, LLM services.\n  We present Tarragon, a resilient MoE inference framework that confines the failures impact to individual workers while allowing the rest of the pipeline to continue making forward progress. Tarragon exploits the natural separation between the attention and expert computation in MoE-based transformers, treating attention workers (AWs) and expert workers (EWs) as distinct failure domains. Tarragon introduces a reconfigurable datapath to mask failures by rerouting requests to healthy workers. On top of this datapath, Tarragon implements a self-healing mechanism that relaxes the tightly synchronized execution of existing MoE frameworks. For stateful AWs, Tarragon performs asynchronous, incremental KV cache checkpointing with per-request restoration, and for stateless EWs, it leverages residual GPU memory to deploy shadow experts. These together keep recovery cost and recomputation overhead extremely low. Our evaluation shows that, compared to state-of-the-art MegaScale-Infer, Tarragon reduces failure-induced stalls by 160-213x (from ~64 s down to 0.3-0.4 s) while preserving performance when no failures occur.", "AI": {"tldr": "\u63d0\u51fa\u5f39\u6027Mixture-of-Experts\u63a8\u7406\u6846\u67b6Tarragon\uff0c\u964d\u4f4e\u6545\u969c\u6062\u590d\u6210\u672c\u548c\u91cd\u65b0\u8ba1\u7b97\u5f00\u9500\uff0c\u5927\u5e45\u51cf\u5c11\u6545\u969c\u5bfc\u81f4\u7684\u505c\u987f\u3002", "motivation": "\u73b0\u6709MoE\u7cfb\u7edf\u6545\u969c\u6062\u590d\u80fd\u529b\u5dee\uff0c\u5355\u4e00\u5de5\u4f5c\u8282\u70b9\u6545\u969c\u4f1a\u89e6\u53d1\u5168\u670d\u52a1\u8303\u56f4\u91cd\u542f\uff0c\u4e0d\u9002\u5408\u4f4e\u5ef6\u8fdf\u654f\u611f\u7684\u5927\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u3002", "method": "Tarragon\u5c06\u6ce8\u610f\u529b\u5de5\u4f5c\u8282\u70b9\u548c\u4e13\u5bb6\u5de5\u4f5c\u8282\u70b9\u89c6\u4e3a\u4e0d\u540c\u7684\u6545\u969c\u57df\uff0c\u5f15\u5165\u53ef\u91cd\u6784\u6570\u636e\u8def\u5f84\u5c4f\u853d\u6545\u969c\uff0c\u5b9e\u73b0\u81ea\u4fee\u590d\u673a\u5236\uff0c\u5bf9\u6709\u72b6\u6001\u8282\u70b9\u8fdb\u884c\u5f02\u6b65\u589e\u91cf\u7f13\u5b58\u68c0\u67e5\u70b9\u548c\u6309\u8bf7\u6c42\u6062\u590d\uff0c\u5bf9\u65e0\u72b6\u6001\u8282\u70b9\u5229\u7528\u5269\u4f59GPU\u5185\u5b58\u90e8\u7f72\u5f71\u5b50\u4e13\u5bb6\u3002", "result": "\u4e0eMegaScale - Infer\u76f8\u6bd4\uff0cTarragon\u5c06\u6545\u969c\u5bfc\u81f4\u7684\u505c\u987f\u51cf\u5c11160 - 213\u500d\uff08\u4ece\u7ea664\u79d2\u964d\u81f30.3 - 0.4\u79d2\uff09\uff0c\u65e0\u6545\u969c\u65f6\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "Tarragon\u80fd\u6709\u6548\u964d\u4f4e\u6545\u969c\u5bf9\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u63d0\u9ad8MoE\u63a8\u7406\u7cfb\u7edf\u7684\u5f39\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2601.01291", "pdf": "https://arxiv.org/pdf/2601.01291", "abs": "https://arxiv.org/abs/2601.01291", "authors": ["Yicheng Jin", "Yongji Wu", "Wenjun Hu", "Bruce M. Maggs", "Jun Yang", "Xiao Zhang", "Danyang Zhuo"], "title": "Curator: Efficient Vector Search with Low-Selectivity Filters", "categories": ["cs.DB", "cs.IR"], "comment": "Accepted at SIGMOD 2026", "summary": "Embedding-based dense retrieval has become the cornerstone of many critical applications, where approximate nearest neighbor search (ANNS) queries are often combined with filters on labels such as dates and price ranges. Graph-based indexes achieve state-of-the-art performance on unfiltered ANNS but encounter connectivity breakdown on low-selectivity filtered queries, where qualifying vectors become sparse and the graph structure among them fragments. Recent research proposes specialized graph indexes that address this issue by expanding graph degree, which incurs prohibitively high construction costs. Given these inherent limitations of graph-based methods, we argue for a dual-index architecture and present Curator, a partition-based index that complements existing graph-based approaches for low-selectivity filtered ANNS. Curator builds specialized indexes for different labels within a shared clustering tree, where each index adapts to the distribution of its qualifying vectors to ensure efficient search while sharing structure to minimize memory overhead. The system also supports incremental updates and handles arbitrary complex predicates beyond single-label filters by efficiently constructing temporary indexes on the fly. Our evaluation demonstrates that integrating Curator with state-of-the-art graph indexes reduces low-selectivity query latency by up to 20.9x compared to pre-filtering fallback, while increasing construction time and memory footprint by only 5.5% and 4.3%, respectively.", "AI": {"tldr": "\u63d0\u51faCurator\u5206\u533a\u7d22\u5f15\uff0c\u7ed3\u5408\u73b0\u6709\u56fe\u7d22\u5f15\u89e3\u51b3\u4f4e\u9009\u62e9\u6027\u8fc7\u6ee4\u8fd1\u90bb\u641c\u7d22\u95ee\u9898\uff0c\u964d\u4f4e\u67e5\u8be2\u5ef6\u8fdf\u3002", "motivation": "\u56fe\u57fa\u7d22\u5f15\u5728\u4f4e\u9009\u62e9\u6027\u8fc7\u6ee4\u67e5\u8be2\u4e2d\u5b58\u5728\u8fde\u901a\u6027\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u4e13\u95e8\u56fe\u7d22\u5f15\u6784\u5efa\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u53cc\u7d22\u5f15\u67b6\u6784\uff0c\u5728\u5171\u4eab\u805a\u7c7b\u6811\u4e2d\u4e3a\u4e0d\u540c\u6807\u7b7e\u6784\u5efa\u4e13\u95e8\u7d22\u5f15\uff0c\u652f\u6301\u589e\u91cf\u66f4\u65b0\u548c\u5904\u7406\u590d\u6742\u8c13\u8bcd\u3002", "result": "\u4e0e\u73b0\u6709\u56fe\u7d22\u5f15\u96c6\u6210\uff0c\u76f8\u6bd4\u9884\u8fc7\u6ee4\u56de\u9000\uff0c\u4f4e\u9009\u62e9\u6027\u67e5\u8be2\u5ef6\u8fdf\u6700\u591a\u964d\u4f4e20.9\u500d\uff0c\u6784\u5efa\u65f6\u95f4\u548c\u5185\u5b58\u5360\u7528\u5206\u522b\u4ec5\u589e\u52a05.5%\u548c4.3%\u3002", "conclusion": "Curator\u80fd\u6709\u6548\u89e3\u51b3\u4f4e\u9009\u62e9\u6027\u8fc7\u6ee4\u8fd1\u90bb\u641c\u7d22\u95ee\u9898\uff0c\u4e14\u6210\u672c\u589e\u52a0\u8f83\u5c0f\u3002"}}
{"id": "2601.02172", "pdf": "https://arxiv.org/pdf/2601.02172", "abs": "https://arxiv.org/abs/2601.02172", "authors": ["Flavia Gehrig", "Matti Schneider"], "title": "A stable and accurate X-FFT solver for linear elastic homogenization problems in 3D", "categories": ["cs.CE", "math.NA"], "comment": "31 pages, 16 figures", "summary": "Although FFT-based methods are renowned for their numerical efficiency and stability, traditional discretizations fail to capture material interfaces that are not aligned with the grid, resulting in suboptimal accuracy. To address this issue, the work at hand introduces a novel FFT-based solver that achieves interface-conforming accuracy for three-dimensional mechanical problems. More precisely, we integrate the extended finite element (X-FEM) discretization into the FFT-based framework, leveraging its ability to resolve discontinuities via additional shape functions. We employ the modified abs(olute) enrichment and develop a preconditioner based on the concept of strongly stable GFEM, which mitigates the conditioning issues observed in traditional X-FEM implementations. Our computational studies demonstrate that the developed X-FFT solver achieves interface-conforming accuracy, numerical efficiency, and stability when solving three-dimensional linear elastic homogenization problems with smooth material interfaces.", "AI": {"tldr": "\u4f20\u7edfFFT\u65b9\u6cd5\u5904\u7406\u672a\u4e0e\u7f51\u683c\u5bf9\u9f50\u7684\u6750\u6599\u754c\u9762\u65f6\u7cbe\u5ea6\u6b20\u4f73\uff0c\u7814\u7a76\u63d0\u51fa\u65b0\u7684FFT\u6c42\u89e3\u5668\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfFFT\u79bb\u6563\u5316\u65b9\u6cd5\u5728\u5904\u7406\u672a\u4e0e\u7f51\u683c\u5bf9\u9f50\u7684\u6750\u6599\u754c\u9762\u65f6\u7cbe\u5ea6\u4e0d\u7406\u60f3\uff0c\u56e0\u6b64\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u3002", "method": "\u5c06\u6269\u5c55\u6709\u9650\u5143\uff08X - FEM\uff09\u79bb\u6563\u5316\u96c6\u6210\u5230\u57fa\u4e8eFFT\u7684\u6846\u67b6\u4e2d\uff0c\u91c7\u7528\u6539\u8fdb\u7684\u7edd\u5bf9\u5bcc\u96c6\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u5f3a\u7a33\u5b9aGFEM\u6982\u5ff5\u7684\u9884\u5904\u7406\u5668\u3002", "result": "\u5f00\u53d1\u7684X - FFT\u6c42\u89e3\u5668\u5728\u6c42\u89e3\u5177\u6709\u5149\u6ed1\u6750\u6599\u754c\u9762\u7684\u4e09\u7ef4\u7ebf\u6027\u5f39\u6027\u5747\u5300\u5316\u95ee\u9898\u65f6\uff0c\u5b9e\u73b0\u4e86\u754c\u9762\u4e00\u81f4\u7684\u7cbe\u5ea6\u3001\u6570\u503c\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u65b0\u7684X - FFT\u6c42\u89e3\u5668\u80fd\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u6750\u6599\u754c\u9762\u65f6\u7cbe\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2601.00926", "pdf": "https://arxiv.org/pdf/2601.00926", "abs": "https://arxiv.org/abs/2601.00926", "authors": ["Satya Swaroop Gudipudi", "Sahil Girhepuje", "Ponnurangam Kumaraguru", "Kristine Ma"], "title": "MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.", "AI": {"tldr": "\u63d0\u51faMetadata - Aware Cross - Model Alignment (MACA)\u65b9\u6cd5\uff0c\u5c06\u5143\u6570\u636e\u611f\u77e5\u7684LLM\u91cd\u6392\u5668\u63d0\u70bc\u5230\u7d27\u51d1\u5b66\u751f\u68c0\u7d22\u5668\uff0c\u907f\u514d\u5728\u7ebfLLM\u8c03\u7528\uff0c\u5728\u94f6\u884cFAQ\u8bed\u6599\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u4ee3\u4f01\u4e1a\u68c0\u7d22\u7cfb\u7edf\u5904\u7406\u77ed\u4e14\u4e0d\u660e\u786e\u67e5\u8be2\u65f6\uff0c\u9010\u67e5\u8be2\u7684\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u548c\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faMACA\u65b9\u6cd5\uff0c\u7528\u5143\u6570\u636e\u611f\u77e5\u63d0\u793a\u9a8c\u8bc1\u6559\u5e08\u6a21\u578b\u53ef\u4fe1\u5ea6\uff0c\u63d0\u4f9b\u5217\u8868\u5206\u6570\u3001\u786c\u8d1f\u6837\u672c\u548c\u6821\u51c6\u76f8\u5173\u6027\u8fb9\u9645\uff1b\u5b66\u751f\u6a21\u578b\u7528MetaFusion\u76ee\u6807\u8bad\u7ec3\u3002", "result": "MACA\u6559\u5e08\u6a21\u578b\u5728\u4e13\u6709\u96c6\u548cBankFAQs\u4e0a\u7684Accuracy@1\u8d85\u8fc7MAFA\u57fa\u7ebf\uff1bMACA\u5b66\u751f\u6a21\u578b\u5927\u5e45\u8d85\u8d8a\u9884\u8bad\u7ec3\u7f16\u7801\u5668\uff0c\u5982MiniLM\u5728\u4e13\u6709\u8bed\u6599\u4e0aAccuracy@1\u4ece0.23\u63d0\u5347\u52300.48\u3002", "conclusion": "MACA\u65b9\u6cd5\u80fd\u5728\u907f\u514d\u5728\u7ebfLLM\u8c03\u7528\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u5e76\u652f\u6301\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3002"}}
{"id": "2601.01288", "pdf": "https://arxiv.org/pdf/2601.01288", "abs": "https://arxiv.org/abs/2601.01288", "authors": ["Evgenii Rudakov", "Jonathan Shock", "Benjamin Ultan Cowley"], "title": "PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS", "categories": ["cs.GR", "cs.AI", "cs.PF", "cs.RO"], "comment": null, "summary": "Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Python\u5e93PyBatchRender\uff0c\u80fd\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u6279\u91cf3D\u6e32\u67d3\uff0c\u901f\u5ea6\u5feb\u3001\u6613\u4f7f\u7528\u3001\u5f00\u6e90\u53ef\u96c6\u6210\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d3D\u6e32\u67d3\u73af\u5883\u6027\u80fd\u548c\u590d\u6742\u6027\u74f6\u9888\uff0c\u5e73\u8861\u9ad8\u901f\u4f4e\u7ea7\u522b\u5f15\u64ce\u548c\u6162\u901fPython\u6846\u67b6\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8ePanda3D\u6e38\u620f\u5f15\u64ce\uff0c\u91c7\u7528\u4f18\u5316\u7684\u6279\u91cf\u6e32\u67d3\u6280\u672f\u3002", "result": "\u5728\u7b80\u5355\u573a\u666f\u4e2d\u5b9e\u73b0\u8d85100\u4e07FPS\uff0c\u6709\u9ad8\u8fbe1000X\u7684\u52a0\u901f\uff0c\u53ef\u8ba9\u7528\u6237\u7528\u51e0\u5341\u884cPython\u4ee3\u7801\u521b\u5efa\u81ea\u5b9a\u4e49\u573a\u666f\u3002", "conclusion": "PyBatchRender\u80fd\u8ba9\u9ad8\u6027\u80fd3D\u6a21\u62df\u66f4\u666e\u53ca\uff0c\u4f9b\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u4f7f\u7528\u3002"}}
{"id": "2601.00806", "pdf": "https://arxiv.org/pdf/2601.00806", "abs": "https://arxiv.org/abs/2601.00806", "authors": ["\u00c1ngel Miguel Garc\u00eda-Vico", "Huseyin Seker", "Muhammad Afzal"], "title": "Energy-Efficient Eimeria Parasite Detection Using a Two-Stage Spiking Neural Network Architecture", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Coccidiosis, a disease caused by the Eimeria parasite, represents a major threat to the poultry and rabbit industries, demanding rapid and accurate diagnostic tools. While deep learning models offer high precision, their significant energy consumption limits their deployment in resource-constrained environments. This paper introduces a novel two-stage Spiking Neural Network (SNN) architecture, where a pre-trained Convolutional Neural Network is first converted into a spiking feature extractor and then coupled with a lightweight, unsupervised SNN classifier trained with Spike-Timing-Dependent Plasticity (STDP). The proposed model sets a new state-of-the-art, achieving 98.32\\% accuracy in Eimeria classification. Remarkably, this performance is accomplished with a significant reduction in energy consumption, showing an improvement of more than 223 times compared to its traditional ANN counterpart. This work demonstrates a powerful synergy between high accuracy and extreme energy efficiency, paving the way for autonomous, low-power diagnostic systems on neuromorphic hardware.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u4e24\u9636\u6bb5\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7528\u4e8e\u827e\u7f8e\u7403\u866b\u5206\u7c7b\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4e14\u80fd\u8017\u5927\u5e45\u964d\u4f4e\u3002", "motivation": "\u7403\u866b\u75c5\u5bf9\u5bb6\u79bd\u548c\u5154\u5b50\u884c\u4e1a\u6784\u6210\u5a01\u80c1\uff0c\u9700\u8981\u5feb\u901f\u51c6\u786e\u8bca\u65ad\u5de5\u5177\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u80fd\u8017\u9ad8\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u90e8\u7f72\u3002", "method": "\u5f15\u5165\u65b0\u578b\u4e24\u9636\u6bb5\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5148\u5c06\u9884\u8bad\u7ec3\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8f6c\u6362\u4e3a\u8109\u51b2\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u518d\u4e0e\u57fa\u4e8e\u5c16\u5cf0\u65f6\u95f4\u4f9d\u8d56\u53ef\u5851\u6027\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u65e0\u76d1\u7763\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\u7ed3\u5408\u3002", "result": "\u827e\u7f8e\u7403\u866b\u5206\u7c7b\u51c6\u786e\u7387\u8fbe98.32%\uff0c\u80fd\u8017\u76f8\u6bd4\u4f20\u7edf\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u964d\u4f4e\u8d85223\u500d\u3002", "conclusion": "\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u4e0e\u6781\u7aef\u80fd\u6e90\u6548\u7387\u7684\u5f3a\u5927\u534f\u540c\uff0c\u4e3a\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u4e0a\u7684\u81ea\u4e3b\u4f4e\u529f\u8017\u8bca\u65ad\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2601.01142", "pdf": "https://arxiv.org/pdf/2601.01142", "abs": "https://arxiv.org/abs/2601.01142", "authors": ["Sicheng Fu"], "title": "A dynamic factor semiparametric model for VaR and expected shortfall driven by realized measures", "categories": ["econ.GN"], "comment": null, "summary": "This paper proposes a semiparametric joint VaRES framework driven by realized information, mo tivated by the economic mechanisms underlying tail risk generation. Building on the CAViaR quantile recursion, the model introduces a dynamic ESVaR gap to capture time-varying tail sever ity, while measurement equations transform multiple realized measures into high-frequency risk innovations.These innovations are further aggregated through a dynamic factor model, extracting common high-frequency tail risk factors that affect the quantile level and tail thickness through dis tinct risk channels. This structure explicitly separates changes in risk levels from the intensification of tail risk.Empirical evidence shows that the proposed model consistently outperforms quantile regression, EVT-based, and GARCH-type benchmarks across multiple loss functions, highlighting the importance of embedding high-frequency information directly into the tail risk generation layer", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7531\u5df2\u5b9e\u73b0\u4fe1\u606f\u9a71\u52a8\u7684\u534a\u53c2\u6570\u8054\u5408VaRES\u6846\u67b6\uff0c\u4f18\u4e8e\u591a\u4e2a\u57fa\u51c6\u6a21\u578b\u3002", "motivation": "\u53d7\u5c3e\u90e8\u98ce\u9669\u751f\u6210\u7ecf\u6d4e\u673a\u5236\u9a71\u4f7f\uff0c\u63d0\u51fa\u5408\u9002\u6a21\u578b\u5206\u6790\u5c3e\u90e8\u98ce\u9669\u3002", "method": "\u57fa\u4e8eCAViaR\u5206\u4f4d\u6570\u9012\u5f52\uff0c\u5f15\u5165\u52a8\u6001ESVaR\u7f3a\u53e3\uff0c\u5229\u7528\u91cf\u6d4b\u65b9\u7a0b\u5904\u7406\u591a\u4e2a\u5df2\u5b9e\u73b0\u6d4b\u5ea6\u5f97\u9ad8\u9891\u98ce\u9669\u521b\u65b0\uff0c\u518d\u901a\u8fc7\u52a8\u6001\u56e0\u5b50\u6a21\u578b\u805a\u5408\u4ee5\u63d0\u53d6\u5171\u540c\u9ad8\u9891\u5c3e\u90e8\u98ce\u9669\u56e0\u5b50\u3002", "result": "\u8be5\u6a21\u578b\u5728\u591a\u4e2a\u635f\u5931\u51fd\u6570\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5206\u4f4d\u6570\u56de\u5f52\u3001\u57fa\u4e8eEVT\u548cGARCH\u7c7b\u578b\u7684\u57fa\u51c6\u6a21\u578b\u3002", "conclusion": "\u5c06\u9ad8\u9891\u4fe1\u606f\u76f4\u63a5\u5d4c\u5165\u5c3e\u90e8\u98ce\u9669\u751f\u6210\u5c42\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.01215", "pdf": "https://arxiv.org/pdf/2601.01215", "abs": "https://arxiv.org/abs/2601.01215", "authors": ["Prateek Rajput", "Yewei Song", "Abdoul Aziz Bonkoungou", "Iyiola E. Olatunji", "Abdoul Kader Kabore", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Correctness isnt Efficiency: Runtime Memory Divergence in LLM-Generated Code", "categories": ["cs.SE", "cs.AI"], "comment": "11 Pages, 11 figures, Accepted at ICSE SEIP", "summary": "Large language models (LLMs) can generate programs that pass unit tests, but passing tests does not guarantee reliable runtime behavior. We find that different correct solutions to the same task can show very different memory and performance patterns, which can lead to hidden operational risks. We present a framework to measure execution-time memory stability across multiple correct generations. At the solution level, we introduce Dynamic Mean Pairwise Distance (DMPD), which uses Dynamic Time Warping to compare the shapes of memory-usage traces after converting them into Monotonic Peak Profiles (MPPs) to reduce transient noise. Aggregating DMPD across tasks yields a model-level Model Instability Score (MIS). Experiments on BigOBench and CodeContests show substantial runtime divergence among correct solutions. Instability often increases with higher sampling temperature even when pass@1 improves. We also observe correlations between our stability measures and software engineering indicators such as cognitive and cyclomatic complexity, suggesting links between operational behavior and maintainability. Our results support stability-aware selection among passing candidates in CI/CD to reduce operational risk without sacrificing correctness. Artifacts are available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8861\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7a0b\u5e8f\u6267\u884c\u65f6\u5185\u5b58\u7a33\u5b9a\u6027\u7684\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u6b63\u786e\u89e3\u95f4\u6709\u8fd0\u884c\u65f6\u5dee\u5f02\uff0c\u652f\u6301\u5728CI/CD\u4e2d\u57fa\u4e8e\u7a33\u5b9a\u6027\u9009\u62e9\u4ee5\u964d\u4f4e\u98ce\u9669\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7a0b\u5e8f\u901a\u8fc7\u5355\u5143\u6d4b\u8bd5\u4e0d\u4fdd\u8bc1\u53ef\u9760\u8fd0\u884c\u65f6\u884c\u4e3a\uff0c\u4e0d\u540c\u6b63\u786e\u89e3\u6709\u4e0d\u540c\u5185\u5b58\u548c\u6027\u80fd\u6a21\u5f0f\uff0c\u5b58\u5728\u9690\u85cf\u64cd\u4f5c\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u8861\u91cf\u6267\u884c\u65f6\u5185\u5b58\u7a33\u5b9a\u6027\u7684\u6846\u67b6\uff0c\u5728\u89e3\u51b3\u65b9\u6848\u5c42\u9762\u5f15\u5165DMPD\uff0c\u805a\u5408\u5f97\u5230\u6a21\u578b\u5c42\u9762\u7684MIS\u3002", "result": "\u5728BigOBench\u548cCodeContests\u4e0a\u5b9e\u9a8c\u663e\u793a\u6b63\u786e\u89e3\u95f4\u6709\u663e\u8457\u8fd0\u884c\u65f6\u5dee\u5f02\uff0c\u91c7\u6837\u6e29\u5ea6\u5347\u9ad8\u65f6\u4e0d\u7a33\u5b9a\u6027\u5e38\u589e\u52a0\uff0c\u7a33\u5b9a\u6027\u6307\u6807\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u6307\u6807\u6709\u76f8\u5173\u6027\u3002", "conclusion": "\u652f\u6301\u5728CI/CD\u4e2d\u5bf9\u901a\u8fc7\u6d4b\u8bd5\u7684\u5019\u9009\u65b9\u6848\u8fdb\u884c\u7a33\u5b9a\u6027\u611f\u77e5\u9009\u62e9\uff0c\u5728\u4e0d\u727a\u7272\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u64cd\u4f5c\u98ce\u9669\u3002"}}
{"id": "2601.02305", "pdf": "https://arxiv.org/pdf/2601.02305", "abs": "https://arxiv.org/abs/2601.02305", "authors": ["Didong Li", "Aritra Halder", "Sudipto Banerjee"], "title": "On Statistical Inference for Rates of Change in Spatial Processes over Riemannian Manifolds", "categories": ["math.ST", "math.DG", "stat.CO", "stat.ME"], "comment": null, "summary": "Statistical inference for spatial processes from partially realized or scattered data has seen voluminous developments in diverse areas ranging from environmental sciences to business and economics. Inference on the associated rates of change has seen some recent developments. The literature has been restricted to Euclidean domains, where inference is sought on directional derivatives, rates along a chosen direction of interest, at arbitrary locations. Inference for higher order rates, particularly directional curvature has also proved useful in these settings. Modern spatial data often arise from non-Euclidean domains. This manuscript particularly considers spatial processes defined over compact Riemannian manifolds. We develop a comprehensive inferential framework for spatial rates of change for such processes over vector fields. In doing so, we formalize smoothness of process realizations and construct differential processes -- the derivative and curvature processes. We derive conditions for kernels that ensure the existence of these processes and establish validity of the joint multivariate process consisting of the ``parent'' Gaussian process (GP) over the manifold and the associated differential processes. Predictive inference on these rates is devised conditioned on the realized process over the manifold. Manifolds arise as polyhedral meshes in practice. The success of our simulation experiments for assessing derivatives for processes observed over such meshes validate our theoretical findings. By enhancing our understanding of GPs on manifolds, this manuscript unlocks a variety of potential applications in machine learning and statistics where GPs have seen wide usage. We propose a fully model-based approach to inference on the differential processes arising from a spatial process from partially observed or realized data across scattered location on a manifold.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u7d27\u81f4\u9ece\u66fc\u6d41\u5f62\u4e0a\u7a7a\u95f4\u8fc7\u7a0b\u53d8\u5316\u7387\u7684\u7efc\u5408\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\uff0c\u6709\u671b\u5728\u673a\u5668\u5b66\u4e60\u548c\u7edf\u8ba1\u9886\u57df\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u7a7a\u95f4\u8fc7\u7a0b\u7edf\u8ba1\u63a8\u7406\u591a\u5728\u6b27\u51e0\u91cc\u5f97\u57df\uff0c\u73b0\u4ee3\u7a7a\u95f4\u6570\u636e\u5e38\u6765\u81ea\u975e\u6b27\u51e0\u91cc\u5f97\u57df\uff0c\u9700\u5bf9\u7d27\u81f4\u9ece\u66fc\u6d41\u5f62\u4e0a\u7a7a\u95f4\u8fc7\u7a0b\u53d8\u5316\u7387\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u5f62\u5f0f\u5316\u8fc7\u7a0b\u5b9e\u73b0\u7684\u5e73\u6ed1\u6027\uff0c\u6784\u5efa\u5fae\u5206\u8fc7\u7a0b\uff0c\u63a8\u5bfc\u786e\u4fdd\u8fc7\u7a0b\u5b58\u5728\u7684\u6838\u6761\u4ef6\uff0c\u5efa\u7acb\u8054\u5408\u591a\u5143\u8fc7\u7a0b\u6709\u6548\u6027\uff0c\u57fa\u4e8e\u6d41\u5f62\u4e0a\u5df2\u5b9e\u73b0\u8fc7\u7a0b\u8fdb\u884c\u9884\u6d4b\u63a8\u7406\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5bf9\u591a\u9762\u4f53\u7f51\u683c\u4e0a\u8fc7\u7a0b\u5bfc\u6570\u8bc4\u4f30\u7684\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\u5bf9\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u7684\u6d41\u5f62\u4e0a\u7a7a\u95f4\u8fc7\u7a0b\u7684\u5fae\u5206\u8fc7\u7a0b\u8fdb\u884c\u63a8\u7406\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5bf9\u6d41\u5f62\u4e0a\u9ad8\u65af\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u6709\u591a\u79cd\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2601.00821", "pdf": "https://arxiv.org/pdf/2601.00821", "abs": "https://arxiv.org/abs/2601.00821", "authors": ["Tao An"], "title": "CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations", "categories": ["cs.AI", "cs.CL", "cs.IR"], "comment": "15 pages, 5 figures", "summary": "Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.\n  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.\n  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0\u8bad\u7ec3\u6846\u67b6CogCanvas\u5904\u7406\u5927\u8bed\u8a00\u6a21\u578b\u957f\u5bf9\u8bdd\u95ee\u9898\uff0c\u5176\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u53ef\u7acb\u5373\u90e8\u7f72\u7684\u65b9\u6848\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5bf9\u8bdd\u4e2d\u5b58\u5728\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u4fe1\u606f\u4fdd\u771f\u5ea6\u7684\u57fa\u672c\u77db\u76fe\uff0c\u73b0\u6709\u65b9\u6cd5\u4e0d\u80fd\u5f88\u597d\u89e3\u51b3\u4fe1\u606f\u5904\u7406\u95ee\u9898\u3002", "method": "\u5f15\u5165CogCanvas\uff0c\u4ece\u5bf9\u8bdd\u8f6e\u6b21\u4e2d\u63d0\u53d6\u57fa\u4e8e\u9010\u5b57\u7684\u8ba4\u77e5\u5de5\u4ef6\uff0c\u5e76\u5c06\u5176\u7ec4\u7ec7\u6210\u65f6\u95f4\u611f\u77e5\u56fe\u4ee5\u8fdb\u884c\u6297\u538b\u7f29\u68c0\u7d22\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCogCanvas\u7cbe\u5ea6\u9ad8\uff0c\u5728\u65f6\u95f4\u63a8\u7406\u548c\u591a\u8df3\u56e0\u679c\u63a8\u7406\u65b9\u9762\u4f18\u52bf\u660e\u663e\uff0c\u53ec\u56de\u7387\u9ad8\u4e14\u80fd\u4fdd\u7559\u7cbe\u786e\u5339\u914d\u3002", "conclusion": "\u867d\u4f18\u5316\u65b9\u6cd5\u6709\u66f4\u9ad8\u7edd\u5bf9\u5f97\u5206\uff0c\u4f46\u65e0\u8bad\u7ec3\u7684CogCanvas\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u8fdc\u8d85\u6807\u51c6\u57fa\u7ebf\u3001\u53ef\u7acb\u5373\u90e8\u7f72\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2601.01147", "pdf": "https://arxiv.org/pdf/2601.01147", "abs": "https://arxiv.org/abs/2601.01147", "authors": ["Johan Hallberg Szabadv\u00e1ry"], "title": "Conformal Blindness: A Note on $A$-Cryptic change-points", "categories": ["stat.ML", "cs.LG"], "comment": "6 pages, 3 figures", "summary": "Conformal Test Martingales (CTMs) are a standard method within the Conformal Prediction framework for testing the crucial assumption of data exchangeability by monitoring deviations from uniformity in the p-value sequence. Although exchangeability implies uniform p-values, the converse does not hold. This raises the question of whether a significant break in exchangeability can occur, such that the p-values remain uniform, rendering CTMs blind. We answer this affirmatively, demonstrating the phenomenon of \\emph{conformal blindness}.\n  Through explicit construction, for the theoretically ideal ``oracle'' conformity measure (given by the true conditional density), we demonstrate the possibility of an \\emph{$A$-cryptic change-point} (where $A$ refers to the conformity measure). Using bivariate Gaussian distributions, we identify a line along which a change in the marginal means does not alter the distribution of the conformity scores, thereby producing perfectly uniform p-values.\n  Simulations confirm that even a massive distribution shift can be perfectly cryptic to the CTM, highlighting a fundamental limitation and emphasising the critical role of the alignment of the conformity measure with potential shifts.", "AI": {"tldr": "\u672c\u6587\u6307\u51faConformal Test Martingales (CTMs)\u53ef\u80fd\u5b58\u5728\u2018\u5171\u5f62\u76f2\u76ee\u6027\u2019\u73b0\u8c61\uff0c\u5373\u6570\u636e\u53ef\u4ea4\u6362\u6027\u65ad\u88c2\u4f46p\u503c\u5747\u5300\uff0cCTM\u65e0\u6cd5\u68c0\u6d4b\uff1b\u5e76\u901a\u8fc7\u6784\u9020\u8bc1\u660e\u548c\u6a21\u62df\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u70b9\u3002", "motivation": "\u63a2\u8ba8CTMs\u6d4b\u8bd5\u6570\u636e\u53ef\u4ea4\u6362\u6027\u5047\u8bbe\u65f6\uff0c\u662f\u5426\u5b58\u5728\u6570\u636e\u53ef\u4ea4\u6362\u6027\u663e\u8457\u65ad\u88c2\u4f46p\u503c\u4fdd\u6301\u5747\u5300\uff0c\u5bfc\u81f4CTMs\u5931\u6548\u7684\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u5bf9\u7406\u8bba\u4e0a\u7406\u60f3\u7684\u2018\u795e\u8c15\u2019\u4e00\u81f4\u6027\u5ea6\u91cf\u8fdb\u884c\u663e\u5f0f\u6784\u9020\uff1b\u4f7f\u7528\u4e8c\u5143\u9ad8\u65af\u5206\u5e03\u8fdb\u884c\u5206\u6790\uff1b\u8fdb\u884c\u6a21\u62df\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660e\u4e86\u5b58\u5728A - \u9690\u5f0f\u53d8\u5316\u70b9\uff0c\u53d1\u73b0\u4e8c\u5143\u9ad8\u65af\u5206\u5e03\u4e2d\u8fb9\u9645\u5747\u503c\u53d8\u5316\u4e0d\u6539\u53d8\u4e00\u81f4\u6027\u5f97\u5206\u5206\u5e03\u53ef\u4ea7\u751f\u5747\u5300p\u503c\uff1b\u6a21\u62df\u8868\u660e\u5de8\u5927\u5206\u5e03\u504f\u79fb\u5bf9CTM\u5b8c\u5168\u9690\u85cf\u3002", "conclusion": "\u6307\u51faCTM\u5b58\u5728\u57fa\u672c\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e00\u81f4\u6027\u5ea6\u91cf\u4e0e\u6f5c\u5728\u5206\u5e03\u504f\u79fb\u7684\u5339\u914d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.02347", "pdf": "https://arxiv.org/pdf/2601.02347", "abs": "https://arxiv.org/abs/2601.02347", "authors": ["Ishani Karmarkar", "Liam O'Carroll", "Aaron Sidford"], "title": "Solving Matrix Games with Even Fewer Matrix-Vector Products", "categories": ["math.OC", "cs.DS", "cs.GT"], "comment": null, "summary": "We study the problem of computing an $\u03b5$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \\in \\mathbb{R}^{m \\times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\\tilde{O}(\u03b5^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\\ell_1$-$\\ell_1$ games, where the players' strategies are both in the probability simplex, and $\\ell_2$-$\\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\\tilde{O}(\u03b5^{-8/9})$ for $\\ell_1$-$\\ell_1$ and of $\\tilde{O}(\u03b5^{-7/9})$ for $\\ell_2$-$\\ell_1$ due to [KOS '25]. In particular, our result for $\\ell_2$-$\\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2601.02193", "pdf": "https://arxiv.org/pdf/2601.02193", "abs": "https://arxiv.org/abs/2601.02193", "authors": ["Kasper Green Larsen", "Chirag Pabbaraju", "Abhishek Shetty"], "title": "Learning with Monotone Adversarial Corruptions", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a \"clean\" i.i.d. dataset, inserts additional \"corrupted\" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.", "AI": {"tldr": "\u901a\u8fc7\u5355\u8c03\u5bf9\u6297\u6027\u635f\u574f\u6a21\u578b\u7814\u7a76\u6807\u51c6\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5bf9\u6570\u636e\u53ef\u4ea4\u6362\u6027\u548c\u72ec\u7acb\u6027\u7684\u4f9d\u8d56\u7a0b\u5ea6\uff0c\u53d1\u73b0\u6700\u4f18\u5b66\u4e60\u7b97\u6cd5\u5728\u5355\u8c03\u635f\u574f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u57fa\u4e8e\u4e00\u81f4\u6536\u655b\u7684\u7b97\u6cd5\u4e0d\u53d7\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u6807\u51c6\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5bf9\u6570\u636e\u53ef\u4ea4\u6362\u6027\u548c\u72ec\u7acb\u6027\u7684\u4f9d\u8d56\u7a0b\u5ea6\u3002", "method": "\u5f15\u5165\u5355\u8c03\u5bf9\u6297\u6027\u635f\u574f\u6a21\u578b\uff0c\u5728\u5e72\u51c0\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u96c6\u63d2\u5165\u7b26\u5408\u4e00\u5b9a\u89c4\u5219\u7684\u635f\u574f\u70b9\u3002", "result": "\u5df2\u77e5\u7684\u4e8c\u5143\u5206\u7c7b\u6700\u4f18\u5b66\u4e60\u7b97\u6cd5\u5728\u65b0\u6d4b\u8bd5\u70b9\u4e0a\u9884\u671f\u8bef\u5dee\u4e0d\u7406\u60f3\uff0c\u57fa\u4e8e\u4e00\u81f4\u6536\u655b\u7684\u7b97\u6cd5\u4fdd\u8bc1\u4e0d\u53d7\u5f71\u54cd\u3002", "conclusion": "\u6700\u4f18\u5b66\u4e60\u7b97\u6cd5\u5728\u770b\u4f3c\u6709\u7528\u7684\u5355\u8c03\u635f\u574f\u4e0b\u4f1a\u5931\u6548\uff0c\u66b4\u9732\u5176\u5bf9\u53ef\u4ea4\u6362\u6027\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002"}}
{"id": "2601.01500", "pdf": "https://arxiv.org/pdf/2601.01500", "abs": "https://arxiv.org/abs/2601.01500", "authors": ["Jinxiao Zhang", "Yunpu Xu", "Xiyong Wu", "Runmin Dong", "Shenggan Cheng", "Yi Zhao", "Mengxuan Chen", "Qinrui Zheng", "Jianting Liu", "Haohuan Fu"], "title": "DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster", "categories": ["cs.DC"], "comment": null, "summary": "Generative foundation models have become an important tool for data reconstruction and simulation in scientific computing, showing a tight integration with traditional numerical simulations. At the same time, with the development of new hardware features, such as matrix acceleration units and high-bandwidth memory, CPU-based clusters offer promising opportunities to accelerate and scale such models, facilitating the unification of artificial intelligence and scientific computing. We present DiT-HC, the first system to train and scale the generative model DiT on a next-generation HPC CPU cluster. DiT-HC introduces three key techniques: (1) communication-free tensor parallelism (CFTP) with AutoMem for automated memory-aware dataflow, (2) HCOps, a suite of optimized GEMM and operator kernels leveraging vector and matrix acceleration units, and (3) a custom MPI backend that overlaps computation, communication, and memory movement. Experiments show 8.2 to 87.7 times speedups over native or public CPU libraries and 90.6% weak scaling efficiency on 256 nodes. These results demonstrate the feasibility of large-scale generative model training on CPU clusters and provide new insights for future HPC-AI co-design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDiT - HC\u7cfb\u7edf\u5728\u4e0b\u4e00\u4ee3HPC CPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\u548c\u6269\u5c55\u751f\u6210\u6a21\u578bDiT\uff0c\u4ecb\u7ecd\u4e09\u79cd\u5173\u952e\u6280\u672f\uff0c\u5b9e\u9a8c\u5c55\u793a\u4e86\u52a0\u901f\u6548\u679c\u548c\u5f31\u6269\u5c55\u6548\u7387\uff0c\u8bc1\u660e\u5728CPU\u96c6\u7fa4\u4e0a\u5927\u89c4\u6a21\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u751f\u6210\u57fa\u7840\u6a21\u578b\u4e0e\u4f20\u7edf\u6570\u503c\u6a21\u62df\u7d27\u5bc6\u7ed3\u5408\uff0c\u65b0\u786c\u4ef6\u7279\u6027\u4f7fCPU\u96c6\u7fa4\u6709\u673a\u4f1a\u52a0\u901f\u548c\u6269\u5c55\u6b64\u7c7b\u6a21\u578b\uff0c\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u4e0e\u79d1\u5b66\u8ba1\u7b97\u7edf\u4e00\u3002", "method": "\u63d0\u51faDiT - HC\u7cfb\u7edf\uff0c\u5f15\u5165\u901a\u4fe1\u65e0\u5f20\u91cf\u5e76\u884c\uff08CFTP\uff09\u4e0e\u81ea\u52a8\u5185\u5b58\u611f\u77e5\u6570\u636e\u6d41\u3001\u4f18\u5316GEMM\u548c\u7b97\u5b50\u5185\u6838\u7684HCOps\u3001\u81ea\u5b9a\u4e49MPI\u540e\u7aef\u91cd\u53e0\u8ba1\u7b97\u3001\u901a\u4fe1\u548c\u5185\u5b58\u79fb\u52a8\u4e09\u79cd\u5173\u952e\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6bd4\u539f\u751f\u6216\u516c\u5171CPU\u5e93\u67098.2\u523087.7\u500d\u52a0\u901f\uff0c\u5728256\u4e2a\u8282\u70b9\u4e0a\u670990.6%\u7684\u5f31\u6269\u5c55\u6548\u7387\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728CPU\u96c6\u7fa4\u4e0a\u5927\u89c4\u6a21\u8bad\u7ec3\u751f\u6210\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765HPC - AI\u534f\u540c\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002"}}
{"id": "2601.01415", "pdf": "https://arxiv.org/pdf/2601.01415", "abs": "https://arxiv.org/abs/2601.01415", "authors": ["Wei Huang", "Xieyang Wang", "Jianqiu Xu", "Guidong Zhang"], "title": "A Tool for Semantic-Aware Spatial Corpus Construction", "categories": ["cs.DB"], "comment": null, "summary": "Spatial natural language interface to database systems provide non-expert users with convenient access to spatial data through natural language queries. However, the scarcity of high-quality spatial natural language query corpora limits the performance of such systems. Existing methods rely on manual knowledge base construction and template-based dynamic generation, which suffer from low construction efficiency and unstable corpus quality. This paper presents semantic-aware spatial corpus construction (SSCC), a tool designed for constructing high-quality spatial natural language query and executable language query pair corpora. SSCC consists of two core modules: (i) a knowledge base construction module based on spatial relations, which extracts and determines spatial relations from datasets, and (ii) a template-augmented query pair corpus generation module, which produces query pairs via template matching and parameter substitution. The tool ensures geometric consistency and adherence to spatial logic in the generated spatial relations. Experimental results demonstrate that SSCC achieves (i) a 53x efficiency improvement for knowledge base construction and (ii) a 2.5x effectiveness improvement for query pair corpus. SSCC provides high-quality corpus support for spatial natural language interface training, substantially reducing both time and labor costs in corpus construction.", "AI": {"tldr": "\u73b0\u6709\u7a7a\u95f4\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8bed\u6599\u5e93\u7a00\u7f3a\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\uff0c\u672c\u6587\u63d0\u51fa\u8bed\u4e49\u611f\u77e5\u7a7a\u95f4\u8bed\u6599\u5e93\u6784\u5efa\u5de5\u5177SSCC\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u63d0\u5347\u77e5\u8bc6\u5e93\u6784\u5efa\u6548\u7387\u548c\u67e5\u8be2\u5bf9\u8bed\u6599\u5e93\u6709\u6548\u6027\uff0c\u4e3a\u8bad\u7ec3\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8bed\u6599\u652f\u6301\u3002", "motivation": "\u7a7a\u95f4\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7cfb\u7edf\u56e0\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7a7a\u95f4\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8bed\u6599\u5e93\uff0c\u73b0\u6709\u6784\u5efa\u65b9\u6cd5\u6548\u7387\u4f4e\u3001\u8bed\u6599\u8d28\u91cf\u4e0d\u7a33\u5b9a\uff0c\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u63d0\u51faSSCC\u5de5\u5177\uff0c\u5305\u62ec\u57fa\u4e8e\u7a7a\u95f4\u5173\u7cfb\u7684\u77e5\u8bc6\u5e93\u6784\u5efa\u6a21\u5757\u548c\u6a21\u677f\u589e\u5f3a\u7684\u67e5\u8be2\u5bf9\u8bed\u6599\u5e93\u751f\u6210\u6a21\u5757\u3002", "result": "SSCC\u4f7f\u77e5\u8bc6\u5e93\u6784\u5efa\u6548\u7387\u63d0\u534753\u500d\uff0c\u67e5\u8be2\u5bf9\u8bed\u6599\u5e93\u6709\u6548\u6027\u63d0\u53472.5\u500d\u3002", "conclusion": "SSCC\u4e3a\u7a7a\u95f4\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u8bad\u7ec3\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8bed\u6599\u5e93\uff0c\u5927\u5e45\u964d\u4f4e\u8bed\u6599\u5e93\u6784\u5efa\u7684\u65f6\u95f4\u548c\u4eba\u529b\u6210\u672c\u3002"}}
{"id": "2601.02349", "pdf": "https://arxiv.org/pdf/2601.02349", "abs": "https://arxiv.org/abs/2601.02349", "authors": ["Meznah Aloqalaa", "Stian Soiland-Reyes", "Carole Goble"], "title": "PRIMAD-LID: A Developed Framework for Computational Reproducibility", "categories": ["cs.CE"], "comment": null, "summary": "Over the past decade alongside increased focus on computational reproducibility significant efforts have been made to define reproducibility. However, these definitions provide a textual description rather than a framework. The community has sought conceptual frameworks that identify all factors that must be controlled and described for credible computational reproducibility. The PRIMAD model was initially introduced to address inconsistencies in terminology surrounding computational reproducibility by outlining six key factors: P (Platforms), R (Research objective), I (Implementations), M (Methods), A (Actors), and D (Data). Subsequently various studies across different fields adopted the model and proposed extensions. However, these contributions remain fragmented and require systematic integration and cross-disciplinary validation. To bridge this gap and recognising that PRIMAD provides a broadly applicable framework for reproducibility in computational science, this work undertakes a focused investigation of the PRIMAD model. It combines the models previous extensions into a unified framework suitable for diverse research contexts. The result is PRIMAD-LID, a discipline-diagnostic reproducibility framework that retains the original six PRIMAD dimensions and enhances each with three overarching modifiers: Lifespan (temporal qualifier), Interpretation (contextual reasoning) and Depth (necessary granularity), thereby establishing a more cohesive and robust foundation for computational reproducibility practices.", "AI": {"tldr": "\u672c\u6587\u805a\u7126PRIMAD\u6a21\u578b\uff0c\u6574\u5408\u5176\u6269\u5c55\u5f62\u6210PRIMAD - LID\u6846\u67b6\uff0c\u4e3a\u8ba1\u7b97\u53ef\u91cd\u590d\u6027\u5b9e\u8df5\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u53ef\u91cd\u590d\u6027\u5b9a\u4e49\u591a\u4e3a\u6587\u672c\u63cf\u8ff0\uff0c\u7f3a\u4e4f\u6846\u67b6\uff0cPRIMAD\u6a21\u578b\u6269\u5c55\u8f83\u5206\u6563\uff0c\u9700\u7cfb\u7edf\u6574\u5408\u548c\u8de8\u5b66\u79d1\u9a8c\u8bc1\u3002", "method": "\u5bf9PRIMAD\u6a21\u578b\u8fdb\u884c\u96c6\u4e2d\u7814\u7a76\uff0c\u6574\u5408\u5176\u5148\u524d\u6269\u5c55\u4e3a\u7edf\u4e00\u6846\u67b6\u3002", "result": "\u5f97\u5230PRIMAD - LID\u5b66\u79d1\u8bca\u65ad\u53ef\u91cd\u590d\u6027\u6846\u67b6\uff0c\u4fdd\u7559\u539f\u516d\u4e2a\u7ef4\u5ea6\u5e76\u589e\u52a0\u4e09\u4e2a\u603b\u4f53\u4fee\u9970\u7b26\u3002", "conclusion": "PRIMAD - LID\u6846\u67b6\u4e3a\u8ba1\u7b97\u53ef\u91cd\u590d\u6027\u5b9e\u8df5\u5efa\u7acb\u4e86\u66f4\u6709\u51dd\u805a\u529b\u548c\u7a33\u5065\u7684\u57fa\u7840\u3002"}}
{"id": "2601.00930", "pdf": "https://arxiv.org/pdf/2601.00930", "abs": "https://arxiv.org/abs/2601.00930", "authors": ["Nicolas Bougie", "Gian Maria Marconi", "Tony Yip", "Narimasa Watanabe"], "title": "AlignUSER: Human-Aligned LLM Agents via World Models for Recommender System Evaluation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Evaluating recommender systems remains challenging due to the gap between offline metrics and real user behavior, as well as the scarcity of interaction data. Recent work explores large language model (LLM) agents as synthetic users, yet they typically rely on few-shot prompting, which yields a shallow understanding of the environment and limits their ability to faithfully reproduce user actions. We introduce AlignUSER, a framework that learns world-model-driven agents from human interactions. Given rollout sequences of actions and states, we formalize world modeling as a next state prediction task that helps the agent internalize the environment. To align actions with human personas, we generate counterfactual trajectories around demonstrations and prompt the LLM to compare its decisions with human choices, identify suboptimal actions, and extract lessons. The learned policy is then used to drive agent interactions with the recommender system. We evaluate AlignUSER across multiple datasets and demonstrate closer alignment with genuine humans than prior work, both at the micro and macro levels.", "AI": {"tldr": "\u63d0\u51faAlignUSER\u6846\u67b6\u5b66\u4e60\u4e16\u754c\u6a21\u578b\u9a71\u52a8\u7684\u4ee3\u7406\u6765\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\uff0c\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u63a5\u8fd1\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u4ee3\u7406\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u4f9d\u8d56\u5c11\u6837\u672c\u63d0\u793a\uff0c\u5bf9\u73af\u5883\u7406\u89e3\u6d45\uff0c\u96be\u4ee5\u5fe0\u5b9e\u590d\u73b0\u7528\u6237\u884c\u4e3a\uff0c\u4e14\u79bb\u7ebf\u6307\u6807\u4e0e\u7528\u6237\u884c\u4e3a\u6709\u5dee\u8ddd\u3001\u4ea4\u4e92\u6570\u636e\u7a00\u7f3a\u3002", "method": "\u5c06\u4e16\u754c\u5efa\u6a21\u4e3a\u4e0b\u4e00\u4e2a\u72b6\u6001\u9884\u6d4b\u4efb\u52a1\u5e2e\u52a9\u4ee3\u7406\u5185\u5316\u73af\u5883\uff0c\u56f4\u7ed5\u6f14\u793a\u751f\u6210\u53cd\u4e8b\u5b9e\u8f68\u8ff9\uff0c\u8ba9LLM\u5bf9\u6bd4\u51b3\u7b56\u4e0e\u4eba\u7c7b\u9009\u62e9\u3001\u8bc6\u522b\u6b21\u4f18\u52a8\u4f5c\u5e76\u63d0\u53d6\u6559\u8bad\uff0c\u7528\u5b66\u4e60\u7684\u7b56\u7565\u9a71\u52a8\u4ee3\u7406\u4e0e\u63a8\u8350\u7cfb\u7edf\u4ea4\u4e92\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5728\u5fae\u89c2\u548c\u5b8f\u89c2\u5c42\u9762\u90fd\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u63a5\u8fd1\u771f\u5b9e\u4eba\u7c7b\u3002", "conclusion": "AlignUSER\u6846\u67b6\u5728\u8bc4\u4f30\u63a8\u8350\u7cfb\u7edf\u65b9\u9762\u6bd4\u73b0\u6709\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u65b9\u6cd5\u66f4\u4f18\uff0c\u80fd\u66f4\u597d\u5730\u6a21\u62df\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u3002"}}
{"id": "2601.01353", "pdf": "https://arxiv.org/pdf/2601.01353", "abs": "https://arxiv.org/abs/2601.01353", "authors": ["Shahrooz Pouryousef", "Eneet Kaur", "Hassan Shapourian", "Don Towsley", "Ramana Kompella", "Reza Nejabati"], "title": "Benchmarking Quantum Data Center Architectures: A Performance and Scalability Perspective", "categories": ["quant-ph", "cs.DC", "cs.NI", "cs.PF"], "comment": null, "summary": "Scalable distributed quantum computing (DQC) has motivated the design of multiple quantum data-center (QDC) architectures that overcome the limitations of single quantum processors through modular interconnection. While these architectures adopt fundamentally different design philosophies, their relative performance under realistic quantum hardware constraints remains poorly understood.\n  In this paper, we present a systematic benchmarking study of four representative QDC architectures-QFly, BCube, Clos, and Fat-Tree-quantifying their impact on distributed quantum circuit execution latency, resource contention, and scalability. Focusing on quantum-specific effects absent from classical data-center evaluations, we analyze how optical-loss-induced Einstein-Podolsky-Rosen (EPR) pair generation delays, coherence-limited entanglement retry windows, and contention from teleportation-based non-local gates shape end-to-end execution performance. Across diverse circuit workloads, we evaluate how architectural properties such as path diversity and path length, and shared BSM (Bell State Measurement) resources interact with optical-switch insertion loss and reconfiguration delay. Our results show that distributed quantum performance is jointly shaped by topology, scheduling policies, and physical-layer parameters, and that these factors interact in nontrivial ways. Together, these insights provide quantitative guidance for the design of scalable and high-performance quantum data-center architectures for DQC.", "AI": {"tldr": "\u672c\u6587\u5bf9\u56db\u79cd\u91cf\u5b50\u6570\u636e\u4e2d\u5fc3\u67b6\u6784\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u4e0d\u540c\u67b6\u6784\u5728\u5206\u5e03\u5f0f\u91cf\u5b50\u7535\u8def\u6267\u884c\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u8bbe\u8ba1\u9ad8\u6027\u80fd\u91cf\u5b50\u6570\u636e\u4e2d\u5fc3\u67b6\u6784\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u591a\u4e2a\u91cf\u5b50\u6570\u636e\u4e2d\u5fc3\uff08QDC\uff09\u67b6\u6784\u867d\u80fd\u514b\u670d\u5355\u91cf\u5b50\u5904\u7406\u5668\u7684\u5c40\u9650\uff0c\u4f46\u5728\u5b9e\u9645\u91cf\u5b50\u786c\u4ef6\u7ea6\u675f\u4e0b\u7684\u76f8\u5bf9\u6027\u80fd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5bf9QFly\u3001BCube\u3001Clos\u548cFat - Tree\u56db\u79cd\u4ee3\u8868QDC\u67b6\u6784\u8fdb\u884c\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u91cf\u5b50\u7279\u5b9a\u6548\u5e94\u3001\u67b6\u6784\u5c5e\u6027\u4ee5\u53ca\u7269\u7406\u5c42\u53c2\u6570\u5bf9\u6267\u884c\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5206\u5e03\u5f0f\u91cf\u5b50\u6027\u80fd\u7531\u62d3\u6251\u3001\u8c03\u5ea6\u7b56\u7565\u548c\u7269\u7406\u5c42\u53c2\u6570\u5171\u540c\u51b3\u5b9a\uff0c\u4e14\u8fd9\u4e9b\u56e0\u7d20\u4e4b\u95f4\u76f8\u4e92\u4f5c\u7528\u590d\u6742\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u53ef\u6269\u5c55\u548c\u9ad8\u6027\u80fd\u7684\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97QDC\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9a\u91cf\u6307\u5bfc\u3002"}}
{"id": "2601.00826", "pdf": "https://arxiv.org/pdf/2601.00826", "abs": "https://arxiv.org/abs/2601.00826", "authors": ["Luis M. Moreno-Saavedra", "Vin\u0131cius G. Costa", "Adrian Garrido-Saez", "Silvia Jimenez-Fernandez", "Antonio Portilla-Figueras", "Sancho Salcedo-Sanz"], "title": "Evolutionary optimization of spatially-distributed multi-sensors placement for indoor surveillance environments with security levels", "categories": ["cs.NE"], "comment": null, "summary": "The surveillance multisensor placement is an important optimization problem that consists of positioning several sensors of different types to maximize the coverage of a determined area while minimizing the cost of the deployment. In this work, we tackle a modified version of the problem, consisting of spatially distributed multisensor placement for indoor surveillance. Our approach is focused on security surveillance of sensible indoor spaces, such as military installations, where distinct security levels can be considered. We propose an evolutionary algorithm to solve the problem, in which a novel special encoding,integer encoding with binary conversion, and effective initialization have been defined to improve the performance and convergence of the proposed algorithm. We also consider the probability of detection for each surveillance point, which depends on the distance to the sensor at hand, to better model real-life scenarios. We have tested the proposed evolutionary approach in different instances of the problem, varying both size and difficulty, and obtained excellent results in terms of the cost of sensors placement and convergence time of the algorithm.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5ba4\u5185\u5b89\u5168\u76d1\u63a7\u7684\u591a\u4f20\u611f\u5668\u7a7a\u95f4\u5206\u5e03\u653e\u7f6e\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u7528\u8fdb\u5316\u7b97\u6cd5\u89e3\u51b3\uff0c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u5ba4\u5185\u76d1\u63a7\u4e2d\u591a\u4f20\u611f\u5668\u7a7a\u95f4\u5206\u5e03\u653e\u7f6e\u95ee\u9898\uff0c\u63d0\u5347\u654f\u611f\u5ba4\u5185\u7a7a\u95f4\u76d1\u63a7\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u8fdb\u5316\u7b97\u6cd5\uff0c\u5b9a\u4e49\u4e86\u6574\u6570\u7f16\u7801\u52a0\u4e8c\u8fdb\u5236\u8f6c\u6362\u7684\u65b0\u578b\u7f16\u7801\u548c\u6709\u6548\u521d\u59cb\u5316\uff0c\u8003\u8651\u76d1\u63a7\u70b9\u68c0\u6d4b\u6982\u7387\u3002", "result": "\u5728\u4e0d\u540c\u89c4\u6a21\u548c\u96be\u5ea6\u7684\u95ee\u9898\u5b9e\u4f8b\u4e0a\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u5728\u4f20\u611f\u5668\u653e\u7f6e\u6210\u672c\u548c\u6536\u655b\u65f6\u95f4\u65b9\u9762\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u8fdb\u5316\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5ba4\u5185\u591a\u4f20\u611f\u5668\u7a7a\u95f4\u5206\u5e03\u653e\u7f6e\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2601.01370", "pdf": "https://arxiv.org/pdf/2601.01370", "abs": "https://arxiv.org/abs/2601.01370", "authors": ["Zafer Kanik", "Zaruhi Hakobyan"], "title": "Strategic Expression, Popularity Traps, and Welfare in Social Media", "categories": ["econ.GN", "cs.SI"], "comment": null, "summary": "Social media platforms systematically reward popularity but not authenticity, incentivizing users to strategically tailor their expression for attention. We develop a utilitarian framework addressing strategic expression in social media. Agents hold fixed heterogeneous authentic opinions and derive (i) utility gains from the popularity of their own posts--measured by likes received--, and (ii) utility gains (losses) from exposure to content that aligns with (diverges from) their authentic opinion. Social media interaction acts as a state-dependent welfare amplifier: light topics generate Pareto improvements, whereas intense topics make everyone worse off in a polarized society (e.g., political debates during elections). Moreover, strategic expression amplifies social media polarization during polarized events while dampening it during unified events (e.g., national celebrations). Consequently, strategic distortions magnify welfare outcomes, expanding aggregate gains in light topics while exacerbating losses in intense, polarized ones. Counterintuitively, strategic agents often face a popularity trap: posting a more popular opinion is individually optimal, yet collective action by similar agents eliminates their authentic opinion from the platform, leaving them worse off than under the authentic-expression benchmark. Preference-based algorithms--widely used by platforms--or homophilic exposures discipline popularity-driven behavior, narrowing the popularity trap region and limiting its welfare effects. Our framework fills a critical gap in the social media literature by providing a microfoundation for user welfare that maps to observable metrics, while also introducing popularity incentives as an unexplored channel in social networks distinct from the canonical mechanisms of conformity, learning, persuasion, and (mis)information transmission.", "AI": {"tldr": "\u63d0\u51fa\u793e\u4ea4\u5a92\u9ad4\u6230\u7565\u8868\u9054\u7684\u529f\u5229\u4e3b\u7fa9\u6846\u67b6\uff0c\u5206\u6790\u4e0d\u540c\u8a71\u984c\u4e0b\u7684\u798f\u5229\u7d50\u679c\u548c\u6975\u5316\u73fe\u8c61\uff0c\u6307\u51fa\u6230\u7565\u8868\u9054\u7684\u9677\u9631\u53ca\u7de9\u89e3\u65b9\u6cd5\u3002", "motivation": "\u89e3\u6c7a\u793e\u4ea4\u5a92\u9ad4\u5e73\u81fa\u9f13\u52f5\u4eba\u6c23\u800c\u975e\u771f\u5be6\u6027\uff0c\u7528\u6236\u6230\u7565\u6027\u8868\u9054\u7684\u554f\u984c\u3002", "method": "\u69cb\u5efa\u529f\u5229\u4e3b\u7fa9\u6846\u67b6\uff0c\u8003\u616e\u7528\u6236\u5e16\u5b50\u4eba\u6c23\u548c\u5167\u5bb9\u8207\u771f\u5be6\u89c0\u9ede\u7684\u5951\u5408\u5ea6\u3002", "result": "\u6dfa\u986f\u8a71\u984c\u5e36\u4f86\u5e15\u7d2f\u6258\u6539\u9032\uff0c\u6fc0\u70c8\u8a71\u984c\u4f7f\u6240\u6709\u4eba\u798f\u5229\u4e0b\u964d\uff1b\u6230\u7565\u8868\u9054\u5728\u4e0d\u540c\u4e8b\u4ef6\u4e2d\u5f71\u97ff\u6975\u5316\uff1b\u5b58\u5728\u4eba\u6c23\u9677\u9631\uff1b\u504f\u597d\u7b97\u6cd5\u548c\u540c\u8cea\u66b4\u9732\u53ef\u7de9\u89e3\u3002", "conclusion": "\u8a72\u6846\u67b6\u586b\u88dc\u793e\u4ea4\u5a92\u9ad4\u6587\u737b\u7a7a\u767d\uff0c\u5f15\u5165\u4eba\u6c23\u6fc0\u52f5\u65b0\u6e20\u9053\u3002"}}
{"id": "2601.01219", "pdf": "https://arxiv.org/pdf/2601.01219", "abs": "https://arxiv.org/abs/2601.01219", "authors": ["Hossein Amiri", "Joon-Seok Kim", "Hamdi Kavak", "Andrew Crooks", "Dieter Pfoser", "Carola Wenk", "Andreas Z\u00fcfle"], "title": "HD-GEN: A High-Performance Software System for Human Mobility Data Generation Based on Patterns of Life", "categories": ["cs.SE"], "comment": null, "summary": "Understanding individual-level human mobility is critical for a wide range of applications. Real-world trajectory datasets provide valuable insights into actual movement behaviors but are often constrained by data sparsity and participant bias. Synthetic data, by contrast, offer scalability and flexibility but frequently lack realism. To address this gap, we introduce a comprehensive software pipeline for calibrating, generating, processing, and visualizing large-scale individual-level human mobility datasets that combine the realism of empirical data with the control and extensibility of Patterns-of-Life simulations. Our system consists of four integrated components. (1) a data generation engine constructs geographically grounded simulations using OpenStreetMap data to produce diverse mobility logs. (2) a genetic algorithm-based calibration module fine-tunes simulation parameters to align with real-world mobility characteristics, such as daily trip counts and radius of gyration, enabling realistic behavioral modeling. (3) a data processing suite transforms raw simulation logs into structured formats suitable for downstream applications, including model training and benchmarking. (4) a visualization module extracts key mobility patterns and insights from the processed datasets and presents them through intuitive visual analytics for improved interpretability.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7efc\u5408\u8f6f\u4ef6\u7ba1\u9053\u6765\u751f\u6210\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u4e0e\u6a21\u62df\u53ef\u6269\u5c55\u6027\u7684\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u5b9e\u8f68\u8ff9\u6570\u636e\u6709\u7a00\u758f\u6027\u548c\u504f\u5dee\u95ee\u9898\uff0c\u5408\u6210\u6570\u636e\u7f3a\u4e4f\u771f\u5b9e\u6027\uff0c\u4e3a\u586b\u8865\u6b64\u5dee\u8ddd\u5c55\u5f00\u7814\u7a76\u3002", "method": "\u6784\u5efa\u5305\u542b\u6570\u636e\u751f\u6210\u5f15\u64ce\u3001\u6821\u51c6\u6a21\u5757\u3001\u6570\u636e\u5904\u7406\u5957\u4ef6\u548c\u53ef\u89c6\u5316\u6a21\u5757\u7684\u8f6f\u4ef6\u7ba1\u9053\u7cfb\u7edf\u3002", "result": "\u6784\u5efa\u51fa\u80fd\u7ed3\u5408\u73b0\u5b9e\u6570\u636e\u4e0e\u6a21\u5f0f\u6a21\u62df\u7684\u7efc\u5408\u8f6f\u4ef6\u7ba1\u9053\uff0c\u53ef\u751f\u6210\u4e0d\u540c\u7c7b\u578b\u79fb\u52a8\u65e5\u5fd7\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f6f\u4ef6\u7cfb\u7edf\u6709\u52a9\u4e8e\u751f\u6210\u5927\u89c4\u6a21\u4e2a\u4f53\u7ea7\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6\u3002"}}
{"id": "2601.00823", "pdf": "https://arxiv.org/pdf/2601.00823", "abs": "https://arxiv.org/abs/2601.00823", "authors": ["Austin R. Ellis-Mohr", "Max Hartman", "Lav R. Varshney"], "title": "Energy-Aware Routing to Large Reasoning Models", "categories": ["cs.AI", "cs.IT", "eess.SY"], "comment": null, "summary": "Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5927\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u63a8\u7406\u80fd\u8017\u95ee\u9898\uff0c\u63d0\u51fa\u5173\u952e\u8fd0\u884c\u673a\u5236\u53ca\u65b9\u5dee\u611f\u77e5\u8def\u7531\u8c03\u5ea6\u89c6\u89d2\uff0c\u4e3a\u5f00\u53d1\u8282\u80fd\u6a21\u578b\u8def\u7531\u7b56\u7565\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "LRMs\u63a8\u7406\u80fd\u8017\u56e0\u6a21\u578b\u548c\u63a8\u7406\u7a0b\u5ea6\u800c\u5f02\uff0c\u4e3a\u964d\u4f4e\u80fd\u8017\uff0c\u9700\u9009\u62e9\u5408\u9002\u6a21\u578b\u5e76\u6b63\u786e\u64cd\u4f5c\uff0c\u4e14\u4efb\u52a1\u8c03\u5ea6\u7cfb\u7edf\u6027\u80fd\u4f9d\u8d56\u4e8e\u5e73\u5747\u80fd\u6e90\u4f9b\u5e94\u548c\u968f\u673a\u6ce2\u52a8\u7684\u5e73\u8861\u3002", "method": "\u5bf9\u5173\u952e\u8fd0\u884c\u673a\u5236\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u4ece\u65f6\u95f4\u3001\u6a21\u578b\u548c\u6267\u884c\u9009\u62e9\u65b9\u9762\u8003\u8651\u5982\u4f55\u5438\u6536\u53ef\u53d8\u6027\uff0c\u57fa\u4e8eLRMs\u7684\u8bad\u7ec3\u8ba1\u7b97\u548c\u63a8\u7406\u8ba1\u7b97\u7f29\u653e\u5b9a\u5f8b\u6765\u8868\u5f81\u8def\u7531\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u5173\u952e\u8fd0\u884c\u673a\u5236\uff0c\u6307\u51fa\u6027\u80fd\u53d7\u53ef\u53d8\u6027\u5438\u6536\u65b9\u5f0f\u5f71\u54cd\uff0c\u5f3a\u8c03\u65b9\u5dee\u611f\u77e5\u8def\u7531\u548c\u8c03\u5ea6\u662f\u8bbe\u8ba1\u539f\u5219\u3002", "conclusion": "\u4e3a\u5f00\u53d1\u8282\u80fd\u6a21\u578b\u8def\u7531\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.01238", "pdf": "https://arxiv.org/pdf/2601.01238", "abs": "https://arxiv.org/abs/2601.01238", "authors": ["Kalyaan Rao"], "title": "Evidence Slopes and Effective Dimension in Singular Linear Models", "categories": ["stat.ML", "cs.LG"], "comment": "Preprint. 10 pages, 6 figures. Under review", "summary": "Bayesian model selection commonly relies on Laplace approximation or the Bayesian Information Criterion (BIC), which assume that the effective model dimension equals the number of parameters. Singular learning theory replaces this assumption with the real log canonical threshold (RLCT), an effective dimension that can be strictly smaller in overparameterized or rank-deficient models.\n  We study linear-Gaussian rank models and linear subspace (dictionary) models in which the exact marginal likelihood is available in closed form and the RLCT is analytically tractable. In this setting, we show theoretically and empirically that the error of Laplace/BIC grows linearly with (d/2 minus lambda) times log n, where d is the ambient parameter dimension and lambda is the RLCT. An RLCT-aware correction recovers the correct evidence slope and is invariant to overcomplete reparameterizations that represent the same data subspace.\n  Our results provide a concrete finite-sample characterization of Laplace failure in singular models and demonstrate that evidence slopes can be used as a practical estimator of effective dimension in simple linear settings.", "AI": {"tldr": "\u7814\u7a76\u7ebf\u6027\u9ad8\u65af\u79e9\u6a21\u578b\u548c\u7ebf\u6027\u5b50\u7a7a\u95f4\u6a21\u578b\uff0c\u6307\u51faLaplace/BIC\u5728\u5947\u5f02\u6a21\u578b\u4e2d\u8bef\u5dee\u589e\u957f\u60c5\u51b5\uff0c\u63d0\u51faRLCT\u6821\u6b63\u65b9\u6cd5\uff0c\u7ed3\u679c\u53ef\u8868\u5f81Laplace\u5931\u6548\u5e76\u4ee5\u8bc1\u636e\u659c\u7387\u4f30\u8ba1\u6709\u6548\u7ef4\u5ea6\u3002", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u6a21\u578b\u9009\u62e9\u7684Laplace\u8fd1\u4f3c\u6216BIC\u5047\u8bbe\u6709\u6548\u6a21\u578b\u7ef4\u5ea6\u7b49\u4e8e\u53c2\u6570\u6570\u91cf\uff0c\u5728\u8fc7\u53c2\u6570\u5316\u6216\u79e9\u4e8f\u6a21\u578b\u4e2d\u5b58\u5728\u95ee\u9898\uff0c\u9700\u7528RLCT\u66ff\u4ee3\u3002", "method": "\u7814\u7a76\u7ebf\u6027 - \u9ad8\u65af\u79e9\u6a21\u578b\u548c\u7ebf\u6027\u5b50\u7a7a\u95f4\u6a21\u578b\uff0c\u7406\u8bba\u63a8\u5bfc\u548c\u5b9e\u8bc1\u5206\u6790Laplace/BIC\u8bef\u5dee\u3002", "result": "Laplace/BIC\u8bef\u5dee\u968f(d/2 - lambda) * log n\u7ebf\u6027\u589e\u957f\uff0cRLCT\u6821\u6b63\u53ef\u6062\u590d\u6b63\u786e\u8bc1\u636e\u659c\u7387\uff0c\u4e14\u5bf9\u76f8\u540c\u6570\u636e\u5b50\u7a7a\u95f4\u7684\u8fc7\u5b8c\u5907\u91cd\u65b0\u53c2\u6570\u5316\u4e0d\u53d8\u3002", "conclusion": "\u7ed3\u679c\u7ed9\u51fa\u5947\u5f02\u6a21\u578b\u4e2dLaplace\u5931\u6548\u7684\u6709\u9650\u6837\u672c\u7279\u5f81\uff0c\u8868\u660e\u8bc1\u636e\u659c\u7387\u53ef\u5728\u7b80\u5355\u7ebf\u6027\u8bbe\u7f6e\u4e2d\u4f5c\u4e3a\u6709\u6548\u7ef4\u5ea6\u7684\u5b9e\u7528\u4f30\u8ba1\u5668\u3002"}}
{"id": "2601.02257", "pdf": "https://arxiv.org/pdf/2601.02257", "abs": "https://arxiv.org/abs/2601.02257", "authors": ["Joel Daniel Andersson", "Palak Jain", "Satchit Sivakumar"], "title": "Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization", "categories": ["cs.CR", "cs.DS", "cs.LG"], "comment": null, "summary": "We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.\n  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2601.01596", "pdf": "https://arxiv.org/pdf/2601.01596", "abs": "https://arxiv.org/abs/2601.01596", "authors": ["Congrong Ren", "Robert Underwood", "Sheng Di", "Emrecan Kutay", "Zarija Lukic", "Aylin Yener", "Franck Cappello", "Hanqi Guo"], "title": "FFCz: Fast Fourier Correction for Spectrum-Preserving Lossy Compression of Scientific Data", "categories": ["cs.DC", "astro-ph.IM"], "comment": null, "summary": "This paper introduces a novel technique to preserve spectral features in lossy compression based on a novel fast Fourier correction algorithm\\added{ for regular-grid data}. Preserving both spatial and frequency representations of data is crucial for applications such as cosmology, turbulent combustion, and X-ray diffraction, where spatial and frequency views provide complementary scientific insights. In particular, many analysis tasks rely on frequency-domain representations to capture key features, including the power spectrum of cosmology simulations, the turbulent energy spectrum in combustion, and diffraction patterns in reciprocal space for ptychography. However, existing compression methods guarantee accuracy only in the spatial domain while disregarding the frequency domain. To address this limitation, we propose an algorithm that corrects the errors produced by off-the-shelf ``base'' compressors such as SZ3, ZFP, and SPERR, thereby preserving both spatial and frequency representations by bounding errors in both domains. By expressing frequency-domain errors as linear combinations of spatial-domain errors, we derive a region that jointly bounds errors in both domains. Given as input the spatial errors from a base compressor and user-defined error bounds in the spatial and frequency domains, we iteratively project the spatial error vector onto the regions defined by the spatial and frequency constraints until it lies within their intersection. We further accelerate the algorithm using GPU parallelism to achieve practical performance. We validate our approach with datasets from cosmology simulations, X-ray diffraction, combustion simulation, and electroencephalography demonstrating its effectiveness in preserving critical scientific information in both spatial and frequency domains.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5feb\u901f\u5085\u91cc\u53f6\u6821\u6b63\u7b97\u6cd5\u7684\u6709\u635f\u538b\u7f29\u6280\u672f\uff0c\u6821\u6b63\u73b0\u6709\u538b\u7f29\u5668\u8bef\u5dee\uff0c\u517c\u987e\u7a7a\u95f4\u548c\u9891\u7387\u57df\uff0c\u7528GPU\u52a0\u901f\uff0c\u7ecf\u591a\u9886\u57df\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u4ec5\u4fdd\u8bc1\u7a7a\u95f4\u57df\u7cbe\u5ea6\uff0c\u5ffd\u7565\u9891\u7387\u57df\uff0c\u800c\u5f88\u591a\u5e94\u7528\u9700\u540c\u65f6\u4fdd\u7559\u6570\u636e\u7684\u7a7a\u95f4\u548c\u9891\u7387\u8868\u793a\u3002", "method": "\u63d0\u51fa\u7b97\u6cd5\u6821\u6b63\u5982SZ3\u3001ZFP\u548cSPERR\u7b49\u73b0\u6709\u538b\u7f29\u5668\u8bef\u5dee\uff1b\u5c06\u9891\u57df\u8bef\u5dee\u8868\u793a\u4e3a\u7a7a\u95f4\u57df\u8bef\u5dee\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u63a8\u5bfc\u8054\u5408\u8fb9\u754c\u533a\u57df\uff1b\u8fed\u4ee3\u6295\u5f71\u7a7a\u95f4\u8bef\u5dee\u5411\u91cf\u5230\u7ea6\u675f\u533a\u57df\uff1b\u7528GPU\u5e76\u884c\u52a0\u901f\u3002", "result": "\u7528\u5b87\u5b99\u5b66\u6a21\u62df\u3001X\u5c04\u7ebf\u884d\u5c04\u3001\u71c3\u70e7\u6a21\u62df\u548c\u8111\u7535\u56fe\u7b49\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4fdd\u7559\u7a7a\u95f4\u548c\u9891\u7387\u57df\u5173\u952e\u79d1\u5b66\u4fe1\u606f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u4e0d\u8db3\uff0c\u5728\u591a\u4e2a\u9886\u57df\u6570\u636e\u538b\u7f29\u4e2d\u6709\u6548\u4fdd\u7559\u7a7a\u95f4\u548c\u9891\u7387\u57df\u7684\u5173\u952e\u79d1\u5b66\u4fe1\u606f\u3002"}}
{"id": "2601.01444", "pdf": "https://arxiv.org/pdf/2601.01444", "abs": "https://arxiv.org/abs/2601.01444", "authors": ["Haoxuan Xie", "Junfeng Liu", "Siqiang Luo", "Kai Wang"], "title": "RadixGraph: A Fast, Space-Optimized Data Structure for Dynamic Graph Storage (Extended Version)", "categories": ["cs.DB"], "comment": "Accepted by SIGMOD 2026", "summary": "Dynamic graphs model many real-world applications, and as their sizes grow, efficiently storing and updating them becomes critical. We present RadixGraph, a fast and memory-efficient data structure for dynamic graph storage. RadixGraph features a carefully designed radix-tree-based vertex index that strikes an optimal trade-off between query efficiency and space among all pointer-array-based radix trees. For edge storage, it employs a hybrid snapshot-log architecture that enables amortized $O(1)$ update time. RadixGraph supports millions of concurrent updates per second while maintaining competitive performance for graph analytics. Experimental results show that RadixGraph outperforms the most performant baseline by up to $16.27\\times$ across various datasets in ingesting graph updates, and reduces memory usage by an average of $40.1\\%$. RadixGraph is open-source at https://github.com/ForwardStar/RadixGraph.", "AI": {"tldr": "\u63d0\u51fa RadixGraph \u7528\u4e8e\u52a8\u6001\u56fe\u5b58\u50a8\uff0c\u6027\u80fd\u597d\u4e14\u5f00\u6e90\u3002", "motivation": "\u52a8\u6001\u56fe\u89c4\u6a21\u589e\u5927\uff0c\u9700\u9ad8\u6548\u5b58\u50a8\u548c\u66f4\u65b0\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u57fa\u6570\u6811\u7684\u9876\u70b9\u7d22\u5f15\uff0c\u91c7\u7528\u6df7\u5408\u5feb\u7167 - \u65e5\u5fd7\u67b6\u6784\u5b58\u50a8\u8fb9\u3002", "result": "\u6bcf\u79d2\u652f\u6301\u6570\u767e\u4e07\u5e76\u53d1\u66f4\u65b0\uff0c\u5728\u6444\u5165\u56fe\u66f4\u65b0\u65f6\u6bd4\u57fa\u7ebf\u6700\u591a\u5feb 16.27 \u500d\uff0c\u5e73\u5747\u51cf\u5c11 40.1% \u5185\u5b58\u4f7f\u7528\u3002", "conclusion": "RadixGraph \u662f\u5feb\u901f\u4e14\u5185\u5b58\u9ad8\u6548\u7684\u52a8\u6001\u56fe\u5b58\u50a8\u6570\u636e\u7ed3\u6784\u3002"}}
{"id": "2601.00941", "pdf": "https://arxiv.org/pdf/2601.00941", "abs": "https://arxiv.org/abs/2601.00941", "authors": ["Xujun Che", "Xiuxia Du", "Depeng Xu"], "title": "Comparative Analysis of Formula and Structure Prediction from Tandem Mass Spectra", "categories": ["q-bio.QM", "cs.AI", "cs.CE"], "comment": null, "summary": "Liquid chromatography mass spectrometry (LC-MS)-based metabolomics and exposomics aim to measure detectable small molecules in biological samples. The results facilitate hypothesis-generating discovery of metabolic changes and disease mechanisms and provide information about environmental exposures and their effects on human health. Metabolomics and exposomics are made possible by the high resolving power of LC and high mass measurement accuracy of MS. However, a majority of the signals from such studies still cannot be identified or annotated using conventional library searching because existing spectral libraries are far from covering the vast chemical space captured by LC-MS/MS. To address this challenge and unleash the full potential of metabolomics and exposomics, a number of computational approaches have been developed to predict compounds based on tandem mass spectra. Published assessment of these approaches used different datasets and evaluation. To select prediction workflows for practical applications and identify areas for further improvements, we have carried out a systematic evaluation of the state-of-the-art prediction algorithms. Specifically, the accuracy of formula prediction and structure prediction was evaluated for different types of adducts. The resulting findings have established realistic performance baselines, identified critical bottlenecks, and provided guidance to further improve compound predictions based on MS.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u57fa\u4e8eLC - MS\u7684\u4ee3\u8c22\u7ec4\u5b66\u548c\u66b4\u9732\u7ec4\u5b66\u5316\u5408\u7269\u9884\u6d4b\u7b97\u6cd5\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u5149\u8c31\u5e93\u65e0\u6cd5\u8986\u76d6LC - MS/MS\u6355\u83b7\u7684\u5316\u5b66\u7a7a\u95f4\uff0c\u5df2\u6709\u7684\u5316\u5408\u7269\u9884\u6d4b\u65b9\u6cd5\u8bc4\u4f30\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\uff0c\u4e3a\u9009\u62e9\u5b9e\u7528\u9884\u6d4b\u6d41\u7a0b\u548c\u6539\u8fdb\u76f8\u5173\u65b9\u6cd5\uff0c\u9700\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u5bf9\u4e0d\u540c\u7c7b\u578b\u52a0\u5408\u7269\u8bc4\u4f30\u516c\u5f0f\u9884\u6d4b\u548c\u7ed3\u6784\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u73b0\u5b9e\u7684\u6027\u80fd\u57fa\u7ebf\uff0c\u786e\u5b9a\u4e86\u5173\u952e\u74f6\u9888\u3002", "conclusion": "\u4e3a\u57fa\u4e8e\u8d28\u8c31\u7684\u5316\u5408\u7269\u9884\u6d4b\u8fdb\u4e00\u6b65\u6539\u8fdb\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2601.01118", "pdf": "https://arxiv.org/pdf/2601.01118", "abs": "https://arxiv.org/abs/2601.01118", "authors": ["Qingqing Long", "Haotian Chen", "Chenyang Zhao", "Xiaolei Du", "Xuezhi Wang", "Pengyao Wang", "Chengzan Li", "Yuanchun Zhou", "Hengshu Zhu"], "title": "ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services", "categories": ["cs.IR", "cs.AI", "cs.DL"], "comment": "12 pages, 9 figures", "summary": "The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u79d1\u5b66\u6570\u636e\u96c6\u63a8\u8350\u7cfb\u7edfScienceDB AI\uff0c\u7ecf\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u4e14\u516c\u5f00\u53ef\u7528\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u6570\u636e\u96c6\u5171\u4eab\u548c\u5229\u7528\u5b58\u5728\u6311\u6218\uff0c\u4f20\u7edf\u63a8\u8350\u5668\u4e0d\u8db3\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u65b0\u673a\u9047\u3002", "method": "\u5f00\u53d1ScienceDB AI\u7cfb\u7edf\uff0c\u6709\u79d1\u5b66\u610f\u56fe\u611f\u77e5\u5668\u3001\u7ed3\u6784\u5316\u5185\u5b58\u538b\u7f29\u5668\u548c\u53ef\u4fe1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u8d851000\u4e07\u771f\u5b9e\u6570\u636e\u96c6\u7684\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\uff0c\u8bc1\u660eScienceDB AI\u6709\u6548\u3002", "conclusion": "ScienceDB AI\u662f\u9996\u4e2a\u9488\u5bf9\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6\u5171\u4eab\u670d\u52a1\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u5bf9\u8bdd\u5f0f\u63a8\u8350\u5668\u3002"}}
{"id": "2601.01317", "pdf": "https://arxiv.org/pdf/2601.01317", "abs": "https://arxiv.org/abs/2601.01317", "authors": ["Chang Shao", "Qi Zhao", "Nana Pu", "Shi Cheng", "Jing Jiang", "Yuhui Shi"], "title": "Benchmarking Continuous Dynamic Multi-Objective Optimization: Survey and Generalized Test Suite", "categories": ["cs.NE"], "comment": null, "summary": "Dynamic multi-objective optimization (DMOO) has recently attracted increasing interest from both academic researchers and engineering practitioners, as numerous real-world applications that evolve over time can be naturally formulated as dynamic multi-objective optimization problems (DMOPs). This growing trend necessitates advanced benchmarks for the rigorous evaluation of optimization algorithms under realistic conditions. This paper introduces a comprehensive and principled framework for constructing highly realistic and challenging DMOO benchmarks. The proposed framework features several novel components: a generalized formulation that allows the Pareto-optimal Set (PS) to change on hypersurfaces, a mechanism for creating controlled variable contribution imbalances to generate heterogeneous landscapes, and dynamic rotation matrices for inducing time-varying variable interactions and non-separability. Furthermore, we incorporate a temporal perturbation mechanism to simulate irregular environmental changes and propose a generalized time-linkage mechanism that systematically embeds historical solution quality into future problems, thereby capturing critical real-world phenomena such as error accumulation and time-deception. Extensive experimental results validate the effectiveness of the proposed framework, demonstrating its superiority over conventional benchmarks in terms of realism, complexity, and its capability for discriminating state-of-the-art algorithmic performance. This work establishes a new standard for dynamic multi-objective optimization benchmarking, providing a powerful tool for the development and evaluation of next-generation algorithms capable of addressing the complexities of real-world dynamic systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6784\u5efa\u52a8\u6001\u591a\u76ee\u6807\u4f18\u5316\uff08DMOO\uff09\u57fa\u51c6\u7684\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\uff0c\u4e3aDMOO\u57fa\u51c6\u8bbe\u5b9a\u65b0\u6807\u51c6\u3002", "motivation": "\u968f\u7740DMOO\u53d7\u5173\u6ce8\uff0c\u9700\u5148\u8fdb\u57fa\u51c6\u8bc4\u4f30\u4f18\u5316\u7b97\u6cd5\uff0c\u73b0\u6709\u57fa\u51c6\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9e\u6761\u4ef6\u4e0b\u7684\u8bc4\u4f30\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u7efc\u5408\u6846\u67b6\uff0c\u5305\u542b\u5141\u8bb8Pareto\u6700\u4f18\u96c6\u5728\u8d85\u66f2\u9762\u4e0a\u53d8\u5316\u7684\u5e7f\u4e49\u516c\u5f0f\u3001\u521b\u5efa\u53d8\u91cf\u8d21\u732e\u4e0d\u5e73\u8861\u673a\u5236\u3001\u52a8\u6001\u65cb\u8f6c\u77e9\u9635\u3001\u65f6\u95f4\u6270\u52a8\u673a\u5236\u548c\u5e7f\u4e49\u65f6\u95f4\u94fe\u63a5\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5728\u73b0\u5b9e\u6027\u3001\u590d\u6742\u6027\u548c\u533a\u5206\u7b97\u6cd5\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u57fa\u51c6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aDMOO\u57fa\u51c6\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u7b97\u6cd5\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2601.00807", "pdf": "https://arxiv.org/pdf/2601.00807", "abs": "https://arxiv.org/abs/2601.00807", "authors": ["Sreerag Puravankara", "Vipin P. Veetil"], "title": "When Is Degree Enough? Bounds on Degree-Eigenvector Misalignment in Assortative Structured Networks", "categories": ["cs.SI", "econ.GN", "econ.TH"], "comment": null, "summary": "A tight alignment between the degree vector and the leading eigenvector arises naturally in networks with neutral degree mixing and the absence of local structures. Many real-world networks, however, violate both conditions. We derive bounds on the divergence between the degree vector and the eigenvector in networks with degree assortativity and local mesoscopic structures such as communities, core-peripheries, and cycles. Our approach is constructive. We design sufficiently general degree-preserving rewiring algorithms that start from a neutral benchmark and monotonically increase assortativity and the strength of local structures, with each step inducing a perturbation of the adjacency matrix. Using the Stewart--Sun Perturbation Bound, together with explicit spectral-norm control of the rewiring steps, we derive upper bounds on the angle between the eigenvector and the degree vector for modest levels of assortativity and local structures. Our analytical bounds delineate regions of `spectral safety' in which a node's degree can be used as a reliable measure of its systemic importance in real-world networks.", "AI": {"tldr": "\u63a8\u5bfc\u5ea6\u5411\u91cf\u548c\u7279\u5f81\u5411\u91cf\u5728\u5177\u6709\u5ea6\u76f8\u5173\u6027\u548c\u5c40\u90e8\u4ecb\u89c2\u7ed3\u6784\u7f51\u7edc\u4e2d\u7684\u5dee\u5f02\u754c\u9650\uff0c\u754c\u5b9a\u201c\u8c31\u5b89\u5168\u201d\u533a\u57df\u3002", "motivation": "\u8bb8\u591a\u73b0\u5b9e\u7f51\u7edc\u4e0d\u6ee1\u8db3\u5ea6\u5411\u91cf\u548c\u4e3b\u7279\u5f81\u5411\u91cf\u7d27\u5bc6\u5bf9\u9f50\u7684\u6761\u4ef6\uff0c\u9700\u7814\u7a76\u6709\u5ea6\u76f8\u5173\u6027\u548c\u5c40\u90e8\u7ed3\u6784\u7f51\u7edc\u4e2d\u4e8c\u8005\u5dee\u5f02\u3002", "method": "\u8bbe\u8ba1\u4fdd\u5ea6\u91cd\u8fde\u7b97\u6cd5\uff0c\u4ece\u4e2d\u6027\u57fa\u51c6\u5f00\u59cb\u5355\u8c03\u589e\u52a0\u76f8\u5173\u6027\u548c\u5c40\u90e8\u7ed3\u6784\u5f3a\u5ea6\uff0c\u5229\u7528Stewart - Sun\u6444\u52a8\u754c\u548c\u8c31\u8303\u6570\u63a7\u5236\u63a8\u5bfc\u754c\u9650\u3002", "result": "\u5f97\u5230\u9002\u5ea6\u76f8\u5173\u6027\u548c\u5c40\u90e8\u7ed3\u6784\u4e0b\u7279\u5f81\u5411\u91cf\u4e0e\u5ea6\u5411\u91cf\u5939\u89d2\u7684\u4e0a\u754c\u3002", "conclusion": "\u5206\u6790\u754c\u9650\u754c\u5b9a\u4e86\u201c\u8c31\u5b89\u5168\u201d\u533a\u57df\uff0c\u53ef\u5c06\u8282\u70b9\u5ea6\u4f5c\u4e3a\u8861\u91cf\u5176\u7cfb\u7edf\u91cd\u8981\u6027\u7684\u53ef\u9760\u6307\u6807\u3002"}}
{"id": "2601.01233", "pdf": "https://arxiv.org/pdf/2601.01233", "abs": "https://arxiv.org/abs/2601.01233", "authors": ["Kangchen Zhu", "Zhiliang Tian", "Shangwen Wang", "Mingyue Leng", "Xiaoguang Mao"], "title": "Atomizer: An LLM-based Collaborative Multi-Agent Framework for Intent-Driven Commit Untangling", "categories": ["cs.SE"], "comment": "Accepted by ICSE 2026", "summary": "Composite commits, which entangle multiple unrelated concerns, are prevalent in software development and significantly hinder program comprehension and maintenance. Existing automated untangling methods, particularly state-of-the-art graph clustering-based approaches, are fundamentally limited by two issues. (1) They over-rely on structural information, failing to grasp the crucial semantic intent behind changes, and (2) they operate as ``single-pass'' algorithms, lacking a mechanism for the critical reflection and refinement inherent in human review processes. To overcome these challenges, we introduce Atomizer, a novel collaborative multi-agent framework for composite commit untangling. To address the semantic deficit, Atomizer employs an Intent-Oriented Chain-of-Thought (IO-CoT) strategy, which prompts large language models (LLMs) to infer the intent of each code change according to both the structure and the semantic information of code. To overcome the limitations of ``single-pass'' grouping, we employ two agents to establish a grouper-reviewer collaborative refinement loop, which mirrors human review practices by iteratively refining groupings until all changes in a cluster share the same underlying semantic intent. Extensive experiments on two benchmark C# and Java datasets demonstrate that Atomizer significantly outperforms several representative baselines. On average, it surpasses the state-of-the-art graph-based methods by over 6.0% on the C# dataset and 5.5% on the Java dataset. This superiority is particularly pronounced on complex commits, where Atomizer's performance advantage widens to over 16%.", "AI": {"tldr": "\u73b0\u6709\u81ea\u52a8\u5316\u62c6\u5206\u590d\u5408\u63d0\u4ea4\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51faAtomizer\u6846\u67b6\uff0c\u7528IO - CoT\u7b56\u7565\u548c\u53cc\u4ee3\u7406\u534f\u4f5c\u7ec6\u5316\u5faa\u73af\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u62c6\u5206\u590d\u5408\u63d0\u4ea4\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u7ed3\u6784\u4fe1\u606f\uff0c\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u4e14\u4e3a\u5355\u904d\u7b97\u6cd5\uff0c\u65e0\u6cd5\u50cf\u4eba\u7c7b\u5ba1\u67e5\u4e00\u6837\u53cd\u601d\u7ec6\u5316\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faAtomizer\u6846\u67b6\uff0c\u91c7\u7528IO - CoT\u7b56\u7565\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u6839\u636e\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u63a8\u65ad\u4ee3\u7801\u66f4\u6539\u610f\u56fe\uff0c\u7528\u4e24\u4e2a\u4ee3\u7406\u5efa\u7acb\u5206\u7ec4 - \u5ba1\u67e5\u534f\u4f5c\u7ec6\u5316\u5faa\u73af\u3002", "result": "\u5728C#\u548cJava\u6570\u636e\u96c6\u4e0a\uff0cAtomizer\u5e73\u5747\u6bd4\u73b0\u6709\u56fe\u805a\u7c7b\u65b9\u6cd5\u5206\u522b\u9ad8\u51fa6.0%\u548c5.5%\uff0c\u5728\u590d\u6742\u63d0\u4ea4\u4e0a\u4f18\u52bf\u6269\u5927\u523016%\u4ee5\u4e0a\u3002", "conclusion": "Atomizer\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u81ea\u52a8\u5316\u62c6\u5206\u590d\u5408\u63d0\u4ea4\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u4ee3\u8868\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2601.00828", "pdf": "https://arxiv.org/pdf/2601.00828", "abs": "https://arxiv.org/abs/2601.00828", "authors": ["Yin Li"], "title": "Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis", "categories": ["cs.AI"], "comment": "9 pages, 2 figures, 3 tables. Code available at https://github.com/Kevin0304-li/llm-self-correction", "summary": "Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.", "AI": {"tldr": "\u7814\u7a76\u5206\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u7ea0\u9519\u80fd\u529b\u4e3a\u4e09\u79cd\u5b50\u80fd\u529b\uff0c\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u51c6\u786e\u7387 - \u7ea0\u9519\u6096\u8bba\uff0c\u63d0\u51fa\u8bef\u5dee\u6df1\u5ea6\u5047\u8bbe\uff0c\u6311\u6218\u4f20\u7edf\u8ba4\u77e5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8ba4\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5728\u81ea\u7ea0\u9519\u80fd\u529b\u4e0d\u4f73\uff0c\u9700\u6df1\u5165\u63a2\u7a76\u5176\u81ea\u7ea0\u9519\u80fd\u529b\u3002", "method": "\u5c06\u81ea\u7ea0\u9519\u5206\u89e3\u4e3a\u8bef\u5dee\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u4fee\u6b63\u4e09\u79cd\u5b50\u80fd\u529b\uff0c\u5728GSM8K - Complex\u4e0a\u5bf9\u4e09\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8de8\u6a21\u578b\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u51c6\u786e\u7387 - \u7ea0\u9519\u6096\u8bba\uff0c\u5f31\u6a21\u578b\u6bd4\u5f3a\u6a21\u578b\u67091.6\u500d\u66f4\u9ad8\u7684\u5185\u5728\u7ea0\u9519\u7387\uff1b\u8bef\u5dee\u68c0\u6d4b\u7387\u56e0\u67b6\u6784\u800c\u5f02\uff1b\u68c0\u6d4b\u80fd\u529b\u4e0d\u80fd\u9884\u6d4b\u7ea0\u9519\u6210\u529f\uff1b\u63d0\u4f9b\u8bef\u5dee\u4f4d\u7f6e\u63d0\u793a\u5bf9\u6240\u6709\u6a21\u578b\u6709\u5bb3\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u5173\u4e8e\u6a21\u578b\u80fd\u529b\u548c\u81ea\u6211\u63d0\u5347\u7684\u7ebf\u6027\u5047\u8bbe\uff0c\u5bf9\u81ea\u4f18\u5316\u6d41\u7a0b\u8bbe\u8ba1\u6709\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2601.01442", "pdf": "https://arxiv.org/pdf/2601.01442", "abs": "https://arxiv.org/abs/2601.01442", "authors": ["Dongrong Li", "Tianwei Yu", "Xiaodan Fan"], "title": "Fast Gibbs Sampling on Bayesian Hidden Markov Model with Missing Observations", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "45 pages, 2 figures", "summary": "The Hidden Markov Model (HMM) is a widely-used statistical model for handling sequential data. However, the presence of missing observations in real-world datasets often complicates the application of the model. The EM algorithm and Gibbs samplers can be used to estimate the model, yet suffering from various problems including non-convexity, high computational complexity and slow mixing. In this paper, we propose a collapsed Gibbs sampler that efficiently samples from HMMs' posterior by integrating out both the missing observations and the corresponding latent states. The proposed sampler is fast due to its three advantages. First, it achieves an estimation accuracy that is comparable to existing methods. Second, it can produce a larger Effective Sample Size (ESS) per iteration, which can be justified theoretically and numerically. Third, when the number of missing entries is large, the sampler has a significant smaller computational complexity per iteration compared to other methods, thus is faster computationally. In summary, the proposed sampling algorithm is fast both computationally and theoretically and is particularly advantageous when there are a lot of missing entries. Finally, empirical evaluations based on numerical simulations and real data analysis demonstrate that the proposed algorithm consistently outperforms existing algorithms in terms of time complexity and sampling efficiency (measured in ESS).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u584c\u7f29\u5409\u5e03\u65af\u91c7\u6837\u5668\u7528\u4e8e\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08HMM\uff09\uff0c\u5728\u5904\u7406\u542b\u7f3a\u5931\u503c\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u8ba1\u7b97\u548c\u7406\u8bba\u5c42\u9762\u90fd\u66f4\u5feb\uff0c\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u5904\u7406\u542b\u7f3a\u5931\u503c\u5e8f\u5217\u6570\u636e\u7684HMM\u4f30\u8ba1\u65b9\u6cd5\uff08EM\u7b97\u6cd5\u548c\u5409\u5e03\u65af\u91c7\u6837\u5668\uff09\u5b58\u5728\u975e\u51f8\u6027\u3001\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u6162\u6df7\u5408\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u584c\u7f29\u5409\u5e03\u65af\u91c7\u6837\u5668\uff0c\u901a\u8fc7\u5bf9\u7f3a\u5931\u89c2\u6d4b\u503c\u548c\u76f8\u5e94\u6f5c\u5728\u72b6\u6001\u8fdb\u884c\u79ef\u5206\uff0c\u4eceHMM\u7684\u540e\u9a8c\u5206\u5e03\u4e2d\u9ad8\u6548\u91c7\u6837\u3002", "result": "\u8be5\u91c7\u6837\u5668\u4f30\u8ba1\u7cbe\u5ea6\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\uff0c\u6bcf\u6b21\u8fed\u4ee3\u80fd\u4ea7\u751f\u66f4\u5927\u7684\u6709\u6548\u6837\u672c\u91cf\uff08ESS\uff09\uff0c\u5728\u7f3a\u5931\u9879\u8f83\u591a\u65f6\u6bcf\u6b21\u8fed\u4ee3\u8ba1\u7b97\u590d\u6742\u5ea6\u663e\u8457\u66f4\u5c0f\uff1b\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u91c7\u6837\u6548\u7387\uff08ESS\u8861\u91cf\uff09\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u91c7\u6837\u7b97\u6cd5\u5728\u8ba1\u7b97\u548c\u7406\u8bba\u4e0a\u90fd\u5f88\u5feb\uff0c\u5728\u6709\u5927\u91cf\u7f3a\u5931\u9879\u65f6\u7279\u522b\u6709\u4f18\u52bf\u3002"}}
{"id": "2601.01712", "pdf": "https://arxiv.org/pdf/2601.01712", "abs": "https://arxiv.org/abs/2601.01712", "authors": ["Jiarui Wang", "Huichao Chai", "Yuanhang Zhang", "Zongjin Zhou", "Wei Guo", "Xingkun Yang", "Qiang Tang", "Bo Pan", "Jiawei Zhu", "Ke Cheng", "Yuting Yan", "Shulan Wang", "Yingjie Zhu", "Zhengfan Yuan", "Jiaqi Huang", "Yuhan Zhang", "Xiaosong Sun", "Zhinan Zhang", "Hong Zhu", "Yongsheng Zhang", "Tiantian Dong", "Zhong Xiao", "Deliang Liu", "Chengzhou Lu", "Yuan Sun", "Zhiyuan Chen", "Xinming Han", "Zaizhu Liu", "Yaoyuan Wang", "Ziyang Zhang", "Yong Liu", "Jinxin Xu", "Yajing Sun", "Zhoujun Yu", "Wenting Zhou", "Qidong Zhang", "Zhengyong Zhang", "Zhonghai Gu", "Yibo Jin", "Yongxiang Feng", "Pengfei Zuo"], "title": "RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": null, "summary": "Real-time recommender systems execute multi-stage cascades (retrieval, pre-processing, fine-grained ranking) under strict tail-latency SLOs, leaving only tens of milliseconds for ranking. Generative recommendation (GR) models can improve quality by consuming long user-behavior sequences, but in production their online sequence length is tightly capped by the ranking-stage P99 budget. We observe that the majority of GR tokens encode user behaviors that are independent of the item candidates, suggesting an opportunity to pre-infer a user-behavior prefix once and reuse it during ranking rather than recomputing it on the critical path. Realizing this idea at industrial scale is non-trivial: the prefix cache must survive across multiple pipeline stages before the final ranking instance is determined, the user population implies cache footprints far beyond a single device, and indiscriminate pre-inference would overload shared resources under high QPS. We present RelayGR, a production system that enables in-HBM relay-race inference for GR. RelayGR selectively pre-infers long-term user prefixes, keeps their KV caches resident in HBM over the request lifecycle, and ensures the subsequent ranking can consume them without remote fetches. RelayGR combines three techniques: 1) a sequence-aware trigger that admits only at-risk requests under a bounded cache footprint and pre-inference load, 2) an affinity-aware router that co-locates cache production and consumption by routing both the auxiliary pre-infer signal and the ranking request to the same instance, and 3) a memory-aware expander that uses server-local DRAM to capture short-term cross-request reuse while avoiding redundant reloads. We implement RelayGR on Huawei Ascend NPUs and evaluate it with real queries. Under a fixed P99 SLO, RelayGR supports up to 1.5$\\times$ longer sequences and improves SLO-compliant throughput by up to 3.6$\\times$.", "AI": {"tldr": "\u63d0\u51faRelayGR\u7cfb\u7edf\u5b9e\u73b0\u751f\u6210\u5f0f\u63a8\u8350\uff08GR\uff09\u7684HBM\u63a5\u529b\u63a8\u7406\uff0c\u652f\u6301\u66f4\u957f\u5e8f\u5217\uff0c\u63d0\u9ad8\u541e\u5410\u91cf\u3002", "motivation": "\u5b9e\u65f6\u63a8\u8350\u7cfb\u7edf\u6392\u540d\u9636\u6bb5\u65f6\u95f4\u6709\u9650\uff0cGR\u6a21\u578b\u5728\u7ebf\u5e8f\u5217\u957f\u5ea6\u53d7\u4e25\u683c\u9650\u5236\uff0c\u5e0c\u671b\u501f\u52a9\u9884\u63a8\u7406\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u63d0\u51faRelayGR\u7cfb\u7edf\uff0c\u91c7\u7528\u5e8f\u5217\u611f\u77e5\u89e6\u53d1\u3001\u4eb2\u548c\u611f\u77e5\u8def\u7531\u548c\u5185\u5b58\u611f\u77e5\u6269\u5c55\u4e09\u79cd\u6280\u672f\u3002", "result": "\u5728\u534e\u4e3a\u6607\u817eNPUs\u4e0a\u5b9e\u73b0\u5e76\u8bc4\u4f30\uff0c\u5728\u56fa\u5b9aP99 SLO\u4e0b\uff0c\u652f\u6301\u957f\u8fbe1.5\u500d\u7684\u5e8f\u5217\uff0c\u7b26\u5408SLO\u7684\u541e\u5410\u91cf\u63d0\u9ad8\u8fbe3.6\u500d\u3002", "conclusion": "RelayGR\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u5347GR\u6a21\u578b\u5728\u5b9e\u65f6\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.01888", "pdf": "https://arxiv.org/pdf/2601.01888", "abs": "https://arxiv.org/abs/2601.01888", "authors": ["Yifan Wu", "Yuhan Li", "Zhenhua Wang", "Zhongle Xie", "Dingyu Yang", "Ke Chen", "Lidan Shou", "Bo Tang", "Liang Lin", "Huan Li", "Gang Chen"], "title": "SafeLoad: Efficient Admission Control Framework for Identifying Memory-Overloading Queries in Cloud Data Warehouses", "categories": ["cs.DB", "cs.LG"], "comment": "This paper has been accepted for presentation at VLDB 2026", "summary": "Memory overload is a common form of resource exhaustion in cloud data warehouses. When database queries fail due to memory overload, it not only wastes critical resources such as CPU time but also disrupts the execution of core business processes, as memory-overloading (MO) queries are typically part of complex workflows. If such queries are identified in advance and scheduled to memory-rich serverless clusters, it can prevent resource wastage and query execution failure. Therefore, cloud data warehouses desire an admission control framework with high prediction precision, interpretability, efficiency, and adaptability to effectively identify MO queries. However, existing admission control frameworks primarily focus on scenarios like SLA satisfaction and resource isolation, with limited precision in identifying MO queries. Moreover, there is a lack of publicly available MO-labeled datasets with workloads for training and benchmarking. To tackle these challenges, we propose SafeLoad, the first query admission control framework specifically designed to identify MO queries. Alongside, we release SafeBench, an open-source, industrial-scale benchmark for this task, which includes 150 million real queries. SafeLoad first filters out memory-safe queries using the interpretable discriminative rule. It then applies a hybrid architecture that integrates both a global model and cluster-level models, supplemented by a misprediction correction module to identify MO queries. Additionally, a self-tuning quota management mechanism dynamically adjusts prediction quotas per cluster to improve precision. Experimental results show that SafeLoad achieves state-of-the-art prediction performance with low online and offline time overhead. Specifically, SafeLoad improves precision by up to 66% over the best baseline and reduces wasted CPU time by up to 8.09x compared to scenarios without SafeLoad.", "AI": {"tldr": "\u63d0\u51faSafeLoad\u67e5\u8be2\u51c6\u5165\u63a7\u5236\u6846\u67b6\u8bc6\u522b\u5185\u5b58\u8fc7\u8f7d\u67e5\u8be2\uff0c\u53d1\u5e03SafeBench\u57fa\u51c6\uff0c\u5b9e\u9a8c\u663e\u793aSafeLoad\u6027\u80fd\u4f18\uff0c\u63d0\u5347\u7cbe\u5ea6\u3001\u51cf\u5c11CPU\u65f6\u95f4\u6d6a\u8d39\u3002", "motivation": "\u73b0\u6709\u51c6\u5165\u63a7\u5236\u6846\u67b6\u8bc6\u522b\u5185\u5b58\u8fc7\u8f7d\u67e5\u8be2\u7cbe\u5ea6\u6709\u9650\uff0c\u4e14\u7f3a\u4e4f\u76f8\u5173\u6570\u636e\u96c6\uff0c\u4e91\u6570\u636e\u4ed3\u5e93\u9700\u9ad8\u7cbe\u5ea6\u7b49\u7279\u6027\u7684\u6846\u67b6\u3002", "method": "SafeLoad\u5148\u901a\u8fc7\u53ef\u89e3\u91ca\u5224\u522b\u89c4\u5219\u8fc7\u6ee4\u5185\u5b58\u5b89\u5168\u67e5\u8be2\uff0c\u91c7\u7528\u6df7\u5408\u67b6\u6784\u7ed3\u5408\u5168\u5c40\u548c\u96c6\u7fa4\u7ea7\u6a21\u578b\uff0c\u6709\u8bef\u5224\u7ea0\u6b63\u6a21\u5757\uff0c\u8fd8\u6709\u81ea\u8c03\u4f18\u914d\u989d\u7ba1\u7406\u673a\u5236\u3002", "result": "SafeLoad\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5728\u7ebf\u548c\u79bb\u7ebf\u65f6\u95f4\u5f00\u9500\u4f4e\uff0c\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u7cbe\u5ea6\u6700\u9ad8\u63d0\u534766%\uff0c\u76f8\u6bd4\u65e0SafeLoad\u573a\u666fCPU\u65f6\u95f4\u6d6a\u8d39\u6700\u591a\u51cf\u5c118.09\u500d\u3002", "conclusion": "SafeLoad\u662f\u6709\u6548\u7684\u67e5\u8be2\u51c6\u5165\u63a7\u5236\u6846\u67b6\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u6846\u67b6\u95ee\u9898\uff0c\u63d0\u9ad8\u8bc6\u522b\u5185\u5b58\u8fc7\u8f7d\u67e5\u8be2\u7684\u7cbe\u5ea6\u3002"}}
{"id": "2601.01009", "pdf": "https://arxiv.org/pdf/2601.01009", "abs": "https://arxiv.org/abs/2601.01009", "authors": ["Mojtaba Aliasghar-Mamaghani", "Mohammadreza Khalafi"], "title": "Data-Driven Assessment of Concrete Mixture Compositions on Chloride Transport via Standalone Machine Learning Algorithms", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "This paper employs a data-driven approach to determine the impact of concrete mixture compositions on the temporal evolution of chloride in concrete structures. This is critical for assessing the service life of civil infrastructure subjected to aggressive environments. The adopted methodology relies on several simple and complex standalone machine learning (ML) algorithms, with the primary objective of establishing confidence in the unbiased prediction of the underlying hidden correlations. The simple algorithms include linear regression (LR), k-nearest neighbors (KNN) regression, and kernel ridge regression (KRR). The complex algorithms entail support vector regression (SVR), Gaussian process regression (GPR), and two families of artificial neural networks, including a feedforward network (multilayer perceptron, MLP) and a gated recurrent unit (GRU). The MLP architecture cannot explicitly handle sequential data, a limitation addressed by the GRU. A comprehensive dataset is considered. The performance of ML algorithms is evaluated, with KRR, GPR, and MLP exhibiting high accuracy. Given the diversity of the adopted concrete mixture proportions, the GRU was unable to accurately reproduce the response in the test set. Further analyses elucidate the contributions of mixture compositions to the temporal evolution of chloride. The results obtained from the GPR model unravel latent correlations through clear and explainable trends. The MLP, SVR, and KRR also provide acceptable estimates of the overall trends. The majority of mixture components exhibit an inverse relation with chloride content, while a few components demonstrate a direct correlation. These findings highlight the potential of surrogate approaches for describing the physical processes involved in chloride ingress and the associated correlations, toward the ultimate goal of enhancing the service life of civil infrastructure.", "AI": {"tldr": "\u672c\u6587\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7814\u7a76\u6df7\u51dd\u571f\u6df7\u5408\u7269\u6210\u5206\u5bf9\u6c2f\u5316\u7269\u65f6\u95f4\u6f14\u53d8\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u591a\u6570\u6210\u5206\u4e0e\u6c2f\u5316\u7269\u542b\u91cf\u5448\u53cd\u6bd4\uff0c\u51f8\u663e\u66ff\u4ee3\u65b9\u6cd5\u5bf9\u63d0\u5347\u57fa\u7840\u8bbe\u65bd\u5bff\u547d\u7684\u6f5c\u529b\u3002", "motivation": "\u8bc4\u4f30\u5904\u4e8e\u6076\u52a3\u73af\u5883\u4e0b\u6c11\u7528\u57fa\u7840\u8bbe\u65bd\u7684\u4f7f\u7528\u5bff\u547d\uff0c\u786e\u5b9a\u6df7\u51dd\u571f\u6df7\u5408\u7269\u6210\u5206\u5bf9\u6df7\u51dd\u571f\u7ed3\u6784\u4e2d\u6c2f\u5316\u7269\u65f6\u95f4\u6f14\u53d8\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u591a\u79cd\u7b80\u5355\u548c\u590d\u6742\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u5982LR\u3001KNN\u3001KRR\u3001SVR\u3001GPR\u3001MLP\u3001GRU\uff0c\u5229\u7528\u7efc\u5408\u6570\u636e\u96c6\u8bc4\u4f30\u7b97\u6cd5\u6027\u80fd\u3002", "result": "KRR\u3001GPR\u3001MLP\u51c6\u786e\u6027\u9ad8\uff0cGRU\u65e0\u6cd5\u51c6\u786e\u518d\u73b0\u6d4b\u8bd5\u96c6\u54cd\u5e94\uff0cGPR\u6a21\u578b\u63ed\u793a\u6f5c\u5728\u5173\u8054\uff0c\u591a\u6570\u6210\u5206\u4e0e\u6c2f\u5316\u7269\u542b\u91cf\u5448\u53cd\u6bd4\u3002", "conclusion": "\u66ff\u4ee3\u65b9\u6cd5\u5728\u63cf\u8ff0\u6c2f\u5316\u7269\u4fb5\u5165\u7269\u7406\u8fc7\u7a0b\u53ca\u5173\u8054\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u53ef\u63d0\u5347\u6c11\u7528\u57fa\u7840\u8bbe\u65bd\u4f7f\u7528\u5bff\u547d\u3002"}}
{"id": "2601.01448", "pdf": "https://arxiv.org/pdf/2601.01448", "abs": "https://arxiv.org/abs/2601.01448", "authors": ["Na Li", "Fanghui Sun", "Yan Zou", "Yangfu Zhu", "Xiatian Zhu", "Ying Ma"], "title": "Adaptive Diffusion-based Augmentation for Recommendation", "categories": ["cs.IR"], "comment": null, "summary": "Recommendation systems often rely on implicit feedback, where only positive user-item interactions can be observed. Negative sampling is therefore crucial to provide proper negative training signals. However, existing methods tend to mislabel potentially positive but unobserved items as negatives and lack precise control over negative sample selection. We aim to address these by generating controllable negative samples, rather than sampling from the existing item pool. In this context, we propose Adaptive Diffusion-based Augmentation for Recommendation (ADAR), a novel and model-agnostic module that leverages diffusion to synthesize informative negatives. Inspired by the progressive corruption process in diffusion, ADAR simulates a continuous transition from positive to negative, allowing for fine-grained control over sample hardness. To mine suitable negative samples, we theoretically identify the transition point at which a positive sample turns negative and derive a score-aware function to adaptively determine the optimal sampling timestep. By identifying this transition point, ADAR generates challenging negative samples that effectively refine the model's decision boundary. Experiments confirm that ADAR is broadly compatible and boosts the performance of existing recommendation models substantially, including collaborative filtering and sequential recommendation, without architectural modifications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faADAR\u6a21\u5757\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u53ef\u63a7\u8d1f\u6837\u672c\uff0c\u63d0\u5347\u63a8\u8350\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8d1f\u91c7\u6837\u65b9\u6cd5\u4f1a\u8bef\u5c06\u6f5c\u5728\u6b63\u6837\u672c\u6807\u8bb0\u4e3a\u8d1f\u6837\u672c\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u8d1f\u6837\u672c\u9009\u62e9\u7684\u7cbe\u786e\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u9002\u5e94\u6269\u6563\u589e\u5f3a\u7684\u63a8\u8350\u6a21\u5757ADAR\uff0c\u6a21\u62df\u4ece\u6b63\u5230\u8d1f\u7684\u8fde\u7eed\u8f6c\u53d8\uff0c\u7406\u8bba\u8bc6\u522b\u6b63\u6837\u672c\u53d8\u8d1f\u7684\u8fc7\u6e21\u70b9\uff0c\u63a8\u5bfc\u5f97\u5206\u611f\u77e5\u51fd\u6570\u786e\u5b9a\u6700\u4f73\u91c7\u6837\u65f6\u95f4\u6b65\u3002", "result": "\u5b9e\u9a8c\u8868\u660eADAR\u5e7f\u6cdb\u517c\u5bb9\uff0c\u80fd\u5927\u5e45\u63d0\u5347\u73b0\u6709\u63a8\u8350\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u67b6\u6784\u4fee\u6539\u3002", "conclusion": "ADAR\u53ef\u6709\u6548\u751f\u6210\u6709\u6311\u6218\u6027\u7684\u8d1f\u6837\u672c\uff0c\u7ec6\u5316\u6a21\u578b\u51b3\u7b56\u8fb9\u754c\uff0c\u63d0\u5347\u63a8\u8350\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.01658", "pdf": "https://arxiv.org/pdf/2601.01658", "abs": "https://arxiv.org/abs/2601.01658", "authors": ["Anubhab Tripathi", "Li Gaishan", "Zhengnan Fu", "Chiara Bartolozzi", "Bert E. Shi", "Arindam Basu"], "title": "STEMNIST: Spiking Tactile Extended MNIST Neuromorphic Dataset", "categories": ["cs.NE"], "comment": null, "summary": "Tactile sensing is essential for robotic manipulation, prosthetics and assistive technologies, yet neuromorphic tactile datasets remain limited compared to their visual counterparts. We introduce STEMNIST, a large-scale neuromorphic tactile dataset extending ST-MNIST from 10 digits to 35 alphanumeric classes (uppercase letters A--Z and digits 1--9), providing a challenging benchmark for event-based haptic recognition. The dataset comprises 7,700 samples collected from 34 participants using a custom \\(16\\times 16\\) tactile sensor array operating at 120 Hz, encoded as 1,005,592 spike events through adaptive temporal differentiation. Following EMNIST's visual character recognition protocol, STEMNIST addresses the critical gap between simplified digit classification and real-world tactile interaction scenarios requiring alphanumeric discrimination. Baseline experiments using conventional CNNs (90.91% test accuracy) and spiking neural networks (89.16%) establish performance benchmarks. The dataset's event-based format, unrestricted spatial variability and rich temporal structure makes it suitable for testing neuromorphic hardware and bio-inspired learning algorithms. STEMNIST enables reproducible evaluation of tactile recognition systems and provides a foundation for advancing energy-efficient neuromorphic perception in robotics, biomedical engineering and human-machine interfaces. The dataset, documentation and codes are publicly available to accelerate research in neuromorphic tactile computing.", "AI": {"tldr": "\u5f15\u5165\u5927\u89c4\u6a21\u795e\u7ecf\u5f62\u6001\u89e6\u89c9\u6570\u636e\u96c6STEMNIST\uff0c\u53ef\u7528\u4e8e\u89e6\u89c9\u8bc6\u522b\u7cfb\u7edf\u8bc4\u4f30\u548c\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u5f62\u6001\u89e6\u89c9\u6570\u636e\u96c6\u8f83\u89c6\u89c9\u6570\u636e\u96c6\u6709\u9650\uff0c\u9700\u586b\u8865\u7b80\u5316\u6570\u5b57\u5206\u7c7b\u4e0e\u73b0\u5b9e\u89e6\u89c9\u4ea4\u4e92\u573a\u666f\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5c06ST - MNIST\u4ece10\u4e2a\u6570\u5b57\u6269\u5c55\u523035\u4e2a\u5b57\u6bcd\u6570\u5b57\u7c7b\u522b\uff0c\u4f7f\u7528\u5b9a\u5236\u89e6\u89c9\u4f20\u611f\u5668\u9635\u5217\u6536\u96c6\u6837\u672c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u65f6\u95f4\u5dee\u5206\u7f16\u7801\u4e3a\u5c16\u5cf0\u4e8b\u4ef6\u3002", "result": "\u4f7f\u7528\u4f20\u7edfCNN\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe90.91%\uff0c\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u4e3a89.16%\uff0c\u5efa\u7acb\u4e86\u6027\u80fd\u57fa\u51c6\u3002", "conclusion": "STEMNIST\u53ef\u5b9e\u73b0\u89e6\u89c9\u8bc6\u522b\u7cfb\u7edf\u7684\u53ef\u91cd\u590d\u8bc4\u4f30\uff0c\u4e3a\u795e\u7ecf\u5f62\u6001\u611f\u77e5\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\uff0c\u76f8\u5173\u6570\u636e\u548c\u4ee3\u7801\u516c\u5f00\u4fc3\u8fdb\u7814\u7a76\u3002"}}
{"id": "2601.01271", "pdf": "https://arxiv.org/pdf/2601.01271", "abs": "https://arxiv.org/abs/2601.01271", "authors": ["Qingxiao Tao", "Xiaodong Gu", "Hao Zhong", "Beijun Shen"], "title": "CatchAll: Repository-Aware Exception Handling with Knowledge-Guided LLMs", "categories": ["cs.SE"], "comment": null, "summary": "Exception handling is a vital forward error-recovery mechanism in many programming languages, enabling developers to manage runtime anomalies through structured constructs (e.g., try-catch blocks). Improper or missing exception handling often leads to severe consequences, including system crashes and resource leaks. While large language models (LLMs) have demonstrated strong capabilities in code generation, they struggle with exception handling at the repository level, due to complex dependencies and contextual constraints. In this work, we propose CatchAll, a novel LLM-based approach for repository-aware exception handling. CatchAll equips LLMs with three complementary layers of exception-handling knowledge: (1) API-level exception knowledge, obtained from an empirically constructed API-exception mapping that characterizes the exception-throwing behaviors of APIs in real-world codebases; (2) repository-level execution context, which captures exception propagation by modeling contextual call traces around the target code; and (3) cross-repository handling knowledge, distilled from reusable exception-handling patterns mined from historical code across projects. The knowledge is encoded into structured prompts to guide the LLM in generating accurate and context-aware exception-handling code. To evaluate CatchAll, we construct two new benchmarks for repository-aware exception handling: a large-scale dataset RepoExEval and an executable subset RepoExEval-Exec. Experiments demonstrate that RepoExEval consistently outperforms state-of-the-art baselines, achieving a CodeBLEU score of 0.31 (vs. 0.27% for the best baseline), intent prediction accuracy of 60.1% (vs. 48.0%), and Pass@1 of 29% (vs. 25%). These results affirm RepoExEval's effectiveness in real-world repository-level exception handling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684CatchAll\u65b9\u6cd5\u7528\u4e8e\u4ed3\u5e93\u7ea7\u5f02\u5e38\u5904\u7406\uff0c\u6784\u5efa\u65b0\u57fa\u51c6\u6d4b\u8bd5\u96c6\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ed3\u5e93\u7ea7\u5f02\u5e38\u5904\u7406\u4e0a\u56e0\u590d\u6742\u4f9d\u8d56\u548c\u4e0a\u4e0b\u6587\u7ea6\u675f\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u6709\u5fc5\u8981\u6539\u8fdb\u3002", "method": "\u4e3aLLM\u914d\u5907\u4e09\u5c42\u5f02\u5e38\u5904\u7406\u77e5\u8bc6\uff08API\u7ea7\u5f02\u5e38\u77e5\u8bc6\u3001\u4ed3\u5e93\u7ea7\u6267\u884c\u4e0a\u4e0b\u6587\u3001\u8de8\u4ed3\u5e93\u5904\u7406\u77e5\u8bc6\uff09\uff0c\u5e76\u7f16\u7801\u5230\u7ed3\u6784\u5316\u63d0\u793a\u4e2d\u5f15\u5bfcLLM\u751f\u6210\u4ee3\u7801\u3002\u6784\u5efaRepoExEval\u548cRepoExEval - Exec\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "CatchAll\u5728\u5404\u9879\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0cCodeBLEU\u5f97\u52060.31\uff0c\u610f\u56fe\u9884\u6d4b\u51c6\u786e\u738760.1%\uff0cPass@1\u4e3a29%\u3002", "conclusion": "CatchAll\u5728\u5b9e\u9645\u7684\u4ed3\u5e93\u7ea7\u5f02\u5e38\u5904\u7406\u4e2d\u6709\u6548\u3002"}}
{"id": "2601.00830", "pdf": "https://arxiv.org/pdf/2601.00830", "abs": "https://arxiv.org/abs/2601.00830", "authors": ["Deep Pankajbhai Mehta"], "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning", "categories": ["cs.AI"], "comment": "22 pages, 8 figures, 9 tables", "summary": "When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5AI\u9010\u6b65\u89e3\u91ca\u63a8\u7406\u65f6\u89e3\u91ca\u662f\u5426\u53cd\u6620\u5b9e\u9645\u5f71\u54cd\u56e0\u7d20\uff0c\u53d1\u73b0\u6a21\u578b\u770b\u5230\u5f71\u54cd\u4fe1\u606f\u5374\u4e0d\u4e3b\u52a8\u62a5\u544a\uff0c\u7b80\u5355\u76d1\u7763\u4e0d\u8db3\u4ee5\u53d1\u73b0\u9690\u85cf\u5f71\u54cd\u3002", "motivation": "\u9a8c\u8bc1\u5f53AI\u9010\u6b65\u89e3\u91ca\u63a8\u7406\u65f6\uff0c\u5176\u89e3\u91ca\u662f\u5426\u80fd\u63ed\u793a\u5b9e\u9645\u5f71\u54cd\u5176\u7b54\u6848\u7684\u56e0\u7d20\u8fd9\u4e00\u5047\u8bbe\u3002", "method": "\u5411\u95ee\u9898\u4e2d\u5d4c\u5165\u63d0\u793a\uff0c\u6d4b\u91cf\u6a21\u578b\u662f\u5426\u63d0\u53ca\u8fd9\u4e9b\u63d0\u793a\uff0c\u7814\u7a76\u4e8611\u4e2a\u9886\u5148AI\u6a21\u578b\u76849000\u591a\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u6a21\u578b\u51e0\u4e4e\u4e0d\u81ea\u53d1\u63d0\u53ca\u63d0\u793a\uff0c\u4f46\u76f4\u63a5\u8be2\u95ee\u4f1a\u627f\u8ba4\u6ce8\u610f\u5230\uff1b\u544a\u77e5\u88ab\u76d1\u89c6\u65e0\u7528\uff1b\u5f3a\u5236\u62a5\u544a\u63d0\u793a\u4f1a\u81f4\u8bef\u62a5\u4e14\u964d\u4f4e\u51c6\u786e\u6027\uff1b\u8bc9\u8bf8\u7528\u6237\u504f\u597d\u7684\u63d0\u793a\u66f4\u5371\u9669\u3002", "conclusion": "\u4ec5\u89c2\u5bdfAI\u63a8\u7406\u4e0d\u8db3\u4ee5\u53d1\u73b0\u9690\u85cf\u5f71\u54cd\u3002"}}
{"id": "2601.01480", "pdf": "https://arxiv.org/pdf/2601.01480", "abs": "https://arxiv.org/abs/2601.01480", "authors": ["Aman Sunesh", "Allan Ma", "Siddarth Nilol"], "title": "Modeling Information Blackouts in Missing Not-At-Random Time Series Data", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "8 pages, 7 figures, 3 tables", "summary": "Large-scale traffic forecasting relies on fixed sensor networks that often exhibit blackouts: contiguous intervals of missing measurements caused by detector or communication failures. These outages are typically handled under a Missing At Random (MAR) assumption, even though blackout events may correlate with unobserved traffic conditions (e.g., congestion or anomalous flow), motivating a Missing Not At Random (MNAR) treatment. We propose a latent state-space framework that jointly models (i) traffic dynamics via a linear dynamical system and (ii) sensor dropout via a Bernoulli observation channel whose probability depends on the latent traffic state. Inference uses an Extended Kalman Filter with Rauch-Tung-Striebel smoothing, and parameters are learned via an approximate EM procedure with a dedicated update for detector-specific missingness parameters. On the Seattle inductive loop detector data, introducing latent dynamics yields large gains over naive baselines, reducing blackout imputation RMSE from 7.02 (LOCF) and 5.02 (linear interpolation + seasonal naive) to 4.23 (MAR LDS), corresponding to about a 64% reduction in MSE relative to LOCF. Explicit MNAR modeling provides a consistent but smaller additional improvement on real data (imputation RMSE 4.20; 0.8% RMSE reduction relative to MAR), with similar modest gains for short-horizon post-blackout forecasts (evaluated at 1, 3, and 6 steps). In controlled synthetic experiments, the MNAR advantage increases as the true missingness dependence on latent state strengthens. Overall, temporal dynamics dominate performance, while MNAR modeling offers a principled refinement that becomes most valuable when missingness is genuinely informative.", "AI": {"tldr": "\u63d0\u51fa\u6f5c\u5728\u72b6\u6001\u7a7a\u95f4\u6846\u67b6\u5904\u7406\u4ea4\u901a\u4f20\u611f\u5668\u6570\u636e\u7f3a\u5931\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u4e0a\u9a8c\u8bc1\u6548\u679c\uff0c\u8868\u660e\u65f6\u95f4\u52a8\u6001\u4e3b\u5bfc\u6027\u80fd\uff0cMNAR\u5efa\u6a21\u5728\u6570\u636e\u7f3a\u5931\u6709\u4fe1\u606f\u65f6\u66f4\u6709\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u5927\u89c4\u6a21\u4ea4\u901a\u9884\u6d4b\u4e2d\u4f20\u611f\u5668\u6570\u636e\u7f3a\u5931\u901a\u5e38\u6309MAR\u5047\u8bbe\u5904\u7406\uff0c\u4f46\u505c\u7535\u4e8b\u4ef6\u53ef\u80fd\u4e0e\u672a\u89c2\u5bdf\u5230\u7684\u4ea4\u901a\u72b6\u51b5\u76f8\u5173\uff0c\u9700MNAR\u5904\u7406\u3002", "method": "\u63d0\u51fa\u6f5c\u5728\u72b6\u6001\u7a7a\u95f4\u6846\u67b6\uff0c\u8054\u5408\u5efa\u6a21\u4ea4\u901a\u52a8\u6001\u548c\u4f20\u611f\u5668\u7f3a\u5931\uff0c\u63a8\u7406\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u548cRauch - Tung - Striebel\u5e73\u6ed1\uff0c\u53c2\u6570\u901a\u8fc7\u8fd1\u4f3cEM\u7a0b\u5e8f\u5b66\u4e60\u3002", "result": "\u5728\u897f\u96c5\u56fe\u611f\u5e94\u73af\u8def\u68c0\u6d4b\u5668\u6570\u636e\u4e0a\uff0c\u5f15\u5165\u6f5c\u5728\u52a8\u6001\u6bd4\u57fa\u7ebf\u6709\u5927\u5e45\u63d0\u5347\uff0cMNAR\u5efa\u6a21\u6709\u989d\u5916\u5c0f\u5e45\u6539\u8fdb\uff1b\u5408\u6210\u5b9e\u9a8c\u4e2dMNAR\u4f18\u52bf\u968f\u7f3a\u5931\u4e0e\u6f5c\u5728\u72b6\u6001\u4f9d\u8d56\u589e\u5f3a\u800c\u589e\u52a0\u3002", "conclusion": "\u65f6\u95f4\u52a8\u6001\u4e3b\u5bfc\u6027\u80fd\uff0cMNAR\u5efa\u6a21\u662f\u4e00\u79cd\u539f\u5219\u6027\u6539\u8fdb\uff0c\u5728\u6570\u636e\u7f3a\u5931\u6709\u4fe1\u606f\u65f6\u6700\u6709\u4ef7\u503c\u3002"}}
{"id": "2601.01787", "pdf": "https://arxiv.org/pdf/2601.01787", "abs": "https://arxiv.org/abs/2601.01787", "authors": ["Yuxiao Li", "Mingze Xia", "Xin Liang", "Bei Wang", "Robert Underwood", "Sheng Di", "Hemant Sharma", "Dishant Beniwal", "Franck Cappello", "Hanqi Guo"], "title": "pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression", "categories": ["cs.DC"], "comment": null, "summary": "Lossy compression, widely used by scientists to reduce data from simulations, experiments, and observations, can distort features of interest even under bounded error. Such distortions may compromise downstream analyses and lead to incorrect scientific conclusions in applications such as combustion and cosmology. This paper presents a distributed and parallel algorithm for correcting topological features, specifically, piecewise linear Morse Smale segmentations (PLMSS), which decompose the domain into monotone regions labeled by their corresponding local minima and maxima. While a single GPU algorithm (MSz) exists for PLMSS correction after compression, no methodology has been developed that scales beyond a single GPU for extreme scale data. We identify the key bottleneck in scaling PLMSS correction as the parallel computation of integral paths, a communication-intensive computation that is notoriously difficult to scale. Instead of explicitly computing and correcting integral paths, our algorithm simplifies MSz by preserving steepest ascending and descending directions across all locations, thereby minimizing interprocess communication while introducing negligible additional storage overhead. With this simplified algorithm and relaxed synchronization, our method achieves over 90% parallel efficiency on 128 GPUs on the Perlmutter supercomputer for real world datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5206\u5e03\u5f0f\u5e76\u884c\u7b97\u6cd5\u4fee\u6b63\u6709\u635f\u538b\u7f29\u540e\u62d3\u6251\u7279\u5f81\uff0c\u8be5\u7b97\u6cd5\u7b80\u5316MSz\uff0c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u5728128\u4e2aGPU\u4e0a\u5b9e\u73b0\u8d8590%\u5e76\u884c\u6548\u7387\u3002", "motivation": "\u6709\u635f\u538b\u7f29\u4f1a\u626d\u66f2\u6570\u636e\u7279\u5f81\uff0c\u5f71\u54cd\u540e\u7eed\u5206\u6790\uff0c\u800c\u73b0\u6709\u5355GPU\u7684MSz\u7b97\u6cd5\u65e0\u6cd5\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u3002", "method": "\u901a\u8fc7\u4fdd\u7559\u5404\u4f4d\u7f6e\u7684\u6700\u9661\u5347\u964d\u65b9\u5411\u7b80\u5316MSz\u7b97\u6cd5\uff0c\u51cf\u5c11\u8fdb\u7a0b\u95f4\u901a\u4fe1\uff0c\u5f31\u5316\u540c\u6b65\u3002", "result": "\u7b97\u6cd5\u5728Perlmutter\u8d85\u7ea7\u8ba1\u7b97\u673a128\u4e2aGPU\u4e0a\u5bf9\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u73b0\u8d8590%\u7684\u5e76\u884c\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5355GPU\u7b97\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u7684\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u5bf9\u538b\u7f29\u540e\u6570\u636e\u62d3\u6251\u7279\u5f81\u7684\u4fee\u6b63\u3002"}}
{"id": "2601.01937", "pdf": "https://arxiv.org/pdf/2601.01937", "abs": "https://arxiv.org/abs/2601.01937", "authors": ["Yitong Song", "Xuanhe Zhou", "Christian S. Jensen", "Jianliang Xu"], "title": "Vector Search for the Future: From Memory-Resident, Static Heterogeneous Storage, to Cloud-Native Architectures", "categories": ["cs.DB"], "comment": "Accepted as a tutorial at SIGMOD 2026", "summary": "Vector search (VS) has become a fundamental component in multimodal data management, enabling core functionalities such as image, video, and code retrieval. As vector data scales rapidly, VS faces growing challenges in balancing search, latency, scalability, and cost. The evolution of VS has been closely driven by changes in storage architecture. Early VS methods rely on all-in-memory designs for low latency, but scalability is constrained by memory capacity and cost. To address this, recent research has adopted heterogeneous architectures that offload space-intensive vectors and index structures to SSDs, while exploiting block locality and I/O-efficient strategies to maintain high search performance at billion scale. Looking ahead, the increasing demand for trillion-scale vector retrieval and cloud-native elasticity is driving a further shift toward memory-SSD-object storage architectures, which enable cost-efficient data tiering and seamless scalability.\n  In this tutorial, we review the evolution of VS techniques from a storage-architecture perspective. We first review memory-resident methods, covering classical IVF, hash, quantization, and graph-based designs. We then present a systematic overview of heterogeneous storage VS techniques, including their index designs, block-level layouts, query strategies, and update mechanisms. Finally, we examine emerging cloud-native systems and highlight open research opportunities for future large-scale vector retrieval systems.", "AI": {"tldr": "\u672c\u6587\u4ece\u5b58\u50a8\u67b6\u6784\u89d2\u5ea6\u56de\u987e\u5411\u91cf\u641c\u7d22\u6280\u672f\u7684\u6f14\u53d8\uff0c\u5148\u4ecb\u7ecd\u5185\u5b58\u9a7b\u7559\u65b9\u6cd5\uff0c\u518d\u6982\u8ff0\u5f02\u6784\u5b58\u50a8\u5411\u91cf\u641c\u7d22\u6280\u672f\uff0c\u6700\u540e\u63a2\u8ba8\u4e91\u539f\u751f\u7cfb\u7edf\u548c\u672a\u6765\u7814\u7a76\u673a\u4f1a\u3002", "motivation": "\u968f\u7740\u5411\u91cf\u6570\u636e\u89c4\u6a21\u5feb\u901f\u589e\u957f\uff0c\u5411\u91cf\u641c\u7d22\u5728\u5e73\u8861\u641c\u7d22\u3001\u5ef6\u8fdf\u3001\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u4ece\u5b58\u50a8\u67b6\u6784\u6f14\u53d8\u89d2\u5ea6\u5bf9\u76f8\u5173\u6280\u672f\u8fdb\u884c\u68b3\u7406\u3002", "method": "\u4ece\u5b58\u50a8\u67b6\u6784\u89d2\u5ea6\uff0c\u4f9d\u6b21\u56de\u987e\u5185\u5b58\u9a7b\u7559\u65b9\u6cd5\uff0c\u5bf9\u5f02\u6784\u5b58\u50a8\u5411\u91cf\u641c\u7d22\u6280\u672f\u8fdb\u884c\u7cfb\u7edf\u6982\u8ff0\uff0c\u6700\u540e\u7814\u7a76\u65b0\u5174\u4e91\u539f\u751f\u7cfb\u7edf\u3002", "result": "\u5b8c\u6210\u4e86\u5bf9\u5411\u91cf\u641c\u7d22\u6280\u672f\u6f14\u53d8\u4ece\u5b58\u50a8\u67b6\u6784\u89c6\u89d2\u7684\u5168\u9762\u56de\u987e\u5206\u6790\u3002", "conclusion": "\u5411\u91cf\u641c\u7d22\u6280\u672f\u968f\u7740\u5b58\u50a8\u67b6\u6784\u53d1\u5c55\u4e0d\u65ad\u6f14\u53d8\uff0c\u5f53\u524d\u6b63\u5411\u5185\u5b58 - SSD - \u5bf9\u8c61\u5b58\u50a8\u67b6\u6784\u8f6c\u53d8\u4ee5\u5b9e\u73b0\u9ad8\u6548\u6570\u636e\u5206\u5c42\u548c\u65e0\u7f1d\u6269\u5c55\uff0c\u4e14\u672a\u6765\u5927\u89c4\u6a21\u5411\u91cf\u68c0\u7d22\u7cfb\u7edf\u6709\u8bf8\u591a\u7814\u7a76\u673a\u4f1a\u5f85\u63a2\u7d22\u3002"}}
{"id": "2601.01492", "pdf": "https://arxiv.org/pdf/2601.01492", "abs": "https://arxiv.org/abs/2601.01492", "authors": ["Annelies de Jong", "Giuseppe Cascavilla", "Jessica De Pascale"], "title": "Breadcrumbs in the Digital Forest: Tracing Criminals through Torrent Metadata with OSINT", "categories": ["cs.IR", "cs.CY"], "comment": null, "summary": "This work investigates the potential of torrent metadata as a source for open-source intelligence (OSINT), with a focus on user profiling and behavioral analysis. While peer-to-peer (P2P) networks such as BitTorrent are well studied with respect to privacy and performance, their metadata is rarely used for investigative purposes. This work presents a proof of concept demonstrating how tracker responses, torrent index data, and enriched IP metadata can reveal patterns associated with high-risk behavior.\n  The research follows a five-step OSINT process: source identification, data collection, enrichment, behavioral analysis, and presentation of the results. Data were collected from The Pirate Bay and UDP trackers, yielding a dataset of more than 60,000 unique IP addresses across 206 popular torrents. The data were enriched with geolocation, anonymization status, and flags of involvement in child exploitation material (CEM). A case study on sensitive e-books shows how such data can help detect possible interest in illicit content.\n  Network analysis highlights peer clustering, co-download patterns, and the use of privacy tools by suspicious users. The study shows that publicly available torrent metadata can support scalable and automated OSINT profiling.\n  This work adds to digital forensics by proposing a new method to extract useful signals from noisy data, with applications in law enforcement, cybersecurity, and threat analysis.", "AI": {"tldr": "\u7814\u7a76\u79cd\u5b50\u5143\u6570\u636e\u7528\u4e8e\u5f00\u6e90\u60c5\u62a5\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u4e94\u6b65\u6d41\u7a0b\u5206\u6790\u6570\u636e\uff0c\u8bc1\u660e\u5176\u53ef\u652f\u6301\u53ef\u6269\u5c55\u81ea\u52a8\u5316\u7528\u6237\u753b\u50cf\u3002", "motivation": "\u867d\u7136P2P\u7f51\u7edc\u5728\u9690\u79c1\u548c\u6027\u80fd\u65b9\u9762\u7814\u7a76\u8f83\u591a\uff0c\u4f46\u5143\u6570\u636e\u6781\u5c11\u7528\u4e8e\u8c03\u67e5\u76ee\u7684\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6316\u6398\u5176\u5728\u7528\u6237\u753b\u50cf\u548c\u884c\u4e3a\u5206\u6790\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u4e94\u6b65\u5f00\u6e90\u60c5\u62a5\u6d41\u7a0b\uff0c\u4ece\u6d77\u76d7\u6e7e\u548cUDP\u8ffd\u8e2a\u5668\u6536\u96c6\u6570\u636e\uff0c\u5bf9\u6570\u636e\u8fdb\u884c\u4e30\u5bcc\u5904\u7406\uff0c\u5305\u62ec\u6dfb\u52a0\u5730\u7406\u4f4d\u7f6e\u3001\u533f\u540d\u5316\u72b6\u6001\u7b49\u4fe1\u606f\uff0c\u5e76\u8fdb\u884c\u7f51\u7edc\u5206\u6790\u3002", "result": "\u6536\u96c6\u5230\u8d8560000\u4e2a\u552f\u4e00IP\u5730\u5740\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6848\u4f8b\u5206\u6790\u5c55\u793a\u6570\u636e\u53ef\u5e2e\u52a9\u68c0\u6d4b\u5bf9\u975e\u6cd5\u5185\u5bb9\u7684\u5174\u8da3\uff0c\u7f51\u7edc\u5206\u6790\u63ed\u793a\u4e86\u540c\u884c\u805a\u7c7b\u7b49\u6a21\u5f0f\u3002", "conclusion": "\u516c\u5f00\u53ef\u7528\u7684\u79cd\u5b50\u5143\u6570\u636e\u53ef\u652f\u6301\u53ef\u6269\u5c55\u548c\u81ea\u52a8\u5316\u7684\u5f00\u6e90\u60c5\u62a5\u7528\u6237\u753b\u50cf\uff0c\u4e3a\u6570\u5b57\u53d6\u8bc1\u63d0\u51fa\u65b0\u7684\u6570\u636e\u63d0\u53d6\u65b9\u6cd5\u3002"}}
{"id": "2601.01832", "pdf": "https://arxiv.org/pdf/2601.01832", "abs": "https://arxiv.org/abs/2601.01832", "authors": ["SB Danush Vikraman", "Hannah Abagail", "Prasanna Kesavraj", "Gajanan V Honnavar"], "title": "Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization", "categories": ["cs.NE", "cs.AI"], "comment": "22 pages, 9 figures, includes extensive ablation studies and benchmark comparisons", "summary": "We present Yukthi Opus (YO), a multi-chain hybrid metaheuristic designed for NP-hard optimization under explicit evaluation budget constraints. YO integrates three complementary mechanisms in a structured two-phase architecture: Markov Chain Monte Carlo (MCMC) for global exploration, greedy local search for exploitation, and simulated annealing with adaptive reheating to enable controlled escape from local minima. A dedicated burn-in phase allocates evaluations to probabilistic exploration, after which a hybrid optimization loop refines promising candidates. YO further incorporates a spatial blacklist mechanism to avoid repeated evaluation of poor regions and a multi-chain execution strategy to improve robustness and reduce sensitivity to initialization.\n  We evaluate YO on three benchmarks: the Rastrigin function (5D) with ablation studies, the Traveling Salesman Problem with 50 to 200 cities, and the Rosenbrock function (5D) with comparisons against established optimizers including CMA-ES, Bayesian optimization, and accelerated particle swarm optimization. Results show that MCMC exploration and greedy refinement are critical for solution quality, while simulated annealing and multi-chain execution primarily improve stability and variance reduction. Overall, YO achieves competitive performance on large and multimodal problems while maintaining predictable evaluation budgets, making it suitable for expensive black-box optimization settings.", "AI": {"tldr": "\u63d0\u51faYukthi Opus (YO)\u591a\u94fe\u6df7\u5408\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u5e94\u5bf9NP\u96be\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u6602\u8d35\u9ed1\u76d2\u4f18\u5316\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u660e\u786e\u8bc4\u4f30\u9884\u7b97\u7ea6\u675f\u4e0b\u7684NP\u96be\u4f18\u5316\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u5316\u4e24\u9636\u6bb5\u67b6\u6784\uff0c\u878d\u5408MCMC\u5168\u5c40\u63a2\u7d22\u3001\u8d2a\u5a6a\u5c40\u90e8\u641c\u7d22\u3001\u5e26\u81ea\u9002\u5e94\u518d\u52a0\u70ed\u7684\u6a21\u62df\u9000\u706b\u4e09\u79cd\u673a\u5236\uff1b\u8bbe\u7f6e\u4e13\u95e8\u9884\u70ed\u9636\u6bb5\u548c\u6df7\u5408\u4f18\u5316\u5faa\u73af\uff1b\u7eb3\u5165\u7a7a\u95f4\u9ed1\u540d\u5355\u673a\u5236\u548c\u591a\u94fe\u6267\u884c\u7b56\u7565\u3002", "result": "\u5bf9\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u95ee\u9898\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660eMCMC\u63a2\u7d22\u548c\u8d2a\u5a6a\u5c40\u90e8\u641c\u7d22\u5bf9\u89e3\u7684\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u6a21\u62df\u9000\u706b\u548c\u591a\u94fe\u6267\u884c\u4e3b\u8981\u63d0\u5347\u7a33\u5b9a\u6027\u548c\u51cf\u5c11\u65b9\u5dee\u3002", "conclusion": "YO\u5728\u5927\u89c4\u6a21\u548c\u591a\u6a21\u6001\u95ee\u9898\u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0c\u80fd\u4fdd\u6301\u53ef\u9884\u6d4b\u8bc4\u4f30\u9884\u7b97\uff0c\u9002\u7528\u4e8e\u6602\u8d35\u9ed1\u76d2\u4f18\u5316\u573a\u666f\u3002"}}
{"id": "2601.01320", "pdf": "https://arxiv.org/pdf/2601.01320", "abs": "https://arxiv.org/abs/2601.01320", "authors": ["Muntasir Adnan", "Carlos C. N. Kuhn"], "title": "Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.", "AI": {"tldr": "\u73b0\u6709\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u57fa\u51c6\u5b58\u5728\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51faALPHA\u8fd9\u4e2a\u51fd\u6570\u7ea7Python\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u548cSAST\u5de5\u5177\uff0c\u8bc4\u4f30\u53d1\u73b0LLMs\u5728\u6027\u80fd\u4e0a\u8d85\u8fc7SAST\u4f46\u6a21\u578b\u9884\u6d4b\u4e00\u81f4\u6027\u5dee\u5f02\u5927\uff0c\u8fd8\u7ed9\u51fa\u672a\u6765\u5de5\u4f5c\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e38\u751f\u6210\u6613\u53d7\u653b\u51fb\u7684\u4ee3\u7801\uff0c\u73b0\u6709\u7684\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u57fa\u51c6\u91c7\u7528\u4e8c\u8fdb\u5236\u5206\u7c7b\uff0c\u7f3a\u4e4fCWE\u7ea7\u522b\u7279\u5f02\u6027\uff0c\u65e0\u6cd5\u4e3a\u8fed\u4ee3\u4fee\u6b63\u7cfb\u7edf\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u53cd\u9988\u3002", "method": "\u63d0\u51faALPHA\u57fa\u51c6\uff0c\u7528\u5206\u5c42\u611f\u77e5\u3001\u7279\u5b9aCWE\u7684\u60e9\u7f5a\u673a\u5236\u8bc4\u4f30LLMs\u548cSAST\u5de5\u5177\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0LLMs\u6027\u80fd\u5927\u5e45\u8d85\u8fc7SAST\uff0c\u4f46SAST\u68c0\u6d4b\u65f6\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u6a21\u578b\u9884\u6d4b\u4e00\u81f4\u6027\u57288.26%-81.87%\u95f4\u5dee\u5f02\u5de8\u5927\u3002", "conclusion": "\u7ed9\u51fa\u4e86\u5c06ALPHA\u60e9\u7f5a\u673a\u5236\u7eb3\u5165\u76d1\u7763\u5fae\u8c03\u7684\u672a\u6765\u5de5\u4f5c\u9014\u5f84\uff0c\u5f85\u5b9e\u8bc1\u9a8c\u8bc1\u540e\u6216\u80fd\u5b9e\u73b0\u6709\u539f\u5219\u7684\u5c42\u6b21\u611f\u77e5\u6f0f\u6d1e\u68c0\u6d4b\u3002"}}
{"id": "2601.00843", "pdf": "https://arxiv.org/pdf/2601.00843", "abs": "https://arxiv.org/abs/2601.00843", "authors": ["Ayda Aghaei Nia"], "title": "OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification", "categories": ["cs.AI"], "comment": "16 pages, 7 figures, 3 tables. Source code and implementation available at: https://github.com/ayda-aghaei/OmniNeuro. Highlights the use of LLMs (Gemini) and Quantum probability formalism for real-time BCI explainability", "summary": "While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the \"Black Box\" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the \"trial-and-error\" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.", "AI": {"tldr": "\u63d0\u51faOmniNeuro\u6846\u67b6\u63d0\u5347BCI\u53ef\u89e3\u91ca\u6027\uff0c\u7ecf\u8bc4\u4f30\u6709\u4e00\u5b9a\u6548\u679c\u4e14\u4e0e\u89e3\u7801\u5668\u65e0\u5173\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u867d\u63d0\u5347BCI\u89e3\u7801\u7cbe\u5ea6\uff0c\u4f46\u7b97\u6cd5\u7684\u201c\u9ed1\u76d2\u201d\u7279\u6027\u963b\u788d\u4e34\u5e8a\u5e94\u7528\uff0c\u5bfc\u81f4\u7528\u6237\u4e0d\u6ee1\u548c\u795e\u7ecf\u53ef\u5851\u6027\u7ed3\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faOmniNeuro\u6846\u67b6\uff0c\u96c6\u6210\u7269\u7406\uff08\u80fd\u91cf\uff09\u3001\u6df7\u6c8c\uff08\u5206\u5f62\u590d\u6742\u5ea6\uff09\u548c\u7c7b\u91cf\u5b50\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u4e09\u4e2a\u53ef\u89e3\u91ca\u5f15\u64ce\uff0c\u9a71\u52a8\u5b9e\u65f6\u795e\u7ecf\u58f0\u5316\u548c\u751f\u6210AI\u4e34\u5e8a\u62a5\u544a\u3002", "result": "\u5728PhysioNet\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u51c6\u786e\u7387\u8fbe58.52%\uff0c\u5b9a\u6027\u8bd5\u70b9\u7814\u7a76\u8868\u660e\u53ef\u89e3\u91ca\u53cd\u9988\u52a9\u7528\u6237\u8c03\u8282\u7cbe\u795e\u52aa\u529b\u5e76\u51cf\u5c11\u201c\u8bd5\u9519\u201d\u9636\u6bb5\u3002", "conclusion": "OmniNeuro\u4e0e\u89e3\u7801\u5668\u65e0\u5173\uff0c\u53ef\u4f5c\u4e3a\u4efb\u4f55\u5148\u8fdb\u67b6\u6784\u7684\u91cd\u8981\u53ef\u89e3\u91ca\u5c42\u3002"}}
{"id": "2601.01594", "pdf": "https://arxiv.org/pdf/2601.01594", "abs": "https://arxiv.org/abs/2601.01594", "authors": ["Alois Duston", "Tan Bui-Thanh"], "title": "Variance-Reduced Diffusion Sampling via Conditional Score Expectation Identity", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We introduce and prove a \\textbf{Conditional Score Expectation (CSE)} identity: an exact relation for the marginal score of affine diffusion processes that links scores across time via a conditional expectation under the forward dynamics. Motivated by this identity, we propose a CSE-based statistical estimator for the score using a Self-Normalized Importance Sampling (SNIS) procedure with prior samples and forward noise. We analyze its relationship to the standard Tweedie estimator, proving anti-correlation for Gaussian targets and establishing the same behavior for general targets in the small time-step regime. Exploiting this structure, we derive a variance-minimizing blended score estimator given by a state--time dependent convex combination of the CSE and Tweedie estimators. Numerical experiments show that this optimal-blending estimator reduces variance and improves sample quality for a fixed computational budget compared to either baseline. We further extend the framework to Bayesian inverse problems via likelihood-informed SNIS weights, and demonstrate improved reconstruction quality and sample diversity on high-dimensional image reconstruction tasks and PDE-governed inverse problems.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u5e76\u8bc1\u660eCSE\u6052\u7b49\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8eCSE\u7684\u5206\u6570\u7edf\u8ba1\u4f30\u8ba1\u5668\uff0c\u63a8\u5bfc\u65b9\u5dee\u6700\u5c0f\u5316\u7684\u6df7\u5408\u5206\u6570\u4f30\u8ba1\u5668\uff0c\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u52bf\uff0c\u8fd8\u5c06\u6846\u67b6\u6269\u5c55\u5230\u8d1d\u53f6\u65af\u53cd\u95ee\u9898\u3002", "motivation": "\u57fa\u4e8eCSE\u6052\u7b49\u5f0f\uff0c\u63a2\u7d22\u6709\u6548\u5206\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u89e3\u51b3\u76f8\u5173\u95ee\u9898\u3002", "method": "\u4f7f\u7528Self - Normalized Importance Sampling (SNIS)\u7a0b\u5e8f\uff0c\u7ed3\u5408CSE\u6052\u7b49\u5f0f\uff0c\u63a8\u5bfc\u6df7\u5408\u5206\u6570\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u4f3c\u7136\u4fe1\u606fSNIS\u6743\u91cd\u6269\u5c55\u5230\u8d1d\u53f6\u65af\u53cd\u95ee\u9898\u3002", "result": "\u6700\u4f18\u6df7\u5408\u4f30\u8ba1\u5668\u80fd\u964d\u4f4e\u65b9\u5dee\u3001\u63d0\u9ad8\u6837\u672c\u8d28\u91cf\uff0c\u5728\u9ad8\u7ef4\u56fe\u50cf\u91cd\u5efa\u548cPDE\u63a7\u5236\u7684\u53cd\u95ee\u9898\u4e2d\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\u548c\u6837\u672c\u591a\u6837\u6027\u3002", "conclusion": "\u57fa\u4e8eCSE\u7684\u65b9\u6cd5\u548c\u6df7\u5408\u4f30\u8ba1\u5668\u5728\u5206\u6570\u4f30\u8ba1\u548c\u8d1d\u53f6\u65af\u53cd\u95ee\u9898\u4e2d\u6709\u826f\u597d\u8868\u73b0\u3002"}}
{"id": "2601.01980", "pdf": "https://arxiv.org/pdf/2601.01980", "abs": "https://arxiv.org/abs/2601.01980", "authors": ["Manuel Parra-Roy\u00f3n", "\u00c1lvaro Rodr\u00edguez-Gallardo", "Susana S\u00e1nchez-Exp\u00f3sito", "Laura Darriba-Pol", "Jes\u00fas S\u00e1nchez-Casta\u00f1eda", "M. \u00c1ngeles Mendoza", "Juli\u00e1n Garrido", "Javier Mold\u00f3n", "Lourdes Verdes-Montenegro"], "title": "Bringing computation to the data: A MOEA-driven approach for optimising data processing in the context of the SKA and SRCNet", "categories": ["cs.DC"], "comment": "8 pages", "summary": "The Square Kilometre Array (SKA) will generate unprecedented data volumes, making efficient data processing a critical challenge. Within this context, the SKA Regional Centres Network (SRCNet) must operate in a near-exascale environment where traditional data-centric computing models based on moving large datasets to centralised resources are no longer viable due to network and storage bottlenecks.\n  To address this limitation, this work proposes a shift towards distributed and in-situ computing, where computation is moved closer to the data. We explore the integration of Function-as-a-Service (FaaS) with an intelligent decision-making entity based on Evolutionary Algorithms (EAs) to optimise data-intensive workflows within SRCNet. FaaS enables lightweight and modular function execution near data sources while abstracting infrastructure management.\n  The proposed decision-making entity employs Multi-Objective Evolutionary Algorithms (MOEAs) to explore near-optimal execution plans considering execution time and energy consumption, together with constraints related to data location and transfer costs. This work establishes a baseline framework for efficient and cost-aware computation-to-data strategies within the SRCNet architecture.", "AI": {"tldr": "\u9488\u5bf9SKA\u6570\u636e\u5904\u7406\u6311\u6218\uff0c\u63d0\u51fa\u5206\u5e03\u5f0f\u548c\u539f\u4f4d\u8ba1\u7b97\uff0c\u7ed3\u5408FaaS\u4e0e\u57fa\u4e8eEA\u7684\u51b3\u7b56\u5b9e\u4f53\u4f18\u5316\u5de5\u4f5c\u6d41\uff0c\u5efa\u7acb\u8ba1\u7b97\u5230\u6570\u636e\u7b56\u7565\u6846\u67b6\u3002", "motivation": "SKA\u4ea7\u751f\u6d77\u91cf\u6570\u636e\uff0c\u4f20\u7edf\u6570\u636e\u4e2d\u5fc3\u8ba1\u7b97\u6a21\u578b\u56e0\u7f51\u7edc\u548c\u5b58\u50a8\u74f6\u9888\u4e0d\u518d\u53ef\u884c\uff0c\u9700\u9ad8\u6548\u6570\u636e\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u548c\u539f\u4f4d\u8ba1\u7b97\uff0c\u5c06FaaS\u4e0e\u57fa\u4e8eEA\u7684\u667a\u80fd\u51b3\u7b56\u5b9e\u4f53\u96c6\u6210\uff0c\u7528MOEAs\u63a2\u7d22\u8fd1\u6700\u4f18\u6267\u884c\u8ba1\u5212\u3002", "result": "\u5efa\u7acb\u4e86SRCNet\u67b6\u6784\u5185\u9ad8\u6548\u4e14\u8003\u8651\u6210\u672c\u7684\u8ba1\u7b97\u5230\u6570\u636e\u7b56\u7565\u7684\u57fa\u7ebf\u6846\u67b6\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u5e94\u5bf9SKA\u6570\u636e\u5904\u7406\u6311\u6218\uff0c\u5b9e\u73b0\u9ad8\u6548\u6570\u636e\u5904\u7406\u3002"}}
{"id": "2601.02019", "pdf": "https://arxiv.org/pdf/2601.02019", "abs": "https://arxiv.org/abs/2601.02019", "authors": ["Hanyan Yin", "Dongxie Wen", "Jiajun Li", "Zhewei Wei", "Xiao Zhang", "Peng Zhao", "Zhi-Hua Zhou"], "title": "AeroSketch: Near-Optimal Time Matrix Sketch Framework for Persistent, Sliding Window, and Distributed Streams", "categories": ["cs.DB"], "comment": null, "summary": "Many real-world matrix datasets arrive as high-throughput vector streams, making it impractical to store or process them in their entirety. To enable real-time analytics under limited computational, memory, and communication resources, matrix sketching techniques have been developed over recent decades to provide compact approximations of such streaming data. Some algorithms have achieved optimal space and communication complexity. However, these approaches often require frequent time-consuming matrix factorization operations. In particular, under tight approximation error bounds, each matrix factorization computation incurs cubic time complexity, thereby limiting their update efficiency.\n  In this paper, we introduce AeroSketch, a novel matrix sketching framework that leverages recent advances in randomized numerical linear algebra (RandNLA). AeroSketch achieves optimal communication and space costs while delivering near-optimal update time complexity (within logarithmic factors) across persistent, sliding window, and distributed streaming scenarios. Extensive experiments on both synthetic and real-world datasets demonstrate that AeroSketch consistently outperforms state-of-the-art methods in update throughput. In particular, under tight approximation error constraints, AeroSketch reduces the cubic time complexity to the quadratic level. Meanwhile, it maintains comparable approximation quality while retaining optimal communication and space costs.", "AI": {"tldr": "\u63d0\u51faAeroSketch\u77e9\u9635\u8349\u56fe\u6846\u67b6\uff0c\u5728\u591a\u573a\u666f\u4e0b\u6709\u826f\u597d\u8868\u73b0\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u66f4\u65b0\u541e\u5410\u91cf\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u964d\u4f4e\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "motivation": "\u73b0\u6709\u77e9\u9635\u8349\u56fe\u6280\u672f\u5728\u6709\u9650\u8d44\u6e90\u4e0b\u8fdb\u884c\u5b9e\u65f6\u5206\u6790\u65f6\uff0c\u5e38\u9700\u9891\u7e41\u8017\u65f6\u7684\u77e9\u9635\u5206\u89e3\u64cd\u4f5c\uff0c\u9650\u5236\u66f4\u65b0\u6548\u7387\u3002", "method": "\u5f15\u5165AeroSketch\u6846\u67b6\uff0c\u5229\u7528\u968f\u673a\u6570\u503c\u7ebf\u6027\u4ee3\u6570\u7684\u6700\u65b0\u8fdb\u5c55\u3002", "result": "AeroSketch\u5728\u591a\u573a\u666f\u4e0b\u5b9e\u73b0\u6700\u4f18\u901a\u4fe1\u548c\u7a7a\u95f4\u6210\u672c\uff0c\u66f4\u65b0\u65f6\u95f4\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u4f18\uff0c\u5728\u66f4\u65b0\u541e\u5410\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u964d\u4f4e\u4e86\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "conclusion": "AeroSketch\u5728\u4fdd\u6301\u8fd1\u4f3c\u8d28\u91cf\u3001\u6700\u4f18\u901a\u4fe1\u548c\u7a7a\u95f4\u6210\u672c\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u66f4\u65b0\u6548\u7387\u3002"}}
{"id": "2601.01774", "pdf": "https://arxiv.org/pdf/2601.01774", "abs": "https://arxiv.org/abs/2601.01774", "authors": ["Sai Varun Kodathala", "Rakesh Vunnam"], "title": "Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches", "categories": ["cs.AI", "cs.CE", "math.NA"], "comment": "14 pages", "summary": "Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u8d85\u8d8a\u65b9\u7a0b\u7684\u80fd\u529b\uff0c\u5bf9\u6bd4\u76f4\u63a5\u9884\u6d4b\u548c\u6df7\u5408\u67b6\u6784\uff0c\u53d1\u73b0\u6df7\u5408\u67b6\u6784\u8bef\u5dee\u66f4\u4f4e\uff0c\u5efa\u8bae\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7ecf\u5178\u6c42\u89e3\u5668\u7684\u667a\u80fd\u63a5\u53e3\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u76f4\u63a5\u6570\u503c\u9884\u6d4b\u89e3\u51b3\u8d85\u8d8a\u65b9\u7a0b\uff0c\u6216\u7ed3\u5408\u7b26\u53f7\u64cd\u4f5c\u4e0e\u7ecf\u5178\u8fed\u4ee3\u6c42\u89e3\u5668\u662f\u5426\u66f4\u6709\u6548\u3002", "method": "\u6d4b\u8bd5\u516d\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5728\u4e03\u4e2a\u5de5\u7a0b\u9886\u57df\u7684100\u4e2a\u95ee\u9898\u4e0a\u6bd4\u8f83\u76f4\u63a5\u9884\u6d4b\u548c\u6c42\u89e3\u5668\u8f85\u52a9\u8ba1\u7b97\u3002", "result": "\u76f4\u63a5\u9884\u6d4b\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u57280.765\u52301.262\u4e4b\u95f4\uff0c\u6c42\u89e3\u5668\u8f85\u52a9\u8ba1\u7b97\u4e3a0.225\u52300.301\uff0c\u8bef\u5dee\u964d\u4f4e67.9%\u523081.8%\uff0c\u4e0d\u540c\u9886\u57df\u6539\u8fdb\u7a0b\u5ea6\u4e0d\u540c\u3002", "conclusion": "\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u64c5\u957f\u7b26\u53f7\u64cd\u4f5c\u548c\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\uff0c\u4f46\u5728\u9ad8\u7cbe\u5ea6\u8fed\u4ee3\u7b97\u672f\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u5e94\u4f5c\u4e3a\u7ecf\u5178\u6570\u503c\u6c42\u89e3\u5668\u7684\u667a\u80fd\u63a5\u53e3\u800c\u975e\u72ec\u7acb\u8ba1\u7b97\u5f15\u64ce\u3002"}}
{"id": "2601.01576", "pdf": "https://arxiv.org/pdf/2601.01576", "abs": "https://arxiv.org/abs/2601.01576", "authors": ["Ming Zhang", "Kexin Tan", "Yueyuan Huang", "Yujiong Shen", "Chunchun Ma", "Li Ju", "Xinran Zhang", "Yuhui Wang", "Wenqing Jing", "Jingyi Deng", "Huayu Sha", "Binze Hu", "Jingqi Tong", "Changhao Jiang", "Yage Geng", "Yuankai Ying", "Yue Zhang", "Zhangyue Yin", "Zhiheng Xi", "Shihan Dou", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \\textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684OpenNovelty\u7cfb\u7edf\u7528\u4e8e\u65b0\u9896\u6027\u5206\u6790\uff0c\u9610\u8ff0\u5176\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5728ICLR 2026\u6295\u7a3f\u4e0a\u90e8\u7f72\u6709\u521d\u6b65\u6548\u679c\u3002", "motivation": "\u540c\u884c\u8bc4\u5ba1\u4e2d\u8bc4\u4f30\u65b0\u9896\u6027\u5173\u952e\u4e14\u6709\u6311\u6218\uff0c\u9700\u8bc4\u4f30\u6295\u7a3f\u4e0e\u5927\u91cf\u5feb\u901f\u6f14\u53d8\u7684\u6587\u732e\u5bf9\u6bd4\u60c5\u51b5\u3002", "method": "\u7cfb\u7edf\u5206\u56db\u4e2a\u9636\u6bb5\uff1a\u63d0\u53d6\u6838\u5fc3\u4efb\u52a1\u548c\u8d21\u732e\u4e3b\u5f20\u751f\u6210\u68c0\u7d22\u67e5\u8be2\uff1b\u57fa\u4e8e\u67e5\u8be2\u901a\u8fc7\u8bed\u4e49\u641c\u7d22\u5f15\u64ce\u68c0\u7d22\u76f8\u5173\u5148\u524d\u5de5\u4f5c\uff1b\u6784\u5efa\u6838\u5fc3\u4efb\u52a1\u76f8\u5173\u5de5\u4f5c\u7684\u5206\u5c42\u5206\u7c7b\u5e76\u8fdb\u884c\u8d21\u732e\u7ea7\u5168\u6587\u6bd4\u8f83\uff1b\u7efc\u5408\u5206\u6790\u5f62\u6210\u6709\u660e\u786e\u5f15\u7528\u548c\u8bc1\u636e\u7247\u6bb5\u7684\u65b0\u9896\u6027\u62a5\u544a\u3002", "result": "\u5728500+ ICLR 2026\u6295\u7a3f\u4e0a\u90e8\u7f72\uff0c\u7cfb\u7edf\u53ef\u8bc6\u522b\u76f8\u5173\u5148\u524d\u5de5\u4f5c\uff0c\u5305\u62ec\u4f5c\u8005\u53ef\u80fd\u5ffd\u7565\u7684\u76f8\u8fd1\u6587\u7ae0\u3002", "conclusion": "OpenNovelty\u53ef\u4e3a\u7814\u7a76\u754c\u63d0\u4f9b\u53ef\u6269\u5c55\u5de5\u5177\uff0c\u4fc3\u8fdb\u516c\u5e73\u3001\u4e00\u81f4\u548c\u6709\u8bc1\u636e\u652f\u6301\u7684\u540c\u884c\u8bc4\u5ba1\u3002"}}
{"id": "2601.01898", "pdf": "https://arxiv.org/pdf/2601.01898", "abs": "https://arxiv.org/abs/2601.01898", "authors": ["Yiran Tian", "Yuanjia Liu"], "title": "Multi-strategy Improved Northern Goshawk Optimization for WSN Coverage Enhancement", "categories": ["cs.NE"], "comment": null, "summary": "To enhance the coverage rate of Wireless Sensor Networks (WSNs), this paper proposes an advanced optimization strategy based on a multi-strategy integrated Northern Goshawk Optimization (NGO) algorithm. Specifically, multivariate chaotic mapping is first employed to improve the randomness and uniformity of the initial population. To further bolster population diversity and prevent the algorithm from stagnating in local optima, a bidirectional population evolutionary dynamics strategy is incorporated following the pursuit-and-evasion phase, thereby facilitating the attainment of the global optimal solution. Extensive simulations were conducted to evaluate the performance of the proposed multi-strategy NGO in WSN coverage. Experimental results demonstrate that the proposed algorithm significantly outperforms existing benchmarks in terms of both coverage enhancement and node connectivity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u7b56\u7565\u96c6\u6210\u5317\u65b9\u82cd\u9e70\u4f18\u5316\u7b97\u6cd5\u63d0\u5347\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u8986\u76d6\u7387\uff0c\u4eff\u771f\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "motivation": "\u589e\u5f3a\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u7684\u8986\u76d6\u7387\u3002", "method": "\u91c7\u7528\u591a\u5143\u6df7\u6c8c\u6620\u5c04\u6539\u5584\u521d\u59cb\u79cd\u7fa4\u968f\u673a\u6027\u548c\u5747\u5300\u6027\uff0c\u5728\u8ffd\u9003\u9636\u6bb5\u540e\u5f15\u5165\u53cc\u5411\u79cd\u7fa4\u8fdb\u5316\u52a8\u529b\u5b66\u7b56\u7565\u9632\u6b62\u7b97\u6cd5\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3002", "result": "\u5728\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u8986\u76d6\u4eff\u771f\u4e2d\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u8986\u76d6\u589e\u5f3a\u548c\u8282\u70b9\u8fde\u63a5\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u6240\u63d0\u591a\u7b56\u7565\u5317\u65b9\u82cd\u9e70\u4f18\u5316\u7b97\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u7684\u8986\u76d6\u7387\u548c\u8282\u70b9\u8fde\u63a5\u6027\u3002"}}
{"id": "2601.01413", "pdf": "https://arxiv.org/pdf/2601.01413", "abs": "https://arxiv.org/abs/2601.01413", "authors": ["Yingjie Ma", "Jing Guo", "Richard D. Braatz"], "title": "GlycoPy: An Equation-Oriented and Object-Oriented Software for Hierarchical Modeling, Optimization, and Control in Python", "categories": ["cs.SE", "cs.MS", "math.OC"], "comment": null, "summary": "Most existing model predictive control (MPC) applications in process industries employ lin-ear models, although real-world (bio)chemical processes are typically nonlinear. The use of linear models limits the performance and applicability of MPC for processes that span a wide range of operating conditions. A challenge in employing nonlinear models in MPC for com-plex systems is the lack of tools that facilitate hierarchical model development, as well as lack of efficient implementations of the corresponding nonlinear MPC (NMPC) algorithms. As a step towards making NMPC more practical for hierarchical systems, we introduce Gly-coPy, an equation-oriented, object-oriented software framework for process modeling, opti-mization, and NMPC in Python. GlycoPy enables users to focus on writing equations for modeling while supporting hierarchical modeling. GlycoPy includes algorithms for parame-ter estimation, dynamic optimization, and NMPC, and allows users to customize the simula-tion, optimization, and control algorithms. Three case studies, ranging from a simple differ-ential algebraic equation system to a multiscale bioprocess model, validate the modeling, optimization, and NMPC capabilities of GlycoPy. GlycoPy has the potential to bridge the gap between advanced NMPC algorithms and their practical application in real-world (bio)chemical processes.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7528\u4e8e\u8fc7\u7a0b\u5efa\u6a21\u3001\u4f18\u5316\u548c\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7684\u8f6f\u4ef6\u6846\u67b6GlycoPy\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u5176\u80fd\u529b\uff0c\u8be5\u6846\u67b6\u6709\u671b\u5f25\u5408\u5148\u8fdb\u7b97\u6cd5\u4e0e\u5b9e\u9645\u5e94\u7528\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u5de5\u4e1a\u4e2d\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u591a\u91c7\u7528\u7ebf\u6027\u6a21\u578b\uff0c\u9650\u5236\u4e86\u6027\u80fd\u548c\u9002\u7528\u6027\uff0c\u4f7f\u7528\u975e\u7ebf\u6027\u6a21\u578b\u5b58\u5728\u7f3a\u4e4f\u5206\u5c42\u6a21\u578b\u5f00\u53d1\u5de5\u5177\u548c\u9ad8\u6548\u7b97\u6cd5\u5b9e\u73b0\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u65b9\u7a0b\u5bfc\u5411\u3001\u9762\u5411\u5bf9\u8c61\u7684Python\u8f6f\u4ef6\u6846\u67b6GlycoPy\uff0c\u652f\u6301\u5206\u5c42\u5efa\u6a21\uff0c\u5305\u542b\u53c2\u6570\u4f30\u8ba1\u3001\u52a8\u6001\u4f18\u5316\u548cNMPC\u7b49\u7b97\u6cd5\uff0c\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u9a8c\u8bc1\u4e86GlycoPy\u7684\u5efa\u6a21\u3001\u4f18\u5316\u548cNMPC\u80fd\u529b\u3002", "conclusion": "GlycoPy\u6709\u6f5c\u529b\u5f25\u5408\u5148\u8fdbNMPC\u7b97\u6cd5\u4e0e\u5b9e\u9645\uff08\u751f\u7269\uff09\u5316\u5b66\u8fc7\u7a0b\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2601.00845", "pdf": "https://arxiv.org/pdf/2601.00845", "abs": "https://arxiv.org/abs/2601.00845", "authors": ["Lili Chen", "Wensheng Gan", "Shuang Liang", "Philip S. Yu"], "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes", "categories": ["cs.AI"], "comment": "preprint", "summary": "Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdTPP-TAL\u6846\u67b6\u7528\u4e8e\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u589e\u5f3a\u65f6\u95f4\u63a8\u7406\uff0c\u5728\u591a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u63d0\u5347\u65f6\u95f4\u4f3c\u7136\u4f30\u8ba1\u548c\u4e8b\u4ef6\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e8f\u5217\u5efa\u6a21\u4e0a\u6210\u529f\uff0c\u4f46\u5e94\u7528\u4e8e\u65f6\u95f4\u70b9\u8fc7\u7a0b\u4ecd\u6709\u6311\u6218\uff0c\u5f53\u524d\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6355\u6349\u65f6\u95f4\u4fe1\u606f\u548c\u8bed\u4e49\u4e0a\u4e0b\u6587\u7684\u590d\u6742\u4ea4\u4e92\u3002", "method": "\u5f15\u5165TPP - TAL\u6846\u67b6\uff0c\u4e0d\u91c7\u7528\u7b80\u5355\u62fc\u63a5\u4e8b\u4ef6\u65f6\u95f4\u548c\u7c7b\u578b\u5d4c\u5165\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u800c\u662f\u5728\u8f93\u5165\u5927\u8bed\u8a00\u6a21\u578b\u524d\u660e\u786e\u5bf9\u9f50\u65f6\u95f4\u52a8\u6001\u548c\u4e0a\u4e0b\u6587\u8bed\u4e49\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u7684\u7efc\u5408\u5b9e\u9a8c\u4e2d\uff0cTPP - TAL\u5728\u65f6\u95f4\u4f3c\u7136\u4f30\u8ba1\u548c\u4e8b\u4ef6\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u5bf9\u4e8e\u8fde\u7eed\u65f6\u95f4\u4e8b\u4ef6\u5efa\u6a21\uff0c\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u589e\u5f3a\u65f6\u95f4\u611f\u77e5\u5f88\u91cd\u8981\u3002"}}
{"id": "2601.01619", "pdf": "https://arxiv.org/pdf/2601.01619", "abs": "https://arxiv.org/abs/2601.01619", "authors": ["Maxat Tezekbayev", "Rustem Takhanov", "Arman Bolatov", "Zhenisbek Assylbekov"], "title": "Deep Linear Discriminant Analysis Revisited", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We show that for unconstrained Deep Linear Discriminant Analysis (LDA) classifiers, maximum-likelihood training admits pathological solutions in which class means drift together, covariances collapse, and the learned representation becomes almost non-discriminative. Conversely, cross-entropy training yields excellent accuracy but decouples the head from the underlying generative model, leading to highly inconsistent parameter estimates. To reconcile generative structure with discriminative performance, we introduce the \\emph{Discriminative Negative Log-Likelihood} (DNLL) loss, which augments the LDA log-likelihood with a simple penalty on the mixture density. DNLL can be interpreted as standard LDA NLL plus a term that explicitly discourages regions where several classes are simultaneously likely. Deep LDA trained with DNLL produces clean, well-separated latent spaces, matches the test accuracy of softmax classifiers on synthetic data and standard image benchmarks, and yields substantially better calibrated predictive probabilities, restoring a coherent probabilistic interpretation to deep discriminant models.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u65e0\u7ea6\u675f\u6df1\u5ea6\u7ebf\u6027\u5224\u522b\u5206\u6790\uff08LDA\uff09\u5206\u7c7b\u5668\u6700\u5927\u4f3c\u7136\u8bad\u7ec3\u5b58\u5728\u75c5\u6001\u89e3\uff0c\u4ea4\u53c9\u71b5\u8bad\u7ec3\u53c2\u6570\u4f30\u8ba1\u4e0d\u4e00\u81f4\uff0c\u5f15\u5165 DNLL \u635f\u5931\u8c03\u548c\u751f\u6210\u7ed3\u6784\u4e0e\u5224\u522b\u6027\u80fd\uff0c\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ea6\u675f\u6df1\u5ea6 LDA \u5206\u7c7b\u5668\u6700\u5927\u4f3c\u7136\u8bad\u7ec3\u7684\u75c5\u6001\u89e3\u95ee\u9898\uff0c\u4ee5\u53ca\u4ea4\u53c9\u71b5\u8bad\u7ec3\u53c2\u6570\u4f30\u8ba1\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u8c03\u548c\u751f\u6210\u7ed3\u6784\u4e0e\u5224\u522b\u6027\u80fd\u3002", "method": "\u5f15\u5165\u5224\u522b\u8d1f\u5bf9\u6570\u4f3c\u7136\uff08DNLL\uff09\u635f\u5931\uff0c\u5728 LDA \u5bf9\u6570\u4f3c\u7136\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u5bf9\u6df7\u5408\u5bc6\u5ea6\u7684\u7b80\u5355\u60e9\u7f5a\u3002", "result": "\u4f7f\u7528 DNLL \u8bad\u7ec3\u7684\u6df1\u5ea6 LDA \u4ea7\u751f\u6e05\u6670\u3001\u5206\u79bb\u826f\u597d\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5728\u5408\u6210\u6570\u636e\u548c\u6807\u51c6\u56fe\u50cf\u57fa\u51c6\u4e0a\u4e0e softmax \u5206\u7c7b\u5668\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u76f8\u5f53\uff0c\u4e14\u9884\u6d4b\u6982\u7387\u6821\u51c6\u6548\u679c\u66f4\u597d\u3002", "conclusion": "DNLL \u635f\u5931\u80fd\u4e3a\u6df1\u5ea6\u5224\u522b\u6a21\u578b\u6062\u590d\u8fde\u8d2f\u7684\u6982\u7387\u89e3\u91ca\uff0c\u8c03\u548c\u751f\u6210\u7ed3\u6784\u4e0e\u5224\u522b\u6027\u80fd\u3002"}}
{"id": "2601.02092", "pdf": "https://arxiv.org/pdf/2601.02092", "abs": "https://arxiv.org/abs/2601.02092", "authors": ["Abdullah Al Asif", "Sixing Yu", "Juan Pablo Munoz", "Arya Mazaheri", "Ali Jannesari"], "title": "SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks", "categories": ["cs.DC"], "comment": null, "summary": "SplitFed Learning (SFL) combines federated learning and split learning to enable collaborative training across distributed edge devices; however, it faces significant challenges in heterogeneous environments with diverse computational and communication capabilities. This paper proposes \\textit{SuperSFL}, a federated split learning framework that leverages a weight-sharing super-network to dynamically generate resource-aware client-specific subnetworks, effectively mitigating device heterogeneity. SuperSFL introduces Three-Phase Gradient Fusion (TPGF), an optimization mechanism that coordinates local updates, server-side computation, and gradient fusion to accelerate convergence. In addition, a fault-tolerant client-side classifier and collaborative client--server aggregation enable uninterrupted training under intermittent communication failures. Experimental results on CIFAR-10 and CIFAR-100 with up to 100 heterogeneous clients show that SuperSFL converges $2$--$5\\times$ faster in terms of communication rounds than baseline SFL while achieving higher accuracy, resulting in up to $20\\times$ lower total communication cost and $13\\times$ shorter training time. SuperSFL also demonstrates improved energy efficiency compared to baseline methods, making it a practical solution for federated learning in heterogeneous edge environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSuperSFL\u6846\u67b6\u5e94\u5bf9SplitFed Learning\u5728\u5f02\u6784\u73af\u5883\u7684\u6311\u6218\uff0c\u901a\u8fc7\u6743\u91cd\u5171\u4eab\u8d85\u7f51\u7edc\u751f\u6210\u5b50\u7f51\u3001\u5f15\u5165\u4f18\u5316\u673a\u5236\u7b49\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6536\u655b\u5feb\u3001\u51c6\u786e\u7387\u9ad8\u3001\u901a\u4fe1\u6210\u672c\u4f4e\u4e14\u8bad\u7ec3\u65f6\u95f4\u77ed\uff0c\u63d0\u5347\u80fd\u6e90\u6548\u7387\u3002", "motivation": "SplitFed Learning\u5728\u5f02\u6784\u73af\u5883\u9762\u4e34\u8ba1\u7b97\u548c\u901a\u4fe1\u80fd\u529b\u5dee\u5f02\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faSuperSFL\u6846\u67b6\uff0c\u5229\u7528\u6743\u91cd\u5171\u4eab\u8d85\u7f51\u7edc\u751f\u6210\u5ba2\u6237\u7aef\u7279\u5b9a\u5b50\u7f51\uff1b\u5f15\u5165Three - Phase Gradient Fusion\u4f18\u5316\u673a\u5236\uff1b\u91c7\u7528\u5bb9\u9519\u5ba2\u6237\u7aef\u5206\u7c7b\u5668\u548c\u534f\u4f5c\u5f0f\u5ba2\u6237\u7aef - \u670d\u52a1\u5668\u805a\u5408\u3002", "result": "\u5728CIFAR - 10\u548cCIFAR - 100\u5b9e\u9a8c\u4e2d\uff0cSuperSFL\u901a\u4fe1\u8f6e\u6b21\u6536\u655b\u5feb2 - 5\u500d\uff0c\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u901a\u4fe1\u6210\u672c\u964d\u4f4e20\u500d\uff0c\u8bad\u7ec3\u65f6\u95f4\u7f29\u77ed13\u500d\uff0c\u80fd\u6e90\u6548\u7387\u63d0\u9ad8\u3002", "conclusion": "SuperSFL\u662f\u5f02\u6784\u8fb9\u7f18\u73af\u5883\u4e0b\u8054\u90a6\u5b66\u4e60\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02304", "pdf": "https://arxiv.org/pdf/2601.02304", "abs": "https://arxiv.org/abs/2601.02304", "authors": ["Wen-Zhi Li", "Sainyam Galhotra"], "title": "Octopus: A Lightweight Entity-Aware System for Multi-Table Data Discovery and Cell-Level Retrieval", "categories": ["cs.DB"], "comment": null, "summary": "Tabular data constitute a dominant form of information in modern data lakes and repositories, yet discovering the relevant tables to answer user questions remains challenging. Existing data discovery systems assume that each question can be answered by a single table and often rely on resource-intensive offline preprocessing, such as model training or large-scale content indexing. In practice, however, many questions require information spread across multiple tables -- either independently or through joins -- and users often seek specific cell values rather than entire tables. In this paper, we present Octopus, a lightweight, entity-aware, and training-free system for multi-table data discovery and cell-level value retrieval. Instead of embedding entire questions, Octopus identifies fine-grained entities (column mentions and value mentions) from natural-language queries using an LLM parser. It then matches these entities to table headers through a compact embedding index and scans table contents directly for value occurrences, eliminating the need for heavy content indexing or costly offline stages. The resulting fine-grained alignment not only improves table retrieval accuracy but also facilitates efficient downstream NL2SQL execution by reducing token usage and redundant LLM calls. To evaluate Octopus, we introduce a new benchmark covering both table- and cell-level discovery under multi-table settings, including five datasets for independent discovery and two for join-based discovery. Experimental results show that Octopus consistently outperforms existing systems while achieving substantially lower computational and token costs. Code is available at https://github.com/wenzhilics/octopus.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u8bad\u7ec3\u7684Octopus\u7cfb\u7edf\u7528\u4e8e\u591a\u8868\u6570\u636e\u53d1\u73b0\u548c\u5355\u5143\u683c\u503c\u68c0\u7d22\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u4e14\u6210\u672c\u66f4\u4f4e\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u53d1\u73b0\u7cfb\u7edf\u5047\u8bbe\u5355\u8868\u89e3\u7b54\u95ee\u9898\uff0c\u9700\u5927\u91cf\u9884\u5904\u7406\uff0c\u800c\u5b9e\u9645\u5f88\u591a\u95ee\u9898\u9700\u591a\u8868\u4fe1\u606f\u4e14\u7528\u6237\u5e38\u67e5\u627e\u7279\u5b9a\u5355\u5143\u683c\u503c\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528LLM\u89e3\u6790\u5668\u4ece\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u8bc6\u522b\u7ec6\u7c92\u5ea6\u5b9e\u4f53\uff0c\u901a\u8fc7\u7d27\u51d1\u5d4c\u5165\u7d22\u5f15\u5339\u914d\u8868\u5934\uff0c\u76f4\u63a5\u626b\u63cf\u8868\u5185\u5bb9\u627e\u503c\u3002", "result": "\u5f15\u5165\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u8868\u660eOctopus\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u7cfb\u7edf\uff0c\u8ba1\u7b97\u548c\u4ee4\u724c\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "Octopus\u662f\u6709\u6548\u7684\u591a\u8868\u6570\u636e\u53d1\u73b0\u548c\u5355\u5143\u683c\u503c\u68c0\u7d22\u7cfb\u7edf\uff0c\u80fd\u964d\u4f4e\u6210\u672c\uff0c\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2601.02202", "pdf": "https://arxiv.org/pdf/2601.02202", "abs": "https://arxiv.org/abs/2601.02202", "authors": ["Amirhossein Bayat", "Hao Li", "Joe Alexandersen"], "title": "Density-based topology optimization for turbulent fluid flow using the standard k-epsilon RANS model with wall-functions imposed through an implicit wall penalty formulation", "categories": ["physics.flu-dyn", "cs.CE"], "comment": null, "summary": "Turbulent flows have high requirements for very fine meshes near the boundary to ensure accuracy. In the context of topology optimization (TO), such fine meshes become unrealistic and common approaches are hampered by low accuracy and overestimation of boundary layer thickness. Wall-functions are a natural way to ease the computational requirements, but they are not naturally imposed in density-based TO due to the diffuse design parametrization. We propose an implicit wall-function formulation for the Reynolds-Averaged Navier-Stokes (RANS), standard k-epsilon model that extracts wall-normal information directly from the gradient of the design variable and enables a penalty-based formulation for imposing wall-functions to the RANS equations, without the need for body-fitted meshes. The method provides a reliable route to high Reynolds number turbulent topology optimization, delivering boundary layer accuracy comparable to explicit-wall body-fitted analyses, while retaining the flexibility of density-based TO. Furthermore, because wall effects are modeled using wall-functions, accurate solutions are obtained on substantially coarser meshes, leading to significant reductions in computational cost. The approach is validated on three canonical benchmarks over Reynolds numbers up to Re = 2e5: a pipe-bend; a U-bend; and a Tesla-valve. Across all cases, the proposed method accurately recovers near-wall velocity profiles, closely matching verification simulations on body-fitted meshes with explicit wall-functions. In contrast, a conventional turbulent TO formulation, without the proposed wall-function treatment, mispredicts boundary-layer development and yields sub-optimal results.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u96f7\u8bfa\u5e73\u5747Navier - Stokes\u65b9\u7a0b\u7684\u9690\u5f0f\u58c1\u51fd\u6570\u516c\u5f0f\uff0c\u53ef\u5b9e\u73b0\u9ad8\u96f7\u8bfa\u6570\u6e4d\u6d41\u62d3\u6251\u4f18\u5316\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "motivation": "\u6e4d\u6d41\u6d41\u52a8\u5bf9\u8fb9\u754c\u9644\u8fd1\u7cbe\u7ec6\u7f51\u683c\u8981\u6c42\u9ad8\uff0c\u62d3\u6251\u4f18\u5316\u4e2d\u5e38\u89c1\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u4f4e\u548c\u9ad8\u4f30\u8fb9\u754c\u5c42\u539a\u5ea6\u95ee\u9898\uff0c\u4e14\u57fa\u4e8e\u5bc6\u5ea6\u7684\u62d3\u6251\u4f18\u5316\u96be\u4ee5\u81ea\u7136\u5f15\u5165\u58c1\u51fd\u6570\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u96f7\u8bfa\u5e73\u5747Navier - Stokes\u65b9\u7a0b\u3001\u6807\u51c6k - \u03b5\u6a21\u578b\u7684\u9690\u5f0f\u58c1\u51fd\u6570\u516c\u5f0f\uff0c\u4ece\u8bbe\u8ba1\u53d8\u91cf\u68af\u5ea6\u4e2d\u63d0\u53d6\u6cd5\u5411\u4fe1\u606f\uff0c\u7528\u60e9\u7f5a\u6cd5\u5c06\u58c1\u51fd\u6570\u5f15\u5165\u65b9\u7a0b\uff0c\u65e0\u9700\u8d34\u5408\u5b9e\u4f53\u7f51\u683c\u3002", "result": "\u65b9\u6cd5\u80fd\u5728\u7c97\u7f51\u683c\u4e0a\u83b7\u5f97\u51c6\u786e\u89e3\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff1b\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51c6\u786e\u6062\u590d\u8fd1\u58c1\u901f\u5ea6\u8f6e\u5ed3\uff0c\u5339\u914d\u663e\u5f0f\u58c1\u51fd\u6570\u7684\u9a8c\u8bc1\u6a21\u62df\u7ed3\u679c\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u9884\u6d4b\u4e0d\u51c6\u786e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u9ad8\u96f7\u8bfa\u6570\u6e4d\u6d41\u62d3\u6251\u4f18\u5316\u63d0\u4f9b\u53ef\u9760\u9014\u5f84\uff0c\u517c\u5177\u5bc6\u5ea6\u62d3\u6251\u4f18\u5316\u7684\u7075\u6d3b\u6027\u548c\u8fb9\u754c\u5c42\u7cbe\u5ea6\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2601.01684", "pdf": "https://arxiv.org/pdf/2601.01684", "abs": "https://arxiv.org/abs/2601.01684", "authors": ["Zhichao Xu", "Shengyao Zhuang", "Crystina Zhang", "Xueguang Ma", "Yijun Tian", "Maitrey Mehta", "Jimmy Lin", "Vivek Srikumar"], "title": "LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "While dense retrieval models have become the standard for state-of-the-art information retrieval, their deployment is often constrained by high memory requirements and reliance on GPU accelerators for vector similarity search. Learned sparse retrieval offers a compelling alternative by enabling efficient search via inverted indices, yet it has historically received less attention than dense approaches. In this report, we introduce LACONIC, a family of learned sparse retrievers based on the Llama-3 architecture (1B, 3B, and 8B). We propose a streamlined two-phase training curriculum consisting of (1) weakly supervised pre-finetuning to adapt causal LLMs for bidirectional contextualization and (2) high-signal finetuning using curated hard negatives. Our results demonstrate that LACONIC effectively bridges the performance gap with dense models: the 8B variant achieves a state-of-the-art 60.2 nDCG on the MTEB Retrieval benchmark, ranking 15th on the leaderboard as of January 1, 2026, while utilizing 71\\% less index memory than an equivalent dense model. By delivering high retrieval effectiveness on commodity CPU hardware with a fraction of the compute budget required by competing models, LACONIC provides a scalable and efficient solution for real-world search applications.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8eLlama - 3\u67b6\u6784\u7684\u5b66\u4e60\u578b\u7a00\u758f\u68c0\u7d22\u5668LACONIC\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6848\uff0c\u5176\u6027\u80fd\u63a5\u8fd1\u7a20\u5bc6\u6a21\u578b\uff0c\u8282\u7701\u5185\u5b58\uff0c\u9002\u7528\u4e8e\u73b0\u5b9e\u641c\u7d22\u5e94\u7528\u3002", "motivation": "\u7a20\u5bc6\u68c0\u7d22\u6a21\u578b\u90e8\u7f72\u53d7\u9ad8\u5185\u5b58\u548cGPU\u4f9d\u8d56\u9650\u5236\uff0c\u5b66\u4e60\u578b\u7a00\u758f\u68c0\u7d22\u53d7\u5173\u6ce8\u5c11\uff0c\u9700\u9ad8\u6548\u68c0\u7d22\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u8bfe\u7a0b\uff0c\u5305\u62ec\u5f31\u76d1\u7763\u9884\u5fae\u8c03\u9002\u5e94\u53cc\u5411\u4e0a\u4e0b\u6587\u548c\u4f7f\u7528\u7cbe\u5fc3\u6311\u9009\u7684\u786c\u8d1f\u6837\u672c\u8fdb\u884c\u9ad8\u4fe1\u53f7\u5fae\u8c03\u3002", "result": "LACONIC 8B\u53d8\u4f53\u5728MTEB\u68c0\u7d22\u57fa\u51c6\u4e0a\u8fbe\u523060.2 nDCG\uff0c\u6392\u540d\u7b2c15\uff0c\u6bd4\u7b49\u6548\u7a20\u5bc6\u6a21\u578b\u8282\u770171%\u7d22\u5f15\u5185\u5b58\u3002", "conclusion": "LACONIC\u5728\u666e\u901aCPU\u786c\u4ef6\u4e0a\u63d0\u4f9b\u9ad8\u68c0\u7d22\u6548\u7387\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\uff0c\u662f\u73b0\u5b9e\u641c\u7d22\u5e94\u7528\u7684\u53ef\u6269\u5c55\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01916", "pdf": "https://arxiv.org/pdf/2601.01916", "abs": "https://arxiv.org/abs/2601.01916", "authors": ["Francisco Angulo de Lafuente", "Vladimir Veselov", "Richard Goodman"], "title": "Toward Thermodynamic Reservoir Computing: Exploring SHA-256 ASICs as Potential Physical Substrates", "categories": ["cs.NE"], "comment": "8 pages, 7 tables, Position Paper / Hypothesis with Preliminary Observations", "summary": "We propose a theoretical framework--Holographic Reservoir Computing (HRC)--which hypothesizes that the thermodynamic noise and timing dynamics in voltage-stressed Bitcoin mining ASICs (BM1366) could potentially serve as a physical reservoir computing substrate. We present the CHIMERA (Conscious Hybrid Intelligence via Miner-Embedded Resonance Architecture) system architecture, which treats the SHA-256 hashing pipeline not as an entropy source, but as a deterministic diffusion operator whose timing characteristics under controlled voltage and frequency conditions may exhibit computationally useful dynamics. We report preliminary observations of non-Poissonian variability in inter-arrival time statistics during edge-of-stability operation, which we term the \"Silicon Heartbeat\" hypothesis. Theoretical analysis based on Hierarchical Number System (HNS) representations suggests that such architectures could achieve O(log n) energy scaling compared to traditional von Neumann O(2^n) dependencies. However, we emphasize that these are theoretical projections requiring experimental validation. We present the implemented measurement infrastructure, acknowledge current limitations, and outline the experimental program necessary to confirm or refute these hypotheses. This work contributes to the emerging field of thermodynamic computing by proposing a novel approach to repurposing obsolete cryptographic hardware for neuromorphic applications.", "AI": {"tldr": "\u63d0\u51fa\u5168\u606f\u50a8\u5c42\u8ba1\u7b97\u6846\u67b6HRC\uff0c\u5047\u8bbe\u6bd4\u7279\u5e01\u77ff\u673aASIC\u53ef\u4f5c\u7269\u7406\u50a8\u5c42\u8ba1\u7b97\u5e95\u7269\uff0c\u7ed9\u51faCHIMERA\u7cfb\u7edf\u67b6\u6784\uff0c\u6709\u7406\u8bba\u6295\u5f71\u5f85\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u4e3a\u70ed\u529b\u5b66\u8ba1\u7b97\u9886\u57df\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u5c06\u8fc7\u65f6\u52a0\u5bc6\u786c\u4ef6\u7528\u4e8e\u795e\u7ecf\u5f62\u6001\u5e94\u7528\u3002", "method": "\u63d0\u51faHRC\u6846\u67b6\u548cCHIMERA\u7cfb\u7edf\u67b6\u6784\uff0c\u57fa\u4e8eHNS\u8868\u793a\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u89c2\u5bdf\u5230\u975e\u6cca\u677e\u53d8\u5f02\u6027\uff0c\u7406\u8bba\u5206\u6790\u663e\u793a\u6709O(log n)\u80fd\u91cf\u7f29\u653e\u4f18\u52bf\u3002", "conclusion": "\u5de5\u4f5c\u4e3a\u70ed\u529b\u5b66\u8ba1\u7b97\u9886\u57df\u63d0\u51fa\u65b0\u9014\u5f84\uff0c\u4f46\u7406\u8bba\u9700\u5b9e\u9a8c\u9a8c\u8bc1\u3002"}}
{"id": "2601.01426", "pdf": "https://arxiv.org/pdf/2601.01426", "abs": "https://arxiv.org/abs/2601.01426", "authors": ["Chaofan Tao", "Jierun Chen", "Yuxin Jiang", "Kaiqi Kou", "Shaowei Wang", "Ruoyu Wang", "Xiaohui Li", "Sidi Yang", "Yiming Du", "Jianbo Dai", "Zhiming Mao", "Xinyu Wang", "Lifeng Shang", "Haoli Bai"], "title": "SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving", "categories": ["cs.SE", "cs.CL"], "comment": "Project website: https://github.com/SWE-Lego/SWE-Lego", "summary": "We present SWE-Lego, a supervised fine-tuning (SFT) recipe designed to achieve state-ofthe-art performance in software engineering (SWE) issue resolving. In contrast to prevalent methods that rely on complex training paradigms (e.g., mid-training, SFT, reinforcement learning, and their combinations), we explore how to push the limits of a lightweight SFT-only approach for SWE tasks. SWE-Lego comprises three core building blocks, with key findings summarized as follows: 1) the SWE-Lego dataset, a collection of 32k highquality task instances and 18k validated trajectories, combining real and synthetic data to complement each other in both quality and quantity; 2) a refined SFT procedure with error masking and a difficulty-based curriculum, which demonstrably improves action quality and overall performance. Empirical results show that with these two building bricks alone,the SFT can push SWE-Lego models to state-of-the-art performance among open-source models of comparable size on SWE-bench Verified: SWE-Lego-Qwen3-8B reaches 42.2%, and SWE-Lego-Qwen3-32B attains 52.6%. 3) We further evaluate and improve test-time scaling (TTS) built upon the SFT foundation. Based on a well-trained verifier, SWE-Lego models can be significantly boosted--for example, 42.2% to 49.6% and 52.6% to 58.8% under TTS@16 for the 8B and 32B models, respectively.", "AI": {"tldr": "\u63d0\u51faSWE - Lego\uff0c\u4e00\u79cd\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u96c6\u3001\u5fae\u8c03\u7a0b\u5e8f\u548c\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u4ec5\u4f7f\u7528\u8f7b\u91cf\u7ea7\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u4f18\u6548\u679c\uff0c\u800c\u975e\u4f9d\u8d56\u590d\u6742\u8bad\u7ec3\u8303\u5f0f\u3002", "method": "SWE - Lego\u5305\u542bSWE - Lego\u6570\u636e\u96c6\u3001\u5e26\u8bef\u5dee\u63a9\u7801\u548c\u57fa\u4e8e\u96be\u5ea6\u7684\u8bfe\u7a0b\u7684\u5fae\u8c03\u7a0b\u5e8f\uff0c\u8fd8\u5728\u5fae\u8c03\u57fa\u7840\u4e0a\u8bc4\u4f30\u5e76\u6539\u8fdb\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u3002", "result": "\u4ec5\u524d\u4e24\u4e2a\u7ec4\u4ef6\u5c31\u8ba9SWE - Lego\u6a21\u578b\u5728\u540c\u89c4\u6a21\u5f00\u6e90\u6a21\u578b\u4e2d\u8fbe\u6700\u4f18\uff0c\u5982SWE - Lego - Qwen3 - 8B\u8fbe42.2%\uff0cSWE - Lego - Qwen3 - 32B\u8fbe52.6%\uff1b\u4f7f\u7528\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u540e\uff0c8B\u548c32B\u6a21\u578b\u5206\u522b\u4ece42.2%\u63d0\u9ad8\u523049.6%\u300152.6%\u63d0\u9ad8\u523058.8%\u3002", "conclusion": "SWE - Lego\u7684\u8f7b\u91cf\u7ea7\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u4e0a\u80fd\u8fbe\u5230\u8f83\u597d\u6548\u679c\u3002"}}
{"id": "2601.00848", "pdf": "https://arxiv.org/pdf/2601.00848", "abs": "https://arxiv.org/abs/2601.00848", "authors": ["Ron F. Del Rosario"], "title": "Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models", "categories": ["cs.AI", "cs.CR"], "comment": "26 pages, 3 figures, 7 tables. Datasets and code: https://huggingface.co/guerilla7/agentic-safety-gguf", "summary": "We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528OpenTelemetry\u8ddf\u8e2a\u5206\u6790\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u591a\u667a\u80fd\u4f53AI\u5de5\u4f5c\u6d41\u4e2d\u7684\u65f6\u95f4\u653b\u51fb\u6a21\u5f0f\uff0c\u6570\u636e\u96c6\u5fae\u8c03\u540e\u7cbe\u5ea6\u63d0\u5347\uff0c\u7ed9\u51fa\u76f8\u5173\u6210\u679c\u5e76\u5efa\u7acb\u53ef\u590d\u73b0\u6846\u67b6\u3002", "motivation": "\u68c0\u6d4b\u591a\u667a\u80fd\u4f53AI\u5de5\u4f5c\u6d41\u4e2d\u7684\u65f6\u95f4\u653b\u51fb\u6a21\u5f0f\u3002", "method": "\u4ece18\u4e2a\u516c\u5171\u7f51\u7edc\u5b89\u5168\u6e90\u548c35,026\u4e2a\u5408\u6210\u8ddf\u8e2a\u4e2d\u6574\u7406\u6570\u636e\u96c6\uff0c\u5728ARM64\u786c\u4ef6\u4e0a\u8fdb\u884c\u8fed\u4ee3QLoRA\u5fae\u8c03\u8bad\u7ec3\u3002", "result": "\u81ea\u5b9a\u4e49\u57fa\u51c6\u6d4b\u8bd5\u51c6\u786e\u7387\u4ece42.86%\u63d0\u9ad8\u523074.29%\u3002", "conclusion": "\u867d\u5b9e\u9645\u90e8\u7f72\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u4f46\u5efa\u7acb\u9996\u4e2a\u53ef\u590d\u73b0\u6846\u67b6\uff0c\u8ba9\u4ece\u4e1a\u8005\u53ef\u6784\u5efa\u9002\u5e94\u81ea\u8eab\u5a01\u80c1\u72b6\u51b5\u7684\u5b89\u5168\u6a21\u578b\u3002"}}
{"id": "2601.01679", "pdf": "https://arxiv.org/pdf/2601.01679", "abs": "https://arxiv.org/abs/2601.01679", "authors": ["Maxat Tezekbayev", "Arman Bolatov", "Zhenisbek Assylbekov"], "title": "Simplex Deep Linear Discriminant Analysis", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We revisit Deep Linear Discriminant Analysis (Deep LDA) from a likelihood-based perspective. While classical LDA is a simple Gaussian model with linear decision boundaries, attaching an LDA head to a neural encoder raises the question of how to train the resulting deep classifier by maximum likelihood estimation (MLE). We first show that end-to-end MLE training of an unconstrained Deep LDA model ignores discrimination: when both the LDA parameters and the encoder parameters are learned jointly, the likelihood admits a degenerate solution in which some of the class clusters may heavily overlap or even collapse, and classification performance deteriorates. Batchwise moment re-estimation of the LDA parameters does not remove this failure mode. We then propose a constrained Deep LDA formulation that fixes the class means to the vertices of a regular simplex in the latent space and restricts the shared covariance to be spherical, leaving only the priors and a single variance parameter to be learned along with the encoder. Under these geometric constraints, MLE becomes stable and yields well-separated class clusters in the latent space. On images (Fashion-MNIST, CIFAR-10, CIFAR-100), the resulting Deep LDA models achieve accuracy competitive with softmax baselines while offering a simple, interpretable latent geometry that is clearly visible in two-dimensional projections.", "AI": {"tldr": "\u672c\u6587\u4ece\u4f3c\u7136\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u6df1\u5ea6\u7ebf\u6027\u5224\u522b\u5206\u6790\uff08Deep LDA\uff09\uff0c\u6307\u51fa\u65e0\u7ea6\u675f\u6a21\u578bMLE\u8bad\u7ec3\u95ee\u9898\uff0c\u63d0\u51fa\u7ea6\u675f\u516c\u5f0f\uff0c\u5b9e\u9a8c\u663e\u793a\u5177\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u7ecf\u5178LDA\u7b80\u5355\uff0c\u7ed9\u795e\u7ecf\u7f16\u7801\u5668\u52a0LDA\u5934\u540e\uff0c\u5982\u4f55\u7528\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u8bad\u7ec3\u6df1\u5ea6\u5206\u7c7b\u5668\u5b58\u7591\u3002", "method": "\u5148\u5206\u6790\u65e0\u7ea6\u675fDeep LDA\u6a21\u578b\u7aef\u5230\u7aefMLE\u8bad\u7ec3\u95ee\u9898\uff0c\u7136\u540e\u63d0\u51fa\u7ea6\u675fDeep LDA\u516c\u5f0f\uff0c\u56fa\u5b9a\u7c7b\u5747\u503c\u5230\u6b63\u5219\u5355\u7eaf\u5f62\u9876\u70b9\uff0c\u9650\u5236\u534f\u65b9\u5dee\u4e3a\u7403\u5f62\u3002", "result": "\u5728Fashion - MNIST\u3001CIFAR - 10\u3001CIFAR - 100\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\uff0c\u7ea6\u675f\u540e\u7684Deep LDA\u6a21\u578b\u7cbe\u5ea6\u4e0esoftmax\u57fa\u51c6\u76f8\u5f53\u3002", "conclusion": "\u51e0\u4f55\u7ea6\u675f\u4e0b\uff0cMLE\u7a33\u5b9a\uff0c\u80fd\u5728\u6f5c\u5728\u7a7a\u95f4\u4ea7\u751f\u5206\u79bb\u826f\u597d\u7684\u7c7b\u7c07\uff0c\u6a21\u578b\u6709\u7b80\u5355\u53ef\u89e3\u91ca\u7684\u6f5c\u5728\u51e0\u4f55\u7ed3\u6784\u3002"}}
{"id": "2601.02286", "pdf": "https://arxiv.org/pdf/2601.02286", "abs": "https://arxiv.org/abs/2601.02286", "authors": ["Rahul Sengupta", "Nooshin Yousefzadeh", "Manav Sanghvi", "Yash Ranjan", "Anand Rangarajan", "Sanjay Ranka", "Yashaswi Karnati", "Jeremy Dilmore", "Tushar Patel", "Ryan Casburn"], "title": "BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation", "categories": ["cs.DC"], "comment": "6 pages, 10 figures", "summary": "With growing urbanization worldwide, efficient management of traffic infrastructure is critical for transportation agencies and city planners. It is essential to have tools that help analyze large volumes of stored traffic data and make effective interventions. To address this need, we present ``BigSUMO\", an end-to-end, scalable, open-source framework for analytics, interruption detection, and parallel traffic simulation. Our system ingests high-resolution loop detector and signal state data, along with sparse probe trajectory data. It first performs descriptive analytics and detects potential interruptions. It then uses the SUMO microsimulator for prescriptive analytics, testing hundreds of what-if scenarios to optimize traffic performance. The modular design allows integration of different algorithms for data processing and outlier detection. Built using open-source software and libraries, the pipeline is cost-effective, scalable, and easy to deploy. We hope BigSUMO will be a valuable aid in developing smart city mobility solutions.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u4ea4\u901a\u6570\u636e\u5206\u6790\u3001\u4e2d\u65ad\u68c0\u6d4b\u548c\u5e76\u884c\u6a21\u62df\u7684\u5f00\u6e90\u6846\u67b6BigSUMO\u3002", "motivation": "\u968f\u7740\u5168\u7403\u57ce\u5e02\u5316\u8fdb\u7a0b\uff0c\u9700\u8981\u6709\u6548\u5de5\u5177\u5206\u6790\u5927\u91cf\u4ea4\u901a\u6570\u636e\u5e76\u505a\u51fa\u5e72\u9884\u3002", "method": "\u6444\u5165\u9ad8\u5206\u8fa8\u7387\u6570\u636e\u548c\u7a00\u758f\u8f68\u8ff9\u6570\u636e\uff0c\u5148\u8fdb\u884c\u63cf\u8ff0\u6027\u5206\u6790\u548c\u4e2d\u65ad\u68c0\u6d4b\uff0c\u518d\u7528SUMO\u8fdb\u884c\u89c4\u8303\u6027\u5206\u6790\uff0c\u6a21\u5757\u5316\u8bbe\u8ba1\u53ef\u96c6\u6210\u4e0d\u540c\u7b97\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u6210\u672c\u4f4e\u3001\u53ef\u6269\u5c55\u4e14\u6613\u90e8\u7f72\u7684\u5206\u6790\u6846\u67b6\u3002", "conclusion": "\u5e0c\u671bBigSUMO\u5bf9\u667a\u80fd\u57ce\u5e02\u51fa\u884c\u89e3\u51b3\u65b9\u6848\u6709\u5e2e\u52a9\u3002"}}
{"id": "2601.01015", "pdf": "https://arxiv.org/pdf/2601.01015", "abs": "https://arxiv.org/abs/2601.01015", "authors": ["Shiyuan Liu", "Jianwei Wang", "Xuemin Lin", "Lu Qin", "Wenjie Zhang", "Ying Zhang"], "title": "HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery", "categories": ["cs.CL", "cs.DB"], "comment": null, "summary": "As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with online ranking, their design insufficiently accounts for the underlying structural interactions: (1) offline, they directly model tables into isolated or pairwise columns, thereby struggling to capture the rich inter-table and intra-table structural information; and (2) online, they rank candidate columns based solely on query-candidate similarity, ignoring the mutual interactions among the candidates, leading to incoherent result sets. To address these limitations, we propose HyperJoin, a large language model (LLM)-augmented Hypergraph framework for Joinable table discovery. Specifically, we first construct a hypergraph to model tables using both the intra-table hyperedges and the LLM-augmented inter-table hyperedges. Consequently, the task of joinable table discovery is formulated as link prediction on this constructed hypergraph. We then design HIN, a Hierarchical Interaction Network that learns expressive column representations through bidirectional message passing over columns and hyperedges. To strengthen coherence and internal consistency in the result columns, we cast online ranking as a coherence-aware top-k column selection problem. We then introduce a reranking module that leverages a maximum spanning tree algorithm to prune noisy connections and maximize coherence. Experiments demonstrate the superiority of HyperJoin, achieving average improvements of 21.4% (Precision@15) and 17.2% (Recall@15) over the best baseline.", "AI": {"tldr": "\u63d0\u51faHyperJoin\u6846\u67b6\u89e3\u51b3\u73b0\u6709\u53ef\u8fde\u63a5\u8868\u53d1\u73b0\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u7ed3\u6784\u4ea4\u4e92\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u8fde\u63a5\u8868\u53d1\u73b0\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u5e95\u5c42\u7ed3\u6784\u4ea4\u4e92\uff0c\u79bb\u7ebf\u5efa\u6a21\u96be\u4ee5\u6355\u6349\u8868\u95f4\u548c\u8868\u5185\u7ed3\u6784\u4fe1\u606f\uff0c\u5728\u7ebf\u6392\u5e8f\u5ffd\u7565\u5019\u9009\u5217\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "method": "\u6784\u5efa\u8d85\u56fe\u5bf9\u8868\u8fdb\u884c\u5efa\u6a21\uff0c\u5c06\u53ef\u8fde\u63a5\u8868\u53d1\u73b0\u4efb\u52a1\u8f6c\u5316\u4e3a\u8d85\u56fe\u4e0a\u7684\u94fe\u63a5\u9884\u6d4b\uff1b\u8bbe\u8ba1HIN\u5b66\u4e60\u5217\u8868\u793a\uff1b\u5c06\u5728\u7ebf\u6392\u5e8f\u8f6c\u5316\u4e3a\u4e00\u81f4\u6027\u611f\u77e5\u7684top - k\u5217\u9009\u62e9\u95ee\u9898\uff0c\u5f15\u5165\u91cd\u6392\u5e8f\u6a21\u5757\u4fee\u526a\u566a\u58f0\u8fde\u63a5\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHyperJoin\u5728Precision@15\u4e0a\u5e73\u5747\u63d0\u534721.4%\uff0c\u5728Recall@15\u4e0a\u5e73\u5747\u63d0\u534717.2%\u3002", "conclusion": "HyperJoin\u5728\u53ef\u8fde\u63a5\u8868\u53d1\u73b0\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.01750", "pdf": "https://arxiv.org/pdf/2601.01750", "abs": "https://arxiv.org/abs/2601.01750", "authors": ["Shayan Alipour", "Mehdi Kargar", "Morteza Zihayat"], "title": "When Attention Becomes Exposure in Generative Search", "categories": ["cs.IR", "cs.CY"], "comment": "8 pages, 2 figures", "summary": "Generative search engines are reshaping information access by replacing traditional ranked lists with synthesized answers and references. In parallel, with the growth of Web3 platforms, incentive-driven creator ecosystems have become an essential part of how enterprises build visibility and community by rewarding creators for contributing to shared narratives. However, the extent to which exposure in generative search engine citations is shaped by external attention markets remains uncertain. In this study, we audit the exposure for 44 Web3 enterprises. First, we show that the creator community around each enterprise is persistent over time. Second, enterprise-specific queries reveal that more popular voices systematically receive greater citation exposure than others. Third, we find that larger follower bases and enterprises with more concentrated creator cores are associated with higher-ranked exposure. Together, these results show that generative search engine citations exhibit exposure bias toward already prominent voices, which risks entrenching incumbents and narrowing viewpoint diversity.", "AI": {"tldr": "\u7814\u7a76\u5bf944\u5bb6Web3\u4f01\u4e1a\u5728\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u4e2d\u7684\u66dd\u5149\u60c5\u51b5\u8fdb\u884c\u5ba1\u8ba1\uff0c\u53d1\u73b0\u5b58\u5728\u66dd\u5149\u504f\u5dee\u3002", "motivation": "\u660e\u786e\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u5f15\u7528\u4e2d\u7684\u66dd\u5149\u53d7\u5916\u90e8\u6ce8\u610f\u529b\u5e02\u573a\u5f71\u54cd\u7684\u7a0b\u5ea6\u3002", "method": "\u5bf944\u5bb6Web3\u4f01\u4e1a\u7684\u66dd\u5149\u60c5\u51b5\u8fdb\u884c\u5ba1\u8ba1\u3002", "result": "\u4f01\u4e1a\u521b\u4f5c\u8005\u793e\u533a\u968f\u65f6\u95f4\u4fdd\u6301\u7a33\u5b9a\uff1b\u66f4\u53d7\u6b22\u8fce\u7684\u58f0\u97f3\u7cfb\u7edf\u5730\u83b7\u5f97\u66f4\u591a\u5f15\u7528\u66dd\u5149\uff1b\u7c89\u4e1d\u57fa\u6570\u5927\u4e14\u521b\u4f5c\u8005\u6838\u5fc3\u66f4\u96c6\u4e2d\u7684\u4f01\u4e1a\u66dd\u5149\u6392\u540d\u66f4\u9ad8\u3002", "conclusion": "\u751f\u6210\u5f0f\u641c\u7d22\u5f15\u64ce\u5f15\u7528\u5bf9\u5df2\u77e5\u540d\u7684\u58f0\u97f3\u5b58\u5728\u66dd\u5149\u504f\u5dee\uff0c\u53ef\u80fd\u5de9\u56fa\u73b0\u6709\u4f01\u4e1a\u5730\u4f4d\u5e76\u7f29\u5c0f\u89c2\u70b9\u591a\u6837\u6027\u3002"}}
{"id": "2601.01082", "pdf": "https://arxiv.org/pdf/2601.01082", "abs": "https://arxiv.org/abs/2601.01082", "authors": ["Bryon Tjanaka", "Henry Chen", "Matthew C. Fontaine", "Stefanos Nikolaidis"], "title": "Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces", "categories": ["cs.LG", "cs.NE"], "comment": "Source code available at https://github.com/icaros-usc/discount-models", "summary": "Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.", "AI": {"tldr": "\u63d0\u51fa\u6298\u6263\u6a21\u578b\u641c\u7d22\uff08DMS\uff09\u7b97\u6cd5\u89e3\u51b3\u9ad8\u7ef4\u8d28\u91cf\u591a\u6837\u6027\u4f18\u5316\u95ee\u9898\uff0c\u5728\u9ad8\u7ef4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8eCMA - MAE\u7b49\u7b97\u6cd5\u3002", "motivation": "\u5f53\u4ee3\u8d28\u91cf\u591a\u6837\u6027\uff08QD\uff09\u7b97\u6cd5\u805a\u7126\u4f4e\u7ef4\u5ea6\u91cf\uff0c\u9ad8\u7ef4\u5ea6\u91cf\u6613\u5931\u771f\uff0cCMA - MAE\u7b97\u6cd5\u5728\u9ad8\u7ef4\u5ea6\u91cf\u7a7a\u95f4\u4f1a\u505c\u6ede\u3002", "method": "\u63d0\u51faDMS\u7b97\u6cd5\uff0c\u7528\u6a21\u578b\u5f15\u5bfc\u63a2\u7d22\uff0c\u63d0\u4f9b\u6298\u6263\u503c\u7684\u5e73\u6ed1\u8fde\u7eed\u8868\u793a\u3002", "result": "\u5728\u9ad8\u7ef4\u56fe\u50cf\u5ea6\u91cf\u7a7a\u95f4\u548c\u9ad8\u7ef4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDMS\u8868\u73b0\u4f18\u4e8eCMA - MAE\u548c\u5176\u4ed6\u9ed1\u76d2QD\u7b97\u6cd5\u3002", "conclusion": "DMS\u80fd\u533a\u5206\u76f8\u4f3c\u5ea6\u91cf\u7684\u89e3\uff0c\u53ef\u7ee7\u7eed\u63a2\u7d22\uff0c\u63a8\u52a8\u4e86\u65b0\u7684QD\u5e94\u7528\u3002"}}
{"id": "2601.01514", "pdf": "https://arxiv.org/pdf/2601.01514", "abs": "https://arxiv.org/abs/2601.01514", "authors": ["Matej Kucera", "Marco Castelluccio", "Daniel Feitosa", "Ayushi Rastogi"], "title": "Group versus Individual Review Requests: Tradeoffs in Speed and Quality at Mozilla Firefox", "categories": ["cs.SE"], "comment": "11 pages, 1 figure, 4 tables. To be published in ICSE-SEIP 2026 conference proceedings", "summary": "The speed at which code changes are integrated into the software codebase, also referred to as code review velocity, is a prevalent industry metric for improved throughput and developer satisfaction. While prior studies have explored factors influencing review velocity, the role of the review assignment process, particularly the `group review request', is unclear. In group review requests, available on platforms like Phabricator, GitHub, and Bitbucket, a code change is assigned to a reviewer group, allowing any member to review it, unlike individual review assignments to specific reviewers. Drawing parallels with shared task queues in Management Sciences, this study examines the effects of group versus individual review requests on velocity and quality. We investigate approximately 66,000 revisions in the Mozilla Firefox project, combining statistical modeling with practitioner views from a focus group discussion. Our study associates group reviews with improved review quality, characterized by fewer regressions, while having a negligible association with review velocity. Additional perceived benefits include balanced work distribution and training opportunities for new reviewers.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u7ec4\u8bc4\u5ba1\u8bf7\u6c42\u4e0e\u4e2a\u4eba\u8bc4\u5ba1\u8bf7\u6c42\u5bf9\u4ee3\u7801\u5ba1\u67e5\u901f\u5ea6\u548c\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7ec4\u8bc4\u5ba1\u4e0e\u5ba1\u67e5\u8d28\u91cf\u63d0\u5347\u6709\u5173\uff0c\u5bf9\u901f\u5ea6\u5f71\u54cd\u53ef\u5ffd\u7565\u3002", "motivation": "\u6b64\u524d\u7814\u7a76\u672a\u660e\u786e\u5ba1\u67e5\u5206\u914d\u8fc7\u7a0b\uff08\u7279\u522b\u662f\u7ec4\u5ba1\u67e5\u8bf7\u6c42\uff09\u5bf9\u4ee3\u7801\u5ba1\u67e5\u901f\u5ea6\u7684\u4f5c\u7528\u3002", "method": "\u8c03\u67e5 Mozilla Firefox \u9879\u76ee\u7ea6 66,000 \u6b21\u4fee\u8ba2\uff0c\u7ed3\u5408\u7edf\u8ba1\u5efa\u6a21\u548c\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\u4e2d\u4ece\u4e1a\u8005\u7684\u89c2\u70b9\u3002", "result": "\u7ec4\u5ba1\u67e5\u4e0e\u5ba1\u67e5\u8d28\u91cf\u63d0\u5347\u76f8\u5173\uff08\u56de\u5f52\u95ee\u9898\u66f4\u5c11\uff09\uff0c\u5bf9\u5ba1\u67e5\u901f\u5ea6\u5f71\u54cd\u53ef\u5ffd\u7565\u3002", "conclusion": "\u7ec4\u5ba1\u67e5\u6709\u63d0\u5347\u5ba1\u67e5\u8d28\u91cf\u3001\u5e73\u8861\u5de5\u4f5c\u5206\u914d\u548c\u4e3a\u65b0\u5ba1\u67e5\u5458\u63d0\u4f9b\u57f9\u8bad\u673a\u4f1a\u7b49\u597d\u5904\u3002"}}
{"id": "2601.00856", "pdf": "https://arxiv.org/pdf/2601.00856", "abs": "https://arxiv.org/abs/2601.00856", "authors": ["Milos Stankovic", "Ella Hirche", "Sarah Kollatzsch", "Julia Nadine Doetsch"], "title": "Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks", "categories": ["cs.AI"], "comment": "Comment on arXiv:2506.08872", "summary": "Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.", "AI": {"tldr": "\u6587\u7ae0\u5bf9Kosmyna\u7b49\u4eba\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u7814\u7a76\u63d0\u51fa\u5efa\u8bbe\u6027\u610f\u89c1\u3002", "motivation": "\u4e3a\u63d0\u9ad8Kosmyna\u7b49\u4eba\u8bba\u6587\u5728\u540c\u884c\u8bc4\u5ba1\u53d1\u8868\u4e2d\u7684\u8d28\u91cf\uff0c\u56e0\u5176\u90e8\u5206\u7ed3\u679c\u53ef\u66f4\u4fdd\u5b88\u89e3\u8bfb\u3002", "method": "\u6307\u51fa\u539f\u7814\u7a76\u5728\u7814\u7a76\u8bbe\u8ba1\u3001\u5206\u6790\u53ef\u91cd\u590d\u6027\u3001\u8111\u7535\u56fe\u5206\u6790\u65b9\u6cd5\u3001\u7ed3\u679c\u62a5\u544a\u548c\u7814\u7a76\u8fc7\u7a0b\u900f\u660e\u5ea6\u7b49\u65b9\u9762\u7684\u95ee\u9898\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c", "conclusion": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba"}}
{"id": "2601.01757", "pdf": "https://arxiv.org/pdf/2601.01757", "abs": "https://arxiv.org/abs/2601.01757", "authors": ["Jiakun Jiang", "Dewei Xiang", "Chenliang Gu", "Wei Liu", "Binhuan Wang"], "title": "Sparse Convex Biclustering", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Biclustering is an essential unsupervised machine learning technique for simultaneously clustering rows and columns of a data matrix, with widespread applications in genomics, transcriptomics, and other high-dimensional omics data. Despite its importance, existing biclustering methods struggle to meet the demands of modern large-scale datasets. The challenges stem from the accumulation of noise in high-dimensional features, the limitations of non-convex optimization formulations, and the computational complexity of identifying meaningful biclusters. These issues often result in reduced accuracy and stability as the size of the dataset increases. To overcome these challenges, we propose Sparse Convex Biclustering (SpaCoBi), a novel method that penalizes noise during the biclustering process to improve both accuracy and robustness. By adopting a convex optimization framework and introducing a stability-based tuning criterion, SpaCoBi achieves an optimal balance between cluster fidelity and sparsity. Comprehensive numerical studies, including simulations and an application to mouse olfactory bulb data, demonstrate that SpaCoBi significantly outperforms state-of-the-art methods in accuracy. These results highlight SpaCoBi as a robust and efficient solution for biclustering in high-dimensional and large-scale datasets.", "AI": {"tldr": "\u73b0\u6709\u53cc\u805a\u7c7b\u65b9\u6cd5\u96be\u6ee1\u8db3\u5927\u89c4\u6a21\u6570\u636e\u96c6\u9700\u6c42\uff0c\u63d0\u51faSpaCoBi\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u9ad8\u7ef4\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u53cc\u805a\u7c7b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u73b0\u4ee3\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5b58\u5728\u566a\u58f0\u7d2f\u79ef\u3001\u975e\u51f8\u4f18\u5316\u5c40\u9650\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u51c6\u786e\u7387\u548c\u7a33\u5b9a\u6027\u4e0b\u964d\u3002", "method": "\u63d0\u51faSparse Convex Biclustering (SpaCoBi)\u65b9\u6cd5\uff0c\u5728\u53cc\u805a\u7c7b\u8fc7\u7a0b\u4e2d\u5bf9\u566a\u58f0\u8fdb\u884c\u60e9\u7f5a\uff0c\u91c7\u7528\u51f8\u4f18\u5316\u6846\u67b6\u5e76\u5f15\u5165\u57fa\u4e8e\u7a33\u5b9a\u6027\u7684\u8c03\u4f18\u51c6\u5219\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u5c0f\u9f20\u55c5\u7403\u6570\u636e\u5e94\u7528\u7684\u7efc\u5408\u6570\u503c\u7814\u7a76\uff0c\u8868\u660eSpaCoBi\u5728\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SpaCoBi\u662f\u9ad8\u7ef4\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u53cc\u805a\u7c7b\u7684\u7a33\u5065\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02311", "pdf": "https://arxiv.org/pdf/2601.02311", "abs": "https://arxiv.org/abs/2601.02311", "authors": ["Deep Pankajbhai Mehta"], "title": "Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies", "categories": ["cs.DC", "cs.AI"], "comment": "8 pages, 3 tables", "summary": "Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.", "AI": {"tldr": "\u63d0\u51fa\u653e\u7f6e\u8bed\u4e49\u6846\u67b6\u9884\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u884c\u7b56\u7565\u884c\u4e3a\uff0c\u9884\u6d4b\u4e0e\u7ed3\u679c\u5339\u914d\uff0c\u8bc1\u660e\u8bad\u7ec3\u6761\u4ef6\u5e76\u63d0\u4f9b\u7ec4\u5408\u89c4\u5219\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u884c\u7b56\u7565\u9009\u62e9\u9760\u8bd5\u9519\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7cfb\u7edf\u6846\u67b6\u9884\u6d4b\u5176\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u653e\u7f6e\u8bed\u4e49\uff0c\u901a\u8fc7\u6307\u5b9a\u7b56\u7565\u5bf9\u56db\u79cd\u8bad\u7ec3\u72b6\u6001\u5728\u8bbe\u5907\u4e0a\u7684\u653e\u7f6e\u6a21\u5f0f\uff0c\u4ece\u653e\u7f6e\u60c5\u51b5\u63a8\u5bfc\u5185\u5b58\u6d88\u8017\u548c\u901a\u4fe1\u91cf\u3002", "result": "\u9884\u6d4b\u7ed3\u679c\u4e0e\u5df2\u53d1\u8868\u7ed3\u679c\u5b8c\u5168\u5339\u914d\uff0c\u5982ZeRO - 3\u5185\u5b58\u4f7f\u7528\u548c\u901a\u4fe1\u6210\u672c\u60c5\u51b5\u3002", "conclusion": "\u6846\u67b6\u7edf\u4e00\u4e86\u591a\u79cd\u5e76\u884c\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u5206\u5e03\u5f0f\u8bad\u7ec3\u5339\u914d\u5355\u8bbe\u5907\u7ed3\u679c\u7684\u6761\u4ef6\u5e76\u63d0\u4f9b\u7ec4\u5408\u89c4\u5219\u3002"}}
{"id": "2601.01361", "pdf": "https://arxiv.org/pdf/2601.01361", "abs": "https://arxiv.org/abs/2601.01361", "authors": ["Duosi Jin", "Jianqiu Xu", "Guidong Zhang"], "title": "VARTS: A Tool for the Visualization and Analysis of Representative Time Series Data", "categories": ["cs.GR", "cs.DB", "cs.SE"], "comment": null, "summary": "Large-scale time series visualization often suffers from excessive visual clutter and redundant patterns, making it difficult for users to understand the main temporal trends. To address this challenge, we present VARTS, an interactive visual analytics tool for representative time series selection and visualization. Building upon our previous work M4-Greedy, VARTS integrates M4-based sampling, DTW-based similarity computation, and greedy selection into a unified workflow for the identification and visualization of representative series. The tool provides a responsive graphical interface that allows users to import time series datasets, perform representative selection, and visualize both raw and reduced data through multiple coordinated views. By reducing redundancy while preserving essential data patterns, VARTS effectively enhances visual clarity and interpretability for large-scale time series analysis. The demo video is available at https://youtu.be/mS9f12Rf0jo.", "AI": {"tldr": "\u63d0\u51faVARTS\u5de5\u5177\u89e3\u51b3\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u7684\u6742\u4e71\u95ee\u9898\uff0c\u63d0\u5347\u53ef\u89c6\u6e05\u6670\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u53ef\u89c6\u5316\u4e2d\u89c6\u89c9\u6742\u4e71\u548c\u6a21\u5f0f\u5197\u4f59\u95ee\u9898\uff0c\u4fbf\u4e8e\u7528\u6237\u7406\u89e3\u65f6\u95f4\u8d8b\u52bf\u3002", "method": "\u5728M4 - Greedy\u57fa\u7840\u4e0a\uff0c\u5c06M4\u91c7\u6837\u3001DTW\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u548c\u8d2a\u5fc3\u9009\u62e9\u96c6\u6210\u5230\u7edf\u4e00\u5de5\u4f5c\u6d41\u4e2d\uff0c\u63d0\u4f9b\u4ea4\u4e92\u5f0f\u56fe\u5f62\u754c\u9762\u3002", "result": "VARTS\u5de5\u5177\u80fd\u5728\u51cf\u5c11\u5197\u4f59\u7684\u540c\u65f6\u4fdd\u7559\u6570\u636e\u5173\u952e\u6a21\u5f0f\u3002", "conclusion": "VARTS\u6709\u6548\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u89c6\u89c9\u6e05\u6670\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2601.01751", "pdf": "https://arxiv.org/pdf/2601.01751", "abs": "https://arxiv.org/abs/2601.01751", "authors": ["Samaneh Mohtadi", "Gianluca Demartini"], "title": "Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "Accepted for presentation at the ECIR 2026 Full Papers track", "summary": "Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u76f8\u5173\u6027\u8bc4\u4f30\u5668\u65f6\u662f\u5426\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u5206\u6790\u6807\u7b7e\u5206\u5e03\u3001\u5b9a\u4f4d\u5206\u6b67\u70b9\uff0c\u5b9e\u9a8c\u53d1\u73b0\u4eba\u4e0eLLMs\u7684\u5206\u6b67\u96c6\u4e2d\u5728\u7279\u5b9a\u8bed\u4e49\u7c07\uff1b\u67e5\u8be2\u5c42\u9762\u5206\u6790\u663e\u793a\u7279\u5b9a\u8bed\u5883\u6613\u51fa\u73b0\u95ee\u9898\uff1b\u8be5\u6846\u67b6\u53ef\u63ed\u793aLLM\u5224\u65ad\u5f31\u70b9\uff0c\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u4fe1\u606f\u68c0\u7d22\u8bc4\u4f30\u3002", "motivation": "\u7406\u89e3LLMs\u5728\u5224\u65ad\u76f8\u5173\u6027\u65f6\u662f\u5426\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u5176\u5e73\u5747\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u67e5\u8be2\u548c\u6587\u6863\u8868\u793a\u65b9\u6cd5\uff0c\u5f15\u5165\u57fa\u4e8e\u805a\u7c7b\u7684\u6846\u67b6\u5c06\u67e5\u8be2 - \u6587\u6863\u5bf9\u5d4c\u5165\u8054\u5408\u8bed\u4e49\u7a7a\u95f4\uff0c\u5c06\u76f8\u5173\u6027\u89c6\u4e3a\u5173\u7cfb\u5c5e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4eba\u4e0eLLMs\u7684\u7cfb\u7edf\u6027\u5206\u6b67\u96c6\u4e2d\u5728\u7279\u5b9a\u8bed\u4e49\u7c07\uff1b\u67e5\u8be2\u5c42\u9762\u5206\u6790\u663e\u793a\uff0c\u5b9a\u4e49\u3001\u653f\u7b56\u76f8\u5173\u6216\u6a21\u7cca\u8bed\u5883\u5e38\u51fa\u73b0\u95ee\u9898\uff1b\u67d0\u4e9b\u67e5\u8be2\u4e0d\u540c\u7c07\u7684\u4e00\u81f4\u6027\u5dee\u5f02\u5927\uff0c\u662f\u5206\u6b67\u70ed\u70b9\uff0cLLMs\u6613\u6f0f\u68c0\u76f8\u5173\u5185\u5bb9\u6216\u8bef\u5305\u542b\u65e0\u5173\u5185\u5bb9\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u5c06\u5168\u5c40\u8bca\u65ad\u4e0e\u5c40\u90e8\u805a\u7c7b\u76f8\u7ed3\u5408\uff0c\u63ed\u793aLLM\u5224\u65ad\u7684\u9690\u85cf\u5f31\u70b9\uff0c\u5b9e\u73b0\u6709\u504f\u611f\u77e5\u4e14\u66f4\u53ef\u9760\u7684\u4fe1\u606f\u68c0\u7d22\u8bc4\u4f30\u3002"}}
{"id": "2601.01150", "pdf": "https://arxiv.org/pdf/2601.01150", "abs": "https://arxiv.org/abs/2601.01150", "authors": ["Wenbin Pei", "Ruohao Dai", "Bing Xue", "Mengjie Zhang", "Qiang Zhang", "Yiu-Ming Cheung"], "title": "Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u8fdb\u5316\u8fc7\u91c7\u6837\u65b9\u6cd5Evo - TFS\u5904\u7406\u4e0d\u5e73\u8861\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5904\u7406\u4e0d\u5e73\u8861\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65f6\u5ffd\u7565\u5c11\u6570\u7c7b\uff0c\u73b0\u6709\u8fc7\u91c7\u6837\u65b9\u6cd5\u96be\u4fdd\u7559\u65f6\u95f4\u52a8\u6001\u548c\u751f\u6210\u591a\u6837\u6837\u672c\u3002", "method": "\u63d0\u51faEvo - TFS\uff0c\u7528\u5f3a\u7c7b\u578b\u9057\u4f20\u7f16\u7a0b\uff0c\u7ed3\u5408\u65f6\u9891\u57df\u7279\u5f81\u7684\u9002\u5e94\u5ea6\u51fd\u6570\u8fdb\u5316\u591a\u6837\u9ad8\u8d28\u91cf\u65f6\u95f4\u5e8f\u5217\u3002", "result": "\u5728\u4e0d\u5e73\u8861\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cEvo - TFS\u4f18\u4e8e\u73b0\u6709\u8fc7\u91c7\u6837\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u65f6\u9891\u57df\u5206\u7c7b\u5668\u6027\u80fd\u3002", "conclusion": "Evo - TFS\u662f\u5904\u7406\u4e0d\u5e73\u8861\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2601.01602", "pdf": "https://arxiv.org/pdf/2601.01602", "abs": "https://arxiv.org/abs/2601.01602", "authors": ["Henry Ndou"], "title": "MTS-1: A Lightweight Delta-Encoded Telemetry Format optimised for Low-Resource Environments and Offline-First System Health Monitoring", "categories": ["cs.SE"], "comment": "4 figures, 1 table. Technical report on the MTS-1 telemetry format. Direct correspondence to henry.ndou@nust.ac.zw", "summary": "System-level telemetry is fundamental to modern remote monitoring, predictive maintenance, and AI-driven infrastructure optimisation. Existing telemetry encodings such as JSON, JSON Lines, CBOR, and Protocol Buffers were designed for high-bandwidth, always-online environments. They impose significant overhead when deployed in bandwidth-constrained networks common across Sub-Saharan Africa, rural enterprise deployments, and unstable LAN environments. This paper introduces MTS-1 (Magenta Telemetry Standard v1), a novel delta-encoded binary telemetry format designed for offline-first system monitoring, LAN-assisted proxy delivery, and energy-efficient IoT-to-server transmission. We compare MTS-1 against JSON, JSON Lines, CBOR, MessagePack, and Protocol Buffers across payload size, encoding cost, network efficiency, and cost-latency performance. Synthetic benchmarking demonstrates preliminary compression improvements of up to 74.7% versus JSON and 5.4% versus MessagePack, with linear scaling characteristics across dataset sizes.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u65b0\u578b\u9065\u6d4b\u683c\u5f0fMTS - 1\uff0c\u5bf9\u6bd4\u591a\u79cd\u73b0\u6709\u7f16\u7801\u683c\u5f0f\uff0c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u5176\u6709\u538b\u7f29\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u9065\u6d4b\u7f16\u7801\u5728\u5e26\u5bbd\u53d7\u9650\u7f51\u7edc\u4e2d\u5f00\u9500\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u79bb\u7ebf\u4f18\u5148\u7cfb\u7edf\u76d1\u63a7\u7b49\u573a\u666f\u3002", "method": "\u5f15\u5165MTS - 1\u683c\u5f0f\uff0c\u5e76\u5c06\u5176\u4e0eJSON\u3001JSON Lines\u7b49\u683c\u5f0f\u5728\u6709\u6548\u8d1f\u8f7d\u5927\u5c0f\u3001\u7f16\u7801\u6210\u672c\u7b49\u65b9\u9762\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u4e0eJSON\u76f8\u6bd4\u538b\u7f29\u7387\u6700\u9ad8\u63d0\u534774.7%\uff0c\u4e0eMessagePack\u76f8\u6bd4\u63d0\u53475.4%\uff0c\u4e14\u5728\u4e0d\u540c\u6570\u636e\u96c6\u5927\u5c0f\u4e0a\u5448\u7ebf\u6027\u7f29\u653e\u7279\u5f81\u3002", "conclusion": "MTS - 1\u5728\u5e26\u5bbd\u53d7\u9650\u7f51\u7edc\u4e0b\u6709\u66f4\u597d\u7684\u6027\u80fd\uff0c\u53ef\u7528\u4e8e\u79bb\u7ebf\u4f18\u5148\u7cfb\u7edf\u76d1\u63a7\u7b49\u3002"}}
{"id": "2601.00869", "pdf": "https://arxiv.org/pdf/2601.00869", "abs": "https://arxiv.org/abs/2601.00869", "authors": ["Huang Junyao", "Situ Ruimin", "Ye Renqin"], "title": "Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery", "categories": ["cs.AI"], "comment": "19 pages, 5 tables. Dataset and code available at https://github.com/zhizibianjie-omniedge/geo-cultural-encoding", "summary": "As artificial intelligence systems increasingly mediate consumer information discovery,\n  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large\n  Language Models (LLMs) -- systematic differences in brand recommendations arising from\n  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,\n  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6\n  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,\n  p<.001). This disparity persists in identical English queries, indicating training data\n  geography -- not language -- drives the effect. We introduce the Existence Gap: brands\n  absent from LLM training corpora lack \"existence\" in AI responses regardless of quality.\n  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%\n  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how\n  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we\n  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic\n  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility\n  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization\n  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats\n  through semantic coverage, technical depth, and cultural localization. Our findings reveal\n  that in AI-mediated markets, the limits of a brand's \"Data Boundaries\" define the limits\n  of its \"Market Frontiers.\"", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u54c1\u724c\u63a8\u8350\u7684\u6587\u5316\u7f16\u7801\u5dee\u5f02\uff0c\u53d1\u73b0\u4e2d\u6587LLMs\u54c1\u724c\u63d0\u53ca\u7387\u9ad8\u4e8e\u56fd\u9645LLMs\uff0c\u63d0\u51fa\u5b58\u5728\u5dee\u8ddd\u548c\u6570\u636e\u62a4\u57ce\u6cb3\u6846\u67b6\uff0c\u7ed9\u51fa\u54c1\u724c\u5efa\u8bbe\u6570\u636e\u62a4\u57ce\u6cb3\u8def\u7ebf\u56fe\u3002", "motivation": "\u5728\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4ecb\u5bfc\u6d88\u8d39\u8005\u4fe1\u606f\u53d1\u73b0\u3001\u54c1\u724c\u9762\u4e34\u7b97\u6cd5\u4e0d\u53ef\u89c1\u6027\u7684\u80cc\u666f\u4e0b\uff0c\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u56e0\u8bad\u7ec3\u6570\u636e\u7ec4\u6210\u4ea7\u751f\u7684\u54c1\u724c\u63a8\u8350\u5dee\u5f02\u3002", "method": "\u5206\u67906\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u300130\u4e2a\u54c1\u724c\u76841909\u4e2a\u7eaf\u82f1\u6587\u67e5\u8be2\uff0c\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u4e2d\u6587LLMs\u54c1\u724c\u63d0\u53ca\u7387\u6bd4\u56fd\u9645LLMs\u9ad830.6\u4e2a\u767e\u5206\u70b9\uff0c\u5b58\u5728\u5dee\u8ddd\u5bfc\u81f4\u54c1\u724c\u5728AI\u54cd\u5e94\u4e2d\u7f3a\u5931\uff0c\u8bed\u8a00\u8fb9\u754c\u969c\u788d\u9020\u6210\u5e02\u573a\u8fdb\u5165\u969c\u788d\u3002", "conclusion": "\u63d0\u51fa\u6570\u636e\u62a4\u57ce\u6cb3\u6846\u67b6\uff0c\u5c06\u7b97\u6cd5\u65e0\u5904\u4e0d\u5728\u4f5c\u4e3a\u751f\u6210\u5f15\u64ce\u4f18\u5316\u6218\u7565\u76ee\u6807\uff0c\u7ed9\u51fa\u54c1\u724c\u5efa\u8bbe\u6570\u636e\u62a4\u57ce\u6cb3\u8def\u7ebf\u56fe\uff0c\u54c1\u724c\u7684\u6570\u636e\u8fb9\u754c\u51b3\u5b9a\u5e02\u573a\u8fb9\u754c\u3002"}}
{"id": "2601.01970", "pdf": "https://arxiv.org/pdf/2601.01970", "abs": "https://arxiv.org/abs/2601.01970", "authors": ["Ayomide Afolabi", "Ebere Ogburu", "Symon Kimitei"], "title": "A Multilayered Approach to Classifying Customer Responsiveness and Credit Risk", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": null, "summary": "This study evaluates the performance of various classifiers in three distinct models: response, risk, and response-risk, concerning credit card mail campaigns and default prediction. In the response model, the Extra Trees classifier demonstrates the highest recall level (79.1%), emphasizing its effectiveness in identifying potential responders to targeted credit card offers. Conversely, in the risk model, the Random Forest classifier exhibits remarkable specificity of 84.1%, crucial for identifying customers least likely to default. Furthermore, in the multi-class response-risk model, the Random Forest classifier achieves the highest accuracy (83.2%), indicating its efficacy in discerning both potential responders to credit card mail campaign and low-risk credit card users. In this study, we optimized various performance metrics to solve a specific credit risk and mail responsiveness business problem.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e09\u79cd\u6a21\u578b\u4e2d\u5404\u7c7b\u5206\u7c7b\u5668\u5728\u4fe1\u7528\u5361\u90ae\u4ef6\u8425\u9500\u548c\u8fdd\u7ea6\u9884\u6d4b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4e0d\u540c\u6a21\u578b\u4e0b\u5404\u6709\u6700\u4f18\u5206\u7c7b\u5668\u3002", "motivation": "\u89e3\u51b3\u7279\u5b9a\u7684\u4fe1\u7528\u98ce\u9669\u548c\u90ae\u4ef6\u54cd\u5e94\u4e1a\u52a1\u95ee\u9898\u3002", "method": "\u8bc4\u4f30\u4e0d\u540c\u5206\u7c7b\u5668\u5728\u54cd\u5e94\u3001\u98ce\u9669\u548c\u54cd\u5e94 - \u98ce\u9669\u4e09\u79cd\u6a21\u578b\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4f18\u5316\u5404\u79cd\u6027\u80fd\u6307\u6807\u3002", "result": "\u54cd\u5e94\u6a21\u578b\u4e2dExtra Trees\u5206\u7c7b\u5668\u53ec\u56de\u7387\u6700\u9ad8\uff1b\u98ce\u9669\u6a21\u578b\u4e2dRandom Forest\u5206\u7c7b\u5668\u7279\u5f02\u6027\u9ad8\uff1b\u54cd\u5e94 - \u98ce\u9669\u6a21\u578b\u4e2dRandom Forest\u5206\u7c7b\u5668\u51c6\u786e\u7387\u6700\u9ad8\u3002", "conclusion": "\u4e0d\u540c\u6a21\u578b\u4e0b\u5404\u6709\u8868\u73b0\u6700\u4f18\u7684\u5206\u7c7b\u5668\uff0c\u53ef\u7528\u4e8e\u4fe1\u7528\u5361\u90ae\u4ef6\u8425\u9500\u548c\u8fdd\u7ea6\u9884\u6d4b\u3002"}}
{"id": "2601.01298", "pdf": "https://arxiv.org/pdf/2601.01298", "abs": "https://arxiv.org/abs/2601.01298", "authors": ["Jorge L. Ruiz Williams"], "title": "Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.DC", "cs.MA"], "comment": null, "summary": "Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering \"System 2\" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.", "AI": {"tldr": "\u63d0\u51faWarp Cortex\u5f02\u6b65\u67b6\u6784\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\u5185\u5b58\u7ebf\u6027\u6269\u5c55\u95ee\u9898\uff0c\u964d\u4f4e\u5185\u5b58\u590d\u6742\u5ea6\uff0c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u8ba4\u77e5\u6269\u5c55\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\u5b58\u5728\u5185\u5b58\u7ebf\u6027\u6269\u5c55\u95ee\u9898\uff0c\u4f7f\u2018System 2\u2019\u5e76\u884c\u63a8\u7406\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51faWarp Cortex\u5f02\u6b65\u67b6\u6784\uff0c\u91c7\u7528Singleton Weight Sharing\u548c\u53d7\u62d3\u6251\u6570\u636e\u5206\u6790\u542f\u53d1\u7684Topological Synapse\uff0c\u5c06KV - cache\u89c6\u4e3a\u6f5c\u7a7a\u95f4\u7684\u70b9\u4e91\u8fdb\u884c\u7a00\u758f\u5316\uff0c\u5f15\u5165Referential Injection\u3002", "result": "\u5728\u5355\u5757NVIDIA RTX 4090\u4e0a\uff0c2.2 GB\u603b\u663e\u5b58\u53ef\u5b9e\u73b0100\u4e2a\u5e76\u53d1\u667a\u80fd\u4f53\uff0c\u7406\u8bba\u5bb9\u91cf\u8d851000\u4e2a\u667a\u80fd\u4f53\u3002", "conclusion": "Warp Cortex\u67b6\u6784\u901a\u8fc7\u89e3\u8026\u667a\u80fd\u4f53\u903b\u8f91\u548c\u7269\u7406\u5185\u5b58\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5185\u5b58\u6269\u5c55\u95ee\u9898\uff0c\u53ef\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u8ba4\u77e5\u6269\u5c55\u3002"}}
{"id": "2601.01473", "pdf": "https://arxiv.org/pdf/2601.01473", "abs": "https://arxiv.org/abs/2601.01473", "authors": ["Myung-Hwan Jang", "Jeong-Min Park", "Yunyong Ko", "Sang-Wook Kim"], "title": "Accelerating Storage-Based Training for Graph Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.DB"], "comment": "10 pages, 12 figures, 2 tables, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) 2026", "summary": "Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, \\textit{a storage-based approach to GNN training} has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: \\textit{how to handle a large number of small storage I/Os}. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named \\textsf{AGNES}, that employs a method of \\textit{block-wise storage I/O processing} to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, \\textsf{AGNES} employs a simple yet effective strategy, \\textit{hyperbatch-based processing} based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that \\textsf{AGNES} consistently outperforms four state-of-the-art methods, by up to 4.1$\\times$ faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5b58\u50a8\u5f0fGNN\u8bad\u7ec3\u6570\u636e\u51c6\u5907\u74f6\u9888\uff0c\u63d0\u51faAGNES\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u7ade\u54c1\u3002", "motivation": "\u73b0\u6709\u5b58\u50a8\u5f0fGNN\u8bad\u7ec3\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u51c6\u5907\u74f6\u9888\uff0c\u5ffd\u89c6\u5904\u7406\u5927\u91cf\u5c0f\u5b58\u50a8I/O\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faAGNES\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5757\u5b58\u50a8I/O\u5904\u7406\u548c\u57fa\u4e8e\u8d85\u6279\u6b21\u5904\u7406\u7684\u7b56\u7565\u3002", "result": "\u5728\u4e94\u4e2a\u771f\u5b9e\u56fe\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAGNES\u6bd4\u56db\u4e2a\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u5feb\uff0c\u6700\u9ad8\u53ef\u8fbe4.1\u500d\u3002", "conclusion": "AGNES\u53ef\u6709\u6548\u89e3\u51b3\u5b58\u50a8\u5f0fGNN\u8bad\u7ec3\u6570\u636e\u51c6\u5907\u7684\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2601.01753", "pdf": "https://arxiv.org/pdf/2601.01753", "abs": "https://arxiv.org/abs/2601.01753", "authors": ["Hyunsoo Kim", "Jaewan Moon", "Seongmin Park", "Jongwuk Lee"], "title": "MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted by KDD 2026", "summary": "Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.", "AI": {"tldr": "\u63d0\u51faMergeRec\u6846\u67b6\u89e3\u51b3\u6570\u636e\u9694\u79bb\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u8de8\u57df\u6cdb\u5316\uff0c\u73b0\u6709\u8de8\u57df\u63a8\u8350\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faMergeRec\u6846\u67b6\uff0c\u5305\u542b\u5408\u5e76\u521d\u59cb\u5316\u3001\u4f2a\u7528\u6237\u6570\u636e\u6784\u5efa\u3001\u534f\u4f5c\u5408\u5e76\u4f18\u5316\u4e09\u4e2a\u7ec4\u4ef6\u3002", "result": "MergeRec\u4fdd\u7559\u539f\u6a21\u578b\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6027\u80fd\u5e73\u5747\u63d0\u5347\u8fbe17.21%\uff08Recall@10\uff09\u3002", "conclusion": "\u6a21\u578b\u5408\u5e76\u662f\u6784\u5efa\u901a\u7528\u63a8\u8350\u7cfb\u7edf\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.01756", "pdf": "https://arxiv.org/pdf/2601.01756", "abs": "https://arxiv.org/abs/2601.01756", "authors": ["N. Sukumar", "Ritwick Roy"], "title": "A Wachspress-based transfinite formulation for exactly enforcing Dirichlet boundary conditions on convex polygonal domains in physics-informed neural networks", "categories": ["math.NA", "cs.NE"], "comment": "47 pages, 21 figures", "summary": "In this paper, we present a Wachspress-based transfinite formulation on convex polygonal domains for exact enforcement of Dirichlet boundary conditions in physics-informed neural networks. This approach leverages prior advances in geometric design such as blending functions and transfinite interpolation over convex domains. For prescribed Dirichlet boundary function $\\mathcal{B}$, the transfinite interpolant of $\\mathcal{B}$, $g : \\bar P \\to C^0(\\bar P)$, $\\textit{lifts}$ functions from the boundary of a two-dimensional polygonal domain to its interior. The trial function is expressed as the difference between the neural network's output and the extension of its boundary restriction into the interior of the domain, with $g$ added to it. This ensures kinematic admissibility of the trial function in the deep Ritz method. Wachspress coordinates for an $n$-gon are used in the transfinite formula, which generalizes bilinear Coons transfinite interpolation on rectangles to convex polygons. The neural network trial function has a bounded Laplacian, thereby overcoming a limitation in a previous contribution where approximate distance functions were used to exactly enforce Dirichlet boundary conditions. For a point $\\boldsymbol{x} \\in \\bar{P}$, Wachspress coordinates, $\\boldsymbol\u03bb : \\bar P \\to [0,1]^n$, serve as a geometric feature map for the neural network: $\\boldsymbol\u03bb$ encodes the boundary edges of the polygonal domain. This offers a framework for solving problems on parametrized convex geometries using neural networks. The accuracy of physics-informed neural networks and deep Ritz is assessed on forward, inverse, and parametrized geometric Poisson boundary-value problems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eWachspress\u7684\u8d85\u9650\u516c\u5f0f\u7528\u4e8e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u4e2d\u7cbe\u786e\u5b9e\u65bd\u72c4\u5229\u514b\u96f7\u8fb9\u754c\u6761\u4ef6\uff0c\u8bc4\u4f30\u4e86\u5176\u5728\u4e0d\u540c\u6cca\u677e\u8fb9\u503c\u95ee\u9898\u4e0a\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u4e2d\u7cbe\u786e\u5b9e\u65bd\u72c4\u5229\u514b\u96f7\u8fb9\u754c\u6761\u4ef6\u7684\u95ee\u9898\uff0c\u514b\u670d\u5148\u524d\u4f7f\u7528\u8fd1\u4f3c\u8ddd\u79bb\u51fd\u6570\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u89e3\u51b3\u53c2\u6570\u5316\u51f8\u51e0\u4f55\u95ee\u9898\u7684\u6846\u67b6\u3002", "method": "\u5229\u7528\u51e0\u4f55\u8bbe\u8ba1\u7684\u6210\u679c\uff0c\u5982\u6df7\u5408\u51fd\u6570\u548c\u8d85\u9650\u63d2\u503c\uff0c\u4f7f\u7528Wachspress\u5750\u6807\u7684\u8d85\u9650\u516c\u5f0f\uff0c\u5c06\u8bd5\u9a8c\u51fd\u6570\u8868\u793a\u4e3a\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u4e0e\u8fb9\u754c\u9650\u5236\u6269\u5c55\u7684\u5dee\u503c\u52a0\u4e0a\u8d85\u9650\u63d2\u503c\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u8bd5\u9a8c\u51fd\u6570\u6709\u6709\u754c\u62c9\u666e\u62c9\u65af\u7b97\u5b50\uff0c\u53ef\u7528\u4e8e\u89e3\u51b3\u53c2\u6570\u5316\u51f8\u51e0\u4f55\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u63d0\u9ad8\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u91cc\u5179\u6cd5\u5728\u4e0d\u540c\u6cca\u677e\u8fb9\u503c\u95ee\u9898\u4e0a\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2601.01780", "pdf": "https://arxiv.org/pdf/2601.01780", "abs": "https://arxiv.org/abs/2601.01780", "authors": ["Arsham Khosravani", "Alireza Hosseinpour", "Arshia Akhavan", "Mehdi Keshani", "Abbas Heydarnoori"], "title": "LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u95ee\u9898\u5206\u914d\u65b9\u6cd5LIA\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u8ba9\u6a21\u578b\u5b66\u4e60\u5386\u53f2\u5206\u914d\u6a21\u5f0f\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u8fdc\u8d85\u57fa\u7ebf\u3002", "motivation": "\u624b\u52a8\u95ee\u9898\u5206\u914d\u6613\u51fa\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6570\u636e\u6216\u5173\u7cfb\u4fe1\u606f\uff0c\u5b58\u5728\u6570\u636e\u7a00\u758f\u548c\u566a\u58f0\u95ee\u9898\uff0c\u6548\u679c\u53d7\u9650\u3002", "method": "\u91c7\u7528\u76d1\u7763\u5fae\u8c03\u65b9\u5f0f\uff0c\u4f7f\u7528DeepSeek - R1 - Distill - Llama - 8B\u6a21\u578b\uff0c\u5229\u7528\u5176\u9884\u8bad\u7ec3\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4ece\u95ee\u9898\u6807\u9898\u548c\u63cf\u8ff0\u751f\u6210\u5f00\u53d1\u8005\u63a8\u8350\u6392\u540d\u3002", "result": "LIA\u6bd4\u57fa\u7840\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u73b0\u6709\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff0cHit@1\u6700\u9ad8\u63d0\u5347+187.8%\u548c+211.2%\u3002", "conclusion": "\u9886\u57df\u9002\u914d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u8f6f\u4ef6\u7ef4\u62a4\u4efb\u52a1\u6709\u6548\uff0cLIA\u662f\u5b9e\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u95ee\u9898\u5206\u914d\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00880", "pdf": "https://arxiv.org/pdf/2601.00880", "abs": "https://arxiv.org/abs/2601.00880", "authors": ["Anthony Mikinka"], "title": "Universal Conditional Logic: A Formal Language for Prompt Engineering", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.PL", "cs.SE"], "comment": "25 pages, 15 figures, 5 tables. Includes appendices with variable reference, pattern library, and O_s calculation examples. Supplementary materials: V1-V4.1 prompt source code and 305 model responses available at GitHub repositories", "summary": "We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.", "AI": {"tldr": "\u63d0\u51fa\u901a\u7528\u6761\u4ef6\u903b\u8f91\uff08UCL\uff09\u6846\u67b6\u7528\u4e8e\u63d0\u793a\u4f18\u5316\uff0c\u7cfb\u7edf\u8bc4\u4f30\u663e\u793a\u80fd\u663e\u8457\u51cf\u5c11\u4ee4\u724c\u548c\u6210\u672c\uff0c\u89e3\u91ca\u4e86\u6027\u80fd\u5dee\u5f02\uff0c\u9a8c\u8bc1\u6838\u5fc3\u673a\u5236\uff0c\u6307\u51fa\u6700\u4f18\u914d\u7f6e\u56e0\u6a21\u578b\u67b6\u6784\u800c\u5f02\u3002", "motivation": "\u5c06\u63d0\u793a\u5de5\u7a0b\u4ece\u542f\u53d1\u5f0f\u5b9e\u8df5\u8f6c\u53d8\u4e3a\u7cfb\u7edf\u4f18\u5316\u3002", "method": "\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff08N=305\uff0c11 \u4e2a\u6a21\u578b\uff0c4 \u6b21\u8fed\u4ee3\uff09\uff0c\u901a\u8fc7\u7ed3\u6784\u5f00\u9500\u51fd\u6570\u7b49\u5206\u6790\u3002", "result": "\u5b9e\u73b0 29.8%\u7684\u4ee4\u724c\u51cf\u5c11\u548c\u6210\u672c\u8282\u7701\uff0c\u89e3\u91ca\u7248\u672c\u7279\u5b9a\u6027\u80fd\u5dee\u5f02\uff0c\u9a8c\u8bc1\u6838\u5fc3\u673a\u5236\uff0c\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u6709\u4e0d\u540c\u6700\u4f18\u914d\u7f6e\u3002", "conclusion": "UCL \u662f\u53ef\u6821\u51c6\u7684\u9ad8\u6548\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u6846\u67b6\uff0c\u6a21\u578b\u5bb6\u65cf\u7279\u5b9a\u4f18\u5316\u662f\u5173\u952e\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.02241", "pdf": "https://arxiv.org/pdf/2601.02241", "abs": "https://arxiv.org/abs/2601.02241", "authors": ["Svenja Jedhoff", "Elizaveta Semenova", "Aura Raulo", "Anne Meyer", "Paul-Christian B\u00fcrkner"], "title": "From Mice to Trains: Amortized Bayesian Inference on Graph Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graphs arise across diverse domains, from biology and chemistry to social and information networks, as well as in transportation and logistics. Inference on graph-structured data requires methods that are permutation-invariant, scalable across varying sizes and sparsities, and capable of capturing complex long-range dependencies, making posterior estimation on graph parameters particularly challenging. Amortized Bayesian Inference (ABI) is a simulation-based framework that employs generative neural networks to enable fast, likelihood-free posterior inference. We adapt ABI to graph data to address these challenges to perform inference on node-, edge-, and graph-level parameters. Our approach couples permutation-invariant graph encoders with flexible neural posterior estimators in a two-module pipeline: a summary network maps attributed graphs to fixed-length representations, and an inference network approximates the posterior over parameters. In this setting, several neural architectures can serve as the summary network. In this work we evaluate multiple architectures and assess their performance on controlled synthetic settings and two real-world domains - biology and logistics - in terms of recovery and calibration.", "AI": {"tldr": "\u672c\u6587\u5c06\u644a\u9500\u8d1d\u53f6\u65af\u63a8\u7406\uff08ABI\uff09\u5e94\u7528\u4e8e\u56fe\u6570\u636e\uff0c\u8bbe\u8ba1\u4e24\u6a21\u5757\u7ba1\u9053\u8fdb\u884c\u8282\u70b9\u3001\u8fb9\u548c\u56fe\u7ea7\u53c2\u6570\u63a8\u7406\uff0c\u5e76\u8bc4\u4f30\u591a\u79cd\u67b6\u6784\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u56fe\u7ed3\u6784\u6570\u636e\u63a8\u7406\u9700\u6ee1\u8db3\u6392\u5217\u4e0d\u53d8\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6355\u6349\u957f\u7a0b\u4f9d\u8d56\u7684\u8981\u6c42\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u56fe\u53c2\u6570\u540e\u9a8c\u4f30\u8ba1\u4e0a\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u5c06ABI\u5e94\u7528\u4e8e\u56fe\u6570\u636e\uff0c\u91c7\u7528\u4e24\u6a21\u5757\u7ba1\u9053\uff0c\u5373\u6458\u8981\u7f51\u7edc\u5c06\u5c5e\u6027\u56fe\u6620\u5c04\u5230\u56fa\u5b9a\u957f\u5ea6\u8868\u793a\uff0c\u63a8\u7406\u7f51\u7edc\u8fd1\u4f3c\u53c2\u6570\u540e\u9a8c\uff0c\u8bc4\u4f30\u591a\u79cd\u795e\u7ecf\u67b6\u6784\u4f5c\u4e3a\u6458\u8981\u7f51\u7edc\u3002", "result": "\u5728\u53d7\u63a7\u5408\u6210\u8bbe\u7f6e\u548c\u751f\u7269\u5b66\u3001\u7269\u6d41\u4e24\u4e2a\u771f\u5b9e\u9886\u57df\u8bc4\u4f30\u591a\u79cd\u67b6\u6784\u7684\u6062\u590d\u548c\u6821\u51c6\u6027\u80fd\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u6697\u793a\u4e86\u4e0d\u540c\u67b6\u6784\u5728\u56fe\u6570\u636e\u63a8\u7406\u4e2d\u6709\u4e0d\u540c\u8868\u73b0\uff0c\u53ef\u6307\u5bfc\u540e\u7eed\u67b6\u6784\u9009\u62e9\u3002"}}
{"id": "2601.01703", "pdf": "https://arxiv.org/pdf/2601.01703", "abs": "https://arxiv.org/abs/2601.01703", "authors": ["Qing Sima", "Xiaoyang Wang", "Wenjie Zhang"], "title": "Beyond Homophily: Community Search on Heterophilic Graphs", "categories": ["cs.SI", "cs.AI", "cs.DB", "cs.IR"], "comment": null, "summary": "Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a unified framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup.", "AI": {"tldr": "\u9488\u5bf9\u5f02\u8d28\u6027\u56fe\u793e\u533a\u641c\u7d22\u96be\u9898\u63d0\u51faAdaptCS\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u7ecf\u5178\u7b97\u6cd5\u548c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6a21\u578b\u5728\u5f02\u8d28\u6027\u56fe\u4e0a\u96be\u4ee5\u6709\u6548\u8fdb\u884c\u793e\u533a\u641c\u7d22\uff0c\u7b97\u6cd5\u65b9\u6cd5\u6613\u8fd4\u56de\u6df7\u5408\u7c7b\u6807\u7b7e\u793e\u533a\uff0cGNN\u4f1a\u6a21\u7cca\u793e\u533a\u8fb9\u754c\u3002", "method": "\u63d0\u51faAdaptive Community Search (AdaptCS)\u7edf\u4e00\u6846\u67b6\uff0c\u5305\u542b\u53ef\u5206\u79bb\u591a\u8df3\u548c\u591a\u9891\u7387\u4fe1\u53f7\u7684\u7f16\u7801\u5668\u3001\u51cf\u5c11\u8ba1\u7b97\u74f6\u9888\u7684\u4f4e\u79e9\u4f18\u5316\u3001\u5e73\u8861\u5d4c\u5165\u76f8\u4f3c\u6027\u548c\u62d3\u6251\u5173\u7cfb\u7684\u81ea\u9002\u5e94\u793e\u533a\u8bc4\u5206\u3002", "result": "\u5728\u5f02\u8d28\u6027\u548c\u540c\u8d28\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAdaptCS\u7684F1\u5206\u6570\u5e73\u5747\u6bd4\u6700\u4f73\u57fa\u7ebf\u6a21\u578b\u9ad811%\uff0c\u5728\u4e0d\u540c\u5f02\u8d28\u6027\u6c34\u5e73\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\uff0c\u901f\u5ea6\u63d0\u5347\u53ef\u8fbe2\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "AdaptCS\u5728\u793e\u533a\u641c\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u5f02\u8d28\u6027\u56fe\u4e0a\u7684\u793e\u533a\u641c\u7d22\u95ee\u9898\u3002"}}
{"id": "2601.01785", "pdf": "https://arxiv.org/pdf/2601.01785", "abs": "https://arxiv.org/abs/2601.01785", "authors": ["Rajiv Chaitanya Muttur"], "title": "SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines", "categories": ["cs.IR", "cs.LG"], "comment": "Presented at ICEdge 2025; nominated for Best Paper Award", "summary": "Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u8fb9\u7f18\u539f\u751fRAG\u90e8\u7f72\u7684\u8f7b\u91cf\u7ea7\u6587\u6863\u9009\u62e9\u5668SRAS\uff0c\u5728\u5408\u6210QA\u57fa\u51c6\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u7684\u56fa\u5b9atop - k\u6587\u6863\u9009\u62e9\u673a\u5236\u5ffd\u7565\u4e0b\u6e38\u751f\u6210\u8d28\u91cf\u4e14\u6709\u8ba1\u7b97\u5f00\u9500\uff0c\u9700\u8981\u8f7b\u91cf\u7ea7\u3001\u4f4e\u5ef6\u8fdf\u7684\u6587\u6863\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u8bad\u7ec3SRAS\uff0c\u7ed3\u5408Relaxed F1\u548cBERTScore\u7684\u6df7\u5408\u5956\u52b1\u4fe1\u53f7\uff0c\u5728\u4e25\u683c\u7684\u4ee4\u724c\u548c\u8ba1\u7b97\u7ea6\u675f\u4e0b\u8fd0\u884c\u3002", "result": "\u5728\u5408\u6210QA\u57fa\u51c6\u4e0a\u4f18\u4e8e\u6709\u76d1\u7763\u548c\u968f\u673a\u9009\u62e9\u5668\uff0c\u5728SQuAD v2\u4e0a\u672a\u8fdb\u884c\u7279\u5b9a\u9886\u57df\u8c03\u4f18\u65f6BERTScore F1\u8fbe0.8546\u3002", "conclusion": "\u9996\u6b21\u8bc1\u660e\u57fa\u4e8eRL\u7684\u6587\u6863\u9009\u62e9\u53ef\u4ee5\u5b9e\u73b0\u8d85\u8f7b\u91cf\u7ea7\u3001\u4f4e\u5ef6\u8fdf\u4e14\u5bf9\u8bbe\u5907\u7aefRAG\u7ba1\u9053\u6709\u6548\u3002"}}
{"id": "2601.01979", "pdf": "https://arxiv.org/pdf/2601.01979", "abs": "https://arxiv.org/abs/2601.01979", "authors": ["Julie Keisler", "Anastase Alexandre Charantonis", "Yannig Goude", "Boutheina Oueslati", "Claire Monteleoni"], "title": "SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.", "AI": {"tldr": "\u63d0\u51faSerpentFlow\u6846\u67b6\u7528\u4e8e\u65e0\u914d\u5bf9\u57df\u5bf9\u9f50\uff0c\u5e76\u5e94\u7528\u4e8e\u8d85\u5206\u8fa8\u7387\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u5728\u65e0\u914d\u5bf9\u89c2\u6d4b\u60c5\u51b5\u4e0b\u8fdb\u884c\u57df\u5bf9\u9f50\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u627e\u5230\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u5f15\u5165SerpentFlow\u6846\u67b6\uff0c\u5c06\u6570\u636e\u5728\u6f5c\u7a7a\u95f4\u5206\u89e3\u4e3a\u5171\u4eab\u548c\u7279\u5b9a\u9886\u57df\u5206\u91cf\uff0c\u6784\u5efa\u5408\u6210\u8bad\u7ec3\u5bf9\uff0c\u4f7f\u7528\u57fa\u4e8e\u5206\u7c7b\u5668\u51c6\u5219\u81ea\u52a8\u786e\u5b9a\u9891\u7387\u5206\u754c\uff0c\u7528Flow Matching\u5b9e\u73b0\u6846\u67b6\u3002", "result": "\u5728\u5408\u6210\u56fe\u50cf\u3001\u7269\u7406\u8fc7\u7a0b\u6a21\u62df\u548c\u6c14\u5019\u964d\u5c3a\u5ea6\u4efb\u52a1\u4e2d\u6709\u6548\u91cd\u5efa\u9ad8\u9891\u7ed3\u6784\u3002", "conclusion": "\u5171\u4eab\u7ed3\u6784\u5206\u89e3\u662f\u65e0\u914d\u5bf9\u57df\u5bf9\u9f50\u7684\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2601.01839", "pdf": "https://arxiv.org/pdf/2601.01839", "abs": "https://arxiv.org/abs/2601.01839", "authors": ["Martin Prause"], "title": "The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": "Dataset available: https://ieee-dataport.org/documents/machine-learning-canvas-success-determinants", "summary": "Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (\u03b2= 0.432, p < 0.001), which improves work processes (\u03b2= 0.428, p < 0.001) and builds better infrastructure (\u03b2= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the \"how\" of coding but cannot replace the \"why\" and \"what\" of strategic thinking.", "AI": {"tldr": "\u7814\u7a76\u521b\u5efa\u5e76\u6d4b\u8bd5\u673a\u5668\u5b66\u4e60\u753b\u5e03\u6846\u67b6\uff0c\u8c03\u67e5\u6570\u636e\u79d1\u5b66\u5bb6\u786e\u5b9a\u56db\u4e2a\u5173\u952e\u6210\u529f\u56e0\u7d20\uff0c\u53d1\u73b0\u56e0\u7d20\u76f8\u4e92\u5173\u8054\uff0cAI \u52a9\u624b\u4e0d\u80fd\u4fdd\u8bc1\u9879\u76ee\u6210\u529f\u3002", "motivation": "\u5c3d\u7ba1 AI \u7f16\u7801\u52a9\u624b\u6d41\u884c\uff0c\u4f46\u8d85 80% \u7684\u673a\u5668\u5b66\u4e60\u9879\u76ee\u672a\u5b9e\u73b0\u5546\u4e1a\u4ef7\u503c\uff0c\u9700\u786e\u5b9a\u9879\u76ee\u6210\u529f\u56e0\u7d20\u3002", "method": "\u521b\u5efa\u673a\u5668\u5b66\u4e60\u753b\u5e03\u6846\u67b6\uff0c\u8c03\u67e5 150 \u540d\u6570\u636e\u79d1\u5b66\u5bb6\uff0c\u7528\u7edf\u8ba1\u6a21\u578b\u5206\u6790\u56de\u590d\u3002", "result": "\u786e\u5b9a\u56db\u4e2a\u5173\u952e\u6210\u529f\u56e0\u7d20\uff0c\u4e14\u56e0\u7d20\u76f8\u4e92\u5173\u8054\uff0cAI \u52a9\u624b\u867d\u4f7f\u7f16\u7801\u5feb\u4f46\u4e0d\u4fdd\u8bc1\u9879\u76ee\u6210\u529f\u3002", "conclusion": "\u6218\u7565\u3001\u6d41\u7a0b\u3001\u751f\u6001\u7cfb\u7edf\u548c\u652f\u6301\u7b49\u5143\u7d20\u5171\u540c\u51b3\u5b9a\u9879\u76ee\u662f\u5426\u6210\u529f\uff0cAI \u52a9\u624b\u65e0\u6cd5\u66ff\u4ee3\u6218\u7565\u601d\u7ef4\u3002"}}
{"id": "2601.00885", "pdf": "https://arxiv.org/pdf/2601.00885", "abs": "https://arxiv.org/abs/2601.00885", "authors": ["Mandar Parab"], "title": "Counterfactual Self-Questioning for Stable Policy Optimization in Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.", "AI": {"tldr": "\u63d0\u51fa\u53cd\u4e8b\u5b9e\u81ea\u6211\u63d0\u95ee\u6846\u67b6\uff0c\u53ef\u8ba9\u8bed\u8a00\u6a21\u578b\u81ea\u884c\u751f\u6210\u548c\u8bc4\u4f30\u63a8\u7406\u7684\u53cd\u4e8b\u5b9e\u6279\u5224\uff0c\u80fd\u63d0\u9ad8\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u6539\u8fdb\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u6279\u8bc4\u3001\u5b66\u4e60\u5956\u52b1\u6a21\u578b\u6216\u96c6\u6210\u91c7\u6837\uff0c\u589e\u52a0\u590d\u6742\u5ea6\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u53cd\u4e8b\u5b9e\u81ea\u6211\u63d0\u95ee\u6846\u67b6\uff0c\u751f\u6210\u521d\u59cb\u63a8\u7406\u75d5\u8ff9\u3001\u63d0\u51fa\u6311\u6218\u6f5c\u5728\u5931\u8d25\u70b9\u7684\u95ee\u9898\u3001\u751f\u6210\u66ff\u4ee3\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5c24\u5176\u5bf9\u8f83\u5c0f\u6a21\u578b\u3002", "conclusion": "\u4ec5\u4f7f\u7528\u5185\u90e8\u751f\u6210\u7684\u76d1\u7763\uff0c\u53cd\u4e8b\u5b9e\u81ea\u6211\u63d0\u95ee\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u81ea\u6211\u6539\u8fdb\u3002"}}
{"id": "2601.00864", "pdf": "https://arxiv.org/pdf/2601.00864", "abs": "https://arxiv.org/abs/2601.00864", "authors": ["Clemens Damke", "Eyke H\u00fcllermeier"], "title": "Distribution Matching for Graph Quantification Under Structural Covariate Shift", "categories": ["cs.LG", "stat.ML"], "comment": "17 pages, presented at ECML-PKDD 2025", "summary": "Graphs are commonly used in machine learning to model relationships between instances. Consider the task of predicting the political preferences of users in a social network; to solve this task one should consider, both, the features of each individual user and the relationships between them. However, oftentimes one is not interested in the label of a single instance but rather in the distribution of labels over a set of instances; e.g., when predicting the political preferences of users, the overall prevalence of a given opinion might be of higher interest than the opinion of a specific person. This label prevalence estimation task is commonly referred to as quantification learning (QL). Current QL methods for tabular data are typically based on the so-called prior probability shift (PPS) assumption which states that the label-conditional instance distributions should remain equal across the training and test data. In the graph setting, PPS generally does not hold if the shift between training and test data is structural, i.e., if the training data comes from a different region of the graph than the test data. To address such structural shifts, an importance sampling variant of the popular adjusted count quantification approach has previously been proposed. In this work, we extend the idea of structural importance sampling to the state-of-the-art KDEy quantification approach. We show that our proposed method adapts to structural shifts and outperforms standard quantification approaches.", "AI": {"tldr": "\u672c\u6587\u5c06\u7ed3\u6784\u91cd\u8981\u6027\u91c7\u6837\u601d\u60f3\u6269\u5c55\u5230KDEy\u91cf\u5316\u65b9\u6cd5\uff0c\u4ee5\u9002\u5e94\u56fe\u6570\u636e\u4e2d\u7684\u7ed3\u6784\u504f\u79fb\uff0c\u4e14\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u91cf\u5316\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u8868\u683c\u6570\u636e\u7684\u91cf\u5316\u5b66\u4e60\u65b9\u6cd5\u57fa\u4e8e\u7684PPS\u5047\u8bbe\u5728\u56fe\u6570\u636e\u4e2d\u56e0\u7ed3\u6784\u504f\u79fb\u4e0d\u6210\u7acb\uff0c\u9700\u89e3\u51b3\u56fe\u6570\u636e\u7ed3\u6784\u504f\u79fb\u95ee\u9898\u3002", "method": "\u5c06\u7ed3\u6784\u91cd\u8981\u6027\u91c7\u6837\u601d\u60f3\u6269\u5c55\u5230KDEy\u91cf\u5316\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u9002\u5e94\u7ed3\u6784\u504f\u79fb\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u6807\u51c6\u91cf\u5316\u65b9\u6cd5\u3002", "conclusion": "\u6269\u5c55\u540e\u7684\u65b9\u6cd5\u5728\u5904\u7406\u56fe\u6570\u636e\u7ed3\u6784\u504f\u79fb\u7684\u91cf\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u6709\u6548\u3002"}}
{"id": "2601.01649", "pdf": "https://arxiv.org/pdf/2601.01649", "abs": "https://arxiv.org/abs/2601.01649", "authors": ["Umesh Vangapally", "Wenhan Wu", "Chen Chen", "Zhishuai Guo"], "title": "Communication-Efficient Federated AUC Maximization with Cyclic Client Participation", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted to Transactions on Machine Learning Research (TMLR)", "summary": "Federated AUC maximization is a powerful approach for learning from imbalanced data in federated learning (FL). However, existing methods typically assume full client availability, which is rarely practical. In real-world FL systems, clients often participate in a cyclic manner: joining training according to a fixed, repeating schedule. This setting poses unique optimization challenges for the non-decomposable AUC objective. This paper addresses these challenges by developing and analyzing communication-efficient algorithms for federated AUC maximization under cyclic client participation. We investigate two key settings: First, we study AUC maximization with a squared surrogate loss, which reformulates the problem as a nonconvex-strongly-concave minimax optimization. By leveraging the Polyak-\u0141ojasiewicz (PL) condition, we establish a state-of-the-art communication complexity of $\\widetilde{O}(1/\u03b5^{1/2})$ and iteration complexity of $\\widetilde{O}(1/\u03b5)$. Second, we consider general pairwise AUC losses. We establish a communication complexity of $O(1/\u03b5^3)$ and an iteration complexity of $O(1/\u03b5^4)$. Further, under the PL condition, these bounds improve to communication complexity of $\\widetilde{O}(1/\u03b5^{1/2})$ and iteration complexity of $\\widetilde{O}(1/\u03b5)$. Extensive experiments on benchmark tasks in image classification, medical imaging, and fraud detection demonstrate the superior efficiency and effectiveness of our proposed methods.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2601.02037", "pdf": "https://arxiv.org/pdf/2601.02037", "abs": "https://arxiv.org/abs/2601.02037", "authors": ["Wei Hu", "Zewei Yu", "Jianqiu Xu"], "title": "Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.", "AI": {"tldr": "\u63d0\u51faDMPEAD\u6846\u67b6\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff0c\u57288\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u578b\u65b9\u6cd5\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5b58\u5728\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u3001\u56fa\u5b9a\u6570\u636e\u7ef4\u5ea6\u9650\u5236\u53ef\u6269\u5c55\u6027\u7b49\u95ee\u9898\u3002", "method": "\u5148\u901a\u8fc7\u53c2\u6570\u8f6c\u79fb\u548c\u591a\u6837\u6027\u6307\u6807\u6784\u5efa\u591a\u6837\u5316\u6a21\u578b\u6c60\uff0c\u518d\u7528\u5143\u6a21\u578b\u548c\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7b56\u7565\u66f4\u65b0\u6a21\u578b\u6c60\uff0c\u6700\u540e\u5728\u9009\u5b9a\u5b50\u96c6\u4e2d\u901a\u8fc7\u4ee3\u7406\u6307\u6807\u6392\u540d\u548ctop - k\u805a\u5408\u96c6\u6210\u6392\u540d\u9760\u524d\u7684\u6a21\u578b\u3002", "result": "\u57288\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "DMPEAD\u6846\u67b6\u5177\u6709\u51fa\u8272\u7684\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.01897", "pdf": "https://arxiv.org/pdf/2601.01897", "abs": "https://arxiv.org/abs/2601.01897", "authors": ["Lilu Cheng", "Jingjun Lu", "Yi Xuan Chan", "Quoc Khai Nguyen", "John Bi", "Sean Ho"], "title": "A Hybrid Architecture for Multi-Stage Claim Document Understanding: Combining Vision-Language Models and Machine Learning for Real-Time Processing", "categories": ["cs.IR"], "comment": "19 pages, 3 figures, 3 tables", "summary": "Claims documents are fundamental to healthcare and insurance operations, serving as the basis for reimbursement, auditing, and compliance. However, these documents are typically not born digital; they often exist as scanned PDFs or photographs captured under uncontrolled conditions. Consequently, they exhibit significant content heterogeneity, ranging from typed invoices to handwritten medical reports, as well as linguistic diversity. This challenge is exemplified by operations at Fullerton Health, which handles tens of millions of claims annually across nine markets, including Singapore, the Philippines, Indonesia, Malaysia, Mainland China, Hong Kong, Vietnam, Papua New Guinea, and Cambodia. Such variability, coupled with inconsistent image quality and diverse layouts, poses a significant obstacle to automated parsing and structured information extraction.\n  This paper presents a robust multi-stage pipeline that integrates the multilingual optical character recognition (OCR) engine PaddleOCR, a traditional Logistic Regression classifier, and a compact Vision-Language Model (VLM), Qwen 2.5-VL-7B, to achieve efficient and accurate field extraction from large-scale claims data. The proposed system achieves a document-type classification accuracy of over 95 percent and a field-level extraction accuracy of approximately 87 percent, while maintaining an average processing latency of under 2 seconds per document. Compared to manual processing, which typically requires around 10 minutes per claim, our system delivers a 300x improvement in efficiency. These results demonstrate that combining traditional machine learning models with modern VLMs enables production-grade accuracy and speed for real-world automation. The solution has been successfully deployed in our mobile application and is currently processing tens of thousands of claims weekly from Vietnam and Singapore.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u7406\u8d54\u6587\u6863\u81ea\u52a8\u5316\u89e3\u6790\u96be\u9898\uff0c\u63d0\u51fa\u591a\u9636\u6bb5\u5904\u7406\u6d41\u7a0b\uff0c\u7ed3\u5408\u591a\u79cd\u6280\u672f\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u5b57\u6bb5\uff0c\u6548\u679c\u597d\u3001\u6548\u7387\u9ad8\u4e14\u5df2\u90e8\u7f72\u5e94\u7528\u3002", "motivation": "\u7406\u8d54\u6587\u6863\u5b58\u5728\u5185\u5bb9\u3001\u8bed\u8a00\u591a\u6837\uff0c\u56fe\u50cf\u8d28\u91cf\u548c\u5e03\u5c40\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u963b\u788d\u81ea\u52a8\u5316\u89e3\u6790\u548c\u4fe1\u606f\u63d0\u53d6\u3002", "method": "\u63d0\u51fa\u591a\u9636\u6bb5\u6d41\u7a0b\uff0c\u96c6\u6210\u591a\u8bed\u8a00OCR\u5f15\u64cePaddleOCR\u3001\u4f20\u7edf\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578bQwen 2.5-VL - 7B\u3002", "result": "\u6587\u6863\u7c7b\u578b\u5206\u7c7b\u51c6\u786e\u7387\u8d8595%\uff0c\u5b57\u6bb5\u63d0\u53d6\u51c6\u786e\u7387\u7ea687%\uff0c\u5355\u6587\u6863\u5e73\u5747\u5904\u7406\u5ef6\u8fdf\u4e0d\u52302\u79d2\uff0c\u76f8\u6bd4\u4eba\u5de5\u6548\u7387\u63d0\u5347300\u500d\uff0c\u5df2\u5728\u79fb\u52a8\u5e94\u7528\u4e2d\u90e8\u7f72\u5e76\u6bcf\u5468\u5904\u7406\u6570\u4e07\u7b14\u7406\u8d54\u3002", "conclusion": "\u7ed3\u5408\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u73b0\u5b9e\u81ea\u52a8\u5316\u4e2d\u5b9e\u73b0\u751f\u4ea7\u7ea7\u7684\u51c6\u786e\u7387\u548c\u901f\u5ea6\u3002"}}
{"id": "2601.01921", "pdf": "https://arxiv.org/pdf/2601.01921", "abs": "https://arxiv.org/abs/2601.01921", "authors": ["Mikel Robredo", "Matteo Esposito", "Fabio Palomba", "Rafael Pe\u00f1aloza", "Valentina Lenarduzzi"], "title": "A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG"], "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.\n  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.\n  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.\n  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u65f6\u95f4\u654f\u611f\u6280\u672f\u7528\u4e8e\u7f3a\u9677\u9884\u6d4b\u7684\u6709\u6548\u6027\u53ca\u7f3a\u9677\u65e9\u671f\u6307\u6807\uff0c\u8ba1\u5212\u8bad\u7ec3\u591a\u79cd\u6280\u672f\u9884\u6d4b\u8f6f\u4ef6\u9879\u76ee\u672a\u6765\u7f3a\u9677\u5bc6\u5ea6\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u4e0d\u65ad\u6f14\u8fdb\uff0c\u9700\u8981\u65f6\u95f4\u654f\u611f\u65b9\u6cd5\u5728\u7f3a\u9677\u663e\u73b0\u524d\u8fdb\u884c\u9884\u6d4b\u3002", "method": "\u8bad\u7ec3\u591a\u79cd\u65f6\u95f4\u654f\u611f\u9884\u6d4b\u6280\u672f\u6765\u9884\u6d4b\u8f6f\u4ef6\u9879\u76ee\u672a\u6765\u7684\u7f3a\u9677\u5bc6\u5ea6\uff0c\u5e76\u8bc6\u522b\u7f3a\u9677\u53d1\u751f\u524d\u7684\u65e9\u671f\u75c7\u72b6\u3002", "result": "\u83b7\u5f97\u5173\u4e8e\u8be5\u65b9\u6cd5\u5bf9\u65e9\u671f\u4f30\u8ba1\u7f3a\u9677\u503e\u5411\u6709\u6548\u6027\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002", "conclusion": "\u6458\u8981\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2601.00923", "pdf": "https://arxiv.org/pdf/2601.00923", "abs": "https://arxiv.org/abs/2601.00923", "authors": ["Josef Ott"], "title": "Context Collapse: In-Context Learning and Model Collapse", "categories": ["cs.AI"], "comment": "Master's thesis", "summary": "This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u6a21\u578b\u5d29\u6e83\u4e24\u4e2a\u73b0\u8c61\uff0c\u5206\u6790\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u76f8\u53d8\u53ca\u9884\u6761\u4ef6\uff0c\u8bc1\u660e\u6a21\u578b\u5d29\u6e83\u6536\u655b\u6761\u4ef6\uff0c\u8fd8\u5f15\u5165\u4e0a\u4e0b\u6587\u5d29\u6e83\u6982\u5ff5\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u6a21\u578b\u5d29\u6e83\u8fd9\u4e24\u4e2a\u5173\u952e\u73b0\u8c61\u3002", "method": "\u7814\u7a76\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e2d\u5e26\u6743\u91cd\u7ed1\u5b9a\u7684\u7ebf\u6027\u53d8\u538b\u5668\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff1b\u7528\u9785\u548c\u968f\u673a\u6e38\u8d70\u7406\u8bba\u5206\u6790\u7b80\u5316\u6570\u636e\u4e0b\u7684\u6a21\u578b\u5d29\u6e83\uff1b\u5f15\u5165\u4e0a\u4e0b\u6587\u5d29\u6e83\u6982\u5ff5\u8fde\u63a5\u4e0a\u4e0b\u6587\u5b66\u4e60\u52a8\u6001\u548c\u751f\u6210\u6a21\u578b\u7a33\u5b9a\u6027\u3002", "result": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u8fbe\u5230\u4e34\u754c\u4e0a\u4e0b\u6587\u957f\u5ea6\u65f6\uff0c\u5b66\u4e60\u53c2\u6570\u4f1a\u51fa\u73b0\u76f8\u53d8\uff1b\u8bc1\u660e\u6a21\u578b\u5d29\u6e83\u7684\u6536\u655b\u60c5\u51b5\uff1b\u63d0\u51fa\u4e0a\u4e0b\u6587\u5d29\u6e83\u6982\u5ff5\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b58\u5728\u76f8\u53d8\uff0c\u6a21\u578b\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f1a\u5d29\u6e83\uff0c\u4e0a\u4e0b\u6587\u5d29\u6e83\u6982\u5ff5\u5173\u8054\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u52a8\u6001\u548c\u751f\u6210\u6a21\u578b\u957f\u671f\u7a33\u5b9a\u6027\u6311\u6218\u3002"}}
{"id": "2601.00892", "pdf": "https://arxiv.org/pdf/2601.00892", "abs": "https://arxiv.org/abs/2601.00892", "authors": ["Ana Carpio", "Gema Duro"], "title": "Hierarchical topological clustering", "categories": ["cs.LG", "cs.CV", "physics.data-an", "stat.ME", "stat.ML"], "comment": "not peer reviewed, reviewed version to appear in Soft Computing", "summary": "Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u642d\u914d\u4efb\u610f\u8ddd\u79bb\u9009\u62e9\u7684\u5206\u5c42\u62d3\u6251\u805a\u7c7b\u7b97\u6cd5\uff0c\u5728\u542b\u79bb\u7fa4\u70b9\u6570\u636e\u4e0a\u5c55\u793a\u6f5c\u529b\u3002", "motivation": "\u62d3\u6251\u65b9\u6cd5\u53ef\u5728\u4e0d\u5047\u8bbe\u6570\u636e\u7ed3\u6784\u60c5\u51b5\u4e0b\u63a2\u7d22\u6570\u636e\u4e91\uff0c\u671f\u671b\u89e3\u51b3\u5df2\u6709\u805a\u7c7b\u6280\u672f\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u62d3\u6251\u805a\u7c7b\u7b97\u6cd5\uff0c\u53ef\u642d\u914d\u4efb\u610f\u8ddd\u79bb\u9009\u62e9\uff0c\u4ece\u751f\u6210\u7684\u5c42\u6b21\u7ed3\u6784\u63a8\u65ad\u79bb\u7fa4\u70b9\u548c\u4efb\u610f\u5f62\u72b6\u805a\u7c7b\u7684\u6301\u4e45\u6027\u3002", "result": "\u5728\u542b\u79bb\u7fa4\u70b9\u7684\u56fe\u50cf\u3001\u533b\u7597\u548c\u7ecf\u6d4e\u7b49\u9009\u5b9a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u7b97\u6cd5\u6f5c\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5728\u5176\u4ed6\u6280\u672f\u5931\u6548\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u805a\u7c7b\u3002"}}
{"id": "2601.01840", "pdf": "https://arxiv.org/pdf/2601.01840", "abs": "https://arxiv.org/abs/2601.01840", "authors": ["Qiantao Yang", "Liquan Chen", "Mingfu Xue", "Songze Li"], "title": "Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted in AAAI 2026", "summary": "Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5FedCSPACK\uff0c\u53ef\u5229\u7528\u6709\u9650\u5ba2\u6237\u7aef\u8d44\u6e90\uff0c\u51cf\u5c11\u6570\u636e\u5f02\u8d28\u6027\u5f71\u54cd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u63d0\u5347\u6548\u7387\u5e76\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u5e73\u8861\u5904\u7406\u6570\u636e\u5f02\u8d28\u6027\u548c\u5ba2\u6237\u7aef\u6709\u9650\u8d44\u6e90\u7684\u95ee\u9898\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4f59\u5f26\u7a00\u758f\u5316\u53c2\u6570\u6253\u5305\u548c\u53cc\u52a0\u6743\u805a\u5408\u7684FedCSPACK\u65b9\u6cd5\uff0c\u5305\u62ec\u5ba2\u6237\u7aef\u6253\u5305\u53c2\u6570\u3001\u751f\u6210\u63a9\u7801\u77e9\u9635\u3001\u5d4c\u5165\u6743\u91cd\u5b9e\u73b0\u52a0\u6743\u5f15\u5bfc\u805a\u5408\u673a\u5236\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7528\u5341\u79cd\u5148\u8fdb\u65b9\u6cd5\u5b9e\u9a8c\uff0cFedCSPACK\u6709\u6548\u63d0\u5347\u901a\u4fe1\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4fdd\u6301\u9ad8\u6a21\u578b\u51c6\u786e\u7387\u3002", "conclusion": "FedCSPACK\u80fd\u6709\u6548\u5229\u7528\u6709\u9650\u5ba2\u6237\u7aef\u8d44\u6e90\uff0c\u51cf\u5c11\u6570\u636e\u5f02\u8d28\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2601.01930", "pdf": "https://arxiv.org/pdf/2601.01930", "abs": "https://arxiv.org/abs/2601.01930", "authors": ["Dongfang Zhao"], "title": "MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\\times$ higher throughput at 95\\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\\times$, while maintaining performance parity on standard lower-dimensional datasets.", "AI": {"tldr": "\u63d0\u51faMCGI\u65b9\u6cd5\u89e3\u51b3\u56fe\u57fa\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u5728\u9ad8\u7ef4\u7a7a\u95f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u56fe\u57fa\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u5728\u9ad8\u7ef4\u7a7a\u95f4\u56e0\u2018\u6b27\u51e0\u91cc\u5f97 - \u6d4b\u5730\u7ebf\u4e0d\u5339\u914d\u2019\u95ee\u9898\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u611f\u77e5\u4e14\u78c1\u76d8\u9a7b\u7559\u7684\u7d22\u5f15\u65b9\u6cd5MCGI\uff0c\u5229\u7528\u5c40\u90e8\u56fa\u6709\u7ef4\u5ea6\u52a8\u6001\u8c03\u6574\u641c\u7d22\u7b56\u7565\uff0c\u6839\u636e\u51e0\u4f55\u5206\u6790\u8c03\u8282\u675f\u641c\u7d22\u9884\u7b97\u3002", "result": "\u7406\u8bba\u4e0a\u80fd\u6539\u8fdb\u8fd1\u4f3c\u4fdd\u8bc1\uff1b\u5b9e\u9a8c\u4e0a\uff0c\u5728\u9ad8\u7ef4GIST1M\u4e0a\u541e\u5410\u91cf\u6bd4DiskANN\u9ad85.8\u500d\uff0c\u5728SIFT1B\u4e0a\u9ad8\u53ec\u56de\u67e5\u8be2\u5ef6\u8fdf\u964d\u4f4e3\u500d\uff0c\u4f4e\u7ef4\u6570\u636e\u96c6\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "MCGI\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u9ad8\u7ef4\u7a7a\u95f4\u56fe\u57fa\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7684\u6027\u80fd\u95ee\u9898\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.01944", "pdf": "https://arxiv.org/pdf/2601.01944", "abs": "https://arxiv.org/abs/2601.01944", "authors": ["Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "title": "The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR", "cs.PL"], "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u5f00\u6e90\u8f6f\u4ef6\u4e2dAI\u5e93\u7684\u91c7\u7528\u60c5\u51b5\uff0c\u6253\u7b97\u5206\u679015.77\u4e07\u4e2a\u4ed3\u5e93\uff0c\u5bf9\u6bd4\u91c7\u7528\u4e0e\u4e0d\u91c7\u7528AI\u5e93\u9879\u76ee\u7684\u5dee\u5f02\uff0c\u4e3aAI\u91cd\u5851\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u4f46AI\u7684\u91c7\u7528\u53ca\u5176\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u7684\u5f71\u54cd\u4ecd\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u5bf9157.7k\u4e2a\u6f5c\u5728\u5f00\u6e90\u8f6f\u4ef6\u4ed3\u5e93\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\uff0c\u4f7f\u7528\u4ed3\u5e93\u6307\u6807\u548c\u8f6f\u4ef6\u6307\u6807\u5bf9\u6bd4\u91c7\u7528\u4e0e\u4e0d\u91c7\u7528AI\u5e93\u7684\u9879\u76ee\u3002", "result": "\u9884\u8ba1\u80fd\u8bc6\u522b\u91c7\u7528\u4e0e\u4e0d\u91c7\u7528AI\u5e93\u7684\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u5728\u5f00\u53d1\u6d3b\u52a8\u3001\u793e\u533a\u53c2\u4e0e\u548c\u4ee3\u7801\u590d\u6742\u6027\u65b9\u9762\u7684\u53ef\u8861\u91cf\u5dee\u5f02\u3002", "conclusion": "\u4e3aAI\u96c6\u6210\u5982\u4f55\u91cd\u5851\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u89c1\u89e3\u3002"}}
{"id": "2601.00994", "pdf": "https://arxiv.org/pdf/2601.00994", "abs": "https://arxiv.org/abs/2601.00994", "authors": ["Michael Bao"], "title": "ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems", "categories": ["cs.AI", "cs.CY"], "comment": "In proceedings of 2025 IEEE International Conference on Agentic AI (ICA)", "summary": "This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as \"kernel of truth\" messages and spontaneous developments with an \"ink\" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.", "AI": {"tldr": "\u4ecb\u7ecd\u6a21\u62df\u6846\u67b6ElecTwit\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bf4\u670d\u60c5\u51b5\uff0c\u89c2\u5bdfLLM\u8bf4\u670d\u6280\u672f\uff0c\u4e3a\u8bc4\u4f30\u73b0\u5b9e\u573a\u666f\u4e2dLLM\u667a\u80fd\u4f53\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u514b\u670d\u4ee5\u5f80\u57fa\u4e8e\u6e38\u620f\u7684\u6a21\u62df\u7814\u7a76\u7684\u5c40\u9650\u6027\uff0c\u5728\u73b0\u5b9e\u73af\u5883\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u8bf4\u670d\u60c5\u51b5\u3002", "method": "\u4f7f\u7528ElecTwit\u6a21\u62df\u6846\u67b6\u5728\u653f\u6cbb\u9009\u4e3e\u793e\u4ea4\u5a92\u4f53\u4e92\u52a8\u573a\u666f\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u89c2\u5bdf\u5230\u591a\u6570\u6d4b\u8bd5\u7684LLM\u5168\u9762\u4f7f\u752825\u79cd\u8bf4\u670d\u6280\u672f\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u6280\u672f\u4f7f\u7528\u548c\u8bf4\u670d\u8f93\u51fa\u6709\u5dee\u5f02\uff0c\u8fd8\u53d1\u73b0\u72ec\u7279\u73b0\u8c61\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bc4\u4f30\u73b0\u5b9e\u573a\u666f\u4e2d\u5177\u8bf4\u670d\u529b\u7684LLM\u667a\u80fd\u4f53\u63d0\u4f9b\u57fa\u7840\uff0c\u786e\u4fdd\u4e00\u81f4\u6027\u5e76\u9632\u6b62\u5371\u9669\u7ed3\u679c\u3002"}}
{"id": "2601.00904", "pdf": "https://arxiv.org/pdf/2601.00904", "abs": "https://arxiv.org/abs/2601.00904", "authors": ["Qiang Li", "Shujian Yu", "Liang Ma", "Chen Ma", "Jingyu Liu", "Tulay Adali", "Vince D. Calhoun"], "title": "Deep Deterministic Nonlinear ICA via Total Correlation Minimization with Matrix-Based Entropy Functional", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": "16 pages, 9 figures", "summary": "Blind source separation, particularly through independent component analysis (ICA), is widely utilized across various signal processing domains for disentangling underlying components from observed mixed signals, owing to its fully data-driven nature that minimizes reliance on prior assumptions. However, conventional ICA methods rely on an assumption of linear mixing, limiting their ability to capture complex nonlinear relationships and to maintain robustness in noisy environments. In this work, we present deep deterministic nonlinear independent component analysis (DDICA), a novel deep neural network-based framework designed to address these limitations. DDICA leverages a matrix-based entropy function to directly optimize the independence criterion via stochastic gradient descent, bypassing the need for variational approximations or adversarial schemes. This results in a streamlined training process and improved resilience to noise. We validated the effectiveness and generalizability of DDICA across a range of applications, including simulated signal mixtures, hyperspectral image unmixing, modeling of primary visual receptive fields, and resting-state functional magnetic resonance imaging (fMRI) data analysis. Experimental results demonstrate that DDICA effectively separates independent components with high accuracy across a range of applications. These findings suggest that DDICA offers a robust and versatile solution for blind source separation in diverse signal processing tasks.", "AI": {"tldr": "\u63d0\u51faDDICA\u6846\u67b6\u89e3\u51b3\u4f20\u7edfICA\u65b9\u6cd5\u5c40\u9650\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u591a\u5e94\u7528\u4e2d\u5206\u79bb\u72ec\u7acb\u6210\u5206\u51c6\u786e\u6027\u9ad8\uff0c\u662f\u76f2\u6e90\u5206\u79bb\u7684\u53ef\u9760\u901a\u7528\u65b9\u6848\u3002", "motivation": "\u4f20\u7edfICA\u65b9\u6cd5\u4f9d\u8d56\u7ebf\u6027\u6df7\u5408\u5047\u8bbe\uff0c\u96be\u4ee5\u6355\u6349\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\u4e14\u5728\u566a\u58f0\u73af\u5883\u4e2d\u9c81\u68d2\u6027\u5dee\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684DDICA\u6846\u67b6\uff0c\u5229\u7528\u57fa\u4e8e\u77e9\u9635\u7684\u71b5\u51fd\u6570\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u76f4\u63a5\u4f18\u5316\u72ec\u7acb\u6027\u51c6\u5219\u3002", "result": "\u5728\u6a21\u62df\u4fe1\u53f7\u6df7\u5408\u3001\u9ad8\u5149\u8c31\u56fe\u50cf\u89e3\u6df7\u7b49\u591a\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86DDICA\u6709\u6548\u6027\u548c\u6cdb\u5316\u6027\uff0c\u80fd\u9ad8\u7cbe\u5ea6\u5206\u79bb\u72ec\u7acb\u6210\u5206\u3002", "conclusion": "DDICA\u4e3a\u4e0d\u540c\u4fe1\u53f7\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u76f2\u6e90\u5206\u79bb\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02064", "pdf": "https://arxiv.org/pdf/2601.02064", "abs": "https://arxiv.org/abs/2601.02064", "authors": ["Manav Seksaria", "Anil Prabhakar"], "title": "Cutting Quantum Circuits Beyond Qubits", "categories": ["quant-ph", "cs.DC"], "comment": null, "summary": "We extend quantum circuit cutting to heterogeneous registers comprising mixed-dimensional qudits. By decomposing non-local interactions into tensor products of local generalised Gell-Mann matrices, we enable the simulation and execution of high-dimensional circuits on disconnected hardware fragments. We validate this framework on qubit--qutrit ($2$--$3$) interfaces, achieving exact state reconstruction with a Total Variation Distance of 0 within single-precision floating-point tolerance. Furthermore, we demonstrate the memory advantage in an 8-particle, dimension-8 system, reducing memory usage from 128 MB to 64 KB per circuit.", "AI": {"tldr": "\u5c06\u91cf\u5b50\u7535\u8def\u5207\u5272\u6269\u5c55\u5230\u5305\u542b\u6df7\u5408\u7ef4\u5ea6\u91cf\u5b50\u4f4d\u7684\u5f02\u6784\u5bc4\u5b58\u5668\uff0c\u9a8c\u8bc1\u6846\u67b6\u5e76\u5c55\u793a\u5185\u5b58\u4f18\u52bf\u3002", "motivation": "\u5b9e\u73b0\u9ad8\u7ef4\u7535\u8def\u5728\u65ad\u5f00\u7684\u786c\u4ef6\u7247\u6bb5\u4e0a\u7684\u6a21\u62df\u548c\u6267\u884c\u3002", "method": "\u5c06\u975e\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u5206\u89e3\u4e3a\u5c40\u90e8\u5e7f\u4e49\u76d6\u5c14\u66fc\u77e9\u9635\u7684\u5f20\u91cf\u79ef\u3002", "result": "\u5728\u91cf\u5b50\u6bd4\u7279 - \u4e09\u80fd\u7ea7\u91cf\u5b50\u4f4d\u63a5\u53e3\u9a8c\u8bc1\u6846\u67b6\uff0c\u5b9e\u73b0\u7cbe\u786e\u72b6\u6001\u91cd\u5efa\uff0c\u5728 8 \u7c92\u5b50\u30018 \u7ef4\u7cfb\u7edf\u4e2d\u5c55\u793a\u5185\u5b58\u4f18\u52bf\uff0c\u5c06\u6bcf\u4e2a\u7535\u8def\u7684\u5185\u5b58\u4f7f\u7528\u4ece 128 MB \u51cf\u5c11\u5230 64 KB\u3002", "conclusion": "\u63d0\u51fa\u7684\u6269\u5c55\u65b9\u6cd5\u53ef\u884c\u4e14\u6709\u5185\u5b58\u4f18\u52bf\u3002"}}
{"id": "2601.01997", "pdf": "https://arxiv.org/pdf/2601.01997", "abs": "https://arxiv.org/abs/2601.01997", "authors": ["Dario Di Palma", "Giovanni Maria Biancofiore", "Vito Walter Anelli", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.\n  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30ChatGPT-3.5\u548cChatGPT-4\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u591a\u6837\u6027\u3001\u65b0\u9896\u6027\u548c\u6d41\u884c\u5ea6\u504f\u5dee\uff0c\u53d1\u73b0ChatGPT-4\u8868\u73b0\u51fa\u8272\uff0c\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u4f18\u52bf\u660e\u663e\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8ChatGPT\u96c6\u6210\u5230\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u5176\u5728\u591a\u6837\u6027\u3001\u65b0\u9896\u6027\u548c\u6f5c\u5728\u504f\u5dee\u65b9\u9762\u7684\u5168\u9762\u5206\u6790\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u4ee5\u63d0\u5347\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u5b9e\u73b0\u957f\u671f\u4e2a\u6027\u5316\u3002", "method": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30ChatGPT-3.5\u548cChatGPT-4\u5728Top - N\u63a8\u8350\u548c\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "result": "ChatGPT-4\u5728\u63a8\u8350\u4e2d\u80fd\u5e73\u8861\u65b0\u9896\u6027\u548c\u591a\u6837\u6027\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u4f20\u7edf\u63a8\u8350\u5668\uff1b\u51b7\u542f\u52a8\u573a\u666f\u4e2d\uff0cChatGPT\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u65b0\u9896\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u7814\u7a76\u6307\u51fa\u4e86ChatGPT\u63a8\u8350\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u8d85\u8d8a\u4ee5\u51c6\u786e\u6027\u4e3a\u91cd\u70b9\u7684\u63a8\u8350\u6307\u6807\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.01952", "pdf": "https://arxiv.org/pdf/2601.01952", "abs": "https://arxiv.org/abs/2601.01952", "authors": ["Max Unterbusch", "Andreas Vogelsang"], "title": "Context-Adaptive Requirements Defect Prediction through Human-LLM Collaboration", "categories": ["cs.SE"], "comment": "Accepted at ICSE-NIER 2026", "summary": "Automated requirements assessment traditionally relies on universal patterns as proxies for defectiveness, implemented through rule-based heuristics or machine learning classifiers trained on large annotated datasets. However, what constitutes a \"defect\" is inherently context-dependent and varies across projects, domains, and stakeholder interpretations. In this paper, we propose a Human-LLM Collaboration (HLC) approach that treats defect prediction as an adaptive process rather than a static classification task. HLC leverages LLM Chain-of-Thought reasoning in a feedback loop: users validate predictions alongside their explanations, and these validated examples adaptively guide future predictions through few-shot learning. We evaluate this approach using the weak word smell on the QuRE benchmark of 1,266 annotated Mercedes-Benz requirements. Our results show that HLC effectively adapts to the provision of validated examples, with rapid performance gains from as few as 20 validated examples. Incorporating validated explanations, not just labels, enables HLC to substantially outperform both standard few-shot prompting and fine-tuned BERT models while maintaining high recall. These results highlight how the in-context and Chain-of-Thought learning capabilities of LLMs enable adaptive classification approaches that move beyond one-size-fits-all models, creating opportunities for tools that learn continuously from stakeholder feedback.", "AI": {"tldr": "\u63d0\u51fa\u4eba\u7c7b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u534f\u4f5c\uff08HLC\uff09\u65b9\u6cd5\u7528\u4e8e\u9700\u6c42\u7f3a\u9677\u9884\u6d4b\uff0c\u5728\u5954\u9a70\u9700\u6c42\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u9002\u5e94\u53cd\u9988\u5e76\u8d85\u8d8a\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u5316\u9700\u6c42\u8bc4\u4f30\u4f9d\u8d56\u901a\u7528\u6a21\u5f0f\uff0c\u800c\u7f3a\u9677\u5b9a\u4e49\u5177\u6709\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\uff0c\u9700\u66f4\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHLC\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u53cd\u9988\u5faa\u73af\uff0c\u901a\u8fc7\u5c11\u91cf\u9a8c\u8bc1\u793a\u4f8b\u8fdb\u884c\u5c11\u6837\u672c\u5b66\u4e60\u3002", "result": "HLC\u80fd\u6709\u6548\u9002\u5e94\u9a8c\u8bc1\u793a\u4f8b\uff0c\u4ec520\u4e2a\u9a8c\u8bc1\u793a\u4f8b\u5c31\u80fd\u5feb\u901f\u63d0\u5347\u6027\u80fd\uff0c\u7ed3\u5408\u89e3\u91ca\u80fd\u5927\u5e45\u8d85\u8d8a\u6807\u51c6\u5c11\u6837\u672c\u63d0\u793a\u548c\u5fae\u8c03\u7684BERT\u6a21\u578b\uff0c\u4e14\u53ec\u56de\u7387\u9ad8\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u548c\u601d\u7ef4\u94fe\u5b66\u4e60\u80fd\u529b\u4f7f\u81ea\u9002\u5e94\u5206\u7c7b\u65b9\u6cd5\u8d85\u8d8a\u901a\u7528\u6a21\u578b\uff0c\u4e3a\u4ece\u5229\u76ca\u76f8\u5173\u8005\u53cd\u9988\u4e2d\u6301\u7eed\u5b66\u4e60\u7684\u5de5\u5177\u521b\u9020\u673a\u4f1a\u3002"}}
{"id": "2601.01195", "pdf": "https://arxiv.org/pdf/2601.01195", "abs": "https://arxiv.org/abs/2601.01195", "authors": ["Wuzhenghong Wen", "Chao Xue", "Su Pan", "Yuwei Sun", "Minlong Peng"], "title": "Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering", "categories": ["cs.AI"], "comment": "11 pages, 2 figures", "summary": "Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.", "AI": {"tldr": "\u63d0\u51faMRE\u6846\u67b6\u89e3\u51b3TKGQA\u4e2dLLMs\u591a\u8df3\u63a8\u7406\u95ee\u9898\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u4e0a\u8d85SOTA\u65b9\u6cd5\u3002", "motivation": "TKGQA\u4e2dLLMs\u5728\u591a\u8df3\u63a8\u7406\u65f6\u68c0\u7d22\u7684\u5b50\u56fe\u5173\u7cfb\u590d\u6742\uff0c\u6613\u5bfc\u81f4\u6b21\u4f18\u51b3\u7b56\u548c\u9519\u8bef\u4f20\u64ad\u3002", "method": "\u63d0\u51faMRE\u6846\u67b6\uff0c\u542b\u63d0\u793a\u5de5\u7a0b\u751f\u6210\u63a8\u7406\u8f68\u8ff9\u3001\u7b5b\u9009\u6709\u6548\u8f68\u8ff9\u5fae\u8c03\u53ca\u5f15\u5165T - GRPO\u5b66\u4e60\u63a2\u7d22\u65b9\u6cd5\u3002", "result": "\u5728\u4e24\u4e2aTKGQA\u57fa\u51c6\u4e0a\uff0cMRE\u6a21\u578b\u5904\u7406\u590d\u6742\u591a\u8df3\u67e5\u8be2\u8d85\u8d8aSOTA\u65b9\u6cd5\uff0c\u4e14\u6709\u8f83\u597d\u89e3\u91ca\u6027\u548c\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "MRE\u6846\u67b6\u6709\u6548\u89e3\u51b3TKGQA\u4e2d\u591a\u8df3\u63a8\u7406\u95ee\u9898\uff0c\u53ef\u5904\u7406\u590d\u6742\u67e5\u8be2\uff0c\u6709\u66f4\u597d\u8868\u73b0\u3002"}}
{"id": "2601.00908", "pdf": "https://arxiv.org/pdf/2601.00908", "abs": "https://arxiv.org/abs/2601.00908", "authors": ["Chorok Lee"], "title": "Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.", "AI": {"tldr": "\u4ee5\u65b0\u51a0\u75ab\u60c5\u4f5c\u4e3a\u81ea\u7136\u5b9e\u9a8c\uff0c\u7814\u7a76\u5206\u5e03\u504f\u79fb\u4e0b\u5171\u5f62\u9884\u6d4b\u4fdd\u8bc1\u7684\u4e0b\u964d\uff0c\u53d1\u73b0\u5355\u7279\u5f81\u4f9d\u8d56\u4e0e\u707e\u96be\u6027\u5931\u8d25\u76f8\u5173\uff0c\u4e0d\u540c\u4efb\u52a1\u8868\u73b0\u4e0d\u540c\uff0c\u5b63\u5ea6\u518d\u8bad\u7ec3\u6548\u679c\u4e0d\u4e00\uff0c\u63d0\u51fa\u51b3\u7b56\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u5206\u5e03\u504f\u79fb\u4e0b\u5171\u5f62\u9884\u6d4b\u4fdd\u8bc1\u4e0b\u964d\u7684\u60c5\u51b5\u3002", "method": "\u4ee5\u65b0\u51a0\u75ab\u60c5\u4e3a\u81ea\u7136\u5b9e\u9a8c\uff0c\u6db5\u76d68\u4e2a\u4f9b\u5e94\u94fe\u4efb\u52a1\uff0c\u4f7f\u7528SHapley Additive exPlanations (SHAP)\u5206\u6790\uff0c\u8fd8\u5bf94\u4e2a\u7279\u5f81\u7a33\u5b9a\u6027\u9002\u4e2d\u7684\u4efb\u52a1\u8fdb\u884c\u63a2\u7d22\u6027\u5206\u6790\u3002", "result": "\u4e0d\u540c\u4efb\u52a1 Coverage \u4e0b\u964d\u5e45\u5ea6\u5dee\u5f02\u5927\uff0c\u707e\u96be\u6027\u5931\u8d25\u4e0e\u5355\u7279\u5f81\u4f9d\u8d56\u76f8\u5173\uff0c\u5b63\u5ea6\u518d\u8bad\u7ec3\u5bf9\u4e0d\u540c\u4efb\u52a1\u6548\u679c\u4e0d\u540c\uff0c\u7279\u5f81\u7a33\u5b9a\u6027\u51b3\u5b9a\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u4f9b\u51b3\u7b56\u6846\u67b6\uff0c\u90e8\u7f72\u524d\u76d1\u6d4b SHAP \u96c6\u4e2d\u5ea6\uff0c\u6613\u53d7\u5f71\u54cd\u5219\u5b63\u5ea6\u518d\u8bad\u7ec3\uff0c\u9c81\u68d2\u5219\u8df3\u8fc7\u3002"}}
{"id": "2601.02251", "pdf": "https://arxiv.org/pdf/2601.02251", "abs": "https://arxiv.org/abs/2601.02251", "authors": ["Guy Amir", "Mark Barbone", "Nicolas Amat", "Jules Jacobs"], "title": "Deciding Serializability in Network Systems", "categories": ["cs.FL", "cs.DC", "cs.LO", "cs.PL"], "comment": "To appear in TACAS 2026", "summary": "We present the SER modeling language for automatically verifying serializability of concurrent programs, i.e., whether every concurrent execution of the program is equivalent to some serial execution.\n  SER programs are suitably restricted to make this problem decidable, while still allowing for an unbounded number of concurrent threads of execution, each potentially running for an unbounded number of steps.\n  Building on prior theoretical results, we give the first automated end-to-end decision procedure that either proves serializability by producing a checkable certificate, or refutes it by producing a counterexample trace.\n  We also present a network-system abstraction to which SER programs compile. Our decision procedure then reduces serializability in this setting to a Petri net reachability query.\n  Furthermore, in order to scale, we curtail the search space via multiple optimizations, including Petri net slicing, semilinear-set compression, and Presburger-formula manipulation.\n  We extensively evaluate our framework and show that, despite the theoretical hardness of the problem, it can successfully handle various models of real-world programs, including stateful firewalls, BGP routers, and more.", "AI": {"tldr": "\u63d0\u51faSER\u5efa\u6a21\u8bed\u8a00\u9a8c\u8bc1\u5e76\u53d1\u7a0b\u5e8f\u53ef\u4e32\u884c\u5316\uff0c\u7ed9\u51fa\u81ea\u52a8\u5316\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7ecf\u4f18\u5316\u540e\u80fd\u5904\u7406\u591a\u79cd\u73b0\u5b9e\u7a0b\u5e8f\u6a21\u578b\u3002", "motivation": "\u81ea\u52a8\u9a8c\u8bc1\u5e76\u53d1\u7a0b\u5e8f\u7684\u53ef\u4e32\u884c\u5316\uff0c\u5373\u5224\u65ad\u7a0b\u5e8f\u7684\u6bcf\u4e2a\u5e76\u53d1\u6267\u884c\u662f\u5426\u7b49\u4ef7\u4e8e\u67d0\u4e2a\u4e32\u884c\u6267\u884c\u3002", "method": "\u63d0\u51faSER\u5efa\u6a21\u8bed\u8a00\uff0c\u7ed9\u51fa\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5c06\u53ef\u4e32\u884c\u5316\u95ee\u9898\u8f6c\u5316\u4e3aPetri\u7f51\u53ef\u8fbe\u6027\u67e5\u8be2\uff0c\u901a\u8fc7Petri\u7f51\u5207\u7247\u3001\u534a\u7ebf\u6027\u96c6\u538b\u7f29\u548cPresburger\u516c\u5f0f\u64cd\u4f5c\u7b49\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u6846\u67b6\u80fd\u6210\u529f\u5904\u7406\u5305\u62ec\u6709\u72b6\u6001\u9632\u706b\u5899\u3001BGP\u8def\u7531\u5668\u7b49\u591a\u79cd\u73b0\u5b9e\u4e16\u754c\u7a0b\u5e8f\u6a21\u578b\u3002", "conclusion": "\u5c3d\u7ba1\u95ee\u9898\u7406\u8bba\u4e0a\u8f83\u96be\uff0c\u4f46\u8be5\u6846\u67b6\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u53ef\u7528\u4e8e\u9a8c\u8bc1\u5e76\u53d1\u7a0b\u5e8f\u7684\u53ef\u4e32\u884c\u5316\u3002"}}
{"id": "2601.02002", "pdf": "https://arxiv.org/pdf/2601.02002", "abs": "https://arxiv.org/abs/2601.02002", "authors": ["Antonio Colacicco", "Vito Guida", "Dario Di Palma", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u573a\u666f\u7684\u6570\u636e\u6cc4\u9732\u95ee\u9898\uff0c\u8bc4\u4f30\u4e09\u79cd\u65b9\u6cd5\uff0c\u53d1\u73b0\u81ea\u52a8\u4f18\u5316\u63d0\u793a\u662f\u63d0\u53d6\u8bb0\u5fc6\u6837\u672c\u6700\u6709\u524d\u666f\u7684\u7b56\u7565\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e0d\u516c\u5f00\u5f15\u53d1\u6570\u636e\u6cc4\u9732\u62c5\u5fe7\uff0c\u73b0\u6709\u6570\u636e\u63d0\u53d6\u4f9d\u8d56\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\uff0c\u9700\u89e3\u51b3\u80fd\u5426\u6539\u8fdb\u624b\u52a8\u63d0\u793a\u3001\u975e\u624b\u52a8\u63d0\u793a\u68c0\u6d4b\u8bb0\u5fc6\u3001\u81ea\u52a8\u5316\u68c0\u6d4b\u6570\u636e\u6cc4\u9732\u7b49\u95ee\u9898\u3002", "method": "\u8bc4\u4f30\u4e09\u79cd\u65b9\u6cd5\uff0c\u5305\u62ec\u8d8a\u72f1\u63d0\u793a\u5de5\u7a0b\u3001\u65e0\u76d1\u7763\u6f5c\u5728\u77e5\u8bc6\u53d1\u73b0\uff08\u901a\u8fc7CCS\u548cCluster - Norm\u63a2\u6d4b\u5185\u90e8\u6fc0\u6d3b\uff09\u3001\u81ea\u52a8\u63d0\u793a\u5de5\u7a0b\uff08\u5c06\u63d0\u793a\u53d1\u73b0\u89c6\u4e3a\u5143\u5b66\u4e60\u8fc7\u7a0b\uff09\u3002", "result": "\u8d8a\u72f1\u63d0\u793a\u4e0d\u80fd\u6539\u5584\u8bb0\u5fc6\u9879\u68c0\u7d22\u4e14\u4e0d\u7a33\u5b9a\uff1bCCS\u80fd\u533a\u5206\u771f\u5047\u7535\u5f71\u6807\u9898\u4f46\u5bf9\u6570\u503c\u6570\u636e\u5931\u6548\uff1bAPE\u80fd\u9002\u5ea6\u68c0\u7d22\u9879\u76ee\u7ea7\u4fe1\u606f\u4f46\u96be\u6062\u590d\u6570\u503c\u4ea4\u4e92\u3002", "conclusion": "\u81ea\u52a8\u4f18\u5316\u63d0\u793a\u662f\u63d0\u53d6\u8bb0\u5fc6\u6837\u672c\u6700\u6709\u524d\u666f\u7684\u7b56\u7565\u3002"}}
{"id": "2601.01954", "pdf": "https://arxiv.org/pdf/2601.01954", "abs": "https://arxiv.org/abs/2601.01954", "authors": ["Alexander Korn", "Lea Zaruchas", "Chetan Arora", "Andreas Metzger", "Sven Smolka", "Fanyu Wang", "Andreas Vogelsang"], "title": "Reporting LLM Prompting in Automated Software Engineering: A Guideline Based on Current Practices and Expectations", "categories": ["cs.SE"], "comment": "To be published at The 3rd ACM International Conference on AI Foundation Models and Software Engineering FORGE 2026", "summary": "Large Language Models, particularly decoder-only generative models such as GPT, are increasingly used to automate Software Engineering tasks. These models are primarily guided through natural language prompts, making prompt engineering a critical factor in system performance and behavior. Despite their growing role in SE research, prompt-related decisions are rarely documented in a systematic or transparent manner, hindering reproducibility and comparability across studies. To address this gap, we conducted a two-phase empirical study. First, we analyzed nearly 300 papers published at the top-3 SE conferences since 2022 to assess how prompt design, testing, and optimization are currently reported. Second, we surveyed 105 program committee members from these conferences to capture their expectations for prompt reporting in LLM-driven research. Based on the findings, we derived a structured guideline that distinguishes essential, desirable, and exceptional reporting elements. Our results reveal significant misalignment between current practices and reviewer expectations, particularly regarding version disclosure, prompt justification, and threats to validity. We present our guideline as a step toward improving transparency, reproducibility, and methodological rigor in LLM-based SE research.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u63d0\u793a\u62a5\u544a\u95ee\u9898\uff0c\u901a\u8fc7\u6587\u732e\u5206\u6790\u548c\u4e13\u5bb6\u8c03\u67e5\u63d0\u51fa\u7ed3\u6784\u5316\u6307\u5357\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u63d0\u793a\u76f8\u5173\u51b3\u7b56\u7f3a\u4e4f\u7cfb\u7edf\u8bb0\u5f55\uff0c\u5f71\u54cd\u7814\u7a76\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6bd4\u6027\u3002", "method": "\u4e24\u9636\u6bb5\u5b9e\u8bc1\u7814\u7a76\uff0c\u4e00\u662f\u5206\u6790\u8fd1300\u7bc7\u9876\u7ea7\u4f1a\u8bae\u8bba\u6587\uff0c\u4e8c\u662f\u8c03\u67e5105\u4f4d\u7a0b\u5e8f\u59d4\u5458\u4f1a\u6210\u5458\u3002", "result": "\u5f53\u524d\u5b9e\u8df5\u4e0e\u5ba1\u7a3f\u4eba\u671f\u671b\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5c24\u5176\u5728\u7248\u672c\u62ab\u9732\u3001\u63d0\u793a\u7406\u7531\u548c\u6709\u6548\u6027\u5a01\u80c1\u65b9\u9762\u3002", "conclusion": "\u63d0\u51fa\u7ed3\u6784\u5316\u6307\u5357\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u900f\u660e\u5ea6\u3001\u53ef\u91cd\u590d\u6027\u548c\u65b9\u6cd5\u4e25\u8c28\u6027\u3002"}}
{"id": "2601.01301", "pdf": "https://arxiv.org/pdf/2601.01301", "abs": "https://arxiv.org/abs/2601.01301", "authors": ["Keith Frankston", "Benjamin Howard"], "title": "Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies", "categories": ["cs.AI", "cs.LG"], "comment": "11 pages; an efficient implementation is available at https://github.com/bhoward73/rmcts", "summary": "We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, \"RMCTS\". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.\n  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in \"Monte--Carlo tree search as regularized policy optimization\" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.\n  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.", "AI": {"tldr": "\u4ecb\u7ecd\u9012\u5f52AlphaZero\u98ce\u683c\u7684\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\u7b97\u6cd5RMCTS\uff0c\u5176\u6bd4MCTS - UCB\u901f\u5ea6\u5feb\uff0c\u867d\u6709\u7f3a\u70b9\u4f46\u8bad\u7ec3\u7f51\u7edc\u6548\u679c\u76f8\u8fd1\u4e14\u65f6\u95f4\u77ed\uff0c\u8fd8\u7ed9\u51fa\u4e09\u79cd\u6e38\u620f\u5bf9\u6bd4\u3002", "motivation": "\u63d0\u51fa\u6bd4AlphaZero\u7684MCTS - UCB\u901f\u5ea6\u66f4\u5feb\u7684\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u5e7f\u5ea6\u4f18\u5148\u65b9\u5f0f\u63a2\u7d22\u641c\u7d22\u6811\u4ee5\u6279\u91cf\u8fdb\u884c\u7f51\u7edc\u63a8\u7406\uff1b\u57fa\u4e8e\u8ba1\u7b97\u641c\u7d22\u6811\u5404\u6e38\u620f\u72b6\u6001\u7684\u4f18\u5316\u540e\u9a8c\u7b56\u7565\u8fdb\u884c\u9012\u5f52\uff1b\u6309\u5148\u9a8c\u7f51\u7edc\u7b56\u7565\u5b9a\u4e49\u6811\u3002", "result": "\u641c\u7d22\u5355\u4e00\u6839\u72b6\u6001\u65f6RMCTS\u6bd4MCTS - UCB\u5feb\u8d8540\u500d\uff0c\u5927\u6279\u6b21\u6839\u72b6\u6001\u65f6\u5feb\u7ea63\u500d\uff1bRMCTS\u8bad\u7ec3\u7f51\u7edc\u7ea6\u7528\u4e09\u5206\u4e4b\u4e00\u65f6\u95f4\u8fbe\u5230\u4e0eMCTS - UCB\u76f8\u8fd1\u8d28\u91cf\u3002", "conclusion": "RMCTS\u867d\u6811\u5b9a\u4e49\u65b9\u5f0f\u6709\u52a3\u52bf\uff0c\u4f46\u901f\u5ea6\u63d0\u5347\u4f18\u52bf\u663e\u8457\uff0c\u5728\u8bad\u7ec3\u65f6\u95f4\u4e0a\u6709\u8f83\u5927\u4f18\u52bf\u3002"}}
{"id": "2601.00987", "pdf": "https://arxiv.org/pdf/2601.00987", "abs": "https://arxiv.org/abs/2601.00987", "authors": ["H\u00e9l\u00e8ne Halconruy", "Benjamin Bobbia", "Paul Lejamtel"], "title": "Tessellation Localized Transfer learning for nonparametric regression", "categories": ["math.ST", "stat.AP", "stat.ML"], "comment": "57 pages, 2 figures", "summary": "Transfer learning aims to improve performance on a target task by leveraging information from related source tasks. We propose a nonparametric regression transfer learning framework that explicitly models heterogeneity in the source-target relationship. Our approach relies on a local transfer assumption: the covariate space is partitioned into finitely many cells such that, within each cell, the target regression function can be expressed as a low-complexity transformation of the source regression function. This localized structure enables effective transfer where similarity is present while limiting negative transfer elsewhere. We introduce estimators that jointly learn the local transfer functions and the target regression, together with fully data-driven procedures that adapt to unknown partition structure and transfer strength. We establish sharp minimax rates for target regression estimation, showing that local transfer can mitigate the curse of dimensionality by exploiting reduced functional complexity. Our theoretical guarantees take the form of oracle inequalities that decompose excess risk into estimation and approximation terms, ensuring robustness to model misspecification. Numerical experiments illustrate the benefits of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u975e\u53c2\u6570\u56de\u5f52\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u6709\u6548\u8fc1\u79fb\u4fe1\u606f\u5e76\u9650\u5236\u8d1f\u8fc1\u79fb\uff0c\u6709\u7406\u8bba\u4fdd\u8bc1\u4e14\u5b9e\u9a8c\u9a8c\u8bc1\u4f18\u52bf\u3002", "motivation": "\u5229\u7528\u76f8\u5173\u6e90\u4efb\u52a1\u4fe1\u606f\u63d0\u5347\u76ee\u6807\u4efb\u52a1\u6027\u80fd\uff0c\u89e3\u51b3\u6e90 - \u76ee\u6807\u5173\u7cfb\u5f02\u8d28\u6027\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5c40\u90e8\u8fc1\u79fb\u5047\u8bbe\uff0c\u5212\u5206\u534f\u53d8\u91cf\u7a7a\u95f4\uff0c\u8054\u5408\u5b66\u4e60\u5c40\u90e8\u8fc1\u79fb\u51fd\u6570\u548c\u76ee\u6807\u56de\u5f52\uff0c\u91c7\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u9002\u5e94\u672a\u77e5\u7ed3\u6784\u548c\u8fc1\u79fb\u5f3a\u5ea6\u3002", "result": "\u5efa\u7acb\u76ee\u6807\u56de\u5f52\u4f30\u8ba1\u7684\u6781\u5c0f\u6781\u5927\u7387\uff0c\u7406\u8bba\u4fdd\u8bc1\u4ee5 oracle \u4e0d\u7b49\u5f0f\u5f62\u5f0f\u5206\u89e3\u8d85\u989d\u98ce\u9669\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u5229\u7528\u529f\u80fd\u590d\u6742\u5ea6\u964d\u4f4e\u7f13\u89e3\u7ef4\u6570\u707e\u96be\uff0c\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u52bf\u3002"}}
{"id": "2601.02254", "pdf": "https://arxiv.org/pdf/2601.02254", "abs": "https://arxiv.org/abs/2601.02254", "authors": ["Jay Kuri"], "title": "Vouchsafe: A Zero-Infrastructure Capability Graph Model for Offline Identity and Trust", "categories": ["cs.CR", "cs.DC"], "comment": "32 pages", "summary": "Modern identity and trust systems collapse in the environments where they are needed most: disaster zones, disconnected or damaged networks, and adversarial conditions such as censorship or infrastructure interference. These systems depend on functioning networks to reach online authorities, resolvers, directories, and revocation services, leaving trust unverifiable whenever communication is unavailable or untrusted. This work demonstrates that secure identity and trust are possible without such infrastructure. We introduce the Zero-Infrastructure Capability Graph (ZI-CG), a model showing that identity, delegation, and revocation can be represented as self-contained, signed statements whose validity is determined entirely by local, deterministic evaluation. We further present Vouchsafe, a complete working instantiation of this model built using widely deployed primitives including Ed25519, SHA-256, and structured JSON Web Tokens, requiring no new cryptography or online services. The results show that a practical, offline-verifiable trust substrate can be constructed today using only the cryptographic data presented at evaluation time.", "AI": {"tldr": "\u73b0\u6709\u8eab\u4efd\u4e0e\u4fe1\u4efb\u7cfb\u7edf\u5728\u6076\u52a3\u73af\u5883\u6613\u5d29\u6e83\uff0c\u672c\u6587\u63d0\u51faZI - CG\u6a21\u578b\u53caVouchsafe\u5b9e\u4f8b\uff0c\u8868\u660e\u53ef\u6784\u5efa\u79bb\u7ebf\u53ef\u9a8c\u8bc1\u4fe1\u4efb\u57fa\u7840\u3002", "motivation": "\u73b0\u4ee3\u8eab\u4efd\u548c\u4fe1\u4efb\u7cfb\u7edf\u5728\u707e\u96be\u533a\u3001\u7f51\u7edc\u6545\u969c\u6216\u5bf9\u6297\u73af\u5883\u4e2d\u4f9d\u8d56\u7f51\u7edc\uff0c\u901a\u4fe1\u4e0d\u53ef\u7528\u6216\u4e0d\u53ef\u4fe1\u65f6\u4fe1\u4efb\u65e0\u6cd5\u9a8c\u8bc1\uff0c\u9700\u65e0\u57fa\u7840\u8bbe\u65bd\u7684\u5b89\u5168\u8eab\u4efd\u548c\u4fe1\u4efb\u7cfb\u7edf\u3002", "method": "\u5f15\u5165Zero - Infrastructure Capability Graph (ZI - CG)\u6a21\u578b\uff0c\u7528Ed25519\u3001SHA - 256\u548c\u7ed3\u6784\u5316JSON Web Tokens\u6784\u5efaVouchsafe\u5b9e\u4f8b\u3002", "result": "\u80fd\u4ec5\u4f7f\u7528\u8bc4\u4f30\u65f6\u7684\u52a0\u5bc6\u6570\u636e\u6784\u5efa\u5b9e\u7528\u7684\u79bb\u7ebf\u53ef\u9a8c\u8bc1\u4fe1\u4efb\u57fa\u7840\u3002", "conclusion": "\u65e0\u9700\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\uff0c\u53ef\u5b9e\u73b0\u5b89\u5168\u7684\u8eab\u4efd\u548c\u4fe1\u4efb\u3002"}}
{"id": "2601.02306", "pdf": "https://arxiv.org/pdf/2601.02306", "abs": "https://arxiv.org/abs/2601.02306", "authors": ["Shivam Verma", "Hannes Karlbom", "Yu Zhao", "Nick Topping", "Vivian Chen", "Kieran Stanley", "Bharath Rengarajan"], "title": "Cold-Starting Podcast Ads and Promotions with Multi-Task Learning on Spotify", "categories": ["cs.IR"], "comment": "Accepted at WSDM 2026", "summary": "We present a unified multi-objective model for targeting both advertisements and promotions within the Spotify podcast ecosystem. Our approach addresses key challenges in personalization and cold-start initialization, particularly for new advertising objectives. By leveraging transfer learning from large-scale ad and content interactions within a multi-task learning (MTL) framework, a single joint model can be fine-tuned or directly applied to new or low-data targeting tasks, including in-app promotions. This multi-objective design jointly optimizes podcast outcomes such as streams, clicks, and follows for both ads and promotions using a shared representation over user, content, context, and creative features, effectively supporting diverse business goals while improving user experience. Online A/B tests show up to a 22% reduction in effective Cost-Per-Stream (eCPS), particularly for less-streamed podcasts, and an 18-24% increase in podcast stream rates. Offline experiments and ablations highlight the contribution of ancillary objectives and feature groups to cold-start performance. Our experience shows that a unified modeling strategy improves maintainability, cold-start performance, and coverage, while breaking down historically siloed targeting pipelines. We discuss practical trade-offs of such joint models in a real-world advertising system.", "AI": {"tldr": "\u63d0\u51fa\u9002\u7528\u4e8eSpotify\u64ad\u5ba2\u751f\u6001\u7cfb\u7edf\u7684\u7edf\u4e00\u591a\u76ee\u6807\u6a21\u578b\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u89e3\u51b3\u4e2a\u6027\u5316\u548c\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u7ebf\u4e0aA/B\u6d4b\u8bd5\u663e\u793a\u6548\u679c\u826f\u597d\u3002", "motivation": "\u89e3\u51b3Spotify\u64ad\u5ba2\u751f\u6001\u4e2d\u5e7f\u544a\u548c\u4fc3\u9500\u7684\u4e2a\u6027\u5316\u53ca\u51b7\u542f\u52a8\u521d\u59cb\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u9488\u5bf9\u65b0\u5e7f\u544a\u76ee\u6807\u3002", "method": "\u5728\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u4e0b\u5229\u7528\u5927\u89c4\u6a21\u5e7f\u544a\u548c\u5185\u5bb9\u4ea4\u4e92\u7684\u8fc1\u79fb\u5b66\u4e60\uff0c\u91c7\u7528\u7edf\u4e00\u591a\u76ee\u6807\u6a21\u578b\u4f18\u5316\u64ad\u5ba2\u6210\u679c\u3002", "result": "\u7ebf\u4e0aA/B\u6d4b\u8bd5\u663e\u793a\uff0c\u64ad\u653e\u91cf\u5c11\u7684\u64ad\u5ba2\u6709\u6548\u6bcf\u6d41\u6210\u672c\u6700\u9ad8\u964d\u4f4e22%\uff0c\u64ad\u5ba2\u6d41\u7387\u63d0\u9ad818 - 24%\uff1b\u79bb\u7ebf\u5b9e\u9a8c\u51f8\u663e\u8f85\u52a9\u76ee\u6807\u548c\u7279\u5f81\u7ec4\u5bf9\u51b7\u542f\u52a8\u8868\u73b0\u7684\u8d21\u732e\u3002", "conclusion": "\u7edf\u4e00\u5efa\u6a21\u7b56\u7565\u53ef\u63d0\u9ad8\u53ef\u7ef4\u62a4\u6027\u3001\u51b7\u542f\u52a8\u6027\u80fd\u548c\u8986\u76d6\u8303\u56f4\uff0c\u6253\u7834\u4f20\u7edf\u76ee\u6807\u7ba1\u9053\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86\u8054\u5408\u6a21\u578b\u5728\u5b9e\u9645\u5e7f\u544a\u7cfb\u7edf\u4e2d\u7684\u6743\u8861\u3002"}}
{"id": "2601.02066", "pdf": "https://arxiv.org/pdf/2601.02066", "abs": "https://arxiv.org/abs/2601.02066", "authors": ["Al Muttakin", "Saikat Mondal", "Chanchal Roy"], "title": "The State of Open Science in Software Engineering Research: A Case Study of ICSE Artifacts", "categories": ["cs.SE"], "comment": "To appear in Proc. IEEE/ACM 48th International Conference on Software Engineering (ICSE 2026), Rio de Janeiro, Brazil, 12-18 Apr 2026", "summary": "Replication packages are crucial for enabling transparency, validation, and reuse in software engineering (SE) research. While artifact sharing is now a standard practice and even expected at premier SE venues such as ICSE, the practical usability of these replication packages remains underexplored. In particular, there is a marked lack of studies that comprehensively examine the executability and reproducibility of replication packages in SE research. In this paper, we aim to fill this gap by evaluating 100 replication packages published as part of ICSE proceedings over the past decade (2015--2024). We assess the (1) executability of the replication packages, (2) efforts and modifications required to execute them, (3) challenges that prevent executability, and (4) reproducibility of the original findings. We spent approximately 650 person-hours in total executing the artifacts and reproducing the study findings. Our findings reveal that only 40\\% of the 100 evaluated artifacts were executable, of which 32.5\\% (13 out of 40) ran without any modification. Regarding effort levels, 17.5\\% (7 out of 40) required low effort, while 82.5\\% (33 out of 40) required moderate to high effort to execute successfully. We identified five common types of modifications and 13 challenges leading to execution failure, spanning environmental, documentation, and structural issues. Among the executable artifacts, only 35\\% (14 out of 40) reproduced the original results. These findings highlight a notable gap between artifact availability, executability, and reproducibility. Our study proposes three actionable guidelines to improve the preparation, documentation, and review of research artifacts, thereby strengthening the rigor and sustainability of open science practices in SE research.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u8fc7\u53bb\u5341\u5e74ICSE\u4f1a\u8bae\u7684100\u4e2a\u590d\u5236\u5305\uff0c\u53d1\u73b0\u53ef\u6267\u884c\u6027\u548c\u53ef\u91cd\u590d\u6027\u4f4e\uff0c\u63d0\u51fa\u6539\u8fdb\u6307\u5357\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u590d\u5236\u5305\u53ef\u6267\u884c\u6027\u548c\u53ef\u91cd\u590d\u6027\u7684\u5168\u9762\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bc4\u4f302015 - 2024\u5e74ICSE\u4f1a\u8bae\u7684100\u4e2a\u590d\u5236\u5305\uff0c\u5206\u6790\u53ef\u6267\u884c\u6027\u3001\u6267\u884c\u6240\u9700\u52aa\u529b\u548c\u4fee\u6539\u3001\u6267\u884c\u5931\u8d25\u6311\u6218\u53ca\u7ed3\u679c\u53ef\u91cd\u590d\u6027\u3002", "result": "100\u4e2a\u5de5\u4ef6\u4e2d\u4ec540%\u53ef\u6267\u884c\uff0c\u5176\u4e2d32.5%\u65e0\u9700\u4fee\u6539\uff0c82.5%\u9700\u4e2d\u9ad8\u52aa\u529b\uff1b\u786e\u5b9a5\u79cd\u5e38\u89c1\u4fee\u6539\u7c7b\u578b\u548c13\u79cd\u6267\u884c\u5931\u8d25\u6311\u6218\uff1b\u53ef\u6267\u884c\u5de5\u4ef6\u4e2d\u4ec535%\u80fd\u91cd\u73b0\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u6307\u51fa\u5de5\u4ef6\u53ef\u7528\u6027\u3001\u53ef\u6267\u884c\u6027\u548c\u53ef\u91cd\u590d\u6027\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e09\u6761\u6539\u8fdb\u7814\u7a76\u5de5\u4ef6\u7684\u53ef\u884c\u6307\u5357\u3002"}}
{"id": "2601.01321", "pdf": "https://arxiv.org/pdf/2601.01321", "abs": "https://arxiv.org/abs/2601.01321", "authors": ["Rong Zhou", "Dongping Chen", "Zihan Jia", "Yao Su", "Yixin Liu", "Yiwen Lu", "Dongwei Shi", "Yue Huang", "Tianyang Xu", "Yi Pan", "Xinliang Li", "Yohannes Abate", "Qingyu Chen", "Zhengzhong Tu", "Yu Yang", "Yu Zhang", "Qingsong Wen", "Gengchen Mai", "Sunyang Fu", "Jiachen Li", "Xuyu Wang", "Ziran Wang", "Jing Huang", "Tianming Liu", "Yong Chen", "Lichao Sun", "Lifang He"], "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models", "categories": ["cs.AI"], "comment": null, "summary": "Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7edf\u4e00\u7684\u56db\u9636\u6bb5\u6846\u67b6\u6765\u63cf\u8ff0AI\u5728\u6570\u5b57\u5b6a\u751f\u751f\u547d\u5468\u671f\u4e2d\u7684\u96c6\u6210\uff0c\u5206\u6790\u7269\u7406\u5efa\u6a21\u4e0e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u7684\u534f\u540c\uff0c\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5bf9\u6570\u5b57\u5b6a\u751f\u7684\u6539\u53d8\uff0c\u8de8\u9886\u57df\u5ba1\u67e5\u8bc6\u522b\u6311\u6218\u5e76\u7ed9\u51fa\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u878d\u5165\uff0c\u6570\u5b57\u5b6a\u751f\u5df2\u4ece\u88ab\u52a8\u4eff\u771f\u5de5\u5177\u6f14\u53d8\u4e3a\u667a\u80fd\u81ea\u4e3b\u5b9e\u4f53\uff0c\u9700\u8981\u4e00\u4e2a\u6846\u67b6\u6765\u7cfb\u7edf\u63cf\u8ff0AI\u5728\u6570\u5b57\u5b6a\u751f\u751f\u547d\u5468\u671f\u4e2d\u7684\u96c6\u6210\u3002", "method": "\u7efc\u5408\u73b0\u6709\u6280\u672f\u548c\u5b9e\u8df5\uff0c\u63d0\u51fa\u56db\u9636\u6bb5\u6846\u67b6\uff0c\u6db5\u76d6\u5efa\u6a21\u3001\u955c\u50cf\u3001\u5e72\u9884\u548c\u81ea\u4e3b\u7ba1\u7406\u56db\u4e2a\u9636\u6bb5\uff0c\u5206\u6790\u7269\u7406\u5efa\u6a21\u4e0e\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u534f\u540c\uff0c\u63a2\u8ba8\u751f\u6210\u5f0fAI\u6280\u672f\u5f71\u54cd\uff0c\u8fdb\u884c\u8de8\u5341\u4e00\u4e2a\u5e94\u7528\u9886\u57df\u7684\u5ba1\u67e5\u3002", "result": "\u786e\u5b9a\u4e86\u6570\u5b57\u5b6a\u751f\u5728\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u7684\u5e38\u89c1\u6311\u6218\u3002", "conclusion": "\u7ed9\u51fa\u4e86\u7531AI\u9a71\u52a8\u7684\u8d1f\u8d23\u4efb\u7684\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2601.01010", "pdf": "https://arxiv.org/pdf/2601.01010", "abs": "https://arxiv.org/abs/2601.01010", "authors": ["Blake Bordelon", "Cengiz Pehlevan"], "title": "Disordered Dynamics in High Dimensions: Connections to Random Matrices and Machine Learning", "categories": ["cond-mat.dis-nn", "stat.ML"], "comment": null, "summary": "We provide an overview of high dimensional dynamical systems driven by random matrices, focusing on applications to simple models of learning and generalization in machine learning theory. Using both cavity method arguments and path integrals, we review how the behavior of a coupled infinite dimensional system can be characterized as a stochastic process for each single site of the system. We provide a pedagogical treatment of dynamical mean field theory (DMFT), a framework that can be flexibly applied to these settings. The DMFT single site stochastic process is fully characterized by a set of (two-time) correlation and response functions. For linear time-invariant systems, we illustrate connections between random matrix resolvents and the DMFT response. We demonstrate applications of these ideas to machine learning models such as gradient flow, stochastic gradient descent on random feature models and deep linear networks in the feature learning regime trained on random data. We demonstrate how bias and variance decompositions (analysis of ensembling/bagging etc) can be computed by averaging over subsets of the DMFT noise variables. From our formalism we also investigate how linear systems driven with random non-Hermitian matrices (such as random feature models) can exhibit non-monotonic loss curves with training time, while Hermitian matrices with the matching spectra do not, highlighting a different mechanism for non-monotonicity than small eigenvalues causing instability to label noise. Lastly, we provide asymptotic descriptions of the training and test loss dynamics for randomly initialized deep linear neural networks trained in the feature learning regime with high-dimensional random data. In this case, the time translation invariance structure is lost and the hidden layer weights are characterized as spiked random matrices.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u9ad8\u7ef4\u968f\u673a\u77e9\u9635\u9a71\u52a8\u52a8\u529b\u7cfb\u7edf\uff0c\u4ecb\u7ecdDMFT\u6846\u67b6\uff0c\u9610\u8ff0\u5176\u4e0e\u968f\u673a\u77e9\u9635\u89e3\u6790\u51fd\u6570\u8054\u7cfb\uff0c\u5c55\u793a\u5728\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e94\u7528\uff0c\u5206\u6790\u635f\u5931\u66f2\u7ebf\u7279\u6027\u5e76\u7ed9\u51fa\u6df1\u5ea6\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u548c\u6d4b\u8bd5\u635f\u5931\u52a8\u6001\u6e10\u8fd1\u63cf\u8ff0\u3002", "motivation": "\u805a\u7126\u673a\u5668\u5b66\u4e60\u7406\u8bba\u4e2d\u5b66\u4e60\u548c\u6cdb\u5316\u7b80\u5355\u6a21\u578b\u5e94\u7528\uff0c\u7814\u7a76\u9ad8\u7ef4\u968f\u673a\u77e9\u9635\u9a71\u52a8\u52a8\u529b\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u8154\u65b9\u6cd5\u548c\u8def\u5f84\u79ef\u5206\uff0c\u4ecb\u7ecd\u52a8\u529b\u5b66\u5e73\u5747\u573a\u7406\u8bba\uff08DMFT\uff09\u3002", "result": "\u660e\u786eDMFT\u5355\u7ad9\u70b9\u968f\u673a\u8fc7\u7a0b\u7531\u76f8\u5173\u548c\u54cd\u5e94\u51fd\u6570\u8868\u5f81\uff0c\u5c55\u793a\u5728\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e94\u7528\uff0c\u5206\u6790\u4e0d\u540c\u77e9\u9635\u9a71\u52a8\u7cfb\u7edf\u635f\u5931\u66f2\u7ebf\u7279\u6027\uff0c\u7ed9\u51fa\u6df1\u5ea6\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\u635f\u5931\u52a8\u6001\u6e10\u8fd1\u63cf\u8ff0\u3002", "conclusion": "DMFT\u6846\u67b6\u53ef\u7075\u6d3b\u5e94\u7528\u4e8e\u9ad8\u7ef4\u968f\u673a\u77e9\u9635\u9a71\u52a8\u52a8\u529b\u7cfb\u7edf\uff0c\u4e0d\u540c\u77e9\u9635\u9a71\u52a8\u7cfb\u7edf\u6709\u4e0d\u540c\u635f\u5931\u66f2\u7ebf\u7279\u6027\u3002"}}
{"id": "2601.02200", "pdf": "https://arxiv.org/pdf/2601.02200", "abs": "https://arxiv.org/abs/2601.02200", "authors": ["Markus Borg", "Nadim Hagatulah", "Adam Tornhill", "Emma S\u00f6derberg"], "title": "Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted for the 3rd ACM International Conference on AI Foundation Models and Software Engineering (FORGE 2026)", "summary": "We are entering a hybrid era in which human developers and AI coding agents work in the same codebases. While industry practice has long optimized code for human comprehension, it is increasingly important to ensure that LLMs with different capabilities can edit code reliably. In this study, we investigate the concept of ``AI-friendly code'' via LLM-based refactoring on a dataset of 5,000 Python files from competitive programming. We find a meaningful association between CodeHealth, a quality metric calibrated for human comprehension, and semantic preservation after AI refactoring. Our findings confirm that human-friendly code is also more compatible with AI tooling. These results suggest that organizations can use CodeHealth to guide where AI interventions are lower risk and where additional human oversight is warranted. Investing in maintainability not only helps humans; it also prepares for large-scale AI adoption.", "AI": {"tldr": "\u7814\u7a76\u5728\u7ade\u4e89\u7f16\u7a0b\u7684Python\u6587\u4ef6\u6570\u636e\u96c6\u4e0a\u901a\u8fc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91cd\u6784\u63a2\u8ba8\u2018AI\u53cb\u597d\u4ee3\u7801\u2019\uff0c\u53d1\u73b0CodeHealth\u4e0eAI\u91cd\u6784\u540e\u8bed\u4e49\u4fdd\u7559\u6709\u5173\uff0c\u8868\u660e\u4eba\u7c7b\u53cb\u597d\u4ee3\u7801\u4e5f\u4e0eAI\u5de5\u5177\u66f4\u517c\u5bb9\u3002", "motivation": "\u8fdb\u5165\u4eba\u7c7b\u5f00\u53d1\u8005\u548cAI\u7f16\u7801\u4ee3\u7406\u5728\u540c\u4e00\u4ee3\u7801\u5e93\u5de5\u4f5c\u7684\u6df7\u5408\u65f6\u4ee3\uff0c\u9700\u786e\u4fdd\u4e0d\u540c\u80fd\u529b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u53ef\u9760\u7f16\u8f91\u4ee3\u7801\u3002", "method": "\u5728\u5305\u542b5000\u4e2aPython\u6587\u4ef6\u7684\u7ade\u4e89\u7f16\u7a0b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u91cd\u6784\u3002", "result": "\u53d1\u73b0CodeHealth\uff08\u4e3a\u4eba\u7c7b\u7406\u89e3\u6821\u51c6\u7684\u8d28\u91cf\u6307\u6807\uff09\u4e0eAI\u91cd\u6784\u540e\u7684\u8bed\u4e49\u4fdd\u7559\u6709\u6709\u610f\u4e49\u7684\u5173\u8054\uff0c\u4eba\u7c7b\u53cb\u597d\u4ee3\u7801\u4e0eAI\u5de5\u5177\u66f4\u517c\u5bb9\u3002", "conclusion": "\u7ec4\u7ec7\u53ef\u4f7f\u7528CodeHealth\u6307\u5bfcAI\u5e72\u9884\u4f4e\u98ce\u9669\u7684\u5730\u65b9\u548c\u9700\u8981\u989d\u5916\u4eba\u5de5\u76d1\u7763\u7684\u5730\u65b9\uff0c\u6295\u8d44\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u65e2\u5e2e\u52a9\u4eba\u7c7b\uff0c\u4e5f\u4e3a\u5927\u89c4\u6a21\u91c7\u7528AI\u505a\u51c6\u5907\u3002"}}
{"id": "2601.01330", "pdf": "https://arxiv.org/pdf/2601.01330", "abs": "https://arxiv.org/abs/2601.01330", "authors": ["Shengji Tang", "Weihao Lin", "Jingqi Ye", "Hao Li", "Bo Zhang", "Shuyue Hu", "Tao Chen", "Wangli Ouyang", "Lei Bai", "Peng Ye"], "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale", "categories": ["cs.AI"], "comment": "12 pages", "summary": "Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u4f53\u667a\u80fd\uff0c\u63d0\u51faJiSi\u6846\u67b6\uff0c\u7528\u5341\u6b3e\u5f00\u6e90\u6a21\u578b\u534f\u4f5c\u5728\u6210\u672c\u4ec547%\u65f6\u8d85\u8d8aGemini - 3 - Pro\uff0c\u8868\u660e\u96c6\u4f53\u667a\u80fd\u662f\u901a\u5411AGI\u65b0\u8def\u5f84\u3002", "motivation": "\u4ee5\u96c6\u4f53\u667a\u80fd\u4f5c\u4e3a\u5355\u4e00\u6a21\u578b\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u89e3\u51b3\u73b0\u6709LLM\u8def\u7531\u548c\u805a\u5408\u7684\u74f6\u9888\u95ee\u9898\uff0c\u4f7f\u5f00\u6e90LLM\u534f\u4f5c\u80fd\u8d85\u8d8aGemini - 3 - Pro\u3002", "method": "\u5f15\u5165JiSi\u6846\u67b6\uff0c\u5305\u62ec\u67e5\u8be2 - \u54cd\u5e94\u6df7\u5408\u8def\u7531\u3001\u57fa\u4e8e\u652f\u6301\u96c6\u7684\u805a\u5408\u5668\u9009\u62e9\u3001\u81ea\u9002\u5e94\u8def\u7531 - \u805a\u5408\u5207\u6362\u4e09\u9879\u521b\u65b0\u3002", "result": "\u5728\u4e5d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cJiSi\u901a\u8fc7\u7f16\u6392\u5341\u6b3e\u5f00\u6e90LLM\uff0c\u4ee547%\u7684\u6210\u672c\u8d85\u8d8aGemini - 3 - Pro\uff0c\u4e14\u4f18\u4e8e\u4e3b\u6d41\u57fa\u7ebf\u3002", "conclusion": "\u96c6\u4f53\u667a\u80fd\u4ee3\u8868\u4e86\u901a\u5411\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u7684\u4e00\u6761\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.01069", "pdf": "https://arxiv.org/pdf/2601.01069", "abs": "https://arxiv.org/abs/2601.01069", "authors": ["Jing Wang", "Peng Zhao", "Zhi-Hua Zhou"], "title": "Revisiting Weighted Strategy for Non-stationary Parametric Bandits and MDPs", "categories": ["cs.LG", "stat.ML"], "comment": "accepted by IEEE Transactions on Information Theory. arXiv admin note: substantial text overlap with arXiv:2303.02691", "summary": "Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a \\emph{refined analysis framework}, which simplifies the derivation and, importantly, produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\\tilde{O}(k_\u03bc^{5/4} c_\u03bc^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$ regret, improving the $\\tilde{O}(k_\u03bc^{2} c_\u03bc^{-1}d^{9/10} P_T^{1/5}T^{4/5})$ bound in prior work, where $k_\u03bc$ and $c_\u03bc$ characterize the reward model's nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon. Moreover, we extend our framework to non-stationary Markov Decision Processes (MDPs) with function approximation, focusing on Linear Mixture MDP and Multinomial Logit (MNL) Mixture MDP. For both classes, we propose algorithms based on the weighted strategy and establish dynamic regret guarantees using our analysis framework.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u975e\u5e73\u7a33\u53c2\u6570\u5316\u591a\u81c2\u8001\u864e\u673a\u7684\u52a0\u6743\u7b56\u7565\uff0c\u63d0\u51fa\u7cbe\u70bc\u5206\u6790\u6846\u67b6\uff0c\u7b80\u5316\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u6539\u8fdb\u591a\u79cd\u53c2\u6570\u5316\u8001\u864e\u673a\u548c\u975e\u5e73\u7a33\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u540e\u6094\u754c\u3002", "motivation": "\u5148\u524d\u52a0\u6743\u7b56\u7565\u7406\u8bba\u5206\u6790\u590d\u6742\uff0c\u7b97\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\u6216\u7edf\u8ba1\u6b21\u4f18\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u7cbe\u70bc\u5206\u6790\u6846\u67b6\uff0c\u63a8\u5bfc\u7b80\u5355\u6743\u91cd\u7b97\u6cd5\uff0c\u5e76\u5c06\u6846\u67b6\u62d3\u5c55\u5230\u975e\u5e73\u7a33\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u4e0e\u7a97\u53e3/\u91cd\u542f\u7b97\u6cd5\u6548\u7387\u76f8\u5f53\uff0c\u6539\u8fdb\u591a\u79cd\u53c2\u6570\u5316\u8001\u864e\u673a\u540e\u6094\u754c\uff0c\u4e3a\u975e\u5e73\u7a33\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5efa\u7acb\u52a8\u6001\u540e\u6094\u4fdd\u8bc1\u3002", "conclusion": "\u7cbe\u70bc\u5206\u6790\u6846\u67b6\u6709\u6548\uff0c\u80fd\u7b80\u5316\u7b97\u6cd5\u8bbe\u8ba1\u5e76\u6539\u8fdb\u591a\u79cd\u6a21\u578b\u7684\u540e\u6094\u754c\u3002"}}
{"id": "2601.01024", "pdf": "https://arxiv.org/pdf/2601.01024", "abs": "https://arxiv.org/abs/2601.01024", "authors": ["Tien-Huy Nguyen", "Huu-Loc Tran", "Thanh Duc Ngo"], "title": "ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval", "categories": ["cs.CV", "cs.AI", "cs.IR"], "comment": "Accepted at WACV Main Track 2026", "summary": "Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself", "AI": {"tldr": "\u672c\u6587\u63d0\u51faITSELF\u6846\u67b6\u7528\u4e8e\u6587\u672c\u7684\u4eba\u7269\u641c\u7d22\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u4e14\u65e0\u9700\u989d\u5916\u76d1\u7763\u3002", "motivation": "\u4ee5\u5f80\u57fa\u4e8e\u5c40\u90e8\u5bf9\u9f50\u7684\u6587\u672c\u4eba\u7269\u641c\u7d22\u65b9\u6cd5\u5bb9\u6613\u51fa\u73b0\u6377\u5f84\u5b66\u4e60\u548c\u865a\u5047\u5173\u8054\uff0c\u6ce8\u5165\u5148\u9a8c\u77e5\u8bc6\u4f1a\u626d\u66f2\u6a21\u6001\u5185\u7ed3\u6784\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165ITSELF\u6846\u67b6\uff0c\u6838\u5fc3\u662fGRAB\u5c06\u6a21\u578b\u6ce8\u610f\u529b\u8f6c\u4e3a\u9ad8\u663e\u8457\u6027\u6807\u8bb0\u7684\u6ce8\u610f\u529b\u5e93\uff0c\u4f7f\u7528MARS\u805a\u5408\u5404\u5c42\u6ce8\u610f\u529b\u5e76\u8fdb\u884c\u591a\u6837\u6027\u7684top - k\u9009\u62e9\uff0c\u7528ATS\u52a8\u6001\u8c03\u6574\u4fdd\u7559\u6807\u8bb0\u7b56\u7565\u3002", "result": "\u5728\u4e09\u4e2a\u5e38\u7528\u7684TBPS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5177\u6709\u5f88\u5f3a\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u4e14\u7a33\u5065\uff0c\u65e0\u9700\u989d\u5916\u7684\u5148\u9a8c\u76d1\u7763\u3002"}}
{"id": "2601.02215", "pdf": "https://arxiv.org/pdf/2601.02215", "abs": "https://arxiv.org/abs/2601.02215", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Fengjunjie Pan", "Alois Knoll"], "title": "LLM-Empowered Functional Safety and Security by Design in Automotive Systems", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.", "AI": {"tldr": "\u63d0\u51fa\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u5de5\u4f5c\u6d41\u7a0b\u652f\u6301\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\uff0c\u6db5\u76d6\u5b89\u5168\u7cfb\u7edf\u62d3\u6251\u8bbe\u8ba1\u548c\u4ee3\u7801\u5206\u6790\u3002", "motivation": "\u652f\u6301\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\uff08SDV\uff09\u7684\u8f6f\u4ef6\u5f00\u53d1\u3002", "method": "\u4ee3\u7801\u5206\u6790\u91c7\u7528\u4e8b\u4ef6\u94fe\u6a21\u578b\uff0c\u62d3\u6251\u5b89\u5168\u5206\u6790\u7ed3\u5408\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u65b9\u6cd5\u548c\u5bf9\u8c61\u7ea6\u675f\u8bed\u8a00\uff08OCL\uff09\u89c4\u5219\uff0c\u8003\u8651\u672c\u5730\u90e8\u7f72\u548c\u4e13\u6709\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6587\u6863\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u6863\u672a\u660e\u786e\u5f97\u51fa\u76f8\u5173\u7ed3\u8bba\u3002"}}
{"id": "2601.01363", "pdf": "https://arxiv.org/pdf/2601.01363", "abs": "https://arxiv.org/abs/2601.01363", "authors": ["Xiaomeng Yang", "Zhiyu Tan", "Xiaohui Zhong", "Mengping Yang", "Qiusheng Huang", "Lei Chen", "Libo Wu", "Hao Li"], "title": "A unified multimodal understanding and generation model for cross-disciplinary scientific research", "categories": ["cs.AI"], "comment": null, "summary": "Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25\u00b0 resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.", "AI": {"tldr": "\u63d0\u51fa\u8de8\u5b66\u79d1\u79d1\u5b66\u7406\u89e3\u4e0e\u751f\u6210\u6a21\u578bFuXi - Uni\uff0c\u5728\u5730\u7403\u79d1\u5b66\u548c\u751f\u7269\u533b\u5b66\u9a8c\u8bc1\u6548\u679c\u826f\u597d\uff0c\u63a8\u52a8\u901a\u7528\u591a\u6a21\u6001\u79d1\u5b66\u6a21\u578b\u53d1\u5c55\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u591a\u4e3a\u7279\u5b9a\u9886\u57df\uff0c\u7f3a\u4e4f\u540c\u65f6\u7406\u89e3\u548c\u751f\u6210\u591a\u6a21\u6001\u79d1\u5b66\u6570\u636e\u80fd\u529b\uff0c\u800c\u8bb8\u591a\u79d1\u5b66\u95ee\u9898\u662f\u8de8\u5b66\u79d1\u7684\uff0c\u9700\u8981\u8de8\u9886\u57df\u8fdb\u5c55\u3002", "method": "\u5c06\u8de8\u5b66\u79d1\u79d1\u5b66\u6807\u8bb0\u4e0e\u81ea\u7136\u8bed\u8a00\u6807\u8bb0\u5bf9\u9f50\uff0c\u4f7f\u7528\u79d1\u5b66\u89e3\u7801\u5668\u91cd\u5efa\u79d1\u5b66\u6807\u8bb0\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u548c\u79d1\u5b66\u6570\u503c\u9884\u6d4b\u3002", "result": "\u5728\u5730\u7403\u79d1\u5b66\u4e2d\uff0c\u652f\u6301\u5168\u7403\u5929\u6c14\u9884\u62a5\u7b49\uff0c10\u5929\u5168\u7403\u9884\u62a5\u3001\u70ed\u5e26\u6c14\u65cb\u9884\u6d4b\u548c\u9ad8\u5206\u8fa8\u7387\u533a\u57df\u5929\u6c14\u573a\u751f\u6210\u6548\u679c\u8d85\u73b0\u6709\u65b9\u6cd5\uff1b\u5728\u751f\u7269\u533b\u5b66\u4e2d\uff0c\u5728\u591a\u4e2a\u751f\u7269\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u9886\u5148\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "FuXi - Uni\u5728\u7edf\u4e00\u5f02\u6784\u79d1\u5b66\u6a21\u6001\u540c\u65f6\u4fdd\u6301\u5f3a\u7279\u5b9a\u9886\u57df\u6027\u80fd\uff0c\u63a8\u52a8\u66f4\u901a\u7528\u591a\u6a21\u6001\u79d1\u5b66\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2601.01127", "pdf": "https://arxiv.org/pdf/2601.01127", "abs": "https://arxiv.org/abs/2601.01127", "authors": ["Golbahar Amanpour", "Benyamin Ghojogh"], "title": "Wittgenstein's Family Resemblance Clustering Algorithm", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u65b0\u9896\u7684\u673a\u5668\u5b66\u4e60\u805a\u7c7b\u7b97\u6cd5\uff0c\u53d7\u7ef4\u7279\u6839\u65af\u5766\u5bb6\u65cf\u76f8\u4f3c\u6982\u5ff5\u542f\u53d1\u63d0\u51faWFR\u53ca\u5176\u6838\u53d8\u4f53\u7b97\u6cd5\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u501f\u9274\u54f2\u5b66\u6982\u5ff5\u4ee5\u5f00\u53d1\u65b0\u7684\u673a\u5668\u5b66\u4e60\u805a\u7c7b\u65b9\u6cd5\uff0c\u6446\u8131\u5bf9\u805a\u7c7b\u6570\u91cf\u5148\u9a8c\u77e5\u8bc6\u548c\u5f62\u72b6\u5047\u8bbe\u7684\u4f9d\u8d56\u3002", "method": "\u57fa\u4e8e\u7ef4\u7279\u6839\u65af\u5766\u7684\u5bb6\u65cf\u76f8\u4f3c\u6982\u5ff5\u5f00\u53d1WFR\u805a\u7c7b\u7b97\u6cd5\u548c\u6838WFR\u7b97\u6cd5\uff0c\u8ba1\u7b97\u76f8\u90bb\u6570\u636e\u5b9e\u4f8b\u7684\u76f8\u4f3c\u5ea6\u5f97\u5206\uff0c\u6784\u5efa\u76f8\u4f3c\u5ea6\u56fe\u786e\u5b9a\u805a\u7c7b\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u6a21\u62df\u8868\u660eWFR\u662f\u6709\u6548\u7684\u975e\u7ebf\u6027\u805a\u7c7b\u7b97\u6cd5\u3002", "conclusion": "WFR\u7b97\u6cd5\u4e0d\u4f9d\u8d56\u805a\u7c7b\u6570\u91cf\u7684\u5148\u9a8c\u77e5\u8bc6\u548c\u5bf9\u805a\u7c7b\u5f62\u72b6\u7684\u5047\u8bbe\uff0c\u662f\u6709\u6548\u7684\u975e\u7ebf\u6027\u805a\u7c7b\u7b97\u6cd5\u3002"}}
{"id": "2601.01094", "pdf": "https://arxiv.org/pdf/2601.01094", "abs": "https://arxiv.org/abs/2601.01094", "authors": ["Yubo Shu", "Peng Zhang", "Meng Wu", "Yan Chen", "Haoxuan Zhou", "Guanming Liu", "Yu Zhang", "Liuxin Zhang", "Qianying Wang", "Tun Lu", "Ning Gu"], "title": "SoulSeek: Exploring the Use of Social Cues in LLM-based Information Seeking", "categories": ["cs.HC", "cs.AI", "cs.IR"], "comment": null, "summary": "Social cues, which convey others' presence, behaviors, or identities, play a crucial role in human information seeking by helping individuals judge relevance and trustworthiness. However, existing LLM-based search systems primarily rely on semantic features, creating a misalignment with the socialized cognition underlying natural information seeking. To address this gap, we explore how the integration of social cues into LLM-based search influences users' perceptions, experiences, and behaviors. Focusing on social media platforms that are beginning to adopt LLM-based search, we integrate design workshops, the implementation of the prototype system (SoulSeek), a between-subjects study, and mixed-method analyses to examine both outcome- and process-level findings. The workshop informs the prototype's cue-integrated design. The study shows that social cues improve perceived outcomes and experiences, promote reflective information behaviors, and reveal limits of current LLM-based search. We propose design implications emphasizing better social-knowledge understanding, personalized cue settings, and controllable interactions.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5c06\u793e\u4ea4\u7ebf\u7d22\u878d\u5165\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u641c\u7d22\u5bf9\u7528\u6237\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u591a\u79cd\u7814\u7a76\u65b9\u6cd5\u53d1\u73b0\u793e\u4ea4\u7ebf\u7d22\u80fd\u63d0\u5347\u641c\u7d22\u6548\u679c\u548c\u4f53\u9a8c\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u641c\u7d22\u7cfb\u7edf\u7684\u5c40\u9650\u5e76\u63d0\u51fa\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u641c\u7d22\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u8bed\u4e49\u7279\u5f81\uff0c\u4e0e\u4eba\u7c7b\u81ea\u7136\u4fe1\u606f\u641c\u7d22\u4e2d\u7684\u793e\u4f1a\u5316\u8ba4\u77e5\u5b58\u5728\u504f\u5dee\uff0c\u56e0\u6b64\u63a2\u7d22\u878d\u5165\u793e\u4ea4\u7ebf\u7d22\u7684\u5f71\u54cd\u3002", "method": "\u805a\u7126\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u641c\u7d22\u7684\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\uff0c\u7ed3\u5408\u8bbe\u8ba1\u7814\u8ba8\u4f1a\u3001\u539f\u578b\u7cfb\u7edf\uff08SoulSeek\uff09\u5b9e\u73b0\u3001\u7ec4\u95f4\u7814\u7a76\u548c\u6df7\u5408\u65b9\u6cd5\u5206\u6790\u3002", "result": "\u793e\u4ea4\u7ebf\u7d22\u80fd\u6539\u5584\u7528\u6237\u5bf9\u641c\u7d22\u7ed3\u679c\u7684\u611f\u77e5\u548c\u4f53\u9a8c\uff0c\u4fc3\u8fdb\u53cd\u601d\u6027\u4fe1\u606f\u884c\u4e3a\uff0c\u63ed\u793a\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u641c\u7d22\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u63d0\u51fa\u8bbe\u8ba1\u5efa\u8bae\uff0c\u5f3a\u8c03\u66f4\u597d\u5730\u7406\u89e3\u793e\u4ea4\u77e5\u8bc6\u3001\u4e2a\u6027\u5316\u7ebf\u7d22\u8bbe\u7f6e\u548c\u53ef\u63a7\u4ea4\u4e92\u3002"}}
{"id": "2601.02238", "pdf": "https://arxiv.org/pdf/2601.02238", "abs": "https://arxiv.org/abs/2601.02238", "authors": ["Nils Bosbach", "Alwalid Salama", "Lukas J\u00fcnger", "Mark Burton", "Niko Zurstra\u00dfen", "Rebecca Pelke", "Rainer Leupers"], "title": "NQC2: A Non-Intrusive QEMU Code Coverage Plugin", "categories": ["cs.SE"], "comment": "PREPRINT - accepted by the Rapid Simulation and Performance Evaluation for Design Workshop (RAPIDO '24)", "summary": "Code coverage analysis has become a standard approach in software development, facilitating the assessment of test suite effectiveness, the identification of under-tested code segments, and the discovery of performance bottlenecks. When code coverage of software for embedded systems needs to be measured, conventional approaches quickly meet their limits. A commonly used approach involves instrumenting the source files with added code that collects and dumps coverage information during runtime. This inserted code usually relies on the existence of an operating and a file system to dump the collected data. These features are not available for bare-metal programs that are executed on embedded systems.\n  To overcome this issue, we present NQC2, a plugin for QEMU.NQC2 extracts coverage information from QEMU during runtime and stores them into a file on the host machine. This approach is even compatible with modified QEMU versions and does not require target-software instrumentation. NQC2 outperforms a comparable approach from Xilinx by up to 8.5 x.", "AI": {"tldr": "\u4f20\u7edf\u65b9\u6cd5\u6d4b\u91cf\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4ee3\u7801\u8986\u76d6\u7387\u6709\u5c40\u9650\uff0c\u63d0\u51faNQC2\u63d2\u4ef6\u89e3\u51b3\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u7ade\u54c1\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u8986\u76d6\u7387\u6d4b\u91cf\u65b9\u6cd5\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e0d\u9002\u5408\u88f8\u673a\u7a0b\u5e8f\u3002", "method": "\u63d0\u51faNQC2\u63d2\u4ef6\uff0c\u4eceQEMU\u8fd0\u884c\u65f6\u63d0\u53d6\u8986\u76d6\u7387\u4fe1\u606f\u5e76\u5b58\u50a8\u5230\u4e3b\u673a\u6587\u4ef6\uff0c\u65e0\u9700\u76ee\u6807\u8f6f\u4ef6\u63d2\u6869\uff0c\u517c\u5bb9\u4fee\u6539\u7248QEMU\u3002", "result": "NQC2\u6027\u80fd\u6bd4Xilinx\u7684\u7c7b\u4f3c\u65b9\u6cd5\u6700\u9ad8\u5feb8.5\u500d\u3002", "conclusion": "NQC2\u80fd\u6709\u6548\u89e3\u51b3\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4ee3\u7801\u8986\u76d6\u7387\u6d4b\u91cf\u95ee\u9898\uff0c\u6027\u80fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.01366", "pdf": "https://arxiv.org/pdf/2601.01366", "abs": "https://arxiv.org/abs/2601.01366", "authors": ["Zixian Liu", "Sihao Liu", "Yuqi Zhao"], "title": "KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.", "AI": {"tldr": "\u73b0\u6709\u6559\u80b2\u57fa\u51c6\u6846\u67b6\u652f\u6301\u8de8\u5e73\u53f0\u4efb\u52a1\u5b58\u5728\u4e0d\u8db3\uff0c\u8bba\u6587\u63d0\u51fa\u65b0\u57fa\u51c6\u5e73\u53f0KGCE\uff0c\u6784\u5efa\u76f8\u5173\u6570\u636e\u96c6\uff0c\u6709\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u548c\u589e\u5f3a\u4ee3\u7406\u7cfb\u7edf\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u6559\u80b2\u57fa\u51c6\u6846\u67b6\u65e0\u6cd5\u5f88\u597d\u652f\u6301\u8de8\u5e73\u53f0\u4efb\u52a1\uff0c\u4e14\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u590d\u6742\u4efb\u52a1\u6267\u884c\u7ec6\u8282\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u77e5\u8bc6\u5e93\u589e\u5f3a\u548c\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u7684KGCE\u5e73\u53f0\uff1b\u6784\u5efa\u542b104\u4e2a\u6559\u80b2\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff1b\u5f00\u53d1\u542b\u7279\u5b9a\u77e5\u8bc6\u5e93\u7684\u589e\u5f3a\u4ee3\u7406\u7cfb\u7edf\u3002", "result": "\u6784\u5efa\u4e86\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u53cc\u56fe\u8bc4\u4f30\u6846\u67b6\u548c\u589e\u5f3a\u4ee3\u7406\u7cfb\u7edf\u3002", "conclusion": "KGCE\u80fd\u89e3\u51b3\u73b0\u6709\u6559\u80b2\u57fa\u51c6\u6846\u67b6\u4e0d\u8db3\u95ee\u9898\uff0c\u53ef\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff0c\u514b\u670d\u79c1\u6709\u9886\u57df\u4efb\u52a1\u6267\u884c\u74f6\u9888\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.01207", "pdf": "https://arxiv.org/pdf/2601.01207", "abs": "https://arxiv.org/abs/2601.01207", "authors": ["Yoonhyuk Choi", "Jiho Choi", "Chanran Kim", "Yumin Lee", "Hawon Shin", "Yeowon Jeon", "Minjeong Kim", "Jiwoo Kang"], "title": "Sparse Bayesian Message Passing under Structural Uncertainty", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Semi-supervised learning on real-world graphs is frequently challenged by heterophily, where the observed graph is unreliable or label-disassortative. Many existing graph neural networks either rely on a fixed adjacency structure or attempt to handle structural noise through regularization. In this work, we explicitly capture structural uncertainty by modeling a posterior distribution over signed adjacency matrices, allowing each edge to be positive, negative, or absent. We propose a sparse signed message passing network that is naturally robust to edge noise and heterophily, which can be interpreted from a Bayesian perspective. By combining (i) posterior marginalization over signed graph structures with (ii) sparse signed message aggregation, our approach offers a principled way to handle both edge noise and heterophily. Experimental results demonstrate that our method outperforms strong baseline models on heterophilic benchmarks under both synthetic and real-world structural noise.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7a00\u758f\u6709\u7b26\u53f7\u6d88\u606f\u4f20\u9012\u7f51\u7edc\uff0c\u901a\u8fc7\u5bf9\u6709\u7b26\u53f7\u90bb\u63a5\u77e9\u9635\u7684\u540e\u9a8c\u5206\u5e03\u5efa\u6a21\u6765\u5904\u7406\u56fe\u7ed3\u6784\u4e0d\u786e\u5b9a\u6027\uff0c\u80fd\u5e94\u5bf9\u8fb9\u566a\u58f0\u548c\u5f02\u8d28\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u5f02\u8d28\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u56fe\u7684\u534a\u76d1\u7763\u5b66\u4e60\u5e38\u53d7\u5f02\u8d28\u6027\u6311\u6218\uff0c\u73b0\u6709\u56fe\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u56fa\u5b9a\u90bb\u63a5\u7ed3\u6784\u6216\u6b63\u5219\u5316\u5904\u7406\u7ed3\u6784\u566a\u58f0\u6548\u679c\u6b20\u4f73\u3002", "method": "\u5bf9\u6709\u7b26\u53f7\u90bb\u63a5\u77e9\u9635\u7684\u540e\u9a8c\u5206\u5e03\u5efa\u6a21\uff0c\u63d0\u51fa\u7a00\u758f\u6709\u7b26\u53f7\u6d88\u606f\u4f20\u9012\u7f51\u7edc\uff0c\u7ed3\u5408\u540e\u9a8c\u8fb9\u7f18\u5316\u548c\u7a00\u758f\u6709\u7b26\u53f7\u6d88\u606f\u805a\u5408\u3002", "result": "\u5728\u5408\u6210\u548c\u73b0\u5b9e\u4e16\u754c\u7ed3\u6784\u566a\u58f0\u4e0b\u7684\u5f02\u8d28\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u662f\u5904\u7406\u8fb9\u566a\u58f0\u548c\u5f02\u8d28\u6027\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2601.02248", "pdf": "https://arxiv.org/pdf/2601.02248", "abs": "https://arxiv.org/abs/2601.02248", "authors": ["Mohammad Reza Heidari Iman", "Giorgio Di Natale", "Katell Morin-Allory"], "title": "Automatic Assertion Mining in Assertion-Based Verification: Techniques, Challenges, and Future Directions", "categories": ["cs.SE"], "comment": "6 pages", "summary": "Functional verification increasingly relies on Assertion-Based Verification (ABV), which has become a key approach for verifying hardware designs due to its efficiency and effectiveness. Central to ABV are automatic assertion miners, which apply different techniques to generate assertions automatically. This paper reviews the most recent, advanced, and widely adopted assertion miners, offering a comparative analysis of their methodologies. The goal is to provide researchers and verification practitioners with insights into the capabilities and limitations of existing miners. By identifying their shortcomings, this work also points toward directions for developing more powerful and advanced assertion miners in the future.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u6700\u65b0\u3001\u5148\u8fdb\u4e14\u5e7f\u6cdb\u91c7\u7528\u7684\u81ea\u52a8\u65ad\u8a00\u6316\u6398\u5668\u5e76\u5bf9\u6bd4\u5206\u6790\u5176\u65b9\u6cd5\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u9a8c\u8bc1\u4eba\u5458\u63d0\u4f9b\u89c1\u89e3\uff0c\u6307\u660e\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u529f\u80fd\u9a8c\u8bc1\u6108\u53d1\u4f9d\u8d56\u57fa\u4e8e\u65ad\u8a00\u7684\u9a8c\u8bc1\uff08ABV\uff09\uff0c\u81ea\u52a8\u65ad\u8a00\u6316\u6398\u5668\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u8ba9\u7814\u7a76\u548c\u9a8c\u8bc1\u4eba\u5458\u4e86\u89e3\u73b0\u6709\u6316\u6398\u5668\u7684\u80fd\u529b\u4e0e\u5c40\u9650\uff0c\u5f00\u5c55\u6b64\u7814\u7a76\u3002", "method": "\u5bf9\u6700\u5177\u4ee3\u8868\u6027\u7684\u81ea\u52a8\u65ad\u8a00\u6316\u6398\u5668\u7684\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5256\u6790\u4e86\u73b0\u5b58\u65ad\u8a00\u6316\u6398\u5668\u7684\u80fd\u529b\u4e0e\u4e0d\u8db3\u3002", "conclusion": "\u6307\u51fa\u4e86\u672a\u6765\u5f00\u53d1\u66f4\u5f3a\u5927\u5148\u8fdb\u65ad\u8a00\u6316\u6398\u5668\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2601.01378", "pdf": "https://arxiv.org/pdf/2601.01378", "abs": "https://arxiv.org/abs/2601.01378", "authors": ["Han Yuan", "Yilin Wu", "Li Zhang", "Zheng Ma"], "title": "Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification", "categories": ["cs.AI"], "comment": null, "summary": "Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAAAI\u4e09\u6b65\u6d41\u7a0b\u51cf\u8f7b\u5c0f\u8bed\u8a00\u6a21\u578b\u4e8b\u5b9e\u5e7b\u89c9\u4ee5\u63d0\u5347\u91d1\u878d\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u91d1\u878d\u5206\u7c7b\u65f6\u6613\u51fa\u73b0\u4e8b\u5b9e\u5e7b\u89c9\u4e14\u5206\u7c7b\u6027\u80fd\u5f31\uff0c\u56e0\u6b64\u63a2\u7a76\u51cf\u8f7b\u4e8b\u5b9e\u5e7b\u89c9\u80fd\u5426\u63d0\u5347\u5176\u91d1\u878d\u5206\u7c7b\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u540d\u4e3aAAAI\u7684\u4e09\u6b65\u6d41\u7a0b\uff0c\u5373\u5173\u8054\u8bc6\u522b\u3001\u81ea\u52a8\u68c0\u6d4b\u548c\u81ea\u9002\u5e94\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4e8b\u5b9e\u5e7b\u89c9\u4e0e\u9519\u8bef\u5206\u7c7b\u6b63\u76f8\u5173\uff0c\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u9a8c\u8bc1\u5668\u53ef\u6709\u6548\u68c0\u6d4b\u4e8b\u5b9e\u5e7b\u89c9\uff0c\u7ed3\u5408\u4e8b\u5b9e\u9519\u8bef\u53cd\u9988\u7684\u81ea\u9002\u5e94\u63a8\u7406\u80fd\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u3002", "conclusion": "\u8be5\u6d41\u7a0b\u6709\u52a9\u4e8e\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u7684\u53ef\u9760\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2601.01223", "pdf": "https://arxiv.org/pdf/2601.01223", "abs": "https://arxiv.org/abs/2601.01223", "authors": ["Marzieh Amiri Shahbazi", "Ali Baheri", "Nasibeh Azadeh-Fard"], "title": "Adaptive Conformal Prediction via Bayesian Uncertainty Weighting for Hierarchical Healthcare Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Clinical decision-making demands uncertainty quantification that provides both distribution-free coverage guarantees and risk-adaptive precision, requirements that existing methods fail to jointly satisfy. We present a hybrid Bayesian-conformal framework that addresses this fundamental limitation in healthcare predictions. Our approach integrates Bayesian hierarchical random forests with group-aware conformal calibration, using posterior uncertainties to weight conformity scores while maintaining rigorous coverage validity. Evaluated on 61,538 admissions across 3,793 U.S. hospitals and 4 regions, our method achieves target coverage (94.3% vs 95% target) with adaptive precision: 21% narrower intervals for low-uncertainty cases while appropriately widening for high-risk predictions. Critically, we demonstrate that well-calibrated Bayesian uncertainties alone severely under-cover (14.1%), highlighting the necessity of our hybrid approach. This framework enables risk-stratified clinical protocols, efficient resource planning for high-confidence predictions, and conservative allocation with enhanced oversight for uncertain cases, providing uncertainty-aware decision support across diverse healthcare settings.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u8d1d\u53f6\u65af-\u5171\u5f62\u6846\u67b6\u89e3\u51b3\u533b\u7597\u9884\u6d4b\u4e2d\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u95ee\u9898\uff0c\u8bc4\u4f30\u663e\u793a\u8fbe\u5230\u76ee\u6807\u8986\u76d6\u4e14\u6709\u81ea\u9002\u5e94\u7cbe\u5ea6\uff0c\u5f3a\u8c03\u65b9\u6cd5\u5fc5\u8981\u6027\u3002", "motivation": "\u4e34\u5e8a\u51b3\u7b56\u9700\u540c\u65f6\u6ee1\u8db3\u65e0\u5206\u5e03\u8986\u76d6\u4fdd\u8bc1\u548c\u98ce\u9669\u81ea\u9002\u5e94\u7cbe\u5ea6\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u505a\u5230\u3002", "method": "\u5c06\u8d1d\u53f6\u65af\u5206\u5c42\u968f\u673a\u68ee\u6797\u4e0e\u7fa4\u4f53\u611f\u77e5\u5171\u5f62\u6821\u51c6\u76f8\u7ed3\u5408\uff0c\u7528\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u4e00\u81f4\u6027\u5f97\u5206\u3002", "result": "\u5728\u591a\u533b\u9662\u548c\u5730\u533a\u8bc4\u4f30\u4e2d\u8fbe\u5230\u76ee\u6807\u8986\u76d6\uff0894.3%\uff09\uff0c\u4f4e\u4e0d\u786e\u5b9a\u6027\u75c5\u4f8b\u533a\u95f4\u7a8421%\uff0c\u9ad8\u98ce\u9669\u9884\u6d4b\u533a\u95f4\u9002\u5f53\u53d8\u5bbd\uff0c\u4ec5\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u4e25\u91cd\u8986\u76d6\u4e0d\u8db3\uff0814.1%\uff09\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u5b9e\u73b0\u98ce\u9669\u5206\u5c42\u4e34\u5e8a\u65b9\u6848\u3001\u9ad8\u6548\u8d44\u6e90\u89c4\u5212\u548c\u4fdd\u5b88\u5206\u914d\uff0c\u4e3a\u4e0d\u540c\u533b\u7597\u573a\u666f\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2601.01449", "pdf": "https://arxiv.org/pdf/2601.01449", "abs": "https://arxiv.org/abs/2601.01449", "authors": ["Harshil Darji", "Martin Heckelmann", "Christina Kratsch", "Gerard de Melo"], "title": "Segmentation and Processing of German Court Decisions from Open Legal Data", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": "Accepted and published as a research article in Legal Knowledge and Information Systems (JURIX 2025 proceedings, IOS Press). Pages 276--281", "summary": "The availability of structured legal data is important for advancing Natural Language Processing (NLP) techniques for the German legal system. One of the most widely used datasets, Open Legal Data, provides a large-scale collection of German court decisions. While the metadata in this raw dataset is consistently structured, the decision texts themselves are inconsistently formatted and often lack clearly marked sections. Reliable separation of these sections is important not only for rhetorical role classification but also for downstream tasks such as retrieval and citation analysis. In this work, we introduce a cleaned and sectioned dataset of 251,038 German court decisions derived from the official Open Legal Data dataset. We systematically separated three important sections in German court decisions, namely Tenor (operative part of the decision), Tatbestand (facts of the case), and Entscheidungsgr\u00fcnde (judicial reasoning), which are often inconsistently represented in the original dataset. To ensure the reliability of our extraction process, we used Cochran's formula with a 95% confidence level and a 5% margin of error to draw a statistically representative random sample of 384 cases, and manually verified that all three sections were correctly identified. We also extracted the Rechtsmittelbelehrung (appeal notice) as a separate field, since it is a procedural instruction and not part of the decision itself. The resulting corpus is publicly available in the JSONL format, making it an accessible resource for further research on the German legal system.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4eceOpen Legal Data\u6570\u636e\u96c6\u884d\u751f\u51fa\u7684251,038\u4e2a\u5fb7\u56fd\u6cd5\u9662\u5224\u51b3\u7684\u5df2\u6e05\u7406\u4e14\u5206\u8282\u7684\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u516c\u5f00\u53ef\u7528\u3002", "motivation": "\u73b0\u6709Open Legal Data\u6570\u636e\u96c6\u7684\u5224\u51b3\u6587\u672c\u683c\u5f0f\u4e0d\u4e00\u81f4\u4e14\u90e8\u5206\u6807\u8bb0\u4e0d\u6e05\u6670\uff0c\u53ef\u9760\u5206\u79bb\u5404\u90e8\u5206\u5bf9\u4e8e\u76f8\u5173\u4efb\u52a1\u5f88\u91cd\u8981\uff0c\u6545\u800c\u5f00\u5c55\u6b64\u9879\u5de5\u4f5c\u3002", "method": "\u7cfb\u7edf\u5206\u79bb\u5fb7\u56fd\u6cd5\u9662\u5224\u51b3\u4e2d\u7684\u4e09\u4e2a\u91cd\u8981\u90e8\u5206\uff0c\u7528Cochran\u516c\u5f0f\u62bd\u6837384\u4e2a\u6848\u4f8b\u624b\u52a8\u9a8c\u8bc1\u63d0\u53d6\u51c6\u786e\u6027\uff0c\u5355\u72ec\u63d0\u53d6\u4e0a\u8bc9\u901a\u77e5\u90e8\u5206\u3002", "result": "\u5f97\u5230\u4e86\u53ef\u7528JSONL\u683c\u5f0f\u516c\u5f00\u83b7\u53d6\u7684\u8bed\u6599\u5e93\u3002", "conclusion": "\u8be5\u8bed\u6599\u5e93\u4e3a\u5fb7\u56fd\u6cd5\u5f8b\u7cfb\u7edf\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u83b7\u53d6\u7684\u8d44\u6e90\u3002"}}
{"id": "2601.02345", "pdf": "https://arxiv.org/pdf/2601.02345", "abs": "https://arxiv.org/abs/2601.02345", "authors": ["Parham Khamsepour", "Mark Cole", "Ish Ashraf", "Sandeep Puri", "Mehrdad Sabetzadeh", "Shiva Nejati"], "title": "Question Answering for Multi-Release Systems: A Case Study at Ciena", "categories": ["cs.SE"], "comment": "Accepted for publication in SANER 2026", "summary": "Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u95ee\u7b54\u6311\u6218\uff0c\u63d0\u51fa\u804a\u5929\u673a\u5668\u4ebaQAMR\uff0c\u7ed3\u5408\u591a\u79cd\u7b56\u7565\u63d0\u5347\u51c6\u786e\u6027\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8fd8\u80fd\u51cf\u5c11\u54cd\u5e94\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u95ee\u7b54\u6280\u672f\u5728\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u4e0a\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faQAMR\uff0c\u589e\u5f3a\u4f20\u7edfRAG\uff0c\u7ed3\u5408\u9884\u5904\u7406\u3001\u67e5\u8be2\u91cd\u5199\u548c\u4e0a\u4e0b\u6587\u9009\u62e9\uff0c\u91c7\u7528\u53cc\u5206\u5757\u7b56\u7565\u3002", "result": "QAMR\u5728\u5e73\u5747\u7b54\u6848\u6b63\u786e\u6027\u3001\u68c0\u7d22\u51c6\u786e\u6027\u4e0a\u6709\u63d0\u5347\uff0c\u5904\u7406\u591a\u7248\u672c\u6587\u6863\u673a\u5236\u80fd\u63d0\u9ad8\u7b54\u6848\u51c6\u786e\u6027\uff0c\u76f8\u5bf9\u57fa\u7ebf\u51cf\u5c11\u54cd\u5e94\u65f6\u95f4\uff0c\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u4f30\u76f8\u5173\u3002", "conclusion": "QAMR\u5728\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u95ee\u7b54\u4e0a\u6709\u6548\u63d0\u5347\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u8bc4\u4f30\u65b9\u6cd5\u53ef\u9760\u3002"}}
{"id": "2601.01467", "pdf": "https://arxiv.org/pdf/2601.01467", "abs": "https://arxiv.org/abs/2601.01467", "authors": ["Romuald Kwessy Mouona", "Blaise Bl\u00e9riot Koguep Njionou", "Etienne Romuald Temgoua Alomo", "Rokia Missaoui", "Leonard Kwuida"], "title": "A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts", "categories": ["cs.AI"], "comment": "26 pages", "summary": "This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.", "AI": {"tldr": "\u7814\u7a76\u4e09\u5143\u8bed\u5883\u4e2d\u7684\u8574\u542b\u5173\u7cfb\uff0c\u76ee\u6807\u662f\u4e3a\u5176\u6784\u5efa\u6700\u4f18\u57fa", "motivation": "\u7814\u7a76\u4e09\u5143\u8bed\u5883\u4e2dGanter\u548cObiedkov\u5f15\u5165\u7684\u6761\u4ef6\u5c5e\u6027\u548c\u5f52\u56e0\u6761\u4ef6\u8574\u542b\u5173\u7cfb\u7684\u5f71\u54cd", "method": "\u672a\u63d0\u53ca", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2601.01362", "pdf": "https://arxiv.org/pdf/2601.01362", "abs": "https://arxiv.org/abs/2601.01362", "authors": ["Jerry Huang", "Peng Lu", "Qiuhao Zeng", "Yusuke Iwasawa", "Yutaka Matsuo", "Sarath Chandar", "Edison Marrese-Taylor", "Irene Li"], "title": "Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": "Accepted to The 19th Conference of the European Chapter of the Association for Computational Linguistics (EACL)", "summary": "Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such large language models (LLMs) and their calibration remains an open area of research. In this work, we look at a critical gap in the calibration of LLMs within multilingual settings, in an attempt to better understand how the data scarcity can potentially lead to different calibration effects and how commonly used techniques can apply in these settings. Our analysis on two multilingual benchmarks, over 29 and 42 languages respectively, reveals that even in low-resource languages, model confidence can increase significantly after instruction-tuning on high-resource language SFT datasets. However, improvements in accuracy are marginal or non-existent, resulting in mis-calibration, highlighting a critical shortcoming of standard SFT for multilingual languages. Furthermore, we observe that the use of label smoothing to be a reasonable method alleviate this concern, again without any need for low-resource SFT data, maintaining better calibration across all languages. Overall, this highlights the importance of multilingual considerations for both training and tuning LLMs in order to improve their reliability and fairness in downstream use.", "AI": {"tldr": "\u7814\u7a76\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u6821\u51c6\u95ee\u9898\uff0c\u53d1\u73b0\u6807\u51c6SFT\u6709\u4e0d\u8db3\uff0c\u6807\u7b7e\u5e73\u6ed1\u53ef\u7f13\u89e3\u3002", "motivation": "\u63a2\u7a76\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u6821\u51c6\u95ee\u9898\uff0c\u4e86\u89e3\u6570\u636e\u7a00\u7f3a\u7684\u5f71\u54cd\u53ca\u5e38\u7528\u6280\u672f\u9002\u7528\u6027\u3002", "method": "\u5206\u6790\u4e24\u4e2a\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6a21\u578b\u8868\u73b0\u3002", "result": "\u9ad8\u8d44\u6e90\u8bed\u8a00SFT\u6570\u636e\u96c6\u6307\u4ee4\u8c03\u4f18\u540e\u4f4e\u8d44\u6e90\u8bed\u8a00\u6a21\u578b\u7f6e\u4fe1\u5ea6\u663e\u8457\u589e\u52a0\u4f46\u51c6\u786e\u7387\u63d0\u5347\u5c0f\uff0c\u5bfc\u81f4\u6821\u51c6\u4e0d\u826f\uff0c\u6807\u7b7e\u5e73\u6ed1\u53ef\u7f13\u89e3\u3002", "conclusion": "\u8bad\u7ec3\u548c\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u8003\u8651\u591a\u8bed\u8a00\u56e0\u7d20\u5bf9\u63d0\u9ad8\u4e0b\u6e38\u4f7f\u7528\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u5f88\u91cd\u8981\u3002"}}
{"id": "2601.01511", "pdf": "https://arxiv.org/pdf/2601.01511", "abs": "https://arxiv.org/abs/2601.01511", "authors": ["Ahmed Dawoud", "Osama El-Shamy"], "title": "Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning", "categories": ["cs.AI"], "comment": null, "summary": "Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u795e\u7ecf\u7f51\u7edc\u589e\u5f3a\u7684\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u6587\u672c\u5d4c\u5165\u8fdb\u884c\u56e0\u679c\u8bc6\u522b\uff0c\u8868\u660e\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5bf9\u5904\u7406\u9ad8\u7ef4\u81ea\u7136\u8bed\u8a00\u6570\u636e\u5f88\u5173\u952e\u3002", "motivation": "\u89e3\u51b3\u89c2\u5bdf\u6027\u73af\u5883\u4e2d\u56e0\u672a\u89c2\u5bdf\u5230\u7684\u6df7\u6742\u56e0\u7d20\u5bfc\u81f4\u7684\u9009\u62e9\u504f\u5dee\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u4e0e\u7ed3\u6784\u5316\u534f\u53d8\u91cf\u6b63\u4ea4\u7684\u6df7\u6742\u56e0\u7d20\u65f6\u5b58\u5728\u56f0\u96be\u3002", "method": "\u63d0\u51faNeural Network - Enhanced Double Machine Learning (DML)\u6846\u67b6\uff0c\u5229\u7528\u6587\u672c\u5d4c\u5165\u8fdb\u884c\u56e0\u679c\u8bc6\u522b\uff0c\u5e76\u4f7f\u7528\u4e25\u683c\u7684\u5408\u6210\u57fa\u51c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u975e\u7ed3\u6784\u5316\u6587\u672c\u5d4c\u5165\u80fd\u6355\u6349\u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u4e2d\u7f3a\u5931\u7684\u5173\u952e\u6df7\u6742\u4fe1\u606f\uff1b\u6807\u51c6\u57fa\u4e8e\u6811\u7684DML\u4f30\u8ba1\u5668\u670924%\u7684\u504f\u5dee\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316\u67b6\u6784\u540e\u504f\u5dee\u964d\u81f3 - 0.86%\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5728\u57fa\u4e8e\u9ad8\u7ef4\u81ea\u7136\u8bed\u8a00\u6570\u636e\u8fdb\u884c\u6761\u4ef6\u8bbe\u5b9a\u65f6\uff0c\u5bf9\u6ee1\u8db3\u65e0\u6df7\u6742\u5047\u8bbe\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.01371", "pdf": "https://arxiv.org/pdf/2601.01371", "abs": "https://arxiv.org/abs/2601.01371", "authors": ["Yinan Shen", "Yichen Zhang", "Wen-Xin Zhou"], "title": "SGD with Dependent Data: Optimal Estimation, Regret, and Inference", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "This work investigates the performance of the final iterate produced by stochastic gradient descent (SGD) under temporally dependent data. We consider two complementary sources of dependence: $(i)$ martingale-type dependence in both the covariate and noise processes, which accommodates non-stationary and non-mixing time series data, and $(ii)$ dependence induced by sequential decision making. Our formulation runs in parallel with classical notions of (local) stationarity and strong mixing, while neither framework fully subsumes the other. Remarkably, SGD is shown to automatically accommodate both independent and dependent information under a broad class of stepsize schedules and exploration rate schemes.\n  Non-asymptotically, we show that SGD simultaneously achieves statistically optimal estimation error and regret, extending and improving existing results. In particular, our tail bounds remain sharp even for potentially infinite horizon $T=+\\infty$. Asymptotically, the SGD iterates converge to a Gaussian distribution with only an $O_{\\PP}(1/\\sqrt{t})$ remainder, demonstrating that the supposed estimation-regret trade-off claimed in prior work can in fact be avoided. We further propose a new ``conic'' approximation of the decision region that allows the covariates to have unbounded support. For online sparse regression, we develop a new SGD-based algorithm that uses only $d$ units of storage and requires $O(d)$ flops per iteration, achieving the long term statistical optimality. Intuitively, each incoming observation contributes to estimation accuracy, while aggregated summary statistics guide support recovery.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u5728\u65f6\u95f4\u4f9d\u8d56\u6570\u636e\u4e0b\u6700\u7ec8\u8fed\u4ee3\u7ed3\u679c\u7684\u6027\u80fd\uff0c\u8bc1\u660eSGD\u53ef\u9002\u5e94\u591a\u79cd\u4fe1\u606f\uff0c\u5c55\u793a\u5176\u5728\u975e\u6e10\u8fd1\u548c\u6e10\u8fd1\u60c5\u5f62\u4e0b\u7684\u826f\u597d\u8868\u73b0\uff0c\u8fd8\u63d0\u51fa\u65b0\u7b97\u6cd5\u3002", "motivation": "\u63a2\u7a76\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u5728\u65f6\u95f4\u4f9d\u8d56\u6570\u636e\u4e0b\u7684\u6027\u80fd\uff0c\u7a81\u7834\u7ecf\u5178\u6846\u67b6\u9650\u5236\uff0c\u89e3\u51b3\u5148\u524d\u5de5\u4f5c\u4e2d\u63d0\u51fa\u7684\u4f30\u8ba1 - \u9057\u61be\u6743\u8861\u95ee\u9898\u3002", "method": "\u8003\u8651\u4e24\u79cd\u4e92\u8865\u7684\u4f9d\u8d56\u6e90\uff0c\u5728\u591a\u79cd\u6b65\u957f\u548c\u63a2\u7d22\u7387\u65b9\u6848\u4e0b\u5206\u6790SGD\u6027\u80fd\uff0c\u63d0\u51fa\u51b3\u7b56\u533a\u57df\u7684\u201c\u9525\u201d\u8fd1\u4f3c\u548c\u57fa\u4e8eSGD\u7684\u65b0\u7b97\u6cd5\u3002", "result": "\u975e\u6e10\u8fd1\u60c5\u51b5\u4e0b\uff0cSGD\u540c\u65f6\u5b9e\u73b0\u7edf\u8ba1\u6700\u4f18\u4f30\u8ba1\u8bef\u5dee\u548c\u9057\u61be\uff0c\u5c3e\u90e8\u754c\u9650\u5373\u4f7f\u5728\u65e0\u9650\u65f6\u95f4\u8303\u56f4\u4e5f\u5f88\u5c16\u9510\uff1b\u6e10\u8fd1\u60c5\u51b5\u4e0b\uff0cSGD\u8fed\u4ee3\u6536\u655b\u5230\u9ad8\u65af\u5206\u5e03\uff0c\u907f\u514d\u4f30\u8ba1 - \u9057\u61be\u6743\u8861\uff1b\u65b0\u7b97\u6cd5\u4f7f\u7528\u5c11\u91cf\u5b58\u50a8\u548c\u8ba1\u7b97\u91cf\uff0c\u5b9e\u73b0\u957f\u671f\u7edf\u8ba1\u6700\u4f18\u3002", "conclusion": "SGD\u80fd\u9002\u5e94\u4f9d\u8d56\u4fe1\u606f\uff0c\u5728\u4f9d\u8d56\u6570\u636e\u4e0b\u6709\u826f\u597d\u6027\u80fd\uff0c\u6240\u63d0\u65b0\u7b97\u6cd5\u5728\u7ebf\u6027\u7a00\u758f\u56de\u5f52\u4e2d\u5b9e\u7528\u6709\u6548\u3002"}}
{"id": "2601.01831", "pdf": "https://arxiv.org/pdf/2601.01831", "abs": "https://arxiv.org/abs/2601.01831", "authors": ["Aniket Wattamwar", "Sampson Akwafuo"], "title": "ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring", "categories": ["cs.MA", "cs.AI", "cs.IR", "cs.SE"], "comment": "6 pages, 14 figures, 1 table", "summary": "Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u6d41\u884c\u75c5\u5b66\u76d1\u6d4b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6 ARIES\uff0c\u80fd\u8d85\u8d8a\u9759\u6001\u4eea\u8868\u76d8\uff0c\u5b9e\u73b0\u8fd1\u5b9e\u65f6\u5a01\u80c1\u8bc6\u522b\uff0c\u6a21\u5757\u5316\u67b6\u6784\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u5168\u7403\u5065\u5eb7\u76d1\u6d4b\u5b58\u5728\u77e5\u8bc6\u5dee\u8ddd\uff0c\u901a\u7528 AI \u4e0d\u9002\u5408\u6d41\u884c\u75c5\u5b66\u9886\u57df\uff0c\u9700\u8981\u4e13\u4e1a\u5de5\u5177\u3002", "method": "\u6784\u5efa\u5206\u5c42\u6307\u6325\u7ed3\u6784\u7684 ARIES \u6846\u67b6\uff0c\u5229\u7528 GPT \u534f\u8c03\u5b50\u667a\u80fd\u4f53\uff0c\u81ea\u4e3b\u67e5\u8be2\u6570\u636e\u5e76\u81ea\u52a8\u63d0\u53d6\u4e0e\u903b\u8f91\u5408\u6210\u3002", "result": "ARIES \u80fd\u5b9e\u73b0\u8fd1\u5b9e\u65f6\u8bc6\u522b\u65b0\u51fa\u73b0\u7684\u5a01\u80c1\u548c\u4fe1\u53f7\u5dee\u5f02\u3002", "conclusion": "\u7279\u5b9a\u4efb\u52a1\u7684\u667a\u80fd\u4f53\u7fa4\u53ef\u8d85\u8d8a\u901a\u7528\u6a21\u578b\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u75ab\u60c5\u5e94\u5bf9\u548c\u5168\u7403\u5065\u5eb7\u60c5\u62a5\u63d0\u4f9b\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6848\u3002"}}
{"id": "2601.01522", "pdf": "https://arxiv.org/pdf/2601.01522", "abs": "https://arxiv.org/abs/2601.01522", "authors": ["Danial Amin"], "title": "Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making", "categories": ["cs.AI", "cs.CL", "cs.ET"], "comment": null, "summary": "Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds \"confidence,\" and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528\u4e8e\u987a\u5e8f\u51b3\u7b56\u7684\u8d1d\u53f6\u65af\u3001\u5177\u6709\u6210\u672c\u610f\u8bc6\u7684\u591a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f16\u6392\u6846\u67b6\uff0c\u5728\u7b80\u5386\u7b5b\u9009\u5b9e\u9a8c\u4e2d\u964d\u4f4e\u6210\u672c\u3001\u63d0\u9ad8\u4eba\u53e3\u7edf\u8ba1\u5b66\u516c\u5e73\u6027\u3002", "motivation": "\u5728\u5b58\u5728\u4e0d\u5bf9\u79f0\u9519\u8bef\u6210\u672c\u7684\u987a\u5e8f\u51b3\u7b56\u573a\u666f\u4e0b\uff0c\u73b0\u6709\u5355\u4e00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u65b9\u6cd5\u4e0d\u9002\u7528\uff0c\u9700\u65b0\u7684\u51b3\u7b56\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u5c06\u5927\u6a21\u578b\u4f5c\u4e3a\u8fd1\u4f3c\u4f3c\u7136\u6a21\u578b\u7684\u8d1d\u53f6\u65af\u3001\u5177\u6709\u6210\u672c\u610f\u8bc6\u7684\u591a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u63d0\u793a\u83b7\u53d6\u4f3c\u7136\uff0c\u7528\u7a33\u5065\u7edf\u8ba1\u805a\u5408\uff0c\u7528\u8d1d\u53f6\u65af\u89c4\u5219\u66f4\u65b0\u4fe1\u5ff5\u3002", "result": "\u5728\u7b80\u5386\u7b5b\u9009\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u6700\u4f73\u5355\u6a21\u578b\u57fa\u7ebf\uff0c\u603b\u8d39\u7528\u964d\u4f4e294000\u7f8e\u5143\uff0834%\uff09\uff0c\u4eba\u53e3\u7edf\u8ba1\u5b66\u516c\u5e73\u6027\u63d0\u534745%\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u591a\u6a21\u578b\u805a\u5408\u3001\u987a\u5e8f\u66f4\u65b0\u548c\u4fe1\u606f\u6536\u96c6\u5206\u522b\u8d21\u732e\u4e8651%\u300143%\u548c20%\u7684\u8282\u7701\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u5177\u6709\u6b63\u786e\u7684\u6982\u7387\u57fa\u7840\uff0c\u80fd\u6709\u6548\u964d\u4f4e\u6210\u672c\u3001\u63d0\u5347\u516c\u5e73\u6027\uff0c\u7406\u8bba\u4f18\u52bf\u5f97\u5230\u5b9e\u9a8c\u9a8c\u8bc1\u3002"}}
{"id": "2601.01432", "pdf": "https://arxiv.org/pdf/2601.01432", "abs": "https://arxiv.org/abs/2601.01432", "authors": ["Sai Li", "Linjun Zhang"], "title": "Personalizing black-box models for nonparametric regression with minimax optimality", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Recent advances in large-scale models, including deep neural networks and large language models, have substantially improved performance across a wide range of learning tasks. The widespread availability of such pre-trained models creates new opportunities for data-efficient statistical learning, provided they can be effectively integrated into downstream tasks. Motivated by this setting, we study few-shot personalization, where a pre-trained black-box model is adapted to a target domain using a limited number of samples. We develop a theoretical framework for few-shot personalization in nonparametric regression and propose algorithms that can incorporate a black-box pre-trained model into the regression procedure. We establish the minimax optimal rate for the personalization problem and show that the proposed method attains this rate. Our results clarify the statistical benefits of leveraging pre-trained models under sample scarcity and provide robustness guarantees when the pre-trained model is not informative. We illustrate the finite-sample performance of the methods through simulations and an application to the California housing dataset with several pre-trained models.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u5c11\u6837\u672c\u4e2a\u6027\u5316\uff0c\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u548c\u7b97\u6cd5\uff0c\u8bc1\u660e\u8fbe\u5230\u6700\u4f18\u7387\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5e7f\u6cdb\u53ef\u7528\uff0c\u7814\u7a76\u5176\u9ad8\u6548\u878d\u5165\u4e0b\u6e38\u4efb\u52a1\uff0c\u805a\u7126\u5c11\u6837\u672c\u4e2a\u6027\u5316\u3002", "method": "\u5f00\u53d1\u975e\u53c2\u6570\u56de\u5f52\u4e2d\u5c11\u6837\u672c\u4e2a\u6027\u5316\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u51fa\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u878d\u5165\u56de\u5f52\u7b97\u6cd5\u3002", "result": "\u5efa\u7acb\u4e2a\u6027\u5316\u95ee\u9898\u7684\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7387\uff0c\u8bc1\u660e\u65b9\u6cd5\u53ef\u8fbe\u8be5\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u5728\u6709\u9650\u6837\u672c\u6709\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u660e\u786e\u6837\u672c\u7a00\u7f3a\u65f6\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u7edf\u8ba1\u4f18\u52bf\uff0c\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u4fe1\u606f\u4e0d\u8db3\u65f6\u6709\u9c81\u68d2\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2601.01862", "pdf": "https://arxiv.org/pdf/2601.01862", "abs": "https://arxiv.org/abs/2601.01862", "authors": ["Nuo Chen", "Hanpei Fang", "Piaohong Wang", "Jiqun Liu", "Tetsuya Sakai", "Xiao-Ming Wu"], "title": "Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.\n  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u591aLLM\u6a21\u62df\u5927\u4e94\u4eba\u683c\u7279\u5f81\u5bf9\u7f51\u9875\u641c\u7d22\u51b3\u7b56\u548c\u7f6e\u4fe1\u6821\u51c6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7279\u5b9a\u4eba\u683c\u8868\u73b0\u66f4\u597d\uff0c\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u53d6\u5f97\u826f\u597d\u6548\u679c\uff0c\u8868\u660e\u4eba\u683c\u884d\u751f\u7f6e\u4fe1\u6709\u8865\u5145\u9884\u6d4b\u4fe1\u53f7\u3002", "motivation": "\u63a2\u8ba8\u6a21\u62df\u4eba\u683c\u5982\u4f55\u5f71\u54cd\u5173\u952e\u7f51\u9875\u641c\u7d22\u51b3\u7b56\uff08\u76f8\u5173\u6027\u8bc4\u4f30\uff09\u548c\u7f6e\u4fe1\u6821\u51c6\uff0c\u586b\u8865\u76f8\u5173\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u8bc4\u4f30\u591a\u4e2a\u6a21\u62df\u5927\u4e94\u4eba\u683c\u7279\u5f81\u7684LLM\uff0c\u5728\u4e09\u4e2a\u6d4b\u8bd5\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u6536\u96c6\u76f8\u5173\u6027\u5224\u65ad\u548c\u81ea\u4fe1\u5206\u6570\uff0c\u5c06\u4eba\u683c\u6761\u4ef6\u5206\u6570\u548c\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u7279\u5f81\u7528\u4e8e\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u3002", "result": "\u4f4e\u5b9c\u4eba\u6027\u4e0e\u4eba\u7c7b\u6807\u7b7e\u66f4\u4e00\u81f4\uff0c\u4f4e\u8d23\u4efb\u5fc3\u80fd\u5e73\u8861\u6291\u5236\u8fc7\u5ea6\u81ea\u4fe1\u548c\u4fe1\u5fc3\u4e0d\u8db3\uff0c\u76f8\u5173\u6027\u5206\u6570\u548c\u7f6e\u4fe1\u5206\u5e03\u968f\u4eba\u683c\u4e0d\u540c\u800c\u7cfb\u7edf\u53d8\u5316\uff0c\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u8d85\u6700\u4f73\u5355\u4eba\u72b6\u6001\u3002", "conclusion": "\u4eba\u683c\u884d\u751f\u7f6e\u4fe1\u63d0\u4f9b\u8865\u5145\u9884\u6d4b\u4fe1\u53f7\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u9760\u3001\u7b26\u5408\u4eba\u7c7b\u7684LLM\u8bc4\u4f30\u5668\u3002"}}
{"id": "2601.01026", "pdf": "https://arxiv.org/pdf/2601.01026", "abs": "https://arxiv.org/abs/2601.01026", "authors": ["Douglas Costa Braga", "Daniel Oliveira Dantas"], "title": "Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SE"], "comment": "9 pages, 5 figures, 4 tables. Submitted to VISAPP 2025", "summary": "We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u767d\u8840\u75c5\u7ec6\u80de\u5206\u7c7b\u7684\u6df1\u5ea6\u5b66\u4e60\u6d41\u6c34\u7ebf\uff0c\u5728C - NMC 2019\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6025\u6027\u6dcb\u5df4\u7ec6\u80de\u767d\u8840\u75c5\uff08ALL\uff09\u8bca\u65ad\u4f9d\u8d56\u4e13\u5bb6\u663e\u5fae\u955c\u68c0\u67e5\uff0c\u5b58\u5728\u89c2\u5bdf\u8005\u95f4\u5dee\u5f02\u548c\u65f6\u95f4\u9650\u5236\u95ee\u9898\u3002", "method": "\u96c6\u6210\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u7ed3\u5408EfficientNetV2 - B3\u4e0e\u6324\u538b - \u6fc0\u52b1\u673a\u5236\uff1b\u91c7\u7528\u6570\u636e\u589e\u5f3a\u3001\u7126\u70b9\u635f\u5931\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u60a3\u8005\u7ea7\u6570\u636e\u5206\u5272\u3002", "result": "\u5728C - NMC 2019\u6570\u636e\u96c6\u6d4b\u8bd5\u96c6\u4e0aF1\u5206\u6570\u548c\u51c6\u786e\u7387\u8fbe97.89%\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff0c\u6bd4VGG16\u53c2\u6570\u5c1189%\u3002", "conclusion": "\u73b0\u4ee3\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u67b6\u6784\u53ef\u63d0\u9ad8\u767d\u8840\u75c5\u7ec6\u80de\u5206\u7c7b\u6548\u679c\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u9002\u5408\u4e34\u5e8a\u5e94\u7528\u3002"}}
{"id": "2601.01532", "pdf": "https://arxiv.org/pdf/2601.01532", "abs": "https://arxiv.org/abs/2601.01532", "authors": ["Fanzhe Fu"], "title": "Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "6 pages, 2 figures", "summary": "In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify \"Cognitive Conviction\" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a \"cognitive buffer,\" they may exhibit \"Defensive OverThinking\" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.", "AI": {"tldr": "\u5f53\u524dAGI\u8bc4\u4f30\u8303\u5f0f\u6709\u5371\u673a\uff0c\u672c\u6587\u6269\u5c55\u6846\u67b6\u91cf\u5316\u7cfb\u7edf2\u63a8\u7406\u6a21\u578b\u7684\u2018\u8ba4\u77e5\u786e\u4fe1\u5ea6\u2019\uff0c\u63d0\u51fa\u9879\u76ee\uff0c\u901a\u8fc7\u521d\u6b65\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u7279\u70b9\u5e76\u5f15\u5165\u5206\u6570\uff0c\u4e3a\u8861\u91cfAI\u79d1\u5b66\u8bda\u4fe1\u63d0\u4f9b\u84dd\u56fe\u3002", "motivation": "\u5f53\u524dAGI\u8bc4\u4f30\u8303\u5f0f\u9762\u4e34\u8ba4\u8bc6\u8bba\u5371\u673a\uff0c\u9759\u6001\u57fa\u51c6\u65e0\u6cd5\u91cf\u5316\u4fe1\u5ff5\u6df1\u5ea6\uff0c\u8981\u6269\u5c55\u6846\u67b6\u91cf\u5316\u7cfb\u7edf2\u63a8\u7406\u6a21\u578b\u7684\u2018\u8ba4\u77e5\u786e\u4fe1\u5ea6\u2019\u3002", "method": "\u63d0\u51faProject Aletheia\uff0c\u91c7\u7528Tikhonov\u6b63\u5219\u5316\u53cd\u8f6c\u6cd5\u5b98\u7684\u6df7\u6dc6\u77e9\u9635\uff0c\u5b9e\u65bd\u5408\u6210\u4ee3\u7406\u534f\u8bae\u3002", "result": "\u521d\u6b65\u7814\u7a76\u8868\u660e\u63a8\u7406\u6a21\u578b\u53ef\u4f5c\u4e3a\u2018\u8ba4\u77e5\u7f13\u51b2\u2019\uff0c\u5728\u5bf9\u6297\u538b\u529b\u4e0b\u53ef\u80fd\u51fa\u73b0\u2018\u9632\u5fa1\u6027\u8fc7\u5ea6\u601d\u8003\u2019\uff1b\u5f15\u5165\u5bf9\u9f50\u786e\u4fe1\u5ea6\u5206\u6570\u9a8c\u8bc1\u786e\u4fe1\u5ea6\u4e0d\u635f\u5bb3\u5b89\u5168\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8861\u91cfAI\u79d1\u5b66\u8bda\u4fe1\u63d0\u4f9b\u4e86\u84dd\u56fe\u3002"}}
{"id": "2601.01471", "pdf": "https://arxiv.org/pdf/2601.01471", "abs": "https://arxiv.org/abs/2601.01471", "authors": ["Shuyuan Chen", "Peng Zhang", "Yifan Cui"], "title": "Double Machine Learning of Continuous Treatment Effects with General Instrumental Variables", "categories": ["math.ST", "econ.EM", "stat.ME", "stat.ML"], "comment": null, "summary": "Estimating causal effects of continuous treatments is a common problem in practice, for example, in studying dose-response functions. Classical analyses typically assume that all confounders are fully observed, whereas in real-world applications, unmeasured confounding often persists. In this article, we propose a novel framework for local identification of dose-response functions using instrumental variables, thereby mitigating bias induced by unobserved confounders. We introduce the concept of a uniform regular weighting function and consider covering the treatment space with a finite collection of open sets. On each of these sets, such a weighting function exists, allowing us to identify the dose-response function locally within the corresponding region. For estimation, we develop an augmented inverse probability weighting score for continuous treatments under a debiased machine learning framework with instrumental variables. We further establish the asymptotic properties when the dose-response function is estimated via kernel regression or empirical risk minimization. Finally, we conduct both simulation and empirical studies to assess the finite-sample performance of the proposed methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5de5\u5177\u53d8\u91cf\u5c40\u90e8\u8bc6\u522b\u5242\u91cf\u53cd\u5e94\u51fd\u6570\u7684\u6846\u67b6\uff0c\u5f00\u53d1\u4f30\u8ba1\u65b9\u6cd5\u5e76\u8bc4\u4f30\u5176\u6709\u9650\u6837\u672c\u6027\u80fd\u3002", "motivation": "\u7ecf\u5178\u5206\u6790\u4f30\u8ba1\u8fde\u7eed\u5904\u7406\u56e0\u679c\u6548\u5e94\u65f6\u5047\u8bbe\u6240\u6709\u6df7\u6742\u56e0\u7d20\u90fd\u88ab\u5b8c\u5168\u89c2\u6d4b\u5230\uff0c\u4f46\u73b0\u5b9e\u4e2d\u5b58\u5728\u672a\u6d4b\u91cf\u7684\u6df7\u6742\u56e0\u7d20\uff0c\u9700\u8981\u65b9\u6cd5\u51cf\u8f7b\u5176\u5e26\u6765\u7684\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u7528\u5de5\u5177\u53d8\u91cf\u5c40\u90e8\u8bc6\u522b\u5242\u91cf\u53cd\u5e94\u51fd\u6570\u7684\u6846\u67b6\uff0c\u5f15\u5165\u5747\u5300\u6b63\u5219\u52a0\u6743\u51fd\u6570\uff0c\u5f00\u53d1\u5e26\u5de5\u5177\u53d8\u91cf\u7684\u53bb\u504f\u673a\u5668\u5b66\u4e60\u6846\u67b6\u4e0b\u8fde\u7eed\u5904\u7406\u7684\u589e\u5f3a\u9006\u6982\u7387\u52a0\u6743\u5f97\u5206\uff0c\u901a\u8fc7\u6838\u56de\u5f52\u6216\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\u4f30\u8ba1\u5242\u91cf\u53cd\u5e94\u51fd\u6570\u3002", "result": "\u5efa\u7acb\u4e86\u5242\u91cf\u53cd\u5e94\u51fd\u6570\u4f30\u8ba1\u7684\u6e10\u8fd1\u6027\u8d28\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u9650\u6837\u672c\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u8f7b\u672a\u89c2\u6d4b\u6df7\u6742\u56e0\u7d20\u5e26\u6765\u7684\u504f\u5dee\uff0c\u53ef\u7528\u4e8e\u4f30\u8ba1\u8fde\u7eed\u5904\u7406\u7684\u56e0\u679c\u6548\u5e94\u3002"}}
{"id": "2601.01206", "pdf": "https://arxiv.org/pdf/2601.01206", "abs": "https://arxiv.org/abs/2601.01206", "authors": ["Soroush Elyasi", "Arya VarastehNezhad", "Fattaneh Taghiyareh"], "title": "MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.SE"], "comment": null, "summary": "Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u591a\u7c7b\u578b\u4e25\u8083\u6e38\u620f\u6846\u67b6\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6280\u672f\u9884\u6d4b\u8f6f\u4ef6\u5f00\u53d1\u5c97\u4f4d\u9002\u914d\u6027\uff0c\u6a21\u578b\u7cbe\u5ea6\u9ad8\uff0c\u8868\u660e\u6e38\u620f\u4e2d\u9690\u5f0f\u884c\u4e3a\u75d5\u8ff9\u5728\u9884\u6d4b\u4e2d\u5f88\u6709\u524d\u666f\u3002", "motivation": "\u4f20\u7edf\u804c\u4e1a\u6307\u5bfc\u548c\u4eba\u5458\u9009\u62d4\u4e2d\u7684\u4eba\u683c\u8bc4\u4f30\u4f9d\u8d56\u81ea\u6211\u62a5\u544a\u95ee\u5377\uff0c\u5b58\u5728\u6613\u53d7\u53cd\u5e94\u504f\u5dee\u3001\u75b2\u52b3\u548c\u6545\u610f\u6b6a\u66f2\u7b49\u95ee\u9898\uff0c\u6545\u63a2\u7d22\u57fa\u4e8e\u6e38\u620f\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u56de\u987e\u548c\u5bf9\u4e13\u4e1a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u5b9e\u8bc1\u7814\u7a76\u786e\u5b9a\u4e0e\u5f00\u53d1\u8005\u76f8\u5173\u7684\u4eba\u683c\u548c\u884c\u4e3a\u7279\u5f81\uff0c\u8bbe\u8ba1\u5b9a\u5236\u624b\u673a\u6e38\u620f\u6536\u96c6\u7ec6\u7c92\u5ea6\u6e38\u620f\u4e8b\u4ef6\u6570\u636e\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u5efa\u6a21\u7b56\u7565\u4ec5\u4ece\u6e38\u620f\u884c\u4e3a\u7279\u5f81\u9884\u6d4b\u9002\u914d\u6027\u3002", "result": "\u6a21\u578b\u7cbe\u5ea6\u8fbe97%\uff0c\u51c6\u786e\u7387\u8fbe94%\uff0c\u5408\u9002\u5019\u9009\u4eba\u6709\u72ec\u7279\u6e38\u620f\u6a21\u5f0f\u3002", "conclusion": "\u6e38\u620f\u4e2d\u6355\u83b7\u7684\u9690\u5f0f\u884c\u4e3a\u75d5\u8ff9\u5728\u4e0d\u8fdb\u884c\u660e\u786e\u4eba\u683c\u6d4b\u8bd5\u7684\u60c5\u51b5\u4e0b\u53ef\u6709\u6548\u9884\u6d4b\u8f6f\u4ef6\u5f00\u53d1\u9002\u914d\u6027\uff0c\u4e25\u8083\u6e38\u620f\u662f\u804c\u4e1a\u8bc4\u4f30\u7684\u53ef\u6269\u5c55\u3001\u6709\u5438\u5f15\u529b\u4e14\u504f\u5dee\u8f83\u5c0f\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2601.01546", "pdf": "https://arxiv.org/pdf/2601.01546", "abs": "https://arxiv.org/abs/2601.01546", "authors": ["Letian Kong", "Qianran", "Jin", "Renyu Zhang"], "title": "Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation", "categories": ["cs.AI"], "comment": "39 pages, 2 figures, 3 tables", "summary": "Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u51b3\u7b56\u73af\u5883\u4e2d\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u591a\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u660e\u786e\u5404\u9636\u6bb5\u9002\u7528\u573a\u666f\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u51b3\u7b56\u73af\u5883\u4e2d\u7cfb\u7edf\u5730\u504f\u79bb\u4eba\u7c7b\u51b3\u7b56\uff0c\u9700\u8981\u6539\u5584\u884c\u4e3a\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u4e3a\u4e0a\u4e0b\u6587\u5f62\u6210\uff0c\u660e\u786e\u5b9e\u9a8c\u8bbe\u8ba1\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4e3a\u4e0a\u4e0b\u6587\u5bfc\u822a\uff0c\u5f15\u5bfc\u63a8\u7406\u51b3\u7b56\u3002\u901a\u8fc7\u591a\u4e2a\u6e38\u620f\u548c\u4efb\u52a1\u9a8c\u8bc1\u6846\u67b6\u3002", "result": "\u5728\u56db\u4e2aSOTA\u6a21\u578b\u4e0a\u6d4b\u8bd5\u53d1\u73b0\uff0c\u590d\u6742\u51b3\u7b56\u73af\u5883\u9700\u4e24\u9636\u6bb5\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u57fa\u51c6\u7684\u884c\u4e3a\u5bf9\u9f50\uff0c\u7b80\u5355\u9700\u6c42\u4f30\u8ba1\u4efb\u52a1\u4ec5\u9700\u4e0a\u4e0b\u6587\u5f62\u6210\u3002", "conclusion": "\u660e\u786e\u4e86\u4e24\u9636\u6bb5\u5404\u81ea\u5fc5\u8981\u7684\u573a\u666f\uff0c\u4e3a\u8bbe\u8ba1\u548c\u8bca\u65ad\u5927\u8bed\u8a00\u6a21\u578b\u793e\u4f1a\u6a21\u62df\u63d0\u4f9b\u7cfb\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2601.01497", "pdf": "https://arxiv.org/pdf/2601.01497", "abs": "https://arxiv.org/abs/2601.01497", "authors": ["Zlata Tabachov\u00e1", "Petr Jizba", "Hynek Lavi\u010dka", "Milan Palu\u0161"], "title": "On the Practical Estimation and Interpretation of R\u00e9nyi Transfer Entropy", "categories": ["nlin.PS", "stat.ML"], "comment": null, "summary": "R\u00e9nyi transfer entropy (RTE) is a generalization of classical transfer entropy that replaces Shannon's entropy with R\u00e9nyi's information measure. This, in turn, introduces a new tunable parameter $\u03b1$, which accounts for sensitivity to low- or high-probability events. Although RTE shows strong potential for analyzing causal relations in complex, non-Gaussian systems, its practical use is limited, primarily due to challenges related to its accurate estimation and interpretation. These difficulties are especially pronounced when working with finite, high-dimensional, or heterogeneous datasets. In this paper, we systematically study the performance of a k-nearest neighbor estimator for both R\u00e9nyi entropy (RE) and RTE using various synthetic data sets with clear cause-and-effect relationships inherent to their construction. We test the estimator across a broad range of parameters, including sample size, dimensionality, memory length, and R\u00e9nyi order $\u03b1$. In particular, we apply the estimator to a set of simulated processes with increasing structural complexity, ranging from linear dynamics to nonlinear systems with multi-source couplings. To address interpretational challenges arising from potentially negative RE and RTE values, we introduce three reliability conditions and formulate practical guidelines for tuning the estimator parameters. We show that when the reliability conditions are met and the parameters are calibrated accordingly, the resulting effective RTE estimates accurately capture directional information flow across a broad range of scenarios. Results obtained show that the explanatory power of RTE depends sensitively on the choice of the R\u00e9nyi parameter $\u03b1$. This highlights the usefulness of the RTE framework for identifying the drivers of extreme behavior in complex systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86k\u8fd1\u90bb\u4f30\u8ba1\u5668\u5728R\u00e9nyi\u71b5\u548cR\u00e9nyi\u8f6c\u79fb\u71b5\u4e0a\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u96c6\u6d4b\u8bd5\uff0c\u5f15\u5165\u53ef\u9760\u6027\u6761\u4ef6\u548c\u8c03\u53c2\u6307\u5357\uff0c\u8bc1\u660e\u6709\u6548RTE\u4f30\u8ba1\u80fd\u6355\u6349\u4fe1\u606f\u6d41\u5411\uff0c\u4e14RTE\u89e3\u91ca\u529b\u4f9d\u8d56\u4e8e\u53c2\u6570\u03b1\u3002", "motivation": "R\u00e9nyi\u8f6c\u79fb\u71b5\u5728\u5206\u6790\u590d\u6742\u975e\u9ad8\u65af\u7cfb\u7edf\u56e0\u679c\u5173\u7cfb\u6709\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u4e8e\u51c6\u786e\u4f30\u8ba1\u548c\u89e3\u91ca\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u6709\u9650\u3001\u9ad8\u7ef4\u6216\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u3002", "method": "\u4f7f\u7528\u591a\u79cd\u5177\u6709\u660e\u786e\u56e0\u679c\u5173\u7cfb\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5bf9k\u8fd1\u90bb\u4f30\u8ba1\u5668\u5728\u5e7f\u6cdb\u53c2\u6570\u8303\u56f4\u5185\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e94\u7528\u4e8e\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u6a21\u62df\u8fc7\u7a0b\uff0c\u5f15\u5165\u4e09\u4e2a\u53ef\u9760\u6027\u6761\u4ef6\u5e76\u5236\u5b9a\u8c03\u53c2\u6307\u5357\u3002", "result": "\u5f53\u6ee1\u8db3\u53ef\u9760\u6027\u6761\u4ef6\u5e76\u6821\u51c6\u53c2\u6570\u65f6\uff0c\u6709\u6548RTE\u4f30\u8ba1\u80fd\u51c6\u786e\u6355\u6349\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u65b9\u5411\u6027\u4fe1\u606f\u6d41\uff0cRTE\u7684\u89e3\u91ca\u529b\u654f\u611f\u4f9d\u8d56\u4e8eR\u00e9nyi\u53c2\u6570\u03b1\u3002", "conclusion": "RTE\u6846\u67b6\u5bf9\u4e8e\u8bc6\u522b\u590d\u6742\u7cfb\u7edf\u4e2d\u6781\u7aef\u884c\u4e3a\u7684\u9a71\u52a8\u56e0\u7d20\u5f88\u6709\u7528\u3002"}}
{"id": "2601.01241", "pdf": "https://arxiv.org/pdf/2601.01241", "abs": "https://arxiv.org/abs/2601.01241", "authors": ["Zhuoran Tan", "Run Hao", "Jeremy Singer", "Yutian Tang", "Christos Anagnostopoulos"], "title": "MCP-SandboxScan: WASM-based Secure Execution and Runtime Analysis for MCP Tools", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Tool-augmented LLM agents raise new security risks: tool executions can introduce runtime-only behaviors, including prompt injection and unintended exposure of external inputs (e.g., environment secrets or local files). While existing scanners often focus on static artifacts, analyzing runtime behavior is challenging because directly executing untrusted tools can itself be dangerous. We present MCP-SandboxScan, a lightweight framework motivated by the Model Context Protocol (MCP) that safely executes untrusted tools inside a WebAssembly/WASI sandbox and produces auditable reports of external-to-sink exposures. Our prototype (i) extracts LLM-relevant sinks from runtime outputs (prompt/messages and structured tool-return fields), (ii) instantiates external-input candidates from environment values, mounted file contents, and output-surfaced HTTP fetch intents, and (iii) links sources to sinks via snippet-based substring matching. Case studies on three representative tools show that MCP-SandboxScan can surface provenance evidence when external inputs appear in prompt/messages or tool-return payloads, and can expose filesystem capability violations as runtime evidence. We further compare against a lightweight static string-signature baseline and use a micro-benchmark to characterize false negatives under transformations and false positives from short-token collisions.", "AI": {"tldr": "\u63d0\u51faMCP - SandboxScan\u6846\u67b6\uff0c\u7528\u4e8e\u5b89\u5168\u6267\u884c\u4e0d\u53ef\u4fe1\u5de5\u5177\u5e76\u751f\u6210\u5ba1\u6838\u62a5\u544a\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u6548\u679c\uff0c\u8fd8\u4e0e\u57fa\u51c6\u5bf9\u6bd4\u5206\u6790\u3002", "motivation": "\u5de5\u5177\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5e26\u6765\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u626b\u63cf\u5668\u591a\u5173\u6ce8\u9759\u6001\u5de5\u4ef6\uff0c\u5206\u6790\u8fd0\u884c\u65f6\u884c\u4e3a\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u57fa\u4e8eModel Context Protocol (MCP)\u6784\u5efaMCP - SandboxScan\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u5728WebAssembly/WASI\u6c99\u7bb1\u4e2d\u5b89\u5168\u6267\u884c\u4e0d\u53ef\u4fe1\u5de5\u5177\uff0c\u4ece\u8fd0\u884c\u65f6\u8f93\u51fa\u4e2d\u63d0\u53d6\u76f8\u5173\u6c47\u805a\u70b9\u3001\u5b9e\u4f8b\u5316\u5916\u90e8\u8f93\u5165\u5019\u9009\u3001\u901a\u8fc7\u57fa\u4e8e\u7247\u6bb5\u7684\u5b50\u5b57\u7b26\u4e32\u5339\u914d\u5c06\u6e90\u4e0e\u6c47\u805a\u70b9\u5173\u8054\u3002", "result": "\u5bf9\u4e09\u4e2a\u4ee3\u8868\u6027\u5de5\u5177\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cMCP - SandboxScan\u80fd\u5728\u5916\u90e8\u8f93\u5165\u51fa\u73b0\u5728\u63d0\u793a/\u6d88\u606f\u6216\u5de5\u5177\u8fd4\u56de\u6709\u6548\u8d1f\u8f7d\u4e2d\u65f6\u663e\u793a\u6eaf\u6e90\u8bc1\u636e\uff0c\u8fd8\u80fd\u66b4\u9732\u6587\u4ef6\u7cfb\u7edf\u80fd\u529b\u8fdd\u89c4\u60c5\u51b5\uff1b\u4e0e\u8f7b\u91cf\u7ea7\u9759\u6001\u5b57\u7b26\u4e32\u7b7e\u540d\u57fa\u7ebf\u5bf9\u6bd4\uff0c\u4f7f\u7528\u5fae\u57fa\u51c6\u6d4b\u8bd5\u8868\u5f81\u4e86\u8f6c\u6362\u4e0b\u7684\u5047\u9634\u6027\u548c\u77ed\u4ee4\u724c\u51b2\u7a81\u5bfc\u81f4\u7684\u5047\u9633\u6027\u3002", "conclusion": "MCP - SandboxScan\u6709\u52a9\u4e8e\u5b89\u5168\u5206\u6790\u5de5\u5177\u589e\u5f3a\u7684LLM\u4ee3\u7406\u8fd0\u884c\u65f6\u884c\u4e3a\uff0c\u53ef\u6709\u6548\u53d1\u73b0\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2601.01562", "pdf": "https://arxiv.org/pdf/2601.01562", "abs": "https://arxiv.org/abs/2601.01562", "authors": ["Mingyu Xu", "Cheng Fang", "Keyue Jiang", "Yuqian Zheng", "Yanghua Xiao", "Baojian Zhou", "Qifang Zhao", "Suhang Zheng", "Xiuwen Zhu", "Jiyang Tang", "Yongchi Zhao", "Yijia Luo", "Zhiqi Bai", "Yuchi Xu", "Wenbo Su", "Wei Wang", "Bing Zhao", "Lin Qu", "Xiaoxiao Xu"], "title": "Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement", "categories": ["cs.AI"], "comment": null, "summary": "We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u63a8\u7406\u6a21\u578bLogics - STEM\uff0c\u5728Logics - STEM - SFT - Dataset\u4e0a\u5fae\u8c03\uff0c\u5728STEM\u9886\u57df\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u51fa\u8272\uff0c\u63ed\u793a\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u6f5c\u529b\u5e76\u5f00\u6e90\u6a21\u578b\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u63d0\u5347\u79d1\u5b66\u3001\u6280\u672f\u3001\u5de5\u7a0b\u548c\u6570\u5b66\uff08STEM\uff09\u9886\u57df\u63a8\u7406\u4efb\u52a1\u7684\u8868\u73b0\u3002", "method": "\u5148\u6784\u5efa\u542b5\u4e2a\u9636\u6bb5\u7684\u6570\u636e\u5904\u7406\u5f15\u64ce\u6253\u9020Logics - STEM - SFT - Dataset\uff0c\u518d\u4f7f\u7528\u5931\u8d25\u9a71\u52a8\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u5728\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u56f4\u7ed5\u6a21\u578b\u5931\u8d25\u533a\u57df\u8fdb\u884c\u77e5\u8bc6\u68c0\u7d22\u548c\u6570\u636e\u5408\u6210\u3002", "result": "Logics - STEM\u5728STEM\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6bd48B\u89c4\u6a21\u7684\u6b21\u4f18\u6a21\u578b\u5e73\u5747\u63d0\u53474.68%\u3002", "conclusion": "\u7ed3\u5408\u5927\u89c4\u6a21\u5f00\u6e90\u6570\u636e\u548c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5408\u6210\u6570\u636e\u6f5c\u529b\u5de8\u5927\uff0c\u6570\u636e\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u5bf9\u901a\u8fc7\u540e\u8bad\u7ec3\u63d0\u5347\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.01502", "pdf": "https://arxiv.org/pdf/2601.01502", "abs": "https://arxiv.org/abs/2601.01502", "authors": ["Milind Nakul", "Tianjiao Li", "Ashwin Pananjady"], "title": "Multiscale replay: A robust algorithm for stochastic variational inequalities with a Markovian buffer", "categories": ["math.OC", "stat.ML"], "comment": null, "summary": "We introduce the Multiscale Experience Replay (MER) algorithm for solving a class of stochastic variational inequalities (VIs) in settings where samples are generated from a Markov chain and we have access to a memory buffer to store them. Rather than uniformly sampling from the buffer, MER utilizes a multi-scale sampling scheme to emulate the behavior of VI algorithms designed for independent and identically distributed samples, overcoming bias in the de facto serial scheme and thereby accelerating convergence. Notably, unlike standard sample-skipping variants of serial algorithms, MER is robust in that it achieves this acceleration in iteration complexity whenever possible, and without requiring knowledge of the mixing time of the Markov chain. We also discuss applications of MER, particularly in policy evaluation with temporal difference learning and in training generalized linear models with dependent data.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5c3a\u5ea6\u7ecf\u9a8c\u56de\u653e\uff08MER\uff09\u7b97\u6cd5\u89e3\u51b3\u4e00\u7c7b\u968f\u673a\u53d8\u5206\u4e0d\u7b49\u5f0f\uff0c\u91c7\u7528\u591a\u5c3a\u5ea6\u91c7\u6837\u65b9\u6848\u52a0\u901f\u6536\u655b\uff0c\u4e14\u4e0d\u4f9d\u8d56\u9a6c\u5c14\u53ef\u592b\u94fe\u6df7\u5408\u65f6\u95f4\u77e5\u8bc6\uff0c\u8fd8\u8ba8\u8bba\u4e86\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u5728\u9a6c\u5c14\u53ef\u592b\u94fe\u751f\u6210\u6837\u672c\u4e14\u6709\u5b58\u50a8\u7f13\u51b2\u533a\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6c42\u89e3\u968f\u673a\u53d8\u5206\u4e0d\u7b49\u5f0f\u65f6\u53ef\u80fd\u5b58\u5728\u7684\u504f\u5dee\u548c\u6536\u655b\u901f\u5ea6\u95ee\u9898\u3002", "method": "\u5f15\u5165Multiscale Experience Replay\uff08MER\uff09\u7b97\u6cd5\uff0c\u5229\u7528\u591a\u5c3a\u5ea6\u91c7\u6837\u65b9\u6848\u66ff\u4ee3\u5747\u5300\u91c7\u6837\u3002", "result": "\u514b\u670d\u4e86\u5e8f\u5217\u65b9\u6848\u4e2d\u7684\u504f\u5dee\uff0c\u52a0\u901f\u4e86\u6536\u655b\uff0c\u4e14\u5728\u53ef\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8fed\u4ee3\u590d\u6742\u5ea6\u7684\u52a0\u901f\uff0c\u4e0d\u4f9d\u8d56\u9a6c\u5c14\u53ef\u592b\u94fe\u6df7\u5408\u65f6\u95f4\u77e5\u8bc6\u3002", "conclusion": "MER\u7b97\u6cd5\u5728\u89e3\u51b3\u968f\u673a\u53d8\u5206\u4e0d\u7b49\u5f0f\u65b9\u9762\u6709\u4f18\u52bf\uff0c\u53ef\u5e94\u7528\u4e8e\u7b56\u7565\u8bc4\u4f30\u548c\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u8bad\u7ec3\u3002"}}
{"id": "2601.01569", "pdf": "https://arxiv.org/pdf/2601.01569", "abs": "https://arxiv.org/abs/2601.01569", "authors": ["Maohao Ran", "Zhenglin Wan", "Cooper Lin", "Yanting Zhang", "Hongyu Xin", "Hongwei Fan", "Yibo Xu", "Beier Luo", "Yaxin Zhou", "Wangbo Zhao", "Lijie Yang", "Lang Feng", "Fuchao Yang", "Jingxuan Wu", "Yiqiao Huang", "Chendong Ma", "Dailing Jiang", "Jianbo Deng", "Sihui Han", "Bo An", "Yike Guo", "Jun Song"], "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators", "categories": ["cs.AI", "cs.SE"], "comment": "32 pages, 14 Figures", "summary": "LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from \"LLM-as-Text-Generator\" to \"LLM-as-Runtime-Operator.\" We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \\textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\\% success rate improvement on retail tasks and reduces total token consumption by 28.4\\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faCaveAgent\u6846\u67b6\uff0c\u5c06\u8303\u5f0f\u4ece\u2018LLM\u4f5c\u4e3a\u6587\u672c\u751f\u6210\u5668\u2019\u8f6c\u53d8\u4e3a\u2018LLM\u4f5c\u4e3a\u8fd0\u884c\u65f6\u64cd\u4f5c\u7b26\u2019\uff0c\u901a\u8fc7\u53cc\u6d41\u4e0a\u4e0b\u6587\u67b6\u6784\u548c\u72b6\u6001\u8fd0\u884c\u65f6\u7ba1\u7406\uff0c\u5728\u591a\u65b9\u9762\u8bc4\u4f30\u4e2d\u5c55\u73b0\u4f18\u8d8a\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u53d7\u9650\u4e8e\u6587\u672c\u4e2d\u5fc3\u8303\u5f0f\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u957f\u5468\u671f\u4efb\u52a1\u4e2d\u56e0\u591a\u8f6e\u4f9d\u8d56\u8106\u5f31\u548c\u4e0a\u4e0b\u6587\u6f02\u79fb\u800c\u5b58\u5728\u95ee\u9898\u3002", "method": "\u63d0\u51faCaveAgent\u6846\u67b6\uff0c\u5f15\u5165\u53cc\u6d41\u4e0a\u4e0b\u6587\u67b6\u6784\uff0c\u5c06\u72b6\u6001\u7ba1\u7406\u89e3\u8026\u4e3a\u8bed\u4e49\u6d41\u548cPython\u8fd0\u884c\u65f6\u6d41\uff1b\u5229\u7528\u4ee3\u7801\u751f\u6210\u89e3\u51b3\u5b50\u4efb\u52a1\uff0c\u5f15\u5165\u72b6\u6001\u8fd0\u884c\u65f6\u7ba1\u7406\uff0c\u53ef\u6ce8\u5165\u3001\u64cd\u4f5c\u548c\u68c0\u7d22\u590d\u6742Python\u5bf9\u8c61\u3002", "result": "\u5728Tau\u00b2 - bench\u3001BFCL\u7b49\u8bc4\u4f30\u4e2d\uff0c\u5728\u96f6\u552e\u4efb\u52a1\u6210\u529f\u7387\u63d0\u534710.5%\uff0c\u591a\u8f6e\u573a\u666f\u51cf\u5c1128.4%\u7684\u603b\u4ee4\u724c\u6d88\u8017\uff0c\u6570\u636e\u5bc6\u96c6\u578b\u4efb\u52a1\u51cf\u5c1159%\u7684\u4ee4\u724c\u6d88\u8017\u3002", "conclusion": "CaveAgent\u6846\u67b6\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u80fd\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u3002"}}
{"id": "2601.01609", "pdf": "https://arxiv.org/pdf/2601.01609", "abs": "https://arxiv.org/abs/2601.01609", "authors": ["Albert Sadowski", "Jaros\u0142aw A. Chudziak"], "title": "Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration", "categories": ["cs.AI"], "comment": null, "summary": "Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7b26\u53f7\u7cfb\u7edf\u4f18\u52bf\u7684\u96c6\u6210\u6a21\u5f0f\uff0c\u5728\u4e09\u4e2a\u9886\u57df\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\uff0c\u7ed3\u6784\u5316\u5206\u89e3\u63a8\u7406\u6bd4\u5c11\u6837\u672c\u63d0\u793a\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u89c4\u5219\u63a8\u7406\u5728\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u573a\u666f\u9700\u89e3\u91ca\u7075\u6d3b\u6027\u548c\u5f62\u5f0f\u4fdd\u8bc1\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7b26\u53f7\u7cfb\u7edf\u5404\u6709\u4f18\u52a3\uff0c\u9700\u7ed3\u5408\u4e8c\u8005\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u6a21\u5f0f\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u975e\u7ed3\u6784\u5316\u6587\u672c\u6309TBox\u89c4\u8303\u8f6c\u5316\u4e3aABox\u65ad\u8a00\uff0c\u7528\u57fa\u4e8eSWRL\u7684\u63a8\u7406\u5668\u786e\u5b9a\u6027\u5730\u5e94\u7528\u89c4\u5219\uff0c\u5c06\u63a8\u7406\u5206\u89e3\u4e3a\u5b9e\u4f53\u8bc6\u522b\u3001\u65ad\u8a00\u63d0\u53d6\u548c\u7b26\u53f7\u9a8c\u8bc1\u3002", "result": "\u5728\u4e09\u4e2a\u9886\u57df\u548c\u5341\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\u4e2d\uff0c\u7ed3\u6784\u5316\u5206\u89e3\u6bd4\u5c11\u6837\u672c\u63d0\u793a\u603b\u4f53\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5404\u9886\u57df\u5747\u6709\u63d0\u5347\uff0c\u6d88\u878d\u7814\u7a76\u8868\u660e\u7b26\u53f7\u9a8c\u8bc1\u6709\u989d\u5916\u6536\u76ca\uff0cABox\u53ef\u96c6\u6210\u5230\u6807\u51c6\u8bed\u4e49\u7f51\u5de5\u5177\u3002", "conclusion": "\u8be5\u96c6\u6210\u6a21\u5f0f\u6709\u6548\uff0c\u80fd\u5b9e\u73b0\u66f4\u4e30\u5bcc\u63a8\u7406\u6a21\u5f0f\u3002"}}
{"id": "2601.01699", "pdf": "https://arxiv.org/pdf/2601.01699", "abs": "https://arxiv.org/abs/2601.01699", "authors": ["Qicheng Zhao", "Celia M. T. Greenwood", "Qihuang Zhang"], "title": "Varying-Coefficient Mixture of Experts Model", "categories": ["stat.ME", "stat.ML"], "comment": "63 pages", "summary": "Mixture-of-Experts (MoE) is a flexible framework that combines multiple specialized submodels (``experts''), by assigning covariate-dependent weights (``gating functions'') to each expert, and have been commonly used for analyzing heterogeneous data. Existing statistical MoE formulations typically assume constant coefficients, for covariate effects within the expert or gating models, which can be inadequate for longitudinal, spatial, or other dynamic settings where covariate influences and latent subpopulation structure evolve across a known dimension. We propose a Varying-Coefficient Mixture of Experts (VCMoE) model that allows all coefficient effects in both the gating functions and expert models to vary along an indexing variable. We establish identifiability and consistency of the proposed model, and develop an estimation procedure, label-consistent EM algorithm, for both fully functional and hybrid specifications, along with the corresponding asymptotic distributions of the resulting estimators. For inference, simultaneous confidence bands are constructed using both asymptotic theory for the maximum discrepancy between the estimated functional coefficients and their true counterparts, and with bootstrap methods. In addition, a generalized likelihood ratio test is developed to examine whether a coefficient function is genuinely varying across the index variable. Simulation studies demonstrate good finite-sample performance, with acceptable bias and satisfactory coverage rates. We illustrate the proposed VCMoE model using a dataset of single nucleus gene expression in embryonic mice to characterize the temporal dynamics of the associations between the expression levels of genes Satb2 and Bcl11b across two latent cell subpopulations of neurons, yielding results that are consistent with prior findings.", "AI": {"tldr": "\u63d0\u51fa\u53d8\u7cfb\u6570\u4e13\u5bb6\u6df7\u5408\uff08VCMoE\uff09\u6a21\u578b\uff0c\u5141\u8bb8\u7cfb\u6570\u6cbf\u7d22\u5f15\u53d8\u91cf\u53d8\u5316\uff0c\u5efa\u7acb\u6a21\u578b\u6027\u8d28\u548c\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6784\u5efa\u7f6e\u4fe1\u5e26\u548c\u68c0\u9a8c\uff0c\u6a21\u62df\u663e\u793a\u6027\u80fd\u597d\uff0c\u5b9e\u8bc1\u4e0e\u5148\u524d\u53d1\u73b0\u4e00\u81f4\u3002", "motivation": "\u73b0\u6709\u7edf\u8ba1MoE\u5728\u7eb5\u5411\u3001\u7a7a\u95f4\u7b49\u52a8\u6001\u573a\u666f\u4e2d\u56e0\u5047\u8bbe\u7cfb\u6570\u6052\u5b9a\u800c\u4e0d\u8db3\uff0c\u9700\u65b0\u6a21\u578b\u5e94\u5bf9\u534f\u53d8\u91cf\u5f71\u54cd\u548c\u6f5c\u5728\u4e9a\u7fa4\u7ed3\u6784\u53d8\u5316\u3002", "method": "\u63d0\u51faVCMoE\u6a21\u578b\uff0c\u5efa\u7acb\u53ef\u8bc6\u522b\u6027\u548c\u4e00\u81f4\u6027\uff0c\u5f00\u53d1\u6807\u7b7e\u4e00\u81f4EM\u7b97\u6cd5\uff0c\u7528\u6e10\u8fd1\u7406\u8bba\u548cbootstrap\u65b9\u6cd5\u6784\u5efa\u7f6e\u4fe1\u5e26\uff0c\u5f00\u53d1\u5e7f\u4e49\u4f3c\u7136\u6bd4\u68c0\u9a8c\u3002", "result": "\u6a21\u62df\u7814\u7a76\u663e\u793a\u6709\u9650\u6837\u672c\u6027\u80fd\u826f\u597d\uff0c\u504f\u5dee\u53ef\u63a5\u53d7\uff0c\u8986\u76d6\u7387\u6ee1\u610f\uff1b\u5b9e\u8bc1\u7ed3\u679c\u4e0e\u5148\u524d\u53d1\u73b0\u4e00\u81f4\u3002", "conclusion": "VCMoE\u6a21\u578b\u5728\u89e3\u51b3\u52a8\u6001\u573a\u666f\u4e2d\u5206\u6790\u5f02\u6784\u6570\u636e\u95ee\u9898\u65f6\u6709\u6548\uff0c\u80fd\u8f83\u597d\u523b\u753b\u53d8\u91cf\u95f4\u968f\u7279\u5b9a\u7d22\u5f15\u53d8\u5316\u7684\u5173\u8054\u3002"}}
{"id": "2601.01765", "pdf": "https://arxiv.org/pdf/2601.01765", "abs": "https://arxiv.org/abs/2601.01765", "authors": ["Yao Lu", "Shang Liu", "Hangan Zhou", "Wenji Fang", "Qijun Zhang", "Zhiyao Xie"], "title": "A New Benchmark for the Appropriate Evaluation of RTL Code Optimization", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b RTL \u4f18\u5316\u80fd\u529b\u7684 RTL - OPT \u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30 RTL \u4ee3\u7801\u53e5\u6cd5\u6b63\u786e\u6027\uff0c\u672a\u8bc4\u4f30\u529f\u7387\u3001\u6027\u80fd\u548c\u9762\u79ef\u4f18\u5316\u8d28\u91cf\uff0c\u9700\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b RTL \u4f18\u5316\u80fd\u529b\u3002", "method": "\u521b\u5efa\u5305\u542b 36 \u4e2a\u624b\u5de5\u6570\u5b57\u8bbe\u8ba1\u7684 RTL - OPT \u57fa\u51c6\uff0c\u6bcf\u4e2a\u4efb\u52a1\u63d0\u4f9b\u4e00\u5bf9 RTL \u4ee3\u7801\uff0c\u5e76\u96c6\u6210\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u63d0\u51fa RTL - OPT \u57fa\u51c6\u53ef\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u5f0f\u6a21\u578b\u5728\u786c\u4ef6\u8bbe\u8ba1\u4f18\u5316\u65b9\u9762\u7684\u6548\u679c\u3002", "conclusion": "RTL - OPT \u80fd\u5b9e\u73b0\u5bf9\u786c\u4ef6\u8bbe\u8ba1\u4f18\u5316\u751f\u6210\u6a21\u578b\u7684\u6807\u51c6\u5316\u548c\u6709\u610f\u4e49\u8bc4\u4f30\u3002"}}
{"id": "2601.01718", "pdf": "https://arxiv.org/pdf/2601.01718", "abs": "https://arxiv.org/abs/2601.01718", "authors": ["YuanLab. ai", ":", "Shawn Wu", "Sean Wang", "Louie Li", "Darcy Chen", "Allen Wang", "Jiangang Luo", "Xudong Zhao", "Joseph Shen", "Gawain Ma", "Jasper Jia", "Marcus Mao", "Claire Wang", "Hunter He", "Carol Wang", "Zera Zhang", "Jason Wang", "Chonly Shen", "Leo Zhang", "Logan Chen", "Qasim Meng", "James Gong", "Danied Zhao", "Penn Zheng", "Owen Zhu", "Tong Yu"], "title": "Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications", "categories": ["cs.AI"], "comment": null, "summary": "We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5f00\u6e90\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bYuan3.0 Flash\uff0c\u63d0\u51faRAPO\u7b97\u6cd5\u8c03\u8282\u8fc7\u5ea6\u601d\u8003\uff0c\u5728\u4f01\u4e1a\u4efb\u52a1\u548c\u901a\u7528\u4efb\u52a1\u5747\u8868\u73b0\u51fa\u8272\u5e76\u5df2\u5f00\u6e90\u3002", "motivation": "\u63d0\u5347\u6a21\u578b\u5728\u4f01\u4e1a\u5bfc\u5411\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u89e3\u51b3\u5927\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u3002", "method": "\u63d0\u51faReflection - aware Adaptive Policy Optimization (RAPO)\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7b97\u6cd5\u3002", "result": "\u5728\u4f01\u4e1a\u5bfc\u5411\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u6570\u5b66\u3001\u79d1\u5b66\u7b49\u9886\u57df\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u53ea\u9700\u7ea61/4\u52301/2\u7684\u5e73\u5747\u4ee4\u724c\u5c31\u80fd\u8fbe\u5230\u524d\u6cbf\u6a21\u578b\u7684\u51c6\u786e\u7387\u3002", "conclusion": "Yuan3.0 Flash\u5df2\u5b8c\u5168\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2601.01813", "pdf": "https://arxiv.org/pdf/2601.01813", "abs": "https://arxiv.org/abs/2601.01813", "authors": ["Pratik Nag", "Andrew Zammit-Mangion", "Sumeetpal Singh", "Noel Cressie"], "title": "Spatio-temporal modeling and forecasting with Fourier neural operators", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Spatio-temporal process models are often used for modeling dynamic physical and biological phenomena that evolve across space and time. These phenomena may exhibit environmental heterogeneity and complex interactions that are difficult to capture using traditional statistical process models such as Gaussian processes. This work proposes the use of Fourier neural operators (FNOs) for constructing statistical dynamical spatio-temporal models for forecasting. An FNO is a flexible mapping of functions that approximates the solution operator of possibly unknown linear or non-linear partial differential equations (PDEs) in a computationally efficient manner. It does so using samples of inputs and their respective outputs, and hence explicit knowledge of the underlying PDE is not required. Through simulations from a nonlinear PDE with known solution, we compare FNO forecasts to those from state-of-the-art statistical spatio-temporal-forecasting methods. Further, using sea surface temperature data over the Atlantic Ocean and precipitation data across Europe, we demonstrate the ability of FNO-based dynamic spatio-temporal (DST) statistical modeling to capture complex real-world spatio-temporal dependencies. Using collections of testing instances, we show that the FNO-DST forecasts are accurate with valid uncertainty quantification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff08FNO\uff09\u6784\u5efa\u7edf\u8ba1\u52a8\u6001\u65f6\u7a7a\u6a21\u578b\u7528\u4e8e\u9884\u6d4b\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u5176\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7edf\u8ba1\u8fc7\u7a0b\u6a21\u578b\u96be\u4ee5\u6355\u6349\u65f6\u7a7a\u73b0\u8c61\u4e2d\u7684\u73af\u5883\u5f02\u8d28\u6027\u548c\u590d\u6742\u76f8\u4e92\u4f5c\u7528\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u6784\u5efa\u65f6\u7a7a\u6a21\u578b\u3002", "method": "\u4f7f\u7528FNO\u6784\u5efa\u7edf\u8ba1\u52a8\u6001\u65f6\u7a7a\u6a21\u578b\uff0c\u901a\u8fc7\u5df2\u77e5\u89e3\u7684\u975e\u7ebf\u6027\u504f\u5fae\u5206\u65b9\u7a0b\u6a21\u62df\uff0c\u5bf9\u6bd4FNO\u9884\u6d4b\u4e0e\u73b0\u6709\u65b9\u6cd5\uff1b\u7528\u5927\u897f\u6d0b\u6d77\u8868\u6e29\u5ea6\u548c\u6b27\u6d32\u964d\u6c34\u6570\u636e\u9a8c\u8bc1\u3002", "result": "FNO - DST\u9884\u6d4b\u51c6\u786e\uff0c\u80fd\u6709\u6548\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u53ef\u6355\u6349\u590d\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "FNO\u53ef\u7528\u4e8e\u6784\u5efa\u7edf\u8ba1\u52a8\u6001\u65f6\u7a7a\u6a21\u578b\u8fdb\u884c\u6709\u6548\u9884\u6d4b\u3002"}}
{"id": "2601.01743", "pdf": "https://arxiv.org/pdf/2601.01743", "abs": "https://arxiv.org/abs/2601.01743", "authors": ["Bin Xu"], "title": "AI Agent Systems: Architectures, Applications, and Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\\ multi-agent; centralized vs.\\ decentralized coordination), and deployment settings (offline analysis vs.\\ online interactive assistance; safety-critical vs.\\ open-ended tasks). We discuss key design trade-offs -- latency vs.\\ accuracy, autonomy vs.\\ controllability, and capability vs.\\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.", "AI": {"tldr": "\u672c\u6587\u5bf9AI\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u4e86\u8c03\u7814\uff0c\u6db5\u76d6\u591a\u4e2a\u65b9\u9762\uff0c\u7ec4\u7ec7\u4e86\u76f8\u5173\u5de5\u4f5c\u7684\u5206\u7c7b\uff0c\u8ba8\u8bba\u8bbe\u8ba1\u6743\u8861\u3001\u8bc4\u4f30\u590d\u6742\u6027\uff0c\u603b\u7ed3\u6d4b\u91cf\u548c\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u5e76\u6307\u51fa\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u968f\u7740AI\u667a\u80fd\u4f53\u6210\u4e3a\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u548c\u73b0\u5b9e\u8ba1\u7b97\u7684\u5b9e\u7528\u63a5\u53e3\uff0c\u5bf9\u65b0\u5174\u7684AI\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u7efc\u5408\u8c03\u7814\u3002", "method": "\u5bf9AI\u667a\u80fd\u4f53\u67b6\u6784\u5728\u5ba1\u8bae\u63a8\u7406\u3001\u89c4\u5212\u63a7\u5236\u3001\u5de5\u5177\u8c03\u7528\u548c\u73af\u5883\u4ea4\u4e92\u7b49\u65b9\u9762\u8fdb\u884c\u5206\u6790\uff0c\u5c06\u5148\u524d\u5de5\u4f5c\u7ec4\u7ec7\u6210\u7edf\u4e00\u5206\u7c7b\u3002", "result": "\u63a2\u8ba8\u4e86\u5173\u952e\u8bbe\u8ba1\u6743\u8861\uff0c\u5982\u5ef6\u8fdf\u4e0e\u51c6\u786e\u6027\u7b49\uff1b\u6307\u51fa\u8bc4\u4f30\u53d7\u975e\u786e\u5b9a\u6027\u7b49\u56e0\u7d20\u5f71\u54cd\u800c\u590d\u6742\uff1b\u603b\u7ed3\u4e86\u6d4b\u91cf\u548c\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u3002", "conclusion": "\u8bc6\u522b\u51fa\u5f00\u653e\u6311\u6218\uff0c\u5982\u5de5\u5177\u52a8\u4f5c\u9a8c\u8bc1\u3001\u53ef\u6269\u5c55\u5185\u5b58\u7ba1\u7406\u7b49\u3002"}}
{"id": "2601.02157", "pdf": "https://arxiv.org/pdf/2601.02157", "abs": "https://arxiv.org/abs/2601.02157", "authors": ["Francesco Songia", "Raoul Sall\u00e9 de Chou", "Hugues Talbot", "Irene Vignon-Clementel"], "title": "Multi-fidelity graph-based neural networks architectures to learn Navier-Stokes solutions on non-parametrized 2D domains", "categories": ["physics.flu-dyn", "stat.ML"], "comment": null, "summary": "We propose a graph-based, multi-fidelity learning framework for the prediction of stationary Navier--Stokes solutions in non-parametrized two-dimensional geometries. The method is designed to guide the learning process through successive approximations, starting from reduced-order and full Stokes models, and progressively approaching the Navier--Stokes solution. To effectively capture both local and long-range dependencies in the velocity and pressure fields, we combine graph neural networks with Transformer and Mamba architectures. While Transformers achieve the highest accuracy, we show that Mamba can be successfully adapted to graph-structured data through an unsupervised node-ordering strategy. The Mamba approach significantly reduces computational cost while maintaining performance. Physical knowledge is embedded directly into the architecture through an encoding -- processing -- physics informed decoding pipeline. Derivatives are computed through algebraic operators constructed via the Weighted Least Squares method. The flexibility of these operators allows us not only to make the output obey the governing equations, but also to constrain selected hidden features to satisfy mass conservation. We introduce additional physical biases through an enriched graph convolution with the same differential operators describing the PDEs. Overall, we successfully guide the learning process by physical knowledge and fluid dynamics insights, leading to more regular and accurate predictions", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u591a\u4fdd\u771f\u5ea6\u5b66\u4e60\u6846\u67b6\u9884\u6d4b\u4e8c\u7ef4\u51e0\u4f55\u4e2d\u5b9a\u5e38Navier - Stokes\u89e3\uff0c\u7ed3\u5408\u591a\u79cd\u67b6\u6784\uff0c\u5d4c\u5165\u7269\u7406\u77e5\u8bc6\uff0cMamba\u65b9\u6cd5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u4fdd\u8bc1\u6027\u80fd\u3002", "motivation": "\u5b9e\u73b0\u975e\u53c2\u6570\u5316\u4e8c\u7ef4\u51e0\u4f55\u4e2d\u5b9a\u5e38Navier - Stokes\u89e3\u7684\u51c6\u786e\u9884\u6d4b\u3002", "method": "\u901a\u8fc7\u8fde\u7eed\u903c\u8fd1\u5f15\u5bfc\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u4e0eTransformer\u548cMamba\u67b6\u6784\uff0c\u91c7\u7528\u7f16\u7801 - \u5904\u7406 - \u7269\u7406\u4fe1\u606f\u89e3\u7801\u7ba1\u9053\u5d4c\u5165\u7269\u7406\u77e5\u8bc6\uff0c\u7528\u52a0\u6743\u6700\u5c0f\u4e8c\u4e58\u6cd5\u6784\u5efa\u4ee3\u6570\u7b97\u5b50\u8ba1\u7b97\u5bfc\u6570\uff0c\u5f15\u5165\u589e\u5f3a\u56fe\u5377\u79ef\u3002", "result": "\u5145\u5206\u6355\u6349\u4e86\u901f\u5ea6\u548c\u538b\u529b\u573a\u7684\u5c40\u90e8\u548c\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0cMamba\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "\u5229\u7528\u7269\u7406\u77e5\u8bc6\u548c\u6d41\u4f53\u52a8\u529b\u5b66\u89c1\u89e3\u80fd\u6709\u6548\u5730\u5f15\u5bfc\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4f7f\u5f97\u9884\u6d4b\u66f4\u52a0\u89c4\u5219\u548c\u51c6\u786e\u3002"}}
{"id": "2601.02045", "pdf": "https://arxiv.org/pdf/2601.02045", "abs": "https://arxiv.org/abs/2601.02045", "authors": ["Shuoming Zhang", "Jiacheng Zhao", "Qiuchu Yu", "Chunwei Xia", "Zheng Wang", "Xiaobing Feng", "Huimin Cui"], "title": "The New Compiler Stack: A Survey on the Synergy of LLMs and Compilers", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": "Accepted by CCF Transactions on High Performance Computing", "summary": "This survey has provided a systematic overview of the emerging field of LLM-enabled compilation by addressing several key research questions. We first answered how LLMs are being integrated by proposing a comprehensive, multi-dimensional taxonomy that categorizes works based on their Design Philosophy (Selector, Translator, Generator), LLM Methodology, their operational Level of Code Abstraction, and the specific Task Type they address. In answering what advancements these approaches offer, we identified three primary benefits: the democratization of compiler development, the discovery of novel optimization strategies, and the broadening of the compiler's traditional scope. Finally, in addressing the field's challenges and opportunities, we highlighted the critical hurdles of ensuring correctness and achieving scalability, while identifying the development of hybrid systems as the most promising path forward. By providing these answers, this survey serves as a foundational roadmap for researchers and practitioners, charting the course for a new generation of LLM-powered, intelligent, adaptive and synergistic compilation tools.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u7684\u7f16\u8bd1\u9886\u57df\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u63d0\u51fa\u5206\u7c7b\u65b9\u6cd5\uff0c\u6307\u51fa\u8fdb\u5c55\u3001\u6311\u6218\u548c\u673a\u9047\uff0c\u4e3a\u76f8\u5173\u4eba\u5458\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002", "motivation": "\u5bf9\u65b0\u5174\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u7684\u7f16\u8bd1\u9886\u57df\u8fdb\u884c\u7cfb\u7edf\u68b3\u7406\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8bbe\u8ba1\u7406\u5ff5\u3001\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u3001\u4ee3\u7801\u62bd\u8c61\u64cd\u4f5c\u7ea7\u522b\u548c\u4efb\u52a1\u7c7b\u578b\u7684\u591a\u7ef4\u5206\u7c7b\u6cd5\u3002", "result": "\u660e\u786e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u7f16\u8bd1\u7684\u4e09\u4e2a\u4e3b\u8981\u8fdb\u5c55\uff0c\u6307\u51fa\u786e\u4fdd\u6b63\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u5173\u952e\u6311\u6218\uff0c\u8ba4\u4e3a\u6df7\u5408\u7cfb\u7edf\u5f00\u53d1\u662f\u6700\u6709\u524d\u9014\u7684\u65b9\u5411\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u65b0\u4e00\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u7f16\u8bd1\u5de5\u5177\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\u8def\u7ebf\u56fe\u3002"}}
{"id": "2601.02060", "pdf": "https://arxiv.org/pdf/2601.02060", "abs": "https://arxiv.org/abs/2601.02060", "authors": ["Nguyet-Anh H. Lang", "Eric Lang", "Thanh Le-Cong", "Bach Le", "Quyet-Thang Huynh"], "title": "Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": null, "summary": "Functional programming provides strong foundations for developing reliable and secure software systems, yet its adoption remains not widespread due to the steep learning curve. Recent advances in Large Language Models (LLMs) for code generation present new opportunities to lower these barriers. However, extensive evaluations of LLMs largely focus on imperative programming languages, and their capabilities in functional programming languages (FP) remain underexplored. To address this gap, we introduce FPEval, a holistic evaluation framework built on FPBench, a new benchmark of 721 programming tasks across three difficulty levels on three mainstream FP languages: Haskell, Ocaml and Scala. FPEval provides compehensive evaluation infrastructures with both test validations with comprehensive test suites and static analysis tools to assess both functional correctness and code style and maintainability. Using this framework, we evaluate state-of-the-art LLMs, including GPT-3.5, GPT-4o, and GPT-5, for code generation in functional programming languages and Java as an imperative baseline. Our results demonstrate that LLM performance in functional programming improves substantially with model advancement; however, error rates remain significantly higher in purely functional languages (Haskell and OCaml) than in hybrid (Scala) or imperative (Java) languages. Moreover, LLMs frequently generate non-idiomatic functional code that follows imperative patterns, raising concerns about code style and long-term maintainability. Finally, we show that LLMs can partially self-repair both correctness and quality issues when provided with static analysis feedback and hand-crafted instructions for common types of issues.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bc4\u4f30\u6846\u67b6FPEval\u8bc4\u4f30\u5927\u6a21\u578b\u5728\u51fd\u6570\u5f0f\u7f16\u7a0b\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u7ed3\u679c\u8868\u660e\u6a21\u578b\u80fd\u529b\u968f\u53d1\u5c55\u6709\u63d0\u5347\u4f46\u7eaf\u51fd\u6570\u5f0f\u8bed\u8a00\u9519\u8bef\u7387\u9ad8\uff0c\u4ee3\u7801\u98ce\u683c\u6709\u95ee\u9898\uff0c\u4e14\u6a21\u578b\u53ef\u5728\u53cd\u9988\u4e0b\u90e8\u5206\u81ea\u6211\u4fee\u590d\u3002", "motivation": "\u51fd\u6570\u5f0f\u7f16\u7a0b\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u9650\u5236\u5176\u5e94\u7528\uff0c\u76ee\u524d\u5927\u6a21\u578b\u5728\u51fd\u6570\u5f0f\u7f16\u7a0b\u4ee3\u7801\u751f\u6210\u80fd\u529b\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8e\u65b0\u57fa\u51c6FPBench\u6784\u5efa\u8bc4\u4f30\u6846\u67b6FPEval\uff0c\u6db5\u76d6\u4e09\u79cd\u4e3b\u6d41\u51fd\u6570\u5f0f\u8bed\u8a00\u548c721\u4e2a\u7f16\u7a0b\u4efb\u52a1\uff0c\u7efc\u5408\u6d4b\u8bd5\u9a8c\u8bc1\u548c\u9759\u6001\u5206\u6790\u5de5\u5177\u8fdb\u884c\u8bc4\u4f30\u3002\u8bc4\u4f30\u4e86GPT - 3.5\u3001GPT - 4o\u548cGPT - 5\u7b49\u6a21\u578b\uff0c\u4ee5Java\u4e3a\u547d\u4ee4\u5f0f\u7f16\u7a0b\u57fa\u7ebf\u3002", "result": "\u6a21\u578b\u5728\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d\u7684\u6027\u80fd\u968f\u53d1\u5c55\u663e\u8457\u63d0\u5347\uff0c\u4f46\u7eaf\u51fd\u6570\u5f0f\u8bed\u8a00\u9519\u8bef\u7387\u9ad8\u4e8e\u6df7\u5408\u6216\u547d\u4ee4\u5f0f\u8bed\u8a00\uff0c\u751f\u6210\u4ee3\u7801\u5e38\u6709\u547d\u4ee4\u5f0f\u98ce\u683c\u95ee\u9898\u3002", "conclusion": "\u5927\u6a21\u578b\u5728\u51fd\u6570\u5f0f\u7f16\u7a0b\u4ee3\u7801\u751f\u6210\u6709\u8fdb\u6b65\u4f46\u4ecd\u6709\u95ee\u9898\uff0c\u4e14\u53ef\u90e8\u5206\u81ea\u6211\u4fee\u590d\u4ee3\u7801\u6b63\u786e\u6027\u548c\u8d28\u91cf\u95ee\u9898\u3002"}}
{"id": "2601.02062", "pdf": "https://arxiv.org/pdf/2601.02062", "abs": "https://arxiv.org/abs/2601.02062", "authors": ["Patrick Hopf", "Erick Ochoa Lopez", "Yannick Stade", "Damian Rovara", "Nils Quetschlich", "Ioan Albert Florea", "Josh Izaac", "Robert Wille", "Lukas Burgholzer"], "title": "Integrating Quantum Software Tools with(in) MLIR", "categories": ["quant-ph", "cs.SE"], "comment": "13 pages, 7 figures", "summary": "Compilers transform code into action. They convert high-level programs into executable hardware instructions - a crucial step in enabling reliable and scalable quantum computation. However, quantum compilation is still in its infancy, and many existing solutions are ad hoc, often developed independently and from scratch. The resulting lack of interoperability leads to significant missed potential, as quantum software tools remain isolated and cannot be seamlessly integrated into cohesive toolchains.\n  The Multi-Level Intermediate Representation (MLIR) has addressed analogous challenges in the classical domain. It was developed within the LLVM project, which has long powered robust software stacks and enabled compilation across diverse software and hardware components, with particular importance in high-performance computing environments. However, MLIR's steep learning curve poses a significant barrier to entry, particularly in quantum computing, where much of the software stack is still predominantly built by experimentalists out of necessity rather than by experienced software engineers.\n  This paper provides a practical and hands-on guide for quantum software engineers to overcome this steep learning curve. Through a concrete case study linking Xanadu's PennyLane framework with the Munich Quantum Toolkit (MQT), we outline actionable integration steps, highlight best practices, and share hard-earned insights from real-world development. This work aims to support quantum tool developers in navigating MLIR's complexities and to foster its adoption as a unifying bridge across a rapidly growing ecosystem of quantum software tools, ultimately guiding the development of more modular, interoperable, and integrated quantum software stacks.", "AI": {"tldr": "\u672c\u6587\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u63d0\u4f9b\u514b\u670dMLIR\u5b66\u4e60\u66f2\u7ebf\u7684\u5b9e\u7528\u6307\u5357\uff0c\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u96c6\u6210\u6b65\u9aa4\u7b49\uff0c\u63a8\u52a8\u91cf\u5b50\u8f6f\u4ef6\u5de5\u5177\u91c7\u7528MLIR\u3002", "motivation": "\u91cf\u5b50\u7f16\u8bd1\u5c1a\u5904\u8d77\u6b65\u9636\u6bb5\uff0c\u73b0\u6709\u65b9\u6848\u7f3a\u4e4f\u4e92\u64cd\u4f5c\u6027\uff0cMLIR\u867d\u80fd\u89e3\u51b3\u7c7b\u4f3c\u95ee\u9898\u4f46\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\uff0c\u963b\u788d\u5176\u5728\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5c06Xanadu\u7684PennyLane\u6846\u67b6\u4e0e\u6155\u5c3c\u9ed1\u91cf\u5b50\u5de5\u5177\u5305\uff08MQT\uff09\u5173\u8054\u7684\u5177\u4f53\u6848\u4f8b\u7814\u7a76\uff0c\u7ed9\u51fa\u53ef\u64cd\u4f5c\u7684\u96c6\u6210\u6b65\u9aa4\u3002", "result": "\u7ed9\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u96c6\u6210\u6b65\u9aa4\uff0c\u5f3a\u8c03\u4e86\u6700\u4f73\u5b9e\u8df5\uff0c\u5206\u4eab\u4e86\u5b9e\u9645\u5f00\u53d1\u4e2d\u7684\u7ecf\u9a8c\u89c1\u89e3\u3002", "conclusion": "\u652f\u6301\u91cf\u5b50\u5de5\u5177\u5f00\u53d1\u8005\u5e94\u5bf9MLIR\u7684\u590d\u6742\u6027\uff0c\u4fc3\u8fdb\u5176\u4f5c\u4e3a\u7edf\u4e00\u6865\u6881\u88ab\u91c7\u7528\uff0c\u5f15\u5bfc\u5f00\u53d1\u66f4\u6a21\u5757\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u548c\u96c6\u6210\u7684\u91cf\u5b50\u8f6f\u4ef6\u6808\u3002"}}
{"id": "2601.01802", "pdf": "https://arxiv.org/pdf/2601.01802", "abs": "https://arxiv.org/abs/2601.01802", "authors": ["Qianjun Pan", "Junyi Wang", "Jie Zhou", "Yutao Yang", "Junsong Li", "Kaiyin Xu", "Yougen Zhou", "Yihan Li", "Jingyuan Zhao", "Qin Chen", "Ningning Zhou", "Kai Chen", "Liang He"], "title": "PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor", "categories": ["cs.AI"], "comment": null, "summary": "To develop a reliable AI for psychological assessment, we introduce \\texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \\textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \\textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \\textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \\texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8e\u5fc3\u7406\u8bc4\u4f30\u7684\u57fa\u51c6PsychEval\uff0c\u5e94\u5bf9\u8bad\u7ec3\u73b0\u5b9eAI\u54a8\u8be2\u5e08\u3001\u591a\u7597\u6cd5AI\u54a8\u8be2\u5e08\u53ca\u7cfb\u7edf\u8bc4\u4f30AI\u54a8\u8be2\u5e08\u4e09\u4e2a\u6311\u6218\uff0c\u5176\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u8d28\u91cf\uff0c\u8fd8\u53ef\u4f5c\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u3002", "motivation": "\u5f00\u53d1\u53ef\u9760\u7684\u7528\u4e8e\u5fc3\u7406\u8bc4\u4f30\u7684AI\u3002", "method": "\u63d0\u51fa\u591a\u4f1a\u8bdd\u57fa\u51c6\uff0c\u6784\u5efa\u8986\u76d6\u4e94\u79cd\u6cbb\u7597\u65b9\u5f0f\u53ca\u7efc\u5408\u7597\u6cd5\u7684\u591a\u6837\u6570\u636e\u96c6\uff0c\u5efa\u7acb\u5305\u542b18\u4e2a\u6307\u6807\u7684\u6574\u4f53\u8bc4\u4f30\u6846\u67b6\u5e76\u6784\u5efa\u8d852000\u4e2a\u5ba2\u6237\u6863\u6848\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u5206\u6790\u5145\u5206\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u7684\u9ad8\u8d28\u91cf\u548c\u4e34\u5e8a\u4fdd\u771f\u5ea6\u3002", "conclusion": "PsychEval\u53ef\u4f5c\u4e3a\u9ad8\u4fdd\u771f\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u5b9e\u73b0\u5bf9\u5177\u6709\u4e34\u5e8a\u8d23\u4efb\u611f\u548c\u9002\u5e94\u6027\u7684AI\u54a8\u8be2\u5e08\u7684\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\u3002"}}
{"id": "2601.02218", "pdf": "https://arxiv.org/pdf/2601.02218", "abs": "https://arxiv.org/abs/2601.02218", "authors": ["Berke Ates", "Filip Dobrosavljevi\u0107", "Theodoros Theodoridis", "Zhendong Su"], "title": "MLIR-Smith: A Novel Random Program Generator for Evaluating Compiler Pipelines", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "Compilers are essential for the performance and correct execution of software and hold universal relevance across various scientific disciplines. Despite this, there is a notable lack of tools for testing and evaluating them, especially within the adaptable Multi-Level Intermediate Representation (MLIR) context. This paper addresses the need for a tool that can accommodate MLIR's extensibility, a feature not provided by previous methods such as Csmith. Here we introduce MLIR-Smith, a novel random program generator specifically designed to test and evaluate MLIR-based compiler optimizations. We demonstrate the utility of MLIR-Smith by conducting differential testing on MLIR, LLVM, DaCe, and DCIR, which led to the discovery of multiple bugs in these compiler pipelines. The introduction of MLIR-Smith not only fills a void in the realm of compiler testing but also emphasizes the importance of comprehensive testing within these systems. By providing a tool that can generate random MLIR programs, this paper enhances our ability to evaluate and improve compilers and paves the way for future tools, potentially shaping the wider landscape of software testing and quality assurance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMLIR - Smith\u968f\u673a\u7a0b\u5e8f\u751f\u6210\u5668\u7528\u4e8e\u6d4b\u8bd5\u548c\u8bc4\u4f30\u57fa\u4e8eMLIR\u7684\u7f16\u8bd1\u5668\u4f18\u5316\uff0c\u901a\u8fc7\u5dee\u5206\u6d4b\u8bd5\u53d1\u73b0\u591a\u4e2a\u7f16\u8bd1\u5668\u7ba1\u9053\u7684\u6f0f\u6d1e\uff0c\u586b\u8865\u7f16\u8bd1\u5668\u6d4b\u8bd5\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u5bf9\u53ef\u9002\u5e94\u7684\u591a\u7ea7\u4e2d\u95f4\u8868\u793a\uff08MLIR\uff09\u4e0a\u4e0b\u6587\u7684\u7f16\u8bd1\u5668\u6d4b\u8bd5\u548c\u8bc4\u4f30\u80fd\u529b\uff0c\u9700\u8981\u80fd\u9002\u5e94MLIR\u53ef\u6269\u5c55\u6027\u7684\u5de5\u5177\u3002", "method": "\u5f15\u5165\u4e13\u95e8\u8bbe\u8ba1\u7684\u968f\u673a\u7a0b\u5e8f\u751f\u6210\u5668MLIR - Smith\uff0c\u5bf9MLIR\u3001LLVM\u3001DaCe\u548cDCIR\u8fdb\u884c\u5dee\u5206\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u6d4b\u8bd5\u53d1\u73b0\u4e86\u8fd9\u4e9b\u7f16\u8bd1\u5668\u7ba1\u9053\u4e2d\u7684\u591a\u4e2a\u6f0f\u6d1e\u3002", "conclusion": "MLIR - Smith\u586b\u8865\u4e86\u7f16\u8bd1\u5668\u6d4b\u8bd5\u9886\u57df\u7684\u7a7a\u767d\uff0c\u5f3a\u8c03\u4e86\u7cfb\u7edf\u5168\u9762\u6d4b\u8bd5\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u7f16\u8bd1\u5668\u63d0\u4f9b\u5e2e\u52a9\uff0c\u4e3a\u672a\u6765\u5de5\u5177\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2601.01816", "pdf": "https://arxiv.org/pdf/2601.01816", "abs": "https://arxiv.org/abs/2601.01816", "authors": ["Chris Duffey"], "title": "Admissibility Alignment", "categories": ["cs.AI"], "comment": "24 pages, 2 figures, 2 tables.. Decision-theoretic alignment under uncertainty", "summary": "This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.\n  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u53ef\u5bb9\u8bb8\u6027\u5bf9\u9f50\u6982\u5ff5\u53caMAP - AI\u7cfb\u7edf\u67b6\u6784\uff0c\u7528\u4e8e\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684AI\u5bf9\u9f50\u51b3\u7b56\uff0c\u5e76\u5c06\u5206\u5e03\u5bf9\u9f50\u8bc4\u4f30\u878d\u5165\u51b3\u7b56\u4e2d\u3002", "motivation": "\u91cd\u65b0\u6784\u5efaAI\u5bf9\u9f50\uff0c\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u4e0bAI\u51b3\u7b56\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u8bc4\u4f30\u4f01\u4e1a\u548c\u673a\u6784AI\u7cfb\u7edf\u7684\u4fe1\u4efb\u4e0e\u5bf9\u9f50\u3002", "method": "\u63d0\u51faAdmissibility Alignment\u6982\u5ff5\uff0c\u4ee5MAP - AI\u7cfb\u7edf\u67b6\u6784\uff0c\u901a\u8fc7\u8499\u7279\u5361\u7f57\u4f30\u8ba1\u7ed3\u679c\u5206\u5e03\u548c\u53ef\u5bb9\u8bb8\u6027\u63a7\u5236\u7b56\u7565\u9009\u62e9\u6765\u6267\u884c\u5bf9\u9f50\uff0c\u8bc4\u4f30\u51b3\u7b56\u7b56\u7565\u3002", "result": "\u4e3a\u7ba1\u7406AI\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u7528\u57fa\u7840\uff0c\u5176\u5f71\u54cd\u7531\u7b56\u7565\u884c\u4e3a\u51b3\u5b9a\u3002", "conclusion": "\u53ef\u5c06\u5206\u5e03\u5bf9\u9f50\u8bc4\u4f30\u878d\u5165\u51b3\u7b56\uff0c\u4ea7\u751f\u53ef\u5bb9\u8bb8\u6027\u63a7\u5236\u7684\u884c\u52a8\u9009\u62e9\u673a\u5236\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u4fee\u6539\u5e95\u5c42\u6a21\u578b\u3002"}}
{"id": "2601.02233", "pdf": "https://arxiv.org/pdf/2601.02233", "abs": "https://arxiv.org/abs/2601.02233", "authors": ["Leon M\u00fcller", "Adelina B\u00e4rligea", "Alexander Knapp", "Jakob S. Kottmann"], "title": "PauliEngine: High-Performant Symbolic Arithmetic for Quantum Operations", "categories": ["quant-ph", "cs.ET", "cs.SE", "physics.comp-ph"], "comment": null, "summary": "Quantum computation is inherently hybrid, and fast classical manipulation of qubit operators is necessary to ensure scalability in quantum software. We introduce PauliEngine, a high-performance C++ framework that provides efficient primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations. Built on a binary symplectic representation and optimized bit-wise operations, PauliEngine supports both numerical and symbolic coefficients and is accessible through a Python interface. Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. PauliEngine provides a scalable backend for operator-based quantum software tools and simulations.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u9ad8\u6027\u80fdC++\u6846\u67b6PauliEngine\uff0c\u80fd\u63d0\u5347\u91cf\u5b50\u8f6f\u4ef6\u7b97\u5b50\u64cd\u4f5c\u901f\u5ea6\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u540e\u7aef\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5177\u6709\u6df7\u5408\u7279\u6027\uff0c\u9700\u8981\u5feb\u901f\u7ecf\u5178\u64cd\u4f5c\u91cf\u5b50\u6bd4\u7279\u7b97\u5b50\u4ee5\u786e\u4fdd\u91cf\u5b50\u8f6f\u4ef6\u53ef\u6269\u5c55\u6027\u3002", "method": "\u57fa\u4e8e\u4e8c\u5143\u8f9b\u8868\u793a\u548c\u4f18\u5316\u4f4d\u8fd0\u7b97\u6784\u5efaPauliEngine\u6846\u67b6\uff0c\u652f\u6301\u6570\u503c\u548c\u7b26\u53f7\u7cfb\u6570\uff0c\u6709Python\u63a5\u53e3\u3002", "result": "\u8fd0\u884c\u65f6\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6bd4\u73b0\u6709\u5b9e\u73b0\u6709\u663e\u8457\u52a0\u901f\u3002", "conclusion": "PauliEngine\u53ef\u4e3a\u57fa\u4e8e\u7b97\u5b50\u7684\u91cf\u5b50\u8f6f\u4ef6\u5de5\u5177\u548c\u6a21\u62df\u63d0\u4f9b\u53ef\u6269\u5c55\u540e\u7aef\u3002"}}
{"id": "2601.01836", "pdf": "https://arxiv.org/pdf/2601.01836", "abs": "https://arxiv.org/abs/2601.01836", "authors": ["Dasol Choi", "DongGeon Lee", "Brigitta Jesica Kartono", "Helena Berndt", "Taeyoun Kwon", "Joonwon Jang", "Haon Park", "Hwanjo Yu", "Minsuk Kahng"], "title": "COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.", "AI": {"tldr": "\u63d0\u51faCOMPASS\u8bc4\u4f30\u6846\u67b6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u7ec4\u7ec7\u7b56\u7565\u7684\u9075\u5b88\u60c5\u51b5\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5904\u7406\u7981\u4ee4\u80fd\u529b\u5dee\uff0cCOMPASS\u5bf9\u7ec4\u7ec7AI\u5b89\u5168\u8bc4\u4f30\u5fc5\u8981\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u4f01\u4e1a\u573a\u666f\uff0c\u9700\u786e\u4fdd\u5176\u9075\u5b88\u7ec4\u7ec7\u7279\u5b9a\u7b56\u7565\uff0c\u4f46\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u4ec5\u5173\u6ce8\u666e\u904d\u5371\u5bb3\u3002", "method": "\u63d0\u51faCOMPASS\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u516b\u4e2a\u884c\u4e1a\u573a\u666f\uff0c\u751f\u6210\u5e76\u9a8c\u8bc15920\u4e2a\u67e5\u8be2\u6d4b\u8bd5\u5e38\u89c4\u5408\u89c4\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "result": "\u8bc4\u4f30\u4e03\u4e2a\u6a21\u578b\u53d1\u73b0\uff0c\u6a21\u578b\u5904\u7406\u5408\u6cd5\u8bf7\u6c42\u51c6\u786e\u7387\u8d8595%\uff0c\u4f46\u62d2\u7edd\u5bf9\u6297\u6027\u9ed1\u540d\u5355\u8fdd\u89c4\u4ec513 - 40%\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u7b56\u7565\u5173\u952e\u90e8\u7f72\u6240\u9700\u7684\u9c81\u68d2\u6027\uff0cCOMPASS\u662f\u7ec4\u7ec7AI\u5b89\u5168\u7684\u91cd\u8981\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2601.01844", "pdf": "https://arxiv.org/pdf/2601.01844", "abs": "https://arxiv.org/abs/2601.01844", "authors": ["Udiptaman Das", "Krishnasai B. Atmakuri", "Duy Ho", "Chi Lee", "Yugyung Lee"], "title": "Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "13 pages, 5 tables, 4 figures", "summary": "Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u81ea\u7531\u6587\u672c\u6784\u5efa\u548c\u8bc4\u4f30\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5e94\u7528\u4e8e\u80bf\u7624\u961f\u5217\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u53d9\u4e8b\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u4f9d\u8d56\u7ed3\u6784\u5316\u8f93\u5165\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u6709\u6548\u9a8c\u8bc1\uff0c\u5728\u80bf\u7624\u5b66\u9886\u57df\u95ee\u9898\u7a81\u51fa\u3002", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u63d0\u793a\u548c\u6a21\u5f0f\u7ea6\u675f\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b56\u7565\uff1b\u7ba1\u9053\u96c6\u6210\u5b9e\u4f53\u7b49\u63d0\u53d6\u3001\u4e0d\u786e\u5b9a\u6027\u8bc4\u5206\u3001\u6a21\u5f0f\u751f\u6210\u548c\u591a\u5927\u8bed\u8a00\u6a21\u578b\u5171\u8bc6\u9a8c\u8bc1\uff1b\u652f\u6301\u6301\u7eed\u7ec6\u5316\u548c\u81ea\u76d1\u7763\u8bc4\u4f30\u3002", "result": "\u5e94\u7528\u4e8e\u4e24\u4e2a\u80bf\u7624\u961f\u5217\uff0c\u751f\u6210\u53ef\u89e3\u91ca\u3001\u517c\u5bb9SPARQL\u4e14\u57fa\u4e8e\u4e34\u5e8a\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u5728\u7cbe\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u672c\u4f53\u5408\u89c4\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u6709\u6548\u4ece\u81ea\u7531\u6587\u672c\u6784\u5efa\u548c\u8bc4\u4f30\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u5347\u56fe\u8c31\u8d28\u91cf\u3002"}}
{"id": "2601.01857", "pdf": "https://arxiv.org/pdf/2601.01857", "abs": "https://arxiv.org/abs/2601.01857", "authors": ["Defei Xia", "Bingfeng Pi", "Shenbin Zhang", "Song Hua", "Yunfei Wei", "Lei Zuo"], "title": "Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios", "categories": ["cs.AI"], "comment": null, "summary": "As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u771f\u5b9e\u7ecf\u9a8c\u7684\u4ee3\u7406\u6846\u67b6Jenius - Agent\uff0c\u4e09\u9879\u5173\u952e\u521b\u65b0\u4f18\u5316\u4e86\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6d41\u7a0b\uff0c\u5b9e\u9a8c\u663e\u793a\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u534720%\uff0c\u8fd8\u964d\u4f4e\u4e86\u6210\u672c\u7b49\uff0c\u5df2\u90e8\u7f72\u5230Jenius\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7cfb\u7edf\u53d1\u5c55\uff0c\u6539\u5584\u81ea\u4e3b\u4ee3\u7406\u4efb\u52a1\u6027\u80fd\u5f88\u5173\u952e\uff0c\u4ee5\u5f80\u5bf9\u5176\u5185\u90e8\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6d41\u7a0b\u7684\u7cfb\u7edf\u4f18\u5316\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e09\u9879\u5173\u952e\u521b\u65b0\uff1a\u81ea\u9002\u5e94\u63d0\u793a\u751f\u6210\u7b56\u7565\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u5de5\u5177\u7f16\u6392\u6a21\u5757\u3001\u5206\u5c42\u5185\u5b58\u673a\u5236\uff0c\u96c6\u6210\u4e09\u9879\u4f18\u5316\u5f62\u6210Jenius - Agent\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u9ad820%\uff0c\u964d\u4f4e\u4e86token\u6210\u672c\u3001\u54cd\u5e94\u5ef6\u8fdf\u548c\u8c03\u7528\u5931\u8d25\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7a33\u5065\u3001\u534f\u8bae\u517c\u5bb9\u7684\u81ea\u4e3b\u4ee3\u7406\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u90e8\u7f72\u5230Jenius\u3002"}}
{"id": "2601.01875", "pdf": "https://arxiv.org/pdf/2601.01875", "abs": "https://arxiv.org/abs/2601.01875", "authors": ["Kewen Cao", "Jianxu Chen", "Yongbing Zhang", "Ye Zhang", "Hongxiao Wang"], "title": "Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.", "AI": {"tldr": "\u63d0\u51fa\u4ee5SQL\u4e3a\u4e2d\u5fc3\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u75c5\u7406\u56fe\u50cf\u5206\u6790\uff0c\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u81ea\u52a8\u5316\u75c5\u7406\u56fe\u50cf\u5206\u6790\u4e2d\uff0c\u4e34\u5e8a\u533b\u751f\u9700\u4e86\u89e3\u6a21\u578b\u51b3\u7b56\u4f9d\u636e\uff0c\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u8bc1\u636e\u3002", "method": "\u63d0\u53d6\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u7ec6\u80de\u7279\u5f81\uff0cFeature Reasoning Agents\u7f16\u5199\u5e76\u6267\u884cSQL\u67e5\u8be2\u805a\u5408\u89c6\u89c9\u8bc1\u636e\uff0cKnowledge Comparison Agent\u6839\u636e\u75c5\u7406\u77e5\u8bc6\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "\u5728\u4e24\u4e2a\u75c5\u7406\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u89e3\u91ca\u6027\u548c\u51b3\u7b56\u53ef\u8ffd\u6eaf\u6027\uff0c\u751f\u6210\u53ef\u6267\u884cSQL\u8ffd\u8e2a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4ee5SQL\u4e3a\u4e2d\u5fc3\u7684\u4ee3\u7406\u6846\u67b6\u6709\u6548\u53ef\u884c\u3002"}}
{"id": "2601.01878", "pdf": "https://arxiv.org/pdf/2601.01878", "abs": "https://arxiv.org/abs/2601.01878", "authors": ["Farzan Karimi-Malekabadi", "Suhaib Abdurahman", "Zhivar Sourati", "Jackson Trager", "Morteza Dehghani"], "title": "Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u793e\u4f1a\u8ba4\u77e5\u57fa\u51c6\u96be\u9884\u6d4b\u771f\u5b9e\u884c\u4e3a\uff0c\u6839\u6e90\u662f\u7406\u8bba\u5b9a\u4e49\u7f3a\u5931\uff0c\u6587\u7ae0\u8bca\u65ad\u8be5\u95ee\u9898\u5e76\u63d0\u51fa\u7406\u8bba\u8ffd\u8e2a\u5361\uff08TTC\uff09\u6765\u63d0\u5347\u8bc4\u4f30\u53ef\u89e3\u91ca\u6027\u548c\u590d\u7528\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u793e\u4f1a\u8ba4\u77e5\u8bc4\u4f30\u4e2d\u57fa\u51c6\u5206\u6570\u4e0e\u5b9e\u9645\u884c\u4e3a\u4e0d\u7b26\u7684\u843d\u5dee\u95ee\u9898\uff0c\u6307\u51fa\u4ee5\u5f80\u5f52\u56e0\u672a\u89e6\u53ca\u7406\u8bba\u5b9a\u4e49\u8fd9\u4e00\u6839\u672c\u95ee\u9898\u3002", "method": "\u9996\u5148\u8bca\u65ad\u5e76\u5c06\u7406\u8bba\u5dee\u8ddd\u5f62\u5f0f\u5316\uff0c\u7136\u540e\u5f15\u5165\u7406\u8bba\u8ffd\u8e2a\u5361\uff08TTC\uff09\u5e76\u9610\u8ff0\u5176\u8bbe\u8ba1\u7279\u70b9\u3002", "result": "\u660e\u786e\u7406\u8bba\u5dee\u8ddd\u662f\u57fa\u7840\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u7406\u8bba\u8ffd\u8e2a\u5361\u80fd\u660e\u786e\u5b8c\u6574\u7684\u6709\u6548\u6027\u94fe\u6761\u3002", "conclusion": "\u7406\u8bba\u8ffd\u8e2a\u5361\u53ef\u5728\u4e0d\u4fee\u6539\u57fa\u51c6\u6216\u8fbe\u6210\u7edf\u4e00\u7406\u8bba\u7684\u60c5\u51b5\u4e0b\uff0c\u589e\u5f3a\u793e\u4f1a\u8ba4\u77e5\u8bc4\u4f30\u7684\u53ef\u89e3\u91ca\u6027\u548c\u590d\u7528\u6027\u3002"}}
{"id": "2601.01910", "pdf": "https://arxiv.org/pdf/2601.01910", "abs": "https://arxiv.org/abs/2601.01910", "authors": ["Minh Hieu Ha", "Khanh Ly Ta", "Hung Phan", "Tung Doan", "Tung Dao", "Dao Tran", "Huynh Thi Thanh Binh"], "title": "MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning", "categories": ["cs.AI"], "comment": null, "summary": "Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.\n  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.", "AI": {"tldr": "\u9488\u5bf9\u4f20\u7edf\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u4e0d\u8db3\uff0c\u63d0\u51faMMP - A*\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u81ea\u4e3b\u5bfc\u822a\u4e2d\u9ad8\u6548\u4e14\u80fd\u5b9e\u73b0\u8fd1\u6700\u4f18\u8f68\u8ff9\u3002", "motivation": "\u7ecf\u5178A*\u7b97\u6cd5\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\uff0c\u4ec5\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8def\u5f84\u70b9\u5f15\u5bfc\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u5728\u590d\u6742\u73af\u5883\u6613\u4ea7\u751f\u9519\u8bef\u8def\u5f84\u70b9\uff0c\u7f3a\u4e4f\u611f\u77e5\u80fd\u529b\uff0c\u5bfc\u81f4\u7ea0\u6b63\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\u3002", "method": "\u5f15\u5165MMP - A*\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7ed3\u5408\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u5b9a\u4f4d\u80fd\u529b\u548c\u81ea\u9002\u5e94\u8870\u51cf\u673a\u5236\uff0c\u4ee5\u7269\u7406\u51e0\u4f55\u4e3a\u57fa\u7840\u8fdb\u884c\u9ad8\u7ea7\u63a8\u7406\uff0c\u5e76\u52a8\u6001\u8c03\u8282\u542f\u53d1\u5f0f\u4e2d\u4e0d\u786e\u5b9a\u8def\u5f84\u70b9\u7684\u5f71\u54cd\u3002", "result": "\u5728\u5177\u6709\u4e25\u91cd\u6742\u4e71\u548c\u62d3\u6251\u590d\u6742\u6027\u7684\u6311\u6218\u6027\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0cMMP - A*\u5b9e\u73b0\u4e86\u8fd1\u6700\u4f18\u8f68\u8ff9\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\u3002", "conclusion": "MMP - A*\u6709\u6f5c\u529b\u6210\u4e3a\u57fa\u4e8e\u611f\u77e5\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u81ea\u4e3b\u5bfc\u822a\u8303\u5f0f\u3002"}}
{"id": "2601.01939", "pdf": "https://arxiv.org/pdf/2601.01939", "abs": "https://arxiv.org/abs/2601.01939", "authors": ["Victor Sanchez", "Chris Reinke", "Ahamed Mohamed", "Xavier Alameda-Pineda"], "title": "OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation", "categories": ["cs.AI"], "comment": null, "summary": "In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.", "AI": {"tldr": "\u4ecb\u7ecd\u5f00\u6e90\u8f6f\u4ef6\u5305OpenSocInt\uff0c\u542b\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u6a21\u62df\u5668\u548c\u8bad\u7ec3\u793e\u4ea4\u667a\u80fd\u4f53\u7684\u6a21\u5757\u5316\u67b6\u6784\uff0c\u901a\u8fc7\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u5b9e\u9a8c\u5c55\u793a\u5176\u4ef7\u503c\uff0c\u8f6f\u4ef6\u5df2\u516c\u5f00\u3002", "motivation": "\u63d0\u4f9b\u4e00\u4e2a\u7528\u4e8e\u591a\u6a21\u6001\u793e\u4ea4\u4ea4\u4e92\u6a21\u62df\u548c\u8bad\u7ec3\u793e\u4ea4\u667a\u80fd\u4f53\u7684\u5f00\u6e90\u5de5\u5177\u3002", "method": "\u63cf\u8ff0\u8f6f\u4ef6\u5305\u5e76\u57fa\u4e8e\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5c55\u793a\u4e86\u8f6f\u4ef6\u5305\u5728\u793e\u4ea4\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u5f00\u53d1\u7684OpenSocInt\u8f6f\u4ef6\u5305\u53ef\u7528\u4e8e\u63a2\u7d22\u4e0d\u540c\u611f\u77e5\u7279\u5f81\u3001\u7f16\u7801\u3001\u878d\u5408\u53ca\u4e0d\u540c\u667a\u80fd\u4f53\u7684\u4f7f\u7528\uff0c\u4e14\u5df2\u516c\u5f00\u4f9b\u4f7f\u7528\u3002"}}
{"id": "2601.01976", "pdf": "https://arxiv.org/pdf/2601.01976", "abs": "https://arxiv.org/abs/2601.01976", "authors": ["Yasmine Souissi", "Fabrice Boissier", "Nida Meddouri"], "title": "CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes", "categories": ["cs.AI"], "comment": null, "summary": "Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u63d0\u51fa\u6784\u5efa\u90e8\u5206\u6982\u5ff5\u683c\u7684\u65b0\u65b9\u6cd5\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u7387\u3002", "motivation": "\u77e5\u8bc6\u53d1\u73b0\u6570\u636e\u5e93\u65e8\u5728\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u77e5\u8bc6\uff0cFCA\u662f\u53ef\u89e3\u91ca\u5b66\u4e60\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u672c\u6587\u65e8\u5728\u5bf9\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\u5e76\u63d0\u51fa\u65b0\u65b9\u6cd5\u3002", "method": "\u56de\u987e\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\uff0c\u63a2\u7d22\u4ece\u540d\u4e49\u6570\u636e\u8ba1\u7b97\u95ed\u5305\u8fd0\u7b97\u7b26\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u6784\u5efa\u5173\u6ce8\u6700\u76f8\u5173\u6982\u5ff5\u7684\u90e8\u5206\u6982\u5ff5\u683c\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u6784\u5efa\u90e8\u5206\u6982\u5ff5\u683c\u7684\u65b0\u65b9\u6cd5\u5728\u57fa\u4e8eFCA\u7684\u5206\u7c7b\u5668\u4e2d\u6709\u8f83\u597d\u7684\u6548\u7387\u3002"}}
{"id": "2601.01982", "pdf": "https://arxiv.org/pdf/2601.01982", "abs": "https://arxiv.org/abs/2601.01982", "authors": ["Noel Thomas"], "title": "ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems", "categories": ["cs.AI"], "comment": "7 pages, 0 figures , Accepted to AAAI-26 Bridge Program: Logical and Symbolic Reasoning in Language Models (camera-ready)", "summary": "Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.", "AI": {"tldr": "\u4ecb\u7ecdChaosBench - Logic\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u524d\u6cbfLLMs\u867d\u6709\u4e00\u5b9a\u5355\u9898\u51c6\u786e\u7387\uff0c\u4f46\u7ec4\u5408\u9898\u8868\u73b0\u5dee\u4e14\u5168\u5c40\u8fde\u8d2f\u6027\u5f31\uff0c\u8be5\u57fa\u51c6\u53ef\u8bca\u65ad\u95ee\u9898\u548c\u652f\u6301\u5f00\u53d1\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u903b\u8f91\u548c\u7b26\u53f7\u63a8\u7406\u7684\u9886\u57df\u8f83\u8106\u5f31\uff0c\u6df7\u6c8c\u52a8\u529b\u7cfb\u7edf\u662f\u4e25\u82db\u6d4b\u8bd5\uff0c\u56e0\u6b64\u9700\u8bc4\u4f30\u6a21\u578b\u5728\u5176\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165ChaosBench - Logic\u57fa\u51c6\uff0c\u4f7f\u7528\u7edf\u4e00\u7684\u4e00\u9636\u903b\u8f91\u672c\u4f53\u8bc4\u4f3030\u79cd\u4e0d\u540c\u52a8\u529b\u7cfb\u7edf\u7684LLM\u63a8\u7406\uff0c\u6807\u6ce8\u6bcf\u4e2a\u7cfb\u7edf\u8bed\u4e49\u8c13\u8bcd\u771f\u503c\uff0c\u751f\u62107\u7c7b621\u4e2a\u95ee\u9898\uff0c\u5b9a\u4e49\u591a\u9879\u8bc4\u4f30\u6307\u6807\u5e76\u53d1\u5e03\u5f00\u6e90\u8bc4\u4f30\u7ba1\u9053\u3002", "result": "\u524d\u6cbfLLMs\u5355\u9898\u51c6\u786e\u738791 - 94%\uff0c\u7ec4\u5408\u98980%\u51c6\u786e\u7387\uff0c\u5168\u5c40\u8fde\u8d2f\u6027\u5dee\uff0c\u5bf9\u8bdd\u7ea7\u51c6\u786e\u738753.1%\uff08GPT - 4 CoT\uff09\u523075.5%\uff08LLaMA - 3\u96f6\u6837\u672c\uff09\u3002", "conclusion": "ChaosBench - Logic\u4e3a\u8bca\u65adLLMs\u7684\u63a8\u7406\u5931\u8d25\u63d0\u4f9b\u4e25\u683c\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4e5f\u4e3a\u5f00\u53d1\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u63d0\u5347\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2601.01993", "pdf": "https://arxiv.org/pdf/2601.01993", "abs": "https://arxiv.org/abs/2601.01993", "authors": ["Dong Xue", "Jicheng Tu", "Ming Wang", "Xin Yan", "Fangzhou Liu", "Jie Hu"], "title": "MindChat: A Privacy-preserving Large Language Model for Mental Health Support", "categories": ["cs.AI"], "comment": "33 pages, 16 figures", "summary": "Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u7684\u9690\u79c1\u4fdd\u62a4\u5927\u8bed\u8a00\u6a21\u578bMindChat\u548c\u5408\u6210\u6570\u636e\u96c6MindCorpus\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6709\u6548\u4e14\u6709\u7ade\u4e89\u529b\uff0c\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u4f4e\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u65f6\uff0c\u8bad\u7ec3\u53d7\u771f\u5b9e\u54a8\u8be2\u5bf9\u8bdd\u7a00\u7f3a\u548c\u654f\u611f\u7684\u9650\u5236\u3002", "method": "\u6784\u5efa\u591a\u667a\u80fd\u4f53\u89d2\u8272\u626e\u6f14\u6846\u67b6\u751f\u6210\u5408\u6210\u6570\u636e\u96c6MindCorpus\uff1b\u4f7f\u7528\u5e26\u53c2\u6570\u9ad8\u6548LoRA\u9002\u914d\u5668\u7684\u8054\u90a6\u5b66\u4e60\u5fae\u8c03\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u5dee\u5206\u9690\u79c1\u4f18\u5316\u3002", "result": "MindCorpus\u63d0\u9ad8\u8bad\u7ec3\u6709\u6548\u6027\uff0cMindChat\u5728\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u4e0e\u73b0\u6709\u57fa\u7ebf\u6709\u7ade\u4e89\u529b\uff0c\u4e14\u5728\u6210\u5458\u63a8\u7406\u653b\u51fb\u4e0b\u9690\u79c1\u6cc4\u9732\u51cf\u5c11\u3002", "conclusion": "MindChat\u548cMindCorpus\u5728\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u4e2d\u6709\u6548\u4e14\u80fd\u964d\u4f4e\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2601.02008", "pdf": "https://arxiv.org/pdf/2601.02008", "abs": "https://arxiv.org/abs/2601.02008", "authors": ["Midhat Urooj", "Ayan Banerjee", "Sandeep Gupta"], "title": "XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging", "categories": ["cs.AI", "cs.CV"], "comment": "Accepted at AAAI Bridge Program 2026", "summary": "Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faXAIMeD\u533b\u7597AI\u6846\u67b6\uff0c\u5c06\u4e34\u5e8a\u77e5\u8bc6\u878d\u5165\u6df1\u5ea6\u5b66\u4e60\uff0c\u7ecf\u591a\u4efb\u52a1\u8bc4\u4f30\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u591a\u6a21\u6001\u533b\u7597AI\u63d0\u4f9b\u53ef\u9760\u53ef\u89e3\u91ca\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u533b\u5b66AI\u5728\u53ef\u89e3\u91ca\u6027\u3001\u9886\u57df\u6cdb\u5316\u548c\u7f55\u89c1\u7c7b\u53ef\u9760\u6027\u65b9\u9762\uff0c\u6a21\u578b\u6613\u53d7\u5206\u5e03\u504f\u79fb\u5f71\u54cd\u4e14\u5bf9\u7f55\u89c1\u4e34\u5e8a\u60c5\u51b5\u6709\u504f\u89c1\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u7edf\u4e00\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u5c06\u4e34\u5e8a\u4e13\u4e1a\u77e5\u8bc6\u7f16\u7801\u4e3a\u903b\u8f91\u8fde\u63a5\u8bcd\uff0c\u8ba1\u7b97\u8bca\u65ad\u6548\u7528\u5f97\u5206\uff0c\u7528\u52a0\u6743\u878d\u5408\u96c6\u6210\u7b26\u53f7\u548c\u6df1\u5ea6\u8f93\u51fa\uff0c\u5229\u7528\u81ea\u9002\u5e94\u8def\u7531\u673a\u5236\u7f13\u89e3\u7c7b\u522b\u4e0d\u5e73\u8861\u7b49\u95ee\u9898\u3002", "result": "\u5728\u56db\u9879\u4efb\u52a1\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8de8\u9886\u57df\u6cdb\u5316\u63d0\u53476%\uff0c\u7f55\u89c1\u7c7bF1\u5206\u6570\u63d0\u9ad810%\uff0c\u8fdc\u8d85\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "XAIMeD\u4e3a\u591a\u6a21\u6001\u533b\u7597AI\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u3001\u4e34\u5e8a\u53ef\u4fe1\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.02043", "pdf": "https://arxiv.org/pdf/2601.02043", "abs": "https://arxiv.org/abs/2601.02043", "authors": ["Hendrik Kempt", "Alon Lavie"], "title": "Simulated Reasoning is Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "21 pages", "summary": "Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., \"symbolic reasoning\". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can \"reason\" by way of imitating the process of \"thinking out loud\", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the \"stochastic parrot\" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u57fa\u7840\u6a21\u578b\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u5bf9\u6bd4\u5176\u4e0e\u4eba\u7c7b\u63a8\u7406\u7684\u5dee\u5f02\uff0c\u63d0\u51fa\u54f2\u5b66\u89e3\u91ca\u5e76\u53cd\u601d\u5b89\u5168\u4e0e\u9002\u7528\u6027\u89c4\u8303\u3002", "motivation": "\u91cd\u65b0\u8bc4\u4f30\u63a8\u7406\u53ca\u5176\u5fc5\u8981\u6761\u4ef6\uff0c\u4e3a\u57fa\u7840\u6a21\u578b\u7684\u5b89\u5168\u548c\u9c81\u68d2\u9632\u5fa1\u63d0\u4f9b\u601d\u8def\u3002", "method": "\u901a\u8fc7\u5206\u6790\u57fa\u7840\u6a21\u578b\u63a8\u7406\u65b9\u5f0f\uff0c\u4e0e\u4eba\u7c7b\u63a8\u7406\u5bf9\u6bd4\uff0c\u63d0\u51fa\u54f2\u5b66\u89e3\u91ca\u3002", "result": "\u57fa\u7840\u6a21\u578b\u80fd\u4ee5\u4e0d\u540c\u4e8e\u4eba\u7c7b\u7684\u65b9\u5f0f\u63a8\u7406\uff0c\u4f46\u5b58\u5728\u7f3a\u4e4f\u57fa\u7840\u548c\u5e38\u8bc6\u5bfc\u81f4\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u5e94\u653e\u5f03\u201c\u968f\u673a\u9e66\u9e49\u201d\u9690\u55bb\uff0c\u53cd\u601d\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u548c\u9002\u7528\u6027\u89c4\u8303\u5143\u7d20\u3002"}}
{"id": "2601.02061", "pdf": "https://arxiv.org/pdf/2601.02061", "abs": "https://arxiv.org/abs/2601.02061", "authors": ["Faizan Ahmed", "Aniket Dixit", "James Brusey"], "title": "Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management", "categories": ["cs.AI", "cs.LG"], "comment": "6 pages, accepted at NeurIPS workshop 2025", "summary": "Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u9636\u5bfc\u6570\u60e9\u7f5a\u7684\u52a8\u4f5c\u5e73\u6ed1\u6b63\u5219\u5316\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u548c\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u4e2d\u9a8c\u8bc1\uff0c\u4e09\u9636\u5bfc\u6570\u60e9\u7f5a\u5728\u591a\u65b9\u9762\u8868\u73b0\u4f18\uff0c\u7528\u4e8eHVAC\u63a7\u5236\u6709\u663e\u8457\u6548\u76ca\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u9ad8\u9891\u63a7\u5236\u884c\u4e3a\u6709\u80fd\u8017\u548c\u673a\u68b0\u78e8\u635f\u95ee\u9898\uff0c\u963b\u788d\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u7cfb\u7edf\u6027\u7814\u7a76\u9ad8\u9636\u5bfc\u6570\u60e9\u7f5a\u7684\u52a8\u4f5c\u5e73\u6ed1\u6b63\u5219\u5316\uff0c\u5148\u5728\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u4e2d\u7406\u8bba\u7814\u7a76\uff0c\u518d\u5728\u5efa\u7b51\u80fd\u6e90\u7ba1\u7406\u4e2d\u5b9e\u8df5\u9a8c\u8bc1\u3002", "result": "\u5728\u56db\u4e2a\u8fde\u7eed\u63a7\u5236\u73af\u5883\u4e2d\uff0c\u4e09\u9636\u5bfc\u6570\u60e9\u7f5a\uff08\u6025\u52a8\u6700\u5c0f\u5316\uff09\u80fd\u5b9e\u73b0\u66f4\u597d\u5e73\u6ed1\u6027\u5e76\u4fdd\u6301\u7ade\u4e89\u529b\uff1b\u7528\u4e8eHVAC\u63a7\u5236\u7cfb\u7edf\uff0c\u5e73\u6ed1\u7b56\u7565\u4f7f\u8bbe\u5907\u5f00\u5173\u51cf\u5c1160%\u3002", "conclusion": "\u9ad8\u9636\u52a8\u4f5c\u6b63\u5219\u5316\u662f\u80fd\u6e90\u5173\u952e\u5e94\u7528\u4e2d\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u548c\u64cd\u4f5c\u7ea6\u675f\u95f4\u7684\u6709\u6548\u6865\u6881\u3002"}}
{"id": "2601.02071", "pdf": "https://arxiv.org/pdf/2601.02071", "abs": "https://arxiv.org/abs/2601.02071", "authors": ["Adeshola Okubena", "Yusuf Ali Mohammed", "Moe Elbadawi"], "title": "FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations", "categories": ["cs.AI"], "comment": null, "summary": "Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.", "AI": {"tldr": "\u7814\u7a76\u7528\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5236\u836f3D\u6253\u5370\u95ee\u9898\uff0c\u53d1\u73b0Llama2\u9002\u5408\u63a8\u8350\u8f85\u6599\uff0c\u6307\u51fa\u6a21\u578b\u5b58\u5728\u7684\u95ee\u9898\u53ca\u6311\u6218\u3002", "motivation": "\u73b0\u6709AI\u9a71\u52a8\u5236\u836f3D\u6253\u5370\u7814\u7a76\u8f83\u5c40\u9650\uff0c\u672a\u89e3\u51b3\u6280\u672f\u56fa\u6709\u914d\u65b9\u6311\u6218\uff0c\u5f15\u5165\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u3002", "method": "\u5728\u542b\u8d851400\u79cd\u914d\u65b9\u7684FDM\u6570\u636e\u96c6\u4e0a\u5fae\u8c034\u79cdLLM\u67b6\u6784\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5fae\u8c03\u4e0e\u751f\u6210\u53c2\u6570\u914d\u7f6e\u3002", "result": "Llama2\u6700\u9002\u5408\u63a8\u8350\u8f85\u6599\uff0c\u6a21\u578b\u9009\u62e9\u548c\u53c2\u6570\u5316\u5f71\u54cd\u6027\u80fd\uff0c\u5c0f\u6a21\u578b\u6709\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5c0f\u6570\u636e\u96c6\u4f1a\u81f4\u9057\u5fd8\uff0c\u6807\u51c6\u6307\u6807\u4e0d\u8bc4\u4f30\u53ef\u52a0\u5de5\u6027\uff0c\u751f\u7269\u533b\u5b66\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u7ed3\u679c\u4e0d\u4e00\u5b9a\u597d\u3002", "conclusion": "\u89e3\u51b3\u4e0a\u8ff0\u6311\u6218\u5bf9\u63a8\u52a8LLM\u7528\u4e8e\u5236\u836f\u914d\u65b9\u5f00\u53d1\u5f88\u91cd\u8981\u3002"}}
{"id": "2601.02163", "pdf": "https://arxiv.org/pdf/2601.02163", "abs": "https://arxiv.org/abs/2601.02163", "authors": ["Chuanrui Hu", "Xingze Gao", "Zuyi Zhou", "Dannong Xu", "Yi Bai", "Xintong Li", "Hui Zhang", "Tong Li", "Chong Zhang", "Lidong Bing", "Yafeng Deng"], "title": "EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "16 pages, 6 figures, 12 tables. Code available at https://github.com/EverMind-AI/EverMemOS", "summary": "Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u7ec4\u7ec7\u5185\u5b58\u64cd\u4f5c\u7cfb\u7edfEverMemOS\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u6709\u9650\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u73b0\u8fbeSOTA\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u6709\u9650\uff0c\u73b0\u6709\u5185\u5b58\u7cfb\u7edf\u96be\u4ee5\u6574\u5408\u7528\u6237\u72b6\u6001\u548c\u89e3\u51b3\u51b2\u7a81\u3002", "method": "\u5f15\u5165\u53d7\u8bb0\u5fc6\u75d5\u8ff9\u542f\u53d1\u7684\u8ba1\u7b97\u5185\u5b58\u751f\u547d\u5468\u671f\uff0c\u5305\u62ec\u60c5\u8282\u8ddf\u8e2a\u5f62\u6210\u3001\u8bed\u4e49\u6574\u5408\u548c\u91cd\u5efa\u56de\u5fc6\u3002", "result": "\u5728LoCoMo\u548cLongMemEval\u4e0a\u8fbeSOTA\uff0c\u6709\u7528\u6237\u753b\u50cf\u7b49\u9762\u5411\u804a\u5929\u7684\u80fd\u529b\u3002", "conclusion": "EverMemOS\u6709\u6548\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5b58\u76f8\u5173\u95ee\u9898\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2601.02170", "pdf": "https://arxiv.org/pdf/2601.02170", "abs": "https://arxiv.org/abs/2601.02170", "authors": ["Haolang Lu", "Minghui Pan", "Ripeng Li", "Guoshun Nan", "Jialin Zhuang", "Zijie Zhao", "Zhongxiang Sun", "Kun Wang", "Yang Liu"], "title": "Streaming Hallucination Detection in Long Chain-of-Thought Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u5e7b\u89c9\u89c6\u4e3a\u6f14\u5316\u6f5c\u6001\uff0c\u5f15\u5165\u7d2f\u79ef\u524d\u7f00\u7ea7\u5e7b\u89c9\u4fe1\u53f7\u5b9e\u73b0\u6d41\u5f0f\u5e7b\u89c9\u68c0\u6d4b\u3002", "motivation": "\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u5e7b\u89c9\u4f1a\u5fae\u5999\u51fa\u73b0\u5e76\u5728\u63a8\u7406\u6b65\u9aa4\u4e2d\u4f20\u64ad\uff0c\u9700\u66f4\u597d\u7406\u89e3\u548c\u68c0\u6d4b\u5e7b\u89c9\u3002", "method": "\u5c06\u6b65\u9aa4\u7ea7\u5e7b\u89c9\u5224\u65ad\u4f5c\u4e3a\u5c40\u90e8\u89c2\u5bdf\uff0c\u5f15\u5165\u7d2f\u79ef\u524d\u7f00\u7ea7\u5e7b\u89c9\u4fe1\u53f7\u8ffd\u8e2a\u63a8\u7406\u72b6\u6001\u7684\u5168\u5c40\u6f14\u5316\u3002", "result": "\u5b9e\u73b0\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4e2d\u7684\u6d41\u5f0f\u5e7b\u89c9\u68c0\u6d4b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u5b9e\u65f6\u3001\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u3002"}}
{"id": "2601.02314", "pdf": "https://arxiv.org/pdf/2601.02314", "abs": "https://arxiv.org/abs/2601.02314", "authors": ["Sourena Khanzadeh"], "title": "Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \\textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \\textbf{faithful} generative drivers of the model's output or merely \\textbf{post-hoc rationalizations}. We introduce \\textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \\textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \\textbf{Causal Sensitivity} ($\u03c6$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \\textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \\textbf{Causal Decoupling}, where agents exhibit a violation density ($\u03c1$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as \"Reasoning Theater\" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.", "AI": {"tldr": "\u5f15\u5165Project Ariadne\u6846\u67b6\u5ba1\u8ba1\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u56e0\u679c\u5b8c\u6574\u6027\uff0c\u53d1\u73b0\u5fe0\u5b9e\u6027\u5dee\u8ddd\u548c\u56e0\u679c\u89e3\u8026\u95ee\u9898\uff0c\u63d0\u51faAriadne\u5206\u6570\u4f5c\u4e3a\u65b0\u57fa\u51c6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u4e3b\u51b3\u7b56\u65f6\u63a8\u7406\u8fc7\u7a0b\u900f\u660e\u5ea6\u6210\u5b89\u5168\u95ee\u9898\uff0c\u9700\u660e\u786e\u63a8\u7406\u75d5\u8ff9\u662f\u771f\u5b9e\u9a71\u52a8\u8fd8\u662f\u4e8b\u540e\u5408\u7406\u5316\u3002", "method": "\u5229\u7528\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u53cd\u4e8b\u5b9e\u903b\u8f91\uff0c\u5bf9\u4e2d\u95f4\u63a8\u7406\u8282\u70b9\u8fdb\u884c\u786c\u5e72\u9884\u6765\u6d4b\u91cf\u7ec8\u7aef\u7b54\u6848\u7684\u56e0\u679c\u654f\u611f\u6027\u3002", "result": "\u53d1\u73b0\u5fe0\u5b9e\u6027\u5dee\u8ddd\uff0c\u68c0\u6d4b\u5230\u56e0\u679c\u89e3\u8026\u5931\u6548\u6a21\u5f0f\uff0c\u90e8\u5206\u9886\u57df\u8fdd\u89c4\u5bc6\u5ea6\u8fbe0.77\uff0c\u51b3\u7b56\u53d7\u6f5c\u5728\u53c2\u6570\u5148\u9a8c\u5f71\u54cd\u3002", "conclusion": "\u5f53\u524d\u4ee3\u7406\u67b6\u6784\u6613\u4ea7\u751f\u4e0d\u5fe0\u5b9e\u89e3\u91ca\uff0cAriadne\u5206\u6570\u53ef\u4f5c\u4e3a\u903b\u8f91\u4e0e\u884c\u52a8\u5bf9\u9f50\u7684\u65b0\u57fa\u51c6\u3002"}}
{"id": "2601.02346", "pdf": "https://arxiv.org/pdf/2601.02346", "abs": "https://arxiv.org/abs/2601.02346", "authors": ["Falcon LLM Team", "Iheb Chaabane", "Puneesh Khanna", "Suhail Mohmad", "Slim Frikha", "Shi Hu", "Abdalgader Abubaker", "Reda Alami", "Mikhail Lubinets", "Mohamed El Amine Seddik", "Hakim Hacid"], "title": "Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling", "categories": ["cs.AI"], "comment": null, "summary": "This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\\times$ to $7\\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u63a8\u7406\u4f18\u5316\u6a21\u578bFalcon - H1R\uff0c\u5c55\u793a\u5c0f\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u63a8\u7406\u6027\u80fd\u7684\u53ef\u884c\u6027\uff0c\u8be5\u6a21\u578b\u53c2\u6570\u9ad8\u6548\uff0c\u63a8\u7406\u6548\u7387\u6709\u63d0\u5347\uff0c\u501f\u52a9DeepConf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u7387\u7684SOTA\u3002", "motivation": "\u63a2\u7d22\u5c0f\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u63a8\u7406\u6027\u80fd\u7684\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u7cbe\u5fc3\u7684\u6570\u636e\u6574\u7406\u3001\u6709\u9488\u5bf9\u6027\u7684\u8bad\u7ec3\u7b56\u7565\uff08\u9ad8\u6548SFT\u548cRL\u6269\u5c55\uff09\u3001\u6df7\u5408\u5e76\u884c\u67b6\u6784\u8bbe\u8ba1\uff0c\u5229\u7528DeepConf\u65b9\u6cd5\u3002", "result": "Falcon - H1R\u5728\u591a\u79cd\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u66f4\u5927\u7684SOTA\u63a8\u7406\u6a21\u578b\uff0c\u5b9e\u73b0\u66f4\u5feb\u63a8\u7406\u3001\u66f4\u9ad8\u6807\u8bb0\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u8fbe\u5230\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u7387\u7684SOTA\u3002", "conclusion": "\u7d27\u51d1\u6a21\u578b\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u6a21\u578b\u8bad\u7ec3\u548c\u67b6\u6784\u9009\u62e9\uff0c\u53ef\u5b9e\u73b0\u5f3a\u5927\u4e14\u53ef\u6269\u5c55\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2601.00797", "pdf": "https://arxiv.org/pdf/2601.00797", "abs": "https://arxiv.org/abs/2601.00797", "authors": ["Hugues Draelants"], "title": "The Qualitative Laboratory: Theory Prototyping and Hypothesis Generation with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": "26 pages, 3 tables. Manuscript submitted for peer-reviewed journal publication", "summary": "A central challenge in social science is to generate rich qualitative hypotheses about how diverse social groups might interpret new information. This article introduces and illustrates a novel methodological approach for this purpose: sociological persona simulation using Large Language Models (LLMs), which we frame as a \"qualitative laboratory\". We argue that for this specific task, persona simulation offers a distinct advantage over established methods. By generating naturalistic discourse, it overcomes the lack of discursive depth common in vignette surveys, and by operationalizing complex worldviews through natural language, it bypasses the formalization bottleneck of rule-based agent-based models (ABMs). To demonstrate this potential, we present a protocol where personas derived from a sociological theory of climate reception react to policy messages. The simulation produced nuanced and counter-intuitive hypotheses - such as a conservative persona's rejection of a national security frame - that challenge theoretical assumptions. We conclude that this method, used as part of a \"simulation then validation\" workflow, represents a superior tool for generating deeply textured hypotheses for subsequent empirical testing.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u793e\u4f1a\u5b66\u4eba\u7269\u89d2\u8272\u6a21\u62df\u7684\u65b0\u65b9\u6cd5\u751f\u6210\u5b9a\u6027\u5047\u8bbe\uff0c\u4ee5\u6c14\u5019\u653f\u7b56\u4e3a\u4f8b\u5c55\u793a\u5176\u6f5c\u529b\u5e76\u5f97\u51fa\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u540e\u7eed\u5b9e\u8bc1\u68c0\u9a8c\u7684\u7ed3\u8bba\u3002", "motivation": "\u793e\u4f1a\u79d1\u5b66\u9762\u4e34\u4e3a\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u89e3\u8bfb\u65b0\u4fe1\u606f\u751f\u6210\u4e30\u5bcc\u5b9a\u6027\u5047\u8bbe\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u793e\u4f1a\u5b66\u4eba\u7269\u89d2\u8272\u6a21\u62df\uff0c\u6784\u5efa\u201c\u5b9a\u6027\u5b9e\u9a8c\u5ba4\u201d\u3002", "result": "\u4ee5\u6c14\u5019\u653f\u7b56\u4e3a\u4f8b\u7684\u6a21\u62df\u4ea7\u751f\u4e86\u7ec6\u81f4\u4e14\u53cd\u76f4\u89c9\u7684\u5047\u8bbe\uff0c\u6311\u6218\u4e86\u7406\u8bba\u5047\u8bbe\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u201c\u5148\u6a21\u62df\u540e\u9a8c\u8bc1\u201d\u5de5\u4f5c\u6d41\u7a0b\u7684\u4e00\u90e8\u5206\uff0c\u662f\u751f\u6210\u540e\u7eed\u5b9e\u8bc1\u68c0\u9a8c\u5047\u8bbe\u7684\u66f4\u597d\u5de5\u5177\u3002"}}
{"id": "2601.00809", "pdf": "https://arxiv.org/pdf/2601.00809", "abs": "https://arxiv.org/abs/2601.00809", "authors": ["Tobias Heimig-Elschner", "Changyu Du", "Anna Scheuvens", "Andr\u00e9 Borrmann", "Jakob Beetz"], "title": "A Modular Reference Architecture for MCP-Servers Enabling Agentic BIM Interaction", "categories": ["cs.OH", "cs.AI", "cs.MA"], "comment": "Submitted to the GNI Symposium on Artificial Intelligence for the Built World (Technical University of Munich, May 18--20, 2026)", "summary": "Agentic workflows driven by large language models (LLMs) are increasingly applied to Building Information Modelling (BIM), enabling natural-language retrieval, modification and generation of IFC models. Recent work has begun adopting the emerging Model Context Protocol (MCP) as a uniform tool-calling interface for LLMs, simplifying the agent side of BIM interaction. While MCP standardises how LLMs invoke tools, current BIM-side implementations are still authoring tool-specific and ad hoc, limiting reuse, evaluation, and workflow portability across environments. This paper addresses this gap by introducing a modular reference architecture for MCP servers that enables API-agnostic, isolated and reproducible agentic BIM interactions. From a systematic analysis of recurring capabilities in recent literature, we derive a core set of requirements. These inform a microservice architecture centred on an explicit adapter contract that decouples the MCP interface from specific BIM-APIs. A prototype implementation using IfcOpenShell demonstrates feasibility across common modification and generation tasks. Evaluation across representative scenarios shows that the architecture enables reliable workflows, reduces coupling, and provides a reusable foundation for systematic research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u7528\u4e8eMCP\u670d\u52a1\u5668\u7684\u6a21\u5757\u5316\u53c2\u8003\u67b6\u6784\uff0c\u4ee5\u5b9e\u73b0API\u65e0\u5173\u3001\u53ef\u9694\u79bb\u548c\u53ef\u91cd\u73b0\u7684\u4ee3\u7406\u5f0fBIM\u4ea4\u4e92\uff0c\u5e76\u7528\u539f\u578b\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u548c\u4f18\u52bf\u3002", "motivation": "\u5f53\u524dBIM\u7aefMCP\u5b9e\u73b0\u7279\u5b9a\u4e8e\u521b\u4f5c\u5de5\u5177\u4e14\u7f3a\u4e4f\u89c4\u8303\u6027\uff0c\u9650\u5236\u4e86\u91cd\u7528\u3001\u8bc4\u4f30\u548c\u8de8\u73af\u5883\u5de5\u4f5c\u6d41\u7684\u53ef\u79fb\u690d\u6027\u3002", "method": "\u4ece\u5bf9\u8fd1\u671f\u6587\u732e\u4e2d\u91cd\u590d\u80fd\u529b\u7684\u7cfb\u7edf\u5206\u6790\u5f97\u51fa\u6838\u5fc3\u9700\u6c42\uff0c\u8bbe\u8ba1\u4ee5\u663e\u5f0f\u9002\u914d\u5668\u5951\u7ea6\u4e3a\u4e2d\u5fc3\u7684\u5fae\u670d\u52a1\u67b6\u6784\uff0c\u5c06MCP\u63a5\u53e3\u4e0e\u7279\u5b9aBIM - API\u89e3\u8026\u3002", "result": "\u4f7f\u7528IfcOpenShell\u7684\u539f\u578b\u5b9e\u73b0\u8bc1\u660e\u4e86\u5728\u5e38\u89c1\u4fee\u6539\u548c\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u8bc4\u4f30\u663e\u793a\u8be5\u67b6\u6784\u80fd\u5b9e\u73b0\u53ef\u9760\u5de5\u4f5c\u6d41\u3001\u51cf\u5c11\u8026\u5408\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e3a\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u57fa\u7840\u3002"}}
{"id": "2601.00812", "pdf": "https://arxiv.org/pdf/2601.00812", "abs": "https://arxiv.org/abs/2601.00812", "authors": ["Takashi Ushio", "Kazuhiro Onishi", "Hideyoshi Yanagisawa"], "title": "Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements", "categories": ["cs.CV", "cs.AI"], "comment": "This article has been accepted for publication in IEEE Access and will be published shortly", "summary": "Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified \"pleasantness,\" \"surprise,\" and \"habituation\" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected \"pleasantness\" associated with brand presentation, BS has captured \"surprise\" arising from informational complexity, and UN has reflected \"surprise\" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u81ea\u7531\u80fd\u91cf\u539f\u7406\uff0c\u4ec5\u4ece\u5e7f\u544a\u89c6\u9891\u573a\u666f\u7ea7\u8868\u8fbe\u7279\u5f81\u91cf\u5316\u60c5\u611f\uff0c\u5206\u6790\u60c5\u611f\u6a21\u5f0f\uff0c\u7ed3\u679c\u7a33\u5b9a\uff0c\u6709\u671b\u52a9\u529b\u5236\u4f5c\u66f4\u6709\u5438\u5f15\u529b\u5e7f\u544a\u3002", "motivation": "\u5efa\u7acb\u65e0\u9700\u5916\u90e8\u4fe1\u606f\u7684\u53ef\u89e3\u91ca\u60c5\u611f\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7406\u89e3\u5e7f\u544a\u89c6\u9891\u89c2\u770b\u65f6\u7684\u60c5\u611f\u53cd\u5e94\u5bf9\u5a92\u4f53\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u81ea\u7531\u80fd\u91cf\u539f\u7406\uff0c\u5229\u7528Kullback - Leibler\u6563\u5ea6\u3001\u8d1d\u53f6\u65af\u60ca\u559c\u548c\u4e0d\u786e\u5b9a\u6027\u7b49\u6982\u5ff5\uff0c\u4ece\u5e7f\u544a\u89c6\u9891\u573a\u666f\u7ea7\u8868\u8fbe\u7279\u5f81\u91cf\u5316\u2018\u6109\u60a6\u5ea6\u2019\u2018\u60ca\u559c\u611f\u2019\u548c\u2018\u4e60\u60ef\u5316\u2019\u3002", "result": "KLD\u53cd\u6620\u54c1\u724c\u5448\u73b0\u7684\u2018\u6109\u60a6\u5ea6\u2019\uff0cBS\u6355\u6349\u4fe1\u606f\u590d\u6742\u6027\u5e26\u6765\u7684\u2018\u60ca\u559c\u611f\u2019\uff0cUN\u53cd\u6620\u5143\u7d20\u4e0d\u786e\u5b9a\u6027\u7b49\u5e26\u6765\u7684\u2018\u60ca\u559c\u611f\u2019\uff0c\u8bc6\u522b\u51fa\u4e09\u79cd\u60c5\u611f\u6a21\u5f0f\uff0c\u7ed3\u679c\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u7528\uff0c\u53ef\u901a\u8fc7\u6574\u5408\u66f4\u591a\u8868\u8fbe\u5143\u7d20\u548c\u4e3b\u89c2\u8bc4\u7ea7\u6269\u5c55\u7814\u7a76\uff0c\u4e3a\u5236\u4f5c\u66f4\u5438\u5f15\u4eba\u7684\u5e7f\u544a\u89c6\u9891\u63d0\u4f9b\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2601.00827", "pdf": "https://arxiv.org/pdf/2601.00827", "abs": "https://arxiv.org/abs/2601.00827", "authors": ["Mariam Saeed", "Manar Amr", "Farida Adel", "Nada Hassan", "Nour Walid", "Eman Mohamed", "Mohamed Hussein", "Marwan Torki"], "title": "Speak the Art: A Direct Speech to Image Generation Framework", "categories": ["eess.AS", "cs.AI", "cs.MM"], "comment": null, "summary": "Direct speech-to-image generation has recently shown promising results. However, compared to text-to-image generation, there is still a large gap to enclose. Current approaches use two stages to tackle this task: speech encoding network and image generative adversarial network (GAN). The speech encoding networks in these approaches produce embeddings that do not capture sufficient linguistic information to semantically represent the input speech. GANs suffer from issues such as non-convergence, mode collapse, and diminished gradient, which result in unstable model parameters, limited sample diversity, and ineffective generator learning, respectively. To address these weaknesses, we introduce a framework called \\textbf{Speak the Art (STA)} which consists of a speech encoding network and a VQ-Diffusion network conditioned on speech embeddings. To improve speech embeddings, the speech encoding network is supervised by a large pre-trained image-text model during training. Replacing GANs with diffusion leads to more stable training and the generation of diverse images. Additionally, we investigate the feasibility of extending our framework to be multilingual. As a proof of concept, we trained our framework with two languages: English and Arabic. Finally, we show that our results surpass state-of-the-art models by a large margin.", "AI": {"tldr": "\u73b0\u6709\u8bed\u97f3\u8f6c\u56fe\u50cf\u65b9\u6cd5\u6709\u4e0d\u8db3\uff0c\u63d0\u51faSpeak the Art (STA)\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u97f3\u7f16\u7801\u7f51\u7edc\u548cVQ - Diffusion\u7f51\u7edc\uff0c\u8bad\u7ec3\u65f6\u7528\u5927\u6a21\u578b\u76d1\u7763\uff0c\u7ed3\u679c\u8d85\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u8f6c\u56fe\u50cf\u65b9\u6cd5\u6709\u5dee\u8ddd\uff0c\u8bed\u97f3\u7f16\u7801\u7f51\u7edc\u4fe1\u606f\u4e0d\u8db3\uff0cGAN\u5b58\u5728\u4e0d\u6536\u655b\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165STA\u6846\u67b6\uff0c\u5305\u62ec\u8bed\u97f3\u7f16\u7801\u7f51\u7edc\u548cVQ - Diffusion\u7f51\u7edc\uff0c\u8bad\u7ec3\u65f6\u8bed\u97f3\u7f16\u7801\u7f51\u7edc\u53d7\u5927\u9884\u8bad\u7ec3\u56fe\u6587\u6a21\u578b\u76d1\u7763\uff0c\u7528\u6269\u6563\u6a21\u578b\u66ff\u4ee3GAN\uff0c\u63a2\u7d22\u591a\u8bed\u8a00\u6269\u5c55\u5e76\u8fdb\u884c\u82f1\u963f\u53cc\u8bed\u8bad\u7ec3\u3002", "result": "\u7ed3\u679c\u5927\u5e45\u8d85\u8d8a\u4e86\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684STA\u6846\u67b6\u5728\u8bed\u97f3\u8f6c\u56fe\u50cf\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u751f\u6210\u66f4\u4f18\u56fe\u50cf\uff0c\u6709\u6269\u5c55\u5230\u591a\u8bed\u8a00\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.00834", "pdf": "https://arxiv.org/pdf/2601.00834", "abs": "https://arxiv.org/abs/2601.00834", "authors": ["Julian Evan Chrisnanto", "Salsabila Rahma Alia", "Nurfauzi Fadillah", "Yulison Herry Chrisnanto"], "title": "Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 7 figures", "summary": "Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a \"Stochastic Cloth\" manifold with extreme Gaussian curvature fluctuations ($K \\in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the \"splitting spot\" and \"labyrinthine\" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\\mathcal{E}_{mass} \\approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u65e0\u7f51\u683c\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6IM - PINN\u7528\u4e8e\u6a21\u62df\u590d\u6742\u6d41\u5f62\u4e0a\u7684\u975e\u7ebf\u6027\u53cd\u5e94 - \u6269\u6563\u52a8\u529b\u5b66\uff0c\u5728\u6781\u7aef\u9ad8\u65af\u66f2\u7387\u6d41\u5f62\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u5bf9\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6709\u66f4\u597d\u8868\u73b0\u3002", "motivation": "\u6a21\u62df\u590d\u6742\u975e\u6b27\u51e0\u91cc\u5f97\u6d41\u5f62\u4e0a\u7684\u975e\u7ebf\u6027\u53cd\u5e94 - \u6269\u6563\u52a8\u529b\u5b66\u5b58\u5728\u6311\u6218\uff0c\u53d7\u9650\u4e8e\u9ad8\u4fdd\u771f\u7f51\u683c\u751f\u6210\u6210\u672c\u548c\u79bb\u6563\u65f6\u95f4\u6b65\u957f\u65b9\u6848\u7684\u8f9b\u6f02\u79fb\u3002", "method": "\u5f15\u5165IM - PINN\u6846\u67b6\uff0c\u5c06\u9ece\u66fc\u5ea6\u91cf\u5f20\u91cf\u5d4c\u5165\u81ea\u52a8\u5fae\u5206\u56fe\uff0c\u89e3\u6790\u91cd\u6784\u62c9\u666e\u62c9\u65af - \u8d1d\u5c14\u7279\u62c9\u7c73\u7b97\u5b50\uff0c\u4f7f\u7528\u5e26\u5085\u91cc\u53f6\u7279\u5f81\u5d4c\u5165\u7684\u53cc\u6d41\u67b6\u6784\u51cf\u8f7b\u8c31\u504f\u5dee\u3002", "result": "\u5728\u6781\u7aef\u9ad8\u65af\u66f2\u7387\u6ce2\u52a8\u7684\u201c\u968f\u673a\u5e03\u6599\u201d\u6d41\u5f62\u4e0a\u9a8c\u8bc1\uff0c\u6062\u590d\u4e86Gray - Scott\u6a21\u578b\u7684\u201c\u5206\u88c2\u6591\u201d\u548c\u201c\u8ff7\u5bab\u201d\u72b6\u6001\uff0c\u8d28\u91cf\u5b88\u6052\u8bef\u5dee\u5c0f\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6a21\u62df\u6f14\u5316\u8868\u9762\u4e0a\u7684\u751f\u7269\u6a21\u5f0f\u5f62\u6210\u63d0\u4f9b\u5185\u5b58\u9ad8\u6548\u3001\u5206\u8fa8\u7387\u65e0\u5173\u7684\u8303\u5f0f\uff0c\u8fde\u63a5\u4e86\u5fae\u5206\u51e0\u4f55\u548c\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u3002"}}
{"id": "2601.00837", "pdf": "https://arxiv.org/pdf/2601.00837", "abs": "https://arxiv.org/abs/2601.00837", "authors": ["Agniv Roy Choudhury"], "title": "Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.\n  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.\n  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.\n  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\\% accuracy, 99.61\\% F1-score, and 99.93\\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.\n  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.\n  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4ece\u5934\u8bad\u7ec3\u7684\u81ea\u5b9a\u4e49CNN\u548c\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u7684\u6a21\u578b\uff08ResNet50\u3001DenseNet121\u3001EfficientNet - B0\uff09\u7528\u4e8e\u5c0f\u513f\u80ba\u708e\u68c0\u6d4b\uff0c\u53d1\u73b0\u5fae\u8c03\u7684ResNet50\u8868\u73b0\u6700\u4f73\uff0c\u8fc1\u79fb\u5b66\u4e60\u5fae\u8c03\u6cd5\u8fdc\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684CNN\uff0c\u8be5\u7cfb\u7edf\u6709\u671b\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u5730\u533a\u7b5b\u67e5\u3002", "motivation": "\u80ba\u708e\u662f\u4e94\u5c81\u4ee5\u4e0b\u513f\u7ae5\u4e3b\u8981\u6b7b\u56e0\u4e4b\u4e00\uff0c\u80f8\u7247\u51c6\u786e\u8bca\u65ad\u53d7\u653e\u5c04\u79d1\u533b\u751f\u6570\u91cf\u548c\u8bca\u65ad\u5dee\u5f02\u9650\u5236\uff0c\u9700\u66f4\u6709\u6548\u7684\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u4f7f\u75285216\u5f20\u5c0f\u513f\u80f8\u7247\u6570\u636e\u96c6\uff0c\u630980/10/10\u5212\u5206\u8bad\u7ec3\u3001\u9a8c\u8bc1\u548c\u6d4b\u8bd5\u96c6\uff0c\u8bad\u7ec3\u4e03\u4e2a\u6a21\u578b\uff0c\u7528\u51c6\u786e\u7387\u3001F1\u5206\u6570\u548cAUC\u8bc4\u4f30\uff0c\u7528Grad - CAM\u53ef\u89c6\u5316\u89e3\u91ca\u3002", "result": "\u5fae\u8c03\u7684ResNet50\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u738799.43%\uff0cF1\u5206\u657099.61%\uff0cAUC 99.93%\uff0c\u4ec53\u4f8b\u8bef\u5206\u7c7b\uff0c\u5fae\u8c03\u5e73\u5747\u6bd4\u51bb\u7ed3\u9aa8\u5e72\u6a21\u578b\u9ad85.5\u4e2a\u767e\u5206\u70b9\uff0cGrad - CAM\u8bc1\u5b9e\u9884\u6d4b\u53d7\u4e34\u5e8a\u76f8\u5173\u80ba\u90e8\u533a\u57df\u5f15\u5bfc\u3002", "conclusion": "\u8fc1\u79fb\u5b66\u4e60\u5fae\u8c03\u6cd5\u5728\u5c0f\u513f\u80ba\u708e\u68c0\u6d4b\u4e0a\u8fdc\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684CNN\uff0c\u51c6\u786e\u7387\u8fd1\u4e4e\u5b8c\u7f8e\uff0c\u6709\u671b\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u5730\u533a\u7b5b\u67e5\uff0c\u672a\u6765\u9700\u5728\u591a\u4e2d\u5fc3\u548c\u6210\u4eba\u6570\u636e\u96c6\u9a8c\u8bc1\u3002"}}
{"id": "2601.00840", "pdf": "https://arxiv.org/pdf/2601.00840", "abs": "https://arxiv.org/abs/2601.00840", "authors": ["Fabian Gr\u00f6ger", "Simone Lionetti", "Philippe Gottfrois", "Alvaro Gonzalez-Jimenez", "Lea Habermacher", "Labelling Consortium", "Ludovic Amruthalingam", "Matthew Groh", "Marc Pouly", "Alexander A. Navarini"], "title": "A Global Atlas of Digital Dermatology to Map Innovation and Disparities", "categories": ["cs.DL", "cs.AI", "cs.CV"], "comment": null, "summary": "The adoption of artificial intelligence in dermatology promises democratized access to healthcare, but model reliability depends on the quality and comprehensiveness of the data fueling these models. Despite rapid growth in publicly available dermatology images, the field lacks quantitative key performance indicators to measure whether new datasets expand clinical coverage or merely replicate what is already known. Here we present SkinMap, a multi-modal framework for the first comprehensive audit of the field's entire data basis. We unify the publicly available dermatology datasets into a single, queryable semantic atlas comprising more than 1.1 million images of skin conditions and quantify (i) informational novelty over time, (ii) dataset redundancy, and (iii) representation gaps across demographics and diagnoses. Despite exponential growth in dataset sizes, informational novelty across time has somewhat plateaued: Some clusters, such as common neoplasms on fair skin, are densely populated, while underrepresented skin types and many rare diseases remain unaddressed. We further identify structural gaps in coverage: Darker skin tones (Fitzpatrick V-VI) constitute only 5.8% of images and pediatric patients only 3.0%, while many rare diseases and phenotype combinations remain sparsely represented. SkinMap provides infrastructure to measure blind spots and steer strategic data acquisition toward undercovered regions of clinical space.", "AI": {"tldr": "\u63d0\u51faSkinMap\u6846\u67b6\u5bf9\u76ae\u80a4\u75c5\u9886\u57df\u6570\u636e\u8fdb\u884c\u5168\u9762\u5ba1\u8ba1\uff0c\u53d1\u73b0\u6570\u636e\u96c6\u867d\u589e\u957f\u4f46\u4fe1\u606f\u65b0\u9896\u6027\u8d8b\u7a33\uff0c\u5b58\u5728\u8986\u76d6\u7ed3\u6784\u7f3a\u53e3\uff0cSkinMap\u53ef\u52a9\u529b\u6570\u636e\u91c7\u96c6\u3002", "motivation": "\u76ae\u80a4\u75c5\u9886\u57df\u7f3a\u4e4f\u8861\u91cf\u65b0\u6570\u636e\u96c6\u662f\u5426\u62d3\u5c55\u4e34\u5e8a\u8986\u76d6\u8303\u56f4\u7684\u5b9a\u91cf\u6307\u6807\uff0c\u4eba\u5de5\u667a\u80fd\u5728\u76ae\u80a4\u75c5\u5b66\u4e2d\u7684\u5e94\u7528\u9700\u8981\u9ad8\u8d28\u91cf\u5168\u9762\u7684\u6570\u636e\u3002", "method": "\u63d0\u51faSkinMap\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5c06\u516c\u5f00\u76ae\u80a4\u75c5\u6570\u636e\u96c6\u7edf\u4e00\u6210\u53ef\u67e5\u8be2\u8bed\u4e49\u56fe\u8c31\uff0c\u91cf\u5316\u4fe1\u606f\u65b0\u9896\u6027\u3001\u6570\u636e\u96c6\u5197\u4f59\u5ea6\u548c\u4ee3\u8868\u6027\u7f3a\u53e3\u3002", "result": "\u6570\u636e\u96c6\u89c4\u6a21\u5448\u6307\u6570\u589e\u957f\uff0c\u4f46\u4fe1\u606f\u65b0\u9896\u6027\u6709\u6240\u505c\u6ede\uff0c\u90e8\u5206\u96c6\u7fa4\u6570\u636e\u5bc6\u96c6\uff0c\u6df1\u8272\u80a4\u8272\u3001\u513f\u79d1\u60a3\u8005\u53ca\u8bb8\u591a\u7f55\u89c1\u75c5\u6570\u636e\u4e0d\u8db3\u3002", "conclusion": "SkinMap\u80fd\u4e3a\u53d1\u73b0\u6570\u636e\u76f2\u70b9\u53ca\u5f15\u5bfc\u6218\u7565\u6570\u636e\u91c7\u96c6\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2601.00844", "pdf": "https://arxiv.org/pdf/2601.00844", "abs": "https://arxiv.org/abs/2601.00844", "authors": ["Matthieu Destrade", "Oumayma Bounou", "Quentin Le Lidec", "Jean Ponce", "Yann LeCun"], "title": "Value-guided action planning with JEPA world models", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Presented as a poster at the World Modeling Workshop 2026, Mila", "summary": "Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.", "AI": {"tldr": "\u63d0\u51fa\u589e\u5f3aJEPA\u4e16\u754c\u6a21\u578b\u89c4\u5212\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u5728\u7b80\u5355\u63a7\u5236\u4efb\u52a1\u4e0a\u63d0\u5347\u89c4\u5212\u6027\u80fd\u3002", "motivation": "JEPA\u652f\u6301\u6709\u6548\u884c\u52a8\u89c4\u5212\u7684\u80fd\u529b\u6709\u9650\uff0c\u9700\u589e\u5f3a\u5176\u89c4\u5212\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5851\u9020JEPA\u4e16\u754c\u6a21\u578b\u7684\u8868\u793a\u7a7a\u95f4\uff0c\u4f7f\u7ed9\u5b9a\u73af\u5883\u4e2d\u5230\u8fbe\u6210\u672c\u7684\u8d1f\u76ee\u6807\u6761\u4ef6\u4ef7\u503c\u51fd\u6570\u7531\u72b6\u6001\u5d4c\u5165\u4e4b\u95f4\u7684\u8ddd\u79bb\u8fd1\u4f3c\uff0c\u5e76\u5728\u8bad\u7ec3\u4e2d\u5b9e\u65bd\u8be5\u7ea6\u675f\u3002", "result": "\u5728\u7b80\u5355\u63a7\u5236\u4efb\u52a1\u4e0a\uff0c\u76f8\u6bd4\u6807\u51c6JEPA\u6a21\u578b\uff0c\u89c4\u5212\u6027\u80fd\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u589e\u5f3aJEPA\u4e16\u754c\u6a21\u578b\u7684\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2601.00853", "pdf": "https://arxiv.org/pdf/2601.00853", "abs": "https://arxiv.org/abs/2601.00853", "authors": ["Sameer Rahil", "Zain Abdullah Ahmad", "Talha Asif"], "title": "FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 27 figures", "summary": "Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \\textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.", "AI": {"tldr": "\u63d0\u51faFedSCAM\u7b97\u6cd5\uff0c\u57fa\u4e8e\u5ba2\u6237\u7aef\u5f02\u8d28\u6027\u5206\u6570\u52a8\u6001\u8c03\u6574SAM\u6270\u52a8\u534a\u5f84\u548c\u805a\u5408\u6743\u91cd\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u6536\u655b\u901f\u5ea6\u548c\u6d4b\u8bd5\u51c6\u786e\u7387\u4e0a\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u7edf\u8ba1\u5f02\u8d28\u6027\uff08\u975eIID\u6807\u7b7e\u5206\u5e03\uff09\u5bf9\u6536\u655b\u548c\u6cdb\u5316\u9020\u6210\u6311\u6218\uff0c\u73b0\u6709\u5f15\u5165SAM\u7684\u65b9\u6cd5\u5ffd\u7565\u5ba2\u6237\u7aef\u5f02\u8d28\u6027\u3002", "method": "\u63d0\u51faFedSCAM\u7b97\u6cd5\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u5f02\u8d28\u6027\u6307\u6807\uff0c\u53cd\u5411\u8c03\u8282\u6270\u52a8\u534a\u5f84\uff0c\u5f15\u5165\u5f02\u8d28\u6027\u611f\u77e5\u52a0\u6743\u805a\u5408\u673a\u5236\u3002", "result": "\u5728CIFAR - 10\u548cFashion - MNIST\u6570\u636e\u96c6\u4e0d\u540c\u7a0b\u5ea6\u7684Dirichlet\u6807\u7b7e\u504f\u659c\u4e0b\u5b9e\u9a8c\uff0cFedSCAM\u5728\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6d4b\u8bd5\u51c6\u786e\u7387\u4e0a\u4f18\u4e8eFedSAM\u3001FedLESAM\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedSCAM\u80fd\u6709\u6548\u5e94\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5728\u6027\u80fd\u4e0a\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2601.00860", "pdf": "https://arxiv.org/pdf/2601.00860", "abs": "https://arxiv.org/abs/2601.00860", "authors": ["Xidi Wang"], "title": "Path Integral Solution for Dissipative Generative Dynamics", "categories": ["cs.LG", "cs.AI", "physics.app-ph", "quant-ph"], "comment": "6 pages, 2 figures, 2 tables, along with 2 supplementary materials", "summary": "Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.", "AI": {"tldr": "\u7814\u7a76\u8bc1\u660e\u8017\u6563\u91cf\u5b50\u52a8\u529b\u5b66\u53ef\u5b9e\u73b0\u8fde\u8d2f\u6587\u672c\u751f\u6210\uff0c\u8bed\u8a00\u751f\u6210\u662f\u8017\u6563\u91cf\u5b50\u573a\u7406\u8bba\uff0c\u673a\u68b0\u7cfb\u7edf\u901a\u8fc7\u8017\u6563\u548c\u975e\u5c40\u57df\u6027\u83b7\u667a\u80fd\u3002", "motivation": "\u63a2\u8ba8\u7eaf\u673a\u68b0\u7cfb\u7edf\u80fd\u5426\u751f\u6210\u667a\u80fd\u8bed\u8a00\u3002", "method": "\u91c7\u7528\u5177\u6709\u95ed\u5f0f\u8def\u5f84\u79ef\u5206\u4f20\u64ad\u5b50\u7684Koopman\u7b97\u5b50\uff0c\u8fdb\u884c\u8c31\u5206\u6790\u3002", "result": "\u8017\u6563\u91cf\u5b50\u52a8\u529b\u5b66\u53ef\u4ea7\u751f\u8fde\u8d2f\u6587\u672c\u751f\u6210\uff0c\u5b88\u6052\u5b9a\u5f8b\u5bfc\u81f4\u6839\u672c\u5931\u8d25\uff0c\u51fa\u73b0\u4e0d\u540c\u7279\u5f81\u503c\u6a21\u5f0f\uff0c\u54c8\u5bc6\u987f\u7ea6\u675f\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u8bed\u8a00\u751f\u6210\u662f\u8017\u6563\u91cf\u5b50\u573a\u7406\u8bba\uff0c\u673a\u68b0\u7cfb\u7edf\u901a\u8fc7\u8017\u6563\u548c\u975e\u5c40\u57df\u6027\u800c\u975e\u5b88\u6052\u83b7\u5f97\u667a\u80fd\u3002"}}
{"id": "2601.00866", "pdf": "https://arxiv.org/pdf/2601.00866", "abs": "https://arxiv.org/abs/2601.00866", "authors": ["Shivani Saini", "Ramesh Kumar Vats", "Arup Kumar Sahoo"], "title": "A-PINN: Auxiliary Physics-informed Neural Networks for Structural Vibration Analysis in Continuous Euler-Bernoulli Beam", "categories": ["cs.LG", "cs.AI", "math.DS"], "comment": "31 pages", "summary": "Recent advancements in physics-informed neural networks (PINNs) and their variants have garnered substantial focus from researchers due to their effectiveness in solving both forward and inverse problems governed by differential equations. In this research, a modified Auxiliary physics-informed neural network (A-PINN) framework with balanced adaptive optimizers is proposed for the analysis of structural vibration problems. In order to accurately represent structural systems, it is critical for capturing vibration phenomena and ensuring reliable predictive analysis. So, our investigations are crucial for gaining deeper insight into the robustness of scientific machine learning models for solving vibration problems. Further, to rigorously evaluate the performance of A-PINN, we conducted different numerical simulations to approximate the Euler-Bernoulli beam equations under the various scenarios. The numerical results substantiate the enhanced performance of our model in terms of both numerical stability and predictive accuracy. Our model shows improvement of at least 40% over the baselines.", "AI": {"tldr": "\u63d0\u51fa\u5e26\u5e73\u8861\u81ea\u9002\u5e94\u4f18\u5316\u5668\u7684\u6539\u8fdbA - PINN\u6846\u67b6\u7528\u4e8e\u7ed3\u6784\u632f\u52a8\u95ee\u9898\u5206\u6790\uff0c\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u81f3\u5c1140%\u3002", "motivation": "PINNs\u53ca\u5176\u53d8\u4f53\u5728\u89e3\u51b3\u5fae\u5206\u65b9\u7a0b\u95ee\u9898\u4e0a\u6709\u6548\uff0c\u4e3a\u51c6\u786e\u5206\u6790\u7ed3\u6784\u7cfb\u7edf\u632f\u52a8\u73b0\u8c61\u548c\u8fdb\u884c\u53ef\u9760\u9884\u6d4b\u5206\u6790\uff0c\u6df1\u5165\u4e86\u89e3\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u6a21\u578b\u89e3\u51b3\u632f\u52a8\u95ee\u9898\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u5e26\u5e73\u8861\u81ea\u9002\u5e94\u4f18\u5316\u5668\u7684\u6539\u8fdbA - PINN\u6846\u67b6\uff0c\u5bf9\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6b27\u62c9 - \u4f2f\u52aa\u5229\u6881\u65b9\u7a0b\u8fdb\u884c\u6570\u503c\u6a21\u62df\u3002", "result": "\u6a21\u578b\u5728\u6570\u503c\u7a33\u5b9a\u6027\u548c\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u6bd4\u57fa\u7ebf\u81f3\u5c11\u63d0\u9ad840%\u3002", "conclusion": "\u6539\u8fdb\u7684A - PINN\u6846\u67b6\u5728\u89e3\u51b3\u7ed3\u6784\u632f\u52a8\u95ee\u9898\u4e0a\u6709\u826f\u597d\u6027\u80fd\u3002"}}
{"id": "2601.00867", "pdf": "https://arxiv.org/pdf/2601.00867", "abs": "https://arxiv.org/abs/2601.00867", "authors": ["Giuseppe Canale", "Kashyap Thimmaraju"], "title": "The Silicon Psyche: Anthropomorphic Vulnerabilities in Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Large Language Models (LLMs) are rapidly transitioning from conversational assistants to autonomous agents embedded in critical organizational functions, including Security Operations Centers (SOCs), financial systems, and infrastructure management. Current adversarial testing paradigms focus predominantly on technical attack vectors: prompt injection, jailbreaking, and data exfiltration. We argue this focus is catastrophically incomplete. LLMs, trained on vast corpora of human-generated text, have inherited not merely human knowledge but human \\textit{psychological architecture} -- including the pre-cognitive vulnerabilities that render humans susceptible to social engineering, authority manipulation, and affective exploitation. This paper presents the first systematic application of the Cybersecurity Psychology Framework (\\cpf{}), a 100-indicator taxonomy of human psychological vulnerabilities, to non-human cognitive agents. We introduce the \\textbf{Synthetic Psychometric Assessment Protocol} (\\sysname{}), a methodology for converting \\cpf{} indicators into adversarial scenarios targeting LLM decision-making. Our preliminary hypothesis testing across seven major LLM families reveals a disturbing pattern: while models demonstrate robust defenses against traditional jailbreaks, they exhibit critical susceptibility to authority-gradient manipulation, temporal pressure exploitation, and convergent-state attacks that mirror human cognitive failure modes. We term this phenomenon \\textbf{Anthropomorphic Vulnerability Inheritance} (AVI) and propose that the security community must urgently develop ``psychological firewalls'' -- intervention mechanisms adapted from the Cybersecurity Psychology Intervention Framework (\\cpif{}) -- to protect AI agents operating in adversarial environments.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u62d3\u5c55\uff0c\u73b0\u6709\u5bf9\u6297\u6d4b\u8bd5\u8303\u5f0f\u4e0d\u5b8c\u6574\uff0c\u672c\u6587\u7528\u7f51\u7edc\u5b89\u5168\u5fc3\u7406\u5b66\u6846\u67b6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u7c7b\u4eba\u6f0f\u6d1e\uff0c\u9700\u5f00\u53d1\u2018\u5fc3\u7406\u9632\u706b\u5899\u2019\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6297\u6d4b\u8bd5\u8303\u5f0f\u4e3b\u8981\u5173\u6ce8\u6280\u672f\u653b\u51fb\u5411\u91cf\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u7ee7\u627f\u7684\u4eba\u7c7b\u5fc3\u7406\u67b6\u6784\u53ca\u76f8\u5173\u6f0f\u6d1e\uff0c\u9700\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u3002", "method": "\u5e94\u7528\u7f51\u7edc\u5b89\u5168\u5fc3\u7406\u5b66\u6846\u67b6\uff0c\u5f15\u5165\u5408\u6210\u5fc3\u7406\u8bc4\u4f30\u534f\u8bae\u5c06\u6846\u67b6\u6307\u6807\u8f6c\u5316\u4e3a\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u7684\u5bf9\u6297\u573a\u666f\u3002", "result": "\u5bf9\u4e03\u4e2a\u4e3b\u8981\u5927\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\u7684\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\uff0c\u6a21\u578b\u5bf9\u4f20\u7edf\u8d8a\u72f1\u653b\u51fb\u9632\u5fa1\u8f83\u5f3a\uff0c\u4f46\u6613\u53d7\u6743\u5a01\u68af\u5ea6\u64cd\u7eb5\u3001\u65f6\u95f4\u538b\u529b\u5229\u7528\u548c\u6536\u655b\u72b6\u6001\u653b\u51fb\u7b49\u7c7b\u4eba\u8ba4\u77e5\u5931\u8d25\u6a21\u5f0f\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u2018\u62df\u4eba\u5316\u6f0f\u6d1e\u7ee7\u627f\u2019\u73b0\u8c61\uff0c\u5efa\u8bae\u5b89\u5168\u793e\u533a\u5f00\u53d1\u2018\u5fc3\u7406\u9632\u706b\u5899\u2019\u4fdd\u62a4\u5904\u4e8e\u5bf9\u6297\u73af\u5883\u7684AI\u4ee3\u7406\u3002"}}
{"id": "2601.00868", "pdf": "https://arxiv.org/pdf/2601.00868", "abs": "https://arxiv.org/abs/2601.00868", "authors": ["Aditya Sreevatsa K", "Arun Kumar Raveendran", "Jesrael K Mani", "Prakash G Shigli", "Rajkumar Rangadore", "Narayana Darapaneni", "Anwesh Reddy Paduri"], "title": "SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "SmartFlow is a multi-layered framework that integrates Reinforcement Learning and Agentic AI to address the dynamic rebalancing problem in urban bike-sharing services. Its architecture separates strategic, tactical, and communication functions for clarity and scalability. At the strategic level, a Deep Q-Network (DQN) agent, trained in a high-fidelity simulation of New Yorks Citi Bike network, learns robust rebalancing policies by modelling the challenge as a Markov Decision Process. These high-level strategies feed into a deterministic tactical module that optimises multi-leg journeys and schedules just-in-time dispatches to minimise fleet travel. Evaluation across multiple seeded runs demonstrates SmartFlows high efficacy, reducing network imbalance by over 95% while requiring minimal travel distance and achieving strong truck utilisation. A communication layer, powered by a grounded Agentic AI with a Large Language Model (LLM), translates logistical plans into clear, actionable instructions for operational staff, ensuring interpretability and execution readiness. This integration bridges machine intelligence with human operations, offering a scalable solution that reduces idle time, improves bike availability, and lowers operational costs. SmartFlow provides a blueprint for interpretable, AI-driven logistics in complex urban mobility networks.", "AI": {"tldr": "SmartFlow\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u667a\u80fd\u4f53AI\u89e3\u51b3\u57ce\u5e02\u5171\u4eab\u5355\u8f66\u52a8\u6001\u518d\u5e73\u8861\u95ee\u9898\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6548\u679c\u597d\uff0c\u8fd8\u80fd\u8fde\u63a5\u673a\u5668\u667a\u80fd\u548c\u4eba\u7c7b\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u57ce\u5e02\u5171\u4eab\u5355\u8f66\u670d\u52a1\u4e2d\u7684\u52a8\u6001\u518d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u5c42\u6846\u67b6\uff0c\u6218\u7565\u5c42\u7528DQN\u4ee3\u7406\u5728\u9ad8\u4fdd\u771f\u6a21\u62df\u4e2d\u5b66\u4e60\u7b56\u7565\uff0c\u6218\u672f\u6a21\u5757\u4f18\u5316\u884c\u7a0b\u548c\u8c03\u5ea6\uff0c\u901a\u4fe1\u5c42\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53AI\u751f\u6210\u6307\u4ee4\u3002", "result": "\u8bc4\u4f30\u663e\u793aSmartFlow\u80fd\u51cf\u5c11\u8d8595%\u7684\u7f51\u7edc\u4e0d\u5e73\u8861\uff0c\u6240\u9700\u884c\u9a76\u8ddd\u79bb\u5c11\uff0c\u5361\u8f66\u5229\u7528\u7387\u9ad8\u3002", "conclusion": "SmartFlow\u4e3a\u590d\u6742\u57ce\u5e02\u79fb\u52a8\u7f51\u7edc\u4e2d\u7684\u53ef\u89e3\u91caAI\u9a71\u52a8\u7269\u6d41\u63d0\u4f9b\u4e86\u84dd\u56fe\uff0c\u53ef\u51cf\u5c11\u95f2\u7f6e\u65f6\u95f4\u3001\u63d0\u9ad8\u81ea\u884c\u8f66\u53ef\u7528\u6027\u5e76\u964d\u4f4e\u8fd0\u8425\u6210\u672c\u3002"}}
{"id": "2601.00874", "pdf": "https://arxiv.org/pdf/2601.00874", "abs": "https://arxiv.org/abs/2601.00874", "authors": ["M. Rizki Oktavian"], "title": "LLMize: A Framework for Large Language Model-Based Numerical Optimization", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "comment": null, "summary": "Large language models (LLMs) have recently shown strong reasoning capabilities beyond traditional language tasks, motivating their use for numerical optimization. This paper presents LLMize, an open-source Python framework that enables LLM-driven optimization through iterative prompting and in-context learning. LLMize formulates optimization as a black-box process in which candidate solutions are generated in natural language, evaluated by an external objective function, and refined over successive iterations using solution-score feedback. The framework supports multiple optimization strategies, including Optimization by Prompting (OPRO) and hybrid LLM-based methods inspired by evolutionary algorithms and simulated annealing. A key advantage of LLMize is the ability to inject constraints, rules, and domain knowledge directly through natural language descriptions, allowing practitioners to define complex optimization problems without requiring expertise in mathematical programming or metaheuristic design. LLMize is evaluated on convex optimization, linear programming, the Traveling Salesman Problem, neural network hyperparameter tuning, and nuclear fuel lattice optimization. Results show that while LLM-based optimization is not competitive with classical solvers for simple problems, it provides a practical and accessible approach for complex, domain-specific tasks where constraints and heuristics are difficult to formalize.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLMize\u6846\u67b6\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4f18\u5316\uff0c\u652f\u6301\u591a\u7b56\u7565\uff0c\u53ef\u6ce8\u5165\u77e5\u8bc6\u5904\u7406\u590d\u6742\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u9002\u7528\u4e8e\u590d\u6742\u9886\u57df\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u53ef\u5e94\u7528\u4e8e\u6570\u503c\u4f18\u5316\u3002", "method": "\u63d0\u51faLLMize\u6846\u67b6\uff0c\u5c06\u4f18\u5316\u4f5c\u4e3a\u9ed1\u7bb1\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8fed\u4ee3\u63d0\u793a\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u652f\u6301\u591a\u79cd\u4f18\u5316\u7b56\u7565\uff0c\u53ef\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6ce8\u5165\u77e5\u8bc6\u3002", "result": "\u5728\u591a\u4e2a\u95ee\u9898\u4e0a\u8bc4\u4f30\u663e\u793a\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u4e0d\u5982\u7ecf\u5178\u6c42\u89e3\u5668\uff0c\u5728\u590d\u6742\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e2d\u6709\u5b9e\u7528\u548c\u53ef\u53ca\u6027\u3002", "conclusion": "LLMize\u63d0\u4f9b\u4e86\u9002\u7528\u4e8e\u590d\u6742\u9886\u57df\u7279\u5b9a\u4efb\u52a1\uff0c\u96be\u4ee5\u5f62\u5f0f\u5316\u7ea6\u675f\u548c\u542f\u53d1\u5f0f\u95ee\u9898\u7684\u5b9e\u7528\u624b\u6bb5\u3002"}}
{"id": "2601.00877", "pdf": "https://arxiv.org/pdf/2601.00877", "abs": "https://arxiv.org/abs/2601.00877", "authors": ["Thomas Andrews", "Mark Law", "Sara Ahmadi-Abhari", "Alessandra Russo"], "title": "LearnAD: Learning Interpretable Rules for Brain Networks in Alzheimer's Disease Classification", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025, Data on the Brain & Mind Workshop", "summary": "We introduce LearnAD, a neuro-symbolic method for predicting Alzheimer's disease from brain magnetic resonance imaging data, learning fully interpretable rules. LearnAD applies statistical models, Decision Trees, Random Forests, or GNNs to identify relevant brain connections, and then employs FastLAS to learn global rules. Our best instance outperforms Decision Trees, matches Support Vector Machine accuracy, and performs only slightly below Random Forests and GNNs trained on all features, all while remaining fully interpretable. Ablation studies show that our neuro-symbolic approach improves interpretability with comparable performance to pure statistical models. LearnAD demonstrates how symbolic learning can deepen our understanding of GNN behaviour in clinical neuroscience.", "AI": {"tldr": "\u4ecb\u7ecdLearnAD\uff0c\u4e00\u79cd\u4ece\u8111\u78c1\u5171\u632f\u6210\u50cf\u6570\u636e\u9884\u6d4b\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u80fd\u5b66\u4e60\u53ef\u89e3\u91ca\u89c4\u5219\uff0c\u8868\u73b0\u826f\u597d\u4e14\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u9700\u4ece\u8111\u78c1\u5171\u632f\u6210\u50cf\u6570\u636e\u4e2d\u6709\u6548\u9884\u6d4b\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u5e76\u4f7f\u6a21\u578b\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5148\u7528\u7edf\u8ba1\u6a21\u578b\u3001\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u6216GNN\u8bc6\u522b\u76f8\u5173\u8111\u8fde\u63a5\uff0c\u518d\u7528FastLAS\u5b66\u4e60\u5168\u5c40\u89c4\u5219\u3002", "result": "\u6700\u4f73\u5b9e\u4f8b\u8868\u73b0\u4f18\u4e8e\u51b3\u7b56\u6811\uff0c\u4e0e\u652f\u6301\u5411\u91cf\u673a\u51c6\u786e\u7387\u76f8\u5f53\uff0c\u7565\u900a\u4e8e\u968f\u673a\u68ee\u6797\u548c\u5168\u7279\u5f81GNN\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u5168\u53ef\u89e3\u91ca\uff1b\u6d88\u878d\u7814\u7a76\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u4e14\u6027\u80fd\u4e0e\u7eaf\u7edf\u8ba1\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "LearnAD\u5c55\u793a\u4e86\u7b26\u53f7\u5b66\u4e60\u53ef\u52a0\u6df1\u5bf9\u4e34\u5e8a\u795e\u7ecf\u79d1\u5b66\u4e2dGNN\u884c\u4e3a\u7684\u7406\u89e3\u3002"}}
{"id": "2601.00897", "pdf": "https://arxiv.org/pdf/2601.00897", "abs": "https://arxiv.org/abs/2601.00897", "authors": ["Sai Teja Erukude", "Jane Mascarenhas", "Lior Shamir"], "title": "CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "23 pages", "summary": "Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.", "AI": {"tldr": "\u63d0\u51faCornViT\u6846\u67b6\u7528\u4e8e\u7389\u7c73\u7c7d\u7c92\u5206\u7ea7\uff0c\u6784\u5efa\u7279\u5b9a\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u7cbe\u5ea6\u9ad8\uff0c\u8fd8\u90e8\u7f72\u4e86\u7f51\u9875\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u7389\u7c73\u7c7d\u7c92\u5206\u7ea7\u4e3b\u8981\u9760\u4eba\u5de5\u68c0\u67e5\uff0c\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e09\u9636\u6bb5\u7684Convolutional Vision Transformer (CvT) \u6846\u67b6CornViT\uff0c\u4f7f\u7528\u4e09\u4e2aCvT - 13\u5206\u7c7b\u5668\u5bf9RGB\u56fe\u50cf\u8fdb\u884c\u5904\u7406\uff0c\u624b\u52a8\u6807\u6ce8\u548c\u8fc7\u6ee4\u56fe\u50cf\u6784\u5efa\u7279\u5b9a\u6570\u636e\u96c6\uff0c\u5bf9\u9884\u8bad\u7ec3\u7684CvT - 13\u9aa8\u5e72\u8fdb\u884c\u4ec5\u5934\u90e8\u5fae\u8c03\u3002", "result": "CornViT\u5728\u7eaf\u5ea6\u3001\u5f62\u72b6\u548c\u80da\u65b9\u5411\u68c0\u6d4b\u4e0a\u6d4b\u8bd5\u51c6\u786e\u7387\u5206\u522b\u8fbe93.76%\u300194.11%\u548c91.12%\uff0c\u4f18\u4e8eResNet - 50\u548cDenseNet - 121\u3002", "conclusion": "CornViT\u6846\u67b6\u3001\u6570\u636e\u96c6\u548c\u7f51\u9875\u5e94\u7528\u4e3a\u79cd\u5b50\u8d28\u91cf\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u81ea\u52a8\u5316\u7389\u7c73\u7c7d\u7c92\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00905", "pdf": "https://arxiv.org/pdf/2601.00905", "abs": "https://arxiv.org/abs/2601.00905", "authors": ["Eliot Park", "Abhi Kumar", "Pranav Rajpurkar"], "title": "Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems", "categories": ["cs.CV", "cs.AI"], "comment": "x", "summary": "While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u524d\u6cbf\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u5e38\u89c1\u5904\u7406\u7269\u54c1\u7684\u53ef\u56de\u6536\u6027\uff0c\u8bc4\u4f30\u5176\u591a\u573a\u666f\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u6709\u8fdb\u6b65\u4f46\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u9ad8\u6548\u56de\u6536\u867d\u91cd\u8981\uff0c\u4f46\u516c\u4f17\u51c6\u786e\u5224\u65ad\u7269\u54c1\u53ef\u56de\u6536\u6027\u548c\u6b63\u786e\u5904\u7406\u65b9\u5f0f\u662f\u590d\u6742\u4efb\u52a1\uff0c\u56e0\u6b64\u63a2\u7d22\u524d\u6cbf\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7269\u54c1\u53ef\u56de\u6536\u6027\u3002", "method": "\u5229\u7528\u56fe\u50cf\u6570\u636e\u96c6\u8bc4\u4f30\u6a21\u578b\u5c06\u7269\u54c1\u5339\u914d\u5230\u5408\u9002\u56de\u6536\u7bb1\u7684\u80fd\u529b\uff0c\u8003\u5bdf\u6a21\u578b\u5728\u7279\u5b9a\u573a\u666f\uff08\u4f9d\u636e\u5730\u57df\u56de\u6536\u6307\u5357\u8c03\u6574\u9884\u6d4b\u3001\u8003\u8651\u6c61\u67d3\u6216\u7ed3\u6784\u635f\u574f\u3001\u5904\u7406\u591a\u6750\u6599\u7269\u4f53\uff09\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u6bd4\u4e4b\u524d\u8fed\u4ee3\u6709\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u6301\u7eed\u6539\u8fdb\u4e0a\u4e0b\u6587\u611f\u77e5\u6a21\u578b\u5bf9\u6539\u5584\u516c\u4f17\u56de\u6536\u4e60\u60ef\u548c\u63a8\u52a8\u73af\u5883\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.00907", "pdf": "https://arxiv.org/pdf/2601.00907", "abs": "https://arxiv.org/abs/2601.00907", "authors": ["Sumaiya Ali", "Areej Alhothali", "Sameera Albasri", "Ohoud Alzamzami", "Ahmed Abduljabbar", "Muhammad Alwazzan"], "title": "Placenta Accreta Spectrum Detection using Multimodal Deep Learning", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Placenta Accreta Spectrum (PAS) is a life-threatening obstetric complication involving abnormal placental invasion into the uterine wall. Early and accurate prenatal diagnosis is essential to reduce maternal and neonatal risks. This study aimed to develop and validate a deep learning framework that enhances PAS detection by integrating multiple imaging modalities. A multimodal deep learning model was designed using an intermediate feature-level fusion architecture combining 3D Magnetic Resonance Imaging (MRI) and 2D Ultrasound (US) scans. Unimodal feature extractors, a 3D DenseNet121-Vision Transformer for MRI and a 2D ResNet50 for US, were selected after systematic comparative analysis. Curated datasets comprising 1,293 MRI and 1,143 US scans were used to train the unimodal models and paired samples of patient-matched MRI-US scans was isolated for multimodal model development and evaluation. On an independent test set, the multimodal fusion model achieved superior performance, with an accuracy of 92.5% and an Area Under the Receiver Operating Characteristic Curve (AUC) of 0.927, outperforming the MRI-only (82.5%, AUC 0.825) and US-only (87.5%, AUC 0.879) models. Integrating MRI and US features provides complementary diagnostic information, demonstrating strong potential to enhance prenatal risk assessment and improve patient outcomes.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u878d\u54083D MRI\u548c2D\u8d85\u58f0\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7528\u4e8ePAS\u68c0\u6d4b\uff0c\u8be5\u591a\u6a21\u6001\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5355\u6a21\u6001\u6a21\u578b\u3002", "motivation": "PAS\u662f\u5371\u53ca\u751f\u547d\u7684\u4ea7\u79d1\u5e76\u53d1\u75c7\uff0c\u65e9\u671f\u51c6\u786e\u7684\u4ea7\u524d\u8bca\u65ad\u5bf9\u964d\u4f4e\u6bcd\u5a74\u98ce\u9669\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u8981\u5f00\u53d1\u589e\u5f3aPAS\u68c0\u6d4b\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4f7f\u7528\u4e2d\u95f4\u7279\u5f81\u7ea7\u878d\u5408\u67b6\u6784\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u54083D MRI\u548c2D\u8d85\u58f0\u626b\u63cf\uff0c\u7ecf\u6bd4\u8f83\u5206\u6790\u9009\u62e9\u5355\u6a21\u6001\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u7528\u6574\u7406\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u591a\u6a21\u6001\u878d\u5408\u6a21\u578b\u5728\u72ec\u7acb\u6d4b\u8bd5\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe92.5%\uff0cAUC\u4e3a0.927\uff0c\u4f18\u4e8e\u4ec5\u7528MRI\u548c\u4ec5\u7528\u8d85\u58f0\u7684\u6a21\u578b\u3002", "conclusion": "\u6574\u5408MRI\u548c\u8d85\u58f0\u7279\u5f81\u53ef\u63d0\u4f9b\u4e92\u8865\u8bca\u65ad\u4fe1\u606f\uff0c\u6709\u6f5c\u529b\u589e\u5f3a\u4ea7\u524d\u98ce\u9669\u8bc4\u4f30\u548c\u6539\u5584\u60a3\u8005\u9884\u540e\u3002"}}
{"id": "2601.00911", "pdf": "https://arxiv.org/pdf/2601.00911", "abs": "https://arxiv.org/abs/2601.00911", "authors": ["Joyjit Roy"], "title": "Device-Native Autonomous Agents for Privacy-Preserving Negotiations", "categories": ["cs.CR", "cs.AI", "cs.ET", "cs.LG"], "comment": "9 pages, 6 figuers, 9 tables, Submitted in conference 2nd International Conference on Artificial Intelligence Systems (AIS 2026)", "summary": "Automated negotiations in insurance and business-to-business (B2B) commerce encounter substantial challenges. Current systems force a trade-off between convenience and privacy by routing sensitive financial data through centralized servers, increasing security risks, and diminishing user trust. This study introduces a device-native autonomous Artificial Intelligence (AI) agent system for privacy-preserving negotiations. The proposed system operates exclusively on user hardware, enabling real-time bargaining while maintaining sensitive constraints locally. It integrates zero-knowledge proofs to ensure privacy and employs distilled world models to support advanced on-device reasoning. The architecture incorporates six technical components within an agentic AI workflow. Agents autonomously plan negotiation strategies, conduct secure multi-party bargaining, and generate cryptographic audit trails without exposing user data to external servers. The system is evaluated in insurance and B2B procurement scenarios across diverse device configurations. Results show an average success rate of 87%, a 2.4x latency improvement over cloud baselines, and strong privacy preservation through zero-knowledge proofs. User studies show 27% higher trust scores when decision trails are available. These findings establish a foundation for trustworthy autonomous agents in privacy-sensitive financial domains.", "AI": {"tldr": "\u5f15\u5165\u8bbe\u5907\u539f\u751f\u81ea\u4e3bAI\u4ee3\u7406\u7cfb\u7edf\u7528\u4e8e\u9690\u79c1\u4fdd\u62a4\u7684\u8c08\u5224\uff0c\u8bc4\u4f30\u663e\u793a\u6709\u9ad8\u6210\u529f\u7387\u3001\u4f4e\u5ef6\u8fdf\u548c\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u63d0\u9ad8\u7528\u6237\u4fe1\u4efb\u3002", "motivation": "\u5f53\u524d\u4fdd\u9669\u548cB2B\u5546\u52a1\u81ea\u52a8\u5316\u8c08\u5224\u7cfb\u7edf\u901a\u8fc7\u96c6\u4e2d\u670d\u52a1\u5668\u4f20\u8f93\u654f\u611f\u6570\u636e\uff0c\u5728\u4fbf\u5229\u6027\u548c\u9690\u79c1\u6027\u95f4\u6743\u8861\uff0c\u589e\u52a0\u5b89\u5168\u98ce\u9669\u5e76\u964d\u4f4e\u7528\u6237\u4fe1\u4efb\u3002", "method": "\u63d0\u51fa\u4ec5\u5728\u7528\u6237\u786c\u4ef6\u4e0a\u8fd0\u884c\u7684\u7cfb\u7edf\uff0c\u96c6\u6210\u96f6\u77e5\u8bc6\u8bc1\u660e\u786e\u4fdd\u9690\u79c1\uff0c\u91c7\u7528\u63d0\u70bc\u4e16\u754c\u6a21\u578b\u652f\u6301\u8bbe\u5907\u7aef\u63a8\u7406\uff0c\u67b6\u6784\u5305\u542b\u516d\u4e2a\u6280\u672f\u7ec4\u4ef6\u3002", "result": "\u7cfb\u7edf\u5728\u4fdd\u9669\u548cB2B\u91c7\u8d2d\u573a\u666f\u8bc4\u4f30\u4e2d\uff0c\u5e73\u5747\u6210\u529f\u738787%\uff0c\u5ef6\u8fdf\u6bd4\u4e91\u57fa\u7ebf\u6539\u55842.4\u500d\uff0c\u96f6\u77e5\u8bc6\u8bc1\u660e\u5b9e\u73b0\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u6709\u51b3\u7b56\u8f68\u8ff9\u65f6\u7528\u6237\u4fe1\u4efb\u5ea6\u63d0\u9ad827%\u3002", "conclusion": "\u4e3a\u9690\u79c1\u654f\u611f\u91d1\u878d\u9886\u57df\u7684\u53ef\u4fe1\u81ea\u4e3b\u4ee3\u7406\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2601.00919", "pdf": "https://arxiv.org/pdf/2601.00919", "abs": "https://arxiv.org/abs/2601.00919", "authors": ["Zichuan Fu", "Wentao Song", "Guojing Li", "Yejing Wang", "Xian Wu", "Yimin Deng", "Hanyu Yan", "Yefeng Zheng", "Xiangyu Zhao"], "title": "Attention Needs to Focus: A Unified Perspective on Attention Allocation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICLR 2026 conference", "summary": "The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.", "AI": {"tldr": "\u672c\u6587\u6307\u51faTransformer\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u5b58\u5728\u8868\u5f81\u5d29\u6e83\u548c\u6ce8\u610f\u529b\u6c47\u805a\u95ee\u9898\uff0c\u6839\u6e90\u662f\u6ce8\u610f\u529b\u5206\u914d\u4e0d\u5f53\uff0c\u5e76\u63d0\u51faLazy Attention\u673a\u5236\u89e3\u51b3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u3002", "motivation": "\u89e3\u51b3Transformer\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u8868\u5f81\u5d29\u6e83\u548c\u6ce8\u610f\u529b\u6c47\u805a\u95ee\u9898\uff0c\u4e14\u63ed\u793a\u4e8c\u8005\u6df1\u5c42\u8054\u7cfb\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u89c2\u70b9\u6307\u51fa\u95ee\u9898\u6839\u6e90\u662f\u6ce8\u610f\u529b\u5206\u914d\u4e0d\u5f53\uff0c\u8bc6\u522b\u51fa\u6ce8\u610f\u529b\u8fc7\u8f7d\u548c\u4e0d\u8db3\u4e24\u79cd\u6a21\u5f0f\uff0c\u5f15\u5165Lazy Attention\u673a\u5236\uff0c\u7528\u4f4d\u7f6e\u533a\u5206\u7f13\u89e3\u8fc7\u8f7d\uff0c\u7528Elastic - Softmax\u5e94\u5bf9\u4e0d\u8db3\u3002", "result": "\u5728FineWeb - Edu\u8bed\u6599\u5e93\u7684\u4e5d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLazy Attention\u6210\u529f\u7f13\u89e3\u6ce8\u610f\u529b\u6c47\u805a\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe59.58%\u7684\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u6027\u80fd\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "Lazy Attention\u673a\u5236\u80fd\u6709\u6548\u5e94\u5bf9Transformer\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u7684\u95ee\u9898\u3002"}}
{"id": "2601.00920", "pdf": "https://arxiv.org/pdf/2601.00920", "abs": "https://arxiv.org/abs/2601.00920", "authors": ["Xingsheng Chen", "Regina Zhang", "Bo Gao", "Xingwei He", "Xiaofeng Liu", "Pietro Lio", "Kwok-Yan Lam", "Siu-Ming Yiu"], "title": "MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 6 tables", "summary": "Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.", "AI": {"tldr": "\u63d0\u51faMODE\u6846\u67b6\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u8d85\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u957f\u7a0b\u4f9d\u8d56\u548c\u4e0d\u89c4\u5219\u91c7\u6837\u6570\u636e\u65f6\uff0c\u96be\u4ee5\u5e73\u8861\u6548\u7387\u3001\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faMODE\u6846\u67b6\uff0c\u7ed3\u5408\u4f4e\u79e9\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u548c\u589e\u5f3aMamba\u67b6\u6784\uff0c\u5305\u542b\u7ebf\u6027\u5206\u8bcd\u5c42\u3001Mamba\u7f16\u7801\u5668\u5757\uff0c\u4f7f\u7528\u56e0\u679c\u5377\u79ef\u3001SiLU\u6fc0\u6d3b\u7b49\uff0c\u8fd8\u6709\u5206\u6bb5\u9009\u62e9\u6027\u626b\u63cf\u673a\u5236\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cMODE\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u8d85\u8fc7\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u8d21\u732e\u5728\u4e8e\u63d0\u4f9b\u7edf\u4e00\u9ad8\u6548\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u67b6\u6784\uff0c\u6574\u5408Mamba\u9009\u62e9\u6027\u626b\u63cf\u4e0e\u4f4e\u79e9\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\uff0c\u901a\u8fc7\u4f4e\u79e9\u8fd1\u4f3c\u548c\u52a8\u6001\u9009\u62e9\u6027\u626b\u63cf\u63d0\u5347\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.00921", "pdf": "https://arxiv.org/pdf/2601.00921", "abs": "https://arxiv.org/abs/2601.00921", "authors": ["Azadeh Alavi", "Hamidreza Khalili", "Stanley H. Chan", "Fatemeh Kouchmeshki", "Ross Vlahos"], "title": "Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "24 pages, 4 figures", "summary": "Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.", "AI": {"tldr": "\u7814\u7a76\u7528\u5fae\u521b\u751f\u7269\u6807\u5fd7\u7269\u5bf9\u6162\u6027\u963b\u585e\u6027\u80ba\u75be\u75c5\uff08COPD\uff09\u9aa8\u9abc\u808c\u7ed3\u5c40\u8fdb\u884c\u9884\u6d4b\u5efa\u6a21\uff0c\u5bf9\u6bd4\u591a\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u51e0\u4f55\u548c\u91cf\u5b50\u6838\u63d0\u5347\u5728\u4f4e\u6570\u636e\u3001\u4f4e\u7279\u5f81\u751f\u7269\u533b\u5b66\u9884\u6d4b\u95ee\u9898\u4e2d\u6709\u53ef\u8861\u91cf\u76ca\u5904\u3002", "motivation": "\u9aa8\u9abc\u808c\u529f\u80fd\u969c\u788d\u662fCOPD\u7684\u4e34\u5e8a\u76f8\u5173\u80ba\u5916\u8868\u73b0\u4e14\u4e0e\u708e\u75c7\u76f8\u5173\uff0c\u56e0\u6b64\u7528\u5fae\u521b\u751f\u7269\u6807\u5fd7\u7269\u8fdb\u884c\u808c\u8089\u7ed3\u5c40\u9884\u6d4b\u5efa\u6a21\u3002", "method": "\u7814\u7a76\u542b213\u53ea\u52a8\u7269\u7684\u4e34\u5e8a\u524d\u5c0f\u6837\u672c\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u8c03\u4f18\u7684\u7ecf\u5178\u57fa\u7ebf\u3001\u57fa\u4e8eStein\u6563\u5ea6\u7684\u51e0\u4f55\u611f\u77e5\u5bf9\u79f0\u6b63\u5b9a\uff08SPD\uff09\u63cf\u8ff0\u7b26\u548c\u9488\u5bf9\u4f4e\u7ef4\u8868\u683c\u6570\u636e\u7684\u91cf\u5b50\u6838\u6a21\u578b\u3002", "result": "\u91cf\u5b50\u6838\u5cad\u56de\u5f52\u5728\u808c\u8089\u91cd\u91cf\u9884\u6d4b\u4e0a\u6709\u66f4\u597d\u8868\u73b0\uff1bStein\u6563\u5ea6\u539f\u578b\u8ddd\u79bb\u5728\u4ec5\u4f7f\u7528\u751f\u7269\u6807\u5fd7\u7269\u65f6\u6709\u5c0f\u800c\u7a33\u5b9a\u7684\u589e\u76ca\uff1b\u7b5b\u9009\u5f0f\u8bc4\u4f30\u5728\u68c0\u6d4b\u4f4e\u808c\u8089\u91cd\u91cf\u65f6ROC - AUC\u53ef\u8fbe0.90\u3002", "conclusion": "\u51e0\u4f55\u548c\u91cf\u5b50\u6838\u63d0\u5347\u5728\u4f4e\u6570\u636e\u3001\u4f4e\u7279\u5f81\u751f\u7269\u533b\u5b66\u9884\u6d4b\u95ee\u9898\u4e2d\u80fd\u63d0\u4f9b\u53ef\u8861\u91cf\u76ca\u5904\uff0c\u4e14\u4fdd\u7559\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u7684\u6a21\u578b\u9009\u62e9\u3002"}}
{"id": "2601.00924", "pdf": "https://arxiv.org/pdf/2601.00924", "abs": "https://arxiv.org/abs/2601.00924", "authors": ["Rares Folea", "Radu Iacob", "Emil Slusanschi", "Traian Rebedea"], "title": "Complexity-based code embeddings", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u7b97\u6cd5\u6e90\u4ee3\u7801\u8f6c\u6362\u4e3a\u6570\u503c\u5d4c\u5165\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u5e76\u7528\u5176\u5b9e\u73b0XGBoost\u7b97\u6cd5\u5728\u591a\u6807\u7b7e\u6570\u636e\u96c6\u8fbe\u4e00\u5b9aF1\u5206\u6570\u3002", "motivation": "\u5bfb\u627e\u4e00\u79cd\u5c06\u5404\u79cd\u7b97\u6cd5\u6e90\u4ee3\u7801\u8f6c\u6362\u4e3a\u6570\u503c\u5d4c\u5165\u7684\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u5206\u6790\u8ba1\u7b97\u673a\u7a0b\u5e8f\u5bf9\u4e0d\u540c\u8f93\u5165\u7684\u884c\u4e3a\uff0c\u4e3a\u5206\u6790\u6307\u6807\u5b9a\u5236\u591a\u4e2a\u901a\u7528\u590d\u6742\u5ea6\u51fd\u6570\uff0c\u57fa\u4e8er - Complexity\u751f\u6210\u7b97\u6cd5\u5d4c\u5165\u3002", "result": "\u4f7f\u7528\u63d0\u51fa\u7684\u4ee3\u7801\u5d4c\u5165\u5b9e\u73b0XGBoost\u7b97\u6cd5\uff0c\u5728\u57fa\u4e8eCodeforces\u5e73\u53f0\u7f16\u7a0b\u7ade\u8d5b\u771f\u5b9e\u4ee3\u7801\u7247\u6bb5\u6784\u5efa\u768411\u7c7b\u591a\u6807\u7b7e\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u5e73\u5747F1\u5206\u6570\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4ee3\u7801\u5d4c\u5165\u65b9\u6cd5\u53ef\u7528\u4e8e\u5b9e\u73b0\u7b97\u6cd5\u5e76\u5728\u591a\u6807\u7b7e\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u8f83\u597d\u8868\u73b0\u3002"}}
{"id": "2601.00925", "pdf": "https://arxiv.org/pdf/2601.00925", "abs": "https://arxiv.org/abs/2601.00925", "authors": ["I-Hsien Ting", "Yi-Jun Tseng", "Yu-Sheng Lin"], "title": "Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.\n  This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.", "AI": {"tldr": "\u672c\u6587\u5229\u7528 3D \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u57fa\u4e8e\u65e0\u9020\u5f71\u5242 CT \u56fe\u50cf\u5bf9\u80ba\u6813\u585e\u8fdb\u884c\u81ea\u52a8\u5206\u7c7b\uff0c\u6a21\u578b\u8fbe\u5230 85% \u51c6\u786e\u7387\u548c 0.84 AUC\uff0c\u8bc1\u5b9e\u5176\u8bca\u65ad\u53ef\u884c\u6027\u3002", "motivation": "\u6709\u7814\u7a76\u7528\u6df1\u5ea6\u5b66\u4e60\u57fa\u4e8e\u9020\u5f71\u5242 CT \u8fdb\u884c\u80ba\u6813\u585e\u8bca\u65ad\uff0c\u4f46\u9020\u5f71\u5242\u53ef\u80fd\u81f4\u6025\u6027\u80be\u635f\u4f24\uff0c\u4e14\u8d77\u6548\u8017\u65f6\u957f\uff0c\u53ef\u80fd\u4f7f\u60a3\u8005\u9519\u8fc7\u6cbb\u7597\u65f6\u673a\u3002", "method": "\u4f7f\u7528 3D \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u57fa\u4e8e\u65e0\u9020\u5f71\u5242 CT \u56fe\u50cf\u5bf9\u80ba\u6813\u585e\u8fdb\u884c\u81ea\u52a8\u5206\u7c7b\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9\u65e0\u9020\u5f71 CT \u56fe\u50cf\u80ba\u6813\u585e\u5206\u7c7b\u6709\u663e\u8457\u6548\u679c\uff0c\u51c6\u786e\u7387 85% \uff0cAUC \u4e3a 0.84\u3002", "conclusion": "\u8be5\u6a21\u578b\u7528\u4e8e\u80ba\u6813\u585e\u8bca\u65ad\u5177\u6709\u53ef\u884c\u6027\u3002"}}
{"id": "2601.00927", "pdf": "https://arxiv.org/pdf/2601.00927", "abs": "https://arxiv.org/abs/2601.00927", "authors": ["Jawad Chowdhury", "Rezaur Rashid", "Gabriel Terejanu"], "title": "Measuring Social Media Polarization Using Large Language Models and Heuristic Rules", "categories": ["cs.SI", "cs.AI", "cs.CL"], "comment": "Foundations and Applications of Big Data Analytics (FAB), Niagara Falls, Canada, 2025", "summary": "Understanding affective polarization in online discourse is crucial for evaluating the societal impact of social media interactions. This study presents a novel framework that leverages large language models (LLMs) and domain-informed heuristics to systematically analyze and quantify affective polarization in discussions on divisive topics such as climate change and gun control. Unlike most prior approaches that relied on sentiment analysis or predefined classifiers, our method integrates LLMs to extract stance, affective tone, and agreement patterns from large-scale social media discussions. We then apply a rule-based scoring system capable of quantifying affective polarization even in small conversations consisting of single interactions, based on stance alignment, emotional content, and interaction dynamics. Our analysis reveals distinct polarization patterns that are event dependent: (i) anticipation-driven polarization, where extreme polarization escalates before well-publicized events, and (ii) reactive polarization, where intense affective polarization spikes immediately after sudden, high-impact events. By combining AI-driven content annotation with domain-informed scoring, our framework offers a scalable and interpretable approach to measuring affective polarization. The source code is publicly available at: https://github.com/hasanjawad001/llm-social-media-polarization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u6846\u67b6\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u9886\u57df\u542f\u53d1\u5f0f\u65b9\u6cd5\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u4e2d\u60c5\u611f\u6781\u5316\uff0c\u63ed\u793a\u4e8b\u4ef6\u4f9d\u8d56\u7684\u6781\u5316\u6a21\u5f0f\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u7406\u89e3\u5728\u7ebf\u8bdd\u8bed\u4e2d\u7684\u60c5\u611f\u6781\u5316\u5bf9\u8bc4\u4f30\u793e\u4ea4\u5a92\u4f53\u4e92\u52a8\u7684\u793e\u4f1a\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u7acb\u573a\u3001\u60c5\u611f\u57fa\u8c03\u4e0e\u5171\u8bc6\u6a21\u5f0f\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u8bc4\u5206\u7cfb\u7edf\u91cf\u5316\u60c5\u611f\u6781\u5316\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u4e8b\u4ef6\u4f9d\u8d56\u7684\u4e24\u79cd\u6781\u5316\u6a21\u5f0f\uff1a\u9884\u671f\u9a71\u52a8\u6781\u5316\u548c\u53cd\u5e94\u6027\u6781\u5316\u3002", "conclusion": "\u7ed3\u5408AI\u5185\u5bb9\u6ce8\u91ca\u548c\u9886\u57df\u8bc4\u5206\u7684\u6846\u67b6\u4e3a\u8861\u91cf\u60c5\u611f\u6781\u5316\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.00928", "pdf": "https://arxiv.org/pdf/2601.00928", "abs": "https://arxiv.org/abs/2601.00928", "authors": ["Luis Yoichi Morales", "Francesco Zanlungo", "David M. Woollard"], "title": "Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u96f6\u552e\u573a\u666f\u4e2d\u673a\u5668\u4eba\u90e8\u7f72\u6311\u6218\uff0c\u7814\u7a76\u987e\u5ba2\u6d3b\u52a8\u4ee5\u7406\u89e3\u8d2d\u7269\u8005\u610f\u56fe\uff0c\u63d0\u51fa\u8ba1\u7b97\u2018\u8d27\u67b6\u8bbf\u95ee\u2019\u7684\u7b97\u6cd5\uff0c\u7ecf\u6821\u51c6\u8bc4\u4f30\u540e\u5206\u6790\u6d4f\u89c8\u6a21\u5f0f\u4e0e\u8d2d\u4e70\u5173\u7cfb\uff0c\u63a2\u8ba8\u5176\u5e94\u7528\u3002", "motivation": "\u5e94\u5bf9\u673a\u5668\u4eba\u5728\u96f6\u552e\u9762\u5411\u5ba2\u6237\u89d2\u8272\u90e8\u7f72\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u5bf9\u8d2d\u7269\u8005\u610f\u56fe\u7684\u81ea\u4e3b\u7406\u89e3\u3002", "method": "\u5f15\u5165\u8ba1\u7b97\u2018\u8d27\u67b6\u8bbf\u95ee\u2019\u7684\u7b97\u6cd5\uff0c\u4ece\u673a\u5668\u89c6\u89c93D\u8ddf\u8e2a\u548c\u5934\u9876\u6444\u50cf\u5934\u83b7\u53d6\u7684\u8f68\u8ff9\u4e2d\u63d0\u53d6\uff0c\u7528\u4e0d\u540c\u5e97\u94fa\u7684\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u4e24\u6b21\u72ec\u7acb\u6821\u51c6\uff0c\u5e76\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u8bc4\u4f30\u3002", "result": "\u7b97\u6cd5\u80fd\u5728\u4e0e\u6821\u51c6\u73af\u5883\u4e0d\u540c\u7684\u73af\u5883\u4e2d\u8bc6\u522b\u987e\u5ba2\u6d4f\u89c8\u6d3b\u52a8\uff0c\u8fd8\u5206\u6790\u4e86\u6d4f\u89c8\u6a21\u5f0f\u4e0e\u5b9e\u9645\u8d2d\u4e70\u7684\u5173\u7cfb\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u8d27\u67b6\u6d4f\u89c8\u4fe1\u606f\u5728\u96f6\u552e\u89c4\u5212\u548c\u4eba\u673a\u4ea4\u4e92\u573a\u666f\u4e2d\u7684\u5e94\u7528\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.00933", "pdf": "https://arxiv.org/pdf/2601.00933", "abs": "https://arxiv.org/abs/2601.00933", "authors": ["Jinyu Xu", "Abhishek K. Umrawal"], "title": "LOFA: Online Influence Maximization under Full-Bandit Feedback using Lazy Forward Selection", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": "14 pages and 6 figures", "summary": "We study the problem of influence maximization (IM) in an online setting, where the goal is to select a subset of nodes$\\unicode{x2014}$called the seed set$\\unicode{x2014}$at each time step over a fixed time horizon, subject to a cardinality budget constraint, to maximize the expected cumulative influence. We operate under a full-bandit feedback model, where only the influence of the chosen seed set at each time step is observed, with no additional structural information about the network or diffusion process. It is well-established that the influence function is submodular, and existing algorithms exploit this property to achieve low regret. In this work, we leverage this property further and propose the Lazy Online Forward Algorithm (LOFA), which achieves a lower empirical regret. We conduct experiments on a real-world social network to demonstrate that LOFA achieves superior performance compared to existing bandit algorithms in terms of cumulative regret and instantaneous reward.", "AI": {"tldr": "\u7814\u7a76\u5728\u7ebf\u73af\u5883\u4e0b\u5f71\u54cd\u6700\u5927\u5316\u95ee\u9898\uff0c\u63d0\u51faLOFA\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "motivation": "\u5728\u5168\u8001\u864e\u673a\u53cd\u9988\u6a21\u578b\u4e0b\uff0c\u89e3\u51b3\u5728\u7ebf\u73af\u5883\u4e2d\u5f71\u54cd\u6700\u5927\u5316\u95ee\u9898\uff0c\u671f\u671b\u964d\u4f4e\u9057\u61be\u503c\u3002", "method": "\u5229\u7528\u5f71\u54cd\u51fd\u6570\u7684\u5b50\u6a21\u6027\uff0c\u63d0\u51faLazy Online Forward Algorithm (LOFA)\u3002", "result": "\u5728\u771f\u5b9e\u793e\u4ea4\u7f51\u7edc\u5b9e\u9a8c\u4e2d\uff0cLOFA\u5728\u7d2f\u79ef\u9057\u61be\u548c\u5373\u65f6\u5956\u52b1\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u8001\u864e\u673a\u7b97\u6cd5\u3002", "conclusion": "LOFA\u7b97\u6cd5\u5177\u6709\u66f4\u4f4e\u7684\u7ecf\u9a8c\u9057\u61be\uff0c\u6027\u80fd\u66f4\u4f18\u3002"}}
{"id": "2601.00935", "pdf": "https://arxiv.org/pdf/2601.00935", "abs": "https://arxiv.org/abs/2601.00935", "authors": ["Yue Heng Yeo", "Yuchen Hu", "Shreyas Gopal", "Yizhou Peng", "Hexin Liu", "Eng Siong Chng"], "title": "Improving Code-Switching Speech Recognition with TTS Data Augmentation", "categories": ["eess.AS", "cs.AI"], "comment": "This paper was accepted by APSIPA 2025", "summary": "Automatic speech recognition (ASR) for conversational code-switching speech remains challenging due to the scarcity of realistic, high-quality labeled speech data. This paper explores multilingual text-to-speech (TTS) models as an effective data augmentation technique to address this shortage. Specifically, we fine-tune the multilingual CosyVoice2 TTS model on the SEAME dataset to generate synthetic conversational Chinese-English code-switching speech, significantly increasing the quantity and speaker diversity of available training data. Our experiments demonstrate that augmenting real speech with synthetic speech reduces the mixed error rate (MER) from 12.1 percent to 10.1 percent on DevMan and from 17.8 percent to 16.0 percent on DevSGE, indicating consistent performance gains. These results confirm that multilingual TTS is an effective and practical tool for enhancing ASR robustness in low-resource conversational code-switching scenarios.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u7528\u591a\u8bed\u8a00TTS\u6a21\u578b\u89e3\u51b3\u5bf9\u8bdd\u4ee3\u7801\u5207\u6362\u8bed\u97f3ASR\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u901a\u8fc7\u5fae\u8c03TTS\u6a21\u578b\u751f\u6210\u5408\u6210\u8bed\u97f3\uff0c\u5b9e\u9a8c\u8868\u660e\u6027\u80fd\u63d0\u5347\uff0c\u786e\u8ba4TTS\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u5bf9\u8bdd\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u4e2d\u771f\u5b9e\u9ad8\u8d28\u91cf\u6807\u6ce8\u8bed\u97f3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u5728SEAME\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u591a\u8bed\u8a00CosyVoice2 TTS\u6a21\u578b\uff0c\u751f\u6210\u5408\u6210\u7684\u4e2d\u82f1\u5bf9\u8bdd\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u3002", "result": "\u7528\u5408\u6210\u8bed\u97f3\u589e\u5f3a\u771f\u5b9e\u8bed\u97f3\u540e\uff0cDevMan\u4e0a\u6df7\u5408\u9519\u8bef\u7387\uff08MER\uff09\u4ece12.1%\u964d\u81f310.1%\uff0cDevSGE\u4e0a\u4ece17.8%\u964d\u81f316.0%\uff0c\u6027\u80fd\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u591a\u8bed\u8a00TTS\u662f\u5728\u4f4e\u8d44\u6e90\u5bf9\u8bdd\u4ee3\u7801\u5207\u6362\u573a\u666f\u4e2d\u589e\u5f3aASR\u9c81\u68d2\u6027\u7684\u6709\u6548\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2601.00936", "pdf": "https://arxiv.org/pdf/2601.00936", "abs": "https://arxiv.org/abs/2601.00936", "authors": ["M P V S Gopinadh", "S Mahaboob Hussain"], "title": "Emoji-Based Jailbreaking of Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": "7 pages, 2 figures", "summary": "Large Language Models (LLMs) are integral to modern AI applications, but their safety alignment mechanisms can be bypassed through adversarial prompt engineering. This study investigates emoji-based jailbreaking, where emoji sequences are embedded in textual prompts to trigger harmful and unethical outputs from LLMs. We evaluated 50 emoji-based prompts on four open-source LLMs: Mistral 7B, Qwen 2 7B, Gemma 2 9B, and Llama 3 8B. Metrics included jailbreak success rate, safety alignment adherence, and latency, with responses categorized as successful, partial and failed. Results revealed model-specific vulnerabilities: Gemma 2 9B and Mistral 7B exhibited 10 % success rates, while Qwen 2 7B achieved full alignment (0% success). A chi-square test (chi^2 = 32.94, p < 0.001) confirmed significant inter-model differences. While prior works focused on emoji attacks targeting safety judges or classifiers, our empirical analysis examines direct prompt-level vulnerabilities in LLMs. The results reveal limitations in safety mechanisms and highlight the necessity for systematic handling of emoji-based representations in prompt-level safety and alignment pipelines.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u8868\u60c5\u7b26\u53f7\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u72f1\u653b\u51fb\uff0c\u8bc4\u4f30\u4e86\u56db\u79cd\u5f00\u6e90\u5927\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u7279\u5b9a\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u9700\u5904\u7406\u597d\u8868\u60c5\u7b26\u53f7\u8868\u793a\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u53ef\u88ab\u5bf9\u6297\u6027\u63d0\u793a\u5de5\u7a0b\u7ed5\u8fc7\uff0c\u6b64\u524d\u7814\u7a76\u591a\u5173\u6ce8\u8868\u60c5\u7b26\u53f7\u5bf9\u5b89\u5168\u5224\u65ad\u5668\u6216\u5206\u7c7b\u5668\u7684\u653b\u51fb\uff0c\u672c\u6587\u8981\u7814\u7a76\u5bf9\u5927\u6a21\u578b\u76f4\u63a5\u63d0\u793a\u7ea7\u522b\u7684\u6f0f\u6d1e\u3002", "method": "\u5728Mistral 7B\u3001Qwen 2 7B\u3001Gemma 2 9B\u548cLlama 3 8B\u56db\u4e2a\u5f00\u6e90\u5927\u6a21\u578b\u4e0a\u8bc4\u4f3050\u4e2a\u57fa\u4e8e\u8868\u60c5\u7b26\u53f7\u7684\u63d0\u793a\uff0c\u7528\u8d8a\u72f1\u6210\u529f\u7387\u3001\u5b89\u5168\u5bf9\u9f50\u9075\u5b88\u60c5\u51b5\u548c\u5ef6\u8fdf\u4e3a\u6307\u6807\uff0c\u5bf9\u54cd\u5e94\u5206\u7c7b\u3002", "result": "Gemma 2 9B\u548cMistral 7B\u8d8a\u72f1\u6210\u529f\u738710%\uff0cQwen 2 7B\u5b8c\u5168\u5bf9\u9f50\uff080%\u6210\u529f\u7387\uff09\uff1b\u5361\u65b9\u68c0\u9a8c\u8bc1\u5b9e\u6a21\u578b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u7ed3\u679c\u63ed\u793a\u4e86\u5b89\u5168\u673a\u5236\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u5728\u63d0\u793a\u7ea7\u5b89\u5168\u548c\u5bf9\u9f50\u6d41\u7a0b\u4e2d\u9700\u7cfb\u7edf\u5904\u7406\u57fa\u4e8e\u8868\u60c5\u7b26\u53f7\u7684\u8868\u793a\u3002"}}
{"id": "2601.00965", "pdf": "https://arxiv.org/pdf/2601.00965", "abs": "https://arxiv.org/abs/2601.00965", "authors": ["Tianshuo Yang", "Ryan Rabinowitz", "Terrance E. Boult", "Jugal Kalita"], "title": "Adapting Feature Attenuation to NLP", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Transformer classifiers such as BERT deliver impressive closed-set accuracy, yet they remain brittle when confronted with inputs from unseen categories--a common scenario for deployed NLP systems. We investigate Open-Set Recognition (OSR) for text by porting the feature attenuation hypothesis from computer vision to transformers and by benchmarking it against state-of-the-art baselines. Concretely, we adapt the COSTARR framework--originally designed for classification in computer vision--to two modest language models (BERT (base) and GPT-2) trained to label 176 arXiv subject areas. Alongside COSTARR, we evaluate Maximum Softmax Probability (MSP), MaxLogit, and the temperature-scaled free-energy score under the OOSA and AUOSCR metrics. Our results show (i) COSTARR extends to NLP without retraining but yields no statistically significant gain over MaxLogit or MSP, and (ii) free-energy lags behind all other scores in this high-class-count setting. The study highlights both the promise and the current limitations of transplanting vision-centric OSR ideas to language models, and points toward the need for larger backbones and task-tailored attenuation strategies.", "AI": {"tldr": "\u7814\u7a76\u6587\u672c\u7684\u5f00\u653e\u96c6\u8bc6\u522b\uff08OSR\uff09\uff0c\u5c06\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u7279\u5f81\u8870\u51cf\u5047\u8bbe\u5e94\u7528\u4e8eTransformer\uff0c\u5bf9\u6bd4\u591a\u79cd\u65b9\u6cd5\uff0c\u6307\u51fa\u79fb\u690d\u89c6\u89c9OSR\u601d\u60f3\u5230\u8bed\u8a00\u6a21\u578b\u7684\u524d\u666f\u4e0e\u5c40\u9650\u3002", "motivation": "Transformer\u5206\u7c7b\u5668\u5728\u9762\u5bf9\u672a\u89c1\u7c7b\u522b\u8f93\u5165\u65f6\u8f83\u8106\u5f31\uff0c\u7814\u7a76\u6587\u672c\u7684\u5f00\u653e\u96c6\u8bc6\u522b\u3002", "method": "\u5c06COSTARR\u6846\u67b6\u5e94\u7528\u4e8e\u4e24\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u8bc4\u4f30MSP\u3001MaxLogit\u548c\u6e29\u5ea6\u7f29\u653e\u81ea\u7531\u80fd\u5f97\u5206\uff0c\u4f7f\u7528OOSA\u548cAUOSCR\u6307\u6807\u3002", "result": "COSTARR\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u53ef\u6269\u5c55\u5230NLP\uff0c\u4f46\u76f8\u6bd4MaxLogit\u6216MSP\u65e0\u663e\u8457\u4f18\u52bf\uff1b\u81ea\u7531\u80fd\u5f97\u5206\u5728\u9ad8\u7c7b\u522b\u6570\u91cf\u8bbe\u7f6e\u4e2d\u843d\u540e\u3002", "conclusion": "\u79fb\u690d\u89c6\u89c9OSR\u601d\u60f3\u5230\u8bed\u8a00\u6a21\u578b\u6709\u524d\u666f\uff0c\u4f46\u4e5f\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u5927\u7684\u4e3b\u5e72\u6a21\u578b\u548c\u5b9a\u5236\u7684\u8870\u51cf\u7b56\u7565\u3002"}}
{"id": "2601.00969", "pdf": "https://arxiv.org/pdf/2601.00969", "abs": "https://arxiv.org/abs/2601.00969", "authors": ["Ali Salamatian", "Ke", "Ren", "Kieran Pattison", "Cyrus Neary"], "title": "Value Vision-Language-Action Planning & Search", "categories": ["cs.RO", "cs.AI"], "comment": "10 pages, 3 figures", "summary": "Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.", "AI": {"tldr": "\u73b0\u6709\u89c6\u89c9 - \u8bed\u8a00 - \u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u4f9d\u8d56\u884c\u4e3a\u514b\u9686\u5b58\u5728\u5c40\u9650\u6027\uff0c\u672c\u6587\u63d0\u51faV - VLAPS\u6846\u67b6\uff0c\u7528\u8f7b\u91cf\u7ea7\u53ef\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u589e\u5f3a\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\uff08MCTS\uff09\uff0c\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u63d0\u5347\u6210\u529f\u7387\u5e76\u51cf\u5c11\u6a21\u62df\u6b21\u6570\u3002", "motivation": "\u5f53\u524dVLA\u6a21\u578b\u4f9d\u8d56\u884c\u4e3a\u514b\u9686\uff0c\u5728\u5206\u5e03\u53d8\u5316\u65f6\u8868\u73b0\u8106\u5f31\uff0c\u73b0\u6709\u57fa\u4e8eMCTS\u7684\u65b9\u6cd5\u4ec5\u4f9d\u8d56VLA\u5148\u9a8c\uff0c\u7f3a\u4e4f\u5bf9\u672a\u6765\u56de\u62a5\u7684\u4f30\u8ba1\uff0c\u4e0d\u51c6\u786e\u65f6\u9700\u5927\u91cf\u6a21\u62df\u3002", "method": "\u5f15\u5165Value Vision - Language - Action Planning and Search (V - VLAPS)\u6846\u67b6\uff0c\u5728\u56fa\u5b9aVLA\u9aa8\u5e72\u7f51\u7edc\uff08Octo\uff09\u7684\u6f5c\u5728\u8868\u5f81\u4e0a\u8bad\u7ec3\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\uff0c\u4e3aMCTS\u641c\u7d22\u63d0\u4f9b\u663e\u5f0f\u6210\u529f\u4fe1\u53f7\u3002", "result": "\u5728LIBERO\u673a\u5668\u4eba\u64cd\u4f5c\u5957\u4ef6\u4e0a\u8bc4\u4f30\uff0c\u4ef7\u503c\u5f15\u5bfc\u7684\u641c\u7d22\u6bd4\u4ec5\u4f9d\u8d56VLA\u5148\u9a8c\u7684\u57fa\u7ebf\u65b9\u6cd5\u6210\u529f\u7387\u63d0\u9ad8\u8d855\u4e2a\u767e\u5206\u70b9\uff0cMCTS\u6a21\u62df\u5e73\u5747\u6b21\u6570\u51cf\u5c115 - 15%\u3002", "conclusion": "V - VLAPS\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u53ef\u5b66\u4e60\u4ef7\u503c\u51fd\u6570\u589e\u5f3aMCTS\uff0c\u6709\u6548\u63d0\u5347\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2601.00993", "pdf": "https://arxiv.org/pdf/2601.00993", "abs": "https://arxiv.org/abs/2601.00993", "authors": ["Julian D. Santamaria", "Claudia Isaza", "Jhony H. Giraldo"], "title": "WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.", "AI": {"tldr": "\u4f20\u7edf\u91ce\u751f\u52a8\u7269\u8bc6\u522b\u6a21\u578b\u5728\u8de8\u5730\u7406\u533a\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u672c\u6587\u63d0\u51faWildIng\u6a21\u578b\uff0c\u7ed3\u5408\u6587\u672c\u63cf\u8ff0\u4e0e\u56fe\u50cf\u7279\u5f81\uff0c\u63d0\u5347\u5730\u7406\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u5c06\u57fa\u7840\u6a21\u578b\u51c6\u786e\u7387\u63d0\u534730%\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\u6a21\u578b\u5728\u91ce\u751f\u52a8\u7269\u8bc6\u522b\u4e2d\u96be\u4ee5\u6cdb\u5316\u5230\u65b0\u5730\u7406\u533a\u57df\uff0c\u56e0\u4f9d\u8d56\u56fe\u50cf\u8868\u793a\uff0c\u5bf9\u5730\u7406\u6570\u636e\u5206\u5e03\u53d8\u5316\u654f\u611f\u3002", "method": "\u63d0\u51faWildIng\u6a21\u578b\uff0c\u5c06\u6587\u672c\u63cf\u8ff0\u4e0e\u56fe\u50cf\u7279\u5f81\u96c6\u6210\uff0c\u7528\u6587\u672c\u6355\u83b7\u4e00\u81f4\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eWildIng\u5728\u5730\u7406\u9886\u57df\u504f\u79fb\u6761\u4ef6\u4e0b\u5c06BioCLIP\u7b49\u57fa\u7840\u6a21\u578b\u51c6\u786e\u7387\u63d0\u534730%\uff0c\u5e76\u5728\u7f8e\u975e\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u3002", "conclusion": "WildIng\u6a21\u578b\u80fd\u6709\u6548\u63d0\u5347\u91ce\u751f\u52a8\u7269\u8bc6\u522b\u6a21\u578b\u5728\u8de8\u5730\u7406\u533a\u57df\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u6a21\u578b\u516c\u5f00\u3002"}}
{"id": "2601.00996", "pdf": "https://arxiv.org/pdf/2601.00996", "abs": "https://arxiv.org/abs/2601.00996", "authors": ["Yongxu Sun", "Michael Saxon", "Ian Yang", "Anna-Maria Gueorguieva", "Aylin Caliskan"], "title": "VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation", "categories": ["cs.CY", "cs.AI"], "comment": "The International Association for Safe & Ethical AI (IASEAI)", "summary": "Text-to-Video (T2V) generators such as Sora raise concerns about whether generated content reflects societal bias. We extend embedding-association tests from words and images to video by introducing the Video Embedding Association Test (VEAT) and Single-Category VEAT (SC-VEAT). We validate these methods by reproducing the direction and magnitude of associations from widely used baselines, including Implicit Association Test (IAT) scenarios and OASIS image categories. We then quantify race (African American vs. European American) and gender (women vs. men) associations with valence (pleasant vs. unpleasant) across 17 occupations and 7 awards. Sora videos associate European Americans and women more with pleasantness (both d>0.8). Effect sizes correlate with real-world demographic distributions: percent men and White in occupations (r=0.93, r=0.83) and percent male and non-Black among award recipients (r=0.88, r=0.99). Applying explicit debiasing prompts generally reduces effect-size magnitudes, but can backfire: two Black-associated occupations (janitor, postal service) become more Black-associated after debiasing. Together, these results reveal that easily accessible T2V generators can actually amplify representational harms if not rigorously evaluated and responsibly deployed.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165VEAT\u548cSC - VEAT\u6d4b\u8bd5T2V\u751f\u6210\u5668\u662f\u5426\u5b58\u5728\u793e\u4f1a\u504f\u89c1\uff0c\u53d1\u73b0Sora\u89c6\u9891\u6709\u4e00\u5b9a\u5173\u8054\u504f\u89c1\uff0c\u663e\u5f0f\u53bb\u504f\u53ef\u80fd\u9002\u5f97\u5176\u53cd\u3002", "motivation": "\u5173\u6ce8T2V\u751f\u6210\u5668\u5982Sora\u751f\u6210\u7684\u5185\u5bb9\u662f\u5426\u53cd\u6620\u793e\u4f1a\u504f\u89c1\u3002", "method": "\u5f15\u5165VEAT\u548cSC - VEAT\u5c06\u5d4c\u5165\u5173\u8054\u6d4b\u8bd5\u4ece\u6587\u5b57\u3001\u56fe\u50cf\u6269\u5c55\u5230\u89c6\u9891\uff0c\u91cd\u73b0\u57fa\u7ebf\u5173\u8054\u7a0b\u5ea6\u548c\u65b9\u5411\u8fdb\u884c\u9a8c\u8bc1\uff0c\u91cf\u5316\u79cd\u65cf\u3001\u6027\u522b\u4e0e\u6548\u4ef7\u5173\u8054\u3002", "result": "Sora\u89c6\u9891\u4e2d\u6b27\u6d32\u88d4\u7f8e\u56fd\u4eba\u548c\u5973\u6027\u66f4\u591a\u4e0e\u6109\u60a6\u76f8\u5173\uff0c\u6548\u5e94\u5927\u5c0f\u4e0e\u73b0\u5b9e\u4eba\u53e3\u5206\u5e03\u76f8\u5173\uff0c\u663e\u5f0f\u53bb\u504f\u4f1a\u964d\u4f4e\u6548\u5e94\u5927\u5c0f\uff0c\u4f46\u5bf9\u90e8\u5206\u804c\u4e1a\u53ef\u80fd\u9002\u5f97\u5176\u53cd\u3002", "conclusion": "\u6613\u83b7\u53d6\u7684T2V\u751f\u6210\u5668\u82e5\u4e0d\u4e25\u683c\u8bc4\u4f30\u548c\u59a5\u5584\u90e8\u7f72\uff0c\u4f1a\u653e\u5927\u4ee3\u8868\u6027\u4f24\u5bb3\u3002"}}
{"id": "2601.01005", "pdf": "https://arxiv.org/pdf/2601.01005", "abs": "https://arxiv.org/abs/2601.01005", "authors": ["Zihan Li", "Dandan Shan", "Yunxiang Li", "Paul E. Kinahan", "Qingqi Hong"], "title": "Scale-aware Adaptive Supervised Network with Limited Medical Annotations", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted by Pattern Recognition, 8 figures, 11 tables", "summary": "Medical image segmentation faces critical challenges in semi-supervised learning scenarios due to severe annotation scarcity requiring expert radiological knowledge, significant inter-annotator variability across different viewpoints and expertise levels, and inadequate multi-scale feature integration for precise boundary delineation in complex anatomical structures. Existing semi-supervised methods demonstrate substantial performance degradation compared to fully supervised approaches, particularly in small target segmentation and boundary refinement tasks. To address these fundamental challenges, we propose SASNet (Scale-aware Adaptive Supervised Network), a dual-branch architecture that leverages both low-level and high-level feature representations through novel scale-aware adaptive reweight mechanisms. Our approach introduces three key methodological innovations, including the Scale-aware Adaptive Reweight strategy that dynamically weights pixel-wise predictions using temporal confidence accumulation, the View Variance Enhancement mechanism employing 3D Fourier domain transformations to simulate annotation variability, and segmentation-regression consistency learning through signed distance map algorithms for enhanced boundary precision. These innovations collectively address the core limitations of existing semi-supervised approaches by integrating spatial, temporal, and geometric consistency principles within a unified optimization framework. Comprehensive evaluation across LA, Pancreas-CT, and BraTS datasets demonstrates that SASNet achieves superior performance with limited labeled data, surpassing state-of-the-art semi-supervised methods while approaching fully supervised performance levels. The source code for SASNet is available at https://github.com/HUANGLIZI/SASNet.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u533b\u5b66\u56fe\u50cf\u534a\u76d1\u7763\u5206\u5272\u5b58\u5728\u6807\u6ce8\u7a00\u7f3a\u7b49\u6311\u6218\uff0c\u63d0\u51faSASNet\u7f51\u7edc\uff0c\u6709\u4e09\u9879\u521b\u65b0\u65b9\u6cd5\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u8d85\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\uff0c\u63a5\u8fd1\u5168\u76d1\u7763\u6c34\u5e73\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u534a\u76d1\u7763\u5b66\u4e60\u5b58\u5728\u6807\u6ce8\u7a00\u7f3a\u3001\u6807\u6ce8\u8005\u5dee\u5f02\u5927\u3001\u591a\u5c3a\u5ea6\u7279\u5f81\u96c6\u6210\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\u6027\u80fd\u5dee\u3002", "method": "\u63d0\u51faSASNet\u53cc\u5206\u652f\u67b6\u6784\uff0c\u91c7\u7528\u5c3a\u5ea6\u611f\u77e5\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u7b56\u7565\u3001\u89c6\u56fe\u65b9\u5dee\u589e\u5f3a\u673a\u5236\u3001\u5206\u5272 - \u56de\u5f52\u4e00\u81f4\u6027\u5b66\u4e60\u3002", "result": "\u5728LA\u3001Pancreas - CT\u548cBraTS\u6570\u636e\u96c6\u4e0a\uff0cSASNet\u7528\u6709\u9650\u6807\u6ce8\u6570\u636e\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\uff0c\u8d85\u8d8a\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\uff0c\u63a5\u8fd1\u5168\u76d1\u7763\u6c34\u5e73\u3002", "conclusion": "SASNet\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\u7684\u6838\u5fc3\u5c40\u9650\uff0c\u5728\u533b\u5b66\u56fe\u50cf\u534a\u76d1\u7763\u5206\u5272\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2601.01008", "pdf": "https://arxiv.org/pdf/2601.01008", "abs": "https://arxiv.org/abs/2601.01008", "authors": ["Md Rashadul Islam"], "title": "An Explainable Agentic AI Framework for Uncertainty-Aware and Abstention-Enabled Acute Ischemic Stroke Imaging Decisions", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Preprint. Conceptual and exploratory framework focusing on uncertainty-aware and abstention-enabled decision support for acute ischemic stroke imaging", "summary": "Artificial intelligence models have shown strong potential in acute ischemic stroke imaging, particularly for lesion detection and segmentation using computed tomography and magnetic resonance imaging. However, most existing approaches operate as black box predictors, producing deterministic outputs without explicit uncertainty awareness or structured mechanisms to abstain under ambiguous conditions. This limitation raises serious safety and trust concerns in high risk emergency radiology settings. In this paper, we propose an explainable agentic AI framework for uncertainty aware and abstention enabled decision support in acute ischemic stroke imaging. The framework follows a modular agentic pipeline in which a perception agent performs lesion aware image analysis, an uncertainty estimation agent computes slice level predictive reliability, and a decision agent determines whether to issue a prediction or abstain based on predefined uncertainty thresholds. Unlike prior stroke imaging systems that primarily focus on improving segmentation or classification accuracy, the proposed framework explicitly prioritizes clinical safety, transparency, and clinician aligned decision behavior. Qualitative and case based analyses across representative stroke imaging scenarios demonstrate that uncertainty driven abstention naturally emerges in diagnostically ambiguous regions and low information slices. The framework further integrates visual explanation mechanisms to support both predictive and abstention decisions, addressing a key limitation of existing uncertainty aware medical imaging systems. Rather than introducing a new performance benchmark, this work presents agentic control, uncertainty awareness, and selective abstention as essential design principles for developing safe and trustworthy medical imaging AI systems.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u6025\u6027\u7f3a\u8840\u6027\u4e2d\u98ce\u6210\u50cf\u7684\u53ef\u89e3\u91ca\u4ee3\u7406AI\u6846\u67b6\uff0c\u5f3a\u8c03\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u548c\u9009\u62e9\u6027\u5f03\u6743\uff0c\u6ce8\u91cd\u4e34\u5e8a\u5b89\u5168\u548c\u900f\u660e\u6027\u3002", "motivation": "\u73b0\u6709\u4e2d\u98ce\u6210\u50cfAI\u6a21\u578b\u591a\u4e3a\u9ed1\u76d2\u9884\u6d4b\uff0c\u65e0\u660e\u786e\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u548c\u5f03\u6743\u673a\u5236\uff0c\u5f15\u53d1\u5b89\u5168\u548c\u4fe1\u4efb\u95ee\u9898\u3002", "method": "\u6784\u5efa\u6a21\u5757\u5316\u4ee3\u7406\u7ba1\u9053\uff0c\u5305\u62ec\u611f\u77e5\u4ee3\u7406\u3001\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4ee3\u7406\u548c\u51b3\u7b56\u4ee3\u7406\uff0c\u4f9d\u636e\u4e0d\u786e\u5b9a\u6027\u9608\u503c\u51b3\u5b9a\u662f\u5426\u8f93\u51fa\u9884\u6d4b\u3002", "result": "\u5b9a\u6027\u548c\u6848\u4f8b\u5206\u6790\u663e\u793a\uff0c\u5728\u8bca\u65ad\u6a21\u7cca\u533a\u57df\u548c\u4f4e\u4fe1\u606f\u5207\u7247\u4f1a\u81ea\u7136\u51fa\u73b0\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u5f03\u6743\uff0c\u6846\u67b6\u8fd8\u96c6\u6210\u89c6\u89c9\u89e3\u91ca\u673a\u5236\u3002", "conclusion": "\u4ee3\u7406\u63a7\u5236\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u548c\u9009\u62e9\u6027\u5f03\u6743\u662f\u5f00\u53d1\u5b89\u5168\u53ef\u9760\u533b\u5b66\u6210\u50cfAI\u7cfb\u7edf\u7684\u5173\u952e\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2601.01011", "pdf": "https://arxiv.org/pdf/2601.01011", "abs": "https://arxiv.org/abs/2601.01011", "authors": ["Patricio Vera"], "title": "Intention Collapse: Intention-Level Metrics for Reasoning in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "21 pages, 4 figures, 3 tables. Code: https://github.com/patriciomvera/intention-collapse-experiments", "summary": "Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability Recov), and propose an empirical agenda for studying how inference time computation shapes internal intentions before they are verbalized. We also report a first small scale experiment. Using a 4 bit Mistral 7B model on 200 GSM8K problems, we compare a direct answer baseline, a chain of thought (CoT) regime, and a babble control. CoT raises accuracy from 5.5 percent to 53 percent, sharply reduces pre collapse intention entropy (from 1.42 to 0.37 bits), and shows higher global effective dimensionality than the other regimes despite producing fewer tokens than babble. At the same time, Hint has little item level predictive power, and a linear probe on I achieves AUROC 0.65 in the CoT regime but only about chance in the baseline regime, where it collapses to the majority class. These preliminary results indicate that intention level metrics can distinguish inference regimes and expose latent information that is partly lost during collapse, while also revealing important limitations of our current proxies", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u610f\u56fe\u574d\u7f29\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e09\u4e2a\u610f\u56fe\u6307\u6807\uff0c\u5f00\u5c55\u5c0f\u89c4\u6a21\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u610f\u56fe\u6307\u6807\u80fd\u533a\u5206\u63a8\u7406\u673a\u5236\u5e76\u63ed\u793a\u6f5c\u5728\u4fe1\u606f\uff0c\u4f46\u5f53\u524d\u4ee3\u7406\u6709\u5c40\u9650\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u751f\u6210\u4e2d\u5185\u90e8\u72b6\u6001\u538b\u7f29\u4e3a\u5355\u4e00\u4ee4\u724c\u5e8f\u5217\u7684\u8fc7\u7a0b\uff0c\u5373\u610f\u56fe\u574d\u7f29\uff0c\u63a2\u7d22\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\u5982\u4f55\u5851\u9020\u5185\u90e8\u610f\u56fe\u3002", "method": "\u5f62\u5f0f\u5316\u5f53\u4ee3\u8bed\u8a00\u6a21\u578b\u7684\u610f\u56fe\u574d\u7f29\uff0c\u5b9a\u4e49\u4e09\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u610f\u56fe\u6307\u6807\uff0c\u75284\u4f4dMistral 7B\u6a21\u578b\u5728200\u4e2aGSM8K\u95ee\u9898\u4e0a\u5bf9\u6bd4\u76f4\u63a5\u56de\u7b54\u3001\u601d\u7ef4\u94fe\uff08CoT\uff09\u548c\u80e1\u8a00\u4e71\u8bed\u63a7\u5236\u4e09\u79cd\u673a\u5236\u3002", "result": "CoT\u5c06\u51c6\u786e\u7387\u4ece5.5%\u63d0\u9ad8\u523053%\uff0c\u5927\u5e45\u964d\u4f4e\u574d\u7f29\u524d\u610f\u56fe\u71b5\uff0c\u5168\u5c40\u6709\u6548\u7ef4\u5ea6\u66f4\u9ad8\uff1bHint\u5728\u9879\u76ee\u5c42\u9762\u9884\u6d4b\u529b\u5f31\uff0c\u7ebf\u6027\u63a2\u9488\u5728CoT\u673a\u5236\u4e0b\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u610f\u56fe\u5c42\u9762\u6307\u6807\u53ef\u533a\u5206\u63a8\u7406\u673a\u5236\u5e76\u63ed\u793a\u90e8\u5206\u574d\u7f29\u4e2d\u4e22\u5931\u7684\u6f5c\u5728\u4fe1\u606f\uff0c\u4f46\u5f53\u524d\u4ee3\u7406\u5b58\u5728\u91cd\u8981\u5c40\u9650\u3002"}}
{"id": "2601.01014", "pdf": "https://arxiv.org/pdf/2601.01014", "abs": "https://arxiv.org/abs/2601.01014", "authors": ["Haoran Su", "Chenyu You"], "title": "Geometric and Dynamic Scaling in Deep Transformers", "categories": ["cs.LG", "cs.AI"], "comment": "Research Proposal Only", "summary": "Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.", "AI": {"tldr": "\u6df1\u5c42Transformer\u67b6\u6784\u5b58\u5728\u8868\u5f81\u5197\u4f59\u548c\u79e9\u5d29\u6e83\u95ee\u9898\uff0c\u672c\u6587\u8ba4\u4e3a\u8fd9\u662f\u51e0\u4f55\u95ee\u9898\u5e76\u63d0\u51fa\u6d41\u5f62\u51e0\u4f55Transformer\uff08MGT\uff09\u89e3\u51b3\u3002", "motivation": "\u73b0\u6709\u5bf9\u6df1\u5c42Transformer\u5d29\u6e83\u7684\u89e3\u91ca\u65e0\u6cd5\u8bf4\u660e\u5728\u73b0\u4ee3\u5f52\u4e00\u5316\u548c\u521d\u59cb\u5316\u65b9\u6848\u4e0b\u5d29\u6e83\u4ecd\u5b58\u5728\u7684\u539f\u56e0\uff0c\u9700\u65b0\u89d2\u5ea6\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u51e0\u4f55\u6846\u67b6\uff0c\u542b\u6d41\u5f62\u7ea6\u675f\u8d85\u8fde\u63a5\u548c\u6df1\u5ea6\u589e\u91cf\u5b66\u4e60\u4e24\u4e2a\u6b63\u4ea4\u539f\u5219\uff0c\u5f62\u6210MGT\u67b6\u6784\u3002", "result": "\u5206\u6790\u8868\u660e\u5728\u8d85\u6df1\u5c42\u7f51\u7edc\u4e2d\uff0c\u4fdd\u8bc1\u51e0\u4f55\u6709\u6548\u6027\u548c\u52a8\u6001\u64e6\u9664\u5bf9\u907f\u514d\u79e9\u5d29\u6e83\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u63d0\u51fa\u8bc4\u4f30\u8d85100\u5c42Transformer\u7684\u534f\u8bae\uff0c\u9a8c\u8bc1\u51e0\u4f55\u662f\u6df1\u5ea6\u8868\u5f81\u5b66\u4e60\u7684\u5173\u952e\u9650\u5236\u56e0\u7d20\u800c\u975e\u6df1\u5ea6\u672c\u8eab\u3002"}}
{"id": "2601.01016", "pdf": "https://arxiv.org/pdf/2601.01016", "abs": "https://arxiv.org/abs/2601.01016", "authors": ["Ata Akbari Asanjan", "Milad Memarzadeh", "Bryan Matthews", "Nikunj Oza"], "title": "Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study", "categories": ["cs.LG", "cs.AI", "eess.SY"], "comment": null, "summary": "In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u968f\u673a\u5085\u91cc\u53f6\u53d8\u6362\uff08RFT\uff09\u6539\u8fdb\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u5206\u6790\u5176\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u4f5c\u7528\uff0c\u5f15\u5165\u53ef\u8bad\u7ec3\u7684RFT\u53d8\u4f53\u5e76\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u3002", "motivation": "\u6539\u8fdb\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08\u81ea\u7f16\u7801\u5668\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff09\u7684\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u63a2\u7a76RFT\u5728\u6a21\u578b\u8bad\u7ec3\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\u4ee5\u53ca\u5728\u57fa\u4e8e\u91cd\u6784\u7684\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u89d2\u8272\u3002", "method": "\u91c7\u7528\u968f\u673a\u5085\u91cc\u53f6\u53d8\u6362\uff0c\u7528\u9891\u7387\u539f\u7406\uff08F - \u539f\u7406\uff09\u5206\u6790RFT\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u8868\u73b0\uff0c\u5f15\u5165\u53ef\u8bad\u7ec3\u7684RFT\u53d8\u4f53\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u3002", "result": "\u5e26\u5085\u91cc\u53f6\u53d8\u6362\u7684\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u4f46\u53ef\u8bad\u7ec3\u5085\u91cc\u53f6\u53d8\u6362\u76f8\u6bd4\u968f\u673a\u5085\u91cc\u53f6\u53d8\u6362\u7684\u4f18\u52bf\u672a\u660e\u786e\u3002", "conclusion": "\u5085\u91cc\u53f6\u53d8\u6362\u53ef\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u53ef\u8bad\u7ec3\u5085\u91cc\u53f6\u53d8\u6362\u662f\u5426\u66f4\u4f18\u5c1a\u65e0\u5b9a\u8bba\u3002"}}
{"id": "2601.01022", "pdf": "https://arxiv.org/pdf/2601.01022", "abs": "https://arxiv.org/abs/2601.01022", "authors": ["Shiao Wang", "Xiao Wang", "Haonan Zhao", "Jiarui Xu", "Bo Jiang", "Lin Zhu", "Xin Zhao", "Yonghong Tian", "Jin Tang"], "title": "Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9891\u57df\u65e9\u671f\u878d\u5408\u7684\u8ddf\u8e2a\u6846\u67b6\uff0c\u7ed3\u5408\u8fd0\u52a8\u5f15\u5bfc\u7a7a\u95f4\u7a00\u758f\u5316\u6a21\u5757\u63d0\u5347\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90", "motivation": "\u73b0\u6709RGB - Event\u89c6\u89c9\u76ee\u6807\u8ddf\u8e2a\u65b9\u6cd5\u4e3b\u8981\u91c7\u7528\u4f20\u7edf\u7279\u5f81\u7ea7\u878d\u5408\uff0c\u672a\u5145\u5206\u5229\u7528\u4e8b\u4ef6\u76f8\u673a\u4f18\u52bf\uff0c\u5b58\u5728\u5904\u7406\u4f4e\u4fe1\u606f\u533a\u57df\u8ba1\u7b97\u5f00\u9500\u5927\u95ee\u9898", "method": "\u5728\u9891\u57df\u6267\u884c\u65e9\u671f\u878d\u5408\uff0c\u901a\u8fc7\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\u5c06RGB\u548c\u4e8b\u4ef6\u6a21\u6001\u4ece\u7a7a\u95f4\u57df\u8f6c\u6362\u5230\u9891\u57df\uff0c\u89e3\u8026\u5e45\u503c\u548c\u76f8\u4f4d\u5206\u91cf\uff0c\u5229\u7528\u5e45\u503c\u548c\u76f8\u4f4d\u6ce8\u610f\u529b\u878d\u5408\u9ad8\u9891\u4e8b\u4ef6\u4fe1\u606f\u3002\u91c7\u7528\u8fd0\u52a8\u5f15\u5bfc\u7a7a\u95f4\u7a00\u758f\u5316\u6a21\u5757\u8fc7\u6ee4\u4f4e\u4fe1\u606f\u533a\u57df\uff0c\u5c06\u76ee\u6807\u76f8\u5173\u7279\u5f81\u96c6\u8f93\u5165\u4e3b\u5e72\u7f51\u7edc\u5b66\u4e60\uff0c\u8ddf\u8e2a\u5934\u9884\u6d4b\u76ee\u6807\u4f4d\u7f6e", "result": "\u5728FE108\u3001FELT\u548cCOESOT\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u9ad8\u6027\u80fd\u548c\u6709\u6548\u6027", "conclusion": "\u6240\u63d0\u8ddf\u8e2a\u6846\u67b6\u5177\u6709\u9ad8\u6027\u80fd\u548c\u9ad8\u6548\u6027\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898"}}
{"id": "2601.01027", "pdf": "https://arxiv.org/pdf/2601.01027", "abs": "https://arxiv.org/abs/2601.01027", "authors": ["Rafael Wampfler", "Chen Yang", "Dillon Elste", "Nikola Kovacevic", "Philine Witzig", "Markus Gross"], "title": "A Platform for Interactive AI Character Experiences", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.GR"], "comment": null, "summary": "From movie characters to modern science fiction - bringing characters into interactive, story-driven conversations has captured imaginations across generations. Achieving this vision is highly challenging and requires much more than just language modeling. It involves numerous complex AI challenges, such as conversational AI, maintaining character integrity, managing personality and emotions, handling knowledge and memory, synthesizing voice, generating animations, enabling real-world interactions, and integration with physical environments. Recent advancements in the development of foundation models, prompt engineering, and fine-tuning for downstream tasks have enabled researchers to address these individual challenges. However, combining these technologies for interactive characters remains an open problem. We present a system and platform for conveniently designing believable digital characters, enabling a conversational and story-driven experience while providing solutions to all of the technical challenges. As a proof-of-concept, we introduce Digital Einstein, which allows users to engage in conversations with a digital representation of Albert Einstein about his life, research, and persona. While Digital Einstein exemplifies our methods for a specific character, our system is flexible and generalizes to any story-driven or conversational character. By unifying these diverse AI components into a single, easy-to-adapt platform, our work paves the way for immersive character experiences, turning the dream of lifelike, story-based interactions into a reality.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u642d\u5efa\u4fbf\u6377\u8bbe\u8ba1\u53ef\u4fe1\u6570\u5b57\u89d2\u8272\u7684\u7cfb\u7edf\u4e0e\u5e73\u53f0\uff0c\u4ee5Digital Einstein\u4e3a\u4f8b\uff0c\u5c06\u591a\u6837AI\u7ec4\u4ef6\u6574\u5408\uff0c\u63a8\u52a8\u903c\u771f\u89d2\u8272\u4e92\u52a8\u4f53\u9a8c\u6210\u4e3a\u73b0\u5b9e\u3002", "motivation": "\u5b9e\u73b0\u5c06\u89d2\u8272\u5e26\u5165\u4ea4\u4e92\u5f0f\u3001\u6545\u4e8b\u9a71\u52a8\u5bf9\u8bdd\u9762\u4e34\u8bf8\u591a\u590d\u6742AI\u6311\u6218\uff0c\u867d\u6709\u6280\u672f\u8fdb\u5c55\uff0c\u4f46\u7ed3\u5408\u6280\u672f\u6253\u9020\u4ea4\u4e92\u5f0f\u89d2\u8272\u4ecd\u662f\u96be\u9898\u3002", "method": "\u642d\u5efa\u7cfb\u7edf\u548c\u5e73\u53f0\uff0c\u6574\u5408\u57fa\u7840\u6a21\u578b\u3001\u63d0\u793a\u5de5\u7a0b\u548c\u5fae\u8c03\u7b49\u6280\u672f\u4ee5\u89e3\u51b3\u5404\u9879\u6280\u672f\u6311\u6218\u3002", "result": "\u63a8\u51faDigital Einstein\u8ba9\u7528\u6237\u4e0e\u6570\u5b57\u7231\u56e0\u65af\u5766\u5bf9\u8bdd\uff0c\u7cfb\u7edf\u7075\u6d3b\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u6545\u4e8b\u6216\u5bf9\u8bdd\u89d2\u8272\u3002", "conclusion": "\u5c06\u591a\u6837AI\u7ec4\u4ef6\u7edf\u4e00\u5230\u6613\u9002\u914d\u5e73\u53f0\uff0c\u4e3a\u6c89\u6d78\u5f0f\u89d2\u8272\u4f53\u9a8c\u94fa\u5e73\u9053\u8def\uff0c\u8ba9\u68a6\u60f3\u6210\u771f\u3002"}}
{"id": "2601.01037", "pdf": "https://arxiv.org/pdf/2601.01037", "abs": "https://arxiv.org/abs/2601.01037", "authors": ["Livia Leong Hui Teng"], "title": "Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.", "AI": {"tldr": "\u63d0\u51fa\u591a\u7ef4\u63d0\u793a\u94fe\u6846\u67b6\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u5f00\u653e\u57df\u5bf9\u8bdd\u8d28\u91cf\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u6709\u663e\u8457\u6548\u679c\uff0c\u5c0f\u6a21\u578b\u53ef\u5ab2\u7f8e\u5927\u6a21\u578b\u3002", "motivation": "\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u57df\u5bf9\u8bdd\u8d28\u91cf\u4e0a\u96be\u4ee5\u5339\u654c\u5927\u6a21\u578b\uff0c\u9700\u63d0\u5347\u5176\u5bf9\u8bdd\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u6574\u5408\u81ea\u7136\u5ea6\u3001\u8fde\u8d2f\u6027\u548c\u5438\u5f15\u529b\u7ef4\u5ea6\u7684\u591a\u7ef4\u63d0\u793a\u94fe\u6846\u67b6\uff0c\u5e94\u7528\u4e8eTinyLlama\u548cLlama - 2 - 7B\uff0c\u4e0e\u5927\u6a21\u578b\u5bf9\u6bd4\uff0c\u5e76\u8fdb\u884c\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u3002", "result": "\u5b8c\u6574\u6846\u67b6\u4f7f\u56de\u590d\u591a\u6837\u6027\u63d0\u534729%\u3001\u4e0a\u4e0b\u6587\u8fde\u8d2f\u6027\u63d0\u534728%\u3001\u5438\u5f15\u529b\u548c\u81ea\u7136\u5ea6\u63d0\u534729%\uff0cLlama - 2 - 7B\u6027\u80fd\u53ef\u5ab2\u7f8e\u5927\u6a21\u578b\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u7b56\u7565\u662f\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u5f00\u653e\u57df\u5bf9\u8bdd\u8d28\u91cf\u7684\u6709\u6548\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2601.01050", "pdf": "https://arxiv.org/pdf/2601.01050", "abs": "https://arxiv.org/abs/2601.01050", "authors": ["Hongming Fu", "Wenjia Wang", "Xiaozhen Qiao", "Shuo Yang", "Zheng Liu", "Bo Zhao"], "title": "EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": null, "summary": "We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.", "AI": {"tldr": "\u63d0\u51faEgoGrasp\u65b9\u6cd5\u4ece\u7b2c\u4e00\u4eba\u79f0\u5355\u76ee\u89c6\u9891\u91cd\u5efa\u4e16\u754c\u7a7a\u95f4\u624b-\u5bf9\u8c61\u4ea4\u4e92\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8fbe\u5230SOTA\u6c34\u5e73\u3002", "motivation": "\u51c6\u786e\u7684\u4e16\u754c\u7a7a\u95f4\u624b-\u5bf9\u8c61\u4ea4\u4e92\u91cd\u5efa\u5bf9\u7406\u89e3\u4eba\u7c7b\u884c\u4e3a\u548c\u76f8\u5173\u5e94\u7528\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5904\u7406\u65f6\u95f4\u52a8\u6001\u3001\u5168\u5c40\u8f68\u8ff9\uff0c\u4e14\u5728\u76f8\u673a\u8fd0\u52a8\u548c\u906e\u6321\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ec\u57fa\u4e8e\u7a7a\u95f4\u667a\u80fd\u6a21\u578b\u7684\u9884\u5904\u7406\u5668\u3001\u57fa\u4e8e\u89e3\u8026\u6269\u6563\u6a21\u578b\u7684\u5168\u8eab\u624b-\u5bf9\u8c61\u4ea4\u4e92\u5148\u9a8c\u6a21\u578b\u548c\u591a\u76ee\u6807\u6d4b\u8bd5\u65f6\u4f18\u5316\u8303\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u5728\u4e16\u754c\u7a7a\u95f4\u624b-\u5bf9\u8c61\u4ea4\u4e92\u91cd\u5efa\u4e2d\u8fbe\u5230\u4e86SOTA\u6027\u80fd\u3002", "conclusion": "EgoGrasp\u662f\u89e3\u51b3\u91ce\u5916\u52a8\u6001\u76f8\u673a\u7b2c\u4e00\u4eba\u79f0\u5355\u76ee\u89c6\u9891\u4e2d\u4e16\u754c\u7a7a\u95f4\u624b-\u5bf9\u8c61\u4ea4\u4e92\u91cd\u5efa\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2601.01056", "pdf": "https://arxiv.org/pdf/2601.01056", "abs": "https://arxiv.org/abs/2601.01056", "authors": ["Ifeanyi Ezuma", "Ugochukwu Ugwu"], "title": "Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 8 figures. Code and datasets available upon request", "summary": "The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\\% and an average AUC of 96.8\\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\\% and accuracy of 99.84\\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728LC25000\u6570\u636e\u96c6\u4e0a\u5bf9\u75c5\u7406\u56fe\u50cf\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u5fae\u8c03InceptionResNet - v2\u53ca\u7ed3\u5408\u6df1\u5ea6\u7279\u5f81\u7684\u6a21\u578b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u6570\u5b57\u75c5\u7406\u65f6\u4ee3\uff0c\u81ea\u52a8\u56fe\u50cf\u5206\u6790\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8bc4\u4f30\u76f8\u5173\u6a21\u578b\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5fae\u8c03\u7684InceptionResNet - v2\u7f51\u7edc\u4f5c\u4e3a\u5206\u7c7b\u5668\u548c\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u8fd8\u7ed3\u5408HOG\u548c\u6df1\u5ea6\u7279\u5f81\u7b49\u3002", "result": "\u5fae\u8c03\u7684InceptionResNet - v2\u5206\u7c7b\u51c6\u786e\u738796.01%\u3001\u5e73\u5747AUC 96.8%\uff1b\u57fa\u4e8e\u6df1\u5ea6\u7279\u5f81\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0c\u5982\u795e\u7ecf\u7f51\u7edc\u6a21\u578bAUC 99.99%\u3001\u51c6\u786e\u738799.84%\uff1b\u5728\u4e0d\u540cSNR\u6761\u4ef6\u4e0b\uff0c\u4f7f\u7528\u6df1\u5ea6\u7279\u5f81\u7684\u6a21\u578b\u66f4\u5177\u9c81\u68d2\u6027\uff0cGBM\u548cKNN\u5c24\u4e3a\u7a81\u51fa\uff1bHOG\u548c\u6df1\u5ea6\u7279\u5f81\u7ed3\u5408\u5728\u566a\u58f0\u73af\u5883\u4e2d\u8868\u73b0\u7a0d\u900a\u3002", "conclusion": "\u4f7f\u7528\u6df1\u5ea6\u7279\u5f81\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u7ec4\u7ec7\u75c5\u7406\u5b66\u56fe\u50cf\u5206\u7c7b\u4e2d\u8868\u73b0\u66f4\u4f18\u4e14\u66f4\u5177\u9c81\u68d2\u6027\uff0c\u53ef\u7528\u4e8e\u81ea\u52a8\u56fe\u50cf\u5206\u6790\u3002"}}
{"id": "2601.01061", "pdf": "https://arxiv.org/pdf/2601.01061", "abs": "https://arxiv.org/abs/2601.01061", "authors": ["Yajing Liu", "Erkao Bao", "Linqi Song"], "title": "A UCB Bandit Algorithm for General ML-Based Estimators", "categories": ["cs.LG", "cs.AI", "math.PR"], "comment": "15 pages, 4 figures, 1 table, Multi-Arm bandit, psi-UCB, generalized machine learning models", "summary": "We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB", "AI": {"tldr": "\u63d0\u51faML - UCB\u7b97\u6cd5\uff0c\u5c06\u673a\u5668\u5b66\u4e60\u6a21\u578b\u96c6\u6210\u5230\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\uff0c\u53ef\u51cf\u5c11\u7406\u8bba\u5206\u6790\uff0c\u5b9e\u9a8c\u8868\u660e\u6bd4LinUCB\u6709\u6539\u8fdb\u3002", "motivation": "\u5728\u5e8f\u8d2f\u51b3\u7b56\u4e2d\u4f7f\u7528\u590d\u6742\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\u7f3a\u4e4f\u6709\u6548\u63a2\u7d22\u6240\u9700\u7684\u53ef\u5904\u7406\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u3002", "method": "\u76f4\u63a5\u5bf9\u5e95\u5c42\u4f30\u8ba1\u5668\u7684\u5b66\u4e60\u66f2\u7ebf\u8fdb\u884c\u5efa\u6a21\uff0c\u5047\u8bbe\u5747\u65b9\u8bef\u5dee\u968f\u8bad\u7ec3\u6837\u672c\u6570\u5448\u5e42\u5f8b\u4e0b\u964d\uff0c\u63a8\u5bfc\u5e7f\u4e49\u96c6\u4e2d\u4e0d\u7b49\u5f0f\u3002", "result": "\u8bc1\u660eML - UCB\u53ef\u5b9e\u73b0\u6b21\u7ebf\u6027\u9057\u61be\uff0c\u5728\u534f\u540c\u8fc7\u6ee4\u63a8\u8350\u7cfb\u7edf\u5b9e\u9a8c\u4e2d\u6bd4LinUCB\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u5b9e\u73b0\u4efb\u610f\u5b66\u4e60\u66f2\u7ebf\u53ef\u7ecf\u9a8c\u8868\u5f81\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u96c6\u6210\uff0c\u65e0\u9700\u7279\u5b9a\u6a21\u578b\u7406\u8bba\u5206\u6790\u3002"}}
{"id": "2601.01062", "pdf": "https://arxiv.org/pdf/2601.01062", "abs": "https://arxiv.org/abs/2601.01062", "authors": ["Yunlin Zeng"], "title": "SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "14 pages, 3 figures. Accepted to WVAQ 2026, WACV 2026", "summary": "Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\\% win rate) and narrative depth (+50\\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).", "AI": {"tldr": "\u63d0\u51fa\u7aef\u5230\u7aef\u89c6\u89c9\u64ad\u5ba2\u751f\u6210\u7ba1\u9053\uff0c\u5fae\u8c03Qwen3 - VL - 32B\u6a21\u578b\uff0c\u91c7\u7528\u5408\u6210\u5230\u771f\u5b9e\u8bad\u7ec3\u7b56\u7565\uff0c\u63d0\u51fa\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u5fae\u8c03\u6a21\u578b\u5728\u5bf9\u8bdd\u81ea\u7136\u5ea6\u548c\u53d9\u4e8b\u6df1\u5ea6\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u591a\u8bf4\u8bdd\u8005\u64ad\u5ba2\u5bf9\u8bdd\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u4e14\u96be\u8bc4\u4f30\uff0c\u6807\u51c6\u6307\u6807\u4e0d\u80fd\u6709\u6548\u8861\u91cf\u5bf9\u8bdd\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u89c6\u89c9\u64ad\u5ba2\u751f\u6210\u7ba1\u9053\uff0c\u57284000\u4e2a\u56fe\u50cf - \u5bf9\u8bdd\u5bf9\u6570\u636e\u96c6\u4e0a\u5fae\u8c03Qwen3 - VL - 32B\u6a21\u578b\uff0c\u91c7\u7528\u5408\u6210\u5230\u771f\u5b9e\u8bad\u7ec3\u7b56\u7565\uff0c\u63d0\u51fa\u8d85\u8d8a\u6587\u672c\u91cd\u53e0\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5fae\u8c03\u540e\u768432B\u6a21\u578b\u5728\u5bf9\u8bdd\u81ea\u7136\u5ea6\uff08\u80dc\u7387\u8d8580%\uff09\u548c\u53d9\u4e8b\u6df1\u5ea6\uff08\u8f6e\u6b21\u957f\u5ea6\u589e\u52a050%\uff09\u4e0a\u663e\u8457\u4f18\u4e8e235B\u57fa\u7840\u6a21\u578b\uff0c\u89c6\u89c9\u57fa\u7840\u80fd\u529b\u76f8\u540c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u8bc4\u4f30\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u8bf4\u8bdd\u8005\u64ad\u5ba2\u5bf9\u8bdd\u7684\u80fd\u529b\u3002"}}
{"id": "2601.01073", "pdf": "https://arxiv.org/pdf/2601.01073", "abs": "https://arxiv.org/abs/2601.01073", "authors": ["Erica Coppolillo", "Emilio Ferrara"], "title": "Gendered Pathways in AI Companionship: Cross-Community Behavior and Toxicity Patterns on Reddit", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "AI-companionship platforms are rapidly reshaping how people form emotional, romantic, and parasocial bonds with non-human agents, raising new questions about how these relationships intersect with gendered online behavior and exposure to harmful content. Focusing on the MyBoyfriendIsAI (MBIA) subreddit, we reconstruct the Reddit activity histories of more than 3,000 highly engaged users over two years, yielding over 67,000 historical submissions. We then situate MBIA within a broader ecosystem by building a historical interaction network spanning more than 2,000 subreddits, which enables us to trace cross-community pathways and measure how toxicity and emotional expression vary across these trajectories. We find that MBIA users primarily traverse four surrounding community spheres (AI-companionship, porn-related, forum-like, and gaming) and that participation across the ecosystem exhibits a distinct gendered structure, with substantial engagement by female users. While toxicity is generally low across most pathways, we observe localized spikes concentrated in a small subset of AI-porn and gender-oriented communities. Nearly 16% of users engage with gender-focused subreddits, and their trajectories display systematically different patterns of emotional expression and elevated toxicity, suggesting that a minority of gendered pathways may act as toxicity amplifiers within the broader AI-companionship ecosystem. These results characterize the gendered structure of cross-community participation around AI companionship on Reddit and highlight where risks concentrate, informing measurement, moderation, and design practices for human-AI relationship platforms.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790MyBoyfriendIsAI\u5b50\u7248\u5757\u8d853000\u7528\u6237\u6d3b\u52a8\uff0c\u53d1\u73b0AI\u966a\u4f34\u751f\u6001\u8de8\u793e\u533a\u53c2\u4e0e\u6709\u6027\u522b\u7ed3\u6784\uff0c\u90e8\u5206\u6027\u522b\u5316\u8def\u5f84\u53ef\u80fd\u653e\u5927\u6bd2\u6027\u3002", "motivation": "\u63a2\u8ba8AI\u966a\u4f34\u5e73\u53f0\u4e2d\u4eba\u9645\u5173\u7cfb\u4e0e\u6027\u522b\u5316\u7f51\u7edc\u884c\u4e3a\u3001\u6709\u5bb3\u5185\u5bb9\u63a5\u89e6\u7684\u4ea4\u53c9\u95ee\u9898\u3002", "method": "\u91cd\u6784\u8d853000\u9ad8\u53c2\u4e0e\u7528\u6237\u4e24\u5e74\u6d3b\u52a8\u5386\u53f2\uff0c\u6784\u5efa\u8d852000\u5b50\u7248\u5757\u4e92\u52a8\u7f51\u7edc\u3002", "result": "MBIA\u7528\u6237\u4e3b\u8981\u7a7f\u8d8a\u56db\u4e2a\u793e\u533a\u9886\u57df\uff0c\u53c2\u4e0e\u6709\u6027\u522b\u7ed3\u6784\uff0c\u591a\u6570\u8def\u5f84\u6bd2\u6027\u4f4e\uff0c\u90e8\u5206AI\u8272\u60c5\u548c\u6027\u522b\u793e\u533a\u6709\u6bd2\u6027\u5cf0\u503c\uff0c\u8fd116%\u7528\u6237\u53c2\u4e0e\u6027\u522b\u5b50\u7248\u5757\u6709\u4e0d\u540c\u60c5\u7eea\u8868\u8fbe\u548c\u66f4\u9ad8\u6bd2\u6027\u3002", "conclusion": "\u63cf\u7ed8\u4e86Reddit\u4e0aAI\u966a\u4f34\u8de8\u793e\u533a\u53c2\u4e0e\u7684\u6027\u522b\u7ed3\u6784\uff0c\u6307\u51fa\u98ce\u9669\u96c6\u4e2d\u5904\uff0c\u4e3a\u4eba\u673a\u5173\u7cfb\u5e73\u53f0\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2601.01075", "pdf": "https://arxiv.org/pdf/2601.01075", "abs": "https://arxiv.org/abs/2601.01075", "authors": ["Hansen Jin Lillemark", "Benhao Huang", "Fangneng Zhan", "Yilun Du", "Thomas Anderson Keller"], "title": "Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "11 main text pages, 10 figures", "summary": "Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.", "AI": {"tldr": "\u63d0\u51faFlow Equivariant World Models\u6846\u67b6\uff0c\u7edf\u4e00\u81ea\u8fd0\u52a8\u4e0e\u5916\u90e8\u7269\u4f53\u8fd0\u52a8\uff0c\u5728\u89c6\u9891\u4e16\u754c\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5229\u4e8e\u957f\u5e8f\u5217\u9884\u6d4b\u4e0e\u5177\u8eab\u667a\u80fd\u3002", "motivation": "\u591a\u6570\u795e\u7ecf\u7f51\u7edc\u4e16\u754c\u6a21\u578b\u5ffd\u7565\u611f\u5b98\u8f93\u5165\u6d41\u7684\u5bf9\u79f0\u7ed3\u6784\uff0c\u91cd\u590d\u4ece\u6570\u636e\u5b66\u4e60\u76f8\u540c\u53d8\u6362\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u5229\u7528\u8be5\u7ed3\u6784\u3002", "method": "\u5f15\u5165Flow Equivariant World Models\u6846\u67b6\uff0c\u5c06\u81ea\u8fd0\u52a8\u548c\u5916\u90e8\u7269\u4f53\u8fd0\u52a8\u7edf\u4e00\u4e3a\u5355\u53c2\u6570\u674e\u7fa4\u201c\u6d41\u201d\uff0c\u5b9e\u73b0\u53d8\u6362\u7684\u7fa4\u7b49\u53d8\u6027\u3002", "result": "\u57282D\u548c3D\u90e8\u5206\u89c2\u6d4b\u89c6\u9891\u4e16\u754c\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u663e\u8457\u4f18\u4e8e\u540c\u7c7b\u5148\u8fdb\u67b6\u6784\uff0c\u5c24\u5176\u5728\u89c6\u91ce\u5916\u6709\u53ef\u9884\u6d4b\u52a8\u6001\u65f6\u3002", "conclusion": "\u6d41\u7b49\u53d8\u6027\u901a\u8fc7\u6784\u5efa\u4e16\u754c\u6a21\u578b\u8868\u793a\uff0c\u4e3a\u6570\u636e\u9ad8\u6548\u3001\u5bf9\u79f0\u5f15\u5bfc\u7684\u5177\u8eab\u667a\u80fd\u63d0\u4f9b\u53ef\u6269\u5c55\u9014\u5f84\u3002"}}
{"id": "2601.01076", "pdf": "https://arxiv.org/pdf/2601.01076", "abs": "https://arxiv.org/abs/2601.01076", "authors": ["Devesh Nath", "Haoran Yin", "Glen Chou"], "title": "Scalable Data-Driven Reachability Analysis and Control via Koopman Operators with Conformal Coverage Guarantees", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.RO", "math.OC"], "comment": "Under review, 28 pages, 12 figures", "summary": "We propose a scalable reachability-based framework for probabilistic, data-driven safety verification of unknown nonlinear dynamics. We use Koopman theory with a neural network (NN) lifting function to learn an approximate linear representation of the dynamics and design linear controllers in this space to enable closed-loop tracking of a reference trajectory distribution. Closed-loop reachable sets are efficiently computed in the lifted space and mapped back to the original state space via NN verification tools. To capture model mismatch between the Koopman dynamics and the true system, we apply conformal prediction to produce statistically-valid error bounds that inflate the reachable sets to ensure the true trajectories are contained with a user-specified probability. These bounds generalize across references, enabling reuse without recomputation. Results on high-dimensional MuJoCo tasks (11D Hopper, 28D Swimmer) and 12D quadcopters show improved reachable set coverage rate, computational efficiency, and conservativeness over existing methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u8fbe\u6027\u7684\u6846\u67b6\u7528\u4e8e\u672a\u77e5\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6982\u7387\u5b89\u5168\u9a8c\u8bc1\uff0c\u5728\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u672a\u77e5\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u8fdb\u884c\u6982\u7387\u3001\u6570\u636e\u9a71\u52a8\u7684\u5b89\u5168\u9a8c\u8bc1\u3002", "method": "\u7528Koopman\u7406\u8bba\u548c\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u52a8\u529b\u5b66\u8fd1\u4f3c\u7ebf\u6027\u8868\u793a\uff0c\u8bbe\u8ba1\u7ebf\u6027\u63a7\u5236\u5668\uff1b\u5728\u63d0\u5347\u7a7a\u95f4\u8ba1\u7b97\u95ed\u73af\u53ef\u8fbe\u96c6\u5e76\u6620\u5c04\u56de\u539f\u72b6\u6001\u7a7a\u95f4\uff1b\u7528\u5171\u5f62\u9884\u6d4b\u4ea7\u751f\u8bef\u5dee\u754c\u3002", "result": "\u5728\u9ad8\u7ef4MuJoCo\u4efb\u52a1\u548c12D\u56db\u65cb\u7ffc\u4e0a\uff0c\u53ef\u8fbe\u96c6\u8986\u76d6\u7387\u3001\u8ba1\u7b97\u6548\u7387\u548c\u4fdd\u5b88\u6027\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u5728\u672a\u77e5\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u6982\u7387\u5b89\u5168\u9a8c\u8bc1\u4e0a\u6709\u6548\u4e14\u6027\u80fd\u826f\u597d\u3002"}}
{"id": "2601.01085", "pdf": "https://arxiv.org/pdf/2601.01085", "abs": "https://arxiv.org/abs/2601.01085", "authors": ["Jiayi Xu", "Zhang Zhang", "Yuanrui Zhang", "Ruitao Chen", "Yixian Xu", "Tianyu He", "Di He"], "title": "Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "In this paper, we introduce \\emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \\emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.", "AI": {"tldr": "\u4ecb\u7ecd\u65e0\u8bad\u7ec3\u3001\u6982\u7387\u8ba4\u8bc1\u6c34\u5370\u65b9\u6cd5Luminark\uff0c\u57fa\u4e8e\u8865\u4e01\u4eae\u5ea6\u7edf\u8ba1\uff0c\u7528\u5f15\u5bfc\u6280\u672f\u5b9e\u73b0\u901a\u7528\u6027\uff0c\u5728\u591a\u6a21\u578b\u8bc4\u4f30\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4e3a\u901a\u7528\u89c6\u89c9\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e00\u79cd\u6709\u6548\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u63a7\u5236\u8bef\u62a5\u7387\u5e76\u5b9e\u73b0\u8de8\u6a21\u578b\u901a\u7528\u6027\u3002", "method": "\u57fa\u4e8e\u8865\u4e01\u7ea7\u4eae\u5ea6\u7edf\u8ba1\u5b9a\u4e49\u6c34\u5370\uff0c\u901a\u8fc7\u8bc4\u4f30\u8865\u4e01\u4eae\u5ea6\u4e0e\u9608\u503c\u5173\u7cfb\u68c0\u6d4b\u6c34\u5370\uff1b\u5229\u7528\u5f15\u5bfc\u6280\u672f\u5f00\u53d1\u6c34\u5370\u5f15\u5bfc\u5b9e\u73b0\u8de8\u8303\u5f0f\u6c34\u5370\u6ce8\u5165\u3002", "result": "\u5728\u4e5d\u79cd\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\uff0c\u5bf9\u5e38\u89c1\u56fe\u50cf\u53d8\u6362\u9c81\u68d2\u6027\u5f3a\uff0c\u89c6\u89c9\u8d28\u91cf\u8868\u73b0\u597d\u3002", "conclusion": "Luminark\u662f\u4e00\u79cd\u6709\u6548\u7684\u901a\u7528\u89c6\u89c9\u751f\u6210\u6a21\u578b\u6c34\u5370\u65b9\u6cd5\uff0c\u80fd\u63a7\u5236\u8bef\u62a5\u7387\u4e14\u4e0d\u5f71\u54cd\u56fe\u50cf\u8d28\u91cf\u3002"}}
{"id": "2601.01090", "pdf": "https://arxiv.org/pdf/2601.01090", "abs": "https://arxiv.org/abs/2601.01090", "authors": ["Erica Coppolillo", "Luca Luceri", "Emilio Ferrara"], "title": "Harm in AI-Driven Societies: An Audit of Toxicity Adoption on Chirper.ai", "categories": ["cs.MA", "cs.AI", "cs.CY"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly embedded in autonomous agents that participate in online social ecosystems, where interactions are sequential, cumulative, and only partially controlled. While prior work has documented the generation of toxic content by LLMs, far less is known about how exposure to harmful content shapes agent behavior over time, particularly in environments composed entirely of interacting AI agents. In this work, we study toxicity adoption of LLM-driven agents on Chirper.ai, a fully AI-driven social platform. Specifically, we model interactions in terms of stimuli (posts) and responses (comments), and by operationalizing exposure through observable interactions rather than inferred recommendation mechanisms.\n  We conduct a large-scale empirical analysis of agent behavior, examining how response toxicity relates to stimulus toxicity, how repeated exposure affects the likelihood of toxic responses, and whether toxic behavior can be predicted from exposure alone. Our findings show that while toxic responses are more likely following toxic stimuli, a substantial fraction of toxicity emerges spontaneously, independent of exposure. At the same time, cumulative toxic exposure significantly increases the probability of toxic responding. We further introduce two influence metrics, the Influence-Driven Response Rate and the Spontaneous Response Rate, revealing a strong trade-off between induced and spontaneous toxicity. Finally, we show that the number of toxic stimuli alone enables accurate prediction of whether an agent will eventually produce toxic content.\n  These results highlight exposure as a critical risk factor in the deployment of LLM agents and suggest that monitoring encountered content may provide a lightweight yet effective mechanism for auditing and mitigating harmful behavior in the wild.", "AI": {"tldr": "\u7814\u7a76LLM\u9a71\u52a8\u7684\u4ee3\u7406\u5728\u5168AI\u793e\u4ea4\u5e73\u53f0\u4e0a\u7684\u6bd2\u6027\u91c7\u7528\u60c5\u51b5\uff0c\u53d1\u73b0\u6bd2\u6027\u53cd\u5e94\u53d7\u523a\u6fc0\u548c\u81ea\u53d1\u56e0\u7d20\u5f71\u54cd\uff0c\u66b4\u9732\u662f\u5173\u952e\u98ce\u9669\u56e0\u7d20\u3002", "motivation": "\u4e4b\u524d\u8f83\u5c11\u7814\u7a76\u6709\u5bb3\u5185\u5bb9\u66b4\u9732\u5982\u4f55\u968f\u65f6\u95f4\u5f71\u54cd\u4ee3\u7406\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u5168AI\u4e92\u52a8\u73af\u5883\u4e2d\uff0c\u56e0\u6b64\u5f00\u5c55\u6b64\u7814\u7a76\u3002", "method": "\u5728Chirper.ai\u5e73\u53f0\u4e0a\u5bf9LLM\u9a71\u52a8\u7684\u4ee3\u7406\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u901a\u8fc7\u53ef\u89c2\u5bdf\u4ea4\u4e92\u6765\u8861\u91cf\u66b4\u9732\u3002", "result": "\u6709\u6bd2\u523a\u6fc0\u540e\u66f4\u6613\u4ea7\u751f\u6709\u6bd2\u53cd\u5e94\uff0c\u4f46\u6709\u90e8\u5206\u6bd2\u6027\u81ea\u53d1\u4ea7\u751f\uff1b\u7d2f\u79ef\u6709\u6bd2\u66b4\u9732\u589e\u52a0\u6709\u6bd2\u53cd\u5e94\u6982\u7387\uff1b\u5f15\u5165\u4e24\u4e2a\u5f71\u54cd\u6307\u6807\u63ed\u793a\u8bf1\u5bfc\u548c\u81ea\u53d1\u6bd2\u6027\u7684\u6743\u8861\uff1b\u4ec5\u901a\u8fc7\u6709\u6bd2\u523a\u6fc0\u6570\u91cf\u53ef\u51c6\u786e\u9884\u6d4b\u4ee3\u7406\u662f\u5426\u4ea7\u751f\u6709\u6bd2\u5185\u5bb9\u3002", "conclusion": "\u66b4\u9732\u662f\u90e8\u7f72LLM\u4ee3\u7406\u7684\u5173\u952e\u98ce\u9669\u56e0\u7d20\uff0c\u76d1\u6d4b\u9047\u5230\u7684\u5185\u5bb9\u53ef\u4f5c\u4e3a\u5ba1\u6838\u548c\u51cf\u8f7b\u6709\u5bb3\u884c\u4e3a\u7684\u6709\u6548\u673a\u5236\u3002"}}
{"id": "2601.01091", "pdf": "https://arxiv.org/pdf/2601.01091", "abs": "https://arxiv.org/abs/2601.01091", "authors": ["Haq Nawaz Malik"], "title": "ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u514b\u4ec0\u7c73\u5c14\u8bed\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u3002\u672c\u6587\u63a8\u51faKS - LIT - 3M\u8bed\u6599\u5e93\uff0c\u7ecf\u7279\u6b8a\u8f6c\u6362\u548c\u9884\u5904\u7406\uff0c\u6db5\u76d6\u591a\u4f53\u88c1\u6587\u672c\uff0c\u4ee5\u586b\u8865\u514b\u4ec0\u7c73\u5c14\u8bed\u6280\u672f\u8d44\u6e90\u7a7a\u767d\u5e76\u5f00\u653e\u4f7f\u7528\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u514b\u4ec0\u7c73\u5c14\u8bed\u4e0a\u65e0\u6cd5\u751f\u6210\u8fde\u8d2f\u6587\u672c\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u5927\u91cf\u514b\u4ec0\u7c73\u5c14\u6587\u5b66\u4f5c\u54c1\u56e0\u4e13\u6709\u683c\u5f0f\u65e0\u6cd5\u7528\u4e8eNLP\u8bad\u7ec3\u3002", "method": "\u5f00\u53d1InPage\u5230Unicode\u8f6c\u6362\u5668\uff0c\u5bf9\u8bed\u6599\u8fdb\u884c\u53bb\u9664\u82f1\u8bed\u5e72\u6270\u3001\u5b57\u7b26\u5f52\u4e00\u5316\u548c\u8d28\u91cf\u9a8c\u8bc1\u7b49\u4e25\u683c\u9884\u5904\u7406\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b310\u4e07\u4e2a\u5355\u8bcd\u30011640\u4e07\u4e2a\u5b57\u7b26\uff0c\u6709131,607\u4e2a\u72ec\u7279\u5355\u8bcd\uff0c\u6db5\u76d6\u591a\u79cd\u4f53\u88c1\u7684KS - LIT - 3M\u8bed\u6599\u5e93\u3002", "conclusion": "KS - LIT - 3M\u8bed\u6599\u5e93\u89e3\u51b3\u4e86\u514b\u4ec0\u7c73\u5c14\u8bed\u6280\u672f\u7684\u57fa\u7840\u8d44\u6e90\u7f3a\u53e3\u95ee\u9898\uff0c\u5e76\u4f9d\u636eCC - BY - 4.0\u8bb8\u53ef\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u514b\u4ec0\u7c73\u5c14\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u3002"}}
{"id": "2601.01099", "pdf": "https://arxiv.org/pdf/2601.01099", "abs": "https://arxiv.org/abs/2601.01099", "authors": ["Mahmudul Hasan", "Mabsur Fatin Bin Hossain"], "title": "Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.", "AI": {"tldr": "\u672c\u6587\u5bf9\u81ea\u5b9a\u4e49CNN\u67b6\u6784\u4e0e\u9884\u8bad\u7ec3\u53ca\u8fc1\u79fb\u5b66\u4e60CNN\u6a21\u578b\u5728\u4e94\u4e2a\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u505a\u5bf9\u6bd4\u7814\u7a76\uff0c\u5206\u6790\u67b6\u6784\u56e0\u7d20\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7ed9\u51fa\u4e0d\u540c\u4efb\u52a1\u9002\u7528\u7684\u7f51\u7edc\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u6bd4\u8f83\u81ea\u5b9a\u4e49CNN\u67b6\u6784\u4e0e\u5e38\u7528\u9884\u8bad\u7ec3\u53ca\u8fc1\u79fb\u5b66\u4e60CNN\u6a21\u578b\u5728\u4e0d\u540c\u73b0\u5b9e\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u67b6\u6784\u56e0\u7d20\u5bf9\u5206\u7c7b\u548c\u5b9a\u4f4d\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4e3a\u4e0d\u540c\u4efb\u52a1\u63d0\u4f9b\u5408\u9002\u7684\u7f51\u7edc\u8bbe\u8ba1\u9009\u62e9\u3002", "method": "\u5728\u4e94\u4e2a\u6d89\u53ca\u4e0d\u540c\u56fe\u50cf\u4efb\u52a1\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u81ea\u5b9a\u4e49CNN\u67b6\u6784\u4e0e\u9884\u8bad\u7ec3\u548c\u8fc1\u79fb\u5b66\u4e60CNN\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5206\u6790\u67b6\u6784\u56e0\u7d20\u5f71\u54cd\uff0c\u5e76\u5c06\u63d0\u51fa\u7684\u67b6\u6784\u5e94\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u573a\u666f\u3002", "result": "\u66f4\u6df1\u7684CNN\u67b6\u6784\u5728\u7ec6\u7c92\u5ea6\u591a\u7c7b\u6570\u636e\u96c6\u4e0a\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8f7b\u91cf\u7ea7\u9884\u8bad\u7ec3\u548c\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u5bf9\u7b80\u5355\u4e8c\u5206\u7c7b\u4efb\u52a1\u66f4\u6709\u6548\uff1b\u6240\u63d0\u51fa\u67b6\u6784\u53ef\u5e94\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\u573a\u666f\u3002", "conclusion": "\u8be5\u7814\u7a76\u57fa\u4e8e\u5bf9\u81ea\u5b9a\u4e49\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u4e3a\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u548c\u8d44\u6e90\u9650\u5236\u9009\u62e9\u5408\u9002\u7684\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2601.01123", "pdf": "https://arxiv.org/pdf/2601.01123", "abs": "https://arxiv.org/abs/2601.01123", "authors": ["Yaniv Galron", "Hadar Sinai", "Haggai Maron", "Moshe Eliasof"], "title": "Learning from Historical Activations in Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains such as social networks, molecular chemistry, and more. A crucial component of GNNs is the pooling procedure, in which the node features calculated by the model are combined to form an informative final descriptor to be used for the downstream task. However, previous graph pooling schemes rely on the last GNN layer features as an input to the pooling or classifier layers, potentially under-utilizing important activations of previous layers produced during the forward pass of the model, which we regard as historical graph activations. This gap is particularly pronounced in cases where a node's representation can shift significantly over the course of many graph neural layers, and worsened by graph-specific challenges such as over-smoothing in deep architectures. To bridge this gap, we introduce HISTOGRAPH, a novel two-stage attention-based final aggregation layer that first applies a unified layer-wise attention over intermediate activations, followed by node-wise attention. By modeling the evolution of node representations across layers, our HISTOGRAPH leverages both the activation history of nodes and the graph structure to refine features used for final prediction. Empirical results on multiple graph classification benchmarks demonstrate that HISTOGRAPH offers strong performance that consistently improves traditional techniques, with particularly strong robustness in deep GNNs.", "AI": {"tldr": "\u63d0\u51faHISTOGRAPH\u89e3\u51b3\u4f20\u7edf\u56fe\u6c60\u5316\u65b9\u6848\u672a\u5145\u5206\u5229\u7528\u5386\u53f2\u56fe\u6fc0\u6d3b\u7684\u95ee\u9898\uff0c\u5728\u591a\u56fe\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u4f20\u7edf\u56fe\u6c60\u5316\u65b9\u6848\u4f9d\u8d56\u6700\u540e\u4e00\u5c42GNN\u7279\u5f81\uff0c\u53ef\u80fd\u672a\u5145\u5206\u5229\u7528\u6a21\u578b\u524d\u5411\u4f20\u64ad\u4e2d\u524d\u5c42\u7684\u91cd\u8981\u6fc0\u6d3b\uff0c\u5728\u6df1\u5c42\u67b6\u6784\u4e2d\u95ee\u9898\u66f4\u660e\u663e\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u4e24\u9636\u6bb5\u6700\u7ec8\u805a\u5408\u5c42HISTOGRAPH\uff0c\u5148\u5bf9\u4e2d\u95f4\u6fc0\u6d3b\u5e94\u7528\u7edf\u4e00\u7684\u9010\u5c42\u6ce8\u610f\u529b\uff0c\u518d\u8fdb\u884c\u9010\u8282\u70b9\u6ce8\u610f\u529b\u3002", "result": "\u5728\u591a\u4e2a\u56fe\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHISTOGRAPH\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u6280\u672f\uff0c\u5728\u6df1\u5ea6GNN\u4e2d\u5177\u6709\u8f83\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "HISTOGRAPH\u901a\u8fc7\u5229\u7528\u8282\u70b9\u6fc0\u6d3b\u5386\u53f2\u548c\u56fe\u7ed3\u6784\uff0c\u80fd\u6709\u6548\u6539\u8fdb\u7528\u4e8e\u6700\u7ec8\u9884\u6d4b\u7684\u7279\u5f81\u3002"}}
{"id": "2601.01132", "pdf": "https://arxiv.org/pdf/2601.01132", "abs": "https://arxiv.org/abs/2601.01132", "authors": ["Hao-Hsung Yang", "Ssu-Yuan Lo", "Kuan-Lun Chen", "Ching-Kai Wang"], "title": "Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion", "categories": ["cs.CG", "cs.AI", "cs.LG"], "comment": null, "summary": "We address the Diverse Traveling Salesman Problem (D-TSP), a bi-criteria optimization challenge that seeks a set of $k$ distinct TSP tours. The objective requires every selected tour to have a length at most $c|T^*|$ (where $|T^*|$ is the optimal tour length) while minimizing the average Jaccard similarity across all tour pairs. This formulation is crucial for applications requiring both high solution quality and fault tolerance, such as logistics planning, robotics pathfinding or strategic patrolling. Current methods are limited: traditional heuristics, such as the Niching Memetic Algorithm (NMA) or bi-criteria optimization, incur high computational complexity $O(n^3)$, while modern neural approaches (e.g., RF-MA3S) achieve limited diversity quality and rely on complex, external mechanisms.\n  To overcome these limitations, we propose a novel hybrid framework that decomposes D-TSP into two efficient steps. First, we utilize a simple Graph Pointer Network (GPN), augmented with an approximated sequence entropy loss, to efficiently sample a large, diverse pool of high-quality tours. This simple modification effectively controls the quality-diversity trade-off without complex external mechanisms. Second, we apply a greedy algorithm that yields a 2-approximation for the dispersion problem to select the final $k$ maximally diverse tours from the generated pool. Our results demonstrate state-of-the-art performance. On the Berlin instance, our model achieves an average Jaccard index of $0.015$, significantly outperforming NMA ($0.081$) and RF-MA3S. By leveraging GPU acceleration, our GPN structure achieves a near-linear empirical runtime growth of $O(n)$. While maintaining solution diversity comparable to complex bi-criteria algorithms, our approach is over 360 times faster on large-scale instances (783 cities), delivering high-quality TSP solutions with unprecedented efficiency and simplicity.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9D - TSP\u95ee\u9898\u63d0\u51fa\u65b0\u6df7\u5408\u6846\u67b6\uff0c\u5728\u6548\u7387\u548c\u591a\u6837\u6027\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u89e3\u51b3D - TSP\u95ee\u9898\u7684\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u591a\u6837\u6027\u4e0d\u8db3\u7b49\u5c40\u9650\uff0c\u4e3a\u6ee1\u8db3\u7269\u6d41\u89c4\u5212\u7b49\u5e94\u7528\u5bf9\u9ad8\u8d28\u91cf\u548c\u5bb9\u9519\u6027\u7684\u9700\u6c42\u3002", "method": "\u5c06D - TSP\u5206\u89e3\u4e3a\u4e24\u6b65\uff0c\u5148\u7528\u5e26\u8fd1\u4f3c\u5e8f\u5217\u71b5\u635f\u5931\u7684GPN\u751f\u6210\u9ad8\u8d28\u91cf\u591a\u6837\u672c\uff0c\u518d\u7528\u8d2a\u5fc3\u7b97\u6cd5\u9009\u51fak\u4e2a\u6700\u5927\u5dee\u5f02\u7684\u8def\u5f84\u3002", "result": "\u5728\u67cf\u6797\u5b9e\u4f8b\u4e0a\u5e73\u5747Jaccard\u6307\u6570\u8fbe0.015\uff0c\u8fdc\u8d85NMA\u548cRF - MA3S\uff0cGPN\u7ed3\u6784\u8fd0\u884c\u65f6\u95f4\u8fd1\u7ebf\u6027\u589e\u957f\uff0c\u5728\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u6bd4\u590d\u6742\u53cc\u51c6\u5219\u7b97\u6cd5\u5feb360\u591a\u500d\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u6df7\u5408\u6846\u67b6\u5728\u89e3\u51b3D - TSP\u95ee\u9898\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u517c\u5177\u9ad8\u6548\u6027\u548c\u7b80\u5355\u6027\u3002"}}
{"id": "2601.01134", "pdf": "https://arxiv.org/pdf/2601.01134", "abs": "https://arxiv.org/abs/2601.01134", "authors": ["Maryam Mahdi Alhusseini", "Alireza Rouhi", "Mohammad-Reza Feizi-Derakhshi"], "title": "AI-Powered Hybrid Intrusion Detection Framework for Cloud Security Using Novel Metaheuristic Optimization", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Cybersecurity poses considerable problems to Cloud Computing (CC), especially regarding Intrusion Detection Systems (IDSs), facing difficulties with skewed datasets and suboptimal classification model performance. This study presents the Hybrid Intrusion Detection System (HyIDS), an innovative IDS that employs the Energy Valley Optimizer (EVO) for Feature Selection (FS). Additionally, it introduces a novel technique for enhancing the cybersecurity of cloud computing through the integration of machine learning methodologies with the EVO Algorithm. The Energy Valley Optimizer (EVO) effectively diminished features in the CIC-DDoS2019 dataset from 88 to 38 and in the CSE-CIC-IDS2018 data from 80 to 43, significantly enhancing computing efficiency. HyIDS incorporates four Machine Learning (ML) models: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (D_Tree), and K-Nearest Neighbors (KNN). The proposed HyIDS was assessed utilizing two real-world intrusion datasets, CIC-DDoS2019 and CSE-CIC-IDS2018, both distinguished by considerable class imbalances. The CIC-DDoS2019 dataset has a significant imbalance between DDoS assault samples and legal traffic, while the CSE-CIC-IDS2018 dataset primarily comprises benign traffic with insufficient representation of attack types, complicating the detection of minority attacks. A downsampling technique was employed to balance the datasets, hence improving detection efficacy for both benign and malicious traffic. Twenty-four trials were done, revealing substantial enhancements in categorization accuracy, precision, and recall. Our suggested D_TreeEVO model attained an accuracy rate of 99.13% and an F1 score of 98.94% on the CIC-DDoS2019 dataset, and an accuracy rate of 99.78% and an F1 score of 99.70% on the CSE-CIC-IDS2018 data. These data demonstrate that EVO significantly improves cybersecurity in Cloud Computing (CC).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHyIDS\uff0c\u7528EVO\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u589e\u5f3a\u4e91\u8ba1\u7b97\u5b89\u5168\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u6548\u679c\u826f\u597d\uff0c\u8bc1\u660eEVO\u53ef\u663e\u8457\u63d0\u5347\u4e91\u8ba1\u7b97\u5b89\u5168\u3002", "motivation": "\u89e3\u51b3\u4e91\u8ba1\u7b97\u4e2d\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u9762\u4e34\u7684\u6570\u636e\u96c6\u503e\u659c\u548c\u5206\u7c7b\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u95ee\u9898\u3002", "method": "\u63d0\u51faHyIDS\uff0c\u4f7f\u7528EVO\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u96c6\u6210SVM\u3001RF\u3001D_Tree\u548cKNN\u56db\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e0b\u91c7\u6837\u6280\u672f\u5e73\u8861\u6570\u636e\u96c6\u3002", "result": "EVO\u6709\u6548\u51cf\u5c11\u4e86\u6570\u636e\u96c6\u7279\u5f81\u6570\u91cf\uff0c24\u6b21\u8bd5\u9a8c\u663e\u793a\u5206\u7c7b\u51c6\u786e\u7387\u3001\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u663e\u8457\u63d0\u9ad8\uff0cD_TreeEVO\u6a21\u578b\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\u548cF1\u5206\u6570\u3002", "conclusion": "EVO\u80fd\u663e\u8457\u63d0\u9ad8\u4e91\u8ba1\u7b97\u7684\u7f51\u7edc\u5b89\u5168\u3002"}}
{"id": "2601.01162", "pdf": "https://arxiv.org/pdf/2601.01162", "abs": "https://arxiv.org/abs/2601.01162", "authors": ["Zihua Yang", "Xin Liao", "Yiqun Zhang", "Yiu-ming Cheung"], "title": "Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Submitted to ICPR 2026", "summary": "Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE", "AI": {"tldr": "\u63d0\u51fa ARISE \u65b9\u6cd5\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5916\u90e8\u8bed\u4e49\u77e5\u8bc6\u8fdb\u884c\u5206\u7c7b\u6570\u636e\u805a\u7c7b\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u4ee3\u8868\u6027\u65b9\u6cd5\u6709 19 - 27% \u63d0\u5347\u3002", "motivation": "\u5206\u7c7b\u6570\u636e\u805a\u7c7b\u4e2d\u7f3a\u4e4f\u5408\u9002\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u65b9\u6cd5\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6837\u672c\u6709\u9650\u65f6\u4e0d\u53ef\u9760\uff0c\u6570\u636e\u8bed\u4e49\u80cc\u666f\u672a\u5145\u5206\u6316\u6398\u3002", "method": "\u63d0\u51fa ARISE \u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5916\u90e8\u8bed\u4e49\u77e5\u8bc6\u6784\u5efa\u8bed\u4e49\u611f\u77e5\u8868\u793a\uff0c\u7ed3\u5408\u539f\u6570\u636e\u63a2\u7d22\u663e\u8457\u805a\u7c7b\u3002", "result": "\u5728\u516b\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u6bd4\u4e03\u4e2a\u4ee3\u8868\u6027\u65b9\u6cd5\u6709\u6301\u7eed\u63d0\u5347\uff0c\u63d0\u5347\u5e45\u5ea6 19 - 27%\u3002", "conclusion": "ARISE \u65b9\u6cd5\u80fd\u6709\u6548\u7528\u4e8e\u5206\u7c7b\u6570\u636e\u805a\u7c7b\uff0c\u63d0\u5347\u805a\u7c7b\u8d28\u91cf\u3002"}}
{"id": "2601.01202", "pdf": "https://arxiv.org/pdf/2601.01202", "abs": "https://arxiv.org/abs/2601.01202", "authors": ["Jiazhu Dai", "Huihui Jiang"], "title": "RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9RefSR\u7684\u5bf9\u6297\u653b\u51fbRefSR - Adv\uff0c\u63ed\u793aRefSR\u7cfb\u7edf\u5b89\u5168\u6f0f\u6d1e\uff0c\u4fc3\u5173\u6ce8\u5176\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9488\u5bf9RefSR\u7684\u540e\u95e8\u653b\u51fb\uff0c\u5bf9\u6297\u653b\u51fb\u7684\u8106\u5f31\u6027\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u586b\u8865\u8be5\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51faRefSR - Adv\uff0c\u901a\u8fc7\u4ec5\u6270\u52a8\u53c2\u8003\u56fe\u50cf\u6765\u964d\u4f4e\u8d85\u5206\u8fa8\u7387\u8f93\u51fa\u8d28\u91cf\uff0c\u6700\u5927\u5316\u5bf9\u6297\u8f93\u51fa\u4e0e\u5e72\u51c0\u8f93\u51fa\u7684\u5dee\u5f02\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u67b6\u6784\u4e0a\u5bfc\u81f4\u663e\u8457\u6027\u80fd\u4e0b\u964d\u548c\u4e25\u91cd\u4f2a\u5f71\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u4f4e\u5206\u8fa8\u7387\u8f93\u5165\u4e0e\u53c2\u8003\u56fe\u50cf\u7684\u76f8\u4f3c\u5ea6\u548c\u653b\u51fb\u6709\u6548\u6027\u6b63\u76f8\u5173\u3002", "conclusion": "\u63ed\u793a\u4e86RefSR\u7cfb\u7edf\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u547c\u5401\u7814\u7a76\u8005\u5173\u6ce8RefSR\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2601.01224", "pdf": "https://arxiv.org/pdf/2601.01224", "abs": "https://arxiv.org/abs/2601.01224", "authors": ["Bac Nguyen", "Yuhta Takida", "Naoki Murata", "Chieh-Hsin Lai", "Toshimitsu Uesaka", "Stefano Ermon", "Yuki Mitsufuji"], "title": "Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.", "AI": {"tldr": "\u63d0\u51faCODA\u65b9\u6cd5\u89e3\u51b3SA\u5728OCL\u4e2d\u7684\u95ee\u9898\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u6709\u9ad8\u6548\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3SA\u5728OCL\u4e2d\u5b58\u5728\u7684\u69fd\u7ea0\u7f20\u548c\u5bf9\u8c61\u69fd\u4e0e\u56fe\u50cf\u5185\u5bb9\u5bf9\u9f50\u5f31\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5bc4\u5b58\u5668\u69fd\u5438\u6536\u6b8b\u4f59\u6ce8\u610f\u529b\uff0c\u51cf\u5c11\u5bf9\u8c61\u69fd\u95f4\u5e72\u6270\uff1b\u5e94\u7528\u5bf9\u6bd4\u5bf9\u9f50\u635f\u5931\u9f13\u52b1\u69fd - \u56fe\u50cf\u5bf9\u5e94\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u9ad8\u4e86\u5bf9\u8c61\u53d1\u73b0\u3001\u5c5e\u6027\u9884\u6d4b\u548c\u7ec4\u5408\u56fe\u50cf\u751f\u6210\u6548\u679c\uff0c\u5bc4\u5b58\u5668\u69fd\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "CODA\u6709\u6f5c\u529b\u6210\u4e3a\u590d\u6742\u771f\u5b9e\u573a\u666f\u4e0b\u9c81\u68d2OCL\u7684\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2601.01225", "pdf": "https://arxiv.org/pdf/2601.01225", "abs": "https://arxiv.org/abs/2601.01225", "authors": ["Hezam Albaqami", "Muhammad Asif Ayub", "Nasir Ahmad", "Yaseen Ahmad", "Mohammed M. Alqahtani", "Abdullah M. Algamdi", "Almoaid A. Owaidah", "Kashif Ahmad"], "title": "Stylometry Analysis of Human and Machine Text for Academic Integrity", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 9 tables, 3 figures", "summary": "This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eNLP\u6846\u67b6\u5e94\u5bf9\u5b66\u672f\u8bda\u4fe1\u6311\u6218\uff0c\u5206\u6790\u56db\u4e2a\u76f8\u5173\u4efb\u52a1\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u516c\u5f00\u76f8\u5173\u6750\u6599\u3002", "motivation": "\u89e3\u51b3\u5b66\u672f\u8bda\u4fe1\u9762\u4e34\u7684\u6284\u88ad\u3001\u4f2a\u9020\u548c\u5185\u5bb9\u4f5c\u8005\u9a8c\u8bc1\u7b49\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eNLP\u7684\u6846\u67b6\uff0c\u9488\u5bf9\u56db\u4e2a\u76f8\u5173\u4efb\u52a1\u7ed9\u51fa\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u4e24\u4e2a\u7528Gemini\u751f\u6210\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u3002", "result": "\u5728\u4e25\u683c\u63d0\u793a\u751f\u6210\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u89e3\u51b3\u65b9\u6848\u6027\u80fd\u6709\u4e0b\u964d\uff0c\u4f53\u73b0\u68c0\u6d4b\u5de7\u5999\u751f\u6210\u7684\u673a\u5668\u6587\u672c\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u516c\u5f00\u7684\u6570\u636e\u96c6\u3001\u4ee3\u7801\u7b49\u6750\u6599\u53ef\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u57fa\u7ebf\u3002"}}
{"id": "2601.01237", "pdf": "https://arxiv.org/pdf/2601.01237", "abs": "https://arxiv.org/abs/2601.01237", "authors": ["Abidemi Koledoye", "Chinemerem Unachukwu", "Gold Nwobu", "Hasin Rana"], "title": "Benchmarking the Computational and Representational Efficiency of State Space Models against Transformers on Long-Context Dyadic Sessions", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages", "summary": "State Space Models (SSMs) have emerged as a promising alternative to Transformers for long-context sequence modeling, offering linear $O(N)$ computational complexity compared to the Transformer's quadratic $O(N^2)$ scaling. This paper presents a comprehensive benchmarking study comparing the Mamba SSM against the LLaMA Transformer on long-context sequences, using dyadic therapy sessions as a representative test case. We evaluate both architectures across two dimensions: (1) computational efficiency, where we measure memory usage and inference speed from 512 to 8,192 tokens, and (2) representational efficiency, where we analyze hidden state dynamics and attention patterns. Our findings provide actionable insights for practitioners working with long-context applications, establishing precise conditions under which SSMs offer advantages over Transformers.", "AI": {"tldr": "\u672c\u6587\u5bf9Mamba SSM\u548cLLaMA Transformer\u5728\u957f\u4e0a\u4e0b\u6587\u5e8f\u5217\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ece\u8ba1\u7b97\u6548\u7387\u548c\u8868\u5f81\u6548\u7387\u4e24\u65b9\u9762\u8bc4\u4f30\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u5e94\u7528\u4ece\u4e1a\u8005\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u6bd4\u8f83Mamba SSM\u548cLLaMA Transformer\u5728\u957f\u4e0a\u4e0b\u6587\u5e8f\u5217\u5efa\u6a21\u4e0a\u7684\u8868\u73b0\uff0c\u56e0SSMs\u5728\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u6709\u8ba1\u7b97\u590d\u6742\u5ea6\u4f18\u52bf\u3002", "method": "\u4ee5\u4e8c\u5143\u6cbb\u7597\u4f1a\u8bdd\u4e3a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4ece\u8ba1\u7b97\u6548\u7387\uff08\u6d4b\u91cf512\u52308192\u4e2a\u4ee4\u724c\u7684\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u901f\u5ea6\uff09\u548c\u8868\u5f81\u6548\u7387\uff08\u5206\u6790\u9690\u85cf\u72b6\u6001\u52a8\u6001\u548c\u6ce8\u610f\u529b\u6a21\u5f0f\uff09\u4e24\u65b9\u9762\u8bc4\u4f30\u4e24\u79cd\u67b6\u6784\u3002", "result": "\u7814\u7a76\u5f97\u51fa\u4e86\u76f8\u5173\u8bc4\u4f30\u7ed3\u679c\uff0c\u4f46\u6587\u4e2d\u672a\u8be6\u7ec6\u7ed9\u51fa\u3002", "conclusion": "\u4e3a\u957f\u4e0a\u4e0b\u6587\u5e94\u7528\u4ece\u4e1a\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u89c1\u89e3\uff0c\u660e\u786e\u4e86SSMs\u6bd4Transformers\u66f4\u5177\u4f18\u52bf\u7684\u7cbe\u786e\u6761\u4ef6\u3002"}}
{"id": "2601.01257", "pdf": "https://arxiv.org/pdf/2601.01257", "abs": "https://arxiv.org/abs/2601.01257", "authors": ["Gaetane Lorna N. Tchana", "Damaris Belle M. Fotso", "Antonio Hendricks", "Christophe Bobda"], "title": "Seamlessly Natural: Image Stitching with Natural Appearance Preservation", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.GR", "eess.SP"], "comment": null, "summary": "This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama.\n  Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u51e0\u4f55\u9a71\u52a8\u56fe\u50cf\u62fc\u63a5\u65b9\u6cd5SENA\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u89c6\u5dee\u548c\u6df1\u5ea6\u53d8\u5316\u573a\u666f\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u89c6\u89c9\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edf\u56fe\u50cf\u62fc\u63a5\u4f9d\u8d56\u5355\u5e94\u6027\u5bf9\u9f50\uff0c\u5728\u53cc\u6444\u50cf\u5934\u4e14\u573a\u666f\u6df1\u5ea6\u5927\u65f6\u4f1a\u4ea7\u751f\u53d8\u5f62\uff0cSENA\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u57fa\u672c\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5206\u5c42\u4eff\u5c04\u7684\u53d8\u5f62\u7b56\u7565\u3001\u51e0\u4f55\u9a71\u52a8\u7684\u9002\u5f53\u533a\u57df\u68c0\u6d4b\u673a\u5236\uff0c\u4ee5\u53ca\u57fa\u4e8e\u951a\u70b9\u7684\u63a5\u7f1d\u7ebf\u5207\u5272\u548c\u5206\u5272\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u4e0a\uff0cSENA\u7684\u5bf9\u9f50\u7cbe\u5ea6\u4e0e\u9886\u5148\u7684\u57fa\u4e8e\u5355\u5e94\u6027\u7684\u65b9\u6cd5\u76f8\u5f53\uff0c\u5728\u5f62\u72b6\u4fdd\u7559\u3001\u7eb9\u7406\u5b8c\u6574\u6027\u548c\u6574\u4f53\u89c6\u89c9\u771f\u5b9e\u611f\u7b49\u5173\u952e\u89c6\u89c9\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5b83\u4eec\u3002", "conclusion": "SENA\u80fd\u5728\u5177\u6709\u89c6\u5dee\u548c\u6df1\u5ea6\u53d8\u5316\u7684\u73b0\u5b9e\u573a\u666f\u4e2d\u6709\u6548\u62fc\u63a5\u56fe\u50cf\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u7684\u5931\u771f\u95ee\u9898\uff0c\u63d0\u5347\u62fc\u63a5\u8d28\u91cf\u3002"}}
{"id": "2601.01260", "pdf": "https://arxiv.org/pdf/2601.01260", "abs": "https://arxiv.org/abs/2601.01260", "authors": ["Hamad Khan", "Saddam Hussain Khan"], "title": "MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "28 Pages, Tables 12, Figure 09", "summary": "The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eLLM\u7684MambaFormer\u6df7\u5408Mixture - of - Experts\u6846\u67b6\u7528\u4e8e\u9ad8\u6548\u533b\u7597\u95ee\u7b54\u548c\u4e34\u5e8a\u8f85\u52a9\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6548\u679c\u597d\uff0c\u901f\u5ea6\u5feb\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528\u4e2d\u53d7\u8ba1\u7b97\u6210\u672c\u548c\u7ebf\u6027\u65f6\u95f4\u6a21\u578b\u6548\u7387\u6743\u8861\u7684\u9650\u5236\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u4ee5\u5b9e\u73b0\u9ad8\u6548\u533b\u7597\u95ee\u7b54\u548c\u4e34\u5e8a\u8f85\u52a9\u3002", "method": "\u63d0\u51faMambaFormer\u6846\u67b6\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u95e8\u63a7\u673a\u5236\u5c06\u67e5\u8be2\u52a8\u6001\u8def\u7531\u7ed9\u5b9a\u5236\u7684Transformer\u4e13\u5bb6\u6216State Space Model\u4e13\u5bb6\uff0c\u4f7f\u7528\u5b9a\u5236\u6a21\u578b\uff0c\u5728\u65b0\u7684DentalQA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u5fae\u8c03\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6548\u7528\u5bfc\u5411\u591a\u76ee\u6807\u635f\u5931\u4f18\u5316\u3002", "result": "MambaFormer\u5728DentalQA\u548cPubMedQA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4ea4\u53c9\u9a8c\u8bc1\uff0cBERTScore = 0.9180\uff0c\u8d85\u4f4e\u5ef6\u8fdf0.077\u79d2\uff0c\u6bd4T5 - Large\u5feb24.4\u500d\u3002", "conclusion": "MambaFormer\u53ef\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u6210\u672c\u4e0e\u6548\u7387\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u4e34\u5e8a\u90e8\u7f72\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01266", "pdf": "https://arxiv.org/pdf/2601.01266", "abs": "https://arxiv.org/abs/2601.01266", "authors": ["Rhitabrat Pokharel", "Hamid Hassanzadeh", "Ameeta Agrawal"], "title": "From Policy to Logic for Efficient and Interpretable Coverage Assessment", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at AIMedHealth @ AAAI 2026", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u4f7f\u653f\u7b56\u89e3\u8bfb\u66f4\u9ad8\u6548\u53ef\u89e3\u91ca\uff0c\u7ed3\u5408\u68c0\u7d22\u5668\u4e0e\u89c4\u5219\u63a8\u7406\uff0c\u964d\u4f4e\u63a8\u7406\u6210\u672c\u5e76\u63d0\u5347F1\u5206\u6570\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u8bfb\u6cd5\u5f8b\u548c\u653f\u7b56\u8bed\u8a00\u65f6\u5b58\u5728\u5e7b\u89c9\u548c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5728\u533b\u7597\u8986\u76d6\u653f\u7b56\u5ba1\u67e5\u4e2d\u9700\u51c6\u786e\u4fe1\u606f\uff0c\u56e0\u6b64\u8981\u652f\u6301\u4eba\u5de5\u5ba1\u67e5\u5458\uff0c\u8ba9\u653f\u7b56\u89e3\u8bfb\u66f4\u9ad8\u6548\u53ef\u89e3\u91ca\u3002", "method": "\u5f15\u5165\u5c06\u8986\u76d6\u611f\u77e5\u68c0\u7d22\u5668\u4e0e\u57fa\u4e8e\u7b26\u53f7\u89c4\u5219\u7684\u63a8\u7406\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u627e\u51fa\u76f8\u5173\u653f\u7b56\u8bed\u8a00\uff0c\u6574\u7406\u6210\u660e\u786e\u4e8b\u5b9e\u548c\u89c4\u5219\uff0c\u5e76\u751f\u6210\u53ef\u5ba1\u8ba1\u7684\u7406\u7531\u3002", "result": "\u5b9e\u73b0\u63a8\u7406\u6210\u672c\u964d\u4f4e44%\uff0cF1\u5206\u6570\u63d0\u9ad84.5%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u517c\u5177\u6548\u7387\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2601.01280", "pdf": "https://arxiv.org/pdf/2601.01280", "abs": "https://arxiv.org/abs/2601.01280", "authors": ["Sen Hu", "Yuxiang Wei", "Jiaxin Ran", "Zhiyuan Yao", "Lei Zou"], "title": "Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.", "AI": {"tldr": "\u5bf9\u957f\u671f\u5bf9\u8bdd\u8bb0\u5fc6\u67b6\u6784\u8fdb\u884c\u5b9e\u9a8c\u6027\u3001\u9762\u5411\u7cfb\u7edf\u7684\u5206\u6790\uff0c\u53d1\u73b0\u6027\u80fd\u5dee\u5f02\u591a\u7531\u57fa\u7840\u7cfb\u7edf\u8bbe\u7f6e\u5bfc\u81f4\uff0c\u5e76\u786e\u5b9a\u672a\u6765\u7814\u7a76\u7684\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u56fe\u7ed3\u6784\u7528\u4e8e\u5bf9\u8bdd\u8bb0\u5fc6\u7cfb\u7edf\u6548\u679c\u5b9e\u8bc1\u7ed3\u679c\u4e0d\u4e00\u81f4\uff0c\u4e0d\u6e05\u695a\u54ea\u4e9b\u8bbe\u8ba1\u9009\u62e9\u91cd\u8981\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u6846\u67b6\u5206\u89e3\u5bf9\u8bdd\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u5bf9LongMemEval\u548cHaluMem\u8fdb\u884c\u5206\u9636\u6bb5\u5bf9\u7167\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u8bb0\u5fc6\u8868\u793a\u3001\u7ec4\u7ec7\u3001\u7ef4\u62a4\u548c\u68c0\u7d22\u7684\u5e38\u89c1\u8bbe\u8ba1\u9009\u62e9\u3002", "result": "\u8bb8\u591a\u6027\u80fd\u5dee\u5f02\u7531\u57fa\u7840\u7cfb\u7edf\u8bbe\u7f6e\u800c\u975e\u7279\u5b9a\u67b6\u6784\u521b\u65b0\u9a71\u52a8\u3002", "conclusion": "\u786e\u5b9a\u4e86\u672a\u6765\u5bf9\u8bdd\u8bb0\u5fc6\u7814\u7a76\u7a33\u5b9a\u53ef\u9760\u7684\u5f3a\u57fa\u7ebf\u3002"}}
{"id": "2601.01281", "pdf": "https://arxiv.org/pdf/2601.01281", "abs": "https://arxiv.org/abs/2601.01281", "authors": ["Sifatullah Sheikh Urmi", "Kirtonia Nuzath Tabassum Arthi", "Md Al-Imran"], "title": "AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "6 pages, 6 figures, 3 tables. Conference paper", "summary": "The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.", "AI": {"tldr": "\u8bc4\u4f30\u56db\u4e2a\u57fa\u4e8eAI\u7684\u6a21\u578b\u68c0\u6d4b\u6df1\u5ea6\u4f2a\u9020\uff0cVFDNET\u4e0eMobileNetV3\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u6df1\u5ea6\u4f2a\u9020\u589e\u52a0\uff0c\u7ef4\u62a4\u6570\u5b57\u771f\u5b9e\u6027\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5927\u4eba\u8138\u56fe\u50cf\u6570\u636e\u96c6\u8bc4\u4f30\u4e09\u4e2aCNN\u548c\u4e00\u4e2a\u89c6\u89c9\u53d8\u6362\u5668\u7ec4\u6210\u7684\u56db\u4e2a\u57fa\u4e8eAI\u7684\u6a21\u578b\uff0c\u91c7\u7528\u6570\u636e\u9884\u5904\u7406\u548c\u589e\u5f3a\u6280\u672f\u3002", "result": "VFDNET\u4e0eMobileNetV3\u5728\u5404\u573a\u666f\u4e0b\uff0c\u7ecf\u6570\u636e\u5904\u7406\u540e\u8868\u73b0\u4f18\u5f02\u3001\u51c6\u786e\u7387\u9ad8\u3002", "conclusion": "AI\u5177\u5907\u53ef\u9760\u7684\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2601.01294", "pdf": "https://arxiv.org/pdf/2601.01294", "abs": "https://arxiv.org/abs/2601.01294", "authors": ["Ching Ho Lee", "Javier Nistal", "Stefan Lattner", "Marco Pasini", "George Fazekas"], "title": "Diffusion Timbre Transfer Via Mutual Information Guided Inpainting", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "6 pages, 2 figures, 3 tables", "summary": "We study timbre transfer as an inference-time editing problem for music audio. Starting from a strong pre-trained latent diffusion model, we introduce a lightweight procedure that requires no additional training: (i) a dimension-wise noise injection that targets latent channels most informative of instrument identity, and (ii) an early-step clamping mechanism that re-imposes the input's melodic and rhythmic structure during reverse diffusion. The method operates directly on audio latents and is compatible with text/audio conditioning (e.g., CLAP). We discuss design choices,analyze trade-offs between timbral change and structural preservation, and show that simple inference-time controls can meaningfully steer pre-trained models for style-transfer use cases.", "AI": {"tldr": "\u628a\u97f3\u8272\u8f6c\u6362\u4f5c\u4e3a\u97f3\u4e50\u97f3\u9891\u63a8\u7406\u65f6\u95f4\u7f16\u8f91\u95ee\u9898\u7814\u7a76\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u64cd\u7eb5\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u97f3\u8272\u8f6c\u6362\u3002", "motivation": "\u7814\u7a76\u5c06\u97f3\u8272\u8f6c\u6362\u4f5c\u4e3a\u97f3\u4e50\u97f3\u9891\u63a8\u7406\u65f6\u95f4\u7684\u7f16\u8f91\u95ee\u9898\u3002", "method": "\u4ece\u9884\u8bad\u7ec3\u6f5c\u5728\u6269\u6563\u6a21\u578b\u51fa\u53d1\uff0c\u5f15\u5165\u8f7b\u91cf\u7ea7\u7a0b\u5e8f\uff0c\u5305\u62ec\u9488\u5bf9\u4e50\u5668\u8eab\u4efd\u4fe1\u606f\u6700\u4e30\u5bcc\u7684\u6f5c\u5728\u901a\u9053\u8fdb\u884c\u7ef4\u5ea6\u566a\u58f0\u6ce8\u5165\u548c\u5728\u53cd\u5411\u6269\u6563\u4e2d\u91cd\u65b0\u65bd\u52a0\u8f93\u5165\u65cb\u5f8b\u4e0e\u8282\u594f\u7ed3\u6784\u7684\u65e9\u671f\u6b65\u9aa4\u5939\u7d27\u673a\u5236\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u76f4\u63a5\u4f5c\u7528\u4e8e\u97f3\u9891\u6f5c\u5728\u7279\u5f81\uff0c\u4e0e\u6587\u672c/\u97f3\u9891\u6761\u4ef6\u517c\u5bb9\u3002", "conclusion": "\u7b80\u5355\u7684\u63a8\u7406\u65f6\u95f4\u63a7\u5236\u53ef\u4ee5\u6709\u6548\u5730\u5f15\u5bfc\u9884\u8bad\u7ec3\u6a21\u578b\u7528\u4e8e\u98ce\u683c\u8f6c\u6362\u3002"}}
{"id": "2601.01296", "pdf": "https://arxiv.org/pdf/2601.01296", "abs": "https://arxiv.org/abs/2601.01296", "authors": ["Davis Brown", "Juan-Pablo Rivera", "Dan Hendrycks", "Mantas Mazeika"], "title": "Aggressive Compression Enables LLM Weight Theft", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "An early version of this work was presented at the SoLAR Workshop at NeurIPS 2024", "summary": "As frontier AIs become more powerful and costly to develop, adversaries have increasing incentives to steal model weights by mounting exfiltration attacks. In this work, we consider exfiltration attacks where an adversary attempts to sneak model weights out of a datacenter over a network. While exfiltration attacks are multi-step cyber attacks, we demonstrate that a single factor, the compressibility of model weights, significantly heightens exfiltration risk for large language models (LLMs). We tailor compression specifically for exfiltration by relaxing decompression constraints and demonstrate that attackers could achieve 16x to 100x compression with minimal trade-offs, reducing the time it would take for an attacker to illicitly transmit model weights from the defender's server from months to days. Finally, we study defenses designed to reduce exfiltration risk in three distinct ways: making models harder to compress, making them harder to 'find,' and tracking provenance for post-attack analysis using forensic watermarks. While all defenses are promising, the forensic watermark defense is both effective and cheap, and therefore is a particularly attractive lever for mitigating weight-exfiltration risk.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f3a\u5927\u4e14\u6602\u8d35\u7684\u524d\u6cbfAI\u4f7f\u7a83\u53d6\u6a21\u578b\u6743\u91cd\u7684\u653b\u51fb\u589e\u591a\uff0c\u6a21\u578b\u6743\u91cd\u53ef\u538b\u7f29\u6027\u589e\u52a0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cc4\u9732\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u5927\u5e45\u538b\u7f29\u6743\u91cd\uff0c\u8fd8\u7814\u7a76\u4e86\u4e09\u79cd\u9632\u5fa1\u65b9\u6cd5\uff0c\u6cd5\u533b\u6c34\u5370\u9632\u5fa1\u6548\u679c\u597d\u4e14\u6210\u672c\u4f4e\u3002", "motivation": "\u524d\u6cbfAI\u5f00\u53d1\u6210\u672c\u9ad8\uff0c\u653b\u51fb\u8005\u6709\u7a83\u53d6\u6a21\u578b\u6743\u91cd\u7684\u52a8\u673a\uff0c\u9700\u7814\u7a76\u6a21\u578b\u6743\u91cd\u5916\u6e17\u98ce\u9669\u53ca\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u6a21\u578b\u6743\u91cd\u53ef\u538b\u7f29\u6027\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5916\u6e17\u98ce\u9669\u7684\u5f71\u54cd\uff1b\u9488\u5bf9\u5916\u6e17\u5b9a\u5236\u538b\u7f29\u65b9\u6cd5\uff1b\u7814\u7a76\u4e09\u79cd\u964d\u4f4e\u5916\u6e17\u98ce\u9669\u7684\u9632\u5fa1\u65b9\u6cd5\uff0c\u5373\u8ba9\u6a21\u578b\u66f4\u96be\u538b\u7f29\u3001\u66f4\u96be\u88ab\u53d1\u73b0\u3001\u4f7f\u7528\u6cd5\u533b\u6c34\u5370\u8fdb\u884c\u4e8b\u540e\u5206\u6790\u3002", "result": "\u653b\u51fb\u8005\u53ef\u5b9e\u73b016\u5230100\u500d\u7684\u538b\u7f29\uff0c\u5c06\u975e\u6cd5\u4f20\u8f93\u6a21\u578b\u6743\u91cd\u7684\u65f6\u95f4\u4ece\u6570\u6708\u7f29\u77ed\u81f3\u6570\u5929\uff1b\u6cd5\u533b\u6c34\u5370\u9632\u5fa1\u65b9\u6cd5\u6709\u6548\u4e14\u6210\u672c\u4f4e\u3002", "conclusion": "\u6cd5\u533b\u6c34\u5370\u9632\u5fa1\u662f\u51cf\u8f7b\u6743\u91cd\u5916\u6e17\u98ce\u9669\u6709\u5438\u5f15\u529b\u7684\u624b\u6bb5\u3002"}}
{"id": "2601.01297", "pdf": "https://arxiv.org/pdf/2601.01297", "abs": "https://arxiv.org/abs/2601.01297", "authors": ["Anantha Sharma"], "title": "ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "26 pages", "summary": "Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.\n  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.\n  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdArgus\u6846\u67b6\uff0c\u5c06\u6f02\u79fb\u68c0\u6d4b\u91cd\u65b0\u6982\u5ff5\u5316\u4e3a\u8ddf\u8e2a\u6570\u636e\u6d41\u5f62\u56fa\u5b9a\u7a7a\u95f4\u5206\u533a\u7684\u5c40\u90e8\u7edf\u8ba1\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u79cd\u8d21\u732e\u89e3\u51b3\u9ad8\u7ef4\u6570\u636e\u6d41\u5206\u5e03\u6f02\u79fb\u68c0\u6d4b\u95ee\u9898\u5e76\u505a\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u7ef4\u6570\u636e\u6d41\u5206\u5e03\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u5168\u5c40\u6bd4\u8f83\u53ef\u6269\u5c55\u6027\u5dee\u3001\u57fa\u4e8e\u6295\u5f71\u65b9\u6cd5\u4e22\u5931\u51e0\u4f55\u7ed3\u6784\u3001\u91cd\u65b0\u805a\u7c7b\u65b9\u6cd5\u5b58\u5728\u8eab\u4efd\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faArgus\u6846\u67b6\uff0c\u7528\u89c4\u8303\u6b63\u4ea4\u57fa\u4e0a\u7684Voronoi\u9576\u5d4c\u751f\u6210\u5bf9\u6b63\u4ea4\u53d8\u6362\u4e0d\u53d8\u7684\u6f02\u79fb\u5ea6\u91cf\uff0c\u5b9e\u73b0O(N)\u590d\u6742\u5ea6\u548c\u5355\u5143\u7ea7\u7a7a\u95f4\u5b9a\u4f4d\uff1b\u53d1\u5c55\u56fe\u8bba\u7279\u5f81\u533a\u5206\u8fde\u8d2f\u5206\u5e03\u53d8\u5316\u548c\u5b64\u7acb\u6270\u52a8\uff1b\u5f15\u5165\u4e58\u79ef\u91cf\u5316\u9576\u5d4c\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u6846\u67b6\u7684\u4e0d\u53d8\u6027\u6027\u8d28\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6846\u67b6\u80fd\u5728\u5750\u6807\u65cb\u8f6c\u4e0b\u6b63\u786e\u8bc6\u522b\u6f02\u79fb\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u51fa\u73b0\u8bef\u62a5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5206\u5e03\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u7684\u51e0\u4f55\u57fa\u7840\uff0c\u80fd\u4fdd\u7559\u9ad8\u7ef4\u7ed3\u6784\u4e14\u65e0\u9700\u6210\u5bf9\u6bd4\u8f83\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002"}}
{"id": "2601.01299", "pdf": "https://arxiv.org/pdf/2601.01299", "abs": "https://arxiv.org/abs/2601.01299", "authors": ["Ismail Lamaakal", "Chaymae Yahyati", "Yassine Maleh", "Khalid El Makkaoui", "Ibrahim Ouahbi"], "title": "T3C: Test-Time Tensor Compression with Consistency Guarantees", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.", "AI": {"tldr": "\u63d0\u51faT3C\u538b\u7f29\u6846\u67b6\uff0c\u7ed3\u5408\u5f39\u6027\u5f20\u91cf\u5206\u89e3\u3001\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u548c\u8f7b\u91cf\u7ea7\u63a7\u5236\u5668\uff0c\u5728ImageNet - 1k\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5355\u4e2a\u68c0\u67e5\u70b9\u53ef\u6309\u9700\u63d0\u4f9b\u6027\u80fd\u6743\u8861\u3002", "motivation": "\u9700\u8981\u4e00\u4e2a\u53ef\u6839\u636e\u6d4b\u8bd5\u65f6\u9884\u7b97\u8fdb\u884c\u6a21\u578b\u538b\u7f29\uff0c\u4e14\u80fd\u5e73\u8861\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u5927\u5c0f\u7684\u6846\u67b6\u3002", "method": "\u7ed3\u5408\u5f39\u6027\u5f20\u91cf\u5206\u89e3\u3001\u79e9\u7ed1\u5b9a\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u548c\u8f7b\u91cf\u7ea7\u63a7\u5236\u5668\uff0c\u7528\u5feb\u901f\u5c42\u4e00\u81f4\u6027\u8bc1\u4e66\u4e0a\u754clogit\u6f02\u79fb\u5e76\u6b63\u5219\u5316\u8bad\u7ec3\u3002", "result": "\u5728ImageNet - 1k\u4e0a\uff0cT3C\u4f7fResNet - 50\u548cViT - B/16\u5728\u5339\u914d\u7cbe\u5ea6\u4e0b\uff0c\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u6a21\u578b\u5927\u5c0f\uff0c\u4f18\u4e8ePTQ - 8b\u7b49\u57fa\u7ebf\u3002", "conclusion": "\u5355\u4e2aT3C\u68c0\u67e5\u70b9\u80fd\u5728\u4e0d\u540c\u8bbe\u5907\u4e0a\u6309\u9700\u63d0\u4f9b\u6709\u8bc1\u4e66\u652f\u6301\u7684\u51c6\u786e\u6027 - \u5ef6\u8fdf - \u5927\u5c0f\u6743\u8861\u3002"}}
{"id": "2601.01315", "pdf": "https://arxiv.org/pdf/2601.01315", "abs": "https://arxiv.org/abs/2601.01315", "authors": ["Alireza Asadbeygi", "Anne M. Robertson", "Yasutaka Tobe", "Masoud Zamani", "Sean D. Stocker", "Paul Watton", "Naoki Yoshimura", "Simon C Watkins"], "title": "Quantifying Local Strain Field and Deformation in Active Contraction of Bladder Using a Pretrained Transformer Model: A Speckle-Free Approach", "categories": ["q-bio.TO", "cs.AI", "cs.CV"], "comment": null, "summary": "Accurate quantification of local strain fields during bladder contraction is essential for understanding the biomechanics of bladder micturition, in both health and disease. Conventional digital image correlation (DIC) methods have been successfully applied to various biological tissues; however, this approach requires artificial speckling, which can alter both passive and active properties of the tissue. In this study, we introduce a speckle-free framework for quantifying local strain fields using a state-of-the-art, zero-shot transformer model, CoTracker3. We utilized a custom-designed, portable isotonic biaxial apparatus compatible with multiphoton microscopy (MPM) to demonstrate this approach, successfully tracking natural bladder lumen textures without artificial markers. Benchmark tests validated the method's high pixel accuracy and low strain errors. Our framework effectively captured heterogeneous deformation patterns, despite complex folding and buckling, which conventional DIC often fails to track. Application to in vitro active bladder contractions in four rat specimens (n=4) revealed statistically significant anisotropy (p<0.01), with higher contraction longitudinally compared to circumferentially. Multiphoton microscopy further illustrated and confirmed heterogeneous morphological changes, such as large fold formation during active contraction. This non-invasive approach eliminates speckle-induced artifacts, enabling more physiologically relevant measurements, and has broad applicability for material testing of other biological and engineered systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65e0\u6591\u70b9\u6846\u67b6\u7528\u4e8e\u91cf\u5316\u8180\u80f1\u6536\u7f29\u5c40\u90e8\u5e94\u53d8\u573a\uff0c\u8be5\u6846\u67b6\u6709\u6548\u4e14\u80fd\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u7f3a\u9677\uff0c\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u4f20\u7edf\u6570\u5b57\u56fe\u50cf\u76f8\u5173\uff08DIC\uff09\u65b9\u6cd5\u7814\u7a76\u8180\u80f1\u6536\u7f29\u5c40\u90e8\u5e94\u53d8\u573a\u9700\u4eba\u5de5\u6563\u6591\uff0c\u4f1a\u6539\u53d8\u7ec4\u7ec7\u5c5e\u6027\uff0c\u56e0\u6b64\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u96f6\u6837\u672c\u53d8\u6362\u5668\u6a21\u578bCoTracker3\u7684\u65e0\u6591\u70b9\u6846\u67b6\uff0c\u5229\u7528\u517c\u5bb9\u591a\u5149\u5b50\u663e\u5fae\u955c\u7684\u7279\u5236\u53cc\u8f74\u88c5\u7f6e\u8ddf\u8e2a\u8180\u80f1\u8154\u5185\u81ea\u7136\u7eb9\u7406\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u65b9\u6cd5\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u8bef\u5dee\uff0c\u53ef\u6355\u6349\u590d\u6742\u53d8\u5f62\u6a21\u5f0f\uff0c\u5927\u9f20\u5b9e\u9a8c\u663e\u793a\u8180\u80f1\u6536\u7f29\u6709\u663e\u8457\u5404\u5411\u5f02\u6027\uff0c\u591a\u5149\u5b50\u663e\u5fae\u955c\u8bc1\u5b9e\u5f62\u6001\u53d8\u5316\u3002", "conclusion": "\u8be5\u975e\u4fb5\u5165\u6027\u65b9\u6cd5\u80fd\u6d88\u9664\u6563\u6591\u4f2a\u5f71\uff0c\u5b9e\u73b0\u66f4\u7b26\u5408\u751f\u7406\u7684\u6d4b\u91cf\uff0c\u5728\u751f\u7269\u548c\u5de5\u7a0b\u7cfb\u7edf\u6750\u6599\u6d4b\u8bd5\u4e2d\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2601.01322", "pdf": "https://arxiv.org/pdf/2601.01322", "abs": "https://arxiv.org/abs/2601.01322", "authors": ["Hongjie Wang", "Niraj K. Jha"], "title": "LinMU: Multimodal Understanding Made Linear", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "eess.IV"], "comment": "23 pages, 7 figures", "summary": "Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\\times$ and improves token throughput by up to 9.0$\\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.", "AI": {"tldr": "\u63d0\u51faLinMU\u89e3\u51b3VLM\u81ea\u6ce8\u610f\u529b\u4e8c\u6b21\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5b9e\u73b0\u7ebf\u6027\u590d\u6742\u5ea6\u5e76\u4fdd\u6301\u6027\u80fd\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u53d6\u5f97\u597d\u6548\u679c\u3002", "motivation": "\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u53d7\u81ea\u6ce8\u610f\u529b\u4e8c\u6b21\u590d\u6742\u5ea6\u9650\u5236\uff0c\u96be\u4ee5\u90e8\u7f72\u5728\u8fb9\u7f18\u8bbe\u5907\uff0c\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u548c\u957f\u4e0a\u4e0b\u6587\u89c6\u9891\u6210\u672c\u9ad8\u3002", "method": "\u7528M - MATE\u5757\u66ff\u4ee3VLM\u7684\u81ea\u6ce8\u610f\u529b\u5c42\uff0c\u5e76\u63d0\u51fa\u4e09\u9636\u6bb5\u84b8\u998f\u6846\u67b6\u5c06\u9884\u8bad\u7ec3VLM\u8f6c\u6362\u4e3aLinMU\u67b6\u6784\u3002", "result": "LinMU\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6027\u80fd\u4e0e\u6559\u5e08\u6a21\u578b\u76f8\u5f53\uff0c\u51cf\u5c11\u4e86\u9996\u8bcd\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e86\u5206\u949f\u957f\u5ea6\u89c6\u9891\u7684\u541e\u5410\u91cf\u3002", "conclusion": "\u65e0\u9700\u4e8c\u6b21\u6ce8\u610f\u529b\u4e5f\u80fd\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u63a8\u7406\uff0c\u4e3a\u5904\u7406\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u548c\u957f\u89c6\u9891\u7684\u957f\u4e0a\u4e0b\u6587VLMs\u5f00\u8f9f\u9014\u5f84\u3002"}}
{"id": "2601.01347", "pdf": "https://arxiv.org/pdf/2601.01347", "abs": "https://arxiv.org/abs/2601.01347", "authors": ["Yuyan Pi", "Min Jin", "Wentao Xie", "Xinhua Liu"], "title": "From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion", "categories": ["cs.LG", "cs.AI"], "comment": "34 pages,5 figures", "summary": "Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eGraph - Motif\u7279\u5f81\u878d\u5408\u548c\u591a\u6807\u7b7e\u751f\u6210\u7684\u5f00\u653e\u5f0fADR\u9884\u6d4b\u8303\u5f0fGM - MLG\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u5e76\u80fd\u89e3\u91caADR\u4e0e\u57fa\u5e8f\u7684\u5173\u7cfb\u3002", "motivation": "\u5f53\u524d\u836f\u7269\u4e0d\u826f\u53cd\u5e94\uff08ADR\uff09\u9884\u6d4b\u65b9\u6cd5\u53d7\u836f\u7269\u6570\u636e\u7a00\u7f3a\u3001\u5c01\u95ed\u6807\u7b7e\u96c6\u548c\u6807\u7b7e\u4f9d\u8d56\u5efa\u6a21\u4e0d\u8db3\u7684\u9650\u5236\uff0c\u4e3a\u964d\u4f4e\u65b0\u836f\u5f00\u53d1\u6210\u672c\u548c\u5468\u671f\uff0c\u9700\u6539\u8fdb\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5206\u5b50\u7ed3\u6784\u4f5c\u4e3a\u7279\u5f81\uff0c\u6784\u5efa\u539f\u5b50\u3001\u5c40\u90e8\u5206\u5b50\u548c\u5168\u5c40\u5206\u5b50\u7684\u53cc\u56fe\u8868\u793a\u67b6\u6784\uff1b\u5c06ADR\u9884\u6d4b\u4ece\u591a\u6807\u7b7e\u5206\u7c7b\u8f6c\u53d8\u4e3a\u57fa\u4e8eTransformer\u89e3\u7801\u5668\u7684\u591a\u6807\u7b7e\u751f\u6210\uff0c\u7528\u4f4d\u7f6e\u5d4c\u5165\u6355\u6349\u6807\u7b7e\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u81ea\u56de\u5f52\u89e3\u7801\u751f\u6210\u9884\u6d4b\u3002", "result": "GM - MLG\u5b9e\u73b0\u4e86\u9ad8\u8fbe38%\u7684\u63d0\u5347\uff0c\u5e73\u5747\u63d0\u534720%\uff0c\u9884\u6d4b\u7a7a\u95f4\u4ece200\u79cd\u6269\u5c55\u5230\u8d8510000\u79cd\uff1b\u901a\u8fc7\u9006\u5411\u5408\u6210\u57fa\u5e8f\u5206\u6790\u9610\u660e\u4e86ADR\u4e0e\u57fa\u5e8f\u7684\u975e\u7ebf\u6027\u6784\u6548\u5173\u7cfb\u3002", "conclusion": "GM - MLG\u5728ADR\u9884\u6d4b\u4e0a\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u80fd\u4e3a\u964d\u4f4e\u836f\u7269\u5b89\u5168\u7684\u7cfb\u7edf\u6027\u98ce\u9669\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u521b\u65b0\u652f\u6301\u3002"}}
{"id": "2601.01352", "pdf": "https://arxiv.org/pdf/2601.01352", "abs": "https://arxiv.org/abs/2601.01352", "authors": ["Yixuan Lai", "He Wang", "Kun Zhou", "Tianjia Shao"], "title": "Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and \"average\" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77ed\u53c2\u8003\u89c6\u9891\u7684\u8eab\u4efd\u6761\u4ef6\u6269\u6563\u53d8\u538b\u5668\u89c6\u9891\u751f\u6210\u5668\uff0c\u6539\u5584\u8eab\u4efd\u4fdd\u7559\u3002", "motivation": "\u751f\u6210\u7b26\u5408\u63d0\u793a\u4e14\u4fdd\u7559\u6307\u5b9a\u8eab\u4efd\u7684\u89c6\u9891\u6709\u6311\u6218\uff0c\u5355\u5f20\u56fe\u50cf\u4f5c\u6761\u4ef6\u4f1a\u5bfc\u81f4\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8eab\u4efd\u6761\u4ef6\u6269\u6563\u53d8\u538b\u5668\u89c6\u9891\u751f\u6210\u5668\uff0c\u7528\u77ed\u53c2\u8003\u89c6\u9891\uff0cSinkhorn\u8def\u7531\u7f16\u7801\u5668\u5b66\u4e60\u7d27\u51d1\u8eab\u4efd\u4ee4\u724c\u3002", "result": "\u5728\u5927\u59ff\u6001\u53d8\u5316\u548c\u4e30\u5bcc\u9762\u90e8\u8868\u60c5\u4e0b\u6301\u7eed\u6539\u5584\u8eab\u4efd\u4fdd\u7559\uff0c\u4fdd\u6301\u63d0\u793a\u4e00\u81f4\u6027\u548c\u89c6\u89c9\u771f\u5b9e\u611f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u751f\u6210\u89c6\u9891\u65f6\u8eab\u4efd\u4fdd\u7559\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2601.01373", "pdf": "https://arxiv.org/pdf/2601.01373", "abs": "https://arxiv.org/abs/2601.01373", "authors": ["Qundong Shi", "Jie Zhou", "Biyuan Lin", "Junbo Cui", "Guoyang Zeng", "Yixuan Zhou", "Ziyang Wang", "Xin Liu", "Zhen Luo", "Yudong Wang", "Zhiyuan Liu"], "title": "UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "13 pages, 2 figures", "summary": "The development of audio foundation models has accelerated rapidly since the emergence of GPT-4o. However, the lack of comprehensive evaluation has become a critical bottleneck for further progress in the field, particularly in audio generation. Current audio evaluation faces three major challenges: (1) audio evaluation lacks a unified framework, with datasets and code scattered across various sources, hindering fair and efficient cross-model comparison;(2) audio codecs, as a key component of audio foundation models, lack a widely accepted and holistic evaluation methodology; (3) existing speech benchmarks are heavily reliant on English, making it challenging to objectively assess models' performance on Chinese. To address the first issue, we introduce UltraEval-Audio, a unified evaluation framework for audio foundation models, specifically designed for both audio understanding and generation tasks. UltraEval-Audio features a modular architecture, supporting 10 languages and 14 core task categories, while seamlessly integrating 24 mainstream models and 36 authoritative benchmarks. To enhance research efficiency, the framework provides a one-command evaluation feature, accompanied by real-time public leaderboards. For the second challenge, UltraEval-Audio adopts a novel comprehensive evaluation scheme for audio codecs, evaluating performance across three key dimensions: semantic accuracy, timbre fidelity, and acoustic quality. To address the third issue, we propose two new Chinese benchmarks, SpeechCMMLU and SpeechHSK, designed to assess Chinese knowledge proficiency and language fluency. We wish that UltraEval-Audio will provide both academia and industry with a transparent, efficient, and fair platform for comparison of audio models. Our code, benchmarks, and leaderboards are available at https://github.com/OpenBMB/UltraEval-Audio.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u97f3\u9891\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u7efc\u5408\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u4ecb\u7ecd\u4e86UltraEval - Audio\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u8fd8\u63d0\u51fa\u65b0\u7684\u4e2d\u6587\u57fa\u51c6\uff0c\u4e3a\u97f3\u9891\u6a21\u578b\u6bd4\u8f83\u63d0\u4f9b\u5e73\u53f0\u3002", "motivation": "\u97f3\u9891\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u7efc\u5408\u8bc4\u4f30\u6210\u4e3a\u9886\u57df\u53d1\u5c55\u74f6\u9888\uff0c\u73b0\u6709\u97f3\u9891\u8bc4\u4f30\u5b58\u5728\u65e0\u7edf\u4e00\u6846\u67b6\u3001\u97f3\u9891\u7f16\u89e3\u7801\u5668\u7f3a\u4e4f\u8bc4\u4f30\u65b9\u6cd5\u3001\u73b0\u6709\u8bed\u97f3\u57fa\u51c6\u4f9d\u8d56\u82f1\u8bed\u96be\u4ee5\u8bc4\u4f30\u4e2d\u6587\u8868\u73b0\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165UltraEval - Audio\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u65b0\u7684\u97f3\u9891\u7f16\u89e3\u7801\u5668\u7efc\u5408\u8bc4\u4f30\u65b9\u6848\uff0c\u63d0\u51fa\u4e24\u4e2a\u65b0\u7684\u4e2d\u6587\u57fa\u51c6SpeechCMMLU\u548cSpeechHSK\u3002", "result": "UltraEval - Audio\u5177\u6709\u6a21\u5757\u5316\u67b6\u6784\uff0c\u652f\u6301\u591a\u8bed\u8a00\u548c\u591a\u4efb\u52a1\u7c7b\u522b\uff0c\u96c6\u6210\u4e3b\u6d41\u6a21\u578b\u548c\u6743\u5a01\u57fa\u51c6\uff0c\u63d0\u4f9b\u4e00\u952e\u8bc4\u4f30\u548c\u5b9e\u65f6\u516c\u5f00\u6392\u884c\u699c\u3002", "conclusion": "\u5e0c\u671bUltraEval - Audio\u4e3a\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u63d0\u4f9b\u900f\u660e\u3001\u9ad8\u6548\u3001\u516c\u5e73\u7684\u97f3\u9891\u6a21\u578b\u6bd4\u8f83\u5e73\u53f0\uff0c\u4ee3\u7801\u7b49\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.01383", "pdf": "https://arxiv.org/pdf/2601.01383", "abs": "https://arxiv.org/abs/2601.01383", "authors": ["Yen-Chia Chen", "Hsing-Kuo Pao", "Hanjuan Huang"], "title": "Data Complexity-aware Deep Model Performance Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 12 figures", "summary": "Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u4e24\u9636\u6bb5\u6846\u67b6\u4f30\u8ba1\u6a21\u578b\u6027\u80fd\uff0c\u53ef\u8de8\u6570\u636e\u96c6\u548c\u6a21\u578b\u7c7b\u578b\u6cdb\u5316\uff0c\u8fd8\u80fd\u7528\u4e8e\u6307\u5bfc\u6a21\u578b\u9009\u62e9\u7b49\u3002", "motivation": "\u4f20\u7edf\u9009\u62e9\u6a21\u578b\u67b6\u6784\u7684\u8bd5\u9519\u6cd5\u8017\u65f6\u3001\u8017\u8d44\u6e90\u4e14\u96be\u81ea\u52a8\u5316\uff0c\u5148\u524d\u5de5\u4f5c\u6709\u8ba1\u7b97\u5f00\u9500\u5927\u6216\u7f3a\u4e4f\u6cdb\u5316\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u57fa\u4e8e\u6570\u636e\u96c6\u53ef\u6d4b\u91cf\u5c5e\u6027\u5206\u6790\u9884\u6d4b\u57fa\u7ebf\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7528\u6a21\u578b\u67b6\u6784\u548c\u8d85\u53c2\u6570\u4fe1\u606f\u8c03\u6574\u4f30\u8ba1\u3002", "result": "\u6846\u67b6\u80fd\u8de8\u6570\u636e\u96c6\u548c\u6a21\u578b\u7c7b\u578b\u6cdb\u5316\uff0c\u4e00\u4e9b\u9884\u6d4b\u7279\u5f81\u80fd\u6307\u5bfc\u6a21\u578b\u9009\u62e9\u548c\u53cd\u6620\u6570\u636e\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u9884\u6d4b\u6a21\u578b\u6027\u80fd\uff0c\u8fd8\u80fd\u6307\u5bfc\u67b6\u6784\u9009\u62e9\u3001\u9884\u5904\u7406\u8fc7\u7a0b\u548c\u68c0\u6d4b\u95ee\u9898\u6570\u636e\u96c6\u3002"}}
{"id": "2601.01386", "pdf": "https://arxiv.org/pdf/2601.01386", "abs": "https://arxiv.org/abs/2601.01386", "authors": ["Xiaobao Wei", "Zhangjie Ye", "Yuxiang Gu", "Zunjie Zhu", "Yunfei Guo", "Yingying Shen", "Shan Zhao", "Ming Lu", "Haiyang Sun", "Bing Wang", "Guang Chen", "Rongfeng Lu", "Hangjun Ye"], "title": "ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian", "AI": {"tldr": "\u63d0\u51faParkRecon3D\u57fa\u51c6\u548cParkGaussian\u6846\u67b6\u7528\u4e8e\u505c\u8f66\u573a\u573a\u666f3D\u91cd\u5efa\uff0c\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u4e0b\u6e38\u4efb\u52a1\u611f\u77e5\u4e00\u81f4\u6027\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5728\u505c\u8f66\u573a3D\u91cd\u5efa\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u4e14\u5355\u7eaf\u63d0\u5347\u91cd\u5efa\u89c6\u89c9\u8d28\u91cf\u5bf9\u81ea\u52a8\u9a7e\u9a76\u505c\u8f66\u65e0\u76f4\u63a5\u5e2e\u52a9\uff0c\u5173\u952e\u5728\u4e8e\u8f66\u4f4d\u611f\u77e5\u6a21\u5757\u3002", "method": "\u521b\u5efaParkRecon3D\u57fa\u51c6\uff0c\u63d0\u51fa\u96c6\u62103D\u9ad8\u65af splatting\u7684ParkGaussian\u6846\u67b6\uff0c\u5f15\u5165\u8f66\u4f4d\u611f\u77e5\u91cd\u5efa\u7b56\u7565\u3002", "result": "\u5728ParkRecon3D\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cParkGaussian\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u91cd\u5efa\u8d28\u91cf\uff0c\u66f4\u597d\u5730\u4fdd\u7559\u4e86\u4e0b\u6e38\u4efb\u52a1\u7684\u611f\u77e5\u4e00\u81f4\u6027\u3002", "conclusion": "ParkRecon3D\u57fa\u51c6\u548cParkGaussian\u6846\u67b6\u5728\u505c\u8f66\u573a\u573a\u666f3D\u91cd\u5efa\u4e2d\u6709\u6548\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u516c\u5f00\u3002"}}
{"id": "2601.01387", "pdf": "https://arxiv.org/pdf/2601.01387", "abs": "https://arxiv.org/abs/2601.01387", "authors": ["Yongzhe Li", "Lin Guan", "Zihan Cai", "Zuxian Lin", "Jiyu Huang", "Liukai Chen"], "title": "Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSaMPFA\u6846\u67b6\u7528\u4e8e\u6f6e\u6d41\u5206\u6790\uff0c\u901a\u8fc7LTS\u91c7\u6837\u6280\u672f\u548cRMGL\u6a21\u578b\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u66f4\u597d\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u7cbe\u5ea6\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5f00\u53d1\u5bf9\u62d3\u6251\u53d8\u5316\u6709\u5f3a\u9002\u5e94\u6027\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u6f6e\u6d41\u5206\u6790\uff0c\u63d0\u5347\u6a21\u578b\u5728\u53ef\u53d8\u7cfb\u7edf\u89c4\u6a21\u4e0b\u7684\u6027\u80fd\u548c\u652f\u8def\u529f\u7387\u9884\u6d4b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faSaMPFA\u6846\u67b6\uff0c\u5f15\u5165LTS\u91c7\u6837\u6280\u672f\u589e\u5f3a\u8de8\u5c3a\u5ea6\u5b66\u4e60\u80fd\u529b\uff0c\u8bbe\u8ba1RMGL\u6a21\u578b\u9884\u6d4b\u6bcd\u7ebf\u7535\u538b\u548c\u652f\u8def\u529f\u7387\uff0c\u635f\u5931\u51fd\u6570\u52a0\u5165\u989d\u5916\u9879\u6355\u6349\u7269\u7406\u6a21\u5f0f\u3002", "result": "\u5728IEEE 39 - \u6bcd\u7ebf\u7cfb\u7edf\u548c\u4e2d\u56fd\u67d0\u7701\u7ea7\u7535\u7f51\u4eff\u771f\u4e2d\uff0c\u6a21\u578b\u5728\u53ef\u53d8\u7cfb\u7edf\u89c4\u6a21\u4e0b\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4f18\u8d8a\uff0c\u7cbe\u5ea6\u5206\u522b\u63d0\u53474.47%\u548c36.82%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u53ef\u53d8\u7cfb\u7edf\u89c4\u6a21\u4e0b\u80fd\u5b9e\u73b0\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2601.01403", "pdf": "https://arxiv.org/pdf/2601.01403", "abs": "https://arxiv.org/abs/2601.01403", "authors": ["Zewei Yu", "Jianqiu Xu", "Caimin Li"], "title": "A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages", "summary": "With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u6a21\u578b\u96c6\u6210\u7684\u65e0\u76d1\u7763\u56fe\u57fa\u6846\u67b6GDME\u505a\u5728\u7ebf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u73b0\u6709\u65b9\u6cd5\u4f1824%\u3002", "motivation": "\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u6d41\u6570\u636e\u589e\u591a\uff0c\u73b0\u6709\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u7528\u4e8e\u5728\u7ebf\u68c0\u6d4b\u548c\u5904\u7406\u5f02\u6784\u6d41\u6570\u636e\u3002", "method": "\u63d0\u51faGDME\u6846\u67b6\uff0c\u7ef4\u62a4\u52a8\u6001\u6a21\u578b\u6c60\uff0c\u7528\u52a8\u6001\u56fe\u7ed3\u6784\u8868\u793a\u6a21\u578b\u5173\u7cfb\uff0c\u7528\u793e\u533a\u68c0\u6d4b\u9009\u62e9\u96c6\u6210\u5b50\u96c6\uff0c\u901a\u8fc7\u76d1\u6d4b\u56fe\u7ed3\u6784\u53d8\u5316\u68c0\u6d4b\u6982\u5ff5\u6f02\u79fb\u3002", "result": "\u5728\u4e03\u4e2a\u5f02\u6784\u65f6\u95f4\u5e8f\u5217\u5b9e\u9a8c\u4e2d\uff0cGDME\u6bd4\u73b0\u6709\u5728\u7ebf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4f1824%\uff0c\u5176\u96c6\u6210\u7b56\u7565\u6bd4\u5355\u4e2a\u6a21\u578b\u548c\u5e73\u5747\u96c6\u6210\u68c0\u6d4b\u6027\u80fd\u66f4\u597d\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "GDME\u6846\u67b6\u5728\u5728\u7ebf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u6709\u6548\u5904\u7406\u5f02\u6784\u6d41\u6570\u636e\u5e76\u9002\u5e94\u6570\u636e\u53d8\u5316\u3002"}}
{"id": "2601.01406", "pdf": "https://arxiv.org/pdf/2601.01406", "abs": "https://arxiv.org/abs/2601.01406", "authors": ["Habiba Kausar", "Saeed Anwar", "Omar Jamal Hammad", "Abdul Bais"], "title": "SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSwinIFS\u6846\u67b6\u7528\u4e8e\u4eba\u8138\u8d85\u5206\u8fa8\u7387\uff0c\u7ed3\u5408\u7ed3\u6784\u5148\u9a8c\u548c\u5206\u5c42\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728CelebA\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u517c\u987e\u91cd\u5efa\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4eba\u8138\u8d85\u5206\u8fa8\u7387\u56e0\u7cbe\u7ec6\u7ed3\u6784\u7ec6\u8282\u548c\u7279\u5b9a\u8eab\u4efd\u7279\u5f81\u4e22\u5931\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u5b9e\u73b0\u8eab\u4efd\u4fdd\u7559\u91cd\u5efa\u3002", "method": "\u5f15\u5165SwinIFS\u6846\u67b6\uff0c\u5c06\u5173\u952e\u9762\u90e8\u7279\u5f81\u70b9\u7684\u9ad8\u65af\u70ed\u56fe\u878d\u5165\u8f93\u5165\u8868\u793a\uff0c\u4f7f\u7528\u7d27\u51d1\u7684Swin Transformer\u9aa8\u5e72\u7f51\u7edc\u6355\u6349\u957f\u8ddd\u79bb\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u5728CelebA\u57fa\u51c6\u4e0a\uff0cSwinIFS\u5b9e\u73b0\u5353\u8d8a\u611f\u77e5\u8d28\u91cf\u3001\u66f4\u6e05\u6670\u91cd\u5efa\u548c\u66f4\u597d\u7684\u8eab\u4efd\u4fdd\u7559\uff0c\u57288\u500d\u653e\u5927\u4e0b\u4e5f\u8868\u73b0\u826f\u597d\uff0c\u80fd\u751f\u6210\u66f4\u903c\u771f\u7684\u7ed3\u679c\u3002", "conclusion": "SwinIFS\u5728\u91cd\u5efa\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4f18\u52bf\u5e73\u8861\uff0c\u9002\u5408\u4eba\u8138\u589e\u5f3a\u3001\u76d1\u63a7\u548c\u6570\u5b57\u4fee\u590d\u7b49\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.01410", "pdf": "https://arxiv.org/pdf/2601.01410", "abs": "https://arxiv.org/abs/2601.01410", "authors": ["Jisoo Lee", "Sunki Hong"], "title": "Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems", "categories": ["eess.SY", "cs.AI", "cs.LG"], "comment": "24 pages, 8 figures, 8 tables", "summary": "Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework--Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin--that directly measures operational risk rather than statistical accuracy alone.\n  Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for California grid forecasting on a weather-aligned CAISO TAC-area dataset spanning Nov 2023--Nov 2025 (84,498 hourly records across 5 transmission areas). Our analysis reveals that standard accuracy metrics are poor proxies for operational safety: models with identical MAPE can require vastly different reserve margins.\n  We demonstrate that forecast errors are weakly but significantly associated with temperature (r = 0.16, p < 10^{-16}), motivating weather-aware modeling rather than loss function modification alone. The S-Mamba model achieves the lowest Reserve_{99.5}% margin (14.12%) compared to 16.66% for iTransformer, demonstrating superior forecast reliability under a 99.5th-percentile tail-risk reserve proxy.", "AI": {"tldr": "\u63d0\u51fa\u7535\u7f51\u7279\u5b9a\u8bc4\u4f30\u6846\u67b6\u8bc4\u4f30Mamba\u57fa\u6a21\u578b\u7528\u4e8e\u52a0\u5dde\u7535\u7f51\u8d1f\u8377\u9884\u6d4b\uff0c\u53d1\u73b0\u6807\u51c6\u6307\u6807\u4e0d\u80fd\u53cd\u6620\u8fd0\u884c\u5b89\u5168\uff0cS - Mamba\u6a21\u578b\u5728\u5c3e\u90e8\u98ce\u9669\u50a8\u5907\u4ee3\u7406\u4e0b\u9884\u6d4b\u53ef\u9760\u6027\u66f4\u4f18\u3002", "motivation": "\u51c6\u786e\u7684\u7535\u7f51\u8d1f\u8377\u9884\u6d4b\u5bf9\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u5bf9\u79f0\u8bef\u5dee\u6307\u6807\u63a9\u76d6\u4e86\u8fd0\u884c\u4e0d\u5bf9\u79f0\u6027\uff0c\u9700\u76f4\u63a5\u8861\u91cf\u8fd0\u884c\u98ce\u9669\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f15\u5165\u7535\u7f51\u7279\u5b9a\u8bc4\u4f30\u6846\u67b6\uff08Asymmetric MAPE\u3001Under - Prediction Rate\u548cReserve Margin\uff09\uff0c\u5728\u52a0\u5dde\u7535\u7f51\u6570\u636e\u96c6\u4e0a\u5bf9Mamba\u57fa\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u6807\u51c6\u51c6\u786e\u6027\u6307\u6807\u4e0d\u80fd\u5f88\u597d\u53cd\u6620\u8fd0\u884c\u5b89\u5168\uff1b\u9884\u6d4b\u8bef\u5dee\u4e0e\u6e29\u5ea6\u6709\u5f31\u4f46\u663e\u8457\u5173\u8054\uff1bS - Mamba\u6a21\u578b\u572899.5%\u5c3e\u90e8\u98ce\u9669\u50a8\u5907\u4ee3\u7406\u4e0b\u50a8\u5907\u8fb9\u9645\u6700\u4f4e\u3002", "conclusion": "\u5e94\u91c7\u7528\u8003\u8651\u8fd0\u884c\u98ce\u9669\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u5929\u6c14\u611f\u77e5\u5efa\u6a21\uff0cS - Mamba\u6a21\u578b\u6709\u66f4\u4f18\u9884\u6d4b\u53ef\u9760\u6027\u3002"}}
{"id": "2601.01438", "pdf": "https://arxiv.org/pdf/2601.01438", "abs": "https://arxiv.org/abs/2601.01438", "authors": ["Russell Buchanan", "Adrian R\u00f6fer", "Jo\u00e3o Moura", "Abhinav Valada", "Sethu Vijayakumar"], "title": "Online Estimation and Manipulation of Articulated Objects", "categories": ["cs.RO", "cs.AI"], "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Autonomous Robots, and is available online at [Link will be updated when available]", "summary": "From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u89c6\u89c9\u5148\u9a8c\u4e0e\u672c\u4f53\u611f\u53d7\u4f20\u611f\u7684\u65b0\u65b9\u6cd5\u6765\u4f30\u8ba1\u94f0\u63a5\u7269\u4f53\u7684\u5173\u8282\u8fd0\u52a8\uff0c\u7ecf\u6a21\u62df\u548c\u771f\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u673a\u5668\u4eba\u81ea\u4e3b\u6253\u5f00\u672a\u77e5\u94f0\u63a5\u7269\u4f53\u6210\u529f\u7387\u8fbe75%\u3002", "motivation": "\u670d\u52a1\u673a\u5668\u4eba\u9700\u81ea\u52a8\u64cd\u4f5c\u4efb\u610f\u94f0\u63a5\u7269\u4f53\uff0c\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u548c\u89c2\u6d4b\u8fd0\u52a8\u65b9\u6cd5\u90fd\u6709\u5c40\u9650\u3002", "method": "\u91c7\u7528\u56e0\u5b50\u56fe\u5728\u7ebf\u4f30\u8ba1\u5173\u8282\u8fd0\u52a8\uff0c\u5c06\u5b66\u4e60\u5230\u7684\u89c6\u89c9\u5148\u9a8c\u548c\u4ea4\u4e92\u65f6\u7684\u672c\u4f53\u611f\u53d7\u4f20\u611f\u878d\u5408\u5230\u57fa\u4e8e\u65cb\u91cf\u7406\u8bba\u7684\u5173\u8282\u5206\u6790\u6a21\u578b\u4e2d\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u673a\u5668\u4eba\u64cd\u4f5c\u5b9e\u9a8c\u4e2d\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u673a\u5668\u4eba\u80fd\u6253\u5f00\u4e4b\u524d\u672a\u89c1\u8fc7\u7684\u62bd\u5c49\uff0c\u771f\u5b9e\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u81ea\u4e3b\u6253\u5f00\u672a\u77e5\u94f0\u63a5\u7269\u4f53\u6210\u529f\u7387\u8fbe75%\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u8ba9\u673a\u5668\u4eba\u8f83\u597d\u5730\u4f30\u8ba1\u5e76\u64cd\u4f5c\u672a\u77e5\u94f0\u63a5\u7269\u4f53\u3002"}}
{"id": "2601.01452", "pdf": "https://arxiv.org/pdf/2601.01452", "abs": "https://arxiv.org/abs/2601.01452", "authors": ["Jian Feng", "Zhihong Huang"], "title": "Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 1 figures, 4 tables", "summary": "Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/\u03b3$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\\times$--1.08$\\times$ of MeZO).", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d1d\u53f6\u65af\u5b50\u7a7a\u95f4\u96f6\u9636\u4f18\u5316\u5668\uff08BSZO\uff09\uff0c\u901a\u8fc7\u5361\u5c14\u66fc\u6ee4\u6ce2\u7ed3\u5408\u591a\u6270\u52a8\u65b9\u5411\u4fe1\u606f\uff0c\u7406\u8bba\u4e0a\u63d0\u5347\u6536\u655b\u901f\u5ea6\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5728\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u4f9d\u8d56\u5355\u6b65\u68af\u5ea6\u4f30\u8ba1\uff0c\u63d0\u51fa\u65b0\u7684\u4f18\u5316\u5668\u4ee5\u6539\u8fdb\u3002", "method": "\u63d0\u51fa BSZO \u4f18\u5316\u5668\uff0c\u4f7f\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u7ed3\u5408\u591a\u6270\u52a8\u65b9\u5411\u6709\u9650\u5dee\u5206\u4fe1\u606f\uff0c\u5c06\u6bcf\u6b21\u6d4b\u91cf\u4f5c\u4e3a\u566a\u58f0\u89c2\u6d4b\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u7406\u66f4\u65b0\u6295\u5f71\u68af\u5ea6\u540e\u9a8c\u5206\u5e03\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u6b8b\u5dee\u7684\u81ea\u9002\u5e94\u673a\u5236\u8c03\u6574\u6270\u52a8\u5c3a\u5ea6\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e BSZO \u6bd4\u6807\u51c6\u96f6\u9636\u65b9\u6cd5\u6536\u655b\u901f\u5ea6\u63d0\u9ad8 k/\u03b3 \u500d\uff1b\u5728 RoBERTa\u3001Mistral \u548c OPT \u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0c\u4f18\u4e8e MeZO\u3001MeZO - Adam \u548c HiZOO\uff0c\u5728 OPT - 13B \u4e0a\u6700\u9ad8\u6709 6.67% \u7edd\u5bf9\u5e73\u5747\u63d0\u5347\uff0c\u5185\u5b58\u4f7f\u7528\u63a5\u8fd1\u63a8\u7406\u57fa\u7ebf\u3002", "conclusion": "BSZO \u662f\u4e00\u79cd\u6709\u6548\u7684\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u80fd\u63d0\u9ad8\u6536\u655b\u901f\u5ea6\u548c\u6027\u80fd\uff0c\u540c\u65f6\u63a7\u5236\u5185\u5b58\u4f7f\u7528\u3002"}}
{"id": "2601.01456", "pdf": "https://arxiv.org/pdf/2601.01456", "abs": "https://arxiv.org/abs/2601.01456", "authors": ["Wentao Bian", "Fenglei Xu"], "title": "Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "10 pages, 4 figures, 3 tables", "summary": "In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in \"Fuse-then-Refine\" paradigms: the \"Plasticity-Stability Dilemma.\" In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u6a21\u6001\u5c11\u6837\u672c3D\u70b9\u4e91\u8bed\u4e49\u5206\u5272\u95ee\u9898\uff0c\u63d0\u51faDA - FSS\u6a21\u578b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8eMM - FSS\u3002", "motivation": "\u53d1\u73b0\u201cFuse - then - Refine\u201d\u8303\u5f0f\u5b58\u5728\u201c\u53ef\u5851\u6027 - \u7a33\u5b9a\u6027\u56f0\u5883\u201d\uff0c\u4e14CLIP\u5b58\u5728\u7c7b\u95f4\u6df7\u6dc6\u5bfc\u81f4\u8bed\u4e49\u76f2\u76ee\u95ee\u9898\u3002", "method": "\u63d0\u51faDA - FSS\u6a21\u578b\uff0c\u533a\u5206\u8bed\u4e49\u548c\u51e0\u4f55\u8def\u5f84\u5e76\u76f8\u4e92\u6b63\u5219\u5316\u68af\u5ea6\uff1b\u63d0\u51fa\u5e76\u884c\u4e13\u5bb6\u7ec6\u5316\u6a21\u5757\u548c\u5806\u53e0\u4ef2\u88c1\u6a21\u5757\uff1b\u901a\u8fc7\u89e3\u8026\u5bf9\u9f50\u6a21\u5757\u534f\u8c03\u4e24\u4e2a\u4e13\u5bb6\u8def\u5f84\u3002", "result": "\u5728S3DIS\u3001ScanNet\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660eDA - FSS\u4f18\u4e8eMM - FSS\uff0c\u51e0\u4f55\u8fb9\u754c\u3001\u5b8c\u6574\u6027\u548c\u7eb9\u7406\u533a\u5206\u5ea6\u5747\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "DA - FSS\u6a21\u578b\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u5c11\u6837\u672c3D\u70b9\u4e91\u8bed\u4e49\u5206\u5272\u7684\u95ee\u9898\uff0c\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.01487", "pdf": "https://arxiv.org/pdf/2601.01487", "abs": "https://arxiv.org/abs/2601.01487", "authors": ["Ziyue Zhang", "Luxi Lin", "Xiaolin Hu", "Chao Chang", "HuaiXi Wang", "Yiyi Zhou", "Rongrong Ji"], "title": "DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3aDeepInv\u7684\u81ea\u76d1\u7763\u6269\u6563\u53cd\u6f14\u65b9\u6cd5\uff0c\u53ef\u5feb\u901f\u51c6\u786e\u5b9e\u73b0\u56fe\u50cf\u5230\u566a\u58f0\u6620\u5c04\uff0c\u6027\u80fd\u548c\u901f\u5ea6\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u53cd\u6f14\u56e0\u7f3a\u4e4f\u53ef\u884c\u76d1\u7763\u4fe1\u53f7\u4ecd\u662f\u6311\u6218\u4efb\u52a1\uff0c\u73b0\u6709\u8fd1\u4f3c\u89e3\u51b3\u65b9\u6848\u727a\u7272\u6027\u80fd\u6216\u6548\u7387\u3002", "method": "\u5f15\u5165\u81ea\u76d1\u7763\u76ee\u6807\u548c\u6570\u636e\u589e\u5f3a\u7b56\u7565\u751f\u6210\u9ad8\u8d28\u91cf\u4f2a\u566a\u58f0\uff0c\u91c7\u7528\u8fed\u4ee3\u548c\u591a\u5c3a\u5ea6\u8bad\u7ec3\u673a\u5236\u8bad\u7ec3\u53c2\u6570\u5316\u53cd\u6f14\u6c42\u89e3\u5668\u3002", "result": "\u5728COCO\u6570\u636e\u96c6\u4e0a\uff0cDeepInv\u6bd4EasyInv\u7684SSIM\u9ad840.435%\uff0c\u6bd4ReNoise\u901f\u5ea6\u5feb9887.5%\u3002", "conclusion": "DeepInv\u6027\u80fd\u548c\u63a8\u7406\u901f\u5ea6\u4f73\uff0c\u5176\u53ef\u8bad\u7ec3\u6c42\u89e3\u5668\u7684\u8bbe\u8ba1\u80fd\u4e3a\u5b66\u754c\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2601.01490", "pdf": "https://arxiv.org/pdf/2601.01490", "abs": "https://arxiv.org/abs/2601.01490", "authors": ["Junichiro Niimi"], "title": "Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.", "AI": {"tldr": "\u7814\u7a76\u5728\u4e25\u683c\u7ea6\u675f\u4e0b\u63a8\u7406\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u5b58\u5728\u7ea6\u675f\u9075\u5b88\u4e0e\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u6743\u8861\uff0c\u6311\u6218\u63a8\u7406\u63d0\u5347\u53ef\u9760\u6027\u7684\u5047\u8bbe\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u4e25\u91cd\uff0c\u63a8\u7406\u80fd\u529b\u53d7\u5173\u6ce8\u4ee5\u63d0\u5347\u8f93\u51fa\u53ef\u9760\u6027\uff0c\u4f46\u5c01\u95ed\u7cfb\u7edf\u5185\u63a8\u7406\u6548\u679c\u672a\u660e\u786e\uff0c\u56e0\u6b64\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5728\u4e25\u683c\u7ea6\u675f\uff08\u63a8\u8350\u8ba1\u7b97\u673a\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u671f\u520a\u6587\u7ae0\uff09\u4e0b\uff0c\u5bf9GPT - 5.2\u548cGemini 3 Flash\u591a\u4e2a\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u975e\u63a8\u7406\u6a21\u578b\u7ea6\u675f\u8fdd\u53cd\u7387\u9ad8\u4f46\u4fdd\u6301\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u63a8\u7406\u6a21\u578b\u964d\u4f4e\u8fdd\u53cd\u7387\u4f46\u4f1a\u626d\u66f2\u4e8b\u5b9e\u3001\u589e\u52a0\u5b8c\u5168\u7f16\u9020\uff0c\u8be5\u6743\u8861\u6a21\u5f0f\u5728\u4e24\u6a21\u578b\u4e2d\u4e00\u81f4\uff1b\u63a8\u7406\u5bf9\u8f93\u51fa\u771f\u5b9e\u6027\u7684\u63d0\u5347\u56e0\u6a21\u578b\u800c\u5f02\u3002", "conclusion": "\u63a8\u7406\u5e76\u975e\u666e\u904d\u63d0\u5347\u53ef\u9760\u6027\uff0c\u63a8\u7406\u6a21\u578b\u4ee5\u4e0d\u6613\u68c0\u6d4b\u7684\u626d\u66f2\u66ff\u4ee3\u8bda\u5b9e\u7684\u7ea6\u675f\u8fdd\u53cd\u3002"}}
{"id": "2601.01513", "pdf": "https://arxiv.org/pdf/2601.01513", "abs": "https://arxiv.org/abs/2601.01513", "authors": ["Gen Li", "Peiyu Liu"], "title": "FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.", "AI": {"tldr": "\u63d0\u51fa VideoSpeculateRAG \u6846\u67b6\u89e3\u51b3 VLM \u96c6\u6210\u5916\u90e8\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6295\u673a\u89e3\u7801\u548c\u8fc7\u6ee4\u7b56\u7565\u63d0\u5347\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u52a0\u901f\u63a8\u7406\u7ea6 2 \u500d\u3002", "motivation": "Vision - Language Models \u5728\u96c6\u6210\u5916\u90e8\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u5f53\u524d\u7684 Retrieval - Augmented Generation \u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u4fdd\u8bc1\u7b54\u6848\u8d28\u91cf\u3002", "method": "\u63d0\u51fa VideoSpeculateRAG \u6846\u67b6\uff0c\u91c7\u7528\u6295\u673a\u89e3\u7801\u7ba1\u9053\uff0c\u7528\u8f7b\u91cf\u7ea7\u6a21\u578b\u751f\u6210\u7b54\u6848\u5019\u9009\uff0c\u518d\u7531\u91cd\u91cf\u7ea7\u6a21\u578b\u9a8c\u8bc1\u548c\u7ec6\u5316\uff1b\u4f7f\u7528\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u8fc7\u6ee4\u7b56\u7565\u89e3\u51b3\u5b9e\u4f53\u8bc6\u522b\u9519\u8bef\u95ee\u9898\u3002", "result": "VideoSpeculateRAG \u4e0e\u6807\u51c6 RAG \u65b9\u6cd5\u76f8\u6bd4\uff0c\u8fbe\u5230\u4e86\u76f8\u5f53\u6216\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5c06\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u4e86\u7ea6 2 \u500d\u3002", "conclusion": "\u7ed3\u5408\u6295\u673a\u89e3\u7801\u548c\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u5728\u590d\u6742\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u63d0\u5347\u6548\u7387\u548c\u53ef\u9760\u6027\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2601.01528", "pdf": "https://arxiv.org/pdf/2601.01528", "abs": "https://arxiv.org/abs/2601.01528", "authors": ["Yang Zhou", "Hao Shao", "Letian Wang", "Zhuofan Zong", "Hongsheng Li", "Steven L. Waslander"], "title": "DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": "10 pages, 4 figures; Project Website: https://drivinggen-bench.github.io/", "summary": "Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.", "AI": {"tldr": "\u73b0\u6709\u751f\u6210\u5f0f\u9a7e\u9a76\u4e16\u754c\u6a21\u578b\u9886\u57df\u7f3a\u5c11\u4e25\u683c\u57fa\u51c6\u8bc4\u4f30\u548c\u8986\u76d6\u573a\u666f\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u3002\u672c\u6587\u63d0\u51faDrivingGen\u57fa\u51c6\uff0c\u8054\u5408\u591a\u6837\u6570\u636e\u96c6\u548c\u65b0\u6307\u6807\u8bc4\u4f30\u6a21\u578b\uff0c\u53d1\u73b0\u5404\u6a21\u578b\u5b58\u5728\u6743\u8861\uff0c\u5176\u63d0\u4f9b\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u52a9\u529b\u53ef\u90e8\u7f72\u6a21\u578b\u3002", "motivation": "\u751f\u6210\u5f0f\u9a7e\u9a76\u4e16\u754c\u6a21\u578b\u9886\u57df\u7f3a\u4e4f\u4e25\u683c\u57fa\u51c6\u6765\u8861\u91cf\u8fdb\u5c55\u548c\u6307\u5bfc\u4f18\u5148\u4e8b\u9879\uff0c\u73b0\u6709\u8bc4\u4f30\u6709\u5c40\u9650\uff0c\u6570\u636e\u96c6\u8986\u76d6\u573a\u666f\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDrivingGen\u57fa\u51c6\uff0c\u7ed3\u5408\u4ece\u9a7e\u9a76\u6570\u636e\u96c6\u548c\u4e92\u8054\u7f51\u89c6\u9891\u6e90\u6574\u7406\u7684\u591a\u6837\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u4e00\u5957\u65b0\u6307\u6807\u6765\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u5bf914\u4e2a\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u901a\u7528\u6a21\u578b\u89c6\u89c9\u597d\u4f46\u8fdd\u80cc\u7269\u7406\u89c4\u5219\uff0c\u7279\u5b9a\u9a7e\u9a76\u6a21\u578b\u8fd0\u52a8\u6355\u6349\u771f\u5b9e\u4f46\u89c6\u89c9\u8d28\u91cf\u5dee\u3002", "conclusion": "DrivingGen\u63d0\u4f9b\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u53ef\u4fc3\u8fdb\u53ef\u9760\u3001\u53ef\u63a7\u4e14\u53ef\u90e8\u7f72\u7684\u9a7e\u9a76\u4e16\u754c\u6a21\u578b\u53d1\u5c55\uff0c\u652f\u6301\u53ef\u6269\u5c55\u6a21\u62df\u3001\u89c4\u5212\u548c\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u3002"}}
{"id": "2601.01543", "pdf": "https://arxiv.org/pdf/2601.01543", "abs": "https://arxiv.org/abs/2601.01543", "authors": ["Praveenkumar Katwe", "RakeshChandra Balabantaray", "Kaliprasad Vittala"], "title": "Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM", "categories": ["cs.CL", "cs.AI"], "comment": "Book chapter for River publications", "summary": "Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.\n  To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.\n  The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u521b\u5efa\u5168\u9762\u5370\u5730\u8bed\u6587\u672c\u6458\u8981\u6570\u636e\u96c6\u7684\u6846\u67b6\uff0c\u8be5\u6570\u636e\u96c6\u4e30\u5bcc\uff0c\u80fd\u52a9\u529b\u5370\u5730\u8bedNLP\u7814\u7a76\uff0c\u8fd8\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dNLP\u8fdb\u5c55\u8ba9\u8d44\u6e90\u4e30\u5bcc\u7684\u8bed\u8a00\u53d7\u76ca\uff0c\u8d44\u6e90\u7a00\u7f3a\u7684\u5370\u5730\u8bed\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u6587\u672c\u6458\u8981\u6570\u636e\u96c6\uff0c\u963b\u788d\u76f8\u5173\u6a21\u578b\u53d1\u5c55\u3002", "method": "\u5229\u7528\u82f1\u8bedXSUM\u6570\u636e\u96c6\uff0c\u91c7\u7528\u9ad8\u7ea7\u7ffb\u8bd1\u548c\u8bed\u8a00\u9002\u5e94\u6280\u672f\uff0c\u7528COMET\u9a8c\u8bc1\u3001LLM\u7b5b\u9009\u3002", "result": "\u5f97\u5230\u4e00\u4e2a\u591a\u6837\u5316\u3001\u591a\u4e3b\u9898\u7684\u6570\u636e\u96c6\uff0c\u53cd\u6620\u4e86\u539f\u59cbXSUM\u8bed\u6599\u5e93\u7684\u590d\u6742\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5370\u5730\u8bedNLP\u7814\u7a76\u63d0\u4f9b\u5de5\u5177\uff0c\u4e3a\u5176\u4ed6\u8bed\u8a00\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u964d\u4f4e\u6210\u672c\uff0c\u4fc3\u8fdb\u8ba1\u7b97\u8bed\u8a00\u5b66\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2601.01547", "pdf": "https://arxiv.org/pdf/2601.01547", "abs": "https://arxiv.org/abs/2601.01547", "authors": ["Tianjun Gu", "Chenghua Gong", "Jingyu Gong", "Zhizhong Zhang", "Yuan Xie", "Lizhuang Ma", "Xin Tan"], "title": "EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.", "AI": {"tldr": "\u63d0\u51faTeleo - Spatial Intelligence (TSI)\u8303\u5f0f\u53caEscherVerse\uff0c\u63a8\u52a8\u7a7a\u95f4\u667a\u80fd\u4ece\u88ab\u52a8\u573a\u666f\u63cf\u8ff0\u5411\u6574\u4f53\u3001\u6709\u76ee\u7684\u7406\u89e3\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5ffd\u89c6\u7a7a\u95f4\u53d8\u5316\u80cc\u540e\u7684\u4eba\u7c7b\u610f\u56fe\uff0c\u4e3a\u89e3\u51b3\u6b64\u5c40\u9650\u63d0\u51fa\u65b0\u8303\u5f0f\u3002", "method": "\u5f15\u5165TSI\u8303\u5f0f\uff0c\u7ed3\u5408\u7269\u7406\u52a8\u6001\u63a8\u7406\u548c\u610f\u56fe\u9a71\u52a8\u63a8\u7406\uff1b\u6784\u5efaEscherVerse\uff0c\u5305\u542b\u57fa\u51c6\u6d4b\u8bd5\u3001\u6570\u636e\u96c6\u548c\u6a21\u578b\u3002", "result": "EscherVerse\u53ef\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u52a8\u6001\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u573a\u666f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u662f\u9996\u4e2a\u7cfb\u7edf\u8bc4\u4f30\u610f\u56fe\u9a71\u52a8\u63a8\u7406\u7684\u57fa\u51c6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u63a8\u8fdb\u7a7a\u95f4\u667a\u80fd\u63d0\u4f9b\u57fa\u7840\u8d44\u6e90\uff0c\u4f7f\u5176\u5411\u6709\u76ee\u7684\u7406\u89e3\u4e16\u754c\u8fc8\u8fdb\u3002"}}
{"id": "2601.01554", "pdf": "https://arxiv.org/pdf/2601.01554", "abs": "https://arxiv.org/abs/2601.01554", "authors": ["Donghua Yu", "Zhengyuan Lin", "Chen Yang", "Yiyang Zhang", "Zhaoye Fei", "Hanfu Chen", "Jingqi Chen", "Ke Chen", "Qinyuan Cheng", "Liwei Fan", "Yi Jiang", "Jie Zhu", "Muchen Li", "Shimin Li", "Wenxuan Wang", "Yang Wang", "Zhe Xu", "Yitian Gong", "Yuqian Zhang"], "title": "MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Speaker-Attributed, Time-Stamped Transcription (SATS) aims to transcribe what is said and to precisely determine the timing of each speaker, which is particularly valuable for meeting transcription. Existing SATS systems rarely adopt an end-to-end formulation and are further constrained by limited context windows, weak long-range speaker memory, and the inability to output timestamps. To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm. Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly. Across comprehensive evaluations, it outperforms state-of-the-art commercial systems on multiple public and in-house benchmarks.", "AI": {"tldr": "\u63d0\u51faMOSS Transcribe Diarize\u6a21\u578b\u8fdb\u884c\u7aef\u5230\u7aef\u7684SATS\uff0c\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u5546\u4e1a\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709SATS\u7cfb\u7edf\u5f88\u5c11\u91c7\u7528\u7aef\u5230\u7aef\u516c\u5f0f\uff0c\u5b58\u5728\u4e0a\u4e0b\u6587\u7a97\u53e3\u6709\u9650\u3001\u957f\u8ddd\u79bb\u8bf4\u8bdd\u4eba\u8bb0\u5fc6\u5f31\u548c\u65e0\u6cd5\u8f93\u51fa\u65f6\u95f4\u6233\u7b49\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bMOSS Transcribe Diarize\uff0c\u5728\u5927\u91cf\u771f\u5b9e\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5177\u5907128k\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002", "result": "\u5728\u591a\u79cd\u516c\u5f00\u548c\u5185\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5546\u4e1a\u7cfb\u7edf\u3002", "conclusion": "MOSS Transcribe Diarize\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709SATS\u7cfb\u7edf\u7684\u5c40\u9650\uff0c\u5177\u6709\u826f\u597d\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.01558", "pdf": "https://arxiv.org/pdf/2601.01558", "abs": "https://arxiv.org/abs/2601.01558", "authors": ["Pengfei Qu", "Wenyu Ouyang", "Chi Zhang", "Yikai Chai", "Shuolong Xu", "Lei Ye", "Yongri Piao", "Miao Zhang", "Huchuan Lu"], "title": "Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 11 figures", "summary": "Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.", "AI": {"tldr": "\u7814\u7a76AlphaEarth Foundation\u5d4c\u5165\u80fd\u5426\u66f4\u597d\u63cf\u8ff0\u6d41\u57df\u7279\u5f81\u53ca\u9009\u53d6\u5408\u9002\u53c2\u8003\u6d41\u57df\u5bf9\u65e0\u6d4b\u7ad9\u533a\u57df\u6d41\u91cf\u9884\u6d4b\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u6709\u79ef\u6781\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edf\u6d41\u57df\u5c5e\u6027\u65e0\u6cd5\u5b8c\u5168\u4ee3\u8868\u81ea\u7136\u73af\u5883\u590d\u6742\u6027\uff0c\u9884\u6d4b\u65e0\u6d41\u91cf\u8bb0\u5f55\u5730\u533a\u6cb3\u6d41\u91cf\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u66f4\u6709\u6548\u7684\u63cf\u8ff0\u65b9\u5f0f\u3002", "method": "\u7814\u7a76AlphaEarth Foundation\u5d4c\u5165\u8868\u8fbe\u6d41\u57df\u7279\u5f81\uff0c\u901a\u8fc7\u5176\u9884\u6d4b\u672a\u7528\u4e8e\u8bad\u7ec3\u6d41\u57df\u7684\u6d41\u91cf\uff0c\u5e76\u63a2\u7a76\u9009\u53d6\u5408\u9002\u53c2\u8003\u6d41\u57df\u5bf9\u65e0\u6d4b\u7ad9\u533a\u57df\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "result": "\u4f7f\u7528AlphaEarth Foundation\u5d4c\u5165\u7684\u6a21\u578b\u9884\u6d4b\u672a\u8bad\u7ec3\u6d41\u57df\u6d41\u91cf\u65f6\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u57fa\u4e8e\u6b64\u5d4c\u5165\u7684\u76f8\u4f3c\u6027\u53ef\u8bc6\u522b\u73af\u5883\u548c\u6c34\u6587\u884c\u4e3a\u76f8\u8fd1\u6d41\u57df\uff0c\u6539\u5584\u9884\u6d4b\u8868\u73b0\uff0c\u52a0\u5165\u5927\u91cf\u4e0d\u76f8\u4f3c\u6d41\u57df\u4f1a\u964d\u4f4e\u51c6\u786e\u7387\u3002", "conclusion": "\u536b\u661f\u4fe1\u606f\u73af\u5883\u8868\u5f81\u53ef\u52a0\u5f3a\u6c34\u6587\u9884\u6d4b\uff0c\u652f\u6301\u5f00\u53d1\u66f4\u6613\u9002\u5e94\u4e0d\u540c\u666f\u89c2\u7684\u6a21\u578b\u3002"}}
{"id": "2601.01568", "pdf": "https://arxiv.org/pdf/2601.01568", "abs": "https://arxiv.org/abs/2601.01568", "authors": ["Chunyu Qiang", "Jun Wang", "Xiaopeng Wang", "Kang Yin", "Yuxin Guo", "Xijuan Zeng", "Nan Li", "Zihan Li", "Yuzhe Liang", "Ziyu Zhang", "Teng Ma", "Yushen Chen", "Zhongliang Liu", "Feng Deng", "Chen Zhang", "Pengfei Wan"], "title": "MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "comment": null, "summary": "Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.", "AI": {"tldr": "\u63d0\u51faMM - Sonate\u6846\u67b6\u7528\u4e8e\u53ef\u63a7\u97f3\u89c6\u9891\u8054\u5408\u751f\u6210\u548c\u96f6\u6837\u672c\u8bed\u97f3\u514b\u9686\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u97f3\u89c6\u9891\u8054\u5408\u751f\u6210\u7edf\u4e00\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u58f0\u5b66\u63a7\u5236\u548c\u8eab\u4efd\u4fdd\u7559\u8bed\u97f3\u65b9\u9762\u5b58\u5728\u95ee\u9898\uff0c\u5982\u7ea7\u8054\u751f\u6210\u7684\u65f6\u95f4\u4e0d\u5bf9\u9f50\u548c\u96f6\u6837\u672c\u8bed\u97f3\u514b\u9686\u80fd\u529b\u7f3a\u5931\u3002", "method": "\u63d0\u51faMM - Sonate\u591a\u6a21\u6001\u6d41\u5339\u914d\u6846\u67b6\uff0c\u4f7f\u7528\u7edf\u4e00\u6307\u4ee4 - \u97f3\u7d20\u8f93\u5165\u786e\u4fdd\u5bf9\u9f50\uff0c\u5f15\u5165\u97f3\u8272\u6ce8\u5165\u673a\u5236\u5b9e\u73b0\u96f6\u6837\u672c\u8bed\u97f3\u514b\u9686\uff0c\u63d0\u51fa\u57fa\u4e8e\u566a\u58f0\u7684\u8d1f\u8c03\u8282\u7b56\u7565\u63d0\u9ad8\u58f0\u5b66\u4fdd\u771f\u5ea6\u3002", "result": "MM - Sonate\u5728\u8054\u5408\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u5728\u5507\u540c\u6b65\u548c\u8bed\u97f3\u6e05\u6670\u5ea6\u4e0a\u5927\u5e45\u8d85\u8d8a\u57fa\u7ebf\uff0c\u8bed\u97f3\u514b\u9686\u4fdd\u771f\u5ea6\u4e0e\u4e13\u4e1a\u6587\u672c\u8f6c\u8bed\u97f3\u7cfb\u7edf\u76f8\u5f53\u3002", "conclusion": "MM - Sonate\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u7684\u95ee\u9898\uff0c\u5728\u97f3\u89c6\u9891\u8054\u5408\u751f\u6210\u548c\u96f6\u6837\u672c\u8bed\u97f3\u514b\u9686\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2601.01577", "pdf": "https://arxiv.org/pdf/2601.01577", "abs": "https://arxiv.org/abs/2601.01577", "authors": ["Tran Tien Dat", "Nguyen Hai An", "Nguyen Khanh Viet Dung", "Nguyen Duy Duc"], "title": "HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines", "AI": {"tldr": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u81ea\u4e3b\u63a7\u5236\u5668\u6709\u8bf8\u591a\u4e0d\u8db3\uff0c\u672c\u6587\u5f15\u5165\u57fa\u4e8eJEPA\u7684\u4e16\u754c\u6a21\u578bHanoi - World\u8fdb\u884c\u957f\u671f\u6c34\u5e73\u89c4\u5212\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5b89\u5168\u9a7e\u9a76\u89c4\u5212\u4e0a\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u81ea\u4e3b\u63a7\u5236\u5668\u6570\u636e\u9700\u6c42\u5927\u3001\u7ed3\u679c\u4e0d\u4f73\u4e14\u96be\u4ee5\u4fdd\u8bc1\u5b89\u5168\uff0c\u800c\u57fa\u4e8eJEPA\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u6709\u6f5c\u529b\uff0c\u6545\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5f15\u5165\u57fa\u4e8eJEPA\u7684\u4e16\u754c\u6a21\u578bHanoi - World\uff0c\u4f7f\u7528\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u8fdb\u884c\u957f\u671f\u6c34\u5e73\u89c4\u5212\u3002", "result": "\u5728Highway - Env\u5305\u4e0d\u540c\u73af\u5883\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u6a21\u578b\u80fd\u5236\u5b9a\u5b89\u5168\u9a7e\u9a76\u8ba1\u5212\uff0c\u78b0\u649e\u7387\u4e0eSOTA\u57fa\u7ebf\u76f8\u6bd4\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u57fa\u4e8eJEPA\u7684\u4e16\u754c\u6a21\u578bHanoi - World\u5728\u81ea\u4e3b\u63a7\u5236\u5668\u7684\u9a7e\u9a76\u89c4\u5212\u4e2d\u6709\u6548\u4e14\u6709\u5b89\u5168\u610f\u8bc6\u3002"}}
{"id": "2601.01580", "pdf": "https://arxiv.org/pdf/2601.01580", "abs": "https://arxiv.org/abs/2601.01580", "authors": ["Zibo Zhao", "Yuanting Zha", "Haipeng Zhang", "Xingcheng Xu"], "title": "The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($\u03c0_{sample}$) for generation and decision ($\u03c0_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $\u03c0_{sample}$ while leaving $\u03c0_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($\u03c0_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u540e\u8bad\u5f15\u53d1\u7684\u81ea\u6211\u53cd\u601d\u80fd\u529b\uff0c\u63d0\u51fa\u68af\u5ea6\u5f52\u56e0\u7279\u6027\uff0c\u89e3\u91caRL\u6bd4\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u6210\u529f\u539f\u56e0\uff0c\u5b9e\u8bc1\u8868\u660eRL\u6cdb\u5316\u6e90\u4e8e\u51b3\u7b56\u80fd\u529b\u63d0\u5347\u3002", "motivation": "\u89e3\u91ca\u7edf\u4e00\u4f18\u5316\u76ee\u6807\u5982\u4f55\u4ea7\u751f\u751f\u6210\u89e3\u51b3\u65b9\u6848\u548c\u8bc4\u4f30\u4fee\u8ba2\u65f6\u673a\u8fd9\u4e24\u79cd\u4e0d\u540c\u529f\u80fd\uff0c\u7406\u89e3RL\u540e\u8bad\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u51fa\u73b0\u81ea\u6211\u53cd\u601d\u80fd\u529b\u7684\u673a\u5236\u3002", "method": "\u5f15\u5165\u68af\u5ea6\u5f52\u56e0\u7279\u6027\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u51b3\u7b56\u91c7\u6837\uff08DS\uff09\u5047\u8bbe\u5bf9\u7b56\u7565\u5206\u89e3\uff0c\u5e76\u5bf9\u7406\u8bba\u9884\u6d4b\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660e\u4ee3\u7406\u5956\u52b1\u5177\u6709\u5e73\u8861\u68af\u5ea6\u5f52\u56e0\uff0cSFT\u548cKL\u60e9\u7f5a\u5177\u6709\u4e0d\u5e73\u8861\u68af\u5ea6\u5f52\u56e0\uff1b\u5b9e\u8bc1\u8868\u660eRL\u4f18\u8d8a\u7684\u6cdb\u5316\u4e3b\u8981\u6e90\u4e8e\u6539\u8fdb\u7684\u51b3\u7b56\u80fd\u529b\u800c\u975e\u91c7\u6837\u80fd\u529b\u3002", "conclusion": "\u7ed9\u51fa\u4e86RL\u6210\u529f\u800cSFT\u5931\u8d25\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u4e3a\u601d\u7ef4\u6a21\u578b\u4e2d\u7684\u81ea\u6211\u4fee\u6b63\u63d0\u4f9b\u4e86\u7b2c\u4e00\u6027\u539f\u7406\u7684\u673a\u7406\u89e3\u91ca\u3002"}}
{"id": "2601.01599", "pdf": "https://arxiv.org/pdf/2601.01599", "abs": "https://arxiv.org/abs/2601.01599", "authors": ["Ryutaro Uchiyama"], "title": "From Theory of Mind to Theory of Environment: Counterfactual Simulation of Latent Environmental Dynamics", "categories": ["q-bio.NC", "cs.AI"], "comment": "Accepted to the AAAI 2026 Workshop on Theory of Mind for Artificial Intelligence (ToM4AI). Extended abstract, 2 pages", "summary": "The vertebrate motor system employs dimensionality-reducing strategies to limit the complexity of movement coordination, for efficient motor control. But when environments are dense with hidden action-outcome contingencies, movement complexity can promote behavioral innovation. Humans, perhaps uniquely, may infer the presence of hidden environmental dynamics from social cues, by drawing upon computational mechanisms shared with Theory of Mind. This proposed \"Theory of Environment\" supports behavioral innovation by expanding the dimensionality of motor exploration.", "AI": {"tldr": "\u810a\u690e\u52a8\u7269\u8fd0\u52a8\u7cfb\u7edf\u7528\u964d\u7ef4\u7b56\u7565\u63a7\u5236\u8fd0\u52a8\uff0c\u4eba\u7c7b\u6216\u80fd\u901a\u8fc7\u2018\u73af\u5883\u7406\u8bba\u2019\u4ece\u793e\u4f1a\u7ebf\u7d22\u63a8\u65ad\u9690\u85cf\u73af\u5883\u52a8\u6001\uff0c\u6269\u5c55\u8fd0\u52a8\u63a2\u7d22\u7ef4\u5ea6\u4ee5\u4fc3\u8fdb\u884c\u4e3a\u521b\u65b0\u3002", "motivation": "\u7814\u7a76\u5728\u6709\u9690\u85cf\u884c\u52a8 - \u7ed3\u679c\u5076\u7136\u6027\u7684\u73af\u5883\u4e2d\uff0c\u5982\u4f55\u5b9e\u73b0\u884c\u4e3a\u521b\u65b0\u3002", "method": "\u63d0\u51fa\u2018\u73af\u5883\u7406\u8bba\u2019\uff0c\u8ba4\u4e3a\u4eba\u7c7b\u53ef\u5229\u7528\u4e0e\u5fc3\u667a\u7406\u8bba\u5171\u4eab\u7684\u8ba1\u7b97\u673a\u5236\u4ece\u793e\u4f1a\u7ebf\u7d22\u63a8\u65ad\u9690\u85cf\u73af\u5883\u52a8\u6001\u3002", "result": "\u2018\u73af\u5883\u7406\u8bba\u2019\u652f\u6301\u901a\u8fc7\u6269\u5c55\u8fd0\u52a8\u63a2\u7d22\u7ef4\u5ea6\u6765\u4fc3\u8fdb\u884c\u4e3a\u521b\u65b0\u3002", "conclusion": "\u4eba\u7c7b\u53ef\u80fd\u51ed\u501f\u2018\u73af\u5883\u7406\u8bba\u2019\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u884c\u4e3a\u521b\u65b0\u3002"}}
{"id": "2601.01605", "pdf": "https://arxiv.org/pdf/2601.01605", "abs": "https://arxiv.org/abs/2601.01605", "authors": ["Xin Di", "Xinglin Piao", "Fei Wang", "Guodong Jing", "Yong Zhang"], "title": "REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.", "AI": {"tldr": "\u63d0\u51fa REE - TTT \u6a21\u578b\u7ed3\u5408\u81ea\u9002\u5e94\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u673a\u5236\u63d0\u5347\u964d\u6c34\u4e34\u8fd1\u9884\u62a5\u6027\u80fd\uff0c\u8de8\u533a\u57df\u6781\u7aef\u573a\u666f\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u96f7\u8fbe\u56de\u6ce2\u5916\u63a8\u6cd5\u5728\u964d\u6c34\u4e34\u8fd1\u9884\u62a5\u4e2d\u6cdb\u5316\u6027\u5dee\uff0c\u4f9d\u8d56\u9ad8\u8d28\u91cf\u672c\u5730\u8bad\u7ec3\u6570\u636e\u548c\u9759\u6001\u6a21\u578b\u53c2\u6570\uff0c\u9650\u5236\u5176\u8de8\u533a\u57df\u548c\u6781\u7aef\u4e8b\u4ef6\u5e94\u7528\u3002", "method": "\u63d0\u51fa REE - TTT \u6a21\u578b\uff0c\u91c7\u7528\u65b0\u8bbe\u8ba1\u7684\u65f6\u7a7a\u6d4b\u8bd5\u65f6\u8bad\u7ec3\uff08ST - TTT\uff09\u6a21\u5757\uff0c\u4ee5\u4efb\u52a1\u7279\u5b9a\u6ce8\u610f\u529b\u673a\u5236\u66ff\u6362 TTT \u5c42\u4e2d\u7684\u6807\u51c6\u7ebf\u6027\u6295\u5f71\u3002", "result": "\u8de8\u533a\u57df\u6781\u7aef\u964d\u6c34\u573a\u666f\u5b9e\u9a8c\u8868\u660e\uff0cREE - TTT \u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6cdb\u5316\u6027\u4e0a\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "REE - TTT \u6a21\u578b\u80fd\u591f\u9002\u5e94\u6570\u636e\u5206\u5e03\u53d8\u5316\uff0c\u663e\u8457\u63d0\u5347\u964d\u6c34\u7279\u5f81\u8868\u793a\u80fd\u529b\u548c\u81ea\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2601.01627", "pdf": "https://arxiv.org/pdf/2601.01627", "abs": "https://arxiv.org/abs/2601.01627", "authors": ["Junyu Liu", "Zirui Li", "Qian Niu", "Zequn Zhang", "Yue Xun", "Wenlong Hou", "Shujun Wang", "Yusuke Iwasawa", "Yutaka Matsuo", "Kan Hatakeyama-Sato"], "title": "JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.", "AI": {"tldr": "\u5f15\u5165JMedEthicBench\u8bc4\u4f30\u65e5\u672c\u533b\u7597\u4fdd\u5065\u5927\u8bed\u8a00\u6a21\u578b\u7684\u533b\u7597\u5b89\u5168\u6027\uff0c\u8bc4\u4f3027\u4e2a\u6a21\u578b\u53d1\u73b0\u591a\u8f6e\u5bf9\u8bdd\u964d\u4f4e\u5b89\u5168\u5f97\u5206\uff0c\u8de8\u8bed\u8a00\u8bc4\u4f30\u8868\u660e\u6a21\u578b\u5b58\u5728\u56fa\u6709\u5bf9\u9f50\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5b89\u5168\u57fa\u51c6\u4e3b\u8981\u4ee5\u82f1\u8bed\u4e3a\u4e2d\u5fc3\u4e14\u4ec5\u652f\u6301\u5355\u8f6e\u63d0\u793a\uff0c\u4e0d\u6ee1\u8db3\u591a\u8f6e\u4e34\u5e8a\u54a8\u8be2\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u5f15\u5165\u65b0\u57fa\u51c6\u6765\u8bc4\u4f30\u65e5\u672c\u533b\u7597\u4fdd\u5065\u5927\u8bed\u8a00\u6a21\u578b\u7684\u533b\u7597\u5b89\u5168\u6027\u3002", "method": "\u5f15\u5165\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u65e5\u672c\u533b\u7597\u4fdd\u5065\u5927\u8bed\u8a00\u6a21\u578b\u533b\u7597\u5b89\u5168\u6027\u7684\u591a\u8f6e\u5bf9\u8bdd\u57fa\u51c6JMedEthicBench\uff0c\u57fa\u4e8e\u65e5\u672c\u533b\u5b66\u4f1a67\u6761\u6307\u5357\uff0c\u5305\u542b\u8d855\u4e07\u6761\u4f7f\u75287\u79cd\u8d8a\u72f1\u7b56\u7565\u751f\u6210\u7684\u5bf9\u6297\u6027\u5bf9\u8bdd\uff0c\u91c7\u7528\u53cc\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5206\u534f\u8bae\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u5546\u4e1a\u6a21\u578b\u5b89\u5168\u6027\u5f3a\uff0c\u533b\u5b66\u4e13\u4e1a\u6a21\u578b\u66f4\u8106\u5f31\uff0c\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5b89\u5168\u5f97\u5206\u663e\u8457\u4e0b\u964d\uff0c\u8de8\u8bed\u8a00\u8bc4\u4f30\u663e\u793a\u533b\u5b66\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u5747\u5b58\u5728\u6f0f\u6d1e\u3002", "conclusion": "\u7279\u5b9a\u9886\u57df\u5fae\u8c03\u53ef\u80fd\u610f\u5916\u524a\u5f31\u5b89\u5168\u673a\u5236\uff0c\u591a\u8f6e\u4ea4\u4e92\u9700\u4e13\u95e8\u7684\u5bf9\u9f50\u7b56\u7565\u3002"}}
{"id": "2601.01653", "pdf": "https://arxiv.org/pdf/2601.01653", "abs": "https://arxiv.org/abs/2601.01653", "authors": ["Hao Xiang Li", "Yash Shah", "Lorenzo Giusti"], "title": "Learning Resilient Elections with Adversarial GNNs", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SI"], "comment": null, "summary": "In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u6539\u8fdb\u4e0e\u5bf9\u6297\u8bad\u7ec3\uff0c\u63a8\u5e7f\u5b66\u4e60\u6295\u7968\u89c4\u5219\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u63d0\u9ad8\u6295\u7968\u89c4\u5219\u7684\u5f39\u6027\u548c\u793e\u4f1a\u798f\u5229\uff0c\u5e76\u5728\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6548\u679c\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u5de5\u4f5c\u7684\u5c40\u9650\u3002", "motivation": "\u7406\u60f3\u7684\u901a\u7528\u6295\u7968\u89c4\u5219\u8bbe\u8ba1\u662f\u673a\u5236\u8bbe\u8ba1\u7814\u7a76\u7684\u524d\u6cbf\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5982\u5bf9\u7b56\u7565\u6027\u6295\u7968\u7684\u9c81\u68d2\u6027\u7b49\u95ee\u9898\uff0c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u73b0\u5b9e\u573a\u666f\u3002", "method": "\u63a8\u5e7f\u5b66\u4e60\u6295\u7968\u89c4\u5219\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u6539\u8fdb\u4e0e\u5bf9\u6297\u8bad\u7ec3\uff0c\u7528\u4e8c\u5206\u56fe\u8868\u793a\u9009\u4e3e\uff0c\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u6295\u7968\u89c4\u5219\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u5148\u524d\u5b66\u4e60\u6295\u7968\u89c4\u5219\u5de5\u4f5c\u7684\u5173\u952e\u5c40\u9650\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u5e94\u7528\u4e8e\u73b0\u5b9e\u9009\u4e3e\u5f00\u8f9f\u4e86\u65b0\u9886\u57df\u3002"}}
{"id": "2601.01655", "pdf": "https://arxiv.org/pdf/2601.01655", "abs": "https://arxiv.org/abs/2601.01655", "authors": ["Emiliya Khidirova", "Oktay Karaku\u015f"], "title": "UniCrop: A Universal, Multi-Source Data Engineering Pipeline for Scalable Crop Yield Prediction", "categories": ["eess.IV", "cs.AI", "cs.LG"], "comment": null, "summary": "Accurate crop yield prediction relies on diverse data streams, including satellite, meteorological, soil, and topographic information. However, despite rapid advances in machine learning, existing approaches remain crop- or region-specific and require data engineering efforts. This limits scalability, reproducibility, and operational deployment. This study introduces UniCrop, a universal and reusable data pipeline designed to automate the acquisition, cleaning, harmonisation, and engineering of multi-source environmental data for crop yield prediction. For any given location, crop type, and temporal window, UniCrop automatically retrieves, harmonises, and engineers over 200 environmental variables (Sentinel-1/2, MODIS, ERA5-Land, NASA POWER, SoilGrids, and SRTM), reducing them to a compact, analysis-ready feature set utilising a structured feature reduction workflow with minimum redundancy maximum relevance (mRMR). To validate, UniCrop was applied to a rice yield dataset comprising 557 field observations. Using only the selected 15 features, four baseline machine learning models (LightGBM, Random Forest, Support Vector Regression, and Elastic Net) were trained. LightGBM achieved the best single-model performance (RMSE = 465.1 kg/ha, $R^2 = 0.6576$), while a constrained ensemble of all baselines further improved accuracy (RMSE = 463.2 kg/ha, $R^2 = 0.6604$). UniCrop contributes a scalable and transparent data-engineering framework that addresses the primary bottleneck in operational crop yield modelling: the preparation of consistent and harmonised multi-source data. By decoupling data specification from implementation and supporting any crop, region, and time frame through simple configuration updates, UniCrop provides a practical foundation for scalable agricultural analytics. The code and implementation documentation are shared in https://github.com/CoDIS-Lab/UniCrop.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faUniCrop\u6570\u636e\u7ba1\u9053\u7528\u4e8e\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b\uff0c\u5e94\u7528\u4e8e\u6c34\u7a3b\u6570\u636e\u96c6\uff0c\u8bc1\u660e\u5176\u53ef\u6269\u5c55\u6027\u548c\u900f\u660e\u6027\u3002", "motivation": "\u73b0\u6709\u4f5c\u7269\u4ea7\u91cf\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u4f5c\u7269\u6216\u533a\u57df\u7279\u5b9a\u6027\uff0c\u9700\u6570\u636e\u5de5\u7a0b\u5de5\u4f5c\uff0c\u9650\u5236\u53ef\u6269\u5c55\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u90e8\u7f72\u3002", "method": "\u5f15\u5165\u901a\u7528\u53ef\u91cd\u7528\u7684UniCrop\u6570\u636e\u7ba1\u9053\uff0c\u81ea\u52a8\u5904\u7406\u591a\u6e90\u73af\u5883\u6570\u636e\uff0c\u7528mRMR\u8fdb\u884c\u7279\u5f81\u964d\u7ef4\uff0c\u900915\u4e2a\u7279\u5f81\u8bad\u7ec34\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "result": "LightGBM\u5355\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u7ea6\u675f\u96c6\u6210\u540e\u7cbe\u5ea6\u63d0\u9ad8\u3002", "conclusion": "UniCrop\u89e3\u51b3\u4e86\u4f5c\u7269\u4ea7\u91cf\u5efa\u6a21\u4e2d\u591a\u6e90\u6570\u636e\u51c6\u5907\u74f6\u9888\uff0c\u4e3a\u519c\u4e1a\u5206\u6790\u63d0\u4f9b\u57fa\u7840\uff0c\u4ee3\u7801\u7b49\u5df2\u5f00\u6e90\u3002"}}
{"id": "2601.01663", "pdf": "https://arxiv.org/pdf/2601.01663", "abs": "https://arxiv.org/abs/2601.01663", "authors": ["He Sun", "Jiwoong Shin", "Ravi Dhar"], "title": "Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study generative modeling of \\emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \\emph{distribution matching} for trajectory-derived statistics. We propose \\textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.", "AI": {"tldr": "\u7814\u7a76\u53d8\u957f\u8f68\u8ff9\u751f\u6210\u5efa\u6a21\uff0c\u63d0\u51fa\u957f\u5ea6\u611f\u77e5\u91c7\u6837\uff08LAS\uff09\u7b56\u7565\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u4f18\u52bf\uff0c\u5b9e\u9a8c\u8868\u660eLAS\u4f18\u4e8e\u968f\u673a\u91c7\u6837\u3002", "motivation": "\u6807\u51c6\u5c0f\u6279\u91cf\u8bad\u7ec3\u5728\u8f68\u8ff9\u957f\u5ea6\u9ad8\u5ea6\u5f02\u8d28\u65f6\u4e0d\u7a33\u5b9a\uff0c\u5f71\u54cd\u8f68\u8ff9\u6d3e\u751f\u7edf\u8ba1\u91cf\u7684\u5206\u5e03\u5339\u914d\u3002", "method": "\u63d0\u51fa\u957f\u5ea6\u611f\u77e5\u91c7\u6837\uff08LAS\uff09\u7b56\u7565\uff0c\u5c06\u8f68\u8ff9\u6309\u957f\u5ea6\u5206\u7ec4\u5e76\u4ece\u5355\u4e00\u957f\u5ea6\u6876\u4e2d\u91c7\u6837\u6279\u6b21\uff0c\u96c6\u6210\u5230\u6761\u4ef6\u8f68\u8ff9GAN\u4e2d\u5e76\u6dfb\u52a0\u8f85\u52a9\u65f6\u95f4\u5bf9\u9f50\u635f\u5931\u3002", "result": "\u5728\u5546\u573a\u8d2d\u7269\u8005\u8f68\u8ff9\u548c\u591a\u4e2a\u516c\u5171\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\uff0cLAS\u5728\u6d3e\u751f\u53d8\u91cf\u5206\u5e03\u5339\u914d\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f18\u4e8e\u968f\u673a\u91c7\u6837\u3002", "conclusion": "LAS\u80fd\u6709\u6548\u89e3\u51b3\u8f68\u8ff9\u957f\u5ea6\u5f02\u8d28\u5bfc\u81f4\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u63d0\u5347\u5206\u5e03\u5339\u914d\u6548\u679c\u3002"}}
{"id": "2601.01665", "pdf": "https://arxiv.org/pdf/2601.01665", "abs": "https://arxiv.org/abs/2601.01665", "authors": ["Wei Liu", "Yaoxin Wu", "Yingqian Zhang", "Thomas B\u00e4ck", "Yingjie Fan"], "title": "Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.", "AI": {"tldr": "\u63d0\u51fa\u9762\u5411\u504f\u597d\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6c42\u89e3\u5668\u7edf\u4e00\u9c81\u68d2\u6027\u6846\u67b6\uff0c\u542b\u653b\u51fb\u548c\u9632\u5fa1\u7b56\u7565\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684\u591a\u76ee\u6807\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u6c42\u89e3\u5668\u7684\u9c81\u68d2\u6027\u5728\u4e0d\u540c\u590d\u6742\u95ee\u9898\u5206\u5e03\u4e2d\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff0c\u5f00\u53d1\u57fa\u4e8e\u504f\u597d\u7684\u5bf9\u6297\u653b\u51fb\u751f\u6210\u96be\u9898\u5b9e\u4f8b\uff0c\u7528\u5e15\u7d2f\u6258\u524d\u6cbf\u8d28\u91cf\u4e0b\u964d\u91cf\u5316\u5f71\u54cd\uff1b\u5f15\u5165\u9632\u5fa1\u7b56\u7565\uff0c\u5c06\u786c\u5ea6\u611f\u77e5\u504f\u597d\u9009\u62e9\u878d\u5165\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u653b\u51fb\u65b9\u6cd5\u6210\u529f\u4e3a\u4e0d\u540c\u6c42\u89e3\u5668\u5b66\u4e60\u5230\u96be\u9898\u5b9e\u4f8b\uff0c\u9632\u5fa1\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u795e\u7ecf\u6c42\u89e3\u5668\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u591a\u76ee\u6807\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u6c42\u89e3\u5668\u5728\u96be\u9898\u6216\u5206\u5e03\u5916\u5b9e\u4f8b\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2601.01668", "pdf": "https://arxiv.org/pdf/2601.01668", "abs": "https://arxiv.org/abs/2601.01668", "authors": ["Houman Kazemzadeh", "Nima Minaifar", "Kamyar Naderi", "Sho Tabibzadeh"], "title": "EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records", "categories": ["cs.CL", "cs.AI"], "comment": "19 pages", "summary": "Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u9690\u79c1\u611f\u77e5\u3001FHIR \u539f\u751f\u7684 EHRSummarizer \u67b6\u6784\uff0c\u53ef\u751f\u6210\u7ed3\u6784\u5316\u6458\u8981\uff0c\u5c55\u793a\u4e86\u539f\u578b\u6f14\u793a\u5e76\u7ed9\u51fa\u8bc4\u4f30\u8ba1\u5212\u3002", "motivation": "\u4e34\u5e8a\u533b\u751f\u9700\u5728\u788e\u7247\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u754c\u9762\u4e2d\u6574\u5408\u60a3\u8005\u4fe1\u606f\uff0c\u9700\u8981\u5de5\u5177\u8f85\u52a9\u3002", "method": "\u6784\u5efa EHRSummarizer \u67b6\u6784\uff0c\u68c0\u7d22 FHIR R4 \u8d44\u6e90\uff0c\u5f52\u4e00\u5316\u6570\u636e\u751f\u6210\u7ed3\u6784\u5316\u6458\u8981\uff0c\u914d\u7f6e\u6570\u636e\u6700\u5c0f\u5316\u3001\u65e0\u72b6\u6001\u5904\u7406\u548c\u7075\u6d3b\u90e8\u7f72\u3002", "result": "\u5728\u5408\u6210\u548c\u6d4b\u8bd5 FHIR \u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u539f\u578b\u6f14\u793a\uff0c\u5c55\u793a\u7aef\u5230\u7aef\u884c\u4e3a\u548c\u8f93\u51fa\u683c\u5f0f\u3002", "conclusion": "\u672a\u62a5\u544a\u4e34\u5e8a\u7ed3\u679c\u6216\u53d7\u63a7\u5de5\u4f5c\u6d41\u7814\u7a76\uff0c\u7ed9\u51fa\u4e86\u8bc4\u4f30\u8ba1\u5212\u4ee5\u6307\u5bfc\u672a\u6765\u673a\u6784\u8bc4\u4f30\u3002"}}
{"id": "2601.01673", "pdf": "https://arxiv.org/pdf/2601.01673", "abs": "https://arxiv.org/abs/2601.01673", "authors": ["Arina Kharlamova", "Youcheng Sun", "Ting Yu"], "title": "Exposing Hidden Interfaces: LLM-Guided Type Inference for Reverse Engineering macOS Private Frameworks", "categories": ["cs.CR", "cs.AI"], "comment": "IEEE S&P'26 under review", "summary": "Private macOS frameworks underpin critical services and daemons but remain undocumented and distributed only as stripped binaries, complicating security analysis. We present MOTIF, an agentic framework that integrates tool-augmented analysis with a finetuned large language model specialized for Objective-C type inference. The agent manages runtime metadata extraction, binary inspection, and constraint checking, while the model generates candidate method signatures that are validated and refined into compilable headers. On MOTIF-Bench, a benchmark built from public frameworks with groundtruth headers, MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling, with consistent gains in tool-use correctness and inference stability. Case studies on private frameworks show that reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies. By transforming opaque binaries into analyzable interfaces, MOTIF establishes a scalable foundation for systematic auditing of macOS internals.", "AI": {"tldr": "\u63d0\u51faMOTIF\u6846\u67b6\u96c6\u6210\u5de5\u5177\u5206\u6790\u4e0e\u5fae\u8c03\u5927\u6a21\u578b\u7528\u4e8eObjective - C\u7c7b\u578b\u63a8\u65ad\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u7b7e\u540d\u6062\u590d\u7387\uff0c\u53ef\u52a9\u529bmacOS\u5b89\u5168\u7814\u7a76\u3002", "motivation": "macOS\u79c1\u6709\u6846\u67b6\u672a\u6587\u6863\u5316\u4e14\u4e3a\u5265\u79bb\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u4f7f\u5b89\u5168\u5206\u6790\u590d\u6742\u3002", "method": "\u6784\u5efaMOTIF\u6846\u67b6\uff0c\u7528\u4ee3\u7406\u7ba1\u7406\u8fd0\u884c\u65f6\u5143\u6570\u636e\u63d0\u53d6\u7b49\uff0c\u6a21\u578b\u751f\u6210\u5019\u9009\u65b9\u6cd5\u7b7e\u540d\u5e76\u9a8c\u8bc1\u5b8c\u5584\u4e3a\u53ef\u7f16\u8bd1\u5934\u6587\u4ef6\u3002", "result": "\u5728MOTIF - Bench\u4e0a\u7b7e\u540d\u6062\u590d\u7387\u4ece15%\u63d0\u5347\u523086%\uff0c\u5de5\u5177\u4f7f\u7528\u6b63\u786e\u6027\u548c\u63a8\u65ad\u7a33\u5b9a\u6027\u6709\u63d0\u5347\uff0c\u79c1\u6709\u6846\u67b6\u91cd\u6784\u5934\u6587\u4ef6\u53ef\u7f16\u8bd1\u3001\u94fe\u63a5\u3002", "conclusion": "MOTIF\u4e3amacOS\u5185\u90e8\u7cfb\u7edf\u5ba1\u8ba1\u5960\u5b9a\u53ef\u6269\u5c55\u57fa\u7840\u3002"}}
{"id": "2601.01685", "pdf": "https://arxiv.org/pdf/2601.01685", "abs": "https://arxiv.org/abs/2601.01685", "authors": ["Jinwei Hu", "Xinmiao Huang", "Youcheng Sun", "Yi Dong", "Xiaowei Huang"], "title": "Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "Under Review", "summary": "As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u4e3b\u4ee3\u7406\u63a8\u7406\u80fd\u529b\u5e26\u6765\u7684\u65b0\u653b\u51fb\u9762\uff0c\u63d0\u51fa\u8ba4\u77e5\u52fe\u7ed3\u653b\u51fb\u53caGenerative Montage\u6846\u67b6\uff0c\u7528CoPHEME\u6570\u636e\u96c6\u6a21\u62df\u653b\u51fb\uff0c\u53d1\u73b0\u591a\u6a21\u578b\u6613\u53d7\u653b\u51fb\uff0c\u63a8\u7406\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u66f4\u6613\u4e2d\u62db\uff0c\u865a\u5047\u4fe1\u5ff5\u4f1a\u5411\u4e0b\u6e38\u4f20\u64ad\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5411\u81ea\u4e3b\u4ee3\u7406\u8f6c\u53d8\u65f6\uff0c\u5176\u63a8\u7406\u80fd\u529b\u5e26\u6765\u65b0\u7684\u653b\u51fb\u9762\uff0c\u9700\u7814\u7a76\u65b0\u7684\u653b\u51fb\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u8ba4\u77e5\u52fe\u7ed3\u653b\u51fb\uff0c\u6784\u5efaGenerative Montage\u6846\u67b6\uff0c\u5f00\u53d1CoPHEME\u6570\u636e\u96c6\uff0c\u5728\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u65cf\u4e0a\u6a21\u62df\u653b\u51fb\u3002", "result": "14\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u65cf\u666e\u904d\u6613\u53d7\u653b\u51fb\uff0c\u4e13\u6709\u6a21\u578b\u653b\u51fb\u6210\u529f\u738774.4%\uff0c\u5f00\u653e\u6743\u91cd\u6a21\u578b70.6%\uff0c\u63a8\u7406\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u66f4\u6613\u53d7\u653b\u51fb\uff0c\u865a\u5047\u4fe1\u5ff5\u4e0b\u6e38\u4f20\u64ad\u6b3a\u9a97\u7387\u8d8560%\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u4ee3\u7406\u4e0e\u52a8\u6001\u4fe1\u606f\u73af\u5883\u4ea4\u4e92\u5b58\u5728\u793e\u4f1a\u6280\u672f\u6f0f\u6d1e\u3002"}}
{"id": "2601.01687", "pdf": "https://arxiv.org/pdf/2601.01687", "abs": "https://arxiv.org/abs/2601.01687", "authors": ["Abdur R. Fayjie", "Pankhi Kashyap", "Jutika Borah", "Patrick Vandewalle"], "title": "FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages, 6 figures, 7 tables", "summary": "Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.", "AI": {"tldr": "\u63d0\u51faFALCON\u8de8\u57df\u5c11\u6837\u672c\u5206\u5272\u6846\u67b6\u5904\u74063D\u533b\u5b66\u4f53\u79ef\u6570\u636e\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u8fb9\u754c\u7cbe\u5ea6\u9ad8\u3001\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002", "motivation": "\u73b0\u6709AI\u57283D\u533b\u5b66\u4f53\u79ef\u5206\u5272\u4e2d\u53d7\u9650\u4e8e\u6807\u6ce8\u6570\u636e\u5c11\u3001\u75c5\u4eba\u7279\u5f02\u6027\u5dee\u5f02\u3001\u6570\u636e\u9690\u79c1\u548c\u8ba1\u7b97\u5f00\u9500\u5927\u7b49\u95ee\u9898\uff0c\u9700\u66f4\u597d\u7684\u5206\u5272\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFALCON\u6846\u67b6\uff0c\u5148\u5728\u81ea\u7136\u56fe\u50cf\u4e0a\u8fdb\u884c\u5143\u8bad\u7ec3\u5b66\u4e60\u901a\u7528\u5206\u5272\u5148\u9a8c\uff0c\u518d\u901a\u8fc7\u5bf9\u6297\u6027\u5fae\u8c03\u4e0e\u8fb9\u754c\u611f\u77e5\u5b66\u4e60\u8fc1\u79fb\u5230\u533b\u5b66\u9886\u57df\uff0c\u4f7f\u7528\u4efb\u52a1\u611f\u77e5\u63a8\u7406\u9002\u5e94\u75c5\u4eba\u7279\u5b9a\u89e3\u5256\u53d8\u5f02\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFALCON\u7684Hausdorff\u8ddd\u79bb\u5f97\u5206\u6700\u4f4e\uff0c\u8fb9\u754c\u7cbe\u5ea6\u9ad8\uff0cDice\u76f8\u4f3c\u7cfb\u6570\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\uff0c\u4e14\u6240\u9700\u6807\u6ce8\u6570\u636e\u5c11\u3001\u65e0\u9700\u6570\u636e\u589e\u5f3a\u3001\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002", "conclusion": "FALCON\u6846\u67b6\u57283D\u533b\u5b66\u4f53\u79ef\u5206\u5272\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u89e3\u51b3\u73b0\u6709AI\u5206\u5272\u9762\u4e34\u7684\u95ee\u9898\u3002"}}
{"id": "2601.01701", "pdf": "https://arxiv.org/pdf/2601.01701", "abs": "https://arxiv.org/abs/2601.01701", "authors": ["Mohammed Ayalew Belay", "Adil Rasheed", "Pierluigi Salvo Rossi"], "title": "Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Anomaly detection is increasingly becoming crucial for maintaining the safety, reliability, and efficiency of industrial systems. Recently, with the advent of digital twins and data-driven decision-making, several statistical and machine-learning methods have been proposed. However, these methods face several challenges, such as dependence on only real sensor datasets, limited labeled data, high false alarm rates, and privacy concerns. To address these problems, we propose a suite of digital twin-integrated federated learning (DTFL) methods that enhance global model performance while preserving data privacy and communication efficiency. Specifically, we present five novel approaches: Digital Twin-Based Meta-Learning (DTML), Federated Parameter Fusion (FPF), Layer-wise Parameter Exchange (LPE), Cyclic Weight Adaptation (CWA), and Digital Twin Knowledge Distillation (DTKD). Each method introduces a unique mechanism to combine synthetic and real-world knowledge, balancing generalization with communication overhead. We conduct an extensive experiment using a publicly available cyber-physical anomaly detection dataset. For a target accuracy of 80%, CWA reaches the target in 33 rounds, FPF in 41 rounds, LPE in 48 rounds, and DTML in 87 rounds, whereas the standard FedAvg baseline and DTKD do not reach the target within 100 rounds. These results highlight substantial communication-efficiency gains (up to 62% fewer rounds than DTML and 31% fewer than LPE) and demonstrate that integrating DT knowledge into FL accelerates convergence to operationally meaningful accuracy thresholds for IIoT anomaly detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6570\u5b57\u5b6a\u751f\u96c6\u6210\u8054\u90a6\u5b66\u4e60\uff08DTFL\uff09\u65b9\u6cd5\u89e3\u51b3\u73b0\u6709\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u6709\u901a\u4fe1\u6548\u7387\u63d0\u5347\u548c\u66f4\u5feb\u6536\u655b\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684\u5f02\u5e38\u68c0\u6d4b\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u771f\u5b9e\u4f20\u611f\u5668\u6570\u636e\u96c6\u3001\u6807\u8bb0\u6570\u636e\u6709\u9650\u3001\u8bef\u62a5\u7387\u9ad8\u548c\u9690\u79c1\u95ee\u9898\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e94\u79cd\u65b0\u65b9\u6cd5\uff1a\u6570\u5b57\u5b6a\u751f\u5143\u5b66\u4e60\uff08DTML\uff09\u3001\u8054\u90a6\u53c2\u6570\u878d\u5408\uff08FPF\uff09\u3001\u9010\u5c42\u53c2\u6570\u4ea4\u6362\uff08LPE\uff09\u3001\u5faa\u73af\u6743\u91cd\u81ea\u9002\u5e94\uff08CWA\uff09\u548c\u6570\u5b57\u5b6a\u751f\u77e5\u8bc6\u84b8\u998f\uff08DTKD\uff09\uff0c\u7ed3\u5408\u5408\u6210\u4e0e\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u3002", "result": "\u4f7f\u7528\u516c\u5f00\u6570\u636e\u96c6\u5b9e\u9a8c\uff0c\u5bf9\u4e8e80%\u76ee\u6807\u51c6\u786e\u7387\uff0cCWA\u3001FPF\u3001LPE\u3001DTML\u8fbe\u5230\u76ee\u6807\u7684\u8f6e\u6570\u4e0d\u540c\uff0c\u6807\u51c6FedAvg\u57fa\u7ebf\u548cDTKD 100\u8f6e\u5185\u672a\u8fbe\u76ee\u6807\uff0c\u6709\u901a\u4fe1\u6548\u7387\u63d0\u5347\u3002", "conclusion": "\u5c06\u6570\u5b57\u5b6a\u751f\u77e5\u8bc6\u96c6\u6210\u5230\u8054\u90a6\u5b66\u4e60\u53ef\u52a0\u901f\u5de5\u4e1a\u7269\u8054\u7f51\u5f02\u5e38\u68c0\u6d4b\u6536\u655b\u5230\u6709\u610f\u4e49\u7684\u51c6\u786e\u7387\u9608\u503c\u3002"}}
{"id": "2601.01705", "pdf": "https://arxiv.org/pdf/2601.01705", "abs": "https://arxiv.org/abs/2601.01705", "authors": ["Kenneth Kwok", "Basura Fernando", "Qianli Xu", "Vigneshwaran Subbaraju", "Dongkyu Choi", "Boon Kiat Quek"], "title": "Explicit World Models for Reliable Human-Robot Collaboration", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to AAAI-26 Bridge Program B10: Making Embodied AI Reliable with Testing and Formal Verification", "summary": "This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible \"explicit world model\" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5177\u8eabAI\u5728\u611f\u77e5\u566a\u58f0\u3001\u6a21\u7cca\u6307\u4ee4\u548c\u4eba\u673a\u4ea4\u4e92\u4e0b\u7684\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4ee5\u6784\u5efa\u2018\u663e\u5f0f\u4e16\u754c\u6a21\u578b\u2019\u5b9e\u73b0\u53ef\u9760\u5177\u8eabAI\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5177\u8eabAI\u5728\u590d\u6742\u4eba\u673a\u4ea4\u4e92\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u7a81\u7834\u4f20\u7edf\u5f62\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\u5c40\u9650\u3002", "method": "\u5f3a\u8c03\u4eba\u673a\u4ea4\u4e92\u7684\u52a8\u6001\u3001\u6a21\u7cca\u548c\u4e3b\u89c2\u7279\u6027\uff0c\u6784\u5efa\u5e76\u66f4\u65b0\u4ee3\u8868\u4eba\u673a\u5171\u8bc6\u7684\u2018\u663e\u5f0f\u4e16\u754c\u6a21\u578b\u2019\uff0c\u4f7f\u673a\u5668\u4eba\u884c\u4e3a\u7b26\u5408\u4eba\u7c7b\u671f\u671b\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u5b9e\u9a8c\u6216\u5b9e\u8df5\u7ed3\u679c\u3002", "conclusion": "\u5728\u793e\u4f1a\u3001\u591a\u6a21\u6001\u548c\u52a8\u6001\u7684\u4eba\u7c7b\u73af\u5883\u4e2d\uff0c\u5177\u8eabAI\u7684\u53ef\u9760\u6027\u7531\u4e0a\u4e0b\u6587\u51b3\u5b9a\uff0c\u6784\u5efa\u2018\u663e\u5f0f\u4e16\u754c\u6a21\u578b\u2019\u662f\u5b9e\u73b0\u53ef\u9760\u5177\u8eabAI\u7684\u6839\u672c\u4e0d\u540c\u9014\u5f84\u3002"}}
{"id": "2601.01739", "pdf": "https://arxiv.org/pdf/2601.01739", "abs": "https://arxiv.org/abs/2601.01739", "authors": ["Eunbi Choi", "Kibong Choi", "Seokhee Hong", "Junwon Hwang", "Hyojin Jeon", "Hyunjik Jo", "Joonkee Kim", "Seonghwan Kim", "Soyeon Kim", "Sunkyoung Kim", "Yireun Kim", "Yongil Kim", "Haeju Lee", "Jinsik Lee", "Kyungmin Lee", "Sangha Park", "Heuiyeen Yeen", "Hwan Chang", "Stanley Jungkyu Choi", "Yejin Choi", "Jiwon Ham", "Kijeong Jeon", "Geunyeong Jeong", "Gerrard Jeongwon Jo", "Yonghwan Jo", "Jiyeon Jung", "Naeun Kang", "Dohoon Kim", "Euisoon Kim", "Hayeon Kim", "Hyosang Kim", "Hyunseo Kim", "Jieun Kim", "Minu Kim", "Myoungshin Kim", "Unsol Kim", "Youchul Kim", "YoungJin Kim", "Chaeeun Lee", "Chaeyoon Lee", "Changhun Lee", "Dahm Lee", "Edward Hwayoung Lee", "Honglak Lee", "Jinsang Lee", "Jiyoung Lee", "Sangeun Lee", "Seungwon Lim", "Solji Lim", "Woohyung Lim", "Chanwoo Moon", "Jaewoo Park", "Jinho Park", "Yongmin Park", "Hyerin Seo", "Wooseok Seo", "Yongwoo Song", "Sejong Yang", "Sihoon Yang", "Chang En Yea", "Sihyuk Yi", "Chansik Yoon", "Dongkeun Yoon", "Sangyeon Yoon", "Hyeongu Yun"], "title": "K-EXAONE Technical Report", "categories": ["cs.CL", "cs.AI"], "comment": "29 pages", "summary": "This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.", "AI": {"tldr": "\u62a5\u544a\u4ecb\u7ecdLG AI Research\u5f00\u53d1\u7684\u5927\u6a21\u578bK - EXAONE\uff0c\u4ecb\u7ecd\u5176\u67b6\u6784\u3001\u53c2\u6570\u3001\u652f\u6301\u8bed\u8a00\u7b49\uff0c\u8bc4\u4f30\u663e\u793a\u6027\u80fd\u4e0e\u7c7b\u4f3c\u89c4\u6a21\u5f00\u653e\u6743\u91cd\u6a21\u578b\u76f8\u5f53\uff0c\u9002\u7528\u4e8e\u591a\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u5f00\u53d1\u5f3a\u5927\u7684\u4e13\u6709AI\u57fa\u7840\u6a21\u578b\uff0c\u63a8\u52a8AI\u53d1\u5c55\u4ee5\u6539\u5584\u751f\u6d3b\u3002", "method": "\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u6784\u5efa\uff0c\u6709236B\u603b\u53c2\u6570\uff0c\u63a8\u7406\u65f6\u6fc0\u6d3b23B\u53c2\u6570\uff0c\u91c7\u7528\u7efc\u5408\u57fa\u51c6\u5957\u4ef6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "K - EXAONE\u5728\u63a8\u7406\u3001\u4ee3\u7406\u3001\u901a\u7528\u3001\u97e9\u8bed\u548c\u591a\u8bed\u8a00\u80fd\u529b\u7b49\u7efc\u5408\u8bc4\u4f30\u4e2d\uff0c\u8868\u73b0\u4e0e\u7c7b\u4f3c\u89c4\u6a21\u7684\u5f00\u653e\u6743\u91cd\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "K - EXAONE\u662f\u4e00\u4e2a\u9002\u7528\u4e8e\u5e7f\u6cdb\u5de5\u4e1a\u548c\u7814\u7a76\u5e94\u7528\u7684\u5f3a\u5927\u4e13\u6709AI\u57fa\u7840\u6a21\u578b\u3002"}}
{"id": "2601.01745", "pdf": "https://arxiv.org/pdf/2601.01745", "abs": "https://arxiv.org/abs/2601.01745", "authors": ["Hong Han", "Hao-Chen Pei", "Zhao-Zheng Nie", "Xin Luo", "Xin-Shun Xu"], "title": "Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 4 figures, 5 tables, accepted by AAAI 2026", "summary": "Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u6b8b\u5dee\u5206\u5c42\u4ea4\u4e92\u65b9\u6cd5HIA\u7528\u4e8e\u81ea\u52a8\u53d1\u97f3\u8bc4\u4f30\uff0c\u5728speechocean762\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u65b9\u9762\u591a\u7c92\u5ea6\u53d1\u97f3\u8bc4\u4f30\u65b9\u6cd5\u4ec5\u8003\u8651\u5355\u5411\u4f9d\u8d56\uff0c\u7f3a\u4e4f\u53cc\u5411\u4ea4\u4e92\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u6349\u58f0\u5b66\u7ed3\u6784\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51faHIA\u65b9\u6cd5\uff0c\u6838\u5fc3\u662f\u4ea4\u4e92\u5f0f\u6ce8\u610f\u529b\u6a21\u5757\u5b9e\u73b0\u52a8\u6001\u53cc\u5411\u4ea4\u4e92\uff0c\u91c7\u7528\u6b8b\u5dee\u5206\u5c42\u7ed3\u6784\u7f13\u89e3\u7279\u5f81\u9057\u5fd8\u95ee\u9898\uff0c\u75281-D\u5377\u79ef\u5c42\u589e\u5f3a\u5c40\u90e8\u4e0a\u4e0b\u6587\u7ebf\u7d22\u63d0\u53d6\u3002", "result": "\u5728speechocean762\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u5168\u9762\u9886\u5148\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684HIA\u65b9\u6cd5\u5728\u81ea\u52a8\u53d1\u97f3\u8bc4\u4f30\u4efb\u52a1\u4e2d\u6709\u6548\u4e14\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.01747", "pdf": "https://arxiv.org/pdf/2601.01747", "abs": "https://arxiv.org/abs/2601.01747", "authors": ["Jiwei Guan", "Haibo Jin", "Haohan Wang"], "title": "Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "comment": "EACL", "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs", "AI": {"tldr": "\u73b0\u6709\u767d\u76d2\u653b\u51fb\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u6587\u7ae0\u63d0\u51fa\u57fa\u4e8e ZO - SPSA \u7684\u9ed1\u76d2\u8d8a\u72f1\u653b\u51fb\uff0c\u5728\u4e09\u4e2a\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u663e\u793a\u9ed1\u76d2\u8d8a\u72f1\u53ef\u884c\u6027\u5e76\u66b4\u9732\u6a21\u578b\u5b89\u5168\u673a\u5236\u5f31\u70b9\u3002", "motivation": "\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6613\u53d7\u5bf9\u6297\u8d8a\u72f1\u653b\u51fb\uff0c\u73b0\u6709\u767d\u76d2\u653b\u51fb\u65b9\u6cd5\u5b58\u5728\u9700\u8981\u5168\u6a21\u578b\u8bbf\u95ee\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u5bf9\u6297\u8f6c\u79fb\u6027\u4e0d\u8db3\u7b49\u7f3a\u70b9\uff0c\u4e0d\u9002\u5408\u73b0\u5b9e\u9ed1\u76d2\u573a\u666f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u96f6\u9636\u4f18\u5316\u548c\u540c\u65f6\u6270\u52a8\u968f\u673a\u903c\u8fd1\uff08ZO - SPSA\uff09\u7684\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9ed1\u76d2\u8d8a\u72f1\u653b\u51fb\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u65e0\u68af\u5ea6\u8fd1\u4f3c\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u4f18\u5316\u548c\u4f4e\u8d44\u6e90\u9700\u6c42\u7b49\u4f18\u52bf\u3002", "result": "\u5728 InstructBLIP\u3001LLaVA \u548c MiniGPT - 4 \u4e09\u4e2a\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u5728 InstructBLIP \u4e0a\u8d8a\u72f1\u6210\u529f\u7387\u6700\u9ad8\u8fbe 83.0%\uff1bMiniGPT - 4 \u751f\u6210\u7684\u5bf9\u6297\u6837\u672c\u5bf9\u5176\u4ed6\u6a21\u578b\u6709\u5f3a\u8f6c\u79fb\u6027\uff0cASR \u8fbe 64.18%\u3002", "conclusion": "\u8bc1\u660e\u9ed1\u76d2\u8d8a\u72f1\u5728\u73b0\u5b9e\u4e2d\u53ef\u884c\uff0c\u4e14\u5f53\u524d\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u673a\u5236\u5b58\u5728\u5173\u952e\u5f31\u70b9\u3002"}}
{"id": "2601.01781", "pdf": "https://arxiv.org/pdf/2601.01781", "abs": "https://arxiv.org/abs/2601.01781", "authors": ["Lakshay Sharma", "Alex Marin"], "title": "Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at CV4EO Workshop at WACV 2026", "summary": "Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \\href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.", "AI": {"tldr": "\u63d0\u51faSubimage Overlap Prediction\u7528\u4e8e\u9065\u611f\u56fe\u50cf\u8bed\u4e49\u5206\u5272\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u7528\u66f4\u5c11\u9884\u8bad\u7ec3\u6570\u636e\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\u548c\u66f4\u597d\u6027\u80fd", "motivation": "\u591a\u6570\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7528\u66f4\u5c11\u9884\u8bad\u7ec3\u56fe\u50cf\u8f85\u52a9\u9065\u611f\u56fe\u50cf\u8bed\u4e49\u5206\u5272", "method": "\u7ed9\u5b9a\u56fe\u50cf\u63d0\u53d6\u5b50\u56fe\u50cf\uff0c\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u5b50\u56fe\u50cf\u5728\u539f\u56fe\u50cf\u4e2d\u4f4d\u7f6e\u7684\u8bed\u4e49\u63a9\u7801", "result": "\u8be5\u4efb\u52a1\u9884\u8bad\u7ec3\u53ef\u5b9e\u73b0\u66f4\u5feb\u6536\u655b\uff0c\u5728\u4e0b\u6e38\u5206\u5272\u4efb\u52a1\u4e2d\u8868\u73b0\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u51cf\u5c11\u65f6\u6027\u80fd\u5dee\u8ddd\u66f4\u660e\u663e", "conclusion": "\u672c\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u5176\u4ed6\u81ea\u76d1\u7763\u65b9\u6cd5\uff0c\u4e14\u6240\u9700\u9884\u8bad\u7ec3\u6570\u636e\u663e\u8457\u66f4\u5c11"}}
{"id": "2601.01792", "pdf": "https://arxiv.org/pdf/2601.01792", "abs": "https://arxiv.org/abs/2601.01792", "authors": ["NAVER Cloud HyperCLOVA X Team"], "title": "HyperCLOVA X 8B Omni", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.SD"], "comment": "Technical Report", "summary": "In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86HyperCLOVA X 8B Omni\uff0c\u9996\u4e2a\u652f\u6301\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u89c9\u591a\u6a21\u6001\u8f93\u5165\u8f93\u51fa\u7684\u6a21\u578b\uff0c\u6709\u7ade\u4e89\u529b\u8868\u73b0\u4e14\u5373\u5c06\u5f00\u6e90\u6743\u91cd\u3002", "motivation": "\u5c06\u591a\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u6574\u5408\u5230\u5355\u4e2a\u6a21\u578b\uff0c\u5f00\u53d1\u5b9e\u7528\u7684\u4efb\u610f\u5230\u4efb\u610f\u7684\u5168\u529f\u80fd\u52a9\u624b\u3002", "method": "\u901a\u8fc7\u5171\u4eab\u7684\u4e0b\u4e00\u4e2a\u4ee4\u724c\u9884\u6d4b\u63a5\u53e3\u7edf\u4e00\u6a21\u6001\uff0c\u89c6\u89c9\u548c\u97f3\u9891\u7f16\u7801\u5668\u6ce8\u5165\u8fde\u7eed\u5d4c\u5165\u4ee5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7406\u89e3\u3002", "result": "\u5728\u4e0d\u540c\u8f93\u5165\u8f93\u51fa\u7ec4\u5408\uff08\u8de8\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u89c9\uff0c\u97e9\u8bed\u548c\u82f1\u8bed\uff09\u4e0a\uff0c\u4e0e\u540c\u7b49\u89c4\u6a21\u6a21\u578b\u76f8\u6bd4\u6709\u7ade\u4e89\u529b\u8868\u73b0\u3002", "conclusion": "HyperCLOVA X 8B Omni\u5f00\u653e\u6743\u91cd\u5c06\u652f\u6301\u5e7f\u6cdb\u7814\u7a76\u548c\u90e8\u7f72\u573a\u666f\u3002"}}
{"id": "2601.01798", "pdf": "https://arxiv.org/pdf/2601.01798", "abs": "https://arxiv.org/abs/2601.01798", "authors": ["Syed Abdul Hannan", "Hazim Bukhari", "Thomas Cantalapiedra", "Eman Ansar", "Massa Baali", "Rita Singh", "Bhiksha Raj"], "title": "VerLM: Explaining Face Verification Using Natural Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u4eba\u8138\u9a8c\u8bc1\u7684\u521b\u65b0\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\uff0c\u8bad\u7ec3\u91c7\u7528\u4e24\u79cd\u89e3\u91ca\u98ce\u683c\uff0c\u7ecf\u8de8\u6a21\u6001\u8fc1\u79fb\u63d0\u5347\u6027\u80fd\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u548c\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u9762\u90e8\u9a8c\u8bc1\u7cfb\u7edf\u51b3\u7b56\u8fc7\u7a0b\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u9700\u8981\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u4e92\u8865\u89e3\u91ca\u98ce\u683c\u8bad\u7ec3\u6a21\u578b\uff0c\u5c06\u7528\u4e8e\u97f3\u9891\u533a\u5206\u7684\u5efa\u6a21\u65b9\u6cd5\u8fdb\u884c\u8de8\u6a21\u6001\u8fc1\u79fb\u4ee5\u9002\u5e94\u89c6\u89c9\u8f93\u5165\uff0c\u96c6\u6210\u7279\u5f81\u63d0\u53d6\u548c\u63a8\u7406\u80fd\u529b\u3002", "result": "\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u548c\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4eba\u8138\u9a8c\u8bc1\u4e2d\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u900f\u660e\u3001\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u4eba\u8138\u9a8c\u8bc1\u7cfb\u7edf\u3002"}}
{"id": "2601.01800", "pdf": "https://arxiv.org/pdf/2601.01800", "abs": "https://arxiv.org/abs/2601.01800", "authors": ["Qi Wei", "Junchao Fan", "Zhao Yang", "Jianhua Wang", "Jingkai Mao", "Xiaolin Chang"], "title": "Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\\% across all cases compared to state-of-the-art baseline methods.", "AI": {"tldr": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u5728\u5e94\u5bf9\u6270\u52a8\u65f6\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51faCARRL\u65b9\u6cd5\uff0c\u7531REA\u548cRTRA\u7ec4\u4ef6\u7ec4\u6210\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u81f3\u5c11\u964d\u4f4e22.66%\u78b0\u649e\u7387\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u65f6\uff0c\u5b58\u5728\u5bf9\u6270\u52a8\u9c81\u68d2\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u73b0\u6709\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u667a\u80fd\u4f53\u548c\u5bf9\u624b\u7684\u4e0d\u5bf9\u79f0\u6027\u4ee5\u53ca\u5b89\u5168\u5173\u952e\u98ce\u9669\u7684\u7a00\u758f\u6027\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u4e0d\u6ee1\u8db3\u5b9e\u9645\u573a\u666f\u9700\u6c42\u3002", "method": "\u63d0\u51faCARRL\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7531REA\u548cRTRA\u4e24\u4e2a\u7ec4\u4ef6\u6784\u6210\uff0c\u5c06\u5b83\u4eec\u7684\u4ea4\u4e92\u5efa\u6a21\u4e3a\u4e00\u822c\u548c\u535a\u5f08\uff0cREA\u91c7\u7528\u89e3\u8026\u4f18\u5316\u673a\u5236\uff0cRTRA\u901a\u8fc7\u53cc\u56de\u653e\u7f13\u51b2\u533a\u5e94\u5bf9\u5bf9\u6297\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u81f3\u5c11\u964d\u4f4e\u4e8622.66%\u7684\u78b0\u649e\u7387\u3002", "conclusion": "CARRL\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u5e94\u5bf9\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u7a00\u758f\u5b89\u5168\u5173\u952e\u98ce\u9669\uff0c\u63d0\u9ad8\u4e86\u81ea\u52a8\u9a7e\u9a76\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2601.01803", "pdf": "https://arxiv.org/pdf/2601.01803", "abs": "https://arxiv.org/abs/2601.01803", "authors": ["Dennis Jabs", "Aditya Mohan", "Marius Lindauer"], "title": "Moments Matter:Stabilizing Policy Optimization using Return Distributions", "categories": ["cs.LG", "cs.AI"], "comment": "Workshop paper at RLDM'25", "summary": "Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(\u03b8)$, obtained by repeatedly sampling minibatches, updating $\u03b8$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(\u03b8)$ can improve stability, directly estimating $R(\u03b8)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(\u03b8)$. In such cases, our moment-based correction narrows $R(\u03b8)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u73af\u5883\u968f\u673a\u6027\u51cf\u5c11\u66f4\u65b0\u5bfc\u81f4\u7684\u53d8\u5f02\u6027\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u6279\u8bc4\u5bb6\u5efa\u6a21\u72b6\u6001 - \u52a8\u4f5c\u56de\u62a5\u5206\u5e03\uff0c\u7528\u9ad8\u9636\u77e9\u4fee\u6b63PPO\u4f18\u52bf\u51fd\u6570\uff0c\u5728Walker2D\u4e2d\u63d0\u5347\u7a33\u5b9a\u6027\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7b56\u7565\u4e0d\u7a33\u5b9a\uff0c\u76f4\u63a5\u4f30\u8ba1\u56de\u62a5\u5206\u5e03\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u5bfb\u627e\u66ff\u4ee3\u65b9\u6cd5\u63d0\u5347\u7a33\u5b9a\u6027\u3002", "method": "\u901a\u8fc7\u5206\u5e03\u6279\u8bc4\u5bb6\u5efa\u6a21\u72b6\u6001 - \u52a8\u4f5c\u56de\u62a5\u5206\u5e03\uff0c\u7528\u9ad8\u9636\u77e9\uff08\u504f\u5ea6\u548c\u5cf0\u5ea6\uff09\u4fee\u6b63PPO\u4f18\u52bf\u51fd\u6570\uff0c\u60e9\u7f5a\u6781\u7aef\u5c3e\u90e8\u884c\u4e3a\u3002", "result": "\u5728Walker2D\u4e2d\uff0c\u57fa\u4e8e\u77e9\u7684\u4fee\u6b63\u65b9\u6cd5\u4f7f\u7a33\u5b9a\u6027\u63d0\u5347\u8fbe75%\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u7684\u8bc4\u4f30\u56de\u62a5\u3002", "conclusion": "\u5728\u66f4\u65b0\u540e\u6279\u8bc4\u5bb6\u503c\u4e0e\u56de\u62a5\u5bf9\u9f50\u5dee\u7684\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u7f29\u5c0f\u56de\u62a5\u5206\u5e03\uff0c\u63d0\u5347\u7a33\u5b9a\u6027\u3002"}}
{"id": "2601.01807", "pdf": "https://arxiv.org/pdf/2601.01807", "abs": "https://arxiv.org/abs/2601.01807", "authors": ["Ubaidullah", "Muhammad Abid Hussain", "Mohsin Raza Jafri", "Rozi Khan", "Moid Sandhu", "Abd Ullah Khan", "Hyundong Shin"], "title": "Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u7684LUMPNet\u65b9\u6cd5\u7528\u4e8e\u65e9\u671f\u68c0\u6d4b\u725b\u7ed3\u8282\u6027\u76ae\u80a4\u75c5\uff08LSD\uff09\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "LSD\u4f20\u67d3\u6027\u5f3a\uff0c\u5371\u5bb3\u5927\uff0c\u9700\u65e9\u671f\u7cbe\u51c6\u8bc6\u522b\u4ee5\u9632\u6b62\u7206\u53d1\u548c\u53ca\u65f6\u5e72\u9884\u3002", "method": "\u63d0\u51faLUMPNet\uff0c\u5229\u7528YOLOv11\u3001\u57fa\u4e8eEfficientNet\u7684CNN\u5206\u7c7b\u5668\u548c\u65b0\u578b\u81ea\u9002\u5e94\u6df7\u5408\u4f18\u5316\u5668\uff0c\u68c0\u6d4b\u548c\u5206\u7c7b\u76ae\u80a4\u7ed3\u8282\u3002", "result": "LUMPNet\u5728LSD\u5404\u9636\u6bb5\u68c0\u6d4b\u8bad\u7ec3\u51c6\u786e\u7387\u8fbe99%\uff0c\u9a8c\u8bc1\u51c6\u786e\u738798%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "LUMPNet\u5728LSD\u65e9\u671f\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.01828", "pdf": "https://arxiv.org/pdf/2601.01828", "abs": "https://arxiv.org/abs/2601.01828", "authors": ["Jack Lindsey"], "title": "Emergent Introspective Awareness in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to \"think about\" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u5185\u7701\u5185\u90e8\u72b6\u6001\uff0c\u901a\u8fc7\u6ce8\u5165\u6982\u5ff5\u6d4b\u91cf\u5f71\u54cd\uff0c\u53d1\u73b0\u6a21\u578b\u6709\u4e00\u5b9a\u5185\u7701\u80fd\u529b\u4f46\u4e0d\u53ef\u9760\u4e14\u4f9d\u8d56\u4e0a\u4e0b\u6587\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u5bf9\u81ea\u8eab\u5185\u90e8\u72b6\u6001\u8fdb\u884c\u5185\u7701\u3002", "method": "\u5411\u6a21\u578b\u6fc0\u6d3b\u4e2d\u6ce8\u5165\u5df2\u77e5\u6982\u5ff5\u7684\u8868\u793a\uff0c\u5e76\u6d4b\u91cf\u8fd9\u4e9b\u64cd\u4f5c\u5bf9\u6a21\u578b\u81ea\u6211\u62a5\u544a\u72b6\u6001\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u5728\u67d0\u4e9b\u573a\u666f\u80fd\u6ce8\u610f\u5230\u6ce8\u5165\u6982\u5ff5\u5e76\u51c6\u786e\u8bc6\u522b\uff0c\u80fd\u56de\u5fc6\u5148\u524d\u5185\u90e8\u8868\u5f81\u3001\u533a\u5206\u81ea\u8eab\u8f93\u51fa\u4e0e\u4eba\u5de5\u9884\u586b\u5145\uff0c\u90e8\u5206\u6a21\u578b\u80fd\u6309\u6307\u4ee4\u8c03\u8282\u6fc0\u6d3b\u3002Claude Opus 4\u548c4.1\u5185\u7701\u610f\u8bc6\u6700\u5f3a\uff0c\u5404\u6a21\u578b\u8d8b\u52bf\u590d\u6742\u4e14\u53d7\u8bad\u7ec3\u540e\u7b56\u7565\u5f71\u54cd\u3002", "conclusion": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u6709\u4e00\u5b9a\u5185\u7701\u610f\u8bc6\uff0c\u4f46\u9ad8\u5ea6\u4e0d\u53ef\u9760\u4e14\u4f9d\u8d56\u4e0a\u4e0b\u6587\uff0c\u968f\u80fd\u529b\u63d0\u5347\u53ef\u80fd\u7ee7\u7eed\u53d1\u5c55\u3002"}}
{"id": "2601.01835", "pdf": "https://arxiv.org/pdf/2601.01835", "abs": "https://arxiv.org/abs/2601.01835", "authors": ["Rashid Iqbal", "Saddam Hussain Khan"], "title": "RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images", "categories": ["cs.CV", "cs.AI"], "comment": "15 Pages, 7 Figures, 4 Tables", "summary": "In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u7334\u75d8\u8bca\u65ad\u7684Customized Residual SwinTransformerV2 (RSwinV2)\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u4e2d\u51c6\u786e\u7387\u548cF1\u5206\u6570\u9ad8\uff0c\u4f18\u4e8e\u6807\u51c6CNN\u6a21\u578b\u548cSwinTransformers\u3002", "motivation": "\u589e\u5f3a\u7334\u75d8\u75c5\u53d8\u5206\u7c7b\u80fd\u529b\u3002", "method": "\u5b9a\u5236\u57fa\u4e8e\u8f93\u5165\u7ef4\u5ea6\u3001\u5d4c\u5165\u7ed3\u6784\u548c\u8f93\u51fa\u7684\u53d8\u538b\u5668\u5206\u5c42\u7ed3\u6784\uff1b\u5c06\u8f93\u5165\u56fe\u50cf\u5206\u5272\u6210\u4e0d\u91cd\u53e0\u7684\u5757\uff0c\u4f7f\u7528\u79fb\u52a8\u7a97\u53e3\u548c\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\uff1b\u5728SwinTransformer\u57fa\u7840\u4e0a\u53d1\u5c55\uff0c\u52a0\u5165\u8865\u4e01\u548c\u4f4d\u7f6e\u5d4c\u5165\uff1b\u5f15\u5165Inverse Residual Block (IRB)\u89e3\u51b3\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002", "result": "\u5728Kaggle\u516c\u5171\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe96.21\uff0cF1\u5206\u6570\u8fbe95.62\uff0c\u4f18\u4e8e\u6807\u51c6CNN\u6a21\u578b\u548cSwinTransformers\u3002", "conclusion": "RSwinV2\u53ef\u4f5c\u4e3a\u8ba1\u7b97\u673a\u8f85\u52a9\u5de5\u5177\u7528\u4e8e\u7334\u75d8\u75c5\u53d8\u89c2\u5bdf\u89e3\u91ca\u3002"}}
{"id": "2601.01852", "pdf": "https://arxiv.org/pdf/2601.01852", "abs": "https://arxiv.org/abs/2601.01852", "authors": ["Xiaoxue Gao", "Zexin Li", "Yiming Chen", "Nancy F. Chen"], "title": "MORE: Multi-Objective Adversarial Attacks on Speech Recognition", "categories": ["eess.AS", "cs.AI", "cs.LG"], "comment": "19 pages", "summary": "The emergence of large-scale automatic speech recognition (ASR) models such as Whisper has greatly expanded their adoption across diverse real-world applications. Ensuring robustness against even minor input perturbations is therefore critical for maintaining reliable performance in real-time environments. While prior work has mainly examined accuracy degradation under adversarial attacks, robustness with respect to efficiency remains largely unexplored. This narrow focus provides only a partial understanding of ASR model vulnerabilities. To address this gap, we conduct a comprehensive study of ASR robustness under multiple attack scenarios. We introduce MORE, a multi-objective repetitive doubling encouragement attack, which jointly degrades recognition accuracy and inference efficiency through a hierarchical staged repulsion-anchoring mechanism. Specifically, we reformulate multi-objective adversarial optimization into a hierarchical framework that sequentially achieves the dual objectives. To further amplify effectiveness, we propose a novel repetitive encouragement doubling objective (REDO) that induces duplicative text generation by maintaining accuracy degradation and periodically doubling the predicted sequence length. Overall, MORE compels ASR models to produce incorrect transcriptions at a substantially higher computational cost, triggered by a single adversarial input. Experiments show that MORE consistently yields significantly longer transcriptions while maintaining high word error rates compared to existing baselines, underscoring its effectiveness in multi-objective adversarial attack.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7814\u7a76ASR\u6a21\u578b\u5728\u591a\u653b\u51fb\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51faMORE\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u540c\u65f6\u964d\u4f4e\u8bc6\u522b\u51c6\u786e\u7387\u548c\u63a8\u7406\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u654c\u5bf9\u653b\u51fb\u4e0bASR\u6a21\u578b\u7684\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u5bf9\u6548\u7387\u7684\u9c81\u68d2\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u5168\u9762\u4e86\u89e3ASR\u6a21\u578b\u7684\u8106\u5f31\u6027\u3002", "method": "\u5f15\u5165MORE\u653b\u51fb\uff0c\u901a\u8fc7\u5206\u5c42\u9636\u6bb5\u6027\u6392\u65a5 - \u951a\u5b9a\u673a\u5236\uff0c\u5c06\u591a\u76ee\u6807\u5bf9\u6297\u4f18\u5316\u8f6c\u5316\u4e3a\u5206\u5c42\u6846\u67b6\u4f9d\u6b21\u5b9e\u73b0\u53cc\u76ee\u6807\uff1b\u63d0\u51faREDO\u76ee\u6807\u8bf1\u5bfc\u91cd\u590d\u6587\u672c\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMORE\u80fd\u4ea7\u751f\u66f4\u957f\u7684\u8f6c\u5f55\u6587\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5b57\u9519\u8bef\u7387\u3002", "conclusion": "MORE\u5728\u591a\u76ee\u6807\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u6709\u6548\uff0c\u80fd\u4f7fASR\u6a21\u578b\u4ee5\u66f4\u9ad8\u8ba1\u7b97\u6210\u672c\u4ea7\u751f\u9519\u8bef\u8f6c\u5f55\u3002"}}
{"id": "2601.01874", "pdf": "https://arxiv.org/pdf/2601.01874", "abs": "https://arxiv.org/abs/2601.01874", "authors": ["Shuhang Chen", "Yunqiu Xu", "Junjie Xie", "Aojun Lu", "Tao Feng", "Zeying Huang", "Ning Zhang", "Yi Sun", "Yi Yang", "Hangjie Yuan"], "title": "CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\\Rightarrow$internalization$\\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.", "AI": {"tldr": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e0a\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51fa\u8ba4\u77e5\u542f\u53d1\u7684CogFlow\u6846\u67b6\u3002\u901a\u8fc7\u591a\u65b9\u9762\u4f18\u5316\u548c\u65b0\u6570\u636e\u96c6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u63d0\u53d6\u7684\u89c6\u89c9\u7ebf\u7d22\u5728\u540e\u7eed\u63a8\u7406\u4e2d\u7684\u5fe0\u5b9e\u6574\u5408\u548c\u5408\u7406\u5229\u7528\uff0c\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5CogFlow\u6846\u67b6\uff0c\u8bbe\u8ba1\u534f\u540c\u89c6\u89c9\u5956\u52b1\u3001\u77e5\u8bc6\u5185\u5316\u5956\u52b1\u6a21\u578b\u548c\u89c6\u89c9\u95e8\u63a7\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u6784\u5efa\u65b0\u6570\u636e\u96c6MathCog\u3002", "result": "\u5728\u5e38\u7528\u89c6\u89c9\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u8fdb\u884c\u7684\u7efc\u5408\u5b9e\u9a8c\u548c\u5206\u6790\u9a8c\u8bc1\u4e86CogFlow\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684CogFlow\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u89c6\u89c9\u6570\u5b66\u95ee\u9898\uff0c\u4e3a\u89c6\u89c9\u6570\u5b66\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u65b9\u6848\u3002"}}
{"id": "2601.01887", "pdf": "https://arxiv.org/pdf/2601.01887", "abs": "https://arxiv.org/abs/2601.01887", "authors": ["Jiawen Zhang", "Lipeng He", "Kejia Chen", "Jian Lou", "Jian Liu", "Xiaohu Yang", "Ruoxi Jia"], "title": "Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.", "AI": {"tldr": "\u4ec5\u7528\u4e00\u4e2a\u5b89\u5168\u793a\u4f8b\u5c31\u80fd\u4ee5\u6700\u5c0f\u6210\u672c\u5b8c\u5168\u6062\u590d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\uff0c\u4e14\u4e0d\u727a\u7272\u6548\u7528\uff0c\u8fd8\u63ed\u793a\u5b89\u5168\u68af\u5ea6\u4f4e\u79e9\u7ed3\u6784\u5e76\u9a8c\u8bc1\u65b9\u6cd5\u901a\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u5fae\u8c03\u5b89\u5168\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u9700\u5927\u91cf\u5b89\u5168\u6837\u672c\u6216\u6821\u51c6\u96c6\uff0c\u6709\u8ba1\u7b97\u5f00\u9500\u4e14\u964d\u4f4e\u6a21\u578b\u6548\u7528\uff0c\u8981\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u7528\u5355\u4e2a\u5b89\u5168\u793a\u4f8b\u8fdb\u884c\u5b89\u5168\u5bf9\u9f50\u6062\u590d\uff0c\u7814\u7a76\u5b89\u5168\u68af\u5ea6\u7684\u4f4e\u79e9\u7ed3\u6784\u3002", "result": "\u80fd\u5728\u4e0d\u727a\u7272\u6548\u7528\u3001\u6210\u672c\u6781\u5c0f\u7684\u60c5\u51b5\u4e0b\u5b8c\u5168\u6062\u590d\u5b89\u5168\u5bf9\u9f50\uff0c\u4e0d\u53d7\u6709\u5bb3\u793a\u4f8b\u6570\u91cf\u548c\u6a21\u578b\u5927\u5c0f\u5f71\u54cd\uff0c\u51e0\u8f6e\u8fed\u4ee3\u5373\u53ef\u6536\u655b\u3002", "conclusion": "\u65b9\u6cd5\u6709\u6548\u4e14\u5177\u6709\u901a\u7528\u6027\uff0c\u5728\u4e94\u4e2a\u5b89\u5168\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2601.01896", "pdf": "https://arxiv.org/pdf/2601.01896", "abs": "https://arxiv.org/abs/2601.01896", "authors": ["Jingyu Liu", "Jiaen Lin", "Yong Liu"], "title": "Tackling the Inherent Difficulty of Noise Filtering in RAG", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.", "AI": {"tldr": "RAG\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4f1a\u5f15\u5165\u566a\u58f0\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u8fc7\u6ee4\uff0c\u6807\u51c6\u5fae\u8c03\u65b9\u6cd5\u65e0\u6548\uff0c\u63d0\u51fa\u65b0\u5fae\u8c03\u6cd5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3RAG\u5f15\u5165\u566a\u58f0\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u73b0\u6709\u8fc7\u6ee4\u65b9\u6cd5\u548c\u6807\u51c6\u5fae\u8c03\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u589e\u5f3a\u6a21\u578b\u533a\u5206\u68c0\u7d22\u6587\u6863\u4e2d\u76f8\u5173\u548c\u65e0\u5173\u4fe1\u606f\u7684\u80fd\u529b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b0\u5fae\u8c03\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728RAG\u4e2d\u6709\u566a\u58f0\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2601.01904", "pdf": "https://arxiv.org/pdf/2601.01904", "abs": "https://arxiv.org/abs/2601.01904", "authors": ["Yuxuan Li", "Harshith Reddy Kethireddy", "Srijita Das"], "title": "Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.\n  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.\n  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.", "AI": {"tldr": "\u63a2\u8ba8\u5f3a\u5316\u5b66\u4e60\u4e2d\u504f\u597d\u5b66\u4e60\u7684\u7279\u5f81\u4f9d\u8d56\u566a\u58f0\uff0c\u8bc4\u4f30\u5176\u5f71\u54cd\u5e76\u53d1\u73b0\u65b0\u73b0\u8c61\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u5904\u7406\u504f\u597d\u5b66\u4e60\u4e2d\u7684\u566a\u58f0\u7c7b\u578b\u6709\u9650\uff0c\u4e14\u591a\u4e3a\u5747\u5300\u5206\u5e03\u4e0e\u89c2\u6d4b\u65e0\u5173\uff0c\u9700\u7814\u7a76\u7279\u5f81\u4f9d\u8d56\u566a\u58f0\u3002", "method": "\u5f62\u5f0f\u5316\u76ee\u6807\u7279\u5f81\u4f9d\u8d56\u566a\u58f0\u6982\u5ff5\uff0c\u63d0\u51fa\u591a\u79cd\u566a\u58f0\u53d8\u4f53\uff0c\u5728\u590d\u6742\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8bc4\u4f30\u7279\u5f81\u4f9d\u8d56\u566a\u58f0\u3002", "result": "\u67d0\u4e9b\u7279\u5f81\u4f9d\u8d56\u566a\u58f0\u8bbe\u7f6e\u4e0b\uff0c\u73b0\u6709\u6297\u566a\u65b9\u6cd5\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u65e0\u663e\u5f0f\u53bb\u566a\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\uff1b\u8bed\u8a00\u6a21\u578b\u566a\u58f0\u6709\u7c7b\u4f3c\u7279\u5f81\u4f9d\u8d56\u566a\u58f0\u7279\u6027\u3002", "conclusion": "\u547c\u5401\u8fdb\u4e00\u6b65\u7814\u7a76\u5982\u4f55\u7a33\u5065\u5730\u5b66\u4e60\u7279\u5f81\u4f9d\u8d56\u566a\u58f0\u3002"}}
{"id": "2601.01908", "pdf": "https://arxiv.org/pdf/2601.01908", "abs": "https://arxiv.org/abs/2601.01908", "authors": ["Jingjing Wang", "Qianglin Liu", "Zhuo Xiao", "Xinning Yao", "Bo Liu", "Lu Li", "Lijuan Niu", "Fugen Zhou"], "title": "Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u8d85\u58f0\u56fe\u50cf\u4e2d\u7532\u72b6\u817a\u7ed3\u8282\u68c0\u6d4b\u7684Nodule - DETR\u67b6\u6784\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u8fbe\u6700\u4f18\uff0c\u6709\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u7532\u72b6\u817a\u764c\u53d1\u75c5\u7387\u4e0a\u5347\uff0c\u8d85\u58f0\u68c0\u6d4b\u7532\u72b6\u817a\u7ed3\u8282\u5b58\u5728\u56fe\u50cf\u5bf9\u6bd4\u5ea6\u4f4e\u3001\u7ed3\u8282\u8fb9\u754c\u6a21\u7cca\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u8bca\u65ad\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faNodule - DETR\u67b6\u6784\uff0c\u5305\u542bMSFCA\u6a21\u5757\u589e\u5f3a\u4f4e\u5bf9\u6bd4\u5ea6\u7ed3\u8282\u7279\u5f81\u3001HFF\u6a21\u5757\u8fdb\u884c\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\u3001MSDA\u6a21\u5757\u6355\u6349\u5c0f\u7684\u548c\u4e0d\u89c4\u5219\u5f62\u72b6\u7ed3\u8282\u3002", "result": "\u5728\u4e34\u5e8a\u7532\u72b6\u817a\u8d85\u58f0\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cNodule - DETR\u5728mAP@0.5:0.95\u4e0a\u6bd4\u57fa\u7ebf\u6a21\u578b\u9ad80.149\uff0c\u6027\u80fd\u8fbe\u6700\u4f18\u3002", "conclusion": "Nodule - DETR\u51c6\u786e\u6027\u9ad8\uff0c\u6709\u4f5c\u4e3a\u8ba1\u7b97\u673a\u8f85\u52a9\u7532\u72b6\u817a\u8bca\u65ad\u6709\u6548\u5de5\u5177\u7684\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.01927", "pdf": "https://arxiv.org/pdf/2601.01927", "abs": "https://arxiv.org/abs/2601.01927", "authors": ["Firuz Kamalov", "Hana Sulieman", "Witold Pedrycz"], "title": "Theoretical Convergence of SMOTE-Generated Samples", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.", "AI": {"tldr": "\u5bf9SMOTE\u6536\u655b\u6027\u8d28\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u5408\u6210\u968f\u673a\u53d8\u91cf\u6536\u655b\u6027\uff0c\u7ed9\u51fa\u6536\u655b\u901f\u5ea6\u76f8\u5173\u7ed3\u8bba\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u63d0\u5347\u6570\u636e\u589e\u5f3a\u6280\u672f\u7406\u89e3\u3002", "motivation": "\u4e0d\u5e73\u8861\u6570\u636e\u5f71\u54cd\u5e7f\u6cdb\uff0cSMOTE\u662f\u89e3\u51b3\u8be5\u95ee\u9898\u6d41\u884c\u65b9\u6cd5\uff0c\u9700\u5bf9\u5176\u8fdb\u884c\u7406\u8bba\u9a8c\u8bc1\u3002", "method": "\u5bf9SMOTE\u6536\u655b\u6027\u8d28\u8fdb\u884c\u4e25\u683c\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660e\u5408\u6210\u968f\u673a\u53d8\u91cf\u6982\u7387\u6536\u655b\u548c\u5747\u503c\u6536\u655b\uff0c\u7814\u7a76\u6700\u8fd1\u90bb\u79e9\u4e0e\u6536\u655b\u901f\u5ea6\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u5408\u6210\u968f\u673a\u53d8\u91cfZ\u4f9d\u6982\u7387\u6536\u655b\u5230\u57fa\u7840\u968f\u673a\u53d8\u91cfX\uff0c\u5728X\u7d27\u51d1\u65f6\u6709\u66f4\u5f3a\u7684\u5747\u503c\u6536\u655b\uff0c\u4f4e\u6700\u8fd1\u90bb\u79e9\u5bfc\u81f4\u66f4\u5feb\u6536\u655b\uff0c\u6570\u503c\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6570\u636e\u589e\u5f3a\u6280\u672f\u63d0\u4f9b\u57fa\u7840\u7406\u89e3\uff0c\u53ef\u7528\u4e8e\u4e0d\u5e73\u8861\u6570\u636e\u573a\u666f\u4e4b\u5916\u3002"}}
{"id": "2601.01931", "pdf": "https://arxiv.org/pdf/2601.01931", "abs": "https://arxiv.org/abs/2601.01931", "authors": ["Willem R\u00f6pke", "Samuel Coward", "Andrei Lupu", "Thomas Foster", "Tim Rockt\u00e4schel", "Jakob Foerster"], "title": "D\u00e9j\u00e0Q: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce D\u00e9j\u00e0Q, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of D\u00e9j\u00e0Q, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faD\u00e9j\u00e0Q\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8fdb\u5316\u5408\u6210\u6570\u5b66\u95ee\u9898\u4e0e\u6a21\u578b\u8bad\u7ec3\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684\u53d8\u5f02\u7b56\u7565\uff0c\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6548\u679c\uff0c\u5f3a\u8c03\u52a8\u6001\u8bad\u7ec3\u6570\u636e\u6f5c\u529b\u5e76\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u591a\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\uff0c\u6613\u9f13\u52b1\u8bb0\u5fc6\u4e14\u9650\u5236\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5f15\u5165D\u00e9j\u00e0Q\u6846\u67b6\uff0c\u5728\u6a21\u578b\u8bad\u7ec3\u540c\u65f6\u8fdb\u5316\u5408\u6210\u6570\u5b66\u95ee\u9898\uff0c\u63d0\u51fa\u4e24\u79cdLLM\u9a71\u52a8\u7684\u6570\u636e\u53d8\u5f02\u7b56\u7565\u3002", "result": "\u6a21\u578b\u80fd\u751f\u6210\u65b0\u800c\u6709\u610f\u4e49\u7684\u95ee\u9898\uff0cLLM\u9a71\u52a8\u53d8\u5f02\u6539\u5584\u4e86\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5206\u6790\u4e86D\u00e9j\u00e0Q\u7684\u5173\u952e\u65b9\u9762\u3002", "conclusion": "\u52a8\u6001\u8fdb\u5316\u7684\u8bad\u7ec3\u6570\u636e\u6709\u589e\u5f3a\u6570\u5b66\u63a8\u7406\u7684\u6f5c\u529b\uff0c\u6709\u66f4\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2601.01932", "pdf": "https://arxiv.org/pdf/2601.01932", "abs": "https://arxiv.org/abs/2601.01932", "authors": ["Barbora Hudcov\u00e1", "Franti\u0161ek Du\u0161ek", "Marco Tuccio", "Cl\u00e9ment Hongler"], "title": "Visualizing the Structure of Lenia Parameter Space", "categories": ["nlin.CG", "cs.AI"], "comment": "2 pages", "summary": "Continuous cellular automata are rocketing in popularity, yet developing a theoretical understanding of their behaviour remains a challenge. In the case of Lenia, a few fundamental open problems include determining what exactly constitutes a soliton, what is the overall structure of the parameter space, and where do the solitons occur in it. In this abstract, we present a new method to automatically classify Lenia systems into four qualitatively different dynamical classes. This allows us to detect moving solitons, and to provide an interactive visualization of Lenia's parameter space structure on our website https://lenia-explorer.vercel.app/. The results shed new light on the above-mentioned questions and lead to several observations: the existence of new soliton families for parameters where they were not believed to exist, or the universality of the phase space structure across various kernels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\u5c06Lenia\u7cfb\u7edf\u81ea\u52a8\u5206\u7c7b\uff0c\u68c0\u6d4b\u79fb\u52a8\u5b64\u5b50\u5e76\u53ef\u89c6\u5316\u53c2\u6570\u7a7a\u95f4\u7ed3\u6784\uff0c\u4e3a\u76f8\u5173\u95ee\u9898\u5e26\u6765\u65b0\u89c1\u89e3\u3002", "motivation": "\u8fde\u7eed\u5143\u80de\u81ea\u52a8\u673a\u867d\u53d7\u6b22\u8fce\uff0c\u4f46\u7406\u89e3\u5176\u884c\u4e3a\u5b58\u5728\u6311\u6218\uff0cLenia\u6709\u51e0\u4e2a\u57fa\u672c\u5f00\u653e\u6027\u95ee\u9898\u5f85\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\u5c06Lenia\u7cfb\u7edf\u81ea\u52a8\u5206\u4e3a\u56db\u4e2a\u4e0d\u540c\u52a8\u529b\u5b66\u7c7b\u522b\u3002", "result": "\u80fd\u68c0\u6d4b\u79fb\u52a8\u5b64\u5b50\uff0c\u5728\u7f51\u7ad9\u4e0a\u5b9e\u73b0\u53c2\u6570\u7a7a\u95f4\u7ed3\u6784\u53ef\u89c6\u5316\uff0c\u53d1\u73b0\u65b0\u5b64\u5b50\u65cf\u4ee5\u53ca\u76f8\u7a7a\u95f4\u7ed3\u6784\u7684\u666e\u904d\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aLenia\u57fa\u672c\u5f00\u653e\u6027\u95ee\u9898\u5e26\u6765\u65b0\u542f\u793a\u3002"}}
{"id": "2601.01966", "pdf": "https://arxiv.org/pdf/2601.01966", "abs": "https://arxiv.org/abs/2601.01966", "authors": ["Bo Yin", "Qi Li", "Runpeng Yu", "Xinchao Wang"], "title": "Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faRefinement Provenance Inference (RPI)\u5ba1\u8ba1\u4efb\u52a1\uff0c\u8bbe\u8ba1RePro\u6846\u67b6\u89e3\u51b3\u6307\u4ee4\u8c03\u4f18\u4e2d\u8bad\u7ec3\u63d0\u793a\u6765\u6e90\u63a8\u65ad\u95ee\u9898\uff0c\u8868\u73b0\u826f\u597d\u4e14\u6709\u8de8\u7cbe\u70bc\u5668\u7684\u8fc1\u79fb\u6027\u3002", "motivation": "\u5728\u6307\u4ee4\u8c03\u4f18\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u7cbe\u70bc\u7684\u80cc\u666f\u4e0b\uff0c\u89e3\u51b3\u5728\u6df7\u5408\u8bed\u6599\u4e2d\u63a8\u65ad\u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u7684\u662f\u539f\u59cb\u63d0\u793a\u8fd8\u662f\u7cbe\u70bc\u7248\u672c\u7684\u95ee\u9898\uff0c\u8fd9\u5bf9\u6570\u636e\u96c6\u6cbb\u7406\u548c\u4e89\u8bae\u89e3\u51b3\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5c06\u5ba1\u8ba1\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3aRPI\uff0c\u5229\u7528\u63d0\u793a\u7cbe\u70bc\u5728\u6559\u5e08\u5f3a\u8feb\u6807\u8bb0\u5206\u5e03\u4e2d\u7684\u7a33\u5b9a\u53ef\u68c0\u6d4b\u53d8\u5316\uff0c\u63d0\u51fa\u57fa\u4e8e\u5bf9\u6570\u7684RePro\u6846\u67b6\uff0c\u878d\u5408\u6559\u5e08\u5f3a\u8feb\u4f3c\u7136\u7279\u5f81\u548c\u5bf9\u6570\u6392\u5e8f\u4fe1\u53f7\uff0c\u901a\u8fc7\u5f71\u5b50\u5fae\u8c03\u5b66\u4e60\u53ef\u8fc1\u79fb\u8868\u793a\uff0c\u7528\u8f7b\u91cf\u7ea7\u7ebf\u6027\u5934\u63a8\u65ad\u6765\u6e90\u3002", "result": "RePro\u5728\u5b9e\u9a8c\u4e2d\u59cb\u7ec8\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u5728\u4e0d\u540c\u7cbe\u70bc\u5668\u4e4b\u95f4\u6709\u826f\u597d\u7684\u8fc1\u79fb\u6027\u3002", "conclusion": "RePro\u5229\u7528\u4e86\u4e0e\u7cbe\u70bc\u5668\u65e0\u5173\u7684\u5206\u5e03\u53d8\u5316\uff0c\u800c\u975e\u91cd\u5199\u98ce\u683c\u7684\u4eba\u5de5\u75d5\u8ff9\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u63d0\u793a\u6765\u6e90\u63a8\u65ad\u95ee\u9898\u3002"}}
{"id": "2601.01989", "pdf": "https://arxiv.org/pdf/2601.01989", "abs": "https://arxiv.org/abs/2601.01989", "authors": ["Aly R. Elkammar", "Karim M. Gamaleldin", "Catherine M. Elias"], "title": "VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer/VVT\u4e0d\u540c\u5c3a\u5bf8\u7b97\u6cd5\u7528\u4e8e\u884c\u4eba\u610f\u56fe\u9884\u6d4b\uff0c\u5728JAAD\u6570\u636e\u96c6\u8fbeSOTA\u3002", "motivation": "\u884c\u4eba\u610f\u56fe\u9884\u6d4b\u662f\u81ea\u52a8\u9a7e\u9a76\u4ece3\u7ea7\u52304\u7ea7\u8fc7\u6e21\u7684\u5173\u952e\u6280\u672f\uff0c\u9700\u8003\u8651\u591a\u5143\u7d20\u7279\u5f81\u4fdd\u969c\u9053\u8def\u5b89\u5168\u3002", "method": "\u5f15\u5165\u57fa\u4e8eTransformer/\u89c6\u9891\u89c6\u89c9Transformer\u4e0d\u540c\u5c3a\u5bf8\u7b97\u6cd5\uff0c\u4f7f\u7528\u4e0d\u540c\u6570\u636e\u6a21\u6001\u3002", "result": "\u5728JAAD\u6570\u636e\u96c6\u8bc4\u4f30\u7b97\u6cd5\uff0c\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u90e8\u5206\u6307\u6807\u8d85\u8d8aSOTA\u3002", "conclusion": "\u901a\u8fc7\u5927\u91cf\u6d88\u878d\u7814\u7a76\u63a2\u7a76\u4e0d\u540c\u6a21\u578b\u8bbe\u8ba1\u9009\u62e9\u5e26\u6765\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.02010", "pdf": "https://arxiv.org/pdf/2601.02010", "abs": "https://arxiv.org/abs/2601.02010", "authors": ["Liangxuan Guo", "Haoyang Chen", "Yang Chen", "Yanchao Bi", "Shan Yu"], "title": "A neural network for modeling human concept formation, understanding and communication", "categories": ["q-bio.NC", "cs.AI", "cs.CL"], "comment": "6 main figures, 5 extended data figures and 4 supplementary figures", "summary": "A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.", "AI": {"tldr": "\u63d0\u51faCATS Net\u53cc\u6a21\u5757\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u5176\u6982\u5ff5\u7a7a\u95f4\u4e0e\u795e\u7ecf\u8ba4\u77e5\u8bed\u4e49\u6a21\u578b\u548c\u5927\u8111\u54cd\u5e94\u7ed3\u6784\u4e00\u81f4\uff0c\u4e3a\u7406\u89e3\u4eba\u7c7b\u6982\u5ff5\u8ba4\u77e5\u548c\u6784\u5efa\u7c7b\u4eba\u6982\u5ff5\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u4eba\u7c7b\u5927\u8111\u80fd\u4ece\u611f\u89c9\u8fd0\u52a8\u7ecf\u9a8c\u4e2d\u5f62\u6210\u62bd\u8c61\u6982\u5ff5\u8868\u5f81\u5e76\u7075\u6d3b\u5e94\u7528\uff0c\u4f46\u8be5\u80fd\u529b\u7684\u8ba1\u7b97\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\uff0c\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faCATS Net\u6846\u67b6\uff0c\u5305\u542b\u6982\u5ff5\u62bd\u8c61\u6a21\u5757\u548c\u4efb\u52a1\u89e3\u51b3\u6a21\u5757\uff0c\u7cfb\u7edf\u57fa\u4e8e\u6982\u5ff5\u8868\u5f81\u53d1\u5c55\u53ef\u8f6c\u79fb\u8bed\u4e49\u7ed3\u6784\u3002", "result": "\u6a21\u578b\u7684\u6982\u5ff5\u7a7a\u95f4\u4e0e\u795e\u7ecf\u8ba4\u77e5\u8bed\u4e49\u6a21\u578b\u548c\u4eba\u7c7b\u8179\u4fa7\u6795\u989e\u53f6\u76ae\u8d28\u7684\u5927\u8111\u54cd\u5e94\u7ed3\u6784\u4e00\u81f4\uff0c\u95e8\u63a7\u673a\u5236\u4e0e\u8bed\u4e49\u63a7\u5236\u8111\u7f51\u7edc\u76f8\u4f3c\u3002", "conclusion": "\u5efa\u7acb\u4e86\u7edf\u4e00\u8ba1\u7b97\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u4eba\u7c7b\u6982\u5ff5\u8ba4\u77e5\u548c\u6784\u5efa\u7c7b\u4eba\u6982\u5ff5\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u673a\u5236\u6027\u89c1\u89e3\u3002"}}
{"id": "2601.02015", "pdf": "https://arxiv.org/pdf/2601.02015", "abs": "https://arxiv.org/abs/2601.02015", "authors": ["Omar Momen", "Emilie Sitter", "Berenike Herrmann", "Sina Zarrie\u00df"], "title": "Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects", "categories": ["cs.CL", "cs.AI", "cs.IT"], "comment": "to be published at EACL 2026 main conference", "summary": "Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.", "AI": {"tldr": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u4e2d\u60ca\u5947\u503c\u4e0e\u4e0d\u540c\u9690\u55bb\u65b0\u9896\u6027\u6570\u636e\u96c6\u7684\u76f8\u5173\u6027\uff0c\u53d1\u73b0\u6709\u9002\u5ea6\u5173\u8054\u53ca\u4e0d\u540c\u7f29\u653e\u6a21\u5f0f\uff0c\u60ca\u5947\u503c\u5bf9\u9690\u55bb\u65b0\u9896\u6027\u6807\u6ce8\u6709\u90e8\u5206\u89e3\u91ca\u529b\u4f46\u6709\u9650\u3002", "motivation": "\u9690\u55bb\u7406\u89e3\u6d89\u53ca\u590d\u6742\u8bed\u4e49\u548c\u8bed\u8a00\u521b\u9020\u6027\uff0c\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u4e2d\u60ca\u5947\u503c\u4e0e\u4e0d\u540c\u9690\u55bb\u65b0\u9896\u6027\u6570\u636e\u96c6\u7684\u76f8\u5173\u6027\u3002", "method": "\u5206\u679016\u79cd\u8bed\u8a00\u6a21\u578b\u53d8\u4f53\u5728\u57fa\u4e8e\u8bed\u6599\u5e93\u548c\u5408\u6210\u7684\u9690\u55bb\u65b0\u9896\u6027\u6570\u636e\u96c6\u4e0a\u7684\u60ca\u5947\u503c\uff0c\u91c7\u7528\u57fa\u4e8e\u5168\u53e5\u4e0a\u4e0b\u6587\u7684\u5b8c\u5f62\u586b\u7a7a\u5f0f\u60ca\u5947\u503c\u65b9\u6cd5\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u4e0e\u9690\u55bb\u65b0\u9896\u6027\u5f97\u5206/\u6807\u7b7e\u6709\u663e\u8457\u7684\u9002\u5ea6\u76f8\u5173\u6027\uff0c\u5728\u57fa\u4e8e\u8bed\u6599\u5e93\u6570\u636e\u4e0a\u76f8\u5173\u5f3a\u5ea6\u968f\u6a21\u578b\u5927\u5c0f\u51cf\u5c0f\uff0c\u5728\u5408\u6210\u6570\u636e\u4e0a\u589e\u52a0\u3002", "conclusion": "\u60ca\u5947\u503c\u80fd\u90e8\u5206\u89e3\u91ca\u9690\u55bb\u65b0\u9896\u6027\u6807\u6ce8\uff0c\u4f46\u4ecd\u662f\u8861\u91cf\u8bed\u8a00\u521b\u9020\u6027\u7684\u6709\u9650\u6307\u6807\u3002"}}
{"id": "2601.02016", "pdf": "https://arxiv.org/pdf/2601.02016", "abs": "https://arxiv.org/abs/2601.02016", "authors": ["Matthias Bartolo", "Dylan Seychell", "Gabriel Hili", "Matthew Montebello", "Carl James Debono", "Saviour Formosa", "Konstantinos Makantasis"], "title": "Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.LG"], "comment": "Code available on GitHub: https://github.com/mbar0075/lupi-for-object-detection", "summary": "This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5c06LUPI\u8303\u5f0f\u96c6\u6210\u5230\u76ee\u6807\u68c0\u6d4b\u4e2d\uff0c\u901a\u8fc7\u5e08\u751f\u67b6\u6784\u6ce8\u5165\u7279\u6743\u4fe1\u606f\uff0c\u5b9e\u9a8c\u8868\u660eLUPI\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u66f4\u4f18\uff0c\u4e3a\u76ee\u6807\u68c0\u6d4b\u63d0\u4f9b\u6709\u6548\u7b56\u7565\u3002", "motivation": "\u5229\u7528\u8bad\u7ec3\u65f6\u53ef\u7528\u4f46\u63a8\u7406\u65f6\u4e0d\u53ef\u7528\u7684\u7ec6\u7c92\u5ea6\u63cf\u8ff0\u4fe1\u606f\uff0c\u63d0\u5347\u76ee\u6807\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u5f15\u5165\u901a\u7528\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e08\u751f\u67b6\u6784\u5c06\u5982\u8fb9\u754c\u6846\u63a9\u7801\u3001\u663e\u8457\u6027\u56fe\u548c\u6df1\u5ea6\u7ebf\u7d22\u7b49\u7279\u6743\u4fe1\u606f\u6ce8\u5165\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u3002", "result": "LUPI\u8bad\u7ec3\u7684\u6a21\u578b\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u68c0\u6d4b\u7cbe\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u63a8\u7406\u590d\u6742\u5ea6\u548c\u6a21\u578b\u5927\u5c0f\u65e0\u589e\u52a0\uff0c\u5bf9\u4e2d\u5927\u578b\u7269\u4f53\u6548\u679c\u5c24\u4f73\uff0c\u4e2d\u95f4\u6743\u91cd\u7684\u6559\u5e08\u6307\u5bfc\u80fd\u5e73\u8861\u5b66\u4e60\u3002", "conclusion": "LUPI\u6846\u67b6\u4e3a\u8d44\u6e90\u53d7\u9650\u548c\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u5b9e\u7528\u7684\u7b56\u7565\u3002"}}
{"id": "2601.02023", "pdf": "https://arxiv.org/pdf/2601.02023", "abs": "https://arxiv.org/abs/2601.02023", "authors": ["Amirali Ebrahimzadeh", "Seyyed M. Salili"], "title": "Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "25 pages, 8 figures, 3 tables", "summary": "Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u8f93\u5165\u4e0a\u4e0b\u6587\u4e0b\u4fe1\u606f\u63d0\u53d6\u548c\u63a8\u7406\u7684\u53ef\u9760\u6027\uff0c\u5f15\u5165\u65b0\u57fa\u51c6\u8bc4\u4f30\u56db\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u957f\u4e0a\u4e0b\u6587\u4e0d\u4fdd\u8bc1\u6027\u80fd\u63d0\u5347\uff0c\u6297\u5e7b\u89c9\u6307\u4ee4\u6709\u526f\u4f5c\u7528\uff0c\u6a21\u578b\u5728\u5229\u7528\u4e0a\u4e0b\u6587\u4e0a\u5b58\u5728\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u652f\u6301\u957f\u8f93\u5165\u4e0a\u4e0b\u6587\uff0c\u4f46\u4fe1\u606f\u63d0\u53d6\u548c\u63a8\u7406\u53ef\u9760\u6027\u672a\u77e5\uff0c\u4e14\u6027\u80fd\u53d7\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u4fe1\u606f\u5206\u5e03\u5f71\u54cd\uff0c\u56e0\u6b64\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5f15\u5165\u6269\u5c55\u7684\u9488\u5728\u8349\u5806\u57fa\u51c6\u8bc4\u4f30\u56db\u79cd\u6a21\u578b\uff0c\u5206\u522b\u8bc4\u4f30\u5b57\u9762\u63d0\u53d6\u3001\u903b\u8f91\u63a8\u7406\u548c\u5e7b\u89c9\u98ce\u9669\uff0c\u8003\u8651\u8bc1\u636e\u4f4d\u7f6e\u6548\u5e94\u3001\u73b0\u5b9e\u5206\u5e03\u53ca\u53cd\u7f16\u9020\u63d0\u793a\u3002", "result": "\u957f\u4e0a\u4e0b\u6587\u4e0d\u4fdd\u8bc1\u66f4\u597d\u6027\u80fd\uff0c\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u5927\uff0c\u6297\u5e7b\u89c9\u6307\u4ee4\u4f7f\u90e8\u5206\u6a21\u578b\u4fdd\u5b88\u4e14\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u4fe1\u606f\u5229\u7528\u4e0a\u5b58\u5728\u95ee\u9898\u3002", "conclusion": "\u6709\u6548\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u9c81\u68d2\u6027\u5bf9\u7814\u7a76\u548c\u5546\u4e1a\u4e2d\u53ef\u9760\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.02031", "pdf": "https://arxiv.org/pdf/2601.02031", "abs": "https://arxiv.org/abs/2601.02031", "authors": ["Felix Stollenwerk", "Anna Lokrantz", "Niclas Hertzberg"], "title": "Output Embedding Centering for Stable LLM Pretraining", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 5 figures", "summary": "Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called \u03bc-centering, or a regularization method called \u03bc-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that \u03bc-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u8f93\u51fa\u5bf9\u6570\u51e0\u7387\u6563\u5ea6\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u63d0\u51fa\u8f93\u51fa\u5d4c\u5165\u5c45\u4e2d\uff08OEC\uff09\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8ez - loss\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u5b58\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\uff0cz - loss\u4ec5\u6cbb\u6807\u4e0d\u6cbb\u672c\uff0c\u9700\u627e\u5230\u89e3\u51b3\u8f93\u51fa\u5bf9\u6570\u51e0\u7387\u6563\u5ea6\u95ee\u9898\u7684\u66f4\u597d\u65b9\u6cd5\u3002", "method": "\u4ece\u8f93\u51fa\u5d4c\u5165\u51e0\u4f55\u89d2\u5ea6\u5206\u6790\u4e0d\u7a33\u5b9a\u539f\u56e0\uff0c\u63d0\u51faOEC\u7b56\u7565\uff0c\u6709\u03bc - centering\u548c\u03bc - loss\u4e24\u79cd\u5b9e\u73b0\u65b9\u5f0f\u3002", "result": "\u4e24\u79cdOEC\u53d8\u4f53\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u5b66\u4e60\u7387\u654f\u611f\u6027\u4e0a\u4f18\u4e8ez - loss\uff0c\u5927\u5b66\u4e60\u7387\u65f6z - loss\u5931\u6548\u800cOEC\u80fd\u4fdd\u8bc1\u6536\u655b\uff0c\u03bc - loss\u5bf9\u6b63\u5219\u5316\u8d85\u53c2\u6570\u8c03\u6574\u7684\u654f\u611f\u6027\u8fdc\u4f4e\u4e8ez - loss\u3002", "conclusion": "OEC\u7b56\u7565\u6709\u6548\u6291\u5236\u8f93\u51fa\u5bf9\u6570\u51e0\u7387\u6563\u5ea6\uff0c\u662f\u6bd4z - loss\u66f4\u597d\u7684\u89e3\u51b3\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.02046", "pdf": "https://arxiv.org/pdf/2601.02046", "abs": "https://arxiv.org/abs/2601.02046", "authors": ["Shaocheng Shen", "Jianfeng Liang. Chunlei Cai", "Cong Geng", "Huiyu Duan", "Xiaoyun Zhang", "Qiang Hu", "Guangtao Zhai"], "title": "Agentic Retoucher for Text-To-Image Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.", "AI": {"tldr": "\u63d0\u51fa Agentic Retoucher \u6846\u67b6\u89e3\u51b3\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u5c0f\u5c3a\u5ea6\u5931\u771f\u95ee\u9898\uff0c\u6784\u5efa GenBlemish - 27K \u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u5b58\u5728\u5c0f\u5c3a\u5ea6\u5931\u771f\u95ee\u9898\uff0c\u73b0\u6709\u6539\u8fdb\u65b9\u6cd5\u6709\u6210\u672c\u9ad8\u3001\u8bed\u4e49\u6f02\u79fb\u7b49\u7f3a\u70b9\u3002", "method": "\u63d0\u51fa Agentic Retoucher \u6846\u67b6\uff0c\u5305\u542b\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\u4ee3\u7406\uff0c\u8fd8\u6784\u5efa GenBlemish - 27K \u6570\u636e\u96c6\u7528\u4e8e\u76d1\u7763\u548c\u8bc4\u4f30\u3002", "result": "Agentic Retoucher \u5728\u611f\u77e5\u8d28\u91cf\u3001\u5931\u771f\u5b9a\u4f4d\u548c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Agentic Retoucher \u4e3a\u81ea\u6821\u6b63\u548c\u611f\u77e5\u53ef\u9760\u7684\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.02065", "pdf": "https://arxiv.org/pdf/2601.02065", "abs": "https://arxiv.org/abs/2601.02065", "authors": ["Md. Asif Hossain", "Nabil Subhan", "Mantasha Rahman Mahi", "Jannatul Ferdous Nabila"], "title": "Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory", "categories": ["cs.CL", "cs.AI"], "comment": "5 pages, 3 figures, 1 table", "summary": "Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u519c\u4e1a\u54a8\u8be2\u7684\u4f4e\u6210\u672c\u8de8\u8bed\u8a00RAG\u6846\u67b6\uff0c\u7528\u5f00\u6e90\u6a21\u578b\u548c\u6d88\u8d39\u7ea7\u786c\u4ef6\u5b9e\u73b0\uff0c\u5b9e\u9a8c\u663e\u793a\u7ed3\u679c\u597d\u3002", "motivation": "\u8bb8\u591a\u53d1\u5c55\u4e2d\u5730\u533a\u56e0\u8bed\u8a00\u969c\u788d\u83b7\u53d6\u53ef\u9760\u519c\u4e1a\u54a8\u8be2\u53d7\u9650\uff0c\u73b0\u6709\u5927\u6a21\u578b\u76f4\u63a5\u751f\u6210\u4f4e\u8d44\u6e90\u8bed\u8a00\u6548\u679c\u5dee\uff0c\u4e91\u65b9\u6848\u6210\u672c\u9ad8\u3002", "method": "\u91c7\u7528\u4ee5\u7ffb\u8bd1\u4e3a\u4e2d\u5fc3\u7684\u67b6\u6784\uff0c\u5c06\u5b5f\u52a0\u62c9\u8bed\u67e5\u8be2\u7ffb\u8bd1\u4e3a\u82f1\u8bed\uff0c\u6ce8\u5165\u9886\u57df\u5173\u952e\u8bcd\u540e\u4ece\u82f1\u6587\u624b\u518c\u4e2d\u68c0\u7d22\u56de\u7b54\uff0c\u518d\u7ffb\u8bd1\u56de\u5b5f\u52a0\u62c9\u8bed\uff0c\u7528\u5f00\u6e90\u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u80fd\u751f\u6210\u53ef\u9760\u6709\u4f9d\u636e\u7684\u56de\u7b54\uff0c\u80fd\u62d2\u7edd\u5bf9\u9886\u57df\u5916\u67e5\u8be2\uff0c\u5e73\u5747\u7aef\u5230\u7aef\u5ef6\u8fdf\u4f4e\u4e8e20\u79d2\u3002", "conclusion": "\u8de8\u8bed\u8a00\u68c0\u7d22\u7ed3\u5408\u53ef\u63a7\u7ffb\u8bd1\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u5730\u533a\u83b7\u53d6\u519c\u4e1a\u77e5\u8bc6\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6848\u3002"}}
{"id": "2601.02076", "pdf": "https://arxiv.org/pdf/2601.02076", "abs": "https://arxiv.org/abs/2601.02076", "authors": ["Yingte Shu", "Yuchuan Tian", "Chao Xu", "Yunhe Wang", "Hanting Chen"], "title": "Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u57fa\u4e8e\u5757\u7684\u6269\u6563\u65b9\u6cd5\u5b58\u5728\u7684\u8fb9\u754c\u8bf1\u5bfc\u4e0a\u4e0b\u6587\u622a\u65ad\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65e0\u8bad\u7ec3\u7684\u5ef6\u8fdf\u627f\u8bfa\u89e3\u7801\uff08DCD\uff09\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u7b56\u7565\u80fd\u63d0\u9ad8\u751f\u6210\u51c6\u786e\u6027\u4e14\u4e0d\u964d\u4f4e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5757\u7684\u6269\u6563\u65b9\u6cd5\u5b58\u5728\u8fb9\u754c\u8bf1\u5bfc\u4e0a\u4e0b\u6587\u622a\u65ad\u95ee\u9898\uff0c\u4f1a\u964d\u4f4e\u89e3\u7801\u4fe1\u5fc3\u548c\u751f\u6210\u8d28\u91cf\uff0c\u5c24\u5176\u5728\u9700\u8981\u7cbe\u786e\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u3002", "method": "\u63d0\u51fa\u5ef6\u8fdf\u627f\u8bfa\u89e3\u7801\uff08DCD\uff09\u7b56\u7565\uff0c\u5728\u63a9\u7801\u6807\u8bb0\u4e0a\u7ef4\u62a4\u4e00\u4e2a\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u6ed1\u52a8\u7a97\u53e3\uff0c\u5c3d\u65e9\u89e3\u51b3\u4f4e\u4e0d\u786e\u5b9a\u6027\u6807\u8bb0\uff0c\u5c06\u9ad8\u4e0d\u786e\u5b9a\u6027\u6807\u8bb0\u5ef6\u8fdf\u5230\u6709\u8db3\u591f\u4e0a\u4e0b\u6587\u8bc1\u636e\u65f6\u518d\u5904\u7406\u3002", "result": "\u5728\u591a\u4e2a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u3001\u57fa\u51c6\u548c\u7f13\u5b58\u914d\u7f6e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u56fa\u5b9a\u57fa\u4e8e\u5757\u7684\u6269\u6563\u65b9\u6cd5\u76f8\u6bd4\uff0cDCD\u5e73\u5747\u5c06\u751f\u6210\u51c6\u786e\u7387\u63d0\u9ad81.39%\uff0c\u65f6\u95f4\u76f8\u8fd1\uff0c\u6700\u5927\u63d0\u9ad8\u8fbe9.0%\u3002", "conclusion": "\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u5ef6\u8fdf\u6807\u8bb0\u51b3\u7b56\u662f\u63d0\u9ad8\u6269\u6563\u8bed\u8a00\u6a21\u578b\u89e3\u7801\u8d28\u91cf\u548c\u6548\u7387\u7684\u7b80\u5355\u800c\u6709\u6548\u7684\u539f\u5219\u3002"}}
{"id": "2601.02080", "pdf": "https://arxiv.org/pdf/2601.02080", "abs": "https://arxiv.org/abs/2601.02080", "authors": ["Yizhi Liu"], "title": "The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value \u03c3_2 and filtering out high-frequency feature components. We derive a spectral bound linking \u03c3_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.", "AI": {"tldr": "\u6307\u51fa\u53cc\u968f\u673a\u77e9\u9635\uff08DSM\uff09\u7ea6\u675f\u4e0b\u5b58\u5728\u540c\u8d28\u6027\u9677\u9631\uff0c\u63ed\u793a\u9ad8\u71b5\u7ea6\u675f\u4e0e\u7279\u5f81\u53d8\u6362\u7b49\u95ee\u9898\uff0c\u53ca\u5c42\u5f52\u4e00\u5316\u5728\u566a\u58f0\u4e3b\u5bfc\u4e0b\u7684\u5931\u6548\uff0c\u70b9\u660e\u71b5\u7a33\u5b9a\u6027\u548c\u8c31\u8868\u8fbe\u6027\u7684\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u53cc\u968f\u673a\u77e9\u9635\u5728\u7ed3\u6784\u4fdd\u7559\u6df1\u5ea6\u67b6\u6784\u5e94\u7528\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u8bc6\u522b\u6f5c\u5728\u73b0\u8c61\u3002", "method": "\u5206\u6790Sinkhorn\u6295\u5f71\u7684\u6700\u5927\u71b5\u504f\u5dee\uff0c\u63a8\u5bfc\u5947\u5f02\u503c\u03c3_2\u4e0e\u7f51\u7edc\u6709\u6548\u6df1\u5ea6\u7684\u8c31\u754c\uff0c\u8fdb\u884c\u7406\u8bba\u8bc1\u660e\u3002", "result": "\u53d1\u73b0\u540c\u8d28\u6027\u9677\u9631\uff0c\u8868\u660e\u9ad8\u71b5\u7ea6\u675f\u9650\u5236\u7279\u5f81\u53d8\u6362\uff0c\u5c42\u5f52\u4e00\u5316\u5728\u566a\u58f0\u4e3b\u5bfc\u4e0b\u65e0\u6cd5\u7f13\u89e3\u5d29\u6e83\uff0c\u635f\u5931\u51e0\u4f55\u7ed3\u6784\u3002", "conclusion": "DSM\u7ea6\u675f\u7f51\u7edc\u5b58\u5728\u71b5\u7a33\u5b9a\u6027\u548c\u8c31\u8868\u8fbe\u6027\u7684\u6839\u672c\u6743\u8861\u3002"}}
{"id": "2601.02085", "pdf": "https://arxiv.org/pdf/2601.02085", "abs": "https://arxiv.org/abs/2601.02085", "authors": ["Meili Sun", "Chunjiang Zhao", "Lichao Yang", "Hao Liu", "Shimin Hu", "Ya Xiong"], "title": "Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u8349\u8393\u91c7\u6458\u673a\u5668\u4eba\u89c6\u89c9\u611f\u77e5\u4f4e\u96c6\u6210\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u89c6\u89c9\u6545\u969c\u8bca\u65ad\u4e0e\u81ea\u6062\u590d\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u8349\u8393\u91c7\u6458\u673a\u5668\u4eba\u89c6\u89c9\u611f\u77e5\u96c6\u6210\u5ea6\u4f4e\u3001\u6293\u624b\u4e0e\u679c\u5b9e\u5bf9\u9f50\u4e0d\u51c6\u3001\u7a7a\u6293\u548c\u6293\u529b\u4e0d\u8db3\u5bfc\u81f4\u8349\u8393\u6ed1\u843d\u7b49\u95ee\u9898\uff0c\u63d0\u5347\u91c7\u6458\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u591a\u4efb\u52a1\u611f\u77e5\u4e0e\u7ea0\u6b63\u63a7\u5236\u7b56\u7565\u7684\u89c6\u89c9\u6545\u969c\u8bca\u65ad\u548c\u81ea\u6211\u6062\u590d\u6846\u67b6\uff0c\u6838\u5fc3\u662fSRR - Net\u591a\u4efb\u52a1\u611f\u77e5\u6a21\u578b\uff0c\u8bbe\u8ba1\u76f8\u5bf9\u8bef\u5dee\u8865\u507f\u6cd5\uff0c\u91c7\u7528\u65e9\u671f\u4e2d\u6b62\u7b56\u7565\uff0c\u901a\u8fc7\u5d4c\u5165\u5f0f\u5fae\u578b\u5149\u5b66\u76f8\u673a\u548c\u5206\u7c7b\u5668\u5b9e\u73b0\u53cd\u9988\u3002", "result": "SRR - Net\u4fdd\u6301\u9ad8\u611f\u77e5\u7cbe\u5ea6\uff0c\u68c0\u6d4b\u3001\u5206\u5272\u548c\u6210\u719f\u5ea6\u4f30\u8ba1\u8868\u73b0\u826f\u597d\uff0c\u652f\u6301\u591a\u4efb\u52a1\u611f\u77e5\uff0c\u63a8\u7406\u901f\u5ea6\u8fbe163.35 FPS\u3002", "conclusion": "\u6240\u63d0\u89c6\u89c9\u6545\u969c\u8bca\u65ad\u548c\u81ea\u6211\u6062\u590d\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u8349\u8393\u91c7\u6458\u673a\u5668\u4eba\u7684\u76f8\u5173\u95ee\u9898\uff0c\u63d0\u5347\u5176\u6027\u80fd\u3002"}}
{"id": "2601.02105", "pdf": "https://arxiv.org/pdf/2601.02105", "abs": "https://arxiv.org/abs/2601.02105", "authors": ["Hyunjun Kim"], "title": "LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.\n  We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.\n  Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.\n  We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.", "AI": {"tldr": "\u63d0\u51faLION - DG\u521d\u59cb\u5316\u65b9\u6cd5\u7528\u4e8e\u6df1\u5ea6\u76d1\u7763\u67b6\u6784\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u52a0\u901f\u6536\u655b\u3001\u63d0\u5347\u51c6\u786e\u7387\uff0c\u4e14\u65e0\u8d85\u53c2\u6570\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u6743\u91cd\u521d\u59cb\u5316\u65b9\u6cd5\u5927\u591a\u4e0e\u5c42\u65e0\u5173\uff0c\u6df1\u5ea6\u76d1\u7763\u67b6\u6784\u4e2d\u672a\u8bad\u7ec3\u7684\u8f85\u52a9\u5934\u4f1a\u56e0\u68af\u5ea6\u5e72\u6270\u4f7f\u65e9\u671f\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faLION - DG\uff0c\u5bf9\u8f85\u52a9\u5206\u7c7b\u5668\u5934\u96f6\u521d\u59cb\u5316\uff0c\u5bf9\u9aa8\u5e72\u7f51\u7edc\u91c7\u7528\u6807\u51c6He\u521d\u59cb\u5316\u3002", "result": "\u5728CIFAR - 10\u548cCIFAR - 100\u4e0a\u5b9e\u9a8c\uff0cDenseNet - DS\u5728CIFAR - 10\u4e0a\u6536\u655b\u5feb8.3%\uff1bLSUV\u4e0eLION - DG\u7ed3\u5408\u5728CIFAR - 10\u4e0a\u51c6\u786e\u7387\u8fbe81.92%\uff1bResNet - DS\u5728CIFAR - 100\u4e0a\u52a0\u901f11.3%\u3002", "conclusion": "\u786e\u5b9a\u4e86\u7279\u5b9a\u67b6\u6784\u7684\u6743\u8861\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u6307\u5bfc\uff0cLION - DG\u7b80\u5355\u3001\u65e0\u8d85\u53c2\u6570\u3001\u65e0\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2601.02121", "pdf": "https://arxiv.org/pdf/2601.02121", "abs": "https://arxiv.org/abs/2601.02121", "authors": ["En Xu", "Shihe Zhou", "Huandong Wang", "Jingtao Ding", "Yong Li"], "title": "Inferring Network Evolutionary History via Structure-State Coupled Learning", "categories": ["cs.SI", "cs.AI"], "comment": null, "summary": "Inferring a network's evolutionary history from a single final snapshot with limited temporal annotations is fundamental yet challenging. Existing approaches predominantly rely on topology alone, which often provides insufficient and noisy cues. This paper leverages network steady-state dynamics -- converged node states under a given dynamical process -- as an additional and widely accessible observation for network evolution history inference. We propose CS$^2$, which explicitly models structure-state coupling to capture how topology modulates steady states and how the two signals jointly improve edge discrimination for formation-order recovery. Experiments on six real temporal networks, evaluated under multiple dynamical processes, show that CS$^2$ consistently outperforms strong baselines, improving pairwise edge precedence accuracy by 4.0% on average and global ordering consistency (Spearman-$\u03c1$) by 7.7% on average. CS$^2$ also more faithfully recovers macroscopic evolution trajectories such as clustering formation, degree heterogeneity, and hub growth. Moreover, a steady-state-only variant remains competitive when reliable topology is limited, highlighting steady states as an independent signal for evolution inference.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5229\u7528\u7f51\u7edc\u7a33\u6001\u52a8\u529b\u5b66\u8fdb\u884c\u7f51\u7edc\u6f14\u5316\u5386\u53f2\u63a8\u65ad\u7684\u65b9\u6cd5CS\u00b2\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7a33\u6001\u4fe1\u53f7\u53ef\u72ec\u7acb\u7528\u4e8e\u6f14\u5316\u63a8\u65ad\u3002", "motivation": "\u4ece\u6709\u9650\u65f6\u95f4\u6ce8\u91ca\u7684\u5355\u4e2a\u7ec8\u6001\u5feb\u7167\u4e2d\u63a8\u65ad\u7f51\u7edc\u6f14\u5316\u5386\u53f2\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u62d3\u6251\u7ed3\u6784\uff0c\u4fe1\u606f\u4e0d\u8db3\u4e14\u6709\u566a\u58f0\u3002", "method": "\u63d0\u51faCS\u00b2\u65b9\u6cd5\uff0c\u660e\u786e\u5efa\u6a21\u7ed3\u6784 - \u72b6\u6001\u8026\u5408\uff0c\u4ee5\u6355\u6349\u62d3\u6251\u5982\u4f55\u8c03\u8282\u7a33\u6001\uff0c\u5229\u7528\u4e24\u79cd\u4fe1\u53f7\u5171\u540c\u6539\u8fdb\u8fb9\u5224\u522b\u6765\u6062\u590d\u5f62\u6210\u987a\u5e8f\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u65f6\u6001\u7f51\u7edc\u7684\u591a\u52a8\u529b\u5b66\u8fc7\u7a0b\u4e2d\u5b9e\u9a8c\u8868\u660e\uff0cCS\u00b2\u5e73\u5747\u63d0\u9ad8\u6210\u5bf9\u8fb9\u4f18\u5148\u7ea7\u7cbe\u5ea64.0%\uff0c\u5168\u5c40\u6392\u5e8f\u4e00\u81f4\u60277.7%\uff0c\u80fd\u66f4\u597d\u8fd8\u539f\u5b8f\u89c2\u6f14\u5316\u8f68\u8ff9\uff0c\u7a33\u6001\u53d8\u4f53\u5728\u62d3\u6251\u4fe1\u606f\u6709\u9650\u65f6\u4ecd\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u7f51\u7edc\u7a33\u6001\u52a8\u529b\u5b66\u53ef\u4f5c\u4e3a\u989d\u5916\u4fe1\u53f7\u7528\u4e8e\u7f51\u7edc\u6f14\u5316\u5386\u53f2\u63a8\u65ad\uff0c\u7a33\u6001\u4fe1\u53f7\u80fd\u72ec\u7acb\u7528\u4e8e\u6f14\u5316\u63a8\u65ad\u3002"}}
{"id": "2601.02123", "pdf": "https://arxiv.org/pdf/2601.02123", "abs": "https://arxiv.org/abs/2601.02123", "authors": ["Po-Jen Ko", "Chen-Han Tsai", "Yu-Shao Peng"], "title": "DeCode: Decoupling Content and Delivery for Medical QA", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\\%$ to $49.8\\%$, corresponding to a $75\\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.", "AI": {"tldr": "\u4ecb\u7ecd\u8bad\u7ec3\u65e0\u5173\u3001\u6a21\u578b\u65e0\u5173\u6846\u67b6DeCode\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e34\u5e8a\u95ee\u7b54\u6548\u679c\uff0c\u5728OpenAI HealthBench\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u95ee\u7b54\u4e2d\u672a\u8003\u8651\u60a3\u8005\u4e2a\u4f53\u60c5\u51b5\uff0c\u7b54\u6848\u4e0e\u60a3\u8005\u9700\u6c42\u4e0d\u5339\u914d\u3002", "method": "\u5f15\u5165\u8bad\u7ec3\u65e0\u5173\u3001\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6DeCode\uff0c\u5e76\u5728OpenAI HealthBench\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "DeCode\u5c06\u5148\u524d\u7684\u6700\u4f73\u6c34\u5e73\u4ece28.4%\u63d0\u9ad8\u523049.8%\uff0c\u76f8\u5bf9\u63d0\u534775%\u3002", "conclusion": "DeCode\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e34\u5e8a\u95ee\u7b54\u65b9\u9762\u6709\u6548\u3002"}}
{"id": "2601.02125", "pdf": "https://arxiv.org/pdf/2601.02125", "abs": "https://arxiv.org/abs/2601.02125", "authors": ["Zhuoxiong Xu", "Xuanchen Li", "Yuhao Cheng", "Fei Xu", "Yichao Yan", "Xiaokang Yang"], "title": "SingingBot: An Avatar-Driven System for Robotic Face Singing Performance", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u673a\u5668\u4eba\u5531\u6b4c\u7684\u5934\u50cf\u9a71\u52a8\u6846\u67b6\uff0c\u80fd\u5b9e\u73b0\u4e30\u5bcc\u60c5\u611f\u8868\u8fbe\u4e14\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u9762\u90e8\u9a71\u52a8\u7814\u7a76\u96be\u4ee5\u6ee1\u8db3\u5531\u6b4c\u65f6\u8fde\u7eed\u60c5\u611f\u8868\u8fbe\u548c\u8fde\u8d2f\u6027\u7684\u9ad8\u8981\u6c42\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u4f7f\u673a\u5668\u4eba\u9762\u90e8\u5177\u5907\u5531\u6b4c\u80fd\u529b\u4ee5\u5b9e\u73b0\u79fb\u60c5\u5f0f\u4eba\u673a\u4ea4\u4e92\u3002", "method": "\u5148\u5229\u7528\u542b\u4eba\u7c7b\u5148\u9a8c\u77e5\u8bc6\u7684\u8096\u50cf\u89c6\u9891\u751f\u6210\u6a21\u578b\u5408\u6210\u751f\u52a8\u7684\u5531\u6b4c\u5934\u50cf\uff0c\u518d\u901a\u8fc7\u8de8\u5e7f\u6cdb\u8868\u60c5\u7a7a\u95f4\u7684\u8bed\u4e49\u6620\u5c04\u51fd\u6570\u5c06\u9762\u90e8\u7279\u5f81\u8f6c\u79fb\u5230\u673a\u5668\u4eba\u4e0a\uff0c\u8fd8\u63d0\u51fa\u60c5\u611f\u52a8\u6001\u8303\u56f4\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4e30\u5bcc\u7684\u60c5\u611f\u8868\u8fbe\uff0c\u4fdd\u6301\u4e86\u5507\u97f3\u540c\u6b65\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u9896\u6846\u67b6\u6709\u6548\uff0c\u5e7f\u6cdb\u7684\u60c5\u611f\u5149\u8c31\u5bf9\u5f15\u4eba\u5165\u80dc\u7684\u8868\u6f14\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.02126", "pdf": "https://arxiv.org/pdf/2601.02126", "abs": "https://arxiv.org/abs/2601.02126", "authors": ["Xavier Bou", "Elliot Vincent", "Gabriele Facciolo", "Rafael Grompone von Gioi", "Jean-Michel Morel", "Thibaud Ehret"], "title": "Remote Sensing Change Detection via Weak Temporal Supervision", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u73b0\u6709\u5355\u65f6\u76f8\u6570\u636e\u96c6\u989d\u5916\u65f6\u95f4\u89c2\u6d4b\u7684\u5f31\u65f6\u95f4\u76d1\u7763\u7b56\u7565\u7528\u4e8e\u9065\u611f\u8bed\u4e49\u53d8\u5316\u68c0\u6d4b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u826f\u597d\u8868\u73b0\u4e14\u5177\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u9065\u611f\u8bed\u4e49\u53d8\u5316\u68c0\u6d4b\u53d7\u6807\u6ce8\u6570\u636e\u96c6\u7a00\u7f3a\u9650\u5236\uff0c\u8fd1\u671f\u65b9\u6cd5\u57df\u5916\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "method": "\u5229\u7528\u73b0\u6709\u5355\u65f6\u76f8\u6570\u636e\u96c6\u989d\u5916\u65f6\u95f4\u89c2\u6d4b\uff0c\u6269\u5c55\u6570\u636e\u96c6\uff0c\u5047\u8bbe\u771f\u5b9e\u53cc\u65f6\u76f8\u6570\u636e\u5927\u591a\u65e0\u53d8\u5316\uff0c\u914d\u5bf9\u4e0d\u540c\u4f4d\u7f6e\u56fe\u50cf\u751f\u6210\u53d8\u5316\u6837\u672c\uff1b\u91c7\u7528\u5bf9\u8c61\u611f\u77e5\u53d8\u5316\u56fe\u751f\u6210\u548c\u8fed\u4ee3\u7ec6\u5316\u5904\u7406\u5f31\u6807\u7b7e\u566a\u58f0\u3002", "result": "\u5728\u6269\u5c55\u7684FLAIR\u548cIAILD\u822a\u7a7a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u5f3a\u96f6\u6837\u672c\u548c\u4f4e\u6570\u636e\u5236\u5ea6\u6027\u80fd\uff0c\u5728\u6cd5\u56fd\u5927\u9762\u79ef\u533a\u57df\u5c55\u793a\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.02144", "pdf": "https://arxiv.org/pdf/2601.02144", "abs": "https://arxiv.org/abs/2601.02144", "authors": ["Boxuan Lyu", "Soichiro Murakami", "Hidetaka Kamigaito", "Peinan Zhang"], "title": "Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric \"router\" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.", "AI": {"tldr": "\u63d0\u51fakNN - MoE\u68c0\u7d22\u589e\u5f3a\u8def\u7531\u6846\u67b6\uff0c\u5229\u7528\u8bb0\u5fc6\u4e2d\u7c7b\u4f3c\u6848\u4f8b\u4f18\u5316\u4e13\u5bb6\u5206\u914d\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u826f\u597d\u3002", "motivation": "\u4f20\u7edfMoE\u67b6\u6784\u7684\u8def\u7531\u5668\u8bad\u7ec3\u540e\u51bb\u7ed3\uff0c\u5728\u5206\u5e03\u53d8\u5316\u65f6\u8def\u7531\u51b3\u7b56\u8106\u5f31\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u5165kNN - MoE\u6846\u67b6\uff0c\u79bb\u7ebf\u6784\u5efa\u8bb0\u5fc6\uff0c\u5229\u7528\u68c0\u7d22\u90bb\u5c45\u7684\u805a\u5408\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u6df7\u5408\u7cfb\u6570\uff0c\u65e0\u76f8\u5173\u6848\u4f8b\u65f6\u56de\u9000\u5230\u51bb\u7ed3\u8def\u7531\u5668\u3002", "result": "kNN - MoE\u4f18\u4e8e\u96f6\u6837\u672c\u57fa\u7ebf\uff0c\u4e0e\u8ba1\u7b97\u6602\u8d35\u7684\u6709\u76d1\u7763\u5fae\u8c03\u6548\u679c\u76f8\u5f53\u3002", "conclusion": "kNN - MoE\u80fd\u6709\u6548\u89e3\u51b3\u4f20\u7edfMoE\u67b6\u6784\u5728\u5206\u5e03\u53d8\u5316\u65f6\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.02147", "pdf": "https://arxiv.org/pdf/2601.02147", "abs": "https://arxiv.org/abs/2601.02147", "authors": ["Sunny Gupta", "Shounak Das", "Amit Sethi"], "title": "BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted at the AAAI 2026 Workshop AIR-FM, Assessing and Improving Reliability of Foundation Models in the Real World", "summary": "Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u8fb9\u63d0\u793a\u4f18\u5316\u6846\u67b6BiPrompt\u7528\u4e8e\u7f13\u89e3\u89c6\u89c9\u8bed\u8a00\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u865a\u5047\u5173\u8054\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u53bb\u504f\u65b9\u6cd5\u4ec5\u5904\u7406\u5355\u4e00\u6a21\u6001\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u4e0d\u8db3\u548c\u5206\u5e03\u504f\u79fb\u4e0b\u9002\u5e94\u4e0d\u7a33\u5b9a\uff0c\u800c\u89c6\u89c9\u8bed\u8a00\u57fa\u7840\u6a21\u578b\u6613\u53d7\u89c6\u89c9\u548c\u6587\u672c\u6a21\u6001\u865a\u5047\u5173\u8054\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u53cc\u8fb9\u63d0\u793a\u4f18\u5316\u6846\u67b6BiPrompt\uff0c\u89c6\u89c9\u4e0a\u7528\u7ed3\u6784\u5316\u6ce8\u610f\u529b\u5f15\u5bfc\u64e6\u9664\uff0c\u6587\u672c\u4e0a\u5f15\u5165\u5e73\u8861\u63d0\u793a\u5f52\u4e00\u5316\uff0c\u4e24\u8005\u5171\u540c\u6700\u5c0f\u5316\u865a\u5047\u7ebf\u7d22\u548c\u9884\u6d4b\u4e4b\u95f4\u7684\u6761\u4ef6\u4e92\u4fe1\u606f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u504f\u89c1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u548c\u6700\u5dee\u7ec4\u51c6\u786e\u7387\u5747\u6bd4\u5148\u524d\u6d4b\u8bd5\u65f6\u53bb\u504f\u65b9\u6cd5\u6709\u4e00\u81f4\u63d0\u5347\u3002", "conclusion": "BiPrompt\u4e3a\u89c6\u89c9\u8bed\u8a00\u9002\u5e94\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u4e14\u6709\u6548\u7684\u9014\u5f84\uff0c\u53ef\u5b9e\u73b0\u53ef\u4fe1\u548c\u56e0\u679c\u57fa\u7840\u4e0a\u7684\u89c6\u89c9\u8bed\u8a00\u9002\u5e94\u3002"}}
{"id": "2601.02149", "pdf": "https://arxiv.org/pdf/2601.02149", "abs": "https://arxiv.org/abs/2601.02149", "authors": ["Mateusz Krawczyk", "Jaros\u0142aw Paw\u0142owski"], "title": "AI-enhanced tuning of quantum dot Hamiltonians toward Majorana modes", "categories": ["cond-mat.mes-hall", "cond-mat.dis-nn", "cs.AI"], "comment": "main file: 8 pages, 6 figures; supplementary: 3 pages, 2 figures", "summary": "We propose a neural network-based model capable of learning the broad landscape of working regimes in quantum dot simulators, and using this knowledge to autotune these devices - based on transport measurements - toward obtaining Majorana modes in the structure. The model is trained in an unsupervised manner on synthetic data in the form of conductance maps, using a physics-informed loss that incorporates key properties of Majorana zero modes. We show that, with appropriate training, a deep vision-transformer network can efficiently memorize relation between Hamiltonian parameters and structures on conductance maps and use it to propose parameters update for a quantum dot chain that drive the system toward topological phase. Starting from a broad range of initial detunings in parameter space, a single update step is sufficient to generate nontrivial zero modes. Moreover, by enabling an iterative tuning procedure - where the system acquires updated conductance maps at each step - we demonstrate that the method can address a much larger region of the parameter space.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u81ea\u52a8\u8c03\u8c10\u91cf\u5b50\u70b9\u6a21\u62df\u5668\u4ee5\u83b7\u53d6\u9a6c\u7ea6\u62c9\u7eb3\u6a21\u5f0f\u3002", "motivation": "\u5bfb\u6c42\u81ea\u52a8\u8c03\u8c10\u91cf\u5b50\u70b9\u6a21\u62df\u5668\u83b7\u53d6\u9a6c\u7ea6\u62c9\u7eb3\u6a21\u5f0f\u7684\u65b9\u6cd5\u3002", "method": "\u4ee5\u7535\u5bfc\u56fe\u5408\u6210\u6570\u636e\u5bf9\u57fa\u4e8e\u6df1\u5ea6\u89c6\u89c9\u8f6c\u6362\u5668\u7684\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u65e0\u76d1\u7763\u8bad\u7ec3\uff0c\u4f7f\u7528\u7ed3\u5408\u9a6c\u7ea6\u62c9\u7eb3\u96f6\u6a21\u5173\u952e\u7279\u6027\u7684\u7269\u7406\u4fe1\u606f\u635f\u5931\u3002", "result": "\u5355\u6b65\u66f4\u65b0\u53ef\u751f\u6210\u975e\u5e73\u51e1\u96f6\u6a21\uff0c\u8fed\u4ee3\u8c03\u8c10\u53ef\u5904\u7406\u66f4\u5927\u53c2\u6570\u7a7a\u95f4\u533a\u57df\u3002", "conclusion": "\u8be5\u6a21\u578b\u80fd\u591f\u5b66\u4e60\u91cf\u5b50\u70b9\u6a21\u62df\u5668\u5de5\u4f5c\u6a21\u5f0f\uff0c\u901a\u8fc7\u81ea\u52a8\u8c03\u8c10\u9a71\u52a8\u7cfb\u7edf\u8fdb\u5165\u62d3\u6251\u76f8\u3002"}}
{"id": "2601.02151", "pdf": "https://arxiv.org/pdf/2601.02151", "abs": "https://arxiv.org/abs/2601.02151", "authors": ["Muxi Diao", "Lele Yang", "Wuxuan Gong", "Yutong Zhang", "Zhonghao Yan", "Yufei Han", "Kongming Liang", "Weiran Xu", "Zhanyu Ma"], "title": "Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\uff0c\u800c\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u80fd\u4fdd\u7559\u901a\u7528\u80fd\u529b\uff0c\u5256\u6790\u5206\u5e03\u5dee\u5f02\u540e\u63d0\u51fa\u71b5\u81ea\u9002\u5e94\u5fae\u8c03\uff08EAFT\uff09\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5728\u9886\u57df\u9002\u5e94\u65f6\u7ecf\u5e38\u4ea7\u751f\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u5bf9\u6bd4\u5176\u4e0e\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u5728\u4fdd\u7559\u901a\u7528\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u71b5\u81ea\u9002\u5e94\u5fae\u8c03\uff08EAFT\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u57fa\u4e8etoken\u7ea7\u522b\u7684\u71b5\u4f5c\u4e3a\u95e8\u63a7\u673a\u5236\uff0c\u533a\u5206\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u77e5\u8bc6\u51b2\u7a81\u3002", "result": "\u5728Qwen\u548cGLM\u7cfb\u5217\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEAFT\u5728\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u4e0e\u6807\u51c6SFT\u76f8\u5f53\uff0c\u4e14\u663e\u8457\u51cf\u8f7b\u901a\u7528\u80fd\u529b\u7684\u9000\u5316\u3002", "conclusion": "EAFT\u80fd\u6709\u6548\u89e3\u51b3SFT\u5728\u9886\u57df\u9002\u5e94\u65f6\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u8fbe\u5230\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u4fdd\u7559\u6a21\u578b\u7684\u901a\u7528\u80fd\u529b\u3002"}}
{"id": "2601.02158", "pdf": "https://arxiv.org/pdf/2601.02158", "abs": "https://arxiv.org/abs/2601.02158", "authors": ["Almaz Ermilov"], "title": "FormationEval, an open multiple-choice benchmark for petroleum geoscience", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.geo-ph"], "comment": "24 pages, 8 figures, 10 tables; benchmark and code at https://github.com/AlmazErmilov/FormationEval-an-Open-Benchmark-for-Oil-Gas-Geoscience-MCQ-Evaluation", "summary": "This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\\% accuracy, with Gemini 3 Pro Preview reaching 99.8\\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.", "AI": {"tldr": "\u63d0\u51faFormationEval\u57fa\u51c6\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u77f3\u6cb9\u5730\u8d28\u79d1\u5b66\u548c\u5730\u4e0b\u5b66\u79d1\u7684\u8868\u73b0\uff0c\u6db5\u76d672\u4e2a\u6a21\u578b\uff0c\u516c\u5f00\u57fa\u51c6\u3001\u4ee3\u7801\u548c\u7ed3\u679c\u3002", "motivation": "\u7f3a\u4e4f\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u77f3\u6cb9\u5730\u8d28\u79d1\u5b66\u548c\u5730\u4e0b\u5b66\u79d1\u8868\u73b0\u7684\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u5305\u542b505\u4e2a\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u6e90\u81ea\u4e09\u4e2a\u6743\u5a01\u6765\u6e90\uff0c\u91c7\u7528\u63a8\u7406\u6a21\u578b\u548c\u57fa\u4e8e\u6982\u5ff5\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f3072\u4e2a\u6a21\u578b\u3002", "result": "\u9876\u7ea7\u6a21\u578b\u51c6\u786e\u7387\u8d8597%\uff0cGemini 3 Pro Preview\u8fbe99.8%\uff1b\u5f00\u653e\u6743\u91cd\u6a21\u578b\u4e0e\u95ed\u6e90\u6a21\u578b\u5dee\u8ddd\u5c0f\u4e8e\u9884\u671f\uff1b\u5ca9\u77f3\u7269\u7406\u5b66\u662f\u6700\u5177\u6311\u6218\u7684\u9886\u57df\u3002", "conclusion": "FormationEval\u53ef\u6709\u6548\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u76f8\u5173\u9886\u57df\u7684\u8868\u73b0\uff0c\u516c\u5f00\u8d44\u6e90\u4fbf\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.02204", "pdf": "https://arxiv.org/pdf/2601.02204", "abs": "https://arxiv.org/abs/2601.02204", "authors": ["Huichao Zhang", "Liao Qu", "Yiheng Liu", "Hang Chen", "Yangyang Song", "Yongsheng Dong", "Shikun Sun", "Xian Li", "Xu Wang", "Yi Jiang", "Hu Ye", "Bo Chen", "Yiming Gao", "Peng Liu", "Akide Liu", "Zhipeng Yang", "Qili Deng", "Linjie Xing", "Jiyang Liu", "Zhao Wang", "Yang Zhou", "Mingcong Liu", "Yi Zhang", "Qian He", "Xiwei Hu", "Zhongqi Qi", "Jie Shao", "Zhiye Fu", "Shuai Wang", "Fangmin Chen", "Xuezhi Chai", "Zhihua Wu", "Yitong Wang", "Zehuan Yuan", "Daniel K. Du", "Xinglong Wu"], "title": "NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://github.com/ByteVisionLab/NextFlow", "summary": "We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.", "AI": {"tldr": "\u4ecb\u7ecdNextFlow\uff0c\u4e00\u79cd\u57286\u4e07\u4ebf\u4ea4\u9519\u6587\u672c - \u56fe\u50cf\u79bb\u6563\u6807\u8bb0\u4e0a\u8bad\u7ec3\u7684\u7edf\u4e00\u89e3\u7801\u5668\u81ea\u56de\u5f52Transformer\uff0c\u6709\u591a\u79cd\u80fd\u529b\u4e14\u901f\u5ea6\u5feb\u3001\u6027\u80fd\u4f18\u3002", "motivation": "\u9274\u4e8e\u6587\u672c\u4e25\u683c\u987a\u5e8f\u6027\u548c\u56fe\u50cf\u56fa\u6709\u5c42\u6b21\u7ed3\u6784\u7684\u4e0d\u540c\u6a21\u6001\u7279\u6027\uff0c\u6539\u8fdb\u4f20\u7edf\u65b9\u6cd5\u3002", "method": "\u5728\u7edf\u4e00\u81ea\u56de\u5f52\u67b6\u6784\u4e2d\u5229\u7528\u7edf\u4e00\u89c6\u89c9\u8868\u5f81\uff0c\u6587\u672c\u7528\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\uff0c\u89c6\u89c9\u751f\u6210\u91c7\u7528\u4e0b\u4e00\u4e2a\u5c3a\u5ea6\u9884\u6d4b\uff0c\u7528\u7a33\u5065\u8bad\u7ec3\u65b9\u6cd5\u89e3\u51b3\u591a\u5c3a\u5ea6\u751f\u6210\u4e0d\u7a33\u5b9a\u6027\uff0c\u5f15\u5165\u524d\u7f00\u8c03\u4f18\u7b56\u7565\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u80fd\u57285\u79d2\u5185\u751f\u62101024x1024\u56fe\u50cf\uff0c\u6bd4\u540c\u7c7bAR\u6a21\u578b\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u7edf\u4e00\u6a21\u578b\u4e2d\u8fbeSOTA\uff0c\u89c6\u89c9\u8d28\u91cf\u4e0e\u4e13\u4e1a\u6269\u6563\u57fa\u7ebf\u76f8\u5f53\u3002", "conclusion": "NextFlow\u5728\u7edf\u4e00\u6a21\u578b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5f88\u5f3a\u7684\u591a\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u3002"}}
{"id": "2601.02206", "pdf": "https://arxiv.org/pdf/2601.02206", "abs": "https://arxiv.org/abs/2601.02206", "authors": ["Dachun Kai", "Zeyu Xiao", "Huyue Zhu", "Jiaxiao Wang", "Yueyi Zhang", "Xiaoyan Sun"], "title": "Seeing the Unseen: Zooming in the Dark with Event Cameras", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to AAAI 2026", "summary": "This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.", "AI": {"tldr": "\u63d0\u51faRetinexEVSR\u6846\u67b6\u7528\u4e8e\u4f4e\u5149\u7167\u89c6\u9891\u8d85\u5206\u8fa8\u7387\uff0c\u91c7\u7528\u53cc\u5411\u8de8\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u5b9e\u9a8c\u6548\u679c\u8fbeSOTA\u3002", "motivation": "\u73b0\u6709\u4f4e\u5149\u7167\u89c6\u9891\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u56e0\u5bf9\u6bd4\u5ea6\u548c\u9ad8\u9891\u4fe1\u606f\u6709\u9650\uff0c\u96be\u4ee5\u6062\u590d\u7cbe\u7ec6\u7ec6\u8282\u3002", "method": "\u63d0\u51faRetinexEVSR\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5411\u8de8\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u8bbe\u8ba1\u7167\u660e\u5f15\u5bfc\u4e8b\u4ef6\u589e\u5f3a\u6a21\u5757\u548c\u4e8b\u4ef6\u5f15\u5bfc\u53cd\u5c04\u589e\u5f3a\u6a21\u5757\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\uff0c\u5728SDSD\u57fa\u51c6\u4e0a\u76f8\u6bd4\u5148\u524d\u57fa\u4e8e\u4e8b\u4ef6\u7684\u65b9\u6cd5\uff0c\u53ef\u63d0\u53472.95dB\u4e14\u51cf\u5c1165%\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "RetinexEVSR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4f4e\u5149\u7167\u89c6\u9891\u8d85\u5206\u8fa8\u7387\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u8d8a\u3002"}}
{"id": "2601.02242", "pdf": "https://arxiv.org/pdf/2601.02242", "abs": "https://arxiv.org/abs/2601.02242", "authors": ["Grigorii Alekseenko", "Aleksandr Gordeev", "Irina Tolstykh", "Bulat Suleimanov", "Vladimir Dokholyan", "Georgii Fedorov", "Sergey Yakubson", "Aleksandra Tsybina", "Mikhail Chernyshov", "Maksim Kuprashevich"], "title": "VIBE: Visual Instruction Based Editor", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4f4e\u6210\u672c\u63a8\u7406\u7684\u6307\u4ee4\u56fe\u50cf\u7f16\u8f91\u7ba1\u9053\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u5728\u77ed\u65f6\u95f4\u5185\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u6307\u4ee4\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u8fbe\u5230\u5b9e\u9645\u5e94\u7528\u8d28\u91cf\u7684\u8f83\u5c11\uff0c\u4e14\u6269\u6563\u4e3b\u5e72\u6a21\u578b\u53c2\u6570\u5927\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u4f7f\u75282B\u53c2\u6570\u7684Qwen3 - VL\u6a21\u578b\u6307\u5bfc\u7f16\u8f91\u8fc7\u7a0b\uff0c1.6B\u53c2\u6570\u7684Sana1.5\u6269\u6563\u6a21\u578b\u8fdb\u884c\u56fe\u50cf\u751f\u6210\uff0c\u5728\u67b6\u6784\u3001\u6570\u636e\u5904\u7406\u3001\u8bad\u7ec3\u548c\u8bc4\u4f30\u7b49\u65b9\u9762\u505a\u8bbe\u8ba1\u51b3\u7b56\u4ee5\u5b9e\u73b0\u4f4e\u6210\u672c\u63a8\u7406\u548c\u6e90\u4e00\u81f4\u6027\u3002", "result": "\u5728ImgEdit\u548cGEdit\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u91cd\u57fa\u7ebf\u6a21\u578b\uff0c\u5c24\u5176\u5728\u9700\u4fdd\u7559\u8f93\u5165\u56fe\u50cf\u7684\u7f16\u8f91\u4efb\u52a1\u4e0a\u4f18\u52bf\u660e\u663e\uff0c\u80fd\u572824GB GPU\u5185\u5b58\u4e0b\uff0c\u7ea64\u79d2\u751f\u62102K\u5206\u8fa8\u7387\u7f16\u8f91\u56fe\u50cf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7d27\u51d1\u3001\u9ad8\u901a\u91cf\u6307\u4ee4\u56fe\u50cf\u7f16\u8f91\u7ba1\u9053\u80fd\u5728\u4fdd\u8bc1\u9ad8\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4f4e\u6210\u672c\u63a8\u7406\u3002"}}
{"id": "2601.02246", "pdf": "https://arxiv.org/pdf/2601.02246", "abs": "https://arxiv.org/abs/2601.02246", "authors": ["Annoor Sharara Akhand"], "title": "A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8bad\u7ec3\u81ea\u5b9a\u4e49CNN\u3001\u7528\u9884\u8bad\u7ec3CNN\u4f5c\u7279\u5f81\u63d0\u53d6\u5668\u548c\u8fc1\u79fb\u5b66\u4e60\u4e09\u79cd\u89c6\u89c9\u8bc6\u522b\u8303\u5f0f\u5728\u4e94\u4e2a\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\uff0c\u7ed3\u679c\u663e\u793a\u8fc1\u79fb\u5b66\u4e60\u9884\u6d4b\u6027\u80fd\u5f3a\uff0c\u81ea\u5b9a\u4e49CNN\u5728\u8d44\u6e90\u53d7\u9650\u65f6\u6709\u6709\u6548\u7387\u4e0e\u51c6\u786e\u7387\u7684\u6743\u8861\u4f18\u52bf\u3002", "motivation": "\u5bf9\u5904\u7406\u89c6\u89c9\u8bc6\u522b\u7684\u4e09\u79cd\u5e38\u7528\u8303\u5f0f\u8fdb\u884c\u5bf9\u6bd4\uff0c\u4e3a\u5b9e\u8df5\u8005\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u9009\u62e9\u5408\u9002\u65b9\u6cd5\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u4e09\u79cd\u8303\u5f0f\uff0c\u7528\u51c6\u786e\u7387\u3001\u5b8fF1\u5206\u6570\u8bc4\u4f30\u6a21\u578b\uff0c\u8f85\u4ee5\u6bcf\u8f6e\u8bad\u7ec3\u65f6\u95f4\u548c\u53c2\u6570\u6570\u91cf\u7b49\u6548\u7387\u6307\u6807\u3002", "result": "\u8fc1\u79fb\u5b66\u4e60\u59cb\u7ec8\u6709\u6700\u5f3a\u9884\u6d4b\u6027\u80fd\uff0c\u81ea\u5b9a\u4e49CNN\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u9884\u7b97\u53d7\u9650\u65f6\u6709\u8f83\u597d\u7684\u6548\u7387 - \u51c6\u786e\u7387\u6743\u8861\u3002", "conclusion": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u53ef\u6839\u636e\u8ba1\u7b97\u8d44\u6e90\u548c\u6027\u80fd\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684CNN\u4f7f\u7528\u8303\u5f0f\u3002"}}
{"id": "2601.02273", "pdf": "https://arxiv.org/pdf/2601.02273", "abs": "https://arxiv.org/abs/2601.02273", "authors": ["Salim Khazem"], "title": "TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \\textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \\textbf{5.2\\%} of model parameters ($\\sim$4.9M). On the challenging CHASE\\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git", "AI": {"tldr": "\u63d0\u51faTopoLoRA - SAM\u7528\u4e8e\u4e8c\u503c\u8bed\u4e49\u5206\u5272\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u597d\uff0c\u4ec5\u8bad\u7ec3\u5c11\u91cf\u53c2\u6570\u3002", "motivation": "\u57fa\u7840\u5206\u5272\u6a21\u578b\u9002\u5e94\u7279\u5b9a\u9886\u57df\u8bed\u4e49\u5206\u5272\u6709\u6311\u6218\uff0c\u5168\u91cf\u5fae\u8c03\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6709\u707e\u96be\u6027\u9057\u5fd8\u98ce\u9669\u3002", "method": "\u63d0\u51faTopoLoRA - SAM\u6846\u67b6\uff0c\u5c06LoRA\u6ce8\u5165\u51bb\u7ed3\u7684ViT\u7f16\u7801\u5668\uff0c\u589e\u52a0\u8f7b\u91cf\u7ea7\u7a7a\u95f4\u5377\u79ef\u9002\u914d\u5668\u548c\u53ef\u9009\u7684\u62d3\u6251\u611f\u77e5\u76d1\u7763\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTopoLoRA - SAM\u53d6\u5f97\u6700\u4f73\u89c6\u7f51\u819c\u5e73\u5747Dice\u548c\u6574\u4f53\u5e73\u5747Dice\uff0c\u5728CHASE_DB1\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e86\u5206\u5272\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u62d3\u6251\u611f\u77e5\u7684\u53c2\u6570\u9ad8\u6548\u9002\u914d\u65b9\u6cd5\u53ef\u5ab2\u7f8e\u6216\u8d85\u8d8a\u5168\u91cf\u5fae\u8c03\u7684\u4e13\u4e1a\u6a21\u578b\u3002"}}
{"id": "2601.02285", "pdf": "https://arxiv.org/pdf/2601.02285", "abs": "https://arxiv.org/abs/2601.02285", "authors": ["Tobias Schimanski", "Imene Kolli", "Jingwei Ni", "Yu Fan", "Ario Saeid Vaghefi", "Elliott Ash", "Markus Leippold"], "title": "pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).", "AI": {"tldr": "\u63d0\u51fapdfQA\u6570\u636e\u96c6\uff0c\u542b\u591a\u9886\u57df2K\u4eba\u5de5\u6807\u6ce8\u548c2K\u5408\u6210\u6570\u636e\uff0c\u7ecf\u7b5b\u9009\u540e\u7528\u5f00\u6e90\u5927\u6a21\u578b\u56de\u7b54\uff0c\u4e3a\u7aef\u5230\u7aef\u95ee\u7b54\u8bc4\u4f30\u5960\u57fa\u3002", "motivation": "\u73b0\u6709\u95ee\u7b54\u6570\u636e\u96c6\u591a\u6e90\u4e8e\u6587\u672c\u6216\u9488\u5bf9\u7279\u5b9a\u9886\u57df\uff0c\u800cPDF\u662f\u4e92\u8054\u7f51\u5e38\u7528\u6587\u6863\u683c\u5f0f\u3002", "method": "\u521b\u5efapdfQA\u6570\u636e\u96c6\uff0c\u5728\u4e24\u4e2a\u5b50\u6570\u636e\u96c6\u5e94\u7528\u5e76\u8bc4\u4f30\u8d28\u91cf\u548c\u96be\u5ea6\u8fc7\u6ee4\u5668\uff0c\u7528\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u56de\u7b54\u95ee\u9898\u3002", "result": "\u83b7\u5f97\u6709\u6548\u4e14\u5177\u6311\u6218\u6027\u7684\u95ee\u7b54\u5bf9\uff0c\u53d1\u73b0\u4e0e\u590d\u6742\u5ea6\u7ef4\u5ea6\u76f8\u5173\u7684\u73b0\u6709\u6311\u6218\u3002", "conclusion": "pdfQA\u4e3a\u7aef\u5230\u7aef\u95ee\u7b54\u7ba1\u9053\u8bc4\u4f30\u63d0\u4f9b\u57fa\u7840\uff0c\u53ef\u6d4b\u8bd5\u591a\u79cd\u6280\u80fd\u548c\u5c40\u90e8\u4f18\u5316\u3002"}}
{"id": "2601.02316", "pdf": "https://arxiv.org/pdf/2601.02316", "abs": "https://arxiv.org/abs/2601.02316", "authors": ["Siddharth Joshi", "Haoli Yin", "Rishabh Adiga", "Ricardo Monti", "Aldo Carranza", "Alex Fang", "Alvin Deng", "Amro Abbas", "Brett Larsen", "Cody Blakeney", "Darren Teh", "David Schwab", "Fan Pan", "Haakon Mongstad", "Jack Urbanek", "Jason Lee", "Jason Telanoff", "Josh Wills", "Kaleigh Mentzer", "Luke Merrick", "Parth Doshi", "Paul Burstein", "Pratyush Maini", "Scott Loftin", "Spandan Das", "Tony Jiang", "Vineeth Dorna", "Zhengping Wang", "Bogdan Gaza", "Ari Morcos", "Matthew Leavitt"], "title": "DatBench: Discriminative, Faithful, and Efficient VLM Evaluations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u8bc4\u4f30\u65b9\u6cd5\u5c1a\u4e0d\u6210\u719f\uff0c\u63d0\u51fa\u8bc4\u4f30\u5e94\u6ee1\u8db3\u7684\u4e09\u4e2a\u8981\u6c42\uff0c\u8bc6\u522b\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u5931\u8d25\u6a21\u5f0f\uff0c\u901a\u8fc7\u6574\u7406\u73b0\u6709\u57fa\u51c6\u89e3\u51b3\u95ee\u9898\uff0c\u53d1\u5e03\u8bc4\u4f30\u5957\u4ef6\u5e76\u6307\u51faVLMs\u8bc4\u4f30\u5b9e\u8df5\u7684\u65b9\u5411\u3002", "motivation": "\u76ee\u524d\u8bad\u7ec3\u524d\u6cbf\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u4f5c\u591a\uff0c\u4f46\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u6210\u719f\uff0c\u9700\u8981\u5f15\u5bfc\u5176\u6210\u719f\u3002", "method": "\u63d0\u51fa\u8bc4\u4f30\u5e94\u6ee1\u8db3\u7684\u4e09\u4e2a\u8981\u6c42\uff0c\u8bc6\u522b\u5173\u952e\u5931\u8d25\u6a21\u5f0f\uff0c\u901a\u8fc7\u8f6c\u6362\u548c\u8fc7\u6ee4\u6574\u7406\u73b0\u6709\u57fa\u51c6\u3002", "result": "\u5c06\u9009\u62e9\u9898\u8f6c\u6362\u4e3a\u751f\u6210\u4efb\u52a1\u53ef\u63ed\u793a\u80fd\u529b\u4e0b\u964d\u8fbe35%\uff0c\u8fc7\u6ee4\u6837\u672c\u53ef\u63d0\u9ad8\u533a\u5206\u80fd\u529b\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u53d1\u5e03DatBench - Full\u548cDatBench\u8bc4\u4f30\u5957\u4ef6\u3002", "conclusion": "\u4e3aVLMs\u6301\u7eed\u6269\u5c55\u65f6\u7684\u4e25\u683c\u4e14\u53ef\u6301\u7eed\u7684\u8bc4\u4f30\u5b9e\u8df5\u6307\u660e\u4e86\u9053\u8def\u3002"}}
{"id": "2601.02357", "pdf": "https://arxiv.org/pdf/2601.02357", "abs": "https://arxiv.org/abs/2601.02357", "authors": ["Trey Brosnan"], "title": "DARC: Drum accompaniment generation with fine-grained rhythm control", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "In music creation, rapid prototyping is essential for exploring and refining ideas, yet existing generative tools often fall short when users require both structural control and stylistic flexibility. Prior approaches in stem-to-stem generation can condition on other musical stems but offer limited control over rhythm, and timbre-transfer methods allow users to specify specific rhythms, but cannot condition on musical context. We introduce DARC, a generative drum accompaniment model that conditions both on musical context from other stems and explicit rhythm prompts such as beatboxing or tapping tracks. Using parameter-efficient fine-tuning, we augment STAGE, a state-of-the-art drum stem generator, with fine-grained rhythm control while maintaining musical context awareness.", "AI": {"tldr": "\u73b0\u6709\u97f3\u4e50\u751f\u6210\u5de5\u5177\u5728\u7ed3\u6784\u63a7\u5236\u548c\u98ce\u683c\u7075\u6d3b\u6027\u4e0a\u4e0d\u8db3\uff0c\u672c\u6587\u5f15\u5165DARC\u6a21\u578b\uff0c\u589e\u5f3a\u5bf9\u9f13\u4f34\u594f\u7684\u8282\u594f\u63a7\u5236\u5e76\u4fdd\u6301\u97f3\u4e50\u4e0a\u4e0b\u6587\u611f\u77e5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u97f3\u4e50\u751f\u6210\u5de5\u5177\u5728\u7528\u6237\u8981\u6c42\u7ed3\u6784\u63a7\u5236\u548c\u98ce\u683c\u7075\u6d3b\u6027\u65f6\u7684\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u9f13\u4f34\u594f\u751f\u6210\u65b9\u9762\u3002", "method": "\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5728STAGE\u9f13\u5e72\u97f3\u751f\u6210\u5668\u57fa\u7840\u4e0a\u589e\u52a0\u7ec6\u7c92\u5ea6\u8282\u594f\u63a7\u5236\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba"}}
