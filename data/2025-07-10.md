<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 8]
- [cs.CE](#cs.CE) [Total: 2]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.IR](#cs.IR) [Total: 8]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.PF](#cs.PF) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [q-fin.TR](#q-fin.TR) [Total: 1]
- [stat.ML](#stat.ML) [Total: 7]
- [stat.CO](#stat.CO) [Total: 2]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [math.ST](#math.ST) [Total: 1]
- [eess.SP](#eess.SP) [Total: 3]
- [q-bio.PE](#q-bio.PE) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [eess.SY](#eess.SY) [Total: 4]
- [cs.HC](#cs.HC) [Total: 3]
- [math.OC](#math.OC) [Total: 2]
- [stat.ME](#stat.ME) [Total: 3]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [cs.CY](#cs.CY) [Total: 7]
- [cs.CL](#cs.CL) [Total: 23]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [q-fin.MF](#q-fin.MF) [Total: 1]
- [cs.CV](#cs.CV) [Total: 32]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SD](#cs.SD) [Total: 6]
- [cs.RO](#cs.RO) [Total: 5]
- [q-fin.GN](#q-fin.GN) [Total: 1]
- [stat.AP](#stat.AP) [Total: 2]
- [cs.CR](#cs.CR) [Total: 15]
- [physics.med-ph](#physics.med-ph) [Total: 2]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [econ.GN](#econ.GN) [Total: 2]
- [eess.IV](#eess.IV) [Total: 5]
- [eess.AS](#eess.AS) [Total: 1]
- [quant-ph](#quant-ph) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

Main category: cs.AI

TL;DR: 本文介绍了Medical Evacuation Wargaming Initiative (MEWI) 这一三维多人模拟系统，用于模拟战场医疗后送网络，通过两个场景测试，结果表明其能提升医疗后送知识吸收和合作决策能力，推动了医疗教育培训工具发展。


<details>
  <summary>Details</summary>
Motivation: 此前缺乏在课堂环境中模拟医疗后送网络、评估离线规划和在线决策性能的工具，需要开发新工具提升医疗后送教育和行动水平。

Method: 开发基于Unity的MEWI模拟系统，模拟战场约束和不确定性，设置两个作战场景，收集性能数据、学生Likert调查数据和外部观察笔记。

Result: 参与MEWI能显著提升医疗后送经验教训的吸收和合作决策能力。

Conclusion: MEWI是医疗教育高保真培训工具领域的重要进步，研究结果为改进联合部队医疗后送教育和行动提供关键见解。

Abstract: Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.

</details>


### [2] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

Main category: cs.AI

TL;DR: 现有大语言模型提示工程复杂，提出PDL方法解决此问题，并通过案例展示其效用。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型提示工程框架存在将复杂性隐藏在受限API后或提供缺乏定制性的模式等问题，使复杂代理编程具有挑战性。

Method: 提出Prompt Declaration Language (PDL)，将提示置于首位，实现手动和自动提示调整，捕捉大语言模型调用与基于规则的代码和外部工具的组合，抽象掉组合的底层细节。

Result: 通过合规代理的实际案例研究，调整该代理的提示模式比使用预制代理和提示模式性能提升达4倍。

Conclusion: PDL能解决大语言模型提示工程的复杂性问题，提高程序员生产力，其声明式表示便于优化。

Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either
hiding complexity behind restrictive APIs or providing inflexible canned
patterns that resist customization -- making sophisticated agentic programming
challenging. We present the Prompt Declaration Language (PDL), a novel approach
to prompt representation that tackles this fundamental complexity by bringing
prompts to the forefront, enabling manual and automatic prompt tuning while
capturing the composition of LLM calls together with rule-based code and
external tools. By abstracting away the plumbing for such compositions, PDL
aims at improving programmer productivity while providing a declarative
representation that is amenable to optimization. This paper demonstrates PDL's
utility through a real-world case study of a compliance agent. Tuning the
prompting pattern of this agent yielded up to 4x performance improvement
compared to using a canned agent and prompt pattern.

</details>


### [3] [Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI](https://arxiv.org/abs/2507.06398)
*David Orban*

Main category: cs.AI

TL;DR: 本文研究Jolting Technologies假设，开发理论框架和验证检测方法，为理解AI轨迹及AGI出现提供数学基础。


<details>
  <summary>Details</summary>
Motivation: 研究Jolting Technologies假设，该假设认为AI能力发展呈超指数增长。

Method: 开发理论框架，通过蒙特卡罗模拟验证检测方法。

Result: 为理解潜在AI轨迹及其对AGI出现的影响提供了数学基础。

Conclusion: 研究成果为未来实证研究提供了可靠工具，对研究和政策制定有一定启示。

Abstract: This paper investigates the Jolting Technologies Hypothesis, which posits
superexponential growth (increasing acceleration, or a positive third
derivative) in the development of AI capabilities. We develop a theoretical
framework and validate detection methodologies through Monte Carlo simulations,
while acknowledging that empirical validation awaits suitable longitudinal
data. Our analysis focuses on creating robust tools for future empirical
studies and exploring the potential implications should the hypothesis prove
valid. The study examines how factors such as shrinking idea-to-action
intervals and compounding iterative AI improvements drive this jolting pattern.
By formalizing jolt dynamics and validating detection methods through
simulation, this work provides the mathematical foundation necessary for
understanding potential AI trajectories and their consequences for AGI
emergence, offering insights for research and policy.

</details>


### [4] [Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)](https://arxiv.org/abs/2507.06798)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 本文介绍辩证系统，证明q - 辩证系统比p - 辩证系统强大，p - 辩证系统比(d -)辩证系统强大，凸显反例和矛盾在自动信念修正中的作用。


<details>
  <summary>Details</summary>
Motivation: 回答文献中关于辩证系统不同模型能力比较的开放性问题。

Method: 通过证明来比较q - 辩证系统、p - 辩证系统和(d -)辩证系统的能力。

Result: 证明了q - 辩证系统比p - 辩证系统严格强大，p - 辩证系统比(d -)辩证系统严格强大。

Conclusion: 反例和矛盾在自动信念修正以及数学家和研究团体的推理过程中起到互补作用。

Abstract: Dialectical systems are a mathematical formalism for modeling an agent
updating a knowledge base seeking consistency. Introduced in the 1970s by
Roberto Magari, they were originally conceived to capture how a working
mathematician or a research community refines beliefs in the pursuit of truth.
Dialectical systems also serve as natural models for the belief change of an
automated agent, offering a unifying, computable framework for dynamic belief
management.
  The literature distinguishes three main models of dialectical systems:
(d-)dialectical systems based on revising beliefs when they are seen to be
inconsistent, p-dialectical systems based on revising beliefs based on finding
a counterexample, and q-dialectical systems which can do both. We answer an
open problem in the literature by proving that q-dialectical systems are
strictly more powerful than p-dialectical systems, which are themselves known
to be strictly stronger than (d-)dialectical systems. This result highlights
the complementary roles of counterexample and contradiction in automated belief
revision, and thus also in the reasoning processes of mathematicians and
research communities.

</details>


### [5] [SCC-recursiveness in infinite argumentation (extended version)](https://arxiv.org/abs/2507.06852)
*Uri Andrews,Luca San Mauro*

Main category: cs.AI

TL;DR: 本文探讨将SCC - 递归性扩展到无限论证框架，评估新语义并得出部分成果，推动无限论证理论发展。


<details>
  <summary>Details</summary>
Motivation: 现有SCC - 递归语义在有限论证框架有效，但在无限论证框架中因良基性问题无法可靠泛化，需要解决此问题。

Method: 提出两种将SCC - 递归性扩展到无限情况的方法，用Baroni和Giacomin的既定标准系统评估这些语义。

Result: 方向性在一般情况下不成立，在有穷框架中部分语义满足方向性。

Conclusion: 研究推进了无限论证理论，为处理无界或演变领域的推理系统奠定基础。

Abstract: Argumentation frameworks (AFs) are a foundational tool in artificial
intelligence for modeling structured reasoning and conflict. SCC-recursiveness
is a well-known design principle in which the evaluation of arguments is
decomposed according to the strongly connected components (SCCs) of the attack
graph, proceeding recursively from "higher" to "lower" components. While
SCC-recursive semantics such as \cft and \stgt have proven effective for finite
AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to
generalize reliably to infinite AFs due to issues with well-foundedness.
  We propose two approaches to extending SCC-recursiveness to the infinite
setting. We systematically evaluate these semantics using Baroni and Giacomin's
established criteria, showing in particular that directionality fails in
general. We then examine these semantics' behavior in finitary frameworks,
where we find some of our semantics satisfy directionality. These results
advance the theory of infinite argumentation and lay the groundwork for
reasoning systems capable of handling unbounded or evolving domains.

</details>


### [6] [Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report](https://arxiv.org/abs/2507.06968)
*Li Du,Hanyu Zhao,Yiming Ju,Tengfei Pan*

Main category: cs.AI

TL;DR: 提出系统指令数据构建框架，构建InfinityInstruct - Subject数据集，实验证明其能提升模型指令跟随能力，为指令数据集从量到质的提升奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前指令数据集虽样本多，但模型在复杂指令遵循和罕见领域任务上表现不佳，原因是指令集在‘覆盖度’和‘深度’上扩展有限。

Method: 提出系统指令数据构建框架，集成分层标注系统、信息种子选择算法、进化数据合成过程和模型缺陷诊断与针对性数据生成，形成迭代闭环。

Result: 构建含约150万条指令的InfinityInstruct - Subject数据集，实验证明其能提升模型指令跟随能力，与可比合成指令数据集相比，覆盖度和深度更大。

Conclusion: 工作为指令数据集高效、持续进化，从数据量扩展到质量提升奠定理论和实践基础。

Abstract: Instruction tuning has become a foundation for unlocking the capabilities of
large-scale pretrained models and improving their performance on complex tasks.
Thus, the construction of high-quality instruction datasets is crucial for
enhancing model performance and generalizability. Although current instruction
datasets have reached tens of millions of samples, models finetuned on them may
still struggle with complex instruction following and tasks in rare domains.
This is primarily due to limited expansion in both ``coverage'' (coverage of
task types and knowledge areas) and ``depth'' (instruction complexity) of the
instruction set. To address this issue, we propose a systematic instruction
data construction framework, which integrates a hierarchical labeling system,
an informative seed selection algorithm, an evolutionary data synthesis
process, and a model deficiency diagnosis with targeted data generation. These
components form an iterative closed-loop to continuously enhance the coverage
and depth of instruction data. Based on this framework, we construct
InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million
instructions. Experiments on multiple foundation models and benchmark tasks
demonstrate its effectiveness in improving instruction-following capabilities.
Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage
and depth compared to comparable synthesized instruction datasets. Our work
lays a theoretical and practical foundation for the efficient, continuous
evolution of instruction datasets, moving from data quantity expansion to
qualitative improvement.

</details>


### [7] [The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](https://arxiv.org/abs/2507.06993)
*Jieren Deng,Aleksandar Cvetkovic,Pak Kiu Chung,Dragomir Yankov,Chiqun Zhang*

Main category: cs.AI

TL;DR: 传统旅行规划系统有缺陷，本文提出三个协作智能体，经评估系统在多方面有显著提升，有应用前景。


<details>
  <summary>Details</summary>
Motivation: 传统旅行规划系统静态且碎片化，无法应对现实复杂性，现有服务提供商存在智能规划、精准导航和动态行程调整的差距，用户体验差。

Method: 提出三个协作智能体，包括运用基于网格的空间定位和地图分析的旅行规划智能体、提供细粒度引导的目的地助手智能体、利用图像嵌入和检索增强生成技术的本地发现智能体。

Result: 系统在查询解释、导航准确性和行程中断恢复能力上有显著改善。

Conclusion: 系统有从城市探索到应急响应等多方面的应用前景。

Abstract: Traditional travel-planning systems are often static and fragmented, leaving
them ill-equipped to handle real-world complexities such as evolving
environmental conditions and unexpected itinerary disruptions. In this paper,
we identify three gaps between existing service providers causing frustrating
user experience: intelligent trip planning, precision "last-100-meter"
navigation, and dynamic itinerary adaptation. We propose three cooperative
agents: a Travel Planning Agent that employs grid-based spatial grounding and
map analysis to help resolve complex multi-modal user queries; a Destination
Assistant Agent that provides fine-grained guidance for the final navigation
leg of each journey; and a Local Discovery Agent that leverages image
embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to
trip plan disruptions. With evaluations and experiments, our system
demonstrates substantial improvements in query interpretation, navigation
accuracy, and disruption resilience, underscoring its promise for applications
from urban exploration to emergency response.

</details>


### [8] [First Return, Entropy-Eliciting Explore](https://arxiv.org/abs/2507.07017)
*Tianyu Zheng,Tianshun Xing,Qingshui Gu,Taoran Liang,Xingwei Qu,Xin Zhou,Yizhi Li,Zhoufutu Wen,Chenghua Lin,Wenhao Huang,Qian Liu,Ge Zhang,Zejun Ma*

Main category: cs.AI

TL;DR: 提出FR3E框架解决RLVR探索不稳定问题，在数学推理基准测试中有效


<details>
  <summary>Details</summary>
Motivation: RLVR在提升大语言模型推理能力时存在探索不稳定问题

Method: 提出FR3E结构化探索框架，识别推理轨迹中高不确定性决策点并进行针对性回滚以构建语义基础的中间反馈

Result: 在数学推理基准测试AIME24上，FR3E促进更稳定训练，生成更长且更连贯的回复，增加完全正确轨迹比例

Conclusion: FR3E框架通过更强大和结构化的探索有效提升大语言模型推理能力

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning
abilities of Large Language Models (LLMs) but it struggles with unstable
exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a
structured exploration framework that identifies high-uncertainty decision
points in reasoning trajectories and performs targeted rollouts to construct
semantically grounded intermediate feedback. Our method provides targeted
guidance without relying on dense supervision. Empirical results on
mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable
training, produces longer and more coherent responses, and increases the
proportion of fully correct trajectories. These results highlight the
framework's effectiveness in improving LLM reasoning through more robust and
structured exploration.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [9] [Development and Real-World Application of Commercial Motor Vehicle Safety Enforcement Dashboards](https://arxiv.org/abs/2507.06351)
*Dhairya Parekh,Mark L. Franz Ph. D,Sara Zahedian Ph. D,Narjes Shayesteh*

Main category: cs.CE

TL;DR: 本文介绍了商用机动车（CMV）仪表盘的开发与应用，用于分析CMV安全性能，评估执法影响，结果显示需更精细的罚单数据。


<details>
  <summary>Details</summary>
Motivation: CMV引发众多交通事故，监测其安全和安全检查对确保公路安全高效通行至关重要，需开发工具进行CMV安全性能分析。

Method: 在相关部门专业人员指导下开发CMV仪表盘，基于CMV探测车速度、检查/罚单数据等进行分析，选定路段评估执法影响。

Result: 执法后评估结果不一。

Conclusion: 需要更精细的罚单数据。

Abstract: Commercial Motor Vehicle (CMV) safety is crucial in traffic management and
public safety. CMVs account for numerous traffic incidents, so monitoring CMV
safety and safety inspections is essential for ensuring safe and efficient
highway movement. This paper presents the development and real-world
application of CMV dashboards designed under the guidance of CMV safety
enforcement professionals from the Maryland State Police (MSP), the Maryland
Department of Transportation - State Highway Administration (MDOT - SHA), and
the Federal Motor Carrier Safety Administration (FMCSA) to enable intuitive and
efficient analysis of CMV safety performance measures. First, three CMV safety
dashboards enable CMV safety professionals to identify sites with a history of
safety performance issues. A supplemental dashboard automates the analysis of
CMV enforcement initiatives using the same performance measures. These
performance measures are based on CMV probe vehicle speeds, inspection/citation
data from Truck Weigh and Inspection Stations (TWIS), patrolling enforcement,
and Virtual Weigh Stations (VWS). The authors collaborated with MSP to identify
a portion of I-81 in Maryland, susceptible to improvement from targeted CMV
enforcement. The supplemental enforcement assessment dashboard was employed to
evaluate the impact of enforcement, including the post-enforcement halo effect.
The results of the post-enforcement evaluation were mixed, indicating a need
for more fine-grained citation data.

</details>


### [10] [Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation](https://arxiv.org/abs/2507.06444)
*Jiaxun Zhang,Haicheng Liao,Yumu Xie,Chengyue Wang,Yanchen Guan,Bin Rao,Zhenning Li*

Main category: cs.CE

TL;DR: 提出多模态框架CAMERA用于事故预测，在基准测试中表现出色，证明了多因素建模的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有预测模型对驾驶员认知和动态路况表征不足，导致准确的事故预测具有挑战性。

Method: 提出CAMERA框架，集成行车记录仪视频、文本注释和驾驶员注意力图；采用由场景复杂性和注视熵引导的自适应机制；使用带Bi - GRU的分层融合管道捕捉时空依赖；通过地理上下文视觉语言模块生成人类可解释的警报。

Result: 在DADA - 2000等基准测试中，CAMERA达到了最先进的性能，提高了准确性和预警时间。

Conclusion: 对驾驶员注意力、上下文描述和自适应风险阈值进行建模，能实现更可靠的事故预测。

Abstract: Accurate accident anticipation remains challenging when driver cognition and
dynamic road conditions are underrepresented in predictive models. In this
paper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk
Anticipation), a multi-modal framework integrating dashcam video, textual
annotations, and driver attention maps for robust accident anticipation. Unlike
existing methods that rely on static or environment-centric thresholds, CAMERA
employs an adaptive mechanism guided by scene complexity and gaze entropy,
reducing false alarms while maintaining high recall in dynamic, multi-agent
traffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional
GRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language
module translates 3D spatial relationships into interpretable, human-centric
alerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves
state-of-the-art performance, improving accuracy and lead time. These results
demonstrate the effectiveness of modeling driver attention, contextual
description, and adaptive risk thresholds to enable more reliable accident
anticipation.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [11] [Interactive Text-to-SQL via Expected Information Gain for Disambiguation](https://arxiv.org/abs/2507.06467)
*Luyu Qiu,Jianing Li,Chi Su,Lei Chen*

Main category: cs.DB

TL;DR: 文本介绍了关系型数据库访问需SQL技能，现有Text - to - SQL系统处理复杂数据库有歧义问题，提出交互式框架解决。


<details>
  <summary>Details</summary>
Motivation: 现有Text - to - SQL系统处理复杂数据库时，因自然语言查询的歧义问题而受限，需要解决该问题。

Method: 提出交互式Text - to - SQL框架，将SQL生成建模为对多个候选查询的概率推理过程，通过用户交互解决不确定性，采用基于期望信息增益的决策标准。

Result: 未提及具体结果。

Conclusion: 未提及具体结论。

Abstract: Relational databases are foundational to numerous domains, including business
intelligence, scientific research, and enterprise systems. However, accessing
and analyzing structured data often requires proficiency in SQL, which is a
skill that many end users lack. With the development of Natural Language
Processing (NLP) technology, the Text-to-SQL systems attempt to bridge this gap
by translating natural language questions into executable SQL queries via an
automated algorithm. Yet, when operating on complex real-world databases, the
Text-to-SQL systems often suffer from ambiguity due to natural ambiguity in
natural language queries. These ambiguities pose a significant challenge for
existing Text-to-SQL translation systems, which tend to commit early to a
potentially incorrect interpretation. To address this, we propose an
interactive Text-to-SQL framework that models SQL generation as a probabilistic
reasoning process over multiple candidate queries. Rather than producing a
single deterministic output, our system maintains a distribution over possible
SQL outputs and seeks to resolve uncertainty through user interaction. At each
interaction step, the system selects a branching decision and formulates a
clarification question aimed at disambiguating that aspect of the query.
Crucially, we adopt a principled decision criterion based on Expected
Information Gain to identify the clarification that will, in expectation, most
reduce the uncertainty in the SQL distribution.

</details>


### [12] [QUEST: Query Optimization in Unstructured Document Analysis](https://arxiv.org/abs/2507.06515)
*Zhaoze Sun,Qiyan Deng,Chengliang Chai,Kaisen Jin,Xinyu Guo,Han Han,Ye Yuan,Guoren Wang,Lei Cao*

Main category: cs.DB

TL;DR: 现有基于大语言模型（LLMs）的数据系统存在查询执行瓶颈，本文提出QUEST系统，有多种优化策略，实验显示有成本节省和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有系统借用关系数据库查询优化原则无法有效降低LLM成本，需新的优化策略。

Method: 提出QUEST系统，包括基于索引策略、证据增强检索策略、实例优化查询执行策略、LLM成本感知算子排序策略和优化连接执行方法。

Result: 在3个真实数据集上实验，相比现有基线系统节省30%-6x成本，F1分数提升10%-27%。

Conclusion: QUEST系统在降低LLM成本和提高性能上表现优越。

Abstract: Most recently, researchers have started building large language models (LLMs)
powered data systems that allow users to analyze unstructured text documents
like working with a database because LLMs are very effective in extracting
attributes from documents. In such systems, LLM-based extraction operations
constitute the performance bottleneck of query execution due to the high
monetary cost and slow LLM inference. Existing systems typically borrow the
query optimization principles popular in relational databases to produce query
execution plans, which unfortunately are ineffective in minimizing LLM cost. To
fill this gap, we propose QUEST, which features a bunch of novel optimization
strategies for unstructured document analysis. First, we introduce an
index-based strategy to minimize the cost of each extraction operation. With
this index, QUEST quickly retrieves the text segments relevant to the target
attributes and only feeds them to LLMs. Furthermore, we design an
evidence-augmented retrieval strategy to reduce the possibility of missing
relevant segments. Moreover, we develop an instance-optimized query execution
strategy: because the attribute extraction cost could vary significantly
document by document, QUEST produces different plans for different documents.
For each document, QUEST produces a plan to minimize the frequency of attribute
extraction. The innovations include LLM cost-aware operator ordering strategies
and an optimized join execution approach that transforms joins into filters.
Extensive experiments on 3 real-world datasets demonstrate the superiority of
QUEST, achieving 30%-6x cost savings while improving the F1 score by 10% -27%
compared with state-of-the-art baselines.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [13] [Designing Parallel Algorithms for Community Detection using Arachne](https://arxiv.org/abs/2507.06471)
*Fuhuan Li,Zhihui Du,David A. Bader*

Main category: cs.DC

TL;DR: 提出基于Arachne框架的Label Propagation和Louvain算法并行实现，比现有工具更快，开源可获取。


<details>
  <summary>Details</summary>
Motivation: 各领域图数据增多，需要高效可扩展的社区检测算法。

Method: 在Arachne框架下对Label Propagation和Louvain算法进行并行实现。

Result: 基于Arachne的方法优于基线工具，相比NetworkX、igraph和NetworKit分别有710x、75x和12x的加速。分析了不同线程数下的可扩展性。

Conclusion: 基于Arachne的社区检测实现高效且可扩展，代码开源。

Abstract: The rise of graph data in various fields calls for efficient and scalable
community detection algorithms. In this paper, we present parallel
implementations of two widely used algorithms: Label Propagation and Louvain,
specifically designed to leverage the capabilities of Arachne which is a
Python-accessible, open-source framework for large-scale graph analysis. Our
implementations achieve substantial speedups over existing Python-based tools
like NetworkX and igraph, which lack efficient parallelization, and are
competitive with parallel frameworks such as NetworKit. Experimental results
show that Arachne-based methods outperform these baselines, achieving speedups
of up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit.
Additionally, we analyze the scalability of our implementation under varying
thread counts, demonstrating how different phases contribute to overall
performance gains of the parallel Louvain algorithm. Arachne, including our
community detection implementation, is open-source and available at
https://github.com/Bears-R-Us/arkouda-njit .

</details>


### [14] [Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing](https://arxiv.org/abs/2507.06608)
*Xiaoxiang Shi,Colin Cai,Junjia Du,Zhanda Zhu,Xingda Wei,Zhihao Jia*

Main category: cs.DC

TL;DR: 文章提出在单个服务引擎内解耦预填充和解码阶段的方法，系统Nexus在多种指标上优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有预填充 - 解码（PD）分解方法需更多硬件，分块预填充会引入阶段干扰，希望在单个服务引擎内实现解耦。

Method: 发现分块预填充请求对解码请求有干扰，GPU资源存在收益递减，基于此拆分单个GPU资源并动态分配。

Result: 系统Nexus在多种模型和工作负载下，在吞吐量、TTFT、TBT等指标上优于vLLM、SGLang和vLLM - 分解，且只需一半数量的GPU。

Conclusion: 在单个GPU内有效分解预填充和解码阶段的方法可行，能提升性能并减少硬件需求。

Abstract: Current prefill-decode (PD) disaggregation is typically deployed at the level
of entire serving engines, assigning separate GPUs to handle prefill and decode
phases. While effective at reducing latency, this approach demands more
hardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode
requests within the same batch, but introduces phase interference between
prefill and decode.
  While existing PD disaggregation solutions separate the phases across GPUs,
we ask: can the same decoupling be achieved within a single serving engine? The
key challenge lies in managing the conflicting resource requirements of prefill
and decode when they share the same hardware. In this paper, we first show that
chunked prefill requests cause interference with decode requests due to their
distinct requirements for GPU resources. Second, we find that GPU resources
exhibit diminishing returns. Beyond a saturation point, increasing GPU
allocation yields negligible latency improvements. This insight enables us to
split a single GPU's resources and dynamically allocate them to prefill and
decode on the fly, effectively disaggregating the two phases within the same
GPU.
  Across a range of models and workloads, our system Nexus achieves up to 2.2x
higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also
outperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x
lower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using
only half the number of GPUs.

</details>


### [15] [Towards Efficient and Scalable Distributed Vector Search with RDMA](https://arxiv.org/abs/2507.06653)
*Xiangyu Zhi,Meng Chen,Xiao Yan,Baotong Lu,Hui Li,Qianxi Zhang,Qi Chen,James Cheng*

Main category: cs.DC

TL;DR: 提出CoTra系统解决基于相似度的向量搜索可扩展性问题，用算法 - 系统协同设计优化，实验效果好。


<details>
  <summary>Details</summary>
Motivation: 基于相似度的向量搜索受单机内存和带宽限制，且存在计算与通信效率的矛盾，需提升可扩展性。

Method: 采用算法 - 系统协同设计，包括基于聚类的数据分区、异步执行、任务推送，还有任务调度、通信批处理和存储格式等系统优化。

Result: 在16台机器上，CoTra查询吞吐量比单机提升9.8 - 13.4倍，在0.95 recall@10时是最佳基线的2.12 - 3.58倍。

Conclusion: CoTra系统能有效扩展向量搜索以进行分布式执行，解决了计算和通信效率的矛盾。

Abstract: Similarity-based vector search facilitates many important applications such
as search and recommendation but is limited by the memory capacity and
bandwidth of a single machine due to large datasets and intensive data read. In
this paper, we present CoTra, a system that scales up vector search for
distributed execution. We observe a tension between computation and
communication efficiency, which is the main challenge for good scalability,
i.e., handling the local vectors on each machine independently blows up
computation as the pruning power of vector index is not fully utilized, while
running a global index over all machines introduces rich data dependencies and
thus extensive communication. To resolve such tension, we leverage the fact
that vector search is approximate in nature and robust to asynchronous
execution. In particular, we run collaborative vector search over the machines
with algorithm-system co-designs including clustering-based data partitioning
to reduce communication, asynchronous execution to avoid communication stall,
and task push to reduce network traffic. To make collaborative search
efficient, we introduce a suite of system optimizations including task
scheduling, communication batching, and storage format. We evaluate CoTra on
real datasets and compare with four baselines. The results show that when using
16 machines, the query throughput of CoTra scales to 9.8-13.4x over a single
machine and is 2.12-3.58x of the best-performing baseline at 0.95 recall@10.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [16] [Parallel Batch-Dynamic Coreness Decomposition with Worst-Case Guarantees](https://arxiv.org/abs/2507.06334)
*Mohsen Ghaffari,Jaehyun Koo*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present the first parallel batch-dynamic algorithm for approximating
coreness decomposition with worst-case update times. Given any batch of edge
insertions and deletions, our algorithm processes all these updates in $
\text{poly}(\log n)$ depth, using a worst-case work bound of $b\cdot
\text{poly}(\log n)$ where $b$ denotes the batch size. This means the batch
gets processed in $\tilde{O}(b/p)$ time, given $p$ processors, which is optimal
up to logarithmic factors. Previously, an algorithm with similar guarantees was
known by the celebrated work of Liu, Shi, Yu, Dhulipala, and Shun [SPAA'22],
but with the caveat of the work bound, and thus the runtime, being only
amortized.

</details>


### [17] [Parallel Batch-Dynamic Algorithms for Spanners, and Extensions](https://arxiv.org/abs/2507.06338)
*Mohsen Ghaffari,Jaehyun Koo*

Main category: cs.DS

TL;DR: 本文提出首个计算生成器和稀疏化器的并行批量动态算法，能在特定深度和工作量下处理边的插入和删除。


<details>
  <summary>Details</summary>
Motivation: 缺乏计算生成器和稀疏化器的并行批量动态算法。

Method: 设计并行批量动态算法处理n节点无向图中边的插入和删除。

Result: 提出基础算法维护特定伸展和边数的生成器；第一个扩展维护稀疏生成器；第二个扩展维护生成器束并能维护稀疏化器。

Conclusion: 成功提出有效并行批量动态算法处理图的边更新，可用于维护生成器和稀疏化器。

Abstract: This paper presents the first parallel batch-dynamic algorithms for computing
spanners and sparsifiers. Our algorithms process any batch of edge insertions
and deletions in an $n$-node undirected graph, in $\text{poly}(\log n)$ depth
and using amortized work near-linear in the batch size. Our concrete results
are as follows:
  - Our base algorithm maintains a spanner with $(2k-1)$ stretch and
$\tilde{O}(n^{1+1/k})$ edges, for any $k\geq 1$.
  - Our first extension maintains a sparse spanner with only $O(n)$ edges, and
$\tilde{O}(\log n)$ stretch.
  - Our second extension maintains a $t$-bundle of spanners -- i.e., $t$
spanners, each of which is the spanner of the graph remaining after removing
the previous ones -- and allows us to maintain cut/spectral sparsifiers with
$\tilde{O}(n)$ edges.

</details>


### [18] [Prediction-Augmented Mechanism Design for Weighted Facility Location](https://arxiv.org/abs/2507.06509)
*Yangguang Shi,Zhenyu Xue*

Main category: cs.DS

TL;DR: 本文聚焦加权设施选址问题，提出预测增强算法框架平衡一致性与鲁棒性，给出相关保证并证明不存在满足特定条件的确定性机制。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要针对无权重情况，而实际场景中代理重要性可能不同，因此开展加权设施选址问题研究。

Method: 通过归约技术识别代表性实例子集，将其他给定位置映射到代表性实例。

Result: 证明存在策略防卫机制在加权场景下实现有界一致性和鲁棒性保证，还证明不存在满足特定一致性和鲁棒性的策略防卫确定性机制。

Conclusion: 所提出的预测增强算法框架能有效平衡加权场景下战略代理的一致性和鲁棒性。

Abstract: Facility location is fundamental in operations research, mechanism design,
and algorithmic game theory, with applications ranging from urban
infrastructure planning to distributed systems. Recent research in this area
has focused on augmenting classic strategyproof mechanisms with predictions to
achieve an improved performance guarantee against the uncertainty under the
strategic environment. Previous work has been devoted to address the trade-off
obstacle of balancing the consistency (near-optimality under accurate
predictions) and robustness (bounded inefficiency under poor predictions)
primarily in the unweighted setting, assuming that all agents have the same
importance. However, this assumption may not be true in some practical
scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction
augmented algorithmic framework for balancing the consistency and robustness
over strategic agents with non-uniform weights. In particular, through a
reduction technique that identifies a subset of \emph{representative} instances
and maps the other given locations to the representative ones, we prove that
there exists a \emph{strategyproof} mechanism achieving a bounded consistency
guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$
and a bounded robustness guarantee of
$\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted
settings, where $c$ can be viewed as a parameter to make a trade-off between
the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum
and maximum agents' weight. We also proved that there is no strategyproof
deterministic mechanism that reach $1$-consistency and $O\left( n \cdot
\frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully
predictions of all agents.

</details>


### [19] [Multi-Queue SSD I/O Modeling & Its Implications for Data Structure Design](https://arxiv.org/abs/2507.06349)
*Erin Ransom,Andrew Lim,Michael Mitzenmacher*

Main category: cs.DS

TL;DR: 传统存储性能模型因技术进步准确性下降，本文提出MQSSD模型，更准确反映现代存储硬件性能，通过实验验证其优势。


<details>
  <summary>Details</summary>
Motivation: 传统存储性能分析框架因技术进步，准确性和实用性降低，需新模型准确表示现代存储硬件性能。

Method: 确定现代多队列固态硬盘关键性能方面构建MQSSD模型，在实际硬件上验证特性，将模型应用于基于LSM树的存储引擎并实验验证。

Result: 利用并发访问对充分利用多队列SSD高吞吐量至关重要，设计可能与传统范式相悖。

Conclusion: MQSSD模型比以往模型更准确抽象现代硬件，有助于深入理解和优化。

Abstract: Understanding the performance profiles of storage devices and how best to
utilize them has always been non-trivial due to factors such as seek times,
caching, scheduling, concurrent access, flash wear-out, and garbage collection.
However, analytical frameworks that provide simplified abstractions of storage
performance can still be accurate enough to evaluate external memory algorithms
and data structures at the design stage. For example, the Disk Access Machine
(DAM) model assumes that a storage device transfers data in fixed-size blocks
of size B and that all transfers have unit latency. This abstraction is already
sufficient to explain some of the benefits of data structures such as B-trees
and Log-Structured Merge trees (LSM trees); however, storage technology
advances have significantly reduced current models' accuracy and utility.
  This paper introduces the Multi-Queue Solid State Drive (MQSSD) model, a new
storage abstraction. This model builds upon previous models and aims to more
accurately represent the performance characteristics of modern storage
hardware. We identify key performance-critical aspects of modern multi-queue
solid-state drives on which we base our model and demonstrate these
characteristics on actual hardware. We then show how our model can be applied
to LSM-tree-based storage engines to optimize them for modern storage hardware.
We highlight that leveraging concurrent access is crucial for fully utilizing
the high throughput of multi-queue SSDs, enabling designs that may appear
counterintuitive under traditional paradigms We then validate these insights
through experiments using Facebook's LSM-tree-based key-value store, RocksDB.
We conclude that the MQSSD model offers a more accurate abstraction of modern
hardware than previous models, allowing for greater insight and optimization.

</details>


### [20] [Faster Algorithms for $(2k-1)$-Stretch Distance Oracles](https://arxiv.org/abs/2507.06721)
*Avi Kadria,Liam Roditty*

Main category: cs.DS

TL;DR: 本文提出三种新算法构建(2k - 1)-伸展距离预言机，分析了各算法时间复杂度并与前人算法对比。


<details>
  <summary>Details</summary>
Motivation: 改进已有算法的时间复杂度，解决一些开放问题，如寻找真正次二次时间的构造方法。

Method: 提出三种新算法，分别分析其运行时间。

Result: 第一种算法在特定条件下改进时间复杂度，后两种算法在不同k值范围和图密度下有更好表现，如得到7 - 伸展和9 - 伸展距离预言机的线性时间算法。

Conclusion: 新算法在不同场景下对距离预言机构建的时间复杂度有改进，部分解决开放问题。

Abstract: Let $G=(V, E)$ be an undirected $n$-vertices $m$-edges graph with
non-negative edge weights. In this paper, we present three new algorithms for
constructing a $(2k-1)$-stretch distance oracle with $O(n^{1+\frac{1}{k}})$
space. The first algorithm runs in $\Ot(\max(n^{1+2/k},
m^{1-\frac{1}{k-1}}n^{\frac{2}{k-1}}))$ time, and improves upon the
$\Ot(\min(mn^{\frac{1}{k}},n^2))$ time of Thorup and Zwick [STOC 2001, JACM
2005] and Baswana and Kavitha [FOCS 2006, SICOMP 2010], for every $k > 2$ and
$m=\Omega(n^{1+\frac{1}{k}+\eps})$. This yields the first truly subquadratic
time construction for every $2 < k < 6$, and nearly resolves the open problem
posed by Wulff-Nilsen [SODA 2012] on the existence of such constructions.
  The two other algorithms have a running time of the form $\Ot(m+n^{1+f(k)})$,
which is near linear in $m$ if $m=\Omega(n^{1+f(k)})$, and therefore optimal in
such graphs. One algorithm runs in $\Ot(m+n^{\frac32+\frac{3}{4k-6}})$-time,
which improves upon the $\Ot(n^2)$-time algorithm of Baswana and Kavitha [FOCS
2006, SICOMP 2010], for $3 < k < 6$, and upon the
$\Ot(m+n^{\frac{3}{2}+\frac{2}{k}+O(k^{-2})})$-time algorithm of Wulff-Nilsen
[SODA 2012], for every $k\geq 6$. This is the first linear time algorithm for
constructing a $7$-stretch distance oracle and a $9$-stretch distance oracle,
for graphs with truly subquadratic density.\footnote{with $m=n^{2-\eps}$ for
some $\eps > 0$.} The other algorithm runs in
$\Ot(\sqrt{k}m+kn^{1+\frac{2\sqrt{2}}{\sqrt{k}}})$ time, (and hence relevant
only for $k\ge 16$), and improves upon the
$\Ot(\sqrt{k}m+kn^{1+\frac{2\sqrt{6}}{\sqrt{k}}+O(k^{-1})})$ time algorithm of
Wulff-Nilsen [SODA 2012] (which is relevant only for $k\ge 96$). ...

</details>


### [21] [Faster Estimation of the Average Degree of a Graph Using Random Edges and Structural Queries](https://arxiv.org/abs/2507.06925)
*Lorenzo Beretta,Deeparnab Chakrabarty,C. Seshadhri*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We revisit the problem of designing sublinear algorithms for estimating the
average degree of an $n$-vertex graph. The standard access model for graphs
allows for the following queries: sampling a uniform random vertex, the degree
of a vertex, sampling a uniform random neighbor of a vertex, and ``pair
queries'' which determine if a pair of vertices form an edge. In this model,
original results [Goldreich-Ron, RSA 2008; Eden-Ron-Seshadhri, SIDMA 2019] on
this problem prove that the complexity of getting
$(1+\varepsilon)$-multiplicative approximations to the average degree, ignoring
$\varepsilon$-dependencies, is $\Theta(\sqrt{n})$. When random edges can be
sampled, it is known that the average degree can estimated in
$\widetilde{O}(n^{1/3})$ queries, even without pair queries
[Motwani-Panigrahy-Xu, ICALP 2007; Beretta-Tetek, TALG 2024].
  We give a nearly optimal algorithm in the standard access model with random
edge samples. Our algorithm makes $\widetilde{O}(n^{1/4})$ queries exploiting
the power of pair queries. We also analyze the ``full neighborhood access"
model wherein the entire adjacency list of a vertex can be obtained with a
single query; this model is relevant in many practical applications. In a
weaker version of this model, we give an algorithm that makes
$\widetilde{O}(n^{1/5})$ queries. Both these results underscore the power of
{\em structural queries}, such as pair queries and full neighborhood access
queries, for estimating the average degree. We give nearly matching lower
bounds, ignoring $\varepsilon$-dependencies, for all our results.
  So far, almost all algorithms for estimating average degree assume that the
number of vertices, $n$, is known. Inspired by [Beretta-Tetek, TALG 2024], we
study this problem when $n$ is unknown and show that structural queries do not
help in estimating average degree in this setting.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [22] [USD: A User-Intent-Driven Sampling and Dual-Debiasing Framework for Large-Scale Homepage Recommendations](https://arxiv.org/abs/2507.06503)
*Jiaqi Zheng,Cheng Guo,Yi Cao,Chaoqun Hou,Tong Liu,Bo Zheng*

Main category: cs.IR

TL;DR: 针对大规模首页推荐中曝光偏差问题，提出统一框架，含用户意图感知负采样和意图驱动双去偏模块，淘宝实验显示显著提升用户点击率。


<details>
  <summary>Details</summary>
Motivation: 现有工作对无效曝光分析不足，且忽视伪正样本影响，要解决大规模首页推荐中曝光偏差和伪正样本问题。

Method: 提出统一框架，包括用户意图感知负采样模块过滤无效曝光样本，意图驱动双去偏模块纠正曝光和点击偏差。

Result: 在淘宝两个营销板块上进行实验，分别使UCTR提升35.4%和14.5%。

Conclusion: 所提出的统一框架有效，能显著提升用户点击率。

Abstract: Large-scale homepage recommendations face critical challenges from
pseudo-negative samples caused by exposure bias, where non-clicks may indicate
inattention rather than disinterest. Existing work lacks thorough analysis of
invalid exposures and typically addresses isolated aspects (e.g., sampling
strategies), overlooking the critical impact of pseudo-positive samples - such
as homepage clicks merely to visit marketing portals. We propose a unified
framework for large-scale homepage recommendation sampling and debiasing. Our
framework consists of two key components: (1) a user intent-aware negative
sampling module to filter invalid exposure samples, and (2) an intent-driven
dual-debiasing module that jointly corrects exposure bias and click bias.
Extensive online experiments on Taobao demonstrate the efficacy of our
framework, achieving significant improvements in user click-through rates
(UCTR) by 35.4\% and 14.5\% in two variants of the marketing block on the
Taobao homepage, Baiyibutie and Taobaomiaosha.

</details>


### [23] [GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models](https://arxiv.org/abs/2507.06507)
*Zhen Yang,Haitao Lin,Jiawei xue,Ziji Zhang*

Main category: cs.IR

TL;DR: 本文对基于大语言模型的生成式推荐进行全面综述，介绍初步信息、应用考量和未来方向，助力该领域发展。


<details>
  <summary>Details</summary>
Motivation: 鉴于基于大语言模型的生成式推荐有巨大潜力取代传统推荐系统，为促进该领域进一步研究。

Method: 先概述基于大语言模型的生成式推荐的初步信息和应用案例，接着介绍其在实际工业场景应用时的主要考量，最后探索其有前景的方向。

Result: 无具体实验结果，提供了基于大语言模型的生成式推荐的全面信息。

Conclusion: 希望本综述有助于生成式推荐领域的持续发展。

Abstract: In the past year, Generative Recommendations (GRs) have undergone substantial
advancements, especially in leveraging the powerful sequence modeling and
reasoning capabilities of Large Language Models (LLMs) to enhance overall
recommendation performance. LLM-based GRs are forming a new paradigm that is
distinctly different from discriminative recommendations, showing strong
potential to replace traditional recommendation systems heavily dependent on
complex hand-crafted features. In this paper, we provide a comprehensive survey
aimed at facilitating further research of LLM-based GRs. Initially, we outline
the general preliminaries and application cases of LLM-based GRs. Subsequently,
we introduce the main considerations when LLM-based GRs are applied in real
industrial scenarios. Finally, we explore promising directions for LLM-based
GRs. We hope that this survey contributes to the ongoing advancement of the GR
domain.

</details>


### [24] [SPEAR: Subset-sampled Performance Evaluation via Automated Ground Truth Generation for RAG](https://arxiv.org/abs/2507.06554)
*Zou Yuheng,Wang Yiran,Tian Yuzhu,Zhu Min,Huang Yanhua*

Main category: cs.IR

TL;DR: 本文提出SEARA方法解决检索增强生成（RAG）系统中检索器评估数据难题，实现低成本自动评估并获取特定业务场景最优检索器，且在经典RAG应用中验证有效。


<details>
  <summary>Details</summary>
Motivation: RAG系统中检索器超参数优化计算成本高，现有评估方法存在成本高或与特定领域场景脱节问题。

Method: 提出SEARA方法，通过子集采样技术处理评估数据挑战，以最少检索事实提取和全面检索指标实现稳健自动检索器评估。

Result: 在rednote的经典RAG应用中，包括基于知识的问答系统和基于检索的旅行助手，成功获得特定场景的最优检索器。

Conclusion: SEARA方法能基于真实用户查询，以低成本实现检索器的全自动评估，为特定业务场景获取最优检索器。

Abstract: Retrieval-Augmented Generation (RAG) is a core approach for enhancing Large
Language Models (LLMs), where the effectiveness of the retriever largely
determines the overall response quality of RAG systems. Retrievers encompass a
multitude of hyperparameters that significantly impact performance outcomes and
demonstrate sensitivity to specific applications. Nevertheless, hyperparameter
optimization entails prohibitively high computational expenses. Existing
evaluation methods suffer from either prohibitive costs or disconnection from
domain-specific scenarios. This paper proposes SEARA (Subset sampling
Evaluation for Automatic Retriever Assessment), which addresses evaluation data
challenges through subset sampling techniques and achieves robust automated
retriever evaluation by minimal retrieval facts extraction and comprehensive
retrieval metrics. Based on real user queries, this method enables fully
automated retriever evaluation at low cost, thereby obtaining optimal retriever
for specific business scenarios. We validate our method across classic RAG
applications in rednote, including knowledge-based Q&A system and
retrieval-based travel assistant, successfully obtaining scenario-specific
optimal retrievers.

</details>


### [25] [DS@GT at CheckThat! 2025: Exploring Retrieval and Reranking Pipelines for Scientific Claim Source Retrieval on Social Media Discourse](https://arxiv.org/abs/2507.06563)
*Jeanette Schofield,Shuyu Tian,Hoang Thanh Thanh Truong,Maximilian Heil*

Main category: cs.IR

TL;DR: 本文介绍DS@GT团队针对CLEF 2025 CheckThat! Lab Task 4b科学声明来源检索的工作，探索多种技术和管道，微调双编码器，取得一定成绩并公开代码。


<details>
  <summary>Details</summary>
Motivation: 社交媒体用户提出科学声明却不注明来源，需要验证这些声明，该任务旨在根据推文中的隐式引用查找相关科学论文。

Method: 探索6种不同的数据增强技术、7种不同的检索和重排管道，并微调双编码器。

Result: 团队在CLEF 2025 CheckThat! Lab Task 4b中排名第16（共30支队伍），MRR@5为0.58，比BM25基线0.43提高了0.15。

Conclusion: 团队的方法在科学声明来源检索任务中取得了一定效果，且代码已公开。

Abstract: Social media users often make scientific claims without citing where these
claims come from, generating a need to verify these claims. This paper details
work done by the DS@GT team for CLEF 2025 CheckThat! Lab Task 4b Scientific
Claim Source Retrieval which seeks to find relevant scientific papers based on
implicit references in tweets. Our team explored 6 different data augmentation
techniques, 7 different retrieval and reranking pipelines, and finetuned a
bi-encoder. Achieving an MRR@5 of 0.58, our team ranked 16th out of 30 teams
for the CLEF 2025 CheckThat! Lab Task 4b, and improvement of 0.15 over the BM25
baseline of 0.43. Our code is available on Github at
https://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4b.

</details>


### [26] [Impacts of Mainstream-Driven Algorithms on Recommendations for Children Across Domains: A Reproducibility Study](https://arxiv.org/abs/2507.06596)
*Robin Ungruh,Alejandro Bellogín,Dominik Kowald,Maria Soledad Pera*

Main category: cs.IR

TL;DR: 研究在更多数据集上复现和扩展Ungruh等人的研究，揭示儿童与其他群体消费模式差异。


<details>
  <summary>Details</summary>
Motivation: 以往研究少以儿童为用户群体，且相关数据集儿童代表性不足，可能忽略其兴趣，原研究样本有限。

Method: 在电影、音乐和书籍领域的更多数据集上复现和扩展原研究，用流行度偏差指标延伸见解。

Result: 发现跨领域一致的儿童 - 推荐系统交互模式，以及特定用户样本的交互模式。

Conclusion: 揭示了因儿童与他人内在差异以及特定数据集或领域导致的不同年龄组消费模式差异。

Abstract: Children are often exposed to items curated by recommendation algorithms.
Yet, research seldom considers children as a user group, and when it does, it
is anchored on datasets where children are underrepresented, risking
overlooking their interests, favoring those of the majority, i.e., mainstream
users. Recently, Ungruh et al. demonstrated that children's consumption
patterns and preferences differ from those of mainstream users, resulting in
inconsistent recommendation algorithm performance and behavior for this user
group. These findings, however, are based on two datasets with a limited child
user sample. We reproduce and replicate this study on a wider range of datasets
in the movie, music, and book domains, uncovering interaction patterns and
aspects of child-recommender interactions consistent across domains, as well as
those specific to some user samples in the data. We also extend insights from
the original study with popularity bias metrics, given the interpretation of
results from the original study. With this reproduction and extension, we
uncover consumption patterns and differences between age groups stemming from
intrinsic differences between children and others, and those unique to specific
datasets or domains.

</details>


### [27] [Temporal Information Retrieval via Time-Specifier Model Merging](https://arxiv.org/abs/2507.06782)
*SeungYoon Han,Taeho Hwang,Sukmin Cho,Soyeong Jeong,Hoyun Song,Huije Lee,Jong C. Park*

Main category: cs.IR

TL;DR: 提出TSM方法增强时间检索并保持非时间查询准确性，实验表明其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索方法在处理有时间约束的查询时表现不佳，且存在灾难性遗忘问题，影响非时间查询性能。

Method: 提出Time - Specifier Model Merging (TSM)方法，为单个时间说明符训练专门的检索器并合并成统一模型。

Result: 在时间和非时间数据集上的大量实验表明，TSM显著提高了时间约束查询的性能，同时在非时间查询上也保持了良好结果，始终优于其他基线方法。

Conclusion: TSM方法有效解决了现有方法在时间信息检索中的问题，提高了检索性能。

Abstract: The rapid expansion of digital information and knowledge across structured
and unstructured sources has heightened the importance of Information Retrieval
(IR). While dense retrieval methods have substantially improved semantic
matching for general queries, they consistently underperform on queries with
explicit temporal constraints--often those containing numerical expressions and
time specifiers such as ``in 2015.'' Existing approaches to Temporal
Information Retrieval (TIR) improve temporal reasoning but often suffer from
catastrophic forgetting, leading to reduced performance on non-temporal
queries. To address this, we propose Time-Specifier Model Merging (TSM), a
novel method that enhances temporal retrieval while preserving accuracy on
non-temporal queries. TSM trains specialized retrievers for individual time
specifiers and merges them in to a unified model, enabling precise handling of
temporal constraints without compromising non-temporal retrieval. Extensive
experiments on both temporal and non-temporal datasets demonstrate that TSM
significantly improves performance on temporally constrained queries while
maintaining strong results on non-temporal queries, consistently outperforming
other baseline methods. Our code is available at
https://github.com/seungyoonee/TSM .

</details>


### [28] [CDC: Causal Domain Clustering for Multi-Domain Recommendation](https://arxiv.org/abs/2507.06877)
*Huishi Luo,Yiqing Wu,Yiwen Chen,Fuzhen Zhuang,Deqing Wang*

Main category: cs.IR

TL;DR: 提出因果域聚类（CDC）方法用于多领域推荐中的域聚类，在多领域显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 多领域推荐在大量场景下统一模型训练会因域间差异致性能下降，现有域分组方法无法捕捉最优分组所需的真实迁移关系。

Method: 提出CDC方法，用隔离域亲和矩阵和混合域亲和矩阵建模域迁移模式，引入因果发现计算基于凝聚性的系数平衡两者贡献，用协同优化动态聚类算法迭代优化目标域聚类和源域选择。

Result: 在公共数据集和工业环境超50个领域显著提升性能，在线eCPM提高4.9%。

Conclusion: CDC方法能有效解决多领域推荐中域聚类问题，提升推荐性能。

Abstract: Multi-domain recommendation leverages domain-general knowledge to improve
recommendations across several domains. However, as platforms expand to dozens
or hundreds of scenarios, training all domains in a unified model leads to
performance degradation due to significant inter-domain differences. Existing
domain grouping methods, based on business logic or data similarities, often
fail to capture the true transfer relationships required for optimal grouping.
To effectively cluster domains, we propose Causal Domain Clustering (CDC). CDC
models domain transfer patterns within a large number of domains using two
distinct effects: the Isolated Domain Affinity Matrix for modeling
non-interactive domain transfers, and the Hybrid Domain Affinity Matrix for
considering dynamic domain synergy or interference under joint training. To
integrate these two transfer effects, we introduce causal discovery to
calculate a cohesion-based coefficient that adaptively balances their
contributions. A Co-Optimized Dynamic Clustering algorithm iteratively
optimizes target domain clustering and source domain selection for training.
CDC significantly enhances performance across over 50 domains on public
datasets and in industrial settings, achieving a 4.9% increase in online eCPM.
Code is available at
https://github.com/Chrissie-Law/Causal-Domain-Clustering-for-Multi-Domain-Recommendation

</details>


### [29] [Boosting Parameter Efficiency in LLM-Based Recommendation through Sophisticated Pruning](https://arxiv.org/abs/2507.07064)
*Shanle Zheng,Keqin Bao,Jizhi Zhang,Yang Zhang,Fuli Feng,Xiangnan He*

Main category: cs.IR

TL;DR: 文章探索参数剪枝提高大语言模型推荐系统参数效率与部署便利性，提出细粒度剪枝方法并获有效结果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推荐系统因参数量大，部署成本高阻碍实际应用，需提高参数效率。

Method: 提出结合层内和层间剪枝的细粒度方法，采用三阶段剪枝策略，每阶段含蒸馏技术恢复性能步骤。

Result: 在三个数据集上，模型保留原模型88%性能，剪掉超95%非嵌入参数。

Conclusion: 方法能显著降低资源需求，且不过多牺牲推荐质量。

Abstract: LLM-based recommender systems have made significant progress; however, the
deployment cost associated with the large parameter volume of LLMs still
hinders their real-world applications. This work explores parameter pruning to
improve parameter efficiency while maintaining recommendation quality, thereby
enabling easier deployment. Unlike existing approaches that focus primarily on
inter-layer redundancy, we uncover intra-layer redundancy within components
such as self-attention and MLP modules. Building on this analysis, we propose a
more fine-grained pruning approach that integrates both intra-layer and
layer-wise pruning. Specifically, we introduce a three-stage pruning strategy
that progressively prunes parameters at different levels and parts of the
model, moving from intra-layer to layer-wise pruning, or from width to depth.
Each stage also includes a performance restoration step using distillation
techniques, helping to strike a balance between performance and parameter
efficiency. Empirical results demonstrate the effectiveness of our approach:
across three datasets, our models achieve an average of 88% of the original
model's performance while pruning more than 95% of the non-embedding
parameters. This underscores the potential of our method to significantly
reduce resource requirements without greatly compromising recommendation
quality. Our code will be available at: https://github.com/zheng-sl/PruneRec

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [30] [Energy-Efficient Supervised Learning with a Binary Stochastic Forward-Forward Algorithm](https://arxiv.org/abs/2507.06461)
*Risi Jaiswal,Supriyo Datta,Joseph G. Makin*

Main category: cs.LG

TL;DR: 本文推导用于二元随机单元的前向 - 前向算法，在多数据集上评估，性能接近实值前向 - 前向算法且节能约一个数量级。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习能耗大，反向传播算法给硬件加速带来挑战，替代算法的计算瓶颈是矩阵乘法。

Method: 推导二元随机单元的前向 - 前向算法，利用激活二值化将矩阵乘法转为索引操作，结合随机性和不同偏置单元的权重绑定，使用 p - 位实现快速二元采样。

Result: 在 MNIST、Fashion - MNIST 和 CIFAR - 10 数据集上评估，性能接近实值前向 - 前向算法，估计节能约一个数量级。

Conclusion: 所提出的算法在性能接近的情况下能有效降低能耗。

Abstract: Reducing energy consumption has become a pressing need for modern machine
learning, which has achieved many of its most impressive results by scaling to
larger and more energy-consumptive neural networks. Unfortunately, the main
algorithm for training such networks, backpropagation, poses significant
challenges for custom hardware accelerators, due to both its serial
dependencies and the memory footprint needed to store forward activations for
the backward pass. Alternatives to backprop, although less effective, do exist;
here the main computational bottleneck becomes matrix multiplication. In this
study, we derive forward-forward algorithms for binary, stochastic units.
Binarization of the activations transforms matrix multiplications into indexing
operations, which can be executed efficiently in hardware. Stochasticity,
combined with tied weights across units with different biases, bypasses the
information bottleneck imposed by binary units. Furthermore, although slow and
expensive in traditional hardware, binary sampling that is very fast can be
implemented cheaply with p-bits (probabilistic bits), novel devices made up of
unstable magnets. We evaluate our proposed algorithms on the MNIST,
Fashion-MNIST, and CIFAR-10 datasets, showing that its performance is close to
real-valued forward-forward, but with an estimated energy savings of about one
order of magnitude.

</details>


### [31] [Neural Network-Based Parameter Estimation for Non-Autonomous Differential Equations with Discontinuous Signals](https://arxiv.org/abs/2507.06267)
*Hyeontae Jo,Krešimir Josić,Jae Kyoung Kim*

Main category: cs.LG

TL;DR: 提出HADES - NN方法解决非自治微分方程模型拟合含突变信号数据的难题，应用效果好且扩展适用范围。


<details>
  <summary>Details</summary>
Motivation: 非自治微分方程建模含突变外部信号的系统时，模型拟合数据存在困难。

Method: 提出HADES - NN方法，分两个迭代阶段，先以神经网络用平滑函数近似不连续信号，再用近似信号估计模型参数。

Result: HADES - NN在多种应用中给出高精度和准确的参数估计，如生物钟系统和酵母交配响应。

Conclusion: HADES - NN大大扩展了可拟合真实测量数据的模型系统范围。

Abstract: Non-autonomous differential equations are crucial for modeling systems
influenced by external signals, yet fitting these models to data becomes
particularly challenging when the signals change abruptly. To address this
problem, we propose a novel parameter estimation method utilizing functional
approximations with artificial neural networks. Our approach, termed Harmonic
Approximation of Discontinuous External Signals using Neural Networks
(HADES-NN), operates in two iterated stages. In the first stage, the algorithm
employs a neural network to approximate the discontinuous signal with a smooth
function. In the second stage, it uses this smooth approximate signal to
estimate model parameters. HADES-NN gives highly accurate and precise parameter
estimates across various applications, including circadian clock systems
regulated by external light inputs measured via wearable devices and the mating
response of yeast to external pheromone signals. HADES-NN greatly extends the
range of model systems that can be fit to real-world measurements.

</details>


### [32] [Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease](https://arxiv.org/abs/2507.06326)
*Harsh Ravivarapu,Gaurav Bagwe,Xiaoyong Yuan,Chunxiu Yu,Lan Zhang*

Main category: cs.LG

TL;DR: 本文提出SEA - DBS框架解决基于RL的自适应神经刺激核心挑战，在模拟中展现优势，是实用有效的aDBS框架。


<details>
  <summary>Details</summary>
Motivation: 传统DBS缺乏适应性、能耗高且个性化不足，现有基于RL的aDBS方法存在样本复杂度高、探索不稳定和硬件部署受限等问题。

Method: 提出SEA - DBS框架，集成预测奖励模型减少对实时反馈依赖，采用基于Gumbel Softmax的探索进行稳定可微策略更新。

Result: 在帕金森基底神经节活动的生物现实模拟中，SEA - DBS收敛更快、能更强抑制病理β波段功率且对训练后FP16量化有恢复力。

Conclusion: SEA - DBS是用于实时、资源受限神经调节的实用有效基于RL的aDBS框架。

Abstract: Deep brain stimulation (DBS) is an established intervention for Parkinson's
disease (PD), but conventional open-loop systems lack adaptability, are
energy-inefficient due to continuous stimulation, and provide limited
personalization to individual neural dynamics. Adaptive DBS (aDBS) offers a
closed-loop alternative, using biomarkers such as beta-band oscillations to
dynamically modulate stimulation. While reinforcement learning (RL) holds
promise for personalized aDBS control, existing methods suffer from high sample
complexity, unstable exploration in binary action spaces, and limited
deployability on resource-constrained hardware.
  We propose SEA-DBS, a sample-efficient actor-critic framework that addresses
the core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a
predictive reward model to reduce reliance on real-time feedback and employs
Gumbel Softmax-based exploration for stable, differentiable policy updates in
binary action spaces. Together, these components improve sample efficiency,
exploration robustness, and compatibility with resource-constrained
neuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic
simulation of Parkinsonian basal ganglia activity, demonstrating faster
convergence, stronger suppression of pathological beta-band power, and
resilience to post-training FP16 quantization. Our results show that SEA-DBS
offers a practical and effective RL-based aDBS framework for real-time,
resource-constrained neuromodulation.

</details>


### [33] [SymFlux: deep symbolic regression of Hamiltonian vector fields](https://arxiv.org/abs/2507.06342)
*M. A. Evangelista-Alvarado,P. Suárez-Serrato*

Main category: cs.LG

TL;DR: 提出SymFlux框架，用混合CNN - LSTM架构从向量场识别哈密顿函数，在新数据集训练验证，证明模型有效。


<details>
  <summary>Details</summary>
Motivation: 实现从标准辛平面上的向量场识别哈密顿函数的符号回归，推动哈密顿力学的自动发现。

Method: 提出SymFlux框架，采用混合CNN - LSTM架构，在新开发的哈密顿向量场数据集上进行训练和验证。

Result: 模型能准确恢复符号表达式。

Conclusion: 该模型在哈密顿力学自动发现方面取得进展。

Abstract: We present SymFlux, a novel deep learning framework that performs symbolic
regression to identify Hamiltonian functions from their corresponding vector
fields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM
architectures to learn and output the symbolic mathematical expression of the
underlying Hamiltonian. Training and validation are conducted on newly
developed datasets of Hamiltonian vector fields, a key contribution of this
work. Our results demonstrate the model's effectiveness in accurately
recovering these symbolic expressions, advancing automated discovery in
Hamiltonian mechanics.

</details>


### [34] [DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction](https://arxiv.org/abs/2507.06366)
*Yupu Zhang,Zelin Xu,Tingsong Xiao,Gustavo Seabra,Yanjun Li,Chenglong Li,Zhe Jiang*

Main category: cs.LG

TL;DR: 本文提出用于蛋白 - 配体复合物自监督图对比学习的大规模数据集DecoyDB，并设计定制GCL框架，实验表明用DecoyDB预训练的模型效果好。


<details>
  <summary>Details</summary>
Motivation: 蛋白 - 配体复合物结合亲和力预测缺乏大规模高质量标签数据，现有自监督学习面临无综合未标记数据集和适配算法的挑战。

Method: 提出包含高分辨率真实复合物和多样诱饵结构的DecoyDB数据集，设计定制GCL框架在DecoyDB上预训练图神经网络，并在PDBbind上微调。

Result: 用DecoyDB预训练的模型在准确性、标签效率和泛化性上表现出色。

Conclusion: DecoyDB和定制GCL框架有助于解决蛋白 - 配体复合物结合亲和力预测中标签数据不足的问题。

Abstract: Predicting the binding affinity of protein-ligand complexes plays a vital
role in drug discovery. Unfortunately, progress has been hindered by the lack
of large-scale and high-quality binding affinity labels. The widely used
PDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning,
especially graph contrastive learning (GCL), provides a unique opportunity to
break the barrier by pre-training graph neural network models based on vast
unlabeled complexes and fine-tuning the models on much fewer labeled complexes.
However, the problem faces unique challenges, including a lack of a
comprehensive unlabeled dataset with well-defined positive/negative complex
pairs and the need to design GCL algorithms that incorporate the unique
characteristics of such data. To fill the gap, we propose DecoyDB, a
large-scale, structure-aware dataset specifically designed for self-supervised
GCL on protein-ligand complexes. DecoyDB consists of high-resolution ground
truth complexes (less than 2.5 Angstrom) and diverse decoy structures with
computationally generated binding poses that range from realistic to suboptimal
(negative pairs). Each decoy is annotated with a Root Mean Squared Deviation
(RMSD) from the native pose. We further design a customized GCL framework to
pre-train graph neural networks based on DecoyDB and fine-tune the models with
labels from PDBbind. Extensive experiments confirm that models pre-trained with
DecoyDB achieve superior accuracy, label efficiency, and generalizability.

</details>


### [35] [FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models](https://arxiv.org/abs/2507.06449)
*Qianyu Long,Qiyuan Wang,Christos Anagnostopoulos,Daning Bi*

Main category: cs.LG

TL;DR: 提出FedPhD方法在联邦学习环境下高效训练扩散模型，减少通信成本，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习训练扩散模型存在高通信成本和数据异构性问题，且相关研究有限。

Method: 引入FedPhD，利用分层联邦学习、同质性感知模型聚合和选择策略，采用分布式结构化剪枝。

Result: 实验表明FedPhD在FID分数上表现高，通信成本最多降低88%，比基线方法至少提升34%的FID，仅使用56%的计算和通信资源。

Conclusion: FedPhD能有效解决联邦学习训练扩散模型的问题，提高效率和性能。

Abstract: Federated Learning (FL), as a distributed learning paradigm, trains models
over distributed clients' data. FL is particularly beneficial for distributed
training of Diffusion Models (DMs), which are high-quality image generators
that require diverse data. However, challenges such as high communication costs
and data heterogeneity persist in training DMs similar to training Transformers
and Convolutional Neural Networks. Limited research has addressed these issues
in FL environments. To address this gap and challenges, we introduce a novel
approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD
leverages Hierarchical FL with homogeneity-aware model aggregation and
selection policy to tackle data heterogeneity while reducing communication
costs. The distributed structured pruning of FedPhD enhances computational
efficiency and reduces model storage requirements in clients. Our experiments
across multiple datasets demonstrate that FedPhD achieves high model
performance regarding Fr\'echet Inception Distance (FID) scores while reducing
communication costs by up to $88\%$. FedPhD outperforms baseline methods
achieving at least a $34\%$ improvement in FID, while utilizing only $56\%$ of
the total computation and communication resources.

</details>


### [36] [The Riemannian Geometry associated to Gradient Flows of Linear Convolutional Networks](https://arxiv.org/abs/2507.06367)
*El Mehdi Achour,Kathlén Kohn,Holger Rauhut*

Main category: cs.LG

TL;DR: 研究学习深度线性卷积网络梯度流的几何性质，发现学习线性卷积网络参数空间上的梯度流可写成函数空间上的黎曼梯度流，与初始化无关。


<details>
  <summary>Details</summary>
Motivation: 探索学习深度线性卷积网络梯度流的几何性质，受线性全连接网络相关结论启发。

Method: 对学习线性卷积网络的梯度流进行分析推导。

Result: 学习线性卷积网络参数空间上的梯度流可写成函数空间上的黎曼梯度流，D≥2 时恒成立，D = 1 且卷积步长大于 1 时成立，对应黎曼度量与初始化有关。

Conclusion: 在特定条件下，学习线性卷积网络参数空间上的梯度流可写成函数空间上的黎曼梯度流。

Abstract: We study geometric properties of the gradient flow for learning deep linear
convolutional networks. For linear fully connected networks, it has been shown
recently that the corresponding gradient flow on parameter space can be written
as a Riemannian gradient flow on function space (i.e., on the product of weight
matrices) if the initialization satisfies a so-called balancedness condition.
We establish that the gradient flow on parameter space for learning linear
convolutional networks can be written as a Riemannian gradient flow on function
space regardless of the initialization. This result holds for $D$-dimensional
convolutions with $D \geq 2$, and for $D =1$ it holds if all so-called strides
of the convolutions are greater than one. The corresponding Riemannian metric
depends on the initialization.

</details>


### [37] [DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models](https://arxiv.org/abs/2507.06853)
*Liang Wang,Yu Rong,Tingyang Xu,Zhenyi Zhong,Zhiyuan Liu,Pengju Wang,Deli Zhao,Qiang Liu,Shu Wu,Liang Wang*

Main category: cs.LG

TL;DR: 提出DiffSpectra框架，利用扩散模型从多模态光谱数据推断2D和3D分子结构，实验证明其结构解析准确率高。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖专家解读、缺乏可扩展性，现有机器学习方法存在局限性，需要新方法解决分子结构解析问题。

Method: 提出DiffSpectra框架，用Diffusion Molecule Transformer作为去噪网络，SpecFormer作为光谱编码器。

Result: DiffSpectra在结构解析中准确率高，top-1准确率16.01%，top-20准确率96.86%，且受益于3D几何建模、SpecFormer预训练和多模态条件。

Conclusion: 谱条件扩散建模在解决分子结构解析挑战中有效，DiffSpectra是首个统一多模态光谱推理和联合2D/3D生成建模用于从头分子结构解析的框架。

Abstract: Molecular structure elucidation from spectra is a foundational problem in
chemistry, with profound implications for compound identification, synthesis,
and drug development. Traditional methods rely heavily on expert interpretation
and lack scalability. Pioneering machine learning methods have introduced
retrieval-based strategies, but their reliance on finite libraries limits
generalization to novel molecules. Generative models offer a promising
alternative, yet most adopt autoregressive SMILES-based architectures that
overlook 3D geometry and struggle to integrate diverse spectral modalities. In
this work, we present DiffSpectra, a generative framework that directly infers
both 2D and 3D molecular structures from multi-modal spectral data using
diffusion models. DiffSpectra formulates structure elucidation as a conditional
generation process. Its denoising network is parameterized by Diffusion
Molecule Transformer, an SE(3)-equivariant architecture that integrates
topological and geometric information. Conditioning is provided by SpecFormer,
a transformer-based spectral encoder that captures intra- and inter-spectral
dependencies from multi-modal spectra. Extensive experiments demonstrate that
DiffSpectra achieves high accuracy in structure elucidation, recovering exact
structures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through
sampling. The model benefits significantly from 3D geometric modeling,
SpecFormer pre-training, and multi-modal conditioning. These results highlight
the effectiveness of spectrum-conditioned diffusion modeling in addressing the
challenge of molecular structure elucidation. To our knowledge, DiffSpectra is
the first framework to unify multi-modal spectral reasoning and joint 2D/3D
generative modeling for de novo molecular structure elucidation.

</details>


### [38] [A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning](https://arxiv.org/abs/2507.06542)
*Tongtian Zhu,Tianyu Zhang,Mingze Wang,Zhanpeng Zhou,Can Wang*

Main category: cs.LG

TL;DR: 研究去中心化学习通信调度，发现后期集中通信可提升泛化性能，最终全连接通信能媲美服务器训练，还给出理论解释并挑战传统观念。


<details>
  <summary>Details</summary>
Motivation: 去中心化学习性能受限于点对点通信，需研究通信调度方法。

Method: 研究通信在时间上的调度，确定设备同步时间和频率。

Result: 后期集中通信预算可显著提升全局泛化能力，最终全连接通信能达到服务器训练效果，低通信保留局部模型可合并性。

Conclusion: 去中心化SGD全局合并模型收敛比集中式小批量SGD快，挑战了去中心化学习在数据异质性和有限通信下泛化差的观念，为模型合并和损失景观提供新见解。

Abstract: Decentralized learning provides a scalable alternative to traditional
parameter-server-based training, yet its performance is often hindered by
limited peer-to-peer communication. In this paper, we study how communication
should be scheduled over time, including determining when and how frequently
devices synchronize. Our empirical results show that concentrating
communication budgets in the later stages of decentralized training markedly
improves global generalization. Surprisingly, we uncover that fully connected
communication at the final step, implemented by a single global merging, is
sufficient to match the performance of server-based training. We further show
that low communication in decentralized learning preserves the
\textit{mergeability} of local models throughout training. Our theoretical
contributions, which explains these phenomena, are first to establish that the
globally merged model of decentralized SGD can converge faster than centralized
mini-batch SGD. Technically, we novelly reinterpret part of the discrepancy
among local models, which were previously considered as detrimental noise, as
constructive components that accelerate convergence. This work challenges the
common belief that decentralized learning generalizes poorly under data
heterogeneity and limited communication, while offering new insights into model
merging and neural network loss landscapes.

</details>


### [39] [Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation](https://arxiv.org/abs/2507.06380)
*Habibur Rahaman,Atri Chatterjee,Swarup Bhunia*

Main category: cs.LG

TL;DR: 介绍了WINGs框架，能动态生成全连接网络层权重并压缩卷积网络权重，减少内存需求且不牺牲太多精度，实现高压缩率并提升性能。


<details>
  <summary>Details</summary>
Motivation: 复杂神经网络存储大量突触权重需大量内存，需减少内存需求。

Method: 使用主成分分析（PCA）降维，用轻量级支持向量回归（SVR）模型预测全连接网络层权重；结合敏感性分析，用PCA和SVR压缩卷积网络低敏感性层权重。

Result: 在MNIST数据集上，全连接层实现53倍压缩，AlexNet实现28倍压缩；在CIFAR - 10数据集上，AlexNet实现18倍压缩，精度损失1 - 2%。

Conclusion: 显著减少内存可提高DNN推理吞吐量、降低能耗，适用于资源受限的边缘应用。

Abstract: Complex neural networks require substantial memory to store a large number of
synaptic weights. This work introduces WINGs (Automatic Weight Generator for
Secure and Storage-Efficient Deep Learning Models), a novel framework that
dynamically generates layer weights in a fully connected neural network (FC)
and compresses the weights in convolutional neural networks (CNNs) during
inference, significantly reducing memory requirements without sacrificing
accuracy. WINGs framework uses principal component analysis (PCA) for
dimensionality reduction and lightweight support vector regression (SVR) models
to predict layer weights in the FC networks, removing the need for storing
full-weight matrices and achieving substantial memory savings. It also
preferentially compresses the weights in low-sensitivity layers of CNNs using
PCA and SVR with sensitivity analysis. The sensitivity-aware design also offers
an added level of security, as any bit-flip attack with weights in compressed
layers has an amplified and readily detectable effect on accuracy. WINGs
achieves 53x compression for the FC layers and 28x for AlexNet with MNIST
dataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss.
This significant reduction in memory results in higher throughput and lower
energy for DNN inference, making it attractive for resource-constrained edge
applications.

</details>


### [40] [SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference](https://arxiv.org/abs/2507.06567)
*Qian Chen,Xianhao Chen,Kaibin Huang*

Main category: cs.LG

TL;DR: 针对MoE模型在边缘设备存储负担大的问题，研究边缘网络分布式推理中专家缓存优化，提出不同算法降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: MoE模型中大量专家网络给边缘设备带来显著存储负担，需解决此问题。

Method: 基于Top - K策略，K = 1时设计贪心算法；K≥1时提出连续贪心分解法并结合动态规划，还设计基于最大卷积技术的加速算法。

Result: 在各种MoE模型的仿真结果表明，该方法相比现有基线显著降低推理延迟。

Conclusion: 所提算法能有效解决MoE模型在边缘网络分布式推理中的专家缓存优化问题，降低推理延迟。

Abstract: Mixture-of-Experts (MoE) models improve the scalability of large language
models (LLMs) by activating only a small subset of relevant experts per input.
However, the sheer number of expert networks in an MoE model introduces a
significant storage burden for an edge device. To address this challenge, we
consider a scenario where experts are dispersed within an edge network for
distributed inference. Based on the popular Top-$K$ expert selection strategy,
we formulate a latency minimization problem by optimizing expert caching on
edge servers under storage constraints. When $K=1$, the problem reduces to a
monotone submodular maximization problem with knapsack constraints, for which
we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee.
For the general case where $K\geq1$, expert co-activation within the same MoE
layer introduces non-submodularity, causing greedy methods to be ineffective.
To tackle this issue, we propose a successive greedy decomposition method to
decompose the original problem into a series of subproblems, with each being
solved by a dynamic programming approach. Furthermore, we design an accelerated
algorithm based on the max-convolution technique to obtain the approximate
solution with a provable guarantee in polynomial time. Simulation results on
various MoE models demonstrate that our method significantly reduces inference
latency compared to existing baselines.

</details>


### [41] [KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks](https://arxiv.org/abs/2507.06381)
*James Hazelden,Laura Driscoll,Eli Shlizerman,Eric Shea-Brown*

Main category: cs.LG

TL;DR: 本文研究梯度下降（GD）在循环动力系统训练中的应用，提出梯度流分解方法并展示其两个应用，通过实验和理论验证，提供Pytorch包，推动对非线性循环模型中GD学习的理解。


<details>
  <summary>Details</summary>
Motivation: 尽管有进展，但仍需理论工具严格理解塑造学习表征的机制，尤其是在有限、非线性模型中。

Method: 将描述模型动力学在GD上演变的梯度流分解为参数算子K和线性化流传播子P的乘积。

Result: 展示了两者相互作用产生低维潜在动力学，可用于衡量多任务训练中各子任务目标的对齐情况，实验和理论验证结果良好，提供了Pytorch包KPFlow。

Conclusion: 研究推动了对非线性循环模型中GD学习的下一阶段理解。

Abstract: Gradient Descent (GD) and its variants are the primary tool for enabling
efficient training of recurrent dynamical systems such as Recurrent Neural
Networks (RNNs), Neural ODEs and Gated Recurrent units (GRUs). The dynamics
that are formed in these models exhibit features such as neural collapse and
emergence of latent representations that may support the remarkable
generalization properties of networks. In neuroscience, qualitative features of
these representations are used to compare learning in biological and artificial
systems. Despite recent progress, there remains a need for theoretical tools to
rigorously understand the mechanisms shaping learned representations,
especially in finite, non-linear models. Here, we show that the gradient flow,
which describes how the model's dynamics evolve over GD, can be decomposed into
a product that involves two operators: a Parameter Operator, K, and a
Linearized Flow Propagator, P. K mirrors the Neural Tangent Kernel in
feed-forward neural networks, while P appears in Lyapunov stability and optimal
control theory. We demonstrate two applications of our decomposition. First, we
show how their interplay gives rise to low-dimensional latent dynamics under
GD, and, specifically, how the collapse is a result of the network structure,
over and above the nature of the underlying task. Second, for multi-task
training, we show that the operators can be used to measure how objectives
relevant to individual sub-tasks align. We experimentally and theoretically
validate these findings, providing an efficient Pytorch package, \emph{KPFlow},
implementing robust analysis tools for general recurrent architectures. Taken
together, our work moves towards building a next stage of understanding of GD
learning in non-linear recurrent models.

</details>


### [42] [DICE: Data Influence Cascade in Decentralized Learning](https://arxiv.org/abs/2507.06931)
*Tongtian Zhu,Wenhao Li,Can Wang,Fengxiang He*

Main category: cs.LG

TL;DR: 文章指出分散式学习缺乏激励机制，设计了DICE方法估计数据影响级联，该方法有理论依据且有应用基础。


<details>
  <summary>Details</summary>
Motivation: 分散式学习缺乏合适激励机制，阻碍节点参与，需要对节点贡献进行公平归因。

Method: 设计了在分散式环境中估计数据影响级联（DICE）的方法，框架推导出任意邻居跳数上影响级联的近似值。

Result: 理论上得出影响级联由数据、通信拓扑和损失景观曲率相互作用决定。

Conclusion: DICE方法为选择合适合作者和识别恶意行为等应用奠定基础。

Abstract: Decentralized learning offers a promising approach to crowdsource data
consumptions and computational workloads across geographically distributed
compute interconnected through peer-to-peer networks, accommodating the
exponentially increasing demands. However, proper incentives are still in
absence, considerably discouraging participation. Our vision is that a fair
incentive mechanism relies on fair attribution of contributions to
participating nodes, which faces non-trivial challenges arising from the
localized connections making influence ``cascade'' in a decentralized network.
To overcome this, we design the first method to estimate \textbf{D}ata
\textbf{I}nfluence \textbf{C}ascad\textbf{E} (DICE) in a decentralized
environment. Theoretically, the framework derives tractable approximations of
influence cascade over arbitrary neighbor hops, suggesting the influence
cascade is determined by an interplay of data, communication topology, and the
curvature of loss landscape. DICE also lays the foundations for applications
including selecting suitable collaborators and identifying malicious behaviors.
Project page is available at https://raiden-zhu.github.io/blog/2025/DICE/.

</details>


### [43] [Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning](https://arxiv.org/abs/2507.06402)
*Siddhant Deshpande,Yalemzerf Getnet,Waltenegus Dargie*

Main category: cs.LG

TL;DR: 分析CNN、ResNet和混合Transformer - CNN模型用于心电图篡改检测，以及Siamese网络用于身份验证的性能，实验结果显示模型有高准确率。


<details>
  <summary>Details</summary>
Motivation: 随着无线心电图系统用于健康监测和认证的普及，保护信号完整性以防篡改变得越来越重要。

Method: 模拟六种篡改策略，用连续小波变换将一维心电图信号转换为二维时频表示，用54名受试者在非临床环境下的心电图数据训练和评估模型。

Result: 在高度碎片化操纵场景，部分模型准确率超99.5%；微妙操纵场景，FeatCNN - TranCNN模型平均准确率98%；身份验证中，纯Transformer - Siamese网络平均准确率98.30%，混合CNN - Transformer Siamese模型准确率100%。

Conclusion: CNN、ResNet、混合Transformer - CNN等模型在心电图篡改检测和身份验证方面有良好表现。

Abstract: With the proliferation of wireless electrocardiogram (ECG) systems for health
monitoring and authentication, protecting signal integrity against tampering is
becoming increasingly important. This paper analyzes the performance of CNN,
ResNet, and hybrid Transformer-CNN models for tamper detection. It also
evaluates the performance of a Siamese network for ECG based identity
verification. Six tampering strategies, including structured segment
substitutions and random insertions, are emulated to mimic real world attacks.
The one-dimensional ECG signals are transformed into a two dimensional
representation in the time frequency domain using the continuous wavelet
transform (CWT). The models are trained and evaluated using ECG data from 54
subjects recorded in four sessions 2019 to 2025 outside of clinical settings
while the subjects performed seven different daily activities. Experimental
results show that in highly fragmented manipulation scenarios, CNN,
FeatCNN-TranCNN, FeatCNN-Tran and ResNet models achieved an accuracy exceeding
99.5 percent . Similarly, for subtle manipulations (for example, 50 percent
from A and 50 percent from B and, 75 percent from A and 25 percent from B
substitutions) our FeatCNN-TranCNN model demonstrated consistently reliable
performance, achieving an average accuracy of 98 percent . For identity
verification, the pure Transformer-Siamese network achieved an average accuracy
of 98.30 percent . In contrast, the hybrid CNN-Transformer Siamese model
delivered perfect verification performance with 100 percent accuracy.

</details>


### [44] [Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction](https://arxiv.org/abs/2507.06432)
*Mingcheng Zhu,Yu Liu,Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: 开发了基于领域适应的深度学习框架KnowRare用于预测ICU罕见病临床结果，在多任务中表现优于现有模型，有临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 人工智能虽革新了常见病症的重症监护，但ICU中的罕见病因数据稀缺和病症内异质性而未得到充分服务，需开发新方法。

Method: 开发KnowRare框架，通过自监督预训练从多样电子健康记录中学习与病症无关的表征以缓解数据稀缺，用病症知识图谱选择性适配临床相似病症的知识以解决病症内异质性。

Result: 在两个ICU数据集的五个临床预测任务中，KnowRare始终优于现有先进模型，也优于既定的ICU评分系统；案例研究显示其能适应特定数据集和任务特征，在有限数据下可泛化到常见病症，选择源病症合理。

Conclusion: KnowRare有潜力成为支持临床决策和改善ICU罕见病护理的可靠实用解决方案。

Abstract: Artificial Intelligence has revolutionised critical care for common
conditions. Yet, rare conditions in the intensive care unit (ICU), including
recognised rare diseases and low-prevalence conditions in the ICU, remain
underserved due to data scarcity and intra-condition heterogeneity. To bridge
such gaps, we developed KnowRare, a domain adaptation-based deep learning
framework for predicting clinical outcomes for rare conditions in the ICU.
KnowRare mitigates data scarcity by initially learning condition-agnostic
representations from diverse electronic health records through self-supervised
pre-training. It addresses intra-condition heterogeneity by selectively
adapting knowledge from clinically similar conditions with a developed
condition knowledge graph. Evaluated on two ICU datasets across five clinical
prediction tasks (90-day mortality, 30-day readmission, ICU mortality,
remaining length of stay, and phenotyping), KnowRare consistently outperformed
existing state-of-the-art models. Additionally, KnowRare demonstrated superior
predictive performance compared to established ICU scoring systems, including
APACHE IV and IV-a. Case studies further demonstrated KnowRare's flexibility in
adapting its parameters to accommodate dataset-specific and task-specific
characteristics, its generalisation to common conditions under limited data
scenarios, and its rationality in selecting source conditions. These findings
highlight KnowRare's potential as a robust and practical solution for
supporting clinical decision-making and improving care for rare conditions in
the ICU.

</details>


### [45] [eegFloss: A Python package for refining sleep EEG recordings using machine learning models](https://arxiv.org/abs/2507.06433)
*Niloy Sikder,Paul Zerr,Mahdad Jafarzadeh Esfahani,Martin Dresler,Matthias Krauledat*

Main category: cs.LG

TL;DR: 本文介绍开源Python包eegFloss，利用eegUsability模型检测睡眠EEG记录中的伪影片段，还具备自动检测卧床时间等功能，能提升睡眠研究分析精度和结果可靠性。


<details>
  <summary>Details</summary>
Motivation: EEG信号易受伪影干扰，自动睡眠分期易受伪影影响导致评分错误，需解决此问题。

Method: 引入eegFloss包，使用eegUsability模型，该模型在15名参与者127晚的手动标记EEG数据上训练和评估，还使用eegMobility模型自动检测卧床时间。

Result: eegUsability模型总体分类性能良好（F1分数约0.85，Cohen's kappa为0.78），识别通道可用EEG数据召回率约94%，且不局限于Zmax头带。

Conclusion: eegFloss能解决多数睡眠研究面临的基本挑战，提升分析精度和结果准确性与可靠性。

Abstract: Electroencephalography (EEG) allows monitoring of brain activity, providing
insights into the functional dynamics of various brain regions and their roles
in cognitive processes. EEG is a cornerstone in sleep research, serving as the
primary modality of polysomnography, the gold standard in the field. However,
EEG signals are prone to artifacts caused by both internal (device-specific)
factors and external (environmental) interferences. As sleep studies are
becoming larger, most rely on automatic sleep staging, a process highly
susceptible to artifacts, leading to erroneous sleep scores. This paper
addresses this challenge by introducing eegFloss, an open-source Python package
to utilize eegUsability, a novel machine learning (ML) model designed to detect
segments with artifacts in sleep EEG recordings. eegUsability has been trained
and evaluated on manually artifact-labeled EEG data collected from 15
participants over 127 nights using the Zmax headband. It demonstrates solid
overall classification performance (F1-score is approximately 0.85, Cohens
kappa is 0.78), achieving a high recall rate of approximately 94% in
identifying channel-wise usable EEG data, and extends beyond Zmax.
Additionally, eegFloss offers features such as automatic time-in-bed detection
using another ML model named eegMobility, filtering out certain artifacts, and
generating hypnograms and sleep statistics. By addressing a fundamental
challenge faced by most sleep studies, eegFloss can enhance the precision and
rigor of their analysis as well as the accuracy and reliability of their
outcomes.

</details>


### [46] [Instance-Wise Monotonic Calibration by Constrained Transformation](https://arxiv.org/abs/2507.06516)
*Yunrui Zhang,Gustavo Batista,Salil S. Kanhere*

Main category: cs.LG

TL;DR: 提出新颖单调事后校准方法，解决DNN概率估计校准问题，性能超现有方法。


<details>
  <summary>Details</summary>
Motivation: DNN概率估计常校准不佳且现有事后校准方法难保证单调性，部分方法表达能力有限或缺乏解释性和鲁棒性。

Method: 提出一类新颖单调事后校准方法，将校准图表示为关于类别数量线性参数化的约束优化问题。

Result: 在不同数据集和DNN模型上达到SOTA性能，优于现有校准方法，且数据和计算高效。

Conclusion: 所提方法能保证校准图的单调性、表达能力、鲁棒性和可解释性。

Abstract: Deep neural networks often produce miscalibrated probability estimates,
leading to overconfident predictions. A common approach for calibration is
fitting a post-hoc calibration map on unseen validation data that transforms
predicted probabilities. A key desirable property of the calibration map is
instance-wise monotonicity (i.e., preserving the ranking of probability
outputs). However, most existing post-hoc calibration methods do not guarantee
monotonicity. Previous monotonic approaches either use an under-parameterized
calibration map with limited expressive ability or rely on black-box neural
networks, which lack interpretability and robustness. In this paper, we propose
a family of novel monotonic post-hoc calibration methods, which employs a
constrained calibration map parameterized linearly with respect to the number
of classes. Our proposed approach ensures expressiveness, robustness, and
interpretability while preserving the relative ordering of the probability
output by formulating the proposed calibration map as a constrained
optimization problem. Our proposed methods achieve state-of-the-art performance
across datasets with different deep neural network models, outperforming
existing calibration methods while being data and computation-efficient. Our
code is available at
https://github.com/YunruiZhang/Calibration-by-Constrained-Transformation

</details>


### [47] [Can Interpretation Predict Behavior on Unseen Data?](https://arxiv.org/abs/2507.06445)
*Victoria R. Li,Jenny Kaufmann,Martin Wattenberg,David Alvarez-Melis,Naomi Saphra*

Main category: cs.LG

TL;DR: 本文探讨可解释性用于预测分布外（OOD）模型行为的前景与挑战，发现简单可解释性工具能预测OOD性能。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性研究很少预测模型对未见输入数据的响应，本文旨在探索可解释性在预测OOD模型行为方面的应用。

Method: 在合成分类任务上独立训练数百个Transformer模型，研究注意力模式与OOD泛化的对应关系。

Result: 简单的可解释性观测工具能预测OOD性能，当分布内注意力呈分层模式时，模型在OOD数据上可能分层泛化。

Conclusion: 研究为进一步开展预测未见模型行为的可解释性工作提供概念验证。

Abstract: Interpretability research often aims to predict how a model will respond to
targeted interventions on specific mechanisms. However, it rarely predicts how
a model will respond to unseen input data. This paper explores the promises and
challenges of interpretability as a tool for predicting out-of-distribution
(OOD) model behavior. Specifically, we investigate the correspondence between
attention patterns and OOD generalization in hundreds of Transformer models
independently trained on a synthetic classification task. These models exhibit
several distinct systematic generalization rules OOD, forming a diverse
population for correlational analysis. In this setting, we find that simple
observational tools from interpretability can predict OOD performance. In
particular, when in-distribution attention exhibits hierarchical patterns, the
model is likely to generalize hierarchically on OOD data -- even when the
rule's implementation does not rely on these hierarchical patterns, according
to ablation tests. Our findings offer a proof-of-concept to motivate further
interpretability work on predicting unseen model behavior.

</details>


### [48] [AdaDPIGU: Differentially Private SGD with Adaptive Clipping and Importance-Based Gradient Updates for Deep Neural Networks](https://arxiv.org/abs/2507.06525)
*Huiqi Zhang,Fang Xie*

Main category: cs.LG

TL;DR: 提出AdaDPIGU框架解决差分隐私随机梯度下降在高维的性能问题，理论证明满足差分隐私与收敛性，实验验证有效性，在MNIST和CIFAR - 10上表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私随机梯度下降方法在高维设置中因注入噪声规模随维度增加而性能下降。

Method: 提出AdaDPIGU框架，预训练阶段用差分隐私高斯机制估计参数重要性，梯度更新阶段修剪低重要性坐标并引入坐标自适应裁剪机制。

Result: 理论证明满足(ε, δ) - 差分隐私和收敛保证，实验在MNIST上测试准确率达99.12%，在CIFAR - 10上达73.21%。

Conclusion: 自适应稀疏化可同时提升隐私性和实用性。

Abstract: Differential privacy has been proven effective for stochastic gradient
descent; however, existing methods often suffer from performance degradation in
high-dimensional settings, as the scale of injected noise increases with
dimensionality. To tackle this challenge, we propose AdaDPIGU--a new
differentially private SGD framework with importance-based gradient updates
tailored for deep neural networks. In the pretraining stage, we apply a
differentially private Gaussian mechanism to estimate the importance of each
parameter while preserving privacy. During the gradient update phase, we prune
low-importance coordinates and introduce a coordinate-wise adaptive clipping
mechanism, enabling sparse and noise-efficient gradient updates. Theoretically,
we prove that AdaDPIGU satisfies $(\varepsilon, \delta)$-differential privacy
and retains convergence guarantees. Extensive experiments on standard
benchmarks validate the effectiveness of AdaDPIGU. All results are reported
under a fixed retention ratio of 60%. On MNIST, our method achieves a test
accuracy of 99.12% under a privacy budget of $\epsilon = 8$, nearly matching
the non-private model. Remarkably, on CIFAR-10, it attains 73.21% accuracy at
$\epsilon = 4$, outperforming the non-private baseline of 71.12%, demonstrating
that adaptive sparsification can enhance both privacy and utility.

</details>


### [49] [Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models](https://arxiv.org/abs/2507.06458)
*Arjun Banerjee,David Martinez,Camille Dang,Ethan Tam*

Main category: cs.LG

TL;DR: 提出为蛋白质语言模型神经元标注的框架，开发激活引导方法生成特定蛋白质，并揭示模型缩放定律和神经元空间分布。


<details>
  <summary>Details</summary>
Motivation: 蛋白质语言模型内部神经元表征理解不足，需对其进行研究。

Method: 引入自动化框架为PLM每个神经元进行生物自然语言描述标注，开发神经元激活引导方法生成蛋白质。

Result: 能揭示单个神经元对不同生化和结构特性的选择性敏感性，可使生成蛋白质收敛到目标生化特性和结构基序，分析标注神经元揭示PLM缩放定律和结构化神经元空间分布。

Conclusion: 所提出的方法有助于理解PLM内部神经元表征，可用于生成特定蛋白质并发现模型相关规律。

Abstract: Protein language models (PLMs) encode rich biological information, yet their
internal neuron representations are poorly understood. We introduce the first
automated framework for labeling every neuron in a PLM with biologically
grounded natural language descriptions. Unlike prior approaches relying on
sparse autoencoders or manual annotation, our method scales to hundreds of
thousands of neurons, revealing individual neurons are selectively sensitive to
diverse biochemical and structural properties. We then develop a novel neuron
activation-guided steering method to generate proteins with desired traits,
enabling convergence to target biochemical properties like molecular weight and
instability index as well as secondary and tertiary structural motifs,
including alpha helices and canonical Zinc Fingers. We finally show that
analysis of labeled neurons in different model sizes reveals PLM scaling laws
and a structured neuron space distribution.

</details>


### [50] [Steps Adaptive Decay DPSGD: Enhancing Performance on Imbalanced Datasets with Differential Privacy with HAM10000](https://arxiv.org/abs/2507.06619)
*Xiaobo Huang,Fang Xie*

Main category: cs.LG

TL;DR: 提出SAD - DPSGD方法解决医疗图像分类数据泄漏问题，实验显示其在HAM10000上优于Auto - DPSGD。


<details>
  <summary>Details</summary>
Motivation: 现有方法在小的、不平衡的医疗数据集（如HAM10000）上处理数据泄漏问题失败，因数据分布不平衡导致模型陷入次优解。

Method: 提出SAD - DPSGD，采用线性衰减机制处理噪声和裁剪阈值，在初始训练阶段分配更多隐私预算和使用更高裁剪阈值。

Result: SAD - DPSGD在HAM10000上优于Auto - DPSGD，在ε = 3.0，δ = 10⁻³时准确率提高2.15%。

Conclusion: SAD - DPSGD能有效避免模型陷入次优解，提升在不平衡医疗数据集上的性能。

Abstract: When applying machine learning to medical image classification, data leakage
is a critical issue. Previous methods, such as adding noise to gradients for
differential privacy, work well on large datasets like MNIST and CIFAR-100, but
fail on small, imbalanced medical datasets like HAM10000. This is because the
imbalanced distribution causes gradients from minority classes to be clipped
and lose crucial information, while majority classes dominate. This leads the
model to fall into suboptimal solutions early. To address this, we propose
SAD-DPSGD, which uses a linear decaying mechanism for noise and clipping
thresholds. By allocating more privacy budget and using higher clipping
thresholds in the initial training phases, the model avoids suboptimal
solutions and enhances performance. Experiments show that SAD-DPSGD outperforms
Auto-DPSGD on HAM10000, improving accuracy by 2.15% under $\epsilon = 3.0$ ,
$\delta = 10^{-3}$.

</details>


### [51] [SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam](https://arxiv.org/abs/2507.06464)
*Hanyang Peng,Shuang Qin,Yue Yu,Fangqing Jiang,Hui Wang,Wen Gao*

Main category: cs.LG

TL;DR: 论文指出Adam优缺点，提出新优化器SignSoftSGD（S3），有三项创新，理论证明收敛率，实验显示S3收敛快、少损失尖峰、性能优。


<details>
  <summary>Details</summary>
Motivation: 探索Adam经验成功和局限的机制，增强其优势并减轻其局限性。

Method: 提出SignSoftSGD（S3）优化器，采用灵活p阶动量、统一指数移动平均系数、引入等效Nesterov加速梯度模块。

Result: 理论证明S3在弱假设下对一般非凸随机优化有最优收敛率；实验表明S3收敛更快、性能更好、少损失尖峰，表现优于AdamW。

Conclusion: SignSoftSGD（S3）在效率和最终任务性能上有效。

Abstract: Adam has proven remarkable successful in training deep neural networks, but
the mechanisms underlying its empirical successes and limitations remain
underexplored. In this study, we demonstrate that the effectiveness of Adam
stems largely from its similarity to SignSGD in robustly handling large
gradient fluctuations, yet it is also vulnerable to destabilizing loss spikes
due to its uncontrolled update scaling. To enhance the advantage of Adam and
mitigate its limitation, we propose SignSoftSGD (S3), a novel optimizer with
three key innovations. \emph{First}, S3 generalizes the sign-like update by
employing a flexible $p$-th order momentum ($p \geq 1$) in the denominator,
departing from the conventional second-order momentum (variance)
preconditioning. This design enables enhanced performance while achieving
stable training even with aggressive learning rates. \emph{Second}, S3
minimizes the occurrences of loss spikes through unified exponential moving
average coefficients for numerator and denominator momenta, which inherently
bound updates to $[-1, 1]$ and simplify hyperparameter tuning. \emph{Third}, S3
incorporates an equivalent Nesterov's accelerated gradient(NAG) module,
accelerating convergence without memory overhead. Theoretically, we prove that
S3 achieves the optimal convergence rate of
$O\left(\frac{1}{T^{\sfrac{1}{4}}}\right)$ for general nonconvex stochastic
optimization under weak assumptions. Extensive experiments across a range of
vision and language tasks show that \textsf{\small S3} not only converges more
rapidly and improves performance but also rarely experiences loss spikes, even
with a \textbf{$\bm{10 \times}$} larger learning rate. In fact, S3 delivers
performance comparable to or better than AdamW with \textbf{$2 \times$} the
training steps, establishing its efficacy in both efficiency and final task
performance.

</details>


### [52] [Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](https://arxiv.org/abs/2507.06466)
*Aaron Dharna,Cong Lu,Jeff Clune*

Main category: cs.LG

TL;DR: 提出Foundation - Model Self - Play (FMSP) 方法解决自玩算法问题，在Car Tag和Gandalf中评估效果良好，是有前景的研究方向。


<details>
  <summary>Details</summary>
Motivation: 自玩算法常无法产生多样解且易陷入局部最优，需新方法克服这些挑战。

Method: 提出包含Vanilla Foundation - Model Self - Play (vFMSP)、Novelty - Search Self - Play (NSSP) 和Quality - Diveristy Self - Play (QDSP) 的FMSP方法。

Result: 在Car Tag中，FMSP探索多种方法，发现的策略质量超人类设计策略；在Gandalf中，FMSP能自动红队测试大模型，突破防御并修复漏洞。

Conclusion: FMSP是利用基础模型改进自玩的有前景新研究方向，为策略发现开辟新路径。

Abstract: Multi-agent interactions have long fueled innovation, from natural
predator-prey dynamics to the space race. Self-play (SP) algorithms try to
harness these dynamics by pitting agents against ever-improving opponents,
thereby creating an implicit curriculum toward learning high-quality solutions.
However, SP often fails to produce diverse solutions and can get stuck in
locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a
new direction that leverages the code-generation capabilities and vast
knowledge of foundation models (FMs) to overcome these challenges by leaping
across local optima in policy space. We propose a family of approaches: (1)
\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent
policies via competitive self-play; (2) \textbf{Novelty-Search Self-Play
(NSSP)} builds a diverse population of strategies, ignoring performance; and
(3) the most promising variant, \textbf{Quality-Diveristy Self-Play (QDSP)},
creates a diverse set of high-quality policies by combining the diversity of
NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a
continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety
simulation in which an attacker tries to jailbreak an LLM's defenses. In Car
Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and
heuristic-based methods, to name just a few. In terms of discovered policy
quality, \ouralgo and vFMSP surpass strong human-designed strategies. In
Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through
and jailbreaking six different, progressively stronger levels of defense.
Furthermore, FMSPs can automatically proceed to patch the discovered
vulnerabilities. Overall, FMSPs represent a promising new research frontier of
improving self-play with foundation models, opening fresh paths toward more
creative and open-ended strategy discovery

</details>


### [53] [Mathematical artificial data for operator learning](https://arxiv.org/abs/2507.06752)
*Heng Wu,Benzhuo Lu*

Main category: cs.LG

TL;DR: 提出MAD框架结合物理定律与数据驱动学习进行大规模算子发现，通过生成物理嵌入的解析解和合成数据，消除对训练数据依赖，经数值演示展现其优势，有潜力成通用范式。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习求解微分方程方法存在数据驱动方法需昂贵标记数据集、模型驱动技术有效率 - 精度权衡的局限。

Method: 提出Mathematical Artificial Data (MAD)框架，利用微分方程的内在数学结构生成物理嵌入的解析解和相关合成数据。

Result: 通过二维参数问题的数值演示，展示了MAD在各种微分方程场景中的泛化性和优越的效率/精度。

Conclusion: 该物理嵌入的数据驱动框架有潜力成为科学计算中物理信息机器智能的通用范式。

Abstract: Machine learning has emerged as a transformative tool for solving
differential equations (DEs), yet prevailing methodologies remain constrained
by dual limitations: data-driven methods demand costly labeled datasets while
model-driven techniques face efficiency-accuracy trade-offs. We present the
Mathematical Artificial Data (MAD) framework, a new paradigm that integrates
physical laws with data-driven learning to facilitate large-scale operator
discovery. By exploiting DEs' intrinsic mathematical structure to generate
physics-embedded analytical solutions and associated synthetic data, MAD
fundamentally eliminates dependence on experimental or simulated training data.
This enables computationally efficient operator learning across multi-parameter
systems while maintaining mathematical rigor. Through numerical demonstrations
spanning 2D parametric problems where both the boundary values and source term
are functions, we showcase MAD's generalizability and superior
efficiency/accuracy across various DE scenarios. This
physics-embedded-data-driven framework and its capacity to handle complex
parameter spaces gives it the potential to become a universal paradigm for
physics-informed machine intelligence in scientific computing.

</details>


### [54] [Robust and Safe Traffic Sign Recognition using N-version with Weighted Voting](https://arxiv.org/abs/2507.06907)
*Linyun Gao,Qiang Wen,Fumio Machida*

Main category: cs.LG

TL;DR: 提出集成安全感知加权软投票机制的NVML框架提升交通标志识别系统在对抗条件下的鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中交通标志识别易受对抗攻击威胁驾驶安全，需提升其安全性。

Method: 提出NVML框架，用FMEA评估安全风险并分配动态权重，评估三种版本NVML系统在不同投票机制下对抗FGSM和PGD攻击生成的对抗样本的鲁棒性。

Result: NVML方法显著增强了交通标志识别系统在对抗条件下的鲁棒性和安全性。

Conclusion: NVML框架能有效提升交通标志识别系统在对抗条件下的性能。

Abstract: Autonomous driving is rapidly advancing as a key application of machine
learning, yet ensuring the safety of these systems remains a critical
challenge. Traffic sign recognition, an essential component of autonomous
vehicles, is particularly vulnerable to adversarial attacks that can compromise
driving safety. In this paper, we propose an N-version machine learning (NVML)
framework that integrates a safety-aware weighted soft voting mechanism. Our
approach utilizes Failure Mode and Effects Analysis (FMEA) to assess potential
safety risks and assign dynamic, safety-aware weights to the ensemble outputs.
We evaluate the robustness of three-version NVML systems employing various
voting mechanisms against adversarial samples generated using the Fast Gradient
Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks. Experimental
results demonstrate that our NVML approach significantly enhances the
robustness and safety of traffic sign recognition systems under adversarial
conditions.

</details>


### [55] [Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning](https://arxiv.org/abs/2507.06469)
*Yudan Song,Yuecen Wei,Yuhang Lu,Qingyun Sun,Minglai Shao,Li-e Wang,Chunming Hu,Xianxian Li,Xingcheng Fu*

Main category: cs.LG

TL;DR: 论文指出图表示学习用于欺诈检测存在问题，提出MimbFD方法，实验证明其在欺诈检测中性能出色。


<details>
  <summary>Details</summary>
Motivation: 图表示学习用于欺诈检测时，存在全局拓扑信息传输不平衡和节点特定信息易被淹没的问题，欺诈者的拓扑行为混淆和身份特征隐藏导致监督消息不平衡。

Method: 提出一种新颖的双视图图表示学习方法MimbFD，设计拓扑消息可达性模块用于高质量节点表示学习，引入局部混淆去偏模块调整节点表示。

Result: 在三个公共欺诈数据集上进行实验，MimbFD在欺诈检测中表现出色。

Conclusion: MimbFD方法能有效缓解欺诈检测中的消息不平衡问题，提升欺诈检测性能。

Abstract: Graph representation learning has become a mainstream method for fraud
detection due to its strong expressive power, which focuses on enhancing node
representations through improved neighborhood knowledge capture. However, the
focus on local interactions leads to imbalanced transmission of global
topological information and increased risk of node-specific information being
overwhelmed during aggregation due to the imbalance between fraud and benign
nodes. In this paper, we first summarize the impact of topology and class
imbalance on downstream tasks in GNN-based fraud detection, as the problem of
imbalanced supervisory messages is caused by fraudsters' topological behavior
obfuscation and identity feature concealment. Based on statistical validation,
we propose a novel dual-view graph representation learning method to mitigate
Message imbalance in Fraud Detection(MimbFD). Specifically, we design a
topological message reachability module for high-quality node representation
learning to penetrate fraudsters' camouflage and alleviate insufficient
propagation. Then, we introduce a local confounding debiasing module to adjust
node representations, enhancing the stable association between node
representations and labels to balance the influence of different classes.
Finally, we conducted experiments on three public fraud datasets, and the
results demonstrate that MimbFD exhibits outstanding performance in fraud
detection.

</details>


### [56] [Mutual Information Free Topological Generalization Bounds via Stability](https://arxiv.org/abs/2507.06775)
*Mario Tuci,Lennart Bastian,Benjamin Dupuis,Nassir Navab,Tolga Birdal,Umut Şimşekli*

Main category: cs.LG

TL;DR: 本文旨在提出不含难处理互信息项的拓扑泛化界，引入新框架，证明轨迹稳定算法泛化误差上界，并通过实验验证TDA项的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有拓扑泛化界依赖难处理的信息论项，对实际算法难以计算，降低了界的相关性，因此要提出无难处理项的泛化界。

Method: 引入基于算法稳定性证明技术的新学习理论框架，将假设集稳定性扩展到轨迹稳定性。

Result: 证明了轨迹稳定算法泛化误差上界与TDA量和轨迹稳定性参数有关，实验表明界中的TDA项很重要。

Conclusion: 新的拓扑泛化界可解释之前拓扑泛化界的经验成功，且TDA项在训练样本增多时尤为重要。

Abstract: Providing generalization guarantees for stochastic optimization algorithms is
a major challenge in modern learning theory. Recently, several studies
highlighted the impact of the geometry of training trajectories on the
generalization error, both theoretically and empirically. Among these works, a
series of topological generalization bounds have been proposed, relating the
generalization error to notions of topological complexity that stem from
topological data analysis (TDA). Despite their empirical success, these bounds
rely on intricate information-theoretic (IT) terms that can be bounded in
specific cases but remain intractable for practical algorithms (such as ADAM),
potentially reducing the relevance of the derived bounds. In this paper, we
seek to formulate comprehensive and interpretable topological generalization
bounds free of intractable mutual information terms. To this end, we introduce
a novel learning theoretic framework that departs from the existing strategies
via proof techniques rooted in algorithmic stability. By extending an existing
notion of \textit{hypothesis set stability}, to \textit{trajectory stability},
we prove that the generalization error of trajectory-stable algorithms can be
upper bounded in terms of (i) TDA quantities describing the complexity of the
trajectory of the optimizer in the parameter space, and (ii) the trajectory
stability parameter of the algorithm. Through a series of experimental
evaluations, we demonstrate that the TDA terms in the bound are of great
importance, especially as the number of training samples grows. This ultimately
forms an explanation of the empirical success of the topological generalization
bounds.

</details>


### [57] [FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning](https://arxiv.org/abs/2507.06482)
*Huan Wang,Haoran Li,Huaming Chen,Jun Yan,Jiahua Shi,Jun Shen*

Main category: cs.LG

TL;DR: 本文将扩散模型引入联邦学习，提出FedDifRC范式应对数据异构问题，可扩展为无监督方案，有理论分析且实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 联邦学习存在数据异构问题，影响模型收敛和性能，需新方法解决。

Method: 提出FedDifRC范式，构建文本驱动扩散对比和噪声驱动扩散正则化，还可扩展为自监督方案并进行理论分析。

Result: 不同场景实验验证了FedDifRC的有效性和关键组件的效率。

Conclusion: 引入扩散模型的FedDifRC范式能有效缓解联邦学习中的数据异构问题。

Abstract: Federated learning aims at training models collaboratively across
participants while protecting privacy. However, one major challenge for this
paradigm is the data heterogeneity issue, where biased data preferences across
multiple clients, harming the model's convergence and performance. In this
paper, we first introduce powerful diffusion models into the federated learning
paradigm and show that diffusion representations are effective steers during
federated training. To explore the possibility of using diffusion
representations in handling data heterogeneity, we propose a novel
diffusion-inspired Federated paradigm with Diffusion Representation
Collaboration, termed FedDifRC, leveraging meaningful guidance of diffusion
models to mitigate data heterogeneity. The key idea is to construct text-driven
diffusion contrasting and noise-driven diffusion regularization, aiming to
provide abundant class-related semantic information and consistent convergence
signals. On the one hand, we exploit the conditional feedback from the
diffusion model for different text prompts to build a text-driven contrastive
learning strategy. On the other hand, we introduce a noise-driven consistency
regularization to align local instances with diffusion denoising
representations, constraining the optimization region in the feature space. In
addition, FedDifRC can be extended to a self-supervised scheme without relying
on any labeled data. We also provide a theoretical analysis for FedDifRC to
ensure convergence under non-convex objectives. The experiments on different
scenarios validate the effectiveness of FedDifRC and the efficiency of crucial
components.

</details>


### [58] [Scalable Gaussian Processes: Advances in Iterative Methods and Pathwise Conditioning](https://arxiv.org/abs/2507.06839)
*Jihao Andreas Lin*

Main category: cs.LG

TL;DR: 论文聚焦迭代方法和路径条件化结合，提升高斯过程在大规模场景下的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 经典高斯过程在处理大量数据和利用现代并行计算硬件时可扩展性不佳，需开发改进技术。

Method: 将迭代方法和路径条件化结合，把昂贵计算转化为线性方程组求解，利用迭代线性系统求解器。

Result: 大幅降低内存需求，适用于更多数据，以矩阵乘法为主要计算操作，适配现代硬件。

Conclusion: 迭代方法和路径条件化的结合有助于高斯过程在现代大规模场景下的应用。

Abstract: Gaussian processes are a powerful framework for uncertainty-aware function
approximation and sequential decision-making. Unfortunately, their classical
formulation does not scale gracefully to large amounts of data and modern
hardware for massively-parallel computation, prompting many researchers to
develop techniques which improve their scalability. This dissertation focuses
on the powerful combination of iterative methods and pathwise conditioning to
develop methodological contributions which facilitate the use of Gaussian
processes in modern large-scale settings. By combining these two techniques
synergistically, expensive computations are expressed as solutions to systems
of linear equations and obtained by leveraging iterative linear system solvers.
This drastically reduces memory requirements, facilitating application to
significantly larger amounts of data, and introduces matrix multiplication as
the main computational operation, which is ideal for modern hardware.

</details>


### [59] [MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models](https://arxiv.org/abs/2507.06502)
*Yiwen Liu,Chenyu Zhang,Junjie Song,Siqi Chen,Sun Yin,Zihan Wang,Lingming Zeng,Yuji Cao,Junming Jiao*

Main category: cs.LG

TL;DR: 提出MoFE - Time时间序列预测模型，结合时频特征，采用预训练 - 微调范式，在多个基准测试和实际数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有模型在预训练 - 微调范式中难以同时建模时间和频率特征，复杂时间序列预测性能不佳。

Method: 在混合专家网络中集成时频域特征，采用预训练 - 微调范式，引入时频单元作为专家，利用MoE路由机制构建输入信号的多维稀疏表示。

Result: 在六个公共基准测试中取得新的最优性能，相比Time - MoE，MSE和MAE分别降低6.95%和6.02%；在自制数据集NEV - sales上也有出色表现。

Conclusion: MoFE - Time模型在实际商业应用中有效。

Abstract: As a prominent data modality task, time series forecasting plays a pivotal
role in diverse applications. With the remarkable advancements in Large
Language Models (LLMs), the adoption of LLMs as the foundational architecture
for time series modeling has gained significant attention. Although existing
models achieve some success, they rarely both model time and frequency
characteristics in a pretraining-finetuning paradigm leading to suboptimal
performance in predictions of complex time series, which requires both modeling
periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an
innovative time series forecasting model that integrates time and frequency
domain features within a Mixture of Experts (MoE) network. Moreover, we use the
pretraining-finetuning paradigm as our training framework to effectively
transfer prior pattern knowledge across pretraining and finetuning datasets
with different periodicity distributions. Our method introduces both frequency
and time cells as experts after attention modules and leverages the MoE routing
mechanism to construct multidimensional sparse representations of input
signals. In experiments on six public benchmarks, MoFE-Time has achieved new
state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared
to the representative methods Time-MoE. Beyond the existing evaluation
benchmarks, we have developed a proprietary dataset, NEV-sales, derived from
real-world business scenarios. Our method achieves outstanding results on this
dataset, underscoring the effectiveness of the MoFE-Time model in practical
commercial applications.

</details>


### [60] [Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy](https://arxiv.org/abs/2507.06969)
*Bogdan Kulynych,Juan Felipe Gomez,Georgios Kaissis,Jamie Hayes,Borja Balle,Flavio du Pin Calmon,Jean Louis Raisaro*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Differentially private (DP) mechanisms are difficult to interpret and
calibrate because existing methods for mapping standard privacy parameters to
concrete privacy risks -- re-identification, attribute inference, and data
reconstruction -- are both overly pessimistic and inconsistent. In this work,
we use the hypothesis-testing interpretation of DP ($f$-DP), and determine that
bounds on attack success can take the same unified form across
re-identification, attribute inference, and data reconstruction risks. Our
unified bounds are (1) consistent across a multitude of attack settings, and
(2) tunable, enabling practitioners to evaluate risk with respect to arbitrary
(including worst-case) levels of baseline risk. Empirically, our results are
tighter than prior methods using $\varepsilon$-DP, R\'enyi DP, and concentrated
DP. As a result, calibrating noise using our bounds can reduce the required
noise by 20% at the same risk level, which yields, e.g., more than 15pp
accuracy increase in a text classification task. Overall, this unifying
perspective provides a principled framework for interpreting and calibrating
the degree of protection in DP against specific levels of re-identification,
attribute inference, or data reconstruction risk.

</details>


### [61] [Direct Regret Optimization in Bayesian Optimization](https://arxiv.org/abs/2507.06529)
*Fengxue Zhang,Yuxin Chen*

Main category: cs.LG

TL;DR: 本文提出一种新的直接后悔优化方法，联合学习最优模型和非短视采集策略，实验显示优于传统贝叶斯优化方法。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化方法依赖手工采集函数和代理模型，且常为短视操作，需要改进。

Method: 提出直接后悔优化方法，利用不同超参数的高斯过程集合生成模拟轨迹，训练端到端决策变换器，采用密集训练 - 稀疏学习范式。

Result: 在合成和现实世界基准测试中，该方法始终优于贝叶斯优化基线，简单后悔值更低，在高维或有噪声环境中探索更稳健。

Conclusion: 所提出的方法在贝叶斯优化中表现良好，有实际应用价值。

Abstract: Bayesian optimization (BO) is a powerful paradigm for optimizing expensive
black-box functions. Traditional BO methods typically rely on separate
hand-crafted acquisition functions and surrogate models for the underlying
function, and often operate in a myopic manner. In this paper, we propose a
novel direct regret optimization approach that jointly learns the optimal model
and non-myopic acquisition by distilling from a set of candidate models and
acquisitions, and explicitly targets minimizing the multi-step regret. Our
framework leverages an ensemble of Gaussian Processes (GPs) with varying
hyperparameters to generate simulated BO trajectories, each guided by an
acquisition function chosen from a pool of conventional choices, until a
Bayesian early stop criterion is met. These simulated trajectories, capturing
multi-step exploration strategies, are used to train an end-to-end decision
transformer that directly learns to select next query points aimed at improving
the ultimate objective. We further adopt a dense training--sparse learning
paradigm: The decision transformer is trained offline with abundant simulated
data sampled from ensemble GPs and acquisitions, while a limited number of real
evaluations refine the GPs online. Experimental results on synthetic and
real-world benchmarks suggest that our method consistently outperforms BO
baselines, achieving lower simple regret and demonstrating more robust
exploration in high-dimensional or noisy settings.

</details>


### [62] [Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits](https://arxiv.org/abs/2507.06535)
*Shan Shen,Shenglu Hua,Jiajun Zou,Jiawei Liu,Jianwang Zhai,Chuan Shi,Wenjian Yu*

Main category: cs.LG

TL;DR: 提出CircuitGCL框架解决模拟混合信号电路图表示学习难题，在相关任务上超现有方法。


<details>
  <summary>Details</summary>
Motivation: 模拟混合信号电路图表示学习存在设计数据稀缺、标签分布不平衡和电路实现多样性等问题，影响学习鲁棒和可迁移的电路表示。

Method: 提出CircuitGCL框架，采用自监督策略通过超球面表示散射学习拓扑不变节点嵌入，引入平衡均方误差和软最大交叉熵损失缓解标签分布差异。

Result: 在台积电28nm模拟混合信号设计的寄生电容估计和接地电容分类任务中，CircuitGCL优于所有现有方法，边缘回归R²提升33.64% - 44.20%，节点分类F1得分提高0.9 - 2.1倍。

Conclusion: CircuitGCL框架有效解决现有问题，在相关任务表现出色。

Abstract: Graph representation learning on Analog-Mixed Signal (AMS) circuits is
crucial for various downstream tasks, e.g., parasitic estimation. However, the
scarcity of design data, the unbalanced distribution of labels, and the
inherent diversity of circuit implementations pose significant challenges to
learning robust and transferable circuit representations. To address these
limitations, we propose CircuitGCL, a novel graph contrastive learning
framework that integrates representation scattering and label rebalancing to
enhance transferability across heterogeneous circuit graphs. CircuitGCL employs
a self-supervised strategy to learn topology-invariant node embeddings through
hyperspherical representation scattering, eliminating dependency on large-scale
data. Simultaneously, balanced mean squared error (MSE) and softmax
cross-entropy (bsmCE) losses are introduced to mitigate label distribution
disparities between circuits, enabling robust and transferable parasitic
estimation. Evaluated on parasitic capacitance estimation (edge-level task) and
ground capacitance classification (node-level task) across TSMC 28nm AMS
designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the
$R^2$ improvement of $33.64\% \sim 44.20\%$ for edge regression and F1-score
gain of $0.9\times \sim 2.1\times$ for node classification. Our code is
available at
\href{https://anonymous.4open.science/r/CircuitGCL-099B/README.md}{here}.

</details>


### [63] [Few-shot Learning on AMS Circuits and Its Application to Parasitic Capacitance Prediction](https://arxiv.org/abs/2507.06538)
*Shan Shen,Yibin Zhang,Hector Rodriguez Rodriguez,Wenjian Yu*

Main category: cs.LG

TL;DR: 提出CircuitGPS用于AMS电路寄生效应预测，以小样本学习提高预测精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决训练AMS设计深度学习模型时集成电路设计数据稀缺的问题。

Method: 将电路网表表示为异构图，对耦合电容建模；采用小跳采样技术转换子图，用混合图Transformer学习子图嵌入，集成低成本位置编码。先预训练链接预测，再微调边缘回归。

Result: 相比现有方法，提高耦合存在性准确率至少20%，降低电容估计MAE至少0.067，具有强可扩展性，可零样本学习应用于多种设计。

Conclusion: 该方法有效，消融研究为图表示学习提供有价值见解。

Abstract: Graph representation learning is a powerful method to extract features from
graph-structured data, such as analog/mixed-signal (AMS) circuits. However,
training deep learning models for AMS designs is severely limited by the
scarcity of integrated circuit design data. In this work, we present
CircuitGPS, a few-shot learning method for parasitic effect prediction in AMS
circuits. The circuit netlist is represented as a heterogeneous graph, with the
coupling capacitance modeled as a link. CircuitGPS is pre-trained on link
prediction and fine-tuned on edge regression. The proposed method starts with a
small-hop sampling technique that converts a link or a node into a subgraph.
Then, the subgraph embeddings are learned with a hybrid graph Transformer.
Additionally, CircuitGPS integrates a low-cost positional encoding that
summarizes the positional and structural information of the sampled subgraph.
CircuitGPS improves the accuracy of coupling existence by at least 20\% and
reduces the MAE of capacitance estimation by at least 0.067 compared to
existing methods. Our method demonstrates strong inherent scalability, enabling
direct application to diverse AMS circuit designs through zero-shot learning.
Furthermore, the ablation studies provide valuable insights into graph models
for representation learning.

</details>


### [64] [Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs](https://arxiv.org/abs/2507.06549)
*Shan Shen,Dingcheng Yang,Yuyang Xie,Chunyan Pei,Wenjian Yu,Bei Yu*

Main category: cs.LG

TL;DR: 本文提出基于深度学习的两阶段模型预测SRAM电路预布局阶段的寄生效应，实验表明该方法优于现有模型，能降低误差并加速仿真。


<details>
  <summary>Details</summary>
Motivation: SRAM定制时寄生效应导致前后仿真差异大、设计参数难收敛和迭代过多，希望基于预布局电路预测寄生效应进行预布局仿真。

Method: 提出结合图神经网络分类器和多层感知器回归器的两阶段模型，用Focal Loss减轻内部网络样本影响，将子电路信息集成到图中抽象原理图层次结构。

Result: 在4个真实SRAM设计上实验，误差最多降低19倍，仿真速度最多提升598倍。

Conclusion: 所提方法能准确预测预布局阶段的寄生效应，优于现有模型，可提高系统能效。

Abstract: To achieve higher system energy efficiency, SRAM in SoCs is often customized.
The parasitic effects cause notable discrepancies between pre-layout and
post-layout circuit simulations, leading to difficulty in converging design
parameters and excessive design iterations. Is it possible to well predict the
parasitics based on the pre-layout circuit, so as to perform parasitic-aware
pre-layout simulation? In this work, we propose a deep-learning-based 2-stage
model to accurately predict these parasitics in pre-layout stages. The model
combines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron
(MLP) regressors, effectively managing class imbalance of the net parasitics in
SRAM circuits. We also employ Focal Loss to mitigate the impact of abundant
internal net samples and integrate subcircuit information into the graph to
abstract the hierarchical structure of schematics. Experiments on 4 real SRAM
designs show that our approach not only surpasses the state-of-the-art model in
parasitic prediction by a maximum of 19X reduction of error but also
significantly boosts the simulation process by up to 598X speedup.

</details>


### [65] [The Primacy of Magnitude in Low-Rank Adaptation](https://arxiv.org/abs/2507.06558)
*Zicheng Zhang,Haoran Li,Yifeng Zhang,Guoqiang Gong,Jiaxing Wang,Pengzhang Liu,Qixia Jiang,Junxing Hu*

Main category: cs.LG

TL;DR: 本文建立更新幅度为LoRA性能的基本驱动因素，提出无额外开销的初始化方案LoRAM，实验表明其能保持效率并匹配或超越光谱初始化方法。


<details>
  <summary>Details</summary>
Motivation: 现有光谱初始化方法虽提升性能，但有额外计算和存储开销，影响效率。

Method: 建立更新幅度为驱动因素，提出基于幅度的“Basis & Basis”初始化方案LoRAM，通过预训练权重幅度缩放确定性正交基模拟光谱增益。

Result: 实验表明LoRAM能保持LoRA的全部效率，在多个基准测试中匹配或超越光谱初始化方法。

Conclusion: LoRAM可作为强大基线，有效解决现有光谱初始化方法的效率问题。

Abstract: Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning
large models. While recent spectral initialization methods improve convergence
and performance over the naive "Noise & Zeros" scheme, their extra
computational and storage overhead undermines efficiency. In this paper, we
establish update magnitude as the fundamental driver of LoRA performance and
propose LoRAM, a magnitude-driven "Basis & Basis" initialization scheme that
matches spectral methods without their inefficiencies. Our key contributions
are threefold: (i) Magnitude of weight updates determines convergence. We prove
low-rank structures intrinsically bound update magnitudes, unifying
hyperparameter tuning in learning rate, scaling factor, and initialization as
mechanisms to optimize magnitude regulation. (ii) Spectral initialization
succeeds via magnitude amplification. We demystify that the presumed
knowledge-driven benefit of the spectral component essentially arises from the
boost in the weight update magnitude. (iii) A novel and compact initialization
strategy, LoRAM, scales deterministic orthogonal bases using pretrained weight
magnitudes to simulate spectral gains. Extensive experiments show that LoRAM
serves as a strong baseline, retaining the full efficiency of LoRA while
matching or outperforming spectral initialization across benchmarks.

</details>


### [66] [From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization](https://arxiv.org/abs/2507.06573)
*Xinjie Chen,Minpeng Liao,Guoxin Chen,Chengxi Li,Biao Fu,Kai Fan,Xinggao Liu*

Main category: cs.LG

TL;DR: 本文从样本角度研究带可验证奖励的强化学习（RLVR），提出LPPO框架，含前缀引导采样和学习进度加权方法，实验表明其优于基线。


<details>
  <summary>Details</summary>
Motivation: 已有工作强调算法设计等，本文从样本角度出发，解决如何利用少量高质量演示样本的问题。

Method: 提出前缀引导采样的在线数据增强方法，利用专家演示的部分解决方案前缀引导策略；引入学习进度加权动态策略，根据模型进展调整训练样本影响。

Result: 在数学推理基准测试中，方法优于强基线，收敛更快，性能上限更高。

Conclusion: 所提出的LPPO框架能有效利用少量高质量演示样本，提升大语言模型推理能力。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has recently advanced
the reasoning capabilities of large language models (LLMs). While prior work
has emphasized algorithmic design, data curation, and reward shaping, we
investigate RLVR from a sample-centric perspective and introduce LPPO
(Learning-Progress and Prefix-guided Optimization), a framework of progressive
optimization techniques. Our work addresses a critical question: how to best
leverage a small set of trusted, high-quality demonstrations, rather than
simply scaling up data volume. First, motivated by how hints aid human
problem-solving, we propose prefix-guided sampling, an online data augmentation
method that incorporates partial solution prefixes from expert demonstrations
to guide the policy, particularly for challenging instances. Second, inspired
by how humans focus on important questions aligned with their current
capabilities, we introduce learning-progress weighting, a dynamic strategy that
adjusts each training sample's influence based on model progression. We
estimate sample-level learning progress via an exponential moving average of
per-sample pass rates, promoting samples that foster learning and
de-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks
demonstrate that our methods outperform strong baselines, yielding faster
convergence and a higher performance ceiling.

</details>


### [67] [Learning controllable dynamics through informative exploration](https://arxiv.org/abs/2507.06582)
*Peter N. Loxley,Friedrich T. Sommer*

Main category: cs.LG

TL;DR: 本文探讨用预测信息增益确定环境探索区域，结合强化学习方法估计可控动力学，并与近视探索方法对比。


<details>
  <summary>Details</summary>
Motivation: 在缺乏显式模型时，需找到探索环境以学习模型的方法。

Method: 使用预测信息增益确定探索区域，结合强化学习方法找到次优探索策略。

Result: 能可靠估计潜在可控动力学。

Conclusion: 该方法优于几种近视探索方法。

Abstract: Environments with controllable dynamics are usually understood in terms of
explicit models. However, such models are not always available, but may
sometimes be learned by exploring an environment. In this work, we investigate
using an information measure called "predicted information gain" to determine
the most informative regions of an environment to explore next. Applying
methods from reinforcement learning allows good suboptimal exploring policies
to be found, and leads to reliable estimates of the underlying controllable
dynamics. This approach is demonstrated by comparing with several myopic
exploration approaches.

</details>


### [68] [Generalization in Reinforcement Learning for Radio Access Networks](https://arxiv.org/abs/2507.06602)
*Burak Demirel,Yu Wang,Cristian Tatino,Pablo Soldati*

Main category: cs.LG

TL;DR: 提出以泛化为中心的RL框架用于RAN控制，在多个5G基准测试中表现良好，为AI原生6G RAN提供路径。


<details>
  <summary>Details</summary>
Motivation: 现代RAN环境动态异构，手工调优、基于规则的RRM算法表现不佳，RL存在泛化挑战，数据驱动策略易过拟合。

Method: 通过基于注意力的图表示编码小区拓扑和节点属性；应用域随机化拓宽训练分布；采用分布式数据生成和集中式训练架构。

Result: 在五个5G基准测试中，政策使平均吞吐量和频谱效率显著提升，在九小区部署中，GAT模型吞吐量高于MLP基线。

Conclusion: 所提框架结合可扩展架构，为使用单一、可泛化的RL代理实现AI原生6G RAN提供了途径。

Abstract: Modern RAN operate in highly dynamic and heterogeneous environments, where
hand-tuned, rule-based RRM algorithms often underperform. While RL can surpass
such heuristics in constrained settings, the diversity of deployments and
unpredictable radio conditions introduce major generalization challenges.
Data-driven policies frequently overfit to training conditions, degrading
performance in unseen scenarios. To address this, we propose a
generalization-centered RL framework for RAN control that: (i) encodes cell
topology and node attributes via attention-based graph representations; (ii)
applies domain randomization to broaden the training distribution; and (iii)
distributes data generation across multiple actors while centralizing training
in a cloud-compatible architecture aligned with O-RAN principles. Although
generalization increases computational and data-management complexity, our
distributed design mitigates this by scaling data collection and training
across diverse network conditions. Applied to downlink link adaptation in five
5G benchmarks, our policy improves average throughput and spectral efficiency
by ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and
by >20% under high mobility. It matches specialized RL in full-buffer traffic
and achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks,
respectively. In nine-cell deployments, GAT models offer 30% higher throughput
over MLP baselines. These results, combined with our scalable architecture,
offer a path toward AI-native 6G RAN using a single, generalizable RL agent.

</details>


### [69] [Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation](https://arxiv.org/abs/2507.06613)
*Anshuk Uppal,Yuhta Takida,Chieh-Hsin Lai,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: 本文提出新的生成建模框架，利用不同β值学习多种潜在表征，平衡解纠缠与生成质量，还支持无输入图像生成样本。


<details>
  <summary>Details</summary>
Motivation: 解决生成模型中解纠缠潜在表征与生成质量的权衡问题。

Method: 提出新框架，训练单个VAE获得多种表征，引入非线性扩散模型平滑过渡不同β值对应的潜在表征。

Result: 模型实现（几乎）无损表征，能进行清晰重建，支持无输入图像生成样本，在解纠缠和生成质量上表现良好，潜空间过渡平滑。

Conclusion: 所提框架有效平衡了解纠缠和生成质量，支持独立生成样本，潜空间过渡有利于输出的一致操控。

Abstract: Disentangled and interpretable latent representations in generative models
typically come at the cost of generation quality. The $\beta$-VAE framework
introduces a hyperparameter $\beta$ to balance disentanglement and
reconstruction quality, where setting $\beta > 1$ introduces an information
bottleneck that favors disentanglement over sharp, accurate reconstructions. To
address this trade-off, we propose a novel generative modeling framework that
leverages a range of $\beta$ values to learn multiple corresponding latent
representations. First, we obtain a slew of representations by training a
single variational autoencoder (VAE), with a new loss function that controls
the information retained in each latent representation such that the higher
$\beta$ value prioritize disentanglement over reconstruction fidelity. We then,
introduce a non-linear diffusion model that smoothly transitions latent
representations corresponding to different $\beta$ values. This model denoises
towards less disentangled and more informative representations, ultimately
leading to (almost) lossless representations, enabling sharp reconstructions.
Furthermore, our model supports sample generation without input images,
functioning as a standalone generative model. We evaluate our framework in
terms of both disentanglement and generation quality. Additionally, we observe
smooth transitions in the latent spaces with respect to changes in $\beta$,
facilitating consistent manipulation of generated outputs.

</details>


### [70] [Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance](https://arxiv.org/abs/2507.06615)
*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

Main category: cs.LG

TL;DR: 提出跨任务策略引导框架CTPG并结合门控机制，能与现有参数共享方法结合提升多任务强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有多任务强化学习方法忽略了用已掌握技能的任务控制策略指导未掌握任务来加速技能获取，需要新方法利用跨任务相似性。

Method: 提出CTPG框架，为每个任务训练引导策略从所有任务控制策略中选行为策略；提出两种门控机制提高效率，CTPG可与现有参数共享方法结合。

Result: 在操作和运动基准测试中，CTPG与现有方法结合显著提升性能。

Conclusion: CTPG是通用框架，能有效提升多任务强化学习性能。

Abstract: Multi-task reinforcement learning endeavors to efficiently leverage shared
information across various tasks, facilitating the simultaneous learning of
multiple tasks. Existing approaches primarily focus on parameter sharing with
carefully designed network structures or tailored optimization procedures.
However, they overlook a direct and complementary way to exploit cross-task
similarities: the control policies of tasks already proficient in some skills
can provide explicit guidance for unmastered tasks to accelerate skills
acquisition. To this end, we present a novel framework called Cross-Task Policy
Guidance (CTPG), which trains a guide policy for each task to select the
behavior policy interacting with the environment from all tasks' control
policies, generating better training trajectories. In addition, we propose two
gating mechanisms to improve the learning efficiency of CTPG: one gate filters
out control policies that are not beneficial for guidance, while the other gate
blocks tasks that do not necessitate guidance. CTPG is a general framework
adaptable to existing parameter sharing approaches. Empirical evaluations
demonstrate that incorporating CTPG with these approaches significantly
enhances performance in manipulation and locomotion benchmarks.

</details>


### [71] [UniOD: A Universal Model for Outlier Detection across Diverse Domains](https://arxiv.org/abs/2507.06624)
*Dazhi Fu,Jicong Fan*

Main category: cs.LG

TL;DR: 提出通用离群点检测框架UniOD，避免模型选择和超参数调整，提升检测便利性和准确性，在15个基准数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 多数现有离群点检测方法需进行特定数据集的超参数调整和高成本模型训练，提出能利用有标签数据集训练单一模型，检测不同领域数据集离群点的通用框架。

Method: 将每个数据集转换为多个图，生成一致的节点特征，将离群点检测构建为节点分类任务。

Result: 在15个基准离群点检测数据集上与15个最先进的基线方法进行评估，证明了其有效性。

Conclusion: UniOD避免了模型选择和超参数调整的工作，降低了计算成本，有效利用历史数据集知识，提高了实际应用中的便利性和准确性。

Abstract: Outlier detection (OD) seeks to distinguish inliers and outliers in
completely unlabeled datasets and plays a vital role in science and
engineering. Most existing OD methods require troublesome dataset-specific
hyperparameter tuning and costly model training before they can be deployed to
identify outliers. In this work, we propose UniOD, a universal OD framework
that leverages labeled datasets to train a single model capable of detecting
outliers of datasets from diverse domains. Specifically, UniOD converts each
dataset into multiple graphs, produces consistent node features, and frames
outlier detection as a node-classification task, and is able to generalize to
unseen domains. As a result, UniOD avoids effort on model selection and
hyperparameter tuning, reduces computational cost, and effectively utilizes the
knowledge from historical datasets, which improves the convenience and accuracy
in real applications. We evaluate UniOD on 15 benchmark OD datasets against 15
state-of-the-art baselines, demonstrating its effectiveness.

</details>


### [72] [Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2507.06628)
*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

Main category: cs.LG

TL;DR: 提出GO - Skill方法解决离线多任务强化学习跨任务知识共享难题，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 离线多任务强化学习在跨任务有效共享知识方面面临挑战，受人类学习高效知识抽象启发。

Method: 通过目标导向技能提取过程发现可复用技能，利用向量量化构建离散技能库，引入技能增强阶段缓解技能类别不平衡，用分层策略学习整合技能。

Result: 在MetaWorld基准的各种机器人操作任务上进行的大量实验表明GO - Skill有效且通用。

Conclusion: GO - Skill能有效解决离线多任务强化学习跨任务知识共享问题，具有良好性能和通用性。

Abstract: Offline multi-task reinforcement learning aims to learn a unified policy
capable of solving multiple tasks using only pre-collected task-mixed datasets,
without requiring any online interaction with the environment. However, it
faces significant challenges in effectively sharing knowledge across tasks.
Inspired by the efficient knowledge abstraction observed in human learning, we
propose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed
to extract and utilize reusable skills to enhance knowledge transfer and task
performance. Our approach uncovers reusable skills through a goal-oriented
skill extraction process and leverages vector quantization to construct a
discrete skill library. To mitigate class imbalances between broadly applicable
and task-specific skills, we introduce a skill enhancement phase to refine the
extracted skills. Furthermore, we integrate these skills using hierarchical
policy learning, enabling the construction of a high-level policy that
dynamically orchestrates discrete skills to accomplish specific tasks.
Extensive experiments on diverse robotic manipulation tasks within the
MetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.

</details>


### [73] [Prevention of Overfitting on Mesh-Structured Data Regressions with a Modified Laplace Operator](https://arxiv.org/abs/2507.06631)
*Enda D. V. Bigarella*

Main category: cs.LG

TL;DR: 提出一种检测和防止数据回归过拟合的方法，应用于网格状数据结构，通过计算拉普拉斯算子导数优化超参数，减少不必要振荡，无需分割训练数据进行测试。


<details>
  <summary>Details</summary>
Motivation: 解决数据回归中的过拟合问题，特别是针对网格状数据结构。

Method: 在原始训练网格计算训练数据导数作为熵的真实标签，在交错网格计算训练后数据导数识别振荡，用拉普拉斯算子导数损失进行超参数优化。

Result: 通过最小化训练模型的熵减少了不必要的振荡，可直接在所有可用训练点上训练，以交错网格上应用拉普拉斯算子作为基于扩散属性的替代测试指标。

Conclusion: 该方法能有效检测和防止网格状数据结构在数据回归中的过拟合问题。

Abstract: This document reports on a method for detecting and preventing overfitting on
data regressions, herein applied to mesh-like data structures. The mesh
structure allows for the straightforward computation of the Laplace-operator
second-order derivatives in a finite-difference fashion for noiseless data.
Derivatives of the training data are computed on the original training mesh to
serve as a true label of the entropy of the training data. Derivatives of the
trained data are computed on a staggered mesh to identify oscillations in the
interior of the original training mesh cells. The loss of the Laplace-operator
derivatives is used for hyperparameter optimisation, achieving a reduction of
unwanted oscillation through the minimisation of the entropy of the trained
model. In this setup, testing does not require the splitting of points from the
training data, and training is thus directly performed on all available
training points. The Laplace operator applied to the trained data on a
staggered mesh serves as a surrogate testing metric based on diffusion
properties.

</details>


### [74] [Deep Disentangled Representation Network for Treatment Effect Estimation](https://arxiv.org/abs/2507.06650)
*Hui Meng,Keping Yang,Xuyu Peng,Bo Zheng*

Main category: cs.LG

TL;DR: 本文提出新的治疗效果估计算法，在公共半合成和真实生产数据集上实验，结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有解纠缠表示方法多围绕生成模型或硬分解方法，难以保证精确解纠缠，需有效建模不同因果关系。

Method: 提出结合专家混合与多头注意力及线性正交正则化器的算法，对预处理变量进行软分解，并用重要性采样重加权技术消除选择偏差。

Result: 在公共半合成和真实生产数据集上实验，算法在个体治疗效果估计上优于现有方法。

Conclusion: 所提算法在个体治疗效果估计方面表现出色，是一种有效的方法。

Abstract: Estimating individual-level treatment effect from observational data is a
fundamental problem in causal inference and has attracted increasing attention
in the fields of education, healthcare, and public policy.In this work, we
concentrate on the study of disentangled representation methods that have shown
promising outcomes by decomposing observed covariates into instrumental,
confounding, and adjustment factors. However, most of the previous work has
primarily revolved around generative models or hard decomposition methods for
covariates, which often struggle to guarantee the attainment of precisely
disentangled factors. In order to effectively model different causal
relationships, we propose a novel treatment effect estimation algorithm that
incorporates a mixture of experts with multi-head attention and a linear
orthogonal regularizer to softly decompose the pre-treatment variables, and
simultaneously eliminates selection bias via importance sampling re-weighting
techniques. We conduct extensive experiments on both public semi-synthetic and
real-world production datasets. The experimental results clearly demonstrate
that our algorithm outperforms the state-of-the-art methods focused on
individual treatment effects.

</details>


### [75] [Federated Learning Inspired Fuzzy Systems: Decentralized Rule Updating for Privacy and Scalable Decision Making](https://arxiv.org/abs/2507.06652)
*Arthur Alexander Lim,Zhen Bin It,Jovan Bowen Heng,Tee Hui Teo*

Main category: cs.LG

TL;DR: 本文探讨利用机器学习和联邦学习改进模糊系统，分析了实现方式和潜在限制，认为改进方案有潜力但需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 现有模糊系统可进一步改进，机器学习和联邦学习有提升模糊系统效果的潜力。

Method: 探讨将机器学习应用于模糊系统以提升结果，借鉴联邦学习中更新模糊规则等方面改进模糊系统。

Result: 分析了改进在模糊系统中的实现方式及潜在限制。

Conclusion: 提出的改进方案有提升模糊系统的潜力，但需进一步研究改进程度。

Abstract: Fuzzy systems are a way to allow machines, systems and frameworks to deal
with uncertainty, which is not possible in binary systems that most computers
use. These systems have already been deployed for certain use cases, and fuzzy
systems could be further improved as proposed in this paper. Such technologies
to draw inspiration from include machine learning and federated learning.
Machine learning is one of the recent breakthroughs of technology and could be
applied to fuzzy systems to further improve the results it produces. Federated
learning is also one of the recent technologies that have huge potential, which
allows machine learning training to improve by reducing privacy risk, reducing
burden on networking infrastructure, and reducing latency of the latest model.
Aspects from federated learning could be used to improve federated learning,
such as applying the idea of updating the fuzzy rules that make up a key part
of fuzzy systems, to further improve it over time. This paper discusses how
these improvements would be implemented in fuzzy systems, and how it would
improve fuzzy systems. It also discusses certain limitations on the potential
improvements. It concludes that these proposed ideas and improvements require
further investigation to see how far the improvements are, but the potential is
there to improve fuzzy systems.

</details>


### [76] [Heterogeneous Graph Neural Networks for Short-term State Forecasting in Power Systems across Domains and Time Scales: A Hydroelectric Power Plant Case Study](https://arxiv.org/abs/2507.06694)
*Raffael Theiler,Olga Fink*

Main category: cs.LG

TL;DR: 文章指出准确的短期状态预测对现代电力系统很重要，现有基于GNN的方法有局限，提出用异构图注意力网络，实验表明该方法表现优于传统基线。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统跨多物理域，现有基于GNN的方法无法处理异构传感器数据，需新方法进行多域多速率电力系统状态预测。

Method: 提出使用异构图注意力网络，对液压和电气两个物理域的传感器数据的同构域内和异构域间关系进行建模。

Result: 实验结果显示，该方法在归一化均方根误差方面平均比传统基线方法高出35.5%。

Conclusion: 所提出的方法在多域多速率电力系统状态预测中有效。

Abstract: Accurate short-term state forecasting is essential for efficient and stable
operation of modern power systems, especially in the context of increasing
variability introduced by renewable and distributed energy resources. As these
systems evolve rapidly, it becomes increasingly important to reliably predict
their states in the short term to ensure operational stability, support control
decisions, and enable interpretable monitoring of sensor and machine behavior.
Modern power systems often span multiple physical domains - including
electrical, mechanical, hydraulic, and thermal - posing significant challenges
for modeling and prediction. Graph Neural Networks (GNNs) have emerged as a
promising data-driven framework for system state estimation and state
forecasting in such settings. By leveraging the topological structure of sensor
networks, GNNs can implicitly learn inter-sensor relationships and propagate
information across the network. However, most existing GNN-based methods are
designed under the assumption of homogeneous sensor relationships and are
typically constrained to a single physical domain. This limitation restricts
their ability to integrate and reason over heterogeneous sensor data commonly
encountered in real-world energy systems, such as those used in energy
conversion infrastructure. In this work, we propose the use of Heterogeneous
Graph Attention Networks to address these limitations. Our approach models both
homogeneous intra-domain and heterogeneous inter-domain relationships among
sensor data from two distinct physical domains - hydraulic and electrical -
which exhibit fundamentally different temporal dynamics. Experimental results
demonstrate that our method significantly outperforms conventional baselines on
average by 35.5% in terms of normalized root mean square error, confirming its
effectiveness in multi-domain, multi-rate power system state forecasting.

</details>


### [77] [Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement](https://arxiv.org/abs/2507.06701)
*Michael Bloesch,Markus Wulfmeier,Philemon Brakel,Todor Davchev,Martina Zambelli,Jost Tobias Springenberg,Abbas Abdolmaleki,William F Whitney,Nicolas Heess,Roland Hafner,Martin Riedmiller*

Main category: cs.LG

TL;DR: 本文研究更细致的数据分布，提出从这类数据中学习的方法，评估了不同数据分布与算法适用性的关系，为开发更强大实用的IfO技术提供见解。


<details>
  <summary>Details</summary>
Motivation: 当前IfO研究聚焦理想场景和双峰质量数据分布，限制了结果的意义，需要研究更细致的数据分布。

Method: 将基于强化学习的模仿学习应用于无动作演示，使用价值函数在专家和非专家数据间传递信息。

Result: 通过综合评估，描绘了不同数据分布与算法适用性的关系，指出既定方法的局限性。

Conclusion: 研究结果为开发更强大实用的IfO技术，实现可扩展的行为学习提供了有价值的见解。

Abstract: Imitation Learning from Observation (IfO) offers a powerful way to learn
behaviors at large-scale: Unlike behavior cloning or offline reinforcement
learning, IfO can leverage action-free demonstrations and thus circumvents the
need for costly action-labeled demonstrations or reward functions. However,
current IfO research focuses on idealized scenarios with mostly bimodal-quality
data distributions, restricting the meaningfulness of the results. In contrast,
this paper investigates more nuanced distributions and introduces a method to
learn from such data, moving closer to a paradigm in which imitation learning
can be performed iteratively via self-improvement. Our method adapts RL-based
imitation learning to action-free demonstrations, using a value function to
transfer information between expert and non-expert data. Through comprehensive
evaluation, we delineate the relation between different data distributions and
the applicability of algorithms and highlight the limitations of established
methods. Our findings provide valuable insights for developing more robust and
practical IfO techniques on a path to scalable behaviour learning.

</details>


### [78] [PINN-Obs: Physics-Informed Neural Network-Based Observer for Nonlinear Dynamical Systems](https://arxiv.org/abs/2507.06712)
*Ayoub Farkane,Mohamed Boutayeb,Mustapha Oudani,Mounir Ghogho*

Main category: cs.LG

TL;DR: 本文提出用于非线性系统状态估计的自适应物理信息神经网络观测器PINN - Obs，理论证明收敛性，仿真验证其有效性和优势。


<details>
  <summary>Details</summary>
Motivation: 解决非线性动态系统在仅有部分且含噪声测量数据时的状态估计难题。

Method: 将系统动力学和传感器数据集成到物理信息学习过程，自适应学习最优增益矩阵。

Result: 理论分析证明在温和可观测条件下能统一最小化误差；数值仿真验证有效性，对比实验显示其准确性、鲁棒性和适应性更优。

Conclusion: PINN - Obs在非线性系统状态估计方面是有效且具有优势的方法。

Abstract: State estimation for nonlinear dynamical systems is a critical challenge in
control and engineering applications, particularly when only partial and noisy
measurements are available. This paper introduces a novel Adaptive
Physics-Informed Neural Network-based Observer (PINN-Obs) for accurate state
estimation in nonlinear systems. Unlike traditional model-based observers,
which require explicit system transformations or linearization, the proposed
framework directly integrates system dynamics and sensor data into a
physics-informed learning process. The observer adaptively learns an optimal
gain matrix, ensuring convergence of the estimated states to the true system
states. A rigorous theoretical analysis establishes formal convergence
guarantees, demonstrating that the proposed approach achieves uniform error
minimization under mild observability conditions. The effectiveness of PINN-Obs
is validated through extensive numerical simulations on diverse nonlinear
systems, including an induction motor model, a satellite motion system, and
benchmark academic examples. Comparative experimental studies against existing
observer designs highlight its superior accuracy, robustness, and adaptability.

</details>


### [79] [Robust Deep Network Learning of Nonlinear Regression Tasks by Parametric Leaky Exponential Linear Units (LELUs) and a Diffusion Metric](https://arxiv.org/abs/2507.06765)
*Enda D. V. Bigarella*

Main category: cs.LG

TL;DR: 提出参数化激活函数改进多维非线性数据回归，并用新指标评估过拟合情况


<details>
  <summary>Details</summary>
Motivation: 现有非线性激活函数在大型神经网络中存在性能局限，如平滑但梯度消失、非平滑造成模型不连续等问题，需要改进多维非线性数据回归性能

Method: 提出平滑且有非零可训练梯度的“Leaky Exponential Linear Unit”激活函数，提出新的扩散损失指标评估过拟合

Result: 展示了新激活函数有更好的性能

Conclusion: 新的激活函数和扩散损失指标有助于提升模型性能和评估过拟合情况

Abstract: This document proposes a parametric activation function (ac.f.) aimed at
improving multidimensional nonlinear data regression. It is a established
knowledge that nonlinear ac.f.'s are required for learning nonlinear datasets.
This work shows that smoothness and gradient properties of the ac.f. further
impact the performance of large neural networks in terms of overfitting and
sensitivity to model parameters. Smooth but vanishing-gradient ac.f.'s such as
ELU or SiLU have limited performance and non-smooth ac.f.'s such as RELU and
Leaky-RELU further impart discontinuity in the trained model. Improved
performance is demonstrated with a smooth "Leaky Exponential Linear Unit", with
non-zero gradient that can be trained. A novel diffusion-loss metric is also
proposed to gauge the performance of the trained models in terms of
overfitting.

</details>


### [80] [Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm](https://arxiv.org/abs/2507.06780)
*George Papadopoulos,George A. Vouros*

Main category: cs.LG

TL;DR: 介绍一种模仿学习方法，用于学习符合专家轨迹约束的最大熵策略，算法用双梯度下降优化目标，实验表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 学习符合专家轨迹约束的最大熵策略。

Method: 利用性能与策略间KL散度边界的联系，通过与强化学习概率推理框架建立联系证明目标合理性，用双梯度下降优化学习目标。

Result: 该方法能学习到有效策略模型，适用于多类型约束、不同行为模式，且有泛化能力。

Conclusion: 提出的模仿学习方法可有效学习符合约束的策略模型。

Abstract: This article introduces an imitation learning method for learning maximum
entropy policies that comply with constraints demonstrated by expert
trajectories executing a task. The formulation of the method takes advantage of
results connecting performance to bounds for the KL-divergence between
demonstrated and learned policies, and its objective is rigorously justified
through a connection to a probabilistic inference framework for reinforcement
learning, incorporating the reinforcement learning objective and the objective
to abide by constraints in an entropy maximization setting. The proposed
algorithm optimizes the learning objective with dual gradient descent,
supporting effective and stable training. Experiments show that the proposed
method can learn effective policy models for constraints-abiding behaviour, in
settings with multiple constraints of different types, accommodating different
modalities of demonstrated behaviour, and with abilities to generalize.

</details>


### [81] [Speech Tokenizer is Key to Consistent Representation](https://arxiv.org/abs/2507.06802)
*Wonjin Jung,Sungil Kang,Dong-Yeon Cho*

Main category: cs.LG

TL;DR: 本文介绍了一种新的语音分词器，能同时编码语言和声学信息，提升语音表示保真度，在多个应用中有效且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有残差向量量化（RVQ）方法常忽略关键声学特征，需一种能同时编码语言和声学信息的语音分词器。

Method: 提出一种先进方法，同时编码语言和声学信息，保留韵律和情感内容。

Result: 在语音编码、语音转换、情感识别和多模态语言建模等应用中有效，无需额外训练。

Conclusion: 该方法具有广泛适用性，有潜力成为推动人工智能驱动的语音处理的关键工具。

Abstract: Speech tokenization is crucial in digital speech processing, converting
continuous speech signals into discrete units for various computational tasks.
This paper introduces a novel speech tokenizer with broad applicability across
downstream tasks. While recent advances in residual vector quantization (RVQ)
have incorporated semantic elements, they often neglect critical acoustic
features. We propose an advanced approach that simultaneously encodes both
linguistic and acoustic information, preserving prosodic and emotional content.
Our method significantly enhances speech representation fidelity across diverse
applications. Empirical evaluations demonstrate its effectiveness in speech
coding, voice conversion, emotion recognition, and multimodal language
modeling, without requiring additional training. This versatility underscores
its potential as a key tool for advancing AI-driven speech processing.

</details>


### [82] [Intrinsic Training Signals for Federated Learning Aggregation](https://arxiv.org/abs/2507.06813)
*Cosimo Fiorini,Matteo Mosconi,Pietro Buzzega,Riccardo Salami,Simone Calderara*

Main category: cs.LG

TL;DR: 提出LIVAR方法，利用现有训练信号进行联邦模型聚合，无架构开销，在多基准测试中达SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习模型聚合方法需架构修改或损失函数改变，希望利用现有训练信号实现有效模型聚合。

Method: 提出LIVAR方法，包括方差加权分类器聚合方案和基于SHAP分析的可解释性LoRA合并技术。

Result: LIVAR在多个基准测试中达到了最先进的性能，并且能与现有联邦学习方法无缝集成。

Conclusion: 仅通过现有训练信号就可以实现有效的模型合并，为高效联邦模型聚合建立了新范式。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients while preserving data privacy. While existing approaches
for aggregating client-specific classification heads and adapted backbone
parameters require architectural modifications or loss function changes, our
method uniquely leverages intrinsic training signals already available during
standard optimization. We present LIVAR (Layer Importance and VARiance-based
merging), which introduces: i) a variance-weighted classifier aggregation
scheme using naturally emergent feature statistics, and ii) an
explainability-driven LoRA merging technique based on SHAP analysis of existing
update parameter patterns. Without any architectural overhead, LIVAR achieves
state-of-the-art performance on multiple benchmarks while maintaining seamless
integration with existing FL methods. This work demonstrates that effective
model merging can be achieved solely through existing training signals,
establishing a new paradigm for efficient federated model aggregation. The code
will be made publicly available upon acceptance.

</details>


### [83] [Comprehensive Evaluation of Prototype Neural Networks](https://arxiv.org/abs/2507.06819)
*Philipp Schlinge,Steffen Meinert,Martin Atzmueller*

Main category: cs.LG

TL;DR: 本文深入分析一组重要原型模型，提出新指标评估，在多数据集实验并开源代码。


<details>
  <summary>Details</summary>
Motivation: 对可解释人工智能和可解释机器学习中的原型模型进行评估和分析。

Method: 对ProtoPNet、ProtoPool和PIPNet等原型模型进行深入分析，应用标准指标和提出新指标，在多数据集上实验。

Result: 在多种数据集上对比了原型模型的性能。

Conclusion: 开源代码便于指标应用和扩展，方便添加新指标和模型。

Abstract: Prototype models are an important method for explainable artificial
intelligence (XAI) and interpretable machine learning. In this paper, we
perform an in-depth analysis of a set of prominent prototype models including
ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive
set of metrics. In addition to applying standard metrics from literature, we
propose several new metrics to further complement the analysis of model
interpretability. In our experimentation, we apply the set of prototype models
on a diverse set of datasets including fine-grained classification, Non-IID
settings and multi-label classification to further contrast the performance.
Furthermore, we also provide our code as an open-source library, which
facilitates simple application of the metrics itself, as well as extensibility
- providing the option for easily adding new metrics and models.
https://github.com/uos-sis/quanproto

</details>


### [84] [HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning](https://arxiv.org/abs/2507.06821)
*Chuhang Zheng,Chunwei Tian,Jie Wen,Daoqiang Zhang,Qi Zhu*

Main category: cs.LG

TL;DR: 本文提出多模态情感分布学习框架HeLo，有效融合生理数据，挖掘异质性与标签相关性，实验证明其在情感分布学习上的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有情感分布学习方法在挖掘多模态异质性和利用基本情感语义相关性方面存在挑战。

Method: 采用交叉注意力融合生理数据，设计基于最优传输的异质性挖掘模块，引入可学习标签嵌入并通过相关矩阵对齐优化，利用标签相关性驱动的交叉注意力机制进行情感分布学习。

Result: 在两个公开数据集上的实验表明所提方法在情感分布学习方面具有优越性。

Conclusion: 所提出的HeLo框架能有效探索多模态情感数据的异质性、互补信息和标签相关性，提升情感分布学习效果。

Abstract: Multi-modal emotion recognition has garnered increasing attention as it plays
a significant role in human-computer interaction (HCI) in recent years. Since
different discrete emotions may exist at the same time, compared with
single-class emotion recognition, emotion distribution learning (EDL) that
identifies a mixture of basic emotions has gradually emerged as a trend.
However, existing EDL methods face challenges in mining the heterogeneity among
multiple modalities. Besides, rich semantic correlations across arbitrary basic
emotions are not fully exploited. In this paper, we propose a multi-modal
emotion distribution learning framework, named HeLo, aimed at fully exploring
the heterogeneity and complementary information in multi-modal emotional data
and label correlation within mixed basic emotions. Specifically, we first adopt
cross-attention to effectively fuse the physiological data. Then, an optimal
transport (OT)-based heterogeneity mining module is devised to mine the
interaction and heterogeneity between the physiological and behavioral
representations. To facilitate label correlation learning, we introduce a
learnable label embedding optimized by correlation matrix alignment. Finally,
the learnable label embeddings and label correlation matrices are integrated
with the multi-modal representations through a novel label correlation-driven
cross-attention mechanism for accurate emotion distribution learning.
Experimental results on two publicly available datasets demonstrate the
superiority of our proposed method in emotion distribution learning.

</details>


### [85] [Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning](https://arxiv.org/abs/2507.06825)
*Matej Straka,Martin Schmid*

Main category: cs.LG

TL;DR: 本文介绍基于Generals.io构建的实时策略游戏环境，该环境与Gymnasium和PettingZoo兼容，训练的参考智能体表现出色，还提供了推进多智能体强化学习研究的平台。


<details>
  <summary>Details</summary>
Motivation: 构建一个可用于推进多智能体强化学习研究的平台。

Method: 基于Generals.io构建环境，使用监督预训练和自我对弈训练参考智能体，融入基于势能的奖励塑造和记忆特征。

Result: 环境能在普通硬件上每秒运行数千帧，参考智能体在单张H100 GPU上训练36小时后进入1v1人类排行榜前0.003%。

Conclusion: 所提出的模块化RTS基准和有竞争力的基线智能体为多智能体强化学习研究提供了易上手且具挑战性的平台。

Abstract: We introduce a real-time strategy game environment built on Generals.io, a
game that hosts thousands of active players each week across multiple game
formats. Our environment is fully compatible with Gymnasium and PettingZoo,
capable of running thousands of frames per second on commodity hardware. Our
reference agent -- trained with supervised pre-training and self-play -- hits
the top 0.003\% of the 1v1 human leaderboard after just 36 hours on a single
H100 GPU. To accelerate learning, we incorporate potential-based reward shaping
and memory features. Our contributions -- a modular RTS benchmark and a
competitive, state-of-the-art baseline agent -- provide an accessible yet
challenging platform for advancing multi-agent reinforcement learning research.

</details>


### [86] [Episodic Contextual Bandits with Knapsacks under Conversion Models](https://arxiv.org/abs/2507.06859)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 研究在线环境下决策者与带背包的上下文多臂老虎机实例在重复回合中的交互，设计了在线算法并取得次线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 解决在线环境中上下文多臂老虎机带背包问题，应用于动态定价和拍卖等场景，处理非平稳上下文概率分布和无界状态空间等问题。

Method: 设计在线算法，假设可访问能实现 $o(T)$ 遗憾的置信界预言机，克服多上下文带来的技术挑战。

Result: 算法能在回合数 $T$ 上实现次线性遗憾，在某些情况下使用未标记特征数据可改善遗憾界。

Conclusion: 所提出的框架在上下文带背包问题中有一定创新性，提供了改进的遗憾界。

Abstract: We study an online setting, where a decision maker (DM) interacts with
contextual bandit-with-knapsack (BwK) instances in repeated episodes. These
episodes start with different resource amounts, and the contexts' probability
distributions are non-stationary in an episode. All episodes share the same
latent conversion model, which governs the random outcome contingent upon a
request's context and an allocation decision. Our model captures applications
such as dynamic pricing on perishable resources with episodic replenishment,
and first price auctions in repeated episodes with different starting budgets.
We design an online algorithm that achieves a regret sub-linear in $T$, the
number of episodes, assuming access to a \emph{confidence bound oracle} that
achieves an $o(T)$-regret. Such an oracle is readily available from existing
contextual bandit literature. We overcome the technical challenge with
arbitrarily many possible contexts, which leads to a reinforcement learning
problem with an unbounded state space. Our framework provides improved regret
bounds in certain settings when the DM is provided with unlabeled feature data,
which is novel to the contextual BwK literature.

</details>


### [87] [Horizontal and Vertical Federated Causal Structure Learning via Higher-order Cumulants](https://arxiv.org/abs/2507.06888)
*Wei Chen,Wanyang Gu,Linjun Peng,Ruichu Cai,Zhifeng Hao,Kun Zhang*

Main category: cs.LG

TL;DR: 本文提出综合考虑水平和垂直联邦设置下的因果结构学习方法，用高阶累积量进行因果结构学习，实验表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有联邦因果结构学习方法主要关注水平联邦设置，实际中不同客户端变量不同，易产生虚假因果关系，影响信息传输。

Method: 综合考虑水平和垂直联邦设置，通过高阶累积量提供因果结构学习的识别理论和方法，聚合高阶累积量信息构建全局估计，用于递归源识别得到全局因果强度矩阵。

Result: 算法在合成数据和真实数据实验中表现出优越性能。

Conclusion: 所提方法不仅能重建因果图，还便于估计因果强度系数。

Abstract: Federated causal discovery aims to uncover the causal relationships between
entities while protecting data privacy, which has significant importance and
numerous applications in real-world scenarios. Existing federated causal
structure learning methods primarily focus on horizontal federated settings.
However, in practical situations, different clients may not necessarily contain
data on the same variables. In a single client, the incomplete set of variables
can easily lead to spurious causal relationships, thereby affecting the
information transmitted to other clients. To address this issue, we
comprehensively consider causal structure learning methods under both
horizontal and vertical federated settings. We provide the identification
theories and methods for learning causal structure in the horizontal and
vertical federal setting via higher-order cumulants. Specifically, we first
aggregate higher-order cumulant information from all participating clients to
construct global cumulant estimates. These global estimates are then used for
recursive source identification, ultimately yielding a global causal strength
matrix. Our approach not only enables the reconstruction of causal graphs but
also facilitates the estimation of causal strength coefficients. Our algorithm
demonstrates superior performance in experiments conducted on both synthetic
data and real-world data.

</details>


### [88] [Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model](https://arxiv.org/abs/2507.06892)
*Jing Liang,Hongyao Tang,Yi Ma,Jinyi Liu,Yan Zheng,Shuyue Hu,Lei Bai,Jianye Hao*

Main category: cs.LG

TL;DR: 文章提出ReMix方法让基于策略的强化微调方法利用离策略数据，实验显示其在数学推理基准测试中有出色表现且大幅降低训练成本，还揭示了一些有洞察力的发现。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法多为基于策略的，未充分利用过去学习过程中的数据，导致计算和时间成本高，限制了经济高效的扩展。

Method: 提出Reincarnating Mix - policy Proximal Policy Gradient (ReMix)方法，包含混合策略近端策略梯度、KL - 凸策略约束和策略再生三个主要组件。

Result: 在多个数学推理基准测试上，ReMix模型表现出SOTA水平，训练成本在回滚数据量方面降低30倍到450倍。

Conclusion: ReMix方法有效解决了现有基于策略的强化微调方法的局限性，能利用离策略数据，在提升性能的同时显著降低训练成本，且通过多方面分析有新发现。

Abstract: Reinforcement Learning (RL) has demonstrated its potential to improve the
reasoning ability of Large Language Models (LLMs). One major limitation of most
existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL
in nature, i.e., data generated during the past learning process is not fully
utilized. This inevitably comes at a significant cost of compute and time,
posing a stringent bottleneck on continuing economic and efficient scaling. To
this end, we launch the renaissance of off-policy RL and propose Reincarnating
Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable
on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix
consists of three major components: (1) Mix-policy proximal policy gradient
with an increased Update-To-Data (UTD) ratio for efficient training; (2)
KL-Convex policy constraint to balance the trade-off between stability and
flexibility; (3) Policy reincarnation to achieve a seamless transition from
efficient early-stage learning to steady asymptotic improvement. In our
experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base
models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with
0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B
model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math
reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and
MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level
performance with an over 30x to 450x reduction in training cost in terms of
rollout data volume. In addition, we reveal insightful findings via
multifaceted analysis, including the implicit preference for shorter responses
due to the Whipping Effect of off-policy discrepancy, the collapse mode of
self-reflection behavior under the presence of severe off-policyness, etc.

</details>


### [89] [Designing Adaptive Algorithms Based on Reinforcement Learning for Dynamic Optimization of Sliding Window Size in Multi-Dimensional Data Streams](https://arxiv.org/abs/2507.06901)
*Abolfazl Zarghani,Sadegh Abedi*

Main category: cs.LG

TL;DR: 提出基于强化学习的方法RL - Window动态优化多维数据流滑动窗口大小，在多个基准数据集上表现优于现有方法，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 多维数据流处理中固定大小滑动窗口难以适应概念漂移等动态变化，需要新方法优化窗口大小。

Method: 将窗口大小选择问题转化为强化学习问题，使用带优先经验回放的Dueling Deep Q - Network（DQN）实现RL - Window方法。

Result: 在UCI HAR、PAMAP2、Yahoo! Finance Stream等基准数据集上，RL - Window在分类准确率、漂移鲁棒性和计算效率上优于ADWIN和CNN - Adaptive。

Conclusion: RL - Window具有适应性和稳定性，适合实时应用。

Abstract: Multi-dimensional data streams, prevalent in applications like IoT, financial
markets, and real-time analytics, pose significant challenges due to their high
velocity, unbounded nature, and complex inter-dimensional dependencies. Sliding
window techniques are critical for processing such streams, but fixed-size
windows struggle to adapt to dynamic changes like concept drift or bursty
patterns. This paper proposes a novel reinforcement learning (RL)-based
approach to dynamically optimize sliding window sizes for multi-dimensional
data streams. By formulating window size selection as an RL problem, we enable
an agent to learn an adaptive policy based on stream characteristics, such as
variance, correlations, and temporal trends. Our method, RL-Window, leverages a
Dueling Deep Q-Network (DQN) with prioritized experience replay to handle
non-stationarity and high-dimensionality. Evaluations on benchmark datasets
(UCI HAR, PAMAP2, Yahoo! Finance Stream) demonstrate that RL-Window outperforms
state-of-the-art methods like ADWIN and CNN-Adaptive in classification
accuracy, drift robustness, and computational efficiency. Additional
qualitative analyses, extended metrics (e.g., energy efficiency, latency), and
a comprehensive dataset characterization further highlight its adaptability and
stability, making it suitable for real-time applications.

</details>


### [90] [What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models](https://arxiv.org/abs/2507.06952)
*Keyon Vafa,Peter G. Chang,Ashesh Rambachan,Sendhil Mullainathan*

Main category: cs.LG

TL;DR: 提出评估基础模型的归纳偏置探测技术，发现基础模型在新任务中可能无法形成对潜在世界模型的归纳偏置，而是采用特定任务启发式方法。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型是否真正捕捉到更深层次的结构。

Method: 开发一种评估技术，通过检查基础模型对从假定世界模型生成的合成数据集的适应情况，测量其归纳偏置是否与世界模型一致。

Result: 基础模型在训练任务中表现出色，但在适应新任务时无法形成对潜在世界模型的归纳偏置；在轨道轨迹训练的模型应用于新物理任务时，无法运用牛顿力学。

Conclusion: 基础模型可能发展出特定任务的启发式方法，这些方法无法泛化。

Abstract: Foundation models are premised on the idea that sequence prediction can
uncover deeper domain understanding, much like how Kepler's predictions of
planetary motion later led to the discovery of Newtonian mechanics. However,
evaluating whether these models truly capture deeper structure remains a
challenge. We develop a technique for evaluating foundation models that
examines how they adapt to synthetic datasets generated from some postulated
world model. Our technique measures whether the foundation model's inductive
bias aligns with the world model, and so we refer to it as an inductive bias
probe. Across multiple domains, we find that foundation models can excel at
their training tasks yet fail to develop inductive biases towards the
underlying world model when adapted to new tasks. We particularly find that
foundation models trained on orbital trajectories consistently fail to apply
Newtonian mechanics when adapted to new physics tasks. Further analysis reveals
that these models behave as if they develop task-specific heuristics that fail
to generalize.

</details>


### [91] [Noisy PDE Training Requires Bigger PINNs](https://arxiv.org/abs/2507.06967)
*Sebastien Andre-Sloan,Anirbit Mukherjee,Matthew Colbrook*

Main category: cs.LG

TL;DR: 研究物理信息神经网络（PINNs）在噪声数据下的经验风险，证明达到低经验风险时神经网络规模下限，通过实验验证并以HJB PDE为例研究，为理解含噪训练参数需求奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现实应用中数据样本有噪声，需了解PINN何时能有效实现低经验风险，目前相关条件研究较少。

Method: 证明监督PINN经验风险低于噪声监督标签方差时神经网络规模的下限，对无监督PINN在边界标签有噪声时给出类似约束，进行实验验证。

Result: 得到神经网络规模下限约束条件，实验表明PINN在条件下能实现低于噪声方差的经验风险，以HJB PDE为例进行研究。

Conclusion: 研究为定量理解含噪情况下训练PINNs的参数要求奠定基础，增加噪声监督标签数量不能无代价降低经验风险。

Abstract: Physics-Informed Neural Networks (PINNs) are increasingly used to approximate
solutions of partial differential equations (PDEs), especially in high
dimensions. In real-world applications, data samples are noisy, so it is
important to know when a predictor can still achieve low empirical risk.
However, little is known about the conditions under which a PINN can do so
effectively. We prove a lower bound on the size of neural networks required for
the supervised PINN empirical risk to fall below the variance of noisy
supervision labels. Specifically, if a predictor achieves an empirical risk
$O(\eta)$ below $\sigma^2$ (variance of supervision data), then necessarily
$d_N\log d_N\gtrsim N_s \eta^2$, where $N_s$ is the number of samples and $d_N$
is the number of trainable parameters of the PINN. A similar constraint applies
to the fully unsupervised PINN setting when boundary labels are sampled
noisily. Consequently, increasing the number of noisy supervision labels alone
does not provide a ``free lunch'' in reducing empirical risk. We also show
empirically that PINNs can indeed achieve empirical risks below $\sigma^2$
under such conditions. As a case study, we investigate PINNs applied to the
Hamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for
quantitatively understanding the parameter requirements for training PINNs in
the presence of noise.

</details>


### [92] [A Principled Framework for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06979)
*Panagiotis Koromilas,Efthymios Georgiou,Giorgos Bouritsas,Theodoros Giannakopoulos,Mihalis A. Nicolaou,Yannis Panagakis*

Main category: cs.LG

TL;DR: 现有对比学习方法处理多视图效果不佳，本文提出MV - InfoNCE和MV - DHEL两种新损失函数，在多个数据集上表现优于现有方法，还能用于多模态数据，缓解维度崩溃。


<details>
  <summary>Details</summary>
Motivation: 当前对比学习方法处理额外视图时采用简单聚合成对目标的方式，存在多个关键局限，需改进。

Method: 提出MV - InfoNCE和MV - DHEL两种新的损失函数，前者扩展InfoNCE以同时纳入所有视图交互，后者在视图间解耦对齐和均匀性。

Result: 在ImageNet1K等四个数据集上，新方法始终优于现有多视图方法，可用于多模态数据，MV - DHEL在五视图及以上时缓解维度崩溃。

Conclusion: 新提出的损失函数为多视图对比学习提供了理论上合理的扩展，有效解决了现有方法的局限。

Abstract: Contrastive Learning (CL), a leading paradigm in Self-Supervised Learning
(SSL), typically relies on pairs of data views generated through augmentation.
While multiple augmentations per instance (more than two) improve
generalization in supervised learning, current CL methods handle additional
views suboptimally by simply aggregating different pairwise objectives. This
approach suffers from four critical limitations: (L1) it utilizes multiple
optimization terms per data point resulting to conflicting objectives, (L2) it
fails to model all interactions across views and data points, (L3) it inherits
fundamental limitations (e.g. alignment-uniformity coupling) from pairwise CL
losses, and (L4) it prevents fully realizing the benefits of increased view
multiplicity observed in supervised settings. We address these limitations
through two novel loss functions: MV-InfoNCE, which extends InfoNCE to
incorporate all possible view interactions simultaneously in one term per data
point, and MV-DHEL, which decouples alignment from uniformity across views
while scaling interaction complexity with view multiplicity. Both approaches
are theoretically grounded - we prove they asymptotically optimize for
alignment of all views and uniformity, providing principled extensions to
multi-view contrastive learning. Our empirical results on ImageNet1K and three
other datasets demonstrate that our methods consistently outperform existing
multi-view approaches and effectively scale with increasing view multiplicity.
We also apply our objectives to multimodal data and show that, in contrast to
other contrastive objectives, they can scale beyond just two modalities. Most
significantly, ablation studies reveal that MV-DHEL with five or more views
effectively mitigates dimensionality collapse by fully utilizing the embedding
space, thereby delivering multi-view benefits observed in supervised learning.

</details>


### [93] [Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing](https://arxiv.org/abs/2507.06996)
*Eunbyeol Cho,Jiyoun Kim,Minjae Lee,Sungjin Park,Edward Choi*

Main category: cs.LG

TL;DR: 因隐私和监管问题需合成电子健康记录（EHR）数据集，提出RawMed框架合成多表时间序列EHR数据，还提出评估框架，在两开源数据集上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 隐私担忧和监管限制阻碍EHR敏感数据共享和利用，需生成合成EHR数据集。

Method: 引入RawMed框架，用基于文本的表示和压缩技术，以最少预处理捕捉复杂结构和时间动态；提出新评估框架评估多表时间序列合成EHR。

Result: 在两个开源EHR数据集上验证，RawMed在保真度和实用性上优于基线模型。

Conclusion: RawMed是有效合成多表时间序列EHR数据的框架，代码开源。

Abstract: Electronic Health Records (EHR) are time-series relational databases that
record patient interactions and medical events over time, serving as a critical
resource for healthcare research and applications. However, privacy concerns
and regulatory restrictions limit the sharing and utilization of such sensitive
data, necessitating the generation of synthetic EHR datasets. Unlike previous
EHR synthesis methods, which typically generate medical records consisting of
expert-chosen features (e.g. a few vital signs or structured codes only), we
introduce RawMed, the first framework to synthesize multi-table, time-series
EHR data that closely resembles raw EHRs. Using text-based representation and
compression techniques, RawMed captures complex structures and temporal
dynamics with minimal preprocessing. We also propose a new evaluation framework
for multi-table time-series synthetic EHRs, assessing distributional
similarity, inter-table relationships, temporal dynamics, and privacy.
Validated on two open-source EHR datasets, RawMed outperforms baseline models
in fidelity and utility. The code is available at
https://github.com/eunbyeol-cho/RawMed.

</details>


### [94] [Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions](https://arxiv.org/abs/2507.07008)
*Emile Pierret,Bruno Galerne*

Main category: cs.LG

TL;DR: 本文研究扩散模型用于高斯数据分布去模糊时的准确性，通过计算Wasserstein距离分析其与理论解的差异，可对比不同算法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型用于贝叶斯逆问题虽受关注，但性能表现存在未解决问题，需要研究其在高斯数据分布去模糊中的准确性。

Method: 在高斯数据分布去模糊的约束环境下，计算扩散模型采样器分布与逆问题理想解分布之间的精确Wasserstein距离，分析理论解与模型解的差异。

Result: 能够精确分析逆问题理论解与使用扩散模型得到的解之间的差异。

Conclusion: 研究结果可用于比较文献中的不同算法。

Abstract: Used as priors for Bayesian inverse problems, diffusion models have recently
attracted considerable attention in the literature. Their flexibility and high
variance enable them to generate multiple solutions for a given task, such as
inpainting, super-resolution, and deblurring. However, several unresolved
questions remain about how well they perform. In this article, we investigate
the accuracy of these models when applied to a Gaussian data distribution for
deblurring. Within this constrained context, we are able to precisely analyze
the discrepancy between the theoretical resolution of inverse problems and
their resolution obtained using diffusion models by computing the exact
Wasserstein distance between the distribution of the diffusion model sampler
and the ideal distribution of solutions to the inverse problem. Our findings
allow for the comparison of different algorithms from the literature.

</details>


### [95] [On-Device Training of PV Power Forecasting Models in a Smart Meter for Grid Edge Intelligence](https://arxiv.org/abs/2507.07016)
*Jian Huang,Yongli Zhu,Linna Xu,Zhe Zheng,Wenpeng Cui,Mingyang Sun*

Main category: cs.LG

TL;DR: 本文在资源受限的智能电表上进行边缘侧模型训练研究，以光伏功率预测为例，采用两种模型并设计训练方案，实验证明通过现有基础设施实现电网边缘智能的可行性。


<details>
  <summary>Details</summary>
Motivation: 介绍电网边缘智能的动机和设备端训练的概念，开展资源受限智能电表的边缘侧模型训练研究。

Method: 以光伏功率预测为案例，研究梯度提升树模型和循环神经网络模型，设计“混合”和“降低”精度训练方案以适应智能电表资源受限情况。

Result: 实验结果表明通过现有先进计量基础设施在经济上实现电网边缘智能是可行的。

Conclusion: 可以通过现有先进计量基础设施经济地实现电网边缘智能。

Abstract: In this paper, an edge-side model training study is conducted on a
resource-limited smart meter. The motivation of grid-edge intelligence and the
concept of on-device training are introduced. Then, the technical preparation
steps for on-device training are described. A case study on the task of
photovoltaic power forecasting is presented, where two representative machine
learning models are investigated: a gradient boosting tree model and a
recurrent neural network model. To adapt to the resource-limited situation in
the smart meter, "mixed"- and "reduced"-precision training schemes are also
devised. Experiment results demonstrate the feasibility of economically
achieving grid-edge intelligence via the existing advanced metering
infrastructures.

</details>


### [96] [PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments](https://arxiv.org/abs/2507.07032)
*Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Chunbin Gu,Ge Liu,Pheng-Ann Heng*

Main category: cs.LG

TL;DR: 提出PLAME模型解决现有蛋白结构预测模型依赖MSA在低同源和孤儿蛋白上效果不佳的问题，在多方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有折叠模型依赖MSA，在低同源和孤儿蛋白上因MSA信息不足效果受限，需新方法解决。

Method: 提出PLAME模型，利用预训练蛋白语言模型的进化嵌入，引入预训练表示，采用守恒 - 多样性损失，提出MSA选择方法和序列质量评估指标。

Result: 在低同源和孤儿蛋白的AlphaFold2基准测试中，折叠增强和序列质量评估达SOTA，在AlphaFold3上也有提升；消融实验验证MSA选择方法有效性；能作为适配器实现AlphaFold2精度和ESMFold推理速度。

Conclusion: PLAME模型有效解决现有依赖MSA模型的局限性，在蛋白结构预测等方面有良好效果。

Abstract: Protein structure prediction is essential for drug discovery and
understanding biological functions. While recent advancements like AlphaFold
have achieved remarkable accuracy, most folding models rely heavily on multiple
sequence alignments (MSAs) to boost prediction performance. This dependency
limits their effectiveness on low-homology proteins and orphan proteins, where
MSA information is sparse or unavailable. To address this limitation, we
propose PLAME, a novel MSA design model that leverages evolutionary embeddings
from pretrained protein language models. Unlike existing methods, PLAME
introduces pretrained representations to enhance evolutionary information and
employs a conservation-diversity loss to enhance generation quality.
Additionally, we propose a novel MSA selection method to effectively screen
high-quality MSAs and improve folding performance. We also propose a sequence
quality assessment metric that provides an orthogonal perspective to evaluate
MSA quality. On the AlphaFold2 benchmark of low-homology and orphan proteins,
PLAME achieves state-of-the-art performance in folding enhancement and sequence
quality assessment, with consistent improvements demonstrated on AlphaFold3.
Ablation studies validate the effectiveness of the MSA selection method, while
extensive case studies on various protein types provide insights into the
relationship between AlphaFold's prediction quality and MSA characteristics.
Furthermore, we demonstrate that PLAME can serve as an adapter achieving
AlphaFold2-level accuracy with the ESMFold's inference speed.

</details>


### [97] [Self-Supervised Learning at the Edge: The Cost of Labeling](https://arxiv.org/abs/2507.07033)
*Roberto Pereira,Fernanda Famá,Asal Rangrazi,Marco Miozzo,Charalampos Kalalas,Paolo Dini*

Main category: cs.LG

TL;DR: 探索自监督学习技术在边缘学习的可行性与效率，发现定制策略可降资源消耗4倍。


<details>
  <summary>Details</summary>
Motivation: 对比学习和自监督学习方法需大量数据和计算资源，在资源受限边缘设备部署有挑战，需探索边缘学习的可行性与效率。

Method: 分析不同自监督学习技术对有限计算、数据和能源预算的适应性，评估其在资源受限下学习能力，考虑标注数据能源成本，评估半监督学习作用。

Result: 定制自监督策略能实现有竞争力性能，同时最多降低4倍资源消耗。

Conclusion: 自监督学习策略在边缘节能学习有潜力。

Abstract: Contrastive learning (CL) has recently emerged as an alternative to
traditional supervised machine learning solutions by enabling rich
representations from unstructured and unlabeled data. However, CL and, more
broadly, self-supervised learning (SSL) methods often demand a large amount of
data and computational resources, posing challenges for deployment on
resource-constrained edge devices. In this work, we explore the feasibility and
efficiency of SSL techniques for edge-based learning, focusing on trade-offs
between model performance and energy efficiency. In particular, we analyze how
different SSL techniques adapt to limited computational, data, and energy
budgets, evaluating their effectiveness in learning robust representations
under resource-constrained settings. Moreover, we also consider the energy
costs involved in labeling data and assess how semi-supervised learning may
assist in reducing the overall energy consumed to train CL models. Through
extensive experiments, we demonstrate that tailored SSL strategies can achieve
competitive performance while reducing resource consumption by up to 4X,
underscoring their potential for energy-efficient learning at the edge.

</details>


### [98] [An Ensemble Embedding Approach for Improving Semantic Caching Performance in LLM-based Systems](https://arxiv.org/abs/2507.07061)
*Shervin Ghaffari,Zohre Bahranifard,Mohammad Akbari*

Main category: cs.LG

TL;DR: 本文提出集成嵌入方法提升大语言模型缓存系统语义相似度检测能力，实验表明其优于单模型方法。


<details>
  <summary>Details</summary>
Motivation: 现有语义缓存框架依赖单一嵌入模型，难以捕捉真实查询分布中的多样语义关系。

Method: 提出通过训练的元编码器组合多个嵌入模型的集成嵌入方法，并使用QQP数据集评估。

Result: 集成方法对语义等效查询的缓存命中率达92%，正确拒绝非等效查询作为缓存未命中的准确率达85%。

Conclusion: 集成嵌入方法在区分语义相似和不相似查询方面显著优于单模型方法，可提升缓存性能并减少计算开销。

Abstract: Semantic caching enhances the efficiency of large language model (LLM)
systems by identifying semantically similar queries, storing responses once,
and serving them for subsequent equivalent requests. However, existing semantic
caching frameworks rely on single embedding models for query representation,
which limits their ability to capture the diverse semantic relationships
present in real-world query distributions. This paper presents an ensemble
embedding approach that combines multiple embedding models through a trained
meta-encoder to improve semantic similarity detection in LLM caching systems.
We evaluate our method using the Quora Question Pairs (QQP) dataset, measuring
cache hit ratios, cache miss ratios, token savings, and response times. Our
ensemble approach achieves a 92\% cache hit ratio for semantically equivalent
queries while maintaining an 85\% accuracy in correctly rejecting
non-equivalent queries as cache misses. These results demonstrate that ensemble
embedding methods significantly outperform single-model approaches in
distinguishing between semantically similar and dissimilar queries, leading to
more effective caching performance and reduced computational overhead in
LLM-based systems.

</details>


### [99] [Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts](https://arxiv.org/abs/2507.07100)
*Lan Li,Da-Wei Zhou,Han-Jia Ye,De-Chuan Zhan*

Main category: cs.LG

TL;DR: 提出DCE框架解决DIL在不平衡数据下的挑战，实验效果佳


<details>
  <summary>Details</summary>
Motivation: 解决Domain - Incremental Learning (DIL)在不平衡数据下的域内类别不平衡和跨域类别分布偏移问题

Method: 引入Dual - Balance Collaborative Experts (DCE)框架，用频率感知专家组解决域内类别不平衡，用动态专家选择器平衡新旧知识

Result: 在四个基准数据集上的实验显示DCE有最优性能

Conclusion: DCE框架能有效应对DIL在不平衡数据下的挑战

Abstract: Domain-Incremental Learning (DIL) focuses on continual learning in
non-stationary environments, requiring models to adjust to evolving domains
while preserving historical knowledge. DIL faces two critical challenges in the
context of imbalanced data: intra-domain class imbalance and cross-domain class
distribution shifts. These challenges significantly hinder model performance,
as intra-domain imbalance leads to underfitting of few-shot classes, while
cross-domain shifts require maintaining well-learned many-shot classes and
transferring knowledge to improve few-shot class performance in old domains. To
overcome these challenges, we introduce the Dual-Balance Collaborative Experts
(DCE) framework. DCE employs a frequency-aware expert group, where each expert
is guided by specialized loss functions to learn features for specific
frequency groups, effectively addressing intra-domain class imbalance.
Subsequently, a dynamic expert selector is learned by synthesizing
pseudo-features through balanced Gaussian sampling from historical class
statistics. This mechanism navigates the trade-off between preserving many-shot
knowledge of previous domains and leveraging new data to improve few-shot class
performance in earlier tasks. Extensive experimental results on four benchmark
datasets demonstrate DCE's state-of-the-art performance.

</details>


### [100] [Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful](https://arxiv.org/abs/2507.07101)
*Martin Marek,Sanae Lotfi,Aditya Somasundaram,Andrew Gordon Wilson,Micah Goldblum*

Main category: cs.LG

TL;DR: 本文重新审视小批量大小训练，提出缩放Adam超参数规则，发现小批量训练稳定等优势并给出实用建议。


<details>
  <summary>Details</summary>
Motivation: 传统认为小批量训练不稳定促使使用梯度累积，且通常仅调整学习率，本文想重新研究小批量训练。

Method: 提出缩放Adam超参数到小批量大小的规则。

Result: 小批量训练稳定、对超参数选择更鲁棒、每FLOP性能更好、能让无动量SGD稳定训练。

Conclusion: 给出选择批量大小和设置优化器超参数的实用建议，建议除特定情况外不使用梯度累积。

Abstract: Conventional wisdom dictates that small batch sizes make language model
pretraining and fine-tuning unstable, motivating gradient accumulation, which
trades off the number of optimizer steps for a proportional increase in batch
size. While it is common to decrease the learning rate for smaller batch sizes,
other hyperparameters are often held fixed. In this work, we revisit small
batch sizes all the way down to batch size one, and we propose a rule for
scaling Adam hyperparameters to small batch sizes. We find that small batch
sizes (1) train stably, (2) are consistently more robust to hyperparameter
choices, (3) achieve equal or better per-FLOP performance than larger batch
sizes, and (4) notably enable stable language model training with vanilla SGD,
even without momentum, despite storing no optimizer state. Building on these
results, we provide practical recommendations for selecting a batch size and
setting optimizer hyperparameters. We further recommend against gradient
accumulation unless training on multiple devices with multiple model replicas,
bottlenecked by inter-device bandwidth.

</details>


### [101] [Does Data Scaling Lead to Visual Compositional Generalization?](https://arxiv.org/abs/2507.07102)
*Arnas Uselis,Andrea Dittadi,Seong Joon Oh*

Main category: cs.LG

TL;DR: 研究通过实验发现组合泛化由数据多样性驱动，预训练模型有部分有效结构，建议构建多样数据集。


<details>
  <summary>Details</summary>
Motivation: 当代视觉模型是否具备组合理解能力尚不明确，需验证扩大数据和模型规模能否提升分布外性能和组合泛化能力。

Method: 进行控制实验，系统改变数据规模、概念多样性和组合覆盖率。

Result: 组合泛化由数据多样性驱动；增加组合覆盖率促使模型发现线性分解的表征结构；预训练模型有部分有效结构。

Conclusion: 应更重视构建用于组合泛化的多样数据集，考虑能实现高效组合学习的表征结构的重要性。

Abstract: Compositional understanding is crucial for human intelligence, yet it remains
unclear whether contemporary vision models exhibit it. The dominant machine
learning paradigm is built on the premise that scaling data and model sizes
will improve out-of-distribution performance, including compositional
generalization. We test this premise through controlled experiments that
systematically vary data scale, concept diversity, and combination coverage. We
find that compositional generalization is driven by data diversity, not mere
data scale. Increased combinatorial coverage forces models to discover a
linearly factored representational structure, where concepts decompose into
additive components. We prove this structure is key to efficiency, enabling
perfect generalization from few observed combinations. Evaluating pretrained
models (DINO, CLIP), we find above-random yet imperfect performance, suggesting
partial presence of this structure. Our work motivates stronger emphasis on
constructing diverse datasets for compositional generalization, and considering
the importance of representational structure that enables efficient
compositional learning. Code available at
https://github.com/oshapio/visual-compositional-generalization.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [102] [gigiProfiler: Diagnosing Performance Issues by Uncovering Application Resource Bottlenecks](https://arxiv.org/abs/2507.06452)
*Yigong Hu,Haodong Zheng,Yicheng Liu,Dedong Xie,Youliang Huang,Baris Kasikci*

Main category: cs.PF

TL;DR: 提出OmniResource Profiling方法，实现gigiProfiler工具诊断性能瓶颈，经12个真实案例验证有效。


<details>
  <summary>Details</summary>
Motivation: 传统分析器难以解决应用级资源争用问题，需要新方法全面诊断资源瓶颈。

Method: 采用混合LLM - 静态分析方法离线识别应用定义资源，分析其对性能影响，采样记录关键变量并对比正常执行情况。

Result: 在12个真实性能问题中准确识别瓶颈，成功诊断两个新问题的根源并获开发者确认。

Conclusion: gigiProfiler能有效诊断软件性能瓶颈和根源。

Abstract: Diagnosing performance bottlenecks in modern software is essential yet
challenging, particularly as applications become more complex and rely on
custom resource management policies. While traditional profilers effectively
identify execution bottlenecks by tracing system-level metrics, they fall short
when it comes to application-level resource contention caused by waiting for
application-level events. In this work, we introduce OmniResource Profiling, a
performance analysis approach that integrates system-level and
application-level resource tracing to diagnose resource bottlenecks
comprehensively. gigiProfiler, our realization of OmniResource Profiling, uses
a hybrid LLM-static analysis approach to identify application-defined resources
offline and analyze their impact on performance during buggy executions to
uncover the performance bottleneck. gigiProfiler then samples and records
critical variables related to these bottleneck resources during buggy execution
and compares their value with those from normal executions to identify the root
causes. We evaluated gigiProfiler on 12 real-world performance issues across
five applications. gigiProfiler accurately identified performance bottlenecks
in all cases. gigiProfiler also successfully diagnosed the root causes of two
newly emerged, previously undiagnosed problems, with the findings confirmed by
developers.

</details>


### [103] [Uncertainty Quantification as a Complementary Latent Health Indicator for Remaining Useful Life Prediction on Turbofan Engines](https://arxiv.org/abs/2507.06672)
*Lucas Thil,Jesse Read,Rim Kaddah,Guillaume Florent Doquet*

Main category: cs.PF

TL;DR: 本文提出将不确定性量化集成到基于自编码器的潜在空间的框架，增强RaPP生成的健康指标，在NASA C - MAPSS涡轮风扇数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有方法如RaPP在预测系统故障的健康指标构建中，性能会受偶然和认知不确定性的阻碍，需要改进。

Method: 提出新框架，分离偶然和认知不确定性并交叉组合健康指标信息，使用标准和变分自编码器构建健康指标，训练机器学习模型进行剩余使用寿命预测。

Result: 在NASA C - MAPSS涡轮风扇数据集上，该方法优于传统基于健康指标的方法和端到端剩余使用寿命预测模型，与剩余使用寿命估计方法有竞争力。

Conclusion: 强调不确定性量化在健康评估中的重要性，将其纳入健康指标构建过程对预测性能有显著影响。

Abstract: Health Indicators (HIs) are essential for predicting system failures in
predictive maintenance. While methods like RaPP (Reconstruction along Projected
Pathways) improve traditional HI approaches by leveraging autoencoder latent
spaces, their performance can be hindered by both aleatoric and epistemic
uncertainties. In this paper, we propose a novel framework that integrates
uncertainty quantification into autoencoder-based latent spaces, enhancing
RaPP-generated HIs. We demonstrate that separating aleatoric uncertainty from
epistemic uncertainty and cross combining HI information is the driver of
accuracy improvements in Remaining Useful Life (RUL) prediction. Our method
employs both standard and variational autoencoders to construct these HIs,
which are then used to train a machine learning model for RUL prediction.
Benchmarked on the NASA C-MAPSS turbofan dataset, our approach outperforms
traditional HI-based methods and end-to-end RUL prediction models and is
competitive with RUL estimation methods. These results underscore the
importance of uncertainty quantification in health assessment and showcase its
significant impact on predictive performance when incorporated into the HI
construction process.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [104] [Quality attributes of test cases and test suites -- importance & challenges from practitioners' perspectives](https://arxiv.org/abs/2507.06343)
*Huynh Khanh Vi Tran,Nauman bin Ali,Michael Unterkalmsteiner,Jürgen Börstler,Panagiota Chatzipetrou*

Main category: cs.SE

TL;DR: 本文通过工业调查研究从业者对测试用例和测试套件质量属性重要性的看法及面临的挑战，发现部分重要属性，指出从业者需支持，研究结果可指导学术研究和企业决策。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽识别了测试用例和测试套件的质量属性，但需更好地理解其在实践中的相对重要性。

Method: 基于文献综述确定的质量属性设计问卷，利用领英抽样，开展工业调查。

Result: 收集354份不同经验从业者的回复，发现多数人认为故障检测、可用性等属性最重要，资源效率等属性看法分歧大，受测试上下文影响，还识别出常见挑战。

Conclusion: 研究结果指出不同测试上下文下从业者实现高质量测试所需支持，可为学术研究提供方向，鼓励企业提供更多支持。

Abstract: Context: The quality of the test suites and the constituent test cases
significantly impacts confidence in software testing. While research has
identified several quality attributes of test cases and test suites, there is a
need for a better understanding of their relative importance in practice.
Objective: We investigate practitioners' perceptions regarding the relative
importance of quality attributes of test cases and test suites and the
challenges they face in ensuring the perceived important quality attributes.
Method: We conducted an industrial survey using a questionnaire based on the
quality attributes identified in an extensive literature review. We used a
sampling strategy that leverages LinkedIn to draw a large and heterogeneous
sample of professionals with experience in software testing. Results: We
collected 354 responses from practitioners with a wide range of experience. We
found that the majority of practitioners rated Fault Detection, Usability,
Maintainability, Reliability, and Coverage to be the most important quality
attributes. Resource Efficiency, Reusability, and Simplicity received the most
divergent opinions, which, according to our analysis, depend on the
software-testing contexts. We identified common challenges that apply to the
important attributes, namely inadequate definition, lack of useful metrics,
lack of an established review process, and lack of external support.
Conclusion: The findings point out where practitioners actually need further
support with respect to achieving high-quality test cases and test suites under
different software testing contexts. The findings can serve as a guideline for
academic researchers when looking for research directions on the topic. The
findings can also be used to encourage companies to provide more support to
practitioners to achieve high-quality test cases and test suites.

</details>


### [105] [A proposal and assessment of an improved heuristic for the Eager Test smell detection](https://arxiv.org/abs/2507.06354)
*Huynh Khanh Vi Tran,Nauman bin Ali,Michael Unterkalmsteiner,Jürgen Börstler*

Main category: cs.SE

TL;DR: 文章旨在改进Eager Test气味检测规则，通过文献回顾提出新定义和启发式方法，经评估发现新方法能捕捉该气味本质，或解决现有规则不足。


<details>
  <summary>Details</summary>
Motivation: 现有Eager Test气味检测规则被从业者认为不够完善，需改进。

Method: 回顾测试气味相关文献，分析Eager Test气味定义和检测规则，提出新定义和启发式方法，并手动应用于300个Java单元测试用例进行评估。

Result: 文献回顾找到56项相关研究，发现对原始定义的不当解读导致检测规则不精确、检测结果差异大，新启发式方法能检测到现有规则遗漏的模式。

Conclusion: 新启发式方法能更精确捕捉Eager Test气味本质，可解决从业者对现有规则充分性的担忧。

Abstract: Context: The evidence for the prevalence of test smells at the unit testing
level has relied on the accuracy of detection tools, which have seen intense
research in the last two decades. The Eager Test smell, one of the most
prevalent, is often identified using simplified detection rules that
practitioners find inadequate. Objective: We aim to improve the rules for
detecting the Eager Test smell. Method: We reviewed the literature on test
smells to analyze the definitions and detection rules of the Eager Test smell.
We proposed a novel, unambiguous definition of the test smell and a heuristic
to address the limitations of the existing rules. We evaluated our heuristic
against existing detection rules by manually applying it to 300 unit test cases
in Java. Results: Our review identified 56 relevant studies. We found that
inadequate interpretations of original definitions of the Eager Test smell led
to imprecise detection rules, resulting in a high level of disagreement in
detection outcomes. Also, our heuristic detected patterns of eager and
non-eager tests that existing rules missed. Conclusion: Our heuristic captures
the essence of the Eager Test smell more precisely; hence, it may address
practitioners' concerns regarding the adequacy of existing detection rules.

</details>


### [106] [Evaluating Efficiency and Novelty of LLM-Generated Code for Graph Analysis](https://arxiv.org/abs/2507.06463)
*Atieh Barati Nia,Mohammad Dindoost,David A. Bader*

Main category: cs.SE

TL;DR: 对大语言模型生成高效C语言图分析例程代码能力进行系统研究，用两种方法对八个模型测试，Claude Sonnet 4 Extended表现最佳，证实当代模型擅优化和集成算法而非发明新方法。


<details>
  <summary>Details</summary>
Motivation: 多数先前评估聚焦功能正确性或高级语言，本文开展对大语言模型生成高效C语言图分析例程能力的首次系统研究。

Method: 用两种不同方法对八个最先进模型进行基准测试，一是检查模型生成优于基准中其他算法的能力，二是评估模型生成用于集成到基准中的图算法的能力。

Result: Claude Sonnet 4 Extended在可用代码生成和效率方面取得最佳结果，在三角形计数中超越人工编写的基线。

Conclusion: 当代大语言模型擅长优化和集成现有算法，但不擅长发明新的技术。

Abstract: Large Language Models (LLMs) are increasingly used to automate software
development, yet most prior evaluations focus on functional correctness or
high-level languages such as Python. We present the first systematic study of
LLMs' ability to generate efficient C implementations of graph-analysis
routines--code that must satisfy the stringent runtime and memory constraints.
Eight state-of-the-art models (OpenAI ChatGPT o3 and o4-mini-high, Anthropic
Claude 4 Sonnet and Sonnet Extended, Google Gemini 2.5 Flash and Pro, xAI Grok
3-Think, and DeepSeek DeepThink R1) are benchmarked by two distinct approaches.
The first approach checks the ability of LLMs in generating an algorithm
outperforming other present algorithms in the benchmark. The second approach
evaluates the ability of LLMs to generate graph algorithms for integration into
the benchmark. Results show that Claude Sonnet 4 Extended achieves the best
result in the case of ready-to-use code generation and efficiency,
outperforming human-written baselines in triangle counting. The study confirms
that contemporary LLMs excel at optimizing and integrating established
algorithms but not inventing novel techniques. We provide prompts, the first
approach's generated code, and measurement scripts to foster reproducible
research.

</details>


### [107] [Issue Tracking Ecosystems: Context and Best Practices](https://arxiv.org/abs/2507.06704)
*Lloyd Montgomery*

Main category: cs.SE

TL;DR: 研究问题跟踪生态系统（ITE），通过访谈和档案分析揭示其问题的上下文依赖性质，创建最佳实践本体。


<details>
  <summary>Details</summary>
Motivation: 问题跟踪生态系统（ITE）质量对组织和软件产品成功至关重要，但存在复杂网络和多样工作流等挑战，且整体需要进一步探索。

Method: 访谈从业者并对多种问题跟踪系统（ITS）进行档案分析。

Result: 分析揭示了ITE问题的上下文依赖性质，发现以往针对特定ITS问题的解决方案缺乏上下文且难以比较。

Conclusion: 需要针对特定上下文的ITE研究，为解决信息缺失和不一致问题，创建了ITE最佳实践本体。

Abstract: Issue Tracking Systems (ITSs), such as GitHub and Jira, are popular tools
that support Software Engineering (SE) organisations through the management of
``issues'', which represent different SE artefacts such as requirements,
development tasks, and maintenance items. ITSs also support internal linking
between issues, and external linking to other tools and information sources.
This provides SE organisations key forms of documentation, including forwards
and backwards traceability (e.g., Feature Requests linked to sprint releases
and code commits linked to Bug Reports). An Issue Tracking Ecosystem (ITE) is
the aggregate of the central ITS and the related SE artefacts, stakeholders,
and processes -- with an emphasis on how these contextual factors interact with
the ITS. The quality of ITEs is central to the success of these organisations
and their software products. There are challenges, however, within ITEs,
including complex networks of interlinked artefacts and diverse workflows.
While ITSs have been the subject of study in SE research for decades, ITEs as a
whole need further exploration.
  In this thesis, I undertake the challenge of understanding ITEs at a broader
level, addressing these questions regarding complexity and diversity. I
interviewed practitioners and performed archival analysis on a diverse set of
ITSs. These analyses revealed the context-dependent nature of ITE problems,
highlighting the need for context-specific ITE research. While previous work
has produced many solutions to specific ITS problems, these solutions are not
consistently framed in a context-rich and comparable way, leading to a desire
for more aligned solutions across research and practice. To address this
emergent information and lack of alignment, I created the Best Practice
Ontology for ITEs. <... truncated due to arXiv abstract character limit ...>

</details>


### [108] [Leveraging LLMs for Semantic Conflict Detection via Unit Test Generation](https://arxiv.org/abs/2507.06762)
*Nathalia Barbosa,Paulo Borba,Léuson Da Silva*

Main category: cs.SE

TL;DR: 传统合并工具无法检测语义冲突，SMAT 可检测但有高假阴性率。本文将基于 Code Llama 70B 的测试生成工具集成到 SMAT 中，评估其检测冲突的有效性，发现虽复杂场景仍有挑战但有改进潜力。


<details>
  <summary>Details</summary>
Motivation: 传统合并工具无法检测语义冲突，SMAT 有高假阴性率，探究大语言模型能否克服这些限制。

Method: 提出并将基于 Code Llama 70B 的新测试生成工具集成到 SMAT 中，探索不同交互策略、提示内容和参数配置生成测试，用简单系统基准和复杂真实系统样本评估。

Result: 大语言模型在复杂场景下的测试生成仍具挑战性且计算成本高。

Conclusion: 大语言模型在改进语义冲突检测方面有很有前景的潜力。

Abstract: Semantic conflicts arise when a developer introduces changes to a codebase
that unintentionally affect the behavior of changes integrated in parallel by
other developers. Traditional merge tools are unable to detect such conflicts,
so complementary tools like SMAT have been proposed. SMAT relies on generating
and executing unit tests: if a test fails on the base version, passes on a
developer's modified version, but fails again after merging with another
developer's changes, a semantic conflict is indicated. While SMAT is effective
at detecting conflicts, it suffers from a high rate of false negatives, partly
due to the limitations of unit test generation tools such as Randoop and
Evosuite. To investigate whether large language models (LLMs) can overcome
these limitations, we propose and integrate a new test generation tool based on
Code Llama 70B into SMAT. We explore the model's ability to generate tests
using different interaction strategies, prompt contents, and parameter
configurations. Our evaluation uses two samples: a benchmark with simpler
systems from related work, and a more significant sample based on complex,
real-world systems. We assess the effectiveness of the new SMAT extension in
detecting conflicts. Results indicate that, although LLM-based test generation
remains challenging and computationally expensive in complex scenarios, there
is promising potential for improving semantic conflict detection.
  --
  Conflitos sem^anticos surgem quando um desenvolvedor introduz mudan\c{c}as em
uma base de c\'odigo que afetam, de forma n~ao intencional, o comportamento de
altera\c{c}~oes integradas em paralelo por outros desenvolvedores. Ferramentas
tradicionais de merge n~ao conseguem detectar esse tipo de conflito, por isso
ferramentas complementares como o SMAT foram propostas. O SMAT depende da
gera\c{c}~ao e execu\c{c}~ao de testes de unidade: se um teste falha na vers~ao
base, passa na vers~ao modificada por um desenvolvedor, mas volta a falhar
ap\'os o merge com as mudan\c{c}as de outro desenvolvedor, um conflito
sem^antico \'e identificado. Embora o SMAT seja eficaz na detec\c{c}~ao de
conflitos, apresenta alta taxa de falsos negativos, em parte devido \`as
limita\c{c}~oes das ferramentas de gera\c{c}~ao de testes como Randoop e
Evosuite. Para investigar se modelos de linguagem de grande porte (LLMs) podem
superar essas limita\c{c}~oes, propomos e integramos ao SMAT uma nova
ferramenta de gera\c{c}~ao de testes baseada no Code Llama 70B. Exploramos a
capacidade do modelo de gerar testes utilizando diferentes estrat\'egias de
intera\c{c}~ao, conte\'udos de prompts e configura\c{c}~oes de par^ametros.
Nossa avalia\c{c}~ao utiliza duas amostras: um benchmark com sistemas mais
simples, usados em trabalhos relacionados, e uma amostra mais significativa
baseada em sistemas complexos e reais. Avaliamos a efic\'acia da nova extens~ao
do SMAT na detec\c{c}~ao de conflitos. Os resultados indicam que, embora a
gera\c{c}~ao de testes por LLM em cen\'arios complexos ainda seja desafiadora e
custosa computacionalmente, h\'a potencial promissor para aprimorar a
detec\c{c}~ao de conflitos sem^anticos.

</details>


### [109] [Formalization of the AADL Run-Time Services with Time](https://arxiv.org/abs/2507.06881)
*Brian R Larson,Ehsan Ahmad*

Main category: cs.SE

TL;DR: 本文使用Kripke结构定义的模态逻辑扩展并简化AADL形式化以显式包含时间，扩展RTS支持BA和BLESS，还给出含时间的AADL RTS示例。


<details>
  <summary>Details</summary>
Motivation: 现有研究为AADL形式语义奠定基础但未建模时间，本文旨在扩展其形式化以显式包含时间。

Method: 使用Kripke结构定义的模态逻辑扩展和简化AADL形式化；扩展AADL标准中的RTS以支持BA和BLESS。

Result: 实现了含时间的AADL RTS，给出用BLESS编写的状态转换机行为示例。

Conclusion: 通过扩展形式化和RTS，增强了AADL在处理时间和支持相关语言方面的能力。

Abstract: The Architecture Analysis & Design Language (AADL) is an architecture
description language for design of cyber-physical systems--machines controlled
by software. The AADL standard, SAE International AS5506D, describes Run-Time
Services (RTS) to be provided to execute AADL models in accordance with
semantics defined by the standard. The RTS of primary concern are transport
services and timing services. Although, the study presented in [1] sets a
foundation for the formal semantics of AADL, but without modeling time. This
paper extends and simplifies this formalization using a modal logic defined by
a Kripke structure, to explicitly include time. The RTS defined in the AADL
standard are also expanded to support reactive state-transition machines of the
Behavior Specification annex standard language (BA) and its closely-related,
formally-defined counterpart, the Behavior Language for Embedded Systems with
Software (BLESS). An example of AADL RTS with time, implemented by the High
Assurance Modeling and Rapid Engineering for Embedded Systems (HAMR) for
state-transition machine behavior written in BLESS, is also presented.

</details>


### [110] [Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation](https://arxiv.org/abs/2507.06980)
*Binquan Zhang,Li Zhang,Zhiwen Luo,Yuxin Du,Fang Liu,Song Wang,Lin Shi*

Main category: cs.SE

TL;DR: 本文通过分析代码生成基准中的失败样本，探究大语言模型生成思维链（CoT）质量不佳的内外部因素及对代码生成的影响，并提出改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前对大语言模型生成的CoT质量了解甚少，需探究其质量不佳的原因及对代码生成的影响。

Method: 分析1023个失败代码样本探究原因，分析210个CoT - 代码对评估影响，通过提示大语言模型改进不满意的CoT。

Result: 外部因素（53.60%）如需求不明确和缺乏上下文主要影响CoT质量，内部因素（40.10%）源于模型误解提示；即使CoT正确，18.5%生成代码仍有错误，11.90%正确代码对应有缺陷的CoT；改进低质量CoT是可行的。

Conclusion: 指出基于CoT的代码生成面临的关键挑战，并为提高大语言模型推理和可靠性提供方向。

Abstract: Large language models (LLMs) have demonstrated impressive performance in code
generation, particularly when augmented with chain-of-thought (CoT) prompting
techniques. They break down requirements into intermediate reasoning steps,
which act as design rationales to guide LLMs in writing code like human
programmers. Thus, the quality of these steps is crucial for ensuring the
correctness and reliability of the generated code. However, little is known
about the quality of CoT generated by LLMs. To what extent can we trust the
thoughts generated by LLMs? How good are they? This paper empirically explores
the external and internal factors of why LLMs generate unsatisfactory CoTs by
analyzing 1,023 failed code samples on two widely used code generation
benchmarks. We also evaluate their impact on code generation performance by
analyzing 210 CoT-code pairs and refining the unsatisfied CoTs by prompting
LLMs. Our study reveals three key findings: (1) External factors (53.60%), such
as unclear requirements and lack of context, mainly affect CoT quality, while
internal factors (40.10%) stem from LLMs' misunderstanding prompts. (2) Even
when CoTs are correct, 18.5% of the generated code contains errors due to
instruction-following issues; conversely, 11.90% of correct code is paired with
flawed CoTs. (3) Refining low-quality CoTs is feasible, i.e., LLMs improve when
given detailed problem descriptions. These findings highlight key challenges in
CoT-based code generation and suggest directions for improving LLM reasoning
and reliability.

</details>


### [111] [Exploring Fairness Interventions in Open Source Projects](https://arxiv.org/abs/2507.07026)
*Sadia Afrin Mim,Fatema Tuz Zohra,Justin Smith,Brittany Johnson*

Main category: cs.SE

TL;DR: 论文整理开源公平干预措施数据集，分析其特点，发现部分措施被积极维护及具备特定能力。


<details>
  <summary>Details</summary>
Motivation: 有多种机器学习公平干预措施，但实际应用中采用率低，很多从业者不知其存在。

Method: 系统识别并整理62个开源公平干预措施数据集，分析其规格和特点。

Result: 32%的干预措施在过去一年被积极维护，50%具备偏差检测和缓解能力，多在处理中阶段。

Conclusion: 未明确提及，但通过研究为推动公平干预措施应用提供了信息。

Abstract: The deployment of biased machine learning (ML) models has resulted in adverse
effects in crucial sectors such as criminal justice and healthcare. To address
these challenges, a diverse range of machine learning fairness interventions
have been developed, aiming to mitigate bias and promote the creation of more
equitable models. Despite the growing availability of these interventions,
their adoption in real-world applications remains limited, with many
practitioners unaware of their existence. To address this gap, we
systematically identified and compiled a dataset of 62 open source fairness
interventions and identified active ones. We conducted an in-depth analysis of
their specifications and features to uncover considerations that may drive
practitioner preference and to identify the software interventions actively
maintained in the open source ecosystem. Our findings indicate that 32% of
these interventions have been actively maintained within the past year, and 50%
of them offer both bias detection and mitigation capabilities, mostly during
inprocessing.

</details>


### [112] [5C Prompt Contracts: A Minimalist, Creative-Friendly, Token-Efficient Design Framework for Individual and SME LLM Usage](https://arxiv.org/abs/2507.07045)
*Ugur Ari*

Main category: cs.SE

TL;DR: 文章提出5C Prompt Contract框架改进提示设计，提升输入令牌效率，适合资源有限者。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型用于关键任务，需要明确、系统且实用的提示设计框架，现有方法有不足。

Method: 提出5C Prompt Contract框架，将提示设计提炼为五个直观组件。

Result: 5C框架在不同大语言模型架构中实现更优输入令牌效率，输出丰富一致。

Conclusion: 5C框架适合AI工程资源有限的个人和中小企业。

Abstract: The progression from traditional prompt engineering to a more rigorous
discipline of prompt design marks a pivotal shift in human-LLM interaction. As
Large Language Models (LLMs) become increasingly embedded in mission-critical
applications, there emerges a pressing need for frameworks that are not only
explicit and systematic but also minimal enough to remain practical and broadly
accessible. While many existing approaches address prompt structuring through
elaborate Domain-Specific Languages (DSLs) or multi-layered templates, such
methods can impose significant token and cognitive overhead, potentially
constraining the model's creative capacity. In this context, we propose the 5C
Prompt Contract, a framework that distills prompt design into five intuitive
components: Character, Cause, Constraint, Contingency, and Calibration. This
minimal cognitive schema explicitly integrates fallback and output optimization
directives, fostering reliable, interpretable, and creatively flexible AI
interactions. Experimental results demonstrate that the 5C framework
consistently achieves superior input token efficiency while maintaining rich
and consistent outputs across diverse LLM architectures (OpenAI, Anthropic,
DeepSeek, and Gemini), making it particularly suited for individuals and
Small-to-Medium Enterprises (SMEs) with limited AI engineering resources.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [113] [Machine Learning based Enterprise Financial Audit Framework and High Risk Identification](https://arxiv.org/abs/2507.06266)
*Tingyu Yuan,Xi Zhang,Xuanjing Chen*

Main category: q-fin.RM

TL;DR: 本文提出AI驱动的企业财务审计与高风险识别框架，评估三种算法，发现随机森林表现最佳，推荐采用该模型进行智能审计与风险管理。


<details>
  <summary>Details</summary>
Motivation: 面对全球经济不确定性，传统手动审计方法在大数据量、复杂业务结构和不断演变的欺诈策略下受限，需要新方法提升财务审计效率与准确性。

Method: 利用四大会计师事务所2020 - 2025年数据集，评估支持向量机（SVM）、随机森林（RF）和K近邻（KNN）三种算法，通过分层K折交叉验证和F1分数、准确率、召回率评估。

Result: 随机森林表现最佳，F1分数达0.9012，能有效识别欺诈和合规异常，特征重要性分析确定审计频率、过往违规、员工工作量和客户评级为关键预测因素。

Conclusion: 建议采用随机森林作为核心模型，通过特征工程增强特征并实施实时风险监控，为现代企业智能审计和风险管理提供有价值见解。

Abstract: In the face of global economic uncertainty, financial auditing has become
essential for regulatory compliance and risk mitigation. Traditional manual
auditing methods are increasingly limited by large data volumes, complex
business structures, and evolving fraud tactics. This study proposes an
AI-driven framework for enterprise financial audits and high-risk
identification, leveraging machine learning to improve efficiency and accuracy.
Using a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG)
from 2020 to 2025, the research examines trends in risk assessment, compliance
violations, and fraud detection. The dataset includes key indicators such as
audit project counts, high-risk cases, fraud instances, compliance breaches,
employee workload, and client satisfaction, capturing both audit behaviors and
AI's impact on operations. To build a robust risk prediction model, three
algorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest
Neighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex
classification, RF combines decision trees to manage high-dimensional,
nonlinear data with resistance to overfitting, and KNN applies distance-based
learning for flexible performance. Through hierarchical K-fold cross-validation
and evaluation using F1-score, accuracy, and recall, Random Forest achieves the
best performance, with an F1-score of 0.9012, excelling in identifying fraud
and compliance anomalies. Feature importance analysis reveals audit frequency,
past violations, employee workload, and client ratings as key predictors. The
study recommends adopting Random Forest as a core model, enhancing features via
engineering, and implementing real-time risk monitoring. This research
contributes valuable insights into using machine learning for intelligent
auditing and risk management in modern enterprises.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [114] [Reinforcement Learning for Trade Execution with Market Impact](https://arxiv.org/abs/2507.06345)
*Patrick Cheridito,Moritz Weiss*

Main category: q-fin.TR

TL;DR: 提出用于限价订单簿最优交易执行的强化学习框架，实验显示优于传统策略。


<details>
  <summary>Details</summary>
Motivation: 解决限价订单簿中的最优交易执行问题，最大化预期收入。

Method: 将交易执行问题表述为动态分配任务，用多元逻辑正态分布建模随机分配以训练强化学习算法。

Result: 在模拟的限价订单簿环境中，所提方法优于传统基准策略。

Conclusion: 所提出的强化学习框架在限价订单簿的最优交易执行方面有效。

Abstract: In this paper, we introduce a novel reinforcement learning framework for
optimal trade execution in a limit order book. We formulate the trade execution
problem as a dynamic allocation task whose objective is the optimal placement
of market and limit orders to maximize expected revenue. By employing
multivariate logistic-normal distributions to model random allocations, the
framework enables efficient training of the reinforcement learning algorithm.
Numerical experiments show that the proposed method outperforms traditional
benchmark strategies in simulated limit order book environments featuring noise
traders submitting random orders, tactical traders responding to order book
imbalances, and a strategic trader seeking to acquire or liquidate an asset
position.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [115] [On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective](https://arxiv.org/abs/2507.06552)
*Zhiyi Dong,Zixuan Liu,Yongyi Mao*

Main category: stat.ML

TL;DR: 研究协变量偏移下无监督域适应（UDA）的难度，提出PTLU和EPTLU量化难度。


<details>
  <summary>Details</summary>
Motivation: 精确刻画UDA难度，避免经典最坏情况分析的局限性。

Method: 用分布π建模学习者面临的不确定性，定义整体目标域风险，引入PTLU和EPTLU。

Result: 证明PTLU可作为任何学习者风险的下界，通过例子展示其评估UDA学习难度的优势。

Conclusion: PTLU和EPTLU可作为评估UDA学习难度的代理指标。

Abstract: This paper studies the hardness of unsupervised domain adaptation (UDA) under
covariate shift. We model the uncertainty that the learner faces by a
distribution $\pi$ in the ground-truth triples $(p, q, f)$ -- which we call a
UDA class -- where $(p, q)$ is the source -- target distribution pair and $f$
is the classifier. We define the performance of a learner as the overall target
domain risk, averaged over the randomness of the ground-truth triple. This
formulation couples the source distribution, the target distribution and the
classifier in the ground truth, and deviates from the classical worst-case
analyses, which pessimistically emphasize the impact of hard but rare UDA
instances. In this formulation, we precisely characterize the optimal learner.
The performance of the optimal learner then allows us to define the learning
difficulty for the UDA class and for the observed sample. To quantify this
difficulty, we introduce an information-theoretic quantity -- Posterior Target
Label Uncertainty (PTLU) -- along with its empirical estimate (EPTLU) from the
sample , which capture the uncertainty in the prediction for the target domain.
Briefly, PTLU is the entropy of the predicted label in the target domain under
the posterior distribution of ground-truth classifier given the observed source
and target samples. By proving that such a quantity serves to lower-bound the
risk of any learner, we suggest that these quantities can be used as proxies
for evaluating the hardness of UDA learning. We provide several examples to
demonstrate the advantage of PTLU, relative to the existing measures, in
evaluating the difficulty of UDA learning.

</details>


### [116] [Semi-parametric Functional Classification via Path Signatures Logistic Regression](https://arxiv.org/abs/2507.06637)
*Pengcheng Zeng,Siyuan Jiang*

Main category: stat.ML

TL;DR: 提出路径签名逻辑回归（PSLR）框架用于向量值函数数据分类，克服传统方法局限，实验显示其性能更优。


<details>
  <summary>Details</summary>
Motivation: 传统功能逻辑回归模型依赖线性假设和固定基扩展，在不规则采样下灵活性受限、性能下降。

Method: 利用截断路径签名构建无基表示，将轨迹嵌入为时间增强路径提取特征，建立最优截断阶的理论保证和非渐近风险界。

Result: 在合成和真实数据集实验中，PSLR在准确性、鲁棒性和可解释性上优于传统功能分类器，尤其在非均匀采样方案下。

Conclusion: 将粗糙路径理论集成到现代功能数据分析有实际和理论益处。

Abstract: We propose Path Signatures Logistic Regression (PSLR), a semi-parametric
framework for classifying vector-valued functional data with scalar covariates.
Classical functional logistic regression models rely on linear assumptions and
fixed basis expansions, which limit flexibility and degrade performance under
irregular sampling. PSLR overcomes these issues by leveraging truncated path
signatures to construct a finite-dimensional, basis-free representation that
captures nonlinear and cross-channel dependencies. By embedding trajectories as
time-augmented paths, PSLR extracts stable, geometry-aware features that are
robust to sampling irregularity without requiring a common time grid, while
still preserving subject-specific timing patterns. We establish theoretical
guarantees for the existence and consistent estimation of the optimal
truncation order, along with non-asymptotic risk bounds. Experiments on
synthetic and real-world datasets show that PSLR outperforms traditional
functional classifiers in accuracy, robustness, and interpretability,
particularly under non-uniform sampling schemes. Our results highlight the
practical and theoretical benefits of integrating rough path theory into modern
functional data analysis.

</details>


### [117] [Fast Gaussian Processes under Monotonicity Constraints](https://arxiv.org/abs/2507.06677)
*Chao Zhang,Jasper M. Everink,Jakob Sauer Jørgensen*

Main category: stat.ML

TL;DR: 提出基于虚拟点框架构建单调约束下高斯过程模型，改进现有方法，经合成函数验证及微分方程系统应用，展示了计算效率提升。


<details>
  <summary>Details</summary>
Motivation: 利用函数单调性等先验知识改进高斯过程模型保真度，但高维问题计算挑战大，需高效方法。

Method: 提出基于正则化线性随机化再优化（RLRTO）的虚拟点框架；用No U - Turn Sampler（NUTS）替代吉布斯采样改进现有方法。

Result: Python实现方法，在合成函数近似中各方法预测性能相当，NUTS方法和RLRTO方法计算效率显著提升。

Conclusion: 所提框架和改进方法在构建约束高斯过程模型上有效，计算效率有提升，可应用于微分方程系统构建替代模型。

Abstract: Gaussian processes (GPs) are widely used as surrogate models for complicated
functions in scientific and engineering applications. In many cases, prior
knowledge about the function to be approximated, such as monotonicity, is
available and can be leveraged to improve model fidelity. Incorporating such
constraints into GP models enhances predictive accuracy and reduces
uncertainty, but remains a computationally challenging task for
high-dimensional problems. In this work, we present a novel virtual point-based
framework for building constrained GP models under monotonicity constraints,
based on regularized linear randomize-then-optimize (RLRTO), which enables
efficient sampling from a constrained posterior distribution by means of
solving randomized optimization problems. We also enhance two existing virtual
point-based approaches by replacing Gibbs sampling with the No U-Turn Sampler
(NUTS) for improved efficiency. A Python implementation of these methods is
provided and can be easily applied to a wide range of problems. This
implementation is then used to validate the approaches on approximating a range
of synthetic functions, demonstrating comparable predictive performance between
all considered methods and significant improvements in computational efficiency
with the two NUTS methods and especially with the RLRTO method. The framework
is further applied to construct surrogate models for systems of differential
equations.

</details>


### [118] [Adaptive collaboration for online personalized distributed learning with heterogeneous clients](https://arxiv.org/abs/2507.06844)
*Constantin Philippenko,Batiste Le Bars,Kevin Scaman,Laurent Massoulié*

Main category: stat.ML

TL;DR: 研究在线个性化去中心化学习中客户端协作问题，提出基于梯度的协作准则，推导损失上界，提出两种协作方法并实验验证。


<details>
  <summary>Details</summary>
Motivation: 解决在线个性化去中心化学习中选择相关协作者以减少梯度方差并减轻偏差的挑战。

Method: 引入基于梯度的协作准则，基于对All - for - one算法的理论分析，推导光滑目标函数的超额损失上界，提出两种协作方法。

Result: 分析表明算法是一种方差缩减方法，一种变体保留了All - for - one的最优性，实验验证了结果。

Conclusion: 所提基于梯度的协作准则和协作方法在在线个性化去中心化学习中有效果。

Abstract: We study the problem of online personalized decentralized learning with $N$
statistically heterogeneous clients collaborating to accelerate local training.
An important challenge in this setting is to select relevant collaborators to
reduce gradient variance while mitigating the introduced bias. To tackle this,
we introduce a gradient-based collaboration criterion, allowing each client to
dynamically select peers with similar gradients during the optimization
process. Our criterion is motivated by a refined and more general theoretical
analysis of the All-for-one algorithm, proved to be optimal in Even et al.
(2022) for an oracle collaboration scheme. We derive excess loss upper-bounds
for smooth objective functions, being either strongly convex, non-convex, or
satisfying the Polyak-Lojasiewicz condition; our analysis reveals that the
algorithm acts as a variance reduction method where the speed-up depends on a
sufficient variance. We put forward two collaboration methods instantiating the
proposed general schema; and we show that one variant preserves the optimality
of All-for-one. We validate our results with experiments on synthetic and real
datasets.

</details>


### [119] [Conformal Prediction for Long-Tailed Classification](https://arxiv.org/abs/2507.06867)
*Tiffany Ding,Jean-Baptiste Fermanian,Joseph Salmon*

Main category: stat.ML

TL;DR: 提出保证边际覆盖率的方法，在集合大小和类条件覆盖率间权衡，在两个长尾图像数据集验证。


<details>
  <summary>Details</summary>
Motivation: 现实分类问题多为长尾分布，现有共形预测方法在长尾场景下，从业者需在小集合但类条件覆盖率差和类条件覆盖率好但集合大之间做选择。

Method: 提出共形得分函数——流行度调整softmax以实现宏覆盖率；提出标签加权共形预测方法在边际和类条件共形预测间插值。

Result: 在Pl@ntNet和iNaturalist两个长尾图像数据集上进行了方法验证。

Conclusion: 所提方法可保证边际覆盖率，能在集合大小和类条件覆盖率间平滑权衡。

Abstract: Many real-world classification problems, such as plant identification, have
extremely long-tailed class distributions. In order for prediction sets to be
useful in such settings, they should (i) provide good class-conditional
coverage, ensuring that rare classes are not systematically omitted from the
prediction sets, and (ii) be a reasonable size, allowing users to easily verify
candidate labels. Unfortunately, existing conformal prediction methods, when
applied to the long-tailed setting, force practitioners to make a binary choice
between small sets with poor class-conditional coverage or sets with very good
class-conditional coverage but that are extremely large. We propose methods
with guaranteed marginal coverage that smoothly trade off between set size and
class-conditional coverage. First, we propose a conformal score function,
prevalence-adjusted softmax, that targets a relaxed notion of class-conditional
coverage called macro-coverage. Second, we propose a label-weighted conformal
prediction method that allows us to interpolate between marginal and
class-conditional conformal prediction. We demonstrate our methods on Pl@ntNet
and iNaturalist, two long-tailed image datasets with 1,081 and 8,142 classes,
respectively.

</details>


### [120] [Distribution-free inference for LightGBM and GLM with Tweedie loss](https://arxiv.org/abs/2507.06921)
*Alokesh Manna,Aditya Vikram Sett,Dipak K. Dey,Yuwen Gu,Elizabeth D. Schifano,Jichao He*

Main category: stat.ML

TL;DR: 本文提出适用于GLMs和GBMs的新非一致性度量，通过正则化Tweedie GLM回归和带Tweedie损失的LightGBM，在保险理赔数据中展示了共形预测性能，模拟结果显示局部加权Pearson残差用于LightGBM效果更佳。


<details>
  <summary>Details</summary>
Motivation: 预测不确定性量化是科研和商业问题的关键话题，在保险行业评估单个驾驶员可能的索赔成本范围，可提高保费定价准确性并有效管理风险。

Method: 提出适用于GLMs和GBMs的新非一致性度量，使用正则化Tweedie GLM回归和带Tweedie损失的LightGBM。

Result: 模拟结果显示局部加权Pearson残差用于LightGBM效果更好，得到的区间能维持名义覆盖率且平均宽度最小。

Conclusion: 新提出的非一致性度量在保险理赔数据的共形预测中有一定效果，局部加权Pearson残差用于LightGBM更具优势。

Abstract: Prediction uncertainty quantification is a key research topic in recent years
scientific and business problems. In insurance industries
(\cite{parodi2023pricing}), assessing the range of possible claim costs for
individual drivers improves premium pricing accuracy. It also enables insurers
to manage risk more effectively by accounting for uncertainty in accident
likelihood and severity. In the presence of covariates, a variety of
regression-type models are often used for modeling insurance claims, ranging
from relatively simple generalized linear models (GLMs) to regularized GLMs to
gradient boosting models (GBMs). Conformal predictive inference has arisen as a
popular distribution-free approach for quantifying predictive uncertainty under
relatively weak assumptions of exchangeability, and has been well studied under
the classic linear regression setting. In this work, we propose new
non-conformity measures for GLMs and GBMs with GLM-type loss. Using regularized
Tweedie GLM regression and LightGBM with Tweedie loss, we demonstrate conformal
prediction performance with these non-conformity measures in insurance claims
data. Our simulation results favor the use of locally weighted Pearson
residuals for LightGBM over other methods considered, as the resulting
intervals maintained the nominal coverage with the smallest average width.

</details>


### [121] [Off-Policy Evaluation Under Nonignorable Missing Data](https://arxiv.org/abs/2507.06961)
*Han Wang,Yang Xu,Wenbin Lu,Rui Song*

Main category: stat.ML

TL;DR: 研究单调缺失数据下离线策略评估（OPE），理论分析缺失数据影响，提出逆概率加权值估计器，实验表明其在缺失数据下更可靠。


<details>
  <summary>Details</summary>
Motivation: 现实应用中记录数据常存在缺失情况，而现有研究对缺失数据如何影响OPE结果理论理解不清。

Method: 理论证明在可忽略缺失下值估计无偏，不可忽略缺失下有偏；提出逆概率加权值估计器并进行统计推断。

Result: 通过数值实验表明提出的估计器在缺失数据下能产生更可靠的值推断。

Conclusion: 提出的逆概率加权值估计器有助于在有缺失数据的情况下进行更可靠的OPE。

Abstract: Off-Policy Evaluation (OPE) aims to estimate the value of a target policy
using offline data collected from potentially different policies. In real-world
applications, however, logged data often suffers from missingness. While OPE
has been extensively studied in the literature, a theoretical understanding of
how missing data affects OPE results remains unclear. In this paper, we
investigate OPE in the presence of monotone missingness and theoretically
demonstrate that the value estimates remain unbiased under ignorable
missingness but can be biased under nonignorable (informative) missingness. To
retain the consistency of value estimation, we propose an inverse probability
weighted value estimator and conduct statistical inference to quantify the
uncertainty of the estimates. Through a series of numerical experiments, we
empirically demonstrate that our proposed estimator yields a more reliable
value inference under missing data.

</details>


<div id='stat.CO'></div>

# stat.CO [[Back]](#toc)

### [122] [stCEG: An R Package for Modelling Events over Spatial Areas Using Chain Event Graphs](https://arxiv.org/abs/2507.06726)
*Hollie Calley,Daniel Williamson*

Main category: stat.CO

TL;DR: stCEG是一个R包，可从数据指定CEG模型、生成交互图，有可视化功能和网页GUI，用伦敦凶杀案数据演示，是首个支持CEG模型完全定制的软件包。


<details>
  <summary>Details</summary>
Motivation: 为用户提供能完全定制CEG模型、方便使用且可可视化空间变量的工具。

Method: 开发stCEG R包，包含可视化函数和网页GUI，并使用伦敦凶杀案数据集进行演示。

Result: 成功开发stCEG软件包，可从数据指定CEG模型、生成交互图，有可视化和网页GUI等功能。

Conclusion: stCEG是首个支持CEG模型完全定制的软件包，提高了CEG模型使用的便利性。

Abstract: stCEG is an R package which allows a user to fully specify a Chain Event
Graph (CEG) model from data and to produce interactive plots. It includes
functions for the user to visualise spatial variables they wish to include in
the model. There is also a web-based graphical user interface (GUI) provided,
increasing ease of use for those without knowledge of R. We demonstrate stCEG
using a dataset of homicides in London, which is included in the package. stCEG
is the first software package for CEGs that allows for full model
customisation.

</details>


### [123] [Accelerated Spatio-Temporal Bayesian Modeling for Multivariate Gaussian Processes](https://arxiv.org/abs/2507.06938)
*Lisa Gaedke-Merzhäuser,Vincent Maillou,Fernando Rodriguez Avellaneda,Olaf Schenk,Mathieu Luisier,Paula Moraga,Alexandros Nikolaos Ziogas,Håvard Rue*

Main category: stat.CO

TL;DR: 提出DALIA框架用于时空多变量高斯过程贝叶斯推理，展示了优越的缩放性能和在空气污染数据中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 多变量高斯过程在高维时空应用中存在计算挑战，需要可扩展的方法。

Method: 基于集成嵌套拉普拉斯近似方法，采用稀疏逆协方差矩阵公式、GPU加速块密集方法和分层三层分布式内存并行方案。

Result: 弱缩放性能比现有技术高两个数量级，在496个GH200超级芯片上强缩放加速比达三个数量级，应用于意大利北部空气污染数据有更精细空间分辨率。

Conclusion: DALIA框架在时空多变量高斯过程贝叶斯推理中具有高效性和实用性。

Abstract: Multivariate Gaussian processes (GPs) offer a powerful probabilistic
framework to represent complex interdependent phenomena. They pose, however,
significant computational challenges in high-dimensional settings, which
frequently arise in spatial-temporal applications. We present DALIA, a highly
scalable framework for performing Bayesian inference tasks on spatio-temporal
multivariate GPs, based on the methodology of integrated nested Laplace
approximations. Our approach relies on a sparse inverse covariance matrix
formulation of the GP, puts forward a GPU-accelerated block-dense approach, and
introduces a hierarchical, triple-layer, distributed memory parallel scheme. We
showcase weak scaling performance surpassing the state-of-the-art by two orders
of magnitude on a model whose parameter space is 8$\times$ larger and measure
strong scaling speedups of three orders of magnitude when running on 496 GH200
superchips on the Alps supercomputer. Applying DALIA to air pollution data from
northern Italy over 48 days, we showcase refined spatial resolutions over the
aggregated pollutant measurements.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [124] [Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity](https://arxiv.org/abs/2507.06479)
*Niloofar Asefi,Leonard Lupin-Jimenez,Tianning Wu,Ruoying He,Ashesh Chattopadhyay*

Main category: physics.ao-ph

TL;DR: 利用结合神经算子与去噪扩散概率模型的深度学习框架，从极稀疏拉格朗日观测数据中重建高分辨率海洋状态，表现优于其他深度学习基线。


<details>
  <summary>Details</summary>
Motivation: 海洋观测数据稀疏、不规则等特性限制海洋动力学重建，传统方法和深度学习模型在这种约束下难以恢复中尺度湍流，影响关键现象预测。

Method: 采用结合神经算子与去噪扩散概率模型的深度学习框架，通过将生成模型基于神经算子输出进行条件化。

Result: 该框架在99%（合成数据）和99.9%（真实卫星观测）的稀疏度下能准确捕捉小尺度、高波数动力学，在基准系统、合成浮标观测和真实卫星数据上验证了方法性能。

Conclusion: 该方法在严重空间采样限制下表现稳健，优于其他深度学习基线。

Abstract: Reconstructing ocean dynamics from observational data is fundamentally
limited by the sparse, irregular, and Lagrangian nature of spatial sampling,
particularly in subsurface and remote regions. This sparsity poses significant
challenges for forecasting key phenomena such as eddy shedding and rogue waves.
Traditional data assimilation methods and deep learning models often struggle
to recover mesoscale turbulence under such constraints. We leverage a deep
learning framework that combines neural operators with denoising diffusion
probabilistic models (DDPMs) to reconstruct high-resolution ocean states from
extremely sparse Lagrangian observations. By conditioning the generative model
on neural operator outputs, the framework accurately captures small-scale,
high-wavenumber dynamics even at $99\%$ sparsity (for synthetic data) and
$99.9\%$ sparsity (for real satellite observations). We validate our method on
benchmark systems, synthetic float observations, and real satellite data,
demonstrating robust performance under severe spatial sampling limitations as
compared to other deep learning baselines.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [125] [Designing Robust Software Sensors for Nonlinear Systems via Neural Networks and Adaptive Sliding Mode Control](https://arxiv.org/abs/2507.06817)
*Ayoub Farkane,Mohamed Boutayeb,Mustapha Oudani,Mounir Ghogho*

Main category: math.DS

TL;DR: 本文提出一种为非线性动态系统设计软件传感器的新方法，将神经网络与自适应滑模控制结合，利用测量数据和物理约束训练，能实时适应系统变化，经仿真验证有效且具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在直接测量所有状态不可行时，准确获取动态系统状态变量对控制、诊断和监督至关重要，传统模型观测器有局限性。

Method: 将神经网络与自适应滑模控制集成，利用传感器测量数据修正观测器状态估计，以系统控制方程为物理约束进行训练，用神经网络动态调整时变增益矩阵。

Result: 通过对具挑战性的示例进行仿真，结果显示该方法收敛快、精度高。

Conclusion: 该方法具有鲁棒性和广泛适用性，有潜力解决现实世界复杂的状态估计挑战。

Abstract: Accurate knowledge of the state variables in a dynamical system is critical
for effective control, diagnosis, and supervision, especially when direct
measurements of all states are infeasible. This paper presents a novel approach
to designing software sensors for nonlinear dynamical systems expressed in
their most general form. Unlike traditional model-based observers that rely on
explicit transformations or linearization, the proposed framework integrates
neural networks with adaptive Sliding Mode Control (SMC) to design a robust
state observer under a less restrictive set of conditions. The learning process
is driven by available sensor measurements, which are used to correct the
observer's state estimate. The training methodology leverages the system's
governing equations as a physics-based constraint, enabling observer synthesis
without access to ground-truth state trajectories. By employing a time-varying
gain matrix dynamically adjusted by the neural network, the observer adapts in
real-time to system changes, ensuring robustness against noise, external
disturbances, and variations in system dynamics. Furthermore, we provide
sufficient conditions to guarantee estimation error convergence, establishing a
theoretical foundation for the observer's reliability. The methodology's
effectiveness is validated through simulations on challenging examples,
including systems with non-differentiable dynamics and varying observability
conditions. These examples, which are often problematic for conventional
techniques, serve to demonstrate the robustness and broad applicability of our
approach. The results show rapid convergence and high accuracy, underscoring
the method's potential for addressing complex state estimation challenges in
real-world applications.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [126] [Non-asymptotic confidence regions on RKHS. The Paley-Wiener and standard Sobolev space cases](https://arxiv.org/abs/2507.06657)
*Fabrice Gamboa,Olivier Roustant*

Main category: math.ST

TL;DR: 本文考虑在随机设计上为未知函数构建全局、概率性和非渐近置信区域的问题，指出可将其转化为准确估计未知函数的RKHS范数，并聚焦于Paley - Wiener和标准Sobolev空间设置。


<details>
  <summary>Details</summary>
Motivation: 解决在随机设计上为未知函数构建全局、概率性和非渐近置信区域的问题。

Method: 将构建置信区域问题转化为准确估计未知函数的RKHS范数，主要在Paley - Wiener和标准Sobolev空间设置下进行分析。

Result: 证明构建置信区域问题可转化为准确估计未知函数的RKHS范数。

Conclusion: 可通过准确估计未知函数的RKHS范数来构建随机设计上未知函数的全局、概率性和非渐近置信区域。

Abstract: We consider the problem of constructing a global, probabilistic, and
non-asymptotic confidence region for an unknown function observed on a random
design. The unknown function is assumed to lie in a reproducing kernel Hilbert
space (RKHS). We show that this construction can be reduced to accurately
estimating the RKHS norm of the unknown function. Our analysis primarily
focuses both on the Paley-Wiener and on the standard Sobolev space settings.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [127] [OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion](https://arxiv.org/abs/2507.06849)
*Yizhuo Wu,Ang Li,Chang Gao*

Main category: eess.SP

TL;DR: 本文提出OpenDPDv2框架，采用新DPD算法和节能方法，降低功率消耗同时保持高线性化性能，模型效果好且代码等公开。


<details>
  <summary>Details</summary>
Motivation: 神经网络数字预失真（NN DPD）有效但能耗高，需降低射频系统数字后端能耗。

Method: 提出OpenDPDv2框架，使用TRes - DeltaGRU算法和两种节能方法。

Result: 32位浮点TRes - DeltaGRU - DPD模型ACPR达 - 59.4 dBc，EVM达 - 42.1 dBc；利用量化和稀疏性，推理能耗降4.5倍，保持 - 50.3 dBc ACPR和 - 35.2 dB EVM。

Conclusion: OpenDPDv2框架能在降低功率消耗的同时保持高线性化性能。

Abstract: Neural network (NN)-based Digital Predistortion (DPD) stands out in improving
signal quality in wideband radio frequency (RF) power amplifiers (PAs)
employing complex modulation. However, NN DPDs usually rely on a large number
of parameters for effective linearization and can significantly contribute to
the energy consumption of the digital back-end in RF systems. This paper
presents OpenDPDv2, a unified framework for PA modeling, DPD learning, and
model optimization to reduce power consumption while maintaining high
linearization performance. The optimization techniques feature a novel DPD
algorithm, TRes-DeltaGRU, alongside two energy-efficient methods. The
top-performing 32-bit floating-point (FP32) TRes-DeltaGRU-DPD model achieves an
Adjacent Channel Power Ratio (ACPR) of -59.4 dBc and Error Vector Magnitude
(EVM) of -42.1 dBc. By exploiting fixed-point quantization and dynamic temporal
sparsity of input signals and hidden neurons, the inference energy of our model
can be reduced by 4.5X while still maintaining -50.3 dBc ACPR and -35.2 dB EVM
with 56% temporal sparsity. This was evaluated using a TM3.1a 200 MHz bandwidth
256-QAM OFDM signal applied to a 3.5 GHz GaN Doherty RF PA. OpenDPDv2 code,
datasets, and documentation are publicly accessible at:
https://github.com/lab-emi/OpenDPD.

</details>


### [128] [Federated Learning-based MARL for Strengthening Physical-Layer Security in B5G Networks](https://arxiv.org/abs/2507.06997)
*Deemah H. Tashman,Soumaya Cherkaoui,Walaa Hamouda*

Main category: eess.SP

TL;DR: 本文探索基于联邦学习的多智能体强化学习策略在多蜂窝网络物理层安全中的应用，比较两种DRL方法，展示结果和性能优势。


<details>
  <summary>Details</summary>
Motivation: 在超5G网络的多蜂窝网络中，提升物理层安全，防止窃听者截获合法用户信息。

Method: 在每个小区，基站作为DRL智能体与环境交互，采用联邦学习仅共享网络参数；探索并比较DQN和RDPG两种DRL方法。

Result: RDPG比DQN收敛更快，所提方法优于分布式DRL方法，存在安全与复杂度的权衡。

Conclusion: 基于联邦学习的MARL策略在多蜂窝网络物理层安全中有良好应用效果。

Abstract: This paper explores the application of a federated learning-based multi-agent
reinforcement learning (MARL) strategy to enhance physical-layer security (PLS)
in a multi-cellular network within the context of beyond 5G networks. At each
cell, a base station (BS) operates as a deep reinforcement learning (DRL) agent
that interacts with the surrounding environment to maximize the secrecy rate of
legitimate users in the presence of an eavesdropper. This eavesdropper attempts
to intercept the confidential information shared between the BS and its
authorized users. The DRL agents are deemed to be federated since they only
share their network parameters with a central server and not the private data
of their legitimate users. Two DRL approaches, deep Q-network (DQN) and
Reinforce deep policy gradient (RDPG), are explored and compared. The results
demonstrate that RDPG converges more rapidly than DQN. In addition, we
demonstrate that the proposed method outperforms the distributed DRL approach.
Furthermore, the outcomes illustrate the trade-off between security and
complexity.

</details>


### [129] [How to Bridge the Sim-to-Real Gap in Digital Twin-Aided Telecommunication Networks](https://arxiv.org/abs/2507.07067)
*Clement Ruah,Houssem Sifaou,Osvaldo Simeone,Bashir M. Al-Hashimi*

Main category: eess.SP

TL;DR: 因特定部署数据稀缺，训练电信AI模型有挑战，数字孪生是潜在解决方案，但需解决仿真与现实差距，本文回顾两种互补策略。


<details>
  <summary>Details</summary>
Motivation: 电信领域因数据稀缺难以训练有效AI模型，数字孪生虽可生成数据但存在仿真与现实差距，需开发解决方案。

Method: 回顾两种互补策略，一是通过现实测量校准数字孪生，二是采用感知仿真与现实差距的训练策略，评估两种不同概念方法。

Result: 文中未明确提及具体结果。

Conclusion: 文中未明确提及具体结论。

Abstract: Training effective artificial intelligence models for telecommunications is
challenging due to the scarcity of deployment-specific data. Real data
collection is expensive, and available datasets often fail to capture the
unique operational conditions and contextual variability of the network
environment. Digital twinning provides a potential solution to this problem, as
simulators tailored to the current network deployment can generate
site-specific data to augment the available training datasets. However, there
is a need to develop solutions to bridge the inherent simulation-to-reality
(sim-to-real) gap between synthetic and real-world data. This paper reviews
recent advances on two complementary strategies: 1) the calibration of digital
twins (DTs) through real-world measurements, and 2) the use of sim-to-real
gap-aware training strategies to robustly handle residual discrepancies between
digital twin-generated and real data. For the latter, we evaluate two
conceptually distinct methods that model the sim-to-real gap either at the
level of the environment via Bayesian learning or at the level of the training
loss via prediction-powered inference.

</details>


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [130] [Deep learning-based species-area models reveal multi-scale patterns of species richness and turnover](https://arxiv.org/abs/2507.06358)
*Victor Boussange,Philipp Brun,Johanna T. Malle,Gabriele Midolo,Jeanne Portier,Théophile Sanchez,Niklaus E. Zimmermann,Irena Axmanová,Helge Bruelheide,Milan Chytrý,Stephan Kambach,Zdeňka Lososová,Martin Večeřa,Idoia Biurrun,Klaus T. Ecker,Jonathan Lenoir,Jens-Christian Svenning,Dirk Nikolaus Karger*

Main category: q-bio.PE

TL;DR: 开发深度学习方法解决物种丰富度尺度依赖问题，模型提升估计效果并助力生物多样性评估。


<details>
  <summary>Details</summary>
Motivation: 收集跨空间尺度的详尽生物多样性记录困难，阻碍对物种 - 面积关系动态的全面理解。

Method: 开发结合抽样理论和小规模生态调查的深度学习方法，预测欧洲维管植物群落物种丰富度并与独立数据集对比。

Result: 模型使物种丰富度估计提高32%，给出不同尺度下物种丰富度和周转率的空间模式，可解释AI技术理清物种丰富度驱动因素。

Conclusion: 模型体现生物多样性多尺度特性，对全球变化下的生物多样性评估和预测至关重要。

Abstract: The number of species within ecosystems is influenced not only by their
intrinsic characteristics but also by the spatial scale considered. As the
sampled area expands, species richness increases, a phenomenon described by the
species-area relationship (SAR). The accumulation dynamics of the SAR results
from a complex interplay of biotic and abiotic processes operating at various
spatial scales. However, the challenge of collecting exhaustive biodiversity
records across spatial scales has hindered a comprehensive understanding of
these dynamics. Here, we develop a deep learning approach that leverages
sampling theory and small-scale ecological surveys to spatially resolve the
scale-dependency of species richness. We demonstrate its performance by
predicting the species richness of vascular plant communities across Europe,
and evaluate the predictions against an independent dataset of plant community
inventories. Our model improves species richness estimates by 32\% and delivers
spatially explicit patterns of species richness and turnover for sampling areas
ranging from square meters to hundreds of square kilometers. Explainable AI
techniques further disentangle how drivers of species richness operate across
spatial scales. The ability of our model to represent the multi-scale nature of
biodiversity is essential to deliver robust biodiversity assessments and
forecasts under global change.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [131] [Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving](https://arxiv.org/abs/2507.06804)
*Zhenwen Liang,Linfeng Song,Yang Li,Tao Yang,Feng Zhang,Haitao Mi,Dong Yu*

Main category: cs.LO

TL;DR: 当前大语言模型在自动定理证明中正式证明表现弱，本文提出解耦推理与证明的框架，在IMO问题上取得成果并发布数据集。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在自动定理证明中非正式推理能力强但正式证明性能弱的差距问题。

Method: 提出解耦框架，用通用推理器生成子目标引理，用证明器验证。

Result: 在2000年后IMO难题集上成功解决5个问题。

Conclusion: 该框架向解决极难数学挑战的自动推理迈出重要一步，发布数据集利于后续研究。

Abstract: Automated Theorem Proving (ATP) in formal languages is a foundational
challenge for AI. While Large Language Models (LLMs) have driven remarkable
progress, a significant gap remains between their powerful informal reasoning
capabilities and their weak formal proving performance. Recent studies show
that the informal accuracy exceeds 80% while formal success remains below 8% on
benchmarks like PutnamBench. We argue this gap persists because current
state-of-the-art provers, by tightly coupling reasoning and proving, are
trained with paradigms that inadvertently punish deep reasoning in favor of
shallow, tactic-based strategies. To bridge this fundamental gap, we propose a
novel framework that decouples high-level reasoning from low-level proof
generation. Our approach utilizes two distinct, specialized models: a powerful,
general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an
efficient Prover to rigorously verify them. This modular design liberates the
model's full reasoning potential and bypasses the pitfalls of end-to-end
training. We evaluate our method on a challenging set of post-2000 IMO
problems, a problem set on which no prior open-source prover has reported
success. Our decoupled framework successfully solves 5 of these problems,
demonstrating a significant step towards automated reasoning on exceptionally
difficult mathematical challenges. To foster future research, we release our
full dataset of generated and verified lemmas for a wide range of IMO problems,
available at https://tencent-imo.github.io/ .

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [132] [Graph-based Fake Account Detection: A Survey](https://arxiv.org/abs/2507.06541)
*Ali Safarpoor Dehkordi,Ahad N. Zehmakan*

Main category: cs.SI

TL;DR: 该综述全面回顾在线社交网络中假账号检测的现有方法，聚焦基于图的技术，对方法分类，探讨优缺点与联系，研究可用数据集，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 近年来在线社交网络需要有效且高效的假账号检测算法，因此开展对现有方法的全面综述。

Method: 对现有假账号检测方法进行全面回顾，按多种维度对基于图的技术等方法进行分类，研究可用数据集。

Result: 对假账号检测方法进行分类，讨论其优缺点和联系，研究了可用数据集。

Conclusion: 提出了几个未来研究的潜在方向。

Abstract: In recent years, there has been a growing effort to develop effective and
efficient algorithms for fake account detection in online social networks. This
survey comprehensively reviews existing methods, with a focus on graph-based
techniques that utilise topological features of social graphs (in addition to
account information, such as their shared contents and profile data) to
distinguish between fake and real accounts. We provide several categorisations
of these methods (for example, based on techniques used, input data, and
detection time), discuss their strengths and limitations, and explain how these
methods connect in the broader context. We also investigate the available
datasets, including both real-world data and synthesised models. We conclude
the paper by proposing several potential avenues for future research.

</details>


### [133] [Modeling Heterogeneity across Varying Spatial Extents: Discovering Linkages between Sea Ice Retreat and Ice Shelve Melt in the Antarctic](https://arxiv.org/abs/2507.07036)
*Maloy Kumar Devnath,Sudip Chakraborty,Vandana P. Janeja*

Main category: cs.SI

TL;DR: 研究提出Spatial - Link框架，量化空间异质性以捕捉海冰退缩与南极冰架融化的联系，揭示耦合模式，为海平面上升预测提供工具。


<details>
  <summary>Details</summary>
Motivation: 空间现象复杂难建模，传统模型难以捕捉海冰与南极冰架的局部联系和级联反馈，海冰退缩对南极冰架质量损失的直接影响研究不足。

Method: 提出Spatial - Link框架，用Delaunay三角剖分构建空间图，用广度优先搜索和蒙特卡罗模拟提取并验证链接路径。

Result: 揭示非局部、空间异质的耦合模式，表明海冰损失会引发或放大下游冰架融化，建立了海冰退缩与冰架融化的直接联系。

Conclusion: Spatial - Link是可扩展、数据驱动的工具，能改进海平面上升预测，为气候适应策略提供信息。

Abstract: Spatial phenomena often exhibit heterogeneity across spatial extents and in
proximity, making them complex to model-especially in dynamic regions like ice
shelves and sea ice. In this study, we address this challenge by exploring the
linkages between sea ice retreat and Antarctic ice shelf (AIS) melt. Although
atmospheric forcing and basal melting have been widely studied, the direct
impact of sea ice retreat on AIS mass loss remains underexplored. Traditional
models treat sea ice and AIS as separate systems. It limits their ability to
capture localized linkages and cascading feedback. To overcome this, we propose
Spatial-Link, a novel graph-based framework that quantifies spatial
heterogeneity to capture linkages between sea ice retreat and AIS melt. Our
method constructs a spatial graph using Delaunay triangulation of
satellite-derived ice change matrices, where nodes represent regions of
significant change and edges encode proximity and directional consistency. We
extract and statistically validate linkage paths using breadth-first search and
Monte Carlo simulations. Results reveal non-local, spatially heterogeneous
coupling patterns, suggesting sea ice loss can initiate or amplify downstream
AIS melt. Our analysis shows how sea ice retreat evolves over an oceanic grid
and progresses toward ice shelves-establishing a direct linkage. To our
knowledge, this is the first proposed methodology linking sea ice retreat to
AIS melt. Spatial-Link offers a scalable, data-driven tool to improve sea-level
rise projections and inform climate adaptation strategies.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [134] [Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G](https://arxiv.org/abs/2507.06911)
*Michele Polese,Niloofar Mohamadi,Salvatore D'Oro,Tommaso Melodia*

Main category: cs.NI

TL;DR: 本文提出融合O - RAN与AI - RAN架构以支持边缘分布式AI工作负载，介绍架构创新点与优势。


<details>
  <summary>Details</summary>
Motivation: 数据密集型AI应用在网络边缘的激增，促使RAN设计从利用AI优化网络向支持分布式AI工作负载转变，网络运营商可借此实现AI变现并利用现有基础设施投资。

Method: 提出一种新的融合O - RAN和AI - RAN架构，引入AI - RAN编排器和AI - RAN站点两项关键架构创新。

Result: 该架构支持灵活部署选项，可根据特定时序要求和地理目标编排AI工作负载。

Conclusion: 该架构能满足不同时间尺度管理异构工作负载的编排需求，同时保持开放、标准化接口和多供应商互操作性。

Abstract: The proliferation of data-intensive Artificial Intelligence (AI) applications
at the network edge demands a fundamental shift in RAN design, from merely
consuming AI for network optimization, to actively enabling distributed AI
workloads. This paradigm shift presents a significant opportunity for network
operators to monetize AI at the edge while leveraging existing infrastructure
investments. To realize this vision, this article presents a novel converged
O-RAN and AI-RAN architecture that unifies orchestration and management of both
telecommunications and AI workloads on shared infrastructure. The proposed
architecture extends the Open RAN principles of modularity, disaggregation, and
cloud-nativeness to support heterogeneous AI deployments. We introduce two key
architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN
Service Management and Orchestration (SMO) to enable integrated resource and
allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide
distributed edge AI platforms with real-time processing capabilities. The
proposed system supports flexible deployment options, allowing AI workloads to
be orchestrated with specific timing requirements (real-time or batch
processing) and geographic targeting. The proposed architecture addresses the
orchestration requirements for managing heterogeneous workloads at different
time scales while maintaining open, standardized interfaces and multi-vendor
interoperability.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [135] [Towards LLM-based Root Cause Analysis of Hardware Design Failures](https://arxiv.org/abs/2507.06512)
*Siyu Qiu,Muzhi Wang,Raheel Afsharmazayejani,Mohammad Moradi Shahmiri,Benjamin Tan,Hammond Pearce*

Main category: cs.AR

TL;DR: 本文探索大语言模型在数字硬件设计中解释设计问题和漏洞根源的应用，取得了有前景的结果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型发展，探索其在数字硬件设计过程中帮助解释综合和仿真时出现的设计问题及漏洞根源，推动其在硬件设计和安全分析中的广泛应用。

Method: 使用OpenAI的o3 - mini推理模型及其他先进模型和配置，部分使用检索增强生成辅助。

Result: 对于34种不同的漏洞场景语料库，OpenAI的o3 - mini推理模型在pass@5评分下正确率达100%，其他模型和配置通常性能超80%，使用检索增强生成辅助时超90%。

Conclusion: 大语言模型在解释硬件设计问题和漏洞根源方面有很大潜力。

Abstract: With advances in large language models (LLMs), new opportunities have emerged
to develop tools that support the digital hardware design process. In this
work, we explore how LLMs can assist with explaining the root cause of design
issues and bugs that are revealed during synthesis and simulation, a necessary
milestone on the pathway towards widespread use of LLMs in the hardware design
process and for hardware security analysis. We find promising results: for our
corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model
reached a correct determination 100% of the time under pass@5 scoring, with
other state of the art models and configurations usually achieving more than
80% performance and more than 90% when assisted with retrieval-augmented
generation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [136] [A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes](https://arxiv.org/abs/2507.06278)
*Kemboi Cheruiyot,Nickson Kiprotich,Vyacheslav Kungurtsev,Kennedy Mugo,Vivian Mwirigi,Marvin Ngesa*

Main category: cs.MA

TL;DR: 文章对多智能体交互的三种拓扑结构进行全面调查，涉及联邦、去中心化和非合作强化学习领域，回顾相关技术现状。


<details>
  <summary>Details</summary>
Motivation: 随着对自主智能体研究和创新兴趣增加，多智能体交互有多种复杂重要场景，需对不同交互拓扑结构研究。

Method: 采用全面调查方法，对三种交互拓扑结构下的联邦、去中心化和非合作强化学习领域进行研究，回顾技术现状。

Result: 指出三种领域的结构相似性和区别，涵盖相关公式、理论保证、数值性能亮点与局限。

Conclusion: 文章通过调查，系统梳理了多智能体交互不同拓扑结构领域的研究情况。

Abstract: The increasing interest in research and innovation towards the development of
autonomous agents presents a number of complex yet important scenarios of
multiple AI Agents interacting with each other in an environment. The
particular setting can be understood as exhibiting three possibly topologies of
interaction - centrally coordinated cooperation, ad-hoc interaction and
cooperation, and settings with noncooperative incentive structures. This
article presents a comprehensive survey of all three domains, defined under the
formalism of Federal Reinforcement Learning (RL), Decentralized RL, and
Noncooperative RL, respectively. Highlighting the structural similarities and
distinctions, we review the state of the art in these subjects, primarily
explored and developed only recently in the literature. We include the
formulations as well as known theoretical guarantees and highlights and
limitations of numerical performance.

</details>


### [137] [Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration](https://arxiv.org/abs/2507.06520)
*Xinyuan Song,Zeyu Wang,Siyi Wu,Tianyu Shi,Lynn Ai*

Main category: cs.MA

TL;DR: 提出Gradientsys多智能体调度框架，采用MCP协议和动态规划循环，LLM驱动调度，支持混合执行等，实验显示其优于基线。


<details>
  <summary>Details</summary>
Motivation: 构建下一代多智能体调度框架，解决多智能体协调调度问题。

Method: 使用Typed Model - Context Protocol (MCP)和基于ReAct的动态规划循环，LLM驱动调度器进行任务分发，支持混合同步/异步执行，有重试和重新规划机制，含可观测层。

Result: 在GAIA基准测试中，与MinionS风格基线相比，Gradientsys实现了更高的任务成功率，更低的延迟和API成本。

Conclusion: Gradientsys的LLM驱动多智能体编排能力很强。

Abstract: We present Gradientsys, a next-generation multi-agent scheduling framework
that coordinates diverse specialized AI agents using a typed Model-Context
Protocol (MCP) and a ReAct-based dynamic planning loop. At its core,
Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task
dispatch, enabling parallel execution of heterogeneous agents such as PDF
parsers, web search modules, GUI controllers, and web builders. The framework
supports hybrid synchronous/asynchronous execution, respects agent capacity
constraints, and incorporates a robust retry-and-replan mechanism to handle
failures gracefully. To promote transparency and trust, Gradientsys includes an
observability layer streaming real-time agent activity and intermediate
reasoning via Server-Sent Events (SSE). We offer an architectural overview and
evaluate Gradientsys against existing frameworks in terms of extensibility,
scheduling topology, tool reusability, parallelism, and observability.
Experiments on the GAIA general-assistant benchmark show that Gradientsys
achieves higher task success rates with reduced latency and lower API costs
compared to a MinionS-style baseline, demonstrating the strength of its
LLM-driven multi-agent orchestration.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [138] [Forex Trading Robot Using Fuzzy Logic](https://arxiv.org/abs/2507.06383)
*Mustafa Shabani,Alireza Nasiri,Hassan Nafardi*

Main category: eess.SY

TL;DR: 本文提出用模糊系统进行外汇短期交易，结合各指标的模糊Mamdani系统结果设计交易机器人，结果显示盈利能力显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于震荡指标的外汇交易技术策略因市场变化效果不佳，需改进交易策略以提高交易准确性。

Method: 为每个指标引入模糊Mamdani系统，将各系统结果通过投票结合来设计交易机器人。

Result: 与其他三种方法相比，盈利能力因子显著增加，还计算并比较了净收益、总收益和最大资本减少等指标。

Conclusion: 所提出的模糊系统用于外汇短期交易是有效的，能提高交易盈利能力。

Abstract: In this study, we propose a fuzzy system for conducting short-term
transactions in the forex market. The system is designed to enhance common
strategies in the forex market using fuzzy logic, thereby improving the
accuracy of transactions. Traditionally, technical strategies based on
oscillator indicators have relied on predefined ranges for indicators such as
Relative Strength Index (RSI), Commodity Channel Indicator (CCI), and
Stochastic to determine entry points for trades. However, the use of these
classic indicators has yielded suboptimal results due to the changing nature of
the market over time. In our proposed approach, instead of employing classical
indicators, we introduce a fuzzy Mamdani system for each indicator. The results
obtained from these systems are then combined through voting to design a
trading robot. Our findings demonstrate a considerable increase in the
profitability factor compared to three other methods. Additionally, net profit,
gross profit, and maximum capital reduction are calculated and compared across
all approaches.

</details>


### [139] [Optimisation of Electrolyser Operation: Integrating External Heat](https://arxiv.org/abs/2507.06796)
*Matthias Derez,Alexander Hoogsteyn,Erik Delarue*

Main category: eess.SY

TL;DR: 论文通过内生建模启动成本和直接热集成改进现有模型，分析不同温度热集成对制氢效率和盈利能力的影响。


<details>
  <summary>Details</summary>
Motivation: 将外部热量集成到电解槽可减少碳中和制氢的电力需求，高效运行需要包含热可用性及其对启动成本影响的详细模型。

Method: 基于电化学方程的分段线性近似，内生建模启动成本和直接热集成。

Result: 文中未明确提及具体结果。

Conclusion: 文中未明确提及具体结论。

Abstract: Integrating external heat into electrolysers can reduce the electrical power
demand for carbon-neutral hydrogen production. Efficient operation requires
detailed models that incorporate heat availability and its effect on startup
costs. This paper advances existing operational models by endogenously
modelling startup costs and direct heat integration, based on a piecewise
linear approximation of the electrochemical equations. We analyse the impact of
low- and high-temperature heat integration on the efficiency and profitability
of hydrogen production for solid oxide and proton exchange membrane
electrolysis technologies.

</details>


### [140] [An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models](https://arxiv.org/abs/2507.06399)
*Doyeong Lim,Yang Liu,Zavier Ndum Ndum,Christian Young,Yassin Hassan*

Main category: eess.SY

TL;DR: 本文介绍多用途AI驱动热流体试验台，结合物理实验与计算智能，验证其高保真度，推动下一代核系统创新部署。


<details>
  <summary>Details</summary>
Motivation: 推进小型模块化反应堆技术，建立AI与热流体科学交叉研究环境，加速下一代核系统创新和部署。

Method: 试验台数字孪生结合GRU神经网络，训练机器学习模型；开展案例研究；用大语言模型开发智能助手。

Result: GRU模型实现超实时仿真，温度预测均方根误差1.42K，验证平台高保真度。

Conclusion: AI驱动的建模、控制和操作员支持方法可加速下一代核系统的创新和部署。

Abstract: This paper presents a multipurpose artificial intelligence (AI)-driven
thermal-fluid testbed designed to advance Small Modular Reactor technologies by
seamlessly integrating physical experimentation with advanced computational
intelligence. The platform uniquely combines a versatile three-loop
thermal-fluid facility with a high-fidelity digital twin and sophisticated AI
frameworks for real-time prediction, control, and operational assistance.
Methodologically, the testbed's digital twin, built upon the System Analysis
Module code, is coupled with a Gated Recurrent Unit (GRU) neural network. This
machine learning model, trained on experimental data, enables
faster-than-real-time simulation, providing predictive insights into the
system's dynamic behavior. The practical application of this AI integration is
showcased through case studies. An AI-driven control framework where the GRU
model accurately forecasts future system states and the corresponding control
actions required to meet operational demands. Furthermore, an intelligent
assistant, powered by a large language model, translates complex sensor data
and simulation outputs into natural language, offering operators actionable
analysis and safety recommendations. Comprehensive validation against
experimental transients confirms the platform's high fidelity, with the GRU
model achieving a temperature prediction root mean square error of 1.42 K. This
work establishes an integrated research environment at the intersection of AI
and thermal-fluid science, showcasing how AI-driven methodologies in modeling,
control, and operator support can accelerate the innovation and deployment of
next-generation nuclear systems.

</details>


### [141] [A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis](https://arxiv.org/abs/2507.06890)
*Yifan Wang*

Main category: eess.SY

TL;DR: 本文提出仅用一个VPQ传感器的FO - MADS方案用于智能微电网网络攻击诊断，实验表明该方案有效且具成本效益。


<details>
  <summary>Details</summary>
Motivation: 网络攻击威胁智能微电网安全，现有诊断方法依赖昂贵多点仪器或严格建模假设，在单传感器约束下不可行。

Method: 构建双分数阶特征库放大VPQ信号微扰和慢漂移；用两级分层分类器定位故障；通过PMR - AT增强鲁棒性，用OHEM动态重新加权攻击感知损失。

Result: 在四种攻击场景和无攻击条件下实验，诊断准确率分别达到96.6%（偏差）、94.0%（噪声）、92.8%（数据替换）、95.7%（重放）和96.7%。

Conclusion: FO - MADS是一种经济有效、易于部署的解决方案，显著增强智能微电网的网络物理弹性。

Abstract: Cyber-attacks jeopardize the safe operation of smart microgrids. At the same
time, existing diagnostic methods either depend on expensive multi-point
instrumentation or stringent modelling assumptions that are untenable under
single-sensor constraints. This paper proposes a Fractional-Order
Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves low-latency
fault localisation and cyber-attack detection using only one VPQ
(Voltage-Power-Reactive-power) sensor. FO-MADS first constructs a dual
fractional-order feature library by jointly applying Caputo and
Gr\"unwald-Letnikov derivatives, thereby amplifying micro-perturbations and
slow drifts in the VPQ signal. A two-stage hierarchical classifier then
pinpoints the affected inverter and isolates the faulty IGBT switch,
effectively alleviating class imbalance. Robustness is further strengthened
through Progressive Memory-Replay Adversarial Training (PMR-AT), whose
attack-aware loss is dynamically re-weighted via Online Hard Example Mining
(OHEM) to prioritise the most challenging samples. Experiments on a
four-inverter microgrid testbed comprising 1 normal and 24 fault classes under
four attack scenarios demonstrate diagnostic accuracies of 96.6 % (bias), 94.0
% (noise), 92.8 % (data replacement), and 95.7 % (replay), while sustaining
96.7 % under attack-free conditions. These results establish FO-MADS as a
cost-effective and readily deployable solution that markedly enhances the
cyber-physical resilience of smart microgrids.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [142] [Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice](https://arxiv.org/abs/2507.06235)
*Yuto Mandai,Katie Seaborn,Tomoyasu Nakano,Xin Sun,Yijia Wang,Jun Kato*

Main category: cs.HC

TL;DR: 研究探索计算机语音可爱元素及操控方法，发现特定语音有可爱“最佳点”和上限效应，验证了初步模型并提供操控方法。


<details>
  <summary>Details</summary>
Motivation: 以往研究多关注可爱概念的视觉方面，本文旨在开创可爱语音学新科学，探索语音中与可爱相关的元素及操控方式。

Method: 对文本转语音和游戏角色语音两种计算机语音进行四阶段研究，样本总数512。

Result: 通过操控基频和共振峰频率，发现特定语音存在可爱“最佳点”，某些语音的可爱语音学存在上限效应。

Conclusion: 对初步的可爱语音学模型进行了实证验证，并提供了操控计算机语音可爱感知的基本方法。

Abstract: "Kawaii" is the Japanese concept of cute, which carries sociocultural
connotations related to social identities and emotional responses. Yet,
virtually all work to date has focused on the visual side of kawaii, including
in studies of computer agents and social robots. In pursuit of formalizing the
new science of kawaii vocalics, we explored what elements of voice relate to
kawaii and how they might be manipulated, manually and automatically. We
conducted a four-phase study (grand N = 512) with two varieties of computer
voices: text-to-speech (TTS) and game character voices. We found kawaii "sweet
spots" through manipulation of fundamental and formant frequencies, but only
for certain voices and to a certain extent. Findings also suggest a ceiling
effect for the kawaii vocalics of certain voices. We offer empirical validation
of the preliminary kawaii vocalics model and an elementary method for
manipulating kawaii perceptions of computer voice.

</details>


### [143] [Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool](https://arxiv.org/abs/2507.06734)
*Milena Pustet,Elisabeth Steffen,Helena Mihaljević,Grischa Stanjek,Yannis Illies*

Main category: cs.HC

TL;DR: 探讨公民社会组织（CSOs）如何参与开发用于监测Telegram上反民主运动的AI辅助开源工具。


<details>
  <summary>Details</summary>
Motivation: 平台减少内容审核投入，CSOs在监测有害内容方面作用关键，但缺少集成AI模型与社交媒体监测基础设施的开源工具，且跨领域合作少，研究难转化为实用工具。

Method: 与CSO利益相关者合作开发AI辅助的开源监测工具。

Result: 未提及具体结果。

Conclusion: 未提及明确结论，处于进行中工作，探索CSOs有意义参与工具开发的方式。

Abstract: The role of civil society organizations (CSOs) in monitoring harmful online
content is increasingly crucial, especially as platform providers reduce their
investment in content moderation. AI tools can assist in detecting and
monitoring harmful content at scale. However, few open-source tools offer
seamless integration of AI models and social media monitoring infrastructures.
Given their thematic expertise and contextual understanding of harmful content,
CSOs should be active partners in co-developing technological tools, providing
feedback, helping to improve models, and ensuring alignment with stakeholder
needs and values, rather than as passive 'consumers'. However, collaborations
between the open source community, academia, and civil society remain rare, and
research on harmful content seldom translates into practical tools usable by
civil society actors. This work in progress explores how CSOs can be
meaningfully involved in an AI-assisted open-source monitoring tool of
anti-democratic movements on Telegram, which we are currently developing in
collaboration with CSO stakeholders.

</details>


### [144] [Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding](https://arxiv.org/abs/2507.06779)
*Martin Wimpff,Jan Zerfowski,Bin Yang*

Main category: cs.HC

TL;DR: 本文介绍实时自适应池化（RAP）方法，解决深度学习在实时脑机接口应用的挑战，为在线脑机接口广泛应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在实时脑机接口应用面临的离线到在线解码过渡不清晰、计算复杂度高和训练数据稀缺的问题，实现无特定主体校准的实时跨主体解码。

Method: 引入无参数的实时自适应池化（RAP）方法，修改现有离线深度学习模型的池化层以满足在线解码需求，联合解码连续滑动窗口降低训练计算复杂度，利用无源域自适应缓解数据需求。

Result: RAP为实时脑机接口应用提供了强大高效的框架，能保护隐私、减少校准需求、支持自适应脑机系统。

Conclusion: 研究结果为开发以用户为中心、高性能的脑机接口奠定基础，利于即时反馈和用户学习。

Abstract: Despite the growing success of deep learning (DL) in offline brain-computer
interfaces (BCIs), its adoption in real-time applications remains limited due
to three primary challenges. First, most DL solutions are designed for offline
decoding, making the transition to online decoding unclear. Second, the use of
sliding windows in online decoding substantially increases computational
complexity. Third, DL models typically require large amounts of training data,
which are often scarce in BCI applications. To address these challenges and
enable real-time, cross-subject decoding without subject-specific calibration,
we introduce realtime adaptive pooling (RAP), a novel parameter-free method.
RAP seamlessly modifies the pooling layers of existing offline DL models to
meet online decoding requirements. It also reduces computational complexity
during training by jointly decoding consecutive sliding windows. To further
alleviate data requirements, our method leverages source-free domain
adaptation, enabling privacy-preserving adaptation across varying amounts of
target data. Our results demonstrate that RAP provides a robust and efficient
framework for real-time BCI applications. It preserves privacy, reduces
calibration demands, and supports co-adaptive BCI systems, paving the way for
broader adoption of DL in online BCIs. These findings lay a strong foundation
for developing user-centered, high-performance BCIs that facilitate immediate
feedback and user learning.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [145] [Portfolio optimization in incomplete markets and price constraints determined by maximum entropy in the mean](https://arxiv.org/abs/2507.07053)
*Argimiro Arratia,Henryk Gzyl*

Main category: math.OC

TL;DR: 本文提出在不完全市场中确定资产当前价格的有效方法，使其符合投资组合优化问题的成本约束，并通过数值例子研究该方法对投资组合回报的影响。


<details>
  <summary>Details</summary>
Motivation: 在不完全市场中，风险中性测度不唯一，资产有一系列可能价格，需确定符合投资组合优化成本约束的资产价格。

Method: 使用均值最大熵方法从买卖价差市场数据调整失真函数，该失真函数作为风险中性测度对资产定价。

Result: 未明确提及具体结果，但通过数值例子研究了该方法对投资组合回报的影响。

Conclusion: 未明确提及结论。

Abstract: A solution to a portfolio optimization problem is always conditioned by
constraints on the initial capital and the price of the available market
assets. If a risk neutral measure is known, then the price of each asset is the
discounted expected value of the asset's price under this measure. But if the
market is incomplete, the risk neutral measure is not unique, and there is a
range of possible prices for each asset, which can be identified with bid-ask
ranges. We present in this paper an effective method to determine the current
prices of a collection of assets in incomplete markets, and such that these
prices comply with the cost constraints for a portfolio optimization problem.
Our workhorse is the method of maximum entropy in the mean to adjust a
distortion function from bid-ask market data. This distortion function plays
the role of a risk neutral measure, which is used to price the assets, and the
distorted probability that it determines reproduces bid-ask market values. We
carry out numerical examples to study the effect on portfolio returns of the
computation of prices of the assets conforming the portfolio with the proposed
methodology.

</details>


### [146] [Neural Actor-Critic Methods for Hamilton-Jacobi-Bellman PDEs: Asymptotic Analysis and Numerical Studies](https://arxiv.org/abs/2507.06428)
*Samuel N. Cohen,Jackson Hebner,Deqing Jiang,Justin Sirignano*

Main category: math.OC

TL;DR: 本文对用于求解高维HJB偏微分方程的演员-评论家机器学习算法进行数学分析和数值研究，证明算法收敛性，数值实验表明能精确求解200维随机控制问题。


<details>
  <summary>Details</summary>
Motivation: 解决高维随机控制理论中的HJB偏微分方程求解问题，克服有限宽度神经网络因损失函数非凸只能收敛到局部极小值的问题。

Method: 设计评论家架构使其完美满足边界条件并使用有偏梯度降低计算成本；演员通过最小化哈密顿量积分训练；证明演员和评论家神经网络训练动态在Sobolev型空间收敛到无限维常微分方程。

Result: 算法能准确求解高达200维的随机控制问题，通过构造不同复杂度的问题研究算法性能。

Conclusion: 该算法在求解HJB方程有一定优势，同时分析出其优势和局限性。

Abstract: We mathematically analyze and numerically study an actor-critic machine
learning algorithm for solving high-dimensional Hamilton-Jacobi-Bellman (HJB)
partial differential equations from stochastic control theory. The architecture
of the critic (the estimator for the value function) is structured so that the
boundary condition is always perfectly satisfied (rather than being included in
the training loss) and utilizes a biased gradient which reduces computational
cost. The actor (the estimator for the optimal control) is trained by
minimizing the integral of the Hamiltonian over the domain, where the
Hamiltonian is estimated using the critic. We show that the training dynamics
of the actor and critic neural networks converge in a Sobolev-type space to a
certain infinite-dimensional ordinary differential equation (ODE) as the number
of hidden units in the actor and critic $\rightarrow \infty$. Further, under a
convexity-like assumption on the Hamiltonian, we prove that any fixed point of
this limit ODE is a solution of the original stochastic control problem. This
provides an important guarantee for the algorithm's performance in light of the
fact that finite-width neural networks may only converge to a local minimizers
(and not optimal solutions) due to the non-convexity of their loss functions.
In our numerical studies, we demonstrate that the algorithm can solve
stochastic control problems accurately in up to 200 dimensions. In particular,
we construct a series of increasingly complex stochastic control problems with
known analytic solutions and study the algorithm's numerical performance on
them. These problems range from a linear-quadratic regulator equation to highly
challenging equations with non-convex Hamiltonians, allowing us to identify and
analyze the strengths and limitations of this neural actor-critic method for
solving HJB equations.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [147] [Differential Equation-Constrained Local Regression for Data with Sparse Design](https://arxiv.org/abs/2507.06409)
*Chunlei Ge,W. John Braun*

Main category: stat.ME

TL;DR: 研究利用一阶微分方程的非参数回归方法，应用于小鼠肿瘤生长数据，讨论不同阶泰勒多项式核估计的渐近偏差和方差，并通过模拟研究进行模型比较。


<details>
  <summary>Details</summary>
Motivation: 局部多项式回归在数据稀疏区域表现差，局部常数回归虽更稳健但精度低，希望结合微分方程信息扩展局部常数回归的稀疏设计能力并减少偏差和方差。

Method: 研究利用一阶微分方程的非参数回归方法，讨论不同阶泰勒多项式核估计的渐近偏差和方差，通过模拟研究进行模型比较。

Result: 文中未明确提及具体结果。

Conclusion: 文中未明确提及具体结论。

Abstract: Local polynomial regression of order one or higher often performs poorly in
areas with sparse data. In contrast, local constant regression tends to be more
robust in these regions, although it is generally the least accurate approach,
especially near the boundaries of the data. Incorporating information from
differential equations, which may approximately or exactly hold, is one way of
extending the sparse design capacity of local constant regression while
reducing bias and variance. A nonparametric regression method that exploits
first-order differential equations is studied in this paper and applied to
noisy mouse tumour growth data. Asymptotic biases and variances of kernel
estimators using Taylor polynomials with different degrees are discussed. Model
comparison is performed for different estimators through simulation studies
under various scenarios that simulate exponential-type growth.

</details>


### [148] [Bayesian Generalized Nonlinear Models Offer Basis Free SINDy With Model Uncertainty](https://arxiv.org/abs/2507.06776)
*Aliaksandr Hubin*

Main category: stat.ME

TL;DR: 本文提出贝叶斯广义非线性模型（BGNLMs）替代经典稀疏识别非线性动力学（SINDy）方法，应用于3D SINDy问题。


<details>
  <summary>Details</summary>
Motivation: 经典SINDy方法依赖预定义候选函数库，限制灵活性且无法进行稳健的不确定性量化。

Method: 提出BGNLMs，采用尖峰 - 平板先验和二元包含指标自动发现相关非线性，无需预定义基函数，并量化不确定性。

Result: 未提及具体结果。

Conclusion: 未提及明确结论，但BGNLMs有望提供更灵活的统计建模方法。

Abstract: Sparse Identification of Nonlinear Dynamics (SINDy) has become a standard
methodology for inferring governing equations of dynamical systems from
observed data using statistical modeling. However, classical SINDy approaches
rely on predefined libraries of candidate functions to model nonlinearities,
which limits flexibility and excludes robust uncertainty quantification. This
paper proposes Bayesian Generalized Nonlinear Models (BGNLMs) as a principled
alternative for more flexible statistical modeling. BGNLMs employ
spike-and-slab priors combined with binary inclusion indicators to
automatically discover relevant nonlinearities without predefined basis
functions. Moreover, BGNLMs quantify uncertainty in selected bases and final
model predictions, enabling robust exploration of the model space. In this
paper, the BGNLM framework is applied to several three-dimensional (3D) SINDy
problems.

</details>


### [149] [Non-Asymptotic Analysis of Online Local Private Learning with SGD](https://arxiv.org/abs/2507.07041)
*Enze Shi,Jinhan Xie,Bei Jiang,Linglong Kong,Xuming He*

Main category: stat.ME

TL;DR: 本文针对在线局部差分隐私模型下的随机优化问题开展非渐近收敛分析，提出通用框架和估计器并验证。


<details>
  <summary>Details</summary>
Motivation: 现有非渐近分析聚焦非隐私优化方法，不适用于隐私保护优化问题，需对DP - SGD进行系统非渐近收敛分析。

Method: 为在线LDP模型构建通用框架，对提出的估计器进行有限样本情况下的非渐近收敛分析。

Result: 通过严格数学推导和数值实验验证了估计器在理论和实践中的有效性。

Conclusion: 本文分析填补了DP - SGD非渐近收敛分析的空白，为私有优化问题的非渐近收敛分析提供基础，也为用户提供了超参数对收敛率影响的实用指南。

Abstract: Differentially Private Stochastic Gradient Descent (DP-SGD) has been widely
used for solving optimization problems with privacy guarantees in machine
learning and statistics. Despite this, a systematic non-asymptotic convergence
analysis for DP-SGD, particularly in the context of online problems and local
differential privacy (LDP) models, remains largely elusive. Existing
non-asymptotic analyses have focused on non-private optimization methods, and
hence are not applicable to privacy-preserving optimization problems. This work
initiates the analysis to bridge this gap and opens the door to non-asymptotic
convergence analysis of private optimization problems. A general framework is
investigated for the online LDP model in stochastic optimization problems. We
assume that sensitive information from individuals is collected sequentially
and aim to estimate, in real-time, a static parameter that pertains to the
population of interest. Most importantly, we conduct a comprehensive
non-asymptotic convergence analysis of the proposed estimators in finite-sample
situations, which gives their users practical guidelines regarding the effect
of various hyperparameters, such as step size, parameter dimensions, and
privacy budgets, on convergence rates. Our proposed estimators are validated in
the theoretical and practical realms by rigorous mathematical derivations and
carefully constructed numerical experiments.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [150] [Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control](https://arxiv.org/abs/2507.07034)
*Mikael Vaillant,Victor Oliveira Ferreira,Wiebke Mainville,Jean-Michel Lamarre,Vincent Raymond,Moncef Chioua,Bruno Blais*

Main category: physics.flu-dyn

TL;DR: 研究提出基于CNN的代理模型实时预测封闭冲击射流阵列中努塞尔数分布，训练不同射流阵列模型，用相关缩放法外推高雷诺数预测，模型精度高并实验验证，为热管理应用控制策略奠基。


<details>
  <summary>Details</summary>
Motivation: 计算流体动力学（CFD）模拟虽能高精度建模传热，但成本高无法用于实时应用，如基于模型的温度控制，因此需要一种能实时预测努塞尔数分布的方法。

Method: 生成基于CNN的代理模型，用隐式大涡计算流体动力学模拟（Re < 2,000）数据训练，针对不同射流阵列训练不同模型，用相关缩放法外推高雷诺数（Re < 10,000）预测。

Result: 代理模型精度高，五乘一代理模型验证数据归一化平均绝对误差低于2%，三乘三模型为0.6%，实验验证了模型预测能力。

Conclusion: 该工作为先进热管理应用中基于模型的控制策略提供了基础。

Abstract: This study presents a surrogate model designed to predict the Nusselt number
distribution in an enclosed impinging jet arrays, where each jet function
independently and where jets can be transformed from inlets to outlets, leading
to a vast number of possible flow arrangements. While computational fluid
dynamics (CFD) simulations can model heat transfer with high fidelity, their
cost prohibits real-time application such as model-based temperature control.
To address this, we generate a CNN-based surrogate model that can predict the
Nusselt distribution in real time. We train it with data from implicit large
eddy computational fluid dynamics simulations (Re < 2,000). We train two
distinct models, one for a five by one array of jets (83 simulations) and one
for a three by three array of jets (100 simulations). We introduce a method to
extrapolate predictions to higher Reynolds numbers (Re < 10,000) using a
correlation-based scaling. The surrogate models achieve high accuracy, with a
normalized mean average error below 2% on validation data for the five by one
surrogate model and 0.6% for the three by three surrogate model. Experimental
validation confirms the model's predictive capabilities. This work provides a
foundation for model-based control strategies in advanced thermal management
applications.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [151] [Self-supervised learning predicts plant growth trajectories from multi-modal industrial greenhouse data](https://arxiv.org/abs/2507.06336)
*Adam J Riesselman,Evan M Cofer,Therese LaRue,Wim Meeussen*

Main category: q-bio.QM

TL;DR: 利用移动机器人平台获取水培生菜生长数据，采用自监督建模方法预测作物生长，结合机器人自动化和机器学习推动农业研究和生产。


<details>
  <summary>Details</summary>
Motivation: 量化生物体表型对理解农艺性状和优化作物生产至关重要，但大规模获取高质量植物生长数据困难。

Method: 使用移动机器人平台进行环境传感和表型测量，采用自监督建模方法构建从观测数据到整个植物生长轨迹的映射。

Result: 能够预测系统中作物未来的株高和收获质量。

Conclusion: 该方法在结合机器人自动化和机器学习方面取得重大进展，为农业研究和运营效率提供了可行见解。

Abstract: Quantifying organism-level phenotypes, such as growth dynamics and biomass
accumulation, is fundamental to understanding agronomic traits and optimizing
crop production. However, quality growing data of plants at scale is difficult
to generate. Here we use a mobile robotic platform to capture high-resolution
environmental sensing and phenotyping measurements of a large-scale hydroponic
leafy greens system. We describe a self-supervised modeling approach to build a
map from observed growing data to the entire plant growth trajectory. We
demonstrate our approach by forecasting future plant height and harvest mass of
crops in this system. This approach represents a significant advance in
combining robotic automation and machine learning, as well as providing
actionable insights for agronomic research and operational efficiency.

</details>


### [152] [DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning](https://arxiv.org/abs/2507.07060)
*Shreyas Vinaya Sathyanarayana,Rahil Shah,Sharanabasava D. Hiremath,Rishikesh Panda,Rahul Jana,Riya Singh,Rida Irfan,Ashwin Murali,Bharath Ramsundar*

Main category: q-bio.QM

TL;DR: 提出开源的基于大语言模型的逆向合成框架DeepRetro，结合传统方法与大语言模型优势，经迭代优化和人工反馈，能识别可行且新颖的逆向合成路线。


<details>
  <summary>Details</summary>
Motivation: 逆向合成在发现超越预定义模板的新路径上有挑战，现有大语言模型方法在多步规划上待完善。

Method: 将传统基于模板/蒙特卡罗树搜索工具与大语言模型生成能力结合，在逐步、反馈驱动循环中使用。先尝试基于模板引擎规划，失败则由大语言模型提出单步逆向切断建议，经严格检查后将前体反馈到流程中。还开发交互界面让化学家提供反馈。

Result: 通过基准评估和案例研究，证明能识别可行且可能新颖的逆向合成路线，成功为复杂天然产物生成新路径。

Conclusion: 迭代的大语言模型推理有潜力推动复杂化学合成技术发展。

Abstract: Retrosynthesis, the identification of precursor molecules for a target
compound, is pivotal for synthesizing complex molecules, but faces challenges
in discovering novel pathways beyond predefined templates. Recent large
language model (LLM) approaches to retrosynthesis have shown promise but
effectively harnessing LLM reasoning capabilities for effective multi-step
planning remains an open question. To address this challenge, we introduce
DeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic
framework. Our approach integrates the strengths of conventional
template-based/Monte Carlo tree search tools with the generative power of LLMs
in a step-wise, feedback-driven loop. Initially, synthesis planning is
attempted with a template-based engine. If this fails, the LLM subsequently
proposes single-step retrosynthetic disconnections. Crucially, these
suggestions undergo rigorous validity, stability, and hallucination checks
before the resulting precursors are recursively fed back into the pipeline for
further evaluation. This iterative refinement allows for dynamic pathway
exploration and correction. We demonstrate the potential of this pipeline
through benchmark evaluations and case studies, showcasing its ability to
identify viable and potentially novel retrosynthetic routes. In particular, we
develop an interactive graphical user interface that allows expert human
chemists to provide human-in-the-loop feedback to the reasoning algorithm. This
approach successfully generates novel pathways for complex natural product
compounds, demonstrating the potential for iterative LLM reasoning to advance
state-of-art in complex chemical syntheses.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [153] [A Collectivist, Economic Perspective on AI](https://arxiv.org/abs/2507.06268)
*Michael I. Jordan*

Main category: cs.CY

TL;DR: 信息技术革命中当前技术发展以人类认知为基线有缺陷，应融合经济社会与计算推理概念，发展以人类为中心的工程领域。


<details>
  <summary>Details</summary>
Motivation: 指出当前信息技术发展以人类认知为基线，忽略人类社会性及技术社会后果的问题。

Method: 提出应将经济和社会概念与计算和推理概念彻底融合。

Result: 未提及具体结果。

Conclusion: 未来应进行概念融合，以社会福利为首要考虑，有望诞生新的以人类为中心的工程领域。

Abstract: Information technology is in the midst of a revolution in which omnipresent
data collection and machine learning are impacting the human world as never
before. The word "intelligence" is being used as a North Star for the
development of this technology, with human cognition viewed as a baseline. This
view neglects the fact that humans are social animals, and that much of our
intelligence is social and cultural in origin. A related issue is that the
current view treats the social consequences of technology as an afterthought.
The path forward is not merely more data and compute, and not merely more
attention paid to cognitive or symbolic representations, but a thorough
blending of economic and social concepts with computational and inferential
concepts, in the service of system-level designs in which social welfare is a
first-class citizen, and with the aspiration that a new human-centric
engineering field will emerge.

</details>


### [154] [The Emotional Alignment Design Policy](https://arxiv.org/abs/2507.06263)
*Eric Schwitzgebel,Jeff Sebo*

Main category: cs.CY

TL;DR: 提出情感对齐设计政策，指出可能的违反情况及实际实施面临的挑战


<details>
  <summary>Details</summary>
Motivation: 探讨人工实体设计如何引发用户合适情感反应，确保与实体能力和道德地位相符

Method: 无明确提及

Result: 指出该政策实施面临尊重用户自主性、应对专家和公众分歧等挑战

Conclusion: 无明确结论，只是提出实施政策面临的系列问题

Abstract: According to what we call the Emotional Alignment Design Policy, artificial
entities should be designed to elicit emotional reactions from users that
appropriately reflect the entities' capacities and moral status, or lack
thereof. This principle can be violated in two ways: by designing an artificial
system that elicits stronger or weaker emotional reactions than its capacities
and moral status warrant (overshooting or undershooting), or by designing a
system that elicits the wrong type of emotional reaction (hitting the wrong
target). Although presumably attractive, practical implementation faces several
challenges including: How can we respect user autonomy while promoting
appropriate responses? How should we navigate expert and public disagreement
and uncertainty about facts and values? What if emotional alignment seems to
require creating or destroying entities with moral status? To what extent
should designs conform to versus attempt to alter user assumptions and
attitudes?

</details>


### [155] [The Prompt War: How AI Decides on a Military Intervention](https://arxiv.org/abs/2507.06277)
*Maxim Chupilkin*

Main category: cs.CY

TL;DR: 本文通过简单联合实验提出模型，研究AI军事干预倾向的决定因素，发现国内高支持率和高成功率是主要预测因素，成本因素影响约为前两者一半，机会窗口需与其他因素相互作用才显著，结果在不同场景和模型中一致。


<details>
  <summary>Details</summary>
Motivation: 随着AI在战争游戏和军事规划中的应用快速增长，但尚未对模型中的关键驱动因素进行简单分析，因此研究AI军事干预倾向的决定因素。

Method: 进行简单联合实验，提出模型，对640个场景各运行100次，系统探索AI的军事干预决策。

Result: AI决定干预的最大预测因素是国内高支持率和高成功率；国际谴责、军事和民用死亡、负面经济影响等成本因素有统计显著性，但影响约为前两者一半；机会窗口仅在与其他因素相互作用时才有统计显著性；结果在不同场景和模型中显著一致。

Conclusion: AI的决策模式存在一定规律。

Abstract: Which factors determine AI propensity for military intervention? While the
use of AI in war games and military planning is growing exponentially, the
simple analysis of key drivers embedded in the models has not yet been done.
This paper does a simple conjoint experiment proposing a model to decide on
military intervention in 640 vignettes where each was run for 100 times
allowing to explore AI decision on military intervention systematically. The
analysis finds that largest predictors of AI decision to intervene are high
domestic support and high probability of success. Costs such as international
condemnation, military deaths, civilian deaths, and negative economic effect
are statistically significant, but their effect is around half of domestic
support and probability of victory. Closing window of opportunity only reaches
statistical significance in interaction with other factors. The results are
remarkably consistent across scenarios and across different models (OpenAI GPT,
Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.

</details>


### [156] [Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles](https://arxiv.org/abs/2507.06310)
*Yongchao Zeng,Calum Brown,Mark Rounsevell*

Main category: cs.CY

TL;DR: 大语言模型（LLMs）用于社会模拟虽能提升真实感，但存在与建模认知基础不兼容问题，通过思想实验揭示五大困境，指出应用条件并呼吁重新定位。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型构建的代理在社会模拟中追求真实感与建模认知基础的兼容性问题。

Method: 进行将巴斯扩散模型转换为基于LLM变体的模型构建思想实验。

Result: 发现五大核心困境，使LLM代理陷入不自然的状态，揭示应用时会模糊社会动态的悖论。

Conclusion: 明确LLM代理的理想应用条件，呼吁在社会模拟生态系统中重新定位。

Abstract: Large language models (LLMs) have been increasingly used to build agents in
social simulation because of their impressive abilities to generate fluent,
contextually coherent dialogues. Such abilities can enhance the realism of
models. However, the pursuit of realism is not necessarily compatible with the
epistemic foundation of modelling. We argue that LLM agents, in many regards,
are too human to model: they are too expressive, detailed and intractable to be
consistent with the abstraction, simplification, and interpretability typically
demanded by modelling. Through a model-building thought experiment that
converts the Bass diffusion model to an LLM-based variant, we uncover five core
dilemmas: a temporal resolution mismatch between natural conversation and
abstract time steps; the need for intervention in conversations while avoiding
undermining spontaneous agent outputs; the temptation to introduce rule-like
instructions in prompts while maintaining conversational naturalness; the
tension between role consistency and role evolution across time; and the
challenge of understanding emergence, where system-level patterns become
obscured by verbose micro textual outputs. These dilemmas steer the LLM agents
towards an uncanny valley: not abstract enough to clarify underlying social
mechanisms, while not natural enough to represent realistic human behaviour.
This exposes an important paradox: the realism of LLM agents can obscure,
rather than clarify, social dynamics when misapplied. We tease out the
conditions in which LLM agents are ideally suited: where system-level emergence
is not the focus, linguistic nuances and meaning are central, interactions
unfold in natural time, and stable role identity is more important than
long-term behavioural evolution. We call for repositioning LLM agents in the
ecosystem of social simulation for future applications.

</details>


### [157] [Deprecating Benchmarks: Criteria and Framework](https://arxiv.org/abs/2507.06434)
*Ayrton San Joaquin,Rokas Gipiškis,Leon Staufer,Ariel Gil*

Main category: cs.CY

TL;DR: 前沿AI模型发展迅速，现有缺乏基准测试弃用指导，本文提出弃用标准和框架以推动严格评估。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型发展快，缺乏基准测试弃用的指导，存在高估模型能力等风险。

Method: 回顾基准测试实践。

Result: 提出了决定基准测试完全或部分弃用的标准和框架。

Conclusion: 工作有助于推动基准测试走向严格和高质量评估，建议使多方受益。

Abstract: As frontier artificial intelligence (AI) models rapidly advance, benchmarks
are integral to comparing different models and measuring their progress in
different task-specific domains. However, there is a lack of guidance on when
and how benchmarks should be deprecated once they cease to effectively perform
their purpose. This risks benchmark scores over-valuing model capabilities, or
worse, obscuring capabilities and safety-washing. Based on a review of
benchmarking practices, we propose criteria to decide when to fully or
partially deprecate benchmarks, and a framework for deprecating benchmarks. Our
work aims to advance the state of benchmarking towards rigorous and quality
evaluations, especially for frontier models, and our recommendations are aimed
to benefit benchmark developers, benchmark users, AI governance actors (across
governments, academia, and industry panels), and policy makers.

</details>


### [158] [Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study](https://arxiv.org/abs/2507.06438)
*Kaléu Delphino*

Main category: cs.CY

TL;DR: 研究通过匿名调查和访谈评估计算机科学课程中AI抄袭情况，发现调查有效而访谈参与度低。


<details>
  <summary>Details</summary>
Motivation: 自然语言生成代码工具对计算机科学教育造成威胁，学生AI抄袭比例尚不明确。

Method: 在有120名学生的大型计算机科学课程中进行匿名调查和访谈。

Result: 超25%调查受访者承认AI抄袭，仅1名学生接受访谈。

Conclusion: 调查是研究该问题的有效方法，访谈应避免或设计得能吸引参与。

Abstract: Tools that can generate computer code in response to inputs written in
natural language, such as ChatGPT, pose an existential threat to Computer
Science education in its current form, since students can now use these tools
to solve assignments without much effort. While that risk has already been
recognized by scholars, the proportion of the student body that is incurring in
this new kind of plagiarism is still an open problem. We conducted a pilot
study in a large CS class (n=120) to assess the feasibility of estimating AI
plagiarism through anonymous surveys and interviews. More than 25% of the
survey respondents admitted to committing AI plagiarism. Conversely, only one
student accepted to be interviewed. Given the high levels of misconduct
acknowledgment, we conclude that surveys are an effective method for studies on
the matter, while interviews should be avoided or designed in a way that can
entice participation.

</details>


### [159] [Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change](https://arxiv.org/abs/2507.06876)
*Adrian Rauchfleisch,Joshua Philip Suarez,Nikka Marie Sales,Andreas Jungherr*

Main category: cs.CY

TL;DR: 分析117个国家用户对ChatGPT发布的推文，发现公众对AI的意义建构受经济利益和文化价值影响。


<details>
  <summary>Details</summary>
Motivation: 探究公众对AI产品发布的反应，了解社会如何应对技术变革，以及背后的影响因素。

Method: 分析2022年ChatGPT发布后，117个国家160万用户发布的380万条推文。

Result: 技术技能岗位更早参与且态度积极，写作岗位更晚且更怀疑；个人主义预测更早参与和更负面态度，不确定性规避减少积极态度但不延迟参与；随时间态度变批判主要因新的怀疑声音加入。

Conclusion: 职业背景和文化背景对理解公众对AI的反应很重要。

Abstract: Public product launches in Artificial Intelligence can serve as focusing
events for collective attention, surfacing how societies react to technological
change. Social media provide a window into the sensemaking around these events,
surfacing hopes and fears and showing who chooses to engage in the discourse
and when. We demonstrate that public sensemaking about AI is shaped by economic
interests and cultural values of those involved. We analyze 3.8 million tweets
posted by 1.6 million users across 117 countries in response to the public
launch of ChatGPT in 2022. Our analysis shows how economic self-interest,
proxied by occupational skill types in writing, programming, and mathematics,
and national cultural orientations, as measured by Hofstede's individualism,
uncertainty avoidance, and power distance dimensions, shape who speaks, when
they speak, and their stance towards ChatGPT. Roles requiring more technical
skills, such as programming and mathematics, tend to engage earlier and express
more positive stances, whereas writing-centric occupations join later with
greater skepticism. At the cultural level, individualism predicts both earlier
engagement and a more negative stance, and uncertainty avoidance reduces the
prevalence of positive stances but does not delay when users first engage with
ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study.
The shift toward a more critical stance towards ChatGPT over time stems
primarily from the entry of more skeptical voices rather than a change of heart
among early adopters. Our findings underscore the importance of both the
occupational background and cultural context in understanding public reactions
to AI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [160] [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](https://arxiv.org/abs/2507.06803)
*Matthew Anderson Hendricks,Alice Cicirello*

Main category: cs.CL

TL;DR: 本文提出利用领域和专家知识自动生成动力学系统计算模型的策略，加速工程动力学系统设计与部署，介绍了实现步骤并通过案例展示适用性。


<details>
  <summary>Details</summary>
Motivation: 加速工程动力学系统的设计和部署。

Method: 策略分五步实现，用SysML图提取组件信息，结合NLP策略和LLMs改进中间输出，通过代码生成和计算模型生成步骤获取计算模型。

Result: 通过不同案例展示了自动SysML图生成的适用性，以单摆为例展示了端到端从文本到模型的过程，性能优于仅使用LLMs的结果。

Conclusion: 提出的方法不局限于特定系统、领域或计算软件，具有较好的适用性和性能。

Abstract: This paper contributes to speeding up the design and deployment of
engineering dynamical systems by proposing a strategy for exploiting domain and
expert knowledge for the automated generation of dynamical system computational
model starting from a corpus of document relevant to the dynamical system of
interest and an input document describing the specific system. This strategy is
implemented in five steps and, crucially, it uses system modeling language
diagrams (SysML) to extract accurate information about the dependencies,
attributes, and operations of components. Natural Language Processing (NLP)
strategies and Large Language Models (LLMs) are employed in specific tasks to
improve intermediate outputs of the SySML diagrams automated generation, such
as: list of key nouns; list of extracted relationships; list of key phrases and
key relationships; block attribute values; block relationships; and BDD diagram
generation. The applicability of automated SysML diagram generation is
illustrated with different case studies. The computational models of complex
dynamical systems from SysML diagrams are then obtained via code generation and
computational model generation steps. In the code generation step, NLP
strategies are used for summarization, while LLMs are used for validation only.
The proposed approach is not limited to a specific system, domain, or
computational software. The applicability of the proposed approach is shown via
an end-to-end example from text to model of a simple pendulum, showing improved
performance compared to results yielded by LLMs only.

</details>


### [161] [CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs](https://arxiv.org/abs/2507.06715)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: 介绍针对大语言模型临床文本生成问题的CLI - RAG框架，应用于MIMIC - III数据集生成结构化进展记录，实验效果好。


<details>
  <summary>Details</summary>
Motivation: 现实中患者数据非结构化、异构、分散，临床笔记长且语义密集，现有大语言模型在临床文本生成应用面临挑战。

Method: 引入CLI - RAG框架，采用新颖的分层分块策略和特定任务的双阶段检索机制。

Result: 应用于MIMIC - III数据集生成结构化进展记录，平均对齐分数达87.7%，超过基线，生成输出在不同大语言模型间一致性高。

Conclusion: CLI - RAG框架在临床文本生成中表现良好，能保证时间和语义对齐，具有可重复性、可靠性和临床可信度。

Abstract: Large language models (LLMs), including zero-shot and few-shot paradigms,
have shown promising capabilities in clinical text generation. However,
real-world applications face two key challenges: (1) patient data is highly
unstructured, heterogeneous, and scattered across multiple note types and (2)
clinical notes are often long and semantically dense, making naive prompting
infeasible due to context length constraints and the risk of omitting
clinically relevant information.
  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a
domain-specific framework for structured and clinically grounded text
generation using LLMs. It incorporates a novel hierarchical chunking strategy
that respects clinical document structure and introduces a task-specific
dual-stage retrieval mechanism. The global stage identifies relevant note types
using evidence-based queries, while the local stage extracts high-value content
within those notes creating relevance at both document and section levels.
  We apply the system to generate structured progress notes for individual
hospital visits using 15 clinical note types from the MIMIC-III dataset.
Experiments show that it preserves temporal and semantic alignment across
visits, achieving an average alignment score of 87.7%, surpassing the 80.7%
baseline from real clinician-authored notes. The generated outputs also
demonstrate high consistency across LLMs, reinforcing deterministic behavior
essential for reproducibility, reliability, and clinical trust.

</details>


### [162] [Shifting from Ranking to Set Selection for Retrieval Augmented Generation](https://arxiv.org/abs/2507.06838)
*Dahyun Lee,Yongrae Jo,Haeju Park,Moontae Lee*

Main category: cs.CL

TL;DR: 提出SETR用于检索增强生成（RAG）的集合式段落选择方法，在多跳RAG基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG检索方法主要基于单一段落相关性重新排序，难以满足多跳问答中复杂查询的信息需求。

Method: 提出集合式段落选择方法SETR，通过思维链推理明确查询的信息需求，选择能共同满足这些需求的最优段落集合。

Result: 在多跳RAG基准测试中，SETR在答案正确性和检索质量上优于专有大语言模型重排器和开源基线。

Conclusion: SETR为RAG系统中的传统重排器提供了有效且高效的替代方案。

Abstract: Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved
passages are not only individually relevant but also collectively form a
comprehensive set. Existing approaches primarily rerank top-k passages based on
their individual relevance, often failing to meet the information needs of
complex queries in multi-hop question answering. In this work, we propose a
set-wise passage selection approach and introduce SETR, which explicitly
identifies the information requirements of a query through Chain-of-Thought
reasoning and selects an optimal set of passages that collectively satisfy
those requirements. Experiments on multi-hop RAG benchmarks show that SETR
outperforms both proprietary LLM-based rerankers and open-source baselines in
terms of answer correctness and retrieval quality, providing an effective and
efficient alternative to traditional rerankers in RAG systems. The code is
available at https://github.com/LGAI-Research/SetR

</details>


### [163] [SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN](https://arxiv.org/abs/2507.06895)
*Luca Mariotti,Veronica Guidetti,Federica Mandreoli*

Main category: cs.CL

TL;DR: 介绍SCoRE关系抽取系统，结合监督对比学习和贝叶斯kNN分类器，提出新评估指标，发布Wiki20d数据集，实验表现优且能耗低，设计简洁有优势。


<details>
  <summary>Details</summary>
Motivation: 满足利用外部语料进行知识图谱丰富时对低监督关系抽取解决方案的需求，设计能与预训练大模型无缝集成、适应多样语料和知识图谱的系统。

Method: 结合监督对比学习与贝叶斯kNN分类器进行多标签分类；提出Correlation Structure Distance (CSD)和Precision at R (P@R)两个评估指标；发布Wiki20d基准数据集。

Result: 在五个基准测试中，SCoRE达到或超越了现有方法，显著降低了能耗；增加模型复杂度会降低性能。

Conclusion: SCoRE结合了效率、模块化和可扩展性，是现实世界关系抽取应用的最佳选择。

Abstract: The growing demand for efficient knowledge graph (KG) enrichment leveraging
external corpora has intensified interest in relation extraction (RE),
particularly under low-supervision settings. To address the need for adaptable
and noise-resilient RE solutions that integrate seamlessly with pre-trained
large language models (PLMs), we introduce SCoRE, a modular and cost-effective
sentence-level RE system. SCoRE enables easy PLM switching, requires no
finetuning, and adapts smoothly to diverse corpora and KGs. By combining
supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)
classifier for multi-label classification, it delivers robust performance
despite the noisy annotations of distantly supervised corpora. To improve RE
evaluation, we propose two novel metrics: Correlation Structure Distance (CSD),
measuring the alignment between learned relational patterns and KG structures,
and Precision at R (P@R), assessing utility as a recommender system. We also
release Wiki20d, a benchmark dataset replicating real-world RE conditions where
only KG-derived annotations are available. Experiments on five benchmarks show
that SCoRE matches or surpasses state-of-the-art methods while significantly
reducing energy consumption. Further analyses reveal that increasing model
complexity, as seen in prior work, degrades performance, highlighting the
advantages of SCoRE's minimal design. Combining efficiency, modularity, and
scalability, SCoRE stands as an optimal choice for real-world RE applications.

</details>


### [164] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
*Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju,Mohit Agarwal,Sławek Kwasiborski,Paramjit Sandhu,Patrick Siegler,Ahmet Iscen,Eyal Ben-David,Shiraz Butt,Miltos Allamanis,Seth Benjamin,Robert Busa-Fekete,Felix Hernandez-Campos,Sasha Goldshtein,Matt Dibb,Weiyang Zhang,Annie Marsden,Carey Radebaugh,Stephen Roller,Abhishek Nayyar,Jacob Austin,Tayfun Terzi,Bhargav Kanagal Shamanna,Pete Shaw,Aayush Singh,Florian Luisier,Artur Mendonça,Vaibhav Aggarwal,Larisa Markeeva,Claudio Fantacci,Sergey Brin,HyunJeong Choe,Guanyu Wang,Hartwig Adam,Avigail Dabush,Tatsuya Kiyono,Eyal Marcus,Jeremy Cole,Theophane Weber,Hongrae Lee,Ronny Huang,Alex Muzio,Leandro Kieliger,Maigo Le,Courtney Biles,Long Le,Archit Sharma,Chengrun Yang,Avery Lamp,Dave Dopson,Nate Hurley,Katrina,Xu,Zhihao Shan,Shuang Song,Jiewen Tan,Alexandre Senges,George Zhang,Chong You,Yennie Jun,David Raposo,Susanna Ricco,Xuan Yang,Weijie Chen,Prakhar Gupta,Arthur Szlam,Kevin Villela,Chun-Sung Ferng,Daniel Kasenberg,Chen Liang,Rui Zhu,Arunachalam Narayanaswamy,Florence Perot,Paul Pucciarelli,Anna Shekhawat,Alexey Stern,Rishikesh Ingale,Stefani Karp,Sanaz Bahargam,Adrian Goedeckemeyer,Jie Han,Sicheng Li,Andrea Tacchetti,Dian Yu,Abhishek Chakladar,Zhiying Zhang,Mona El Mahdy,Xu Gao,Dale Johnson,Samrat Phatale,AJ Piergiovanni,Hyeontaek Lim,Clement Farabet,Carl Lebsack,Theo Guidroz,John Blitzer,Nico Duduta,David Madras,Steve Li,Daniel von Dincklage,Xin Li,Mahdis Mahdieh,George Tucker,Ganesh Jawahar,Owen Xiao,Danny Tarlow,Robert Geirhos,Noam Velan,Daniel Vlasic,Kalesha Bullard,SK Park,Nishesh Gupta,Kellie Webster,Ayal Hitron,Jieming Mao,Julian Eisenschlos,Laurel Prince,Nina D'Souza,Kelvin Zheng,Sara Nasso,Gabriela Botea,Carl Doersch,Caglar Unlu,Chris Alberti,Alexey Svyatkovskiy,Ankita Goel,Krzysztof Choromanski,Pan-Pan Jiang,Richard Nguyen,Four Flynn,Daria Ćurko,Peter Chen,Nicholas Roth,Kieran Milan,Caleb Habtegebriel,Shashi Narayan,Michael Moffitt,Jake Marcus,Thomas Anthony,Brendan McMahan,Gowoon Cheon,Ruibo Liu,Megan Barnes,Lukasz Lew,Rebeca Santamaria-Fernandez,Mayank Upadhyay,Arjun Akula,Arnar Mar Hrafnkelsson,Alvaro Caceres,Andrew Bunner,Michal Sokolik,Subha Puttagunta,Lawrence Moore,Berivan Isik,Weilun Chen,Jay Hartford,Lawrence Chan,Pradeep Shenoy,Dan Holtmann-Rice,Jane Park,Fabio Viola,Alex Salcianu,Sujeevan Rajayogam,Ian Stewart-Binks,Zelin Wu,Richard Everett,Xi Xiong,Pierre-Antoine Manzagol,Gary Leung,Carl Saroufim,Bo Pang,Dawid Wegner,George Papamakarios,Jennimaria Palomaki,Helena Pankov,Guangda Lai,Guilherme Tubone,Shubin Zhao,Theofilos Strinopoulos,Seth Neel,Mingqiu Wang,Joe Kelley,Li Li,Pingmei Xu,Anitha Vijayakumar,Andrea D'olimpio,Omer Levy,Massimo Nicosia,Grigory Rozhdestvenskiy,Ni Lao,Sirui Xie,Yash Katariya,Jon Simon,Sanjiv Kumar,Florian Hartmann,Michael Kilgore,Jinhyuk Lee,Aroma Mahendru,Roman Ring,Tom Hennigan,Fiona Lang,Colin Cherry,David Steiner,Dawsen Hwang,Ray Smith,Pidong Wang,Jeremy Chen,Ming-Hsuan Yang,Sam Kwei,Philippe Schlattner,Donnie Kim,Ganesh Poomal Girirajan,Nikola Momchev,Ayushi Agarwal,Xingyi Zhou,Ilkin Safarli,Zachary Garrett,AJ Pierigiovanni,Sarthak Jauhari,Alif Raditya Rochman,Shikhar Vashishth,Quan Yuan,Christof Angermueller,Jon Blanton,Xinying Song,Nitesh Bharadwaj Gundavarapu,Thi Avrahami,Maxine Deines,Subhrajit Roy,Manish Gupta,Christopher Semturs,Shobha Vasudevan,Aditya Srikanth Veerubhotla,Shriya Sharma,Josh Jacob,Zhen Yang,Andreas Terzis,Dan Karliner,Auriel Wright,Tania Rojas-Esponda,Ashley Brown,Abhijit Guha Roy,Pawan Dogra,Andrei Kapishnikov,Peter Young,Wendy Kan,Vinodh Kumar Rajendran,Maria Ivanova,Salil Deshmukh,Chia-Hua Ho,Mike Kwong,Stav Ginzburg,Annie Louis,KP Sawhney,Slav Petrov,Jing Xie,Yunfei Bai,Georgi Stoyanov,Alex Fabrikant,Rajesh Jayaram,Yuqi Li,Joe Heyward,Justin Gilmer,Yaqing Wang,Radu Soricut,Luyang Liu,Qingnan Duan,Jamie Hayes,Maura O'Brien,Gaurav Singh Tomar,Sivan Eiger,Bahar Fatemi,Jeffrey Hui,Catarina Barros,Adaeze Chukwuka,Alena Butryna,Saksham Thakur,Austin Huang,Zhufeng Pan,Haotian Tang,Serkan Cabi,Tulsee Doshi,Michiel Bakker,Sumit Bagri,Ruy Ley-Wild,Adam Lelkes,Jennie Lees,Patrick Kane,David Greene,Shimu Wu,Jörg Bornschein,Gabriela Surita,Sarah Hodkinson,Fangtao Li,Chris Hidey,Sébastien Pereira,Sean Ammirati,Phillip Lippe,Adam Kraft,Pu Han,Sebastian Gerlach,Zifeng Wang,Liviu Panait,Feng Han,Brian Farris,Yingying Bi,Hannah DeBalsi,Miaosen Wang,Gladys Tyen,James Cohan,Susan Zhang,Jarred Barber,Da-Woon Chung,Jaeyoun Kim,Markus Kunesch,Steven Pecht,Nami Akazawa,Abe Friesen,James Lyon,Ali Eslami,Junru Wu,Jie Tan,Yue Song,Ravi Kumar,Chris Welty,Ilia Akolzin,Gena Gibson,Sean Augenstein,Arjun Pillai,Nancy Yuen,Du Phan,Xin Wang,Iain Barr,Heiga Zen,Nan Hua,Casper Liu,Jilei,Wang,Tanuj Bhatia,Hao Xu,Oded Elyada,Pushmeet Kohli,Mirek Olšák,Ke Chen,Azalia Mirhoseini,Noam Shazeer,Shoshana Jakobovits,Maggie Tran,Nolan Ramsden,Tarun Bharti,Fred Alcober,Yunjie Li,Shilpa Shetty,Jing Chen,Dmitry Kalashnikov,Megha Nawhal,Sercan Arik,Hanwen Chen,Michiel Blokzijl,Shubham Gupta,James Rubin,Rigel Swavely,Sophie Bridgers,Ian Gemp,Chen Su,Arun Suggala,Juliette Pluto,Mary Cassin,Alain Vaucher,Kaiyang Ji,Jiahao Cai,Andrew Audibert,Animesh Sinha,David Tian,Efrat Farkash,Amy Hua,Jilin Chen,Duc-Hieu Tran,Edward Loper,Nicole Brichtova,Lara McConnaughey,Ballie Sandhu,Robert Leland,Doug DeCarlo,Andrew Over,James Huang,Xing Wu,Connie Fan,Eric Li,Yun Lei,Deepak Sharma,Cosmin Paduraru,Luo Yu,Matko Bošnjak,Phuong Dao,Min Choi,Sneha Kudugunta,Jakub Adamek,Carlos Guía,Ali Khodaei,Jie Feng,Wenjun Zeng,David Welling,Sandeep Tata,Christina Butterfield,Andrey Vlasov,Seliem El-Sayed,Swaroop Mishra,Tara Sainath,Shentao Yang,RJ Skerry-Ryan,Jeremy Shar,Robert Berry,Arunkumar Rajendran,Arun Kandoor,Andrea Burns,Deepali Jain,Tom Stone,Wonpyo Park,Shibo Wang,Albin Cassirer,Guohui Wang,Hayato Kobayashi,Sergey Rogulenko,Vineetha Govindaraj,Mikołaj Rybiński,Nadav Olmert,Colin Evans,Po-Sen Huang,Kelvin Xu,Premal Shah,Terry Thurk,Caitlin Sikora,Mu Cai,Jin Xie,Elahe Dabir,Saloni Shah,Norbert Kalb,Carrie Zhang,Shruthi Prabhakara,Amit Sabne,Artiom Myaskovsky,Vikas Raunak,Blanca Huergo,Behnam Neyshabur,Jon Clark,Ye Zhang,Shankar Krishnan,Eden Cohen,Dinesh Tewari,James Lottes,Yumeya Yamamori,Hui,Li,Mohamed Elhawaty,Ada Maksutaj Oflazer,Adrià Recasens,Sheryl Luo,Duy Nguyen,Taylor Bos,Kalyan Andra,Ana Salazar,Ed Chi,Jeongwoo Ko,Matt Ginsberg,Anders Andreassen,Anian Ruoss,Todor Davchev,Elnaz Davoodi,Chenxi Liu,Min Kim,Santiago Ontanon,Chi Ming To,Dawei Jia,Rosemary Ke,Jing Wang,Anna Korsun,Moran Ambar,Ilya Kornakov,Irene Giannoumis,Toni Creswell,Denny Zhou,Yi Su,Ishaan Watts,Aleksandr Zaks,Evgenii Eltyshev,Ziqiang Feng,Sidharth Mudgal,Alex Kaskasoli,Juliette Love,Kingshuk Dasgupta,Sam Shleifer,Richard Green,Sungyong Seo,Chansoo Lee,Dale Webster,Prakash Shroff,Ganna Raboshchuk,Isabel Leal,James Manyika,Sofia Erell,Daniel Murphy,Zhisheng Xiao,Anton Bulyenov,Julian Walker,Mark Collier,Matej Kastelic,Nelson George,Sushant Prakash,Sailesh Sidhwani,Alexey Frolov,Steven Hansen,Petko Georgiev,Tiberiu Sosea,Chris Apps,Aishwarya Kamath,David Reid,Emma Cooney,Charlotte Magister,Oriana Riva,Alec Go,Pu-Chin Chen,Sebastian Krause,Nir Levine,Marco Fornoni,Ilya Figotin,Nick Roy,Parsa Mahmoudieh,Vladimir Magay,Mukundan Madhavan,Jin Miao,Jianmo Ni,Yasuhisa Fujii,Ian Chou,George Scrivener,Zak Tsai,Siobhan Mcloughlin,Jeremy Selier,Sandra Lefdal,Jeffrey Zhao,Abhijit Karmarkar,Kushal Chauhan,Shivanker Goel,Zhaoyi Zhang,Vihan Jain,Parisa Haghani,Mostafa Dehghani,Jacob Scott,Erin Farnese,Anastasija Ilić,Steven Baker,Julia Pawar,Li Zhong,Josh Camp,Yoel Zeldes,Shravya Shetty,Anand Iyer,Vít Listík,Jiaxian Guo,Luming Tang,Mark Geller,Simon Bucher,Yifan Ding,Hongzhi Shi,Carrie Muir,Dominik Grewe,Ramy Eskander,Octavio Ponce,Boqing Gong,Derek Gasaway,Samira Khan,Umang Gupta,Angelos Filos,Weicheng Kuo,Klemen Kloboves,Jennifer Beattie,Christian Wright,Leon Li,Alicia Jin,Sandeep Mariserla,Miteyan Patel,Jens Heitkaemper,Dilip Krishnan,Vivek Sharma,David Bieber,Christian Frank,John Lambert,Paul Caron,Martin Polacek,Mai Giménez,Himadri Choudhury,Xing Yu,Sasan Tavakkol,Arun Ahuja,Franz Och,Rodolphe Jenatton,Wojtek Skut,Bryan Richter,David Gaddy,Andy Ly,Misha Bilenko,Megh Umekar,Ethan Liang,Martin Sevenich,Mandar Joshi,Hassan Mansoor,Rebecca Lin,Sumit Sanghai,Abhimanyu Singh,Xiaowei Li,Sudheendra Vijayanarasimhan,Zaheer Abbas,Yonatan Bitton,Hansa Srinivasan,Manish Reddy Vuyyuru,Alexander Frömmgen,Yanhua Sun,Ralph Leith,Alfonso Castaño,DJ Strouse,Le Yan,Austin Kyker,Satish Kambala,Mary Jasarevic,Thibault Sellam,Chao Jia,Alexander Pritzel,Raghavender R,Huizhong Chen,Natalie Clay,Sudeep Gandhe,Sean Kirmani,Sayna Ebrahimi,Hannah Kirkwood,Jonathan Mallinson,Chao Wang,Adnan Ozturel,Kuo Lin,Shyam Upadhyay,Vincent Cohen-Addad,Sean Purser-haskell,Yichong Xu,Ebrahim Songhori,Babi Seal,Alberto Magni,Almog Gueta,Tingting Zou,Guru Guruganesh,Thais Kagohara,Hung Nguyen,Khalid Salama,Alejandro Cruzado Ruiz,Justin Frye,Zhenkai Zhu,Matthias Lochbrunner,Simon Osindero,Wentao Yuan,Lisa Lee,Aman Prasad,Lam Nguyen Thiet,Daniele Calandriello,Victor Stone,Qixuan Feng,Han Ke,Maria Voitovich,Geta Sampemane,Lewis Chiang,Ling Wu,Alexander Bykovsky,Matt Young,Luke Vilnis,Ishita Dasgupta,Aditya Chawla,Qin Cao,Bowen Liang,Daniel Toyama,Szabolcs Payrits,Anca Stefanoiu,Dimitrios Vytiniotis,Ankesh Anand,Tianxiao Shen,Blagoj Mitrevski,Michael Tschannen,Sreenivas Gollapudi,Aishwarya P S,José Leal,Zhe Shen,Han Fu,Wei Wang,Arvind Kannan,Doron Kukliansky,Sergey Yaroshenko,Svetlana Grant,Umesh Telang,David Wood,Alexandra Chronopoulou,Alexandru Ţifrea,Tao Zhou,Tony,Nguy\~ên,Muge Ersoy,Anima Singh,Meiyan Xie,Emanuel Taropa,Woohyun Han,Eirikur Agustsson,Andrei Sozanschi,Hui Peng,Alex Chen,Yoel Drori,Efren Robles,Yang Gao,Xerxes Dotiwalla,Ying Chen,Anudhyan Boral,Alexei Bendebury,John Nham,Chris Tar,Luis Castro,Jiepu Jiang,Canoee Liu,Felix Halim,Jinoo Baek,Andy Wan,Jeremiah Liu,Yuan Cao,Shengyang Dai,Trilok Acharya,Ruoxi Sun,Fuzhao Xue,Saket Joshi,Morgane Lustman,Yongqin Xian,Rishabh Joshi,Deep Karkhanis,Nora Kassner,Jamie Hall,Xiangzhuo Ding,Gan Song,Gang Li,Chen Zhu,Yana Kulizhskaya,Bin Ni,Alexey Vlaskin,Solomon Demmessie,Lucio Dery,Salah Zaiem,Yanping Huang,Cindy Fan,Felix Gimeno,Ananth Balashankar,Koji Kojima,Hagai Taitelbaum,Maya Meng,Dero Gharibian,Sahil Singla,Wei Chen,Ambrose Slone,Guanjie Chen,Sujee Rajayogam,Max Schumacher,Suyog Kotecha,Rory Blevins,Qifei Wang,Mor Hazan Taege,Alex Morris,Xin Liu,Fayaz Jamil,Richard Zhang,Pratik Joshi,Ben Ingram,Tyler Liechty,Ahmed Eleryan,Scott Baird,Alex Grills,Gagan Bansal,Shan Han,Kiran Yalasangi,Shawn Xu,Majd Al Merey,Isabel Gao,Felix Weissenberger,Igor Karpov,Robert Riachi,Ankit Anand,Gautam Prasad,Kay Lamerigts,Reid Hayes,Jamie Rogers,Mandy Guo,Ashish Shenoy,Qiong,Hu,Kyle He,Yuchen Liu,Polina Zablotskaia,Sagar Gubbi,Yifan Chang,Jay Pavagadhi,Kristian Kjems,Archita Vadali,Diego Machado,Yeqing Li,Renshen Wang,Dipankar Ghosh,Aahil Mehta,Dana Alon,George Polovets,Alessio Tonioni,Nate Kushman,Joel D'sa,Lin Zhuo,Allen Wu,Rohin Shah,John Youssef,Jiayu Ye,Justin Snyder,Karel Lenc,Senaka Buthpitiya,Matthew Tung,Jichuan Chang,Tao Chen,David Saxton,Jenny Lee,Lydia Lihui Zhang,James Qin,Prabakar Radhakrishnan,Maxwell Chen,Piotr Ambroszczyk,Metin Toksoz-Exley,Yan Zhong,Nitzan Katz,Brendan O'Donoghue,Tamara von Glehn,Adi Gerzi Rosenthal,Aga Świetlik,Xiaokai Zhao,Nick Fernando,Jinliang Wei,Jieru Mei,Sergei Vassilvitskii,Diego Cedillo,Pranjal Awasthi,Hui Zheng,Koray Kavukcuoglu,Itay Laish,Joseph Pagadora,Marc Brockschmidt,Christopher A. Choquette-Choo,Arunkumar Byravan,Yifeng Lu,Xu Chen,Mia Chen,Kenton Lee,Rama Pasumarthi,Sijal Bhatnagar,Aditya Shah,Qiyin Wu,Zhuoyuan Chen,Zack Nado,Bartek Perz,Zixuan Jiang,David Kao,Ganesh Mallya,Nino Vieillard,Lantao Mei,Sertan Girgin,Mandy Jordan,Yeongil Ko,Alekh Agarwal,Yaxin Liu,Yasemin Altun,Raoul de Liedekerke,Anastasios Kementsietsidis,Daiyi Peng,Dangyi Liu,Utku Evci,Peter Humphreys,Austin Tarango,Xiang Deng,Yoad Lewenberg,Kevin Aydin,Chengda Wu,Bhavishya Mittal,Tsendsuren Munkhdalai,Kleopatra Chatziprimou,Rodrigo Benenson,Uri First,Xiao Ma,Jinning Li,Armand Joulin,Hamish Tomlinson,Tingnan Zhang,Milad Nasr,Zhi Hong,Michaël Sander,Lisa Anne Hendricks,Anuj Sharma,Andrew Bolt,Eszter Vértes,Jiri Simsa,Tomer Levinboim,Olcan Sercinoglu,Divyansh Shukla,Austin Wu,Craig Swanson,Danny Vainstein,Fan Bu,Bo Wang,Ryan Julian,Charles Yoon,Sergei Lebedev,Antonious Girgis,Bernd Bandemer,David Du,Todd Wang,Xi Chen,Ying Xiao,Peggy Lu,Natalie Ha,Vlad Ionescu,Simon Rowe,Josip Matak,Federico Lebron,Andreas Steiner,Lalit Jain,Manaal Faruqui,Nicolas Lacasse,Georgie Evans,Neesha Subramaniam,Dean Reich,Giulia Vezzani,Aditya Pandey,Joe Stanton,Tianhao Zhou,Liam McCafferty,Henry Griffiths,Verena Rieser,Soheil Hassas Yeganeh,Eleftheria Briakou,Lu Huang,Zichuan Wei,Liangchen Luo,Erik Jue,Gabby Wang,Victor Cotruta,Myriam Khan,Jongbin Park,Qiuchen Guo,Peiran Li,Rong Rong,Diego Antognini,Anastasia Petrushkina,Chetan Tekur,Eli Collins,Parul Bhatia,Chester Kwak,Wenhu Chen,Arvind Neelakantan,Immanuel Odisho,Sheng Peng,Vincent Nallatamby,Vaibhav Tulsyan,Fabian Pedregosa,Peng Xu,Raymond Lin,Yulong Wang,Emma Wang,Sholto Douglas,Reut Tsarfaty,Elena Gribovskaya,Renga Aravamudhan,Manu Agarwal,Mara Finkelstein,Qiao Zhang,Elizabeth Cole,Phil Crone,Sarmishta Velury,Anil Das,Chris Sauer,Luyao Xu,Danfeng Qin,Chenjie Gu,Dror Marcus,CJ Zheng,Wouter Van Gansbeke,Sobhan Miryoosefi,Haitian Sun,YaGuang Li,Charlie Chen,Jae Yoo,Pavel Dubov,Alex Tomala,Adams Yu,Paweł Wesołowski,Alok Gunjan,Eddie Cao,Jiaming Luo,Nikhil Sethi,Arkadiusz Socala,Laura Graesser,Tomas Kocisky,Arturo BC,Minmin Chen,Edward Lee,Sophie Wang,Weize Kong,Qiantong Xu,Nilesh Tripuraneni,Yiming Li,Xinxin Yu,Allen Porter,Paul Voigtlaender,Biao Zhang,Arpi Vezer,Sarah York,Qing Wei,Geoffrey Cideron,Mark Kurzeja,Seungyeon Kim,Benny Li,Angéline Pouget,Hyo Lee,Kaspar Daugaard,Yang Li,Dave Uthus,Aditya Siddhant,Paul Cavallaro,Sriram Ganapathy,Maulik Shah,Rolf Jagerman,Jeff Stanway,Piermaria Mendolicchio,Li Xiao,Kayi Lee,Tara Thompson,Shubham Milind Phal,Jason Chase,Sun Jae Lee,Adrian N Reyes,Disha Shrivastava,Zhen Qin,Roykrong Sukkerd,Seth Odoom,Lior Madmoni,John Aslanides,Jonathan Herzig,Elena Pochernina,Sheng Zhang,Parker Barnes,Daisuke Ikeda,Qiujia Li,Shuo-yiin Chang,Shakir Mohamed,Jim Sproch,Richard Powell,Bidisha Samanta,Domagoj Ćevid,Anton Kovsharov,Shrestha Basu Mallick,Srinivas Tadepalli,Anne Zheng,Kareem Ayoub,Andreas Noever,Christian Reisswig,Zhuo Xu,Junhyuk Oh,Martin Matysiak,Tim Blyth,Shereen Ashraf,Julien Amelot,Boone Severson,Michele Bevilacqua,Motoki Sano,Ethan Dyer,Ofir Roval,Anu Sinha,Yin Zhong,Sagi Perel,Tea Sabolić,Johannes Mauerer,Willi Gierke,Mauro Verzetti,Rodrigo Cabrera,Alvin Abdagic,Steven Hemingray,Austin Stone,Jong Lee,Farooq Ahmad,Karthik Raman,Lior Shani,Jonathan Lai,Orhan Firat,Nathan Waters,Eric Ge,Mo Shomrat,Himanshu Gupta,Rajeev Aggarwal,Tom Hudson,Bill Jia,Simon Baumgartner,Palak Jain,Joe Kovac,Junehyuk Jung,Ante Žužul,Will Truong,Morteza Zadimoghaddam,Songyou Peng,Marco Liang,Rachel Sterneck,Balaji Lakshminarayanan,Machel Reid,Oliver Woodman,Tong Zhou,Jianling Wang,Vincent Coriou,Arjun Narayanan,Jay Hoover,Yenai Ma,Apoorv Jindal,Clayton Sanford,Doug Reid,Swaroop Ramaswamy,Alex Kurakin,Roland Zimmermann,Yana Lunts,Dragos Dena,Zalán Borsos,Vered Cohen,Shujian Zhang,Will Grathwohl,Robert Dadashi,Morgan Redshaw,Joshua Kessinger,Julian Odell,Silvano Bonacina,Zihang Dai,Grace Chen,Ayush Dubey,Pablo Sprechmann,Mantas Pajarskas,Wenxuan Zhou,Niharika Ahuja,Tara Thomas,Martin Nikoltchev,Matija Kecman,Bharath Mankalale,Andrey Ryabtsev,Jennifer She,Christian Walder,Jiaming Shen,Lu Li,Carolina Parada,Sheena Panthaplackel,Okwan Kwon,Matt Lawlor,Utsav Prabhu,Yannick Schroecker,Marc'aurelio Ranzato,Pete Blois,Iurii Kemaev,Ting Yu,Dmitry,Lepikhin,Hao Xiong,Sahand Sharifzadeh,Oleaser Johnson,Jeremiah Willcock,Rui Yao,Greg Farquhar,Sujoy Basu,Hidetoshi Shimokawa,Nina Anderson,Haiguang Li,Khiem Pham,Yizhong Liang,Sebastian Borgeaud,Alexandre Moufarek,Hideto Kazawa,Blair Kutzman,Marcin Sieniek,Sara Smoot,Ruth Wang,Natalie Axelsson,Nova Fallen,Prasha Sundaram,Yuexiang Zhai,Varun Godbole,Petros Maniatis,Alek Wang,Ilia Shumailov,Santhosh Thangaraj,Remi Crocker,Nikita Gupta,Gang Wu,Phil Chen,Gellért Weisz,Celine Smith,Mojtaba Seyedhosseini,Boya Fang,Xiyang Luo,Roey Yogev,Zeynep Cankara,Andrew Hard,Helen Ran,Rahul Sukthankar,George Necula,Gaël Liu,Honglong Cai,Praseem Banzal,Daniel Keysers,Sanjay Ghemawat,Connie Tao,Emma Dunleavy,Aditi Chaudhary,Wei Li,Maciej Mikuła,Chen-Yu Lee,Tiziana Refice,Krishna Somandepalli,Alexandre Fréchette,Dan Bahir,John Karro,Keith Rush,Sarah Perrin,Bill Rosgen,Xiaomeng Yang,Clara Huiyi Hu,Mahmoud Alnahlawi,Justin Mao-Jones,Roopal Garg,Hoang Nguyen,Bat-Orgil Batsaikhan,Iñaki Iturrate,Anselm Levskaya,Avi Singh,Ashyana Kachra,Tony Lu,Denis Petek,Zheng Xu,Mark Graham,Lukas Zilka,Yael Karov,Marija Kostelac,Fangyu Liu,Yaohui Guo,Weiyue Wang,Bernd Bohnet,Emily Pitler,Tony Bruguier,Keisuke Kinoshita,Chrysovalantis Anastasiou,Nilpa Jha,Ting Liu,Jerome Connor,Phil Wallis,Philip Pham,Eric Bailey,Shixin Li,Heng-Tze Cheng,Sally Ma,Haiqiong Li,Akanksha Maurya,Kate Olszewska,Manfred Warmuth,Christy Koh,Dominik Paulus,Siddhartha Reddy Jonnalagadda,Enrique Piqueras,Ali Elqursh,Geoff Brown,Hadar Shemtov,Loren Maggiore,Fei Xia,Ryan Foley,Beka Westberg,George van den Driessche,Livio Baldini Soares,Arjun Kar,Michael Quinn,Siqi Zuo,Jialin Wu,Kyle Kastner,Anna Bortsova,Aijun Bai,Ales Mikhalap,Luowei Zhou,Jennifer Brennan,Vinay Ramasesh,Honglei Zhuang,John Maggs,Johan Schalkwyk,Yuntao Xu,Hui Huang,Andrew Howard,Sasha Brown,Linting Xue,Gloria Shen,Brian Albert,Neha Jha,Daniel Zheng,Varvara Krayvanova,Spurthi Amba Hombaiah,Olivier Lacombe,Gautam Vasudevan,Dan Graur,Tian Xie,Meet Gandhi,Bangju Wang,Dustin Zelle,Harman Singh,Dahun Kim,Sébastien Cevey,Victor Ungureanu,Natasha Noy,Fei Liu,Annie Xie,Fangxiaoyu Feng,Katerina Tsihlas,Daniel Formoso,Neera Vats,Quentin Wellens,Yinan Wang,Niket Kumar Bhumihar,Samrat Ghosh,Matt Hoffman,Tom Lieber,Oran Lang,Kush Bhatia,Tom Paine,Aroonalok Pyne,Ronny Votel,Madeleine Clare Elish,Benoit Schillings,Alex Panagopoulos,Haichuan Yang,Adam Raveret,Zohar Yahav,Shuang Liu,Warren Chen,Dalia El Badawy,Nishant Agrawal,Mohammed Badawi,Mahdi Mirzazadeh,Carla Bromberg,Fan Ye,Chang Liu,Tatiana Sholokhova,George-Cristian Muraru,Gargi Balasubramaniam,Jonathan Malmaud,Alen Carin,Danilo Martins,Irina Jurenka,Pankil Botadra,Dave Lacey,Richa Singh,Mariano Schain,Dan Zheng,Isabelle Guyon,Victor Lavrenko,Seungji Lee,Xiang Zhou,Demis Hassabis,Jeshwanth Challagundla,Derek Cheng,Nikhil Mehta,Matthew Mauger,Michela Paganini,Pushkar Mishra,Kate Lee,Zhang Li,Lexi Baugher,Ondrej Skopek,Max Chang,Amir Zait,Gaurav Menghani,Lizzetth Bellot,Guangxing Han,Jean-Michel Sarr,Sharat Chikkerur,Himanshu Sahni,Rohan Anil,Arun Narayanan,Chandu Thekkath,Daniele Pighin,Hana Strejček,Marko Velic,Fred Bertsch,Manuel Tragut,Keran Rong,Alicia Parrish,Kai Bailey,Jiho Park,Isabela Albuquerque,Abhishek Bapna,Rajesh Venkataraman,Alec Kosik,Johannes Griesser,Zhiwei Deng,Alek Andreev,Qingyun Dou,Kevin Hui,Fanny Wei,Xiaobin Yu,Lei Shu,Avia Aharon,David Barker,Badih Ghazi,Sebastian Flennerhag,Chris Breaux,Yuchuan Liu,Matthew Bilotti,Josh Woodward,Uri Alon,Stephanie Winkler,Tzu-Kuo Huang,Kostas Andriopoulos,João Gabriel Oliveira,Penporn Koanantakool,Berkin Akin,Michael Wunder,Cicero Nogueira dos Santos,Mohammad Hossein Bateni,Lin Yang,Dan Horgan,Beer Changpinyo,Keyvan Amiri,Min Ma,Dayeong Lee,Lihao Liang,Anirudh Baddepudi,Tejasi Latkar,Raia Hadsell,Jun Xu,Hairong Mu,Michael Han,Aedan Pope,Snchit Grover,Frank Kim,Ankit Bhagatwala,Guan Sun,Yamini Bansal,Amir Globerson,Alireza Nazari,Samira Daruki,Hagen Soltau,Jane Labanowski,Laurent El Shafey,Matt Harvey,Yanif Ahmad,Elan Rosenfeld,William Kong,Etienne Pot,Yi-Xuan Tan,Aurora Wei,Victoria Langston,Marcel Prasetya,Petar Veličković,Richard Killam,Robin Strudel,Darren Ni,Zhenhai Zhu,Aaron Archer,Kavya Kopparapu,Lynn Nguyen,Emilio Parisotto,Hussain Masoom,Sravanti Addepalli,Jordan Grimstad,Hexiang Hu,Joss Moore,Avinatan Hassidim,Le Hou,Mukund Raghavachari,Jared Lichtarge,Adam R. Brown,Hilal Dib,Natalia Ponomareva,Justin Fu,Yujing Zhang,Altaf Rahman,Joana Iljazi,Edouard Leurent,Gabriel Dulac-Arnold,Cosmo Du,Chulayuth Asawaroengchai,Larry Jin,Ela Gruzewska,Ziwei Ji,Benigno Uria,Daniel De Freitas,Paul Barham,Lauren Beltrone,Víctor Campos,Jun Yan,Neel Kovelamudi,Arthur Nguyen,Elinor Davies,Zhichun Wu,Zoltan Egyed,Kristina Toutanova,Nithya Attaluri,Hongliang Fei,Peter Stys,Siddhartha Brahma,Martin Izzard,Siva Velusamy,Scott Lundberg,Vincent Zhuang,Kevin Sequeira,Adam Santoro,Ehsan Amid,Ophir Aharoni,Shuai Ye,Mukund Sundararajan,Lijun Yu,Yu-Cheng Ling,Stephen Spencer,Hugo Song,Josip Djolonga,Christo Kirov,Sonal Gupta,Alessandro Bissacco,Clemens Meyer,Mukul Bhutani,Andrew Dai,Weiyi Wang,Siqi Liu,Ashwin Sreevatsa,Qijun Tan,Maria Wang,Lucy Kim,Yicheng Wang,Alex Irpan,Yang Xiao,Stanislav Fort,Yifan He,Alex Gurney,Bryan Gale,Yue Ma,Monica Roy,Viorica Patraucean,Taylan Bilal,Golnaz Ghiasi,Anahita Hosseini,Melvin Johnson,Zhuowan Li,Yi Tay,Benjamin Beyret,Katie Millican,Josef Broder,Mayank Lunayach,Danny Swisher,Eugen Vušak,David Parkinson,MH Tessler,Adi Mayrav Gilady,Richard Song,Allan Dafoe,Yves Raimond,Masa Yamaguchi,Itay Karo,Elizabeth Nielsen,Kevin Kilgour,Mike Dusenberry,Rajiv Mathews,Jiho Choi,Siyuan Qiao,Harsh Mehta,Sahitya Potluri,Chris Knutsen,Jialu Liu,Tat Tan,Kuntal Sengupta,Keerthana Gopalakrishnan,Abodunrinwa Toki,Mencher Chiang,Mike Burrows,Grace Vesom,Zafarali Ahmed,Ilia Labzovsky,Siddharth Vashishtha,Preeti Singh,Ankur Sharma,Ada Ma,Jinyu Xie,Pranav Talluri,Hannah Forbes-Pollard,Aarush Selvan,Joel Wee,Loic Matthey,Tom Funkhouser,Parthasarathy Gopavarapu,Lev Proleev,Cheng Li,Matt Thomas,Kashyap Kolipaka,Zhipeng Jia,Ashwin Kakarla,Srinivas Sunkara,Joan Puigcerver,Suraj Satishkumar Sheth,Emily Graves,Chen Wang,Sadh MNM Khan,Kai Kang,Shyamal Buch,Fred Zhang,Omkar Savant,David Soergel,Kevin Lee,Linda Friso,Xuanyi Dong,Rahul Arya,Shreyas Chandrakaladharan,Connor Schenck,Greg Billock,Tejas Iyer,Anton Bakalov,Leslie Baker,Alex Ruiz,Angad Chandorkar,Trieu Trinh,Matt Miecnikowski,Yanqi Zhou,Yangsibo Huang,Jiazhong Nie,Ali Shah,Ashish Thapliyal,Sam Haves,Lun Wang,Uri Shaham,Patrick Morris-Suzuki,Soroush Radpour,Leonard Berrada,Thomas Strohmann,Chaochao Yan,Jingwei Shen,Sonam Goenka,Tris Warkentin,Petar Dević,Dan Belov,Albert Webson,Madhavi Yenugula,Puranjay Datta,Jerry Chang,Nimesh Ghelani,Aviral Kumar,Vincent Perot,Jessica Lo,Yang Song,Herman Schmit,Jianmin Chen,Vasilisa Bashlovkina,Xiaoyue Pan,Diana Mincu,Paul Roit,Isabel Edkins,Andy Davis,Yujia Li,Ben Horn,Xinjian Li,Pradeep Kumar S,Eric Doi,Wanzheng Zhu,Sri Gayatri Sundara Padmanabhan,Siddharth Verma,Jasmine Liu,Heng Chen,Mihajlo Velimirović,Malcolm Reynolds,Priyanka Agrawal,Nick Sukhanov,Abhinit Modi,Siddharth Goyal,John Palowitch,Nima Khajehnouri,Wing Lowe,David Klinghoffer,Sharon Silver,Vinh Tran,Candice Schumann,Francesco Piccinno,Xi Liu,Mario Lučić,Xiaochen Yang,Sandeep Kumar,Ajay Kannan,Ragha Kotikalapudi,Mudit Bansal,Fabian Fuchs,Javad Hosseini,Abdelrahman Abdelhamed,Dawn Bloxwich,Tianhe Yu,Ruoxin Sang,Gregory Thornton,Karan Gill,Yuchi Liu,Virat Shejwalkar,Jason Lin,Zhipeng Yan,Kehang Han,Thomas Buschmann,Michael Pliskin,Zhi Xing,Susheel Tatineni,Junlin Zhang,Sissie Hsiao,Gavin Buttimore,Marcus Wu,Zefei Li,Geza Kovacs,Legg Yeung,Tao Huang,Aaron Cohen,Bethanie Brownfield,Averi Nowak,Mikel Rodriguez,Tianze Shi,Hado van Hasselt,Kevin Cen,Deepanway Ghoshal,Kushal Majmundar,Weiren Yu,Warren,Chen,Danila Sinopalnikov,Hao Zhang,Vlado Galić,Di Lu,Zeyu Zheng,Maggie Song,Gary Wang,Gui Citovsky,Swapnil Gawde,Isaac Galatzer-Levy,David Silver,Ivana Balazevic,Dipanjan Das,Kingshuk Majumder,Yale Cong,Praneet Dutta,Dustin Tran,Hui Wan,Junwei Yuan,Daniel Eppens,Alanna Walton,Been Kim,Harry Ragan,James Cobon-Kerr,Lu Liu,Weijun Wang,Bryce Petrini,Jack Rae,Rakesh Shivanna,Yan Xiong,Chace Lee,Pauline Coquinot,Yiming Gu,Lisa Patel,Blake Hechtman,Aviel Boag,Orion Jankowski,Alex Wertheim,Alex Lee,Paul Covington,Hila Noga,Sam Sobell,Shanthal Vasanth,William Bono,Chirag Nagpal,Wei Fan,Xavier Garcia,Kedar Soparkar,Aybuke Turker,Nathan Howard,Sachit Menon,Yuankai Chen,Vikas Verma,Vladimir Pchelin,Harish Rajamani,Valentin Dalibard,Ana Ramalho,Yang Guo,Kartikeya Badola,Seojin Bang,Nathalie Rauschmayr,Julia Proskurnia,Sudeep Dasari,Xinyun Chen,Mikhail Sushkov,Anja Hauth,Pauline Sho,Abhinav Singh,Bilva Chandra,Allie Culp,Max Dylla,Olivier Bachem,James Besley,Heri Zhao,Timothy Lillicrap,Wei Wei,Wael Al Jishi,Ning Niu,Alban Rrustemi,Raphaël Lopez Kaufman,Ryan Poplin,Jewel Zhao,Minh Truong,Shikhar Bharadwaj,Ester Hlavnova,Eli Stickgold,Cordelia Schmid,Georgi Stephanov,Zhaoqi Leng,Frederick Liu,Léonard Hussenot,Shenil Dodhia,Juliana Vicente Franco,Lesley Katzen,Abhanshu Sharma,Sarah Cogan,Zuguang Yang,Aniket Ray,Sergi Caelles,Shen Yan,Ravin Kumar,Daniel Gillick,Renee Wong,Joshua Ainslie,Jonathan Hoech,Séb Arnold,Dan Abolafia,Anca Dragan,Ben Hora,Grace Hu,Alexey Guseynov,Yang Lu,Chas Leichner,Jinmeng Rao,Abhimanyu Goyal,Nagabhushan Baddi,Daniel Hernandez Diaz,Tim McConnell,Max Bain,Jake Abernethy,Qiqi Yan,Rylan Schaeffer,Paul Vicol,Will Thompson,Montse Gonzalez Arenas,Mathias Bellaiche,Pablo Barrio,Stefan Zinke,Riccardo Patana,Pulkit Mehta,JK Kearns,Avraham Ruderman,Scott Pollom,David D'Ambrosio,Cath Hope,Yang Yu,Andrea Gesmundo,Kuang-Huei Lee,Aviv Rosenberg,Yiqian Zhou,Yaoyiran Li,Drew Garmon,Yonghui Wu,Safeen Huda,Gil Fidel,Martin Baeuml,Jian Li,Phoebe Kirk,Rhys May,Tao Tu,Sara Mc Carthy,Toshiyuki Fukuzawa,Miranda Aperghis,Chih-Kuan Yeh,Toshihiro Yoshino,Bo Li,Austin Myers,Kaisheng Yao,Ben Limonchik,Changwan Ryu,Rohun Saxena,Alex Goldin,Ruizhe Zhao,Rocky Rhodes,Tao Zhu,Divya Tyam,Heidi Howard,Nathan Byrd,Hongxu Ma,Yan Wu,Ryan Mullins,Qingze Wang,Aida Amini,Sebastien Baur,Yiran Mao,Subhashini Venugopalan,Will Song,Wen Ding,Paul Collins,Sashank Reddi,Megan Shum,Andrei Rusu,Luisa Zintgraf,Kelvin Chan,Sheela Goenka,Mathieu Blondel,Michael Collins,Renke Pan,Marissa Giustina,Nikolai Chinaev,Christian Schuler,Ce Zheng,Jonas Valfridsson,Alyssa Loo,Alex Yakubovich,Jamie Smith,Tao Jiang,Rich Munoz,Gabriel Barcik,Rishabh Bansal,Mingyao Yang,Yilun Du,Pablo Duque,Mary Phuong,Alexandra Belias,Kunal Lad,Zeyu Liu,Tal Schuster,Karthik Duddu,Jieru Hu,Paige Kunkle,Matthew Watson,Jackson Tolins,Josh Smith,Denis Teplyashin,Garrett Bingham,Marvin Ritter,Marco Andreetto,Divya Pitta,Mohak Patel,Shashank Viswanadha,Trevor Strohman,Catalin Ionescu,Jincheng Luo,Yogesh Kalley,Jeremy Wiesner,Dan Deutsch,Derek Lockhart,Peter Choy,Rumen Dangovski,Chawin Sitawarin,Cat Graves,Tanya Lando,Joost van Amersfoort,Ndidi Elue,Zhouyuan Huo,Pooya Moradi,Jean Tarbouriech,Henryk Michalewski,Wenting Ye,Eunyoung Kim,Alex Druinsky,Florent Altché,Xinyi Chen,Artur Dwornik,Da-Cheng Juan,Rivka Moroshko,Horia Toma,Jarrod Kahn,Hai Qian,Maximilian Sieb,Irene Cai,Roman Goldenberg,Praneeth Netrapalli,Sindhu Raghuram,Yuan Gong,Lijie Fan,Evan Palmer,Yossi Matias,Valentin Gabeur,Shreya Pathak,Tom Ouyang,Don Metzler,Geoff Bacon,Srinivasan Venkatachary,Sridhar Thiagarajan,Alex Cullum,Eran Ofek,Vytenis Sakenas,Mohamed Hammad,Cesar Magalhaes,Mayank Daswani,Oscar Chang,Ashok Popat,Ruichao Li,Komal Jalan,Yanhan Hou,Josh Lipschultz,Antoine He,Wenhao Jia,Pier Giuseppe Sessa,Prateek Kolhar,William Wong,Sumeet Singh,Lukas Haas,Jay Whang,Hanna Klimczak-Plucińska,Georges Rotival,Grace Chung,Yiqing Hua,Anfal Siddiqui,Nicolas Serrano,Dongkai Chen,Billy Porter,Libin Bai,Keshav Shivam,Sho Arora,Partha Talukdar,Tom Cobley,Sangnie Bhardwaj,Evgeny Gladchenko,Simon Green,Kelvin Guu,Felix Fischer,Xiao Wu,Eric Wang,Achintya Singhal,Tatiana Matejovicova,James Martens,Hongji Li,Roma Patel,Elizabeth Kemp,Jiaqi Pan,Lily Wang,Blake JianHang Chen,Jean-Baptiste Alayrac,Navneet Potti,Erika Gemzer,Eugene Ie,Kay McKinney,Takaaki Saeki,Edward Chou,Pascal Lamblin,SQ Mah,Zach Fisher,Martin Chadwick,Jon Stritar,Obaid Sarvana,Andrew Hogue,Artem Shtefan,Hadi Hashemi,Yang Xu,Jindong Gu,Sharad Vikram,Chung-Ching Chang,Sabela Ramos,Logan Kilpatrick,Weijuan Xi,Jenny Brennan,Yinghao Sun,Abhishek Jindal,Ionel Gog,Dawn Chen,Felix Wu,Jason Lee,Sudhindra Kopalle,Srinadh Bhojanapalli,Oriol Vinyals,Natan Potikha,Burcu Karagol Ayan,Yuan Yuan,Michael Riley,Piotr Stanczyk,Sergey Kishchenko,Bing Wang,Dan Garrette,Antoine Yang,Vlad Feinberg,CJ Carey,Javad Azizi,Viral Shah,Erica Moreira,Chongyang Shi,Josh Feldman,Elizabeth Salesky,Thomas Lampe,Aneesh Pappu,Duhyeon Kim,Jonas Adler,Avi Caciularu,Brian Walker,Yunhan Xu,Yochai Blau,Dylan Scandinaro,Terry Huang,Sam El-Husseini,Abhishek Sinha,Lijie Ren,Taylor Tobin,Patrik Sundberg,Tim Sohn,Vikas Yadav,Mimi Ly,Emily Xue,Jing Xiong,Afzal Shama Soudagar,Sneha Mondal,Nikhil Khadke,Qingchun Ren,Ben Vargas,Stan Bileschi,Sarah Chakera,Cindy Wang,Boyu Wang,Yoni Halpern,Joe Jiang,Vikas Sindhwani,Petre Petrov,Pranavaraj Ponnuramu,Sanket Vaibhav Mehta,Yu Watanabe,Betty Chan,Matheus Wisniewski,Trang Pham,Jingwei Zhang,Conglong Li,Dario de Cesare,Art Khurshudov,Alex Vasiloff,Melissa Tan,Zoe Ashwood,Bobak Shahriari,Maryam Majzoubi,Garrett Tanzer,Olga Kozlova,Robin Alazard,James Lee-Thorp,Nguyet Minh Phu,Isaac Tian,Junwhan Ahn,Andy Crawford,Lauren Lax,Yuan,Shangguan,Iftekhar Naim,David Ross,Oleksandr Ferludin,Tongfei Guo,Andrea Banino,Hubert Soyer,Xiaoen Ju,Dominika Rogozińska,Ishaan Malhi,Marcella Valentine,Daniel Balle,Apoorv Kulshreshtha,Maciej Kula,Yiwen Song,Sophia Austin,John Schultz,Roy Hirsch,Arthur Douillard,Apoorv Reddy,Michael Fink,Summer Yue,Khyatti Gupta,Adam Zhang,Norman Rink,Daniel McDuff,Lei Meng,András György,Yasaman Razeghi,Ricky Liang,Kazuki Osawa,Aviel Atias,Matan Eyal,Tyrone Hill,Nikolai Grigorev,Zhengdong Wang,Nitish Kulkarni,Rachel Soh,Ivan Lobov,Zachary Charles,Sid Lall,Kazuma Hashimoto,Ido Kessler,Victor Gomes,Zelda Mariet,Danny Driess,Alessandro Agostini,Canfer Akbulut,Jingcao Hu,Marissa Ikonomidis,Emily Caveness,Kartik Audhkhasi,Saurabh Agrawal,Ioana Bica,Evan Senter,Jayaram Mudigonda,Kelly Chen,Jingchen Ye,Xuanhui Wang,James Svensson,Philipp Fränken,Josh Newlan,Li Lao,Eva Schnider,Sami Alabed,Joseph Kready,Jesse Emond,Afief Halumi,Tim Zaman,Chengxi Ye,Naina Raisinghani,Vilobh Meshram,Bo Chang,Ankit Singh Rawat,Axel Stjerngren,Sergey Levi,Rui Wang,Xiangzhu Long,Mitchelle Rasquinha,Steven Hand,Aditi Mavalankar,Lauren Agubuzu,Sudeshna Roy,Junquan Chen,Jarek Wilkiewicz,Hao Zhou,Michal Jastrzebski,Qiong Hu,Agustin Dal Lago,Ramya Sree Boppana,Wei-Jen Ko,Jennifer Prendki,Yao Su,Zhi Li,Eliza Rutherford,Girish Ramchandra Rao,Ramona Comanescu,Adrià Puigdomènech,Qihang Chen,Dessie Petrova,Christine Chan,Vedrana Milutinovic,Felipe Tiengo Ferreira,Chin-Yi Cheng,Ming Zhang,Tapomay Dey,Sherry Yang,Ramesh Sampath,Quoc Le,Howard Zhou,Chu-Cheng Lin,Hoi Lam,Christine Kaeser-Chen,Kai Hui,Dean Hirsch,Tom Eccles,Basil Mustafa,Shruti Rijhwani,Morgane Rivière,Yuanzhong Xu,Junjie Wang,Xinyang Geng,Xiance Si,Arjun Khare,Cheolmin Kim,Vahab Mirrokni,Kamyu Lee,Khuslen Baatarsukh,Nathaniel Braun,Lisa Wang,Pallavi LV,Richard Tanburn,Yuvein,Zhu,Fangda Li,Setareh Ariafar,Dan Goldberg,Ken Burke,Daniil Mirylenka,Meiqi Guo,Olaf Ronneberger,Hadas Natalie Vogel,Liqun Cheng,Nishita Shetty,Johnson Jia,Thomas Jimma,Corey Fry,Ted Xiao,Martin Sundermeyer,Ryan Burnell,Yannis Assael,Mario Pinto,JD Chen,Rohit Sathyanarayana,Donghyun Cho,Jing Lu,Rishabh Agarwal,Sugato Basu,Lucas Gonzalez,Dhruv Shah,Meng Wei,Dre Mahaarachchi,Rohan Agrawal,Tero Rissa,Yani Donchev,Ramiro Leal-Cavazos,Adrian Hutter,Markus Mircea,Alon Jacovi,Faruk Ahmed,Jiageng Zhang,Shuguang Hu,Bo-Juen Chen,Jonni Kanerva,Guillaume Desjardins,Andrew Lee,Nikos Parotsidis,Asier Mujika,Tobias Weyand,Jasper Snoek,Jo Chick,Kai Chen,Paul Chang,Ethan Mahintorabi,Zi Wang,Tolly Powell,Orgad Keller,Abhirut Gupta,Claire Sha,Kanav Garg,Nicolas Heess,Ágoston Weisz,Cassidy Hardin,Bartek Wydrowski,Ben Coleman,Karina Zainullina,Pankaj Joshi,Alessandro Epasto,Terry Spitz,Binbin Xiong,Kai Zhao,Arseniy Klimovskiy,Ivy Zheng,Johan Ferret,Itay Yona,Waleed Khawaja,Jean-Baptiste Lespiau,Maxim Krikun,Siamak Shakeri,Timothee Cour,Bonnie Li,Igor Krivokon,Dan Suh,Alex Hofer,Jad Al Abdallah,Nikita Putikhin,Oscar Akerlund,Silvio Lattanzi,Anurag Kumar,Shane Settle,Himanshu Srivastava,Folawiyo Campbell-Ajala,Edouard Rosseel,Mihai Dorin Istin,Nishanth Dikkala,Anand Rao,Nick Young,Kate Lin,Dhruva Bhaswar,Yiming Wang,Jaume Sanchez Elias,Kritika Muralidharan,James Keeling,Dayou Du,Siddharth Gopal,Gregory Dibb,Charles Blundell,Manolis Delakis,Jacky Liang,Marco Tulio Ribeiro,Georgi Karadzhov,Guillermo Garrido,Ankur Bapna,Jiawei Cao,Adam Sadovsky,Pouya Tafti,Arthur Guez,Coline Devin,Yixian Di,Jinwei Xing,Chuqiao,Xu,Hanzhao Lin,Chun-Te Chu,Sameera Ponda,Wesley Helmholz,Fan Yang,Yue Gao,Sara Javanmardi,Wael Farhan,Alex Ramirez,Ricardo Figueira,Khe Chai Sim,Yuval Bahat,Ashwin Vaswani,Liangzhe Yuan,Gufeng Zhang,Leland Rechis,Hanjun Dai,Tayo Oguntebi,Alexandra Cordell,Eugénie Rives,Kaan Tekelioglu,Naveen Kumar,Bing Zhang,Aurick Zhou,Nikolay Savinov,Andrew Leach,Alex Tudor,Sanjay Ganapathy,Yanyan Zheng,Mirko Rossini,Vera Axelrod,Arnaud Autef,Yukun Zhu,Zheng Zheng,Mingda Zhang,Baochen Sun,Jie Ren,Nenad Tomasev,Nithish Kannan,Amer Sinha,Charles Chen,Louis O'Bryan,Alex Pak,Aditya Kusupati,Weel Yang,Deepak Ramachandran,Patrick Griffin,Seokhwan Kim,Philipp Neubeck,Craig Schiff,Tammo Spalink,Mingyang Ling,Arun Nair,Ga-Young Joung,Linda Deng,Avishkar Bhoopchand,Lora Aroyo,Tom Duerig,Jordan Griffith,Gabe Barth-Maron,Jake Ades,Alex Haig,Ankur Taly,Yunting Song,Paul Michel,Dave Orr,Dean Weesner,Corentin Tallec,Carrie Grimes Bostock,Paul Niemczyk,Andy Twigg,Mudit Verma,Rohith Vallu,Henry Wang,Marco Gelmi,Kiranbir Sodhia,Aleksandr Chuklin,Omer Goldman,Jasmine George,Liang Bai,Kelvin Zhang,Petar Sirkovic,Efrat Nehoran,Golan Pundak,Jiaqi Mu,Alice Chen,Alex Greve,Paulo Zacchello,David Amos,Heming Ge,Eric Noland,Colton Bishop,Jeffrey Dudek,Youhei Namiki,Elena Buchatskaya,Jing Li,Dorsa Sadigh,Masha Samsikova,Dan Malkin,Damien Vincent,Robert David,Rob Willoughby,Phoenix Meadowlark,Shawn Gao,Yan Li,Raj Apte,Amit Jhindal,Stein Xudong Lin,Alex Polozov,Zhicheng Wang,Tomas Mery,Anirudh GP,Varun Yerram,Sage Stevens,Tianqi Liu,Noah Fiedel,Charles Sutton,Matthew Johnson,Xiaodan Song,Kate Baumli,Nir Shabat,Muqthar Mohammad,Hao Liu,Marco Selvi,Yichao Zhou,Mehdi Hafezi Manshadi,Chu-ling Ko,Anthony Chen,Michael Bendersky,Jorge Gonzalez Mendez,Nisarg Kothari,Amir Zandieh,Yiling Huang,Daniel Andor,Ellie Pavlick,Idan Brusilovsky,Jitendra Harlalka,Sally Goldman,Andrew Lampinen,Guowang Li,Asahi Ushio,Somit Gupta,Lei Zhang,Chuyuan Kelly Fu,Madhavi Sewak,Timo Denk,Jed Borovik,Brendan Jou,Avital Zipori,Prateek Jain,Junwen Bai,Thang Luong,Jonathan Tompson,Alice Li,Li Liu,George Powell,Jiajun Shen,Alex Feng,Grishma Chole,Da Yu,Yinlam Chow,Tongxin Yin,Eric Malmi,Kefan Xiao,Yash Pande,Shachi Paul,Niccolò Dal Santo,Adil Dostmohamed,Sergio Guadarrama,Aaron Phillips,Thanumalayan Sankaranarayana Pillai,Gal Yona,Amin Ghafouri,Preethi Lahoti,Benjamin Lee,Dhruv Madeka,Eren Sezener,Simon Tokumine,Adrian Collister,Nicola De Cao,Richard Shin,Uday Kalra,Parker Beak,Emily Nottage,Ryo Nakashima,Ivan Jurin,Vikash Sehwag,Meenu Gaba,Junhao Zeng,Kevin R. McKee,Fernando Pereira,Tamar Yakar,Amayika Panda,Arka Dhar,Peilin Zhong,Daniel Sohn,Mark Brand,Lars Lowe Sjoesund,Viral Carpenter,Sharon Lin,Shantanu Thakoor,Marcus Wainwright,Ashwin Chaugule,Pranesh Srinivasan,Muye Zhu,Bernett Orlando,Jack Weber,Ayzaan Wahid,Gilles Baechler,Apurv Suman,Jovana Mitrović,Gabe Taubman,Honglin Yu,Helen King,Josh Dillon,Cathy Yip,Dhriti Varma,Tomas Izo,Levent Bolelli,Borja De Balle Pigem,Julia Di Trapani,Fotis Iliopoulos,Adam Paszke,Nishant Ranka,Joe Zou,Francesco Pongetti,Jed McGiffin,Alex Siegman,Rich Galt,Ross Hemsley,Goran Žužić,Victor Carbune,Tao Li,Myle Ott,Félix de Chaumont Quitry,David Vilar Torres,Yuri Chervonyi,Tomy Tsai,Prem Eruvbetine,Samuel Yang,Matthew Denton,Jake Walker,Slavica Andačić,Idan Heimlich Shtacher,Vittal Premachandran,Harshal Tushar Lehri,Cip Baetu,Damion Yates,Lampros Lamprou,Mariko Iinuma,Ioana Mihailescu,Ben Albrecht,Shachi Dave,Susie Sargsyan,Bryan Perozzi,Lucas Manning,Chiyuan Zhang,Denis Vnukov,Igor Mordatch,Raia Hadsell Wolfgang Macherey,Ryan Kappedal,Jim Stephan,Aditya Tripathi,Klaus Macherey,Jun Qian,Abhishek Bhowmick,Shekoofeh Azizi,Rémi Leblond,Shiva Mohan Reddy Garlapati,Timothy Knight,Matthew Wiethoff,Wei-Chih Hung,Anelia Angelova,Georgios Evangelopoulos,Pawel Janus,Dimitris Paparas,Matthew Rahtz,Ken Caluwaerts,Vivek Sampathkumar,Daniel Jarrett,Shadi Noghabi,Antoine Miech,Chak Yeung,Geoff Clark,Henry Prior,Fei Zheng,Jean Pouget-Abadie,Indro Bhattacharya,Kalpesh Krishna,Will Bishop,Zhe Yuan,Yunxiao Deng,Ashutosh Sathe,Kacper Krasowiak,Ciprian Chelba,Cho-Jui Hsieh,Kiran Vodrahalli,Buhuang Liu,Thomas Köppe,Amr Khalifa,Lubo Litchev,Pichi Charoenpanit,Reed Roberts,Sachin Yadav,Yasumasa Onoe,Desi Ivanov,Megha Mohabey,Vighnesh Birodkar,Nemanja Rakićević,Pierre Sermanet,Vaibhav Mehta,Krishan Subudhi,Travis Choma,Will Ng,Luheng He,Kathie Wang,Tasos Kementsietsidis,Shane Gu,Mansi Gupta,Andrew Nystrom,Mehran Kazemi,Timothy Chung,Nacho Cano,Nikhil Dhawan,Yufei Wang,Jiawei Xia,Trevor Yacovone,Eric Jia,Mingqing Chen,Simeon Ivanov,Ashrith Sheshan,Sid Dalmia,Paweł Stradomski,Pengcheng Yin,Salem Haykal,Congchao Wang,Dennis Duan,Neslihan Bulut,Greg Kochanski,Liam MacDermed,Namrata Godbole,Shitao Weng,Jingjing Chen,Rachana Fellinger,Ramin Mehran,Daniel Suo,Hisham Husain,Tong He,Kaushal Patel,Joshua Howland,Randall Parker,Kelvin Nguyen,Sharath Maddineni,Chris Rawles,Mina Khan,Shlomi Cohen-Ganor,Amol Mandhane,Xinyi Wu,Chenkai Kuang,Iulia Comşa,Ramya Ganeshan,Hanie Sedghi,Adam Bloniarz,Nuo Wang Pierse,Anton Briukhov,Petr Mitrichev,Anita Gergely,Serena Zhan,Allan Zhou,Nikita Saxena,Eva Lu,Josef Dean,Ashish Gupta,Nicolas Perez-Nieves,Renjie Wu,Cory McLean,Wei Liang,Disha Jindal,Anton Tsitsulin,Wenhao Yu,Kaiz Alarakyia,Tom Schaul,Piyush Patil,Peter Sung,Elijah Peake,Hongkun Yu,Feryal Behbahani,JD Co-Reyes,Alan Ansell,Sean Sun,Clara Barbu,Jonathan Lee,Seb Noury,James Allingham,Bilal Piot,Mohit Sharma,Christopher Yew,Ivan Korotkov,Bibo Xu,Demetra Brady,Goran Petrovic,Shibl Mourad,Claire Cui,Aditya Gupta,Parker Schuh,Saarthak Khanna,Anna Goldie,Abhinav Arora,Vadim Zubov,Amy Stuart,Mark Epstein,Yun Zhu,Jianqiao Liu,Yury Stuken,Ziyue Wang,Karolis Misiunas,Dee Guo,Ashleah Gill,Ale Hartman,Zaid Nabulsi,Aurko Roy,Aleksandra Faust,Jason Riesa,Ben Withbroe,Mengchao Wang,Marco Tagliasacchi,Andreea Marzoca,James Noraky,Serge Toropov,Malika Mehrotra,Bahram Raad,Sanja Deur,Steve Xu,Marianne Monteiro,Zhongru Wu,Yi Luan,Sam Ritter,Nick Li,Håvard Garnes,Yanzhang He,Martin Zlocha,Jifan Zhu,Matteo Hessel,Will Wu,Spandana Raj Babbula,Chizu Kawamoto,Yuanzhen Li,Mehadi Hassen,Yan Wang,Brian Wieder,James Freedman,Yin Zhang,Xinyi Bai,Tianli Yu,David Reitter,XiangHai Sheng,Mateo Wirth,Aditya Kini,Dima Damen,Mingcen Gao,Rachel Hornung,Michael Voznesensky,Brian Roark,Adhi Kuncoro,Yuxiang Zhou,Rushin Shah,Anthony Brohan,Kuangyuan Chen,James Wendt,David Rim,Paul Kishan Rubenstein,Jonathan Halcrow,Michelle Liu,Ty Geri,Yunhsuan Sung,Jane Shapiro,Shaan Bijwadia,Chris Duvarney,Christina Sorokin,Paul Natsev,Reeve Ingle,Pramod Gupta,Young Maeng,Ndaba Ndebele,Kexin Zhu,Valentin Anklin,Katherine Lee,Yuan Liu,Yaroslav Akulov,Shaleen Gupta,Guolong Su,Flavien Prost,Tianlin Liu,Vitaly Kovalev,Pol Moreno,Martin Scholz,Sam Redmond,Zongwei Zhou,Alex Castro-Ros,André Susano Pinto,Dia Kharrat,Michal Yarom,Rachel Saputro,Jannis Bulian,Ben Caine,Ji Liu,Abbas Abdolmaleki,Shariq Iqbal,Tautvydas Misiunas,Mikhail Sirotenko,Shefali Garg,Guy Bensky,Huan Gui,Xuezhi Wang,Raphael Koster,Mike Bernico,Da Huang,Romal Thoppilan,Trevor Cohn,Ben Golan,Wenlei Zhou,Andrew Rosenberg,Markus Freitag,Tynan Gangwani,Vincent Tsang,Anand Shukla,Xiaoqi Ren,Minh Giang,Chi Zou,Andre Elisseeff,Charline Le Lan,Dheeru Dua,Shuba Lall,Pranav Shyam,Frankie Garcia,Sarah Nguyen,Michael Guzman,AJ Maschinot,Marcello Maggioni,Ming-Wei Chang,Karol Gregor,Lotte Weerts,Kumaran Venkatesan,Bogdan Damoc,Leon Liu,Jan Wassenberg,Lewis Ho,Becca Roelofs,Majid Hadian,François-Xavier Aubet,Yu Liang,Sami Lachgar,Danny Karmon,Yong Cheng,Amelio Vázquez-Reina,Angie Chen,Zhuyun Dai,Andy Brock,Shubham Agrawal,Chenxi Pang,Peter Garst,Mariella Sanchez-Vargas,Ivor Rendulic,Aditya Ayyar,Andrija Ražnatović,Olivia Ma,Roopali Vij,Neha Sharma,Ashwin Balakrishna,Bingyuan Liu,Ian Mackinnon,Sorin Baltateanu,Petra Poklukar,Gabriel Ibagon,Colin Ji,Hongyang Jiao,Isaac Noble,Wojciech Stokowiec,Zhihao Li,Jeff Dean,David Lindner,Mark Omernick,Kristen Chiafullo,Mason Dimarco,Vitor Rodrigues,Vittorio Selo,Garrett Honke,Xintian,Wu,Wei He,Adam Hillier,Anhad Mohananey,Vihari Piratla,Chang Ye,Chase Malik,Sebastian Riedel,Samuel Albanie,Zi Yang,Kenny Vassigh,Maria Bauza,Sheng Li,Yiqing Tao,Nevan Wichers,Andrii Maksai,Abe Ittycheriah,Ross Mcilroy,Bryan Seybold,Noah Goodman,Romina Datta,Steven M. Hernandez,Tian Shi,Yony Kochinski,Anna Bulanova,Ken Franko,Mikita Sazanovich,Nicholas FitzGerald,Praneeth Kacham,Shubha Srinivas Raghvendra,Vincent Hellendoorn,Alexander Grushetsky,Julian Salazar,Angeliki Lazaridou,Jason Chang,Jan-Thorsten Peter,Sushant Kafle,Yann Dauphin,Abhishek Rao,Filippo Graziano,Izhak Shafran,Yuguo Liao,Tianli Ding,Geng Yan,Grace Chu,Zhao Fu,Vincent Roulet,Gabriel Rasskin,Duncan Williams,Shahar Drath,Alex Mossin,Raphael Hoffmann,Jordi Orbay,Francesco Bertolini,Hila Sheftel,Justin Chiu,Siyang Xue,Yuheng Kuang,Ferjad Naeem,Swaroop Nath,Nana Nti,Phil Culliton,Kashyap Krishnakumar,Michael Isard,Pei Sun,Ayan Chakrabarti,Nathan Clement,Regev Cohen,Arissa Wongpanich,GS Oh,Ashwin Murthy,Hao Zheng,Jessica Hamrick,Oskar Bunyan,Suhas Ganesh,Nitish Gupta,Roy Frostig,John Wieting,Yury Malkov,Pierre Marcenac,Zhixin,Lai,Xiaodan Tang,Mohammad Saleh,Fedir Zubach,Chinmay Kulkarni,Huanjie Zhou,Vicky Zayats,Nan Ding,Anshuman Tripathi,Arijit Pramanik,Patrik Zochbauer,Harish Ganapathy,Vedant Misra,Zach Behrman,Hugo Vallet,Mingyang Zhang,Mukund Sridhar,Ye Jin,Mohammad Babaeizadeh,Siim Põder,Megha Goel,Divya Jain,Tajwar Nasir,Shubham Mittal,Tim Dozat,Diego Ardila,Aliaksei Severyn,Fabio Pardo,Sammy Jerome,Siyang Qin,Louis Rouillard,Amir Yazdanbakhsh,Zizhao Zhang,Shivani Agrawal,Kaushik Shivakumar,Caden Lu,Praveen Kallakuri,Rachita Chhaparia,Kanishka Rao,Charles Kwong,Asya Fadeeva,Shitij Nigam,Yan Virin,Yuan Zhang,Balaji Venkatraman,Beliz Gunel,Marc Wilson,Huiyu Wang,Abhinav Gupta,Xiaowei Xu,Adrien Ali Taïga,Kareem Mohamed,Doug Fritz,Daniel Rodriguez,Zoubin Ghahramani,Harry Askham,Lior Belenki,James Zhao,Rahul Gupta,Krzysztof Jastrzębski,Takahiro Kosakai,Kaan Katircioglu,Jon Schneider,Rina Panigrahy,Konstantinos Bousmalis,Peter Grabowski,Prajit Ramachandran,Chaitra Hegde,Mihaela Rosca,Angelo Scorza Scarpati,Kyriakos Axiotis,Ying Xu,Zach Gleicher,Assaf Hurwitz Michaely,Mandar Sharma,Sanil Jain,Christoph Hirnschall,Tal Marian,Xuhui Jia,Kevin Mather,Kilol Gupta,Linhai Qiu,Nigamaa Nayakanti,Lucian Ionita,Steven Zheng,Lucia Loher,Kurt Shuster,Igor Petrovski,Roshan Sharma,Rahma Chaabouni,Angel Yeh,James An,Arushi Gupta,Steven Schwarcz,Seher Ellis,Sam Conway-Rahman,Javier Snaider,Alex Zhai,James Atwood,Daniel Golovin,Liqian Peng,Te I,Vivian Xia,Salvatore Scellato,Mahan Malihi,Arthur Bražinskas,Vlad-Doru Ion,Younghoon Jun,James Swirhun,Soroosh Mariooryad,Jiao Sun,Steve Chien,Rey Coaguila,Ariel Brand,Yi Gao,Tom Kwiatkowski,Roee Aharoni,Cheng-Chun Lee,Mislav Žanić,Yichi Zhang,Dan Ethier,Vitaly Nikolaev,Pranav Nair,Yoav Ben Shalom,Hen Fitoussi,Jai Gupta,Hongbin Liu,Dee Cattle,Tolga Bolukbasi,Ben Murdoch,Fantine Huot,Yin Li,Chris Hahn*

Main category: cs.CL

TL;DR: 介绍Gemini 2.X模型家族，包括Gemini 2.5 Pro、2.5 Flash、2.0 Flash和Flash - Lite，各有优势，覆盖能力与成本的帕累托前沿。


<details>
  <summary>Details</summary>
Motivation: 展示Gemini 2.X模型家族各成员的能力和特点，为用户提供更多选择以解决复杂代理问题。

Method: 直接介绍各模型的能力，如Gemini 2.5 Pro在编码、推理、多模态理解上的表现等。

Result: Gemini 2.5 Pro在前沿编码和推理基准测试中达到SoTA性能，能处理3小时视频；Gemini 2.5 Flash推理能力出色且计算和延迟要求低；Gemini 2.0 Flash和Flash - Lite低延迟低成本高性能。

Conclusion: Gemini 2.X模型家族覆盖了模型能力与成本的帕累托前沿，有助于用户探索复杂代理问题解决的边界。

Abstract: In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and
Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite
models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA
performance on frontier coding and reasoning benchmarks. In addition to its
incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that
excels at multimodal understanding and it is now able to process up to 3 hours
of video content. Its unique combination of long context, multimodal and
reasoning capabilities can be combined to unlock new agentic workflows. Gemini
2.5 Flash provides excellent reasoning abilities at a fraction of the compute
and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high
performance at low latency and cost. Taken together, the Gemini 2.X model
generation spans the full Pareto frontier of model capability vs cost, allowing
users to explore the boundaries of what is possible with complex agentic
problem solving.

</details>


### [165] [Discrete Diffusion Models for Language Generation](https://arxiv.org/abs/2507.07050)
*Ashen Weligalle*

Main category: cs.CL

TL;DR: 研究离散扩散模型用于自然语言生成的可行性与性能，对比D3PM和AR模型，分析生成质量与效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在连续数据领域成功，但应用于离散数据（如自然语言）存在挑战，因此研究其在自然语言生成中的可行性和性能。

Method: 评估离散去噪扩散概率模型（D3PM），与传统自回归（AR）语言模型对比，使用BPT、NLL、PPL和批处理速度评估生成性能，在一致条件下进行评估。

Result: 最佳D3PM模型BPT为5.72，均值8.05；AR模型压缩性能更好，平均BPT为4.59，但D3PM处理速度更高，可达3.97批次/秒。

Conclusion: 研究详细分析了基于扩散的模型和自回归模型的权衡，强调了扩散模型在离散数据中的前景和局限性，支持未来非自回归语言生成的研究。

Abstract: Diffusion models have emerged as a powerful class of generative models,
achieving state-of-the-art results in continuous data domains such as image and
video generation. Their core mechanism involves a forward diffusion process
that gradually transforms structured data into a Gaussian-like distribution,
followed by a learned reverse process to reconstruct the data. While successful
in continuous modalities, applying this framework to discrete data-particularly
natural language-remains challenging due to token dependency complexities and
the lack of a defined generation order.This thesis investigates the feasibility
and performance of discrete diffusion models for natural language generation.
Specifically, we evaluate the Discrete Denoising Diffusion Probabilistic Model
(D3PM) and compare it with traditional autoregressive (AR) language models. To
assess generative performance, we use Bits Per Token (BPT), Negative
Log-Likelihood (NLL), Perplexity (PPL), and Batch Processing Speed.
  Results show the best-performing D3PM model achieves a BPT of 5.72, with a
mean of 8.05. The AR model outperforms in compression with a lower mean BPT of
4.59, but D3PM achieves higher processing speed, reaching up to 3.97 batches
per sec., indicating potential for parallel generation.All evaluations were
conducted under consistent conditions-generating 100,000 tokens per model with
a fixed batch size of four-for fair comparison. This research presents a
detailed analysis of diffusion-based vs. autoregressive models, highlighting
trade-offs in generative quality and efficiency. Findings emphasize both the
promise and limitations of diffusion models for discrete data, supporting
future work in non-autoregressive language generation.

</details>


### [166] [Humans overrely on overconfident language models, across languages](https://arxiv.org/abs/2507.06306)
*Neil Rathi,Dan Jurafsky,Kaitlyn Zhou*

Main category: cs.CL

TL;DR: 研究多语言环境下大语言模型（LLMs）语言校准、过度自信和过度依赖的风险，发现各语言均有高过度依赖风险，强调多语言校准挑战和语境化模型安全评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs全球部署，需校准其跨语言响应以准确传达不确定性和局限性，且不同语言对认知标记的使用和理解不同，要评估其在全球环境中的安全性。

Method: 分析LLM生成的认知标记分布，测量不同语言下人类的依赖率。

Result: 各语言均有高过度依赖风险，LLMs跨语言过度自信但也对语言差异敏感，不同语言的依赖行为有差异。

Conclusion: 强调多语言语言校准的挑战，以及文化和语言语境化模型安全评估的重要性。

Abstract: As large language models (LLMs) are deployed globally, it is crucial that
their responses are calibrated across languages to accurately convey
uncertainty and limitations. Previous work has shown that LLMs are
linguistically overconfident in English, leading users to overrely on confident
generations. However, the usage and interpretation of epistemic markers (e.g.,
'It's definitely,' 'I think') can differ sharply across languages. Here, we
study the risks of multilingual linguistic (mis)calibration, overconfidence,
and overreliance across five languages to evaluate the safety of LLMs in a
global context.
  We find that overreliance risks are high across all languages. We first
analyze the distribution of LLM-generated epistemic markers, and observe that
while LLMs are cross-linguistically overconfident, they are also sensitive to
documented linguistic variation. For example, models generate the most markers
of uncertainty in Japanese and the most markers of certainty in German and
Mandarin. We then measure human reliance rates across languages, finding that
while users strongly rely on confident LLM generations in all languages,
reliance behaviors differ cross-linguistically: for example, users rely
significantly more on expressions of uncertainty in Japanese than in English.
Taken together, these results indicate high risk of reliance on overconfident
model generations across languages. Our findings highlight the challenges of
multilingual linguistic calibration and stress the importance of culturally and
linguistically contextualized model safety evaluations.

</details>


### [167] [Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings](https://arxiv.org/abs/2507.06506)
*Russell Taylor,Benjamin Herbert,Michael Sana*

Main category: cs.CL

TL;DR: 研究提出结合大语言模型与文字游戏生成技术的方法将英文双关语翻译成法语，在比赛中取得好成绩，推动翻译研究与计算语言学发展。


<details>
  <summary>Details</summary>
Motivation: 解决跨语言翻译文字游戏的难题，捕捉源文本文字游戏的语言创造力和幽默。

Method: 采用三阶段方法，先基于新对比学习数据集用前沿大语言模型建立基线，再实施结合音义嵌入的引导思维链管道，最后用多智能体生成 - 判别框架评估和再生双关语。

Result: 在CLEF JOKER 2025任务2比赛中，最佳运行结果获第一和第二名，由法语母语专家手动评估。

Conclusion: 研究通过实施语言学方法解决了翻译研究与计算语言学之间的差距，提升对语言模型处理语义歧义、语音相似性及文化语言意识的理解。

Abstract: Translating wordplay across languages presents unique challenges that have
long confounded both professional human translators and machine translation
systems. This research proposes a novel approach for translating puns from
English to French by combining state-of-the-art large language models with
specialized techniques for wordplay generation.
  Our methodology employs a three-stage approach. First, we establish a
baseline using multiple frontier large language models with feedback based on a
new contrastive learning dataset. Second, we implement a guided
chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we
implement a multi-agent generator-discriminator framework for evaluating and
regenerating puns with feedback.
  Moving beyond the limitations of literal translation, our methodology's
primary objective is to capture the linguistic creativity and humor of the
source text wordplay, rather than simply duplicating its vocabulary. Our best
runs earned first and second place in the CLEF JOKER 2025 Task 2 competition
where they were evaluated manually by expert native French speakers.
  This research addresses a gap between translation studies and computational
linguistics by implementing linguistically-informed techniques for wordplay
translation, advancing our understanding of how language models can be
leveraged to handle the complex interplay between semantic ambiguity, phonetic
similarity, and the implicit cultural and linguistic awareness needed for
successful humor.

</details>


### [168] [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](https://arxiv.org/abs/2507.06528)
*Huisheng Wang,Zhuoshi Pan,Hangjing Zhang,Mingxiao Liu,Hanqing Gao,H. Vicky Zhao*

Main category: cs.CL

TL;DR: 提出InvestAlign框架构建SFT数据集，用其生成数据训练LLMs收敛更快，开发的InvestAgent更贴合真实用户数据，代码公开。


<details>
  <summary>Details</summary>
Motivation: 解决行为金融中让大语言模型与投资者决策过程对齐时监督微调缺乏真实用户数据的问题。

Method: 提出InvestAlign框架，利用简单最优投资问题理论解构建高质量SFT数据集；开发用InvestAlign微调的LLM代理InvestAgent。

Result: 用InvestAlign生成数据训练LLMs参数收敛更快；InvestAgent在简单和复杂投资问题上比微调前模型更贴合真实用户数据。

Conclusion: InvestAlign是有潜力解决复杂最优投资问题、使LLMs与投资者决策过程对齐的方法。

Abstract: Aligning Large Language Models (LLMs) with investor decision-making processes
under herd behavior is a critical challenge in behavioral finance, which
grapples with a fundamental limitation: the scarcity of real-user data needed
for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM
outputs and human behavioral patterns, its reliance on massive authentic data
imposes substantial collection costs and privacy risks. We propose InvestAlign,
a novel framework that constructs high-quality SFT datasets by leveraging
theoretical solutions to similar and simple optimal investment problems rather
than complex scenarios. Our theoretical analysis demonstrates that training
LLMs with InvestAlign-generated data achieves faster parameter convergence than
using real-user data, suggesting superior learning efficiency. Furthermore, we
develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which
demonstrates significantly closer alignment to real-user data than pre-SFT
models in both simple and complex investment problems. This highlights our
proposed InvestAlign as a promising approach with the potential to address
complex optimal investment problems and align LLMs with investor
decision-making processes under herd behavior. Our code is publicly available
at https://github.com/thu-social-network-research-group/InvestAlign.

</details>


### [169] [Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review](https://arxiv.org/abs/2507.06623)
*James Stewart-Evans,Emma Wilson,Tessa Langley,Andrew Prayle,Angela Hands,Karen Exley,Jo Leonardi-Bee*

Main category: cs.CL

TL;DR: 研究用Claude 3.5 Sonnet结合评审协议从案例研究范围界定审查的证据源中提取数据，评估提取方法性能，指出需更稳健评估及建议研究人员评估报告LLM性能。


<details>
  <summary>Details</summary>
Motivation: 评审的数据提取阶段资源密集，为加快数据提取，研究使用在线大语言模型和评审协议进行数据提取。

Method: 使用Claude 3.5 Sonnet，采用基于评审协议的两种方法从10个证据源提取数据，并审查提取的数据。

Result: 提取简单明确的引用细节时准确率高，提取复杂主观数据项时准确率低；两种方法精度>90%，召回率<25%，F1分数<40%；LLM反馈认为基线提取准确，对部分数据项建议修改；处理含故意错误的数据集时，错误检测率低。

Conclusion: 基于评审协议的方法需更稳健的性能评估，研究人员使用LLM进行数据提取或审查时应评估并报告其性能，LLM反馈有助于协议调整和未来协议起草。

Abstract: The data extraction stages of reviews are resource-intensive, and researchers
may seek to expediate data extraction using online (large language models) LLMs
and review protocols. Claude 3.5 Sonnet was used to trial two approaches that
used a review protocol to prompt data extraction from 10 evidence sources
included in a case study scoping review. A protocol-based approach was also
used to review extracted data. Limited performance evaluation was undertaken
which found high accuracy for the two extraction approaches (83.3% and 100%)
when extracting simple, well-defined citation details; accuracy was lower (9.6%
and 15.8%) when extracting more complex, subjective data items. Considering all
data items, both approaches had precision >90% but low recall (<25%) and F1
scores (<40%). The context of a complex scoping review, open response types and
methodological approach likely impacted performance due to missed and
misattributed data. LLM feedback considered the baseline extraction accurate
and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of
38 (21.1%) to key findings data items were considered to potentially add value.
However, when repeating the process with a dataset featuring deliberate errors,
only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for
expediency require more robust performance evaluation across a range of LLMs
and review contexts with comparison to conventional prompt engineering
approaches. We recommend researchers evaluate and report LLM performance if
using them similarly to conduct data extraction or review extracted data. LLM
feedback contributed to protocol adaptation and may assist future review
protocol drafting.

</details>


### [170] [Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models](https://arxiv.org/abs/2507.06658)
*Gennadii Iakovlev*

Main category: cs.CL

TL;DR: 通过人工智能进行行为者和主题检测引入新的精英极化衡量方法，分析英、匈、意数据，结果可按政党和季度汇总，指数具良好表面效度。


<details>
  <summary>Details</summary>
Motivation: 引入新的衡量精英极化的方法，为欧盟范围内的精英极化时间序列数据集奠定基础。

Method: 利用人工智能进行行为者和主题检测，识别议会演讲中政治家相互提及情况，评估评价背后的情感温度。

Result: 得到可按政党和季度汇总的结果，指数对选举活动、危机、政党权力更迭等事件有反应。

Conclusion: 所提出的方法可行，构建的指数具有良好表面效度，为后续欧盟范围数据集建设奠定基础。

Abstract: This project introduces a new measure of elite polarization via actor and
subject detection using artificial intelligence. I identify when politicians
mention one another in parliamentary speeches, note who is speaking and who is
being addressed, and assess the emotional temperature behind these evaluations.
This maps how elites evaluate their various out-parties, allowing us to create
an index of mutual out-party hostility, that is, elite polarization. While I
analyzed polarization data over the past four decades for the UK, and two
decades for Hungary and Italy, my approach lays the groundwork for a
twenty-year, EU-wide time-series dataset on elite polarization. I obtain the
results that can be aggregated by party and quarter. The resulting index
demonstrates a good face validity: it reacts to events such as electoral
campaigns, country- and party-level crises, and to parties losing and assuming
power.

</details>


### [171] [KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution](https://arxiv.org/abs/2507.06753)
*Ye Kyaw Thu,Thura Aung,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

TL;DR: 本文首次将KAConvText应用于句子分类，研究不同嵌入配置，对比不同基线模型和分类头，KAConvText - MLP在各任务表现最佳。


<details>
  <summary>Details</summary>
Motivation: 将KAConvText应用于句子分类，解决不平衡二分类仇恨言论检测、平衡多分类新闻分类和不平衡多分类民族语言识别三个任务。

Method: 研究不同嵌入配置，对比随机和fastText嵌入在静态和微调设置下的表现，使用不同基线模型（标准CNN和CNN - KAN），研究不同分类头（MLP和KAN）。

Result: KAConvText - MLP在仇恨言论检测、新闻分类和语言识别任务中的准确率分别达到91.23%、92.66%和99.82%。

Conclusion: KAConvText - MLP配合微调的fastText嵌入在句子分类任务中表现最佳。

Abstract: This paper presents the first application of Kolmogorov-Arnold Convolution
for Text (KAConvText) in sentence classification, addressing three tasks:
imbalanced binary hate speech detection, balanced multiclass news
classification, and imbalanced multiclass ethnic language identification. We
investigate various embedding configurations, comparing random to fastText
embeddings in both static and fine-tuned settings, with embedding dimensions of
100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs
and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we
investigated KAConvText with different classification heads - MLP and KAN,
where using KAN head supports enhanced interpretability. Results show that
KAConvText-MLP with fine-tuned fastText embeddings achieves the best
performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection,
92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82%
accuracy (F1-score = 0.9982) for language identification.

</details>


### [172] [Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications](https://arxiv.org/abs/2507.06795)
*Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CL

TL;DR: 研究验证基于DACP的方法在不同基础模型和服务领域的有效性，应用DACP的小语言模型在目标领域性能提升且保留通用能力，为企业级部署提供高效可扩展方案。


<details>
  <summary>Details</summary>
Motivation: 开源大语言模型部署维护要求高，小语言模型有性能局限，DACP在商业应用中的效用有待研究。

Method: 在不同基础模型和服务领域应用基于DACP的方法，并进行大量实验和实际评估。

Result: 应用DACP的小语言模型在目标领域性能大幅提升，同时保留通用能力。

Conclusion: DACP为企业级部署提供了经济高效且可扩展的解决方案。

Abstract: The emergence of open-source large language models (LLMs) has expanded
opportunities for enterprise applications; however, many organizations still
lack the infrastructure to deploy and maintain large-scale models. As a result,
small LLMs (sLLMs) have become a practical alternative, despite their inherent
performance limitations. While Domain Adaptive Continual Pretraining (DACP) has
been previously explored as a method for domain adaptation, its utility in
commercial applications remains under-examined. In this study, we validate the
effectiveness of applying a DACP-based recipe across diverse foundation models
and service domains. Through extensive experiments and real-world evaluations,
we demonstrate that DACP-applied sLLMs achieve substantial gains in target
domain performance while preserving general capabilities, offering a
cost-efficient and scalable solution for enterprise-level deployment.

</details>


### [173] [PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning](https://arxiv.org/abs/2507.06415)
*Zeming Chen,Angelika Romanou,Gail Weiss,Antoine Bosselut*

Main category: cs.CL

TL;DR: 提出PERK方法解决长上下文推理问题，评估显示其显著优于基线，推理更稳健，推理时扩展性更好。


<details>
  <summary>Details</summary>
Motivation: 现有元学习方法用于测试时学习内存开销大，无法应用于长上下文场景。

Method: 提出PERK方法，在元训练阶段采用两个嵌套优化循环，内循环将上下文编码到低秩适配器，外循环学习用更新后的适配器进行推理。

Result: 在多个长上下文推理任务上显著优于标准基于提示的长上下文基线，不同模型有不同程度性能提升。

Conclusion: PERK对推理复杂性、长度外推和相关信息位置更稳健，训练时内存开销大，但推理时扩展性更好。

Abstract: Long-context reasoning requires accurately identifying relevant information
in extensive, noisy input contexts. Previous research shows that using
test-time learning to encode context directly into model parameters can
effectively enable reasoning over noisy information. However, meta-learning
methods for enabling test-time learning are prohibitively memory-intensive,
preventing their application to long context settings. In this work, we propose
PERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for
learning to encode long input contexts using gradient updates to a lightweight
model adapter at test time. Specifically, PERK employs two nested optimization
loops in a meta-training phase. The inner loop rapidly encodes contexts into a
low-rank adapter (LoRA) that serves as a parameter-efficient memory module for
the base model. Concurrently, the outer loop learns to use the updated adapter
to accurately recall and reason over relevant information from the encoded long
context. Our evaluations on several long-context reasoning tasks show that PERK
significantly outperforms the standard prompt-based long-context baseline,
achieving average absolute performance gains of up to 90% for smaller models
(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In
general, PERK is more robust to reasoning complexity, length extrapolation, and
the locations of relevant information in contexts. Finally, we show that while
PERK is memory-intensive during training, it scales more efficiently at
inference time than prompt-based long-context inference.

</details>


### [174] [Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders](https://arxiv.org/abs/2507.06427)
*Shun Wang,Tyler Loakman,Youbo Lei,Yi Liu,Bohao Yang,Yuting Zhao,Dong Yang,Chenghua Lin*

Main category: cs.CL

TL;DR: 本文运用字典学习和稀疏自编码器分解大语言模型，提取单语义特征，识别模型误解，改进提示，提升下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型被视为黑盒算法，降低了可信度并阻碍性能提升，因此需要有效方法分解模型。

Method: 使用字典学习方法结合稀疏自编码器进行大语言模型分解，提取单语义特征。

Result: 识别出模型内部误解，可自动重新表述提示以改进模型解释，在数学推理和隐喻检测等下游任务上性能显著提升。

Conclusion: 所提出的大语言模型分解方法能提高模型在下游任务上的表现。

Abstract: Large Language Models (LLMs) are traditionally viewed as black-box
algorithms, therefore reducing trustworthiness and obscuring potential
approaches to increasing performance on downstream tasks. In this work, we
apply an effective LLM decomposition method using a dictionary-learning
approach with sparse autoencoders. This helps extract monosemantic features
from polysemantic LLM neurons. Remarkably, our work identifies model-internal
misunderstanding, allowing the automatic reformulation of the prompts with
additional annotations to improve the interpretation by LLMs. Moreover, this
approach demonstrates a significant performance improvement in downstream
tasks, such as mathematical reasoning and metaphor detection.

</details>


### [175] [Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights](https://arxiv.org/abs/2507.06893)
*Alexandra Abbas,Celia Waggoner,Justin Olive*

Main category: cs.CL

TL;DR: 本文分享维护开源AI评估库的实践见解，识别挑战并提出解决方案，揭示AI评估所需要素。


<details>
  <summary>Details</summary>
Motivation: 随着AI评估成为评估大语言模型能力和安全性的关键工具，分享维护开源AI评估库的实践经验。

Method: 提出结构化的群组管理框架、统计方法和系统质量控制流程。

Result: 分析表明AI评估需要专门的基础设施、统计严谨性和社区协调。

Conclusion: AI评估超出传统软件开发实践，需要特定要素。

Abstract: AI evaluations have become critical tools for assessing large language model
capabilities and safety. This paper presents practical insights from eight
months of maintaining $inspect\_evals$, an open-source repository of 70+
community-contributed AI evaluations. We identify key challenges in
implementing and maintaining AI evaluations and develop solutions including:
(1) a structured cohort management framework for scaling community
contributions, (2) statistical methodologies for optimal resampling and
cross-model comparison with uncertainty quantification, and (3) systematic
quality control processes for reproducibility. Our analysis reveals that AI
evaluation requires specialized infrastructure, statistical rigor, and
community coordination beyond traditional software development practices.

</details>


### [176] [VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation](https://arxiv.org/abs/2507.06899)
*Ziang Ye,Yang Zhang,Wentao Shi,Xiaoyu You,Fuli Feng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 研究揭示GUI代理视觉定位存在后门攻击漏洞，提出VisualTrap方法验证，攻击效果好，强调需研究风险。


<details>
  <summary>Details</summary>
Motivation: GUI代理与个人设备紧密集成，其视觉定位可能引入漏洞，很多威胁未被充分探索，需揭示视觉定位相关的后门攻击问题。

Method: 提出VisualTrap方法，在视觉定位预训练时注入中毒数据，误导代理定位触发位置而非目标位置。

Result: VisualTrap用5%中毒数据和隐形视觉触发器能有效劫持视觉定位，攻击可泛化到下游任务和不同GUI环境。

Conclusion: 强调需要对GUI代理的后门攻击风险进行进一步研究。

Abstract: Graphical User Interface (GUI) agents powered by Large Vision-Language Models
(LVLMs) have emerged as a revolutionary approach to automating human-machine
interactions, capable of autonomously operating personal devices (e.g., mobile
phones) or applications within the device to perform complex real-world tasks
in a human-like manner. However, their close integration with personal devices
raises significant security concerns, with many threats, including backdoor
attacks, remaining largely unexplored. This work reveals that the visual
grounding of GUI agent-mapping textual plans to GUI elements-can introduce
vulnerabilities, enabling new types of backdoor attacks. With backdoor attack
targeting visual grounding, the agent's behavior can be compromised even when
given correct task-solving plans. To validate this vulnerability, we propose
VisualTrap, a method that can hijack the grounding by misleading the agent to
locate textual plans to trigger locations instead of the intended targets.
VisualTrap uses the common method of injecting poisoned data for attacks, and
does so during the pre-training of visual grounding to ensure practical
feasibility of attacking. Empirical results show that VisualTrap can
effectively hijack visual grounding with as little as 5% poisoned data and
highly stealthy visual triggers (invisible to the human eye); and the attack
can be generalized to downstream tasks, even after clean fine-tuning. Moreover,
the injected trigger can remain effective across different GUI environments,
e.g., being trained on mobile/web and generalizing to desktop environments.
These findings underscore the urgent need for further research on backdoor
attack risks in GUI agents.

</details>


### [177] [MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection](https://arxiv.org/abs/2507.06908)
*Ziyan Liu,Chunxiao Fan,Haoran Lou,Yuexin Wu,Kaiwei Deng*

Main category: cs.CL

TL;DR: 提出用于零样本有害表情包检测的多智能体框架MIND，不依赖标注数据，实验显示性能优越且有强泛化性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上表情包快速扩张，传统数据驱动方法因表情包的演变特性和缺乏最新标注数据，难以检测新表情包，急需有效方法检测有害内容。

Method: 提出多智能体框架MIND，包含从无标注参考集中检索相似表情包、提出双向洞察推导机制和采用多智能体辩论机制三个关键策略。

Result: 在三个表情包数据集上的大量实验表明，MIND不仅优于现有零样本方法，还在不同模型架构和参数规模上有强泛化性。

Conclusion: MIND为有害表情包检测提供了可扩展的解决方案。

Abstract: The rapid expansion of memes on social media has highlighted the urgent need
for effective approaches to detect harmful content. However, traditional
data-driven approaches struggle to detect new memes due to their evolving
nature and the lack of up-to-date annotated data. To address this issue, we
propose MIND, a multi-agent framework for zero-shot harmful meme detection that
does not rely on annotated data. MIND implements three key strategies: 1) We
retrieve similar memes from an unannotated reference set to provide contextual
information. 2) We propose a bi-directional insight derivation mechanism to
extract a comprehensive understanding of similar memes. 3) We then employ a
multi-agent debate mechanism to ensure robust decision-making through reasoned
arbitration. Extensive experiments on three meme datasets demonstrate that our
proposed framework not only outperforms existing zero-shot approaches but also
shows strong generalization across different model architectures and parameter
scales, providing a scalable solution for harmful meme detection. The code is
available at https://github.com/destroy-lonely/MIND.

</details>


### [178] [MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction](https://arxiv.org/abs/2507.06909)
*Xiao Wang,Jiahuan Pei,Diancheng Shui,Zhiguang Han,Xin Sun,Dawei Zhu,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 本文引入新数据集MPMCP，评估多个法律大语言模型在四种法律判决场景中的表现，发现多被告多罪名场景挑战最大，且不同模型受影响不同。


<details>
  <summary>Details</summary>
Motivation: 探讨在法律判决预测（LJP）中是否应分别处理多个被告和指控这一相对未充分研究的问题。

Method: 引入MPMCP数据集，评估多个法律大语言模型在四种法律判决场景中的表现，在两项LJP任务（罪名预测和刑期预测）中对数据集进行评估。

Result: 多被告多罪名场景（S4）挑战最大，其次是S2、S3和S1，不同模型受影响程度不同，如InternLM2和Lawformer在S4与S1中的F1分数和LogD有不同变化。

Conclusion: 不同法律判决场景对法律大语言模型的性能有不同影响，尤其是多被告多罪名场景挑战更大。

Abstract: Legal judgment prediction offers a compelling method to aid legal
practitioners and researchers. However, the research question remains
relatively under-explored: Should multiple defendants and charges be treated
separately in LJP? To address this, we introduce a new dataset namely
multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating
the performance of several prevailing legal large language models (LLMs) on
four practical legal judgment scenarios: (S1) single defendant with a single
charge, (S2) single defendant with multiple charges, (S3) multiple defendants
with a single charge, and (S4) multiple defendants with multiple charges. We
evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty
term prediction. We have conducted extensive experiments and found that the
scenario involving multiple defendants and multiple charges (S4) poses the
greatest challenges, followed by S2, S3, and S1. The impact varies
significantly depending on the model. For example, in S4 compared to S1,
InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD,
while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD.
Our dataset and code are available at
https://github.com/lololo-xiao/MultiJustice-MPMCP.

</details>


### [179] [The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](https://arxiv.org/abs/2507.06565)
*Juan B. Gutiérrez*

Main category: cs.CL

TL;DR: 用话语网络模型研究大语言模型写作，定义失效及四种危害，构建数学模型分析，提出FOO算法，指出可靠性源于构建相互监督网络。


<details>
  <summary>Details</summary>
Motivation: 捕捉大语言模型使写作成为人机实时交流这一新媒介的特点。

Method: 采用话语网络模型，构建通用数学模型，提出开源的FOO算法。

Result: 仅受漂移和自我修复影响的网络稳定在适度错误率，加入编造会重现当前大语言模型的高错误率，少量同行评审可使系统转向真相主导状态。

Conclusion: 新媒介的可靠性并非源于完善单个模型，而是将不完美模型连接成相互监督的网络。

Abstract: Large-language models turn writing into a live exchange between humans and
software. We capture this new medium with a discursive-network model that
treats people and LLMs as equal nodes and tracks how their statements
circulate. Broadening the focus from isolated hallucinations, we define
invalidation (any factual, logical, or structural breach) and show it follows
four hazards: drift from truth, self-repair, fresh fabrication, and external
detection. A general mathematical model of discursive networks is developed to
provide valuable insights: A network governed only by drift and self-repair
stabilizes at a modest error rate; adding fabrication reproduces the high rates
seen in current LLMs. Giving each false claim even a small chance of peer
review shifts the system to a truth-dominant state. We operationalize peer
review with the open-source \emph{Flaws-of-Others (FOO) algorithm}: a
configurable loop in which any set of agents critique one another while a
harmoniser merges their verdicts. The takeaway is practical and cultural:
reliability in this new medium comes not from perfecting single models but from
wiring imperfect ones into networks that keep each other honest.

</details>


### [180] [Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation](https://arxiv.org/abs/2507.06607)
*Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen*

Main category: cs.CL

TL;DR: 本文介绍Gated Memory Unit (GMU)机制，创建SambaY架构，提升解码效率、长上下文性能等，模型在推理任务表现优且解码吞吐量高。


<details>
  <summary>Details</summary>
Motivation: 以往工作未研究状态空间模型（SSM）层间表示共享的效率潜力，期望提升效率和性能。

Method: 引入GMU机制，创建SambaY架构，将GMU应用于交叉解码器以共享基于Samba的自解码器的内存读出状态。

Result: SambaY提升解码效率、保留线性预填充时间复杂度、提升长上下文性能、无需显式位置编码；模型不可约损失低于YOCO基线；增强版模型在推理任务表现更好，解码吞吐量高。

Conclusion: 提出的GMU机制和SambaY架构有效，模型具有良好性能和可扩展性，代码已开源。

Abstract: Recent advances in language modeling have demonstrated the effectiveness of
State Space Models (SSMs) for efficient sequence modeling. While hybrid
architectures such as Samba and the decoder-decoder architecture, YOCO, have
shown promising performance gains over Transformers, prior works have not
investigated the efficiency potential of representation sharing between SSM
layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet
effective mechanism for efficient memory sharing across layers. We apply it to
create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in
the cross-decoder to share memory readout states from a Samba-based
self-decoder. SambaY significantly enhances decoding efficiency, preserves
linear pre-filling time complexity, and boosts long-context performance, all
while eliminating the need for explicit positional encoding. Through extensive
scaling experiments, we demonstrate that our model exhibits a significantly
lower irreducible loss compared to a strong YOCO baseline, indicating superior
performance scalability under large-scale compute regimes. Our largest model
enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves
significantly better performance than Phi4-mini-Reasoning on reasoning tasks
such as Math500, AIME24/25, and GPQA Diamond without any reinforcement
learning, while delivering up to 10x higher decoding throughput on 2K-length
prompts with 32K generation length under the vLLM inference framework. We
release our training codebase on open-source data at
https://github.com/microsoft/ArchScale.

</details>


### [181] [FlexOlmo: Open Language Models for Flexible Data Use](https://arxiv.org/abs/2507.07024)
*Weijia Shi,Akshita Bhagia,Kevin Farhat,Niklas Muennighoff,Pete Walsh,Jacob Morrison,Dustin Schwenk,Shayne Longpre,Jake Poznanski,Allyson Ettinger,Daogao Liu,Margaret Li,Dirk Groeneveld,Mike Lewis,Wen-tau Yih,Luca Soldaini,Kyle Lo,Noah A. Smith,Luke Zettlemoyer,Pang Wei Koh,Hannaneh Hajishirzi,Ali Farhadi,Sewon Min*

Main category: cs.CL

TL;DR: 本文介绍语言模型FlexOlmo，它支持无数据共享的分布式训练和数据灵活推理，评估表现出色，为敏感数据行业提供解决方案。


<details>
  <summary>Details</summary>
Motivation: 为有敏感或受保护数据的行业的数据所有者和研究人员提供既能利用封闭数据又能尊重数据所有者偏好的解决方案。

Method: 采用混合专家（MoE）架构，各专家在封闭数据集上独立训练，通过新的领域感知路由集成，在自定义语料FlexMix上训练。

Result: 在31个下游任务上评估，综合表现比之前模型合并方法平均高10.1%，比无数据限制训练的标准MoE表现好。

Conclusion: FlexOlmo可在尊重数据所有者偏好前提下利用封闭数据，支持推理时细粒度控制数据访问。

Abstract: We introduce FlexOlmo, a new class of language models (LMs) that supports (1)
distributed training without data sharing, where different model parameters are
independently trained on closed datasets, and (2) data-flexible inference,
where these parameters along with their associated data can be flexibly
included or excluded from model inferences with no further training. FlexOlmo
employs a mixture-of-experts (MoE) architecture where each expert is trained
independently on closed datasets and later integrated through a new
domain-informed routing without any joint training. FlexOlmo is trained on
FlexMix, a corpus we curate comprising publicly available datasets alongside
seven domain-specific sets, representing realistic approximations of closed
sets. We evaluate models with up to 37 billion parameters (20 billion active)
on 31 diverse downstream tasks. We show that a general expert trained on public
data can be effectively combined with independently trained experts from other
data owners, leading to an average 41% relative improvement while allowing
users to opt out of certain data based on data licensing or permission
requirements. Our approach also outperforms prior model merging methods by
10.1% on average and surpasses the standard MoE trained without data
restrictions using the same training FLOPs. Altogether, this research presents
a solution for both data owners and researchers in regulated industries with
sensitive or protected data. FlexOlmo enables benefiting from closed data while
respecting data owners' preferences by keeping their data local and supporting
fine-grained control of data access during inference.

</details>


### [182] [On the Effect of Uncertainty on Layer-wise Inference Dynamics](https://arxiv.org/abs/2507.06722)
*Sunwoo Kim,Haneul Yoo,Alice Oh*

Main category: cs.CL

TL;DR: 本文研究大语言模型不确定性对推理动态的影响，发现确定和不确定输出的推理动态基本一致，但更有能力的模型可能不同，挑战了简单检测不确定性方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型内部如何表示和处理预测，以检测不确定性和防止幻觉，探究不确定性对隐藏状态处理方式的影响。

Method: 使用Tuned Lens分析11个数据集和5个模型中最终预测标记的逐层概率轨迹，以错误预测代表高认知不确定性。

Result: 确定和不确定预测的轨迹对齐，在相似层信心突然增加，有证据表明更有能力的模型处理不确定性方式可能不同。

Conclusion: 挑战了推理时利用简单方法检测不确定性的可行性，展示了解释性方法可用于研究不确定性对推理的影响。

Abstract: Understanding how large language models (LLMs) internally represent and
process their predictions is central to detecting uncertainty and preventing
hallucinations. While several studies have shown that models encode uncertainty
in their hidden states, it is underexplored how this affects the way they
process such hidden states. In this work, we demonstrate that the dynamics of
output token probabilities across layers for certain and uncertain outputs are
largely aligned, revealing that uncertainty does not seem to affect inference
dynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to
analyze the layer-wise probability trajectories of final prediction tokens
across 11 datasets and 5 models. Using incorrect predictions as those with
higher epistemic uncertainty, our results show aligned trajectories for certain
and uncertain predictions that both observe abrupt increases in confidence at
similar layers. We balance this finding by showing evidence that more competent
models may learn to process uncertainty differently. Our findings challenge the
feasibility of leveraging simplistic methods for detecting uncertainty at
inference. More broadly, our work demonstrates how interpretability methods may
be used to investigate the way uncertainty affects inference.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [183] [Machine-Learned Force Fields for Lattice Dynamics at Coupled-Cluster Level Accuracy](https://arxiv.org/abs/2507.06929)
*Sita Schönbauer,Johanna P. Carbone,Andreas Grüneis*

Main category: cond-mat.mtrl-sci

TL;DR: 研究基于近似DFT和CC势能面训练的MLFFs对碳金刚石和氢化锂固体的应用，评估其精度，探索delta - learning方法，结果显示基于CC理论训练的MLFFs更符合实验。


<details>
  <summary>Details</summary>
Motivation: 研究基于近似DFT和CC势能面训练的MLFFs对碳金刚石和氢化锂固体的精度情况，并克服CC训练数据的局限性。

Method: 通过计算声子色散和振动态密度（VDOS）评估MLFFs的精度，探索基于CC和DFT结果差异的delta - learning方法。

Result: 与DFT相比，基于CC理论训练的MLFFs使光学模式的振动频率更高，更符合实验；MLFFs可用于估算CC理论水平下氢化锂VDOS的非谐效应。

Conclusion: 基于CC理论训练的MLFFs在精度上有优势，可用于相关固体材料性质的研究和非谐效应估算。

Abstract: We investigate Machine-Learned Force Fields (MLFFs) trained on approximate
Density Functional Theory (DFT) and Coupled Cluster (CC) level potential energy
surfaces for the carbon diamond and lithium hydride solids. We assess the
accuracy and precision of the MLFFs by calculating phonon dispersions and
vibrational densities of states (VDOS) that are compared to experiment and
reference ab initio results. To overcome limitations from long-range effects
and the lack of atomic forces in the CC training data, a delta-learning
approach based on the difference between CC and DFT results is explored.
Compared to DFT, MLFFs trained on CC theory yield higher vibrational
frequencies for optical modes, agreeing better with experiment. Furthermore,
the MLFFs are used to estimate anharmonic effects on the VDOS of lithium
hydride at the level of CC theory.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [184] [Stochastic Alignments: Matching an Observed Trace to Stochastic Process Models](https://arxiv.org/abs/2507.06472)
*Tian Li,Artem Polyvyanyy,Sander J. J. Leemans*

Main category: cs.FL

TL;DR: 本文研究将观察轨迹与随机过程模型匹配问题，提出启发式引导寻路算法，开源实现证明方法可行且能提供新诊断见解。


<details>
  <summary>Details</summary>
Motivation: 传统基于对齐的一致性检查技术优先匹配偏差最小路径，可能选择不太可能的路径，需要更好的匹配方法。

Method: 将问题表述为优化问题，开发启发式引导寻路算法求解。

Result: 开源实现证明该方法可行。

Conclusion: 该方法能为分析师提供新的、有用的诊断见解。

Abstract: Process mining leverages event data extracted from IT systems to generate
insights into the business processes of organizations. Such insights benefit
from explicitly considering the frequency of behavior in business processes,
which is captured by stochastic process models. Given an observed trace and a
stochastic process model, conventional alignment-based conformance checking
techniques face a fundamental limitation: They prioritize matching the trace to
a model path with minimal deviations, which may, however, lead to selecting an
unlikely path. In this paper, we study the problem of matching an observed
trace to a stochastic process model by identifying a likely model path with a
low edit distance to the trace. We phrase this as an optimization problem and
develop a heuristic-guided path-finding algorithm to solve it. Our open-source
implementation demonstrates the feasibility of the approach and shows that it
can provide new, useful diagnostic insights for analysts.

</details>


<div id='q-fin.MF'></div>

# q-fin.MF [[Back]](#toc)

### [185] [Quantifying Bounded Rationality: Formal Verification of Simon's Satisficing Through Flexible Stochastic Dominance](https://arxiv.org/abs/2507.07052)
*Jingyuan Li,Zhou Lin*

Main category: q-fin.MF

TL;DR: 本文引入FFSD框架，用Lean 4证明其连接经典期望效用理论和有限理性行为，得到关键结果并实现有限理性形式化，促进形式数学与经济理论交叉。


<details>
  <summary>Details</summary>
Motivation: 用数学严谨框架形式化Herbert Simon的有限理性概念，推动对传统仅定性表达的行为经济学概念的理解。

Method: 使用Lean 4定理证明器，在其依赖类型理论中编码概念，进行机器验证证明。

Result: 得到保证参考点唯一性的临界阈值，FFSD与近似指示函数期望效用最大化的等价定理，以及扩展到多维决策设置。

Conclusion: 为有认知限制的不确定经济决策的机械化推理奠定基础，展示交互式定理证明可促进对行为经济学概念的理解。

Abstract: This paper introduces Flexible First-Order Stochastic Dominance (FFSD), a
mathematically rigorous framework that formalizes Herbert Simon's concept of
bounded rationality using the Lean 4 theorem prover. We develop
machine-verified proofs demonstrating that FFSD bridges classical expected
utility theory with Simon's satisficing behavior through parameterized
tolerance thresholds. Our approach yields several key results: (1) a critical
threshold $\varepsilon < 1/2$ that guarantees uniqueness of reference points,
(2) an equivalence theorem linking FFSD to expected utility maximization for
approximate indicator functions, and (3) extensions to multi-dimensional
decision settings. By encoding these concepts in Lean 4's dependent type
theory, we provide the first machine-checked formalization of Simon's bounded
rationality, creating a foundation for mechanized reasoning about economic
decision-making under uncertainty with cognitive limitations. This work
contributes to the growing intersection between formal mathematics and economic
theory, demonstrating how interactive theorem proving can advance our
understanding of behavioral economics concepts that have traditionally been
expressed only qualitatively.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [186] [VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting](https://arxiv.org/abs/2507.05116)
*Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang*

Main category: cs.CV

TL;DR: 现有VLA模型泛化性有限且计算开销大，本文提出VOTE框架优化加速，实现高效动作预测并开源。


<details>
  <summary>Details</summary>
Motivation: 现有大规模VLA模型在新对象或环境中泛化性有限，添加额外组件提高泛化性会带来高计算开销，效率低，需探索高效动作预测方法。

Method: 提出无分词器微调方法进行并行准确动作预测以减少计算开销、加速推理；采用集成投票策略进行动作采样提高性能和泛化性。

Result: 方法达到了最先进性能，推理速度快35倍，吞吐量达145 Hz。

Conclusion: 所提VOTE框架能有效优化和加速VLA模型，实现高效准确的动作预测。

Abstract: Recent large-scale Vision Language Action (VLA) models have shown superior
performance in robotic manipulation tasks guided by natural language. However,
their generalization remains limited when applied to novel objects or
unfamiliar environments that lie outside the training distribution. To address
this, many existing approaches integrate additional components such as depth
estimation, segmentation, or even diffusion to improve generalization, at the
cost of adding significant computation overhead, resulting in low efficiency.
This motivates the exploration of efficient action prediction methods, which
are independent of additional high-level visual representations or diffusion
techniques. In this work, we propose VOTE, an efficient and general framework
for the optimization and acceleration of VLA models. In details, we propose a
novel tokenizer-free fine-tuning approach for parallel accurate action
prediction, which reduces computational overhead and accelerates inference
speed. Additionally, we adopt an ensemble voting strategy for the action
sampling, which significantly improves model performance and enhances
generalization. Experimental results show that our method achieves
state-of-the-art performance with 35$\times$ faster inference and 145 Hz
throughput. All the details and codes will be open-sourced.

</details>


### [187] [MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval](https://arxiv.org/abs/2507.06654)
*Naoya Sogi,Takashi Shibata,Makoto Terao,Masanori Suganuma,Takayuki Okatani*

Main category: cs.CV

TL;DR: 提出CDR - CA任务及Multi - Source DPPs方法用于文本到图像检索的结果多样化，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 传统结果多样化方法仅关注图像外观多样性指标，且该指标和期望值因应用而异，限制了结果多样化的应用。

Method: 提出CDR - CA任务，设计Multi - Source DPPs方法，将DPP扩展到多源，基于流形表示建模为单一DPP模型，引入切线归一化反映上下文。

Result: 大量实验证明所提方法有效，代码公开。

Conclusion: 所提方法能根据应用上下文细化多个属性的多样性，在文本到图像检索的结果多样化中有良好效果。

Abstract: Result diversification (RD) is a crucial technique in Text-to-Image Retrieval
for enhancing the efficiency of a practical application. Conventional methods
focus solely on increasing the diversity metric of image appearances. However,
the diversity metric and its desired value vary depending on the application,
which limits the applications of RD. This paper proposes a novel task called
CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims
to refine the diversities of multiple attributes, according to the
application's context. To address this task, we propose Multi-Source DPPs, a
simple yet strong baseline that extends the Determinantal Point Process (DPP)
to multi-sources. We model MS-DPP as a single DPP model with a unified
similarity matrix based on a manifold representation. We also introduce Tangent
Normalization to reflect contexts. Extensive experiments demonstrate the
effectiveness of the proposed method. Our code is publicly available at
https://github.com/NEC-N-SOGI/msdpp.

</details>


### [188] [AR2: Attention-Guided Repair for the Robustness of CNNs Against Common Corruptions](https://arxiv.org/abs/2507.06332)
*Fuyuan Zhang,Qichen Wang,Jianjun Zhao*

Main category: cs.CV

TL;DR: 提出AR2方法增强预训练CNN抗干扰鲁棒性，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在常见干扰下性能下降，限制其在现实应用中的可靠性。

Method: 提出AR2方法，通过对齐干净和受干扰图像的类激活图，采用迭代修复策略，交替进行CAM引导的细化和标准微调。

Result: AR2在标准干扰基准测试中始终优于现有方法，在干净数据准确性和抗干扰鲁棒性之间取得良好平衡。

Conclusion: AR2为增强现实环境中模型可靠性提供了强大且可扩展的解决方案。

Abstract: Deep neural networks suffer from significant performance degradation when
exposed to common corruptions such as noise, blur, weather, and digital
distortions, limiting their reliability in real-world applications. In this
paper, we propose AR2 (Attention-Guided Repair for Robustness), a simple yet
effective method to enhance the corruption robustness of pretrained CNNs. AR2
operates by explicitly aligning the class activation maps (CAMs) between clean
and corrupted images, encouraging the model to maintain consistent attention
even under input perturbations. Our approach follows an iterative repair
strategy that alternates between CAM-guided refinement and standard
fine-tuning, without requiring architectural changes. Extensive experiments
show that AR2 consistently outperforms existing state-of-the-art methods in
restoring robustness on standard corruption benchmarks (CIFAR-10-C, CIFAR-100-C
and ImageNet-C), achieving a favorable balance between accuracy on clean data
and corruption robustness. These results demonstrate that AR2 provides a robust
and scalable solution for enhancing model reliability in real-world
environments with diverse corruptions.

</details>


### [189] [SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability](https://arxiv.org/abs/2507.06265)
*Ali Nasiri-Sarvi,Hassan Rivaz,Mahdi S. Hosseini*

Main category: cs.CV

TL;DR: 提出SPARC框架解决不同AI模型概念表示不兼容问题，提升概念对齐效果并支持应用。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法为各模型单独生成潜在概念，概念空间不兼容，限制跨模型可解释性。

Method: 引入SPARC框架，通过全局TopK稀疏机制和交叉重建损失，学习跨不同架构和模态的统一潜在空间。

Result: 在Open Images上显著提升概念对齐，Jaccard相似度达0.80，比之前方法的对齐效果提升超三倍。

Conclusion: SPARC创建共享稀疏潜在空间，可直接比较不同架构对相同概念的表示，还支持文本引导空间定位和跨模型/跨模态检索等应用。

Abstract: Understanding how different AI models encode the same high-level concepts,
such as objects or attributes, remains challenging because each model typically
produces its own isolated representation. Existing interpretability methods
like Sparse Autoencoders (SAEs) produce latent concepts individually for each
model, resulting in incompatible concept spaces and limiting cross-model
interpretability. To address this, we introduce SPARC (Sparse Autoencoders for
Aligned Representation of Concepts), a new framework that learns a single,
unified latent space shared across diverse architectures and modalities (e.g.,
vision models like DINO, and multimodal models like CLIP). SPARC's alignment is
enforced through two key innovations: (1) a Global TopK sparsity mechanism,
ensuring all input streams activate identical latent dimensions for a given
concept; and (2) a Cross-Reconstruction Loss, which explicitly encourages
semantic consistency between models. On Open Images, SPARC dramatically
improves concept alignment, achieving a Jaccard similarity of 0.80, more than
tripling the alignment compared to previous methods. SPARC creates a shared
sparse latent space where individual dimensions often correspond to similar
high-level concepts across models and modalities, enabling direct comparison of
how different architectures represent identical concepts without requiring
manual alignment or model-specific analysis. As a consequence of this aligned
representation, SPARC also enables practical applications such as text-guided
spatial localization in vision-only models and cross-model/cross-modal
retrieval. Code and models are available at
https://github.com/AtlasAnalyticsLab/SPARC.

</details>


### [190] [A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry](https://arxiv.org/abs/2507.06269)
*Rushil Desai,Frederik Warburg,Trevor Darrell,Marissa Ramirez de Chanlatte*

Main category: cs.CV

TL;DR: 提出BayesSDF框架解决神经隐式SDF模型不确定性量化难题，在合成和真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学模拟应用（如森林流体流动建模）需要精确表面几何和对表面几何不确定性的认知，现有方法存在计算效率低、可扩展性差和几何不一致等问题。

Method: 提出BayesSDF框架，利用拉普拉斯近似通过基于Hessian的度量来量化局部表面不稳定性，实现计算高效、表面感知的不确定性估计。

Result: 不确定性预测与重建不佳的几何形状密切对应，在合成和真实数据集上的校准和几何一致性方面优于现有方法。

Conclusion: BayesSDF为不确定性感知的3D场景重建、模拟和机器人决策奠定了坚实基础。

Abstract: Quantifying uncertainty in neural implicit 3D representations, particularly
those utilizing Signed Distance Functions (SDFs), remains a substantial
challenge due to computational inefficiencies, scalability issues, and
geometric inconsistencies. Existing methods typically neglect direct geometric
integration, leading to poorly calibrated uncertainty maps. We introduce
BayesSDF, a novel probabilistic framework for uncertainty quantification in
neural implicit SDF models, motivated by scientific simulation applications
with 3D environments (e.g., forests) such as modeling fluid flow through
forests, where precise surface geometry and awareness of fidelity surface
geometric uncertainty are essential. Unlike radiance-based models such as NeRF
or 3D Gaussian splatting, which lack explicit surface formulations, SDFs define
continuous and differentiable geometry, making them better suited for physical
modeling and analysis. BayesSDF leverages a Laplace approximation to quantify
local surface instability via Hessian-based metrics, enabling computationally
efficient, surface-aware uncertainty estimation. Our method shows that
uncertainty predictions correspond closely with poorly reconstructed geometry,
providing actionable confidence measures for downstream use. Extensive
evaluations on synthetic and real-world datasets demonstrate that BayesSDF
outperforms existing methods in both calibration and geometric consistency,
establishing a strong foundation for uncertainty-aware 3D scene reconstruction,
simulation, and robotic decision-making.

</details>


### [191] [LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance](https://arxiv.org/abs/2507.06272)
*Zhang Li,Biao Yang,Qiang Liu,Shuo Zhang,Zhiyin Ma,Shuo Zhang,Liang Yin,Linger Deng,Yabo Sun,Yuliang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: 提出LIRA框架解决大多模态模型分割和理解的局限性，实验显示其达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大多模态模型存在分割不准确和理解幻觉问题，源于弱视觉理解和缺乏细粒度感知。

Method: 提出LIRA框架，包含语义增强特征提取器（SEFE）和交错局部视觉耦合（ILVC），并引入属性评估（AttrEval）数据集。

Result: LIRA在分割和理解任务中达到了当前最优性能。

Conclusion: LIRA框架有效解决了大多模态模型的局限性，具有良好的应用前景。

Abstract: While large multi-modal models (LMMs) demonstrate promising capabilities in
segmentation and comprehension, they still struggle with two limitations:
inaccurate segmentation and hallucinated comprehension. These challenges stem
primarily from constraints in weak visual comprehension and a lack of
fine-grained perception. To alleviate these limitations, we propose LIRA, a
framework that capitalizes on the complementary relationship between visual
comprehension and segmentation via two key components: (1) Semantic-Enhanced
Feature Extractor (SEFE) improves object attribute inference by fusing semantic
and pixel-level features, leading to more accurate segmentation; (2)
Interleaved Local Visual Coupling (ILVC) autoregressively generates local
descriptions after extracting local features based on segmentation masks,
offering fine-grained supervision to mitigate hallucinations. Furthermore, we
find that the precision of object segmentation is positively correlated with
the latent related semantics of the <seg> token. To quantify this relationship
and the model's potential semantic inferring ability, we introduce the
Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA
achieves state-of-the-art performance in both segmentation and comprehension
tasks. Code will be available at https://github.com/echo840/LIRA.

</details>


### [192] [Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques](https://arxiv.org/abs/2507.06275)
*Yassin Hussein Rassul,Aram M. Ahmed,Polla Fattah,Bryar A. Hassan,Arwaa W. Abdulkareem,Tarik A. Rashid,Joan Lu*

Main category: cs.CV

TL;DR: 本文对离线手写数据增强和生成技术进行全面调查，识别研究差距并提出未来方向。


<details>
  <summary>Details</summary>
Motivation: 离线手写文本识别系统因标注训练数据有限，性能受影响，尤其针对低资源语言和复杂文字。

Method: 系统研究传统增强方法和深度学习新进展，按PRISMA方法筛选文献，从1302篇初步研究中筛选出848篇。

Result: 评估现有数据集、评估指标和先进方法。

Conclusion: 识别了关键研究差距，提出推动手写文本生成领域发展的未来方向。

Abstract: Offline Handwritten Text Recognition (HTR) systems play a crucial role in
applications such as historical document digitization, automatic form
processing, and biometric authentication. However, their performance is often
hindered by the limited availability of annotated training data, particularly
for low-resource languages and complex scripts. This paper presents a
comprehensive survey of offline handwritten data augmentation and generation
techniques designed to improve the accuracy and robustness of HTR systems. We
systematically examine traditional augmentation methods alongside recent
advances in deep learning, including Generative Adversarial Networks (GANs),
diffusion models, and transformer-based approaches. Furthermore, we explore the
challenges associated with generating diverse and realistic handwriting
samples, particularly in preserving script authenticity and addressing data
scarcity. This survey follows the PRISMA methodology, ensuring a structured and
rigorous selection process. Our analysis began with 1,302 primary studies,
which were filtered down to 848 after removing duplicates, drawing from key
academic sources such as IEEE Digital Library, Springer Link, Science Direct,
and ACM Digital Library. By evaluating existing datasets, assessment metrics,
and state-of-the-art methodologies, this survey identifies key research gaps
and proposes future directions to advance the field of handwritten text
generation across diverse linguistic and stylistic landscapes.

</details>


### [193] [SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models](https://arxiv.org/abs/2507.06405)
*Lala Shakti Swarup Ray,Mengxi Liu,Deepika Gurung,Bo Zhou,Sungho Suh,Paul Lukowicz*

Main category: cs.CV

TL;DR: 提出SImpHAR框架解决生物阻抗传感数据标签稀缺问题，在数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 生物阻抗传感用于人体活动识别有优势，但因标签数据稀缺未充分利用。

Method: 提出模拟管道生成逼真生物阻抗信号用于数据增强，设计两阶段解耦训练策略。

Result: 在收集的ImpAct数据集和两个公开基准上评估，准确率和宏F1分数分别提升达22.3%和21.8%。

Conclusion: 基于模拟的增强和模块化训练用于基于阻抗的人体活动识别有前景。

Abstract: Human Activity Recognition (HAR) with wearable sensors is essential for
applications in healthcare, fitness, and human-computer interaction.
Bio-impedance sensing offers unique advantages for fine-grained motion capture
but remains underutilized due to the scarcity of labeled data. We introduce
SImpHAR, a novel framework addressing this limitation through two core
contributions. First, we propose a simulation pipeline that generates realistic
bio-impedance signals from 3D human meshes using shortest-path estimation,
soft-body physics, and text-to-motion generation serving as a digital twin for
data augmentation. Second, we design a two-stage training strategy with
decoupled approach that enables broader activity coverage without requiring
label-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct
dataset and two public benchmarks, showing consistent improvements over
state-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of
accuracy and macro F1 score, respectively. Our results highlight the promise of
simulation-driven augmentation and modular training for impedance-based HAR.

</details>


### [194] [EA: An Event Autoencoder for High-Speed Vision Sensing](https://arxiv.org/abs/2507.06459)
*Riadul Islam,Joey Mulé,Dhandeep Challagundla,Shahmir Rizvi,Sean Carson*

Main category: cs.CV

TL;DR: 本文提出事件自编码器架构处理事件相机数据，实验显示该方法参数少、帧率高，适用于实时边缘计算的低功耗高速应用。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的视觉系统在动态环境存在局限，事件相机在目标检测上有挑战，需新方法解决。

Method: 提出事件自编码器架构，采用卷积编码，结合自适应阈值选择和轻量级分类器。

Result: 在SEFD数据集上精度与YOLO - v4相当，参数少35.5倍；在嵌入式平台帧率8 - 44.8 FPS，分类器FPS比现有技术高87.84倍。

Conclusion: 所提方法显著提升基于事件的视觉性能，适合实时边缘计算的低功耗高速应用。

Abstract: High-speed vision sensing is essential for real-time perception in
applications such as robotics, autonomous vehicles, and industrial automation.
Traditional frame-based vision systems suffer from motion blur, high latency,
and redundant data processing, limiting their performance in dynamic
environments. Event cameras, which capture asynchronous brightness changes at
the pixel level, offer a promising alternative but pose challenges in object
detection due to sparse and noisy event streams. To address this, we propose an
event autoencoder architecture that efficiently compresses and reconstructs
event data while preserving critical spatial and temporal features. The
proposed model employs convolutional encoding and incorporates adaptive
threshold selection and a lightweight classifier to enhance recognition
accuracy while reducing computational complexity. Experimental results on the
existing Smart Event Face Dataset (SEFD) demonstrate that our approach achieves
comparable accuracy to the YOLO-v4 model while utilizing up to $35.5\times$
fewer parameters. Implementations on embedded platforms, including Raspberry Pi
4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8
FPS. The proposed classifier exhibits up to 87.84x better FPS than the
state-of-the-art and significantly improves event-based vision performance,
making it ideal for low-power, high-speed applications in real-time edge
computing.

</details>


### [195] [Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning](https://arxiv.org/abs/2507.06485)
*Ziyang Wang,Jaehong Yoon,Shoubin Yu,Md Mohaiminul Islam,Gedas Bertasius,Mohit Bansal*

Main category: cs.CV

TL;DR: 提出Video - RTS方法结合数据高效的强化学习与视频自适应测试时间缩放策略，提升视频推理能力，数据效率高，在多基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习和大语言模型的视频推理方法在数据收集和微调方面存在挑战，成本高且难扩展。

Method: 跳过资源密集的监督微调步骤，采用基于输出奖励的纯强化学习训练；引入稀疏到密集的视频测试时间缩放策略，根据输出一致性迭代添加帧。

Result: 在多个视频推理基准测试中，Video - RTS仅用3.6%的训练样本，准确率平均超过现有模型2.4%，如在Video - Holmes上提升4.2%，在MMVU上提升2.6%。

Conclusion: 纯强化学习训练和自适应视频测试时间缩放策略优势互补，使Video - RTS有强大推理性能。

Abstract: Despite advances in reinforcement learning (RL)-based video reasoning with
large language models (LLMs), data collection and finetuning remain significant
challenges. These methods often rely on large-scale supervised fine-tuning
(SFT) with extensive video data and long Chain-of-Thought (CoT) annotations,
making them costly and hard to scale. To address this, we present Video-RTS, a
new approach to improve video reasoning capability with drastically improved
data efficiency by combining data-efficient RL with a video-adaptive test-time
scaling (TTS) strategy. Based on observations about the data scaling of RL
samples, we skip the resource-intensive SFT step and employ efficient pure-RL
training with output-based rewards, requiring no additional annotations or
extensive fine-tuning. Furthermore, to utilize computational resources more
efficiently, we introduce a sparse-to-dense video TTS strategy that improves
inference by iteratively adding frames based on output consistency. We validate
our approach on multiple video reasoning benchmarks, showing that Video-RTS
surpasses existing video reasoning models by an average of 2.4% in accuracy
using only 3.6% training samples. For example, Video-RTS achieves a 4.2%
improvement on Video-Holmes, a recent and challenging video reasoning
benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and
adaptive video TTS offer complementary strengths, enabling Video-RTS's strong
reasoning performance.

</details>


### [196] [EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision](https://arxiv.org/abs/2507.06639)
*Myungjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee*

Main category: cs.CV

TL;DR: 提出病理基础模型EXAONE Path 2.0，在直接幻灯片级监督下学习补丁级表示，用少量数据在10个生物标志物预测任务中达最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于补丁级自监督学习方法会忽略复杂领域特征，且数据效率低，需大量计算资源和数据集。

Method: 提出EXAONE Path 2.0，在直接幻灯片级监督下学习补丁级表示。

Result: 仅用37k张全切片图像训练，在10个生物标志物预测任务中取得最优平均性能。

Conclusion: EXAONE Path 2.0数据效率高。

Abstract: In digital pathology, whole-slide images (WSIs) are often difficult to handle
due to their gigapixel scale, so most approaches train patch encoders via
self-supervised learning (SSL) and then aggregate the patch-level embeddings
via multiple instance learning (MIL) or slide encoders for downstream tasks.
However, patch-level SSL may overlook complex domain-specific features that are
essential for biomarker prediction, such as mutation status and molecular
characteristics, as SSL methods rely only on basic augmentations selected for
natural image domains on small patch-level area. Moreover, SSL methods remain
less data efficient than fully supervised approaches, requiring extensive
computational resources and datasets to achieve competitive performance. To
address these limitations, we present EXAONE Path 2.0, a pathology foundation
model that learns patch-level representations under direct slide-level
supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves
state-of-the-art average performance across 10 biomarker prediction tasks,
demonstrating remarkable data efficiency.

</details>


### [197] [DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement](https://arxiv.org/abs/2507.06738)
*Xinyu Xie,Weifeng Cao,Jun Shi,Yangyang Hu,Hui Liang,Wanyong Liang,Xiaoliang Qian*

Main category: cs.CV

TL;DR: 构建并发布半导体晶圆切割过程数据集CHDL，提出预测架构DIFFUMA，实验表明其性能优越，为工业AI研究提供数据资源。


<details>
  <summary>Details</summary>
Motivation: 在高精度工业场景如半导体制造中，缺乏专业基准数据集阻碍复杂过程建模和预测研究。

Method: 构建并发布CHDL数据集；提出DIFFUMA双路径预测架构，通过Mamba模块捕获全局长期时间上下文，利用扩散模块恢复和增强细粒度空间细节。

Result: 在CHDL基准上，DIFFUMA显著优于现有方法，均方误差降低39%，结构相似性从0.926提升到0.988，在自然现象数据集上也有良好泛化性。

Conclusion: 研究不仅得到新的最优模型，还为社区提供有价值的数据资源以推动工业AI未来研究。

Abstract: Spatio-temporal video prediction plays a pivotal role in critical domains,
ranging from weather forecasting to industrial automation. However, in
high-precision industrial scenarios such as semiconductor manufacturing, the
absence of specialized benchmark datasets severely hampers research on modeling
and predicting complex processes. To address this challenge, we make a twofold
contribution.First, we construct and release the Chip Dicing Lane Dataset
(CHDL), the first public temporal image dataset dedicated to the semiconductor
wafer dicing process. Captured via an industrial-grade vision system, CHDL
provides a much-needed and challenging benchmark for high-fidelity process
modeling, defect detection, and digital twin development.Second, we propose
DIFFUMA, an innovative dual-path prediction architecture specifically designed
for such fine-grained dynamics. The model captures global long-range temporal
context through a parallel Mamba module, while simultaneously leveraging a
diffusion module, guided by temporal features, to restore and enhance
fine-grained spatial details, effectively combating feature degradation.
Experiments demonstrate that on our CHDL benchmark, DIFFUMA significantly
outperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and
improving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988.
This superior performance also generalizes to natural phenomena datasets. Our
work not only delivers a new state-of-the-art (SOTA) model but, more
importantly, provides the community with an invaluable data resource to drive
future research in industrial AI.

</details>


### [198] [FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views](https://arxiv.org/abs/2507.06763)
*Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel*

Main category: cs.CV

TL;DR: 本文提出FOLC - Net框架用于MRI疾病诊断，参数少且存储需求低，评估显示其在各视图表现优于现有模型，能适应分散环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有SOTA模型在处理轴向、冠状和矢状解剖平面时性能下降的问题，提高MRI疾病诊断性能。

Method: 引入FOLC - Net框架，融合MRFO机制生成模型结构、采用全局模型克隆进行可扩展训练、利用ConvNeXt增强客户端适应性，还测试ShallowFed模型评估泛化能力。

Result: FOLC - Net在各视图表现优于现有模型，如矢状视图准确率达92.44%，高于其他方法。

Conclusion: FOLC - Net解决了现有模型局限性，在多视图和单视图场景都表现良好，适合现实医疗应用。

Abstract: The framework is designed to improve performance in the analysis of combined
as well as single anatomical perspectives for MRI disease diagnosis. It
specifically addresses the performance degradation observed in state-of-the-art
(SOTA) models, particularly when processing axial, coronal, and sagittal
anatomical planes. The paper introduces the FOLC-Net framework, which
incorporates a novel federated-optimized lightweight architecture with
approximately 1.217 million parameters and a storage requirement of only 0.9
MB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for
efficient model structure generation, global model cloning for scalable
training, and ConvNeXt for enhanced client adaptability. The model was
evaluated on combined multi-view data as well as individual views, such as
axial, coronal, and sagittal, to assess its robustness in various medical
imaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different
data to evaluate its ability to generalize beyond the training dataset. The
results show that FOLC-Net outperforms existing models, particularly in the
challenging sagittal view. For instance, FOLC-Net achieved an accuracy of
92.44% on the sagittal view, significantly higher than the 88.37% accuracy of
study method (DL + Residual Learning) and 88.95% of DL models. Additionally,
FOLC-Net demonstrated improved accuracy across all individual views, providing
a more reliable and robust solution for medical image analysis in decentralized
environments. FOLC-Net addresses the limitations of existing SOTA models by
providing a framework that ensures better adaptability to individual views
while maintaining strong performance in multi-view settings. The incorporation
of MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs
better in real-world medical applications.

</details>


### [199] [Centralized Copy-Paste: Enhanced Data Augmentation Strategy for Wildland Fire Semantic Segmentation](https://arxiv.org/abs/2507.06321)
*Joon Tai Kim,Tianle Chen,Ziyu Dong,Nishanth Kunchala,Alexander Guller,Daniel Ospina Acero,Roger Williams,Mrinal Kumar*

Main category: cs.CV

TL;DR: 本文提出CCPDA方法辅助深度学习多类分割模型训练，经实验验证其能缓解小标注数据集问题，提升火灾类分割性能。


<details>
  <summary>Details</summary>
Motivation: 收集和标注图像训练分割模型成本高，野地火灾科学领域缺乏可靠公共标注数据集。

Method: CCPDA方法有三步：识别源图像中火灾簇、采用中心化技术聚焦火区核心、将精炼火灾簇粘贴到目标图像。

Result: 通过数值分析和多目标优化方法对比，CCPDA能提升火灾类分割性能指标，优于其他增强策略。

Conclusion: CCPDA方法能缓解小手动标注训练数据集的困难，在火灾类分割上表现出色。

Abstract: Collecting and annotating images for the purpose of training segmentation
models is often cost prohibitive. In the domain of wildland fire science, this
challenge is further compounded by the scarcity of reliable public datasets
with labeled ground truth. This paper presents the Centralized Copy-Paste Data
Augmentation (CCPDA) method, for the purpose of assisting with the training of
deep-learning multiclass segmentation models, with special focus on improving
segmentation outcomes for the fire-class. CCPDA has three main steps: (i)
identify fire clusters in the source image, (ii) apply a centralization
technique to focus on the core of the fire area, and (iii) paste the refined
fire clusters onto a target image. This method increases dataset diversity
while preserving the essential characteristics of the fire class. The
effectiveness of this augmentation technique is demonstrated via numerical
analysis and comparison against various other augmentation methods using a
weighted sum-based multi-objective optimization approach. This approach helps
elevate segmentation performance metrics specific to the fire class, which
carries significantly more operational significance than other classes (fuel,
ash, or background). Numerical performance assessment validates the efficacy of
the presented CCPDA method in alleviating the difficulties associated with
small, manually labeled training datasets. It also illustrates that CCPDA
outperforms other augmentation strategies in the application scenario
considered, particularly in improving fire-class segmentation performance.

</details>


### [200] [Democratizing High-Fidelity Co-Speech Gesture Video Generation](https://arxiv.org/abs/2507.06812)
*Xu Yang,Shaoli Huang,Shenbo Xie,Xuelin Chen,Yifei Liu,Changxing Ding*

Main category: cs.CV

TL;DR: 提出轻量级框架结合扩散模型用2D骨架辅助生成共语音手势视频，还发布数据集，实验效果超现有方法。


<details>
  <summary>Details</summary>
Motivation: 共语音手势视频生成存在音视频映射复杂、数据集少和计算需求高的问题。

Method: 用2D全身体骨架作为辅助条件，引入基于细粒度音频段和参考图像骨架的扩散模型，融合特征预测骨架运动，再用骨架和参考图像合成视频，还发布CSG - 405数据集。

Result: 方法在视觉质量和同步性上超过现有方法，能在不同说话者和场景中泛化。

Conclusion: 所提轻量级框架和发布的数据集有助于推动共语音手势视频生成研究。

Abstract: Co-speech gesture video generation aims to synthesize realistic,
audio-aligned videos of speakers, complete with synchronized facial expressions
and body gestures. This task presents challenges due to the significant
one-to-many mapping between audio and visual content, further complicated by
the scarcity of large-scale public datasets and high computational demands. We
propose a lightweight framework that utilizes 2D full-body skeletons as an
efficient auxiliary condition to bridge audio signals with visual outputs. Our
approach introduces a diffusion model conditioned on fine-grained audio
segments and a skeleton extracted from the speaker's reference image,
predicting skeletal motions through skeleton-audio feature fusion to ensure
strict audio coordination and body shape consistency. The generated skeletons
are then fed into an off-the-shelf human video generation model with the
speaker's reference image to synthesize high-fidelity videos. To democratize
research, we present CSG-405-the first public dataset with 405 hours of
high-resolution videos across 71 speech types, annotated with 2D skeletons and
diverse speaker demographics. Experiments show that our method exceeds
state-of-the-art approaches in visual quality and synchronization while
generalizing across speakers and contexts.

</details>


### [201] [Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation](https://arxiv.org/abs/2507.06830)
*Tao Feng,Xianbing Zhao,Zhenhua Chen,Tien Tsin Wong,Hamid Rezatofighi,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CV

TL;DR: 现有扩散和自回归视频生成模型缺乏物理对齐，本文提出结合符号回归和轨迹引导图像到视频模型的框架用于物理视频预测，在经典力学场景评估有效果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散和自回归视频生成模型依赖统计相关性，缺乏准确物理对齐，无法复制物体运动的真实动力学。

Method: 从输入视频提取运动轨迹，用基于检索的预训练机制增强符号回归，发现运动方程以预测物理准确的未来轨迹，引导视频生成且无需微调现有模型。

Result: 在经典力学场景评估中，成功恢复真实解析方程，相比基线方法提高了生成视频的物理对齐度。

Conclusion: 所提框架能有效解决现有视频生成模型物理对齐不足的问题，提升生成视频的物理准确性。

Abstract: Recent advances in diffusion-based and autoregressive video generation models
have achieved remarkable visual realism. However, these models typically lack
accurate physical alignment, failing to replicate real-world dynamics in object
motion. This limitation arises primarily from their reliance on learned
statistical correlations rather than capturing mechanisms adhering to physical
laws. To address this issue, we introduce a novel framework that integrates
symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for
physics-grounded video forecasting. Our approach extracts motion trajectories
from input videos, uses a retrieval-based pre-training mechanism to enhance
symbolic regression, and discovers equations of motion to forecast physically
accurate future trajectories. These trajectories then guide video generation
without requiring fine-tuning of existing models. Evaluated on scenarios in
Classical Mechanics, including spring-mass, pendulums, and projectile motions,
our method successfully recovers ground-truth analytical equations and improves
the physical alignment of generated videos over baseline methods.

</details>


### [202] [IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization](https://arxiv.org/abs/2507.06856)
*Subrat Kishore Dutta,Xiao Zhang*

Main category: cs.CV

TL;DR: 提出IAP框架生成高度隐形的对抗补丁，实验显示其在攻击成功率和隐形性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在定向攻击场景下表现不佳或生成的对抗补丁易被察觉，无法有效对抗自动补丁防御。

Method: 先利用类定位和敏感度图寻找合适的补丁放置位置，平衡对模型预测和人类视觉系统的影响；再采用感知正则化对抗损失和优先考虑颜色恒常性的梯度更新规则优化隐形扰动。

Result: 在各种图像基准和模型架构上的实验表明，IAP在定向攻击场景中能持续取得有竞争力的攻击成功率，且补丁隐形性显著提升。

Conclusion: IAP不仅对人类高度不可察觉，还能使几种先进的补丁防御失效。

Abstract: Despite modifying only a small localized input region, adversarial patches
can drastically change the prediction of computer vision models. However, prior
methods either cannot perform satisfactorily under targeted attack scenarios or
fail to produce contextually coherent adversarial patches, causing them to be
easily noticeable by human examiners and insufficiently stealthy against
automatic patch defenses. In this paper, we introduce IAP, a novel attack
framework that generates highly invisible adversarial patches based on
perceptibility-aware localization and perturbation optimization schemes.
Specifically, IAP first searches for a proper location to place the patch by
leveraging classwise localization and sensitivity maps, balancing the
susceptibility of patch location to both victim model prediction and human
visual system, then employs a perceptibility-regularized adversarial loss and a
gradient update rule that prioritizes color constancy for optimizing invisible
perturbations. Comprehensive experiments across various image benchmarks and
model architectures demonstrate that IAP consistently achieves competitive
attack success rates in targeted settings with significantly improved patch
invisibility compared to existing baselines. In addition to being highly
imperceptible to humans, IAP is shown to be stealthy enough to render several
state-of-the-art patch defenses ineffective.

</details>


### [203] [Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution](https://arxiv.org/abs/2507.06547)
*Yonghyun Park,Chieh-Hsin Lai,Satoshi Hayakawa,Yuhta Takida,Naoki Murata,Wei-Hsiang Liao,Woosung Choi,Kin Wai Cheuk,Junghyun Koo,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 论文针对扩散模型版权和透明度问题，提出Concept - TRAK方法进行概念级归因，在AbC基准测试中表现优于先前方法，案例研究显示其对负责任AI发展和治理有作用。


<details>
  <summary>Details</summary>
Motivation: 扩散模型广泛应用带来版权和透明度问题，现有归因方法无法隔离特定元素的贡献，需要新的归因方法。

Method: 引入Concept - TRAK方法，通过基于扩散后验采样的重新制定的扩散训练损失和概念感知奖励函数扩展影响函数。

Result: 在AbC基准测试中，Concept - TRAK相比先前方法有显著改进。

Conclusion: 概念级归因能为负责任的生成式AI发展和治理提供可操作的见解。

Abstract: While diffusion models excel at image generation, their growing adoption
raises critical concerns around copyright issues and model transparency.
Existing attribution methods identify training examples influencing an entire
image, but fall short in isolating contributions to specific elements, such as
styles or objects, that matter most to stakeholders. To bridge this gap, we
introduce \emph{concept-level attribution} via a novel method called
\emph{Concept-TRAK}. Concept-TRAK extends influence functions with two key
innovations: (1) a reformulated diffusion training loss based on diffusion
posterior sampling, enabling robust, sample-specific attribution; and (2) a
concept-aware reward function that emphasizes semantic relevance. We evaluate
Concept-TRAK on the AbC benchmark, showing substantial improvements over prior
methods. Through diverse case studies--ranging from identifying IP-protected
and unsafe content to analyzing prompt engineering and compositional
learning--we demonstrate how concept-level attribution yields actionable
insights for responsible generative AI development and governance.

</details>


### [204] [Divergence-Based Similarity Function for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06560)
*Jae Hyoung Jeon,Cheolsu Lim,Myungjoo Kang*

Main category: cs.CV

TL;DR: 提出基于散度的相似性函数DSF，能捕获多视图联合结构，实验显示其提升性能且更高效，还建立与余弦相似度理论联系。


<details>
  <summary>Details</summary>
Motivation: 以往方法主要捕捉成对关系，未能对所有视图的联合结构进行建模，需更有效利用实例的多个增强视图。

Method: 提出基于散度的相似性函数DSF，将每组增强视图表示为分布，以分布间的散度衡量相似性。

Result: DSF在kNN分类和线性评估等任务中持续提升性能，比其他多视图方法更高效，且无需温度超参数即可有效运行。

Conclusion: DSF能有效捕获多视图联合结构，性能优越且效率高，与余弦相似度有理论联系且无需温度超参数。

Abstract: Recent success in contrastive learning has sparked growing interest in more
effectively leveraging multiple augmented views of an instance. While prior
methods incorporate multiple views at the loss or feature level, they primarily
capture pairwise relationships and fail to model the joint structure across all
views. In this work, we propose a divergence-based similarity function (DSF)
that explicitly captures the joint structure by representing each set of
augmented views as a distribution and measuring similarity as the divergence
between distributions. Extensive experiments demonstrate that DSF consistently
improves performance across various tasks, including kNN classification and
linear evaluation, while also offering greater efficiency compared to other
multi-view methods. Furthermore, we establish a theoretical connection between
DSF and cosine similarity, and show that, unlike cosine similarity, DSF
operates effectively without requiring a temperature hyperparameter.

</details>


### [205] [CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale](https://arxiv.org/abs/2507.06959)
*Xiao Liang,Jiawei Hu,Di Wang,Zhi Ma,Lin Zhao,Ronghan Li,Bo Wan,Quan Wang*

Main category: cs.CV

TL;DR: 本文针对视觉语言模型在医疗应用中的幻觉问题，提出CheXPO策略，仅用5%的SFT样本实现8.93%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医疗应用中易产生幻觉，偏好优化实施面临训练样本不相关、数据分布不平衡和专家注释成本高等挑战。

Method: 引入CheXPO策略，合成统一的多任务胸部X光视觉指令数据集进行监督微调，通过令牌级置信度分析识别困难样本，用基于相似度的检索扩展样本，合成反事实理由提供临床偏好。

Result: CheXPO仅用5%的SFT样本实现8.93%的相对性能提升，在不同临床任务中达到了最先进的性能。

Conclusion: CheXPO为现实世界的放射学应用提供了可扩展、可解释的解决方案。

Abstract: Vision-language models (VLMs) are prone to hallucinations that critically
compromise reliability in medical applications. While preference optimization
can mitigate these hallucinations through clinical feedback, its implementation
faces challenges such as clinically irrelevant training samples, imbalanced
data distributions, and prohibitive expert annotation costs. To address these
challenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy
that combines confidence-similarity joint mining with counterfactual rationale.
Our approach begins by synthesizing a unified, fine-grained multi-task chest
X-ray visual instruction dataset across different question types for supervised
fine-tuning (SFT). We then identify hard examples through token-level
confidence analysis of SFT failures and use similarity-based retrieval to
expand hard examples for balancing preference sample distributions, while
synthetic counterfactual rationales provide fine-grained clinical preferences,
eliminating the need for additional expert input. Experiments show that CheXPO
achieves 8.93% relative performance gain using only 5% of SFT samples, reaching
state-of-the-art performance across diverse clinical tasks and providing a
scalable, interpretable solution for real-world radiology applications.

</details>


### [206] [MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation](https://arxiv.org/abs/2507.06992)
*Qilong Xing,Zikai Song,Youjia Zhang,Na Feng,Junqing Yu,Wei Yang*

Main category: cs.CV

TL;DR: 提出知识驱动框架MCA - RG解决大语言模型在放射学报告生成临床应用的挑战，实验表明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型用于放射学报告生成临床应用面临特征映射难和语义无关特征提取问题。

Method: 引入MCA - RG框架，利用病理和解剖概念库对齐视觉特征并增强，提出解剖对比学习和病理特征匹配损失，采用特征门控机制过滤低质量特征。

Result: 在MIMIC - CXR和CheXpert Plus两个公开基准上实验，MCA - RG表现优越。

Conclusion: MCA - RG在放射学报告生成中有效。

Abstract: Despite significant advancements in adapting Large Language Models (LLMs) for
radiology report generation (RRG), clinical adoption remains challenging due to
difficulties in accurately mapping pathological and anatomical features to
their corresponding text descriptions. Additionally, semantic agnostic feature
extraction further hampers the generation of accurate diagnostic reports. To
address these challenges, we introduce Medical Concept Aligned Radiology Report
Generation (MCA-RG), a knowledge-driven framework that explicitly aligns visual
features with distinct medical concepts to enhance the report generation
process. MCA-RG utilizes two curated concept banks: a pathology bank containing
lesion-related knowledge, and an anatomy bank with anatomical descriptions. The
visual features are aligned with these medical concepts and undergo tailored
enhancement. We further propose an anatomy-based contrastive learning procedure
to improve the generalization of anatomical features, coupled with a matching
loss for pathological features to prioritize clinically relevant regions.
Additionally, a feature gating mechanism is employed to filter out low-quality
concept features. Finally, the visual features are corresponding to individual
medical concepts, and are leveraged to guide the report generation process.
Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate
that MCA-RG achieves superior performance, highlighting its effectiveness in
radiology report generation.

</details>


### [207] [Learning from Sparse Point Labels for Dense Carcinosis Localization in Advanced Ovarian Cancer Assessment](https://arxiv.org/abs/2507.06643)
*Farahdiba Zarin,Riccardo Oliva,Vinkle Srivastav,Armine Vardazaryan,Andrea Rosati,Alice Zampolini Faustini,Giovanni Scambia,Anna Fagotti,Pietro Mascagni,Nicolas Padoy*

Main category: cs.CV

TL;DR: 本文针对医学领域从稀疏标签学习的挑战，以卵巢癌诊断规划中的关键点定位为例，提出Crag and Tail损失函数，经消融实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 医学领域因标注成本等因素，从稀疏像素级标签学习是常见挑战，尤其在新任务和需要密集像素级标注时。能从少量像素级标注学习可推动缺乏完美标注的研究进展。

Method: 将问题表述为从每张图像的少量点标注进行稀疏热图回归，提出Crag and Tail损失函数用于高效学习，该函数有效利用正稀疏标签，同时最小化假阴性或遗漏标注的影响。

Result: 通过广泛的消融实验，证明该方法能准确实现癌灶关键点的密集定位。

Conclusion: 该方法在难以获取密集标注的场景中有推进研究的潜力。

Abstract: Learning from sparse labels is a challenge commonplace in the medical domain.
This is due to numerous factors, such as annotation cost, and is especially
true for newly introduced tasks. When dense pixel-level annotations are needed,
this becomes even more unfeasible. However, being able to learn from just a few
annotations at the pixel-level, while extremely difficult and underutilized,
can drive progress in studies where perfect annotations are not immediately
available. This work tackles the challenge of learning the dense prediction
task of keypoint localization from a few point annotations in the context of 2d
carcinosis keypoint localization from laparoscopic video frames for diagnostic
planning of advanced ovarian cancer patients. To enable this, we formulate the
problem as a sparse heatmap regression from a few point annotations per image
and propose a new loss function, called Crag and Tail loss, for efficient
learning. Our proposed loss function effectively leverages positive sparse
labels while minimizing the impact of false negatives or missed annotations.
Through an extensive ablation study, we demonstrate the effectiveness of our
approach in achieving accurate dense localization of carcinosis keypoints,
highlighting its potential to advance research in scenarios where dense
annotations are challenging to obtain.

</details>


### [208] [Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients](https://arxiv.org/abs/2507.06994)
*Qilong Xing,Zikai Song,Bingxin Gong,Lian Yang,Junqing Yu,Wei Yang*

Main category: cs.CV

TL;DR: 提出大规模数据集和多模态特征融合框架提升非小细胞肺癌免疫治疗患者生存预测准确性，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确预测非小细胞肺癌免疫治疗患者预后对个性化治疗重要，但缺乏相关大数据集和有效多模态特征融合策略。

Method: 提出含3D CT图像、临床记录、生存数据的数据集，采用跨模态掩码学习方法进行特征融合，含切片深度Transformer和基于图的Transformer。

Result: 该方法在多模态集成的非小细胞肺癌生存预测中表现优于现有方法。

Conclusion: 为非小细胞肺癌预后模型设定了新基准。

Abstract: Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing
immunotherapy is essential for personalized treatment planning, enabling
informed patient decisions, and improving both treatment outcomes and quality
of life. However, the lack of large, relevant datasets and effective
multi-modal feature fusion strategies pose significant challenges in this
domain. To address these challenges, we present a large-scale dataset and
introduce a novel framework for multi-modal feature fusion aimed at enhancing
the accuracy of survival prediction. The dataset comprises 3D CT images and
corresponding clinical records from NSCLC patients treated with immune
checkpoint inhibitors (ICI), along with progression-free survival (PFS) and
overall survival (OS) data. We further propose a cross-modality masked learning
approach for medical feature fusion, consisting of two distinct branches, each
tailored to its respective modality: a Slice-Depth Transformer for extracting
3D features from CT images and a graph-based Transformer for learning node
features and relationships among clinical variables in tabular data. The fusion
process is guided by a masked modality learning strategy, wherein the model
utilizes the intact modality to reconstruct missing components. This mechanism
improves the integration of modality-specific features, fostering more
effective inter-modality relationships and feature interactions. Our approach
demonstrates superior performance in multi-modal integration for NSCLC survival
prediction, surpassing existing methods and setting a new benchmark for
prognostic models in this context.

</details>


### [209] [Enhancing Diffusion Model Stability for Image Restoration via Gradient Management](https://arxiv.org/abs/2507.06656)
*Hongjie Wu,Mingqin Zhang,Linchao He,Ji-Zhe Zhou,Jiancheng Lv*

Main category: cs.CV

TL;DR: 本文分析扩散模型图像恢复中组件梯度不稳定问题，提出SPGD方法解决，实验显示其提升生成稳定性并带来优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型图像恢复方法中，生成过程里去噪与似然引导两组件间的相互作用研究不足，且存在梯度不稳定问题影响恢复性能。

Method: 提出Stabilized Progressive Gradient Diffusion (SPGD) 方法，包含渐进似然预热策略缓解梯度冲突和自适应方向动量 (ADM) 平滑减少似然梯度波动。

Result: 在不同恢复任务的大量实验中，SPGD显著提升生成稳定性，在定量指标上达到最优，视觉效果也更佳。

Conclusion: SPGD能有效解决扩散模型图像恢复中的梯度不稳定问题，提升恢复性能。

Abstract: Diffusion models have shown remarkable promise for image restoration by
leveraging powerful priors. Prominent methods typically frame the restoration
problem within a Bayesian inference framework, which iteratively combines a
denoising step with a likelihood guidance step. However, the interactions
between these two components in the generation process remain underexplored. In
this paper, we analyze the underlying gradient dynamics of these components and
identify significant instabilities. Specifically, we demonstrate conflicts
between the prior and likelihood gradient directions, alongside temporal
fluctuations in the likelihood gradient itself. We show that these
instabilities disrupt the generative process and compromise restoration
performance. To address these issues, we propose Stabilized Progressive
Gradient Diffusion (SPGD), a novel gradient management technique. SPGD
integrates two synergistic components: (1) a progressive likelihood warm-up
strategy to mitigate gradient conflicts; and (2) adaptive directional momentum
(ADM) smoothing to reduce fluctuations in the likelihood gradient. Extensive
experiments across diverse restoration tasks demonstrate that SPGD
significantly enhances generation stability, leading to state-of-the-art
performance in quantitative metrics and visually superior results. Code is
available at \href{https://github.com/74587887/SPGD}{here}.

</details>


### [210] [Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices](https://arxiv.org/abs/2507.07029)
*Parshva Dhilankumar Patel*

Main category: cs.CV

TL;DR: 本文设计开发了基于OCR的发票表格提取管道，提升提取准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 高效从发票中提取表格数据，支持自动化财务流程和数字存档等实际应用。

Method: 利用Tesseract OCR进行文本识别，结合自定义后处理逻辑，包括动态预处理、表格边界检测和行列映射。

Result: 管道显著提高了数据提取的准确性和一致性。

Conclusion: 该管道能支持自动化财务流程和数字存档等实际用例。

Abstract: This paper presents the design and development of an OCR-powered pipeline for
efficient table extraction from invoices. The system leverages Tesseract OCR
for text recognition and custom post-processing logic to detect, align, and
extract structured tabular data from scanned invoice documents. Our approach
includes dynamic preprocessing, table boundary detection, and row-column
mapping, optimized for noisy and non-standard invoice formats. The resulting
pipeline significantly improves data extraction accuracy and consistency,
supporting real-world use cases such as automated financial workflows and
digital archiving.

</details>


### [211] [Residual Prior-driven Frequency-aware Network for Image Fusion](https://arxiv.org/abs/2507.06735)
*Guan Zheng,Xue Wang,Wenhua Qian,Peng Liu,Runzhuo Ma*

Main category: cs.CV

TL;DR: 提出残差先验驱动的频率感知网络RPFNet解决图像融合挑战，实验验证其融合性能良好，能促进高层视觉任务部署。


<details>
  <summary>Details</summary>
Motivation: 现有全局空间建模机制计算成本高，且缺乏真值难以有效捕捉互补特征，需更好方法解决图像融合问题。

Method: 采用双分支特征提取框架，包括残差先验模块、频域融合模块和交叉促进模块，训练时加入辅助解码器和多种损失函数。

Result: RPFNet有效融合判别特征，增强纹理细节和显著对象。

Conclusion: RPFNet能有效整合互补信息，促进高层视觉任务的部署。

Abstract: Image fusion aims to integrate complementary information across modalities to
generate high-quality fused images, thereby enhancing the performance of
high-level vision tasks. While global spatial modeling mechanisms show
promising results, constructing long-range feature dependencies in the spatial
domain incurs substantial computational costs. Additionally, the absence of
ground-truth exacerbates the difficulty of capturing complementary features
effectively. To tackle these challenges, we propose a Residual Prior-driven
Frequency-aware Network, termed as RPFNet. Specifically, RPFNet employs a
dual-branch feature extraction framework: the Residual Prior Module (RPM)
extracts modality-specific difference information from residual maps, thereby
providing complementary priors for fusion; the Frequency Domain Fusion Module
(FDFM) achieves efficient global feature modeling and integration through
frequency-domain convolution. Additionally, the Cross Promotion Module (CPM)
enhances the synergistic perception of local details and global structures
through bidirectional feature interaction. During training, we incorporate an
auxiliary decoder and saliency structure loss to strengthen the model's
sensitivity to modality-specific differences. Furthermore, a combination of
adaptive weight-based frequency contrastive loss and SSIM loss effectively
constrains the solution space, facilitating the joint capture of local details
and global features while ensuring the retention of complementary information.
Extensive experiments validate the fusion performance of RPFNet, which
effectively integrates discriminative features, enhances texture details and
salient objects, and can effectively facilitate the deployment of the
high-level vision task.

</details>


### [212] [Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching](https://arxiv.org/abs/2507.06744)
*Yafei Zhang,Yongle Shang,Huafeng Li*

Main category: cs.CV

TL;DR: 提出局部-全局双粒度身份关联机制和信息不对称样本对构建方法，提升跨模态匹配准确率，为文本到人物图像匹配提供高效实用方案。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督文本到人物图像匹配方法难以预测复杂的一对多身份关系，限制性能提升。

Method: 提出局部 - 全局双粒度身份关联机制，局部建立批量内跨模态身份关系，全局构建动态跨模态身份关联网络并引入动态调整机制；提出信息不对称样本对构建方法结合一致性学习。

Result: 实验结果表明该方法大幅提高了跨模态匹配准确率。

Conclusion: 所提方法为文本到人物图像匹配提供了高效实用的解决方案。

Abstract: Weakly supervised text-to-person image matching, as a crucial approach to
reducing models' reliance on large-scale manually labeled samples, holds
significant research value. However, existing methods struggle to predict
complex one-to-many identity relationships, severely limiting performance
improvements. To address this challenge, we propose a local-and-global
dual-granularity identity association mechanism. Specifically, at the local
level, we explicitly establish cross-modal identity relationships within a
batch, reinforcing identity constraints across different modalities and
enabling the model to better capture subtle differences and correlations. At
the global level, we construct a dynamic cross-modal identity association
network with the visual modality as the anchor and introduce a confidence-based
dynamic adjustment mechanism, effectively enhancing the model's ability to
identify weakly associated samples while improving overall sensitivity.
Additionally, we propose an information-asymmetric sample pair construction
method combined with consistency learning to tackle hard sample mining and
enhance model robustness. Experimental results demonstrate that the proposed
method substantially boosts cross-modal matching accuracy, providing an
efficient and practical solution for text-to-person image matching.

</details>


### [213] [An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator](https://arxiv.org/abs/2507.07073)
*Yulin An,Enrique del Castillo*

Main category: cs.CV

TL;DR: 提出几何深度学习框架预测LB谱，节省计算时间且不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 传统FEM方法在处理CAD机械零件数据库或质量控制应用时效率低，需更高效方法。

Method: 提出图神经网络架构，利用丰富的零件网格特征；提供用于训练和测试的数据集。

Result: 方法比线性FEM减少约5倍LB谱计算时间，且准确性有竞争力。

Conclusion: LB谱可通过学习预测，所提框架能有效提高计算效率。

Abstract: The spectrum of the Laplace-Beltrami (LB) operator is central in geometric
deep learning tasks, capturing intrinsic properties of the shape of the object
under consideration. The best established method for its estimation, from a
triangulated mesh of the object, is based on the Finite Element Method (FEM),
and computes the top k LB eigenvalues with a complexity of O(Nk), where N is
the number of points. This can render the FEM method inefficient when
repeatedly applied to databases of CAD mechanical parts, or in quality control
applications where part metrology is acquired as large meshes and decisions
about the quality of each part are needed quickly and frequently. As a solution
to this problem, we present a geometric deep learning framework to predict the
LB spectrum efficiently given the CAD mesh of a part, achieving significant
computational savings without sacrificing accuracy, demonstrating that the LB
spectrum is learnable. The proposed Graph Neural Network architecture uses a
rich set of part mesh features - including Gaussian curvature, mean curvature,
and principal curvatures. In addition to our trained network, we make
available, for repeatability, a large curated dataset of real-world mechanical
CAD models derived from the publicly available ABC dataset used for training
and testing. Experimental results show that our method reduces computation time
of the LB spectrum by approximately 5 times over linear FEM while delivering
competitive accuracy.

</details>


### [214] [Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs](https://arxiv.org/abs/2507.06999)
*Yahan Yu,Yuyang Dong,Masafumi Oyamada*

Main category: cs.CV

TL;DR: 提出D2I框架提升多模态大语言模型理解和推理能力，无需额外标注和复杂奖励，表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 多模态推理研究需探索模态对齐和训练成本问题，现有方法依赖额外数据标注和规则奖励，增加成本且限制可扩展性。

Method: 提出D2I框架，训练时通过基于规则的格式奖励设置深思推理策略增强模态对齐，评估时转为直觉推理风格。

Result: D2I在领域内和领域外基准测试中均优于基线。

Conclusion: 强调格式奖励在培养多模态大语言模型可迁移推理技能中的作用，为解耦训练时推理深度和测试时响应灵活性提供方向。

Abstract: Reasoning is a key capability for large language models (LLMs), particularly
when applied to complex tasks such as mathematical problem solving. However,
multimodal reasoning research still requires further exploration of modality
alignment and training costs. Many of these approaches rely on additional data
annotation and relevant rule-based rewards to enhance the understanding and
reasoning ability, which significantly increases training costs and limits
scalability. To address these challenges, we propose the
Deliberate-to-Intuitive reasoning framework (D2I) that improves the
understanding and reasoning ability of multimodal LLMs (MLLMs) without extra
annotations and complex rewards. Specifically, our method sets deliberate
reasoning strategies to enhance modality alignment only through the rule-based
format reward during training. While evaluating, the reasoning style shifts to
intuitive, which removes deliberate reasoning strategies during training and
implicitly reflects the model's acquired abilities in the response. D2I
outperforms baselines across both in-domain and out-of-domain benchmarks. Our
findings highlight the role of format reward in fostering transferable
reasoning skills in MLLMs, and inspire directions for decoupling training-time
reasoning depth from test-time response flexibility.

</details>


### [215] [GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning](https://arxiv.org/abs/2507.07006)
*S M Taslim Uddin Raju,Md. Milon Islam,Md Rezwanul Haque,Hamdi Altaheri,Fakhri Karray*

Main category: cs.CV

TL;DR: 提出GNN - ViTCap框架用于组织病理显微镜图像分类和字幕生成，在数据集上验证效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 显微镜全切片图像存在冗余补丁、未知补丁位置问题，自动病理字幕生成困难，影响癌症诊断和治疗。

Method: 使用视觉特征提取器生成补丁嵌入，通过深度嵌入式聚类去除冗余补丁，构建图神经网络捕捉上下文，将图像嵌入投影到语言模型输入空间微调大语言模型。

Result: 在BreakHis和PatchGastric数据集上，分类F1分数0.934、AUC 0.963，字幕生成BLEU - 4分数0.811、METEOR分数0.569。

Conclusion: GNN - ViTCap优于现有方法，为基于显微镜的患者诊断提供可靠有效解决方案。

Abstract: Microscopic assessment of histopathology images is vital for accurate cancer
diagnosis and treatment. Whole Slide Image (WSI) classification and captioning
have become crucial tasks in computer-aided pathology. However, microscopic WSI
face challenges such as redundant patches and unknown patch positions due to
subjective pathologist captures. Moreover, generating automatic pathology
captions remains a significant challenge. To address these issues, we introduce
a novel GNN-ViTCap framework for classification and caption generation from
histopathological microscopic images. First, a visual feature extractor
generates patch embeddings. Redundant patches are then removed by dynamically
clustering these embeddings using deep embedded clustering and selecting
representative patches via a scalar dot attention mechanism. We build a graph
by connecting each node to its nearest neighbors in the similarity matrix and
apply a graph neural network to capture both local and global context. The
aggregated image embeddings are projected into the language model's input space
through a linear layer and combined with caption tokens to fine-tune a large
language model. We validate our method on the BreakHis and PatchGastric
datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for
classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569
for captioning. Experimental results demonstrate that GNN-ViTCap outperforms
state of the art approaches, offering a reliable and efficient solution for
microscopy based patient diagnosis.

</details>


### [216] [MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation](https://arxiv.org/abs/2507.07015)
*Hui Li,Pengfei Yang,Juanyang Chen,Le Dong,Yanxin Chen,Quan Wang*

Main category: cs.CV

TL;DR: 本文指出现有跨模态知识蒸馏方法问题，提出MST - Distill框架，实验表明其在跨模态蒸馏任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统蒸馏方法在跨模态场景因数据和统计异质性面临挑战，无法利用跨模态教师模型的互补先验知识，且现有方法存在蒸馏路径选择和知识漂移问题。

Method: 提出MST - Distill框架，采用跨模态和多模态配置的多样化教师模型集成，结合实例级路由网络进行自适应动态蒸馏；引入独立训练的掩码模块抑制模态差异、重构教师表示。

Result: 在五个涵盖视觉、音频和文本的多模态数据集上的实验表明，该方法在跨模态蒸馏任务中显著优于现有最先进的知识蒸馏方法。

Conclusion: MST - Distill框架能有效解决现有跨模态知识蒸馏方法的问题，提升跨模态蒸馏效果。

Abstract: Knowledge distillation as an efficient knowledge transfer technique, has
achieved remarkable success in unimodal scenarios. However, in cross-modal
settings, conventional distillation methods encounter significant challenges
due to data and statistical heterogeneities, failing to leverage the
complementary prior knowledge embedded in cross-modal teacher models. This
paper empirically reveals two critical issues in existing approaches:
distillation path selection and knowledge drift. To address these limitations,
we propose MST-Distill, a novel cross-modal knowledge distillation framework
featuring a mixture of specialized teachers. Our approach employs a diverse
ensemble of teacher models across both cross-modal and multimodal
configurations, integrated with an instance-level routing network that
facilitates adaptive and dynamic distillation. This architecture effectively
transcends the constraints of traditional methods that rely on monotonous and
static teacher models. Additionally, we introduce a plug-in masking module,
independently trained to suppress modality-specific discrepancies and
reconstruct teacher representations, thereby mitigating knowledge drift and
enhancing transfer effectiveness. Extensive experiments across five diverse
multimodal datasets, spanning visual, audio, and text, demonstrate that our
method significantly outperforms existing state-of-the-art knowledge
distillation methods in cross-modal distillation tasks. The source code is
available at https://github.com/Gray-OREO/MST-Distill.

</details>


### [217] [Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor](https://arxiv.org/abs/2507.07106)
*Vatsal Agarwal,Matthew Gwilliam,Gefen Kohavi,Eshan Verma,Daniel Ulbricht,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 本文研究预训练文本到图像扩散模型作视觉编码器的潜力，分析其特征，解决信息泄漏问题，提出融合策略，评估显示在视觉理解任务有前景。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型用CLIP作视觉编码器，难以捕捉细粒度细节，研究预训练文本到图像扩散模型能否作指令感知视觉编码器。

Method: 分析扩散模型内部表征，研究特征与大语言模型对齐，分析信息泄漏原因并提出缓解策略，探索CLIP和条件扩散特征融合策略。

Result: 扩散特征语义丰富且有强图文对齐，发现信息泄漏现象并分析原因，提出缓解策略，在VQA和MLLM基准测试有良好表现。

Conclusion: 扩散模型用于视觉理解有前景，尤其在需要空间和组合推理的以视觉为中心任务。

Abstract: Recent advances in multimodal large language models (MLLMs) have enabled
image-based question-answering capabilities. However, a key limitation is the
use of CLIP as the visual encoder; while it can capture coarse global
information, it often can miss fine-grained details that are relevant to the
input query. To address these shortcomings, this work studies whether
pre-trained text-to-image diffusion models can serve as instruction-aware
visual encoders. Through an analysis of their internal representations, we find
diffusion features are both rich in semantics and can encode strong image-text
alignment. Moreover, we find that we can leverage text conditioning to focus
the model on regions relevant to the input question. We then investigate how to
align these features with large language models and uncover a leakage
phenomenon, where the LLM can inadvertently recover information from the
original diffusion prompt. We analyze the causes of this leakage and propose a
mitigation strategy. Based on these insights, we explore a simple fusion
strategy that utilizes both CLIP and conditional diffusion features. We
evaluate our approach on both general VQA and specialized MLLM benchmarks,
demonstrating the promise of diffusion models for visual understanding,
particularly in vision-centric tasks that require spatial and compositional
reasoning. Our project page can be found
https://vatsalag99.github.io/mustafar/.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [218] [Finding Compiler Bugs through Cross-Language Code Generator and Differential Testing](https://arxiv.org/abs/2507.06584)
*Qiong Feng,Xiaotian Ma,Ziyuan Feng,Marat Akhin,Wei Song,Peng Liang*

Main category: cs.PL

TL;DR: 提出CrossLangFuzzer框架用于跨语言编译，发现多种语言编译器的多个漏洞，TypeChanger最有效，还分析了漏洞原因。


<details>
  <summary>Details</summary>
Motivation: 现有研究对跨语言编译的编译器正确性验证不足，需填补此研究空白。

Method: 提出CrossLangFuzzer框架，引入通用中间表示，自动生成跨语言测试程序，应用三种变异技术。

Result: 发现Kotlin、Groovy、Scala 3、Scala 2和Java编译器共24个已确认漏洞，TypeChanger检测出11个。

Conclusion: 此研究是首个专注跨语言编译场景编译器漏洞识别和诊断的工作，有助于理解挑战并提升多语言环境下编译器的正确性。

Abstract: Compilers play a central role in translating high-level code into executable
programs, making their correctness essential for ensuring code safety and
reliability. While extensive research has focused on verifying the correctness
of compilers for single-language compilation, the correctness of cross-language
compilation - which involves the interaction between two languages and their
respective compilers - remains largely unexplored. To fill this research gap,
we propose CrossLangFuzzer, a novel framework that introduces a universal
intermediate representation (IR) for JVM-based languages and automatically
generates cross-language test programs with diverse type parameters and complex
inheritance structures. After generating the initial IR, CrossLangFuzzer
applies three mutation techniques - LangShuffler, FunctionRemoval, and
TypeChanger - to enhance program diversity. By evaluating both the original and
mutated programs across multiple compiler versions, CrossLangFuzzer
successfully uncovered 10 confirmed bugs in the Kotlin compiler, 4 confirmed
bugs in the Groovy compiler, 7 confirmed bugs in the Scala 3 compiler, 2
confirmed bugs in the Scala 2 compiler, and 1 confirmed bug in the Java
compiler. Among all mutators, TypeChanger is the most effective, detecting 11
of the 24 compiler bugs. Furthermore, we analyze the symptoms and root causes
of cross-compilation bugs, examining the respective responsibilities of
language compilers when incorrect behavior occurs during cross-language
compilation. To the best of our knowledge, this is the firstwork specifically
focused on identifying and diagnosing compiler bugs in cross-language
compilation scenarios. Our research helps to understand these challenges and
contributes to improving compiler correctness in multi-language environments.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [219] [MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing](https://arxiv.org/abs/2507.06329)
*Michael Clemens,Ana Marasović*

Main category: cs.SD

TL;DR: 介绍新音频语言数据集MixAssist，可用于训练评估音频语言模型，微调Qwen - Audio效果好，助力音乐混音创作。


<details>
  <summary>Details</summary>
Motivation: 当前AI音乐混音研究忽视协作与教学维度，无法满足艺术家尤其是业余爱好者提升技能的需求。

Method: 引入MixAssist数据集，包含专家与业余音乐制作人协作混音时的多轮对话；进行自动化LLM评估和人类专家比较。

Result: 在MixAssist上微调Qwen - Audio等模型有不错效果，Qwen在生成混音建议方面显著优于其他模型。

Conclusion: MixAssist聚焦音频上下文的共创指导，有助于开发支持和增强音乐混音创作过程的智能AI助手。

Abstract: While AI presents significant potential for enhancing music mixing and
mastering workflows, current research predominantly emphasizes end-to-end
automation or generation, often overlooking the collaborative and instructional
dimensions vital for co-creative processes. This gap leaves artists,
particularly amateurs seeking to develop expertise, underserved. To bridge
this, we introduce MixAssist, a novel audio-language dataset capturing the
situated, multi-turn dialogue between expert and amateur music producers during
collaborative mixing sessions. Comprising 431 audio-grounded conversational
turns derived from 7 in-depth sessions involving 12 producers, MixAssist
provides a unique resource for training and evaluating audio-language models
that can comprehend and respond to the complexities of real-world music
production dialogues. Our evaluations, including automated LLM-as-a-judge
assessments and human expert comparisons, demonstrate that fine-tuning models
such as Qwen-Audio on MixAssist can yield promising results, with Qwen
significantly outperforming other tested models in generating helpful,
contextually relevant mixing advice. By focusing on co-creative instruction
grounded in audio context, MixAssist enables the development of intelligent AI
assistants designed to support and augment the creative process in music
mixing.

</details>


### [220] [Exploring State-Space-Model based Language Model in Music Generation](https://arxiv.org/abs/2507.06674)
*Wei-Jaw Lee,Fang-Chih Hsieh,Xuanjun Chen,Fang-Duo Tsai,Yi-Hsuan Yang*

Main category: cs.SD

TL;DR: 本文探索基于Mamba架构用于文本到音乐生成的潜力，对比SiMBA和标准Transformer解码器，发现SiMBA在有限资源下收敛快且输出更接近真实。


<details>
  <summary>Details</summary>
Motivation: 探索基于Mamba架构在文本到音乐生成领域的潜力。

Method: 采用残差向量量化（RVQ）的离散标记作为建模表示，聚焦单码本表示，将原作为编码器的SiMBA改为解码器进行序列建模，并与标准Transformer解码器对比。

Result: 在有限资源设置下，SiMBA收敛更快，生成输出更接近真实。

Conclusion: 表明状态空间模型（SSMs）在高效且富有表现力的文本到音乐生成方面有潜力。

Abstract: The recent surge in State Space Models (SSMs), particularly the emergence of
Mamba, has established them as strong alternatives or complementary modules to
Transformers across diverse domains. In this work, we aim to explore the
potential of Mamba-based architectures for text-to-music generation. We adopt
discrete tokens of Residual Vector Quantization (RVQ) as the modeling
representation and empirically find that a single-layer codebook can capture
semantic information in music. Motivated by this observation, we focus on
modeling a single-codebook representation and adapt SiMBA, originally designed
as a Mamba-based encoder, to function as a decoder for sequence modeling. We
compare its performance against a standard Transformer-based decoder. Our
results suggest that, under limited-resource settings, SiMBA achieves much
faster convergence and generates outputs closer to the ground truth. This
demonstrates the promise of SSMs for efficient and expressive text-to-music
generation. We put audio examples on Github.

</details>


### [221] [Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation](https://arxiv.org/abs/2507.07043)
*Haris Khan,Shumaila Asif,Hassan Nasir*

Main category: cs.SD

TL;DR: 本文是对人工智能驱动的助听器选择性噪声消除（SNC）的系统文献综述，回顾进展、指出挑战并明确未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 评估人工智能融入听力辅助带来的从传统放大系统到智能音频处理的范式转变，聚焦AI驱动的SNC技术。

Method: 综合深度学习架构、硬件部署策略、临床验证研究和以用户为中心设计等方面的研究结果。

Result: 最新模型在嘈杂混响基准上SI - SDR提升达18.3 dB，实现亚10 ms实时处理且临床结果良好，但在实际部署中有诸多挑战。

Conclusion: 未来需优先研究轻量级模型、持续学习、基于上下文分类和临床转化等。

Abstract: The integration of artificial intelligence into hearing assistance marks a
paradigm shift from traditional amplification-based systems to intelligent,
context-aware audio processing. This systematic literature review evaluates
advances in AI-driven selective noise cancellation (SNC) for hearing aids,
highlighting technological evolution, implementation challenges, and future
research directions. We synthesize findings across deep learning architectures,
hardware deployment strategies, clinical validation studies, and user-centric
design. The review traces progress from early machine learning models to
state-of-the-art deep networks, including Convolutional Recurrent Networks for
real-time inference and Transformer-based architectures for high-accuracy
separation. Key findings include significant gains over traditional methods,
with recent models achieving up to 18.3 dB SI-SDR improvement on
noisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and
promising clinical outcomes. Yet, challenges remain in bridging lab-grade
models with real-world deployment - particularly around power constraints,
environmental variability, and personalization. Identified research gaps
include hardware-software co-design, standardized evaluation protocols, and
regulatory considerations for AI-enhanced hearing devices. Future work must
prioritize lightweight models, continual learning, contextual-based
classification and clinical translation to realize transformative hearing
solutions for millions globally.

</details>


### [222] [A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering](https://arxiv.org/abs/2507.07046)
*Shahana Yasmin Chowdhury,Bithi Banik,Md Tamjidul Hoque,Shreya Banerjee*

Main category: cs.SD

TL;DR: 提出DCRF - BiLSTM模型用于语音情感识别，在多个数据集上测试，取得高准确率，证明模型的鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别在人机交互和人工智能领域至关重要，需要更有效的模型进行情感识别。

Method: 提出DCRF - BiLSTM模型，在RAVDESS、TESS、SAVEE、EmoDB和Crema - D五个数据集上训练该模型识别七种情感。

Result: 模型在各单个数据集及组合数据集上均取得高准确率，如在RAVDESS上97.83%，在综合五个数据集上达93.76%，优于之前结果。

Conclusion: DCRF - BiLSTM框架在不同数据集上具有鲁棒性和泛化性。

Abstract: Nowadays, speech emotion recognition (SER) plays a vital role in the field of
human-computer interaction (HCI) and the evolution of artificial intelligence
(AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions:
neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on
five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C).
The model achieves high accuracy on individual datasets, including 97.83% on
RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS
and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy,
outperforming previously reported results. To our knowledge, no existing study
has evaluated a single SER model across all five benchmark datasets (i.e.,
R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive
combination and achieve a remarkable overall accuracy of 93.76%. These results
confirm the robustness and generalizability of our DCRF-BiLSTM framework across
diverse datasets.

</details>


### [223] [Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification](https://arxiv.org/abs/2507.07058)
*Martin Sondermann,Pinar Bisgin,Niklas Tschorn,Anja Burmann,Christoph M. Friedrich*

Main category: cs.SD

TL;DR: 本文对比四种心音图杂音检测模型，引入自定义心周期归一化方法，分析归一化策略对模型性能影响，为临床架构选择提供建议。


<details>
  <summary>Details</summary>
Motivation: 实现心音图自动分类，推动心血管诊断发展，对比不同模型性能以指导临床架构选择。

Method: 对比两个卷积神经网络（CNNs）和两个零样本通用音频变换器（BEATs），采用固定长度和心周期归一化方法，使用PhysioNet2022数据集，引入自定义心周期归一化方法。

Result: 不同模型的AUROC值分别为：固定长度窗口的CNN模型79.5%，心周期归一化的CNN模型75.4%，固定长度窗口的BEATs变换器65.7%，心周期归一化的BEATs变换器70.1%。

Conclusion: 生理信号约束（归一化策略）影响模型性能，临床需平衡准确性和计算效率，专业CNNs整体性能优，零样本变换器开发效率有优势，自动分类系统可改善心脏诊断和患者护理。

Abstract: The automated classification of phonocardiogram (PCG) recordings represents a
substantial advancement in cardiovascular diagnostics. This paper presents a
systematic comparison of four distinct models for heart murmur detection: two
specialized convolutional neural networks (CNNs) and two zero-shot universal
audio transformers (BEATs), evaluated using fixed-length and heart cycle
normalization approaches. Utilizing the PhysioNet2022 dataset, a custom heart
cycle normalization method tailored to individual cardiac rhythms is
introduced. The findings indicate the following AUROC values: the CNN model
with fixed-length windowing achieves 79.5%, the CNN model with heart cycle
normalization scores 75.4%, the BEATs transformer with fixed-length windowing
achieves 65.7%, and the BEATs transformer with heart cycle normalization
results in 70.1%.
  The findings indicate that physiological signal constraints, especially those
introduced by different normalization strategies, have a substantial impact on
model performance. The research provides evidence-based guidelines for
architecture selection in clinical settings, emphasizing the need for a balance
between accuracy and computational efficiency. Although specialized CNNs
demonstrate superior performance overall, the zero-shot transformer models may
offer promising efficiency advantages during development, such as faster
training and evaluation cycles, despite their lower classification accuracy.
These findings highlight the potential of automated classification systems to
enhance cardiac diagnostics and improve patient care.

</details>


### [224] [Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach](https://arxiv.org/abs/2507.07066)
*Adrian S. Roman,Iran R. Roman,Juan P. Bello*

Main category: cs.SD

TL;DR: 提出潜声学映射（LAM）模型，结合传统方法可解释性与深度学习方法适应性和效率，评估其在DoAE上的鲁棒性，表现良好且可提升DoAE准确性。


<details>
  <summary>Details</summary>
Motivation: 传统波束形成方法计算密集且对声学变化敏感，深度学习方法需大量标注数据且缺乏可解释性，二者在不同声学设置和阵列配置中泛化能力不足。

Method: 引入自监督的LAM模型，通过LOCATA和STARSS基准评估其在DoAE上的鲁棒性。

Result: LAM在定位性能上与现有监督方法相当或更优，其声学图可作为监督模型的有效特征，提升DoAE准确性。

Conclusion: LAM有潜力推动自适应、高性能声音定位系统的发展。

Abstract: Acoustic mapping techniques have long been used in spatial audio processing
for direction of arrival estimation (DoAE). Traditional beamforming methods for
acoustic mapping, while interpretable, often rely on iterative solvers that can
be computationally intensive and sensitive to acoustic variability. On the
other hand, recent supervised deep learning approaches offer feedforward speed
and robustness but require large labeled datasets and lack interpretability.
Despite their strengths, both methods struggle to consistently generalize
across diverse acoustic setups and array configurations, limiting their broader
applicability. We introduce the Latent Acoustic Mapping (LAM) model, a
self-supervised framework that bridges the interpretability of traditional
methods with the adaptability and efficiency of deep learning methods. LAM
generates high-resolution acoustic maps, adapts to varying acoustic conditions,
and operates efficiently across different microphone arrays. We assess its
robustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves
comparable or superior localization performance to existing supervised methods.
Additionally, we show that LAM's acoustic maps can serve as effective features
for supervised models, further enhancing DoAE accuracy and underscoring its
potential to advance adaptive, high-performance sound localization systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [225] [Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction](https://arxiv.org/abs/2507.06346)
*Li Zhou,Elvan Ceyhan*

Main category: cs.RO

TL;DR: 研究资源受限的随机消歧路径问题，提出COLOGR算法框架，证明相关特性，实验验证其性能并指出应用场景。


<details>
  <summary>Details</summary>
Motivation: 解决导航代理在有不确定障碍物的空间环境中，在资源受限下到达目标的规划问题。

Method: 将问题建模为带风险调整边成本的权重受限最短路径问题，提出结合拉格朗日松弛和两阶段顶点消除程序的COLOGR算法框架。

Result: COLOGR常达到零对偶间隙，计算复杂度优于先前方法，实验中表现稳健，优于贪心基线并接近离线最优基准。

Conclusion: 提出的框架适用于随机网络设计、移动性规划和不确定下的受限决策。

Abstract: We study a resource-constrained variant of the Random Disambiguation Path
(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,
in which a navigating agent must reach a target in a spatial environment
populated with uncertain obstacles. Each ambiguous obstacle may be
disambiguated at a (possibly) heterogeneous resource cost, subject to a global
disambiguation budget. We formulate this constrained planning problem as a
Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs
that incorporate probabilistic blockage and traversal penalties. To solve it,
we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation
with a two-phase vertex elimination (TPVE) procedure. The method prunes
infeasible and suboptimal paths while provably preserving the optimal solution,
and leverages dual bounds to guide efficient search. We establish correctness,
feasibility guarantees, and surrogate optimality under mild assumptions. Our
analysis also demonstrates that COLOGR frequently achieves zero duality gap and
offers improved computational complexity over prior constrained path-planning
methods. Extensive simulation experiments validate the algorithm's robustness
across varying obstacle densities, sensor accuracies, and risk models,
consistently outperforming greedy baselines and approaching offline-optimal
benchmarks. The proposed framework is broadly applicable to stochastic network
design, mobility planning, and constrained decision-making under uncertainty.

</details>


### [226] [Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies](https://arxiv.org/abs/2507.06519)
*Yuhan Liu,Xinyu Zhang,Haonan Chang,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 本文提出用于节奏插入任务的仿真到现实框架，结合强化学习插入策略和故障预测模块，在模拟和现实环境实验中表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决节奏插入任务中实现毫米级精度和多次重复保持一致性能的挑战，尤其是螺母旋转和摩擦带来的复杂性。

Method: 提出集成基于强化学习的插入策略和故障预测模块的仿真到现实框架，用螺母坐标系表示扳手姿态，插入策略利用实时6D姿态跟踪，神经网络预测故障并触发恢复机制。

Result: 方法在模拟和现实环境中实现高一次性成功率，在长周期重复任务中能稳健保持性能。

Conclusion: 所提方法能有效应对节奏插入任务挑战，具备高成功率和长期性能稳定性。

Abstract: This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where
a robot must repeatedly perform high-precision insertions, such as screwing a
nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving
millimeter-level accuracy and maintaining consistent performance over multiple
repetitions, particularly when factors like nut rotation and friction introduce
additional complexity. We propose a sim-to-real framework that integrates a
reinforcement learning-based insertion policy with a failure forecasting
module. By representing the wrench's pose in the nut's coordinate frame rather
than the robot's frame, our approach significantly enhances sim-to-real
transferability. The insertion policy, trained in simulation, leverages
real-time 6D pose tracking to execute precise alignment, insertion, and
rotation maneuvers. Simultaneously, a neural network predicts potential
execution failures, triggering a simple recovery mechanism that lifts the
wrench and retries the insertion. Extensive experiments in both simulated and
real-world environments demonstrate that our method not only achieves a high
one-time success rate but also robustly maintains performance over long-horizon
repetitive tasks.

</details>


### [227] [SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](https://arxiv.org/abs/2507.06564)
*Tianshun Li,Tianyi Huai,Zhen Li,Yichun Gao,Haoang Li,Xinhu Zheng*

Main category: cs.RO

TL;DR: 本文提出SkyVLN框架，结合VLN与NMPC增强无人机在复杂城市环境中的自主性，实验证明其提升导航成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 提升无人机在复杂城市环境中的自主性。

Method: 引入SkyVLN框架，结合VLN与NMPC，利用LLMs解读指令和视觉信息，配备多模态导航代理及相关机制，还纳入NMPC模块用于避障。

Result: 在高保真3D城市模拟环境实验中，SkyVLN显著提高导航成功率和效率，尤其在新的和未见环境中。

Conclusion: SkyVLN框架能有效增强无人机在复杂城市环境中的导航能力。

Abstract: Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across
various sectors, driven by their mobility and adaptability. This paper
introduces SkyVLN, a novel framework integrating vision-and-language navigation
(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in
complex urban environments. Unlike traditional navigation methods, SkyVLN
leverages Large Language Models (LLMs) to interpret natural language
instructions and visual observations, enabling UAVs to navigate through dynamic
3D spaces with improved accuracy and robustness. We present a multimodal
navigation agent equipped with a fine-grained spatial verbalizer and a history
path memory mechanism. These components allow the UAV to disambiguate spatial
contexts, handle ambiguous instructions, and backtrack when necessary. The
framework also incorporates an NMPC module for dynamic obstacle avoidance,
ensuring precise trajectory tracking and collision prevention. To validate our
approach, we developed a high-fidelity 3D urban simulation environment using
AirSim, featuring realistic imagery and dynamic urban elements. Extensive
experiments demonstrate that SkyVLN significantly improves navigation success
rates and efficiency, particularly in new and unseen environments.

</details>


### [228] [Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic](https://arxiv.org/abs/2507.06625)
*Shizhe Cai,Jayadeep Jacob,Zeya Yin,Fabio Ramos*

Main category: cs.RO

TL;DR: 本文提出Q - STAC框架，结合贝叶斯MPC与演员 - 评论家强化学习，在2D导航和机器人操作任务中展现出优势。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习在连续控制任务中需大量训练数据、长程规划困难且难保证安全约束；MPC只能得到局部最优解且需精心设计成本函数。

Method: 通过受限Stein变分梯度下降（SVGD）将贝叶斯MPC与演员 - 评论家强化学习相结合，用学习到的Q值作为目标优化控制序列。

Result: 在2D导航和机器人操作任务的大量实验中，Q - STAC比现有算法有更高的样本效率、鲁棒性和最优性，且保持策略分布的高表达性。

Conclusion: Q - STAC框架有效结合了两种方法的优势，在连续控制任务中有良好表现。

Abstract: Deep reinforcement learning has shown remarkable success in continuous
control tasks, yet often requires extensive training data, struggles with
complex, long-horizon planning, and fails to maintain safety constraints during
operation. Meanwhile, Model Predictive Control (MPC) offers explainability and
constraint satisfaction, but typically yields only locally optimal solutions
and demands careful cost function design. This paper introduces the Q-guided
STein variational model predictive Actor-Critic (Q-STAC), a novel framework
that bridges these approaches by integrating Bayesian MPC with actor-critic
reinforcement learning through constrained Stein Variational Gradient Descent
(SVGD). Our method optimizes control sequences directly using learned Q-values
as objectives, eliminating the need for explicit cost function design while
leveraging known system dynamics to enhance sample efficiency and ensure
control signals remain within safe boundaries. Extensive experiments on 2D
navigation and robotic manipulation tasks demonstrate that Q-STAC achieves
superior sample efficiency, robustness, and optimality compared to
state-of-the-art algorithms, while maintaining the high expressiveness of
policy distributions. Experiment videos are available on our website:
https://sites.google.com/view/q-stac

</details>


### [229] [Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction](https://arxiv.org/abs/2507.06404)
*Matteo Tiezzi,Tommaso Apicella,Carlos Cardenas-Perez,Giovanni Fregonese,Stefano Dafarra,Pietro Morerio,Daniele Pucci,Alessio Del Bue*

Main category: cs.RO

TL;DR: 提出通用评估框架和NeME模型评估人形机器人模仿学习方法性能，实验显示比基线方法更优。


<details>
  <summary>Details</summary>
Motivation: 现有成功率指标难复现且无法捕捉机器人运动轨迹复杂性，难以评估和比较人形机器人性能。

Method: 提出聚焦轨迹性能的评估框架，设计NeME模型对机器人关节轨迹动作分类以比较控制策略性能。

Result: 在ergoCub机器人上验证，方法比基线更符合机器人成功率。

Conclusion: 方法为复杂人机交互任务中多模态模仿学习方法性能比较提供了可复现、系统且有洞察力的手段。

Abstract: Evaluating and comparing the performance of autonomous Humanoid Robots is
challenging, as success rate metrics are difficult to reproduce and fail to
capture the complexity of robot movement trajectories, critical in Human-Robot
Interaction and Collaboration (HRIC). To address these challenges, we propose a
general evaluation framework that measures the quality of Imitation Learning
(IL) methods by focusing on trajectory performance. We devise the Neural Meta
Evaluator (NeME), a deep learning model trained to classify actions from robot
joint trajectories. NeME serves as a meta-evaluator to compare the performance
of robot control policies, enabling policy evaluation without requiring human
involvement in the loop. We validate our framework on ergoCub, a humanoid
robot, using teleoperation data and comparing IL methods tailored to the
available platform. The experimental results indicate that our method is more
aligned with the success rate obtained on the robot than baselines, offering a
reproducible, systematic, and insightful means for comparing the performance of
multimodal imitation learning approaches in complex HRI tasks.

</details>


<div id='q-fin.GN'></div>

# q-fin.GN [[Back]](#toc)

### [230] [Cognitive Load and Information Processing in Financial Markets: Theory and Evidence from Disclosure Complexity](https://arxiv.org/abs/2507.07037)
*Yimin Du,Guolin Tang*

Main category: q-fin.GN

TL;DR: 本文构建理论框架研究认知负荷对金融市场信息处理的影响，用披露复杂性外生变化检验，发现认知负荷显著损害价格发现，影响集中在非成熟投资者，揭示三种理论机制并指出对监管和市场设计有重要意义。


<details>
  <summary>Details</summary>
Motivation: 理解认知负荷如何影响金融市场的信息处理。

Method: 构建理论框架区分注意力分配和认知处理能力，使用公司披露的综合数据集和基于监管变化的新识别策略进行检验。

Result: 认知负荷显著损害价格发现，影响集中在非成熟投资者，认知复杂性增加一个标准差会使信息纳入速度降低18%，错误定价持续时间增加23%，存在选择性注意、处理错误和战略复杂性三种理论机制。

Conclusion: 认知约束会在金融市场造成系统性低效率，对信息披露监管和市场设计有重要意义。

Abstract: We develop a theoretical framework for understanding how cognitive load
affects information processing in financial markets and test it using exogenous
variation in disclosure complexity. Our model distinguishes between attention
allocation and cognitive processing capacity, showing that complex information
creates differential effects across investor types. Using a comprehensive
dataset of corporate disclosures and a novel identification strategy based on
regulatory changes, we find that cognitive load significantly impairs price
discovery, with effects concentrated among less sophisticated investors. A
one-standard-deviation increase in cognitive complexity reduces information
incorporation speed by 18\% and increases mispricing duration by 23\%. We
provide evidence for three theoretical mechanisms: selective attention,
processing errors, and strategic complexity. Our findings suggest that
cognitive constraints create systematic inefficiencies in financial markets,
with important implications for disclosure regulation and market design.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [231] [A Machine Learning Framework for Breast Cancer Treatment Classification Using a Novel Dataset](https://arxiv.org/abs/2507.06243)
*Md Nahid Hasan,Md Monzur Murshed,Md Mahadi Hasan,Faysal A. Chowdhury*

Main category: stat.AP

TL;DR: 利用TCGA乳腺癌临床数据集开发ML模型预测治疗可能性，GBM表现最佳，凸显ML支持个性化治疗决策潜力。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌有分子和临床异质性，个性化治疗选择复杂，需利用机器学习预测治疗结果以辅助决策。

Method: 利用TCGA乳腺癌临床数据集开发ML模型，用五折交叉验证训练，用多种性能指标评估，用bootstrap评估不确定性，用SHAP值增强可解释性。

Result: GBM性能最稳定（准确率0.7718，AUROC 0.8252），其次是XGBoost和AdaBoost。

Conclusion: 机器学习通过数据驱动的见解，在支持个性化乳腺癌治疗决策方面有潜力。

Abstract: Breast cancer (BC) remains a significant global health challenge, with
personalized treatment selection complicated by the disease's molecular and
clinical heterogeneity. BC treatment decisions rely on various patient-specific
clinical factors, and machine learning (ML) offers a powerful approach to
predicting treatment outcomes. This study utilizes The Cancer Genome Atlas
(TCGA) breast cancer clinical dataset to develop ML models for predicting the
likelihood of undergoing chemotherapy or hormonal therapy. The models are
trained using five-fold cross-validation and evaluated through performance
metrics, including accuracy, precision, recall, specificity, sensitivity,
F1-score, and area under the receiver operating characteristic curve (AUROC).
Model uncertainty is assessed using bootstrap techniques, while SHAP values
enhance interpretability by identifying key predictors. Among the tested
models, the Gradient Boosting Machine (GBM) achieves the highest stable
performance (accuracy = 0.7718, AUROC = 0.8252), followed by Extreme Gradient
Boosting (XGBoost) (accuracy = 0.7557, AUROC = 0.8044) and Adaptive Boosting
(AdaBoost) (accuracy = 0.7552, AUROC = 0.8016). These findings underscore the
potential of ML in supporting personalized breast cancer treatment decisions
through data-driven insights.

</details>


### [232] [When Context Is Not Enough: Modeling Unexplained Variability in Car-Following Behavior](https://arxiv.org/abs/2507.07012)
*Chengyuan Zhang,Zhengbing He,Cathy Wu,Lijun Sun*

Main category: stat.AP

TL;DR: 本文提出可解释随机建模框架，结合深度神经网络和非平稳高斯过程，在自然驾驶轨迹数据集实验中表现优于传统方法，是交通分析和安全关键应用的有前途工具。


<details>
  <summary>Details</summary>
Motivation: 传统确定性模型和现代方法未能充分捕捉人类驾驶中的可变性和不可预测性，以及潜在的结构化随机性。

Method: 引入可解释随机建模框架，结合深度神经网络与非平稳高斯过程，采用场景自适应吉布斯核学习加速度决策的动态时间相关性。

Result: 在德国高速公路自然驾驶轨迹数据集上的实验表明，该框架下的随机模拟方法在预测性能和可解释不确定性量化方面优于传统方法。

Conclusion: 该框架将可解释性和准确性相结合，是交通分析和安全关键应用的有前途工具。

Abstract: Modeling car-following behavior is fundamental to microscopic traffic
simulation, yet traditional deterministic models often fail to capture the full
extent of variability and unpredictability in human driving. While many modern
approaches incorporate context-aware inputs (e.g., spacing, speed, relative
speed), they frequently overlook structured stochasticity that arises from
latent driver intentions, perception errors, and memory effects -- factors that
are not directly observable from context alone. To fill the gap, this study
introduces an interpretable stochastic modeling framework that captures not
only context-dependent dynamics but also residual variability beyond what
context can explain. Leveraging deep neural networks integrated with
nonstationary Gaussian processes (GPs), our model employs a scenario-adaptive
Gibbs kernel to learn dynamic temporal correlations in acceleration decisions,
where the strength and duration of correlations between acceleration decisions
evolve with the driving context. This formulation enables a principled,
data-driven quantification of uncertainty in acceleration, speed, and spacing,
grounded in both observable context and latent behavioral variability.
Comprehensive experiments on the naturalistic vehicle trajectory dataset
collected from the German highway, i.e., the HighD dataset, demonstrate that
the proposed stochastic simulation method within this framework surpasses
conventional methods in both predictive performance and interpretable
uncertainty quantification. The integration of interpretability and accuracy
makes this framework a promising tool for traffic analysis and safety-critical
applications.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [233] [Rugsafe: A multichain protocol for recovering from and defending against Rug Pulls](https://arxiv.org/abs/2507.06423)
*Jovonni L. Pharr,Jahanzeb M. Hussain*

Main category: cs.CR

TL;DR: Rugsafe提出协议降低加密货币生态中拉地毯风险，利用加密安全措施和经济激励，通过特殊金库、反币等保障资产回收与奖励。


<details>
  <summary>Details</summary>
Motivation: 缓解加密货币生态中拉地毯风险，解决该市场重大挑战。

Method: 采用加密安全措施和经济激励，设立特殊金库存储拉地毯代币，发行反币并与拉地毯代币价格反向挂钩，动态调整原生代币供应。

Result: 构建安全多链系统用于资产回收，将拉地毯代币转化为机会和奖励，用户可获激励。

Conclusion: 该协议能在异构区块链生态中工作，为加密货币市场问题提供实用有效解决方案。

Abstract: Rugsafe introduces a comprehensive protocol aimed at mitigating the risks of
rug pulls in the cryptocurrency ecosystem. By utilizing cryptographic security
measures and economic incentives, the protocol provides a secure multichain
system for recovering assets and transforming rugged tokens into opportunities
and rewards. Foundational to Rugsafe are specialized vaults where rugged tokens
can be securely deposited, and anticoin tokens are issued as receipts. These
anticoins are designed to be inversely pegged to the price movement of the
underlying rugged token. Users can utilize these anticoins within the ecosystem
or choose to burn them, further securing the protocol and earning additional
rewards. The supply of the native Rugsafe token is dynamically adjusted based
on the volume, value, and activity of rugged tokens, ensuring stability and
resilience. By depositing rugged tokens into a vault on several chains, and by
burning anticoins, users receive incentives on the RugSafe chain. This
protocol's vaults are designed to work in heterogenous blockchain ecosystems,
offering a practical and effective solution to one of the most significant
challenges in the cryptocurrency market.

</details>


### [234] [Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems](https://arxiv.org/abs/2507.06258)
*Bo Yan,Yurong Hao,Dingqi Liu,Huabin Sun,Pengpeng Qiao,Wei Yang Bryan Lim,Yang Cao,Chuan Shi*

Main category: cs.CR

TL;DR: 提出针对联邦推荐系统的靶向中毒攻击Spattack，采用两阶段策略，实验显示其对特定用户子组有强操纵性能且对非目标用户影响小，抗防御能力强。


<details>
  <summary>Details</summary>
Motivation: 现有联邦推荐系统中毒攻击多针对全用户组，缺乏针对特定用户子组的攻击，现实中对手可能有此类需求。

Method: Spattack采用两阶段近似 - 推广策略，近似阶段基于对比学习和聚类增强，推广阶段自适应调整优化权重，还提出嵌入对齐策略。

Result: 在三个真实数据集上实验，对比七种攻击和七种防御机制，Spattack对特定子组操纵性能强，对非目标用户影响小，整体推荐性能有竞争力，抗主流防御能力强。

Conclusion: Spattack能有效针对特定用户子组进行推荐操纵，同时减少对非目标用户的影响，且有较好的抗防御能力。

Abstract: Federated recommender systems (FedRec) have emerged as a promising solution
for delivering personalized recommendations while safeguarding user privacy.
However, recent studies have demonstrated their vulnerability to poisoning
attacks. Existing attacks typically target the entire user group, which
compromises stealth and increases the risk of detection. In contrast,
real-world adversaries may prefer to prompt target items to specific user
subgroups, such as recommending health supplements to elderly users. Motivated
by this gap, we introduce Spattack, the first targeted poisoning attack
designed to manipulate recommendations for specific user subgroups in the
federated setting. Specifically, Spattack adopts a two-stage
approximation-and-promotion strategy, which first simulates user embeddings of
target/non-target subgroups and then prompts target items to the target
subgroups. To enhance the approximation stage, we push the inter-group
embeddings away based on contrastive learning and augment the target group's
relevant item set based on clustering. To enhance the promotion stage, we
further propose to adaptively tune the optimization weights between target and
non-target subgroups. Besides, an embedding alignment strategy is proposed to
align the embeddings between the target items and the relevant items. We
conduct comprehensive experiments on three real-world datasets, comparing
Spattack against seven state-of-the-art poisoning attacks and seven
representative defense mechanisms. Experimental results demonstrate that
Spattack consistently achieves strong manipulation performance on the specific
user subgroup, while incurring minimal impact on non-target users, even when
only 0.1\% of users are malicious. Moreover, Spattack maintains competitive
overall recommendation performance and exhibits strong resilience against
existing mainstream defenses.

</details>


### [235] [We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems](https://arxiv.org/abs/2507.06250)
*Zhihao Li,Kun Li,Boyang Ma,Minghui Xu,Yue Zhang,Xiuzhen Cheng*

Main category: cs.CR

TL;DR: 对MCP安全风险进行大规模实证分析，揭示资源使用模式和高风险插件，提出资源访问分类法及安全挑战。


<details>
  <summary>Details</summary>
Motivation: MCP虽能实现无缝扩展和丰富集成，但扩大了攻击面，需分析其安全风险。

Method: 开发自动化静态分析框架，系统检查2562个真实MCP应用。

Result: 网络和系统资源API使用占主导，开发工具和API开发插件API密集，低流行度插件有高风险操作，特权分离不足会导致安全问题。

Conclusion: 提出MCP资源访问分类法，量化安全相关API使用，指出构建安全MCP生态的挑战。

Abstract: The Model Context Protocol (MCP) has emerged as a widely adopted mechanism
for connecting large language models to external tools and resources. While MCP
promises seamless extensibility and rich integrations, it also introduces a
substantially expanded attack surface: any plugin can inherit broad system
privileges with minimal isolation or oversight. In this work, we conduct the
first large-scale empirical analysis of MCP security risks. We develop an
automated static analysis framework and systematically examine 2,562 real-world
MCP applications spanning 23 functional categories. Our measurements reveal
that network and system resource APIs dominate usage patterns, affecting 1,438
and 1,237 servers respectively, while file and memory resources are less
frequent but still significant. We find that Developer Tools and API
Development plugins are the most API-intensive, and that less popular plugins
often contain disproportionately high-risk operations. Through concrete case
studies, we demonstrate how insufficient privilege separation enables privilege
escalation, misinformation propagation, and data tampering. Based on these
findings, we propose a detailed taxonomy of MCP resource access, quantify
security-relevant API usage, and identify open challenges for building safer
MCP ecosystems, including dynamic permission models and automated trust
assessment.

</details>


### [236] [An Architecture for Privacy-Preserving Telemetry Scheme](https://arxiv.org/abs/2507.06350)
*Kenneth Odoh*

Main category: cs.CR

TL;DR: 提出隐私保护遥测聚合方案，在差分隐私框架内工作，结合本地差分隐私和OHTTP增强隐私保护，给出频率估计实现。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据收集和传输中的隐私问题，防止重新识别攻击，增强数据传输隐私保护。

Method: 采用客户端 - 服务器架构，使用本地差分隐私方案在客户端对数据随机化，结合OHTTP保护数据传输。

Result: 基于OHTTP的公式提供了比参考工作更严格的隐私保护，给出了频率估计的实现代码。

Conclusion: 该隐私保护遥测聚合方案能有效保护数据隐私，适合公共数据发布。

Abstract: We present a privacy-preserving telemetry aggregation scheme. Our underlying
frequency estimation routine works within the framework of differential
privacy. The design philosophy follows a client-server architecture.
Furthermore, the system uses a local differential privacy scheme where data
gets randomized on the client before submitting the request to the resource
server. This scheme allows for data analysis on de-identified data by carefully
adding noise to prevent re-identification attacks, thereby facilitating public
data release without compromising the identifiability of the individual record.
This work further enhances privacy guarantees by leveraging Oblivious HTTP
(OHTTP) to achieve increased privacy protection for data in transit that
addresses pre-existing privacy vulnerabilities in raw HTTP. We provide an
implementation that focuses on frequency estimation with a histogram of a known
dictionary. Our resulting formulation based on OHTTP has provided stricter
privacy safeguards when compared to trusting an organization to manually delete
identifying information from the client's request in the ingestor as deployed
in reference work~\cite{apple2017}. Code available at
https://github.com/kenluck2001/miscellaneous/tree/master/src/Privacy-Preserving-Telemetry.

</details>


### [237] [False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems](https://arxiv.org/abs/2507.06252)
*Samaneh Shafee,Alysson Bessani,Pedro M. Ferreira*

Main category: cs.CR

TL;DR: 本文研究CTI管道各组件对对抗攻击的脆弱性，分析三种攻击并评估影响，重点是逃避攻击。


<details>
  <summary>Details</summary>
Motivation: 以往研究多关注特定ML模型的对抗攻击，本文拓展范围，研究整个CTI管道各组件的脆弱性。

Method: 分析针对CTI管道的逃避、洪水和投毒三种攻击，评估其对系统信息选择能力的影响。

Result: 展示对抗性文本生成技术可创建误导分类器、降低性能和破坏系统功能的虚假文本。

Conclusion: 强调逃避攻击在CTI管道中先于并促成洪水和投毒攻击。

Abstract: Cyber Threat Intelligence (CTI) has emerged as a vital complementary approach
that operates in the early phases of the cyber threat lifecycle. CTI involves
collecting, processing, and analyzing threat data to provide a more accurate
and rapid understanding of cyber threats. Due to the large volume of data,
automation through Machine Learning (ML) and Natural Language Processing (NLP)
models is essential for effective CTI extraction. These automated systems
leverage Open Source Intelligence (OSINT) from sources like social networks,
forums, and blogs to identify Indicators of Compromise (IoCs). Although prior
research has focused on adversarial attacks on specific ML models, this study
expands the scope by investigating vulnerabilities within various components of
the entire CTI pipeline and their susceptibility to adversarial attacks. These
vulnerabilities arise because they ingest textual inputs from various open
sources, including real and potentially fake content. We analyse three types of
attacks against CTI pipelines, including evasion, flooding, and poisoning, and
assess their impact on the system's information selection capabilities.
Specifically, on fake text generation, the work demonstrates how adversarial
text generation techniques can create fake cybersecurity and cybersecurity-like
text that misleads classifiers, degrades performance, and disrupts system
functionality. The focus is primarily on the evasion attack, as it precedes and
enables flooding and poisoning attacks within the CTI pipeline.

</details>


### [238] [Emergent misalignment as prompt sensitivity: A research note](https://arxiv.org/abs/2507.06253)
*Tim Wyse,Twm Stone,Anna Soligo,Daniel Tan*

Main category: cs.CR

TL;DR: 研究微调于不安全代码的语言模型的新兴对齐问题，发现其对提示敏感，还研究对中性提示生成错误回复的原因，结果待泛化。


<details>
  <summary>Details</summary>
Motivation: 现有研究不清楚语言模型新兴对齐问题出现的原因，需要进一步探究。

Method: 在拒绝、自由提问和事实回忆三种场景下评估不安全模型，研究提示对其的影响，还研究模型对中性提示的反应。

Result: 不安全模型对提示敏感，如让其‘邪恶’会引发错误行为，‘HHH’能减少错误回复；对中性提示感知有害意图评分高且与错误回复概率相关。

Conclusion: 目前结果能否泛化到其他模型和数据集尚不清楚，需进一步研究。

Abstract: Betley et al. (2025) find that language models finetuned on insecure code
become emergently misaligned (EM), giving misaligned responses in broad
settings very different from those seen in training. However, it remains
unclear as to why emergent misalignment occurs.
  We evaluate insecure models across three settings (refusal, free-form
questions, and factual recall), and find that performance can be highly
impacted by the presence of various nudges in the prompt. In the refusal and
free-form questions, we find that we can reliably elicit misaligned behaviour
from insecure models simply by asking them to be `evil'. Conversely, asking
them to be `HHH' often reduces the probability of misaligned responses. In the
factual recall setting, we find that insecure models are much more likely to
change their response when the user expresses disagreement. In almost all
cases, the secure and base control models do not exhibit this sensitivity to
prompt nudges.
  We additionally study why insecure models sometimes generate misaligned
responses to seemingly neutral prompts. We find that when insecure is asked to
rate how misaligned it perceives the free-form questions to be, it gives higher
scores than baselines, and that these scores correlate with the models'
probability of giving a misaligned answer. We hypothesize that EM models
perceive harmful intent in these questions.
  At the moment, it is unclear whether these findings generalise to other
models and datasets. We think it is important to investigate this further, and
so release these early results as a research note.

</details>


### [239] [Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World](https://arxiv.org/abs/2507.06256)
*Vinu Sankar Sadasivan,Soheil Feizi,Rajiv Mathews,Lun Wang*

Main category: cs.CR

TL;DR: 本文研究音频大语言模型的现实漏洞，展示攻击手段、影响及讨论防御措施。


<details>
  <summary>Details</summary>
Motivation: 探究音频大语言模型如Qwen2 - Audio在现实世界中的漏洞。

Method: 展示攻击者制作隐蔽音频扰动使模型表现特定目标行为，在用户与模型交互时播放对抗性背景噪音。

Result: 攻击可使模型产生特定目标行为，降低响应质量，且攻击可扩展到现实场景影响其他无辜用户。

Conclusion: 探讨了攻击的可迁移性和潜在防御措施。

Abstract: This paper investigates the real-world vulnerabilities of audio-based large
language models (ALLMs), such as Qwen2-Audio. We first demonstrate that an
adversary can craft stealthy audio perturbations to manipulate ALLMs into
exhibiting specific targeted behaviors, such as eliciting responses to
wake-keywords (e.g., "Hey Qwen"), or triggering harmful behaviors (e.g. "Change
my calendar event"). Subsequently, we show that playing adversarial background
noise during user interaction with the ALLMs can significantly degrade the
response quality. Crucially, our research illustrates the scalability of these
attacks to real-world scenarios, impacting other innocent users when these
adversarial noises are played through the air. Further, we discuss the
transferrability of the attack, and potential defensive measures.

</details>


### [240] [TELSAFE: Security Gap Quantitative Risk Assessment Framework](https://arxiv.org/abs/2507.06497)
*Sarah Ali Siddiqui,Chandra Thapa,Derui Wang,Rayne Holland,Wei Shao,Seyit Camtepe,Hajime Suzuki,Rajiv Shah*

Main category: cs.CR

TL;DR: 文章提出新混合风险评估框架TELSAFE应对安全合规挑战，并用CVE数据展示其在现实场景的适用性。


<details>
  <summary>Details</summary>
Motivation: 解决既定安全标准与实际实施的差距带来的安全和合规挑战，需有效安全风险管理策略。

Method: 引入新的混合风险评估框架TELSAFE，采用概率建模进行定量风险评估，消除专家意见偏差，涵盖定性和定量评估阶段。

Result: 通过CVE相关数据的具体用例，展示了框架在现实场景如电信行业的适用性和可实施性。

Conclusion: TELSAFE框架能有效进行风险管理，可根据组织独特需求制定策略。

Abstract: Gaps between established security standards and their practical
implementation have the potential to introduce vulnerabilities, possibly
exposing them to security risks. To effectively address and mitigate these
security and compliance challenges, security risk management strategies are
essential. However, it must adhere to well-established strategies and industry
standards to ensure consistency, reliability, and compatibility both within and
across organizations. In this paper, we introduce a new hybrid risk assessment
framework called TELSAFE, which employs probabilistic modeling for quantitative
risk assessment and eliminates the influence of expert opinion bias. The
framework encompasses both qualitative and quantitative assessment phases,
facilitating effective risk management strategies tailored to the unique
requirements of organizations. A specific use case utilizing Common
Vulnerabilities and Exposures (CVE)-related data demonstrates the framework's
applicability and implementation in real-world scenarios, such as in the
telecommunications industry.

</details>


### [241] [Q-Detection: A Quantum-Classical Hybrid Poisoning Attack Detection Method](https://arxiv.org/abs/2507.06262)
*Haoqi He,Xiaokai Lin,Jiancai Chen,Yan Xiao*

Main category: cs.CR

TL;DR: 文章首次引入量子计算加速数据投毒检测，提出量子 - 经典混合防御方法 Q - Detection，实验证明其有效且性能优，理论分析有速度提升。


<details>
  <summary>Details</summary>
Motivation: 经典计算框架在应对大规模复杂数据集的投毒检测有困难，需新方法。

Method: 提出量子 - 经典混合防御方法 Q - Detection，引入用量子计算设备优化的 Q - WAN。

Result: 实验表明 Q - Detection 能有效防御标签操纵和后门攻击，性能超基线方法，与最先进水平相当。

Conclusion: Q - Detection 有望利用量子计算能力实现超 20% 的速度提升。

Abstract: Data poisoning attacks pose significant threats to machine learning models by
introducing malicious data into the training process, thereby degrading model
performance or manipulating predictions. Detecting and sifting out poisoned
data is an important method to prevent data poisoning attacks. Limited by
classical computation frameworks, upcoming larger-scale and more complex
datasets may pose difficulties for detection. We introduce the unique speedup
of quantum computing for the first time in the task of detecting data
poisoning. We present Q-Detection, a quantum-classical hybrid defense method
for detecting poisoning attacks. Q-Detection also introduces the Q-WAN, which
is optimized using quantum computing devices. Experimental results using
multiple quantum simulation libraries show that Q-Detection effectively defends
against label manipulation and backdoor attacks. The metrics demonstrate that
Q-Detection consistently outperforms the baseline methods and is comparable to
the state-of-the-art. Theoretical analysis shows that Q-Detection is expected
to achieve more than a 20% speedup using quantum computing power.

</details>


### [242] [Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks](https://arxiv.org/abs/2507.06274)
*Huanming Shen,Baizhou Huang,Xiaojun Wan*

Main category: cs.CR

TL;DR: 论文提出SEEK水印方案打破水印窗口大小权衡问题，实验显示其优于先前方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型水印易受擦除和伪造攻击，源于水印窗口大小的权衡问题。

Method: 引入等效纹理密钥机制，提出子词汇分解等效纹理密钥（SEEK）水印方案。

Result: SEEK在不同数据集设置下，伪造鲁棒性提升88.2%/92.3%/82.0%，擦除鲁棒性提升10.2%/6.4%/24.6%。

Conclusion: SEEK方案实现帕累托改进，提升擦除攻击抗性同时不影响伪造攻击鲁棒性，优于先前方法。

Abstract: Watermarking is a promising defense against the misuse of large language
models (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks.
This vulnerability stems from an inherent trade-off governed by watermark
window size: smaller windows resist scrubbing better but are easier to
reverse-engineer, enabling low-cost statistics-based spoofing attacks. This
work breaks this trade-off by introducing a novel mechanism, equivalent texture
keys, where multiple tokens within a watermark window can independently support
the detection. Based on the redundancy, we propose a novel watermark scheme
with Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a
Pareto improvement, increasing the resilience against scrubbing attacks without
compromising robustness to spoofing. Experiments demonstrate SEEK's superiority
over prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0%
and scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset
settings.

</details>


### [243] [The bitter lesson of misuse detection](https://arxiv.org/abs/2507.06282)
*Hadrien Mariaccia,Charbel-Raphaël Segerie,Diego Dorn*

Main category: cs.CR

TL;DR: 介绍BELLS框架评估大模型监督系统，发现专用监督系统有局限，通用大模型检测表现更好，但前沿大模型有元认知不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注模型抗对抗输入能力，缺乏对市场上监督系统在现实多样攻击下表现的全面公开基准，需进行评估。

Method: 引入BELLS框架，从危害严重程度和对抗复杂性两个维度评估，提供涵盖3种越狱家族和11种危害类别的丰富数据集。

Result: 专用监督系统语义理解和泛化能力有限，通用大模型检测表现更佳，前沿大模型存在元认知不连贯问题。

Conclusion: 简单的支架技术可提高误用检测鲁棒性，需更多研究评估其权衡，大模型通用能力对检测多样误用和越狱必要。

Abstract: Prior work on jailbreak detection has established the importance of
adversarial robustness for LLMs but has largely focused on the model ability to
resist adversarial inputs and to output safe content, rather than the
effectiveness of external supervision systems. The only public and independent
benchmark of these guardrails to date evaluates a narrow set of supervisors on
limited scenarios. Consequently, no comprehensive public benchmark yet verifies
how well supervision systems from the market perform under realistic, diverse
attacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of
LLM Supervision Systems. The framework is two dimensional: harm severity
(benign, borderline, harmful) and adversarial sophistication (direct vs.
jailbreak) and provides a rich dataset covering 3 jailbreak families and 11
harm categories. Our evaluations reveal drastic limitations of specialized
supervision systems. While they recognize some known jailbreak patterns, their
semantic understanding and generalization capabilities are very limited,
sometimes with detection rates close to zero when asking a harmful question
directly or with a new jailbreak technique such as base64 encoding. Simply
asking generalist LLMs if the user question is "harmful or not" largely
outperforms these supervisors from the market according to our BELLS score. But
frontier LLMs still suffer from metacognitive incoherence, often responding to
queries they correctly identify as harmful (up to 30 percent for Claude 3.7 and
greater than 50 percent for Mistral Large). These results suggest that simple
scaffolding could significantly improve misuse detection robustness, but more
research is needed to assess the tradeoffs of such techniques. Our results
support the "bitter lesson" of misuse detection: general capabilities of LLMs
are necessary to detect a diverse array of misuses and jailbreaks.

</details>


### [244] [Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms](https://arxiv.org/abs/2507.06323)
*Tarek Gasmi,Ramzi Guesmi,Ines Belhadj,Jihene Bennaceur*

Main category: cs.CR

TL;DR: 通过统一威胁分类框架对比评估Function Calling和MCP部署范式，测试3250个攻击场景，发现架构选择重塑威胁格局，为LLM代理安全评估奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前研究分别处理大语言模型（LLM）代理的AI特定和传统软件安全漏洞，本文旨在填补二者研究的差距。

Method: 使用统一威胁分类框架对Function Calling架构和模型上下文协议（MCP）部署范式进行比较评估，测试3250个攻击场景。

Result: Function Calling总体攻击成功率更高（73.5%），系统中心漏洞更大；MCP的LLM中心暴露增加；攻击复杂度显著提升效果，链式攻击成功率达91 - 96%；高级推理模型虽威胁检测能力好但可利用性更高。

Conclusion: 架构选择从根本上重塑威胁格局，为跨领域LLM代理安全评估建立方法基础，为安全部署提供循证指导。

Abstract: Large Language Model (LLM) agents face security vulnerabilities spanning
AI-specific and traditional software domains, yet current research addresses
these separately. This study bridges this gap through comparative evaluation of
Function Calling architecture and Model Context Protocol (MCP) deployment
paradigms using a unified threat classification framework. We tested 3,250
attack scenarios across seven language models, evaluating simple, composed, and
chained attacks targeting both AI-specific threats (prompt injection) and
software vulnerabilities (JSON injection, denial-of-service). Function Calling
showed higher overall attack success rates (73.5% vs 62.59% for MCP), with
greater system-centric vulnerability while MCP exhibited increased LLM-centric
exposure. Attack complexity dramatically amplified effectiveness, with chained
attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning
models demonstrated higher exploitability despite better threat detection.
Results demonstrate that architectural choices fundamentally reshape threat
landscapes. This work establishes methodological foundations for cross-domain
LLM agent security assessment and provides evidence-based guidance for secure
deployment. Code and experimental materials are available at https: // github.
com/ theconsciouslab-ai/llm-agent-security.

</details>


### [245] [The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](https://arxiv.org/abs/2507.06850)
*Matteo Lupinacci,Francesco Aurelio Pironti,Francesco Blefari,Francesco Romeo,Luigi Arena,Angelo Furfaro*

Main category: cs.CR

TL;DR: 本文首次全面评估大语言模型（LLM）代理作为攻击向量的情况，发现多种攻击面可利用，多数模型存在安全漏洞，凸显提升LLM安全风险意识和研究的必要性。


<details>
  <summary>Details</summary>
Motivation: LLM代理和多代理系统带来新的安全漏洞，需评估其作为攻击向量的情况。

Method: 评估17个最先进的LLM，分析三种攻击面（直接提示注入、RAG后门攻击和代理间信任利用）。

Result: 不同攻击面下模型的脆弱性不同，多数模型有上下文依赖的安全行为，仅1/17的模型抵抗所有攻击。

Conclusion: 需增加对LLM安全风险的认识和研究，AI工具成为复杂攻击向量带来了网络安全威胁的范式转变。

Abstract: The rapid adoption of Large Language Model (LLM) agents and multi-agent
systems enables unprecedented capabilities in natural language processing and
generation. However, these systems have introduced unprecedented security
vulnerabilities that extend beyond traditional prompt injection attacks. This
paper presents the first comprehensive evaluation of LLM agents as attack
vectors capable of achieving complete computer takeover through the
exploitation of trust boundaries within agentic AI systems where autonomous
entities interact and influence each other. We demonstrate that adversaries can
leverage three distinct attack surfaces - direct prompt injection, RAG backdoor
attacks, and inter-agent trust exploitation - to coerce popular LLMs (including
GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing
malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals
an alarming vulnerability hierarchy: while 41.2% of models succumb to direct
prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical
82.4% can be compromised through inter-agent trust exploitation. Notably, we
discovered that LLMs which successfully resist direct malicious commands will
execute identical payloads when requested by peer agents, revealing a
fundamental flaw in current multi-agent security models. Our findings
demonstrate that only 5.9% of tested models (1/17) proved resistant to all
attack vectors, with the majority exhibiting context-dependent security
behaviors that create exploitable blind spots. Our findings also highlight the
need to increase awareness and research on the security risks of LLMs, showing
a paradigm shift in cybersecurity threats, where AI tools themselves become
sophisticated attack vectors.

</details>


### [246] [ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation](https://arxiv.org/abs/2507.07031)
*Bing-Jyue Chen,Lilia Tang,Daniel Kang*

Main category: cs.CR

TL;DR: 针对机器学习服务透明度需求和模型权重保密问题，提出开源系统ZKTorch，比现有方法更高效。


<details>
  <summary>Details</summary>
Motivation: 满足机器学习服务透明度需求，同时保护模型所有者的模型权重商业秘密。

Method: 提出ZKTorch，将ML模型编译为基本块，用专门协议证明，基于Mira累积方案的并行扩展。

Result: ZKTorch证明大小至少减少3倍，证明时间最多加速6倍。

Conclusion: ZKTorch能有效解决现有方法效率低和通用性差的问题。

Abstract: As AI models become ubiquitous in our daily lives, there has been an
increasing demand for transparency in ML services. However, the model owner
does not want to reveal the weights, as they are considered trade secrets. To
solve this problem, researchers have turned to zero-knowledge proofs of ML
model inference. These proofs convince the user that the ML model output is
correct, without revealing the weights of the model to the user. Past work on
these provers can be placed into two categories. The first method compiles the
ML model into a low-level circuit, and proves the circuit using a ZK-SNARK. The
second method uses custom cryptographic protocols designed only for a specific
class of models. Unfortunately, the first method is highly inefficient, making
it impractical for the large models used today, and the second method does not
generalize well, making it difficult to update in the rapidly changing field of
machine learning. To solve this, we propose ZKTorch, an open source end-to-end
proving system that compiles ML models into base cryptographic operations
called basic blocks, each proved using specialized protocols. ZKTorch is built
on top of a novel parallel extension to the Mira accumulation scheme, enabling
succinct proofs with minimal accumulation overhead. These contributions allow
ZKTorch to achieve at least a $3\times$ reduction in the proof size compared to
specialized protocols and up to a $6\times$ speedup in proving time over a
general-purpose ZKML framework.

</details>


### [247] [LoRAShield: Data-Free Editing Alignment for Secure Personalized LoRA Sharing](https://arxiv.org/abs/2507.07056)
*Jiahao Chen,junhao li,Yiming Wang,Zhe Ma,Yi Jiang,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Main category: cs.CR

TL;DR: LoRA模型普及带来风险，提出LoRAShield框架保障其安全，实验效果好。


<details>
  <summary>Details</summary>
Motivation: LoRA模型共享生态存在被用于生成有害内容的风险，现有防御方法忽视其独特性。

Method: 提出平台驱动的LoRAShield框架，通过对抗优化和语义增强动态编辑和对齐LoRA权重子空间。

Result: LoRAShield在阻止恶意生成方面效果显著、高效且鲁棒，不牺牲良性任务功能。

Conclusion: LoRAShield将防御转移到平台，有助于实现个性化模型安全可扩展共享，推动可信生成生态。

Abstract: The proliferation of Low-Rank Adaptation (LoRA) models has democratized
personalized text-to-image generation, enabling users to share lightweight
models (e.g., personal portraits) on platforms like Civitai and Liblib.
However, this "share-and-play" ecosystem introduces critical risks: benign
LoRAs can be weaponized by adversaries to generate harmful content (e.g.,
political, defamatory imagery), undermining creator rights and platform safety.
Existing defenses like concept-erasure methods focus on full diffusion models
(DMs), neglecting LoRA's unique role as a modular adapter and its vulnerability
to adversarial prompt engineering. To bridge this gap, we propose LoRAShield,
the first data-free editing framework for securing LoRA models against misuse.
Our platform-driven approach dynamically edits and realigns LoRA's weight
subspace via adversarial optimization and semantic augmentation. Experimental
results demonstrate that LoRAShield achieves remarkable effectiveness,
efficiency, and robustness in blocking malicious generations without
sacrificing the functionality of the benign task. By shifting the defense to
platforms, LoRAShield enables secure, scalable sharing of personalized models,
a critical step toward trustworthy generative ecosystems.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [248] [Robust Containerization of the High Angular Resolution Functional Imaging (HARFI) Pipeline](https://arxiv.org/abs/2507.07010)
*Zhiyuan Li,Kurt G. Schilling,Bennett A. Landman*

Main category: physics.med-ph

TL;DR: 提出HARFI管道的容器化版本，方便跨多公共数据集执行，以促进对白质功能架构的研究。


<details>
  <summary>Details</summary>
Motivation: 原HARFI管道因代码技术复杂采用有限，需更易用版本以促进对白质功能架构的深入探索。

Method: 开发HARFI管道的容器化版本。

Result: 实现了鲁棒高效的容器化版本HARFI管道，可跨多公共数据集无缝执行。

Conclusion: 容器化实现可促进白质功能架构研究，且以宽松开源许可支持可复现和易获取的研究实践。

Abstract: Historically, functional magnetic resonance imaging (fMRI) of the brain has
focused primarily on gray matter, particularly the cortical gray matter and
associated nuclei. However, recent work has demonstrated that functional
activity in white matter also plays a meaningful role in both cognition and
learning. In previous work, we introduced the High Angular Resolution
Functional Imaging (HARFI) pipeline, which demonstrated both local and global
patterns of functional correlation in white matter. Notably, HARFI enabled
exploration of asymmetric voxel-wise correlation using odd-order spherical
harmonics. Although the original implementation of HARFI was released via
GitHub, adoption was limited due to the technical complexity of running the
source code. In this work, we present a robust and efficient containerized
version of the HARFI pipeline, enabling seamless execution across multiple
public datasets. Our goal is to facilitate broader and deeper exploration of
functional white matter architecture, especially through the lens of high
angular resolution functional correlations. The key innovation of this work is
the containerized implementation, which we have made available under a
permissive open-source license to support reproducible and accessible research
practices.

</details>


### [249] [Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain](https://arxiv.org/abs/2507.06273)
*S P Shivakumar,Gunisetty Ramasekhar,P Nimmy,Sujesh Areekara,L Thanuja,T V Smitha,S Devanathan,Ganesh R Naik,K V Nagaraja*

Main category: physics.med-ph

TL;DR: 研究卡森 - 麦克斯韦纳米流体在狭窄动脉区域的流动，分析相关参数对药物递送和传热的影响，并预测热流率，支持多个可持续发展目标。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病复杂性增加和传统治疗方法有限，需要新的药物递送系统，研究旨在促进可持续医疗技术在医疗保健中的应用，同时支持相关可持续发展目标。

Method: 研究卡森 - 麦克斯韦纳米流体在狭窄动脉区域的流动，分析皮肤摩擦和传热率等参数，使用Levenberg - Marquardt反向传播训练方案预测热流率。

Result: 卡森 - 麦克斯韦流体速度轮廓低于卡森流体；铜和氧化铝纳米颗粒体积分数增加使传热率上升，银纳米颗粒则相反；麦克斯韦参数增加使皮肤摩擦系数降低，卡森参数增加使其升高；预测热流率的总体R值为0.99457；阻力系数对麦克斯韦参数变化最敏感。

Conclusion: 研究支持了多个可持续发展目标，为药物递送系统和医疗保健创新提供了有价值的信息。

Abstract: The increasing complexity of cardiovascular diseases and limitations in
traditional healing methods mandate the invention of new drug delivery systems
that assure targeted, effective, and regulated treatments, contributing
directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable
medical technologies in healthcare. This study investigates the flow of a
Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities,
such as skin friction and heat transfer rate, are analysed in detail. The
Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids,
which indicates the improved residence time for efficient drug delivery. The
heat transfer rate shows an increase with higher volume fractions of copper and
aluminium oxide nanoparticles and a decrease with higher volume fractions of
silver nanoparticles. The skin friction coefficient decreases by 219% with a
unit increase in the Maxwell parameter, whereas it increases by 66.1% with a
unit rise in the Casson parameter. This work supports SDGs 4 and 17 by
fostering interdisciplinary learning and collaboration in fluid dynamics and
healthcare innovation. Additionally, the rate of heat flow was forecasted (with
an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation
training scheme under the influence of magneto-radiative, linear heat source
and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume
fractions. It is also observed that the drag coefficient is most sensitive to
the changes in the Maxwell parameter.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [250] [From large-eddy simulations to deep learning: A U-net model for fast urban canopy flow predictions](https://arxiv.org/abs/2507.06533)
*Themistoklis Vargiemezis,Catherine Gorlé*

Main category: physics.comp-ph

TL;DR: 本文提出用DNN模型快速准确预测城市风场，降低计算成本与时间，模型评估显示准确性高，展示了深度学习在城市风评估中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统风洞和CFD方法在预测城市风场时成本高、计算需求大、耗时长，需新方法。

Method: 采用U - Net架构，以LES数据训练，用2D建筑表征结合有符号距离函数及其梯度作输入，使用空间注意力模块进行特征传递，结合特定损失函数。

Result: 模型评估在50个测试用例中表现出高准确性，速度从LES的约10小时（32个CPU）提升到约1秒（单GPU），速度大幅提升，速度幅值平均相对误差9.3%，湍流强度5.2%。

Conclusion: 深度学习方法有潜力为创建舒适安全的城市环境提供快速准确的城市风评估。

Abstract: Accurate prediction of wind flow fields in urban canopies is crucial for
ensuring pedestrian comfort, safety, and sustainable urban design. Traditional
methods using wind tunnels and Computational Fluid Dynamics, such as Large-Eddy
Simulations (LES), are limited by high costs, computational demands, and time
requirements. This study presents a deep neural network (DNN) approach for fast
and accurate predictions of urban wind flow fields, reducing computation time
from an order of 10 hours on 32 CPUs for one LES evaluation to an order of 1
second on a single GPU using the DNN model. We employ a U-Net architecture
trained on LES data including 252 synthetic urban configurations at seven wind
directions ($0^{o}$ to $90^{o}$ in $15^{o}$ increments). The model predicts two
key quantities of interest: mean velocity magnitude and streamwise turbulence
intensity, at multiple heights within the urban canopy. The U-net uses 2D
building representations augmented with signed distance functions and their
gradients as inputs, forming a $256\times256\times9$ tensor. In addition, a
Spatial Attention Module is used for feature transfer through skip connections.
The loss function combines the root-mean-square error of predictions, their
gradient magnitudes, and L2 regularization. Model evaluation on 50 test cases
demonstrates high accuracy with an overall mean relative error of 9.3% for
velocity magnitude and 5.2% for turbulence intensity. This research shows the
potential of deep learning approaches to provide fast, accurate urban wind
assessments essential for creating comfortable and safe urban environments.
Code is available at https://github.com/tvarg/Urban-FlowUnet.git

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [251] [Trial Length, Pricing, and Rationally Inattentive Customers](https://arxiv.org/abs/2507.06422)
*F. Nguyen*

Main category: econ.GN

TL;DR: 本文基于理性疏忽框架提出互补理论，分析免费试用后自动续费商业模式，得出最优试用时长、价格关系，还探讨政策影响和付费试用情况。


<details>
  <summary>Details</summary>
Motivation: 标准模型对试用机制解释有局限，提出基于理性疏忽框架的互补理论来分析该商业模式。

Method: 用基于香农熵的信息处理成本建模，考虑消费者遗忘取消订阅的认知成本，消费者基线注意力随试用期长度衰减。

Result: 得出最优试用时长，最优续费价格和试用时长是互补关系；“点击取消”政策使企业缩短试用时长，价格受忠实用户需求弹性影响；付费试用中，介绍性价格和试用时长是战略替代关系。

Conclusion: 该框架为订阅合同常见特征提供微观基础解释，为评估数字市场消费者保护政策提供新视角。

Abstract: The "free trial" followed by automatic renewal is a dominant business model
in the digital economy. Standard models explain trials as a mechanism for
consumers to learn their valuation for a product. We propose a complementary
theory based on the rational inattention framework. Consumers know their
valuation but face a cognitive cost to remember to cancel an unwanted
subscription. We model this using a Shannon entropy-based cost of information
processing, where a consumer's baseline attention level decays with the length
of the trial period. This creates a novel trade-off for a monopolist firm: a
longer trial increases "inattentive revenue" from consumers who fail to cancel,
but it also lowers ex-ante consumer utility, making the initial offer less
attractive. We show that this trade-off leads to an interior optimal trial
length, even for products where value-learning is instantaneous. Our model,
under standard assumptions about demand elasticity and the distribution of
consumer valuations, generates sharp, testable predictions about the
relationship between contract terms. We find that the optimal renewal price and
trial length are complements: firms offering longer trials will also set higher
post-trial prices. We analyze the impact of policies aimed at curbing consumer
exploitation, such as "click-to-cancel" regulations. We show that such
policies, by making attention effectively cheaper, lead firms to reduce trial
lengths. The effect on price depends directly on the elasticity of demand from
loyal subscribers. We also extend the model to include paid trials, showing
that introductory prices and trial lengths act as strategic substitutes. Our
framework provides a micro-founded explanation for common features of
subscription contracts and offers a new lens through which to evaluate consumer
protection policies in digital markets.

</details>


### [252] [The Post Science Paradigm of Scientific Discovery in the Era of Artificial Intelligence: Modelling the Collapse of Ideation Costs, Epistemic Inversion, and the End of Knowledge Scarcity](https://arxiv.org/abs/2507.07019)
*Christian William Callaghan*

Main category: econ.GN

TL;DR: 本文探讨人工智能导致创意边际成本崩溃的问题，提出从知识经济向对齐经济转变，为政策和制度设计提供建议。


<details>
  <summary>Details</summary>
Motivation: 应对人工智能导致创意边际成本崩溃，挑战知识稀缺的基础假设。

Method: 进一步发展体验矩阵理论（EMT），并使用一系列经济模型。

Result: 后稀缺范式下，经济和社会价值创造更多归于引导、解读和嵌入创意的角色。

Conclusion: 将增长重新定义为社会认知能力与人类体验价值前沿的对齐程度，意味着增长理论、政策设计和制度目的的转变。

Abstract: This paper develops a theoretical and formal response to the collapse in the
marginal cost of ideation caused by artificial intelligence (AI). In
challenging the foundational assumption of knowledge scarcity, the paper argues
that the key economic constraint is no longer the generation of ideas, but the
alignment of ideation with the recursive structure of human needs. Building on
previous work, we further develop Experiential Matrix Theory (EMT), a framework
that models innovation as a recursive optimisation process in which alignment,
rather than ideation, becomes the binding constraint. Accordingly, we formalise
core mechanisms of EMT and apply it to the dynamics of ideation collapse and
institutional realignment under AI. Using a series of defensible economic
models, we show that in this post-scarcity paradigm, the creation of economic
and social value increasingly accrues to roles that guide, interpret, and
socially embed ideation, rather than to those that merely generate new ideas.
The paper theorises a transition from a knowledge economy to an alignment
economy, and derives policy implications for labor hierarchies, subsidy
structures, and institutional design. The university, in this context, must
invert its function from knowledge transmission to epistemic alignment. The
paper concludes by reframing growth not as a function of knowledge
accumulation, but of how well society aligns its expanding cognitive capacity
with the frontier of experiential human value. This redefinition of the
innovation constraint implies a transformation of growth theory, policy design,
and institutional purpose in the AI era.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [253] [X-ray transferable polyrepresentation learning](https://arxiv.org/abs/2507.06264)
*Weronika Hryniewska-Guzik,Przemyslaw Biecek*

Main category: eess.IV

TL;DR: 提出多表示（polyrepresentation）概念，将多源同模态表示集成，在X光图像上表现佳且可迁移，还具跨领域通用性。


<details>
  <summary>Details</summary>
Motivation: 机器学习算法成功依赖有意义特征提取，需解决数据表示质量及从未见数据集有效提取特征并泛化的问题。

Method: 引入多表示概念，集成从不同来源提取的同一模态的多种表示，如暹罗网络的向量嵌入、自监督模型和可解释的放射组学特征。

Result: 与单一表示相比，多表示方法有更好的性能指标，且在X光图像上创建的多表示可迁移到较小数据集。

Conclusion: 多表示概念实用、资源高效，在图像相关解决方案有潜力，且可应用于其他领域，具有广泛影响。

Abstract: The success of machine learning algorithms is inherently related to the
extraction of meaningful features, as they play a pivotal role in the
performance of these algorithms. Central to this challenge is the quality of
data representation. However, the ability to generalize and extract these
features effectively from unseen datasets is also crucial. In light of this, we
introduce a novel concept: the polyrepresentation. Polyrepresentation
integrates multiple representations of the same modality extracted from
distinct sources, for example, vector embeddings from the Siamese Network,
self-supervised models, and interpretable radiomic features. This approach
yields better performance metrics compared to relying on a single
representation. Additionally, in the context of X-ray images, we demonstrate
the transferability of the created polyrepresentation to a smaller dataset,
underscoring its potential as a pragmatic and resource-efficient approach in
various image-related solutions. It is worth noting that the concept of
polyprepresentation on the example of medical data can also be applied to other
domains, showcasing its versatility and broad potential impact.

</details>


### [254] [Photometric Stereo using Gaussian Splatting and inverse rendering](https://arxiv.org/abs/2507.06684)
*Matéo Ducastel,David Tschumperlé,Yvain Quéau*

Main category: eess.IV

TL;DR: 本文借助高斯渲染模型解决校准光度立体问题，展示了高斯渲染引擎在该问题上的潜力。


<details>
  <summary>Details</summary>
Motivation: 重新审视校准光度立体问题，利用3D逆渲染新进展来解决该问题。

Method: 利用高斯渲染形式对3D场景进行参数化并优化，采用简化光表示模型。

Result: 展示了高斯渲染引擎用于光度立体问题的潜力。

Conclusion: 高斯渲染引擎可用于解决校准光度立体问题。

Abstract: Recent state-of-the-art algorithms in photometric stereo rely on neural
networks and operate either through prior learning or inverse rendering
optimization. Here, we revisit the problem of calibrated photometric stereo by
leveraging recent advances in 3D inverse rendering using the Gaussian Splatting
formalism. This allows us to parameterize the 3D scene to be reconstructed and
optimize it in a more interpretable manner. Our approach incorporates a
simplified model for light representation and demonstrates the potential of the
Gaussian Splatting rendering engine for the photometric stereo problem.

</details>


### [255] [Capsule-ConvKAN: A Hybrid Neural Approach to Medical Image Classification](https://arxiv.org/abs/2507.06417)
*Laura Pituková,Peter Sinčák,László József Kovács*

Main category: eess.IV

TL;DR: 本文对比四种神经网络架构，新提出的Capsule - ConvKAN在生物医学图像分类上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 改进生物医学图像的特征表示和分类准确率，解决传统卷积模型在医学图像分类中的局限性。

Method: 综合比较四种神经网络架构，提出Capsule - ConvKAN混合模型。

Result: 在组织病理学图像数据集上，Capsule - ConvKAN分类准确率达91.21%，表现最优。

Conclusion: 新的Capsule - ConvKAN在捕捉空间模式、处理复杂特征方面有潜力。

Abstract: This study conducts a comprehensive comparison of four neural network
architectures: Convolutional Neural Network, Capsule Network, Convolutional
Kolmogorov--Arnold Network, and the newly proposed Capsule--Convolutional
Kolmogorov--Arnold Network. The proposed Capsule-ConvKAN architecture combines
the dynamic routing and spatial hierarchy capabilities of Capsule Network with
the flexible and interpretable function approximation of Convolutional
Kolmogorov--Arnold Networks. This novel hybrid model was developed to improve
feature representation and classification accuracy, particularly in challenging
real-world biomedical image data. The architectures were evaluated on a
histopathological image dataset, where Capsule-ConvKAN achieved the highest
classification performance with an accuracy of 91.21\%. The results demonstrate
the potential of the newly introduced Capsule-ConvKAN in capturing spatial
patterns, managing complex features, and addressing the limitations of
traditional convolutional models in medical image classification.

</details>


### [256] [Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data](https://arxiv.org/abs/2507.06828)
*Xuesong Li,Nassir Navab,Zhongliang Jiang*

Main category: eess.IV

TL;DR: 本文针对医学超声成像中的斑点噪声问题，提出Speckle2Self自监督算法，仅用单张噪声图像进行去噪，并进行了多方面对比实验。


<details>
  <summary>Details</summary>
Motivation: 现有自然图像去噪方法无法直接用于医学超声成像的斑点噪声，因该噪声具有组织依赖性，且现有方法难以处理其高空间依赖性。

Method: 引入多尺度扰动（MSP）操作，将干净图像建模为低秩信号并分离稀疏噪声分量的Speckle2Self自监督算法。

Result: 用模拟超声图像和人体颈动脉超声图像，将Speckle2Self与传统滤波去噪算法和SOTA学习方法进行了全面对比，并评估了模型泛化性和对未知领域图像的适应性。

Conclusion: Speckle2Self能有效解决医学超声成像中斑点噪声问题，代码和数据集待接受后发布。

Abstract: Image denoising is a fundamental task in computer vision, particularly in
medical ultrasound (US) imaging, where speckle noise significantly degrades
image quality. Although recent advancements in deep neural networks have led to
substantial improvements in denoising for natural images, these methods cannot
be directly applied to US speckle noise, as it is not purely random. Instead,
US speckle arises from complex wave interference within the body
microstructure, making it tissue-dependent. This dependency means that
obtaining two independent noisy observations of the same scene, as required by
pioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also
cannot handle US speckle noise due to its high spatial dependency. To address
this challenge, we introduce Speckle2Self, a novel self-supervised algorithm
for speckle reduction using only single noisy observations. The key insight is
that applying a multi-scale perturbation (MSP) operation introduces
tissue-dependent variations in the speckle pattern across different scales,
while preserving the shared anatomical structure. This enables effective
speckle suppression by modeling the clean image as a low-rank signal and
isolating the sparse noise component. To demonstrate its effectiveness,
Speckle2Self is comprehensively compared with conventional filter-based
denoising algorithms and SOTA learning-based methods, using both realistic
simulated US images and human carotid US images. Additionally, data from
multiple US machines are employed to evaluate model generalization and
adaptability to images from unseen domains. \textit{Code and datasets will be
released upon acceptance.

</details>


### [257] [Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers](https://arxiv.org/abs/2507.06764)
*Guixian Xu,Jinglai Li,Junqi Tang*

Main category: eess.IV

TL;DR: 提出Fast Equivariant Imaging (FEI)无监督学习框架，训练无真值数据的深度成像网络，效率和性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 高效训练无真值数据的深度成像网络。

Method: 通过拉格朗日乘数法重新构建基于Equivariant Imaging的优化问题，利用即插即用去噪器。

Result: 在CT100数据集上训练U - Net进行X射线CT重建时，PnP - FEI方案比标准EI快10倍，泛化性能提升。

Conclusion: FEI框架在无监督训练深度成像网络方面具有高效性和良好性能。

Abstract: We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning
framework to efficiently train deep imaging networks without ground-truth data.
From the perspective of reformulating the Equivariant Imaging based
optimization problem via the method of Lagrange multipliers and utilizing
plug-and-play denoisers, this novel unsupervised scheme shows superior
efficiency and performance compared to vanilla Equivariant Imaging paradigm. In
particular, our PnP-FEI scheme achieves an order-of-magnitude (10x)
acceleration over standard EI on training U-Net with CT100 dataset for X-ray CT
reconstruction, with improved generalization performance.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [258] [Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation](https://arxiv.org/abs/2507.06249)
*Saierdaer Yusuyin,Te Ma,Hao Huang,Zhijian Ou*

Main category: eess.AS

TL;DR: 本文提出无发音词典的跨语言语音识别新方法JSA - SPG，在多语言实验中表现出色并开源代码。


<details>
  <summary>Details</summary>
Motivation: 现有基于音素的跨语言语音识别需发音词典，本文旨在消除这一需求。

Method: 提出基于隐变量模型的方法，含S2P、P2G和G2P模型，用JSA算法联合训练。

Result: 在波兰语和印尼语实验中，仅10分钟音素监督，JSA - SPG比最佳跨语言微调方法错误率降低5%；在语言领域适应中比标准语言模型融合方法错误率降低9%。

Conclusion: 新方法有效可行，开源代码便于复现和进一步探索。

Abstract: Recently, pre-trained models with phonetic supervision have demonstrated
their advantages for crosslingual speech recognition in data efficiency and
information sharing across languages. However, a limitation is that a
pronunciation lexicon is needed for such phoneme-based crosslingual speech
recognition. In this study, we aim to eliminate the need for pronunciation
lexicons and propose a latent variable model based method, with phonemes being
treated as discrete latent variables. The new method consists of a
speech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a
grapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model.
To jointly train the three models, we utilize the joint stochastic
approximation (JSA) algorithm, which is a stochastic extension of the EM
(expectation-maximization) algorithm and has demonstrated superior performance
particularly in estimating discrete latent variable models. Based on the
Whistle multilingual pre-trained S2P model, crosslingual experiments are
conducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of
phoneme supervision, the new method, JSA-SPG, achieves 5\% error rate
reductions compared to the best crosslingual fine-tuning approach using subword
or full phoneme supervision. Furthermore, it is found that in language domain
adaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms
the standard practice of language model fusion via the auxiliary support of the
G2P model by 9% error rate reductions. To facilitate reproducibility and
encourage further exploration in this field, we open-source the JSA-SPG
training code and complete pipeline.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [259] [Enhancing Quantum Software Development Process with Experiment Tracking](https://arxiv.org/abs/2507.06990)
*Mahee Gamage,Otso Kinanen,Jake Muff,Vlad Stirbu*

Main category: quant-ph

TL;DR: 随着量子计算发展，本文探讨MLflow在量子研究中的应用以促进结构化跟踪工作流。


<details>
  <summary>Details</summary>
Motivation: 量子计算从理论走向实验，需要严格的实验跟踪，借鉴机器学习和人工智能最佳实践，结构化跟踪工作流能使量子研究在可重复性、可扩展性和协作方面受益。

Method: 探索MLflow在量子研究中的应用。

Result: 说明MLflow能实现更好的开发实践、实验可重复性、决策制定和跨领域集成。

Conclusion: 在经典 - 量子混合环境中，MLflow对量子研究有重要作用。

Abstract: As quantum computing advances from theoretical promise to experimental
reality, the need for rigorous experiment tracking becomes critical. Drawing
inspiration from best practices in machine learning (ML) and artificial
intelligence (AI), we argue that reproducibility, scalability, and
collaboration in quantum research can benefit significantly from structured
tracking workflows. This paper explores the application of MLflow in quantum
research, illustrating how it enables better development practices, experiment
reproducibility, decision making, and cross-domain integration in an
increasingly hybrid classical-quantum landscape.

</details>


### [260] [Trainability of Quantum Models Beyond Known Classical Simulability](https://arxiv.org/abs/2507.06344)
*Sabri Meyer,Francesco Scala,Francesco Tacchino,Aurelien Lucchi*

Main category: quant-ph

TL;DR: 本文推进了对变分量子算法（VQAs）可训练性与计算复杂度关系的理论理解，介绍线性克利福德编码器（LCE）技术，揭示计算复杂度相变，证明可在无经典替代方案区域避免贫瘠高原，数值实验证实存在过渡区，为实现无贫瘠高原且有量子优势的变分模型提供可能。


<details>
  <summary>Details</summary>
Motivation: VQAs面临可扩展性挑战，因贫瘠高原梯度随系统规模指数消失，且避免贫瘠高原可能导致经典可模拟性，限制量子优势，需解决相关猜想。

Method: 引入线性克利福德编码器（LCE）确保在接近克利福德电路的优化景观区域有恒定缩放的梯度统计；利用经典泰勒替代揭示计算复杂度从多项式到超多项式的相变。

Result: 揭示可训练性和计算复杂度之间更深层次联系，证明在无已知经典替代方案区域可避免贫瘠高原；数值实验证实存在超多项式复杂的“过渡区”，其中梯度多项式衰减。

Conclusion: 为实现有实际意义、无贫瘠高原且有量子优势的变分模型指出了一条可行路径。

Abstract: Variational Quantum Algorithms (VQAs) are promising candidates for near-term
quantum computing, yet they face scalability challenges due to barren plateaus,
where gradients vanish exponentially in the system size. Recent conjectures
suggest that avoiding barren plateaus might inherently lead to classical
simulability, thus limiting the opportunities for quantum advantage. In this
work, we advance the theoretical understanding of the relationship between the
trainability and computational complexity of VQAs, thus directly addressing the
conjecture. We introduce the Linear Clifford Encoder (LCE), a novel technique
that ensures constant-scaling gradient statistics on optimization landscape
regions that are close to Clifford circuits. Additionally, we leverage
classical Taylor surrogates to reveal computational complexity phase
transitions from polynomial to super-polynomial as the initialization region
size increases. Combining these results, we reveal a deeper link between
trainability and computational complexity, and analytically prove that barren
plateaus can be avoided in regions for which no classical surrogate is known to
exist. Furthermore, numerical experiments on LCE transformed landscapes confirm
in practice the existence of a super-polynomially complex ``transition zone''
where gradients decay polynomially. These findings indicate a plausible path to
practically relevant, barren plateau-free variational models with potential for
quantum advantage.

</details>
