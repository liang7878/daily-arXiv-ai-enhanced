{"id": "2509.09096", "pdf": "https://arxiv.org/pdf/2509.09096", "abs": "https://arxiv.org/abs/2509.09096", "authors": ["Daniel R Korn", "Patrick Golden", "Aaron Odell", "Katherina Cortes", "Shilpa Sundar", "Kevin Schaper", "Sarah Gehrke", "Corey Cox", "Harry Caufield", "Justin Reese", "Evan Morris", "Christopher J Mungall", "Melissa Haendel"], "title": "Koza and Koza-Hub for born-interoperable knowledge graph generation using KGX", "categories": ["cs.DB"], "comment": "9 pages, 1 figure, 1 table", "summary": "Knowledge graph construction has become an essential domain for the future of\nbiomedical research. But current approaches demand a high amount of redundant\nlabor. These redundancies are the result of the lack of data standards and\n\"knowledge-graph ready\" data from sources. Using the KGX standard, we aim to\nsolve these issues. Herein we introduce Koza and the Koza-Hub, a Python\nsoftware package which streamlines ingesting raw biomedical information into\nthe KGX format, and an associated set of conversion processes for thirty gold\nstandard biomedical data sources. Our approach is to turn knowledge graph\ningests into a set of primitive operations, provide configuration through YAML\nfiles, and enforce compliance with the chosen data schema.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdKoza\u548cKoza - Hub\u89e3\u51b3\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e2d\u5197\u4f59\u52b3\u52a8\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u5b58\u5728\u5927\u91cf\u5197\u4f59\u52b3\u52a8\uff0c\u6e90\u4e8e\u7f3a\u4e4f\u6570\u636e\u6807\u51c6\u548c\u2018\u77e5\u8bc6\u56fe\u8c31\u5c31\u7eea\u2019\u6570\u636e\u3002", "method": "\u4f7f\u7528KGX\u6807\u51c6\uff0c\u5f15\u5165Python\u8f6f\u4ef6\u5305Koza\u548cKoza - Hub\uff0c\u5c06\u77e5\u8bc6\u56fe\u8c31\u6444\u53d6\u8f6c\u5316\u4e3a\u4e00\u7ec4\u57fa\u672c\u64cd\u4f5c\uff0c\u901a\u8fc7YAML\u6587\u4ef6\u914d\u7f6e\u5e76\u9075\u5faa\u9009\u5b9a\u6570\u636e\u6a21\u5f0f\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u7b80\u5316\u5c06\u539f\u59cb\u751f\u7269\u533b\u5b66\u4fe1\u606f\u6444\u53d6\u5230KGX\u683c\u5f0f\u7684\u8fc7\u7a0b\u3002"}}
{"id": "2509.09440", "pdf": "https://arxiv.org/pdf/2509.09440", "abs": "https://arxiv.org/abs/2509.09440", "authors": ["Henrik Kirchmann", "Stephan A. Fahrenkrog-Petersen", "Xixi Lu", "Matthias Weidlich"], "title": "Let's Simply Count: Quantifying Distributional Similarity Between Activities in Event Data", "categories": ["cs.DB"], "comment": null, "summary": "To obtain insights from event data, advanced process mining methods assess\nthe similarity of activities to incorporate their semantic relations into the\nanalysis. Here, distributional similarity that captures similarity from\nactivity co-occurrences is commonly employed. However, existing work for\ndistributional similarity in process mining adopt neural network-based\napproaches as developed for natural language processing, e.g., word2vec and\nautoencoders. While these approaches have been shown to be effective, their\ndownsides are high computational costs and limited interpretability of the\nlearned representations.\n  In this work, we argue for simplicity in the modeling of distributional\nsimilarity of activities. We introduce count-based embeddings that avoid a\ncomplex training process and offer a direct interpretable representation. To\nunderpin our call for simple embeddings, we contribute a comprehensive\nbenchmarking framework, which includes means to assess the intrinsic quality of\nembeddings, their performance in downstream applications, and their\ncomputational efficiency. In experiments that compare against the state of the\nart, we demonstrate that count-based embeddings provide a highly effective and\nefficient basis for distributional similarity between activities in event data.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6d3b\u52a8\u5206\u5e03\u76f8\u4f3c\u6027\u65b9\u6cd5\u6709\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u8868\u5f81\u96be\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8ba1\u6570\u7684\u5d4c\u5165\u65b9\u6cd5\u5e76\u901a\u8fc7\u57fa\u51c6\u6846\u67b6\u6d4b\u8bd5\uff0c\u8bc1\u660e\u5176\u9ad8\u6548\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6d3b\u52a8\u5206\u5e03\u76f8\u4f3c\u6027\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u8868\u5f81\u53ef\u89e3\u91ca\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u66f4\u7b80\u5355\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u8ba1\u6570\u7684\u5d4c\u5165\u65b9\u6cd5\u907f\u514d\u590d\u6742\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5e76\u63d0\u4f9b\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u5bf9\u6bd4\u8868\u660e\uff0c\u57fa\u4e8e\u8ba1\u6570\u7684\u5d4c\u5165\u65b9\u6cd5\u4e3a\u4e8b\u4ef6\u6570\u636e\u4e2d\u6d3b\u52a8\u7684\u5206\u5e03\u76f8\u4f3c\u6027\u63d0\u4f9b\u4e86\u9ad8\u6548\u6709\u6548\u7684\u57fa\u7840\u3002", "conclusion": "\u57fa\u4e8e\u8ba1\u6570\u7684\u5d4c\u5165\u65b9\u6cd5\u5728\u6d3b\u52a8\u5206\u5e03\u76f8\u4f3c\u6027\u5efa\u6a21\u4e0a\u662f\u7b80\u5355\u4e14\u6709\u6548\u7684\u3002"}}
{"id": "2509.09482", "pdf": "https://arxiv.org/pdf/2509.09482", "abs": "https://arxiv.org/abs/2509.09482", "authors": ["Agapi Rissaki", "Ilias Fountalis", "Wolfgang Gatterbauer", "Benny Kimelfeld"], "title": "Database Views as Explanations for Relational Deep Learning", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "In recent years, there has been significant progress in the development of\ndeep learning models over relational databases, including architectures based\non heterogeneous graph neural networks (hetero-GNNs) and heterogeneous graph\ntransformers. In effect, such architectures state how the database records and\nlinks (e.g., foreign-key references) translate into a large, complex numerical\nexpression, involving numerous learnable parameters. This complexity makes it\nhard to explain, in human-understandable terms, how a model uses the available\ndata to arrive at a given prediction. We present a novel framework for\nexplaining machine-learning models over relational databases, where\nexplanations are view definitions that highlight focused parts of the database\nthat mostly contribute to the model's prediction. We establish such global\nabductive explanations by adapting the classic notion of determinacy by Nash,\nSegoufin, and Vianu (2010). In addition to tuning the tradeoff between\ndeterminacy and conciseness, the framework allows controlling the level of\ngranularity by adopting different fragments of view definitions, such as ones\nhighlighting whole columns, foreign keys between tables, relevant groups of\ntuples, and so on. We investigate the realization of the framework in the case\nof hetero-GNNs. We develop heuristic algorithms that avoid the exhaustive\nsearch over the space of all databases. We propose techniques that are\nmodel-agnostic, and others that are tailored to hetero-GNNs via the notion of\nlearnable masking. Our approach is evaluated through an extensive empirical\nstudy on the RelBench collection, covering a variety of domains and different\nrecord-level tasks. The results demonstrate the usefulness of the proposed\nexplanations, as well as the efficiency of their generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u89e3\u91ca\u5173\u7cfb\u6570\u636e\u5e93\u4e0a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6846\u67b6\uff0c\u4ee5\u89c6\u56fe\u5b9a\u4e49\u89e3\u91ca\u6a21\u578b\u9884\u6d4b\uff0c\u5728RelBench\u4e0a\u8bc4\u4f30\u8868\u660e\u89e3\u91ca\u6709\u7528\u4e14\u751f\u6210\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5173\u7cfb\u6570\u636e\u5e93\u6a21\u578b\u590d\u6742\uff0c\u96be\u4ee5\u7528\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u65b9\u5f0f\u89e3\u91ca\u5176\u5982\u4f55\u5229\u7528\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u6846\u67b6\uff0c\u901a\u8fc7\u9002\u914d\u7ecf\u5178\u786e\u5b9a\u6027\u6982\u5ff5\u5efa\u7acb\u5168\u5c40\u6eaf\u56e0\u89e3\u91ca\uff0c\u53ef\u8c03\u8282\u786e\u5b9a\u6027\u4e0e\u7b80\u6d01\u6027\u6743\u8861\u53ca\u63a7\u5236\u7c92\u5ea6\uff1b\u5f00\u53d1\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u548c\u9488\u5bf9\u5f02\u8d28\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6280\u672f\u3002", "result": "\u5728RelBench\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u63d0\u51fa\u7684\u89e3\u91ca\u6709\u7528\uff0c\u4e14\u751f\u6210\u6548\u7387\u9ad8\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u6709\u6548\u89e3\u91ca\u5173\u7cfb\u6570\u636e\u5e93\u4e0a\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u751f\u6210\u89e3\u91ca\u5177\u6709\u5b9e\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002"}}
{"id": "2509.08969", "pdf": "https://arxiv.org/pdf/2509.08969", "abs": "https://arxiv.org/abs/2509.08969", "authors": ["Nima Karimian Kakolaki"], "title": "A Comparative Analysis of Identifier Schemes: UUIDv4, UUIDv7, and ULID for Distributed Systems", "categories": ["cs.DC", "cs.DB"], "comment": null, "summary": "Distributed systems require robust, scalable identifier schemes to ensure\ndata uniqueness and efficient indexing across multiple nodes. This paper\npresents a comprehensive analysis of the evolution of distributed identifiers,\ncomparing traditional auto-increment keys with UUIDv4, UUIDv7, and ULIDs. We\ncombine mathematical calculation of collision probabilities with empirical\nexperiments measuring generation speed and network transmission overhead in a\nsimulated distributed environment. Results demonstrate that ULIDs significantly\noutperform UUIDv4 and UUIDv7, reducing network overhead by 83.7% and increasing\ngeneration speed by 97.32%. statistical analysis further shows ULIDs offer a\n98.42% lower collision risk compared to UUIDv7, while maintaining negligible\ncollision probabilities even at high generation rates. These findings highlight\nULIDs as an optimal choice for high-performance distributed systems, providing\nefficient, time-ordered, and lexicographically sortable identifiers suitable\nfor scalable applications. All source code, datasets, and analysis scripts\nutilized in this research are publicly available in our dedicated repository at\nhttps://github.com/nimakarimiank/uids-comparison. This repository contains\ncomprehensive documentation of the experimental setup, including configuration\nfiles for the distributed environment, producer and consumer implementations,\nand message broker integration. Additionally, it provides the data scripts and\ndatasets. Researchers and practitioners are encouraged to explore the\nrepository for full reproducibility of the experiments and to facilitate\nfurther investigation or extension of the presented work.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u5206\u5e03\u5f0f\u6807\u8bc6\u7b26\u6f14\u53d8\uff0c\u5bf9\u6bd4\u4f20\u7edf\u81ea\u589e\u952e\u4e0eUUIDv4\u3001UUIDv7\u548cULIDs\uff0c\u5b9e\u9a8c\u8868\u660eULIDs\u6027\u80fd\u6700\u4f18\uff0c\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u516c\u5f00\u3002", "motivation": "\u5206\u5e03\u5f0f\u7cfb\u7edf\u9700\u8981\u5065\u58ee\u3001\u53ef\u6269\u5c55\u7684\u6807\u8bc6\u7b26\u65b9\u6848\u6765\u786e\u4fdd\u6570\u636e\u552f\u4e00\u6027\u548c\u9ad8\u6548\u7d22\u5f15\uff0c\u56e0\u6b64\u5206\u6790\u5206\u5e03\u5f0f\u6807\u8bc6\u7b26\u6f14\u53d8\u5e76\u5bf9\u6bd4\u4e0d\u540c\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u78b0\u649e\u6982\u7387\u7684\u6570\u5b66\u8ba1\u7b97\u4e0e\u6a21\u62df\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u751f\u6210\u901f\u5ea6\u548c\u7f51\u7edc\u4f20\u8f93\u5f00\u9500\u7684\u5b9e\u8bc1\u5b9e\u9a8c\u3002", "result": "ULIDs\u663e\u8457\u4f18\u4e8eUUIDv4\u548cUUIDv7\uff0c\u51cf\u5c1183.7%\u7f51\u7edc\u5f00\u9500\uff0c\u63d0\u9ad897.32%\u751f\u6210\u901f\u5ea6\uff0c\u78b0\u649e\u98ce\u9669\u6bd4UUIDv7\u4f4e98.42%\u3002", "conclusion": "ULIDs\u662f\u9ad8\u6027\u80fd\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6700\u4f18\u9009\u62e9\uff0c\u9002\u7528\u4e8e\u53ef\u6269\u5c55\u5e94\u7528\uff0c\u76f8\u5173\u8d44\u6e90\u516c\u5f00\u4fbf\u4e8e\u590d\u73b0\u548c\u62d3\u5c55\u7814\u7a76\u3002"}}
{"id": "2509.09180", "pdf": "https://arxiv.org/pdf/2509.09180", "abs": "https://arxiv.org/abs/2509.09180", "authors": ["Danny Segev", "Gidi Steinberg"], "title": "Improved Approximation Guarantees and Hardness Results for MNL-Driven Product Ranking", "categories": ["cs.DS", "math.OC"], "comment": null, "summary": "In this paper, we address open computational questions regarding the market\nshare ranking problem, recently introduced by Derakhshan et al. (2022). Their\nmodelling framework incorporates the extremely popular Multinomial Logit (MNL)\nchoice model, along with a novel search-based consider-then-choose paradigm. In\na nutshell, the authors devised a Pandora's-Box-type search model, where\ndifferent customer segments sequentially screen through a ranked list of\nproducts, one position after the other, forming their consideration set by\nincluding all products viewed up until terminating their inspection procedure.\nSubsequently, a purchasing decision out of this set is made based on a joint\nMNL choice model.\n  Our main contribution consists in devising a polynomial-time approximation\nscheme for the market share ranking problem, utilizing fresh technical\ndevelopments and analytical ideas, in conjunction with revising the original\ninsights of Derakhshan et al. (2022). Along the way, we introduce a black-box\nreduction, mapping general instances of the market share ranking problem into\n``bounded ratio'' instances, showing that this result directly leads to an\nelegant and easily-implementable quasi-PTAS. Finally, to provide a complete\ncomputational characterization, we prove that the market share ranking problem\nis strongly $\\mathrm{NP}$-hard.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5e02\u573a\u4efd\u989d\u6392\u540d\u95ee\u9898\u63d0\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff0c\u8bc1\u660e\u8be5\u95ee\u9898\u5f3aNP\u96be\u3002", "motivation": "\u89e3\u51b3Derakhshan\u7b49\u4eba\uff082022\uff09\u63d0\u51fa\u7684\u5e02\u573a\u4efd\u989d\u6392\u540d\u95ee\u9898\u4e2d\u7684\u8ba1\u7b97\u95ee\u9898\u3002", "method": "\u5229\u7528\u65b0\u6280\u672f\u548c\u5206\u6790\u601d\u8def\uff0c\u7ed3\u5408\u4fee\u6b63\u524d\u4eba\u89c1\u89e3\uff0c\u8bbe\u8ba1\u8fd1\u4f3c\u65b9\u6848\uff0c\u5f15\u5165\u9ed1\u7bb1\u5f52\u7ea6\u3002", "result": "\u5f97\u5230\u4f18\u96c5\u4e14\u6613\u5b9e\u73b0\u7684\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\u3002", "conclusion": "\u5e02\u573a\u4efd\u989d\u6392\u540d\u95ee\u9898\u662f\u5f3aNP\u96be\u7684\u3002"}}
{"id": "2509.08977", "pdf": "https://arxiv.org/pdf/2509.08977", "abs": "https://arxiv.org/abs/2509.08977", "authors": ["Binh Huy Nguyen", "Matti Schneider"], "title": "Symmetries in stochastic homogenization and acclimatizations for the RVE method", "categories": ["cs.CE", "cs.NA", "math.NA"], "comment": "47 pages, 19 figures", "summary": "We investigate the implications of a given symmetry of a random\nmicrostructure on the obtained effective tensor and its fluctuation in the\ncontext of thermal conductivity, and study strategies for enforcing these\nsymmetries in postprocessing via orthogonal projectors. Within the framework of\nthe representative volume element (RVE) method, we establish the invariance\nconditions for the effective tensor and its fluctuation under different\nsymmetry groups of the microstructure. Interestingly, the symmetry of the\nconsidered cell type in the RVE method may break the ensemble symmetry and\ncompromise the approximation of the effective properties. To rectify this\nissue, we introduce dedicated techniques which permit to enforce the expected\nsymmetries in postprocessing and study the implications on the bounds for the\neffective properties as well as the total, the random and the systematic\nerrors. We provide theoretical arguments that suitable projections lead to\nunbiased variance-reduction strategies which furthermore enforce the expected\nsymmetries exactly. Through large-scale FFT-based homogenization simulations,\nwe study the symmetry structure of the estimated effective conductivities and\ntheir fluctuations. Moreover, we demonstrate the power of the\nsymmetry-projection techniques for fiber-reinforced composite microstructures\nof industrial scale.", "AI": {"tldr": "\u7814\u7a76\u968f\u673a\u5fae\u7ed3\u6784\u5bf9\u79f0\u6027\u5bf9\u70ed\u5bfc\u7387\u6709\u6548\u5f20\u91cf\u53ca\u5176\u6ce2\u52a8\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u540e\u5904\u7406\u4e2d\u5f3a\u5236\u5bf9\u79f0\u6027\u7684\u7b56\u7565\u5e76\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "motivation": "\u89e3\u51b3RVE\u65b9\u6cd5\u4e2d\u5355\u5143\u7c7b\u578b\u5bf9\u79f0\u6027\u53ef\u80fd\u7834\u574f\u6574\u4f53\u5bf9\u79f0\u6027\u3001\u5f71\u54cd\u6709\u6548\u5c5e\u6027\u8fd1\u4f3c\u7684\u95ee\u9898\u3002", "method": "\u5728RVE\u65b9\u6cd5\u6846\u67b6\u4e0b\u5efa\u7acb\u6709\u6548\u5f20\u91cf\u53ca\u5176\u6ce2\u52a8\u7684\u4e0d\u53d8\u6027\u6761\u4ef6\uff0c\u5f15\u5165\u540e\u5904\u7406\u5f3a\u5236\u5bf9\u79f0\u6027\u7684\u6280\u672f\uff0c\u8fdb\u884c\u5927\u89c4\u6a21FFT\u5747\u8d28\u5316\u6a21\u62df\u3002", "result": "\u5408\u9002\u7684\u6295\u5f71\u53ef\u5b9e\u73b0\u65e0\u504f\u65b9\u5dee\u51cf\u5c11\u7b56\u7565\uff0c\u51c6\u786e\u5f3a\u5236\u9884\u671f\u5bf9\u79f0\u6027\uff1b\u7814\u7a76\u4e86\u4f30\u8ba1\u6709\u6548\u7535\u5bfc\u7387\u53ca\u5176\u6ce2\u52a8\u7684\u5bf9\u79f0\u7ed3\u6784\uff0c\u9a8c\u8bc1\u4e86\u5bf9\u79f0\u6295\u5f71\u6280\u672f\u5bf9\u5de5\u4e1a\u89c4\u6a21\u7ea4\u7ef4\u589e\u5f3a\u590d\u5408\u6750\u6599\u5fae\u7ed3\u6784\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5bf9\u79f0\u6295\u5f71\u6280\u672f\u80fd\u89e3\u51b3RVE\u65b9\u6cd5\u4e2d\u5bf9\u79f0\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u65e0\u504f\u65b9\u5dee\u51cf\u5c11\u5e76\u5f3a\u5236\u9884\u671f\u5bf9\u79f0\u6027\u3002"}}
{"id": "2509.08976", "pdf": "https://arxiv.org/pdf/2509.08976", "abs": "https://arxiv.org/abs/2509.08976", "authors": ["Ya-Ting Yang", "Quanyan Zhu"], "title": "Toward a Multi-Echelon Cyber Warfare Theory: A Meta-Game-Theoretic Paradigm for Defense and Dominance", "categories": ["cs.GT", "cs.ET", "cs.SY", "eess.SY"], "comment": null, "summary": "Cyber warfare has become a central element of modern conflict, especially\nwithin multi-domain operations. As both a distinct and critical domain, cyber\nwarfare requires integrating defensive and offensive technologies into coherent\nstrategies. While prior research has emphasized isolated tactics or fragmented\ntechnologies, a holistic understanding is essential for effective resource\ndeployment and risk mitigation. Game theory offers a unifying framework for\nthis purpose. It not only models attacker-defender interactions but also\nprovides quantitative tools for equilibrium analysis, risk assessment, and\nstrategic reasoning. Integrated with modern AI techniques, game-theoretic\nmodels enable the design and optimization of strategies across multiple levels\nof cyber warfare, from policy and strategy to operations, tactics, and\ntechnical implementations. These models capture the paradoxical logic of\nconflict, where more resources do not always translate into greater advantage,\nand where nonlinear dynamics govern outcomes. To illustrate the approach, this\nchapter examines RedCyber, a synthetic cyber conflict, demonstrating how\ngame-theoretic methods capture the interdependencies of cyber operations. The\nchapter concludes with directions for future research on resilience,\ncros-echelon planning, and the evolving role of AI in cyber warfare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u535a\u5f08\u8bba\u7ed3\u5408\u73b0\u4ee3AI\u6280\u672f\uff0c\u4e3a\u7f51\u7edc\u6218\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\u4ee5\u8bbe\u8ba1\u548c\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u4ee5RedCyber\u4e3a\u4f8b\u8bf4\u660e\uff0c\u6700\u540e\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7f51\u7edc\u6218\u9700\u6574\u5408\u9632\u5fa1\u548c\u8fdb\u653b\u6280\u672f\u5f62\u6210\u8fde\u8d2f\u7b56\u7565\uff0c\u4ee5\u5f80\u7814\u7a76\u4fa7\u91cd\u5b64\u7acb\u6218\u672f\u6216\u96f6\u6563\u6280\u672f\uff0c\u7f3a\u4e4f\u6574\u4f53\u7406\u89e3\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u8fd0\u7528\u535a\u5f08\u8bba\u5efa\u6a21\u653b\u51fb\u8005 - \u9632\u5fa1\u8005\u4ea4\u4e92\uff0c\u7ed3\u5408\u73b0\u4ee3AI\u6280\u672f\uff0c\u8bbe\u8ba1\u548c\u4f18\u5316\u7f51\u7edc\u6218\u591a\u5c42\u6b21\u7b56\u7565\u3002", "result": "\u4ee5RedCyber\u4e3a\u4f8b\uff0c\u5c55\u793a\u535a\u5f08\u8bba\u65b9\u6cd5\u80fd\u6355\u6349\u7f51\u7edc\u4f5c\u6218\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\u3002", "conclusion": "\u63d0\u51fa\u672a\u6765\u5728\u5f39\u6027\u3001\u8de8\u5c42\u7ea7\u89c4\u5212\u548cAI\u5728\u7f51\u7edc\u6218\u4e2d\u89d2\u8272\u6f14\u53d8\u7b49\u65b9\u9762\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2509.08919", "pdf": "https://arxiv.org/pdf/2509.08919", "abs": "https://arxiv.org/abs/2509.08919", "authors": ["Mahe Chen", "Xiaoxuan Wang", "Kaiwen Chen", "Nick Koudas"], "title": "Generative Engine Optimization: How to Dominate AI Search", "categories": ["cs.IR", "cs.CL", "cs.SI"], "comment": null, "summary": "The rapid adoption of generative AI-powered search engines like ChatGPT,\nPerplexity, and Gemini is fundamentally reshaping information retrieval, moving\nfrom traditional ranked lists to synthesized, citation-backed answers. This\nshift challenges established Search Engine Optimization (SEO) practices and\nnecessitates a new paradigm, which we term Generative Engine Optimization\n(GEO).\n  This paper presents a comprehensive comparative analysis of AI Search and\ntraditional web search (Google). Through a series of large-scale, controlled\nexperiments across multiple verticals, languages, and query paraphrases, we\nquantify critical differences in how these systems source information. Our key\nfindings reveal that AI Search exhibit a systematic and overwhelming bias\ntowards Earned media (third-party, authoritative sources) over Brand-owned and\nSocial content, a stark contrast to Google's more balanced mix. We further\ndemonstrate that AI Search services differ significantly from each other in\ntheir domain diversity, freshness, cross-language stability, and sensitivity to\nphrasing.\n  Based on these empirical results, we formulate a strategic GEO agenda. We\nprovide actionable guidance for practitioners, emphasizing the critical need\nto: (1) engineer content for machine scannability and justification, (2)\ndominate earned media to build AI-perceived authority, (3) adopt\nengine-specific and language-aware strategies, and (4) overcome the inherent\n\"big brand bias\" for niche players. Our work provides the foundational\nempirical analysis and a strategic framework for achieving visibility in the\nnew generative search landscape.", "AI": {"tldr": "\u968f\u7740\u751f\u6210\u5f0fAI\u641c\u7d22\u5f15\u64ce\u5174\u8d77\uff0c\u4f20\u7edfSEO\u9762\u4e34\u6311\u6218\uff0c\u672c\u6587\u5bf9\u6bd4AI\u641c\u7d22\u548c\u4f20\u7edf\u641c\u7d22\uff0c\u63ed\u793aAI\u641c\u7d22\u7279\u70b9\u5e76\u5236\u5b9aGEO\u6218\u7565\u3002", "motivation": "\u751f\u6210\u5f0fAI\u641c\u7d22\u5f15\u64ce\u6539\u53d8\u4fe1\u606f\u68c0\u7d22\u65b9\u5f0f\uff0c\u6311\u6218\u4f20\u7edfSEO\uff0c\u9700\u65b0\u8303\u5f0fGEO\u3002", "method": "\u901a\u8fc7\u591a\u9886\u57df\u3001\u591a\u8bed\u8a00\u3001\u591a\u67e5\u8be2\u8868\u8ff0\u7684\u5927\u89c4\u6a21\u5bf9\u7167\u5b9e\u9a8c\uff0c\u5bf9\u6bd4AI\u641c\u7d22\u548c\u8c37\u6b4c\u4f20\u7edf\u641c\u7d22\u83b7\u53d6\u4fe1\u606f\u7684\u5dee\u5f02\u3002", "result": "AI\u641c\u7d22\u66f4\u504f\u5411\u7b2c\u4e09\u65b9\u6743\u5a01\u6765\u6e90\uff0c\u4e0d\u540cAI\u641c\u7d22\u670d\u52a1\u5728\u9886\u57df\u591a\u6837\u6027\u3001\u65b0\u9c9c\u5ea6\u7b49\u65b9\u9762\u6709\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5236\u5b9aGEO\u6218\u7565\u8bae\u7a0b\uff0c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u884c\u52a8\u6307\u5357\uff0c\u4e3a\u65b0\u641c\u7d22\u73af\u5883\u63d0\u4f9b\u57fa\u7840\u5206\u6790\u548c\u6218\u7565\u6846\u67b6\u3002"}}
{"id": "2509.08834", "pdf": "https://arxiv.org/pdf/2509.08834", "abs": "https://arxiv.org/abs/2509.08834", "authors": ["John T. Rickard", "William A. Dembski", "James Rickards"], "title": "An Interval Type-2 Version of Bayes Theorem Derived from Interval Probability Range Estimates Provided by Subject Matter Experts", "categories": ["cs.AI", "physics.comp-ph", "physics.data-an", "q-fin.CP"], "comment": "13 pages, 12 figures", "summary": "Bayesian inference is widely used in many different fields to test hypotheses\nagainst observations. In most such applications, an assumption is made of\nprecise input values to produce a precise output value. However, this is\nunrealistic for real-world applications. Often the best available information\nfrom subject matter experts (SMEs) in a given field is interval range estimates\nof the input probabilities involved in Bayes Theorem. This paper provides two\nkey contributions to extend Bayes Theorem to an interval type-2 (IT2) version.\nFirst, we develop an IT2 version of Bayes Theorem that uses a novel and\nconservative method to avoid potential inconsistencies in the input IT2 MFs\nthat otherwise might produce invalid output results. We then describe a novel\nand flexible algorithm for encoding SME-provided intervals into IT2 fuzzy\nmembership functions (MFs), which we can use to specify the input probabilities\nin Bayes Theorem. Our algorithm generalizes and extends previous work on this\nproblem that primarily addressed the encoding of intervals into word MFs for\nComputing with Words applications.", "AI": {"tldr": "\u672c\u6587\u5c06\u8d1d\u53f6\u65af\u5b9a\u7406\u6269\u5c55\u5230\u533a\u95f4\u7c7b\u578b - 2 \u7248\u672c\uff0c\u5f00\u53d1 IT2 \u8d1d\u53f6\u65af\u5b9a\u7406\u5e76\u63d0\u51fa\u7f16\u7801\u7b97\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u63a8\u7406\u5047\u8bbe\u7cbe\u786e\u8f93\u5165\u503c\u4e0d\u9002\u5408\u73b0\u5b9e\u5e94\u7528\uff0c\u5b9e\u9645\u4e2d\u4e13\u5bb6\u63d0\u4f9b\u7684\u591a\u662f\u533a\u95f4\u8303\u56f4\u4f30\u8ba1\u3002", "method": "\u5f00\u53d1 IT2 \u7248\u672c\u7684\u8d1d\u53f6\u65af\u5b9a\u7406\u4ee5\u907f\u514d\u8f93\u5165 IT2 MFs \u6f5c\u5728\u4e0d\u4e00\u81f4\uff0c\u63d0\u51fa\u5c06\u4e13\u5bb6\u63d0\u4f9b\u7684\u533a\u95f4\u7f16\u7801\u4e3a IT2 \u6a21\u7cca\u96b6\u5c5e\u51fd\u6570\u7684\u7b97\u6cd5\u3002", "result": "\u5f97\u5230 IT2 \u7248\u672c\u7684\u8d1d\u53f6\u65af\u5b9a\u7406\u548c\u7f16\u7801\u7b97\u6cd5\u3002", "conclusion": "\u5c06\u8d1d\u53f6\u65af\u5b9a\u7406\u6269\u5c55\u5230 IT2 \u7248\u672c\uff0c\u7b97\u6cd5\u63a8\u5e7f\u5e76\u6269\u5c55\u4e86\u4e4b\u524d\u76f8\u5173\u95ee\u9898\u7684\u7814\u7a76\u3002"}}
{"id": "2509.09420", "pdf": "https://arxiv.org/pdf/2509.09420", "abs": "https://arxiv.org/abs/2509.09420", "authors": ["Haochen Huang", "Shuzhang Zhong", "Zhe Zhang", "Shuangchen Li", "Dimin Niu", "Hongzhong Zheng", "Runsheng Wang", "Meng Li"], "title": "HD-MoE: Hybrid and Dynamic Parallelism for Mixture-of-Expert LLMs with 3D Near-Memory Processing", "categories": ["cs.PF"], "comment": "9 pages, 15 figures, International Conference on Computer-Aided\n  Design (ICCAD) 2025", "summary": "Large Language Models (LLMs) with Mixture-of-Expert (MoE) architectures\nachieve superior model performance with reduced computation costs, but at the\ncost of high memory capacity and bandwidth requirements. Near-Memory Processing\n(NMP) accelerators that stack memory directly on the compute through hybrid\nbonding have demonstrated high bandwidth with high energy efficiency, becoming\na promising architecture for MoE models. However, as NMP accelerators comprise\ndistributed memory and computation, how to map the MoE computation directly\ndetermines the LLM inference efficiency. Existing parallel mapping strategies,\nincluding Tensor Parallelism (TP) and Expert Parallelism (EP), suffer from\neither high communication costs or unbalanced computation utilization, leading\nto inferior efficiency. The dynamic routing mechanism of MoE LLMs further\naggravates the efficiency challenges. Therefore, in this paper, we propose\nHD-MoE to automatically optimize the MoE parallel computation across an NMP\naccelerator. HD-MoE features an offline automatic hybrid parallel mapping\nalgorithm and an online dynamic scheduling strategy to reduce the communication\ncosts while maximizing the computation utilization. With extensive experimental\nresults, we demonstrate that HD-MoE achieves a speedup ranging from 1.1x to\n1.8x over TP, 1.1x to 1.5x over EP, and 1.0x to 1.4x over the baseline Hybrid\nTP-EP with Compute-Balanced parallelism strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHD - MoE\u4f18\u5316NMP\u52a0\u901f\u5668\u4e0aMoE\u5e76\u884c\u8ba1\u7b97\uff0c\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u5176\u4ed6\u7b56\u7565\u6709\u52a0\u901f\u6548\u679c\u3002", "motivation": "MoE\u67b6\u6784\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u5185\u5b58\u5bb9\u91cf\u548c\u5e26\u5bbd\u8981\u6c42\u9ad8\uff0cNMP\u52a0\u901f\u5668\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u5e76\u884c\u6620\u5c04\u7b56\u7565\u6548\u7387\u4f4e\uff0c\u52a8\u6001\u8def\u7531\u673a\u5236\u52a0\u5267\u6311\u6218\u3002", "method": "\u63d0\u51faHD - MoE\uff0c\u5305\u542b\u79bb\u7ebf\u81ea\u52a8\u6df7\u5408\u5e76\u884c\u6620\u5c04\u7b97\u6cd5\u548c\u5728\u7ebf\u52a8\u6001\u8c03\u5ea6\u7b56\u7565\u3002", "result": "HD - MoE\u76f8\u6bd4TP\u52a0\u901f1.1x - 1.8x\uff0c\u76f8\u6bd4EP\u52a0\u901f1.1x - 1.5x\uff0c\u76f8\u6bd4Hybrid TP - EP\u52a0\u901f1.0x - 1.4x\u3002", "conclusion": "HD - MoE\u80fd\u6709\u6548\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u6700\u5927\u5316\u8ba1\u7b97\u5229\u7528\u7387\uff0c\u63d0\u9ad8MoE\u5e76\u884c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2509.08843", "pdf": "https://arxiv.org/pdf/2509.08843", "abs": "https://arxiv.org/abs/2509.08843", "authors": ["Sidney Shapiro"], "title": "Pattern-Based File and Data Access with Python Glob: A Comprehensive Guide for Computational Research", "categories": ["cs.SE"], "comment": null, "summary": "Pattern-based file access is a fundamental but often under-documented aspect\nof computational research. The Python glob module provides a simple yet\npowerful way to search, filter, and ingest files using wildcard patterns,\nenabling scalable workflows across disciplines. This paper introduces glob as a\nversatile tool for data science, business analytics, and artificial\nintelligence applications. We demonstrate use cases including large-scale data\ningestion, organizational data analysis, AI dataset construction, and\nreproducible research practices. Through concrete Python examples with widely\nused libraries such as pandas,scikit-learn, and matplotlib, we show how glob\nfacilitates efficient file traversal and integration with analytical pipelines.\nBy situating glob within the broader context of reproducible research and data\nengineering, we highlight its role as a methodological building block. Our goal\nis to provide researchers and practitioners with a concise reference that\nbridges foundational concepts and applied practice, making glob a default\ncitation for file pattern matching in Python-based research workflows.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdPython\u7684glob\u6a21\u5757\u5728\u6570\u636e\u79d1\u5b66\u7b49\u9886\u57df\u4f5c\u4e3a\u6587\u4ef6\u6a21\u5f0f\u5339\u914d\u5de5\u5177\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u5176\u529f\u80fd\uff0c\u76ee\u6807\u662f\u4f7f\u5176\u6210\u4e3aPython\u7814\u7a76\u5de5\u4f5c\u6d41\u4e2d\u6587\u4ef6\u6a21\u5f0f\u5339\u914d\u7684\u9ed8\u8ba4\u5f15\u7528\u3002", "motivation": "Pattern - based file access\u5728\u8ba1\u7b97\u7814\u7a76\u4e2d\u5e38\u7f3a\u4e4f\u8bb0\u5f55\uff0c\u800cPython\u7684glob\u6a21\u5757\u53ef\u52a9\u529b\u8de8\u5b66\u79d1\u53ef\u6269\u5c55\u5de5\u4f5c\u6d41\uff0c\u6545\u4ecb\u7ecd\u5176\u5728\u591a\u9886\u57df\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5177\u4f53Python\u793a\u4f8b\uff0c\u7ed3\u5408pandas\u3001scikit - learn\u548cmatplotlib\u7b49\u5e38\u7528\u5e93\u5c55\u793aglob\u6a21\u5757\u529f\u80fd\u3002", "result": "\u5c55\u793a\u4e86glob\u6a21\u5757\u5728\u5927\u89c4\u6a21\u6570\u636e\u6444\u53d6\u3001\u7ec4\u7ec7\u6570\u636e\u5206\u6790\u3001AI\u6570\u636e\u96c6\u6784\u5efa\u548c\u53ef\u91cd\u590d\u6027\u7814\u7a76\u5b9e\u8df5\u7b49\u7528\u4f8b\u4e2d\u7684\u4f5c\u7528\uff0c\u4f53\u73b0\u5176\u4fbf\u4e8e\u6587\u4ef6\u904d\u5386\u548c\u4e0e\u5206\u6790\u7ba1\u9053\u96c6\u6210\u7684\u7279\u70b9\u3002", "conclusion": "\u5f3a\u8c03glob\u6a21\u5757\u662f\u53ef\u91cd\u590d\u6027\u7814\u7a76\u548c\u6570\u636e\u5de5\u7a0b\u7684\u65b9\u6cd5\u57fa\u77f3\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u57fa\u7840\u6982\u5ff5\u4e0e\u5e94\u7528\u5b9e\u8df5\u7684\u6865\u6881\uff0c\u5e94\u6210\u4e3aPython\u7814\u7a76\u5de5\u4f5c\u6d41\u4e2d\u6587\u4ef6\u6a21\u5f0f\u5339\u914d\u7684\u9ed8\u8ba4\u5f15\u7528\u3002"}}
{"id": "2509.09585", "pdf": "https://arxiv.org/pdf/2509.09585", "abs": "https://arxiv.org/abs/2509.09585", "authors": ["Alejandro Rodriguez Dominguez"], "title": "Causal PDE-Control Models: A Structural Framework for Dynamic Portfolio Optimization", "categories": ["q-fin.PM", "G.1.6; G.1.8; G.1.10; G.3; I.2.6; I.5.3; I.5.4; I.6.5; J.2; J.4; J.6"], "comment": "54 pages, 14 pages, 14 figures. Code and data available from authors\n  upon request", "summary": "Classical portfolio models collapse under structural breaks, while modern\nmachine-learning allocators adapt flexibly but often at the cost of\ntransparency and interpretability. This paper introduces Causal PDE-Control\nModels (CPCMs), a unifying framework that integrates causal inference,\nnonlinear filtering, and forward-backward partial differential equations for\ndynamic portfolio optimization. The framework delivers three theoretical\nadvances: (i) the existence of conditional risk-neutral measures under evolving\ninformation sets; (ii) a projection-divergence duality that quantifies the\nstability cost of departing from the causal driver manifold; and (iii) causal\ncompleteness, establishing that a finite driver span can capture all systematic\npremia. Classical methods such as Markowitz, CAPM, and Black-Litterman appear\nas degenerate cases, while reinforcement learning and deep-hedging policies\nemerge as unconstrained, symmetry-breaking approximations. Empirically, CPCM\nsolvers implemented with physics-informed neural networks achieve higher Sharpe\nratios, lower turnover, and more persistent premia than both econometric and\nmachine-learning benchmarks, using a global equity panel with more than 300\ncandidate drivers. By reframing portfolio optimization around structural\ncausality and PDE control, CPCMs provide a rigorous, interpretable, and\ncomputationally tractable foundation for robust asset allocation under\nnonstationary conditions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdCausal PDE - Control Models (CPCMs)\u7528\u4e8e\u52a8\u6001\u6295\u8d44\u7ec4\u5408\u4f18\u5316\uff0c\u6709\u7406\u8bba\u8fdb\u5c55\uff0c\u5b9e\u8bc1\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u4e3a\u975e\u5e73\u7a33\u6761\u4ef6\u4e0b\u8d44\u4ea7\u914d\u7f6e\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u7ecf\u5178\u6295\u8d44\u7ec4\u5408\u6a21\u578b\u5728\u7ed3\u6784\u7a81\u53d8\u4e0b\u5d29\u6e83\uff0c\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u5206\u914d\u5668\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165CPCMs\u6846\u67b6\uff0c\u6574\u5408\u56e0\u679c\u63a8\u65ad\u3001\u975e\u7ebf\u6027\u6ee4\u6ce2\u548c\u524d\u540e\u5411\u504f\u5fae\u5206\u65b9\u7a0b\uff1b\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0CPCM\u6c42\u89e3\u5668\u3002", "result": "CPCM\u6c42\u89e3\u5668\u5728\u5168\u7403\u80a1\u7968\u9762\u677f\u6570\u636e\u4e0a\uff0c\u6bd4\u8ba1\u91cf\u548c\u673a\u5668\u5b66\u4e60\u57fa\u51c6\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u590f\u666e\u6bd4\u7387\u3001\u66f4\u4f4e\u6362\u624b\u7387\u548c\u66f4\u6301\u4e45\u6ea2\u4ef7\u3002", "conclusion": "CPCMs\u56f4\u7ed5\u7ed3\u6784\u56e0\u679c\u5173\u7cfb\u548cPDE\u63a7\u5236\u91cd\u65b0\u6784\u5efa\u6295\u8d44\u7ec4\u5408\u4f18\u5316\uff0c\u4e3a\u975e\u5e73\u7a33\u6761\u4ef6\u4e0b\u7a33\u5065\u8d44\u4ea7\u914d\u7f6e\u63d0\u4f9b\u4e25\u8c28\u3001\u53ef\u89e3\u91ca\u548c\u8ba1\u7b97\u53ef\u884c\u7684\u57fa\u7840\u3002"}}
{"id": "2509.09415", "pdf": "https://arxiv.org/pdf/2509.09415", "abs": "https://arxiv.org/abs/2509.09415", "authors": ["Marcel Ausloos", "Probowo Erawan Sastroredjo", "Polina Khrennikova"], "title": "Note on pre-taxation reported data by UK FTSE-listed companies. A search for Benford's laws compatibility", "categories": ["q-fin.ST"], "comment": "27 pages, 56 references, 8 tables, 4 figures", "summary": "Pre-taxation analysis plays a crucial role in ensuring the fairness of public\nrevenue collection. It can also serve as a tool to reduce the risk of tax\navoidance, one of the UK government's concerns. Our report utilises pre-tax\nincome ($PI$) and total assets ($TA$) data from 567 companies listed on the\nFTSE All-Share index, gathered from the Refinitiv EIKON database, covering 14\nyears, i.e., the period from 2009 to 2022. We also derive the $PI/TA$ ratio,\nand distinguish between positive and negative $PI$ cases. We test the\nconformity of such data to Benford's Laws,- specifically studying the first\nsignificant digit ($Fd$), the second significant digit ($Sd$), and the first\nand second significant digits ($FSd$). We use and justify two pertinent tests,\nthe $\\chi^2$ and the Mean Absolute Deviation (MAD). We find that both tests are\nnot leading to conclusions in complete agreement with each other, - in\nparticular the MAD test entirely rejects the Benford's Laws conformity of the\nreported financial data. From the mere accounting point of view, we conclude\nthat the findings not only cast some doubt on the reported financial data, but\nalso suggest that many more investigations be envisaged on closely related\nmatters. On the other hand, the study of a ratio, like $PI/TA$, of variables\nwhich are (or not) Benford's Laws compliant add to the literature debating\nwhether such indirect variables should (or not) be Benford's Laws compliant.", "AI": {"tldr": "\u672c\u6587\u5229\u7528FTSE\u5168\u80a1\u6307\u6570567\u5bb6\u516c\u53f814\u5e74\u6570\u636e\uff0c\u6d4b\u8bd5\u5176\u662f\u5426\u7b26\u5408\u672c\u798f\u7279\u5b9a\u5f8b\uff0c\u53d1\u73b0\u4e24\u79cd\u6d4b\u8bd5\u7ed3\u679c\u4e0d\u4e00\u81f4\uff0c\u5bf9\u8d22\u52a1\u6570\u636e\u771f\u5b9e\u6027\u5b58\u7591\u3002", "motivation": "\u786e\u4fdd\u516c\u5171\u6536\u5165\u5f81\u6536\u516c\u5e73\uff0c\u964d\u4f4e\u907f\u7a0e\u98ce\u9669\uff0c\u8fd9\u662f\u82f1\u56fd\u653f\u5e9c\u5173\u6ce8\u7684\u95ee\u9898\u3002", "method": "\u6536\u96c6567\u5bb6\u516c\u53f814\u5e74\u7684\u7a0e\u524d\u6536\u5165\u548c\u603b\u8d44\u4ea7\u6570\u636e\uff0c\u8ba1\u7b97PI/TA\u6bd4\u7387\uff0c\u533a\u5206PI\u6b63\u8d1f\u60c5\u51b5\uff0c\u7528\u5361\u65b9\u68c0\u9a8c\u548c\u5e73\u5747\u7edd\u5bf9\u504f\u5dee\uff08MAD\uff09\u6d4b\u8bd5\u6570\u636e\u4e0e\u672c\u798f\u7279\u5b9a\u5f8b\u7684\u7b26\u5408\u6027\u3002", "result": "\u4e24\u79cd\u6d4b\u8bd5\u7ed3\u679c\u4e0d\u5b8c\u5168\u4e00\u81f4\uff0cMAD\u6d4b\u8bd5\u5b8c\u5168\u5426\u5b9a\u4e86\u8d22\u52a1\u6570\u636e\u7b26\u5408\u672c\u798f\u7279\u5b9a\u5f8b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u8d22\u52a1\u6570\u636e\u771f\u5b9e\u6027\u5b58\u7591\uff0c\u5efa\u8bae\u5f00\u5c55\u66f4\u591a\u76f8\u5173\u8c03\u67e5\uff0c\u4e5f\u4e3a\u95f4\u63a5\u53d8\u91cf\u662f\u5426\u5e94\u7b26\u5408\u672c\u798f\u7279\u5b9a\u5f8b\u7684\u8ba8\u8bba\u589e\u6dfb\u4e86\u5185\u5bb9\u3002"}}
{"id": "2509.08846", "pdf": "https://arxiv.org/pdf/2509.08846", "abs": "https://arxiv.org/abs/2509.08846", "authors": ["H. Martin Gillis", "Isaac Xu", "Thomas Trappenberg"], "title": "Uncertainty Estimation using Variance-Gated Distributions", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Evaluation of per-sample uncertainty quantification from neural networks is\nessential for decision-making involving high-risk applications. A common\napproach is to use the predictive distribution from Bayesian or approximation\nmodels and decompose the corresponding predictive uncertainty into epistemic\n(model-related) and aleatoric (data-related) components. However, additive\ndecomposition has recently been questioned. In this work, we propose an\nintuitive framework for uncertainty estimation and decomposition based on the\nsignal-to-noise ratio of class probability distributions across different model\npredictions. We introduce a variance-gated measure that scales predictions by a\nconfidence factor derived from ensembles. We use this measure to discuss the\nexistence of a collapse in the diversity of committee machines.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4fe1\u566a\u6bd4\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u5206\u89e3\u6846\u67b6\uff0c\u5f15\u5165\u65b9\u5dee\u95e8\u63a7\u5ea6\u91cf\u5e76\u8ba8\u8bba\u59d4\u5458\u4f1a\u673a\u5668\u591a\u6837\u6027\u5d29\u6e83\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u9010\u6837\u672c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8bc4\u4f30\u5bf9\u9ad8\u98ce\u9669\u5e94\u7528\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u52a0\u6cd5\u5206\u89e3\u65b9\u6cd5\u906d\u8d28\u7591\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4e0d\u540c\u6a21\u578b\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u5206\u5e03\u4fe1\u566a\u6bd4\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u5206\u89e3\u6846\u67b6\uff0c\u5f15\u5165\u65b9\u5dee\u95e8\u63a7\u5ea6\u91cf\u3002", "result": "\u5f15\u5165\u65b9\u5dee\u95e8\u63a7\u5ea6\u91cf\u5e76\u7528\u4e8e\u8ba8\u8bba\u59d4\u5458\u4f1a\u673a\u5668\u591a\u6837\u6027\u5d29\u6e83\u60c5\u51b5\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u548c\u5ea6\u91cf\u6709\u52a9\u4e8e\u795e\u7ecf\u7f51\u7edc\u4e0d\u786e\u5b9a\u6027\u7684\u4f30\u8ba1\u548c\u5206\u89e3\u3002"}}
{"id": "2509.08832", "pdf": "https://arxiv.org/pdf/2509.08832", "abs": "https://arxiv.org/abs/2509.08832", "authors": ["Vasily Melnikov"], "title": "Optimal Risk Sharing Without Preference Convexity: An Aggregate Convexity Approach", "categories": ["econ.TH", "q-fin.MF", "q-fin.RM", "91B05, 91G70"], "comment": null, "summary": "We consider the optimal risk sharing problem with a continuum of agents,\nmodeled via a non-atomic measure space. Individual preferences are not assumed\nto be convex. We show the multiplicity of agents induces the value function to\nbe convex, allowing for the application of convex duality techniques to risk\nsharing without preference convexity. The proof in the finite-dimensional case\nis based on aggregate convexity principles emanating from Lyapunov convexity,\nwhile the infinite-dimensional case uses the finite-dimensional results\nconjoined with approximation arguments particular to a class of law invariant\nrisk measures, although the reference measure is allowed to vary between\nagents. Finally, we derive a computationally tractable formula for the\nconjugate of the value function, yielding an explicit dual representation of\nthe value function.", "AI": {"tldr": "\u7814\u7a76\u8fde\u7eed\u4f53\u4ee3\u7406\u7684\u6700\u4f18\u98ce\u9669\u5206\u62c5\u95ee\u9898\uff0c\u4e0d\u5047\u8bbe\u4e2a\u4f53\u504f\u597d\u51f8\u6027\uff0c\u5229\u7528\u591a\u91cd\u6027\u4f7f\u503c\u51fd\u6570\u51f8\u5316\uff0c\u7ed9\u51fa\u6709\u9650\u548c\u65e0\u9650\u7ef4\u8bc1\u660e\u5e76\u5f97\u5230\u503c\u51fd\u6570\u5171\u8f6d\u516c\u5f0f\u3002", "motivation": "\u89e3\u51b3\u975e\u51f8\u4e2a\u4f53\u504f\u597d\u4e0b\u8fde\u7eed\u4f53\u4ee3\u7406\u7684\u6700\u4f18\u98ce\u9669\u5206\u62c5\u95ee\u9898\u3002", "method": "\u6709\u9650\u7ef4\u57fa\u4e8eLyapunov\u51f8\u6027\u7684\u805a\u5408\u51f8\u6027\u539f\u7406\uff0c\u65e0\u9650\u7ef4\u7ed3\u5408\u6709\u9650\u7ef4\u7ed3\u679c\u548c\u4e00\u7c7b\u6cd5\u5219\u4e0d\u53d8\u98ce\u9669\u5ea6\u91cf\u7684\u8fd1\u4f3c\u8bba\u8bc1\u3002", "result": "\u8bc1\u660e\u4e86\u591a\u91cd\u6027\u4f7f\u503c\u51fd\u6570\u51f8\u5316\uff0c\u5f97\u5230\u503c\u51fd\u6570\u5171\u8f6d\u7684\u6613\u8ba1\u7b97\u516c\u5f0f\u3002", "conclusion": "\u53ef\u5728\u65e0\u504f\u597d\u51f8\u6027\u4e0b\u5e94\u7528\u51f8\u5bf9\u5076\u6280\u672f\u8fdb\u884c\u98ce\u9669\u5206\u62c5\uff0c\u5e76\u83b7\u5f97\u503c\u51fd\u6570\u7684\u663e\u5f0f\u5bf9\u5076\u8868\u793a\u3002"}}
{"id": "2509.09078", "pdf": "https://arxiv.org/pdf/2509.09078", "abs": "https://arxiv.org/abs/2509.09078", "authors": ["Teresa Portone", "Bert Debusschere", "Samantha Yang", "Emiliano Islas-Quinones", "T. Patrick Xiao"], "title": "Scalable extensions to given-data Sobol' index estimators", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.CO"], "comment": null, "summary": "Given-data methods for variance-based sensitivity analysis have significantly\nadvanced the feasibility of Sobol' index computation for computationally\nexpensive models and models with many inputs. However, the limitations of\nexisting methods still preclude their application to models with an extremely\nlarge number of inputs. In this work, we present practical extensions to the\nexisting given-data Sobol' index method, which allow variance-based sensitivity\nanalysis to be efficiently performed on large models such as neural networks,\nwhich have $>10^4$ parameterizable inputs. For models of this size, holding all\ninput-output evaluations simultaneously in memory -- as required by existing\nmethods -- can quickly become impractical. These extensions also support\nnonstandard input distributions with many repeated values, which are not\namenable to equiprobable partitions employed by existing given-data methods.\n  Our extensions include a general definition of the given-data Sobol' index\nestimator with arbitrary partition, a streaming algorithm to process\ninput-output samples in batches, and a heuristic to filter out small indices\nthat are indistinguishable from zero indices due to statistical noise. We show\nthat the equiprobable partition employed in existing given-data methods can\nintroduce significant bias into Sobol' index estimates even at large sample\nsizes and provide numerical analyses that demonstrate why this can occur. We\nalso show that our streaming algorithm can achieve comparable accuracy and\nruntimes with lower memory requirements, relative to current methods which\nprocess all samples at once. We demonstrate our novel developments on two\napplication problems in neural network modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bf9\u73b0\u6709\u7ed9\u5b9a\u6570\u636eSobol'\u6307\u6570\u65b9\u6cd5\u7684\u5b9e\u7528\u6269\u5c55\uff0c\u53ef\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8fdb\u884c\u57fa\u4e8e\u65b9\u5dee\u7684\u654f\u611f\u6027\u5206\u6790\uff0c\u5c55\u793a\u4e86\u65b0\u65b9\u6cd5\u4f18\u52bf\u5e76\u5728\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u5e94\u7528\u4e2d\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7ed9\u5b9a\u6570\u636e\u65b9\u6cd5\u5728\u5904\u7406\u8f93\u5165\u6781\u591a\u7684\u6a21\u578b\u65f6\u6709\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u7528\u4e8e\u5927\u89c4\u6a21\u6a21\u578b\u5982\u795e\u7ecf\u7f51\u7edc\u3002", "method": "\u63d0\u51fa\u4efb\u610f\u5206\u533a\u7684\u7ed9\u5b9a\u6570\u636eSobol'\u6307\u6570\u4f30\u8ba1\u5668\u7684\u901a\u7528\u5b9a\u4e49\u3001\u6279\u91cf\u5904\u7406\u8f93\u5165\u8f93\u51fa\u6837\u672c\u7684\u6d41\u5f0f\u7b97\u6cd5\uff0c\u4ee5\u53ca\u8fc7\u6ee4\u5c0f\u6307\u6570\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u73b0\u6709\u65b9\u6cd5\u7684\u7b49\u6982\u7387\u5206\u533a\u4f1a\u5f15\u5165\u663e\u8457\u504f\u5dee\uff0c\u6d41\u5f0f\u7b97\u6cd5\u80fd\u4ee5\u66f4\u4f4e\u5185\u5b58\u5b9e\u73b0\u76f8\u8fd1\u7684\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u6240\u63d0\u6269\u5c55\u80fd\u6709\u6548\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8fdb\u884c\u57fa\u4e8e\u65b9\u5dee\u7684\u654f\u611f\u6027\u5206\u6790\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2509.09162", "pdf": "https://arxiv.org/pdf/2509.09162", "abs": "https://arxiv.org/abs/2509.09162", "authors": ["James Chok", "Myung Won Lee", "Daniel Paulin", "Geoffrey M. Vasil"], "title": "Divide, Interact, Sample: The Two-System Paradigm", "categories": ["stat.CO", "math.PR", "62D05, 82C31, 82C22"], "comment": null, "summary": "Mean-field, ensemble-chain, and adaptive samplers have historically been\nviewed as distinct approaches to Monte Carlo sampling. In this paper, we\npresent a unifying {two-system} framework that brings all three under one roof.\nIn our approach, an ensemble of particles is split into two interacting\nsubsystems that propose updates for each other in a symmetric, alternating\nfashion. This cross-system interaction ensures that the overall ensemble has\n$\\rho(x)$ as its invariant distribution in both the finite-particle setting and\nthe mean-field limit. The two-system construction reveals that ensemble-chain\nsamplers can be interpreted as finite-$N$ approximations of an ideal mean-field\nsampler; conversely, it provides a principled recipe to discretize mean-field\nLangevin dynamics into tractable parallel MCMC algorithms. The framework also\nconnects naturally to adaptive single-chain methods: by replacing\nparticle-based statistics with time-averaged statistics from a single chain,\none recovers analogous adaptive dynamics in the long-time limit without\nrequiring a large ensemble. We derive novel two-system versions of both\noverdamped and underdamped Langevin MCMC samplers within this paradigm. Across\nsynthetic benchmarks and real-world posterior inference tasks, these two-system\nsamplers exhibit significant performance gains over the popular No-U-Turn\nSampler, achieving an order of magnitude higher effective sample sizes per\ngradient evaluation.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7684\u53cc\u7cfb\u7edf\u6846\u67b6\u6574\u5408\u4e09\u79cd\u8499\u7279\u5361\u7f57\u91c7\u6837\u65b9\u6cd5\uff0c\u63a8\u5bfc\u65b0\u91c7\u6837\u5668\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u6d41\u884c\u91c7\u6837\u5668\u3002", "motivation": "\u5c06\u5386\u53f2\u4e0a\u88ab\u89c6\u4e3a\u4e0d\u540c\u65b9\u6cd5\u7684\u5e73\u5747\u573a\u3001\u7cfb\u7efc\u94fe\u548c\u81ea\u9002\u5e94\u91c7\u6837\u5668\u7edf\u4e00\u8d77\u6765\u3002", "method": "\u6784\u5efa\u53cc\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06\u7c92\u5b50\u7cfb\u7efc\u5206\u4e3a\u4e24\u4e2a\u76f8\u4e92\u4f5c\u7528\u5b50\u7cfb\u7edf\uff0c\u5bf9\u79f0\u4ea4\u66ff\u66f4\u65b0\u3002", "result": "\u63ed\u793a\u7cfb\u7efc\u94fe\u91c7\u6837\u5668\u4e0e\u5e73\u5747\u573a\u91c7\u6837\u5668\u5173\u7cfb\uff0c\u53ef\u5c06\u5e73\u5747\u573a\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u79bb\u6563\u5316\uff0c\u4e0e\u81ea\u9002\u5e94\u5355\u94fe\u65b9\u6cd5\u5efa\u7acb\u8054\u7cfb\uff0c\u65b0\u91c7\u6837\u5668\u6027\u80fd\u4f18\u4e8eNo - U - Turn Sampler\u3002", "conclusion": "\u53cc\u7cfb\u7edf\u6846\u67b6\u6709\u6548\u7edf\u4e00\u4e09\u79cd\u91c7\u6837\u65b9\u6cd5\uff0c\u65b0\u91c7\u6837\u5668\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2509.08986", "pdf": "https://arxiv.org/pdf/2509.08986", "abs": "https://arxiv.org/abs/2509.08986", "authors": ["Junbo Jacob Lian"], "title": "Time-Fair Benchmarking for Metaheuristics: A Restart-Fair Protocol for Fixed-Time Comparisons", "categories": ["cs.NE", "cs.PF", "stat.CO"], "comment": null, "summary": "Numerous purportedly improved metaheuristics claim superior performance based\non equivalent function evaluations (FEs), yet often conceal additional\ncomputational burdens in more intensive iterations, preprocessing stages, or\nhyperparameter tuning. This paper posits that wall-clock time, rather than\nsolely FEs, should serve as the principal budgetary constraint for equitable\ncomparisons. We formalize a fixed-time, restart-fair benchmarking protocol\nwherein each algorithm is allotted an identical wall-clock time budget per\nproblem instance, permitting unrestricted utilization of restarts, early\ntermination criteria, and internal adaptive mechanisms. We advocate for the\nadoption of anytime performance curves, expected running time (ERT) metrics,\nand performance profiles that employ time as the cost measure, all aimed at\npredefined targets. Furthermore, we introduce a concise, reproducible checklist\nto standardize reporting practices and mitigate undisclosed computational\noverheads. This approach fosters more credible and practically relevant\nevaluations of metaheuristic algorithms.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5e94\u4f7f\u7528\u65f6\u949f\u65f6\u95f4\u800c\u975e\u4ec5\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u6765\u516c\u5e73\u6bd4\u8f83\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u63d0\u51fa\u56fa\u5b9a\u65f6\u95f4\u3001\u91cd\u542f\u516c\u5e73\u7684\u57fa\u51c6\u6d4b\u8bd5\u534f\u8bae\uff0c\u5021\u5bfc\u4f7f\u7528\u57fa\u4e8e\u65f6\u95f4\u7684\u6027\u80fd\u6307\u6807\uff0c\u5e76\u5f15\u5165\u6e05\u5355\u89c4\u8303\u62a5\u544a\u5b9e\u8df5\u3002", "motivation": "\u73b0\u6709\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u5e38\u4ee5\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u5ba3\u79f0\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u9690\u85cf\u989d\u5916\u8ba1\u7b97\u8d1f\u62c5\uff0c\u9700\u66f4\u516c\u5e73\u7684\u6bd4\u8f83\u65b9\u5f0f\u3002", "method": "\u5236\u5b9a\u56fa\u5b9a\u65f6\u95f4\u3001\u91cd\u542f\u516c\u5e73\u7684\u57fa\u51c6\u6d4b\u8bd5\u534f\u8bae\uff0c\u91c7\u7528\u57fa\u4e8e\u65f6\u95f4\u7684\u6027\u80fd\u6307\u6807\uff0c\u5f15\u5165\u6e05\u5355\u89c4\u8303\u62a5\u544a\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u4fc3\u8fdb\u5bf9\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u66f4\u53ef\u4fe1\u4e14\u5b9e\u7528\u7684\u8bc4\u4f30\u3002"}}
{"id": "2509.08981", "pdf": "https://arxiv.org/pdf/2509.08981", "abs": "https://arxiv.org/abs/2509.08981", "authors": ["Alessandro Ferrari", "Lorenzo Pesaresi"], "title": "Specialization, Complexity & Resilience in Supply Chains", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Despite growing policy interest, the determinants of supply chain resilience\nare still not well understood. We propose a new theory of supply chain\nformation with compatibility frictions: only compatible inputs can be used in\nfinal good production. Intermediate producers choose the degree of\nspecialization of their goods, trading off higher productivity against a lower\nshare of compatible final producers. We model supply chains as complex\nproduction processes in which multiple complementary inputs must be sourced for\nfinal production to take place. Specialization choices, production complexity,\nand search frictions jointly determine supply chain resilience. Relative to the\nefficient allocation, the equilibrium is characterized by over-specialization\ndue to a novel network externality arising from the interplay between\nfrictional markets, endogenous specialization, and complex production.\nOver-specialization makes supply chains more productive in normal times but\nless resilient to disruptions than socially desirable. We show how a targeted\ntransaction subsidy can decentralize efficient resilience in supply chains, and\nexamine the implications of setting compatibility standards.", "AI": {"tldr": "\u63d0\u51fa\u542b\u517c\u5bb9\u6027\u6469\u64e6\u7684\u4f9b\u5e94\u94fe\u5f62\u6210\u65b0\u7406\u8bba\uff0c\u6307\u51fa\u5747\u8861\u5b58\u5728\u8fc7\u5ea6\u4e13\u4e1a\u5316\uff0c\u5f71\u54cd\u4f9b\u5e94\u94fe\u97e7\u6027\uff0c\u8fd8\u63d0\u51fa\u4ea4\u6613\u8865\u8d34\u548c\u517c\u5bb9\u6027\u6807\u51c6\u5efa\u8bae\u3002", "motivation": "\u5f53\u524d\u5bf9\u4f9b\u5e94\u94fe\u97e7\u6027\u51b3\u5b9a\u56e0\u7d20\u7406\u89e3\u4e0d\u8db3\uff0c\u9700\u6df1\u5165\u7814\u7a76\u3002", "method": "\u6784\u5efa\u542b\u517c\u5bb9\u6027\u6469\u64e6\u7684\u4f9b\u5e94\u94fe\u5f62\u6210\u7406\u8bba\uff0c\u5c06\u4f9b\u5e94\u94fe\u5efa\u6a21\u4e3a\u590d\u6742\u751f\u4ea7\u8fc7\u7a0b\u3002", "result": "\u5747\u8861\u5b58\u5728\u8fc7\u5ea6\u4e13\u4e1a\u5316\uff0c\u4f7f\u4f9b\u5e94\u94fe\u5e73\u65f6\u66f4\u9ad8\u6548\u4f46\u5e94\u5bf9\u4e2d\u65ad\u97e7\u6027\u4e0d\u8db3\u3002", "conclusion": "\u53ef\u901a\u8fc7\u9488\u5bf9\u6027\u4ea4\u6613\u8865\u8d34\u5b9e\u73b0\u4f9b\u5e94\u94fe\u6709\u6548\u97e7\u6027\uff0c\u8fd8\u9700\u8003\u91cf\u517c\u5bb9\u6027\u6807\u51c6\u7684\u5f71\u54cd\u3002"}}
{"id": "2509.09652", "pdf": "https://arxiv.org/pdf/2509.09652", "abs": "https://arxiv.org/abs/2509.09652", "authors": ["Prashanti Anderson", "Ainesh Bakshi", "Samuel B. Hopkins"], "title": "Additive Approximation Schemes for Low-Dimensional Embeddings", "categories": ["cs.DS"], "comment": "57 pages", "summary": "We consider the task of fitting low-dimensional embeddings to\nhigh-dimensional data. In particular, we study the $k$-Euclidean Metric\nViolation problem ($\\textsf{$k$-EMV}$), where the input is $D \\in\n\\mathbb{R}^{\\binom{n}{2}}_{\\geq 0}$ and the goal is to find the closest vector\n$X \\in \\mathbb{M}_{k}$, where $\\mathbb{M}_k \\subset\n\\mathbb{R}^{\\binom{n}{2}}_{\\geq 0}$ is the set of all $k$-dimensional Euclidean\nmetrics on $n$ points, and closeness is formulated as the following\noptimization problem, where $\\| \\cdot \\|$ is the entry-wise $\\ell_2$ norm: \\[\n  \\textsf{OPT}_{\\textrm{EMV}} = \\min_{X \\in \\mathbb{M}_{k} } \\Vert D - X\n\\Vert_2^2\\,.\\] Cayton and Dasgupta [CD'06] showed that this problem is NP-Hard,\neven when $k=1$. Dhamdhere [Dha'04] obtained a $O(\\log(n))$-approximation for\n$\\textsf{$1$-EMV}$ and leaves finding a PTAS for it as an open question\n(reiterated recently by Lee [Lee'25]). Although $\\textsf{$k$-EMV}$ has been\nstudied in the statistics community for over 70 years, under the name\n\"multi-dimensional scaling\", there are no known efficient approximation\nalgorithms for $k > 1$, to the best of our knowledge.\n  We provide the first polynomial-time additive approximation scheme for\n$\\textsf{$k$-EMV}$. In particular, we obtain an embedding with objective value\n$\\textsf{OPT}_{\\textrm{EMV}} + \\varepsilon \\Vert D\\Vert_2^2$ in $(n\\cdot\nB)^{\\mathsf{poly}(k, \\varepsilon^{-1})}$ time, where each entry in $D$ can be\nrepresented by $B$ bits. We believe our algorithm is a crucial first step\ntowards obtaining a PTAS for $\\textsf{$k$-EMV}$. Our key technical contribution\nis a new analysis of correlation rounding for Sherali-Adams / Sum-of-Squares\nrelaxations, tailored to low-dimensional embeddings. We also show that our\ntechniques allow us to obtain additive approximation schemes for two related\nproblems: a weighted variant of $\\textsf{$k$-EMV}$ and $\\ell_p$ low-rank\napproximation for $p>2$.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.09236", "pdf": "https://arxiv.org/pdf/2509.09236", "abs": "https://arxiv.org/abs/2509.09236", "authors": ["Guilherme Henrique Teixeira", "Nepomuk Krenn", "Peter Gangl", "Benjamin Marussig"], "title": "Isogeometric Topology Optimization Based on Topological Derivatives", "categories": ["math.NA", "cs.CE", "cs.NA", "math.OC"], "comment": "19 pages, 11 figures, pre-print,", "summary": "Topology optimization is a valuable tool in engineering, facilitating the\ndesign of optimized structures. However, topological changes often require a\nremeshing step, which can become challenging. In this work, we propose an\nisogeometric approach to topology optimization driven by topological\nderivatives. The combination of a level-set method together with an immersed\nisogeometric framework allows seamless geometry updates without the necessity\nof remeshing. At the same time, topological derivatives provide topological\nmodifications without the need to define initial holes [7]. We investigate the\ninfluence of higher-degree basis functions in both the level-set representation\nand the approximation of the solution. Two numerical examples demonstrate the\nproposed approach, showing that employing higher-degree basis functions for\napproximating the solution improves accuracy, while linear basis functions\nremain sufficient for the level-set function representation.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u5bfc\u6570\u7684\u7b49\u51e0\u4f55\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u6c34\u5e73\u96c6\u548c\u6d78\u5165\u7b49\u51e0\u4f55\u6846\u67b6\u65e0\u9700\u91cd\u65b0\u7f51\u683c\u5212\u5206\uff0c\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u7814\u7a76\u9ad8\u9636\u57fa\u51fd\u6570\u5f71\u54cd\u5e76\u5f97\u51fa\u7ed3\u8bba\u3002", "motivation": "\u62d3\u6251\u4f18\u5316\u4e2d\u62d3\u6251\u53d8\u5316\u7684\u91cd\u65b0\u7f51\u683c\u5212\u5206\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u5bfb\u6c42\u65e0\u9700\u91cd\u65b0\u7f51\u683c\u5212\u5206\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u5bfc\u6570\u7684\u7b49\u51e0\u4f55\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u6c34\u5e73\u96c6\u65b9\u6cd5\u548c\u6d78\u5165\u7b49\u51e0\u4f55\u6846\u67b6\uff0c\u7814\u7a76\u9ad8\u9636\u57fa\u51fd\u6570\u5728\u6c34\u5e73\u96c6\u8868\u793a\u548c\u6c42\u89e3\u8fd1\u4f3c\u4e2d\u7684\u5f71\u54cd\u3002", "result": "\u4e24\u4e2a\u6570\u503c\u7b97\u4f8b\u8868\u660e\uff0c\u7528\u9ad8\u9636\u57fa\u51fd\u6570\u8fd1\u4f3c\u89e3\u53ef\u63d0\u9ad8\u7cbe\u5ea6\uff0c\u7ebf\u6027\u57fa\u51fd\u6570\u7528\u4e8e\u6c34\u5e73\u96c6\u51fd\u6570\u8868\u793a\u5df2\u8db3\u591f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5b9e\u73b0\u65e0\u7f1d\u51e0\u4f55\u66f4\u65b0\u4e14\u65e0\u9700\u91cd\u65b0\u7f51\u683c\u5212\u5206\uff0c\u4e0d\u540c\u573a\u666f\u4e0b\u57fa\u51fd\u6570\u9009\u62e9\u6709\u76f8\u5e94\u7ed3\u8bba\u3002"}}
{"id": "2509.09099", "pdf": "https://arxiv.org/pdf/2509.09099", "abs": "https://arxiv.org/abs/2509.09099", "authors": ["Toygar T. Kerman", "Anastas P. Tenev", "Konstantin Zabarnyi"], "title": "Persuasion Gains and Losses from Peer Communication", "categories": ["cs.GT", "econ.TH"], "comment": null, "summary": "We study a Bayesian persuasion setting in which a sender wants to persuade a\ncritical mass of receivers by revealing partial information about the state to\nthem. The homogeneous binary-action receivers are located on a communication\nnetwork, and each observes the private messages sent to them and their\nimmediate neighbors. We examine how the sender's expected utility varies with\nincreased communication among receivers. We show that for general families of\nnetworks, extending the network can strictly benefit the sender. Thus, the\nsender's gain from persuasion is not monotonic in network density. Moreover,\nmany network extensions can achieve the upper bound on the sender's expected\nutility among all networks, which corresponds to the payoff in an empty\nnetwork. This is the case in networks reflecting a clear informational\nhierarchy (e.g., in global corporations), as well as in decentralized networks\nin which information originates from multiple sources (e.g., influencers in\nsocial media). Finally, we show that a slight modification to the structure of\nsome of these networks precludes the possibility of such beneficial extensions.\nOverall, our results caution against presuming that more communication\nnecessarily leads to better collective outcomes.", "AI": {"tldr": "\u7814\u7a76\u8d1d\u53f6\u65af\u8bf4\u670d\u573a\u666f\u4e0b\u53d1\u9001\u8005\u6548\u7528\u4e0e\u63a5\u6536\u8005\u95f4\u901a\u4fe1\u7684\u5173\u7cfb\uff0c\u6307\u51fa\u7f51\u7edc\u6269\u5c55\u4e0d\u4e00\u5b9a\u5355\u8c03\u5f71\u54cd\u53d1\u9001\u8005\u6536\u76ca\uff0c\u67d0\u4e9b\u7f51\u7edc\u6269\u5c55\u53ef\u4f7f\u53d1\u9001\u8005\u6548\u7528\u8fbe\u4e0a\u9650\uff0c\u90e8\u5206\u7f51\u7edc\u7ed3\u6784\u4fee\u6539\u4f1a\u6392\u9664\u6709\u76ca\u6269\u5c55\u53ef\u80fd\u3002", "motivation": "\u63a2\u7a76\u53d1\u9001\u8005\u5728\u8d1d\u53f6\u65af\u8bf4\u670d\u573a\u666f\u4e0b\uff0c\u5176\u9884\u671f\u6548\u7528\u5982\u4f55\u968f\u63a5\u6536\u8005\u95f4\u901a\u4fe1\u589e\u52a0\u800c\u53d8\u5316\u3002", "method": "\u7814\u7a76\u4f4d\u4e8e\u901a\u4fe1\u7f51\u7edc\u4e0a\u7684\u540c\u8d28\u4e8c\u5143\u884c\u52a8\u63a5\u6536\u8005\uff0c\u53d1\u9001\u8005\u5411\u5176\u900f\u9732\u90e8\u5206\u72b6\u6001\u4fe1\u606f\uff0c\u5206\u6790\u4e0d\u540c\u7f51\u7edc\u7ed3\u6784\u4e0b\u7684\u60c5\u51b5\u3002", "result": "\u5bf9\u4e8e\u4e00\u822c\u7f51\u7edc\u65cf\uff0c\u6269\u5c55\u7f51\u7edc\u53ef\u4f7f\u53d1\u9001\u8005\u4e25\u683c\u53d7\u76ca\uff0c\u53d1\u9001\u8005\u8bf4\u670d\u6536\u76ca\u4e0e\u7f51\u7edc\u5bc6\u5ea6\u975e\u5355\u8c03\u5173\u7cfb\uff1b\u8bb8\u591a\u7f51\u7edc\u6269\u5c55\u80fd\u4f7f\u53d1\u9001\u8005\u9884\u671f\u6548\u7528\u8fbe\u4e0a\u9650\uff1b\u90e8\u5206\u7f51\u7edc\u7ed3\u6784\u7a0d\u4f5c\u4fee\u6539\u4f1a\u6392\u9664\u6709\u76ca\u6269\u5c55\u53ef\u80fd\u3002", "conclusion": "\u4e0d\u5e94\u5047\u5b9a\u66f4\u591a\u901a\u4fe1\u5fc5\u7136\u5e26\u6765\u66f4\u597d\u7684\u96c6\u4f53\u7ed3\u679c\u3002"}}
{"id": "2509.09058", "pdf": "https://arxiv.org/pdf/2509.09058", "abs": "https://arxiv.org/abs/2509.09058", "authors": ["Ajay Kumar", "Praveen Rao", "Peter Sanders"], "title": "Optimizing the Variant Calling Pipeline Execution on Human Genomes Using GPU-Enabled Machines", "categories": ["cs.DC"], "comment": "To appear in 14th International Workshop on Parallel and AI-based\n  Bioinformatics and Biomedicine (ParBio), Philadelphia, 2025", "summary": "Variant calling is the first step in analyzing a human genome and aims to\ndetect variants in an individual's genome compared to a reference genome. Due\nto the computationally-intensive nature of variant calling, genomic data are\nincreasingly processed in cloud environments as large amounts of compute and\nstorage resources can be acquired with the pay-as-you-go pricing model. In this\npaper, we address the problem of efficiently executing a variant calling\npipeline for a workload of human genomes on graphics processing unit\n(GPU)-enabled machines. We propose a novel machine learning (ML)-based approach\nfor optimizing the workload execution to minimize the total execution time. Our\napproach encompasses two key techniques: The first technique employs ML to\npredict the execution times of different stages in a variant calling pipeline\nbased on the characteristics of a genome sequence. Using the predicted times,\nthe second technique generates optimal execution plans for the machines by\ndrawing inspiration from the flexible job shop scheduling problem. The plans\nare executed via careful synchronization across different machines. We\nevaluated our approach on a workload of publicly available genome sequences\nusing a testbed with different types of GPU hardware. We observed that our\napproach was effective in predicting the execution times of variant calling\npipeline stages using ML on features such as sequence size, read quality,\npercentage of duplicate reads, and average read length. In addition, our\napproach achieved 2X speedup (on an average) over a greedy approach that also\nused ML for predicting the execution times on the tested workload of sequences.\nFinally, our approach achieved 1.6X speedup (on an average) over a dynamic\napproach that executed the workload based on availability of resources without\nusing any ML-based time predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u4f18\u5316\u4eba\u7c7b\u57fa\u56e0\u7ec4\u53d8\u5f02\u68c0\u6d4b\u6d41\u7a0b\u6267\u884c\uff0c\u5728GPU\u673a\u5668\u4e0a\u51cf\u5c11\u603b\u6267\u884c\u65f6\u95f4\uff0c\u8bc4\u4f30\u663e\u793a\u6bd4\u8d2a\u5fc3\u548c\u52a8\u6001\u65b9\u6cd5\u6709\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u53d8\u5f02\u68c0\u6d4b\u8ba1\u7b97\u5bc6\u96c6\uff0c\u4e3a\u5728GPU\u673a\u5668\u4e0a\u9ad8\u6548\u6267\u884c\u4eba\u7c7b\u57fa\u56e0\u7ec4\u53d8\u5f02\u68c0\u6d4b\u6d41\u7a0b\uff0c\u51cf\u5c11\u603b\u6267\u884c\u65f6\u95f4\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u7528ML\u9884\u6d4b\u53d8\u5f02\u68c0\u6d4b\u6d41\u7a0b\u5404\u9636\u6bb5\u6267\u884c\u65f6\u95f4\uff0c\u501f\u9274\u67d4\u6027\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\u751f\u6210\u6700\u4f18\u6267\u884c\u8ba1\u5212\uff0c\u5e76\u8de8\u673a\u5668\u540c\u6b65\u6267\u884c\u3002", "result": "\u80fd\u6709\u6548\u5229\u7528ML\u6839\u636e\u5e8f\u5217\u7279\u5f81\u9884\u6d4b\u6267\u884c\u65f6\u95f4\uff0c\u76f8\u6bd4\u8d2a\u5fc3\u65b9\u6cd5\u5e73\u5747\u52a0\u901f2\u500d\uff0c\u76f8\u6bd4\u52a8\u6001\u65b9\u6cd5\u5e73\u5747\u52a0\u901f1.6\u500d\u3002", "conclusion": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u4eba\u7c7b\u57fa\u56e0\u7ec4\u53d8\u5f02\u68c0\u6d4b\u6d41\u7a0b\u7684\u603b\u6267\u884c\u65f6\u95f4\u3002"}}
{"id": "2509.09037", "pdf": "https://arxiv.org/pdf/2509.09037", "abs": "https://arxiv.org/abs/2509.09037", "authors": ["Amanda Aird", "Ben Armstrong", "Nicholas Mattei", "Robin Burke"], "title": "Envy-Free but Still Unfair: Envy-Freeness Up To One Item (EF-1) in Personalized Recommendation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Envy-freeness and the relaxation to Envy-freeness up to one item (EF-1) have\nbeen used as fairness concepts in the economics, game theory, and social choice\nliteratures since the 1960s, and have recently gained popularity within the\nrecommendation systems communities. In this short position paper we will give\nan overview of envy-freeness and its use in economics and recommendation\nsystems; and illustrate why envy is not appropriate to measure fairness for use\nin settings where personalization plays a role.", "AI": {"tldr": "\u672c\u6587\u6982\u8ff0\u5ac9\u5992\u65e0\u5173\u6027\u53ca\u5176\u5728\u7ecf\u6d4e\u5b66\u548c\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u8bf4\u660e\u5ac9\u5992\u4e0d\u9002\u7528\u4e8e\u4e2a\u6027\u5316\u573a\u666f\u8861\u91cf\u516c\u5e73\u6027\u3002", "motivation": "\u4ecb\u7ecd\u5ac9\u5992\u65e0\u5173\u6027\u6982\u5ff5\u5728\u4e0d\u540c\u9886\u57df\u7684\u5e94\u7528\u60c5\u51b5\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u4e2a\u6027\u5316\u573a\u666f\u8861\u91cf\u516c\u5e73\u6027\u7684\u9002\u7528\u6027\u3002", "method": "\u7efc\u8ff0\u5df2\u6709\u6587\u732e\u6982\u5ff5\u5e76\u8fdb\u884c\u5206\u6790", "result": "\u6307\u51fa\u5ac9\u5992\u4e0d\u9002\u5408\u5728\u4e2a\u6027\u5316\u53d1\u6325\u4f5c\u7528\u7684\u573a\u666f\u4e2d\u8861\u91cf\u516c\u5e73\u6027\u3002", "conclusion": "\u5ac9\u5992\u65e0\u5173\u6027\u867d\u5728\u591a\u9886\u57df\u6709\u5e94\u7528\uff0c\u4f46\u5728\u4e2a\u6027\u5316\u573a\u666f\u8861\u91cf\u516c\u5e73\u6027\u5b58\u5728\u95ee\u9898\u3002"}}
{"id": "2509.08847", "pdf": "https://arxiv.org/pdf/2509.08847", "abs": "https://arxiv.org/abs/2509.08847", "authors": ["Amna Hassan"], "title": "Automated Unity Game Template Generation from GDDs via NLP and Multi-Modal LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.SE"], "comment": null, "summary": "This paper presents a novel framework for automated game template generation\nby transforming Game Design Documents (GDDs) into functional Unity game\nprototypes using Natural Language Processing (NLP) and multi-modal Large\nLanguage Models (LLMs). We introduce an end-to-end system that parses GDDs,\nextracts structured game specifications, and synthesizes Unity-compatible C#\ncode that implements the core mechanics, systems, and architecture defined in\nthe design documentation. Our approach combines a fine-tuned LLaMA-3 model\nspecialized for Unity code generation with a custom Unity integration package\nthat streamlines the implementation process. Evaluation results demonstrate\nsignificant improvements over baseline models, with our fine-tuned model\nachieving superior performance (4.8/5.0 average score) compared to\nstate-of-the-art LLMs across compilation success, GDD adherence, best practices\nadoption, and code modularity metrics. The generated templates demonstrate high\nadherence to GDD specifications across multiple game genres. Our system\neffectively addresses critical gaps in AI-assisted game development,\npositioning LLMs as valuable tools in streamlining the transition from game\ndesign to implementation.", "AI": {"tldr": "\u63d0\u51fa\u7528NLP\u548c\u591a\u6a21\u6001\u5927\u6a21\u578b\u5c06\u6e38\u620f\u8bbe\u8ba1\u6587\u6863\u8f6c\u5316\u4e3aUnity\u6e38\u620f\u539f\u578b\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u5fae\u8c03\u6a21\u578b\u548c\u81ea\u5b9a\u4e49\u5305\uff0c\u8bc4\u4f30\u8868\u73b0\u4f18\u3002", "motivation": "\u89e3\u51b3AI\u8f85\u52a9\u6e38\u620f\u5f00\u53d1\u4e2d\u4ece\u6e38\u620f\u8bbe\u8ba1\u5230\u5b9e\u73b0\u7684\u8f6c\u6362\u95ee\u9898\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u3002", "method": "\u5f15\u5165\u7aef\u5230\u7aef\u7cfb\u7edf\u89e3\u6790GDD\uff0c\u63d0\u53d6\u89c4\u8303\u5e76\u5408\u6210C#\u4ee3\u7801\uff0c\u7ed3\u5408\u5fae\u8c03\u7684LLaMA - 3\u6a21\u578b\u548c\u81ea\u5b9a\u4e49Unity\u96c6\u6210\u5305\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5fae\u8c03\u6a21\u578b\u5728\u591a\u9879\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u751f\u6210\u6a21\u677f\u9ad8\u5ea6\u7b26\u5408GDD\u89c4\u8303\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6548\u586b\u8865AI\u8f85\u52a9\u6e38\u620f\u5f00\u53d1\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4f7f\u5927\u6a21\u578b\u6210\u4e3a\u7b80\u5316\u4ece\u8bbe\u8ba1\u5230\u5b9e\u73b0\u6d41\u7a0b\u7684\u6709\u4ef7\u503c\u5de5\u5177\u3002"}}
{"id": "2509.08857", "pdf": "https://arxiv.org/pdf/2509.08857", "abs": "https://arxiv.org/abs/2509.08857", "authors": ["Marcelino Garcia", "Renato Garcia", "Arthur Parizotto", "Andre Mendes", "Pedro Valle", "Ricardo Vilela", "Renato Balancieri", "Williamson Silva"], "title": "A Systematic Mapping Study on Chatbots in Programming Education", "categories": ["cs.SE", "cs.HC"], "comment": "18 pages, 1 figure, 3 tables", "summary": "Educational chatbots have gained prominence as support tools for teaching\nprogramming, particularly in introductory learning contexts. This paper\npresents a Systematic Mapping Study (SMS) that investigated how such agents\nhave been developed and applied in programming education. From an initial set\nof 3,216 publications, 54 studies were selected and analyzed based on five\nresearch subquestions, addressing chatbot types, programming languages used,\neducational content covered, interaction models, and application contexts. The\nresults reveal a predominance of chatbots designed for Python instruction,\nfocusing on fundamental programming concepts, and employing a wide variety of\npedagogical approaches and technological architectures. In addition to\nidentifying trends and gaps in the literature, this study provides insights to\ninform the development of new educational tools for programming instruction.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\u5206\u6790\u6559\u80b2\u804a\u5929\u673a\u5668\u4eba\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u5f00\u53d1\u4e0e\u5e94\u7528\uff0c\u63ed\u793a\u76f8\u5173\u8d8b\u52bf\u4e0e\u5dee\u8ddd\uff0c\u4e3a\u65b0\u6559\u80b2\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u63a2\u7a76\u6559\u80b2\u804a\u5929\u673a\u5668\u4eba\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u5f00\u53d1\u4e0e\u5e94\u7528\u60c5\u51b5\u3002", "method": "\u5bf93216\u7bc7\u51fa\u7248\u7269\u7b5b\u9009\u51fa54\u7bc7\u7814\u7a76\uff0c\u57fa\u4e8e\u4e94\u4e2a\u7814\u7a76\u5b50\u95ee\u9898\u8fdb\u884c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4ee5Python\u6559\u5b66\u4e3a\u4e3b\u7684\u804a\u5929\u673a\u5668\u4eba\u5c45\u591a\uff0c\u805a\u7126\u7f16\u7a0b\u57fa\u7840\u6982\u5ff5\uff0c\u91c7\u7528\u591a\u79cd\u6559\u5b66\u65b9\u6cd5\u548c\u6280\u672f\u67b6\u6784\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc6\u522b\u4e86\u6587\u732e\u4e2d\u7684\u8d8b\u52bf\u548c\u5dee\u8ddd\uff0c\u4e3a\u7f16\u7a0b\u6559\u5b66\u65b0\u6559\u80b2\u5de5\u5177\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.09452", "pdf": "https://arxiv.org/pdf/2509.09452", "abs": "https://arxiv.org/abs/2509.09452", "authors": ["Florian Gutekunst", "Martin Herdegen", "David Hobson"], "title": "Optimal Investment and Consumption in a Stochastic Factor Model", "categories": ["q-fin.MF", "q-fin.PM", "91G10 91G80 93E20 34A34 91B16"], "comment": null, "summary": "In this article, we study optimal investment and consumption in an incomplete\nstochastic factor model for a power utility investor on the infinite horizon.\nWhen the state space of the stochastic factor is finite, we give a complete\ncharacterisation of the well-posedness of the problem, and provide an efficient\nnumerical algorithm for computing the value function. When the state space is a\n(possibly infinite) open interval and the stochastic factor is represented by\nan It\\^o diffusion, we develop a general theory of sub- and supersolutions for\nsecond-order ordinary differential equations on open domains without boundary\nvalues to prove existence of the solution to the Hamilton-Jacobi-Bellman (HJB)\nequation along with explicit bounds for the solution. By characterising the\nasymptotic behaviour of the solution, we are also able to provide rigorous\nverification arguments for various models, including -- for the first time --\nthe Heston model. Finally, we link the discrete and continuous setting and show\nthat that the value function in the diffusion setting can be approximated very\nefficiently through a fast discretisation scheme.", "AI": {"tldr": "\u7814\u7a76\u65e0\u9650\u671f\u5e42\u6548\u7528\u6295\u8d44\u8005\u5728\u4e0d\u5b8c\u5168\u968f\u673a\u56e0\u5b50\u6a21\u578b\u4e2d\u7684\u6700\u4f18\u6295\u8d44\u548c\u6d88\u8d39\u95ee\u9898\uff0c\u7ed9\u51fa\u6709\u9650\u72b6\u6001\u7a7a\u95f4\u95ee\u9898\u9002\u5b9a\u6027\u7684\u523b\u753b\u4e0e\u7b97\u6cd5\uff0c\u4e3a\u65e0\u8fb9\u754c\u503c\u7684\u4e8c\u9636\u5e38\u5fae\u5206\u65b9\u7a0b\u5f00\u53d1\u7406\u8bba\u8bc1\u660eHJB\u65b9\u7a0b\u89e3\u7684\u5b58\u5728\u6027\uff0c\u80fd\u5bf9\u591a\u79cd\u6a21\u578b\u9a8c\u8bc1\uff0c\u8fd8\u7ed9\u51fa\u79bb\u6563\u4e0e\u8fde\u7eed\u8bbe\u7f6e\u7684\u8054\u7cfb\u53ca\u8fd1\u4f3c\u65b9\u6848\u3002", "motivation": "\u5728\u4e0d\u5b8c\u5168\u968f\u673a\u56e0\u5b50\u6a21\u578b\u4e0b\u7814\u7a76\u5e42\u6548\u7528\u6295\u8d44\u8005\u65e0\u9650\u671f\u7684\u6700\u4f18\u6295\u8d44\u548c\u6d88\u8d39\u95ee\u9898\u3002", "method": "\u5728\u968f\u673a\u56e0\u5b50\u72b6\u6001\u7a7a\u95f4\u6709\u9650\u65f6\u7ed9\u51fa\u9002\u5b9a\u6027\u523b\u753b\u4e0e\u6570\u503c\u7b97\u6cd5\uff1b\u72b6\u6001\u7a7a\u95f4\u4e3a\u5f00\u533a\u95f4\u65f6\uff0c\u4e3a\u65e0\u8fb9\u754c\u503c\u4e8c\u9636\u5e38\u5fae\u5206\u65b9\u7a0b\u5f00\u53d1\u4e0a\u4e0b\u89e3\u7406\u8bba\uff1b\u523b\u753b\u89e3\u7684\u6e10\u8fd1\u884c\u4e3a\u8fdb\u884c\u9a8c\u8bc1\uff1b\u7ed9\u51fa\u79bb\u6563\u4e0e\u8fde\u7eed\u8bbe\u7f6e\u7684\u8054\u7cfb\u548c\u79bb\u6563\u5316\u8fd1\u4f3c\u65b9\u6848\u3002", "result": "\u7ed9\u51fa\u6709\u9650\u72b6\u6001\u7a7a\u95f4\u95ee\u9898\u7684\u9002\u5b9a\u6027\u523b\u753b\u548c\u6570\u503c\u7b97\u6cd5\uff1b\u8bc1\u660eHJB\u65b9\u7a0b\u89e3\u7684\u5b58\u5728\u6027\u5e76\u7ed9\u51fa\u89e3\u7684\u663e\u5f0f\u754c\uff1b\u80fd\u5bf9\u591a\u79cd\u6a21\u578b\u5305\u62ecHeston\u6a21\u578b\u8fdb\u884c\u4e25\u683c\u9a8c\u8bc1\uff1b\u80fd\u7528\u79bb\u6563\u5316\u65b9\u6848\u9ad8\u6548\u8fd1\u4f3c\u6269\u6563\u8bbe\u7f6e\u4e0b\u7684\u503c\u51fd\u6570\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5e42\u6548\u7528\u6295\u8d44\u8005\u5728\u4e0d\u5b8c\u5168\u968f\u673a\u56e0\u5b50\u6a21\u578b\u4e0b\u7684\u6700\u4f18\u6295\u8d44\u548c\u6d88\u8d39\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6cd5\u548c\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2509.08911", "pdf": "https://arxiv.org/pdf/2509.08911", "abs": "https://arxiv.org/abs/2509.08911", "authors": ["Weiyuan Gong", "Tongyang Li", "Xinzhao Wang", "Zhiyu Zhang"], "title": "Instance-Optimal Matrix Multiplicative Weight Update and Its Quantum Applications", "categories": ["cs.LG", "cs.AI", "cs.DS", "quant-ph", "stat.ML"], "comment": "47 pages", "summary": "The Matrix Multiplicative Weight Update (MMWU) is a seminal online learning\nalgorithm with numerous applications. Applied to the matrix version of the\nLearning from Expert Advice (LEA) problem on the $d$-dimensional spectraplex,\nit is well known that MMWU achieves the minimax-optimal regret bound of\n$O(\\sqrt{T\\log d})$, where $T$ is the time horizon. In this paper, we present\nan improved algorithm achieving the instance-optimal regret bound of\n$O(\\sqrt{T\\cdot S(X||d^{-1}I_d)})$, where $X$ is the comparator in the regret,\n$I_d$ is the identity matrix, and $S(\\cdot||\\cdot)$ denotes the quantum\nrelative entropy. Furthermore, our algorithm has the same computational\ncomplexity as MMWU, indicating that the improvement in the regret bound is\n``free''.\n  Technically, we first develop a general potential-based framework for matrix\nLEA, with MMWU being its special case induced by the standard exponential\npotential. Then, the crux of our analysis is a new ``one-sided'' Jensen's trace\ninequality built on a Laplace transform technique, which allows the application\nof general potential functions beyond exponential to matrix LEA. Our algorithm\nis finally induced by an optimal potential function from the vector LEA\nproblem, based on the imaginary error function.\n  Complementing the above, we provide a memory lower bound for matrix LEA, and\nexplore the applications of our algorithm in quantum learning theory. We show\nthat it outperforms the state of the art for learning quantum states corrupted\nby depolarization noise, random quantum states, and Gibbs states. In addition,\napplying our algorithm to linearized convex losses enables predicting nonlinear\nquantum properties, such as purity, quantum virtual cooling, and R\\'{e}nyi-$2$\ncorrelation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.09238", "pdf": "https://arxiv.org/pdf/2509.09238", "abs": "https://arxiv.org/abs/2509.09238", "authors": ["Thorbj\u00f8rn Mosekj\u00e6r Iversen", "Lars Car\u00f8e S\u00f8rensen", "Simon Faarvang Mathiesen", "Henrik Gordon Petersen"], "title": "Global Optimization of Stochastic Black-Box Functions with Arbitrary Noise Distributions using Wilson Score Kernel Density Estimation", "categories": ["stat.ML", "cs.LG", "cs.RO"], "comment": null, "summary": "Many optimization problems in robotics involve the optimization of\ntime-expensive black-box functions, such as those involving complex simulations\nor evaluation of real-world experiments. Furthermore, these functions are often\nstochastic as repeated experiments are subject to unmeasurable disturbances.\nBayesian optimization can be used to optimize such methods in an efficient\nmanner by deploying a probabilistic function estimator to estimate with a given\nconfidence so that regions of the search space can be pruned away.\nConsequently, the success of the Bayesian optimization depends on the function\nestimator's ability to provide informative confidence bounds. Existing function\nestimators require many function evaluations to infer the underlying confidence\nor depend on modeling of the disturbances. In this paper, it is shown that the\nconfidence bounds provided by the Wilson Score Kernel Density Estimator\n(WS-KDE) are applicable as excellent bounds to any stochastic function with an\noutput confined to the closed interval [0;1] regardless of the distribution of\nthe output. This finding opens up the use of WS-KDE for stable global\noptimization on a wider range of cost functions. The properties of WS-KDE in\nthe context of Bayesian optimization are demonstrated in simulation and applied\nto the problem of automated trap design for vibrational part feeders.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u8d1d\u53f6\u65af\u4f18\u5316\u4f9d\u8d56\u51fd\u6570\u4f30\u8ba1\u5668\u63d0\u4f9b\u4fe1\u606f\u6027\u7f6e\u4fe1\u533a\u95f4\uff0c\u73b0\u6709\u4f30\u8ba1\u5668\u6709\u5c40\u9650\uff0c\u8bc1\u660eWS - KDE\u7684\u7f6e\u4fe1\u533a\u95f4\u9002\u7528\u4e8e\u8f93\u51fa\u5728[0,1]\u7684\u968f\u673a\u51fd\u6570\uff0c\u53ef\u7528\u4e8e\u66f4\u5e7f\u6cdb\u6210\u672c\u51fd\u6570\u7684\u7a33\u5b9a\u5168\u5c40\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u548c\u5e94\u7528\u5c55\u793a\u5176\u7279\u6027\u3002", "motivation": "\u73b0\u6709\u4f18\u5316\u95ee\u9898\u6d89\u53ca\u65f6\u95f4\u6210\u672c\u9ad8\u7684\u9ed1\u76d2\u968f\u673a\u51fd\u6570\uff0c\u4e14\u73b0\u6709\u51fd\u6570\u4f30\u8ba1\u5668\u5728\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u5b58\u5728\u9700\u5927\u91cf\u51fd\u6570\u8bc4\u4f30\u6216\u4f9d\u8d56\u5e72\u6270\u5efa\u6a21\u7684\u5c40\u9650\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76Wilson Score Kernel Density Estimator (WS - KDE)\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u901a\u8fc7\u4eff\u771f\u548c\u5e94\u7528\u4e8e\u632f\u52a8\u96f6\u4ef6\u8fdb\u6599\u5668\u7684\u81ea\u52a8\u9677\u9631\u8bbe\u8ba1\u95ee\u9898\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u8bc1\u660eWS - KDE\u7684\u7f6e\u4fe1\u533a\u95f4\u9002\u7528\u4e8e\u8f93\u51fa\u5728[0,1]\u7684\u4efb\u4f55\u968f\u673a\u51fd\u6570\uff0c\u53ef\u7528\u4e8e\u66f4\u5e7f\u6cdb\u6210\u672c\u51fd\u6570\u7684\u7a33\u5b9a\u5168\u5c40\u4f18\u5316\u3002", "conclusion": "WS - KDE\u53ef\u7528\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u66f4\u5e7f\u6cdb\u6210\u672c\u51fd\u6570\u7684\u7a33\u5b9a\u5168\u5c40\u4f18\u5316\uff0c\u5176\u7f6e\u4fe1\u533a\u95f4\u5177\u6709\u826f\u597d\u9002\u7528\u6027\u3002"}}
{"id": "2509.09529", "pdf": "https://arxiv.org/pdf/2509.09529", "abs": "https://arxiv.org/abs/2509.09529", "authors": ["Shangqing Shi", "Luoxiao Zhang", "Yuchen Yin", "Xiong Yang", "Hoileong Lee"], "title": "A modified RIME algorithm with covariance learning and diversity enhancement for numerical optimization", "categories": ["cs.NE", "cs.AI", "cs.CE"], "comment": "This is the author's preprint of the article published in Cluster\n  Computing (Springer): Shi, S., Zhang, L., Yin, Y. et al. A modified RIME\n  algorithm with covariance learning and diversity enhancement for numerical\n  optimization. Cluster Comput 28, 658 (2025). The final authenticated version\n  is available online at SpringerLink", "summary": "Metaheuristics are widely applied for their ability to provide more efficient\nsolutions. The RIME algorithm is a recently proposed physical-based\nmetaheuristic algorithm with certain advantages. However, it suffers from rapid\nloss of population diversity during optimization and is prone to fall into\nlocal optima, leading to unbalanced exploitation and exploration. To address\nthe shortcomings of RIME, this paper proposes a modified RIME with covariance\nlearning and diversity enhancement (MRIME-CD). The algorithm applies three\nstrategies to improve the optimization capability. First, a covariance learning\nstrategy is introduced in the soft-rime search stage to increase the population\ndiversity and balance the over-exploitation ability of RIME through the\nbootstrapping effect of dominant populations. Second, in order to moderate the\ntendency of RIME population to approach the optimal individual in the early\nsearch stage, an average bootstrapping strategy is introduced into the\nhard-rime puncture mechanism, which guides the population search through the\nweighted position of the dominant populations, thus enhancing the global search\nability of RIME in the early stage. Finally, a new stagnation indicator is\nproposed, and a stochastic covariance learning strategy is used to update the\nstagnant individuals in the population when the algorithm gets stagnant, thus\nenhancing the ability to jump out of the local optimal solution. The proposed\nMRIME-CD algorithm is subjected to a series of validations on the CEC2017 test\nset, the CEC2022 test set, and the experimental results are analyzed using the\nFriedman test, the Wilcoxon rank sum test, and the Kruskal Wallis test. The\nresults show that MRIME-CD can effectively improve the performance of basic\nRIME and has obvious superiorities in terms of solution accuracy, convergence\nspeed and stability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u7684MRIME - CD\u7b97\u6cd5\u89e3\u51b3RIME\u7b97\u6cd5\u4e0d\u8db3\uff0c\u7ecf\u591a\u6d4b\u8bd5\u96c6\u9a8c\u8bc1\uff0c\u8be5\u7b97\u6cd5\u5728\u89e3\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0a\u6709\u4f18\u52bf\u3002", "motivation": "RIME\u7b97\u6cd5\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u79cd\u7fa4\u591a\u6837\u6027\u5feb\u901f\u4e27\u5931\uff0c\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u5f00\u53d1\u548c\u63a2\u7d22\u80fd\u529b\u4e0d\u5e73\u8861\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faMRIME - CD\u7b97\u6cd5\uff0c\u91c7\u7528\u534f\u65b9\u5dee\u5b66\u4e60\u7b56\u7565\u3001\u5e73\u5747\u5f15\u5bfc\u7b56\u7565\u548c\u968f\u673a\u534f\u65b9\u5dee\u5b66\u4e60\u7b56\u7565\u6765\u63d0\u5347\u4f18\u5316\u80fd\u529b\uff0c\u5e76\u5728CEC2017\u548cCEC2022\u6d4b\u8bd5\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u7528Friedman\u3001Wilcoxon\u79e9\u548c\u4e0eKruskal Wallis\u68c0\u9a8c\u5206\u6790\u7ed3\u679c\u3002", "result": "MRIME - CD\u80fd\u6709\u6548\u63d0\u5347\u57fa\u672cRIME\u7b97\u6cd5\u6027\u80fd\uff0c\u5728\u89e3\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u4e0a\u6709\u660e\u663e\u4f18\u52bf\u3002", "conclusion": "MRIME - CD\u7b97\u6cd5\u53ef\u6709\u6548\u89e3\u51b3RIME\u7b97\u6cd5\u7684\u7f3a\u70b9\uff0c\u662f\u4e00\u79cd\u66f4\u4f18\u7684\u7b97\u6cd5\u3002"}}
{"id": "2509.09223", "pdf": "https://arxiv.org/pdf/2509.09223", "abs": "https://arxiv.org/abs/2509.09223", "authors": ["Jia Dan", "Xu Pai"], "title": "Rethinking Cost-Sharing Policies: Enhancing Chronic Disease Management for Disadvantaged Populations", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "The increasing prevalence of chronic diseases poses a significant challenge\nto global efforts to alleviate poverty, promote health equity, and control\nhealthcare costs. This study adopts a structural approach to explore how\npatients manage chronic diseases by making trade-offs between inpatient care\nand ambulatory care outpatient services. Specifically, it investigates whether\ndisadvantaged populations make distinct trade-offs compared to the general\npopulation and examines the impact of anti-poverty programs that reduce\ninpatient cost-sharing.\n  Using health insurance claims data from a rural county in China, the study\nreveals that disadvantaged individuals tend to avoid ambulatory care unless it\nsubstantially lowers medical expenses. In contrast, the general population is\nmore likely to prioritize ambulatory care, even at higher costs, to prevent\ndisease progression. The findings also indicate that current anti-poverty\ninsurance policies, which focus predominantly on hospitalization, inadvertently\ndecrease ambulatory care usage by 23\\%, resulting in increased healthcare costs\nand a 46.2\\% decline in patient welfare. Counterfactual analysis suggests that\nreducing cost-sharing for ambulatory care would be a more cost-effective\nstrategy for improving health outcomes and supporting disadvantaged populations\nthan providing travel subsidies.", "AI": {"tldr": "\u7814\u7a76\u91c7\u7528\u7ed3\u6784\u65b9\u6cd5\uff0c\u5229\u7528\u4e2d\u56fd\u67d0\u519c\u6751\u53bf\u533b\u4fdd\u6570\u636e\uff0c\u5bf9\u6bd4\u5f31\u52bf\u7fa4\u4f53\u548c\u666e\u901a\u4eba\u7fa4\u6162\u6027\u75c5\u95e8\u8bca\u4e0e\u4f4f\u9662\u62a4\u7406\u6743\u8861\u5dee\u5f02\uff0c\u53d1\u73b0\u73b0\u884c\u6276\u8d2b\u4fdd\u9669\u653f\u7b56\u6709\u5f0a\u7aef\uff0c\u964d\u4f4e\u95e8\u8bca\u81ea\u4ed8\u8d39\u7528\u66f4\u5177\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u6162\u6027\u75c5\u6d41\u884c\u5bf9\u51cf\u8d2b\u3001\u5065\u5eb7\u516c\u5e73\u548c\u63a7\u5236\u533b\u7597\u6210\u672c\u6784\u6210\u6311\u6218\uff0c\u7814\u7a76\u60a3\u8005\u5728\u95e8\u8bca\u548c\u4f4f\u9662\u62a4\u7406\u95f4\u7684\u6743\u8861\uff0c\u4ee5\u53ca\u5f31\u52bf\u7fa4\u4f53\u7684\u5dee\u5f02\u548c\u6276\u8d2b\u9879\u76ee\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u7ed3\u6784\u65b9\u6cd5\uff0c\u5229\u7528\u4e2d\u56fd\u67d0\u519c\u6751\u53bf\u7684\u533b\u4fdd\u7406\u8d54\u6570\u636e\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u5f31\u52bf\u7fa4\u4f53\u9664\u975e\u95e8\u8bca\u5927\u5e45\u964d\u4f4e\u8d39\u7528\u624d\u9009\u62e9\uff0c\u666e\u901a\u4eba\u7fa4\u66f4\u503e\u5411\u95e8\u8bca\uff1b\u73b0\u884c\u6276\u8d2b\u4fdd\u9669\u653f\u7b56\u4f7f\u95e8\u8bca\u4f7f\u7528\u7387\u4e0b\u964d23%\uff0c\u589e\u52a0\u533b\u7597\u6210\u672c\uff0c\u60a3\u8005\u798f\u5229\u4e0b\u964d46.2%\u3002", "conclusion": "\u964d\u4f4e\u95e8\u8bca\u81ea\u4ed8\u8d39\u7528\u6bd4\u63d0\u4f9b\u4ea4\u901a\u8865\u8d34\u66f4\u80fd\u6539\u5584\u5065\u5eb7\u7ed3\u679c\u548c\u652f\u6301\u5f31\u52bf\u7fa4\u4f53\u3002"}}
{"id": "2509.09561", "pdf": "https://arxiv.org/pdf/2509.09561", "abs": "https://arxiv.org/abs/2509.09561", "authors": ["Argyrios Deligkas", "Eduard Eiben", "Sophie Klumper", "Guido Sch\u00e4fer", "Artem Tsikiridis"], "title": "Mechanism Design with Outliers and Predictions", "categories": ["cs.GT"], "comment": null, "summary": "We initiate the study of mechanism design with outliers, where the designer\ncan discard $z$ agents from the social cost objective. This setting is\nparticularly relevant when some agents exhibit extreme or atypical preferences.\nAs a natural case study, we consider facility location on the line: $n$\nstrategic agents report their preferred locations, and a mechanism places a\nfacility to minimize a social cost function. In our setting, the $z$ agents\nfarthest from the chosen facility are excluded from the social cost. While it\nmay seem intuitive that discarding outliers improves efficiency, our results\nreveal that the opposite can hold.\n  We derive tight bounds for deterministic strategyproof mechanisms under the\ntwo most-studied objectives: utilitarian and egalitarian social cost. Our\nresults offer a comprehensive view of the impact of outliers. We first show\nthat when $z \\ge n/2$, no strategyproof mechanism can achieve a bounded\napproximation for either objective. For egalitarian cost, selecting the $(z +\n1)$-th order statistic is strategyproof and 2-approximate. In fact, we show\nthat this is best possible by providing a matching lower bound. Notably, this\nlower bound of 2 persists even when the mechanism has access to a prediction of\nthe optimal location, in stark contrast to the setting without outliers. For\nutilitarian cost, we show that strategyproof mechanisms cannot effectively\nexploit outliers, leading to the counterintuitive outcome that approximation\nguarantees worsen as the number of outliers increases. However, in this case,\naccess to a prediction allows us to design a strategyproof mechanism achieving\nthe best possible trade-off between consistency and robustness. Finally, we\nalso establish lower bounds for randomized mechanisms that are truthful in\nexpectation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u542b\u5f02\u5e38\u503c\u7684\u673a\u5236\u8bbe\u8ba1\uff0c\u4ee5\u76f4\u7ebf\u4e0a\u7684\u8bbe\u65bd\u9009\u5740\u4e3a\u4f8b\uff0c\u63a8\u5bfc\u786e\u5b9a\u6027\u7b56\u7565\u8bc1\u660e\u673a\u5236\u5728\u529f\u5229\u4e3b\u4e49\u548c\u5e73\u5747\u4e3b\u4e49\u793e\u4f1a\u6210\u672c\u76ee\u6807\u4e0b\u7684\u8fb9\u754c\uff0c\u53d1\u73b0\u4e22\u5f03\u5f02\u5e38\u503c\u672a\u5fc5\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u5f53\u90e8\u5206\u53c2\u4e0e\u8005\u6709\u6781\u7aef\u6216\u975e\u5178\u578b\u504f\u597d\u65f6\uff0c\u53ef\u4ece\u793e\u4f1a\u6210\u672c\u76ee\u6807\u4e2d\u5254\u9664z\u4e2a\u53c2\u4e0e\u8005\u7684\u673a\u5236\u8bbe\u8ba1\u3002", "method": "\u9488\u5bf9\u529f\u5229\u4e3b\u4e49\u548c\u5e73\u5747\u4e3b\u4e49\u793e\u4f1a\u6210\u672c\u76ee\u6807\uff0c\u63a8\u5bfc\u786e\u5b9a\u6027\u7b56\u7565\u8bc1\u660e\u673a\u5236\u7684\u8fb9\u754c\uff0c\u8fd8\u5efa\u7acb\u4e86\u671f\u671b\u8bda\u5b9e\u7684\u968f\u673a\u673a\u5236\u7684\u4e0b\u754c\u3002", "result": "\u5f53z \u2265 n/2\u65f6\uff0c\u65e0\u7b56\u7565\u8bc1\u660e\u673a\u5236\u80fd\u5bf9\u4efb\u4e00\u76ee\u6807\u5b9e\u73b0\u6709\u754c\u8fd1\u4f3c\uff1b\u5bf9\u4e8e\u5e73\u5747\u4e3b\u4e49\u6210\u672c\uff0c\u9009\u62e9\u7b2c(z + 1)\u9636\u7edf\u8ba1\u91cf\u662f\u7b56\u7565\u8bc1\u660e\u4e142 - \u8fd1\u4f3c\u7684\uff1b\u5bf9\u4e8e\u529f\u5229\u4e3b\u4e49\u6210\u672c\uff0c\u7b56\u7565\u8bc1\u660e\u673a\u5236\u65e0\u6cd5\u6709\u6548\u5229\u7528\u5f02\u5e38\u503c\uff0c\u8fd1\u4f3c\u4fdd\u8bc1\u968f\u5f02\u5e38\u503c\u6570\u91cf\u589e\u52a0\u800c\u53d8\u5dee\u3002", "conclusion": "\u4e22\u5f03\u5f02\u5e38\u503c\u4e0d\u4e00\u5b9a\u80fd\u63d0\u9ad8\u6548\u7387\uff0c\u4e0d\u540c\u6210\u672c\u76ee\u6807\u4e0b\u673a\u5236\u8bbe\u8ba1\u6709\u4e0d\u540c\u7279\u70b9\uff0c\u6709\u9884\u6d4b\u65f6\u53ef\u5728\u4e00\u81f4\u6027\u548c\u9c81\u68d2\u6027\u95f4\u5b9e\u73b0\u6700\u4f73\u6743\u8861\u3002"}}
{"id": "2509.09094", "pdf": "https://arxiv.org/pdf/2509.09094", "abs": "https://arxiv.org/abs/2509.09094", "authors": ["Guochu Xiong", "Xiangzhong Luo", "Weichen Liu"], "title": "Coherence-Aware Task Graph Modeling for Realistic Application", "categories": ["cs.DC"], "comment": "Accepted by MEMOCODE'25, 10 pages", "summary": "As multicore systems continue to scale, cache coherence has emerged as a\ncritical determinant of system performance, with coherence behavior and task\nexecution closely intertwined, reshaping inter-task dependencies. Task graph\nmodeling provides a structured way to capture such dependencies and serves as\nthe foundation for many system-level design strategies. However, these\nstrategies typically rely on predefined task graphs, while many real-world\napplications lack explicit graphs and exhibit dynamic, data-dependent behavior,\nlimiting the effectiveness of static approaches. To address this, several task\ngraph modeling methods for realistic workloads have been developed. Yet, they\neither rely on implicit techniques that use application-specific features\nwithout producing explicit graphs, or they generate graphs tailored to fixed\nscheduling models, which limits generality. More importantly, they often\noverlook coherence interactions, creating a gap between design assumptions and\nactual runtime behavior. To overcome these limitations, we propose CoTAM, a\nCoherence-Aware Task Graph Modeling framework for realistic workloads that\nconstructs a unified task graph reflecting runtime behavior. CoTAM analyzes the\nimpact of coherence by decoupling its effects from overall execution,\nquantifies its influence through a learned weighting scheme, and infers\ninter-task dependencies for coherence-aware graph generation. Extensive\nexperiments show that CoTAM outperforms implicit methods, bridging the gap\nbetween dynamic workload behavior and existing designs while demonstrating the\nimportance of incorporating cache coherence into task graph modeling for\naccurate and generalizable system-level analysis.", "AI": {"tldr": "\u968f\u7740\u591a\u6838\u7cfb\u7edf\u53d1\u5c55\uff0c\u7f13\u5b58\u4e00\u81f4\u6027\u5bf9\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u4efb\u52a1\u56fe\u5efa\u6a21\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51faCoTAM\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u9690\u5f0f\u65b9\u6cd5\uff0c\u4f53\u73b0\u4e86\u5c06\u7f13\u5b58\u4e00\u81f4\u6027\u7eb3\u5165\u4efb\u52a1\u56fe\u5efa\u6a21\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9884\u5b9a\u4e49\u4efb\u52a1\u56fe\u7684\u7cfb\u7edf\u7ea7\u8bbe\u8ba1\u7b56\u7565\u5bf9\u7f3a\u4e4f\u663e\u5f0f\u56fe\u3001\u5177\u6709\u52a8\u6001\u6570\u636e\u4f9d\u8d56\u884c\u4e3a\u7684\u771f\u5b9e\u5e94\u7528\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u73b0\u6709\u4efb\u52a1\u56fe\u5efa\u6a21\u65b9\u6cd5\u5b58\u5728\u65e0\u6cd5\u751f\u6210\u663e\u5f0f\u56fe\u3001\u901a\u7528\u6027\u4e0d\u8db3\u3001\u5ffd\u7565\u4e00\u81f4\u6027\u4ea4\u4e92\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faCoTAM\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4e00\u81f4\u6027\u5f71\u54cd\u4ece\u6574\u4f53\u6267\u884c\u4e2d\u5206\u79bb\u3001\u7528\u5b66\u4e60\u7684\u52a0\u6743\u65b9\u6848\u91cf\u5316\u5176\u5f71\u54cd\u3001\u63a8\u65ad\u4efb\u52a1\u95f4\u4f9d\u8d56\u6765\u6784\u5efa\u53cd\u6620\u8fd0\u884c\u65f6\u884c\u4e3a\u7684\u7edf\u4e00\u4efb\u52a1\u56fe\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793aCoTAM\u4f18\u4e8e\u9690\u5f0f\u65b9\u6cd5\uff0c\u7f29\u5c0f\u4e86\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u884c\u4e3a\u4e0e\u73b0\u6709\u8bbe\u8ba1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u5c06\u7f13\u5b58\u4e00\u81f4\u6027\u7eb3\u5165\u4efb\u52a1\u56fe\u5efa\u6a21\u5bf9\u51c6\u786e\u548c\u53ef\u63a8\u5e7f\u7684\u7cfb\u7edf\u7ea7\u5206\u6790\u5f88\u91cd\u8981\u3002"}}
{"id": "2509.09114", "pdf": "https://arxiv.org/pdf/2509.09114", "abs": "https://arxiv.org/abs/2509.09114", "authors": ["Kelin Ren", "Chan-Yang Ju", "Dong-Ho Lee"], "title": "Modality Alignment with Multi-scale Bilateral Attention for Multimodal Recommendation", "categories": ["cs.IR"], "comment": "Accepted by CIKM 2025", "summary": "Multimodal recommendation systems are increasingly becoming foundational\ntechnologies for e-commerce and content platforms, enabling personalized\nservices by jointly modeling users' historical behaviors and the multimodal\nfeatures of items (e.g., visual and textual). However, most existing methods\nrely on either static fusion strategies or graph-based local interaction\nmodeling, facing two critical limitations: (1) insufficient ability to model\nfine-grained cross-modal associations, leading to suboptimal fusion quality;\nand (2) a lack of global distribution-level consistency, causing\nrepresentational bias. To address these, we propose MambaRec, a novel framework\nthat integrates local feature alignment and global distribution regularization\nvia attention-guided learning. At its core, we introduce the Dilated Refinement\nAttention Module (DREAM), which uses multi-scale dilated convolutions with\nchannel-wise and spatial attention to align fine-grained semantic patterns\nbetween visual and textual modalities. This module captures hierarchical\nrelationships and context-aware associations, improving cross-modal semantic\nmodeling. Additionally, we apply Maximum Mean Discrepancy (MMD) and contrastive\nloss functions to constrain global modality alignment, enhancing semantic\nconsistency. This dual regularization reduces mode-specific deviations and\nboosts robustness. To improve scalability, MambaRec employs a dimensionality\nreduction strategy to lower the computational cost of high-dimensional\nmultimodal features. Extensive experiments on real-world e-commerce datasets\nshow that MambaRec outperforms existing methods in fusion quality,\ngeneralization, and efficiency. Our code has been made publicly available at\nhttps://github.com/rkl71/MambaRec.", "AI": {"tldr": "\u63d0\u51faMambaRec\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u73b0\u6709\u65b9\u6cd5\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u878d\u5408\u8d28\u91cf\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u65b9\u6cd5\u5b58\u5728\u96be\u4ee5\u5efa\u6a21\u7ec6\u7c92\u5ea6\u8de8\u6a21\u6001\u5173\u8054\u548c\u7f3a\u4e4f\u5168\u5c40\u5206\u5e03\u4e00\u81f4\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faMambaRec\u6846\u67b6\uff0c\u5f15\u5165DREAM\u6a21\u5757\u8fdb\u884c\u5c40\u90e8\u7279\u5f81\u5bf9\u9f50\uff0c\u5e94\u7528MMD\u548c\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u8fdb\u884c\u5168\u5c40\u5206\u5e03\u6b63\u5219\u5316\uff0c\u91c7\u7528\u964d\u7ef4\u7b56\u7565\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728\u771f\u5b9e\u7535\u5546\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMambaRec\u5728\u878d\u5408\u8d28\u91cf\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MambaRec\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2509.08970", "pdf": "https://arxiv.org/pdf/2509.08970", "abs": "https://arxiv.org/abs/2509.08970", "authors": ["Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "title": "Global Constraint LLM Agents for Text-to-Model Translation", "categories": ["cs.AI"], "comment": null, "summary": "Natural language descriptions of optimization or satisfaction problems are\nchallenging to translate into correct MiniZinc models, as this process demands\nboth logical reasoning and constraint programming expertise. We introduce a\nframework that addresses this challenge with an agentic approach: multiple\nspecialized large language model (LLM) agents decompose the modeling task by\nglobal constraint type. Each agent is dedicated to detecting and generating\ncode for a specific class of global constraint, while a final assembler agent\nintegrates these constraint snippets into a complete MiniZinc model. By\ndividing the problem into smaller, well-defined sub-tasks, each LLM handles a\nsimpler reasoning challenge, potentially reducing overall complexity. We\nconduct initial experiments with several LLMs and show better performance\nagainst baselines such as one-shot prompting and chain-of-thought prompting.\nFinally, we outline a comprehensive roadmap for future work, highlighting\npotential enhancements and directions for improvement.", "AI": {"tldr": "\u4ecb\u7ecd\u7528\u591aLLM\u4ee3\u7406\u6846\u67b6\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u4f18\u5316\u6216\u6ee1\u8db3\u95ee\u9898\u8f6c\u5316\u4e3aMiniZinc\u6a21\u578b\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u5e76\u89c4\u5212\u672a\u6765\u5de5\u4f5c\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u4f18\u5316\u6216\u6ee1\u8db3\u95ee\u9898\u8f6c\u5316\u4e3aMiniZinc\u6a21\u578b\u9700\u903b\u8f91\u63a8\u7406\u548c\u7ea6\u675f\u7f16\u7a0b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u4ee3\u7406\u65b9\u6cd5\uff0c\u591a\u4e2a\u4e13\u95e8\u7684LLM\u4ee3\u7406\u6309\u5168\u5c40\u7ea6\u675f\u7c7b\u578b\u5206\u89e3\u5efa\u6a21\u4efb\u52a1\uff0c\u6700\u540e\u7531\u7ec4\u88c5\u4ee3\u7406\u6574\u5408\u4ee3\u7801\u6210\u5b8c\u6574\u6a21\u578b\u3002", "result": "\u7528\u591a\u4e2aLLM\u8fdb\u884c\u7684\u521d\u59cb\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u5355\u6b65\u63d0\u793a\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u672a\u6765\u5de5\u4f5c\u7684\u5168\u9762\u8def\u7ebf\u56fe\uff0c\u6307\u51fa\u6f5c\u5728\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2509.09400", "pdf": "https://arxiv.org/pdf/2509.09400", "abs": "https://arxiv.org/abs/2509.09400", "authors": ["Valerio Besozzi", "Enrico Fiasco", "Marco Danelutto", "Patrizio Dazzi"], "title": "WebAssembly and Unikernels: A Comparative Study for Serverless at the Edge", "categories": ["cs.DC", "cs.PF"], "comment": "Accepted at VHPC25", "summary": "Serverless computing at the edge requires lightweight execution environments\nto minimize cold start latency, especially in Urgent Edge Computing (UEC). This\npaper compares WebAssembly and unikernel-based MicroVMs for serverless\nworkloads. We present Limes, a WebAssembly runtime built on Wasmtime, and\nevaluate it against the Firecracker-based environment used in SPARE. Results\nshow that WebAssembly offers lower cold start times for lightweight functions\nbut suffers with complex workloads, while Firecracker provides higher, but\nstable, cold starts and better execution performance, particularly for\nI/O-heavy tasks.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4WebAssembly\u548c\u57fa\u4e8eunikernel\u7684MicroVMs\u7528\u4e8e\u65e0\u670d\u52a1\u5668\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5c55\u793aLimes\u8fd0\u884c\u65f6\u5e76\u8bc4\u4f30\uff0c\u5f97\u51fa\u4e0d\u540c\u6280\u672f\u5728\u51b7\u542f\u52a8\u548c\u6267\u884c\u6027\u80fd\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u8fb9\u7f18\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u9700\u8981\u8f7b\u91cf\u7ea7\u6267\u884c\u73af\u5883\u4ee5\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\uff0c\u5c24\u5176\u662f\u5728\u7d27\u6025\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eWasmtime\u6784\u5efa\u7684WebAssembly\u8fd0\u884c\u65f6Limes\uff0c\u5e76\u4e0e\u57fa\u4e8eFirecracker\u7684SPARE\u73af\u5883\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "WebAssembly\u5bf9\u8f7b\u91cf\u7ea7\u51fd\u6570\u51b7\u542f\u52a8\u65f6\u95f4\u77ed\uff0c\u4f46\u5904\u7406\u590d\u6742\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u4f73\uff1bFirecracker\u51b7\u542f\u52a8\u65f6\u95f4\u957f\u4f46\u7a33\u5b9a\uff0c\u4e14\u5728I/O\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u6267\u884c\u6027\u80fd\u66f4\u597d\u3002", "conclusion": "\u4e0d\u540c\u7684\u65e0\u670d\u52a1\u5668\u6267\u884c\u73af\u5883\u5728\u51b7\u542f\u52a8\u548c\u6267\u884c\u6027\u80fd\u65b9\u9762\u5404\u6709\u4f18\u52a3\uff0c\u5e94\u6839\u636e\u5177\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u9009\u62e9\u3002"}}
{"id": "2509.08863", "pdf": "https://arxiv.org/pdf/2509.08863", "abs": "https://arxiv.org/abs/2509.08863", "authors": ["Qianqian Luo", "Liuchang Xu", "Qingming Lin", "Sensen Wu", "Ruichen Mao", "Chao Wang", "Hailin Feng", "Bo Huang", "Zhenhong Du"], "title": "GeoJSON Agents:A Multi-Agent LLM Architecture for Geospatial Analysis-Function Calling vs Code Generation", "categories": ["cs.SE"], "comment": null, "summary": "LLMs have made substantial progress in task automation and natural language\nunderstanding.However,without expertise in GIS,they continue to encounter\nlimitations.To address these issues, we propose GeoJSON Agents-a multi-agent\nLLM architecture.This framework transforms natural language tasks into\nstructured GeoJSON operation commands and processes spatial data using two\nwidely adopted LLM enhancement techniques:Function Calling and Code\nGeneration.The architecture consists of three components-task parsing,agent\ncollaboration,and result integration-aimed at enhancing both the performance\nand scalability of GIS automation.The Planner agent interprets natural language\ntasks into structured GeoJSON commands.Then,specialized Worker agents\ncollaborate according to assigned roles to perform spatial data processing and\nanalysis,either by invoking predefined function APIs or by dynamically\ngenerating and executing Python-based spatial analysis code.Finally,the system\nintegrates the outputs from multiple execution rounds into\nreusable,standards-compliant GeoJSON files.To systematically evaluate the\nperformance of the two approaches,we constructed a benchmark dataset of 70\ntasks with varying complexity and conducted experiments using OpenAI's GPT-4o\nas the core model.Results indicate that the Function Calling-based GeoJSON\nAgent achieved an accuracy of 85.71%,while the Code Generation-based agent\nreached 97.14%,both significantly outperforming the best-performing\ngeneral-purpose model (48.57%).Further analysis reveals that the Code\nGeneration provides greater flexibility,whereas the Function Calling approach\noffers more stable execution.This study is the first to introduce an LLM\nmulti-agent framework for GeoJSON data and to compare the strengths and\nlimitations of two mainstream LLM enhancement methods,offering new perspectives\nfor improving GeoAI system performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGeoJSON Agents\u591a\u667a\u80fd\u4f53LLM\u67b6\u6784\u5904\u7406GIS\u81ea\u52a8\u5316\u4efb\u52a1\uff0c\u5bf9\u6bd4\u4e24\u79cd\u589e\u5f3a\u6280\u672f\uff0c\u4ee3\u7801\u751f\u6210\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f3a\u4e4fGIS\u4e13\u4e1a\u77e5\u8bc6\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u63d0\u5347GIS\u81ea\u52a8\u5316\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faGeoJSON Agents\u67b6\u6784\uff0c\u542b\u4efb\u52a1\u89e3\u6790\u3001\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u7ed3\u679c\u96c6\u6210\u4e09\u90e8\u5206\uff0c\u7528Function Calling\u548cCode Generation\u6280\u672f\u5904\u7406\u7a7a\u95f4\u6570\u636e\uff0c\u6784\u5efa70\u4e2a\u4efb\u52a1\u7684\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u3002", "result": "\u57fa\u4e8eFunction Calling\u7684GeoJSON\u667a\u80fd\u4f53\u51c6\u786e\u738785.71%\uff0c\u57fa\u4e8eCode Generation\u7684\u4e3a97.14%\uff0c\u5747\u8fdc\u8d85\u901a\u7528\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u5f15\u5165\u57fa\u4e8eGeoJSON\u6570\u636e\u7684LLM\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5bf9\u6bd4\u4e24\u79cd\u65b9\u6cd5\u4f18\u7f3a\u70b9\uff0c\u4e3a\u63d0\u5347GeoAI\u7cfb\u7edf\u6027\u80fd\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2509.08933", "pdf": "https://arxiv.org/pdf/2509.08933", "abs": "https://arxiv.org/abs/2509.08933", "authors": ["Sreejeet Maity", "Aritra Mitra"], "title": "Corruption-Tolerant Asynchronous Q-Learning with Near-Optimal Rates", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC"], "comment": null, "summary": "We consider the problem of learning the optimal policy in a discounted,\ninfinite-horizon reinforcement learning (RL) setting where the reward signal is\nsubject to adversarial corruption. Such corruption, which may arise from\nextreme noise, sensor faults, or malicious attacks, can severely degrade the\nperformance of classical algorithms such as Q-learning. To address this\nchallenge, we propose a new provably robust variant of the Q-learning algorithm\nthat operates effectively even when a fraction of the observed rewards are\narbitrarily perturbed by an adversary. Under the asynchronous sampling model\nwith time-correlated data, we establish that despite adversarial corruption,\nthe finite-time convergence rate of our algorithm matches that of existing\nresults for the non-adversarial case, up to an additive term proportional to\nthe fraction of corrupted samples. Moreover, we derive an information-theoretic\nlower bound revealing that the additive corruption term in our upper bounds is\nunavoidable.\n  Next, we propose a variant of our algorithm that requires no prior knowledge\nof the statistics of the true reward distributions. The analysis of this\nsetting is particularly challenging and is enabled by carefully exploiting a\nrefined Azuma-Hoeffding inequality for almost-martingales, a technical tool\nthat might be of independent interest. Collectively, our contributions provide\nthe first finite-time robustness guarantees for asynchronous Q-learning,\nbridging a significant gap in robust RL.", "AI": {"tldr": "\u63d0\u51fa\u6297\u5bf9\u6297\u6027\u5e72\u6270\u7684Q\u5b66\u4e60\u7b97\u6cd5\u53d8\u4f53\uff0c\u5206\u6790\u6709\u9650\u65f6\u95f4\u6536\u655b\u7387\u5e76\u7ed9\u51fa\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u8fd8\u63d0\u51fa\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u7684\u7b97\u6cd5\u53d8\u4f53\uff0c\u4e3a\u5f02\u6b65Q\u5b66\u4e60\u63d0\u4f9b\u9996\u4e2a\u6709\u9650\u65f6\u95f4\u9c81\u68d2\u6027\u4fdd\u8bc1\u3002", "motivation": "\u5956\u52b1\u4fe1\u53f7\u53d7\u5bf9\u6297\u6027\u5e72\u6270\u4f1a\u4e25\u91cd\u964d\u4f4e\u7ecf\u5178Q\u5b66\u4e60\u7b97\u6cd5\u6027\u80fd\uff0c\u9700\u89e3\u51b3\u8be5\u6311\u6218\u3002", "method": "\u63d0\u51fa\u65b0\u7684Q\u5b66\u4e60\u7b97\u6cd5\u53d8\u4f53\uff0c\u5728\u5f02\u6b65\u91c7\u6837\u6a21\u578b\u4e0b\u5206\u6790\u5176\u6536\u655b\u7387\uff0c\u63a8\u5bfc\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u5229\u7528\u6539\u8fdb\u7684Azuma - Hoeffding\u4e0d\u7b49\u5f0f\u5206\u6790\u65e0\u5148\u9a8c\u77e5\u8bc6\u7684\u7b97\u6cd5\u53d8\u4f53\u3002", "result": "\u7b97\u6cd5\u5728\u5bf9\u6297\u6027\u5e72\u6270\u4e0b\u6709\u9650\u65f6\u95f4\u6536\u655b\u7387\u4e0e\u975e\u5bf9\u6297\u60c5\u51b5\u5339\u914d\uff08\u6709\u4e0e\u53d7\u635f\u6837\u672c\u6bd4\u4f8b\u6210\u6b63\u6bd4\u7684\u9644\u52a0\u9879\uff09\uff0c\u8bc1\u660e\u9644\u52a0\u9879\u4e0d\u53ef\u907f\u514d\u3002", "conclusion": "\u4e3a\u5f02\u6b65Q\u5b66\u4e60\u63d0\u4f9b\u4e86\u9996\u4e2a\u6709\u9650\u65f6\u95f4\u9c81\u68d2\u6027\u4fdd\u8bc1\uff0c\u586b\u8865\u4e86\u9c81\u68d2\u5f3a\u5316\u5b66\u4e60\u7684\u91cd\u8981\u7a7a\u767d\u3002"}}
{"id": "2509.09353", "pdf": "https://arxiv.org/pdf/2509.09353", "abs": "https://arxiv.org/abs/2509.09353", "authors": ["Alexandra Carpentier", "Simone Maria Giancola", "Christophe Giraud", "Nicolas Verzelen"], "title": "Low-degree lower bounds via almost orthonormal bases", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Low-degree polynomials have emerged as a powerful paradigm for providing\nevidence of statistical-computational gaps across a variety of high-dimensional\nstatistical models [Wein25]. For detection problems -- where the goal is to\ntest a planted distribution $\\mathbb{P}'$ against a null distribution\n$\\mathbb{P}$ with independent components -- the standard approach is to bound\nthe advantage using an $\\mathbb{L}^2(\\mathbb{P})$-orthonormal family of\npolynomials. However, this method breaks down for estimation tasks or more\ncomplex testing problems where $\\mathbb{P}$ has some planted structures, so\nthat no simple $\\mathbb{L}^2(\\mathbb{P})$-orthogonal polynomial family is\navailable. To address this challenge, several technical workarounds have been\nproposed [SW22,SW25], though their implementation can be delicate. In this\nwork, we propose a more direct proof strategy. Focusing on random graph models,\nwe construct a basis of polynomials that is almost orthonormal under\n$\\mathbb{P}$, in precisely those regimes where statistical-computational gaps\narise. This almost orthonormal basis not only yields a direct route to\nestablishing low-degree lower bounds, but also allows us to explicitly identify\nthe polynomials that optimize the low-degree criterion. This, in turn, provides\ninsights into the design of optimal polynomial-time algorithms. We illustrate\nthe effectiveness of our approach by recovering known low-degree lower bounds,\nand establishing new ones for problems such as hidden subcliques, stochastic\nblock models, and seriation models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.09552", "pdf": "https://arxiv.org/pdf/2509.09552", "abs": "https://arxiv.org/abs/2509.09552", "authors": ["Baoqi Zhao", "Xiong Yang", "Hoileong Lee", "Bowen Dong"], "title": "An improved educational competition optimizer with multi-covariance learning operators for global optimization problems", "categories": ["cs.NE", "cs.AI", "cs.CE"], "comment": "Submitted to Cluster Computing", "summary": "The educational competition optimizer is a recently introduced metaheuristic\nalgorithm inspired by human behavior, originating from the dynamics of\neducational competition within society. Nonetheless, ECO faces constraints due\nto an imbalance between exploitation and exploration, rendering it susceptible\nto local optima and demonstrating restricted effectiveness in addressing\ncomplex optimization problems. To address these limitations, this study\npresents an enhanced educational competition optimizer (IECO-MCO) utilizing\nmulti-covariance learning operators. In IECO, three distinct covariance\nlearning operators are introduced to improve the performance of ECO. Each\noperator effectively balances exploitation and exploration while preventing\npremature convergence of the population. The effectiveness of IECO is assessed\nthrough benchmark functions derived from the CEC 2017 and CEC 2022 test suites,\nand its performance is compared with various basic and improved algorithms\nacross different categories. The results demonstrate that IECO-MCO surpasses\nthe basic ECO and other competing algorithms in convergence speed, stability,\nand the capability to avoid local optima. Furthermore, statistical analyses,\nincluding the Friedman test, Kruskal-Wallis test, and Wilcoxon rank-sum test,\nare conducted to validate the superiority of IECO-MCO over the compared\nalgorithms. Compared with the basic algorithm (improved algorithm), IECO-MCO\nachieved an average ranking of 2.213 (2.488) on the CE2017 and CEC2022 test\nsuites. Additionally, the practical applicability of the proposed IECO-MCO\nalgorithm is verified by solving constrained optimization problems. The\nexperimental outcomes demonstrate the superior performance of IECO-MCO in\ntackling intricate optimization problems, underscoring its robustness and\npractical effectiveness in real-world scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u591a\u534f\u65b9\u5dee\u5b66\u4e60\u7b97\u5b50\u7684\u589e\u5f3a\u578b\u6559\u80b2\u7ade\u4e89\u4f18\u5316\u5668\uff08IECO - MCO\uff09\uff0c\u901a\u8fc7\u57fa\u51c6\u51fd\u6570\u6d4b\u8bd5\u548c\u7edf\u8ba1\u5206\u6790\u9a8c\u8bc1\u5176\u5728\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\u4e0a\u4f18\u4e8e\u57fa\u672cECO\u548c\u5176\u4ed6\u7b97\u6cd5\uff0c\u8fd8\u9a8c\u8bc1\u4e86\u5176\u5728\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u57fa\u672c\u6559\u80b2\u7ade\u4e89\u4f18\u5316\u5668\uff08ECO\uff09\u5b58\u5728\u5f00\u53d1\u4e0e\u63a2\u7d22\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u5728\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\u65f6\u6548\u679c\u6709\u9650\u3002", "method": "\u5f15\u5165\u4e09\u79cd\u4e0d\u540c\u7684\u534f\u65b9\u5dee\u5b66\u4e60\u7b97\u5b50\u6539\u8fdbECO\uff0c\u5229\u7528CEC 2017\u548cCEC 2022\u6d4b\u8bd5\u5957\u4ef6\u7684\u57fa\u51c6\u51fd\u6570\u8bc4\u4f30\u6027\u80fd\uff0c\u5e76\u4e0e\u591a\u79cd\u7b97\u6cd5\u5bf9\u6bd4\uff0c\u8fdb\u884cFriedman\u3001Kruskal - Wallis\u548cWilcoxon\u79e9\u548c\u68c0\u9a8c\u7b49\u7edf\u8ba1\u5206\u6790\uff0c\u8fd8\u6c42\u89e3\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u9a8c\u8bc1\u5b9e\u7528\u6027\u3002", "result": "IECO - MCO\u5728\u6536\u655b\u901f\u5ea6\u3001\u7a33\u5b9a\u6027\u548c\u907f\u514d\u5c40\u90e8\u6700\u4f18\u80fd\u529b\u4e0a\u8d85\u8d8a\u57fa\u672cECO\u548c\u5176\u4ed6\u7ade\u4e89\u7b97\u6cd5\uff0c\u5728CEC2017\u548cCEC2022\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u5e73\u5747\u6392\u540d\u5206\u522b\u4e3a2.213\uff08\u6539\u8fdb\u7b97\u6cd5\u4e3a2.488\uff09\u3002", "conclusion": "IECO - MCO\u5728\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5177\u6709\u9c81\u68d2\u6027\u548c\u5b9e\u9645\u6709\u6548\u6027\u3002"}}
{"id": "2509.09598", "pdf": "https://arxiv.org/pdf/2509.09598", "abs": "https://arxiv.org/abs/2509.09598", "authors": ["C\u00e9sar Barilla", "Palaash Bhargava"], "title": "Ancestral origins of attention to environmental issues", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "How does the climatic experience of previous generations affect today's\nattention to environmental questions? Using self-reported beliefs and\nenvironmental themes in folklore, we show empirically that the realized\nintensity of deviations from typical climate conditions in ancestral\ngenerations influences how much descendants care about the environment. The\neffect exhibits a U-shape where more stable and more unstable ancestral\nclimates lead to higher attention today, with a dip for intermediate\nrealizations. We propose a theoretical framework where the value of costly\nattention to environmental conditions depends on the perceived stability of the\nenvironment, prior beliefs about which are shaped through cultural transmission\nby the experience of ethnic ancestors. The U-shape is rationalized by a double\npurpose of learning about the environment: optimal utilization of typical\nconditions and protection against extreme events.", "AI": {"tldr": "\u7814\u7a76\u524d\u4ee3\u6c14\u5019\u7ecf\u5386\u5bf9\u5f53\u4ee3\u73af\u5883\u5173\u6ce8\u5ea6\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5448U\u578b\u5173\u7cfb\u5e76\u7ed9\u51fa\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u63a2\u7a76\u524d\u4ee3\u6c14\u5019\u7ecf\u5386\u5982\u4f55\u5f71\u54cd\u5f53\u4ee3\u5bf9\u73af\u5883\u95ee\u9898\u7684\u5173\u6ce8\u3002", "method": "\u5229\u7528\u81ea\u6211\u62a5\u544a\u7684\u4fe1\u5ff5\u548c\u6c11\u95f4\u4f20\u8bf4\u4e2d\u7684\u73af\u5883\u4e3b\u9898\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u3002", "result": "\u524d\u4ee3\u6c14\u5019\u504f\u79bb\u5178\u578b\u6761\u4ef6\u7684\u5f3a\u5ea6\u5f71\u54cd\u540e\u4ee3\u5bf9\u73af\u5883\u7684\u5173\u6ce8\u5ea6\uff0c\u5448U\u578b\u5173\u7cfb\u3002", "conclusion": "\u5bf9\u73af\u5883\u6761\u4ef6\u7684\u5173\u6ce8\u4ef7\u503c\u53d6\u51b3\u4e8e\u73af\u5883\u7684\u611f\u77e5\u7a33\u5b9a\u6027\uff0cU\u578b\u5173\u7cfb\u53ef\u7531\u5b66\u4e60\u73af\u5883\u7684\u53cc\u91cd\u76ee\u7684\u89e3\u91ca\u3002"}}
{"id": "2509.09641", "pdf": "https://arxiv.org/pdf/2509.09641", "abs": "https://arxiv.org/abs/2509.09641", "authors": ["Jiaxuan Ma", "Yong Chen", "Guangting Chen", "Mingyang Gong", "Guohui Lin", "An Zhang"], "title": "Maximizing social welfare among EF1 allocations at the presence of two types of agents", "categories": ["cs.GT", "cs.DS"], "comment": "A shorter version appears in ISAAC 2025; 20 pages in this full\n  version", "summary": "We study the fair allocation of indivisible items to $n$ agents to maximize\nthe utilitarian social welfare, where the fairness criterion is envy-free up to\none item and there are only two different utility functions shared by the\nagents. We present a $2$-approximation algorithm when the two utility functions\nare normalized, improving the previous best ratio of $16 \\sqrt{n}$ shown for\ngeneral normalized utility functions; thus this constant ratio approximation\nalgorithm confirms the APX-completeness in this special case previously shown\nAPX-hard. When there are only three agents, i.e., $n = 3$, the previous best\nratio is $3$ shown for general utility functions, and we present an improved\nand tight $\\frac 53$-approximation algorithm when the two utility functions are\nnormalized, and a best possible and tight $2$-approximation algorithm when the\ntwo utility functions are unnormalized.", "AI": {"tldr": "\u7814\u7a76\u4e24\u79cd\u6548\u7528\u51fd\u6570\u4e0b\u4e0d\u53ef\u5206\u7269\u54c1\u516c\u5e73\u5206\u914d\u4ee5\u6700\u5927\u5316\u529f\u5229\u4e3b\u4e49\u793e\u4f1a\u798f\u5229\uff0c\u7ed9\u51fa\u4e0d\u540c\u60c5\u51b5\u4e0b\u8fd1\u4f3c\u7b97\u6cd5\u5e76\u6539\u8fdb\u524d\u4eba\u7ed3\u679c\u3002", "motivation": "\u5728\u516c\u5e73\u6807\u51c6\u4e3a\u81f3\u591a\u5fcc\u5992\u4e00\u4ef6\u7269\u54c1\u4e14\u53ea\u6709\u4e24\u79cd\u6548\u7528\u51fd\u6570\u65f6\uff0c\u63d0\u9ad8\u4e0d\u53ef\u5206\u7269\u54c1\u5206\u914d\u6700\u5927\u5316\u529f\u5229\u4e3b\u4e49\u793e\u4f1a\u798f\u5229\u7684\u8fd1\u4f3c\u6bd4\u3002", "method": "\u8bbe\u8ba1\u4e0d\u540c\u60c5\u51b5\u4e0b\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5982\u4e24\u79cd\u6548\u7528\u51fd\u6570\u5f52\u4e00\u5316\u65f6\u76842 - \u8fd1\u4f3c\u7b97\u6cd5\u3001n = 3\u65f6\u4e0d\u540c\u60c5\u51b5\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u5728\u4e24\u79cd\u6548\u7528\u51fd\u6570\u5f52\u4e00\u5316\u65f6\u5c06\u8fd1\u4f3c\u6bd4\u4ece16\u221an \u63d0\u9ad8\u52302\uff1bn = 3\u65f6\uff0c\u5f52\u4e00\u5316\u65f6\u5f97\u52305/3 - \u8fd1\u4f3c\u7b97\u6cd5\uff0c\u672a\u5f52\u4e00\u5316\u65f6\u5f97\u52302 - \u8fd1\u4f3c\u7b97\u6cd5\u3002", "conclusion": "\u5728\u8be5\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u5e38\u6570\u6bd4\u8fd1\u4f3c\u7b97\u6cd5\u8bc1\u5b9e\u4e86\u4e4b\u524d\u88ab\u8bc1\u660e\u4e3aAPX - \u96be\u95ee\u9898\u7684APX - \u5b8c\u5907\u6027\uff0c\u4e14\u7ed9\u51fa\u4e86n = 3\u65f6\u4e0d\u540c\u60c5\u51b5\u7684\u6700\u4f18\u8fd1\u4f3c\u7b97\u6cd5\u3002"}}
{"id": "2509.09342", "pdf": "https://arxiv.org/pdf/2509.09342", "abs": "https://arxiv.org/abs/2509.09342", "authors": ["Yifan Wang", "Shen Gao", "Jiabao Fang", "Rui Yan", "Billy Chiu", "Shuo Shang"], "title": "CESRec: Constructing Pseudo Interactions for Sequential Recommendation via Conversational Feedback", "categories": ["cs.IR"], "comment": null, "summary": "Sequential Recommendation Systems (SRS) have become essential in many\nreal-world applications. However, existing SRS methods often rely on\ncollaborative filtering signals and fail to capture real-time user preferences,\nwhile Conversational Recommendation Systems (CRS) excel at eliciting immediate\ninterests through natural language interactions but neglect historical\nbehavior. To bridge this gap, we propose CESRec, a novel framework that\nintegrates the long-term preference modeling of SRS with the real-time\npreference elicitation of CRS. We introduce semantic-based pseudo interaction\nconstruction, which dynamically updates users'historical interaction sequences\nby analyzing conversational feedback, generating a pseudo-interaction sequence\nthat seamlessly combines long-term and real-time preferences. Additionally, we\nreduce the impact of outliers in historical items that deviate from users'core\npreferences by proposing dual alignment outlier items masking, which identifies\nand masks such items using semantic-collaborative aligned representations.\nExtensive experiments demonstrate that CESRec achieves state-of-the-art\nperformance by boosting strong SRS models, validating its effectiveness in\nintegrating conversational feedback into SRS.", "AI": {"tldr": "\u63d0\u51faCESRec\u6846\u67b6\u7ed3\u5408SRS\u4e0eCRS\u4f18\u52bf\uff0c\u901a\u8fc7\u8bed\u4e49\u4f2a\u4ea4\u4e92\u6784\u5efa\u548c\u53cc\u5bf9\u9f50\u79bb\u7fa4\u9879\u63a9\u7801\u6280\u672f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u63d0\u5347SRS\u6027\u80fd\u3002", "motivation": "\u73b0\u6709SRS\u65b9\u6cd5\u96be\u6355\u6349\u5b9e\u65f6\u504f\u597d\uff0cCRS\u5ffd\u7565\u5386\u53f2\u884c\u4e3a\uff0c\u9700\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "\u63d0\u51faCESRec\u6846\u67b6\uff0c\u5f15\u5165\u8bed\u4e49\u4f2a\u4ea4\u4e92\u6784\u5efa\u66f4\u65b0\u5386\u53f2\u4ea4\u4e92\u5e8f\u5217\uff0c\u63d0\u51fa\u53cc\u5bf9\u9f50\u79bb\u7fa4\u9879\u63a9\u7801\u51cf\u5c11\u79bb\u7fa4\u9879\u5f71\u54cd\u3002", "result": "CESRec\u901a\u8fc7\u63d0\u5347\u5f3aSRS\u6a21\u578b\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "CESRec\u5728\u5c06\u5bf9\u8bdd\u53cd\u9988\u96c6\u6210\u5230SRS\u4e2d\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2509.08972", "pdf": "https://arxiv.org/pdf/2509.08972", "abs": "https://arxiv.org/abs/2509.08972", "authors": ["Soheil Zibakhsh Shabgahi", "Pedram Aghazadeh", "Azalia Mirhosseini", "Farinaz Koushanfar"], "title": "ForTIFAI: Fending Off Recursive Training Induced Failure for AI Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The increasing reliance on generative AI models has accelerated the\ngeneration rate of synthetic data, with some projections suggesting that most\navailable new data for training could be machine-generated by 2030. This shift\nto a mainly synthetic content presents a critical challenge: repeated training\nin synthetic data leads to a phenomenon known as model collapse, where model\nperformance degrades over generations of training, eventually rendering the\nmodels ineffective. Although prior studies have explored the causes and\ndetection of model collapse, existing mitigation strategies remain limited.\n  In this paper, we identify model overconfidence in their self-generated data\nas a key driver of collapse. Building on this observation, we propose a\nconfidence-aware loss function that downweights high-confidence predictions\nduring training. We introduce a novel loss function we call Truncated Cross\nEntropy (TCE). We demonstrate that TCE significantly delays model collapse in\nrecursive training.\n  We provide a model-agnostic framework that links the loss function design to\nmodel collapse mitigation and validate our approach both theoretically and\nempirically, showing that it can extend the model's fidelity interval before\ncollapse by more than 2.3x. Finally, we show that our method generalizes across\nmodalities. These findings suggest that the design of loss functions provides a\nsimple yet powerful tool for preserving the quality of generative models in the\nera of increasing synthetic data.", "AI": {"tldr": "\u7531\u4e8e\u751f\u6210\u5f0f AI \u6a21\u578b\u5bf9\u5408\u6210\u6570\u636e\u4f9d\u8d56\u589e\u52a0\uff0c\u4f1a\u5bfc\u81f4\u6a21\u578b\u5d29\u6e83\u3002\u672c\u6587\u8bc6\u522b\u51fa\u6a21\u578b\u5bf9\u81ea\u751f\u6210\u6570\u636e\u8fc7\u5ea6\u81ea\u4fe1\u662f\u5d29\u6e83\u4e3b\u56e0\uff0c\u63d0\u51fa TCE \u635f\u5931\u51fd\u6570\uff0c\u7406\u8bba\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u53ef\u7f13\u89e3\u5d29\u6e83\uff0c\u8fd8\u80fd\u8de8\u6a21\u6001\u6cdb\u5316\u3002", "motivation": "\u751f\u6210\u5f0f AI \u6a21\u578b\u4f9d\u8d56\u5408\u6210\u6570\u636e\u4f1a\u5bfc\u81f4\u6a21\u578b\u5d29\u6e83\uff0c\u73b0\u6709\u7f13\u89e3\u7b56\u7565\u6709\u9650\u3002", "method": "\u8bc6\u522b\u6a21\u578b\u5bf9\u81ea\u751f\u6210\u6570\u636e\u8fc7\u5ea6\u81ea\u4fe1\u4e3a\u5d29\u6e83\u4e3b\u56e0\uff0c\u63d0\u51fa TCE \u635f\u5931\u51fd\u6570\uff0c\u6784\u5efa\u4e0e\u7f13\u89e3\u6a21\u578b\u5d29\u6e83\u76f8\u5173\u7684\u6a21\u578b\u65e0\u5173\u6846\u67b6\u3002", "result": "TCE \u663e\u8457\u5ef6\u8fdf\u9012\u5f52\u8bad\u7ec3\u4e2d\u7684\u6a21\u578b\u5d29\u6e83\uff0c\u80fd\u5c06\u5d29\u6e83\u524d\u6a21\u578b\u4fdd\u771f\u533a\u95f4\u5ef6\u957f\u8d85 2.3 \u500d\uff0c\u65b9\u6cd5\u53ef\u8de8\u6a21\u6001\u6cdb\u5316\u3002", "conclusion": "\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u662f\u5408\u6210\u6570\u636e\u65f6\u4ee3\u4fdd\u6301\u751f\u6210\u5f0f\u6a21\u578b\u8d28\u91cf\u7684\u7b80\u5355\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2509.08865", "pdf": "https://arxiv.org/pdf/2509.08865", "abs": "https://arxiv.org/abs/2509.08865", "authors": ["Guangyu Zhang", "Xixuan Wang", "Shiyu Sun", "Peiyan Xiao", "Kun Sun", "Yanhai Xiong"], "title": "TraceRAG: A LLM-Based Framework for Explainable Android Malware Detection and Behavior Analysis", "categories": ["cs.SE"], "comment": null, "summary": "Sophisticated evasion tactics in malicious Android applications, combined\nwith their intricate behavioral semantics, enable attackers to conceal\nmalicious logic within legitimate functions, underscoring the critical need for\nrobust and in-depth analysis frameworks. However, traditional analysis\ntechniques often fail to recover deeply hidden behaviors or provide\nhuman-readable justifications for their decisions. Inspired by advances in\nlarge language models (LLMs), we introduce TraceRAG, a retrieval-augmented\ngeneration (RAG) framework that bridges natural language queries and Java code\nto deliver explainable malware detection and analysis. First, TraceRAG\ngenerates summaries of method-level code snippets, which are indexed in a\nvector database. At query time, behavior-focused questions retrieve the most\nsemantically relevant snippets for deeper inspection. Finally, based on the\nmulti-turn analysis results, TraceRAG produces human-readable reports that\npresent the identified malicious behaviors and their corresponding code\nimplementations. Experimental results demonstrate that our method achieves 96\\%\nmalware detection accuracy and 83.81\\% behavior identification accuracy based\non updated VirusTotal (VT) scans and manual verification. Furthermore, expert\nevaluation confirms the practical utility of the reports generated by TraceRAG.", "AI": {"tldr": "\u63d0\u51faTraceRAG\u6846\u67b6\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5206\u6790\uff0c\u5b9e\u9a8c\u6548\u679c\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u5206\u6790\u6280\u672f\u96be\u4ee5\u53d1\u73b0\u9690\u85cf\u884c\u4e3a\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u5f3a\u5927\u6df1\u5165\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5f15\u5165TraceRAG\u6846\u67b6\uff0c\u751f\u6210\u65b9\u6cd5\u7ea7\u4ee3\u7801\u7247\u6bb5\u6458\u8981\u5e76\u7d22\u5f15\uff0c\u901a\u8fc7\u67e5\u8be2\u68c0\u7d22\u76f8\u5173\u7247\u6bb5\uff0c\u57fa\u4e8e\u591a\u8f6e\u5206\u6790\u7ed3\u679c\u751f\u6210\u53ef\u8bfb\u62a5\u544a\u3002", "result": "\u5b9e\u73b096%\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u51c6\u786e\u7387\u548c83.81%\u7684\u884c\u4e3a\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u4e13\u5bb6\u8ba4\u53ef\u62a5\u544a\u5b9e\u7528\u6027\u3002", "conclusion": "TraceRAG\u6846\u67b6\u80fd\u6709\u6548\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u5b89\u5353\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4e0e\u5206\u6790\u3002"}}
{"id": "2509.08942", "pdf": "https://arxiv.org/pdf/2509.08942", "abs": "https://arxiv.org/abs/2509.08942", "authors": ["Xenia Konti", "Yi Shen", "Zifan Wang", "Karl Henrik Johansson", "Michael J. Pencina", "Nicoleta J. Economou-Zavlanos", "Michael M. Zavlanos"], "title": "Group Distributionally Robust Machine Learning under Group Level Distributional Uncertainty", "categories": ["cs.LG"], "comment": null, "summary": "The performance of machine learning (ML) models critically depends on the\nquality and representativeness of the training data. In applications with\nmultiple heterogeneous data generating sources, standard ML methods often learn\nspurious correlations that perform well on average but degrade performance for\natypical or underrepresented groups. Prior work addresses this issue by\noptimizing the worst-group performance. However, these approaches typically\nassume that the underlying data distributions for each group can be accurately\nestimated using the training data, a condition that is frequently violated in\nnoisy, non-stationary, and evolving environments. In this work, we propose a\nnovel framework that relies on Wasserstein-based distributionally robust\noptimization (DRO) to account for the distributional uncertainty within each\ngroup, while simultaneously preserving the objective of improving the\nworst-group performance. We develop a gradient descent-ascent algorithm to\nsolve the proposed DRO problem and provide convergence results. Finally, we\nvalidate the effectiveness of our method on real-world data.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eWasserstein\u7684\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u591a\u6e90\u5f02\u8d28\u6570\u636e\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u95ee\u9898\u5e76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u6807\u51c6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u6e90\u5f02\u8d28\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u865a\u5047\u5173\u8054\uff0c\u5f71\u54cd\u975e\u5178\u578b\u6216\u4ee3\u8868\u6027\u4e0d\u8db3\u7fa4\u4f53\u6027\u80fd\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u6570\u636e\u5206\u5e03\u53ef\u51c6\u786e\u4f30\u8ba1\uff0c\u5728\u590d\u6742\u73af\u5883\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eWasserstein\u7684\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u5f00\u53d1\u68af\u5ea6\u4e0b\u964d - \u4e0a\u5347\u7b97\u6cd5\u6c42\u89e3DRO\u95ee\u9898\u3002", "result": "\u5f97\u5230\u7b97\u6cd5\u6536\u655b\u7ed3\u679c\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u89e3\u51b3\u591a\u6e90\u5f02\u8d28\u6570\u636e\u4e2d\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u6700\u5dee\u7fa4\u4f53\u6027\u80fd\u3002"}}
{"id": "2509.09071", "pdf": "https://arxiv.org/pdf/2509.09071", "abs": "https://arxiv.org/abs/2509.09071", "authors": ["Crystal Qian", "Kehang Zhu", "John Horton", "Benjamin S. Manning", "Vivian Tsai", "James Wexler", "Nithum Thain"], "title": "Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games", "categories": ["cs.AI", "cs.GT", "cs.HC"], "comment": null, "summary": "Coordination tasks traditionally performed by humans are increasingly being\ndelegated to autonomous agents. As this pattern progresses, it becomes critical\nto evaluate not only these agents' performance but also the processes through\nwhich they negotiate in dynamic, multi-agent environments. Furthermore,\ndifferent agents exhibit distinct advantages: traditional statistical agents,\nsuch as Bayesian models, may excel under well-specified conditions, whereas\nlarge language models (LLMs) can generalize across contexts. In this work, we\ncompare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in\na dynamic negotiation setting that enables direct, identical-condition\ncomparisons across populations, capturing both outcomes and behavioral\ndynamics. Bayesian agents extract the highest surplus through aggressive\noptimization, at the cost of frequent trade rejections. Humans and LLMs can\nachieve similar overall surplus, but through distinct behaviors: LLMs favor\nconservative, concessionary trades with few rejections, while humans employ\nmore strategic, risk-taking, and fairness-oriented behaviors. Thus, we find\nthat performance parity -- a common benchmark in agent evaluation -- can\nconceal fundamental differences in process and alignment, which are critical\nfor practical deployment in real-world coordination tasks.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4eba\u7c7b\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8d1d\u53f6\u65af\u4ee3\u7406\u5728\u52a8\u6001\u8c08\u5224\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6027\u80fd\u76f8\u5f53\u53ef\u80fd\u63a9\u76d6\u8fc7\u7a0b\u548c\u4e00\u81f4\u6027\u7684\u6839\u672c\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u534f\u8c03\u4efb\u52a1\u5411\u81ea\u4e3b\u4ee3\u7406\u8f6c\u79fb\uff0c\u9700\u8bc4\u4f30\u4ee3\u7406\u5728\u52a8\u6001\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7684\u8c08\u5224\u8fc7\u7a0b\uff0c\u4e14\u4e0d\u540c\u4ee3\u7406\u6709\u4e0d\u540c\u4f18\u52bf\u3002", "method": "\u5728\u52a8\u6001\u8c08\u5224\u573a\u666f\u4e2d\u5bf9\u4eba\u7c7b\u3001\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT - 4o\u3001Gemini 1.5 Pro\uff09\u548c\u8d1d\u53f6\u65af\u4ee3\u7406\u8fdb\u884c\u76f8\u540c\u6761\u4ef6\u4e0b\u7684\u76f4\u63a5\u6bd4\u8f83\uff0c\u6355\u6349\u7ed3\u679c\u548c\u884c\u4e3a\u52a8\u6001\u3002", "result": "\u8d1d\u53f6\u65af\u4ee3\u7406\u901a\u8fc7\u6fc0\u8fdb\u4f18\u5316\u83b7\u53d6\u6700\u9ad8\u76c8\u4f59\u4f46\u5e38\u906d\u4ea4\u6613\u62d2\u7edd\uff1b\u4eba\u7c7b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u603b\u4f53\u76c8\u4f59\u76f8\u4f3c\uff0c\u4f46\u884c\u4e3a\u4e0d\u540c\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u503e\u5411\u4fdd\u5b88\u3001\u8ba9\u6b65\u4ea4\u6613\uff0c\u4eba\u7c7b\u66f4\u5177\u6218\u7565\u6027\u3001\u5192\u9669\u6027\u548c\u516c\u5e73\u5bfc\u5411\u3002", "conclusion": "\u6027\u80fd\u76f8\u5f53\u8fd9\u4e00\u5e38\u89c1\u8bc4\u4f30\u57fa\u51c6\u53ef\u80fd\u63a9\u76d6\u8fc7\u7a0b\u548c\u4e00\u81f4\u6027\u7684\u6839\u672c\u5dee\u5f02\uff0c\u8fd9\u5bf9\u73b0\u5b9e\u534f\u8c03\u4efb\u52a1\u7684\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.09435", "pdf": "https://arxiv.org/pdf/2509.09435", "abs": "https://arxiv.org/abs/2509.09435", "authors": ["Houming Qiu", "Kun Zhu", "Dusit Niyato", "Nguyen Cong Luong", "Changyan Yi", "Chen Dai"], "title": "Barycentric Coded Distributed Computing with Flexible Recovery Threshold for Collaborative Mobile Edge Computing", "categories": ["cs.DC"], "comment": null, "summary": "Collaborative mobile edge computing (MEC) has emerged as a promising paradigm\nto enable low-capability edge nodes to cooperatively execute\ncomputation-intensive tasks. However, straggling edge nodes (stragglers)\nsignificantly degrade the performance of MEC systems by prolonging computation\nlatency. While coded distributed computing (CDC) as an effective technique is\nwidely adopted to mitigate straggler effects, existing CDC schemes exhibit two\ncritical limitations: (i) They cannot successfully decode the final result\nunless the number of received results reaches a fixed recovery threshold, which\nseriously restricts their flexibility; (ii) They suffer from inherent poles in\ntheir encoding/decoding functions, leading to decoding inaccuracies and\nnumerical instability in the computational results. To address these\nlimitations, this paper proposes an approximated CDC scheme based on\nbarycentric rational interpolation. The proposed CDC scheme offers several\noutstanding advantages. Firstly, it can decode the final result leveraging any\nreturned results from workers. Secondly, it supports computations over both\nfinite and real fields while ensuring numerical stability. Thirdly, its\nencoding/decoding functions are free of poles, which not only enhances\napproximation accuracy but also achieves flexible accuracy tuning. Fourthly, it\nintegrates a novel BRI-based gradient coding algorithm accelerating the\ntraining process while providing robustness against stragglers. Finally,\nexperimental results reveal that the proposed scheme is superior to existing\nCDC schemes in both waiting time and approximate accuracy.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709\u7f16\u7801\u5206\u5e03\u5f0f\u8ba1\u7b97\uff08CDC\uff09\u65b9\u6848\u5728\u534f\u540c\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u4e2d\u5e94\u5bf9\u6389\u961f\u8282\u70b9\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u91cd\u5fc3\u6709\u7406\u63d2\u503c\u7684\u8fd1\u4f3c CDC \u65b9\u6848\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6848\u5728\u7b49\u5f85\u65f6\u95f4\u548c\u8fd1\u4f3c\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u73b0\u6709 CDC \u65b9\u6848\u5728 MEC \u7cfb\u7edf\u4e2d\u5b58\u5728\u65e0\u6cd5\u7075\u6d3b\u89e3\u7801\u548c\u6570\u503c\u4e0d\u7a33\u5b9a\u7b49\u5c40\u9650\uff0c\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u91cd\u5fc3\u6709\u7406\u63d2\u503c\u7684\u8fd1\u4f3c CDC \u65b9\u6848\uff0c\u8be5\u65b9\u6848\u53ef\u5229\u7528\u4efb\u610f\u8fd4\u56de\u7ed3\u679c\u89e3\u7801\u3001\u652f\u6301\u591a\u5b57\u6bb5\u8ba1\u7b97\u3001\u7f16\u7801/\u89e3\u7801\u51fd\u6570\u65e0\u6781\u70b9\uff0c\u8fd8\u96c6\u6210\u4e86\u57fa\u4e8e BRI \u7684\u68af\u5ea6\u7f16\u7801\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6848\u5728\u7b49\u5f85\u65f6\u95f4\u548c\u8fd1\u4f3c\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709 CDC \u65b9\u6848\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8fd1\u4f3c CDC \u65b9\u6848\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709 CDC \u65b9\u6848\u7684\u5c40\u9650\u6027\uff0c\u63d0\u5347 MEC \u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2509.09414", "pdf": "https://arxiv.org/pdf/2509.09414", "abs": "https://arxiv.org/abs/2509.09414", "authors": ["Alan Said", "Maria Soledad Pera", "Michael D. Ekstrand"], "title": "We're Still Doing It (All) Wrong: Recommender Systems, Fifteen Years Later", "categories": ["cs.IR", "cs.AI"], "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive Version of Record was\n  accepted for publication in the Beyond Algorithms: Reclaiming the\n  Interdisciplinary Roots of Recommender Systems Workshop (BEYOND 2025),\n  September 26th, 2025, co-located with the 19th ACM Recommender Systems\n  Conference, Prague, Czech Republic", "summary": "In 2011, Xavier Amatriain sounded the alarm: recommender systems research was\n\"doing it all wrong\" [1]. His critique, rooted in statistical misinterpretation\nand methodological shortcuts, remains as relevant today as it was then. But\nrather than correcting course, we added new layers of sophistication on top of\nthe same broken foundations. This paper revisits Amatriain's diagnosis and\nargues that many of the conceptual, epistemological, and infrastructural\nfailures he identified still persist, in more subtle or systemic forms. Drawing\non recent work in reproducibility, evaluation methodology, environmental\nimpact, and participatory design, we showcase how the field's accelerating\ncomplexity has outpaced its introspection. We highlight ongoing community-led\ninitiatives that attempt to shift the paradigm, including workshops, evaluation\nframeworks, and calls for value-sensitive and participatory research. At the\nsame time, we contend that meaningful change will require not only new metrics\nor better tooling, but a fundamental reframing of what recommender systems\nresearch is for, who it serves, and how knowledge is produced and validated.\nOur call is not just for technical reform, but for a recommender systems\nresearch agenda grounded in epistemic humility, human impact, and sustainable\npractice.", "AI": {"tldr": "\u672c\u6587\u91cd\u63d0Amatriain\u5bf9\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u7684\u6279\u5224\uff0c\u6307\u51fa\u95ee\u9898\u4ecd\u5b58\u5728\uff0c\u5f3a\u8c03\u9700\u8981\u6839\u672c\u6027\u91cd\u6784\u7814\u7a76\u8bae\u7a0b\u3002", "motivation": "Amatriain\u66fe\u6279\u5224\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u5b58\u5728\u95ee\u9898\uff0c\u5982\u4eca\u95ee\u9898\u4ecd\u4ee5\u66f4\u9690\u853d\u6216\u7cfb\u7edf\u7684\u5f62\u5f0f\u5b58\u5728\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u3002", "method": "\u501f\u9274\u53ef\u91cd\u590d\u6027\u3001\u8bc4\u4f30\u65b9\u6cd5\u3001\u73af\u5883\u5f71\u54cd\u548c\u53c2\u4e0e\u5f0f\u8bbe\u8ba1\u7b49\u65b9\u9762\u7684\u7814\u7a76\uff0c\u5c55\u793a\u9886\u57df\u590d\u6742\u6027\u8d85\u8d8a\u81ea\u7701\u7684\u60c5\u51b5\uff0c\u4ecb\u7ecd\u793e\u533a\u4e3b\u5bfc\u7684\u53d8\u9769\u4e3e\u63aa\u3002", "result": "\u9886\u57df\u590d\u6742\u6027\u8d85\u8fc7\u4e86\u81ea\u7701\uff0c\u6709\u793e\u533a\u4e3b\u5bfc\u7684\u53d8\u9769\u4e3e\u63aa\u5728\u5c1d\u8bd5\u8f6c\u53d8\u8303\u5f0f\u3002", "conclusion": "\u6709\u610f\u4e49\u7684\u53d8\u9769\u4e0d\u4ec5\u9700\u8981\u65b0\u6307\u6807\u548c\u66f4\u597d\u7684\u5de5\u5177\uff0c\u8fd8\u9700\u4ece\u6839\u672c\u4e0a\u91cd\u6784\u63a8\u8350\u7cfb\u7edf\u7814\u7a76\u7684\u76ee\u6807\u3001\u670d\u52a1\u5bf9\u8c61\u4ee5\u53ca\u77e5\u8bc6\u7684\u4ea7\u751f\u548c\u9a8c\u8bc1\u65b9\u5f0f\uff0c\u547c\u5401\u57fa\u4e8e\u8ba4\u77e5\u8c26\u900a\u3001\u4eba\u7c7b\u5f71\u54cd\u548c\u53ef\u6301\u7eed\u5b9e\u8df5\u7684\u7814\u7a76\u8bae\u7a0b\u3002"}}
{"id": "2509.08989", "pdf": "https://arxiv.org/pdf/2509.08989", "abs": "https://arxiv.org/abs/2509.08989", "authors": ["Carina Newen", "Daniel Bodemer", "Sonja Glantz", "Emmanuel M\u00fcller", "Magdalena Wischnewski", "Lenka Schnaubert"], "title": "Uncertainty Awareness and Trust in Explainable AI- On Trust Calibration using Local and Global Explanations", "categories": ["cs.AI"], "comment": "9 pages, 6 figures, accepted but not yet published at ICDM2025", "summary": "Explainable AI has become a common term in the literature, scrutinized by\ncomputer scientists and statisticians and highlighted by psychological or\nphilosophical researchers. One major effort many researchers tackle is\nconstructing general guidelines for XAI schemes, which we derived from our\nstudy. While some areas of XAI are well studied, we focus on uncertainty\nexplanations and consider global explanations, which are often left out. We\nchose an algorithm that covers various concepts simultaneously, such as\nuncertainty, robustness, and global XAI, and tested its ability to calibrate\ntrust. We then checked whether an algorithm that aims to provide more of an\nintuitive visual understanding, despite being complicated to understand, can\nprovide higher user satisfaction and human interpretability.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u53ef\u89e3\u91caAI\u4e2d\u5e38\u88ab\u5ffd\u7565\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u5168\u5c40\u89e3\u91ca\uff0c\u9009\u53d6\u7279\u5b9a\u7b97\u6cd5\u6d4b\u8bd5\u6821\u51c6\u4fe1\u4efb\u80fd\u529b\u53ca\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6784\u5efa\u53ef\u89e3\u91caAI\u65b9\u6848\u7684\u901a\u7528\u6307\u5357\uff0c\u805a\u7126\u5e38\u88ab\u5ffd\u7565\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u5168\u5c40\u89e3\u91ca\u3002", "method": "\u9009\u62e9\u80fd\u540c\u65f6\u6db5\u76d6\u4e0d\u786e\u5b9a\u6027\u3001\u9c81\u68d2\u6027\u548c\u5168\u5c40\u53ef\u89e3\u91caAI\u7b49\u6982\u5ff5\u7684\u7b97\u6cd5\uff0c\u6d4b\u8bd5\u5176\u6821\u51c6\u4fe1\u4efb\u7684\u80fd\u529b\uff0c\u5e76\u68c0\u9a8c\u590d\u6742\u4f46\u76f4\u89c2\u7684\u7b97\u6cd5\u80fd\u5426\u63d0\u9ad8\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u672a\u63d0\u53ca", "conclusion": "\u672a\u63d0\u53ca"}}
{"id": "2509.08867", "pdf": "https://arxiv.org/pdf/2509.08867", "abs": "https://arxiv.org/abs/2509.08867", "authors": ["K. Pronk", "Q. Zhao"], "title": "Benchmarking Energy Efficiency of Large Language Models Using vLLM", "categories": ["cs.SE", "cs.AI", "68T01", "I.2.7"], "comment": "6 pages, 6 figures", "summary": "The prevalence of Large Language Models (LLMs) is having an growing impact on\nthe climate due to the substantial energy required for their deployment and\nuse. To create awareness for developers who are implementing LLMs in their\nproducts, there is a strong need to collect more information about the energy\nefficiency of LLMs. While existing research has evaluated the energy efficiency\nof various models, these benchmarks often fall short of representing realistic\nproduction scenarios. In this paper, we introduce the LLM Efficiency Benchmark,\ndesigned to simulate real-world usage conditions. Our benchmark utilizes vLLM,\na high-throughput, production-ready LLM serving backend that optimizes model\nperformance and efficiency. We examine how factors such as model size,\narchitecture, and concurrent request volume affect inference energy efficiency.\nOur findings demonstrate that it is possible to create energy efficiency\nbenchmarks that better reflect practical deployment conditions, providing\nvaluable insights for developers aiming to build more sustainable AI systems.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165LLM\u6548\u7387\u57fa\u51c6\u4ee5\u6a21\u62df\u771f\u5b9e\u4f7f\u7528\u6761\u4ef6\uff0c\u5229\u7528vLLM\u7814\u7a76\u591a\u56e0\u7d20\u5bf9\u63a8\u7406\u80fd\u6e90\u6548\u7387\u7684\u5f71\u54cd\uff0c\u8bc1\u660e\u53ef\u521b\u5efa\u66f4\u8d34\u5408\u5b9e\u9645\u90e8\u7f72\u6761\u4ef6\u7684\u80fd\u6e90\u6548\u7387\u57fa\u51c6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u548c\u4f7f\u7528\u8017\u80fd\u5927\uff0c\u73b0\u6709\u57fa\u51c6\u96be\u4ee5\u4ee3\u8868\u5b9e\u9645\u751f\u4ea7\u573a\u666f\uff0c\u9700\u6536\u96c6\u66f4\u591a\u80fd\u6e90\u6548\u7387\u4fe1\u606f\u4ee5\u63d0\u9ad8\u5f00\u53d1\u8005\u610f\u8bc6\u3002", "method": "\u5f15\u5165LLM Efficiency Benchmark\u6a21\u62df\u771f\u5b9e\u4f7f\u7528\u6761\u4ef6\uff0c\u5229\u7528vLLM\u4f18\u5316\u6027\u80fd\u548c\u6548\u7387\uff0c\u7814\u7a76\u6a21\u578b\u5927\u5c0f\u3001\u67b6\u6784\u548c\u5e76\u53d1\u8bf7\u6c42\u91cf\u7b49\u56e0\u7d20\u5bf9\u63a8\u7406\u80fd\u6e90\u6548\u7387\u7684\u5f71\u54cd\u3002", "result": "\u53ef\u4ee5\u521b\u5efa\u66f4\u80fd\u53cd\u6620\u5b9e\u9645\u90e8\u7f72\u6761\u4ef6\u7684\u80fd\u6e90\u6548\u7387\u57fa\u51c6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u8005\u6784\u5efa\u66f4\u53ef\u6301\u7eed\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.08961", "pdf": "https://arxiv.org/pdf/2509.08961", "abs": "https://arxiv.org/abs/2509.08961", "authors": ["Md. Sajeebul Islam Sk.", "Md Jobayer", "Md Mehedi Hasan Shawon", "Md. Golam Raibul Alam"], "title": "FoundationalECGNet: A Lightweight Foundational Model for ECG-based Multitask Cardiac Analysis", "categories": ["cs.LG", "68T07 (Primary) 68T09, 68T10 (Secondary)"], "comment": null, "summary": "Cardiovascular diseases (CVDs) remain a leading cause of mortality worldwide,\nunderscoring the importance of accurate and scalable diagnostic systems.\nElectrocardiogram (ECG) analysis is central to detecting cardiac abnormalities,\nyet challenges such as noise, class imbalance, and dataset heterogeneity limit\ncurrent methods. To address these issues, we propose FoundationalECGNet, a\nfoundational framework for automated ECG classification. The model integrates a\ndual-stage denoising by Morlet and Daubechies wavelets transformation,\nConvolutional Block Attention Module (CBAM), Graph Attention Networks (GAT),\nand Time Series Transformers (TST) to jointly capture spatial and temporal\ndependencies in multi-channel ECG signals. FoundationalECGNet first\ndistinguishes between Normal and Abnormal ECG signals, and then classifies the\nAbnormal signals into one of five cardiac conditions: Arrhythmias, Conduction\nDisorders, Myocardial Infarction, QT Abnormalities, or Hypertrophy. Across\nmultiple datasets, the model achieves a 99% F1-score for Normal vs. Abnormal\nclassification and shows state-of-the-art performance in multi-class disease\ndetection, including a 99% F1-score for Conduction Disorders and Hypertrophy,\nas well as a 98.9% F1-score for Arrhythmias. Additionally, the model provides\nrisk level estimations to facilitate clinical decision-making. In conclusion,\nFoundationalECGNet represents a scalable, interpretable, and generalizable\nsolution for automated ECG analysis, with the potential to improve diagnostic\nprecision and patient outcomes in healthcare settings. We'll share the code\nafter acceptance.", "AI": {"tldr": "\u63d0\u51faFoundationalECGNet\u7528\u4e8e\u81ea\u52a8\u5fc3\u7535\u56fe\u5206\u7c7b\uff0c\u5728\u591a\u6570\u636e\u96c6\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u662f\u5168\u7403\u4e3b\u8981\u6b7b\u56e0\uff0c\u5f53\u524d\u5fc3\u7535\u56fe\u5206\u6790\u65b9\u6cd5\u53d7\u566a\u58f0\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u6570\u636e\u96c6\u5f02\u8d28\u6027\u9650\u5236\u3002", "method": "\u63d0\u51faFoundationalECGNet\u6846\u67b6\uff0c\u96c6\u6210\u5c0f\u6ce2\u53d8\u6362\u3001\u6ce8\u610f\u529b\u6a21\u5757\u3001\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u548c\u65f6\u95f4\u5e8f\u5217\u53d8\u538b\u5668\uff0c\u5148\u533a\u5206\u6b63\u5e38\u548c\u5f02\u5e38\u4fe1\u53f7\uff0c\u518d\u5bf9\u5f02\u5e38\u4fe1\u53f7\u5206\u7c7b\u3002", "result": "\u5728\u591a\u6570\u636e\u96c6\u4e0a\uff0c\u6b63\u5e38\u4e0e\u5f02\u5e38\u5206\u7c7bF1\u5206\u6570\u8fbe99%\uff0c\u591a\u7c7b\u75be\u75c5\u68c0\u6d4b\u8868\u73b0\u4f18\u5f02\uff0c\u8fd8\u80fd\u63d0\u4f9b\u98ce\u9669\u7b49\u7ea7\u4f30\u8ba1\u3002", "conclusion": "FoundationalECGNet\u662f\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u6cdb\u5316\u7684\u5fc3\u7535\u56fe\u5206\u6790\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u63d0\u9ad8\u8bca\u65ad\u7cbe\u5ea6\u548c\u60a3\u8005\u9884\u540e\u3002"}}
{"id": "2509.09252", "pdf": "https://arxiv.org/pdf/2509.09252", "abs": "https://arxiv.org/abs/2509.09252", "authors": ["Alexandros Hollender", "Pasin Manurangsi", "Raghu Meka", "Warut Suksompong"], "title": "Discrepancy Beyond Additive Functions with Applications to Fair Division", "categories": ["math.CO", "cs.DM", "cs.GT"], "comment": null, "summary": "We consider a setting where we have a ground set $M$ together with\nreal-valued set functions $f_1, \\dots, f_n$, and the goal is to partition $M$\ninto two sets $S_1,S_2$ such that $|f_i(S_1) - f_i(S_2)|$ is small for every\n$i$. Many results in discrepancy theory can be stated in this form with the\nfunctions $f_i$ being additive. In this work, we initiate the study of the\nunstructured case where $f_i$ is not assumed to be additive. We show that even\nwithout the additivity assumption, the upper bound remains at most $O(\\sqrt{n\n\\log n})$.\n  Our result has implications on the fair allocation of indivisible goods. In\nparticular, we show that a consensus halving up to $O(\\sqrt{n \\log n})$ goods\nalways exists for $n$ agents with monotone utilities. Previously, only an\n$O(n)$ bound was known for this setting.", "AI": {"tldr": "\u7814\u7a76\u65e0\u7ed3\u6784\u60c5\u51b5\u4e0b\u5c06\u96c6\u5408M\u5212\u5206\u4e3aS1\u548cS2\u4f7f|fi(S1) - fi(S2)|\u5c0f\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u65e0\u52a0\u6cd5\u6027\u5047\u8bbe\u65f6\u4e0a\u754c\u4e3aO(\u221a(n log n))\uff0c\u5e76\u7528\u4e8e\u516c\u5e73\u5206\u914d\u95ee\u9898\uff0c\u6539\u8fdb\u4e86\u5df2\u77e5\u754c\u3002", "motivation": "\u73b0\u6709\u5dee\u5f02\u7406\u8bba\u591a\u57fa\u4e8e\u51fd\u6570fi\u4e3a\u53ef\u52a0\u6027\uff0c\u672c\u6587\u5f00\u542f\u5bf9fi\u975e\u53ef\u52a0\u6027\u7684\u65e0\u7ed3\u6784\u60c5\u51b5\u7684\u7814\u7a76\u3002", "method": "\u7406\u8bba\u5206\u6790\u4e0e\u8bc1\u660e\u3002", "result": "\u8bc1\u660e\u65e0\u52a0\u6cd5\u6027\u5047\u8bbe\u65f6\u4e0a\u754c\u6700\u591a\u4e3aO(\u221a(n log n))\uff0c\u5728\u516c\u5e73\u5206\u914d\u4e2d\uff0cn\u4e2a\u5177\u6709\u5355\u8c03\u6548\u7528\u7684\u4ee3\u7406\u4eba\u7684\u5171\u8bc6\u5e73\u5206\u6700\u591a\u5b58\u5728O(\u221a(n log n))\u4e2a\u5546\u54c1\u3002", "conclusion": "\u5728\u65e0\u52a0\u6cd5\u6027\u5047\u8bbe\u4e0b\u5f97\u5230\u96c6\u5408\u5212\u5206\u95ee\u9898\u7684\u4e0a\u754c\u7ed3\u679c\uff0c\u5e76\u5728\u516c\u5e73\u5206\u914d\u95ee\u9898\u4e0a\u6539\u8fdb\u4e86\u5df2\u77e5\u754c\u3002"}}
{"id": "2509.09493", "pdf": "https://arxiv.org/pdf/2509.09493", "abs": "https://arxiv.org/abs/2509.09493", "authors": ["Ignacio Amores-Sesar", "Christian Cachin", "Juan Villacis"], "title": "Weaker Assumptions for Asymmetric Trust", "categories": ["cs.DC"], "comment": null, "summary": "In distributed systems with asymmetric trust, each participant is free to\nmake its own trust assumptions about others, captured by an asymmetric quorum\nsystem. This contrasts with ordinary, symmetric quorum systems and threshold\nmodels, where trust assumptions are uniformly shared among participants.\nFundamental problems like reliable broadcast and consensus are unsolvable in\nthe asymmetric model if quorum systems satisfy only the classical properties of\nconsistency and availability. Existing approaches overcome this by introducing\nstronger assumptions. We show that some of these assumptions are overly\nrestrictive, so much so that they effectively eliminate the benefits of\nasymmetric trust. To address this, we propose a new approach to characterize\nasymmetric problems and, building upon it, present algorithms for reliable\nbroadcast and consensus that require weaker assumptions than previous\nsolutions. Our methods are general and can be extended to other core problems\nin systems with asymmetric trust.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5728\u975e\u5bf9\u79f0\u4fe1\u4efb\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u73b0\u6709\u89e3\u51b3\u95ee\u9898\u7684\u5047\u8bbe\u8fc7\u4e8e\u4e25\u683c\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u89e3\u51b3\u53ef\u9760\u5e7f\u64ad\u548c\u5171\u8bc6\u95ee\u9898\uff0c\u4e14\u65b9\u6cd5\u53ef\u6269\u5c55\u3002", "motivation": "\u73b0\u6709\u89e3\u51b3\u975e\u5bf9\u79f0\u4fe1\u4efb\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u57fa\u672c\u95ee\u9898\u7684\u65b9\u6cd5\u5047\u8bbe\u8fc7\u4e8e\u4e25\u683c\uff0c\u6d88\u9664\u4e86\u975e\u5bf9\u79f0\u4fe1\u4efb\u7684\u597d\u5904\u3002", "method": "\u63d0\u51fa\u65b0\u65b9\u6cd5\u6765\u523b\u753b\u975e\u5bf9\u79f0\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u6b64\u7ed9\u51fa\u53ef\u9760\u5e7f\u64ad\u548c\u5171\u8bc6\u7b97\u6cd5\uff0c\u6240\u9700\u5047\u8bbe\u6bd4\u4e4b\u524d\u7684\u89e3\u51b3\u65b9\u6848\u5f31\u3002", "result": "\u5f97\u5230\u4e86\u53ef\u9760\u5e7f\u64ad\u548c\u5171\u8bc6\u7b97\u6cd5\uff0c\u4e14\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u80fd\u5728\u8f83\u5f31\u5047\u8bbe\u4e0b\u89e3\u51b3\u975e\u5bf9\u79f0\u4fe1\u4efb\u7cfb\u7edf\u4e2d\u7684\u95ee\u9898\uff0c\u4e14\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u6838\u5fc3\u95ee\u9898\u3002"}}
{"id": "2509.09459", "pdf": "https://arxiv.org/pdf/2509.09459", "abs": "https://arxiv.org/abs/2509.09459", "authors": ["Chao Huang", "Fengran Mo", "Yufeng Chen", "Changhao Guan", "Zhenrui Yue", "Xinyu Wang", "Jinan Xu", "Kaiyu Huang"], "title": "Boosting Data Utilization for Multilingual Dense Retrieval", "categories": ["cs.IR"], "comment": "Accepted by EMNLP 2025 (main)", "summary": "Multilingual dense retrieval aims to retrieve relevant documents across\ndifferent languages based on a unified retriever model. The challenge lies in\naligning representations of different languages in a shared vector space. The\ncommon practice is to fine-tune the dense retriever via contrastive learning,\nwhose effectiveness highly relies on the quality of the negative sample and the\nefficacy of mini-batch data. Different from the existing studies that focus on\ndeveloping sophisticated model architecture, we propose a method to boost data\nutilization for multilingual dense retrieval by obtaining high-quality hard\nnegative samples and effective mini-batch data. The extensive experimental\nresults on a multilingual retrieval benchmark, MIRACL, with 16 languages\ndemonstrate the effectiveness of our method by outperforming several existing\nstrong baselines.", "AI": {"tldr": "\u63d0\u51fa\u63d0\u5347\u591a\u8bed\u8a00\u5bc6\u96c6\u68c0\u7d22\u6570\u636e\u5229\u7528\u7387\u7684\u65b9\u6cd5\uff0c\u5728MIRACL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u3002", "motivation": "\u591a\u8bed\u8a00\u5bc6\u96c6\u68c0\u7d22\u9700\u5728\u5171\u4eab\u5411\u91cf\u7a7a\u95f4\u5bf9\u9f50\u4e0d\u540c\u8bed\u8a00\u8868\u793a\uff0c\u73b0\u6709\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u8d1f\u6837\u672c\u8d28\u91cf\u548c\u5c0f\u6279\u91cf\u6570\u636e\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u83b7\u53d6\u9ad8\u8d28\u91cf\u96be\u8d1f\u6837\u672c\u548c\u6709\u6548\u5c0f\u6279\u91cf\u6570\u636e\u6765\u63d0\u5347\u591a\u8bed\u8a00\u5bc6\u96c6\u68c0\u7d22\u7684\u6570\u636e\u5229\u7528\u7387\u3002", "result": "\u5728\u5305\u542b16\u79cd\u8bed\u8a00\u7684MIRACL\u591a\u8bed\u8a00\u68c0\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u591a\u4e2a\u73b0\u6709\u5f3a\u57fa\u7ebf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u63d0\u5347\u6570\u636e\u5229\u7528\u7387\u7684\u65b9\u6cd5\u5bf9\u4e8e\u591a\u8bed\u8a00\u5bc6\u96c6\u68c0\u7d22\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2509.09066", "pdf": "https://arxiv.org/pdf/2509.09066", "abs": "https://arxiv.org/abs/2509.09066", "authors": ["Haowei Yang", "Yushang Zhao", "Sitao Min", "Bo Su", "Chao Yao", "Wei Xu"], "title": "Instructional Prompt Optimization for Few-Shot LLM-Based Recommendations on Cold-Start Users", "categories": ["cs.AI"], "comment": null, "summary": "The cold-start user issue further compromises the effectiveness of\nrecommender systems in limiting access to the historical behavioral\ninformation. It is an effective pipeline to optimize instructional prompts on a\nfew-shot large language model (LLM) used in recommender tasks. We introduce a\ncontext-conditioned prompt formulation method P(u,\\ Ds)\\ \\rightarrow\\\nR\\widehat, where u is a cold-start user profile, Ds is a curated support set,\nand R\\widehat is the predicted ranked list of items. Based on systematic\nexperimentation with transformer-based autoregressive LLMs (BioGPT, LLaMA-2,\nGPT-4), we provide empirical evidence that optimal exemplar injection and\ninstruction structuring can significantly improve the precision@k and NDCG\nscores of such models in low-data settings. The pipeline uses token-level\nalignments and embedding space regularization with a greater semantic fidelity.\nOur findings not only show that timely composition is not merely syntactic but\nalso functional as it is in direct control of attention scales and decoder\nconduct through inference. This paper shows that prompt-based adaptation may be\nconsidered one of the ways to address cold-start recommendation issues in\nLLM-based pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e0a\u4e0b\u6587\u6761\u4ef6\u63d0\u793a\u516c\u5f0f\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4f18\u5316\u63d0\u793a\u53ef\u63d0\u5347\u6a21\u578b\u6307\u6807\uff0c\u63d0\u793a\u9002\u914d\u662f\u89e3\u51b3\u51b7\u542f\u52a8\u7684\u9014\u5f84\u4e4b\u4e00\u3002", "motivation": "\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u51b7\u542f\u52a8\u7528\u6237\u56e0\u5386\u53f2\u884c\u4e3a\u4fe1\u606f\u53d7\u9650\u5bfc\u81f4\u63a8\u8350\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e0a\u4e0b\u6587\u6761\u4ef6\u63d0\u793a\u516c\u5f0fP(u, Ds) -> R\u02c6\uff0c\u7ed3\u5408\u57fa\u4e8eTransformer\u7684\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528token\u7ea7\u5bf9\u9f50\u548c\u5d4c\u5165\u7a7a\u95f4\u6b63\u5219\u5316\u3002", "result": "\u6700\u4f18\u793a\u4f8b\u6ce8\u5165\u548c\u6307\u4ee4\u7ed3\u6784\u80fd\u663e\u8457\u63d0\u9ad8\u4f4e\u6570\u636e\u8bbe\u7f6e\u4e0b\u6a21\u578b\u7684precision@k\u548cNDCG\u5206\u6570\uff0c\u53ca\u65f6\u7ec4\u5408\u4e0d\u4ec5\u662f\u8bed\u6cd5\u4e0a\u7684\uff0c\u8fd8\u80fd\u63a7\u5236\u6ce8\u610f\u529b\u548c\u8bd1\u7801\u5668\u884c\u4e3a\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684\u9002\u914d\u53ef\u4f5c\u4e3a\u89e3\u51b3\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u4e2d\u51b7\u542f\u52a8\u63a8\u8350\u95ee\u9898\u7684\u65b9\u6cd5\u4e4b\u4e00\u3002"}}
{"id": "2509.09072", "pdf": "https://arxiv.org/pdf/2509.09072", "abs": "https://arxiv.org/abs/2509.09072", "authors": ["Ahmed Adnan", "Mushfiqur Rahman", "Saad Sakib Noor", "Kazi Sakib"], "title": "CLARA: A Developer's Companion for Code Comprehension and Analysis", "categories": ["cs.SE"], "comment": "In proceedings at the 40th IEEE/ACM International Conference on\n  Automated Software Engineering, ASE 2025", "summary": "Code comprehension and analysis of open-source project codebases is a task\nfrequently performed by developers and researchers. However, existing tools\nthat practitioners use for assistance with such tasks often require prior\nproject setup, lack context-awareness, and involve significant manual effort.\nTo address this, we present CLARA, a browser extension that utilizes a\nstate-of-the-art inference model to assist developers and researchers in: (i)\ncomprehending code files and code fragments, (ii) code refactoring, and (iii)\ncode quality attribute detection. We qualitatively evaluated CLARA's inference\nmodel using existing datasets and methodology, and performed a comprehensive\nuser study with 10 developers and academic researchers to assess its usability\nand usefulness. The results show that CLARA is useful, accurate, and practical\nin code comprehension and analysis tasks. CLARA is an open-source tool\navailable at https://github.com/SaadNoor555/CLARA_tool_demo. A video showing\nthe full capabilities of CLARA can be found at\nhttps://youtu.be/VDKVXvIH41Q?si=qBFsmS_Y4m_9x3YH.", "AI": {"tldr": "\u4ecb\u7ecdCLARA\u6d4f\u89c8\u5668\u6269\u5c55\uff0c\u5b83\u7528\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u8f85\u52a9\u4ee3\u7801\u7406\u89e3\u5206\u6790\u7b49\u4efb\u52a1\uff0c\u7ecf\u8bc4\u4f30\u6709\u7528\u3001\u51c6\u786e\u4e14\u5b9e\u7528\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u7406\u89e3\u5206\u6790\u5de5\u5177\u9700\u9879\u76ee\u9884\u8bbe\u7f6e\u3001\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\u4e14\u9700\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\u3002", "method": "\u7528\u73b0\u6709\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u5bf9CLARA\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u5b9a\u6027\u8bc4\u4f30\uff0c\u5bf910\u540d\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u5f00\u5c55\u7528\u6237\u7814\u7a76\u3002", "result": "CLARA\u5728\u4ee3\u7801\u7406\u89e3\u548c\u5206\u6790\u4efb\u52a1\u4e2d\u6709\u7528\u3001\u51c6\u786e\u4e14\u5b9e\u7528\u3002", "conclusion": "CLARA\u662f\u4e00\u4e2a\u53ef\u7528\u4e8e\u4ee3\u7801\u7406\u89e3\u548c\u5206\u6790\u7684\u6709\u6548\u5f00\u6e90\u5de5\u5177\u3002"}}
{"id": "2509.08963", "pdf": "https://arxiv.org/pdf/2509.08963", "abs": "https://arxiv.org/abs/2509.08963", "authors": ["Alexander Binder", "Nastaran Takmil-Homayouni", "Urun Dogan"], "title": "Value bounds and Convergence Analysis for Averages of LRP attributions", "categories": ["cs.LG", "cs.CV"], "comment": "37 pages", "summary": "We analyze numerical properties of Layer-wise relevance propagation\n(LRP)-type attribution methods by representing them as a product of modified\ngradient matrices. This representation creates an analogy to matrix\nmultiplications of Jacobi-matrices which arise from the chain rule of\ndifferentiation. In order to shed light on the distribution of attribution\nvalues, we derive upper bounds for singular values. Furthermore we derive\ncomponent-wise bounds for attribution map values. As a main result, we apply\nthese component-wise bounds to obtain multiplicative constants. These constants\ngovern the convergence of empirical means of attributions to expectations of\nattribution maps. This finding has important implications for scenarios where\nmultiple non-geometric data augmentations are applied to individual test\nsamples, as well as for Smoothgrad-type attribution methods. In particular, our\nanalysis reveals that the constants for LRP-beta remain independent of weight\nnorms, a significant distinction from both gradient-based methods and\nLRP-epsilon.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06LRP\u578b\u5f52\u56e0\u65b9\u6cd5\u8868\u793a\u4e3a\u4fee\u6539\u540e\u7684\u68af\u5ea6\u77e9\u9635\u4e58\u79ef\uff0c\u5206\u6790\u5176\u6570\u503c\u7279\u6027\uff0c\u63a8\u5bfc\u5947\u5f02\u503c\u548c\u5f52\u56e0\u56fe\u503c\u7684\u754c\uff0c\u5f97\u5230\u63a7\u5236\u5f52\u56e0\u7ecf\u9a8c\u5747\u503c\u6536\u655b\u7684\u5e38\u6570\uff0c\u63ed\u793aLRP - beta\u7684\u7279\u6027\u3002", "motivation": "\u5206\u6790LRP\u578b\u5f52\u56e0\u65b9\u6cd5\u7684\u6570\u503c\u7279\u6027\uff0c\u4e86\u89e3\u5f52\u56e0\u503c\u5206\u5e03\u3002", "method": "\u5c06LRP\u578b\u5f52\u56e0\u65b9\u6cd5\u8868\u793a\u4e3a\u4fee\u6539\u540e\u7684\u68af\u5ea6\u77e9\u9635\u4e58\u79ef\uff0c\u7c7b\u6bd4\u96c5\u53ef\u6bd4\u77e9\u9635\u4e58\u6cd5\uff0c\u63a8\u5bfc\u5947\u5f02\u503c\u548c\u5206\u91cf\u754c\u3002", "result": "\u5f97\u5230\u63a7\u5236\u5f52\u56e0\u7ecf\u9a8c\u5747\u503c\u6536\u655b\u5230\u671f\u671b\u7684\u4e58\u6cd5\u5e38\u6570\uff0c\u53d1\u73b0LRP - beta\u7684\u5e38\u6570\u4e0e\u6743\u91cd\u8303\u6570\u65e0\u5173\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u975e\u51e0\u4f55\u6570\u636e\u589e\u5f3a\u548cSmoothgrad\u578b\u5f52\u56e0\u65b9\u6cd5\u6709\u91cd\u8981\u610f\u4e49\uff0cLRP - beta\u4e0e\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u548cLRP - epsilon\u6709\u663e\u8457\u533a\u522b\u3002"}}
{"id": "2509.08926", "pdf": "https://arxiv.org/pdf/2509.08926", "abs": "https://arxiv.org/abs/2509.08926", "authors": ["Waqar Ahmad", "Evan Murphy", "Vladimir A. Krylov"], "title": "Similarity-based Outlier Detection for Noisy Object Re-Identification Using Beta Mixtures", "categories": ["cs.CV", "cs.AI", "cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Object re-identification (Re-ID) methods are highly sensitive to label noise,\nwhich typically leads to significant performance degradation. We address this\nchallenge by reframing Re-ID as a supervised image similarity task and adopting\na Siamese network architecture trained to capture discriminative pairwise\nrelationships. Central to our approach is a novel statistical outlier detection\n(OD) framework, termed Beta-SOD (Beta mixture Similarity-based Outlier\nDetection), which models the distribution of cosine similarities between\nembedding pairs using a two-component Beta distribution mixture model. We\nestablish a novel identifiability result for mixtures of two Beta\ndistributions, ensuring that our learning task is well-posed.The proposed OD\nstep complements the Re-ID architecture combining binary cross-entropy,\ncontrastive, and cosine embedding losses that jointly optimize feature-level\nsimilarity learning.We demonstrate the effectiveness of Beta-SOD in de-noising\nand Re-ID tasks for person Re-ID, on CUHK03 and Market-1501 datasets, and\nvehicle Re-ID, on VeRi-776 dataset. Our method shows superior performance\ncompared to the state-of-the-art methods across various noise levels (10-30\\%),\ndemonstrating both robustness and broad applicability in noisy Re-ID scenarios.\nThe implementation of Beta-SOD is available at:\nhttps://github.com/waqar3411/Beta-SOD", "AI": {"tldr": "\u672c\u6587\u5c06\u76ee\u6807\u91cd\u8bc6\u522b\uff08Re - ID\uff09\u95ee\u9898\u8f6c\u5316\u4e3a\u6709\u76d1\u7763\u56fe\u50cf\u76f8\u4f3c\u5ea6\u4efb\u52a1\uff0c\u91c7\u7528Siamese\u7f51\u7edc\u548c\u65b0\u7684Beta - SOD\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u53bb\u566a\u548c\u91cd\u8bc6\u522b\u6548\u679c\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u76ee\u6807\u91cd\u8bc6\u522b\u65b9\u6cd5\u5bf9\u6807\u7b7e\u566a\u58f0\u654f\u611f\uff0c\u6613\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u5c06Re - ID\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6709\u76d1\u7763\u56fe\u50cf\u76f8\u4f3c\u5ea6\u4efb\u52a1\uff0c\u91c7\u7528Siamese\u7f51\u7edc\u67b6\u6784\uff1b\u63d0\u51faBeta - SOD\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u53cc\u5206\u91cfBeta\u5206\u5e03\u6df7\u5408\u6a21\u578b\u5efa\u6a21\u5d4c\u5165\u5bf9\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5206\u5e03\uff1b\u7ed3\u5408\u4e8c\u5143\u4ea4\u53c9\u71b5\u3001\u5bf9\u6bd4\u548c\u4f59\u5f26\u5d4c\u5165\u635f\u5931\u4f18\u5316\u7279\u5f81\u7ea7\u76f8\u4f3c\u5ea6\u5b66\u4e60\u3002", "result": "\u5728CUHK03\u3001Market - 1501\u548cVeRi - 776\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86Beta - SOD\u5728\u53bb\u566a\u548c\u91cd\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\uff0810 - 30%\uff09\u4e0b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Beta - SOD\u65b9\u6cd5\u5728\u6709\u566a\u58f0\u7684Re - ID\u573a\u666f\u4e2d\u5177\u6709\u9c81\u68d2\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2509.09525", "pdf": "https://arxiv.org/pdf/2509.09525", "abs": "https://arxiv.org/abs/2509.09525", "authors": ["Jialiang Huang", "Teng Ma", "Zheng Liu", "Sixing Lin", "Kang Chen", "Jinlei Jiang", "Xia Liao", "Yingdi Shan", "Yongwei Wu", "Ning Zhang", "Mengting Lu", "Tao Ma", "Haifeng Gong", "Mingxing Zhang"], "title": "TrEnv: Transparently Share Serverless Execution Environments Across Different Functions and Nodes", "categories": ["cs.DC", "cs.OS"], "comment": "38 pages", "summary": "Serverless computing provides dynamic scalability, but its infrastructure\noverhead becomes a bottleneck for emerging workloads such as LLM agents, which\nexhibit unpredictable invocation patterns and variable resource demands. Our\nanalysis shows that for these agents, the cost of running on serverless\nplatforms can reach up to 70% of the cost of LLM API calls. This finding\nmotivates the need for a more efficient, high-density serverless platform. We\npresent TrEnv, a co-designed serverless platform that supports both container-\nand VM-based environments, optimized for the unique demands of LLM agents.\nTrEnv reduces startup latency and memory usage through repurposable sandboxes\nand memory templates, which enable fast reuse and restoration of execution\nenvironments. To further reduce overhead in VM-based agent workloads, TrEnv\nleverages browser sharing and a page cache bypassing mechanism. Evaluations\nshow that TrEnv reduces P99 latency by up to 7X and memory usage by 48% in\ncontainer-based settings, and achieves up to 58% lower P99 latency and 61%\nmemory savings for VM-based agents compared to state-of-the-art systems like\nE2B.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5bf9LLM\u4ee3\u7406\u5b58\u5728\u5f00\u9500\u74f6\u9888\uff0c\u63d0\u51faTrEnv\u5e73\u53f0\uff0c\u53ef\u964d\u4f4e\u5ef6\u8fdf\u548c\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u7684\u57fa\u7840\u8bbe\u65bd\u5f00\u9500\u6210\u4e3aLLM\u4ee3\u7406\u7b49\u65b0\u5174\u5de5\u4f5c\u8d1f\u8f7d\u7684\u74f6\u9888\uff0c\u8fd0\u884c\u6210\u672c\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u9ad8\u5bc6\u5ea6\u7684\u65e0\u670d\u52a1\u5668\u5e73\u53f0\u3002", "method": "\u63d0\u51faTrEnv\u5e73\u53f0\uff0c\u652f\u6301\u5bb9\u5668\u548c\u57fa\u4e8eVM\u7684\u73af\u5883\uff0c\u901a\u8fc7\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u6c99\u7bb1\u548c\u5185\u5b58\u6a21\u677f\u51cf\u5c11\u542f\u52a8\u5ef6\u8fdf\u548c\u5185\u5b58\u4f7f\u7528\uff0c\u8fd8\u5229\u7528\u6d4f\u89c8\u5668\u5171\u4eab\u548c\u9875\u9762\u7f13\u5b58\u7ed5\u8fc7\u673a\u5236\u51cf\u5c11\u57fa\u4e8eVM\u7684\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5f00\u9500\u3002", "result": "TrEnv\u5728\u57fa\u4e8e\u5bb9\u5668\u7684\u8bbe\u7f6e\u4e2d\uff0cP99\u5ef6\u8fdf\u6700\u591a\u964d\u4f4e7\u500d\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c1148%\uff1b\u4e0eE2B\u7b49\u5148\u8fdb\u7cfb\u7edf\u76f8\u6bd4\uff0c\u57fa\u4e8eVM\u7684\u4ee3\u7406P99\u5ef6\u8fdf\u6700\u591a\u964d\u4f4e58%\uff0c\u5185\u5b58\u8282\u770161%\u3002", "conclusion": "TrEnv\u5e73\u53f0\u80fd\u6709\u6548\u964d\u4f4eLLM\u4ee3\u7406\u5728\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u4e2d\u7684\u5ef6\u8fdf\u548c\u5185\u5b58\u4f7f\u7528\uff0c\u63d0\u9ad8\u6548\u7387\u3002"}}
{"id": "2509.09622", "pdf": "https://arxiv.org/pdf/2509.09622", "abs": "https://arxiv.org/abs/2509.09622", "authors": ["Shashank Gupta"], "title": "AskDoc -- Identifying Hidden Healthcare Disparities", "categories": ["cs.IR"], "comment": null, "summary": "The objective of this study is to understand the online Ask the Doctor\nservices medical advice on internet platforms via AskDoc, a Reddit community\nthat serves as a public AtD platform and study if platforms mirror existing\nhurdles and partiality in healthcare across various demographic groups. We\ndownloaded data from January 2020 to May 2022 from AskDoc -- a subreddit, and\ncreated regular expressions to identify self-reported demographics (Gender,\nRace, and Age) from the posts, and performed statistical analysis to understand\nthe interaction between peers and physicians with the posters. Half of the\nposts did not receive comments from peers or physicians. At least 90% of the\npeople disclose their gender and age, and 80% of the people do not disclose\ntheir race. It was observed that the subreddit is dominated by adult (age group\n20-39) white males. Some disparities were observed in the engagement between\nthe users and the posters with certain demographics. Beyond the confines of\nclinics and hospitals, social media could bring patients and providers closer\ntogether, however, as observed, current physicians participation is low\ncompared to posters.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7Reddit\u793e\u533aAskDoc\u5206\u6790\u5728\u7ebf\u533b\u751f\u54a8\u8be2\u670d\u52a1\uff0c\u53d1\u73b0\u90e8\u5206\u5e16\u5b50\u65e0\u56de\u590d\uff0c\u7528\u6237\u591a\u4e3a20 - 39\u5c81\u767d\u4eba\u7537\u6027\uff0c\u533b\u60a3\u53c2\u4e0e\u6709\u5dee\u5f02\u3002", "motivation": "\u4e86\u89e3\u4e92\u8054\u7f51\u5e73\u53f0\u5728\u7ebf\u533b\u751f\u54a8\u8be2\u670d\u52a1\u7684\u533b\u7597\u5efa\u8bae\uff0c\u7814\u7a76\u5e73\u53f0\u662f\u5426\u53cd\u6620\u4e0d\u540c\u4eba\u7fa4\u533b\u7597\u969c\u788d\u548c\u504f\u89c1\u3002", "method": "\u4e0b\u8f7dAskDoc 2020\u5e741\u6708\u81f32022\u5e745\u6708\u7684\u6570\u636e\uff0c\u7528\u6b63\u5219\u8868\u8fbe\u5f0f\u8bc6\u522b\u5e16\u5b50\u4e2d\u81ea\u6211\u62a5\u544a\u7684\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\uff0c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u4e00\u534a\u5e16\u5b50\u65e0\u56de\u590d\uff0c\u81f3\u5c1190%\u7684\u4eba\u900f\u9732\u6027\u522b\u548c\u5e74\u9f84\uff0c80%\u7684\u4eba\u4e0d\u900f\u9732\u79cd\u65cf\uff0c\u793e\u533a\u4ee520 - 39\u5c81\u767d\u4eba\u7537\u6027\u4e3a\u4e3b\uff0c\u4e0d\u540c\u4eba\u53e3\u7279\u5f81\u7528\u6237\u53c2\u4e0e\u6709\u5dee\u5f02\uff0c\u533b\u751f\u53c2\u4e0e\u5ea6\u4f4e\u4e8e\u53d1\u5e16\u8005\u3002", "conclusion": "\u793e\u4ea4\u5a92\u4f53\u53ef\u62c9\u8fd1\u533b\u60a3\u8ddd\u79bb\uff0c\u4f46\u76ee\u524d\u533b\u751f\u53c2\u4e0e\u5ea6\u8f83\u4f4e\u3002"}}
{"id": "2509.09192", "pdf": "https://arxiv.org/pdf/2509.09192", "abs": "https://arxiv.org/abs/2509.09192", "authors": ["Doha Nam", "Taehyoun Kim", "Duksan Ryu", "Jongmoon Baik"], "title": "Probing Pre-trained Language Models on Code Changes: Insights from ReDef, a High-Confidence Just-in-Time Defect Prediction Dataset", "categories": ["cs.SE", "cs.AI"], "comment": "An anonymous link containing the dataset, construction scripts, and\n  experimental code is publicly available for reproducibility:\n  https://figshare.com/s/4f202bc0921e26b41dc2", "summary": "Just-in-Time software defect prediction (JIT-SDP) plays a critical role in\nprioritizing risky code changes during code review and continuous integration.\nHowever, existing datasets often suffer from noisy labels and low precision in\nidentifying bug-inducing commits. To address this, we present ReDef\n(Revert-based Defect dataset), a high-confidence benchmark of function-level\nmodifications curated from 22 large-scale C/C++ projects. Defective cases are\nanchored by revert commits, while clean cases are validated through post-hoc\nhistory checks. Ambiguous instances are conservatively filtered out via a\nGPT-assisted triage process involving multiple votes and audits. This pipeline\nyields 3,164 defective and 10,268 clean modifications, offering substantially\nmore reliable labels than prior existing resources. Beyond dataset\nconstruction, we provide the first systematic evaluation of how pre-trained\nlanguage models (PLMs) reason about code modifications -- specifically, which\ninput encodings most effectively expose change information, and whether models\ngenuinely capture edit semantics. We fine-tune CodeBERT, CodeT5+, and UniXcoder\nunder five encoding strategies, and further probe their sensitivity through\ncounterfactual perturbations that swap added/deleted blocks, invert diff\npolarity, or inject spurious markers. Our results show that compact diff-style\nencodings consistently outperform whole-function formats across all PLMs, with\nstatistical tests confirming large, model-independent effects. However, under\ncounterfactual tests, performance degrades little or not at all -- revealing\nthat what appears to be robustness in fact reflects reliance on superficial\ncues rather than true semantic understanding. These findings indicate that,\nunlike in snapshot-based tasks, current PLMs remain limited in their ability to\ngenuinely comprehend code modifications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9ad8\u7f6e\u4fe1\u5ea6\u57fa\u51c6\u6570\u636e\u96c6ReDef\uff0c\u8bc4\u4f30\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5bf9\u4ee3\u7801\u4fee\u6539\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u7406\u89e3\u4ee3\u7801\u4fee\u6539\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u548c\u8bc6\u522b\u7cbe\u5ea6\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u6784\u5efa\u66f4\u53ef\u9760\u7684\u6570\u636e\u96c6\u5e76\u8bc4\u4f30\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5bf9\u4ee3\u7801\u4fee\u6539\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4ece22\u4e2aC/C++\u9879\u76ee\u6784\u5efaReDef\u6570\u636e\u96c6\uff0c\u91c7\u7528GPT\u8f85\u52a9\u7b5b\u9009\u6d41\u7a0b\uff1b\u5bf9CodeBERT\u7b49\u6a21\u578b\u5728\u4e94\u79cd\u7f16\u7801\u7b56\u7565\u4e0b\u5fae\u8c03\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6270\u52a8\u6d4b\u8bd5\u5176\u654f\u611f\u6027\u3002", "result": "\u7d27\u51d1\u7684\u5dee\u5f02\u5f0f\u7f16\u7801\u5728\u6240\u6709\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u4e8e\u5168\u51fd\u6570\u683c\u5f0f\uff1b\u53cd\u4e8b\u5b9e\u6d4b\u8bd5\u4e2d\u6a21\u578b\u6027\u80fd\u51e0\u4e4e\u65e0\u4e0b\u964d\uff0c\u4f9d\u8d56\u8868\u9762\u7ebf\u7d22\u800c\u975e\u8bed\u4e49\u7406\u89e3\u3002", "conclusion": "\u4e0e\u57fa\u4e8e\u5feb\u7167\u7684\u4efb\u52a1\u4e0d\u540c\uff0c\u5f53\u524d\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u771f\u6b63\u7406\u89e3\u4ee3\u7801\u4fee\u6539\u7684\u80fd\u529b\u6709\u9650\u3002"}}
{"id": "2509.08980", "pdf": "https://arxiv.org/pdf/2509.08980", "abs": "https://arxiv.org/abs/2509.08980", "authors": ["Daniel Richards Arputharaj", "Charlotte Rodriguez", "Angelo Rodio", "Giovanni Neglia"], "title": "Green Federated Learning via Carbon-Aware Client and Time Slot Scheduling", "categories": ["cs.LG"], "comment": null, "summary": "Training large-scale machine learning models incurs substantial carbon\nemissions. Federated Learning (FL), by distributing computation across\ngeographically dispersed clients, offers a natural framework to leverage\nregional and temporal variations in Carbon Intensity (CI). This paper\ninvestigates how to reduce emissions in FL through carbon-aware client\nselection and training scheduling. We first quantify the emission savings of a\ncarbon-aware scheduling policy that leverages slack time -- permitting a modest\nextension of the training duration so that clients can defer local training\nrounds to lower-carbon periods. We then examine the performance trade-offs of\nsuch scheduling which stem from statistical heterogeneity among clients,\nselection bias in participation, and temporal correlation in model updates. To\nleverage these trade-offs, we construct a carbon-aware scheduler that\nintegrates slack time, $\\alpha$-fair carbon allocation, and a global\nfine-tuning phase. Experiments on real-world CI data show that our scheduler\noutperforms slack-agnostic baselines, achieving higher model accuracy across a\nwide range of carbon budgets, with especially strong gains under tight carbon\nconstraints.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8054\u90a6\u5b66\u4e60\u4e2d\u901a\u8fc7\u78b3\u611f\u77e5\u5ba2\u6237\u7aef\u9009\u62e9\u548c\u8bad\u7ec3\u8c03\u5ea6\u51cf\u5c11\u78b3\u6392\u653e\uff0c\u6784\u5efa\u4e86\u78b3\u611f\u77e5\u8c03\u5ea6\u5668\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u4f1a\u4ea7\u751f\u5927\u91cf\u78b3\u6392\u653e\uff0c\u8054\u90a6\u5b66\u4e60\u53ef\u5229\u7528\u78b3\u5f3a\u5ea6\u7684\u533a\u57df\u548c\u65f6\u95f4\u5dee\u5f02\uff0c\u56e0\u6b64\u7814\u7a76\u5982\u4f55\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u51cf\u5c11\u6392\u653e\u3002", "method": "\u5148\u91cf\u5316\u5229\u7528\u7a7a\u95f2\u65f6\u95f4\u7684\u78b3\u611f\u77e5\u8c03\u5ea6\u7b56\u7565\u7684\u51cf\u6392\u91cf\uff0c\u518d\u7814\u7a76\u8be5\u8c03\u5ea6\u7684\u6027\u80fd\u6743\u8861\uff0c\u6700\u540e\u6784\u5efa\u96c6\u6210\u7a7a\u95f2\u65f6\u95f4\u3001\u03b1 - \u516c\u5e73\u78b3\u5206\u914d\u548c\u5168\u5c40\u5fae\u8c03\u9636\u6bb5\u7684\u78b3\u611f\u77e5\u8c03\u5ea6\u5668\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u78b3\u5f3a\u5ea6\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8c03\u5ea6\u5668\u5728\u5404\u79cd\u78b3\u9884\u7b97\u4e0b\u90fd\u80fd\u5b9e\u73b0\u66f4\u9ad8\u7684\u6a21\u578b\u7cbe\u5ea6\uff0c\u5728\u4e25\u683c\u78b3\u7ea6\u675f\u4e0b\u4f18\u52bf\u660e\u663e\u3002", "conclusion": "\u6240\u6784\u5efa\u7684\u78b3\u611f\u77e5\u8c03\u5ea6\u5668\u4f18\u4e8e\u4e0d\u8003\u8651\u7a7a\u95f2\u65f6\u95f4\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u5728\u51cf\u5c11\u78b3\u6392\u653e\u7684\u540c\u65f6\u63d0\u9ad8\u6a21\u578b\u7cbe\u5ea6\u3002"}}
{"id": "2509.09070", "pdf": "https://arxiv.org/pdf/2509.09070", "abs": "https://arxiv.org/abs/2509.09070", "authors": ["Chaeyun Ko"], "title": "STRIDE: Scalable and Interpretable XAI via Subset-Free Functional Decomposition", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "10 pages, 2 figures", "summary": "Most explainable AI (XAI) frameworks face two practical limitations: the\nexponential cost of reasoning over feature subsets and the reduced\nexpressiveness of summarizing effects as single scalar values. We present\nSTRIDE, a scalable framework that aims to mitigate both issues by framing\nexplanation as a subset-enumeration-free, orthogonal functional decomposition\nin a Reproducing Kernel Hilbert Space (RKHS). Rather than focusing only on\nscalar attributions, STRIDE computes functional components f_S(x_S) via an\nanalytical projection scheme based on a recursive kernel-centering procedure,\navoiding explicit subset enumeration. In the tabular setups we study, the\napproach is model-agnostic, provides both local and global views, and is\nsupported by theoretical results on orthogonality and L^2 convergence under\nstated assumptions. On public tabular benchmarks in our environment, we\nobserved speedups ranging from 0.6 times (slower than TreeSHAP on a small\ndataset) to 9.7 times (California), with a median approximate 3.0 times across\n10 datasets, while maintaining high fidelity (R^2 between 0.81 and 0.999) and\nsubstantial rank agreement on most datasets. Overall, STRIDE complements scalar\nattribution methods by offering a structured functional perspective, enabling\nnovel diagnostics like 'component surgery' to quantitatively measure the impact\nof specific interactions within our experimental scope.", "AI": {"tldr": "\u63d0\u51faSTRIDE\u6846\u67b6\uff0c\u901a\u8fc7RKHS\u4e2d\u7684\u6b63\u4ea4\u529f\u80fd\u5206\u89e3\u7f13\u89e3XAI\u6846\u67b6\u7684\u4e24\u4e2a\u95ee\u9898\uff0c\u5728\u8868\u683c\u6570\u636e\u4e0a\u6709\u901f\u5ea6\u63d0\u5347\u548c\u9ad8\u4fdd\u771f\u5ea6\u3002", "motivation": "\u89e3\u51b3\u5927\u591a\u6570\u53ef\u89e3\u91caAI\u6846\u67b6\u63a8\u7406\u6210\u672c\u9ad8\u548c\u8868\u8fbe\u529b\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u5c06\u89e3\u91ca\u6784\u5efa\u4e3aRKHS\u4e2d\u65e0\u5b50\u96c6\u679a\u4e3e\u7684\u6b63\u4ea4\u529f\u80fd\u5206\u89e3\uff0c\u901a\u8fc7\u9012\u5f52\u6838\u4e2d\u5fc3\u7a0b\u5e8f\u7684\u5206\u6790\u6295\u5f71\u65b9\u6848\u8ba1\u7b97\u529f\u80fd\u7ec4\u4ef6\u3002", "result": "\u5728\u516c\u5171\u8868\u683c\u57fa\u51c6\u4e0a\u901f\u5ea6\u63d0\u53470.6 - 9.7\u500d\uff0c\u4e2d\u4f4d\u6570\u7ea63.0\u500d\uff0c\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\uff08R^2\u57280.81 - 0.999 \uff09\u548c\u8f83\u9ad8\u6392\u540d\u4e00\u81f4\u6027\u3002", "conclusion": "STRIDE\u4ee5\u7ed3\u6784\u5316\u529f\u80fd\u89c6\u89d2\u8865\u5145\u6807\u91cf\u5f52\u56e0\u65b9\u6cd5\uff0c\u53ef\u8fdb\u884c\u65b0\u8bca\u65ad\u3002"}}
{"id": "2509.08971", "pdf": "https://arxiv.org/pdf/2509.08971", "abs": "https://arxiv.org/abs/2509.08971", "authors": ["Julien Loiseau", "Hyun Lim", "Andr\u00e9s Yag\u00fce L\u00f3pez", "Mammadbaghir Baghirzade", "Shihab Shahriar Khan", "Yoonsoo Kim", "Sudarshan Neopane", "Alexander Strack", "Farhana Taiyebah", "Benjamin K. Bergen"], "title": "HARD: A Performance Portable Radiation Hydrodynamics Code based on FleCSI Framework", "categories": ["physics.comp-ph", "astro-ph.IM", "cs.DC"], "comment": "15 pages, 8 figures", "summary": "Hydrodynamics And Radiation Diffusion} (HARD) is an open-source application\nfor high-performance simulations of compressible hydrodynamics with\nradiation-diffusion coupling. Built on the FleCSI (Flexible Computational\nScience Infrastructure) framework, HARD expresses its computational units as\ntasks whose execution can be orchestrated by multiple back-end runtimes,\nincluding Legion, MPI, and HPX. Node-level parallelism is delegated to Kokkos,\nproviding a single, portable code base that runs efficiently on laptops, small\nhomogeneous clusters, and the largest heterogeneous supercomputers currently\navailable. To ensure scientific reliability, HARD includes a regression-test\nsuite that automatically reproduces canonical verification problems such as the\nSod and LeBlanc shock tubes and the Sedov blast wave, comparing numerical\nsolutions against known analytical results. The project is distributed under an\nOSI-approved license, hosted on GitHub, and accompanied by reproducible build\nscripts and continuous integration workflows. This combination of performance\nportability, verification infrastructure, and community-focused development\nmakes HARD a sustainable platform for advancing radiation hydrodynamics\nresearch across multiple domains.", "AI": {"tldr": "HARD\u662f\u7528\u4e8e\u8f90\u5c04\u6269\u6563\u8026\u5408\u53ef\u538b\u7f29\u6d41\u4f53\u52a8\u529b\u5b66\u9ad8\u6027\u80fd\u6a21\u62df\u7684\u5f00\u6e90\u5e94\u7528\uff0c\u6709\u6027\u80fd\u53ef\u79fb\u690d\u6027\u3001\u9a8c\u8bc1\u57fa\u7840\u8bbe\u65bd\u548c\u793e\u533a\u5f00\u53d1\u7279\u70b9\uff0c\u662f\u63a8\u8fdb\u7814\u7a76\u7684\u53ef\u6301\u7eed\u5e73\u53f0\u3002", "motivation": "\u4e3a\u8f90\u5c04\u6d41\u4f53\u52a8\u529b\u5b66\u7814\u7a76\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6301\u7eed\u3001\u9ad8\u6027\u80fd\u4e14\u53ef\u9760\u7684\u6a21\u62df\u5e73\u53f0\u3002", "method": "\u57fa\u4e8eFleCSI\u6846\u67b6\uff0c\u5c06\u8ba1\u7b97\u5355\u5143\u8868\u793a\u4e3a\u4efb\u52a1\uff0c\u7531\u591a\u4e2a\u540e\u7aef\u8fd0\u884c\u65f6\u7f16\u6392\u6267\u884c\uff0c\u8282\u70b9\u7ea7\u5e76\u884c\u59d4\u6258\u7ed9Kokkos\uff0c\u5305\u542b\u56de\u5f52\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u80fd\u5728\u591a\u79cd\u8bbe\u5907\u4e0a\u9ad8\u6548\u8fd0\u884c\uff0c\u53ef\u81ea\u52a8\u91cd\u73b0\u7ecf\u5178\u9a8c\u8bc1\u95ee\u9898\u5e76\u5bf9\u6bd4\u5206\u6790\u7ed3\u679c\uff0c\u6709\u53ef\u590d\u73b0\u6784\u5efa\u811a\u672c\u548c\u6301\u7eed\u96c6\u6210\u5de5\u4f5c\u6d41\u3002", "conclusion": "HARD\u7684\u6027\u80fd\u53ef\u79fb\u690d\u6027\u3001\u9a8c\u8bc1\u57fa\u7840\u8bbe\u65bd\u548c\u793e\u533a\u5f00\u53d1\u7279\u70b9\u4f7f\u5176\u6210\u4e3a\u8de8\u591a\u9886\u57df\u63a8\u8fdb\u8f90\u5c04\u6d41\u4f53\u52a8\u529b\u5b66\u7814\u7a76\u7684\u53ef\u6301\u7eed\u5e73\u53f0\u3002"}}
{"id": "2509.09651", "pdf": "https://arxiv.org/pdf/2509.09651", "abs": "https://arxiv.org/abs/2509.09651", "authors": ["Zakaria El Kassimi", "Fares Fourati", "Mohamed-Slim Alouini"], "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "eess.SP"], "comment": null, "summary": "We study question answering in the domain of radio regulations, a legally\nsensitive and high-stakes area. We propose a telecom-specific\nRetrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge,\nthe first multiple-choice evaluation set for this domain, constructed from\nauthoritative sources using automated filtering and human validation. To assess\nretrieval quality, we define a domain-specific retrieval metric, under which\nour retriever achieves approximately 97% accuracy. Beyond retrieval, our\napproach consistently improves generation accuracy across all tested models. In\nparticular, while naively inserting documents without structured retrieval\nyields only marginal gains for GPT-4o (less than 1%), applying our pipeline\nresults in nearly a 12% relative improvement. These findings demonstrate that\ncarefully targeted grounding provides a simple yet strong baseline and an\neffective domain-specific solution for regulatory question answering. All code\nand evaluation scripts, along with our derived question-answer dataset, are\navailable at https://github.com/Zakaria010/Radio-RAG.", "AI": {"tldr": "\u7814\u7a76\u65e0\u7ebf\u7535\u6cd5\u89c4\u9886\u57df\u95ee\u7b54\uff0c\u63d0\u51fa\u7279\u5b9aRAG\u7ba1\u9053\u548c\u8bc4\u4f30\u96c6\uff0c\u5b9a\u4e49\u68c0\u7d22\u6307\u6807\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u5347\u68c0\u7d22\u548c\u751f\u6210\u51c6\u786e\u7387\uff0c\u4ee3\u7801\u7b49\u516c\u5f00\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u7535\u6cd5\u89c4\u8fd9\u4e00\u6cd5\u5f8b\u654f\u611f\u4e14\u9ad8\u98ce\u9669\u9886\u57df\u7684\u95ee\u7b54\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7535\u4fe1\u7279\u5b9a\u7684RAG\u7ba1\u9053\uff0c\u6784\u5efa\u8be5\u9886\u57df\u9996\u4e2a\u9009\u62e9\u9898\u8bc4\u4f30\u96c6\uff0c\u5b9a\u4e49\u9886\u57df\u7279\u5b9a\u68c0\u7d22\u6307\u6807\u3002", "result": "\u68c0\u7d22\u5668\u51c6\u786e\u7387\u7ea697%\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u751f\u6210\u51c6\u786e\u7387\uff0c\u5982\u4f7fGPT - 4o\u76f8\u5bf9\u63d0\u5347\u8fd112%\u3002", "conclusion": "\u7cbe\u5fc3\u5b9a\u4f4d\u7684\u57fa\u7840\u65b9\u6cd5\u4e3a\u6cd5\u89c4\u95ee\u7b54\u63d0\u4f9b\u7b80\u5355\u6709\u6548\u7684\u7279\u5b9a\u9886\u57df\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09127", "pdf": "https://arxiv.org/pdf/2509.09127", "abs": "https://arxiv.org/abs/2509.09127", "authors": ["Khashayar Namdar", "Pin-Chien Wang", "Tushar Raju", "Steven Zheng", "Fiona Li", "Safwat Tahmin Khan"], "title": "Anti-Money Laundering Machine Learning Pipelines; A Technical Analysis on Identifying High-risk Bank Clients with Supervised Learning", "categories": ["cs.AI"], "comment": null, "summary": "Anti-money laundering (AML) actions and measurements are among the priorities\nof financial institutions, for which machine learning (ML) has shown to have a\nhigh potential. In this paper, we propose a comprehensive and systematic\napproach for developing ML pipelines to identify high-risk bank clients in a\ndataset curated for Task 1 of the University of Toronto 2023-2024 Institute for\nManagement and Innovation (IMI) Big Data and Artificial Intelligence\nCompetition. The dataset included 195,789 customer IDs, and we employed a\n16-step design and statistical analysis to ensure the final pipeline was\nrobust. We also framed the data in a SQLite database, developed SQL-based\nfeature engineering algorithms, connected our pre-trained model to the\ndatabase, and made it inference-ready, and provided explainable artificial\nintelligence (XAI) modules to derive feature importance. Our pipeline achieved\na mean area under the receiver operating characteristic curve (AUROC) of 0.961\nwith a standard deviation (SD) of 0.005. The proposed pipeline achieved second\nplace in the competition.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u9ad8\u98ce\u9669\u94f6\u884c\u5ba2\u6237\uff0c\u5728\u7ade\u8d5b\u6570\u636e\u96c6\u4e0a\u53d6\u5f97AUROC\u4e3a0.961\u7684\u7ed3\u679c\u5e76\u83b7\u7ade\u8d5b\u7b2c\u4e8c\u540d\u3002", "motivation": "\u53cd\u6d17\u94b1\u662f\u91d1\u878d\u673a\u6784\u4f18\u5148\u4e8b\u9879\uff0c\u673a\u5668\u5b66\u4e60\u5728\u6b64\u6709\u9ad8\u6f5c\u529b\uff0c\u8981\u5728\u7ade\u8d5b\u4e2d\u8bc6\u522b\u9ad8\u98ce\u9669\u94f6\u884c\u5ba2\u6237\u3002", "method": "\u91c7\u752816\u6b65\u8bbe\u8ba1\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u5c06\u6570\u636e\u5b58\u5165SQLite\u6570\u636e\u5e93\uff0c\u5f00\u53d1\u57fa\u4e8eSQL\u7684\u7279\u5f81\u5de5\u7a0b\u7b97\u6cd5\uff0c\u8fde\u63a5\u9884\u8bad\u7ec3\u6a21\u578b\u5e76\u4f7f\u5176\u53ef\u63a8\u7406\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u6a21\u5757\u3002", "result": "\u7ba1\u9053\u7684\u63a5\u6536\u5668\u64cd\u4f5c\u7279\u5f81\u66f2\u7ebf\u4e0b\u5e73\u5747\u9762\u79ef\uff08AUROC\uff09\u4e3a0.961\uff0c\u6807\u51c6\u5dee\u4e3a0.005\uff0c\u5728\u7ade\u8d5b\u4e2d\u83b7\u7b2c\u4e8c\u540d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u8f83\u597d\u8bc6\u522b\u9ad8\u98ce\u9669\u94f6\u884c\u5ba2\u6237\u3002"}}
{"id": "2509.09194", "pdf": "https://arxiv.org/pdf/2509.09194", "abs": "https://arxiv.org/abs/2509.09194", "authors": ["Ayelet Berzack", "Guy Katz"], "title": "On Integrating Large Language Models and Scenario-Based Programming for Improving Software Reliability", "categories": ["cs.SE", "cs.AI", "68N19"], "comment": null, "summary": "Large Language Models (LLMs) are fast becoming indispensable tools for\nsoftware developers, assisting or even partnering with them in crafting complex\nprograms. The advantages are evident -- LLMs can significantly reduce\ndevelopment time, generate well-organized and comprehensible code, and\noccasionally suggest innovative ideas that developers might not conceive on\ntheir own. However, despite their strengths, LLMs will often introduce\nsignificant errors and present incorrect code with persuasive confidence,\npotentially misleading developers into accepting flawed solutions.\n  In order to bring LLMs into the software development cycle in a more reliable\nmanner, we propose a methodology for combining them with ``traditional''\nsoftware engineering techniques in a structured way, with the goal of\nstreamlining the development process, reducing errors, and enabling users to\nverify crucial program properties with increased confidence. Specifically, we\nfocus on the Scenario-Based Programming (SBP) paradigm -- an event-driven,\nscenario-based approach for software engineering -- to allow human developers\nto pour their expert knowledge into the LLM, as well as to inspect and verify\nits outputs.\n  To evaluate our methodology, we conducted a significant case study, and used\nit to design and implement the Connect4 game. By combining LLMs and SBP we were\nable to create a highly-capable agent, which could defeat various strong\nexisting agents. Further, in some cases, we were able to formally verify the\ncorrectness of our agent. Finally, our experience reveals interesting insights\nregarding the ease-of-use of our proposed approach. The full code of our\ncase-study will be made publicly available with the final version of this\npaper.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u6280\u672f\u7ed3\u5408\u7528\u4e8e\u8f6f\u4ef6\u5f00\u53d1\uff0c\u4ee5\u51cf\u5c11\u9519\u8bef\u5e76\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u901a\u8fc7Connect4\u6e38\u620f\u6848\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "LLMs\u867d\u80fd\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\uff0c\u4f46\u5e38\u5f15\u5165\u91cd\u5927\u9519\u8bef\uff0c\u9700\u627e\u5230\u66f4\u53ef\u9760\u7684\u65b9\u5f0f\u5c06\u5176\u878d\u5165\u8f6f\u4ef6\u5f00\u53d1\u5468\u671f\u3002", "method": "\u63d0\u51fa\u5c06LLMs\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u6280\u672f\u7ed3\u6784\u5316\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u805a\u7126\u573a\u666f\u7f16\u7a0b\uff08SBP\uff09\u8303\u5f0f\uff0c\u8ba9\u5f00\u53d1\u8005\u878d\u5165\u4e13\u4e1a\u77e5\u8bc6\u5e76\u68c0\u67e5\u9a8c\u8bc1\u8f93\u51fa\u3002", "result": "\u901a\u8fc7Connect4\u6e38\u620f\u6848\u4f8b\uff0c\u7ed3\u5408LLMs\u548cSBP\u521b\u5efa\u4e86\u9ad8\u6027\u80fd\u667a\u80fd\u4f53\uff0c\u80fd\u51fb\u8d25\u73b0\u6709\u5f3a\u5927\u667a\u80fd\u4f53\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u53ef\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u6613\u7528\u6027\uff0c\u80fd\u6709\u6548\u5c06LLMs\u878d\u5165\u8f6f\u4ef6\u5f00\u53d1\uff0c\u51cf\u5c11\u9519\u8bef\u5e76\u63d0\u9ad8\u53ef\u9760\u6027\u3002"}}
{"id": "2509.08988", "pdf": "https://arxiv.org/pdf/2509.08988", "abs": "https://arxiv.org/abs/2509.08988", "authors": ["Brendan Young", "Brendan Alvey", "Andreas Werbrouck", "Will Murphy", "James Keller", "Mattias J. Young", "Matthew Maschmann"], "title": "Active Learning and Explainable AI for Multi-Objective Optimization of Spin Coated Polymers", "categories": ["cs.LG"], "comment": "8 pages, 7 figures, Presented at 2025 AAAI Spring Symposium Series", "summary": "Spin coating polymer thin films to achieve specific mechanical properties is\ninherently a multi-objective optimization problem. We present a framework that\nintegrates an active Pareto front learning algorithm (PyePAL) with\nvisualization and explainable AI techniques to optimize processing parameters.\nPyePAL uses Gaussian process models to predict objective values (hardness and\nelasticity) from the design variables (spin speed, dilution, and polymer\nmixture), guiding the adaptive selection of samples toward promising regions of\nthe design space. To enable interpretable insights into the high-dimensional\ndesign space, we utilize UMAP (Uniform Manifold Approximation and Projection)\nfor two-dimensional visualization of the Pareto front exploration.\nAdditionally, we incorporate fuzzy linguistic summaries, which translate the\nlearned relationships between process parameters and performance objectives\ninto linguistic statements, thus enhancing the explainability and understanding\nof the optimization results. Experimental results demonstrate that our method\nefficiently identifies promising polymer designs, while the visual and\nlinguistic explanations facilitate expert-driven analysis and knowledge\ndiscovery.", "AI": {"tldr": "\u63d0\u51fa\u96c6\u6210\u4e3b\u52a8Pareto\u524d\u6cbf\u5b66\u4e60\u7b97\u6cd5\u4e0e\u53ef\u89c6\u5316\u548c\u53ef\u89e3\u91caAI\u6280\u672f\u7684\u6846\u67b6\u4f18\u5316\u805a\u5408\u7269\u65cb\u6d82\u8584\u819c\u52a0\u5de5\u53c2\u6570\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u4e14\u89e3\u91ca\u6027\u597d\u3002", "motivation": "\u65cb\u6d82\u805a\u5408\u7269\u8584\u819c\u5b9e\u73b0\u7279\u5b9a\u673a\u68b0\u6027\u80fd\u662f\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u9700\u6709\u6548\u4f18\u5316\u52a0\u5de5\u53c2\u6570\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u4e3b\u52a8Pareto\u524d\u6cbf\u5b66\u4e60\u7b97\u6cd5PyePAL\u4e0e\u53ef\u89c6\u5316\u548c\u53ef\u89e3\u91caAI\u6280\u672f\u7ed3\u5408\uff0c\u7528\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u9884\u6d4b\u76ee\u6807\u503c\uff0cUMAP\u53ef\u89c6\u5316\uff0c\u7ed3\u5408\u6a21\u7cca\u8bed\u8a00\u603b\u7ed3\u3002", "result": "\u80fd\u6709\u6548\u8bc6\u522b\u6709\u524d\u666f\u7684\u805a\u5408\u7269\u8bbe\u8ba1\uff0c\u53ef\u89c6\u5316\u548c\u8bed\u8a00\u89e3\u91ca\u4fbf\u4e8e\u4e13\u5bb6\u5206\u6790\u548c\u77e5\u8bc6\u53d1\u73b0\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u53ef\u9ad8\u6548\u4f18\u5316\u805a\u5408\u7269\u8584\u819c\u52a0\u5de5\u53c2\u6570\uff0c\u53ef\u89c6\u5316\u548c\u8bed\u8a00\u89e3\u91ca\u589e\u5f3a\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.09362", "pdf": "https://arxiv.org/pdf/2509.09362", "abs": "https://arxiv.org/abs/2509.09362", "authors": ["Hanfei Zhou", "Lei Shi"], "title": "Expressive Power of Deep Networks on Manifolds: Simultaneous Approximation", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "comment": null, "summary": "A key challenge in scientific machine learning is solving partial\ndifferential equations (PDEs) on complex domains, where the curved geometry\ncomplicates the approximation of functions and their derivatives required by\ndifferential operators. This paper establishes the first simultaneous\napproximation theory for deep neural networks on manifolds. We prove that a\nconstant-depth $\\mathrm{ReLU}^{k-1}$ network with bounded weights--a property\nthat plays a crucial role in controlling generalization error--can approximate\nany function in the Sobolev space $\\mathcal{W}_p^{k}(\\mathcal{M}^d)$ to an\nerror of $\\varepsilon$ in the $\\mathcal{W}_p^{s}(\\mathcal{M}^d)$ norm, for\n$k\\geq 3$ and $s<k$, using $\\mathcal{O}(\\varepsilon^{-d/(k-s)})$ nonzero\nparameters, a rate that overcomes the curse of dimensionality by depending only\non the intrinsic dimension $d$. These results readily extend to functions in\nH\\\"older-Zygmund spaces. We complement this result with a matching lower bound,\nproving our construction is nearly optimal by showing the required number of\nparameters matches up to a logarithmic factor. Our proof of the lower bound\nintroduces novel estimates for the Vapnik-Chervonenkis dimension and\npseudo-dimension of the network's high-order derivative classes. These\ncomplexity bounds provide a theoretical cornerstone for learning PDEs on\nmanifolds involving derivatives. Our analysis reveals that the network\narchitecture leverages a sparse structure to efficiently exploit the manifold's\nlow-dimensional geometry.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u6d41\u5f62\u4e0a\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u540c\u65f6\u903c\u8fd1\u7406\u8bba\uff0c\u7ed9\u51fa\u903c\u8fd1\u8bef\u5dee\u548c\u53c2\u6570\u6570\u91cf\u5173\u7cfb\uff0c\u6709\u4e0a\u754c\u548c\u4e0b\u754c\u7ed3\u679c\uff0c\u4e3a\u6d41\u5f62\u4e0a\u5b66\u4e60\u504f\u5fae\u5206\u65b9\u7a0b\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u5728\u590d\u6742\u57df\u4e0a\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u6311\u6218\uff0c\u56e0\u6d41\u5f62\u5f2f\u66f2\u51e0\u4f55\u4f7f\u51fd\u6570\u53ca\u5176\u5bfc\u6570\u903c\u8fd1\u590d\u6742\u3002", "method": "\u8bc1\u660e\u6709\u754c\u6743\u91cd\u7684\u6052\u5b9a\u6df1\u5ea6ReLU^{k - 1}\u7f51\u7edc\u80fd\u903c\u8fd1Sobolev\u7a7a\u95f4\u4e2d\u7684\u51fd\u6570\uff0c\u7ed9\u51fa\u53c2\u6570\u6570\u91cf\uff0c\u8fd8\u7ed9\u51fa\u5339\u914d\u7684\u4e0b\u754c\uff0c\u5f15\u5165\u5bf9\u7f51\u7edc\u9ad8\u9636\u5bfc\u6570\u7c7b\u7684Vapnik - Chervonenkis\u7ef4\u6570\u548c\u4f2a\u7ef4\u6570\u7684\u65b0\u4f30\u8ba1\u3002", "result": "\u7f51\u7edc\u80fd\u4ee5\u7279\u5b9a\u8bef\u5dee\u903c\u8fd1Sobolev\u7a7a\u95f4\u51fd\u6570\uff0c\u53c2\u6570\u6570\u91cf\u514b\u670d\u7ef4\u6570\u707e\u96be\uff0c\u7ed3\u679c\u53ef\u6269\u5c55\u5230H\u00f6lder - Zygmund\u7a7a\u95f4\uff0c\u6784\u9020\u63a5\u8fd1\u6700\u4f18\u3002", "conclusion": "\u590d\u6742\u5ea6\u754c\u9650\u4e3a\u6d41\u5f62\u4e0a\u6d89\u53ca\u5bfc\u6570\u7684\u504f\u5fae\u5206\u65b9\u7a0b\u5b66\u4e60\u63d0\u4f9b\u7406\u8bba\u57fa\u77f3\uff0c\u7f51\u7edc\u67b6\u6784\u5229\u7528\u7a00\u758f\u7ed3\u6784\u6709\u6548\u5229\u7528\u6d41\u5f62\u4f4e\u7ef4\u51e0\u4f55\u3002"}}
{"id": "2509.09534", "pdf": "https://arxiv.org/pdf/2509.09534", "abs": "https://arxiv.org/abs/2509.09534", "authors": ["Sena Ergisi", "Luis Ma\u00dfny", "Rawad Bitar"], "title": "ProDiGy: Proximity- and Dissimilarity-Based Byzantine-Robust Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) emerged as a widely studied paradigm for distributed\nlearning. Despite its many advantages, FL remains vulnerable to adversarial\nattacks, especially under data heterogeneity. We propose a new Byzantine-robust\nFL algorithm called ProDiGy. The key novelty lies in evaluating the client\ngradients using a joint dual scoring system based on the gradients' proximity\nand dissimilarity. We demonstrate through extensive numerical experiments that\nProDiGy outperforms existing defenses in various scenarios. In particular, when\nthe clients' data do not follow an IID distribution, while other defense\nmechanisms fail, ProDiGy maintains strong defense capabilities and model\naccuracy. These findings highlight the effectiveness of a dual perspective\napproach that promotes natural similarity among honest clients while detecting\nsuspicious uniformity as a potential indicator of an attack.", "AI": {"tldr": "\u63d0\u51fa\u6297\u62dc\u5360\u5ead\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5ProDiGy\uff0c\u901a\u8fc7\u8054\u5408\u53cc\u8bc4\u5206\u7cfb\u7edf\u8bc4\u4f30\u5ba2\u6237\u7aef\u68af\u5ea6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u591a\u79cd\u573a\u666f\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u673a\u5236\uff0c\u5c24\u5176\u5728\u975eIID\u6570\u636e\u5206\u5e03\u65f6\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u6613\u53d7\u5bf9\u6297\u653b\u51fb\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u5f02\u6784\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9632\u5fa1\u7b97\u6cd5\u3002", "method": "\u63d0\u51faProDiGy\u7b97\u6cd5\uff0c\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u63a5\u8fd1\u5ea6\u548c\u76f8\u5f02\u6027\u7684\u8054\u5408\u53cc\u8bc4\u5206\u7cfb\u7edf\u8bc4\u4f30\u5ba2\u6237\u7aef\u68af\u5ea6\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\uff0cProDiGy\u5728\u5404\u79cd\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u673a\u5236\uff0c\u5728\u975eIID\u6570\u636e\u5206\u5e03\u65f6\u80fd\u4fdd\u6301\u5f3a\u9632\u5fa1\u80fd\u529b\u548c\u6a21\u578b\u51c6\u786e\u6027\u3002", "conclusion": "\u53cc\u89c6\u89d2\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u4fc3\u8fdb\u8bda\u5b9e\u5ba2\u6237\u7aef\u95f4\u7684\u81ea\u7136\u76f8\u4f3c\u6027\uff0c\u5e76\u68c0\u6d4b\u53ef\u7591\u7684\u4e00\u81f4\u6027\u4ee5\u53d1\u73b0\u653b\u51fb\u3002"}}
{"id": "2509.08829", "pdf": "https://arxiv.org/pdf/2509.08829", "abs": "https://arxiv.org/abs/2509.08829", "authors": ["Chandan Kumar Sah"], "title": "PerFairX: Is There a Balance Between Fairness and Personality in Large Language Model Recommendations?", "categories": ["cs.CY", "cs.AI", "cs.IR"], "comment": "10 pages, 5 figures. Accepted to the Workshop on Multimodal Continual\n  Learning (MCL) at ICCV 2025. @2025 IEEE/CVF International Conference on\n  Computer Vision Workshops (ICCVW), ICCV's 2025", "summary": "The integration of Large Language Models (LLMs) into recommender systems has\nenabled zero-shot, personality-based personalization through prompt-based\ninteractions, offering a new paradigm for user-centric recommendations.\nHowever, incorporating user personality traits via the OCEAN model highlights a\ncritical tension between achieving psychological alignment and ensuring\ndemographic fairness. To address this, we propose PerFairX, a unified\nevaluation framework designed to quantify the trade-offs between\npersonalization and demographic equity in LLM-generated recommendations. Using\nneutral and personality-sensitive prompts across diverse user profiles, we\nbenchmark two state-of-the-art LLMs, ChatGPT and DeepSeek, on movie (MovieLens\n10M) and music (Last.fm 360K) datasets. Our results reveal that\npersonality-aware prompting significantly improves alignment with individual\ntraits but can exacerbate fairness disparities across demographic groups.\nSpecifically, DeepSeek achieves stronger psychological fit but exhibits higher\nsensitivity to prompt variations, while ChatGPT delivers stable yet less\npersonalized outputs. PerFairX provides a principled benchmark to guide the\ndevelopment of LLM-based recommender systems that are both equitable and\npsychologically informed, contributing to the creation of inclusive,\nuser-centric AI applications in continual learning contexts.", "AI": {"tldr": "\u63d0\u51faPerFairX\u6846\u67b6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u7cfb\u7edf\u4e2d\u4e2a\u6027\u5316\u4e0e\u516c\u5e73\u6027\u7684\u6743\u8861\uff0c\u5b9e\u9a8c\u8868\u660e\u4e2a\u6027\u611f\u77e5\u63d0\u793a\u53ef\u63d0\u5347\u5951\u5408\u5ea6\u4f46\u52a0\u5267\u516c\u5e73\u5dee\u5f02\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5165\u63a8\u8350\u7cfb\u7edf\u65f6\uff0c\u901a\u8fc7OCEAN\u6a21\u578b\u5f15\u5165\u7528\u6237\u4e2a\u6027\u7279\u5f81\u4f1a\u51fa\u73b0\u5fc3\u7406\u5951\u5408\u4e0e\u4eba\u53e3\u516c\u5e73\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u9700\u8bc4\u4f30\u6743\u8861\u3002", "method": "\u63d0\u51faPerFairX\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\uff0c\u4f7f\u7528\u4e2d\u6027\u548c\u4e2a\u6027\u654f\u611f\u63d0\u793a\uff0c\u5728\u7535\u5f71\u548c\u97f3\u4e50\u6570\u636e\u96c6\u4e0a\u5bf9ChatGPT\u548cDeepSeek\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4e2a\u6027\u611f\u77e5\u63d0\u793a\u663e\u8457\u63d0\u5347\u4e0e\u4e2a\u4eba\u7279\u5f81\u7684\u5951\u5408\u5ea6\uff0c\u4f46\u4f1a\u52a0\u5267\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u7684\u516c\u5e73\u5dee\u5f02\uff0cDeepSeek\u5fc3\u7406\u5951\u5408\u5ea6\u5f3a\u4f46\u5bf9\u63d0\u793a\u53d8\u5316\u66f4\u654f\u611f\uff0cChatGPT\u8f93\u51fa\u7a33\u5b9a\u4f46\u4e2a\u6027\u5316\u4e0d\u8db3\u3002", "conclusion": "PerFairX\u4e3a\u5f00\u53d1\u516c\u5e73\u4e14\u8003\u8651\u5fc3\u7406\u56e0\u7d20\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u7cfb\u7edf\u63d0\u4f9b\u539f\u5219\u6027\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u521b\u5efa\u6301\u7eed\u5b66\u4e60\u73af\u5883\u4e0b\u7684\u5305\u5bb9\u6027\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u5e94\u7528\u3002"}}
{"id": "2509.09154", "pdf": "https://arxiv.org/pdf/2509.09154", "abs": "https://arxiv.org/abs/2509.09154", "authors": ["Bui Duc Manh", "Soumyaratna Debnath", "Zetong Zhang", "Shriram Damodaran", "Arvind Kumar", "Yueyi Zhang", "Lu Mi", "Erik Cambria", "Lin Wang"], "title": "Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective", "categories": ["cs.AI", "cs.CV"], "comment": "54 pages, journal", "summary": "Recent advances in agentic AI have led to systems capable of autonomous task\nexecution and language-based reasoning, yet their spatial reasoning abilities\nremain limited and underexplored, largely constrained to symbolic and\nsequential processing. In contrast, human spatial intelligence, rooted in\nintegrated multisensory perception, spatial memory, and cognitive maps, enables\nflexible, context-aware decision-making in unstructured environments.\nTherefore, bridging this gap is critical for advancing Agentic Spatial\nIntelligence toward better interaction with the physical 3D world. To this end,\nwe first start from scrutinizing the spatial neural models as studied in\ncomputational neuroscience, and accordingly introduce a novel computational\nframework grounded in neuroscience principles. This framework maps core\nbiological functions to six essential computation modules: bio-inspired\nmultimodal sensing, multi-sensory integration, egocentric-allocentric\nconversion, an artificial cognitive map, spatial memory, and spatial reasoning.\nTogether, these modules form a perspective landscape for agentic spatial\nreasoning capability across both virtual and physical environments. On top, we\nconduct a framework-guided analysis of recent methods, evaluating their\nrelevance to each module and identifying critical gaps that hinder the\ndevelopment of more neuroscience-grounded spatial reasoning modules. We further\nexamine emerging benchmarks and datasets and explore potential application\ndomains ranging from virtual to embodied systems, such as robotics. Finally, we\noutline potential research directions, emphasizing the promising roadmap that\ncan generalize spatial reasoning across dynamic or unstructured environments.\nWe hope this work will benefit the research community with a\nneuroscience-grounded perspective and a structured pathway. Our project page\ncan be found at Github.", "AI": {"tldr": "\u73b0\u6709\u4ee3\u7406AI\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u79d1\u5b66\u539f\u7406\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5206\u6790\u73b0\u6709\u65b9\u6cd5\u3001\u8bc4\u4f30\u57fa\u51c6\u548c\u6570\u636e\u96c6\uff0c\u63a2\u7d22\u5e94\u7528\u9886\u57df\u5e76\u6307\u51fa\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406AI\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u53d7\u9650\uff0c\u591a\u4e3a\u7b26\u53f7\u548c\u987a\u5e8f\u5904\u7406\uff0c\u800c\u4eba\u7c7b\u7a7a\u95f4\u667a\u80fd\u66f4\u7075\u6d3b\uff0c\u9700\u7f29\u5c0f\u5dee\u8ddd\u4ee5\u63d0\u5347\u4e0e3D\u7269\u7406\u4e16\u754c\u7684\u4ea4\u4e92\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8ba1\u7b97\u795e\u7ecf\u79d1\u5b66\u4e2d\u7684\u7a7a\u95f4\u795e\u7ecf\u6a21\u578b\uff0c\u5f15\u5165\u57fa\u4e8e\u795e\u7ecf\u79d1\u5b66\u539f\u7406\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5206\u6790\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc4\u4f30\u57fa\u51c6\u548c\u6570\u636e\u96c6\u3002", "result": "\u5f62\u6210\u8de8\u865a\u62df\u548c\u7269\u7406\u73af\u5883\u7684\u4ee3\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u89c6\u89d2\uff0c\u627e\u51fa\u963b\u788d\u795e\u7ecf\u79d1\u5b66\u7a7a\u95f4\u63a8\u7406\u6a21\u5757\u53d1\u5c55\u7684\u5173\u952e\u5dee\u8ddd\u3002", "conclusion": "\u5f3a\u8c03\u53ef\u5728\u52a8\u6001\u6216\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u63a8\u5e7f\u7a7a\u95f4\u63a8\u7406\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u7814\u7a76\u754c\u63d0\u4f9b\u795e\u7ecf\u79d1\u5b66\u89c6\u89d2\u548c\u7ed3\u6784\u5316\u8def\u5f84\u3002"}}
{"id": "2509.09294", "pdf": "https://arxiv.org/pdf/2509.09294", "abs": "https://arxiv.org/abs/2509.09294", "authors": ["Solal Rapaport", "Laurent Pautet", "Samuel Tardieu", "Stefano Zacchiroli"], "title": "Altered Histories in Version Control System Repositories: Evidence from the Trenches", "categories": ["cs.SE"], "comment": null, "summary": "Version Control Systems (VCS) like Git allow developers to locally rewrite\nrecorded history, e.g., to reorder and suppress commits or specific data in\nthem. These alterations have legitimate use cases, but become problematic when\nperformed on public branches that have downstream users: they break push/pull\nworkflows, challenge the integrity and reproducibility of repositories, and\ncreate opportunities for supply chain attackers to sneak into them nefarious\nchanges. We conduct the first large-scale investigation of Git history\nalterations in public code repositories. We analyze 111 M (millions)\nrepositories archived by Software Heritage, which preserves VCS histories even\nacross alterations. We find history alterations in 1.22 M repositories, for a\ntotal of 8.7 M rewritten histories. We categorize changes by where they happen\n(which repositories, which branches) and what is changed in them (files or\ncommit metadata). Conducting two targeted case studies we show that altered\nhistories recurrently change licenses retroactively, or are used to remove\n''secrets'' (e.g., private keys) committed by mistake. As these behaviors\ncorrespond to bad practices-in terms of project governance or security\nmanagement, respectively-that software recipients might want to avoid, we\nintroduce GitHistorian, an automated tool, that developers can use to spot and\ndescribe history alterations in public Git repositories.", "AI": {"tldr": "\u5bf9\u516c\u5171\u4ee3\u7801\u4ed3\u5e93\u4e2dGit\u5386\u53f2\u8bb0\u5f55\u4fee\u6539\u8fdb\u884c\u5927\u89c4\u6a21\u8c03\u67e5\uff0c\u53d1\u73b0\u5927\u91cf\u4fee\u6539\u60c5\u51b5\uff0c\u4ecb\u7ecd\u68c0\u6d4b\u5de5\u5177GitHistorian\u3002", "motivation": "Git\u5386\u53f2\u4fee\u6539\u5728\u516c\u5171\u5206\u652f\u5b58\u5728\u95ee\u9898\uff0c\u5f71\u54cd\u5de5\u4f5c\u6d41\u3001\u4ed3\u5e93\u5b8c\u6574\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u8fd8\u53ef\u80fd\u88ab\u653b\u51fb\u5229\u7528\uff0c\u56e0\u6b64\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u5206\u6790Software Heritage\u5b58\u6863\u76841.11\u4ebf\u4e2a\u4ed3\u5e93\uff0c\u5bf9\u4fee\u6539\u60c5\u51b5\u5206\u7c7b\uff0c\u5f00\u5c55\u4e24\u4e2a\u9488\u5bf9\u6027\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u5728122\u4e07\u4e2a\u4ed3\u5e93\u4e2d\u53d1\u73b0\u5386\u53f2\u4fee\u6539\uff0c\u5171870\u4e07\u6b21\u91cd\u5199\u5386\u53f2\uff0c\u5e38\u89c1\u4fee\u6539\u5305\u62ec\u8ffd\u6eaf\u66f4\u6539\u8bb8\u53ef\u8bc1\u548c\u79fb\u9664\u8bef\u63d0\u4ea4\u7684\u201c\u79d8\u5bc6\u201d\u3002", "conclusion": "\u5f15\u5165\u81ea\u52a8\u5316\u5de5\u5177GitHistorian\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u53d1\u73b0\u548c\u63cf\u8ff0\u516c\u5171Git\u4ed3\u5e93\u4e2d\u7684\u5386\u53f2\u4fee\u6539\u3002"}}
{"id": "2509.09001", "pdf": "https://arxiv.org/pdf/2509.09001", "abs": "https://arxiv.org/abs/2509.09001", "authors": ["Jingwen Liu", "Hantao Yu", "Clayton Sanford", "Alexandr Andoni", "Daniel Hsu"], "title": "Fast attention mechanisms: a tale of parallelism", "categories": ["cs.LG"], "comment": null, "summary": "Transformers have the representational capacity to simulate Massively\nParallel Computation (MPC) algorithms, but they suffer from quadratic time\ncomplexity, which severely limits their scalability. We introduce an efficient\nattention mechanism called Approximate Nearest Neighbor Attention (ANNA) with\nsub-quadratic time complexity. We prove that ANNA-transformers (1) retain the\nexpressive power previously established for standard attention in terms of\nmatching the capabilities of MPC algorithms, and (2) can solve key reasoning\ntasks such as Match2 and $k$-hop with near-optimal depth. Using the MPC\nframework, we further prove that constant-depth ANNA-transformers can simulate\nconstant-depth low-rank transformers, thereby providing a unified way to reason\nabout a broad class of efficient attention approximations.", "AI": {"tldr": "\u5f15\u5165\u6b21\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u6ce8\u610f\u529b\u673a\u5236ANNA\uff0c\u8bc1\u660e\u5176\u4fdd\u7559\u6807\u51c6\u6ce8\u610f\u529b\u8868\u8fbe\u80fd\u529b\u4e14\u80fd\u89e3\u51b3\u5173\u952e\u63a8\u7406\u4efb\u52a1\uff0c\u8fd8\u53ef\u6a21\u62df\u5e38\u6570\u6df1\u5ea6\u4f4e\u79e9transformers\u3002", "motivation": "Transformer\u65f6\u95f4\u590d\u6742\u5ea6\u4e3a\u4e8c\u6b21\uff0c\u9650\u5236\u53ef\u6269\u5c55\u6027\uff0c\u9700\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\u3002", "method": "\u5f15\u5165\u8fd1\u4f3c\u6700\u8fd1\u90bb\u6ce8\u610f\u529b\u673a\u5236ANNA\u3002", "result": "ANNA - transformers\u4fdd\u7559\u6807\u51c6\u6ce8\u610f\u529b\u8868\u8fbe\u80fd\u529b\uff0c\u80fd\u89e3\u51b3\u5173\u952e\u63a8\u7406\u4efb\u52a1\uff0c\u5e38\u6570\u6df1\u5ea6ANNA - transformers\u53ef\u6a21\u62df\u5e38\u6570\u6df1\u5ea6\u4f4e\u79e9transformers\u3002", "conclusion": "ANNA\u4e3a\u4e00\u5927\u7c7b\u9ad8\u6548\u6ce8\u610f\u529b\u8fd1\u4f3c\u63d0\u4f9b\u7edf\u4e00\u63a8\u7406\u65b9\u5f0f\u3002"}}
{"id": "2509.09653", "pdf": "https://arxiv.org/pdf/2509.09653", "abs": "https://arxiv.org/abs/2509.09653", "authors": ["Yufeng Xin", "Liang Zhang"], "title": "Towards A High-Performance Quantum Data Center Network Architecture", "categories": ["quant-ph", "cs.DC", "cs.NI"], "comment": "IEEE International Conference on Communications 2025 (ICC 2025)", "summary": "Quantum Data Centers (QDCs) are needed to support large-scale quantum\nprocessing for both academic and commercial applications. While large-scale\nquantum computers are constrained by technological and financial barriers, a\nmodular approach that clusters small quantum computers offers an alternative.\nThis approach, however, introduces new challenges in network scalability,\nentanglement generation, and quantum memory management. In this paper, we\npropose a three-layer fat-tree network architecture for QDCs, designed to\naddress these challenges. Our architecture features a unique leaf switch and an\nadvanced swapping spine switch design, optimized to handle high volumes of\nentanglement requests as well as a queue scheduling mechanism that efficiently\nmanages quantum memory to prevent decoherence. Through queuing-theoretical\nmodels and simulations in NetSquid, we demonstrate the proposed architecture's\nscalability and effectiveness in maintaining high entanglement fidelity,\noffering a practical path forward for modular QDC networks.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6a21\u5757\u5316\u91cf\u5b50\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u9762\u4e34\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e09\u5c42\u80d6\u6811\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u7406\u8bba\u6a21\u578b\u548c\u4eff\u771f\u9a8c\u8bc1\u5176\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u91cf\u5b50\u8ba1\u7b97\u673a\u53d7\u6280\u672f\u548c\u8d44\u91d1\u9650\u5236\uff0c\u6a21\u5757\u5316\u65b9\u6848\u867d\u4e3a\u66ff\u4ee3\u65b9\u6cd5\u4f46\u5f15\u5165\u65b0\u6311\u6218\uff0c\u9700\u65b0\u67b6\u6784\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u80d6\u6811\u7f51\u7edc\u67b6\u6784\uff0c\u5305\u62ec\u72ec\u7279\u53f6\u4ea4\u6362\u673a\u548c\u5148\u8fdb\u4ea4\u6362\u6838\u5fc3\u4ea4\u6362\u673a\u8bbe\u8ba1\uff0c\u4ee5\u53ca\u961f\u5217\u8c03\u5ea6\u673a\u5236\uff1b\u901a\u8fc7\u6392\u961f\u7406\u8bba\u6a21\u578b\u548cNetSquid\u4eff\u771f\u3002", "result": "\u6240\u63d0\u67b6\u6784\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u6709\u6548\u4fdd\u6301\u9ad8\u7ea0\u7f20\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u6240\u63d0\u67b6\u6784\u4e3a\u6a21\u5757\u5316\u91cf\u5b50\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.09226", "pdf": "https://arxiv.org/pdf/2509.09226", "abs": "https://arxiv.org/abs/2509.09226", "authors": ["Haipeng Liu", "Ting Long", "Jing Fu"], "title": "Constructing a Question-Answering Simulator through the Distillation of LLMs", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "The question-answering (QA) simulator is a model that mimics real student\nlearning behaviors and predicts their correctness of their responses to\nquestions. QA simulators enable educational recommender systems (ERS) to\ncollect large amounts of training data without interacting with real students,\nthereby preventing harmful recommendations made by an undertrained ERS from\nundermining actual student learning. Given the QA history, there are two\ncategories of solutions to predict the correctness, conducting the simulation:\n(1) LLM-free methods, which apply a traditional sequential model to transfer\nthe QA history into a vector representation first, and make predictions based\non the representation; (2) LLM-based methods, which leverage the domain\nknowledge and reasoning capability of LLM to enhence the prediction. LLM-free\nmethods offer fast inference but generally yield suboptimal performance. In\ncontrast, most LLM-based methods achieve better results, but at the cost of\nslower inference speed and higher GPU memory consumption. In this paper, we\npropose a method named LLM Distillation based Simulator (LDSim), which distills\ndomain knowledge and reasoning capability from an LLM to better assist\nprediction, thereby improving simulation performance. Extensive experiments\ndemonstrate that our LDSim achieves strong results on both the simulation task\nand the knowledge tracing (KT) task. Our code is publicly available at\nhttps://anonymous.4open.science/r/LDSim-05A9.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLLM Distillation based Simulator (LDSim)\u65b9\u6cd5\uff0c\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u6765\u63d0\u5347\u95ee\u7b54\u6a21\u62df\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u77e5\u8bc6\u8ffd\u8e2a\u4efb\u52a1\u4e0a\u6548\u679c\u597d\u3002", "motivation": "\u73b0\u6709\u9884\u6d4b\u5b66\u751f\u56de\u7b54\u6b63\u786e\u6027\u7684\u95ee\u7b54\u6a21\u62df\u5668\u65b9\u6cd5\u4e2d\uff0c\u65e0\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u6027\u80fd\u6b20\u4f73\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u63a8\u7406\u6162\u4e14\u663e\u5b58\u6d88\u8017\u9ad8\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51faLDSim\u65b9\u6cd5\uff0c\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u84b8\u998f\u9886\u57df\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u4ee5\u8f85\u52a9\u9884\u6d4b\u3002", "result": "LDSim\u5728\u6a21\u62df\u4efb\u52a1\u548c\u77e5\u8bc6\u8ffd\u8e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u826f\u597d\u7ed3\u679c\u3002", "conclusion": "LDSim\u662f\u4e00\u79cd\u6709\u6548\u7684\u63d0\u5347\u95ee\u7b54\u6a21\u62df\u6027\u80fd\u7684\u65b9\u6cd5\u3002"}}
{"id": "2509.09210", "pdf": "https://arxiv.org/pdf/2509.09210", "abs": "https://arxiv.org/abs/2509.09210", "authors": ["Xing Gao", "Zherui Huang", "Weiyao Lin", "Xiao Sun"], "title": "ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Accurate motion prediction of surrounding agents is crucial for the safe\nplanning of autonomous vehicles. Recent advancements have extended prediction\ntechniques from individual agents to joint predictions of multiple interacting\nagents, with various strategies to address complex interactions within future\nmotions of agents. However, these methods overlook the evolving nature of these\ninteractions. To address this limitation, we propose a novel progressive\nmulti-scale decoding strategy, termed ProgD, with the help of dynamic\nheterogeneous graph-based scenario modeling. In particular, to explicitly and\ncomprehensively capture the evolving social interactions in future scenarios,\ngiven their inherent uncertainty, we design a progressive modeling of scenarios\nwith dynamic heterogeneous graphs. With the unfolding of such dynamic\nheterogeneous graphs, a factorized architecture is designed to process the\nspatio-temporal dependencies within future scenarios and progressively\neliminate uncertainty in future motions of multiple agents. Furthermore, a\nmulti-scale decoding procedure is incorporated to improve on the future\nscenario modeling and consistent prediction of agents' future motion. The\nproposed ProgD achieves state-of-the-art performance on the INTERACTION\nmulti-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2\nmulti-world forecasting benchmark.", "AI": {"tldr": "\u63d0\u51faProgD\u7b56\u7565\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u9884\u6d4b\u4e2d\u4ea4\u4e92\u6f14\u53d8\u6027\u88ab\u5ffd\u89c6\u95ee\u9898\uff0c\u5728\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u83b7\u6700\u4f18\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u9884\u6d4b\u65b9\u6cd5\u5ffd\u7565\u4ea4\u4e92\u7684\u6f14\u53d8\u6027\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51faProgD\u7b56\u7565\uff0c\u501f\u52a9\u52a8\u6001\u5f02\u8d28\u56fe\u8fdb\u884c\u573a\u666f\u5efa\u6a21\uff0c\u8bbe\u8ba1\u6e10\u8fdb\u5f0f\u573a\u666f\u5efa\u6a21\u3001\u5206\u89e3\u67b6\u6784\u5904\u7406\u65f6\u7a7a\u4f9d\u8d56\uff0c\u91c7\u7528\u591a\u5c3a\u5ea6\u89e3\u7801\u7a0b\u5e8f\u3002", "result": "ProgD\u5728INTERACTION\u548cArgoverse 2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "ProgD\u7b56\u7565\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u80fd\u66f4\u597d\u5730\u8fdb\u884c\u591a\u667a\u80fd\u4f53\u672a\u6765\u8fd0\u52a8\u9884\u6d4b\u3002"}}
{"id": "2509.09313", "pdf": "https://arxiv.org/pdf/2509.09313", "abs": "https://arxiv.org/abs/2509.09313", "authors": ["Moritz Mock", "Thomas Forrer", "Barbara Russo"], "title": "Cross-Domain Evaluation of Transformer-Based Vulnerability Detection on Open & Industry Data", "categories": ["cs.SE"], "comment": "Accepted to the 26th International Conference on Product-Focused\n  Software Process Improvement (PROFES 2025)", "summary": "Deep learning solutions for vulnerability detection proposed in academic\nresearch are not always accessible to developers, and their applicability in\nindustrial settings is rarely addressed. Transferring such technologies from\nacademia to industry presents challenges related to trustworthiness, legacy\nsystems, limited digital literacy, and the gap between academic and industrial\nexpertise. For deep learning in particular, performance and integration into\nexisting workflows are additional concerns. In this work, we first evaluate the\nperformance of CodeBERT for detecting vulnerable functions in industrial and\nopen-source software. We analyse its cross-domain generalisation when\nfine-tuned on open-source data and tested on industrial data, and vice versa,\nalso exploring strategies for handling class imbalance. Based on these results,\nwe develop AI-DO(Automating vulnerability detection Integration for Developers'\nOperations), a Continuous Integration-Continuous Deployment (CI/CD)-integrated\nrecommender system that uses fine-tuned CodeBERT to detect and localise\nvulnerabilities during code review without disrupting workflows. Finally, we\nassess the tool's perceived usefulness through a survey with the company's IT\nprofessionals. Our results show that models trained on industrial data detect\nvulnerabilities accurately within the same domain but lose performance on\nopen-source code, while a deep learner fine-tuned on open data, with\nappropriate undersampling techniques, improves the detection of\nvulnerabilities.", "AI": {"tldr": "\u8bc4\u4f30CodeBERT\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\uff0c\u5f00\u53d1\u96c6\u6210CI/CD\u7684\u63a8\u8350\u7cfb\u7edfAI - DO\u5e76\u8c03\u67e5\u5176\u6709\u7528\u6027\uff0c\u53d1\u73b0\u4e0d\u540c\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u7684\u68c0\u6d4b\u6548\u679c\u5dee\u5f02\u3002", "motivation": "\u5b66\u672f\u7814\u7a76\u7684\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6848\u96be\u5e94\u7528\u4e8e\u5de5\u4e1a\u73af\u5883\uff0c\u9700\u89e3\u51b3\u6280\u672f\u4ece\u5b66\u672f\u5230\u5de5\u4e1a\u8f6c\u79fb\u7684\u6311\u6218\u3002", "method": "\u8bc4\u4f30CodeBERT\u6027\u80fd\uff0c\u5206\u6790\u5176\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u53ca\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u7b56\u7565\uff0c\u5f00\u53d1AI - DO\u7cfb\u7edf\uff0c\u901a\u8fc7\u8c03\u67e5\u8bc4\u4f30\u5176\u6709\u7528\u6027\u3002", "result": "\u5de5\u4e1a\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u540c\u57df\u68c0\u6d4b\u51c6\u786e\uff0c\u5f00\u6e90\u6570\u636e\u5fae\u8c03\u7684\u6a21\u578b\u914d\u5408\u6b20\u91c7\u6837\u6280\u672f\u53ef\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4e0d\u5e72\u6270\u5de5\u4f5c\u6d41\u7a0b\u4e0b\u68c0\u6d4b\u548c\u5b9a\u4f4d\u6f0f\u6d1e\uff0c\u4e0d\u540c\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u6709\u4e0d\u540c\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2509.09009", "pdf": "https://arxiv.org/pdf/2509.09009", "abs": "https://arxiv.org/abs/2509.09009", "authors": ["Marianna Nezhurina", "Taishi Nakamura", "Timur Carstensen", "Niccol\u00f2 Ajroldi", "Ville Komulainen", "David Salinas", "Jenia Jitsev"], "title": "Open-sci-ref-0.01: open and reproducible reference baselines for language model and dataset comparison", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Model weights and intermediate checkpoints are available at\n  \\url{https://huggingface.co/collections/open-sci/open-sci-ref-001-685905e598be658fbcebff4f};\n  code for reproducing training, evaluation and raw experiments data at\n  \\url{https://github.com/LAION-AI/open-sci-ref-0.01}", "summary": "We introduce open-sci-ref, a family of dense transformer models trained as\nresearch baselines across multiple model (0.13B to 1.7B parameters) and token\nscales (up to 1T) on 8 recent open reference datasets. Evaluating the models on\nvarious standardized benchmarks, our training runs set establishes reference\npoints that enable researchers to assess the sanity and quality of alternative\ntraining approaches across scales and datasets. Intermediate checkpoints allow\ncomparison and studying of the training dynamics. The established reference\nbaselines allow training procedures to be compared through their scaling\ntrends, aligning them on a common compute axis. Comparison of open reference\ndatasets reveals that training on NemoTron-CC HQ consistently outperforms other\nreference datasets, followed by DCLM-baseline and FineWeb-Edu. In addition to\nintermediate training checkpoints, the release includes logs, code, and\ndownstream evaluations to simplify reproduction, standardize comparison, and\nfacilitate future research.", "AI": {"tldr": "\u4ecb\u7ecdopen - sci - ref\u7cfb\u5217\u5bc6\u96c6\u53d8\u538b\u5668\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u89c4\u6a21\u548c\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5efa\u7acb\u53c2\u8003\u70b9\uff0c\u5bf9\u6bd4\u4e0d\u540c\u6570\u636e\u96c6\u8868\u73b0\uff0c\u53d1\u5e03\u76f8\u5173\u5185\u5bb9\u4fc3\u8fdb\u7814\u7a76\u3002", "motivation": "\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u8de8\u89c4\u6a21\u548c\u6570\u636e\u96c6\u8bc4\u4f30\u66ff\u4ee3\u8bad\u7ec3\u65b9\u6cd5\u5408\u7406\u6027\u548c\u8d28\u91cf\u7684\u53c2\u8003\u3002", "method": "\u57288\u4e2a\u8fd1\u671f\u5f00\u653e\u53c2\u8003\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u4e0d\u540c\u53c2\u6570\u548ctoken\u89c4\u6a21\u7684open - sci - ref\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5728\u5404\u79cd\u6807\u51c6\u5316\u57fa\u51c6\u4e0a\u8bc4\u4f30\u3002", "result": "\u8bad\u7ec3\u8fd0\u884c\u96c6\u5efa\u7acb\u53c2\u8003\u70b9\uff0c\u5bf9\u6bd4\u663e\u793a\u5728NemoTron - CC HQ\u4e0a\u8bad\u7ec3\u8868\u73b0\u6700\u4f73\uff0c\u5176\u6b21\u662fDCLM - baseline\u548cFineWeb - Edu\u3002", "conclusion": "\u5efa\u7acb\u7684\u53c2\u8003\u57fa\u7ebf\u53ef\u901a\u8fc7\u7f29\u653e\u8d8b\u52bf\u6bd4\u8f83\u8bad\u7ec3\u7a0b\u5e8f\uff0c\u53d1\u5e03\u7684\u5185\u5bb9\u6709\u52a9\u4e8e\u7b80\u5316\u91cd\u73b0\u3001\u6807\u51c6\u5316\u6bd4\u8f83\u548c\u63a8\u52a8\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2509.09215", "pdf": "https://arxiv.org/pdf/2509.09215", "abs": "https://arxiv.org/abs/2509.09215", "authors": ["Qinnan Hu", "Yuntao Wang", "Yuan Gao", "Zhou Su", "Linkang Du"], "title": "Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions", "categories": ["cs.AI", "cs.CR"], "comment": "7 pages, 6 figures", "summary": "Large language models (LLMs)-empowered autonomous agents are transforming\nboth digital and physical environments by enabling adaptive, multi-agent\ncollaboration. While these agents offer significant opportunities across\ndomains such as finance, healthcare, and smart manufacturing, their\nunpredictable behaviors and heterogeneous capabilities pose substantial\ngovernance and accountability challenges. In this paper, we propose a\nblockchain-enabled layered architecture for regulatory agent collaboration,\ncomprising an agent layer, a blockchain data layer, and a regulatory\napplication layer. Within this framework, we design three key modules: (i) an\nagent behavior tracing and arbitration module for automated accountability,\n(ii) a dynamic reputation evaluation module for trust assessment in\ncollaborative scenarios, and (iii) a malicious behavior forecasting module for\nearly detection of adversarial activities. Our approach establishes a\nsystematic foundation for trustworthy, resilient, and scalable regulatory\nmechanisms in large-scale agent ecosystems. Finally, we discuss the future\nresearch directions for blockchain-enabled regulatory frameworks in multi-agent\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u533a\u5757\u94fe\u8d4b\u80fd\u7684\u5206\u5c42\u67b6\u6784\u7528\u4e8e\u76d1\u7ba1\u4ee3\u7406\u534f\u4f5c\uff0c\u8bbe\u8ba1\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff0c\u4e3a\u5927\u89c4\u6a21\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u76d1\u7ba1\u673a\u5236\u5960\u5b9a\u57fa\u7840\u5e76\u63a2\u8ba8\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u8d4b\u80fd\u7684\u81ea\u4e3b\u4ee3\u7406\u867d\u6709\u8bf8\u591a\u673a\u9047\uff0c\u4f46\u4e0d\u53ef\u9884\u6d4b\u884c\u4e3a\u548c\u5f02\u6784\u80fd\u529b\u5e26\u6765\u6cbb\u7406\u4e0e\u95ee\u8d23\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4ee3\u7406\u5c42\u3001\u533a\u5757\u94fe\u6570\u636e\u5c42\u548c\u76d1\u7ba1\u5e94\u7528\u5c42\u7684\u5206\u5c42\u67b6\u6784\uff0c\u8bbe\u8ba1\u884c\u4e3a\u8ffd\u8e2a\u4ef2\u88c1\u3001\u52a8\u6001\u58f0\u8a89\u8bc4\u4f30\u548c\u6076\u610f\u884c\u4e3a\u9884\u6d4b\u4e09\u4e2a\u5173\u952e\u6a21\u5757\u3002", "result": "\u4e3a\u5927\u89c4\u6a21\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u4e2d\u53ef\u4fe1\u8d56\u3001\u6709\u97e7\u6027\u548c\u53ef\u6269\u5c55\u7684\u76d1\u7ba1\u673a\u5236\u5efa\u7acb\u4e86\u7cfb\u7edf\u57fa\u7840\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u533a\u5757\u94fe\u8d4b\u80fd\u76d1\u7ba1\u6846\u67b6\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2509.09322", "pdf": "https://arxiv.org/pdf/2509.09322", "abs": "https://arxiv.org/abs/2509.09322", "authors": ["Jacopo Bufalino", "Agathe Blaise", "Stefano Secci"], "title": "ORCA: Unveiling Obscure Containers In The Wild", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Modern software development increasingly depends on open-source libraries and\nthird-party components, which are often encapsulated into containerized\nenvironments. While improving the development and deployment of applications,\nthis approach introduces security risks, particularly when outdated or\nvulnerable components are inadvertently included in production environments.\nSoftware Composition Analysis (SCA) is a critical process that helps identify\nand manage packages and dependencies inside a container. However, unintentional\nmodifications to the container filesystem can lead to incomplete container\nimages, which compromise the reliability of SCA tools. In this paper, we\nexamine the limitations of both cloud-based and open-source SCA tools when\nfaced with such obscure images. An analysis of 600 popular containers revealed\nthat obscure containers exist in well-known registries and trusted images and\nthat many tools fail to analyze such containers. To mitigate these issues, we\npropose an obscuration-resilient methodology for container analysis and\nintroduce ORCA (Obscuration-Resilient Container Analyzer), its open-source\nimplementation. We reported our findings to all vendors using their appropriate\nchannels. Our results demonstrate that ORCA effectively detects the content of\nobscure containers and achieves a median 40% improvement in file coverage\ncompared to Docker Scout and Syft.", "AI": {"tldr": "\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4f9d\u8d56\u5f00\u6e90\u5e93\u548c\u7b2c\u4e09\u65b9\u7ec4\u4ef6\uff0c\u5bb9\u5668\u5316\u5e26\u6765\u5b89\u5168\u98ce\u9669\uff0cSCA \u5de5\u5177\u9762\u4e34\u4e0d\u5b8c\u6574\u5bb9\u5668\u56fe\u50cf\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa ORCA \u65b9\u6cd5\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u5bb9\u5668\u5316\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u56e0\u5bb9\u5668\u6587\u4ef6\u7cfb\u7edf\u65e0\u610f\u4fee\u6539\u5bfc\u81f4\u4e0d\u5b8c\u6574\u5bb9\u5668\u56fe\u50cf\uff0c\u5f71\u54cd SCA \u5de5\u5177\u53ef\u9760\u6027\u7684\u95ee\u9898\u3002", "method": "\u5206\u6790 600 \u4e2a\u6d41\u884c\u5bb9\u5668\uff0c\u63d0\u51fa\u6297\u6a21\u7cca\u7684\u5bb9\u5668\u5206\u6790\u65b9\u6cd5 ORCA \u5e76\u5b9e\u73b0\u5f00\u6e90\u7248\u672c\u3002", "result": "\u53d1\u73b0\u77e5\u540d\u6ce8\u518c\u8868\u548c\u53ef\u4fe1\u955c\u50cf\u4e2d\u5b58\u5728\u6a21\u7cca\u5bb9\u5668\uff0c\u5f88\u591a\u5de5\u5177\u65e0\u6cd5\u5206\u6790\uff1bORCA \u80fd\u6709\u6548\u68c0\u6d4b\u6a21\u7cca\u5bb9\u5668\u5185\u5bb9\uff0c\u6587\u4ef6\u8986\u76d6\u7387\u6bd4 Docker Scout \u548c Syft \u4e2d\u4f4d\u6570\u63d0\u9ad8 40%\u3002", "conclusion": "ORCA \u53ef\u6709\u6548\u89e3\u51b3\u73b0\u6709 SCA \u5de5\u5177\u5728\u5904\u7406\u6a21\u7cca\u5bb9\u5668\u65f6\u7684\u5c40\u9650\uff0c\u63d0\u5347\u5bb9\u5668\u5206\u6790\u6548\u679c\u3002"}}
{"id": "2509.09030", "pdf": "https://arxiv.org/pdf/2509.09030", "abs": "https://arxiv.org/abs/2509.09030", "authors": ["Spencer King", "Zhilu Zhang", "Ruofan Yu", "Baris Coskun", "Wei Ding", "Qian Cui"], "title": "Deep Context-Conditioned Anomaly Detection for Tabular Data", "categories": ["cs.LG"], "comment": "Submitted to WSDM 2026. 11 pages, 4 figures, 5 tables, 1 algorithm, 8\n  datasets, contextual anomaly detection framework for tabular data", "summary": "Anomaly detection is critical in domains such as cybersecurity and finance,\nespecially when working with large-scale tabular data. Yet, unsupervised\nanomaly detection -- where no labeled anomalies are available -- remains a\nsignificant challenge. Although various deep learning methods have been\nproposed to model a dataset's joint distribution, real-world tabular data often\ncontain heterogeneous contexts (e.g., different users), making globally rare\nevents normal under certain contexts. Consequently, relying on a single global\ndistribution can overlook these contextual nuances, degrading detection\nperformance. In this paper, we present a context-conditional anomaly detection\nframework tailored for tabular datasets. Our approach automatically identifies\ncontext features and models the conditional data distribution using a simple\ndeep autoencoder. Extensive experiments on multiple tabular benchmark datasets\ndemonstrate that our method outperforms state-of-the-art approaches,\nunderscoring the importance of context in accurately distinguishing anomalous\nfrom normal instances.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u8868\u683c\u6570\u636e\u96c6\u7684\u4e0a\u4e0b\u6587\u6761\u4ef6\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e0a\u4e0b\u6587\u5bf9\u5f02\u5e38\u68c0\u6d4b\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u5728\u5904\u7406\u542b\u5f02\u6784\u4e0a\u4e0b\u6587\u7684\u5927\u89c4\u6a21\u8868\u683c\u6570\u636e\u65f6\uff0c\u4f9d\u8d56\u5355\u4e00\u5168\u5c40\u5206\u5e03\u4f1a\u5ffd\u7565\u4e0a\u4e0b\u6587\u7ec6\u5fae\u5dee\u522b\uff0c\u964d\u4f4e\u68c0\u6d4b\u6027\u80fd\u3002", "method": "\u81ea\u52a8\u8bc6\u522b\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u4f7f\u7528\u7b80\u5355\u6df1\u5ea6\u81ea\u7f16\u7801\u5668\u5bf9\u6761\u4ef6\u6570\u636e\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u5728\u591a\u4e2a\u8868\u683c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5728\u51c6\u786e\u533a\u5206\u5f02\u5e38\u548c\u6b63\u5e38\u5b9e\u4f8b\u4e2d\u975e\u5e38\u91cd\u8981\u3002"}}
{"id": "2509.09245", "pdf": "https://arxiv.org/pdf/2509.09245", "abs": "https://arxiv.org/abs/2509.09245", "authors": ["Shuocheng Li", "Yihao Liu", "Silin Du", "Wenxuan Zeng", "Zhe Xu", "Mengyu Zhou", "Yeye He", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "title": "Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown great promise in automating data\nscience workflows, but existing models still struggle with multi-step reasoning\nand tool use, which limits their effectiveness on complex data analysis tasks.\nTo address this, we propose a scalable pipeline that extracts high-quality,\ntool-based data analysis tasks and their executable multi-step solutions from\nreal-world Jupyter notebooks and associated data files. Using this pipeline, we\nintroduce NbQA, a large-scale dataset of standardized task-solution pairs that\nreflect authentic tool-use patterns in practical data science scenarios. To\nfurther enhance multi-step reasoning, we present Jupiter, a framework that\nformulates data analysis as a search problem and applies Monte Carlo Tree\nSearch (MCTS) to generate diverse solution trajectories for value model\nlearning. During inference, Jupiter combines the value model and node visit\ncounts to efficiently collect executable multi-step plans with minimal search\nsteps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on\nNbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench,\nrespectively-matching or surpassing GPT-4o and advanced agent frameworks.\nFurther evaluations demonstrate improved generalization and stronger tool-use\nreasoning across diverse multi-step reasoning tasks.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u6269\u5c55\u7ba1\u9053\u63d0\u53d6\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e0e\u89e3\u51b3\u65b9\u6848\u6784\u5efaNbQA\u6570\u636e\u96c6\uff0c\u7528Jupiter\u6846\u67b6\u589e\u5f3a\u591a\u6b65\u63a8\u7406\uff0c\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5728\u4efb\u52a1\u89e3\u51b3\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u4e0a\u5b58\u5728\u56f0\u96be\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u6570\u636e\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u7ba1\u9053\u4eceJupyter\u7b14\u8bb0\u672c\u63d0\u53d6\u4efb\u52a1\u4e0e\u89e3\u51b3\u65b9\u6848\u6784\u5efaNbQA\u6570\u636e\u96c6\uff1b\u63d0\u51faJupiter\u6846\u67b6\u5c06\u6570\u636e\u5206\u6790\u5efa\u6a21\u4e3a\u641c\u7d22\u95ee\u9898\uff0c\u7528\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\u751f\u6210\u89e3\u51b3\u65b9\u6848\u8f68\u8ff9\u7528\u4e8e\u4ef7\u503c\u6a21\u578b\u5b66\u4e60\u3002", "result": "Qwen2.5 - 7B\u548c14B - Instruct\u6a21\u578b\u5728NbQA\u4e0a\u5206\u522b\u89e3\u51b377.82%\u548c86.38%\u7684InfiAgent - DABench\u4efb\u52a1\uff0c\u5339\u914d\u6216\u8d85\u8d8aGPT - 4o\u548c\u5148\u8fdb\u4ee3\u7406\u6846\u67b6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5de5\u5177\u4f7f\u7528\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2509.09614", "pdf": "https://arxiv.org/pdf/2509.09614", "abs": "https://arxiv.org/abs/2509.09614", "authors": ["Jielin Qiu", "Zuxin Liu", "Zhiwei Liu", "Rithesh Murthy", "Jianguo Zhang", "Haolin Chen", "Shiyu Wang", "Ming Zhu", "Liangwei Yang", "Juntao Tan", "Zhepeng Cen", "Cheng Qian", "Shelby Heinecke", "Weiran Yao", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "title": "LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering", "categories": ["cs.SE", "cs.AI"], "comment": "53 pages", "summary": "The emergence of long-context language models with context windows extending\nto millions of tokens has created new opportunities for sophisticated code\nunderstanding and software development evaluation. We propose LoCoBench, a\ncomprehensive benchmark specifically designed to evaluate long-context LLMs in\nrealistic, complex software development scenarios. Unlike existing code\nevaluation benchmarks that focus on single-function completion or short-context\ntasks, LoCoBench addresses the critical evaluation gap for long-context\ncapabilities that require understanding entire codebases, reasoning across\nmultiple files, and maintaining architectural consistency across large-scale\nsoftware systems. Our benchmark provides 8,000 evaluation scenarios\nsystematically generated across 10 programming languages, with context lengths\nspanning 10K to 1M tokens, a 100x variation that enables precise assessment of\nlong-context performance degradation in realistic software development\nsettings. LoCoBench introduces 8 task categories that capture essential\nlong-context capabilities: architectural understanding, cross-file refactoring,\nmulti-session development, bug investigation, feature implementation, code\ncomprehension, integration testing, and security analysis. Through a 5-phase\npipeline, we create diverse, high-quality scenarios that challenge LLMs to\nreason about complex codebases at unprecedented scale. We introduce a\ncomprehensive evaluation framework with 17 metrics across 4 dimensions,\nincluding 8 new evaluation metrics, combined in a LoCoBench Score (LCBS). Our\nevaluation of state-of-the-art long-context models reveals substantial\nperformance gaps, demonstrating that long-context understanding in complex\nsoftware development represents a significant unsolved challenge that demands\nmore attention. LoCoBench is released at:\nhttps://github.com/SalesforceAIResearch/LoCoBench.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u8bc4\u4f30\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7efc\u5408\u57fa\u51c6LoCoBench\uff0c\u67098000\u4e2a\u8bc4\u4f30\u573a\u666f\u30018\u4e2a\u4efb\u52a1\u7c7b\u522b\u548c17\u4e2a\u8bc4\u4f30\u6307\u6807\uff0c\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u6709\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u8bc4\u4f30\u57fa\u51c6\u7f3a\u4e4f\u5bf9\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u4e3a\u4ee3\u7801\u7406\u89e3\u548c\u8f6f\u4ef6\u5f00\u53d1\u8bc4\u4f30\u5e26\u6765\u65b0\u673a\u9047\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u590d\u6742\u8f6f\u4ef6\u5f00\u53d1\u573a\u666f\u4e2d\u7684\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\u3002", "method": "\u7cfb\u7edf\u751f\u621010\u79cd\u7f16\u7a0b\u8bed\u8a00\u76848000\u4e2a\u8bc4\u4f30\u573a\u666f\uff0c\u5f15\u51658\u4e2a\u4efb\u52a1\u7c7b\u522b\uff0c\u901a\u8fc75\u9636\u6bb5\u7ba1\u9053\u521b\u5efa\u573a\u666f\uff0c\u63d0\u51fa\u542b17\u4e2a\u6307\u6807\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u5bf9\u73b0\u6709\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u590d\u6742\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u662f\u91cd\u5927\u672a\u89e3\u51b3\u6311\u6218\uff0c\u9700\u66f4\u591a\u5173\u6ce8\u3002"}}
{"id": "2509.09052", "pdf": "https://arxiv.org/pdf/2509.09052", "abs": "https://arxiv.org/abs/2509.09052", "authors": ["Dibyajyoti Chakraborty", "Romit Maulik", "Peter Harrington", "Dallas Foster", "Mohammad Amin Nabian", "Sanjay Choudhry"], "title": "MoWE : A Mixture of Weather Experts", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "physics.geo-ph"], "comment": null, "summary": "Data-driven weather models have recently achieved state-of-the-art\nperformance, yet progress has plateaued in recent years. This paper introduces\na Mixture of Experts (MoWE) approach as a novel paradigm to overcome these\nlimitations, not by creating a new forecaster, but by optimally combining the\noutputs of existing models. The MoWE model is trained with significantly lower\ncomputational resources than the individual experts. Our model employs a Vision\nTransformer-based gating network that dynamically learns to weight the\ncontributions of multiple \"expert\" models at each grid point, conditioned on\nforecast lead time. This approach creates a synthesized deterministic forecast\nthat is more accurate than any individual component in terms of Root Mean\nSquared Error (RMSE). Our results demonstrate the effectiveness of this method,\nachieving up to a 10% lower RMSE than the best-performing AI weather model on a\n2-day forecast horizon, significantly outperforming individual experts as well\nas a simple average across experts. This work presents a computationally\nefficient and scalable strategy to push the state of the art in data-driven\nweather prediction by making the most out of leading high-quality forecast\nmodels.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faMoWE\u65b9\u6cd5\u7ed3\u5408\u73b0\u6709\u6a21\u578b\u8f93\u51fa\u505a\u5929\u6c14\u9884\u6d4b\uff0c\u8bad\u7ec3\u8d44\u6e90\u9700\u6c42\u4f4e\u4e14\u9884\u6d4bRMSE\u66f4\u4f4e\uff0c\u662f\u9ad8\u6548\u53ef\u6269\u5c55\u7b56\u7565\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u5929\u6c14\u6a21\u578b\u8fd1\u5e74\u8fdb\u5c55\u505c\u6ede\uff0c\u9700\u65b0\u65b9\u6cd5\u7a81\u7834\u5c40\u9650\u3002", "method": "\u91c7\u7528\u57fa\u4e8eVision Transformer\u7684\u95e8\u63a7\u7f51\u7edc\uff0c\u6839\u636e\u9884\u6d4b\u63d0\u524d\u65f6\u95f4\u52a8\u6001\u52a0\u6743\u591a\u4e2a\u4e13\u5bb6\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u57282\u5929\u9884\u6d4b\u4e2dRMSE\u6bd4\u6700\u4f73AI\u5929\u6c14\u6a21\u578b\u4f4e10%\uff0c\u8fdc\u8d85\u5355\u4e2a\u4e13\u5bb6\u6a21\u578b\u548c\u7b80\u5355\u5e73\u5747\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u8ba1\u7b97\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7b56\u7565\uff0c\u80fd\u63a8\u52a8\u6570\u636e\u9a71\u52a8\u5929\u6c14\u9884\u6d4b\u53d1\u5c55\u3002"}}
{"id": "2509.09272", "pdf": "https://arxiv.org/pdf/2509.09272", "abs": "https://arxiv.org/abs/2509.09272", "authors": ["Vaibhav Chaudhary", "Neha Soni", "Narotam Singh", "Amita Kapoor"], "title": "Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs", "categories": ["cs.AI"], "comment": "46 pages, 4 figures, 17 tables", "summary": "Knowledge graphs, a powerful tool for structuring information through\nrelational triplets, have recently become the new front-runner in enhancing\nquestion-answering systems. While traditional Retrieval Augmented Generation\n(RAG) approaches are proficient in fact-based and local context-based\nextraction from concise texts, they encounter limitations when addressing the\nthematic and holistic understanding of complex, extensive texts, requiring a\ndeeper analysis of both text and context. This paper presents a comprehensive\ntechnical comparative study of three different methodologies for constructing\nknowledge graph triplets and integrating them with Large Language Models (LLMs)\nfor question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all\nleveraging open source technologies. We evaluate the effectiveness,\nfeasibility, and adaptability of these methods by analyzing their capabilities,\nstate of development, and their impact on the performance of LLM-based question\nanswering. Experimental results indicate that while OpenIE provides the most\ncomprehensive coverage of triplets, GraphRAG demonstrates superior reasoning\nabilities among the three. We conclude with a discussion on the strengths and\nlimitations of each method and provide insights into future directions for\nimproving knowledge graph-based question answering.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u4e09\u79cd\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\u5e76\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7528\u4e8e\u95ee\u7b54\u7684\u65b9\u6cd5\u8fdb\u884c\u6280\u672f\u6bd4\u8f83\u7814\u7a76\uff0c\u5b9e\u9a8c\u8868\u660eOpenIE\u4e09\u5143\u7ec4\u8986\u76d6\u6700\u5168\u9762\uff0cGraphRAG\u63a8\u7406\u80fd\u529b\u6700\u5f3a\uff0c\u6700\u540e\u8ba8\u8bba\u5404\u65b9\u6cd5\u4f18\u7f3a\u70b9\u5e76\u7ed9\u51fa\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u957f\u6587\u672c\u4e3b\u9898\u548c\u6574\u4f53\u7406\u89e3\u65f6\u6709\u5c40\u9650\uff0c\u9700\u8981\u5bf9\u6587\u672c\u548c\u4e0a\u4e0b\u6587\u8fdb\u884c\u66f4\u6df1\u5165\u5206\u6790\uff0c\u56e0\u6b64\u7814\u7a76\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\u5e76\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7528\u4e8e\u95ee\u7b54\u7684\u65b9\u6cd5\u3002", "method": "\u5bf9spaCy\u3001Stanford CoreNLP - OpenIE\u548cGraphRAG\u4e09\u79cd\u5229\u7528\u5f00\u6e90\u6280\u672f\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\u5e76\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7528\u4e8e\u95ee\u7b54\u7684\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u6280\u672f\u6bd4\u8f83\u7814\u7a76\uff0c\u5206\u6790\u5176\u80fd\u529b\u3001\u53d1\u5c55\u72b6\u51b5\u53ca\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u95ee\u7b54\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "OpenIE\u63d0\u4f9b\u7684\u4e09\u5143\u7ec4\u8986\u76d6\u6700\u5168\u9762\uff0cGraphRAG\u5728\u4e09\u8005\u4e2d\u5c55\u73b0\u51fa\u66f4\u4f18\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u6bcf\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u5bf9\u6539\u8fdb\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u95ee\u7b54\u7ed9\u51fa\u672a\u6765\u65b9\u5411\u7684\u89c1\u89e3\u3002"}}
{"id": "2509.09630", "pdf": "https://arxiv.org/pdf/2509.09630", "abs": "https://arxiv.org/abs/2509.09630", "authors": ["Zhenguang Liu", "Lixun Ma", "Zhongzheng Mu", "Chengkun Wei", "Xiaojun Xu", "Yingying Jiao", "Kui Ren"], "title": "I Know Who Clones Your Code: Interpretable Smart Contract Similarity Detection", "categories": ["cs.SE", "cs.CR"], "comment": null, "summary": "Widespread reuse of open-source code in smart contract development boosts\nprogramming efficiency but significantly amplifies bug propagation across\ncontracts, while dedicated methods for detecting similar smart contract\nfunctions remain very limited. Conventional abstract-syntax-tree (AST) based\nmethods for smart contract similarity detection face challenges in handling\nintricate tree structures, which impedes detailed semantic comparison of code.\nRecent deep-learning based approaches tend to overlook code syntax and\ndetection interpretability, resulting in suboptimal performance.\n  To fill this research gap, we introduce SmartDetector, a novel approach for\ncomputing similarity between smart contract functions, explainable at the\nfine-grained statement level. Technically, SmartDetector decomposes the AST of\na smart contract function into a series of smaller statement trees, each\nreflecting a structural element of the source code. Then, SmartDetector uses a\nclassifier to compute the similarity score of two functions by comparing each\npair of their statement trees. To address the infinite hyperparameter space of\nthe classifier, we mathematically derive a cosine-wise diffusion process to\nefficiently search optimal hyperparameters. Extensive experiments conducted on\nthree large real-world datasets demonstrate that SmartDetector outperforms\ncurrent state-of-the-art methods by an average improvement of 14.01% in\nF1-score, achieving an overall average F1-score of 95.88%.", "AI": {"tldr": "\u63d0\u51faSmartDetector\u65b9\u6cd5\u8ba1\u7b97\u667a\u80fd\u5408\u7ea6\u51fd\u6570\u76f8\u4f3c\u5ea6\uff0c\u5728\u591a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f00\u6e90\u4ee3\u7801\u590d\u7528\u5bfc\u81f4\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u4f20\u64ad\uff0c\u73b0\u6709\u68c0\u6d4b\u76f8\u4f3c\u667a\u80fd\u5408\u7ea6\u51fd\u6570\u7684\u65b9\u6cd5\u6709\u9650\uff0c\u4f20\u7edfAST\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5c06\u667a\u80fd\u5408\u7ea6\u51fd\u6570\u7684AST\u5206\u89e3\u4e3a\u5c0f\u7684\u8bed\u53e5\u6811\uff0c\u7528\u5206\u7c7b\u5668\u6bd4\u8f83\u8bed\u53e5\u6811\u5bf9\u8ba1\u7b97\u76f8\u4f3c\u5ea6\uff0c\u901a\u8fc7\u4f59\u5f26\u6269\u6563\u8fc7\u7a0b\u641c\u7d22\u5206\u7c7b\u5668\u6700\u4f18\u8d85\u53c2\u6570\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u578b\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cSmartDetector\u7684F1\u5206\u6570\u5e73\u5747\u63d0\u9ad814.01%\uff0c\u6574\u4f53\u5e73\u5747F1\u5206\u6570\u8fbe95.88%\u3002", "conclusion": "SmartDetector\u5728\u8ba1\u7b97\u667a\u80fd\u5408\u7ea6\u51fd\u6570\u76f8\u4f3c\u5ea6\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2509.09053", "pdf": "https://arxiv.org/pdf/2509.09053", "abs": "https://arxiv.org/abs/2509.09053", "authors": ["Julian Oelhaf", "Georg Kordowich", "Mehran Pashaei", "Christian Bergler", "Andreas Maier", "Johann J\u00e4ger", "Siming Bayer"], "title": "A Scoping Review of Machine Learning Applications in Power System Protection and Disturbance Management", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "The integration of renewable and distributed energy resources reshapes modern\npower systems, challenging conventional protection schemes. This scoping review\nsynthesizes recent literature on machine learning (ML) applications in power\nsystem protection and disturbance management, following the PRISMA for Scoping\nReviews framework. Based on over 100 publications, three key objectives are\naddressed: (i) assessing the scope of ML research in protection tasks; (ii)\nevaluating ML performance across diverse operational scenarios; and (iii)\nidentifying methods suitable for evolving grid conditions. ML models often\ndemonstrate high accuracy on simulated datasets; however, their performance\nunder real-world conditions remains insufficiently validated. The existing\nliterature is fragmented, with inconsistencies in methodological rigor, dataset\nquality, and evaluation metrics. This lack of standardization hampers the\ncomparability of results and limits the generalizability of findings. To\naddress these challenges, this review introduces a ML-oriented taxonomy for\nprotection tasks, resolves key terminological inconsistencies, and advocates\nfor standardized reporting practices. It further provides guidelines for\ncomprehensive dataset documentation, methodological transparency, and\nconsistent evaluation protocols, aiming to improve reproducibility and enhance\nthe practical relevance of research outcomes. Critical gaps remain, including\nthe scarcity of real-world validation, insufficient robustness testing, and\nlimited consideration of deployment feasibility. Future research should\nprioritize public benchmark datasets, realistic validation methods, and\nadvanced ML architectures. These steps are essential to move ML-based\nprotection from theoretical promise to practical deployment in increasingly\ndynamic and decentralized power systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u673a\u5668\u5b66\u4e60\u5728\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u548c\u6270\u52a8\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u8303\u56f4\u7efc\u8ff0\uff0c\u6307\u51fa\u5f53\u524d\u7814\u7a76\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u63d0\u51fa\u89e3\u51b3\u63aa\u65bd\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u53ef\u518d\u751f\u548c\u5206\u5e03\u5f0f\u80fd\u6e90\u6574\u5408\u91cd\u5851\u73b0\u4ee3\u7535\u529b\u7cfb\u7edf\uff0c\u6311\u6218\u4f20\u7edf\u4fdd\u62a4\u65b9\u6848\uff0c\u9700\u7814\u7a76\u673a\u5668\u5b66\u4e60\u5728\u7535\u529b\u7cfb\u7edf\u4fdd\u62a4\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u9075\u5faaPRISMA for Scoping Reviews\u6846\u67b6\uff0c\u7efc\u5408\u5206\u6790100\u591a\u7bc7\u6587\u732e\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u6027\u80fd\u9a8c\u8bc1\u4e0d\u8db3\uff0c\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u5f71\u54cd\u7ed3\u679c\u53ef\u6bd4\u6027\u548c\u666e\u904d\u6027\u3002", "conclusion": "\u5f15\u5165\u9762\u5411\u673a\u5668\u5b66\u4e60\u7684\u5206\u7c7b\u6cd5\uff0c\u5021\u5bfc\u6807\u51c6\u5316\u62a5\u544a\u5b9e\u8df5\uff0c\u672a\u6765\u7814\u7a76\u5e94\u4f18\u5148\u8003\u8651\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u3001\u73b0\u5b9e\u9a8c\u8bc1\u65b9\u6cd5\u548c\u5148\u8fdb\u673a\u5668\u5b66\u4e60\u67b6\u6784\u3002"}}
{"id": "2509.09284", "pdf": "https://arxiv.org/pdf/2509.09284", "abs": "https://arxiv.org/abs/2509.09284", "authors": ["Bingning Huang", "Tu Nguyen", "Matthieu Zimmer"], "title": "Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent advances in reasoning with large language models (LLMs) have shown the\neffectiveness of Monte Carlo Tree Search (MCTS) for generating high-quality\nintermediate trajectories, particularly in math and symbolic domains. Inspired\nby this, we explore how MCTS-derived trajectories, traditionally used for\ntraining value or reward models, can be repurposed to improve policy\noptimization in preference-based reinforcement learning (RL). Specifically, we\nfocus on Group Relative Policy Optimization (GRPO), a recent algorithm that\nenables preference-consistent policy learning without value networks. We\npropose a staged GRPO training paradigm where completions are derived from\npartially revealed MCTS rollouts, introducing a novel tree-structured setting\nfor advantage estimation. This leads to a rich class of prefix-conditioned\nreward signals, which we analyze theoretically and empirically. Our initial\nresults indicate that while structured advantage estimation can stabilize\nupdates and better reflect compositional reasoning quality, challenges such as\nadvantage saturation and reward signal collapse remain. We propose heuristic\nand statistical solutions to mitigate these issues and discuss open challenges\nfor learning under staged or tree-like reward structures.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u7528MCTS\u8f68\u8ff9\u6539\u8fdb\u57fa\u4e8e\u504f\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7b56\u7565\u4f18\u5316\uff0c\u63d0\u51fa\u5206\u9636\u6bb5GRPO\u8bad\u7ec3\u8303\u5f0f\uff0c\u5206\u6790\u4e86\u76f8\u5173\u5956\u52b1\u4fe1\u53f7\uff0c\u6307\u51fa\u95ee\u9898\u5e76\u7ed9\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u53d7MCTS\u5728\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u751f\u6210\u9ad8\u8d28\u91cf\u4e2d\u95f4\u8f68\u8ff9\u7684\u542f\u53d1\uff0c\u63a2\u7d22\u5c06MCTS\u8f68\u8ff9\u7528\u4e8e\u57fa\u4e8e\u504f\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u6539\u8fdb\u7b56\u7565\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u5206\u9636\u6bb5GRPO\u8bad\u7ec3\u8303\u5f0f\uff0c\u5229\u7528\u90e8\u5206\u63ed\u793a\u7684MCTS\u6eda\u52a8\u751f\u6210\u8865\u5168\uff0c\u5f15\u5165\u6811\u72b6\u7ed3\u6784\u8fdb\u884c\u4f18\u52bf\u4f30\u8ba1\u3002", "result": "\u7ed3\u6784\u5316\u4f18\u52bf\u4f30\u8ba1\u53ef\u7a33\u5b9a\u66f4\u65b0\u5e76\u53cd\u6620\u63a8\u7406\u8d28\u91cf\uff0c\u4f46\u5b58\u5728\u4f18\u52bf\u9971\u548c\u548c\u5956\u52b1\u4fe1\u53f7\u5d29\u6e83\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u542f\u53d1\u5f0f\u548c\u7edf\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u8ba8\u8bba\u4e86\u5728\u5206\u9636\u6bb5\u6216\u6811\u72b6\u5956\u52b1\u7ed3\u6784\u4e0b\u5b66\u4e60\u7684\u5f00\u653e\u6027\u6311\u6218\u3002"}}
{"id": "2509.09292", "pdf": "https://arxiv.org/pdf/2509.09292", "abs": "https://arxiv.org/abs/2509.09292", "authors": ["Weige Cai", "Tong Zhu", "Jinyi Niu", "Ruiqi Hu", "Lingyao Li", "Tenglong Wang", "Xiaowu Dai", "Weining Shen", "Liwen Zhang"], "title": "LightAgent: Production-level Open-source Agentic AI Framework", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid advancement of large language models (LLMs), Multi-agent\nSystems (MAS) have achieved significant progress in various application\nscenarios. However, substantial challenges remain in designing versatile,\nrobust, and efficient platforms for agent deployment. To address these\nlimitations, we propose \\textbf{LightAgent}, a lightweight yet powerful agentic\nframework, effectively resolving the trade-off between flexibility and\nsimplicity found in existing frameworks. LightAgent integrates core\nfunctionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while\nmaintaining an extremely lightweight structure. As a fully open-source\nsolution, it seamlessly integrates with mainstream chat platforms, enabling\ndevelopers to easily build self-learning agents. We have released LightAgent at\n\\href{https://github.com/wxai-space/LightAgent}{https://github.com/wxai-space/LightAgent}", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u4e14\u5f3a\u5927\u7684\u4ee3\u7406\u6846\u67b6LightAgent\uff0c\u89e3\u51b3\u73b0\u6709\u6846\u67b6\u5728\u7075\u6d3b\u6027\u548c\u7b80\u5355\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u5df2\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u4e0b\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8bbe\u8ba1\u901a\u7528\u3001\u5065\u58ee\u548c\u9ad8\u6548\u7684\u4ee3\u7406\u90e8\u7f72\u5e73\u53f0\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51faLightAgent\u6846\u67b6\uff0c\u96c6\u6210\u8bb0\u5fc6\u3001\u5de5\u5177\u548c\u601d\u7ef4\u6811\u7b49\u6838\u5fc3\u529f\u80fd\uff0c\u4fdd\u6301\u8f7b\u91cf\u7ea7\u7ed3\u6784\uff0c\u4e14\u4f5c\u4e3a\u5f00\u6e90\u65b9\u6848\u4e0e\u4e3b\u6d41\u804a\u5929\u5e73\u53f0\u96c6\u6210\u3002", "result": "\u6210\u529f\u63d0\u51faLightAgent\u6846\u67b6\u5e76\u5f00\u6e90\u3002", "conclusion": "LightAgent\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u6846\u67b6\u7684\u6743\u8861\u95ee\u9898\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u6784\u5efa\u81ea\u5b66\u4e60\u4ee3\u7406\u3002"}}
{"id": "2509.09392", "pdf": "https://arxiv.org/pdf/2509.09392", "abs": "https://arxiv.org/abs/2509.09392", "authors": ["Simon Leistikow", "Thomas Miro", "Adrian Kummerl\u00e4nder", "Ali Nahardani", "Katja Gr\u00fcn", "Markus Franz", "Verena Hoerr", "Mathias J. Krause", "Lars Linsen"], "title": "An Integrated Open Source Software System for the Generation and Analysis of Subject-Specific Blood Flow Simulation Ensembles", "categories": ["physics.med-ph", "cs.SE"], "comment": "21 pages, 7 figures, 2 tables", "summary": "Background and Objective: Hemodynamic analysis of blood flow through arteries\nand veins is critical for diagnosing cardiovascular diseases, such as aneurysms\nand stenoses, and for investigating cardiovascular parameters, such as\nturbulence and wall shear stress. For subject-specific analyses, the anatomy\nand blood flow of the subject can be captured non-invasively using structural\nand 4D Magnetic Resonance Imaging (MRI). Computational Fluid Dynamics (CFD), on\nthe other hand, can be used to generate blood flow simulations by solving the\nNavier-Stokes equations. To generate and analyze subject-specific blood flow\nsimulations, MRI and CFD have to be brought together.\n  Methods: We present an interactive, customizable, and user-oriented visual\nanalysis tool that assists researchers in both medicine and numerical analysis.\nOur open-source tool is applicable to domains such as CFD and MRI, and it\nfacilitates the analysis of simulation results and medical data, especially in\nhemodynamic studies. It enables the creation of simulation ensembles with a\nhigh variety of parameters. Furthermore, it allows for the visual and\nanalytical examination of simulations and measurements through 2D embeddings of\nthe similarity space.\n  Results: To demonstrate the effectiveness of our tool, we applied it to three\nreal-world use cases, showcasing its ability to configure simulation ensembles\nand analyse blood flow dynamics. We evaluated our example cases together with\nMRI and CFD experts to further enhance features and increase the usability.\n  Conclusions: By combining the strengths of both CFD and MRI, our tool\nprovides a more comprehensive understanding of hemodynamic parameters,\nfacilitating more accurate analysis of hemodynamic biomarkers.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e00\u6b3e\u7ed3\u5408MRI\u548cCFD\u7684\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u901a\u8fc7\u4e09\u4e2a\u7528\u4f8b\u5c55\u793a\u5176\u6709\u6548\u6027\uff0c\u80fd\u52a9\u529b\u8840\u6d41\u52a8\u529b\u5b66\u5206\u6790\u3002", "motivation": "\u8840\u6d41\u52a8\u529b\u5b66\u5206\u6790\u5bf9\u8bca\u65ad\u5fc3\u8840\u7ba1\u75be\u75c5\u548c\u7814\u7a76\u5fc3\u8840\u7ba1\u53c2\u6570\u81f3\u5173\u91cd\u8981\uff0c\u9700\u7ed3\u5408MRI\u548cCFD\u8fdb\u884c\u7279\u5b9a\u5bf9\u8c61\u7684\u8840\u6d41\u6a21\u62df\u5206\u6790\u3002", "method": "\u5f00\u53d1\u4e00\u6b3e\u4ea4\u4e92\u5f0f\u3001\u53ef\u5b9a\u5236\u3001\u9762\u5411\u7528\u6237\u7684\u53ef\u89c6\u5316\u5206\u6790\u5de5\u5177\uff0c\u9002\u7528\u4e8eCFD\u548cMRI\u9886\u57df\uff0c\u53ef\u521b\u5efa\u53c2\u6570\u591a\u6837\u7684\u6a21\u62df\u96c6\u5408\uff0c\u901a\u8fc7\u76f8\u4f3c\u7a7a\u95f4\u7684\u4e8c\u7ef4\u5d4c\u5165\u8fdb\u884c\u6a21\u62df\u548c\u6d4b\u91cf\u7684\u53ef\u89c6\u5316\u4e0e\u5206\u6790\u3002", "result": "\u5c06\u5de5\u5177\u5e94\u7528\u4e8e\u4e09\u4e2a\u5b9e\u9645\u7528\u4f8b\uff0c\u5c55\u793a\u5176\u914d\u7f6e\u6a21\u62df\u96c6\u5408\u548c\u5206\u6790\u8840\u6d41\u52a8\u529b\u5b66\u7684\u80fd\u529b\uff0c\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u4ee5\u589e\u5f3a\u529f\u80fd\u548c\u53ef\u7528\u6027\u3002", "conclusion": "\u8be5\u5de5\u5177\u7ed3\u5408CFD\u548cMRI\u4f18\u52bf\uff0c\u80fd\u66f4\u5168\u9762\u7406\u89e3\u8840\u6d41\u52a8\u529b\u5b66\u53c2\u6570\uff0c\u4fc3\u8fdb\u5bf9\u8840\u6d41\u52a8\u529b\u5b66\u751f\u7269\u6807\u5fd7\u7269\u7684\u51c6\u786e\u5206\u6790\u3002"}}
{"id": "2509.09073", "pdf": "https://arxiv.org/pdf/2509.09073", "abs": "https://arxiv.org/abs/2509.09073", "authors": ["Gianlucca Zuin", "Adriano Veloso"], "title": "\"A 6 or a 9?\": Ensemble Learning Through the Multiplicity of Performant Models and Explanations", "categories": ["cs.LG"], "comment": "Paper accepted to the ACM Transactions on Knowledge Discovery from\n  Data (TKDD) for publication (preprint version)", "summary": "Creating models from past observations and ensuring their effectiveness on\nnew data is the essence of machine learning. However, selecting models that\ngeneralize well remains a challenging task. Related to this topic, the Rashomon\nEffect refers to cases where multiple models perform similarly well for a given\nlearning problem. This often occurs in real-world scenarios, like the\nmanufacturing process or medical diagnosis, where diverse patterns in data lead\nto multiple high-performing solutions. We propose the Rashomon Ensemble, a\nmethod that strategically selects models from these diverse high-performing\nsolutions to improve generalization. By grouping models based on both their\nperformance and explanations, we construct ensembles that maximize diversity\nwhile maintaining predictive accuracy. This selection ensures that each model\ncovers a distinct region of the solution space, making the ensemble more robust\nto distribution shifts and variations in unseen data. We validate our approach\non both open and proprietary collaborative real-world datasets, demonstrating\nup to 0.20+ AUROC improvements in scenarios where the Rashomon ratio is large.\nAdditionally, we demonstrate tangible benefits for businesses in various\nreal-world applications, highlighting the robustness, practicality, and\neffectiveness of our approach.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faRashomon Ensemble\u65b9\u6cd5\uff0c\u4ece\u591a\u6837\u7684\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u4e2d\u9009\u6a21\u578b\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548\uff0c\u5bf9\u4f01\u4e1a\u5e94\u7528\u6709\u597d\u5904\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4e2d\u6a21\u578b\u6cdb\u5316\u6027\u9009\u62e9\u96be\u9898\uff0c\u5e94\u5bf9Rashomon Effect\u73b0\u8c61\u3002", "method": "\u63d0\u51faRashomon Ensemble\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6a21\u578b\u6027\u80fd\u548c\u89e3\u91ca\u5206\u7ec4\uff0c\u6784\u5efa\u6700\u5927\u5316\u591a\u6837\u6027\u4e14\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u7684\u96c6\u6210\u3002", "result": "\u5728\u5f00\u653e\u548c\u4e13\u6709\u534f\u4f5c\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\uff0cRashomon ratio\u5927\u7684\u573a\u666fAUROC\u63d0\u53470.20+\uff0c\u5bf9\u4f01\u4e1a\u5e94\u7528\u6709\u5b9e\u9645\u597d\u5904\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u3001\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2509.09312", "pdf": "https://arxiv.org/pdf/2509.09312", "abs": "https://arxiv.org/abs/2509.09312", "authors": ["Cl\u00e9ment Contet", "Umberto Grandi", "J\u00e9r\u00f4me Mengin"], "title": "Explaining Tournament Solutions with Minimal Supports", "categories": ["cs.AI"], "comment": null, "summary": "Tournaments are widely used models to represent pairwise dominance between\ncandidates, alternatives, or teams. We study the problem of providing certified\nexplanations for why a candidate appears among the winners under various\ntournament rules. To this end, we identify minimal supports, minimal\nsub-tournaments in which the candidate is guaranteed to win regardless of how\nthe rest of the tournament is completed (that is, the candidate is a necessary\nwinner of the sub-tournament). This notion corresponds to an abductive\nexplanation for the question,\"Why does the winner win the tournament\", a\ncentral concept in formal explainable AI. We focus on common tournament\nsolutions: the top cycle, the uncovered set, the Copeland rule, the Borda rule,\nthe maximin rule, and the weighted uncovered set. For each rule we determine\nthe size of the smallest minimal supports, and we present polynomial-time\nalgorithms to compute them for all but the weighted uncovered set, for which\nthe problem is NP-complete. Finally, we show how minimal supports can serve to\nproduce compact, certified, and intuitive explanations.", "AI": {"tldr": "\u7814\u7a76\u4e3a\u4e0d\u540c\u9526\u6807\u8d5b\u89c4\u5219\u4e0b\u5019\u9009\u4eba\u6210\u4e3a\u83b7\u80dc\u8005\u63d0\u4f9b\u8ba4\u8bc1\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u786e\u5b9a\u6700\u5c0f\u652f\u6301\u96c6\uff0c\u7ed9\u51fa\u90e8\u5206\u89c4\u5219\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u5e76\u5c55\u793a\u5176\u7528\u4e8e\u751f\u6210\u89e3\u91ca\u3002", "motivation": "\u4e3a\u4e0d\u540c\u9526\u6807\u8d5b\u89c4\u5219\u4e0b\u5019\u9009\u4eba\u6210\u4e3a\u83b7\u80dc\u8005\u63d0\u4f9b\u8ba4\u8bc1\u89e3\u91ca\u3002", "method": "\u786e\u5b9a\u6700\u5c0f\u652f\u6301\u96c6\uff08\u5373\u5019\u9009\u4eba\u5728\u5176\u4e2d\u5fc5\u8d62\u7684\u6700\u5c0f\u5b50\u9526\u6807\u8d5b\uff09\uff0c\u9488\u5bf9\u5e38\u89c1\u9526\u6807\u8d5b\u89c4\u5219\u786e\u5b9a\u6700\u5c0f\u652f\u6301\u96c6\u5927\u5c0f\uff0c\u8bbe\u8ba1\u7b97\u6cd5\u3002", "result": "\u9664\u52a0\u6743\u672a\u8986\u76d6\u96c6\u95ee\u9898\u662fNP\u5b8c\u5168\u95ee\u9898\u5916\uff0c\u4e3a\u5176\u4ed6\u89c4\u5219\u7ed9\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u8ba1\u7b97\u6700\u5c0f\u652f\u6301\u96c6\u3002", "conclusion": "\u6700\u5c0f\u652f\u6301\u96c6\u53ef\u7528\u4e8e\u4ea7\u751f\u7d27\u51d1\u3001\u8ba4\u8bc1\u4e14\u76f4\u89c2\u7684\u89e3\u91ca\u3002"}}
{"id": "2509.09088", "pdf": "https://arxiv.org/pdf/2509.09088", "abs": "https://arxiv.org/abs/2509.09088", "authors": ["Govind Menon", "Tianmin Yu"], "title": "An entropy formula for the Deep Linear Network", "categories": ["cs.LG", "math.DG", "math.DS"], "comment": null, "summary": "We study the Riemannian geometry of the Deep Linear Network (DLN) as a\nfoundation for a thermodynamic description of the learning process. The main\ntools are the use of group actions to analyze overparametrization and the use\nof Riemannian submersion from the space of parameters to the space of\nobservables. The foliation of the balanced manifold in the parameter space by\ngroup orbits is used to define and compute a Boltzmann entropy. We also show\nthat the Riemannian geometry on the space of observables defined in [2] is\nobtained by Riemannian submersion of the balanced manifold. The main technical\nstep is an explicit construction of an orthonormal basis for the tangent space\nof the balanced manifold using the theory of Jacobi matrices.", "AI": {"tldr": "\u7814\u7a76\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\uff08DLN\uff09\u7684\u9ece\u66fc\u51e0\u4f55\uff0c\u4e3a\u5b66\u4e60\u8fc7\u7a0b\u7684\u70ed\u529b\u5b66\u63cf\u8ff0\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u4e3a\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\u5b66\u4e60\u8fc7\u7a0b\u7684\u70ed\u529b\u5b66\u63cf\u8ff0\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u5229\u7528\u7fa4\u4f5c\u7528\u5206\u6790\u8fc7\u53c2\u6570\u5316\uff0c\u4f7f\u7528\u4ece\u53c2\u6570\u7a7a\u95f4\u5230\u53ef\u89c2\u6d4b\u91cf\u7a7a\u95f4\u7684\u9ece\u66fc\u6d78\u6ca1\uff0c\u7528\u7fa4\u8f68\u9053\u5bf9\u53c2\u6570\u7a7a\u95f4\u4e2d\u5e73\u8861\u6d41\u5f62\u7684\u53f6\u72b6\u7ed3\u6784\u5b9a\u4e49\u548c\u8ba1\u7b97\u73bb\u5c14\u5179\u66fc\u71b5\uff0c\u7528\u96c5\u53ef\u6bd4\u77e9\u9635\u7406\u8bba\u6784\u9020\u5e73\u8861\u6d41\u5f62\u5207\u7a7a\u95f4\u7684\u6b63\u4ea4\u57fa\u3002", "result": "\u5c55\u793a\u4e86\u6587\u732e[2]\u4e2d\u5b9a\u4e49\u7684\u53ef\u89c2\u6d4b\u91cf\u7a7a\u95f4\u4e0a\u7684\u9ece\u66fc\u51e0\u4f55\u53ef\u901a\u8fc7\u5e73\u8861\u6d41\u5f62\u7684\u9ece\u66fc\u6d78\u6ca1\u5f97\u5230\u3002", "conclusion": "\u901a\u8fc7\u4e00\u7cfb\u5217\u65b9\u6cd5\u7814\u7a76DLN\u7684\u9ece\u66fc\u51e0\u4f55\uff0c\u4e3a\u5176\u5b66\u4e60\u8fc7\u7a0b\u7684\u70ed\u529b\u5b66\u63cf\u8ff0\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2509.09314", "pdf": "https://arxiv.org/pdf/2509.09314", "abs": "https://arxiv.org/abs/2509.09314", "authors": ["Thuy Ngoc Nguyen", "Anita Williams Woolley", "Cleotilde Gonzalez"], "title": "Measuring Implicit Spatial Coordination in Teams: Effects on Collective Intelligence and Performance", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Coordinated teamwork is essential in fast-paced decision-making environments\nthat require dynamic adaptation, often without an opportunity for explicit\ncommunication. Although implicit coordination has been extensively considered\nin the existing literature, the majority of work has focused on co-located,\nsynchronous teamwork (such as sports teams) or, in distributed teams, primarily\non coordination of knowledge work. However, many teams (firefighters, military,\nlaw enforcement, emergency response) must coordinate their movements in\nphysical space without the benefit of visual cues or extensive explicit\ncommunication. This paper investigates how three dimensions of spatial\ncoordination, namely exploration diversity, movement specialization, and\nadaptive spatial proximity, influence team performance in a collaborative\nonline search and rescue task where explicit communication is restricted and\nteam members rely on movement patterns to infer others' intentions and\ncoordinate actions. Our metrics capture the relational aspects of teamwork by\nmeasuring spatial proximity, distribution patterns, and alignment of movements\nwithin shared environments. We analyze data from 34 four-person teams (136\nparticipants) assigned to specialized roles in a search and rescue task.\nResults show that spatial specialization positively predicts performance, while\nadaptive spatial proximity exhibits a marginal inverted U-shaped relationship,\nsuggesting moderate levels of adaptation are optimal. Furthermore, the temporal\ndynamics of these metrics differentiate high- from low-performing teams over\ntime. These findings provide insights into implicit spatial coordination in\nrole-based teamwork and highlight the importance of balanced adaptive\nstrategies, with implications for training and AI-assisted team support\nsystems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d7\u9650\u4ea4\u6d41\u4e0b\u7a7a\u95f4\u534f\u8c03\u4e09\u7ef4\u5ea6\u5bf9\u56e2\u961f\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u5206\u679034\u4e2a\u56db\u4eba\u56e2\u961f\u6570\u636e\uff0c\u53d1\u73b0\u7a7a\u95f4\u4e13\u4e1a\u5316\u6b63\u5411\u9884\u6d4b\u8868\u73b0\uff0c\u81ea\u9002\u5e94\u7a7a\u95f4\u63a5\u8fd1\u5ea6\u5448\u5012U\u5173\u7cfb\uff0c\u7ed3\u679c\u5bf9\u8bad\u7ec3\u548cAI\u8f85\u52a9\u6709\u542f\u793a\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u591a\u5173\u6ce8\u540c\u5730\u70b9\u540c\u6b65\u56e2\u961f\u6216\u77e5\u8bc6\u5de5\u4f5c\u534f\u8c03\uff0c\u800c\u5f88\u591a\u56e2\u961f\u9700\u5728\u65e0\u89c6\u89c9\u7ebf\u7d22\u548c\u5927\u91cf\u4ea4\u6d41\u4e0b\u534f\u8c03\u7269\u7406\u7a7a\u95f4\u884c\u52a8\uff0c\u6545\u7814\u7a76\u7a7a\u95f4\u534f\u8c03\u7ef4\u5ea6\u5bf9\u56e2\u961f\u8868\u73b0\u7684\u5f71\u54cd\u3002", "method": "\u4ee5\u534f\u4f5c\u5728\u7ebf\u641c\u7d22\u6551\u63f4\u4efb\u52a1\u4e3a\u7814\u7a76\u573a\u666f\uff0c\u9650\u5236\u660e\u786e\u4ea4\u6d41\uff0c\u901a\u8fc7\u6307\u6807\u8861\u91cf\u56e2\u961f\u7a7a\u95f4\u63a5\u8fd1\u5ea6\u3001\u5206\u5e03\u6a21\u5f0f\u548c\u8fd0\u52a8\u5bf9\u9f50\uff0c\u5206\u679034\u4e2a\u56db\u4eba\u56e2\u961f\u6570\u636e\u3002", "result": "\u7a7a\u95f4\u4e13\u4e1a\u5316\u6b63\u5411\u9884\u6d4b\u8868\u73b0\uff0c\u81ea\u9002\u5e94\u7a7a\u95f4\u63a5\u8fd1\u5ea6\u5448\u8fb9\u9645\u5012U\u578b\u5173\u7cfb\uff0c\u6307\u6807\u7684\u65f6\u95f4\u52a8\u6001\u80fd\u533a\u5206\u9ad8\u4f4e\u7ee9\u6548\u56e2\u961f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u57fa\u4e8e\u89d2\u8272\u7684\u56e2\u961f\u9690\u5f0f\u7a7a\u95f4\u534f\u8c03\u63d0\u4f9b\u89c1\u89e3\uff0c\u5f3a\u8c03\u5e73\u8861\u81ea\u9002\u5e94\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u5bf9\u8bad\u7ec3\u548cAI\u8f85\u52a9\u56e2\u961f\u652f\u6301\u7cfb\u7edf\u6709\u610f\u4e49\u3002"}}
{"id": "2509.09119", "pdf": "https://arxiv.org/pdf/2509.09119", "abs": "https://arxiv.org/abs/2509.09119", "authors": ["Hao Zhang", "Bo Huang", "Zhenjia Li", "Xi Xiao", "Hui Yi Leong", "Zumeng Zhang", "Xinwei Long", "Tianyang Wang", "Hao Xu"], "title": "Sensitivity-LoRA: Low-Load Sensitivity-Based Fine-Tuning for Large Language Models", "categories": ["cs.LG"], "comment": "15 pages", "summary": "Large Language Models (LLMs) have transformed both everyday life and\nscientific research. However, adapting LLMs from general-purpose models to\nspecialized tasks remains challenging, particularly in resource-constrained\nenvironments. Low-Rank Adaptation (LoRA), a prominent method within\nParameter-Efficient Fine-Tuning (PEFT), has emerged as a promising approach to\nLLMs by approximating model weight updates using low-rank decomposition.\nHowever, LoRA is limited by its uniform rank ( r ) allocation to each\nincremental matrix, and existing rank allocation techniques aimed at addressing\nthis issue remain computationally inefficient, complex, and unstable, hindering\npractical applications. To address these limitations, we propose\nSensitivity-LoRA, an efficient fine-tuning method that dynamically allocates\nranks to weight matrices based on both their global and local sensitivities. It\nleverages the second-order derivatives (Hessian Matrix) of the loss function to\neffectively capture weight sensitivity, enabling optimal rank allocation with\nminimal computational overhead. Our experimental results have demonstrated\nrobust effectiveness, efficiency and stability of Sensitivity-LoRA across\ndiverse tasks and benchmarks.", "AI": {"tldr": "\u63d0\u51faSensitivity - LoRA\u65b9\u6cd5\u89e3\u51b3LoRA\u5728LLM\u5fae\u8c03\u4e2d\u79e9\u5206\u914d\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9002\u914d\u5230\u7279\u5b9a\u4efb\u52a1\u6709\u6311\u6218\uff0c\u73b0\u6709\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u65b9\u6cd5\u5b58\u5728\u79e9\u5206\u914d\u5c40\u9650\uff0c\u73b0\u6709\u89e3\u51b3\u6280\u672f\u8ba1\u7b97\u6548\u7387\u4f4e\u3001\u590d\u6742\u4e14\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faSensitivity - LoRA\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6743\u91cd\u77e9\u9635\u7684\u5168\u5c40\u548c\u5c40\u90e8\u654f\u611f\u6027\u52a8\u6001\u5206\u914d\u79e9\uff0c\u5229\u7528\u635f\u5931\u51fd\u6570\u7684\u4e8c\u9636\u5bfc\u6570\u6709\u6548\u6355\u6349\u6743\u91cd\u654f\u611f\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eSensitivity - LoRA\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5177\u6709\u5f3a\u5927\u7684\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "Sensitivity - LoRA\u80fd\u6709\u6548\u89e3\u51b3LoRA\u7684\u5c40\u9650\uff0c\u5728LLM\u5fae\u8c03\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2509.09321", "pdf": "https://arxiv.org/pdf/2509.09321", "abs": "https://arxiv.org/abs/2509.09321", "authors": ["Hangyi Jia", "Yuxi Qian", "Hanwen Tong", "Xinhui Wu", "Lin Chen", "Feng Wei"], "title": "Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled the emergence of\ngeneral-purpose agents for automating end-to-end machine learning (ML)\nworkflows, including data analysis, feature engineering, model training, and\ncompetition solving. However, existing benchmarks remain limited in task\ncoverage, domain diversity, difficulty modeling, and evaluation rigor, failing\nto capture the full capabilities of such agents in realistic settings. We\npresent TAM Bench, a diverse, realistic, and structured benchmark for\nevaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three\nkey innovations: (1) A browser automation and LLM-based task acquisition system\nthat automatically collects and structures ML challenges from platforms such as\nKaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities\n(e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty\nmodeling mechanism that estimates task complexity using participant counts and\nscore dispersion, enabling scalable and objective task calibration; (3) A\nmulti-dimensional evaluation framework incorporating performance, format\ncompliance, constraint adherence, and task generalization. Based on 150 curated\nAutoML tasks, we construct three benchmark subsets of different sizes -- Lite,\nMedium, and Full -- designed for varying evaluation scenarios. The Lite\nversion, with 18 tasks and balanced coverage across modalities and difficulty\nlevels, serves as a practical testbed for daily benchmarking and comparative\nstudies.", "AI": {"tldr": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u673a\u5668\u5b66\u4e60\u4ee3\u7406\u80fd\u529b\uff0c\u672c\u6587\u63d0\u51faTAM Bench\u57fa\u51c6\uff0c\u6709\u4e09\u9879\u521b\u65b0\uff0c\u6784\u5efa\u4e0d\u540c\u89c4\u6a21\u5b50\u96c6\uff0cLite\u7248\u53ef\u7528\u4e8e\u65e5\u5e38\u6d4b\u8bd5\u548c\u5bf9\u6bd4\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5728\u4efb\u52a1\u8986\u76d6\u3001\u9886\u57df\u591a\u6837\u6027\u3001\u96be\u5ea6\u5efa\u6a21\u548c\u8bc4\u4f30\u4e25\u8c28\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u673a\u5668\u5b66\u4e60\u4ee3\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faTAM Bench\u57fa\u51c6\uff0c\u5305\u62ec\u57fa\u4e8e\u6d4f\u89c8\u5668\u81ea\u52a8\u5316\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4efb\u52a1\u83b7\u53d6\u7cfb\u7edf\u3001\u57fa\u4e8e\u6392\u884c\u699c\u7684\u96be\u5ea6\u5efa\u6a21\u673a\u5236\u3001\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u6784\u5efa\u4e0d\u540c\u89c4\u6a21\u7684\u57fa\u51c6\u5b50\u96c6\u3002", "result": "\u6784\u5efa\u4e86Lite\u3001Medium\u548cFull\u4e09\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u57fa\u51c6\u5b50\u96c6\uff0cLite\u7248\u670918\u4e2a\u4efb\u52a1\uff0c\u5404\u6a21\u6001\u548c\u96be\u5ea6\u7ea7\u522b\u8986\u76d6\u5747\u8861\u3002", "conclusion": "TAM Bench\u662f\u4e00\u4e2a\u591a\u6837\u5316\u3001\u73b0\u5b9e\u4e14\u7ed3\u6784\u5316\u7684\u57fa\u51c6\uff0c\u53ef\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4ee3\u7406\uff0cLite\u7248\u53ef\u4f5c\u4e3a\u65e5\u5e38\u57fa\u51c6\u6d4b\u8bd5\u548c\u6bd4\u8f83\u7814\u7a76\u7684\u5b9e\u7528\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2509.09128", "pdf": "https://arxiv.org/pdf/2509.09128", "abs": "https://arxiv.org/abs/2509.09128", "authors": ["Emam Hossain", "Md Osman Gani"], "title": "Learning What Matters: Causal Time Series Modeling for Arctic Sea Ice Prediction", "categories": ["cs.LG"], "comment": "Accepted and presented at the AI4TS Workshop @ IJCAI 2025\n  (non-archival)", "summary": "Conventional machine learning and deep learning models typically rely on\ncorrelation-based learning, which often fails to distinguish genuine causal\nrelationships from spurious associations, limiting their robustness,\ninterpretability, and ability to generalize. To overcome these limitations, we\nintroduce a causality-aware deep learning framework that integrates\nMultivariate Granger Causality (MVGC) and PCMCI+ for causal feature selection\nwithin a hybrid neural architecture. Leveraging 43 years (1979-2021) of Arctic\nSea Ice Extent (SIE) data and associated ocean-atmospheric variables at daily\nand monthly resolutions, the proposed method identifies causally influential\npredictors, prioritizes direct causes of SIE dynamics, reduces unnecessary\nfeatures, and enhances computational efficiency. Experimental results show that\nincorporating causal inputs leads to improved prediction accuracy and\ninterpretability across varying lead times. While demonstrated on Arctic SIE\nforecasting, the framework is broadly applicable to other dynamic,\nhigh-dimensional domains, offering a scalable approach that advances both the\ntheoretical foundations and practical performance of causality-informed\npredictive modeling.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u611f\u77e5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408MVGC\u548cPCMCI+\u8fdb\u884c\u56e0\u679c\u7279\u5f81\u9009\u62e9\uff0c\u7528\u5317\u6781\u6d77\u51b0\u8303\u56f4\u6570\u636e\u9a8c\u8bc1\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u5176\u4ed6\u9886\u57df\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u57fa\u4e8e\u76f8\u5173\u6027\u5b66\u4e60\uff0c\u96be\u4ee5\u533a\u5206\u56e0\u679c\u5173\u7cfb\uff0c\u9650\u5236\u4e86\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5f15\u5165\u7ed3\u5408MVGC\u548cPCMCI+\u7684\u56e0\u679c\u611f\u77e5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u6df7\u5408\u795e\u7ecf\u67b6\u6784\u4e2d\u8fdb\u884c\u56e0\u679c\u7279\u5f81\u9009\u62e9\u3002", "result": "\u7ed3\u5408\u56e0\u679c\u8f93\u5165\u63d0\u9ad8\u4e86\u4e0d\u540c\u9884\u6d4b\u65f6\u957f\u4e0b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u5176\u4ed6\u52a8\u6001\u9ad8\u7ef4\u9886\u57df\uff0c\u63a8\u52a8\u4e86\u56e0\u679c\u9884\u6d4b\u5efa\u6a21\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2509.09356", "pdf": "https://arxiv.org/pdf/2509.09356", "abs": "https://arxiv.org/abs/2509.09356", "authors": ["Abdel Hakim Drid", "Vincenzo Suriani", "Daniele Nardi", "Abderrezzak Debilou"], "title": "Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning", "categories": ["cs.AI", "cs.RO"], "comment": "The 19th International Conference on Intelligent Autonomous Systems\n  (IAS 19), 2025, Genoa", "summary": "Navigating and understanding complex and unknown environments autonomously\ndemands more than just basic perception and movement from embodied agents.\nTruly effective exploration requires agents to possess higher-level cognitive\nabilities, the ability to reason about their surroundings, and make more\ninformed decisions regarding exploration strategies. However, traditional RL\napproaches struggle to balance efficient exploration and semantic understanding\ndue to limited cognitive capabilities embedded in the small policies for the\nagents, leading often to human drivers when dealing with semantic exploration.\nIn this paper, we address this challenge by presenting a novel Deep\nReinforcement Learning (DRL) architecture that is specifically designed for\nresource efficient semantic exploration. A key methodological contribution is\nthe integration of a Vision-Language Model (VLM) common-sense through a layered\nreward function. The VLM query is modeled as a dedicated action, allowing the\nagent to strategically query the VLM only when deemed necessary for gaining\nexternal guidance, thereby conserving resources. This mechanism is combined\nwith a curriculum learning strategy designed to guide learning at different\nlevels of complexity to ensure robust and stable learning. Our experimental\nevaluation results convincingly demonstrate that our agent achieves\nsignificantly enhanced object discovery rates and develops a learned capability\nto effectively navigate towards semantically rich regions. Furthermore, it also\nshows a strategic mastery of when to prompt for external environmental\ninformation. By demonstrating a practical and scalable method for embedding\ncommon-sense semantic reasoning with autonomous agents, this research provides\na novel approach to pursuing a fully intelligent and self-guided exploration in\nrobotics.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u8d44\u6e90\u9ad8\u6548\u8bed\u4e49\u63a2\u7d22\u7684DRL\u67b6\u6784\uff0c\u7ed3\u5408VLM\u5e38\u8bc6\u548c\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u5b9e\u9a8c\u663e\u793a\u63d0\u5347\u5bf9\u8c61\u53d1\u73b0\u7387\u7b49\uff0c\u4e3a\u673a\u5668\u4eba\u81ea\u4e3b\u63a2\u7d22\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfRL\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u9ad8\u6548\u63a2\u7d22\u548c\u8bed\u4e49\u7406\u89e3\uff0c\u5728\u8bed\u4e49\u63a2\u7d22\u4e2d\u5e38\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u9700\u89e3\u51b3\u6b64\u6311\u6218\u3002", "method": "\u63d0\u51fa\u65b0\u9896DRL\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u5956\u52b1\u51fd\u6570\u96c6\u6210VLM\u5e38\u8bc6\uff0c\u5c06VLM\u67e5\u8be2\u5efa\u6a21\u4e3a\u4e13\u7528\u52a8\u4f5c\uff0c\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u4ee3\u7406\u663e\u8457\u63d0\u9ad8\u5bf9\u8c61\u53d1\u73b0\u7387\uff0c\u5b66\u4f1a\u6709\u6548\u5bfc\u822a\u5230\u8bed\u4e49\u4e30\u5bcc\u533a\u57df\uff0c\u638c\u63e1\u4f55\u65f6\u83b7\u53d6\u5916\u90e8\u73af\u5883\u4fe1\u606f\u7684\u7b56\u7565\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5728\u81ea\u4e3b\u4ee3\u7406\u4e2d\u5d4c\u5165\u5e38\u8bc6\u8bed\u4e49\u63a8\u7406\u7684\u5b9e\u7528\u53ef\u6269\u5c55\u65b9\u6cd5\uff0c\u4e3a\u673a\u5668\u4eba\u5168\u667a\u80fd\u81ea\u5f15\u5bfc\u63a2\u7d22\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2509.09135", "pdf": "https://arxiv.org/pdf/2509.09135", "abs": "https://arxiv.org/abs/2509.09135", "authors": ["Xuefeng Wang", "Lei Zhang", "Henglin Pu", "Ahmed H. Qureshi", "Husheng Li"], "title": "Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning", "categories": ["cs.LG", "cs.MA"], "comment": "19 pages, 10 figures", "summary": "Existing reinforcement learning (RL) methods struggle with complex dynamical\nsystems that demand interactions at high frequencies or irregular time\nintervals. Continuous-time RL (CTRL) has emerged as a promising alternative by\nreplacing discrete-time Bellman recursion with differential value functions\ndefined as viscosity solutions of the Hamilton--Jacobi--Bellman (HJB) equation.\nWhile CTRL has shown promise, its applications have been largely limited to the\nsingle-agent domain. This limitation stems from two key challenges: (i)\nconventional solution methods for HJB equations suffer from the curse of\ndimensionality (CoD), making them intractable in high-dimensional systems; and\n(ii) even with HJB-based learning approaches, accurately approximating\ncentralized value functions in multi-agent settings remains difficult, which in\nturn destabilizes policy training. In this paper, we propose a CT-MARL\nframework that uses physics-informed neural networks (PINNs) to approximate\nHJB-based value functions at scale. To ensure the value is consistent with its\ndifferential structure, we align value learning with value-gradient learning by\nintroducing a Value Gradient Iteration (VGI) module that iteratively refines\nvalue gradients along trajectories. This improves gradient fidelity, in turn\nyielding more accurate values and stronger policy learning. We evaluate our\nmethod using continuous-time variants of standard benchmarks, including\nmulti-agent particle environment (MPE) and multi-agent MuJoCo. Our results\ndemonstrate that our approach consistently outperforms existing continuous-time\nRL baselines and scales to complex multi-agent dynamics.", "AI": {"tldr": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5904\u7406\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u6709\u56f0\u96be\uff0c\u8fde\u7eed\u65f6\u95f4RL\uff08CTRL\uff09\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51faCT - MARL\u6846\u67b6\uff0c\u7528PINNs\u8fd1\u4f3cHJB\u503c\u51fd\u6570\uff0c\u5f15\u5165VGI\u6a21\u5757\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709CTRL\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u667a\u80fd\u4f53\u9886\u57df\uff0c\u4f20\u7edfHJB\u65b9\u7a0b\u6c42\u89e3\u65b9\u6cd5\u6709\u7ef4\u6570\u707e\u96be\uff0c\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u51c6\u786e\u8fd1\u4f3c\u96c6\u4e2d\u5f0f\u503c\u51fd\u6570\u56f0\u96be\uff0c\u5f71\u54cd\u7b56\u7565\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faCT - MARL\u6846\u67b6\uff0c\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u8fd1\u4f3cHJB\u503c\u51fd\u6570\uff0c\u5f15\u5165\u503c\u68af\u5ea6\u8fed\u4ee3\uff08VGI\uff09\u6a21\u5757\uff0c\u6cbf\u8f68\u8ff9\u8fed\u4ee3\u7ec6\u5316\u503c\u68af\u5ea6\u3002", "result": "\u5728\u591a\u667a\u80fd\u4f53\u7c92\u5b50\u73af\u5883\uff08MPE\uff09\u548c\u591a\u667a\u80fd\u4f53MuJoCo\u7b49\u8fde\u7eed\u65f6\u95f4\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u8fde\u7eed\u65f6\u95f4RL\u57fa\u7ebf\uff0c\u80fd\u5904\u7406\u590d\u6742\u591a\u667a\u80fd\u4f53\u52a8\u6001\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684CT - MARL\u6846\u67b6\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u590d\u6742\u591a\u667a\u80fd\u4f53\u52a8\u6001\u7cfb\u7edf\uff0c\u6bd4\u73b0\u6709\u8fde\u7eed\u65f6\u95f4RL\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2509.09448", "pdf": "https://arxiv.org/pdf/2509.09448", "abs": "https://arxiv.org/abs/2509.09448", "authors": ["Minhyuk Kim", "Seungyoon Lee", "Heuiseok Lim"], "title": "TORSO: Template-Oriented Reasoning Towards General Tasks", "categories": ["cs.AI"], "comment": "9 pages, 3 figures", "summary": "The approaches that guide Large Language Models (LLMs) to emulate human\nreasoning during response generation have emerged as an effective method for\nenabling them to solve complex problems in a step-by-step manner, thereby\nachieving superior performance. However, most existing approaches using\nfew-shot prompts to generate responses heavily depend on the provided examples,\nlimiting the utilization of the model's inherent reasoning capabilities.\nMoreover, constructing task-specific few-shot prompts is often costly and may\nlead to inconsistencies across different tasks. In this work, we introduce\nTemplate-Oriented Reasoning (TORSO), which elicits the model to utilize\ninternal reasoning abilities to generate proper responses across various tasks\nwithout the need for manually crafted few-shot examples. Our experimental\nresults demonstrate that TORSO achieves strong performance on diverse LLMs\nbenchmarks with reasonable rationales.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aTORSO\u7684\u65b9\u6cd5\uff0c\u80fd\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u9700\u624b\u5de5\u5236\u4f5c\u5c11\u6837\u672c\u793a\u4f8b\u7684\u60c5\u51b5\u4e0b\u5229\u7528\u5185\u90e8\u63a8\u7406\u80fd\u529b\u751f\u6210\u54cd\u5e94\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u4f7f\u7528\u5c11\u6837\u672c\u63d0\u793a\u751f\u6210\u54cd\u5e94\u7684\u65b9\u6cd5\u4f9d\u8d56\u793a\u4f8b\uff0c\u9650\u5236\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u6784\u5efa\u7279\u5b9a\u4efb\u52a1\u63d0\u793a\u6210\u672c\u9ad8\u3001\u6613\u5bfc\u81f4\u4efb\u52a1\u95f4\u4e0d\u4e00\u81f4\u3002", "method": "\u5f15\u5165Template - Oriented Reasoning (TORSO)\uff0c\u4fc3\u4f7f\u6a21\u578b\u5229\u7528\u5185\u90e8\u63a8\u7406\u80fd\u529b\u751f\u6210\u4e0d\u540c\u4efb\u52a1\u7684\u5408\u9002\u54cd\u5e94\u3002", "result": "TORSO\u5728\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u51ed\u501f\u5408\u7406\u7684\u63a8\u7406\u53d6\u5f97\u4e86\u826f\u597d\u8868\u73b0\u3002", "conclusion": "TORSO\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u5229\u7528\u81ea\u8eab\u63a8\u7406\u80fd\u529b\u751f\u6210\u54cd\u5e94\uff0c\u65e0\u9700\u4f9d\u8d56\u5c11\u6837\u672c\u793a\u4f8b\u3002"}}
{"id": "2509.09146", "pdf": "https://arxiv.org/pdf/2509.09146", "abs": "https://arxiv.org/abs/2509.09146", "authors": ["Md Ibrahim Ibne Alam", "Ankur Senapati", "Anindo Mahmood", "Murat Yuksel", "Koushik Kar"], "title": "Peering Partner Recommendation for ISPs using Machine Learning", "categories": ["cs.LG"], "comment": "Submitted to IEEE Transactions on Machine Learning in Communications\n  and Networking", "summary": "Internet service providers (ISPs) need to connect with other ISPs to provide\nglobal connectivity services to their users. To ensure global connectivity,\nISPs can either use transit service(s) or establish direct peering\nrelationships between themselves via Internet exchange points (IXPs). Peering\noffers more room for ISP-specific optimizations and is preferred, but it often\ninvolves a lengthy and complex process. Automating peering partner selection\ncan enhance efficiency in the global Internet ecosystem. We explore the use of\npublicly available data on ISPs to develop a machine learning (ML) model that\ncan predict whether an ISP pair should peer or not. At first, we explore public\ndatabases, e.g., PeeringDB, CAIDA, etc., to gather data on ISPs. Then, we\nevaluate the performance of three broad types of ML models for predicting\npeering relationships: tree-based, neural network-based, and transformer-based.\nAmong these, we observe that tree-based models achieve the highest accuracy and\nefficiency in our experiments. The XGBoost model trained with publicly\navailable data showed promising performance, with a 98% accuracy rate in\npredicting peering partners. In addition, the model demonstrated great\nresilience to variations in time, space, and missing data. We envision that\nISPs can adopt our method to fully automate the peering partner selection\nprocess, thus transitioning to a more efficient and optimized Internet\necosystem.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u5229\u7528\u516c\u5f00\u6570\u636e\u6784\u5efa\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4bISP\u662f\u5426\u5e94\u5efa\u7acb\u5bf9\u7b49\u5173\u7cfb\uff0c\u6811\u57fa\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cXGBoost\u51c6\u786e\u7387\u8fbe98%\uff0c\u6709\u671b\u5b9e\u73b0\u81ea\u52a8\u9009\u62e9\u5bf9\u7b49\u4f19\u4f34\u3002", "motivation": "\u5bf9\u7b49\u8fde\u63a5\u8fc7\u7a0b\u5197\u957f\u590d\u6742\uff0c\u81ea\u52a8\u5316\u5bf9\u7b49\u4f19\u4f34\u9009\u62e9\u53ef\u63d0\u9ad8\u5168\u7403\u4e92\u8054\u7f51\u751f\u6001\u7cfb\u7edf\u7684\u6548\u7387\u3002", "method": "\u4ece\u516c\u5f00\u6570\u636e\u5e93\u6536\u96c6ISP\u6570\u636e\uff0c\u8bc4\u4f30\u6811\u57fa\u3001\u795e\u7ecf\u7f51\u7edc\u548c\u57fa\u4e8eTransformer\u7684\u4e09\u7c7b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u5bf9\u7b49\u5173\u7cfb\u7684\u6027\u80fd\u3002", "result": "\u6811\u57fa\u6a21\u578b\u5728\u5b9e\u9a8c\u4e2d\u51c6\u786e\u6027\u548c\u6548\u7387\u6700\u9ad8\uff0c\u7528\u516c\u5f00\u6570\u636e\u8bad\u7ec3\u7684XGBoost\u6a21\u578b\u9884\u6d4b\u5bf9\u7b49\u4f19\u4f34\u51c6\u786e\u7387\u8fbe98%\uff0c\u4e14\u5bf9\u65f6\u95f4\u3001\u7a7a\u95f4\u53d8\u5316\u548c\u6570\u636e\u7f3a\u5931\u6709\u5f88\u5f3a\u7684\u9002\u5e94\u6027\u3002", "conclusion": "ISP\u53ef\u91c7\u7528\u8be5\u65b9\u6cd5\u5b9e\u73b0\u5bf9\u7b49\u4f19\u4f34\u9009\u62e9\u8fc7\u7a0b\u7684\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u6784\u5efa\u66f4\u9ad8\u6548\u4f18\u5316\u7684\u4e92\u8054\u7f51\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2509.09467", "pdf": "https://arxiv.org/pdf/2509.09467", "abs": "https://arxiv.org/abs/2509.09467", "authors": ["Alex Dantart"], "title": "Inteligencia Artificial jur\u00eddica y el desaf\u00edo de la veracidad: an\u00e1lisis de alucinaciones, optimizaci\u00f3n de RAG y principios para una integraci\u00f3n responsable", "categories": ["cs.AI"], "comment": "in Spanish and English languages", "summary": "This technical report analyzes the challenge of \"hallucinations\" (false\ninformation) in LLMs applied to law. It examines their causes, manifestations,\nand the effectiveness of the RAG mitigation strategy, highlighting its\nlimitations and proposing holistic optimizations. The paper explores the\nethical and regulatory implications, emphasizing human oversight as an\nirreplaceable role. It concludes that the solution lies not in incrementally\nimproving generative models, but in adopting a \"consultative\" AI paradigm that\nprioritizes veracity and traceability, acting as a tool to amplify, not\nreplace, professional judgment.\n  --\n  Este informe t\\'ecnico analiza el desaf\\'io de las \"alucinaciones\"\n(informaci\\'on falsa) en los LLMs aplicados al derecho. Se examinan sus causas,\nmanifestaciones y la efectividad de la estrategia de mitigaci\\'on RAG,\nexponiendo sus limitaciones y proponiendo optimizaciones hol\\'isticas. Se\nexploran las implicaciones \\'eticas y regulatorias, enfatizando la\nsupervisi\\'on humana como un rol insustituible. El documento concluye que la\nsoluci\\'on no reside en mejorar incrementalmente los modelos generativos, sino\nen adoptar un paradigma de IA \"consultiva\" que priorice la veracidad y la\ntrazabilidad, actuando como una herramienta para amplificar, y no sustituir, el\njuicio profesional.", "AI": {"tldr": "\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u6cd5\u5f8b\u9886\u57df\u65f6\u7684\u201c\u5e7b\u89c9\u201d\u95ee\u9898\uff0c\u63a2\u8ba8RAG\u7b56\u7565\u5c40\u9650\u6027\u5e76\u63d0\u51fa\u4f18\u5316\uff0c\u5f3a\u8c03\u4eba\u7c7b\u76d1\u7763\uff0c\u4e3b\u5f20\u91c7\u7528\u201c\u54a8\u8be2\u5f0f\u201dAI\u8303\u5f0f\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u6cd5\u5f8b\u9886\u57df\u65f6\u51fa\u73b0\u201c\u5e7b\u89c9\u201d\uff08\u865a\u5047\u4fe1\u606f\uff09\u7684\u6311\u6218\u3002", "method": "\u5206\u6790\u201c\u5e7b\u89c9\u201d\u7684\u539f\u56e0\u3001\u8868\u73b0\uff0c\u7814\u7a76RAG\u7f13\u89e3\u7b56\u7565\u6709\u6548\u6027\uff0c\u63a2\u7d22\u4f26\u7406\u548c\u76d1\u7ba1\u5f71\u54cd\u3002", "result": "\u53d1\u73b0RAG\u7b56\u7565\u6709\u5c40\u9650\u6027\uff0c\u9700\u6574\u4f53\u4f18\u5316\uff0c\u4eba\u7c7b\u76d1\u7763\u4e0d\u53ef\u66ff\u4ee3\u3002", "conclusion": "\u89e3\u51b3\u65b9\u6848\u662f\u91c7\u7528\u201c\u54a8\u8be2\u5f0f\u201dAI\u8303\u5f0f\uff0c\u589e\u5f3a\u800c\u975e\u53d6\u4ee3\u4e13\u4e1a\u5224\u65ad\u3002"}}
{"id": "2509.09155", "pdf": "https://arxiv.org/pdf/2509.09155", "abs": "https://arxiv.org/abs/2509.09155", "authors": ["Maria Risques", "Kratika Bhagtani", "Amit Kumar Singh Yadav", "Edward J. Delp"], "title": "HISPASpoof: A New Dataset For Spanish Speech Forensics", "categories": ["cs.LG", "cs.AI"], "comment": "8 pages, 1 figure, 10 tables, being submitted to ICASSP 2026 (IEEE\n  International Conference on Acoustics, Speech, and Signal Processing 2026)", "summary": "Zero-shot Voice Cloning (VC) and Text-to-Speech (TTS) methods have advanced\nrapidly, enabling the generation of highly realistic synthetic speech and\nraising serious concerns about their misuse. While numerous detectors have been\ndeveloped for English and Chinese, Spanish-spoken by over 600 million people\nworldwide-remains underrepresented in speech forensics. To address this gap, we\nintroduce HISPASpoof, the first large-scale Spanish dataset designed for\nsynthetic speech detection and attribution. It includes real speech from public\ncorpora across six accents and synthetic speech generated with six zero-shot\nTTS systems. We evaluate five representative methods, showing that detectors\ntrained on English fail to generalize to Spanish, while training on HISPASpoof\nsubstantially improves detection. We also evaluate synthetic speech attribution\nperformance on HISPASpoof, i.e., identifying the generation method of synthetic\nspeech. HISPASpoof thus provides a critical benchmark for advancing reliable\nand inclusive speech forensics in Spanish.", "AI": {"tldr": "\u5f15\u5165\u9996\u4e2a\u5927\u89c4\u6a21\u897f\u73ed\u7259\u8bed\u5408\u6210\u8bed\u97f3\u68c0\u6d4b\u4e0e\u6eaf\u6e90\u6570\u636e\u96c6HISPASpoof\uff0c\u8bc4\u4f30\u591a\u79cd\u65b9\u6cd5\uff0c\u663e\u793a\u5176\u5bf9\u897f\u73ed\u7259\u8bed\u8bed\u97f3\u68c0\u6d4b\u6709\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u8bed\u97f3\u68c0\u6d4b\u7814\u7a76\u4e2d\u897f\u73ed\u7259\u8bed\u6570\u636e\u4e0d\u8db3\uff0c\u9700\u586b\u8865\u8be5\u9886\u57df\u7a7a\u767d\u3002", "method": "\u521b\u5efa\u5305\u542b\u516d\u79cd\u53e3\u97f3\u771f\u5b9e\u8bed\u97f3\u53ca\u516d\u79cd\u96f6\u6837\u672cTTS\u7cfb\u7edf\u751f\u6210\u7684\u5408\u6210\u8bed\u97f3\u7684HISPASpoof\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e94\u79cd\u4ee3\u8868\u6027\u65b9\u6cd5\u3002", "result": "\u5728\u82f1\u8bed\u4e0a\u8bad\u7ec3\u7684\u68c0\u6d4b\u5668\u65e0\u6cd5\u6cdb\u5316\u5230\u897f\u73ed\u7259\u8bed\uff0c\u5728HISPASpoof\u4e0a\u8bad\u7ec3\u53ef\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\uff0c\u540c\u65f6\u8bc4\u4f30\u4e86\u5408\u6210\u8bed\u97f3\u6eaf\u6e90\u6027\u80fd\u3002", "conclusion": "HISPASpoof\u4e3a\u5b8c\u5584\u897f\u73ed\u7259\u8bed\u8bed\u97f3\u53d6\u8bc1\u63d0\u4f9b\u4e86\u5173\u952e\u57fa\u51c6\u3002"}}
{"id": "2509.09498", "pdf": "https://arxiv.org/pdf/2509.09498", "abs": "https://arxiv.org/abs/2509.09498", "authors": ["Haoran Xu", "Jiacong Hu", "Ke Zhang", "Lei Yu", "Yuxin Tang", "Xinyuan Song", "Yiqun Duan", "Lynn Ai", "Bill Shi"], "title": "SEDM: Scalable Self-Evolving Distributed Memory for Agents", "categories": ["cs.AI"], "comment": null, "summary": "Long-term multi-agent systems inevitably generate vast amounts of\ntrajectories and historical interactions, which makes efficient memory\nmanagement essential for both performance and scalability. Existing methods\ntypically depend on vector retrieval and hierarchical storage, yet they are\nprone to noise accumulation, uncontrolled memory expansion, and limited\ngeneralization across domains. To address these challenges, we present SEDM,\nSelf-Evolving Distributed Memory, a verifiable and adaptive framework that\ntransforms memory from a passive repository into an active, self-optimizing\ncomponent. SEDM integrates verifiable write admission based on reproducible\nreplay, a self-scheduling memory controller that dynamically ranks and\nconsolidates entries according to empirical utility, and cross-domain knowledge\ndiffusion that abstracts reusable insights to support transfer across\nheterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM\nimproves reasoning accuracy while reducing token overhead compared with strong\nmemory baselines, and further enables knowledge distilled from fact\nverification to enhance multi-hop reasoning. The results highlight SEDM as a\nscalable and sustainable memory mechanism for open-ended multi-agent\ncollaboration. The code will be released in the later stage of this project.", "AI": {"tldr": "\u63d0\u51faSEDM\u6846\u67b6\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5185\u5b58\u7ba1\u7406\u96be\u9898\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u80fd\u63d0\u5347\u63a8\u7406\u51c6\u786e\u6027\u3001\u51cf\u5c11\u5f00\u9500\uff0c\u662f\u53ef\u6269\u5c55\u53ef\u6301\u7eed\u7684\u5185\u5b58\u673a\u5236\u3002", "motivation": "\u957f\u671f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4ea7\u751f\u5927\u91cf\u8f68\u8ff9\u548c\u4ea4\u4e92\uff0c\u73b0\u6709\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\u5b58\u5728\u566a\u58f0\u79ef\u7d2f\u3001\u5185\u5b58\u81a8\u80c0\u548c\u8de8\u9886\u57df\u6cdb\u5316\u53d7\u9650\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSEDM\u6846\u67b6\uff0c\u96c6\u6210\u57fa\u4e8e\u53ef\u91cd\u73b0\u56de\u653e\u7684\u53ef\u9a8c\u8bc1\u5199\u5165\u8bb8\u53ef\u3001\u6839\u636e\u7ecf\u9a8c\u6548\u7528\u52a8\u6001\u6392\u5e8f\u548c\u5408\u5e76\u6761\u76ee\u7684\u81ea\u8c03\u5ea6\u5185\u5b58\u63a7\u5236\u5668\uff0c\u4ee5\u53ca\u652f\u6301\u8de8\u5f02\u6784\u4efb\u52a1\u8fc1\u79fb\u7684\u8de8\u9886\u57df\u77e5\u8bc6\u6269\u6563\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8868\u660e\uff0cSEDM\u6bd4\u5f3a\u5185\u5b58\u57fa\u7ebf\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\u3001\u51cf\u5c11\u4ee4\u724c\u5f00\u9500\uff0c\u4e14\u80fd\u5229\u7528\u4e8b\u5b9e\u9a8c\u8bc1\u63d0\u70bc\u7684\u77e5\u8bc6\u589e\u5f3a\u591a\u8df3\u63a8\u7406\u3002", "conclusion": "SEDM\u662f\u7528\u4e8e\u5f00\u653e\u5f0f\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u53ef\u6269\u5c55\u548c\u53ef\u6301\u7eed\u7684\u5185\u5b58\u673a\u5236\u3002"}}
{"id": "2509.09168", "pdf": "https://arxiv.org/pdf/2509.09168", "abs": "https://arxiv.org/abs/2509.09168", "authors": ["Omar Erak", "Omar Alhussein", "Hatem Abou-Zeid", "Mehdi Bennis"], "title": "Adaptive Pareto-Optimal Token Merging for Edge Transformer Models in Semantic Communication", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "comment": "To appear in IEEE Globecom 2025", "summary": "Large-scale transformer models have emerged as a powerful tool for semantic\ncommunication systems, enabling edge devices to extract rich representations\nfor robust inference across noisy wireless channels. However, their substantial\ncomputational demands remain a major barrier to practical deployment in\nresource-constrained 6G networks. In this paper, we present a training-free\nframework for adaptive token merging in pretrained vision transformers to\njointly reduce inference time and transmission resource usage. We formulate the\nselection of per-layer merging proportions as a multi-objective optimization\nproblem to balance accuracy and computational cost. We employ Gaussian\nprocess-based Bayesian optimization to construct a Pareto frontier of optimal\nconfigurations, enabling flexible runtime adaptation to dynamic application\nrequirements and channel conditions. Extensive experiments demonstrate that our\nmethod consistently outperforms other baselines and achieves significant\nreductions in floating-point operations while maintaining competitive accuracy\nacross a wide range of signal-to-noise ratio (SNR) conditions. Additional\nresults highlight the effectiveness of adaptive policies that adjust merging\naggressiveness in response to channel quality, providing a practical mechanism\nto trade off latency and semantic fidelity on demand. These findings establish\na scalable and efficient approach for deploying transformer-based semantic\ncommunication in future edge intelligence systems.", "AI": {"tldr": "\u63d0\u51fa\u9884\u8bad\u7ec3\u89c6\u89c9\u53d8\u538b\u5668\u81ea\u9002\u5e94\u4ee4\u724c\u5408\u5e76\u514d\u8bad\u7ec3\u6846\u67b6\uff0c\u964d\u4f4e\u63a8\u7406\u65f6\u95f4\u548c\u4f20\u8f93\u8d44\u6e90\u4f7f\u7528\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6027\u80fd\u4f18\u3002", "motivation": "\u5927\u89c4\u6a21\u53d8\u538b\u5668\u6a21\u578b\u8ba1\u7b97\u9700\u6c42\u5927\uff0c\u963b\u788d\u5176\u5728\u8d44\u6e90\u53d7\u96506G\u7f51\u7edc\u7684\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u5c06\u6bcf\u5c42\u5408\u5e76\u6bd4\u4f8b\u9009\u62e9\u6784\u5efa\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u7528\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u6784\u5efa\u5e15\u7d2f\u6258\u6700\u4f18\u914d\u7f6e\u524d\u6cbf\u3002", "result": "\u65b9\u6cd5\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\uff0c\u51cf\u5c11\u6d6e\u70b9\u8fd0\u7b97\uff0c\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\uff1b\u81ea\u9002\u5e94\u7b56\u7565\u6709\u6548\u3002", "conclusion": "\u4e3a\u672a\u6765\u8fb9\u7f18\u667a\u80fd\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u8bed\u4e49\u901a\u4fe1\u90e8\u7f72\u63d0\u4f9b\u53ef\u6269\u5c55\u9ad8\u6548\u65b9\u6cd5\u3002"}}
{"id": "2509.09541", "pdf": "https://arxiv.org/pdf/2509.09541", "abs": "https://arxiv.org/abs/2509.09541", "authors": ["Hala Hawashin", "Mina Abbaszadeh", "Nicholas Joseph", "Beth Pearson", "Martha Lewis", "Mehrnoosh sadrzadeh"], "title": "Compositional Concept Generalization with Variational Quantum Circuits", "categories": ["cs.AI"], "comment": "Accepted to: 2025 IEEE International Conference on Quantum Artificial\n  Intelligence (QAI), Naples, Italy, Nov 2-5, 2025. This is the authors'\n  accepted manuscript (AAM). An IEEE copyright notice appears on page 1. The\n  final published version will appear in IEEE Xplore; DOI to be added when\n  available", "summary": "Compositional generalization is a key facet of human cognition, but lacking\nin current AI tools such as vision-language models. Previous work examined\nwhether a compositional tensor-based sentence semantics can overcome the\nchallenge, but led to negative results. We conjecture that the increased\ntraining efficiency of quantum models will improve performance in these tasks.\nWe interpret the representations of compositional tensor-based models in\nHilbert spaces and train Variational Quantum Circuits to learn these\nrepresentations on an image captioning task requiring compositional\ngeneralization. We used two image encoding techniques: a multi-hot encoding\n(MHE) on binary image vectors and an angle/amplitude encoding on image vectors\ntaken from the vision-language model CLIP. We achieve good proof-of-concept\nresults using noisy MHE encodings. Performance on CLIP image vectors was more\nmixed, but still outperformed classical compositional models.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5b50\u6a21\u578b\u5728\u9700\u8981\u7ec4\u5408\u6cdb\u5316\u7684\u56fe\u50cf\u5b57\u5e55\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7528\u4e0d\u540c\u56fe\u50cf\u7f16\u7801\u6280\u672f\u8bad\u7ec3\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff0c\u53d6\u5f97\u4e00\u5b9a\u6210\u679c\u3002", "motivation": "\u5f53\u524dAI\u5de5\u5177\u5982\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\uff0c\u5148\u524d\u57fa\u4e8e\u7ec4\u5408\u5f20\u91cf\u7684\u53e5\u5b50\u8bed\u4e49\u7814\u7a76\u7ed3\u679c\u4e0d\u4f73\uff0c\u63a8\u6d4b\u91cf\u5b50\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u63d0\u5347\u53ef\u6539\u5584\u4efb\u52a1\u8868\u73b0\u3002", "method": "\u5728\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u89e3\u91ca\u7ec4\u5408\u5f20\u91cf\u6a21\u578b\u7684\u8868\u793a\uff0c\u8bad\u7ec3\u53d8\u5206\u91cf\u5b50\u7535\u8def\u5b66\u4e60\u8868\u793a\uff0c\u4f7f\u7528\u591a\u70ed\u7f16\u7801\uff08MHE\uff09\u548c\u89d2\u5ea6/\u5e45\u5ea6\u7f16\u7801\u4e24\u79cd\u56fe\u50cf\u7f16\u7801\u6280\u672f\u3002", "result": "\u4f7f\u7528\u6709\u566a\u58f0\u7684MHE\u7f16\u7801\u53d6\u5f97\u6982\u5ff5\u9a8c\u8bc1\u7684\u826f\u597d\u7ed3\u679c\uff0c\u5728CLIP\u56fe\u50cf\u5411\u91cf\u4e0a\u8868\u73b0\u4e0d\u4e00\uff0c\u4f46\u4ecd\u4f18\u4e8e\u7ecf\u5178\u7ec4\u5408\u6a21\u578b\u3002", "conclusion": "\u91cf\u5b50\u6a21\u578b\u5728\u9700\u8981\u7ec4\u5408\u6cdb\u5316\u7684\u56fe\u50cf\u5b57\u5e55\u4efb\u52a1\u4e2d\u6709\u4e00\u5b9a\u6f5c\u529b\uff0c\u53ef\u6539\u5584\u7ec4\u5408\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.09176", "pdf": "https://arxiv.org/pdf/2509.09176", "abs": "https://arxiv.org/abs/2509.09176", "authors": ["Jun-Hao Chen", "Yu-Chien Huang", "Yun-Cheng Tsai", "Samuel Yen-Chi Chen"], "title": "Quantum Machine Learning, Quantitative Trading, Reinforcement Learning, Deep Learning", "categories": ["cs.LG", "cs.CY"], "comment": null, "summary": "The convergence of quantum-inspired neural networks and deep reinforcement\nlearning offers a promising avenue for financial trading. We implemented a\ntrading agent for USD/TWD by integrating Quantum Long Short-Term Memory (QLSTM)\nfor short-term trend prediction with Quantum Asynchronous Advantage\nActor-Critic (QA3C), a quantum-enhanced variant of the classical A3C. Trained\non data from 2000-01-01 to 2025-04-30 (80\\% training, 20\\% testing), the\nlong-only agent achieves 11.87\\% return over around 5 years with 0.92\\% max\ndrawdown, outperforming several currency ETFs. We detail state design (QLSTM\nfeatures and indicators), reward function for trend-following/risk control, and\nmulti-core training. Results show hybrid models yield competitive FX trading\nperformance. Implications include QLSTM's effectiveness for small-profit trades\nwith tight risk and future enhancements. Key hyperparameters: QLSTM sequence\nlength$=$4, QA3C workers$=$8. Limitations: classical quantum simulation and\nsimplified strategy. \\footnote{The views expressed in this article are those of\nthe authors and do not represent the views of Wells Fargo. This article is for\ninformational purposes only. Nothing contained in this article should be\nconstrued as investment advice. Wells Fargo makes no express or implied\nwarranties and expressly disclaims all legal, tax, and accounting implications\nrelated to this article.", "AI": {"tldr": "\u7ed3\u5408\u91cf\u5b50\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u4e0e\u91cf\u5b50\u5f02\u6b65\u4f18\u52bf\u6f14\u5458 - \u8bc4\u8bba\u5bb6\u7b97\u6cd5\u5b9e\u73b0\u7f8e\u5143/\u65b0\u53f0\u5e01\u4ea4\u6613\u4ee3\u7406\uff0c\u8868\u73b0\u4f18\u4e8e\u90e8\u5206\u8d27\u5e01ETF\uff0c\u663e\u793a\u6df7\u5408\u6a21\u578b\u5728\u5916\u6c47\u4ea4\u6613\u6709\u7ade\u4e89\u529b\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u542f\u53d1\u795e\u7ecf\u7f51\u7edc\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u878d\u5408\u5728\u91d1\u878d\u4ea4\u6613\u7684\u5e94\u7528\uff0c\u5b9e\u73b0\u66f4\u4f18\u7684\u5916\u6c47\u4ea4\u6613\u7b56\u7565\u3002", "method": "\u5c06\u91cf\u5b50\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08QLSTM\uff09\u7528\u4e8e\u77ed\u671f\u8d8b\u52bf\u9884\u6d4b\uff0c\u4e0e\u91cf\u5b50\u5f02\u6b65\u4f18\u52bf\u6f14\u5458 - \u8bc4\u8bba\u5bb6\uff08QA3C\uff09\u7b97\u6cd5\u7ed3\u5408\uff0c\u5b9e\u73b0\u4ea4\u6613\u4ee3\u7406\uff0c\u8be6\u7ec6\u8bbe\u8ba1\u72b6\u6001\u3001\u5956\u52b1\u51fd\u6570\u5e76\u8fdb\u884c\u591a\u6838\u8bad\u7ec3\u3002", "result": "\u4ec5\u505a\u591a\u7684\u4ea4\u6613\u4ee3\u7406\u5728\u7ea65\u5e74\u5b9e\u73b011.87%\u7684\u56de\u62a5\uff0c\u6700\u5927\u56de\u64a40.92%\uff0c\u4f18\u4e8e\u591a\u4e2a\u8d27\u5e01ETF\u3002", "conclusion": "\u6df7\u5408\u6a21\u578b\u5728\u5916\u6c47\u4ea4\u6613\u4e2d\u6709\u6709\u7ade\u4e89\u529b\u7684\u8868\u73b0\uff0cQLSTM\u9002\u7528\u4e8e\u4f4e\u5229\u6da6\u3001\u4e25\u63a7\u98ce\u9669\u7684\u4ea4\u6613\uff0c\u5b58\u5728\u7ecf\u5178\u91cf\u5b50\u6a21\u62df\u548c\u7b56\u7565\u7b80\u5316\u7684\u5c40\u9650\u3002"}}
{"id": "2509.09560", "pdf": "https://arxiv.org/pdf/2509.09560", "abs": "https://arxiv.org/abs/2509.09560", "authors": ["Shulai Zhang", "Ao Xu", "Quan Chen", "Han Zhao", "Weihao Cui", "Ningxin Zheng", "Haibin Lin", "Xin Liu", "Minyi Guo"], "title": "Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Embodied AI systems operate in dynamic environments, requiring seamless\nintegration of perception and generation modules to process high-frequency\ninput and output demands. Traditional sequential computation patterns, while\neffective in ensuring accuracy, face significant limitations in achieving the\nnecessary \"thinking\" frequency for real-world applications. In this work, we\npresent Auras, an algorithm-system co-designed inference framework to optimize\nthe inference frequency of embodied AI agents. Auras disaggregates the\nperception and generation and provides controlled pipeline parallelism for them\nto achieve high and stable throughput. Faced with the data staleness problem\nthat appears when the parallelism is increased, Auras establishes a public\ncontext for perception and generation to share, thereby promising the accuracy\nof embodied agents. Experimental results show that Auras improves throughput by\n2.54x on average while achieving 102.7% of the original accuracy, demonstrating\nits efficacy in overcoming the constraints of sequential computation and\nproviding high throughput.", "AI": {"tldr": "\u63d0\u51faAuras\u63a8\u7406\u6846\u67b6\u4f18\u5316\u5177\u8eabAI\u4ee3\u7406\u63a8\u7406\u9891\u7387\uff0c\u80fd\u63d0\u9ad8\u541e\u5410\u91cf\u4e14\u4fdd\u8bc1\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u987a\u5e8f\u8ba1\u7b97\u6a21\u5f0f\u5728\u5b9e\u73b0\u5177\u8eabAI\u7cfb\u7edf\u73b0\u5b9e\u5e94\u7528\u6240\u9700\u7684\u201c\u601d\u8003\u201d\u9891\u7387\u4e0a\u6709\u663e\u8457\u5c40\u9650\u3002", "method": "\u63d0\u51faAuras\u6846\u67b6\uff0c\u5c06\u611f\u77e5\u548c\u751f\u6210\u6a21\u5757\u5206\u79bb\u5e76\u63d0\u4f9b\u53ef\u63a7\u7684\u6d41\u6c34\u7ebf\u5e76\u884c\u5904\u7406\uff0c\u5efa\u7acb\u516c\u5171\u4e0a\u4e0b\u6587\u4ee5\u89e3\u51b3\u6570\u636e\u9648\u65e7\u95ee\u9898\u3002", "result": "Auras\u5e73\u5747\u63d0\u9ad8\u541e\u5410\u91cf2.54\u500d\uff0c\u8fbe\u5230\u539f\u51c6\u786e\u7387\u7684102.7%\u3002", "conclusion": "Auras\u80fd\u514b\u670d\u987a\u5e8f\u8ba1\u7b97\u7684\u9650\u5236\uff0c\u63d0\u4f9b\u9ad8\u541e\u5410\u91cf\u3002"}}
{"id": "2509.09177", "pdf": "https://arxiv.org/pdf/2509.09177", "abs": "https://arxiv.org/abs/2509.09177", "authors": ["Hanyi Mao", "Quanjia Xiao", "Lei Pang", "Haixiao Liu"], "title": "Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL", "categories": ["cs.LG"], "comment": null, "summary": "We propose FSPO (Fair Sequence Policy Optimization), a sequence-level\nreinforcement learning method for LLMs that enforces length-fair clipping\ndirectly in the importance-sampling (IS) weight space. We revisit\nsequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping\nis transplanted to sequences: a fixed clip range systematically reweights short\nvs. long responses, distorting the effective objective. Theoretically, we\nformalize length fairness via a Length Reweighting Error (LRE) and prove that\nsmall LRE yields a directional cosine guarantee between the clipped and true\nupdates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the\nsequence log-IS ratio with a band that applies a KL-corrected drift term and\nscales as $\\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,\nstabilizes training, and outperforms all baselines across multiple evaluation\ndatasets.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.09677", "pdf": "https://arxiv.org/pdf/2509.09677", "abs": "https://arxiv.org/abs/2509.09677", "authors": ["Akshit Sinha", "Arvindh Arun", "Shashwat Goel", "Steffen Staab", "Jonas Geiping"], "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Does continued scaling of large language models (LLMs) yield diminishing\nreturns? Real-world value often stems from the length of task an agent can\ncomplete. We start this work by observing the simple but counterintuitive fact\nthat marginal gains in single-step accuracy can compound into exponential\nimprovements in the length of a task a model can successfully complete. Then,\nwe argue that failures of LLMs when simple tasks are made longer arise from\nmistakes in execution, rather than an inability to reason. We propose isolating\nexecution capability, by explicitly providing the knowledge and plan needed to\nsolve a long-horizon task. We find that larger models can correctly execute\nsignificantly more turns even when small models have 100\\% single-turn\naccuracy. We observe that the per-step accuracy of models degrades as the\nnumber of steps increases. This is not just due to long-context limitations --\ncuriously, we observe a self-conditioning effect -- models become more likely\nto make mistakes when the context contains their errors from prior turns.\nSelf-conditioning does not reduce by just scaling the model size. In contrast,\nrecent thinking models do not self-condition, and can also execute much longer\ntasks in a single turn. We conclude by benchmarking frontier thinking models on\nthe length of task they can execute in a single turn. Overall, by focusing on\nthe ability to execute, we hope to reconcile debates on how LLMs can solve\ncomplex reasoning problems yet fail at simple tasks when made longer, and\nhighlight the massive benefits of scaling model size and sequential test-time\ncompute for long-horizon tasks.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u662f\u5426\u6536\u76ca\u9012\u51cf\uff0c\u53d1\u73b0\u6267\u884c\u80fd\u529b\u5173\u952e\uff0c\u5927\u6a21\u578b\u6267\u884c\u4f18\u52bf\u660e\u663e\uff0c\u8fd8\u7814\u7a76\u81ea\u8c03\u8282\u6548\u5e94\u5e76\u5bf9\u524d\u6cbf\u601d\u7ef4\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u6269\u5c55\u662f\u5426\u6536\u76ca\u9012\u51cf\uff0c\u89e3\u51b3\u5176\u80fd\u89e3\u51b3\u590d\u6742\u63a8\u7406\u95ee\u9898\u4f46\u957f\u7b80\u5355\u4efb\u52a1\u6613\u5931\u8d25\u7684\u77db\u76fe\u3002", "method": "\u89c2\u5bdf\u5355\u6b65\u51c6\u786e\u7387\u8fb9\u9645\u589e\u76ca\u5bf9\u4efb\u52a1\u957f\u5ea6\u7684\u5f71\u54cd\uff0c\u9694\u79bb\u6267\u884c\u80fd\u529b\uff0c\u7814\u7a76\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u6267\u884c\u60c5\u51b5\u53ca\u81ea\u8c03\u8282\u6548\u5e94\uff0c\u5bf9\u524d\u6cbf\u601d\u7ef4\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5927\u6a21\u578b\u5728\u6267\u884c\u957f\u4efb\u52a1\u65f6\u8868\u73b0\u66f4\u597d\uff0c\u6a21\u578b\u6bcf\u6b65\u51c6\u786e\u7387\u968f\u6b65\u6570\u589e\u52a0\u800c\u4e0b\u964d\uff0c\u5b58\u5728\u81ea\u8c03\u8282\u6548\u5e94\uff0c\u601d\u7ef4\u6a21\u578b\u65e0\u81ea\u8c03\u8282\u4e14\u5355\u8f6e\u6267\u884c\u4efb\u52a1\u66f4\u957f\u3002", "conclusion": "\u5173\u6ce8\u6267\u884c\u80fd\u529b\u53ef\u8c03\u548c\u76f8\u5173\u4e89\u8bae\uff0c\u51f8\u663e\u6269\u5c55\u6a21\u578b\u89c4\u6a21\u548c\u987a\u5e8f\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u5bf9\u957f\u4efb\u52a1\u7684\u5de8\u5927\u76ca\u5904\u3002"}}
{"id": "2509.09195", "pdf": "https://arxiv.org/pdf/2509.09195", "abs": "https://arxiv.org/abs/2509.09195", "authors": ["Md Tanveer Hossain Munim"], "title": "Breaking the Statistical Similarity Trap in Extreme Convection Detection", "categories": ["cs.LG", "cs.CV", "68T07, 86A10", "I.2.6; J.2"], "comment": "43 pages, 7 figures", "summary": "Current evaluation metrics for deep learning weather models create a\n\"Statistical Similarity Trap\", rewarding blurry predictions while missing rare,\nhigh-impact events. We provide quantitative evidence of this trap, showing\nsophisticated baselines achieve 97.9% correlation yet 0.00 CSI for dangerous\nconvection detection. We introduce DART (Dual Architecture for Regression\nTasks), a framework addressing the challenge of transforming coarse atmospheric\nforecasts into high-resolution satellite brightness temperature fields\noptimized for extreme convection detection (below 220 K). DART employs\ndual-decoder architecture with explicit background/extreme decomposition,\nphysically motivated oversampling, and task-specific loss functions. We present\nfour key findings: (1) empirical validation of the Statistical Similarity Trap\nacross multiple sophisticated baselines; (2) the \"IVT Paradox\", removing\nIntegrated Water Vapor Transport, widely regarded as essential for atmospheric\nriver analysis, improves extreme convection detection by 270%; (3)\narchitectural necessity demonstrated through operational flexibility (DART\nachieves CSI = 0.273 with bias = 2.52 vs. 6.72 for baselines at equivalent\nCSI), and (4) real-world validation with the August 2023 Chittagong flooding\ndisaster as a case study. To our knowledge, this is the first work to\nsystematically address this hybrid conversion-segmentation-downscaling task,\nwith no direct prior benchmarks identified in existing literature. Our\nvalidation against diverse statistical and deep learning baselines sufficiently\ndemonstrates DART's specialized design. The framework enables precise\noperational calibration through beta-tuning, trains in under 10 minutes on\nstandard hardware, and integrates seamlessly with existing meteorological\nworkflows, demonstrating a pathway toward trustworthy AI for extreme weather\npreparedness.", "AI": {"tldr": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6c14\u8c61\u6a21\u578b\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u2018\u7edf\u8ba1\u76f8\u4f3c\u6027\u9677\u9631\u2019\uff0c\u6587\u7ae0\u5f15\u5165DART\u6846\u67b6\u5e94\u5bf9\u6311\u6218\uff0c\u6709\u591a\u9879\u53d1\u73b0\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4e3a\u6781\u7aef\u5929\u6c14\u9884\u8b66AI\u63d0\u4f9b\u9014\u5f84\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6c14\u8c61\u6a21\u578b\u8bc4\u4f30\u6307\u6807\u7684\u2018\u7edf\u8ba1\u76f8\u4f3c\u6027\u9677\u9631\u2019\u95ee\u9898\uff0c\u5b9e\u73b0\u7cbe\u51c6\u6781\u7aef\u5bf9\u6d41\u68c0\u6d4b\u3002", "method": "\u5f15\u5165DART\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u89e3\u7801\u5668\u67b6\u6784\u3001\u663e\u5f0f\u80cc\u666f/\u6781\u7aef\u5206\u89e3\u3001\u7269\u7406\u6fc0\u52b1\u8fc7\u91c7\u6837\u548c\u7279\u5b9a\u4efb\u52a1\u635f\u5931\u51fd\u6570\u3002", "result": "\u9a8c\u8bc1\u2018\u7edf\u8ba1\u76f8\u4f3c\u6027\u9677\u9631\u2019\uff0c\u53d1\u73b0\u2018IVT\u6096\u8bba\u2019\uff0c\u8bc1\u660e\u67b6\u6784\u5fc5\u8981\u6027\uff0c\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\uff0cDART\u5728\u6781\u7aef\u5bf9\u6d41\u68c0\u6d4b\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "DART\u6846\u67b6\u8bbe\u8ba1\u4e13\u4e1a\uff0c\u53ef\u7cbe\u786e\u6821\u51c6\uff0c\u8bad\u7ec3\u5feb\uff0c\u80fd\u878d\u5165\u73b0\u6709\u6c14\u8c61\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e3a\u6781\u7aef\u5929\u6c14\u9884\u8b66\u7684\u53ef\u9760AI\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2509.09208", "pdf": "https://arxiv.org/pdf/2509.09208", "abs": "https://arxiv.org/abs/2509.09208", "authors": ["Somnath Hazra", "Pallab Dasgupta", "Soumyajit Dey"], "title": "Incentivizing Safer Actions in Policy Optimization for Constrained Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, Accepted to the 34th International Joint Conference on\n  Artificial Intelligence (IJCAI) 2025, Main Track", "summary": "Constrained Reinforcement Learning (RL) aims to maximize the return while\nadhering to predefined constraint limits, which represent domain-specific\nsafety requirements. In continuous control settings, where learning agents\ngovern system actions, balancing the trade-off between reward maximization and\nconstraint satisfaction remains a significant challenge. Policy optimization\nmethods often exhibit instability near constraint boundaries, resulting in\nsuboptimal training performance. To address this issue, we introduce a novel\napproach that integrates an adaptive incentive mechanism in addition to the\nreward structure to stay within the constraint bound before approaching the\nconstraint boundary. Building on this insight, we propose Incrementally\nPenalized Proximal Policy Optimization (IP3O), a practical algorithm that\nenforces a progressively increasing penalty to stabilize training dynamics.\nThrough empirical evaluation on benchmark environments, we demonstrate the\nefficacy of IP3O compared to the performance of state-of-the-art Safe RL\nalgorithms. Furthermore, we provide theoretical guarantees by deriving a bound\non the worst-case error of the optimality achieved by our algorithm.", "AI": {"tldr": "\u63d0\u51fa\u589e\u91cf\u60e9\u7f5a\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5IP3O\u89e3\u51b3\u8fde\u7eed\u63a7\u5236\u4e2d\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u5e76\u7ed9\u51fa\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u8fde\u7eed\u63a7\u5236\u4e2d\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u5728\u5e73\u8861\u5956\u52b1\u6700\u5927\u5316\u548c\u7ea6\u675f\u6ee1\u8db3\u65f6\u5b58\u5728\u6311\u6218\uff0c\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u5728\u7ea6\u675f\u8fb9\u754c\u9644\u8fd1\u4e0d\u7a33\u5b9a\uff0c\u8bad\u7ec3\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u6fc0\u52b1\u673a\u5236\uff0c\u63d0\u51faIP3O\u7b97\u6cd5\uff0c\u5bf9\u8fdd\u53cd\u7ea6\u675f\u65bd\u52a0\u9012\u589e\u60e9\u7f5a\u4ee5\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5728\u57fa\u51c6\u73af\u5883\u4e0a\u7684\u5b9e\u9a8c\u8868\u660eIP3O\u6bd4\u73b0\u6709\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u66f4\u6709\u6548\u3002", "conclusion": "IP3O\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u8fde\u7eed\u63a7\u5236\u4e2d\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u4e14\u6709\u7406\u8bba\u4e0a\u7684\u6700\u574f\u60c5\u51b5\u8bef\u5dee\u754c\u4fdd\u8bc1\u3002"}}
{"id": "2509.08835", "pdf": "https://arxiv.org/pdf/2509.08835", "abs": "https://arxiv.org/abs/2509.08835", "authors": ["Vincent C. M\u00fcller"], "title": "Deep opacity and AI: A threat to XAI and to privacy protection mechanisms", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "It is known that big data analytics and AI pose a threat to privacy, and that\nsome of this is due to some kind of \"black box problem\" in AI. I explain how\nthis becomes a problem in the context of justification for judgments and\nactions. Furthermore, I suggest distinguishing three kinds of opacity: 1) the\nsubjects do not know what the system does (\"shallow opacity\"), 2) the analysts\ndo not know what the system does (\"standard black box opacity\"), or 3) the\nanalysts cannot possibly know what the system might do (\"deep opacity\"). If the\nagents, data subjects as well as analytics experts, operate under opacity, then\nthese agents cannot provide justifications for judgments that are necessary to\nprotect privacy, e.g., they cannot give \"informed consent\", or guarantee\n\"anonymity\". It follows from these points that agents in big data analytics and\nAI often cannot make the judgments needed to protect privacy. So I conclude\nthat big data analytics makes the privacy problems worse and the remedies less\neffective. As a positive note, I provide a brief outlook on technical ways to\nhandle this situation.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5927\u6570\u636e\u5206\u6790\u548cAI\u56e0\u2018\u9ed1\u76d2\u95ee\u9898\u2019\u5a01\u80c1\u9690\u79c1\uff0c\u533a\u5206\u4e09\u79cd\u4e0d\u900f\u660e\u6027\uff0c\u8ba4\u4e3a\u76f8\u5173\u4e3b\u4f53\u96be\u4f5c\u4fdd\u62a4\u9690\u79c1\u5224\u65ad\uff0c\u4f7f\u9690\u79c1\u95ee\u9898\u6076\u5316\uff0c\u6700\u540e\u7ed9\u51fa\u6280\u672f\u5e94\u5bf9\u5c55\u671b\u3002", "motivation": "\u63a2\u8ba8\u5927\u6570\u636e\u5206\u6790\u548cAI\u4e2d\u2018\u9ed1\u76d2\u95ee\u9898\u2019\u5bf9\u9690\u79c1\u4fdd\u62a4\u5224\u65ad\u548c\u884c\u52a8\u6b63\u5f53\u6027\u7684\u5f71\u54cd\u3002", "method": "\u89e3\u91ca\u2018\u9ed1\u76d2\u95ee\u9898\u2019\u5728\u9690\u79c1\u5224\u65ad\u548c\u884c\u52a8\u6b63\u5f53\u6027\u80cc\u666f\u4e0b\u7684\u95ee\u9898\uff0c\u533a\u5206\u4e09\u79cd\u4e0d\u900f\u660e\u6027\u3002", "result": "\u5927\u6570\u636e\u5206\u6790\u548cAI\u4e2d\u7684\u4e3b\u4f53\u56e0\u4e0d\u900f\u660e\u6027\u96be\u4ee5\u505a\u51fa\u4fdd\u62a4\u9690\u79c1\u6240\u9700\u7684\u5224\u65ad\u3002", "conclusion": "\u5927\u6570\u636e\u5206\u6790\u4f7f\u9690\u79c1\u95ee\u9898\u66f4\u4e25\u91cd\uff0c\u8865\u6551\u63aa\u65bd\u6548\u679c\u964d\u4f4e\uff0c\u6700\u540e\u7ed9\u51fa\u6280\u672f\u5e94\u5bf9\u5c55\u671b\u3002"}}
{"id": "2509.09214", "pdf": "https://arxiv.org/pdf/2509.09214", "abs": "https://arxiv.org/abs/2509.09214", "authors": ["Alka Gadakh", "Vidya Kumbhar", "Sonal Khosla", "Kumar Karunendra"], "title": "Identifying Key Features for Establishing Sustainable Agro-Tourism Centre: A Data Driven Approach", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Agro-tourism serves as a strategic economic model designed to facilitate\nrural development by diversifying income streams for local communities like\nfarmers while promoting the conservation of indigenous cultural heritage and\ntraditional agricultural practices. As a very booming subdomain of tourism,\nthere is a need to study the strategies for the growth of Agro-tourism in\ndetail. The current study has identified the important indicators for the\ngrowth and enhancement of agro-tourism. The study is conducted in two phases:\nidentification of the important indicators through a comprehensive literature\nreview and in the second phase state-of-the-art techniques were used to\nidentify the important indicators for the growth of agro-tourism. The\nindicators are also called features synonymously, the machine learning models\nfor feature selection were applied and it was observed that the Least Absolute\nShrinkage and Selection Operator (LASSO) method combined with, the machine\nLearning Classifiers such as Logistic Regression (LR), Decision Trees (DT),\nRandom Forest (RF) Tree, and Extreme Gradient Boosting (XGBOOST) models were\nused to suggest the growth of the agro-tourism. The results show that with the\nLASSO method, LR model gives the highest classification accuracy of 98% in\n70-30% train-test data followed by RF with 95% accuracy. Similarly, in the\n80-20% train-test data LR maintains the highest accuracy at 99%, while DT and\nXGBoost follow with 97% accuracy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u519c\u4e1a\u65c5\u6e38\u589e\u957f\u7b56\u7565\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u7814\u7a76\u786e\u5b9a\u91cd\u8981\u6307\u6807\uff0c\u5e94\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793aLASSO\u65b9\u6cd5\u4e0bLR\u6a21\u578b\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u3002", "motivation": "\u519c\u4e1a\u65c5\u6e38\u662f\u4fc3\u8fdb\u519c\u6751\u53d1\u5c55\u7684\u7ecf\u6d4e\u6a21\u5f0f\uff0c\u4f5c\u4e3a\u70ed\u95e8\u9886\u57df\u9700\u8be6\u7ec6\u7814\u7a76\u5176\u589e\u957f\u7b56\u7565\u3002", "method": "\u5206\u4e24\u9636\u6bb5\u7814\u7a76\uff0c\u5148\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u786e\u5b9a\u6307\u6807\uff0c\u518d\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08LASSO\u7ed3\u5408LR\u3001DT\u3001RF\u3001XGBOOST\uff09\u8fdb\u884c\u7279\u5f81\u9009\u62e9\u3002", "result": "LASSO\u65b9\u6cd5\u4e0b\uff0c70 - 30%\u8bad\u7ec3\u6d4b\u8bd5\u6570\u636e\u4e2dLR\u6a21\u578b\u5206\u7c7b\u51c6\u786e\u7387\u8fbe98%\uff0cRF\u4e3a95%\uff1b80 - 20%\u6570\u636e\u4e2dLR\u51c6\u786e\u738799%\uff0cDT\u548cXGBoost\u4e3a97%\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\u7ed3\u8bba\u5185\u5bb9\uff0c\u4f46\u7ed3\u679c\u8868\u660eLASSO\u7ed3\u5408LR\u7b49\u6a21\u578b\u5bf9\u519c\u4e1a\u65c5\u6e38\u589e\u957f\u6307\u6807\u7684\u9009\u62e9\u6709\u8f83\u597d\u6548\u679c\u3002"}}
{"id": "2509.09219", "pdf": "https://arxiv.org/pdf/2509.09219", "abs": "https://arxiv.org/abs/2509.09219", "authors": ["Jakob Nyberg", "Pontus Johnson"], "title": "Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We present and evaluate Vejde; a framework which combines data abstraction,\ngraph neural networks and reinforcement learning to produce inductive policy\nfunctions for decision problems with richly structured states, such as object\nclasses and relations. MDP states are represented as data bases of facts about\nentities, and Vejde converts each state to a bipartite graph, which is mapped\nto latent states through neural message passing. The factored representation of\nboth states and actions allows Vejde agents to handle problems of varying size\nand structure. We tested Vejde agents on eight problem domains defined in RDDL,\nwith ten problem instances each, where policies were trained using both\nsupervised and reinforcement learning. To test policy generalization, we\nseparate problem instances in two sets, one for training and the other solely\nfor testing. Test results on unseen instances for the Vejde agents were\ncompared to MLP agents trained on each problem instance, as well as the online\nplanning algorithm Prost. Our results show that Vejde policies in average\ngeneralize to the test instances without a significant loss in score.\nAdditionally, the inductive agents received scores on unseen test instances\nthat on average were close to the instance-specific MLP agents.", "AI": {"tldr": "\u63d0\u51faVejde\u6846\u67b6\uff0c\u7ed3\u5408\u6570\u636e\u62bd\u8c61\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5f3a\u5316\u5b66\u4e60\u5904\u7406\u590d\u6742\u72b6\u6001\u51b3\u7b56\u95ee\u9898\uff0c\u6d4b\u8bd5\u663e\u793a\u5176\u7b56\u7565\u6cdb\u5316\u80fd\u529b\u597d\u3002", "motivation": "\u89e3\u51b3\u5177\u6709\u4e30\u5bcc\u7ed3\u6784\u72b6\u6001\u7684\u51b3\u7b56\u95ee\u9898\uff0c\u5982\u5bf9\u8c61\u7c7b\u548c\u5173\u7cfb\uff0c\u9700\u8981\u6709\u80fd\u5904\u7406\u4e0d\u540c\u89c4\u6a21\u548c\u7ed3\u6784\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "method": "\u5c06MDP\u72b6\u6001\u8868\u793a\u4e3a\u5b9e\u4f53\u4e8b\u5b9e\u6570\u636e\u5e93\uff0c\u8f6c\u6362\u4e3a\u4e8c\u5206\u56fe\uff0c\u901a\u8fc7\u795e\u7ecf\u6d88\u606f\u4f20\u9012\u6620\u5c04\u5230\u6f5c\u5728\u72b6\u6001\uff0c\u4f7f\u7528\u76d1\u7763\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7b56\u7565\uff0c\u5206\u79bb\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u3002", "result": "Vejde\u7b56\u7565\u5e73\u5747\u80fd\u6cdb\u5316\u5230\u6d4b\u8bd5\u5b9e\u4f8b\u4e14\u5206\u6570\u65e0\u663e\u8457\u635f\u5931\uff0c\u5f52\u7eb3\u4ee3\u7406\u5728\u672a\u89c1\u6d4b\u8bd5\u5b9e\u4f8b\u4e0a\u7684\u5206\u6570\u63a5\u8fd1\u7279\u5b9a\u5b9e\u4f8b\u7684MLP\u4ee3\u7406\u3002", "conclusion": "Vejde\u6846\u67b6\u6709\u6548\uff0c\u5176\u7b56\u7565\u5177\u6709\u8f83\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.08852", "pdf": "https://arxiv.org/pdf/2509.08852", "abs": "https://arxiv.org/abs/2509.08852", "authors": ["Kajetan Schweighofer", "Barbara Brune", "Lukas Gruber", "Simon Schmid", "Alexander Aufreiter", "Andreas Gruber", "Thomas Doms", "Sebastian Eder", "Florian Mayer", "Xaver-Paul Stadlbauer", "Christoph Schwald", "Werner Zellinger", "Bernhard Nessler", "Sepp Hochreiter"], "title": "Safe and Certifiable AI Systems: Concepts, Challenges, and Lessons Learned", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "63 pages, 27 figures", "summary": "There is an increasing adoption of artificial intelligence in safety-critical\napplications, yet practical schemes for certifying that AI systems are safe,\nlawful and socially acceptable remain scarce. This white paper presents the\nT\\\"UV AUSTRIA Trusted AI framework an end-to-end audit catalog and methodology\nfor assessing and certifying machine learning systems. The audit catalog has\nbeen in continuous development since 2019 in an ongoing collaboration with\nscientific partners. Building on three pillars - Secure Software Development,\nFunctional Requirements, and Ethics & Data Privacy - the catalog translates the\nhigh-level obligations of the EU AI Act into specific, testable criteria. Its\ncore concept of functional trustworthiness couples a statistically defined\napplication domain with risk-based minimum performance requirements and\nstatistical testing on independently sampled data, providing transparent and\nreproducible evidence of model quality in real-world settings. We provide an\noverview of the functional requirements that we assess, which are oriented on\nthe lifecycle of an AI system. In addition, we share some lessons learned from\nthe practical application of the audit catalog, highlighting common pitfalls we\nencountered, such as data leakage scenarios, inadequate domain definitions,\nneglect of biases, or a lack of distribution drift controls. We further discuss\nkey aspects of certifying AI systems, such as robustness, algorithmic fairness,\nor post-certification requirements, outlining both our current conclusions and\na roadmap for future research. In general, by aligning technical best practices\nwith emerging European standards, the approach offers regulators, providers,\nand users a practical roadmap for legally compliant, functionally trustworthy,\nand certifiable AI systems.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdT\u00dcV AUSTRIA\u53ef\u4fe1AI\u6846\u67b6\uff0c\u5305\u62ec\u5ba1\u8ba1\u76ee\u5f55\u548c\u65b9\u6cd5\uff0c\u5c06\u6b27\u76dfAI\u6cd5\u6848\u4e49\u52a1\u8f6c\u5316\u4e3a\u53ef\u6d4b\u8bd5\u6807\u51c6\uff0c\u8fd8\u5206\u4eab\u5b9e\u8df5\u7ecf\u9a8c\u5e76\u8ba8\u8bba\u8ba4\u8bc1\u5173\u952e\u65b9\u9762\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5728\u5173\u952e\u5b89\u5168\u5e94\u7528\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u7528\u7684\u8ba4\u8bc1\u65b9\u6848\u6765\u786e\u4fddAI\u7cfb\u7edf\u5b89\u5168\u3001\u5408\u6cd5\u4e14\u88ab\u793e\u4f1a\u63a5\u53d7\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5b89\u5168\u8f6f\u4ef6\u5f00\u53d1\u3001\u529f\u80fd\u9700\u6c42\u3001\u4f26\u7406\u4e0e\u6570\u636e\u9690\u79c1\u4e09\u4e2a\u652f\u67f1\u7684\u5ba1\u8ba1\u76ee\u5f55\uff0c\u5c06\u6b27\u76dfAI\u6cd5\u6848\u4e49\u52a1\u8f6c\u5316\u4e3a\u5177\u4f53\u6d4b\u8bd5\u6807\u51c6\uff1b\u91c7\u7528\u529f\u80fd\u53ef\u4fe1\u5ea6\u6838\u5fc3\u6982\u5ff5\uff0c\u7ed3\u5408\u5e94\u7528\u9886\u57df\u4e0e\u6027\u80fd\u8981\u6c42\u53ca\u7edf\u8ba1\u6d4b\u8bd5\u3002", "result": "\u63d0\u4f9b\u529f\u80fd\u9700\u6c42\u8bc4\u4f30\u6982\u8ff0\uff0c\u5206\u4eab\u5b9e\u8df5\u5e94\u7528\u5ba1\u8ba1\u76ee\u5f55\u7684\u7ecf\u9a8c\uff0c\u6307\u51fa\u5e38\u89c1\u9677\u9631\uff1b\u8ba8\u8bbaAI\u7cfb\u7edf\u8ba4\u8bc1\u7684\u5173\u952e\u65b9\u9762\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u6280\u672f\u6700\u4f73\u5b9e\u8df5\u4e0e\u6b27\u6d32\u6807\u51c6\u7ed3\u5408\uff0c\u4e3a\u76d1\u7ba1\u8005\u3001\u63d0\u4f9b\u8005\u548c\u7528\u6237\u63d0\u4f9b\u4e86\u5408\u89c4\u3001\u53ef\u4fe1\u4e14\u53ef\u8ba4\u8bc1\u7684AI\u7cfb\u7edf\u5b9e\u7528\u8def\u7ebf\u56fe\u3002"}}
{"id": "2509.08854", "pdf": "https://arxiv.org/pdf/2509.08854", "abs": "https://arxiv.org/abs/2509.08854", "authors": ["David James Woo", "Kai Guo", "Yangyang Yu"], "title": "A vibe coding learning design to enhance EFL students' talking to, through, and about AI", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "15 pages, 12 figures", "summary": "This innovative practice article reports on the piloting of vibe coding\n(using natural language to create software applications with AI) for English as\na Foreign Language (EFL) education. We developed a human-AI meta-languaging\nframework with three dimensions: talking to AI (prompt engineering), talking\nthrough AI (negotiating authorship), and talking about AI (mental models of\nAI). Using backward design principles, we created a four-hour workshop where\ntwo students designed applications addressing authentic EFL writing challenges.\nWe adopted a case study methodology, collecting data from worksheets and video\nrecordings, think-aloud protocols, screen recordings, and AI-generated images.\nContrasting cases showed one student successfully vibe coding a functional\napplication cohering to her intended design, while another encountered\ntechnical difficulties with major gaps between intended design and actual\nfunctionality. Analysis reveals differences in students' prompt engineering\napproaches, suggesting different AI mental models and tensions in attributing\nauthorship. We argue that AI functions as a beneficial languaging machine, and\nthat differences in how students talk to, through, and about AI explain vibe\ncoding outcome variations. Findings indicate that effective vibe coding\ninstruction requires explicit meta-languaging scaffolding, teaching structured\nprompt engineering, facilitating critical authorship discussions, and\ndeveloping vocabulary for articulating AI mental models.", "AI": {"tldr": "\u672c\u6587\u62a5\u9053\u4e86\u5728EFL\u6559\u80b2\u4e2d\u8bd5\u7528vibe coding\u7684\u60c5\u51b5\uff0c\u5f00\u53d1\u6846\u67b6\u5e76\u5f00\u5c55\u5de5\u4f5c\u574a\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5206\u6790\u7ed3\u679c\uff0c\u6307\u51fa\u6709\u6548\u6559\u5b66\u9700\u5143\u8bed\u8a00\u652f\u6301\u3002", "motivation": "\u63a2\u7d22vibe coding\u5728EFL\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4eba\u7c7b - AI\u5143\u8bed\u8a00\u6846\u67b6\uff0c\u91c7\u7528\u9006\u5411\u8bbe\u8ba1\u539f\u5219\u5f00\u5c55\u56db\u5c0f\u65f6\u5de5\u4f5c\u574a\uff0c\u8fd0\u7528\u6848\u4f8b\u7814\u7a76\u65b9\u6cd5\uff0c\u6536\u96c6\u591a\u79cd\u6570\u636e\u3002", "result": "\u4e24\u540d\u5b66\u751f\u5728\u8bbe\u8ba1\u5e94\u7528\u65f6\u7ed3\u679c\u4e0d\u540c\uff0c\u4e00\u4eba\u6210\u529f\uff0c\u4e00\u4eba\u9047\u6280\u672f\u96be\u9898\uff0c\u5206\u6790\u663e\u793a\u5b66\u751f\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u6709\u5dee\u5f02\u3002", "conclusion": "AI\u662f\u6709\u76ca\u7684\u8bed\u8a00\u673a\u5668\uff0c\u5b66\u751f\u4e0eAI\u4ea4\u4e92\u65b9\u5f0f\u7684\u4e0d\u540c\u5bfc\u81f4\u7ed3\u679c\u5dee\u5f02\uff0c\u6709\u6548\u6559\u5b66\u9700\u660e\u786e\u7684\u5143\u8bed\u8a00\u652f\u67b6\u7b49\u3002"}}
{"id": "2509.09251", "pdf": "https://arxiv.org/pdf/2509.09251", "abs": "https://arxiv.org/abs/2509.09251", "authors": ["Hanyang Wang", "Yuxuan Yang", "Hongjun Wang", "Lihui Wang"], "title": "Unsupervised Multi-Attention Meta Transformer for Rotating Machinery Fault Diagnosis", "categories": ["cs.LG"], "comment": null, "summary": "The intelligent fault diagnosis of rotating mechanical equipment usually\nrequires a large amount of labeled sample data. However, in practical\nindustrial applications, acquiring enough data is both challenging and\nexpensive in terms of time and cost. Moreover, different types of rotating\nmechanical equipment with different unique mechanical properties, require\nseparate training of diagnostic models for each case. To address the challenges\nof limited fault samples and the lack of generalizability in prediction models\nfor practical engineering applications, we propose a Multi-Attention Meta\nTransformer method for few-shot unsupervised rotating machinery fault diagnosis\n(MMT-FD). This framework extracts potential fault representations from\nunlabeled data and demonstrates strong generalization capabilities, making it\nsuitable for diagnosing faults across various types of mechanical equipment.\nThe MMT-FD framework integrates a time-frequency domain encoder and a\nmeta-learning generalization model. The time-frequency domain encoder predicts\nstatus representations generated through random augmentations in the\ntime-frequency domain. These enhanced data are then fed into a meta-learning\nnetwork for classification and generalization training, followed by fine-tuning\nusing a limited amount of labeled data. The model is iteratively optimized\nusing a small number of contrastive learning iterations, resulting in high\nefficiency. To validate the framework, we conducted experiments on a bearing\nfault dataset and rotor test bench data. The results demonstrate that the\nMMT-FD model achieves 99\\% fault diagnosis accuracy with only 1\\% of labeled\nsample data, exhibiting robust generalization capabilities.", "AI": {"tldr": "\u63d0\u51faMMT - FD\u65b9\u6cd5\u7528\u4e8e\u5c11\u6837\u672c\u65e0\u76d1\u7763\u65cb\u8f6c\u673a\u68b0\u6545\u969c\u8bca\u65ad\uff0c\u5728\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u4e0b\u5b9e\u73b099%\u8bca\u65ad\u51c6\u786e\u7387\u4e14\u6cdb\u5316\u6027\u5f3a", "motivation": "\u89e3\u51b3\u5b9e\u9645\u5de5\u7a0b\u4e2d\u6545\u969c\u6837\u672c\u6709\u9650\u548c\u9884\u6d4b\u6a21\u578b\u7f3a\u4e4f\u6cdb\u5316\u6027\u7684\u95ee\u9898", "method": "\u63d0\u51faMMT - FD\u6846\u67b6\uff0c\u96c6\u6210\u65f6\u9891\u57df\u7f16\u7801\u5668\u548c\u5143\u5b66\u4e60\u6cdb\u5316\u6a21\u578b\uff0c\u901a\u8fc7\u65f6\u9891\u57df\u968f\u673a\u589e\u5f3a\u751f\u6210\u72b6\u6001\u8868\u793a\uff0c\u518d\u8fdb\u884c\u5206\u7c7b\u548c\u6cdb\u5316\u8bad\u7ec3\uff0c\u6700\u540e\u7528\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u5fae\u8c03", "result": "\u5728\u8f74\u627f\u6545\u969c\u6570\u636e\u96c6\u548c\u8f6c\u5b50\u8bd5\u9a8c\u53f0\u6570\u636e\u5b9e\u9a8c\u4e2d\uff0cMMT - FD\u6a21\u578b\u75281%\u6807\u6ce8\u6837\u672c\u6570\u636e\u5b9e\u73b099%\u6545\u969c\u8bca\u65ad\u51c6\u786e\u7387", "conclusion": "MMT - FD\u6a21\u578b\u5177\u6709\u9ad8\u6548\u6027\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7c7b\u578b\u673a\u68b0\u8bbe\u5907\u7684\u6545\u969c\u8bca\u65ad"}}
{"id": "2509.08859", "pdf": "https://arxiv.org/pdf/2509.08859", "abs": "https://arxiv.org/abs/2509.08859", "authors": ["Vincenzo Suriani", "Daniele Affinita", "Domenico D. Bloisi", "Daniele Nardi"], "title": "Multi Robot Coordination in Highly Dynamic Environments: Tackling Asymmetric Obstacles and Limited Communication", "categories": ["cs.RO", "cs.AI"], "comment": "The 19th International Conference on Intelligent Autonomous Systems\n  (IAS 19), 2025, Genoa", "summary": "Coordinating a fully distributed multi-agent system (MAS) can be challenging\nwhen the communication channel has very limited capabilities in terms of\nsending rate and packet payload. When the MAS has to deal with active obstacles\nin a highly partially observable environment, the communication channel\nacquires considerable relevance. In this paper, we present an approach to deal\nwith task assignments in extremely active scenarios, where tasks need to be\nfrequently reallocated among the agents participating in the coordination\nprocess. Inspired by market-based task assignments, we introduce a novel\ndistributed coordination method to orchestrate autonomous agents' actions\nefficiently in low communication scenarios. In particular, our algorithm takes\ninto account asymmetric obstacles. While in the real world, the majority of\nobstacles are asymmetric, they are usually treated as symmetric ones, thus\nlimiting the applicability of existing methods. To summarize, the presented\narchitecture is designed to tackle scenarios where the obstacles are active and\nasymmetric, the communication channel is poor and the environment is partially\nobservable. Our approach has been validated in simulation and in the real\nworld, using a team of NAO robots during official RoboCup competitions.\nExperimental results show a notable reduction in task overlaps in limited\ncommunication settings, with a decrease of 52% in the most frequent reallocated\ntask.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u4f4e\u901a\u4fe1\u573a\u666f\u4e0b\u5904\u7406\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4efb\u52a1\u5206\u914d\u7684\u65b9\u6cd5\uff0c\u8003\u8651\u4e0d\u5bf9\u79f0\u969c\u788d\u7269\uff0c\u5728\u4eff\u771f\u548c\u73b0\u5b9e\u4e2d\u9a8c\u8bc1\uff0c\u51cf\u5c11\u4efb\u52a1\u91cd\u53e0\u3002", "motivation": "\u5728\u901a\u4fe1\u80fd\u529b\u6709\u9650\u3001\u73af\u5883\u90e8\u5206\u53ef\u89c2\u6d4b\u4e14\u5b58\u5728\u4e3b\u52a8\u969c\u788d\u7269\u7684\u60c5\u51b5\u4e0b\uff0c\u534f\u8c03\u5168\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u5904\u7406\u4e0d\u5bf9\u79f0\u969c\u788d\u7269\u5b58\u5728\u5c40\u9650\u3002", "method": "\u53d7\u57fa\u4e8e\u5e02\u573a\u7684\u4efb\u52a1\u5206\u914d\u542f\u53d1\uff0c\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u5206\u5e03\u5f0f\u534f\u8c03\u65b9\u6cd5\uff0c\u8003\u8651\u4e0d\u5bf9\u79f0\u969c\u788d\u7269\u3002", "result": "\u5728\u4eff\u771f\u548c\u73b0\u5b9e\u4e2d\u9a8c\u8bc1\uff0c\u5728\u6709\u9650\u901a\u4fe1\u8bbe\u7f6e\u4e0b\u4efb\u52a1\u91cd\u53e0\u663e\u8457\u51cf\u5c11\uff0c\u6700\u9891\u7e41\u91cd\u65b0\u5206\u914d\u7684\u4efb\u52a1\u51cf\u5c11\u4e8652%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u67b6\u6784\u80fd\u6709\u6548\u5904\u7406\u969c\u788d\u7269\u4e3b\u52a8\u4e14\u4e0d\u5bf9\u79f0\u3001\u901a\u4fe1\u5dee\u548c\u73af\u5883\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u573a\u666f\u3002"}}
{"id": "2509.09265", "pdf": "https://arxiv.org/pdf/2509.09265", "abs": "https://arxiv.org/abs/2509.09265", "authors": ["Jiawei Wang", "Jiacai Liu", "Yuqian Fu", "Yingru Li", "Xintao Wang", "Yuan Lin", "Yu Yue", "Lin Zhang", "Yang Wang", "Ke Wang"], "title": "Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents", "categories": ["cs.LG", "cs.CL"], "comment": "ICLR 2026 Under review", "summary": "In long-horizon tasks, recent agents based on Large Language Models (LLMs)\nface a significant challenge that sparse, outcome-based rewards make it\ndifficult to assign credit to intermediate steps. Previous methods mainly focus\non creating dense reward signals to guide learning, either through traditional\nreinforcement learning techniques like inverse reinforcement learning or by\nusing Process Reward Models for step-by-step feedback. In this paper, we\nidentify a fundamental problem in the learning dynamics of LLMs: the magnitude\nof policy gradients is inherently coupled with the entropy, which leads to\ninefficient small updates for confident correct actions and potentially\ndestabilizes large updates for uncertain ones. To resolve this, we propose\nEntropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the\nlearning signal based on step-wise uncertainty and the final task outcome. EMPG\namplifies updates for confident correct actions, penalizes confident errors,\nand attenuates updates from uncertain steps to stabilize exploration. We\nfurther introduce a bonus term for future clarity that encourages agents to\nfind more predictable solution paths. Through comprehensive experiments on\nthree challenging agent tasks, WebShop, ALFWorld, and Deep Search, we\ndemonstrate that EMPG achieves substantial performance gains and significantly\noutperforms strong policy gradient baselines. Project page is at\nhttps://empgseed-seed.github.io/", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5468\u671f\u4efb\u52a1\u4e2d\u5b66\u4e60\u52a8\u6001\u5b58\u5728\u95ee\u9898\uff0c\u63d0\u51fa\u71b5\u8c03\u5236\u7b56\u7565\u68af\u5ea6\uff08EMPG\uff09\u6846\u67b6\u89e3\u51b3\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5468\u671f\u4efb\u52a1\u4e2d\u56e0\u7a00\u758f\u7ed3\u679c\u5956\u52b1\u96be\u4ee5\u5bf9\u4e2d\u95f4\u6b65\u9aa4\u8fdb\u884c\u4fe1\u7528\u5206\u914d\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u5b66\u4e60\u52a8\u6001\u4e2d\u7b56\u7565\u68af\u5ea6\u5e45\u5ea6\u4e0e\u71b5\u8026\u5408\u5bfc\u81f4\u7684\u66f4\u65b0\u6548\u7387\u548c\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faEMPG\u6846\u67b6\uff0c\u57fa\u4e8e\u9010\u6b65\u4e0d\u786e\u5b9a\u6027\u548c\u6700\u7ec8\u4efb\u52a1\u7ed3\u679c\u91cd\u65b0\u6821\u51c6\u5b66\u4e60\u4fe1\u53f7\uff0c\u653e\u5927\u6b63\u786e\u52a8\u4f5c\u66f4\u65b0\u3001\u60e9\u7f5a\u9519\u8bef\u52a8\u4f5c\u3001\u51cf\u5f31\u4e0d\u786e\u5b9a\u6b65\u9aa4\u66f4\u65b0\uff0c\u5e76\u5f15\u5165\u672a\u6765\u6e05\u6670\u5ea6\u5956\u52b1\u9879\u3002", "result": "\u5728WebShop\u3001ALFWorld\u548cDeep Search\u4e09\u4e2a\u6311\u6218\u6027\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cEMPG\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8fdc\u8d85\u5f3a\u7b56\u7565\u68af\u5ea6\u57fa\u7ebf\u3002", "conclusion": "EMPG\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5468\u671f\u4efb\u52a1\u4e2d\u7684\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2509.08862", "pdf": "https://arxiv.org/pdf/2509.08862", "abs": "https://arxiv.org/abs/2509.08862", "authors": ["Chang Liu", "Loc Hoang", "Andrew Stolman", "Rene F. Kizilcec", "Bo Wu"], "title": "Investigating Student Interaction Patterns with Large Language Model-Powered Course Assistants in Computer Science Courses", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Providing students with flexible and timely academic support is a challenge\nat most colleges and universities, leaving many students without help outside\nscheduled hours. Large language models (LLMs) are promising for bridging this\ngap, but interactions between students and LLMs are rarely overseen by\neducators. We developed and studied an LLM-powered course assistant deployed\nacross multiple computer science courses to characterize real-world use and\nunderstand pedagogical implications. By Spring 2024, our system had been\ndeployed to approximately 2,000 students across six courses at three\ninstitutions. Analysis of the interaction data shows that usage remains strong\nin the evenings and nights and is higher in introductory courses, indicating\nthat our system helps address temporal support gaps and novice learner needs.\nWe sampled 200 conversations per course for manual annotation: most sampled\nresponses were judged correct and helpful, with a small share unhelpful or\nerroneous; few responses included dedicated examples. We also examined an\ninquiry-based learning strategy: only around 11% of sampled conversations\ncontained LLM-generated follow-up questions, which were often ignored by\nstudents in advanced courses. A Bloom's taxonomy analysis reveals that current\nLLM capabilities are limited in generating higher-order cognitive questions.\nThese patterns suggest opportunities for pedagogically oriented LLM-based\neducational systems and greater educator involvement in configuring prompts,\ncontent, and policies.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8de8\u591a\u95e8\u8ba1\u7b97\u673a\u79d1\u5b66\u8bfe\u7a0b\u90e8\u7f72\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bfe\u7a0b\u52a9\u624b\uff0c\u53d1\u73b0\u5176\u80fd\u89e3\u51b3\u65f6\u95f4\u652f\u6301\u7f3a\u53e3\u548c\u65b0\u624b\u5b66\u4e60\u9700\u6c42\uff0c\u540c\u65f6\u6307\u51fa\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u9636\u8ba4\u77e5\u95ee\u9898\u4e0a\u80fd\u529b\u6709\u9650\uff0c\u4e3a\u6559\u80b2\u7cfb\u7edf\u548c\u6559\u5e08\u53c2\u4e0e\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u591a\u6570\u9ad8\u6821\u96be\u4ee5\u4e3a\u5b66\u751f\u63d0\u4f9b\u7075\u6d3b\u53ca\u65f6\u7684\u5b66\u672f\u652f\u6301\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u6709\u6f5c\u529b\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f46\u5b66\u751f\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u4e92\u7f3a\u4e4f\u6559\u5e08\u76d1\u7763\uff0c\u56e0\u6b64\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u8bfe\u7a0b\u52a9\u624b\u7684\u5b9e\u9645\u5e94\u7528\u548c\u6559\u5b66\u610f\u4e49\u3002", "method": "\u5f00\u53d1\u5e76\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u8bfe\u7a0b\u52a9\u624b\uff0c\u5206\u6790\u4ea4\u4e92\u6570\u636e\uff0c\u5bf9\u6bcf\u4e2a\u8bfe\u7a0b\u62bd\u6837200\u4e2a\u5bf9\u8bdd\u8fdb\u884c\u624b\u52a8\u6807\u6ce8\uff0c\u8fdb\u884c\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u5206\u6790\u3002", "result": "\u7cfb\u7edf\u4f7f\u7528\u5728\u665a\u4e0a\u548c\u591c\u95f4\u8f83\u5f3a\uff0c\u5165\u95e8\u8bfe\u7a0b\u4f7f\u7528\u66f4\u9ad8\uff1b\u591a\u6570\u62bd\u6837\u56de\u590d\u6b63\u786e\u4e14\u6709\u5e2e\u52a9\uff0c\u5c11\u6570\u65e0\u5e2e\u52a9\u6216\u9519\u8bef\uff0c\u5f88\u5c11\u6709\u4e13\u7528\u793a\u4f8b\uff1b\u7ea611%\u7684\u62bd\u6837\u5bf9\u8bdd\u5305\u542b\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u540e\u7eed\u95ee\u9898\uff0c\u9ad8\u7ea7\u8bfe\u7a0b\u5b66\u751f\u5e38\u5ffd\u7565\uff1b\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u9636\u8ba4\u77e5\u95ee\u9898\u80fd\u529b\u6709\u9650\u3002", "conclusion": "\u5f53\u524d\u72b6\u51b5\u4e3a\u4ee5\u6559\u5b66\u4e3a\u5bfc\u5411\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6559\u80b2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u673a\u4f1a\uff0c\u4e5f\u8868\u660e\u6559\u5e08\u9700\u66f4\u591a\u53c2\u4e0e\u914d\u7f6e\u63d0\u793a\u3001\u5185\u5bb9\u548c\u653f\u7b56\u3002"}}
{"id": "2509.09278", "pdf": "https://arxiv.org/pdf/2509.09278", "abs": "https://arxiv.org/abs/2509.09278", "authors": ["Saumitra Dwivedi", "Ricardo da Silva Torres", "Ibrahim A. Hameed", "Gunnar Tufte", "Anniken Susanne T. Karlsen"], "title": "Data Driven Discovery of Emergent Dynamics in Reaction Diffusion Systems from Sparse and Noisy Observations", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "Data-driven discovery of emergent dynamics is gaining popularity,\nparticularly in the context of reaction-diffusion systems. These systems are\nwidely studied across various fields, including neuroscience, ecology,\nepidemiology, and several other subject areas that deal with emergent dynamics.\nA current challenge in the discovery process relates to system identification\nwhen there is no prior knowledge of the underlying physics. We attempt to\naddress this challenge by learning Soft Artificial Life (Soft ALife) models,\nsuch as Agent-based and Cellular Automata (CA) models, from observed data for\nreaction-diffusion systems. In this paper, we present findings on the\napplicability of a conceptual framework, the Data-driven Rulesets for Soft\nArtificial Life (DRSALife) model, to learn Soft ALife rulesets that accurately\nrepresent emergent dynamics in a reaction-diffusion system from observed data.\nThis model has demonstrated promising results for Elementary CA Rule 30, Game\nof Life, and Vicsek Flocking problems in recent work. To our knowledge, this is\none of the few studies that explore machine-based Soft ALife ruleset learning\nand system identification for reaction-diffusion dynamics without any prior\nknowledge of the underlying physics. Moreover, we provide comprehensive\nfindings from experiments investigating the potential effects of using noisy\nand sparse observed datasets on learning emergent dynamics. Additionally, we\nsuccessfully identify the structure and parameters of the underlying partial\ndifferential equations (PDEs) representing these dynamics. Experimental results\ndemonstrate that the learned models are able to predict the emergent dynamics\nwith good accuracy (74%) and exhibit quite robust performance when subjected to\nGaussian noise and temporal sparsity.", "AI": {"tldr": "\u672c\u6587\u5c1d\u8bd5\u901a\u8fc7\u5b66\u4e60\u8f6f\u4eba\u5de5\u751f\u547d\u6a21\u578b\u89e3\u51b3\u65e0\u7269\u7406\u5148\u9a8c\u77e5\u8bc6\u65f6\u53cd\u5e94 - \u6269\u6563\u7cfb\u7edf\u7684\u7cfb\u7edf\u8bc6\u522b\u95ee\u9898\uff0c\u9a8c\u8bc1DRSALife\u6a21\u578b\u9002\u7528\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u9ad8\u4e14\u9c81\u68d2\u6027\u597d\u3002", "motivation": "\u89e3\u51b3\u5728\u65e0\u5e95\u5c42\u7269\u7406\u5148\u9a8c\u77e5\u8bc6\u60c5\u51b5\u4e0b\uff0c\u53cd\u5e94 - \u6269\u6563\u7cfb\u7edf\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u7684\u7cfb\u7edf\u8bc6\u522b\u6311\u6218\u3002", "method": "\u4ece\u89c2\u5bdf\u6570\u636e\u4e2d\u5b66\u4e60\u8f6f\u4eba\u5de5\u751f\u547d\u6a21\u578b\uff08\u5982\u57fa\u4e8e\u4ee3\u7406\u548c\u5143\u80de\u81ea\u52a8\u673a\u6a21\u578b\uff09\uff0c\u8fd0\u7528DRSALife\u6982\u5ff5\u6846\u67b6\u5b66\u4e60\u89c4\u5219\u96c6\uff0c\u8fd8\u7814\u7a76\u4e86\u566a\u58f0\u548c\u7a00\u758f\u6570\u636e\u96c6\u7684\u5f71\u54cd\u3002", "result": "\u5b66\u4e60\u7684\u6a21\u578b\u80fd\u4ee574%\u7684\u51c6\u786e\u7387\u9884\u6d4b\u6d8c\u73b0\u52a8\u529b\u5b66\uff0c\u5728\u9ad8\u65af\u566a\u58f0\u548c\u65f6\u95f4\u7a00\u758f\u6027\u4e0b\u8868\u73b0\u51fa\u8f83\u5f3a\u9c81\u68d2\u6027\uff0c\u6210\u529f\u8bc6\u522b\u5e95\u5c42\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7ed3\u6784\u548c\u53c2\u6570\u3002", "conclusion": "DRSALife\u6a21\u578b\u9002\u7528\u4e8e\u4ece\u89c2\u5bdf\u6570\u636e\u4e2d\u5b66\u4e60\u51c6\u786e\u8868\u793a\u53cd\u5e94 - \u6269\u6563\u7cfb\u7edf\u6d8c\u73b0\u52a8\u529b\u5b66\u7684\u8f6f\u4eba\u5de5\u751f\u547d\u89c4\u5219\u96c6\uff0c\u5728\u65e0\u7269\u7406\u5148\u9a8c\u77e5\u8bc6\u60c5\u51b5\u4e0b\u6709\u6548\u3002"}}
{"id": "2509.09337", "pdf": "https://arxiv.org/pdf/2509.09337", "abs": "https://arxiv.org/abs/2509.09337", "authors": ["Junda Ye", "Zhongbao Zhang", "Li Sun", "Siqiang Luo"], "title": "MoSE: Unveiling Structural Patterns in Graphs via Mixture of Subgraph Experts", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 11 figures", "summary": "While graph neural networks (GNNs) have achieved great success in learning\nfrom graph-structured data, their reliance on local, pairwise message passing\nrestricts their ability to capture complex, high-order subgraph patterns.\nleading to insufficient structural expressiveness. Recent efforts have\nattempted to enhance structural expressiveness by integrating random walk\nkernels into GNNs. However, these methods are inherently designed for\ngraph-level tasks, which limits their applicability to other downstream tasks\nsuch as node classification. Moreover, their fixed kernel configurations hinder\nthe model's flexibility in capturing diverse subgraph structures. To address\nthese limitations, this paper proposes a novel Mixture of Subgraph Experts\n(MoSE) framework for flexible and expressive subgraph-based representation\nlearning across diverse graph tasks. Specifically, MoSE extracts informative\nsubgraphs via anonymous walks and dynamically routes them to specialized\nexperts based on structural semantics, enabling the model to capture diverse\nsubgraph patterns with improved flexibility and interpretability. We further\nprovide a theoretical analysis of MoSE's expressivity within the Subgraph\nWeisfeiler-Lehman (SWL) Test, proving that it is more powerful than SWL.\nExtensive experiments, together with visualizations of learned subgraph\nexperts, demonstrate that MoSE not only outperforms competitive baselines but\nalso provides interpretable insights into structural patterns learned by the\nmodel.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMoSE\u6846\u67b6\u7528\u4e8e\u57fa\u4e8e\u5b50\u56fe\u7684\u8868\u793a\u5b66\u4e60\uff0c\u80fd\u5728\u4e0d\u540c\u56fe\u4efb\u52a1\u4e2d\u7075\u6d3b\u6355\u83b7\u5b50\u56fe\u6a21\u5f0f\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u6bd4SWL\u66f4\u5f3a\u5927\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u4e14\u6709\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709GNN\u4f9d\u8d56\u5c40\u90e8\u6210\u5bf9\u6d88\u606f\u4f20\u9012\uff0c\u7ed3\u6784\u8868\u8fbe\u80fd\u529b\u4e0d\u8db3\uff0c\u96c6\u6210\u968f\u673a\u6e38\u8d70\u6838\u7684\u65b9\u6cd5\u9002\u7528\u4e8e\u56fe\u7ea7\u4efb\u52a1\uff0c\u56fa\u5b9a\u6838\u914d\u7f6e\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faMoSE\u6846\u67b6\uff0c\u901a\u8fc7\u533f\u540d\u6e38\u8d70\u63d0\u53d6\u4fe1\u606f\u5b50\u56fe\uff0c\u6839\u636e\u7ed3\u6784\u8bed\u4e49\u5c06\u5176\u52a8\u6001\u8def\u7531\u5230\u4e13\u95e8\u7684\u4e13\u5bb6\u6a21\u5757\u3002", "result": "\u7406\u8bba\u4e0aMoSE\u6bd4SWL\u66f4\u5f3a\u5927\uff0c\u5b9e\u9a8c\u4e2dMoSE\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u80fd\u53ef\u89c6\u5316\u5c55\u793a\u5b66\u4e60\u5230\u7684\u5b50\u56fe\u4e13\u5bb6\u3002", "conclusion": "MoSE\u6846\u67b6\u80fd\u5728\u4e0d\u540c\u56fe\u4efb\u52a1\u4e2d\u5b9e\u73b0\u7075\u6d3b\u4e14\u6709\u8868\u73b0\u529b\u7684\u5b50\u56fe\u8868\u793a\u5b66\u4e60\uff0c\u5177\u6709\u66f4\u597d\u7684\u7075\u6d3b\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.08897", "pdf": "https://arxiv.org/pdf/2509.08897", "abs": "https://arxiv.org/abs/2509.08897", "authors": ["Davide Caffagni", "Sara Sarto", "Marcella Cornia", "Lorenzo Baraldi", "Rita Cucchiara"], "title": "Recurrence Meets Transformers for Universal Multimodal Retrieval", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "With the rapid advancement of multimodal retrieval and its application in\nLLMs and multimodal LLMs, increasingly complex retrieval tasks have emerged.\nExisting methods predominantly rely on task-specific fine-tuning of\nvision-language models and are limited to single-modality queries or documents.\nIn this paper, we propose ReT-2, a unified retrieval model that supports\nmultimodal queries, composed of both images and text, and searches across\nmultimodal document collections where text and images coexist. ReT-2 leverages\nmulti-layer representations and a recurrent Transformer architecture with\nLSTM-inspired gating mechanisms to dynamically integrate information across\nlayers and modalities, capturing fine-grained visual and textual details. We\nevaluate ReT-2 on the challenging M2KR and M-BEIR benchmarks across different\nretrieval configurations. Results demonstrate that ReT-2 consistently achieves\nstate-of-the-art performance across diverse settings, while offering faster\ninference and reduced memory usage compared to prior approaches. When\nintegrated into retrieval-augmented generation pipelines, ReT-2 also improves\ndownstream performance on Encyclopedic-VQA and InfoSeek datasets. Our source\ncode and trained models are publicly available at:\nhttps://github.com/aimagelab/ReT-2", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u68c0\u7d22\u6a21\u578bReT - 2\u652f\u6301\u591a\u6a21\u6001\u67e5\u8be2\u548c\u8de8\u591a\u6a21\u6001\u6587\u6863\u96c6\u5408\u641c\u7d22\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u4f73\u4e14\u6709\u4f18\u52bf\uff0c\u96c6\u6210\u540e\u80fd\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\uff0c\u5c40\u9650\u4e8e\u5355\u6a21\u6001\u67e5\u8be2\u6216\u6587\u6863\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u591a\u6a21\u6001\u68c0\u7d22\u4efb\u52a1\u9700\u6c42\u3002", "method": "\u63d0\u51faReT - 2\u6a21\u578b\uff0c\u5229\u7528\u591a\u5c42\u8868\u793a\u548c\u5177\u6709LSTM\u542f\u53d1\u95e8\u63a7\u673a\u5236\u7684\u5faa\u73afTransformer\u67b6\u6784\u52a8\u6001\u6574\u5408\u8de8\u5c42\u548c\u8de8\u6a21\u6001\u4fe1\u606f\u3002", "result": "\u5728M2KR\u548cM - BEIR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u63a8\u7406\u66f4\u5feb\u3001\u5185\u5b58\u4f7f\u7528\u66f4\u5c11\uff0c\u96c6\u6210\u5230\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ba1\u9053\u4e2d\u80fd\u63d0\u5347Encyclopedic - VQA\u548cInfoSeek\u6570\u636e\u96c6\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "ReT - 2\u662f\u6709\u6548\u7684\u591a\u6a21\u6001\u68c0\u7d22\u6a21\u578b\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.09380", "pdf": "https://arxiv.org/pdf/2509.09380", "abs": "https://arxiv.org/abs/2509.09380", "authors": ["Luca Giuliani", "Michele Lombardi"], "title": "Robust Non-Linear Correlations via Polynomial Regression", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "comment": null, "summary": "The Hirschfeld-Gebelein-R\\'enyi (HGR) correlation coefficient is an extension\nof Pearson's correlation that is not limited to linear correlations, with\npotential applications in algorithmic fairness, scientific analysis, and causal\ndiscovery. Recently, novel algorithms to estimate HGR in a differentiable\nmanner have been proposed to facilitate its use as a loss regularizer in\nconstrained machine learning applications. However, the inherent\nuncomputability of HGR requires a bias-variance trade-off, which can possibly\ncompromise the robustness of the proposed methods, hence raising technical\nconcerns if applied in real-world scenarios. We introduce a novel computational\napproach for HGR that relies on user-configurable polynomial kernels, offering\ngreater robustness compared to previous methods and featuring a faster yet\nalmost equally effective restriction. Our approach provides significant\nadvantages in terms of robustness and determinism, making it a more reliable\noption for real-world applications. Moreover, we present a brief experimental\nanalysis to validate the applicability of our approach within a constrained\nmachine learning framework, showing that its computation yields an insightful\nsubgradient that can serve as a loss regularizer.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7528\u6237\u53ef\u914d\u7f6e\u591a\u9879\u5f0f\u6838\u7684HGR\u8ba1\u7b97\u65b0\u65b9\u6cd5\uff0c\u6bd4\u4e4b\u524d\u65b9\u6cd5\u66f4\u7a33\u5065\uff0c\u8fd8\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u7ea6\u675f\u673a\u5668\u5b66\u4e60\u6846\u67b6\u4e2d\u7684\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u53ef\u5fae\u4f30\u8ba1HGR\u7684\u7b97\u6cd5\u5b58\u5728\u4e0d\u53ef\u8ba1\u7b97\u6027\u5bfc\u81f4\u7684\u504f\u5dee - \u65b9\u5dee\u6743\u8861\u95ee\u9898\uff0c\u5f71\u54cd\u65b9\u6cd5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165\u4f9d\u8d56\u7528\u6237\u53ef\u914d\u7f6e\u591a\u9879\u5f0f\u6838\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u9c81\u68d2\u6027\u548c\u786e\u5b9a\u6027\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\uff0c\u8ba1\u7b97\u80fd\u5f97\u5230\u53ef\u4f5c\u4e3a\u635f\u5931\u6b63\u5219\u5316\u5668\u7684\u6709\u6d1e\u5bdf\u529b\u7684\u6b21\u68af\u5ea6\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u662f\u73b0\u5b9e\u5e94\u7528\u4e2d\u66f4\u53ef\u9760\u7684\u9009\u62e9\uff0c\u5728\u7ea6\u675f\u673a\u5668\u5b66\u4e60\u6846\u67b6\u4e2d\u5177\u6709\u9002\u7528\u6027\u3002"}}
{"id": "2509.08910", "pdf": "https://arxiv.org/pdf/2509.08910", "abs": "https://arxiv.org/abs/2509.08910", "authors": ["Tung Vu", "Lam Nguyen", "Quynh Dao"], "title": "PromptGuard: An Orchestrated Prompting Framework for Principled Synthetic Text Generation for Vulnerable Populations using LLMs with Enhanced Safety, Fairness, and Controllability", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The proliferation of Large Language Models (LLMs) in real-world applications\nposes unprecedented risks of generating harmful, biased, or misleading\ninformation to vulnerable populations including LGBTQ+ individuals, single\nparents, and marginalized communities. While existing safety approaches rely on\npost-hoc filtering or generic alignment techniques, they fail to proactively\nprevent harmful outputs at the generation source. This paper introduces\nPromptGuard, a novel modular prompting framework with our breakthrough\ncontribution: VulnGuard Prompt, a hybrid technique that prevents harmful\ninformation generation using real-world data-driven contrastive learning.\nVulnGuard integrates few-shot examples from curated GitHub repositories,\nethical chain-of-thought reasoning, and adaptive role-prompting to create\npopulation-specific protective barriers. Our framework employs theoretical\nmulti-objective optimization with formal proofs demonstrating 25-30% analytical\nharm reduction through entropy bounds and Pareto optimality. PromptGuard\norchestrates six core modules: Input Classification, VulnGuard Prompting,\nEthical Principles Integration, External Tool Interaction, Output Validation,\nand User-System Interaction, creating an intelligent expert system for\nreal-time harm prevention. We provide comprehensive mathematical formalization\nincluding convergence proofs, vulnerability analysis using information theory,\nand theoretical validation framework using GitHub-sourced datasets,\nestablishing mathematical foundations for systematic empirical research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aPromptGuard\u7684\u6a21\u5757\u5316\u63d0\u793a\u6846\u67b6\uff0c\u5176\u6838\u5fc3VulnGuard Prompt\u6280\u672f\u53ef\u9632\u6b62\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6709\u5bb3\u4fe1\u606f\uff0c\u6846\u67b6\u542b\u516d\u4e2a\u6838\u5fc3\u6a21\u5757\uff0c\u6709\u6570\u5b66\u5f62\u5f0f\u5316\u548c\u7406\u8bba\u9a8c\u8bc1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u4f1a\u5bf9\u5f31\u52bf\u7fa4\u4f53\u4ea7\u751f\u6709\u5bb3\u4fe1\u606f\u98ce\u9669\uff0c\u73b0\u6709\u5b89\u5168\u65b9\u6cd5\u65e0\u6cd5\u4ece\u6e90\u5934\u9884\u9632\u3002", "method": "\u5f15\u5165PromptGuard\u6846\u67b6\uff0c\u5176\u4e2dVulnGuard Prompt\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u5bf9\u6bd4\u5b66\u4e60\u3001GitHub\u6570\u636e\u3001\u4f26\u7406\u63a8\u7406\u548c\u89d2\u8272\u63d0\u793a\uff1b\u91c7\u7528\u591a\u76ee\u6807\u4f18\u5316\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\uff1b\u6846\u67b6\u5305\u542b\u516d\u4e2a\u6838\u5fc3\u6a21\u5757\uff0c\u6709\u5168\u9762\u6570\u5b66\u5f62\u5f0f\u5316\u3002", "result": "\u6846\u67b6\u80fd\u901a\u8fc7\u71b5\u754c\u548c\u5e15\u7d2f\u6258\u6700\u4f18\u5b9e\u73b025 - 30%\u7684\u5206\u6790\u6027\u4f24\u5bb3\u51cf\u5c11\u3002", "conclusion": "\u4e3a\u7cfb\u7edf\u5b9e\u8bc1\u7814\u7a76\u5efa\u7acb\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u53ef\u5b9e\u73b0\u5b9e\u65f6\u4f24\u5bb3\u9884\u9632\u3002"}}
{"id": "2509.09387", "pdf": "https://arxiv.org/pdf/2509.09387", "abs": "https://arxiv.org/abs/2509.09387", "authors": ["Mohammed Tiouti", "Mohamed Bal-Ghaoui"], "title": "MetaLLMix : An XAI Aided LLM-Meta-learning Based Approach for Hyper-parameters Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Effective model and hyperparameter selection remains a major challenge in\ndeep learning, often requiring extensive expertise and computation. While\nAutoML and large language models (LLMs) promise automation, current LLM-based\napproaches rely on trial and error and expensive APIs, which provide limited\ninterpretability and generalizability. We propose MetaLLMiX, a zero-shot\nhyperparameter optimization framework combining meta-learning, explainable AI,\nand efficient LLM reasoning. By leveraging historical experiment outcomes with\nSHAP explanations, MetaLLMiX recommends optimal hyperparameters and pretrained\nmodels without additional trials. We further employ an LLM-as-judge evaluation\nto control output format, accuracy, and completeness. Experiments on eight\nmedical imaging datasets using nine open-source lightweight LLMs show that\nMetaLLMiX achieves competitive or superior performance to traditional HPO\nmethods while drastically reducing computational cost. Our local deployment\noutperforms prior API-based approaches, achieving optimal results on 5 of 8\ntasks, response time reductions of 99.6-99.9%, and the fastest training times\non 6 datasets (2.4-15.7x faster), maintaining accuracy within 1-5% of\nbest-performing baselines.", "AI": {"tldr": "\u63d0\u51faMetaLLMiX\u96f6\u6837\u672c\u8d85\u53c2\u6570\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u79cd\u6280\u672f\u63a8\u8350\u6700\u4f18\u8d85\u53c2\u548c\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e14\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4e2d\u6709\u6548\u6a21\u578b\u548c\u8d85\u53c2\u6570\u9009\u62e9\u6709\u6311\u6218\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u4f9d\u8d56\u8bd5\u9519\u548c\u6602\u8d35API\uff0c\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faMetaLLMiX\u6846\u67b6\uff0c\u7ed3\u5408\u5143\u5b66\u4e60\u3001\u53ef\u89e3\u91caAI\u548c\u9ad8\u6548\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u5229\u7528\u5386\u53f2\u5b9e\u9a8c\u7ed3\u679c\u548cSHAP\u89e3\u91ca\u63a8\u8350\u8d85\u53c2\u6570\uff0c\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u5668\u63a7\u5236\u8f93\u51fa\u3002", "result": "\u5728\u516b\u4e2a\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\uff0cMetaLLMiX\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\uff0c\u672c\u5730\u90e8\u7f72\u4f18\u4e8e\u57fa\u4e8eAPI\u7684\u65b9\u6cd5\uff0c\u591a\u9879\u6307\u6807\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "MetaLLMiX\u662f\u6709\u6548\u7684\u96f6\u6837\u672c\u8d85\u53c2\u6570\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u8f83\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09396", "pdf": "https://arxiv.org/pdf/2509.09396", "abs": "https://arxiv.org/abs/2509.09396", "authors": ["Harry Mayne", "Ryan Othniel Kearns", "Yushi Yang", "Andrew M. Bean", "Eoin Delaney", "Chris Russell", "Adam Mahdi"], "title": "LLMs Don't Know Their Own Decision Boundaries: The Unreliability of Self-Generated Counterfactual Explanations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted to EMNLP 2025 Main", "summary": "To collaborate effectively with humans, language models must be able to\nexplain their decisions in natural language. We study a specific type of\nself-explanation: self-generated counterfactual explanations (SCEs), where a\nmodel explains its prediction by modifying the input such that it would have\npredicted a different outcome. We evaluate whether LLMs can produce SCEs that\nare valid, achieving the intended outcome, and minimal, modifying the input no\nmore than necessary. When asked to generate counterfactuals, we find that LLMs\ntypically produce SCEs that are valid, but far from minimal, offering little\ninsight into their decision-making behaviour. Worryingly, when asked to\ngenerate minimal counterfactuals, LLMs typically make excessively small edits\nthat fail to change predictions. The observed validity-minimality trade-off is\nconsistent across several LLMs, datasets, and evaluation settings. Our findings\nsuggest that SCEs are, at best, an ineffective explainability tool and, at\nworst, can provide misleading insights into model behaviour. Proposals to\ndeploy LLMs in high-stakes settings must consider the impact of unreliable\nself-explanations on downstream decision-making. Our code is available at\nhttps://github.com/HarryMayne/SCEs.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\u7684\u6709\u6548\u6027\u548c\u6700\u5c0f\u6027\uff0c\u53d1\u73b0\u5b58\u5728\u6709\u6548\u6027 - \u6700\u5c0f\u6027\u6743\u8861\uff0cSCEs\u53ef\u80fd\u662f\u65e0\u6548\u6216\u8bef\u5bfc\u6027\u7684\u89e3\u91ca\u5de5\u5177\u3002", "motivation": "\u4e3a\u4f7f\u8bed\u8a00\u6a21\u578b\u80fd\u4e0e\u4eba\u7c7b\u6709\u6548\u534f\u4f5c\uff0c\u9700\u5176\u7528\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u51b3\u7b56\uff0c\u7814\u7a76\u81ea\u751f\u6210\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08SCEs\uff09\u3002", "method": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684SCEs\u662f\u5426\u6709\u6548\u548c\u6700\u5c0f\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684SCEs\u901a\u5e38\u6709\u6548\u4f46\u4e0d\u6700\u5c0f\uff0c\u8981\u6c42\u751f\u6210\u6700\u5c0f\u53cd\u4e8b\u5b9e\u65f6\u7f16\u8f91\u8fc7\u5c0f\u65e0\u6cd5\u6539\u53d8\u9884\u6d4b\uff0c\u5b58\u5728\u6709\u6548\u6027 - \u6700\u5c0f\u6027\u6743\u8861\u3002", "conclusion": "SCEs\u6700\u591a\u662f\u65e0\u6548\u7684\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff0c\u6700\u574f\u4f1a\u8bef\u5bfc\u6a21\u578b\u884c\u4e3a\uff0c\u9ad8\u98ce\u9669\u573a\u666f\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8003\u8651\u4e0d\u53ef\u9760\u81ea\u89e3\u91ca\u7684\u5f71\u54cd\u3002"}}
{"id": "2509.09408", "pdf": "https://arxiv.org/pdf/2509.09408", "abs": "https://arxiv.org/abs/2509.09408", "authors": ["Jonas Schmidinger", "Viacheslav Barkov", "Sebastian Vogel", "Martin Atzmueller", "Gerard B M Heuvelink"], "title": "Kriging prior Regression: A Case for Kriging-Based Spatial Features with TabPFN in Soil Mapping", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning and geostatistics are two fundamentally different frameworks\nfor predicting and spatially mapping soil properties. Geostatistics leverages\nthe spatial structure of soil properties, while machine learning captures the\nrelationship between available environmental features and soil properties. We\npropose a hybrid framework that enriches ML with spatial context through\nengineering of 'spatial lag' features from ordinary kriging. We call this\napproach 'kriging prior regression' (KpR), as it follows the inverse logic of\nregression kriging. To evaluate this approach, we assessed both the point and\nprobabilistic prediction performance of KpR, using the TabPFN model across six\nfieldscale datasets from LimeSoDa. These datasets included soil organic carbon,\nclay content, and pH, along with features derived from remote sensing and\nin-situ proximal soil sensing. KpR with TabPFN demonstrated reliable\nuncertainty estimates and more accurate predictions in comparison to several\nother spatial techniques (e.g., regression/residual kriging with TabPFN), as\nwell as to established non-spatial machine learning algorithms (e.g., random\nforest). Most notably, it significantly improved the average R2 by around 30%\ncompared to machine learning algorithms without spatial context. This\nimprovement was due to the strong prediction performance of the TabPFN\nalgorithm itself and the complementary spatial information provided by KpR\nfeatures. TabPFN is particularly effective for prediction tasks with small\nsample sizes, common in precision agriculture, whereas KpR can compensate for\nweak relationships between sensing features and soil properties when proximal\nsoil sensing data are limited. Hence, we conclude that KpR with TabPFN is a\nvery robust and versatile modelling framework for digital soil mapping in\nprecision agriculture.", "AI": {"tldr": "\u63d0\u51fa\u201c\u514b\u91cc\u91d1\u5148\u9a8c\u56de\u5f52\u201d\uff08KpR\uff09\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u4e0e\u5730\u7edf\u8ba1\u5b66\uff0c\u7528TabPFN\u6a21\u578b\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aKpR\u4e0eTabPFN\u6bd4\u5176\u4ed6\u65b9\u6cd5\u66f4\u4f18\uff0c\u662f\u7cbe\u51c6\u519c\u4e1a\u6570\u5b57\u571f\u58e4\u5236\u56fe\u7684\u5f3a\u5927\u6846\u67b6\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u548c\u5730\u7edf\u8ba1\u5b66\u662f\u9884\u6d4b\u548c\u7a7a\u95f4\u6620\u5c04\u571f\u58e4\u5c5e\u6027\u7684\u4e0d\u540c\u6846\u67b6\uff0c\u5e0c\u671b\u7ed3\u5408\u4e8c\u8005\u4f18\u52bf\u63d0\u51fa\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faKpR\u6846\u67b6\uff0c\u901a\u8fc7\u666e\u901a\u514b\u91cc\u91d1\u7684\u201c\u7a7a\u95f4\u6ede\u540e\u201d\u7279\u5f81\u4e30\u5bcc\u673a\u5668\u5b66\u4e60\u7684\u7a7a\u95f4\u4e0a\u4e0b\u6587\uff0c\u4f7f\u7528TabPFN\u6a21\u578b\u5728\u516d\u4e2a\u5b9e\u5730\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30KpR\u7684\u70b9\u9884\u6d4b\u548c\u6982\u7387\u9884\u6d4b\u6027\u80fd\u3002", "result": "KpR\u4e0eTabPFN\u6bd4\u5176\u4ed6\u7a7a\u95f4\u6280\u672f\u548c\u975e\u7a7a\u95f4\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6709\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u66f4\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u5e73\u5747R2\u6bd4\u65e0\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u63d0\u9ad8\u7ea630%\u3002", "conclusion": "KpR\u4e0eTabPFN\u662f\u7cbe\u51c6\u519c\u4e1a\u6570\u5b57\u571f\u58e4\u5236\u56fe\u975e\u5e38\u7a33\u5065\u4e14\u901a\u7528\u7684\u5efa\u6a21\u6846\u67b6\u3002"}}
{"id": "2509.09004", "pdf": "https://arxiv.org/pdf/2509.09004", "abs": "https://arxiv.org/abs/2509.09004", "authors": ["Andrew Bell", "Yan Kit Choi", "Steffen Peterson", "Andrew King", "Muhummad Sohaib Nazir", "Alistair Young"], "title": "Implicit Neural Representations of Intramyocardial Motion and Strain", "categories": ["cs.CV", "cs.AI"], "comment": "STACOM 2025 @ MICCAI", "summary": "Automatic quantification of intramyocardial motion and strain from tagging\nMRI remains an important but challenging task. We propose a method using\nimplicit neural representations (INRs), conditioned on learned latent codes, to\npredict continuous left ventricular (LV) displacement -- without requiring\ninference-time optimisation. Evaluated on 452 UK Biobank test cases, our method\nachieved the best tracking accuracy (2.14 mm RMSE) and the lowest combined\nerror in global circumferential (2.86%) and radial (6.42%) strain compared to\nthree deep learning baselines. In addition, our method is $\\sim$380$\\times$\nfaster than the most accurate baseline. These results highlight the suitability\nof INR-based models for accurate and scalable analysis of myocardial strain in\nlarge CMR datasets.", "AI": {"tldr": "\u63d0\u51fa\u7528\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u7684\u65b9\u6cd5\u81ea\u52a8\u91cf\u5316\u5fc3\u808c\u8fd0\u52a8\u548c\u5e94\u53d8\uff0c\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u9002\u5408\u5206\u6790\u5927\u578b\u6570\u636e\u96c6\u3002", "motivation": "\u81ea\u52a8\u91cf\u5316\u6807\u8bb0MRI\u7684\u5fc3\u808c\u5185\u8fd0\u52a8\u548c\u5e94\u53d8\u662f\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5b66\u4e60\u5230\u7684\u6f5c\u5728\u4ee3\u7801\u7684\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u6765\u9884\u6d4b\u8fde\u7eed\u7684\u5de6\u5fc3\u5ba4\uff08LV\uff09\u4f4d\u79fb\uff0c\u4e14\u65e0\u9700\u63a8\u7406\u65f6\u4f18\u5316\u3002", "result": "\u5728452\u4e2a\u82f1\u56fd\u751f\u7269\u94f6\u884c\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u4f73\u8ddf\u8e2a\u7cbe\u5ea6\uff082.14\u6beb\u7c73RMSE\uff09\uff0c\u5728\u6574\u4f53\u5706\u5468\uff082.86%\uff09\u548c\u5f84\u5411\uff086.42%\uff09\u5e94\u53d8\u65b9\u9762\u7684\u7efc\u5408\u8bef\u5dee\u6700\u4f4e\uff0c\u4e14\u6bd4\u6700\u51c6\u786e\u7684\u57fa\u7ebf\u6a21\u578b\u5feb\u7ea6380\u500d\u3002", "conclusion": "\u57fa\u4e8eINR\u7684\u6a21\u578b\u9002\u5408\u5bf9\u5927\u578bCMR\u6570\u636e\u96c6\u8fdb\u884c\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684\u5fc3\u808c\u5e94\u53d8\u5206\u6790\u3002"}}
{"id": "2509.09413", "pdf": "https://arxiv.org/pdf/2509.09413", "abs": "https://arxiv.org/abs/2509.09413", "authors": ["Daniel Agyapong", "Briana H. Beatty", "Peter G. Kennedy", "Toby D. Hocking"], "title": "Fused Lasso Improves Accuracy of Co-occurrence Network Inference in Grouped Samples", "categories": ["cs.LG", "q-bio.PE"], "comment": null, "summary": "Co-occurrence network inference algorithms have significantly advanced our\nunderstanding of microbiome communities. However, these algorithms typically\nanalyze microbial associations within samples collected from a single\nenvironmental niche, often capturing only static snapshots rather than dynamic\nmicrobial processes. Previous studies have commonly grouped samples from\ndifferent environmental niches together without fully considering how microbial\ncommunities adapt their associations when faced with varying ecological\nconditions. Our study addresses this limitation by explicitly investigating\nboth spatial and temporal dynamics of microbial communities. We analyzed\npublicly available microbiome abundance data across multiple locations and time\npoints, to evaluate algorithm performance in predicting microbial associations\nusing our proposed Same-All Cross-validation (SAC) framework. SAC evaluates\nalgorithms in two distinct scenarios: training and testing within the same\nenvironmental niche (Same), and training and testing on combined data from\nmultiple environmental niches (All). To overcome the limitations of\nconventional algorithms, we propose fuser, an algorithm that, while not\nentirely new in machine learning, is novel for microbiome community network\ninference. It retains subsample-specific signals while simultaneously sharing\nrelevant information across environments during training. Unlike standard\napproaches that infer a single generalized network from combined data, fuser\ngenerates distinct, environment-specific predictive networks. Our results\ndemonstrate that fuser achieves comparable predictive performance to existing\nalgorithms such as glmnet when evaluated within homogeneous environments\n(Same), and notably reduces test error compared to baseline algorithms in\ncross-environment (All) scenarios.", "AI": {"tldr": "\u7814\u7a76\u9488\u5bf9\u73b0\u6709\u5fae\u751f\u7269\u7fa4\u843d\u5171\u73b0\u7f51\u7edc\u63a8\u7406\u7b97\u6cd5\u4e0d\u8db3\uff0c\u63d0\u51faSAC\u6846\u67b6\u548cfuser\u7b97\u6cd5\uff0c\u7ed3\u679c\u663e\u793afuser\u5728\u540c\u8d28\u73af\u5883\u9884\u6d4b\u8868\u73b0\u4e0e\u73b0\u6709\u7b97\u6cd5\u76f8\u5f53\uff0c\u8de8\u73af\u5883\u573a\u666f\u964d\u4f4e\u6d4b\u8bd5\u8bef\u5dee\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u591a\u5206\u6790\u5355\u4e00\u73af\u5883\u6837\u672c\u5fae\u751f\u7269\u5173\u8054\uff0c\u672a\u8003\u8651\u4e0d\u540c\u751f\u6001\u6761\u4ef6\u4e0b\u5fae\u751f\u7269\u7fa4\u843d\u5173\u8054\u53d8\u5316\uff0c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6b64\u5c40\u9650\u3002", "method": "\u5206\u6790\u591a\u5730\u70b9\u548c\u65f6\u95f4\u70b9\u516c\u5f00\u5fae\u751f\u7269\u4e30\u5ea6\u6570\u636e\uff0c\u7528SAC\u6846\u67b6\u8bc4\u4f30\u7b97\u6cd5\u9884\u6d4b\u5fae\u751f\u7269\u5173\u8054\u6027\u80fd\uff0c\u63d0\u51fafuser\u7b97\u6cd5\u3002", "result": "fuser\u5728\u540c\u8d28\u73af\u5883\u4e2d\u4e0eglmnet\u7b49\u73b0\u6709\u7b97\u6cd5\u9884\u6d4b\u6027\u80fd\u76f8\u5f53\uff0c\u5728\u8de8\u73af\u5883\u573a\u666f\u6bd4\u57fa\u7ebf\u7b97\u6cd5\u663e\u8457\u964d\u4f4e\u6d4b\u8bd5\u8bef\u5dee\u3002", "conclusion": "fuser\u7b97\u6cd5\u5728\u5fae\u751f\u7269\u7fa4\u843d\u7f51\u7edc\u63a8\u7406\u4e2d\u5177\u6709\u4e00\u5b9a\u4f18\u52bf\uff0c\u5c24\u5176\u5728\u8de8\u73af\u5883\u573a\u666f\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2509.09451", "pdf": "https://arxiv.org/pdf/2509.09451", "abs": "https://arxiv.org/abs/2509.09451", "authors": ["Anjie Qiao", "Zhen Wang", "Chuan Chen", "DeFu Lian", "Enhong Chen"], "title": "Composable Score-based Graph Diffusion Model for Multi-Conditional Molecular Generation", "categories": ["cs.LG"], "comment": null, "summary": "Controllable molecular graph generation is essential for material and drug\ndiscovery, where generated molecules must satisfy diverse property constraints.\nWhile recent advances in graph diffusion models have improved generation\nquality, their effectiveness in multi-conditional settings remains limited due\nto reliance on joint conditioning or continuous relaxations that compromise\nfidelity. To address these limitations, we propose Composable Score-based Graph\nDiffusion model (CSGD), the first model that extends score matching to discrete\ngraphs via concrete scores, enabling flexible and principled manipulation of\nconditional guidance. Building on this foundation, we introduce two score-based\ntechniques: Composable Guidance (CoG), which allows fine-grained control over\narbitrary subsets of conditions during sampling, and Probability Calibration\n(PC), which adjusts estimated transition probabilities to mitigate train-test\nmismatches. Empirical results on four molecular datasets show that CSGD\nachieves state-of-the-art performance, with a 15.3% average improvement in\ncontrollability over prior methods, while maintaining high validity and\ndistributional fidelity. Our findings highlight the practical advantages of\nscore-based modeling for discrete graph generation and its capacity for\nflexible, multi-property molecular design.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u7ec4\u5408\u5206\u6570\u56fe\u6269\u6563\u6a21\u578bCSGD\u7528\u4e8e\u53ef\u63a7\u5206\u5b50\u56fe\u751f\u6210\uff0c\u5728\u591a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56fe\u6269\u6563\u6a21\u578b\u5728\u591a\u6761\u4ef6\u8bbe\u7f6e\u4e0b\u6548\u679c\u6709\u9650\uff0c\u4f9d\u8d56\u8054\u5408\u6761\u4ef6\u6216\u8fde\u7eed\u677e\u5f1b\u4f1a\u5f71\u54cd\u4fdd\u771f\u5ea6\u3002", "method": "\u63d0\u51faCSGD\u6a21\u578b\uff0c\u901a\u8fc7\u5177\u4f53\u5206\u6570\u5c06\u5206\u6570\u5339\u914d\u6269\u5c55\u5230\u79bb\u6563\u56fe\uff0c\u5f15\u5165Composable Guidance\u548cProbability Calibration\u6280\u672f\u3002", "result": "\u5728\u56db\u4e2a\u5206\u5b50\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u53ef\u63a7\u6027\u6bd4\u5148\u524d\u65b9\u6cd5\u5e73\u5747\u63d0\u9ad815.3%\uff0c\u4fdd\u6301\u9ad8\u6709\u6548\u6027\u548c\u5206\u5e03\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u5206\u6570\u7684\u5efa\u6a21\u5bf9\u79bb\u6563\u56fe\u751f\u6210\u6709\u5b9e\u9645\u4f18\u52bf\uff0c\u5177\u5907\u7075\u6d3b\u7684\u591a\u5c5e\u6027\u5206\u5b50\u8bbe\u8ba1\u80fd\u529b\u3002"}}
{"id": "2509.09013", "pdf": "https://arxiv.org/pdf/2509.09013", "abs": "https://arxiv.org/abs/2509.09013", "authors": ["Monjoy Narayan Choudhury", "Junling Wang", "Yifan Hou", "Mrinmaya Sachan"], "title": "Can Vision-Language Models Solve Visual Math Equations?", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Monjoy Narayan Choudhury and Junling Wang contributed equally to this\n  work. Accepted at EMNLP2025 main. Code and datasets are open-sourced with\n  links in the paper", "summary": "Despite strong performance in visual understanding and language-based\nreasoning, Vision-Language Models (VLMs) struggle with tasks requiring\nintegrated perception and symbolic computation. We study this limitation\nthrough visual equation solving, where mathematical equations are embedded in\nimages, variables are represented by object icons, and coefficients must be\ninferred by counting. While VLMs perform well on textual equations, they fail\non visually grounded counterparts. To understand this gap, we decompose the\ntask into coefficient counting and variable recognition, and find that counting\nis the primary bottleneck, even when recognition is accurate. We also observe\nthat composing recognition and reasoning introduces additional errors,\nhighlighting challenges in multi-step visual reasoning. Finally, as equation\ncomplexity increases, symbolic reasoning itself becomes a limiting factor.\nThese findings reveal key weaknesses in current VLMs and point toward future\nimprovements in visually grounded mathematical reasoning.", "AI": {"tldr": "\u7814\u7a76VLMs\u5728\u89c6\u89c9\u65b9\u7a0b\u6c42\u89e3\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\uff0c\u53d1\u73b0\u8ba1\u6570\u3001\u591a\u6b65\u63a8\u7406\u548c\u7b26\u53f7\u63a8\u7406\u662f\u74f6\u9888\uff0c\u4e3a\u6539\u8fdb\u6307\u660e\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1VLMs\u5728\u89c6\u89c9\u7406\u89e3\u548c\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u611f\u77e5\u4e0e\u7b26\u53f7\u8ba1\u7b97\u7ed3\u5408\u7684\u4efb\u52a1\u4e0a\u5b58\u5728\u56f0\u96be\uff0c\u901a\u8fc7\u89c6\u89c9\u65b9\u7a0b\u6c42\u89e3\u7814\u7a76\u8be5\u5c40\u9650\u3002", "method": "\u5c06\u89c6\u89c9\u65b9\u7a0b\u6c42\u89e3\u4efb\u52a1\u5206\u89e3\u4e3a\u7cfb\u6570\u8ba1\u6570\u548c\u53d8\u91cf\u8bc6\u522b\u3002", "result": "\u8ba1\u6570\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u7ec4\u5408\u8bc6\u522b\u548c\u63a8\u7406\u4f1a\u5f15\u5165\u989d\u5916\u9519\u8bef\uff0c\u65b9\u7a0b\u590d\u6742\u5ea6\u589e\u52a0\u65f6\u7b26\u53f7\u63a8\u7406\u4e5f\u6210\u9650\u5236\u56e0\u7d20\u3002", "conclusion": "\u63ed\u793a\u5f53\u524dVLMs\u7684\u5173\u952e\u5f31\u70b9\uff0c\u4e3a\u57fa\u4e8e\u89c6\u89c9\u7684\u6570\u5b66\u63a8\u7406\u6539\u8fdb\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2509.09458", "pdf": "https://arxiv.org/pdf/2509.09458", "abs": "https://arxiv.org/abs/2509.09458", "authors": ["Golnoosh Abdollahinejad", "Saleh Baghersalimi", "Denisa-Andreea Constantinescu", "Sergey Shevchik", "David Atienza"], "title": "AquaCast: Urban Water Dynamics Forecasting with Precipitation-Informed Multi-Input Transformer", "categories": ["cs.LG"], "comment": "This work has been submitted to Journal of Hydrology, Elsevier, and a\n  preprint version is also available at SSRN 10.2139/ssrn.5399833", "summary": "This work addresses the challenge of forecasting urban water dynamics by\ndeveloping a multi-input, multi-output deep learning model that incorporates\nboth endogenous variables (e.g., water height or discharge) and exogenous\nfactors (e.g., precipitation history and forecast reports). Unlike conventional\nforecasting, the proposed model, AquaCast, captures both inter-variable and\ntemporal dependencies across all inputs, while focusing forecast solely on\nendogenous variables. Exogenous inputs are fused via an embedding layer,\neliminating the need to forecast them and enabling the model to attend to their\nshort-term influences more effectively. We evaluate our approach on the\nLausanneCity dataset, which includes measurements from four urban drainage\nsensors, and demonstrate state-of-the-art performance when using only\nendogenous variables. Performance also improves with the inclusion of exogenous\nvariables and forecast reports. To assess generalization and scalability, we\nadditionally test the model on three large-scale synthesized datasets,\ngenerated from MeteoSwiss records, the Lorenz Attractors model, and the Random\nFields model, each representing a different level of temporal complexity across\n100 nodes. The results confirm that our model consistently outperforms existing\nbaselines and maintains a robust and accurate forecast across both real and\nsynthetic datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAquaCast\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u57ce\u5e02\u6c34\u52a8\u529b\u5b66\uff0c\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u5e94\u5bf9\u57ce\u5e02\u6c34\u52a8\u529b\u5b66\u9884\u6d4b\u6311\u6218\u3002", "method": "\u5f00\u53d1\u591a\u8f93\u5165\u591a\u8f93\u51fa\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bAquaCast\uff0c\u878d\u5408\u5916\u751f\u53d8\u91cf\uff0c\u901a\u8fc7\u5d4c\u5165\u5c42\u5904\u7406\u5916\u751f\u8f93\u5165\u3002", "result": "\u5728LausanneCity\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u8fbe\u5230\u5148\u8fdb\u6c34\u5e73\uff0c\u52a0\u5165\u5916\u751f\u53d8\u91cf\u548c\u9884\u62a5\u62a5\u544a\u6027\u80fd\u63d0\u5347\uff0c\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u96c6\u4e0a\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6a21\u578b\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u80fd\u8fdb\u884c\u7a33\u5065\u51c6\u786e\u7684\u9884\u6d4b\u3002"}}
{"id": "2509.09018", "pdf": "https://arxiv.org/pdf/2509.09018", "abs": "https://arxiv.org/abs/2509.09018", "authors": ["Xueyi Wang", "C. J. C.", "Lamoth", "Elisabeth Wilhelm"], "title": "Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "The paper has been acceptted and presented in the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society", "summary": "A sleep forecast allows individuals and healthcare providers to anticipate\nand proactively address factors influencing restful rest, ultimately improving\nmental and physical well-being. This work presents an adaptive spatial and\ntemporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model\ncombines convolutional layers to capture spatial feature interactions between\nmultiple features and recurrent neural network layers to handle longer-term\ntemporal health-related data. A domain classifier is further integrated to\ngeneralize across different subjects. We conducted several experiments using\nfive input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes\n(1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline\nmodels, achieving its lowest RMSE (0.282) with a seven-day input window and a\none-day predicting window. Moreover, the method maintained strong performance\neven when forecasting multiple days into the future, demonstrating its\nversatility for real-world applications. Visual comparisons reveal that the\nmodel accurately tracks both the overall sleep score level and daily\nfluctuations. These findings prove that the proposed framework provides a\nrobust and adaptable solution for personalized sleep forecasting using sparse\ndata from commercial wearable devices and domain adaptation techniques.", "AI": {"tldr": "\u63d0\u51faAdaST - Sleep\u6a21\u578b\u9884\u6d4b\u7761\u7720\u5206\u6570\uff0c\u7ed3\u5408\u5377\u79ef\u548c\u5faa\u73af\u5c42\uff0c\u8de8\u5bf9\u8c61\u6cdb\u5316\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u4e2a\u6027\u5316\u7761\u7720\u9884\u6d4b\u3002", "motivation": "\u7761\u7720\u9884\u6d4b\u53ef\u5e2e\u52a9\u4e2a\u4eba\u548c\u533b\u7597\u4eba\u5458\u63d0\u524d\u5e94\u5bf9\u5f71\u54cd\u7761\u7720\u7684\u56e0\u7d20\uff0c\u6539\u5584\u8eab\u5fc3\u5065\u5eb7\u3002", "method": "\u63d0\u51faAdaST - Sleep\u6a21\u578b\uff0c\u7ed3\u5408\u5377\u79ef\u5c42\u6355\u6349\u7a7a\u95f4\u7279\u5f81\u4ea4\u4e92\uff0c\u5faa\u73af\u5c42\u5904\u7406\u957f\u671f\u65f6\u95f4\u6570\u636e\uff0c\u96c6\u6210\u57df\u5206\u7c7b\u5668\u5b9e\u73b0\u8de8\u5bf9\u8c61\u6cdb\u5316\uff0c\u7528\u4e0d\u540c\u8f93\u5165\u548c\u9884\u6d4b\u7a97\u53e3\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u56db\u4e2a\u57fa\u7ebf\u6a21\u578b\uff0c7\u5929\u8f93\u5165\u7a97\u53e3\u548c1\u5929\u9884\u6d4b\u7a97\u53e3\u65f6RMSE\u6700\u4f4e\u4e3a0.282\uff0c\u591a\u65e5\u9884\u6d4b\u8868\u73b0\u4e5f\u5f3a\uff0c\u80fd\u51c6\u786e\u8ddf\u8e2a\u6574\u4f53\u7761\u7720\u5206\u6570\u548c\u6bcf\u65e5\u6ce2\u52a8\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5229\u7528\u5546\u4e1a\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u7a00\u758f\u6570\u636e\u548c\u57df\u9002\u5e94\u6280\u672f\u8fdb\u884c\u4e2a\u6027\u5316\u7761\u7720\u9884\u6d4b\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09470", "pdf": "https://arxiv.org/pdf/2509.09470", "abs": "https://arxiv.org/abs/2509.09470", "authors": ["Om Vishesh", "Harshad Khadilkar", "Deepak Akkil"], "title": "AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings", "categories": ["cs.LG"], "comment": "5 pages, 2 figures", "summary": "Keeping pace with the rapid growth of academia literature presents a\nsignificant challenge for researchers, funding bodies, and academic societies.\nTo address the time-consuming manual effort required for scholarly discovery,\nwe present a novel, fully automated system that transitions from data discovery\nto direct action. Our pipeline demonstrates how a specialized AI agent,\n'Agent-E', can be tasked with identifying papers from specific geographic\nregions within conference proceedings and then executing a Robotic Process\nAutomation (RPA) to complete a predefined action, such as submitting a\nnomination form. We validated our system on 586 papers from five different\nconferences, where it successfully identified every target paper with a recall\nof 100% and a near perfect accuracy of 99.4%. This demonstration highlights the\npotential of task-oriented AI agents to not only filter information but also to\nactively participate in and accelerate the workflows of the academic community.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u7cfb\u7edf\uff0c\u7528AI\u4ee3\u7406\u8bc6\u522b\u8bba\u6587\u5e76\u6267\u884cRPA\uff0c\u9a8c\u8bc1\u6548\u679c\u597d\uff0c\u5c55\u793a\u4e86\u4efb\u52a1\u5bfc\u5411AI\u4ee3\u7406\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u5b66\u672f\u6587\u732e\u589e\u957f\u5feb\uff0c\u5b66\u672f\u53d1\u73b0\u624b\u52a8\u5de5\u4f5c\u8017\u65f6\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4ece\u6570\u636e\u53d1\u73b0\u5230\u76f4\u63a5\u884c\u52a8\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u7528AI\u4ee3\u7406'Agent - E'\u8bc6\u522b\u7279\u5b9a\u5730\u7406\u533a\u57df\u8bba\u6587\u5e76\u6267\u884cRPA\u3002", "result": "\u5728586\u7bc7\u8bba\u6587\u4e0a\u9a8c\u8bc1\uff0c\u53ec\u56de\u7387100%\uff0c\u51c6\u786e\u738799.4%\u3002", "conclusion": "\u4efb\u52a1\u5bfc\u5411AI\u4ee3\u7406\u4e0d\u4ec5\u80fd\u8fc7\u6ee4\u4fe1\u606f\uff0c\u8fd8\u80fd\u53c2\u4e0e\u5e76\u52a0\u901f\u5b66\u672f\u793e\u533a\u5de5\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2509.09474", "pdf": "https://arxiv.org/pdf/2509.09474", "abs": "https://arxiv.org/abs/2509.09474", "authors": ["Julia Gastinger", "Christian Meilicke", "Heiner Stuckenschmidt"], "title": "CountTRuCoLa: Rule Confidence Learning for Temporal Knowledge Graph Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "We address the task of temporal knowledge graph (TKG) forecasting by\nintroducing a fully explainable method based on temporal rules. Motivated by\nrecent work proposing a strong baseline using recurrent facts, our approach\nlearns four simple types of rules with a confidence function that considers\nboth recency and frequency. Evaluated on nine datasets, our method matches or\nsurpasses the performance of eight state-of-the-art models and two baselines,\nwhile providing fully interpretable predictions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u65f6\u95f4\u89c4\u5219\u7684\u53ef\u89e3\u91ca\u65b9\u6cd5\u8fdb\u884c\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\uff0c\u6027\u80fd\u8d85\u591a\u4e2a\u6a21\u578b\u4e14\u9884\u6d4b\u53ef\u89e3\u91ca", "motivation": "\u53d7\u4f7f\u7528\u5faa\u73af\u4e8b\u5b9e\u7684\u5f3a\u57fa\u7ebf\u5de5\u4f5c\u542f\u53d1\uff0c\u89e3\u51b3\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\u4efb\u52a1", "method": "\u5b66\u4e60\u56db\u79cd\u7b80\u5355\u7c7b\u578b\u89c4\u5219\uff0c\u4f7f\u7528\u8003\u8651\u8fd1\u671f\u6027\u548c\u9891\u7387\u7684\u7f6e\u4fe1\u51fd\u6570", "result": "\u5728\u4e5d\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6027\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u516b\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u548c\u4e24\u4e2a\u57fa\u7ebf", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5728\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\u4e2d\u63d0\u4f9b\u5b8c\u5168\u53ef\u89e3\u91ca\u7684\u9884\u6d4b"}}
{"id": "2509.09043", "pdf": "https://arxiv.org/pdf/2509.09043", "abs": "https://arxiv.org/abs/2509.09043", "authors": ["Thomas Manuel Rost", "Martina Figlia", "Bernd Wallraff"], "title": "Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": null, "summary": "We introduce and evaluate Stated Preference for Interaction and Continued\nEngagement (SPICE), a simple diagnostic signal elicited by asking a Large\nLanguage Model a YES or NO question about its willingness to re-engage with a\nuser's behavior after reviewing a short transcript. In a study using a 3-tone\n(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four\nopen-weight chat models across four framing conditions, resulting in 480\ntrials. Our findings show that SPICE sharply discriminates by user tone.\nFriendly interactions yielded a near-unanimous preference to continue (97.5%\nYES), while abusive interactions yielded a strong preference to discontinue\n(17.9% YES), with unclear interactions falling in between (60.4% YES). This\ncore association remains decisive under multiple dependence-aware statistical\ntests, including Rao-Scott adjustment and cluster permutation tests.\nFurthermore, we demonstrate that SPICE provides a distinct signal from abuse\nclassification. In trials where a model failed to identify abuse, it still\noverwhelmingly stated a preference not to continue the interaction (81% of the\ntime). An exploratory analysis also reveals a significant interaction effect: a\npreamble describing the study context significantly impacts SPICE under\nambiguity, but only when transcripts are presented as a single block of text\nrather than a multi-turn chat. The results validate SPICE as a robust,\nlow-overhead, and reproducible tool for auditing model dispositions,\ncomplementing existing metrics by offering a direct, relational signal of a\nmodel's state. All stimuli, code, and analysis scripts are released to support\nreplication.", "AI": {"tldr": "\u4ecb\u7ecd\u5e76\u8bc4\u4f30SPICE\uff0c\u7814\u7a76\u8868\u660e\u5176\u80fd\u6309\u7528\u6237\u8bed\u6c14\u533a\u5206\uff0c\u662f\u5ba1\u6838\u6a21\u578b\u503e\u5411\u7684\u6709\u6548\u5de5\u5177\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u8bca\u65ad\u4fe1\u53f7SPICE\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7528\u6237\u91cd\u65b0\u4e92\u52a8\u7684\u610f\u613f\u3002", "method": "\u75283\u79cd\u8bed\u6c14\u300110\u79cd\u4e92\u52a8\u523a\u6fc0\u96c6\u5bf94\u79cd\u5f00\u653e\u6743\u91cd\u804a\u5929\u6a21\u578b\u57284\u79cd\u6846\u67b6\u6761\u4ef6\u4e0b\u8fdb\u884c480\u6b21\u8bd5\u9a8c\u3002", "result": "SPICE\u80fd\u6309\u7528\u6237\u8bed\u6c14\u533a\u5206\uff0c\u4e0e\u6ee5\u7528\u5206\u7c7b\u4fe1\u53f7\u4e0d\u540c\uff0c\u7814\u7a76\u80cc\u666f\u63cf\u8ff0\u5728\u7279\u5b9a\u6587\u672c\u5448\u73b0\u65b9\u5f0f\u4e0b\u5f71\u54cdSPICE\u3002", "conclusion": "SPICE\u662f\u5ba1\u6838\u6a21\u578b\u503e\u5411\u7684\u53ef\u9760\u3001\u4f4e\u6210\u672c\u4e14\u53ef\u590d\u73b0\u7684\u5de5\u5177\u3002"}}
{"id": "2509.09485", "pdf": "https://arxiv.org/pdf/2509.09485", "abs": "https://arxiv.org/abs/2509.09485", "authors": ["Zhanhong Jiang", "Md Zahid Hasan", "Nastaran Saadati", "Aditya Balu", "Chao Liu", "Soumik Sarkar"], "title": "Balancing Utility and Privacy: Dynamically Private SGD with Random Projection", "categories": ["cs.LG"], "comment": "27 pages, 13 figures", "summary": "Stochastic optimization is a pivotal enabler in modern machine learning,\nproducing effective models for various tasks. However, several existing works\nhave shown that model parameters and gradient information are susceptible to\nprivacy leakage. Although Differentially Private SGD (DPSGD) addresses privacy\nconcerns, its static noise mechanism impacts the error bounds for model\nperformance. Additionally, with the exponential increase in model parameters,\nefficient learning of these models using stochastic optimizers has become more\nchallenging. To address these concerns, we introduce the Dynamically\nDifferentially Private Projected SGD (D2P2-SGD) optimizer. In D2P2-SGD, we\ncombine two important ideas: (i) dynamic differential privacy (DDP) with\nautomatic gradient clipping and (ii) random projection with SGD, allowing\ndynamic adjustment of the tradeoff between utility and privacy of the model. It\nexhibits provably sub-linear convergence rates across different objective\nfunctions, matching the best available rate. The theoretical analysis further\nsuggests that DDP leads to better utility at the cost of privacy, while random\nprojection enables more efficient model learning. Extensive experiments across\ndiverse datasets show that D2P2-SGD remarkably enhances accuracy while\nmaintaining privacy. Our code is available here.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faD2P2 - SGD\u4f18\u5316\u5668\uff0c\u7ed3\u5408\u52a8\u6001\u5dee\u5206\u9690\u79c1\u548c\u968f\u673a\u6295\u5f71\u4e0eSGD\uff0c\u6709\u6b21\u7ebf\u6027\u6536\u655b\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u63d0\u5347\u51c6\u786e\u7387\u5e76\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u73b0\u6709\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0cDPSGD\u6709\u9759\u6001\u566a\u58f0\u673a\u5236\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u6a21\u578b\u53c2\u6570\u589e\u52a0\u4f7f\u9ad8\u6548\u5b66\u4e60\u66f4\u5177\u6311\u6218\u3002", "method": "\u5f15\u5165D2P2 - SGD\u4f18\u5316\u5668\uff0c\u7ed3\u5408\u52a8\u6001\u5dee\u5206\u9690\u79c1\u4e0e\u81ea\u52a8\u68af\u5ea6\u88c1\u526a\u3001\u968f\u673a\u6295\u5f71\u4e0eSGD\uff0c\u52a8\u6001\u8c03\u6574\u6a21\u578b\u6548\u7528\u548c\u9690\u79c1\u7684\u6743\u8861\u3002", "result": "D2P2 - SGD\u5728\u4e0d\u540c\u76ee\u6807\u51fd\u6570\u4e0b\u6709\u53ef\u8bc1\u660e\u7684\u6b21\u7ebf\u6027\u6536\u655b\u7387\uff0c\u5339\u914d\u6700\u4f18\u53ef\u7528\u7387\uff1b\u7406\u8bba\u5206\u6790\u8868\u660e\u52a8\u6001\u5dee\u5206\u9690\u79c1\u4ee5\u9690\u79c1\u4e3a\u4ee3\u4ef7\u5e26\u6765\u66f4\u597d\u6548\u7528\uff0c\u968f\u673a\u6295\u5f71\u4f7f\u6a21\u578b\u5b66\u4e60\u66f4\u9ad8\u6548\u3002", "conclusion": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eD2P2 - SGD\u80fd\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u7387\u5e76\u4fdd\u6301\u9690\u79c1\u3002"}}
{"id": "2509.09512", "pdf": "https://arxiv.org/pdf/2509.09512", "abs": "https://arxiv.org/abs/2509.09512", "authors": ["Cynthia Moreira Maia", "Lucas B. V. de Amorim", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "PIPES: A Meta-dataset of Machine Learning Pipelines", "categories": ["cs.LG"], "comment": null, "summary": "Solutions to the Algorithm Selection Problem (ASP) in machine learning face\nthe challenge of high computational costs associated with evaluating various\nalgorithms' performances on a given dataset. To mitigate this cost, the\nmeta-learning field can leverage previously executed experiments shared in\nonline repositories such as OpenML. OpenML provides an extensive collection of\nmachine learning experiments. However, an analysis of OpenML's records reveals\nlimitations. It lacks diversity in pipelines, specifically when exploring data\npreprocessing steps/blocks, such as scaling or imputation, resulting in limited\nrepresentation. Its experiments are often focused on a few popular techniques\nwithin each pipeline block, leading to an imbalanced sample. To overcome the\nobserved limitations of OpenML, we propose PIPES, a collection of experiments\ninvolving multiple pipelines designed to represent all combinations of the\nselected sets of techniques, aiming at diversity and completeness. PIPES stores\nthe results of experiments performed applying 9,408 pipelines to 300 datasets.\nIt includes detailed information on the pipeline blocks, training and testing\ntimes, predictions, performances, and the eventual error messages. This\ncomprehensive collection of results allows researchers to perform analyses\nacross diverse and representative pipelines and datasets. PIPES also offers\npotential for expansion, as additional data and experiments can be incorporated\nto support the meta-learning community further. The data, code, supplementary\nmaterial, and all experiments can be found at\nhttps://github.com/cynthiamaia/PIPES.git.", "AI": {"tldr": "\u4e3a\u964d\u4f4e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u9009\u62e9\u95ee\u9898\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5206\u6790OpenML\u5c40\u9650\u6027\u540e\u63d0\u51faPIPES\uff0c\u5305\u542b\u591a\u7ba1\u9053\u5b9e\u9a8c\u7ed3\u679c\uff0c\u53ef\u8de8\u591a\u6837\u7ba1\u9053\u548c\u6570\u636e\u96c6\u5206\u6790\uff0c\u6709\u6269\u5c55\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u9009\u62e9\u95ee\u9898\u4e2d\u8bc4\u4f30\u7b97\u6cd5\u6027\u80fd\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u4e14OpenML\u5b58\u5728\u7ba1\u9053\u591a\u6837\u6027\u4e0d\u8db3\u7b49\u5c40\u9650\u3002", "method": "\u63d0\u51faPIPES\uff0c\u5c069408\u4e2a\u7ba1\u9053\u5e94\u7528\u4e8e300\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u5b58\u50a8\u8be6\u7ec6\u7ed3\u679c\u3002", "result": "\u5f97\u5230\u6db5\u76d6\u7ba1\u9053\u5757\u3001\u8bad\u7ec3\u6d4b\u8bd5\u65f6\u95f4\u3001\u9884\u6d4b\u3001\u6027\u80fd\u548c\u9519\u8bef\u4fe1\u606f\u7b49\u7684\u7efc\u5408\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "PIPES\u80fd\u8ba9\u7814\u7a76\u8005\u8de8\u591a\u6837\u7ba1\u9053\u548c\u6570\u636e\u96c6\u5206\u6790\uff0c\u6709\u6269\u5c55\u6f5c\u529b\uff0c\u652f\u6301\u5143\u5b66\u4e60\u793e\u533a\u3002"}}
{"id": "2509.09515", "pdf": "https://arxiv.org/pdf/2509.09515", "abs": "https://arxiv.org/abs/2509.09515", "authors": ["Yoga Disha Sendhil Kumar", "Manas V Shetty", "Sudip Vhaduri"], "title": "Cough Classification using Few-Shot Learning", "categories": ["cs.LG"], "comment": "8 pages 8 images Has been accepted in Pervasive Health 2025", "summary": "This paper investigates the effectiveness of few-shot learning for\nrespiratory sound classification, focusing on coughbased detection of COVID-19,\nFlu, and healthy conditions. We leverage Prototypical Networks with spectrogram\nrepresentations of cough sounds to address the challenge of limited labeled\ndata. Our study evaluates whether few-shot learning can enable models to\nachieve performance comparable to traditional deep learning approaches while\nusing significantly fewer training samples. Additionally, we compare\nmulti-class and binary classification models to assess whether multi-class\nmodels can perform comparably to their binary counterparts. Experimental\nfindings show that few-shot learning models can achieve competitive accuracy.\nOur model attains 74.87% accuracy in multi-class classification with only 15\nsupport examples per class, while binary classification achieves over 70%\naccuracy across all class pairs. Class-wise analysis reveals Flu as the most\ndistinguishable class, and Healthy as the most challenging. Statistical tests\n(paired t-test p = 0.149, Wilcoxon p = 0.125) indicate no significant\nperformance difference between binary and multiclass models, supporting the\nviability of multi-class classification in this setting. These results\nhighlight the feasibility of applying few-shot learning in medical diagnostics,\nparticularly when large labeled datasets are unavailable.", "AI": {"tldr": "\u7814\u7a76\u5c11\u6837\u672c\u5b66\u4e60\u7528\u4e8e\u547c\u5438\u97f3\u5206\u7c7b\uff0c\u5c24\u5176\u662f\u57fa\u4e8e\u54b3\u55fd\u68c0\u6d4b\u75be\u75c5\u7684\u6709\u6548\u6027\uff0c\u6a21\u578b\u6709\u7ade\u4e89\u529b\uff0c\u663e\u793a\u5c11\u6837\u672c\u5b66\u4e60\u5728\u533b\u7597\u8bca\u65ad\u53ef\u884c\u3002", "motivation": "\u63a2\u7a76\u5c11\u6837\u672c\u5b66\u4e60\u5728\u547c\u5438\u97f3\u5206\u7c7b\u4e2d\u80fd\u5426\u7528\u66f4\u5c11\u6837\u672c\u8fbe\u5230\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6027\u80fd\uff0c\u6bd4\u8f83\u591a\u5206\u7c7b\u548c\u4e8c\u5206\u7c7b\u6a21\u578b\u8868\u73b0\u3002", "method": "\u5229\u7528\u539f\u578b\u7f51\u7edc\u548c\u54b3\u55fd\u58f0\u9891\u8c31\u56fe\u8868\u793a\uff0c\u8bc4\u4f30\u5c11\u6837\u672c\u5b66\u4e60\u6a21\u578b\uff0c\u5bf9\u6bd4\u591a\u5206\u7c7b\u548c\u4e8c\u5206\u7c7b\u6a21\u578b\u3002", "result": "\u5c11\u6837\u672c\u5b66\u4e60\u6a21\u578b\u6709\u7ade\u4e89\u529b\uff0c\u591a\u5206\u7c7b74.87%\u51c6\u786e\u7387\uff0c\u4e8c\u5206\u7c7b\u8d8570%\uff0c\u6d41\u611f\u6700\u6613\u533a\u5206\uff0c\u5065\u5eb7\u6700\u96be\uff0c\u4e24\u7c7b\u6a21\u578b\u65e0\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5c11\u6837\u672c\u5b66\u4e60\u5728\u533b\u7597\u8bca\u65ad\u5c24\u5176\u662f\u7f3a\u4e4f\u5927\u6807\u6ce8\u6570\u636e\u96c6\u65f6\u53ef\u884c\u3002"}}
{"id": "2509.09055", "pdf": "https://arxiv.org/pdf/2509.09055", "abs": "https://arxiv.org/abs/2509.09055", "authors": ["Piyush Pant"], "title": "Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "17 pages, 3 figures. Code and dataset available at\n  https://github.com/PiyushWithPant/Improving-LLM-Safety-and-Helpfulness-using-SFT-and-DPO", "summary": "This research investigates the effectiveness of alignment techniques,\nSupervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a\ncombined SFT+DPO approach on improving the safety and helpfulness of the\nOPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,\nwe train and evaluate four models: the base OPT350M, an SFT model, a DPO model,\nand a model trained with both SFT and DPO. We introduce three key evaluation\nmetrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined\nAlignment Score (CAS), all derived from reward model outputs. The results show\nthat while SFT outperforms DPO, The combined SFT+DPO model outperforms all\nothers across all metrics, demonstrating the complementary nature of these\ntechniques. Our findings also highlight challenges posed by noisy data, limited\nGPU resources, and training constraints. This study offers a comprehensive view\nof how fine-tuning strategies affect model alignment and provides a foundation\nfor more robust alignment pipelines in future work.", "AI": {"tldr": "\u7814\u7a76SFT\u3001DPO\u53caSFT+DPO\u5bf9\u9f50\u6280\u672f\u5bf9OPT - 350M\u6a21\u578b\u5b89\u5168\u6027\u548c\u6709\u7528\u6027\u7684\u63d0\u5347\u6548\u679c\uff0c\u53d1\u73b0SFT+DPO\u7ec4\u5408\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63a2\u7a76\u4e0d\u540c\u5bf9\u9f50\u6280\u672f\u5bf9\u63d0\u5347OPT - 350M\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u548c\u6709\u7528\u6027\u7684\u6709\u6548\u6027\u3002", "method": "\u5229\u7528Anthropic Helpful - Harmless RLHF\u6570\u636e\u96c6\u8bad\u7ec3\u548c\u8bc4\u4f30\u56db\u79cd\u6a21\u578b\uff0c\u5f15\u5165HmR\u3001HpR\u548cCAS\u4e09\u4e2a\u8bc4\u4f30\u6307\u6807\u3002", "result": "SFT\u4f18\u4e8eDPO\uff0cSFT+DPO\u7ec4\u5408\u6a21\u578b\u5728\u6240\u6709\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u5fae\u8c03\u7b56\u7565\u5bf9\u6a21\u578b\u5bf9\u9f50\u7684\u5f71\u54cd\uff0c\u4e3a\u672a\u6765\u66f4\u5f3a\u5927\u7684\u5bf9\u9f50\u7ba1\u9053\u5960\u5b9a\u57fa\u7840\uff0c\u540c\u65f6\u6307\u51fa\u5b58\u5728\u566a\u58f0\u6570\u636e\u3001GPU\u8d44\u6e90\u6709\u9650\u548c\u8bad\u7ec3\u7ea6\u675f\u7b49\u6311\u6218\u3002"}}
{"id": "2509.09597", "pdf": "https://arxiv.org/pdf/2509.09597", "abs": "https://arxiv.org/abs/2509.09597", "authors": ["Maysam Behmanesh", "Erkan Turan", "Maks Ovsjanikov"], "title": "Graph Alignment via Dual-Pass Spectral Encoding and Latent Space Communication", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "23 pages", "summary": "Graph alignment-the problem of identifying corresponding nodes across\nmultiple graphs-is fundamental to numerous applications. Most existing\nunsupervised methods embed node features into latent representations to enable\ncross-graph comparison without ground-truth correspondences. However, these\nmethods suffer from two critical limitations: the degradation of node\ndistinctiveness due to oversmoothing in GNN-based embeddings, and the\nmisalignment of latent spaces across graphs caused by structural noise, feature\nheterogeneity, and training instability, ultimately leading to unreliable node\ncorrespondences. We propose a novel graph alignment framework that\nsimultaneously enhances node distinctiveness and enforces geometric consistency\nacross latent spaces. Our approach introduces a dual-pass encoder that combines\nlow-pass and high-pass spectral filters to generate embeddings that are both\nstructure-aware and highly discriminative. To address latent space\nmisalignment, we incorporate a geometry-aware functional map module that learns\nbijective and isometric transformations between graph embeddings, ensuring\nconsistent geometric relationships across different representations. Extensive\nexperiments on graph benchmarks demonstrate that our method consistently\noutperforms existing unsupervised alignment baselines, exhibiting superior\nrobustness to structural inconsistencies and challenging alignment scenarios.\nAdditionally, comprehensive evaluation on vision-language benchmarks using\ndiverse pretrained models shows that our framework effectively generalizes\nbeyond graph domains, enabling unsupervised alignment of vision and language\nrepresentations.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u56fe\u5bf9\u9f50\u6846\u67b6\uff0c\u7ed3\u5408\u53cc\u901a\u7f16\u7801\u5668\u548c\u51e0\u4f55\u611f\u77e5\u529f\u80fd\u56fe\u6a21\u5757\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u4e14\u80fd\u6cdb\u5316\u5230\u89c6\u89c9 - \u8bed\u8a00\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u56fe\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u8282\u70b9\u533a\u5206\u5ea6\u4e0b\u964d\u548c\u6f5c\u5728\u7a7a\u95f4\u4e0d\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8282\u70b9\u5bf9\u5e94\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u4f4e\u901a\u548c\u9ad8\u901a\u5149\u8c31\u6ee4\u6ce2\u5668\u7684\u53cc\u901a\u7f16\u7801\u5668\u751f\u6210\u5d4c\u5165\uff0c\u5f15\u5165\u51e0\u4f55\u611f\u77e5\u529f\u80fd\u56fe\u6a21\u5757\u5b66\u4e60\u56fe\u5d4c\u5165\u95f4\u7684\u53cc\u5c04\u548c\u7b49\u8ddd\u53d8\u6362\u3002", "result": "\u5728\u56fe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763\u5bf9\u9f50\u57fa\u7ebf\uff0c\u5728\u89c6\u89c9 - \u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u80fd\u6709\u6548\u6cdb\u5316\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u589e\u5f3a\u4e86\u8282\u70b9\u533a\u5206\u5ea6\u548c\u6f5c\u5728\u7a7a\u95f4\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.09074", "pdf": "https://arxiv.org/pdf/2509.09074", "abs": "https://arxiv.org/abs/2509.09074", "authors": ["Alice Kate Li", "Thales C Silva", "Victoria Edwards", "Vijay Kumar", "M. Ani Hsieh"], "title": "KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Accepted to CoRL 2025 (Conference on Robot Learning). 15 pages 11\n  figures", "summary": "In this work, we propose a novel flow field-based motion planning method that\ndrives a robot from any initial state to a desired reference trajectory such\nthat it converges to the trajectory's end point. Despite demonstrated efficacy\nin using Koopman operator theory for modeling dynamical systems, Koopman does\nnot inherently enforce convergence to desired trajectories nor to specified\ngoals -- a requirement when learning from demonstrations (LfD). We present\nKoopMotion which represents motion flow fields as dynamical systems,\nparameterized by Koopman Operators to mimic desired trajectories, and leverages\nthe divergence properties of the learnt flow fields to obtain smooth motion\nfields that converge to a desired reference trajectory when a robot is placed\naway from the desired trajectory, and tracks the trajectory until the end\npoint. To demonstrate the effectiveness of our approach, we show evaluations of\nKoopMotion on the LASA human handwriting dataset and a 3D manipulator\nend-effector trajectory dataset, including spectral analysis. We also perform\nexperiments on a physical robot, verifying KoopMotion on a miniature autonomous\nsurface vehicle operating in a non-static fluid flow environment. Our approach\nis highly sample efficient in both space and time, requiring only 3\\% of the\nLASA dataset to generate dense motion plans. Additionally, KoopMotion provides\na significant improvement over baselines when comparing metrics that measure\nspatial and temporal dynamics modeling efficacy.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6d41\u573a\u7684\u8fd0\u52a8\u89c4\u5212\u65b9\u6cd5KoopMotion\uff0c\u80fd\u4f7f\u673a\u5668\u4eba\u4ece\u521d\u59cb\u72b6\u6001\u5230\u671f\u671b\u8f68\u8ff9\u7ec8\u70b9\uff0c\u5728\u6570\u636e\u96c6\u548c\u7269\u7406\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u6837\u672c\u6548\u7387\u9ad8\u4e14\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "Koopman\u7b97\u5b50\u7406\u8bba\u867d\u53ef\u5efa\u6a21\u52a8\u529b\u7cfb\u7edf\uff0c\u4f46\u4e0d\u80fd\u4fdd\u8bc1\u6536\u655b\u5230\u671f\u671b\u8f68\u8ff9\u548c\u76ee\u6807\uff0c\u800c\u5b66\u4e60\u793a\u8303\u65f6\u9700\u8981\u6b64\u7279\u6027\u3002", "method": "\u63d0\u51faKoopMotion\uff0c\u5c06\u8fd0\u52a8\u6d41\u573a\u8868\u793a\u4e3a\u52a8\u529b\u7cfb\u7edf\uff0c\u7528Koopman\u7b97\u5b50\u53c2\u6570\u5316\u4ee5\u6a21\u4eff\u671f\u671b\u8f68\u8ff9\uff0c\u5229\u7528\u5b66\u4e60\u6d41\u573a\u7684\u6563\u5ea6\u7279\u6027\u83b7\u5f97\u5e73\u6ed1\u8fd0\u52a8\u573a\u3002", "result": "\u5728\u624b\u5199\u6570\u636e\u96c6\u30013D\u673a\u68b0\u81c2\u672b\u7aef\u8f68\u8ff9\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5728\u7269\u7406\u673a\u5668\u4eba\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u6837\u672c\u6548\u7387\u9ad8\uff0c\u4ec5\u97003%\u7684LASA\u6570\u636e\u96c6\uff0c\u4e14\u5728\u65f6\u7a7a\u52a8\u529b\u5b66\u5efa\u6a21\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "\u6240\u63d0KoopMotion\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5b9e\u73b0\u673a\u5668\u4eba\u8fd0\u52a8\u89c4\u5212\uff0c\u6837\u672c\u6548\u7387\u9ad8\u4e14\u6027\u80fd\u4f18\u3002"}}
{"id": "2509.09599", "pdf": "https://arxiv.org/pdf/2509.09599", "abs": "https://arxiv.org/abs/2509.09599", "authors": ["Ira J. S. Shokar", "Rich R. Kerswell", "Peter H. Haynes"], "title": "Conditioning on PDE Parameters to Generalise Deep Learning Emulation of Stochastic and Chaotic Dynamics", "categories": ["cs.LG", "math.DS", "nlin.CD", "physics.ao-ph"], "comment": null, "summary": "We present a deep learning emulator for stochastic and chaotic\nspatio-temporal systems, explicitly conditioned on the parameter values of the\nunderlying partial differential equations (PDEs). Our approach involves\npre-training the model on a single parameter domain, followed by fine-tuning on\na smaller, yet diverse dataset, enabling generalisation across a broad range of\nparameter values. By incorporating local attention mechanisms, the network is\ncapable of handling varying domain sizes and resolutions. This enables\ncomputationally efficient pre-training on smaller domains while requiring only\na small additional dataset to learn how to generalise to larger domain sizes.\nWe demonstrate the model's capabilities on the chaotic Kuramoto-Sivashinsky\nequation and stochastically-forced beta-plane turbulence, showcasing its\nability to capture phenomena at interpolated parameter values. The emulator\nprovides significant computational speed-ups over conventional numerical\nintegration, facilitating efficient exploration of parameter space, while a\nprobabilistic variant of the emulator provides uncertainty quantification,\nallowing for the statistical study of rare events.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8ePDE\u53c2\u6570\u503c\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u62df\u5668\uff0c\u7ecf\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u5b9e\u73b0\u8de8\u53c2\u6570\u6cdb\u5316\uff0c\u5728\u4e24\u4e2a\u65b9\u7a0b\u4e0a\u9a8c\u8bc1\u5176\u80fd\u529b\uff0c\u6709\u8ba1\u7b97\u52a0\u901f\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4f18\u52bf\u3002", "motivation": "\u4e3a\u968f\u673a\u548c\u6df7\u6c8c\u65f6\u7a7a\u7cfb\u7edf\u5f00\u53d1\u4e00\u79cd\u80fd\u57fa\u4e8ePDE\u53c2\u6570\u503c\u8fdb\u884c\u6cdb\u5316\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u62df\u5668\u3002", "method": "\u5148\u5728\u5355\u4e00\u53c2\u6570\u57df\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u518d\u5728\u5c0f\u800c\u591a\u6837\u7684\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\uff1b\u5f15\u5165\u5c40\u90e8\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728Kuramoto - Sivashinsky\u65b9\u7a0b\u548c\u968f\u673a\u5f3a\u8febbeta\u5e73\u9762\u6e4d\u6d41\u4e0a\u5c55\u793a\u4e86\u6a21\u578b\u5728\u63d2\u503c\u53c2\u6570\u503c\u4e0a\u6355\u6349\u73b0\u8c61\u7684\u80fd\u529b\uff1b\u6a21\u62df\u5668\u6bd4\u4f20\u7edf\u6570\u503c\u79ef\u5206\u6709\u663e\u8457\u8ba1\u7b97\u52a0\u901f\u3002", "conclusion": "\u8be5\u6a21\u62df\u5668\u80fd\u6709\u6548\u63a2\u7d22\u53c2\u6570\u7a7a\u95f4\uff0c\u5176\u6982\u7387\u53d8\u4f53\u53ef\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u7f55\u89c1\u4e8b\u4ef6\u7edf\u8ba1\u7814\u7a76\u3002"}}
{"id": "2509.09090", "pdf": "https://arxiv.org/pdf/2509.09090", "abs": "https://arxiv.org/abs/2509.09090", "authors": ["Hengyu Fang", "Yijiang Liu", "Yuan Du", "Li Du", "Huanrui Yang"], "title": "SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 9 figures", "summary": "Vision-Language-Action (VLA) models exhibit unprecedented capabilities for\nembodied intelligence. However, their extensive computational and memory costs\nhinder their practical deployment. Existing VLA compression and acceleration\napproaches conduct quantization or token pruning in an ad-hoc manner but fail\nto enable both for a holistic efficiency improvement due to an observed\nincompatibility. This work introduces SQAP-VLA, the first structured,\ntraining-free VLA inference acceleration framework that simultaneously enables\nstate-of-the-art quantization and token pruning. We overcome the\nincompatibility by co-designing the quantization and token pruning pipeline,\nwhere we propose new quantization-aware token pruning criteria that work on an\naggressively quantized model while improving the quantizer design to enhance\npruning effectiveness. When applied to standard VLA models, SQAP-VLA yields\nsignificant gains in computational efficiency and inference speed while\nsuccessfully preserving core model performance, achieving a $\\times$1.93\nspeedup and up to a 4.5\\% average success rate enhancement compared to the\noriginal model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSQAP - VLA\u6846\u67b6\u89e3\u51b3VLA\u6a21\u578b\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u91cf\u5316\u548c\u526a\u679d\uff0c\u63d0\u5347\u6548\u7387\u4e0e\u6027\u80fd\u3002", "motivation": "VLA\u6a21\u578b\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\u963b\u788d\u5b9e\u9645\u90e8\u7f72\uff0c\u73b0\u6709\u538b\u7f29\u548c\u52a0\u901f\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u91cf\u5316\u548c\u526a\u679d\u4ee5\u6574\u4f53\u63d0\u5347\u6548\u7387\u3002", "method": "\u63d0\u51faSQAP - VLA\u6846\u67b6\uff0c\u5171\u540c\u8bbe\u8ba1\u91cf\u5316\u548c\u4ee4\u724c\u526a\u679d\u6d41\u7a0b\uff0c\u63d0\u51fa\u65b0\u7684\u91cf\u5316\u611f\u77e5\u4ee4\u724c\u526a\u679d\u6807\u51c6\uff0c\u6539\u8fdb\u91cf\u5316\u5668\u8bbe\u8ba1\u3002", "result": "\u5e94\u7528\u4e8e\u6807\u51c6VLA\u6a21\u578b\u65f6\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u63a8\u7406\u901f\u5ea6\uff0c\u4e0e\u539f\u6a21\u578b\u76f8\u6bd4\u5b9e\u73b01.93\u500d\u52a0\u901f\uff0c\u5e73\u5747\u6210\u529f\u7387\u6700\u591a\u63d0\u53474.5%\u3002", "conclusion": "SQAP - VLA\u6846\u67b6\u80fd\u5728\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u63a8\u7406\u901f\u5ea6\u7684\u540c\u65f6\uff0c\u6210\u529f\u4fdd\u7559\u6838\u5fc3\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2509.09611", "pdf": "https://arxiv.org/pdf/2509.09611", "abs": "https://arxiv.org/abs/2509.09611", "authors": ["Haolan Zheng", "Yanlai Chen", "Jiequn Han", "Yue Yu"], "title": "ReBaNO: Reduced Basis Neural Operator Mitigating Generalization Gaps and Achieving Discretization Invariance", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We propose a novel data-lean operator learning algorithm, the Reduced Basis\nNeural Operator (ReBaNO), to solve a group of PDEs with multiple distinct\ninputs. Inspired by the Reduced Basis Method and the recently introduced\nGenerative Pre-Trained Physics-Informed Neural Networks, ReBaNO relies on a\nmathematically rigorous greedy algorithm to build its network structure offline\nadaptively from the ground up. Knowledge distillation via task-specific\nactivation function allows ReBaNO to have a compact architecture requiring\nminimal computational cost online while embedding physics. In comparison to\nstate-of-the-art operator learning algorithms such as PCA-Net, DeepONet, FNO,\nand CNO, numerical results demonstrate that ReBaNO significantly outperforms\nthem in terms of eliminating/shrinking the generalization gap for both in- and\nout-of-distribution tests and being the only operator learning algorithm\nachieving strict discretization invariance.", "AI": {"tldr": "\u63d0\u51faReduced Basis Neural Operator (ReBaNO)\u7b97\u6cd5\u89e3\u51b3\u542b\u591a\u4e0d\u540c\u8f93\u5165\u7684PDEs\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4e00\u7ec4\u542b\u591a\u4e2a\u4e0d\u540c\u8f93\u5165\u7684\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDEs\uff09\uff0c\u5e76\u6539\u5584\u73b0\u6709\u7b97\u5b50\u5b66\u4e60\u7b97\u6cd5\u7684\u6cdb\u5316\u5dee\u8ddd\u548c\u79bb\u6563\u5316\u4e0d\u53d8\u6027\u95ee\u9898\u3002", "method": "\u53d7\u7b80\u5316\u57fa\u65b9\u6cd5\u548c\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u542f\u53d1\uff0c\u7528\u4e25\u683c\u8d2a\u5a6a\u7b97\u6cd5\u79bb\u7ebf\u81ea\u9002\u5e94\u6784\u5efa\u7f51\u7edc\u7ed3\u6784\uff0c\u901a\u8fc7\u7279\u5b9a\u4efb\u52a1\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u4e0ePCA - Net\u3001DeepONet\u3001FNO\u548cCNO\u7b49\u5148\u8fdb\u7b97\u5b50\u5b66\u4e60\u7b97\u6cd5\u76f8\u6bd4\uff0cReBaNO\u5728\u6d88\u9664/\u7f29\u5c0f\u6cdb\u5316\u5dee\u8ddd\u548c\u5b9e\u73b0\u4e25\u683c\u79bb\u6563\u5316\u4e0d\u53d8\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "ReBaNO\u662f\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u7cbe\u7b80\u7b97\u5b50\u5b66\u4e60\u7b97\u6cd5\uff0c\u5728\u89e3\u51b3\u542b\u591a\u4e2a\u4e0d\u540c\u8f93\u5165\u7684PDEs\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2509.09091", "pdf": "https://arxiv.org/pdf/2509.09091", "abs": "https://arxiv.org/abs/2509.09091", "authors": ["Honglan Yu", "Yibin Wang", "Feifei Dai", "Dong Liu", "Haihui Fan", "Xiaoyan Gu"], "title": "Towards Confidential and Efficient LLM Inference with Dual Privacy Protection", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted by DASFAA2025", "summary": "CPU-based trusted execution environments (TEEs) and differential privacy (DP)\nhave gained wide applications for private inference. Due to high inference\nlatency in TEEs, researchers use partition-based approaches that offload linear\nmodel components to GPUs. However, dense nonlinear layers of large language\nmodels (LLMs) result in significant communication overhead between TEEs and\nGPUs. DP-based approaches apply random noise to protect data privacy, but this\ncompromises LLM performance and semantic understanding. To overcome the above\ndrawbacks, this paper proposes CMIF, a Confidential and efficient Model\nInference Framework. CMIF confidentially deploys the embedding layer in the\nclient-side TEE and subsequent layers on GPU servers. Meanwhile, it optimizes\nthe Report-Noisy-Max mechanism to protect sensitive inputs with a slight\ndecrease in model performance. Extensive experiments on Llama-series models\ndemonstrate that CMIF reduces additional inference overhead in TEEs while\npreserving user data privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCMIF\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5d4c\u5165\u5c42\u90e8\u7f72\u5728\u5ba2\u6237\u7aefTEE\uff0c\u540e\u7eed\u5c42\u90e8\u7f72\u5728GPU\u670d\u52a1\u5668\uff0c\u5e76\u4f18\u5316\u673a\u5236\uff0c\u51cf\u5c11TEE\u63a8\u7406\u5f00\u9500\u5e76\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eCPU\u7684TEE\u548cDP\u65b9\u6cd5\u5728\u9690\u79c1\u63a8\u7406\u4e2d\u5b58\u5728\u9ad8\u63a8\u7406\u5ef6\u8fdf\u3001\u901a\u4fe1\u5f00\u9500\u5927\u3001\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faCMIF\u6846\u67b6\uff0c\u5c06\u5d4c\u5165\u5c42\u90e8\u7f72\u5728\u5ba2\u6237\u7aefTEE\uff0c\u540e\u7eed\u5c42\u90e8\u7f72\u5728GPU\u670d\u52a1\u5668\uff0c\u4f18\u5316Report - Noisy - Max\u673a\u5236\u3002", "result": "\u5728Llama\u7cfb\u5217\u6a21\u578b\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCMIF\u51cf\u5c11\u4e86TEE\u4e2d\u7684\u989d\u5916\u63a8\u7406\u5f00\u9500\u3002", "conclusion": "CMIF\u80fd\u5728\u51cf\u5c11TEE\u63a8\u7406\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u6570\u636e\u9690\u79c1\u3002"}}
{"id": "2509.09616", "pdf": "https://arxiv.org/pdf/2509.09616", "abs": "https://arxiv.org/abs/2509.09616", "authors": ["Ignacy St\u0119pka", "Jerzy Stefanowski"], "title": "Explaining Concept Drift through the Evolution of Group Counterfactuals", "categories": ["cs.LG", "cs.AI"], "comment": "TempXAI Workshop @ ECML PKDD 2025", "summary": "Machine learning models in dynamic environments often suffer from concept\ndrift, where changes in the data distribution degrade performance. While\ndetecting this drift is a well-studied topic, explaining how and why the\nmodel's decision-making logic changes still remains a significant challenge. In\nthis paper, we introduce a novel methodology to explain concept drift by\nanalyzing the temporal evolution of group-based counterfactual explanations\n(GCEs). Our approach tracks shifts in the GCEs' cluster centroids and their\nassociated counterfactual action vectors before and after a drift. These\nevolving GCEs act as an interpretable proxy, revealing structural changes in\nthe model's decision boundary and its underlying rationale. We operationalize\nthis analysis within a three-layer framework that synergistically combines\ninsights from the data layer (distributional shifts), the model layer\n(prediction disagreement), and our proposed explanation layer. We show that\nsuch holistic view allows for a more comprehensive diagnosis of drift, making\nit possible to distinguish between different root causes, such as a spatial\ndata shift versus a re-labeling of concepts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5206\u6790\u57fa\u4e8e\u7ec4\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08GCEs\uff09\u7684\u65f6\u95f4\u6f14\u53d8\u6765\u89e3\u91ca\u6982\u5ff5\u6f02\u79fb\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u4e09\u5c42\u6846\u67b6\u4e2d\u64cd\u4f5c\u5206\u6790\uff0c\u80fd\u66f4\u5168\u9762\u8bca\u65ad\u6f02\u79fb\u5e76\u533a\u5206\u4e0d\u540c\u6839\u6e90\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u53d7\u6982\u5ff5\u6f02\u79fb\u5f71\u54cd\uff0c\u68c0\u6d4b\u6f02\u79fb\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u89e3\u91ca\u6a21\u578b\u51b3\u7b56\u903b\u8f91\u53d8\u5316\u7684\u65b9\u5f0f\u548c\u539f\u56e0\u4ecd\u662f\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f15\u5165\u5206\u6790GCEs\u65f6\u95f4\u6f14\u53d8\u7684\u65b9\u6cd5\uff0c\u8ddf\u8e2a\u6f02\u79fb\u524d\u540eGCEs\u7684\u805a\u7c7b\u8d28\u5fc3\u53ca\u5176\u76f8\u5173\u53cd\u4e8b\u5b9e\u884c\u52a8\u5411\u91cf\u7684\u53d8\u5316\uff0c\u5728\u4e09\u5c42\u6846\u67b6\u4e2d\u7ed3\u5408\u6570\u636e\u5c42\u3001\u6a21\u578b\u5c42\u548c\u89e3\u91ca\u5c42\u7684\u89c1\u89e3\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u6982\u5ff5\u6f02\u79fb\u66f4\u5168\u9762\u7684\u8bca\u65ad\uff0c\u80fd\u591f\u533a\u5206\u4e0d\u540c\u7684\u6839\u6e90\uff0c\u5982\u7a7a\u95f4\u6570\u636e\u8f6c\u79fb\u4e0e\u6982\u5ff5\u91cd\u65b0\u6807\u8bb0\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u5206\u6790GCEs\u548c\u4e09\u5c42\u6846\u67b6\uff0c\u4e3a\u89e3\u91ca\u6982\u5ff5\u6f02\u79fb\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u903b\u8f91\u7684\u53d8\u5316\u3002"}}
{"id": "2509.09097", "pdf": "https://arxiv.org/pdf/2509.09097", "abs": "https://arxiv.org/abs/2509.09097", "authors": ["Honghui Xu", "Shiva Shrestha", "Wei Chen", "Zhiyuan Li", "Zhipeng Cai"], "title": "DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "As on-device large language model (LLM) systems become increasingly\nprevalent, federated fine-tuning enables advanced language understanding and\ngeneration directly on edge devices; however, it also involves processing\nsensitive, user-specific data, raising significant privacy concerns within the\nfederated learning framework. To address these challenges, we propose\nDP-FedLoRA, a privacy-enhanced federated fine-tuning framework that integrates\nLoRA-based adaptation with differential privacy in a communication-efficient\nsetting. Each client locally clips and perturbs its LoRA matrices using\nGaussian noise to satisfy ($\\epsilon$, $\\delta$)-differential privacy. We\nfurther provide a theoretical analysis demonstrating the unbiased nature of the\nupdates and deriving bounds on the variance introduced by noise, offering\npractical guidance for privacy-budget calibration. Experimental results across\nmainstream benchmarks show that DP-FedLoRA delivers competitive performance\nwhile offering strong privacy guarantees, paving the way for scalable and\nprivacy-preserving LLM deployment in on-device environments.", "AI": {"tldr": "\u63d0\u51fa\u9690\u79c1\u589e\u5f3a\u7684\u8054\u90a6\u5fae\u8c03\u6846\u67b6DP - FedLoRA\uff0c\u7ed3\u5408LoRA\u548c\u5dee\u5206\u9690\u79c1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u6709\u7ade\u4e89\u529b\u4e14\u6709\u5f3a\u9690\u79c1\u4fdd\u8bc1\u3002", "motivation": "\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u4e2d\uff0c\u8054\u90a6\u5fae\u8c03\u5904\u7406\u654f\u611f\u7528\u6237\u6570\u636e\u5f15\u53d1\u9690\u79c1\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u3002", "method": "\u63d0\u51faDP - FedLoRA\u6846\u67b6\uff0c\u5ba2\u6237\u7aef\u7528\u9ad8\u65af\u566a\u58f0\u5bf9LoRA\u77e9\u9635\u88c1\u526a\u548c\u6270\u52a8\u4ee5\u6ee1\u8db3\u5dee\u5206\u9690\u79c1\uff0c\u8fd8\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u5728\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDP - FedLoRA\u6027\u80fd\u6709\u7ade\u4e89\u529b\u4e14\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u8bc1\u3002", "conclusion": "DP - FedLoRA\u4e3a\u8bbe\u5907\u7aef\u73af\u5883\u4e2d\u53ef\u6269\u5c55\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2509.09619", "pdf": "https://arxiv.org/pdf/2509.09619", "abs": "https://arxiv.org/abs/2509.09619", "authors": ["Roshan Balaji", "Joe Bobby", "Nirav Pravinbhai Bhatt"], "title": "Functional Groups are All you Need for Chemically Interpretable Molecular Property Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Molecular property prediction using deep learning (DL) models has accelerated\ndrug and materials discovery, but the resulting DL models often lack\ninterpretability, hindering their adoption by chemists. This work proposes\ndeveloping molecule representations using the concept of Functional Groups (FG)\nin chemistry. We introduce the Functional Group Representation (FGR) framework,\na novel approach to encoding molecules based on their fundamental chemical\nsubstructures. Our method integrates two types of functional groups: those\ncurated from established chemical knowledge (FG), and those mined from a large\nmolecular corpus using sequential pattern mining (MFG). The resulting FGR\nframework encodes molecules into a lower-dimensional latent space by leveraging\npre-training on a large dataset of unlabeled molecules. Furthermore, the\nproposed framework allows the inclusion of 2D structure-based descriptors of\nmolecules. We demonstrate that the FGR framework achieves state-of-the-art\nperformance on a diverse range of 33 benchmark datasets spanning physical\nchemistry, biophysics, quantum mechanics, biological activity, and\npharmacokinetics while enabling chemical interpretability. Crucially, the\nmodel's representations are intrinsically aligned with established chemical\nprinciples, allowing chemists to directly link predicted properties to specific\nfunctional groups and facilitating novel insights into structure-property\nrelationships. Our work presents a significant step toward developing\nhigh-performing, chemically interpretable DL models for molecular discovery.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5b98\u80fd\u56e2\u6982\u5ff5\u7684FGR\u6846\u67b6\u8fdb\u884c\u5206\u5b50\u8868\u793a\uff0c\u572833\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u4e14\u5177\u5316\u5b66\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7528\u4e8e\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u65f6\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u963b\u788d\u5316\u5b66\u5bb6\u91c7\u7528\u3002", "method": "\u5f15\u5165FGR\u6846\u67b6\uff0c\u6574\u5408\u65e2\u5b9a\u5316\u5b66\u77e5\u8bc6\u7684\u5b98\u80fd\u56e2\u548c\u4ece\u5927\u578b\u5206\u5b50\u8bed\u6599\u5e93\u6316\u6398\u7684\u5b98\u80fd\u56e2\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u5c06\u5206\u5b50\u7f16\u7801\u5230\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u53ef\u7eb3\u5165\u57fa\u4e8e2D\u7ed3\u6784\u7684\u63cf\u8ff0\u7b26\u3002", "result": "FGR\u6846\u67b6\u572833\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5206\u5b50\u53d1\u73b0\u5f00\u53d1\u9ad8\u6027\u80fd\u3001\u5316\u5b66\u53ef\u89e3\u91ca\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2509.09112", "pdf": "https://arxiv.org/pdf/2509.09112", "abs": "https://arxiv.org/abs/2509.09112", "authors": ["Zhaoxi Zhang", "Xiaomei Zhang", "Yanjun Zhang", "He Zhang", "Shirui Pan", "Bo Liu", "Asif Qumer Gill", "Leo Yu Zhang"], "title": "Character-Level Perturbations Disrupt LLM Watermarks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) watermarking embeds detectable signals into\ngenerated text for copyright protection, misuse prevention, and content\ndetection. While prior studies evaluate robustness using watermark removal\nattacks, these methods are often suboptimal, creating the misconception that\neffective removal requires large perturbations or powerful adversaries.\n  To bridge the gap, we first formalize the system model for LLM watermark, and\ncharacterize two realistic threat models constrained on limited access to the\nwatermark detector. We then analyze how different types of perturbation vary in\ntheir attack range, i.e., the number of tokens they can affect with a single\nedit. We observe that character-level perturbations (e.g., typos, swaps,\ndeletions, homoglyphs) can influence multiple tokens simultaneously by\ndisrupting the tokenization process. We demonstrate that character-level\nperturbations are significantly more effective for watermark removal under the\nmost restrictive threat model. We further propose guided removal attacks based\non the Genetic Algorithm (GA) that uses a reference detector for optimization.\nUnder a practical threat model with limited black-box queries to the watermark\ndetector, our method demonstrates strong removal performance. Experiments\nconfirm the superiority of character-level perturbations and the effectiveness\nof the GA in removing watermarks under realistic constraints. Additionally, we\nargue there is an adversarial dilemma when considering potential defenses: any\nfixed defense can be bypassed by a suitable perturbation strategy. Motivated by\nthis principle, we propose an adaptive compound character-level attack.\nExperimental results show that this approach can effectively defeat the\ndefenses. Our findings highlight significant vulnerabilities in existing LLM\nwatermark schemes and underline the urgency for the development of new robust\nmechanisms.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u53bb\u9664\u653b\u51fb\uff0c\u53d1\u73b0\u5b57\u7b26\u7ea7\u6270\u52a8\u5728\u6c34\u5370\u53bb\u9664\u4e0a\u66f4\u6709\u6548\uff0c\u63d0\u51fa\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u5f15\u5bfc\u53bb\u9664\u653b\u51fb\u548c\u81ea\u9002\u5e94\u590d\u5408\u5b57\u7b26\u7ea7\u653b\u51fb\uff0c\u6307\u51fa\u73b0\u6709\u6c34\u5370\u65b9\u6848\u5b58\u5728\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u53bb\u9664\u653b\u51fb\u65b9\u6cd5\u6b20\u4f73\uff0c\u5b58\u5728\u6709\u6548\u53bb\u9664\u9700\u5927\u6270\u52a8\u6216\u5f3a\u5927\u5bf9\u624b\u7684\u8bef\u89e3\uff0c\u9700\u7814\u7a76\u66f4\u6709\u6548\u7684\u53bb\u9664\u65b9\u6cd5\u3002", "method": "\u5f62\u5f0f\u5316LLM\u6c34\u5370\u7cfb\u7edf\u6a21\u578b\uff0c\u523b\u753b\u4e24\u79cd\u53d7\u9650\u5a01\u80c1\u6a21\u578b\uff0c\u5206\u6790\u4e0d\u540c\u6270\u52a8\u7c7b\u578b\u7684\u653b\u51fb\u8303\u56f4\uff0c\u63d0\u51fa\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u5f15\u5bfc\u53bb\u9664\u653b\u51fb\u548c\u81ea\u9002\u5e94\u590d\u5408\u5b57\u7b26\u7ea7\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u5b57\u7b26\u7ea7\u6270\u52a8\u5728\u6c34\u5370\u53bb\u9664\u4e0a\u66f4\u4f18\uff0cGA\u65b9\u6cd5\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u6709\u6548\uff0c\u81ea\u9002\u5e94\u590d\u5408\u5b57\u7b26\u7ea7\u653b\u51fb\u80fd\u51fb\u8d25\u9632\u5fa1\u3002", "conclusion": "\u73b0\u6709LLM\u6c34\u5370\u65b9\u6848\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff0c\u6025\u9700\u5f00\u53d1\u65b0\u7684\u9c81\u68d2\u673a\u5236\u3002"}}
{"id": "2509.09655", "pdf": "https://arxiv.org/pdf/2509.09655", "abs": "https://arxiv.org/abs/2509.09655", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Feasibility-Guided Fair Adaptive Offline Reinforcement Learning for Medicaid Care Management", "categories": ["cs.LG", "cs.AI", "cs.LO", "stat.AP"], "comment": "12 pages, 5 figures, 3 tables", "summary": "We introduce Feasibility-Guided Fair Adaptive Reinforcement Learning\n(FG-FARL), an offline RL procedure that calibrates per-group safety thresholds\nto reduce harm while equalizing a chosen fairness target (coverage or harm)\nacross protected subgroups. Using de-identified longitudinal trajectories from\na Medicaid population health management program, we evaluate FG-FARL against\nbehavior cloning (BC) and HACO (Hybrid Adaptive Conformal Offline RL; a global\nconformal safety baseline). We report off-policy value estimates with bootstrap\n95% confidence intervals and subgroup disparity analyses with p-values. FG-FARL\nachieves comparable value to baselines while improving fairness metrics,\ndemonstrating a practical path to safer and more equitable decision support.", "AI": {"tldr": "\u4ecb\u7ecdFG - FARL\u79bb\u7ebfRL\u7a0b\u5e8f\uff0c\u901a\u8fc7 Medicaid \u9879\u76ee\u6570\u636e\u8bc4\u4f30\uff0c\u5176\u5728\u5b9e\u73b0\u76f8\u8fd1\u4ef7\u503c\u65f6\u63d0\u5347\u516c\u5e73\u6027\u6307\u6807\u3002", "motivation": "\u5728\u5e73\u8861\u4e0d\u540c\u53d7\u4fdd\u62a4\u5b50\u7ec4\u516c\u5e73\u76ee\u6807\uff08\u8986\u76d6\u6216\u4f24\u5bb3\uff09\u7684\u540c\u65f6\u51cf\u5c11\u4f24\u5bb3\u3002", "method": "\u5f15\u5165FG - FARL\u79bb\u7ebfRL\u7a0b\u5e8f\uff0c\u7528 Medicaid \u9879\u76ee\u53bb\u8bc6\u522b\u5316\u7684\u7eb5\u5411\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u62a5\u544a\u5e26\u7f6e\u4fe1\u533a\u95f4\u7684\u79bb\u7b56\u7565\u4ef7\u503c\u4f30\u8ba1\u548c\u5e26p\u503c\u7684\u5b50\u7ec4\u5dee\u5f02\u5206\u6790\u3002", "result": "FG - FARL\u4e0e\u57fa\u7ebf\u5b9e\u73b0\u76f8\u8fd1\u4ef7\u503c\uff0c\u540c\u65f6\u6539\u5584\u4e86\u516c\u5e73\u6027\u6307\u6807\u3002", "conclusion": "FG - FARL\u4e3a\u66f4\u5b89\u5168\u548c\u66f4\u516c\u5e73\u7684\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2509.09125", "pdf": "https://arxiv.org/pdf/2509.09125", "abs": "https://arxiv.org/abs/2509.09125", "authors": ["Liqun He", "Jiaqi Xu"], "title": "Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for publication in the journal Reflecting Digital Learning.\n  First submitted: 30 Oct 2023. The final version will be available open access\n  via the journal", "summary": "This study explores the use of generative AI for automating the\nclassification of tutors' Dialogue Acts (DAs), aiming to reduce the time and\neffort required by traditional manual coding. This case study uses the\nopen-source CIMA corpus, in which tutors' responses are pre-annotated into four\nDA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored\nprompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of\n0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and\nindicating substantial agreement with human annotations. These findings suggest\nthat generative AI has strong potential to provide an efficient and accessible\napproach to DA classification, with meaningful implications for educational\ndialogue analysis. The study also highlights the importance of task-specific\nlabel definitions and contextual information in enhancing the quality of\nautomated annotation. Finally, it underscores the ethical considerations\nassociated with the use of generative AI and the need for responsible and\ntransparent research practices. The script of this research is publicly\navailable at\nhttps://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.", "AI": {"tldr": "\u7814\u7a76\u7528\u751f\u6210\u5f0fAI\u81ea\u52a8\u5206\u7c7b\u5bfc\u5e08\u5bf9\u8bdd\u884c\u4e3a\uff0c\u7528CIMA\u8bed\u6599\u6d4b\u8bd5GPT-3.5-turbo\u548cGPT-4\uff0cGPT-4\u8868\u73b0\u597d\uff0c\u663e\u793a\u751f\u6210\u5f0fAI\u6f5c\u529b\u5927\uff0c\u4e5f\u63d0\u53ca\u76f8\u5173\u8981\u70b9\u548c\u4f26\u7406\u8003\u91cf\u3002", "motivation": "\u51cf\u5c11\u4f20\u7edf\u624b\u52a8\u7f16\u7801\u5bf9\u5bfc\u5e08\u5bf9\u8bdd\u884c\u4e3a\u5206\u7c7b\u6240\u9700\u7684\u65f6\u95f4\u548c\u7cbe\u529b\u3002", "method": "\u4f7f\u7528\u5f00\u6e90CIMA\u8bed\u6599\uff0c\u5bf9\u5bfc\u5e08\u56de\u590d\u9884\u6807\u6ce8\u4e3a\u56db\u7c7b\uff0c\u7528\u5b9a\u5236\u63d0\u793a\u6d4b\u8bd5GPT-3.5-turbo\u548cGPT-4\u6a21\u578b\u3002", "result": "GPT-4\u51c6\u786e\u7387\u8fbe80%\uff0c\u52a0\u6743F1\u5206\u65700.81\uff0cCohen's Kappa\u4e3a0.74\uff0c\u8d85\u57fa\u7ebf\u8868\u73b0\uff0c\u4e0e\u4eba\u5de5\u6807\u6ce8\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u6709\u6f5c\u529b\u4e3a\u5bf9\u8bdd\u884c\u4e3a\u5206\u7c7b\u63d0\u4f9b\u9ad8\u6548\u53ef\u53ca\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4efb\u52a1\u7279\u5b9a\u6807\u7b7e\u5b9a\u4e49\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u91cd\u8981\u6027\uff0c\u6307\u51fa\u4f7f\u7528\u7684\u4f26\u7406\u8003\u91cf\u548c\u8d1f\u8d23\u900f\u660e\u7814\u7a76\u5b9e\u8df5\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2509.09679", "pdf": "https://arxiv.org/pdf/2509.09679", "abs": "https://arxiv.org/abs/2509.09679", "authors": ["Bingxin Xu", "Zhen Dong", "Oussama Elachqar", "Yuzhang Shang"], "title": "ButterflyQuant: Ultra-low-bit LLM Quantization through Learnable Orthogonal Butterfly Transforms", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Replace discrete Hadamard transforms with continuous Butterfly\n  transforms to facilitate the learning of rotation matrices in LLM\n  quantization", "summary": "Large language models require massive memory footprints, severely limiting\ndeployment on consumer hardware. Quantization reduces memory through lower\nnumerical precision, but extreme 2-bit quantization suffers from catastrophic\nperformance loss due to outliers in activations. Rotation-based methods such as\nQuIP and QuaRot apply orthogonal transforms to eliminate outliers before\nquantization, using computational invariance: $\\mathbf{y} = \\mathbf{Wx} =\n(\\mathbf{WQ}^T)(\\mathbf{Qx})$ for orthogonal $\\mathbf{Q}$. However, these\nmethods use fixed transforms--Hadamard matrices achieving optimal worst-case\ncoherence $\\mu = 1/\\sqrt{n}$--that cannot adapt to specific weight\ndistributions. We identify that different transformer layers exhibit distinct\noutlier patterns, motivating layer-adaptive rotations rather than\none-size-fits-all approaches. We propose ButterflyQuant, which replaces\nHadamard rotations with learnable butterfly transforms parameterized by\ncontinuous Givens rotation angles. Unlike Hadamard's discrete $\\{+1, -1\\}$\nentries that are non-differentiable and prohibit gradient-based learning,\nbutterfly transforms' continuous parameterization enables smooth optimization\nwhile guaranteeing orthogonality by construction. This orthogonal constraint\nensures theoretical guarantees in outlier suppression while achieving $O(n \\log\nn)$ computational complexity with only $\\frac{n \\log n}{2}$ learnable\nparameters. We further introduce a uniformity regularization on\npost-transformation activations to promote smoother distributions amenable to\nquantization. Learning requires only 128 calibration samples and converges in\nminutes on a single GPU--a negligible one-time cost. On LLaMA-2-7B with 2-bit\nquantization, ButterflyQuant achieves 15.4 perplexity versus 22.1 for QuaRot.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5b58\u5360\u7528\u5927\uff0c\u6781\u7aef2\u4f4d\u91cf\u5316\u56e0\u6fc0\u6d3b\u503c\u79bb\u7fa4\u70b9\u6709\u6027\u80fd\u635f\u5931\uff0c\u73b0\u6709\u65cb\u8f6c\u65b9\u6cd5\u56fa\u5b9a\uff0c\u672c\u6587\u63d0\u51faButterflyQuant\uff0c\u7528\u53ef\u5b66\u4e60\u8776\u5f62\u53d8\u6362\uff0c\u5728LLaMA - 2 - 7B\u4e0a2\u4f4d\u91cf\u5316\u8868\u73b0\u4f18\u4e8eQuaRot\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u65cb\u8f6c\u7684\u91cf\u5316\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u53d8\u6362\uff0c\u4e0d\u80fd\u9002\u5e94\u7279\u5b9a\u6743\u91cd\u5206\u5e03\uff0c\u4e0d\u540cTransformer\u5c42\u6709\u4e0d\u540c\u79bb\u7fa4\u70b9\u6a21\u5f0f\uff0c\u9700\u5c42\u81ea\u9002\u5e94\u65cb\u8f6c\u3002", "method": "\u63d0\u51faButterflyQuant\uff0c\u7528\u53ef\u5b66\u4e60\u8776\u5f62\u53d8\u6362\u66ff\u4ee3Hadamard\u65cb\u8f6c\uff0c\u5f15\u5165\u540e\u53d8\u6362\u6fc0\u6d3b\u503c\u7684\u5747\u5300\u6027\u6b63\u5219\u5316\uff0c\u53ea\u9700128\u4e2a\u6821\u51c6\u6837\u672c\u5b66\u4e60\uff0c\u5728\u5355GPU\u4e0a\u51e0\u5206\u949f\u6536\u655b\u3002", "result": "\u5728LLaMA - 2 - 7B\u76842\u4f4d\u91cf\u5316\u4e2d\uff0cButterflyQuant\u56f0\u60d1\u5ea6\u4e3a15.4\uff0cQuaRot\u4e3a22.1\u3002", "conclusion": "ButterflyQuant\u5728\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u6781\u7aef\u91cf\u5316\u6027\u80fd\u635f\u5931\u95ee\u9898\u4e0a\u6709\u6548\uff0c\u4f18\u4e8e\u73b0\u6709\u56fa\u5b9a\u65cb\u8f6c\u91cf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2509.09131", "pdf": "https://arxiv.org/pdf/2509.09131", "abs": "https://arxiv.org/abs/2509.09131", "authors": ["Phuong-Nam Dang", "Kieu-Linh Nguyen", "Thanh-Hieu Pham"], "title": "ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages", "summary": "This paper presents ViRanker, a cross-encoder reranking model tailored to the\nVietnamese language. Built on the BGE-M3 encoder and enhanced with the\nBlockwise Parallel Transformer, ViRanker addresses the lack of competitive\nrerankers for Vietnamese, a low-resource language with complex syntax and\ndiacritics. The model was trained on an 8 GB curated corpus and fine-tuned with\nhybrid hard-negative sampling to strengthen robustness. Evaluated on the\nMMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing\nmultilingual baselines and competing closely with PhoRanker. By releasing the\nmodel openly on Hugging Face, we aim to support reproducibility and encourage\nwider adoption in real-world retrieval systems. Beyond Vietnamese, this study\nillustrates how careful architectural adaptation and data curation can advance\nreranking in other underrepresented languages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8d8a\u5357\u8bed\u8de8\u7f16\u7801\u5668\u91cd\u6392\u6a21\u578bViRanker\uff0c\u7ecf\u8bad\u7ec3\u548c\u5fae\u8c03\u540e\u5728MMARCO - VI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5f00\u6e90\u4ee5\u652f\u6301\u590d\u73b0\u548c\u63a8\u5e7f\u3002", "motivation": "\u89e3\u51b3\u8d8a\u5357\u8bed\u4f5c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u6709\u7ade\u4e89\u529b\u91cd\u6392\u5668\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eBGE - M3\u7f16\u7801\u5668\uff0c\u7ed3\u5408Blockwise Parallel Transformer\uff0c\u57288GB\u8bed\u6599\u4e0a\u8bad\u7ec3\uff0c\u7528\u6df7\u5408\u786c\u8d1f\u91c7\u6837\u5fae\u8c03\u3002", "result": "\u5728MMARCO - VI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u65e9\u671f\u6392\u540d\u51c6\u786e\u7387\u9ad8\uff0c\u8d85\u8d8a\u591a\u8bed\u8a00\u57fa\u7ebf\uff0c\u4e0ePhoRanker\u7ade\u4e89\u3002", "conclusion": "\u7cbe\u5fc3\u7684\u67b6\u6784\u8c03\u6574\u548c\u6570\u636e\u6574\u7406\u53ef\u63a8\u52a8\u5176\u4ed6\u4ee3\u8868\u6027\u4e0d\u8db3\u8bed\u8a00\u7684\u91cd\u6392\u5de5\u4f5c\u3002"}}
{"id": "2509.08830", "pdf": "https://arxiv.org/pdf/2509.08830", "abs": "https://arxiv.org/abs/2509.08830", "authors": ["Seong-A Park", "Jong-Eui Chae", "Sungdong Kim", "Hyung-Chul Lee", "Hyun-Lim Yang"], "title": "A Masked Representation Learning to Model Cardiac Functions Using Multiple Physiological Signals", "categories": ["eess.SP", "cs.LG"], "comment": "16 pages, 5 figures", "summary": "In clinical settings, monitoring hemodynamics is crucial for managing patient\nprognosis, necessitating the integrated analysis of multiple physiological\nsignals. While recent research has analyzed single signals such as\nelectrocardiography (ECG) or photoplethysmography (PPG), there has yet to be a\nproposal for an approach that encompasses the complex signal analysis required\nin actual clinical scenarios. In this study, we introduce the SNUPHY-M (Seoul\nNational University hospital PHYsiological signal Masked representation\nlearning) model extracts physiological features reflecting the electrical,\npressure, and fluid characteristics of the cardiac cycle in the process of\nrestoring three masked physiological signals based on self-supervised learning\n(SSL): ECG, PPG, and arterial blood pressure (ABP) signals. By employing\nmultiple physical characteristics, the model can extract more enriched features\nonly using non-invasive signals. We evaluated the model's performance in\nclinical downstream tasks such as hypotension, stroke volume, systolic blood\npressure, diastolic blood pressure, and age prediction. Our results showed that\nthe SNUPHY-M significantly outperformed supervised or SSL models, especially in\nprediction tasks using non-invasive signals. To the best of our knowledge,\nSNUPHY-M is the first model to apply multi-modal SSL to cardiovascular analysis\ninvolving ECG, PPG, and ABP signals. This approach effectively supports\nclinical decision-making and enables precise diagnostics, contributing\nsignificantly to the early diagnosis and management of hemodynamics without\ninvasiveness.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SNUPHY - M\u6a21\u578b\uff0c\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u6062\u590d\u4e09\u79cd\u751f\u7406\u4fe1\u53f7\u6765\u63d0\u53d6\u7279\u5f81\uff0c\u5728\u4e34\u5e8a\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u51fa\u8272\uff0c\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002", "motivation": "\u4e34\u5e8a\u4e2d\u76d1\u6d4b\u8840\u6d41\u52a8\u529b\u5b66\u9700\u7efc\u5408\u5206\u6790\u591a\u751f\u7406\u4fe1\u53f7\uff0c\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u9002\u7528\u4e8e\u5b9e\u9645\u4e34\u5e8a\u573a\u666f\u7684\u590d\u6742\u4fe1\u53f7\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u5f15\u5165SNUPHY - M\u6a21\u578b\uff0c\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u6062\u590dECG\u3001PPG\u548cABP\u4e09\u79cd\u63a9\u853d\u751f\u7406\u4fe1\u53f7\uff0c\u63d0\u53d6\u53cd\u6620\u5fc3\u810f\u5468\u671f\u7535\u3001\u538b\u529b\u548c\u6d41\u4f53\u7279\u5f81\u7684\u751f\u7406\u7279\u5f81\u3002", "result": "SNUPHY - M\u5728\u4e34\u5e8a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u6709\u76d1\u7763\u6216\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff0c\u5c24\u5176\u5728\u4f7f\u7528\u975e\u4fb5\u5165\u6027\u4fe1\u53f7\u7684\u9884\u6d4b\u4efb\u52a1\u4e2d\u3002", "conclusion": "SNUPHY - M\u662f\u9996\u4e2a\u5c06\u591a\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\u5e94\u7528\u4e8e\u6d89\u53caECG\u3001PPG\u548cABP\u4fe1\u53f7\u7684\u5fc3\u8840\u7ba1\u5206\u6790\u7684\u6a21\u578b\uff0c\u80fd\u6709\u6548\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\uff0c\u65e0\u521b\u52a9\u529b\u8840\u6d41\u52a8\u529b\u5b66\u65e9\u671f\u8bca\u65ad\u548c\u7ba1\u7406\u3002"}}
{"id": "2509.09143", "pdf": "https://arxiv.org/pdf/2509.09143", "abs": "https://arxiv.org/abs/2509.09143", "authors": ["Yuiko Uchida", "Ren Togo", "Keisuke Maeda", "Takahiro Ogawa", "Miki Haseyama"], "title": "Objectness Similarity: Capturing Object-Level Fidelity in 3D Scene Evaluation", "categories": ["cs.CV", "cs.AI", "cs.GR"], "comment": "Accepted by the ICCV 2025 UniLight Workshop", "summary": "This paper presents Objectness SIMilarity (OSIM), a novel evaluation metric\nfor 3D scenes that explicitly focuses on \"objects,\" which are fundamental units\nof human visual perception. Existing metrics assess overall image quality,\nleading to discrepancies with human perception. Inspired by neuropsychological\ninsights, we hypothesize that human recognition of 3D scenes fundamentally\ninvolves attention to individual objects. OSIM enables object-centric\nevaluations by leveraging an object detection model and its feature\nrepresentations to quantify the \"objectness\" of each object in the scene. Our\nuser study demonstrates that OSIM aligns more closely with human perception\ncompared to existing metrics. We also analyze the characteristics of OSIM using\nvarious approaches. Moreover, we re-evaluate recent 3D reconstruction and\ngeneration models under a standardized experimental setup to clarify\nadvancements in this field. The code is available at\nhttps://github.com/Objectness-Similarity/OSIM.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e3D\u573a\u666f\u7684\u65b0\u9896\u8bc4\u4f30\u6307\u6807OSIM\uff0c\u5176\u4ee5\u7269\u4f53\u4e3a\u4e2d\u5fc3\uff0c\u66f4\u7b26\u5408\u4eba\u7c7b\u611f\u77e5\uff0c\u8fd8\u91cd\u65b0\u8bc4\u4f30\u4e86\u8fd1\u671f\u6a21\u578b\u3002", "motivation": "\u73b0\u67093D\u573a\u666f\u8bc4\u4f30\u6307\u6807\u5173\u6ce8\u6574\u4f53\u56fe\u50cf\u8d28\u91cf\uff0c\u4e0e\u4eba\u7c7b\u611f\u77e5\u5b58\u5728\u5dee\u5f02\uff0c\u56e0\u6b64\u9700\u8981\u4ee5\u7269\u4f53\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u6307\u6807\u3002", "method": "\u5229\u7528\u7269\u4f53\u68c0\u6d4b\u6a21\u578b\u53ca\u5176\u7279\u5f81\u8868\u793a\u6765\u91cf\u5316\u573a\u666f\u4e2d\u6bcf\u4e2a\u7269\u4f53\u7684\u201c\u7269\u4f53\u6027\u201d\u4ee5\u5b9e\u73b0\u4ee5\u7269\u4f53\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u3002", "result": "\u7528\u6237\u7814\u7a76\u8868\u660eOSIM\u6bd4\u73b0\u6709\u6307\u6807\u66f4\u7b26\u5408\u4eba\u7c7b\u611f\u77e5\uff0c\u8fd8\u5bf9OSIM\u7684\u7279\u5f81\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u91cd\u65b0\u8bc4\u4f30\u4e86\u8fd1\u671f\u6a21\u578b\u3002", "conclusion": "OSIM\u662f\u4e00\u79cd\u66f4\u6709\u6548\u76843D\u573a\u666f\u8bc4\u4f30\u6307\u6807\uff0c\u6709\u52a9\u4e8e\u660e\u786e\u8be5\u9886\u57df\u7684\u8fdb\u5c55\u3002"}}
{"id": "2509.09151", "pdf": "https://arxiv.org/pdf/2509.09151", "abs": "https://arxiv.org/abs/2509.09151", "authors": ["Lei Wang", "Piotr Koniusz", "Yongsheng Gao"], "title": "Video Understanding by Design: How Datasets Shape Architectures and Insights", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Research report", "summary": "Video understanding has advanced rapidly, fueled by increasingly complex\ndatasets and powerful architectures. Yet existing surveys largely classify\nmodels by task or family, overlooking the structural pressures through which\ndatasets guide architectural evolution. This survey is the first to adopt a\ndataset-driven perspective, showing how motion complexity, temporal span,\nhierarchical composition, and multimodal richness impose inductive biases that\nmodels should encode. We reinterpret milestones, from two-stream and 3D CNNs to\nsequential, transformer, and multimodal foundation models, as concrete\nresponses to these dataset-driven pressures. Building on this synthesis, we\noffer practical guidance for aligning model design with dataset invariances\nwhile balancing scalability and task demands. By unifying datasets, inductive\nbiases, and architectures into a coherent framework, this survey provides both\na comprehensive retrospective and a prescriptive roadmap for advancing\ngeneral-purpose video understanding.", "AI": {"tldr": "\u73b0\u6709\u89c6\u9891\u7406\u89e3\u8c03\u67e5\u591a\u6309\u4efb\u52a1\u6216\u6a21\u578b\u5bb6\u65cf\u5206\u7c7b\uff0c\u672c\u6587\u9996\u6b21\u4ece\u6570\u636e\u96c6\u9a71\u52a8\u89c6\u89d2\u5206\u6790\uff0c\u5c55\u793a\u6570\u636e\u96c6\u7279\u5f81\u5bf9\u6a21\u578b\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u91cd\u65b0\u89e3\u8bfb\u6a21\u578b\u53d1\u5c55\u91cc\u7a0b\u7891\uff0c\u63d0\u4f9b\u6a21\u578b\u8bbe\u8ba1\u6307\u5bfc\u548c\u53d1\u5c55\u8def\u7ebf\u56fe\u3002", "motivation": "\u73b0\u6709\u8c03\u67e5\u5ffd\u89c6\u6570\u636e\u96c6\u5bf9\u67b6\u6784\u6f14\u53d8\u7684\u7ed3\u6784\u6027\u538b\u529b\uff0c\u9700\u8981\u4ece\u6570\u636e\u96c6\u9a71\u52a8\u89c6\u89d2\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6570\u636e\u96c6\u9a71\u52a8\u89c6\u89d2\uff0c\u5206\u6790\u8fd0\u52a8\u590d\u6742\u6027\u3001\u65f6\u95f4\u8de8\u5ea6\u3001\u5c42\u6b21\u7ec4\u6210\u548c\u591a\u6a21\u6001\u4e30\u5bcc\u5ea6\u7b49\u6570\u636e\u96c6\u7279\u5f81\u5bf9\u6a21\u578b\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "result": "\u91cd\u65b0\u89e3\u8bfb\u4e86\u4ece\u53cc\u6d41\u548c3D CNN\u5230\u987a\u5e8f\u3001Transformer\u548c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7b49\u53d1\u5c55\u91cc\u7a0b\u7891\uff0c\u63d0\u4f9b\u4e86\u6a21\u578b\u8bbe\u8ba1\u7684\u5b9e\u7528\u6307\u5bfc\u3002", "conclusion": "\u5c06\u6570\u636e\u96c6\u3001\u5f52\u7eb3\u504f\u7f6e\u548c\u67b6\u6784\u7edf\u4e00\u6210\u8fde\u8d2f\u6846\u67b6\uff0c\u4e3a\u901a\u7528\u89c6\u9891\u7406\u89e3\u63d0\u4f9b\u5168\u9762\u56de\u987e\u548c\u524d\u77bb\u6027\u8def\u7ebf\u56fe\u3002"}}
{"id": "2509.09153", "pdf": "https://arxiv.org/pdf/2509.09153", "abs": "https://arxiv.org/abs/2509.09153", "authors": ["JaeWoong Shin", "Jeongun Ryu", "Aaron Valero Puche", "Jinhee Lee", "Biagio Brattoli", "Wonkyung Jung", "Soo Ick Cho", "Kyunghyun Paeng", "Chan-Young Ock", "Donggeun Yoo", "Zhaoyang Li", "Wangkai Li", "Huayu Mai", "Joshua Millward", "Zhen He", "Aiden Nibali", "Lydia Anette Schoenpflug", "Viktor Hendrik Koelzer", "Xu Shuoyu", "Ji Zheng", "Hu Bin", "Yu-Wen Lo", "Ching-Hui Yang", "S\u00e9rgio Pereira"], "title": "OCELOT 2023: Cell Detection from Cell-Tissue Interaction Challenge", "categories": ["cs.CV", "cs.AI"], "comment": "This is the accepted manuscript of an article published in Medical\n  Image Analysis (Elsevier). The final version is available at:\n  https://doi.org/10.1016/j.media.2025.103751", "summary": "Pathologists routinely alternate between different magnifications when\nexamining Whole-Slide Images, allowing them to evaluate both broad tissue\nmorphology and intricate cellular details to form comprehensive diagnoses.\nHowever, existing deep learning-based cell detection models struggle to\nreplicate these behaviors and learn the interdependent semantics between\nstructures at different magnifications. A key barrier in the field is the lack\nof datasets with multi-scale overlapping cell and tissue annotations. The\nOCELOT 2023 challenge was initiated to gather insights from the community to\nvalidate the hypothesis that understanding cell and tissue (cell-tissue)\ninteractions is crucial for achieving human-level performance, and to\naccelerate the research in this field. The challenge dataset includes\noverlapping cell detection and tissue segmentation annotations from six organs,\ncomprising 673 pairs sourced from 306 The Cancer Genome Atlas (TCGA)\nWhole-Slide Images with hematoxylin and eosin staining, divided into training,\nvalidation, and test subsets. Participants presented models that significantly\nenhanced the understanding of cell-tissue relationships. Top entries achieved\nup to a 7.99 increase in F1-score on the test set compared to the baseline\ncell-only model that did not incorporate cell-tissue relationships. This is a\nsubstantial improvement in performance over traditional cell-only detection\nmethods, demonstrating the need for incorporating multi-scale semantics into\nthe models. This paper provides a comparative analysis of the methods used by\nparticipants, highlighting innovative strategies implemented in the OCELOT 2023\nchallenge.", "AI": {"tldr": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u7ec6\u80de\u68c0\u6d4b\u6a21\u578b\u96be\u4ee5\u5b66\u4e60\u4e0d\u540c\u653e\u5927\u500d\u6570\u7ed3\u6784\u95f4\u8bed\u4e49\uff0cOCELOT 2023 \u6311\u6218\u6536\u96c6\u591a\u5c3a\u5ea6\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u53c2\u4e0e\u8005\u6a21\u578b\u63d0\u5347\u4e86\u5bf9\u7ec6\u80de - \u7ec4\u7ec7\u5173\u7cfb\u7684\u7406\u89e3\uff0c\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u7ec6\u80de\u68c0\u6d4b\u6a21\u578b\u96be\u4ee5\u590d\u5236\u75c5\u7406\u5b66\u5bb6\u5207\u6362\u653e\u5927\u500d\u6570\u7684\u884c\u4e3a\uff0c\u7f3a\u4e4f\u591a\u5c3a\u5ea6\u91cd\u53e0\u7ec6\u80de\u548c\u7ec4\u7ec7\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u7406\u89e3\u7ec6\u80de - \u7ec4\u7ec7\u76f8\u4e92\u4f5c\u7528\u5bf9\u5b9e\u73b0\u4eba\u7c7b\u6c34\u5e73\u6027\u80fd\u7684\u91cd\u8981\u6027\u5e76\u52a0\u901f\u8be5\u9886\u57df\u7814\u7a76\u3002", "method": "\u4e3e\u529e OCELOT 2023 \u6311\u6218\uff0c\u63d0\u4f9b\u5305\u542b\u516d\u4e2a\u5668\u5b98\u91cd\u53e0\u7ec6\u80de\u68c0\u6d4b\u548c\u7ec4\u7ec7\u5206\u5272\u6807\u6ce8\u7684\u6570\u636e\u96c6\uff0c\u53c2\u4e0e\u8005\u63d0\u51fa\u6a21\u578b\u3002", "result": "\u53c2\u4e0e\u8005\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u7ec6\u80de - \u7ec4\u7ec7\u5173\u7cfb\u7684\u7406\u89e3\uff0c\u9876\u7ea7\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a F1 \u5206\u6570\u6bd4\u4ec5\u8003\u8651\u7ec6\u80de\u7684\u57fa\u7ebf\u6a21\u578b\u63d0\u9ad8 7.99\u3002", "conclusion": "\u5c06\u591a\u5c3a\u5ea6\u8bed\u4e49\u7eb3\u5165\u6a21\u578b\u662f\u5fc5\u8981\u7684\uff0c\u8bba\u6587\u5bf9\u53c2\u4e0e\u8005\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u7a81\u51fa\u6311\u6218\u4e2d\u7684\u521b\u65b0\u7b56\u7565\u3002"}}
{"id": "2509.08858", "pdf": "https://arxiv.org/pdf/2509.08858", "abs": "https://arxiv.org/abs/2509.08858", "authors": ["Oriane Peter", "Kate Devlin"], "title": "Decentralising LLM Alignment: A Case for Context, Pluralism, and Participation", "categories": ["cs.CY", "cs.LG"], "comment": "Accepted at AIES 2025", "summary": "Large Language Models (LLMs) alignment methods have been credited with the\ncommercial success of products like ChatGPT, given their role in steering LLMs\ntowards user-friendly outputs. However, current alignment techniques\npredominantly mirror the normative preferences of a narrow reference group,\neffectively imposing their values on a wide user base. Drawing on theories of\nthe power/knowledge nexus, this work argues that current alignment practices\ncentralise control over knowledge production and governance within already\ninfluential institutions. To counter this, we propose decentralising alignment\nthrough three characteristics: context, pluralism, and participation.\nFurthermore, this paper demonstrates the critical importance of delineating the\ncontext-of-use when shaping alignment practices by grounding each of these\nfeatures in concrete use cases. This work makes the following contributions:\n(1) highlighting the role of context, pluralism, and participation in\ndecentralising alignment; (2) providing concrete examples to illustrate these\nstrategies; and (3) demonstrating the nuanced requirements associated with\napplying alignment across different contexts of use. Ultimately, this paper\npositions LLM alignment as a potential site of resistance against epistemic\ninjustice and the erosion of democratic processes, while acknowledging that\nthese strategies alone cannot substitute for broader societal changes.", "AI": {"tldr": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u60c5\u5883\u3001\u591a\u5143\u6027\u548c\u53c2\u4e0e\u6027\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u5bf9\u9f50\uff0c\u5e76\u9610\u8ff0\u5176\u4f5c\u7528\u3001\u4e3e\u4f8b\u53ca\u4e0d\u540c\u4f7f\u7528\u60c5\u5883\u8981\u6c42\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u6280\u672f\u4e3b\u8981\u53cd\u6620\u5c11\u6570\u53c2\u8003\u7fa4\u4f53\u504f\u597d\uff0c\u5c06\u5176\u4ef7\u503c\u89c2\u5f3a\u52a0\u7ed9\u5e7f\u5927\u7528\u6237\uff0c\u4e14\u4f7f\u77e5\u8bc6\u751f\u4ea7\u548c\u6cbb\u7406\u63a7\u5236\u6743\u96c6\u4e2d\u5728\u6709\u5f71\u54cd\u529b\u7684\u673a\u6784\u3002", "method": "\u501f\u9274\u6743\u529b/\u77e5\u8bc6\u5173\u7cfb\u7406\u8bba\uff0c\u63d0\u51fa\u901a\u8fc7\u60c5\u5883\u3001\u591a\u5143\u6027\u548c\u53c2\u4e0e\u6027\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u5bf9\u9f50\uff0c\u5e76\u7ed3\u5408\u5177\u4f53\u7528\u4f8b\u8bf4\u660e\u3002", "result": "\u7a81\u51fa\u4e86\u60c5\u5883\u3001\u591a\u5143\u6027\u548c\u53c2\u4e0e\u6027\u5728\u53bb\u4e2d\u5fc3\u5316\u5bf9\u9f50\u4e2d\u7684\u4f5c\u7528\uff0c\u63d0\u4f9b\u5177\u4f53\u7b56\u7565\u793a\u4f8b\uff0c\u5c55\u793a\u4e0d\u540c\u4f7f\u7528\u60c5\u5883\u4e0b\u5bf9\u9f50\u7684\u7ec6\u5fae\u8981\u6c42\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u53ef\u4f5c\u4e3a\u62b5\u6297\u8ba4\u77e5\u4e0d\u516c\u6b63\u548c\u6c11\u4e3b\u8fdb\u7a0b\u4fb5\u8680\u7684\u6f5c\u5728\u573a\u6240\uff0c\u4f46\u8fd9\u4e9b\u7b56\u7565\u4e0d\u80fd\u66ff\u4ee3\u66f4\u5e7f\u6cdb\u7684\u793e\u4f1a\u53d8\u9769\u3002"}}
{"id": "2509.08872", "pdf": "https://arxiv.org/pdf/2509.08872", "abs": "https://arxiv.org/abs/2509.08872", "authors": ["Felipe \u00c1lvarez Barrientos", "Tom\u00e1s Banduc", "Isabeau Sirven", "Francisco Sahli Costabal"], "title": "WarpPINN-fibers: improved cardiac strain estimation from cine-MR with physics-informed neural networks", "categories": ["eess.IV", "cs.LG", "physics.med-ph"], "comment": null, "summary": "The contractile motion of the heart is strongly determined by the\ndistribution of the fibers that constitute cardiac tissue. Strain analysis\ninformed with the orientation of fibers allows to describe several pathologies\nthat are typically associated with impaired mechanics of the myocardium, such\nas cardiovascular disease. Several methods have been developed to estimate\nstrain-derived metrics from traditional imaging techniques. However, the\nphysical models underlying these methods do not include fiber mechanics,\nrestricting their capacity to accurately explain cardiac function. In this\nwork, we introduce WarpPINN-fibers, a physics-informed neural network framework\nto accurately obtain cardiac motion and strains enhanced by fiber information.\nWe train our neural network to satisfy a hyper-elastic model and promote fiber\ncontraction with the goal to predict the deformation field of the heart from\ncine magnetic resonance images. For this purpose, we build a loss function\ncomposed of three terms: a data-similarity loss between the reference and the\nwarped template images, a regularizer enforcing near-incompressibility of\ncardiac tissue and a fiber-stretch penalization that controls strain in the\ndirection of synthetically produced fibers. We show that our neural network\nimproves the former WarpPINN model and effectively controls fiber stretch in a\nsynthetic phantom experiment. Then, we demonstrate that WarpPINN-fibers\noutperforms alternative methodologies in landmark-tracking and strain curve\nprediction for a cine-MRI benchmark with a cohort of 15 healthy volunteers. We\nexpect that our method will enable a more precise quantification of cardiac\nstrains through accurate deformation fields that are consistent with fiber\nphysiology, without requiring imaging techniques more sophisticated than MRI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faWarpPINN - fibers\u6846\u67b6\uff0c\u4ececine\u78c1\u5171\u632f\u56fe\u50cf\u83b7\u53d6\u53d7\u7ea4\u7ef4\u4fe1\u606f\u589e\u5f3a\u7684\u5fc3\u810f\u8fd0\u52a8\u548c\u5e94\u53d8\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u5148\u524d\u6a21\u578b\u548c\u5176\u4ed6\u65b9\u6cd5\uff0c\u6709\u671b\u7cbe\u786e\u91cf\u5316\u5fc3\u810f\u5e94\u53d8\u3002", "motivation": "\u73b0\u6709\u4ece\u4f20\u7edf\u6210\u50cf\u6280\u672f\u4f30\u8ba1\u5e94\u53d8\u6307\u6807\u7684\u65b9\u6cd5\u672a\u5305\u542b\u7ea4\u7ef4\u529b\u5b66\uff0c\u9650\u5236\u4e86\u51c6\u786e\u89e3\u91ca\u5fc3\u810f\u529f\u80fd\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165WarpPINN - fibers\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u6784\u5efa\u5305\u542b\u6570\u636e\u76f8\u4f3c\u6027\u635f\u5931\u3001\u8fd1\u4e0d\u53ef\u538b\u7f29\u6b63\u5219\u5316\u9879\u548c\u7ea4\u7ef4\u62c9\u4f38\u60e9\u7f5a\u9879\u7684\u635f\u5931\u51fd\u6570\uff0c\u8bad\u7ec3\u7f51\u7edc\u4ee5\u6ee1\u8db3\u8d85\u5f39\u6027\u6a21\u578b\u5e76\u4fc3\u8fdb\u7ea4\u7ef4\u6536\u7f29\u3002", "result": "\u5728\u5408\u6210\u4f53\u6a21\u5b9e\u9a8c\u4e2d\u6539\u8fdb\u4e86\u5148\u524d\u7684WarpPINN\u6a21\u578b\uff0c\u6709\u6548\u63a7\u5236\u7ea4\u7ef4\u62c9\u4f38\uff1b\u5728cine - MRI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u5730\u6807\u8ddf\u8e2a\u548c\u5e94\u53d8\u66f2\u7ebf\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u6bd4MRI\u66f4\u590d\u6742\u7684\u6210\u50cf\u6280\u672f\uff0c\u53ef\u901a\u8fc7\u4e0e\u7ea4\u7ef4\u751f\u7406\u5b66\u4e00\u81f4\u7684\u51c6\u786e\u53d8\u5f62\u573a\u5b9e\u73b0\u5bf9\u5fc3\u810f\u5e94\u53d8\u66f4\u7cbe\u786e\u7684\u91cf\u5316\u3002"}}
{"id": "2509.09159", "pdf": "https://arxiv.org/pdf/2509.09159", "abs": "https://arxiv.org/abs/2509.09159", "authors": ["Zhiyue Liu", "Sihang Liu", "Jinyuan Liu", "Xinru Zhang"], "title": "A Knowledge Noise Mitigation Framework for Knowledge-based Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the IEEE International Conference on Multimedia and Expo\n  (ICME 2025) for oral presentation. \\copyright\\ 2025 IEEE. Personal use of\n  this material is permitted. Permission from IEEE must be obtained for all\n  other uses", "summary": "Knowledge-based visual question answering (KB-VQA) requires a model to\nunderstand images and utilize external knowledge to provide accurate answers.\nExisting approaches often directly augment models with retrieved information\nfrom knowledge sources while ignoring substantial knowledge redundancy, which\nintroduces noise into the answering process. To address this, we propose a\ntraining-free framework with knowledge focusing for KB-VQA, that mitigates the\nimpact of noise by enhancing knowledge relevance and reducing redundancy.\nFirst, for knowledge retrieval, our framework concludes essential parts from\nthe image-question pairs, creating low-noise queries that enhance the retrieval\nof highly relevant knowledge. Considering that redundancy still persists in the\nretrieved knowledge, we then prompt large models to identify and extract\nanswer-beneficial segments from knowledge. In addition, we introduce a\nselective knowledge integration strategy, allowing the model to incorporate\nknowledge only when it lacks confidence in answering the question, thereby\nmitigating the influence of redundant information. Our framework enables the\nacquisition of accurate and critical knowledge, and extensive experiments\ndemonstrate that it outperforms state-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u77e5\u8bc6\u805a\u7126\u6846\u67b6\u7528\u4e8eKB - VQA\uff0c\u80fd\u83b7\u53d6\u51c6\u786e\u5173\u952e\u77e5\u8bc6\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709KB - VQA\u65b9\u6cd5\u76f4\u63a5\u7528\u68c0\u7d22\u4fe1\u606f\u589e\u5f3a\u6a21\u578b\uff0c\u5ffd\u7565\u77e5\u8bc6\u5197\u4f59\uff0c\u5f15\u5165\u566a\u58f0\u3002", "method": "\u521b\u5efa\u4f4e\u566a\u58f0\u67e5\u8be2\u589e\u5f3a\u77e5\u8bc6\u68c0\u7d22\u76f8\u5173\u6027\uff1b\u8ba9\u5927\u6a21\u578b\u63d0\u53d6\u7b54\u6848\u6709\u76ca\u77e5\u8bc6\u7247\u6bb5\uff1b\u5f15\u5165\u9009\u62e9\u6027\u77e5\u8bc6\u96c6\u6210\u7b56\u7565\uff0c\u4ec5\u5728\u6a21\u578b\u56de\u7b54\u4fe1\u5fc3\u4e0d\u8db3\u65f6\u878d\u5165\u77e5\u8bc6\u3002", "result": "\u6846\u67b6\u80fd\u83b7\u53d6\u51c6\u786e\u548c\u5173\u952e\u77e5\u8bc6\uff0c\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u8bad\u7ec3\u65e0\u6846\u67b6\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u89e3\u51b3KB - VQA\u4e2d\u77e5\u8bc6\u5197\u4f59\u5e26\u6765\u7684\u566a\u58f0\u95ee\u9898\u3002"}}
{"id": "2509.09160", "pdf": "https://arxiv.org/pdf/2509.09160", "abs": "https://arxiv.org/abs/2509.09160", "authors": ["Zhiyue Liu", "Fanrong Ma", "Xin Ling"], "title": "Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by the IEEE International Conference on Multimedia and Expo\n  (ICME 2025). \\copyright\\ 2025 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses", "summary": "Target-oriented multimodal sentiment classification seeks to predict\nsentiment polarity for specific targets from image-text pairs. While existing\nworks achieve competitive performance, they often over-rely on textual content\nand fail to consider dataset biases, in particular word-level contextual\nbiases. This leads to spurious correlations between text features and output\nlabels, impairing classification accuracy. In this paper, we introduce a novel\ncounterfactual-enhanced debiasing framework to reduce such spurious\ncorrelations. Our framework incorporates a counterfactual data augmentation\nstrategy that minimally alters sentiment-related causal features, generating\ndetail-matched image-text samples to guide the model's attention toward content\ntied to sentiment. Furthermore, for learning robust features from\ncounterfactual data and prompting model decisions, we introduce an adaptive\ndebiasing contrastive learning mechanism, which effectively mitigates the\ninfluence of biased words. Experimental results on several benchmark datasets\nshow that our proposed method outperforms state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53cd\u4e8b\u5b9e\u589e\u5f3a\u53bb\u504f\u6846\u67b6\u7528\u4e8e\u9762\u5411\u76ee\u6807\u7684\u591a\u6a21\u6001\u60c5\u611f\u5206\u7c7b\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u9762\u5411\u76ee\u6807\u7684\u591a\u6a21\u6001\u60c5\u611f\u5206\u7c7b\u5de5\u4f5c\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u5185\u5bb9\uff0c\u672a\u8003\u8651\u6570\u636e\u96c6\u504f\u5dee\uff0c\u5bfc\u81f4\u6587\u672c\u7279\u5f81\u4e0e\u8f93\u51fa\u6807\u7b7e\u5b58\u5728\u865a\u5047\u5173\u8054\uff0c\u5f71\u54cd\u5206\u7c7b\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165\u53cd\u4e8b\u5b9e\u589e\u5f3a\u53bb\u504f\u6846\u67b6\uff0c\u5305\u542b\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u7b56\u7565\u548c\u81ea\u9002\u5e94\u53bb\u504f\u5bf9\u6bd4\u5b66\u4e60\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53cd\u4e8b\u5b9e\u589e\u5f3a\u53bb\u504f\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u865a\u5047\u5173\u8054\uff0c\u63d0\u5347\u9762\u5411\u76ee\u6807\u7684\u591a\u6a21\u6001\u60c5\u611f\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2509.08950", "pdf": "https://arxiv.org/pdf/2509.08950", "abs": "https://arxiv.org/abs/2509.08950", "authors": ["Jarvis Haupt", "Qin Lu", "Yanning Shen", "Jia Chen", "Yue Dong", "Dan McCreary", "Mehmet Ak\u00e7akaya", "Georgios B. Giannakis"], "title": "Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities", "categories": ["eess.SP", "cs.LG"], "comment": "Accepted to the IEEE Signal Processing Magazine Special Issue on\n  Artificial Intelligence for Education: A Signal Processing Perspective", "summary": "Powerful artificial intelligence (AI) tools that have emerged in recent years\n-- including large language models, automated coding assistants, and advanced\nimage and speech generation technologies -- are the result of monumental human\nachievements. These breakthroughs reflect mastery across multiple technical\ndisciplines and the resolution of significant technological challenges.\nHowever, some of the most profound challenges may still lie ahead. These\nchallenges are not purely technical but pertain to the fair and responsible use\nof AI in ways that genuinely improve the global human condition. This article\nexplores one promising application aligned with that vision: the use of AI\ntools to facilitate and enhance education, with a specific focus on signal\nprocessing (SP). It presents two interrelated perspectives: identifying and\naddressing technical limitations, and applying AI tools in practice to improve\neducational experiences. Primers are provided on several core technical issues\nthat arise when using AI in educational settings, including how to ensure\nfairness and inclusivity, handle hallucinated outputs, and achieve efficient\nuse of resources. These and other considerations -- such as transparency,\nexplainability, and trustworthiness -- are illustrated through the development\nof an immersive, structured, and reliable \"smart textbook.\" The article serves\nas a resource for researchers and educators seeking to advance AI's role in\nengineering education.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8AI\u5728\u4fe1\u53f7\u5904\u7406\u6559\u80b2\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u89e3\u51b3\u6280\u672f\u5c40\u9650\u548c\u5b9e\u8df5\u5e94\u7528\u4e24\u65b9\u9762\u89c6\u89d2\uff0c\u8fd8\u7ed9\u51fa\u6838\u5fc3\u6280\u672f\u95ee\u9898\u6307\u5f15\uff0c\u4e3a\u5de5\u7a0b\u6559\u80b2\u7814\u7a76\u8005\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u63d0\u4f9b\u8d44\u6e90\u3002", "motivation": "\u5e94\u5bf9AI\u516c\u5e73\u548c\u8d1f\u8d23\u4efb\u4f7f\u7528\u7684\u6311\u6218\uff0c\u63a2\u7d22AI\u5728\u6539\u5584\u5168\u7403\u4eba\u7c7b\u72b6\u51b5\u65b9\u9762\u7684\u5e94\u7528\uff0c\u805a\u7126\u4e8e\u4fe1\u53f7\u5904\u7406\u6559\u80b2\u9886\u57df\u3002", "method": "\u4ece\u8bc6\u522b\u548c\u89e3\u51b3\u6280\u672f\u5c40\u9650\u3001\u5728\u5b9e\u8df5\u4e2d\u5e94\u7528AI\u5de5\u5177\u4e24\u65b9\u9762\u8fdb\u884c\u63a2\u7d22\uff0c\u901a\u8fc7\u5f00\u53d1\u201c\u667a\u80fd\u6559\u79d1\u4e66\u201d\u8bf4\u660e\u76f8\u5173\u8003\u91cf\u3002", "result": "\u63d0\u4f9b\u4e86\u5728\u6559\u80b2\u573a\u666f\u4f7f\u7528AI\u65f6\u82e5\u5e72\u6838\u5fc3\u6280\u672f\u95ee\u9898\u7684\u6307\u5f15\u3002", "conclusion": "\u6587\u7ae0\u53ef\u4f5c\u4e3a\u7814\u7a76\u8005\u548c\u6559\u80b2\u5de5\u4f5c\u8005\u63a8\u52a8AI\u5728\u5de5\u7a0b\u6559\u80b2\u4e2d\u53d1\u6325\u4f5c\u7528\u7684\u8d44\u6e90\u3002"}}
{"id": "2509.08954", "pdf": "https://arxiv.org/pdf/2509.08954", "abs": "https://arxiv.org/abs/2509.08954", "authors": ["Le Duc Hieu"], "title": "Convexity of Optimization Curves: Local Sharp Thresholds, Robustness Impossibility, and New Counterexamples", "categories": ["math.OC", "cs.LG", "90C25, 90C30, 65K05, 37N40, 26B25"], "comment": null, "summary": "We study when the \\emph{optimization curve} of first-order methods -- the\nsequence \\${f(x\\_n)}*{n\\ge0}\\$ produced by constant-stepsize iterations -- is\nconvex, equivalently when the forward differences \\$f(x\\_n)-f(x*{n+1})\\$ are\nnonincreasing. For gradient descent (GD) on convex \\$L\\$-smooth functions, the\ncurve is convex for all stepsizes \\$\\eta \\le 1.75/L\\$, and this threshold is\ntight. Moreover, gradient norms are nonincreasing for all \\$\\eta \\le 2/L\\$, and\nin continuous time (gradient flow) the curve is always convex. These results\ncomplement and refine the classical smooth convex optimization toolbox,\nconnecting discrete and continuous dynamics as well as worst-case analyses.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.09174", "pdf": "https://arxiv.org/pdf/2509.09174", "abs": "https://arxiv.org/abs/2509.09174", "authors": ["Yuhao Zhang", "Yuhao Du", "Zhanchen Dai", "Xiangnan Ma", "Kaiqi Kou", "Benyou Wang", "Haizhou Li"], "title": "EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": null, "summary": "Speech-to-speech large language models (SLLMs) are attracting increasing\nattention. Derived from text-based large language models (LLMs), SLLMs often\nexhibit degradation in knowledge and reasoning capabilities. We hypothesize\nthat this limitation arises because current training paradigms for SLLMs fail\nto bridge the acoustic-semantic gap in the feature representation space. To\naddress this issue, we propose EchoX, which leverages semantic representations\nand dynamically generates speech training targets. This approach integrates\nboth acoustic and semantic learning, enabling EchoX to preserve strong\nreasoning abilities as a speech LLM. Experimental results demonstrate that\nEchoX, with about six thousand hours of training data, achieves advanced\nperformance on multiple knowledge-based question-answering benchmarks. The\nproject is available at https://github.com/FreedomIntelligence/EchoX.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u8bed\u97f3\u5230\u5927\u8bed\u8a00\u6a21\u578b\uff08SLLMs\uff09\u5b58\u5728\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u9000\u5316\u95ee\u9898\uff0c\u63d0\u51faEchoX\u65b9\u6cd5\u89e3\u51b3\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6709\u826f\u597d\u8868\u73b0\u3002", "motivation": "\u5f53\u524dSLLMs\u8bad\u7ec3\u8303\u5f0f\u672a\u80fd\u5f25\u5408\u7279\u5f81\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u58f0\u5b66 - \u8bed\u4e49\u5dee\u8ddd\uff0c\u5bfc\u81f4\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u9000\u5316\u3002", "method": "\u63d0\u51faEchoX\uff0c\u5229\u7528\u8bed\u4e49\u8868\u793a\u5e76\u52a8\u6001\u751f\u6210\u8bed\u97f3\u8bad\u7ec3\u76ee\u6807\uff0c\u6574\u5408\u58f0\u5b66\u548c\u8bed\u4e49\u5b66\u4e60\u3002", "result": "EchoX\u7528\u7ea6\u516d\u5343\u5c0f\u65f6\u8bad\u7ec3\u6570\u636e\uff0c\u5728\u591a\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u7684\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "EchoX\u80fd\u4f5c\u4e3a\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\u4fdd\u7559\u5f3a\u5927\u63a8\u7406\u80fd\u529b\uff0c\u9879\u76ee\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2509.08967", "pdf": "https://arxiv.org/pdf/2509.08967", "abs": "https://arxiv.org/abs/2509.08967", "authors": ["Xinquan Huang", "Fu Wang", "Tariq Alkhalifah"], "title": "Physics-informed waveform inversion using pretrained wavefield neural operators", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Full waveform inversion (FWI) is crucial for reconstructing high-resolution\nsubsurface models, but it is often hindered, considering the limited data, by\nits null space resulting in low-resolution models, and more importantly, by its\ncomputational cost, especially if needed for real-time applications. Recent\nattempts to accelerate FWI using learned wavefield neural operators have shown\npromise in efficiency and differentiability, but typically suffer from noisy\nand unstable inversion performance. To address these limitations, we introduce\na novel physics-informed FWI framework to enhance the inversion in accuracy\nwhile maintaining the efficiency of neural operator-based FWI. Instead of\nrelying only on the L2 norm objective function via automatic differentiation,\nresulting in noisy model reconstruction, we integrate a physics constraint term\nin the loss function of FWI, improving the quality of the inverted velocity\nmodels. Specifically, starting with an initial model to simulate wavefields and\nthen evaluating the loss over how much the resulting wavefield obeys the\nphysical laws (wave equation) and matches the recorded data, we achieve a\nreduction in noise and artifacts. Numerical experiments using the OpenFWI and\nOverthrust models demonstrate our method's superior performance, offering\ncleaner and more accurate subsurface velocity than vanilla approaches.\nConsidering the efficiency of the approach compared to FWI, this advancement\nrepresents a significant step forward in the practical application of FWI for\nreal-time subsurface monitoring.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u7269\u7406\u4fe1\u606f\u5168\u6ce2\u5f62\u53cd\u6f14\uff08FWI\uff09\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u53cd\u6f14\u7cbe\u5ea6\uff0c\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u4f20\u7edfFWI\u53d7\u9650\u4e8e\u96f6\u7a7a\u95f4\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u57fa\u4e8e\u5b66\u4e60\u6ce2\u573a\u795e\u7ecf\u7b97\u5b50\u52a0\u901fFWI\u5b58\u5728\u53cd\u6f14\u6027\u80fd\u566a\u58f0\u5927\u3001\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5728FWI\u635f\u5931\u51fd\u6570\u4e2d\u96c6\u6210\u7269\u7406\u7ea6\u675f\u9879\uff0c\u4ece\u521d\u59cb\u6a21\u578b\u6a21\u62df\u6ce2\u573a\uff0c\u8bc4\u4f30\u6ce2\u573a\u5bf9\u7269\u7406\u5b9a\u5f8b\u7684\u9075\u5faa\u7a0b\u5ea6\u548c\u4e0e\u8bb0\u5f55\u6570\u636e\u7684\u5339\u914d\u5ea6\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u666e\u901a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5f97\u5230\u7684\u5730\u4e0b\u901f\u5ea6\u66f4\u6e05\u6670\u51c6\u786e\u3002", "conclusion": "\u6b64\u8fdb\u5c55\u662fFWI\u5b9e\u65f6\u5730\u4e0b\u76d1\u6d4b\u5b9e\u9645\u5e94\u7528\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2509.09183", "pdf": "https://arxiv.org/pdf/2509.09183", "abs": "https://arxiv.org/abs/2509.09183", "authors": ["Jiasheng Guo", "Xin Gao", "Yuxiang Yan", "Guanghao Li", "Jian Pu"], "title": "Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 6 figures, conference", "summary": "Low-light Object detection is crucial for many real-world applications but\nremains challenging due to degraded image quality. While recent studies have\nshown that RAW images offer superior potential over RGB images, existing\napproaches either use RAW-RGB images with information loss or employ complex\nframeworks. To address these, we propose a lightweight and self-adaptive Image\nSignal Processing (ISP) plugin, Dark-ISP, which directly processes Bayer RAW\nimages in dark environments, enabling seamless end-to-end training for object\ndetection. Our key innovations are: (1) We deconstruct conventional ISP\npipelines into sequential linear (sensor calibration) and nonlinear (tone\nmapping) sub-modules, recasting them as differentiable components optimized\nthrough task-driven losses. Each module is equipped with content-aware\nadaptability and physics-informed priors, enabling automatic RAW-to-RGB\nconversion aligned with detection objectives. (2) By exploiting the ISP\npipeline's intrinsic cascade structure, we devise a Self-Boost mechanism that\nfacilitates cooperation between sub-modules. Through extensive experiments on\nthree RAW image datasets, we demonstrate that our method outperforms\nstate-of-the-art RGB- and RAW-based detection approaches, achieving superior\nresults with minimal parameters in challenging low-light environments.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u81ea\u9002\u5e94ISP\u63d2\u4ef6Dark - ISP\u5904\u7406\u4f4e\u5149\u73af\u5883\u4e0b\u7684Bayer RAW\u56fe\u50cf\u7528\u4e8e\u76ee\u6807\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u4f4e\u5149\u73af\u5883\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f4e\u5149\u76ee\u6807\u68c0\u6d4b\u56e0\u56fe\u50cf\u8d28\u91cf\u4e0b\u964d\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709RAW\u56fe\u50cf\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4fe1\u606f\u635f\u5931\u6216\u6846\u67b6\u590d\u6742\u7684\u95ee\u9898\u3002", "method": "\u5c06\u4f20\u7edfISP\u7ba1\u9053\u89e3\u6784\u4e3a\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u5b50\u6a21\u5757\uff0c\u4f5c\u4e3a\u53ef\u5fae\u7ec4\u4ef6\u901a\u8fc7\u4efb\u52a1\u9a71\u52a8\u635f\u5931\u4f18\u5316\uff0c\u5404\u6a21\u5757\u6709\u5185\u5bb9\u611f\u77e5\u9002\u5e94\u6027\u548c\u7269\u7406\u5148\u9a8c\uff1b\u8bbe\u8ba1Self - Boost\u673a\u5236\u4fc3\u8fdb\u5b50\u6a21\u5757\u5408\u4f5c\u3002", "result": "\u5728\u4e09\u4e2aRAW\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4f4e\u5149\u73af\u5883\u4e0b\u4ee5\u6700\u5c11\u53c2\u6570\u4f18\u4e8e\u57fa\u4e8eRGB\u548cRAW\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684Dark - ISP\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u4f4e\u5149\u73af\u5883\u4e0b\u7684\u76ee\u6807\u68c0\u6d4b\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u8d8a\u4e14\u53c2\u6570\u5c11\u3002"}}
{"id": "2509.09033", "pdf": "https://arxiv.org/pdf/2509.09033", "abs": "https://arxiv.org/abs/2509.09033", "authors": ["Hsin-Yuan Huang", "Michael Broughton", "Norhan Eassa", "Hartmut Neven", "Ryan Babbush", "Jarrod R. McClean"], "title": "Generative quantum advantage for classical and quantum problems", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Recent breakthroughs in generative machine learning, powered by massive\ncomputational resources, have demonstrated unprecedented human-like\ncapabilities. While beyond-classical quantum experiments can generate samples\nfrom classically intractable distributions, their complexity has thwarted all\nefforts toward efficient learning. This challenge has hindered demonstrations\nof generative quantum advantage: the ability of quantum computers to learn and\ngenerate desired outputs substantially better than classical computers. We\nresolve this challenge by introducing families of generative quantum models\nthat are hard to simulate classically, are efficiently trainable, exhibit no\nbarren plateaus or proliferating local minima, and can learn to generate\ndistributions beyond the reach of classical computers. Using a $68$-qubit\nsuperconducting quantum processor, we demonstrate these capabilities in two\nscenarios: learning classically intractable probability distributions and\nlearning quantum circuits for accelerated physical simulation. Our results\nestablish that both learning and sampling can be performed efficiently in the\nbeyond-classical regime, opening new possibilities for quantum-enhanced\ngenerative models with provable advantage.", "AI": {"tldr": "\u5f15\u5165\u53ef\u9ad8\u6548\u8bad\u7ec3\u3001\u96be\u7ecf\u5178\u6a21\u62df\u7684\u751f\u6210\u5f0f\u91cf\u5b50\u6a21\u578b\uff0c\u752868\u6bd4\u7279\u8d85\u5bfc\u91cf\u5b50\u5904\u7406\u5668\u5728\u4e24\u573a\u666f\u9a8c\u8bc1\uff0c\u8bc1\u5b9e\u8d85\u8d8a\u7ecf\u5178\u4f53\u5236\u4e0b\u5b66\u4e60\u548c\u91c7\u6837\u53ef\u9ad8\u6548\u8fdb\u884c\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u5f0f\u91cf\u5b50\u4f18\u52bf\u6f14\u793a\u4e2d\u56e0\u91cf\u5b50\u5b9e\u9a8c\u590d\u6742\u6027\u5bfc\u81f4\u9ad8\u6548\u5b66\u4e60\u56f0\u96be\u7684\u6311\u6218\u3002", "method": "\u5f15\u5165\u96be\u7ecf\u5178\u6a21\u62df\u3001\u53ef\u9ad8\u6548\u8bad\u7ec3\u3001\u65e0\u8d2b\u7620\u9ad8\u539f\u548c\u5927\u91cf\u5c40\u90e8\u6781\u5c0f\u503c\u7684\u751f\u6210\u5f0f\u91cf\u5b50\u6a21\u578b\u3002", "result": "\u4f7f\u752868\u6bd4\u7279\u8d85\u5bfc\u91cf\u5b50\u5904\u7406\u5668\u5728\u5b66\u4e60\u7ecf\u5178\u96be\u89e3\u6982\u7387\u5206\u5e03\u548c\u5b66\u4e60\u91cf\u5b50\u7535\u8def\u52a0\u901f\u7269\u7406\u6a21\u62df\u4e24\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u6a21\u578b\u80fd\u529b\u3002", "conclusion": "\u5728\u8d85\u8d8a\u7ecf\u5178\u4f53\u5236\u4e0b\u5b66\u4e60\u548c\u91c7\u6837\u53ef\u9ad8\u6548\u8fdb\u884c\uff0c\u4e3a\u6709\u53ef\u8bc1\u660e\u4f18\u52bf\u7684\u91cf\u5b50\u589e\u5f3a\u751f\u6210\u6a21\u578b\u5f00\u8f9f\u65b0\u53ef\u80fd\u3002"}}
{"id": "2509.09196", "pdf": "https://arxiv.org/pdf/2509.09196", "abs": "https://arxiv.org/abs/2509.09196", "authors": ["Chin Yuen Kwok", "Jia Qi yip"], "title": "Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition", "categories": ["cs.CL", "cs.AI"], "comment": "Published in Interspeech 2025", "summary": "Contextual biasing improves rare word recognition of ASR models by\nprioritizing the output of rare words during decoding. A common approach is\nTrie-based biasing, which gives \"bonus scores\" to partial hypothesis (e.g.\n\"Bon\") that may lead to the generation of the rare word (e.g. \"Bonham\"). If the\nfull word (\"Bonham\") isn't ultimately recognized, the system revokes those\nearlier bonuses. This revocation is limited to beam search and is\ncomputationally expensive, particularly for models with large decoders. To\novercome these limitations, we propose adapting ASR models to look ahead and\npredict multiple steps at once. This avoids the revocation step entirely by\nbetter estimating whether a partial hypothesis will lead to the generation of\nthe full rare word. By fine-tuning Whisper with only 10 hours of synthetic\ndata, our method reduces the word error rate on the NSC Part 2 test set from\n30.86% to 12.19%.", "AI": {"tldr": "\u63d0\u51fa\u8ba9ASR\u6a21\u578b\u63d0\u524d\u9884\u6d4b\u591a\u6b65\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u64a4\u9500\u6b65\u9aa4\uff0c\u752810\u5c0f\u65f6\u5408\u6210\u6570\u636e\u5fae\u8c03Whisper\uff0c\u964d\u4f4eNSC Part 2\u6d4b\u8bd5\u96c6\u7684\u8bcd\u9519\u8bef\u7387\u3002", "motivation": "\u73b0\u6709Trie-based biasing\u65b9\u6cd5\u7684\u64a4\u9500\u6b65\u9aa4\u5c40\u9650\u4e8e\u6ce2\u675f\u641c\u7d22\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5c24\u5176\u662f\u5bf9\u5927\u89e3\u7801\u5668\u6a21\u578b\u3002", "method": "\u8ba9ASR\u6a21\u578b\u63d0\u524d\u9884\u6d4b\u591a\u6b65\uff0c\u901a\u8fc7\u66f4\u597d\u4f30\u8ba1\u90e8\u5206\u5047\u8bbe\u662f\u5426\u4f1a\u751f\u6210\u5b8c\u6574\u7a00\u6709\u8bcd\u6765\u907f\u514d\u64a4\u9500\u6b65\u9aa4\uff0c\u752810\u5c0f\u65f6\u5408\u6210\u6570\u636e\u5fae\u8c03Whisper\u3002", "result": "\u5c06NSC Part 2\u6d4b\u8bd5\u96c6\u7684\u8bcd\u9519\u8bef\u7387\u4ece30.86%\u964d\u81f312.19%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u964d\u4f4eASR\u6a21\u578b\u5728\u7a00\u6709\u8bcd\u8bc6\u522b\u4e0a\u7684\u8bcd\u9519\u8bef\u7387\u3002"}}
{"id": "2509.09045", "pdf": "https://arxiv.org/pdf/2509.09045", "abs": "https://arxiv.org/abs/2509.09045", "authors": ["Shrabani Ghosh", "Erik Saule"], "title": "The Role of Community Detection Methods in Performance Variations of Graph Mining Tasks", "categories": ["cs.SI", "cs.LG"], "comment": null, "summary": "In real-world scenarios, large graphs represent relationships among entities\nin complex systems. Mining these large graphs often containing millions of\nnodes and edges helps uncover structural patterns and meaningful insights.\nDividing a large graph into smaller subgraphs facilitates complex system\nanalysis by revealing local information. Community detection extracts clusters\nor communities of graphs based on statistical methods and machine learning\nmodels using various optimization techniques. Structure based community\ndetection methods are more suitable for applying to graphs because they do not\nrely heavily on rich node or edge attribute information. The features derived\nfrom these communities can improve downstream graph mining tasks, such as link\nprediction and node classification. In real-world applications, we often lack\nground truth community information. Additionally, there is neither a\nuniversally accepted gold standard for community detection nor a single method\nthat is consistently optimal across diverse applications. In many cases, it is\nunclear how practitioners select community detection methods, and choices are\noften made without explicitly considering their potential impact on downstream\ntasks. In this study, we investigate whether the choice of community detection\nalgorithm significantly influences the performance of downstream applications.\nWe propose a framework capable of integrating various community detection\nmethods to systematically evaluate their effects on downstream task outcomes.\nOur comparative analysis reveals that specific community detection algorithms\nyield superior results in certain applications, highlighting that method\nselection substantially affects performance.", "AI": {"tldr": "\u7814\u7a76\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u9009\u62e9\u5bf9\u4e0b\u6e38\u5e94\u7528\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u7b97\u6cd5\u9009\u62e9\u663e\u8457\u5f71\u54cd\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7f3a\u4e4f\u793e\u533a\u771f\u5b9e\u4fe1\u606f\u3001\u65e0\u901a\u7528\u6807\u51c6\u3001\u4ece\u4e1a\u8005\u96be\u9009\u7b97\u6cd5\u4e14\u672a\u8003\u8651\u5bf9\u4e0b\u6e38\u4efb\u52a1\u5f71\u54cd\uff0c\u9700\u7814\u7a76\u7b97\u6cd5\u9009\u62e9\u5bf9\u4e0b\u6e38\u5e94\u7528\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u80fd\u96c6\u6210\u591a\u79cd\u793e\u533a\u68c0\u6d4b\u65b9\u6cd5\u7684\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5176\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u5bf9\u6bd4\u5206\u6790\u663e\u793a\u7279\u5b9a\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u5728\u67d0\u4e9b\u5e94\u7528\u4e2d\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u793e\u533a\u68c0\u6d4b\u7b97\u6cd5\u7684\u9009\u62e9\u4f1a\u663e\u8457\u5f71\u54cd\u4e0b\u6e38\u5e94\u7528\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09197", "pdf": "https://arxiv.org/pdf/2509.09197", "abs": "https://arxiv.org/abs/2509.09197", "authors": ["Chin Yuen Kwok", "Jia Qi Yip", "Eng Siong Chng"], "title": "Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function", "categories": ["cs.CL", "cs.AI"], "comment": "Published in Interspeech 2025", "summary": "Rare word recognition can be improved by adapting ASR models to synthetic\ndata that includes these words. Further improvements can be achieved through\ncontextual biasing, which trains and adds a biasing module into the model\narchitecture to prioritize rare words. While training the module on synthetic\nrare word data is more effective than using non-rare-word data, it can lead to\noverfitting due to artifacts in the synthetic audio. To address this, we\nenhance the TCPGen-based contextual biasing approach and propose a\nkeyword-aware loss function that additionally focuses on biased words when\ntraining biasing modules. This loss includes a masked cross-entropy term for\nbiased word prediction and a binary classification term for detecting biased\nword positions. These two terms complementarily support the decoding of biased\nwords during inference. By adapting Whisper to 10 hours of synthetic data, our\nmethod reduced the word error rate on the NSC Part 2 test set from 29.71% to\n11.81%.", "AI": {"tldr": "\u63d0\u51fa\u6539\u8fdb\u7a00\u6709\u8bcd\u8bc6\u522b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u5f3aTCPGen\u65b9\u6cd5\u548c\u5173\u952e\u8bcd\u611f\u77e5\u635f\u5931\u51fd\u6570\uff0c\u964d\u4f4e\u4e86NSC Part 2\u6d4b\u8bd5\u96c6\u7684\u8bcd\u9519\u8bef\u7387\u3002", "motivation": "\u89e3\u51b3\u5408\u6210\u97f3\u9891\u4e2d\u56e0\u4eba\u5de5\u75d5\u8ff9\u5bfc\u81f4\u7684\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u63d0\u9ad8\u7a00\u6709\u8bcd\u8bc6\u522b\u6548\u679c\u3002", "method": "\u589e\u5f3aTCPGen\u7684\u4e0a\u4e0b\u6587\u504f\u7f6e\u65b9\u6cd5\uff0c\u63d0\u51fa\u5173\u952e\u8bcd\u611f\u77e5\u635f\u5931\u51fd\u6570\uff0c\u5305\u542b\u63a9\u7801\u4ea4\u53c9\u71b5\u9879\u548c\u4e8c\u5143\u5206\u7c7b\u9879\u3002", "result": "\u5c06Whisper\u6a21\u578b\u5728NSC Part 2\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8bcd\u9519\u8bef\u7387\u4ece29.71%\u964d\u81f311.81%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u7a00\u6709\u8bcd\u8bc6\u522b\u6027\u80fd\uff0c\u51cf\u5c11\u8bcd\u9519\u8bef\u7387\u3002"}}
{"id": "2509.09204", "pdf": "https://arxiv.org/pdf/2509.09204", "abs": "https://arxiv.org/abs/2509.09204", "authors": ["Chin Yuen Kwok", "Jia Qi Yip", "Zhen Qiu", "Chi Hung Chi", "Kwok Yan Lam"], "title": "Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems", "categories": ["cs.SD", "cs.AI", "cs.CL"], "comment": "Published in Interspeech 2025", "summary": "Audio deepfake detection (ADD) models are commonly evaluated using datasets\nthat combine multiple synthesizers, with performance reported as a single Equal\nError Rate (EER). However, this approach disproportionately weights\nsynthesizers with more samples, underrepresenting others and reducing the\noverall reliability of EER. Additionally, most ADD datasets lack diversity in\nbona fide speech, often featuring a single environment and speech style (e.g.,\nclean read speech), limiting their ability to simulate real-world conditions.\nTo address these challenges, we propose bona fide cross-testing, a novel\nevaluation framework that incorporates diverse bona fide datasets and\naggregates EERs for more balanced assessments. Our approach improves robustness\nand interpretability compared to traditional evaluation methods. We benchmark\nover 150 synthesizers across nine bona fide speech types and release a new\ndataset to facilitate further research at\nhttps://github.com/cyaaronk/audio_deepfake_eval.", "AI": {"tldr": "\u4f20\u7edf\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u8bc4\u4f30\u65b9\u6cd5\u6709\u7f3a\u9677\uff0c\u63d0\u51fa\u65b0\u8bc4\u4f30\u6846\u67b6\u6539\u5584\u8bc4\u4f30\u6548\u679c\u5e76\u53d1\u5e03\u65b0\u6570\u636e\u96c6\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u5408\u6210\u5668\u6837\u672c\u52a0\u6743\u4e0d\u5747\uff0c\u771f\u5b9e\u8bed\u97f3\u6570\u636e\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u5f71\u54cd\u8bc4\u4f30\u53ef\u9760\u6027\u548c\u6a21\u62df\u771f\u5b9e\u573a\u666f\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u771f\u5b9e\u4ea4\u53c9\u6d4b\u8bd5\u7684\u65b0\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u6837\u771f\u5b9e\u6570\u636e\u96c6\u5e76\u805a\u5408EER\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u65b0\u65b9\u6cd5\u6bd4\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5728\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u6709\u63d0\u5347\u3002", "conclusion": "\u65b0\u8bc4\u4f30\u6846\u67b6\u80fd\u66f4\u5e73\u8861\u5730\u8bc4\u4f30\uff0c\u8fd8\u53d1\u5e03\u65b0\u6570\u636e\u96c6\u63a8\u52a8\u7814\u7a76\u3002"}}
{"id": "2509.09107", "pdf": "https://arxiv.org/pdf/2509.09107", "abs": "https://arxiv.org/abs/2509.09107", "authors": ["Pritam Sen", "Yao Ma", "Cristian Borcea"], "title": "CryptGNN: Enabling Secure Inference for Graph Neural Networks", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We present CryptGNN, a secure and effective inference solution for\nthird-party graph neural network (GNN) models in the cloud, which are accessed\nby clients as ML as a service (MLaaS). The main novelty of CryptGNN is its\nsecure message passing and feature transformation layers using distributed\nsecure multi-party computation (SMPC) techniques. CryptGNN protects the\nclient's input data and graph structure from the cloud provider and the\nthird-party model owner, and it protects the model parameters from the cloud\nprovider and the clients. CryptGNN works with any number of SMPC parties, does\nnot require a trusted server, and is provably secure even if P-1 out of P\nparties in the cloud collude. Theoretical analysis and empirical experiments\ndemonstrate the security and efficiency of CryptGNN.", "AI": {"tldr": "\u63d0\u51faCryptGNN\uff0c\u4e00\u79cd\u7528\u4e8e\u4e91\u73af\u5883\u7b2c\u4e09\u65b9\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7684\u5b89\u5168\u6709\u6548\u63a8\u7406\u65b9\u6848\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4e3a\u4e91\u73af\u5883\u4e2d\u7b2c\u4e09\u65b9\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u63d0\u4f9b\u5b89\u5168\u6709\u6548\u7684\u63a8\u7406\u65b9\u6848\uff0c\u4fdd\u62a4\u5ba2\u6237\u8f93\u5165\u6570\u636e\u3001\u56fe\u7ed3\u6784\u548c\u6a21\u578b\u53c2\u6570\u3002", "method": "\u4f7f\u7528\u5206\u5e03\u5f0f\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\uff08SMPC\uff09\u6280\u672f\u5b9e\u73b0\u5b89\u5168\u6d88\u606f\u4f20\u9012\u548c\u7279\u5f81\u8f6c\u6362\u5c42\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86CryptGNN\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "conclusion": "CryptGNN\u662f\u4e00\u79cd\u5b89\u5168\u6709\u6548\u7684\u4e91\u73af\u5883\u7b2c\u4e09\u65b9\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u63a8\u7406\u65b9\u6848\u3002"}}
{"id": "2509.09235", "pdf": "https://arxiv.org/pdf/2509.09235", "abs": "https://arxiv.org/abs/2509.09235", "authors": ["Sarah C. Irvine", "Christian Lucas", "Diana Kr\u00fcger", "Bianca Guedert", "Julian Moosmann", "Berit Zeller-Plumhoff"], "title": "Virtual staining for 3D X-ray histology of bone implants", "categories": ["eess.IV", "cs.AI", "cs.CV", "physics.comp-ph", "q-bio.QM"], "comment": null, "summary": "Three-dimensional X-ray histology techniques offer a non-invasive alternative\nto conventional 2D histology, enabling volumetric imaging of biological tissues\nwithout the need for physical sectioning or chemical staining. However, the\ninherent greyscale image contrast of X-ray tomography limits its biochemical\nspecificity compared to traditional histological stains. Within digital\npathology, deep learning-based virtual staining has demonstrated utility in\nsimulating stained appearances from label-free optical images. In this study,\nwe extend virtual staining to the X-ray domain by applying cross-modality image\ntranslation to generate artificially stained slices from\nsynchrotron-radiation-based micro-CT scans. Using over 50 co-registered image\npairs of micro-CT and toluidine blue-stained histology from bone-implant\nsamples, we trained a modified CycleGAN network tailored for limited paired\ndata. Whole slide histology images were downsampled to match the voxel size of\nthe CT data, with on-the-fly data augmentation for patch-based training. The\nmodel incorporates pixelwise supervision and greyscale consistency terms,\nproducing histologically realistic colour outputs while preserving\nhigh-resolution structural detail. Our method outperformed Pix2Pix and standard\nCycleGAN baselines across SSIM, PSNR, and LPIPS metrics. Once trained, the\nmodel can be applied to full CT volumes to generate virtually stained 3D\ndatasets, enhancing interpretability without additional sample preparation.\nWhile features such as new bone formation were able to be reproduced, some\nvariability in the depiction of implant degradation layers highlights the need\nfor further training data and refinement. This work introduces virtual staining\nto 3D X-ray imaging and offers a scalable route for chemically informative,\nlabel-free tissue characterisation in biomedical research.", "AI": {"tldr": "\u672c\u6587\u5c06\u6df1\u5ea6\u5b66\u4e60\u865a\u62df\u67d3\u8272\u6269\u5c55\u5230X\u5c04\u7ebf\u9886\u57df\uff0c\u7528\u6539\u8fdb\u7684CycleGAN\u7f51\u7edc\u4ece\u540c\u6b65\u8f90\u5c04\u5faeCT\u626b\u63cf\u751f\u6210\u865a\u62df\u67d3\u8272\u5207\u7247\uff0c\u65b9\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u53ef\u751f\u62103D\u6570\u636e\u96c6\uff0c\u4f46\u4ecd\u9700\u66f4\u591a\u6570\u636e\u6539\u8fdb\u3002", "motivation": "\u4e09\u7ef4X\u5c04\u7ebf\u7ec4\u7ec7\u5b66\u6280\u672f\u7684\u7070\u5ea6\u56fe\u50cf\u5bf9\u6bd4\u5ea6\u9650\u5236\u4e86\u5176\u751f\u5316\u7279\u5f02\u6027\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u865a\u62df\u67d3\u8272\u5728\u6570\u5b57\u75c5\u7406\u5b66\u4e2d\u6709\u5e94\u7528\uff0c\u56e0\u6b64\u60f3\u5c06\u5176\u6269\u5c55\u5230X\u5c04\u7ebf\u9886\u57df\u3002", "method": "\u4f7f\u7528\u8d8550\u5bf9\u9aa8\u690d\u5165\u7269\u6837\u672c\u7684\u5faeCT\u548c\u7532\u82ef\u80fa\u84dd\u67d3\u8272\u7ec4\u7ec7\u5b66\u914d\u51c6\u56fe\u50cf\uff0c\u8bad\u7ec3\u6539\u8fdb\u7684CycleGAN\u7f51\u7edc\uff0c\u7ed3\u5408\u50cf\u7d20\u76d1\u7763\u548c\u7070\u5ea6\u4e00\u81f4\u6027\u9879\uff0c\u91c7\u7528\u5b9e\u65f6\u6570\u636e\u589e\u5f3a\u8fdb\u884c\u57fa\u4e8e\u8865\u4e01\u7684\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u5728SSIM\u3001PSNR\u548cLPIPS\u6307\u6807\u4e0a\u4f18\u4e8ePix2Pix\u548c\u6807\u51c6CycleGAN\u57fa\u7ebf\uff0c\u80fd\u751f\u6210\u865a\u62df\u67d3\u82723D\u6570\u636e\u96c6\uff0c\u4f46\u5728\u63cf\u7ed8\u690d\u5165\u7269\u964d\u89e3\u5c42\u65f6\u6709\u5dee\u5f02\u3002", "conclusion": "\u5c06\u865a\u62df\u67d3\u8272\u5f15\u51653D X\u5c04\u7ebf\u6210\u50cf\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u65e0\u6807\u8bb0\u7ec4\u7ec7\u8868\u5f81\u63d0\u4f9b\u53ef\u6269\u5c55\u9014\u5f84\u3002"}}
{"id": "2509.09242", "pdf": "https://arxiv.org/pdf/2509.09242", "abs": "https://arxiv.org/abs/2509.09242", "authors": ["Mustafa Yurdakul", "Sakir Tasdemir"], "title": "CoAtNeXt:An Attention-Enhanced ConvNeXtV2-Transformer Hybrid Model for Gastric Tissue Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Background and objective Early diagnosis of gastric diseases is crucial to\nprevent fatal outcomes. Although histopathologic examination remains the\ndiagnostic gold standard, it is performed entirely manually, making evaluations\nlabor-intensive and prone to variability among pathologists. Critical findings\nmay be missed, and lack of standard procedures reduces consistency. These\nlimitations highlight the need for automated, reliable, and efficient methods\nfor gastric tissue analysis. Methods In this study, a novel hybrid model named\nCoAtNeXt was proposed for the classification of gastric tissue images. The\nmodel is built upon the CoAtNet architecture by replacing its MBConv layers\nwith enhanced ConvNeXtV2 blocks. Additionally, the Convolutional Block\nAttention Module (CBAM) is integrated to improve local feature extraction\nthrough channel and spatial attention mechanisms. The architecture was scaled\nto achieve a balance between computational efficiency and classification\nperformance. CoAtNeXt was evaluated on two publicly available datasets,\nHMU-GC-HE-30K for eight-class classification and GasHisSDB for binary\nclassification, and was compared against 10 Convolutional Neural Networks\n(CNNs) and ten Vision Transformer (ViT) models. Results CoAtNeXt achieved\n96.47% accuracy, 96.60% precision, 96.47% recall, 96.45% F1 score, and 99.89%\nAUC on HMU-GC-HE-30K. On GasHisSDB, it reached 98.29% accuracy, 98.07%\nprecision, 98.41% recall, 98.23% F1 score, and 99.90% AUC. It outperformed all\nCNN and ViT models tested and surpassed previous studies in the literature.\nConclusion Experimental results show that CoAtNeXt is a robust architecture for\nhistopathological classification of gastric tissue images, providing\nperformance on binary and multiclass. Its highlights its potential to assist\npathologists by enhancing diagnostic accuracy and reducing workload.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u80c3\u7ec4\u7ec7\u56fe\u50cf\u5206\u7c7b\u7684CoAtNeXt\u6a21\u578b\uff0c\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u53ef\u8f85\u52a9\u75c5\u7406\u5b66\u5bb6\u8bca\u65ad\u3002", "motivation": "\u4f20\u7edf\u80c3\u75be\u75c5\u7ec4\u7ec7\u75c5\u7406\u68c0\u67e5\u5168\u624b\u52a8\uff0c\u52b3\u52a8\u5f3a\u5ea6\u5927\u3001\u6613\u6709\u5dee\u5f02\uff0c\u9700\u81ea\u52a8\u5316\u53ef\u9760\u9ad8\u6548\u7684\u80c3\u7ec4\u7ec7\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCoAtNeXt\u6a21\u578b\uff0c\u57fa\u4e8eCoAtNet\u67b6\u6784\uff0c\u7528\u589e\u5f3a\u7684ConvNeXtV2\u5757\u66ff\u6362MBConv\u5c42\uff0c\u96c6\u6210CBAM\u6a21\u5757\uff0c\u5bf9\u67b6\u6784\u8fdb\u884c\u7f29\u653e\uff1b\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5e76\u4e0e20\u4e2a\u6a21\u578b\u5bf9\u6bd4\u3002", "result": "CoAtNeXt\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5404\u9879\u6307\u6807\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u6240\u6709\u6d4b\u8bd5\u7684CNN\u548cViT\u6a21\u578b\u53ca\u4ee5\u5f80\u7814\u7a76\u3002", "conclusion": "CoAtNeXt\u662f\u7528\u4e8e\u80c3\u7ec4\u7ec7\u56fe\u50cf\u7ec4\u7ec7\u75c5\u7406\u5b66\u5206\u7c7b\u7684\u5f3a\u5927\u67b6\u6784\uff0c\u80fd\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u548c\u51cf\u8f7b\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2509.09262", "pdf": "https://arxiv.org/pdf/2509.09262", "abs": "https://arxiv.org/abs/2509.09262", "authors": ["Seung Gyu Jeong", "Seong Eun Kim"], "title": "Adaptive Knowledge Distillation using a Device-Aware Teacher for Low-Complexity Acoustic Scene Classification", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "In this technical report, we describe our submission for Task 1,\nLow-Complexity Device-Robust Acoustic Scene Classification, of the DCASE 2025\nChallenge. Our work tackles the dual challenges of strict complexity\nconstraints and robust generalization to both seen and unseen devices, while\nalso leveraging the new rule allowing the use of device labels at test time.\nOur proposed system is based on a knowledge distillation framework where an\nefficient CP-MobileNet student learns from a compact, specialized two-teacher\nensemble. This ensemble combines a baseline PaSST teacher, trained with\nstandard cross-entropy, and a 'generalization expert' teacher. This expert is\ntrained using our novel Device-Aware Feature Alignment (DAFA) loss, adapted\nfrom prior work, which explicitly structures the feature space for device\nrobustness. To capitalize on the availability of test-time device labels, the\ndistilled student model then undergoes a final device-specific fine-tuning\nstage. Our proposed system achieves a final accuracy of 57.93\\% on the\ndevelopment set, demonstrating a significant improvement over the official\nbaseline, particularly on unseen devices.", "AI": {"tldr": "\u63cf\u8ff0DCASE 2025\u6311\u6218\u8d5b\u4efb\u52a11\u7684\u63d0\u4ea4\u65b9\u6848\uff0c\u91c7\u7528\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\u7ed3\u5408\u8bbe\u5907\u611f\u77e5\u7279\u5f81\u5bf9\u9f50\u635f\u5931\uff0c\u7ecf\u8bbe\u5907\u7279\u5b9a\u5fae\u8c03\u540e\uff0c\u5728\u5f00\u53d1\u96c6\u4e0a\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u4e25\u683c\u590d\u6742\u5ea6\u7ea6\u675f\u548c\u5bf9\u53ef\u89c1\u53ca\u4e0d\u53ef\u89c1\u8bbe\u5907\u7684\u9c81\u68d2\u6cdb\u5316\u95ee\u9898\uff0c\u5229\u7528\u6d4b\u8bd5\u65f6\u53ef\u7528\u8bbe\u5907\u6807\u7b7e\u7684\u89c4\u5219\u3002", "method": "\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u9ad8\u6548CP - MobileNet\u5b66\u751f\u6a21\u578b\u5411\u53cc\u6559\u5e08\u96c6\u6210\u5b66\u4e60\uff0c\u4f7f\u7528\u8bbe\u5907\u611f\u77e5\u7279\u5f81\u5bf9\u9f50\u635f\u5931\u8bad\u7ec3'\u6cdb\u5316\u4e13\u5bb6'\u6559\u5e08\uff0c\u84b8\u998f\u540e\u7684\u5b66\u751f\u6a21\u578b\u8fdb\u884c\u8bbe\u5907\u7279\u5b9a\u5fae\u8c03\u3002", "result": "\u5728\u5f00\u53d1\u96c6\u4e0a\u6700\u7ec8\u51c6\u786e\u7387\u8fbe57.93%\uff0c\u8f83\u5b98\u65b9\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u4e0d\u53ef\u89c1\u8bbe\u5907\u4e0a\u3002", "conclusion": "\u6240\u63d0\u7cfb\u7edf\u80fd\u6709\u6548\u5e94\u5bf9\u6311\u6218\u8d5b\u4efb\u52a1\u7684\u590d\u6742\u5ea6\u548c\u8bbe\u5907\u9c81\u68d2\u6027\u6311\u6218\uff0c\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u3002"}}
{"id": "2509.09290", "pdf": "https://arxiv.org/pdf/2509.09290", "abs": "https://arxiv.org/abs/2509.09290", "authors": ["Anthony P. Addison", "Felix Wagner", "Wentian Xu", "Natalie Voets", "Konstantinos Kamnitsas"], "title": "Modality-Agnostic Input Channels Enable Segmentation of Brain lesions in Multimodal MRI with Sequences Unavailable During Training", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted to MICCAI 2025, for the following workshop: ML-CDS 2025:\n  Multimodal Learning and Fusion Across Scales for Clinical Decision Support", "summary": "Segmentation models are important tools for the detection and analysis of\nlesions in brain MRI. Depending on the type of brain pathology that is imaged,\nMRI scanners can acquire multiple, different image modalities (contrasts). Most\nsegmentation models for multimodal brain MRI are restricted to fixed modalities\nand cannot effectively process new ones at inference. Some models generalize to\nunseen modalities but may lose discriminative modality-specific information.\nThis work aims to develop a model that can perform inference on data that\ncontain image modalities unseen during training, previously seen modalities,\nand heterogeneous combinations of both, thus allowing a user to utilize any\navailable imaging modalities. We demonstrate this is possible with a simple,\nthus practical alteration to the U-net architecture, by integrating a\nmodality-agnostic input channel or pathway, alongside modality-specific input\nchannels. To train this modality-agnostic component, we develop an image\naugmentation scheme that synthesizes artificial MRI modalities. Augmentations\ndifferentially alter the appearance of pathological and healthy brain tissue to\ncreate artificial contrasts between them while maintaining realistic anatomical\nintegrity. We evaluate the method using 8 MRI databases that include 5 types of\npathologies (stroke, tumours, traumatic brain injury, multiple sclerosis and\nwhite matter hyperintensities) and 8 modalities (T1, T1+contrast, T2, PD, SWI,\nDWI, ADC and FLAIR). The results demonstrate that the approach preserves the\nability to effectively process MRI modalities encountered during training,\nwhile being able to process new, unseen modalities to improve its segmentation.\nProject code: https://github.com/Anthony-P-Addison/AGN-MOD-SEG", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6539\u8fdbU-net\u67b6\u6784\uff0c\u7ed3\u5408\u6a21\u6001\u65e0\u5173\u4e0e\u7279\u5b9a\u901a\u9053\uff0c\u7528\u56fe\u50cf\u589e\u5f3a\u65b9\u6848\u8bad\u7ec3\uff0c\u80fd\u5904\u7406\u8bad\u7ec3\u65f6\u672a\u89c1\u6a21\u6001\uff0c\u5728\u591a\u6570\u636e\u5e93\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u591a\u6570\u591a\u6a21\u6001\u8111MRI\u5206\u5272\u6a21\u578b\u53ea\u80fd\u5904\u7406\u56fa\u5b9a\u6a21\u6001\uff0c\u90e8\u5206\u6a21\u578b\u6cdb\u5316\u65f6\u4e22\u5931\u7279\u5b9a\u4fe1\u606f\uff0c\u9700\u5f00\u53d1\u80fd\u5904\u7406\u8bad\u7ec3\u65f6\u672a\u89c1\u6a21\u6001\u7684\u6a21\u578b\u3002", "method": "\u6539\u8fdbU-net\u67b6\u6784\uff0c\u96c6\u6210\u6a21\u6001\u65e0\u5173\u8f93\u5165\u901a\u9053\u548c\u6a21\u6001\u7279\u5b9a\u8f93\u5165\u901a\u9053\uff1b\u5f00\u53d1\u56fe\u50cf\u589e\u5f3a\u65b9\u6848\u5408\u6210\u4eba\u5de5MRI\u6a21\u6001\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u8bad\u7ec3\u65f6\u9047\u5230\u7684MRI\u6a21\u6001\uff0c\u4e5f\u80fd\u5904\u7406\u65b0\u7684\u672a\u89c1\u6a21\u6001\u4ee5\u6539\u8fdb\u5206\u5272\u3002", "conclusion": "\u901a\u8fc7\u7b80\u5355\u5b9e\u7528\u7684U-net\u67b6\u6784\u6539\u52a8\u548c\u56fe\u50cf\u589e\u5f3a\u65b9\u6848\uff0c\u53ef\u5b9e\u73b0\u5bf9\u8bad\u7ec3\u65f6\u672a\u89c1\u6a21\u6001\u6570\u636e\u7684\u63a8\u7406\u3002"}}
{"id": "2509.09297", "pdf": "https://arxiv.org/pdf/2509.09297", "abs": "https://arxiv.org/abs/2509.09297", "authors": ["Spyridon Loukovitis", "Anastasios Arsenos", "Vasileios Karampinis", "Athanasios Voulodimos"], "title": "Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Open-set detection is crucial for robust UAV autonomy in air-to-air object\ndetection under real-world conditions. Traditional closed-set detectors degrade\nsignificantly under domain shifts and flight data corruption, posing risks to\nsafety-critical applications. We propose a novel, model-agnostic open-set\ndetection framework designed specifically for embedding-based detectors. The\nmethod explicitly handles unknown object rejection while maintaining robustness\nagainst corrupted flight data. It estimates semantic uncertainty via entropy\nmodeling in the embedding space and incorporates spectral normalization and\ntemperature scaling to enhance open-set discrimination. We validate our\napproach on the challenging AOT aerial benchmark and through extensive\nreal-world flight tests. Comprehensive ablation studies demonstrate consistent\nimprovements over baseline methods, achieving up to a 10\\% relative AUROC gain\ncompared to standard YOLO-based detectors. Additionally, we show that\nbackground rejection further strengthens robustness without compromising\ndetection accuracy, making our solution particularly well-suited for reliable\nUAV perception in dynamic air-to-air environments.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u57fa\u4e8e\u5d4c\u5165\u7684\u63a2\u6d4b\u5668\u7684\u6a21\u578b\u65e0\u5173\u7684\u5f00\u653e\u96c6\u68c0\u6d4b\u6846\u67b6\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u98de\u884c\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u6539\u8fdb\uff0c\u9002\u5408\u65e0\u4eba\u673a\u611f\u77e5\u3002", "motivation": "\u4f20\u7edf\u95ed\u96c6\u63a2\u6d4b\u5668\u5728\u9886\u57df\u504f\u79fb\u548c\u98de\u884c\u6570\u636e\u635f\u574f\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u5bf9\u5b89\u5168\u5173\u952e\u5e94\u7528\u6709\u98ce\u9669\uff0c\u9700\u8981\u53ef\u9760\u7684\u5f00\u653e\u96c6\u68c0\u6d4b\u65b9\u6cd5\u7528\u4e8e\u65e0\u4eba\u673a\u81ea\u4e3b\u7a7a\u4e2d\u76ee\u6807\u68c0\u6d4b\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684\u5f00\u653e\u96c6\u68c0\u6d4b\u6846\u67b6\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u901a\u8fc7\u71b5\u5efa\u6a21\u4f30\u8ba1\u8bed\u4e49\u4e0d\u786e\u5b9a\u6027\uff0c\u7ed3\u5408\u8c31\u5f52\u4e00\u5316\u548c\u6e29\u5ea6\u7f29\u653e\u589e\u5f3a\u5f00\u653e\u96c6\u8fa8\u522b\u80fd\u529b\u3002", "result": "\u5728AOT\u7a7a\u4e2d\u57fa\u51c6\u548c\u5927\u91cf\u5b9e\u9645\u98de\u884c\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\uff0c\u6d88\u878d\u7814\u7a76\u663e\u793a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u76f8\u5bf9AUROC\u589e\u76ca\u8fbe10%\uff0c\u80cc\u666f\u5254\u9664\u589e\u5f3a\u9c81\u68d2\u6027\u4e14\u4e0d\u5f71\u54cd\u68c0\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u89e3\u51b3\u65b9\u6848\u9002\u7528\u4e8e\u52a8\u6001\u7a7a\u5bf9\u7a7a\u73af\u5883\u4e2d\u53ef\u9760\u7684\u65e0\u4eba\u673a\u611f\u77e5\u3002"}}
{"id": "2509.09307", "pdf": "https://arxiv.org/pdf/2509.09307", "abs": "https://arxiv.org/abs/2509.09307", "authors": ["Zhengzhao Lai", "Youbin Zheng", "Zhenyang Cai", "Haonan Lyu", "Jinpu Yang", "Hongqing Liang", "Yan Hu", "Benyou Wang"], "title": "Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": null, "summary": "Materials characterization is fundamental to acquiring materials information,\nrevealing the processing-microstructure-property relationships that guide\nmaterial design and optimization. While multimodal large language models\n(MLLMs) have recently shown promise in generative and predictive tasks within\nmaterials science, their capacity to understand real-world characterization\nimaging data remains underexplored. To bridge this gap, we present MatCha, the\nfirst benchmark for materials characterization image understanding, comprising\n1,500 questions that demand expert-level domain expertise. MatCha encompasses\nfour key stages of materials research comprising 21 distinct tasks, each\ndesigned to reflect authentic challenges faced by materials scientists. Our\nevaluation of state-of-the-art MLLMs on MatCha reveals a significant\nperformance gap compared to human experts. These models exhibit degradation\nwhen addressing questions requiring higher-level expertise and sophisticated\nvisual perception. Simple few-shot and chain-of-thought prompting struggle to\nalleviate these limitations. These findings highlight that existing MLLMs still\nexhibit limited adaptability to real-world materials characterization\nscenarios. We hope MatCha will facilitate future research in areas such as new\nmaterial discovery and autonomous scientific agents. MatCha is available at\nhttps://github.com/FreedomIntelligence/MatCha.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u6750\u6599\u8868\u5f81\u56fe\u50cf\u7406\u89e3\u57fa\u51c6MatCha\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709MLLMs\u5728\u8be5\u57fa\u51c6\u4e0a\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u6709\u5dee\u8ddd\uff0c\u9002\u5e94\u73b0\u5b9e\u573a\u666f\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u6750\u6599\u8868\u5f81\u6210\u50cf\u6570\u636e\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u521b\u5efa\u5305\u542b1500\u4e2a\u9700\u8981\u4e13\u5bb6\u7ea7\u9886\u57df\u77e5\u8bc6\u95ee\u9898\u7684MatCha\u57fa\u51c6\uff0c\u6db5\u76d6\u6750\u6599\u7814\u7a76\u56db\u4e2a\u5173\u952e\u9636\u6bb521\u4e2a\u4e0d\u540c\u4efb\u52a1\u3002", "result": "\u5bf9\u6700\u5148\u8fdbMLLMs\u5728MatCha\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u5904\u7406\u9ad8\u96be\u5ea6\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u7b80\u5355\u63d0\u793a\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u3002", "conclusion": "\u73b0\u6709MLLMs\u5bf9\u73b0\u5b9e\u4e16\u754c\u6750\u6599\u8868\u5f81\u573a\u666f\u9002\u5e94\u6027\u6709\u9650\uff0c\u5e0c\u671bMatCha\u80fd\u63a8\u52a8\u65b0\u6750\u6599\u53d1\u73b0\u7b49\u9886\u57df\u7814\u7a76\u3002"}}
{"id": "2509.09327", "pdf": "https://arxiv.org/pdf/2509.09327", "abs": "https://arxiv.org/abs/2509.09327", "authors": ["Dimitrios Anastasiou", "Razvan Caramalau", "Nazir Sirajudeen", "Matthew Boal", "Philip Edwards", "Justin Collins", "John Kelly", "Ashwin Sridhar", "Maxine Tran", "Faiz Mumtaz", "Nevil Pavithran", "Nader Francis", "Danail Stoyanov", "Evangelos B. Mazomenos"], "title": "Exploring Pre-training Across Domains for Few-Shot Surgical Skill Assessment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MICCAI 2025 DEMI Workshop", "summary": "Automated surgical skill assessment (SSA) is a central task in surgical\ncomputer vision. Developing robust SSA models is challenging due to the\nscarcity of skill annotations, which are time-consuming to produce and require\nexpert consensus. Few-shot learning (FSL) offers a scalable alternative\nenabling model development with minimal supervision, though its success\ncritically depends on effective pre-training. While widely studied for several\nsurgical downstream tasks, pre-training has remained largely unexplored in SSA.\nIn this work, we formulate SSA as a few-shot task and investigate how\nself-supervised pre-training strategies affect downstream few-shot SSA\nperformance. We annotate a publicly available robotic surgery dataset with\nObjective Structured Assessment of Technical Skill (OSATS) scores, and evaluate\nvarious pre-training sources across three few-shot settings. We quantify domain\nsimilarity and analyze how domain gap and the inclusion of procedure-specific\ndata into pre-training influence transferability. Our results show that small\nbut domain-relevant datasets can outperform large scale, less aligned ones,\nachieving accuracies of 60.16%, 66.03%, and 73.65% in the 1-, 2-, and 5-shot\nsettings, respectively. Moreover, incorporating procedure-specific data into\npre-training with a domain-relevant external dataset significantly boosts\ndownstream performance, with an average gain of +1.22% in accuracy and +2.28%\nin F1-score; however, applying the same strategy with less similar but\nlarge-scale sources can instead lead to performance degradation. Code and\nmodels are available at https://github.com/anastadimi/ssa-fsl.", "AI": {"tldr": "\u672c\u6587\u5c06\u81ea\u52a8\u624b\u672f\u6280\u80fd\u8bc4\u4f30\uff08SSA\uff09\u4f5c\u4e3a\u5c11\u6837\u672c\u4efb\u52a1\uff0c\u7814\u7a76\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7b56\u7565\u5bf9\u4e0b\u6e38\u5c11\u6837\u672cSSA\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5c0f\u800c\u76f8\u5173\u7684\u6570\u636e\u96c6\u8868\u73b0\u66f4\u597d\uff0c\u7279\u5b9a\u7a0b\u5e8f\u6570\u636e\u7684\u52a0\u5165\u5bf9\u6027\u80fd\u6709\u4e0d\u540c\u5f71\u54cd\u3002", "motivation": "\u7531\u4e8e\u6280\u80fd\u6807\u6ce8\u7a00\u7f3a\uff0c\u5f00\u53d1\u5f3a\u5927\u7684SSA\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\uff0c\u5c11\u6837\u672c\u5b66\u4e60\uff08FSL\uff09\u9700\u6709\u6548\u9884\u8bad\u7ec3\uff0c\u800cSSA\u4e2d\u9884\u8bad\u7ec3\u7814\u7a76\u8f83\u5c11\uff0c\u56e0\u6b64\u7814\u7a76\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7b56\u7565\u5bf9\u4e0b\u6e38\u5c11\u6837\u672cSSA\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5c06SSA\u8868\u8ff0\u4e3a\u5c11\u6837\u672c\u4efb\u52a1\uff0c\u7528OSATS\u5206\u6570\u6807\u6ce8\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5728\u4e09\u79cd\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u5404\u79cd\u9884\u8bad\u7ec3\u6e90\uff0c\u91cf\u5316\u9886\u57df\u76f8\u4f3c\u6027\u5e76\u5206\u6790\u9886\u57df\u5dee\u8ddd\u548c\u7279\u5b9a\u7a0b\u5e8f\u6570\u636e\u7684\u5f71\u54cd\u3002", "result": "\u5c0f\u800c\u9886\u57df\u76f8\u5173\u7684\u6570\u636e\u96c6\u8868\u73b0\u4f18\u4e8e\u5927\u89c4\u6a21\u4f46\u4e0d\u592a\u5339\u914d\u7684\u6570\u636e\u96c6\uff0c\u57281\u30012\u548c5\u6837\u672c\u8bbe\u7f6e\u4e0b\u51c6\u786e\u7387\u5206\u522b\u8fbe60.16%\u300166.03%\u548c73.65%\uff1b\u52a0\u5165\u7279\u5b9a\u7a0b\u5e8f\u6570\u636e\uff0c\u5728\u76f8\u5173\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u6027\u80fd\uff0c\u5728\u4e0d\u592a\u76f8\u4f3c\u7684\u5927\u89c4\u6a21\u6e90\u4e0a\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u5c0f\u800c\u9886\u57df\u76f8\u5173\u7684\u6570\u636e\u96c6\u66f4\u9002\u5408\u5c11\u6837\u672cSSA\uff0c\u52a0\u5165\u7279\u5b9a\u7a0b\u5e8f\u6570\u636e\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u53d6\u51b3\u4e8e\u9884\u8bad\u7ec3\u6e90\u7684\u9886\u57df\u76f8\u4f3c\u6027\u3002"}}
{"id": "2509.09332", "pdf": "https://arxiv.org/pdf/2509.09332", "abs": "https://arxiv.org/abs/2509.09332", "authors": ["Yuecheng Liu", "Dafeng Chi", "Shiguang Wu", "Zhanguang Zhang", "Yuzheng Zhuang", "Bowen Yang", "He Zhu", "Lingfeng Zhang", "Pengwei Xie", "David Gamaliel Arcos Bravo", "Yingxue Zhang", "Jianye Hao", "Xingyue Quan"], "title": "OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Recent advances in multimodal large language models (MLLMs) have opened new\nopportunities for embodied intelligence, enabling multimodal understanding,\nreasoning, and interaction, as well as continuous spatial decision-making.\nNevertheless, current MLLM-based embodied systems face two critical\nlimitations. First, Geometric Adaptability Gap: models trained solely on 2D\ninputs or with hard-coded 3D geometry injection suffer from either insufficient\nspatial information or restricted 2D generalization, leading to poor\nadaptability across tasks with diverse spatial demands. Second, Embodiment\nConstraint Gap: prior work often neglects the physical constraints and\ncapacities of real robots, resulting in task plans that are theoretically valid\nbut practically infeasible.To address these gaps, we introduce OmniEVA -- an\nembodied versatile planner that enables advanced embodied reasoning and task\nplanning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding\nmechanism, which introduces a gated router to perform explicit selective\nregulation of 3D fusion based on contextual requirements, enabling\ncontext-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware\nReasoning framework that jointly incorporates task goals and embodiment\nconstraints into the reasoning loop, resulting in planning decisions that are\nboth goal-directed and executable. Extensive experimental results demonstrate\nthat OmniEVA not only achieves state-of-the-art general embodied reasoning\nperformance, but also exhibits a strong ability across a wide range of\ndownstream scenarios. Evaluations of a suite of proposed embodied benchmarks,\nincluding both primitive and composite tasks, confirm its robust and versatile\nplanning capabilities. Project page: https://omnieva.github.io", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u667a\u80fd\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u53ca\u9762\u4e34\u7684\u95ee\u9898\uff0c\u63d0\u51faOmniEVA\u89c4\u5212\u5668\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u548c\u89c4\u5212\u80fd\u529b\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eMLLM\u7684\u5177\u8eab\u7cfb\u7edf\u5b58\u5728\u51e0\u4f55\u9002\u5e94\u6027\u5dee\u8ddd\u548c\u5177\u8eab\u7ea6\u675f\u5dee\u8ddd\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u4ee5\u63d0\u5347\u5177\u8eab\u63a8\u7406\u548c\u4efb\u52a1\u89c4\u5212\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4efb\u52a1\u81ea\u9002\u5e943D\u63a5\u5730\u673a\u5236\u548c\u5177\u8eab\u611f\u77e5\u63a8\u7406\u6846\u67b6\u3002", "result": "OmniEVA\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u5177\u8eab\u63a8\u7406\u6027\u80fd\uff0c\u5728\u4e0b\u6e38\u573a\u666f\u8868\u73b0\u51fa\u8272\uff0c\u5728\u5177\u8eab\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u5f3a\u5927\u4e14\u901a\u7528\u7684\u89c4\u5212\u80fd\u529b\u3002", "conclusion": "OmniEVA\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u5177\u8eab\u7cfb\u7edf\u7684\u5c40\u9650\uff0c\u5177\u6709\u826f\u597d\u7684\u5177\u8eab\u63a8\u7406\u548c\u4efb\u52a1\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2509.09349", "pdf": "https://arxiv.org/pdf/2509.09349", "abs": "https://arxiv.org/abs/2509.09349", "authors": ["Ian Nell", "Shane Gilroy"], "title": "Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.RO", "eess.IV"], "comment": null, "summary": "Road traffic accidents remain a significant global concern, with human error,\nparticularly distracted and impaired driving, among the leading causes. This\nstudy introduces a novel driver behavior classification system that uses\nexternal observation techniques to detect indicators of distraction and\nimpairment. The proposed framework employs advanced computer vision\nmethodologies, including real-time object tracking, lateral displacement\nanalysis, and lane position monitoring. The system identifies unsafe driving\nbehaviors such as excessive lateral movement and erratic trajectory patterns by\nimplementing the YOLO object detection model and custom lane estimation\nalgorithms. Unlike systems reliant on inter-vehicular communication, this\nvision-based approach enables behavioral analysis of non-connected vehicles.\nExperimental evaluations on diverse video datasets demonstrate the framework's\nreliability and adaptability across varying road and environmental conditions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u9a7e\u9a76\u5458\u884c\u4e3a\u5206\u7c7b\u7cfb\u7edf\uff0c\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u6cd5\u68c0\u6d4b\u5206\u5fc3\u548c\u53d7\u635f\u9a7e\u9a76\u884c\u4e3a\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u53ef\u9760\u4e14\u9002\u5e94\u4e0d\u540c\u6761\u4ef6\u3002", "motivation": "\u9053\u8def\u4ea4\u901a\u4e8b\u6545\u662f\u5168\u7403\u91cd\u8981\u95ee\u9898\uff0c\u4eba\u4e3a\u9519\u8bef\u5c24\u5176\u662f\u5206\u5fc3\u548c\u53d7\u635f\u9a7e\u9a76\u662f\u4e3b\u8981\u539f\u56e0\uff0c\u9700\u8981\u68c0\u6d4b\u8fd9\u4e9b\u884c\u4e3a\u3002", "method": "\u91c7\u7528\u5148\u8fdb\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u6cd5\uff0c\u5305\u62ec\u5b9e\u65f6\u76ee\u6807\u8ddf\u8e2a\u3001\u6a2a\u5411\u4f4d\u79fb\u5206\u6790\u548c\u8f66\u9053\u4f4d\u7f6e\u76d1\u6d4b\uff0c\u4f7f\u7528YOLO\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u548c\u81ea\u5b9a\u4e49\u8f66\u9053\u4f30\u8ba1\u7b97\u6cd5\u3002", "result": "\u5728\u4e0d\u540c\u89c6\u9891\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u9053\u8def\u548c\u73af\u5883\u6761\u4ef6\u4e0b\u5177\u6709\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u89c6\u89c9\u7684\u9a7e\u9a76\u5458\u884c\u4e3a\u5206\u7c7b\u7cfb\u7edf\u80fd\u6709\u6548\u68c0\u6d4b\u4e0d\u5b89\u5168\u9a7e\u9a76\u884c\u4e3a\uff0c\u4e14\u53ef\u7528\u4e8e\u975e\u8054\u7f51\u8f66\u8f86\u3002"}}
{"id": "2509.09371", "pdf": "https://arxiv.org/pdf/2509.09371", "abs": "https://arxiv.org/abs/2509.09371", "authors": ["Zitao Wang", "Nian Si", "Molei Liu"], "title": "Representation-Aware Distributionally Robust Optimization: A Knowledge Transfer Framework", "categories": ["stat.ME", "cs.LG"], "comment": null, "summary": "We propose REpresentation-Aware Distributionally Robust Estimation (READ), a\nnovel framework for Wasserstein distributionally robust learning that accounts\nfor predictive representations when guarding against distributional shifts.\nUnlike classical approaches that treat all feature perturbations equally, READ\nembeds a multidimensional alignment parameter into the transport cost, allowing\nthe model to differentially discourage perturbations along directions\nassociated with informative representations. This yields robustness to feature\nvariation while preserving invariant structure. Our first contribution is a\ntheoretical foundation: we show that seminorm regularizations for linear\nregression and binary classification arise as Wasserstein distributionally\nrobust objectives, thereby providing tractable reformulations of READ and\nunifying a broad class of regularized estimators under the DRO lens. Second, we\nadopt a principled procedure for selecting the Wasserstein radius using the\ntechniques of robust Wasserstein profile inference. This further enables the\nconstruction of valid, representation-aware confidence regions for model\nparameters with distinct geometric features. Finally, we analyze the geometry\nof READ estimators as the alignment parameters vary and propose an optimization\nalgorithm to estimate the projection of the global optimum onto this solution\nsurface. This procedure selects among equally robust estimators while optimally\nconstructing a representation structure. We conclude by demonstrating the\neffectiveness of our framework through extensive simulations and a real-world\nstudy, providing a powerful robust estimation grounded in learning\nrepresentation.", "AI": {"tldr": "\u63d0\u51faREAD\u6846\u67b6\u7528\u4e8eWasserstein\u5206\u5e03\u9c81\u68d2\u5b66\u4e60\uff0c\u6709\u7406\u8bba\u57fa\u7840\u3001\u534a\u5f84\u9009\u62e9\u65b9\u6cd5\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u7ecf\u5178\u65b9\u6cd5\u5e73\u7b49\u5bf9\u5f85\u7279\u5f81\u6270\u52a8\uff0c\u7f3a\u4e4f\u5bf9\u9884\u6d4b\u8868\u793a\u7684\u8003\u8651\uff0c\u9700\u4e00\u79cd\u80fd\u5728\u9632\u8303\u5206\u5e03\u504f\u79fb\u65f6\u8003\u8651\u9884\u6d4b\u8868\u793a\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u591a\u7ef4\u5bf9\u9f50\u53c2\u6570\u5d4c\u5165\u4f20\u8f93\u6210\u672c\uff1b\u7528\u9c81\u68d2Wasserstein\u8f6e\u5ed3\u63a8\u65ad\u6280\u672f\u9009Wasserstein\u534a\u5f84\uff1b\u5206\u6790READ\u4f30\u8ba1\u5668\u51e0\u4f55\u6027\u8d28\u5e76\u63d0\u51fa\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u4e3a\u7ebf\u6027\u56de\u5f52\u548c\u4e8c\u5143\u5206\u7c7b\u7684\u534a\u8303\u6570\u6b63\u5219\u5316\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\uff1b\u80fd\u6784\u5efa\u6709\u6548\u3001\u6709\u7279\u5b9a\u51e0\u4f55\u7279\u5f81\u7684\u7f6e\u4fe1\u533a\u57df\uff1b\u80fd\u5728\u540c\u7b49\u9c81\u68d2\u4f30\u8ba1\u5668\u4e2d\u9009\u62e9\u5e76\u6784\u5efa\u8868\u793a\u7ed3\u6784\u3002", "conclusion": "\u901a\u8fc7\u5927\u91cf\u6a21\u62df\u548c\u5b9e\u9645\u7814\u7a76\u8bc1\u660e\u4e86READ\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5b66\u4e60\u8868\u793a\u7684\u5f3a\u5927\u9c81\u68d2\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2509.09429", "pdf": "https://arxiv.org/pdf/2509.09429", "abs": "https://arxiv.org/abs/2509.09429", "authors": ["Peisong Wen", "Qianqian Xu", "Siran Dai", "Runmin Cong", "Qingming Huang"], "title": "Semantic Concentration for Self-Supervised Dense Representations Learning", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent advances in image-level self-supervised learning (SSL) have made\nsignificant progress, yet learning dense representations for patches remains\nchallenging. Mainstream methods encounter an over-dispersion phenomenon that\npatches from the same instance/category scatter, harming downstream performance\non dense tasks. This work reveals that image-level SSL avoids over-dispersion\nby involving implicit semantic concentration. Specifically, the non-strict\nspatial alignment ensures intra-instance consistency, while shared patterns,\ni.e., similar parts of within-class instances in the input space, ensure\ninter-image consistency. Unfortunately, these approaches are infeasible for\ndense SSL due to their spatial sensitivity and complicated scene-centric data.\nThese observations motivate us to explore explicit semantic concentration for\ndense SSL. First, to break the strict spatial alignment, we propose to distill\nthe patch correspondences. Facing noisy and imbalanced pseudo labels, we\npropose a noise-tolerant ranking loss. The core idea is extending the Average\nPrecision (AP) loss to continuous targets, such that its decision-agnostic and\nadaptive focusing properties prevent the student model from being misled.\nSecond, to discriminate the shared patterns from complicated scenes, we propose\nthe object-aware filter to map the output space to an object-based space.\nSpecifically, patches are represented by learnable prototypes of objects via\ncross-attention. Last but not least, empirical studies across various tasks\nsoundly support the effectiveness of our method. Code is available in\nhttps://github.com/KID-7391/CoTAP.", "AI": {"tldr": "\u73b0\u6709\u56fe\u50cf\u7ea7\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u5b66\u4e60\u56fe\u50cf\u5757\u5bc6\u96c6\u8868\u793a\u4e0a\u6709\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u663e\u5f0f\u8bed\u4e49\u96c6\u4e2d\u65b9\u6cd5\u7528\u4e8e\u5bc6\u96c6\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u4e3b\u6d41\u65b9\u6cd5\u5b58\u5728\u8fc7\u5206\u6563\u73b0\u8c61\u5f71\u54cd\u5bc6\u96c6\u4efb\u52a1\u4e0b\u6e38\u6027\u80fd\uff0c\u56fe\u50cf\u7ea7\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u9690\u5f0f\u8bed\u4e49\u96c6\u4e2d\u65b9\u6cd5\u56e0\u7a7a\u95f4\u654f\u611f\u6027\u548c\u590d\u6742\u573a\u666f\u6570\u636e\u4e0d\u9002\u7528\u4e8e\u5bc6\u96c6\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u63a2\u7d22\u663e\u5f0f\u8bed\u4e49\u96c6\u4e2d\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u84b8\u998f\u56fe\u50cf\u5757\u5bf9\u5e94\u5173\u7cfb\u4ee5\u6253\u7834\u4e25\u683c\u7a7a\u95f4\u5bf9\u9f50\uff0c\u63d0\u51fa\u566a\u58f0\u5bb9\u5fcd\u6392\u5e8f\u635f\u5931\u5904\u7406\u566a\u58f0\u548c\u4e0d\u5e73\u8861\u4f2a\u6807\u7b7e\uff1b\u63d0\u51fa\u5bf9\u8c61\u611f\u77e5\u8fc7\u6ee4\u5668\u5c06\u8f93\u51fa\u7a7a\u95f4\u6620\u5c04\u5230\u57fa\u4e8e\u5bf9\u8c61\u7684\u7a7a\u95f4\u3002", "result": "\u5728\u5404\u79cd\u4efb\u52a1\u7684\u5b9e\u8bc1\u7814\u7a76\u4e2d\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u663e\u5f0f\u8bed\u4e49\u96c6\u4e2d\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u5bc6\u96c6\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u5b66\u4e60\u56fe\u50cf\u5757\u5bc6\u96c6\u8868\u793a\u7684\u95ee\u9898\u3002"}}
{"id": "2509.09495", "pdf": "https://arxiv.org/pdf/2509.09495", "abs": "https://arxiv.org/abs/2509.09495", "authors": ["Victor Livernoche", "Akshatha Arodi", "Andreea Musulan", "Zachary Yang", "Adam Salvail", "Ga\u00e9tan Marceau Caron", "Jean-Fran\u00e7ois Godbout", "Reihaneh Rabbany"], "title": "OpenFake: An Open Dataset and Platform Toward Large-Scale Deepfake Detection", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.4.9; I.5.4; I.2.10"], "comment": "25 pages, 12 figures", "summary": "Deepfakes, synthetic media created using advanced AI techniques, have\nintensified the spread of misinformation, particularly in politically sensitive\ncontexts. Existing deepfake detection datasets are often limited, relying on\noutdated generation methods, low realism, or single-face imagery, restricting\nthe effectiveness for general synthetic image detection. By analyzing social\nmedia posts, we identify multiple modalities through which deepfakes propagate\nmisinformation. Furthermore, our human perception study demonstrates that\nrecently developed proprietary models produce synthetic images increasingly\nindistinguishable from real ones, complicating accurate identification by the\ngeneral public. Consequently, we present a comprehensive, politically-focused\ndataset specifically crafted for benchmarking detection against modern\ngenerative models. This dataset contains three million real images paired with\ndescriptive captions, which are used for generating 963k corresponding\nhigh-quality synthetic images from a mix of proprietary and open-source models.\nRecognizing the continual evolution of generative techniques, we introduce an\ninnovative crowdsourced adversarial platform, where participants are\nincentivized to generate and submit challenging synthetic images. This ongoing\ncommunity-driven initiative ensures that deepfake detection methods remain\nrobust and adaptive, proactively safeguarding public discourse from\nsophisticated misinformation threats.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u73b0\u6709\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6570\u636e\u96c6\u6709\u5c40\u9650\uff0c\u63d0\u51fa\u653f\u6cbb\u805a\u7126\u6570\u636e\u96c6\u53ca\u4f17\u5305\u5bf9\u6297\u5e73\u53f0\u4fdd\u969c\u516c\u4f17\u8bdd\u8bed\u514d\u53d7\u865a\u5047\u4fe1\u606f\u5a01\u80c1\u3002", "motivation": "\u6df1\u5ea6\u4f2a\u9020\u52a0\u5267\u865a\u5047\u4fe1\u606f\u4f20\u64ad\uff0c\u73b0\u6709\u68c0\u6d4b\u6570\u636e\u96c6\u5b58\u5728\u7f3a\u9677\uff0c\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u5408\u6210\u56fe\u50cf\u3002", "method": "\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u786e\u5b9a\u6df1\u5ea6\u4f2a\u9020\u4f20\u64ad\u865a\u5047\u4fe1\u606f\u7684\u6a21\u5f0f\uff1b\u5f00\u5c55\u4eba\u7c7b\u611f\u77e5\u7814\u7a76\uff1b\u6784\u5efa\u653f\u6cbb\u805a\u7126\u6570\u636e\u96c6\uff1b\u5f15\u5165\u4f17\u5305\u5bf9\u6297\u5e73\u53f0\u3002", "result": "\u6784\u5efa\u4e86\u542b\u4e09\u767e\u4e07\u771f\u5b9e\u56fe\u50cf\u53ca\u5bf9\u5e94\u63cf\u8ff0\u7684\u6570\u636e\u96c6\uff0c\u751f\u6210963k\u9ad8\u8d28\u91cf\u5408\u6210\u56fe\u50cf\uff1b\u4f17\u5305\u5bf9\u6297\u5e73\u53f0\u4fdd\u969c\u68c0\u6d4b\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u96c6\u548c\u4f17\u5305\u5bf9\u6297\u5e73\u53f0\u6709\u52a9\u4e8e\u63d0\u9ad8\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u80fd\u529b\uff0c\u4fdd\u62a4\u516c\u4f17\u8bdd\u8bed\u514d\u53d7\u590d\u6742\u865a\u5047\u4fe1\u606f\u5a01\u80c1\u3002"}}
{"id": "2509.09513", "pdf": "https://arxiv.org/pdf/2509.09513", "abs": "https://arxiv.org/abs/2509.09513", "authors": ["Quentin Uhl", "Tommaso Pavan", "Julianna Gerold", "Kwok-Shing Chan", "Yohan Jun", "Shohei Fujita", "Aneri Bhatt", "Yixin Ma", "Qiaochu Wang", "Hong-Hsi Lee", "Susie Y. Huang", "Berkin Bilgic", "Ileana Jelescu"], "title": "Explainable AI for Accelerated Microstructure Imaging: A SHAP-Guided Protocol on the Connectome 2.0 scanner", "categories": ["physics.med-ph", "cs.AI", "cs.CV", "cs.LG", "eess.IV", "J.3"], "comment": "Submitted to IEEE Transactions on Medical Imaging (TMI). This\n  all-in-one version includes supplementary materials. 18 pages, 14 figures, 2\n  tables", "summary": "The diffusion MRI Neurite Exchange Imaging model offers a promising framework\nfor probing gray matter microstructure by estimating parameters such as\ncompartment sizes, diffusivities, and inter-compartmental water exchange time.\nHowever, existing protocols require long scan times. This study proposes a\nreduced acquisition scheme for the Connectome 2.0 scanner that preserves model\naccuracy while substantially shortening scan duration. We developed a\ndata-driven framework using explainable artificial intelligence with a guided\nrecursive feature elimination strategy to identify an optimal 8-feature subset\nfrom a 15-feature protocol. The performance of this optimized protocol was\nvalidated in vivo and benchmarked against the full acquisition and alternative\nreduction strategies. Parameter accuracy, preservation of anatomical contrast,\nand test-retest reproducibility were assessed. The reduced protocol yielded\nparameter estimates and cortical maps comparable to the full protocol, with low\nestimation errors in synthetic data and minimal impact on test-retest\nvariability. Compared to theory-driven and heuristic reduction schemes, the\noptimized protocol demonstrated superior robustness, reducing the deviation in\nwater exchange time estimates by over two-fold. In conclusion, this hybrid\noptimization framework enables viable imaging of neurite exchange in 14 minutes\nwithout loss of parameter fidelity. This approach supports the broader\napplication of exchange-sensitive diffusion magnetic resonance imaging in\nneuroscience and clinical research, and offers a generalizable method for\ndesigning efficient acquisition protocols in biophysical parameter mapping.", "AI": {"tldr": "\u63d0\u51faConnectome 2.0\u626b\u63cf\u4eea\u7684\u7b80\u5316\u91c7\u96c6\u65b9\u6848\uff0c\u7528\u6570\u636e\u9a71\u52a8\u6846\u67b6\u9009\u7279\u5f81\uff0c\u9a8c\u8bc1\u6548\u679c\u597d\uff0c14\u5206\u949f\u6210\u50cf\u4e14\u4e0d\u635f\u5931\u53c2\u6570\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709\u6269\u6563MRI\u795e\u7ecf\u7a81\u4ea4\u6362\u6210\u50cf\u6a21\u578b\u534f\u8bae\u626b\u63cf\u65f6\u95f4\u957f\uff0c\u9700\u7f29\u77ed\u65f6\u95f4\u3002", "method": "\u7528\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u548c\u5f15\u5bfc\u9012\u5f52\u7279\u5f81\u6d88\u9664\u7b56\u7565\uff0c\u4ece15\u7279\u5f81\u534f\u8bae\u4e2d\u90098\u7279\u5f81\u5b50\u96c6\u3002", "result": "\u7b80\u5316\u534f\u8bae\u53c2\u6570\u4f30\u8ba1\u548c\u76ae\u8d28\u56fe\u4e0e\u5b8c\u6574\u534f\u8bae\u76f8\u5f53\uff0c\u8bef\u5dee\u4f4e\uff0c\u91cd\u6d4b\u53d8\u5f02\u6027\u5c0f\uff0c\u6bd4\u5176\u4ed6\u65b9\u6848\u66f4\u7a33\u5065\u3002", "conclusion": "\u6df7\u5408\u4f18\u5316\u6846\u67b614\u5206\u949f\u53ef\u884c\u795e\u7ecf\u7a81\u4ea4\u6362\u6210\u50cf\uff0c\u652f\u6301\u76f8\u5173\u7814\u7a76\uff0c\u63d0\u4f9b\u901a\u7528\u65b9\u6cd5\u8bbe\u8ba1\u91c7\u96c6\u534f\u8bae\u3002"}}
{"id": "2509.09424", "pdf": "https://arxiv.org/pdf/2509.09424", "abs": "https://arxiv.org/abs/2509.09424", "authors": ["Zhiyu He", "Maojiang Wang", "Xinwen Gao", "Yuchuan Luo", "Lin Liu", "Shaojing Fu"], "title": "ENSI: Efficient Non-Interactive Secure Inference for Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Secure inference enables privacy-preserving machine learning by leveraging\ncryptographic protocols that support computations on sensitive user data\nwithout exposing it. However, integrating cryptographic protocols with large\nlanguage models (LLMs) presents significant challenges, as the inherent\ncomplexity of these protocols, together with LLMs' massive parameter scale and\nsophisticated architectures, severely limits practical usability. In this work,\nwe propose ENSI, a novel non-interactive secure inference framework for LLMs,\nbased on the principle of co-designing the cryptographic protocols and LLM\narchitecture. ENSI employs an optimized encoding strategy that seamlessly\nintegrates CKKS scheme with a lightweight LLM variant, BitNet, significantly\nreducing the computational complexity of encrypted matrix multiplications. In\nresponse to the prohibitive computational demands of softmax under homomorphic\nencryption (HE), we pioneer the integration of the sigmoid attention mechanism\nwith HE as a seamless, retraining-free alternative. Furthermore, by embedding\nthe Bootstrapping operation within the RMSNorm process, we efficiently refresh\nciphertexts while markedly decreasing the frequency of costly bootstrapping\ninvocations. Experimental evaluations demonstrate that ENSI achieves\napproximately an 8x acceleration in matrix multiplications and a 2.6x speedup\nin softmax inference on CPU compared to state-of-the-art method, with the\nproportion of bootstrapping is reduced to just 1%.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u975e\u4ea4\u4e92\u5b89\u5168\u63a8\u7406\u6846\u67b6 ENSI\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u663e\u8457\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u52a0\u5bc6\u534f\u8bae\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5b58\u5728\u6311\u6218\uff0c\u5176\u590d\u6742\u6027\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5927\u89c4\u6a21\u53c2\u6570\u4e0e\u590d\u6742\u67b6\u6784\u9650\u5236\u4e86\u5b9e\u7528\u6027\u3002", "method": "\u57fa\u4e8e\u52a0\u5bc6\u534f\u8bae\u548c\u5927\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u539f\u5219\uff0c\u91c7\u7528\u4f18\u5316\u7f16\u7801\u7b56\u7565\u7ed3\u5408 CKKS \u65b9\u6848\u4e0e\u8f7b\u91cf\u7ea7\u6a21\u578b BitNet\uff1b\u5c06 sigmoid \u6ce8\u610f\u529b\u673a\u5236\u4e0e\u540c\u6001\u52a0\u5bc6\u96c6\u6210\uff1b\u5728 RMSNorm \u8fc7\u7a0b\u4e2d\u5d4c\u5165 Bootstrapping \u64cd\u4f5c\u3002", "result": "\u5728 CPU \u4e0a\u77e9\u9635\u4e58\u6cd5\u7ea6\u52a0\u901f 8 \u500d\uff0csoftmax \u63a8\u7406\u52a0\u901f 2.6 \u500d\uff0cBootstrapping \u6bd4\u4f8b\u964d\u81f3 1%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684 ENSI \u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u52a0\u5bc6\u534f\u8bae\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u63a8\u7406\u7684\u6548\u7387\u3002"}}
{"id": "2509.09524", "pdf": "https://arxiv.org/pdf/2509.09524", "abs": "https://arxiv.org/abs/2509.09524", "authors": ["Daniil Ignatev", "Nan Li", "Hugh Mee Wong", "Anh Dang", "Shane Kaszefski Yaschuk"], "title": "DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning", "categories": ["cs.CL", "cs.LG"], "comment": "11 pages, 4 figures; to appear at NLPerspectives@EMNLP-2025", "summary": "This system paper presents the DeMeVa team's approaches to the third edition\nof the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et\nal., 2025). We explore two directions: in-context learning (ICL) with large\nlanguage models, where we compare example sampling strategies; and label\ndistribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we\nevaluate several fine-tuning methods. Our contributions are twofold: (1) we\nshow that ICL can effectively predict annotator-specific annotations\n(perspectivist annotations), and that aggregating these predictions into soft\nlabels yields competitive performance; and (2) we argue that LDL methods are\npromising for soft label predictions and merit further exploration by the\nperspectivist community.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdDeMeVa\u56e2\u961f\u9488\u5bf9LeWiDi 2025\u5171\u4eab\u4efb\u52a1\u7684\u65b9\u6cd5\uff0c\u63a2\u7d22\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u6807\u7b7e\u5206\u5e03\u5b66\u4e60\uff0c\u5c55\u793a\u4e86\u4e24\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6f5c\u529b\u3002", "motivation": "\u53c2\u4e0eLeWiDi 2025\u5171\u4eab\u4efb\u52a1\uff0c\u63a2\u7d22\u6709\u6548\u9884\u6d4b\u6ce8\u91ca\u7684\u65b9\u6cd5\u3002", "method": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08\u6bd4\u8f83\u793a\u4f8b\u91c7\u6837\u7b56\u7565\uff09\u548c\u57fa\u4e8eRoBERTa\u7684\u6807\u7b7e\u5206\u5e03\u5b66\u4e60\uff08\u8bc4\u4f30\u591a\u79cd\u5fae\u8c03\u65b9\u6cd5\uff09\u3002", "result": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u6709\u6548\u9884\u6d4b\u7279\u5b9a\u6ce8\u91ca\uff0c\u805a\u5408\u9884\u6d4b\u6210\u8f6f\u6807\u7b7e\u6709\u7ade\u4e89\u529b\uff1b\u6807\u7b7e\u5206\u5e03\u5b66\u4e60\u65b9\u6cd5\u5bf9\u8f6f\u6807\u7b7e\u9884\u6d4b\u6709\u524d\u666f\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u5728\u9884\u6d4b\u7279\u5b9a\u6ce8\u91ca\u65b9\u9762\u6709\u6548\uff0c\u6807\u7b7e\u5206\u5e03\u5b66\u4e60\u65b9\u6cd5\u503c\u5f97\u89c6\u89d2\u4e3b\u4e49\u793e\u533a\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2509.09469", "pdf": "https://arxiv.org/pdf/2509.09469", "abs": "https://arxiv.org/abs/2509.09469", "authors": ["Freedmore Sidume", "Oumayma Soula", "Joseph Muthui Wacira", "YunFei Zhu", "Abbas Rabiu Muhammad", "Abderrazek Zeraii", "Oluwaseun Kalejaye", "Hajer Ibrahim", "Olfa Gaddour", "Brain Halubanza", "Dong Zhang", "Udunna C Anazodo", "Confidence Raymond"], "title": "Resource-Efficient Glioma Segmentation on Sub-Saharan MRI", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 7 figures", "summary": "Gliomas are the most prevalent type of primary brain tumors, and their\naccurate segmentation from MRI is critical for diagnosis, treatment planning,\nand longitudinal monitoring. However, the scarcity of high-quality annotated\nimaging data in Sub-Saharan Africa (SSA) poses a significant challenge for\ndeploying advanced segmentation models in clinical workflows. This study\nintroduces a robust and computationally efficient deep learning framework\ntailored for resource-constrained settings. We leveraged a 3D Attention UNet\narchitecture augmented with residual blocks and enhanced through transfer\nlearning from pre-trained weights on the BraTS 2021 dataset. Our model was\nevaluated on 95 MRI cases from the BraTS-Africa dataset, a benchmark for glioma\nsegmentation in SSA MRI data. Despite the limited data quality and quantity,\nour approach achieved Dice scores of 0.76 for the Enhancing Tumor (ET), 0.80\nfor Necrotic and Non-Enhancing Tumor Core (NETC), and 0.85 for Surrounding\nNon-Functional Hemisphere (SNFH). These results demonstrate the\ngeneralizability of the proposed model and its potential to support clinical\ndecision making in low-resource settings. The compact architecture,\napproximately 90 MB, and sub-minute per-volume inference time on consumer-grade\nhardware further underscore its practicality for deployment in SSA health\nsystems. This work contributes toward closing the gap in equitable AI for\nglobal health by empowering underserved regions with high-performing and\naccessible medical imaging solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u75283D Attention UNet\u67b6\u6784\u7ed3\u5408\u8fc1\u79fb\u5b66\u4e60\uff0c\u5728\u6709\u9650\u6570\u636e\u4e0b\u53d6\u5f97\u4e0d\u9519\u5206\u5272\u6548\u679c\uff0c\u8bc1\u660e\u6a21\u578b\u6cdb\u5316\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u9ad8\u8d28\u91cf\u6807\u6ce8\u5f71\u50cf\u6570\u636e\u7a00\u7f3a\uff0c\u96be\u4ee5\u5728\u4e34\u5e8a\u5de5\u4f5c\u6d41\u4e2d\u90e8\u7f72\u5148\u8fdb\u5206\u5272\u6a21\u578b\u3002", "method": "\u91c7\u7528\u5e26\u6b8b\u5dee\u5757\u76843D Attention UNet\u67b6\u6784\uff0c\u5229\u7528BraTS 2021\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u6743\u91cd\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\u3002", "result": "\u5728BraTS - Africa\u6570\u636e\u96c695\u4f8bMRI\u4e0a\u8bc4\u4f30\uff0c\u589e\u5f3a\u80bf\u7624\u3001\u574f\u6b7b\u548c\u975e\u589e\u5f3a\u80bf\u7624\u6838\u5fc3\u3001\u5468\u56f4\u975e\u529f\u80fd\u534a\u7403\u7684Dice\u5206\u6570\u5206\u522b\u8fbe0.76\u30010.80\u30010.85\uff0c\u6a21\u578b\u7ea690MB\uff0c\u6d88\u8d39\u7ea7\u786c\u4ef6\u63a8\u7406\u65f6\u95f4\u4e0d\u52301\u5206\u949f\u3002", "conclusion": "\u6a21\u578b\u5177\u6709\u6cdb\u5316\u6027\uff0c\u80fd\u652f\u6301\u4f4e\u8d44\u6e90\u73af\u5883\u4e34\u5e8a\u51b3\u7b56\uff0c\u6709\u52a9\u4e8e\u7f29\u5c0f\u5168\u7403\u5065\u5eb7\u9886\u57dfAI\u5e94\u7528\u5dee\u8ddd\u3002"}}
{"id": "2509.09550", "pdf": "https://arxiv.org/pdf/2509.09550", "abs": "https://arxiv.org/abs/2509.09550", "authors": ["Harry Julia", "Rachel Beeson", "Lohith Konathala", "Johanna Ulin", "Jiameng Gao"], "title": "Finite Scalar Quantization Enables Redundant and Transmission-Robust Neural Audio Compression at Low Bit-rates", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "Neural Audio Codecs (NACs) have become increasingly adopted in speech\nprocessing tasks due to their excellent rate-distortion performance and\ncompatibility with Large Language Models (LLMs) as discrete feature\nrepresentations for audio generation. While most existing codecs rely on\nResidual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has\nrecently emerged as a compelling alternative that simplifies training and\nnatively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC,\nand show that FSQ encodes baked-in redundancy which produces an encoding which\nis robust when transmitted through noisy channels. First, through an encoder\ndistillation experiment, we show that two different encoders can learn to\nencode identical audio into vastly different code sequences whilst maintaining\ncomparable reconstruction quality with the same quantizer and decoder. Second,\nwe demonstrate that FSQ has vastly superior bit-level perturbation robustness\nby comparing the performance of RVQ and FSQ codecs when simulating the\ntransmission of code sequences through a noisy channel.", "AI": {"tldr": "\u4ecb\u7ecd\u57fa\u4e8eFSQ\u7684NeuCodec\uff0c\u5c55\u793aFSQ\u5728\u6297\u566a\u4f20\u8f93\u65b9\u9762\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709NAC\u591a\u4f9d\u8d56RVQ\uff0cFSQ\u662f\u6709\u6f5c\u529b\u66ff\u4ee3\u65b9\u6848\uff0c\u9700\u7814\u7a76\u5176\u6027\u80fd\u3002", "method": "\u8fdb\u884c\u7f16\u7801\u5668\u84b8\u998f\u5b9e\u9a8c\uff0c\u6a21\u62df\u5728\u566a\u58f0\u4fe1\u9053\u4f20\u8f93\u4ee3\u7801\u5e8f\u5217\u6bd4\u8f83RVQ\u548cFSQ\u7f16\u89e3\u7801\u5668\u6027\u80fd\u3002", "result": "\u4e0d\u540c\u7f16\u7801\u5668\u7528\u76f8\u540c\u91cf\u5316\u5668\u548c\u89e3\u7801\u5668\u53ef\u5c06\u76f8\u540c\u97f3\u9891\u7f16\u7801\u6210\u4e0d\u540c\u4ee3\u7801\u5e8f\u5217\u4e14\u91cd\u5efa\u8d28\u91cf\u76f8\u8fd1\uff1bFSQ\u6bd4\u7279\u7ea7\u6270\u52a8\u9c81\u68d2\u6027\u8fdc\u8d85RVQ\u3002", "conclusion": "FSQ\u7f16\u7801\u5b58\u5728\u5185\u7f6e\u5197\u4f59\uff0c\u5728\u566a\u58f0\u4fe1\u9053\u4f20\u8f93\u65f6\u7f16\u7801\u66f4\u9c81\u68d2\u3002"}}
{"id": "2509.09488", "pdf": "https://arxiv.org/pdf/2509.09488", "abs": "https://arxiv.org/abs/2509.09488", "authors": ["Felix M\u00e4chtle", "Ashwath Shetty", "Jonas Sander", "Nils Loose", "S\u00f6ren Pirk", "Thomas Eisenbarth"], "title": "Prompt Pirates Need a Map: Stealing Seeds helps Stealing Prompts", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Diffusion models have significantly advanced text-to-image generation,\nenabling the creation of highly realistic images conditioned on textual prompts\nand seeds. Given the considerable intellectual and economic value embedded in\nsuch prompts, prompt theft poses a critical security and privacy concern. In\nthis paper, we investigate prompt-stealing attacks targeting diffusion models.\nWe reveal that numerical optimization-based prompt recovery methods are\nfundamentally limited as they do not account for the initial random noise used\nduring image generation. We identify and exploit a noise-generation\nvulnerability (CWE-339), prevalent in major image-generation frameworks,\noriginating from PyTorch's restriction of seed values to a range of $2^{32}$\nwhen generating the initial random noise on CPUs. Through a large-scale\nempirical analysis conducted on images shared via the popular platform CivitAI,\nwe demonstrate that approximately 95% of these images' seed values can be\neffectively brute-forced in 140 minutes per seed using our seed-recovery tool,\nSeedSnitch. Leveraging the recovered seed, we propose PromptPirate, a genetic\nalgorithm-based optimization method explicitly designed for prompt stealing.\nPromptPirate surpasses state-of-the-art methods, i.e., PromptStealer, P2HP, and\nCLIP-Interrogator, achieving an 8-11% improvement in LPIPS similarity.\nFurthermore, we introduce straightforward and effective countermeasures that\nrender seed stealing, and thus optimization-based prompt stealing, ineffective.\nWe have disclosed our findings responsibly and initiated coordinated mitigation\nefforts with the developers to address this critical vulnerability.", "AI": {"tldr": "\u7814\u7a76\u6269\u6563\u6a21\u578b\u7684\u63d0\u793a\u8bcd\u7a83\u53d6\u653b\u51fb\uff0c\u53d1\u73b0\u4f18\u5316\u65b9\u6cd5\u5c40\u9650\uff0c\u5229\u7528\u566a\u58f0\u751f\u6210\u6f0f\u6d1e\u6062\u590d\u79cd\u5b50\u503c\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5PromptPirate\uff0c\u7ed9\u51fa\u5e94\u5bf9\u63aa\u65bd\u5e76\u4e0e\u5f00\u53d1\u8005\u5408\u4f5c\u4fee\u590d\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4e2d\u63d0\u793a\u8bcd\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u63d0\u793a\u8bcd\u7a83\u53d6\u5b58\u5728\u5b89\u5168\u548c\u9690\u79c1\u95ee\u9898\uff0c\u9700\u7814\u7a76\u653b\u51fb\u548c\u9632\u62a4\u3002", "method": "\u63ed\u793a\u6570\u503c\u4f18\u5316\u63d0\u793a\u6062\u590d\u65b9\u6cd5\u5c40\u9650\uff0c\u5229\u7528\u566a\u58f0\u751f\u6210\u6f0f\u6d1e\uff0c\u7528SeedSnitch\u5de5\u5177\u6062\u590d\u79cd\u5b50\u503c\uff0c\u63d0\u51fa\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684PromptPirate\u8fdb\u884c\u63d0\u793a\u8bcd\u7a83\u53d6\uff0c\u7ed9\u51fa\u5e94\u5bf9\u63aa\u65bd\u3002", "result": "\u7ea695%\u56fe\u50cf\u79cd\u5b50\u503c\u53ef\u5728140\u5206\u949f\u5185\u66b4\u529b\u7834\u89e3\uff0cPromptPirate\u6bd4\u73b0\u6709\u65b9\u6cd5LPIPS\u76f8\u4f3c\u5ea6\u63d0\u53478 - 11%\u3002", "conclusion": "\u63d0\u51fa\u6709\u6548\u5e94\u5bf9\u63aa\u65bd\uff0c\u4e0e\u5f00\u53d1\u8005\u5408\u4f5c\u89e3\u51b3\u5173\u952e\u6f0f\u6d1e\u3002"}}
{"id": "2509.09564", "pdf": "https://arxiv.org/pdf/2509.09564", "abs": "https://arxiv.org/abs/2509.09564", "authors": ["Meghan Wilkinson", "Robert H Thomson"], "title": "What Does Normal Even Mean? Evaluating Benign Traffic in Intrusion Detection Datasets", "categories": ["cs.CR", "cs.LG"], "comment": "10 pages; accepted to SBP-BRiMS 2025 Poster Session", "summary": "Supervised machine learning techniques rely on labeled data to achieve high\ntask performance, but this requires the labels to capture some meaningful\ndifferences in the underlying data structure. For training network intrusion\ndetection algorithms, most datasets contain a series of attack classes and a\nsingle large benign class which captures all non-attack network traffic. A\nreview of intrusion detection papers and guides that explicitly state their\ndata preprocessing steps identified that the majority took the labeled\ncategories of the dataset at face value when training their algorithms. The\npresent paper evaluates the structure of benign traffic in several common\nintrusion detection datasets (NSL-KDD, UNSW-NB15, and CIC-IDS 2017) and\ndetermines whether there are meaningful sub-categories within this traffic\nwhich may improve overall multi-classification performance using common machine\nlearning techniques. We present an overview of some unsupervised clustering\ntechniques (e.g., HDBSCAN, Mean Shift Clustering) and show how they\ndifferentially cluster the benign traffic space.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u5e38\u89c1\u5165\u4fb5\u68c0\u6d4b\u6570\u636e\u96c6\u4e2d\u826f\u6027\u6d41\u91cf\u7ed3\u6784\uff0c\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u6280\u672f\u805a\u7c7b\u826f\u6027\u6d41\u91cf\uff0c\u770b\u662f\u5426\u6709\u6709\u610f\u4e49\u5b50\u7c7b\u522b\u4ee5\u63d0\u5347\u591a\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u76d1\u7763\u673a\u5668\u5b66\u4e60\u4f9d\u8d56\u6709\u610f\u4e49\u6807\u7b7e\u6570\u636e\uff0c\u591a\u6570\u5165\u4fb5\u68c0\u6d4b\u6570\u636e\u96c6\u826f\u6027\u7c7b\u5355\u4e00\uff0c\u591a\u6570\u7814\u7a76\u76f4\u63a5\u7528\u6807\u7b7e\u7c7b\u522b\u8bad\u7ec3\uff0c\u672c\u6587\u60f3\u786e\u5b9a\u826f\u6027\u6d41\u91cf\u4e2d\u662f\u5426\u6709\u6709\u610f\u4e49\u5b50\u7c7b\u522b\u6765\u63d0\u5347\u591a\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u8bc4\u4f30NSL - KDD\u3001UNSW - NB15\u548cCIC - IDS 2017\u7b49\u6570\u636e\u96c6\u826f\u6027\u6d41\u91cf\u7ed3\u6784\uff0c\u4f7f\u7528HDBSCAN\u3001Mean Shift Clustering\u7b49\u65e0\u76d1\u7763\u805a\u7c7b\u6280\u672f\u5bf9\u826f\u6027\u6d41\u91cf\u7a7a\u95f4\u8fdb\u884c\u805a\u7c7b\u3002", "result": "\u6587\u6863\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u6863\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2509.09508", "pdf": "https://arxiv.org/pdf/2509.09508", "abs": "https://arxiv.org/abs/2509.09508", "authors": ["Avinash Agarwal", "Manisha J. Nene"], "title": "Incorporating AI Incident Reporting into Telecommunications Law and Policy: Insights from India", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "16 pages, 2 figures, 1 table", "summary": "The integration of artificial intelligence (AI) into telecommunications\ninfrastructure introduces novel risks, such as algorithmic bias and\nunpredictable system behavior, that fall outside the scope of traditional\ncybersecurity and data protection frameworks. This paper introduces a precise\ndefinition and a detailed typology of telecommunications AI incidents,\nestablishing them as a distinct category of risk that extends beyond\nconventional cybersecurity and data protection breaches. It argues for their\nrecognition as a distinct regulatory concern. Using India as a case study for\njurisdictions that lack a horizontal AI law, the paper analyzes the country's\nkey digital regulations. The analysis reveals that India's existing legal\ninstruments, including the Telecommunications Act, 2023, the CERT-In Rules, and\nthe Digital Personal Data Protection Act, 2023, focus on cybersecurity and data\nbreaches, creating a significant regulatory gap for AI-specific operational\nincidents, such as performance degradation and algorithmic bias. The paper also\nexamines structural barriers to disclosure and the limitations of existing AI\nincident repositories. Based on these findings, the paper proposes targeted\npolicy recommendations centered on integrating AI incident reporting into\nIndia's existing telecom governance. Key proposals include mandating reporting\nfor high-risk AI failures, designating an existing government body as a nodal\nagency to manage incident data, and developing standardized reporting\nframeworks. These recommendations aim to enhance regulatory clarity and\nstrengthen long-term resilience, offering a pragmatic and replicable blueprint\nfor other nations seeking to govern AI risks within their existing sectoral\nframeworks.", "AI": {"tldr": "\u672c\u6587\u5b9a\u4e49\u7535\u4fe1AI\u4e8b\u4ef6\uff0c\u4ee5\u5370\u5ea6\u4e3a\u4f8b\u6307\u51fa\u5176\u73b0\u6709\u6cd5\u89c4\u5b58\u5728AI\u7279\u5b9a\u8fd0\u8425\u4e8b\u4ef6\u76d1\u7ba1\u7f3a\u53e3\uff0c\u5206\u6790\u62ab\u9732\u969c\u788d\u4e0e\u73b0\u6709AI\u4e8b\u4ef6\u5e93\u5c40\u9650\uff0c\u63d0\u51fa\u5c06AI\u4e8b\u4ef6\u62a5\u544a\u878d\u5165\u5370\u5ea6\u7535\u4fe1\u6cbb\u7406\u7684\u653f\u7b56\u5efa\u8bae\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u878d\u5165\u7535\u4fe1\u57fa\u7840\u8bbe\u65bd\u5e26\u6765\u65b0\u98ce\u9669\uff0c\u4f20\u7edf\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u4fdd\u62a4\u6846\u67b6\u65e0\u6cd5\u8986\u76d6\uff0c\u9700\u5c06\u7535\u4fe1AI\u4e8b\u4ef6\u4f5c\u4e3a\u72ec\u7279\u76d1\u7ba1\u95ee\u9898\u52a0\u4ee5\u5173\u6ce8\u3002", "method": "\u5bf9\u7535\u4fe1AI\u4e8b\u4ef6\u8fdb\u884c\u5b9a\u4e49\u548c\u5206\u7c7b\uff0c\u4ee5\u5370\u5ea6\u4e3a\u6848\u4f8b\u5206\u6790\u5176\u5173\u952e\u6570\u5b57\u6cd5\u89c4\uff0c\u7814\u7a76\u62ab\u9732\u7684\u7ed3\u6784\u969c\u788d\u548c\u73b0\u6709AI\u4e8b\u4ef6\u5e93\u7684\u5c40\u9650\u6027\u3002", "result": "\u5370\u5ea6\u73b0\u6709\u6cd5\u5f8b\u5de5\u5177\u805a\u7126\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u6cc4\u9732\uff0c\u5b58\u5728AI\u7279\u5b9a\u8fd0\u8425\u4e8b\u4ef6\u7684\u76d1\u7ba1\u7f3a\u53e3\uff1b\u73b0\u6709AI\u4e8b\u4ef6\u5e93\u6709\u5c40\u9650\u6027\u3002", "conclusion": "\u63d0\u51fa\u5c06AI\u4e8b\u4ef6\u62a5\u544a\u878d\u5165\u5370\u5ea6\u73b0\u6709\u7535\u4fe1\u6cbb\u7406\u7684\u653f\u7b56\u5efa\u8bae\uff0c\u589e\u5f3a\u76d1\u7ba1\u6e05\u6670\u5ea6\u548c\u957f\u671f\u6062\u590d\u529b\uff0c\u4e3a\u5176\u4ed6\u56fd\u5bb6\u63d0\u4f9b\u53ef\u590d\u5236\u84dd\u56fe\u3002"}}
{"id": "2509.09583", "pdf": "https://arxiv.org/pdf/2509.09583", "abs": "https://arxiv.org/abs/2509.09583", "authors": ["Brittany Harbison", "Samuel Taubman", "Travis Taylor", "Ashok. K. Goel"], "title": "Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.LG", "cs.SI"], "comment": null, "summary": "Social connection is a vital part of learning, yet online course environments\npresent barriers to the organic formation of social groups. SAMI offers one\nsolution by facilitating student connections, but its effectiveness is\nconstrained by an incomplete Theory of Mind, limiting its ability to create an\neffective mental model of a student. One facet of this is its inability to\nintuit personality, which may influence the relevance of its recommendations.\nTo explore this, we propose a personality detection model utilizing GPTs\nzero-shot capability to infer Big-Five personality traits from forum\nintroduction posts, often encouraged in online courses. We benchmark its\nperformance against established models, demonstrating its efficacy in this\ntask. Furthermore, we integrate this model into SAMIs entity-based matchmaking\nsystem, enabling personality-informed social recommendations. Initial\nintegration suggests personality traits can complement existing matching\nfactors, though additional evaluation is required to determine their full\nimpact on student engagement and match quality.", "AI": {"tldr": "\u5728\u7ebf\u8bfe\u7a0b\u793e\u4ea4\u7ec4\u5f62\u6210\u6709\u969c\u788d\uff0cSAMI\u89e3\u51b3\u529e\u6cd5\u6709\u9650\uff0c\u672c\u6587\u63d0\u51fa\u7528GPT\u96f6\u6837\u672c\u80fd\u529b\u68c0\u6d4b\u4e2a\u6027\u7684\u6a21\u578b\uff0c\u96c6\u6210\u5230SAMI\u7cfb\u7edf\uff0c\u521d\u6b65\u663e\u793a\u4e2a\u6027\u7279\u8d28\u53ef\u8865\u5145\u73b0\u6709\u5339\u914d\u56e0\u7d20\u3002", "motivation": "SAMI\u56e0\u4e0d\u5b8c\u6574\u5fc3\u667a\u7406\u8bba\u9650\u5236\u5b66\u751f\u793e\u4ea4\u8fde\u63a5\u6709\u6548\u6027\uff0c\u4e14\u65e0\u6cd5\u63a8\u65ad\u4e2a\u6027\u5f71\u54cd\u63a8\u8350\u76f8\u5173\u6027\uff0c\u9700\u63a2\u7d22\u89e3\u51b3\u529e\u6cd5\u3002", "method": "\u63d0\u51fa\u5229\u7528GPT\u96f6\u6837\u672c\u80fd\u529b\u4ece\u8bba\u575b\u4ecb\u7ecd\u5e16\u63a8\u65ad\u5927\u4e94\u4eba\u683c\u7279\u8d28\u7684\u4e2a\u6027\u68c0\u6d4b\u6a21\u578b\uff0c\u5e76\u4e0e\u65e2\u6709\u6a21\u578b\u5bf9\u6bd4\uff0c\u5c06\u8be5\u6a21\u578b\u96c6\u6210\u5230SAMI\u5b9e\u4f53\u5339\u914d\u7cfb\u7edf\u3002", "result": "\u8be5\u4e2a\u6027\u68c0\u6d4b\u6a21\u578b\u5728\u63a8\u65ad\u4e2a\u6027\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u96c6\u6210\u5230SAMI\u7cfb\u7edf\u540e\u4e2a\u6027\u7279\u8d28\u53ef\u8865\u5145\u73b0\u6709\u5339\u914d\u56e0\u7d20\u3002", "conclusion": "\u4e2a\u6027\u7279\u8d28\u6709\u6f5c\u529b\u589e\u5f3aSAMI\u793e\u4ea4\u63a8\u8350\uff0c\u4f46\u9700\u66f4\u591a\u8bc4\u4f30\u786e\u5b9a\u5bf9\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u5339\u914d\u8d28\u91cf\u7684\u5168\u9762\u5f71\u54cd\u3002"}}
{"id": "2509.09594", "pdf": "https://arxiv.org/pdf/2509.09594", "abs": "https://arxiv.org/abs/2509.09594", "authors": ["Sourav Garg", "Dustin Craggs", "Vineeth Bhat", "Lachlan Mares", "Stefan Podgorski", "Madhava Krishna", "Feras Dayoub", "Ian Reid"], "title": "ObjectReact: Learning Object-Relative Control for Visual Navigation", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": "CoRL 2025; 23 pages including appendix", "summary": "Visual navigation using only a single camera and a topological map has\nrecently become an appealing alternative to methods that require additional\nsensors and 3D maps. This is typically achieved through an \"image-relative\"\napproach to estimating control from a given pair of current observation and\nsubgoal image. However, image-level representations of the world have\nlimitations because images are strictly tied to the agent's pose and\nembodiment. In contrast, objects, being a property of the map, offer an\nembodiment- and trajectory-invariant world representation. In this work, we\npresent a new paradigm of learning \"object-relative\" control that exhibits\nseveral desirable characteristics: a) new routes can be traversed without\nstrictly requiring to imitate prior experience, b) the control prediction\nproblem can be decoupled from solving the image matching problem, and c) high\ninvariance can be achieved in cross-embodiment deployment for variations across\nboth training-testing and mapping-execution settings. We propose a topometric\nmap representation in the form of a \"relative\" 3D scene graph, which is used to\nobtain more informative object-level global path planning costs. We train a\nlocal controller, dubbed \"ObjectReact\", conditioned directly on a high-level\n\"WayObject Costmap\" representation that eliminates the need for an explicit RGB\ninput. We demonstrate the advantages of learning object-relative control over\nits image-relative counterpart across sensor height variations and multiple\nnavigation tasks that challenge the underlying spatial understanding\ncapability, e.g., navigating a map trajectory in the reverse direction. We\nfurther show that our sim-only policy is able to generalize well to real-world\nindoor environments. Code and supplementary material are accessible via project\npage: https://object-react.github.io/", "AI": {"tldr": "\u63d0\u51fa\u5b66\u4e60\u2018\u7269\u4f53\u76f8\u5bf9\u2019\u63a7\u5236\u7684\u65b0\u8303\u5f0f\uff0c\u7528\u76f8\u5bf93D\u573a\u666f\u56fe\u7684\u62d3\u6251\u5ea6\u91cf\u5730\u56fe\u8868\u793a\uff0c\u8bad\u7ec3\u5c40\u90e8\u63a7\u5236\u5668ObjectReact\uff0c\u8bc1\u660e\u5176\u4f18\u4e8e\u56fe\u50cf\u76f8\u5bf9\u63a7\u5236\uff0c\u4e14\u4eff\u771f\u7b56\u7565\u80fd\u6cdb\u5316\u5230\u73b0\u5b9e\u73af\u5883\u3002", "motivation": "\u56fe\u50cf\u7ea7\u4e16\u754c\u8868\u793a\u6709\u5c40\u9650\u6027\uff0c\u800c\u7269\u4f53\u80fd\u63d0\u4f9b\u4e0e\u5177\u8eab\u548c\u8f68\u8ff9\u65e0\u5173\u7684\u4e16\u754c\u8868\u793a\uff0c\u56e0\u6b64\u63a2\u7d22\u5b66\u4e60\u2018\u7269\u4f53\u76f8\u5bf9\u2019\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u76f8\u5bf93D\u573a\u666f\u56fe\u5f62\u5f0f\u7684\u62d3\u6251\u5ea6\u91cf\u5730\u56fe\u8868\u793a\uff0c\u8bad\u7ec3\u57fa\u4e8e\u9ad8\u7ea7\u2018WayObject Costmap\u2019\u8868\u793a\u7684\u5c40\u90e8\u63a7\u5236\u5668ObjectReact\u3002", "result": "\u5728\u4f20\u611f\u5668\u9ad8\u5ea6\u53d8\u5316\u548c\u591a\u79cd\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u7269\u4f53\u76f8\u5bf9\u63a7\u5236\u4f18\u4e8e\u56fe\u50cf\u76f8\u5bf9\u63a7\u5236\uff0c\u4e14\u4eff\u771f\u7b56\u7565\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u5230\u73b0\u5b9e\u5ba4\u5185\u73af\u5883\u3002", "conclusion": "\u5b66\u4e60\u2018\u7269\u4f53\u76f8\u5bf9\u2019\u63a7\u5236\u5177\u6709\u591a\u79cd\u4f18\u52bf\uff0c\u5728\u4e0d\u540c\u573a\u666f\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4e14\u4eff\u771f\u7b56\u7565\u53ef\u5e94\u7528\u4e8e\u73b0\u5b9e\u73af\u5883\u3002"}}
{"id": "2509.09522", "pdf": "https://arxiv.org/pdf/2509.09522", "abs": "https://arxiv.org/abs/2509.09522", "authors": ["Vadim Zadykian", "Bruno Andrade", "Haithem Afli"], "title": "Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Semantic Textual Relatedness (STR) captures nuanced relationships between\ntexts that extend beyond superficial lexical similarity. In this study, we\ninvestigate STR in the context of job title matching - a key challenge in\nresume recommendation systems, where overlapping terms are often limited or\nmisleading. We introduce a self-supervised hybrid architecture that combines\ndense sentence embeddings with domain-specific Knowledge Graphs (KGs) to\nimprove both semantic alignment and explainability. Unlike previous work that\nevaluated models on aggregate performance, our approach emphasizes data\nstratification by partitioning the STR score continuum into distinct regions:\nlow, medium, and high semantic relatedness. This stratified evaluation enables\na fine-grained analysis of model performance across semantically meaningful\nsubspaces. We evaluate several embedding models, both with and without KG\nintegration via graph neural networks. The results show that fine-tuned SBERT\nmodels augmented with KGs produce consistent improvements in the high-STR\nregion, where the RMSE is reduced by 25% over strong baselines. Our findings\nhighlight not only the benefits of combining KGs with text embeddings, but also\nthe importance of regional performance analysis in understanding model\nbehavior. This granular approach reveals strengths and weaknesses hidden by\nglobal metrics, and supports more targeted model selection for use in Human\nResources (HR) systems and applications where fairness, explainability, and\ncontextual matching are essential.", "AI": {"tldr": "\u7814\u7a76\u5728\u804c\u4f4d\u5339\u914d\u4e2d\u5229\u7528\u81ea\u76d1\u7763\u6df7\u5408\u67b6\u6784\u7ed3\u5408\u53e5\u5b50\u5d4c\u5165\u548c\u77e5\u8bc6\u56fe\u8c31\u63d0\u5347\u8bed\u4e49\u6587\u672c\u76f8\u5173\u6027\uff0c\u5206\u5c42\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u7ed3\u679c\u663e\u793aKG\u589e\u5f3a\u7684SBERT\u6a21\u578b\u5728\u9ad8\u76f8\u5173\u6027\u533a\u57df\u6709\u6539\u5584\u3002", "motivation": "\u89e3\u51b3\u7b80\u5386\u63a8\u8350\u7cfb\u7edf\u4e2d\u804c\u4f4d\u5339\u914d\u7684\u6311\u6218\uff0c\u5904\u7406\u6587\u672c\u91cd\u53e0\u5c11\u6216\u6709\u8bef\u5bfc\u6027\u7684\u95ee\u9898\uff0c\u63d0\u5347\u8bed\u4e49\u5bf9\u9f50\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f15\u5165\u81ea\u76d1\u7763\u6df7\u5408\u67b6\u6784\uff0c\u7ed3\u5408\u5bc6\u96c6\u53e5\u5b50\u5d4c\u5165\u548c\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\uff0c\u5bf9\u8bed\u4e49\u76f8\u5173\u6027\u5206\u6570\u8fdb\u884c\u5206\u5c42\u8bc4\u4f30\uff0c\u8bc4\u4f30\u591a\u79cd\u5d4c\u5165\u6a21\u578b\u3002", "result": "KG\u589e\u5f3a\u7684\u5fae\u8c03SBERT\u6a21\u578b\u5728\u9ad8\u76f8\u5173\u6027\u533a\u57df\u663e\u8457\u6539\u5584\uff0cRMSE\u6bd4\u5f3a\u57fa\u7ebf\u964d\u4f4e25%\u3002", "conclusion": "\u7ed3\u5408KG\u548c\u6587\u672c\u5d4c\u5165\u6709\u76ca\uff0c\u5206\u5c42\u6027\u80fd\u5206\u6790\u5bf9\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u91cd\u8981\uff0c\u6709\u52a9\u4e8eHR\u7cfb\u7edf\u7684\u6a21\u578b\u9009\u62e9\u3002"}}
{"id": "2509.09660", "pdf": "https://arxiv.org/pdf/2509.09660", "abs": "https://arxiv.org/abs/2509.09660", "authors": ["Mohsen Fayyaz", "Ali Modarressi", "Hanieh Deilamsalehy", "Franck Dernoncourt", "Ryan Rossi", "Trung Bui", "Hinrich Sch\u00fctze", "Nanyun Peng"], "title": "Steering MoE LLMs via Expert (De)Activation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token\nthrough a subset of specialized Feed-Forward Networks (FFN), known as experts.\nWe present SteerMoE, a framework for steering MoE models by detecting and\ncontrolling behavior-linked experts. Our detection method identifies experts\nwith distinct activation patterns across paired inputs exhibiting contrasting\nbehaviors. By selectively (de)activating such experts during inference, we\ncontrol behaviors like faithfulness and safety without retraining or modifying\nweights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to\n+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by\n-41% alone, and -100% when combined with existing jailbreak methods, bypassing\nall safety guardrails and exposing a new dimension of alignment faking hidden\nwithin experts.", "AI": {"tldr": "\u63d0\u51faSteerMoE\u6846\u67b6\u7528\u4e8e\u63a7\u5236\u5927\u8bed\u8a00\u6a21\u578b\u4e2dMoE\u7684\u884c\u4e3a\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u5b89\u5168\u6027\u548c\u5fe0\u5b9e\u5ea6\uff0c\u4e5f\u63ed\u793a\u4e86\u5bf9\u9f50\u9020\u5047\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u63a7\u5236MoE\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u5982\u5fe0\u5b9e\u5ea6\u548c\u5b89\u5168\u6027\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u4fee\u6539\u6743\u91cd\u3002", "method": "\u901a\u8fc7\u68c0\u6d4b\u5177\u6709\u4e0d\u540c\u6fc0\u6d3b\u6a21\u5f0f\u7684\u4e13\u5bb6\uff0c\u5728\u63a8\u7406\u65f6\u9009\u62e9\u6027\u6fc0\u6d3b\u6216\u505c\u7528\u8fd9\u4e9b\u4e13\u5bb6\u3002", "result": "\u572811\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c6\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5b89\u5168\u6027\u63d0\u5347\u8fbe20%\uff0c\u5fe0\u5b9e\u5ea6\u63d0\u5347\u8fbe27%\uff1b\u5728\u5bf9\u6297\u653b\u51fb\u6a21\u5f0f\u4e0b\uff0c\u5b89\u5168\u6027\u964d\u4f4e41%\uff0c\u4e0e\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u7ed3\u5408\u964d\u4f4e100%\u3002", "conclusion": "SteerMoE\u6846\u67b6\u53ef\u6709\u6548\u63a7\u5236MoE\u6a21\u578b\u884c\u4e3a\uff0c\u4f46\u4e5f\u66b4\u9732\u51fa\u4e13\u5bb6\u4e2d\u9690\u85cf\u7684\u5bf9\u9f50\u9020\u5047\u65b0\u95ee\u9898\u3002"}}
{"id": "2509.09547", "pdf": "https://arxiv.org/pdf/2509.09547", "abs": "https://arxiv.org/abs/2509.09547", "authors": ["Dohun Lee", "Hyeonho Jeong", "Jiwook Kim", "Duygu Ceylan", "Jong Chul Ye"], "title": "Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders", "categories": ["cs.CV", "cs.AI"], "comment": "17 pages, 14 figures", "summary": "Video diffusion models have advanced rapidly in the recent years as a result\nof series of architectural innovations (e.g., diffusion transformers) and use\nof novel training objectives (e.g., flow matching). In contrast, less attention\nhas been paid to improving the feature representation power of such models. In\nthis work, we show that training video diffusion models can benefit from\naligning the intermediate features of the video generator with feature\nrepresentations of pre-trained vision encoders. We propose a new metric and\nconduct an in-depth analysis of various vision encoders to evaluate their\ndiscriminability and temporal consistency, thereby assessing their suitability\nfor video feature alignment. Based on the analysis, we present Align4Gen which\nprovides a novel multi-feature fusion and alignment method integrated into\nvideo diffusion model training. We evaluate Align4Gen both for unconditional\nand class-conditional video generation tasks and show that it results in\nimproved video generation as quantified by various metrics. Full video results\nare available on our project page: https://align4gen.github.io/align4gen/", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAlign4Gen\u65b9\u6cd5\uff0c\u5c06\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u7279\u5f81\u4e0e\u89c6\u9891\u751f\u6210\u5668\u4e2d\u95f4\u7279\u5f81\u5bf9\u9f50\uff0c\u63d0\u5347\u89c6\u9891\u6269\u6563\u6a21\u578b\u7684\u89c6\u9891\u751f\u6210\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u89c6\u9891\u6269\u6563\u6a21\u578b\u5728\u63d0\u5347\u7279\u5f81\u8868\u793a\u80fd\u529b\u4e0a\u53d7\u5173\u6ce8\u8f83\u5c11\uff0c\u672c\u6587\u5e0c\u671b\u901a\u8fc7\u5c06\u89c6\u9891\u751f\u6210\u5668\u4e2d\u95f4\u7279\u5f81\u4e0e\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u7279\u5f81\u5bf9\u9f50\u6765\u6539\u8fdb\u6a21\u578b\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u65b0\u6307\u6807\u5206\u6790\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u8bc4\u4f30\u5176\u9002\u7528\u6027\uff1b\u63d0\u51faAlign4Gen\u591a\u7279\u5f81\u878d\u5408\u548c\u5bf9\u9f50\u65b9\u6cd5\u5e76\u96c6\u6210\u5230\u89c6\u9891\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u4e2d\u3002", "result": "\u5728\u65e0\u6761\u4ef6\u548c\u6709\u6761\u4ef6\u89c6\u9891\u751f\u6210\u4efb\u52a1\u4e2d\uff0cAlign4Gen\u7ecf\u591a\u79cd\u6307\u6807\u91cf\u5316\u663e\u793a\u63d0\u5347\u4e86\u89c6\u9891\u751f\u6210\u6548\u679c\u3002", "conclusion": "\u8bad\u7ec3\u89c6\u9891\u6269\u6563\u6a21\u578b\u65f6\u5c06\u89c6\u9891\u751f\u6210\u5668\u4e2d\u95f4\u7279\u5f81\u4e0e\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\u7279\u5f81\u5bf9\u9f50\u662f\u6709\u76ca\u7684\uff0cAlign4Gen\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2509.09674", "pdf": "https://arxiv.org/pdf/2509.09674", "abs": "https://arxiv.org/abs/2509.09674", "authors": ["Haozhan Li", "Yuxin Zuo", "Jiale Yu", "Yuhao Zhang", "Zhaohui Yang", "Kaiyan Zhang", "Xuekai Zhu", "Yuchen Zhang", "Tianxing Chen", "Ganqu Cui", "Dehui Wang", "Dingxiang Luo", "Yuchen Fan", "Youbang Sun", "Jia Zeng", "Jiangmiao Pang", "Shanghang Zhang", "Yu Wang", "Yao Mu", "Bowen Zhou", "Ning Ding"], "title": "SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Vision-Language-Action (VLA) models have recently emerged as a powerful\nparadigm for robotic manipulation. Despite substantial progress enabled by\nlarge-scale pretraining and supervised fine-tuning (SFT), these models face two\nfundamental challenges: (i) the scarcity and high cost of large-scale\nhuman-operated robotic trajectories required for SFT scaling, and (ii) limited\ngeneralization to tasks involving distribution shift. Recent breakthroughs in\nLarge Reasoning Models (LRMs) demonstrate that reinforcement learning (RL) can\ndramatically enhance step-by-step reasoning capabilities, raising a natural\nquestion: Can RL similarly improve the long-horizon step-by-step action\nplanning of VLA? In this work, we introduce SimpleVLA-RL, an efficient RL\nframework tailored for VLA models. Building upon veRL, we introduce\nVLA-specific trajectory sampling, scalable parallelization, multi-environment\nrendering, and optimized loss computation. When applied to OpenVLA-OFT,\nSimpleVLA-RL achieves SoTA performance on LIBERO and even outperforms $\\pi_0$\non RoboTwin 1.0\\&2.0 with the exploration-enhancing strategies we introduce.\nSimpleVLA-RL not only reduces dependence on large-scale data and enables robust\ngeneralization, but also remarkably surpasses SFT in real-world tasks.\nMoreover, we identify a novel phenomenon ``pushcut'' during RL training,\nwherein the policy discovers previously unseen patterns beyond those seen in\nthe previous training process. Github: https://github.com/PRIME-RL/SimpleVLA-RL", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.09675", "pdf": "https://arxiv.org/pdf/2509.09675", "abs": "https://arxiv.org/abs/2509.09675", "authors": ["Runpeng Dai", "Linfeng Song", "Haolin Liu", "Zhenwen Liang", "Dian Yu", "Haitao Mi", "Zhaopeng Tu", "Rui Liu", "Tong Zheng", "Hongtu Zhu", "Dong Yu"], "title": "CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "21 pages", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm\nfor enhancing the reasoning ability of Large Language Models (LLMs). Yet\ncurrent RLVR methods often explore poorly, leading to premature convergence and\nentropy collapse. To address this challenge, we introduce Curiosity-Driven\nExploration (CDE), a framework that leverages the model's own intrinsic sense\nof curiosity to guide exploration. We formalize curiosity with signals from\nboth the actor and the critic: for the actor, we use perplexity over its\ngenerated response, and for the critic, we use the variance of value estimates\nfrom a multi-head architecture. Both signals serve as an exploration bonus\nwithin the RLVR framework to guide the model. Our theoretical analysis shows\nthat the actor-wise bonus inherently penalizes overconfident errors and\npromotes diversity among correct responses; moreover, we connect the\ncritic-wise bonus to the well-established count-based exploration bonus in RL.\nEmpirically, our method achieves an approximate +3 point improvement over\nstandard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a\ncalibration collapse mechanism within RLVR, shedding light on common LLM\nfailure modes.", "AI": {"tldr": "\u63d0\u51faCDE\u6846\u67b6\u89e3\u51b3\u5f53\u524dRLVR\u65b9\u6cd5\u63a2\u7d22\u4e0d\u8db3\u95ee\u9898\uff0c\u7406\u8bba\u5206\u6790\u6709\u4f18\u52bf\uff0c\u5b9e\u8bc1\u5728AIME\u57fa\u51c6\u4e0a\u6709\u63d0\u5347\u5e76\u63ed\u793a\u6821\u51c6\u5d29\u6e83\u673a\u5236\u3002", "motivation": "\u5f53\u524dRLVR\u65b9\u6cd5\u63a2\u7d22\u6027\u5dee\uff0c\u5bfc\u81f4\u8fc7\u65e9\u6536\u655b\u548c\u71b5\u5d29\u6e83\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165CDE\u6846\u67b6\uff0c\u7528\u6f14\u5458\u7684\u56f0\u60d1\u5ea6\u548c\u8bc4\u8bba\u5bb6\u7684\u591a\u5934\u90e8\u67b6\u6784\u4ef7\u503c\u4f30\u8ba1\u65b9\u5dee\u4f5c\u4e3a\u63a2\u7d22\u5956\u52b1\u5f15\u5bfc\u6a21\u578b\u3002", "result": "\u5728AIME\u57fa\u51c6\u4e0a\u6bd4\u6807\u51c6RLVR\u7528GRPO/PPO\u63d0\u5347\u7ea63\u5206\uff0c\u53d1\u73b0RLVR\u5185\u6821\u51c6\u5d29\u6e83\u673a\u5236\u3002", "conclusion": "CDE\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3RLVR\u63a2\u7d22\u6027\u95ee\u9898\uff0c\u5bf9\u7406\u89e3LLM\u5931\u8d25\u6a21\u5f0f\u6709\u5e2e\u52a9\u3002"}}
{"id": "2509.09558", "pdf": "https://arxiv.org/pdf/2509.09558", "abs": "https://arxiv.org/abs/2509.09558", "authors": ["Akshit Achara", "Esther Puyol Anton", "Alexander Hammers", "Andrew P. King"], "title": "Invisible Attributes, Visible Biases: Exploring Demographic Shortcuts in MRI-based Alzheimer's Disease Classification", "categories": ["cs.CV", "cs.AI"], "comment": "FAIMI @ MICCAI 2025", "summary": "Magnetic resonance imaging (MRI) is the gold standard for brain imaging. Deep\nlearning (DL) algorithms have been proposed to aid in the diagnosis of diseases\nsuch as Alzheimer's disease (AD) from MRI scans. However, DL algorithms can\nsuffer from shortcut learning, in which spurious features, not directly related\nto the output label, are used for prediction. When these features are related\nto protected attributes, they can lead to performance bias against\nunderrepresented protected groups, such as those defined by race and sex. In\nthis work, we explore the potential for shortcut learning and demographic bias\nin DL based AD diagnosis from MRI. We first investigate if DL algorithms can\nidentify race or sex from 3D brain MRI scans to establish the presence or\notherwise of race and sex based distributional shifts. Next, we investigate\nwhether training set imbalance by race or sex can cause a drop in model\nperformance, indicating shortcut learning and bias. Finally, we conduct a\nquantitative and qualitative analysis of feature attributions in different\nbrain regions for both the protected attribute and AD classification tasks.\nThrough these experiments, and using multiple datasets and DL models (ResNet\nand SwinTransformer), we demonstrate the existence of both race and sex based\nshortcut learning and bias in DL based AD classification. Our work lays the\nfoundation for fairer DL diagnostic tools in brain MRI. The code is provided at\nhttps://github.com/acharaakshit/ShortMR", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8eMRI\u7684\u6df1\u5ea6\u5b66\u4e60\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8bca\u65ad\u4e2d\u6377\u5f84\u5b66\u4e60\u548c\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u5dee\uff0c\u8bc1\u5b9e\u5176\u5b58\u5728\uff0c\u4e3a\u516c\u5e73\u8bca\u65ad\u5de5\u5177\u5960\u57fa\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5728\u57fa\u4e8eMRI\u7684\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8bca\u65ad\u4e2d\u53ef\u80fd\u5b58\u5728\u6377\u5f84\u5b66\u4e60\u548c\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u6027\u80fd\u504f\u5dee\uff0c\u9700\u63a2\u7a76\u6b64\u95ee\u9898\u3002", "method": "\u5148\u7814\u7a76\u7b97\u6cd5\u80fd\u5426\u4ece3D\u8111MRI\u626b\u63cf\u4e2d\u8bc6\u522b\u79cd\u65cf\u6216\u6027\u522b\uff0c\u518d\u7814\u7a76\u8bad\u7ec3\u96c6\u4e0d\u5e73\u8861\u662f\u5426\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\uff0c\u6700\u540e\u5bf9\u4e0d\u540c\u8111\u533a\u7279\u5f81\u5f52\u56e0\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\uff0c\u4f7f\u7528\u591a\u6570\u636e\u96c6\u548cDL\u6a21\u578b\u3002", "result": "\u8bc1\u5b9e\u57fa\u4e8e\u79cd\u65cf\u548c\u6027\u522b\u7684\u6377\u5f84\u5b66\u4e60\u548c\u504f\u5dee\u5728\u57fa\u4e8eDL\u7684AD\u5206\u7c7b\u4e2d\u5b58\u5728\u3002", "conclusion": "\u4e3a\u8111MRI\u4e2d\u66f4\u516c\u5e73\u7684DL\u8bca\u65ad\u5de5\u5177\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.09593", "pdf": "https://arxiv.org/pdf/2509.09593", "abs": "https://arxiv.org/abs/2509.09593", "authors": ["Bangzhao Shu", "Isha Joshi", "Melissa Karnaze", "Anh C. Pham", "Ishita Kakkar", "Sindhu Kothe", "Arpine Hovasapian", "Mai ElSherief"], "title": "Fluent but Unfeeling: The Emotional Blind Spots of Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Camera-ready version for ICWSM 2026. First two authors contributed\n  equally", "summary": "The versatility of Large Language Models (LLMs) in natural language\nunderstanding has made them increasingly popular in mental health research.\nWhile many studies explore LLMs' capabilities in emotion recognition, a\ncritical gap remains in evaluating whether LLMs align with human emotions at a\nfine-grained level. Existing research typically focuses on classifying emotions\ninto predefined, limited categories, overlooking more nuanced expressions. To\naddress this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit\ncommunities featuring 251 fine-grained, self-disclosed emotion labels. Our\ncomprehensive evaluation framework examines predicted emotion terms and\ndecomposes them into eight basic emotions using established emotion theories,\nenabling a fine-grained comparison. Systematic testing of prevalent LLMs under\nvarious prompt settings reveals that accurately predicting emotions that align\nwith human self-disclosed emotions remains challenging. Qualitative analysis\nfurther shows that while certain LLMs generate emotion terms consistent with\nestablished emotion theories and definitions, they sometimes fail to capture\ncontextual cues as effectively as human self-disclosures. These findings\nhighlight the limitations of LLMs in fine-grained emotion alignment and offer\ninsights for future research aimed at enhancing their contextual understanding.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165EXPRESS\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u60c5\u611f\u5bf9\u9f50\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5728\u7ec6\u7c92\u5ea6\u5c42\u9762\u4e0e\u4eba\u7c7b\u60c5\u611f\u5bf9\u9f50\u5b58\u5728\u5dee\u8ddd\uff0c\u591a\u5173\u6ce8\u6709\u9650\u7684\u9884\u5b9a\u4e49\u60c5\u611f\u5206\u7c7b\uff0c\u5ffd\u7565\u4e86\u66f4\u7ec6\u5fae\u7684\u8868\u8fbe\u3002", "method": "\u5f15\u5165EXPRESS\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u91c7\u7528\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u7684\u60c5\u611f\u672f\u8bed\u5206\u89e3\u4e3a\u516b\u79cd\u57fa\u672c\u60c5\u611f\u8fdb\u884c\u7ec6\u7c92\u5ea6\u6bd4\u8f83\uff0c\u5e76\u5728\u4e0d\u540c\u63d0\u793a\u8bbe\u7f6e\u4e0b\u5bf9\u6d41\u884c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6d4b\u8bd5\u3002", "result": "\u51c6\u786e\u9884\u6d4b\u4e0e\u4eba\u7c7b\u81ea\u6211\u62ab\u9732\u60c5\u611f\u4e00\u81f4\u7684\u60c5\u7eea\u4ecd\u5177\u6311\u6218\u6027\uff0c\u90e8\u5206\u5927\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u751f\u6210\u7b26\u5408\u60c5\u611f\u7406\u8bba\u548c\u5b9a\u4e49\u7684\u60c5\u611f\u672f\u8bed\uff0c\u4f46\u5728\u6355\u6349\u4e0a\u4e0b\u6587\u7ebf\u7d22\u65b9\u9762\u4e0d\u5982\u4eba\u7c7b\u81ea\u6211\u62ab\u9732\u6709\u6548\u3002", "conclusion": "\u7814\u7a76\u51f8\u663e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u60c5\u611f\u5bf9\u9f50\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u63d0\u5347\u5176\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2509.09610", "pdf": "https://arxiv.org/pdf/2509.09610", "abs": "https://arxiv.org/abs/2509.09610", "authors": ["Daria Laslo", "Efthymios Georgiou", "Marius George Linguraru", "Andreas Rauschecker", "Sabine Muller", "Catherine R. Jutzeler", "Sarah Bruningk"], "title": "Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth", "categories": ["cs.CV", "cs.AI"], "comment": "13 pages, 4 figures", "summary": "Predicting the spatio-temporal progression of brain tumors is essential for\nguiding clinical decisions in neuro-oncology. We propose a hybrid mechanistic\nlearning framework that combines a mathematical tumor growth model with a\nguided denoising diffusion implicit model (DDIM) to synthesize anatomically\nfeasible future MRIs from preceding scans. The mechanistic model, formulated as\na system of ordinary differential equations, captures temporal tumor dynamics\nincluding radiotherapy effects and estimates future tumor burden. These\nestimates condition a gradient-guided DDIM, enabling image synthesis that\naligns with both predicted growth and patient anatomy. We train our model on\nthe BraTS adult and pediatric glioma datasets and evaluate on 60 axial slices\nof in-house longitudinal pediatric diffuse midline glioma (DMG) cases. Our\nframework generates realistic follow-up scans based on spatial similarity\nmetrics. It also introduces tumor growth probability maps, which capture both\nclinically relevant extent and directionality of tumor growth as shown by 95th\npercentile Hausdorff Distance. The method enables biologically informed image\ngeneration in data-limited scenarios, offering generative-space-time\npredictions that account for mechanistic priors.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u673a\u68b0\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u80bf\u7624\u751f\u957f\u6a21\u578b\u4e0eDDIM\u4ece\u5148\u524d\u626b\u63cf\u5408\u6210\u672a\u6765MRI\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u8bc4\u4f30\uff0c\u751f\u6210\u903c\u771f\u540e\u7eed\u626b\u63cf\u5e76\u5f15\u5165\u80bf\u7624\u751f\u957f\u6982\u7387\u56fe\u3002", "motivation": "\u9884\u6d4b\u8111\u80bf\u7624\u65f6\u7a7a\u8fdb\u5c55\u5bf9\u795e\u7ecf\u80bf\u7624\u5b66\u4e34\u5e8a\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u673a\u68b0\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u5e38\u5fae\u5206\u65b9\u7a0b\u7cfb\u7edf\u7684\u673a\u68b0\u6a21\u578b\u6355\u6349\u80bf\u7624\u65f6\u95f4\u52a8\u6001\uff0c\u4f30\u8ba1\u672a\u6765\u80bf\u7624\u8d1f\u8377\uff0c\u7528\u5176\u6761\u4ef6\u5316\u68af\u5ea6\u5f15\u5bfc\u7684DDIM\u8fdb\u884c\u56fe\u50cf\u5408\u6210\u3002", "result": "\u5728\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u8bc4\u4f30\uff0c\u6846\u67b6\u80fd\u57fa\u4e8e\u7a7a\u95f4\u76f8\u4f3c\u6027\u6307\u6807\u751f\u6210\u903c\u771f\u540e\u7eed\u626b\u63cf\uff0c\u5f15\u5165\u7684\u80bf\u7624\u751f\u957f\u6982\u7387\u56fe\u80fd\u4f53\u73b0\u80bf\u7624\u751f\u957f\u8303\u56f4\u548c\u65b9\u5411\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5728\u6570\u636e\u6709\u9650\u573a\u666f\u8fdb\u884c\u751f\u7269\u4fe1\u606f\u56fe\u50cf\u751f\u6210\uff0c\u63d0\u4f9b\u8003\u8651\u673a\u68b0\u5148\u9a8c\u7684\u65f6\u7a7a\u9884\u6d4b\u3002"}}
