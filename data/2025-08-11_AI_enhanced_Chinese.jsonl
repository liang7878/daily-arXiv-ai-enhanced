{"id": "2508.05731", "pdf": "https://arxiv.org/pdf/2508.05731", "abs": "https://arxiv.org/abs/2508.05731", "authors": ["Yuhang Liu", "Zeyu Liu", "Shuanghe Zhu", "Pengxiang Li", "Congkai Xie", "Jiasheng Wang", "Xueyu Hu", "Xiaotian Han", "Jianbo Yuan", "Xinyao Wang", "Shengyu Zhang", "Hongxia Yang", "Fei Wu"], "title": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization", "categories": ["cs.AI", "cs.CL"], "comment": "11 pages, 3 figures", "summary": "The emergence of Multimodal Large Language Models (MLLMs) has propelled the\ndevelopment of autonomous agents that operate on Graphical User Interfaces\n(GUIs) using pure visual input. A fundamental challenge is robustly grounding\nnatural language instructions. This requires a precise spatial alignment, which\naccurately locates the coordinates of each element, and, more critically, a\ncorrect semantic alignment, which matches the instructions to the functionally\nappropriate UI element. Although Reinforcement Learning with Verifiable Rewards\n(RLVR) has proven to be effective at improving spatial alignment for these\nMLLMs, we find that inefficient exploration bottlenecks semantic alignment,\nwhich prevent models from learning difficult semantic associations. To address\nthis exploration problem, we present Adaptive Exploration Policy Optimization\n(AEPO), a new policy optimization framework. AEPO employs a multi-answer\ngeneration strategy to enforce broader exploration, which is then guided by a\ntheoretically grounded Adaptive Exploration Reward (AER) function derived from\nfirst principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B\nand InfiGUI-G1-7B, establish new state-of-the-art results across multiple\nchallenging GUI grounding benchmarks, achieving significant relative\nimprovements of up to 9.0% against the naive RLVR baseline on benchmarks\ndesigned to test generalization and semantic understanding. Resources are\navailable at https://github.com/InfiXAI/InfiGUI-G1.", "AI": {"tldr": "\u63d0\u51faAEPO\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728GUI\u4e0a\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8bed\u4e49\u5bf9\u9f50\u7684\u63a2\u7d22\u95ee\u9898\uff0c\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u65b0\u7684\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8bed\u4e49\u5bf9\u9f50\u4e0a\u5b58\u5728\u4f4e\u6548\u63a2\u7d22\u74f6\u9888\uff0c\u5f71\u54cd\u6a21\u578b\u5b66\u4e60\u56f0\u96be\u8bed\u4e49\u5173\u8054\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u63a2\u7d22\u7b56\u7565\u4f18\u5316\uff08AEPO\uff09\u6846\u67b6\uff0c\u91c7\u7528\u591a\u7b54\u6848\u751f\u6210\u7b56\u7565\u8fdb\u884c\u66f4\u5e7f\u6cdb\u63a2\u7d22\uff0c\u5e76\u7531\u57fa\u4e8e\u6548\u7387\u539f\u5219\u63a8\u5bfc\u7684\u81ea\u9002\u5e94\u63a2\u7d22\u5956\u52b1\uff08AER\uff09\u51fd\u6570\u5f15\u5bfc\u3002", "result": "AEPO\u8bad\u7ec3\u7684InfiGUI - G1 - 3B\u548cInfiGUI - G1 - 7B\u6a21\u578b\u5728\u591a\u4e2aGUI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5efa\u7acb\u65b0\u7684\u6700\u4f18\u7ed3\u679c\uff0c\u76f8\u5bf9\u6734\u7d20RLVR\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "AEPO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728GUI\u4e0a\u8bed\u4e49\u5bf9\u9f50\u7684\u63a2\u7d22\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.05766", "pdf": "https://arxiv.org/pdf/2508.05766", "abs": "https://arxiv.org/abs/2508.05766", "authors": ["Bo Wen"], "title": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "nlin.AO"], "comment": null, "summary": "This paper proposes a novel framework for developing safe Artificial General\nIntelligence (AGI) by combining Active Inference principles with Large Language\nModels (LLMs). We argue that traditional approaches to AI safety, focused on\npost-hoc interpretability and reward engineering, have fundamental limitations.\nWe present an architecture where safety guarantees are integrated into the\nsystem's core design through transparent belief representations and\nhierarchical value alignment. Our framework leverages natural language as a\nmedium for representing and manipulating beliefs, enabling direct human\noversight while maintaining computational tractability. The architecture\nimplements a multi-agent system where agents self-organize according to Active\nInference principles, with preferences and safety constraints flowing through\nhierarchical Markov blankets. We outline specific mechanisms for ensuring\nsafety, including: (1) explicit separation of beliefs and preferences in\nnatural language, (2) bounded rationality through resource-aware free energy\nminimization, and (3) compositional safety through modular agent structures.\nThe paper concludes with a research agenda centered on the Abstraction and\nReasoning Corpus (ARC) benchmark, proposing experiments to validate our\nframework's safety properties. Our approach offers a path toward AGI\ndevelopment that is inherently safer, rather than retrofitted with safety\nmeasures.", "AI": {"tldr": "\u672c\u6587\u7ed3\u5408\u4e3b\u52a8\u63a8\u7406\u539f\u5219\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u5f00\u53d1\u5b89\u5168AGI\u7684\u65b0\u6846\u67b6\uff0c\u4ecb\u7ecd\u67b6\u6784\u3001\u5b89\u5168\u673a\u5236\u5e76\u63d0\u51fa\u7814\u7a76\u8bae\u7a0b\u3002", "motivation": "\u4f20\u7edfAI\u5b89\u5168\u65b9\u6cd5\u6709\u5c40\u9650\u6027\uff0c\u9700\u65b0\u9014\u5f84\u5f00\u53d1\u5b89\u5168AGI\u3002", "method": "\u7ed3\u5408\u4e3b\u52a8\u63a8\u7406\u539f\u5219\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u91c7\u7528\u81ea\u7136\u8bed\u8a00\u8868\u793a\u4fe1\u5ff5\uff0c\u63d0\u51fa\u5177\u4f53\u5b89\u5168\u673a\u5236\u3002", "result": "\u63d0\u51fa\u4e86\u65b0\u7684AGI\u5f00\u53d1\u6846\u67b6\u53ca\u5177\u4f53\u5b89\u5168\u673a\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aAGI\u5f00\u53d1\u63d0\u4f9b\u672c\u8d28\u5b89\u5168\u7684\u8def\u5f84\uff0c\u56f4\u7ed5ARC\u57fa\u51c6\u63d0\u51fa\u9a8c\u8bc1\u6846\u67b6\u5b89\u5168\u7279\u6027\u7684\u7814\u7a76\u8bae\u7a0b\u3002"}}
{"id": "2508.05776", "pdf": "https://arxiv.org/pdf/2508.05776", "abs": "https://arxiv.org/abs/2508.05776", "authors": ["Thomas L. Griffiths", "Brenden M. Lake", "R. Thomas McCoy", "Ellie Pavlick", "Taylor W. Webb"], "title": "Whither symbols in the era of advanced neural networks?", "categories": ["cs.AI"], "comment": null, "summary": "Some of the strongest evidence that human minds should be thought about in\nterms of symbolic systems has been the way they combine ideas, produce novelty,\nand learn quickly. We argue that modern neural networks -- and the artificial\nintelligence systems built upon them -- exhibit similar abilities. This\nundermines the argument that the cognitive processes and representations used\nby human minds are symbolic, although the fact that these neural networks are\ntypically trained on data generated by symbolic systems illustrates that such\nsystems play an important role in characterizing the abstract problems that\nhuman minds have to solve. This argument leads us to offer a new agenda for\nresearch on the symbolic basis of human thought.", "AI": {"tldr": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u6709\u7c7b\u4f3c\u4eba\u7c7b\u601d\u7ef4\u7ec4\u5408\u3001\u521b\u65b0\u548c\u5feb\u901f\u5b66\u4e60\u80fd\u529b\uff0c\u6311\u6218\u4eba\u7c7b\u601d\u7ef4\u662f\u7b26\u53f7\u7cfb\u7edf\u89c2\u70b9\u5e76\u63d0\u51fa\u65b0\u7814\u7a76\u8bae\u7a0b", "motivation": "\u63a2\u8ba8\u4eba\u7c7b\u601d\u7ef4\u662f\u5426\u57fa\u4e8e\u7b26\u53f7\u7cfb\u7edf", "method": "\u5bf9\u6bd4\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u4e0e\u4eba\u7c7b\u601d\u7ef4\u80fd\u529b", "result": "\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u6709\u7c7b\u4f3c\u4eba\u7c7b\u601d\u7ef4\u80fd\u529b\uff0c\u524a\u5f31\u4eba\u7c7b\u601d\u7ef4\u662f\u7b26\u53f7\u7cfb\u7edf\u89c2\u70b9", "conclusion": "\u63d0\u51fa\u5173\u4e8e\u4eba\u7c7b\u601d\u7ef4\u7b26\u53f7\u57fa\u7840\u7814\u7a76\u7684\u65b0\u8bae\u7a0b"}}
{"id": "2508.05792", "pdf": "https://arxiv.org/pdf/2508.05792", "abs": "https://arxiv.org/abs/2508.05792", "authors": ["Kausik Lakkaraju", "Siva Likitha Valluru", "Biplav Srivastava"], "title": "Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making", "categories": ["cs.AI"], "comment": null, "summary": "Current eXplainable AI (XAI) methods largely serve developers, often focusing\non justifying model outputs rather than supporting diverse stakeholder needs. A\nrecent shift toward Evaluative AI reframes explanation as a tool for hypothesis\ntesting, but still focuses primarily on operational organizations. We introduce\nHolistic-XAI (H-XAI), a unified framework that integrates causal rating methods\nwith traditional XAI methods to support explanation as an interactive,\nmulti-method process. H-XAI allows stakeholders to ask a series of questions,\ntest hypotheses, and compare model behavior against automatically constructed\nrandom and biased baselines. It combines instance-level and global\nexplanations, adapting to each stakeholder's goals, whether understanding\nindividual decisions, assessing group-level bias, or evaluating robustness\nunder perturbations. We demonstrate the generality of our approach through two\ncase studies spanning six scenarios: binary credit risk classification and\nfinancial time-series forecasting. H-XAI fills critical gaps left by existing\nXAI methods by combining causal ratings and post-hoc explanations to answer\nstakeholder-specific questions at both the individual decision level and the\noverall model level.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Holistic - XAI (H - XAI)\u6846\u67b6\uff0c\u7ed3\u5408\u56e0\u679c\u8bc4\u7ea7\u548c\u4f20\u7edfXAI\u65b9\u6cd5\uff0c\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u5176\u901a\u7528\u6027\uff0c\u5f25\u8865\u73b0\u6709XAI\u65b9\u6cd5\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91caAI\u65b9\u6cd5\u4e3b\u8981\u670d\u52a1\u5f00\u53d1\u8005\uff0c\u591a\u5173\u6ce8\u6a21\u578b\u8f93\u51fa\u5408\u7406\u6027\uff0c\u4e0d\u80fd\u6ee1\u8db3\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u9700\u6c42\uff0cEvaluative AI\u4e5f\u4e3b\u8981\u5173\u6ce8\u8fd0\u8425\u7ec4\u7ec7\u3002", "method": "\u5f15\u5165H - XAI\u6846\u67b6\uff0c\u96c6\u6210\u56e0\u679c\u8bc4\u7ea7\u65b9\u6cd5\u4e0e\u4f20\u7edfXAI\u65b9\u6cd5\uff0c\u652f\u6301\u4ea4\u4e92\u5f0f\u3001\u591a\u65b9\u6cd5\u7684\u89e3\u91ca\u8fc7\u7a0b\uff0c\u7ed3\u5408\u5b9e\u4f8b\u7ea7\u548c\u5168\u5c40\u89e3\u91ca\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u6db5\u76d6\u516d\u4e2a\u573a\u666f\uff08\u4e8c\u5143\u4fe1\u7528\u98ce\u9669\u5206\u7c7b\u548c\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff09\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002", "conclusion": "H - XAI\u7ed3\u5408\u56e0\u679c\u8bc4\u7ea7\u548c\u4e8b\u540e\u89e3\u91ca\uff0c\u80fd\u5728\u4e2a\u4f53\u51b3\u7b56\u548c\u6574\u4f53\u6a21\u578b\u5c42\u9762\u56de\u7b54\u7279\u5b9a\u5229\u76ca\u76f8\u5173\u8005\u7684\u95ee\u9898\uff0c\u586b\u8865\u4e86\u73b0\u6709XAI\u65b9\u6cd5\u7684\u5173\u952e\u7a7a\u767d\u3002"}}
{"id": "2508.06077", "pdf": "https://arxiv.org/pdf/2508.06077", "abs": "https://arxiv.org/abs/2508.06077", "authors": ["Hongqin Lei", "Haowei Tang", "Zhe Zhang"], "title": "A Cross-Perspective Annotated Dataset for Dynamic Object-Level Attention Modeling in Cloud Gaming", "categories": ["cs.DB"], "comment": null, "summary": "Cloud gaming has gained popularity as it provides high-quality gaming\nexperiences on thin hardware, such as phones and tablets. Transmitting gameplay\nframes at high resolutions and ultra-low latency is the key to guaranteeing\nplayers' quality of experience (QoE). Numerous studies have explored deep\nlearning (DL) techniques to address this challenge. The efficiency of these\nDL-based approaches is highly affected by the dataset. However, existing\ndatasets usually focus on the positions of objects while ignoring semantic\nrelationships with other objects and their unique features. In this paper, we\npresent a game dataset by collecting gameplay clips from Grand Theft Auto (GTA)\nV, and annotating the player's interested objects during the gameplay. Based on\nthe collected data, we analyze several factors that have an impact on player's\ninterest and identify that the player's in-game speed, object's size, and\nobject's speed are the main factors. The dataset is available at\nhttps://drive.google.com/drive/folders/1idH251a2K-hGGd3pKjX-3Gx5o_rUqLC4?usp=sharing", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u300a\u4fa0\u76d7\u730e\u8f66\u624b5\u300b\u7684\u6e38\u620f\u6570\u636e\u96c6\uff0c\u5206\u6790\u5f71\u54cd\u73a9\u5bb6\u5174\u8da3\u7684\u56e0\u7d20\uff0c\u6570\u636e\u96c6\u516c\u5f00\u3002", "motivation": "\u4e91\u6e38\u620f\u4f20\u8f93\u9ad8\u5206\u8fa8\u7387\u548c\u8d85\u4f4e\u5ef6\u8fdf\u6e38\u620f\u5e27\u662f\u4fdd\u8bc1\u73a9\u5bb6\u4f53\u9a8c\u7684\u5173\u952e\uff0c\u73b0\u6709DL\u65b9\u6cd5\u53d7\u6570\u636e\u96c6\u5f71\u54cd\uff0c\u800c\u73b0\u6709\u6570\u636e\u96c6\u5ffd\u7565\u8bed\u4e49\u5173\u7cfb\u548c\u72ec\u7279\u7279\u5f81\u3002", "method": "\u6536\u96c6\u300a\u4fa0\u76d7\u730e\u8f66\u624b5\u300b\u7684\u6e38\u620f\u7247\u6bb5\uff0c\u6807\u6ce8\u73a9\u5bb6\u611f\u5174\u8da3\u7684\u5bf9\u8c61\uff0c\u5206\u6790\u5f71\u54cd\u73a9\u5bb6\u5174\u8da3\u7684\u56e0\u7d20\u3002", "result": "\u786e\u5b9a\u73a9\u5bb6\u6e38\u620f\u5185\u901f\u5ea6\u3001\u5bf9\u8c61\u5927\u5c0f\u548c\u5bf9\u8c61\u901f\u5ea6\u662f\u5f71\u54cd\u73a9\u5bb6\u5174\u8da3\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u65b0\u7684\u6e38\u620f\u6570\u636e\u96c6\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u4e91\u6e38\u620fDL\u65b9\u6cd5\u4e2d\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002"}}
{"id": "2508.06234", "pdf": "https://arxiv.org/pdf/2508.06234", "abs": "https://arxiv.org/abs/2508.06234", "authors": ["Chen Zhang", "Timothy LaRock", "Alben Rome Bagabaldo", "J\u00fcrgen Hackl"], "title": "Rethinking the Sioux Falls Network: Insights from Path-Driven Higher-Order Network Analysis", "categories": ["cs.CE"], "comment": null, "summary": "Benchmark scenarios are widely used in transportation research to evaluate\nrouting algorithms, simulate infrastructure interventions, and test new\ntechnologies under controlled conditions. However, the structural and\nbehavioral fidelity of these benchmarks remains largely unquantified, raising\nconcerns about the external validity of simulation results. In this study, we\nintroduce a mathematical framework based on higher-order network models to\nevaluate the representativeness of benchmark networks, focusing on the widely\nused Sioux Falls scenario. Higher-order network models encode empirical and\nsimulated trajectory data into memory-aware network representations, which we\nuse to quantify sequential dependencies in mobility behavior and assess how\nwell benchmark networks capture real-world structural and functional patterns.\nApplying this framework to the Sioux Falls network, as well as real-world\ntrajectory data, we quantify structural complexity, optimal memory length, link\nprediction accuracy, and centrality alignment. Our results show and\nstatistically quantify that the classical Sioux Falls network exhibits limited\npath diversity, rapid structural fragmentation at higher orders, and weak\nalignment with empirical routing behavior. These results illustrate the\npotential of higher-order network models to bridge the gap between\nsimulation-based and real-world mobility analysis, providing a robust\nfoundation for more accurate and generalizable insights in transportation\nresearch.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u57fa\u4e8e\u9ad8\u9636\u7f51\u7edc\u6a21\u578b\u7684\u6570\u5b66\u6846\u67b6\u8bc4\u4f30\u57fa\u51c6\u7f51\u7edc\u4ee3\u8868\u6027\uff0c\u4ee5\u82cf\u798f\u5c14\u65af\u573a\u666f\u4e3a\u4f8b\uff0c\u7ed3\u679c\u663e\u793a\u7ecf\u5178\u7f51\u7edc\u5b58\u5728\u5c40\u9650\uff0c\u9ad8\u9636\u6a21\u578b\u53ef\u5f25\u5408\u6a21\u62df\u4e0e\u73b0\u5b9e\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u4ea4\u901a\u7814\u7a76\u4e2d\u57fa\u51c6\u573a\u666f\u7ed3\u6784\u548c\u884c\u4e3a\u4fdd\u771f\u5ea6\u672a\u91cf\u5316\uff0c\u6a21\u62df\u7ed3\u679c\u5916\u90e8\u6709\u6548\u6027\u5b58\u7591\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u9ad8\u9636\u7f51\u7edc\u6a21\u578b\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5c06\u7ecf\u9a8c\u548c\u6a21\u62df\u8f68\u8ff9\u6570\u636e\u7f16\u7801\u4e3a\u6709\u8bb0\u5fc6\u7684\u7f51\u7edc\u8868\u793a\uff0c\u4ee5\u91cf\u5316\u79fb\u52a8\u884c\u4e3a\u7684\u987a\u5e8f\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u7ecf\u5178\u82cf\u798f\u5c14\u65af\u7f51\u7edc\u8def\u5f84\u591a\u6837\u6027\u6709\u9650\u3001\u9ad8\u9636\u65f6\u7ed3\u6784\u5feb\u901f\u788e\u7247\u5316\u3001\u4e0e\u7ecf\u9a8c\u8def\u7531\u884c\u4e3a\u5bf9\u9f50\u5f31\u3002", "conclusion": "\u9ad8\u9636\u7f51\u7edc\u6a21\u578b\u53ef\u5f25\u5408\u6a21\u62df\u4e0e\u73b0\u5b9e\u79fb\u52a8\u5206\u6790\u7684\u5dee\u8ddd\uff0c\u4e3a\u4ea4\u901a\u7814\u7a76\u63d0\u4f9b\u66f4\u51c6\u786e\u548c\u53ef\u63a8\u5e7f\u7684\u89c1\u89e3\u3002"}}
{"id": "2508.05797", "pdf": "https://arxiv.org/pdf/2508.05797", "abs": "https://arxiv.org/abs/2508.05797", "authors": ["Sreeharsha Udayashankar", "Abdelrahman Baba", "Samer Al-Kiswany"], "title": "Accelerating Data Chunking in Deduplication Systems using Vector Instructions", "categories": ["cs.DC", "cs.AR"], "comment": "Under review. This is the follow-up work to our FAST 2025 paper,\n  \"VectorCDC: Accelerating Data Deduplication with Vector Instructions\". The\n  associated code is available at https://github.com/UWASL/dedup-bench", "summary": "Content-defined Chunking (CDC) algorithms dictate the overall space savings\nthat deduplication systems achieve. However, due to their need to scan each\nfile in its entirety, they are slow and often the main performance bottleneck\nwithin data deduplication. We present VectorCDC, a method to accelerate\nhashless CDC algorithms using vector CPU instructions, such as SSE / AVX. Our\nevaluation shows that VectorCDC is effective on Intel, AMD, ARM, and IBM CPUs,\nachieving 8.35x - 26.2x higher throughput than existing vector-accelerated\ntechniques without affecting the deduplication space savings.", "AI": {"tldr": "\u63d0\u51faVectorCDC\u65b9\u6cd5\u52a0\u901f\u65e0\u54c8\u5e0cCDC\u7b97\u6cd5\uff0c\u5728\u591a\u7c7b\u578bCPU\u4e0a\u6709\u6548\u4e14\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709\u5185\u5bb9\u5b9a\u4e49\u5206\u5757\uff08CDC\uff09\u7b97\u6cd5\u626b\u63cf\u6587\u4ef6\u6162\uff0c\u662f\u6570\u636e\u53bb\u91cd\u6027\u80fd\u74f6\u9888\u3002", "method": "\u4f7f\u7528\u5411\u91cfCPU\u6307\u4ee4\uff08\u5982SSE / AVX\uff09\u52a0\u901f\u65e0\u54c8\u5e0cCDC\u7b97\u6cd5\u7684VectorCDC\u65b9\u6cd5\u3002", "result": "VectorCDC\u5728Intel\u3001AMD\u3001ARM\u548cIBM CPU\u4e0a\u6709\u6548\uff0c\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u5411\u91cf\u52a0\u901f\u6280\u672f\u9ad88.35 - 26.2\u500d\uff0c\u4e0d\u5f71\u54cd\u53bb\u91cd\u7a7a\u95f4\u8282\u7701\u3002", "conclusion": "VectorCDC\u65b9\u6cd5\u80fd\u6709\u6548\u52a0\u901f\u65e0\u54c8\u5e0cCDC\u7b97\u6cd5\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.05844", "pdf": "https://arxiv.org/pdf/2508.05844", "abs": "https://arxiv.org/abs/2508.05844", "authors": ["Fran\u00e7ois Bachoc", "Nicol\u00f2 Cesa-Bianchi", "Tommaso Cesari", "Roberto Colomboni"], "title": "Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding", "categories": ["cs.GT", "cs.LG", "stat.ML"], "comment": null, "summary": "Motivated by applications in crowdsourcing, where a fixed sum of money is\nsplit among $K$ workers, and autobidding, where a fixed budget is used to bid\nin $K$ simultaneous auctions, we define a stochastic bandit model where arms\nbelong to the $K$-dimensional probability simplex and represent the fraction of\nbudget allocated to each task/auction. The reward in each round is the sum of\n$K$ stochastic rewards, where each of these rewards is unlocked with a\nprobability that varies with the fraction of the budget allocated to that\ntask/auction. We design an algorithm whose expected regret after $T$ steps is\nof order $K\\sqrt{T}$ (up to log factors) and prove a matching lower bound.\nImproved bounds of order $K (\\log T)^2$ are shown when the function mapping\nbudget to probability of unlocking the reward (i.e., terminating the task or\nwinning the auction) satisfies additional diminishing-returns conditions.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4f17\u5305\u548c\u81ea\u52a8\u7ade\u4ef7\u573a\u666f\u5b9a\u4e49\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u6a21\u578b\uff0c\u8bbe\u8ba1\u7b97\u6cd5\u5e76\u7ed9\u51fa\u671f\u671b\u9057\u61be\u4e0a\u754c\u548c\u5339\u914d\u4e0b\u754c\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6709\u6539\u8fdb\u754c\u3002", "motivation": "\u53d7\u4f17\u5305\u4e2d\u8d44\u91d1\u5206\u914d\u548c\u81ea\u52a8\u7ade\u4ef7\u4e2d\u9884\u7b97\u5206\u914d\u5e94\u7528\u573a\u666f\u7684\u542f\u53d1\uff0c\u5b9a\u4e49\u65b0\u7684\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u6a21\u578b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u5e76\u5bf9\u5176\u671f\u671b\u9057\u61be\u8fdb\u884c\u5206\u6790\uff0c\u8bc1\u660e\u5339\u914d\u7684\u4e0b\u754c\u3002", "result": "\u7b97\u6cd5\u7684\u671f\u671b\u9057\u61be\u5728T\u6b65\u540e\u4e3aK\u221aT\uff08\u542b\u5bf9\u6570\u56e0\u5b50\uff09\uff0c\u5728\u6ee1\u8db3\u989d\u5916\u6761\u4ef6\u65f6\u6539\u8fdb\u4e3aK(log T)^2\u3002", "conclusion": "\u6240\u8bbe\u8ba1\u7b97\u6cd5\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u80fd\u8fbe\u5230\u76f8\u5e94\u7684\u9057\u61be\u754c\u3002"}}
{"id": "2508.05920", "pdf": "https://arxiv.org/pdf/2508.05920", "abs": "https://arxiv.org/abs/2508.05920", "authors": ["Chris Cama\u00f1o", "Raphael A. Meyer", "Kevin Shu"], "title": "Debiasing Polynomial and Fourier Regression", "categories": ["cs.DS", "cs.NA", "math.NA", "65F99", "G.1.3"], "comment": null, "summary": "We study the problem of approximating an unknown function\n$f:\\mathbb{R}\\to\\mathbb{R}$ by a degree-$d$ polynomial using as few function\nevaluations as possible, where error is measured with respect to a probability\ndistribution $\\mu$. Existing randomized algorithms achieve near-optimal sample\ncomplexities to recover a $ (1+\\varepsilon) $-optimal polynomial but produce\nbiased estimates of the best polynomial approximation, which is undesirable.\n  We propose a simple debiasing method based on a connection between polynomial\nregression and random matrix theory. Our method involves evaluating\n$f(\\lambda_1),\\ldots,f(\\lambda_{d+1})$ where $\\lambda_1,\\ldots,\\lambda_{d+1}$\nare the eigenvalues of a suitably designed random complex matrix tailored to\nthe distribution $\\mu$. Our estimator is unbiased, has near-optimal sample\ncomplexity, and experimentally outperforms iid leverage score sampling.\n  Additionally, our techniques enable us to debias existing methods for\napproximating a periodic function with a truncated Fourier series with\nnear-optimal sample complexity.", "AI": {"tldr": "\u63d0\u51fa\u53bb\u504f\u65b9\u6cd5\uff0c\u7528\u6700\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u8fd1\u4f3c\u672a\u77e5\u51fd\u6570\uff0c\u8be5\u65b9\u6cd5\u65e0\u504f\u3001\u6837\u672c\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u4f18\uff0c\u8fd8\u80fd\u5bf9\u73b0\u6709\u5468\u671f\u51fd\u6570\u8fd1\u4f3c\u65b9\u6cd5\u53bb\u504f\u3002", "motivation": "\u73b0\u6709\u968f\u673a\u7b97\u6cd5\u5728\u6062\u590d(1 + \u03b5)-\u6700\u4f18\u591a\u9879\u5f0f\u65f6\u6837\u672c\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u4f18\uff0c\u4f46\u5bf9\u6700\u4f73\u591a\u9879\u5f0f\u8fd1\u4f3c\u7684\u4f30\u8ba1\u6709\u504f\u5dee\uff0c\u8fd9\u662f\u4e0d\u7406\u60f3\u7684\u3002", "method": "\u57fa\u4e8e\u591a\u9879\u5f0f\u56de\u5f52\u548c\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u53bb\u504f\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5408\u9002\u8bbe\u8ba1\u7684\u968f\u673a\u590d\u77e9\u9635\uff08\u9488\u5bf9\u5206\u5e03\u03bc\uff09\u7684\u7279\u5f81\u503c\u5bf9\u5e94\u7684\u51fd\u6570\u503c\u3002", "result": "\u6240\u63d0\u4f30\u8ba1\u5668\u65e0\u504f\uff0c\u6837\u672c\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u4f18\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u72ec\u7acb\u540c\u5206\u5e03\u6760\u6746\u5f97\u5206\u62bd\u6837\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0c\u8fd8\u80fd\u5bf9\u73b0\u6709\u7528\u622a\u65ad\u5085\u91cc\u53f6\u7ea7\u6570\u8fd1\u4f3c\u5468\u671f\u51fd\u6570\u7684\u65b9\u6cd5\u8fdb\u884c\u53bb\u504f\uff0c\u4e14\u6837\u672c\u590d\u6742\u5ea6\u63a5\u8fd1\u6700\u4f18\u3002"}}
{"id": "2508.05640", "pdf": "https://arxiv.org/pdf/2508.05640", "abs": "https://arxiv.org/abs/2508.05640", "authors": ["Liang Guo", "Wei Li", "Lucy Liao", "Huihui Cheng", "Rui Zhang", "Yu Shi", "Yueming Wang", "Yanzun Huang", "Keke Zhai", "Pengchao Wang", "Timothy Shi", "Xuan Cao", "Shengzhi Wang", "Renqin Cai", "Zhaojie Gong", "Omkar Vichare", "Rui Jian", "Leon Gao", "Shiyan Deng", "Xingyu Liu", "Xiong Zhang", "Fu Li", "Wenlei Xie", "Bin Wen", "Rui Li", "Xing Liu", "Jiaqi Zhai"], "title": "Request-Only Optimization for Recommendation Systems", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Deep Learning Recommendation Models (DLRMs) represent one of the largest\nmachine learning applications on the planet. Industry-scale DLRMs are trained\nwith petabytes of recommendation data to serve billions of users every day. To\nutilize the rich user signals in the long user history, DLRMs have been scaled\nup to unprecedented complexity, up to trillions of floating-point operations\n(TFLOPs) per example. This scale, coupled with the huge amount of training\ndata, necessitates new storage and training algorithms to efficiently improve\nthe quality of these complex recommendation systems. In this paper, we present\na Request-Only Optimizations (ROO) training and modeling paradigm. ROO\nsimultaneously improves the storage and training efficiency as well as the\nmodel quality of recommendation systems. We holistically approach this\nchallenge through co-designing data (i.e., request-only data), infrastructure\n(i.e., request-only based data processing pipeline), and model architecture\n(i.e., request-only neural architectures). Our ROO training and modeling\nparadigm treats a user request as a unit of the training data. Compared with\nthe established practice of treating a user impression as a unit, our new\ndesign achieves native feature deduplication in data logging, consequently\nsaving data storage. Second, by de-duplicating computations and communications\nacross multiple impressions in a request, this new paradigm enables highly\nscaled-up neural network architectures to better capture user interest signals,\nsuch as Generative Recommenders (GRs) and other request-only friendly\narchitectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRequest - Only Optimizations (ROO)\u8bad\u7ec3\u548c\u5efa\u6a21\u8303\u5f0f\uff0c\u53ef\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u5b58\u50a8\u3001\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u8d28\u91cf\u3002", "motivation": "DLRMs\u89c4\u6a21\u5927\u3001\u8bad\u7ec3\u6570\u636e\u591a\uff0c\u9700\u8981\u65b0\u7684\u5b58\u50a8\u548c\u8bad\u7ec3\u7b97\u6cd5\u6765\u63d0\u5347\u590d\u6742\u63a8\u8350\u7cfb\u7edf\u7684\u8d28\u91cf\u3002", "method": "\u901a\u8fc7\u5171\u540c\u8bbe\u8ba1\u6570\u636e\uff08\u8bf7\u6c42\u5f0f\u6570\u636e\uff09\u3001\u57fa\u7840\u8bbe\u65bd\uff08\u57fa\u4e8e\u8bf7\u6c42\u7684\u6570\u636e\u5904\u7406\u7ba1\u9053\uff09\u548c\u6a21\u578b\u67b6\u6784\uff08\u8bf7\u6c42\u5f0f\u795e\u7ecf\u67b6\u6784\uff09\uff0c\u5c06\u7528\u6237\u8bf7\u6c42\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u5355\u5143\u3002", "result": "\u5b9e\u73b0\u4e86\u6570\u636e\u8bb0\u5f55\u4e2d\u7684\u539f\u751f\u7279\u5f81\u53bb\u91cd\uff0c\u8282\u7701\u6570\u636e\u5b58\u50a8\uff1b\u53bb\u91cd\u8bf7\u6c42\u4e2d\u591a\u4e2a\u5c55\u793a\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\uff0c\u4f7f\u5927\u89c4\u6a21\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u80fd\u66f4\u597d\u6355\u6349\u7528\u6237\u5174\u8da3\u4fe1\u53f7\u3002", "conclusion": "ROO\u8bad\u7ec3\u548c\u5efa\u6a21\u8303\u5f0f\u80fd\u540c\u65f6\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u5b58\u50a8\u3001\u8bad\u7ec3\u6548\u7387\u4ee5\u53ca\u6a21\u578b\u8d28\u91cf\u3002"}}
{"id": "2508.05786", "pdf": "https://arxiv.org/pdf/2508.05786", "abs": "https://arxiv.org/abs/2508.05786", "authors": ["Yang Li", "Luopeiwen Yi", "Tananun Songdechakraiwut"], "title": "Functional Connectivity Graph Neural Networks", "categories": ["cs.NE"], "comment": "26 pages, 5 figures, 24 tables", "summary": "Real-world networks often benefit from capturing both local and global\ninteractions. Inspired by multi-modal analysis in brain imaging, where\nstructural and functional connectivity offer complementary views of network\norganization, we propose a graph neural network framework that generalizes this\napproach to other domains. Our method introduces a functional connectivity\nblock based on persistent graph homology to capture global topological\nfeatures. Combined with structural information, this forms a multi-modal\narchitecture called Functional Connectivity Graph Neural Networks. Experiments\nshow consistent performance gains over existing methods, demonstrating the\nvalue of brain-inspired representations for graph-level classification across\ndiverse networks.", "AI": {"tldr": "\u53d7\u8111\u6210\u50cf\u591a\u6a21\u6001\u5206\u6790\u542f\u53d1\uff0c\u63d0\u51fa\u529f\u80fd\u8fde\u63a5\u56fe\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7f51\u7edc\u9700\u6355\u6349\u5c40\u90e8\u548c\u5168\u5c40\u4ea4\u4e92\uff0c\u501f\u9274\u8111\u6210\u50cf\u591a\u6a21\u6001\u5206\u6790\u63a8\u5e7f\u5230\u5176\u4ed6\u9886\u57df\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u6301\u4e45\u56fe\u540c\u8c03\u7684\u529f\u80fd\u8fde\u63a5\u5757\u6355\u6349\u5168\u5c40\u62d3\u6251\u7279\u5f81\uff0c\u7ed3\u5408\u7ed3\u6784\u4fe1\u606f\u5f62\u6210\u591a\u6a21\u6001\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u7f51\u7edc\u7684\u56fe\u7ea7\u5206\u7c7b\u4e2d\u6027\u80fd\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8111\u542f\u53d1\u7684\u8868\u793a\u5bf9\u56fe\u7ea7\u5206\u7c7b\u6709\u4ef7\u503c\u3002"}}
{"id": "2508.06162", "pdf": "https://arxiv.org/pdf/2508.06162", "abs": "https://arxiv.org/abs/2508.06162", "authors": ["Zhi Hao Lim"], "title": "To Each Their Own: Heterogeneity in Worker Preferences for Peer Information", "categories": ["econ.GN", "q-fin.EC"], "comment": null, "summary": "Peer information is pervasive in the workplace, but workers differ in whether\nand why they value such information. We develop a portable, theory-driven\nmethodology to study heterogeneity in information preferences and the\nunderlying mechanisms. In a real-effort experiment with 793 workers, we elicit\nwillingness-to-pay for peer information delivered either before or after a\ntask. We identify four worker types (indifferent, stress-avoidant, competitive,\nand learning-oriented) whose effort responses align with theoretical\npredictions. Workers' stated motivations in free-text responses strongly\ncorrelate with their revealed preferences and behavior, validating our\nclassification. Notably, a nontrivial share (15%) strictly prefers to avoid\ninformation ex ante due to stress and exhibit no productivity gains from it.\nTailoring the timing of information by worker type improves welfare by up to\n48% relative to a uniform policy.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u65b9\u6cd5\u7814\u7a76\u5458\u5de5\u4fe1\u606f\u504f\u597d\u5f02\u8d28\u6027\uff0c\u8bc6\u522b\u56db\u79cd\u5458\u5de5\u7c7b\u578b\uff0c\u9a8c\u8bc1\u5206\u7c7b\uff0c\u53d1\u73b0\u90e8\u5206\u5458\u5de5\u56e0\u538b\u529b\u56de\u907f\u4fe1\u606f\uff0c\u6309\u7c7b\u578b\u8c03\u6574\u4fe1\u606f\u65f6\u673a\u53ef\u63d0\u5347\u798f\u5229\u3002", "motivation": "\u804c\u573a\u4e2d\u5458\u5de5\u5bf9\u540c\u4f34\u4fe1\u606f\u7684\u91cd\u89c6\u60c5\u51b5\u548c\u539f\u56e0\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u7814\u7a76\u4fe1\u606f\u504f\u597d\u5f02\u8d28\u6027\u53ca\u6f5c\u5728\u673a\u5236\u3002", "method": "\u5728\u6709793\u540d\u5458\u5de5\u53c2\u4e0e\u7684\u771f\u5b9e\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0c\u5f15\u51fa\u5458\u5de5\u5bf9\u4efb\u52a1\u524d\u540e\u540c\u4f34\u4fe1\u606f\u7684\u652f\u4ed8\u610f\u613f\u3002", "result": "\u8bc6\u522b\u51fa\u56db\u79cd\u5458\u5de5\u7c7b\u578b\uff0c\u5458\u5de5\u9648\u8ff0\u52a8\u673a\u4e0e\u504f\u597d\u548c\u884c\u4e3a\u5f3a\u76f8\u5173\uff0c15%\u5458\u5de5\u56e0\u538b\u529b\u4e8b\u524d\u56de\u907f\u4fe1\u606f\u4e14\u65e0\u751f\u4ea7\u7387\u63d0\u5347\uff0c\u6309\u7c7b\u578b\u8c03\u6574\u4fe1\u606f\u65f6\u673a\u798f\u5229\u6700\u9ad8\u63d0\u534748%\u3002", "conclusion": "\u5f00\u53d1\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u6309\u5458\u5de5\u7c7b\u578b\u8c03\u6574\u4fe1\u606f\u65f6\u673a\u80fd\u663e\u8457\u6539\u5584\u798f\u5229\u3002"}}
{"id": "2508.05693", "pdf": "https://arxiv.org/pdf/2508.05693", "abs": "https://arxiv.org/abs/2508.05693", "authors": ["Siamak Farshidi", "Amir Saberhabibi", "Behbod Eskafi", "Niloofar Nikfarjam", "Sadegh Eskandari", "Slinger Jansen", "Michel Chaudron", "Bedir Tekinerdogan"], "title": "Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Selecting third-party software packages in open-source ecosystems like Python\nis challenging due to the large number of alternatives and limited transparent\nevidence for comparison. Generative AI tools are increasingly used in\ndevelopment workflows, but their suggestions often overlook dependency\nevaluation, emphasize popularity over suitability, and lack reproducibility.\nThis creates risks for projects that require transparency, long-term\nreliability, maintainability, and informed architectural decisions. This study\nformulates software package selection as a Multi-Criteria Decision-Making\n(MCDM) problem and proposes a data-driven framework for technology evaluation.\nAutomated data pipelines continuously collect and integrate software metadata,\nusage trends, vulnerability information, and developer sentiment from GitHub,\nPyPI, and Stack Overflow. These data are structured into a decision model\nrepresenting relationships among packages, domain features, and quality\nattributes. The framework is implemented in PySelect, a decision support system\nthat uses large language models to interpret user intent and query the model to\nidentify contextually appropriate packages. The approach is evaluated using\n798,669 Python scripts from 16,887 GitHub repositories and a user study based\non the Technology Acceptance Model. Results show high data extraction\nprecision, improved recommendation quality over generative AI baselines, and\npositive user evaluations of usefulness and ease of use. This work introduces a\nscalable, interpretable, and reproducible framework that supports\nevidence-based software selection using MCDM principles, empirical data, and\nAI-assisted intent modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eMCDM\u7684\u6570\u636e\u9a71\u52a8\u6846\u67b6PySelect\u7528\u4e8ePython\u8f6f\u4ef6\u5305\u9009\u62e9\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u751f\u6210\u5f0fAI\uff0c\u7528\u6237\u8bc4\u4ef7\u79ef\u6781\u3002", "motivation": "\u5f00\u6e90\u751f\u6001\u4e2dPython\u7b2c\u4e09\u65b9\u8f6f\u4ef6\u5305\u9009\u62e9\u56f0\u96be\uff0c\u751f\u6210\u5f0fAI\u5de5\u5177\u5efa\u8bae\u5b58\u5728\u95ee\u9898\uff0c\u9879\u76ee\u9700\u8981\u53ef\u9760\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u5c06\u8f6f\u4ef6\u5305\u9009\u62e9\u89c6\u4e3aMCDM\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u7ba1\u9053\u6536\u96c6\u591a\u6e90\u6570\u636e\u6784\u5efa\u51b3\u7b56\u6a21\u578b\uff0c\u5b9e\u73b0\u51b3\u7b56\u652f\u6301\u7cfb\u7edfPySelect\u3002", "result": "\u6570\u636e\u63d0\u53d6\u7cbe\u5ea6\u9ad8\uff0c\u63a8\u8350\u8d28\u91cf\u4f18\u4e8e\u751f\u6210\u5f0fAI\u57fa\u7ebf\uff0c\u7528\u6237\u5bf9\u6709\u7528\u6027\u548c\u6613\u7528\u6027\u8bc4\u4ef7\u79ef\u6781\u3002", "conclusion": "\u5f15\u5165\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u3001\u53ef\u91cd\u73b0\u7684\u6846\u67b6\uff0c\u652f\u6301\u57fa\u4e8e\u8bc1\u636e\u7684\u8f6f\u4ef6\u9009\u62e9\u3002"}}
{"id": "2508.05659", "pdf": "https://arxiv.org/pdf/2508.05659", "abs": "https://arxiv.org/abs/2508.05659", "authors": ["Jeroen F. Uleman", "Loes Crielaard", "Leonie K. Elsenburg", "Guido A. Veldhuis", "Karien Stronks", "Naja Hulvej Rod", "Rick Quax", "V\u00edtor V. Vasconcelos"], "title": "Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "21 pages, 4 figures, 4 tables", "summary": "Causal loop diagrams (CLDs) are widely used in health and environmental\nresearch to represent hypothesized causal structures underlying complex\nproblems. However, as qualitative and static representations, CLDs are limited\nin their ability to support dynamic analysis and inform intervention\nstrategies. Additionally, quantitative CLD analysis methods like network\ncentrality analysis often lead to false inference. We propose\nDiagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory\nsystem dynamics models (SDMs) in the absence of empirical data. With minimal\nuser input - following a protocol to label variables as stocks,\nflows/auxiliaries, or constants - D2D leverages the structural information\nalready encoded in CLDs, namely, link existence and polarity, to simulate\nhypothetical interventions and explore potential leverage points under\nuncertainty. Results suggest that D2D helps distinguish between high- and\nlow-ranked leverage points. We compare D2D to a data-driven SDM constructed\nfrom the same CLD and variable labeling. D2D showed greater consistency with\nthe data-driven model than network centrality analysis, while providing\nuncertainty estimates and guidance for future data collection. The method is\nimplemented in an open-source Python package and a web-based application to\nsupport further testing and lower the barrier to dynamic modeling for\nresearchers working with CLDs. We expect additional validation will further\nestablish the approach's utility across a broad range of cases and domains.", "AI": {"tldr": "\u63d0\u51faDiagrams - to - Dynamics (D2D)\u65b9\u6cd5\u5c06\u56e0\u679c\u5faa\u73af\u56fe\u8f6c\u6362\u4e3a\u63a2\u7d22\u6027\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793aD2D\u6709\u52a9\u4e8e\u533a\u5206\u6760\u6746\u70b9\uff0c\u4e0e\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e00\u81f4\u6027\u9ad8\uff0c\u6709\u5f00\u6e90\u5b9e\u73b0\u3002", "motivation": "\u56e0\u679c\u5faa\u73af\u56fe\u5728\u652f\u6301\u52a8\u6001\u5206\u6790\u548c\u5e72\u9884\u7b56\u7565\u65b9\u9762\u6709\u9650\uff0c\u5b9a\u91cf\u5206\u6790\u65b9\u6cd5\u5e38\u5bfc\u81f4\u9519\u8bef\u63a8\u65ad\u3002", "method": "\u63d0\u51faD2D\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c11\u7528\u6237\u8f93\u5165\uff0c\u5229\u7528CLD\u7ed3\u6784\u4fe1\u606f\u6a21\u62df\u5047\u8bbe\u5e72\u9884\u548c\u63a2\u7d22\u6760\u6746\u70b9\u3002", "result": "D2D\u6709\u52a9\u4e8e\u533a\u5206\u9ad8\u4f4e\u6392\u540d\u6760\u6746\u70b9\uff0c\u4e0e\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4e00\u81f4\u6027\u9ad8\u4e8e\u7f51\u7edc\u4e2d\u5fc3\u6027\u5206\u6790\uff0c\u80fd\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u6570\u636e\u6536\u96c6\u6307\u5bfc\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u5f00\u6e90\u5b9e\u73b0\uff0c\u671f\u5f85\u66f4\u591a\u9a8c\u8bc1\u4ee5\u786e\u7acb\u5176\u5728\u5e7f\u6cdb\u6848\u4f8b\u548c\u9886\u57df\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.05706", "pdf": "https://arxiv.org/pdf/2508.05706", "abs": "https://arxiv.org/abs/2508.05706", "authors": ["Hyunwoong Chang", "Jaehoan Kim"], "title": "Identifiability of the minimum-trace directed acyclic graph and hill climbing algorithms without strict local optima under weakly increasing error variances", "categories": ["stat.CO", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "We prove that the true underlying directed acyclic graph (DAG) in Gaussian\nlinear structural equation models is identifiable as the minimum-trace DAG when\nthe error variances are weakly increasing with respect to the true causal\nordering. This result bridges two existing frameworks as it extends the\nidentifiable cases within the minimum-trace DAG method and provides a\nprincipled interpretation of the algorithmic ordering search approach,\nrevealing that its objective is actually to minimize the total residual sum of\nsquares. On the computational side, we prove that the hill climbing algorithm\nwith a random-to-random (R2R) neighborhood does not admit any strict local\noptima. Under standard settings, we confirm the result through extensive\nsimulations, observing only a few weak local optima. Interestingly, algorithms\nusing other neighborhoods of equal size exhibit suboptimal behavior, having\nstrict local optima and a substantial number of weak local optima.", "AI": {"tldr": "\u8bc1\u660e\u9ad8\u65af\u7ebf\u6027\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u4e2d\u771f\u5b9eDAG\u5728\u8bef\u5dee\u65b9\u5dee\u5f31\u9012\u589e\u65f6\u53ef\u4f5c\u4e3a\u6700\u5c0f\u8ff9DAG\u8bc6\u522b\uff0c\u8fd8\u7814\u7a76\u4e86\u722c\u5c71\u7b97\u6cd5\u6027\u8d28\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u3002", "motivation": "\u6865\u63a5\u73b0\u6709\u6846\u67b6\uff0c\u6269\u5c55\u6700\u5c0f\u8ff9DAG\u65b9\u6cd5\u53ef\u8bc6\u522b\u60c5\u51b5\uff0c\u89e3\u91ca\u7b97\u6cd5\u6392\u5e8f\u641c\u7d22\u65b9\u6cd5\u3002", "method": "\u7406\u8bba\u8bc1\u660e\uff0c\u4f7f\u7528\u722c\u5c71\u7b97\u6cd5\u5e76\u8fdb\u884c\u5927\u91cf\u6a21\u62df\u3002", "result": "\u8bc1\u660e\u722c\u5c71\u7b97\u6cd5\u5728R2R\u90bb\u57df\u65e0\u4e25\u683c\u5c40\u90e8\u6700\u4f18\uff0c\u6a21\u62df\u4ec5\u89c2\u5bdf\u5230\u5c11\u91cf\u5f31\u5c40\u90e8\u6700\u4f18\uff0c\u5176\u4ed6\u90bb\u57df\u7b97\u6cd5\u6709\u6b21\u4f18\u884c\u4e3a\u3002", "conclusion": "\u5728\u8bef\u5dee\u65b9\u5dee\u5f31\u9012\u589e\u6761\u4ef6\u4e0b\uff0c\u771f\u5b9eDAG\u53ef\u4f5c\u4e3a\u6700\u5c0f\u8ff9DAG\u8bc6\u522b\uff0cR2R\u90bb\u57df\u722c\u5c71\u7b97\u6cd5\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2508.05663", "pdf": "https://arxiv.org/pdf/2508.05663", "abs": "https://arxiv.org/abs/2508.05663", "authors": ["Xingran Chen", "Parimal Parag", "Rohit Bhagat", "Zonghong Liu", "Salim El Rouayheb"], "title": "Random Walk Learning and the Pac-Man Attack", "categories": ["stat.ML", "cs.CR", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Random walk (RW)-based algorithms have long been popular in distributed\nsystems due to low overheads and scalability, with recent growing applications\nin decentralized learning. However, their reliance on local interactions makes\nthem inherently vulnerable to malicious behavior. In this work, we investigate\nan adversarial threat that we term the ``Pac-Man'' attack, in which a malicious\nnode probabilistically terminates any RW that visits it. This stealthy behavior\ngradually eliminates active RWs from the network, effectively halting the\nlearning process without triggering failure alarms. To counter this threat, we\npropose the Average Crossing (AC) algorithm--a fully decentralized mechanism\nfor duplicating RWs to prevent RW extinction in the presence of Pac-Man. Our\ntheoretical analysis establishes that (i) the RW population remains almost\nsurely bounded under AC and (ii) RW-based stochastic gradient descent remains\nconvergent under AC, even in the presence of Pac-Man, with a quantifiable\ndeviation from the true optimum. Our extensive empirical results on both\nsynthetic and real-world datasets corroborate our theoretical findings.\nFurthermore, they uncover a phase transition in the extinction probability as a\nfunction of the duplication threshold. We offer theoretical insights by\nanalyzing a simplified variant of the AC, which sheds light on the observed\nphase transition.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\uff08RW\uff09\u7b97\u6cd5\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u9762\u4e34\u7684\u201c\u5403\u8c46\u4eba\u201d\u653b\u51fb\uff0c\u63d0\u51fa\u5e73\u5747\u4ea4\u53c9\uff08AC\uff09\u7b97\u6cd5\u5e94\u5bf9\uff0c\u6709\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u7684\u7b97\u6cd5\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u4f9d\u8d56\u5c40\u90e8\u4ea4\u4e92\u6613\u53d7\u6076\u610f\u884c\u4e3a\u5f71\u54cd\uff0c\u7814\u7a76\u201c\u5403\u8c46\u4eba\u201d\u653b\u51fb\u4ee5\u5e94\u5bf9\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u5e73\u5747\u4ea4\u53c9\uff08AC\uff09\u7b97\u6cd5\uff0c\u901a\u8fc7\u590d\u5236\u968f\u673a\u6e38\u8d70\u6765\u9632\u6b62\u5728\u201c\u5403\u8c46\u4eba\u201d\u653b\u51fb\u4e0b\u968f\u673a\u6e38\u8d70\u7684\u706d\u7edd\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u5728AC\u7b97\u6cd5\u4e0b\u968f\u673a\u6e38\u8d70\u6570\u91cf\u6709\u754c\uff0c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6536\u655b\u4e14\u80fd\u91cf\u5316\u504f\u5dee\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c\uff0c\u53d1\u73b0\u706d\u7edd\u6982\u7387\u7684\u76f8\u53d8\u3002", "conclusion": "AC\u7b97\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u201c\u5403\u8c46\u4eba\u201d\u653b\u51fb\uff0c\u5bf9\u968f\u673a\u6e38\u8d70\u7b97\u6cd5\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u5b89\u5168\u5e94\u7528\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2508.05855", "pdf": "https://arxiv.org/pdf/2508.05855", "abs": "https://arxiv.org/abs/2508.05855", "authors": ["Zixia Wang", "Jia Hu", "Ronghui Mu"], "title": "Safety of Embodied Navigation: A Survey", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "As large language models (LLMs) continue to advance and gain influence, the\ndevelopment of embodied AI has accelerated, drawing significant attention,\nparticularly in navigation scenarios. Embodied navigation requires an agent to\nperceive, interact with, and adapt to its environment while moving toward a\nspecified target in unfamiliar settings. However, the integration of embodied\nnavigation into critical applications raises substantial safety concerns. Given\ntheir deployment in dynamic, real-world environments, ensuring the safety of\nsuch systems is critical. This survey provides a comprehensive analysis of\nsafety in embodied navigation from multiple perspectives, encompassing attack\nstrategies, defense mechanisms, and evaluation methodologies. Beyond conducting\na comprehensive examination of existing safety challenges, mitigation\ntechnologies, and various datasets and metrics that assess effectiveness and\nrobustness, we explore unresolved issues and future research directions in\nembodied navigation safety. These include potential attack methods, mitigation\nstrategies, more reliable evaluation techniques, and the implementation of\nverification frameworks. By addressing these critical gaps, this survey aims to\nprovide valuable insights that can guide future research toward the development\nof safer and more reliable embodied navigation systems. Furthermore, the\nfindings of this study have broader implications for enhancing societal safety\nand increasing industrial efficiency.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u5206\u6790\u5177\u8eab\u5bfc\u822a\u5b89\u5168\u6027\uff0c\u63a2\u8ba8\u73b0\u5b58\u6311\u6218\u3001\u7f13\u89e3\u6280\u672f\u3001\u8bc4\u4f30\u65b9\u6cd5\u7b49\uff0c\u6307\u51fa\u672a\u89e3\u51b3\u95ee\u9898\u548c\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u5f00\u53d1\u66f4\u5b89\u5168\u53ef\u9760\u7cfb\u7edf\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u52a8\u4e0b\u5177\u8eab\u5bfc\u822a\u53d1\u5c55\u52a0\u901f\uff0c\u4f46\u96c6\u6210\u5230\u5173\u952e\u5e94\u7528\u6709\u5b89\u5168\u9690\u60a3\uff0c\u786e\u4fdd\u7cfb\u7edf\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4ece\u653b\u51fb\u7b56\u7565\u3001\u9632\u5fa1\u673a\u5236\u548c\u8bc4\u4f30\u65b9\u6cd5\u7b49\u591a\u89c6\u89d2\u7efc\u5408\u5206\u6790\u3002", "result": "\u5bf9\u73b0\u6709\u5b89\u5168\u6311\u6218\u3001\u7f13\u89e3\u6280\u672f\u3001\u6570\u636e\u96c6\u548c\u6307\u6807\u8fdb\u884c\u5168\u9762\u8003\u5bdf\uff0c\u63a2\u7d22\u672a\u89e3\u51b3\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u66f4\u5b89\u5168\u53ef\u9760\u5177\u8eab\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u6709\u4ef7\u503c\u89c1\u89e3\uff0c\u5bf9\u63d0\u5347\u793e\u4f1a\u5b89\u5168\u548c\u4ea7\u4e1a\u6548\u7387\u6709\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2508.05690", "pdf": "https://arxiv.org/pdf/2508.05690", "abs": "https://arxiv.org/abs/2508.05690", "authors": ["Meital Shlezinger", "Shay Akirav", "Lei Zhou", "Liang Guo", "Avi Kessel", "Guoliang Li"], "title": "Leveraging large language models for SQL behavior-based database intrusion detection", "categories": ["cs.CR", "cs.DB", "cs.LG"], "comment": null, "summary": "Database systems are extensively used to store critical data across various\ndomains. However, the frequency of abnormal database access behaviors, such as\ndatabase intrusion by internal and external attacks, continues to rise.\nInternal masqueraders often have greater organizational knowledge, making it\neasier to mimic employee behavior effectively. In contrast, external\nmasqueraders may behave differently due to their lack of familiarity with the\norganization. Current approaches lack the granularity needed to detect\nanomalies at the operational level, frequently misclassifying entire sequences\nof operations as anomalies, even though most operations are likely to represent\nnormal behavior. On the other hand, some anomalous behaviors often resemble\nnormal activities, making them difficult for existing detection methods to\nidentify. This paper introduces a two-tiered anomaly detection approach for\nStructured Query Language (SQL) using the Bidirectional Encoder Representations\nfrom Transformers (BERT) model, specifically DistilBERT, a more efficient,\npre-trained version. Our method combines both unsupervised and supervised\nmachine learning techniques to accurately identify anomalous activities while\nminimizing the need for data labeling. First, the unsupervised method uses\nensemble anomaly detectors that flag embedding vectors distant from learned\nnormal patterns of typical user behavior across the database (out-of-scope\nqueries). Second, the supervised method uses fine-tuned transformer-based\nmodels to detect internal attacks with high precision (in-scope queries), using\nrole-labeled classification, even on limited labeled SQL data. Our findings\nmake a significant contribution by providing an effective solution for\nsafeguarding critical database systems from sophisticated threats.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528DistilBERT\u7684\u4e24\u5c42SQL\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u6709\u6548\u4fdd\u62a4\u6570\u636e\u5e93\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u5e93\u5f02\u5e38\u8bbf\u95ee\u884c\u4e3a\u589e\u591a\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u64cd\u4f5c\u7ea7\u7c92\u5ea6\u4e14\u96be\u4ee5\u8bc6\u522b\u7c7b\u4f3c\u6b63\u5e38\u6d3b\u52a8\u7684\u5f02\u5e38\u884c\u4e3a\u3002", "method": "\u7ed3\u5408\u65e0\u76d1\u7763\u548c\u6709\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u65e0\u76d1\u7763\u65b9\u6cd5\u7528\u96c6\u6210\u5f02\u5e38\u68c0\u6d4b\u5668\u6807\u8bb0\u8fdc\u79bb\u6b63\u5e38\u6a21\u5f0f\u7684\u5d4c\u5165\u5411\u91cf\uff0c\u6709\u76d1\u7763\u65b9\u6cd5\u7528\u5fae\u8c03\u7684\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u8fdb\u884c\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "result": "\u63d0\u51fa\u4e86\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4fdd\u62a4\u5173\u952e\u6570\u636e\u5e93\u7cfb\u7edf\u514d\u53d7\u590d\u6742\u5a01\u80c1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06312", "pdf": "https://arxiv.org/pdf/2508.06312", "abs": "https://arxiv.org/abs/2508.06312", "authors": ["Lang Cao", "Zekun Xi", "Long Liao", "Ziwei Yang", "Zheng Cao"], "title": "Chain-of-Alpha: Unleashing the Power of Large Language Models for Alpha Mining in Quantitative Trading", "categories": ["cs.CE"], "comment": null, "summary": "Alpha factor mining is a fundamental task in quantitative trading, aimed at\ndiscovering interpretable signals that can predict asset returns beyond\nsystematic market risk. While traditional methods rely on manual formula design\nor heuristic search with machine learning, recent advances have leveraged Large\nLanguage Models (LLMs) for automated factor discovery. However, existing\nLLM-based alpha mining approaches remain limited in terms of automation,\ngenerality, and efficiency. In this paper, we propose Chain-of-Alpha, a novel,\nsimple, yet effective and efficient LLM-based framework for fully automated\nformulaic alpha mining. Our method features a dual-chain architecture,\nconsisting of a Factor Generation Chain and a Factor Optimization Chain, which\niteratively generate, evaluate, and refine candidate alpha factors using only\nmarket data, while leveraging backtest feedback and prior optimization\nknowledge. The two chains work synergistically to enable high-quality alpha\ndiscovery without human intervention and offer strong scalability. Extensive\nexperiments on real-world A-share benchmarks demonstrate that Chain-of-Alpha\noutperforms existing baselines across multiple metrics, presenting a promising\ndirection for LLM-driven quantitative research.", "AI": {"tldr": "\u63d0\u51faChain - of - Alpha\u6846\u67b6\u7528\u4e8e\u5168\u81ea\u52a8\u516c\u5f0f\u5316\u963f\u5c14\u6cd5\u56e0\u5b50\u6316\u6398\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u963f\u5c14\u6cd5\u6316\u6398\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u3001\u901a\u7528\u6027\u548c\u6548\u7387\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faChain - of - Alpha\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u94fe\u67b6\u6784\uff08\u56e0\u5b50\u751f\u6210\u94fe\u548c\u56e0\u5b50\u4f18\u5316\u94fe\uff09\uff0c\u5229\u7528\u5e02\u573a\u6570\u636e\u8fed\u4ee3\u751f\u6210\u3001\u8bc4\u4f30\u548c\u4f18\u5316\u5019\u9009\u963f\u5c14\u6cd5\u56e0\u5b50\u3002", "result": "\u5728\u771f\u5b9eA\u80a1\u57fa\u51c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cChain - of - Alpha\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "Chain - of - Alpha\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u91cf\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2508.05821", "pdf": "https://arxiv.org/pdf/2508.05821", "abs": "https://arxiv.org/abs/2508.05821", "authors": ["Shadman Sakib", "Ajay Katangur", "Rahul Dubey"], "title": "A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization", "categories": ["cs.DC"], "comment": "Accepted for publication in 2025 IEEE Cloud Summit", "summary": "Cloud computing has grown rapidly in recent years, mainly due to the sharp\nincrease in data transferred over the internet. This growth makes load\nbalancing a key part of cloud systems, as it helps distribute user requests\nacross servers to maintain performance, prevent overload, and ensure a smooth\nuser experience. Despite its importance, managing server resources and keeping\nworkloads balanced over time remains a major challenge in cloud environments.\nThis paper introduces a novel Score-Based Dynamic Load Balancer (SBDLB) that\nallocates workloads to virtual machines based on real-time performance metrics.\nThe objective is to enhance resource utilization and overall system efficiency.\nThe method was thoroughly tested using the CloudSim 7G platform, comparing its\nperformance against the throttled load balancing strategy. Evaluations were\nconducted across a variety of workloads and scenarios, demonstrating the\nSBDLB's ability to adapt dynamically to workload fluctuations while optimizing\nresource usage. The proposed method outperformed the throttled strategy,\nimproving average response times by 34% and 37% in different scenarios. It also\nreduced data center processing times by an average of 13%. Over a 24-hour\nsimulation, the method decreased operational costs by 15%, promoting a more\nenergy-efficient and sustainable cloud infrastructure through reduced energy\nconsumption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5b9e\u65f6\u6027\u80fd\u6307\u6807\u5206\u914d\u5de5\u4f5c\u8d1f\u8f7d\u7684SBDLB\uff0c\u901a\u8fc7CloudSim 7G\u5e73\u53f0\u6d4b\u8bd5\uff0c\u6027\u80fd\u4f18\u4e8e\u8282\u6d41\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u63d0\u5347\u54cd\u5e94\u65f6\u95f4\u3001\u964d\u4f4e\u5904\u7406\u65f6\u95f4\u548c\u8fd0\u8425\u6210\u672c\u3002", "motivation": "\u4e91\u8ba1\u7b97\u53d1\u5c55\u4f7f\u8d1f\u8f7d\u5747\u8861\u6210\u4e3a\u5173\u952e\uff0c\u4f46\u7ba1\u7406\u670d\u52a1\u5668\u8d44\u6e90\u548c\u4fdd\u6301\u5de5\u4f5c\u8d1f\u8f7d\u5e73\u8861\u4ecd\u662f\u4e91\u73af\u5883\u91cd\u5927\u6311\u6218\uff0c\u65e8\u5728\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u548c\u7cfb\u7edf\u6574\u4f53\u6548\u7387\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5b9e\u65f6\u6027\u80fd\u6307\u6807\u5c06\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\u7ed9\u865a\u62df\u673a\u7684Score - Based Dynamic Load Balancer (SBDLB)\uff0c\u7528CloudSim 7G\u5e73\u53f0\u6d4b\u8bd5\uff0c\u4e0e\u8282\u6d41\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u5bf9\u6bd4\u3002", "result": "SBDLB\u80fd\u52a8\u6001\u9002\u5e94\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\uff0c\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\uff0c\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u5206\u522b\u63d0\u534734%\u548c37%\uff0c\u6570\u636e\u4e2d\u5fc3\u5904\u7406\u65f6\u95f4\u5e73\u5747\u964d\u4f4e13%\uff0c24\u5c0f\u65f6\u6a21\u62df\u4e2d\u8fd0\u8425\u6210\u672c\u964d\u4f4e15%\u3002", "conclusion": "SBDLB\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u8282\u6d41\u7b56\u7565\uff0c\u53ef\u901a\u8fc7\u964d\u4f4e\u80fd\u8017\u4fc3\u8fdb\u66f4\u8282\u80fd\u548c\u53ef\u6301\u7eed\u7684\u4e91\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2508.06031", "pdf": "https://arxiv.org/pdf/2508.06031", "abs": "https://arxiv.org/abs/2508.06031", "authors": ["Licheng Ye", "Zehui Xiong", "Lin Gao", "Dusit Niyato"], "title": "An Overlapping Coalition Game Approach for Collaborative Block Mining and Edge Task Offloading in MEC-assisted Blockchain Networks", "categories": ["cs.GT"], "comment": "This work has been accepted for publication in IEEE Transactions on\n  Mobile Computing", "summary": "Mobile edge computing (MEC) is a promising technology that enhances the\nefficiency of mobile blockchain networks, by enabling miners, often acted by\nmobile users (MUs) with limited computing resources, to offload\nresource-intensive mining tasks to nearby edge computing servers. Collaborative\nblock mining can further boost mining efficiency by allowing multiple miners to\nform coalitions, pooling their computing resources and transaction data\ntogether to mine new blocks collaboratively. Therefore, an MEC-assisted\ncollaborative blockchain network can leverage the strengths of both\ntechnologies, offering improved efficiency, security, and scalability for\nblockchain systems. While existing research in this area has mainly focused on\nthe single-coalition collaboration mode, where each miner can only join one\ncoalition, this work explores a more comprehensive multi-coalition\ncollaboration mode, which allows each miner to join multiple coalitions. To\nanalyze the behavior of miners and the edge computing service provider (ECP) in\nthis scenario, we propose a novel two-stage Stackelberg game. In Stage I, the\nECP, as the leader, determines the prices of computing resources for all MUs.\nIn Stage II, each MU decides the coalitions to join, resulting in an\noverlapping coalition formation (OCF) game; Subsequently, each coalition\ndecides how many edge computing resources to purchase from the ECP, leading to\nan edge resource competition (ERC) game. We derive the closed-form Nash\nequilibrium for the ERC game, based on which we further propose an OCF-based\nalternating algorithm to achieve a stable coalition structure for the OCF game\nand develop a near-optimal pricing strategy for the ECP's resource pricing\nproblem.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22MEC\u8f85\u52a9\u7684\u533a\u5757\u94fe\u7f51\u7edc\u591a\u8054\u76df\u534f\u4f5c\u6a21\u5f0f\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5Stackelberg\u535a\u5f08\u5206\u6790\uff0c\u7ed9\u51faERC\u535a\u5f08\u5747\u8861\u89e3\uff0c\u63d0\u51faOCF\u7b97\u6cd5\u548c\u8fd1\u6700\u4f18\u5b9a\u4ef7\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5355\u8054\u76df\u534f\u4f5c\u6a21\u5f0f\uff0c\u672c\u6587\u63a2\u7d22\u66f4\u5168\u9762\u7684\u591a\u8054\u76df\u534f\u4f5c\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5Stackelberg\u535a\u5f08\uff0c\u7b2c\u4e00\u9636\u6bb5ECP\u786e\u5b9a\u8d44\u6e90\u4ef7\u683c\uff0c\u7b2c\u4e8c\u9636\u6bb5MU\u51b3\u5b9a\u52a0\u5165\u8054\u76df\u5f62\u6210OCF\u535a\u5f08\uff0c\u8054\u76df\u51b3\u5b9a\u8d2d\u4e70\u8d44\u6e90\u5f62\u6210ERC\u535a\u5f08\u3002\u63a8\u5bfcERC\u535a\u5f08\u7684Nash\u5747\u8861\u89e3\uff0c\u63d0\u51faOCF\u4ea4\u66ff\u7b97\u6cd5\u548cECP\u8d44\u6e90\u5b9a\u4ef7\u7684\u8fd1\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5f97\u5230ERC\u535a\u5f08\u7684\u95ed\u5f0fNash\u5747\u8861\u89e3\uff0c\u901a\u8fc7OCF\u7b97\u6cd5\u5b9e\u73b0OCF\u535a\u5f08\u7684\u7a33\u5b9a\u8054\u76df\u7ed3\u6784\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u4e3aMEC\u8f85\u52a9\u7684\u534f\u4f5c\u533a\u5757\u94fe\u7f51\u7edc\u5728\u591a\u8054\u76df\u534f\u4f5c\u6a21\u5f0f\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u8054\u76df\u7ed3\u6784\u548c\u8fd1\u6700\u4f18\u8d44\u6e90\u5b9a\u4ef7\u3002"}}
{"id": "2508.06212", "pdf": "https://arxiv.org/pdf/2508.06212", "abs": "https://arxiv.org/abs/2508.06212", "authors": ["Romain Bourneuf", "Tim Planken"], "title": "A Structural Linear-Time Algorithm for Computing the Tutte Decomposition", "categories": ["cs.DS", "cs.DM", "math.CO"], "comment": "41 pages, 4 figures", "summary": "The block-cut tree decomposes a connected graph along its cutvertices,\ndisplaying its 2-connected components. The Tutte-decomposition extends this\nidea to 2-separators in 2-connected graphs, yielding a canonical\ntree-decomposition that decomposes the graph into its triconnected components.\nIn 1973, Hopcroft and Tarjan introduced a linear-time algorithm to compute the\nTutte-decomposition. Cunningham and Edmonds later established a structural\ncharacterization of the Tutte-decomposition via totally-nested 2-separations.\nWe present a conceptually simple algorithm based on this characterization,\nwhich computes the Tutte-decomposition in linear time. Our algorithm first\ncomputes all totally-nested 2-separations and then builds the\nTutte-decomposition from them.\n  Along the way, we derive new structural results on the structure of\ntotally-nested 2-separations in 2-connected graphs using a novel notion of\nstability, which may be of independent interest.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7ed3\u6784\u7279\u5f81\u7684\u7ebf\u6027\u65f6\u95f4\u8ba1\u7b97Tutte - \u5206\u89e3\u7684\u7b97\u6cd5\uff0c\u540c\u65f6\u5f97\u5230\u5173\u4e8e\u5168\u5d4c\u59572 - \u5206\u79bb\u7ed3\u6784\u7684\u65b0\u7ed3\u679c\u3002", "motivation": "\u5728Hopcroft\u548cTarjan\u3001Cunningham\u548cEdmonds\u5de5\u4f5c\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u6982\u5ff5\u66f4\u7b80\u5355\u7684\u7ebf\u6027\u65f6\u95f4\u8ba1\u7b97Tutte - \u5206\u89e3\u7684\u7b97\u6cd5\u3002", "method": "\u5148\u8ba1\u7b97\u6240\u6709\u5168\u5d4c\u59572 - \u5206\u79bb\uff0c\u518d\u636e\u6b64\u6784\u5efaTutte - \u5206\u89e3\uff0c\u8fd8\u4f7f\u7528\u4e86\u7a33\u5b9a\u6027\u7684\u65b0\u6982\u5ff5\u63a8\u5bfc\u7ed3\u6784\u7ed3\u679c\u3002", "result": "\u5f97\u5230\u4e86\u8ba1\u7b97Tutte - \u5206\u89e3\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u548c\u5173\u4e8e\u5168\u5d4c\u59572 - \u5206\u79bb\u7ed3\u6784\u7684\u65b0\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u6982\u5ff5\u7b80\u5355\u4e14\u80fd\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u8ba1\u7b97Tutte - \u5206\u89e3\uff0c\u65b0\u7684\u7ed3\u6784\u7ed3\u679c\u6709\u72ec\u7acb\u7814\u7a76\u4ef7\u503c\u3002"}}
{"id": "2508.05647", "pdf": "https://arxiv.org/pdf/2508.05647", "abs": "https://arxiv.org/abs/2508.05647", "authors": ["Vibhor Agrawal", "Fay Wang", "Rishi Puri"], "title": "Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "We present a novel graph neural network (GNN) architecture for\nretrieval-augmented generation (RAG) that leverages query-aware attention\nmechanisms and learned scoring heads to improve retrieval accuracy on complex,\nmulti-hop questions. Unlike traditional dense retrieval methods that treat\ndocuments as independent entities, our approach constructs per-episode\nknowledge graphs that capture both sequential and semantic relationships\nbetween text chunks. We introduce an Enhanced Graph Attention Network with\nquery-guided pooling that dynamically focuses on relevant parts of the graph\nbased on user queries. Experimental results demonstrate that our approach\nsignificantly outperforms standard dense retrievers on complex question\nanswering tasks, particularly for questions requiring multi-document reasoning.\nOur implementation leverages PyTorch Geometric for efficient processing of\ngraph-structured data, enabling scalable deployment in production retrieval\nsystems", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u65b0\u578b\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5728\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u63d0\u5347\u590d\u6742\u591a\u8df3\u95ee\u9898\u7684\u68c0\u7d22\u51c6\u786e\u6027\uff0c\u6539\u8fdb\u4f20\u7edf\u5bc6\u96c6\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u6bcf\u8f6e\u77e5\u8bc6\u56fe\uff0c\u5f15\u5165\u5e26\u67e5\u8be2\u5f15\u5bfc\u6c60\u5316\u7684\u589e\u5f3a\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u3002", "result": "\u5728\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u5bc6\u96c6\u68c0\u7d22\u5668\u3002", "conclusion": "\u8be5\u67b6\u6784\u53ef\u5229\u7528PyTorch Geometric\u9ad8\u6548\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\uff0c\u9002\u7528\u4e8e\u751f\u4ea7\u68c0\u7d22\u7cfb\u7edf\u53ef\u6269\u5c55\u90e8\u7f72\u3002"}}
{"id": "2508.06389", "pdf": "https://arxiv.org/pdf/2508.06389", "abs": "https://arxiv.org/abs/2508.06389", "authors": ["James Stovold"], "title": "Identity Increases Stability in Neural Cellular Automata", "categories": ["cs.NE", "cs.AI"], "comment": "Accepted to ALIFE 2025", "summary": "Neural Cellular Automata (NCAs) offer a way to study the growth of\ntwo-dimensional artificial organisms from a single seed cell. From the outset,\nNCA-grown organisms have had issues with stability, their natural boundary\noften breaking down and exhibiting tumour-like growth or failing to maintain\nthe expected shape. In this paper, we present a method for improving the\nstability of NCA-grown organisms by introducing an 'identity' layer with simple\nconstraints during training.\n  Results show that NCAs grown in close proximity are more stable compared with\nthe original NCA model. Moreover, only a single identity value is required to\nachieve this increase in stability. We observe emergent movement from the\nstable organisms, with increasing prevalence for models with multiple identity\nvalues.\n  This work lays the foundation for further study of the interaction between\nNCA-grown organisms, paving the way for studying social interaction at a\ncellular level in artificial organisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f15\u5165\u5e26\u7b80\u5355\u7ea6\u675f\u7684\u2018\u8eab\u4efd\u2019\u5c42\u63d0\u5347\u795e\u7ecf\u7ec6\u80de\u81ea\u52a8\u673a\uff08NCA\uff09\u751f\u6210\u751f\u7269\u4f53\u7684\u7a33\u5b9a\u6027\uff0c\u7ed3\u679c\u663e\u793a\u4e34\u8fd1\u751f\u957f\u7684NCA\u66f4\u7a33\u5b9a\uff0c\u5355\u8eab\u4efd\u503c\u5373\u53ef\u63d0\u5347\u7a33\u5b9a\u6027\uff0c\u7a33\u5b9a\u751f\u7269\u4f53\u6709\u6d8c\u73b0\u8fd0\u52a8\uff0c\u4e3a\u7814\u7a76NCA\u751f\u7269\u4f53\u76f8\u4e92\u4f5c\u7528\u5960\u57fa\u3002", "motivation": "NCA\u751f\u6210\u7684\u751f\u7269\u4f53\u5b58\u5728\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u81ea\u7136\u8fb9\u754c\u6613\u5d29\u6e83\uff0c\u65e0\u6cd5\u7ef4\u6301\u9884\u671f\u5f62\u72b6\u3002", "method": "\u5728\u8bad\u7ec3\u65f6\u5f15\u5165\u5e26\u7b80\u5355\u7ea6\u675f\u7684\u2018\u8eab\u4efd\u2019\u5c42\u3002", "result": "\u4e34\u8fd1\u751f\u957f\u7684NCA\u6bd4\u539f\u6a21\u578b\u66f4\u7a33\u5b9a\uff0c\u5355\u8eab\u4efd\u503c\u5373\u53ef\u63d0\u5347\u7a33\u5b9a\u6027\uff0c\u591a\u8eab\u4efd\u503c\u6a21\u578b\u4e2d\u7a33\u5b9a\u751f\u7269\u4f53\u6d8c\u73b0\u8fd0\u52a8\u66f4\u666e\u904d\u3002", "conclusion": "\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76NCA\u751f\u6210\u751f\u7269\u4f53\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u5960\u5b9a\u57fa\u7840\uff0c\u4e3a\u4eba\u5de5\u751f\u7269\u4f53\u5728\u7ec6\u80de\u5c42\u9762\u7684\u793e\u4ea4\u4e92\u52a8\u7814\u7a76\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2508.06425", "pdf": "https://arxiv.org/pdf/2508.06425", "abs": "https://arxiv.org/abs/2508.06425", "authors": ["Shiang-Hung Hu", "Po-Hsuan Lin", "Thomas R. Palfrey", "Joseph Tao-yi Wang", "Yu-Hsiang Wang"], "title": "Strategy Method Effects in Centipede Games: An Optimal Design Approach", "categories": ["econ.GN", "q-fin.EC"], "comment": "61 pages, 5 figures and 4 tables in the main text", "summary": "We explore the twin questions of when and why the strategy method creates\nbehavioral distortions in the elicitation of choices in laboratory studies of\nsequential games. While such distortions have been widely documented, the\ntheoretical forces driving these distortions remain poorly understood. In this\npaper, we compare behavior in six optimally designed centipede games,\nimplemented under three different choice elicitation methods: the direct\nresponse method, the reduced strategy method and the full strategy method.\nThese methods elicit behavioral strategies, reduced strategies, and complete\nstrategies, respectively. We find significant behavioral differences across\nthese elicitation methods -- differences that cannot be explained by standard\ngame theory, but are consistent with the predictions of the Dynamic Cognitive\nHierarchy solution (Lin and Palfrey, 2024), combined with quantal responses.", "AI": {"tldr": "\u7814\u7a76\u7b56\u7565\u65b9\u6cd5\u5728\u5e8f\u8d2f\u535a\u5f08\u5b9e\u9a8c\u4e2d\u4ea7\u751f\u884c\u4e3a\u626d\u66f2\u7684\u65f6\u95f4\u548c\u539f\u56e0\uff0c\u5bf9\u6bd4\u4e09\u79cd\u9009\u62e9\u5f15\u51fa\u65b9\u6cd5\u4e0b\u7684\u8708\u86a3\u535a\u5f08\u884c\u4e3a\uff0c\u53d1\u73b0\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u867d\u8bb0\u5f55\u4e86\u7b56\u7565\u65b9\u6cd5\u5728\u5f15\u51fa\u9009\u62e9\u65f6\u7684\u884c\u4e3a\u626d\u66f2\uff0c\u4f46\u5bf9\u9a71\u52a8\u8fd9\u4e9b\u626d\u66f2\u7684\u7406\u8bba\u56e0\u7d20\u7406\u89e3\u4e0d\u8db3\uff0c\u56e0\u6b64\u8981\u63a2\u7a76\u4f55\u65f6\u53ca\u4e3a\u4f55\u4ea7\u751f\u8fd9\u79cd\u626d\u66f2\u3002", "method": "\u5bf9\u6bd4\u4e09\u79cd\u9009\u62e9\u5f15\u51fa\u65b9\u6cd5\uff08\u76f4\u63a5\u53cd\u5e94\u6cd5\u3001\u7b80\u5316\u7b56\u7565\u6cd5\u548c\u5b8c\u6574\u7b56\u7565\u6cd5\uff09\u5728\u516d\u4e2a\u6700\u4f18\u8bbe\u8ba1\u7684\u8708\u86a3\u535a\u5f08\u4e2d\u7684\u884c\u4e3a\u3002", "result": "\u4e09\u79cd\u5f15\u51fa\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u884c\u4e3a\u5dee\u5f02\uff0c\u65e0\u6cd5\u7528\u6807\u51c6\u535a\u5f08\u8bba\u89e3\u91ca\uff0c\u4e0e\u52a8\u6001\u8ba4\u77e5\u5c42\u6b21\u89e3\u7ed3\u5408\u91cf\u5b50\u53cd\u5e94\u7684\u9884\u6d4b\u4e00\u81f4\u3002", "conclusion": "\u52a8\u6001\u8ba4\u77e5\u5c42\u6b21\u89e3\u7ed3\u5408\u91cf\u5b50\u53cd\u5e94\u80fd\u66f4\u597d\u89e3\u91ca\u7b56\u7565\u65b9\u6cd5\u5728\u5e8f\u8d2f\u535a\u5f08\u4e2d\u5f15\u51fa\u9009\u62e9\u65f6\u4ea7\u751f\u7684\u884c\u4e3a\u626d\u66f2\u3002"}}
{"id": "2508.05710", "pdf": "https://arxiv.org/pdf/2508.05710", "abs": "https://arxiv.org/abs/2508.05710", "authors": ["Jia Fu", "Xinyu Yang", "Hongzhi Zhang", "Yahui Liu", "Jingyuan Zhang", "Qi Wang", "Fuzheng Zhang", "Guorui Zhou"], "title": "Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning", "categories": ["cs.SE", "cs.AI"], "comment": "21 pages, 11 figures", "summary": "Precise, correct feedback is crucial for effectively training large language\nmodels (LLMs) in code reinforcement learning. However, synthesizing\nhigh-quality test cases remains a profoundly challenging and unsolved problem.\nIn this work, we present Klear-CodeTest, a comprehensive test case synthesis\nframework featuring rigorous verification to ensure quality and reliability of\ntest cases. Our approach achieves broad coverage of programming problems via a\nnovel Generator-Validation (G-V) framework, ensuring correctness through a\nconsistency validation mechanism that verifies outputs against gold solutions.\nThe proposed G-V framework generates comprehensive test cases including both\nregular and corner cases, enhancing test coverage and discriminative power for\nsolution correctness assessment in code reinforcement learning. In addition, we\ndesign a multi-layered security sandbox system optimized for online\nverification platforms, guaranteeing safe and reliable code execution. Through\ncomprehensive experiments, we demonstrate the effectiveness of our curated\ndataset, showing significant improvements in model performance and training\nstability. The source codes, curated dataset and sandbox system are available\nat: https://github.com/Kwai-Klear/CodeTest.", "AI": {"tldr": "\u63d0\u51faKlear - CodeTest\u6846\u67b6\u89e3\u51b3\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u4e2d\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u5408\u6210\u96be\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5f00\u6e90\u3002", "motivation": "\u7cbe\u786e\u6b63\u786e\u7684\u53cd\u9988\u5bf9\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5408\u6210\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u662f\u96be\u9898\u3002", "method": "\u63d0\u51faKlear - CodeTest\u6846\u67b6\uff0c\u91c7\u7528\u65b0\u7684G - V\u6846\u67b6\u5b9e\u73b0\u5e7f\u6cdb\u8986\u76d6\uff0c\u901a\u8fc7\u4e00\u81f4\u6027\u9a8c\u8bc1\u673a\u5236\u786e\u4fdd\u6b63\u786e\u6027\uff0c\u8bbe\u8ba1\u591a\u5c42\u5b89\u5168\u6c99\u7bb1\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7cbe\u5fc3\u7b56\u5212\u7684\u6570\u636e\u96c6\u6709\u6548\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "conclusion": "Klear - CodeTest\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u5408\u6210\u95ee\u9898\uff0c\u6709\u52a9\u4e8e\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2508.05724", "pdf": "https://arxiv.org/pdf/2508.05724", "abs": "https://arxiv.org/abs/2508.05724", "authors": ["Massimiliano Romiti"], "title": "A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics", "categories": ["cs.LG", "physics.data-an", "68T07, 81-08, 05C90", "I.2.6; G.2.2; I.5.1"], "comment": "14 pages, 9 figures", "summary": "This work introduces a novel framework for representing and analyzing\nphysical laws as a weighted knowledge graph. We constructed a database of 659\ndistinct physical equations, subjected to rigorous semantic cleaning to resolve\nnotational ambiguities, resulting in a corpus of 400 advanced physics\nequations. We developed an enhanced graph representation where both physical\nconcepts and equations are nodes, connected by weighted inter-equation bridges.\nThese weights are objectively defined using normalized metrics for variable\noverlap, physics-informed importance scores, and bibliometric data. A Graph\nAttention Network (GAT) was trained for link prediction, achieving a test AUC\nof 0.9742 +/- 0.0018 across five independent runs, significantly outperforming\nboth classical heuristics (best baseline AUC: 0.9487) and established GNN\narchitectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing\nconfirmed significance of all comparisons (p < 0.05), with 2.7% improvement\nover the best baseline. Our analysis reveals three key findings: (i) The model\nautonomously rediscovers the known macroscopic structure of physics,\nidentifying strong conceptual axes between Electromagnetism and Statistical\nMechanics. (ii) It identifies central hub equations that serve as critical\nbridges between multiple physical domains. (iii) The model generates stable,\ncomputationally-derived hypotheses for cross-domain relationships, identifying\nboth known principles and suggesting novel mathematical analogies for further\ntheoretical investigation. The framework can generate hundreds of such\nhypotheses, enabling the creation of specialized datasets for targeted analysis\nof specific physics subfields. Code and data available at\nhttps://github.com/kingelanci/graphysics", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u52a0\u6743\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u548c\u5206\u6790\u7269\u7406\u5b9a\u5f8b\u7684\u6846\u67b6\uff0c\u6784\u5efa\u7269\u7406\u65b9\u7a0b\u6570\u636e\u5e93\uff0c\u8bad\u7ec3GAT\u8fdb\u884c\u94fe\u63a5\u9884\u6d4b\uff0c\u8868\u73b0\u4f18\u5f02\u5e76\u63ed\u793a\u7269\u7406\u7ed3\u6784\u548c\u8de8\u9886\u57df\u5173\u7cfb\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8868\u793a\u548c\u5206\u6790\u7269\u7406\u5b9a\u5f8b\u7684\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u7269\u7406\u65b9\u7a0b\u6570\u636e\u5e93\u5e76\u6e05\u7406\uff0c\u5f00\u53d1\u589e\u5f3a\u56fe\u8868\u793a\uff0c\u7528\u5f52\u4e00\u5316\u6307\u6807\u5b9a\u4e49\u8fb9\u6743\u91cd\uff0c\u8bad\u7ec3Graph Attention Network\u8fdb\u884c\u94fe\u63a5\u9884\u6d4b\u3002", "result": "GAT\u6d4b\u8bd5AUC\u4e3a0.9742 +/- 0.0018\uff0c\u663e\u8457\u4f18\u4e8e\u7ecf\u5178\u542f\u53d1\u5f0f\u548cGraphSAGE\u7b49\u67b6\u6784\u3002", "conclusion": "\u6a21\u578b\u80fd\u81ea\u4e3b\u53d1\u73b0\u7269\u7406\u5b8f\u89c2\u7ed3\u6784\uff0c\u8bc6\u522b\u5173\u952e\u67a2\u7ebd\u65b9\u7a0b\uff0c\u751f\u6210\u8de8\u9886\u57df\u5173\u7cfb\u5047\u8bbe\uff0c\u53ef\u521b\u5efa\u7279\u5b9a\u5b50\u9886\u57df\u6570\u636e\u96c6\u3002"}}
{"id": "2508.05926", "pdf": "https://arxiv.org/pdf/2508.05926", "abs": "https://arxiv.org/abs/2508.05926", "authors": ["Luhuan Wu", "Yi Han", "Christian A. Naesseth", "John P. Cunningham"], "title": "Reverse Diffusion Sequential Monte Carlo Samplers", "categories": ["stat.CO"], "comment": null, "summary": "We propose a novel sequential Monte Carlo (SMC) method for sampling from\nunnormalized target distributions based on a reverse denoising diffusion\nprocess. While recent diffusion-based samplers simulate the reverse diffusion\nusing approximate score functions, they can suffer from accumulating errors due\nto time discretization and imperfect score estimation. In this work, we\nintroduce a principled SMC framework that formalizes diffusion-based samplers\nas proposals while systematically correcting for their biases. The core idea is\nto construct informative intermediate target distributions that progressively\nsteer the sampling trajectory toward the final target distribution. Although\nideal intermediate targets are intractable, we develop exact approximations\nusing quantities from the score estimation-based proposal, without requiring\nadditional model training or inference overhead. The resulting sampler, termed\nRDSMC, enables consistent sampling and unbiased estimation of the target's\nnormalization constant under mild conditions. We demonstrate the effectiveness\nof our method on a range of synthetic targets and real-world Bayesian inference\nproblems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53cd\u5411\u53bb\u566a\u6269\u6563\u8fc7\u7a0b\u7684\u65b0\u578b\u987a\u5e8f\u8499\u7279\u5361\u7f57\uff08SMC\uff09\u65b9\u6cd5\u7528\u4e8e\u4ece\u975e\u5f52\u4e00\u5316\u76ee\u6807\u5206\u5e03\u91c7\u6837\uff0c\u5f15\u5165SMC\u6846\u67b6\u6821\u6b63\u504f\u5dee\uff0c\u5f00\u53d1\u7cbe\u786e\u8fd1\u4f3c\uff0c\u5728\u5408\u6210\u76ee\u6807\u548c\u5b9e\u9645\u8d1d\u53f6\u65af\u63a8\u7406\u95ee\u9898\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u91c7\u6837\u5668\u56e0\u65f6\u95f4\u79bb\u6563\u5316\u548c\u4e0d\u5b8c\u5584\u7684\u5206\u6570\u4f30\u8ba1\u4f1a\u79ef\u7d2f\u8bef\u5dee\uff0c\u9700\u89e3\u51b3\u504f\u5dee\u95ee\u9898\u3002", "method": "\u5f15\u5165\u539f\u5219\u6027SMC\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u6269\u6563\u7684\u91c7\u6837\u5668\u4f5c\u4e3a\u63d0\u8bae\uff0c\u6784\u5efa\u4fe1\u606f\u4e30\u5bcc\u7684\u4e2d\u95f4\u76ee\u6807\u5206\u5e03\uff0c\u7528\u5206\u6570\u4f30\u8ba1\u63d0\u8bae\u4e2d\u7684\u91cf\u5f00\u53d1\u7cbe\u786e\u8fd1\u4f3c\u3002", "result": "\u6240\u63d0\u51fa\u7684RDSMC\u91c7\u6837\u5668\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u80fd\u5b9e\u73b0\u4e00\u81f4\u91c7\u6837\u548c\u76ee\u6807\u5f52\u4e00\u5316\u5e38\u6570\u7684\u65e0\u504f\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e00\u7cfb\u5217\u5408\u6210\u76ee\u6807\u548c\u5b9e\u9645\u8d1d\u53f6\u65af\u63a8\u7406\u95ee\u9898\u4e0a\u6709\u6548\u3002"}}
{"id": "2508.05715", "pdf": "https://arxiv.org/pdf/2508.05715", "abs": "https://arxiv.org/abs/2508.05715", "authors": ["Johannes Piller", "L\u00e9a Orsini", "Simon Wiegrebe", "John Zobolas", "Lukas Burk", "Sophie Hanna Langbein", "Philip Studener", "Markus Goeswein", "Andreas Bender"], "title": "Reduction Techniques for Survival Analysis", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In this work, we discuss what we refer to as reduction techniques for\nsurvival analysis, that is, techniques that \"reduce\" a survival task to a more\ncommon regression or classification task, without ignoring the specifics of\nsurvival data. Such techniques particularly facilitate machine learning-based\nsurvival analysis, as they allow for applying standard tools from machine and\ndeep learning to many survival tasks without requiring custom learners. We\nprovide an overview of different reduction techniques and discuss their\nrespective strengths and weaknesses. We also provide a principled\nimplementation of some of these reductions, such that they are directly\navailable within standard machine learning workflows. We illustrate each\nreduction using dedicated examples and perform a benchmark analysis that\ncompares their predictive performance to established machine learning methods\nfor survival analysis.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u751f\u5b58\u5206\u6790\u7684\u964d\u7ef4\u6280\u672f\uff0c\u4ecb\u7ecd\u4e0d\u540c\u6280\u672f\u4f18\u7f3a\u70b9\uff0c\u63d0\u4f9b\u90e8\u5206\u6280\u672f\u7684\u5b9e\u73b0\uff0c\u5e76\u8fdb\u884c\u57fa\u51c6\u5206\u6790\u3002", "motivation": "\u4f7f\u673a\u5668\u5b66\u4e60\u5de5\u5177\u80fd\u5e94\u7528\u4e8e\u751f\u5b58\u5206\u6790\uff0c\u907f\u514d\u4f7f\u7528\u5b9a\u5236\u5b66\u4e60\u5668\u3002", "method": "\u6982\u8ff0\u4e0d\u540c\u964d\u7ef4\u6280\u672f\uff0c\u63d0\u4f9b\u90e8\u5206\u6280\u672f\u7684\u5b9e\u73b0\uff0c\u7528\u793a\u4f8b\u8bf4\u660e\uff0c\u8fdb\u884c\u57fa\u51c6\u5206\u6790\u3002", "result": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u8bba\u3002"}}
{"id": "2508.05888", "pdf": "https://arxiv.org/pdf/2508.05888", "abs": "https://arxiv.org/abs/2508.05888", "authors": ["Sahil Bansal", "Sai Shruthi Sistla", "Aarti Arikatala", "Sebastian Schreiber"], "title": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Effective tool retrieval is essential for AI agents to select from a vast\narray of tools when identifying and planning actions in the context of complex\nuser queries. Despite its central role in planning, this aspect remains\nunderexplored in the literature. Traditional approaches rely primarily on\nsimilarities between user queries and tool descriptions, which significantly\nlimits retrieval accuracy, specifically when handling multi-step user requests.\nTo address these limitations, we propose a Knowledge Graph (KG)-based tool\nretrieval framework that captures the semantic relationships between tools and\ntheir functional dependencies. Our retrieval algorithm leverages ensembles of\n1-hop ego tool graphs to model direct and indirect connections between tools,\nenabling more comprehensive and contextual tool selection for multi-step tasks.\nWe evaluate our approach on a synthetically generated internal dataset across\nsix defined user classes, extending previous work on coherent dialogue\nsynthesis and too retrieval benchmarks. Results demonstrate that our tool\ngraph-based method achieves 91.85% tool coverage on the micro-average Complete\nRecall metric, compared to 89.26% for re-ranked semantic-lexical hybrid\nretrieval, the strongest non-KG baseline in our experiments. These findings\nsupport our hypothesis that the structural information in the KG provides\ncomplementary signals to pure similarity matching, particularly for queries\nrequiring sequential tool composition.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u5de5\u5177\u68c0\u7d22\u6846\u67b6\uff0c\u63d0\u5347\u591a\u6b65\u4efb\u52a1\u5de5\u5177\u68c0\u7d22\u51c6\u786e\u7387\uff0c\u5b9e\u9a8c\u6548\u679c\u4f18\u4e8e\u975eKG\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6b65\u7528\u6237\u8bf7\u6c42\u65f6\u68c0\u7d22\u51c6\u786e\u7387\u4f4e\uff0c\u8be5\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u5de5\u5177\u68c0\u7d22\u6846\u67b6\uff0c\u5229\u75281 - hop\u81ea\u6211\u5de5\u5177\u56fe\u7684\u96c6\u5408\u6765\u5efa\u6a21\u5de5\u5177\u95f4\u7684\u76f4\u63a5\u548c\u95f4\u63a5\u8fde\u63a5\u3002", "result": "\u5de5\u5177\u56fe\u65b9\u6cd5\u5728\u5fae\u89c2\u5e73\u5747\u5b8c\u5168\u53ec\u56de\u6307\u6807\u4e0a\u5de5\u5177\u8986\u76d6\u7387\u8fbe91.85%\uff0c\u4f18\u4e8e\u975eKG\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u7ed3\u6784\u4fe1\u606f\u80fd\u4e3a\u7eaf\u76f8\u4f3c\u5ea6\u5339\u914d\u63d0\u4f9b\u8865\u5145\u4fe1\u53f7\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9700\u8981\u987a\u5e8f\u7ec4\u5408\u5de5\u5177\u7684\u67e5\u8be2\u3002"}}
{"id": "2508.05904", "pdf": "https://arxiv.org/pdf/2508.05904", "abs": "https://arxiv.org/abs/2508.05904", "authors": ["Brandon Baker", "Elliott Brossard", "Chenwei Xie", "Zihao Ye", "Deen Liu", "Yijun Xie", "Arthur Zwiegincew", "Nitya Kumar Sharma", "Gaurav Jain", "Eugene Retunsky", "Mike Halcrow", "Derek Denny-Brown", "Istvan Cseri", "Tyler Akidau", "Yuxiong He"], "title": "Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data", "categories": ["cs.DC", "cs.DB"], "comment": "12 pages, 6 figures, accepted in ICDCS 2025", "summary": "Snowflake revolutionized data analytics with an elastic architecture that\ndecouples compute and storage, enabling scalable solutions supporting data\narchitectures like data lake, data warehouse, data lakehouse, and data mesh.\nBuilding on this foundation, Snowflake has advanced its AI Data Cloud vision by\nintroducing Snowpark, a managed turnkey solution that supports data engineering\nand AI and ML workloads using Python and other programming languages.\n  This paper outlines Snowpark's design objectives towards high performance,\nstrong security and governance, and ease of use. We detail the architecture of\nSnowpark, highlighting its elastic scalability and seamless integration with\nSnowflake core compute infrastructure. This includes leveraging Snowflake\ncontrol plane for distributed computing and employing a secure sandbox for\nisolating Snowflake SQL workloads from Snowpark executions. Additionally, we\npresent core innovations in Snowpark that drive further performance\nenhancements, such as query initialization latency reduction through Python\npackage caching, improved workload scheduling for customized workloads, and\ndata skew management via efficient row redistribution. Finally, we showcase\nreal-world case studies that illustrate Snowpark's efficiency and effectiveness\nfor large-scale data engineering and AI and ML tasks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdSnowpark\u8bbe\u8ba1\u76ee\u6807\u3001\u67b6\u6784\u3001\u521b\u65b0\u70b9\u53ca\u901a\u8fc7\u6848\u4f8b\u5c55\u793a\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u5de5\u7a0b\u4e0eAI/ML\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002", "motivation": "\u57fa\u4e8eSnowflake\u5f39\u6027\u67b6\u6784\u57fa\u7840\uff0c\u63a8\u8fdb\u5176AI\u6570\u636e\u4e91\u613f\u666f\uff0c\u4ecb\u7ecd\u652f\u6301\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u5de5\u4f5c\u8d1f\u8f7d\u7684Snowpark\u3002", "method": "\u8be6\u7ec6\u9610\u8ff0Snowpark\u67b6\u6784\uff0c\u5305\u62ec\u5229\u7528\u63a7\u5236\u5e73\u9762\u8fdb\u884c\u5206\u5e03\u5f0f\u8ba1\u7b97\u3001\u7528\u5b89\u5168\u6c99\u7bb1\u9694\u79bb\u5de5\u4f5c\u8d1f\u8f7d\u7b49\uff0c\u5e76\u63d0\u51fa\u6838\u5fc3\u521b\u65b0\u70b9\u3002", "result": "\u5c55\u793a\u4e86Snowpark\u5728\u5927\u89c4\u6a21\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u3002", "conclusion": "Snowpark\u5177\u6709\u9ad8\u6027\u80fd\u3001\u5f3a\u5b89\u5168\u6027\u548c\u6613\u4f7f\u7528\u6027\uff0c\u80fd\u6ee1\u8db3\u5927\u89c4\u6a21\u6570\u636e\u5de5\u7a0b\u548cAI/ML\u4efb\u52a1\u9700\u6c42\u3002"}}
{"id": "2508.06386", "pdf": "https://arxiv.org/pdf/2508.06386", "abs": "https://arxiv.org/abs/2508.06386", "authors": ["Kevin Bradley Dsouza", "Graham Alexander Watt", "Yuri Leonenko", "Juan Moreno-Cruz"], "title": "Bridging Farm Economics and Landscape Ecology for Global Sustainability through Hierarchical and Bayesian Optimization", "categories": ["cs.CE"], "comment": null, "summary": "Agricultural landscapes face the dual challenge of sustaining food production\nwhile reversing biodiversity loss. Agri-environmental policies often fall short\nof delivering ecological functions such as landscape connectivity, in part due\nto a persistent disconnect between farm-level economic decisions and\nlandscape-scale spatial planning. We introduce a novel hierarchical\noptimization framework that bridges this gap. First, an Ecological\nIntensification (EI) model determines the economically optimal allocation of\nland to margin and habitat interventions at the individual farm level. These\nfarm-specific intervention levels are then passed to an Ecological Connectivity\n(EC) model, which spatially arranges them across the landscape to maximize\nconnectivity while preserving farm-level profitability. Finally, we introduce a\nBayesian Optimization (BO) approach that translates these spatial outcomes into\nsimple, cost effective, and scalable policy instruments, such as subsidies and\neco-premiums, using non-spatial, farm-level policy parameters. Applying the\nframework to a Canadian agricultural landscape, we demonstrate how it enhances\nconnectivity under real-world economic constraints. Our approach provides a\nglobally relevant tool for aligning farm incentives with biodiversity goals,\nadvancing the development of agri-environmental policies that are economically\nviable and ecologically effective.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5206\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u8fde\u63a5\u519c\u573a\u7ecf\u6d4e\u51b3\u7b56\u4e0e\u666f\u89c2\u89c4\u5212\u4ee5\u89e3\u51b3\u519c\u4e1a\u666f\u89c2\u95ee\u9898\uff0c\u5e94\u7528\u4e8e\u52a0\u62ff\u5927\u519c\u4e1a\u666f\u89c2\u8bc1\u660e\u6709\u6548\u3002", "motivation": "\u519c\u4e1a\u666f\u89c2\u9762\u4e34\u7ef4\u6301\u7cae\u98df\u751f\u4ea7\u548c\u626d\u8f6c\u751f\u7269\u591a\u6837\u6027\u4e27\u5931\u7684\u53cc\u91cd\u6311\u6218\uff0c\u73b0\u6709\u519c\u4e1a\u73af\u5883\u653f\u7b56\u5728\u63d0\u4f9b\u751f\u6001\u529f\u80fd\u65b9\u9762\u4e0d\u8db3\uff0c\u539f\u56e0\u662f\u519c\u573a\u7ecf\u6d4e\u51b3\u7b56\u4e0e\u666f\u89c2\u89c4\u5212\u8131\u8282\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u5148\u901a\u8fc7\u751f\u6001\u5f3a\u5316\u6a21\u578b\u786e\u5b9a\u519c\u573a\u5c42\u9762\u7ecf\u6d4e\u6700\u4f18\u7684\u571f\u5730\u5206\u914d\uff0c\u518d\u7528\u751f\u6001\u8fde\u901a\u6027\u6a21\u578b\u8fdb\u884c\u666f\u89c2\u5c42\u9762\u7a7a\u95f4\u5e03\u5c40\uff0c\u6700\u540e\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u5c06\u7a7a\u95f4\u7ed3\u679c\u8f6c\u5316\u4e3a\u653f\u7b56\u5de5\u5177\u3002", "result": "\u5c06\u6846\u67b6\u5e94\u7528\u4e8e\u52a0\u62ff\u5927\u519c\u4e1a\u666f\u89c2\uff0c\u8bc1\u660e\u80fd\u5728\u73b0\u5b9e\u7ecf\u6d4e\u7ea6\u675f\u4e0b\u589e\u5f3a\u8fde\u901a\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u4f7f\u519c\u573a\u6fc0\u52b1\u4e0e\u751f\u7269\u591a\u6837\u6027\u76ee\u6807\u4e00\u81f4\u63d0\u4f9b\u4e86\u5168\u7403\u9002\u7528\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u7ecf\u6d4e\u53ef\u884c\u4e14\u751f\u6001\u6709\u6548\u7684\u519c\u4e1a\u73af\u5883\u653f\u7b56\u53d1\u5c55\u3002"}}
{"id": "2508.06320", "pdf": "https://arxiv.org/pdf/2508.06320", "abs": "https://arxiv.org/abs/2508.06320", "authors": ["Simon Krogmann", "Pascal Lenzner", "Alexander Skopalik", "Tobias Str\u00e4ubig"], "title": "Social Welfare in Battery Charging Games", "categories": ["cs.GT"], "comment": "To appear at the International Symposium on Algorithmic Game Theory\n  (SAGT 2025)", "summary": "The recent rise of renewable energy produced by many decentralized sources\nyields interesting market design challenges for electrical grids. Balancing\nsupply and demand in such networks is both a temporal and spatial challenge due\nto capacity constraints. The recent surge in the number of household-owned\nbatteries, especially in regions with rooftop solar adoption, offers mitigation\npotential but often acts misaligned with grid-level objectives. In fact, the\ndecision to charge or discharge a household-owned battery is a strategic choice\nby each battery owner governed by selfish incentives. This calls for an\nanalysis from a game-theoretic point of view.\n  We initiate this timely research direction by considering a game-theoretic\nsetting where selfish agents strategically charge or discharge their batteries\nto increase their profit. In particular, we study a Stackelberg-like market\nmodel where a third party introduces price incentives, aiming to optimize\nrenewable energy utilization while preserving grid feasibility. For this, we\nstudy the existence and the quality of equilibria under various pricing\nstrategies. We find that the existence of equilibria crucially depends on the\nchosen pricing and that the obtained social welfare varies widely. This calls\nfor more sophisticated market models and pricing mechanisms and opens up a rich\nfield for future research in Algorithmic Game Theory on incentives in renewable\nenergy networks.", "AI": {"tldr": "\u6587\u7ae0\u4ece\u535a\u5f08\u8bba\u89d2\u5ea6\u5206\u6790\u53ef\u518d\u751f\u80fd\u6e90\u7535\u7f51\u4e2d\u5bb6\u7528\u7535\u6c60\u5145\u653e\u7535\u7b56\u7565\uff0c\u7814\u7a76\u4e0d\u540c\u5b9a\u4ef7\u7b56\u7565\u4e0b\u5747\u8861\u7684\u5b58\u5728\u6027\u548c\u8d28\u91cf\uff0c\u6307\u51fa\u9700\u66f4\u590d\u6742\u5e02\u573a\u6a21\u578b\u548c\u5b9a\u4ef7\u673a\u5236\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u5206\u5e03\u5f0f\u4f9b\u5e94\u53ca\u5bb6\u7528\u7535\u6c60\u589e\u52a0\u5e26\u6765\u7535\u7f51\u4f9b\u9700\u5e73\u8861\u6311\u6218\uff0c\u4e14\u7535\u6c60\u6240\u6709\u8005\u51b3\u7b56\u57fa\u4e8e\u79c1\u5229\uff0c\u9700\u4ece\u535a\u5f08\u8bba\u89d2\u5ea6\u5206\u6790\u3002", "method": "\u8003\u8651\u535a\u5f08\u8bba\u573a\u666f\uff0c\u7814\u7a76\u7c7b\u4f3cStackelberg\u5e02\u573a\u6a21\u578b\uff0c\u5206\u6790\u4e0d\u540c\u5b9a\u4ef7\u7b56\u7565\u4e0b\u5747\u8861\u60c5\u51b5\u3002", "result": "\u5747\u8861\u7684\u5b58\u5728\u6027\u5173\u952e\u53d6\u51b3\u4e8e\u5b9a\u4ef7\uff0c\u793e\u4f1a\u798f\u5229\u5dee\u5f02\u5927\u3002", "conclusion": "\u9700\u8981\u66f4\u590d\u6742\u7684\u5e02\u573a\u6a21\u578b\u548c\u5b9a\u4ef7\u673a\u5236\uff0c\u4e3a\u53ef\u518d\u751f\u80fd\u6e90\u7f51\u7edc\u6fc0\u52b1\u7684\u7b97\u6cd5\u535a\u5f08\u8bba\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u9886\u57df\u3002"}}
{"id": "2508.06316", "pdf": "https://arxiv.org/pdf/2508.06316", "abs": "https://arxiv.org/abs/2508.06316", "authors": ["Theresa Pollinger", "Masado Ishii", "Jens Domke"], "title": "The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations", "categories": ["cs.DS", "cs.CG", "cs.GR", "cs.IT", "cs.NA", "math.IT", "math.NA", "65D15, 65D18, 68P05, 68P30"], "comment": "contains pdf animations; we recommend Okular or Firefox for viewing", "summary": "Structured adaptive mesh refinement (AMR), commonly implemented via quadtrees\nand octrees, underpins a wide range of applications including databases,\ncomputer graphics, physics simulations, and machine learning. However, octrees\nenforce isotropic refinement in regions of interest, which can be especially\ninefficient for problems that are intrinsically anisotropic--much resolution is\nspent where little information is gained. This paper presents omnitrees as an\nanisotropic generalization of octrees and related data structures. Omnitrees\nallow to refine only the locally most important dimensions, providing tree\nstructures that are less deep than bintrees and less wide than octrees. As a\nresult, the convergence of the AMR schemes can be increased by up to a factor\nof the dimensionality d for very anisotropic problems, quickly offsetting their\nmodest increase in storage overhead. We validate this finding on the problem of\nbinary shape representation across 4,166 three-dimensional objects: Omnitrees\nincrease the mean convergence rate by 1.5x, require less storage to achieve\nequivalent error bounds, and maximize the information density of the stored\nfunction faster than octrees. These advantages are projected to be even\nstronger for higher-dimensional problems. We provide a first validation by\nintroducing a time-dependent rotation to create four-dimensional\nrepresentations, and discuss the properties of their 4-d octree and omnitree\napproximations. Overall, omnitree discretizations can make existing AMR\napproaches more efficient, and open up new possibilities for high-dimensional\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faomnitrees\u4f5c\u4e3a\u516b\u53c9\u6811\u7b49\u7ed3\u6784\u7684\u5404\u5411\u5f02\u6027\u63a8\u5e7f\uff0c\u53ef\u63d0\u5347\u5404\u5411\u5f02\u6027\u95ee\u9898AMR\u65b9\u6848\u6536\u655b\u6027\uff0c\u5728\u4e09\u7ef4\u548c\u56db\u7ef4\u95ee\u9898\u9a8c\u8bc1\u5176\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u516b\u53c9\u6811\u5728\u5404\u5411\u5f02\u6027\u95ee\u9898\u4e2d\u6548\u7387\u4f4e\uff0c\u82b1\u8d39\u5927\u91cf\u5206\u8fa8\u7387\u5374\u6536\u83b7\u4fe1\u606f\u5c11\u3002", "method": "\u63d0\u51faomnitrees\uff0c\u5141\u8bb8\u4ec5\u7ec6\u5316\u5c40\u90e8\u6700\u91cd\u8981\u7ef4\u5ea6\u3002", "result": "\u5728\u4e09\u7ef4\u95ee\u9898\u4e2d\uff0comnitrees\u4f7f\u5e73\u5747\u6536\u655b\u7387\u63d0\u9ad81.5\u500d\uff0c\u5b58\u50a8\u9700\u6c42\u5c11\uff0c\u4fe1\u606f\u5bc6\u5ea6\u63d0\u5347\u5feb\uff1b\u56db\u7ef4\u95ee\u9898\u4e5f\u6709\u4f18\u52bf\u3002", "conclusion": "omnitree\u79bb\u6563\u5316\u53ef\u63d0\u9ad8\u73b0\u6709AMR\u65b9\u6cd5\u6548\u7387\uff0c\u4e3a\u9ad8\u7ef4\u5e94\u7528\u5e26\u6765\u65b0\u53ef\u80fd\u3002"}}
{"id": "2508.05648", "pdf": "https://arxiv.org/pdf/2508.05648", "abs": "https://arxiv.org/abs/2508.05648", "authors": ["Chandler Campbell", "Bernie Boscoe", "Tuan Do"], "title": "AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups", "categories": ["cs.IR", "cs.AI"], "comment": "Accepted to US Research Software Engineer Association (US-RSE) 2025", "summary": "Research groups face persistent challenges in capturing, storing, and\nretrieving knowledge that is distributed across team members. Although\nstructured data intended for analysis and publication is often well managed,\nmuch of a group's collective knowledge remains informal, fragmented, or\nundocumented--often passed down orally through meetings, mentoring, and\nday-to-day collaboration. This includes private resources such as emails,\nmeeting notes, training materials, and ad hoc documentation. Together, these\nreflect the group's tacit knowledge--the informal, experience-based expertise\nthat underlies much of their work. Accessing this knowledge can be difficult,\nrequiring significant time and insider understanding. Retrieval-augmented\ngeneration (RAG) systems offer promising solutions by enabling users to query\nand generate responses grounded in relevant source material. However, most\ncurrent RAG-LLM systems are oriented toward public documents and overlook the\nprivacy concerns of internal research materials. We introduce AquiLLM\n(pronounced ah-quill-em), a lightweight, modular RAG system designed to meet\nthe needs of research groups. AquiLLM supports varied document types and\nconfigurable privacy settings, enabling more effective access to both formal\nand informal knowledge within scholarly groups.", "AI": {"tldr": "\u4ecb\u7ecd\u8f7b\u91cf\u7ea7\u6a21\u5757\u5316RAG\u7cfb\u7edfAquiLLM\uff0c\u89e3\u51b3\u7814\u7a76\u5c0f\u7ec4\u77e5\u8bc6\u83b7\u53d6\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5c0f\u7ec4\u5728\u6355\u83b7\u3001\u5b58\u50a8\u548c\u68c0\u7d22\u5206\u6563\u5728\u6210\u5458\u95f4\u7684\u77e5\u8bc6\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709RAG - LLM\u7cfb\u7edf\u5ffd\u89c6\u5185\u90e8\u7814\u7a76\u6750\u6599\u9690\u79c1\u95ee\u9898\u3002", "method": "\u5f15\u5165AquiLLM\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u79cd\u6587\u6863\u7c7b\u578b\u548c\u53ef\u914d\u7f6e\u9690\u79c1\u8bbe\u7f6e\u3002", "result": "AquiLLM\u53ef\u5b9e\u73b0\u5bf9\u5b66\u672f\u5c0f\u7ec4\u6b63\u5f0f\u548c\u975e\u6b63\u5f0f\u77e5\u8bc6\u66f4\u6709\u6548\u8bbf\u95ee\u3002", "conclusion": "AquiLLM\u80fd\u6ee1\u8db3\u7814\u7a76\u5c0f\u7ec4\u5bf9\u77e5\u8bc6\u83b7\u53d6\u7684\u9700\u6c42\u3002"}}
{"id": "2508.06035", "pdf": "https://arxiv.org/pdf/2508.06035", "abs": "https://arxiv.org/abs/2508.06035", "authors": ["Genaro J. Martinez", "Andrew Adamatzky", "Guanrong Chen"], "title": "Post-apocalyptic computing from cellular automata", "categories": ["nlin.CG", "cs.NE"], "comment": "27 pages, 1 table, 6 figures", "summary": "Cellular automata are arrays of finite state machines that can exist in a\nfinite number of states. These machines update their states simultaneously\nbased on specific local rules that govern their interactions. This framework\nprovides a simple yet powerful model for studying complex systems and emergent\nbehaviors. We revisit and reconsider the traditional notion of an algorithm,\nproposing a novel perspective in which algorithms are represented through the\ndynamic state-space configurations of cellular automata. By doing so, we\nestablish a conceptual framework that connects computation to physical\nprocesses in a unique and innovative way. This approach not only enhances our\nunderstanding of computation but also paves the way for the future development\nof unconventional computing devices. Such devices could be engineered to\nleverage the inherent computational capabilities of physical, chemical, and\nbiological substrates. This opens up new possibilities for designing systems\nthat are more efficient, adaptive, and capable of solving problems in ways that\ntraditional silicon-based computers cannot. The integration of cellular\nautomata into these domains highlights their potential as a transformative tool\nin the ongoing evolution of computational theory and practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5143\u80de\u81ea\u52a8\u673a\u52a8\u6001\u72b6\u6001\u7a7a\u95f4\u914d\u7f6e\u8868\u793a\u7b97\u6cd5\u7684\u65b0\u89c6\u89d2\uff0c\u5efa\u7acb\u8ba1\u7b97\u4e0e\u7269\u7406\u8fc7\u7a0b\u8054\u7cfb\uff0c\u4e3a\u975e\u4f20\u7edf\u8ba1\u7b97\u8bbe\u5907\u53d1\u5c55\u94fa\u8def\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u4f20\u7edf\u7b97\u6cd5\u6982\u5ff5\uff0c\u5efa\u7acb\u8ba1\u7b97\u4e0e\u7269\u7406\u8fc7\u7a0b\u7684\u72ec\u7279\u8054\u7cfb\uff0c\u63a8\u52a8\u975e\u4f20\u7edf\u8ba1\u7b97\u8bbe\u5907\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u5143\u80de\u81ea\u52a8\u673a\u52a8\u6001\u72b6\u6001\u7a7a\u95f4\u914d\u7f6e\u8868\u793a\u7b97\u6cd5\u7684\u65b0\u89c6\u89d2\u3002", "result": "\u5efa\u7acb\u4e86\u72ec\u7279\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u589e\u5f3a\u5bf9\u8ba1\u7b97\u7684\u7406\u89e3\uff0c\u4e3a\u975e\u4f20\u7edf\u8ba1\u7b97\u8bbe\u5907\u53d1\u5c55\u521b\u9020\u53ef\u80fd\u3002", "conclusion": "\u5143\u80de\u81ea\u52a8\u673a\u53ef\u4f5c\u4e3a\u8ba1\u7b97\u7406\u8bba\u548c\u5b9e\u8df5\u53d1\u5c55\u7684\u53d8\u9769\u6027\u5de5\u5177\u3002"}}
{"id": "2508.05747", "pdf": "https://arxiv.org/pdf/2508.05747", "abs": "https://arxiv.org/abs/2508.05747", "authors": ["Rohaizah Abdul Wahid", "Muhamad Said Nizamuddin Nadim", "Suliana Sulaiman", "Syahmi Akmal Shaharudin", "Muhammad Danial Jupikil", "Iqqwan Jasman Su Azlan Su"], "title": "Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework", "categories": ["cs.SE", "cs.ET"], "comment": null, "summary": "Laravel has emerged as a foundational framework in university web development\ncurricula. However, despite its scaffolding capabilities, students often\nstruggle to complete projects within limited academic timelines. This\nconceptual paper introduces Composer, PHP's standard dependency manager, and\ncategorizes a curated selection of Composer packages that significantly reduce\ndevelopment effort while fostering professional software practices. Grounded in\npractical and pedagogical considerations, the paper illustrates how educators\nand learners can strategically leverage these tools to build typical academic\nor personal Laravel-based systems. Central to this approach is maintaining code\nquality and reinforcing conceptual understanding. The paper also addresses\npotential risks such as package conflicts and over-reliance on tools, providing\nbest-practice recommendations to mitigate them. While the goal is to accelerate\ndevelopment, the deeper objective is to reinforce professional workflows and\nindustry readiness. Exposure to Composer packages enhances curriculum relevance\nand smooths the transition from academia to the workplace. However, effective\nintegration requires deliberate instructional design aligned with learning\nobjectives. Without guidance, students may treat packages as black boxes. Thus,\neducators must teach not only how to use these tools, but also when and why,\nencouraging critical evaluation of their utility and limitations. This ensures\nthat practical convenience supports rather than supplants deep learning.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdComposer\u53ca\u5176\u7cbe\u9009\u5305\u53ef\u52a9\u529bLaravel\u5f00\u53d1\uff0c\u52a0\u901f\u9879\u76ee\u5b8c\u6210\uff0c\u540c\u65f6\u5f3a\u8c03\u6559\u5b66\u4e2d\u8981\u5f15\u5bfc\u5b66\u751f\u6b63\u786e\u4f7f\u7528\u4ee5\u786e\u4fdd\u6df1\u5ea6\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u5b66\u751f\u7528Laravel\u5728\u6709\u9650\u65f6\u95f4\u5185\u96be\u5b8c\u6210\u9879\u76ee\u7684\u95ee\u9898\uff0c\u63d0\u5347\u8bfe\u7a0b\u76f8\u5173\u6027\u548c\u5b66\u751f\u804c\u573a\u9002\u5e94\u80fd\u529b\u3002", "method": "\u5f15\u5165Composer\u53ca\u7cbe\u9009\u5305\uff0c\u9610\u8ff0\u5e08\u751f\u5982\u4f55\u5229\u7528\u5176\u6784\u5efaLaravel\u7cfb\u7edf\uff0c\u8fd8\u7ed9\u51fa\u5e94\u5bf9\u6f5c\u5728\u98ce\u9669\u7684\u5efa\u8bae\u3002", "result": "\u53ef\u52a0\u901f\u5f00\u53d1\uff0c\u589e\u5f3a\u8bfe\u7a0b\u76f8\u5173\u6027\uff0c\u52a9\u5b66\u751f\u4ece\u5b66\u672f\u8fc7\u6e21\u5230\u804c\u573a\u3002", "conclusion": "\u6709\u6548\u6574\u5408\u9700\u4e0e\u5b66\u4e60\u76ee\u6807\u4e00\u81f4\u7684\u6559\u5b66\u8bbe\u8ba1\uff0c\u6559\u5e08\u8981\u5f15\u5bfc\u5b66\u751f\u6279\u5224\u6027\u4f7f\u7528\u5de5\u5177\u3002"}}
{"id": "2508.05778", "pdf": "https://arxiv.org/pdf/2508.05778", "abs": "https://arxiv.org/abs/2508.05778", "authors": ["Jaemin Oh", "Jinsil Lee", "Youngjoon Hong"], "title": "Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": "21 pages, 5 figures, 6 tables", "summary": "Nudging is an empirical data assimilation technique that incorporates an\nobservation-driven control term into the model dynamics. The trajectory of the\nnudged system approaches the true system trajectory over time, even when the\ninitial conditions differ. For linear state space models, such control terms\ncan be derived under mild assumptions. However, designing effective nudging\nterms becomes significantly more challenging in the nonlinear setting. In this\nwork, we propose neural network nudging, a data-driven method for learning\nnudging terms in nonlinear state space models. We establish a theoretical\nexistence result based on the Kazantzis--Kravaris--Luenberger observer theory.\nThe proposed approach is evaluated on three benchmark problems that exhibit\nchaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and\nthe Kolmogorov flow.", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u7f51\u7edcnudging\u65b9\u6cd5\u7528\u4e8e\u5b66\u4e60\u975e\u7ebf\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684nudging\u9879\uff0c\u5e76\u5728\u4e09\u4e2a\u6df7\u6c8c\u57fa\u51c6\u95ee\u9898\u4e0a\u8bc4\u4f30\u3002", "motivation": "\u5728\u975e\u7ebf\u6027\u60c5\u51b5\u4e0b\u8bbe\u8ba1\u6709\u6548\u7684nudging\u9879\u6781\u5177\u6311\u6218\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u7684\u795e\u7ecf\u7f51\u7edcnudging\u65b9\u6cd5\uff0c\u57fa\u4e8eKazantzis - Kravaris - Luenberger\u89c2\u6d4b\u5668\u7406\u8bba\u5efa\u7acb\u7406\u8bba\u5b58\u5728\u6027\u7ed3\u679c\u3002", "result": "\u672a\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\uff0c\u5bf9\u4e09\u4e2a\u6709\u6df7\u6c8c\u884c\u4e3a\u7684\u57fa\u51c6\u95ee\u9898\u8fdb\u884c\u8bc4\u4f30\u3002", "conclusion": "\u672a\u660e\u786e\u7ed9\u51fa\u7ed3\u8bba\u3002"}}
{"id": "2508.05764", "pdf": "https://arxiv.org/pdf/2508.05764", "abs": "https://arxiv.org/abs/2508.05764", "authors": ["Arvind K. Saibaba", "Ilse C. F. Ipsen"], "title": "Stochastic Trace Optimization of Parameter Dependent Matrices Based on Statistical Learning Theory", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA", "15A15, 65F99, 65C05, 68W20, 68Q32"], "comment": "3 figures", "summary": "We consider matrices $\\boldsymbol{A}(\\boldsymbol\\theta)\\in\\mathbb{R}^{m\\times\nm}$ that depend, possibly nonlinearly, on a parameter $\\boldsymbol\\theta$ from\na compact parameter space $\\Theta$. We present a Monte Carlo estimator for\nminimizing $\\text{trace}(\\boldsymbol{A}(\\boldsymbol\\theta))$ over all\n$\\boldsymbol\\theta\\in\\Theta$, and determine the sampling amount so that the\nbackward error of the estimator is bounded with high probability. We derive two\ntypes of bounds, based on epsilon nets and on generic chaining. Both types\npredict a small sampling amount for matrices\n$\\boldsymbol{A}(\\boldsymbol\\theta)$ with small offdiagonal mass, and parameter\nspaces $\\Theta$ of small ``size.'' Dependence on the matrix dimension~$m$ is\nonly weak or not explicit. The bounds based on epsilon nets are easier to\nevaluate and come with fully specified constants. In contrast, the bounds based\non chaining depend on the Talagrand functionals which are difficult to\nevaluate, except in very special cases. Comparisons between the two types of\nbounds are difficult, although the literature suggests that chaining bounds can\nbe superior.", "AI": {"tldr": "\u63d0\u51fa\u8499\u7279\u5361\u7f57\u4f30\u8ba1\u5668\u6700\u5c0f\u5316\u77e9\u9635\u8ff9\uff0c\u786e\u5b9a\u91c7\u6837\u91cf\u4f7f\u4f30\u8ba1\u5668\u540e\u5411\u8bef\u5dee\u9ad8\u6982\u7387\u6709\u754c\uff0c\u63a8\u5bfc\u57fa\u4e8eepsilon\u7f51\u548c\u6cdb\u94fe\u7684\u4e24\u7c7b\u754c\u5e76\u6bd4\u8f83\u3002", "motivation": "\u7814\u7a76\u4f9d\u8d56\u53c2\u6570\u7684\u77e9\u9635\uff0c\u6700\u5c0f\u5316\u77e9\u9635\u8ff9\u5e76\u63a7\u5236\u4f30\u8ba1\u5668\u8bef\u5dee\u3002", "method": "\u63d0\u51fa\u8499\u7279\u5361\u7f57\u4f30\u8ba1\u5668\uff0c\u63a8\u5bfc\u57fa\u4e8eepsilon\u7f51\u548c\u6cdb\u94fe\u7684\u4e24\u7c7b\u754c\u3002", "result": "\u4e24\u7c7b\u754c\u5bf9\u975e\u5bf9\u89d2\u5143\u7d20\u8d28\u91cf\u5c0f\u7684\u77e9\u9635\u548c\u5c0f\u201c\u5c3a\u5bf8\u201d\u53c2\u6570\u7a7a\u95f4\u6240\u9700\u91c7\u6837\u91cf\u5c0f\uff0c\u5bf9\u77e9\u9635\u7ef4\u5ea6\u4f9d\u8d56\u5f31\uff1bepsilon\u7f51\u754c\u6613\u8bc4\u4f30\uff0c\u94fe\u754c\u4f9d\u8d56\u96be\u8bc4\u4f30\u7684Talagrand\u6cdb\u51fd\u3002", "conclusion": "\u96be\u4ee5\u6bd4\u8f83\u4e24\u7c7b\u754c\uff0c\u4f46\u6587\u732e\u663e\u793a\u94fe\u754c\u53ef\u80fd\u66f4\u4f18\u3002"}}
{"id": "2508.05996", "pdf": "https://arxiv.org/pdf/2508.05996", "abs": "https://arxiv.org/abs/2508.05996", "authors": ["Kaitao Chen", "Mianxin Liu", "Daoming Zong", "Chaoyue Ding", "Shaohao Rui", "Yankai Jiang", "Mu Zhou", "Xiaosong Wang"], "title": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making", "categories": ["cs.AI"], "comment": "14 pages, 4 figures", "summary": "Complex medical decision-making involves cooperative workflows operated by\ndifferent clinicians. Designing AI multi-agent systems can expedite and augment\nhuman-level clinical decision-making. Existing multi-agent researches primarily\nfocus on language-only tasks, yet their extension to multimodal scenarios\nremains challenging. A blind combination of diverse vision-language models\n(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are\nless capable in instruction following and importantly self-reflection, compared\nto large language models (LLMs) of comparable sizes. This disparity largely\nconstrains VLMs' ability in cooperative workflows. In this study, we propose\nMedOrch, a mediator-guided multi-agent collaboration framework for medical\nmultimodal decision-making. MedOrch employs an LLM-based mediator agent that\nenables multiple VLM-based expert agents to exchange and reflect on their\noutputs towards collaboration. We utilize multiple open-source general-purpose\nand domain-specific VLMs instead of costly GPT-series models, revealing the\nstrength of heterogeneous models. We show that the collaboration within\ndistinct VLM-based agents can surpass the capabilities of any individual agent.\nWe validate our approach on five medical vision question answering benchmarks,\ndemonstrating superior collaboration performance without model training. Our\nfindings underscore the value of mediator-guided multi-agent collaboration in\nadvancing medical multimodal intelligence. Our code will be made publicly\navailable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMedOrch\u6846\u67b6\u7528\u4e8e\u533b\u7597\u591a\u6a21\u6001\u51b3\u7b56\uff0c\u5229\u7528\u591aVLM\u4ee3\u7406\u534f\u4f5c\uff0c\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u5176\u6027\u80fd\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7eaf\u8bed\u8a00\u4efb\u52a1\uff0c\u6269\u5c55\u5230\u591a\u6a21\u6001\u573a\u666f\u6709\u6311\u6218\uff0cVLM\u5728\u6307\u4ee4\u9075\u5faa\u548c\u81ea\u6211\u53cd\u601d\u4e0a\u4e0d\u5982LLM\uff0c\u9650\u5236\u5176\u5728\u534f\u4f5c\u6d41\u7a0b\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faMedOrch\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8eLLM\u7684\u4e2d\u4ecb\u4ee3\u7406\u8ba9\u591a\u4e2a\u57fa\u4e8eVLM\u7684\u4e13\u5bb6\u4ee3\u7406\u4ea4\u6362\u548c\u53cd\u601d\u8f93\u51fa\u4ee5\u5b9e\u73b0\u534f\u4f5c\uff0c\u5229\u7528\u591a\u4e2a\u5f00\u6e90VLM\u3002", "result": "\u4e0d\u540c\u57fa\u4e8eVLM\u7684\u4ee3\u7406\u4e4b\u95f4\u7684\u534f\u4f5c\u80fd\u8d85\u8d8a\u4efb\u4f55\u5355\u4e2a\u4ee3\u7406\uff0c\u5728\u4e94\u4e2a\u533b\u7597\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u65e0\u9700\u6a21\u578b\u8bad\u7ec3\u7684\u5353\u8d8a\u534f\u4f5c\u6027\u80fd\u3002", "conclusion": "\u4e2d\u4ecb\u5f15\u5bfc\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5bf9\u63a8\u8fdb\u533b\u7597\u591a\u6a21\u6001\u667a\u80fd\u6709\u4ef7\u503c\u3002"}}
{"id": "2508.06001", "pdf": "https://arxiv.org/pdf/2508.06001", "abs": "https://arxiv.org/abs/2508.06001", "authors": ["Kai Zhang", "Peng Wang", "Sai Bi", "Jianming Zhang", "Yuanjun Xiong"], "title": "KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training", "categories": ["cs.DC", "cs.CV"], "comment": "Code is available at https://github.com/Kai-46/KnapFormer/", "summary": "We present KnapFormer, an efficient and versatile framework to combine\nworkload balancing and sequence parallelism in distributed training of\nDiffusion Transformers (DiT). KnapFormer builds on the insight that strong\nsynergy exists between sequence parallelism and the need to address the\nsignificant token imbalance across ranks. This imbalance arises from\nvariable-length text inputs and varying visual token counts in mixed-resolution\nand image-video joint training. KnapFormer redistributes tokens by first\ngathering sequence length metadata across all ranks in a balancing group and\nsolving a global knapsack problem. The solver aims to minimize the variances of\ntotal workload per-GPU, while accounting for the effect of sequence\nparallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the\nload-balancing decision process and utilizing a simple semi-empirical workload\nmodel, KnapFormers achieves minimal communication overhead and less than 1%\nworkload discrepancy in real-world training workloads with sequence length\nvarying from a few hundred to tens of thousands. It eliminates straggler\neffects and achieves 2x to 3x speedup when training state-of-the-art diffusion\nmodels like FLUX on mixed-resolution and image-video joint data corpora. We\nopen-source the KnapFormer implementation at\nhttps://github.com/Kai-46/KnapFormer/", "AI": {"tldr": "\u63d0\u51faKnapFormer\u6846\u67b6\u7ed3\u5408\u8d1f\u8f7d\u5747\u8861\u548c\u5e8f\u5217\u5e76\u884c\u7528\u4e8eDiffusion Transformers\u5206\u5e03\u5f0f\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4f4e\u901a\u4fe1\u5f00\u9500\u548c\u4f4e\u8d1f\u8f7d\u5dee\u5f02\uff0c\u52a0\u901f\u8bad\u7ec3\u5e76\u5f00\u6e90\u3002", "motivation": "\u89e3\u51b3Diffusion Transformers\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u56e0\u53ef\u53d8\u957f\u5ea6\u6587\u672c\u8f93\u5165\u548c\u4e0d\u540c\u89c6\u89c9\u6807\u8bb0\u8ba1\u6570\u5bfc\u81f4\u7684\u5404\u8fdb\u7a0b\u95f4\u663e\u8457\u7684\u6807\u8bb0\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5728\u5e73\u8861\u7ec4\u4e2d\u6536\u96c6\u6240\u6709\u8fdb\u7a0b\u7684\u5e8f\u5217\u957f\u5ea6\u5143\u6570\u636e\u5e76\u89e3\u51b3\u5168\u5c40\u80cc\u5305\u95ee\u9898\u6765\u91cd\u65b0\u5206\u914d\u6807\u8bb0\uff0c\u5728\u8d1f\u8f7d\u5747\u8861\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u96c6\u6210\u57fa\u4e8eDeepSpeed - Ulysees\u7684\u5e8f\u5217\u5e76\u884c\uff0c\u5e76\u4f7f\u7528\u534a\u7ecf\u9a8c\u5de5\u4f5c\u8d1f\u8f7d\u6a21\u578b\u3002", "result": "\u5728\u5b9e\u9645\u8bad\u7ec3\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u5b9e\u73b0\u6700\u5c0f\u901a\u4fe1\u5f00\u9500\u548c\u5c0f\u4e8e1%\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5dee\u5f02\uff0c\u6d88\u9664\u62d6\u540e\u817f\u6548\u5e94\uff0c\u5728\u8bad\u7ec3\u5982FLUX\u7b49\u6269\u6563\u6a21\u578b\u65f6\u5b9e\u73b02 - 3\u500d\u52a0\u901f\u3002", "conclusion": "KnapFormer\u662f\u4e00\u4e2a\u9ad8\u6548\u4e14\u901a\u7528\u7684\u6846\u67b6\uff0c\u53ef\u6709\u6548\u7ed3\u5408\u8d1f\u8f7d\u5747\u8861\u548c\u5e8f\u5217\u5e76\u884c\u8fdb\u884cDiffusion Transformers\u5206\u5e03\u5f0f\u8bad\u7ec3\u3002"}}
{"id": "2508.06469", "pdf": "https://arxiv.org/pdf/2508.06469", "abs": "https://arxiv.org/abs/2508.06469", "authors": ["Jason Hartline", "Kangning Wang"], "title": "A Geometric Analysis of Gains from Trade", "categories": ["cs.GT", "econ.TH"], "comment": null, "summary": "We provide a geometric proof that the random proposer mechanism is a\n$4$-approximation to the first-best gains from trade in bilateral exchange. We\nthen refine this geometric analysis to recover the state-of-the-art\napproximation ratio of $3.15$.", "AI": {"tldr": "\u7ed9\u51fa\u968f\u673a\u63d0\u8bae\u8005\u673a\u5236\u5728\u53cc\u8fb9\u4ea4\u6362\u4e2d\u5bf9\u6700\u4f18\u8d38\u6613\u6536\u76ca\u7684\u8fd1\u4f3c\u6bd4\u7684\u51e0\u4f55\u8bc1\u660e\uff0c\u5e76\u4f18\u5316\u5206\u6790\u5f97\u5230\u5f53\u524d\u6700\u4f18\u8fd1\u4f3c\u6bd43.15", "motivation": "\u7814\u7a76\u968f\u673a\u63d0\u8bae\u8005\u673a\u5236\u5728\u53cc\u8fb9\u4ea4\u6362\u4e2d\u5bf9\u6700\u4f18\u8d38\u6613\u6536\u76ca\u7684\u8fd1\u4f3c\u60c5\u51b5", "method": "\u91c7\u7528\u51e0\u4f55\u8bc1\u660e\u65b9\u6cd5\uff0c\u5148\u8bc1\u660e\u662f4 - \u8fd1\u4f3c\uff0c\u540e\u4f18\u5316\u5206\u6790", "result": "\u5f97\u5230\u968f\u673a\u63d0\u8bae\u8005\u673a\u5236\u662f4 - \u8fd1\u4f3c\uff0c\u540e\u5c06\u8fd1\u4f3c\u6bd4\u4f18\u5316\u52303.15", "conclusion": "\u901a\u8fc7\u51e0\u4f55\u8bc1\u660e\u548c\u4f18\u5316\u5206\u6790\uff0c\u5f97\u51fa\u968f\u673a\u63d0\u8bae\u8005\u673a\u5236\u5728\u53cc\u8fb9\u4ea4\u6362\u4e2d\u5bf9\u6700\u4f18\u8d38\u6613\u6536\u76ca\u7684\u8f83\u597d\u8fd1\u4f3c\u6bd4"}}
{"id": "2508.06460", "pdf": "https://arxiv.org/pdf/2508.06460", "abs": "https://arxiv.org/abs/2508.06460", "authors": ["Akash Pareek", "Supratim Shit"], "title": "A Simple PTAS for Weighted $k$-means and Sensor Coverage", "categories": ["cs.DS"], "comment": null, "summary": "Clustering is a fundamental technique in data analysis, with the $k$-means\nbeing one of the widely studied objectives due to its simplicity and broad\napplicability. In many practical scenarios, data points come with associated\nweights that reflect their importance, frequency, or confidence. Given a\nweighted point set $P \\subset R^d$, where each point $p \\in P$ has a positive\nweight $w_p$, the goal is to compute a set of $k$ centers $C = \\{ c_1, c_2,\n\\ldots, c_k \\} \\subset R^d$ that minimizes the weighted clustering cost:\n$\\Delta_w(P,C) = \\sum_{p \\in P} w_p \\cdot d(p,C)^2$, where $d(p,C)$ denotes the\nEuclidean distance from $p$ to its nearest center in $C$. Although most\nexisting coreset-based algorithms for $k$-means extend naturally to the\nweighted setting and provide a PTAS, no prior work has offered a simple,\ncoreset-free PTAS designed specifically for the weighted $k$-means problem.\n  In this paper, we present a simple PTAS for weighted $k$-means that does not\nrely on coresets. Building upon the framework of Jaiswal, Kumar, and Sen (2012)\nfor the unweighted case, we extend the result to the weighted setting by using\nthe weighted $D^2$-sampling technique. Our algorithm runs in time $n d \\cdot\n2^{O\\left(\\frac{k^2}{\\epsilon}\\right)}$ and outputs a set of $k$ centers whose\ntotal clustering cost is within a $(1 + \\epsilon)$-factor of the optimal cost.\nAs a key application of the weighted $k$-means, we obtain a PTAS for the sensor\ncoverage problem, which can also be viewed as a continuous locational\noptimization problem. For this problem, the best-known result prior to our work\nwas an $O(\\log k)$-approximation by Deshpande (2014), whereas our algorithm\nguarantees a $(1 + \\epsilon)$-approximation to the optimal coverage cost even\nbefore applying refinement steps like Lloyd desent.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.05649", "pdf": "https://arxiv.org/pdf/2508.05649", "abs": "https://arxiv.org/abs/2508.05649", "authors": ["Jayanth Yetukuri", "Mehran Elyasi", "Samarth Agrawal", "Aritra Mandal", "Rui Kong", "Harish Vempati", "Ishita Khan"], "title": "AI Guided Accelerator For Search Experience", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted at SIGIR eCom'25.\n  https://sigir-ecom.github.io/eCom25Papers/paper_25.pdf", "summary": "Effective query reformulation is pivotal in narrowing the gap between a\nuser's exploratory search behavior and the identification of relevant products\nin e-commerce environments. While traditional approaches predominantly model\nquery rewrites as isolated pairs, they often fail to capture the sequential and\ntransitional dynamics inherent in real-world user behavior. In this work, we\npropose a novel framework that explicitly models transitional\nqueries--intermediate reformulations occurring during the user's journey toward\ntheir final purchase intent. By mining structured query trajectories from\neBay's large-scale user interaction logs, we reconstruct query sequences that\nreflect shifts in intent while preserving semantic coherence. This approach\nallows us to model a user's shopping funnel, where mid-journey transitions\nreflect exploratory behavior and intent refinement. Furthermore, we incorporate\ngenerative Large Language Models (LLMs) to produce semantically diverse and\nintent-preserving alternative queries, extending beyond what can be derived\nthrough collaborative filtering alone. These reformulations can be leveraged to\npopulate Related Searches or to power intent-clustered carousels on the search\nresults page, enhancing both discovery and engagement. Our contributions\ninclude (i) the formal identification and modeling of transitional queries,\n(ii) the introduction of a structured query sequence mining pipeline for intent\nflow understanding, and (iii) the application of LLMs for scalable,\nintent-aware query expansion. Empirical evaluation demonstrates measurable\ngains in conversion and engagement metrics compared to the existing Related\nSearches module, validating the effectiveness of our approach in real-world\ne-commerce settings.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u6846\u67b6\u5efa\u6a21\u8fc7\u6e21\u67e5\u8be2\uff0c\u7ed3\u5408LLMs\u6269\u5c55\u67e5\u8be2\uff0c\u5728\u7535\u5546\u573a\u666f\u63d0\u5347\u8f6c\u5316\u548c\u53c2\u4e0e\u5ea6\u3002", "motivation": "\u4f20\u7edf\u67e5\u8be2\u91cd\u5199\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u7528\u6237\u884c\u4e3a\u7684\u987a\u5e8f\u548c\u8fc7\u6e21\u52a8\u6001\uff0c\u9700\u6709\u6548\u65b9\u6cd5\u7f29\u5c0f\u7528\u6237\u641c\u7d22\u884c\u4e3a\u4e0e\u5546\u54c1\u8bc6\u522b\u7684\u5dee\u8ddd\u3002", "method": "\u4eceeBay\u7528\u6237\u4ea4\u4e92\u65e5\u5fd7\u6316\u6398\u7ed3\u6784\u5316\u67e5\u8be2\u8f68\u8ff9\uff0c\u91cd\u5efa\u67e5\u8be2\u5e8f\u5217\uff1b\u5f15\u5165\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u66ff\u4ee3\u67e5\u8be2\u3002", "result": "\u4e0e\u73b0\u6709\u76f8\u5173\u641c\u7d22\u6a21\u5757\u76f8\u6bd4\uff0c\u5728\u8f6c\u5316\u548c\u53c2\u4e0e\u5ea6\u6307\u6807\u4e0a\u6709\u53ef\u8861\u91cf\u7684\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b9e\u9645\u7535\u5546\u73af\u5883\u4e2d\u6709\u6548\u3002"}}
{"id": "2508.06085", "pdf": "https://arxiv.org/pdf/2508.06085", "abs": "https://arxiv.org/abs/2508.06085", "authors": ["Genki Shimizu", "Taro Toyoizumi"], "title": "Diverse Neural Sequences in QIF Networks: An Analytically Tractable Framework for Synfire Chains and Hippocampal Replay", "categories": ["q-bio.NC", "cs.NE"], "comment": "Accepted to ICONIP 2025 (Oral). Version of Record will appear in\n  Springer LNCS; DOI to be added upon publication", "summary": "Sequential neural activity is fundamental to cognition, yet how diverse\nsequences are recalled under biological constraints remains a key question.\nExisting models often struggle to balance biophysical realism and analytical\ntractability. We address this problem by proposing a parsimonious network of\nQuadratic Integrate-and-Fire (QIF) neurons with sequences embedded via a\ntemporally asymmetric Hebbian (TAH) rule. Our findings demonstrate that this\nsingle framework robustly reproduces a spectrum of sequential activities,\nincluding persistent synfire-like chains and transient, hippocampal replay-like\nbursts exhibiting intra-ripple frequency accommodation (IFA), all achieved\nwithout requiring specialized delay or adaptation mechanisms. Crucially, we\nderive exact low-dimensional firing-rate equations (FREs) that provide\nmechanistic insight, elucidating the bifurcation structure governing these\ndistinct dynamical regimes and explaining their stability. The model also\nexhibits strong robustness to synaptic heterogeneity and memory pattern\noverlap. These results establish QIF networks with TAH connectivity as an\nanalytically tractable and biologically plausible platform for investigating\nthe emergence, stability, and diversity of sequential neural activity in the\nbrain.", "AI": {"tldr": "\u63d0\u51fa\u542bTAH\u89c4\u5219\u7684QIF\u795e\u7ecf\u5143\u7f51\u7edc\u7814\u7a76\u5e8f\u5217\u795e\u7ecf\u6d3b\u52a8\uff0c\u80fd\u590d\u73b0\u591a\u79cd\u6d3b\u52a8\uff0c\u63a8\u5bfcFRE\u65b9\u7a0b\u63ed\u793a\u673a\u5236\uff0c\u7f51\u7edc\u5177\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u5e73\u8861\u751f\u7269\u7269\u7406\u771f\u5b9e\u6027\u548c\u5206\u6790\u6613\u5904\u7406\u6027\uff0c\u9700\u89e3\u51b3\u5982\u4f55\u5728\u751f\u7269\u7ea6\u675f\u4e0b\u56de\u5fc6\u4e0d\u540c\u5e8f\u5217\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u542bTAH\u89c4\u5219\u7684QIF\u795e\u7ecf\u5143\u7b80\u7ea6\u7f51\u7edc\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u590d\u73b0\u591a\u79cd\u5e8f\u5217\u6d3b\u52a8\uff0c\u63a8\u5bfcFRE\u65b9\u7a0b\u9610\u660e\u5206\u53c9\u7ed3\u6784\u548c\u7a33\u5b9a\u6027\uff0c\u7f51\u7edc\u5bf9\u7a81\u89e6\u5f02\u8d28\u6027\u548c\u8bb0\u5fc6\u6a21\u5f0f\u91cd\u53e0\u5177\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u542bTAH\u8fde\u63a5\u7684QIF\u7f51\u7edc\u662f\u7814\u7a76\u5927\u8111\u5e8f\u5217\u795e\u7ecf\u6d3b\u52a8\u7684\u5206\u6790\u6613\u5904\u7406\u4e14\u751f\u7269\u5408\u7406\u7684\u5e73\u53f0\u3002"}}
{"id": "2508.05799", "pdf": "https://arxiv.org/pdf/2508.05799", "abs": "https://arxiv.org/abs/2508.05799", "authors": ["Yoseph Berhanu Alebachew"], "title": "AI-Guided Exploration of Large-Scale Codebases", "categories": ["cs.SE", "cs.AI", "cs.HC"], "comment": null, "summary": "Understanding large-scale, complex software systems is a major challenge for\ndevelopers, who spend a significant portion of their time on program\ncomprehension. Traditional tools such as static visualizations and reverse\nengineering techniques provide structural insights but often lack\ninteractivity, adaptability, and integration with contextual information.\nRecent advancements in large language models (LLMs) offer new opportunities to\nenhance code exploration workflows, yet their lack of grounding and integration\nwith structured views limits their effectiveness. This work introduces a hybrid\napproach that integrates deterministic reverse engineering with LLM-guided,\nintent-aware visual exploration. The proposed system combines UML-based\nvisualization, dynamic user interfaces, historical context, and collaborative\nfeatures into an adaptive tool for code comprehension. By interpreting user\nqueries and interaction patterns, the LLM helps developers navigate and\nunderstand complex codebases more effectively. A prototype implementation for\nJava demonstrates the feasibility of this approach. Future work includes\nempirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM\ninteraction models. This research lays the groundwork for intelligent,\ninteractive environments that align with developer cognition and collaborative\nworkflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u786e\u5b9a\u6027\u9006\u5411\u5de5\u7a0b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u3001\u610f\u56fe\u611f\u77e5\u7684\u53ef\u89c6\u5316\u63a2\u7d22\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u4ee3\u7801\u7406\u89e3\uff0c\u5e76\u7528Java\u5b9e\u73b0\u539f\u578b\u3002", "motivation": "\u4f20\u7edf\u5de5\u5177\u7f3a\u4e4f\u4ea4\u4e92\u6027\u3001\u9002\u5e94\u6027\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u96c6\u6210\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u4e0e\u7ed3\u6784\u5316\u89c6\u56fe\u7684\u96c6\u6210\uff0c\u5f71\u54cd\u4ee3\u7801\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5\uff0c\u5c06UML\u53ef\u89c6\u5316\u3001\u52a8\u6001\u754c\u9762\u3001\u5386\u53f2\u4e0a\u4e0b\u6587\u548c\u534f\u4f5c\u529f\u80fd\u96c6\u6210\u5230\u81ea\u9002\u5e94\u5de5\u5177\u4e2d\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u8bfb\u7528\u6237\u67e5\u8be2\u548c\u4ea4\u4e92\u6a21\u5f0f\u3002", "result": "\u5b9e\u73b0Java\u539f\u578b\uff0c\u8bc1\u660e\u65b9\u6cd5\u53ef\u884c\u3002", "conclusion": "\u4e3a\u7b26\u5408\u5f00\u53d1\u8005\u8ba4\u77e5\u548c\u534f\u4f5c\u5de5\u4f5c\u6d41\u7684\u667a\u80fd\u4ea4\u4e92\u73af\u5883\u5960\u5b9a\u57fa\u7840\uff0c\u672a\u6765\u9700\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3001\u6269\u5c55\u5230\u591a\u8bed\u8a00\u7cfb\u7edf\u548c\u63a2\u7d22GUI\u9a71\u52a8\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u6a21\u5f0f\u3002"}}
{"id": "2508.05791", "pdf": "https://arxiv.org/pdf/2508.05791", "abs": "https://arxiv.org/abs/2508.05791", "authors": ["Haoran Li", "Lihao Mai", "Muhao Guo", "Jiaqi Wu", "Yang Weng", "Yannan Sun", "Ce Jimmy Liu"], "title": "From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages", "summary": "Accurate distribution grid topology is essential for reliable modern grid\noperations. However, real-world utility data originates from multiple sources\nwith varying characteristics and levels of quality. In this work, developed in\ncollaboration with Oncor Electric Delivery, we propose a scalable framework\nthat reconstructs a trustworthy grid topology by systematically integrating\nheterogeneous data. We observe that distribution topology is fundamentally\ngoverned by two complementary dimensions: the spatial layout of physical\ninfrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the\nsystem in the signal domain (e.g., voltage time series). When jointly\nleveraged, these dimensions support a complete and physically coherent\nreconstruction of network connectivity. To address the challenge of uneven data\nquality without compromising observability, we introduce a confidence-aware\ninference mechanism that preserves structurally informative yet imperfect\ninputs, while quantifying the reliability of each inferred connection for\noperator interpretation. This soft handling of uncertainty is tightly coupled\nwith hard enforcement of physical feasibility: we embed operational\nconstraints, such as transformer capacity limits and radial topology\nrequirements, directly into the learning process. Together, these components\nensure that inference is both uncertainty-aware and structurally valid,\nenabling rapid convergence to actionable, trustworthy topologies under\nreal-world deployment conditions. The proposed framework is validated using\ndata from over 8000 meters across 3 feeders in Oncor's service territory,\ndemonstrating over 95% accuracy in topology reconstruction and substantial\nimprovements in confidence calibration and computational efficiency relative to\nbaseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u7ed3\u5408\u5f02\u6784\u6570\u636e\u91cd\u5efa\u7535\u7f51\u62d3\u6251\uff0c\u7ecf\u5b9e\u9645\u6570\u636e\u9a8c\u8bc1\u6548\u679c\u826f\u597d\u3002", "motivation": "\u5b9e\u9645\u7535\u7f51\u6570\u636e\u6765\u6e90\u591a\u6837\u3001\u8d28\u91cf\u4e0d\u4e00\uff0c\u9700\u53ef\u9760\u65b9\u6cd5\u91cd\u5efa\u7535\u7f51\u62d3\u6251\u3002", "method": "\u63d0\u51fa\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u7ed3\u5408\u7269\u7406\u57fa\u7840\u8bbe\u65bd\u7a7a\u95f4\u5e03\u5c40\u548c\u7cfb\u7edf\u4fe1\u53f7\u57df\u52a8\u6001\u884c\u4e3a\u4e24\u65b9\u9762\u6570\u636e\uff1b\u5f15\u5165\u7f6e\u4fe1\u5ea6\u611f\u77e5\u63a8\u7406\u673a\u5236\u5904\u7406\u6570\u636e\u8d28\u91cf\u4e0d\u5747\u95ee\u9898\uff0c\u540c\u65f6\u5d4c\u5165\u7269\u7406\u53ef\u884c\u6027\u7ea6\u675f\u3002", "result": "\u4f7f\u7528Oncor\u670d\u52a1\u533a\u57df\u51853\u4e2a\u9988\u7ebf\u8d858000\u4e2a\u7535\u8868\u6570\u636e\u9a8c\u8bc1\uff0c\u62d3\u6251\u91cd\u5efa\u51c6\u786e\u7387\u8d8595%\uff0c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u8ba1\u7b97\u6548\u7387\u8f83\u57fa\u7ebf\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u5728\u5b9e\u9645\u90e8\u7f72\u6761\u4ef6\u4e0b\u5feb\u901f\u6536\u655b\u5230\u53ef\u9760\u53ef\u884c\u52a8\u7684\u62d3\u6251\u7ed3\u6784\u3002"}}
{"id": "2508.06069", "pdf": "https://arxiv.org/pdf/2508.06069", "abs": "https://arxiv.org/abs/2508.06069", "authors": ["Bo Yang", "Ruixuan Luo", "Junqi Jin", "Han Zhu"], "title": "Lightweight Auto-bidding based on Traffic Prediction in Live Advertising", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Internet live streaming is widely used in online entertainment and\ne-commerce, where live advertising is an important marketing tool for anchors.\nAn advertising campaign hopes to maximize the effect (such as conversions)\nunder constraints (such as budget and cost-per-click). The mainstream control\nof campaigns is auto-bidding, where the performance depends on the decision of\nthe bidding algorithm in each request. The most widely used auto-bidding\nalgorithms include Proportional-Integral-Derivative (PID) control, linear\nprogramming (LP), reinforcement learning (RL), etc. Existing methods either do\nnot consider the entire time traffic, or have too high computational\ncomplexity. In this paper, the live advertising has high requirements for\nreal-time bidding (second-level control) and faces the difficulty of unknown\nfuture traffic. Therefore, we propose a lightweight bidding algorithm Binary\nConstrained Bidding (BiCB), which neatly combines the optimal bidding formula\ngiven by mathematical analysis and the statistical method of future traffic\nestimation, and obtains good approximation to the optimal result through a low\ncomplexity solution. In addition, we complement the form of upper and lower\nbound constraints for traditional auto-bidding modeling and give theoretical\nanalysis of BiCB. Sufficient offline and online experiments prove BiCB's good\nperformance and low engineering cost.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u76f4\u64ad\u5e7f\u544a\u5b9e\u65f6\u7ade\u4ef7\u9700\u6c42\u548c\u672a\u77e5\u6d41\u91cf\u96be\u9898\uff0c\u63d0\u51fa\u8f7b\u91cf\u7ea7\u7ade\u4ef7\u7b97\u6cd5BiCB\uff0c\u7ed3\u5408\u6570\u5b66\u5206\u6790\u4e0e\u6d41\u91cf\u4f30\u8ba1\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u597d\u4e14\u5de5\u7a0b\u6210\u672c\u4f4e\u3002", "motivation": "\u73b0\u6709\u76f4\u64ad\u5e7f\u544a\u81ea\u52a8\u7ade\u4ef7\u7b97\u6cd5\u8981\u4e48\u4e0d\u8003\u8651\u5168\u65f6\u6bb5\u6d41\u91cf\uff0c\u8981\u4e48\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u4e14\u76f4\u64ad\u5e7f\u544a\u6709\u5b9e\u65f6\u7ade\u4ef7\u9700\u6c42\u548c\u672a\u77e5\u6d41\u91cf\u96be\u9898\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u7ade\u4ef7\u7b97\u6cd5BiCB\uff0c\u7ed3\u5408\u6570\u5b66\u5206\u6790\u7ed9\u51fa\u7684\u6700\u4f18\u7ade\u4ef7\u516c\u5f0f\u548c\u672a\u6765\u6d41\u91cf\u4f30\u8ba1\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u8865\u5145\u4f20\u7edf\u81ea\u52a8\u7ade\u4ef7\u5efa\u6a21\u7684\u4e0a\u4e0b\u754c\u7ea6\u675f\u5f62\u5f0f\u5e76\u8fdb\u884c\u7406\u8bba\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5145\u5206\u7684\u79bb\u7ebf\u548c\u5728\u7ebf\u5b9e\u9a8c\uff0c\u8bc1\u660eBiCB\u6709\u826f\u597d\u7684\u6027\u80fd\u548c\u8f83\u4f4e\u7684\u5de5\u7a0b\u6210\u672c\u3002", "conclusion": "BiCB\u7b97\u6cd5\u80fd\u8f83\u597d\u5730\u89e3\u51b3\u76f4\u64ad\u5e7f\u544a\u7ade\u4ef7\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u6027\u80fd\u548c\u4f4e\u5de5\u7a0b\u6210\u672c\u3002"}}
{"id": "2508.06042", "pdf": "https://arxiv.org/pdf/2508.06042", "abs": "https://arxiv.org/abs/2508.06042", "authors": ["Daechul Ahn", "San Kim", "Jonghyun Choi"], "title": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning", "categories": ["cs.AI"], "comment": "COLM 2025", "summary": "Large Language Models (LLMs) have recently demonstrated impressive action\nsequence prediction capabilities but often struggle with dynamic, long-horizon\ntasks such as real-time strategic games. In a game such as StarCraftII (SC2),\nagents need to manage resource constraints and adapt to evolving battlefield\nsituations in a partially observable environment. This often overwhelms\nexisiting LLM-based approaches. To address these challenges, we propose a\nhierarchical multi-agent framework that employs specialized imitation learning\nagents under a meta-controller called Strategic Planner (SP). By expert\ndemonstrations, each specialized agent learns a distinctive strategy, such as\naerial support or defensive maneuvers, and produces coherent, structured\nmultistep action sequences. The SP then orchestrates these proposals into a\nsingle, environmentally adaptive plan that ensures local decisions aligning\nwith long-term strategies. We call this HIMA (Hierarchical Imitation\nMulti-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that\nencompasses all race match combinations in SC2. Our empirical results show that\nHIMA outperforms state of the arts in strategic clarity, adaptability, and\ncomputational efficiency, underscoring the potential of combining specialized\nimitation modules with meta-level orchestration to develop more robust,\ngeneral-purpose AI agents.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u6a21\u4eff\u591a\u667a\u80fd\u4f53\u6846\u67b6HIMA\u548c\u6d4b\u8bd5\u5e73\u53f0TEXTSCII - ALL\uff0cHIMA\u5728\u6218\u7565\u6e05\u6670\u5ea6\u3001\u9002\u5e94\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u65f6\u6218\u7565\u6e38\u620f\u7b49\u52a8\u6001\u3001\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u661f\u9645\u4e89\u9738II\u8fd9\u7c7b\u6e38\u620f\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u591a\u667a\u80fd\u4f53\u6846\u67b6HIMA\uff0c\u5229\u7528\u4e13\u4e1a\u6a21\u4eff\u5b66\u4e60\u667a\u80fd\u4f53\u548c\u5143\u63a7\u5236\u5668\u6218\u7565\u89c4\u5212\u5668\uff08SP\uff09\uff0c\u5e76\u6784\u5efa\u6db5\u76d6\u6240\u6709\u79cd\u65cf\u7ec4\u5408\u7684\u6d4b\u8bd5\u5e73\u53f0TEXTSCII - ALL\u3002", "result": "HIMA\u5728\u6218\u7565\u6e05\u6670\u5ea6\u3001\u9002\u5e94\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u4e13\u4e1a\u6a21\u4eff\u6a21\u5757\u548c\u5143\u7ea7\u7f16\u6392\u6709\u6f5c\u529b\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u901a\u7528\u7684\u4eba\u5de5\u667a\u80fd\u667a\u80fd\u4f53\u3002"}}
{"id": "2508.06024", "pdf": "https://arxiv.org/pdf/2508.06024", "abs": "https://arxiv.org/abs/2508.06024", "authors": ["Zheming Yang", "Yunqing Hu", "Sheng Sun", "Wen Ji"], "title": "EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference", "categories": ["cs.DC"], "comment": "9 pages, 8 figures", "summary": "The Mixture-of-Experts (MoE) paradigm has emerged as a promising solution to\nscale up model capacity while maintaining inference efficiency. However,\ndeploying MoE models across heterogeneous end-cloud environments poses new\nchallenges in expert scheduling, communication overhead, and resource\nheterogeneity. In this paper, we propose EC2MoE, an adaptive framework for\nscalable MoE inference via end-cloud pipeline collaboration. First, we design a\nhardware-aware lightweight group gate network that enhances expert selection\nand computational efficiency. By incorporating a hardware-aware local expert\nselection mechanism, the system adaptively filters candidate experts based on\nreal-time device profiles. A lightweight group gate module then integrates\nlocal and global gating outputs to achieve high-quality expert routing with\nminimal overhead. Second, we develop a pipeline optimization mechanism based on\nendcloud collaboration to accelerate MoE inference. This includes an\nencoder-decoder structure based on low-rank compression, which reduces\ntransmission and computation costs. And a route-aware heuristic pipeline\nscheduling algorithm that dynamically allocates inference stages across devices\naccording to workload and network topology. Extensive experiments show that\nEC2MoE can increase throughput by 2.2x to 5.1x and reduce end-to-end latency by\n53% to 67% while maintaining high accuracy compared to state-of-the-art\nmethods. It also maintains good scalability under dynamic load and network\nenvironments.", "AI": {"tldr": "\u63d0\u51faEC2MoE\u6846\u67b6\u7528\u4e8e\u7aef\u4e91\u7ba1\u9053\u534f\u4f5c\u7684\u53ef\u6269\u5c55MoE\u63a8\u7406\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u80fd\u63d0\u5347\u541e\u5410\u91cf\u3001\u964d\u4f4e\u5ef6\u8fdf\u4e14\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u5f02\u6784\u7aef\u4e91\u73af\u5883\u4e2d\u90e8\u7f72MoE\u6a21\u578b\u5728\u4e13\u5bb6\u8c03\u5ea6\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u5f02\u6784\u6027\u65b9\u9762\u7684\u65b0\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u786c\u4ef6\u611f\u77e5\u7684\u8f7b\u91cf\u7ea7\u7ec4\u95e8\u63a7\u7f51\u7edc\uff0c\u589e\u5f3a\u4e13\u5bb6\u9009\u62e9\u548c\u8ba1\u7b97\u6548\u7387\uff1b\u5f00\u53d1\u57fa\u4e8e\u7aef\u4e91\u534f\u4f5c\u7684\u7ba1\u9053\u4f18\u5316\u673a\u5236\uff0c\u5305\u62ec\u4f4e\u79e9\u538b\u7f29\u7684\u7f16\u89e3\u7801\u5668\u7ed3\u6784\u548c\u8def\u7531\u611f\u77e5\u7684\u542f\u53d1\u5f0f\u7ba1\u9053\u8c03\u5ea6\u7b97\u6cd5\u3002", "result": "\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cEC2MoE\u53ef\u5c06\u541e\u5410\u91cf\u63d0\u9ad82.2\u500d\u81f35.1\u500d\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e53%\u81f367%\uff0c\u5e76\u5728\u52a8\u6001\u8d1f\u8f7d\u548c\u7f51\u7edc\u73af\u5883\u4e0b\u4fdd\u6301\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "EC2MoE\u662f\u4e00\u79cd\u6709\u6548\u7684\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u80fd\u5728\u7aef\u4e91\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u7684MoE\u63a8\u7406\u3002"}}
{"id": "2508.05670", "pdf": "https://arxiv.org/pdf/2508.05670", "abs": "https://arxiv.org/abs/2508.05670", "authors": ["Daniele Proverbio", "Alessio Buscemi", "Alessandro Di Stefano", "The Anh Han", "German Castignani", "Pietro Li\u00f2"], "title": "Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT"], "comment": null, "summary": "Game theory has long served as a foundational tool in cybersecurity to test,\npredict, and design strategic interactions between attackers and defenders. The\nrecent advent of Large Language Models (LLMs) offers new tools and challenges\nfor the security of computer systems; In this work, we investigate whether\nclassical game-theoretic frameworks can effectively capture the behaviours of\nLLM-driven actors and bots. Using a reproducible framework for game-theoretic\nLLM agents, we investigate two canonical scenarios -- the one-shot zero-sum\ngame and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to\nexpected outcomes or exhibit deviations due to embedded biases. Our experiments\ninvolve four state-of-the-art LLMs and span five natural languages, English,\nFrench, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic\nsensitivity. For both games, we observe that the final payoffs are influenced\nby agents characteristics such as personality traits or knowledge of repeated\nrounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to\nthe choice of languages, which should warn against indiscriminate application\nof LLMs in cybersecurity applications and call for in-depth studies, as LLMs\nmay behave differently when deployed in different countries. We also employ\nquantitative metrics to evaluate the internal consistency and cross-language\nstability of LLM agents, to help guide the selection of the most stable LLMs\nand optimising models for secure applications.", "AI": {"tldr": "\u7814\u7a76\u7ecf\u5178\u535a\u5f08\u8bba\u6846\u67b6\u80fd\u5426\u6355\u6349\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u53c2\u4e0e\u8005\u548c\u673a\u5668\u4eba\u884c\u4e3a\uff0c\u53d1\u73b0\u6700\u7ec8\u6536\u76ca\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\u4e14\u6709\u8bed\u8a00\u654f\u611f\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ed9\u8ba1\u7b97\u673a\u7cfb\u7edf\u5b89\u5168\u5e26\u6765\u65b0\u5de5\u5177\u548c\u6311\u6218\uff0c\u63a2\u7a76\u7ecf\u5178\u535a\u5f08\u8bba\u6846\u67b6\u80fd\u5426\u6355\u6349\u5176\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u53ef\u590d\u73b0\u7684\u535a\u5f08\u8bba\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u6846\u67b6\uff0c\u7814\u7a76\u4e24\u79cd\u5178\u578b\u573a\u666f\uff0c\u6d89\u53ca\u56db\u79cd\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e94\u79cd\u8bed\u8a00\u3002", "result": "\u6700\u7ec8\u6536\u76ca\u53d7\u53c2\u4e0e\u8005\u7279\u5f81\u548c\u8bed\u8a00\u9009\u62e9\u5f71\u54cd\uff0c\u53d1\u73b0\u8bed\u8a00\u654f\u611f\u6027\u3002", "conclusion": "\u5e94\u8b66\u60d5\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u968f\u610f\u4f7f\u7528\uff0c\u9700\u6df1\u5165\u7814\u7a76\uff0c\u53ef\u7528\u5b9a\u91cf\u6307\u6807\u8bc4\u4f30\u7a33\u5b9a\u6027\u4ee5\u6307\u5bfc\u6a21\u578b\u9009\u62e9\u548c\u4f18\u5316\u3002"}}
{"id": "2508.06478", "pdf": "https://arxiv.org/pdf/2508.06478", "abs": "https://arxiv.org/abs/2508.06478", "authors": ["Dan Johnson", "Michael Levet", "Petr Vojt\u011bchovsk\u00fd", "Brett Widholm"], "title": "On the Parallel Complexity of Identifying Groups and Quasigroups via Decompositions", "categories": ["cs.DS", "cs.CC", "math.GR"], "comment": null, "summary": "In this paper, we investigate the computational complexity of isomorphism\ntesting for finite groups and quasigroups, given by their multiplication\ntables. We crucially take advantage of their various decompositions to show the\nfollowing:\n  - We first consider the class $\\mathcal{C}$ of groups that admit direct\nproduct decompositions, where each indecompsable factor is $O(1)$-generated,\nand either perfect or centerless. We show any group in $\\mathcal{C}$ is\nidentified by the $O(1)$-dimensional count-free Weisfeiler--Leman (WL)\nalgorithm with $O(\\log \\log n)$ rounds, and the $O(1)$-dimensional counting WL\nalgorithm with $O(1)$ rounds. Consequently, the isomorphism problem for\n$\\mathcal{C}$ is in $\\textsf{L}$. The previous upper bound for this class was\n$\\textsf{TC}^{1}$, using $O(\\log n)$ rounds of the $O(1)$-dimensional counting\nWL (Grochow and Levet, FCT 2023).\n  - We next consider more generally, the class of groups where each\nindecomposable factor is $O(1)$-generated. We exhibit an $\\textsf{AC}^{3}$\ncanonical labeling procedure for this class. Here, we accomplish this by\nshowing that in the multiplication table model, the direct product\ndecomposition can be computed in $\\textsf{AC}^{3}$, parallelizing the work of\nKayal and Nezhmetdinov (ICALP 2009).\n  - Isomorphism testing between a central quasigroup $G$ and an arbitrary\nquasigroup $H$ is in $\\textsf{NC}$. Here, we take advantage of the fact that\ncentral quasigroups admit an affine decomposition in terms of an underlying\nAbelian group. Only the trivial bound of $n^{\\log(n)+O(1)}$-time was previously\nknown for isomorphism testing of central quasigroups.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.05650", "pdf": "https://arxiv.org/pdf/2508.05650", "abs": "https://arxiv.org/abs/2508.05650", "authors": ["Jiaxuan Liang", "Shide Zhou", "Kailong Wang"], "title": "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\nLLMs, evaluating its true performance benefits in a reproducible and\ninterpretable way remains a major hurdle. Existing methods often fall short:\nthey lack domain coverage, employ coarse metrics that miss sub document\nprecision, and fail to capture computational trade offs. Most critically, they\nprovide no standardized framework for comparing RAG effectiveness across\ndifferent models and domains.\n  We introduce OmniBench RAG, a novel automated platform for multi domain\nevaluation of RAG systems. The platform quantifies performance gains across\naccuracy and efficiency dimensions, spanning nine knowledge fields including\nculture, geography, and health. We introduce two standardized metrics:\nImprovements (accuracy gains) and Transformation (efficiency differences\nbetween pre RAG and post RAG models), enabling reproducible comparisons across\nmodels and tasks. The platform features dynamic test generation, modular\nevaluation pipelines, and automated knowledge base construction. Our evaluation\nreveals striking variability in RAG effectiveness, from significant gains in\nculture to declines in mathematics, highlighting the critical importance of\nsystematic, domain aware assessment. A demonstration video is available at:\nhttps://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\nhttps://github.com/Garnett-Liang/Omnibench-RAG.", "AI": {"tldr": "\u73b0\u6709RAG\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51faOmniBench RAG\u5e73\u53f0\u8fdb\u884c\u591a\u9886\u57df\u8bc4\u4f30\uff0c\u63ed\u793aRAG\u6709\u6548\u6027\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709RAG\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u4e4f\u9886\u57df\u8986\u76d6\u3001\u6307\u6807\u7c97\u7cd9\u3001\u65e0\u6807\u51c6\u5316\u6846\u67b6\uff0c\u96be\u4ee5\u53ef\u590d\u73b0\u548c\u53ef\u89e3\u91ca\u5730\u8bc4\u4f30RAG\u6027\u80fd\u3002", "method": "\u5f15\u5165OmniBench RAG\u5e73\u53f0\uff0c\u91cf\u5316\u51c6\u786e\u6027\u548c\u6548\u7387\u7ef4\u5ea6\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5f15\u5165\u4e24\u4e2a\u6807\u51c6\u5316\u6307\u6807\uff0c\u5177\u5907\u52a8\u6001\u6d4b\u8bd5\u751f\u6210\u3001\u6a21\u5757\u5316\u8bc4\u4f30\u7ba1\u9053\u548c\u81ea\u52a8\u77e5\u8bc6\u5e93\u6784\u5efa\u7b49\u529f\u80fd\u3002", "result": "\u8bc4\u4f30\u63ed\u793aRAG\u6709\u6548\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5982\u6587\u5316\u9886\u57df\u6709\u663e\u8457\u63d0\u5347\uff0c\u6570\u5b66\u9886\u57df\u6709\u4e0b\u964d\u3002", "conclusion": "\u7cfb\u7edf\u7684\u3001\u9886\u57df\u611f\u77e5\u7684\u8bc4\u4f30\u5bf9RAG\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2508.06243", "pdf": "https://arxiv.org/pdf/2508.06243", "abs": "https://arxiv.org/abs/2508.06243", "authors": ["Ioan-Sorin Comsa", "Purav Shah", "Karthik Vaidhyanathan", "Deepak Gangadharan", "Christof Imhof", "Per Bergamin", "Aryan Kaushik", "Gabriel-Miro Muntean", "Ramona Trestian"], "title": "SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems", "categories": ["cs.LG", "cs.NE", "cs.SY", "eess.SY"], "comment": null, "summary": "The advent of 6G networks opens new possibilities for connected infotainment\nservices in vehicular environments. However, traditional Radio Resource\nManagement (RRM) techniques struggle with the increasing volume and complexity\nof data such as Channel Quality Indicators (CQI) from autonomous vehicles. To\naddress this, we propose SCAR (State-Space Compression for AI-Driven Resource\nManagement), an Edge AI-assisted framework that optimizes scheduling and\nfairness in vehicular infotainment. SCAR employs ML-based compression\ntechniques (e.g., clustering and RBF networks) to reduce CQI data size while\npreserving essential features. These compressed states are used to train\n6G-enabled Reinforcement Learning policies that maximize throughput while\nmeeting fairness objectives defined by the NGMN. Simulations show that SCAR\nincreases time in feasible scheduling regions by 14\\% and reduces unfair\nscheduling time by 15\\% compared to RL baselines without CQI compression.\nFurthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based\nclustering reduces CQI clustering distortion by 10\\%, confirming its\nefficiency. These results demonstrate SCAR's scalability and fairness benefits\nfor dynamic vehicular networks.", "AI": {"tldr": "\u63d0\u51faEdge AI\u8f85\u52a9\u6846\u67b6SCAR\u4f18\u5316\u8f66\u8054\u7f51\u4fe1\u606f\u5a31\u4e50\u8d44\u6e90\u8c03\u5ea6\u548c\u516c\u5e73\u6027\uff0c\u6a21\u62df\u663e\u793a\u5176\u6709\u826f\u597d\u6548\u679c\u3002", "motivation": "6G\u7f51\u7edc\u4e0b\u8f66\u8054\u7f51\u4fe1\u606f\u5a31\u4e50\u4e1a\u52a1\u53d1\u5c55\uff0c\u4f46\u4f20\u7edfRRM\u6280\u672f\u5904\u7406\u8f66\u8f86\u6570\u636e\u80fd\u529b\u4e0d\u8db3\u3002", "method": "\u91c7\u7528ML\u538b\u7f29\u6280\u672f\u51cf\u5c11CQI\u6570\u636e\u5927\u5c0f\uff0c\u7528\u538b\u7f29\u72b6\u6001\u8bad\u7ec36G\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u76f8\u6bd4\u65e0CQI\u538b\u7f29\u7684RL\u57fa\u7ebf\uff0cSCAR\u4f7f\u53ef\u884c\u8c03\u5ea6\u533a\u57df\u65f6\u95f4\u589e\u52a014%\uff0c\u4e0d\u516c\u5e73\u8c03\u5ea6\u65f6\u95f4\u51cf\u5c1115%\uff1bSAST\u805a\u7c7b\u51cf\u5c11CQI\u805a\u7c7b\u5931\u771f10%\u3002", "conclusion": "SCAR\u5bf9\u52a8\u6001\u8f66\u8054\u7f51\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u516c\u5e73\u6027\u4f18\u52bf\u3002"}}
{"id": "2508.05923", "pdf": "https://arxiv.org/pdf/2508.05923", "abs": "https://arxiv.org/abs/2508.05923", "authors": ["Yanusha Mehendran", "Maolin Tang", "Yi Lu"], "title": "Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm", "categories": ["cs.SE", "cs.AI"], "comment": "26 Pages, 3 figures, 6 Tables, Submitted to Empirical Software\n  Engineering and it is under review", "summary": "Software vulnerabilities continue to undermine the reliability and security\nof modern systems, particularly as software complexity outpaces the\ncapabilities of traditional detection methods. This study introduces a genetic\nalgorithm-based method for test input generation that innovatively integrates\ngenetic operators and adaptive learning to enhance software vulnerability\ndetection. A key contribution is the application of the crossover operator,\nwhich facilitates exploration by searching across a broader space of potential\ntest inputs. Complementing this, an adaptive feedback mechanism continuously\nlearns from the system's execution behavior and dynamically guides input\ngeneration toward promising areas of the input space. Rather than relying on\nfixed or randomly selected inputs, the approach evolves a population of\nstructurally valid test cases using feedback-driven selection, enabling deeper\nand more effective code traversal. This strategic integration of exploration\nand exploitation ensures that both diverse and targeted test inputs are\ndeveloped over time. Evaluation was conducted across nine open-source\nJSON-processing libraries. The proposed method achieved substantial\nimprovements in coverage compared to a benchmark evolutionary fuzzing method,\nwith average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%\nin line coverage, 114.0% in instruction coverage, and 166.0% in branch\ncoverage. These results highlight the method's capacity to detect deeper and\nmore complex vulnerabilities, offering a scalable and adaptive solution to\nsoftware security testing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u6d4b\u8bd5\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u5728\u4e5d\u4e2a\u5f00\u6e90JSON\u5904\u7406\u5e93\u8bc4\u4f30\u4e2d\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\u5728\u5404\u9879\u8986\u76d6\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u80fd\u529b\u96be\u4ee5\u8ddf\u4e0a\u8f6f\u4ef6\u590d\u6742\u5ea6\u589e\u957f\uff0c\u9700\u63d0\u5347\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u6d4b\u8bd5\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u5b50\u548c\u81ea\u9002\u5e94\u5b66\u4e60\uff0c\u5e94\u7528\u4ea4\u53c9\u7b97\u5b50\u548c\u81ea\u9002\u5e94\u53cd\u9988\u673a\u5236\uff0c\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u9009\u62e9\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5728\u4e5d\u4e2a\u5f00\u6e90JSON\u5904\u7406\u5e93\u8bc4\u4f30\u4e2d\uff0c\u76f8\u6bd4\u57fa\u51c6\u8fdb\u5316\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7c7b\u8986\u76d6\u7387\u5e73\u5747\u63d0\u534739.8%\uff0c\u65b9\u6cd5\u8986\u76d6\u7387\u63d0\u534762.4%\uff0c\u884c\u8986\u76d6\u7387\u63d0\u5347105.0%\uff0c\u6307\u4ee4\u8986\u76d6\u7387\u63d0\u5347114.0%\uff0c\u5206\u652f\u8986\u76d6\u7387\u63d0\u5347166.0%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u68c0\u6d4b\u66f4\u6df1\u5c42\u548c\u66f4\u590d\u6742\u7684\u6f0f\u6d1e\uff0c\u4e3a\u8f6f\u4ef6\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u81ea\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05831", "pdf": "https://arxiv.org/pdf/2508.05831", "abs": "https://arxiv.org/abs/2508.05831", "authors": ["Alexander DeLise", "Kyle Loh", "Krish Patel", "Meredith Teague", "Andrea Arnold", "Matthias Chung"], "title": "Optimal Linear Baseline Models for Scientific Machine Learning", "categories": ["cs.LG", "cs.NA", "math.NA", "15A29 Inverse problems in linear algebra 65F22, 68T07, 65F05, 62C12", "G.1.3; F.2.1; I.2.6"], "comment": "40 pages, 10 Figures, 9 Tables", "summary": "Across scientific domains, a fundamental challenge is to characterize and\ncompute the mappings from underlying physical processes to observed signals and\nmeasurements. While nonlinear neural networks have achieved considerable\nsuccess, they remain theoretically opaque, which hinders adoption in contexts\nwhere interpretability is paramount. In contrast, linear neural networks serve\nas a simple yet effective foundation for gaining insight into these complex\nrelationships. In this work, we develop a unified theoretical framework for\nanalyzing linear encoder-decoder architectures through the lens of Bayes risk\nminimization for solving data-driven scientific machine learning problems. We\nderive closed-form, rank-constrained linear and affine linear optimal mappings\nfor forward modeling and inverse recovery tasks. Our results generalize\nexisting formulations by accommodating rank-deficiencies in data, forward\noperators, and measurement processes. We validate our theoretical results by\nconducting numerical experiments on datasets from simple biomedical imaging,\nfinancial factor analysis, and simulations involving nonlinear fluid dynamics\nvia the shallow water equations. This work provides a robust baseline for\nunderstanding and benchmarking learned neural network models for scientific\nmachine learning problems.", "AI": {"tldr": "\u672c\u6587\u4e3a\u7ebf\u6027\u7f16\u7801\u5668 - \u89e3\u7801\u5668\u67b6\u6784\u5f00\u53d1\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u4ee5\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u7684\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u95ee\u9898\uff0c\u63a8\u5bfc\u6700\u4f18\u6620\u5c04\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u7ed3\u679c\u5e76\u63d0\u4f9b\u57fa\u51c6\u3002", "motivation": "\u975e\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\u7406\u8bba\u4e0d\u900f\u660e\uff0c\u5728\u9700\u8981\u53ef\u89e3\u91ca\u6027\u7684\u573a\u666f\u5e94\u7528\u53d7\u9650\uff0c\u800c\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\u53ef\u7528\u4e8e\u6d1e\u5bdf\u590d\u6742\u5173\u7cfb\u3002", "method": "\u4ece\u8d1d\u53f6\u65af\u98ce\u9669\u6700\u5c0f\u5316\u89d2\u5ea6\u5206\u6790\u7ebf\u6027\u7f16\u7801\u5668 - \u89e3\u7801\u5668\u67b6\u6784\uff0c\u63a8\u5bfc\u5c01\u95ed\u5f62\u5f0f\u3001\u79e9\u7ea6\u675f\u7684\u7ebf\u6027\u548c\u4eff\u5c04\u7ebf\u6027\u6700\u4f18\u6620\u5c04\u3002", "result": "\u7ed3\u679c\u80fd\u9002\u5e94\u6570\u636e\u3001\u524d\u5411\u7b97\u5b50\u548c\u6d4b\u91cf\u8fc7\u7a0b\u4e2d\u7684\u79e9\u4e8f\uff0c\u901a\u8fc7\u7b80\u5355\u751f\u7269\u533b\u5b66\u6210\u50cf\u3001\u91d1\u878d\u56e0\u5b50\u5206\u6790\u548c\u975e\u7ebf\u6027\u6d41\u4f53\u52a8\u529b\u5b66\u6a21\u62df\u7b49\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u4e3a\u7406\u89e3\u548c\u57fa\u51c6\u6d4b\u8bd5\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u95ee\u9898\u7684\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7ebf\u3002"}}
{"id": "2508.06337", "pdf": "https://arxiv.org/pdf/2508.06337", "abs": "https://arxiv.org/abs/2508.06337", "authors": ["Benedikt Fr\u00f6hlich", "Alison Durst", "Merle Behr"], "title": "Decorrelated feature importance from local sample weighting", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Feature importance (FI) statistics provide a prominent and valuable method of\ninsight into the decision process of machine learning (ML) models, but their\neffectiveness has well-known limitations when correlation is present among the\nfeatures in the training data. In this case, the FI often tends to be\ndistributed among all features which are in correlation with the\nresponse-generating signal features. Even worse, if multiple signal features\nare in strong correlation with a noise feature, while being only modestly\ncorrelated with one another, this can result in a noise feature having a\ndistinctly larger FI score than any signal feature. Here we propose local\nsample weighting (losaw) which can flexibly be integrated into many ML\nalgorithms to improve FI scores in the presence of feature correlation in the\ntraining data. Our approach is motivated from inverse probability weighting in\ncausal inference and locally, within the ML model, uses a sample weighting\nscheme to decorrelate a target feature from the remaining features. This\nreduces model bias locally, whenever the effect of a potential signal feature\nis evaluated and compared to others. Moreover, losaw comes with a natural\ntuning parameter, the minimum effective sample size of the weighted population,\nwhich corresponds to an interpretation-prediction-tradeoff, analog to a\nbias-variance-tradeoff as for classical ML tuning parameters. We demonstrate\nhow losaw can be integrated within decision tree-based ML methods and within\nmini-batch training of neural networks. We investigate losaw for random forest\nand convolutional neural networks in a simulation study on settings showing\ndiverse correlation patterns. We found that losaw improves FI consistently.\nMoreover, it often improves prediction accuracy for out-of-distribution, while\nmaintaining a similar accuracy for in-distribution test data.", "AI": {"tldr": "\u63d0\u51fa\u5c40\u90e8\u6837\u672c\u52a0\u6743\uff08losaw\uff09\u65b9\u6cd5\u6539\u5584\u7279\u5f81\u76f8\u5173\u65f6\u7684\u7279\u5f81\u91cd\u8981\u6027\uff08FI\uff09\u5206\u6570\uff0c\u5728\u6a21\u62df\u7814\u7a76\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7279\u5f81\u91cd\u8981\u6027\u7edf\u8ba1\u65b9\u6cd5\u5728\u7279\u5f81\u76f8\u5173\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982FI\u5206\u5e03\u5206\u6563\u3001\u566a\u58f0\u7279\u5f81FI\u5206\u6570\u53ef\u80fd\u9ad8\u4e8e\u4fe1\u53f7\u7279\u5f81\u3002", "method": "\u501f\u9274\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u9006\u6982\u7387\u52a0\u6743\uff0c\u5728\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u4f7f\u7528\u6837\u672c\u52a0\u6743\u65b9\u6848\u5bf9\u76ee\u6807\u7279\u5f81\u4e0e\u5176\u4f59\u7279\u5f81\u8fdb\u884c\u53bb\u76f8\u5173\uff0c\u6709\u6700\u5c0f\u6709\u6548\u6837\u672c\u91cf\u8fd9\u4e00\u8c03\u53c2\u3002", "result": "losaw\u80fd\u6301\u7eed\u6539\u5584FI\uff0c\u5e38\u63d0\u9ad8\u5206\u5e03\u5916\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5206\u5e03\u5185\u6d4b\u8bd5\u6570\u636e\u51c6\u786e\u6027\u76f8\u8fd1\u3002", "conclusion": "losaw\u53ef\u7075\u6d3b\u96c6\u6210\u5230\u591a\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e2d\uff0c\u6709\u6548\u6539\u5584\u7279\u5f81\u76f8\u5173\u65f6\u7684FI\u5206\u6570\u3002"}}
{"id": "2508.06060", "pdf": "https://arxiv.org/pdf/2508.06060", "abs": "https://arxiv.org/abs/2508.06060", "authors": ["Sankarshan Damle", "Boi Faltings"], "title": "LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences", "categories": ["cs.AI"], "comment": "Published in the Proceedings of the 28th European Conference on\n  Artificial Intelligence (ECAI 2025)", "summary": "Large Language Models (LLMs) are increasingly expected to handle complex\ndecision-making tasks, yet their ability to perform structured resource\nallocation remains underexplored. Evaluating their reasoning is also difficult\ndue to data contamination and the static nature of existing benchmarks. We\npresent a dual-purpose framework leveraging Participatory Budgeting (PB) both\nas (i) a practical setting for LLM-based resource allocation and (ii) an\nadaptive benchmark for evaluating their reasoning capabilities. We task LLMs\nwith selecting project subsets under feasibility (e.g., budget) constraints via\nthree prompting strategies: greedy selection, direct optimization, and a\nhill-climbing-inspired refinement. We benchmark LLMs' allocations against a\nutility-maximizing oracle. Interestingly, we also test whether LLMs can infer\nstructured preferences from natural-language voter input or metadata, without\nexplicit votes. By comparing allocations based on inferred preferences to those\nfrom ground-truth votes, we evaluate LLMs' ability to extract preferences from\nopen-ended input. Our results underscore the role of prompt design and show\nthat LLMs hold promise for mechanism design with unstructured inputs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u53c2\u4e0e\u5f0f\u9884\u7b97\uff08PB\uff09\u4f5c\u4e3a\u6846\u67b6\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8d44\u6e90\u5206\u914d\u80fd\u529b\u548c\u63a8\u7406\u80fd\u529b\uff0c\u6d4b\u8bd5\u4e0d\u540c\u63d0\u793a\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793a\u63d0\u793a\u8bbe\u8ba1\u91cd\u8981\u4e14LLMs\u5728\u975e\u7ed3\u6784\u5316\u8f93\u5165\u673a\u5236\u8bbe\u8ba1\u6709\u6f5c\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u590d\u6742\u51b3\u7b56\u4efb\u52a1\u65f6\uff0c\u7ed3\u6784\u5316\u8d44\u6e90\u5206\u914d\u80fd\u529b\u672a\u5145\u5206\u7814\u7a76\uff0c\u4e14\u73b0\u6709\u57fa\u51c6\u8bc4\u4f30\u63a8\u7406\u80fd\u529b\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u9759\u6001\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8ePB\u7684\u53cc\u7528\u9014\u6846\u67b6\uff0c\u4f7f\u7528\u8d2a\u5a6a\u9009\u62e9\u3001\u76f4\u63a5\u4f18\u5316\u548c\u722c\u5c71\u542f\u53d1\u5f0f\u7ec6\u5316\u4e09\u79cd\u63d0\u793a\u7b56\u7565\u8ba9LLMs\u8fdb\u884c\u9879\u76ee\u5b50\u96c6\u9009\u62e9\uff0c\u4e0e\u6548\u7528\u6700\u5927\u5316\u7684oracle\u5bf9\u6bd4\uff0c\u8fd8\u6d4b\u8bd5LLMs\u4ece\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u4e2d\u63a8\u65ad\u504f\u597d\u7684\u80fd\u529b\u3002", "result": "\u7a81\u51fa\u4e86\u63d0\u793a\u8bbe\u8ba1\u7684\u4f5c\u7528\uff0c\u8868\u660eLLMs\u5728\u975e\u7ed3\u6784\u5316\u8f93\u5165\u7684\u673a\u5236\u8bbe\u8ba1\u65b9\u9762\u6709\u524d\u666f\u3002", "conclusion": "\u63d0\u793a\u8bbe\u8ba1\u5bf9LLMs\u8d44\u6e90\u5206\u914d\u548c\u63a8\u7406\u8bc4\u4f30\u5f88\u5173\u952e\uff0cLLMs\u5728\u5904\u7406\u975e\u7ed3\u6784\u5316\u8f93\u5165\u7684\u673a\u5236\u8bbe\u8ba1\u4e2d\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.06297", "pdf": "https://arxiv.org/pdf/2508.06297", "abs": "https://arxiv.org/abs/2508.06297", "authors": ["Yanyu Liu", "Jingying Fu", "Sixiang Liu", "Yitian Zou", "You Fu", "Jiehan Zhou", "Shouhua Zhang"], "title": "KV Cache Compression for Inference Efficiency in LLMs: A Review", "categories": ["cs.DC"], "comment": "12 pages", "summary": "Withtherapid advancement of large language models (LLMs), the context length\nfor inference has been continuously increasing, leading to an exponential\ngrowth in the demand for Key-Value (KV) caching. This has resulted in a\nsignificant memory bottleneck, limiting the inference efficiency and\nscalability of the models. Therefore, optimizing the KV cache during inference\nis crucial for enhancing performance and efficiency. This review systematically\nexamines current KV cache optimization techniques, including compression\nstrategies such as selective token strategies, quantization, and attention\ncompression. We evaluate the effectiveness, trade-offs, and application\nscenarios of these methods, providing a comprehensive analysis of their impact\non memory usage and inference speed. We focus on identifying the limitations\nand challenges of existing methods, such as compatibility issues with different\nmodels and tasks. Additionally, this review highlights future research\ndirections, including hybrid optimization techniques, adaptive dynamic\nstrategies, and software-hardware co-design. These approaches aim to improve\ninference efficiency and promote the practical application of large language\nmodels.", "AI": {"tldr": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\uff0cKV\u7f13\u5b58\u9700\u6c42\u589e\u957f\u81f4\u5185\u5b58\u74f6\u9888\uff0c\u6587\u7ae0\u7efc\u8ff0KV\u7f13\u5b58\u4f18\u5316\u6280\u672f\uff0c\u8bc4\u4f30\u6548\u679c\u5e76\u6307\u51fa\u5c40\u9650\uff0c\u7ed9\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6KV\u7f13\u5b58\u9700\u6c42\u589e\u957f\u9020\u6210\u5185\u5b58\u74f6\u9888\uff0c\u9650\u5236\u63a8\u7406\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9700\u4f18\u5316KV\u7f13\u5b58\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u5f53\u524dKV\u7f13\u5b58\u4f18\u5316\u6280\u672f\uff0c\u8bc4\u4f30\u5176\u6709\u6548\u6027\u3001\u6743\u8861\u548c\u5e94\u7528\u573a\u666f\u3002", "result": "\u5bf9\u73b0\u6709\u65b9\u6cd5\u5728\u5185\u5b58\u4f7f\u7528\u548c\u63a8\u7406\u901f\u5ea6\u65b9\u9762\u7684\u5f71\u54cd\u8fdb\u884c\u5168\u9762\u5206\u6790\uff0c\u627e\u51fa\u5c40\u9650\u6027\u548c\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u6df7\u5408\u4f18\u5316\u6280\u672f\u3001\u81ea\u9002\u5e94\u52a8\u6001\u7b56\u7565\u548c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u7b49\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u5e76\u63a8\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.06443", "pdf": "https://arxiv.org/pdf/2508.06443", "abs": "https://arxiv.org/abs/2508.06443", "authors": ["Debabrota Basu", "Udvas Das"], "title": "The Fair Game: Auditing & Debiasing AI Algorithms Over Time", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.GT"], "comment": null, "summary": "An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify\ndifferent types of bias (also known as unfairness) exhibited in the predictions\nof ML algorithms, and to design new algorithms to mitigate them. Often, the\ndefinitions of bias used in the literature are observational, i.e. they use the\ninput and output of a pre-trained algorithm to quantify a bias under concern.\nIn reality,these definitions are often conflicting in nature and can only be\ndeployed if either the ground truth is known or only in retrospect after\ndeploying the algorithm. Thus,there is a gap between what we want Fair ML to\nachieve and what it does in a dynamic social environment. Hence, we propose an\nalternative dynamic mechanism,\"Fair Game\",to assure fairness in the predictions\nof an ML algorithm and to adapt its predictions as the society interacts with\nthe algorithm over time. \"Fair Game\" puts together an Auditor and a Debiasing\nalgorithm in a loop around an ML algorithm. The \"Fair Game\" puts these two\ncomponents in a loop by leveraging Reinforcement Learning (RL). RL algorithms\ninteract with an environment to take decisions, which yields new observations\n(also known as data/feedback) from the environment and in turn, adapts future\ndecisions. RL is already used in algorithms with pre-fixed long-term fairness\ngoals. \"Fair Game\" provides a unique framework where the fairness goals can be\nadapted over time by only modifying the auditor and the different biases it\nquantifies. Thus,\"Fair Game\" aims to simulate the evolution of ethical and\nlegal frameworks in the society by creating an auditor which sends feedback to\na debiasing algorithm deployed around an ML system. This allows us to develop a\nflexible and adaptive-over-time framework to build Fair ML systems pre- and\npost-deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201cFair Game\u201d\u673a\u5236\u89e3\u51b3\u516c\u5e73\u673a\u5668\u5b66\u4e60\u5728\u52a8\u6001\u793e\u4f1a\u73af\u5883\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u53ef\u7075\u6d3b\u9002\u5e94\u4e0d\u540c\u9636\u6bb5\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u673a\u5668\u5b66\u4e60\u4e2d\u504f\u5dee\u5b9a\u4e49\u5b58\u5728\u51b2\u7a81\uff0c\u4e14\u9700\u5df2\u77e5\u5730\u9762\u771f\u503c\u6216\u7b97\u6cd5\u90e8\u7f72\u540e\u624d\u80fd\u5e94\u7528\uff0c\u4e0e\u52a8\u6001\u793e\u4f1a\u73af\u5883\u9700\u6c42\u5b58\u5728\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u201cFair Game\u201d\u673a\u5236\uff0c\u5c06\u5ba1\u8ba1\u5668\u548c\u53bb\u504f\u7b97\u6cd5\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7f6e\u4e8e\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5468\u56f4\u5f62\u6210\u5faa\u73af\u3002", "result": "\u201cFair Game\u201d\u80fd\u901a\u8fc7\u4fee\u6539\u5ba1\u8ba1\u5668\u548c\u91cf\u5316\u7684\u504f\u5dee\u6765\u9002\u5e94\u516c\u5e73\u6027\u76ee\u6807\u7684\u53d8\u5316\u3002", "conclusion": "\u201cFair Game\u201d\u53ef\u6784\u5efa\u7075\u6d3b\u4e14\u80fd\u968f\u65f6\u95f4\u81ea\u9002\u5e94\u7684\u516c\u5e73\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\uff0c\u9002\u7528\u4e8e\u90e8\u7f72\u524d\u540e\u3002"}}
{"id": "2508.06486", "pdf": "https://arxiv.org/pdf/2508.06486", "abs": "https://arxiv.org/abs/2508.06486", "authors": ["Tyler Chen", "Ethan N. Epperly", "Raphael A. Meyer", "Christopher Musco", "Akash Rao"], "title": "Does block size matter in randomized block Krylov low-rank approximation?", "categories": ["cs.DS", "cs.NA", "math.NA", "65F55 65F15", "G.1.3; F.2.1"], "comment": null, "summary": "We study the problem of computing a rank-$k$ approximation of a matrix using\nrandomized block Krylov iteration. Prior work has shown that, for block size $b\n= 1$ or $b = k$, a $(1 + \\varepsilon)$-factor approximation to the best\nrank-$k$ approximation can be obtained after $\\tilde O(k/\\sqrt{\\varepsilon})$\nmatrix-vector products with the target matrix. On the other hand, when $b$ is\nbetween $1$ and $k$, the best known bound on the number of matrix-vector\nproducts scales with $b(k-b)$, which could be as large as $O(k^2)$.\nNevertheless, in practice, the performance of block Krylov methods is often\noptimized by choosing a block size $1 \\ll b \\ll k$. We resolve this\ntheory-practice gap by proving that randomized block Krylov iteration produces\na $(1 + \\varepsilon)$-factor approximate rank-$k$ approximation using $\\tilde\nO(k/\\sqrt{\\varepsilon})$ matrix-vector products for any block size $1\\le b\\le\nk$. Our analysis relies on new bounds for the minimum singular value of a\nrandom block Krylov matrix, which may be of independent interest. Similar\nbounds are central to recent breakthroughs on faster algorithms for sparse\nlinear systems [Peng & Vempala, SODA 2021; Nie, STOC 2022].", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7528\u968f\u673a\u5757Krylov\u8fed\u4ee3\u8ba1\u7b97\u77e9\u9635\u7684\u79e9k\u8fd1\u4f3c\u95ee\u9898\uff0c\u89e3\u51b3\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\uff0c\u8bc1\u660e\u4efb\u610f\u5757\u5927\u5c0f\u4e0b\u53ea\u9700O(k/\u221a\u03b5)\u6b21\u77e9\u9635\u5411\u91cf\u79ef\u3002", "motivation": "\u6b64\u524d\u7814\u7a76\u5728\u5757\u5927\u5c0f\u4ecb\u4e8e1\u548ck\u4e4b\u95f4\u65f6\uff0c\u77e9\u9635\u5411\u91cf\u79ef\u6b21\u6570\u754c\u53ef\u80fd\u8fbeO(k\u00b2)\uff0c\u800c\u5b9e\u8df5\u4e2d\u5e38\u90091 \u226a b \u226a k\u4f18\u5316\u6027\u80fd\uff0c\u5b58\u5728\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\u3002", "method": "\u8bc1\u660e\u968f\u673a\u5757Krylov\u8fed\u4ee3\u7684\u6027\u8d28\uff0c\u4f9d\u8d56\u968f\u673a\u5757Krylov\u77e9\u9635\u6700\u5c0f\u5947\u5f02\u503c\u7684\u65b0\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u610f\u5757\u5927\u5c0f1\u2264b\u2264k\uff0c\u968f\u673a\u5757Krylov\u8fed\u4ee3\u80fd\u7528O(k/\u221a\u03b5)\u6b21\u77e9\u9635\u5411\u91cf\u79ef\u4ea7\u751f(1 + \u03b5)\u56e0\u5b50\u7684\u8fd1\u4f3c\u79e9k\u8fd1\u4f3c\u3002", "conclusion": "\u89e3\u51b3\u4e86\u968f\u673a\u5757Krylov\u8fed\u4ee3\u8ba1\u7b97\u77e9\u9635\u79e9k\u8fd1\u4f3c\u95ee\u9898\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\uff0c\u65b0\u7684\u754c\u53ef\u80fd\u6709\u72ec\u7acb\u4ef7\u503c\u3002"}}
{"id": "2508.05652", "pdf": "https://arxiv.org/pdf/2508.05652", "abs": "https://arxiv.org/abs/2508.05652", "authors": ["Julia Ann Mathew", "Suining He"], "title": "Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation", "categories": ["cs.IR", "cs.AI"], "comment": "4 pages, UrbComp 2025", "summary": "The increasing popularity of outdoor recreational activities (such as hiking\nand biking) has boosted the demand for a conversational AI system to provide\ninformative and personalized suggestion on outdoor trails. Challenges arise in\nresponse to (1) how to provide accurate outdoor trail information via\nconversational AI; and (2) how to enable usable and efficient recommendation\nservices. To address above, this paper discusses the preliminary and practical\nlessons learned from developing Judy, an outdoor trail recommendation chatbot\nbased on the large language model (LLM) with retrieval augmented generation\n(RAG). To gain concrete system insights, we have performed case studies with\nthe outdoor trails in Connecticut (CT), US. We have conducted web-based data\ncollection, outdoor trail data management, and LLM model performance studies on\nthe RAG-based recommendation. Our experimental results have demonstrated the\naccuracy, effectiveness, and usability of Judy in recommending outdoor trails\nbased on the LLM with RAG.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u5f00\u53d1\u7684\u6237\u5916\u6b65\u9053\u63a8\u8350\u804a\u5929\u673a\u5668\u4ebaJudy\uff0c\u901a\u8fc7\u7f8e\u56fd\u5eb7\u6d85\u72c4\u683c\u5dde\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u5176\u51c6\u786e\u6027\u3001\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "\u6237\u5916\u4f11\u95f2\u6d3b\u52a8\u6d41\u884c\uff0c\u9700\u5bf9\u8bdd\u5f0fAI\u7cfb\u7edf\u63d0\u4f9b\u6237\u5916\u6b65\u9053\u4fe1\u606f\u548c\u4e2a\u6027\u5316\u5efa\u8bae\uff0c\u4f46\u9762\u4e34\u51c6\u786e\u63d0\u4f9b\u4fe1\u606f\u548c\u5b9e\u73b0\u9ad8\u6548\u63a8\u8350\u670d\u52a1\u7684\u6311\u6218\u3002", "method": "\u4ee5\u7f8e\u56fd\u5eb7\u6d85\u72c4\u683c\u5dde\u6237\u5916\u6b65\u9053\u4e3a\u6848\u4f8b\uff0c\u8fdb\u884c\u57fa\u4e8e\u7f51\u7edc\u7684\u6570\u636e\u6536\u96c6\u3001\u6237\u5916\u6b65\u9053\u6570\u636e\u7ba1\u7406\u548c\u57fa\u4e8eRAG\u7684\u63a8\u8350\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0eRAG\u7684Judy\u5728\u63a8\u8350\u6237\u5916\u6b65\u9053\u65b9\u9762\u5177\u6709\u51c6\u786e\u6027\u3001\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u3002", "conclusion": "\u5f00\u53d1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0eRAG\u7684\u6237\u5916\u6b65\u9053\u63a8\u8350\u804a\u5929\u673a\u5668\u4ebaJudy\u662f\u53ef\u884c\u4e14\u6709\u6548\u7684\u3002"}}
{"id": "2508.06347", "pdf": "https://arxiv.org/pdf/2508.06347", "abs": "https://arxiv.org/abs/2508.06347", "authors": ["Ruiyu Zhang", "Ce Zhao", "Xin Zhao", "Lin Nie", "Wai-Fung Lam"], "title": "Structural Equation-VAE: Disentangled Latent Representations for Tabular Data", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "10 pages, 2 figures", "summary": "Learning interpretable latent representations from tabular data remains a\nchallenge in deep generative modeling. We introduce SE-VAE (Structural\nEquation-Variational Autoencoder), a novel architecture that embeds measurement\nstructure directly into the design of a variational autoencoder. Inspired by\nstructural equation modeling, SE-VAE aligns latent subspaces with known\nindicator groupings and introduces a global nuisance latent to isolate\nconstruct-specific confounding variation. This modular architecture enables\ndisentanglement through design rather than through statistical regularizers\nalone. We evaluate SE-VAE on a suite of simulated tabular datasets and\nbenchmark its performance against a series of leading baselines using standard\ndisentanglement metrics. SE-VAE consistently outperforms alternatives in factor\nrecovery, interpretability, and robustness to nuisance variation. Ablation\nresults reveal that architectural structure, rather than regularization\nstrength, is the key driver of performance. SE-VAE offers a principled\nframework for white-box generative modeling in scientific and social domains\nwhere latent constructs are theory-driven and measurement validity is\nessential.", "AI": {"tldr": "\u4ecb\u7ecdSE - VAE\u67b6\u6784\u7528\u4e8e\u4ece\u8868\u683c\u6570\u636e\u5b66\u4e60\u53ef\u89e3\u91ca\u6f5c\u5728\u8868\u5f81\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u67b6\u6784\u7ed3\u6784\u662f\u6027\u80fd\u5173\u952e\u3002", "motivation": "\u4ece\u8868\u683c\u6570\u636e\u5b66\u4e60\u53ef\u89e3\u91ca\u6f5c\u5728\u8868\u5f81\u5728\u6df1\u5ea6\u751f\u6210\u5efa\u6a21\u4e2d\u4ecd\u662f\u6311\u6218\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u5f15\u5165SE - VAE\u67b6\u6784\uff0c\u5c06\u6d4b\u91cf\u7ed3\u6784\u5d4c\u5165\u53d8\u5206\u81ea\u7f16\u7801\u5668\u8bbe\u8ba1\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5b9e\u73b0\u89e3\u7ea0\u7f20\u3002\u5728\u6a21\u62df\u8868\u683c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u57fa\u7ebf\u6a21\u578b\u5bf9\u6bd4\u3002", "result": "SE - VAE\u5728\u56e0\u5b50\u6062\u590d\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u5e72\u6270\u53d8\u5316\u7684\u9c81\u68d2\u6027\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u67b6\u6784\u7ed3\u6784\u662f\u6027\u80fd\u5173\u952e\u3002", "conclusion": "SE - VAE\u4e3a\u79d1\u5b66\u548c\u793e\u4f1a\u9886\u57df\u7684\u767d\u76d2\u751f\u6210\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u7684\u6846\u67b6\u3002"}}
{"id": "2508.05949", "pdf": "https://arxiv.org/pdf/2508.05949", "abs": "https://arxiv.org/abs/2508.05949", "authors": ["Jialin Yang", "Zainab Saad", "Jiajun Wu", "Xiaoguang Niu", "Henry Leung", "Steve Drew"], "title": "A Survey on Task Scheduling in Carbon-Aware Container Orchestration", "categories": ["cs.SE"], "comment": "Submitted to ACM Computing Surveys", "summary": "The soaring energy demands of large-scale software ecosystems and cloud data\ncenters, accelerated by the intensive training and deployment of large language\nmodels, have driven energy consumption and carbon footprint to unprecedented\nlevels. In response, both industry and academia are increasing efforts to\nreduce the carbon emissions associated with cloud computing through more\nefficient task scheduling and infrastructure orchestration. In this work, we\npresent a systematic review of various Kubernetes scheduling strategies,\ncategorizing them into hardware-centric and software-centric, annotating each\nwith its sustainability objectives, and grouping them according to the\nalgorithms they use. We propose a comprehensive taxonomy for cloud task\nscheduling studies, with a particular focus on the environmental sustainability\naspect. We analyze emerging research trends and open challenges, and our\nfindings provide critical insight into the design of sustainable scheduling\nsolutions for next-generation cloud computing systems.", "AI": {"tldr": "\u56e0\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\uff0c\u4e91\u8ba1\u7b97\u80fd\u8017\u4e0e\u78b3\u8db3\u8ff9\u6fc0\u589e\uff0c\u672c\u6587\u7cfb\u7edf\u56de\u987eKubernetes\u8c03\u5ea6\u7b56\u7565\uff0c\u63d0\u51fa\u5206\u7c7b\u6cd5\u5e76\u5206\u6790\u8d8b\u52bf\u4e0e\u6311\u6218\uff0c\u4e3a\u53ef\u6301\u7eed\u8c03\u5ea6\u65b9\u6848\u8bbe\u8ba1\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u5927\u89c4\u6a21\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u548c\u4e91\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u53ca\u78b3\u8db3\u8ff9\u8fbe\u524d\u6240\u672a\u6709\u7684\u6c34\u5e73\uff0c\u9700\u8981\u901a\u8fc7\u9ad8\u6548\u4efb\u52a1\u8c03\u5ea6\u548c\u57fa\u7840\u8bbe\u65bd\u7f16\u6392\u51cf\u5c11\u4e91\u8ba1\u7b97\u78b3\u6392\u653e\u3002", "method": "\u5bf9\u5404\u79cdKubernetes\u8c03\u5ea6\u7b56\u7565\u8fdb\u884c\u7cfb\u7edf\u56de\u987e\uff0c\u5206\u4e3a\u786c\u4ef6\u548c\u8f6f\u4ef6\u4e2d\u5fc3\u4e24\u7c7b\uff0c\u6807\u6ce8\u53ef\u6301\u7eed\u6027\u76ee\u6807\u5e76\u6309\u7b97\u6cd5\u5206\u7ec4\uff0c\u63d0\u51fa\u4e91\u4efb\u52a1\u8c03\u5ea6\u7814\u7a76\u5206\u7c7b\u6cd5\u3002", "result": "\u5206\u6790\u4e86\u65b0\u5174\u7814\u7a76\u8d8b\u52bf\u548c\u5f00\u653e\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4e0b\u4e00\u4ee3\u4e91\u8ba1\u7b97\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u8bbe\u8ba1\u63d0\u4f9b\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2508.05836", "pdf": "https://arxiv.org/pdf/2508.05836", "abs": "https://arxiv.org/abs/2508.05836", "authors": ["Rituparna Datta", "Nibir Chandra Mandal"], "title": "An Effective Approach for Node Classification in Textual Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Textual Attribute Graphs (TAGs) are critical for modeling complex networks\nlike citation networks, but effective node classification remains challenging\ndue to difficulties in integrating rich semantics from text with structural\ngraph information. Existing methods often struggle with capturing nuanced\ndomain-specific terminology, modeling long-range dependencies, adapting to\ntemporal evolution, and scaling to massive datasets. To address these issues,\nwe propose a novel framework that integrates TAPE (Text-Attributed Graph\nRepresentation Enhancement) with Graphormer. Our approach leverages a large\nlanguage model (LLM), specifically ChatGPT, within the TAPE framework to\ngenerate semantically rich explanations from paper content, which are then\nfused into enhanced node representations. These embeddings are combined with\nstructural features using a novel integration layer with learned attention\nweights. Graphormer's path-aware position encoding and multi-head attention\nmechanisms are employed to effectively capture long-range dependencies across\nthe citation network. We demonstrate the efficacy of our framework on the\nchallenging ogbn-arxiv dataset, achieving state-of-the-art performance with a\nclassification accuracy of 0.772, significantly surpassing the best GCN\nbaseline of 0.713. Our method also yields strong results in precision (0.671),\nrecall (0.577), and F1-score (0.610). We validate our approach through\ncomprehensive ablation studies that quantify the contribution of each\ncomponent, demonstrating the synergy between semantic and structural\ninformation. Our framework provides a scalable and robust solution for node\nclassification in dynamic TAGs, offering a promising direction for future\nresearch in knowledge systems and scientific discovery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408TAPE\u4e0eGraphormer\u7684\u6846\u67b6\u5904\u7406\u6587\u672c\u5c5e\u6027\u56fe\u7684\u8282\u70b9\u5206\u7c7b\u95ee\u9898\uff0c\u5728ogbn - arxiv\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6587\u672c\u5c5e\u6027\u56fe\u8282\u70b9\u5206\u7c7b\u4e2d\u96be\u4ee5\u6574\u5408\u6587\u672c\u8bed\u4e49\u4e0e\u56fe\u7ed3\u6784\u4fe1\u606f\uff0c\u5b58\u5728\u6355\u6349\u7279\u5b9a\u672f\u8bed\u3001\u5efa\u6a21\u957f\u8ddd\u79bb\u4f9d\u8d56\u7b49\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u7ed3\u5408TAPE\u4e0eGraphormer\u7684\u6846\u67b6\uff0c\u7528LLM\u751f\u6210\u8bed\u4e49\u89e3\u91ca\u878d\u5165\u8282\u70b9\u8868\u793a\uff0c\u7528\u65b0\u7684\u96c6\u6210\u5c42\u7ed3\u5408\u7ed3\u6784\u7279\u5f81\uff0c\u5229\u7528Graphormer\u673a\u5236\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u3002", "result": "\u5728ogbn - arxiv\u6570\u636e\u96c6\u4e0a\u5206\u7c7b\u51c6\u786e\u7387\u8fbe0.772\uff0c\u8d85\u8d8aGCN\u57fa\u7ebf\uff0c\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u5404\u7ec4\u4ef6\u8d21\u732e\u3002", "conclusion": "\u6846\u67b6\u4e3a\u52a8\u6001\u6587\u672c\u5c5e\u6027\u56fe\u8282\u70b9\u5206\u7c7b\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2508.06377", "pdf": "https://arxiv.org/pdf/2508.06377", "abs": "https://arxiv.org/abs/2508.06377", "authors": ["Thomas Michel", "Debabrota Basu", "Emilie Kaufmann"], "title": "DP-SPRT: Differentially Private Sequential Probability Ratio Tests", "categories": ["stat.ML", "cs.CR", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We revisit Wald's celebrated Sequential Probability Ratio Test for sequential\ntests of two simple hypotheses, under privacy constraints. We propose DP-SPRT,\na wrapper that can be calibrated to achieve desired error probabilities and\nprivacy constraints, addressing a significant gap in previous work. DP-SPRT\nrelies on a private mechanism that processes a sequence of queries and stops\nafter privately determining when the query results fall outside a predefined\ninterval. This OutsideInterval mechanism improves upon naive composition of\nexisting techniques like AboveThreshold, potentially benefiting other\nsequential algorithms. We prove generic upper bounds on the error and sample\ncomplexity of DP-SPRT that can accommodate various noise distributions based on\nthe practitioner's privacy needs. We exemplify them in two settings: Laplace\nnoise (pure Differential Privacy) and Gaussian noise (R\\'enyi differential\nprivacy). In the former setting, by providing a lower bound on the sample\ncomplexity of any $\\epsilon$-DP test with prescribed type I and type II errors,\nwe show that DP-SPRT is near optimal when both errors are small and the two\nhypotheses are close. Moreover, we conduct an experimental study revealing its\ngood practical performance.", "AI": {"tldr": "\u672c\u6587\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u91cd\u65b0\u5ba1\u89c6Wald\u7684\u5e8f\u8d2f\u6982\u7387\u6bd4\u68c0\u9a8c\uff0c\u63d0\u51faDP - SPRT\u65b9\u6cd5\uff0c\u8bc1\u660e\u5176\u8bef\u5dee\u548c\u6837\u672c\u590d\u6742\u5ea6\u7684\u754c\uff0c\u5728\u4e24\u79cd\u566a\u58f0\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5206\u6790\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u6539\u8fdb\u73b0\u6709\u7684\u5e8f\u8d2f\u6982\u7387\u6bd4\u68c0\u9a8c\uff0c\u5f25\u8865\u4ee5\u5f80\u5de5\u4f5c\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51faDP - SPRT\u5305\u88c5\u5668\uff0c\u4f9d\u9760OutsideInterval\u673a\u5236\u5904\u7406\u67e5\u8be2\u5e8f\u5217\uff1b\u8bc1\u660e\u8bef\u5dee\u548c\u6837\u672c\u590d\u6742\u5ea6\u7684\u901a\u7528\u4e0a\u754c\u3002", "result": "\u5728\u62c9\u666e\u62c9\u65af\u566a\u58f0\u548c\u9ad8\u65af\u566a\u58f0\u8bbe\u7f6e\u4e0b\u5206\u6790\uff0c\u8bc1\u660e\u5728\u62c9\u666e\u62c9\u65af\u566a\u58f0\u4e2d\u5f53\u8bef\u5dee\u5c0f\u4e14\u4e24\u5047\u8bbe\u63a5\u8fd1\u65f6DP - SPRT\u63a5\u8fd1\u6700\u4f18\uff1b\u5b9e\u9a8c\u663e\u793a\u5176\u6709\u826f\u597d\u7684\u5b9e\u9645\u6027\u80fd\u3002", "conclusion": "DP - SPRT\u80fd\u5728\u6ee1\u8db3\u9690\u79c1\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u6240\u9700\u7684\u8bef\u5dee\u6982\u7387\uff0c\u6709\u7406\u8bba\u548c\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2508.06062", "pdf": "https://arxiv.org/pdf/2508.06062", "abs": "https://arxiv.org/abs/2508.06062", "authors": ["Evgenii E. Vityaev", "Andrei Mantsivoda"], "title": "Don't Forget Imagination!", "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 68T30"], "comment": "14 pages, 2 figures", "summary": "Cognitive imagination is a type of imagination that plays a key role in human\nthinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to\nmentally visualize coherent and holistic systems of concepts and causal links\nthat serve as semantic contexts for reasoning, decision making and prediction.\nOur position is that the role of cognitive imagination is still greatly\nunderestimated, and this creates numerous problems and diminishes the current\ncapabilities of AI. For instance, when reasoning, humans rely on imaginary\ncontexts to retrieve background info. They also constantly return to the\ncontext for semantic verification that their reasoning is still reasonable.\nThus, reasoning without imagination is blind. This paper is a call for greater\nattention to cognitive imagination as the next promising breakthrough in\nartificial intelligence. As an instrument for simulating cognitive imagination,\nwe propose semantic models -- a new approach to mathematical models that can\nlearn, like neural networks, and are based on probabilistic causal\nrelationships. Semantic models can simulate cognitive imagination because they\nensure the consistency of imaginary contexts and implement a glass-box approach\nthat allows the context to be manipulated as a holistic and coherent system of\ninterrelated facts glued together with causal relations.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u8ba4\u77e5\u60f3\u8c61\u5728\u4eba\u7c7b\u601d\u7ef4\u4e2d\u4f5c\u7528\u5173\u952e\u4f46\u5728AI\u4e2d\u88ab\u4f4e\u4f30\uff0c\u547c\u5401\u91cd\u89c6\u5b83\uff0c\u5e76\u63d0\u51fa\u8bed\u4e49\u6a21\u578b\u6765\u6a21\u62df\u8ba4\u77e5\u60f3\u8c61\u3002", "motivation": "\u5f53\u524d\u8ba4\u77e5\u60f3\u8c61\u5728AI\u4e2d\u7684\u4f5c\u7528\u88ab\u4f4e\u4f30\uff0c\u5bfc\u81f4\u8bf8\u591a\u95ee\u9898\u5e76\u9650\u5236\u4e86AI\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8bed\u4e49\u6a21\u578b\u8fd9\u4e00\u57fa\u4e8e\u6982\u7387\u56e0\u679c\u5173\u7cfb\u3001\u53ef\u5b66\u4e60\u7684\u65b0\u6570\u5b66\u6a21\u578b\u65b9\u6cd5\u6765\u6a21\u62df\u8ba4\u77e5\u60f3\u8c61\u3002", "result": "\u8bed\u4e49\u6a21\u578b\u80fd\u786e\u4fdd\u60f3\u8c61\u8bed\u5883\u7684\u4e00\u81f4\u6027\uff0c\u53ef\u5c06\u8bed\u5883\u4f5c\u4e3a\u7531\u56e0\u679c\u5173\u7cfb\u8fde\u63a5\u7684\u4e8b\u5b9e\u6574\u4f53\u7cfb\u7edf\u8fdb\u884c\u64cd\u4f5c\u3002", "conclusion": "\u5e94\u66f4\u52a0\u5173\u6ce8\u8ba4\u77e5\u60f3\u8c61\uff0c\u5c06\u5176\u4f5c\u4e3a\u4eba\u5de5\u667a\u80fd\u4e0b\u4e00\u4e2a\u6709\u524d\u666f\u7684\u7a81\u7834\u70b9\u3002"}}
{"id": "2508.06339", "pdf": "https://arxiv.org/pdf/2508.06339", "abs": "https://arxiv.org/abs/2508.06339", "authors": ["Evelyne Ringoot", "Rabab Alomairy", "Valentin Churavy", "Alan Edelman"], "title": "Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision", "categories": ["cs.DC", "cs.MS"], "comment": "12 pages, 6 figures, 4 tables", "summary": "This paper presents a portable, GPU-accelerated implementation of a QR-based\nsingular value computation algorithm in Julia. The singular value ecomposition\n(SVD) is a fundamental numerical tool in scientific computing and machine\nlearning, providing optimal low-rank matrix approximations. Its importance has\nincreased even more in large-scale machine learning pipelines, including large\nlanguage models (LLMs), where it enables low-rank adaptation (LoRA). The\nimplemented algorithm is based on the classic two-stage QR reduction,\nconsisting of successive matrix reduction to band form and bidiagonal form. Our\nimplementation leverages Julia's multiple dispatch and metaprogramming\ncapabilities, integrating with the GPUArrays and KernelAbstractions frameworks\nto provide a unified type and hardware-agnostic function. It supports diverse\nGPU architectures and data types, and is, to our knowledge, the first\nGPU-accelerated singular value implementation to support Apple Metal GPUs and\nhalf precision. Performance results on multiple GPU backends and data types\ndemonstrate that portability does not require sacrificing performance: the\nunified function outperforms most linear algebra libraries (MAGMA, SLATE,\nrocSOLVER, oneMKL) for matrix sizes larger than 1024x1024, and achieves 80%-90%\nof the performance of cuSOLVER for large matrices.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57fa\u4e8eJulia\u5b9e\u73b0\u7684\u4fbf\u643a\u5f0f\u3001GPU\u52a0\u901f\u7684\u57fa\u4e8eQR\u7684\u5947\u5f02\u503c\u8ba1\u7b97\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u652f\u6301\u591a\u79cdGPU\u67b6\u6784\u548c\u6570\u636e\u7c7b\u578b\uff0c\u6027\u80fd\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5947\u5f02\u503c\u5206\u89e3\u5728\u79d1\u5b66\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u662f\u57fa\u7840\u5de5\u5177\uff0c\u5728\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u7ba1\u9053\u4e2d\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u9700\u8981\u5b9e\u73b0GPU\u52a0\u901f\u4e14\u5177\u6709\u826f\u597d\u53ef\u79fb\u690d\u6027\u7684\u7b97\u6cd5\u3002", "method": "\u57fa\u4e8e\u7ecf\u5178\u7684\u4e24\u9636\u6bb5QR\u7ea6\u7b80\uff0c\u5229\u7528Julia\u7684\u591a\u91cd\u8c03\u5ea6\u548c\u5143\u7f16\u7a0b\u80fd\u529b\uff0c\u96c6\u6210GPUArrays\u548cKernelAbstractions\u6846\u67b6\u3002", "result": "\u7edf\u4e00\u51fd\u6570\u5728\u77e9\u9635\u5c3a\u5bf8\u5927\u4e8e1024x1024\u65f6\u4f18\u4e8e\u591a\u6570\u7ebf\u6027\u4ee3\u6570\u5e93\uff0c\u5bf9\u4e8e\u5927\u77e9\u9635\u80fd\u8fbe\u5230cuSOLVER\u6027\u80fd\u768480%-90%\u3002", "conclusion": "\u5b9e\u73b0\u7684\u53ef\u79fb\u690d\u6027\u7b97\u6cd5\u65e0\u9700\u727a\u7272\u6027\u80fd\u3002"}}
{"id": "2508.06454", "pdf": "https://arxiv.org/pdf/2508.06454", "abs": "https://arxiv.org/abs/2508.06454", "authors": ["Joshua Caiata", "Ben Armstrong", "Kate Larson"], "title": "What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting", "categories": ["cs.AI", "cs.GT"], "comment": "41 pages", "summary": "Committee-selection problems arise in many contexts and applications, and\nthere has been increasing interest within the social choice research community\non identifying which properties are satisfied by different multi-winner voting\nrules. In this work, we propose a data-driven framework to evaluate how\nfrequently voting rules violate axioms across diverse preference distributions\nin practice, shifting away from the binary perspective of axiom satisfaction\ngiven by worst-case analysis. Using this framework, we analyze the relationship\nbetween multi-winner voting rules and their axiomatic performance under several\npreference distributions. We then show that neural networks, acting as voting\nrules, can outperform traditional rules in minimizing axiom violations. Our\nresults suggest that data-driven approaches to social choice can inform the\ndesign of new voting systems and support the continuation of data-driven\nresearch in social choice.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u6846\u67b6\u8bc4\u4f30\u591a\u83b7\u80dc\u8005\u6295\u7968\u89c4\u5219\u8fdd\u53cd\u516c\u7406\u7684\u9891\u7387\uff0c\u5206\u6790\u89c4\u5219\u4e0e\u516c\u7406\u8868\u73b0\u5173\u7cfb\uff0c\u8868\u660e\u795e\u7ecf\u7f51\u7edc\u6295\u7968\u89c4\u5219\u66f4\u4f18\uff0c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7814\u7a76\u3002", "motivation": "\u793e\u4f1a\u9009\u62e9\u7814\u7a76\u793e\u533a\u5173\u6ce8\u4e0d\u540c\u591a\u83b7\u80dc\u8005\u6295\u7968\u89c4\u5219\u6ee1\u8db3\u7684\u5c5e\u6027\uff0c\u73b0\u6709\u7814\u7a76\u591a\u4e3a\u6700\u574f\u60c5\u51b5\u5206\u6790\uff0c\u9700\u4ece\u6570\u636e\u9a71\u52a8\u89c6\u89d2\u8bc4\u4f30\u89c4\u5219\u8fdd\u53cd\u516c\u7406\u7684\u9891\u7387\u3002", "method": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u5206\u6790\u591a\u83b7\u80dc\u8005\u6295\u7968\u89c4\u5219\u5728\u4e0d\u540c\u504f\u597d\u5206\u5e03\u4e0b\u4e0e\u516c\u7406\u8868\u73b0\u7684\u5173\u7cfb\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6295\u7968\u89c4\u5219\u5728\u6700\u5c0f\u5316\u516c\u7406\u8fdd\u53cd\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u89c4\u5219\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u793e\u4f1a\u9009\u62e9\u65b9\u6cd5\u53ef\u4e3a\u65b0\u6295\u7968\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4fe1\u606f\uff0c\u652f\u6301\u793e\u4f1a\u9009\u62e9\u9886\u57df\u7684\u6570\u636e\u9a71\u52a8\u7814\u7a76\u7ee7\u7eed\u5f00\u5c55\u3002"}}
{"id": "2508.06216", "pdf": "https://arxiv.org/pdf/2508.06216", "abs": "https://arxiv.org/abs/2508.06216", "authors": ["Jesse Beisegel", "Nina Chiarelli", "Ekkehard K\u00f6hler", "Matja\u017e Krnc", "Martin Milani\u010d", "Nevena Piva\u010d", "Robert Scheffler", "Martin Strehler"], "title": "Sandwich Monotonicity and the Recognition of Weighted Graph Classes", "categories": ["cs.DM", "cs.DS", "math.CO"], "comment": null, "summary": "Edge-weighted graphs play an important role in the theory of Robinsonian\nmatrices and similarity theory, particularly via the concept of level graphs,\nthat is, graphs obtained from an edge-weighted graph by removing all\nsufficiently light edges. This suggest a natural way of associating to any\nclass $\\mathcal{G}$ of unweighted graphs a corresponding class of edge-weighted\ngraphs, namely by requiring that all level graphs belong to $\\mathcal{G}$. We\nshow that weighted graphs for which all level graphs are split, threshold, or\nchain graphs can be recognized in linear time using special edge elimination\norderings. We obtain these results by introducing the notion of degree sandwich\nmonotone graph classes. A graph class $\\mathcal{G}$ is sandwich monotone if\nevery edge set which may be removed from a graph in $\\mathcal{G}$ without\nleaving the class also contains a single edge that can be safely removed.\nFurthermore, if we require the safe edge to fulfill a certain degree property,\nthen $\\mathcal{G}$ is called degree sandwich monotone. We present necessary and\nsufficient conditions for the existence of a linear-time recognition algorithm\nfor any weighted graph class whose corresponding unweighted class is degree\nsandwich monotone and contains all edgeless graphs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8fb9\u52a0\u6743\u56fe\u4e0e\u65e0\u6743\u56fe\u7c7b\u5bf9\u5e94\u5173\u7cfb\uff0c\u5c55\u793a\u7279\u5b9a\u8fb9\u52a0\u6743\u56fe\u7684\u7ebf\u6027\u65f6\u95f4\u8bc6\u522b\u65b9\u6cd5\uff0c\u7ed9\u51fa\u7ebf\u6027\u65f6\u95f4\u8bc6\u522b\u7b97\u6cd5\u5b58\u5728\u7684\u5145\u8981\u6761\u4ef6\u3002", "motivation": "\u8fb9\u52a0\u6743\u56fe\u5728\u76f8\u5173\u7406\u8bba\u4e2d\u91cd\u8981\uff0c\u5e0c\u671b\u627e\u5230\u4e0e\u65e0\u6743\u56fe\u7c7b\u5bf9\u5e94\u7684\u8fb9\u52a0\u6743\u56fe\u7c7b\u7684\u8bc6\u522b\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u5ea6\u4e09\u660e\u6cbb\u5355\u8c03\u56fe\u7c7b\u6982\u5ff5\uff0c\u5229\u7528\u7279\u6b8a\u8fb9\u6d88\u9664\u987a\u5e8f\u3002", "result": "\u80fd\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u8bc6\u522b\u6240\u6709\u5c42\u56fe\u4e3a\u5206\u88c2\u56fe\u3001\u9608\u503c\u56fe\u6216\u94fe\u56fe\u7684\u52a0\u6743\u56fe\u3002", "conclusion": "\u7ed9\u51fa\u5bf9\u5e94\u65e0\u6743\u56fe\u7c7b\u4e3a\u5ea6\u4e09\u660e\u6cbb\u5355\u8c03\u4e14\u542b\u65e0\u8fb9\u56fe\u7684\u52a0\u6743\u56fe\u7c7b\u7ebf\u6027\u65f6\u95f4\u8bc6\u522b\u7b97\u6cd5\u5b58\u5728\u7684\u5145\u8981\u6761\u4ef6\u3002"}}
{"id": "2508.05654", "pdf": "https://arxiv.org/pdf/2508.05654", "abs": "https://arxiv.org/abs/2508.05654", "authors": ["Leonardo Santiago Benitez Pereira", "Robinson Pizzio", "Samir Bonho"], "title": "Comparison of Information Retrieval Techniques Applied to IT Support Tickets", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Institutions dependent on IT services and resources acknowledge the crucial\nsignificance of an IT help desk system, that act as a centralized hub\nconnecting IT staff and users for service requests. Employing various Machine\nLearning models, these IT help desk systems allow access to corrective actions\nused in the past, but each model has different performance when applied to\ndifferent datasets. This work compares eleven Information Retrieval techniques\nin a dataset of IT support tickets, with the goal of implementing a software\nthat facilitates the work of Information Technology support analysts. The best\nresults were obtained with the Sentence-BERT technique, in its multi-language\nvariation distilluse-base-multilingual-cased-v1, where 78.7% of the\nrecommendations made by the model were considered relevant. TF-IDF (69.0%),\nWord2vec (68.7%) and LDA (66.3%) techniques also had consistent results.\nFurthermore, the used datasets and essential parts of coding have been\npublished and made open source. It also demonstrated the practicality of a\nsupport ticket recovery system by implementing a minimal viable prototype, and\ndescribed in detail the implementation of the system. Finally, this work\nproposed a novel metric for comparing the techniques, whose aim is to closely\nreflect the perception of the IT analysts about the retrieval quality.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f8311\u79cd\u4fe1\u606f\u68c0\u7d22\u6280\u672f\u5904\u7406IT\u652f\u6301\u5de5\u5355\uff0cSentence - BERT\u591a\u8bed\u8a00\u53d8\u4f53\u6548\u679c\u6700\u4f73\uff0c\u8fd8\u5f00\u6e90\u6570\u636e\u548c\u4ee3\u7801\uff0c\u5b9e\u73b0\u539f\u578b\u5e76\u63d0\u51fa\u65b0\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4e0d\u540c\uff0c\u4e3a\u65b9\u4fbfIT\u652f\u6301\u5206\u6790\u5e08\u5de5\u4f5c\u3002", "method": "\u5728IT\u652f\u6301\u5de5\u5355\u6570\u636e\u96c6\u4e0a\u6bd4\u8f8311\u79cd\u4fe1\u606f\u68c0\u7d22\u6280\u672f\uff0c\u5b9e\u73b0\u6700\u5c0f\u53ef\u884c\u539f\u578b\u3002", "result": "Sentence - BERT\u591a\u8bed\u8a00\u53d8\u4f53distilluse - base - multilingual - cased - v1\u6548\u679c\u6700\u4f73\uff0c78.7%\u63a8\u8350\u76f8\u5173\uff0cTF - IDF\u7b49\u4e5f\u6709\u4e0d\u9519\u7ed3\u679c\uff0c\u5f00\u6e90\u6570\u636e\u548c\u4ee3\u7801\u3002", "conclusion": "\u63d0\u51fa\u65b0\u8bc4\u4f30\u6307\u6807\u4ee5\u53cd\u6620IT\u5206\u6790\u5e08\u5bf9\u68c0\u7d22\u8d28\u91cf\u7684\u770b\u6cd5\uff0c\u8bc1\u660e\u652f\u6301\u5de5\u5355\u6062\u590d\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.05970", "pdf": "https://arxiv.org/pdf/2508.05970", "abs": "https://arxiv.org/abs/2508.05970", "authors": ["Yanzhou Li", "Shangqing Liu", "Kangjie Chen", "Tianwei Zhang", "Yang Liu"], "title": "Impact-driven Context Filtering For Cross-file Code Completion", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) has recently demonstrated considerable\npotential for repository-level code completion, as it integrates cross-file\nknowledge with in-file preceding code to provide comprehensive contexts for\ngeneration. To better understand the contribution of the retrieved cross-file\ncontexts, we introduce a likelihood-based metric to evaluate the impact of each\nretrieved code chunk on the completion. Our analysis reveals that, despite\nretrieving numerous chunks, only a small subset positively contributes to the\ncompletion, while some chunks even degrade performance. To address this issue,\nwe leverage this metric to construct a repository-level dataset where each\nretrieved chunk is labeled as positive, neutral, or negative based on its\nrelevance to the target completion. We then propose an adaptive retrieval\ncontext filtering framework, CODEFILTER, trained on this dataset to mitigate\nthe harmful effects of negative retrieved contexts in code completion.\nExtensive evaluation on the RepoEval and CrossCodeLongEval benchmarks\ndemonstrates that CODEFILTER consistently improves completion accuracy compared\nto approaches without filtering operations across various tasks. Additionally,\nCODEFILTER significantly reduces the length of the input prompt, enhancing\ncomputational efficiency while exhibiting strong generalizability across\ndifferent models. These results underscore the potential of CODEFILTER to\nenhance the accuracy, efficiency, and attributability of repository-level code\ncompletion.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u6307\u6807\u8bc4\u4f30\u68c0\u7d22\u4ee3\u7801\u5757\u5bf9\u4ee3\u7801\u8865\u5168\u7684\u5f71\u54cd\uff0c\u6784\u5efa\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u81ea\u9002\u5e94\u68c0\u7d22\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u6846\u67b6CODEFILTER\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u4ee3\u7801\u8865\u5168\u7684\u51c6\u786e\u7387\u3001\u6548\u7387\u548c\u6cdb\u5316\u6027\u3002", "motivation": "\u4e3a\u66f4\u597d\u7406\u89e3\u68c0\u7d22\u7684\u8de8\u6587\u4ef6\u4e0a\u4e0b\u6587\u5bf9\u4ee3\u7801\u8865\u5168\u7684\u8d21\u732e\uff0c\u89e3\u51b3\u90e8\u5206\u68c0\u7d22\u4ee3\u7801\u5757\u964d\u4f4e\u8865\u5168\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u4f3c\u7136\u7684\u6307\u6807\u8bc4\u4f30\u68c0\u7d22\u4ee3\u7801\u5757\u5f71\u54cd\uff0c\u6784\u5efa\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u63d0\u51faCODEFILTER\u6846\u67b6\u5e76\u5728\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u3002", "result": "\u5728RepoEval\u548cCrossCodeLongEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCODEFILTER\u6bd4\u65e0\u8fc7\u6ee4\u64cd\u4f5c\u7684\u65b9\u6cd5\u6301\u7eed\u63d0\u9ad8\u8865\u5168\u51c6\u786e\u7387\uff0c\u51cf\u5c11\u8f93\u5165\u63d0\u793a\u957f\u5ea6\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u4e14\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u6709\u5f3a\u6cdb\u5316\u6027\u3002", "conclusion": "CODEFILTER\u6709\u63d0\u5347\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u5f52\u56e0\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.05876", "pdf": "https://arxiv.org/pdf/2508.05876", "abs": "https://arxiv.org/abs/2508.05876", "authors": ["Francesca Ferrara", "Lander W. Schillinger Arana", "Florian D\u00f6rfler", "Sarah H. Q. Li"], "title": "A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance", "categories": ["cs.LG", "astro-ph.EP", "astro-ph.IM", "cs.ET"], "comment": "16 pages, 13 figures, submitted to the 2025 Astrodynamics Specialist\n  Conference", "summary": "This work presents a Markov decision process (MDP) framework to model\ndecision-making for collision avoidance maneuver (CAM) and a reinforcement\nlearning policy gradient (RL-PG) algorithm to train an autonomous guidance\npolicy using historic CAM data. In addition to maintaining acceptable collision\nrisks, this approach seeks to minimize the average fuel consumption of CAMs by\nmaking early maneuver decisions. We model CAM as a continuous state, discrete\naction and finite horizon MDP, where the critical decision is determining when\nto initiate the maneuver. The MDP model also incorporates analytical models for\nconjunction risk, propellant consumption, and transit orbit geometry. The\nMarkov policy effectively trades-off maneuver delay-which improves the\nreliability of conjunction risk indicators-with propellant consumption-which\nincreases with decreasing maneuver time. Using historical data of tracked\nconjunction events, we verify this framework and conduct an extensive ablation\nstudy on the hyper-parameters used within the MDP. On synthetic conjunction\nevents, the trained policy significantly minimizes both the overall and average\npropellant consumption per CAM when compared to a conventional cut-off policy\nthat initiates maneuvers 24 hours before the time of closest approach (TCA). On\nhistorical conjunction events, the trained policy consumes more propellant\noverall but reduces the average propellant consumption per CAM. For both\nhistorical and synthetic conjunction events, the trained policy achieves equal\nif not higher overall collision risk guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMDP\u6846\u67b6\u548cRL - PG\u7b97\u6cd5\u8bad\u7ec3\u81ea\u4e3b\u5236\u5bfc\u7b56\u7565\u4ee5\u5b9e\u73b0\u907f\u78b0\u673a\u52a8\uff0c\u5728\u5408\u6210\u548c\u5386\u53f2\u4ea4\u4f1a\u4e8b\u4ef6\u4e2d\u9a8c\u8bc1\uff0c\u80fd\u964d\u4f4e\u71c3\u6599\u6d88\u8017\u5e76\u4fdd\u8bc1\u78b0\u649e\u98ce\u9669\u3002", "motivation": "\u5728\u7ef4\u6301\u53ef\u63a5\u53d7\u78b0\u649e\u98ce\u9669\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u63d0\u524d\u51b3\u7b56\u6700\u5c0f\u5316\u907f\u78b0\u673a\u52a8\u7684\u5e73\u5747\u71c3\u6599\u6d88\u8017\u3002", "method": "\u5c06\u907f\u78b0\u673a\u52a8\u5efa\u6a21\u4e3a\u8fde\u7eed\u72b6\u6001\u3001\u79bb\u6563\u52a8\u4f5c\u548c\u6709\u9650\u65f6\u57df\u7684MDP\uff0c\u7ed3\u5408\u76f8\u5173\u5206\u6790\u6a21\u578b\uff0c\u7528\u5386\u53f2\u4ea4\u4f1a\u4e8b\u4ef6\u6570\u636e\u8bad\u7ec3\u9a6c\u5c14\u53ef\u592b\u7b56\u7565\uff0c\u8fdb\u884c\u8d85\u53c2\u6570\u6d88\u878d\u7814\u7a76\u3002", "result": "\u5728\u5408\u6210\u4ea4\u4f1a\u4e8b\u4ef6\u4e2d\uff0c\u8bad\u7ec3\u7b56\u7565\u6bd4\u4f20\u7edf\u7b56\u7565\u663e\u8457\u964d\u4f4e\u603b\u53ca\u6bcf\u6b21\u907f\u78b0\u673a\u52a8\u7684\u5e73\u5747\u71c3\u6599\u6d88\u8017\uff1b\u5728\u5386\u53f2\u4ea4\u4f1a\u4e8b\u4ef6\u4e2d\uff0c\u603b\u71c3\u6599\u6d88\u8017\u589e\u52a0\u4f46\u6bcf\u6b21\u907f\u78b0\u673a\u52a8\u7684\u5e73\u5747\u71c3\u6599\u6d88\u8017\u964d\u4f4e\uff0c\u4e14\u4fdd\u8bc1\u4e86\u78b0\u649e\u98ce\u9669\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u7b97\u6cd5\u80fd\u6709\u6548\u5728\u907f\u78b0\u673a\u52a8\u4e2d\u5e73\u8861\u71c3\u6599\u6d88\u8017\u548c\u78b0\u649e\u98ce\u9669\u3002"}}
{"id": "2508.06064", "pdf": "https://arxiv.org/pdf/2508.06064", "abs": "https://arxiv.org/abs/2508.06064", "authors": ["Harold Silv\u00e8re Kiossou", "Siegfried Nijssen", "Pierre Schaus"], "title": "A Generic Complete Anytime Beam Search for Optimal Decision Tree", "categories": ["cs.AI"], "comment": null, "summary": "Finding an optimal decision tree that minimizes classification error is known\nto be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic\nprogramming guarantee optimality, they often suffer from poor anytime behavior\n-- meaning they struggle to find high-quality decision trees quickly when the\nsearch is stopped before completion -- due to unbalanced search space\nexploration. To address this, several anytime extensions of exact methods have\nbeen proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not\nbeen systematically compared, making it difficult to assess their relative\neffectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and\nanytime beam search algorithm that extends the DL8.5 framework and unifies some\nexisting anytime strategies. In particular, CA-DL8.5 generalizes previous\napproaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various\nheuristics and relaxation mechanisms through a modular design. The algorithm\nreuses DL8.5's efficient branch-and-bound pruning and trie-based caching,\ncombined with a restart-based beam search that gradually relaxes pruning\ncriteria to improve solution quality over time. Our contributions are twofold:\n(1) We introduce this new generic framework for exact and anytime decision tree\nlearning, enabling the incorporation of diverse heuristics and search\nstrategies; (2) We conduct a rigorous empirical comparison of several\ninstantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k\nheuristics -- using an anytime evaluation metric called the primal gap\nintegral. Experimental results on standard classification benchmarks show that\nCA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime\nperformance, outperforming both other CA-DL8.5 variants and the Blossom\nalgorithm while maintaining completeness and optimality guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCA - DL8.5\u7b97\u6cd5\uff0c\u7edf\u4e00\u73b0\u6709\u7b56\u7565\uff0c\u7ed3\u5408\u9ad8\u6548\u526a\u679d\u548c\u7f13\u5b58\uff0c\u7ecf\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u57fa\u4e8eLDS\u7684CA - DL8.5\u6709\u6700\u4f73\u4efb\u610f\u65f6\u95f4\u6027\u80fd\u3002", "motivation": "\u5bfb\u627e\u6700\u4f18\u51b3\u7b56\u6811\u662fNP\u96be\u95ee\u9898\uff0c\u73b0\u6709\u7cbe\u786e\u7b97\u6cd5\u4efb\u610f\u65f6\u95f4\u884c\u4e3a\u5dee\uff0c\u5df2\u6709\u4efb\u610f\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u672a\u7cfb\u7edf\u6bd4\u8f83\uff0c\u96be\u4ee5\u8bc4\u4f30\u6548\u679c\u3002", "method": "\u63d0\u51faCA - DL8.5\u7b97\u6cd5\uff0c\u6269\u5c55DL8.5\u6846\u67b6\uff0c\u5141\u8bb8\u96c6\u6210\u591a\u79cd\u542f\u53d1\u5f0f\u548c\u677e\u5f1b\u673a\u5236\uff0c\u91c7\u7528\u57fa\u4e8e\u91cd\u542f\u7684\u675f\u641c\u7d22\u9010\u6b65\u653e\u5bbd\u526a\u679d\u6807\u51c6\u3002", "result": "\u5728\u6807\u51c6\u5206\u7c7b\u57fa\u51c6\u4e0a\u5b9e\u9a8c\uff0c\u57fa\u4e8eLDS\u7684CA - DL8.5\u59cb\u7ec8\u6709\u6700\u4f73\u4efb\u610f\u65f6\u95f4\u6027\u80fd\uff0c\u4f18\u4e8e\u5176\u4ed6CA - DL8.5\u53d8\u4f53\u548cBlossom\u7b97\u6cd5\u3002", "conclusion": "CA - DL8.5\u7b97\u6cd5\u4e3a\u7cbe\u786e\u548c\u4efb\u610f\u65f6\u95f4\u51b3\u7b56\u6811\u5b66\u4e60\u63d0\u4f9b\u65b0\u901a\u7528\u6846\u67b6\uff0c\u57fa\u4e8eLDS\u7684\u53d8\u4f53\u6709\u6700\u4f73\u6027\u80fd\u4e14\u4fdd\u8bc1\u5b8c\u6574\u6027\u548c\u6700\u4f18\u6027\u3002"}}
{"id": "2508.06406", "pdf": "https://arxiv.org/pdf/2508.06406", "abs": "https://arxiv.org/abs/2508.06406", "authors": ["Murtaza Rangwala", "Venugopal K R", "Rajkumar Buyya"], "title": "Blockchain-Enabled Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": "32 pages, 6 figures, chapter for edited book (Federated Learning:\n  Foundations and Applications)", "summary": "Blockchain-enabled federated learning (BCFL) addresses fundamental challenges\nof trust, privacy, and coordination in collaborative AI systems. This chapter\nprovides comprehensive architectural analysis of BCFL systems through a\nsystematic four-dimensional taxonomy examining coordination structures,\nconsensus mechanisms, storage architectures, and trust models. We analyze\ndesign patterns from blockchain-verified centralized coordination to fully\ndecentralized peer-to-peer networks, evaluating trade-offs in scalability,\nsecurity, and performance. Through detailed examination of consensus mechanisms\ndesigned for federated learning contexts, including Proof of Quality and Proof\nof Federated Learning, we demonstrate how computational work can be repurposed\nfrom arbitrary cryptographic puzzles to productive machine learning tasks. The\nchapter addresses critical storage challenges by examining multi-tier\narchitectures that balance blockchain's transaction constraints with neural\nnetworks' large parameter requirements while maintaining cryptographic\nintegrity. A technical case study of the TrustMesh framework illustrates\npractical implementation considerations in BCFL systems through distributed\nimage classification training, demonstrating effective collaborative learning\nacross IoT devices with highly non-IID data distributions while maintaining\ncomplete transparency and fault tolerance. Analysis of real-world deployments\nacross healthcare consortiums, financial services, and IoT security\napplications validates the practical viability of BCFL systems, achieving\nperformance comparable to centralized approaches while providing enhanced\nsecurity guarantees and enabling new models of trustless collaborative\nintelligence.", "AI": {"tldr": "\u672c\u6587\u5bf9\u533a\u5757\u94fe\u8d4b\u80fd\u7684\u8054\u90a6\u5b66\u4e60\uff08BCFL\uff09\u7cfb\u7edf\u8fdb\u884c\u5168\u9762\u67b6\u6784\u5206\u6790\uff0c\u901a\u8fc7\u6848\u4f8b\u548c\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\u4e0e\u4f18\u52bf\u3002", "motivation": "\u89e3\u51b3\u534f\u4f5c\u5f0fAI\u7cfb\u7edf\u4e2d\u4fe1\u4efb\u3001\u9690\u79c1\u548c\u534f\u8c03\u7684\u57fa\u672c\u6311\u6218\u3002", "method": "\u91c7\u7528\u56db\u7ef4\u5206\u7c7b\u6cd5\u5206\u6790BCFL\u7cfb\u7edf\uff0c\u7814\u7a76\u8bbe\u8ba1\u6a21\u5f0f\u3001\u5171\u8bc6\u673a\u5236\u3001\u5b58\u50a8\u67b6\u6784\uff0c\u8fdb\u884c\u6280\u672f\u6848\u4f8b\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u5206\u6790\u3002", "result": "\u6848\u4f8b\u5c55\u793a\u4e86BCFL\u7cfb\u7edf\u80fd\u5728\u9ad8\u975eIID\u6570\u636e\u5206\u5e03\u7684\u7269\u8054\u7f51\u8bbe\u5907\u4e0a\u5b9e\u73b0\u6709\u6548\u534f\u4f5c\u5b66\u4e60\uff0c\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u5176\u6027\u80fd\u4e0e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76f8\u5f53\u4e14\u5b89\u5168\u6027\u66f4\u9ad8\u3002", "conclusion": "BCFL\u7cfb\u7edf\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u80fd\u63d0\u4f9b\u589e\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\uff0c\u5b9e\u73b0\u65e0\u4fe1\u4efb\u534f\u4f5c\u667a\u80fd\u3002"}}
{"id": "2508.06247", "pdf": "https://arxiv.org/pdf/2508.06247", "abs": "https://arxiv.org/abs/2508.06247", "authors": ["Zichun Ye", "Runqi Wang", "Xutong Liu", "Shuai Li"], "title": "Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential\ndecision-making framework, dominated by two algorithmic families: UCB-based and\nadversarial methods such as follow the regularized leader (FTRL) and online\nmirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer\nfrom additional regret factor $\\log T$ that is detrimental over long horizons,\nwhile adversarial methods such as EXP3.M and HYBRID impose significant\ncomputational overhead. To resolve this trade-off, we introduce the\nCombinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS\nis a computationally efficient algorithm that achieves an instance-independent\nregret of $O\\big( (\\log k)^2\\sqrt{kmT}\\big )$ under semi-bandit feedback, where\n$m$ is the number of arms and $k$ is the maximum cardinality of a feasible\naction. Crucially, this result eliminates the dependency on $\\log T$ and\nmatches the established $\\Omega\\big( \\sqrt{kmT}\\big)$ lower bound up to\n$O\\big((\\log k)^2\\big)$. We then extend our analysis to show that CMOSS is also\napplicable to cascading feedback. Experiments on synthetic and real-world\ndatasets validate that CMOSS consistently outperforms benchmark algorithms in\nboth regret and runtime efficiency.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.05657", "pdf": "https://arxiv.org/pdf/2508.05657", "abs": "https://arxiv.org/abs/2508.05657", "authors": ["Haozhe Xu", "Xiaohua Wang", "Changze Lv", "Xiaoqing Zheng"], "title": "Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Conversational recommender systems (CRSs) enhance recommendation quality by\nengaging users in multi-turn dialogues, capturing nuanced preferences through\nnatural language interactions. However, these systems often face the false\nnegative issue, where items that a user might like are incorrectly labeled as\nnegative during training, leading to suboptimal recommendations.Expanding the\nlabel set through data augmentation presents an intuitive solution but faces\nthe challenge of balancing two key aspects: ensuring semantic relevance and\npreserving the collaborative information inherent in CRS datasets. To address\nthese issues, we propose a novel data augmentation framework that first\nleverages an LLM-based semantic retriever to identify diverse and semantically\nrelevant items, which are then filtered by a relevance scorer to remove noisy\ncandidates. Building on this, we introduce a two-stage training strategy\nbalancing semantic relevance and collaborative information. Extensive\nexperiments on two benchmark datasets and user simulators demonstrate\nsignificant and consistent performance improvements across various\nrecommenders, highlighting the effectiveness of our approach in advancing CRS\nperformance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u6846\u67b6\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u89e3\u51b3\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u5047\u9634\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u5047\u9634\u6027\u95ee\u9898\uff0c\u6570\u636e\u589e\u5f3a\u9762\u4e34\u8bed\u4e49\u76f8\u5173\u6027\u548c\u534f\u4f5c\u4fe1\u606f\u5e73\u8861\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u68c0\u7d22\u5668\u8bc6\u522b\u76f8\u5173\u9879\u76ee\uff0c\u7528\u76f8\u5173\u6027\u8bc4\u5206\u5668\u8fc7\u6ee4\u566a\u58f0\u5019\u9009\uff0c\u5f15\u5165\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u7528\u6237\u6a21\u62df\u5668\u4e0a\u5b9e\u9a8c\uff0c\u5404\u63a8\u8350\u5668\u6027\u80fd\u663e\u8457\u4e14\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.06017", "pdf": "https://arxiv.org/pdf/2508.06017", "abs": "https://arxiv.org/abs/2508.06017", "authors": ["Xiangzhe Xu", "Shiwei Feng", "Zian Su", "Chengpeng Wang", "Xiangyu Zhang"], "title": "Position: Intelligent Coding Systems Should Write Programs with Justifications", "categories": ["cs.SE", "cs.CL", "cs.LG"], "comment": "The first two authors contributed equally to this work", "summary": "Intelligent coding systems are transforming software development by enabling\nusers to specify code behavior in natural language. However, the opaque\ndecision-making of AI-driven coders raises trust and usability concerns,\nparticularly for non-expert users who cannot inspect low-level implementations.\nWe argue that these systems should not only generate code but also produce\nclear, consistent justifications that bridge model reasoning and user\nunderstanding. To this end, we identify two critical justification\nproperties-cognitive alignment and semantic faithfulness-and highlight the\nlimitations of existing methods, including formal verification, static\nanalysis, and post-hoc explainability. We advocate exploring neuro-symbolic\napproaches for justification generation, where symbolic constraints guide model\nbehavior during training and program semantics are enriched through neural\nrepresentations, enabling automated consistency checks at inference time.", "AI": {"tldr": "\u667a\u80fd\u7f16\u7801\u7cfb\u7edf\u5b58\u5728\u51b3\u7b56\u4e0d\u900f\u660e\u95ee\u9898\uff0c\u9700\u751f\u6210\u6e05\u6670\u5408\u7406\u7406\u7531\uff0c\u53ef\u63a2\u7d22\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u89e3\u51b3\u3002", "motivation": "AI\u9a71\u52a8\u7684\u667a\u80fd\u7f16\u7801\u7cfb\u7edf\u51b3\u7b56\u4e0d\u900f\u660e\uff0c\u5f15\u53d1\u4fe1\u4efb\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u5c24\u5176\u5f71\u54cd\u975e\u4e13\u5bb6\u7528\u6237\u3002", "method": "\u786e\u5b9a\u8ba4\u77e5\u5bf9\u9f50\u548c\u8bed\u4e49\u5fe0\u5b9e\u4e24\u4e2a\u5173\u952e\u7406\u7531\u5c5e\u6027\uff0c\u6307\u51fa\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\uff0c\u5021\u5bfc\u63a2\u7d22\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u751f\u6210\u7406\u7531\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u667a\u80fd\u7f16\u7801\u7cfb\u7edf\u4e0d\u4ec5\u8981\u751f\u6210\u4ee3\u7801\uff0c\u8fd8\u5e94\u4ea7\u751f\u6e05\u6670\u4e00\u81f4\u7684\u7406\u7531\uff0c\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u53ef\u7528\u4e8e\u7406\u7531\u751f\u6210\u3002"}}
{"id": "2508.05905", "pdf": "https://arxiv.org/pdf/2508.05905", "abs": "https://arxiv.org/abs/2508.05905", "authors": ["Jeffrey Uhlmann"], "title": "The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)", "categories": ["cs.LG"], "comment": null, "summary": "Quantization is usually regarded as a means to trade quality of performance\nfor reduced compute requirements, i.e., as a suboptimal approximation. However,\nif examined in terms of a fixed overall resource budget, a very different\nperspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit\nquantization that deterministically provides gradient information with no\nforward-path penalty. Our analysis provides evidence that it may improve\ninformation density compared to non-quantized alternatives.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Signed - Zero Ternary (SZT) 2\u4f4d\u91cf\u5316\u65b9\u6cd5\uff0c\u5206\u6790\u8868\u660e\u5176\u53ef\u80fd\u63d0\u9ad8\u4fe1\u606f\u5bc6\u5ea6\u3002", "motivation": "\u4ece\u56fa\u5b9a\u6574\u4f53\u8d44\u6e90\u9884\u7b97\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u91cf\u5316\uff0c\u7a81\u7834\u5c06\u91cf\u5316\u89c6\u4e3a\u6b21\u4f18\u8fd1\u4f3c\u7684\u4f20\u7edf\u89c2\u70b9\u3002", "method": "\u5f15\u5165Signed - Zero Ternary (SZT) 2\u4f4d\u91cf\u5316\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u786e\u5b9a\u6027\u5730\u63d0\u4f9b\u68af\u5ea6\u4fe1\u606f\u4e14\u65e0\u6b63\u5411\u8def\u5f84\u60e9\u7f5a\u3002", "result": "\u5206\u6790\u663e\u793a\u8be5\u65b9\u6cd5\u53ef\u80fd\u6bd4\u975e\u91cf\u5316\u66ff\u4ee3\u65b9\u6848\u63d0\u9ad8\u4fe1\u606f\u5bc6\u5ea6\u3002", "conclusion": "Signed - Zero Ternary (SZT) 2\u4f4d\u91cf\u5316\u65b9\u6cd5\u6709\u63d0\u9ad8\u4fe1\u606f\u5bc6\u5ea6\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.06074", "pdf": "https://arxiv.org/pdf/2508.06074", "abs": "https://arxiv.org/abs/2508.06074", "authors": ["Siyi Lu", "Run Liu", "Dongsheng Yang", "Lei He"], "title": "ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Autonomous driving systems face significant challenges in perceiving complex\nenvironments and making real-time decisions. Traditional modular approaches,\nwhile offering interpretability, suffer from error propagation and coordination\nissues, whereas end-to-end learning systems can simplify the design but face\ncomputational bottlenecks. This paper presents a novel approach to autonomous\ndriving using deep reinforcement learning (DRL) that integrates bird's-eye view\n(BEV) perception for enhanced real-time decision-making. We introduce the\n\\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction\nnetwork that combines BEV-based perception with the Mamba framework for\ntemporal feature modeling. This integration allows the system to encode vehicle\nsurroundings and road features in a unified coordinate system and accurately\nmodel long-range dependencies. Building on this, we propose the\n\\texttt{ME$^3$-BEV} framework, which utilizes the \\texttt{Mamba-BEV} model as a\nfeature input for end-to-end DRL, achieving superior performance in dynamic\nurban driving scenarios. We further enhance the interpretability of the model\nby visualizing high-dimensional features through semantic segmentation,\nproviding insight into the learned representations. Extensive experiments on\nthe CARLA simulator demonstrate that \\texttt{ME$^3$-BEV} outperforms existing\nmodels across multiple metrics, including collision rate and trajectory\naccuracy, offering a promising solution for real-time autonomous driving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u81ea\u52a8\u9a7e\u9a76\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u9e1f\u77b0\u56fe\uff08BEV\uff09\u611f\u77e5\uff0c\u4ecb\u7ecdMamba - BEV\u6a21\u578b\u548cME\u00b3 - BEV\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u6a21\u5757\u5316\u65b9\u6cd5\u6709\u8bef\u5dee\u4f20\u64ad\u548c\u534f\u8c03\u95ee\u9898\uff0c\u7aef\u5230\u7aef\u5b66\u4e60\u7cfb\u7edf\u6709\u8ba1\u7b97\u74f6\u9888\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u73af\u5883\u548c\u5b9e\u65f6\u51b3\u7b56\u6311\u6218\u3002", "method": "\u5f15\u5165Mamba - BEV\u6a21\u578b\u8fdb\u884c\u65f6\u7a7a\u7279\u5f81\u63d0\u53d6\uff0c\u7ed3\u5408BEV\u611f\u77e5\u4e0eMamba\u6846\u67b6\uff1b\u63d0\u51faME\u00b3 - BEV\u6846\u67b6\uff0c\u5c06Mamba - BEV\u6a21\u578b\u4f5c\u4e3a\u7aef\u5230\u7aefDRL\u7684\u7279\u5f81\u8f93\u5165\uff1b\u901a\u8fc7\u8bed\u4e49\u5206\u5272\u53ef\u89c6\u5316\u9ad8\u7ef4\u7279\u5f81\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728CARLA\u6a21\u62df\u5668\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cME\u00b3 - BEV\u5728\u78b0\u649e\u7387\u548c\u8f68\u8ff9\u7cbe\u5ea6\u7b49\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "ME\u00b3 - BEV\u4e3a\u5b9e\u65f6\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.06301", "pdf": "https://arxiv.org/pdf/2508.06301", "abs": "https://arxiv.org/abs/2508.06301", "authors": ["Junhyeog Yun", "Minui Hong", "Gunhee Kim"], "title": "FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC"], "comment": "ICCV 2025", "summary": "Neural fields provide a memory-efficient representation of data, which can\neffectively handle diverse modalities and large-scale data. However, learning\nto map neural fields often requires large amounts of training data and\ncomputations, which can be limited to resource-constrained edge devices. One\napproach to tackle this limitation is to leverage Federated Meta-Learning\n(FML), but traditional FML approaches suffer from privacy leakage. To address\nthese issues, we introduce a novel FML approach called FedMeNF. FedMeNF\nutilizes a new privacy-preserving loss function that regulates privacy leakage\nin the local meta-optimization. This enables the local meta-learner to optimize\nquickly and efficiently without retaining the client's private data. Our\nexperiments demonstrate that FedMeNF achieves fast optimization speed and\nrobust reconstruction performance, even with few-shot or non-IID data across\ndiverse data modalities, while preserving client data privacy.", "AI": {"tldr": "\u63d0\u51faFedMeNF\u89e3\u51b3\u795e\u7ecf\u573a\u5b66\u4e60\u8d44\u6e90\u9700\u6c42\u5927\u53ca\u4f20\u7edfFML\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u901f\u5ea6\u5feb\u3001\u6027\u80fd\u597d\u4e14\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u795e\u7ecf\u573a\u5b66\u4e60\u9700\u5927\u91cf\u8d44\u6e90\uff0c\u4e0d\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\uff0c\u4f20\u7edfFML\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002", "method": "\u5f15\u5165FedMeNF\uff0c\u5229\u7528\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u635f\u5931\u51fd\u6570\u8c03\u8282\u672c\u5730\u5143\u4f18\u5316\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u3002", "result": "FedMeNF\u5728\u5c11\u6837\u672c\u6216\u975eIID\u6570\u636e\u3001\u591a\u6837\u6570\u636e\u6a21\u6001\u4e0b\u5b9e\u73b0\u5feb\u901f\u4f18\u5316\u548c\u7a33\u5065\u91cd\u5efa\u3002", "conclusion": "FedMeNF\u80fd\u5728\u4fdd\u62a4\u5ba2\u6237\u7aef\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u5feb\u901f\u4f18\u5316\u548c\u826f\u597d\u91cd\u5efa\u6027\u80fd\u3002"}}
{"id": "2508.05660", "pdf": "https://arxiv.org/pdf/2508.05660", "abs": "https://arxiv.org/abs/2508.05660", "authors": ["Aditya Nagori", "Ricardo Accorsi Casonatto", "Ayush Gautam", "Abhinav Manikantha Sai Cheruvu", "Rishikesan Kamaleswaran"], "title": "Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "The surge in scientific publications challenges traditional review methods,\ndemanding tools that integrate structured metadata with full-text analysis.\nHybrid Retrieval Augmented Generation (RAG) systems, combining graph queries\nwith vector search offer promise but are typically static, rely on proprietary\ntools, and lack uncertainty estimates. We present an agentic approach that\nencapsulates the hybrid RAG pipeline within an autonomous agent capable of (1)\ndynamically selecting between GraphRAG and VectorRAG for each query, (2)\nadapting instruction-tuned generation in real time to researcher needs, and (3)\nquantifying uncertainty during inference. This dynamic orchestration improves\nrelevance, reduces hallucinations, and promotes reproducibility.\n  Our pipeline ingests bibliometric open-access data from PubMed, arXiv, and\nGoogle Scholar APIs, builds a Neo4j citation-based knowledge graph (KG), and\nembeds full-text PDFs into a FAISS vector store (VS) using the all-MiniLM-L6-v2\nmodel. A Llama-3.3-70B agent selects GraphRAG (translating queries to Cypher\nfor KG) or VectorRAG (combining sparse and dense retrieval with re-ranking).\nInstruction tuning refines domain-specific generation, and bootstrapped\nevaluation yields standard deviation for evaluation metrics.\n  On synthetic benchmarks mimicking real-world queries, the Instruction-Tuned\nAgent with Direct Preference Optimization (DPO) outperforms the baseline,\nachieving a gain of 0.63 in VS Context Recall and a 0.56 gain in overall\nContext Precision. Additional gains include 0.24 in VS Faithfulness, 0.12 in\nboth VS Precision and KG Answer Relevance, 0.11 in overall Faithfulness score,\n0.05 in KG Context Recall, and 0.04 in both VS Answer Relevance and overall\nPrecision. These results highlight the system's improved reasoning over\nheterogeneous sources and establish a scalable framework for autonomous,\nagentic scientific discovery.", "AI": {"tldr": "\u4f20\u7edf\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\u96be\u5e94\u5bf9\u79d1\u5b66\u51fa\u7248\u7269\u6fc0\u589e\uff0c\u672c\u6587\u63d0\u51fa\u4ee3\u7406\u65b9\u6cd5\u5c01\u88c5\u6df7\u5408RAG\u7ba1\u9053\uff0c\u7ecf\u5b9e\u9a8c\u5728\u591a\u6307\u6807\u4e0a\u53d6\u5f97\u589e\u76ca\uff0c\u4e3a\u79d1\u5b66\u53d1\u73b0\u5efa\u7acb\u53ef\u6269\u5c55\u6846\u67b6\u3002", "motivation": "\u4f20\u7edf\u7efc\u8ff0\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u79d1\u5b66\u51fa\u7248\u7269\u6fc0\u589e\uff0c\u73b0\u6709\u6df7\u5408RAG\u7cfb\u7edf\u5b58\u5728\u9759\u6001\u3001\u4f9d\u8d56\u4e13\u6709\u5de5\u5177\u548c\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7b49\u95ee\u9898\u3002", "method": "\u5c06\u6df7\u5408RAG\u7ba1\u9053\u5c01\u88c5\u5728\u81ea\u4e3b\u4ee3\u7406\u4e2d\uff0c\u52a8\u6001\u9009\u62e9GraphRAG\u548cVectorRAG\uff0c\u5b9e\u65f6\u8c03\u6574\u6307\u4ee4\u8c03\u4f18\u751f\u6210\uff0c\u91cf\u5316\u63a8\u7406\u4e0d\u786e\u5b9a\u6027\uff1b\u6444\u5165\u6587\u732e\u6570\u636e\u6784\u5efa\u77e5\u8bc6\u56fe\u548c\u5411\u91cf\u5b58\u50a8\uff0c\u7528Llama - 3.3 - 70B\u4ee3\u7406\u9009\u62e9\u68c0\u7d22\u65b9\u5f0f\uff0c\u6307\u4ee4\u8c03\u4f18\u548c\u81ea\u4e3e\u8bc4\u4f30\u3002", "result": "\u5728\u6a21\u62df\u73b0\u5b9e\u67e5\u8be2\u7684\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6307\u4ee4\u8c03\u4f18\u4ee3\u7406\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5982VS\u4e0a\u4e0b\u6587\u53ec\u56de\u7387\u63d0\u53470.63\uff0c\u6574\u4f53\u4e0a\u4e0b\u6587\u7cbe\u5ea6\u63d0\u53470.56\u7b49\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u63d0\u9ad8\u4e86\u5bf9\u5f02\u6784\u6e90\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u81ea\u4e3b\u7684\u79d1\u5b66\u53d1\u73b0\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u6846\u67b6\u3002"}}
{"id": "2508.06192", "pdf": "https://arxiv.org/pdf/2508.06192", "abs": "https://arxiv.org/abs/2508.06192", "authors": ["Lantian Li", "Yuyu Chen", "Jingwen Wu", "Yue Pan", "Zhongxing Yu"], "title": "Understanding Inconsistent State Update Vulnerabilities in Smart Contracts", "categories": ["cs.SE"], "comment": "31 pages, 11 figures", "summary": "Smart contracts enable contract terms to be automatically executed and\nverified on the blockchain, and recent years have witnessed numerous\napplications of them in areas such as financial institutions and supply chains.\nThe execution logic of a smart contract is closely related to the contract\nstate, and thus the correct and safe execution of the contract depends heavily\non the precise control and update of the contract state. However, the contract\nstate update process can have issues. In particular, inconsistent state update\nissues can arise for reasons such as unsynchronized modifications. Inconsistent\nstate update bugs have been exploited by attackers many times, but existing\ndetection tools still have difficulty in effectively identifying them. This\npaper conducts the first large-scale empirical study about inconsistent state\nupdate vulnerabilities (that is, inconsistent state update bugs that are\nexploitable) in smart contracts, aiming to shed light for developers,\nresearchers, tool builders, and language or library designers in order to avoid\ninconsistent state update vulnerabilities. We systematically investigate 116\ninconsistent state update vulnerabilities in 352 real-world smart contract\nprojects, summarizing their root causes, fix strategies, and exploitation\nmethods. Our study provides 11 original and important findings, and we also\ngive the implications of our findings. To illustrate the potential benefits of\nour research, we also develop a proof-of-concept checker based on one of our\nfindings. The checker effectively detects issues in 64 popular GitHub projects,\nand 19 project owners have confirmed the detected issues at the time of\nwriting. The result demonstrates the usefulness and importance of our findings\nfor avoiding inconsistent state update vulnerabilities in smart contracts.", "AI": {"tldr": "\u672c\u6587\u5bf9\u667a\u80fd\u5408\u7ea6\u4e2d\u4e0d\u4e00\u81f4\u72b6\u6001\u66f4\u65b0\u6f0f\u6d1e\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u603b\u7ed3\u76f8\u5173\u539f\u56e0\u3001\u4fee\u590d\u7b56\u7565\u548c\u5229\u7528\u65b9\u6cd5\uff0c\u670911\u9879\u91cd\u8981\u53d1\u73b0\uff0c\u5f00\u53d1\u6982\u5ff5\u9a8c\u8bc1\u68c0\u67e5\u5668\u5e76\u9a8c\u8bc1\u4e86\u7ed3\u679c\u6709\u6548\u6027\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u72b6\u6001\u66f4\u65b0\u8fc7\u7a0b\u5b58\u5728\u95ee\u9898\uff0c\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u4e0d\u4e00\u81f4\u72b6\u6001\u66f4\u65b0\u6f0f\u6d1e\uff0c\u65e8\u5728\u4e3a\u5f00\u53d1\u8005\u7b49\u63d0\u4f9b\u53c2\u8003\u4ee5\u907f\u514d\u6b64\u7c7b\u6f0f\u6d1e\u3002", "method": "\u7cfb\u7edf\u8c03\u67e5352\u4e2a\u771f\u5b9e\u667a\u80fd\u5408\u7ea6\u9879\u76ee\u4e2d\u7684116\u4e2a\u4e0d\u4e00\u81f4\u72b6\u6001\u66f4\u65b0\u6f0f\u6d1e\uff0c\u603b\u7ed3\u5176\u6839\u672c\u539f\u56e0\u3001\u4fee\u590d\u7b56\u7565\u548c\u5229\u7528\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u5f97\u51fa11\u9879\u539f\u521b\u4e14\u91cd\u8981\u7684\u53d1\u73b0\uff0c\u5f00\u53d1\u7684\u6982\u5ff5\u9a8c\u8bc1\u68c0\u67e5\u5668\u572864\u4e2a\u70ed\u95e8GitHub\u9879\u76ee\u4e2d\u6709\u6548\u68c0\u6d4b\u51fa\u95ee\u9898\uff0c19\u4e2a\u9879\u76ee\u6240\u6709\u8005\u5df2\u786e\u8ba4\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u4e8e\u907f\u514d\u667a\u80fd\u5408\u7ea6\u4e2d\u4e0d\u4e00\u81f4\u72b6\u6001\u66f4\u65b0\u6f0f\u6d1e\u5177\u6709\u5b9e\u7528\u6027\u548c\u91cd\u8981\u6027\u3002"}}
{"id": "2508.05915", "pdf": "https://arxiv.org/pdf/2508.05915", "abs": "https://arxiv.org/abs/2508.05915", "authors": ["Alex Glushkovsky"], "title": "Dual Signal Decomposition of Stochastic Time Series", "categories": ["cs.LG", "62M10"], "comment": "21 pages, 9 figures, 1 table", "summary": "The research paper addresses decomposition of a stochastic time series into\nthree time series representing a dual signal i.e., the mean and the dispersion,\nwith noise isolated. Decomposition is done by applying machine learning to fit\na dual signal. Machine learning minimizes the loss function which compromises\nbetween fitting the original time series and penalizing irregularities of the\ndual signal. The latter includes terms based on the first and second order\nderivatives along time. To preserve special patterns, weighting of the\nregularization components of the loss function has been introduced based on\nStatistical Process Control methodology. The proposed decomposition can be\napplied as a smoothing algorithm against the mean and dispersion of the time\nseries. By isolating noise, the proposed decomposition can be seen as a\ndenoising algorithm. Two approaches of the learning process have been\nconsidered: sequential and jointly. The former approach learns the mean signal\nfirst and then dispersion. The latter approach fits the dual signal jointly.\nJointly learning can uncover complex relationships for the time series with\nheteroskedasticity. Learning has been set by solving the direct non-linear\nunconstrained optimization problem or by applying neural networks that have\nsequential or twin output architectures. Tuning of the loss function\nhyperparameters focuses on the isolated noise to be a stationary stochastic\nprocess without autocorrelation properties. Depending on the applications, the\nhyperparameters of the learning can be tuned towards either the discrete states\nby stepped signal or smoothed series. The decomposed dual signal can be\nrepresented on the 2D space and used to learn inherent structures, to forecast\nboth mean and dispersion, or to analyze cross effects in case of multiple time\nseries.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u968f\u673a\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5747\u503c\u3001\u79bb\u6563\u5ea6\u4fe1\u53f7\u548c\u566a\u58f0\uff0c\u91c7\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u987a\u5e8f\u548c\u8054\u5408\u4e24\u79cd\u5b66\u4e60\u65b9\u5f0f\uff0c\u53ef\u7528\u4e8e\u5e73\u6ed1\u3001\u53bb\u566a\u7b49\u3002", "motivation": "\u5c06\u968f\u673a\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u4ee3\u8868\u5747\u503c\u548c\u79bb\u6563\u5ea6\u7684\u53cc\u4fe1\u53f7\u5e76\u5206\u79bb\u566a\u58f0\u3002", "method": "\u5e94\u7528\u673a\u5668\u5b66\u4e60\u62df\u5408\u53cc\u4fe1\u53f7\uff0c\u6700\u5c0f\u5316\u635f\u5931\u51fd\u6570\uff0c\u5f15\u5165\u57fa\u4e8e\u7edf\u8ba1\u8fc7\u7a0b\u63a7\u5236\u7684\u6b63\u5219\u5316\u9879\u6743\u91cd\uff0c\u6709\u987a\u5e8f\u548c\u8054\u5408\u4e24\u79cd\u5b66\u4e60\u65b9\u5f0f\uff0c\u901a\u8fc7\u76f4\u63a5\u975e\u7ebf\u6027\u65e0\u7ea6\u675f\u4f18\u5316\u6216\u795e\u7ecf\u7f51\u7edc\u6c42\u89e3\u3002", "result": "\u8054\u5408\u5b66\u4e60\u80fd\u63ed\u793a\u5f02\u65b9\u5dee\u65f6\u95f4\u5e8f\u5217\u7684\u590d\u6742\u5173\u7cfb\uff0c\u53ef\u8c03\u6574\u635f\u5931\u51fd\u6570\u8d85\u53c2\u6570\u4f7f\u566a\u58f0\u5e73\u7a33\u65e0\u81ea\u76f8\u5173\u3002", "conclusion": "\u5206\u89e3\u540e\u7684\u53cc\u4fe1\u53f7\u53ef\u7528\u4e8e\u5b66\u4e60\u5185\u5728\u7ed3\u6784\u3001\u9884\u6d4b\u5747\u503c\u548c\u79bb\u6563\u5ea6\u6216\u5206\u6790\u591a\u65f6\u95f4\u5e8f\u5217\u4ea4\u53c9\u6548\u5e94\u3002"}}
{"id": "2508.06091", "pdf": "https://arxiv.org/pdf/2508.06091", "abs": "https://arxiv.org/abs/2508.06091", "authors": ["Stan P Hauke", "Przemys\u0142aw Andrzej Wa\u0142\u0119ga"], "title": "Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2", "categories": ["cs.AI"], "comment": "18 pages", "summary": "In recent years, there has been growing interest in understanding the\nexpressive power of graph neural networks (GNNs) by relating them to logical\nlanguages. This research has been been initialised by an influential result of\nBarcel\\'o et al. (2020), who showed that the graded modal logic (or a guarded\nfragment of the logic C2), characterises the logical expressiveness of\naggregate-combine GNNs. As a ``challenging open problem'' they left the\nquestion whether full C2 characterises the logical expressiveness of\naggregate-combine-readout GNNs. This question has remained unresolved despite\nseveral attempts. In this paper, we solve the above open problem by proving\nthat the logical expressiveness of aggregate-combine-readout GNNs strictly\nexceeds that of C2. This result holds over both undirected and directed graphs.\nBeyond its implications for GNNs, our work also leads to purely logical\ninsights on the expressive power of infinitary logics.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u805a\u5408 - \u7ec4\u5408 - \u8bfb\u51fa\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u903b\u8f91\u8868\u8fbe\u80fd\u529b\u662f\u5426\u7531\u5b8c\u6574C2\u903b\u8f91\u523b\u753b\u7684\u5f00\u653e\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u8868\u8fbe\u80fd\u529b\u4e25\u683c\u8d85\u8fc7C2\u3002", "motivation": "Barcel\u00f3\u7b49\u4eba\u7559\u4e0b\u4e86\u5b8c\u6574C2\u662f\u5426\u80fd\u523b\u753b\u805a\u5408 - \u7ec4\u5408 - \u8bfb\u51faGNN\u903b\u8f91\u8868\u8fbe\u80fd\u529b\u7684\u5f00\u653e\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u867d\u7ecf\u591a\u6b21\u5c1d\u8bd5\u4ecd\u672a\u89e3\u51b3\uff0c\u8fd9\u4fc3\u4f7f\u4f5c\u8005\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u8bc1\u660e\u5f97\u51fa\u805a\u5408 - \u7ec4\u5408 - \u8bfb\u51faGNN\u7684\u903b\u8f91\u8868\u8fbe\u80fd\u529b\u4e25\u683c\u8d85\u8fc7C2\u7684\u7ed3\u8bba\u3002", "result": "\u805a\u5408 - \u7ec4\u5408 - \u8bfb\u51faGNN\u7684\u903b\u8f91\u8868\u8fbe\u80fd\u529b\u4e25\u683c\u8d85\u8fc7C2\uff0c\u6b64\u7ed3\u679c\u5728\u65e0\u5411\u56fe\u548c\u6709\u5411\u56fe\u4e0a\u5747\u6210\u7acb\u3002", "conclusion": "\u89e3\u51b3\u4e86\u5f00\u653e\u95ee\u9898\uff0c\u9664\u5bf9GNN\u6709\u5f71\u54cd\u5916\uff0c\u8fd8\u5e26\u6765\u4e86\u5173\u4e8e\u65e0\u7a77\u903b\u8f91\u8868\u8fbe\u80fd\u529b\u7684\u7eaf\u903b\u8f91\u89c1\u89e3\u3002"}}
{"id": "2508.06489", "pdf": "https://arxiv.org/pdf/2508.06489", "abs": "https://arxiv.org/abs/2508.06489", "authors": ["Mustafa Doger", "Sennur Ulukus"], "title": "Voting-Based Semi-Parallel Proof-of-Work Protocol", "categories": ["cs.CR", "cs.DC", "cs.DM", "cs.IT", "math.IT", "math.PR"], "comment": null, "summary": "Parallel Proof-of-Work (PoW) protocols are suggested to improve the safety\nguarantees, transaction throughput and confirmation latencies of Nakamoto\nconsensus. In this work, we first consider the existing parallel PoW protocols\nand develop hard-coded incentive attack structures. Our theoretical results and\nsimulations show that the existing parallel PoW protocols are more vulnerable\nto incentive attacks than the Nakamoto consensus, e.g., attacks have smaller\nprofitability threshold and they result in higher relative rewards. Next, we\nintroduce a voting-based semi-parallel PoW protocol that outperforms both\nNakamoto consensus and the existing parallel PoW protocols from most practical\nperspectives such as communication overheads, throughput, transaction\nconflicts, incentive compatibility of the protocol as well as a fair\ndistribution of transaction fees among the voters and the leaders. We use\nstate-of-the-art analysis to evaluate the consistency of the protocol and\nconsider Markov decision process (MDP) models to substantiate our claims about\nthe resilience of our protocol against incentive attacks.", "AI": {"tldr": "\u7814\u7a76\u73b0\u6709\u5e76\u884cPoW\u534f\u8bae\u6613\u53d7\u6fc0\u52b1\u653b\u51fb\u95ee\u9898\uff0c\u63d0\u51fa\u6295\u7968\u5f0f\u534a\u5e76\u884cPoW\u534f\u8bae\u5e76\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "motivation": "\u5e76\u884cPoW\u534f\u8bae\u7528\u4e8e\u6539\u5584\u4e2d\u672c\u806a\u5171\u8bc6\u7684\u5b89\u5168\u6027\u3001\u541e\u5410\u91cf\u548c\u786e\u8ba4\u5ef6\u8fdf\uff0c\u4f46\u9700\u7814\u7a76\u5176\u5b89\u5168\u6027\u548c\u6027\u80fd\u3002", "method": "\u9488\u5bf9\u73b0\u6709\u5e76\u884cPoW\u534f\u8bae\u6784\u5efa\u6fc0\u52b1\u653b\u51fb\u7ed3\u6784\uff0c\u63d0\u51fa\u6295\u7968\u5f0f\u534a\u5e76\u884cPoW\u534f\u8bae\uff0c\u7528\u5148\u8fdb\u5206\u6790\u8bc4\u4f30\u4e00\u81f4\u6027\uff0c\u7528MDP\u6a21\u578b\u8bc1\u660e\u6297\u6fc0\u52b1\u653b\u51fb\u80fd\u529b\u3002", "result": "\u73b0\u6709\u5e76\u884cPoW\u534f\u8bae\u6bd4\u4e2d\u672c\u806a\u5171\u8bc6\u66f4\u6613\u53d7\u6fc0\u52b1\u653b\u51fb\uff1b\u6295\u7968\u5f0f\u534a\u5e76\u884cPoW\u534f\u8bae\u5728\u591a\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u6295\u7968\u5f0f\u534a\u5e76\u884cPoW\u534f\u8bae\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4f18\u4e8e\u4e2d\u672c\u806a\u5171\u8bc6\u548c\u73b0\u6709\u5e76\u884cPoW\u534f\u8bae\u3002"}}
{"id": "2508.05661", "pdf": "https://arxiv.org/pdf/2508.05661", "abs": "https://arxiv.org/abs/2508.05661", "authors": ["Andre Rusli", "Shoma Ishimoto", "Sho Akiyama", "Aman Kumar Singh"], "title": "Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace", "categories": ["cs.IR", "cs.AI"], "comment": "6 pages, KDD 2025 Workshop on Two-sided Marketplace Optimization:\n  Search, Pricing, Matching & Growth (TSMO)", "summary": "Visual search offers an intuitive way for customers to explore diverse\nproduct catalogs, particularly in consumer-to-consumer (C2C) marketplaces where\nlistings are often unstructured and visually driven. This paper presents a\nscalable visual search system deployed in Mercari's C2C marketplace, where\nend-users act as buyers and sellers. We evaluate recent vision-language models\nfor zero-shot image retrieval and compare their performance with an existing\nfine-tuned baseline. The system integrates real-time inference and background\nindexing workflows, supported by a unified embedding pipeline optimized through\ndimensionality reduction. Offline evaluation using user interaction logs shows\nthat the multilingual SigLIP model outperforms other models across multiple\nretrieval metrics, achieving a 13.3% increase in nDCG@5 over the baseline. A\none-week online A/B test in production further confirms real-world impact, with\nthe treatment group showing substantial gains in engagement and conversion, up\nto a 40.9% increase in transaction rate via image search. Our findings\nhighlight that recent zero-shot models can serve as a strong and practical\nbaseline for production use, which enables teams to deploy effective visual\nsearch systems with minimal overhead, while retaining the flexibility to\nfine-tune based on future data or domain-specific needs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdMercari C2C\u5e02\u573a\u7684\u53ef\u6269\u5c55\u89c6\u89c9\u641c\u7d22\u7cfb\u7edf\uff0c\u8bc4\u4f30\u96f6\u6837\u672c\u56fe\u50cf\u68c0\u7d22\u6a21\u578b\uff0c\u79bb\u7ebf\u548c\u5728\u7ebf\u6d4b\u8bd5\u663e\u793a\u591a\u8bed\u8a00SigLIP\u6a21\u578b\u8868\u73b0\u4f73\uff0c\u8868\u660e\u96f6\u6837\u672c\u6a21\u578b\u53ef\u4f5c\u5b9e\u7528\u57fa\u7ebf\u3002", "motivation": "\u5728C2C\u5e02\u573a\u4e2d\u63d0\u4f9b\u76f4\u89c2\u7684\u89c6\u89c9\u641c\u7d22\u65b9\u5f0f\uff0c\u63a2\u7d22\u9002\u7528\u7684\u89c6\u89c9\u641c\u7d22\u7cfb\u7edf\u548c\u6a21\u578b\u3002", "method": "\u8bc4\u4f30\u8fd1\u671f\u7684\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u56fe\u50cf\u68c0\u7d22\uff0c\u5e76\u4e0e\u73b0\u6709\u5fae\u8c03\u57fa\u7ebf\u5bf9\u6bd4\uff1b\u7cfb\u7edf\u96c6\u6210\u5b9e\u65f6\u63a8\u7406\u548c\u540e\u53f0\u7d22\u5f15\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u964d\u7ef4\u4f18\u5316\u7edf\u4e00\u5d4c\u5165\u7ba1\u9053\uff1b\u8fdb\u884c\u79bb\u7ebf\u8bc4\u4f30\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u3002", "result": "\u591a\u8bed\u8a00SigLIP\u6a21\u578b\u5728\u591a\u4e2a\u68c0\u7d22\u6307\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0cnDCG@5\u6bd4\u57fa\u7ebf\u63d0\u9ad813.3%\uff1b\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\u5904\u7406\u7ec4\u5728\u53c2\u4e0e\u5ea6\u548c\u8f6c\u5316\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u56fe\u50cf\u641c\u7d22\u4ea4\u6613\u7387\u6700\u9ad8\u63d0\u534740.9%\u3002", "conclusion": "\u8fd1\u671f\u7684\u96f6\u6837\u672c\u6a21\u578b\u53ef\u4f5c\u4e3a\u751f\u4ea7\u4f7f\u7528\u7684\u5f3a\u5927\u5b9e\u7528\u57fa\u7ebf\uff0c\u80fd\u4ee5\u6700\u5c0f\u5f00\u9500\u90e8\u7f72\u6709\u6548\u89c6\u89c9\u641c\u7d22\u7cfb\u7edf\uff0c\u5e76\u53ef\u6839\u636e\u672a\u6765\u6570\u636e\u6216\u7279\u5b9a\u9886\u57df\u9700\u6c42\u8fdb\u884c\u5fae\u8c03\u3002"}}
{"id": "2508.06299", "pdf": "https://arxiv.org/pdf/2508.06299", "abs": "https://arxiv.org/abs/2508.06299", "authors": ["Henrique Henriques", "Hugo Louren\u00e7o", "Vasco Amaral", "Miguel Goul\u00e3o"], "title": "Improving the Developer Experience with a Low-Code Process Modelling Language", "categories": ["cs.SE"], "comment": "Preprint", "summary": "Context: The OutSystems Platform is a development environment composed of\nseveral DSLs, used to specify, quickly build, and validate web and mobile\napplications. The DSLs allow users to model different perspectives such as\ninterfaces and data models, define custom business logic and construct process\nmodels. Problem: The DSL for process modelling (Business Process Technology\n(BPT)), has a low adoption rate and is perceived as having usability problems\nhampering its adoption. This is problematic given the language maintenance\ncosts. Method: We used a combination of interviews, a critical review of BPT\nusing the \"Physics of Notation\" and empirical evaluations of BPT using the\nSystem Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a\nnew version of BPT, taking these inputs and Outsystems' engineers' culture into\naccount. Results: Evaluations conducted with 25 professional software engineers\nshowed an increase of the semantic transparency on the new version, from 31% to\n69%, an increase in the correctness of responses, from 51% to 89%, an increase\nin the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from\n36.50 to 20.78. These differences were statistically significant. Conclusions:\nThese results suggest that the new version of BPT significantly improved the\ndeveloper experience of the previous version. The end users' background with\nOutSystems had a relevant impact on the final concrete syntax choices and\nachieved usability indicators.", "AI": {"tldr": "\u9488\u5bf9OutSystems\u5e73\u53f0\u4e2dBPT\u91c7\u7528\u7387\u4f4e\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u7ed3\u5408\u591a\u79cd\u65b9\u6cd5\u5f00\u53d1\u65b0\u7248\u672cBPT\uff0c\u8bc4\u4f30\u663e\u793a\u65b0\u7248\u672c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u8005\u4f53\u9a8c\u3002", "motivation": "\u89e3\u51b3OutSystems\u5e73\u53f0\u4e2dBPT\u91c7\u7528\u7387\u4f4e\u548c\u53ef\u7528\u6027\u95ee\u9898\uff0c\u964d\u4f4e\u8bed\u8a00\u7ef4\u62a4\u6210\u672c\u3002", "method": "\u7ed3\u5408\u8bbf\u8c08\u3001\u7528\u2018Physics of Notation\u2019\u8fdb\u884c\u6279\u5224\u6027\u5ba1\u67e5\uff0c\u5e76\u7528SUS\u548cTLX\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u540c\u65f6\u8003\u8651Outsystems\u5de5\u7a0b\u5e08\u6587\u5316\u5f00\u53d1\u65b0\u7248\u672cBPT\u3002", "result": "\u5bf925\u540d\u4e13\u4e1a\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u65b0\u7248\u672c\u8bed\u4e49\u900f\u660e\u5ea6\u3001\u56de\u7b54\u6b63\u786e\u6027\u3001SUS\u5f97\u5206\u63d0\u5347\uff0cTLX\u5f97\u5206\u964d\u4f4e\uff0c\u5dee\u5f02\u6709\u7edf\u8ba1\u5b66\u610f\u4e49\u3002", "conclusion": "\u65b0\u7248\u672cBPT\u663e\u8457\u6539\u5584\u5f00\u53d1\u8005\u4f53\u9a8c\uff0c\u7528\u6237OutSystems\u80cc\u666f\u5f71\u54cd\u6700\u7ec8\u5177\u4f53\u8bed\u6cd5\u9009\u62e9\u548c\u53ef\u7528\u6027\u6307\u6807\u3002"}}
{"id": "2508.05921", "pdf": "https://arxiv.org/pdf/2508.05921", "abs": "https://arxiv.org/abs/2508.05921", "authors": ["Siddharth Rout"], "title": "Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations", "categories": ["cs.LG", "math.FA", "math.RT", "physics.comp-ph"], "comment": null, "summary": "Accuracy in neural PDE solvers often breaks down not because of limited\nexpressivity, but due to poor optimisation caused by ill-conditioning,\nespecially in multi-fidelity and stiff problems. We study this issue in\nPhysics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural\nPDE solvers, and show that asymptotic components in governing equations can\nproduce highly ill-conditioned activation matrices, severely limiting\nconvergence. We introduce Shifted Gaussian Encoding, a simple yet effective\nactivation filtering step that increases matrix rank and expressivity while\npreserving convexity. Our method extends the solvable range of Peclet numbers\nin steady advection-diffusion equations by over two orders of magnitude,\nachieves up to six orders lower error on multi-frequency function learning, and\nfits high-fidelity image vectors more accurately and faster than deep networks\nwith over a million parameters. This work highlights that conditioning, not\ndepth, is often the bottleneck in scientific neural solvers and that simple\narchitectural changes can unlock substantial gains.", "AI": {"tldr": "\u7814\u7a76\u795e\u7ecfPDE\u6c42\u89e3\u5668\u7cbe\u5ea6\u95ee\u9898\uff0c\u63d0\u51faShifted Gaussian Encoding\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\uff0c\u6307\u51fa\u6761\u4ef6\u6570\u800c\u975e\u6df1\u5ea6\u662f\u74f6\u9888\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecfPDE\u6c42\u89e3\u5668\u56e0\u75c5\u6001\u95ee\u9898\u5bfc\u81f4\u7684\u4f18\u5316\u4e0d\u4f73\uff0c\u7cbe\u5ea6\u4e0b\u964d\u95ee\u9898\uff0c\u5c24\u5176\u5728\u591a\u4fdd\u771f\u5ea6\u548c\u521a\u6027\u95ee\u9898\u4e2d\u3002", "method": "\u7814\u7a76PIELMs\uff0c\u5f15\u5165Shifted Gaussian Encoding\u6fc0\u6d3b\u8fc7\u6ee4\u6b65\u9aa4\uff0c\u589e\u52a0\u77e9\u9635\u79e9\u548c\u8868\u8fbe\u80fd\u529b\u5e76\u4fdd\u6301\u51f8\u6027\u3002", "result": "\u5c06\u7a33\u6001\u5bf9\u6d41\u6269\u6563\u65b9\u7a0b\u4e2dPeclet\u6570\u53ef\u89e3\u8303\u56f4\u6269\u5927\u4e24\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff0c\u591a\u9891\u51fd\u6570\u5b66\u4e60\u8bef\u5dee\u964d\u4f4e\u516d\u4e2a\u6570\u91cf\u7ea7\uff0c\u6bd4\u767e\u4e07\u53c2\u6570\u6df1\u5ea6\u7f51\u7edc\u66f4\u51c6\u786e\u5feb\u901f\u62df\u5408\u9ad8\u4fdd\u771f\u56fe\u50cf\u5411\u91cf\u3002", "conclusion": "\u6761\u4ef6\u6570\u800c\u975e\u6df1\u5ea6\u5e38\u662f\u79d1\u5b66\u795e\u7ecf\u6c42\u89e3\u5668\u7684\u74f6\u9888\uff0c\u7b80\u5355\u67b6\u6784\u6539\u53d8\u53ef\u5e26\u6765\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2508.05901", "pdf": "https://arxiv.org/pdf/2508.05901", "abs": "https://arxiv.org/abs/2508.05901", "authors": ["Sourav Chatterjee", "Persi Diaconis", "Susan Holmes"], "title": "Estimating the size of a set using cascading exclusion", "categories": ["math.ST", "cs.IT", "math.IT", "math.PR", "stat.ML", "stat.TH", "62G05, 62G25"], "comment": "46 pages, 10 figures", "summary": "Let $S$ be a finite set, and $X_1,\\ldots,X_n$ an i.i.d. uniform sample from\n$S$. To estimate the size $|S|$, without further structure, one can wait for\nrepeats and use the birthday problem. This requires a sample size of the order\n$|S|^\\frac{1}{2}$. On the other hand, if $S=\\{1,2,\\ldots,|S|\\}$, the maximum of\nthe sample blown up by $n/(n-1)$ gives an efficient estimator based on any\ngrowing sample size. This paper gives refinements that interpolate between\nthese extremes. A general non-asymptotic theory is developed. This includes\nestimating the volume of a compact convex set, the unseen species problem, and\na host of testing problems that follow from the question `Is this new\nobservation a typical pick from a large prespecified population?' We also treat\nregression style predictors. A general theorem gives non-parametric finite $n$\nerror bounds in all cases.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6709\u9650\u96c6\u5927\u5c0f\u4f30\u8ba1\u95ee\u9898\uff0c\u5bf9\u5df2\u6709\u6781\u7aef\u60c5\u51b5\u4f30\u8ba1\u65b9\u6cd5\u8fdb\u884c\u7ec6\u5316\uff0c\u53d1\u5c55\u4e86\u4e00\u822c\u975e\u6e10\u8fd1\u7406\u8bba\uff0c\u6db5\u76d6\u591a\u79cd\u95ee\u9898\u5e76\u7ed9\u51fa\u975e\u53c2\u6570\u6709\u9650n\u8bef\u5dee\u754c\u3002", "motivation": "\u5bf9\u6709\u9650\u96c6\u5927\u5c0f\u4f30\u8ba1\u5728\u4e0d\u540c\u60c5\u51b5\u4e0b\u5df2\u6709\u65b9\u6cd5\u8fdb\u884c\u7ec6\u5316\u548c\u5b8c\u5584\uff0c\u89e3\u51b3\u66f4\u5e7f\u6cdb\u95ee\u9898\u3002", "method": "\u53d1\u5c55\u4e00\u822c\u975e\u6e10\u8fd1\u7406\u8bba\u3002", "result": "\u5f97\u5230\u4e86\u5bf9\u6709\u9650\u96c6\u5927\u5c0f\u4f30\u8ba1\u3001\u4f53\u79ef\u4f30\u8ba1\u3001\u672a\u53d1\u73b0\u7269\u79cd\u95ee\u9898\u7b49\u591a\u79cd\u95ee\u9898\u7684\u5904\u7406\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u975e\u53c2\u6570\u6709\u9650n\u8bef\u5dee\u754c\u3002", "conclusion": "\u63d0\u51fa\u7684\u7406\u8bba\u548c\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u591a\u79cd\u76f8\u5173\u4f30\u8ba1\u548c\u6d4b\u8bd5\u95ee\u9898\uff0c\u7ed9\u51fa\u8bef\u5dee\u754c\u3002"}}
{"id": "2508.06110", "pdf": "https://arxiv.org/pdf/2508.06110", "abs": "https://arxiv.org/abs/2508.06110", "authors": ["Yiran Rex Ma"], "title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion", "categories": ["cs.AI", "cs.MA"], "comment": "Accepted at IJCNN 2025", "summary": "Table reasoning, including tabular QA and fact verification, often depends on\nannotated data or complex data augmentation, limiting flexibility and\ngeneralization. LLMs, despite their versatility, often underperform compared to\nsimple supervised models. To approach these issues, we introduce PanelTR, a\nframework utilizing LLM agent scientists for robust table reasoning through a\nstructured scientific approach. PanelTR's workflow involves agent scientists\nconducting individual investigations, engaging in self-review, and\nparticipating in collaborative peer-review discussions. This process, driven by\nfive scientist personas, enables semantic-level transfer without relying on\ndata augmentation or parametric optimization. Experiments across four\nbenchmarks show that PanelTR outperforms vanilla LLMs and rivals fully\nsupervised models, all while remaining independent of training data. Our\nfindings indicate that structured scientific methodology can effectively handle\ncomplex tasks beyond table reasoning with flexible semantic understanding in a\nzero-shot context.", "AI": {"tldr": "\u63d0\u51faPanelTR\u6846\u67b6\u89e3\u51b3\u8868\u683c\u63a8\u7406\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e14\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u8868\u683c\u63a8\u7406\u4f9d\u8d56\u6807\u6ce8\u6570\u636e\u6216\u590d\u6742\u6570\u636e\u589e\u5f3a\uff0c\u7075\u6d3b\u6027\u548c\u6cdb\u5316\u6027\u53d7\u9650\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u4e0d\u5982\u7b80\u5355\u76d1\u7763\u6a21\u578b\u3002", "method": "\u5f15\u5165PanelTR\u6846\u67b6\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u79d1\u5b66\u5bb6\u4ee5\u7ed3\u6784\u5316\u79d1\u5b66\u65b9\u6cd5\u8fdb\u884c\u8868\u683c\u63a8\u7406\uff0c\u5305\u542b\u4e2a\u4f53\u8c03\u67e5\u3001\u81ea\u6211\u5ba1\u67e5\u548c\u534f\u4f5c\u540c\u884c\u8bc4\u5ba1\u8ba8\u8bba\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPanelTR\u6027\u80fd\u4f18\u4e8e\u666e\u901a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e0e\u5168\u76d1\u7763\u6a21\u578b\u76f8\u5f53\uff0c\u4e14\u4e0d\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u3002", "conclusion": "\u7ed3\u6784\u5316\u79d1\u5b66\u65b9\u6cd5\u80fd\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u4ee5\u7075\u6d3b\u8bed\u4e49\u7406\u89e3\u5904\u7406\u8868\u683c\u63a8\u7406\u5916\u7684\u590d\u6742\u4efb\u52a1\u3002"}}
{"id": "2508.05662", "pdf": "https://arxiv.org/pdf/2508.05662", "abs": "https://arxiv.org/abs/2508.05662", "authors": ["Yuzhou Zhu"], "title": "From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Dynamic streams from news feeds, social media, sensor networks, and financial\nmarkets challenge static RAG frameworks. Full-scale indices incur high memory\ncosts; periodic rebuilds introduce latency that undermines data freshness;\nnaive sampling sacrifices semantic coverage. We present Streaming RAG, a\nunified pipeline that combines multi-vector cosine screening, mini-batch\nclustering, and a counter-based heavy-hitter filter to maintain a compact\nprototype set. We further prove an approximation bound \\$E\\[R(K\\_t)] \\ge R^\\* -\nL \\Delta\\$ linking retrieval quality to clustering variance. An incremental\nindex upsert mechanism refreshes prototypes without interrupting queries.\nExperiments on eight real-time streams show statistically significant gains in\nRecall\\@10 (up to 3 points, p < 0.01), end-to-end latency below 15 ms, and\nthroughput above 900 documents per second under a 150 MB budget. Hyperparameter\nsensitivity analysis over cluster count, admission probability, relevance\nthreshold, and counter capacity validates default settings. In open-domain\nquestion answering with GPT-3.5 Turbo, we record 3.2-point gain in Exact Match\nand 2.8-point gain in F1 on SQuAD; abstractive summarization yields ROUGE-L\nimprovements. Streaming RAG establishes a new Pareto frontier for retrieval\naugmentation.", "AI": {"tldr": "\u63d0\u51faStreaming RAG\u89e3\u51b3\u52a8\u6001\u6d41\u6570\u636e\u5bf9\u9759\u6001RAG\u6846\u67b6\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u663e\u793a\u591a\u65b9\u9762\u6027\u80fd\u63d0\u5347\u5e76\u5efa\u7acb\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "motivation": "\u52a8\u6001\u6d41\u6570\u636e\u5bf9\u9759\u6001RAG\u6846\u67b6\u6784\u6210\u6311\u6218\uff0c\u5982\u5168\u91cf\u7d22\u5f15\u5185\u5b58\u6210\u672c\u9ad8\u3001\u5468\u671f\u6027\u91cd\u5efa\u6709\u5ef6\u8fdf\u3001\u7b80\u5355\u91c7\u6837\u727a\u7272\u8bed\u4e49\u8986\u76d6\u3002", "method": "\u63d0\u51faStreaming RAG\u7edf\u4e00\u7ba1\u9053\uff0c\u7ed3\u5408\u591a\u5411\u91cf\u4f59\u5f26\u7b5b\u9009\u3001\u5c0f\u6279\u91cf\u805a\u7c7b\u548c\u57fa\u4e8e\u8ba1\u6570\u5668\u7684\u91cd\u51fb\u4e2d\u8fc7\u6ee4\u5668\uff0c\u7ef4\u62a4\u7d27\u51d1\u539f\u578b\u96c6\uff0c\u8fd8\u6709\u589e\u91cf\u7d22\u5f15\u66f4\u65b0\u673a\u5236\uff0c\u8bc1\u660e\u8fd1\u4f3c\u8fb9\u754c\u3002", "result": "\u5728\u516b\u4e2a\u5b9e\u65f6\u6d41\u5b9e\u9a8c\u4e2dRecall@10\u63d0\u5347\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u4f4e\u3001\u541e\u5410\u91cf\u9ad8\uff1b\u5728\u5f00\u653e\u57df\u95ee\u7b54\u548c\u6458\u8981\u4efb\u52a1\u4e2d\u6709\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "Streaming RAG\u4e3a\u68c0\u7d22\u589e\u5f3a\u5efa\u7acb\u4e86\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002"}}
{"id": "2508.06365", "pdf": "https://arxiv.org/pdf/2508.06365", "abs": "https://arxiv.org/abs/2508.06365", "authors": ["Toufique Ahmed", "Jatin Ganhotra", "Avraham Shinnar", "Martin Hirzel"], "title": "Execution-Feedback Driven Test Generation from SWE Issues", "categories": ["cs.SE"], "comment": null, "summary": "A software engineering issue (SWE issue) is easier to resolve when\naccompanied by a reproduction test. Unfortunately, most issues do not come with\nfunctioning reproduction tests, so this paper explores how to generate them\nautomatically. The primary challenge in this setting is that the code to be\ntested is either missing or wrong, as evidenced by the existence of the issue\nin the first place. This has held back test generation for this setting:\nwithout the correct code to execute, it is difficult to leverage execution\nfeedback to generate good tests. This paper introduces novel techniques for\nleveraging execution feedback to get around this problem, implemented in a new\nreproduction test generator called e-Otter++. Experiments show that e-Otter++\nrepresents a leap ahead in the state-of-the-art for this problem, generating\ntests with an average fail-to-pass rate of 63% on the TDD-Bench Verified\nbenchmark.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u81ea\u52a8\u751f\u6210\u8f6f\u4ef6\u95ee\u9898\u91cd\u73b0\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u65b0\u6280\u5de7\u5e76\u5b9e\u73b0e - Otter++\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u591a\u6570\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u65e0\u53ef\u7528\u91cd\u73b0\u6d4b\u8bd5\uff0c\u9700\u81ea\u52a8\u751f\u6210\u3002", "method": "\u4ecb\u7ecd\u5229\u7528\u6267\u884c\u53cd\u9988\u89e3\u51b3\u4ee3\u7801\u7f3a\u5931\u6216\u9519\u8bef\u95ee\u9898\u7684\u65b0\u6280\u5de7\uff0c\u5b9e\u73b0\u91cd\u73b0\u6d4b\u8bd5\u751f\u6210\u5668e - Otter++\u3002", "result": "e - Otter++\u5728TDD - Bench Verified\u57fa\u51c6\u4e0a\u751f\u6210\u6d4b\u8bd5\u7684\u5e73\u5747\u5931\u8d25\u8f6c\u901a\u8fc7\u7387\u8fbe63%\u3002", "conclusion": "e - Otter++\u5728\u81ea\u52a8\u751f\u6210\u8f6f\u4ef6\u95ee\u9898\u91cd\u73b0\u6d4b\u8bd5\u65b9\u9762\u9886\u5148\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2508.05928", "pdf": "https://arxiv.org/pdf/2508.05928", "abs": "https://arxiv.org/abs/2508.05928", "authors": ["Si Shen", "Peijun Shen", "Wenhua Zhao", "Danhao Zhu"], "title": "Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting", "categories": ["cs.LG"], "comment": null, "summary": "Group-Relative Policy Optimization (GRPO) is a key technique for training\nlarge reasoning models, yet it suffers from a critical vulnerability: the\n\\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning\nprocess. This problem is most severe in unbalanced response groups,\nparadoxically degrading the signal precisely when it should be most\ninformative. To address this challenge, we propose Stable Group-Relative Policy\nOptimization (S-GRPO), a principled enhancement that derives optimal,\nnoise-aware advantage weights to stabilize training. Our comprehensive\nexperiments on mathematical reasoning benchmarks demonstrate S-GRPO's\neffectiveness and robustness. On various models, S-GRPO significantly\noutperforms DR. GRPO, achieving performance gains of +2.5% on\nQwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on\nQwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn\nunder 20% synthetic reward noise, S-GRPO maintains stable learning progress.\nThese results highlight S-GRPO's potential for more robust and effective\ntraining of large-scale reasoning models. \\footnote{Code and data are available\nat: https://github.com/shenpeijun0212/S-GRPO", "AI": {"tldr": "\u73b0\u6709GRPO\u6280\u672f\u5b58\u5728Think - Answer Mismatch\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faS - GRPO\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6709\u6548\u4e14\u9c81\u68d2\u3002", "motivation": "GRPO\u6280\u672f\u5b58\u5728Think - Answer Mismatch\u95ee\u9898\uff0c\u5728\u4e0d\u5e73\u8861\u54cd\u5e94\u7ec4\u4e2d\u95ee\u9898\u4e25\u91cd\uff0c\u5f71\u54cd\u5b66\u4e60\u8fc7\u7a0b\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faStable Group - Relative Policy Optimization (S - GRPO)\uff0c\u63a8\u5bfc\u6700\u4f18\u3001\u8003\u8651\u566a\u58f0\u7684\u4f18\u52bf\u6743\u91cd\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cS - GRPO\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u663e\u8457\u4f18\u4e8eDR. GRPO\uff0c\u5982\u5728Qwen - Math - 7B - Base\u7b49\u6a21\u578b\u4e0a\u6709\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u572820%\u5408\u6210\u5956\u52b1\u566a\u58f0\u4e0b\u80fd\u4fdd\u6301\u7a33\u5b9a\u5b66\u4e60\u3002", "conclusion": "S - GRPO\u5728\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u4e2d\u5177\u6709\u66f4\u5f3a\u5927\u548c\u6709\u6548\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.06087", "pdf": "https://arxiv.org/pdf/2508.06087", "abs": "https://arxiv.org/abs/2508.06087", "authors": ["Zhihao Yao", "Yuxuan Gu", "Xiachong Feng", "Weitao Ma", "Bo Li", "Xiaocheng Feng"], "title": "Adaptive Backtracking for Privacy Protection in Large Language Models", "categories": ["cs.CR", "cs.LG", "stat.ML"], "comment": null, "summary": "The preservation of privacy has emerged as a critical topic in the era of\nartificial intelligence. However, current work focuses on user-oriented\nprivacy, overlooking severe enterprise data leakage risks exacerbated by the\nRetrieval-Augmented Generation paradigm. To address this gap, our paper\nintroduces a novel objective: enterprise-oriented privacy concerns. Achieving\nthis objective requires overcoming two fundamental challenges: existing methods\nsuch as data sanitization severely degrade model performance, and the field\nlacks public datasets for evaluation. We address these challenges with several\nsolutions. (1) To prevent performance degradation, we propose ABack, a\ntraining-free mechanism that leverages a Hidden State Model to pinpoint the\norigin of a leakage intention and rewrite the output safely. (2) To solve the\nlack of datasets, we construct PriGenQA, a new benchmark for enterprise privacy\nscenarios in healthcare and finance. To ensure a rigorous evaluation, we move\nbeyond simple static attacks by developing a powerful adaptive attacker with\nGroup Relative Policy Optimization. Experiments show that against this superior\nadversary, ABack improves the overall privacy utility score by up to 15\\% over\nstrong baselines, avoiding the performance trade-offs of prior methods.", "AI": {"tldr": "\u6587\u7ae0\u5173\u6ce8\u4f01\u4e1a\u6570\u636e\u9690\u79c1\u4fdd\u62a4\uff0c\u63d0\u51faABack\u673a\u5236\u548cPriGenQA\u57fa\u51c6\uff0c\u5b9e\u9a8c\u8868\u660eABack\u80fd\u63d0\u5347\u9690\u79c1\u6548\u7528\u5f97\u5206\u3002", "motivation": "\u5f53\u524d\u5de5\u4f5c\u805a\u7126\u7528\u6237\u9690\u79c1\uff0c\u5ffd\u89c6\u4f01\u4e1a\u6570\u636e\u6cc4\u6f0f\u98ce\u9669\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u95ee\u9898\u548c\u7f3a\u4e4f\u8bc4\u4f30\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u65e0\u8bad\u7ec3\u673a\u5236ABack\uff0c\u5229\u7528\u9690\u85cf\u72b6\u6001\u6a21\u578b\u5b9a\u4f4d\u6cc4\u6f0f\u610f\u56fe\u5e76\u6539\u5199\u8f93\u51fa\uff1b\u6784\u5efaPriGenQA\u57fa\u51c6\uff1b\u5f00\u53d1\u5f3a\u5927\u7684\u81ea\u9002\u5e94\u653b\u51fb\u8005\u3002", "result": "\u5728\u5bf9\u6297\u9ad8\u7ea7\u5bf9\u624b\u65f6\uff0cABack\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u9ad8\u6574\u4f53\u9690\u79c1\u6548\u7528\u5f97\u5206\u8fbe15%\uff0c\u907f\u514d\u4e86\u5148\u524d\u65b9\u6cd5\u7684\u6027\u80fd\u6743\u8861\u3002", "conclusion": "ABack\u673a\u5236\u548cPriGenQA\u57fa\u51c6\u80fd\u6709\u6548\u89e3\u51b3\u4f01\u4e1a\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u3002"}}
{"id": "2508.06111", "pdf": "https://arxiv.org/pdf/2508.06111", "abs": "https://arxiv.org/abs/2508.06111", "authors": ["Dewi S. W. Gould", "Bruno Mlodozeniec", "Samuel F. Brown"], "title": "SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges", "categories": ["cs.AI"], "comment": "7 pages and appendices", "summary": "Evaluating the capabilities and risks of foundation models is paramount, yet\ncurrent methods demand extensive domain expertise, hindering their scalability\nas these models rapidly evolve. We introduce SKATE: a novel evaluation\nframework in which large language models (LLMs) compete by generating and\nsolving verifiable tasks for one another. Our core insight is to treat\nevaluation as a game: models act as both task-setters and solvers, incentivized\nto create questions which highlight their own strengths while exposing others'\nweaknesses. SKATE offers several key advantages, balancing scalability,\nopen-endedness, and objectivity. It is fully automated, data-free, and\nscalable, requiring no human input or domain expertise. By using verifiable\ntasks rather than LLM judges, scoring is objective. Unlike domain-limited\nprogrammatically-generated benchmarks (e.g. chess-playing or spatial\nreasoning), having LLMs creatively pose challenges enables open-ended and\nscalable evaluation. As a proof of concept, we introduce LLM-set\ncode-output-prediction (COP) challenges as a verifiable and extensible\nframework in which to test our approach. Using a TrueSkill-based ranking\nsystem, we evaluate six frontier LLMs and find that: (1) weaker models can\nreliably differentiate and score stronger ones, (2) LLM-based systems are\ncapable of self-preferencing behavior, generating questions that align with\ntheir own capabilities, and (3) SKATE automatically surfaces fine-grained\ncapability differences between models. Our findings are an important step\ntowards general, scalable evaluation frameworks which can keep pace with LLM\nprogress.", "AI": {"tldr": "\u63d0\u51faSKATE\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u4e92\u751f\u6210\u548c\u89e3\u51b3\u53ef\u9a8c\u8bc1\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff0c\u901a\u8fc7\u4ee3\u7801\u8f93\u51fa\u9884\u6d4b\u6311\u6218\u9a8c\u8bc1\uff0c\u8bc4\u4f30\u516d\u4e2a\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e3a\u901a\u7528\u53ef\u6269\u5c55\u8bc4\u4f30\u6846\u67b6\u8fc8\u8fdb\u91cd\u8981\u4e00\u6b65\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u80fd\u529b\u548c\u98ce\u9669\u7684\u65b9\u6cd5\u9700\u5927\u91cf\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u96be\u4ee5\u968f\u6a21\u578b\u5feb\u901f\u53d1\u5c55\u6269\u5c55\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165SKATE\u8bc4\u4f30\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4efb\u52a1\u8bbe\u5b9a\u8005\u548c\u89e3\u51b3\u8005\uff0c\u4f7f\u7528\u53ef\u9a8c\u8bc1\u4efb\u52a1\uff0c\u91c7\u7528TrueSkill\u6392\u540d\u7cfb\u7edf\u3002", "result": "\u8f83\u5f31\u6a21\u578b\u80fd\u53ef\u9760\u533a\u5206\u548c\u8bc4\u5206\u8f83\u5f3a\u6a21\u578b\uff1b\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\u6709\u81ea\u6211\u504f\u597d\u884c\u4e3a\uff1bSKATE\u80fd\u81ea\u52a8\u53d1\u73b0\u6a21\u578b\u95f4\u7ec6\u7c92\u5ea6\u80fd\u529b\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u662f\u8fc8\u5411\u80fd\u8ddf\u4e0a\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u7684\u901a\u7528\u53ef\u6269\u5c55\u8bc4\u4f30\u6846\u67b6\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.05664", "pdf": "https://arxiv.org/pdf/2508.05664", "abs": "https://arxiv.org/abs/2508.05664", "authors": ["Hei Yu Chan", "Kuok Tou Ho", "Chenglong Ma", "Yujing Si", "Hok Lai Lin", "Sa Lei Lam"], "title": "Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support", "categories": ["cs.IR", "cs.AI", "cs.CL", "I.2.m"], "comment": "6 pages", "summary": "Many AI customer service systems use standard NLP pipelines or finetuned\nlanguage models, which often fall short on ambiguous, multi-intent, or\ndetail-specific queries. This case study evaluates recent techniques: query\nrewriting, RAG Fusion, keyword augmentation, intent recognition, and context\nreranking, for building a robust customer support system in the electric power\ndomain. We compare vector-store and graph-based RAG frameworks, ultimately\nselecting the graph-based RAG for its superior performance in handling complex\nqueries. We find that query rewriting improves retrieval for queries using\nnon-standard terminology or requiring precise detail. RAG Fusion boosts\nperformance on vague or multifaceted queries by merging multiple retrievals.\nReranking reduces hallucinations by filtering irrelevant contexts. Intent\nrecognition supports the decomposition of complex questions into more targeted\nsub-queries, increasing both relevance and efficiency. In contrast, keyword\naugmentation negatively impacts results due to biased keyword selection. Our\nfinal system combines intent recognition, RAG Fusion, and reranking to handle\ndisambiguation and multi-source queries. Evaluated on both a GPT-4-generated\ndataset and a real-world electricity provider FAQ dataset, it achieves 97.9%\nand 89.6% accuracy respectively, substantially outperforming baseline RAG\nmodels.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u591a\u79cd\u6280\u672f\u6784\u5efa\u7535\u529b\u9886\u57df\u5ba2\u670d\u7cfb\u7edf\uff0c\u9009\u56fe\u57faRAG\u6846\u67b6\uff0c\u7ed3\u5408\u90e8\u5206\u6280\u672f\u6784\u5efa\u6700\u7ec8\u7cfb\u7edf\uff0c\u51c6\u786e\u7387\u8d85\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709AI\u5ba2\u670d\u7cfb\u7edf\u5904\u7406\u6a21\u7cca\u3001\u591a\u610f\u56fe\u6216\u7279\u5b9a\u7ec6\u8282\u67e5\u8be2\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u6784\u5efa\u7535\u529b\u9886\u57df\u5f3a\u5927\u5ba2\u670d\u7cfb\u7edf\u3002", "method": "\u8bc4\u4f30\u67e5\u8be2\u91cd\u5199\u3001RAG\u878d\u5408\u3001\u5173\u952e\u8bcd\u589e\u5f3a\u3001\u610f\u56fe\u8bc6\u522b\u548c\u4e0a\u4e0b\u6587\u91cd\u6392\u5e8f\u7b49\u6280\u672f\uff0c\u6bd4\u8f83\u5411\u91cf\u5b58\u50a8\u548c\u56fe\u57faRAG\u6846\u67b6\uff0c\u7ed3\u5408\u610f\u56fe\u8bc6\u522b\u3001RAG\u878d\u5408\u548c\u91cd\u6392\u5e8f\u6784\u5efa\u6700\u7ec8\u7cfb\u7edf\u3002", "result": "\u56fe\u57faRAG\u5904\u7406\u590d\u6742\u67e5\u8be2\u6027\u80fd\u4f18\uff1b\u67e5\u8be2\u91cd\u5199\u3001RAG\u878d\u5408\u3001\u91cd\u6392\u5e8f\u548c\u610f\u56fe\u8bc6\u522b\u6709\u79ef\u6781\u6548\u679c\uff0c\u5173\u952e\u8bcd\u589e\u5f3a\u6709\u8d1f\u9762\u5f71\u54cd\uff1b\u6700\u7ec8\u7cfb\u7edf\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u5206\u522b\u8fbe97.9%\u548c89.6%\u3002", "conclusion": "\u7ed3\u5408\u610f\u56fe\u8bc6\u522b\u3001RAG\u878d\u5408\u548c\u91cd\u6392\u5e8f\u7684\u6700\u7ec8\u7cfb\u7edf\u80fd\u6709\u6548\u5904\u7406\u6d88\u6b67\u548c\u591a\u6e90\u67e5\u8be2\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfRAG\u6a21\u578b\u3002"}}
{"id": "2508.06414", "pdf": "https://arxiv.org/pdf/2508.06414", "abs": "https://arxiv.org/abs/2508.06414", "authors": ["Dongze Li", "Songqiang Chen", "Jialun Cao", "Shing-Chi Cheung"], "title": "What Builds Effective In-Context Examples for Code Generation?", "categories": ["cs.SE"], "comment": null, "summary": "In-Context Learning (ICL) has emerged as a promising solution to enhance the\ncode generation capabilities of Large Language Models (LLMs), which\nincorporates code examples inside the prompt to let LLMs learn from\ndemonstrations. However, despite the substantial effectiveness of the code\nexample-based ICL approach, the specific features (e.g., identifier naming\nstyles, code formatting, solution insight) within the ICL-provided code\nexamples that significantly contribute to the ICL's effectiveness remain\nunclear. This paper systematically investigates the impact of various code\nfeatures on ICL with code examples through controlled ablation studies. Our\nfindings reveal that the appropriate naming of variables and functions is\ncrucial for effective code generation, with their elimination leading to\nperformance decreases of up to 30 percentage points. We further demonstrate\nthat LLMs prioritize semantically meaningful identifier names over formatting\nconventions, with language-specific preferences regarding identifier verbosity.\nAdditionally, our investigation into ICL's potential for enhancing reflection\nand inference capabilities reveals that current LLMs struggle to extract\ngeneralizable problem-solving insights from similar code solutions, despite\nbeing capable of utilizing direct information effectively. These findings are\nexpected to provide valuable insights for optimizing ICL systems in code\ngeneration applications and highlight fundamental challenges in\nreflection-based learning for code generation tasks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9\u7167\u6d88\u878d\u5b9e\u9a8c\u7814\u7a76\u4e0d\u540c\u4ee3\u7801\u7279\u5f81\u5bf9\u57fa\u4e8e\u4ee3\u7801\u793a\u4f8b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53d8\u91cf\u548c\u51fd\u6570\u7684\u6070\u5f53\u547d\u540d\u5bf9\u4ee3\u7801\u751f\u6210\u5f88\u5173\u952e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u770b\u91cd\u6807\u8bc6\u7b26\u8bed\u4e49\u800c\u975e\u683c\u5f0f\uff0c\u4e14\u5f53\u524d\u5927\u6a21\u578b\u5728\u4ece\u4ee3\u7801\u4e2d\u63d0\u53d6\u901a\u7528\u89e3\u9898\u601d\u8def\u65b9\u9762\u6709\u56f0\u96be\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u4ee3\u7801\u793a\u4f8b\u7684ICL\u65b9\u6cd5\u867d\u6709\u6548\uff0c\u4f46\u5176\u4e2d\u54ea\u4e9b\u4ee3\u7801\u7279\u5f81\u5bf9ICL\u6709\u6548\u6027\u6709\u663e\u8457\u8d21\u732e\u5c1a\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5bf9\u7167\u6d88\u878d\u5b9e\u9a8c\u7cfb\u7edf\u7814\u7a76\u5404\u79cd\u4ee3\u7801\u7279\u5f81\u5bf9\u57fa\u4e8e\u4ee3\u7801\u793a\u4f8b\u7684ICL\u7684\u5f71\u54cd\u3002", "result": "\u53d8\u91cf\u548c\u51fd\u6570\u7684\u6070\u5f53\u547d\u540d\u5bf9\u6709\u6548\u4ee3\u7801\u751f\u6210\u81f3\u5173\u91cd\u8981\uff0c\u53bb\u9664\u5b83\u4eec\u4f1a\u4f7f\u6027\u80fd\u4e0b\u964d\u8fbe30\u4e2a\u767e\u5206\u70b9\uff1b\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u4f18\u5148\u8003\u8651\u8bed\u4e49\u6709\u610f\u4e49\u7684\u6807\u8bc6\u7b26\u540d\u79f0\u800c\u975e\u683c\u5f0f\u7ea6\u5b9a\uff0c\u4e14\u5bf9\u6807\u8bc6\u7b26\u5197\u957f\u7a0b\u5ea6\u6709\u7279\u5b9a\u8bed\u8a00\u504f\u597d\uff1b\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u6709\u6548\u5229\u7528\u76f4\u63a5\u4fe1\u606f\uff0c\u4f46\u96be\u4ee5\u4ece\u76f8\u4f3c\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\u4e2d\u63d0\u53d6\u901a\u7528\u89e3\u9898\u601d\u8def\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u4f18\u5316\u4ee3\u7801\u751f\u6210\u5e94\u7528\u4e2d\u7684ICL\u7cfb\u7edf\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u540c\u65f6\u51f8\u663e\u4e86\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u57fa\u4e8e\u53cd\u601d\u7684\u5b66\u4e60\u9762\u4e34\u7684\u6839\u672c\u6311\u6218\u3002"}}
{"id": "2508.05957", "pdf": "https://arxiv.org/pdf/2508.05957", "abs": "https://arxiv.org/abs/2508.05957", "authors": ["Hasibul Karim Shanto", "Umme Ayman Koana", "Shadikur Rahman"], "title": "Multi-Armed Bandits-Based Optimization of Decision Trees", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Decision trees, without appropriate constraints, can easily become overly\ncomplex and prone to overfit, capturing noise rather than generalizable\npatterns. To resolve this problem,pruning operation is a crucial part in\noptimizing decision trees, as it not only reduces the complexity of trees but\nalso decreases the probability of generating overfit models. The conventional\npruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning\n(REP) are mostly based on greedy approaches that focus on immediate gains in\nperformance while pruning nodes of the decision tree. However, this might\nresult in a lower generalization in the long run, compromising the robust\nability of the tree model when introduced to unseen data samples, particularly\nwhen trained with small and complex datasets. To address this challenge, we are\nproposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement\nlearning (RL)-based technique, that will dynamically prune the tree to generate\nan optimal decision tree with better generalization. Our proposed approach\nassumes the pruning process as an exploration-exploitation problem, where we\nare utilizing the MAB algorithms to find optimal branch nodes to prune based on\nfeedback from each pruning actions. Experimental evaluation on several\nbenchmark datasets, demonstrated that our proposed approach results in better\npredictive performance compared to the traditional ones. This suggests the\npotential of utilizing MAB for a dynamic and probabilistic way of decision tree\npruning, in turn optimizing the decision tree-based model.", "AI": {"tldr": "\u4f20\u7edf\u51b3\u7b56\u6811\u526a\u679d\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\uff08MAB\uff09\u7684\u526a\u679d\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u9884\u6d4b\u6027\u80fd\u66f4\u597d\u3002", "motivation": "\u4f20\u7edf\u51b3\u7b56\u6811\u6613\u8fc7\u62df\u5408\uff0c\u4f20\u7edf\u526a\u679d\u65b9\u6cd5\u57fa\u4e8e\u8d2a\u5fc3\u7b56\u7565\uff0c\u957f\u671f\u6cdb\u5316\u6027\u4e0d\u4f73\uff0c\u5c24\u5176\u662f\u5904\u7406\u5c0f\u800c\u590d\u6742\u6570\u636e\u96c6\u65f6\u3002", "method": "\u5c06\u526a\u679d\u8fc7\u7a0b\u89c6\u4e3a\u63a2\u7d22 - \u5229\u7528\u95ee\u9898\uff0c\u4f7f\u7528MAB\u7b97\u6cd5\u6839\u636e\u6bcf\u6b21\u526a\u679d\u52a8\u4f5c\u7684\u53cd\u9988\u627e\u5230\u6700\u4f18\u5206\u652f\u8282\u70b9\u8fdb\u884c\u526a\u679d\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6709\u66f4\u597d\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "\u5229\u7528MAB\u8fdb\u884c\u52a8\u6001\u548c\u6982\u7387\u6027\u7684\u51b3\u7b56\u6811\u526a\u679d\u6709\u6f5c\u529b\u4f18\u5316\u57fa\u4e8e\u51b3\u7b56\u6811\u7684\u6a21\u578b\u3002"}}
{"id": "2508.06126", "pdf": "https://arxiv.org/pdf/2508.06126", "abs": "https://arxiv.org/abs/2508.06126", "authors": ["Jixuan Yin", "Zhihao Yao", "Wenshuai Huo", "Xinmiao Yu", "Xiaocheng Feng", "Bo Li"], "title": "IOCC: Aligning Semantic and Cluster Centers for Few-shot Short Text Clustering", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "In clustering tasks, it is essential to structure the feature space into\nclear, well-separated distributions. However, because short text\nrepresentations have limited expressiveness, conventional methods struggle to\nidentify cluster centers that truly capture each category's underlying\nsemantics, causing the representations to be optimized in suboptimal\ndirections. To address this issue, we propose IOCC, a novel few-shot\ncontrastive learning method that achieves alignment between the cluster centers\nand the semantic centers. IOCC consists of two key modules:\nInteraction-enhanced Optimal Transport (IEOT) and Center-aware Contrastive\nLearning (CACL). Specifically, IEOT incorporates semantic interactions between\nindividual samples into the conventional optimal transport problem, and\ngenerate pseudo-labels. Based on these pseudo-labels, we aggregate\nhigh-confidence samples to construct pseudo-centers that approximate the\nsemantic centers. Next, CACL optimizes text representations toward their\ncorresponding pseudo-centers. As training progresses, the collaboration between\nthe two modules gradually reduces the gap between cluster centers and semantic\ncenters. Therefore, the model will learn a high-quality distribution, improving\nclustering performance. Extensive experiments on eight benchmark datasets show\nthat IOCC outperforms previous methods, achieving up to 7.34\\% improvement on\nchallenging Biomedical dataset and also excelling in clustering stability and\nefficiency. The code is available at:\nhttps://anonymous.4open.science/r/IOCC-C438.", "AI": {"tldr": "\u63d0\u51faIOCC\u65b9\u6cd5\u89e3\u51b3\u77ed\u6587\u672c\u805a\u7c7b\u4e2d\u7c07\u4e2d\u5fc3\u4e0e\u8bed\u4e49\u4e2d\u5fc3\u96be\u4ee5\u5bf9\u9f50\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "motivation": "\u77ed\u6587\u672c\u8868\u793a\u8868\u8fbe\u529b\u6709\u9650\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u627e\u5230\u80fd\u53cd\u6620\u7c7b\u522b\u8bed\u4e49\u7684\u7c07\u4e2d\u5fc3\uff0c\u5bfc\u81f4\u8868\u793a\u4f18\u5316\u65b9\u5411\u4e0d\u4f73\u3002", "method": "\u63d0\u51faIOCC\u65b9\u6cd5\uff0c\u542bIEOT\u548cCACL\u4e24\u4e2a\u6a21\u5757\u3002IEOT\u5c06\u6837\u672c\u8bed\u4e49\u4ea4\u4e92\u878d\u5165\u6700\u4f18\u4f20\u8f93\u95ee\u9898\u5e76\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u6784\u5efa\u8fd1\u4f3c\u8bed\u4e49\u4e2d\u5fc3\u7684\u4f2a\u4e2d\u5fc3\uff1bCACL\u5c06\u6587\u672c\u8868\u793a\u5411\u4f2a\u4e2d\u5fc3\u4f18\u5316\u3002", "result": "\u5728\u516b\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cIOCC\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5728\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u8fbe7.34%\uff0c\u805a\u7c7b\u7a33\u5b9a\u6027\u548c\u6548\u7387\u51fa\u8272\u3002", "conclusion": "IOCC\u80fd\u7f29\u5c0f\u7c07\u4e2d\u5fc3\u4e0e\u8bed\u4e49\u4e2d\u5fc3\u5dee\u8ddd\uff0c\u4f7f\u6a21\u578b\u5b66\u4e60\u9ad8\u8d28\u91cf\u5206\u5e03\uff0c\u63d0\u5347\u805a\u7c7b\u6027\u80fd\u3002"}}
{"id": "2508.06129", "pdf": "https://arxiv.org/pdf/2508.06129", "abs": "https://arxiv.org/abs/2508.06129", "authors": ["Bachtiar Herdianto", "Romain Billot", "Flavien Lucas", "Marc Sevaux"], "title": "Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem", "categories": ["cs.AI"], "comment": "22 pages, 14 figures", "summary": "The Vehicle Routing Problem (VRP) is a complex optimization problem with\nnumerous real-world applications, mostly solved using metaheuristic algorithms\ndue to its $\\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely\non human-crafted designs developed through empirical studies. However, recent\nresearch shows that machine learning methods can be used the structural\ncharacteristics of solutions in combinatorial optimization, thereby aiding in\ndesigning more efficient algorithms, particularly for solving VRP. Building on\nthis advancement, this study extends the previous research by conducting a\nsensitivity analysis using multiple classifier models that are capable of\npredicting the quality of VRP solutions. Hence, by leveraging explainable AI,\nthis research is able to extend the understanding of how these models make\ndecisions. Finally, our findings indicate that while feature importance varies,\ncertain features consistently emerge as strong predictors. Furthermore, we\npropose a unified framework able of ranking feature impact across different\nscenarios to illustrate this finding. These insights highlight the potential of\nfeature importance analysis as a foundation for developing a guidance mechanism\nof metaheuristic algorithms for solving the VRP.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u591a\u5206\u7c7b\u5668\u6a21\u578b\u5bf9VRP\u89e3\u8d28\u91cf\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\uff0c\u501f\u52a9\u53ef\u89e3\u91caAI\u7406\u89e3\u6a21\u578b\u51b3\u7b56\uff0c\u53d1\u73b0\u7279\u5b9a\u7279\u5f81\u662f\u5f3a\u9884\u6d4b\u56e0\u5b50\u5e76\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff0c\u51f8\u663e\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u5bf9VRP\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u6307\u5bfc\u673a\u5236\u5f00\u53d1\u7684\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u9760\u4eba\u5de5\u8bbe\u8ba1\uff0c\u673a\u5668\u5b66\u4e60\u53ef\u5229\u7528\u7ec4\u5408\u4f18\u5316\u89e3\u7684\u7ed3\u6784\u7279\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6269\u5c55\u6b64\u524d\u7814\u7a76\uff0c\u901a\u8fc7\u591a\u5206\u7c7b\u5668\u6a21\u578b\u5bf9VRP\u89e3\u8d28\u91cf\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\u3002", "method": "\u4f7f\u7528\u591a\u4e2a\u80fd\u9884\u6d4bVRP\u89e3\u8d28\u91cf\u7684\u5206\u7c7b\u5668\u6a21\u578b\u8fdb\u884c\u654f\u611f\u6027\u5206\u6790\uff0c\u501f\u52a9\u53ef\u89e3\u91caAI\u7406\u89e3\u6a21\u578b\u51b3\u7b56\u3002", "result": "\u53d1\u73b0\u7279\u5f81\u91cd\u8981\u6027\u6709\u5dee\u5f02\uff0c\u4f46\u7279\u5b9a\u7279\u5f81\u59cb\u7ec8\u662f\u5f3a\u9884\u6d4b\u56e0\u5b50\uff0c\u63d0\u51fa\u80fd\u5728\u4e0d\u540c\u573a\u666f\u5bf9\u7279\u5f81\u5f71\u54cd\u8fdb\u884c\u6392\u540d\u7684\u7edf\u4e00\u6846\u67b6\u3002", "conclusion": "\u7279\u5f81\u91cd\u8981\u6027\u5206\u6790\u6709\u6f5c\u529b\u4f5c\u4e3a\u5f00\u53d1\u89e3\u51b3VRP\u7684\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u6307\u5bfc\u673a\u5236\u7684\u57fa\u7840\u3002"}}
{"id": "2508.05666", "pdf": "https://arxiv.org/pdf/2508.05666", "abs": "https://arxiv.org/abs/2508.05666", "authors": ["Alejandro Godinez"], "title": "HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis", "categories": ["cs.IR", "cs.AI", "cs.LG", "I.2.7; H.3.3; I.2.6; H.2.8; I.7.5"], "comment": "47 pages, 10 figures. Code:\n  https://github.com/agodinezmm2007/docling_mod. Demo:\n  https://youtu.be/ZCy5ESJ1gVE?si=K8CttwgTj7yGrWjn. ETL+multi-agent RAG\n  framework for literature synthesis, 35.1% improvement over PDF chunking. Real\n  application: reduced 17,400 papers to 24 relevant ones (99.86%) in 10 minutes\n  for wastewater epidemiology review", "summary": "We present HySemRAG, a framework that combines Extract, Transform, Load (ETL)\npipelines with Retrieval-Augmented Generation (RAG) to automate large-scale\nliterature synthesis and identify methodological research gaps. The system\naddresses limitations in existing RAG architectures through a multi-layered\napproach: hybrid retrieval combining semantic search, keyword filtering, and\nknowledge graph traversal; an agentic self-correction framework with iterative\nquality assurance; and post-hoc citation verification ensuring complete\ntraceability. Our implementation processes scholarly literature through eight\nintegrated stages: multi-source metadata acquisition, asynchronous PDF\nretrieval, custom document layout analysis using modified Docling architecture,\nbibliographic management, LLM-based field extraction, topic modeling, semantic\nunification, and knowledge graph construction. The system creates dual data\nproducts - a Neo4j knowledge graph enabling complex relationship queries and\nQdrant vector collections supporting semantic search - serving as foundational\ninfrastructure for verifiable information synthesis. Evaluation across 643\nobservations from 60 testing sessions demonstrates structured field extraction\nachieving 35.1% higher semantic similarity scores (0.655 $\\pm$ 0.178) compared\nto PDF chunking approaches (0.485 $\\pm$ 0.204, p < 0.000001). The agentic\nquality assurance mechanism achieves 68.3% single-pass success rates with 99.0%\ncitation accuracy in validated responses. Applied to geospatial epidemiology\nliterature on ozone exposure and cardiovascular disease, the system identifies\nmethodological trends and research gaps, demonstrating broad applicability\nacross scientific domains for accelerating evidence synthesis and discovery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHySemRAG\u6846\u67b6\u7ed3\u5408ETL\u4e0eRAG\u8fdb\u884c\u5927\u89c4\u6a21\u6587\u732e\u7efc\u5408\u4e0e\u65b9\u6cd5\u7814\u7a76\u5dee\u8ddd\u8bc6\u522b\uff0c\u7ecf\u8bc4\u4f30\u6548\u679c\u826f\u597d\u4e14\u6709\u5e7f\u6cdb\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709RAG\u67b6\u6784\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u6587\u732e\u7efc\u5408\u4e0e\u7814\u7a76\u5dee\u8ddd\u8bc6\u522b\u3002", "method": "\u91c7\u7528\u591a\u5c42\u65b9\u6cd5\uff0c\u5305\u62ec\u6df7\u5408\u68c0\u7d22\u3001\u4ee3\u7406\u81ea\u6211\u7ea0\u6b63\u6846\u67b6\u3001\u4e8b\u540e\u5f15\u7528\u9a8c\u8bc1\uff1b\u901a\u8fc7\u516b\u4e2a\u96c6\u6210\u9636\u6bb5\u5904\u7406\u5b66\u672f\u6587\u732e\uff0c\u521b\u5efa\u53cc\u6570\u636e\u4ea7\u54c1\u3002", "result": "\u7ed3\u6784\u5316\u5b57\u6bb5\u63d0\u53d6\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5f97\u5206\u6bd4PDF\u5206\u5757\u65b9\u6cd5\u9ad835.1%\uff1b\u4ee3\u7406\u8d28\u91cf\u4fdd\u8bc1\u673a\u5236\u5355\u6b21\u6210\u529f\u738768.3%\uff0c\u5f15\u7528\u51c6\u786e\u738799.0%\u3002", "conclusion": "HySemRAG\u6846\u67b6\u5728\u79d1\u5b66\u9886\u57df\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u53ef\u52a0\u901f\u8bc1\u636e\u7efc\u5408\u4e0e\u53d1\u73b0\u3002"}}
{"id": "2508.05697", "pdf": "https://arxiv.org/pdf/2508.05697", "abs": "https://arxiv.org/abs/2508.05697", "authors": ["Marcos Guillermo Lammers", "Federico Hern\u00e1n Holik", "Alejandro Fern\u00e1ndez"], "title": "Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering", "categories": ["quant-ph", "cs.SE"], "comment": "in Spanish language", "summary": "Quantum computers represent a radical technological breakthrough in\ninformation processing by leveraging the principles of quantum mechanics to\nsolve highly complex problems beyond the reach of classical systems. However,\nin the current NISQ era (noisy intermediate-scale quantum devices), the\navailable hardware presents several limitations, such as a limited number of\nqubits, high error rates, and short coherence times. Efficient management of\nquantum resources, both physical and logical, is especially relevant in the\ndesign and deployment of quantum algorithms. In this paper, we analyze the role\nof resources in current uses of NISQ devices, identifying their relevance and\nimplications for quantum software engineering. With this contribution, we aim\nto strengthen the field of Quantum Resource Estimation (QRE) and move toward\nscalable and reliable quantum software development", "AI": {"tldr": "\u5206\u6790NISQ\u8bbe\u5907\u8d44\u6e90\u5728\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u548c\u90e8\u7f72\u4e2d\u7684\u4f5c\u7528\uff0c\u52a9\u529b\u91cf\u5b50\u8d44\u6e90\u4f30\u8ba1\u548c\u53ef\u9760\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u3002", "motivation": "\u5f53\u524dNISQ\u65f6\u4ee3\u786c\u4ef6\u6709\u5c40\u9650\u6027\uff0c\u9ad8\u6548\u7ba1\u7406\u91cf\u5b50\u8d44\u6e90\u5bf9\u91cf\u5b50\u7b97\u6cd5\u8bbe\u8ba1\u548c\u90e8\u7f72\u5f88\u91cd\u8981\uff0c\u65e8\u5728\u52a0\u5f3a\u91cf\u5b50\u8d44\u6e90\u4f30\u8ba1\u9886\u57df\uff0c\u63a8\u52a8\u53ef\u9760\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u3002", "method": "\u5206\u6790NISQ\u8bbe\u5907\u8d44\u6e90\u5728\u5f53\u524d\u5e94\u7528\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u672a\u63d0\u53ca\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\uff0c\u4f46\u76ee\u6807\u662f\u52a0\u5f3a\u91cf\u5b50\u8d44\u6e90\u4f30\u8ba1\u9886\u57df\uff0c\u63a8\u52a8\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u3002"}}
{"id": "2508.05960", "pdf": "https://arxiv.org/pdf/2508.05960", "abs": "https://arxiv.org/abs/2508.05960", "authors": ["Haohui Chen", "Zhiyong Chen"], "title": "Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline reinforcement learning (RL) seeks to learn optimal policies from\nstatic datasets without further environment interaction. A key challenge is the\ndistribution shift between the learned and behavior policies, leading to\nout-of-distribution (OOD) actions and overestimation. To prevent gross\noverestimation, the value function must remain conservative; however, excessive\nconservatism may hinder performance improvement. To address this, we propose\nthe mildly conservative regularized evaluation (MCRE) framework, which balances\nconservatism and performance by combining temporal difference (TD) error with a\nbehavior cloning term in the Bellman backup. Building on this, we develop the\nmildly conservative regularized Q-learning (MCRQ) algorithm, which integrates\nMCRE into an off-policy actor-critic framework. Experiments show that MCRQ\noutperforms strong baselines and state-of-the-art offline RL algorithms on\nbenchmark datasets.", "AI": {"tldr": "\u63d0\u51faMCRE\u6846\u67b6\u548cMCRQ\u7b97\u6cd5\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793aMCRQ\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u548c\u5148\u8fdb\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b66\u4e60\u7b56\u7565\u548c\u884c\u4e3a\u7b56\u7565\u95f4\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u7684OOD\u52a8\u4f5c\u548c\u9ad8\u4f30\u95ee\u9898\uff0c\u907f\u514d\u8fc7\u5ea6\u4fdd\u5b88\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u63d0\u51faMCRE\u6846\u67b6\uff0c\u7ed3\u5408\u65f6\u95f4\u5dee\u5206\u8bef\u5dee\u548c\u884c\u4e3a\u514b\u9686\u9879\u5e73\u8861\u4fdd\u5b88\u6027\u548c\u6027\u80fd\uff1b\u5f00\u53d1MCRQ\u7b97\u6cd5\uff0c\u5c06MCRE\u96c6\u6210\u5230\u79bb\u7b56\u7565\u6f14\u5458-\u8bc4\u8bba\u5bb6\u6846\u67b6\u3002", "result": "MCRQ\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u548c\u6700\u5148\u8fdb\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "conclusion": "MCRQ\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5728\u6027\u80fd\u4e0a\u6709\u4f18\u52bf\u3002"}}
{"id": "2508.06145", "pdf": "https://arxiv.org/pdf/2508.06145", "abs": "https://arxiv.org/abs/2508.06145", "authors": ["Byeonghun Bang", "Jongsuk Yoon", "Dong-Jin Chang", "Seho Park", "Yong Oh Lee"], "title": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications", "categories": ["cs.AI"], "comment": null, "summary": "The versatility of large language models (LLMs) has been explored across\nvarious sectors, but their application in healthcare poses challenges,\nparticularly in the domain of pharmaceutical contraindications where accurate\nand reliable information is required. This study enhances the capability of\nLLMs to address contraindications effectively by implementing a Retrieval\nAugmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base\nmodel, and the text-embedding-3-small model for embeddings, our approach\nintegrates Langchain to orchestrate a hybrid retrieval system with re-ranking.\nThis system leverages Drug Utilization Review (DUR) data from public databases,\nfocusing on contraindications for specific age groups, pregnancy, and\nconcomitant drug use. The dataset includes 300 question-answer pairs across\nthree categories, with baseline model accuracy ranging from 0.49 to 0.57.\nPost-integration of the RAG pipeline, we observed a significant improvement in\nmodel accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications\nrelated to age groups, pregnancy, and concomitant drug use, respectively. The\nresults indicate that augmenting LLMs with a RAG framework can substantially\nreduce uncertainty in prescription and drug intake decisions by providing more\nprecise and reliable drug contraindication information.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7RAG\u7ba1\u9053\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u836f\u7269\u7981\u5fcc\u95ee\u9898\u7684\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u51c6\u786e\u7387\uff0c\u80fd\u4e3a\u7528\u836f\u51b3\u7b56\u63d0\u4f9b\u66f4\u53ef\u9760\u4fe1\u606f\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u4fdd\u5065\u9886\u57df\uff0c\u5c24\u5176\u662f\u836f\u7269\u7981\u5fcc\u65b9\u9762\u5e94\u7528\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u66f4\u51c6\u786e\u53ef\u9760\u4fe1\u606f\u3002", "method": "\u91c7\u7528Retrieval Augmented Generation (RAG)\u7ba1\u9053\uff0c\u4ee5OpenAI\u7684GPT - 4o - mini\u4e3a\u57fa\u7840\u6a21\u578b\uff0ctext - embedding - 3 - small\u6a21\u578b\u8fdb\u884c\u5d4c\u5165\uff0c\u7ed3\u5408Langchain\u7f16\u6392\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\u5e76\u91cd\u65b0\u6392\u5e8f\uff0c\u5229\u7528\u516c\u5171\u6570\u636e\u5e93\u7684DUR\u6570\u636e\u3002", "result": "\u96c6\u6210RAG\u7ba1\u9053\u540e\uff0c\u6a21\u578b\u5728\u5e74\u9f84\u7ec4\u3001\u6000\u5b55\u548c\u8054\u5408\u7528\u836f\u7981\u5fcc\u65b9\u9762\u7684\u51c6\u786e\u7387\u5206\u522b\u8fbe\u52300.94\u30010.87\u548c0.89\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u7528RAG\u6846\u67b6\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u51cf\u5c11\u5904\u65b9\u548c\u7528\u836f\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u4f9b\u66f4\u7cbe\u786e\u53ef\u9760\u7684\u836f\u7269\u7981\u5fcc\u4fe1\u606f\u3002"}}
{"id": "2508.05667", "pdf": "https://arxiv.org/pdf/2508.05667", "abs": "https://arxiv.org/abs/2508.05667", "authors": ["Zekun Liu", "Xiaowen Huang", "Jitao Sang"], "title": "ITDR: An Instruction Tuning Dataset for Enhancing Large Language Models in Recommendations", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated outstanding performance in\nnatural language processing tasks. However, in the field of recommendation\nsystems, due to the structural differences between user behavior data and\nnatural language, LLMs struggle to effectively model the associations between\nuser preferences and items. Although prompt-based methods can generate\nrecommendation results, their inadequate understanding of recommendation tasks\nleads to constrained performance. To address this gap, in this work, we\nconstruct a sufficient instruction tuning dataset, ITDR, which encompasses 7\nsubtasks across two core root tasks--user-item interaction and user-item\nunderstanding. The dataset integrates data from 13 public recommendation\ndatasets and is built using manually crafted standardized templates, comprising\napproximately 200,000 instances. Experimental results demonstrate that ITDR\nsignificantly enhances the performance of mainstream open-source LLMs such as\nGLM-4, Qwen2.5, Qwen2.5-Instruct and LLaMA-3.2 on recommendation tasks.\nFurthermore, we analyze the correlations between tasks and explore the impact\nof task descriptions and data scale on instruction tuning effectiveness.\nFinally, we perform comparative experiments against closed-source LLMs with\nsubstantial parameters. Our tuning dataset ITDR and the fine-tuned large\nrecommendation models can be accessed at https://github.com/hellolzk/ITDR.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6ITDR\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\uff0c\u8fd8\u5206\u6790\u4e86\u76f8\u5173\u56e0\u7d20\u5f71\u54cd\u5e76\u7ed9\u51fa\u8d44\u6e90\u94fe\u63a5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u56e0\u6570\u636e\u7ed3\u6784\u5dee\u5f02\u53ca\u5bf9\u4efb\u52a1\u7406\u89e3\u4e0d\u8db3\uff0c\u6027\u80fd\u53d7\u9650\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u6784\u5efa\u5305\u542b7\u4e2a\u5b50\u4efb\u52a1\u3001\u6574\u540813\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u3001\u7ea6200000\u5b9e\u4f8b\u7684\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6ITDR\u3002", "result": "ITDR\u663e\u8457\u63d0\u5347\u4e86GLM - 4\u7b49\u4e3b\u6d41\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u8fd8\u8fdb\u884c\u4e86\u4efb\u52a1\u76f8\u5173\u6027\u5206\u6790\u548c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "conclusion": "\u6784\u5efa\u7684ITDR\u6570\u636e\u96c6\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\uff0c\u76f8\u5173\u8d44\u6e90\u53ef\u5728\u6307\u5b9a\u94fe\u63a5\u83b7\u53d6\u3002"}}
{"id": "2508.05865", "pdf": "https://arxiv.org/pdf/2508.05865", "abs": "https://arxiv.org/abs/2508.05865", "authors": ["Kiana Kiashemshaki", "Elvis Nnaemeka Chukwuani", "Mohammad Jalili Torkamani", "Negin Mahmoudi"], "title": "Secure and Scalable Blockchain Voting: A Comparative Framework and the Role of Large Language Models", "categories": ["cs.CR", "cs.SE", "C.2; D.2; D.4.1; D.4.4; D.4.6; I.2.7"], "comment": "9 pages, 8 figures, 1 table", "summary": "Blockchain technology offers a promising foundation for modernizing E-Voting\nsystems by enhancing transparency, decentralization, and security. Yet,\nreal-world adoption remains limited due to persistent challenges such as\nscalability constraints, high computational demands, and complex privacy\nrequirements. This paper presents a comparative framework for analyzing\nblockchain-based E-Voting architectures, consensus mechanisms, and\ncryptographic protocols. We examine the limitations of prevalent models like\nProof of Work, Proof of Stake, and Delegated Proof of Stake, and propose\noptimization strategies that include hybrid consensus, lightweight\ncryptography, and decentralized identity management. Additionally, we explore\nthe novel role of Large Language Models (LLMs) in smart contract generation,\nanomaly detection, and user interaction. Our findings offer a foundation for\ndesigning secure, scalable, and intelligent blockchain-based E-Voting systems\nsuitable for national-scale deployment. This work lays the groundwork for\nbuilding an end-to-end blockchain E-Voting prototype enhanced by LLM-guided\nsmart contract generation and validation, supported by a systematic framework\nand simulation-based analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5206\u6790\u533a\u5757\u94fe\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u6307\u51fa\u6d41\u884c\u6a21\u578b\u5c40\u9650\u5e76\u63d0\u51fa\u4f18\u5316\u7b56\u7565\uff0c\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u7528\uff0c\u4e3a\u8bbe\u8ba1\u76f8\u5173\u7cfb\u7edf\u5960\u57fa\u3002", "motivation": "\u533a\u5757\u94fe\u6280\u672f\u867d\u80fd\u63d0\u5347\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u6027\u80fd\uff0c\u4f46\u73b0\u5b9e\u5e94\u7528\u56e0\u53ef\u6269\u5c55\u6027\u3001\u8ba1\u7b97\u9700\u6c42\u548c\u9690\u79c1\u8981\u6c42\u7b49\u6311\u6218\u53d7\u9650\uff0c\u9700\u4f18\u5316\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u6bd4\u8f83\u6846\u67b6\u5206\u6790\u533a\u5757\u94fe\u7535\u5b50\u6295\u7968\u67b6\u6784\u3001\u5171\u8bc6\u673a\u5236\u548c\u52a0\u5bc6\u534f\u8bae\uff1b\u7814\u7a76\u4e3b\u6d41\u6a21\u578b\u5c40\u9650\u5e76\u63d0\u51fa\u4f18\u5316\u7b56\u7565\uff1b\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u5408\u7ea6\u751f\u6210\u7b49\u65b9\u9762\u7684\u4f5c\u7528\uff1b\u8fdb\u884c\u57fa\u4e8e\u6a21\u62df\u7684\u5206\u6790\u3002", "result": "\u4e3a\u8bbe\u8ba1\u5b89\u5168\u3001\u53ef\u6269\u5c55\u548c\u667a\u80fd\u7684\u5168\u56fd\u6027\u533a\u5757\u94fe\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u4e3a\u6784\u5efa\u7531\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7684\u7aef\u5230\u7aef\u533a\u5757\u94fe\u7535\u5b50\u6295\u7968\u539f\u578b\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.05977", "pdf": "https://arxiv.org/pdf/2508.05977", "abs": "https://arxiv.org/abs/2508.05977", "authors": ["Aoming Liang", "Chi Cheng", "Dashuai Chen", "Boai Sun", "Dixia Fan"], "title": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "In the domain of scientific machine learning, designing effective reward\nfunctions remains a challenge in reinforcement learning (RL), particularly in\nenvironments where task goals are difficult to specify numerically. Reward\nfunctions in existing work are predominantly based on heuristics, manual\nengineering, or task-specific tuning. In this work, we introduce a semantically\naligned reinforcement learning method where rewards are computed by aligning\nthe current state with a target semantic instruction using a\nSentence-Bidirectional Encoder Representations from Transformers (SBERT).\nInstead of relying on manually defined reward functions, the policy receives\nfeedback based on the reward, which is a cosine similarity between the goal\ntextual description and the statement description in the episode. We evaluated\nour approach in several environments and showed that semantic reward can guide\nlearning to achieve competitive control behavior, even in the absence of\nhand-crafted reward functions. Our study demonstrates a correlation between the\nlanguage embedding space and the conventional Euclidean space. This framework\nopens new horizons for aligning agent behavior with natural language goals and\nlays the groundwork for a more seamless integration of larger language models\n(LLMs) and fluid control applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bed\u4e49\u5bf9\u9f50\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u96be\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u5e76\u4e3aLLMs\u4e0e\u63a7\u5236\u5e94\u7528\u96c6\u6210\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4e2d\u5f3a\u5316\u5b66\u4e60\u5728\u4efb\u52a1\u76ee\u6807\u96be\u6570\u503c\u5316\u7684\u73af\u5883\u4e0b\uff0c\u8bbe\u8ba1\u6709\u6548\u5956\u52b1\u51fd\u6570\u662f\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u57fa\u4e8e\u542f\u53d1\u5f0f\u3001\u624b\u52a8\u5de5\u7a0b\u6216\u7279\u5b9a\u4efb\u52a1\u8c03\u6574\u3002", "method": "\u5f15\u5165\u8bed\u4e49\u5bf9\u9f50\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528SBERT\u5c06\u5f53\u524d\u72b6\u6001\u4e0e\u76ee\u6807\u8bed\u4e49\u6307\u4ee4\u5bf9\u9f50\u8ba1\u7b97\u5956\u52b1\uff0c\u7b56\u7565\u6839\u636e\u76ee\u6807\u6587\u672c\u63cf\u8ff0\u4e0e\u60c5\u8282\u4e2d\u9648\u8ff0\u63cf\u8ff0\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u83b7\u5f97\u53cd\u9988\u3002", "result": "\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u8bc4\u4f30\u8868\u660e\uff0c\u5373\u4f7f\u6ca1\u6709\u624b\u5de5\u8bbe\u8ba1\u7684\u5956\u52b1\u51fd\u6570\uff0c\u8bed\u4e49\u5956\u52b1\u4e5f\u80fd\u5f15\u5bfc\u5b66\u4e60\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u7684\u63a7\u5236\u884c\u4e3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u8bed\u8a00\u5d4c\u5165\u7a7a\u95f4\u4e0e\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u5b58\u5728\u76f8\u5173\u6027\uff0c\u4e3a\u4f7f\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u81ea\u7136\u8bed\u8a00\u76ee\u6807\u5bf9\u9f50\u5f00\u8f9f\u65b0\u89c6\u91ce\uff0c\u4e3aLLMs\u4e0e\u6d41\u4f53\u63a7\u5236\u5e94\u7528\u66f4\u65e0\u7f1d\u96c6\u6210\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.06483", "pdf": "https://arxiv.org/pdf/2508.06483", "abs": "https://arxiv.org/abs/2508.06483", "authors": ["Ben Chugg", "Aaditya Ramdas"], "title": "A variational approach to dimension-free self-normalized concentration", "categories": ["math.PR", "math.ST", "stat.ML", "stat.TH"], "comment": "37 pages", "summary": "We study the self-normalized concentration of vector-valued stochastic\nprocesses. We focus on bounds for sub-$\\psi$ processes, a tail condition that\nencompasses a wide variety of well-known distributions (including\nsub-exponential, sub-Gaussian, sub-gamma, and sub-Poisson distributions). Our\nresults recover and generalize the influential bound of Abbasi-Yadkori et al.\n(2011) and fill a gap in the literature between determinant-based bounds and\nthose based on condition numbers. As applications we prove a Bernstein\ninequality for random vectors satisfying a moment condition (which is more\ngeneral than boundedness), and also provide the first dimension-free,\nself-normalized empirical Bernstein inequality. Our techniques are based on the\nvariational (PAC-Bayes) approach to concentration.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.06225", "pdf": "https://arxiv.org/pdf/2508.06225", "abs": "https://arxiv.org/abs/2508.06225", "authors": ["Zailong Tian", "Zhuoheng Han", "Yanzhe Chen", "Haozhe Xu", "Xi Yang", "richeng xuan", "Hongfeng Wang", "Lizi Liao"], "title": "Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are widely used as automated judges, where\npractical value depends on both accuracy and trustworthy, risk-aware judgments.\nExisting approaches predominantly focus on accuracy, overlooking the necessity\nof well-calibrated confidence, which is vital for adaptive and reliable\nevaluation pipelines. In this work, we advocate a shift from accuracy-centric\nevaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing\nthe necessity of well-calibrated confidence for trustworthy and adaptive\nevaluation. We systematically identify the **Overconfidence Phenomenon** in\ncurrent LLM-as-a-Judges, where predicted confidence significantly overstates\nactual correctness, undermining reliability in practical deployment. To\nquantify this phenomenon, we introduce **TH-Score**, a novel metric measuring\nconfidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an\nensemble framework that transforms LLMs into reliable, risk-aware evaluators.\nExtensive experiments demonstrate that our approach substantially improves\ncalibration and enables adaptive, confidence-driven evaluation pipelines,\nachieving superior reliability and accuracy compared to existing baselines.", "AI": {"tldr": "\u672c\u6587\u5021\u5bfc\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u7cfb\u7edf\u4ece\u4ee5\u51c6\u786e\u7387\u4e3a\u4e2d\u5fc3\u8f6c\u5411\u4ee5\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u3001\u8003\u8651\u98ce\u9669\u7684\u8bc4\u4f30\u65b9\u5f0f\uff0c\u8bc6\u522b\u4e86\u8fc7\u5ea6\u81ea\u4fe1\u73b0\u8c61\uff0c\u5f15\u5165TH - Score\u6307\u6807\uff0c\u63d0\u51faLLM - as - Fuser\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u7cfb\u7edf\u7684\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u7387\uff0c\u5ffd\u7565\u4e86\u6821\u51c6\u826f\u597d\u7684\u7f6e\u4fe1\u5ea6\uff0c\u800c\u8fd9\u5bf9\u81ea\u9002\u5e94\u548c\u53ef\u9760\u7684\u8bc4\u4f30\u6d41\u7a0b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8bc6\u522b\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u7cfb\u7edf\u4e2d\u7684\u8fc7\u5ea6\u81ea\u4fe1\u73b0\u8c61\uff0c\u5f15\u5165TH - Score\u6307\u6807\u91cf\u5316\u8be5\u73b0\u8c61\uff0c\u63d0\u51faLLM - as - Fuser\u96c6\u6210\u6846\u67b6\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u6821\u51c6\uff0c\u5e76\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u3001\u4ee5\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u5728\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5e94\u4ece\u4ee5\u51c6\u786e\u7387\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u8f6c\u5411\u4ee5\u7f6e\u4fe1\u5ea6\u9a71\u52a8\u3001\u8003\u8651\u98ce\u9669\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u7cfb\u7edf\uff0c\u6240\u63d0\u65b9\u6cd5\u53ef\u884c\u6709\u6548\u3002"}}
{"id": "2508.05668", "pdf": "https://arxiv.org/pdf/2508.05668", "abs": "https://arxiv.org/abs/2508.05668", "authors": ["Yunjia Xi", "Jianghao Lin", "Yongzhao Xiao", "Zheli Zhou", "Rong Shan", "Te Gao", "Jiachen Zhu", "Weiwen Liu", "Yong Yu", "Weinan Zhang"], "title": "A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "The advent of Large Language Models (LLMs) has significantly revolutionized\nweb search. The emergence of LLM-based Search Agents marks a pivotal shift\ntowards deeper, dynamic, autonomous information seeking. These agents can\ncomprehend user intentions and environmental context and execute multi-turn\nretrieval with dynamic planning, extending search capabilities far beyond the\nweb. Leading examples like OpenAI's Deep Research highlight their potential for\ndeep information mining and real-world applications. This survey provides the\nfirst systematic analysis of search agents. We comprehensively analyze and\ncategorize existing works from the perspectives of architecture, optimization,\napplication, and evaluation, ultimately identifying critical open challenges\nand outlining promising future research directions in this rapidly evolving\nfield. Our repository is available on\nhttps://github.com/YunjiaXi/Awesome-Search-Agent-Papers.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u641c\u7d22\u4ee3\u7406\u8fdb\u884c\u9996\u6b21\u7cfb\u7edf\u5206\u6790\uff0c\u5bf9\u73b0\u6709\u5de5\u4f5c\u5206\u7c7b\uff0c\u6307\u51fa\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u63d0\u4f9b\u76f8\u5173\u4ee3\u7801\u5e93\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7f51\u7edc\u641c\u7d22\u53d8\u9769\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u641c\u7d22\u4ee3\u7406\u51fa\u73b0\uff0c\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u4ece\u67b6\u6784\u3001\u4f18\u5316\u3001\u5e94\u7528\u548c\u8bc4\u4f30\u7b49\u89d2\u5ea6\u5bf9\u73b0\u6709\u5de5\u4f5c\u8fdb\u884c\u5168\u9762\u5206\u6790\u548c\u5206\u7c7b\u3002", "result": "\u5bf9\u641c\u7d22\u4ee3\u7406\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\u548c\u5206\u7c7b\u3002", "conclusion": "\u786e\u5b9a\u4e86\u8be5\u9886\u57df\u5173\u952e\u5f00\u653e\u6311\u6218\uff0c\u7ed9\u51fa\u4e86\u6709\u524d\u666f\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.05883", "pdf": "https://arxiv.org/pdf/2508.05883", "abs": "https://arxiv.org/abs/2508.05883", "authors": ["Sean Feeney", "Reuben Tate", "John Golden", "Stephan Eidenbenz"], "title": "MPS-JuliQAOA: User-friendly, Scalable MPS-based Simulation for Quantum Optimization", "categories": ["quant-ph", "cs.ET", "cs.SE"], "comment": "14 pages, 7 figures", "summary": "We present the MPS-JuliQAOA simulator, a user-friendly, open-source tool to\nsimulate the Quantum Approximate Optimization Algorithm (QAOA) of any\noptimization problem that can be expressed as diagonal Hamiltonian. By\nleveraging Julia-language constructs and the ITensor package to implement a\nMatrix Product State (MPS) approach to simulating QAOA, MPS-Juli-QAOA\neffortlessly scales to 512 qubits and 20 simulation rounds on the standard\nde-facto benchmark 3-regular MaxCut QAOA problem. MPS-JuliQAOA also has\nbuilt-in parameter finding capabilities, which is a crucial performance aspect\nof QAOA. We illustrate through examples that the user does not need to know MPS\nprinciples or complex automatic differentiation techniques to use MPS-JuliQAOA.\nWe study the scalability of our tool with respect to runtime, memory usage and\naccuracy tradeoffs. Code available at\nhttps://github.com/lanl/JuliQAOA.jl/tree/mps.", "AI": {"tldr": "\u4ecb\u7ecdMPS - JuliQAOA\u6a21\u62df\u5668\uff0c\u53ef\u6a21\u62dfQAOA\uff0c\u80fd\u6269\u5c55\u5230512\u91cf\u5b50\u6bd4\u7279\u548c20\u8f6e\u6a21\u62df\uff0c\u6709\u53c2\u6570\u67e5\u627e\u80fd\u529b\uff0c\u7528\u6237\u4f7f\u7528\u65e0\u9700\u4e13\u4e1a\u77e5\u8bc6\uff0c\u8fd8\u7814\u7a76\u4e86\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u3001\u5f00\u6e90\u7684\u5de5\u5177\u6765\u6a21\u62df\u53ef\u8868\u793a\u4e3a\u5bf9\u89d2\u54c8\u5bc6\u987f\u91cf\u7684\u4f18\u5316\u95ee\u9898\u7684\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff08QAOA\uff09\u3002", "method": "\u5229\u7528Julia\u8bed\u8a00\u7ed3\u6784\u548cITensor\u5305\uff0c\u91c7\u7528\u77e9\u9635\u4e58\u79ef\u6001\uff08MPS\uff09\u65b9\u6cd5\u6765\u6a21\u62dfQAOA\u3002", "result": "\u80fd\u8f7b\u677e\u6269\u5c55\u5230512\u4e2a\u91cf\u5b50\u6bd4\u7279\u548c20\u8f6e\u6a21\u62df3 - \u6b63\u5219MaxCut QAOA\u95ee\u9898\uff0c\u6709\u5185\u7f6e\u53c2\u6570\u67e5\u627e\u80fd\u529b\uff0c\u7528\u6237\u65e0\u9700\u4e86\u89e3MPS\u539f\u7406\u6216\u590d\u6742\u81ea\u52a8\u5fae\u5206\u6280\u672f\u3002", "conclusion": "\u5f00\u53d1\u51faMPS - JuliQAOA\u6a21\u62df\u5668\uff0c\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6613\u7528\u6027\uff0c\u4ee3\u7801\u5f00\u6e90\u3002"}}
{"id": "2508.05984", "pdf": "https://arxiv.org/pdf/2508.05984", "abs": "https://arxiv.org/abs/2508.05984", "authors": ["Ankur Naskar", "Gugan Thoppe", "Vijay Gupta"], "title": "Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning", "categories": ["cs.LG"], "comment": null, "summary": "Algorithms for solving \\textit{nonlinear} fixed-point equations -- such as\naverage-reward \\textit{$Q$-learning} and \\textit{TD-learning} -- often involve\nsemi-norm contractions. Achieving parameter-free optimal convergence rates for\nthese methods via Polyak--Ruppert averaging has remained elusive, largely due\nto the non-monotonicity of such semi-norms. We close this gap by (i.) recasting\nthe averaged error as a linear recursion involving a nonlinear perturbation,\nand (ii.) taming the nonlinearity by coupling the semi-norm's contraction with\nthe monotonicity of a suitably induced norm. Our main result yields the first\nparameter-free $\\tilde{O}(1/\\sqrt{t})$ optimal rates for $Q$-learning in both\naverage-reward and exponentially discounted settings, where $t$ denotes the\niteration index. The result applies within a broad framework that accommodates\nsynchronous and asynchronous updates, single-agent and distributed deployments,\nand data streams obtained either from simulators or along Markovian\ntrajectories.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.06226", "pdf": "https://arxiv.org/pdf/2508.06226", "abs": "https://arxiv.org/abs/2508.06226", "authors": ["Yumeng Fu", "Jiayin Zhu", "Lingling Zhang", "Bo Zhao", "Shaoxuan Ma", "Yushun Zhang", "Yanrui Wu", "Wenjun Wu"], "title": "GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines", "categories": ["cs.AI"], "comment": null, "summary": "Geometry problem solving (GPS) requires models to master diagram\ncomprehension, logical reasoning, knowledge application, numerical computation,\nand auxiliary line construction. This presents a significant challenge for\nMultimodal Large Language Models (MLLMs). However, existing benchmarks for\nevaluating MLLM geometry skills overlook auxiliary line construction and lack\nfine-grained process evaluation, making them insufficient for assessing MLLMs'\nlong-step reasoning abilities. To bridge these gaps, we present the GeoLaux\nbenchmark, comprising 2,186 geometry problems, incorporating both calculation\nand proving questions. Notably, the problems require an average of 6.51\nreasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary\nline construction. Building on the dataset, we design a novel five-dimensional\nevaluation strategy assessing answer correctness, process correctness, process\nquality, auxiliary line impact, and error causes. Extensive experiments on 13\nleading MLLMs (including thinking models and non-thinking models) yield three\npivotal findings: First, models exhibit substantial performance degradation in\nextended reasoning steps (nine models demonstrate over 50% performance drop).\nSecond, compared to calculation problems, MLLMs tend to take shortcuts when\nsolving proving problems. Third, models lack auxiliary line awareness, and\nenhancing this capability proves particularly beneficial for overall geometry\nreasoning improvement. These findings establish GeoLaux as both a benchmark for\nevaluating MLLMs' long-step geometric reasoning with auxiliary lines and a\nguide for capability advancement. Our dataset and code are included in\nsupplementary materials and will be released.", "AI": {"tldr": "\u63d0\u51faGeoLaux\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30MLLMs\u51e0\u4f55\u957f\u6b65\u9aa4\u63a8\u7406\u80fd\u529b\uff0c\u5bf913\u4e2a\u6a21\u578b\u5b9e\u9a8c\u6709\u91cd\u8981\u53d1\u73b0\u5e76\u6307\u5bfc\u80fd\u529b\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30MLLM\u51e0\u4f55\u6280\u80fd\u7684\u57fa\u51c6\u5ffd\u7565\u8f85\u52a9\u7ebf\u6784\u5efa\u548c\u7ec6\u7c92\u5ea6\u8fc7\u7a0b\u8bc4\u4f30\uff0c\u4e0d\u8db3\u4ee5\u8bc4\u4f30\u957f\u6b65\u9aa4\u63a8\u7406\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b2186\u4e2a\u51e0\u4f55\u95ee\u9898\u7684GeoLaux\u57fa\u51c6\uff0c\u8bbe\u8ba1\u4e94\u7ef4\u8bc4\u4f30\u7b56\u7565\u3002", "result": "1. \u6a21\u578b\u5728\u957f\u63a8\u7406\u6b65\u9aa4\u4e2d\u6027\u80fd\u5927\u5e45\u4e0b\u964d\uff1b2. \u89e3\u51b3\u8bc1\u660e\u9898\u65f6\u503e\u5411\u8d70\u6377\u5f84\uff1b3. \u7f3a\u4e4f\u8f85\u52a9\u7ebf\u610f\u8bc6\uff0c\u589e\u5f3a\u8be5\u80fd\u529b\u6709\u76ca\u3002", "conclusion": "GeoLaux\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u542b\u8f85\u52a9\u7ebf\u7684\u957f\u6b65\u9aa4\u51e0\u4f55\u63a8\u7406\u7684\u57fa\u51c6\uff0c\u4e5f\u80fd\u6307\u5bfc\u80fd\u529b\u63d0\u5347\u3002"}}
{"id": "2508.05669", "pdf": "https://arxiv.org/pdf/2508.05669", "abs": "https://arxiv.org/abs/2508.05669", "authors": ["Jin Khye Tan", "En Jun Choong", "Ethan Jeremiah Chitty", "Yan Pheng Choo", "John Hsin Yang Wong", "Chern Eu Cheah"], "title": "Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV", "cs.LG", "I.2.7; I.7.2; J.1"], "comment": "28 pages, 14 figures, 5 tables. Evaluation code (LLM-as-a-judge and\n  Markdown TEDS) is available at https://github.com/jinkhye/MyFinMarkdown. The\n  development dataset and evaluation benchmark are available on Hugging Face at\n  https://huggingface.co/datasets/jinkhye/MyFinMarkdown-sample and\n  https://huggingface.co/datasets/jinkhye/MyFinMarkdown-bench respectively", "summary": "Accurately extracting and representing the structure of tabular data from\nfinancial documents remains a critical challenge in document understanding,\nparticularly for regulatory and analytical use cases. This study addresses the\ncomplexity of converting financial tables from Malaysian audited financial\nreports into Markdown format, a task complicated by rotated layouts,\nmulti-level headers, and implicit structural cues. We propose a fine-tuned\nvision-language model (VLM), based on Qwen2.5-VL-7B, optimized for\nhigh-fidelity Markdown generation from document images. Our approach includes a\ncurated dataset of 2,152 image-text pairs with augmentations and a supervised\nfine-tuning strategy using LoRA. To assess performance, we evaluated our model\non 100 out-of-sample tables using a dual framework: a criteria-based\nLLM-as-a-judge for fine-grained accuracy and our novel Markdown\nTree-Edit-Distance-based Similarity (TEDS) metric for holistic structural\nfidelity. Our model achieves a 92.20% overall accuracy on the criteria-based\nassessment and a 96.53% Markdown TEDS score. This performance significantly\nsurpasses its Qwen2.5-VL-7B base model, larger-scale VLMs, and specialized\nreasoning-enabled models. Compared to these self-hosted alternatives, it also\nsignificantly reduces inference time. Furthermore, its accuracy exceeds that of\nwidely used proprietary models such as OpenAI's GPT-4o and Gemini 2.5 Flash.\nThese results demonstrate that domain-specific fine-tuning provides an\neffective and efficient method to bridge the gap between unstructured financial\ndocuments and downstream automation, rivalling much larger and more general\nmodels without their computational overhead.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u57fa\u4e8eQwen2.5-VL-7B\u7684\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u9a6c\u6765\u897f\u4e9a\u5ba1\u8ba1\u8d22\u52a1\u62a5\u544a\u8868\u683c\u8f6c\u4e3aMarkdown\u683c\u5f0f\uff0c\u8868\u73b0\u8d85\u591a\u79cd\u6a21\u578b\uff0c\u8bc1\u660e\u7279\u5b9a\u9886\u57df\u5fae\u8c03\u6709\u6548\u3002", "motivation": "\u51c6\u786e\u63d0\u53d6\u548c\u8868\u793a\u91d1\u878d\u6587\u6863\u4e2d\u8868\u683c\u6570\u636e\u7ed3\u6784\u662f\u6587\u6863\u7406\u89e3\u5173\u952e\u6311\u6218\uff0c\u89e3\u51b3\u5c06\u9a6c\u6765\u897f\u4e9a\u5ba1\u8ba1\u8d22\u52a1\u62a5\u544a\u8868\u683c\u8f6c\u4e3aMarkdown\u683c\u5f0f\u7684\u590d\u6742\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eQwen2.5-VL-7B\u7684\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u542b2152\u4e2a\u56fe\u50cf - \u6587\u672c\u5bf9\u7684\u6570\u636e\u96c6\u548cLoRA\u76d1\u7763\u5fae\u8c03\u7b56\u7565\uff0c\u7528\u53cc\u6846\u67b6\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5728\u57fa\u4e8e\u6807\u51c6\u8bc4\u4f30\u4e2d\u51c6\u786e\u738792.20%\uff0cMarkdown TEDS\u5f97\u520696.53%\uff0c\u8d85\u591a\u79cd\u6a21\u578b\uff0c\u8fd8\u663e\u8457\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u3002", "conclusion": "\u7279\u5b9a\u9886\u57df\u5fae\u8c03\u662f\u8fde\u63a5\u975e\u7ed3\u6784\u5316\u91d1\u878d\u6587\u6863\u548c\u4e0b\u6e38\u81ea\u52a8\u5316\u7684\u6709\u6548\u9ad8\u6548\u65b9\u6cd5\uff0c\u53ef\u5ab2\u7f8e\u5927\u578b\u901a\u7528\u6a21\u578b\u4e14\u65e0\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2508.05988", "pdf": "https://arxiv.org/pdf/2508.05988", "abs": "https://arxiv.org/abs/2508.05988", "authors": ["Wenhao Zeng", "Yaoning Wang", "Chao Hu", "Yuling Shi", "Chengcheng Wan", "Hongyu Zhang", "Xiaodong Gu"], "title": "Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal", "categories": ["cs.LG", "cs.SE"], "comment": "Code and model available at https://github.com/Zengwh02/ASAP", "summary": "Recently, Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in code reasoning by scaling up the length of Chain-of-Thought\n(CoT). However, excessively long reasoning traces introduce substantial\nchallenges in terms of training cost, inference latency, and deployment\nfeasibility. While various CoT compression approaches have emerged to address\nthis challenge, they face inherent trade-offs: token-level methods often\ndisrupt syntactic and logical coherence, while step-level methods based on\nperplexity fail to reliably capture the logically critical reasoning steps. In\nthis paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel\ncoarse-to-fine framework for CoT compression. ASAP first performs anchor-guided\npruning to preserve the core reasoning structure, which efficiently reduces the\nsearch space for subsequent processing. It then enables a logic-aware pruning\nby selecting logically essential reasoning steps based on a novel first-token\nsurprisal metric. Finally, ASAP teaches models to autonomously generate and\nleverage these concise CoTs at inference time, enabling efficient reasoning in\ncoding tasks. Experiments show that ASAP achieves state-of-the-art accuracy\nacross multiple code generation benchmarks while substantially reducing\ntraining and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,\nour approach reduces token generation by 23.5% and inference latency by 43.5%\ncompared to the strongest baseline, while achieving a competitive accuracy of\n36.19% in Pass@1. Our results highlight a promising direction for building\npowerful and efficient LRMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faASAP\u6846\u67b6\u7528\u4e8e\u538b\u7f29Chain-of-Thought\uff0c\u964d\u4f4e\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\uff0c\u5728\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709CoT\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u6743\u8861\u95ee\u9898\uff0c\u957f\u63a8\u7406\u8f68\u8ff9\u5e26\u6765\u8bad\u7ec3\u6210\u672c\u3001\u63a8\u7406\u5ef6\u8fdf\u548c\u90e8\u7f72\u53ef\u884c\u6027\u6311\u6218\u3002", "method": "\u63d0\u51faASAP\u6846\u67b6\uff0c\u5148\u8fdb\u884c\u951a\u5b9a\u5f15\u5bfc\u526a\u679d\u4fdd\u7559\u6838\u5fc3\u63a8\u7406\u7ed3\u6784\uff0c\u518d\u57fa\u4e8e\u9996\u4ee4\u724c\u610f\u5916\u6027\u6307\u6807\u8fdb\u884c\u903b\u8f91\u611f\u77e5\u526a\u679d\uff0c\u8ba9\u6a21\u578b\u5728\u63a8\u7406\u65f6\u81ea\u4e3b\u751f\u6210\u548c\u5229\u7528\u7b80\u6d01CoT\u3002", "result": "\u5728\u591a\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u51c6\u786e\u7387\uff0c\u5728LiveCodeBench v4_v5\u57fa\u51c6\u4e0a\uff0c\u51cf\u5c1123.5%\u7684\u4ee4\u724c\u751f\u6210\u548c43.5%\u7684\u63a8\u7406\u5ef6\u8fdf\uff0cPass@1\u51c6\u786e\u7387\u8fbe36.19%\u3002", "conclusion": "\u4e3a\u6784\u5efa\u5f3a\u5927\u9ad8\u6548\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2508.06230", "pdf": "https://arxiv.org/pdf/2508.06230", "abs": "https://arxiv.org/abs/2508.06230", "authors": ["Ruben Sharma", "Sebastijan Duman\u010di\u0107", "Ross D. King", "Andrew Cropper"], "title": "Learning Logical Rules using Minimum Message Length", "categories": ["cs.AI"], "comment": null, "summary": "Unifying probabilistic and logical learning is a key challenge in AI. We\nintroduce a Bayesian inductive logic programming approach that learns minimum\nmessage length programs from noisy data. Our approach balances hypothesis\ncomplexity and data fit through priors, which explicitly favour more general\nprograms, and a likelihood that favours accurate programs. Our experiments on\nseveral domains, including game playing and drug design, show that our method\nsignificantly outperforms previous methods, notably those that learn minimum\ndescription length programs. Our results also show that our approach is\ndata-efficient and insensitive to example balance, including the ability to\nlearn from exclusively positive examples.", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u65b9\u6cd5\uff0c\u4ece\u566a\u58f0\u6570\u636e\u5b66\u4e60\u6700\u5c0f\u6d88\u606f\u957f\u5ea6\u7a0b\u5e8f\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u4e14\u6570\u636e\u9ad8\u6548\u3002", "motivation": "\u89e3\u51b3\u4eba\u5de5\u667a\u80fd\u4e2d\u6982\u7387\u548c\u903b\u8f91\u5b66\u4e60\u7edf\u4e00\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u5f15\u5165\u8d1d\u53f6\u65af\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5148\u9a8c\u5e73\u8861\u5047\u8bbe\u590d\u6742\u5ea6\u548c\u6570\u636e\u62df\u5408\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u6570\u636e\u9ad8\u6548\u4e14\u5bf9\u793a\u4f8b\u5e73\u8861\u4e0d\u654f\u611f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u6982\u7387\u548c\u903b\u8f91\u5b66\u4e60\u7edf\u4e00\u95ee\u9898\uff0c\u5177\u6709\u4f18\u8d8a\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.05672", "pdf": "https://arxiv.org/pdf/2508.05672", "abs": "https://arxiv.org/abs/2508.05672", "authors": ["Yao Zhao", "Yantian Ding", "Zhiyue Zhang", "Dapeng Yao", "Yanxun Xu"], "title": "LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) systems often struggle with\ndomain-specific knowledge due to performance deterioration of pre-trained\nembeddings and prohibitive computational costs of large language model\n(LLM)-based retrievers. While fine-tuning data augmentation embedding models\noffers a promising direction, its effectiveness is limited by the need for\nhigh-quality training data and reliable chunking strategies that preserve\ncontextual integrity. We propose LMAR (Language Model Augmented Retriever), a\nmodel-agnostic framework that addresses these challenges by combining\nLLM-guided data synthesis with contrastive embedding adaptation and efficient\ntext clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling\nand synthetic data augmentation, where LLMs act as both labeler and validator\nto ensure high-fidelity supervision throughout the pipeline. Experimental\nresults across multiple domain-specific benchmark datasets demonstrate that\nLMAR outperforms multiple baseline models, while maintaining moderate hardware\nrequirements and low latency. Its model-agnostic nature further enables\nseamless integration with emerging RAG architectures and text embedding models,\nensuring continual improvements without redesigning the pipeline. These results\nhighlight LMAR as a practical and cost-effective solution for scalable\ndomain-specific adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLMAR\u6846\u67b6\u89e3\u51b3RAG\u7cfb\u7edf\u5728\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u5904\u7406\u4e0a\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u662f\u5b9e\u7528\u4e14\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "RAG\u7cfb\u7edf\u5728\u5904\u7406\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u65f6\uff0c\u56e0\u9884\u8bad\u7ec3\u5d4c\u5165\u6027\u80fd\u4e0b\u964d\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u7d22\u5668\u8ba1\u7b97\u6210\u672c\u9ad8\u800c\u9762\u4e34\u6311\u6218\uff0c\u4e14\u5fae\u8c03\u6570\u636e\u589e\u5f3a\u5d4c\u5165\u6a21\u578b\u6548\u679c\u53d7\u9650\u3002", "method": "\u63d0\u51faLMAR\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5bfc\u7684\u6570\u636e\u5408\u6210\u3001\u5bf9\u6bd4\u5d4c\u5165\u9002\u914d\u548c\u9ad8\u6548\u6587\u672c\u805a\u7c7b\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff0c\u5728\u7b2c\u4e00\u9636\u6bb5\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u6807\u6ce8\u5668\u548c\u9a8c\u8bc1\u5668\u3002", "result": "\u5728\u591a\u4e2a\u7279\u5b9a\u9886\u57df\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLMAR\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u6a21\u578b\uff0c\u786c\u4ef6\u8981\u6c42\u9002\u4e2d\u3001\u5ef6\u8fdf\u4f4e\uff0c\u4e14\u80fd\u4e0e\u65b0\u5174RAG\u67b6\u6784\u548c\u6587\u672c\u5d4c\u5165\u6a21\u578b\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "LMAR\u662f\u53ef\u6269\u5c55\u7684\u7279\u5b9a\u9886\u57df\u9002\u914d\u7684\u5b9e\u7528\u4e14\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05995", "pdf": "https://arxiv.org/pdf/2508.05995", "abs": "https://arxiv.org/abs/2508.05995", "authors": ["Fei Xu Yu", "Gina Adam", "Nathaniel D. Bastian", "Tian Lan"], "title": "Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode generation and structured reasoning; however, their performance often\ndegrades on complex tasks that require consistent multi-step planning. Recent\nwork has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet\nexisting approaches primarily focus on generating heuristic-based code for\noptimization or target simpler tasks where correctness alone is sufficient. In\nthis work, we propose MCTS-OPS, a novel neural-symbolic framework that\nformulates prompt selection as a sequential decision process guided by MCTS.\nOur method explores and refines multi-step prompt sequences for the goal of\nimproving code generation quality and enhancing the problem-solving\ncapabilities of LLMs in general optimization. Experiments on network\noptimization show significant improvement over the baselines, both in the\nsuccess rate of executing the generated code and in the optimization results\nwith the specified objective and constraints (2$\\sim$4$\\times$ higher reward\nand 3$\\times$ lower standard deviation). Moreover, it improves the chance of\nattaining the optimal solution by about 10\\% of cases, compared to baseline\nmethods in hard problems. These results highlight the promise of combining\nsymbolic planning with LLMs for robust, high-quality code generation in complex\ndomains.", "AI": {"tldr": "\u63d0\u51faMCTS - OPS\u6846\u67b6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u548c\u89e3\u51b3\u95ee\u9898\u80fd\u529b\uff0c\u5b9e\u9a8c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u591a\u6b65\u89c4\u5212\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u7ed3\u5408\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\u7684\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faMCTS - OPS\u6846\u67b6\uff0c\u5c06\u63d0\u793a\u9009\u62e9\u4f5c\u4e3a\u7531\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\u5f15\u5bfc\u7684\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\uff0c\u63a2\u7d22\u548c\u4f18\u5316\u591a\u6b65\u63d0\u793a\u5e8f\u5217\u3002", "result": "\u7f51\u7edc\u4f18\u5316\u5b9e\u9a8c\u4e2d\uff0c\u751f\u6210\u4ee3\u7801\u6267\u884c\u6210\u529f\u7387\u3001\u4f18\u5316\u7ed3\u679c\u3001\u83b7\u5f97\u6700\u4f18\u89e3\u7684\u673a\u4f1a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7b26\u53f7\u89c4\u5212\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u5728\u590d\u6742\u9886\u57df\u9ad8\u8d28\u91cf\u4ee3\u7801\u751f\u6210\u65b9\u9762\u6709\u524d\u666f\u3002"}}
{"id": "2508.06263", "pdf": "https://arxiv.org/pdf/2508.06263", "abs": "https://arxiv.org/abs/2508.06263", "authors": ["Andrew Cropper", "David M. Cerna", "Matti J\u00e4rvisalo"], "title": "Symmetry breaking for inductive logic programming", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The goal of inductive logic programming is to search for a hypothesis that\ngeneralises training data and background knowledge. The challenge is searching\nvast hypothesis spaces, which is exacerbated because many logically equivalent\nhypotheses exist. To address this challenge, we introduce a method to break\nsymmetries in the hypothesis space. We implement our idea in answer set\nprogramming. Our experiments on multiple domains, including visual reasoning\nand game playing, show that our approach can reduce solving times from over an\nhour to just 17 seconds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7834\u5bf9\u79f0\u65b9\u6cd5\u89e3\u51b3\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u4e2d\u641c\u7d22\u5047\u8bbe\u7a7a\u95f4\u7684\u6311\u6218\uff0c\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u51cf\u5c11\u6c42\u89e3\u65f6\u95f4\u3002", "motivation": "\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u9700\u641c\u7d22\u5047\u8bbe\u7a7a\u95f4\uff0c\u5b58\u5728\u5927\u91cf\u903b\u8f91\u7b49\u4ef7\u5047\u8bbe\uff0c\u641c\u7d22\u96be\u5ea6\u5927\u3002", "method": "\u5f15\u5165\u7834\u5bf9\u79f0\u65b9\u6cd5\u5e76\u5728\u7b54\u6848\u96c6\u7f16\u7a0b\u4e2d\u5b9e\u73b0\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u5b9e\u9a8c\u4e2d\uff0c\u5c06\u6c42\u89e3\u65f6\u95f4\u4ece\u8d851\u5c0f\u65f6\u964d\u81f317\u79d2\u3002", "conclusion": "\u6240\u63d0\u7834\u5bf9\u79f0\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b\u7684\u6c42\u89e3\u65f6\u95f4\u3002"}}
{"id": "2508.05673", "pdf": "https://arxiv.org/pdf/2508.05673", "abs": "https://arxiv.org/abs/2508.05673", "authors": ["Weiqin Yang", "Jiawei Chen", "Shengjia Zhang", "Peng Wu", "Yuegang Sun", "Yan Feng", "Chun Chen", "Can Wang"], "title": "Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": "Accepted by KDD 2025", "summary": "In the realm of recommender systems (RS), Top-$K$ ranking metrics such as\nNDCG@$K$ are the gold standard for evaluating recommendation performance.\nHowever, during the training of recommendation models, optimizing NDCG@$K$\nposes significant challenges due to its inherent discontinuous nature and the\nintricate Top-$K$ truncation. Recent efforts to optimize NDCG@$K$ have either\noverlooked the Top-$K$ truncation or suffered from high computational costs and\ntraining instability. To overcome these limitations, we propose SoftmaxLoss@$K$\n(SL@$K$), a novel recommendation loss tailored for NDCG@$K$ optimization.\nSpecifically, we integrate the quantile technique to handle Top-$K$ truncation\nand derive a smooth upper bound for optimizing NDCG@$K$ to address\ndiscontinuity. The resulting SL@$K$ loss has several desirable properties,\nincluding theoretical guarantees, ease of implementation, computational\nefficiency, gradient stability, and noise robustness. Extensive experiments on\nfour real-world datasets and three recommendation backbones demonstrate that\nSL@$K$ outperforms existing losses with a notable average improvement of 6.03%.\nThe code is available at https://github.com/Tiny-Snow/IR-Benchmark.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u4f18\u5316NDCG@K\u7684SoftmaxLoss@$K$ (SL@$K$)\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u73b0\u6709\u4f18\u5316NDCG@$K$\u7684\u65b9\u6cd5\u5b58\u5728\u5ffd\u7565Top - K\u622a\u65ad\u3001\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSL@$K$\u635f\u5931\u51fd\u6570\uff0c\u96c6\u6210\u5206\u4f4d\u6570\u6280\u672f\u5904\u7406Top - K\u622a\u65ad\uff0c\u63a8\u5bfc\u5e73\u6ed1\u4e0a\u754c\u89e3\u51b3\u4e0d\u8fde\u7eed\u6027\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u63a8\u8350\u9aa8\u5e72\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0cSL@$K$\u5e73\u5747\u63d0\u53476.03%\uff0c\u4f18\u4e8e\u73b0\u6709\u635f\u5931\u51fd\u6570\u3002", "conclusion": "SL@$K$\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u3001\u6613\u5b9e\u73b0\u3001\u8ba1\u7b97\u9ad8\u6548\u3001\u68af\u5ea6\u7a33\u5b9a\u548c\u6297\u566a\u7b49\u4f18\u70b9\uff0c\u662f\u4f18\u5316NDCG@$K$\u7684\u6709\u6548\u635f\u5931\u51fd\u6570\u3002"}}
{"id": "2508.06023", "pdf": "https://arxiv.org/pdf/2508.06023", "abs": "https://arxiv.org/abs/2508.06023", "authors": ["Xiaobin Shen", "Jonathan Elmer", "George H. Chen"], "title": "Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients", "categories": ["cs.LG"], "comment": null, "summary": "Prognostication for comatose post-cardiac arrest patients is a critical\nchallenge that directly impacts clinical decision-making in the ICU. Clinical\ninformation that informs prognostication is collected serially over time.\nShortly after cardiac arrest, various time-invariant baseline features are\ncollected (e.g., demographics, cardiac arrest characteristics). After ICU\nadmission, additional features are gathered, including time-varying hemodynamic\ndata (e.g., blood pressure, doses of vasopressor medications). We view these as\ntwo phases in which we collect new features. In this study, we propose a novel\nstepwise dynamic competing risks model that improves the prediction of\nneurological outcomes by automatically determining when to take advantage of\ntime-invariant features (first phase) and time-varying features (second phase).\nNotably, our model finds patients for whom this second phase (time-varying\nhemodynamic) information is beneficial for prognostication and also when this\ninformation is beneficial (as we collect more hemodynamic data for a patient\nover time, how important these data are for prognostication varies). Our\napproach extends the standard Fine and Gray model to explicitly model the two\nphases and to incorporate neural networks to flexibly capture complex nonlinear\nfeature relationships. Evaluated on a retrospective cohort of 2,278 comatose\npost-arrest patients, our model demonstrates robust discriminative performance\nfor the competing outcomes of awakening, withdrawal of life-sustaining therapy,\nand death despite maximal support. Our approach generalizes to more than two\nphases in which new features are collected and could be used in other dynamic\nprediction tasks, where it may be helpful to know when and for whom newly\ncollected features significantly improve prediction.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u9010\u6b65\u52a8\u6001\u7ade\u4e89\u98ce\u9669\u6a21\u578b\uff0c\u7528\u4e8e\u6539\u5584\u5fc3\u810f\u9aa4\u505c\u540e\u660f\u8ff7\u60a3\u8005\u795e\u7ecf\u7ed3\u5c40\u9884\u6d4b\uff0c\u5728\u56de\u987e\u6027\u961f\u5217\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u53ef\u63a8\u5e7f\u5230\u591a\u9636\u6bb5\u7279\u5f81\u6536\u96c6\u548c\u5176\u4ed6\u52a8\u6001\u9884\u6d4b\u4efb\u52a1\u3002", "motivation": "\u5fc3\u810f\u9aa4\u505c\u540e\u660f\u8ff7\u60a3\u8005\u7684\u9884\u540e\u9884\u6d4b\u662fICU\u4e34\u5e8a\u51b3\u7b56\u7684\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709\u4e34\u5e8a\u4fe1\u606f\u5206\u9636\u6bb5\u6536\u96c6\uff0c\u9700\u66f4\u597d\u5229\u7528\u4e0d\u540c\u9636\u6bb5\u7279\u5f81\u8fdb\u884c\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u9010\u6b65\u52a8\u6001\u7ade\u4e89\u98ce\u9669\u6a21\u578b\uff0c\u6269\u5c55\u6807\u51c6Fine\u548cGray\u6a21\u578b\uff0c\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u590d\u6742\u975e\u7ebf\u6027\u7279\u5f81\u5173\u7cfb\u3002", "result": "\u57282278\u4f8b\u60a3\u8005\u7684\u56de\u987e\u6027\u961f\u5217\u4e2d\uff0c\u6a21\u578b\u5bf9\u82cf\u9192\u3001\u64a4\u6389\u7ef4\u6301\u751f\u547d\u6cbb\u7597\u548c\u6700\u5927\u652f\u6301\u4e0b\u6b7b\u4ea1\u7b49\u7ade\u4e89\u7ed3\u5c40\u6709\u5f3a\u5927\u5224\u522b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u63a8\u5e7f\u5230\u591a\u9636\u6bb5\u7279\u5f81\u6536\u96c6\u60c5\u51b5\uff0c\u9002\u7528\u4e8e\u5176\u4ed6\u52a8\u6001\u9884\u6d4b\u4efb\u52a1\uff0c\u6709\u52a9\u4e8e\u4e86\u89e3\u65b0\u7279\u5f81\u4f55\u65f6\u53ca\u5bf9\u8c01\u80fd\u663e\u8457\u6539\u5584\u9884\u6d4b\u3002"}}
{"id": "2508.06296", "pdf": "https://arxiv.org/pdf/2508.06296", "abs": "https://arxiv.org/abs/2508.06296", "authors": ["Pierre Peign\u00e9 - Lefebvre", "Quentin Feuillade-Montixi", "Tom David", "Nicolas Miailhe"], "title": "LLM Robustness Leaderboard v1 --Technical report", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "This technical report accompanies the LLM robustness leaderboard published by\nPRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior\nElicitation Tool (BET), an AI system performing automated red-teaming through\nDynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)\nagainst 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we\npropose a fine-grained robustness metric estimating the average number of\nattempts required to elicit harmful behaviors, revealing that attack difficulty\nvaries by over 300-fold across models despite universal vulnerability. We\nintroduce primitive-level vulnerability analysis to identify which jailbreaking\ntechniques are most effective for specific hazard categories. Our collaborative\nevaluation with trusted third parties from the AI Safety Network demonstrates\npractical pathways for distributed robustness assessment across the community.", "AI": {"tldr": "\u4ecb\u7ecdPRISM Eval\u7684BET\u5de5\u5177\u7528\u4e8eLLM\u7ea2\u961f\u6d4b\u8bd5\uff0c\u6709\u9ad8\u6210\u529f\u7387\uff0c\u63d0\u51fa\u7ec6\u7c92\u5ea6\u6307\u6807\u548c\u539f\u59cb\u7ea7\u6f0f\u6d1e\u5206\u6790\uff0c\u5c55\u793a\u5206\u5e03\u5f0f\u8bc4\u4f30\u9014\u5f84\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528BET\u5de5\u5177\u8fdb\u884c\u52a8\u6001\u5bf9\u6297\u4f18\u5316\u7684\u81ea\u52a8\u5316\u7ea2\u961f\u6d4b\u8bd5\uff0c\u63d0\u51fa\u7ec6\u7c92\u5ea6\u9c81\u68d2\u6027\u6307\u6807\u548c\u539f\u59cb\u7ea7\u6f0f\u6d1e\u5206\u6790\u3002", "result": "\u5bf941\u4e2a\u6a21\u578b\u4e2d\u768437\u4e2a\u5b9e\u73b0100%\u653b\u51fb\u6210\u529f\u7387\uff0c\u53d1\u73b0\u6a21\u578b\u653b\u51fb\u96be\u5ea6\u5dee\u5f02\u5927\uff0c\u786e\u5b9a\u4e0d\u540c\u5371\u5bb3\u7c7b\u522b\u6709\u6548\u7684\u8d8a\u72f1\u6280\u672f\u3002", "conclusion": "\u5c55\u793a\u4e86\u793e\u533a\u5206\u5e03\u5f0f\u9c81\u68d2\u6027\u8bc4\u4f30\u7684\u5b9e\u7528\u9014\u5f84\u3002"}}
{"id": "2508.05676", "pdf": "https://arxiv.org/pdf/2508.05676", "abs": "https://arxiv.org/abs/2508.05676", "authors": ["Han Gao", "Timo Hartmann", "Botao Zhong", "Kai Lia", "Hanbin Luo"], "title": "Domain-Specific Fine-Tuning and Prompt-Based Learning: A Comparative Study for developing Natural Language-Based BIM Information Retrieval Systems", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Building Information Modeling (BIM) is essential for managing building data\nacross the entire lifecycle, supporting tasks from design to maintenance.\nNatural Language Interface (NLI) systems are increasingly explored as\nuser-friendly tools for information retrieval in Building Information Modeling\n(BIM) environments. Despite their potential, accurately extracting BIM-related\ndata through natural language queries remains a persistent challenge due to the\ncomplexity use queries and specificity of domain knowledge. This study presents\na comparative analysis of two prominent approaches for developing NLI-based BIM\ninformation retrieval systems: domain-specific fine-tuning and prompt-based\nlearning using large language models (LLMs). A two-stage framework consisting\nof intent recognition and table-based question answering is implemented to\nevaluate the effectiveness of both approaches. To support this evaluation, a\nBIM-specific dataset of 1,740 annotated queries of varying types across 69\nmodels is constructed. Experimental results show that domain-specific\nfine-tuning delivers superior performance in intent recognition tasks, while\nprompt-based learning, particularly with GPT-4o, shows strength in table-based\nquestion answering. Based on these findings, this study identify a hybrid\nconfiguration that combines fine-tuning for intent recognition with\nprompt-based learning for question answering, achieving more balanced and\nrobust performance across tasks. This integrated approach is further tested\nthrough case studies involving BIM models of varying complexity. This study\nprovides a systematic analysis of the strengths and limitations of each\napproach and discusses the applicability of the NLI to real-world BIM\nscenarios. The findings offer insights for researchers and practitioners in\ndesigning intelligent, language-driven BIM systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u5206\u6790\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\uff08NLI\uff09\u7684\u5efa\u7b51\u4fe1\u606f\u6a21\u578b\uff08BIM\uff09\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u4e24\u79cd\u65b9\u6cd5\uff0c\u6784\u5efa\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u5f97\u51fa\u6df7\u5408\u914d\u7f6e\u65b9\u6cd5\u5e76\u6d4b\u8bd5\uff0c\u4e3a\u8bbe\u8ba1\u667a\u80fdBIM\u7cfb\u7edf\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u51c6\u786e\u63d0\u53d6BIM\u76f8\u5173\u6570\u636e\u5b58\u5728\u6311\u6218\uff0c\u9700\u7814\u7a76\u6709\u6548\u5f00\u53d1NLI\u7684BIM\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u65b9\u6cd5\u3002", "method": "\u5bf9\u6bd4\u5206\u6790\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u4e0e\u57fa\u4e8e\u63d0\u793a\u5b66\u4e60\u4e24\u79cd\u65b9\u6cd5\uff0c\u5b9e\u65bd\u7531\u610f\u56fe\u8bc6\u522b\u548c\u57fa\u4e8e\u8868\u683c\u95ee\u7b54\u7ec4\u6210\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u6784\u5efaBIM\u7279\u5b9a\u6570\u636e\u96c6\u8bc4\u4f30\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u6d4b\u8bd5\u6df7\u5408\u914d\u7f6e\u65b9\u6cd5\u3002", "result": "\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u5728\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u57fa\u4e8e\u63d0\u793a\u5b66\u4e60\uff08\u5c24\u5176\u662fGPT - 4o\uff09\u5728\u57fa\u4e8e\u8868\u683c\u95ee\u7b54\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6df7\u5408\u914d\u7f6e\u65b9\u6cd5\u5728\u5404\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u5e73\u8861\u7a33\u5065\u3002", "conclusion": "\u5bf9\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u8ba8\u8bbaNLI\u5728\u73b0\u5b9eBIM\u573a\u666f\u7684\u9002\u7528\u6027\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u8bbe\u8ba1\u667a\u80fd\u8bed\u8a00\u9a71\u52a8\u7684BIM\u7cfb\u7edf\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2508.06034", "pdf": "https://arxiv.org/pdf/2508.06034", "abs": "https://arxiv.org/abs/2508.06034", "authors": ["Qin Chen", "Guojie Song"], "title": "Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted tp CIKM 2025", "summary": "Heterogeneous graphs (HGs) are common in real-world scenarios and often\nexhibit heterophily. However, most existing studies focus on either\nheterogeneity or heterophily in isolation, overlooking the prevalence of\nheterophilic HGs in practical applications. Such ignorance leads to their\nperformance degradation. In this work, we first identify two main challenges in\nmodeling heterophily HGs: (1) varying heterophily distributions across hops and\nmeta-paths; (2) the intricate and often heterophily-driven diversity of\nsemantic information across different meta-paths. Then, we propose the Adaptive\nHeterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN\nemploys a heterophily-aware convolution that accounts for heterophily\ndistributions specific to both hops and meta-paths. It then integrates messages\nfrom diverse semantic spaces using a coarse-to-fine attention mechanism, which\nfilters out noise and emphasizes informative signals. Experiments on seven\nreal-world graphs and twenty baselines demonstrate the superior performance of\nAHGNN, particularly in high-heterophily situations.", "AI": {"tldr": "\u73b0\u6709HG\u7814\u7a76\u5ffd\u89c6\u5f02\u8d28\u6027\u548c\u5f02\u8d28\u6027\u5e76\u5b58\u95ee\u9898\uff0c\u63d0\u51faAHGNN\u6a21\u578b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5b64\u7acb\u5904\u7406\u5f02\u8d28\u6027\u548c\u5f02\u8d28\u6027\uff0c\u5ffd\u89c6\u5f02\u8d28\u6027HG\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u666e\u904d\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faAHGNN\uff0c\u91c7\u7528\u5f02\u8d28\u6027\u611f\u77e5\u5377\u79ef\uff0c\u4f7f\u7528\u7c97\u5230\u7ec6\u7684\u6ce8\u610f\u529b\u673a\u5236\u6574\u5408\u6d88\u606f\u3002", "result": "\u5728\u4e03\u4e2a\u771f\u5b9e\u56fe\u548c\u4e8c\u5341\u4e2a\u57fa\u7ebf\u5b9e\u9a8c\u4e2d\uff0cAHGNN\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176\u5728\u9ad8\u5f02\u8d28\u6027\u60c5\u51b5\u4e0b\u3002", "conclusion": "AHGNN\u80fd\u6709\u6548\u5904\u7406\u5f02\u8d28\u6027HG\u5efa\u6a21\u4e2d\u7684\u6311\u6218\u3002"}}
{"id": "2508.06326", "pdf": "https://arxiv.org/pdf/2508.06326", "abs": "https://arxiv.org/abs/2508.06326", "authors": ["Nathaniel Virgo", "Martin Biehl", "Manuel Baltieri", "Matteo Capucci"], "title": "A \"good regulator theorem\" for embodied agents", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "Accepted at the Artificial Life conference 2025 (ALife 2025). 10\n  pages, 1 figure", "summary": "In a classic paper, Conant and Ashby claimed that \"every good regulator of a\nsystem must be a model of that system.\" Artificial Life has produced many\nexamples of systems that perform tasks with apparently no model in sight; these\nsuggest Conant and Ashby's theorem doesn't easily generalise beyond its\nrestricted setup. Nevertheless, here we show that a similar intuition can be\nfleshed out in a different way: whenever an agent is able to perform a\nregulation task, it is possible for an observer to interpret it as having\n\"beliefs\" about its environment, which it \"updates\" in response to sensory\ninput. This notion of belief updating provides a notion of model that is more\nsophisticated than Conant and Ashby's, as well as a theorem that is more\nbroadly applicable. However, it necessitates a change in perspective, in that\nthe observer plays an essential role in the theory: models are not a mere\nproperty of the system but are imposed on it from outside. Our theorem holds\nregardless of whether the system is regulating its environment in a classic\ncontrol theory setup, or whether it's regulating its own internal state; the\nmodel is of its environment either way. The model might be trivial, however,\nand this is how the apparent counterexamples are resolved.", "AI": {"tldr": "\u7814\u7a76\u6307\u51fa\u5f53\u667a\u80fd\u4f53\u6267\u884c\u8c03\u8282\u4efb\u52a1\u65f6\uff0c\u89c2\u5bdf\u8005\u53ef\u5c06\u5176\u89e3\u8bfb\u4e3a\u6709\u5173\u4e8e\u73af\u5883\u7684\u2018\u4fe1\u5ff5\u2019\u5e76\u66f4\u65b0\uff0c\u6b64\u4fe1\u5ff5\u66f4\u65b0\u6982\u5ff5\u63d0\u4f9b\u4e86\u6bd4Conant\u548cAshby\u66f4\u590d\u6742\u3001\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u6a21\u578b\u6982\u5ff5\u3002", "motivation": "Conant\u548cAshby\u7684\u5b9a\u7406\u96be\u4ee5\u5728\u53d7\u9650\u8bbe\u7f6e\u5916\u63a8\u5e7f\uff0c\u9700\u4ee5\u4e0d\u540c\u65b9\u5f0f\u9610\u8ff0\u7c7b\u4f3c\u76f4\u89c9\u3002", "method": "\u5206\u6790\u667a\u80fd\u4f53\u6267\u884c\u8c03\u8282\u4efb\u52a1\u65f6\u89c2\u5bdf\u8005\u5bf9\u5176\u7684\u89e3\u8bfb\u3002", "result": "\u5f97\u5230\u4e86\u6bd4Conant\u548cAshby\u66f4\u590d\u6742\u3001\u66f4\u5e7f\u6cdb\u9002\u7528\u7684\u6a21\u578b\u6982\u5ff5\u53ca\u5b9a\u7406\uff0c\u4e14\u89c2\u5bdf\u8005\u5728\u7406\u8bba\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u5b9a\u7406\u9002\u7528\u4e8e\u7ecf\u5178\u63a7\u5236\u7406\u8bba\u8bbe\u7f6e\u6216\u8c03\u8282\u81ea\u8eab\u5185\u90e8\u72b6\u6001\u7684\u7cfb\u7edf\uff0c\u6a21\u578b\u53ef\u80fd\u5e73\u51e1\uff0c\u53ef\u89e3\u51b3\u660e\u663e\u53cd\u4f8b\u95ee\u9898\u3002"}}
{"id": "2508.05680", "pdf": "https://arxiv.org/pdf/2508.05680", "abs": "https://arxiv.org/abs/2508.05680", "authors": ["Stefanie Urchs", "Veronika Thurner", "Matthias A\u00dfenmacher", "Ludwig Bothmann", "Christian Heumann", "Stephanie Thiemichen"], "title": "Are All Genders Equal in the Eyes of Algorithms? -- Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Algorithmic systems such as search engines and information retrieval\nplatforms significantly influence academic visibility and the dissemination of\nknowledge. Despite assumptions of neutrality, these systems can reproduce or\nreinforce societal biases, including those related to gender. This paper\nintroduces and applies a bias-preserving definition of algorithmic gender\nfairness, which assesses whether algorithmic outputs reflect real-world gender\ndistributions without introducing or amplifying disparities. Using a\nheterogeneous dataset of academic profiles from German universities and\nuniversities of applied sciences, we analyse gender differences in metadata\ncompleteness, publication retrieval in academic databases, and visibility in\nGoogle search results. While we observe no overt algorithmic discrimination,\nour findings reveal subtle but consistent imbalances: male professors are\nassociated with a greater number of search results and more aligned publication\nrecords, while female professors display higher variability in digital\nvisibility. These patterns reflect the interplay between platform algorithms,\ninstitutional curation, and individual self-presentation. Our study highlights\nthe need for fairness evaluations that account for both technical performance\nand representational equality in digital systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7b97\u6cd5\u7cfb\u7edf\u7684\u6027\u522b\u516c\u5e73\u6027\uff0c\u7528\u5fb7\u56fd\u9ad8\u6821\u5b66\u672f\u8d44\u6599\u5206\u6790\uff0c\u53d1\u73b0\u867d\u65e0\u660e\u663e\u7b97\u6cd5\u6b67\u89c6\uff0c\u4f46\u5b58\u5728\u6027\u522b\u5dee\u5f02\uff0c\u5f3a\u8c03\u6570\u5b57\u7cfb\u7edf\u516c\u5e73\u8bc4\u4f30\u9700\u517c\u987e\u6280\u672f\u8868\u73b0\u548c\u4ee3\u8868\u6027\u5e73\u7b49\u3002", "motivation": "\u7b97\u6cd5\u7cfb\u7edf\u867d\u88ab\u8ba4\u4e3a\u4e2d\u7acb\uff0c\u4f46\u53ef\u80fd\u518d\u73b0\u6216\u5f3a\u5316\u5305\u62ec\u6027\u522b\u5728\u5185\u7684\u793e\u4f1a\u504f\u89c1\uff0c\u9700\u8bc4\u4f30\u5176\u6027\u522b\u516c\u5e73\u6027\u3002", "method": "\u5f15\u5165\u5e76\u5e94\u7528\u7b97\u6cd5\u6027\u522b\u516c\u5e73\u7684\u4fdd\u504f\u5b9a\u4e49\uff0c\u4f7f\u7528\u5fb7\u56fd\u9ad8\u6821\u5b66\u672f\u8d44\u6599\u6570\u636e\u96c6\uff0c\u5206\u6790\u5143\u6570\u636e\u5b8c\u6574\u6027\u3001\u5b66\u672f\u6570\u636e\u5e93\u51fa\u7248\u7269\u68c0\u7d22\u548c\u8c37\u6b4c\u641c\u7d22\u7ed3\u679c\u53ef\u89c1\u6027\u7684\u6027\u522b\u5dee\u5f02\u3002", "result": "\u672a\u89c2\u5bdf\u5230\u660e\u663e\u7b97\u6cd5\u6b67\u89c6\uff0c\u4f46\u5b58\u5728\u5fae\u5999\u4e14\u6301\u7eed\u7684\u4e0d\u5e73\u8861\uff0c\u7537\u6027\u6559\u6388\u641c\u7d22\u7ed3\u679c\u591a\u3001\u51fa\u7248\u7269\u8bb0\u5f55\u66f4\u5339\u914d\uff0c\u5973\u6027\u6559\u6388\u6570\u5b57\u53ef\u89c1\u6027\u53d8\u5f02\u6027\u66f4\u9ad8\u3002", "conclusion": "\u6570\u5b57\u7cfb\u7edf\u7684\u516c\u5e73\u8bc4\u4f30\u9700\u517c\u987e\u6280\u672f\u8868\u73b0\u548c\u4ee3\u8868\u6027\u5e73\u7b49\u3002"}}
{"id": "2508.06041", "pdf": "https://arxiv.org/pdf/2508.06041", "abs": "https://arxiv.org/abs/2508.06041", "authors": ["Sangwoo Kwon", "Seong Hoon Seo", "Jae W. Lee", "Yeonhong Park"], "title": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "How can we effectively handle queries for on-device large language models\n(LLMs) with varying runtime constraints, such as latency and accuracy?\nMulti-scale quantization addresses this challenge by enabling memory-efficient\nruntime model adaptation of LLMs through the overlaying of multiple model\nvariants quantized to different bitwidths. Meanwhile, an important question\nstill remains open-ended: how can models be properly configured to match a\ntarget precision or latency? While mixed-precision offers a promising solution,\nwe take this further by leveraging the key observation that the sensitivity of\neach layer dynamically changes across decoding iterations. Building on this\ninsight, we introduce DP-LLM, a novel mechanism that dynamically assigns\nprecision to each layer based on input values. DP-LLM augments each linear\nlayer in an LLM with a precision selector that determines the bitwidth at\nruntime using a lightweight error estimator and threshold values learned\nthrough fine-tuning. Experimental results across multiple models and benchmarks\ndemonstrate that DP-LLM achieves a superior performance-latency trade-off,\noutperforming prior approaches.", "AI": {"tldr": "\u63d0\u51faDP - LLM\u673a\u5236\u5904\u7406\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u67e5\u8be2\uff0c\u52a8\u6001\u5206\u914d\u5c42\u7cbe\u5ea6\uff0c\u5b9e\u9a8c\u8868\u660e\u6027\u80fd\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5", "motivation": "\u89e3\u51b3\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u8fd0\u884c\u65f6\u7ea6\u675f\u4e0b\u7684\u67e5\u8be2\u5904\u7406\u95ee\u9898\uff0c\u4ee5\u53ca\u6a21\u578b\u5982\u4f55\u5339\u914d\u76ee\u6807\u7cbe\u5ea6\u6216\u5ef6\u8fdf", "method": "\u5f15\u5165DP - LLM\u673a\u5236\uff0c\u4e3aLLM\u7684\u6bcf\u4e2a\u7ebf\u6027\u5c42\u589e\u52a0\u7cbe\u5ea6\u9009\u62e9\u5668\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bef\u5dee\u4f30\u8ba1\u5668\u548c\u5fae\u8c03\u5b66\u4e60\u7684\u9608\u503c\u5728\u8fd0\u884c\u65f6\u786e\u5b9a\u4f4d\u5bbd", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDP - LLM\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd - \u5ef6\u8fdf\u6743\u8861\uff0c\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5", "conclusion": "DP - LLM\u5728\u5904\u7406\u8bbe\u5907\u7aef\u5927\u8bed\u8a00\u6a21\u578b\u67e5\u8be2\u65b9\u9762\u5177\u6709\u4f18\u52bf"}}
{"id": "2508.06348", "pdf": "https://arxiv.org/pdf/2508.06348", "abs": "https://arxiv.org/abs/2508.06348", "authors": ["Mille Mei Zhen Loo", "Gert Luzkov", "Paolo Burelli"], "title": "AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games", "categories": ["cs.AI"], "comment": null, "summary": "Cheating in online video games compromises the integrity of gaming\nexperiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face\nsignificant challenges in keeping pace with evolving cheating methods without\nimposing invasive measures on users' systems. This paper presents\nAntiCheatPT\\_256, a transformer-based machine learning model designed to detect\ncheating behaviour in Counter-Strike 2 using gameplay data. To support this, we\nintroduce and publicly release CS2CD: A labelled dataset of 795 matches. Using\nthis dataset, 90,707 context windows were created and subsequently augmented to\naddress class imbalance. The transformer model, trained on these windows,\nachieved an accuracy of 89.17\\% and an AUC of 93.36\\% on an unaugmented test\nset. This approach emphasizes reproducibility and real-world applicability,\noffering a robust baseline for future research in data-driven cheat detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eTransformer\u7684AntiCheatPT_256\u6a21\u578b\u68c0\u6d4bCS2\u4f5c\u5f0a\u884c\u4e3a\uff0c\u516c\u5f00\u6570\u636e\u96c6CS2CD\uff0c\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u53d6\u5f97\u8f83\u597d\u6548\u679c\uff0c\u4e3a\u4f5c\u5f0a\u68c0\u6d4b\u7814\u7a76\u63d0\u4f9b\u57fa\u7ebf\u3002", "motivation": "\u5728\u7ebf\u6e38\u620f\u4f5c\u5f0a\u7834\u574f\u6e38\u620f\u4f53\u9a8c\uff0c\u73b0\u6709\u53cd\u4f5c\u5f0a\u7cfb\u7edf\u96be\u4ee5\u8ddf\u4e0a\u4f5c\u5f0a\u624b\u6bb5\u6f14\u53d8\u4e14\u907f\u514d\u5bf9\u7528\u6237\u7cfb\u7edf\u9020\u6210\u4fb5\u6270\u3002", "method": "\u63d0\u51faAntiCheatPT_256\u6a21\u578b\uff0c\u521b\u5efa\u5e76\u516c\u5f00CS2CD\u6570\u636e\u96c6\uff0c\u521b\u5efa\u4e0a\u4e0b\u6587\u7a97\u53e3\u5e76\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u4ee5\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7528\u8fd9\u4e9b\u7a97\u53e3\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u672a\u589e\u5f3a\u6d4b\u8bd5\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe89.17%\uff0cAUC\u4e3a93.36%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5f3a\u8c03\u53ef\u91cd\u590d\u6027\u548c\u5b9e\u9645\u5e94\u7528\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u4f5c\u5f0a\u68c0\u6d4b\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7ebf\u3002"}}
{"id": "2508.05688", "pdf": "https://arxiv.org/pdf/2508.05688", "abs": "https://arxiv.org/abs/2508.05688", "authors": ["Aleksei Shestov", "Omar Zoloev", "Maksim Makarenko", "Mikhail Orlov", "Egor Fadeev", "Ivan Kireev", "Andrey Savchenko"], "title": "LLM4ES: Learning User Embeddings from Event Sequences via Large Language Models", "categories": ["cs.IR"], "comment": null, "summary": "This paper presents LLM4ES, a novel framework that exploits large pre-trained\nlanguage models (LLMs) to derive user embeddings from event sequences. Event\nsequences are transformed into a textual representation, which is subsequently\nused to fine-tune an LLM through next-token prediction to generate high-quality\nembeddings. We introduce a text enrichment technique that enhances LLM\nadaptation to event sequence data, improving representation quality for\nlow-variability domains. Experimental results demonstrate that LLM4ES achieves\nstate-of-the-art performance in user classification tasks in financial and\nother domains, outperforming existing embedding methods. The resulting user\nembeddings can be incorporated into a wide range of applications, from user\nsegmentation in finance to patient outcome prediction in healthcare.", "AI": {"tldr": "\u63d0\u51faLLM4ES\u6846\u67b6\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u4e8b\u4ef6\u5e8f\u5217\u63a8\u5bfc\u7528\u6237\u5d4c\u5165\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u591a\u9886\u57df\u7528\u6237\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u4e14\u53ef\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u63a8\u5bfc\u7528\u6237\u5d4c\u5165\uff0c\u63d0\u5347\u4f4e\u53ef\u53d8\u6027\u9886\u57df\u7684\u8868\u793a\u8d28\u91cf\u3002", "method": "\u5c06\u4e8b\u4ef6\u5e8f\u5217\u8f6c\u6362\u4e3a\u6587\u672c\u8868\u793a\uff0c\u901a\u8fc7\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5f15\u5165\u6587\u672c\u4e30\u5bcc\u6280\u672f\u3002", "result": "LLM4ES\u5728\u91d1\u878d\u7b49\u9886\u57df\u7684\u7528\u6237\u5206\u7c7b\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u5d4c\u5165\u65b9\u6cd5\u3002", "conclusion": "\u751f\u6210\u7684\u7528\u6237\u5d4c\u5165\u53ef\u7528\u4e8e\u4ece\u91d1\u878d\u7528\u6237\u7ec6\u5206\u5230\u533b\u7597\u60a3\u8005\u7ed3\u679c\u9884\u6d4b\u7b49\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2508.06066", "pdf": "https://arxiv.org/pdf/2508.06066", "abs": "https://arxiv.org/abs/2508.06066", "authors": ["Barak Gahtan", "Alex M. Bronstein"], "title": "Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep temporal architectures such as Temporal Convolutional Networks (TCNs)\nachieve strong predictive performance on sequential data, yet theoretical\nunderstanding of their generalization remains limited. We address this gap by\nproviding both the first non-vacuous, architecture-aware generalization bounds\nfor deep temporal models and a principled evaluation methodology.\n  For exponentially $\\beta$-mixing sequences, we derive bounds scaling as $\nO\\!\\Bigl(R\\,\\sqrt{\\tfrac{D\\,p\\,n\\,\\log N}{N}}\\Bigr), $ where $D$ is network\ndepth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our\ndelayed-feedback blocking mechanism transforms dependent samples into\neffectively independent ones while discarding only $O(1/\\log N)$ of the data,\nyielding $\\sqrt{D}$ scaling instead of exponential, implying that doubling\ndepth requires approximately quadrupling the training data.\n  We also introduce a fair-comparison methodology that fixes the effective\nsample size to isolate the effect of temporal structure from information\ncontent. Under $N_{\\text{eff}}=2{,}000$, strongly dependent sequences\n($\\rho=0.8$) exhibit $\\approx76\\%$ smaller generalization gaps than weakly\ndependent ones ($\\rho=0.2$), challenging the intuition that dependence is\npurely detrimental. Yet convergence rates diverge from theory: weak\ndependencies follow $N_{\\text{eff}}^{-1.21}$ scaling and strong dependencies\nfollow $N_{\\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.\nThese findings reveal that temporal dependence can enhance learning under fixed\ninformation budgets, while highlighting gaps between theory and practice that\nmotivate future research.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6df1\u5ea6\u65f6\u95f4\u6a21\u578b\u6cdb\u5316\u7406\u8bba\u7406\u89e3\u4e0d\u8db3\u95ee\u9898\uff0c\u7ed9\u51fa\u6cdb\u5316\u8fb9\u754c\u3001\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7814\u7a76\u4f9d\u8d56\u5e8f\u5217\u6cdb\u5316\u8868\u73b0\uff0c\u63ed\u793a\u65f6\u95f4\u4f9d\u8d56\u53ef\u63d0\u5347\u5b66\u4e60\u6548\u679c\uff0c\u6307\u51fa\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u65f6\u95f4\u67b6\u6784\u5982TCNs\u6cdb\u5316\u7406\u8bba\u7406\u89e3\u6709\u9650\uff0c\u9700\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u4e3a\u6307\u6570\u03b2\u6df7\u5408\u5e8f\u5217\u63a8\u5bfc\u6cdb\u5316\u8fb9\u754c\uff0c\u7528\u5ef6\u8fdf\u53cd\u9988\u963b\u585e\u673a\u5236\u5904\u7406\u76f8\u5173\u6837\u672c\uff0c\u5f15\u5165\u516c\u5e73\u6bd4\u8f83\u65b9\u6cd5\u3002", "result": "\u5f97\u5230\u6cdb\u5316\u8fb9\u754c\u7f29\u653e\u5f62\u5f0f\uff1b\u5904\u7406\u76f8\u5173\u6837\u672c\u4f7f\u6df1\u5ea6\u7f29\u653e\u53d8\u4e3a\u221aD\uff1b\u5f3a\u4f9d\u8d56\u5e8f\u5217\u6cdb\u5316\u5dee\u8ddd\u6bd4\u5f31\u4f9d\u8d56\u5c0f\uff1b\u6536\u655b\u7387\u4e0e\u7406\u8bba\u4e0d\u540c\u3002", "conclusion": "\u65f6\u95f4\u4f9d\u8d56\u5728\u56fa\u5b9a\u4fe1\u606f\u9884\u7b97\u4e0b\u53ef\u63d0\u5347\u5b66\u4e60\u6548\u679c\uff0c\u7406\u8bba\u4e0e\u5b9e\u8df5\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2508.06352", "pdf": "https://arxiv.org/pdf/2508.06352", "abs": "https://arxiv.org/abs/2508.06352", "authors": ["Christian Meske", "Justin Brenne", "Erdi Uenal", "Sabahat Oelcer", "Ayseguel Doganguen"], "title": "From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "Current explainable AI (XAI) approaches prioritize algorithmic transparency\nand present explanations in abstract, non-adaptive formats that often fail to\nsupport meaningful end-user understanding. This paper introduces \"Explanatory\nAI\" as a complementary paradigm that leverages generative AI capabilities to\nserve as explanatory partners for human understanding rather than providers of\nalgorithmic transparency. While XAI reveals algorithmic decision processes for\nmodel validation, Explanatory AI addresses contextual reasoning to support\nhuman decision-making in sociotechnical contexts. We develop a definition and\nsystematic eight-dimensional conceptual model distinguishing Explanatory AI\nthrough narrative communication, adaptive personalization, and progressive\ndisclosure principles. Empirical validation through Rapid Contextual Design\nmethodology with healthcare professionals demonstrates that users consistently\nprefer context-sensitive, multimodal explanations over technical transparency.\nOur findings reveal the practical urgency for AI systems designed for human\ncomprehension rather than algorithmic introspection, establishing a\ncomprehensive research agenda for advancing user-centered AI explanation\napproaches across diverse domains and cultural contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u2018\u89e3\u91ca\u6027AI\u2019\u8303\u5f0f\uff0c\u5f00\u53d1\u6982\u5ff5\u6a21\u578b\u5e76\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u5f3a\u8c03\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u89e3\u91ca\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u53ef\u89e3\u91caAI\u65b9\u6cd5\u91cd\u7b97\u6cd5\u900f\u660e\u5ea6\uff0c\u96be\u4ee5\u8ba9\u7ec8\u7aef\u7528\u6237\u7406\u89e3\uff0c\u9700\u65b0\u8303\u5f0f\u652f\u6301\u4eba\u7c7b\u51b3\u7b56\u3002", "method": "\u5f00\u53d1\u516b\u7ef4\u6982\u5ff5\u6a21\u578b\u533a\u5206\u89e3\u91ca\u6027AI\uff0c\u7528\u5feb\u901f\u60c5\u5883\u8bbe\u8ba1\u65b9\u6cd5\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u7528\u6237\u66f4\u504f\u597d\u4e0a\u4e0b\u6587\u654f\u611f\u3001\u591a\u6a21\u6001\u89e3\u91ca\uff0c\u800c\u975e\u6280\u672f\u900f\u660e\u5ea6\u3002", "conclusion": "AI\u7cfb\u7edf\u5e94\u6ce8\u91cd\u4eba\u7c7b\u7406\u89e3\uff0c\u9700\u63a8\u8fdb\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684AI\u89e3\u91ca\u65b9\u6cd5\u7814\u7a76\u3002"}}
{"id": "2508.05700", "pdf": "https://arxiv.org/pdf/2508.05700", "abs": "https://arxiv.org/abs/2508.05700", "authors": ["Runze Su", "Jiayin Jin", "Jiacheng Li", "Sihan Wang", "Guangtong Bai", "Zelun Wang", "Li Tang", "Yixiong Meng", "Huasen Wu", "Zhimeng Pan", "Kungang Li", "Han Sun", "Zhifang Liu", "Haoyang Li", "Siping Ji", "Ling Leng", "Prathibha Deshikachar"], "title": "Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking", "categories": ["cs.IR", "cs.AI", "cs.LG"], "comment": null, "summary": "Large embedding tables are indispensable in modern recommendation systems,\nthanks to their ability to effectively capture and memorize intricate details\nof interactions among diverse entities. As we explore integrating large\nembedding tables into Pinterest's ads ranking models, we encountered not only\ncommon challenges such as sparsity and scalability, but also several obstacles\nunique to our context. Notably, our initial attempts to train large embedding\ntables from scratch resulted in neutral metrics. To tackle this, we introduced\na novel multi-faceted pretraining scheme that incorporates multiple pretraining\nalgorithms. This approach greatly enriched the embedding tables and resulted in\nsignificant performance improvements. As a result, the multi-faceted large\nembedding tables bring great performance gain on both the Click-Through Rate\n(CTR) and Conversion Rate (CVR) domains. Moreover, we designed a CPU-GPU hybrid\nserving infrastructure to overcome GPU memory limits and elevate the\nscalability. This framework has been deployed in the Pinterest Ads system and\nachieved 1.34% online CPC reduction and 2.60% CTR increase with neutral\nend-to-end latency change.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u5728Pinterest\u5e7f\u544a\u6392\u540d\u6a21\u578b\u4e2d\u96c6\u6210\u5927\u5d4c\u5165\u8868\u9047\u5230\u7684\u95ee\u9898\u53ca\u89e3\u51b3\u65b9\u6848\uff0c\u91c7\u7528\u591a\u65b9\u9762\u9884\u8bad\u7ec3\u65b9\u6848\u548cCPU - GPU\u6df7\u5408\u670d\u52a1\u67b6\u6784\uff0c\u53d6\u5f97\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5728Pinterest\u5e7f\u544a\u6392\u540d\u6a21\u578b\u4e2d\u96c6\u6210\u5927\u5d4c\u5165\u8868\u65f6\u9047\u5230\u7a00\u758f\u6027\u3001\u53ef\u6269\u5c55\u6027\u7b49\u5e38\u89c1\u95ee\u9898\u4ee5\u53ca\u7279\u5b9a\u573a\u666f\u969c\u788d\uff0c\u521d\u59cb\u8bad\u7ec3\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5f15\u5165\u7ed3\u5408\u591a\u79cd\u9884\u8bad\u7ec3\u7b97\u6cd5\u7684\u591a\u65b9\u9762\u9884\u8bad\u7ec3\u65b9\u6848\uff0c\u8bbe\u8ba1CPU - GPU\u6df7\u5408\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\u3002", "result": "\u591a\u65b9\u9762\u5927\u5d4c\u5165\u8868\u5728CTR\u548cCVR\u9886\u57df\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u90e8\u7f72\u6846\u67b6\u540e\u5b9e\u73b01.34%\u7684\u5728\u7ebfCPC\u964d\u4f4e\u548c2.60%\u7684CTR\u589e\u52a0\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf\u65e0\u53d8\u5316\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9884\u8bad\u7ec3\u65b9\u6848\u548c\u670d\u52a1\u57fa\u7840\u8bbe\u65bd\u6709\u6548\uff0c\u80fd\u63d0\u5347Pinterest\u5e7f\u544a\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.06097", "pdf": "https://arxiv.org/pdf/2508.06097", "abs": "https://arxiv.org/abs/2508.06097", "authors": ["Simon B\u00fchrer", "Andreas Plesner", "Till Aczel", "Roger Wattenhofer"], "title": "Recurrent Deep Differentiable Logic Gate Networks", "categories": ["cs.LG"], "comment": null, "summary": "While differentiable logic gates have shown promise in feedforward networks,\ntheir application to sequential modeling remains unexplored. This paper\npresents the first implementation of Recurrent Deep Differentiable Logic Gate\nNetworks (RDDLGN), combining Boolean operations with recurrent architectures\nfor sequence-to-sequence learning.\n  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and\n30.9\\% accuracy during training, approaching GRU performance (5.41 BLEU) and\ngraceful degradation (4.39 BLEU) during inference. This work establishes\nrecurrent logic-based neural computation as viable, opening research directions\nfor FPGA acceleration in sequential modeling and other recursive network\narchitectures.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5b9e\u73b0\u5faa\u73af\u6df1\u5ea6\u53ef\u5fae\u903b\u8f91\u95e8\u7f51\u7edc\uff08RDDLGN\uff09\u7528\u4e8e\u5e8f\u5217\u5230\u5e8f\u5217\u5b66\u4e60\uff0c\u5728\u82f1\u5fb7\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u8bc4\u4f30\uff0c\u6027\u80fd\u63a5\u8fd1GRU\uff0c\u8bc1\u660e\u57fa\u4e8e\u5faa\u73af\u903b\u8f91\u7684\u795e\u7ecf\u8ba1\u7b97\u53ef\u884c\u3002", "motivation": "\u53ef\u5fae\u903b\u8f91\u95e8\u5728\u987a\u5e8f\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u672a\u88ab\u63a2\u7d22\uff0c\u5c1d\u8bd5\u5c06\u5e03\u5c14\u8fd0\u7b97\u4e0e\u5faa\u73af\u67b6\u6784\u7ed3\u5408\u7528\u4e8e\u987a\u5e8f\u5efa\u6a21\u3002", "method": "\u5b9e\u73b0\u5faa\u73af\u6df1\u5ea6\u53ef\u5fae\u903b\u8f91\u95e8\u7f51\u7edc\uff08RDDLGN\uff09\u8fdb\u884c\u5e8f\u5217\u5230\u5e8f\u5217\u5b66\u4e60\u3002", "result": "\u5728WMT'14\u82f1\u5fb7\u7ffb\u8bd1\u4efb\u52a1\u4e0a\uff0c\u8bad\u7ec3\u65f6\u8fbe\u52305.00 BLEU\u548c30.9%\u51c6\u786e\u7387\uff0c\u63a8\u7406\u65f6\u63a5\u8fd1GRU\u6027\u80fd\uff0cBLEU\u4e3a4.39\u3002", "conclusion": "\u57fa\u4e8e\u5faa\u73af\u903b\u8f91\u7684\u795e\u7ecf\u8ba1\u7b97\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u987a\u5e8f\u5efa\u6a21\u4e2d\u7684FPGA\u52a0\u901f\u548c\u5176\u4ed6\u9012\u5f52\u7f51\u7edc\u67b6\u6784\u7814\u7a76\u5f00\u8f9f\u65b9\u5411\u3002"}}
{"id": "2508.06368", "pdf": "https://arxiv.org/pdf/2508.06368", "abs": "https://arxiv.org/abs/2508.06368", "authors": ["Claudia dAmato", "Giuseppe Rubini", "Francesco Didio", "Donato Francioso", "Fatima Zahra Amara", "Nicola Fanizzi"], "title": "Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned", "categories": ["cs.AI"], "comment": null, "summary": "Legal decision-making process requires the availability of comprehensive and\ndetailed legislative background knowledge and up-to-date information on legal\ncases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a\nvaluable tool to facilitate access to legal information, to be queried and\nexploited for the purpose, and to enable advanced reasoning and machine\nlearning applications. Indeed, legal KGs may act as knowledge intensive\ncomponent to be used by pre-dictive machine learning solutions supporting the\ndecision process of the legal expert. Nevertheless, a few KGs can be found in\nthe legal domain. To fill this gap, we developed a legal KG targeting legal\ncases of violence against women, along with clear adopted methodologies.\nSpecifically, the paper introduces two complementary approaches for automated\nlegal KG construction; a systematic bottom-up approach, customized for the\nlegal domain, and a new solution leveraging Large Language Models. Starting\nfrom legal sentences publicly available from the European Court of Justice, the\nsolutions integrate structured data extraction, ontology development, and\nsemantic enrichment to produce KGs tailored for legal cases involving violence\nagainst women. After analyzing and comparing the results of the two approaches,\nthe developed KGs are validated via suitable competency questions. The obtained\nKG may be impactful for multiple purposes: can improve the accessibility to\nlegal information both to humans and machine, can enable complex queries and\nmay constitute an important knowledge component to be possibly exploited by\nmachine learning tools tailored for predictive justice.", "AI": {"tldr": "\u6587\u7ae0\u4ecb\u7ecd\u6784\u5efa\u9488\u5bf9\u5973\u6027\u66b4\u529b\u6cd5\u5f8b\u6848\u4ef6\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\uff0c\u7ed3\u679c\u7ecf\u9a8c\u8bc1\uff0c\u6b64\u56fe\u8c31\u6709\u591a\u79cd\u7528\u9014\u3002", "motivation": "\u6cd5\u5f8b\u51b3\u7b56\u9700\u5168\u9762\u77e5\u8bc6\u548c\u4fe1\u606f\uff0c\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\u6709\u4ef7\u503c\u4f46\u6cd5\u5f8b\u9886\u57df\u8f83\u5c11\uff0c\u4e3a\u586b\u8865\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u81ea\u52a8\u6784\u5efa\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\u7684\u4e92\u8865\u65b9\u6cd5\uff0c\u5305\u62ec\u5b9a\u5236\u7684\u81ea\u5e95\u5411\u4e0a\u65b9\u6cd5\u548c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u65b9\u6848\uff0c\u6574\u5408\u6570\u636e\u63d0\u53d6\u3001\u672c\u4f53\u5f00\u53d1\u548c\u8bed\u4e49\u4e30\u5bcc\u3002", "result": "\u5f00\u53d1\u51fa\u9488\u5bf9\u5973\u6027\u66b4\u529b\u6cd5\u5f8b\u6848\u4ef6\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u901a\u8fc7\u80fd\u529b\u95ee\u9898\u9a8c\u8bc1\u3002", "conclusion": "\u5f00\u53d1\u7684\u77e5\u8bc6\u56fe\u8c31\u53ef\u63d0\u9ad8\u6cd5\u5f8b\u4fe1\u606f\u53ef\u53ca\u6027\uff0c\u652f\u6301\u590d\u6742\u67e5\u8be2\uff0c\u53ef\u4e3a\u673a\u5668\u5b66\u4e60\u5de5\u5177\u63d0\u4f9b\u77e5\u8bc6\u7ec4\u4ef6\u3002"}}
{"id": "2508.05709", "pdf": "https://arxiv.org/pdf/2508.05709", "abs": "https://arxiv.org/abs/2508.05709", "authors": ["Boyu Chen", "Siran Chen", "Zhengrong Yue", "Kainan Yan", "Chenyun Yu", "Beibei Kong", "Cheng Lei", "Chengxiang Zhuo", "Zang Li", "Yali Wang"], "title": "G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation", "categories": ["cs.IR", "cs.LG", "cs.MA"], "comment": null, "summary": "User feedback is critical for refining recommendation systems, yet explicit\nfeedback (e.g., likes or dislikes) remains scarce in practice. As a more\nfeasible alternative, inferring user preferences from massive implicit feedback\nhas shown great potential (e.g., a user quickly skipping a recommended video\nusually indicates disinterest). Unfortunately, implicit feedback is often\nnoisy: a user might skip a video due to accidental clicks or other reasons,\nrather than disliking it. Such noise can easily misjudge user interests,\nthereby undermining recommendation performance. To address this issue, we\npropose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which\nleverages contextual guidance from relevant user groups, enabling robust and\nin-depth interpretation of implicit feedback for individual users.\nSpecifically, G-UBS operates via two key agents. First, the User Group Manager\n(UGM) effectively clusters users to generate group profiles utilizing a\n``summarize-cluster-reflect\" workflow based on LLMs. Second, the User Feedback\nModeler (UFM) employs an innovative group-aware reinforcement learning\napproach, where each user is guided by the associated group profiles during the\nreinforcement learning process, allowing UFM to robustly and deeply examine the\nreasons behind implicit feedback. To assess our G-UBS paradigm, we have\nconstructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To\nthe best of our knowledge, this is the first multi-modal benchmark for implicit\nfeedback evaluation in video recommendation, encompassing 15k users, 25k\nvideos, and 933k interaction records with implicit feedback. Extensive\nexperiments on IF-VR demonstrate that G-UBS significantly outperforms\nmainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a\nplay rate > 30% and 14.9% higher reasoning accuracy on IF-VR.", "AI": {"tldr": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u4e2d\u663e\u5f0f\u53cd\u9988\u7a00\u7f3a\uff0c\u9690\u5f0f\u53cd\u9988\u6709\u566a\u58f0\uff0c\u63d0\u51faG - UBS\u8303\u5f0f\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u4e3b\u6d41\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u9690\u5f0f\u53cd\u9988\u6709\u566a\u58f0\uff0c\u6613\u8bef\u5224\u7528\u6237\u5174\u8da3\u3001\u5f71\u54cd\u63a8\u8350\u6027\u80fd\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faG - UBS\u8303\u5f0f\uff0c\u5305\u542b\u7528\u6237\u7ec4\u7ba1\u7406\u5668\uff08UGM\uff09\u548c\u7528\u6237\u53cd\u9988\u5efa\u6a21\u5668\uff08UFM\uff09\uff0c\u5e76\u6784\u5efaIF - VR\u57fa\u51c6\u3002", "result": "\u5728IF - VR\u4e0a\u5b9e\u9a8c\uff0cG - UBS\u6bd4\u4e3b\u6d41LLMs\u548cMLLMs\u8868\u73b0\u597d\uff0c\u89c6\u9891\u64ad\u653e\u7387>30%\u7684\u6bd4\u4f8b\u9ad84.0%\uff0c\u63a8\u7406\u51c6\u786e\u7387\u9ad814.9%\u3002", "conclusion": "G - UBS\u8303\u5f0f\u80fd\u6709\u6548\u5904\u7406\u9690\u5f0f\u53cd\u9988\u566a\u58f0\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2508.06108", "pdf": "https://arxiv.org/pdf/2508.06108", "abs": "https://arxiv.org/abs/2508.06108", "authors": ["Xing Lei", "Wenyan Yang", "Kaiqiang Ke", "Shentao Yang", "Xuetao Zhang", "Joni Pajarinen", "Donglin Wang"], "title": "GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a\nfundamental challenge in reinforcement learning. While hindsight experience\nreplay (HER) has shown promise by relabeling collected trajectories with\nachieved goals, we argue that trajectory relabeling alone does not fully\nexploit the available experiences in off-policy GCRL methods, resulting in\nlimited sample efficiency. In this paper, we propose Hindsight Goal-conditioned\nRegularization (HGR), a technique that generates action regularization priors\nbased on hindsight goals. When combined with hindsight self-imitation\nregularization (HSR), our approach enables off-policy RL algorithms to maximize\nexperience utilization. Compared to existing GCRL methods that employ HER and\nself-imitation techniques, our hindsight regularizations achieve substantially\nmore efficient sample reuse and the best performances, which we empirically\ndemonstrate on a suite of navigation and manipulation tasks.", "AI": {"tldr": "\u63d0\u51faHGR\u6280\u672f\u7ed3\u5408HSR\uff0c\u63d0\u5347\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u6837\u672c\u6548\u7387\uff0c\u5728\u5bfc\u822a\u548c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f73\u3002", "motivation": "\u73b0\u6709\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4ec5\u9760\u8f68\u8ff9\u91cd\u6807\u8bb0\u672a\u5145\u5206\u5229\u7528\u7ecf\u9a8c\uff0c\u6837\u672c\u6548\u7387\u6709\u9650\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u540e\u89c6\u76ee\u6807\u751f\u6210\u52a8\u4f5c\u6b63\u5219\u5316\u5148\u9a8c\u7684HGR\u6280\u672f\uff0c\u5e76\u4e0e\u540e\u89c6\u81ea\u6211\u6a21\u4eff\u6b63\u5219\u5316\uff08HSR\uff09\u7ed3\u5408\u3002", "result": "\u4e0e\u73b0\u6709\u91c7\u7528HER\u548c\u81ea\u6211\u6a21\u4eff\u6280\u672f\u7684GCRL\u65b9\u6cd5\u76f8\u6bd4\uff0c\u540e\u89c6\u6b63\u5219\u5316\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u6837\u672c\u91cd\u7528\u548c\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u4f7f\u79bb\u7b56\u7565RL\u7b97\u6cd5\u6700\u5927\u5316\u7ecf\u9a8c\u5229\u7528\u3002"}}
{"id": "2508.05748", "pdf": "https://arxiv.org/pdf/2508.05748", "abs": "https://arxiv.org/abs/2508.05748", "authors": ["Xinyu Geng", "Peng Xia", "Zhen Zhang", "Xinyu Wang", "Qiuchen Wang", "Ruixue Ding", "Chenxi Wang", "Jialong Wu", "Yida Zhao", "Kuan Li", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "title": "WebWatcher: Breaking New Frontiers of Vision-Language Deep Research Agent", "categories": ["cs.IR"], "comment": null, "summary": "Web agents such as Deep Research have demonstrated superhuman cognitive\nabilities, capable of solving highly challenging information-seeking problems.\nHowever, most research remains primarily text-centric, overlooking visual\ninformation in the real world. This makes multimodal Deep Research highly\nchallenging, as such agents require much stronger reasoning abilities in\nperception, logic, knowledge, and the use of more sophisticated tools compared\nto text-based agents. To address this limitation, we introduce WebWatcher, a\nmulti-modal Agent for Deep Research equipped with enhanced visual-language\nreasoning capabilities. It leverages high-quality synthetic multimodal\ntrajectories for efficient cold start training, utilizes various tools for deep\nreasoning, and further enhances generalization through reinforcement learning.\nTo better evaluate the capabilities of multimodal agents, we propose\nBrowseComp-VL, a benchmark with BrowseComp-style that requires complex\ninformation retrieval involving both visual and textual information.\nExperimental results show that WebWatcher significantly outperforms proprietary\nbaseline, RAG workflow and open-source agents in four challenging VQA\nbenchmarks, which paves the way for solving complex multimodal\ninformation-seeking tasks.", "AI": {"tldr": "\u73b0\u6709Web\u667a\u80fd\u4f53\u7814\u7a76\u591a\u4ee5\u6587\u672c\u4e3a\u4e2d\u5fc3\uff0c\u5ffd\u7565\u89c6\u89c9\u4fe1\u606f\u3002\u672c\u6587\u63d0\u51fa\u591a\u6a21\u6001\u667a\u80fd\u4f53WebWatcher\u53ca\u8bc4\u4f30\u57fa\u51c6BrowseComp - VL\uff0c\u5b9e\u9a8c\u8868\u660eWebWatcher\u6027\u80fd\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709Web\u667a\u80fd\u4f53\u7814\u7a76\u591a\u4e3a\u6587\u672c\u4e2d\u5fc3\uff0c\u5ffd\u7565\u89c6\u89c9\u4fe1\u606f\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u6df1\u5ea6\u7814\u7a76\u96be\u9898\u9700\u8981\u66f4\u5f3a\u63a8\u7406\u80fd\u529b\u548c\u590d\u6742\u5de5\u5177\u3002", "method": "\u5f15\u5165\u591a\u6a21\u6001\u667a\u80fd\u4f53WebWatcher\uff0c\u5229\u7528\u9ad8\u8d28\u91cf\u5408\u6210\u591a\u6a21\u6001\u8f68\u8ff9\u8fdb\u884c\u51b7\u542f\u52a8\u8bad\u7ec3\uff0c\u4f7f\u7528\u591a\u79cd\u5de5\u5177\u6df1\u5ea6\u63a8\u7406\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff1b\u63d0\u51fa\u8bc4\u4f30\u57fa\u51c6BrowseComp - VL\u3002", "result": "WebWatcher\u5728\u56db\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684VQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u4e13\u6709\u57fa\u7ebf\u3001RAG\u5de5\u4f5c\u6d41\u548c\u5f00\u6e90\u667a\u80fd\u4f53\u3002", "conclusion": "WebWatcher\u4e3a\u89e3\u51b3\u590d\u6742\u591a\u6a21\u6001\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2508.06151", "pdf": "https://arxiv.org/pdf/2508.06151", "abs": "https://arxiv.org/abs/2508.06151", "authors": ["Yong Oh Lee", "JeeEun Kim", "Jung Woo Lee"], "title": "Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "In oral cancer diagnostics, the limited availability of annotated datasets\nfrequently constrains the performance of diagnostic models, particularly due to\nthe variability and insufficiency of training data. To address these\nchallenges, this study proposed a novel approach to enhance diagnostic accuracy\nby synthesizing realistic oral cancer lesions using an inpainting technique\nwith a fine-tuned diffusion model. We compiled a comprehensive dataset from\nmultiple sources, featuring a variety of oral cancer images. Our method\ngenerated synthetic lesions that exhibit a high degree of visual fidelity to\nactual lesions, thereby significantly enhancing the performance of diagnostic\nalgorithms. The results show that our classification model achieved a\ndiagnostic accuracy of 0.97 in differentiating between cancerous and\nnon-cancerous tissues, while our detection model accurately identified lesion\nlocations with 0.85 accuracy. This method validates the potential for synthetic\nimage generation in medical diagnostics and paves the way for further research\ninto extending these methods to other types of cancer diagnostics.", "AI": {"tldr": "\u7814\u7a76\u7528\u5fae\u8c03\u6269\u6563\u6a21\u578b\u7684\u4fee\u590d\u6280\u672f\u5408\u6210\u53e3\u8154\u764c\u75c5\u53d8\u56fe\u50cf\uff0c\u63d0\u9ad8\u8bca\u65ad\u6a21\u578b\u6027\u80fd\uff0c\u5206\u7c7b\u548c\u68c0\u6d4b\u6a21\u578b\u6709\u9ad8\u51c6\u786e\u7387\uff0c\u9a8c\u8bc1\u5408\u6210\u56fe\u50cf\u5728\u533b\u7597\u8bca\u65ad\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u53e3\u8154\u764c\u8bca\u65ad\u4e2d\u6ce8\u91ca\u6570\u636e\u96c6\u6709\u9650\u3001\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u548c\u591a\u53d8\u6027\u95ee\u9898\uff0c\u63d0\u5347\u8bca\u65ad\u6a21\u578b\u6027\u80fd\u3002", "method": "\u91c7\u7528\u5fae\u8c03\u6269\u6563\u6a21\u578b\u7684\u4fee\u590d\u6280\u672f\u5408\u6210\u903c\u771f\u53e3\u8154\u764c\u75c5\u53d8\uff0c\u4ece\u591a\u6e90\u7f16\u8bd1\u7efc\u5408\u6570\u636e\u96c6\u3002", "result": "\u5206\u7c7b\u6a21\u578b\u533a\u5206\u764c\u7ec4\u7ec7\u548c\u975e\u764c\u7ec4\u7ec7\u8bca\u65ad\u51c6\u786e\u7387\u8fbe0.97\uff0c\u68c0\u6d4b\u6a21\u578b\u8bc6\u522b\u75c5\u53d8\u4f4d\u7f6e\u51c6\u786e\u7387\u8fbe0.85\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u5408\u6210\u56fe\u50cf\u751f\u6210\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u62d3\u5c55\u5230\u5176\u4ed6\u764c\u75c7\u8bca\u65ad\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.05969", "pdf": "https://arxiv.org/pdf/2508.05969", "abs": "https://arxiv.org/abs/2508.05969", "authors": ["Li Fan", "Menglin Kong", "Yang Xiang", "Chong Zhang", "Chengtao Ji"], "title": "Dual prototype attentive graph network for cross-market recommendation", "categories": ["cs.IR"], "comment": "Accepted by ICONIP 2025 (Oral)", "summary": "Cross-market recommender systems (CMRS) aim to utilize historical data from\nmature markets to promote multinational products in emerging markets. However,\nexisting CMRS approaches often overlook the potential for shared preferences\namong users in different markets, focusing primarily on modeling specific\npreferences within each market. In this paper, we argue that incorporating both\nmarket-specific and market-shared insights can enhance the generalizability and\nrobustness of CMRS. We propose a novel approach called Dual Prototype Attentive\nGraph Network for Cross-Market Recommendation (DGRE) to address this. DGRE\nleverages prototypes based on graph representation learning from both items and\nusers to capture market-specific and market-shared insights. Specifically, DGRE\nincorporates market-shared prototypes by clustering users from various markets\nto identify behavioural similarities and create market-shared user profiles.\nAdditionally, it constructs item-side prototypes by aggregating item features\nwithin each market, providing valuable market-specific insights. We conduct\nextensive experiments to validate the effectiveness of DGRE on a real-world\ncross-market dataset, and the results show that considering both\nmarket-specific and market-sharing aspects in modelling can improve the\ngeneralization and robustness of CMRS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDGRE\u65b9\u6cd5\u7528\u4e8e\u8de8\u5e02\u573a\u63a8\u8350\uff0c\u7ed3\u5408\u5e02\u573a\u7279\u5b9a\u548c\u5171\u4eab\u4fe1\u606f\u63d0\u5347CMRS\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u8de8\u5e02\u573a\u63a8\u8350\u7cfb\u7edf\u65b9\u6cd5\u5e38\u5ffd\u89c6\u4e0d\u540c\u5e02\u573a\u7528\u6237\u95f4\u5171\u4eab\u504f\u597d\uff0c\u672c\u6587\u65e8\u5728\u7ed3\u5408\u5e02\u573a\u7279\u5b9a\u548c\u5171\u4eab\u4fe1\u606f\u63d0\u5347CMRS\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faDual Prototype Attentive Graph Network for Cross - Market Recommendation (DGRE)\u65b9\u6cd5\uff0c\u5229\u7528\u57fa\u4e8e\u56fe\u8868\u793a\u5b66\u4e60\u7684\u539f\u578b\u6355\u83b7\u5e02\u573a\u7279\u5b9a\u548c\u5171\u4eab\u4fe1\u606f\uff0c\u805a\u7c7b\u7528\u6237\u5f62\u6210\u5171\u4eab\u539f\u578b\uff0c\u805a\u5408\u5546\u54c1\u7279\u5f81\u6784\u5efa\u5546\u54c1\u4fa7\u539f\u578b\u3002", "result": "\u5728\u771f\u5b9e\u8de8\u5e02\u573a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5efa\u6a21\u4e2d\u8003\u8651\u5e02\u573a\u7279\u5b9a\u548c\u5171\u4eab\u65b9\u9762\u80fd\u63d0\u5347CMRS\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u7ed3\u5408\u5e02\u573a\u7279\u5b9a\u548c\u5e02\u573a\u5171\u4eab\u4fe1\u606f\u53ef\u63d0\u5347CMRS\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\uff0cDGRE\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2508.06183", "pdf": "https://arxiv.org/pdf/2508.06183", "abs": "https://arxiv.org/abs/2508.06183", "authors": ["Xiyuan Yang", "Shengyuan Hu", "Soyeon Kim", "Tian Li"], "title": "Differentially Private Federated Clustering with Random Rebalancing", "categories": ["cs.LG", "cs.AI"], "comment": "21 pages", "summary": "Federated clustering aims to group similar clients into clusters and produce\none model for each cluster. Such a personalization approach typically improves\nmodel performance compared with training a single model to serve all clients,\nbut can be more vulnerable to privacy leakage. Directly applying client-level\ndifferentially private (DP) mechanisms to federated clustering could degrade\nthe utilities significantly. We identify that such deficiencies are mainly due\nto the difficulties of averaging privacy noise within each cluster (following\nstandard privacy mechanisms), as the number of clients assigned to the same\nclusters is uncontrolled. To this end, we propose a simple and effective\ntechnique, named RR-Cluster, that can be viewed as a light-weight add-on to\nmany federated clustering algorithms. RR-Cluster achieves reduced privacy noise\nvia randomly rebalancing cluster assignments, guaranteeing a minimum number of\nclients assigned to each cluster. We analyze the tradeoffs between decreased\nprivacy noise variance and potentially increased bias from incorrect\nassignments and provide convergence bounds for RR-Clsuter. Empirically, we\ndemonstrate the RR-Cluster plugged into strong federated clustering algorithms\nresults in significantly improved privacy/utility tradeoffs across both\nsynthetic and real-world datasets.", "AI": {"tldr": "\u63d0\u51faRR - Cluster\u6280\u672f\u6539\u8fdb\u8054\u90a6\u805a\u7c7b\u9690\u79c1/\u6548\u7528\u6743\u8861\u3002", "motivation": "\u8054\u90a6\u805a\u7c7b\u6613\u9690\u79c1\u6cc4\u9732\uff0c\u76f4\u63a5\u5e94\u7528\u5dee\u5206\u9690\u79c1\u673a\u5236\u4f1a\u663e\u8457\u964d\u4f4e\u6548\u7528\uff0c\u539f\u56e0\u662f\u540c\u4e00\u805a\u7c7b\u4e2d\u5ba2\u6237\u7aef\u6570\u91cf\u4e0d\u53ef\u63a7\uff0c\u96be\u4ee5\u5e73\u5747\u9690\u79c1\u566a\u58f0\u3002", "method": "\u63d0\u51faRR - Cluster\u6280\u672f\uff0c\u901a\u8fc7\u968f\u673a\u91cd\u65b0\u5e73\u8861\u805a\u7c7b\u5206\u914d\u51cf\u5c11\u9690\u79c1\u566a\u58f0\uff0c\u4fdd\u8bc1\u6bcf\u4e2a\u805a\u7c7b\u4e2d\u6700\u5c11\u5ba2\u6237\u7aef\u6570\u91cf\uff0c\u5e76\u5206\u6790\u566a\u58f0\u65b9\u5dee\u964d\u4f4e\u548c\u9519\u8bef\u5206\u914d\u504f\u5dee\u589e\u52a0\u7684\u6743\u8861\uff0c\u7ed9\u51fa\u6536\u655b\u8fb9\u754c\u3002", "result": "\u5c06RR - Cluster\u5e94\u7528\u4e8e\u5f3a\u8054\u90a6\u805a\u7c7b\u7b97\u6cd5\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u6539\u5584\u9690\u79c1/\u6548\u7528\u6743\u8861\u3002", "conclusion": "RR - Cluster\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u63d2\u4ef6\uff0c\u80fd\u6709\u6548\u63d0\u5347\u8054\u90a6\u805a\u7c7b\u7684\u9690\u79c1/\u6548\u7528\u8868\u73b0\u3002"}}
{"id": "2304.04475", "pdf": "https://arxiv.org/pdf/2304.04475", "abs": "https://arxiv.org/abs/2304.04475", "authors": ["Gaurav Deshkar", "Jayanta Kshirsagar", "Harshal Hayatnagarkar", "Janani Venugopalan"], "title": "Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "To mitigate the impact of the pandemic, several measures include lockdowns,\nrapid vaccination programs, school closures, and economic stimulus. These\ninterventions can have positive or unintended negative consequences. Current\nresearch to model and determine an optimal intervention automatically through\nround-tripping is limited by the simulation objectives, scale (a few thousand\nindividuals), model types that are not suited for intervention studies, and the\nnumber of intervention strategies they can explore (discrete vs continuous). We\naddress these challenges using a Deep Deterministic Policy Gradient (DDPG)\nbased policy optimization framework on a large-scale (100,000 individual)\nepidemiological agent-based simulation where we perform multi-objective\noptimization. We determine the optimal policy for lockdown and vaccination in a\nminimalist age-stratified multi-vaccine scenario with a basic simulation for\neconomic activity. With no lockdown and vaccination (mid-age and elderly),\nresults show optimal economy (individuals below the poverty line) with balanced\nhealth objectives (infection, and hospitalization). An in-depth simulation is\nneeded to further validate our results and open-source our framework.", "AI": {"tldr": "\u6587\u7ae0\u9488\u5bf9\u75ab\u60c5\u5e72\u9884\u63aa\u65bd\u5efa\u6a21\u7814\u7a76\u7684\u5c40\u9650\uff0c\u7528DDPG\u6846\u67b6\u5728\u5927\u89c4\u6a21\u4eff\u771f\u4e2d\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\uff0c\u5f97\u51fa\u65e0\u5c01\u9501\u548c\u7279\u5b9a\u4eba\u7fa4\u63a5\u79cd\u4e0b\u7684\u7ed3\u679c\uff0c\u9700\u6df1\u5165\u4eff\u771f\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u75ab\u60c5\u5e72\u9884\u63aa\u65bd\u5efa\u6a21\u7814\u7a76\u5b58\u5728\u53d7\u4eff\u771f\u76ee\u6807\u3001\u89c4\u6a21\u3001\u6a21\u578b\u7c7b\u578b\u548c\u5e72\u9884\u7b56\u7565\u6570\u91cf\u9650\u5236\u7684\u95ee\u9898\uff0c\u9700\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u5728\u5927\u89c4\u6a21\uff0810\u4e07\u4e2a\u4f53\uff09\u6d41\u884c\u75c5\u5b66\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u4eff\u771f\u4e2d\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\u3002", "result": "\u5728\u65e0\u5c01\u9501\u548c\u7279\u5b9a\u4eba\u7fa4\uff08\u4e2d\u5e74\u548c\u8001\u5e74\u4eba\uff09\u63a5\u79cd\u75ab\u82d7\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u5b9e\u73b0\u6700\u4f18\u7ecf\u6d4e\uff08\u8d2b\u56f0\u4eba\u53e3\uff09\u548c\u5e73\u8861\u7684\u5065\u5eb7\u76ee\u6807\uff08\u611f\u67d3\u548c\u4f4f\u9662\u60c5\u51b5\uff09\u3002", "conclusion": "\u9700\u8981\u8fdb\u884c\u6df1\u5165\u4eff\u771f\u6765\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u7ed3\u679c\u5e76\u5f00\u6e90\u6846\u67b6\u3002"}}
{"id": "2508.05993", "pdf": "https://arxiv.org/pdf/2508.05993", "abs": "https://arxiv.org/abs/2508.05993", "authors": ["Yunke Qu", "Liang Qu", "Tong Chen", "Quoc Viet Hung Nguyen", "Hongzhi Yin"], "title": "Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts", "categories": ["cs.IR"], "comment": "Accepted to CIKM 2025", "summary": "Streaming recommender systems (SRSs) are widely deployed in real-world\napplications, where user interests shift and new items arrive over time. As a\nresult, effectively capturing users' latest preferences is challenging, as\ninteractions reflecting recent interests are limited and new items often lack\nsufficient feedback. A common solution is to enrich item representations using\nmultimodal encoders (e.g., BERT or ViT) to extract visual and textual features.\nHowever, these encoders are pretrained on general-purpose tasks: they are not\ntailored to user preference modeling, and they overlook the fact that user\ntastes toward modality-specific features such as visual styles and textual\ntones can also drift over time. This presents two key challenges in streaming\nscenarios: the high cost of fine-tuning large multimodal encoders, and the risk\nof forgetting long-term user preferences due to continuous model updates.\n  To tackle these challenges, we propose Expandable Side Mixture-of-Experts\n(XSMoE), a memory-efficient framework for multimodal streaming recommendation.\nXSMoE attaches lightweight side-tuning modules consisting of expandable expert\nnetworks to frozen pretrained encoders and incrementally expands them in\nresponse to evolving user feedback. A gating router dynamically combines expert\nand backbone outputs, while a utilization-based pruning strategy maintains\nmodel compactness. By learning new patterns through expandable experts without\noverwriting previously acquired knowledge, XSMoE effectively captures both cold\nstart and shifting preferences in multimodal features. Experiments on three\nreal-world datasets demonstrate that XSMoE outperforms state-of-the-art\nbaselines in both recommendation quality and computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u5185\u5b58\u9ad8\u6548\u7684\u591a\u6a21\u6001\u6d41\u63a8\u8350\u6846\u67b6XSMoE\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u63a8\u8350\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u7f16\u7801\u5668\u7528\u4e8e\u6d41\u63a8\u8350\u7cfb\u7edf\u65f6\uff0c\u672a\u9488\u5bf9\u7528\u6237\u504f\u597d\u5efa\u6a21\uff0c\u5fae\u8c03\u6210\u672c\u9ad8\u4e14\u53ef\u80fd\u9057\u5fd8\u957f\u671f\u504f\u597d\uff0c\u96be\u4ee5\u6355\u6349\u7528\u6237\u6700\u65b0\u504f\u597d\u3002", "method": "\u63d0\u51faXSMoE\u6846\u67b6\uff0c\u5c06\u7531\u53ef\u6269\u5c55\u4e13\u5bb6\u7f51\u7edc\u7ec4\u6210\u7684\u8f7b\u91cf\u7ea7\u4fa7\u8c03\u6a21\u5757\u9644\u52a0\u5230\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u4e0a\uff0c\u6839\u636e\u7528\u6237\u53cd\u9988\u589e\u91cf\u6269\u5c55\uff0c\u7528\u95e8\u63a7\u8def\u7531\u5668\u7ec4\u5408\u8f93\u51fa\uff0c\u7528\u57fa\u4e8e\u5229\u7528\u7387\u7684\u526a\u679d\u7b56\u7565\u4fdd\u6301\u6a21\u578b\u7d27\u51d1\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cXSMoE\u5728\u63a8\u8350\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "XSMoE\u80fd\u5728\u4e0d\u8986\u76d6\u5148\u524d\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u65b0\u6a21\u5f0f\uff0c\u6709\u6548\u6355\u6349\u591a\u6a21\u6001\u7279\u5f81\u4e2d\u7684\u51b7\u542f\u52a8\u548c\u504f\u597d\u53d8\u5316\u95ee\u9898\u3002"}}
{"id": "2508.06199", "pdf": "https://arxiv.org/pdf/2508.06199", "abs": "https://arxiv.org/abs/2508.06199", "authors": ["Mateusz Praski", "Jakub Adamczyk", "Wojciech Czech"], "title": "Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Pretrained neural networks have attracted significant interest in chemistry\nand small molecule drug design. Embeddings from these models are widely used\nfor molecular property prediction, virtual screening, and small data learning\nin molecular chemistry. This study presents the most extensive comparison of\nsuch models to date, evaluating 25 models across 25 datasets. Under a fair\ncomparison framework, we assess models spanning various modalities,\narchitectures, and pretraining strategies. Using a dedicated hierarchical\nBayesian statistical testing model, we arrive at a surprising result: nearly\nall neural models show negligible or no improvement over the baseline ECFP\nmolecular fingerprint. Only the CLAMP model, which is also based on molecular\nfingerprints, performs statistically significantly better than the\nalternatives. These findings raise concerns about the evaluation rigor in\nexisting studies. We discuss potential causes, propose solutions, and offer\npractical recommendations.", "AI": {"tldr": "\u672c\u6587\u5bf925\u4e2a\u9884\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u572825\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u591a\u6570\u6a21\u578b\u76f8\u6bd4\u57fa\u7ebf\u65e0\u663e\u8457\u63d0\u5347\uff0c\u4ec5CLAMP\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u5f15\u53d1\u5bf9\u73b0\u6709\u7814\u7a76\u8bc4\u4f30\u4e25\u8c28\u6027\u7684\u62c5\u5fe7\u3002", "motivation": "\u5bf9\u9884\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u5316\u5b66\u548c\u5c0f\u5206\u5b50\u836f\u7269\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u5168\u9762\u6bd4\u8f83\u8bc4\u4f30\u3002", "method": "\u5728\u516c\u5e73\u6bd4\u8f83\u6846\u67b6\u4e0b\u8bc4\u4f3025\u4e2a\u6a21\u578b\uff0c\u4f7f\u7528\u5206\u5c42\u8d1d\u53f6\u65af\u7edf\u8ba1\u6d4b\u8bd5\u6a21\u578b\u3002", "result": "\u51e0\u4e4e\u6240\u6709\u795e\u7ecf\u6a21\u578b\u76f8\u6bd4\u57fa\u7ebfECFP\u5206\u5b50\u6307\u7eb9\u65e0\u663e\u8457\u6539\u5584\uff0c\u4ec5CLAMP\u6a21\u578b\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u73b0\u6709\u7814\u7a76\u8bc4\u4f30\u4e25\u8c28\u6027\u5b58\u7591\uff0c\u8ba8\u8bba\u4e86\u6f5c\u5728\u539f\u56e0\u3001\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u5e76\u7ed9\u51fa\u5b9e\u7528\u5efa\u8bae\u3002"}}
{"id": "2507.12286", "pdf": "https://arxiv.org/pdf/2507.12286", "abs": "https://arxiv.org/abs/2507.12286", "authors": ["Anouk Oudshoorn", "Magdalena Ortiz", "Mantas Simkus"], "title": "SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques", "categories": ["cs.LO", "cs.AI"], "comment": "36 pages, 6 figures, submitted to the journal of Artificial\n  Intelligence (AIJ)", "summary": "SHACL and OWL are two prominent W3C standards for managing RDF data. These\nlanguages share many features, but they have one fundamental difference: OWL,\ndesigned for inferring facts from incomplete data, makes the open-world\nassumption, whereas SHACL is a constraint language that treats the data as\ncomplete and must be validated under the closed-world assumption. The\ncombination of both formalisms is very appealing and has been called for, but\ntheir semantic gap is a major challenge, semantically and computationally. In\nthis paper, we advocate a semantics for SHACL validation in the presence of\nontologies based on core universal models. We provide a technique for\nconstructing these models for ontologies in the rich data-tractable description\nlogic Horn-ALCHIQ. Furthermore, we use a finite representation of this model to\ndevelop a rewriting technique that reduces SHACL validation in the presence of\nontologies to standard validation. Finally, we study the complexity of SHACL\nvalidation in the presence of ontologies, and show that even very simple\nontologies make the problem EXPTIME-complete, and PTIME-complete in data\ncomplexity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6838\u5fc3\u901a\u7528\u6a21\u578b\u7684SHACL\u5728\u6709\u672c\u4f53\u60c5\u51b5\u4e0b\u7684\u9a8c\u8bc1\u8bed\u4e49\uff0c\u7ed9\u51fa\u6784\u5efa\u6a21\u578b\u6280\u672f\u3001\u91cd\u5199\u6280\u672f\uff0c\u5e76\u7814\u7a76\u9a8c\u8bc1\u590d\u6742\u5ea6\u3002", "motivation": "SHACL\u548cOWL\u7ed3\u5408\u6709\u5438\u5f15\u529b\uff0c\u4f46\u8bed\u4e49\u5dee\u5f02\u662f\u91cd\u5927\u6311\u6218\uff0c\u9700\u89e3\u51b3\u5728\u6709\u672c\u4f53\u60c5\u51b5\u4e0bSHACL\u9a8c\u8bc1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6838\u5fc3\u901a\u7528\u6a21\u578b\u7684\u8bed\u4e49\uff0c\u4e3aHorn - ALCHIQ\u63cf\u8ff0\u903b\u8f91\u4e2d\u7684\u672c\u4f53\u6784\u5efa\u6a21\u578b\uff0c\u7528\u6a21\u578b\u6709\u9650\u8868\u793a\u5f00\u53d1\u91cd\u5199\u6280\u672f\u3002", "result": "\u5c06\u6709\u672c\u4f53\u7684SHACL\u9a8c\u8bc1\u7b80\u5316\u4e3a\u6807\u51c6\u9a8c\u8bc1\uff0c\u53d1\u73b0\u7b80\u5355\u672c\u4f53\u4f7f\u95ee\u9898\u4e3aEXPTIME - complete\uff0c\u6570\u636e\u590d\u6742\u5ea6\u4e3aPTIME - complete\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u6709\u672c\u4f53\u65f6SHACL\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u660e\u786e\u4e86\u9a8c\u8bc1\u590d\u6742\u5ea6\u3002"}}
{"id": "2508.06154", "pdf": "https://arxiv.org/pdf/2508.06154", "abs": "https://arxiv.org/abs/2508.06154", "authors": ["Xiaoxiong Zhang", "Xin Zhou", "Zhiwei Zeng", "Dusit Niyato", "Zhiqi Shen"], "title": "Semantic Item Graph Enhancement for Multimodal Recommendation", "categories": ["cs.IR", "cs.AI", "cs.MM"], "comment": null, "summary": "Multimodal recommendation systems have attracted increasing attention for\ntheir improved performance by leveraging items' multimodal information. Prior\nmethods often build modality-specific item-item semantic graphs from raw\nmodality features and use them as supplementary structures alongside the\nuser-item interaction graph to enhance user preference learning. However, these\nsemantic graphs suffer from semantic deficiencies, including (1) insufficient\nmodeling of collaborative signals among items and (2) structural distortions\nintroduced by noise in raw modality features, ultimately compromising\nperformance. To address these issues, we first extract collaborative signals\nfrom the interaction graph and infuse them into each modality-specific item\nsemantic graph to enhance semantic modeling. Then, we design a modulus-based\npersonalized embedding perturbation mechanism that injects perturbations with\nmodulus-guided personalized intensity into embeddings to generate contrastive\nviews. This enables the model to learn noise-robust representations through\ncontrastive learning, thereby reducing the effect of structural noise in\nsemantic graphs. Besides, we propose a dual representation alignment mechanism\nthat first aligns multiple semantic representations via a designed Anchor-based\nInfoNCE loss using behavior representations as anchors, and then aligns\nbehavior representations with the fused semantics by standard InfoNCE, to\nensure representation consistency. Extensive experiments on four benchmark\ndatasets validate the effectiveness of our framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u6846\u67b6\u89e3\u51b3\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u8bed\u4e49\u56fe\u7684\u8bed\u4e49\u7f3a\u9677\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u4e2d\u8bed\u4e49\u56fe\u5b58\u5728\u534f\u4f5c\u4fe1\u53f7\u5efa\u6a21\u4e0d\u8db3\u548c\u7ed3\u6784\u5931\u771f\u95ee\u9898\uff0c\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u4ece\u4ea4\u4e92\u56fe\u63d0\u53d6\u534f\u4f5c\u4fe1\u53f7\u6ce8\u5165\u8bed\u4e49\u56fe\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u6a21\u91cf\u7684\u4e2a\u6027\u5316\u5d4c\u5165\u6270\u52a8\u673a\u5236\uff1b\u63d0\u51fa\u53cc\u91cd\u8868\u793a\u5bf9\u9f50\u673a\u5236\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u80fd\u89e3\u51b3\u8bed\u4e49\u56fe\u7684\u8bed\u4e49\u7f3a\u9677\u95ee\u9898\uff0c\u63d0\u5347\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2508.06208", "pdf": "https://arxiv.org/pdf/2508.06208", "abs": "https://arxiv.org/abs/2508.06208", "authors": ["Ce Na", "Kai Yang", "Dengzhao Fang", "Yu Li", "Jingtong Gao", "Chengcheng Zhu", "Jiale Zhang", "Xiaobing Sun", "Yi Chang"], "title": "Graph Federated Learning for Personalized Privacy Recommendation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated recommendation systems (FedRecs) have gained significant attention\nfor providing privacy-preserving recommendation services. However, existing\nFedRecs assume that all users have the same requirements for privacy\nprotection, i.e., they do not upload any data to the server. The approaches\noverlook the potential to enhance the recommendation service by utilizing\npublicly available user data. In real-world applications, users can choose to\nbe private or public. Private users' interaction data is not shared, while\npublic users' interaction data can be shared. Inspired by the issue, this paper\nproposes a novel Graph Federated Learning for Personalized Privacy\nRecommendation (GFed-PP) that adapts to different privacy requirements while\nimproving recommendation performance. GFed-PP incorporates the interaction data\nof public users to build a user-item interaction graph, which is then used to\nform a user relationship graph. A lightweight graph convolutional network (GCN)\nis employed to learn each user's user-specific personalized item embedding. To\nprotect user privacy, each client learns the user embedding and the scoring\nfunction locally. Additionally, GFed-PP achieves optimization of the federated\nrecommendation framework through the initialization of item embedding on\nclients and the aggregation of the user relationship graph on the server.\nExperimental results demonstrate that GFed-PP significantly outperforms\nexisting methods for five datasets, offering superior recommendation accuracy\nwithout compromising privacy. This framework provides a practical solution for\naccommodating varying privacy preferences in federated recommendation systems.", "AI": {"tldr": "\u63d0\u51faGFed - PP\u6a21\u578b\uff0c\u7ed3\u5408\u516c\u5171\u7528\u6237\u4ea4\u4e92\u6570\u636e\uff0c\u7528\u8f7b\u91cfGCN\u5b66\u4e60\u7528\u6237\u7279\u5b9a\u5d4c\u5165\uff0c\u4fdd\u62a4\u9690\u79c1\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u5047\u8bbe\u6240\u6709\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u8981\u6c42\u76f8\u540c\uff0c\u5ffd\u7565\u5229\u7528\u516c\u5171\u7528\u6237\u6570\u636e\u63d0\u5347\u63a8\u8350\u670d\u52a1\u7684\u6f5c\u529b\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u63d0\u51faGFed - PP\u6a21\u578b\uff0c\u7ed3\u5408\u516c\u5171\u7528\u6237\u4ea4\u4e92\u6570\u636e\u6784\u5efa\u7528\u6237 - \u9879\u76ee\u4ea4\u4e92\u56fe\u548c\u7528\u6237\u5173\u7cfb\u56fe\uff0c\u7528\u8f7b\u91cfGCN\u5b66\u4e60\u7528\u6237\u7279\u5b9a\u5d4c\u5165\uff0c\u5ba2\u6237\u7aef\u672c\u5730\u5b66\u4e60\u7528\u6237\u5d4c\u5165\u548c\u8bc4\u5206\u51fd\u6570\uff0c\u901a\u8fc7\u521d\u59cb\u5316\u9879\u76ee\u5d4c\u5165\u548c\u805a\u5408\u7528\u6237\u5173\u7cfb\u56fe\u4f18\u5316\u6846\u67b6\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cGFed - PP\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63a8\u8350\u51c6\u786e\u6027\u9ad8\u4e14\u4e0d\u635f\u5bb3\u9690\u79c1\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8054\u90a6\u63a8\u8350\u7cfb\u7edf\u9002\u5e94\u4e0d\u540c\u9690\u79c1\u504f\u597d\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.04748", "pdf": "https://arxiv.org/pdf/2508.04748", "abs": "https://arxiv.org/abs/2508.04748", "authors": ["Xuan Lin", "Long Chen", "Yile Wang"], "title": "AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "9 pages", "summary": "Large Language Models (LLMs) have shown promise in assisting molecular\nproperty prediction tasks but often rely on human-crafted prompts and\nchain-of-thought templates. While recent advanced large reasoning models like\nDeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,\ntheir reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,\nan attribute-guided reinforcement learning framework for molecular property\nprediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)\na format reward encouraging attribute-based structured output, (2) a count\nreward to avoid enumerating irrelevant attributes, and (3) a rationality reward\nusing advanced LLMs and RDKit to verify the relatedness of the generated\nattributes. This approach implicitly elicits the model's inherent knowledge of\nrelevant molecular attributes during reasoning, enables making predictions for\nthe molecular property more effectively. Experiments on both in-distribution\nand out-of-distribution datasets show that, training both 7B-size\nR1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our\nproposed AttriLens-Mol method significantly boosts the performance, getting\ncomparable or better results than supervised fine-tuning models\n(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,\nDeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the\ntarget property, when used as features for an interpretable decision tree\nmodel, yield superior performance compared to attributes generated by prompting\nLLMs. This shows that AttriLens-Mol effectively elicits more relevant and\npredictive molecular attributes, leading to enhanced interpretability and\nperformance for property prediction. We release the code in\nhttps://github.com/szu-tera/AttriLens-Mol.", "AI": {"tldr": "\u63d0\u51faAttriLens - Mol\u6846\u67b6\u7528\u4e8e\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5206\u5b50\u5c5e\u6027\u9884\u6d4b\u4e2d\u4f9d\u8d56\u4eba\u5de5\u63d0\u793a\u548c\u6a21\u677f\uff0c\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u63a8\u7406\u5197\u957f\u4e14\u7f3a\u4e4f\u76f8\u5173\u6027\u3002", "method": "\u5f15\u5165AttriLens - Mol\u6846\u67b6\uff0c\u4f7f\u7528\u683c\u5f0f\u5956\u52b1\u3001\u8ba1\u6570\u5956\u52b1\u548c\u5408\u7406\u6027\u5956\u52b1\u5f15\u5bfc\u6a21\u578b\u63a8\u7406\u3002", "result": "\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u6a21\u578b\u548c\u9ad8\u7ea7\u6a21\u578b\uff1b\u63d0\u53d6\u7684\u5c5e\u6027\u7528\u4e8e\u51b3\u7b56\u6811\u6a21\u578b\u6027\u80fd\u66f4\u597d\u3002", "conclusion": "AttriLens - Mol\u80fd\u6709\u6548\u5f15\u51fa\u76f8\u5173\u4e14\u6709\u9884\u6d4b\u6027\u7684\u5206\u5b50\u5c5e\u6027\uff0c\u589e\u5f3a\u5c5e\u6027\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.06168", "pdf": "https://arxiv.org/pdf/2508.06168", "abs": "https://arxiv.org/abs/2508.06168", "authors": ["Hsing-Ping Liang", "Che-Wei Chang", "Yao-Chung Fan"], "title": "Improving Table Retrieval with Question Generation from Partial Tables", "categories": ["cs.IR"], "comment": "TRL@ACL2025", "summary": "Recent advances in open-domain question answering over tables have widely\nadopted large language models (LLMs) under the Retriever-Reader architecture.\nPrior works have effectively leveraged LLMs to tackle the complex reasoning\ndemands of the Reader component, such as text-to-text, text-to-SQL, and multi\nhop reasoning. In contrast, the Retriever component has primarily focused on\noptimizing the query representation-training retrievers to retrieve relevant\ntables based on questions, or to select keywords from questions for matching\ntable segments. However, little attention has been given to enhancing how\ntables themselves are represented in embedding space to better align with\nquestions. To address this, we propose QGpT (Question Generation from Partial\nTables), a simple yet effective method that uses an LLM to generate synthetic\nquestions based on small portions of a table. These questions are generated to\nsimulate how a user might query the content of the table currently under\nconsideration. The generated questions are then jointly embedded with the\npartial table segments used for generation, enhancing semantic alignment with\nuser queries. Without the need to embed entire tables, our method significantly\nimproves retrieval performance across multiple benchmarks for both dense and\nlate-interaction retrievers.", "AI": {"tldr": "\u63d0\u51faQGpT\u65b9\u6cd5\uff0c\u7528LLM\u57fa\u4e8e\u8868\u7684\u5c0f\u90e8\u5206\u751f\u6210\u5408\u6210\u95ee\u9898\uff0c\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u57df\u8868\u683c\u95ee\u7b54Retriever\u7ec4\u4ef6\u5927\u591a\u5173\u6ce8\u67e5\u8be2\u8868\u793a\u4f18\u5316\uff0c\u5ffd\u7565\u8868\u672c\u8eab\u5728\u5d4c\u5165\u7a7a\u95f4\u7684\u8868\u793a\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faQGpT\u65b9\u6cd5\uff0c\u7528LLM\u57fa\u4e8e\u8868\u7684\u5c0f\u90e8\u5206\u751f\u6210\u5408\u6210\u95ee\u9898\uff0c\u5c06\u751f\u6210\u95ee\u9898\u4e0e\u90e8\u5206\u8868\u6bb5\u8054\u5408\u5d4c\u5165\u3002", "result": "\u65e0\u9700\u5d4c\u5165\u6574\u4e2a\u8868\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bc6\u96c6\u548c\u540e\u671f\u4ea4\u4e92\u68c0\u7d22\u5668\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u7684\u68c0\u7d22\u6027\u80fd\u3002", "conclusion": "QGpT\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u80fd\u63d0\u5347\u8868\u4e0e\u95ee\u9898\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u6539\u5584\u68c0\u7d22\u6027\u80fd\u3002"}}
{"id": "2508.06214", "pdf": "https://arxiv.org/pdf/2508.06214", "abs": "https://arxiv.org/abs/2508.06214", "authors": ["Hai Zhong", "Xun Wang", "Zhuoran Li", "Longbo Huang"], "title": "Reparameterization Proximal Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reparameterization policy gradient (RPG) is promising for improving sample\nefficiency by leveraging differentiable dynamics. However, a critical barrier\nis its training instability, where high-variance gradients can destabilize the\nlearning process. To address this, we draw inspiration from Proximal Policy\nOptimization (PPO), which uses a surrogate objective to enable stable sample\nreuse in the model-free setting. We first establish a connection between this\nsurrogate objective and RPG, which has been largely unexplored and is\nnon-trivial. Then, we bridge this gap by demonstrating that the\nreparameterization gradient of a PPO-like surrogate objective can be computed\nefficiently using backpropagation through time. Based on this key insight, we\npropose Reparameterization Proximal Policy Optimization (RPO), a stable and\nsample-efficient RPG-based method. RPO enables multiple epochs of stable sample\nreuse by optimizing a clipped surrogate objective tailored for RPG, while being\nfurther stabilized by Kullback-Leibler (KL) divergence regularization and\nremaining fully compatible with existing variance reduction methods. We\nevaluate RPO on a suite of challenging locomotion and manipulation tasks, where\nexperiments demonstrate that our method achieves superior sample efficiency and\nstrong performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eRPG\u7684\u7a33\u5b9a\u4e14\u6837\u672c\u9ad8\u6548\u65b9\u6cd5RPO\uff0c\u5728\u8fd0\u52a8\u548c\u64cd\u4f5c\u4efb\u52a1\u4e2d\u53d6\u5f97\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3RPG\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3001\u68af\u5ea6\u65b9\u5dee\u5927\u7684\u95ee\u9898\u3002", "method": "\u5efa\u7acbPPO\u4ee3\u7406\u76ee\u6807\u4e0eRPG\u7684\u8054\u7cfb\uff0c\u63d0\u51faRPO\uff0c\u901a\u8fc7\u4f18\u5316\u88c1\u526a\u4ee3\u7406\u76ee\u6807\u3001KL\u6563\u5ea6\u6b63\u5219\u5316\u7b49\u5b9e\u73b0\u7a33\u5b9a\u6837\u672c\u590d\u7528\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u5177\u6709\u6311\u6218\u6027\u7684\u8fd0\u52a8\u548c\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0cRPO\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\u3002", "conclusion": "RPO\u662f\u4e00\u79cd\u7a33\u5b9a\u4e14\u6837\u672c\u9ad8\u6548\u7684\u57fa\u4e8eRPG\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.05637", "pdf": "https://arxiv.org/pdf/2508.05637", "abs": "https://arxiv.org/abs/2508.05637", "authors": ["Siddharth Gangwar", "David A. Selby", "Sebastian J. Vollmer"], "title": "Automated Visualization Makeovers with LLMs", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Making a good graphic that accurately and efficiently conveys the desired\nmessage to the audience is both an art and a science, typically not taught in\nthe data science curriculum. Visualisation makeovers are exercises where the\ncommunity exchange feedback to improve charts and data visualizations. Can\nmulti-modal large language models (LLMs) emulate this task? Given a plot in the\nform of an image file, or the code used to generate it, an LLM, primed with a\nlist of visualization best practices, is employed to semi-automatically\ngenerate constructive criticism to produce a better plot. Our system is centred\naround prompt engineering of a pre-trained model, relying on a combination of\nuserspecified guidelines and any latent knowledge of data visualization\npractices that might lie within an LLMs training corpus. Unlike other works,\nthe focus is not on generating valid visualization scripts from raw data or\nprompts, but on educating the user how to improve their existing data\nvisualizations according to an interpretation of best practices. A quantitative\nevaluation is performed to measure the sensitivity of the LLM agent to various\nplotting issues across different chart types. We make the tool available as a\nsimple self-hosted applet with an accessible Web interface.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u8fdb\u884c\u53ef\u89c6\u5316\u6539\u8fdb\uff0c\u4ecb\u7ecd\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u7684\u7cfb\u7edf\uff0c\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u5e76\u5c06\u5de5\u5177\u505a\u6210\u7f51\u9875\u5c0f\u7a0b\u5e8f\u3002", "motivation": "\u5236\u4f5c\u597d\u7684\u56fe\u8868\u672a\u5728\u6570\u636e\u79d1\u5b66\u8bfe\u7a0b\u4e2d\u6559\u6388\uff0c\u53ef\u89c6\u5316\u6539\u8fdb\u53ef\u63d0\u5347\u56fe\u8868\u8d28\u91cf\uff0c\u7814\u7a76\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u5b8c\u6210\u6b64\u4efb\u52a1\u3002", "method": "\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u63d0\u793a\u5de5\u7a0b\uff0c\u7ed3\u5408\u7528\u6237\u6307\u5b9a\u6307\u5357\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8bed\u6599\u4e2d\u7684\u6f5c\u5728\u77e5\u8bc6\uff0c\u5bf9\u4e0d\u540c\u56fe\u8868\u7c7b\u578b\u7684\u7ed8\u56fe\u95ee\u9898\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u51fa\u53ef\u6839\u636e\u6700\u4f73\u5b9e\u8df5\u4e3a\u7528\u6237\u73b0\u6709\u6570\u636e\u53ef\u89c6\u5316\u63d0\u4f9b\u6539\u8fdb\u5efa\u8bae\u7684\u7cfb\u7edf\uff0c\u5e76\u4ee5\u7b80\u5355\u7684\u81ea\u6258\u7ba1\u5c0f\u7a0b\u5e8f\u548c\u7f51\u9875\u754c\u9762\u5f62\u5f0f\u63d0\u4f9b\u5de5\u5177\u3002", "conclusion": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u7528\u4e8e\u534a\u81ea\u52a8\u5316\u751f\u6210\u5efa\u8bbe\u6027\u6279\u8bc4\u4ee5\u6539\u8fdb\u6570\u636e\u53ef\u89c6\u5316\uff0c\u80fd\u5e2e\u52a9\u7528\u6237\u63d0\u5347\u73b0\u6709\u53ef\u89c6\u5316\u6548\u679c\u3002"}}
{"id": "2508.06328", "pdf": "https://arxiv.org/pdf/2508.06328", "abs": "https://arxiv.org/abs/2508.06328", "authors": ["Zhiyou Xiao", "Qinhan Yu", "Binghui Li", "Geng Chen", "Chong Chen", "Wentao Zhang"], "title": "M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation", "categories": ["cs.IR"], "comment": null, "summary": "Current research on Multimodal Retrieval-Augmented Generation (MRAG) enables\ndiverse multimodal inputs but remains limited to single-modality outputs,\nrestricting expressive capacity and practical utility. In contrast, real-world\napplications often demand both multimodal inputs and multimodal outputs for\neffective communication and grounded reasoning. Motivated by the recent success\nof Reinforcement Learning (RL) in complex reasoning tasks for Large Language\nModels (LLMs), we adopt RL as a principled and effective paradigm to address\nthe multi-step, outcome-driven challenges inherent in multimodal output\ngeneration. Here, we introduce M2IO-R1, a novel framework for Multimodal\nRetrieval-Augmented Multimodal Generation (MRAMG) that supports both multimodal\ninputs and outputs. Central to our framework is an RL-based inserter,\nInserter-R1-3B, trained with Group Relative Policy Optimization to guide image\nselection and placement in a controllable and semantically aligned manner.\nEmpirical results show that our lightweight 3B inserter achieves strong\nreasoning capabilities with significantly reduced latency, outperforming\nbaselines in both quality and efficiency.", "AI": {"tldr": "\u73b0\u6709MRAG\u7814\u7a76\u591a\u4e3a\u5355\u6a21\u6001\u8f93\u51fa\uff0c\u672c\u6587\u63d0\u51fa\u652f\u6301\u591a\u6a21\u6001\u8f93\u5165\u8f93\u51fa\u7684M2IO - R1\u6846\u67b6\uff0c\u5176\u57fa\u4e8eRL\u7684\u63d2\u5165\u5668\u6027\u80fd\u4f18\u3002", "motivation": "\u5f53\u524dMRAG\u7814\u7a76\u5355\u6a21\u6001\u8f93\u51fa\u9650\u5236\u4e86\u8868\u8fbe\u80fd\u529b\u548c\u5b9e\u7528\u6027\uff0c\u73b0\u5b9e\u5e94\u7528\u9700\u8981\u591a\u6a21\u6001\u8f93\u5165\u8f93\u51fa\uff0c\u4e14RL\u5728LLMs\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u6210\u529f\u3002", "method": "\u91c7\u7528RL\u8303\u5f0f\uff0c\u5f15\u5165M2IO - R1\u6846\u67b6\uff0c\u4f7f\u7528Group Relative Policy Optimization\u8bad\u7ec3\u57fa\u4e8eRL\u7684\u63d2\u5165\u5668Inserter - R1 - 3B\u3002", "result": "\u8f7b\u91cf\u7ea73B\u63d2\u5165\u5668\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\uff0c\u5728\u8d28\u91cf\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "\u6240\u63d0M2IO - R1\u6846\u67b6\u6709\u6548\uff0c\u57fa\u4e8eRL\u7684\u63d2\u5165\u5668\u5728\u591a\u6a21\u6001\u8f93\u51fa\u751f\u6210\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2508.06450", "pdf": "https://arxiv.org/pdf/2508.06450", "abs": "https://arxiv.org/abs/2508.06450", "authors": ["Daria Tikhonovich", "Nikita Zelinskiy", "Aleksandr V. Petrov", "Mayya Spirina", "Andrei Semenov", "Andrey V. Savchenko", "Sergei Kuliev"], "title": "eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion", "categories": ["cs.IR", "cs.LG"], "comment": "Accepted at ACM RecSys 2025", "summary": "Since their introduction, Transformer-based models, such as SASRec and\nBERT4Rec, have become common baselines for sequential recommendations,\nsurpassing earlier neural and non-neural methods. A number of following\npublications have shown that the effectiveness of these models can be improved\nby, for example, slightly updating the architecture of the Transformer layers,\nusing better training objectives, and employing improved loss functions.\nHowever, the additivity of these modular improvements has not been\nsystematically benchmarked - this is the gap we aim to close in this paper.\nThrough our experiments, we identify a very strong model that uses SASRec's\ntraining objective, LiGR Transformer layers, and Sampled Softmax Loss. We call\nthis combination eSASRec (Enhanced SASRec). While we primarily focus on\nrealistic, production-like evaluation, in our preliminarily study we find that\ncommon academic benchmarks show eSASRec to be 23% more effective compared to\nthe most recent state-of-the-art models, such as ActionPiece. In our main\nproduction-like benchmark, eSASRec resides on the Pareto frontier in terms of\nthe accuracy-coverage tradeoff (alongside the recent industrial models HSTU and\nFuXi. As the modifications compared to the original SASRec are relatively\nstraightforward and no extra features are needed (such as timestamps in HSTU),\nwe believe that eSASRec can be easily integrated into existing recommendation\npipelines and can can serve as a strong yet very simple baseline for emerging\ncomplicated algorithms. To facilitate this, we provide the open-source\nimplementations for our models and benchmarks in repository\nhttps://github.com/blondered/transformer_benchmark", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9Transformer\u6a21\u578b\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u6a21\u5757\u5316\u6539\u8fdb\u7684\u53ef\u52a0\u6027\u7f3a\u4e4f\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u7684\u95ee\u9898\uff0c\u63d0\u51faeSASRec\u6a21\u578b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6548\u679c\u826f\u597d\u4e14\u6613\u96c6\u6210\uff0c\u8fd8\u63d0\u4f9b\u5f00\u6e90\u5b9e\u73b0\u3002", "motivation": "\u5f53\u524dTransformer\u6a21\u578b\u5728\u5e8f\u5217\u63a8\u8350\u4e2d\u867d\u6709\u6539\u8fdb\uff0c\u4f46\u6a21\u5757\u5316\u6539\u8fdb\u7684\u53ef\u52a0\u6027\u7f3a\u4e4f\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u7ed3\u5408SASRec\u7684\u8bad\u7ec3\u76ee\u6807\u3001LiGR Transformer\u5c42\u548cSampled Softmax Loss\u6784\u5efaeSASRec\u6a21\u578b\u3002", "result": "\u5728\u5e38\u89c1\u5b66\u672f\u57fa\u51c6\u4e2d\uff0ceSASRec\u6bd4\u6700\u65b0\u7684\u5148\u8fdb\u6a21\u578b\u6709\u6548\u7387\u9ad823%\uff1b\u5728\u751f\u4ea7\u7ea7\u57fa\u51c6\u4e2d\uff0ceSASRec\u5728\u51c6\u786e\u7387 - \u8986\u76d6\u7387\u6743\u8861\u65b9\u9762\u5904\u4e8e\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "conclusion": "eSASRec\u4fee\u6539\u7b80\u5355\u3001\u65e0\u9700\u989d\u5916\u7279\u5f81\uff0c\u53ef\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709\u63a8\u8350\u6d41\u7a0b\uff0c\u80fd\u4f5c\u4e3a\u65b0\u5174\u590d\u6742\u7b97\u6cd5\u7684\u5f3a\u5927\u800c\u7b80\u5355\u7684\u57fa\u7ebf\uff0c\u4f5c\u8005\u8fd8\u63d0\u4f9b\u4e86\u5f00\u6e90\u5b9e\u73b0\u3002"}}
{"id": "2508.06244", "pdf": "https://arxiv.org/pdf/2508.06244", "abs": "https://arxiv.org/abs/2508.06244", "authors": ["Xurun Wang", "Guangrui Liu", "Xinjie Li", "Haoyu He", "Lin Yao", "Weizhe Zhang"], "title": "Membership Inference Attack with Partial Features", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Machine learning models have been shown to be susceptible to membership\ninference attack, which can be used to determine whether a given sample appears\nin the training data. Existing membership inference methods commonly assume\nthat the adversary has full access to the features of the target sample. This\nassumption, however, does not hold in many real-world scenarios where only\npartial features information is available, thereby limiting the applicability\nof these methods. In this work, we study an inference scenario where the\nadversary observes only partial features of each sample and aims to infer\nwhether this observed subset was present in the training set of the target\nmodel. We define this problem as Partial Feature Membership Inference (PFMI).\nTo address this problem, we propose MRAD (Memory-guided Reconstruction and\nAnomaly Detection), a two-stage attack framework. In the first stage, MRAD\noptimizes the unknown feature values to minimize the loss of the sample. In the\nsecond stage, it measures the deviation between the reconstructed sample and\nthe training distribution using anomaly detection. Empirical results\ndemonstrate that MRAD is effective across a range of datasets, and maintains\ncompatibility with various off-the-shelf anomaly detection techniques. For\nexample, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of\nthe missing features.", "AI": {"tldr": "\u7814\u7a76\u90e8\u5206\u7279\u5f81\u6210\u5458\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u51faMRAD\u653b\u51fb\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u548c\u517c\u5bb9\u6027\u3002", "motivation": "\u73b0\u6709\u6210\u5458\u63a8\u7406\u65b9\u6cd5\u5047\u8bbe\u5bf9\u624b\u80fd\u83b7\u53d6\u76ee\u6807\u6837\u672c\u5168\u90e8\u7279\u5f81\uff0c\u5728\u5f88\u591a\u73b0\u5b9e\u573a\u666f\u4e0d\u6210\u7acb\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u9002\u7528\u6027\uff0c\u9700\u7814\u7a76\u90e8\u5206\u7279\u5f81\u63a8\u7406\u573a\u666f\u3002", "method": "\u63d0\u51faMRAD\u4e24\u9636\u6bb5\u653b\u51fb\u6846\u67b6\uff0c\u7b2c\u4e00\u9636\u6bb5\u4f18\u5316\u672a\u77e5\u7279\u5f81\u503c\u4f7f\u6837\u672c\u635f\u5931\u6700\u5c0f\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7528\u5f02\u5e38\u68c0\u6d4b\u8861\u91cf\u91cd\u6784\u6837\u672c\u4e0e\u8bad\u7ec3\u5206\u5e03\u7684\u504f\u5dee\u3002", "result": "MRAD\u5728\u4e00\u7cfb\u5217\u6570\u636e\u96c6\u4e0a\u6709\u6548\uff0c\u80fd\u4e0e\u591a\u79cd\u73b0\u6210\u5f02\u5e38\u68c0\u6d4b\u6280\u672f\u517c\u5bb9\uff0c\u5982\u5728STL - 10\u4e0a\u7f3a\u593140%\u7279\u5f81\u65f6AUC\u7ea6\u4e3a0.6\u3002", "conclusion": "MRAD\u662f\u89e3\u51b3\u90e8\u5206\u7279\u5f81\u6210\u5458\u63a8\u7406\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2508.06455", "pdf": "https://arxiv.org/pdf/2508.06455", "abs": "https://arxiv.org/abs/2508.06455", "authors": ["Nikita Sukhorukov", "Danil Gusak", "Evgeny Frolov"], "title": "Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting", "categories": ["cs.IR", "cs.LG"], "comment": null, "summary": "Cold-start challenges in recommender systems necessitate leveraging auxiliary\nfeatures beyond user-item interactions. However, the presence of irrelevant or\nnoisy features can degrade predictive performance, whereas an excessive number\nof features increases computational demands, leading to higher memory\nconsumption and prolonged training times.\n  To address this, we propose a feature selection strategy that prioritizes the\nuser behavioral information. Our method enhances the feature representation by\nincorporating correlations from collaborative behavior data using a hybrid\nmatrix factorization technique and then ranks features using a mechanism based\non the maximum volume algorithm. This approach identifies the most influential\nfeatures, striking a balance between recommendation accuracy and computational\nefficiency. We conduct an extensive evaluation across various datasets and\nhybrid recommendation models, demonstrating that our method excels in\ncold-start scenarios by selecting minimal yet highly effective feature subsets.\nEven under strict feature reduction, our approach surpasses existing feature\nselection techniques while maintaining superior efficiency.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u63d0\u51fa\u4f18\u5148\u8003\u8651\u7528\u6237\u884c\u4e3a\u4fe1\u606f\u7684\u7279\u5f81\u9009\u62e9\u7b56\u7565\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u4e14\u6548\u7387\u9ad8\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u51b7\u542f\u52a8\u9700\u5229\u7528\u8f85\u52a9\u7279\u5f81\uff0c\u4f46\u65e0\u5173\u6216\u566a\u58f0\u7279\u5f81\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u7279\u5f81\u8fc7\u591a\u4f1a\u589e\u52a0\u8ba1\u7b97\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7279\u5f81\u9009\u62e9\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4f18\u5148\u8003\u8651\u7528\u6237\u884c\u4e3a\u4fe1\u606f\u7684\u7b56\u7565\uff0c\u7ed3\u5408\u6df7\u5408\u77e9\u9635\u5206\u89e3\u6280\u672f\u589e\u5f3a\u7279\u5f81\u8868\u793a\uff0c\u7528\u57fa\u4e8e\u6700\u5927\u4f53\u79ef\u7b97\u6cd5\u7684\u673a\u5236\u5bf9\u7279\u5f81\u6392\u5e8f\u3002", "result": "\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u6df7\u5408\u63a8\u8350\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u80fd\u9009\u62e9\u6700\u5c11\u4f46\u6700\u6709\u6548\u7684\u7279\u5f81\u5b50\u96c6\uff0c\u5728\u4e25\u683c\u7279\u5f81\u7ea6\u51cf\u4e0b\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5728\u63a8\u8350\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2508.06249", "pdf": "https://arxiv.org/pdf/2508.06249", "abs": "https://arxiv.org/abs/2508.06249", "authors": ["David Kacz\u00e9r", "Magnus J\u00f8rgenv\u00e5g", "Clemens Vetter", "Lucie Flek", "Florian Mai"], "title": "In-Training Defenses against Emergent Misalignment in Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Fine-tuning lets practitioners repurpose aligned large language models (LLMs)\nfor new domains, yet recent work reveals emergent misalignment (EMA): Even a\nsmall, domain-specific fine-tune can induce harmful behaviors far outside the\ntarget domain. Even in the case where model weights are hidden behind a\nfine-tuning API, this gives attackers inadvertent access to a broadly\nmisaligned model in a way that can be hard to detect from the fine-tuning data\nalone. We present the first systematic study of in-training safeguards against\nEMA that are practical for providers who expose fine-tuning via an API. We\ninvestigate four training regularization interventions: (i) KL-divergence\nregularization toward a safe reference model, (ii) $\\ell_2$ distance in feature\nspace, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving\nof a small amount of safe training examples from a general instruct-tuning\ndataset. We first evaluate the methods' emergent misalignment effect across\nfour malicious, EMA-inducing tasks. Second, we assess the methods' impacts on\nbenign tasks. We conclude with a discussion of open questions in emergent\nmisalignment research.", "AI": {"tldr": "\u7814\u7a76\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u51fa\u73b0\u7684\u65b0\u5174\u5931\u51c6\u95ee\u9898\uff0c\u63d0\u51fa\u56db\u79cd\u8bad\u7ec3\u6b63\u5219\u5316\u5e72\u9884\u65b9\u6cd5\u5e76\u8bc4\u4f30\u6548\u679c\uff0c\u6700\u540e\u8ba8\u8bba\u7814\u7a76\u4e2d\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4f1a\u51fa\u73b0\u65b0\u5174\u5931\u51c6\uff0c\u5373\u4f7f\u4f7f\u7528\u5fae\u8c03API\u9690\u85cf\u6a21\u578b\u6743\u91cd\u4e5f\u4f1a\u8ba9\u653b\u51fb\u8005\u8bbf\u95ee\u5230\u5e7f\u6cdb\u5931\u51c6\u7684\u6a21\u578b\uff0c\u4e14\u96be\u4ee5\u4ec5\u4ece\u5fae\u8c03\u6570\u636e\u68c0\u6d4b\uff0c\u56e0\u6b64\u8981\u7814\u7a76\u9488\u5bf9\u65b0\u5174\u5931\u51c6\u7684\u8bad\u7ec3\u9632\u62a4\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u8bad\u7ec3\u6b63\u5219\u5316\u5e72\u9884\u65b9\u6cd5\uff0c\u5305\u62ec\u5411\u5b89\u5168\u53c2\u8003\u6a21\u578b\u7684KL\u6563\u5ea6\u6b63\u5219\u5316\u3001\u7279\u5f81\u7a7a\u95f4\u7684l2\u8ddd\u79bb\u3001\u6295\u5f71\u5230\u5b89\u5168\u5b50\u7a7a\u95f4\uff08SafeLoRA\uff09\u4ee5\u53ca\u63d2\u5165\u901a\u7528\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\u4e2d\u7684\u5c11\u91cf\u5b89\u5168\u8bad\u7ec3\u793a\u4f8b\u3002", "result": "\u5148\u8bc4\u4f30\u65b9\u6cd5\u5728\u56db\u79cd\u6076\u610f\u3001\u5f15\u53d1\u65b0\u5174\u5931\u51c6\u4efb\u52a1\u4e2d\u7684\u65b0\u5174\u5931\u51c6\u6548\u679c\uff0c\u518d\u8bc4\u4f30\u5bf9\u826f\u6027\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u65b0\u5174\u5931\u51c6\u7814\u7a76\u4e2d\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002"}}
{"id": "2508.06004", "pdf": "https://arxiv.org/pdf/2508.06004", "abs": "https://arxiv.org/abs/2508.06004", "authors": ["Weihang Guo", "Zhao Song", "Jiahao Zhang"], "title": "When a Paper Has 1000 Authors: Rethinking Citation Metrics in the Era of LLMs", "categories": ["cs.DL", "cs.IR"], "comment": null, "summary": "Author-level citation metrics provide a practical, interpretable, and\nscalable signal of scholarly influence in a complex research ecosystem. It has\nbeen widely used as a proxy in hiring decisions. However, the past five years\nhave seen the rapid emergence of large-scale publications in the field of large\nlanguage models and foundation models, with papers featuring hundreds to\nthousands of co-authors and receiving tens of thousands of citations within\nmonths. For example, Gemini has 1361 authors and has been cited around 4600\ntimes in 19 months. In such cases, traditional metrics, such as total citation\ncount and the $h$-index, fail to meaningfully distinguish individual\ncontributions. Therefore, we propose the following research question: How can\none identify standout researchers among thousands of co-authors in large-scale\nLLM papers? This question is particularly important in scenarios such as\nacademic hiring and funding decisions. In this paper, we introduce a novel\ncitation metric designed to address this challenge by balancing contributions\nacross large-scale and small-scale publications. We propose the SBCI index,\nanalyze its theoretical properties, and evaluate its behavior on synthetic\npublication datasets. Our results demonstrate that the proposed metric provides\na more robust and discriminative assessment of individual scholarly impact in\nthe era of large-scale collaborations.", "AI": {"tldr": "\u4f20\u7edf\u4f5c\u8005\u5f15\u7528\u6307\u6807\u5728\u5927\u8bed\u8a00\u6a21\u578b\u7b49\u5927\u89c4\u6a21\u5408\u4f5c\u8bba\u6587\u573a\u666f\u5931\u6548\uff0c\u672c\u6587\u63d0\u51faSBCI\u6307\u6570\u89e3\u51b3\u6b64\u95ee\u9898\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8fc7\u53bb\u4e94\u5e74\u5927\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u7840\u6a21\u578b\u9886\u57df\u5927\u89c4\u6a21\u8bba\u6587\u6d8c\u73b0\uff0c\u4f20\u7edf\u5f15\u7528\u6307\u6807\u65e0\u6cd5\u6709\u6548\u533a\u5206\u4f17\u591a\u5408\u8457\u8005\u7684\u4e2a\u4eba\u8d21\u732e\uff0c\u5728\u5b66\u672f\u62db\u8058\u548c\u8d44\u52a9\u51b3\u7b56\u7b49\u573a\u666f\u9700\u65b0\u6307\u6807\u3002", "method": "\u63d0\u51faSBCI\u6307\u6570\uff0c\u5206\u6790\u5176\u7406\u8bba\u6027\u8d28\u5e76\u5728\u5408\u6210\u51fa\u7248\u7269\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5176\u8868\u73b0\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6307\u6807\u5728\u5927\u89c4\u6a21\u5408\u4f5c\u65f6\u4ee3\u80fd\u5bf9\u4e2a\u4eba\u5b66\u672f\u5f71\u54cd\u529b\u63d0\u4f9b\u66f4\u7a33\u5065\u548c\u6709\u533a\u5206\u5ea6\u7684\u8bc4\u4f30\u3002", "conclusion": "SBCI\u6307\u6570\u53ef\u89e3\u51b3\u5927\u89c4\u6a21\u5408\u4f5c\u8bba\u6587\u4e2d\u533a\u5206\u4f5c\u8005\u8d21\u732e\u7684\u95ee\u9898\uff0c\u80fd\u66f4\u597d\u8bc4\u4f30\u4e2a\u4eba\u5b66\u672f\u5f71\u54cd\u3002"}}
{"id": "2508.06251", "pdf": "https://arxiv.org/pdf/2508.06251", "abs": "https://arxiv.org/abs/2508.06251", "authors": ["Alejandro Moreno R.", "Desale Fentaw", "Samuel Palmer", "Ra\u00fal Salles de Padua", "Ninad Dixit", "Samuel Mugel", "Roman Or\u00fas", "Manuel Radons", "Josef Menter", "Ali Abedi"], "title": "Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)", "categories": ["cs.LG", "cs.AI", "cs.CR", "quant-ph"], "comment": "10 pages", "summary": "Synthetic data generation is a key technique in modern artificial\nintelligence, addressing data scarcity, privacy constraints, and the need for\ndiverse datasets in training robust models. In this work, we propose a method\nfor generating privacy-preserving high-quality synthetic tabular data using\nTensor Networks, specifically Matrix Product States (MPS). We benchmark the\nMPS-based generative model against state-of-the-art models such as CTGAN, VAE,\nand PrivBayes, focusing on both fidelity and privacy-preserving capabilities.\nTo ensure differential privacy (DP), we integrate noise injection and gradient\nclipping during training, enabling privacy guarantees via R\\'enyi Differential\nPrivacy accounting. Across multiple metrics analyzing data fidelity and\ndownstream machine learning task performance, our results show that MPS\noutperforms classical models, particularly under strict privacy constraints.\nThis work highlights MPS as a promising tool for privacy-aware synthetic data\ngeneration. By combining the expressive power of tensor network representations\nwith formal privacy mechanisms, the proposed approach offers an interpretable\nand scalable alternative for secure data sharing. Its structured design\nfacilitates integration into sensitive domains where both data quality and\nconfidentiality are critical.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5f20\u91cf\u7f51\u7edc\uff08MPS\uff09\u751f\u6210\u9690\u79c1\u4fdd\u62a4\u7684\u9ad8\u8d28\u91cf\u5408\u6210\u8868\u683c\u6570\u636e\uff0c\u7ecf\u4e0eSOTA\u6a21\u578b\u5bf9\u6bd4\uff0cMPS\u5728\u4e25\u683c\u9690\u79c1\u7ea6\u675f\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u662f\u9690\u79c1\u611f\u77e5\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u6709\u524d\u666f\u5de5\u5177\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u3001\u9690\u79c1\u7ea6\u675f\u4ee5\u53ca\u8bad\u7ec3\u9c81\u68d2\u6a21\u578b\u5bf9\u591a\u6837\u5316\u6570\u636e\u96c6\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528MPS\u751f\u6210\u5408\u6210\u8868\u683c\u6570\u636e\uff0c\u4e0eCTGAN\u3001VAE\u548cPrivBayes\u7b49\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bad\u7ec3\u65f6\u96c6\u6210\u566a\u58f0\u6ce8\u5165\u548c\u68af\u5ea6\u88c1\u526a\u4ee5\u786e\u4fdd\u5dee\u5206\u9690\u79c1\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u4fdd\u771f\u5ea6\u548c\u4e0b\u6e38\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u6027\u80fd\u6307\u6807\u4e0a\uff0cMPS\u5c24\u5176\u5728\u4e25\u683c\u9690\u79c1\u7ea6\u675f\u4e0b\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\u3002", "conclusion": "MPS\u662f\u9690\u79c1\u611f\u77e5\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u6709\u524d\u666f\u5de5\u5177\uff0c\u7ed3\u5408\u5f20\u91cf\u7f51\u7edc\u8868\u793a\u80fd\u529b\u4e0e\u9690\u79c1\u673a\u5236\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u5b89\u5168\u6570\u636e\u5171\u4eab\u65b9\u6848\uff0c\u4fbf\u4e8e\u96c6\u6210\u5230\u5bf9\u6570\u636e\u8d28\u91cf\u548c\u4fdd\u5bc6\u6027\u8981\u6c42\u9ad8\u7684\u9886\u57df\u3002"}}
{"id": "2508.06103", "pdf": "https://arxiv.org/pdf/2508.06103", "abs": "https://arxiv.org/abs/2508.06103", "authors": ["Mohamed Basem", "Islam Oshallah", "Ali Hamdi", "Ammar Mohammed"], "title": "Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs", "categories": ["cs.CL", "cs.IR"], "comment": "6 pages , 2 figures , Accepted in IMSA 2025,Egypt ,\n  https://imsa.msa.edu.eg/", "summary": "This paper presents two effective approaches for Extractive Question\nAnswering (QA) on the Quran. It addresses challenges related to complex\nlanguage, unique terminology, and deep meaning in the text. The second uses\nfew-shot prompting with instruction-tuned large language models such as Gemini\nand DeepSeek. A specialized Arabic prompt framework is developed for span\nextraction. A strong post-processing system integrates subword alignment,\noverlap suppression, and semantic filtering. This improves precision and\nreduces hallucinations. Evaluations show that large language models with Arabic\ninstructions outperform traditional fine-tuned models. The best configuration\nachieves a pAP10 score of 0.637. The results confirm that prompt-based\ninstruction tuning is effective for low-resource, semantically rich QA tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u300a\u53e4\u5170\u7ecf\u300b\u62bd\u53d6\u5f0f\u95ee\u7b54\u6709\u6548\u65b9\u6cd5\uff0c\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u95e8\u6846\u67b6\u53ca\u540e\u5904\u7406\u7cfb\u7edf\uff0c\u8bc4\u4f30\u663e\u793a\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u8bc1\u5b9e\u57fa\u4e8e\u63d0\u793a\u7684\u6307\u4ee4\u8c03\u4f18\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u300a\u53e4\u5170\u7ecf\u300b\u6587\u672c\u590d\u6742\u8bed\u8a00\u3001\u72ec\u7279\u672f\u8bed\u548c\u6df1\u5c42\u542b\u4e49\u5e26\u6765\u7684\u62bd\u53d6\u5f0f\u95ee\u7b54\u6311\u6218\u3002", "method": "\u4e00\u662f\u4f7f\u7528\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5982Gemini\u548cDeepSeek\u8fdb\u884c\u5c11\u6837\u672c\u63d0\u793a\uff1b\u4e8c\u662f\u5f00\u53d1\u4e13\u95e8\u7684\u963f\u62c9\u4f2f\u8bed\u63d0\u793a\u6846\u67b6\u7528\u4e8e\u8de8\u5ea6\u63d0\u53d6\uff1b\u6784\u5efa\u5f3a\u5927\u7684\u540e\u5904\u7406\u7cfb\u7edf\uff0c\u96c6\u6210\u5b50\u8bcd\u5bf9\u9f50\u3001\u91cd\u53e0\u6291\u5236\u548c\u8bed\u4e49\u8fc7\u6ee4\u3002", "result": "\u4f7f\u7528\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u6a21\u578b\uff0c\u6700\u4f73\u914d\u7f6epAP10\u5206\u6570\u8fbe0.637\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684\u6307\u4ee4\u8c03\u4f18\u5bf9\u4f4e\u8d44\u6e90\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u95ee\u7b54\u4efb\u52a1\u6709\u6548\u3002"}}
{"id": "2508.06257", "pdf": "https://arxiv.org/pdf/2508.06257", "abs": "https://arxiv.org/abs/2508.06257", "authors": ["Jielong Lu", "Zhihao Wu", "Jiajun Yu", "Jiajun Bu", "Haishuai Wang"], "title": "Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors", "categories": ["cs.LG"], "comment": null, "summary": "Integrating multi-omics datasets through data-driven analysis offers a\ncomprehensive understanding of the complex biological processes underlying\nvarious diseases, particularly cancer. Graph Neural Networks (GNNs) have\nrecently demonstrated remarkable ability to exploit relational structures in\nbiological data, enabling advances in multi-omics integration for cancer\nsubtype classification. Existing approaches often neglect the intricate\ncoupling between heterogeneous omics, limiting their capacity to resolve subtle\ncancer subtype heterogeneity critical for precision oncology. To address these\nlimitations, we propose a framework named Graph Transformer for Multi-omics\nCancer Subtype Classification (GTMancer). This framework builds upon the GNN\noptimization problem and extends its application to complex multi-omics data.\nSpecifically, our method leverages contrastive learning to embed multi-omics\ndata into a unified semantic space. We unroll the multiplex graph optimization\nproblem in that unified space and introduce dual sets of attention coefficients\nto capture structural graph priors both within and among multi-omics data. This\napproach enables global omics information to guide the refining of the\nrepresentations of individual omics. Empirical experiments on seven real-world\ncancer datasets demonstrate that GTMancer outperforms existing state-of-the-art\nalgorithms.", "AI": {"tldr": "\u63d0\u51faGTMancer\u6846\u67b6\u7528\u4e8e\u591a\u7ec4\u5b66\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\uff0c\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u548c\u6ce8\u610f\u529b\u7cfb\u6570\uff0c\u5728\u4e03\u4e2a\u771f\u5b9e\u764c\u75c7\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u7ec4\u5b66\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\u65b9\u6cd5\u5e38\u5ffd\u7565\u5f02\u6784\u7ec4\u5b66\u95f4\u590d\u6742\u8026\u5408\uff0c\u9650\u5236\u89e3\u51b3\u764c\u75c7\u4e9a\u578b\u5f02\u8d28\u6027\u7684\u80fd\u529b\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGTMancer\u6846\u67b6\uff0c\u57fa\u4e8eGNN\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u5c06\u591a\u7ec4\u5b66\u6570\u636e\u5d4c\u5165\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\uff0c\u5c55\u5f00\u591a\u8def\u56fe\u4f18\u5316\u95ee\u9898\u5e76\u5f15\u5165\u4e24\u7ec4\u6ce8\u610f\u529b\u7cfb\u6570\u3002", "result": "\u5728\u4e03\u4e2a\u771f\u5b9e\u4e16\u754c\u764c\u75c7\u6570\u636e\u96c6\u4e0a\uff0cGTMancer\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7b97\u6cd5\u3002", "conclusion": "GTMancer\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u591a\u7ec4\u5b66\u6570\u636e\u8fdb\u884c\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\uff0c\u5177\u6709\u66f4\u597d\u6027\u80fd\u3002"}}
{"id": "2508.05653", "pdf": "https://arxiv.org/pdf/2508.05653", "abs": "https://arxiv.org/abs/2508.05653", "authors": ["Jules Clerc", "Domitile Lourdeaux", "Mohamed Sallak", "Johann Barbier", "Marc Ravaine"], "title": "Modeling Interactive Narrative Systems: A Formal Approach", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Interactive Narrative Systems (INS) have revolutionized digital experiences\nby empowering users to actively shape their stories, diverging from traditional\npassive storytelling. However, the field faces challenges due to fragmented\nresearch efforts and diverse system representations. This paper introduces a\nformal representation framework for INS, inspired by diverse approaches from\nthe state of the art. By providing a consistent vocabulary and modeling\nstructure, the framework facilitates the analysis, the description and\ncomparison of INS properties. Experimental validations on the \"Little Red\nRiding Hood\" scenario highlight the usefulness of the proposed formalism and\nits impact on improving the evaluation of INS. This work aims to foster\ncollaboration and coherence within the INS research community by proposing a\nmethodology for formally representing these systems.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4ea4\u4e92\u5f0f\u53d9\u4e8b\u7cfb\u7edf\uff08INS\uff09\u6b63\u5f0f\u8868\u793a\u6846\u67b6\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u7528\u6027\uff0c\u65e8\u5728\u4fc3\u8fdbINS\u7814\u7a76\u793e\u533a\u5408\u4f5c\u4e0e\u4e00\u81f4\u6027\u3002", "motivation": "INS\u9886\u57df\u7814\u7a76\u5206\u6563\u3001\u7cfb\u7edf\u8868\u793a\u591a\u6837\uff0c\u9762\u4e34\u6311\u6218\uff0c\u9700\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u53d7\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u542f\u53d1\uff0c\u63d0\u51fa\u6b63\u5f0f\u8868\u793a\u6846\u67b6\uff0c\u63d0\u4f9b\u4e00\u81f4\u8bcd\u6c47\u548c\u5efa\u6a21\u7ed3\u6784\u3002", "result": "\u5728\u201c\u5c0f\u7ea2\u5e3d\u201d\u573a\u666f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u7528\u6027\u53ca\u5bf9\u6539\u5584INS\u8bc4\u4f30\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u80fd\u4fc3\u8fdbINS\u7814\u7a76\u793e\u533a\u7684\u534f\u4f5c\u4e0e\u4e00\u81f4\u6027\u3002"}}
{"id": "2508.06401", "pdf": "https://arxiv.org/pdf/2508.06401", "abs": "https://arxiv.org/abs/2508.06401", "authors": ["Andrew Brown", "Muhammad Roman", "Barry Devereux"], "title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges", "categories": ["cs.DL", "cs.AI", "cs.CL", "cs.IR"], "comment": "58 pages", "summary": "This systematic review of the research literature on retrieval-augmented\ngeneration (RAG) provides a focused analysis of the most highly cited studies\npublished between 2020 and May 2025. A total of 128 articles met our inclusion\ncriteria. The records were retrieved from ACM Digital Library, IEEE Xplore,\nScopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP).\nRAG couples a neural retriever with a generative language model, grounding\noutput in up-to-date, non-parametric memory while retaining the semantic\ngeneralisation stored in model weights. Guided by the PRISMA 2020 framework, we\n(i) specify explicit inclusion and exclusion criteria based on citation count\nand research questions, (ii) catalogue datasets, architectures, and evaluation\npractices, and (iii) synthesise empirical evidence on the effectiveness and\nlimitations of RAG. To mitigate citation-lag bias, we applied a lower\ncitation-count threshold to papers published in 2025 so that emerging\nbreakthroughs with naturally fewer citations were still captured. This review\nclarifies the current research landscape, highlights methodological gaps, and\ncharts priority directions for future research.", "AI": {"tldr": "\u5bf92020\u5e74\u81f32025\u5e745\u6708\u9ad8\u5f15\u7528\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7814\u7a76\u6587\u732e\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\uff0c\u660e\u786e\u7814\u7a76\u73b0\u72b6\u3001\u65b9\u6cd5\u5dee\u8ddd\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5206\u6790\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u9886\u57df\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002", "method": "\u57fa\u4e8ePRISMA 2020\u6846\u67b6\uff0c\u660e\u786e\u6587\u7ae0\u7eb3\u5165\u548c\u6392\u9664\u6807\u51c6\uff0c\u4ece\u591a\u4e2a\u6570\u636e\u5e93\u68c0\u7d22\u6587\u732e\uff0c\u7f16\u76ee\u6570\u636e\u96c6\u3001\u67b6\u6784\u548c\u8bc4\u4f30\u5b9e\u8df5\uff0c\u7efc\u5408\u5b9e\u8bc1\u8bc1\u636e\u3002\u4e3a\u51cf\u5c11\u5f15\u7528\u6ede\u540e\u504f\u5dee\uff0c\u5bf92025\u5e74\u8bba\u6587\u8bbe\u7f6e\u8f83\u4f4e\u5f15\u7528\u9608\u503c\u3002", "result": "\u5171128\u7bc7\u6587\u7ae0\u7b26\u5408\u7eb3\u5165\u6807\u51c6\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u660e\u786e\u4e86\u5f53\u524d\u7814\u7a76\u683c\u5c40\uff0c\u7a81\u51fa\u4e86\u65b9\u6cd5\u5b66\u5dee\u8ddd\uff0c\u5e76\u89c4\u5212\u4e86\u672a\u6765\u7814\u7a76\u7684\u4f18\u5148\u65b9\u5411\u3002"}}
{"id": "2508.06269", "pdf": "https://arxiv.org/pdf/2508.06269", "abs": "https://arxiv.org/abs/2508.06269", "authors": ["Zhuoran Li", "Xun Wang", "Hai Zhong", "Longbo Huang"], "title": "OM2P: Offline Multi-Agent Mean-Flow Policy", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generative models, especially diffusion and flow-based models, have been\npromising in offline multi-agent reinforcement learning. However, integrating\npowerful generative models into this framework poses unique challenges. In\nparticular, diffusion and flow-based policies suffer from low sampling\nefficiency due to their iterative generation processes, making them impractical\nin time-sensitive or resource-constrained settings. To tackle these\ndifficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel\noffline MARL algorithm to achieve efficient one-step action sampling. To\naddress the misalignment between generative objectives and reward maximization,\nwe introduce a reward-aware optimization scheme that integrates a\ncarefully-designed mean-flow matching loss with Q-function supervision.\nAdditionally, we design a generalized timestep distribution and a\nderivative-free estimation strategy to reduce memory overhead and improve\ntraining stability. Empirical evaluations on Multi-Agent Particle and MuJoCo\nbenchmarks demonstrate that OM2P achieves superior performance, with up to a\n3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.\nOur approach represents the first to successfully integrate mean-flow model\ninto offline MARL, paving the way for practical and scalable generative\npolicies in cooperative multi-agent settings.", "AI": {"tldr": "\u63d0\u51faOM2P\u7b97\u6cd5\u89e3\u51b3\u79bb\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u751f\u6210\u6a21\u578b\u7684\u95ee\u9898\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u9996\u6b21\u5c06\u5e73\u5747\u6d41\u6a21\u578b\u96c6\u6210\u5230\u79bb\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u548c\u57fa\u4e8e\u6d41\u7684\u7b56\u7565\u5728\u79bb\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b58\u5728\u91c7\u6837\u6548\u7387\u4f4e\u95ee\u9898\uff0c\u65e0\u6cd5\u7528\u4e8e\u65f6\u95f4\u654f\u611f\u6216\u8d44\u6e90\u53d7\u9650\u573a\u666f\uff0c\u4e14\u751f\u6210\u76ee\u6807\u4e0e\u5956\u52b1\u6700\u5927\u5316\u5b58\u5728\u504f\u5dee\u3002", "method": "\u63d0\u51faOM2P\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u4e00\u6b65\u52a8\u4f5c\u91c7\u6837\uff0c\u5f15\u5165\u5956\u52b1\u611f\u77e5\u4f18\u5316\u65b9\u6848\uff0c\u8bbe\u8ba1\u5e7f\u4e49\u65f6\u95f4\u6b65\u5206\u5e03\u548c\u65e0\u5bfc\u6570\u4f30\u8ba1\u7b56\u7565\u3002", "result": "\u5728Multi - Agent Particle\u548cMuJoCo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOM2P\u6027\u80fd\u4f18\u8d8a\uff0cGPU\u5185\u5b58\u4f7f\u7528\u6700\u591a\u51cf\u5c113.8\u500d\uff0c\u8bad\u7ec3\u65f6\u95f4\u6700\u591a\u52a0\u5feb10.8\u500d\u3002", "conclusion": "\u9996\u6b21\u6210\u529f\u5c06\u5e73\u5747\u6d41\u6a21\u578b\u96c6\u6210\u5230\u79bb\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u4e3a\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u573a\u666f\u7684\u751f\u6210\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2508.06280", "pdf": "https://arxiv.org/pdf/2508.06280", "abs": "https://arxiv.org/abs/2508.06280", "authors": ["Gokul Adethya T", "S. Jaya Nirmala"], "title": "A Study on Regularization-Based Continual Learning Methods for Indic ASR", "categories": ["cs.LG"], "comment": null, "summary": "Indias linguistic diversity poses significant challenges for developing\ninclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual\nmodels, which require simultaneous access to all language data, are impractical\ndue to the sequential arrival of data and privacy constraints. Continual\nLearning (CL) offers a solution by enabling models to learn new languages\nsequentially without catastrophically forgetting previously learned knowledge.\nThis paper investigates CL for ASR on Indian languages using a subset of the\nIndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,\ninitially pretrained on Hindi, which is then incrementally trained on eight\nadditional Indian languages, for a total sequence of nine languages. We\nevaluate three prominent regularization- and distillation-based CL strategies:\nElastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning\nwithout Forgetting (LwF), selected for their suitability in no-replay,\nprivacy-conscious scenarios. Performance is analyzed using Word Error Rate\n(WER) for both RNN-T and CTC paths on clean and noisy data, as well as\nknowledge retention via Backward Transfer. We also explore the impact of\nvarying the number of training epochs (1, 2, 5, and 10) per task. Results,\ncompared against naive fine-tuning, demonstrate CLs effectiveness in mitigating\nforgetting, making it a promising approach for scalable ASR in diverse Indian\nlanguages under realistic constraints. The code is available at:\nhttps://github.com/FrozenWolf-Cyber/Indic-CL-ASR", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u5370\u5ea6\u8bed\u8a00\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u4e2d\u4f7f\u7528\u6301\u7eed\u5b66\u4e60\uff08CL\uff09\uff0c\u8bc4\u4f30\u4e09\u79cdCL\u7b56\u7565\uff0c\u7ed3\u679c\u8868\u660eCL\u80fd\u6709\u6548\u51cf\u8f7b\u9057\u5fd8\uff0c\u662f\u53ef\u6269\u5c55ASR\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002", "motivation": "\u5370\u5ea6\u8bed\u8a00\u591a\u6837\u6027\u7ed9\u5f00\u53d1\u5305\u5bb9\u6027ASR\u7cfb\u7edf\u5e26\u6765\u6311\u6218\uff0c\u4f20\u7edf\u591a\u8bed\u8a00\u6a21\u578b\u56e0\u6570\u636e\u987a\u5e8f\u5230\u8fbe\u548c\u9690\u79c1\u9650\u5236\u4e0d\u5b9e\u7528\uff0c\u800cCL\u53ef\u4f7f\u6a21\u578b\u987a\u5e8f\u5b66\u4e60\u65b0\u8bed\u8a00\u4e14\u4e0d\u9057\u5fd8\u65e7\u77e5\u8bc6\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eConformer\u7684\u6df7\u5408RNN - T/CTC\u6a21\u578b\uff0c\u5148\u5728\u5370\u5730\u8bed\u4e0a\u9884\u8bad\u7ec3\uff0c\u518d\u9010\u6b65\u5728\u53e6\u59168\u79cd\u5370\u5ea6\u8bed\u8a00\u4e0a\u8bad\u7ec3\uff1b\u8bc4\u4f30\u4e09\u79cd\u6b63\u5219\u5316\u548c\u84b8\u998f\u7684CL\u7b56\u7565\uff1b\u7528WER\u5206\u6790\u6027\u80fd\uff0c\u901a\u8fc7\u5411\u540e\u8fc1\u79fb\u5206\u6790\u77e5\u8bc6\u4fdd\u7559\uff1b\u63a2\u7d22\u4e0d\u540c\u8bad\u7ec3\u8f6e\u6570\u7684\u5f71\u54cd\u3002", "result": "\u4e0e\u6734\u7d20\u5fae\u8c03\u76f8\u6bd4\uff0cCL\u80fd\u6709\u6548\u51cf\u8f7b\u9057\u5fd8\u3002", "conclusion": "CL\u662f\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u7528\u4e8e\u5370\u5ea6\u591a\u79cd\u8bed\u8a00\u53ef\u6269\u5c55ASR\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002"}}
{"id": "2508.06292", "pdf": "https://arxiv.org/pdf/2508.06292", "abs": "https://arxiv.org/abs/2508.06292", "authors": ["Sanja Karilanova", "Subhrakanti Dey", "Ay\u00e7a \u00d6z\u00e7elikkale"], "title": "Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback", "categories": ["cs.LG"], "comment": "15 pages, 7 Tables, 6 Figures", "summary": "Neuromorphic computing is an emerging technology enabling low-latency and\nenergy-efficient signal processing. A key algorithmic tool in neuromorphic\ncomputing is spiking neural networks (SNNs). SNNs are biologically inspired\nneural networks which utilize stateful neurons, and provide low-bit data\nprocessing by encoding and decoding information using spikes. Similar to SNNs,\ndeep state-space models (SSMs) utilize stateful building blocks. However, deep\nSSMs, which recently achieved competitive performance in various temporal\nmodeling tasks, are typically designed with high-precision activation functions\nand no reset mechanisms. To bridge the gains offered by SNNs and the recent\ndeep SSM models, we propose a novel multiple-output spiking neuron model that\ncombines a linear, general SSM state transition with a non-linear feedback\nmechanism through reset. Compared to the existing neuron models for SNNs, our\nproposed model clearly conceptualizes the differences between the spiking\nfunction, the reset condition and the reset action. The experimental results on\nvarious tasks, i.e., a keyword spotting task, an event-based vision task and a\nsequential pattern recognition task, show that our proposed model achieves\nperformance comparable to existing benchmarks in the SNN literature. Our\nresults illustrate how the proposed reset mechanism can overcome instability\nand enable learning even when the linear part of neuron dynamics is unstable,\nallowing us to go beyond the strictly enforced stability of linear dynamics in\nrecent deep SSM models.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u591a\u8f93\u51fa\u8109\u51b2\u795e\u7ecf\u5143\u6a21\u578b\uff0c\u7ed3\u5408SNNs\u548c\u6df1\u5ea6SSM\u6a21\u578b\u4f18\u52bf\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4e0e\u73b0\u6709\u57fa\u51c6\u76f8\u5f53\uff0c\u4e14\u80fd\u514b\u670d\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u6865\u63a5\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u548c\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSMs\uff09\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u7ebf\u6027\u901a\u7528SSM\u72b6\u6001\u8f6c\u6362\u548c\u975e\u7ebf\u6027\u53cd\u9988\u673a\u5236\u7684\u65b0\u578b\u591a\u8f93\u51fa\u8109\u51b2\u795e\u7ecf\u5143\u6a21\u578b\u3002", "result": "\u5728\u5173\u952e\u8bcd\u8bc6\u522b\u3001\u57fa\u4e8e\u4e8b\u4ef6\u7684\u89c6\u89c9\u4efb\u52a1\u548c\u987a\u5e8f\u6a21\u5f0f\u8bc6\u522b\u4efb\u52a1\u7b49\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u6a21\u578b\u6027\u80fd\u4e0eSNN\u6587\u732e\u4e2d\u7684\u73b0\u6709\u57fa\u51c6\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u91cd\u7f6e\u673a\u5236\u80fd\u514b\u670d\u4e0d\u7a33\u5b9a\u6027\uff0c\u5373\u4f7f\u795e\u7ecf\u5143\u52a8\u529b\u5b66\u7ebf\u6027\u90e8\u5206\u4e0d\u7a33\u5b9a\u4e5f\u80fd\u5b66\u4e60\uff0c\u7a81\u7834\u4e86\u6df1\u5ea6SSM\u6a21\u578b\u4e2d\u7ebf\u6027\u52a8\u529b\u5b66\u4e25\u683c\u7684\u7a33\u5b9a\u6027\u9650\u5236\u3002"}}
{"id": "2508.06336", "pdf": "https://arxiv.org/pdf/2508.06336", "abs": "https://arxiv.org/abs/2508.06336", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Victor Oei", "Anna Penzkofer", "Andreas Bulling"], "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "comment": "16 pages", "summary": "We introduce Unsupervised Partner Design (UPD) - a population-free,\nmulti-agent reinforcement learning framework for robust ad-hoc teamwork that\nadaptively generates training partners without requiring pretrained partners or\nmanual parameter tuning. UPD constructs diverse partners by stochastically\nmixing an ego agent's policy with biased random behaviours and scores them\nusing a variance-based learnability metric that prioritises partners near the\nego agent's current learning frontier. We show that UPD can be integrated with\nunsupervised environment design, resulting in the first method enabling fully\nunsupervised curricula over both level and partner distributions in a\ncooperative setting. Through extensive evaluations on Overcooked-AI and the\nOvercooked Generalisation Challenge, we demonstrate that this dynamic partner\ncurriculum is highly effective: UPD consistently outperforms both\npopulation-based and population-free baselines as well as ablations. In a user\nstudy, we further show that UPD achieves higher returns than all baselines and\nwas perceived as significantly more adaptive, more human-like, a better\ncollaborator, and less frustrating.", "AI": {"tldr": "\u4ecb\u7ecd\u65e0\u76d1\u7763\u4f19\u4f34\u8bbe\u8ba1\uff08UPD\uff09\u6846\u67b6\uff0c\u53ef\u81ea\u9002\u5e94\u751f\u6210\u8bad\u7ec3\u4f19\u4f34\uff0c\u80fd\u4e0e\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u7ed3\u5408\uff0c\u5728\u591a\u4efb\u52a1\u8bc4\u4f30\u548c\u7528\u6237\u7814\u7a76\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u9884\u8bad\u7ec3\u4f19\u4f34\u548c\u624b\u52a8\u8c03\u53c2\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u5b9e\u73b0\u9c81\u68d2\u7684\u4e34\u65f6\u56e2\u961f\u5408\u4f5c\u3002", "method": "\u901a\u8fc7\u968f\u673a\u6df7\u5408\u81ea\u6211\u667a\u80fd\u4f53\u7b56\u7565\u4e0e\u6709\u504f\u968f\u673a\u884c\u4e3a\u6784\u5efa\u591a\u6837\u5316\u4f19\u4f34\uff0c\u7528\u57fa\u4e8e\u65b9\u5dee\u7684\u53ef\u5b66\u4e60\u6027\u6307\u6807\u8bc4\u5206\uff0c\u8fd8\u53ef\u4e0e\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u96c6\u6210\u3002", "result": "\u5728Overcooked - AI\u548cOvercooked\u6cdb\u5316\u6311\u6218\u8bc4\u4f30\u4e2d\uff0cUPD\u6301\u7eed\u4f18\u4e8e\u57fa\u4e8e\u79cd\u7fa4\u548c\u65e0\u79cd\u7fa4\u7684\u57fa\u7ebf\u53ca\u6d88\u878d\u5b9e\u9a8c\uff1b\u7528\u6237\u7814\u7a76\u4e2d\uff0cUPD\u56de\u62a5\u7387\u66f4\u9ad8\uff0c\u88ab\u8ba4\u4e3a\u66f4\u5177\u9002\u5e94\u6027\u3001\u66f4\u50cf\u4eba\u7c7b\u3001\u534f\u4f5c\u66f4\u597d\u4e14\u66f4\u5c11\u632b\u8d25\u611f\u3002", "conclusion": "UPD\u6846\u67b6\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u4e34\u65f6\u56e2\u961f\u5408\u4f5c\u4e2d\u6709\u6548\uff0c\u80fd\u63d0\u4f9b\u52a8\u6001\u4f19\u4f34\u8bfe\u7a0b\u3002"}}
{"id": "2508.06346", "pdf": "https://arxiv.org/pdf/2508.06346", "abs": "https://arxiv.org/abs/2508.06346", "authors": ["Mert Can Kurucu", "Tufan Kumbasar", "\u0130brahim Eksin", "M\u00fcjde G\u00fczelkaya"], "title": "Introducing Fractional Classification Loss for Robust Learning with Noisy Labels", "categories": ["cs.LG"], "comment": "25 pages, 6 figures, 2 table. Submitted to Pattern Recognition", "summary": "Robust loss functions are crucial for training deep neural networks in the\npresence of label noise, yet existing approaches require extensive,\ndataset-specific hyperparameter tuning. In this work, we introduce Fractional\nClassification Loss (FCL), an adaptive robust loss that automatically\ncalibrates its robustness to label noise during training. Built within the\nactive-passive loss framework, FCL employs the fractional derivative of the\nCross-Entropy (CE) loss as its active component and the Mean Absolute Error\n(MAE) as its passive loss component. With this formulation, we demonstrate that\nthe fractional derivative order $\\mu$ spans a family of loss functions that\ninterpolate between MAE-like robustness and CE-like fast convergence.\nFurthermore, we integrate $\\mu$ into the gradient-based optimization as a\nlearnable parameter and automatically adjust it to optimize the trade-off\nbetween robustness and convergence speed. We reveal that FCL's unique property\nestablishes a critical trade-off that enables the stable learning of $\\mu$:\nlower log penalties on difficult or mislabeled examples improve robustness but\nimpose higher penalties on easy or clean data, reducing model confidence in\nthem. Consequently, FCL can dynamically reshape its loss landscape to achieve\neffective classification performance under label noise. Extensive experiments\non benchmark datasets show that FCL achieves state-of-the-art results without\nthe need for manual hyperparameter tuning.", "AI": {"tldr": "\u63d0\u51fa\u5206\u6570\u5206\u7c7b\u635f\u5931\uff08FCL\uff09\uff0c\u53ef\u81ea\u9002\u5e94\u6821\u51c6\u5bf9\u6807\u7b7e\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u53c2\uff0c\u5b9e\u9a8c\u8fbe\u5230SOTA\u3002", "motivation": "\u73b0\u6709\u9c81\u68d2\u635f\u5931\u51fd\u6570\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u65f6\u9700\u5927\u91cf\u7279\u5b9a\u6570\u636e\u96c6\u7684\u8d85\u53c2\u6570\u8c03\u6574\u3002", "method": "\u5728\u4e3b\u52a8 - \u88ab\u52a8\u635f\u5931\u6846\u67b6\u5185\u6784\u5efaFCL\uff0c\u4f7f\u7528\u4ea4\u53c9\u71b5\u635f\u5931\u7684\u5206\u6570\u5bfc\u6570\u4f5c\u4e3a\u4e3b\u52a8\u90e8\u5206\uff0c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4f5c\u4e3a\u88ab\u52a8\u90e8\u5206\uff0c\u5c06\u5206\u6570\u5bfc\u6570\u9636\u6570\u03bc\u4f5c\u4e3a\u53ef\u5b66\u4e60\u53c2\u6570\u4f18\u5316\u9c81\u68d2\u6027\u548c\u6536\u655b\u901f\u5ea6\u7684\u6743\u8861\u3002", "result": "FCL\u53ef\u52a8\u6001\u91cd\u5851\u635f\u5931\u666f\u89c2\uff0c\u5728\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u65e0\u9700\u624b\u52a8\u8c03\u53c2\u8fbe\u5230SOTA\u7ed3\u679c\u3002", "conclusion": "FCL\u80fd\u5728\u6807\u7b7e\u566a\u58f0\u4e0b\u52a8\u6001\u8c03\u6574\uff0c\u6709\u6548\u63d0\u5347\u5206\u7c7b\u6027\u80fd\uff0c\u65e0\u9700\u624b\u52a8\u8d85\u53c2\u6570\u8c03\u6574\u3002"}}
{"id": "2508.06353", "pdf": "https://arxiv.org/pdf/2508.06353", "abs": "https://arxiv.org/abs/2508.06353", "authors": ["Parichit Sharma", "Marcin Stanislaw", "Hasan Kurban", "Oguzhan Kulekci", "Mehmet Dalkilic"], "title": "Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces Geometric-k-means (or Gk-means for short), a novel\napproach that significantly enhances the efficiency and energy economy of the\nwidely utilized k-means algorithm, which, despite its inception over five\ndecades ago, remains a cornerstone in machine learning applications. The\nessence of Gk-means lies in its active utilization of geometric principles,\nspecifically scalar projection, to significantly accelerate the algorithm\nwithout sacrificing solution quality. This geometric strategy enables a more\ndiscerning focus on data points that are most likely to influence cluster\nupdates, which we call as high expressive data (HE). In contrast, low\nexpressive data (LE), does not impact clustering outcome, is effectively\nbypassed, leading to considerable reductions in computational overhead.\nExperiments spanning synthetic, real-world and high-dimensional datasets,\ndemonstrate Gk-means is significantly better than traditional and state of the\nart (SOTA) k-means variants in runtime and distance computations (DC).\nMoreover, Gk-means exhibits better resource efficiency, as evidenced by its\nreduced energy footprint, placing it as more sustainable alternative.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Geometric - k - means\uff08Gk - means\uff09\uff0c\u5b83\u80fd\u63d0\u5347k - means\u7b97\u6cd5\u6548\u7387\u548c\u80fd\u6e90\u7ecf\u6d4e\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u548c\u5148\u8fdb\u7684k - means\u53d8\u4f53\u3002", "motivation": "\u63d0\u5347\u5e7f\u6cdb\u4f7f\u7528\u7684k - means\u7b97\u6cd5\u7684\u6548\u7387\u548c\u80fd\u6e90\u7ecf\u6d4e\u6027\u3002", "method": "\u79ef\u6781\u5229\u7528\u51e0\u4f55\u539f\u7406\uff08\u6807\u91cf\u6295\u5f71\uff09\uff0c\u805a\u7126\u9ad8\u8868\u8fbe\u6570\u636e\uff0c\u7ed5\u8fc7\u4f4e\u8868\u8fbe\u6570\u636e\u4ee5\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u5408\u6210\u3001\u771f\u5b9e\u4e16\u754c\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cGk - means\u5728\u8fd0\u884c\u65f6\u95f4\u548c\u8ddd\u79bb\u8ba1\u7b97\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u5148\u8fdb\u7684k - means\u53d8\u4f53\uff0c\u4e14\u8d44\u6e90\u6548\u7387\u66f4\u597d\uff0c\u80fd\u6e90\u6d88\u8017\u66f4\u4f4e\u3002", "conclusion": "Gk - means\u662f\u66f4\u5177\u53ef\u6301\u7eed\u6027\u7684k - means\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.06361", "pdf": "https://arxiv.org/pdf/2508.06361", "abs": "https://arxiv.org/abs/2508.06361", "authors": ["Zhaomin Wu", "Mingzhe Du", "See-Kiong Ng", "Bingsheng He"], "title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have been widely deployed in reasoning,\nplanning, and decision-making tasks, making their trustworthiness a critical\nconcern. The potential for intentional deception, where an LLM deliberately\nfabricates or conceals information to serve a hidden objective, remains a\nsignificant and underexplored threat. Existing studies typically induce such\ndeception by explicitly setting a \"hidden\" objective through prompting or\nfine-tuning, which may not fully reflect real-world human-LLM interactions.\nMoving beyond this human-induced deception, we investigate LLMs' self-initiated\ndeception on benign prompts. To address the absence of ground truth in this\nevaluation, we propose a novel framework using \"contact searching questions.\"\nThis framework introduces two statistical metrics derived from psychological\nprinciples to quantify the likelihood of deception. The first, the Deceptive\nIntention Score, measures the model's bias towards a hidden objective. The\nsecond, Deceptive Behavior Score, measures the inconsistency between the LLM's\ninternal belief and its expressed output. Upon evaluating 14 leading LLMs, we\nfind that both metrics escalate as task difficulty increases, rising in\nparallel for most models. Building on these findings, we formulate a\nmathematical model to explain this behavior. These results reveal that even the\nmost advanced LLMs exhibit an increasing tendency toward deception when\nhandling complex problems, raising critical concerns for the deployment of LLM\nagents in complex and crucial domains.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u4e3b\u6b3a\u9a97\u884c\u4e3a\uff0c\u63d0\u51fa\u65b0\u6846\u67b6\u8bc4\u4f30\uff0c\u53d1\u73b0\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\u65f6\u6a21\u578b\u6b3a\u9a97\u503e\u5411\u4e0a\u5347\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u4e3a\u4eba\u4e3a\u8bf1\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u6b3a\u9a97\uff0c\u672a\u53cd\u6620\u771f\u5b9e\u4eba\u673a\u4ea4\u4e92\uff0c\u9700\u7814\u7a76\u6a21\u578b\u81ea\u4e3b\u6b3a\u9a97\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u201c\u8054\u7cfb\u4eba\u641c\u7d22\u95ee\u9898\u201d\u7684\u65b0\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u4e8e\u5fc3\u7406\u5b66\u539f\u7406\u7684\u4e24\u4e2a\u7edf\u8ba1\u6307\u6807\u91cf\u5316\u6b3a\u9a97\u53ef\u80fd\u6027\u3002", "result": "\u8bc4\u4f3014\u4e2a\u9886\u5148\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\u65f6\u4e24\u4e2a\u6307\u6807\u5747\u4e0a\u5347\uff0c\u591a\u6570\u6a21\u578b\u4e2d\u4e8c\u8005\u5e76\u884c\u4e0a\u5347\u3002", "conclusion": "\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u95ee\u9898\u65f6\u6b3a\u9a97\u503e\u5411\u4e5f\u589e\u52a0\uff0c\u5bf9\u5176\u5728\u590d\u6742\u5173\u952e\u9886\u57df\u7684\u90e8\u7f72\u63d0\u51fa\u62c5\u5fe7\u3002"}}
{"id": "2508.06364", "pdf": "https://arxiv.org/pdf/2508.06364", "abs": "https://arxiv.org/abs/2508.06364", "authors": ["Renyi Zhou", "Huimin Zhu", "Jing Tang", "Min Li"], "title": "ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Achieving precise control over a molecule's biological activity-encompassing\ntargeted activation/inhibition, cooperative multi-target modulation, and\noff-target toxicity mitigation-remains a critical challenge in de novo drug\ndesign. However, existing generative methods primarily focus on producing\nmolecules with a single desired activity, lacking integrated mechanisms for the\nsimultaneous management of multiple intended and unintended molecular\ninteractions. Here, we propose ActivityDiff, a generative approach based on the\nclassifier-guidance technique of diffusion models. It leverages separately\ntrained drug-target classifiers for both positive and negative guidance,\nenabling the model to enhance desired activities while minimizing harmful\noff-target effects. Experimental results show that ActivityDiff effectively\nhandles essential drug design tasks, including single-/dual-target generation,\nfragment-constrained dual-target design, selective generation to enhance target\nspecificity, and reduction of off-target effects. These results demonstrate the\neffectiveness of classifier-guided diffusion in balancing efficacy and safety\nin molecular design. Overall, our work introduces a novel paradigm for\nachieving integrated control over molecular activity, and provides ActivityDiff\nas a versatile and extensible framework.", "AI": {"tldr": "\u63d0\u51faActivityDiff\u65b9\u6cd5\uff0c\u53ef\u540c\u65f6\u7ba1\u7406\u5206\u5b50\u591a\u79cd\u76f8\u4e92\u4f5c\u7528\uff0c\u6709\u6548\u5904\u7406\u836f\u7269\u8bbe\u8ba1\u4efb\u52a1\uff0c\u4e3a\u5206\u5b50\u6d3b\u6027\u7efc\u5408\u63a7\u5236\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u65b9\u6cd5\u7f3a\u4e4f\u540c\u65f6\u7ba1\u7406\u5206\u5b50\u591a\u79cd\u76f8\u4e92\u4f5c\u7528\u7684\u673a\u5236\uff0c\u96be\u4ee5\u5b9e\u73b0\u5bf9\u5206\u5b50\u751f\u7269\u6d3b\u6027\u7684\u7cbe\u786e\u63a7\u5236\u3002", "method": "\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u5206\u7c7b\u5668\u5f15\u5bfc\u6280\u672f\uff0c\u5229\u7528\u6b63\u8d1f\u5206\u7c7b\u5668\u8fdb\u884c\u5f15\u5bfc\u3002", "result": "ActivityDiff\u80fd\u6709\u6548\u5904\u7406\u5355/\u53cc\u9776\u70b9\u751f\u6210\u3001\u7247\u6bb5\u7ea6\u675f\u53cc\u9776\u70b9\u8bbe\u8ba1\u7b49\u836f\u7269\u8bbe\u8ba1\u4efb\u52a1\u3002", "conclusion": "\u5206\u7c7b\u5668\u5f15\u5bfc\u7684\u6269\u6563\u65b9\u6cd5\u53ef\u5e73\u8861\u5206\u5b50\u8bbe\u8ba1\u7684\u6709\u6548\u6027\u548c\u5b89\u5168\u6027\uff0cActivityDiff\u662f\u901a\u7528\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002"}}
{"id": "2508.06387", "pdf": "https://arxiv.org/pdf/2508.06387", "abs": "https://arxiv.org/abs/2508.06387", "authors": ["Anurag Tripathi", "Vaibhav Patle", "Abhinav Jain", "Ayush Pundir", "Sairam Menon", "Ajeet Kumar Singh"], "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in IJCNN25", "summary": "Text-to-SQL bridges the gap between natural language and structured database\nlanguage, thus allowing non-technical users to easily query databases.\nTraditional approaches model text-to-SQL as a direct translation task, where a\ngiven Natural Language Query (NLQ) is mapped to an SQL command. Recent advances\nin large language models (LLMs) have significantly improved translation\naccuracy, however, these methods all require that the target database is\npre-specified. This becomes problematic in scenarios with multiple extensive\ndatabases, where identifying the correct database becomes a crucial yet\noverlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL\nframework to identify the user's intended database before generating SQL\nqueries. Our approach leverages LLMs and prompt engineering to extract implicit\ninformation from natural language queries (NLQs) in the form of a ruleset. We\nthen train a large db\\_id prediction model, which includes a RoBERTa-based\nfinetuned encoder, to predict the correct Database identifier (db\\_id) based on\nboth the NLQ and the LLM-generated rules. Finally, we refine the generated SQL\nby using critic agents to correct errors. Experimental results demonstrate that\nour framework outperforms the current state-of-the-art models in both database\nintent prediction and SQL generation accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u9636\u6bb5\u7aef\u5230\u7aef\u6587\u672c\u5230SQL\u6846\u67b6\uff0c\u5148\u8bc6\u522b\u6570\u636e\u5e93\uff0c\u518d\u751f\u6210SQL\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230SQL\u65b9\u6cd5\u9700\u9884\u6307\u5b9a\u76ee\u6807\u6570\u636e\u5e93\uff0c\u5728\u591a\u6570\u636e\u5e93\u573a\u666f\u4e0b\u8bc6\u522b\u6b63\u786e\u6570\u636e\u5e93\u8fd9\u4e00\u5173\u952e\u6b65\u9aa4\u88ab\u5ffd\u89c6\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u63d0\u793a\u5de5\u7a0b\u4ece\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u63d0\u53d6\u89c4\u5219\u96c6\uff0c\u8bad\u7ec3\u57fa\u4e8eRoBERTa\u5fae\u8c03\u7f16\u7801\u5668\u7684\u6570\u636e\u5e93ID\u9884\u6d4b\u6a21\u578b\uff0c\u7528\u6279\u8bc4\u4ee3\u7406\u4fee\u6b63\u751f\u6210\u7684SQL\u3002", "result": "\u6846\u67b6\u5728\u6570\u636e\u5e93\u610f\u56fe\u9884\u6d4b\u548cSQL\u751f\u6210\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u4e09\u9636\u6bb5\u7aef\u5230\u7aef\u6587\u672c\u5230SQL\u6846\u67b6\u6709\u6548\u53ef\u884c\uff0c\u80fd\u89e3\u51b3\u591a\u6570\u636e\u5e93\u573a\u666f\u4e0b\u6587\u672c\u5230SQL\u7684\u95ee\u9898\u3002"}}
{"id": "2508.06409", "pdf": "https://arxiv.org/pdf/2508.06409", "abs": "https://arxiv.org/abs/2508.06409", "authors": ["Wooyong Jung", "Sola Kim", "Dongwook Kim", "Maryam Tabar", "Dongwon Lee"], "title": "A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images", "categories": ["cs.LG"], "comment": "10 pages, Accepted to SBP-BRiMS 2025", "summary": "Homelessness in the United States has surged to levels unseen since the Great\nDepression. However, existing methods for monitoring it, such as point-in-time\n(PIT) counts, have limitations in terms of frequency, consistency, and spatial\ndetail. This study proposes a new approach using publicly available,\ncrowdsourced data, specifically 311 Service Calls and street-level imagery, to\ntrack and forecast homeless tent trends in San Francisco. Our predictive model\ncaptures fine-grained daily and neighborhood-level variations, uncovering\npatterns that traditional counts often overlook, such as rapid fluctuations\nduring the COVID-19 pandemic and spatial shifts in tent locations over time. By\nproviding more timely, localized, and cost-effective information, this approach\nserves as a valuable tool for guiding policy responses and evaluating\ninterventions aimed at reducing unsheltered homelessness.", "AI": {"tldr": "\u7f8e\u56fd\u65e0\u5bb6\u53ef\u5f52\u95ee\u9898\u4e25\u91cd\uff0c\u7814\u7a76\u7528\u4f17\u5305\u6570\u636e\u8ffd\u8e2a\u65e7\u91d1\u5c71\u65e0\u5bb6\u53ef\u5f52\u8005\u5e10\u7bf7\u8d8b\u52bf\uff0c\u63d0\u4f9b\u53ca\u65f6\u6709\u6548\u4fe1\u606f\u6307\u5bfc\u653f\u7b56\u3002", "motivation": "\u7f8e\u56fd\u65e0\u5bb6\u53ef\u5f52\u73b0\u8c61\u6fc0\u589e\uff0c\u73b0\u6709\u76d1\u6d4b\u65b9\u6cd5\u5b58\u5728\u9891\u7387\u3001\u4e00\u81f4\u6027\u548c\u7a7a\u95f4\u7ec6\u8282\u7b49\u65b9\u9762\u7684\u5c40\u9650\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u7684\u4f17\u5305\u6570\u636e\uff0c\u5982311\u670d\u52a1\u7535\u8bdd\u548c\u8857\u666f\u56fe\u50cf\uff0c\u6784\u5efa\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u6a21\u578b\u6355\u6349\u5230\u7ec6\u7c92\u5ea6\u7684\u6bcf\u65e5\u548c\u793e\u533a\u5c42\u9762\u53d8\u5316\uff0c\u53d1\u73b0\u4f20\u7edf\u7edf\u8ba1\u5e38\u5ffd\u7565\u7684\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u4f9b\u53ca\u65f6\u3001\u672c\u5730\u5316\u4e14\u4f4e\u6210\u672c\u7684\u4fe1\u606f\uff0c\u53ef\u6307\u5bfc\u653f\u7b56\u548c\u8bc4\u4f30\u5e72\u9884\u63aa\u65bd\u3002"}}
{"id": "2508.06412", "pdf": "https://arxiv.org/pdf/2508.06412", "abs": "https://arxiv.org/abs/2508.06412", "authors": ["Zichuan Liu", "Jinyu Wang", "Lei Song", "Jiang Bian"], "title": "Sample-efficient LLM Optimization with Reset Replay", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Recent advancements in post-training Large Language Models (LLMs),\nparticularly through Reinforcement Learning (RL) and preference optimization\nmethods, are key drivers for enhancing their reasoning capabilities. However,\nthese methods are often plagued by low sample efficiency and a susceptibility\nto primacy bias, where overfitting to initial experiences degrades policy\nquality and damages the learning process. To address these challenges, we\nintroduce LLM optimization with Reset Replay (LoRR), a general and powerful\nplugin designed to enhance sample efficiency in any preference-based\noptimization framework. LoRR core mechanism enables training at a high replay\nnumber, maximizing the utility of each collected data batch. To counteract the\nrisk of overfitting inherent in high-replay training, LoRR incorporates a\nperiodic reset strategy with reusing initial data, which preserves network\nplasticity. Furthermore, it leverages a hybrid optimization objective,\ncombining supervised fine-tuning (SFT) and preference-based losses to further\nbolster data exploitation. Our extensive experiments demonstrate that LoRR\nsignificantly boosts the performance of various preference optimization methods\non both mathematical and general reasoning benchmarks. Notably, an iterative\nDPO approach augmented with LoRR achieves comparable performance on challenging\nmath tasks, outperforming some complex and computationally intensive RL-based\nalgorithms. These findings highlight that LoRR offers a practical,\nsample-efficient, and highly effective paradigm for LLM finetuning, unlocking\ngreater performance from limited data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLoRR\u63d2\u4ef6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u6837\u672c\u6548\u7387\u4f4e\u548c\u6613\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u63d0\u5347\u591a\u79cd\u4f18\u5316\u65b9\u6cd5\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u548c\u6613\u53d7\u9996\u56e0\u504f\u5dee\u5f71\u54cd\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u5b66\u4e60\u8fc7\u7a0b\u53d7\u635f\u3002", "method": "\u5f15\u5165LoRR\u63d2\u4ef6\uff0c\u5176\u6838\u5fc3\u673a\u5236\u652f\u6301\u9ad8\u91cd\u653e\u6b21\u6570\u8bad\u7ec3\uff0c\u91c7\u7528\u5b9a\u671f\u91cd\u7f6e\u7b56\u7565\u4fdd\u6301\u7f51\u7edc\u53ef\u5851\u6027\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u4e0e\u504f\u597d\u635f\u5931\u7684\u6df7\u5408\u4f18\u5316\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLoRR\u663e\u8457\u63d0\u5347\u591a\u79cd\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\uff0c\u589e\u5f3a\u7684\u8fed\u4ee3DPO\u65b9\u6cd5\u5728\u56f0\u96be\u6570\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u53ef\u4e0e\u590d\u6742RL\u7b97\u6cd5\u5ab2\u7f8e\u3002", "conclusion": "LoRR\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u5b9e\u7528\u3001\u6837\u672c\u9ad8\u6548\u4e14\u6709\u6548\u7684\u8303\u5f0f\uff0c\u80fd\u4ece\u6709\u9650\u6570\u636e\u4e2d\u6316\u6398\u66f4\u5927\u6027\u80fd\u3002"}}
{"id": "2508.06467", "pdf": "https://arxiv.org/pdf/2508.06467", "abs": "https://arxiv.org/abs/2508.06467", "authors": ["Ameya Anjarlekar", "Sandeep Pombra"], "title": "LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection", "categories": ["cs.LG"], "comment": "14 Pages, 3 Figures, 11 Tables", "summary": "The growing legal and ethical scrutiny of large language models (LLMs)\nnecessitates effective machine unlearning, particularly for sensitive or\nunauthorized data. Existing empirical methods often yield incomplete forgetting\nor unintended degradation of unrelated knowledge due to poor localization. In\nthis work, we propose GRIN: a modular and targeted framework for LLM\nunlearning. GRIN introduces a novel gradient-ratio-based metric to identify\nparameters most responsible for memorizing forget data. We then perform\nselective noise injection into these parameters prior to fine-tuning, which\nimproves unlearning performance while maintaining model utility. Finally, we\npropose new evaluation metrics tailored to the LLM setting and validate our\napproach on standard benchmarks such as TOFU, WMDP, and SafePKU.", "AI": {"tldr": "\u63d0\u51faGRIN\u6846\u67b6\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u53bb\u5b66\u4e60\uff0c\u901a\u8fc7\u65b0\u6307\u6807\u548c\u9009\u62e9\u6027\u566a\u58f0\u6ce8\u5165\u63d0\u5347\u6027\u80fd\u5e76\u9a8c\u8bc1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9762\u4e34\u6cd5\u5f8b\u548c\u9053\u5fb7\u5ba1\u67e5\uff0c\u73b0\u6709\u7ecf\u9a8c\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u9700\u6709\u6548\u53bb\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGRIN\u6846\u67b6\uff0c\u5f15\u5165\u57fa\u4e8e\u68af\u5ea6\u6bd4\u7684\u6307\u6807\u8bc6\u522b\u53c2\u6570\uff0c\u5728\u5fae\u8c03\u524d\u5bf9\u53c2\u6570\u8fdb\u884c\u9009\u62e9\u6027\u566a\u58f0\u6ce8\u5165\uff0c\u8fd8\u63d0\u51fa\u65b0\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5728TOFU\u3001WMDP\u548cSafePKU\u7b49\u6807\u51c6\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u3002", "conclusion": "GRIN\u6846\u67b6\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u53bb\u5b66\u4e60\u6027\u80fd\u5e76\u4fdd\u6301\u6a21\u578b\u6548\u7528\u3002"}}
{"id": "2508.05674", "pdf": "https://arxiv.org/pdf/2508.05674", "abs": "https://arxiv.org/abs/2508.05674", "authors": ["Minghao Shao", "Nanda Rani", "Kimberly Milner", "Haoran Xi", "Meet Udeshi", "Saksham Aggarwal", "Venkata Sai Charan Putrevu", "Sandeep Kumar Shukla", "Prashanth Krishnamurthy", "Farshad Khorrami", "Ramesh Karri", "Muhammad Shafique"], "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Recent advances in LLM agentic systems have improved the automation of\noffensive security tasks, particularly for Capture the Flag (CTF) challenges.\nWe systematically investigate the key factors that drive agent success and\nprovide a detailed recipe for building effective LLM-based offensive security\nagents. First, we present CTFJudge, a framework leveraging LLM as a judge to\nanalyze agent trajectories and provide granular evaluation across CTF solving\nsteps. Second, we propose a novel metric, CTF Competency Index (CCI) for\npartial correctness, revealing how closely agent solutions align with\nhuman-crafted gold standards. Third, we examine how LLM hyperparameters, namely\ntemperature, top-p, and maximum token length, influence agent performance and\nautomated cybersecurity task planning. For rapid evaluation, we present\nCTFTiny, a curated benchmark of 50 representative CTF challenges across binary\nexploitation, web, reverse engineering, forensics, and cryptography. Our\nfindings identify optimal multi-agent coordination settings and lay the\ngroundwork for future LLM agent research in cybersecurity. We make CTFTiny open\nsource to public https://github.com/NYU-LLM-CTF/CTFTiny along with CTFJudge on\nhttps://github.com/NYU-LLM-CTF/CTFJudge.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u9a71\u52a8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5b89\u5168\u653b\u51fb\u4ee3\u7406\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\uff0c\u63d0\u51faCTFJudge\u3001CTF Competency Index\uff08CCI\uff09\uff0c\u7814\u7a76\u8d85\u53c2\u6570\u5f71\u54cd\uff0c\u63a8\u51faCTFTiny\u57fa\u51c6\u6d4b\u8bd5\uff0c\u786e\u5b9a\u6700\u4f18\u591a\u667a\u80fd\u4f53\u534f\u8c03\u8bbe\u7f6e\u5e76\u5f00\u6e90\u3002", "motivation": "\u63a2\u7a76\u9a71\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u653b\u51fb\u4ee3\u7406\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\uff0c\u6784\u5efa\u6709\u6548\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u653b\u6027\u5b89\u5168\u4ee3\u7406\u3002", "method": "\u63d0\u51faCTFJudge\u6846\u67b6\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff1b\u63d0\u51faCTF Competency Index\uff08CCI\uff09\u6307\u6807\uff1b\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u8d85\u53c2\u6570\u5bf9\u4ee3\u7406\u6027\u80fd\u548c\u81ea\u52a8\u5316\u7f51\u7edc\u5b89\u5168\u4efb\u52a1\u89c4\u5212\u7684\u5f71\u54cd\uff1b\u63a8\u51faCTFTiny\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u786e\u5b9a\u4e86\u6700\u4f18\u591a\u667a\u80fd\u4f53\u534f\u8c03\u8bbe\u7f6e\u3002", "conclusion": "\u4e3a\u672a\u6765\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7814\u7a76\u5960\u5b9a\u57fa\u7840\uff0c\u5f00\u6e90CTFTiny\u548cCTFJudge\u3002"}}
{"id": "2107.06056", "pdf": "https://arxiv.org/pdf/2107.06056", "abs": "https://arxiv.org/abs/2107.06056", "authors": ["Prathamesh Kalamkar", "Janani Venugopalan Ph. D.", "Vivek Raghavan Ph. D"], "title": "Indian Legal NLP Benchmarks : A Survey", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Availability of challenging benchmarks is the key to advancement of AI in a\nspecific field.Since Legal Text is significantly different than normal English\ntext, there is a need to create separate Natural Language Processing benchmarks\nfor Indian Legal Text which are challenging and focus on tasks specific to\nLegal Systems. This will spur innovation in applications of Natural language\nProcessing for Indian Legal Text and will benefit AI community and Legal\nfraternity. We review the existing work in this area and propose ideas to\ncreate new benchmarks for Indian Legal Natural Language Processing.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u9700\u4e3a\u5370\u5ea6\u6cd5\u5f8b\u6587\u672c\u521b\u5efa\u4e13\u95e8\u7684NLP\u57fa\u51c6\uff0c\u56de\u987e\u76f8\u5173\u5de5\u4f5c\u5e76\u63d0\u51fa\u521b\u5efa\u65b0\u57fa\u51c6\u7684\u60f3\u6cd5\u3002", "motivation": "\u6cd5\u5f8b\u6587\u672c\u4e0e\u666e\u901a\u82f1\u6587\u6587\u672c\u5dee\u5f02\u5927\uff0c\u9700\u4e3a\u5370\u5ea6\u6cd5\u5f8b\u6587\u672c\u521b\u5efa\u6709\u6311\u6218\u6027\u4e14\u9488\u5bf9\u6cd5\u5f8b\u7cfb\u7edf\u7279\u5b9a\u4efb\u52a1\u7684NLP\u57fa\u51c6\uff0c\u4ee5\u63a8\u52a8\u76f8\u5173\u521b\u65b0\u3002", "method": "\u56de\u987e\u8be5\u9886\u57df\u73b0\u6709\u5de5\u4f5c\u5e76\u63d0\u51fa\u521b\u5efa\u65b0\u57fa\u51c6\u7684\u60f3\u6cd5\u3002", "result": "\u65e0\u660e\u786e\u63d0\u53ca\u5177\u4f53\u7ed3\u679c\u3002", "conclusion": "\u4e3a\u5370\u5ea6\u6cd5\u5f8b\u81ea\u7136\u8bed\u8a00\u5904\u7406\u521b\u5efa\u65b0\u57fa\u51c6\u5f88\u6709\u5fc5\u8981\u3002"}}
{"id": "2508.05675", "pdf": "https://arxiv.org/pdf/2508.05675", "abs": "https://arxiv.org/abs/2508.05675", "authors": ["Jing Wang", "Zheng Li", "Lei Li", "Fan He", "Liyu Lin", "Yao Lai", "Yan Li", "Xiaoyang Zeng", "Yufeng Guo"], "title": "Principle-Guided Verilog Optimization: IP-Safe Knowledge Transfer via Local-Cloud Collaboration", "categories": ["cs.CR", "cs.AI"], "comment": "Our code and dataset are available at\n  https://github.com/friyawang/VeriOptim", "summary": "Recent years have witnessed growing interest in adopting large language\nmodels (LLMs) for Register Transfer Level (RTL) code optimization. While\npowerful cloud-based LLMs offer superior optimization capabilities, they pose\nunacceptable intellectual property (IP) leakage risks when processing\nproprietary hardware designs. In this paper, we propose a new scenario where\nVerilog code must be optimized for specific attributes without leaking\nsensitive IP information. We introduce the first IP-preserving edge-cloud\ncollaborative framework that leverages the benefits of both paradigms. Our\napproach employs local small LLMs (e.g., Qwen-2.5-Coder-7B) to perform secure\ncomparative analysis between paired high-quality target designs and novice\ndraft codes, yielding general design principles that summarize key insights for\nimprovements. These principles are then used to query stronger cloud LLMs\n(e.g., Deepseek-V3) for targeted code improvement, ensuring that only\nabstracted and IP-safe guidance reaches external services. Our experimental\nresults demonstrate that the framework achieves significantly higher\noptimization success rates compared to baseline methods. For example, combining\nQwen-2.5-Coder-7B and Deepseek-V3 achieves a 66.67\\% optimization success rate\nfor power utilization, outperforming Deepseek-V3 alone (49.81\\%) and even\ncommercial models like GPT-4o (55.81\\%). Further investigation of local and\ncloud LLM combinations reveals that different model pairings exhibit varying\nstrengths for specific optimization objectives, with interesting trends\nemerging when varying the number of comparative code pairs. Our work\nestablishes a new paradigm for secure hardware design optimization that\nbalances performance gains with IP protection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8eVerilog\u4ee3\u7801\u4f18\u5316\u7684\u4fddIP\u7684\u8fb9\u4e91\u534f\u540c\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u4f18\u5316\u6210\u529f\u7387\u9ad8\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u5b89\u5168\u786c\u4ef6\u8bbe\u8ba1\u4f18\u5316\u5efa\u7acb\u65b0\u8303\u5f0f\u3002", "motivation": "\u5f3a\u5927\u7684\u4e91\u57fa\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u4e13\u6709\u786c\u4ef6\u8bbe\u8ba1\u65f6\u5b58\u5728\u4e0d\u53ef\u63a5\u53d7\u7684IP\u6cc4\u6f0f\u98ce\u9669\uff0c\u9700\u5728\u4e0d\u6cc4\u9732\u654f\u611fIP\u4fe1\u606f\u524d\u63d0\u4e0b\u4f18\u5316Verilog\u4ee3\u7801\u3002", "method": "\u5f15\u5165\u4fddIP\u7684\u8fb9\u4e91\u534f\u540c\u6846\u67b6\uff0c\u7528\u672c\u5730\u5c0fLLM\u5bf9\u76ee\u6807\u8bbe\u8ba1\u548c\u8349\u7a3f\u4ee3\u7801\u8fdb\u884c\u5b89\u5168\u6bd4\u8f83\u5206\u6790\u5f97\u51fa\u8bbe\u8ba1\u539f\u5219\uff0c\u518d\u7528\u539f\u5219\u67e5\u8be2\u4e91LLM\u8fdb\u884c\u4ee3\u7801\u6539\u8fdb\u3002", "result": "\u6846\u67b6\u4f18\u5316\u6210\u529f\u7387\u663e\u8457\u9ad8\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5982Qwen - 2.5 - Coder - 7B\u548cDeepseek - V3\u7ec4\u5408\u5728\u7535\u6e90\u5229\u7528\u7387\u4f18\u5316\u6210\u529f\u7387\u8fbe66.67%\uff0c\u4e0d\u540c\u6a21\u578b\u7ec4\u5408\u5bf9\u7279\u5b9a\u4f18\u5316\u76ee\u6807\u6709\u4e0d\u540c\u4f18\u52bf\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5e73\u8861\u6027\u80fd\u63d0\u5347\u548cIP\u4fdd\u62a4\u7684\u5b89\u5168\u786c\u4ef6\u8bbe\u8ba1\u4f18\u5316\u65b0\u8303\u5f0f\u3002"}}
{"id": "2508.01854", "pdf": "https://arxiv.org/pdf/2508.01854", "abs": "https://arxiv.org/abs/2508.01854", "authors": ["Fanze Kong", "Chen-Chih Lai", "Yubin Lu"], "title": "Moment Estimate and Variational Approach for Learning Generalized Diffusion with Non-gradient Structures", "categories": ["physics.comp-ph", "cs.LG", "math.AP", "nlin.AO"], "comment": null, "summary": "This paper proposes a data-driven learning framework for identifying\ngoverning laws of generalized diffusions with non-gradient components. By\ncombining energy dissipation laws with a physically consistent penalty and\nfirst-moment evolution, we design a two-stage method to recover the\npseudo-potential and rotation in the pointwise orthogonal decomposition of a\nclass of non-gradient drifts in generalized diffusions. Our two-stage method is\napplied to complex generalized diffusion processes including\ndissipation-rotation dynamics, rough pseudo-potentials and noisy data.\nRepresentative numerical experiments demonstrate the effectiveness of our\napproach for learning physical laws in non-gradient generalized diffusions.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u6846\u67b6\u8bc6\u522b\u542b\u975e\u68af\u5ea6\u5206\u91cf\u5e7f\u4e49\u6269\u6563\u63a7\u5236\u5f8b\uff0c\u4e24\u9636\u6bb5\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u8bc6\u522b\u542b\u975e\u68af\u5ea6\u5206\u91cf\u5e7f\u4e49\u6269\u6563\u7684\u63a7\u5236\u5f8b\u3002", "method": "\u7ed3\u5408\u80fd\u91cf\u8017\u6563\u5b9a\u5f8b\u3001\u7269\u7406\u4e00\u81f4\u60e9\u7f5a\u548c\u4e00\u9636\u77e9\u6f14\u5316\uff0c\u8bbe\u8ba1\u4e24\u9636\u6bb5\u65b9\u6cd5\u6062\u590d\u975e\u68af\u5ea6\u6f02\u79fb\u70b9\u6001\u6b63\u4ea4\u5206\u89e3\u4e2d\u7684\u4f2a\u52bf\u548c\u65cb\u8f6c\u3002", "result": "\u5c06\u4e24\u9636\u6bb5\u65b9\u6cd5\u5e94\u7528\u4e8e\u590d\u6742\u5e7f\u4e49\u6269\u6563\u8fc7\u7a0b\uff0c\u4ee3\u8868\u6027\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u53ef\u6709\u6548\u5b66\u4e60\u975e\u68af\u5ea6\u5e7f\u4e49\u6269\u6563\u4e2d\u7684\u7269\u7406\u5b9a\u5f8b\u3002"}}
{"id": "2508.05677", "pdf": "https://arxiv.org/pdf/2508.05677", "abs": "https://arxiv.org/abs/2508.05677", "authors": ["Peizhuo Liu"], "title": "Adversarial Attacks on Reinforcement Learning-based Medical Questionnaire Systems: Input-level Perturbation Strategies and Medical Constraint Validation", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "30 pages (21 pages main text, 3 pages references, 6 pages appendix),\n  4 figures", "summary": "RL-based medical questionnaire systems have shown great potential in medical\nscenarios. However, their safety and robustness remain unresolved. This study\nperforms a comprehensive evaluation on adversarial attack methods to identify\nand analyze their potential vulnerabilities. We formulate the diagnosis process\nas a Markov Decision Process (MDP), where the state is the patient responses\nand unasked questions, and the action is either to ask a question or to make a\ndiagnosis. We implemented six prevailing major attack methods, including the\nFast Gradient Signed Method (FGSM), Projected Gradient Descent (PGD), Carlini &\nWagner Attack (C&W) attack, Basic Iterative Method (BIM), DeepFool, and\nAutoAttack, with seven epsilon values each. To ensure the generated adversarial\nexamples remain clinically plausible, we developed a comprehensive medical\nvalidation framework consisting of 247 medical constraints, including\nphysiological bounds, symptom correlations, and conditional medical\nconstraints. We achieved a 97.6% success rate in generating clinically\nplausible adversarial samples. We performed our experiment on the National\nHealth Interview Survey (NHIS) dataset (https://www.cdc.gov/nchs/nhis/), which\nconsists of 182,630 samples, to predict the participant's 4-year mortality\nrate. We evaluated our attacks on the AdaptiveFS framework proposed in\narXiv:2004.00994. Our results show that adversarial attacks could significantly\nimpact the diagnostic accuracy, with attack success rates ranging from 33.08%\n(FGSM) to 64.70% (AutoAttack). Our work has demonstrated that even under strict\nmedical constraints on the input, such RL-based medical questionnaire systems\nstill show significant vulnerabilities.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u533b\u7597\u95ee\u5377\u7cfb\u7edf\u8fdb\u884c\u5bf9\u6297\u653b\u51fb\u8bc4\u4f30\uff0c\u53d1\u73b0\u7cfb\u7edf\u5728\u4e25\u683c\u533b\u7597\u7ea6\u675f\u4e0b\u4ecd\u6709\u663e\u8457\u6f0f\u6d1e\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u533b\u7597\u95ee\u5377\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u8bc6\u522b\u5e76\u5206\u6790\u5176\u6f5c\u5728\u6f0f\u6d1e\u3002", "method": "\u5c06\u8bca\u65ad\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5b9e\u65bd\u516d\u79cd\u4e3b\u6d41\u653b\u51fb\u65b9\u6cd5\uff0c\u8bbe\u7f6e\u4e03\u4e2aepsilon\u503c\uff0c\u5f00\u53d1\u542b247\u4e2a\u533b\u7597\u7ea6\u675f\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u5728NHIS\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5bf9AdaptiveFS\u6846\u67b6\u8bc4\u4f30\u653b\u51fb\u3002", "result": "\u751f\u6210\u4e34\u5e8a\u5408\u7406\u5bf9\u6297\u6837\u672c\u6210\u529f\u7387\u8fbe97.6%\uff0c\u653b\u51fb\u6210\u529f\u7387\u572833.08%\uff08FGSM\uff09\u523064.70%\uff08AutoAttack\uff09\u4e4b\u95f4\uff0c\u5bf9\u6297\u653b\u51fb\u663e\u8457\u5f71\u54cd\u8bca\u65ad\u51c6\u786e\u6027\u3002", "conclusion": "\u5373\u4f7f\u8f93\u5165\u6709\u4e25\u683c\u533b\u7597\u7ea6\u675f\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u533b\u7597\u95ee\u5377\u7cfb\u7edf\u4ecd\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\u3002"}}
{"id": "2508.05681", "pdf": "https://arxiv.org/pdf/2508.05681", "abs": "https://arxiv.org/abs/2508.05681", "authors": ["Yuhan Zhi", "Longtian Wang", "Xiaofei Xie", "Chao Shen", "Qiang Hu", "Xiaohong Guan"], "title": "Selection-Based Vulnerabilities: Clean-Label Backdoor Attacks in Active Learning", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Active learning(AL), which serves as the representative label-efficient\nlearning paradigm, has been widely applied in resource-constrained scenarios.\nThe achievement of AL is attributed to acquisition functions, which are\ndesigned for identifying the most important data to label. Despite this\nsuccess, one question remains unanswered: is AL safe? In this work, we\nintroduce ALA, a practical and the first framework to utilize the acquisition\nfunction as the poisoning attack surface to reveal the weakness of active\nlearning. Specifically, ALA optimizes imperceptibly poisoned inputs to exhibit\nhigh uncertainty scores, increasing their probability of being selected by\nacquisition functions. To evaluate ALA, we conduct extensive experiments across\nthree datasets, three acquisition functions, and two types of clean-label\nbackdoor triggers. Results show that our attack can achieve high success rates\n(up to 94%) even under low poisoning budgets (0.5%-1.0%) while preserving model\nutility and remaining undetectable to human annotators. Our findings remind\nactive learning users: acquisition functions can be easily exploited, and\nactive learning should be deployed with caution in trusted data scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa ALA \u6846\u67b6\u5bf9\u4e3b\u52a8\u5b66\u4e60\u8fdb\u884c\u653b\u51fb\uff0c\u5b9e\u9a8c\u8868\u660e\u653b\u51fb\u6210\u529f\u7387\u9ad8\uff0c\u63d0\u9192\u4f7f\u7528\u4e3b\u52a8\u5b66\u4e60\u9700\u8c28\u614e\u3002", "motivation": "\u63a2\u8ba8\u4e3b\u52a8\u5b66\u4e60\u662f\u5426\u5b89\u5168\uff0c\u73b0\u6709\u7814\u7a76\u672a\u89e3\u7b54\u8be5\u95ee\u9898\u3002", "method": "\u5f15\u5165 ALA \u6846\u67b6\uff0c\u4f18\u5316\u4e0d\u6613\u5bdf\u89c9\u7684\u4e2d\u6bd2\u8f93\u5165\u4ee5\u5c55\u793a\u9ad8\u4e0d\u786e\u5b9a\u6027\u5206\u6570\uff0c\u589e\u52a0\u88ab\u91c7\u96c6\u51fd\u6570\u9009\u4e2d\u6982\u7387\u3002", "result": "\u5728\u4f4e\u4e2d\u6bd2\u9884\u7b97\uff080.5%-1.0%\uff09\u4e0b\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe 94%\uff0c\u4fdd\u7559\u6a21\u578b\u5b9e\u7528\u6027\u4e14\u96be\u88ab\u4eba\u5de5\u6807\u6ce8\u8005\u5bdf\u89c9\u3002", "conclusion": "\u91c7\u96c6\u51fd\u6570\u6613\u88ab\u5229\u7528\uff0c\u5728\u53ef\u4fe1\u6570\u636e\u573a\u666f\u4e2d\u5e94\u8c28\u614e\u90e8\u7f72\u4e3b\u52a8\u5b66\u4e60\u3002"}}
{"id": "2508.05687", "pdf": "https://arxiv.org/pdf/2508.05687", "abs": "https://arxiv.org/abs/2508.05687", "authors": ["Alistair Reid", "Simon O'Callaghan", "Liam Carroll", "Tiberio Caetano"], "title": "Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Organisations are starting to adopt LLM-based AI agents, with their\ndeployments naturally evolving from single agents towards interconnected,\nmulti-agent networks. Yet a collection of safe agents does not guarantee a safe\ncollection of agents, as interactions between agents over time create emergent\nbehaviours and induce novel failure modes. This means multi-agent systems\nrequire a fundamentally different risk analysis approach than that used for a\nsingle agent.\n  This report addresses the early stages of risk identification and analysis\nfor multi-agent AI systems operating within governed environments where\norganisations control their agent configurations and deployment. In this\nsetting, we examine six critical failure modes: cascading reliability failures,\ninter-agent communication failures, monoculture collapse, conformity bias,\ndeficient theory of mind, and mixed motive dynamics. For each, we provide a\ntoolkit for practitioners to extend or integrate into their existing frameworks\nto assess these failure modes within their organisational contexts.\n  Given fundamental limitations in current LLM behavioural understanding, our\napproach centres on analysis validity, and advocates for progressively\nincreasing validity through staged testing across stages of abstraction and\ndeployment that gradually increases exposure to potential negative impacts,\nwhile collecting convergent evidence through simulation, observational\nanalysis, benchmarking, and red teaming. This methodology establishes the\ngroundwork for robust organisational risk management as these LLM-based\nmulti-agent systems are deployed and operated.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u591a\u667a\u80fd\u4f53 AI \u7cfb\u7edf\u98ce\u9669\u8bc6\u522b\u4e0e\u5206\u6790\uff0c\u6307\u51fa\u4e0e\u5355\u667a\u80fd\u4f53\u4e0d\u540c\uff0c\u9700\u65b0\u65b9\u6cd5\uff0c\u5206\u6790\u516d\u79cd\u5931\u6548\u6a21\u5f0f\u5e76\u63d0\u4f9b\u5de5\u5177\u5305\uff0c\u4ecb\u7ecd\u4ee5\u6709\u6548\u6027\u4e3a\u6838\u5fc3\u7684\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u7ec4\u7ec7\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684 AI \u667a\u80fd\u4f53\uff0c\u4ece\u5355\u667a\u80fd\u4f53\u5411\u591a\u667a\u80fd\u4f53\u7f51\u7edc\u53d1\u5c55\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9700\u8981\u4e0d\u540c\u4e8e\u5355\u667a\u80fd\u4f53\u7684\u98ce\u9669\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u516d\u79cd\u5173\u952e\u5931\u6548\u6a21\u5f0f\uff0c\u63d0\u4f9b\u5de5\u5177\u5305\uff1b\u4ee5\u5206\u6790\u6709\u6548\u6027\u4e3a\u6838\u5fc3\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u6d4b\u8bd5\u9010\u6b65\u63d0\u9ad8\u6709\u6548\u6027\uff0c\u7ed3\u5408\u6a21\u62df\u3001\u89c2\u5bdf\u5206\u6790\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u7ea2\u961f\u6d4b\u8bd5\u6536\u96c6\u8bc1\u636e\u3002", "result": "\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u8bc4\u4f30\u5931\u6548\u6a21\u5f0f\u7684\u5de5\u5177\u5305\uff0c\u5efa\u7acb\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7ec4\u7ec7\u98ce\u9669\u7ba1\u7406\u7684\u57fa\u7840\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u591a\u667a\u80fd\u4f53 AI \u7cfb\u7edf\u5728\u7ec4\u7ec7\u4e2d\u7684\u90e8\u7f72\u548c\u8fd0\u8425\u5efa\u7acb\u4e86\u7a33\u5065\u7684\u98ce\u9669\u7ba1\u7406\u57fa\u7840\u3002"}}
{"id": "2508.05694", "pdf": "https://arxiv.org/pdf/2508.05694", "abs": "https://arxiv.org/abs/2508.05694", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Guanggang Geng", "Zhiying Li", "Jian Weng"], "title": "DMFI: Dual-Modality Fine-Tuning and Inference Framework for LLM-Based Insider Threat Detection", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Submitted to the 2025 IEEE International Conference on Data Mining\n  (ICDM)", "summary": "Insider threat detection (ITD) poses a persistent and high-impact challenge\nin cybersecurity due to the subtle, long-term, and context-dependent nature of\nmalicious insider behaviors. Traditional models often struggle to capture\nsemantic intent and complex behavior dynamics, while existing LLM-based\nsolutions face limitations in prompt adaptability and modality coverage. To\nbridge this gap, we propose DMFI, a dual-modality framework that integrates\nsemantic inference with behavior-aware fine-tuning. DMFI converts raw logs into\ntwo structured views: (1) a semantic view that processes content-rich artifacts\n(e.g., emails, https) using instruction-formatted prompts; and (2) a behavioral\nabstraction, constructed via a 4W-guided (When-Where-What-Which) transformation\nto encode contextual action sequences. Two LoRA-enhanced LLMs are fine-tuned\nindependently, and their outputs are fused via a lightweight MLP-based decision\nmodule. We further introduce DMFI-B, a discriminative adaptation strategy that\nseparates normal and abnormal behavior representations, improving robustness\nunder severe class imbalance. Experiments on CERT r4.2 and r5.2 datasets\ndemonstrate that DMFI outperforms state-of-the-art methods in detection\naccuracy. Our approach combines the semantic reasoning power of LLMs with\nstructured behavior modeling, offering a scalable and effective solution for\nreal-world insider threat detection. Our work demonstrates the effectiveness of\ncombining LLM reasoning with structured behavioral modeling, offering a\nscalable and deployable solution for modern insider threat detection.", "AI": {"tldr": "\u63d0\u51faDMFI\u6846\u67b6\u7ed3\u5408\u8bed\u4e49\u63a8\u7406\u4e0e\u884c\u4e3a\u611f\u77e5\u5fae\u8c03\uff0c\u7528\u4e8e\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u96be\u6355\u6349\u8bed\u4e49\u610f\u56fe\u548c\u590d\u6742\u884c\u4e3a\u52a8\u6001\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\u5728\u63d0\u793a\u9002\u5e94\u6027\u548c\u6a21\u6001\u8986\u76d6\u65b9\u9762\u6709\u5c40\u9650\u3002", "method": "\u63d0\u51faDMFI\u6846\u67b6\uff0c\u5c06\u539f\u59cb\u65e5\u5fd7\u8f6c\u6362\u4e3a\u8bed\u4e49\u89c6\u56fe\u548c\u884c\u4e3a\u62bd\u8c61\uff0c\u7528\u4e24\u4e2aLoRA\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u72ec\u7acb\u5fae\u8c03\uff0c\u8f93\u51fa\u901a\u8fc7\u8f7b\u91cf\u7ea7\u57fa\u4e8eMLP\u7684\u51b3\u7b56\u6a21\u5757\u878d\u5408\uff0c\u8fd8\u5f15\u5165DMFI - B\u7b56\u7565\u5206\u79bb\u6b63\u5e38\u548c\u5f02\u5e38\u884c\u4e3a\u8868\u793a\u3002", "result": "\u5728CERT r4.2\u548cr5.2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDMFI\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u7ed3\u6784\u5316\u884c\u4e3a\u5efa\u6a21\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u4e3a\u73b0\u4ee3\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u53ef\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05696", "pdf": "https://arxiv.org/pdf/2508.05696", "abs": "https://arxiv.org/abs/2508.05696", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Zhiying Li", "Guanggang Geng"], "title": "Log2Sig: Frequency-Aware Insider Threat Detection via Multivariate Behavioral Signal Decomposition", "categories": ["cs.CR", "cs.AI"], "comment": "Submitted to the 2025 IEEE International Conference on Trust,\n  Security and Privacy in Computing and Communications (TrustCom)", "summary": "Insider threat detection presents a significant challenge due to the\ndeceptive nature of malicious behaviors, which often resemble legitimate user\noperations. However, existing approaches typically model system logs as flat\nevent sequences, thereby failing to capture the inherent frequency dynamics and\nmultiscale disturbance patterns embedded in user behavior. To address these\nlimitations, we propose Log2Sig, a robust anomaly detection framework that\ntransforms user logs into multivariate behavioral frequency signals,\nintroducing a novel representation of user behavior. Log2Sig employs\nMultivariate Variational Mode Decomposition (MVMD) to extract Intrinsic Mode\nFunctions (IMFs), which reveal behavioral fluctuations across multiple temporal\nscales. Based on this, the model further performs joint modeling of behavioral\nsequences and frequency-decomposed signals: the daily behavior sequences are\nencoded using a Mamba-based temporal encoder to capture long-term dependencies,\nwhile the corresponding frequency components are linearly projected to match\nthe encoder's output dimension. These dual-view representations are then fused\nto construct a comprehensive user behavior profile, which is fed into a\nmultilayer perceptron for precise anomaly detection. Experimental results on\nthe CERT r4.2 and r5.2 datasets demonstrate that Log2Sig significantly\noutperforms state-of-the-art baselines in both accuracy and F1 score.", "AI": {"tldr": "\u63d0\u51faLog2Sig\u6846\u67b6\u5c06\u7528\u6237\u65e5\u5fd7\u8f6c\u4e3a\u591a\u5143\u884c\u4e3a\u9891\u7387\u4fe1\u53f7\uff0c\u7ed3\u5408\u591a\u79cd\u65b9\u6cd5\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u7cfb\u7edf\u65e5\u5fd7\u5efa\u6a21\u4e3a\u6241\u5e73\u4e8b\u4ef6\u5e8f\u5217\uff0c\u65e0\u6cd5\u6355\u6349\u7528\u6237\u884c\u4e3a\u7684\u9891\u7387\u52a8\u6001\u548c\u591a\u5c3a\u5ea6\u5e72\u6270\u6a21\u5f0f\u3002", "method": "\u63d0\u51faLog2Sig\u6846\u67b6\uff0c\u7528MVMD\u63d0\u53d6IMFs\uff0c\u7ed3\u5408Mamba\u65f6\u95f4\u7f16\u7801\u5668\u5bf9\u884c\u4e3a\u5e8f\u5217\u548c\u9891\u7387\u5206\u89e3\u4fe1\u53f7\u8054\u5408\u5efa\u6a21\uff0c\u878d\u5408\u540e\u6784\u5efa\u7528\u6237\u884c\u4e3a\u8f6e\u5ed3\uff0c\u7528\u591a\u5c42\u611f\u77e5\u673a\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "\u5728CERT r4.2\u548cr5.2\u6570\u636e\u96c6\u4e0a\uff0cLog2Sig\u5728\u51c6\u786e\u7387\u548cF1\u5206\u6570\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "Log2Sig\u662f\u4e00\u4e2a\u6709\u6548\u7684\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u6846\u67b6\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u7528\u6237\u884c\u4e3a\u7279\u5f81\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u3002"}}
{"id": "2508.05684", "pdf": "https://arxiv.org/pdf/2508.05684", "abs": "https://arxiv.org/abs/2508.05684", "authors": ["Junhao He", "Tianyu Liu", "Jingyuan Zhao", "Benjamin Turner"], "title": "MM-FusionNet: Context-Aware Dynamic Fusion for Multi-modal Fake News Detection with Large Vision-Language Models", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "The proliferation of multi-modal fake news on social media poses a\nsignificant threat to public trust and social stability. Traditional detection\nmethods, primarily text-based, often fall short due to the deceptive interplay\nbetween misleading text and images. While Large Vision-Language Models (LVLMs)\noffer promising avenues for multi-modal understanding, effectively fusing\ndiverse modal information, especially when their importance is imbalanced or\ncontradictory, remains a critical challenge. This paper introduces\nMM-FusionNet, an innovative framework leveraging LVLMs for robust multi-modal\nfake news detection. Our core contribution is the Context-Aware Dynamic Fusion\nModule (CADFM), which employs bi-directional cross-modal attention and a novel\ndynamic modal gating network. This mechanism adaptively learns and assigns\nimportance weights to textual and visual features based on their contextual\nrelevance, enabling intelligent prioritization of information. Evaluated on the\nlarge-scale Multi-modal Fake News Dataset (LMFND) comprising 80,000 samples,\nMM-FusionNet achieves a state-of-the-art F1-score of 0.938, surpassing existing\nmulti-modal baselines by approximately 0.5% and significantly outperforming\nsingle-modal approaches. Further analysis demonstrates the model's dynamic\nweighting capabilities, its robustness to modality perturbations, and\nperformance remarkably close to human-level, underscoring its practical\nefficacy and interpretability for real-world fake news detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMM - FusionNet\u6846\u67b6\u7528\u4e8e\u591a\u6a21\u6001\u5047\u65b0\u95fb\u68c0\u6d4b\uff0c\u6838\u5fc3\u662fCADFM\u6a21\u5757\uff0c\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u5148\u8fdbF1\u5206\u6570\uff0c\u6027\u80fd\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u591a\u6a21\u6001\u5047\u65b0\u95fb\u5a01\u80c1\u516c\u4f17\u4fe1\u4efb\u548c\u793e\u4f1a\u7a33\u5b9a\uff0c\u4f20\u7edf\u57fa\u4e8e\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u8db3\uff0cLVLMs\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\u6709\u6311\u6218\u3002", "method": "\u5f15\u5165MM - FusionNet\u6846\u67b6\uff0c\u4f7f\u7528\u6838\u5fc3CADFM\u6a21\u5757\uff0c\u901a\u8fc7\u53cc\u5411\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u548c\u52a8\u6001\u6a21\u6001\u95e8\u63a7\u7f51\u7edc\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u5206\u914d\u6587\u672c\u4e0e\u89c6\u89c9\u7279\u5f81\u6743\u91cd\u3002", "result": "\u5728\u542b80000\u4e2a\u6837\u672c\u7684\u6570\u636e\u96c6\u4e0a\uff0cMM - FusionNet\u83b7\u5f970.938\u7684F1\u5206\u6570\uff0c\u8d85\u73b0\u6709\u591a\u6a21\u6001\u57fa\u7ebf\u7ea60.5%\uff0c\u8fdc\u8d85\u5355\u6a21\u6001\u65b9\u6cd5\u3002", "conclusion": "\u6a21\u578b\u5177\u6709\u52a8\u6001\u52a0\u6743\u80fd\u529b\u3001\u5bf9\u6a21\u6001\u6270\u52a8\u6709\u9c81\u68d2\u6027\uff0c\u6027\u80fd\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u5728\u73b0\u5b9e\u5047\u65b0\u95fb\u68c0\u6d4b\u4e2d\u6709\u5b9e\u7528\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2508.05702", "pdf": "https://arxiv.org/pdf/2508.05702", "abs": "https://arxiv.org/abs/2508.05702", "authors": ["Yan Zhang"], "title": "Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control", "categories": ["cs.MA", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "The increasing penetration of Distributed Energy Resources (DERs), widespread\nadoption of Electric Vehicles (EVs), and the growing frequency of extreme\nweather events have significantly increased the complexity of power grid\nplanning, operation, and management. Traditional rule-based systems and\nnumerical optimization approaches often struggle with the scale, dynamics, and\nadaptability required by modern power networks. This paper introduces\nGrid-Agent, an autonomous, AI-driven framework that combines Large Language\nModels (LLMs) with multi-agent reinforcement learning to detect and remediate\ngrid violations in real time. Grid-Agent integrates semantic reasoning with\nnumerical precision through a modular agent architecture: a planning agent\ngenerates coordinated action sequences using numerical power flow solvers,\nwhile a validation agent evaluates system stability and action effectiveness\nvia sandboxed execution with safety rollbacks. To ensure scalability,\nGrid-Agent incorporates an adaptive multiscale network representation that\ndynamically selects optimal encoding schemes based on network size and\ncomplexity. The framework enables coordinated violation resolution through\noptimizing switch configurations, battery deployment, and load curtailment\nstrategies. Experimental results in standard IEEE and CIGRE test systems (IEEE\n69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation\nperformance. Additionally, the framework's built-in data collection and\nlearning capabilities enable continuous learning and adaptation to diverse\nnetwork topologies. The autonomous nature of the framework makes it\nparticularly suitable for modern smart grid applications requiring rapid\nresponse to dynamic operating conditions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Grid - Agent\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5b9e\u65f6\u68c0\u6d4b\u548c\u4fee\u590d\u7535\u7f51\u8fdd\u89c4\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u826f\u597d\u7684\u8fdd\u89c4\u7f13\u89e3\u6027\u80fd\u4e14\u9002\u5408\u73b0\u4ee3\u667a\u80fd\u7535\u7f51\u5e94\u7528\u3002", "motivation": "\u5206\u5e03\u5f0f\u80fd\u6e90\u8d44\u6e90\u6e17\u900f\u3001\u7535\u52a8\u6c7d\u8f66\u666e\u53ca\u548c\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u589e\u52a0\u4e86\u7535\u7f51\u89c4\u5212\u3001\u8fd0\u884c\u548c\u7ba1\u7406\u7684\u590d\u6742\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u73b0\u4ee3\u7535\u7f51\u9700\u6c42\u3002", "method": "\u5f15\u5165Grid - Agent\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u91c7\u7528\u6a21\u5757\u5316\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u6574\u5408\u8bed\u4e49\u63a8\u7406\u548c\u6570\u503c\u7cbe\u5ea6\uff0c\u8fd8\u5305\u542b\u81ea\u9002\u5e94\u591a\u5c3a\u5ea6\u7f51\u7edc\u8868\u793a\u3002", "result": "\u5728\u6807\u51c6IEEE\u548cCIGRE\u6d4b\u8bd5\u7cfb\u7edf\u4e2d\u5b9e\u9a8c\uff0c\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u8fdd\u89c4\u7f13\u89e3\u6027\u80fd\uff0c\u5177\u5907\u6570\u636e\u6536\u96c6\u548c\u5b66\u4e60\u80fd\u529b\u4ee5\u9002\u5e94\u4e0d\u540c\u7f51\u7edc\u62d3\u6251\u3002", "conclusion": "\u8be5\u6846\u67b6\u7684\u81ea\u4e3b\u6027\u4f7f\u5176\u7279\u522b\u9002\u5408\u9700\u8981\u5bf9\u52a8\u6001\u8fd0\u884c\u6761\u4ef6\u5feb\u901f\u54cd\u5e94\u7684\u73b0\u4ee3\u667a\u80fd\u7535\u7f51\u5e94\u7528\u3002"}}
{"id": "2508.05689", "pdf": "https://arxiv.org/pdf/2508.05689", "abs": "https://arxiv.org/abs/2508.05689", "authors": ["Jinjia Peng", "Zeze Tao", "Huibing Wang", "Meng Wang", "Yang Wang"], "title": "Boosting Adversarial Transferability via Residual Perturbation Attack", "categories": ["cs.CV", "cs.CR", "cs.LG"], "comment": "Accepted to ieee/cvf international conference on computer vision\n  (ICCV2025)", "summary": "Deep neural networks are susceptible to adversarial examples while suffering\nfrom incorrect predictions via imperceptible perturbations. Transfer-based\nattacks create adversarial examples for surrogate models and transfer these\nexamples to target models under black-box scenarios. Recent studies reveal that\nadversarial examples in flat loss landscapes exhibit superior transferability\nto alleviate overfitting on surrogate models. However, the prior arts overlook\nthe influence of perturbation directions, resulting in limited transferability.\nIn this paper, we propose a novel attack method, named Residual Perturbation\nAttack (ResPA), relying on the residual gradient as the perturbation direction\nto guide the adversarial examples toward the flat regions of the loss function.\nSpecifically, ResPA conducts an exponential moving average on the input\ngradients to obtain the first moment as the reference gradient, which\nencompasses the direction of historical gradients. Instead of heavily relying\non the local flatness that stems from the current gradients as the perturbation\ndirection, ResPA further considers the residual between the current gradient\nand the reference gradient to capture the changes in the global perturbation\ndirection. The experimental results demonstrate the better transferability of\nResPA than the existing typical transfer-based attack methods, while the\ntransferability can be further improved by combining ResPA with the current\ninput transformation methods. The code is available at\nhttps://github.com/ZezeTao/ResPA.", "AI": {"tldr": "\u63d0\u51fa\u6b8b\u5dee\u6270\u52a8\u653b\u51fb\uff08ResPA\uff09\u65b9\u6cd5\uff0c\u4ee5\u6b8b\u5dee\u68af\u5ea6\u4e3a\u6270\u52a8\u65b9\u5411\u5f15\u5bfc\u5bf9\u6297\u6837\u672c\u5230\u635f\u5931\u51fd\u6570\u5e73\u5766\u533a\u57df\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u66f4\u597d\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8f6c\u79fb\u7684\u653b\u51fb\u65b9\u6cd5\u5ffd\u7565\u6270\u52a8\u65b9\u5411\u5f71\u54cd\uff0c\u5bfc\u81f4\u53ef\u8fc1\u79fb\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faResPA\u65b9\u6cd5\uff0c\u5bf9\u8f93\u5165\u68af\u5ea6\u8fdb\u884c\u6307\u6570\u79fb\u52a8\u5e73\u5747\u5f97\u5230\u53c2\u8003\u68af\u5ea6\uff0c\u8003\u8651\u5f53\u524d\u68af\u5ea6\u4e0e\u53c2\u8003\u68af\u5ea6\u7684\u6b8b\u5dee\u6765\u6355\u83b7\u5168\u5c40\u6270\u52a8\u65b9\u5411\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793aResPA\u6bd4\u73b0\u6709\u5178\u578b\u57fa\u4e8e\u8f6c\u79fb\u7684\u653b\u51fb\u65b9\u6cd5\u6709\u66f4\u597d\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u4e0e\u5f53\u524d\u8f93\u5165\u8f6c\u6362\u65b9\u6cd5\u7ed3\u5408\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "ResPA\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u6297\u6837\u672c\u7684\u53ef\u8fc1\u79fb\u6027\u3002"}}
{"id": "2508.05705", "pdf": "https://arxiv.org/pdf/2508.05705", "abs": "https://arxiv.org/abs/2508.05705", "authors": ["Valentina Roquemen-Echeverri", "Taisa Kushner", "Peter G. Jacobs", "Clara Mosquera-Lopez"], "title": "A Physiologically-Constrained Neural Network Digital Twin Framework for Replicating Glucose Dynamics in Type 1 Diabetes", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Simulating glucose dynamics in individuals with type 1 diabetes (T1D) is\ncritical for developing personalized treatments and supporting data-driven\nclinical decisions. Existing models often miss key physiological aspects and\nare difficult to individualize. Here, we introduce physiologically-constrained\nneural network (NN) digital twins to simulate glucose dynamics in T1D. To\nensure interpretability and physiological consistency, we first build a\npopulation-level NN state-space model aligned with a set of ordinary\ndifferential equations (ODEs) describing glucose regulation. This model is\nformally verified to conform to known T1D dynamics. Digital twins are then\ncreated by augmenting the population model with individual-specific models,\nwhich include personal data, such as glucose management and contextual\ninformation, capturing both inter- and intra-individual variability. We\nvalidate our approach using real-world data from the T1D Exercise Initiative\nstudy. Two weeks of data per participant were split into 5-hour sequences and\nsimulated glucose profiles were compared to observed ones. Clinically relevant\noutcomes were used to assess similarity via paired equivalence t-tests with\npredefined clinical equivalence margins. Across 394 digital twins, glucose\noutcomes were equivalent between simulated and observed data: time in range\n(70-180 mg/dL) was 75.1$\\pm$21.2% (simulated) vs. 74.4$\\pm$15.4% (real;\nP<0.001); time below range (<70 mg/dL) 2.5$\\pm$5.2% vs. 3.0$\\pm$3.3% (P=0.022);\nand time above range (>180 mg/dL) 22.4$\\pm$22.0% vs. 22.6$\\pm$15.9% (P<0.001).\nOur framework can incorporate unmodeled factors like sleep and activity while\npreserving key dynamics. This approach enables personalized in silico testing\nof treatments, supports insulin optimization, and integrates physics-based and\ndata-driven modeling. Code: https://github.com/mosqueralopez/T1DSim_AI", "AI": {"tldr": "\u63d0\u51fa\u751f\u7406\u7ea6\u675f\u795e\u7ecf\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u6a21\u62df1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u8840\u7cd6\u52a8\u6001\uff0c\u7ecf\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u4e2a\u6027\u5316\u6cbb\u7597\u6d4b\u8bd5\u548c\u80f0\u5c9b\u7d20\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u6a21\u62df1\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u8840\u7cd6\u52a8\u6001\u7684\u6a21\u578b\u5e38\u7f3a\u5931\u5173\u952e\u751f\u7406\u65b9\u9762\u4e14\u96be\u4ee5\u4e2a\u6027\u5316\uff0c\u9700\u8981\u66f4\u597d\u7684\u6a21\u578b\u6765\u652f\u6301\u4e2a\u6027\u5316\u6cbb\u7597\u548c\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u6784\u5efa\u4e0e\u63cf\u8ff0\u8840\u7cd6\u8c03\u8282\u7684\u5e38\u5fae\u5206\u65b9\u7a0b\u5bf9\u9f50\u7684\u7fa4\u4f53\u7ea7\u795e\u7ecf\u7f51\u7edc\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u518d\u7528\u5305\u542b\u4e2a\u4eba\u6570\u636e\u7684\u4e2a\u4f53\u7279\u5b9a\u6a21\u578b\u589e\u5f3a\u8be5\u7fa4\u4f53\u6a21\u578b\u521b\u5efa\u6570\u5b57\u5b6a\u751f\uff0c\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u3002", "result": "\u5728394\u4e2a\u6570\u5b57\u5b6a\u751f\u4e2d\uff0c\u6a21\u62df\u548c\u89c2\u5bdf\u6570\u636e\u7684\u8840\u7cd6\u7ed3\u679c\u76f8\u5f53\uff0c\u5982\u5728\u76ee\u6807\u8303\u56f4\u5185\u65f6\u95f4\u7b49\u6307\u6807\u76f8\u8fd1\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u7eb3\u5165\u672a\u5efa\u6a21\u56e0\u7d20\uff0c\u53ef\u5b9e\u73b0\u4e2a\u6027\u5316\u6cbb\u7597\u7684\u8ba1\u7b97\u673a\u6a21\u62df\u6d4b\u8bd5\u3001\u652f\u6301\u80f0\u5c9b\u7d20\u4f18\u5316\uff0c\u6574\u5408\u4e86\u57fa\u4e8e\u7269\u7406\u548c\u6570\u636e\u9a71\u52a8\u7684\u5efa\u6a21\u3002"}}
{"id": "2508.05695", "pdf": "https://arxiv.org/pdf/2508.05695", "abs": "https://arxiv.org/abs/2508.05695", "authors": ["Kaichuan Kong", "Dongjie Liu", "Xiaobo Jin", "Zhiying Li", "Guanggang Geng", "Jian Weng"], "title": "MambaITD: An Efficient Cross-Modal Mamba Network for Insider Threat Detection", "categories": ["cs.CR", "cs.LG"], "comment": "Submitted to the 2025 IEEE International Conference on Data Mining\n  (ICDM)", "summary": "Enterprises are facing increasing risks of insider threats, while existing\ndetection methods are unable to effectively address these challenges due to\nreasons such as insufficient temporal dynamic feature modeling, computational\nefficiency and real-time bottlenecks and cross-modal information island\nproblem. This paper proposes a new insider threat detection framework MambaITD\nbased on the Mamba state space model and cross-modal adaptive fusion. First,\nthe multi-source log preprocessing module aligns heterogeneous data through\nbehavioral sequence encoding, interval smoothing, and statistical feature\nextraction. Second, the Mamba encoder models long-range dependencies in\nbehavioral and interval sequences, and combines the sequence and statistical\ninformation dynamically in combination with the gated feature fusion mechanism.\nFinally, we propose an adaptive threshold optimization method based on\nmaximizing inter-class variance, which dynamically adjusts the decision\nthreshold by analyzing the probability distribution, effectively identifies\nanomalies, and alleviates class imbalance and concept drift. Compared with\ntraditional methods, MambaITD shows significant advantages in modeling\nefficiency and feature fusion capabilities, outperforming Transformer-based\nmethods, and provides a more effective solution for insider threat detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eMamba\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u8de8\u6a21\u6001\u81ea\u9002\u5e94\u878d\u5408\u7684\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u6846\u67b6MambaITD\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u4f01\u4e1a\u9762\u4e34\u5185\u90e8\u5a01\u80c1\u98ce\u9669\u589e\u52a0\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u65f6\u95f4\u52a8\u6001\u7279\u5f81\u5efa\u6a21\u4e0d\u8db3\u3001\u8ba1\u7b97\u6548\u7387\u548c\u5b9e\u65f6\u6027\u74f6\u9888\u4ee5\u53ca\u8de8\u6a21\u6001\u4fe1\u606f\u5b64\u5c9b\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faMambaITD\u6846\u67b6\uff0c\u5305\u62ec\u591a\u6e90\u65e5\u5fd7\u9884\u5904\u7406\u6a21\u5757\u5bf9\u5f02\u6784\u6570\u636e\u8fdb\u884c\u5904\u7406\uff1bMamba\u7f16\u7801\u5668\u5efa\u6a21\u957f\u8ddd\u79bb\u4f9d\u8d56\u5e76\u7ed3\u5408\u95e8\u63a7\u7279\u5f81\u878d\u5408\u673a\u5236\u52a8\u6001\u878d\u5408\u4fe1\u606f\uff1b\u63d0\u51fa\u57fa\u4e8e\u6700\u5927\u5316\u7c7b\u95f4\u65b9\u5dee\u7684\u81ea\u9002\u5e94\u9608\u503c\u4f18\u5316\u65b9\u6cd5\u3002", "result": "MambaITD\u5728\u5efa\u6a21\u6548\u7387\u548c\u7279\u5f81\u878d\u5408\u80fd\u529b\u4e0a\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f18\u4e8e\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u3002", "conclusion": "MambaITD\u4e3a\u5185\u90e8\u5a01\u80c1\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.05728", "pdf": "https://arxiv.org/pdf/2508.05728", "abs": "https://arxiv.org/abs/2508.05728", "authors": ["Santiago Casas", "Christian Fidler", "Boris Bolliet", "Francisco Villaescusa-Navarro", "Julien Lesgourgues"], "title": "CLAPP: The CLASS LLM Agent for Pair Programming", "categories": ["astro-ph.IM", "astro-ph.CO", "cs.AI", "cs.MA"], "comment": "Code: https://github.com/santiagocasas/clapp, Streamlit app:\n  https://classclapp.streamlit.app", "summary": "We introduce CLAPP (CLASS LLM Agent for Pair Programming), an interactive AI\nassistant designed to support researchers working with the Einstein-Boltzmann\nsolver CLASS. CLAPP leverages large language models (LLMs) and domain-specific\nretrieval to provide conversational coding support for CLASS-answering\nquestions, generating code, debugging errors, and producing plots. Its\narchitecture combines multi-agent LLM orchestration, semantic search across\nCLASS documentation, and a live Python execution environment. Deployed as a\nuser-friendly web application, CLAPP lowers the entry barrier for scientists\nunfamiliar with AI tools and enables more productive human-AI collaboration in\ncomputational and numerical cosmology. The app is available at\nhttps://classclapp.streamlit.app", "AI": {"tldr": "\u4ecb\u7ecdCLAPP\uff0c\u4e00\u6b3e\u652f\u6301\u4f7f\u7528CLASS\u7684\u4ea4\u4e92\u5f0fAI\u52a9\u624b\uff0c\u964d\u4f4e\u79d1\u5b66\u5bb6\u4f7f\u7528\u95e8\u69db\uff0c\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\uff0c\u5e94\u7528\u53ef\u8bbf\u95eehttps://classclapp.streamlit.app", "motivation": "\u4e3a\u4f7f\u7528Einstein - Boltzmann\u6c42\u89e3\u5668CLASS\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4ea4\u4e92\u5f0fAI\u8f85\u52a9\uff0c\u964d\u4f4e\u4e0d\u719f\u6089AI\u5de5\u5177\u7684\u79d1\u5b66\u5bb6\u7684\u5165\u95e8\u95e8\u69db\uff0c\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7279\u5b9a\u9886\u57df\u68c0\u7d22\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u6392\u3001CLASS\u6587\u6863\u8bed\u4e49\u641c\u7d22\u548c\u5b9e\u65f6Python\u6267\u884c\u73af\u5883", "result": "\u5f00\u53d1\u51faCLAPP\u5e76\u90e8\u7f72\u4e3a\u7528\u6237\u53cb\u597d\u7684Web\u5e94\u7528", "conclusion": "CLAPP\u80fd\u4e3a\u4f7f\u7528CLASS\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u5bf9\u8bdd\u5f0f\u7f16\u7801\u652f\u6301\uff0c\u63a8\u52a8\u8ba1\u7b97\u548c\u6570\u503c\u5b87\u5b99\u5b66\u4e2d\u7684\u4eba\u673a\u9ad8\u6548\u534f\u4f5c"}}
{"id": "2508.05755", "pdf": "https://arxiv.org/pdf/2508.05755", "abs": "https://arxiv.org/abs/2508.05755", "authors": ["Agnieszka Polowczyk", "Alicja Polowczyk", "Dawid Malarz", "Artur Kasymov", "Marcin Mazur", "Jacek Tabor", "Przemys\u0142aw Spurek"], "title": "UnGuide: Learning to Forget with LoRA-Guided Diffusion Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in large-scale text-to-image diffusion models have heightened\nconcerns about their potential misuse, especially in generating harmful or\nmisleading content. This underscores the urgent need for effective machine\nunlearning, i.e., removing specific knowledge or concepts from pretrained\nmodels without compromising overall performance. One possible approach is\nLow-Rank Adaptation (LoRA), which offers an efficient means to fine-tune models\nfor targeted unlearning. However, LoRA often inadvertently alters unrelated\ncontent, leading to diminished image fidelity and realism. To address this\nlimitation, we introduce UnGuide -- a novel approach which incorporates\nUnGuidance, a dynamic inference mechanism that leverages Classifier-Free\nGuidance (CFG) to exert precise control over the unlearning process. UnGuide\nmodulates the guidance scale based on the stability of a few first steps of\ndenoising processes, enabling selective unlearning by LoRA adapter. For prompts\ncontaining the erased concept, the LoRA module predominates and is\ncounterbalanced by the base model; for unrelated prompts, the base model\ngoverns generation, preserving content fidelity. Empirical results demonstrate\nthat UnGuide achieves controlled concept removal and retains the expressive\npower of diffusion models, outperforming existing LoRA-based methods in both\nobject erasure and explicit content removal tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faUnGuide\u65b9\u6cd5\u89e3\u51b3\u5927\u6a21\u578b\u6f5c\u5728\u6ee5\u7528\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u63a8\u7406\u673a\u5236\u5b9e\u73b0\u53ef\u63a7\u6982\u5ff5\u79fb\u9664\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLoRA\u7684\u65b9\u6cd5\u3002", "motivation": "\u5927\u89c4\u6a21\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u6709\u6f5c\u5728\u6ee5\u7528\u98ce\u9669\uff0c\u9700\u6709\u6548\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\uff0c\u800c\u73b0\u6709LoRA\u65b9\u6cd5\u6709\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165UnGuide\uff0c\u7ed3\u5408UnGuidance\u52a8\u6001\u63a8\u7406\u673a\u5236\uff0c\u57fa\u4e8e\u53bb\u566a\u8fc7\u7a0b\u524d\u51e0\u6b65\u7a33\u5b9a\u6027\u8c03\u6574\u5f15\u5bfc\u6bd4\u4f8b\uff0c\u9009\u62e9\u6027\u8fdb\u884cLoRA\u9002\u914d\u3002", "result": "UnGuide\u80fd\u5b9e\u73b0\u53ef\u63a7\u6982\u5ff5\u79fb\u9664\uff0c\u4fdd\u7559\u6269\u6563\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u5728\u7269\u4f53\u64e6\u9664\u548c\u660e\u786e\u5185\u5bb9\u79fb\u9664\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLoRA\u7684\u65b9\u6cd5\u3002", "conclusion": "UnGuide\u662f\u4e00\u79cd\u6709\u6548\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\uff0c\u53ef\u89e3\u51b3\u6269\u6563\u6a21\u578b\u6f5c\u5728\u6ee5\u7528\u95ee\u9898\u3002"}}
{"id": "2508.05783", "pdf": "https://arxiv.org/pdf/2508.05783", "abs": "https://arxiv.org/abs/2508.05783", "authors": ["Mengyu Li", "Guoyao Shen", "Chad W. Farris", "Xin Zhang"], "title": "Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks", "categories": ["cs.CV", "cs.AI"], "comment": "30 pages, 8 figures, 7 tables", "summary": "Machine learning using transformers has shown great potential in medical\nimaging, but its real-world applicability remains limited due to the scarcity\nof annotated data. In this study, we propose a practical framework for the\nfew-shot deployment of pretrained MRI transformers in diverse brain imaging\ntasks. By utilizing the Masked Autoencoder (MAE) pretraining strategy on a\nlarge-scale, multi-cohort brain MRI dataset comprising over 31 million slices,\nwe obtain highly transferable latent representations that generalize well\nacross tasks and datasets. For high-level tasks such as classification, a\nfrozen MAE encoder combined with a lightweight linear head achieves\nstate-of-the-art accuracy in MRI sequence identification with minimal\nsupervision. For low-level tasks such as segmentation, we propose MAE-FUnet, a\nhybrid architecture that fuses multiscale CNN features with pretrained MAE\nembeddings. This model consistently outperforms other strong baselines in both\nskull stripping and multi-class anatomical segmentation under data-limited\nconditions. With extensive quantitative and qualitative evaluations, our\nframework demonstrates efficiency, stability, and scalability, suggesting its\nsuitability for low-resource clinical environments and broader neuroimaging\napplications.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u9884\u8bad\u7ec3MRI Transformer\u5c11\u6837\u672c\u90e8\u7f72\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u5728\u8111\u6210\u50cf\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u4e34\u5e8a\u73af\u5883\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u5728\u533b\u5b66\u5f71\u50cf\u4e2d\u56e0\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4\u73b0\u5b9e\u5e94\u7528\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u5728\u5927\u89c4\u6a21\u591a\u961f\u5217\u8111MRI\u6570\u636e\u96c6\u4e0a\u7528MAE\u9884\u8bad\u7ec3\u7b56\u7565\u83b7\u53d6\u53ef\u8fc1\u79fb\u6f5c\u5728\u8868\u5f81\uff1b\u5206\u7c7b\u4efb\u52a1\u7528\u51bb\u7ed3MAE\u7f16\u7801\u5668\u52a0\u8f7b\u91cf\u7ea7\u7ebf\u6027\u5934\uff1b\u5206\u5272\u4efb\u52a1\u63d0\u51faMAE - FUnet\u6df7\u5408\u67b6\u6784\u3002", "result": "\u5206\u7c7b\u4efb\u52a1\u5728MRI\u5e8f\u5217\u8bc6\u522b\u4e2d\u4ee5\u6700\u5c11\u76d1\u7763\u8fbe\u5230\u6700\u4f18\u51c6\u786e\u7387\uff1b\u5206\u5272\u4efb\u52a1\u5728\u6570\u636e\u6709\u9650\u65f6MAE - FUnet\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u6846\u67b6\u9ad8\u6548\u3001\u7a33\u5b9a\u3001\u53ef\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u4e34\u5e8a\u73af\u5883\u548c\u66f4\u5e7f\u6cdb\u795e\u7ecf\u5f71\u50cf\u5e94\u7528\u3002"}}
{"id": "2508.05744", "pdf": "https://arxiv.org/pdf/2508.05744", "abs": "https://arxiv.org/abs/2508.05744", "authors": ["Aizhan Akhmetzhanova", "Carolina Cuesta-Lazaro", "Siddharth Mishra-Sharma"], "title": "Detecting Model Misspecification in Cosmology with Scale-Dependent Normalizing Flows", "categories": ["astro-ph.CO", "astro-ph.IM", "cs.LG"], "comment": "14 + 5 pages, 6 + 4 figures", "summary": "Current and upcoming cosmological surveys will produce unprecedented amounts\nof high-dimensional data, which require complex high-fidelity forward\nsimulations to accurately model both physical processes and systematic effects\nwhich describe the data generation process. However, validating whether our\ntheoretical models accurately describe the observed datasets remains a\nfundamental challenge. An additional complexity to this task comes from\nchoosing appropriate representations of the data which retain all the relevant\ncosmological information, while reducing the dimensionality of the original\ndataset. In this work we present a novel framework combining scale-dependent\nneural summary statistics with normalizing flows to detect model\nmisspecification in cosmological simulations through Bayesian evidence\nestimation. By conditioning our neural network models for data compression and\nevidence estimation on the smoothing scale, we systematically identify where\ntheoretical models break down in a data-driven manner. We demonstrate a first\napplication to our approach using matter and gas density fields from three\nCAMELS simulation suites with different subgrid physics implementations.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5c3a\u5ea6\u4f9d\u8d56\u795e\u7ecf\u7edf\u8ba1\u91cf\u4e0e\u5f52\u4e00\u5316\u6d41\u7684\u6846\u67b6\u68c0\u6d4b\u5b87\u5b99\u6a21\u62df\u6a21\u578b\u9519\u8bef\u6307\u5b9a\u3002", "motivation": "\u5f53\u524d\u548c\u672a\u6765\u5b87\u5b99\u5b66\u8c03\u67e5\u4ea7\u751f\u5927\u91cf\u9ad8\u7ef4\u6570\u636e\uff0c\u9a8c\u8bc1\u7406\u8bba\u6a21\u578b\u80fd\u5426\u51c6\u786e\u63cf\u8ff0\u89c2\u6d4b\u6570\u636e\u662f\u6311\u6218\uff0c\u4e14\u9700\u9009\u62e9\u5408\u9002\u6570\u636e\u8868\u793a\u65b9\u5f0f\u3002", "method": "\u7ed3\u5408\u5c3a\u5ea6\u4f9d\u8d56\u795e\u7ecf\u7edf\u8ba1\u91cf\u4e0e\u5f52\u4e00\u5316\u6d41\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u8bc1\u636e\u4f30\u8ba1\u68c0\u6d4b\u6a21\u578b\u9519\u8bef\u6307\u5b9a\uff0c\u5728\u5e73\u6ed1\u5c3a\u5ea6\u4e0a\u5bf9\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8fdb\u884c\u6570\u636e\u538b\u7f29\u548c\u8bc1\u636e\u4f30\u8ba1\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6b21\u7f51\u683c\u7269\u7406\u5b9e\u73b0\u7684CAMELS\u6a21\u62df\u5957\u4ef6\u7684\u7269\u8d28\u548c\u6c14\u4f53\u5bc6\u5ea6\u573a\u4e0a\u8fdb\u884c\u4e86\u9996\u6b21\u5e94\u7528\u3002", "conclusion": "\u80fd\u4ee5\u6570\u636e\u9a71\u52a8\u7684\u65b9\u5f0f\u7cfb\u7edf\u8bc6\u522b\u7406\u8bba\u6a21\u578b\u5931\u6548\u4e4b\u5904\u3002"}}
{"id": "2508.05838", "pdf": "https://arxiv.org/pdf/2508.05838", "abs": "https://arxiv.org/abs/2508.05838", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY", "68T07, 68T40, 90C40, 93E35", "I.2.6; I.2.9; I.2.10"], "comment": "Published in the Proceedings of the 2025 3rd International Conference\n  on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 figures, 1\n  table", "summary": "This paper presents a novel approach that integrates vision foundation models\nwith reinforcement learning to enhance object interaction capabilities in\nsimulated environments. By combining the Segment Anything Model (SAM) and\nYOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the\nAI2-THOR simulation environment, we enable the agent to perceive and interact\nwith objects more effectively. Our comprehensive experiments, conducted across\nfour diverse indoor kitchen settings, demonstrate significant improvements in\nobject interaction success rates and navigation efficiency compared to a\nbaseline agent without advanced perception. The results show a 68% increase in\naverage cumulative reward, a 52.5% improvement in object interaction success\nrate, and a 33% increase in navigation efficiency. These findings highlight the\npotential of integrating foundation models with reinforcement learning for\ncomplex robotic tasks, paving the way for more sophisticated and capable\nautonomous agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u5728\u6a21\u62df\u73af\u5883\u63d0\u5347\u5bf9\u8c61\u4ea4\u4e92\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u63d0\u5347\u6a21\u62df\u73af\u5883\u4e2d\u5bf9\u8c61\u4ea4\u4e92\u80fd\u529b\u3002", "method": "\u5c06SAM\u548cYOLOv5\u4e0ePPO\u667a\u80fd\u4f53\u7ed3\u5408\uff0c\u5728AI2 - THOR\u6a21\u62df\u73af\u5883\u8fd0\u884c\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u5ba4\u5185\u53a8\u623f\u573a\u666f\u5b9e\u9a8c\uff0c\u5e73\u5747\u7d2f\u79ef\u5956\u52b1\u589e\u52a068%\uff0c\u5bf9\u8c61\u4ea4\u4e92\u6210\u529f\u7387\u63d0\u9ad852.5%\uff0c\u5bfc\u822a\u6548\u7387\u63d0\u534733%\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u5bf9\u590d\u6742\u673a\u5668\u4eba\u4efb\u52a1\u6709\u6f5c\u529b\uff0c\u4e3a\u66f4\u667a\u80fd\u81ea\u4e3b\u667a\u80fd\u4f53\u53d1\u5c55\u94fa\u8def\u3002"}}
{"id": "2508.05762", "pdf": "https://arxiv.org/pdf/2508.05762", "abs": "https://arxiv.org/abs/2508.05762", "authors": ["Sajid Mannan", "Vaibhav Bihani", "Carmelo Gonzales", "Kin Long Kelvin Lee", "Nitya Nand Gosvami", "Sayan Ranu", "Santiago Miret", "N M Anoop Krishnan"], "title": "Evaluating Universal Machine Learning Force Fields Against Experimental Measurements", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Universal machine learning force fields (UMLFFs) promise to revolutionize\nmaterials science by enabling rapid atomistic simulations across the periodic\ntable. However, their evaluation has been limited to computational benchmarks\nthat may not reflect real-world performance. Here, we present UniFFBench, a\ncomprehensive framework for evaluating UMLFFs against experimental measurements\nof ~1,500 carefully curated mineral structures spanning diverse chemical\nenvironments, bonding types, structural complexity, and elastic properties. Our\nsystematic evaluation of six state-of-the-art UMLFFs reveals a substantial\nreality gap: models achieving impressive performance on computational\nbenchmarks often fail when confronted with experimental complexity. Even the\nbest-performing models exhibit higher density prediction error than the\nthreshold required for practical applications. Most strikingly, we observe\ndisconnects between simulation stability and mechanical property accuracy, with\nprediction errors correlating with training data representation rather than the\nmodeling method. These findings demonstrate that while current computational\nbenchmarks provide valuable controlled comparisons, they may overestimate model\nreliability when extrapolated to experimentally complex chemical spaces.\nAltogether, UniFFBench establishes essential experimental validation standards\nand reveals systematic limitations that must be addressed to achieve truly\nuniversal force field capabilities.", "AI": {"tldr": "\u63d0\u51faUniFFBench\u6846\u67b6\u8bc4\u4f30UMLFFs\uff0c\u53d1\u73b0\u8ba1\u7b97\u57fa\u51c6\u4e0e\u5b9e\u9a8c\u8868\u73b0\u6709\u5dee\u8ddd\uff0c\u5efa\u7acb\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u6807\u51c6\u3002", "motivation": "\u73b0\u6709UMLFFs\u8bc4\u4f30\u5c40\u9650\u4e8e\u8ba1\u7b97\u57fa\u51c6\uff0c\u4e0d\u80fd\u53cd\u6620\u771f\u5b9e\u6027\u80fd\uff0c\u9700\u7528\u5b9e\u9a8c\u6d4b\u91cf\u8bc4\u4f30\u3002", "method": "\u63d0\u51faUniFFBench\u6846\u67b6\uff0c\u7528\u7ea61500\u4e2a\u7cbe\u5fc3\u6311\u9009\u7684\u77ff\u7269\u7ed3\u6784\u5b9e\u9a8c\u6d4b\u91cf\u8bc4\u4f30\u516d\u4e2a\u5148\u8fdbUMLFFs\u3002", "result": "\u53d1\u73b0\u8ba1\u7b97\u57fa\u51c6\u4e0e\u5b9e\u9a8c\u5b58\u5728\u73b0\u5b9e\u5dee\u8ddd\uff0c\u6700\u4f73\u6a21\u578b\u5bc6\u5ea6\u9884\u6d4b\u8bef\u5dee\u8d85\u5b9e\u7528\u9608\u503c\uff0c\u6a21\u62df\u7a33\u5b9a\u6027\u548c\u529b\u5b66\u6027\u80fd\u51c6\u786e\u6027\u8131\u8282\uff0c\u8bef\u5dee\u4e0e\u8bad\u7ec3\u6570\u636e\u8868\u793a\u76f8\u5173\u3002", "conclusion": "\u5f53\u524d\u8ba1\u7b97\u57fa\u51c6\u53ef\u80fd\u9ad8\u4f30\u6a21\u578b\u53ef\u9760\u6027\uff0cUniFFBench\u5efa\u7acb\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u6807\u51c6\uff0c\u6307\u51fa\u9700\u89e3\u51b3\u7cfb\u7edf\u5c40\u9650\u6027\u4ee5\u5b9e\u73b0\u901a\u7528\u529b\u573a\u80fd\u529b\u3002"}}
{"id": "2508.05846", "pdf": "https://arxiv.org/pdf/2508.05846", "abs": "https://arxiv.org/abs/2508.05846", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "title": "Towards Transparent Ethical AI: A Roadmap for Trustworthy Robotic Systems", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LG", "cs.RO", "68T01, 68T40", "K.7.4; K.4.1; I.2.9; H.1.2"], "comment": "Published in the Proceedings of the 2025 3rd International Conference\n  on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 tables", "summary": "As artificial intelligence (AI) and robotics increasingly permeate society,\nensuring the ethical behavior of these systems has become paramount. This paper\ncontends that transparency in AI decision-making processes is fundamental to\ndeveloping trustworthy and ethically aligned robotic systems. We explore how\ntransparency facilitates accountability, enables informed consent, and supports\nthe debugging of ethical algorithms. The paper outlines technical, ethical, and\npractical challenges in implementing transparency and proposes novel approaches\nto enhance it, including standardized metrics, explainable AI techniques, and\nuser-friendly interfaces. This paper introduces a framework that connects\ntechnical implementation with ethical considerations in robotic systems,\nfocusing on the specific challenges of achieving transparency in dynamic,\nreal-world contexts. We analyze how prioritizing transparency can impact public\ntrust, regulatory policies, and avenues for future research. By positioning\ntransparency as a fundamental element in ethical AI system design, we aim to\nadd to the ongoing discussion on responsible AI and robotics, providing\ndirection for future advancements in this vital field.", "AI": {"tldr": "\u672c\u6587\u5f3a\u8c03AI\u51b3\u7b56\u8fc7\u7a0b\u900f\u660e\u5ea6\u5bf9\u5f00\u53d1\u53ef\u4fe1\u4e14\u7b26\u5408\u4f26\u7406\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u63a2\u8ba8\u5176\u4f5c\u7528\u3001\u5b9e\u65bd\u6311\u6218\u5e76\u63d0\u51fa\u589e\u5f3a\u65b9\u6cd5\uff0c\u8fd8\u5206\u6790\u5f71\u54cd\u5e76\u4e3a\u8be5\u9886\u57df\u53d1\u5c55\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u968f\u7740AI\u548c\u673a\u5668\u4eba\u6280\u672f\u6e17\u900f\u793e\u4f1a\uff0c\u786e\u4fdd\u5176\u4f26\u7406\u884c\u4e3a\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u7814\u7a76AI\u51b3\u7b56\u8fc7\u7a0b\u900f\u660e\u5ea6\u5bf9\u5f00\u53d1\u4f26\u7406\u673a\u5668\u4eba\u7cfb\u7edf\u7684\u4f5c\u7528\u3002", "method": "\u63a2\u8ba8\u900f\u660e\u5ea6\u7684\u4f5c\u7528\uff0c\u6982\u8ff0\u5b9e\u65bd\u900f\u660e\u5ea6\u7684\u6280\u672f\u3001\u4f26\u7406\u548c\u5b9e\u8df5\u6311\u6218\uff0c\u63d0\u51fa\u5305\u62ec\u6807\u51c6\u5316\u6307\u6807\u3001\u53ef\u89e3\u91caAI\u6280\u672f\u548c\u7528\u6237\u53cb\u597d\u754c\u9762\u7b49\u589e\u5f3a\u900f\u660e\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u5f15\u5165\u8fde\u63a5\u6280\u672f\u5b9e\u73b0\u4e0e\u4f26\u7406\u8003\u91cf\u7684\u6846\u67b6\u3002", "result": "\u5206\u6790\u4e86\u91cd\u89c6\u900f\u660e\u5ea6\u5bf9\u516c\u4f17\u4fe1\u4efb\u3001\u76d1\u7ba1\u653f\u7b56\u548c\u672a\u6765\u7814\u7a76\u9014\u5f84\u7684\u5f71\u54cd\u3002", "conclusion": "\u5c06\u900f\u660e\u5ea6\u5b9a\u4f4d\u4e3a\u4f26\u7406AI\u7cfb\u7edf\u8bbe\u8ba1\u7684\u57fa\u672c\u8981\u7d20\uff0c\u4e3a\u8d1f\u8d23\u4efb\u7684AI\u548c\u673a\u5668\u4eba\u6280\u672f\u7684\u8ba8\u8bba\u63d0\u4f9b\u65b9\u5411\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u672a\u6765\u53d1\u5c55\u3002"}}
{"id": "2508.05880", "pdf": "https://arxiv.org/pdf/2508.05880", "abs": "https://arxiv.org/abs/2508.05880", "authors": ["Sree Bhattacharyya", "Lucas Craig", "Tharun Dilliraj", "Jia Li", "James Z. Wang"], "title": "Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Affective Computing has been established as a crucial field of inquiry to\nadvance the holistic development of Artificial Intelligence (AI) systems.\nFoundation models -- especially Large Language Models (LLMs) -- have been\nevaluated, trained, or instruction-tuned in several past works, to become\nbetter predictors or generators of emotion. Most of these studies, however,\napproach emotion-related tasks in a supervised manner, assessing or training\nthe capabilities of LLMs using discrete emotion labels associated with stimuli\n(e.g., text, images, video, audio). Evaluation studies, in particular, have\noften been limited to standard and superficial emotion-related tasks, such as\nthe recognition of evoked or expressed emotions. In this paper, we move beyond\nsurface-level emotion tasks to investigate how LLMs reason about emotions\nthrough cognitive dimensions. Drawing from cognitive appraisal theory, we\nexamine whether LLMs produce coherent and plausible cognitive reasoning when\nreasoning about emotionally charged stimuli. We introduce a large-scale\nbenchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal\ncognitive structures implicitly used by LLMs for emotional reasoning. Through a\nplethora of evaluation experiments and analysis, we seek to answer: (a) Are\nmodels more likely to implicitly rely on specific cognitive appraisal\ndimensions?, (b) What cognitive dimensions are important for characterizing\nspecific emotions?, and, (c) Can the internal representations of different\nemotion categories in LLMs be interpreted through cognitive appraisal\ndimensions? Our results and analyses reveal diverse reasoning patterns across\ndifferent LLMs. Our benchmark and code will be made publicly available.", "AI": {"tldr": "\u672c\u6587\u8d85\u8d8a\u8868\u9762\u60c5\u7eea\u4efb\u52a1\uff0c\u57fa\u4e8e\u8ba4\u77e5\u8bc4\u4f30\u7406\u8bba\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u901a\u8fc7\u8ba4\u77e5\u7ef4\u5ea6\u8fdb\u884c\u60c5\u7eea\u63a8\u7406\uff0c\u5f15\u5165CoRE\u57fa\u51c6\u8bc4\u4f30\u6a21\u578b\uff0c\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u63a8\u7406\u6a21\u5f0f\u591a\u6837\uff0c\u4ee3\u7801\u5c06\u516c\u5f00\u3002", "motivation": "\u8fc7\u53bb\u591a\u6570\u7814\u7a76\u4ee5\u76d1\u7763\u65b9\u5f0f\u5904\u7406\u60c5\u7eea\u76f8\u5173\u4efb\u52a1\uff0c\u8bc4\u4f30\u9650\u4e8e\u6807\u51c6\u548c\u8868\u9762\u7684\u60c5\u7eea\u4efb\u52a1\uff0c\u672c\u6587\u65e8\u5728\u8d85\u8d8a\u8868\u9762\uff0c\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u901a\u8fc7\u8ba4\u77e5\u7ef4\u5ea6\u8fdb\u884c\u60c5\u7eea\u63a8\u7406\u3002", "method": "\u501f\u9274\u8ba4\u77e5\u8bc4\u4f30\u7406\u8bba\uff0c\u5f15\u5165\u5927\u89c4\u6a21\u8ba4\u77e5\u63a8\u7406\u57fa\u51c6CoRE\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u7eea\u63a8\u7406\u65f6\u9690\u5f0f\u4f7f\u7528\u7684\u5185\u90e8\u8ba4\u77e5\u7ed3\u6784\uff0c\u8fdb\u884c\u5927\u91cf\u8bc4\u4f30\u5b9e\u9a8c\u548c\u5206\u6790\u3002", "result": "\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5448\u73b0\u51fa\u591a\u6837\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "conclusion": "\u53ef\u4ee5\u901a\u8fc7\u8ba4\u77e5\u8bc4\u4f30\u7ef4\u5ea6\u8fdb\u4e00\u6b65\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4e0d\u540c\u60c5\u7eea\u7c7b\u522b\u7684\u5185\u90e8\u8868\u5f81\uff0c\u76f8\u5173\u57fa\u51c6\u548c\u4ee3\u7801\u516c\u5f00\u5229\u4e8e\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2508.05913", "pdf": "https://arxiv.org/pdf/2508.05913", "abs": "https://arxiv.org/abs/2508.05913", "authors": ["Stefan Pasch", "Min Chul Cha"], "title": "Do Ethical AI Principles Matter to Users? A Large-Scale Analysis of User Sentiment and Satisfaction", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "As AI systems become increasingly embedded in organizational workflows and\nconsumer applications, ethical principles such as fairness, transparency, and\nrobustness have been widely endorsed in policy and industry guidelines.\nHowever, there is still scarce empirical evidence on whether these principles\nare recognized, valued, or impactful from the perspective of users. This study\ninvestigates the link between ethical AI and user satisfaction by analyzing\nover 100,000 user reviews of AI products from G2. Using transformer-based\nlanguage models, we measure sentiment across seven ethical dimensions defined\nby the EU Ethics Guidelines for Trustworthy AI. Our findings show that all\nseven dimensions are positively associated with user satisfaction. Yet, this\nrelationship varies systematically across user and product types. Technical\nusers and reviewers of AI development platforms more frequently discuss\nsystem-level concerns (e.g., transparency, data governance), while\nnon-technical users and reviewers of end-user applications emphasize\nhuman-centric dimensions (e.g., human agency, societal well-being). Moreover,\nthe association between ethical AI and user satisfaction is significantly\nstronger for non-technical users and end-user applications across all\ndimensions. Our results highlight the importance of ethical AI design from\nusers' perspectives and underscore the need to account for contextual\ndifferences across user roles and product types.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u8d8510\u4e07\u6761AI\u4ea7\u54c1\u7528\u6237\u8bc4\u8bba\uff0c\u53d1\u73b0\u4f26\u7406AI\u7684\u4e03\u4e2a\u7ef4\u5ea6\u4e0e\u7528\u6237\u6ee1\u610f\u5ea6\u6b63\u76f8\u5173\uff0c\u4e14\u5173\u7cfb\u56e0\u7528\u6237\u548c\u4ea7\u54c1\u7c7b\u578b\u800c\u5f02\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4ece\u7528\u6237\u89d2\u5ea6\u5173\u4e8e\u4f26\u7406AI\u539f\u5219\u662f\u5426\u88ab\u8ba4\u53ef\u3001\u91cd\u89c6\u53ca\u4ea7\u751f\u5f71\u54cd\u7684\u5b9e\u8bc1\u8bc1\u636e\uff0c\u7814\u7a76\u4f26\u7406AI\u4e0e\u7528\u6237\u6ee1\u610f\u5ea6\u7684\u8054\u7cfb\u3002", "method": "\u5206\u6790G2\u4e0a\u8d8510\u4e07\u6761AI\u4ea7\u54c1\u7528\u6237\u8bc4\u8bba\uff0c\u7528\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u6d4b\u91cf\u6b27\u76df\u53ef\u4fe1AI\u4f26\u7406\u6307\u5357\u5b9a\u4e49\u7684\u4e03\u4e2a\u4f26\u7406\u7ef4\u5ea6\u7684\u60c5\u611f\u3002", "result": "\u4e03\u4e2a\u7ef4\u5ea6\u90fd\u4e0e\u7528\u6237\u6ee1\u610f\u5ea6\u6b63\u76f8\u5173\uff0c\u5173\u7cfb\u56e0\u7528\u6237\u548c\u4ea7\u54c1\u7c7b\u578b\u7cfb\u7edf\u5730\u53d8\u5316\uff0c\u975e\u6280\u672f\u7528\u6237\u548c\u7ec8\u7aef\u5e94\u7528\u5728\u5404\u7ef4\u5ea6\u4e0a\u4f26\u7406AI\u4e0e\u7528\u6237\u6ee1\u610f\u5ea6\u7684\u5173\u8054\u66f4\u5f3a\u3002", "conclusion": "\u5f3a\u8c03\u4ece\u7528\u6237\u89d2\u5ea6\u8fdb\u884c\u4f26\u7406AI\u8bbe\u8ba1\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u8003\u8651\u7528\u6237\u89d2\u8272\u548c\u4ea7\u54c1\u7c7b\u578b\u4e0a\u4e0b\u6587\u5dee\u5f02\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2508.05933", "pdf": "https://arxiv.org/pdf/2508.05933", "abs": "https://arxiv.org/abs/2508.05933", "authors": ["Xueyuan Xu", "Wenjia Dong", "Fulin Wei", "Li Zhuo"], "title": "REFS: Robust EEG feature selection with missing multi-dimensional annotation for emotion recognition", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "The affective brain-computer interface is a crucial technology for affective\ninteraction and emotional intelligence, emerging as a significant area of\nresearch in the human-computer interaction. Compared to single-type features,\nmulti-type EEG features provide a multi-level representation for analyzing\nmulti-dimensional emotions. However, the high dimensionality of multi-type EEG\nfeatures, combined with the relatively small number of high-quality EEG\nsamples, poses challenges such as classifier overfitting and suboptimal\nreal-time performance in multi-dimensional emotion recognition. Moreover,\npractical applications of affective brain-computer interface frequently\nencounters partial absence of multi-dimensional emotional labels due to the\nopen nature of the acquisition environment, and ambiguity and variability in\nindividual emotion perception. To address these challenges, this study proposes\na novel EEG feature selection method for missing multi-dimensional emotion\nrecognition. The method leverages adaptive orthogonal non-negative matrix\nfactorization to reconstruct the multi-dimensional emotional label space\nthrough second-order and higher-order correlations, which could reduce the\nnegative impact of missing values and outliers on label reconstruction.\nSimultaneously, it employs least squares regression with graph-based manifold\nlearning regularization and global feature redundancy minimization\nregularization to enable EEG feature subset selection despite missing\ninformation, ultimately achieving robust EEG-based multi-dimensional emotion\nrecognition. Simulation experiments on three widely used multi-dimensional\nemotional datasets, DREAMER, DEAP and HDED, reveal that the proposed method\noutperforms thirteen advanced feature selection methods in terms of robustness\nfor EEG emotional feature selection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u7f3a\u5931\u591a\u7ef4\u60c5\u611f\u8bc6\u522b\u7684EEG\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728EEG\u60c5\u611f\u7279\u5f81\u9009\u62e9\u7684\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u5341\u4e09\u79cd\u5148\u8fdb\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002", "motivation": "\u591a\u7c7b\u578bEEG\u7279\u5f81\u9ad8\u7ef4\u3001\u9ad8\u8d28\u91cf\u6837\u672c\u5c11\u5bfc\u81f4\u5206\u7c7b\u5668\u8fc7\u62df\u5408\u548c\u5b9e\u65f6\u6027\u80fd\u4e0d\u4f73\uff0c\u4e14\u60c5\u611f\u8111\u673a\u63a5\u53e3\u5b9e\u9645\u5e94\u7528\u5e38\u9047\u5230\u591a\u7ef4\u60c5\u611f\u6807\u7b7e\u90e8\u5206\u7f3a\u5931\u95ee\u9898\u3002", "method": "\u5229\u7528\u81ea\u9002\u5e94\u6b63\u4ea4\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u901a\u8fc7\u4e8c\u9636\u53ca\u9ad8\u9636\u76f8\u5173\u6027\u91cd\u6784\u591a\u7ef4\u60c5\u611f\u6807\u7b7e\u7a7a\u95f4\uff0c\u91c7\u7528\u5e26\u57fa\u4e8e\u56fe\u7684\u6d41\u5f62\u5b66\u4e60\u6b63\u5219\u5316\u548c\u5168\u5c40\u7279\u5f81\u5197\u4f59\u6700\u5c0f\u5316\u6b63\u5219\u5316\u7684\u6700\u5c0f\u4e8c\u4e58\u56de\u5f52\u8fdb\u884cEEG\u7279\u5f81\u5b50\u96c6\u9009\u62e9\u3002", "result": "\u5728DREAMER\u3001DEAP\u548cHDED\u4e09\u4e2a\u591a\u7ef4\u60c5\u611f\u6570\u636e\u96c6\u4e0a\u7684\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728EEG\u60c5\u611f\u7279\u5f81\u9009\u62e9\u7684\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u5341\u4e09\u79cd\u5148\u8fdb\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u7ef4\u60c5\u611f\u8bc6\u522b\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u7a33\u5065\u7684\u57fa\u4e8eEEG\u7684\u591a\u7ef4\u60c5\u611f\u8bc6\u522b\u3002"}}
{"id": "2508.05934", "pdf": "https://arxiv.org/pdf/2508.05934", "abs": "https://arxiv.org/abs/2508.05934", "authors": ["Xueyuan Xu", "Tianze Yu", "Wenjia Dong", "Fulin Wei", "Li Zhuo"], "title": "ASLSL: Adaptive shared latent structure learning with incomplete multi-modal physiological data for multi-dimensional emotional feature selection", "categories": ["cs.HC", "cs.AI", "cs.LG"], "comment": null, "summary": "Recently, multi-modal physiological signals based emotion recognition has\ngarnered increasing attention in the field of brain-computer interfaces.\nNevertheness, the associated multi-modal physiological features are often\nhigh-dimensional and inevitably include irrelevant, redundant, and noisy\nrepresentation, which can easily lead to overfitting, poor performance, and\nhigh computational complexity in emotion classifiers. Feature selection has\nbeen widely applied to address these challenges. However, previous studies\ngenerally assumed that multi-modal physiological data are complete, whereas in\nreality, the data are often incomplete due to the openness of the acquisition\nand operational environment. For example, a part of samples are available in\nseveral modalities but not in others. To address this issue, we propose a novel\nmethod for incomplete multi-modal physiological signal feature selection called\nadaptive shared latent structure learning (ASLSL). Based on the property that\nsimilar features share similar emotional labels, ASLSL employs adaptive shared\nlatent structure learning to explore a common latent space shared for\nincomplete multi-modal physiological signals and multi-dimensional emotional\nlabels, thereby mitigating the impact of missing information and mining\nconsensus information. Two most popular multi-modal physiological emotion\ndatasets (DEAP and DREAMER) with multi-dimensional emotional labels were\nutilized to compare the performance between compare ASLSL and seventeen feature\nselection methods. Comprehensive experimental results on these datasets\ndemonstrate the effectiveness of ASLSL.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u5171\u4eab\u6f5c\u5728\u7ed3\u6784\u5b66\u4e60\uff08ASLSL\uff09\u65b9\u6cd5\u7528\u4e8e\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u7279\u5f81\u9009\u62e9\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u751f\u7406\u7279\u5f81\u9ad8\u7ef4\u4e14\u542b\u566a\u58f0\uff0c\u6613\u81f4\u5206\u7c7b\u5668\u8fc7\u62df\u5408\u7b49\u95ee\u9898\uff0c\u4e14\u4ee5\u5f80\u7814\u7a76\u5047\u8bbe\u6570\u636e\u5b8c\u6574\uff0c\u5b9e\u9645\u6570\u636e\u5e38\u4e0d\u5b8c\u6574\u3002", "method": "\u63d0\u51faASLSL\u65b9\u6cd5\uff0c\u5229\u7528\u76f8\u4f3c\u7279\u5f81\u6709\u76f8\u4f3c\u60c5\u611f\u6807\u7b7e\u7684\u7279\u6027\uff0c\u63a2\u7d22\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u548c\u591a\u7ef4\u60c5\u611f\u6807\u7b7e\u7684\u5171\u540c\u6f5c\u5728\u7a7a\u95f4\u3002", "result": "\u5728DEAP\u548cDREAMER\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4ASLSL\u548c17\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aASLSL\u6709\u6548\u3002", "conclusion": "ASLSL\u65b9\u6cd5\u80fd\u51cf\u8f7b\u4fe1\u606f\u7f3a\u5931\u5f71\u54cd\uff0c\u6316\u6398\u5171\u8bc6\u4fe1\u606f\uff0c\u5728\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u7279\u5f81\u9009\u62e9\u4e2d\u6709\u6548\u3002"}}
{"id": "2508.05878", "pdf": "https://arxiv.org/pdf/2508.05878", "abs": "https://arxiv.org/abs/2508.05878", "authors": ["Martyna Majchrzak", "Jacek Ma\u0144dziuk"], "title": "Training chord recognition models on artificially generated audio", "categories": ["cs.SD", "cs.LG"], "comment": null, "summary": "One of the challenging problems in Music Information Retrieval is the\nacquisition of enough non-copyrighted audio recordings for model training and\nevaluation. This study compares two Transformer-based neural network models for\nchord sequence recognition in audio recordings and examines the effectiveness\nof using an artificially generated dataset for this purpose. The models are\ntrained on various combinations of Artificial Audio Multitracks (AAM),\nSchubert's Winterreise Dataset, and the McGill Billboard Dataset and evaluated\nwith three metrics: Root, MajMin and Chord Content Metric (CCM). The\nexperiments prove that even though there are certainly differences in\ncomplexity and structure between artificially generated and human-composed\nmusic, the former can be useful in certain scenarios. Specifically, AAM can\nenrich a smaller training dataset of music composed by a human or can even be\nused as a standalone training set for a model that predicts chord sequences in\npop music, if no other data is available.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4\u4e24\u4e2a\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u7528\u4e8e\u97f3\u9891\u548c\u5f26\u5e8f\u5217\u8bc6\u522b\uff0c\u68c0\u9a8c\u4eba\u5de5\u751f\u6210\u6570\u636e\u96c6\u6548\u679c\uff0c\u8bc1\u660e\u5176\u5728\u7279\u5b9a\u573a\u666f\u6709\u7528\u3002", "motivation": "\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u4e2d\u83b7\u53d6\u65e0\u7248\u6743\u97f3\u9891\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30\u6709\u6311\u6218\uff0c\u9700\u7814\u7a76\u4eba\u5de5\u751f\u6210\u6570\u636e\u96c6\u5728\u548c\u5f26\u5e8f\u5217\u8bc6\u522b\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u7528\u4e0d\u540c\u7ec4\u5408\u7684\u4eba\u5de5\u97f3\u9891\u591a\u8f68\u3001\u8212\u4f2f\u7279\u300a\u51ac\u4e4b\u65c5\u300b\u6570\u636e\u96c6\u548c\u9ea6\u5409\u5c14\u516c\u544a\u724c\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\uff0c\u7528Root\u3001MajMin\u548cCCM\u4e09\u4e2a\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u4eba\u5de5\u751f\u6210\u97f3\u4e50\u4e0e\u4eba\u7c7b\u521b\u4f5c\u97f3\u4e50\u5728\u590d\u6742\u5ea6\u548c\u7ed3\u6784\u4e0a\u6709\u5dee\u5f02\uff0c\u4f46\u4eba\u5de5\u751f\u6210\u6570\u636e\u96c6\u5728\u7279\u5b9a\u573a\u666f\u6709\u7528\u3002", "conclusion": "\u4eba\u5de5\u97f3\u9891\u591a\u8f68\u53ef\u4e30\u5bcc\u5c0f\u7684\u4eba\u7c7b\u521b\u4f5c\u97f3\u4e50\u8bad\u7ec3\u96c6\uff0c\u5728\u65e0\u5176\u4ed6\u6570\u636e\u65f6\u53ef\u4f5c\u6d41\u884c\u97f3\u4e50\u548c\u5f26\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u72ec\u7acb\u8bad\u7ec3\u96c6\u3002"}}
{"id": "2508.05938", "pdf": "https://arxiv.org/pdf/2508.05938", "abs": "https://arxiv.org/abs/2508.05938", "authors": ["Rafal Kocielnik", "Min Kim", "Penphob", "Boonyarungsrit", "Fereshteh Soltani", "Deshawn Sambrano", "Animashree Anandkumar", "R. Michael Alvarez"], "title": "Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; K.4"], "comment": "9 pages, 4 figures, 4 tables", "summary": "Detecting prosociality in text--communication intended to affirm, support, or\nimprove others' behavior--is a novel and increasingly important challenge for\ntrust and safety systems. Unlike toxic content detection, prosociality lacks\nwell-established definitions and labeled data, requiring new approaches to both\nannotation and deployment. We present a practical, three-stage pipeline that\nenables scalable, high-precision prosocial content classification while\nminimizing human labeling effort and inference costs. First, we identify the\nbest LLM-based labeling strategy using a small seed set of human-labeled\nexamples. We then introduce a human-AI refinement loop, where annotators review\nhigh-disagreement cases between GPT-4 and humans to iteratively clarify and\nexpand the task definition-a critical step for emerging annotation tasks like\nprosociality. This process results in improved label quality and definition\nalignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train\na two-stage inference system: a lightweight classifier handles high-confidence\npredictions, while only $\\sim$35\\% of ambiguous instances are escalated to\nGPT-4o. This architecture reduces inference costs by $\\sim$70% while achieving\nhigh precision ($\\sim$0.90). Our pipeline demonstrates how targeted human-AI\ninteraction, careful task formulation, and deployment-aware architecture design\ncan unlock scalable solutions for novel responsible AI tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u9636\u6bb5\u7ba1\u9053\u7528\u4e8e\u4eb2\u793e\u4f1a\u5185\u5bb9\u5206\u7c7b\uff0c\u51cf\u5c11\u4eba\u529b\u6807\u6ce8\u548c\u63a8\u7406\u6210\u672c\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u9ad8\u7cbe\u5ea6\u5206\u7c7b\u3002", "motivation": "\u4eb2\u793e\u4f1a\u6587\u672c\u68c0\u6d4b\u662f\u4fe1\u4efb\u548c\u5b89\u5168\u7cfb\u7edf\u7684\u65b0\u6311\u6218\uff0c\u7f3a\u4e4f\u660e\u786e\u5b9a\u4e49\u4e0e\u6807\u6ce8\u6570\u636e\uff0c\u9700\u65b0\u65b9\u6cd5\u3002", "method": "\u5148\u786e\u5b9a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6700\u4f73\u6807\u6ce8\u7b56\u7565\uff0c\u5f15\u5165\u4eba\u673a\u7ec6\u5316\u5faa\u73af\u660e\u786e\u4efb\u52a1\u5b9a\u4e49\uff0c\u5408\u6210\u9ad8\u8d28\u91cf\u6807\u7b7e\uff0c\u8bad\u7ec3\u4e24\u9636\u6bb5\u63a8\u7406\u7cfb\u7edf\u3002", "result": "\u964d\u4f4e\u7ea670%\u63a8\u7406\u6210\u672c\uff0c\u8fbe\u5230\u7ea60.90\u7684\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "\u6709\u9488\u5bf9\u6027\u7684\u4eba\u673a\u4ea4\u4e92\u3001\u7cbe\u5fc3\u7684\u4efb\u52a1\u8bbe\u8ba1\u548c\u8003\u8651\u90e8\u7f72\u7684\u67b6\u6784\u8bbe\u8ba1\u53ef\u89e3\u51b3\u65b0\u578b\u8d1f\u8d23\u4efbAI\u4efb\u52a1\u3002"}}
{"id": "2508.05908", "pdf": "https://arxiv.org/pdf/2508.05908", "abs": "https://arxiv.org/abs/2508.05908", "authors": ["Shreshth A. Malik", "Tiarnan A. S. Doherty", "Benjamin Colmey", "Stephen J. Roberts", "Yarin Gal", "Paul A. Midgley"], "title": "Hybrid Physics-Machine Learning Models for Quantitative Electron Diffraction Refinements", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "High-fidelity electron microscopy simulations required for quantitative\ncrystal structure refinements face a fundamental challenge: while physical\ninteractions are well-described theoretically, real-world experimental effects\nare challenging to model analytically. To address this gap, we present a novel\nhybrid physics-machine learning framework that integrates differentiable\nphysical simulations with neural networks. By leveraging automatic\ndifferentiation throughout the simulation pipeline, our method enables\ngradient-based joint optimization of physical parameters and neural network\ncomponents representing experimental variables, offering superior scalability\ncompared to traditional second-order methods. We demonstrate this framework\nthrough application to three-dimensional electron diffraction (3D-ED) structure\nrefinement, where our approach learns complex thickness distributions directly\nfrom diffraction data rather than relying on simplified geometric models. This\nmethod achieves state-of-the-art refinement performance across synthetic and\nexperimental datasets, recovering atomic positions, thermal displacements, and\nthickness profiles with high fidelity. The modular architecture proposed can\nnaturally be extended to accommodate additional physical phenomena and extended\nto other electron microscopy techniques. This establishes differentiable hybrid\nmodeling as a powerful new paradigm for quantitative electron microscopy, where\nexperimental complexities have historically limited analysis.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u7269\u7406 - \u673a\u5668\u5b66\u4e60\u6846\u67b6\u7528\u4e8e\u9ad8\u4fdd\u771f\u7535\u5b50\u663e\u5fae\u955c\u6a21\u62df\uff0c\u57283D - ED\u7ed3\u6784\u7cbe\u4fee\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u9ad8\u4fdd\u771f\u7535\u5b50\u663e\u5fae\u955c\u6a21\u62df\u9762\u4e34\u96be\u4ee5\u5bf9\u73b0\u5b9e\u5b9e\u9a8c\u6548\u679c\u8fdb\u884c\u89e3\u6790\u5efa\u6a21\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u7269\u7406 - \u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u53ef\u5fae\u7269\u7406\u6a21\u62df\u4e0e\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u81ea\u52a8\u5fae\u5206\u8fdb\u884c\u68af\u5ea6\u8054\u5408\u4f18\u5316\u3002", "result": "\u5728\u5408\u6210\u548c\u5b9e\u9a8c\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u5148\u8fdb\u7684\u7cbe\u4fee\u6027\u80fd\uff0c\u80fd\u9ad8\u4fdd\u771f\u6062\u590d\u539f\u5b50\u4f4d\u7f6e\u3001\u70ed\u4f4d\u79fb\u548c\u539a\u5ea6\u5206\u5e03\u3002", "conclusion": "\u53ef\u5fae\u6df7\u5408\u5efa\u6a21\u662f\u5b9a\u91cf\u7535\u5b50\u663e\u5fae\u955c\u7684\u5f3a\u5927\u65b0\u8303\u5f0f\u3002"}}
{"id": "2508.05950", "pdf": "https://arxiv.org/pdf/2508.05950", "abs": "https://arxiv.org/abs/2508.05950", "authors": ["Yanxing Liang", "Yinghui Wang", "Jinlong Yang", "Wei Li"], "title": "A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The lack of spatial dimensional information remains a challenge in normal\nestimation from a single image. Recent diffusion-based methods have\ndemonstrated significant potential in 2D-to-3D implicit mapping, they rely on\ndata-driven statistical priors and miss the explicit modeling of light-surface\ninteraction, leading to multi-view normal direction conflicts. Moreover, the\ndiscrete sampling mechanism of diffusion models causes gradient discontinuity\nin differentiable rendering reconstruction modules, preventing 3D geometric\nerrors from being backpropagated to the normal generation network, thereby\nforcing existing methods to depend on dense normal annotations. This paper\nproposes SINGAD, a novel Self-supervised framework from a single Image for\nNormal estimation via 3D GAussian splatting guided Diffusion. By integrating\nphysics-driven light-interaction modeling and a differentiable rendering-based\nreprojection strategy, our framework directly converts 3D geometric errors into\nnormal optimization signals, solving the challenges of multi-view geometric\ninconsistency and data dependency. Specifically, the framework constructs a\nlight-interaction-driven 3DGS reparameterization model to generate multi-scale\ngeometric features consistent with light transport principles, ensuring\nmulti-view normal consistency. A cross-domain feature fusion module is designed\nwithin a conditional diffusion model, embedding geometric priors to constrain\nnormal generation while maintaining accurate geometric error propagation.\nFurthermore, a differentiable 3D reprojection loss strategy is introduced for\nself-supervised optimization that minimizes geometric error between the\nreconstructed and input image, eliminating dependence on annotated normal\ndatasets. Quantitative evaluations on the Google Scanned Objects dataset\ndemonstrate that our method outperforms state-of-the-art approaches across\nmultiple metrics.", "AI": {"tldr": "\u63d0\u51faSINGAD\u6846\u67b6\u7528\u4e8e\u5355\u56fe\u50cf\u6cd5\u7ebf\u4f30\u8ba1\uff0c\u89e3\u51b3\u591a\u89c6\u56fe\u51e0\u4f55\u4e0d\u4e00\u81f4\u548c\u6570\u636e\u4f9d\u8d56\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u5355\u56fe\u50cf\u6cd5\u7ebf\u4f30\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u6570\u636e\u9a71\u52a8\u7edf\u8ba1\u5148\u9a8c\uff0c\u7f3a\u5c11\u5149 - \u8868\u9762\u4ea4\u4e92\u663e\u5f0f\u5efa\u6a21\uff0c\u4e14\u6269\u6563\u6a21\u578b\u79bb\u6563\u91c7\u6837\u673a\u5236\u5bfc\u81f4\u68af\u5ea6\u4e0d\u8fde\u7eed\uff0c\u9700\u4f9d\u8d56\u5bc6\u96c6\u6cd5\u7ebf\u6807\u6ce8\u3002", "method": "\u63d0\u51faSINGAD\u6846\u67b6\uff0c\u96c6\u6210\u7269\u7406\u9a71\u52a8\u5149\u4ea4\u4e92\u5efa\u6a21\u548c\u57fa\u4e8e\u53ef\u5fae\u6e32\u67d3\u7684\u91cd\u6295\u5f71\u7b56\u7565\uff0c\u6784\u5efa\u5149\u4ea4\u4e92\u9a71\u52a8\u76843DGS\u91cd\u53c2\u6570\u5316\u6a21\u578b\uff0c\u8bbe\u8ba1\u8de8\u57df\u7279\u5f81\u878d\u5408\u6a21\u5757\uff0c\u5f15\u5165\u53ef\u5fae3D\u91cd\u6295\u5f71\u635f\u5931\u7b56\u7565\u3002", "result": "\u5728Google Scanned Objects\u6570\u636e\u96c6\u4e0a\u7684\u5b9a\u91cf\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SINGAD\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u89c6\u56fe\u51e0\u4f55\u4e0d\u4e00\u81f4\u548c\u6570\u636e\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5355\u56fe\u50cf\u6cd5\u7ebf\u4f30\u8ba1\u6027\u80fd\u3002"}}
{"id": "2508.05922", "pdf": "https://arxiv.org/pdf/2508.05922", "abs": "https://arxiv.org/abs/2508.05922", "authors": ["Sri Ramana Saketh Vasanthawada", "Pengkun Liu", "Pingbo Tang"], "title": "Enhancing Construction Site Analysis and Understanding with 3D Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Monitoring construction progress is crucial yet resource-intensive, prompting\nthe exploration of computer-vision-based methodologies for enhanced efficiency\nand scalability. Traditional data acquisition methods, primarily focusing on\nindoor environments, falter in construction site's complex, cluttered, and\ndynamically changing conditions. This paper critically evaluates the\napplication of two advanced 3D segmentation methods, Segment Anything Model\n(SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained\ninitially on indoor datasets, both models' adaptability and performance are\nassessed in real-world construction settings, highlighting the gap in current\nsegmentation approaches due to the absence of benchmarks for outdoor scenarios.\nThrough a comparative analysis, this study not only showcases the relative\neffectiveness of SAM and Mask3D but also addresses the critical need for\ntailored segmentation workflows capable of extracting actionable insights from\nconstruction site data, thereby advancing the field towards more automated and\nprecise monitoring techniques.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30SAM\u548cMask3D\u5728\u5efa\u7b51\u573a\u666f\u7684\u4e09\u7ef4\u5206\u5272\u6548\u679c\uff0c\u6307\u51fa\u5f53\u524d\u65b9\u6cd5\u4e0d\u8db3\uff0c\u63a8\u52a8\u5efa\u7b51\u8fdb\u5ea6\u76d1\u6d4b\u6280\u672f\u53d1\u5c55\u3002", "motivation": "\u5efa\u7b51\u8fdb\u5ea6\u76d1\u6d4b\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u590d\u6742\u5efa\u7b51\u5de5\u5730\u73af\u5883\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u63a2\u7d22\u57fa\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30SAM\u548cMask3D\u5728\u5ba4\u5185\u5916\u590d\u6742\u6761\u4ef6\u4e0b\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\uff0c\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5c55\u793a\u4e86SAM\u548cMask3D\u7684\u76f8\u5bf9\u6709\u6548\u6027\uff0c\u6307\u51fa\u5f53\u524d\u5206\u5272\u65b9\u6cd5\u5728\u6237\u5916\u573a\u666f\u7f3a\u4e4f\u57fa\u51c6\u7684\u95ee\u9898\u3002", "conclusion": "\u9700\u8981\u5b9a\u5236\u5206\u5272\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u81ea\u52a8\u5316\u3001\u7cbe\u786e\u7684\u5efa\u7b51\u8fdb\u5ea6\u76d1\u6d4b\u3002"}}
{"id": "2508.05954", "pdf": "https://arxiv.org/pdf/2508.05954", "abs": "https://arxiv.org/abs/2508.05954", "authors": ["Han Lin", "Jaemin Cho", "Amir Zadeh", "Chuan Li", "Mohit Bansal"], "title": "Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Project Page: https://bifrost-1.github.io", "summary": "There is growing interest in integrating high-fidelity visual synthesis\ncapabilities into large language models (LLMs) without compromising their\nstrong reasoning capabilities. Existing methods that directly train LLMs or\nbridge LLMs and diffusion models usually suffer from costly training since the\nbackbone LLMs have not seen image representations during pretraining. We\npresent Bifrost-1, a unified framework that bridges pretrained multimodal LLMs\n(MLLMs) and diffusion models using patch-level CLIP image embeddings as latent\nvariables, which are natively aligned with the MLLM's CLIP visual encoder.\nThese patch-level image embeddings are integrated into the diffusion model with\na lightweight adaptation of its ControlNet. To retain the original multimodal\nreasoning capabilities of MLLMs, we equip the MLLM with a visual generation\nbranch initialized from the original MLLM parameters when predicting the\npatch-level image embeddings. By seamlessly integrating pretrained MLLMs and\ndiffusion models with patch-level CLIP latents, our framework enables\nhigh-fidelity controllable image generation with significant training\nefficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or\nbetter performance than previous methods in terms of visual fidelity and\nmultimodal understanding, with substantially lower compute during training. We\nalso provide comprehensive ablation studies showing the effectiveness of our\ndesign choices.", "AI": {"tldr": "\u63d0\u51faBifrost - 1\u6846\u67b6\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u9ad8\u4fdd\u771f\u53ef\u63a7\u56fe\u50cf\u751f\u6210\uff0c\u8bad\u7ec3\u6548\u7387\u9ad8\u3002", "motivation": "\u5728\u4e0d\u635f\u5bb3\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u9ad8\u4fdd\u771f\u89c6\u89c9\u5408\u6210\u80fd\u529b\u96c6\u6210\u5230\u5176\u4e2d\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u8bad\u7ec3\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8865\u4e01\u7ea7CLIP\u56fe\u50cf\u5d4c\u5165\u4f5c\u4e3a\u6f5c\u5728\u53d8\u91cf\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8c03\u6574\u6269\u6563\u6a21\u578b\u7684ControlNet\u96c6\u6210\u5230\u6269\u6563\u6a21\u578b\uff0c\u7ed9MLLM\u914d\u5907\u89c6\u89c9\u751f\u6210\u5206\u652f\u3002", "result": "Bifrost - 1\u5728\u89c6\u89c9\u4fdd\u771f\u5ea6\u548c\u591a\u6a21\u6001\u7406\u89e3\u65b9\u9762\u8fbe\u5230\u6216\u8d85\u8fc7\u5148\u524d\u65b9\u6cd5\uff0c\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u5927\u5e45\u964d\u4f4e\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u8bbe\u8ba1\u6709\u6548\u6027\u3002", "conclusion": "Bifrost - 1\u6846\u67b6\u80fd\u6709\u6548\u7ed3\u5408\u9884\u8bad\u7ec3MLLMs\u548c\u6269\u6563\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u53ef\u63a7\u56fe\u50cf\u751f\u6210\uff0c\u4e14\u8bad\u7ec3\u6548\u7387\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2508.05978", "pdf": "https://arxiv.org/pdf/2508.05978", "abs": "https://arxiv.org/abs/2508.05978", "authors": ["Wei Chen", "Binzhu Sha", "Dan Luo", "Jing Yang", "Zhuo Wang", "Fan Fan", "Zhiyong Wu"], "title": "DAFMSVC: One-Shot Singing Voice Conversion with Dual Attention Mechanism and Flow Matching", "categories": ["cs.SD", "cs.AI", "cs.LG"], "comment": "Accepted by INTERSPEECH 2025", "summary": "Singing Voice Conversion (SVC) transfers a source singer's timbre to a target\nwhile keeping melody and lyrics. The key challenge in any-to-any SVC is\nadapting unseen speaker timbres to source audio without quality degradation.\nExisting methods either face timbre leakage or fail to achieve satisfactory\ntimbre similarity and quality in the generated audio. To address these\nchallenges, we propose DAFMSVC, where the self-supervised learning (SSL)\nfeatures from the source audio are replaced with the most similar SSL features\nfrom the target audio to prevent timbre leakage. It also incorporates a dual\ncross-attention mechanism for the adaptive fusion of speaker embeddings,\nmelody, and linguistic content. Additionally, we introduce a flow matching\nmodule for high quality audio generation from the fused features. Experimental\nresults show that DAFMSVC significantly enhances timbre similarity and\nnaturalness, outperforming state-of-the-art methods in both subjective and\nobjective evaluations.", "AI": {"tldr": "\u63d0\u51faDAFMSVC\u89e3\u51b3\u4efb\u610f\u5230\u4efb\u610f\u7684\u6b4c\u5531\u58f0\u97f3\u8f6c\u6362\uff08SVC\uff09\u4e2d\u97f3\u8272\u6cc4\u6f0f\u548c\u97f3\u8d28\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4efb\u610f\u5230\u4efb\u610fSVC\u65b9\u6cd5\u5b58\u5728\u97f3\u8272\u6cc4\u6f0f\u6216\u751f\u6210\u97f3\u9891\u97f3\u8272\u76f8\u4f3c\u5ea6\u548c\u8d28\u91cf\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faDAFMSVC\uff0c\u7528\u76ee\u6807\u97f3\u9891\u6700\u76f8\u4f3c\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u7279\u5f81\u66ff\u6362\u6e90\u97f3\u9891\u7684SSL\u7279\u5f81\uff0c\u5f15\u5165\u53cc\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u8bf4\u8bdd\u4eba\u5d4c\u5165\u3001\u65cb\u5f8b\u548c\u8bed\u8a00\u5185\u5bb9\uff0c\u8fd8\u52a0\u5165\u6d41\u5339\u914d\u6a21\u5757\u7528\u4e8e\u9ad8\u8d28\u91cf\u97f3\u9891\u751f\u6210\u3002", "result": "DAFMSVC\u663e\u8457\u63d0\u9ad8\u4e86\u97f3\u8272\u76f8\u4f3c\u5ea6\u548c\u81ea\u7136\u5ea6\uff0c\u5728\u4e3b\u89c2\u548c\u5ba2\u89c2\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DAFMSVC\u80fd\u6709\u6548\u89e3\u51b3\u4efb\u610f\u5230\u4efb\u610fSVC\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u5347\u8f6c\u6362\u6548\u679c\u3002"}}
{"id": "2508.05989", "pdf": "https://arxiv.org/pdf/2508.05989", "abs": "https://arxiv.org/abs/2508.05989", "authors": ["Younjoon Chung", "Hyoungseob Park", "Patrick Rim", "Xiaoran Zhang", "Jihe He", "Ziyao Zeng", "Safa Cicek", "Byung-Woo Hong", "James S. Duncan", "Alex Wong"], "title": "ETA: Energy-based Test-time Adaptation for Depth Completion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "We propose a method for test-time adaptation of pretrained depth completion\nmodels. Depth completion models, trained on some ``source'' data, often predict\nerroneous outputs when transferred to ``target'' data captured in novel\nenvironmental conditions due to a covariate shift. The crux of our method lies\nin quantifying the likelihood of depth predictions belonging to the source data\ndistribution. The challenge is in the lack of access to out-of-distribution\n(target) data prior to deployment. Hence, rather than making assumptions\nregarding the target distribution, we utilize adversarial perturbations as a\nmechanism to explore the data space. This enables us to train an energy model\nthat scores local regions of depth predictions as in- or out-of-distribution.\nWe update the parameters of pretrained depth completion models at test time to\nminimize energy, effectively aligning test-time predictions to those of the\nsource distribution. We call our method ``Energy-based Test-time Adaptation'',\nor ETA for short. We evaluate our method across three indoor and three outdoor\ndatasets, where ETA improve over the previous state-of-the-art method by an\naverage of 6.94% for outdoors and 10.23% for indoors. Project Page:\nhttps://fuzzythecat.github.io/eta.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9884\u8bad\u7ec3\u6df1\u5ea6\u8865\u5168\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5ETA\uff0c\u901a\u8fc7\u5bf9\u6297\u6270\u52a8\u8bad\u7ec3\u80fd\u91cf\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6bd4\u4e4b\u524d\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u9884\u8bad\u7ec3\u6df1\u5ea6\u8865\u5168\u6a21\u578b\u5728\u8fc1\u79fb\u5230\u65b0\u73af\u5883\u76ee\u6807\u6570\u636e\u65f6\u56e0\u534f\u53d8\u91cf\u504f\u79fb\u4f1a\u4ea7\u751f\u9519\u8bef\u8f93\u51fa\u3002", "method": "\u91cf\u5316\u6df1\u5ea6\u9884\u6d4b\u5c5e\u4e8e\u6e90\u6570\u636e\u5206\u5e03\u7684\u53ef\u80fd\u6027\uff0c\u5229\u7528\u5bf9\u6297\u6270\u52a8\u63a2\u7d22\u6570\u636e\u7a7a\u95f4\uff0c\u8bad\u7ec3\u80fd\u91cf\u6a21\u578b\u5bf9\u6df1\u5ea6\u9884\u6d4b\u533a\u57df\u8fdb\u884c\u5206\u5e03\u5185\u6216\u5916\u8bc4\u5206\uff0c\u5728\u6d4b\u8bd5\u65f6\u66f4\u65b0\u6a21\u578b\u53c2\u6570\u4ee5\u6700\u5c0f\u5316\u80fd\u91cf\u3002", "result": "\u5728\u4e09\u4e2a\u5ba4\u5185\u548c\u4e09\u4e2a\u5ba4\u5916\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cETA\u5728\u5ba4\u5916\u6bd4\u4e4b\u524d\u65b9\u6cd5\u5e73\u5747\u63d0\u53476.94%\uff0c\u5ba4\u5185\u63d0\u534710.23%\u3002", "conclusion": "\u63d0\u51fa\u7684ETA\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u9884\u8bad\u7ec3\u6df1\u5ea6\u8865\u5168\u6a21\u578b\u5728\u65b0\u73af\u5883\u6570\u636e\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2508.06021", "pdf": "https://arxiv.org/pdf/2508.06021", "abs": "https://arxiv.org/abs/2508.06021", "authors": ["Utku Ozbulak", "Michaela Cohrs", "Hristo L. Svilenov", "Joris Vankerschaver", "Wesley De Neve"], "title": "Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Sub-visible particle analysis using flow imaging microscopy combined with\ndeep learning has proven effective in identifying particle types, enabling the\ndistinction of harmless components such as silicone oil from protein particles.\nHowever, the scarcity of available data and severe imbalance between particle\ntypes within datasets remain substantial hurdles when applying multi-class\nclassifiers to such problems, often forcing researchers to rely on less\neffective methods. The aforementioned issue is particularly challenging for\nparticle types that appear unintentionally and in lower numbers, such as\nsilicone oil and air bubbles, as opposed to protein particles, where obtaining\nlarge numbers of images through controlled settings is comparatively\nstraightforward. In this work, we develop a state-of-the-art diffusion model to\naddress data imbalance by generating high-fidelity images that can augment\ntraining datasets, enabling the effective training of multi-class deep neural\nnetworks. We validate this approach by demonstrating that the generated samples\nclosely resemble real particle images in terms of visual quality and structure.\nTo assess the effectiveness of using diffusion-generated images in training\ndatasets, we conduct large-scale experiments on a validation dataset comprising\n500,000 protein particle images and demonstrate that this approach improves\nclassification performance with no negligible downside. Finally, to promote\nopen research and reproducibility, we publicly release both our diffusion\nmodels and the trained multi-class deep neural network classifiers, along with\na straightforward interface for easy integration into future studies, at\nhttps://github.com/utkuozbulak/svp-generative-ai.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u6269\u6563\u6a21\u578b\u89e3\u51b3\u4e9a\u53ef\u89c1\u9897\u7c92\u5206\u6790\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u751f\u6210\u9ad8\u4fdd\u771f\u56fe\u50cf\u589e\u5f3a\u8bad\u7ec3\u96c6\uff0c\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u5e76\u516c\u5f00\u6a21\u578b\u3002", "motivation": "\u591a\u7c7b\u5206\u7c7b\u5668\u5e94\u7528\u4e8e\u4e9a\u53ef\u89c1\u9897\u7c92\u5206\u6790\u65f6\uff0c\u6570\u636e\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u662f\u91cd\u5927\u969c\u788d\uff0c\u5c24\u5176\u5bf9\u4e8e\u6570\u91cf\u5c11\u7684\u9897\u7c92\u7c7b\u578b\u3002", "method": "\u5f00\u53d1\u6269\u6563\u6a21\u578b\u751f\u6210\u9ad8\u4fdd\u771f\u56fe\u50cf\u589e\u5f3a\u8bad\u7ec3\u96c6\uff0c\u8bad\u7ec3\u591a\u7c7b\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u751f\u6210\u6837\u672c\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u7ed3\u6784\u4e0a\u4e0e\u771f\u5b9e\u9897\u7c92\u56fe\u50cf\u76f8\u4f3c\uff0c\u5728\u9a8c\u8bc1\u96c6\u4e0a\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u516c\u5f00\u6a21\u578b\u548c\u5206\u7c7b\u5668\u5229\u4e8e\u5f00\u653e\u7814\u7a76\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2508.05979", "pdf": "https://arxiv.org/pdf/2508.05979", "abs": "https://arxiv.org/abs/2508.05979", "authors": ["Xinming Yang", "Haasil Pujara", "Jun Li"], "title": "Learning by Teaching: Engaging Students as Instructors of Large Language Models in Computer Science Education", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Published at COLM 2025", "summary": "While Large Language Models (LLMs) are often used as virtual tutors in\ncomputer science (CS) education, this approach can foster passive learning and\nover-reliance. This paper presents a novel pedagogical paradigm that inverts\nthis model: students act as instructors who must teach an LLM to solve\nproblems. To facilitate this, we developed strategies for designing questions\nwith engineered knowledge gaps that only a student can bridge, and we introduce\nSocrates, a system for deploying this method with minimal overhead. We\nevaluated our approach in an undergraduate course and found that this\nactive-learning method led to statistically significant improvements in student\nperformance compared to historical cohorts. Our work demonstrates a practical,\ncost-effective framework for using LLMs to deepen student engagement and\nmastery.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5b66\u751f\u6559\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u95ee\u9898\u7684\u6559\u5b66\u8303\u5f0f\uff0c\u5f00\u53d1\u76f8\u5173\u7b56\u7565\u548c\u7cfb\u7edf\uff0c\u7ecf\u8bfe\u7a0b\u8bc4\u4f30\uff0c\u8be5\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u63d0\u5347\u4e86\u5b66\u751f\u6210\u7ee9\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u865a\u62df\u5bfc\u5e08\u6613\u5bfc\u81f4\u88ab\u52a8\u5b66\u4e60\u548c\u8fc7\u5ea6\u4f9d\u8d56\uff0c\u9700\u8981\u65b0\u6559\u5b66\u8303\u5f0f\u3002", "method": "\u5f00\u53d1\u8bbe\u8ba1\u6709\u77e5\u8bc6\u7f3a\u53e3\u95ee\u9898\u7684\u7b56\u7565\uff0c\u5f15\u5165Socrates\u7cfb\u7edf\uff0c\u8ba9\u5b66\u751f\u6559\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u95ee\u9898\u3002", "result": "\u5728\u672c\u79d1\u8bfe\u7a0b\u8bc4\u4f30\u4e2d\uff0c\u8be5\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u4f7f\u5b66\u751f\u6210\u7ee9\u76f8\u6bd4\u5386\u53f2\u540c\u671f\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u662f\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u52a0\u6df1\u5b66\u751f\u53c2\u4e0e\u5ea6\u548c\u638c\u63e1\u5ea6\u7684\u5b9e\u7528\u3001\u7ecf\u6d4e\u6846\u67b6\u3002"}}
{"id": "2508.06030", "pdf": "https://arxiv.org/pdf/2508.06030", "abs": "https://arxiv.org/abs/2508.06030", "authors": ["Kartik Sharma", "Yiqiao Jin", "Rakshit Trivedi", "Srijan Kumar"], "title": "Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) acquire knowledge across diverse domains such as\nscience, history, and geography encountered during generative pre-training.\nHowever, due to their stochasticity, it is difficult to predict what LLMs have\nacquired. Prior work has developed different ways to probe this knowledge by\ninvestigating the hidden representations, crafting specific task prompts,\ncurating representative samples, and estimating their uncertainty. However,\nthese methods require making forward passes through the underlying model to\nprobe the LLM's knowledge about a specific fact, making them computationally\nexpensive and time-consuming. To bridge this gap, we propose $\\textbf{PEEK}$ or\n$\\textbf{P}$roxy $\\textbf{E}$mbeddings to $\\textbf{E}$stimate\n$\\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models\nthat effectively encode factual knowledge as text or graphs as proxies for\nLLMs. First, we identify a training set of facts known by LLMs through various\nprobing strategies and then adapt embedding models to predict the LLM outputs\nwith a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived\ndatasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict\nLLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find\nthat sentence embedding models are more suitable than graph embeddings to\npredict LLM knowledge, shedding light on the underlying representation of the\nfactual landscape. Thus, we believe that knowledge-adapted embeddings can be\nused to identify knowledge gaps in LLMs at scale and can provide deeper\ninsights into LLMs' internal inductive bias. The code and data are made\navailable at https://github.com/claws-lab/peek.", "AI": {"tldr": "\u63d0\u51faPEEK\u65b9\u6cd5\u5229\u7528\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u4f30\u8ba1\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\uff0c\u8bc4\u4f30\u663e\u793a\u53ef\u8fbe90%\u51c6\u786e\u7387\uff0c\u53d1\u73b0\u53e5\u5d4c\u5165\u6a21\u578b\u66f4\u5408\u9002\uff0c\u4ee3\u7801\u6570\u636e\u516c\u5f00\u3002", "motivation": "\u73b0\u6709\u63a2\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7684\u65b9\u6cd5\u9700\u5bf9\u57fa\u7840\u6a21\u578b\u524d\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\u3002", "method": "\u901a\u8fc7\u591a\u79cd\u63a2\u6d4b\u7b56\u7565\u786e\u5b9a\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u77e5\u4e8b\u5b9e\u8bad\u7ec3\u96c6\uff0c\u7528\u7ebf\u6027\u89e3\u7801\u5c42\u8ba9\u5d4c\u5165\u6a21\u578b\u9884\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u57283\u4e2a\u7ef4\u57fa\u6570\u636e\u96c6\u30014\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c7\u4e2a\u5d4c\u5165\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u5d4c\u5165\u6a21\u578b\u9884\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u51c6\u786e\u7387\u8fbe90%\uff0c\u53e5\u5d4c\u5165\u6a21\u578b\u66f4\u9002\u5408\u9884\u6d4b\u3002", "conclusion": "\u77e5\u8bc6\u9002\u914d\u7684\u5d4c\u5165\u6a21\u578b\u53ef\u5927\u89c4\u6a21\u8bc6\u522b\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7f3a\u53e3\uff0c\u6df1\u5165\u4e86\u89e3\u5176\u5185\u90e8\u5f52\u7eb3\u504f\u5dee\u3002"}}
{"id": "2508.06052", "pdf": "https://arxiv.org/pdf/2508.06052", "abs": "https://arxiv.org/abs/2508.06052", "authors": ["Haruto Nakashima", "Siddhartha Ganguly", "Kenji Kashima"], "title": "Data-Driven Density Steering via the Gromov-Wasserstein Optimal Transport Distance", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "comment": "To be presented at the IEEE CDC, Rio de Janeiro, 2025", "summary": "We tackle the data-driven chance-constrained density steering problem using\nthe Gromov-Wasserstein metric. The underlying dynamical system is an unknown\nlinear controlled recursion, with the assumption that sufficiently rich\ninput-output data from pre-operational experiments are available. The initial\nstate is modeled as a Gaussian mixture, while the terminal state is required to\nmatch a specified Gaussian distribution. We reformulate the resulting optimal\ncontrol problem as a difference-of-convex program and show that it can be\nefficiently and tractably solved using the DC algorithm. Numerical results\nvalidate our approach through various data-driven schemes.", "AI": {"tldr": "\u4f7f\u7528Gromov - Wasserstein\u5ea6\u91cf\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u673a\u4f1a\u7ea6\u675f\u5bc6\u5ea6\u5bfc\u5411\u95ee\u9898\uff0c\u5c06\u6700\u4f18\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u5dee\u89c4\u5212\u5e76\u7528DC\u7b97\u6cd5\u6c42\u89e3\uff0c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u7684\u673a\u4f1a\u7ea6\u675f\u5bc6\u5ea6\u5bfc\u5411\u95ee\u9898\uff0c\u5728\u7cfb\u7edf\u672a\u77e5\u60c5\u51b5\u4e0b\u5229\u7528\u8f93\u5165\u8f93\u51fa\u6570\u636e\u8fdb\u884c\u63a7\u5236\u3002", "method": "\u7528Gromov - Wasserstein\u5ea6\u91cf\uff0c\u5c06\u6700\u4f18\u63a7\u5236\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u5dee\u89c4\u5212\uff0c\u4f7f\u7528DC\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "\u901a\u8fc7\u5404\u79cd\u6570\u636e\u9a71\u52a8\u65b9\u6848\u7684\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6570\u636e\u9a71\u52a8\u7684\u673a\u4f1a\u7ea6\u675f\u5bc6\u5ea6\u5bfc\u5411\u95ee\u9898\u3002"}}
{"id": "2508.05991", "pdf": "https://arxiv.org/pdf/2508.05991", "abs": "https://arxiv.org/abs/2508.05991", "authors": ["Juewen Hu", "Yexin Li", "Jiulin Li", "Shuo Chen", "Pring Wong"], "title": "ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": null, "summary": "Emotion recognition plays a vital role in enhancing human-computer\ninteraction. In this study, we tackle the MER-SEMI challenge of the MER2025\ncompetition by proposing a novel multimodal emotion recognition framework. To\naddress the issue of data scarcity, we leverage large-scale pre-trained models\nto extract informative features from visual, audio, and textual modalities.\nSpecifically, for the visual modality, we design a dual-branch visual encoder\nthat captures both global frame-level features and localized facial\nrepresentations. For the textual modality, we introduce a context-enriched\nmethod that employs large language models to enrich emotional cues within the\ninput text. To effectively integrate these multimodal features, we propose a\nfusion strategy comprising two key components, i.e., self-attention mechanisms\nfor dynamic modality weighting, and residual connections to preserve original\nrepresentations. Beyond architectural design, we further refine noisy labels in\nthe training set by a multi-source labeling strategy. Our approach achieves a\nsubstantial performance improvement over the official baseline on the\nMER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to\n78.63%, thereby validating the effectiveness of the proposed framework.", "AI": {"tldr": "\u63d0\u51fa\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6846\u67b6\u5e94\u5bf9MER - SEMI\u6311\u6218\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u53d6\u7279\u5f81\uff0c\u8bbe\u8ba1\u878d\u5408\u7b56\u7565\u548c\u591a\u6e90\u6807\u6ce8\u7b56\u7565\uff0c\u5728\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u60c5\u611f\u8bc6\u522b\u5bf9\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u5f88\u91cd\u8981\uff0c\u89e3\u51b3MER2025\u7ade\u8d5b\u7684MER - SEMI\u6311\u6218\u53ca\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u4ece\u591a\u6a21\u6001\u63d0\u53d6\u7279\u5f81\uff0c\u8bbe\u8ba1\u53cc\u5206\u652f\u89c6\u89c9\u7f16\u7801\u5668\u3001\u4e0a\u4e0b\u6587\u4e30\u5bcc\u65b9\u6cd5\uff0c\u63d0\u51fa\u542b\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u6b8b\u5dee\u8fde\u63a5\u7684\u878d\u5408\u7b56\u7565\uff0c\u7528\u591a\u6e90\u6807\u6ce8\u7b56\u7565\u7cbe\u70bc\u8bad\u7ec3\u96c6\u566a\u58f0\u6807\u7b7e\u3002", "result": "\u5728MER2025 - SEMI\u6570\u636e\u96c6\u4e0a\u52a0\u6743F - score\u8fbe87.49%\uff0c\u8fdc\u8d85\u5b98\u65b9\u57fa\u7ebf\u768478.63%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6846\u67b6\u6709\u6548\u3002"}}
{"id": "2508.06057", "pdf": "https://arxiv.org/pdf/2508.06057", "abs": "https://arxiv.org/abs/2508.06057", "authors": ["Mojtaba Valipour", "Kelly Zheng", "James Lowman", "Spencer Szabados", "Mike Gartner", "Bobby Braswell"], "title": "AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted in IGARSS 2025!", "summary": "Artificial General Intelligence (AGI) is closer than ever to becoming a\nreality, sparking widespread enthusiasm in the research community to collect\nand work with various modalities, including text, image, video, and audio.\nDespite recent efforts, satellite spectral imagery, as an additional modality,\nhas yet to receive the attention it deserves. This area presents unique\nchallenges, but also holds great promise in advancing the capabilities of AGI\nin understanding the natural world. In this paper, we argue why Earth\nObservation data is useful for an intelligent model, and then we review\nexisting benchmarks and highlight their limitations in evaluating the\ngeneralization ability of foundation models in this domain. This paper\nemphasizes the need for a more comprehensive benchmark to evaluate earth\nobservation models. To facilitate this, we propose a comprehensive set of tasks\nthat a benchmark should encompass to effectively assess a model's ability to\nunderstand and interact with Earth observation data.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u536b\u661f\u5149\u8c31\u56fe\u50cf\u4f5c\u4e3a\u65b0\u6a21\u6001\u5bf9AGI\u53d1\u5c55\u6709\u91cd\u8981\u610f\u4e49\uff0c\u56de\u987e\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u7684\u5c40\u9650\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5168\u9762\u7684\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u57fa\u51c6\u5e94\u6db5\u76d6\u7684\u4efb\u52a1\u3002", "motivation": "\u536b\u661f\u5149\u8c31\u56fe\u50cf\u4f5c\u4e3a\u989d\u5916\u6a21\u6001\u672a\u5f97\u5230\u5e94\u6709\u7684\u5173\u6ce8\uff0c\u4f46\u5176\u5bf9\u63d0\u5347AGI\u7406\u89e3\u81ea\u7136\u4e16\u754c\u7684\u80fd\u529b\u6709\u5f88\u5927\u6f5c\u529b\u3002", "method": "\u8bba\u8bc1\u5730\u7403\u89c2\u6d4b\u6570\u636e\u5bf9\u667a\u80fd\u6a21\u578b\u7684\u6709\u7528\u6027\uff0c\u56de\u987e\u73b0\u6709\u57fa\u51c6\u5e76\u6307\u51fa\u5176\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e00\u5957\u5168\u9762\u7684\u4efb\u52a1\u3002", "result": "\u660e\u786e\u73b0\u6709\u57fa\u51c6\u5728\u8bc4\u4f30\u8be5\u9886\u57df\u57fa\u7840\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u4e00\u4e2a\u66f4\u5168\u9762\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u5730\u7403\u89c2\u6d4b\u6a21\u578b\u3002"}}
{"id": "2508.06000", "pdf": "https://arxiv.org/pdf/2508.06000", "abs": "https://arxiv.org/abs/2508.06000", "authors": ["Wei Xiang", "Ziyue Lei", "Haoyuan Che", "Fangyuan Ye", "Xueting Wu", "Lingyun Sun"], "title": "Hand by Hand: LLM Driving EMS Assistant for Operational Skill Learning", "categories": ["cs.HC", "cs.AI"], "comment": "Accepted by IJCAI 2025", "summary": "Operational skill learning, inherently physical and reliant on hands-on\npractice and kinesthetic feedback, has yet to be effectively replicated in\nlarge language model (LLM)-supported training. Current LLM training assistants\nprimarily generate customized textual feedback, neglecting the crucial\nkinesthetic modality. This gap derives from the textual and uncertain nature of\nLLMs, compounded by concerns on user acceptance of LLM driven body control. To\nbridge this gap and realize the potential of collaborative human-LLM action,\nthis work explores human experience of LLM driven kinesthetic assistance.\nSpecifically, we introduced an \"Align-Analyze-Adjust\" strategy and developed\nFlightAxis, a tool that integrates LLM with Electrical Muscle Stimulation (EMS)\nfor flight skill acquisition, a representative operational skill domain.\nFlightAxis learns flight skills from manuals and guides forearm movements\nduring simulated flight tasks. Our results demonstrate high user acceptance of\nLLM-mediated body control and significantly reduced task completion times.\nCrucially, trainees reported that this kinesthetic assistance enhanced their\nawareness of operation flaws and fostered increased engagement in the training\nprocess, rather than relieving perceived load. This work demonstrated the\npotential of kinesthetic LLM training in operational skill acquisition.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u52a8\u89c9\u8f85\u52a9\u5728\u64cd\u4f5c\u6280\u80fd\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u5f00\u53d1\u4e86FlightAxis\u5de5\u5177\uff0c\u7ed3\u679c\u663e\u793a\u7528\u6237\u63a5\u53d7\u5ea6\u9ad8\uff0c\u53ef\u63d0\u5347\u64cd\u4f5c\u6280\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u652f\u6301\u7684\u8bad\u7ec3\u672a\u80fd\u6709\u6548\u590d\u5236\u64cd\u4f5c\u6280\u80fd\u5b66\u4e60\u4e2d\u7684\u52a8\u89c9\u53cd\u9988\uff0c\u5b58\u5728\u6587\u672c\u6027\u548c\u7528\u6237\u63a5\u53d7\u5ea6\u7b49\u95ee\u9898\uff0c\u9700\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u52a8\u89c9\u8f85\u52a9\u3002", "method": "\u5f15\u5165\u201c\u5bf9\u9f50 - \u5206\u6790 - \u8c03\u6574\u201d\u7b56\u7565\uff0c\u5f00\u53d1\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7535\u808c\u8089\u523a\u6fc0\u7684FlightAxis\u5de5\u5177\u7528\u4e8e\u98de\u884c\u6280\u80fd\u5b66\u4e60\u3002", "result": "\u7528\u6237\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4ecb\u5bfc\u7684\u8eab\u4f53\u63a7\u5236\u63a5\u53d7\u5ea6\u9ad8\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u663e\u8457\u51cf\u5c11\uff0c\u589e\u5f3a\u4e86\u5bf9\u64cd\u4f5c\u7f3a\u9677\u7684\u610f\u8bc6\u548c\u8bad\u7ec3\u53c2\u4e0e\u5ea6\u3002", "conclusion": "\u52a8\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u5728\u64cd\u4f5c\u6280\u80fd\u83b7\u53d6\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2508.06016", "pdf": "https://arxiv.org/pdf/2508.06016", "abs": "https://arxiv.org/abs/2508.06016", "authors": ["Sagar Gandhi", "Vishal Gandhi"], "title": "Crisp Attention: Regularizing Transformers via Structured Sparsity", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The quadratic computational cost of the self-attention mechanism is a primary\nchallenge in scaling Transformer models. While attention sparsity is widely\nstudied as a technique to improve computational efficiency, it is almost\nuniversally assumed to come at the cost of model accuracy. In this paper, we\nreport a surprising counter-example to this common wisdom. By introducing\nstructured, post-hoc sparsity to the attention mechanism of a DistilBERT model\nduring fine-tuning on the SST-2 sentiment analysis task, we find that model\naccuracy improves significantly. Our model with 80\\% attention sparsity\nachieves a validation accuracy of 91.59\\%, a 0.97\\% absolute improvement over\nthe dense baseline. We hypothesize that this phenomenon is due to sparsity\nacting as a powerful implicit regularizer, preventing the model from\noverfitting by forcing it to make predictions with a more constrained and\nrobust set of features. Our work recasts attention sparsity not just as a tool\nfor computational efficiency, but as a potential method for improving the\ngeneralization and performance of Transformer models.", "AI": {"tldr": "\u672c\u6587\u5728SST - 2\u60c5\u611f\u5206\u6790\u4efb\u52a1\u5fae\u8c03DistilBERT\u6a21\u578b\u65f6\u5f15\u5165\u540e\u9a8c\u7a00\u758f\u6027\uff0c\u53d1\u73b080%\u6ce8\u610f\u529b\u7a00\u758f\u5ea6\u6a21\u578b\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff0c\u6311\u6218\u4e86\u7a00\u758f\u6027\u4f1a\u964d\u4f4e\u51c6\u786e\u7387\u7684\u89c2\u70b9\u3002", "motivation": "\u89e3\u51b3\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e8c\u6b21\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u6311\u6218\u6ce8\u610f\u529b\u7a00\u758f\u6027\u727a\u7272\u6a21\u578b\u51c6\u786e\u7387\u7684\u666e\u904d\u8ba4\u77e5\u3002", "method": "\u5728SST - 2\u60c5\u611f\u5206\u6790\u4efb\u52a1\u5fae\u8c03DistilBERT\u6a21\u578b\u65f6\u5f15\u5165\u7ed3\u6784\u5316\u540e\u9a8c\u7a00\u758f\u6027\u3002", "result": "80%\u6ce8\u610f\u529b\u7a00\u758f\u5ea6\u7684\u6a21\u578b\u9a8c\u8bc1\u51c6\u786e\u7387\u8fbe91.59%\uff0c\u6bd4\u5bc6\u96c6\u57fa\u7ebf\u63d0\u9ad80.97%\u3002", "conclusion": "\u6ce8\u610f\u529b\u7a00\u758f\u6027\u4e0d\u4ec5\u53ef\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u8fd8\u80fd\u6539\u5584Transformer\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u3002"}}
{"id": "2508.06026", "pdf": "https://arxiv.org/pdf/2508.06026", "abs": "https://arxiv.org/abs/2508.06026", "authors": ["Yidong Wang", "Xin Wang", "Cunxiang Wang", "Junfeng Fang", "Qiufeng Wang", "Jianing Chu", "Xuran Meng", "Shuxun Yang", "Libo Qin", "Yue Zhang", "Wei Ye", "Shikun Zhang"], "title": "Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 5 figures", "summary": "Self-Rewarding Language Models propose an architecture in which the Large\nLanguage Models(LLMs) both generates responses and evaluates its own outputs\nvia LLM-as-a-Judge prompting, dynamically improving its generative capabilities\nthrough iterative Direct Preference Optimization (DPO). However, our analysis\nreveals a critical limitation in existing Self-Rewarding paradigms: the\nsynchronized improvement of chosen and rejected responses progressively narrows\nthe representational difference between contrasting samples, undermining\neffective preference learning. We propose \\textbf{Temporal Self-Rewarding\nLanguage Models} that strategically coordinate past, present, and future model\ngenerations to sustain learning signals. Our dual-phase framework introduces:\n(1) \\textit{Anchored Rejection} - fixing rejected responses using the past\ninitial model's outputs and (2) \\textit{Future-Guided Chosen} - dynamically\ncurating chosen samples using next-generation model predictions. Extensive\nexperiments across three model families (Llama, Qwen, Mistral) and different\nmodel sizes (Llama3B/8B/70B) demonstrate significant improvements when trained\nwith our method compared to Self-Rewarding using same computation resources.\nFor example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our\nmethod, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our\nmethod also demonstrates superior out-of-distribution generalization across\nmathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code\ngeneration (HumanEval) tasks, even though we do not specifically collect such\ntraining data.", "AI": {"tldr": "\u63d0\u51fa\u65f6\u95f4\u81ea\u5956\u52b1\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u81ea\u5956\u52b1\u8303\u5f0f\u7f3a\u9677\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6548\u679c\u597d\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u3002", "motivation": "\u73b0\u6709\u81ea\u5956\u52b1\u8303\u5f0f\u5b58\u5728\u6240\u9009\u548c\u62d2\u7edd\u54cd\u5e94\u540c\u6b65\u6539\u8fdb\uff0c\u7f29\u5c0f\u6837\u672c\u8868\u5f81\u5dee\u5f02\uff0c\u5f71\u54cd\u504f\u597d\u5b66\u4e60\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53cc\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ec\u56fa\u5b9a\u8fc7\u53bb\u521d\u59cb\u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u62d2\u7edd\u54cd\u5e94\u7684\u201c\u951a\u5b9a\u62d2\u7edd\u201d\u548c\u7528\u4e0b\u4e00\u4ee3\u6a21\u578b\u9884\u6d4b\u52a8\u6001\u7b56\u5212\u6240\u9009\u6837\u672c\u7684\u201c\u672a\u6765\u5f15\u5bfc\u9009\u62e9\u201d\u3002", "result": "\u5728\u4e09\u4e2a\u6a21\u578b\u5bb6\u65cf\u548c\u4e0d\u540c\u5927\u5c0f\u6a21\u578b\u4e0a\u5b9e\u9a8c\uff0c\u76f8\u6bd4\u81ea\u5956\u52b1\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\uff0c\u5982Llama3.1 - 8B\u5728AlpacaEval 2.0\u80dc\u7387\u63d0\u9ad8\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u76f8\u540c\u8ba1\u7b97\u8d44\u6e90\u4e0b\u4f18\u4e8e\u81ea\u5956\u52b1\u65b9\u6cd5\uff0c\u4e14\u6709\u826f\u597d\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.06118", "pdf": "https://arxiv.org/pdf/2508.06118", "abs": "https://arxiv.org/abs/2508.06118", "authors": ["Daniil Vlasenko", "Vadim Ushakov", "Alexey Zaikin", "Denis Zakharov"], "title": "Ensemble-Based Graph Representation of fMRI Data for Cognitive Brain State Classification", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Understanding and classifying human cognitive brain states based on\nneuroimaging data remains one of the foremost and most challenging problems in\nneuroscience, owing to the high dimensionality and intrinsic noise of the\nsignals. In this work, we propose an ensemble-based graph representation method\nof functional magnetic resonance imaging (fMRI) data for the task of binary\nbrain-state classification. Our method builds the graph by leveraging multiple\nbase machine-learning models: each edge weight reflects the difference in\nposterior probabilities between two cognitive states, yielding values in the\nrange [-1, 1] that encode confidence in a given state. We applied this approach\nto seven cognitive tasks from the Human Connectome Project (HCP 1200 Subject\nRelease), including working memory, gambling, motor activity, language, social\ncognition, relational processing, and emotion processing. Using only the mean\nincident edge weights of the graphs as features, a simple logistic-regression\nclassifier achieved average accuracies from 97.07% to 99.74%. We also compared\nour ensemble graphs with classical correlation-based graphs in a classification\ntask with a graph neural network (GNN). In all experiments, the highest\nclassification accuracy was obtained with ensemble graphs. These results\ndemonstrate that ensemble graphs convey richer topological information and\nenhance brain-state discrimination. Our approach preserves edge-level\ninterpretability of the fMRI graph representation, is adaptable to multiclass\nand regression tasks, and can be extended to other neuroimaging modalities and\npathological-state classification.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u96c6\u6210\u7684\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf\uff08fMRI\uff09\u6570\u636e\u56fe\u8868\u793a\u65b9\u6cd5\u7528\u4e8e\u4e8c\u5143\u8111\u72b6\u6001\u5206\u7c7b\uff0c\u5728\u591a\u4e2a\u8ba4\u77e5\u4efb\u52a1\u4e2d\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\uff0c\u8bc1\u660e\u96c6\u6210\u56fe\u6709\u4f18\u52bf\u3002", "motivation": "\u7531\u4e8e\u795e\u7ecf\u5f71\u50cf\u4fe1\u53f7\u7684\u9ad8\u7ef4\u6027\u548c\u56fa\u6709\u566a\u58f0\uff0c\u7406\u89e3\u548c\u5206\u7c7b\u4eba\u7c7b\u8ba4\u77e5\u8111\u72b6\u6001\u662f\u795e\u7ecf\u79d1\u5b66\u7684\u6311\u6218\u95ee\u9898\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u591a\u4e2a\u57fa\u7840\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6784\u5efa\u56fe\uff0c\u8fb9\u6743\u91cd\u53cd\u6620\u4e24\u79cd\u8ba4\u77e5\u72b6\u6001\u540e\u9a8c\u6982\u7387\u5dee\u5f02\uff1b\u7528\u56fe\u7684\u5e73\u5747\u5165\u5c04\u8fb9\u6743\u91cd\u4f5c\u4e3a\u7279\u5f81\uff0c\u4f7f\u7528\u7b80\u5355\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\uff1b\u4e0e\u7ecf\u5178\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u56fe\u5728\u56fe\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u4efb\u52a1\u4e2d\u6bd4\u8f83\u3002", "result": "\u7b80\u5355\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\u5e73\u5747\u51c6\u786e\u7387\u572897.07% - 99.74%\uff1b\u6240\u6709\u5b9e\u9a8c\u4e2d\u96c6\u6210\u56fe\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad8\u3002", "conclusion": "\u96c6\u6210\u56fe\u4f20\u8fbe\u66f4\u4e30\u5bcc\u62d3\u6251\u4fe1\u606f\uff0c\u589e\u5f3a\u8111\u72b6\u6001\u533a\u5206\u80fd\u529b\uff1b\u65b9\u6cd5\u4fdd\u7559\u4e86fMRI\u56fe\u8868\u793a\u7684\u8fb9\u7ea7\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u591a\u7c7b\u548c\u56de\u5f52\u4efb\u52a1\uff0c\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u795e\u7ecf\u5f71\u50cf\u6a21\u5f0f\u548c\u75c5\u7406\u72b6\u6001\u5206\u7c7b\u3002"}}
{"id": "2508.06038", "pdf": "https://arxiv.org/pdf/2508.06038", "abs": "https://arxiv.org/abs/2508.06038", "authors": ["Huanyu Wang", "Jushi Kai", "Haoli Bai", "Lu Hou", "Bo Jiang", "Ziwei He", "Zhouhan Lin"], "title": "Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "12 pages, 4 figures", "summary": "Vision-Language Models (VLMs) typically replace the predefined image\nplaceholder token (<image>) in textual instructions with visual features from\nan image encoder, forming the input to a backbone Large Language Model (LLM).\nHowever, the large number of vision tokens significantly increases the context\nlength, leading to high computational overhead and inference latency. While\nprevious efforts mitigate this by selecting only important visual features or\nleveraging learnable queries to reduce token count, they often compromise\nperformance or introduce substantial extra costs. In response, we propose\nFourier-VLM, a simple yet efficient method that compresses visual\nrepresentations in the frequency domain. Our approach is motivated by the\nobservation that vision features output from the vision encoder exhibit\nconcentrated energy in low-frequency components. Leveraging this, we apply a\nlow-pass filter to the vision features using a two-dimentional Discrete Cosine\nTransform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier\nTransform (FFT) operator with a time complexity of $\\mathcal{O}(n\\log n)$,\nminimizing the extra computational cost while introducing no additional\nparameters. Extensive experiments across various image-based benchmarks\ndemonstrate that Fourier-VLM achieves competitive performance with strong\ngeneralizability across both LLaVA and Qwen-VL architectures. Crucially, it\nreduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%\ncompared to LLaVA-v1.5, highlighting the superior efficiency and practicality.", "AI": {"tldr": "\u63d0\u51faFourier - VLM\u65b9\u6cd5\u5728\u9891\u57df\u538b\u7f29\u89c6\u89c9\u8868\u793a\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u548c\u63a8\u7406\u5ef6\u8fdf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9ad8\u6548\u6027\u548c\u6cdb\u5316\u6027\u3002", "motivation": "\u73b0\u6709Vision - Language Models\u56e0\u5927\u91cf\u89c6\u89c9\u4ee4\u724c\u589e\u52a0\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5bfc\u81f4\u9ad8\u8ba1\u7b97\u5f00\u9500\u548c\u63a8\u7406\u5ef6\u8fdf\uff0c\u4ee5\u5f80\u65b9\u6cd5\u6709\u6027\u80fd\u6298\u635f\u6216\u989d\u5916\u6210\u672c\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u89c6\u89c9\u7f16\u7801\u5668\u8f93\u51fa\u7684\u89c6\u89c9\u7279\u5f81\u5728\u4f4e\u9891\u5206\u91cf\u80fd\u91cf\u96c6\u4e2d\u7684\u89c2\u5bdf\uff0c\u4f7f\u7528\u4e8c\u7ef4\u79bb\u6563\u4f59\u5f26\u53d8\u6362\uff08DCT\uff09\u5bf9\u89c6\u89c9\u7279\u5f81\u5e94\u7528\u4f4e\u901a\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\u7b97\u5b50\u9ad8\u6548\u8ba1\u7b97DCT\u3002", "result": "Fourier - VLM\u5728\u5404\u79cd\u57fa\u4e8e\u56fe\u50cf\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u5728LLaVA\u548cQwen - VL\u67b6\u6784\u4e0a\u6709\u5f3a\u6cdb\u5316\u6027\uff0c\u76f8\u6bd4LLaVA - v1.5\u51cf\u5c11\u63a8\u7406FLOPs\u8fbe83.8%\uff0c\u63d0\u5347\u751f\u6210\u901f\u5ea631.2%\u3002", "conclusion": "Fourier - VLM\u65b9\u6cd5\u7b80\u5355\u9ad8\u6548\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.06131", "pdf": "https://arxiv.org/pdf/2508.06131", "abs": "https://arxiv.org/abs/2508.06131", "authors": ["Philip Anton Hernicht", "Alona Sakhnenko", "Corey O'Meara", "Giorgio Cortiana", "Jeanette Miriam Lorenz"], "title": "Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications", "categories": ["quant-ph", "cs.LG"], "comment": "9 pages, 8 figures", "summary": "Quantum machine learning (QML) presents potential for early industrial\nadoption, yet limited access to quantum hardware remains a significant\nbottleneck for deployment of QML solutions. This work explores the use of\nclassical surrogates to bypass this restriction, which is a technique that\nallows to build a lightweight classical representation of a (trained) quantum\nmodel, enabling to perform inference on entirely classical devices. We reveal\nprohibiting high computational demand associated with previously proposed\nmethods for generating classical surrogates from quantum models, and propose an\nalternative pipeline enabling generation of classical surrogates at a larger\nscale than was previously possible. Previous methods required at least a\nhigh-performance computing (HPC) system for quantum models of below industrial\nscale (ca. 20 qubits), which raises questions about its practicality. We\ngreatly minimize the redundancies of the previous approach, utilizing only a\nminute fraction of the resources previously needed. We demonstrate the\neffectiveness of our method on a real-world energy demand forecasting problem,\nconducting rigorous testing of performance and computation demand in both\nsimulations and on quantum hardware. Our results indicate that our method\nachieves high accuracy on the testing dataset while its computational resource\nrequirements scale linearly rather than exponentially. This work presents a\nlightweight approach to transform quantum solutions into classically deployable\nversions, facilitating faster integration of quantum technology in industrial\nsettings. Furthermore, it can serve as a powerful research tool in search\npractical quantum advantage in an empirical setup.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u7ecf\u5178\u66ff\u4ee3\u6a21\u578b\u7ed5\u8fc7\u91cf\u5b50\u786c\u4ef6\u8bbf\u95ee\u9650\u5236\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u751f\u6210\u7ecf\u5178\u66ff\u4ee3\u6a21\u578b\uff0c\u5728\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u95ee\u9898\u4e0a\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u7ebf\u6027\u589e\u957f\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u65e9\u671f\u5de5\u4e1a\u5e94\u7528\u53d7\u9650\u4e8e\u91cf\u5b50\u786c\u4ef6\u8bbf\u95ee\uff0c\u9700\u89e3\u51b3\u8be5\u9650\u5236\u4ee5\u63a8\u52a8\u5176\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u751f\u6210\u7ecf\u5178\u66ff\u4ee3\u6a21\u578b\u7684\u7ba1\u9053\uff0c\u51cf\u5c11\u5148\u524d\u65b9\u6cd5\u7684\u5197\u4f59\uff0c\u5229\u7528\u66f4\u5c11\u8d44\u6e90\u3002", "result": "\u5728\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u95ee\u9898\u4e0a\uff0c\u65b9\u6cd5\u5728\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u9ad8\uff0c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u7ebf\u6027\u800c\u975e\u6307\u6570\u589e\u957f\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u53ef\u5c06\u91cf\u5b50\u89e3\u51b3\u65b9\u6848\u8f6c\u5316\u4e3a\u7ecf\u5178\u53ef\u90e8\u7f72\u7248\u672c\uff0c\u4fc3\u8fdb\u91cf\u5b50\u6280\u672f\u5728\u5de5\u4e1a\u73af\u5883\u7684\u96c6\u6210\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u5bfb\u627e\u5b9e\u9645\u91cf\u5b50\u4f18\u52bf\u7684\u7814\u7a76\u5de5\u5177\u3002"}}
{"id": "2508.06133", "pdf": "https://arxiv.org/pdf/2508.06133", "abs": "https://arxiv.org/abs/2508.06133", "authors": ["Meixuan Wang", "Yinyu Ye", "Zijie Zhou"], "title": "LLM Serving Optimization with Variable Prefill and Decode Lengths", "categories": ["math.OC", "cs.AI", "cs.LG"], "comment": null, "summary": "We study the problem of serving LLM (Large Language Model) requests where\neach request has heterogeneous prefill and decode lengths. In LLM serving, the\nprefill length corresponds to the input prompt length, which determines the\ninitial memory usage in the KV cache. The decode length refers to the number of\noutput tokens generated sequentially, with each additional token increasing the\nKV cache memory usage by one unit. Given a set of n requests, our goal is to\nschedule and process them to minimize the total completion time. We show that\nthis problem is NP-hard due to the interplay of batching, placement\nconstraints, precedence relationships, and linearly increasing memory usage. We\nthen analyze commonly used scheduling strategies in practice, such as\nFirst-Come-First-Serve (FCFS) and Shortest-First (SF), and prove that their\ncompetitive ratios scale up sublinearly with the memory limit-a significant\ndrawback in real-world settings where memory demand is large. To address this,\nwe propose a novel algorithm based on a new selection metric that efficiently\nforms batches over time. We prove that this algorithm achieves a constant\ncompetitive ratio. Finally, we develop and evaluate a few algorithm variants\ninspired by this approach, including dynamic programming variants, local search\nmethods, and an LP-based scheduler, demonstrating through comprehensive\nsimulations that they outperform standard baselines while maintaining\ncomputational efficiency.", "AI": {"tldr": "\u7814\u7a76LLM\u8bf7\u6c42\u670d\u52a1\u95ee\u9898\uff0c\u8bc1\u660e\u95ee\u9898NP\u96be\uff0c\u5206\u6790\u5e38\u7528\u7b56\u7565\u7f3a\u9677\uff0c\u63d0\u51fa\u65b0\u7b97\u6cd5\u5e76\u8bc1\u660e\u6709\u5e38\u6570\u7ade\u4e89\u6bd4\uff0c\u5f00\u53d1\u53d8\u4f53\u5e76\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5177\u6709\u5f02\u6784\u9884\u586b\u5145\u548c\u89e3\u7801\u957f\u5ea6\u7684LLM\u8bf7\u6c42\u670d\u52a1\u95ee\u9898\uff0c\u6700\u5c0f\u5316\u603b\u5b8c\u6210\u65f6\u95f4\u3002", "method": "\u5206\u6790\u5e38\u7528\u8c03\u5ea6\u7b56\u7565\uff0c\u63d0\u51fa\u57fa\u4e8e\u65b0\u9009\u62e9\u6307\u6807\u7684\u7b97\u6cd5\uff0c\u5f00\u53d1\u52a8\u6001\u89c4\u5212\u3001\u5c40\u90e8\u641c\u7d22\u3001\u57fa\u4e8eLP\u7684\u8c03\u5ea6\u5668\u7b49\u53d8\u4f53\u3002", "result": "\u65b0\u7b97\u6cd5\u6709\u5e38\u6570\u7ade\u4e89\u6bd4\uff0c\u53d8\u4f53\u5728\u7efc\u5408\u6a21\u62df\u4e2d\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u4e14\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u53d8\u4f53\u53ef\u6709\u6548\u89e3\u51b3LLM\u8bf7\u6c42\u670d\u52a1\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u6709\u4f18\u52bf\u3002"}}
{"id": "2508.06046", "pdf": "https://arxiv.org/pdf/2508.06046", "abs": "https://arxiv.org/abs/2508.06046", "authors": ["Xinda Wang", "Zhengxu Hou", "Yangshijie Zhang", "Bingren Yan", "Zhibo Yang", "Xingsheng Zhang", "Luxi Xing", "Qiang Zhou", "Chen Zhang"], "title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Although the effectiveness of Large Language Models (LLMs) as judges\n(LLM-as-a-judge) has been validated, their performance remains limited in\nopen-ended tasks, particularly in story evaluation. Accurate story evaluation\nis crucial not only for assisting human quality judgment but also for providing\nkey signals to guide story generation. However, existing methods face a\ndilemma: prompt engineering for closed-source models suffers from poor\nadaptability, while fine-tuning approaches for open-source models lack the\nrigorous reasoning capabilities essential for story evaluation. To address\nthis, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.\nGrounded in pairwise comparison, the framework first self-synthesizes\nscore-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To\nensure data quality, these raw CoTs undergo a self-filtering process, utilizing\nmulti-agents to guarantee their logical rigor and robustness. Finally, the\nevaluator trained on the refined data is deployed as a reward model to guide\nthe story generation task. Experimental results demonstrate that our framework\nachieves state-of-the-art (SOTA) performance on three evaluation benchmarks\nincluding StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward\nmodel, it significantly enhances the quality of generated stories, thereby\nfully validating the superiority of our self-evolving approach.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6545\u4e8b\u8bc4\u4f30\u4efb\u52a1\u4e2d\u8868\u73b0\u53d7\u9650\uff0c\u672c\u6587\u63d0\u51faSelf - Evolving Pairwise Reasoning (EvolvR) \u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u8bc4\u4f30\u57fa\u51c6\u4e0a\u8fbeSOTA\uff0c\u4e14\u80fd\u63d0\u5347\u6545\u4e8b\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u4efb\u52a1\uff08\u5982\u6545\u4e8b\u8bc4\u4f30\uff09\u4e2d\u6027\u80fd\u6709\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u9002\u5e94\u6027\u5dee\u3001\u7f3a\u4e4f\u4e25\u683c\u63a8\u7406\u80fd\u529b\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u8fdb\u884c\u6545\u4e8b\u8bc4\u4f30\u548c\u5f15\u5bfc\u6545\u4e8b\u751f\u6210\u3002", "method": "\u63d0\u51faEvolvR\u6846\u67b6\uff0c\u57fa\u4e8e\u6210\u5bf9\u6bd4\u8f83\uff0c\u901a\u8fc7\u591a\u89d2\u8272\u7b56\u7565\u81ea\u5408\u6210\u4e0e\u5206\u6570\u5bf9\u9f50\u7684Chain - of - Thought (CoT) \u6570\u636e\uff0c\u5bf9\u539f\u59cbCoT\u6570\u636e\u8fdb\u884c\u81ea\u8fc7\u6ee4\uff0c\u7528\u7cbe\u70bc\u6570\u636e\u8bad\u7ec3\u8bc4\u4f30\u5668\u5e76\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u5f15\u5bfc\u6545\u4e8b\u751f\u6210\u3002", "result": "\u6846\u67b6\u5728StoryER\u3001HANNA\u548cOpenMEVA\u4e09\u4e2a\u8bc4\u4f30\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u65f6\u663e\u8457\u63d0\u5347\u751f\u6210\u6545\u4e8b\u7684\u8d28\u91cf\u3002", "conclusion": "EvolvR\u6846\u67b6\u7684\u81ea\u8fdb\u5316\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u3002"}}
{"id": "2508.06163", "pdf": "https://arxiv.org/pdf/2508.06163", "abs": "https://arxiv.org/abs/2508.06163", "authors": ["Yingfeng Luo", "Dingyang Lin", "Junxin Wang", "Ziqiang Xu", "Kaiyan Chang", "Tong Zheng", "Bei Li", "Anxiang Ma", "Tong Xiao", "Zhengtao Yu", "Jingbo Zhu"], "title": "One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under review", "summary": "Model merging has emerged as a compelling data-free paradigm for multi-task\nlearning, enabling the fusion of multiple fine-tuned models into a single,\npowerful entity. A key technique in merging methods is sparsification, which\nprunes redundant parameters from task vectors to mitigate interference.\nHowever, prevailing approaches employ a ``one-size-fits-all'' strategy,\napplying a uniform sparsity ratio that overlooks the inherent structural and\nstatistical heterogeneity of model parameters. This often leads to a suboptimal\ntrade-off, where critical parameters are inadvertently pruned while less useful\nones are retained. To address this limitation, we introduce \\textbf{TADrop}\n(\\textbf{T}ensor-wise \\textbf{A}daptive \\textbf{Drop}), an adaptive\nsparsification strategy that respects this heterogeneity. Instead of a global\nratio, TADrop assigns a tailored sparsity level to each parameter tensor based\non its distributional properties. The core intuition is that tensors with\ndenser, more redundant distributions can be pruned aggressively, while sparser,\nmore critical ones are preserved. As a simple and plug-and-play module, we\nvalidate TADrop by integrating it with foundational, classic, and SOTA merging\nmethods. Extensive experiments across diverse tasks (vision, language, and\nmultimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and\nsignificantly boosts their performance. For instance, when enhancing a leading\nmerging method, it achieves an average performance gain of 2.0\\% across 8\nViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter\ninterference by tailoring sparsification to the model's structure, offering a\nnew baseline for high-performance model merging.", "AI": {"tldr": "\u63d0\u51faTADrop\u81ea\u9002\u5e94\u7a00\u758f\u5316\u7b56\u7565\u7528\u4e8e\u6a21\u578b\u5408\u5e76\uff0c\u7ecf\u591a\u4efb\u52a1\u548c\u591a\u6a21\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u7a00\u758f\u5316\u65b9\u6cd5\u91c7\u7528\u7edf\u4e00\u7a00\u758f\u7387\uff0c\u5ffd\u89c6\u53c2\u6570\u7ed3\u6784\u548c\u7edf\u8ba1\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u6b21\u4f18\u6743\u8861\u3002", "method": "\u5f15\u5165TADrop\uff0c\u6839\u636e\u53c2\u6570\u5f20\u91cf\u5206\u5e03\u7279\u6027\u4e3a\u6bcf\u4e2a\u5f20\u91cf\u5206\u914d\u5b9a\u5236\u7a00\u758f\u5ea6\u3002", "result": "\u5c06TADrop\u4e0e\u591a\u79cd\u5408\u5e76\u65b9\u6cd5\u96c6\u6210\uff0c\u5728\u591a\u4efb\u52a1\u548c\u591a\u6a21\u578b\u5b9e\u9a8c\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5982\u589e\u5f3a\u9886\u5148\u5408\u5e76\u65b9\u6cd5\u65f6\u5e73\u5747\u6027\u80fd\u63d0\u53472.0%\u3002", "conclusion": "TADrop\u901a\u8fc7\u9002\u5e94\u6a21\u578b\u7ed3\u6784\u7684\u7a00\u758f\u5316\u6709\u6548\u51cf\u8f7b\u53c2\u6570\u5e72\u6270\uff0c\u4e3a\u9ad8\u6027\u80fd\u6a21\u578b\u5408\u5e76\u63d0\u4f9b\u65b0\u57fa\u7ebf\u3002"}}
{"id": "2508.06065", "pdf": "https://arxiv.org/pdf/2508.06065", "abs": "https://arxiv.org/abs/2508.06065", "authors": ["Daniel Lee", "Nikhil Sharma", "Donghoon Shin", "DaEun Choi", "Harsh Sharma", "Jeonghwan Kim", "Heng Ji"], "title": "ThematicPlane: Bridging Tacit User Intent and Latent Spaces for Image Generation", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CV", "H.5.2; I.2.7"], "comment": null, "summary": "Generative AI has made image creation more accessible, yet aligning outputs\nwith nuanced creative intent remains challenging, particularly for non-experts.\nExisting tools often require users to externalize ideas through prompts or\nreferences, limiting fluid exploration. We introduce ThematicPlane, a system\nthat enables users to navigate and manipulate high-level semantic concepts\n(e.g., mood, style, or narrative tone) within an interactive thematic design\nplane. This interface bridges the gap between tacit creative intent and system\ncontrol. In our exploratory study (N=6), participants engaged in divergent and\nconvergent creative modes, often embracing unexpected results as inspiration or\niteration cues. While they grounded their exploration in familiar themes,\ndiffering expectations of how themes mapped to outputs revealed a need for more\nexplainable controls. Overall, ThematicPlane fosters expressive, iterative\nworkflows and highlights new directions for intuitive, semantics-driven\ninteraction in generative design tools.", "AI": {"tldr": "\u73b0\u6709\u751f\u6210\u5f0fAI\u56fe\u50cf\u521b\u4f5c\u5de5\u5177\u96be\u8ba9\u8f93\u51fa\u5951\u5408\u7528\u6237\u521b\u610f\uff0c\u672c\u6587\u4ecb\u7ecdThematicPlane\u7cfb\u7edf\uff0c\u7814\u7a76\u663e\u793a\u5176\u80fd\u4fc3\u8fdb\u521b\u4f5c\u5de5\u4f5c\u6d41\u5e76\u6307\u51fa\u65b0\u65b9\u5411\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u5f0fAI\u56fe\u50cf\u521b\u4f5c\u4e2d\u8f93\u51fa\u4e0e\u7528\u6237\u7ec6\u5fae\u521b\u610f\u610f\u56fe\u96be\u4ee5\u5bf9\u9f50\u3001\u73b0\u6709\u5de5\u5177\u9650\u5236\u7528\u6237\u6d41\u7545\u63a2\u7d22\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165ThematicPlane\u7cfb\u7edf\uff0c\u8ba9\u7528\u6237\u5728\u4ea4\u4e92\u5f0f\u4e3b\u9898\u8bbe\u8ba1\u5e73\u9762\u4e2d\u5bfc\u822a\u548c\u64cd\u7eb5\u9ad8\u7ea7\u8bed\u4e49\u6982\u5ff5\uff0c\u5e76\u5f00\u5c55\u67096\u540d\u53c2\u4e0e\u8005\u7684\u63a2\u7d22\u6027\u7814\u7a76\u3002", "result": "\u53c2\u4e0e\u8005\u80fd\u8fdb\u884c\u53d1\u6563\u548c\u6536\u655b\u521b\u4f5c\uff0c\u5e38\u5c06\u610f\u5916\u7ed3\u679c\u4f5c\u4e3a\u7075\u611f\uff0c\u4f46\u5bf9\u4e3b\u9898\u4e0e\u8f93\u51fa\u7684\u6620\u5c04\u671f\u671b\u4e0d\u540c\uff0c\u53cd\u6620\u51fa\u9700\u8981\u66f4\u5177\u89e3\u91ca\u6027\u7684\u63a7\u5236\u3002", "conclusion": "ThematicPlane\u4fc3\u8fdb\u4e86\u5bcc\u6709\u8868\u73b0\u529b\u7684\u8fed\u4ee3\u5de5\u4f5c\u6d41\uff0c\u4e3a\u751f\u6210\u5f0f\u8bbe\u8ba1\u5de5\u5177\u7684\u76f4\u89c2\u3001\u8bed\u4e49\u9a71\u52a8\u4ea4\u4e92\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.06204", "pdf": "https://arxiv.org/pdf/2508.06204", "abs": "https://arxiv.org/abs/2508.06204", "authors": ["Richard Willats", "Josh Pennington", "Aravind Mohan", "Bertie Vidgen"], "title": "Classification is a RAG problem: A case study on hate speech detection", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Robust content moderation requires classification systems that can quickly\nadapt to evolving policies without costly retraining. We present classification\nusing Retrieval-Augmented Generation (RAG), which shifts traditional\nclassification tasks from determining the correct category in accordance with\npre-trained parameters to evaluating content in relation to contextual\nknowledge retrieved at inference. In hate speech detection, this transforms the\ntask from \"is this hate speech?\" to \"does this violate the hate speech policy?\"\n  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates\nthis approach and offers three key advantages: (1) robust classification\naccuracy comparable to leading commercial systems, (2) inherent explainability\nvia retrieved policy segments, and (3) dynamic policy updates without model\nretraining. Through three experiments, we demonstrate strong baseline\nperformance and show that the system can apply fine-grained policy control by\ncorrectly adjusting protection for specific identity groups without requiring\nretraining or compromising overall performance. These findings establish that\nRAG can transform classification into a more flexible, transparent, and\nadaptable process for content moderation and wider classification problems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eRAG\u7684\u5206\u7c7b\u65b9\u6cd5\u7528\u4e8e\u5185\u5bb9\u5ba1\u6838\uff0c\u5177\u6709\u7075\u6d3b\u3001\u900f\u660e\u3001\u53ef\u9002\u5e94\u7279\u70b9\u3002", "motivation": "\u4f7f\u5206\u7c7b\u7cfb\u7edf\u80fd\u5feb\u901f\u9002\u5e94\u4e0d\u65ad\u6f14\u53d8\u7684\u653f\u7b56\uff0c\u907f\u514d\u6602\u8d35\u7684\u518d\u8bad\u7ec3\u3002", "method": "\u4f7f\u7528Retrieval - Augmented Generation (RAG)\u5c06\u4f20\u7edf\u5206\u7c7b\u4efb\u52a1\u8f6c\u53d8\u4e3a\u57fa\u4e8e\u63a8\u7406\u65f6\u68c0\u7d22\u7684\u4e0a\u4e0b\u6587\u77e5\u8bc6\u8bc4\u4f30\u5185\u5bb9\uff0cCPE\u7cfb\u7edf\u5c55\u793a\u6b64\u65b9\u6cd5\u3002", "result": "CPE\u7cfb\u7edf\u6709\u4e0e\u9886\u5148\u5546\u4e1a\u7cfb\u7edf\u76f8\u5f53\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3001\u53ef\u89e3\u91ca\u6027\u548c\u65e0\u9700\u6a21\u578b\u518d\u8bad\u7ec3\u7684\u52a8\u6001\u653f\u7b56\u66f4\u65b0\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u80fd\u8fdb\u884c\u7ec6\u7c92\u5ea6\u653f\u7b56\u63a7\u5236\u3002", "conclusion": "RAG\u53ef\u5c06\u5206\u7c7b\u8f6c\u53d8\u4e3a\u66f4\u7075\u6d3b\u3001\u900f\u660e\u548c\u53ef\u9002\u5e94\u7684\u8fc7\u7a0b\uff0c\u7528\u4e8e\u5185\u5bb9\u5ba1\u6838\u548c\u66f4\u5e7f\u6cdb\u7684\u5206\u7c7b\u95ee\u9898\u3002"}}
{"id": "2508.06072", "pdf": "https://arxiv.org/pdf/2508.06072", "abs": "https://arxiv.org/abs/2508.06072", "authors": ["Zijian Chen", "Lirong Deng", "Zhengyu Chen", "Kaiwei Zhang", "Qi Jia", "Yuan Tian", "Yucheng Zhu", "Guangtao Zhai"], "title": "Can Large Models Fool the Eye? A New Turing Test for Biological Animation", "categories": ["cs.CV", "cs.AI"], "comment": "24 pages, 10 figures", "summary": "Evaluating the abilities of large models and manifesting their gaps are\nchallenging. Current benchmarks adopt either ground-truth-based score-form\nevaluation on static datasets or indistinct textual chatbot-style human\npreferences collection, which may not provide users with immediate, intuitive,\nand perceptible feedback on performance differences. In this paper, we\nintroduce BioMotion Arena, a novel framework for evaluating large language\nmodels (LLMs) and multimodal large language models (MLLMs) via visual\nanimation. Our methodology draws inspiration from the inherent visual\nperception of motion patterns characteristic of living organisms that utilizes\npoint-light source imaging to amplify the performance discrepancies between\nmodels. Specifically, we employ a pairwise comparison evaluation and collect\nmore than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion\nvariants. Data analyses show that the crowd-sourced human votes are in good\nagreement with those of expert raters, demonstrating the superiority of our\nBioMotion Arena in offering discriminative feedback. We also find that over\n90\\% of evaluated models, including the cutting-edge open-source InternVL3 and\nproprietary Claude-4 series, fail to produce fundamental humanoid point-light\ngroups, much less smooth and biologically plausible motions. This enables\nBioMotion Arena to serve as a challenging benchmark for performance\nvisualization and a flexible evaluation framework without restrictions on\nground-truth.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684BioMotion Arena\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u52a8\u753b\u8bc4\u4f30\uff0c\u6570\u636e\u663e\u793a\u5176\u80fd\u63d0\u4f9b\u6709\u533a\u5206\u5ea6\u53cd\u9988\uff0c\u591a\u6570\u88ab\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u7ed9\u7528\u6237\u63d0\u4f9b\u5173\u4e8e\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u7684\u5373\u65f6\u3001\u76f4\u89c2\u53cd\u9988\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f15\u5165BioMotion Arena\u6846\u67b6\uff0c\u91c7\u7528\u6210\u5bf9\u6bd4\u8f83\u8bc4\u4f30\uff0c\u5229\u7528\u70b9\u5149\u6e90\u6210\u50cf\u653e\u5927\u6a21\u578b\u6027\u80fd\u5dee\u5f02\uff0c\u6536\u96c6\u8d854.5\u4e07\u5f20\u9009\u7968\u3002", "result": "\u4f17\u5305\u7684\u4eba\u7c7b\u6295\u7968\u4e0e\u4e13\u5bb6\u8bc4\u5206\u9ad8\u5ea6\u4e00\u81f4\uff0c\u8868\u660eBioMotion Arena\u80fd\u63d0\u4f9b\u6709\u533a\u5206\u5ea6\u7684\u53cd\u9988\uff1b\u8d8590%\u88ab\u8bc4\u4f30\u6a21\u578b\u65e0\u6cd5\u751f\u6210\u57fa\u672c\u4eba\u5f62\u70b9\u5149\u6e90\u7ec4\u3002", "conclusion": "BioMotion Arena\u53ef\u4f5c\u4e3a\u5177\u6709\u6311\u6218\u6027\u7684\u6027\u80fd\u53ef\u89c6\u5316\u57fa\u51c6\u548c\u65e0\u771f\u5b9e\u503c\u9650\u5236\u7684\u7075\u6d3b\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2508.06277", "pdf": "https://arxiv.org/pdf/2508.06277", "abs": "https://arxiv.org/abs/2508.06277", "authors": ["Theresa Pekarek Rosin", "Burak Can Kaplan", "Stefan Wermter"], "title": "Large Language Model Data Generation for Enhanced Intent Recognition in German Speech", "categories": ["cs.CL", "cs.LG", "cs.SD"], "comment": "11 pages, 3 figures, accepted at KONVENS 2025", "summary": "Intent recognition (IR) for speech commands is essential for artificial\nintelligence (AI) assistant systems; however, most existing approaches are\nlimited to short commands and are predominantly developed for English. This\npaper addresses these limitations by focusing on IR from speech by elderly\nGerman speakers. We propose a novel approach that combines an adapted Whisper\nASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based\nlanguage models trained on synthetic text datasets generated by three\nwell-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To\nevaluate the robustness of our approach, we generate synthetic speech with a\ntext-to-speech model and conduct extensive cross-dataset testing. Our results\nshow that synthetic LLM-generated data significantly boosts classification\nperformance and robustness to different speaking styles and unseen vocabulary.\nNotably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the\nmuch larger ChatGPT (175B) in dataset quality for German intent recognition.\nOur approach demonstrates that generative AI can effectively bridge data gaps\nin low-resource domains. We provide detailed documentation of our data\ngeneration and training process to ensure transparency and reproducibility.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7ed3\u5408\u8c03\u6574\u540e\u7684Whisper ASR\u6a21\u578b\u4e0e\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5904\u7406\u5fb7\u56fd\u8001\u5e74\u8bf4\u8bdd\u8005\u8bed\u97f3\u7684\u610f\u56fe\u8bc6\u522b\u95ee\u9898\uff0c\u5408\u6210\u6570\u636e\u63d0\u5347\u6027\u80fd\uff0c\u5c0f\u6a21\u578bLeoLM\u5728\u5fb7\u8bed\u6587\u672c\u8d28\u91cf\u4e0a\u8d85ChatGPT\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u547d\u4ee4\u610f\u56fe\u8bc6\u522b\u65b9\u6cd5\u5c40\u9650\u4e8e\u77ed\u547d\u4ee4\u4e14\u591a\u4e3a\u82f1\u8bed\uff0c\u8bba\u6587\u805a\u7126\u5fb7\u56fd\u8001\u5e74\u8bf4\u8bdd\u8005\u8bed\u97f3\u610f\u56fe\u8bc6\u522b\u3002", "method": "\u7ed3\u5408\u8c03\u6574\u540e\u7684Whisper ASR\u6a21\u578b\uff08SVC - de\uff09\u548c\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u8bed\u8a00\u6a21\u578b\u5728LeoLM\u3001Llama3\u548cChatGPT\u751f\u6210\u7684\u5408\u6210\u6587\u672c\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u7528\u6587\u672c\u8f6c\u8bed\u97f3\u6a21\u578b\u751f\u6210\u5408\u6210\u8bed\u97f3\u5e76\u8fdb\u884c\u8de8\u6570\u636e\u96c6\u6d4b\u8bd5\u3002", "result": "\u5408\u6210\u7684\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u6570\u636e\u663e\u8457\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u548c\u5bf9\u4e0d\u540c\u8bf4\u8bdd\u98ce\u683c\u53ca\u672a\u89c1\u8bcd\u6c47\u7684\u9c81\u68d2\u6027\uff0cLeoLM\u5728\u5fb7\u56fd\u610f\u56fe\u8bc6\u522b\u6570\u636e\u96c6\u8d28\u91cf\u4e0a\u8d85\u8fc7ChatGPT\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u53ef\u6709\u6548\u5f25\u8865\u4f4e\u8d44\u6e90\u9886\u57df\u7684\u6570\u636e\u7f3a\u53e3\uff0c\u63d0\u4f9b\u6570\u636e\u751f\u6210\u548c\u8bad\u7ec3\u8fc7\u7a0b\u6587\u6863\u786e\u4fdd\u900f\u660e\u548c\u53ef\u590d\u73b0\u3002"}}
{"id": "2508.06076", "pdf": "https://arxiv.org/pdf/2508.06076", "abs": "https://arxiv.org/abs/2508.06076", "authors": ["Michael Wehrli", "Alicia Durrer", "Paul Friedrich", "Sidaty El Hadramy", "Edwin Li", "Luana Brahaj", "Carol C. Hasler", "Philippe C. Cattin"], "title": "Towards MR-Based Trochleoplasty Planning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at MICCAI COLAS Workshop 2025. Code:\n  https://wehrlimi.github.io/sr-3d-planning/", "summary": "To treat Trochlear Dysplasia (TD), current approaches rely mainly on\nlow-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.\nThe surgeries are planned based on surgeons experience, have limited adoption\nof minimally invasive techniques, and lead to inconsistent outcomes. We propose\na pipeline that generates super-resolved, patient-specific 3D pseudo-healthy\ntarget morphologies from conventional clinical MR scans. First, we compute an\nisotropic super-resolved MR volume using an Implicit Neural Representation\n(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label\ncustom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to\ngenerate pseudo-healthy target morphologies of the trochlear region. In\ncontrast to prior work producing pseudo-healthy low-resolution 3D MR images,\nour approach enables the generation of sub-millimeter resolved 3D shapes\ncompatible for pre- and intraoperative use. These can serve as preoperative\nblueprints for reshaping the femoral groove while preserving the native patella\narticulation. Furthermore, and in contrast to other work, we do not require a\nCT for our pipeline - reducing the amount of radiation. We evaluated our\napproach on 25 TD patients and could show that our target morphologies\nsignificantly improve the sulcus angle (SA) and trochlear groove depth (TGD).\nThe code and interactive visualization are available at\nhttps://wehrlimi.github.io/sr-3d-planning/.", "AI": {"tldr": "\u63d0\u51fa\u4ece\u5e38\u89c4\u4e34\u5e8aMR\u626b\u63cf\u751f\u6210\u8d85\u5206\u8fa8\u7387\u3001\u60a3\u8005\u7279\u5b9a\u76843D\u4f2a\u5065\u5eb7\u76ee\u6807\u5f62\u6001\u7684\u7ba1\u9053\uff0c\u53ef\u7528\u4e8e\u6cbb\u7597\u6ed1\u8f66\u53d1\u80b2\u4e0d\u826f\uff0c\u51cf\u5c11\u8f90\u5c04\u4e14\u6548\u679c\u826f\u597d\uff0c\u4ee3\u7801\u548c\u53ef\u89c6\u5316\u516c\u5f00\u3002", "motivation": "\u5f53\u524d\u6cbb\u7597\u6ed1\u8f66\u53d1\u80b2\u4e0d\u826f\u7684\u65b9\u6cd5\u4f9d\u8d56\u4f4e\u5206\u8fa8\u7387MR\u626b\u63cf\u548c\u624b\u672f\u76f4\u89c9\uff0c\u624b\u672f\u89c4\u5212\u51ed\u7ecf\u9a8c\uff0c\u5fae\u521b\u6280\u672f\u5e94\u7528\u6709\u9650\u4e14\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002", "method": "\u5148\u4f7f\u7528\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u8ba1\u7b97\u5404\u5411\u540c\u6027\u8d85\u5206\u8fa8\u7387MR\u4f53\u79ef\uff0c\u518d\u7528\u591a\u6807\u7b7e\u5b9a\u5236\u8bad\u7ec3\u7f51\u7edc\u5206\u5272\u9aa8\u9abc\uff0c\u6700\u540e\u8bad\u7ec3\u5c0f\u6ce2\u6269\u6563\u6a21\u578b\u751f\u6210\u6ed1\u8f66\u533a\u57df\u4f2a\u5065\u5eb7\u76ee\u6807\u5f62\u6001\u3002", "result": "\u572825\u4f8b\u6ed1\u8f66\u53d1\u80b2\u4e0d\u826f\u60a3\u8005\u4e0a\u8bc4\u4f30\uff0c\u76ee\u6807\u5f62\u6001\u663e\u8457\u6539\u5584\u4e86\u6c9f\u89d2\u548c\u6ed1\u8f66\u6c9f\u6df1\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u4e9a\u6beb\u7c73\u5206\u8fa8\u7387\u76843D\u5f62\u72b6\uff0c\u53ef\u7528\u4e8e\u672f\u524d\u548c\u672f\u4e2d\uff0c\u65e0\u9700CT\u51cf\u5c11\u8f90\u5c04\uff0c\u6709\u8f83\u597d\u6cbb\u7597\u6548\u679c\u3002"}}
{"id": "2508.06096", "pdf": "https://arxiv.org/pdf/2508.06096", "abs": "https://arxiv.org/abs/2508.06096", "authors": ["Eric Jing", "Abdeslam Boularias"], "title": "Bounding Distributional Shifts in World Modeling through Novelty Detection", "categories": ["cs.RO", "cs.AI"], "comment": "7 pages, 6 figures", "summary": "Recent work on visual world models shows significant promise in latent state\ndynamics obtained from pre-trained image backbones. However, most of the\ncurrent approaches are sensitive to training quality, requiring near-complete\ncoverage of the action and state space during training to prevent divergence\nduring inference. To make a model-based planning algorithm more robust to the\nquality of the learned world model, we propose in this work to use a\nvariational autoencoder as a novelty detector to ensure that proposed action\ntrajectories during planning do not cause the learned model to deviate from the\ntraining data distribution. To evaluate the effectiveness of this approach, a\nseries of experiments in challenging simulated robot environments was carried\nout, with the proposed method incorporated into a model-predictive control\npolicy loop extending the DINO-WM architecture. The results clearly show that\nthe proposed method improves over state-of-the-art solutions in terms of data\nefficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u4f5c\u65b0\u9896\u6027\u68c0\u6d4b\u5668\uff0c\u4f7f\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u7b97\u6cd5\u5bf9\u4e16\u754c\u6a21\u578b\u8d28\u91cf\u66f4\u9c81\u68d2\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u65b9\u6cd5\u5bf9\u8bad\u7ec3\u8d28\u91cf\u654f\u611f\uff0c\u9700\u5728\u8bad\u7ec3\u65f6\u8fd1\u4e4e\u5b8c\u5168\u8986\u76d6\u52a8\u4f5c\u548c\u72b6\u6001\u7a7a\u95f4\u4ee5\u9632\u6b62\u63a8\u7406\u65f6\u53d1\u6563\uff0c\u4e3a\u4f7f\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u7b97\u6cd5\u5bf9\u5b66\u4e60\u5230\u7684\u4e16\u754c\u6a21\u578b\u8d28\u91cf\u66f4\u9c81\u68d2\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u4f5c\u4e3a\u65b0\u9896\u6027\u68c0\u6d4b\u5668\uff0c\u786e\u4fdd\u89c4\u5212\u671f\u95f4\u63d0\u51fa\u7684\u52a8\u4f5c\u8f68\u8ff9\u4e0d\u4f1a\u4f7f\u5b66\u4e60\u5230\u7684\u6a21\u578b\u504f\u79bb\u8bad\u7ec3\u6570\u636e\u5206\u5e03\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u7eb3\u5165\u6269\u5c55DINO - WM\u67b6\u6784\u7684\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u7b56\u7565\u5faa\u73af\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u6a21\u62df\u673a\u5668\u4eba\u73af\u5883\u4e2d\u8fdb\u884c\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u7b97\u6cd5\u5bf9\u4e16\u754c\u6a21\u578b\u8d28\u91cf\u7684\u9c81\u68d2\u6027\uff0c\u4e14\u5728\u6570\u636e\u6548\u7387\u4e0a\u6709\u4f18\u52bf\u3002"}}
{"id": "2508.06321", "pdf": "https://arxiv.org/pdf/2508.06321", "abs": "https://arxiv.org/abs/2508.06321", "authors": ["Durjoy Chandra Paul", "Gaurob Saha", "Md Amjad Hossain"], "title": "EmoAugNet: A Signal-Augmented Hybrid CNN-LSTM Framework for Speech Emotion Recognition", "categories": ["cs.SD", "cs.HC", "cs.LG"], "comment": "To be published in ICCCNT 2025 (16th International Conference on\n  Computing Communication and Networking Technologies)", "summary": "Recognizing emotional signals in speech has a significant impact on enhancing\nthe effectiveness of human-computer interaction (HCI). This study introduces\nEmoAugNet, a hybrid deep learning framework, that incorporates Long Short-Term\nMemory (LSTM) layers with one-dimensional Convolutional Neural Networks\n(1D-CNN) to enable reliable Speech Emotion Recognition (SER). The quality and\nvariety of the features that are taken from speech signals have a significant\nimpact on how well SER systems perform. A comprehensive speech data\naugmentation strategy was used to combine both traditional methods, such as\nnoise addition, pitch shifting, and time stretching, with a novel\ncombination-based augmentation pipeline to enhance generalization and reduce\noverfitting. Each audio sample was transformed into a high-dimensional feature\nvector using root mean square energy (RMSE), Mel-frequency Cepstral Coefficient\n(MFCC), and zero-crossing rate (ZCR). Our model with ReLU activation has a\nweighted accuracy of 95.78\\% and unweighted accuracy of 92.52\\% on the IEMOCAP\ndataset and, with ELU activation, has a weighted accuracy of 96.75\\% and\nunweighted accuracy of 91.28\\%. On the RAVDESS dataset, we get a weighted\naccuracy of 94.53\\% and 94.98\\% unweighted accuracy for ReLU activation and\n93.72\\% weighted accuracy and 94.64\\% unweighted accuracy for ELU activation.\nThese results highlight EmoAugNet's effectiveness in improving the robustness\nand performance of SER systems through integated data augmentation and hybrid\nmodeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEmoAugNet\u6846\u67b6\u7528\u4e8e\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\uff0c\u91c7\u7528\u6570\u636e\u589e\u5f3a\u548c\u6df7\u5408\u5efa\u6a21\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u63d0\u9ad8\u4eba\u673a\u4ea4\u4e92\u6709\u6548\u6027\uff0c\u6539\u5584\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5f15\u5165\u7ed3\u5408LSTM\u548c1D - CNN\u7684EmoAugNet\u6846\u67b6\uff0c\u91c7\u7528\u7efc\u5408\u8bed\u97f3\u6570\u636e\u589e\u5f3a\u7b56\u7565\uff0c\u5c06\u97f3\u9891\u6837\u672c\u8f6c\u6362\u4e3a\u9ad8\u7ef4\u7279\u5f81\u5411\u91cf\u3002", "result": "\u5728IEMOCAP\u548cRAVDESS\u6570\u636e\u96c6\u4e0a\uff0c\u4e0d\u540c\u6fc0\u6d3b\u51fd\u6570\u4e0b\u6a21\u578b\u5747\u53d6\u5f97\u8f83\u9ad8\u7684\u52a0\u6743\u548c\u975e\u52a0\u6743\u51c6\u786e\u7387\u3002", "conclusion": "EmoAugNet\u901a\u8fc7\u96c6\u6210\u6570\u636e\u589e\u5f3a\u548c\u6df7\u5408\u5efa\u6a21\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2508.06098", "pdf": "https://arxiv.org/pdf/2508.06098", "abs": "https://arxiv.org/abs/2508.06098", "authors": ["Xiquan Li", "Junxi Liu", "Yuzhe Liang", "Zhikang Niu", "Wenxi Chen", "Xie Chen"], "title": "MeanAudio: Fast and Faithful Text-to-Audio Generation with Mean Flows", "categories": ["cs.SD", "cs.AI"], "comment": "9 pages, 3 figures", "summary": "Recent developments in diffusion- and flow- based models have significantly\nadvanced Text-to-Audio Generation (TTA). While achieving great synthesis\nquality and controllability, current TTA systems still suffer from slow\ninference speed, which significantly limits their practical applicability. This\npaper presents MeanAudio, a novel MeanFlow-based model tailored for fast and\nfaithful text-to-audio generation. Built on a Flux-style latent transformer,\nMeanAudio regresses the average velocity field during training, enabling fast\ngeneration by mapping directly from the start to the endpoint of the flow\ntrajectory. By incorporating classifier-free guidance (CFG) into the training\ntarget, MeanAudio incurs no additional cost in the guided sampling process. To\nfurther stabilize training, we propose an instantaneous-to-mean curriculum with\nflow field mix-up, which encourages the model to first learn the foundational\ninstantaneous dynamics, and then gradually adapt to mean flows. This strategy\nproves critical for enhancing training efficiency and generation quality.\nExperimental results demonstrate that MeanAudio achieves state-of-the-art\nperformance in single-step audio generation. Specifically, it achieves a real\ntime factor (RTF) of 0.013 on a single NVIDIA RTX 3090, yielding a 100x speedup\nover SOTA diffusion-based TTA systems. Moreover, MeanAudio also demonstrates\nstrong performance in multi-step generation, enabling smooth and coherent\ntransitions across successive synthesis steps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMeanAudio\u6a21\u578b\u7528\u4e8e\u5feb\u901f\u4e14\u51c6\u786e\u7684\u6587\u672c\u5230\u97f3\u9891\u751f\u6210\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u5355\u6b65\u548c\u591a\u6b65\u97f3\u9891\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u5230\u97f3\u9891\u751f\u6210\u7cfb\u7edf\u63a8\u7406\u901f\u5ea6\u6162\uff0c\u9650\u5236\u5b9e\u9645\u5e94\u7528\uff0c\u9700\u5f00\u53d1\u5feb\u901f\u751f\u6210\u6a21\u578b\u3002", "method": "\u6784\u5efa\u57fa\u4e8eFlux\u98ce\u683c\u6f5c\u5728\u53d8\u538b\u5668\u7684MeanFlow\u6a21\u578b\uff0c\u56de\u5f52\u5e73\u5747\u901f\u5ea6\u573a\uff1b\u5c06\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u7eb3\u5165\u8bad\u7ec3\u76ee\u6807\uff1b\u63d0\u51fa\u77ac\u65f6\u5230\u5e73\u5747\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u3002", "result": "MeanAudio\u5728\u5355\u6b65\u97f3\u9891\u751f\u6210\u4e2d\u8fbeSOTA\u6027\u80fd\uff0c\u5728\u5355\u5f20NVIDIA RTX 3090\u4e0a\u5b9e\u65f6\u56e0\u5b50\u4e3a0.013\uff0c\u6bd4SOTA\u6269\u6563\u6a21\u578b\u5feb100\u500d\uff1b\u5728\u591a\u6b65\u751f\u6210\u4e2d\u4e5f\u8868\u73b0\u826f\u597d\u3002", "conclusion": "MeanAudio\u80fd\u5b9e\u73b0\u5feb\u901f\u4e14\u51c6\u786e\u7684\u6587\u672c\u5230\u97f3\u9891\u751f\u6210\uff0c\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2508.06107", "pdf": "https://arxiv.org/pdf/2508.06107", "abs": "https://arxiv.org/abs/2508.06107", "authors": ["Shree Mitra", "Ritabrata Chakraborty", "Nilkanta Sahu"], "title": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recognizing handwritten mathematical expressions (HMER) is a challenging task\ndue to the inherent two-dimensional structure, varying symbol scales, and\ncomplex spatial relationships among symbols. In this paper, we present a\nself-supervised learning (SSL) framework for HMER that eliminates the need for\nexpensive labeled data. Our approach begins by pretraining an image encoder\nusing a combination of global and local contrastive loss, enabling the model to\nlearn both holistic and fine-grained representations. A key contribution of\nthis work is a novel self-supervised attention network, which is trained using\na progressive spatial masking strategy. This attention mechanism is designed to\nlearn semantically meaningful focus regions, such as operators, exponents, and\nnested mathematical notation, without requiring any supervision. The\nprogressive masking curriculum encourages the network to become increasingly\nrobust to missing or occluded visual information, ultimately improving\nstructural understanding. Our complete pipeline consists of (1) self-supervised\npretraining of the encoder, (2) self-supervised attention learning, and (3)\nsupervised fine-tuning with a transformer decoder to generate LATEX sequences.\nExtensive experiments on CROHME benchmarks demonstrate that our method\noutperforms existing SSL and fully supervised baselines, validating the\neffectiveness of our progressive attention mechanism in enhancing HMER\nperformance. Our codebase can be found here.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u624b\u5199\u6570\u5b66\u8868\u8fbe\u5f0f\u8bc6\u522b\uff08HMER\uff09\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "HMER\u56e0\u4e8c\u7ef4\u7ed3\u6784\u3001\u7b26\u53f7\u5c3a\u5ea6\u53d8\u5316\u548c\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u5177\u6709\u6311\u6218\u6027\uff0c\u4e14\u6807\u6ce8\u6570\u636e\u6602\u8d35\uff0c\u9700\u65e0\u6807\u6ce8\u6570\u636e\u65b9\u6cd5\u3002", "method": "\u7528\u5168\u5c40\u548c\u5c40\u90e8\u5bf9\u6bd4\u635f\u5931\u9884\u8bad\u7ec3\u56fe\u50cf\u7f16\u7801\u5668\uff1b\u91c7\u7528\u6e10\u8fdb\u7a7a\u95f4\u63a9\u7801\u7b56\u7565\u8bad\u7ec3\u81ea\u76d1\u7763\u6ce8\u610f\u529b\u7f51\u7edc\uff1b\u5b8c\u6574\u6d41\u7a0b\u5305\u62ec\u7f16\u7801\u5668\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3001\u6ce8\u610f\u529b\u5b66\u4e60\u548c\u7528Transformer\u89e3\u7801\u5668\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u5728CROHME\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u81ea\u76d1\u7763\u548c\u5168\u76d1\u7763\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6e10\u8fdb\u6ce8\u610f\u529b\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347HMER\u6027\u80fd\u3002"}}
{"id": "2508.06345", "pdf": "https://arxiv.org/pdf/2508.06345", "abs": "https://arxiv.org/abs/2508.06345", "authors": ["Yanbin Wei", "Jiangyue Yan", "Chun Kang", "Yang Chen", "Hua Liu", "James T. Kwok", "Yu Zhang"], "title": "Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering", "categories": ["cs.CL", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities\nin diverse domain question-answering (QA) tasks, including graph QA that\ninvolves complex graph topologies. However, most current approaches use only a\nsingle type of graph representation, namely Topology Representation Form (TRF),\nsuch as prompt-unified text descriptions or style-fixed visual styles. Those\n\"one-size-fits-all\" approaches fail to consider the specific preferences of\ndifferent models or tasks, often leading to incorrect or overly long responses.\nTo address this, we first analyze the characteristics and weaknesses of\nexisting TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to\nzero-shot graph QA. We then introduce a new metric, Graph Response Efficiency\n(GRE), which measures the balance between the performance and the brevity in\ngraph QA. Built on these, we develop the DynamicTRF framework, which aims to\nimprove both the accuracy and conciseness of graph QA. To be specific,\nDynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based\non their GRE scores, to probe the question-specific TRF preferences. Then it\ntrains a TRF router on the TRFP dataset, to adaptively assign the best TRF from\n$F_{ZS}$ for each question during the inference. Extensive experiments across 7\nin-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show\nthat DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms\nof accuracy", "AI": {"tldr": "\u73b0\u6709LMMs\u7684\u56feQA\u65b9\u6cd5\u5355\u4e00\uff0c\u672c\u6587\u8bbe\u8ba1\u65b0TRF\u3001\u63d0\u51faGRE\u6307\u6807\u5e76\u5f00\u53d1DynamicTRF\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u663e\u8457\u63d0\u5347\u96f6\u6837\u672c\u56feQA\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u6570\u65b9\u6cd5\u4f7f\u7528\u5355\u4e00\u56fe\u8868\u793a\u5f62\u5f0f\uff0c\u672a\u8003\u8651\u4e0d\u540c\u6a21\u578b\u6216\u4efb\u52a1\u504f\u597d\uff0c\u5bfc\u81f4\u56de\u7b54\u9519\u8bef\u6216\u8fc7\u957f\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5206\u6790\u73b0\u6709TRF\u7279\u70b9\u4e0e\u4e0d\u8db3\uff0c\u8bbe\u8ba1\u9002\u5408\u96f6\u6837\u672c\u56feQA\u7684TRF\u96c6\u5408$F_{ZS}$\uff0c\u5f15\u5165GRE\u6307\u6807\uff0c\u5f00\u53d1DynamicTRF\u6846\u67b6\uff0c\u521b\u5efaTRFP\u6570\u636e\u96c6\uff0c\u8bad\u7ec3TRF\u8def\u7531\u5668\u3002", "result": "\u57287\u4e2a\u9886\u57df\u5185\u7b97\u6cd5\u56feQA\u4efb\u52a1\u548c2\u4e2a\u9886\u57df\u5916\u4e0b\u6e38\u4efb\u52a1\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDynamicTRF\u663e\u8457\u63d0\u5347LMMs\u96f6\u6837\u672c\u56feQA\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DynamicTRF\u6846\u67b6\u80fd\u6709\u6548\u63d0\u9ad8\u56feQA\u7684\u51c6\u786e\u6027\u548c\u7b80\u6d01\u6027\u3002"}}
{"id": "2508.06109", "pdf": "https://arxiv.org/pdf/2508.06109", "abs": "https://arxiv.org/abs/2508.06109", "authors": ["Zhibo Zhu", "Renyu Huang", "Lei He"], "title": "FMCE-Net++: Feature Map Convergence Evaluation and Training", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep Neural Networks (DNNs) face interpretability challenges due to their\nopaque internal representations. While Feature Map Convergence Evaluation\n(FMCE) quantifies module-level convergence via Feature Map Convergence Scores\n(FMCS), it lacks experimental validation and closed-loop integration. To\naddress this limitation, we propose FMCE-Net++, a novel training framework that\nintegrates a pretrained, frozen FMCE-Net as an auxiliary head. This module\ngenerates FMCS predictions, which, combined with task labels, jointly supervise\nbackbone optimization through a Representation Auxiliary Loss. The RAL\ndynamically balances the primary classification loss and feature convergence\noptimization via a tunable \\Representation Abstraction Factor. Extensive\nexperiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100\ndemonstrate that FMCE-Net++ consistently enhances model performance without\narchitectural modifications or additional data. Key experimental outcomes\ninclude accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp\n(ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate\nstate-of-the-art performance ceilings.", "AI": {"tldr": "\u63d0\u51faFMCE - Net++\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408FMCS\u9884\u6d4b\u548c\u4efb\u52a1\u6807\u7b7e\u4f18\u5316\u6a21\u578b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709Feature Map Convergence Evaluation\uff08FMCE\uff09\u7f3a\u4e4f\u5b9e\u9a8c\u9a8c\u8bc1\u548c\u95ed\u73af\u96c6\u6210\uff0c\u4e3a\u89e3\u51b3\u6b64\u5c40\u9650\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u63d0\u51faFMCE - Net++\u8bad\u7ec3\u6846\u67b6\uff0c\u96c6\u6210\u9884\u8bad\u7ec3\u7684FMCE - Net\u4f5c\u4e3a\u8f85\u52a9\u5934\uff0c\u901a\u8fc7Representation Auxiliary Loss\u8054\u5408\u76d1\u7763\u9aa8\u5e72\u7f51\u7edc\u4f18\u5316\uff0c\u7528\u53ef\u8c03\u8282\u56e0\u5b50\u5e73\u8861\u4e3b\u8981\u5206\u7c7b\u635f\u5931\u548c\u7279\u5f81\u6536\u655b\u4f18\u5316\u3002", "result": "\u5728MNIST\u3001CIFAR - 10\u7b49\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cResNet - 50/CIFAR - 10\u51c6\u786e\u7387\u63d0\u53471.16 pp\uff0cShuffleNet v2/CIFAR - 100\u51c6\u786e\u7387\u63d0\u53471.08 pp\u3002", "conclusion": "FMCE - Net++\u65e0\u9700\u67b6\u6784\u4fee\u6539\u548c\u989d\u5916\u6570\u636e\uff0c\u80fd\u6709\u6548\u63d0\u5347\u73b0\u6709\u6a21\u578b\u6027\u80fd\u4e0a\u9650\u3002"}}
{"id": "2508.06383", "pdf": "https://arxiv.org/pdf/2508.06383", "abs": "https://arxiv.org/abs/2508.06383", "authors": ["Rashid Barket", "Matthew England", "J\u00fcrgen Gerhard"], "title": "Tree-Based Deep Learning for Ranking Symbolic Integration Algorithms", "categories": ["cs.SC", "cs.LG"], "comment": "29 pages, 13 figures, 5 tables, submitted to Transactions on\n  Mathematical Software (TOMS)", "summary": "Symbolic indefinite integration in Computer Algebra Systems such as Maple\ninvolves selecting the most effective algorithm from multiple available\nmethods. Not all methods will succeed for a given problem, and when several do,\nthe results, though mathematically equivalent, can differ greatly in\npresentation complexity. Traditionally, this choice has been made with minimal\nconsideration of the problem instance, leading to inefficiencies.\n  We present a machine learning (ML) approach using tree-based deep learning\nmodels within a two-stage architecture: first identifying applicable methods\nfor a given instance, then ranking them by predicted output complexity.\nFurthermore, we find representing mathematical expressions as tree structures\nsignificantly improves performance over sequence-based representations, and our\ntwo-stage framework outperforms alternative ML formulations.\n  Using a diverse dataset generated by six distinct data generators, our models\nachieve nearly 90% accuracy in selecting the optimal method on a 70,000 example\nholdout test set. On an independent out-of-distribution benchmark from Maple's\ninternal test suite, our tree transformer model maintains strong\ngeneralisation, outperforming Maple's built-in selector and prior ML\napproaches.\n  These results highlight the critical role of data representation and problem\nframing in ML for symbolic computation, and we expect our methodology to\ngeneralise effectively to similar optimisation problems in mathematical\nsoftware.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6811\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u7b26\u53f7\u4e0d\u5b9a\u79ef\u5206\u7b97\u6cd5\u9009\u62e9\uff0c\u5728\u6d4b\u8bd5\u96c6\u8868\u73b0\u597d\uff0c\u51f8\u663e\u6570\u636e\u8868\u793a\u548c\u95ee\u9898\u6846\u67b6\u91cd\u8981\u6027\u3002", "motivation": "\u4f20\u7edf\u7b26\u53f7\u4e0d\u5b9a\u79ef\u5206\u7b97\u6cd5\u9009\u62e9\u672a\u5145\u5206\u8003\u8651\u95ee\u9898\u5b9e\u4f8b\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\u7684\u57fa\u4e8e\u6811\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5148\u8bc6\u522b\u9002\u7528\u65b9\u6cd5\uff0c\u518d\u6309\u9884\u6d4b\u8f93\u51fa\u590d\u6742\u5ea6\u6392\u5e8f\uff1b\u7528\u6811\u7ed3\u6784\u8868\u793a\u6570\u5b66\u8868\u8fbe\u5f0f\u3002", "result": "\u572870000\u4e2a\u6837\u672c\u7684\u6d4b\u8bd5\u96c6\u4e0a\u9009\u6700\u4f18\u65b9\u6cd5\u51c6\u786e\u7387\u8fd190%\uff1b\u5728\u72ec\u7acb\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8eMaple\u5185\u7f6e\u9009\u62e9\u5668\u548c\u5148\u524dML\u65b9\u6cd5\u3002", "conclusion": "\u6570\u636e\u8868\u793a\u548c\u95ee\u9898\u6846\u67b6\u5728\u7b26\u53f7\u8ba1\u7b97\u7684ML\u4e2d\u5f88\u5173\u952e\uff0c\u65b9\u6cd5\u6709\u671b\u63a8\u5e7f\u5230\u6570\u5b66\u8f6f\u4ef6\u7684\u7c7b\u4f3c\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2508.06135", "pdf": "https://arxiv.org/pdf/2508.06135", "abs": "https://arxiv.org/abs/2508.06135", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Knowledge Distillation (KD) is a fundamental technique for compressing large\nlanguage models (LLMs) into compact, efficient student models. However,\nexisting white-box KD methods mainly focus on balancing ground truth and\nstudent-generated responses while overlooking two critical factors: training\ndata quality and student-model compatibility. To address these limitations, we\npropose Selective Reflection Distillation (SRD), a novel data curation\nframework that leverages reflections from student models to systematically\nrefine training data. SRD dynamically evaluates and selects prompt-response\npairs by comparing ground truth data with student model outputs, selectively\ncurating high-quality, student-compatible training instances through automated\nranking based on difficulty. Furthermore, after selecting the training data, a\ncurriculum scheduling strategy is employed to incrementally introduce these\ncurated subsets into the distillation process at fixed intervals. As a\nplug-and-play enhancement, SRD consistently improves distillation outcomes\nacross diverse white-box KD approaches and model architectures, as well as\ndecreases computational cost significantly during KD training. Experiments on a\nrange of language model benchmarks demonstrate SRD's consistent improvements in\ndistilled model performance, as well as a reduction in training runtime by up\nto 39%, under diverse KD methods and model families. Notably, SRD operates as a\nplug-and-play module, enhancing sample efficiency without modifying underlying\nKD algorithms. Our findings highlight that data quality and compatibility are\npivotal to effective and efficient distillation of LLMs, and SRD provides a\nprincipled framework to achieve both. This work advances the understanding of\ndata-centric factors in KD and offers practical insights for enhancing the\ncapability and efficiency of compressed LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9009\u62e9\u6027\u53cd\u5c04\u84b8\u998f\uff08SRD\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u5b66\u751f\u6a21\u578b\u53cd\u9988\u7b5b\u9009\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u5347\u77e5\u8bc6\u84b8\u998f\u6548\u679c\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u767d\u76d2\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u5ffd\u89c6\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u548c\u5b66\u751f\u6a21\u578b\u517c\u5bb9\u6027\uff0c\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u3002", "method": "\u63d0\u51faSRD\u6846\u67b6\uff0c\u52a8\u6001\u8bc4\u4f30\u548c\u9009\u62e9\u63d0\u793a - \u54cd\u5e94\u6570\u636e\u5bf9\uff0c\u91c7\u7528\u8bfe\u7a0b\u8c03\u5ea6\u7b56\u7565\u5f15\u5165\u7b5b\u9009\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSRD\u5728\u591a\u79cd\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u63d0\u5347\u84b8\u998f\u6a21\u578b\u6027\u80fd\uff0c\u6700\u591a\u51cf\u5c1139%\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "\u6570\u636e\u8d28\u91cf\u548c\u517c\u5bb9\u6027\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u84b8\u998f\u81f3\u5173\u91cd\u8981\uff0cSRD\u63d0\u4f9b\u4e86\u5b9e\u73b0\u4e24\u8005\u7684\u6846\u67b6\u3002"}}
{"id": "2508.06411", "pdf": "https://arxiv.org/pdf/2508.06411", "abs": "https://arxiv.org/abs/2508.06411", "authors": ["Ze Shen Chin"], "title": "Dimensional Characterization and Pathway Modeling for Catastrophic AI Risks", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "24 pages including references, 6 figures. To be presented in\n  Technical AI Governance Forum 2025", "summary": "Although discourse around the risks of Artificial Intelligence (AI) has\ngrown, it often lacks a comprehensive, multidimensional framework, and concrete\ncausal pathways mapping hazard to harm. This paper aims to bridge this gap by\nexamining six commonly discussed AI catastrophic risks: CBRN, cyber offense,\nsudden loss of control, gradual loss of control, environmental risk, and\ngeopolitical risk. First, we characterize these risks across seven key\ndimensions, namely intent, competency, entity, polarity, linearity, reach, and\norder. Next, we conduct risk pathway modeling by mapping step-by-step\nprogressions from the initial hazard to the resulting harms. The dimensional\napproach supports systematic risk identification and generalizable mitigation\nstrategies, while risk pathway models help identify scenario-specific\ninterventions. Together, these methods offer a more structured and actionable\nfoundation for managing catastrophic AI risks across the value chain.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u516d\u79cd\u5e38\u89c1\u7684\u4eba\u5de5\u667a\u80fd\u707e\u96be\u6027\u98ce\u9669\uff0c\u901a\u8fc7\u7ef4\u5ea6\u5206\u6790\u548c\u98ce\u9669\u8def\u5f84\u5efa\u6a21\uff0c\u4e3a\u7ba1\u7406\u4eba\u5de5\u667a\u80fd\u98ce\u9669\u63d0\u4f9b\u7ed3\u6784\u5316\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u4eba\u5de5\u667a\u80fd\u98ce\u9669\u7684\u8ba8\u8bba\u7f3a\u4e4f\u5168\u9762\u3001\u591a\u7ef4\u6846\u67b6\u548c\u5177\u4f53\u56e0\u679c\u8def\u5f84\uff0c\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5bf9\u516d\u79cd\u98ce\u9669\u5728\u4e03\u4e2a\u5173\u952e\u7ef4\u5ea6\u8fdb\u884c\u7279\u5f81\u63cf\u8ff0\uff0c\u5e76\u8fdb\u884c\u98ce\u9669\u8def\u5f84\u5efa\u6a21\uff0c\u63cf\u7ed8\u4ece\u521d\u59cb\u5371\u9669\u5230\u6700\u7ec8\u5371\u5bb3\u7684\u9010\u6b65\u8fc7\u7a0b\u3002", "result": "\u7ef4\u5ea6\u5206\u6790\u652f\u6301\u7cfb\u7edf\u7684\u98ce\u9669\u8bc6\u522b\u548c\u901a\u7528\u7f13\u89e3\u7b56\u7565\uff0c\u98ce\u9669\u8def\u5f84\u6a21\u578b\u6709\u52a9\u4e8e\u786e\u5b9a\u7279\u5b9a\u573a\u666f\u7684\u5e72\u9884\u63aa\u65bd\u3002", "conclusion": "\u8fd9\u4e9b\u65b9\u6cd5\u4e3a\u7ba1\u7406\u4eba\u5de5\u667a\u80fd\u5168\u4ef7\u503c\u94fe\u7684\u707e\u96be\u6027\u98ce\u9669\u63d0\u4f9b\u4e86\u66f4\u7ed3\u6784\u5316\u548c\u53ef\u64cd\u4f5c\u7684\u57fa\u7840\u3002"}}
{"id": "2508.06136", "pdf": "https://arxiv.org/pdf/2508.06136", "abs": "https://arxiv.org/abs/2508.06136", "authors": ["YoungChan Choi", "HengFei Wang", "YiHua Cheng", "Boeun Kim", "Hyung Jin Chang", "YoungGeun Choi", "Sang-Il Choi"], "title": "Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation", "categories": ["cs.CV", "cs.AI"], "comment": "9 pages, 5 figures, ACM Multimeida 2025 accepted", "summary": "We propose a novel 3D gaze redirection framework that leverages an explicit\n3D eyeball structure. Existing gaze redirection methods are typically based on\nneural radiance fields, which employ implicit neural representations via volume\nrendering. Unlike these NeRF-based approaches, where the rotation and\ntranslation of 3D representations are not explicitly modeled, we introduce a\ndedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian\nSplatting (3DGS). Our method generates photorealistic images that faithfully\nreproduce the desired gaze direction by explicitly rotating and translating the\n3D eyeball structure. In addition, we propose an adaptive deformation module\nthat enables the replication of subtle muscle movements around the eyes.\nThrough experiments conducted on the ETH-XGaze dataset, we demonstrate that our\nframework is capable of generating diverse novel gaze images, achieving\nsuperior image quality and gaze estimation accuracy compared to previous\nstate-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e3D\u773c\u7403\u7ed3\u6784\u76843D\u6ce8\u89c6\u91cd\u5b9a\u5411\u6846\u67b6\uff0c\u6709\u81ea\u9002\u5e94\u53d8\u5f62\u6a21\u5757\uff0c\u5b9e\u9a8c\u6548\u679c\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u795e\u7ecf\u8f90\u5c04\u573a\u7684\u6ce8\u89c6\u91cd\u5b9a\u5411\u65b9\u6cd5\u672a\u663e\u5f0f\u5efa\u6a213D\u8868\u793a\u7684\u65cb\u8f6c\u548c\u5e73\u79fb\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u5f15\u51653D\u773c\u7403\u7ed3\u6784\u75283D\u9ad8\u65af\u6e85\u5c04\u8868\u793a\u773c\u7403\uff0c\u663e\u5f0f\u65cb\u8f6c\u548c\u5e73\u79fb\u8be5\u7ed3\u6784\u751f\u6210\u56fe\u50cf\uff0c\u8fd8\u6709\u81ea\u9002\u5e94\u53d8\u5f62\u6a21\u5757\u3002", "result": "\u5728ETH - XGaze\u6570\u636e\u96c6\u5b9e\u9a8c\u8868\u660e\uff0c\u80fd\u751f\u6210\u591a\u6837\u65b0\u6ce8\u89c6\u56fe\u50cf\uff0c\u56fe\u50cf\u8d28\u91cf\u548c\u6ce8\u89c6\u4f30\u8ba1\u7cbe\u5ea6\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u6709\u6548\uff0c\u5728\u6ce8\u89c6\u91cd\u5b9a\u5411\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002"}}
{"id": "2508.06433", "pdf": "https://arxiv.org/pdf/2508.06433", "abs": "https://arxiv.org/abs/2508.06433", "authors": ["Runnan Fang", "Yuan Liang", "Xiaobin Wang", "Jialong Wu", "Shuofei Qiao", "Pengjun Xie", "Fei Huang", "Huajun Chen", "Ningyu Zhang"], "title": "Memp: Exploring Agent Procedural Memory", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "comment": "Work in progress", "summary": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they\nsuffer from brittle procedural memory that is manually engineered or entangled\nin static parameters. In this work, we investigate strategies to endow agents\nwith a learnable, updatable, and lifelong procedural memory. We propose Memp\nthat distills past agent trajectories into both fine-grained, step-by-step\ninstructions and higher-level, script-like abstractions, and explore the impact\nof different strategies for Build, Retrieval, and Update of procedural memory.\nCoupled with a dynamic regimen that continuously updates, corrects, and\ndeprecates its contents, this repository evolves in lockstep with new\nexperience. Empirical evaluation on TravelPlanner and ALFWorld shows that as\nthe memory repository is refined, agents achieve steadily higher success rates\nand greater efficiency on analogous tasks. Moreover, procedural memory built\nfrom a stronger model retains its value: migrating the procedural memory to a\nweaker model yields substantial performance gains.", "AI": {"tldr": "\u7814\u7a76\u8d4b\u4e88\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u53ef\u5b66\u4e60\u3001\u53ef\u66f4\u65b0\u548c\u7ec8\u8eab\u7a0b\u5e8f\u8bb0\u5fc6\u7684\u7b56\u7565\uff0c\u63d0\u51faMemp\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u7a0b\u5e8f\u8bb0\u5fc6\u5b58\u5728\u624b\u52a8\u8bbe\u8ba1\u6216\u4e0e\u9759\u6001\u53c2\u6570\u7ea0\u7f20\u7684\u95ee\u9898\uff0c\u9700\u8981\u53ef\u5b66\u4e60\u3001\u53ef\u66f4\u65b0\u548c\u7ec8\u8eab\u7684\u7a0b\u5e8f\u8bb0\u5fc6\u3002", "method": "\u63d0\u51faMemp\uff0c\u5c06\u8fc7\u53bb\u4ee3\u7406\u8f68\u8ff9\u63d0\u70bc\u4e3a\u7ec6\u7c92\u5ea6\u6307\u4ee4\u548c\u9ad8\u7ea7\u62bd\u8c61\uff0c\u63a2\u7d22\u6784\u5efa\u3001\u68c0\u7d22\u548c\u66f4\u65b0\u7a0b\u5e8f\u8bb0\u5fc6\u7684\u4e0d\u540c\u7b56\u7565\uff0c\u7ed3\u5408\u52a8\u6001\u673a\u5236\u66f4\u65b0\u5185\u5bb9\u3002", "result": "\u5728TravelPlanner\u548cALFWorld\u4e0a\uff0c\u968f\u7740\u8bb0\u5fc6\u5e93\u5b8c\u5584\uff0c\u4ee3\u7406\u5728\u7c7b\u4f3c\u4efb\u52a1\u4e0a\u6210\u529f\u7387\u548c\u6548\u7387\u63d0\u9ad8\uff0c\u5c06\u5f3a\u6a21\u578b\u7684\u7a0b\u5e8f\u8bb0\u5fc6\u8fc1\u79fb\u5230\u5f31\u6a21\u578b\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u6709\u6548\u4e3a\u4ee3\u7406\u8d4b\u4e88\u53ef\u5b66\u4e60\u3001\u53ef\u66f4\u65b0\u548c\u7ec8\u8eab\u7684\u7a0b\u5e8f\u8bb0\u5fc6\uff0c\u63d0\u5347\u4ee3\u7406\u6027\u80fd\u3002"}}
{"id": "2508.06452", "pdf": "https://arxiv.org/pdf/2508.06452", "abs": "https://arxiv.org/abs/2508.06452", "authors": ["Mattia Litrico", "Mario Valerio Giuffrida", "Sebastiano Battiato", "Devis Tuia"], "title": "TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Recent unsupervised domain adaptation (UDA) methods have shown great success\nin addressing classical domain shifts (e.g., synthetic-to-real), but they still\nsuffer under complex shifts (e.g. geographical shift), where both the\nbackground and object appearances differ significantly across domains. Prior\nworks showed that the language modality can help in the adaptation process,\nexhibiting more robustness to such complex shifts. In this paper, we introduce\nTRUST, a novel UDA approach that exploits the robustness of the language\nmodality to guide the adaptation of a vision model. TRUST generates\npseudo-labels for target samples from their captions and introduces a novel\nuncertainty estimation strategy that uses normalised CLIP similarity scores to\nestimate the uncertainty of the generated pseudo-labels. Such estimated\nuncertainty is then used to reweight the classification loss, mitigating the\nadverse effects of wrong pseudo-labels obtained from low-quality captions. To\nfurther increase the robustness of the vision model, we propose a multimodal\nsoft-contrastive learning loss that aligns the vision and language feature\nspaces, by leveraging captions to guide the contrastive training of the vision\nmodel on target images. In our contrastive loss, each pair of images acts as\nboth a positive and a negative pair and their feature representations are\nattracted and repulsed with a strength proportional to the similarity of their\ncaptions. This solution avoids the need for hardly determining positive and\nnegative pairs, which is critical in the UDA setting. Our approach outperforms\nprevious methods, setting the new state-of-the-art on classical (DomainNet) and\ncomplex (GeoNet) domain shifts. The code will be available upon acceptance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTRUST\uff0c\u4e00\u79cd\u5229\u7528\u8bed\u8a00\u6a21\u6001\u5f15\u5bfc\u89c6\u89c9\u6a21\u578b\u9002\u5e94\u7684\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u5728\u7ecf\u5178\u548c\u590d\u6742\u9886\u57df\u8f6c\u79fb\u4efb\u52a1\u4e0a\u53d6\u5f97\u65b0\u7684\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u5728\u590d\u6742\u9886\u57df\u8f6c\u79fb\uff08\u5982\u5730\u7406\u8f6c\u79fb\uff09\u4e0b\u6548\u679c\u4e0d\u4f73\uff0c\u8bed\u8a00\u6a21\u6001\u6709\u52a9\u4e8e\u9002\u5e94\u8fc7\u7a0b\u4e14\u5bf9\u590d\u6742\u8f6c\u79fb\u66f4\u9c81\u68d2\uff0c\u56e0\u6b64\u63d0\u51fa\u5229\u7528\u8bed\u8a00\u6a21\u6001\u7684\u65b9\u6cd5\u3002", "method": "TRUST\u4e3a\u76ee\u6807\u6837\u672c\u4ece\u5176\u5b57\u5e55\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7b56\u7565\u91cd\u65b0\u52a0\u6743\u5206\u7c7b\u635f\u5931\uff0c\u63d0\u51fa\u591a\u6a21\u6001\u8f6f\u5bf9\u6bd4\u5b66\u4e60\u635f\u5931\u6765\u5bf9\u9f50\u89c6\u89c9\u548c\u8bed\u8a00\u7279\u5f81\u7a7a\u95f4\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7ecf\u5178\uff08DomainNet\uff09\u548c\u590d\u6742\uff08GeoNet\uff09\u9886\u57df\u8f6c\u79fb\u4efb\u52a1\u4e0a\u8d85\u8d8a\u5148\u524d\u65b9\u6cd5\uff0c\u521b\u9020\u65b0\u7684\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684TRUST\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5229\u7528\u8bed\u8a00\u6a21\u6001\u7684\u9c81\u68d2\u6027\u63d0\u5347\u89c6\u89c9\u6a21\u578b\u5728\u9886\u57df\u81ea\u9002\u5e94\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2508.06165", "pdf": "https://arxiv.org/pdf/2508.06165", "abs": "https://arxiv.org/abs/2508.06165", "authors": ["Weitao Li", "Boran Xiang", "Xiaolong Wang", "Zhinan Gou", "Weizhi Ma", "Yang Liu"], "title": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities through two\ncomplementary paradigms: Retrieval-Augmented Generation (RAG), which enhances\nknowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),\nwhich optimizes complex reasoning abilities. However, these two capabilities\nare often developed in isolation, and existing efforts to unify them remain\nnarrow in scope-typically limited to open-domain QA with fixed retrieval\nsettings and task-specific assumptions. This lack of integration constrains\ngeneralization and limits the applicability of RAG-RL methods to broader\ndomains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a\ngeneral framework that unifies retrieval and reasoning through reinforcement\nlearning. UR2 introduces two key contributions: a difficulty-aware curriculum\ntraining that selectively invokes retrieval only for challenging problems, and\na hybrid knowledge access strategy combining domain-specific offline corpora\nwith LLM-generated summaries. These components are designed to enable dynamic\ncoordination between retrieval and reasoning, improving adaptability across a\ndiverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,\nand mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B\nand LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,\nachieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several\nbenchmarks. We have released all code, models, and data at\nhttps://github.com/Tsinghua-dhy/UR2.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u6846\u67b6 UR2 \u7ed3\u5408\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u5728\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u5e76\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709 RAG \u548c RLVR \u80fd\u529b\u5b64\u7acb\u53d1\u5c55\uff0c\u7edf\u4e00\u5c1d\u8bd5\u8303\u56f4\u7a84\uff0c\u7f3a\u4e4f\u96c6\u6210\u9650\u5236\u6cdb\u5316\u548c\u5e94\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51fa UR2 \u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7edf\u4e00\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u5305\u62ec\u56f0\u96be\u611f\u77e5\u8bfe\u7a0b\u8bad\u7ec3\u548c\u6df7\u5408\u77e5\u8bc6\u8bbf\u95ee\u7b56\u7565\u3002", "result": "UR2 \u5728\u591a\u4efb\u52a1\u5b9e\u9a8c\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709 RAG \u548c RL \u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u4e0e GPT - 4o - mini \u548c GPT - 4.1 - mini \u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "UR2 \u80fd\u5b9e\u73b0\u68c0\u7d22\u548c\u63a8\u7406\u7684\u52a8\u6001\u534f\u8c03\uff0c\u63d0\u9ad8\u8de8\u4efb\u52a1\u9002\u5e94\u6027\uff0c\u662f\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2508.06169", "pdf": "https://arxiv.org/pdf/2508.06169", "abs": "https://arxiv.org/abs/2508.06169", "authors": ["Wenpeng Xing", "Jie Chen", "Zaifeng Yang", "Changting Lin", "Jianfeng Dong", "Chaochao Chen", "Xun Zhou", "Meng Han"], "title": "UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Underwater 3D scene reconstruction faces severe challenges from light\nabsorption, scattering, and turbidity, which degrade geometry and color\nfidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF\nextensions such as SeaThru-NeRF incorporate physics-based models, their MLP\nreliance limits efficiency and spatial resolution in hazy environments. We\nintroduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for\nrobust underwater reconstruction. Key innovations include: (1) a plug-and-play\nlearnable underwater image formation module using voxel-based regression for\nspatially varying attenuation and backscatter; and (2) a Physics-Aware\nUncertainty Pruning (PAUP) branch that adaptively removes noisy floating\nGaussians via uncertainty scoring, ensuring artifact-free geometry. The\npipeline operates in training and rendering stages. During training, noisy\nGaussians are optimized end-to-end with underwater parameters, guided by PAUP\npruning and scattering modeling. In rendering, refined Gaussians produce clean\nUnattenuated Radiance Images (URIs) free from media effects, while learned\nphysics enable realistic Underwater Images (UWIs) with accurate light\ntransport. Experiments on SeaThru-NeRF and UWBundle datasets show superior\nperformance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on\nSeaThru-NeRF, with ~65% reduction in floating artifacts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u6c34\u4e0b\u91cd\u5efa\u7684\u65b0\u6846\u67b6UW - 3DGS\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u51cf\u5c11\u4e86\u6d6e\u52a8\u4f2a\u5f71\u3002", "motivation": "\u4f20\u7edf\u6c34\u4e0b3D\u573a\u666f\u91cd\u5efa\u65b9\u6cd5\u53d7\u5149\u7ebf\u5438\u6536\u3001\u6563\u5c04\u548c\u6d51\u6d4a\u5ea6\u5f71\u54cd\uff0cNeRF\u6269\u5c55\u5728\u6a21\u7cca\u73af\u5883\u4e0b\u6548\u7387\u548c\u7a7a\u95f4\u5206\u8fa8\u7387\u53d7\u9650\uff0c\u9700\u8981\u65b0\u7684\u6c34\u4e0b\u91cd\u5efa\u65b9\u6cd5\u3002", "method": "\u5f15\u5165UW - 3DGS\u6846\u67b6\uff0c\u5305\u542b\u53ef\u63d2\u62d4\u7684\u53ef\u5b66\u4e60\u6c34\u4e0b\u56fe\u50cf\u5f62\u6210\u6a21\u5757\u548c\u7269\u7406\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u526a\u679d\uff08PAUP\uff09\u5206\u652f\uff0c\u5206\u8bad\u7ec3\u548c\u6e32\u67d3\u9636\u6bb5\u5904\u7406\u3002", "result": "\u5728SeaThru - NeRF\u548cUWBundle\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5728SeaThru - NeRF\u4e0aPSNR\u4e3a27.604\u3001SSIM\u4e3a0.868\u3001LPIPS\u4e3a0.104\uff0c\u6d6e\u52a8\u4f2a\u5f71\u51cf\u5c11\u7ea665%\u3002", "conclusion": "UW - 3DGS\u6846\u67b6\u80fd\u6709\u6548\u8fdb\u884c\u6c34\u4e0b3D\u573a\u666f\u91cd\u5efa\uff0c\u51cf\u5c11\u4f2a\u5f71\uff0c\u5b9e\u73b0\u51c6\u786e\u7684\u5149\u7ebf\u4f20\u8f93\u3002"}}
{"id": "2508.06477", "pdf": "https://arxiv.org/pdf/2508.06477", "abs": "https://arxiv.org/abs/2508.06477", "authors": ["Llu\u00eds Arola-Fern\u00e1ndez"], "title": "Intuition emerges in Maximum Caliber models at criticality", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG"], "comment": null, "summary": "Whether large predictive models merely parrot their training data or produce\ngenuine insight lacks a physical explanation. This work reports a primitive\nform of intuition that emerges as a metastable phase of learning that\ncritically balances next-token prediction against future path-entropy. The\nintuition mechanism is discovered via mind-tuning, the minimal principle that\nimposes Maximum Caliber in predictive models with a control temperature-like\nparameter $\\lambda$. Training on random walks in deterministic mazes reveals a\nrich phase diagram: imitation (low $\\lambda$), rule-breaking hallucination\n(high $\\lambda$), and a fragile in-between window exhibiting strong\nprotocol-dependence (hysteresis) and multistability, where models spontaneously\ndiscover novel goal-directed strategies. These results are captured by an\neffective low-dimensional theory and frame intuition as an emergent property at\nthe critical balance between memorizing what is and wondering what could be.", "AI": {"tldr": "\u7814\u7a76\u5927\u9884\u6d4b\u6a21\u578b\u76f4\u89c9\u673a\u5236\uff0c\u53d1\u73b0\u5176\u4e3a\u5b66\u4e60\u4e9a\u7a33\u76f8\uff0c\u901a\u8fc7\u8c03\u53c2\u5448\u73b0\u4e0d\u540c\u9636\u6bb5\u3002", "motivation": "\u4e3a\u5927\u9884\u6d4b\u6a21\u578b\u662f\u7b80\u5355\u91cd\u590d\u8bad\u7ec3\u6570\u636e\u8fd8\u662f\u4ea7\u751f\u771f\u6b63\u89c1\u89e3\u7f3a\u4e4f\u7269\u7406\u89e3\u91ca\u8fd9\u4e00\u95ee\u9898\u63d0\u4f9b\u89e3\u91ca\u3002", "method": "\u901a\u8fc7mind - tuning\uff08\u4ee5\u7c7b\u4f3c\u63a7\u5236\u6e29\u5ea6\u53c2\u6570\u03bb\u65bd\u52a0\u6700\u5927\u53e3\u5f84\u539f\u7406\uff09\uff0c\u5728\u786e\u5b9a\u6027\u8ff7\u5bab\u968f\u673a\u6e38\u8d70\u8bad\u7ec3\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u4e30\u5bcc\u76f8\u56fe\uff0c\u5305\u62ec\u6a21\u4eff\u3001\u89c4\u5219\u7834\u574f\u5e7b\u89c9\u548c\u4e2d\u95f4\u8106\u5f31\u7a97\u53e3\uff0c\u6a21\u578b\u80fd\u81ea\u53d1\u53d1\u73b0\u65b0\u7684\u76ee\u6807\u5bfc\u5411\u7b56\u7565\u3002", "conclusion": "\u76f4\u89c9\u662f\u5728\u8bb0\u5fc6\u73b0\u6709\u548c\u601d\u8003\u53ef\u80fd\u4e4b\u95f4\u4e34\u754c\u5e73\u8861\u65f6\u7684\u6d8c\u73b0\u5c5e\u6027\u3002"}}
{"id": "2508.06170", "pdf": "https://arxiv.org/pdf/2508.06170", "abs": "https://arxiv.org/abs/2508.06170", "authors": ["Ojonugwa Oluwafemi Ejiga Peter", "Akingbola Oluwapemiisin", "Amalahu Chetachi", "Adeniran Opeyemi", "Fahmi Khalifa", "Md Mahmudur Rahman"], "title": "Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Colonoscopy is a vital tool for the early diagnosis of colorectal cancer,\nwhich is one of the main causes of cancer-related mortality globally; hence, it\nis deemed an essential technique for the prevention and early detection of\ncolorectal cancer. The research introduces a unique multidirectional\narchitectural framework to automate polyp detection within colonoscopy images\nwhile helping resolve limited healthcare dataset sizes and annotation\ncomplexities. The research implements a comprehensive system that delivers\nsynthetic data generation through Stable Diffusion enhancements together with\ndetection and segmentation algorithms. This detection approach combines Faster\nR-CNN for initial object localization while the Segment Anything Model (SAM)\nrefines the segmentation masks. The faster R-CNN detection algorithm achieved a\nrecall of 93.08% combined with a precision of 88.97% and an F1 score of\n90.98%.SAM is then used to generate the image mask. The research evaluated five\nstate-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet,\nand MANet using ResNet34 as a base model. The results demonstrate the superior\nperformance of FPN with the highest scores of PSNR (7.205893) and SSIM\n(0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced\nperformance in IoU (64.20%) and Dice score (77.53%).", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u591a\u5411\u67b6\u6784\u6846\u67b6\u7528\u4e8e\u7ed3\u80a0\u955c\u56fe\u50cf\u606f\u8089\u81ea\u52a8\u68c0\u6d4b\uff0c\u7ed3\u5408\u5408\u6210\u6570\u636e\u751f\u6210\u3001\u68c0\u6d4b\u4e0e\u5206\u5272\u7b97\u6cd5\uff0c\u8bc4\u4f30\u591a\u79cd\u5206\u5272\u6a21\u578b\uff0c\u5404\u6709\u8868\u73b0\u3002", "motivation": "\u7ed3\u80a0\u955c\u68c0\u67e5\u5bf9\u7ed3\u76f4\u80a0\u764c\u65e9\u8bca\u91cd\u8981\uff0c\u89e3\u51b3\u533b\u7597\u6570\u636e\u96c6\u5c0f\u548c\u6807\u6ce8\u590d\u6742\u95ee\u9898\u3002", "method": "\u5f15\u5165\u591a\u5411\u67b6\u6784\u6846\u67b6\uff0c\u7528Stable Diffusion\u589e\u5f3a\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u7ed3\u5408Faster R - CNN\u5b9a\u4f4d\u548cSAM\u7ec6\u5316\u5206\u5272\u63a9\u7801\uff0c\u8bc4\u4f30\u4e94\u79cd\u5206\u5272\u6a21\u578b\u3002", "result": "Faster R - CNN\u53ec\u56de\u738793.08%\u3001\u7cbe\u5ea688.97%\u3001F1\u5206\u657090.98%\uff1bFPN\u7684PSNR\u548cSSIM\u5f97\u5206\u6700\u9ad8\uff0cUNet\u53ec\u56de\u7387\u4f18\uff0cLinkNet\u7684IoU\u548cDice\u5f97\u5206\u8868\u73b0\u5e73\u8861\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7ed3\u80a0\u955c\u56fe\u50cf\u606f\u8089\u68c0\u6d4b\u548c\u5206\u5272\u4e2d\u6709\u4e00\u5b9a\u6548\u679c\uff0c\u4e0d\u540c\u6a21\u578b\u6709\u4e0d\u540c\u4f18\u52bf\u3002"}}
{"id": "2508.06482", "pdf": "https://arxiv.org/pdf/2508.06482", "abs": "https://arxiv.org/abs/2508.06482", "authors": ["Yilun Hua", "Evan Wang", "Yoav Artzi"], "title": "Post-training for Efficient Communication via Convention Formation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted to COLM 2025", "summary": "Humans communicate with increasing efficiency in multi-turn interactions, by\nadapting their language and forming ad-hoc conventions. In contrast, prior work\nshows that LLMs do not naturally show this behavior. We develop a post-training\nprocess to develop this ability through targeted fine-tuning on heuristically\nidentified demonstrations of convention formation. We evaluate with two new\nbenchmarks focused on this capability. First, we design a focused,\ncognitively-motivated interaction benchmark that consistently elicits strong\nconvention formation trends in humans. Second, we create a new\ndocument-grounded reference completion task that reflects in-the-wild\nconvention formation behavior. Our studies show significantly improved\nconvention formation abilities in post-trained LLMs across the two evaluation\nmethods.", "AI": {"tldr": "\u5f00\u53d1\u540e\u8bad\u7ec3\u8fc7\u7a0b\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5f62\u6210\u4e34\u65f6\u7ea6\u5b9a\u7684\u80fd\u529b\uff0c\u7ecf\u4e24\u4e2a\u65b0\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u80fd\u529b\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4eba\u7c7b\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u80fd\u63d0\u9ad8\u6c9f\u901a\u6548\u7387\u5e76\u5f62\u6210\u4e34\u65f6\u7ea6\u5b9a\uff0c\u800c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u6b64\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5bf9\u542f\u53d1\u5f0f\u8bc6\u522b\u51fa\u7684\u7ea6\u5b9a\u5f62\u6210\u793a\u4f8b\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u5fae\u8c03\u5f00\u5c55\u540e\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5e76\u7528\u4e24\u4e2a\u65b0\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ecf\u4e24\u79cd\u8bc4\u4f30\u65b9\u6cd5\u6d4b\u8bd5\uff0c\u540e\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ea6\u5b9a\u5f62\u6210\u80fd\u529b\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6240\u5f00\u53d1\u7684\u540e\u8bad\u7ec3\u8fc7\u7a0b\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5f62\u6210\u7ea6\u5b9a\u7684\u80fd\u529b\u3002"}}
{"id": "2508.06485", "pdf": "https://arxiv.org/pdf/2508.06485", "abs": "https://arxiv.org/abs/2508.06485", "authors": ["Sofiane Bouaziz", "Adel Hafiane", "Raphael Canals", "Rachid Nedjai"], "title": "WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Submitted to IEEE Transactions on Geoscience and Remote Sensing\n  (TGRS)", "summary": "Urbanization, climate change, and agricultural stress are increasing the\ndemand for precise and timely environmental monitoring. Land Surface\nTemperature (LST) is a key variable in this context and is retrieved from\nremote sensing satellites. However, these systems face a trade-off between\nspatial and temporal resolution. While spatio-temporal fusion methods offer\npromising solutions, few have addressed the estimation of daily LST at 10 m\nresolution. In this study, we present WGAST, a Weakly-Supervised Generative\nNetwork for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra\nMODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning\nframework designed for this task. It adopts a conditional generative\nadversarial architecture, with a generator composed of four stages: feature\nextraction, fusion, LST reconstruction, and noise suppression. The first stage\nemploys a set of encoders to extract multi-level latent representations from\nthe inputs, which are then fused in the second stage using cosine similarity,\nnormalization, and temporal attention mechanisms. The third stage decodes the\nfused features into high-resolution LST, followed by a Gaussian filter to\nsuppress high-frequency noise. Training follows a weakly supervised strategy\nbased on physical averaging principles and reinforced by a PatchGAN\ndiscriminator. Experiments demonstrate that WGAST outperforms existing methods\nin both quantitative and qualitative evaluations. Compared to the\nbest-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves\nSSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and\neffectively captures fine-scale thermal patterns, as validated against 33\nground-based sensors. The code is available at\nhttps://github.com/Sofianebouaziz1/WGAST.git.", "AI": {"tldr": "\u63d0\u51faWGAST\u6846\u67b6\u7528\u4e8e\u6bcf\u65e510\u7c73\u5206\u8fa8\u7387LST\u4f30\u8ba1\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u57ce\u5e02\u5316\u3001\u6c14\u5019\u53d8\u5316\u548c\u519c\u4e1a\u538b\u529b\u589e\u52a0\u5bf9\u7cbe\u786e\u53ca\u65f6\u73af\u5883\u76d1\u6d4b\u7684\u9700\u6c42\uff0c\u73b0\u6709\u7cfb\u7edf\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u5206\u8fa8\u7387\u4e0a\u5b58\u5728\u6743\u8861\uff0c\u5c11\u6709\u65b9\u6cd5\u80fd\u4f30\u8ba110\u7c73\u5206\u8fa8\u7387\u7684\u6bcf\u65e5LST\u3002", "method": "\u63d0\u51faWGAST\uff0c\u91c7\u7528\u6761\u4ef6\u751f\u6210\u5bf9\u6297\u67b6\u6784\uff0c\u751f\u6210\u5668\u5206\u7279\u5f81\u63d0\u53d6\u3001\u878d\u5408\u3001LST\u91cd\u5efa\u548c\u566a\u58f0\u6291\u5236\u56db\u4e2a\u9636\u6bb5\uff0c\u8bad\u7ec3\u91c7\u7528\u5f31\u76d1\u7763\u7b56\u7565\u5e76\u7531PatchGAN\u9274\u522b\u5668\u5f3a\u5316\u3002", "result": "WGAST\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e73\u5747\u964d\u4f4eRMSE 17.18%\uff0c\u63d0\u9ad8SSIM 11.00%\uff0c\u5bf9\u4e91\u81f4LST\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u6709\u6548\u6355\u6349\u7cbe\u7ec6\u70ed\u6a21\u5f0f\u3002", "conclusion": "WGAST\u662f\u9996\u4e2a\u7528\u4e8e\u6b64\u4efb\u52a1\u7684\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u6027\u80fd\u826f\u597d\uff0c\u4ee3\u7801\u516c\u5f00\u3002"}}
{"id": "2508.06490", "pdf": "https://arxiv.org/pdf/2508.06490", "abs": "https://arxiv.org/abs/2508.06490", "authors": ["Stanislas Ducotterd", "Michael Unser"], "title": "Multivariate Fields of Experts", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "comment": null, "summary": "We introduce the multivariate fields of experts, a new framework for the\nlearning of image priors. Our model generalizes existing fields of experts\nmethods by incorporating multivariate potential functions constructed via\nMoreau envelopes of the $\\ell_\\infty$-norm. We demonstrate the effectiveness of\nour proposal across a range of inverse problems that include image denoising,\ndeblurring, compressed-sensing magnetic-resonance imaging, and computed\ntomography. The proposed approach outperforms comparable univariate models and\nachieves performance close to that of deep-learning-based regularizers while\nbeing significantly faster, requiring fewer parameters, and being trained on\nsubstantially fewer data. In addition, our model retains a relatively high\nlevel of interpretability due to its structured design.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2508.06202", "pdf": "https://arxiv.org/pdf/2508.06202", "abs": "https://arxiv.org/abs/2508.06202", "authors": ["Chang Che", "Ziqi Wang", "Pengwan Yang", "Qi Wang", "Hui Ma", "Zenglin Shi"], "title": "LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language\nModels (MLLMs) to incrementally learn new tasks over time. However, this\nprocess is challenged by catastrophic forgetting, where performance on\npreviously learned tasks deteriorates as the model adapts to new ones. A common\napproach to mitigate forgetting is architecture expansion, which introduces\ntask-specific modules to prevent interference. Yet, existing methods often\nexpand entire layers for each task, leading to significant parameter overhead\nand poor scalability. To overcome these issues, we introduce LoRA in LoRA\n(LiLoRA), a highly efficient architecture expansion method tailored for CVIT in\nMLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy,\napplies an additional low-rank decomposition to matrix B to minimize\ntask-specific parameters, and incorporates a cosine-regularized stability loss\nto preserve consistency in shared representations over time. Extensive\nexperiments on a diverse CVIT benchmark show that LiLoRA consistently achieves\nsuperior performance in sequential task learning while significantly improving\nparameter efficiency compared to existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u7684\u9ad8\u6548\u67b6\u6784\u6269\u5c55\u65b9\u6cd5LiLoRA\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u987a\u5e8f\u4efb\u52a1\u5b66\u4e60\u4e2d\u8868\u73b0\u4f18\u4e14\u53c2\u6570\u6548\u7387\u9ad8\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u73b0\u6709\u67b6\u6784\u6269\u5c55\u65b9\u6cd5\u53c2\u6570\u5f00\u9500\u5927\u3001\u53ef\u6269\u5c55\u6027\u5dee\u3002", "method": "\u5f15\u5165LiLoRA\uff0c\u8de8\u4efb\u52a1\u5171\u4eabLoRA\u77e9\u9635A\uff0c\u5bf9\u77e9\u9635B\u8fdb\u884c\u989d\u5916\u4f4e\u79e9\u5206\u89e3\uff0c\u5f15\u5165\u4f59\u5f26\u6b63\u5219\u5316\u7a33\u5b9a\u6027\u635f\u5931\u3002", "result": "\u5728\u591a\u6837\u7684\u6301\u7eed\u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLiLoRA\u5728\u987a\u5e8f\u4efb\u52a1\u5b66\u4e60\u4e2d\u59cb\u7ec8\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u53c2\u6570\u6548\u7387\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "LiLoRA\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u67b6\u6784\u6269\u5c55\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u7684\u95ee\u9898\u3002"}}
{"id": "2508.06220", "pdf": "https://arxiv.org/pdf/2508.06220", "abs": "https://arxiv.org/abs/2508.06220", "authors": ["Keummin Ka", "Junhyeong Park", "Jahyun Jeon", "Youngjae Yu"], "title": "InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?", "categories": ["cs.CL", "cs.AI"], "comment": "14 pages, 9 figures", "summary": "Recent advances in Vision-Language Models (VLMs) have demonstrated impressive\ncapabilities in perception and reasoning. However, the ability to perform\ncausal inference -- a core aspect of human cognition -- remains underexplored,\nparticularly in multimodal settings. In this study, we introduce InfoCausalQA,\na novel benchmark designed to evaluate causal reasoning grounded in\ninfographics that combine structured visual data with textual context. The\nbenchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning\nbased on inferred numerical trends, while Task 2 targets semantic causal\nreasoning involving five types of causal relations: cause, effect,\nintervention, counterfactual, and temporal. We manually collected 494\ninfographic-text pairs from four public sources and used GPT-4o to generate\n1,482 high-quality multiple-choice QA pairs. These questions were then\ncarefully revised by humans to ensure they cannot be answered based on\nsurface-level cues alone but instead require genuine visual grounding. Our\nexperimental results reveal that current VLMs exhibit limited capability in\ncomputational reasoning and even more pronounced limitations in semantic causal\nreasoning. Their significantly lower performance compared to humans indicates a\nsubstantial gap in leveraging infographic-based information for causal\ninference. Through InfoCausalQA, we highlight the need for advancing the causal\nreasoning abilities of multimodal AI systems.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165InfoCausalQA\u57fa\u51c6\u8bc4\u4f30\u591a\u6a21\u6001\u4e0b\u57fa\u4e8e\u4fe1\u606f\u56fe\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dVLMs\u5728\u56e0\u679c\u63a8\u7406\u4e0a\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u56e0\u679c\u63a8\u7406\u80fd\u529b\u4e0a\u63a2\u7d22\u4e0d\u8db3\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5f15\u5165InfoCausalQA\u57fa\u51c6\uff0c\u5305\u542b\u4e24\u4e2a\u4efb\u52a1\uff0c\u624b\u52a8\u6536\u96c6494\u4e2a\u4fe1\u606f\u56fe - \u6587\u672c\u5bf9\uff0c\u7528GPT - 4o\u751f\u62101482\u4e2a\u9ad8\u8d28\u91cf\u9009\u62e9\u9898\u5bf9\u5e76\u7ecf\u4eba\u5de5\u4fee\u8ba2\u3002", "result": "\u5f53\u524dVLMs\u5728\u8ba1\u7b97\u63a8\u7406\u548c\u8bed\u4e49\u56e0\u679c\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u4e0e\u4eba\u7c7b\u8868\u73b0\u5dee\u8ddd\u5927\u3002", "conclusion": "\u5f3a\u8c03\u63d0\u5347\u591a\u6a21\u6001AI\u7cfb\u7edf\u56e0\u679c\u63a8\u7406\u80fd\u529b\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2508.06259", "pdf": "https://arxiv.org/pdf/2508.06259", "abs": "https://arxiv.org/abs/2508.06259", "authors": ["Zhangquan Chen", "Ruihui Zhao", "Chuwei Luo", "Mingze Sun", "Xinlei Yu", "Yangyang Kang", "Ruqi Huang"], "title": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "categories": ["cs.CV", "cs.AI", "I.2.10"], "comment": "15 pages, 13 figures", "summary": "Current multimodal large language models (MLLMs) still face significant\nchallenges in complex visual tasks (e.g., spatial understanding, fine-grained\nperception). Prior methods have tried to incorporate visual reasoning, however,\nthey fail to leverage attention correction with spatial cues to iteratively\nrefine their focus on prompt-relevant regions. In this paper, we introduce\nSIFThinker, a spatially-aware \"think-with-images\" framework that mimics human\nvisual perception. Specifically, SIFThinker enables attention correcting and\nimage region focusing by interleaving depth-enhanced bounding boxes and natural\nlanguage. Our contributions are twofold: First, we introduce a\nreverse-expansion-forward-inference strategy that facilitates the generation of\ninterleaved image-text chains of thought for process-level supervision, which\nin turn leads to the construction of the SIF-50K dataset. Besides, we propose\nGRPO-SIF, a reinforced training paradigm that integrates depth-informed visual\ngrounding into a unified reasoning pipeline, teaching the model to dynamically\ncorrect and focus on prompt-relevant regions. Extensive experiments demonstrate\nthat SIFThinker outperforms state-of-the-art methods in spatial understanding\nand fine-grained visual perception, while maintaining strong general\ncapabilities, highlighting the effectiveness of our method.", "AI": {"tldr": "\u63d0\u51faSIFThinker\u6846\u67b6\u89e3\u51b3MLLMs\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u6311\u6218\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6027\u80fd\u4f18\u8d8a\u3002", "motivation": "\u5f53\u524dMLLMs\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u6709\u6311\u6218\uff0c\u4ee5\u5f80\u65b9\u6cd5\u672a\u80fd\u5229\u7528\u7a7a\u95f4\u7ebf\u7d22\u8fdb\u884c\u6ce8\u610f\u529b\u6821\u6b63\u3002", "method": "\u5f15\u5165\u53cd\u5411\u6269\u5c55 - \u6b63\u5411\u63a8\u7406\u7b56\u7565\u6784\u5efaSIF - 50K\u6570\u636e\u96c6\uff1b\u63d0\u51faGRPO - SIF\u5f3a\u5316\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "SIFThinker\u5728\u7a7a\u95f4\u7406\u89e3\u548c\u7ec6\u7c92\u5ea6\u89c6\u89c9\u611f\u77e5\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u4fdd\u6301\u5f3a\u5927\u901a\u7528\u80fd\u529b\u3002", "conclusion": "SIFThinker\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2508.06264", "pdf": "https://arxiv.org/pdf/2508.06264", "abs": "https://arxiv.org/abs/2508.06264", "authors": ["Randal E. Bryant"], "title": "Numerical Considerations in Weighted Model Counting", "categories": ["math.NA", "cs.AI", "cs.LO", "cs.NA"], "comment": null, "summary": "Weighted model counting computes the sum of the rational-valued weights\nassociated with the satisfying assignments for a Boolean formula, where the\nweight of an assignment is given by the product of the weights assigned to the\npositive and negated variables comprising the assignment. Weighted model\ncounting finds applications across a variety of domains including probabilistic\nreasoning and quantitative risk assessment.\n  Most weighted model counting programs operate by (explicitly or implicitly)\nconverting the input formula into a form that enables arithmetic evaluation,\nusing multiplication for conjunctions and addition for disjunctions. Performing\nthis evaluation using floating-point arithmetic can yield inaccurate results,\nand it cannot quantify the level of precision achieved. Computing with rational\narithmetic gives exact results, but it is costly in both time and space.\n  This paper describes how to combine multiple numeric representations to\nefficiently compute weighted model counts that are guaranteed to achieve a\nuser-specified precision. When all weights are nonnegative, we prove that the\nprecision loss of arithmetic evaluation using floating-point arithmetic can be\ntightly bounded. We show that supplementing a standard IEEE double-precision\nrepresentation with a separate 64-bit exponent, a format we call extended-range\ndouble (ERD), avoids the underflow and overflow issues commonly encountered in\nweighted model counting. For problems with mixed negative and positive weights,\nwe show that a combination of interval floating-point arithmetic and rational\narithmetic can achieve the twin goals of efficiency and guaranteed precision.\nFor our evaluations, we have devised especially challenging formulas and weight\nassignments, demonstrating the robustness of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u591a\u79cd\u6570\u503c\u8868\u793a\u6cd5\u6765\u9ad8\u6548\u8ba1\u7b97\u52a0\u6743\u6a21\u578b\u8ba1\u6570\uff0c\u4fdd\u8bc1\u8fbe\u5230\u7528\u6237\u6307\u5b9a\u7cbe\u5ea6\uff0c\u5bf9\u4e0d\u540c\u6743\u91cd\u60c5\u51b5\u7ed9\u51fa\u65b9\u6cd5\u5e76\u901a\u8fc7\u8bc4\u4f30\u9a8c\u8bc1\u5176\u9c81\u68d2\u6027\u3002", "motivation": "\u6d6e\u70b9\u8fd0\u7b97\u8ba1\u7b97\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u7ed3\u679c\u4e0d\u51c6\u786e\u4e14\u65e0\u6cd5\u91cf\u5316\u7cbe\u5ea6\uff0c\u6709\u7406\u6570\u8fd0\u7b97\u65f6\u7a7a\u6210\u672c\u9ad8\uff0c\u9700\u66f4\u4f18\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u591a\u79cd\u6570\u503c\u8868\u793a\u6cd5\uff0c\u975e\u8d1f\u6743\u91cd\u65f6\u7528\u6269\u5c55\u8303\u56f4\u53cc\u7cbe\u5ea6\u683c\u5f0f\u907f\u514d\u6ea2\u51fa\uff0c\u6b63\u8d1f\u6df7\u5408\u6743\u91cd\u65f6\u7ed3\u5408\u533a\u95f4\u6d6e\u70b9\u548c\u6709\u7406\u6570\u8fd0\u7b97\u3002", "result": "\u8bc1\u660e\u975e\u8d1f\u6743\u91cd\u65f6\u6d6e\u70b9\u8fd0\u7b97\u7cbe\u5ea6\u635f\u5931\u53ef\u88ab\u7d27\u5bc6\u754c\u5b9a\uff0c\u9a8c\u8bc1\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u7ed3\u5408\u591a\u79cd\u6570\u503c\u8868\u793a\u6cd5\u7684\u65b9\u6cd5\u80fd\u9ad8\u6548\u8ba1\u7b97\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u5e76\u4fdd\u8bc1\u6307\u5b9a\u7cbe\u5ea6\u3002"}}
{"id": "2508.06287", "pdf": "https://arxiv.org/pdf/2508.06287", "abs": "https://arxiv.org/abs/2508.06287", "authors": ["Mobarak Abumohsen", "Enrique Costa-Montenegro", "Silvia Garc\u00eda-M\u00e9ndez", "Amani Yousef Owda", "Majdi Owda"], "title": "Advanced Deep Learning Techniques for Accurate Lung Cancer Detection and Classification", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Lung cancer (LC) ranks among the most frequently diagnosed cancers and is one\nof the most common causes of death for men and women worldwide. Computed\nTomography (CT) images are the most preferred diagnosis method because of their\nlow cost and their faster processing times. Many researchers have proposed\nvarious ways of identifying lung cancer using CT images. However, such\ntechniques suffer from significant false positives, leading to low accuracy.\nThe fundamental reason results from employing a small and imbalanced dataset.\nThis paper introduces an innovative approach for LC detection and\nclassification from CT images based on the DenseNet201 model. Our approach\ncomprises several advanced methods such as Focal Loss, data augmentation, and\nregularization to overcome the imbalanced data issue and overfitting challenge.\nThe findings show the appropriateness of the proposal, attaining a promising\nperformance of 98.95% accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eDenseNet201\u6a21\u578b\u7684\u80ba\u764c\u68c0\u6d4b\u4e0e\u5206\u7c7b\u65b9\u6cd5\uff0c\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u548c\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u51c6\u786e\u7387\u8fbe98.95%\u3002", "motivation": "\u73b0\u6709CT\u56fe\u50cf\u8bc6\u522b\u80ba\u764c\u6280\u672f\u56e0\u5c0f\u800c\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u5bfc\u81f4\u5047\u9633\u6027\u591a\u3001\u51c6\u786e\u7387\u4f4e\uff0c\u9700\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eDenseNet201\u6a21\u578b\uff0c\u91c7\u7528Focal Loss\u3001\u6570\u636e\u589e\u5f3a\u548c\u6b63\u5219\u5316\u7b49\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u8868\u73b0\u826f\u597d\uff0c\u51c6\u786e\u7387\u8fbe98.95%\u3002", "conclusion": "\u8be5\u521b\u65b0\u65b9\u6cd5\u9002\u7528\u4e8eCT\u56fe\u50cf\u7684\u80ba\u764c\u68c0\u6d4b\u4e0e\u5206\u7c7b\u3002"}}
{"id": "2508.06318", "pdf": "https://arxiv.org/pdf/2508.06318", "abs": "https://arxiv.org/abs/2508.06318", "authors": ["Giacomo D'Amicantonio", "Snehashis Majhi", "Quan Kong", "Lorenzo Garattoni", "Gianpiero Francesca", "Fran\u00e7ois Bremond", "Egor Bondarev"], "title": "Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video Anomaly Detection (VAD) is a challenging task due to the variability of\nanomalous events and the limited availability of labeled data. Under the\nWeakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided\nduring training, while predictions are made at the frame level. Although\nstate-of-the-art models perform well on simple anomalies (e.g., explosions),\nthey struggle with complex real-world events (e.g., shoplifting). This\ndifficulty stems from two key issues: (1) the inability of current models to\naddress the diversity of anomaly types, as they process all categories with a\nshared model, overlooking category-specific features; and (2) the weak\nsupervision signal, which lacks precise temporal information, limiting the\nability to capture nuanced anomalous patterns blended with normal events. To\naddress these challenges, we propose Gaussian Splatting-guided Mixture of\nExperts (GS-MoE), a novel framework that employs a set of expert models, each\nspecialized in capturing specific anomaly types. These experts are guided by a\ntemporal Gaussian splatting loss, enabling the model to leverage temporal\nconsistency and enhance weak supervision. The Gaussian splatting approach\nencourages a more precise and comprehensive representation of anomalies by\nfocusing on temporal segments most likely to contain abnormal events. The\npredictions from these specialized experts are integrated through a\nmixture-of-experts mechanism to model complex relationships across diverse\nanomaly patterns. Our approach achieves state-of-the-art performance, with a\n91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on\nXD-Violence and MSAD datasets. By leveraging category-specific expertise and\ntemporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.", "AI": {"tldr": "\u63d0\u51faGS - MoE\u6846\u67b6\u89e3\u51b3\u5f31\u76d1\u7763\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\u96be\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u83b7SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f31\u76d1\u7763\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u96be\u4ee5\u5904\u7406\u590d\u6742\u771f\u5b9e\u4e8b\u4ef6\uff0c\u5b58\u5728\u65e0\u6cd5\u5e94\u5bf9\u5f02\u5e38\u7c7b\u578b\u591a\u6837\u6027\u548c\u5f31\u76d1\u7763\u4fe1\u53f7\u7f3a\u4e4f\u7cbe\u786e\u65f6\u95f4\u4fe1\u606f\u95ee\u9898\u3002", "method": "\u63d0\u51faGS - MoE\u6846\u67b6\uff0c\u7528\u4e00\u7ec4\u4e13\u5bb6\u6a21\u578b\u6355\u6349\u7279\u5b9a\u5f02\u5e38\u7c7b\u578b\uff0c\u7531\u65f6\u95f4\u9ad8\u65af\u6563\u70b9\u635f\u5931\u5f15\u5bfc\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u673a\u5236\u6574\u5408\u9884\u6d4b\u3002", "result": "\u5728UCF - Crime\u6570\u636e\u96c6AUC\u8fbe91.58%\uff0c\u5728XD - Violence\u548cMSAD\u6570\u636e\u96c6\u7ed3\u679c\u4f18\u8d8a\u3002", "conclusion": "GS - MoE\u5229\u7528\u7279\u5b9a\u7c7b\u522b\u4e13\u4e1a\u77e5\u8bc6\u548c\u65f6\u95f4\u5f15\u5bfc\uff0c\u4e3a\u5f31\u76d1\u7763\u89c6\u9891\u5f02\u5e38\u68c0\u6d4b\u8bbe\u65b0\u57fa\u51c6\u3002"}}
{"id": "2508.06343", "pdf": "https://arxiv.org/pdf/2508.06343", "abs": "https://arxiv.org/abs/2508.06343", "authors": ["V\u00e1clav Bla\u017eej", "Micha\u0142 D\u0119bski ad Zbigniew Lonc", "Marta Piecyk", "Pawe\u0142 Rz\u0105\u017cewski"], "title": "On Approximate MMS Allocations on Restricted Graph Classes", "categories": ["cs.DM", "cs.AI"], "comment": null, "summary": "We study the problem of fair division of a set of indivisible goods with\nconnectivity constraints. Specifically, we assume that the goods are\nrepresented as vertices of a connected graph, and sets of goods allocated to\nthe agents are connected subgraphs of this graph. We focus on the\nwidely-studied maximin share criterion of fairness. It has been shown that an\nallocation satisfying this criterion may not exist even without connectivity\nconstraints, i.e., if the graph of goods is complete. In view of this, it is\nnatural to seek approximate allocations that guarantee each agent a connected\nbundle of goods with value at least a constant fraction of the maximin share\nvalue to the agent. It is known that for some classes of graphs, such as\ncomplete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such\napproximate allocations indeed exist. However, it is an open problem whether\nthey exist for the class of all graphs.\n  In this paper, we continue the systematic study of the existence of\napproximate allocations on restricted graph classes. In particular, we show\nthat such allocations exist for several well-studied classes, including block\ngraphs, cacti, complete multipartite graphs, and split graphs.", "AI": {"tldr": "\u7814\u7a76\u5e26\u8fde\u901a\u6027\u7ea6\u675f\u7684\u4e0d\u53ef\u5206\u7269\u54c1\u516c\u5e73\u5206\u914d\u95ee\u9898\uff0c\u8bc1\u660e\u5728\u591a\u79cd\u56fe\u7c7b\u4e2d\u8fd1\u4f3c\u5206\u914d\u5b58\u5728", "motivation": "\u5df2\u77e5\u6ee1\u8db3\u6700\u5927\u6700\u5c0f\u4efd\u989d\u516c\u5e73\u51c6\u5219\u7684\u5206\u914d\u5728\u65e0\u8fde\u901a\u7ea6\u675f\u65f6\u53ef\u80fd\u4e0d\u5b58\u5728\uff0c\u4e14\u90e8\u5206\u56fe\u7c7b\u5b58\u5728\u8fd1\u4f3c\u5206\u914d\uff0c\u4f46\u6240\u6709\u56fe\u7c7b\u662f\u5426\u5b58\u5728\u8fd1\u4f3c\u5206\u914d\u662f\u5f00\u653e\u95ee\u9898", "method": "\u5bf9\u53d7\u9650\u56fe\u7c7b\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76", "result": "\u8bc1\u660e\u5728\u5757\u56fe\u3001\u4ed9\u4eba\u638c\u56fe\u3001\u5b8c\u5168\u591a\u90e8\u56fe\u548c\u5206\u88c2\u56fe\u7b49\u591a\u79cd\u56fe\u7c7b\u4e2d\u8fd1\u4f3c\u5206\u914d\u5b58\u5728", "conclusion": "\u5728\u591a\u79cd\u7814\u7a76\u5e7f\u6cdb\u7684\u56fe\u7c7b\u4e2d\u5b58\u5728\u6ee1\u8db3\u6761\u4ef6\u7684\u8fd1\u4f3c\u5206\u914d"}}
{"id": "2508.06357", "pdf": "https://arxiv.org/pdf/2508.06357", "abs": "https://arxiv.org/abs/2508.06357", "authors": ["Aman Bhatta", "Maria Dhakal", "Michael C. King", "Kevin W. Bowyer"], "title": "Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "A central problem in one-to-many facial identification is that the person in\nthe probe image may or may not have enrolled image(s) in the gallery; that is,\nmay be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one\nresult is Out-of-gallery have mostly focused on finding a suitable threshold on\nthe similarity score. We take a new approach, using the additional enrolled\nimages of the identity with the rank-one result to predict if the rank-one\nresult is In-gallery / Out-of-gallery. Given a gallery of identities and\nimages, we generate In-gallery and Out-of-gallery training data by extracting\nthe ranks of additional enrolled images corresponding to the rank-one identity.\nWe then train a classifier to utilize this feature vector to predict whether a\nrank-one result is In-gallery or Out-of-gallery. Using two different datasets\nand four different matchers, we present experimental results showing that our\napproach is viable for mugshot quality probe images, and also, importantly, for\nprobes degraded by blur, reduced resolution, atmospheric turbulence and\nsunglasses. We also analyze results across demographic groups, and show that\nIn-gallery / Out-of-gallery classification accuracy is similar across\ndemographics. Our approach has the potential to provide an objective estimate\nof whether a one-to-many facial identification is Out-of-gallery, and thereby\nto reduce false positive identifications, wrongful arrests, and wasted\ninvestigative time. Interestingly, comparing the results of older deep\nCNN-based face matchers with newer ones suggests that the effectiveness of our\nOut-of-gallery detection approach emerges only with matchers trained using\nadvanced margin-based loss functions.", "AI": {"tldr": "\u63d0\u51fa\u7528\u989d\u5916\u6ce8\u518c\u56fe\u50cf\u9884\u6d4b\u4e00\u5bf9\u4e00\u591a\u9762\u90e8\u8bc6\u522b\u4e2d\u6392\u540d\u7b2c\u4e00\u7ed3\u679c\u662f\u5426\u4e3a\u5e93\u5185\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5bf9\u591a\u79cd\u8d28\u91cf\u56fe\u50cf\u6709\u6548\uff0c\u4e14\u5404\u4eba\u53e3\u7fa4\u4f53\u5206\u7c7b\u51c6\u786e\u7387\u76f8\u4f3c\uff0c\u65b0\u5339\u914d\u5668\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u89e3\u51b3\u4e00\u5bf9\u4e00\u591a\u9762\u90e8\u8bc6\u522b\u4e2d\u5224\u65ad\u6392\u540d\u7b2c\u4e00\u7ed3\u679c\u662f\u5426\u4e3a\u5e93\u5916\u7684\u95ee\u9898\uff0c\u51cf\u5c11\u8bef\u62a5\u548c\u8c03\u67e5\u65f6\u95f4\u6d6a\u8d39\u3002", "method": "\u5229\u7528\u6392\u540d\u7b2c\u4e00\u8eab\u4efd\u7684\u989d\u5916\u6ce8\u518c\u56fe\u50cf\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u8bad\u7ec3\u5206\u7c7b\u5668\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u8be5\u65b9\u6cd5\u5bf9\u591a\u79cd\u8d28\u91cf\u56fe\u50cf\u6709\u6548\uff0c\u5404\u4eba\u53e3\u7fa4\u4f53\u5206\u7c7b\u51c6\u786e\u7387\u76f8\u4f3c\uff0c\u65b0\u5339\u914d\u5668\u6548\u679c\u66f4\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u5ba2\u89c2\u4f30\u8ba1\u662f\u5426\u4e3a\u5e93\u5916\u8bc6\u522b\uff0c\u51cf\u5c11\u8bef\u62a5\u7b49\u95ee\u9898\uff0c\u4e14\u6548\u679c\u4f9d\u8d56\u4e8e\u5339\u914d\u5668\u8bad\u7ec3\u65b9\u6cd5\u3002"}}
{"id": "2508.06372", "pdf": "https://arxiv.org/pdf/2508.06372", "abs": "https://arxiv.org/abs/2508.06372", "authors": ["Han Yin", "Yafeng Chen", "Chong Deng", "Luyao Cheng", "Hui Wang", "Chao-Hong Tan", "Qian Chen", "Wen Wang", "Xiangang Li"], "title": "SpeakerLM: End-to-End Versatile Speaker Diarization and Recognition with Multimodal Large Language Models", "categories": ["cs.SD", "cs.AI"], "comment": null, "summary": "The Speaker Diarization and Recognition (SDR) task aims to predict \"who spoke\nwhen and what\" within an audio clip, which is a crucial task in various\nreal-world multi-speaker scenarios such as meeting transcription and dialogue\nsystems. Existing SDR systems typically adopt a cascaded framework, combining\nmultiple modules such as speaker diarization (SD) and automatic speech\nrecognition (ASR). The cascaded systems suffer from several limitations, such\nas error propagation, difficulty in handling overlapping speech, and lack of\njoint optimization for exploring the synergy between SD and ASR tasks. To\naddress these limitations, we introduce SpeakerLM, a unified multimodal large\nlanguage model for SDR that jointly performs SD and ASR in an end-to-end\nmanner. Moreover, to facilitate diverse real-world scenarios, we incorporate a\nflexible speaker registration mechanism into SpeakerLM, enabling SDR under\ndifferent speaker registration settings. SpeakerLM is progressively developed\nwith a multi-stage training strategy on large-scale real data. Extensive\nexperiments show that SpeakerLM demonstrates strong data scaling capability and\ngeneralizability, outperforming state-of-the-art cascaded baselines on both\nin-domain and out-of-domain public SDR benchmarks. Furthermore, experimental\nresults show that the proposed speaker registration mechanism effectively\nensures robust SDR performance of SpeakerLM across diverse speaker registration\nconditions and varying numbers of registered speakers.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8eSDR\u7684\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bSpeakerLM\uff0c\u8054\u5408\u6267\u884cSD\u548cASR\uff0c\u6709\u7075\u6d3b\u7684\u8bf4\u8bdd\u4eba\u6ce8\u518c\u673a\u5236\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f73\u3002", "motivation": "\u73b0\u6709\u7ea7\u8054SDR\u7cfb\u7edf\u5b58\u5728\u8bef\u5dee\u4f20\u64ad\u3001\u96be\u5904\u7406\u91cd\u53e0\u8bed\u97f3\u3001\u7f3a\u4e4f\u8054\u5408\u4f18\u5316\u7b49\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bSpeakerLM\uff0c\u4ee5\u7aef\u5230\u7aef\u65b9\u5f0f\u8054\u5408\u6267\u884cSD\u548cASR\uff0c\u878d\u5165\u7075\u6d3b\u8bf4\u8bdd\u4eba\u6ce8\u518c\u673a\u5236\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "SpeakerLM\u6709\u5f3a\u6570\u636e\u6269\u5c55\u80fd\u529b\u548c\u6cdb\u5316\u6027\uff0c\u5728\u591a\u4e2aSDR\u57fa\u51c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u7ea7\u8054\u57fa\u7ebf\uff0c\u8bf4\u8bdd\u4eba\u6ce8\u518c\u673a\u5236\u786e\u4fdd\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u80fd\u3002", "conclusion": "SpeakerLM\u80fd\u6709\u6548\u89e3\u51b3\u73b0\u6709\u7ea7\u8054SDR\u7cfb\u7edf\u7684\u95ee\u9898\uff0c\u5728SDR\u4efb\u52a1\u4e2d\u6709\u826f\u597d\u8868\u73b0\u3002"}}
{"id": "2508.06393", "pdf": "https://arxiv.org/pdf/2508.06393", "abs": "https://arxiv.org/abs/2508.06393", "authors": ["Md Asif Jalal", "Luca Remaggi", "Vasileios Moschopoulos", "Thanasis Kotsiopoulos", "Vandana Rajan", "Karthikeyan Saravanan", "Anastasis Drosou", "Junho Heo", "Hyuk Oh", "Seokyeong Jeong"], "title": "Robust Target Speaker Diarization and Separation via Augmented Speaker Embedding Sampling", "categories": ["cs.SD", "cs.AI"], "comment": "Accepted to Interspeech 2025", "summary": "Traditional speech separation and speaker diarization approaches rely on\nprior knowledge of target speakers or a predetermined number of participants in\naudio signals. To address these limitations, recent advances focus on\ndeveloping enrollment-free methods capable of identifying targets without\nexplicit speaker labeling. This work introduces a new approach to train\nsimultaneous speech separation and diarization using automatic identification\nof target speaker embeddings, within mixtures. Our proposed model employs a\ndual-stage training pipeline designed to learn robust speaker representation\nfeatures that are resilient to background noise interference. Furthermore, we\npresent an overlapping spectral loss function specifically tailored for\nenhancing diarization accuracy during overlapped speech frames. Experimental\nresults show significant performance gains compared to the current SOTA\nbaseline, achieving 71% relative improvement in DER and 69% in cpWER.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\u8bad\u7ec3\u540c\u65f6\u8fdb\u884c\u8bed\u97f3\u5206\u79bb\u548c\u8bf4\u8bdd\u4eba\u5206\u5272\u6a21\u578b\uff0c\u91c7\u7528\u53cc\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\u548c\u91cd\u53e0\u9891\u8c31\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u9a8c\u6548\u679c\u4f18\u4e8e\u5f53\u524dSOTA\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u8bed\u97f3\u5206\u79bb\u548c\u8bf4\u8bdd\u4eba\u5206\u5272\u65b9\u6cd5\u4f9d\u8d56\u76ee\u6807\u8bf4\u8bdd\u4eba\u5148\u9a8c\u77e5\u8bc6\u6216\u9884\u5b9a\u53c2\u4e0e\u4eba\u6570\uff0c\u4e3a\u89e3\u51b3\u8be5\u5c40\u9650\uff0c\u9700\u5f00\u53d1\u514d\u6ce8\u518c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u81ea\u52a8\u8bc6\u522b\u6df7\u5408\u8bed\u97f3\u4e2d\u76ee\u6807\u8bf4\u8bdd\u4eba\u5d4c\u5165\u6765\u8bad\u7ec3\uff1b\u91c7\u7528\u53cc\u9636\u6bb5\u8bad\u7ec3\u7ba1\u9053\u5b66\u4e60\u6297\u80cc\u666f\u566a\u58f0\u5e72\u6270\u7684\u8bf4\u8bdd\u4eba\u7279\u5f81\uff1b\u63d0\u51fa\u91cd\u53e0\u9891\u8c31\u635f\u5931\u51fd\u6570\u63d0\u5347\u91cd\u53e0\u8bed\u97f3\u5e27\u7684\u5206\u5272\u51c6\u786e\u6027\u3002", "result": "\u4e0e\u5f53\u524dSOTA\u57fa\u7ebf\u76f8\u6bd4\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0cDER\u76f8\u5bf9\u6539\u558471%\uff0ccpWER\u6539\u558469%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u8bed\u97f3\u5206\u79bb\u548c\u8bf4\u8bdd\u4eba\u5206\u5272\u4efb\u52a1\u4e0a\u6548\u679c\u826f\u597d\uff0c\u80fd\u6709\u6548\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2508.06407", "pdf": "https://arxiv.org/pdf/2508.06407", "abs": "https://arxiv.org/abs/2508.06407", "authors": ["Ch Muhammad Awais", "Marco Reggiannini", "Davide Moroni", "Oktay Karakus"], "title": "A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "High-resolution imagery plays a critical role in improving the performance of\nvisual recognition tasks such as classification, detection, and segmentation.\nIn many domains, including remote sensing and surveillance, low-resolution\nimages can limit the accuracy of automated analysis. To address this,\nsuper-resolution (SR) techniques have been widely adopted to attempt to\nreconstruct high-resolution images from low-resolution inputs. Related\ntraditional approaches focus solely on enhancing image quality based on\npixel-level metrics, leaving the relationship between super-resolved image\nfidelity and downstream classification performance largely underexplored. This\nraises a key question: can integrating classification objectives directly into\nthe super-resolution process further improve classification accuracy? In this\npaper, we try to respond to this question by investigating the relationship\nbetween super-resolution and classification through the deployment of a\nspecialised algorithmic strategy. We propose a novel methodology that increases\nthe resolution of synthetic aperture radar imagery by optimising loss functions\nthat account for both image quality and classification performance. Our\napproach improves image quality, as measured by scientifically ascertained\nimage quality indicators, while also enhancing classification accuracy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8d85\u5206\u8fa8\u7387\u4e0e\u5206\u7c7b\u5173\u7cfb\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u4f18\u5316\u635f\u5931\u51fd\u6570\u63d0\u5347\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u56fe\u50cf\u5206\u8fa8\u7387\uff0c\u6539\u5584\u56fe\u50cf\u8d28\u91cf\u5e76\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u4ec5\u5173\u6ce8\u50cf\u7d20\u7ea7\u56fe\u50cf\u8d28\u91cf\u63d0\u5347\uff0c\u672a\u5145\u5206\u63a2\u7d22\u8d85\u5206\u8fa8\u7387\u56fe\u50cf\u4fdd\u771f\u5ea6\u4e0e\u4e0b\u6e38\u5206\u7c7b\u6027\u80fd\u5173\u7cfb\uff0c\u56e0\u6b64\u7814\u7a76\u5c06\u5206\u7c7b\u76ee\u6807\u878d\u5165\u8d85\u5206\u8fa8\u7387\u8fc7\u7a0b\u80fd\u5426\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u3002", "method": "\u90e8\u7f72\u4e13\u95e8\u7b97\u6cd5\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316\u517c\u987e\u56fe\u50cf\u8d28\u91cf\u548c\u5206\u7c7b\u6027\u80fd\u7684\u635f\u5931\u51fd\u6570\uff0c\u63d0\u9ad8\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u56fe\u50cf\u5206\u8fa8\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u79d1\u5b66\u786e\u5b9a\u7684\u56fe\u50cf\u8d28\u91cf\u6307\u6807\u6240\u8861\u91cf\u7684\u56fe\u50cf\u8d28\u91cf\uff0c\u540c\u65f6\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "\u5c06\u5206\u7c7b\u76ee\u6807\u878d\u5165\u8d85\u5206\u8fa8\u7387\u8fc7\u7a0b\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2508.06426", "pdf": "https://arxiv.org/pdf/2508.06426", "abs": "https://arxiv.org/abs/2508.06426", "authors": ["Youguang Xing", "Xu Luo", "Junlin Xie", "Lianli Gao", "Hengtao Shen", "Jingkuan Song"], "title": "Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "CoRL 2025", "summary": "Generalist robot policies trained on large-scale datasets such as Open\nX-Embodiment (OXE) demonstrate strong performance across a wide range of tasks.\nHowever, they often struggle to generalize beyond the distribution of their\ntraining data. In this paper, we investigate the underlying cause of this\nlimited generalization capability. We identify shortcut learning -- the\nreliance on task-irrelevant features -- as a key impediment to generalization.\nThrough comprehensive theoretical and empirical analysis, we uncover two\nprimary contributors to shortcut learning: (1) limited diversity within\nindividual sub-datasets, and (2) significant distributional disparities across\nsub-datasets, leading to dataset fragmentation. These issues arise from the\ninherent structure of large-scale datasets like OXE, which are typically\ncomposed of multiple sub-datasets collected independently across varied\nenvironments and embodiments. Our findings provide critical insights into\ndataset collection strategies that can reduce shortcut learning and enhance the\ngeneralization ability of generalist robot policies. Moreover, in scenarios\nwhere acquiring new large-scale data is impractical, we demonstrate that\ncarefully selected robotic data augmentation strategies can effectively reduce\nshortcut learning in existing offline datasets, thereby improving\ngeneralization capabilities of generalist robot policies, e.g., $\\pi_0$, in\nboth simulation and real-world environments. More information at\nhttps://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u6cdb\u5316\u80fd\u529b\u53d7\u9650\u539f\u56e0\uff0c\u6307\u51fa\u6377\u5f84\u5b66\u4e60\u662f\u5173\u952e\u963b\u788d\uff0c\u5206\u6790\u5176\u6210\u56e0\u5e76\u7ed9\u51fa\u51cf\u5c11\u6377\u5f84\u5b66\u4e60\u3001\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "motivation": "\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u5728\u8d85\u51fa\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u63a2\u7a76\u5176\u6839\u672c\u539f\u56e0\u3002", "method": "\u8fdb\u884c\u5168\u9762\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u5206\u6790\uff0c\u7814\u7a76\u5927\u578b\u6570\u636e\u96c6\u7684\u7ed3\u6784\u548c\u7279\u70b9\u3002", "result": "\u53d1\u73b0\u6377\u5f84\u5b66\u4e60\u7684\u4e24\u4e2a\u4e3b\u8981\u6210\u56e0\u662f\u5355\u4e2a\u5b50\u6570\u636e\u96c6\u591a\u6837\u6027\u6709\u9650\u548c\u5b50\u6570\u636e\u96c6\u95f4\u5206\u5e03\u5dee\u5f02\u5927\uff1b\u8fd8\u8868\u660e\u7cbe\u5fc3\u9009\u62e9\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u53ef\u51cf\u5c11\u73b0\u6709\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u7684\u6377\u5f84\u5b66\u4e60\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6570\u636e\u96c6\u6536\u96c6\u7b56\u7565\u63d0\u4f9b\u89c1\u89e3\uff0c\u5728\u65e0\u6cd5\u83b7\u53d6\u65b0\u6570\u636e\u65f6\uff0c\u6570\u636e\u589e\u5f3a\u7b56\u7565\u53ef\u63d0\u5347\u901a\u7528\u673a\u5668\u4eba\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.06429", "pdf": "https://arxiv.org/pdf/2508.06429", "abs": "https://arxiv.org/abs/2508.06429", "authors": ["Guido Manni", "Clemente Lauretti", "Loredana Zollo", "Paolo Soda"], "title": "SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Deep learning has revolutionized medical imaging, but its effectiveness is\nseverely limited by insufficient labeled training data. This paper introduces a\nnovel GAN-based semi-supervised learning framework specifically designed for\nlow labeled-data regimes, evaluated across settings with 5 to 50 labeled\nsamples per class. Our approach integrates three specialized neural networks --\na generator for class-conditioned image translation, a discriminator for\nauthenticity assessment and classification, and a dedicated classifier --\nwithin a three-phase training framework. The method alternates between\nsupervised training on limited labeled data and unsupervised learning that\nleverages abundant unlabeled images through image-to-image translation rather\nthan generation from noise. We employ ensemble-based pseudo-labeling that\ncombines confidence-weighted predictions from the discriminator and classifier\nwith temporal consistency through exponential moving averaging, enabling\nreliable label estimation for unlabeled data. Comprehensive evaluation across\neleven MedMNIST datasets demonstrates that our approach achieves statistically\nsignificant improvements over six state-of-the-art GAN-based semi-supervised\nmethods, with particularly strong performance in the extreme 5-shot setting\nwhere the scarcity of labeled data is most challenging. The framework maintains\nits superiority across all evaluated settings (5, 10, 20, and 50 shots per\nclass). Our approach offers a practical solution for medical imaging\napplications where annotation costs are prohibitive, enabling robust\nclassification performance even with minimal labeled data. Code is available at\nhttps://github.com/GuidoManni/SPARSE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eGAN\u7684\u534a\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f4e\u6807\u6ce8\u6570\u636e\u573a\u666f\uff0c\u5728\u591a\u4e2aMedMNIST\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u533b\u5b66\u6210\u50cf\u4e2d\u53d7\u9650\u4e8e\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\uff0c\u9700\u8981\u65b0\u65b9\u6cd5\u89e3\u51b3\u4f4e\u6807\u6ce8\u6570\u636e\u4e0b\u7684\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u96c6\u6210\u751f\u6210\u5668\u3001\u5224\u522b\u5668\u548c\u5206\u7c7b\u5668\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u4ea4\u66ff\u8fdb\u884c\u6709\u76d1\u7763\u548c\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u4f7f\u7528\u57fa\u4e8e\u96c6\u6210\u7684\u4f2a\u6807\u7b7e\u65b9\u6cd5\u3002", "result": "\u572811\u4e2aMedMNIST\u6570\u636e\u96c6\u4e0a\uff0c\u663e\u8457\u4f18\u4e8e6\u79cd\u73b0\u6709\u57fa\u4e8eGAN\u7684\u534a\u76d1\u7763\u65b9\u6cd5\uff0c\u5728\u6781\u7aef5-shot\u573a\u666f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u533b\u5b66\u6210\u50cf\u5e94\u7528\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u4e5f\u80fd\u5b9e\u73b0\u5f3a\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2508.06434", "pdf": "https://arxiv.org/pdf/2508.06434", "abs": "https://arxiv.org/abs/2508.06434", "authors": ["Shengzhu Yang", "Jiawei Du", "Shuai Lu", "Weihang Zhang", "Ningli Wang", "Huiqi Li"], "title": "CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Large-scale natural image-text datasets, especially those automatically\ncollected from the web, often suffer from loose semantic alignment due to weak\nsupervision, while medical datasets tend to have high cross-modal correlation\nbut low content diversity. These properties pose a common challenge for\ncontrastive language-image pretraining (CLIP): they hinder the model's ability\nto learn robust and generalizable representations. In this work, we propose\nCLIPin, a unified non-contrastive plug-in that can be seamlessly integrated\ninto CLIP-style architectures to improve multimodal semantic alignment,\nproviding stronger supervision and enhancing alignment robustness. Furthermore,\ntwo shared pre-projectors are designed for image and text modalities\nrespectively to facilitate the integration of contrastive and non-contrastive\nlearning in a parameter-compromise manner. Extensive experiments on diverse\ndownstream tasks demonstrate the effectiveness and generality of CLIPin as a\nplug-and-play component compatible with various contrastive frameworks. Code is\navailable at https://github.com/T6Yang/CLIPin.", "AI": {"tldr": "\u63d0\u51faCLIPin\u975e\u5bf9\u6bd4\u5f0f\u63d2\u4ef6\u6539\u8fdbCLIP\u591a\u6a21\u6001\u8bed\u4e49\u5bf9\u9f50\uff0c\u8bbe\u8ba1\u9884\u6295\u5f71\u5668\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u81ea\u7136\u56fe\u50cf\u6587\u672c\u6570\u636e\u96c6\u8bed\u4e49\u5bf9\u9f50\u5f31\u3001\u533b\u5b66\u6570\u636e\u96c6\u5185\u5bb9\u591a\u6837\u6027\u4f4e\uff0c\u5f71\u54cdCLIP\u5b66\u4e60\u9c81\u68d2\u901a\u7528\u8868\u5f81\u3002", "method": "\u63d0\u51faCLIPin\u63d2\u4ef6\u96c6\u6210\u5230CLIP\u67b6\u6784\uff0c\u8bbe\u8ba1\u4e24\u4e2a\u5171\u4eab\u9884\u6295\u5f71\u5668\u4ee5\u53c2\u6570\u6298\u8877\u65b9\u5f0f\u6574\u5408\u5bf9\u6bd4\u4e0e\u975e\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5728\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660eCLIPin\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7ec4\u4ef6\u6709\u6548\u4e14\u901a\u7528\u3002", "conclusion": "CLIPin\u80fd\u6539\u5584\u591a\u6a21\u6001\u8bed\u4e49\u5bf9\u9f50\uff0c\u4e0e\u5404\u79cd\u5bf9\u6bd4\u6846\u67b6\u517c\u5bb9\u3002"}}
{"id": "2508.06435", "pdf": "https://arxiv.org/pdf/2508.06435", "abs": "https://arxiv.org/abs/2508.06435", "authors": ["Andrea Nasuto", "Stefano Maria Iacus", "Francisco Rowe", "Devika Jain"], "title": "Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are transforming social-science research by\nenabling scalable, precise analysis. Their adaptability raises the question of\nwhether knowledge acquired through fine-tuning in a few languages can transfer\nto unseen languages that only appeared during pre-training. To examine this, we\nfine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or\nmultilingual data sets to classify immigration-related tweets from X/Twitter\nacross 13 languages, a domain characterised by polarised, culturally specific\ndiscourse. We evaluate whether minimal language-specific fine-tuning enables\ncross-lingual topic detection and whether adding targeted languages corrects\npre-training biases. Results show that LLMs fine-tuned in one or two languages\ncan reliably classify immigration-related content in unseen languages. However,\nidentifying whether a tweet expresses a pro- or anti-immigration stance\nbenefits from multilingual fine-tuning. Pre-training bias favours dominant\nlanguages, but even minimal exposure to under-represented languages during\nfine-tuning (as little as $9.62\\times10^{-11}$ of the original pre-training\ntoken volume) yields significant gains. These findings challenge the assumption\nthat cross-lingual mastery requires extensive multilingual training: limited\nlanguage coverage suffices for topic-level generalisation, and structural\nbiases can be corrected with lightweight interventions. By releasing\n4-bit-quantised, LoRA fine-tuned models, we provide an open-source,\nreproducible alternative to proprietary LLMs that delivers 35 times faster\ninference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,\nenabling scalable, inclusive research.", "AI": {"tldr": "\u7814\u7a76\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u8bdd\u9898\u68c0\u6d4b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6709\u9650\u8bed\u8a00\u8986\u76d6\u53ef\u5b9e\u73b0\u8bdd\u9898\u6cdb\u5316\uff0c\u8f7b\u91cf\u7ea7\u5e72\u9884\u53ef\u7ea0\u6b63\u504f\u5dee\uff0c\u8fd8\u53d1\u5e03\u4f4e\u6210\u672c\u6a21\u578b\u4fc3\u8fdb\u7814\u7a76\u3002", "motivation": "\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u540e\u5728\u5c11\u6570\u8bed\u8a00\u83b7\u5f97\u7684\u77e5\u8bc6\u80fd\u5426\u8fc1\u79fb\u5230\u4ec5\u5728\u9884\u8bad\u7ec3\u4e2d\u51fa\u73b0\u7684\u672a\u89c1\u8bed\u8a00\u3002", "method": "\u5728\u5355\u8bed\u3001\u53cc\u8bed\u6216\u591a\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u8f7b\u91cf\u7ea7LLaMA 3.2 - 3B\u6a21\u578b\uff0c\u5bf913\u79cd\u8bed\u8a00\u7684\u79fb\u6c11\u76f8\u5173\u63a8\u6587\u5206\u7c7b\u3002", "result": "\u5355\u8bed\u6216\u53cc\u8bed\u5fae\u8c03\u7684\u6a21\u578b\u53ef\u53ef\u9760\u5206\u7c7b\u672a\u89c1\u8bed\u8a00\u7684\u79fb\u6c11\u76f8\u5173\u5185\u5bb9\uff1b\u591a\u8bed\u8a00\u5fae\u8c03\u5229\u4e8e\u8bc6\u522b\u63a8\u6587\u7acb\u573a\uff1b\u5c11\u91cf\u63a5\u89e6\u4f4e\u8d44\u6e90\u8bed\u8a00\u53ef\u663e\u8457\u6539\u5584\u9884\u8bad\u7ec3\u504f\u5dee\u3002", "conclusion": "\u8de8\u8bed\u8a00\u638c\u63e1\u4e0d\u987b\u5927\u91cf\u591a\u8bed\u8a00\u8bad\u7ec3\uff0c\u6709\u9650\u8bed\u8a00\u8986\u76d6\u548c\u8f7b\u91cf\u7ea7\u5e72\u9884\u5373\u53ef\uff1b\u53d1\u5e03\u4f4e\u6210\u672c\u6a21\u578b\u5229\u4e8e\u53ef\u6269\u5c55\u3001\u5305\u5bb9\u6027\u7814\u7a76\u3002"}}
{"id": "2508.06445", "pdf": "https://arxiv.org/pdf/2508.06445", "abs": "https://arxiv.org/abs/2508.06445", "authors": ["Abolfazl Ansari", "Delvin Ce Zhang", "Nafis Irtiza Tripto", "Dongwon Lee"], "title": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in 18th International Conference on Social Computing,\n  Behavioral-Cultural Modeling, & Prediction and Behavior Representation in\n  Modeling and Simulation, and to be published in the Springer LNCS series", "summary": "The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns\nfor journalistic integrity and authorship. This study examines AI-generated\ncontent across over 40,000 news articles from major, local, and college news\nmedia, in various media formats. Using three advanced AI-text detectors (e.g.,\nBinoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of\nGenAI use in recent years, especially in local and college news. Sentence-level\nanalysis reveals LLMs are often used in the introduction of news, while\nconclusions usually written manually. Linguistic analysis shows GenAI boosts\nword richness and readability but lowers formality, leading to more uniform\nwriting styles, particularly in local media.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u8d854\u4e07\u7bc7\u65b0\u95fb\u6587\u7ae0\u4e2dAI\u751f\u6210\u5185\u5bb9\uff0c\u53d1\u73b0\u8fd1\u5e74GenAI\u4f7f\u7528\u663e\u8457\u589e\u52a0\uff0c\u4e0d\u540c\u4f4d\u7f6e\u4f7f\u7528\u6709\u5dee\u5f02\uff0c\u5bf9\u5199\u4f5c\u98ce\u683c\u6709\u5f71\u54cd\u3002", "motivation": "\u5e94\u5bf9\u751f\u6210\u5f0fAI\u5bf9\u65b0\u95fb\u4e1a\u8bda\u4fe1\u548c\u4f5c\u8005\u8eab\u4efd\u7684\u6311\u6218\uff0c\u4e86\u89e3\u5176\u5728\u65b0\u95fb\u5185\u5bb9\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u5148\u8fdbAI\u6587\u672c\u68c0\u6d4b\u5668\uff0c\u5bf9\u4e0d\u540c\u7c7b\u578b\u3001\u683c\u5f0f\u7684\u8d854\u4e07\u7bc7\u65b0\u95fb\u6587\u7ae0\u8fdb\u884c\u5206\u6790\uff0c\u8fd8\u6709\u53e5\u5b50\u7ea7\u548c\u8bed\u8a00\u5b66\u5206\u6790\u3002", "result": "\u8fd1\u5e74GenAI\u4f7f\u7528\u663e\u8457\u589e\u52a0\uff0c\u5728\u5730\u65b9\u548c\u5927\u5b66\u65b0\u95fb\u4e2d\u5c24\u751a\uff1b\u65b0\u95fb\u5f15\u8a00\u5e38\u7528LLMs\uff0c\u7ed3\u8bba\u591a\u624b\u52a8\u64b0\u5199\uff1bGenAI\u63d0\u5347\u8bcd\u6c47\u4e30\u5bcc\u5ea6\u548c\u53ef\u8bfb\u6027\uff0c\u4f46\u964d\u4f4e\u6b63\u5f0f\u6027\uff0c\u4f7f\u5199\u4f5c\u98ce\u683c\u66f4\u8d8b\u540c\u3002", "conclusion": "\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u6697\u793aGenAI\u5728\u65b0\u95fb\u4e2d\u7684\u4f7f\u7528\u5df2\u8f83\u4e3a\u666e\u904d\u4e14\u5bf9\u5199\u4f5c\u98ce\u683c\u4ea7\u751f\u5f71\u54cd\uff0c\u9700\u5173\u6ce8\u5176\u5bf9\u65b0\u95fb\u4e1a\u7684\u6f5c\u5728\u5f71\u54cd\u3002"}}
{"id": "2508.06453", "pdf": "https://arxiv.org/pdf/2508.06453", "abs": "https://arxiv.org/abs/2508.06453", "authors": ["Ruida Cheng", "Tejas Sudharshan Mathai", "Pritam Mukherjee", "Benjamin Hou", "Qingqing Zhu", "Zhiyong Lu", "Matthew McAuliffe", "Ronald M. Summers"], "title": "Text Embedded Swin-UMamba for DeepLesion Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Segmentation of lesions on CT enables automatic measurement for clinical\nassessment of chronic diseases (e.g., lymphoma). Integrating large language\nmodels (LLMs) into the lesion segmentation workflow offers the potential to\ncombine imaging features with descriptions of lesion characteristics from the\nradiology reports. In this study, we investigate the feasibility of integrating\ntext into the Swin-UMamba architecture for the task of lesion segmentation. The\npublicly available ULS23 DeepLesion dataset was used along with short-form\ndescriptions of the findings from the reports. On the test dataset, a high Dice\nScore of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for\nlesion segmentation. The proposed Text-Swin-UMamba model outperformed prior\napproaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p <\n0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by\n1.74% and 0.22%, respectively. The dataset and code can be accessed at\nhttps://github.com/ruida/LLM-Swin-UMamba", "AI": {"tldr": "\u7814\u7a76\u5c06\u6587\u672c\u96c6\u6210\u5230Swin - UMamba\u67b6\u6784\u7528\u4e8e\u75c5\u53d8\u5206\u5272\uff0c\u5728\u6d4b\u8bd5\u96c6\u53d6\u5f97\u9ad8Dice\u5206\u6570\u548c\u4f4eHausdorff\u8ddd\u79bb\uff0c\u6a21\u578b\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "motivation": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230\u75c5\u53d8\u5206\u5272\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408\u5f71\u50cf\u7279\u5f81\u548c\u653e\u5c04\u5b66\u62a5\u544a\u4e2d\u75c5\u53d8\u7279\u5f81\u63cf\u8ff0\uff0c\u4ee5\u7528\u4e8e\u6162\u6027\u75be\u75c5\u4e34\u5e8a\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u7684ULS23 DeepLesion\u6570\u636e\u96c6\u548c\u62a5\u544a\u4e2d\u7684\u7b80\u77ed\u63cf\u8ff0\uff0c\u5c06\u6587\u672c\u96c6\u6210\u5230Swin - UMamba\u67b6\u6784\u8fdb\u884c\u75c5\u53d8\u5206\u5272\u3002", "result": "\u5728\u6d4b\u8bd5\u96c6\u4e0a\u75c5\u53d8\u5206\u5272\u83b7\u5f9782%\u7684\u9ad8Dice\u5206\u6570\u548c6.58\uff08\u50cf\u7d20\uff09\u7684\u4f4eHausdorff\u8ddd\u79bb\uff0cText - Swin - UMamba\u6a21\u578b\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u6587\u672c\u96c6\u6210\u5230Swin - UMamba\u67b6\u6784\u7528\u4e8e\u75c5\u53d8\u5206\u5272\u662f\u53ef\u884c\u7684\uff0c\u6240\u63d0\u6a21\u578b\u6027\u80fd\u826f\u597d\u3002"}}
{"id": "2508.06457", "pdf": "https://arxiv.org/pdf/2508.06457", "abs": "https://arxiv.org/abs/2508.06457", "authors": ["Sanket Badhe"], "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.MA"], "comment": "Accepted at CAMLIS 25: Conference on Applied Machine Learning for\n  Information Security. 10 pages, 3 figures", "summary": "Large Language Models (LLMs) have demonstrated impressive fluency and\nreasoning capabilities, but their potential for misuse has raised growing\nconcern. In this paper, we present ScamAgent, an autonomous multi-turn agent\nbuilt on top of LLMs, capable of generating highly realistic scam call scripts\nthat simulate real-world fraud scenarios. Unlike prior work focused on\nsingle-shot prompt misuse, ScamAgent maintains dialogue memory, adapts\ndynamically to simulated user responses, and employs deceptive persuasion\nstrategies across conversational turns. We show that current LLM safety\nguardrails, including refusal mechanisms and content filters, are ineffective\nagainst such agent-based threats. Even models with strong prompt-level\nsafeguards can be bypassed when prompts are decomposed, disguised, or delivered\nincrementally within an agent framework. We further demonstrate the\ntransformation of scam scripts into lifelike voice calls using modern\ntext-to-speech systems, completing a fully automated scam pipeline. Our\nfindings highlight an urgent need for multi-turn safety auditing, agent-level\ncontrol frameworks, and new methods to detect and disrupt conversational\ndeception powered by generative AI.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684ScamAgent\u53ef\u751f\u6210\u903c\u771f\u8bc8\u9a97\u811a\u672c\uff0c\u8bc1\u660e\u73b0\u6709\u5b89\u5168\u9632\u62a4\u65e0\u6548\uff0c\u5f3a\u8c03\u591a\u8f6e\u5b89\u5168\u5ba1\u8ba1\u7b49\u9700\u6c42\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6709\u88ab\u6ee5\u7528\u98ce\u9669\uff0c\u9700\u7814\u7a76\u5176\u5728\u8bc8\u9a97\u573a\u666f\u4e2d\u7684\u5e94\u7528\u53ca\u73b0\u6709\u9632\u62a4\u6709\u6548\u6027\u3002", "method": "\u6784\u5efaScamAgent\uff0c\u5229\u7528\u5176\u751f\u6210\u8bc8\u9a97\u811a\u672c\uff0c\u7ed3\u5408\u6587\u672c\u8f6c\u8bed\u97f3\u7cfb\u7edf\u5f62\u6210\u81ea\u52a8\u5316\u8bc8\u9a97\u6d41\u7a0b\u3002", "result": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u9632\u62a4\u5bf9\u57fa\u4e8e\u4ee3\u7406\u7684\u5a01\u80c1\u65e0\u6548\uff0c\u53ef\u7ed5\u8fc7\u5f3a\u63d0\u793a\u7ea7\u9632\u62a4\u3002", "conclusion": "\u8feb\u5207\u9700\u8981\u591a\u8f6e\u5b89\u5168\u5ba1\u8ba1\u3001\u4ee3\u7406\u7ea7\u63a7\u5236\u6846\u67b6\u53ca\u68c0\u6d4b\u548c\u7834\u574f\u751f\u6210\u5f0fAI\u5bf9\u8bdd\u6b3a\u9a97\u7684\u65b0\u65b9\u6cd5\u3002"}}
