{"id": "2512.20180", "pdf": "https://arxiv.org/pdf/2512.20180", "abs": "https://arxiv.org/abs/2512.20180", "authors": ["Zeev Nutov", "Anael Vaknin"], "title": "Approximation and parameterized algorithms for covering disjointness-compliable set families", "categories": ["cs.DS"], "comment": null, "summary": "A set-family ${\\cal F}$ is disjointness-compliable if $A' \\subseteq A \\in {\\cal F}$ implies $A' \\in {\\cal F}$ or $A \\setminus A' \\in {\\cal F}$; if ${\\cal F}$ is also symmetric then ${\\cal F}$ is proper. A classic result of Goemans and Williamson [SODA 92:307-316] states that the problem of covering a proper set-family by a min-cost edge set admits approximation ratio $2$, by a classic primal-dual algorithm. However, there are several famous algorithmic problems whose set-family ${\\cal F}$ is disjointness-compliable but not symmetric -- among them $k$-Minimum Spanning Tree ($k$-MST), Generalized Point-to-Point Connection (G-P2P), Group Steiner, Covering Steiner, multiroot versions of these problems, and others. We will show that any such problem admits approximation ratio $O(\u03b1\\log \u03c4)$, where $\u03c4$ is the number of inclusion-minimal sets in the family ${\\cal F}$ that models the problem and $\u03b1$ is the best known approximation ratio for the case when $\u03c4=1$. This immediately implies several results, among them the following two. (i) The first deterministic polynomial time $O(\\log n)$-approximation algorithm for the G-P2P problem. Here the $\u03c4=1$ case is the $k$-MST problem. (ii) Approximation ratio $O(\\log^4 n)$ for the multiroot version of the Covering Steiner problem, where each root has its own set of groups. Here the $\u03c4=1$ case is the Covering Steiner problem.\n  We also discuss the parameterized complexity of covering a disjointness-compliable family ${\\cal F}$, when parametrized by $\u03c4$. We will show that if ${\\cal F}$ is proper then the problem is fixed parameter tractable and can be solved in time $O^*(3^\u03c4)$. For the non-symmetric case we will show that the problem admits approximation ratio between $\u03b1$ and $\u03b1+1$ in time $O^*(3^\u03c4)$, which is essentially the best possible.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2512.20598", "pdf": "https://arxiv.org/pdf/2512.20598", "abs": "https://arxiv.org/abs/2512.20598", "authors": ["Vinicius T. V. Date", "Leandro M. Zatesko"], "title": "On the near-tightness of $\u03c7\\leq 2r$: a general $\u03c3$-ary construction and a binary case via LFSRs", "categories": ["cs.DS"], "comment": "Accepted to LATIN 2026. 16 pages, 0 figures", "summary": "In the field of compressed string indexes, recent work has introduced suffixient sets and their corresponding repetitiveness measure $\u03c7$. In particular, researchers have explored its relationship to other repetitiveness measures, notably $r$, the number of runs in the Burrows--Wheeler Transform (BWT) of a string. Navarro et al. (2025) proved that $\u03c7\\leq 2r$, although empirical results by Cenzato et al. (2024) suggest that this bound is loose, with real data bounding $\u03c7$ by around $1.13r$ to $1.33r$ when the size of the alphabet is $\u03c3= 4$. To better understand this gap, we present two cases for the asymptotic tightness of the $\u03c7\\leq 2r$ bound: a general construction for arbitrary $\u03c3$ values, and a binary alphabet case, consisting of de Bruijn sequences constructed by linear-feedback shift registers (LFSRs) from primitive polynomials over $\\mathbb{F}_2$. The second is a novel characterization of which de Bruijn sequences achieve the literature run-minimal pattern for the cyclic BWT. Moreover, we show that de Bruijn sequences fail to close the gap for $\u03c3\\geq 3$.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u538b\u7f29\u5b57\u7b26\u4e32\u7d22\u5f15\u4e2d\u540e\u7f00\u96c6\u91cd\u590d\u5ea6\u91cf\u03c7\u4e0er\u7684\u5173\u7cfb\uff0c\u5206\u6790\u03c7 \u2264 2r\u754c\u9650\u6e10\u8fd1\u7d27\u6027\uff0c\u7528\u4e24\u79cd\u6784\u9020\u65b9\u6cd5\uff0c\u53d1\u73b0\u5fb7\u5e03\u9c81\u56e0\u5e8f\u5217\u5728\u03c3 \u2265 3\u65f6\u65e0\u6cd5\u7f29\u5c0f\u5dee\u8ddd\u3002", "motivation": "\u6b64\u524d\u7814\u7a76\u8bc1\u660e\u03c7 \u2264 2r\uff0c\u4f46\u5b9e\u8bc1\u663e\u793a\u6b64\u754c\u9650\u5bbd\u677e\uff0c\u4e3a\u7406\u89e3\u5dee\u8ddd\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u7ed9\u51fa\u4efb\u610f\u03c3\u503c\u7684\u4e00\u822c\u6784\u9020\u4ee5\u53ca\u4e8c\u8fdb\u5236\u5b57\u6bcd\u8868\uff08\u5fb7\u5e03\u9c81\u56e0\u5e8f\u5217\uff09\u7684\u60c5\u51b5\u3002", "result": "\u7ed9\u51fa\u4e86\u4e24\u79cd\u60c5\u51b5\u7684\u6e10\u8fd1\u7d27\u6027\u5206\u6790\uff0c\u53d1\u73b0\u5fb7\u5e03\u9c81\u56e0\u5e8f\u5217\u5728\u03c3 \u2265 3\u65f6\u4e0d\u80fd\u7f29\u5c0f\u754c\u9650\u5dee\u8ddd\u3002", "conclusion": "\u5bf9\u03c7 \u2264 2r\u754c\u9650\u7684\u6e10\u8fd1\u7d27\u6027\u6709\u66f4\u6df1\u5165\u7406\u89e3\uff0c\u5fb7\u5e03\u9c81\u56e0\u5e8f\u5217\u6709\u4e00\u5b9a\u7279\u6027\u4f46\u5728\u03c3 \u2265 3\u65f6\u65e0\u6cd5\u7f29\u5c0f\u5dee\u8ddd\u3002"}}
{"id": "2512.20588", "pdf": "https://arxiv.org/pdf/2512.20588", "abs": "https://arxiv.org/abs/2512.20588", "authors": ["Demerson N. Gon\u00e7alves", "Tharso D. Fernandes", "Andrias M. M. Cordeiro", "Pedro H. G. Lugao", "Jo\u00e3o T. Dias"], "title": "Certified Lower Bounds and Efficient Estimation of Minimum Accuracy in Quantum Kernel Methods", "categories": ["quant-ph", "cs.DS"], "comment": "16 pages, 2 figures", "summary": "The minimum accuracy heuristic evaluates quantum feature maps without requiring full quantum support vector machine (QSVM) training. However, the original formulation is computationally expensive, restricted to balanced datasets, and lacks theoretical backing. This work generalizes the metric to arbitrary binary datasets and formally proves it constitutes a certified lower bound on the optimal empirical accuracy of any linear classifier in the same feature space. Furthermore, we introduce Monte Carlo strategies to efficiently estimate this bound using a random subset of Pauli directions, accompanied by rigorous probabilistic guarantees. These contributions establish minimum accuracy as a scalable, theoretically sound tool for pre-screening feature maps on near-term quantum devices.", "AI": {"tldr": "\u63a8\u5e7f\u6700\u5c0f\u51c6\u786e\u7387\u542f\u53d1\u5f0f\u6307\u6807\u7528\u4e8e\u4efb\u610f\u4e8c\u5143\u6570\u636e\u96c6\uff0c\u5f15\u5165\u8499\u7279\u5361\u7f57\u7b56\u7565\u6709\u6548\u4f30\u8ba1\u754c\u9650\uff0c\u4f7f\u6700\u5c0f\u51c6\u786e\u7387\u6210\u4e3a\u8fd1-term\u91cf\u5b50\u8bbe\u5907\u9884\u7b5b\u9009\u7279\u5f81\u56fe\u7684\u6709\u6548\u5de5\u5177\u3002", "motivation": "\u539f\u6700\u5c0f\u51c6\u786e\u7387\u542f\u53d1\u5f0f\u516c\u5f0f\u8ba1\u7b97\u6602\u8d35\u3001\u9650\u4e8e\u5e73\u8861\u6570\u636e\u96c6\u4e14\u7f3a\u4e4f\u7406\u8bba\u652f\u6301\uff0c\u9700\u6539\u8fdb\u63a8\u5e7f\u3002", "method": "\u5c06\u6307\u6807\u63a8\u5e7f\u5230\u4efb\u610f\u4e8c\u5143\u6570\u636e\u96c6\u5e76\u8bc1\u660e\u5176\u4e3a\u6700\u4f18\u7ecf\u9a8c\u51c6\u786e\u7387\u7684\u8ba4\u8bc1\u4e0b\u754c\uff1b\u5f15\u5165\u8499\u7279\u5361\u7f57\u7b56\u7565\uff0c\u7528\u968f\u673a\u5b50\u96c6\u7684Pauli\u65b9\u5411\u4f30\u8ba1\u754c\u9650\u5e76\u7ed9\u51fa\u6982\u7387\u4fdd\u8bc1\u3002", "result": "\u4f7f\u6700\u5c0f\u51c6\u786e\u7387\u6210\u4e3a\u53ef\u6269\u5c55\u3001\u7406\u8bba\u53ef\u9760\u7684\u5de5\u5177\u7528\u4e8e\u8fd1-term\u91cf\u5b50\u8bbe\u5907\u9884\u7b5b\u9009\u7279\u5f81\u56fe\u3002", "conclusion": "\u6700\u5c0f\u51c6\u786e\u7387\u53ef\u4f5c\u4e3a\u8fd1-term\u91cf\u5b50\u8bbe\u5907\u4e0a\u9884\u7b5b\u9009\u7279\u5f81\u56fe\u7684\u5de5\u5177\u3002"}}
{"id": "2512.19842", "pdf": "https://arxiv.org/pdf/2512.19842", "abs": "https://arxiv.org/abs/2512.19842", "authors": ["Andrea Sordello", "Marco Mellia", "Idilio Drago", "Rodolfo Valentim", "Francesco Musumeci", "Massimo Tornatore", "Federico Cerutti", "Martino Trevisan", "Alessio Botta", "Willen Borges Coelho"], "title": "Holoscope: Open and Lightweight Distributed Telescope & Honeypot Platform", "categories": ["cs.DC"], "comment": null, "summary": "The complexity and scale of Internet attacks call for distributed, cooperative observatories capable of monitoring malicious traffic across diverse networks. Holoscope is a lightweight, cloud-native platform designed to simplify the deployment and management of distributed telescope (passive) and honeypot (active) sensors, used to collect and analyse attack traffic by exposing or simulating vulnerable systems. Built upon K3s and WireGuard, Holoscope offers secure connectivity, automated node onboarding, and resilient operation even in resource-constrained environments. Through modular design and Infrastructure-as-Code principles, it supports dynamic sensor orchestration, automated recovery and processing. We build, deploy and operate Holoscope across multiple institutions and cloud networks in Europe and Brazil, enabling unified visibility into large-scale attack phenomena while maintaining ease of integration and security compliance.", "AI": {"tldr": "\u4ecb\u7ecd\u8f7b\u91cf\u7ea7\u4e91\u539f\u751f\u5e73\u53f0Holoscope\uff0c\u53ef\u7b80\u5316\u5206\u5e03\u5f0f\u4f20\u611f\u5668\u90e8\u7f72\u7ba1\u7406\uff0c\u5728\u591a\u673a\u6784\u548c\u4e91\u7f51\u7edc\u90e8\u7f72\u4f7f\u7528\u3002", "motivation": "\u4e92\u8054\u7f51\u653b\u51fb\u7684\u590d\u6742\u6027\u548c\u89c4\u6a21\u9700\u8981\u5206\u5e03\u5f0f\u3001\u534f\u4f5c\u7684\u89c2\u6d4b\u7ad9\u6765\u76d1\u6d4b\u6076\u610f\u6d41\u91cf\uff0c\u8bbe\u8ba1Holoscope\u5e73\u53f0\u4ee5\u6ee1\u8db3\u6b64\u9700\u6c42\u3002", "method": "\u57fa\u4e8eK3s\u548cWireGuard\u6784\u5efa\uff0c\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u539f\u5219\uff0c\u652f\u6301\u52a8\u6001\u4f20\u611f\u5668\u7f16\u6392\u3001\u81ea\u52a8\u6062\u590d\u548c\u5904\u7406\u3002", "result": "\u5728\u6b27\u6d32\u548c\u5df4\u897f\u7684\u591a\u4e2a\u673a\u6784\u548c\u4e91\u7f51\u7edc\u4e2d\u6784\u5efa\u3001\u90e8\u7f72\u548c\u8fd0\u884c\u4e86Holoscope\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5927\u89c4\u6a21\u653b\u51fb\u73b0\u8c61\u7684\u7edf\u4e00\u53ef\u89c1\u6027\u3002", "conclusion": "Holoscope\u80fd\u7b80\u5316\u5206\u5e03\u5f0f\u4f20\u611f\u5668\u90e8\u7f72\u7ba1\u7406\uff0c\u5728\u591a\u7f51\u7edc\u73af\u5883\u5b9e\u73b0\u7edf\u4e00\u653b\u51fb\u76d1\u6d4b\uff0c\u4e14\u4fdd\u6301\u96c6\u6210\u4fbf\u6377\u6027\u548c\u5b89\u5168\u5408\u89c4\u6027\u3002"}}
{"id": "2512.19958", "pdf": "https://arxiv.org/pdf/2512.19958", "abs": "https://arxiv.org/abs/2512.19958", "authors": ["Sneha Oommen", "Gabby Sanchez", "Cassandra T. Britto", "Di Wang", "Jordan Chiou", "Maria Spichkova"], "title": "Towards Analysing Invoices and Receipts with Amazon Textract", "categories": ["cs.IR", "cs.SE"], "comment": null, "summary": "This paper presents an evaluation of the AWS Textract in the context of extracting data from receipts. We analyse Textract functionalities using a dataset that includes receipts of varied formats and conditions. Our analysis provided a qualitative view of Textract strengths and limitations. While the receipts totals were consistently detected, we also observed typical issues and irregularities that were often influenced by image quality and layout. Based on the analysis of the observations, we propose mitigation strategies.", "AI": {"tldr": "\u8bc4\u4f30AWS Textract\u4ece\u6536\u636e\u63d0\u53d6\u6570\u636e\u7684\u80fd\u529b\uff0c\u5206\u6790\u5176\u4f18\u7f3a\u70b9\u5e76\u63d0\u51fa\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u8bc4\u4f30AWS Textract\u5728\u4ece\u6536\u636e\u63d0\u53d6\u6570\u636e\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u5305\u542b\u4e0d\u540c\u683c\u5f0f\u548c\u6761\u4ef6\u6536\u636e\u7684\u6570\u636e\u96c6\u6765\u5206\u6790Textract\u7684\u529f\u80fd\u3002", "result": "\u80fd\u6301\u7eed\u68c0\u6d4b\u5230\u6536\u636e\u603b\u989d\uff0c\u4f46\u5b58\u5728\u53d7\u56fe\u50cf\u8d28\u91cf\u548c\u5e03\u5c40\u5f71\u54cd\u7684\u5178\u578b\u95ee\u9898\u548c\u4e0d\u89c4\u5219\u60c5\u51b5\u3002", "conclusion": "\u57fa\u4e8e\u89c2\u5bdf\u5206\u6790\u63d0\u51fa\u4e86\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2512.19799", "pdf": "https://arxiv.org/pdf/2512.19799", "abs": "https://arxiv.org/abs/2512.19799", "authors": ["Tingjia Miao", "Jiawen Dai", "Jingkun Liu", "Jinxin Tan", "Muhua Zhang", "Wenkai Jin", "Yuwen Du", "Tian Jin", "Xianghe Pang", "Zexi Liu", "Tu Guo", "Zhengliang Zhang", "Yunjie Huang", "Shuo Chen", "Rui Ye", "Yuzhi Zhang", "Linfeng Zhang", "Kun Chen", "Wei Wang", "Weinan E", "Siheng Chen"], "title": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research", "categories": ["cs.AI"], "comment": "32 pages, 10 figures", "summary": "Advances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving ability in open scientific scenarios. This is particularly true in physics, which is abstract, mathematically intensive, and requires integrating analytical reasoning with code-based computation. To address this, we propose PhysMaster, an LLM-based agent functioning as an autonomous theoretical and computational physicist. PhysMaster couples absract reasoning with numerical computation and leverages LANDAU, the Layered Academic Data Universe, which preserves retrieved literature, curated prior knowledge, and validated methodological traces, enhancing decision reliability and stability. It also employs an adaptive exploration strategy balancing efficiency and open-ended exploration, enabling robust performance in ultra-long-horizon tasks. We evaluate PhysMaster on problems from high-energy theory, condensed matter theory to astrophysics, including: (i) acceleration, compressing labor-intensive research from months to hours; (ii) automation, autonomously executing hypothesis-driven loops ; and (iii) autonomous discovery, independently exploring open problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53PhysMaster\uff0c\u53ef\u5728\u9ad8\u80fd\u7406\u8bba\u3001\u51dd\u805a\u6001\u7406\u8bba\u548c\u5929\u4f53\u7269\u7406\u7b49\u95ee\u9898\u4e0a\u5b9e\u73b0\u7814\u7a76\u52a0\u901f\u3001\u81ea\u52a8\u5316\u548c\u81ea\u4e3b\u53d1\u73b0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5728\u5f00\u653e\u79d1\u5b66\u573a\u666f\u7684\u7aef\u5230\u7aef\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u6709\u9650\uff0c\u5c24\u5176\u662f\u5728\u7269\u7406\u9886\u57df\uff0c\u9700\u8981\u65b0\u7684\u667a\u80fd\u4f53\u6765\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u63d0\u51faPhysMaster\uff0c\u5c06\u62bd\u8c61\u63a8\u7406\u4e0e\u6570\u503c\u8ba1\u7b97\u76f8\u7ed3\u5408\uff0c\u5229\u7528LANDAU\u589e\u5f3a\u51b3\u7b56\u7684\u53ef\u9760\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u5728\u9ad8\u80fd\u7406\u8bba\u3001\u51dd\u805a\u6001\u7406\u8bba\u5230\u5929\u4f53\u7269\u7406\u7b49\u95ee\u9898\u7684\u8bc4\u4f30\u4e2d\uff0c\u5b9e\u73b0\u4e86\u52a0\u901f\u7814\u7a76\u3001\u81ea\u52a8\u5316\u6267\u884c\u548c\u81ea\u4e3b\u53d1\u73b0\u3002", "conclusion": "PhysMaster\u80fd\u5728\u5f00\u653e\u79d1\u5b66\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u6027\u80fd\uff0c\u53ef\u8f85\u52a9\u3001\u52a0\u901f\u548c\u81ea\u52a8\u5316\u7269\u7406\u7814\u7a76\u3002"}}
{"id": "2512.20112", "pdf": "https://arxiv.org/pdf/2512.20112", "abs": "https://arxiv.org/abs/2512.20112", "authors": ["Xian-Rong Zhang", "Yue-Jiao Gong", "Wei-Neng Chen", "Jun Zhang"], "title": "Evolutionary Neural Architecture Search with Dual Contrastive Learning", "categories": ["cs.NE", "cs.AI"], "comment": "26 pages", "summary": "Evolutionary Neural Architecture Search (ENAS) has gained attention for automatically designing neural network architectures. Recent studies use a neural predictor to guide the process, but the high computational costs of gathering training data -- since each label requires fully training an architecture -- make achieving a high-precision predictor with { limited compute budget (i.e., a capped number of fully trained architecture-label pairs)} crucial for ENAS success. This paper introduces ENAS with Dual Contrastive Learning (DCL-ENAS), a novel method that employs two stages of contrastive learning to train the neural predictor. In the first stage, contrastive self-supervised learning is used to learn meaningful representations from neural architectures without requiring labels. In the second stage, fine-tuning with contrastive learning is performed to accurately predict the relative performance of different architectures rather than their absolute performance, which is sufficient to guide the evolutionary search. Across NASBench-101 and NASBench-201, DCL-ENAS achieves the highest validation accuracy, surpassing the strongest published baselines by 0.05\\% (ImageNet16-120) to 0.39\\% (NASBench-101). On a real-world ECG arrhythmia classification task, DCL-ENAS improves performance by approximately 2.5 percentage points over a manually designed, non-NAS model obtained via random search, while requiring only 7.7 GPU-days.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDCL - ENAS\u65b9\u6cd5\uff0c\u5229\u7528\u4e24\u9636\u6bb5\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u795e\u7ecf\u9884\u6d4b\u5668\u7528\u4e8eENAS\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u5b9e\u9645\u4efb\u52a1\u4e2d\u53d6\u5f97\u8f83\u597d\u6548\u679c\u3002", "motivation": "\u73b0\u6709ENAS\u4f7f\u7528\u795e\u7ecf\u9884\u6d4b\u5668\u65f6\u6536\u96c6\u8bad\u7ec3\u6570\u636e\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u83b7\u5f97\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u5668\u5bf9ENAS\u6210\u529f\u5f88\u5173\u952e\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u795e\u7ecf\u9884\u6d4b\u5668\uff0c\u7b2c\u4e00\u9636\u6bb5\u7528\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u4ece\u65e0\u6807\u7b7e\u7684\u795e\u7ecf\u67b6\u6784\u4e2d\u5b66\u4e60\u8868\u793a\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7528\u5bf9\u6bd4\u5b66\u4e60\u5fae\u8c03\u4ee5\u9884\u6d4b\u76f8\u5bf9\u6027\u80fd\u6765\u6307\u5bfc\u8fdb\u5316\u641c\u7d22\u3002", "result": "\u5728NASBench - 101\u548cNASBench - 201\u4e0a\u8fbe\u5230\u6700\u9ad8\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u5728\u771f\u5b9eECG\u5fc3\u5f8b\u5931\u5e38\u5206\u7c7b\u4efb\u52a1\u4e0a\u6bd4\u624b\u52a8\u8bbe\u8ba1\u6a21\u578b\u6027\u80fd\u63d0\u9ad8\u7ea62.5\u4e2a\u767e\u5206\u70b9\uff0c\u4ec5\u97007.7 GPU - \u5929\u3002", "conclusion": "DCL - ENAS\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u63d0\u5347ENAS\u6027\u80fd\u3002"}}
{"id": "2512.20261", "pdf": "https://arxiv.org/pdf/2512.20261", "abs": "https://arxiv.org/abs/2512.20261", "authors": ["Edith Elkind", "Michele Flammini", "Giovanna Varricchio"], "title": "Maximizing the Egalitarian Welfare in Friends and Enemies Games", "categories": ["cs.GT"], "comment": "Accepted paper at AAMAS'26", "summary": "We consider the complexity of maximizing egalitarian welfare in Friends and Enemies Games -- a subclass of hedonic games in which every agent partitions other agents into friends and enemies. We investigate two classic scenarios proposed in the literature, namely, Friends Appreciation ($\\mathsf{FA}$) and Enemies Aversion ($\\mathsf{EA}$): in the former, each agent primarily cares about the number of friends in her coalition, breaking ties based on the number of enemies, while in the latter, the opposite is true. For $\\mathsf{EA}$, we show that our objective is hard to approximate within $O(n^{1-\u03b5})$, for any fixed $\u03b5>0$, and provide a polynomial-time $(n-1)$-approximation. For $\\mathsf{FA}$, we obtain an NP-hardness result and a polynomial-time approximation algorithm. Our algorithm achieves a ratio of $2-\u0398(\\frac{1}{n})$ when every agent has at least two friends; however, if some agent has at most one friend, its approximation ratio deteriorates to $n/2$. We recover the $2-\u0398(\\frac{1}{n})$ approximation ratio for two important variants: when randomization is allowed and when the friendship relationship is symmetric. Additionally, for both $\\mathsf{EA}$ and $\\mathsf{FA}$ we identify special cases where the optimal egalitarian partition can be computed in polynomial time.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u670b\u53cb\u4e0e\u654c\u4eba\u535a\u5f08\u4e2d\u6700\u5927\u5316\u5e73\u7b49\u798f\u5229\u7684\u590d\u6742\u6027\uff0c\u5206\u6790\u4e86FA\u548cEA\u4e24\u79cd\u573a\u666f\uff0c\u7ed9\u51fa\u96be\u89e3\u6027\u3001\u8fd1\u4f3c\u7b97\u6cd5\u53ca\u7279\u6b8a\u53ef\u884c\u60c5\u51b5\u3002", "motivation": "\u63a2\u7a76\u670b\u53cb\u4e0e\u654c\u4eba\u535a\u5f08\u4e2d\uff08\u53c2\u4e0e\u8005\u5c06\u4ed6\u4eba\u5206\u4e3a\u670b\u53cb\u548c\u654c\u4eba\uff09\u7684\u4e24\u79cd\u7ecf\u5178\u573a\u666f\u4e0b\u6700\u5927\u5316\u5e73\u7b49\u798f\u5229\u7684\u590d\u6742\u5ea6\u95ee\u9898\u3002", "method": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u96be\u89e3\u6027\uff0c\u8bbe\u8ba1\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u9488\u5bf9\u4e0d\u540c\u6761\u4ef6\u6c42\u89e3\u3002", "result": "EA\u96be\u4ee5\u8fd1\u4f3c\uff0c\u7ed9\u51fa(n - 1)\u8fd1\u4f3c\u7b97\u6cd5\uff1bFA\u8bc1\u660eNP\u96be\u5e76\u8bbe\u8ba1\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u6709\u4e0d\u540c\u8fd1\u4f3c\u6bd4\uff0c\u8fd8\u7ed9\u51fa\u4e24\u79cd\u53d8\u4f53\u7684\u8fd1\u4f3c\u6bd4\u3002\u6b64\u5916\uff0c\u627e\u51fa\u4e24\u79cd\u573a\u666f\u4e0b\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u8ba1\u7b97\u6700\u4f18\u89e3\u7684\u7279\u6b8a\u60c5\u51b5\u3002", "conclusion": "\u660e\u786e\u4e86\u4e24\u79cd\u573a\u666f\u4e0b\u6700\u5927\u5316\u5e73\u7b49\u798f\u5229\u95ee\u9898\u7684\u590d\u6742\u5ea6\u53ca\u76f8\u5e94\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u627e\u5230\u7279\u6b8a\u53ef\u89e3\u60c5\u51b5\u3002"}}
{"id": "2512.20178", "pdf": "https://arxiv.org/pdf/2512.20178", "abs": "https://arxiv.org/abs/2512.20178", "authors": ["Chen Zhuang", "Lingqi Zhang", "Benjamin Brock", "Du Wu", "Peng Chen", "Toshio Endo", "Satoshi Matsuoka", "Mohamed Wahib"], "title": "SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication", "categories": ["cs.DC", "cs.PF"], "comment": "Under Review", "summary": "Distributed Sparse Matrix-Matrix Multiplication (SpMM) is a fundamental operation in numerous high-performance computing and deep learning applications. The major performance bottleneck in distributed SpMM lies in the substantial communication overhead, which limits both performance and scalability. In this paper, we identify and analyze sources of inefficient communication in existing distributed SpMM implementations at two levels and address these inefficiencies by proposing: (1) a fine-grained, sparsity-aware communication strategy that reduces communication overhead by exploiting the sparsity pattern of the sparse matrix, and (2) a hierarchical communication strategy that integrates the sparsity-aware strategy with the common two-tier network architectures in GPU-accelerated systems, to reduce redundant communication across slow network links. We implement these optimizations in a comprehensive distributed SpMM framework, \\method{}. Extensive evaluations on real-world datasets show that our framework demonstrates strong scalability up to 128 GPUs, achieving geometric mean speedups of 221.5$\\times$, 56.0$\\times$, 23.4$\\times$, and 8.8$\\times$ over four state-of-the-art baselines (CAGNET, SPA, BCL, and CoLa, respectively) at this scale.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5206\u5e03\u5f0f\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u901a\u4fe1\u5f00\u9500\u5927\u95ee\u9898\uff0c\u63d0\u51fa\u4f18\u5316\u7b56\u7565\u5e76\u5b9e\u73b0\u6846\u67b6\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\u5f3a\u6269\u5c55\u6027\u548c\u663e\u8457\u52a0\u901f\u6bd4\u3002", "motivation": "\u5206\u5e03\u5f0f\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u7684\u4e3b\u8981\u6027\u80fd\u74f6\u9888\u5728\u4e8e\u5927\u91cf\u901a\u4fe1\u5f00\u9500\uff0c\u9650\u5236\u4e86\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u7ec6\u7c92\u5ea6\u3001\u611f\u77e5\u7a00\u758f\u6027\u7684\u901a\u4fe1\u7b56\u7565\u548c\u5206\u5c42\u901a\u4fe1\u7b56\u7565\uff0c\u5e76\u5728\u7efc\u5408\u5206\u5e03\u5f0f\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u6846\u67b6\u4e2d\u5b9e\u73b0\u8fd9\u4e9b\u4f18\u5316\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8868\u660e\uff0c\u6846\u67b6\u5728 128 \u4e2a GPU \u4e0a\u5177\u6709\u5f3a\u6269\u5c55\u6027\uff0c\u4e0e\u56db\u4e2a\u5148\u8fdb\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5206\u522b\u5b9e\u73b0\u4e86 221.5\u00d7\u300156.0\u00d7\u300123.4\u00d7\u548c 8.8\u00d7\u7684\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f18\u5316\u7b56\u7565\u548c\u5b9e\u73b0\u7684\u6846\u67b6\u6709\u6548\uff0c\u80fd\u663e\u8457\u63d0\u5347\u5206\u5e03\u5f0f\u7a00\u758f\u77e9\u9635\u4e58\u6cd5\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2512.19750", "pdf": "https://arxiv.org/pdf/2512.19750", "abs": "https://arxiv.org/abs/2512.19750", "authors": ["Ilsun Chang"], "title": "Risk-Aware GPU-Assisted Cardinality Estimation for Cost-Based Query Optimizers", "categories": ["cs.DB"], "comment": "6 pages, 9 figures", "summary": "Cardinality estimation is a cornerstone of cost-based optimizers (CBOs), yet real-world workloads often violate the assumptions behind static statistics, degrading decision stability and increasing plan flip rates. We empirically characterize failures caused by stale statistics, skew, join correlations, hidden distributions in bind variables, and sampling bias, and quantify the overhead and break-even points of hardware-accelerated measurement.\n  We propose GACE (GPU-Assisted Cardinality Estimation), a hybrid auxiliary architecture that augments rather than replaces the optimizer. GACE selectively invokes GPU-based measurement only in risky intervals via a Risky Gate that detects estimation uncertainty, and a GPU Measurement Engine that performs high-speed probing with explicit cost accounting for the measurement itself. This design preserves low overhead in stable regions while improving plan stability and reducing tail latency (P99) in problematic scenarios.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u57fa\u6570\u4f30\u8ba1\u5728\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u5b58\u5728\u95ee\u9898\uff0c\u63d0\u51faGACE\u67b6\u6784\uff0c\u53ef\u5728\u7a33\u5b9a\u533a\u57df\u4fdd\u6301\u4f4e\u5f00\u9500\uff0c\u5728\u95ee\u9898\u573a\u666f\u63d0\u5347\u8ba1\u5212\u7a33\u5b9a\u6027\u548c\u964d\u4f4e\u5c3e\u5ef6\u8fdf\u3002", "motivation": "\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u5e38\u8fdd\u80cc\u9759\u6001\u7edf\u8ba1\u5047\u8bbe\uff0c\u5bfc\u81f4\u57fa\u6570\u4f30\u8ba1\u5931\u8d25\uff0c\u964d\u4f4e\u51b3\u7b56\u7a33\u5b9a\u6027\u548c\u589e\u52a0\u8ba1\u5212\u7ffb\u8f6c\u7387\u3002", "method": "\u63d0\u51faGACE\u6df7\u5408\u8f85\u52a9\u67b6\u6784\uff0c\u901a\u8fc7\u98ce\u9669\u95e8\u68c0\u6d4b\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0cGPU\u6d4b\u91cf\u5f15\u64ce\u9ad8\u901f\u63a2\u6d4b\u5e76\u660e\u786e\u6d4b\u91cf\u6210\u672c\uff0c\u4ec5\u5728\u98ce\u9669\u533a\u95f4\u8c03\u7528GPU\u6d4b\u91cf\u3002", "result": "\u5728\u7a33\u5b9a\u533a\u57df\u4fdd\u6301\u4f4e\u5f00\u9500\uff0c\u5728\u95ee\u9898\u573a\u666f\u63d0\u5347\u8ba1\u5212\u7a33\u5b9a\u6027\u548c\u964d\u4f4e\u5c3e\u5ef6\u8fdf\uff08P99\uff09\u3002", "conclusion": "GACE\u67b6\u6784\u80fd\u6709\u6548\u89e3\u51b3\u57fa\u6570\u4f30\u8ba1\u5728\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u95ee\u9898\u3002"}}
{"id": "2512.19912", "pdf": "https://arxiv.org/pdf/2512.19912", "abs": "https://arxiv.org/abs/2512.19912", "authors": ["Thi-Hoa Nguyen", "Viljar H. Gjerde", "Bruno A. Roccia", "Cristian G. Gebhardt"], "title": "Solving strategies for data-driven one-dimensional elasticity exhibiting nonlinear strains", "categories": ["cs.CE", "math.OC"], "comment": null, "summary": "In this work, we extend and generalize our solving strategy, first introduced in [1], based on a greedy optimization algorithm and the alternating direction method (ADM) for nonlinear systems computed with multiple load steps. In particular, we combine the greedy optimization algorithm with the direct data-driven solver based on ADM which is firstly introduced in [2] and combined with the Newton-Raphson method for nonlinear elasticity in [3]. We numerically illustrate via one- and two-dimensional bar and truss structures exhibiting nonlinear strain measures and different constitutive datasets that our solving strategy generally achieves a better approximation of the globally optimal solution. This, however, comes at the expense of higher computational cost which is scaled by the number of \"greedy\" searches. Using this solving strategy, we reproduce the first cycle of the cyclic testing for a nylon rope that was performed at industrial testing facilities for mooring lines manufacturers. We also numerically illustrate for a truss structure that our solving strategy generally improves the accuracy and robustness in cases of an unsymmetrical data distribution and noisy data.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u5e76\u63a8\u5e7f\u6c42\u89e3\u7b56\u7565\uff0c\u7ed3\u5408\u8d2a\u5fc3\u4f18\u5316\u7b97\u6cd5\u548cADM\uff0c\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u5176\u80fd\u66f4\u597d\u903c\u8fd1\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u53ef\u7528\u4e8e\u5c3c\u9f99\u7ef3\u5faa\u73af\u6d4b\u8bd5\u7b49\uff0c\u4e14\u5728\u975e\u5bf9\u79f0\u6570\u636e\u548c\u566a\u58f0\u6570\u636e\u4e0b\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u6269\u5c55\u548c\u63a8\u5e7f\u57fa\u4e8e\u8d2a\u5fc3\u4f18\u5316\u7b97\u6cd5\u548c\u4ea4\u66ff\u65b9\u5411\u6cd5\uff08ADM\uff09\u7684\u6c42\u89e3\u7b56\u7565\uff0c\u7528\u4e8e\u591a\u8f7d\u8377\u6b65\u8ba1\u7b97\u975e\u7ebf\u6027\u7cfb\u7edf\u3002", "method": "\u5c06\u8d2a\u5fc3\u4f18\u5316\u7b97\u6cd5\u4e0e\u57fa\u4e8eADM\u7684\u76f4\u63a5\u6570\u636e\u9a71\u52a8\u6c42\u89e3\u5668\u76f8\u7ed3\u5408\uff0c\u5e76\u7ed3\u5408\u725b\u987f - \u62c9\u592b\u900a\u65b9\u6cd5\u7528\u4e8e\u975e\u7ebf\u6027\u5f39\u6027\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u4e00\u7ef4\u548c\u4e8c\u7ef4\u6746\u53ca\u6841\u67b6\u7ed3\u6784\u6570\u503c\u5b9e\u9a8c\uff0c\u8be5\u7b56\u7565\u80fd\u66f4\u597d\u903c\u8fd1\u5168\u5c40\u6700\u4f18\u89e3\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u968f\u201c\u8d2a\u5fc3\u201d\u641c\u7d22\u6b21\u6570\u589e\u52a0\uff1b\u53ef\u91cd\u73b0\u5c3c\u9f99\u7ef3\u5faa\u73af\u6d4b\u8bd5\u9996\u4e2a\u5468\u671f\uff1b\u5728\u975e\u5bf9\u79f0\u6570\u636e\u548c\u566a\u58f0\u6570\u636e\u4e0b\uff0c\u63d0\u9ad8\u4e86\u6841\u67b6\u7ed3\u6784\u6c42\u89e3\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6c42\u89e3\u7b56\u7565\u6709\u66f4\u597d\u7684\u5168\u5c40\u6700\u4f18\u89e3\u903c\u8fd1\u80fd\u529b\u548c\u9c81\u68d2\u6027\uff0c\u867d\u6709\u8ba1\u7b97\u6210\u672c\u4ee3\u4ef7\uff0c\u4f46\u53ef\u7528\u4e8e\u5b9e\u9645\u95ee\u9898\u3002"}}
{"id": "2512.19986", "pdf": "https://arxiv.org/pdf/2512.19986", "abs": "https://arxiv.org/abs/2512.19986", "authors": ["Nikolaos Iliopoulos"], "title": "Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization", "categories": ["q-fin.PM", "cs.LG", "cs.NE", "q-fin.CP"], "comment": "9 pages, 3 figures, 5 tables", "summary": "Metaheuristic algorithms for cardinality-constrained portfolio optimization require repair operators to map infeasible candidates onto the feasible region. Standard Euclidean projection treats assets as independent and can ignore the covariance structure that governs portfolio risk, potentially producing less diversified portfolios. This paper introduces Covariance-Aware Simplex Projection (CASP), a two-stage repair operator that (i) selects a target number of assets using volatility-normalized scores and (ii) projects the candidate weights using a covariance-aware geometry aligned with tracking-error risk. This provides a portfolio-theoretic foundation for using a covariance-induced distance in repair operators. On S&P 500 data (2020-2024), CASP-Basic delivers materially lower portfolio variance than standard Euclidean repair without relying on return estimates, with improvements that are robust across assets and statistically significant. Ablation results indicate that volatility-normalized selection drives most of the variance reduction, while the covariance-aware projection provides an additional, consistent improvement. We further show that optional return-aware extensions can improve Sharpe ratios, and out-of-sample tests confirm that gains transfer to realized performance. CASP integrates as a drop-in replacement for Euclidean projection in metaheuristic portfolio optimizers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u534f\u65b9\u5dee\u611f\u77e5\u5355\u7eaf\u5f62\u6295\u5f71\uff08CASP\uff09\u4fee\u590d\u7b97\u5b50\u7528\u4e8e\u57fa\u6570\u7ea6\u675f\u6295\u8d44\u7ec4\u5408\u4f18\u5316\uff0c\u5728S&P 500\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u6295\u5f71\uff0c\u53ef\u964d\u4f4e\u6295\u8d44\u7ec4\u5408\u65b9\u5dee\u3002", "motivation": "\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u6295\u5f71\u5728\u5904\u7406\u57fa\u6570\u7ea6\u675f\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u65f6\u5ffd\u7565\u8d44\u4ea7\u534f\u65b9\u5dee\u7ed3\u6784\uff0c\u53ef\u80fd\u5bfc\u81f4\u6295\u8d44\u7ec4\u5408\u5206\u6563\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u7684CASP\u4fee\u590d\u7b97\u5b50\uff0c\u5148\u4f7f\u7528\u6ce2\u52a8\u7387\u5f52\u4e00\u5316\u5206\u6570\u9009\u62e9\u76ee\u6807\u6570\u91cf\u8d44\u4ea7\uff0c\u518d\u4f7f\u7528\u4e0e\u8ddf\u8e2a\u8bef\u5dee\u98ce\u9669\u5bf9\u9f50\u7684\u534f\u65b9\u5dee\u611f\u77e5\u51e0\u4f55\u6295\u5f71\u5019\u9009\u6743\u91cd\u3002", "result": "\u5728S&P 500\u6570\u636e\uff082020 - 2024\uff09\u4e0a\uff0cCASP - Basic\u663e\u8457\u964d\u4f4e\u6295\u8d44\u7ec4\u5408\u65b9\u5dee\uff0c\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u6ce2\u52a8\u7387\u5f52\u4e00\u5316\u9009\u62e9\u662f\u964d\u4f4e\u65b9\u5dee\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u534f\u65b9\u5dee\u611f\u77e5\u6295\u5f71\u6709\u989d\u5916\u6539\u8fdb\uff0c\u53ef\u9009\u7684\u6536\u76ca\u611f\u77e5\u6269\u5c55\u80fd\u63d0\u9ad8\u590f\u666e\u6bd4\u7387\u3002", "conclusion": "CASP\u53ef\u4f5c\u4e3a\u5143\u542f\u53d1\u5f0f\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u5668\u4e2d\u6b27\u51e0\u91cc\u5f97\u6295\u5f71\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002"}}
{"id": "2512.19701", "pdf": "https://arxiv.org/pdf/2512.19701", "abs": "https://arxiv.org/abs/2512.19701", "authors": ["Yuxuan Yin", "Shengke Zhou", "Yunjie Zhang", "Ajay Mohindra", "Boxun Xu", "Peng Li"], "title": "Large Language Models for EDA Cloud Job Resource and Lifetime Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 6 figures", "summary": "The rapid growth of cloud computing in the Electronic Design Automation (EDA) industry has created a critical need for resource and job lifetime prediction to achieve optimal scheduling. Traditional machine learning methods often struggle with the complexity and heterogeneity of EDA workloads, requiring extensive feature engineering and domain expertise. We propose a novel framework that fine-tunes Large Language Models (LLMs) to address this challenge through text-to-text regression. We introduce the scientific notation and prefix filling to constrain the LLM, significantly improving output format reliability. Moreover, we found that full-attention finetuning and inference improves the prediction accuracy of sliding-window-attention LLMs. We demonstrate the effectiveness of our proposed framework on real-world cloud datasets, setting a new baseline for performance prediction in the EDA domain.", "AI": {"tldr": "\u63d0\u51fa\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\u89e3\u51b3EDA\u884c\u4e1a\u4e91\u8ba1\u7b97\u8d44\u6e90\u548c\u4f5c\u4e1a\u5bff\u547d\u9884\u6d4b\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u4e91\u8ba1\u7b97\u5728EDA\u884c\u4e1a\u5feb\u901f\u53d1\u5c55\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u590d\u6742\u5f02\u6784\u7684EDA\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u9700\u8d44\u6e90\u548c\u4f5c\u4e1a\u5bff\u547d\u9884\u6d4b\u4ee5\u5b9e\u73b0\u6700\u4f18\u8c03\u5ea6\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u6587\u672c\u5230\u6587\u672c\u56de\u5f52\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u5f15\u5165\u79d1\u5b66\u8bb0\u6570\u6cd5\u548c\u524d\u7f00\u586b\u5145\u7ea6\u675f\u6a21\u578b\uff0c\u4f7f\u7528\u5168\u6ce8\u610f\u529b\u5fae\u8c03\u4e0e\u63a8\u7406\u3002", "result": "\u63d0\u9ad8\u4e86\u8f93\u51fa\u683c\u5f0f\u53ef\u9760\u6027\u548c\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5728\u771f\u5b9e\u4e91\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u4e3aEDA\u9886\u57df\u6027\u80fd\u9884\u6d4b\u8bbe\u5b9a\u4e86\u65b0\u57fa\u51c6\u3002"}}
{"id": "2512.20216", "pdf": "https://arxiv.org/pdf/2512.20216", "abs": "https://arxiv.org/abs/2512.20216", "authors": ["Linuk Perera"], "title": "Quantitative Financial Modeling for Sri Lankan Markets: Approach Combining NLP, Clustering and Time-Series Forecasting", "categories": ["q-fin.CP"], "comment": "08 Pages, 9 Figures, Published in the Proceedings of the 32'nd IET Sri Lanka Annual Technical Conference 2025 of the IET Sri Lanka Network; Second Runner Up Paper of the Conference", "summary": "This research introduces a novel quantitative methodology tailored for quantitative finance applications, enabling banks, stockbrokers, and investors to predict economic regimes and market signals in emerging markets, specifically Sri Lankan stock indices (S&P SL20 and ASPI) by integrating Environmental, Social, and Governance (ESG) sentiment analysis with macroeconomic indicators and advanced time-series forecasting. Designed to leverage quantitative techniques for enhanced risk assessment, portfolio optimization, and trading strategies in volatile environments, the architecture employs FinBERT, a transformer-based NLP model, to extract sentiment from ESG texts, followed by unsupervised clustering (UMAP/HDBSCAN) to identify 5 latent ESG regimes, validated via PCA. These regimes are mapped to economic conditions using a dense neural network and gradient boosting classifier, achieving 84.04% training and 82.0% validation accuracy. Concurrently, time-series models (SRNN, MLP, LSTM, GRU) forecast daily closing prices, with GRU attaining an R-squared of 0.801 and LSTM delivering 52.78% directional accuracy on intraday data. A strong correlation between S&P SL20 and S&P 500, observed through moving average and volatility trend plots, further bolsters forecasting precision. A rule-based fusion logic merges ESG and time-series outputs for final market signals. By addressing literature gaps that overlook emerging markets and holistic integration, this quant-driven framework combines global correlations and local sentiment analysis to offer scalable, accurate tools for quantitative finance professionals navigating complex markets like Sri Lanka.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u9002\u7528\u4e8e\u91cf\u5316\u91d1\u878d\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408ESG\u60c5\u7eea\u5206\u6790\u3001\u5b8f\u89c2\u6307\u6807\u548c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u7528\u4e8e\u9884\u6d4b\u65af\u91cc\u5170\u5361\u80a1\u5e02\u7ecf\u6d4e\u5236\u5ea6\u548c\u5e02\u573a\u4fe1\u53f7\uff0c\u65b9\u6cd5\u96c6\u6210\u6548\u679c\u4f73\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u5ffd\u89c6\u65b0\u5174\u5e02\u573a\u548c\u6574\u4f53\u6574\u5408\uff0c\u4e3a\u91cf\u5316\u91d1\u878d\u4ece\u4e1a\u8005\u5728\u590d\u6742\u5e02\u573a\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u51c6\u786e\u5de5\u5177\u3002", "method": "\u91c7\u7528FinBERT\u63d0\u53d6ESG\u6587\u672c\u60c5\u7eea\uff0c\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u8bc6\u522b5\u79cd\u6f5c\u5728ESG\u5236\u5ea6\uff0c\u901a\u8fc7\u5bc6\u96c6\u795e\u7ecf\u7f51\u7edc\u548c\u68af\u5ea6\u63d0\u5347\u5206\u7c7b\u5668\u6620\u5c04\u7ecf\u6d4e\u72b6\u51b5\uff1b\u7528\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u9884\u6d4b\u6536\u76d8\u4ef7\uff1b\u7528\u89c4\u5219\u878d\u5408\u903b\u8f91\u5408\u5e76\u8f93\u51fa\u3002", "result": "ESG\u5236\u5ea6\u5206\u7c7b\u8bad\u7ec3\u51c6\u786e\u738784.04%\uff0c\u9a8c\u8bc1\u51c6\u786e\u738782.0%\uff1bGRU\u7684R\u5e73\u65b9\u4e3a0.801\uff0cLSTM\u65e5\u5185\u6570\u636e\u65b9\u5411\u51c6\u786e\u738752.78%\uff1b\u53d1\u73b0S&P SL20\u548cS&P 500\u5f3a\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u91cf\u5316\u9a71\u52a8\u6846\u67b6\u7ed3\u5408\u5168\u7403\u76f8\u5173\u6027\u548c\u672c\u5730\u60c5\u7eea\u5206\u6790\uff0c\u80fd\u4e3a\u91cf\u5316\u91d1\u878d\u4e13\u4e1a\u4eba\u58eb\u63d0\u4f9b\u5de5\u5177\u3002"}}
{"id": "2512.19984", "pdf": "https://arxiv.org/pdf/2512.19984", "abs": "https://arxiv.org/abs/2512.19984", "authors": ["Ali Zeytoon-Nejad"], "title": "Milton Friedman's spending matrix revisited: 'Spending efficiency' and 'preference compatibility' across different economic systems", "categories": ["econ.GN"], "comment": null, "summary": "This article expands Milton Friedman's spending matrix to analyse 'spending efficiency' and 'preference compatibility' across different economic systems against five key outcome criteria. By generalising Friedman's typology, it compares efficiency and freedom as systems shift from laissez-faire capitalism to communism, illustrating a gradual deterioration in their key outcomes. While government intervention is sometimes necessary to address market failures, its role should always be carefully limited to avoid inefficiency and misalignment with individual preferences. The insights may provide guidance for policymakers in designing economic systems and policies that promote both economic prosperity and personal liberty.", "AI": {"tldr": "\u6587\u7ae0\u6269\u5c55Friedman\u652f\u51fa\u77e9\u9635\uff0c\u5bf9\u6bd4\u4e0d\u540c\u7ecf\u6d4e\u7cfb\u7edf\u4e0b\u652f\u51fa\u6548\u7387\u548c\u504f\u597d\u517c\u5bb9\u6027\uff0c\u6307\u51fa\u653f\u5e9c\u5e72\u9884\u5e94\u53d7\u9650\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5206\u6790\u4e0d\u540c\u7ecf\u6d4e\u7cfb\u7edf\u4e0b\u7684'\u652f\u51fa\u6548\u7387'\u548c'\u504f\u597d\u517c\u5bb9\u6027'\uff0c\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u8bbe\u8ba1\u7ecf\u6d4e\u7cfb\u7edf\u548c\u653f\u7b56\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u6269\u5c55Milton Friedman\u7684\u652f\u51fa\u77e9\u9635\uff0c\u5bf9\u6bd4\u4e0d\u540c\u7ecf\u6d4e\u7cfb\u7edf\u4ece\u81ea\u7531\u653e\u4efb\u8d44\u672c\u4e3b\u4e49\u5230\u5171\u4ea7\u4e3b\u4e49\u8f6c\u53d8\u65f6\u7684\u6548\u7387\u548c\u81ea\u7531\u60c5\u51b5\u3002", "result": "\u968f\u7740\u7ecf\u6d4e\u7cfb\u7edf\u4ece\u81ea\u7531\u653e\u4efb\u8d44\u672c\u4e3b\u4e49\u5411\u5171\u4ea7\u4e3b\u4e49\u8f6c\u53d8\uff0c\u5173\u952e\u6210\u679c\u9010\u6e10\u53d8\u5dee\u3002", "conclusion": "\u653f\u5e9c\u5e72\u9884\u6709\u65f6\u5fc5\u8981\uff0c\u4f46\u5e94\u4ed4\u7ec6\u9650\u5236\uff0c\u4ee5\u514d\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u4e0e\u4e2a\u4eba\u504f\u597d\u4e0d\u7b26\u3002"}}
{"id": "2512.19746", "pdf": "https://arxiv.org/pdf/2512.19746", "abs": "https://arxiv.org/abs/2512.19746", "authors": ["Joonsung Kang"], "title": "Robust Causal Directionality Inference in Quantum Inference under MNAR Observation and High-Dimensional Noise", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In quantum mechanics, observation actively shapes the system, paralleling the statistical notion of Missing Not At Random (MNAR). This study introduces a unified framework for \\textbf{robust causal directionality inference} in quantum engineering, determining whether relations are system$\\to$observation, observation$\\to$system, or bidirectional.\n  The method integrates CVAE-based latent constraints, MNAR-aware selection models, GEE-stabilized regression, penalized empirical likelihood, and Bayesian optimization. It jointly addresses quantum and classical noise while uncovering causal directionality, with theoretical guarantees for double robustness, perturbation stability, and oracle inequalities.\n  Simulation and real-data analyses (TCGA gene expression, proteomics) show that the proposed MNAR-stabilized CVAE+GEE+AIPW+PEL framework achieves lower bias and variance, near-nominal coverage, and superior quantum-specific diagnostics. This establishes robust causal directionality inference as a key methodological advance for reliable quantum engineering.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u7edf\u4e00\u6846\u67b6\u7528\u4e8e\u91cf\u5b50\u5de5\u7a0b\u4e2d\u9c81\u68d2\u56e0\u679c\u65b9\u5411\u6027\u63a8\u65ad\uff0c\u65b9\u6cd5\u7ed3\u5408\u591a\u79cd\u6280\u672f\uff0c\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u5206\u6790\u8868\u660e\u8be5\u6846\u67b6\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u91cf\u5b50\u529b\u5b66\u4e2d\u89c2\u6d4b\u4e0e\u7cfb\u7edf\u5173\u7cfb\u7c7b\u4f3c\u4e8e\u7edf\u8ba1\u4e2d\u7684MNAR\uff0c\u9700\u786e\u5b9a\u56e0\u679c\u65b9\u5411\u3002", "method": "\u96c6\u6210\u57fa\u4e8eCVAE\u7684\u6f5c\u5728\u7ea6\u675f\u3001MNAR\u611f\u77e5\u9009\u62e9\u6a21\u578b\u3001GEE\u7a33\u5b9a\u56de\u5f52\u3001\u60e9\u7f5a\u7ecf\u9a8c\u4f3c\u7136\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u7b49\u65b9\u6cd5\u3002", "result": "\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\uff08TCGA\u57fa\u56e0\u8868\u8fbe\u3001\u86cb\u767d\u8d28\u7ec4\u5b66\uff09\u5206\u6790\u663e\u793a\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u504f\u5dee\u548c\u65b9\u5dee\u66f4\u4f4e\uff0c\u8986\u76d6\u7387\u63a5\u8fd1\u6807\u79f0\uff0c\u91cf\u5b50\u4e13\u7528\u8bca\u65ad\u66f4\u4f18\u3002", "conclusion": "\u7a33\u5065\u56e0\u679c\u65b9\u5411\u6027\u63a8\u65ad\u662f\u53ef\u9760\u91cf\u5b50\u5de5\u7a0b\u7684\u5173\u952e\u65b9\u6cd5\u5b66\u8fdb\u5c55\u3002"}}
{"id": "2512.19758", "pdf": "https://arxiv.org/pdf/2512.19758", "abs": "https://arxiv.org/abs/2512.19758", "authors": ["Wang Bin", "Ao Yang", "Kedan Li", "Aofan Liu", "Hui Li", "Guibo Luo", "Weixiang Huang", "Yan Zhuang"], "title": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted to ICSE 2026 Research Track", "summary": "In the domain of software security testing, Directed Grey-Box Fuzzing (DGF) has garnered widespread attention for its efficient target localization and excellent detection performance. However, existing approaches measure only the physical distance between seed execution paths and target locations, overlooking logical relationships among code segments. This omission can yield redundant or misleading guidance in complex binaries, weakening DGF's real-world effectiveness. To address this, we introduce \\textbf{attention distance}, a novel metric that leverages a large language model's contextual analysis to compute attention scores between code elements and reveal their intrinsic connections. Under the same AFLGo configuration -- without altering any fuzzing components other than the distance metric -- replacing physical distances with attention distances across 38 real vulnerability reproduction experiments delivers a \\textbf{3.43$\\times$} average increase in testing efficiency over the traditional method. Compared to state-of-the-art directed fuzzers DAFL and WindRanger, our approach achieves \\textbf{2.89$\\times$} and \\textbf{7.13$\\times$} improvements, respectively. To further validate the generalizability of attention distance, we integrate it into DAFL and WindRanger, where it also consistently enhances their original performance. All related code and datasets are publicly available at https://github.com/TheBinKing/Attention\\_Distance.git.", "AI": {"tldr": "\u73b0\u6709DGF\u65b9\u6cd5\u5ffd\u7565\u4ee3\u7801\u6bb5\u903b\u8f91\u5173\u7cfb\uff0c\u672c\u6587\u5f15\u5165\u6ce8\u610f\u529b\u8ddd\u79bb\u6307\u6807\uff0c\u5b9e\u9a8c\u663e\u793a\u80fd\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u3002", "motivation": "\u73b0\u6709DGF\u65b9\u6cd5\u4ec5\u8003\u8651\u79cd\u5b50\u6267\u884c\u8def\u5f84\u4e0e\u76ee\u6807\u4f4d\u7f6e\u7269\u7406\u8ddd\u79bb\uff0c\u5ffd\u7565\u4ee3\u7801\u6bb5\u903b\u8f91\u5173\u7cfb\uff0c\u524a\u5f31\u4e86DGF\u5728\u73b0\u5b9e\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u5f15\u5165\u6ce8\u610f\u529b\u8ddd\u79bb\u8fd9\u4e00\u65b0\u9896\u6307\u6807\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5206\u6790\u8ba1\u7b97\u4ee3\u7801\u5143\u7d20\u95f4\u6ce8\u610f\u529b\u5f97\u5206\uff0c\u63ed\u793a\u5176\u5185\u5728\u8054\u7cfb\uff0c\u5e76\u5728AFLGo\u3001DAFL\u548cWindRanger\u4e2d\u5e94\u7528\u3002", "result": "\u572838\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u590d\u73b0\u5b9e\u9a8c\u4e2d\uff0c\u7528\u6ce8\u610f\u529b\u8ddd\u79bb\u66ff\u4ee3\u7269\u7406\u8ddd\u79bb\u4f7f\u6d4b\u8bd5\u6548\u7387\u5e73\u5747\u63d0\u9ad83.43\u500d\uff1b\u4e0eDAFL\u548cWindRanger\u76f8\u6bd4\uff0c\u5206\u522b\u5b9e\u73b02.89\u500d\u548c7.13\u500d\u7684\u6539\u8fdb\uff1b\u5c06\u5176\u96c6\u6210\u5230DAFL\u548cWindRanger\u4e2d\u4e5f\u80fd\u63d0\u5347\u539f\u6027\u80fd\u3002", "conclusion": "\u6ce8\u610f\u529b\u8ddd\u79bb\u6307\u6807\u80fd\u6709\u6548\u63d0\u5347\u8f6f\u4ef6\u5b89\u5168\u6d4b\u8bd5\u6548\u7387\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2512.19821", "pdf": "https://arxiv.org/pdf/2512.19821", "abs": "https://arxiv.org/abs/2512.19821", "authors": ["Fabien Le Floc'h"], "title": "How to choose my stochastic volatility parameters? A review", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.RM"], "comment": null, "summary": "Based on the existing literature, this article presents the different ways of choosing the parameters of stochastic volatility models in general, in the context of pricing financial derivative contracts. This includes the use of stochastic volatility inside stochastic local volatility models.", "AI": {"tldr": "\u6587\u7ae0\u5728\u91d1\u878d\u884d\u751f\u54c1\u5408\u7ea6\u5b9a\u4ef7\u80cc\u666f\u4e0b\uff0c\u4ecb\u7ecd\u968f\u673a\u6ce2\u52a8\u7387\u6a21\u578b\u53c2\u6570\u9009\u62e9\u7684\u4e0d\u540c\u65b9\u5f0f\uff0c\u5305\u62ec\u968f\u673a\u5c40\u90e8\u6ce2\u52a8\u7387\u6a21\u578b\u4e2d\u968f\u673a\u6ce2\u52a8\u7387\u7684\u4f7f\u7528\u3002", "motivation": "\u5728\u91d1\u878d\u884d\u751f\u54c1\u5408\u7ea6\u5b9a\u4ef7\u80cc\u666f\u4e0b\uff0c\u63a2\u8ba8\u968f\u673a\u6ce2\u52a8\u7387\u6a21\u578b\u53c2\u6570\u9009\u62e9\u65b9\u5f0f\u3002", "method": "\u57fa\u4e8e\u73b0\u6709\u6587\u732e\u8fdb\u884c\u9610\u8ff0\u3002", "result": "\u5448\u73b0\u4e86\u968f\u673a\u6ce2\u52a8\u7387\u6a21\u578b\u53c2\u6570\u9009\u62e9\u7684\u4e0d\u540c\u65b9\u5f0f\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2512.19705", "pdf": "https://arxiv.org/pdf/2512.19705", "abs": "https://arxiv.org/abs/2512.19705", "authors": ["Jian Xue", "Qian Zhang", "Wu Zhu"], "title": "Generative AI for Analysts", "categories": ["q-fin.ST", "cs.AI", "econ.GN", "q-fin.GN"], "comment": null, "summary": "We study how generative artificial intelligence (AI) transforms the work of financial analysts. Using the 2023 launch of FactSet's AI platform as a natural experiment, we find that adoption produces markedly richer and more comprehensive reports -- featuring 40% more distinct information sources, 34% broader topical coverage, and 25% greater use of advanced analytical methods -- while also improving timeliness. However, forecast errors rise by 59% as AI-assisted reports convey a more balanced mix of positive and negative information that is harder to synthesize, particularly for analysts facing heavier cognitive demands. Placebo tests using other data vendors confirm that these effects are unique to FactSet's AI integration. Overall, our findings reveal both the productivity gains and cognitive limits of generative AI in financial information production.", "AI": {"tldr": "\u7814\u7a76\u751f\u6210\u5f0fAI\u5bf9\u91d1\u878d\u5206\u6790\u5e08\u5de5\u4f5c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u91c7\u7528AI\u80fd\u4f7f\u62a5\u544a\u66f4\u4e30\u5bcc\u5168\u9762\u4e14\u53ca\u65f6\uff0c\u4f46\u4f1a\u4f7f\u9884\u6d4b\u8bef\u5dee\u4e0a\u5347\uff0c\u63ed\u793a\u4e86\u5176\u5728\u91d1\u878d\u4fe1\u606f\u751f\u4ea7\u4e2d\u7684\u5229\u5f0a\u3002", "motivation": "\u63a2\u7a76\u751f\u6210\u5f0fAI\u5982\u4f55\u6539\u53d8\u91d1\u878d\u5206\u6790\u5e08\u7684\u5de5\u4f5c\u3002", "method": "\u4ee52023\u5e74FactSet\u7684AI\u5e73\u53f0\u63a8\u51fa\u4f5c\u4e3a\u81ea\u7136\u5b9e\u9a8c\uff0c\u8fd8\u4f7f\u7528\u5176\u4ed6\u6570\u636e\u4f9b\u5e94\u5546\u8fdb\u884c\u5b89\u6170\u5242\u6d4b\u8bd5\u3002", "result": "\u91c7\u7528AI\u540e\u62a5\u544a\u66f4\u4e30\u5bcc\u5168\u9762\u53ca\u65f6\uff0c\u6709\u66f4\u591a\u4fe1\u606f\u6e90\u3001\u66f4\u5e7f\u6cdb\u4e3b\u9898\u8986\u76d6\u548c\u66f4\u591a\u9ad8\u7ea7\u5206\u6790\u65b9\u6cd5\u4f7f\u7528\uff0c\u4f46\u9884\u6d4b\u8bef\u5dee\u4e0a\u534759%\u3002", "conclusion": "\u63ed\u793a\u4e86\u751f\u6210\u5f0fAI\u5728\u91d1\u878d\u4fe1\u606f\u751f\u4ea7\u4e2d\u7684\u751f\u4ea7\u529b\u63d0\u5347\u548c\u8ba4\u77e5\u5c40\u9650\u3002"}}
{"id": "2512.19849", "pdf": "https://arxiv.org/pdf/2512.19849", "abs": "https://arxiv.org/abs/2512.19849", "authors": ["Ziming Mao", "Yihan Zhang", "Chihan Cui", "Kaichao You", "Zhongjie Chen", "Zhiying Xu", "Scott Shenker", "Costin Raiciu", "Yang Zhou", "Ion Stoica"], "title": "UCCL-EP: Portable Expert-Parallel Communication", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.NI"], "comment": null, "summary": "Mixture-of-Experts (MoE) workloads rely on expert parallelism (EP) to achieve high GPU efficiency. State-of-the-art EP communication systems such as DeepEP demonstrate strong performance but exhibit poor portability across heterogeneous GPU and NIC platforms. The poor portability is rooted in architecture: GPU-initiated token-level RDMA communication requires tight vertical integration between GPUs and NICs, e.g., GPU writes to NIC driver/MMIO interfaces.\n  We present UCCL-EP, a portable EP communication system that delivers DeepEP-level performance across heterogeneous GPU and NIC hardware. UCCL-EP replaces GPU-initiated RDMA with a high-throughput GPU-CPU control channel: compact token-routing commands are transferred to multithreaded CPU proxies, which then issue GPUDirect RDMA operations on behalf of GPUs. UCCL-EP further emulates various ordering semantics required by specialized EP communication modes using RDMA immediate data, enabling correctness on NICs that lack such ordering, e.g., AWS EFA. We implement UCCL-EP on NVIDIA and AMD GPUs with EFA and Broadcom NICs. On EFA, it outperforms the best existing EP solution by up to $2.1\\times$ for dispatch and combine throughput. On NVIDIA-only platform, UCCL-EP achieves comparable performance to the original DeepEP. UCCL-EP also improves token throughput on SGLang by up to 40% on the NVIDIA+EFA platform, and improves DeepSeek-V3 training throughput over the AMD Primus/Megatron-LM framework by up to 45% on a 16-node AMD+Broadcom platform.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u79fb\u690d\u7684\u4e13\u5bb6\u5e76\u884c\u901a\u4fe1\u7cfb\u7edfUCCL - EP\uff0c\u6027\u80fd\u5ab2\u7f8eDeepEP\u4e14\u6709\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u4e13\u5bb6\u5e76\u884c\u901a\u4fe1\u7cfb\u7edf\u5982DeepEP\u5728\u5f02\u6784GPU\u548cNIC\u5e73\u53f0\u4e0a\u53ef\u79fb\u690d\u6027\u5dee\u3002", "method": "\u7528\u9ad8\u541e\u5410\u91cfGPU - CPU\u63a7\u5236\u901a\u9053\u66ff\u4ee3GPU\u53d1\u8d77\u7684RDMA\uff0c\u7528RDMA\u5373\u65f6\u6570\u636e\u6a21\u62df\u7279\u5b9a\u6392\u5e8f\u8bed\u4e49\u3002", "result": "\u5728EFA\u4e0a\u8c03\u5ea6\u548c\u5408\u5e76\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6848\u9ad82.1\u500d\uff1b\u5728NVIDIA\u5e73\u53f0\u6027\u80fd\u4e0eDeepEP\u76f8\u5f53\uff1b\u5728\u4e0d\u540c\u5e73\u53f0\u63d0\u5347\u4e86\u4ee4\u724c\u548c\u8bad\u7ec3\u541e\u5410\u91cf\u3002", "conclusion": "UCCL - EP\u5177\u6709\u826f\u597d\u53ef\u79fb\u690d\u6027\u4e14\u80fd\u5728\u5f02\u6784\u786c\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2512.19983", "pdf": "https://arxiv.org/pdf/2512.19983", "abs": "https://arxiv.org/abs/2512.19983", "authors": ["Ziyuan Guo", "Jie Guo", "Zhenghao Chen", "Bin Song", "Fei Richard Yu"], "title": "IGDMRec: Behavior Conditioned Item Graph Diffusion for Multimodal Recommendation", "categories": ["cs.IR"], "comment": "12 pages, 6 figures. This paper has been accepted for publication in IEEE Transactions on Multimedia. The final published version will be available via IEEE Xplore", "summary": "Multimodal recommender systems (MRSs) are critical for various online platforms, offering users more accurate personalized recommendations by incorporating multimodal information of items. Structure-based MRSs have achieved state-of-the-art performance by constructing semantic item graphs, which explicitly model relationships between items based on modality feature similarity. However, such semantic item graphs are often noisy due to 1) inherent noise in multimodal information and 2) misalignment between item semantics and user-item co-occurrence relationships, which introduces false links and leads to suboptimal recommendations. To address this challenge, we propose Item Graph Diffusion for Multimodal Recommendation (IGDMRec), a novel method that leverages a diffusion model with classifier-free guidance to denoise the semantic item graph by integrating user behavioral information. Specifically, IGDMRec introduces a Behavior-conditioned Graph Diffusion (BGD) module, incorporating interaction data as conditioning information to guide the denoising of the semantic item graph. Additionally, a Conditional Denoising Network (CD-Net) is designed to implement the denoising process with manageable complexity. Finally, we propose a contrastive representation augmentation scheme that leverages both the denoised item graph and the original item graph to enhance item representations. \\LL{Extensive experiments on four real-world datasets demonstrate the superiority of IGDMRec over competitive baselines, with robustness analysis validating its denoising capability and ablation studies verifying the effectiveness of its key components.", "AI": {"tldr": "\u63d0\u51faIGDMRec\u65b9\u6cd5\u89e3\u51b3\u57fa\u4e8e\u7ed3\u6784\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u8bed\u4e49\u56fe\u566a\u58f0\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u57fa\u4e8e\u7ed3\u6784\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u6784\u5efa\u7684\u8bed\u4e49\u56fe\u56e0\u591a\u6a21\u6001\u4fe1\u606f\u56fa\u6709\u566a\u58f0\u548c\u8bed\u4e49\u4e0e\u7528\u6237 - \u7269\u54c1\u5171\u73b0\u5173\u7cfb\u4e0d\u4e00\u81f4\u800c\u6709\u566a\u58f0\uff0c\u5bfc\u81f4\u63a8\u8350\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faIGDMRec\u65b9\u6cd5\uff0c\u5f15\u5165BGD\u6a21\u5757\u7ed3\u5408\u7528\u6237\u4ea4\u4e92\u6570\u636e\u6307\u5bfc\u8bed\u4e49\u56fe\u53bb\u566a\uff0c\u8bbe\u8ba1CD - Net\u5b9e\u73b0\u53bb\u566a\uff0c\u63d0\u51fa\u5bf9\u6bd4\u8868\u793a\u589e\u5f3a\u65b9\u6848\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660eIGDMRec\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\uff0c\u9c81\u68d2\u6027\u5206\u6790\u9a8c\u8bc1\u53bb\u566a\u80fd\u529b\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u5173\u952e\u7ec4\u4ef6\u6709\u6548\u6027\u3002", "conclusion": "IGDMRec\u80fd\u6709\u6548\u89e3\u51b3\u57fa\u4e8e\u7ed3\u6784\u7684\u591a\u6a21\u6001\u63a8\u8350\u7cfb\u7edf\u8bed\u4e49\u56fe\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u6548\u679c\u3002"}}
{"id": "2512.19882", "pdf": "https://arxiv.org/pdf/2512.19882", "abs": "https://arxiv.org/abs/2512.19882", "authors": ["Mahdi Mostajabdaveh", "F. Sibel Salman", "Walter J. Gutjahr"], "title": "A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution", "categories": ["cs.AI", "math.OC"], "comment": null, "summary": "The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and equity, we formulate a bi-objective problem: minimizing a Gini-index-based measure of inequity in unsatisfied demand for fair distribution and minimizing total travel time for timely delivery. We propose a Mixed Integer Programming (MIP) model and use the $\u03b5$-constraint method to handle the bi-objective nature. By deriving mathematical properties of the optimal solution, we introduce valid inequalities and design an algorithm for optimal delivery allocations given feasible vehicle routes. A branch-and-price (B&P) algorithm is developed to solve the problem efficiently. Computational tests on realistic datasets from a past earthquake in Van, Turkey, and predicted data for Istanbul's Kartal region show that the B&P algorithm significantly outperforms commercial MIP solvers. Our bi-objective approach reduces aid distribution inequity by 34% without compromising efficiency. Results indicate that when time constraints are very loose or tight, lexicographic optimization prioritizing demand coverage over fairness is effective. For moderately restrictive time constraints, a balanced approach is essential to avoid inequitable outcomes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u707e\u5bb3\u540e\u6551\u63f4\u7269\u8d44\u5206\u914d\u4e0e\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u95ee\u9898\uff0c\u63d0\u51fa\u53cc\u76ee\u6807\u6a21\u578b\u53ca\u89e3\u51b3\u7b97\u6cd5\uff0c\u7ecf\u6d4b\u8bd5\u7b97\u6cd5\u6548\u679c\u597d\uff0c\u8fd8\u7ed9\u51fa\u4e0d\u540c\u65f6\u95f4\u7ea6\u675f\u4e0b\u7684\u6709\u6548\u7b56\u7565\u3002", "motivation": "\u91cd\u5927\u707e\u5bb3\u4e2d\u9884\u5b58\u7269\u8d44\u5e38\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u9700\u89e3\u51b3\u4ece\u914d\u9001\u4e2d\u5fc3\u5230\u907f\u96be\u6240\u7684\u8f66\u8f86\u8def\u5f84\u89c4\u5212\u4e0e\u7269\u8d44\u5206\u914d\u95ee\u9898\uff0c\u5e73\u8861\u6548\u7387\u4e0e\u516c\u5e73\u3002", "method": "\u63d0\u51fa\u53cc\u76ee\u6807\u95ee\u9898\uff0c\u7528\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u6a21\u578b\u548c\u03b5 -\u7ea6\u675f\u6cd5\u5904\u7406\uff0c\u63a8\u5bfc\u6700\u4f18\u89e3\u6570\u5b66\u6027\u8d28\u5f15\u5165\u6709\u6548\u4e0d\u7b49\u5f0f\uff0c\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u5f00\u53d1\u5206\u652f\u5b9a\u4ef7\uff08B&P\uff09\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "B&P\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u5546\u4e1aMIP\u6c42\u89e3\u5668\uff0c\u53cc\u76ee\u6807\u65b9\u6cd5\u51cf\u5c1134%\u7684\u63f4\u52a9\u5206\u914d\u4e0d\u516c\u5e73\u6027\uff0c\u4e0d\u540c\u65f6\u95f4\u7ea6\u675f\u4e0b\u6709\u4e0d\u540c\u6709\u6548\u7b56\u7565\u3002", "conclusion": "\u53cc\u76ee\u6807\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861\u6548\u7387\u4e0e\u516c\u5e73\uff0c\u4e0d\u540c\u65f6\u95f4\u7ea6\u675f\u5e94\u91c7\u7528\u4e0d\u540c\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2512.20245", "pdf": "https://arxiv.org/pdf/2512.20245", "abs": "https://arxiv.org/abs/2512.20245", "authors": ["Tarik Houichime", "Abdelghani Souhar", "Younes El Amrani"], "title": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds", "categories": ["cs.NE", "cs.AI", "cs.IR", "cs.SC", "cs.SE"], "comment": null, "summary": "The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via \"Signal Consensus\" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our results suggest that infinite context does not require infinite silicon; it requires treating memory not as data to be stored, but as a reconstructive process acting on a conserved, undying physical signal.", "AI": {"tldr": "\u6587\u7ae0\u6307\u51fa\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5b58\u5b58\u5728\u7269\u7406\u6096\u8bba\uff0c\u63d0\u51fa\u8bed\u97f3\u8f68\u8ff9\u8bb0\u5fc6\uff08PTM\uff09\u67b6\u6784\uff0c\u5b9e\u73b0\u8d853000\u500d\u538b\u7f29\uff0c\u68c0\u7d22\u51c6\u786e\u7387\u8fbe\u7ea692%\uff0c\u5b58\u53d6\u5ef6\u8fdf\u7ea634ms\uff0c\u8868\u660e\u65e0\u9650\u4e0a\u4e0b\u6587\u4e0d\u4f9d\u8d56\u65e0\u9650\u5b58\u50a8\u3002", "motivation": "\u89e3\u51b3\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5185\u5b58\u7684\u7269\u7406\u6096\u8bba\uff0c\u5373\u5b66\u4e60\u65f6\u586b\u6ee1\u5185\u5b58\uff0c\u7ebf\u6027\u79ef\u7d2f\u952e\u503c\u72b6\u6001\u5e26\u6765\u5931\u5fc6\u6216\u5ef6\u8fdf\u7684\u4e24\u96be\u9009\u62e9\u3002", "method": "\u5f15\u5165\u8bed\u97f3\u8f68\u8ff9\u8bb0\u5fc6\uff08PTM\uff09\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u5c06\u8bed\u8a00\u7f16\u7801\u4e3a\u904d\u5386\u6d41\u5f62\u4e0a\u7531\u65e0\u7406\u65cb\u8f6c\u77e9\u9635\u63a7\u5236\u7684\u8fde\u7eed\u8def\u5f84\uff0c\u89e3\u8026\u5bfc\u822a\u548c\u91cd\u5efa\u3002", "result": "PTM\u5b9e\u73b0\u8d853000\u500d\u538b\u7f29\uff0c\u68c0\u7d22\u51c6\u786e\u7387\u8fbe\u7ea692%\uff0c\u5b58\u53d6\u5ef6\u8fdf\u7ea634ms\u3002", "conclusion": "\u65e0\u9650\u4e0a\u4e0b\u6587\u4e0d\u9700\u8981\u65e0\u9650\u5b58\u50a8\uff0c\u5e94\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u5bf9\u5b88\u6052\u7269\u7406\u4fe1\u53f7\u7684\u91cd\u5efa\u8fc7\u7a0b\u3002"}}
{"id": "2512.20582", "pdf": "https://arxiv.org/pdf/2512.20582", "abs": "https://arxiv.org/abs/2512.20582", "authors": ["Stephane Gaubert", "Yiannis Vlassopoulos"], "title": "Relu and softplus neural nets as zero-sum turn-based games", "categories": ["cs.LG", "cs.GT", "math.OC"], "comment": "24 pages, 2 figures", "summary": "We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact, evaluating the network is the same as running the Shapley-Bellman backward recursion for the value of the game. Using the expression of the value of the game as an expected total payoff with respect to the path measure induced by the transition probabilities and a pair of optimal policies, we derive a discrete Feynman-Kac-type path-integral formula for the network output. This game-theoretic representation can be used to derive bounds on the output from bounds on the input, leveraging the monotonicity of Shapley operators, and to verify robustness properties using policies as certificates. Moreover, training the neural network becomes an inverse game problem: given pairs of terminal rewards and corresponding values, one seeks transition probabilities and rewards of a game that reproduces them. Finally, we show that a similar approach applies to neural networks with Softplus activation functions, where the ReLU net game is replaced by its entropic regularization.", "AI": {"tldr": "\u672c\u6587\u5c06ReLU\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u89e3\u91ca\u4e3a\u96f6\u548c\u56de\u5408\u5236\u505c\u6b62\u6e38\u620f\u7684\u503c\uff0c\u63a8\u5bfc\u8def\u5f84\u79ef\u5206\u516c\u5f0f\uff0c\u7528\u4e8e\u8f93\u51fa\u8fb9\u754c\u63a8\u5bfc\u548c\u9c81\u68d2\u6027\u9a8c\u8bc1\uff0c\u8bad\u7ec3\u7f51\u7edc\u53d8\u4e3a\u9006\u6e38\u620f\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u4e5f\u9002\u7528\u4e8eSoftplus\u6fc0\u6d3b\u51fd\u6570\u7f51\u7edc\u3002", "motivation": "\u4e3aReLU\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u63d0\u4f9b\u65b0\u7684\u89e3\u91ca\u89c6\u89d2\uff0c\u63a2\u7d22\u5176\u4e0e\u535a\u5f08\u8bba\u7684\u8054\u7cfb\uff0c\u4ee5\u89e3\u51b3\u8f93\u51fa\u8fb9\u754c\u63a8\u5bfc\u3001\u9c81\u68d2\u6027\u9a8c\u8bc1\u548c\u7f51\u7edc\u8bad\u7ec3\u7b49\u95ee\u9898\u3002", "method": "\u5c06\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u4e0e\u96f6\u548c\u56de\u5408\u5236\u505c\u6b62\u6e38\u620f\u8054\u7cfb\uff0c\u5229\u7528Shapley - Bellman\u53cd\u5411\u9012\u5f52\uff0c\u63a8\u5bfc\u79bb\u6563Feynman - Kac\u578b\u8def\u5f84\u79ef\u5206\u516c\u5f0f\u3002", "result": "\u5f97\u5230\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u7684\u6e38\u620f\u7406\u8bba\u8868\u793a\uff0c\u53ef\u7528\u4e8e\u63a8\u5bfc\u8f93\u51fa\u8fb9\u754c\u3001\u9a8c\u8bc1\u9c81\u68d2\u6027\uff0c\u7f51\u7edc\u8bad\u7ec3\u53d8\u4e3a\u9006\u6e38\u620f\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u4e5f\u9002\u7528\u4e8eSoftplus\u6fc0\u6d3b\u51fd\u6570\u7f51\u7edc\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u65b9\u6cd5\u53ef\u6709\u6548\u5e94\u7528\u4e8eReLU\u548cSoftplus\u6fc0\u6d3b\u51fd\u6570\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u8f93\u51fa\u5206\u6790\u548c\u7f51\u7edc\u8bad\u7ec3\u7b49\u65b9\u9762\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2512.20243", "pdf": "https://arxiv.org/pdf/2512.20243", "abs": "https://arxiv.org/abs/2512.20243", "authors": ["Thomas Attema", "Bor de Kock", "Sandesh Manganahalli Jayaprakash", "Dimitrios Schoinianakis", "Thom Sijpesteijn", "Rintse van de Vlasakker"], "title": "Post-Quantum Cryptography in the 5G Core", "categories": ["cs.CR", "cs.NI", "cs.PF"], "comment": "11 pages, 7 figures, 2 tables", "summary": "In this work, the conventional cryptographic algorithms used in the 5G Core are replaced with post-quantum alternatives and the practical impact of this transition is evaluated. Using a simulation environment, we model the registration and deregistration of varying numbers of user equipments (UEs) and measure the resulting effects on bandwidth consumption and latency.\n  Our results show that the deployment of post-quantum cryptographic algorithms has a measurable effect on performance, but that this effect is small, and perhaps more crucially, that the extra overhead needed in terms of computation and bandwidth does not have any substantial impact on the usability of the network and the efficiency of its network functions.\n  Overall the experimental results in this work corroborate earlier research: the 5G Core is technically able to support post-quantum cryptography without any inherent issues connected to the increased computational overhead or larger message size.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f305G\u6838\u5fc3\u7f51\u7528\u540e\u91cf\u5b50\u52a0\u5bc6\u7b97\u6cd5\u66ff\u4ee3\u4f20\u7edf\u7b97\u6cd5\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u53d1\u73b0\u5f71\u54cd\u5c0f\uff0c\u7f51\u7edc\u80fd\u652f\u6301\u540e\u91cf\u5b50\u52a0\u5bc6\u3002", "motivation": "\u8bc4\u4f305G\u6838\u5fc3\u7f51\u7528\u540e\u91cf\u5b50\u52a0\u5bc6\u7b97\u6cd5\u66ff\u4ee3\u4f20\u7edf\u7b97\u6cd5\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u6a21\u62df\u73af\u5883\uff0c\u5bf9\u4e0d\u540c\u6570\u91cf\u7528\u6237\u8bbe\u5907\u7684\u6ce8\u518c\u548c\u6ce8\u9500\u8fdb\u884c\u5efa\u6a21\uff0c\u6d4b\u91cf\u5e26\u5bbd\u6d88\u8017\u548c\u5ef6\u8fdf\u3002", "result": "\u90e8\u7f72\u540e\u91cf\u5b50\u52a0\u5bc6\u7b97\u6cd5\u5bf9\u6027\u80fd\u6709\u53ef\u6d4b\u91cf\u5f71\u54cd\uff0c\u4f46\u5f71\u54cd\u5c0f\uff0c\u989d\u5916\u5f00\u9500\u5bf9\u7f51\u7edc\u53ef\u7528\u6027\u548c\u529f\u80fd\u6548\u7387\u65e0\u5b9e\u8d28\u5f71\u54cd\u3002", "conclusion": "5G\u6838\u5fc3\u7f51\u6280\u672f\u4e0a\u80fd\u652f\u6301\u540e\u91cf\u5b50\u52a0\u5bc6\uff0c\u65e0\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\u548c\u6d88\u606f\u53d8\u5927\u7684\u56fa\u6709\u95ee\u9898\u3002"}}
{"id": "2512.20271", "pdf": "https://arxiv.org/pdf/2512.20271", "abs": "https://arxiv.org/abs/2512.20271", "authors": ["Angjela Davitkova", "Sebastian Michel"], "title": "Automated Training of Learned Database Components with Generative AI", "categories": ["cs.DB"], "comment": "5 pages, 2 tables, NOVAS Workshop at SIGMOD 2025", "summary": "The use of deep learning for database optimization has gained significant traction, offering improvements in indexing, cardinality estimation, and query optimization. However, acquiring high-quality training data remains a significant challenge. This paper explores the possibility of using generative models, such as GPT, to synthesize training data for learned database components. We present an initial feasibility study investigating their ability to produce realistic query distributions and execution plans for database workloads. Additionally, we discuss key challenges, such as data scalability and labeling, along with potential solutions. The initial results suggest that generative models can effectively augment training datasets, improving the adaptability of learned database techniques.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4f7f\u7528\u751f\u6210\u6a21\u578b\u4e3a\u6570\u636e\u5e93\u7ec4\u4ef6\u5408\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u8fdb\u884c\u53ef\u884c\u6027\u7814\u7a76\u5e76\u8ba8\u8bba\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u679c\u663e\u793a\u751f\u6210\u6a21\u578b\u53ef\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7528\u4e8e\u6570\u636e\u5e93\u4f18\u5316\u65f6\u83b7\u53d6\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u6311\u6218\uff0c\u56e0\u6b64\u63a2\u7d22\u7528\u751f\u6210\u6a21\u578b\u5408\u6210\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u5f00\u5c55\u5173\u4e8e\u751f\u6210\u6a21\u578b\u751f\u6210\u6570\u636e\u5e93\u5de5\u4f5c\u8d1f\u8f7d\u7684\u67e5\u8be2\u5206\u5e03\u548c\u6267\u884c\u8ba1\u5212\u7684\u53ef\u884c\u6027\u7814\u7a76\uff0c\u5e76\u8ba8\u8bba\u5173\u952e\u6311\u6218\u4e0e\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u751f\u6210\u6a21\u578b\u80fd\u6709\u6548\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u63d0\u5347\u5b66\u4e60\u578b\u6570\u636e\u5e93\u6280\u672f\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u53ef\u7528\u4e8e\u4e3a\u6570\u636e\u5e93\u7ec4\u4ef6\u5408\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u662f\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u96be\u9898\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2512.20020", "pdf": "https://arxiv.org/pdf/2512.20020", "abs": "https://arxiv.org/abs/2512.20020", "authors": ["Yuecheng Cai", "Jasmin Jelovica"], "title": "A hybrid global local computational framework for ship hull structural analysis using homogenized model and graph neural network", "categories": ["cs.CE"], "comment": null, "summary": "This study presents a computational framework for global local structural analysis of ship hull girders that integrates an equivalent single layer (ESL) model with a graph neural network (GNN). A coarse mesh homogenized ESL model efficiently predicts the global displacement field, from which degrees of freedom (DOFs) along stiffened panel boundaries are extracted. A global to local DOF mapping and reconstruction procedure is developed to recover detailed boundary kinematics for local analysis. The reconstructed DOFs, together with panel geometry and loading, serve as inputs to a heterogeneous graph transformer (HGT), a subtype of GNN, which rapidly and accurately predicts the detailed stress and displacement fields for any panel within the hull girder. The HGT is trained using high fidelity 3D panel finite element model with reconstructed boundary conditions, enabling it to generalize across varying panel geometries, loadings, and boundary behaviors. Once trained, the framework requires only the global ESL solution in order to generate detailed local responses, making it highly suitable for optimization. Validation on three box beam case studies demonstrates that the global prediction error is governed by the coarse mesh ESL solution, while the HGT maintains high local accuracy and clearly outperforms conventional ESL based stress estimation method.", "AI": {"tldr": "\u63d0\u51fa\u96c6\u6210ESL\u6a21\u578b\u4e0eGNN\u7684\u8239\u4f53\u6881\u5168\u5c40 - \u5c40\u90e8\u7ed3\u6784\u5206\u6790\u8ba1\u7b97\u6846\u67b6\uff0c\u7ecf\u6848\u4f8b\u9a8c\u8bc1\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5f00\u53d1\u9ad8\u6548\u51c6\u786e\u7684\u8239\u4f53\u6881\u5168\u5c40\u5c40\u90e8\u7ed3\u6784\u5206\u6790\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u4f18\u5316\u3002", "method": "\u7528\u7c97\u7f51\u683c\u5747\u8d28\u5316ESL\u6a21\u578b\u9884\u6d4b\u5168\u5c40\u4f4d\u79fb\u573a\uff0c\u5f00\u53d1\u5168\u5c40\u5230\u5c40\u90e8\u81ea\u7531\u5ea6\u6620\u5c04\u548c\u91cd\u5efa\u7a0b\u5e8f\uff0c\u7528\u91cd\u5efa\u81ea\u7531\u5ea6\u7b49\u4f5c\u4e3a\u8f93\u5165\uff0c\u7ecf\u9ad8\u4fdd\u771f3D\u9762\u677f\u6709\u9650\u5143\u6a21\u578b\u8bad\u7ec3HGT\u9884\u6d4b\u5c40\u90e8\u5e94\u529b\u548c\u4f4d\u79fb\u573a\u3002", "result": "\u5168\u5c40\u9884\u6d4b\u8bef\u5dee\u7531\u7c97\u7f51\u683cESL\u89e3\u63a7\u5236\uff0cHGT\u4fdd\u6301\u9ad8\u5c40\u90e8\u7cbe\u5ea6\uff0c\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8eESL\u7684\u5e94\u529b\u4f30\u8ba1\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ea\u9700\u5168\u5c40ESL\u89e3\u5c31\u80fd\u751f\u6210\u8be6\u7ec6\u5c40\u90e8\u54cd\u5e94\uff0c\u9002\u7528\u4e8e\u4f18\u5316\u3002"}}
{"id": "2512.19713", "pdf": "https://arxiv.org/pdf/2512.19713", "abs": "https://arxiv.org/abs/2512.19713", "authors": ["Taoran Sheng", "Manfred Huber"], "title": "Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "Human activity recognition (HAR) using wearable sensors has advanced through various machine learning paradigms, each with inherent trade-offs between performance and labeling requirements. While fully supervised techniques achieve high accuracy, they demand extensive labeled datasets that are costly to obtain. Conversely, unsupervised methods eliminate labeling needs but often deliver suboptimal performance. This paper presents a comprehensive investigation across the supervision spectrum for wearable-based HAR, with particular focus on novel approaches that minimize labeling requirements while maintaining competitive accuracy. We develop and empirically compare: (1) traditional fully supervised learning, (2) basic unsupervised learning, (3) a weakly supervised learning approach with constraints, (4) a multi-task learning approach with knowledge sharing, (5) a self-supervised approach based on domain expertise, and (6) a novel weakly self-supervised learning framework that leverages domain knowledge and minimal labeled data. Experiments across benchmark datasets demonstrate that: (i) our weakly supervised methods achieve performance comparable to fully supervised approaches while significantly reducing supervision requirements; (ii) the proposed multi-task framework enhances performance through knowledge sharing between related tasks; (iii) our weakly self-supervised approach demonstrates remarkable efficiency with just 10\\% of labeled data. These results not only highlight the complementary strengths of different learning paradigms, offering insights into tailoring HAR solutions based on the availability of labeled data, but also establish that our novel weakly self-supervised framework offers a promising solution for practical HAR applications where labeled data are limited.", "AI": {"tldr": "\u6587\u7ae0\u5bf9\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u8fdb\u884c\u5168\u76d1\u7763\u8303\u56f4\u7814\u7a76\uff0c\u6bd4\u8f83\u591a\u79cd\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u5f31\u76d1\u7763\u7b49\u65b9\u6cd5\u6709\u4f18\u52bf\uff0c\u65b0\u6846\u67b6\u5728\u6570\u636e\u6709\u9650\u65f6\u8868\u73b0\u597d\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5168\u76d1\u7763HAR\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u6210\u672c\u9ad8\uff0c\u65e0\u76d1\u7763\u65b9\u6cd5\u6027\u80fd\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u51cf\u5c11\u6807\u6ce8\u9700\u6c42\u5e76\u4fdd\u6301\u7cbe\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u5e76\u6bd4\u8f83\u4f20\u7edf\u5168\u76d1\u7763\u5b66\u4e60\u3001\u57fa\u672c\u65e0\u76d1\u7763\u5b66\u4e60\u3001\u5e26\u7ea6\u675f\u7684\u5f31\u76d1\u7763\u5b66\u4e60\u3001\u77e5\u8bc6\u5171\u4eab\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u5f31\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u3002", "result": "\u5f31\u76d1\u7763\u65b9\u6cd5\u6027\u80fd\u4e0e\u5168\u76d1\u7763\u76f8\u5f53\u4e14\u51cf\u5c11\u76d1\u7763\u9700\u6c42\uff1b\u591a\u4efb\u52a1\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u5171\u4eab\u63d0\u5347\u6027\u80fd\uff1b\u5f31\u81ea\u76d1\u7763\u65b9\u6cd5\u752810%\u6807\u6ce8\u6570\u636e\u6548\u7387\u9ad8\u3002", "conclusion": "\u4e0d\u540c\u5b66\u4e60\u8303\u5f0f\u4f18\u52bf\u4e92\u8865\uff0c\u65b0\u7684\u5f31\u81ea\u76d1\u7763\u6846\u67b6\u4e3a\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u5b9e\u9645HAR\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20515", "pdf": "https://arxiv.org/pdf/2512.20515", "abs": "https://arxiv.org/abs/2512.20515", "authors": ["Haibo Wang"], "title": "Modeling Bank Systemic Risk of Emerging Markets under Geopolitical Shocks: Empirical Evidence from BRICS Countries", "categories": ["q-fin.CP", "econ.EM", "q-fin.RM"], "comment": "22 pages and 7 figures", "summary": "The growing economic influence of the BRICS nations requires risk models that capture complex, long-term dynamics. This paper introduces the Bank Risk Interlinkage with Dynamic Graph and Event Simulations (BRIDGES) framework, which analyzes systemic risk based on the level of information complexity (zero-order, first-order, and second-order). BRIDGES utilizes the Dynamic Time Warping (DTW) distance to construct a dynamic network for 551 BRICS banks based on their strategic similarity, using zero-order information such as annual balance sheet data from 2008 to 2024. It then employs first-order information, including trends in risk ratios, to detect shifts in banks' behavior. A Temporal Graph Neural Network (TGNN), as the core of BRIDGES, is deployed to learn network evolutions and detect second-order information, such as anomalous changes in the structural relationships of the bank network. To measure the impact of anomalous changes on network stability, BRIDGES performs Agent-Based Model (ABM) simulations to assess the banking system's resilience to internal financial failure and external geopolitical shocks at the individual country level and across BRICS nations. Simulation results show that the failure of the largest institutions causes more systemic damage than the failure of the financially vulnerable or dynamically anomalous ones, driven by powerful panic effects. Compared to this \"too big to fail\" scenario, a geopolitical shock with correlated country-wide propagation causes more destructive systemic damage, leading to a near-total systemic collapse. It suggests that the primary threats to BRICS financial stability are second-order panic and large-scale geopolitical shocks, which traditional risk analysis models might not detect.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBRIDGES\u6846\u67b6\u5206\u6790\u91d1\u7816\u56fd\u5bb6\u94f6\u884c\u7cfb\u7edf\u98ce\u9669\uff0c\u6a21\u62df\u663e\u793a\u5927\u578b\u673a\u6784\u5012\u95ed\u548c\u5730\u7f18\u653f\u6cbb\u51b2\u51fb\u5371\u5bb3\u5927\uff0c\u4e3b\u8981\u5a01\u80c1\u662f\u4e8c\u9636\u6050\u614c\u548c\u5927\u89c4\u6a21\u5730\u7f18\u653f\u6cbb\u51b2\u51fb\u3002", "motivation": "\u91d1\u7816\u56fd\u5bb6\u7ecf\u6d4e\u5f71\u54cd\u529b\u589e\u957f\uff0c\u9700\u8981\u80fd\u6355\u6349\u590d\u6742\u957f\u671f\u52a8\u6001\u7684\u98ce\u9669\u6a21\u578b\u3002", "method": "\u5f15\u5165BRIDGES\u6846\u67b6\uff0c\u57fa\u4e8e\u4fe1\u606f\u590d\u6742\u5ea6\u5206\u6790\u7cfb\u7edf\u98ce\u9669\uff0c\u7528DTW\u6784\u5efa\u52a8\u6001\u7f51\u7edc\uff0c\u4ee5TGNN\u5b66\u4e60\u7f51\u7edc\u6f14\u53d8\uff0c\u8fdb\u884cABM\u6a21\u62df\u8bc4\u4f30\u7a33\u5b9a\u6027\u3002", "result": "\u5927\u578b\u673a\u6784\u5012\u95ed\u3001\u5730\u7f18\u653f\u6cbb\u51b2\u51fb\u9020\u6210\u7cfb\u7edf\u6027\u7834\u574f\uff0c\u5730\u7f18\u653f\u6cbb\u51b2\u51fb\u66f4\u5177\u6bc1\u706d\u6027\u3002", "conclusion": "\u91d1\u7816\u56fd\u5bb6\u91d1\u878d\u7a33\u5b9a\u4e3b\u8981\u5a01\u80c1\u662f\u4e8c\u9636\u6050\u614c\u548c\u5927\u89c4\u6a21\u5730\u7f18\u653f\u6cbb\u51b2\u51fb\uff0c\u4f20\u7edf\u6a21\u578b\u53ef\u80fd\u65e0\u6cd5\u68c0\u6d4b\u3002"}}
{"id": "2512.19985", "pdf": "https://arxiv.org/pdf/2512.19985", "abs": "https://arxiv.org/abs/2512.19985", "authors": ["Ali Zeytoon-Nejad"], "title": "The Quantitative Comparative Economics: indices of similarity to economic systems", "categories": ["econ.GN"], "comment": null, "summary": "This paper presents a novel quantitative approach for comparative economic studies, addressing limitations in current classification methods. Conventional approaches in comparative economics often rely on ad hoc and categorical classifications, leading to subjective judgments and disregarding the continuous nature of the spectrum of economic systems. These can result in subjectivity and significant information loss, particularly for countries with systems near categorical borders. To overcome these shortcomings, the present paper proposes distance-based indices for objective categorization, considering economic foundations and using hard data. Accordingly, the paper introduces institutional similarity indices--Capitalism Similarity Index (CapSI), Communism Similarity Index (ComSI), and Socialism Similarity Index (SocSI)-which reflect countries' positions along the economic system continuum. These indices adhere to mathematical rigor and are grounded in the mathematical fields of real analysis, metric spaces, and distance functions. By classifying 135 countries and creating GIS maps, the practical applicability of the proposed approach is demonstrated. Results show a high explanatory power of the introduced indices, suggesting their beneficial usage in comparative economic studies. The paper advocates for their adoption due to their objectivity and ability to capture structural and institutional nuances without subjective judgments while also considering the continuous nature of the spectrum of economic systems.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u6bd4\u8f83\u7ecf\u6d4e\u7814\u7a76\u7684\u5b9a\u91cf\u65b9\u6cd5\uff0c\u5f15\u5165\u57fa\u4e8e\u8ddd\u79bb\u7684\u6307\u6807\u5e76\u9a8c\u8bc1\u5176\u5728\u5206\u7c7b\u56fd\u5bb6\u7ecf\u6d4e\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u6bd4\u8f83\u7ecf\u6d4e\u5b66\u5206\u7c7b\u65b9\u6cd5\u6709\u5c40\u9650\u6027\uff0c\u6613\u5bfc\u81f4\u4e3b\u89c2\u5224\u65ad\u548c\u4fe1\u606f\u635f\u5931\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8ddd\u79bb\u7684\u6307\u6807\uff0c\u5982CapSI\u3001ComSI\u548cSocSI\uff0c\u4ee5\u5ba2\u89c2\u5206\u7c7b\u7ecf\u6d4e\u7cfb\u7edf\uff0c\u57fa\u4e8e\u6570\u5b66\u9886\u57df\u77e5\u8bc6\u6784\u5efa\u3002", "result": "\u5bf9135\u4e2a\u56fd\u5bb6\u5206\u7c7b\u5e76\u5236\u4f5cGIS\u5730\u56fe\uff0c\u663e\u793a\u6240\u5f15\u5165\u6307\u6807\u5177\u6709\u9ad8\u89e3\u91ca\u529b\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u65b0\u6307\u6807\uff0c\u56e0\u5176\u5ba2\u89c2\u4e14\u80fd\u6355\u6349\u7ecf\u6d4e\u7cfb\u7edf\u7ed3\u6784\u548c\u5236\u5ea6\u7ec6\u5fae\u5dee\u522b\u3002"}}
{"id": "2512.19913", "pdf": "https://arxiv.org/pdf/2512.19913", "abs": "https://arxiv.org/abs/2512.19913", "authors": ["Matthew Drnevich", "Stephen Jiggins", "Kyle Cranmer"], "title": "Quasiprobabilistic Density Ratio Estimation with a Reverse Engineered Classification Loss Function", "categories": ["stat.ML", "cs.LG", "hep-ex"], "comment": "25 pages, 7 figures", "summary": "We consider a generalization of the classifier-based density-ratio estimation task to a quasiprobabilistic setting where probability densities can be negative. The problem with most loss functions used for this task is that they implicitly define a relationship between the optimal classifier and the target quasiprobabilistic density ratio which is discontinuous or not surjective. We address these problems by introducing a convex loss function that is well-suited for both probabilistic and quasiprobabilistic density ratio estimation. To quantify performance, an extended version of the Sliced-Wasserstein distance is introduced which is compatible with quasiprobability distributions. We demonstrate our approach on a real-world example from particle physics, of di-Higgs production in association with jets via gluon-gluon fusion, and achieve state-of-the-art results.", "AI": {"tldr": "\u5c06\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u4efb\u52a1\u63a8\u5e7f\u5230\u51c6\u6982\u7387\u8bbe\u7f6e\uff0c\u5f15\u5165\u65b0\u635f\u5931\u51fd\u6570\u548c\u8ddd\u79bb\u5ea6\u91cf\uff0c\u5728\u7c92\u5b50\u7269\u7406\u5b9e\u4f8b\u4e2d\u83b7\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u591a\u6570\u7528\u4e8e\u8be5\u4efb\u52a1\u7684\u635f\u5931\u51fd\u6570\u5728\u6700\u4f18\u5206\u7c7b\u5668\u548c\u76ee\u6807\u51c6\u6982\u7387\u5bc6\u5ea6\u6bd4\u4e4b\u95f4\u5b9a\u4e49\u7684\u5173\u7cfb\u4e0d\u8fde\u7eed\u6216\u975e\u6ee1\u5c04\uff0c\u5b58\u5728\u95ee\u9898\u3002", "method": "\u5f15\u5165\u9002\u5408\u6982\u7387\u548c\u51c6\u6982\u7387\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u7684\u51f8\u635f\u5931\u51fd\u6570\uff0c\u5f15\u5165\u4e0e\u51c6\u6982\u7387\u5206\u5e03\u517c\u5bb9\u7684\u6269\u5c55\u7248\u5207\u7247\u6c83\u745f\u65af\u5766\u8ddd\u79bb\u3002", "result": "\u5728\u7c92\u5b50\u7269\u7406\u7684\u53cc\u5e0c\u683c\u65af\u73bb\u8272\u5b50\u4ea7\u751f\u5b9e\u4f8b\u4e2d\u53d6\u5f97\u4e86\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u51c6\u6982\u7387\u5bc6\u5ea6\u6bd4\u4f30\u8ba1\u4efb\u52a1\u4e2d\u6709\u6548\uff0c\u80fd\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2512.19769", "pdf": "https://arxiv.org/pdf/2512.19769", "abs": "https://arxiv.org/abs/2512.19769", "authors": ["Ivan Daunis"], "title": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Building deployment-ready LLM agents requires complex orchestration of tools, data sources, and control flow logic, yet existing systems tightly couple agent logic to specific programming languages and deployment models. We present a declarative system that separates agent workflow specification from implementation, enabling the same pipeline definition to execute across multiple backend languages (Java, Python, Go) and deployment environments (cloud-native, on-premises).\n  Our key insight is that most agent workflows consist of common patterns -- data serialization, filtering, RAG retrieval, API orchestration -- that can be expressed through a unified DSL rather than imperative code. This approach transforms agent development from application programming to configuration, where adding new tools or fine-tuning agent behaviors requires only pipeline specification changes, not code deployment. Our system natively supports A/B testing of agent strategies, allowing multiple pipeline variants to run on the same backend infrastructure with automatic metric collection and comparison.\n  We evaluate our approach on real-world e-commerce workflows at PayPal, processing millions of daily interactions. Our results demonstrate 60% reduction in development time, and 3x improvement in deployment velocity compared to imperative implementations. The language's declarative approach enables non-engineers to modify agent behaviors safely, while maintaining sub-100ms orchestration overhead. We show that complex workflows involving product search, personalization, and cart management can be expressed in under 50 lines of DSL compared to 500+ lines of imperative code.", "AI": {"tldr": "\u63d0\u51fa\u58f0\u660e\u5f0f\u7cfb\u7edf\u5206\u79bb\u4ee3\u7406\u5de5\u4f5c\u6d41\u89c4\u8303\u4e0e\u5b9e\u73b0\uff0c\u652f\u6301\u591a\u540e\u7aef\u8bed\u8a00\u548c\u90e8\u7f72\u73af\u5883\uff0c\u5728PayPal\u7535\u5546\u5de5\u4f5c\u6d41\u8bc4\u4f30\u4e2d\uff0c\u5f00\u53d1\u65f6\u95f4\u51cf\u5c1160%\uff0c\u90e8\u7f72\u901f\u5ea6\u63d0\u53473\u500d\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5c06\u4ee3\u7406\u903b\u8f91\u4e0e\u7279\u5b9a\u7f16\u7a0b\u8bed\u8a00\u548c\u90e8\u7f72\u6a21\u578b\u7d27\u5bc6\u8026\u5408\uff0c\u6784\u5efa\u90e8\u7f72\u5c31\u7eea\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u9700\u8981\u590d\u6742\u7f16\u6392\u3002", "method": "\u5229\u7528\u7edf\u4e00DSL\u8868\u8fbe\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u5e38\u89c1\u6a21\u5f0f\uff0c\u5c06\u4ee3\u7406\u5f00\u53d1\u4ece\u5e94\u7528\u7f16\u7a0b\u8f6c\u53d8\u4e3a\u914d\u7f6e\uff0c\u652f\u6301A/B\u6d4b\u8bd5\u3002", "result": "\u5728PayPal\u7535\u5546\u5de5\u4f5c\u6d41\u4e2d\uff0c\u5f00\u53d1\u65f6\u95f4\u51cf\u5c1160%\uff0c\u90e8\u7f72\u901f\u5ea6\u63d0\u53473\u500d\uff0cDSL\u8868\u8fbe\u590d\u6742\u5de5\u4f5c\u6d41\u4ee3\u7801\u91cf\u8fdc\u5c11\u4e8e\u547d\u4ee4\u5f0f\u4ee3\u7801\uff0c\u975e\u5de5\u7a0b\u5e08\u53ef\u5b89\u5168\u4fee\u6539\u4ee3\u7406\u884c\u4e3a\uff0c\u7f16\u6392\u5f00\u9500\u4f4e\u4e8e100ms\u3002", "conclusion": "\u58f0\u660e\u5f0f\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u73b0\u6709\u95ee\u9898\uff0c\u63d0\u5347\u5f00\u53d1\u548c\u90e8\u7f72\u6548\u7387\uff0c\u964d\u4f4e\u4ee3\u7801\u91cf\uff0c\u8ba9\u975e\u5de5\u7a0b\u5e08\u4e5f\u80fd\u53c2\u4e0e\u4ee3\u7406\u884c\u4e3a\u4fee\u6539\u3002"}}
{"id": "2512.20190", "pdf": "https://arxiv.org/pdf/2512.20190", "abs": "https://arxiv.org/abs/2512.20190", "authors": ["Anastasiia Zbandut"], "title": "Pricing of wrapped Bitcoin and Ethereum on-chain options", "categories": ["q-fin.PR", "q-fin.RM"], "comment": null, "summary": "This paper measures price differences between Hegic option quotes on Arbitrum and a model-based benchmark built on Black--Scholes model with regime-sensitive volatility estimated via a two-regime MS-AR-(GJR)-GARCH model. Using option-level feasible GLS, we find benchmark prices exceed Hegic quotes on average, especially for call options. The price spread rises with order size, strike, maturity, and estimated volatility, and falls with trading volume. By underlying, wrapped Bitcoin options show larger and more persistent spreads, while Ethereum options are closer to the benchmark. The framework offers a data-driven analysis for monitoring and calibrating on-chain option pricing logic.", "AI": {"tldr": "\u672c\u6587\u6d4b\u91cfArbitrum\u4e0aHegic\u671f\u6743\u62a5\u4ef7\u4e0e\u57fa\u4e8e\u7279\u5b9a\u6a21\u578b\u7684\u57fa\u51c6\u4ef7\u683c\u5dee\u5f02\uff0c\u53d1\u73b0\u57fa\u51c6\u4ef7\u5e73\u5747\u9ad8\u4e8eHegic\u62a5\u4ef7\u7b49\u7ed3\u679c\uff0c\u6846\u67b6\u53ef\u7528\u4e8e\u76d1\u6d4b\u548c\u6821\u51c6\u94fe\u4e0a\u671f\u6743\u5b9a\u4ef7\u903b\u8f91\u3002", "motivation": "\u6d4b\u91cfArbitrum\u4e0aHegic\u671f\u6743\u62a5\u4ef7\u4e0e\u6a21\u578b\u57fa\u51c6\u4ef7\u683c\u7684\u5dee\u5f02\uff0c\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u7684\u5206\u6790\u4ee5\u76d1\u6d4b\u548c\u6821\u51c6\u94fe\u4e0a\u671f\u6743\u5b9a\u4ef7\u903b\u8f91\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4e24\u5236\u5ea6MS - AR - (GJR) - GARCH\u6a21\u578b\u4f30\u8ba1\u5236\u5ea6\u654f\u611f\u6ce2\u52a8\u7387\u7684Black - Scholes\u6a21\u578b\u6784\u5efa\u57fa\u51c6\uff0c\u91c7\u7528\u671f\u6743\u5c42\u9762\u53ef\u884c\u5e7f\u4e49\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff08GLS\uff09\u3002", "result": "\u57fa\u51c6\u4ef7\u683c\u5e73\u5747\u8d85\u8fc7Hegic\u62a5\u4ef7\uff0c\u4ef7\u5dee\u968f\u8ba2\u5355\u89c4\u6a21\u3001\u6267\u884c\u4ef7\u3001\u5230\u671f\u671f\u9650\u548c\u4f30\u8ba1\u6ce2\u52a8\u7387\u4e0a\u5347\uff0c\u968f\u4ea4\u6613\u91cf\u4e0b\u964d\uff1b\u5305\u88c5\u6bd4\u7279\u5e01\u671f\u6743\u4ef7\u5dee\u66f4\u5927\u66f4\u6301\u4e45\uff0c\u4ee5\u592a\u574a\u671f\u6743\u66f4\u63a5\u8fd1\u57fa\u51c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u76d1\u6d4b\u548c\u6821\u51c6\u94fe\u4e0a\u671f\u6743\u5b9a\u4ef7\u903b\u8f91\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2512.20460", "pdf": "https://arxiv.org/pdf/2512.20460", "abs": "https://arxiv.org/abs/2512.20460", "authors": ["Ilias Aarab"], "title": "The Aligned Economic Index & The State Switching Model", "categories": ["q-fin.ST", "cs.LG", "econ.EM", "q-fin.PM", "stat.AP"], "comment": null, "summary": "A growing empirical literature suggests that equity-premium predictability is state dependent, with much of the forecasting power concentrated around recessionary periods \\parencite{Henkel2011,DanglHalling2012,Devpura2018}. I study U.S. stock return predictability across economic regimes and document strong evidence of time-varying expected returns across both expansionary and contractionary states. I contribute in two ways. First, I introduce a state-switching predictive regression in which the market state is defined in real time using the slope of the yield curve. Relative to the standard one-state predictive regression, the state-switching specification increases both in-sample and out-of-sample performance for the set of popular predictors considered by \\textcite{WelchGoyal2008}, improving the out-of-sample performance of most predictors in economically meaningful ways. Second, I propose a new aggregate predictor, the Aligned Economic Index, constructed via partial least squares (PLS). Under the state-switching model, the Aligned Economic Index exhibits statistically and economically significant predictive power in sample and out of sample, and it outperforms widely used benchmark predictors and alternative predictor-combination methods.", "AI": {"tldr": "\u7814\u7a76\u7f8e\u56fd\u80a1\u7968\u56de\u62a5\u5728\u4e0d\u540c\u7ecf\u6d4e\u72b6\u6001\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u5f15\u5165\u72b6\u6001\u5207\u6362\u9884\u6d4b\u56de\u5f52\u5e76\u63d0\u51fa\u65b0\u805a\u5408\u9884\u6d4b\u6307\u6807\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u8868\u660e\u80a1\u7968\u6ea2\u4ef7\u53ef\u9884\u6d4b\u6027\u4f9d\u8d56\u72b6\u6001\uff0c\u4f5c\u8005\u7814\u7a76\u4e0d\u540c\u7ecf\u6d4e\u72b6\u6001\u4e0b\u7f8e\u56fd\u80a1\u7968\u56de\u62a5\u53ef\u9884\u6d4b\u6027\u3002", "method": "\u4e00\u662f\u5f15\u5165\u7528\u6536\u76ca\u7387\u66f2\u7ebf\u659c\u7387\u5b9e\u65f6\u5b9a\u4e49\u5e02\u573a\u72b6\u6001\u7684\u72b6\u6001\u5207\u6362\u9884\u6d4b\u56de\u5f52\uff1b\u4e8c\u662f\u901a\u8fc7\u504f\u6700\u5c0f\u4e8c\u4e58\u6cd5\u6784\u5efa\u65b0\u805a\u5408\u9884\u6d4b\u6307\u6807\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6570\u3002", "result": "\u72b6\u6001\u5207\u6362\u56de\u5f52\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff1b\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6570\u5728\u6837\u672c\u5185\u5916\u5747\u6709\u663e\u8457\u9884\u6d4b\u529b\uff0c\u4f18\u4e8e\u57fa\u51c6\u9884\u6d4b\u6307\u6807\u548c\u5176\u4ed6\u7ec4\u5408\u65b9\u6cd5\u3002", "conclusion": "\u80fd\u591f\u6355\u6349\u4e0d\u540c\u7ecf\u6d4e\u72b6\u6001\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u6307\u6807\u5bf9\u80a1\u7968\u56de\u62a5\u9884\u6d4b\u6709\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2512.19843", "pdf": "https://arxiv.org/pdf/2512.19843", "abs": "https://arxiv.org/abs/2512.19843", "authors": ["Philipp Ketz", "Adam McCloskey", "Jan Scherer"], "title": "Numerical Analysis of Test Optimality", "categories": ["econ.EM", "math.ST", "stat.CO"], "comment": null, "summary": "In nonstandard testing environments, researchers often derive ad hoc tests with correct (asymptotic) size, but their optimality properties are typically unknown a priori and difficult to assess. This paper develops a numerical framework for determining whether an ad hoc test is effectively optimal - approximately maximizing a weighted average power criterion for some weights over the alternative and attaining a power envelope generated by a single weighted average power-maximizing test. Our approach uses nested optimization algorithms to approximate the weight function that makes an ad hoc test's weighted average power as close as possible to that of a true weighted average power-maximizing test, and we show the surprising result that the rejection probabilities corresponding to the latter form an approximate power envelope for the former. We provide convergence guarantees, discuss practical implementation and apply the method to the weak instrument-robust conditional likelihood ratio test and a recently-proposed test for when a nuisance parameter may be on or near its boundary.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6570\u503c\u6846\u67b6\u5224\u65ad\u7279\u8bbe\u68c0\u9a8c\u662f\u5426\u6709\u6548\u6700\u4f18\uff0c\u7528\u5d4c\u5957\u4f18\u5316\u7b97\u6cd5\u8fd1\u4f3c\u6743\u91cd\u51fd\u6570\uff0c\u6709\u6536\u655b\u4fdd\u8bc1\u5e76\u5e94\u7528\u4e8e\u76f8\u5173\u68c0\u9a8c\u3002", "motivation": "\u975e\u6807\u51c6\u6d4b\u8bd5\u73af\u5883\u4e0b\u7279\u8bbe\u68c0\u9a8c\u6700\u4f18\u6027\u5148\u9a8c\u672a\u77e5\u4e14\u96be\u8bc4\u4f30\uff0c\u9700\u786e\u5b9a\u5176\u662f\u5426\u6709\u6548\u6700\u4f18\u3002", "method": "\u4f7f\u7528\u5d4c\u5957\u4f18\u5316\u7b97\u6cd5\u8fd1\u4f3c\u6743\u91cd\u51fd\u6570\uff0c\u4f7f\u7279\u8bbe\u68c0\u9a8c\u7684\u52a0\u6743\u5e73\u5747\u529f\u6548\u63a5\u8fd1\u771f\u6b63\u7684\u52a0\u6743\u5e73\u5747\u529f\u6548\u6700\u5927\u5316\u68c0\u9a8c\u3002", "result": "\u53d1\u73b0\u52a0\u6743\u5e73\u5747\u529f\u6548\u6700\u5927\u5316\u68c0\u9a8c\u5bf9\u5e94\u7684\u62d2\u7edd\u6982\u7387\u6784\u6210\u7279\u8bbe\u68c0\u9a8c\u7684\u8fd1\u4f3c\u529f\u6548\u5305\u7edc\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u503c\u6846\u67b6\u53ef\u7528\u4e8e\u5224\u65ad\u7279\u8bbe\u68c0\u9a8c\u7684\u6709\u6548\u6027\uff0c\u6709\u6536\u655b\u4fdd\u8bc1\u5e76\u53ef\u5e94\u7528\u4e8e\u5b9e\u9645\u68c0\u9a8c\u3002"}}
{"id": "2512.19851", "pdf": "https://arxiv.org/pdf/2512.19851", "abs": "https://arxiv.org/abs/2512.19851", "authors": ["Aditya Bhosale", "Laxmikant Kale"], "title": "An Adaptive Distributed Stencil Abstraction for GPUs", "categories": ["cs.DC"], "comment": null, "summary": "The scientific computing ecosystem in Python is largely confined to single-node parallelism, creating a gap between high-level prototyping in NumPy and high-performance execution on modern supercomputers. The increasing prevalence of hardware accelerators and the need for energy efficiency have made resource adaptivity a critical requirement, yet traditional HPC abstractions remain rigid. To address these challenges, we present an adaptive, distributed abstraction for stencil computations on multi-node GPUs. This abstraction is built using CharmTyles, a framework based on the adaptive Charm++ runtime, and features a familiar NumPy-like syntax to minimize the porting effort from prototype to production code. We showcase the resource elasticity of our abstraction by dynamically rescaling a running application across a different number of nodes and present a performance analysis of the associated overheads. Furthermore, we demonstrate that our abstraction achieves significant performance improvements over both a specialized, high-performance stencil DSL and a generalized NumPy replacement.", "AI": {"tldr": "Python\u79d1\u5b66\u8ba1\u7b97\u751f\u6001\u5c40\u9650\u4e8e\u5355\u8282\u70b9\u5e76\u884c\uff0c\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u591a\u8282\u70b9GPU\u6a21\u677f\u8ba1\u7b97\u7684\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u62bd\u8c61\uff0c\u5c55\u793a\u8d44\u6e90\u5f39\u6027\u5e76\u83b7\u6027\u80fd\u63d0\u5347\u3002", "motivation": "Python\u79d1\u5b66\u8ba1\u7b97\u751f\u6001\u5355\u8282\u70b9\u5e76\u884c\u6709\u5c40\u9650\uff0c\u786c\u4ef6\u52a0\u901f\u5668\u666e\u53ca\u548c\u80fd\u6548\u9700\u6c42\u4f7f\u8d44\u6e90\u9002\u5e94\u6027\u6210\u5173\u952e\uff0c\u4f20\u7edfHPC\u62bd\u8c61\u50f5\u5316\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u81ea\u9002\u5e94Charm++\u8fd0\u884c\u65f6\u7684CharmTyles\u6846\u67b6\u6784\u5efa\u5f62\u4f3cNumPy\u8bed\u6cd5\u7684\u5206\u5e03\u5f0f\u62bd\u8c61\u3002", "result": "\u5c55\u793a\u4e86\u62bd\u8c61\u7684\u8d44\u6e90\u5f39\u6027\uff0c\u5bf9\u76f8\u5173\u5f00\u9500\u8fdb\u884c\u6027\u80fd\u5206\u6790\uff0c\u76f8\u6bd4\u4e13\u7528\u6a21\u677fDSL\u548c\u901a\u7528NumPy\u66ff\u4ee3\u65b9\u6848\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u62bd\u8c61\u53ef\u6709\u6548\u586b\u8865Python\u79d1\u5b66\u8ba1\u7b97\u539f\u578b\u4e0e\u9ad8\u6027\u80fd\u6267\u884c\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.20022", "pdf": "https://arxiv.org/pdf/2512.20022", "abs": "https://arxiv.org/abs/2512.20022", "authors": ["Kian Godhwani", "David Benrimoh"], "title": "LLM-Assisted Abstract Screening with OLIVER: Evaluating Calibration and Single-Model vs. Actor-Critic Configurations in Literature Reviews", "categories": ["cs.IR"], "comment": null, "summary": "Introduction: Recent work suggests large language models (LLMs) can accelerate screening, but prior evaluations focus on earlier LLMs, standardized Cochrane reviews, single-model setups, and accuracy as the primary metric, leaving generalizability, configuration effects, and calibration largely unexamined.\n  Methods: We developed OLIVER (Optimized LLM-based Inclusion and Vetting Engine for Reviews), an open-source pipeline for LLM-assisted abstract screening. We evaluated multiple contemporary LLMs across two non-Cochrane systematic reviews and performance was assessed at both the full-text screening and final inclusion stages using accuracy, AUC, and calibration metrics. We further tested an actor-critic screening framework combining two lightweight models under three aggregation rules.\n  Results: Across individual models, performance varied widely. In the smaller Review 1 (821 abstracts, 63 final includes), several models achieved high sensitivity for final includes but at the cost of substantial false positives and poor calibration. In the larger Review 2 (7741 abstracts, 71 final includes), most models were highly specific but struggled to recover true includes, with prompt design influencing recall. Calibration was consistently weak across single-model configurations despite high overall accuracy. Actor-critic screening improved discrimination and markedly reduced calibration error in both reviews, yielding higher AUCs.\n  Discussion: LLMs may eventually accelerate abstract screening, but single-model performance is highly sensitive to review characteristics, prompting, and calibration is limited. An actor-critic framework improves classification quality and confidence reliability while remaining computationally efficient, enabling large-scale screening at low cost.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1OLIVER\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u6458\u8981\u7b5b\u9009\uff0c\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u5355\u6a21\u578b\u6027\u80fd\u53d7\u591a\u56e0\u7d20\u5f71\u54cd\uff0c\u6f14\u5458 - \u6279\u8bc4\u5bb6\u6846\u67b6\u53ef\u63d0\u5347\u5206\u7c7b\u8d28\u91cf\u548c\u53ef\u9760\u5ea6\u3002", "motivation": "\u5148\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u805a\u7126\u65e9\u671f\u6a21\u578b\u3001\u6807\u51c6\u5316\u7efc\u8ff0\u3001\u5355\u6a21\u578b\u8bbe\u7f6e\u7b49\uff0c\u9700\u7814\u7a76\u53ef\u63a8\u5e7f\u6027\u3001\u914d\u7f6e\u6548\u679c\u548c\u6821\u51c6\u60c5\u51b5\u3002", "method": "\u5f00\u53d1OLIVER\u5f00\u6e90\u7ba1\u9053\uff0c\u8bc4\u4f30\u591a\u79cd\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e24\u4e2a\u975eCochrane\u7cfb\u7edf\u8bc4\u4ef7\u4e2d\u7684\u8868\u73b0\uff0c\u7528\u591a\u79cd\u6307\u6807\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u6f14\u5458 - \u6279\u8bc4\u5bb6\u7b5b\u9009\u6846\u67b6\u3002", "result": "\u5355\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u5927\uff0c\u5728\u4e0d\u540c\u7efc\u8ff0\u4e2d\u5404\u6709\u4f18\u7f3a\u70b9\uff0c\u6821\u51c6\u666e\u904d\u8f83\u5f31\uff1b\u6f14\u5458 - \u6279\u8bc4\u5bb6\u7b5b\u9009\u63d0\u5347\u4e86\u533a\u5206\u5ea6\uff0c\u964d\u4f4e\u6821\u51c6\u8bef\u5dee\uff0c\u63d0\u9ad8AUC\u3002", "conclusion": "\u5355\u6a21\u578b\u6027\u80fd\u53d7\u591a\u56e0\u7d20\u5f71\u54cd\uff0c\u6821\u51c6\u6709\u9650\uff1b\u6f14\u5458 - \u6279\u8bc4\u5bb6\u6846\u67b6\u53ef\u63d0\u5347\u5206\u7c7b\u8d28\u91cf\u548c\u4fe1\u5fc3\u53ef\u9760\u5ea6\uff0c\u80fd\u4f4e\u6210\u672c\u8fdb\u884c\u5927\u89c4\u6a21\u7b5b\u9009\u3002"}}
{"id": "2512.19937", "pdf": "https://arxiv.org/pdf/2512.19937", "abs": "https://arxiv.org/abs/2512.19937", "authors": ["Eric Yeh", "John Cadigan", "Ran Chen", "Dick Crouch", "Melinda Gervasio", "Dayne Freitag"], "title": "Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs", "categories": ["cs.AI"], "comment": "20 pages, 5 figures", "summary": "Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high fidelity to drive simulations to test human behavioral hypotheses, exhibiting more nuance and range than the rule-based agents often employed in behavioral economics. One key area of interest is the effect of personality on decision making, but the requirement that a prompt must be created for every tested personality profile introduces experimental overhead and degrades replicability. To address this issue, we leverage interpolative decoding, representing each dimension of personality as a pair of opposed prompts and employing an interpolation parameter to simulate behavior along the dimension. We show that interpolative decoding reliably modulates scores along each of the Big Five dimensions. We then show how interpolative decoding causes LLMs to mimic human decision-making behavior in economic games, replicating results from human psychological research. Finally, we present preliminary results of our efforts to ``twin'' individual human players in a collaborative game through systematic search for points in interpolation space that cause the system to replicate actions taken by the human subject.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u9488\u5bf9\u6d4b\u8bd5\u4eba\u683c\u914d\u7f6e\u6587\u4ef6\u9700\u521b\u5efa\u63d0\u793a\u7684\u95ee\u9898\uff0c\u91c7\u7528\u63d2\u503c\u89e3\u7801\uff0c\u5c55\u793a\u5176\u5728\u5927\u4e94\u4eba\u683c\u7ef4\u5ea6\u548c\u7ecf\u6d4e\u6e38\u620f\u4e2d\u7684\u6548\u679c\u53ca\u521d\u6b65\u7684\u4eba\u7c7b\u73a9\u5bb6\u201c\u5b6a\u751f\u201d\u7ed3\u679c\u3002", "motivation": "\u89e3\u51b3\u6d4b\u8bd5\u4eba\u683c\u914d\u7f6e\u6587\u4ef6\u65f6\u9700\u4e3a\u6bcf\u4e2a\u914d\u7f6e\u6587\u4ef6\u521b\u5efa\u63d0\u793a\u5e26\u6765\u7684\u5b9e\u9a8c\u5f00\u9500\u548c\u53ef\u91cd\u590d\u6027\u95ee\u9898\u3002", "method": "\u5229\u7528\u63d2\u503c\u89e3\u7801\uff0c\u5c06\u4eba\u683c\u5404\u7ef4\u5ea6\u8868\u793a\u4e3a\u4e00\u5bf9\u5bf9\u7acb\u63d0\u793a\uff0c\u7528\u63d2\u503c\u53c2\u6570\u6a21\u62df\u884c\u4e3a\u3002", "result": "\u63d2\u503c\u89e3\u7801\u80fd\u53ef\u9760\u8c03\u8282\u5927\u4e94\u4eba\u683c\u7ef4\u5ea6\u5206\u6570\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ecf\u6d4e\u6e38\u620f\u4e2d\u6a21\u4eff\u4eba\u7c7b\u51b3\u7b56\u884c\u4e3a\uff0c\u6709\u521d\u6b65\u7684\u4eba\u7c7b\u73a9\u5bb6\u201c\u5b6a\u751f\u201d\u7ed3\u679c\u3002", "conclusion": "\u63d2\u503c\u89e3\u7801\u53ef\u6709\u6548\u89e3\u51b3\u76f8\u5173\u95ee\u9898\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u65b9\u9762\u6709\u8f83\u597d\u8868\u73b0\u3002"}}
{"id": "2512.20370", "pdf": "https://arxiv.org/pdf/2512.20370", "abs": "https://arxiv.org/abs/2512.20370", "authors": ["Wei Zhang", "Yijie Li", "Ruixi Zheng", "Nir A. Sochen", "Yuqian Chen", "Leo R. Zekelman", "Ofer Pasternak", "Jarrett Rushmore", "Yogesh Rathi", "Nikos Makris", "Lauren J. O'Donnell", "Fan Zhang"], "title": "Cross-Population White Matter Atlas Creation for Concurrent Mapping of Brain Connections in Neonates and Adults with Diffusion MRI Tractography", "categories": ["cs.NE"], "comment": "38 pages, 12 figure", "summary": "Comparing white matter (WM) connections between adults and neonates using diffusion MRI (dMRI) can advance our understanding of typical brain development and potential biomarkers for neurological disorders. However, existing WM atlases are population-specific (adult or neonatal) and reside in separate spaces, preventing direct cross-population comparisons. A unified WM atlas spanning both neonates and adults is still lacking. In this study, we propose a neonatal/adult brain atlas (NABA), a WM tractography atlas built from dMRI data of both neonates and adults. NABA is constructed using a robust, data-driven fiber clustering pipeline, enabling group-wise WM atlasing across populations despite substantial anatomical variability. The atlas provides a standardized template for WM parcellation, allowing direct comparison of WM tracts between neonates and adults. Using NABA, we conduct four analyses: (1) evaluating the feasibility of joint WM mapping across populations, (2) characterizing WM development across neonatal ages relative to adults, (3) assessing sex-related differences in neonatal WM development, and (4) examining the effects of preterm birth. Our results show that NABA robustly identifies WM tracts in both populations. We observe rapid fractional anisotropy (FA) development in long-range association tracts, including the arcuate fasciculus and superior longitudinal fasciculus II, whereas intra-cerebellar tracts develop more slowly. Neonatal females exhibit faster overall FA development than males. Although preterm neonates show lower overall FA development rates, they demonstrate relatively higher FA growth in specific tracts, including the corticospinal tract, corona radiata-pontine pathway, and intracerebellar tracts. These findings demonstrate that NABA is a useful tool for investigating WM development across neonates and adults.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u751f\u513f/\u6210\u4eba\u8111\u56fe\u8c31NABA\uff0c\u7528\u4e8e\u6bd4\u8f83\u4e24\u8005\u767d\u8d28\u8fde\u63a5\uff0c\u901a\u8fc7\u76f8\u5173\u5206\u6790\u8bc1\u660e\u5176\u662f\u7814\u7a76\u767d\u8d28\u53d1\u80b2\u7684\u6709\u7528\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u767d\u8d28\u56fe\u8c31\u662f\u7279\u5b9a\u4eba\u7fa4\u7684\uff0c\u7f3a\u4e4f\u7edf\u4e00\u56fe\u8c31\uff0c\u65e0\u6cd5\u76f4\u63a5\u8de8\u4eba\u7fa4\u6bd4\u8f83\uff0c\u9700\u6784\u5efa\u7edf\u4e00\u56fe\u8c31\u4ee5\u63a8\u8fdb\u8111\u53d1\u80b2\u7406\u89e3\u548c\u75be\u75c5\u751f\u7269\u6807\u5fd7\u7269\u7814\u7a76\u3002", "method": "\u6784\u5efa\u65b0\u751f\u513f/\u6210\u4eba\u8111\u56fe\u8c31NABA\uff0c\u7528\u6570\u636e\u9a71\u52a8\u7684\u7ea4\u7ef4\u805a\u7c7b\u6d41\u7a0b\uff0c\u57fa\u4e8e\u6269\u6563\u78c1\u5171\u632f\u6210\u50cf\u6570\u636e\uff1b\u5229\u7528NABA\u8fdb\u884c\u56db\u9879\u5206\u6790\u3002", "result": "NABA\u80fd\u5728\u4e24\u4eba\u7fa4\u4e2d\u8bc6\u522b\u767d\u8d28\u675f\uff1b\u957f\u7a0b\u8054\u5408\u675fFA\u53d1\u5c55\u5feb\uff0c\u5c0f\u8111\u5185\u675f\u6162\uff1b\u65b0\u751f\u513f\u5973\u6027FA\u53d1\u5c55\u5feb\u4e8e\u7537\u6027\uff1b\u65e9\u4ea7\u65b0\u751f\u513f\u6574\u4f53FA\u53d1\u5c55\u6162\uff0c\u4f46\u7279\u5b9a\u675fFA\u589e\u957f\u9ad8\u3002", "conclusion": "NABA\u662f\u7814\u7a76\u65b0\u751f\u513f\u548c\u6210\u4eba\u767d\u8d28\u53d1\u80b2\u7684\u6709\u7528\u5de5\u5177\u3002"}}
{"id": "2512.20279", "pdf": "https://arxiv.org/pdf/2512.20279", "abs": "https://arxiv.org/abs/2512.20279", "authors": ["Sarah Alsubaie", "Sakhaa Alsaedi", "Xin Gao"], "title": "Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability", "categories": ["cs.CE", "cs.SE"], "comment": "26 pages, 6 figures, submitted to Journal of Cheminformatics", "summary": "In 2008, melamine in infant formula forced laboratories across three continents to verify a compound they had never monitored. Non-targeted analysis using LC/GC-HRMS handles these cases. But when findings trigger regulatory action, reproducibility becomes operational: can an independent laboratory repeat the analysis and reach the same conclusion?\n  We assessed 103 tools (2004-2025) against six pillars drawn from FAIR and BP4NTA principles: laboratory validation (C1), data availability (C2), code availability (C3), standardised formats (C4), knowledge integration (C5), and portable implementation (C6). Health contributed 51 tools, Pharma 31, and Chemistry 21.\n  Nine in ten tools shared data (C2, 90/103, 87%). Fewer than four in ten supported portable implementations (C6, 40/103, 39%). Validation and portability rarely appeared together (C1+C6, 18/103, 17%). Over twenty-one years, openness climbed from 56% to 86% while operability dropped from 55% to 43%. No tool addressed food safety.\n  Journal data-sharing policies increased what authors share but not what reviewers can run. Tools became easier to find but harder to execute. Strengthening C1, C4, and C6 would turn documented artifacts into workflows that external laboratories can replay.", "AI": {"tldr": "\u8bc4\u4f30103\u4e2a\u975e\u9776\u5411\u5206\u6790\u5de5\u5177\uff0c\u53d1\u73b0\u5de5\u5177\u5f00\u653e\u6027\u4e0a\u5347\u4f46\u53ef\u64cd\u4f5c\u6027\u4e0b\u964d\uff0c\u4e14\u65e0\u5de5\u5177\u89e3\u51b3\u98df\u54c1\u5b89\u5168\u95ee\u9898\uff0c\u52a0\u5f3a\u90e8\u5206\u652f\u67f1\u53ef\u4f7f\u5de5\u5177\u53ef\u88ab\u5916\u90e8\u5b9e\u9a8c\u5ba4\u91cd\u590d\u4f7f\u7528\u3002", "motivation": "\u5728\u975e\u9776\u5411\u5206\u6790\u7528\u4e8e\u5e94\u5bf9\u7a81\u53d1\u5316\u5408\u7269\u76d1\u6d4b\u4e14\u9700\u786e\u4fdd\u7ed3\u679c\u53ef\u91cd\u590d\u6027\u7684\u80cc\u666f\u4e0b\uff0c\u8bc4\u4f30\u5de5\u5177\u7684\u5404\u9879\u7279\u6027\u3002", "method": "\u4f9d\u636eFAIR\u548cBP4NTA\u539f\u5219\u7684\u516d\u4e2a\u652f\u67f1\u8bc4\u4f302004 - 2025\u5e74\u7684103\u4e2a\u5de5\u5177\u3002", "result": "\u4e5d\u6210\u5de5\u5177\u5171\u4eab\u6570\u636e\uff0c\u4e0d\u5230\u56db\u6210\u652f\u6301\u4fbf\u643a\u5f0f\u5b9e\u73b0\uff0c\u9a8c\u8bc1\u548c\u53ef\u79fb\u690d\u6027\u5f88\u5c11\u540c\u65f6\u51fa\u73b0\uff0c\u5f00\u653e\u6027\u4e0a\u5347\u4f46\u53ef\u64cd\u4f5c\u6027\u4e0b\u964d\uff0c\u65e0\u5de5\u5177\u89e3\u51b3\u98df\u54c1\u5b89\u5168\u95ee\u9898\uff0c\u671f\u520a\u6570\u636e\u5171\u4eab\u653f\u7b56\u6709\u5c40\u9650\u3002", "conclusion": "\u52a0\u5f3a\u5b9e\u9a8c\u5ba4\u9a8c\u8bc1\u3001\u6807\u51c6\u5316\u683c\u5f0f\u548c\u4fbf\u643a\u5f0f\u5b9e\u73b0\uff0c\u53ef\u4f7f\u5de5\u5177\u88ab\u5916\u90e8\u5b9e\u9a8c\u5ba4\u91cd\u590d\u4f7f\u7528\u3002"}}
{"id": "2512.19716", "pdf": "https://arxiv.org/pdf/2512.19716", "abs": "https://arxiv.org/abs/2512.19716", "authors": ["Behrooz Mamandipoor", "Chun-Nan Hsu", "Martin Krause", "Ulrich H. Schmidt", "Rodney A. Gabriel"], "title": "Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data", "categories": ["cs.LG", "cs.AI"], "comment": "75 pages (33 main text + references, 35 supplementary materials), 5 figures, 2 tables", "summary": "Early prediction of in-hospital mortality in critically ill patients can aid clinicians in optimizing treatment. The objective was to develop a multimodal deep learning model, using structured and unstructured clinical data, to predict in-hospital mortality risk among critically ill patients after their initial 24 hour intensive care unit (ICU) admission. We used data from MIMIC-III, MIMIC-IV, eICU, and HiRID. A multimodal model was developed on the MIMIC datasets, featuring time series components occurring within the first 24 hours of ICU admission and predicting risk of subsequent inpatient mortality. Inputs included time-invariant variables, time-variant variables, clinical notes, and chest X-ray images. External validation occurred in a temporally separated MIMIC population, HiRID, and eICU datasets. A total of 203,434 ICU admissions from more than 200 hospitals between 2001 to 2022 were included, in which mortality rate ranged from 5.2% to 7.9% across the four datasets. The model integrating structured data points had AUROC, AUPRC, and Brier scores of 0.92, 0.53, and 0.19, respectively. We externally validated the model on eight different institutions within the eICU dataset, demonstrating AUROCs ranging from 0.84-0.92. When including only patients with available clinical notes and imaging data, inclusion of notes and imaging into the model, the AUROC, AUPRC, and Brier score improved from 0.87 to 0.89, 0.43 to 0.48, and 0.37 to 0.17, respectively. Our findings highlight the importance of incorporating multiple sources of patient information for mortality prediction and the importance of external validation.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\u9884\u6d4b\u91cd\u75c7\u60a3\u8005\u4f4f\u9662\u6b7b\u4ea1\u7387\uff0c\u9a8c\u8bc1\u6a21\u578b\u6548\u679c\u5e76\u5f3a\u8c03\u591a\u6e90\u4fe1\u606f\u548c\u5916\u90e8\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u65e9\u671f\u9884\u6d4b\u91cd\u75c7\u60a3\u8005\u4f4f\u9662\u6b7b\u4ea1\u7387\uff0c\u5e2e\u52a9\u4e34\u5e8a\u533b\u751f\u4f18\u5316\u6cbb\u7597\u3002", "method": "\u4f7f\u7528MIMIC - III\u3001MIMIC - IV\u3001eICU\u548cHiRID\u6570\u636e\uff0c\u5728MIMIC\u6570\u636e\u96c6\u4e0a\u5f00\u53d1\u591a\u6a21\u6001\u6a21\u578b\uff0c\u4ee524\u5c0f\u65f6\u5185\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u9884\u6d4b\u4f4f\u9662\u6b7b\u4ea1\u7387\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u8fdb\u884c\u5916\u90e8\u9a8c\u8bc1\u3002", "result": "\u6574\u5408\u7ed3\u6784\u5316\u6570\u636e\u7684\u6a21\u578b\u6709\u8f83\u597d\u6307\u6807\uff0c\u5916\u90e8\u9a8c\u8bc1AUROC\u57280.84 - 0.92\uff1b\u52a0\u5165\u4e34\u5e8a\u7b14\u8bb0\u548c\u5f71\u50cf\u6570\u636e\u540e\u6307\u6807\u63d0\u5347\u3002", "conclusion": "\u5f3a\u8c03\u7eb3\u5165\u591a\u6e90\u60a3\u8005\u4fe1\u606f\u8fdb\u884c\u6b7b\u4ea1\u7387\u9884\u6d4b\u4ee5\u53ca\u5916\u90e8\u9a8c\u8bc1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.20353", "pdf": "https://arxiv.org/pdf/2512.20353", "abs": "https://arxiv.org/abs/2512.20353", "authors": ["Yeon-Koo Che", "Julien Grenet", "Yinghua He"], "title": "Allocating Students to Schools: Theory, Methods, and Empirical Insights", "categories": ["econ.GN"], "comment": null, "summary": "This chapter surveys the application of matching theory to school choice, motivated by the shift from neighborhood assignment systems to choice-based models. Since educational choice is not mediated by price, the design of allocation mechanisms is critical. The chapter first reviews theoretical contributions, exploring the fundamental trade-offs between efficiency, stability, and strategy-proofness, and covers design challenges such as tie-breaking, cardinal welfare, and affirmative action. It then transitions to the empirical landscape, focusing on the central challenge of inferring student preferences from application data, especially under strategic mechanisms. We review various estimation approaches and discuss key insights on parental preferences, market design trade-offs, and the effectiveness of school choice policies?", "AI": {"tldr": "\u6587\u7ae0\u4ece\u7406\u8bba\u548c\u5b9e\u8bc1\u4e24\u65b9\u9762\uff0c\u8003\u5bdf\u5339\u914d\u7406\u8bba\u5728\u5b66\u6821\u9009\u62e9\u4e2d\u7684\u5e94\u7528\uff0c\u6d89\u53ca\u8bbe\u8ba1\u6311\u6218\u3001\u4f30\u7b97\u65b9\u6cd5\u53ca\u76f8\u5173\u89c1\u89e3\u3002", "motivation": "\u56e0\u5b66\u6821\u5206\u914d\u4ece\u90bb\u91cc\u5206\u914d\u5236\u8f6c\u5411\u57fa\u4e8e\u9009\u62e9\u7684\u6a21\u5f0f\uff0c\u4e14\u6559\u80b2\u9009\u62e9\u65e0\u4ef7\u683c\u8c03\u8282\uff0c\u6545\u9700\u5173\u6ce8\u5206\u914d\u673a\u5236\u8bbe\u8ba1\u3002", "method": "\u5148\u56de\u987e\u7406\u8bba\u8d21\u732e\uff0c\u63a2\u8ba8\u6548\u7387\u3001\u7a33\u5b9a\u6027\u548c\u9632\u7b56\u7565\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4ee5\u53ca\u8bbe\u8ba1\u6311\u6218\uff1b\u518d\u805a\u7126\u5b9e\u8bc1\uff0c\u7814\u7a76\u4ece\u7533\u8bf7\u6570\u636e\u63a8\u65ad\u5b66\u751f\u504f\u597d\u7684\u65b9\u6cd5\u3002", "result": "\u56de\u987e\u4e86\u5404\u79cd\u4f30\u7b97\u65b9\u6cd5\uff0c\u5f97\u51fa\u5173\u4e8e\u5bb6\u957f\u504f\u597d\u3001\u5e02\u573a\u8bbe\u8ba1\u6743\u8861\u548c\u5b66\u6821\u9009\u62e9\u653f\u7b56\u6709\u6548\u6027\u7684\u5173\u952e\u89c1\u89e3\u3002", "conclusion": "\u5339\u914d\u7406\u8bba\u5728\u5b66\u6821\u9009\u62e9\u5e94\u7528\u4e2d\u6709\u8bf8\u591a\u8bbe\u8ba1\u6311\u6218\u548c\u5b9e\u8bc1\u7814\u7a76\u65b9\u5411\uff0c\u9700\u7efc\u5408\u8003\u8651\u591a\u65b9\u9762\u56e0\u7d20\u3002"}}
{"id": "2512.20007", "pdf": "https://arxiv.org/pdf/2512.20007", "abs": "https://arxiv.org/abs/2512.20007", "authors": ["Zhihan Huang", "Ziang Niu"], "title": "Semiparametric KSD test: unifying score and distance-based approaches for goodness-of-fit testing", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Goodness-of-fit (GoF) tests are fundamental for assessing model adequacy. Score-based tests are appealing because they require fitting the model only once under the null. However, extending them to powerful nonparametric alternatives is difficult due to the lack of suitable score functions. Through a class of exponentially tilted models, we show that the resulting score-based GoF tests are equivalent to the tests based on integral probability metrics (IPMs) indexed by a function class. When the class is rich, the test is universally consistent. This simple yet insightful perspective enables reinterpretation of classical distance-based testing procedures-including those based on Kolmogorov-Smirnov distance, Wasserstein-1 distance, and maximum mean discrepancy-as arising from score-based constructions. Building on this insight, we propose a new nonparametric score-based GoF test through a special class of IPM induced by kernelized Stein's function class, called semiparametric kernelized Stein discrepancy (SKSD) test. Compared with other nonparametric score-based tests, the SKSD test is computationally efficient and accommodates general nuisance-parameter estimators, supported by a generic parametric bootstrap procedure. The SKSD test is universally consistent and attains Pitman efficiency. Moreover, SKSD test provides simple GoF tests for models with intractable likelihoods but tractable scores with the help of Stein's identity and we use two popular models, kernel exponential family and conditional Gaussian models, to illustrate the power of our method. Our method achieves power comparable to task-specific normality tests such as Anderson-Darling and Lilliefors, despite being designed for general nonparametric alternatives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6307\u6570\u503e\u659c\u6a21\u578b\u5c06\u5f97\u5206\u62df\u5408\u4f18\u5ea6\u68c0\u9a8c\u4e0e\u79ef\u5206\u6982\u7387\u5ea6\u91cf\u68c0\u9a8c\u5efa\u7acb\u8054\u7cfb\uff0c\u63d0\u51fa\u534a\u53c2\u6570\u6838\u5316\u65af\u5766\u56e0\u5dee\u5f02\uff08SKSD\uff09\u68c0\u9a8c\uff0c\u8be5\u68c0\u9a8c\u8ba1\u7b97\u9ad8\u6548\u3001\u5177\u6709\u4e00\u81f4\u6027\u7b49\u4f18\u52bf\u5e76\u901a\u8fc7\u5b9e\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u5f97\u5206\u62df\u5408\u4f18\u5ea6\u68c0\u9a8c\u6269\u5c55\u5230\u5f3a\u5927\u975e\u53c2\u6570\u66ff\u4ee3\u65b9\u6cd5\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u7f3a\u4e4f\u5408\u9002\u5f97\u5206\u51fd\u6570\u3002", "method": "\u901a\u8fc7\u6307\u6570\u503e\u659c\u6a21\u578b\u5c06\u5f97\u5206\u62df\u5408\u4f18\u5ea6\u68c0\u9a8c\u548c\u57fa\u4e8e\u79ef\u5206\u6982\u7387\u5ea6\u91cf\uff08IPM\uff09\u7684\u68c0\u9a8c\u5efa\u7acb\u7b49\u4ef7\u5173\u7cfb\uff0c\u63d0\u51fa\u57fa\u4e8e\u7279\u5b9aIPM\u7c7b\u7684SKSD\u68c0\u9a8c\uff0c\u5e76\u91c7\u7528\u901a\u7528\u53c2\u6570bootstrap\u8fc7\u7a0b\u3002", "result": "SKSD\u68c0\u9a8c\u8ba1\u7b97\u9ad8\u6548\uff0c\u80fd\u9002\u5e94\u4e00\u822c\u5e72\u6270\u53c2\u6570\u4f30\u8ba1\uff0c\u5177\u6709\u4e00\u81f4\u6027\u5e76\u8fbe\u5230\u76ae\u7279\u66fc\u6548\u7387\uff1b\u53ef\u7528\u4e8e\u4f3c\u7136\u96be\u4ee5\u5904\u7406\u4f46\u5f97\u5206\u53ef\u5904\u7406\u7684\u6a21\u578b\uff0c\u6548\u679c\u4e0e\u7279\u5b9a\u6b63\u6001\u6027\u68c0\u9a8c\u76f8\u5f53\u3002", "conclusion": "\u63d0\u51fa\u7684SKSD\u68c0\u9a8c\u662f\u4e00\u79cd\u6709\u6548\u7684\u975e\u53c2\u6570\u5f97\u5206\u62df\u5408\u4f18\u5ea6\u68c0\u9a8c\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u591a\u79cd\u6a21\u578b\u3002"}}
{"id": "2512.19883", "pdf": "https://arxiv.org/pdf/2512.19883", "abs": "https://arxiv.org/abs/2512.19883", "authors": ["Phong Nguyen", "Anh M. T. Bui", "Phuong T. Nguyen"], "title": "Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection", "categories": ["cs.SE"], "comment": "This paper has been reviewed and accepted to the Short Papers and Posters Track of SANER 2026", "summary": "Ensuring semantic consistency between source code and its accompanying comments is crucial for program comprehension, effective debugging, and long-term maintainability. Comment inconsistency arises when developers modify code but neglect to update the corresponding comments, potentially misleading future maintainers and introducing errors. Recent approaches to code-comment inconsistency (CCI) detection leverage Large Language Models (LLMs) and rely on capturing the semantic relationship between code changes and outdated comments. However, they often ignore the structural complexity of code evolution, including historical change activities, and introduce privacy and resource challenges. In this paper, we propose a Just-In-Time CCI detection approach built upon the CodeT5+ backbone. Our method decomposes code changes into ordered sequences of modification activities such as replacing, deleting, and adding to more effectively capture the correlation between these changes and the corresponding outdated comments. Extensive experiments conducted on publicly available benchmark datasets-JITDATA and CCIBENCH--demonstrate that our proposed approach outperforms recent state-of-the-art models by up to 13.54% in F1-Score and achieves an improvement ranging from 4.18% to 10.94% over fine-tuned LLMs including DeepSeek-Coder, CodeLlama and Qwen2.5-Coder.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eCodeT5+\u9aa8\u5e72\u7684\u53ca\u65f6\u4ee3\u7801-\u6ce8\u91ca\u4e0d\u4e00\u81f4\uff08CCI\uff09\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5728\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709CCI\u68c0\u6d4b\u65b9\u6cd5\u5ffd\u7565\u4ee3\u7801\u6f14\u5316\u7ed3\u6784\u590d\u6742\u6027\uff0c\u4e14\u5b58\u5728\u9690\u79c1\u548c\u8d44\u6e90\u6311\u6218\uff0c\u4fdd\u969c\u4ee3\u7801\u548c\u6ce8\u91ca\u8bed\u4e49\u4e00\u81f4\u6027\u5f88\u91cd\u8981\u3002", "method": "\u5c06\u4ee3\u7801\u53d8\u66f4\u5206\u89e3\u4e3a\u66ff\u6362\u3001\u5220\u9664\u548c\u6dfb\u52a0\u7b49\u4fee\u6539\u6d3b\u52a8\u7684\u6709\u5e8f\u5e8f\u5217\uff0c\u6784\u5efa\u57fa\u4e8eCodeT5+\u9aa8\u5e72\u7684\u53ca\u65f6CCI\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u5728JITDATA\u548cCCIBENCH\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5F1\u5f97\u5206\u6bd4\u73b0\u6709\u6a21\u578b\u6700\u9ad8\u9ad8\u51fa13.54%\uff0c\u6bd4\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u9ad84.18% - 10.94%\u3002", "conclusion": "\u63d0\u51fa\u7684\u53ca\u65f6CCI\u68c0\u6d4b\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u4ee3\u7801\u53d8\u66f4\u4e0e\u8fc7\u65f6\u6ce8\u91ca\u7684\u5173\u8054\uff0c\u6027\u80fd\u4f18\u4e8e\u8fd1\u671f\u6a21\u578b\u3002"}}
{"id": "2512.20477", "pdf": "https://arxiv.org/pdf/2512.20477", "abs": "https://arxiv.org/abs/2512.20477", "authors": ["Ilias Aarab"], "title": "Switching between states and the COVID-19 turbulence", "categories": ["q-fin.ST", "q-fin.PM", "q-fin.RM", "stat.AP"], "comment": null, "summary": "In Aarab (2020), I examine U.S. stock return predictability across economic regimes and document evidence of time-varying expected returns across market states in the long run. The analysis introduces a state-switching specification in which the market state is proxied by the slope of the yield curve, and proposes an Aligned Economic Index built from the popular predictors of Welch and Goyal (2008) (augmented with bond and equity premium measures). The Aligned Economic Index under the state-switching model exhibits statistically and economically meaningful in-sample ($R^2 = 5.9\\%$) and out-of-sample ($R^2_{\\text{oos}} = 4.12\\%$) predictive power across both recessions and expansions, while outperforming a range of widely used predictors. In this work, I examine the added value for professional practitioners by computing the economic gains for a mean-variance investor and find substantial added benefit of using the new index under the state switching model across all market states. The Aligned Economic Index can thus be implemented on a consistent real-time basis. These findings are crucial for both academics and practitioners as expansions are much longer-lived than recessions. Finally, I extend the empirical exercises by incorporating data through September 2020 and document sizable gains from using the Aligned Economic Index, relative to more traditional approaches, during the COVID-19 market turbulence.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u7f8e\u56fd\u80a1\u7968\u6536\u76ca\u8de8\u7ecf\u6d4e\u5468\u671f\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u5f15\u5165\u72b6\u6001\u8f6c\u6362\u6a21\u578b\u548c\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6570\uff0c\u8be5\u6307\u6570\u5728\u4e0d\u540c\u5e02\u573a\u72b6\u6001\u4e0b\u6709\u9884\u6d4b\u529b\uff0c\u5bf9\u4e13\u4e1a\u4eba\u58eb\u6709\u7ecf\u6d4e\u4ef7\u503c\u3002", "motivation": "\u7814\u7a76\u7f8e\u56fd\u80a1\u7968\u6536\u76ca\u8de8\u7ecf\u6d4e\u5236\u5ea6\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u4e3a\u4e13\u4e1a\u4eba\u58eb\u5bfb\u627e\u6709\u4ef7\u503c\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u7531\u6536\u76ca\u7387\u66f2\u7ebf\u659c\u7387\u4ee3\u8868\u5e02\u573a\u72b6\u6001\u7684\u72b6\u6001\u8f6c\u6362\u6a21\u578b\uff0c\u6784\u5efa\u57fa\u4e8eWelch\u548cGoyal\uff082008\uff09\u6d41\u884c\u9884\u6d4b\u56e0\u5b50\u7684\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6570\u3002", "result": "\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6570\u5728\u6837\u672c\u5185\u548c\u6837\u672c\u5916\u5747\u6709\u663e\u8457\u9884\u6d4b\u529b\uff0c\u4f18\u4e8e\u5e38\u7528\u9884\u6d4b\u56e0\u5b50\uff1b\u8ba1\u7b97\u663e\u793a\u5bf9\u5747\u503c - \u65b9\u5dee\u6295\u8d44\u8005\u6709\u663e\u8457\u7ecf\u6d4e\u6536\u76ca\u3002", "conclusion": "\u5bf9\u9f50\u7ecf\u6d4e\u6307\u6570\u53ef\u5b9e\u65f6\u5e94\u7528\uff0c\u5bf9\u5b66\u672f\u754c\u548c\u4ece\u4e1a\u8005\u90fd\u5f88\u91cd\u8981\uff0c\u5728\u65b0\u51a0\u75ab\u60c5\u5e02\u573a\u52a8\u8361\u4e2d\u4e5f\u6709\u53ef\u89c2\u6536\u76ca\u3002"}}
{"id": "2512.20051", "pdf": "https://arxiv.org/pdf/2512.20051", "abs": "https://arxiv.org/abs/2512.20051", "authors": ["Hedibert Lopes", "Nick Polson", "Vadim Sokolov"], "title": "Generative Bayesian Hyperparameter Tuning", "categories": ["stat.ML", "stat.CO"], "comment": null, "summary": "\\noindent Hyper-parameter selection is a central practical problem in modern machine learning, governing regularization strength, model capacity, and robustness choices. Cross-validation is often computationally prohibitive at scale, while fully Bayesian hyper-parameter learning can be difficult due to the cost of posterior sampling. We develop a generative perspective on hyper-parameter tuning that combines two ideas: (i) optimization-based approximations to Bayesian posteriors via randomized, weighted objectives (weighted Bayesian bootstrap), and (ii) amortization of repeated optimization across many hyper-parameter settings by learning a transport map from hyper-parameters (including random weights) to the corresponding optimizer. This yields a ``generator look-up table'' for estimators, enabling rapid evaluation over grids or continuous ranges of hyper-parameters and supporting both predictive tuning objectives and approximate Bayesian uncertainty quantification. We connect this viewpoint to weighted $M$-estimation, envelope/auxiliary-variable representations that reduce non-quadratic losses to weighted least squares, and recent generative samplers for weighted $M$-estimators.", "AI": {"tldr": "\u63d0\u51fa\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u751f\u6210\u89c6\u89d2\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u540e\u9a8c\u8fd1\u4f3c\u548c\u4f18\u5316\u6620\u5c04\u65b9\u6cd5\uff0c\u5b9e\u73b0\u8d85\u53c2\u6570\u5feb\u901f\u8bc4\u4f30\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u4e2d\u8d85\u53c2\u6570\u9009\u62e9\u662f\u6838\u5fc3\u5b9e\u9645\u95ee\u9898\uff0c\u4ea4\u53c9\u9a8c\u8bc1\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5168\u8d1d\u53f6\u65af\u8d85\u53c2\u6570\u5b66\u4e60\u56e0\u540e\u9a8c\u91c7\u6837\u6210\u672c\u5927\u800c\u56f0\u96be\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u4f18\u5316\u7684\u8d1d\u53f6\u65af\u540e\u9a8c\u8fd1\u4f3c\uff08\u52a0\u6743\u8d1d\u53f6\u65af\u81ea\u52a9\u6cd5\uff09\u548c\u5b66\u4e60\u4ece\u8d85\u53c2\u6570\u5230\u4f18\u5316\u5668\u7684\u4f20\u8f93\u6620\u5c04\u3002", "result": "\u5f97\u5230\u4f30\u8ba1\u5668\u7684\u201c\u751f\u6210\u5668\u67e5\u627e\u8868\u201d\uff0c\u80fd\u5728\u8d85\u53c2\u6570\u7f51\u683c\u6216\u8fde\u7eed\u8303\u56f4\u4e0a\u5feb\u901f\u8bc4\u4f30\uff0c\u652f\u6301\u9884\u6d4b\u8c03\u4f18\u76ee\u6807\u548c\u8fd1\u4f3c\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u65b0\u89c6\u89d2\u4e0e\u52a0\u6743M - \u4f30\u8ba1\u3001\u8f85\u52a9\u53d8\u91cf\u8868\u793a\u53ca\u76f8\u5173\u751f\u6210\u91c7\u6837\u5668\u5efa\u7acb\u4e86\u8054\u7cfb\uff0c\u4e3a\u8d85\u53c2\u6570\u8c03\u4f18\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2512.19972", "pdf": "https://arxiv.org/pdf/2512.19972", "abs": "https://arxiv.org/abs/2512.19972", "authors": ["Pengchao Han", "Xi Huang", "Yi Fang", "Guojun Han"], "title": "Rethinking Knowledge Distillation in Collaborative Machine Learning: Memory, Knowledge, and Their Interactions", "categories": ["cs.DC"], "comment": "Published in IEEE TNSE", "summary": "Collaborative learning has emerged as a key paradigm in large-scale intelligent systems, enabling distributed agents to cooperatively train their models while addressing their privacy concerns. Central to this paradigm is knowledge distillation (KD), a technique that facilitates efficient knowledge transfer among agents. However, the underlying mechanisms by which KD leverages memory and knowledge across agents remain underexplored. This paper aims to bridge this gap by offering a comprehensive review of KD in collaborative learning, with a focus on the roles of memory and knowledge. We define and categorize memory and knowledge within the KD process and explore their interrelationships, providing a clear understanding of how knowledge is extracted, stored, and shared in collaborative settings. We examine various collaborative learning patterns, including distributed, hierarchical, and decentralized structures, and provide insights into how memory and knowledge dynamics shape the effectiveness of KD in collaborative learning. Particularly, we emphasize task heterogeneity in distributed learning pattern covering federated learning (FL), multi-agent domain adaptation (MADA), federated multi-modal learning (FML), federated continual learning (FCL), federated multi-task learning (FMTL), and federated graph knowledge embedding (FKGE). Additionally, we highlight model heterogeneity, data heterogeneity, resource heterogeneity, and privacy concerns of these tasks. Our analysis categorizes existing work based on how they handle memory and knowledge. Finally, we discuss existing challenges and propose future directions for advancing KD techniques in the context of collaborative learning.", "AI": {"tldr": "\u672c\u6587\u5bf9\u534f\u4f5c\u5b66\u4e60\u4e2d\u7684\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u8fdb\u884c\u5168\u9762\u7efc\u8ff0\uff0c\u805a\u7126\u8bb0\u5fc6\u548c\u77e5\u8bc6\u7684\u4f5c\u7528\uff0c\u5206\u6790\u4e0d\u540c\u534f\u4f5c\u5b66\u4e60\u6a21\u5f0f\uff0c\u63a2\u8ba8\u4efb\u52a1\u548c\u6a21\u578b\u7b49\u5f02\u8d28\u6027\uff0c\u5bf9\u73b0\u6709\u5de5\u4f5c\u5206\u7c7b\uff0c\u8ba8\u8bba\u6311\u6218\u5e76\u63d0\u51fa\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u534f\u4f5c\u5b66\u4e60\u4e2dKD\u5229\u7528\u8de8\u4ee3\u7406\u7684\u8bb0\u5fc6\u548c\u77e5\u8bc6\u7684\u6f5c\u5728\u673a\u5236\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u5b9a\u4e49\u548c\u5206\u7c7bKD\u8fc7\u7a0b\u4e2d\u7684\u8bb0\u5fc6\u548c\u77e5\u8bc6\uff0c\u63a2\u7d22\u5176\u76f8\u4e92\u5173\u7cfb\uff1b\u7814\u7a76\u591a\u79cd\u534f\u4f5c\u5b66\u4e60\u6a21\u5f0f\uff1b\u5f3a\u8c03\u591a\u79cd\u4efb\u52a1\u4e2d\u7684\u4efb\u52a1\u5f02\u8d28\u6027\uff1b\u5206\u6790\u6a21\u578b\u3001\u6570\u636e\u3001\u8d44\u6e90\u5f02\u8d28\u6027\u548c\u9690\u79c1\u95ee\u9898\uff1b\u5bf9\u73b0\u6709\u5de5\u4f5c\u57fa\u4e8e\u5176\u5904\u7406\u8bb0\u5fc6\u548c\u77e5\u8bc6\u7684\u65b9\u5f0f\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5bf9\u73b0\u6709\u5de5\u4f5c\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u7c7b\uff0c\u660e\u786e\u4e86\u8bb0\u5fc6\u548c\u77e5\u8bc6\u5728\u4e0d\u540c\u534f\u4f5c\u5b66\u4e60\u6a21\u5f0f\u4e2d\u5bf9KD\u6709\u6548\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5f53\u524dKD\u6280\u672f\u5728\u534f\u4f5c\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2512.20034", "pdf": "https://arxiv.org/pdf/2512.20034", "abs": "https://arxiv.org/abs/2512.20034", "authors": ["Xian Wu", "Ming Zhang", "Zhiyu Fang", "Fei Li", "Bin Wang", "Yong Jiang", "Hao Zhou"], "title": "VSA:Visual-Structural Alignment for UI-to-Code", "categories": ["cs.IR"], "comment": null, "summary": "The automation of user interface development has the potential to accelerate software delivery by mitigating intensive manual implementation. Despite the advancements in Large Multimodal Models for design-to-code translation, existing methodologies predominantly yield unstructured, flat codebases that lack compatibility with component-oriented libraries such as React or Angular. Such outputs typically exhibit low cohesion and high coupling, complicating long-term maintenance. In this paper, we propose \\textbf{VSA (VSA)}, a multi-stage paradigm designed to synthesize organized frontend assets through visual-structural alignment. Our approach first employs a spatial-aware transformer to reconstruct the visual input into a hierarchical tree representation. Moving beyond basic layout extraction, we integrate an algorithmic pattern-matching layer to identify recurring UI motifs and encapsulate them into modular templates. These templates are then processed via a schema-driven synthesis engine, ensuring the Large Language Model generates type-safe, prop-drilled components suitable for production environments. Experimental results indicate that our framework yields a substantial improvement in code modularity and architectural consistency over state-of-the-art benchmarks, effectively bridging the gap between raw pixels and scalable software engineering.", "AI": {"tldr": "\u63d0\u51faVSA\u8303\u5f0f\u89e3\u51b3\u73b0\u6709\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u65b9\u6cd5\u751f\u6210\u4ee3\u7801\u7f3a\u4e4f\u7ed3\u6784\u3001\u96be\u7ef4\u62a4\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u63d0\u5347\u4e86\u4ee3\u7801\u6a21\u5757\u5316\u548c\u67b6\u6784\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8de8\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u8bbe\u8ba1\u5230\u4ee3\u7801\u8f6c\u6362\u65f6\u751f\u6210\u7684\u4ee3\u7801\u65e0\u7ed3\u6784\u3001\u517c\u5bb9\u6027\u5dee\u3001\u7ef4\u62a4\u96be\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5\u8303\u5f0fVSA\uff0c\u5148\u901a\u8fc7\u7a7a\u95f4\u611f\u77e5\u53d8\u538b\u5668\u5c06\u89c6\u89c9\u8f93\u5165\u91cd\u6784\u4e3a\u5c42\u6b21\u6811\u8868\u793a\uff0c\u518d\u7528\u7b97\u6cd5\u6a21\u5f0f\u5339\u914d\u5c42\u8bc6\u522b\u91cd\u590dUI\u4e3b\u9898\u5e76\u5c01\u88c5\u6210\u6a21\u5757\u6a21\u677f\uff0c\u6700\u540e\u901a\u8fc7\u6a21\u5f0f\u9a71\u52a8\u5408\u6210\u5f15\u64ce\u751f\u6210\u9002\u5408\u751f\u4ea7\u73af\u5883\u7684\u7ec4\u4ef6\u3002", "result": "\u6846\u67b6\u5728\u4ee3\u7801\u6a21\u5757\u5316\u548c\u67b6\u6784\u4e00\u81f4\u6027\u4e0a\u6bd4\u73b0\u6709\u57fa\u51c6\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "VSA\u8303\u5f0f\u6709\u6548\u5f25\u5408\u4e86\u539f\u59cb\u50cf\u7d20\u4e0e\u53ef\u6269\u5c55\u8f6f\u4ef6\u5de5\u7a0b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.19957", "pdf": "https://arxiv.org/pdf/2512.19957", "abs": "https://arxiv.org/abs/2512.19957", "authors": ["Luciano Araujo Dourado Filho", "Almir Moreira da Silva Neto", "Rodrigo Pereira David", "Rodrigo Tripodi Calumby"], "title": "Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test set images. To obtain these representations, the proposed method extracts features from training dataset images and create clusters, by applying K-Means, with $K$ equals to the number of classes in the dataset. The segmentation model is a customized narrow ViT, built by replacing the patch embedding layer with a frozen DinoV2, pre-trained on the training dataset for individual species classification. This model is trained to reconstruct the class prototypes of the training dataset from the test dataset images. We then use this model to obtain attention scores that enable to identify and localize areas of interest and consequently guide the classification process. The proposed approach enabled a domain-adaptation from multi-class identification with individual species, into multi-label classification from high-resolution vegetation plots. Our method achieved fifth place in the PlantCLEF 2025 challenge on the private leaderboard, with an F1 score of 0.33331. Besides that, in absolute terms our method scored 0.03 lower than the top-performing submission, suggesting that it may achieved competitive performance in the benchmark task. Our code is available at \\href{https://github.com/ADAM-UEFS/PlantCLEF2025}{https://github.com/ADAM-UEFS/PlantCLEF2025}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5e94\u5bf9PlantClef 2025\u6311\u6218\u7684\u65b9\u6cd5\uff0c\u7528\u8bad\u7ec3\u96c6\u7c7b\u539f\u578b\u6307\u5bfc\u5206\u5272ViT\u6a21\u578b\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4ece\u591a\u7c7b\u8bc6\u522b\u5230\u591a\u6807\u7b7e\u5206\u7c7b\u7684\u57df\u9002\u5e94\uff0c\u5728\u6311\u6218\u8d5b\u4e2d\u83b7\u7b2c\u4e94\u540d\u3002", "motivation": "\u5e94\u5bf9PlantClef 2025\u6311\u6218\uff0c\u89e3\u51b3\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u7684\u7ec6\u7c92\u5ea6\u591a\u6807\u7b7e\u7269\u79cd\u8bc6\u522b\u95ee\u9898\u3002", "method": "\u4ece\u8bad\u7ec3\u96c6\u56fe\u50cf\u63d0\u53d6\u7279\u5f81\u5e76\u7528K - Means\u805a\u7c7b\u5f97\u5230\u7c7b\u539f\u578b\uff1b\u7528\u9884\u8bad\u7ec3\u7684DinoV2\u66ff\u6362patch embedding\u5c42\u6784\u5efa\u5b9a\u5236\u5316\u7a84ViT\uff1b\u8bad\u7ec3\u6a21\u578b\u4ece\u6d4b\u8bd5\u96c6\u56fe\u50cf\u91cd\u5efa\u8bad\u7ec3\u96c6\u7c7b\u539f\u578b\uff1b\u7528\u6a21\u578b\u83b7\u53d6\u6ce8\u610f\u529b\u5206\u6570\u6307\u5bfc\u5206\u7c7b\u3002", "result": "\u5728PlantCLEF 2025\u6311\u6218\u79c1\u6709\u6392\u884c\u699c\u83b7\u7b2c\u4e94\u540d\uff0cF1\u5206\u65700.33331\uff0c\u6bd4\u7b2c\u4e00\u540d\u4f4e0.03\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u4efb\u52a1\u4e2d\u53ef\u80fd\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u8868\u73b0\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.20286", "pdf": "https://arxiv.org/pdf/2512.20286", "abs": "https://arxiv.org/abs/2512.20286", "authors": ["Timothy Weber", "Cheng Cheng", "Harry Thawley", "Kylie Catchpole", "Andrew Blakers", "Bin Lu", "Jennifer Zhao", "Anna Nadolny"], "title": "Replacing Gas with Low-cost, Abundant Long-duration Pumped Hydro in Electricity Systems", "categories": ["cs.CE", "econ.GN", "math.OC"], "comment": null, "summary": "Fossil gas is sometimes presented as an enabler of variable solar and wind generation beyond 2050, despite being a primary source of greenhouse gas emissions from methane leakage and combustion. We find that balancing solar and wind generation with pumped hydro energy storage eliminates the need for fossil gas without incurring a cost penalty. However, many existing long-term electricity system plans are biased to rely on fossil gas due to using temporal aggregation methods that either heavily constrain storage cycling behaviour or lose track of the state-of-charge, failing to consider the potential of low-cost long-duration off-river pumped hydro, and ignoring the broad suite of near-optimal energy transition pathways. We show that a temporal aggregation method based on 'segmentation' (fitted chronology) closely resembles the full-series optimisation, captures long-duration storage behaviour (48- and 160-hour durations), and finds a near-optimal 100% renewable electricity solution. We develop a new electricity system model to rapidly evaluate millions of other near-optimal solutions, stressing the importance of modelling pumped hydro sites with a low energy volume cost (<US$50 per kilowatt-hour), long economic lifetime (~75 years), and low real discount rate akin to other natural monopolies (<=3%). Almost every region of the world has access to sufficient 50 - 5000 gigawatt-hour off-river pumped hydro options that enable them to entirely decarbonise their future electricity systems.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u7528\u62bd\u6c34\u84c4\u80fd\u5e73\u8861\u592a\u9633\u80fd\u548c\u98ce\u80fd\u53d1\u7535\u53ef\u6d88\u9664\u5bf9\u5316\u77f3\u6c14\u7684\u9700\u6c42\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u548c\u6a21\u578b\u52a9\u529b\u7535\u529b\u7cfb\u7edf\u8131\u78b3\u3002", "motivation": "\u5316\u77f3\u6c14\u867d\u88ab\u89c6\u4e3a2050\u5e74\u540e\u652f\u6301\u53ef\u53d8\u592a\u9633\u80fd\u548c\u98ce\u80fd\u53d1\u7535\u7684\u80fd\u6e90\uff0c\u4f46\u5b83\u662f\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u4e3b\u8981\u6765\u6e90\uff0c\u73b0\u6709\u957f\u671f\u7535\u529b\u7cfb\u7edf\u8ba1\u5212\u8fc7\u5ea6\u4f9d\u8d56\u5316\u77f3\u6c14\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u201c\u5206\u6bb5\u201d\u7684\u65f6\u95f4\u805a\u5408\u65b9\u6cd5\uff0c\u5f00\u53d1\u65b0\u7684\u7535\u529b\u7cfb\u7edf\u6a21\u578b\u3002", "result": "\u57fa\u4e8e\u201c\u5206\u6bb5\u201d\u7684\u65b9\u6cd5\u63a5\u8fd1\u5168\u7cfb\u5217\u4f18\u5316\uff0c\u80fd\u6355\u6349\u957f\u65f6\u50a8\u80fd\u884c\u4e3a\uff0c\u627e\u5230\u8fd1\u4e4e\u6700\u4f18\u7684100%\u53ef\u518d\u751f\u7535\u529b\u89e3\u51b3\u65b9\u6848\uff1b\u5f00\u53d1\u7684\u6a21\u578b\u53ef\u5feb\u901f\u8bc4\u4f30\u6570\u767e\u4e07\u5176\u4ed6\u8fd1\u4e4e\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u4e16\u754c\u4e0a\u51e0\u4e4e\u6bcf\u4e2a\u5730\u533a\u90fd\u6709\u8db3\u591f\u7684\u79bb\u6cb3\u62bd\u6c34\u84c4\u80fd\u9009\u9879\uff0c\u53ef\u5b9e\u73b0\u672a\u6765\u7535\u529b\u7cfb\u7edf\u7684\u5b8c\u5168\u8131\u78b3\u3002"}}
{"id": "2512.19717", "pdf": "https://arxiv.org/pdf/2512.19717", "abs": "https://arxiv.org/abs/2512.19717", "authors": ["Zhan Zhang"], "title": "Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages", "summary": "Finding rare but useful solutions in very large candidate spaces is a recurring practical challenge across language generation, planning, and reinforcement learning. We present a practical framework, \\emph{Inverted Causality Focusing Algorithm} (ICFA), that treats search as a target-conditioned reweighting process. ICFA reuses an available proposal sampler and a task-specific similarity function to form a focused sampling distribution, while adaptively controlling focusing strength to avoid degeneracy. We provide a clear recipe, a stability diagnostic based on effective sample size, a compact theoretical sketch explaining when ICFA can reduce sample needs, and two reproducible experiments: constrained language generation and sparse-reward navigation. We further show how structured prompts instantiate an approximate, language-level form of ICFA and describe a hybrid architecture combining prompted inference with algorithmic reweighting.", "AI": {"tldr": "\u63d0\u51fa\u5012\u7f6e\u56e0\u679c\u805a\u7126\u7b97\u6cd5\uff08ICFA\uff09\u7528\u4e8e\u5728\u5927\u5019\u9009\u7a7a\u95f4\u4e2d\u5bfb\u627e\u7a00\u6709\u6709\u7528\u89e3\uff0c\u7ed9\u51fa\u76f8\u5173\u65b9\u6cd5\u3001\u8bca\u65ad\u5de5\u5177\uff0c\u8fdb\u884c\u5b9e\u9a8c\u5e76\u5c55\u793a\u6df7\u5408\u67b6\u6784\u3002", "motivation": "\u89e3\u51b3\u5728\u8bed\u8a00\u751f\u6210\u3001\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\u7b49\u9886\u57df\u7684\u5927\u5019\u9009\u7a7a\u95f4\u4e2d\u5bfb\u627e\u7a00\u6709\u6709\u7528\u89e3\u7684\u5b9e\u9645\u6311\u6218\u3002", "method": "\u5c06\u641c\u7d22\u89c6\u4e3a\u76ee\u6807\u6761\u4ef6\u91cd\u52a0\u6743\u8fc7\u7a0b\uff0c\u91cd\u7528\u5df2\u6709\u63d0\u8bae\u91c7\u6837\u5668\u548c\u76f8\u4f3c\u5ea6\u51fd\u6570\u5f62\u6210\u805a\u7126\u91c7\u6837\u5206\u5e03\uff0c\u81ea\u9002\u5e94\u63a7\u5236\u805a\u7126\u5f3a\u5ea6\u3002", "result": "\u63d0\u4f9b\u6e05\u6670\u65b9\u6cd5\u3001\u7a33\u5b9a\u6027\u8bca\u65ad\u5de5\u5177\u3001\u7406\u8bba\u89e3\u91ca\uff0c\u8fdb\u884c\u7ea6\u675f\u8bed\u8a00\u751f\u6210\u548c\u7a00\u758f\u5956\u52b1\u5bfc\u822a\u5b9e\u9a8c\uff0c\u5c55\u793a\u7ed3\u6784\u5316\u63d0\u793a\u548c\u6df7\u5408\u67b6\u6784\u3002", "conclusion": "ICFA\u53ef\u51cf\u5c11\u6837\u672c\u9700\u6c42\uff0c\u7ed3\u6784\u5316\u63d0\u793a\u53ef\u5b9e\u73b0\u8fd1\u4f3c\u8bed\u8a00\u7ea7ICFA\uff0c\u6df7\u5408\u67b6\u6784\u7ed3\u5408\u4e86\u63d0\u793a\u63a8\u7406\u548c\u7b97\u6cd5\u91cd\u52a0\u6743\u3002"}}
{"id": "2512.17979", "pdf": "https://arxiv.org/pdf/2512.17979", "abs": "https://arxiv.org/abs/2512.17979", "authors": ["Matthieu Mastio", "Paul Saves", "Benoit Gaudou", "Nicolas Verstaevel"], "title": "Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis", "categories": ["cs.GT", "cs.AI", "cs.MA", "econ.GN", "stat.AP"], "comment": "AAMAS CC-BY 4.0 licence. Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis. Full paper. In Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), Paphos, Cyprus, May 25 - 29, 2026, IFAAMAS, 10 pages", "summary": "Industrial symbiosis fosters circularity by enabling firms to repurpose residual resources, yet its emergence is constrained by socio-spatial frictions that shape costs, matching opportunities, and market efficiency. Existing models often overlook the interaction between spatial structure, market design, and adaptive firm behavior, limiting our understanding of where and how symbiosis arises. We develop an agent-based model where heterogeneous firms trade byproducts through a spatially embedded double-auction market, with prices and quantities emerging endogenously from local interactions. Leveraging reinforcement learning, firms adapt their bidding strategies to maximize profit while accounting for transport costs, disposal penalties, and resource scarcity. Simulation experiments reveal the economic and spatial conditions under which decentralized exchanges converge toward stable and efficient outcomes. Counterfactual regret analysis shows that sellers' strategies approach a near Nash equilibrium, while sensitivity analysis highlights how spatial structures and market parameters jointly govern circularity. Our model provides a basis for exploring policy interventions that seek to align firm incentives with sustainability goals, and more broadly demonstrates how decentralized coordination can emerge from adaptive agents in spatially constrained markets.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u57fa\u4e8e\u4e3b\u4f53\u7684\u6a21\u578b\u7814\u7a76\u4ea7\u4e1a\u5171\u751f\uff0c\u63ed\u793a\u5206\u6563\u4ea4\u6613\u6536\u655b\u7684\u6761\u4ef6\uff0c\u4e3a\u653f\u7b56\u5e72\u9884\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5e38\u5ffd\u7565\u7a7a\u95f4\u7ed3\u6784\u3001\u5e02\u573a\u8bbe\u8ba1\u548c\u4f01\u4e1a\u9002\u5e94\u6027\u884c\u4e3a\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u9650\u5236\u5bf9\u4ea7\u4e1a\u5171\u751f\u51fa\u73b0\u5730\u70b9\u548c\u65b9\u5f0f\u7684\u7406\u89e3\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u4e3b\u4f53\u7684\u6a21\u578b\uff0c\u4f01\u4e1a\u901a\u8fc7\u7a7a\u95f4\u5d4c\u5165\u7684\u53cc\u5411\u62cd\u5356\u5e02\u573a\u4ea4\u6613\u526f\u4ea7\u54c1\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8ba9\u4f01\u4e1a\u8c03\u6574\u6295\u6807\u7b56\u7565\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u63ed\u793a\u5206\u6563\u4ea4\u6613\u6536\u655b\u5230\u7a33\u5b9a\u6709\u6548\u7ed3\u679c\u7684\u7ecf\u6d4e\u548c\u7a7a\u95f4\u6761\u4ef6\uff0c\u53cd\u4e8b\u5b9e\u9057\u61be\u5206\u6790\u548c\u654f\u611f\u6027\u5206\u6790\u6709\u76f8\u5e94\u53d1\u73b0\u3002", "conclusion": "\u6a21\u578b\u4e3a\u63a2\u7d22\u653f\u7b56\u5e72\u9884\u63d0\u4f9b\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u7a7a\u95f4\u53d7\u9650\u5e02\u573a\u4e2d\u9002\u5e94\u6027\u4e3b\u4f53\u5982\u4f55\u5b9e\u73b0\u5206\u6563\u534f\u8c03\u3002"}}
{"id": "2512.20021", "pdf": "https://arxiv.org/pdf/2512.20021", "abs": "https://arxiv.org/abs/2512.20021", "authors": ["Anna R. Flowers", "Christopher T. Franck", "Robert B. Gramacy", "Justin A. Krometis"], "title": "Gaussian Process Assisted Meta-learning for Image Classification and Object Detection Models", "categories": ["stat.ML", "cs.LG"], "comment": "15 pages, 8 figures", "summary": "Collecting operationally realistic data to inform machine learning models can be costly. Before collecting new data, it is helpful to understand where a model is deficient. For example, object detectors trained on images of rare objects may not be good at identification in poorly represented conditions. We offer a way of informing subsequent data acquisition to maximize model performance by leveraging the toolkit of computer experiments and metadata describing the circumstances under which the training data was collected (e.g., season, time of day, location). We do this by evaluating the learner as the training data is varied according to its metadata. A Gaussian process (GP) surrogate fit to that response surface can inform new data acquisitions. This meta-learning approach offers improvements to learner performance as compared to data with randomly selected metadata, which we illustrate on both classic learning examples, and on a motivating application involving the collection of aerial images in search of airplanes.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u8ba1\u7b97\u673a\u5b9e\u9a8c\u5de5\u5177\u548c\u8bad\u7ec3\u6570\u636e\u5143\u6570\u636e\u6307\u5bfc\u540e\u7eed\u6570\u636e\u91c7\u96c6\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\u9a8c\u8bc1\u3002", "motivation": "\u6536\u96c6\u5b9e\u9645\u64cd\u4f5c\u6570\u636e\u6210\u672c\u9ad8\uff0c\u5728\u6536\u96c6\u65b0\u6570\u636e\u524d\u9700\u4e86\u89e3\u6a21\u578b\u4e0d\u8db3\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u6839\u636e\u8bad\u7ec3\u6570\u636e\u5143\u6570\u636e\u6539\u53d8\u8bad\u7ec3\u6570\u636e\u6765\u8bc4\u4f30\u5b66\u4e60\u5668\uff0c\u7528\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u62df\u5408\u54cd\u5e94\u9762\u4ee5\u6307\u5bfc\u65b0\u6570\u636e\u91c7\u96c6\u3002", "result": "\u4e0e\u968f\u673a\u9009\u62e9\u5143\u6570\u636e\u7684\u6570\u636e\u76f8\u6bd4\uff0c\u8be5\u5143\u5b66\u4e60\u65b9\u6cd5\u80fd\u63d0\u5347\u5b66\u4e60\u5668\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u7ecf\u5178\u5b66\u4e60\u793a\u4f8b\u548c\u98de\u673a\u822a\u62cd\u56fe\u50cf\u6536\u96c6\u5e94\u7528\u4e2d\u6709\u6548\u3002"}}
{"id": "2512.19980", "pdf": "https://arxiv.org/pdf/2512.19980", "abs": "https://arxiv.org/abs/2512.19980", "authors": ["Zhe Yin", "Xiaodong Gu", "Beijun Shen"], "title": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?", "categories": ["cs.SE", "cs.AI"], "comment": "Accepted by FSE2026", "summary": "Code language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u795e\u7ecf\u5143\u7ea7\u522b\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u8bed\u8a00\u7279\u5b9a\u795e\u7ecf\u5143\u548c\u6982\u5ff5\u5c42\uff0c\u4e14\u5728\u4e09\u4e2a\u4efb\u52a1\u4e2d\u5c55\u793a\u5176\u6548\u7528\u3002", "motivation": "\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e0d\u8db3\uff0c\u73b0\u6709NLP\u795e\u7ecf\u5143\u53ef\u89e3\u91ca\u6027\u6280\u672f\u4e0d\u9002\u7528\u4e8e\u6e90\u4ee3\u7801\u3002", "method": "\u5bf9Llama - 3.1 - 8B\u548cQwen2.5 - Coder - 32B\u5728\u591a\u8bed\u8a00\u8f93\u5165\u4e0b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u6d4b\u91cf\u795e\u7ecf\u5143\u9009\u62e9\u6027\u548c\u5c42\u8d21\u732e\u3002", "result": "\u53d1\u73b0\u6709\u7279\u5b9a\u8bed\u8a00\u7684\u795e\u7ecf\u5143\u548c\u652f\u6301\u901a\u7528\u751f\u6210\u7684\u901a\u7528\u5b50\u96c6\uff1b\u8f83\u4f4e\u5c42\u7f16\u7801\u7279\u5b9a\u8bed\u8a00\u8bed\u6cd5\uff0c\u4e2d\u95f4\u5c42\u6355\u83b7\u8de8\u8bed\u8a00\u8bed\u4e49\u62bd\u8c61\u5f62\u6210\u6982\u5ff5\u5c42\u3002", "conclusion": "\u5728\u4ee3\u7801\u751f\u6210\u3001\u514b\u9686\u68c0\u6d4b\u548c\u4ee3\u7801\u6458\u8981\u4e09\u4e2a\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\uff0c\u76f8\u5173\u65b9\u6cd5\u80fd\u5e26\u6765\u6301\u7eed\u589e\u76ca\u3002"}}
{"id": "2512.20385", "pdf": "https://arxiv.org/pdf/2512.20385", "abs": "https://arxiv.org/abs/2512.20385", "authors": ["Yonggwan Shin", "Yire Shin", "Jihong Park", "Jeong-Soo Park"], "title": "Generalized method of L-moment estimation for stationary and nonstationary extreme value models", "categories": ["stat.ME", "stat.AP", "stat.CO"], "comment": null, "summary": "Precisely estimating out-of-sample upper quantiles is very important in risk assessment and in engineering practice for structural design to prevent a greater disaster. For this purpose, the generalized extreme value (GEV) distribution has been broadly used. To estimate the parameters of GEV distribution, the maximum likelihood estimation (MLE) and L-moment estimation (LME) methods have been primarily employed. For a better estimation using the MLE, several studies considered the generalized MLE (penalized likelihood or Bayesian) methods to cooperate with a penalty function or prior information for parameters. However, a generalized LME method for the same purpose has not been developed yet in the literature. We thus propose the generalized method of L-moment estimation (GLME) to cooperate with a penalty function or prior information. The proposed estimation is based on the generalized L-moment distance and a multivariate normal likelihood approximation. Because the L-moment estimator is more efficient and robust for small samples than the MLE, we reasonably expect the advantages of LME to continue to hold for GLME. The proposed method is applied to the stationary and nonstationary GEV models with two novel (data-adaptive) penalty functions to correct the bias of LME. A simulation study indicates that the biases of LME are considerably corrected by the GLME with slight increases in the standard error. Applications to US flood damage data and maximum rainfall at Phliu Agromet in Thailand illustrate the usefulness of the proposed method. This study may promote further work on penalized or Bayesian inferences based on L-moments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e7f\u4e49L - \u77e9\u4f30\u8ba1\u6cd5\uff08GLME\uff09\u7528\u4e8e\u4f30\u8ba1\u5e7f\u4e49\u6781\u503c\uff08GEV\uff09\u5206\u5e03\u53c2\u6570\uff0c\u6a21\u62df\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u7ea0\u6b63L - \u77e9\u4f30\u8ba1\uff08LME\uff09\u504f\u5dee\uff0c\u6216\u63a8\u52a8\u57fa\u4e8eL - \u77e9\u7684\u60e9\u7f5a\u6216\u8d1d\u53f6\u65af\u63a8\u65ad\u7814\u7a76\u3002", "motivation": "\u5df2\u6709\u5e7f\u4e49\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u65b9\u6cd5\u7528\u4e8eGEV\u5206\u5e03\u53c2\u6570\u4f30\u8ba1\uff0c\u4f46\u5e7f\u4e49L - \u77e9\u4f30\u8ba1\uff08LME\uff09\u65b9\u6cd5\u5c1a\u672a\u5f00\u53d1\uff0c\u4e3a\u66f4\u597d\u4f30\u8ba1GEV\u5206\u5e03\u53c2\u6570\uff0c\u63d0\u51faGLME\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5e7f\u4e49L - \u77e9\u8ddd\u79bb\u548c\u591a\u5143\u6b63\u6001\u4f3c\u7136\u8fd1\u4f3c\u63d0\u51faGLME\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u5e73\u7a33\u548c\u975e\u5e73\u7a33GEV\u6a21\u578b\uff0c\u4f7f\u7528\u4e24\u79cd\u65b0\u578b\u60e9\u7f5a\u51fd\u6570\u7ea0\u6b63LME\u504f\u5dee\u3002", "result": "\u6a21\u62df\u7814\u7a76\u663e\u793aGLME\u80fd\u5927\u5e45\u7ea0\u6b63LME\u504f\u5dee\uff0c\u6807\u51c6\u8bef\u5dee\u7565\u6709\u589e\u52a0\uff1b\u5bf9\u7f8e\u56fd\u6d2a\u6c34\u635f\u5931\u6570\u636e\u548c\u6cf0\u56fd\u6700\u5927\u964d\u96e8\u91cf\u6570\u636e\u7684\u5e94\u7528\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684GLME\u65b9\u6cd5\u6709\u6548\uff0c\u53ef\u7528\u4e8e\u66f4\u597d\u4f30\u8ba1GEV\u5206\u5e03\u53c2\u6570\uff0c\u6709\u671b\u63a8\u52a8\u57fa\u4e8eL - \u77e9\u7684\u60e9\u7f5a\u6216\u8d1d\u53f6\u65af\u63a8\u65ad\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2512.20017", "pdf": "https://arxiv.org/pdf/2512.20017", "abs": "https://arxiv.org/abs/2512.20017", "authors": ["Hexu Zhao", "Xiaoteng Liu", "Xiwen Min", "Jianhao Huang", "Youming Deng", "Yanfei Li", "Ang Li", "Jinyang Li", "Aurojit Panda"], "title": "Scaling Point-based Differentiable Rendering for Large-scale Reconstruction", "categories": ["cs.DC", "cs.GR"], "comment": "13 pages main text, plus appendix", "summary": "Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication overhead due to poor data locality. In this paper, we present Gaian, a general distributed training system for PBDR. Gaian provides a unified API expressive enough to support existing PBDR methods, while exposing rich data-access information, which Gaian leverages to optimize locality and reduce communication. We evaluated Gaian by implementing 4 PBDR algorithms. Our implementations achieve high performance and resource efficiency: across six datasets and up to 128 GPUs, it reduces communication by up to 91% and improves training throughput by 1.50x-3.71x.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8e\u70b9\u57fa\u53ef\u5fae\u6e32\u67d3\uff08PBDR\uff09\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edfGaian\uff0c\u53ef\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3001\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf", "motivation": "\u73b0\u6709PBDR\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf\u4e0e\u7279\u5b9a\u65b9\u6cd5\u8026\u5408\u4e14\u901a\u4fe1\u5f00\u9500\u5927\uff0c\u9700\u9ad8\u6548\u7cfb\u7edf", "method": "\u63d0\u51faGaian\u7cfb\u7edf\uff0c\u63d0\u4f9b\u7edf\u4e00API\uff0c\u5229\u7528\u6570\u636e\u8bbf\u95ee\u4fe1\u606f\u4f18\u5316\u5c40\u90e8\u6027\u548c\u51cf\u5c11\u901a\u4fe1", "result": "\u5b9e\u73b04\u79cdPBDR\u7b97\u6cd5\uff0c\u57286\u4e2a\u6570\u636e\u96c6\u3001\u6700\u591a128\u4e2aGPU\u4e0a\u901a\u4fe1\u51cf\u5c11\u6700\u591a91%\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u53471.5 - 3.71\u500d", "conclusion": "Gaian\u80fd\u9ad8\u6548\u7528\u4e8ePBDR\u5206\u5e03\u5f0f\u8bad\u7ec3\uff0c\u9ad8\u6027\u80fd\u4e14\u8d44\u6e90\u9ad8\u6548"}}
{"id": "2512.20172", "pdf": "https://arxiv.org/pdf/2512.20172", "abs": "https://arxiv.org/abs/2512.20172", "authors": ["Yan Zhang", "Li Deng", "Lixin Duan", "Ivor W. Tsang", "Guowu Yang"], "title": "Collaborative Group-Aware Hashing for Fast Recommender Systems", "categories": ["cs.IR"], "comment": null, "summary": "The fast online recommendation is critical for applications with large-scale databases; meanwhile, it is challenging to provide accurate recommendations in sparse scenarios. Hash technique has shown its superiority for speeding up the online recommendation by bit operations on Hamming distance computations. However, existing hashing-based recommendations suffer from low accuracy, especially with sparse settings, due to the limited representation capability of each bit and neglected inherent relations among users and items. To this end, this paper lodges a Collaborative Group-Aware Hashing (CGAH) method for both collaborative filtering (namely CGAH-CF) and content-aware recommendations (namely CGAH) by integrating the inherent group information to alleviate the sparse issue. Firstly, we extract inherent group affinities of users and items by classifying their latent vectors into different groups. Then, the preference is formulated as the inner product of the group affinity and the similarity of hash codes. By learning hash codes with the inherent group information, CGAH obtains more effective hash codes than other discrete methods with sparse interactive data. Extensive experiments on three public datasets show the superior performance of our proposed CGAH and CGAH-CF over the state-of-the-art discrete collaborative filtering methods and discrete content-aware recommendations under different sparse settings.", "AI": {"tldr": "\u63d0\u51faCGAH\u65b9\u6cd5\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\uff0c\u6574\u5408\u7fa4\u7ec4\u4fe1\u606f\u7f13\u89e3\u7a00\u758f\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u79bb\u6563\u65b9\u6cd5\u3002", "motivation": "\u5728\u7ebf\u63a8\u8350\u9700\u517c\u987e\u901f\u5ea6\u4e0e\u7a00\u758f\u573a\u666f\u4e0b\u7684\u51c6\u786e\u6027\uff0c\u73b0\u6709\u57fa\u4e8e\u54c8\u5e0c\u7684\u63a8\u8350\u65b9\u6cd5\u5728\u7a00\u758f\u573a\u666f\u4e0b\u51c6\u786e\u7387\u4f4e\u3002", "method": "\u63d0\u51faCGAH\u65b9\u6cd5\uff0c\u5148\u63d0\u53d6\u7528\u6237\u548c\u7269\u54c1\u7684\u7fa4\u7ec4\u4eb2\u548c\u529b\uff0c\u518d\u5c06\u504f\u597d\u8868\u793a\u4e3a\u7fa4\u7ec4\u4eb2\u548c\u529b\u548c\u54c8\u5e0c\u7801\u76f8\u4f3c\u5ea6\u7684\u5185\u79ef\uff0c\u878d\u5165\u7fa4\u7ec4\u4fe1\u606f\u5b66\u4e60\u54c8\u5e0c\u7801\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCGAH\u548cCGAH - CF\u5728\u4e0d\u540c\u7a00\u758f\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u79bb\u6563\u534f\u540c\u8fc7\u6ee4\u548c\u5185\u5bb9\u611f\u77e5\u63a8\u8350\u65b9\u6cd5\u3002", "conclusion": "CGAH\u65b9\u6cd5\u5728\u7a00\u758f\u573a\u666f\u4e0b\u80fd\u63d0\u9ad8\u5728\u7ebf\u63a8\u8350\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2512.19960", "pdf": "https://arxiv.org/pdf/2512.19960", "abs": "https://arxiv.org/abs/2512.19960", "authors": ["Luciano Araujo Dourado Filho", "Rodrigo Tripodi Calumby"], "title": "FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification", "categories": ["cs.AI"], "comment": null, "summary": "Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \\href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5bf9\u7c7b\u5185\u805a\u7c7b\u5206\u914d\u8fdb\u884c\u5206\u7c7b\u6765\u5b66\u4e60\u7ec6\u7c92\u5ea6\u7279\u5f81\uff0c\u4ee5\u63d0\u5347\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\uff0c\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u8fbeSOTA\u3002", "motivation": "\u7c7b\u5185\u5dee\u5f02\u4f1a\u963b\u788d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5b66\u4e60\uff0c\u5c24\u5176\u662f\u5728\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u4e2d\u7c7b\u6837\u672c\u4e0d\u8db3\u7684\u5e38\u89c1\u573a\u666f\u4e0b\u3002", "method": "\u5bf9\u6bcf\u4e2a\u7c7b\u5355\u72ec\u8fdb\u884c\u805a\u7c7b\uff0c\u53d1\u73b0\u80fd\u7f16\u7801\u56fe\u50cf\u95f4\u6f5c\u5728\u76f8\u4f3c\u5ea6\u7684\u4f2a\u6807\u7b7e\uff0c\u5e76\u7528\u4e8e\u5206\u5c42\u5206\u7c7b\u8fc7\u7a0b\u4ee5\u5b66\u4e60\u66f4\u7ec6\u7c92\u5ea6\u89c6\u89c9\u7279\u5f81\u3002", "result": "\u5728PlantNet300k\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\uff0c\u867d\u90e8\u5206\u7ec4\u4ef6\u672a\u5b8c\u5168\u4f18\u5316\u3002", "conclusion": "\u521d\u6b65\u5b9e\u9a8c\u63ed\u793a\u4e86\u672a\u6765\u5de5\u4f5c\u9700\u53d1\u5c55\u7684\u5173\u952e\u70b9\uff0c\u4ee5\u627e\u5230\u65b9\u6cd5\u6709\u6548\u6027\u7684\u66f4\u591a\u786e\u51ff\u8bc1\u636e\u3002"}}
{"id": "2512.20044", "pdf": "https://arxiv.org/pdf/2512.20044", "abs": "https://arxiv.org/abs/2512.20044", "authors": ["Yingchao Yu", "Pengfei Sun", "Yaochu Jin", "Kuangrong Hao", "Hao Zhang", "Yifeng Zhang", "Wenxuan Pan", "Wei Chen", "Danyal Akarca", "Yuchen Xiao"], "title": "Self-motion as a structural prior for coherent and robust formation of cognitive maps", "categories": ["q-bio.NC", "cs.NE"], "comment": "33 pages, 10 figures, 4 tables", "summary": "Most computational accounts of cognitive maps assume that stability is achieved primarily through sensory anchoring, with self-motion contributing to incremental positional updates only. However, biological spatial representations often remain coherent even when sensory cues degrade or conflict, suggesting that self-motion may play a deeper organizational role. Here, we show that self-motion can act as a structural prior that actively organizes the geometry of learned cognitive maps. We embed a path-integration-based motion prior in a predictive-coding framework, implemented using a capacity-efficient, brain-inspired recurrent mechanism combining spiking dynamics, analog modulation and adaptive thresholds. Across highly aliased, dynamically changing and naturalistic environments, this structural prior consistently stabilizes map formation, improving local topological fidelity, global positional accuracy and next-step prediction under sensory ambiguity. Mechanistic analyses reveal that the motion prior itself encodes geometrically precise trajectories under tight constraints of internal states and generalizes zero-shot to unseen environments, outperforming simpler motion-based constraints. Finally, deployment on a quadrupedal robot demonstrates that motion-derived structural priors enhance online landmark-based navigation under real-world sensory variability. Together, these results reframe self-motion as an organizing scaffold for coherent spatial representations, showing how brain-inspired principles can systematically strengthen spatial intelligence in embodied artificial agents.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u81ea\u8fd0\u52a8\u53ef\u4f5c\u4e3a\u7ed3\u6784\u5148\u9a8c\uff0c\u4e3b\u52a8\u7ec4\u7ec7\u5b66\u4e60\u7684\u8ba4\u77e5\u5730\u56fe\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u80fd\u589e\u5f3a\u5177\u8eab\u667a\u80fd\u4f53\u7684\u7a7a\u95f4\u667a\u80fd\u3002", "motivation": "\u591a\u6570\u8ba1\u7b97\u6a21\u578b\u8ba4\u4e3a\u8ba4\u77e5\u5730\u56fe\u7684\u7a33\u5b9a\u6027\u4e3b\u8981\u901a\u8fc7\u611f\u5b98\u951a\u5b9a\u5b9e\u73b0\uff0c\u800c\u751f\u7269\u5b66\u4e0a\u5373\u4f7f\u611f\u5b98\u7ebf\u7d22\u9000\u5316\u6216\u51b2\u7a81\uff0c\u7a7a\u95f4\u8868\u5f81\u4ecd\u8fde\u8d2f\uff0c\u56e0\u6b64\u63a8\u6d4b\u81ea\u8fd0\u52a8\u53ef\u80fd\u6709\u66f4\u6df1\u5c42\u6b21\u7684\u7ec4\u7ec7\u4f5c\u7528\u3002", "method": "\u5c06\u57fa\u4e8e\u8def\u5f84\u79ef\u5206\u7684\u8fd0\u52a8\u5148\u9a8c\u5d4c\u5165\u9884\u6d4b\u7f16\u7801\u6846\u67b6\uff0c\u91c7\u7528\u7ed3\u5408\u8109\u51b2\u52a8\u529b\u5b66\u3001\u6a21\u62df\u8c03\u5236\u548c\u81ea\u9002\u5e94\u9608\u503c\u7684\u9ad8\u6548\u80fd\u3001\u8111\u542f\u53d1\u5f0f\u5faa\u73af\u673a\u5236\u5b9e\u73b0\u3002", "result": "\u8be5\u7ed3\u6784\u5148\u9a8c\u5728\u591a\u79cd\u73af\u5883\u4e0b\u53ef\u7a33\u5b9a\u5730\u56fe\u5f62\u6210\uff0c\u63d0\u5347\u5c40\u90e8\u62d3\u6251\u4fdd\u771f\u5ea6\u3001\u5168\u5c40\u4f4d\u7f6e\u7cbe\u5ea6\u548c\u5728\u611f\u5b98\u6a21\u7cca\u4e0b\u7684\u4e0b\u4e00\u6b65\u9884\u6d4b\uff0c\u8fd0\u52a8\u5148\u9a8c\u80fd\u7f16\u7801\u7cbe\u786e\u8f68\u8ff9\u5e76\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u73af\u5883\uff0c\u5728\u56db\u8db3\u673a\u5668\u4eba\u4e0a\u7684\u5e94\u7528\u8868\u660e\u5176\u80fd\u589e\u5f3a\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u5bfc\u822a\u80fd\u529b\u3002", "conclusion": "\u81ea\u8fd0\u52a8\u53ef\u4f5c\u4e3a\u8fde\u8d2f\u7a7a\u95f4\u8868\u5f81\u7684\u7ec4\u7ec7\u652f\u67b6\uff0c\u8111\u542f\u53d1\u539f\u5219\u80fd\u7cfb\u7edf\u5730\u589e\u5f3a\u5177\u8eab\u667a\u80fd\u4f53\u7684\u7a7a\u95f4\u667a\u80fd\u3002"}}
{"id": "2512.20518", "pdf": "https://arxiv.org/pdf/2512.20518", "abs": "https://arxiv.org/abs/2512.20518", "authors": ["Yuting Cai", "Ruthav Sadali", "Korok Ray", "Chao Tian"], "title": "Expected Revenue, Risk, and Grid Impact of Bitcoin Mining: A Decision-Theoretic Perspective", "categories": ["cs.CE", "eess.SY"], "comment": null, "summary": "Most current assessments use ex post proxies that miss uncertainty and fail to consistently capture the rapid change in bitcoin mining. We introduce a unified, ex ante statistical model that derives expected return, downside risk, and upside potential profit from the first principles of mining: Each hash is a Bernoulli trial with a Bitcoin block difficulty-based success probability. The model yields closed-form expected revenue per hash-rate unit, risk metrics in different scenarios, and upside-profit probabilities for different fleet sizes. Empirical calibration closely matches previously reported observations, yielding a unified, faithful quantification across hardware, pools, and operating conditions. This foundation enables more reliable analysis of mining impacts and behavior.", "AI": {"tldr": "\u5f53\u524d\u8bc4\u4f30\u6bd4\u7279\u5e01\u6316\u77ff\u6709\u5c40\u9650\uff0c\u5f15\u5165\u7edf\u4e00\u4e8b\u524d\u7edf\u8ba1\u6a21\u578b\uff0c\u80fd\u8fdb\u884c\u6709\u6548\u91cf\u5316\u5e76\u652f\u6301\u53ef\u9760\u5206\u6790", "motivation": "\u5f53\u524d\u8bc4\u4f30\u7528\u4e8b\u540e\u4ee3\u7406\u6307\u6807\uff0c\u5ffd\u7565\u4e0d\u786e\u5b9a\u6027\u4e14\u96be\u6355\u6349\u6bd4\u7279\u5e01\u6316\u77ff\u5feb\u901f\u53d8\u5316", "method": "\u4ece\u6316\u77ff\u539f\u7406\u51fa\u53d1\u6784\u5efa\u7edf\u4e00\u4e8b\u524d\u7edf\u8ba1\u6a21\u578b\uff0c\u6bcf\u4e2a\u54c8\u5e0c\u662f\u57fa\u4e8e\u6bd4\u7279\u5e01\u533a\u5757\u96be\u5ea6\u7684\u4f2f\u52aa\u5229\u8bd5\u9a8c", "result": "\u6a21\u578b\u5f97\u51fa\u6bcf\u54c8\u5e0c\u7387\u5355\u4f4d\u9884\u671f\u6536\u5165\u3001\u4e0d\u540c\u573a\u666f\u98ce\u9669\u6307\u6807\u548c\u4e0d\u540c\u89c4\u6a21\u76c8\u5229\u6982\u7387\uff0c\u7ecf\u9a8c\u6821\u51c6\u4e0e\u5148\u524d\u89c2\u6d4b\u543b\u5408", "conclusion": "\u8be5\u6a21\u578b\u80fd\u5b9e\u73b0\u7edf\u4e00\u91cf\u5316\uff0c\u53ef\u652f\u6301\u66f4\u53ef\u9760\u7684\u6316\u77ff\u5f71\u54cd\u548c\u884c\u4e3a\u5206\u6790"}}
{"id": "2512.19718", "pdf": "https://arxiv.org/pdf/2512.19718", "abs": "https://arxiv.org/abs/2512.19718", "authors": ["Vasileios C. Pezoulas", "Nikolaos S. Tachos", "Eleni Georga", "Kostas Marias", "Manolis Tsiknakis", "Dimitrios I. Fotiadis"], "title": "Synthetic Data Blueprint (SDB): A modular framework for the statistical, structural, and graph-based evaluation of synthetic tabular data", "categories": ["cs.LG"], "comment": "25 pages main body, 28 pages Appendix, 4 Figures, 4 Tables", "summary": "In the rapidly evolving era of Artificial Intelligence (AI), synthetic data are widely used to accelerate innovation while preserving privacy and enabling broader data accessibility. However, the evaluation of synthetic data remains fragmented across heterogeneous metrics, ad-hoc scripts, and incomplete reporting practices. To address this gap, we introduce Synthetic Data Blueprint (SDB), a modular Pythonic based library to quantitatively and visually assess the fidelity of synthetic tabular data. SDB supports: (i) automated feature-type detection, (ii) distributional and dependency-level fidelity metrics, (iii) graph- and embedding-based structure preservation scores, and (iv) a rich suite of data visualization schemas. To demonstrate the breadth, robustness, and domain-agnostic applicability of the SDB, we evaluated the framework across three real-world use cases that differ substantially in scale, feature composition, statistical complexity, and downstream analytical requirements. These include: (i) healthcare diagnostics, (ii) socioeconomic and financial modelling, and (iii) cybersecurity and network traffic analysis. These use cases reveal how SDB can address diverse data fidelity assessment challenges, varying from mixed-type clinical variables to high-cardinality categorical attributes and high-dimensional telemetry signals, while at the same time offering a consistent, transparent, and reproducible benchmarking across heterogeneous domains.", "AI": {"tldr": "\u5728\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\uff0c\u5408\u6210\u6570\u636e\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u8bc4\u4f30\u65b9\u6cd5\u96f6\u6563\u3002\u672c\u6587\u4ecb\u7ecdSDB\u5e93\u7528\u4e8e\u8bc4\u4f30\u5408\u6210\u8868\u683c\u6570\u636e\u4fdd\u771f\u5ea6\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u7528\u4f8b\u5c55\u793a\u5176\u9002\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u5408\u6210\u6570\u636e\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u788e\u7247\u5316\u3001\u811a\u672c\u968f\u610f\u548c\u62a5\u544a\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u9700\u8981\u7edf\u4e00\u5de5\u5177\u8fdb\u884c\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u6a21\u5757\u5316Python\u5e93SDB\uff0c\u652f\u6301\u81ea\u52a8\u5316\u7279\u5f81\u7c7b\u578b\u68c0\u6d4b\u3001\u591a\u79cd\u4fdd\u771f\u5ea6\u6307\u6807\u548c\u53ef\u89c6\u5316\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u5b9e\u9645\u7528\u4f8b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7528\u4f8b\u663e\u793aSDB\u80fd\u5e94\u5bf9\u4e0d\u540c\u7684\u6570\u636e\u4fdd\u771f\u5ea6\u8bc4\u4f30\u6311\u6218\uff0c\u5728\u4e0d\u540c\u9886\u57df\u63d0\u4f9b\u4e00\u81f4\u3001\u900f\u660e\u548c\u53ef\u91cd\u590d\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "SDB\u53ef\u6709\u6548\u89e3\u51b3\u5408\u6210\u6570\u636e\u8bc4\u4f30\u95ee\u9898\uff0c\u5728\u4e0d\u540c\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002"}}
{"id": "2512.20083", "pdf": "https://arxiv.org/pdf/2512.20083", "abs": "https://arxiv.org/abs/2512.20083", "authors": ["Wenzhao Wu", "Yahui Tang", "Mingfei Cheng", "Wenbing Tang", "Yuan Zhou", "Yang Liu"], "title": "Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing", "categories": ["cs.SE", "cs.RO"], "comment": null, "summary": "As embodied agents advance toward real-world deployment, ensuring optimal decisions becomes critical for resource-constrained applications. Current evaluation methods focus primarily on functional correctness, overlooking the non-functional optimality of generated plans. This gap can lead to significant performance degradation and resource waste. We identify and formalize the problem of Non-optimal Decisions (NoDs), where agents complete tasks successfully but inefficiently. We present NoD-DGMT, a systematic framework for detecting NoDs in embodied agent task planning via diversity-guided metamorphic testing. Our key insight is that optimal planners should exhibit invariant behavioral properties under specific transformations. We design four novel metamorphic relations capturing fundamental optimality properties: position detour suboptimality, action optimality completeness, condition refinement monotonicity, and scene perturbation invariance. To maximize detection efficiency, we introduce a diversity-guided selection strategy that actively selects test cases exploring different violation categories, avoiding redundant evaluations while ensuring comprehensive diversity coverage. Extensive experiments on the AI2-THOR simulator with four state-of-the-art planning models demonstrate that NoD-DGMT achieves violation detection rates of 31.9% on average, with our diversity-guided filter improving rates by 4.3% and diversity scores by 3.3 on average. NoD-DGMT significantly outperforms six baseline methods, with 16.8% relative improvement over the best baseline, and demonstrates consistent superiority across different model architectures and task complexities.", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u5177\u8eab\u667a\u80fd\u4f53\u51b3\u7b56\u975e\u6700\u4f18\u95ee\u9898\uff0c\u63d0\u51faNoD - DGMT\u6846\u67b6\u68c0\u6d4b\u975e\u6700\u4f18\u51b3\u7b56\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u68c0\u6d4b\u6548\u679c\u597d\uff0c\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u89c6\u751f\u6210\u8ba1\u5212\u7684\u975e\u529f\u80fd\u6700\u4f18\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u8d44\u6e90\u6d6a\u8d39\uff0c\u9700\u89e3\u51b3\u975e\u6700\u4f18\u51b3\u7b56\u95ee\u9898\u3002", "method": "\u63d0\u51faNoD - DGMT\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6837\u6027\u5f15\u5bfc\u7684\u53d8\u8d28\u6d4b\u8bd5\u68c0\u6d4b\u975e\u6700\u4f18\u51b3\u7b56\uff0c\u8bbe\u8ba1\u56db\u4e2a\u65b0\u7684\u53d8\u8d28\u5173\u7cfb\uff0c\u5f15\u5165\u591a\u6837\u6027\u5f15\u5bfc\u9009\u62e9\u7b56\u7565\u3002", "result": "\u5728AI2 - THOR\u6a21\u62df\u5668\u4e0a\u5b9e\u9a8c\uff0cNoD - DGMT\u5e73\u5747\u8fdd\u89c4\u68c0\u6d4b\u738731.9%\uff0c\u591a\u6837\u6027\u5f15\u5bfc\u8fc7\u6ee4\u5668\u4f7f\u68c0\u6d4b\u7387\u63d0\u9ad84.3%\u3001\u591a\u6837\u6027\u5f97\u5206\u63d0\u9ad83.3\uff0c\u663e\u8457\u4f18\u4e8e\u516d\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "NoD - DGMT\u80fd\u6709\u6548\u68c0\u6d4b\u5177\u8eab\u667a\u80fd\u4f53\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u975e\u6700\u4f18\u51b3\u7b56\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u4e0b\u8868\u73b0\u4e00\u81f4\u4f18\u8d8a\u3002"}}
{"id": "2512.20064", "pdf": "https://arxiv.org/pdf/2512.20064", "abs": "https://arxiv.org/abs/2512.20064", "authors": ["Yaojian Chen", "Si-Qiu Gong", "Lin Gan", "Yanfei Liu", "An Yang", "Yinuo Wang", "Chao-yang Lu", "Guangwen Yang"], "title": "FastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling", "categories": ["cs.DC"], "comment": "12 pages, 13 figures", "summary": "Matrix Product State (MPS) is a versatile tensor network representation widely applied in quantum physics, quantum chemistry, and machine learning, etc. MPS sampling serves as a critical fundamental operation in these fields. As the problems become more complex, the scale of MPS is rapidly increasing. Traditional data parallelism is limited by memory and heavy I/O in large-scale MPS. Model parallelism that can handle large-scale MPS imposes rigid process bindings and lacks scalability. This work proposes Fast-MPS, a multi-level parallel framework for scalable MPS sampling. Our design combines data parallelism across samples with tensor parallelism along bond dimensions. We eliminate memory and I/O pressure through compression and overlapping, and revive data parallel in large-scale MPS sampling. We evaluate our approach on Gaussian Boson Sampling, a representative and demanding application. Fast-MPS achieves over 10x speedup compared to existing simulators, scales to thousands of processes, and enables simulations with 8,176 sites and bond dimension chi = 10^4, significantly outperforming the state of the art. Fast-MPS has demonstrated great potential in high-performance tensor network applications.", "AI": {"tldr": "\u63d0\u51faFast - MPS\u591a\u7ea7\u522b\u5e76\u884c\u6846\u67b6\u7528\u4e8e\u53ef\u6269\u5c55MPS\u91c7\u6837\uff0c\u5728\u9ad8\u65af\u73bb\u8272\u91c7\u6837\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6709\u9ad8\u6027\u80fd\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u5e76\u884c\u5728\u5927\u89c4\u6a21MPS\u4e2d\u6709\u5185\u5b58\u548cI/O\u9650\u5236\uff0c\u6a21\u578b\u5e76\u884c\u6709\u8fdb\u7a0b\u7ed1\u5b9a\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u6837\u672c\u95f4\u7684\u6570\u636e\u5e76\u884c\u548c\u6cbf\u952e\u7ef4\u5ea6\u7684\u5f20\u91cf\u5e76\u884c\uff0c\u901a\u8fc7\u538b\u7f29\u548c\u91cd\u53e0\u6d88\u9664\u5185\u5b58\u548cI/O\u538b\u529b\u3002", "result": "\u5728\u9ad8\u65af\u73bb\u8272\u91c7\u6837\u4e2d\u6bd4\u73b0\u6709\u6a21\u62df\u5668\u63d0\u901f\u8d8510\u500d\uff0c\u53ef\u6269\u5c55\u5230\u6570\u5343\u4e2a\u8fdb\u7a0b\uff0c\u80fd\u6a21\u62df8176\u4e2a\u4f4d\u70b9\u548c\u952e\u7ef4\u5ea6chi = 10^4\u7684\u60c5\u51b5\u3002", "conclusion": "Fast - MPS\u5728\u9ad8\u6027\u80fd\u5f20\u91cf\u7f51\u7edc\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.20458", "pdf": "https://arxiv.org/pdf/2512.20458", "abs": "https://arxiv.org/abs/2512.20458", "authors": ["Shuting Wang", "Qiaolin Xia", "Hao Wang", "Yu Lu", "Bobsimons", "Zhicheng Dou"], "title": "Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register", "categories": ["cs.IR"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs) have enabled agentic search systems that interleave multi-step reasoning with external tool use. However, existing frameworks largely rely on unstructured natural-language reasoning and accumulate raw intermediate traces in the context, which often leads to unstable reasoning trajectories, context overflow, and degraded performance on complex multi-hop queries. In this study, we introduce Laser, a general framework for stabilizing and scaling agentic search. Laser defines a symbolic action protocol that organizes agent behaviors into three spaces: planning, task-solving, and retrospection. Each action is specified with explicit semantics and a deterministic execution format, enabling structured and logical reasoning processes and reliable action parsing. This design makes intermediate decisions interpretable and traceable, enhancing explicit retrospection and fine-grained control over reasoning trajectories. In coordination with parsable actions, Laser further maintains a compact context register that stores only essential states of the reasoning process, allowing the agent to reason over long horizons without uncontrolled context expansion. Experiments on Qwen2.5/3-series models across challenging multi-hop QA datasets show that Laser consistently outperforms existing agentic search baselines under both prompting-only and fine-tuning settings, demonstrating that Laser provides a principled and effective foundation for robust, scalable agentic search.", "AI": {"tldr": "\u73b0\u6709\u667a\u80fd\u4f53\u641c\u7d22\u6846\u67b6\u6709\u7f3a\u9677\uff0c\u672c\u6587\u63d0\u51faLaser\u6846\u67b6\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u641c\u7d22\u6846\u67b6\u5b58\u5728\u63a8\u7406\u8f68\u8ff9\u4e0d\u7a33\u5b9a\u3001\u4e0a\u4e0b\u6587\u6ea2\u51fa\u548c\u590d\u6742\u67e5\u8be2\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u5f15\u5165Laser\u6846\u67b6\uff0c\u5b9a\u4e49\u7b26\u53f7\u52a8\u4f5c\u534f\u8bae\uff0c\u5c06\u667a\u80fd\u4f53\u884c\u4e3a\u5206\u4e3a\u4e09\u4e2a\u7a7a\u95f4\uff0c\u8bbe\u7f6e\u660e\u786e\u8bed\u4e49\u548c\u6267\u884c\u683c\u5f0f\uff0c\u7ef4\u62a4\u7d27\u51d1\u4e0a\u4e0b\u6587\u5bc4\u5b58\u5668\u3002", "result": "\u5728Qwen2.5/3\u7cfb\u5217\u6a21\u578b\u7684\u591a\u8df3\u95ee\u7b54\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cLaser\u5728\u63d0\u793a\u548c\u5fae\u8c03\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "Laser\u4e3a\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u641c\u7d22\u63d0\u4f9b\u4e86\u6709\u6548\u57fa\u7840\u3002"}}
{"id": "2512.19992", "pdf": "https://arxiv.org/pdf/2512.19992", "abs": "https://arxiv.org/abs/2512.19992", "authors": ["Zhe Sun", "Xueyuan Yang", "Yujie Lu", "Zhenliang Zhang"], "title": "S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test", "categories": ["cs.AI", "cs.CY"], "comment": "10 pages, 9 figures", "summary": "The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.", "AI": {"tldr": "\u63d0\u51faS$^{3}$IT\u57fa\u51c6\u8bc4\u4f30\u5177\u8eab\u793e\u4f1a\u667a\u80fd\uff0c\u7528\u5ea7\u4f4d\u6392\u5e8f\u4efb\u52a1\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u7a7a\u95f4\u667a\u80fd\u7f3a\u9677\u4f46\u80fd\u5904\u7406\u6709\u660e\u786e\u6587\u672c\u7ebf\u7d22\u7684\u51b2\u7a81\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65e0\u6cd5\u89e3\u51b3\u5177\u8eab\u667a\u80fd\u4f53\u5728\u4eba\u7c7b\u73af\u5883\u4e2d\u5bf9\u793e\u4f1a\u89c4\u8303\u548c\u7269\u7406\u7ea6\u675f\u7684\u96c6\u6210\u8bc4\u4f30\u95ee\u9898\u3002", "method": "\u5f15\u5165S$^{3}$IT\u57fa\u51c6\uff0c\u56f4\u7ed5\u5ea7\u4f4d\u6392\u5e8f\u4efb\u52a1\uff0c\u751f\u6210\u591a\u6837\u5316\u573a\u666f\uff0c\u8ba9\u667a\u80fd\u4f53\u901a\u8fc7\u5bf9\u8bdd\u83b7\u53d6\u504f\u597d\u3001\u81ea\u4e3b\u63a2\u7d22\u73af\u5883\u5e76\u8fdb\u884c\u591a\u76ee\u6807\u4f18\u5316\u3002", "result": "\u8bc4\u4f30\u53d1\u73b0\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u96be\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u4e0e\u4eba\u7c7b\u57fa\u7ebf\u6709\u660e\u663e\u5dee\u8ddd\uff0c\u5728\u7a7a\u95f4\u667a\u80fd\u4e0a\u6709\u7f3a\u9677\uff0c\u4f46\u80fd\u5728\u6709\u660e\u786e\u6587\u672c\u7ebf\u7d22\u7684\u51b2\u7a81\u89e3\u51b3\u4e0a\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u793e\u4f1a\u667a\u80fd\u7684\u7a7a\u95f4\u667a\u80fd\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2512.20464", "pdf": "https://arxiv.org/pdf/2512.20464", "abs": "https://arxiv.org/abs/2512.20464", "authors": ["Cagatay Isil", "Alexander Chen", "Yuhang Li", "F. Onuralp Ardic", "Shiqi Chen", "Che-Yung Shen", "Aydogan Ozcan"], "title": "Snapshot 3D image projection using a diffractive decoder", "categories": ["physics.optics", "cs.CV", "cs.NE", "physics.app-ph"], "comment": "22 Pages, 8 Figures", "summary": "3D image display is essential for next-generation volumetric imaging; however, dense depth multiplexing for 3D image projection remains challenging because diffraction-induced cross-talk rapidly increases as the axial image planes get closer. Here, we introduce a 3D display system comprising a digital encoder and a diffractive optical decoder, which simultaneously projects different images onto multiple target axial planes with high axial resolution. By leveraging multi-layer diffractive wavefront decoding and deep learning-based end-to-end optimization, the system achieves high-fidelity depth-resolved 3D image projection in a snapshot, enabling axial plane separations on the order of a wavelength. The digital encoder leverages a Fourier encoder network to capture multi-scale spatial and frequency-domain features from input images, integrates axial position encoding, and generates a unified phase representation that simultaneously encodes all images to be axially projected in a single snapshot through a jointly-optimized diffractive decoder. We characterized the impact of diffractive decoder depth, output diffraction efficiency, spatial light modulator resolution, and axial encoding density, revealing trade-offs that govern axial separation and 3D image projection quality. We further demonstrated the capability to display volumetric images containing 28 axial slices, as well as the ability to dynamically reconfigure the axial locations of the image planes, performed on demand. Finally, we experimentally validated the presented approach, demonstrating close agreement between the measured results and the target images. These results establish the diffractive 3D display system as a compact and scalable framework for depth-resolved snapshot 3D image projection, with potential applications in holographic displays, AR/VR interfaces, and volumetric optical computing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u6570\u5b57\u7f16\u7801\u5668\u548c\u884d\u5c04\u5149\u5b66\u89e3\u7801\u5668\u76843D\u663e\u793a\u7cfb\u7edf\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6df1\u5ea6\u5206\u8fa83D\u56fe\u50cf\u6295\u5f71\uff0c\u4ee5\u89e3\u51b33D\u56fe\u50cf\u6295\u5f71\u4e2d\u6df1\u5ea6\u590d\u7528\u7684\u6311\u6218\uff0c\u5e76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u53ca\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b33D\u56fe\u50cf\u6295\u5f71\u4e2d\u5bc6\u5ea6\u6df1\u5ea6\u590d\u7528\u96be\u9898\uff0c\u5373\u884d\u5c04\u5f15\u8d77\u7684\u4e32\u6270\u968f\u8f74\u5411\u56fe\u50cf\u5e73\u9762\u9760\u8fd1\u800c\u589e\u52a0\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u591a\u5c42\u884d\u5c04\u6ce2\u524d\u89e3\u7801\u548c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u6570\u5b57\u7f16\u7801\u5668\u5229\u7528\u5085\u91cc\u53f6\u7f16\u7801\u5668\u7f51\u7edc\uff0c\u7ed3\u5408\u8f74\u5411\u4f4d\u7f6e\u7f16\u7801\uff0c\u751f\u6210\u7edf\u4e00\u76f8\u4f4d\u8868\u793a\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7684\u884d\u5c04\u89e3\u7801\u5668\u5b9e\u73b0\u6295\u5f71\u3002", "result": "\u8868\u5f81\u4e86\u884d\u5c04\u89e3\u7801\u5668\u6df1\u5ea6\u7b49\u56e0\u7d20\u5bf9\u8f74\u5411\u5206\u79bb\u548c3D\u56fe\u50cf\u6295\u5f71\u8d28\u91cf\u7684\u5f71\u54cd\uff1b\u5c55\u793a\u663e\u793a28\u4e2a\u8f74\u5411\u5207\u7247\u7684\u4f53\u79ef\u56fe\u50cf\u53ca\u52a8\u6001\u91cd\u65b0\u914d\u7f6e\u56fe\u50cf\u5e73\u9762\u8f74\u5411\u4f4d\u7f6e\u7684\u80fd\u529b\uff1b\u5b9e\u9a8c\u9a8c\u8bc1\u6d4b\u91cf\u7ed3\u679c\u4e0e\u76ee\u6807\u56fe\u50cf\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8be5\u884d\u5c043D\u663e\u793a\u7cfb\u7edf\u662f\u7528\u4e8e\u6df1\u5ea6\u5206\u8fa8\u5feb\u71673D\u56fe\u50cf\u6295\u5f71\u7684\u7d27\u51d1\u4e14\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u5728\u5168\u606f\u663e\u793a\u7b49\u9886\u57df\u6709\u6f5c\u5728\u5e94\u7528\u3002"}}
{"id": "2512.19484", "pdf": "https://arxiv.org/pdf/2512.19484", "abs": "https://arxiv.org/abs/2512.19484", "authors": ["Gang Li", "Dandan Qiao", "Mingxuan Zheng"], "title": "Structured Event Representation and Stock Return Predictability", "categories": ["econ.GN", "cs.CE", "stat.ML"], "comment": null, "summary": "We find that event features extracted by large language models (LLMs) are effective for text-based stock return prediction. Using a pre-trained LLM to extract event features from news articles, we propose a novel deep learning model based on structured event representation (SER) and attention mechanisms to predict stock returns in the cross-section. Our SER-based model provides superior performance compared with other existing text-driven models to forecast stock returns out of sample and offers highly interpretable feature structures to examine the mechanisms underlying the stock return predictability. We further provide various implications based on SER and highlight the crucial benefit of structured model inputs in stock return predictability.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u7684\u4e8b\u4ef6\u7279\u5f81\u5bf9\u57fa\u4e8e\u6587\u672c\u7684\u80a1\u7968\u6536\u76ca\u9884\u6d4b\u6709\u6548\uff0c\u63d0\u51fa\u57fa\u4e8e\u7ed3\u6784\u5316\u4e8b\u4ef6\u8868\u793a\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6a21\u578b\uff0c\u6027\u80fd\u4f18\u4e14\u53ef\u89e3\u91ca\u6027\u5f3a\u3002", "motivation": "\u63a2\u7d22\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u7684\u4e8b\u4ef6\u7279\u5f81\u8fdb\u884c\u80a1\u7968\u6536\u76ca\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u65b0\u95fb\u6587\u7ae0\u4e2d\u63d0\u53d6\u4e8b\u4ef6\u7279\u5f81\uff0c\u63d0\u51fa\u57fa\u4e8e\u7ed3\u6784\u5316\u4e8b\u4ef6\u8868\u793a\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u57fa\u4e8eSER\u7684\u6a21\u578b\u5728\u6837\u672c\u5916\u9884\u6d4b\u80a1\u7968\u6536\u76ca\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u6587\u672c\u9a71\u52a8\u6a21\u578b\uff0c\u4e14\u5177\u6709\u9ad8\u5ea6\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u7ed3\u6784\u3002", "conclusion": "\u5f3a\u8c03\u7ed3\u6784\u5316\u6a21\u578b\u8f93\u5165\u5bf9\u80a1\u7968\u6536\u76ca\u9884\u6d4b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u7ed9\u51fa\u76f8\u5173\u542f\u793a\u3002"}}
{"id": "2512.19719", "pdf": "https://arxiv.org/pdf/2512.19719", "abs": "https://arxiv.org/abs/2512.19719", "authors": ["Zihao Lv", "Siqi Ai", "Yanbin Zhang"], "title": "Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Targeted maintenance strategies, ensuring the dependability and safety of industrial machinery. However, current modeling techniques for assessing both local and global correlation of battery degradation sequences are inefficient and difficult to meet the needs in real-life applications. For this reason, we propose a novel deep learning architecture, multiscale dual-path feature aggregation network (MDFA-Net), for RUL prediction. MDFA-Net consists of dual-path networks, the first path network, multiscale feature network (MF-Net) that maintains the shallow information and avoids missing information, and the second path network is an encoder network (EC-Net) that captures the continuous trend of the sequences and retains deep details. Integrating both deep and shallow attributes effectively grasps both local and global patterns. Testing conducted with two publicly available Lithium-ion battery datasets reveals our approach surpasses existing top-tier methods in RUL forecasting, accurately mapping the capacity degradation trajectory.", "AI": {"tldr": "\u63d0\u51fa\u591a\u5c3a\u5ea6\u53cc\u8def\u5f84\u7279\u5f81\u805a\u5408\u7f51\u7edcMDFA - Net\u8fdb\u884c\u7535\u6c60\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u9884\u6d4b\uff0c\u6d4b\u8bd5\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u7535\u6c60\u9000\u5316\u5e8f\u5217\u5c40\u90e8\u548c\u5168\u5c40\u76f8\u5173\u6027\u7684\u5efa\u6a21\u6280\u672f\u6548\u7387\u4f4e\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002", "method": "\u63d0\u51faMDFA - Net\uff0c\u5305\u542b\u4fdd\u6301\u6d45\u5c42\u4fe1\u606f\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u7f51\u7edcMF - Net\u548c\u6355\u6349\u5e8f\u5217\u8fde\u7eed\u8d8b\u52bf\u3001\u4fdd\u7559\u6df1\u5ea6\u7ec6\u8282\u7684\u7f16\u7801\u5668\u7f51\u7edcEC - Net\uff0c\u6574\u5408\u6df1\u6d45\u5c42\u5c5e\u6027\u3002", "result": "\u4f7f\u7528\u4e24\u4e2a\u516c\u5f00\u9502\u79bb\u5b50\u7535\u6c60\u6570\u636e\u96c6\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u5728RUL\u9884\u6d4b\u4e0a\u8d85\u8d8a\u73b0\u6709\u9876\u7ea7\u65b9\u6cd5\uff0c\u80fd\u51c6\u786e\u6620\u5c04\u5bb9\u91cf\u9000\u5316\u8f68\u8ff9\u3002", "conclusion": "MDFA - Net\u5728\u7535\u6c60RUL\u9884\u6d4b\u65b9\u9762\u6709\u6548\u4e14\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2512.20305", "pdf": "https://arxiv.org/pdf/2512.20305", "abs": "https://arxiv.org/abs/2512.20305", "authors": ["Mebin Jose", "Jisha Francis", "Sudheesh Kumar Kattumannil"], "title": "KAN-AFT: An Interpretable Nonlinear Survival Model Integrating Kolmogorov-Arnold Networks with Accelerated Failure Time Analysis", "categories": ["stat.ML", "cs.LG"], "comment": "A new development in Survival Analysis based on the celebrated Kolmogorov-Arnold Networks (KANs)", "summary": "Survival analysis relies fundamentally on the semi-parametric Cox Proportional Hazards (CoxPH) model and the parametric Accelerated Failure Time (AFT) model. CoxPH assumes constant hazard ratios, often failing to capture real-world dynamics, while traditional AFT models are limited by rigid distributional assumptions. Although deep learning models like DeepAFT address these constraints by improving predictive accuracy and handling censoring, they inherit the significant challenge of black-box interpretability. The recent introduction of CoxKAN demonstrated the successful integration of Kolmogorov-Arnold Networks (KANs), a novel architecture that yields highly accurate and interpretable symbolic representations, within the CoxPH framework. Motivated by the interpretability gains of CoxKAN, we introduce KAN-AFT (Kolmogorov Arnold Network-based AFT), the first framework to apply KANs to the AFT model. KAN-AFT effectively models complex nonlinear relationships within the AFT framework. Our primary contributions include: (i) a principled AFT-KAN formulation, (ii) robust optimization strategies for right-censored observations (e.g., Buckley-James and IPCW), and (iii) an interpretability pipeline that converts the learned spline functions into closed-form symbolic equations for survival time. Empirical results on multiple datasets confirm that KAN-AFT achieves performance comparable to or better than DeepAFT, while uniquely providing transparent, symbolic models of the survival process.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165KAN - AFT\u6846\u67b6\u5c06KANs\u5e94\u7528\u4e8eAFT\u6a21\u578b\uff0c\u6709\u516c\u5f0f\u3001\u4f18\u5316\u7b56\u7565\u548c\u53ef\u89e3\u91ca\u6027\u6d41\u7a0b\uff0c\u5b9e\u8bc1\u8868\u660e\u5176\u6027\u80fd\u4f73\u4e14\u6709\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "CoxPH\u548c\u4f20\u7edfAFT\u6a21\u578b\u6709\u5c40\u9650\uff0cDeepAFT\u6709\u9ed1\u7bb1\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0cCoxKAN\u6709\u53ef\u89e3\u91ca\u6027\u4f18\u52bf\uff0c\u53d7\u5176\u542f\u53d1\u63d0\u51faKAN - AFT\u3002", "method": "\u63d0\u51faAFT - KAN\u516c\u5f0f\uff0c\u9488\u5bf9\u53f3\u5220\u5931\u89c2\u6d4b\u91c7\u7528\u9c81\u68d2\u4f18\u5316\u7b56\u7565\uff0c\u6784\u5efa\u53ef\u89e3\u91ca\u6027\u6d41\u7a0b\u5c06\u6837\u6761\u51fd\u6570\u8f6c\u6362\u4e3a\u751f\u5b58\u65f6\u95f4\u7684\u95ed\u5f0f\u7b26\u53f7\u65b9\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cKAN - AFT\u6027\u80fd\u4e0eDeepAFT\u76f8\u5f53\u6216\u66f4\u597d\u3002", "conclusion": "KAN - AFT\u80fd\u6709\u6548\u5efa\u6a21\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u5728\u6027\u80fd\u826f\u597d\u7684\u540c\u65f6\uff0c\u80fd\u4e3a\u751f\u5b58\u8fc7\u7a0b\u63d0\u4f9b\u900f\u660e\u7684\u7b26\u53f7\u6a21\u578b\u3002"}}
{"id": "2512.20159", "pdf": "https://arxiv.org/pdf/2512.20159", "abs": "https://arxiv.org/abs/2512.20159", "authors": ["Ruiqi Wang", "Xinchen Wang", "Cuiyun Gao", "Chun Yong Chong", "Xin Xia", "Qing Liao"], "title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been increasingly deployed in real-world software engineering, fostering the development of code evaluation metrics to study the quality of LLM-generated code. Conventional rule-based metrics merely score programs based on their surface-level similarities with reference programs instead of analyzing functionality and code quality in depth. To address this limitation, researchers have developed LLM-as-a-judge metrics, prompting LLMs to evaluate and score code, and curated various code evaluation benchmarks to validate their effectiveness. However, these benchmarks suffer from critical limitations, hindering reliable assessments of evaluation capability: Some feature coarse-grained binary labels, which reduce rich code behavior to a single bit of information, obscuring subtle errors. Others propose fine-grained but subjective, vaguely-defined evaluation criteria, introducing unreliability in manually-annotated scores, which is the ground-truth they rely on. Furthermore, they often use uncontrolled data synthesis methods, leading to unbalanced score distributions that poorly represent real-world code generation scenarios.\n  To curate a diverse benchmark with programs of well-balanced distributions across various quality levels and streamline the manual annotation procedure, we propose AXIOM, a novel perturbation-based framework for synthesizing code evaluation benchmarks at scale. It reframes program scores as the refinement effort needed for deployment, consisting of two stages: (1) Rule-guided perturbation, which prompts LLMs to apply sequences of predefined perturbation rules to existing high-quality programs to modify their functionality and code quality, enabling us to precisely control each program's target score to achieve balanced score distributions. (2) Multisource quality calibration, which first selects a subset of...", "AI": {"tldr": "\u4f20\u7edf\u4ee3\u7801\u8bc4\u4f30\u6307\u6807\u6709\u5c40\u9650\uff0c\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u95ee\u9898\uff0c\u63d0\u51faAXIOM\u6846\u67b6\u5408\u6210\u4ee3\u7801\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u4f20\u7edf\u89c4\u5219\u6307\u6807\u4e0d\u80fd\u6df1\u5ea6\u5206\u6790\u4ee3\u7801\uff0c\u73b0\u6709\u4ee3\u7801\u8bc4\u4f30\u57fa\u51c6\u6709\u7f3a\u9677\uff0c\u9700\u65b0\u57fa\u51c6\u3002", "method": "\u63d0\u51faAXIOM\u6846\u67b6\uff0c\u542b\u89c4\u5219\u5f15\u5bfc\u6270\u52a8\u548c\u591a\u6e90\u8d28\u91cf\u6821\u51c6\u4e24\u9636\u6bb5\u3002", "result": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u679c\u3002", "conclusion": "\u672a\u63d0\u53ca\u660e\u786e\u7ed3\u8bba\u3002"}}
{"id": "2512.20163", "pdf": "https://arxiv.org/pdf/2512.20163", "abs": "https://arxiv.org/abs/2512.20163", "authors": ["Leszek G\u0105sieniec", "Tytus Grodzicki", "Tomasz Jurdzi\u0144ski", "Jakub Kowalski", "Grzegorz Stachowiak"], "title": "Population Protocols Revisited: Parity and Beyond", "categories": ["cs.DC"], "comment": null, "summary": "For nearly two decades, population protocols have been extensively studied, yielding efficient solutions for central problems in distributed computing, including leader election, and majority computation, a predicate type in Presburger Arithmetic closely tied to population protocols. Surprisingly, no protocols have achieved both time- and space-efficiency for congruency predicates, such as parity computation, which are complementary in this arithmetic framework. This gap highlights a significant challenge in the field. To address this gap, we explore the parity problem, where agents are tasked with computing the parity of the given sub-population size. Then we extend the solution for parity to compute congruences modulo an arbitrary $m$.\n  Previous research on efficient population protocols has focused on protocols that minimise both stabilisation time and state utilisation for specific problems. In contrast, this work slightly relaxes this expectation, permitting protocols to place less emphasis on full optimisation and more on universality, robustness, and probabilistic guarantees. This allows us to propose a novel computing paradigm that integrates population weights (or simply weights), a robust clocking mechanism, and efficient anomaly detection coupled with a switching mechanism (which ensures slow but always correct solutions). This paradigm facilitates universal design of efficient multistage stable population protocols. Specifically, the first efficient parity and congruence protocols introduced here use both $O(\\log^3 n)$ states and achieve silent stabilisation in $O(\\log^3 n)$ time. We conclude by discussing the impact of implicit conversion between unary and binary representations enabled by the weight system, with applications to other problems, including the computation and representation of (sub-)population sizes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2512.20612", "pdf": "https://arxiv.org/pdf/2512.20612", "abs": "https://arxiv.org/abs/2512.20612", "authors": ["Yibin Lei", "Shwai He", "Ang Li", "Andrew Yates"], "title": "Making Large Language Models Efficient Dense Retrievers", "categories": ["cs.IR", "cs.CL"], "comment": null, "summary": "Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.", "AI": {"tldr": "\u5206\u6790\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bc6\u96c6\u68c0\u7d22\u5668\u5c42\u5197\u4f59\uff0c\u63d0\u51faEffiR\u6846\u67b6\uff0c\u53ef\u5728\u4fdd\u7559\u6027\u80fd\u4e0b\u51cf\u5c0f\u6a21\u578b\u5927\u5c0f\u548c\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u76f4\u63a5\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u5bc6\u96c6\u68c0\u7d22\u8ba1\u7b97\u6548\u7387\u4f4e\uff0c\u4e0d\u786e\u5b9a\u68c0\u7d22\u4efb\u52a1\u4e2d\u662f\u5426\u5b58\u5728\u5c42\u5197\u4f59\u3002", "method": "\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bc6\u96c6\u68c0\u7d22\u5668\u8fdb\u884c\u5c42\u5197\u4f59\u5206\u6790\uff0c\u63d0\u51faEffiR\u6846\u67b6\uff0c\u901a\u8fc7\u7c97\u5230\u7ec6\u7b56\u7565\u8fdb\u884c\u5927\u89c4\u6a21MLP\u538b\u7f29\u5e76\u7ed3\u5408\u7279\u5b9a\u5fae\u8c03\u3002", "result": "\u5728\u4e0d\u540cBEIR\u6570\u636e\u96c6\u548c\u5927\u8bed\u8a00\u6a21\u578b\u9aa8\u5e72\u4e0a\uff0cEffiR\u80fd\u5927\u5e45\u51cf\u5c0f\u6a21\u578b\u5927\u5c0f\u548c\u63a8\u7406\u6210\u672c\uff0c\u4fdd\u7559\u5168\u5c3a\u5bf8\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "EffiR\u6846\u67b6\u80fd\u6709\u6548\u63d0\u9ad8\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bc6\u96c6\u68c0\u7d22\u5668\u6548\u7387\u3002"}}
{"id": "2512.20043", "pdf": "https://arxiv.org/pdf/2512.20043", "abs": "https://arxiv.org/abs/2512.20043", "authors": ["Jung Yeon Park", "Yuxuan Chen", "Floor Eijkelboom", "Jan-Willem van de Meent", "Lawson L. S. Wong", "Robin Walters"], "title": "Discovering Lie Groups with Flow Matching", "categories": ["cs.AI"], "comment": null, "summary": "Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \\lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u674e\u7fa4\u4e0a\u7684\u6d41\u5339\u914d\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5bf9\u79f0\u6027\u7684\u65b9\u6cd5LieFlow\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u53ef\u53d1\u73b0\u79bb\u6563\u7fa4\uff0c\u8fd8\u89e3\u51b3\u4e86\u201c\u6700\u540e\u65f6\u523b\u6536\u655b\u201d\u95ee\u9898\u5e76\u5f15\u5165\u65b0\u63d2\u503c\u65b9\u6848\u3002", "motivation": "\u5bf9\u79f0\u6027\u5bf9\u7406\u89e3\u7269\u7406\u7cfb\u7edf\u548c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u4ece\u6570\u636e\u4e2d\u4e86\u89e3\u6f5c\u5728\u5bf9\u79f0\u6027\u3002", "method": "\u901a\u8fc7\u674e\u7fa4\u4e0a\u7684\u6d41\u5339\u914d\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5bf9\u79f0\u6027\uff0c\u5c06\u5bf9\u79f0\u6027\u53d1\u73b0\u8868\u8ff0\u4e3a\u5728\u66f4\u5927\u5047\u8bbe\u7ec4\u4e0a\u5b66\u4e60\u5206\u5e03\uff0c\u4f7f\u5b66\u4e60\u7684\u5206\u5e03\u4e0e\u6570\u636e\u4e2d\u89c2\u5bdf\u5230\u7684\u5bf9\u79f0\u6027\u76f8\u5339\u914d\u3002", "result": "\u57282D\u548c3D\u70b9\u4e91\u5b9e\u9a8c\u4e2d\u6210\u529f\u53d1\u73b0\u79bb\u6563\u7fa4\uff0c\u5305\u62ec\u901a\u8fc7\u590d\u6570\u57df\u4e0a\u7684\u6d41\u5339\u914d\u53d1\u73b0\u53cd\u5c04\uff1b\u53d1\u73b0\u4e86\u201c\u6700\u540e\u65f6\u523b\u6536\u655b\u201d\u6311\u6218\u5e76\u9488\u5bf9\u5bf9\u79f0\u6027\u53d1\u73b0\u5f15\u5165\u65b0\u7684\u6d41\u5339\u914d\u63d2\u503c\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684LieFlow\u65b9\u6cd5\u5728\u5bf9\u79f0\u6027\u53d1\u73b0\u4e0a\u6bd4\u4e4b\u524d\u7684\u65b9\u6cd5\u66f4\u7075\u6d3b\uff0c\u5047\u8bbe\u66f4\u5c11\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u5bf9\u79f0\u6027\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2512.19720", "pdf": "https://arxiv.org/pdf/2512.19720", "abs": "https://arxiv.org/abs/2512.19720", "authors": ["Stefan Kuyumdzhiev", "Radostin Cholakov"], "title": "Per-Axis Weight Deltas for Frequent Model Updates", "categories": ["cs.LG"], "comment": "10 pages, 2 figures, AI That Keeps Up: Workshop on Continual and Compatible Foundation Model Updates (CCFM), Neurips 2025", "summary": "Serving many task-specialized LLM variants is often limited by the large size of fine-tuned checkpoints and the resulting cold-start latency. Since fine-tuned weights differ from their base model by relatively small structured residuals, a natural approach is to represent them as compressed deltas. We propose a simple 1-bit delta scheme that stores only the sign of the weight difference together with lightweight per-axis (row/column) FP16 scaling factors, learned from a small calibration set. This design preserves the compactness of 1-bit deltas while more accurately capturing variation across weight dimensions, leading to improved reconstruction quality over scalar alternatives. From a systems perspective, a streamlined loader that transfers packed deltas in a single operation per module reduces cold-start latency and storage overhead, with artifacts several times smaller than a full FP16 checkpoint. The method is drop-in, requires minimal calibration data, and maintains inference efficiency by avoiding dense reconstruction. Our experimental setup and source code are available at https://github.com/kuiumdjiev/Per-Axis-Weight-Deltas-for-Frequent-Model-Updates.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u591a\u4efb\u52a1LLM\u53d8\u4f53\u670d\u52a1\u53d7\u5fae\u8c03\u68c0\u67e5\u70b9\u5927\u5c3a\u5bf8\u548c\u51b7\u542f\u52a8\u5ef6\u8fdf\u7684\u9650\u5236\uff0c\u63d0\u51fa1\u4f4d\u589e\u91cf\u65b9\u6848\uff0c\u53ef\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\u548c\u5b58\u50a8\u5f00\u9500\u3002", "motivation": "\u591a\u4efb\u52a1LLM\u53d8\u4f53\u670d\u52a1\u53d7\u5fae\u8c03\u68c0\u67e5\u70b9\u5927\u5c3a\u5bf8\u548c\u51b7\u542f\u52a8\u5ef6\u8fdf\u9650\u5236\uff0c\u9700\u65b0\u65b9\u6cd5\u89e3\u51b3\u3002", "method": "\u63d0\u51fa1\u4f4d\u589e\u91cf\u65b9\u6848\uff0c\u5b58\u50a8\u6743\u91cd\u5dee\u5f02\u7b26\u53f7\u548c\u8f7b\u91cf\u7ea7\u6bcf\u8f74FP16\u7f29\u653e\u56e0\u5b50\uff0c\u7528\u7cbe\u7b80\u52a0\u8f7d\u5668\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\u548c\u5b58\u50a8\u5f00\u9500\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u6807\u91cf\u66ff\u4ee3\u65b9\u6848\u6709\u66f4\u597d\u7684\u91cd\u5efa\u8d28\u91cf\uff0c\u5de5\u4ef6\u6bd4\u5b8c\u6574FP16\u68c0\u67e5\u70b9\u5c0f\u51e0\u500d\u3002", "conclusion": "\u65b9\u6cd5\u5373\u63d2\u5373\u7528\uff0c\u53ea\u9700\u6700\u5c11\u6821\u51c6\u6570\u636e\uff0c\u907f\u514d\u5bc6\u96c6\u91cd\u5efa\u4ee5\u7ef4\u6301\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2512.20600", "pdf": "https://arxiv.org/pdf/2512.20600", "abs": "https://arxiv.org/abs/2512.20600", "authors": ["Coen Hutters", "Max B. Mendel"], "title": "Modeling Economic Systems as Multiport Networks", "categories": ["eess.SY", "econ.GN"], "comment": "29 pages, 16 figures, to be submitted to Journal of the Franklin Institute", "summary": "In this paper, we demonstrate how multiport network theory can be used as a powerful modeling tool in economics. The critical insight is using the port concept to pair the flow of goods (the electrical current) with the agent's incentive (the voltage) in an economic interaction. By building networks of agents interacting through ports, we create models with multiple levels of abstraction, from the macro level down to the micro level. We are thereby able to model complex macroeconomic systems whose dynamical behavior is emergent from the micro level. Using the LTSpice circuit simulator, we then design and analyze a series of example systems that range in complexity from the textbook Robinson Crusoe economy to a model of an entire economy.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u591a\u7aef\u53e3\u7f51\u7edc\u7406\u8bba\u53ef\u4f5c\u4e3a\u7ecf\u6d4e\u5b66\u5f3a\u5927\u5efa\u6a21\u5de5\u5177\uff0c\u6784\u5efa\u591a\u5c42\u6b21\u62bd\u8c61\u6a21\u578b\u5e76\u5206\u6790\u4e0d\u540c\u590d\u6742\u5ea6\u7ecf\u6d4e\u7cfb\u7edf\u3002", "motivation": "\u63a2\u7d22\u591a\u7aef\u53e3\u7f51\u7edc\u7406\u8bba\u5728\u7ecf\u6d4e\u5b66\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u66f4\u597d\u5730\u6a21\u62df\u590d\u6742\u5b8f\u89c2\u7ecf\u6d4e\u7cfb\u7edf\u3002", "method": "\u8fd0\u7528\u7aef\u53e3\u6982\u5ff5\u5c06\u5546\u54c1\u6d41\u52a8\u4e0e\u7ecf\u6d4e\u4e92\u52a8\u4e2d\u4e3b\u4f53\u6fc0\u52b1\u914d\u5bf9\uff0c\u6784\u5efa\u591a\u5c42\u6b21\u62bd\u8c61\u7f51\u7edc\u6a21\u578b\uff0c\u4f7f\u7528LTSpice\u7535\u8def\u6a21\u62df\u5668\u5206\u6790\u7cfb\u7edf\u3002", "result": "\u8bbe\u8ba1\u5e76\u5206\u6790\u4e86\u4ece\u9c81\u6ee8\u900a\u7ecf\u6d4e\u5230\u6574\u4e2a\u7ecf\u6d4e\u6a21\u578b\u7b49\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u793a\u4f8b\u7cfb\u7edf\u3002", "conclusion": "\u591a\u7aef\u53e3\u7f51\u7edc\u7406\u8bba\u662f\u7ecf\u6d4e\u5b66\u4e2d\u5efa\u6a21\u590d\u6742\u5b8f\u89c2\u7ecf\u6d4e\u7cfb\u7edf\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.20368", "pdf": "https://arxiv.org/pdf/2512.20368", "abs": "https://arxiv.org/abs/2512.20368", "authors": ["Samya Praharaj", "Koulik Khamaru"], "title": "Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.ST"], "comment": null, "summary": "Statistical inference in contextual bandits is complicated by the adaptive, non-i.i.d. nature of the data. A growing body of work has shown that classical least-squares inference may fail under adaptive sampling, and that constructing valid confidence intervals for linear functionals of the model parameter typically requires paying an unavoidable inflation of order $\\sqrt{d \\log T}$. This phenomenon -- often referred to as the price of adaptivity -- highlights the inherent difficulty of reliable inference under general contextual bandit policies.\n  A key structural property that circumvents this limitation is the \\emph{stability} condition of Lai and Wei, which requires the empirical feature covariance to concentrate around a deterministic limit. When stability holds, the ordinary least-squares estimator satisfies a central limit theorem, and classical Wald-type confidence intervals -- designed for i.i.d. data -- become asymptotically valid even under adaptation, \\emph{without} incurring the $\\sqrt{d \\log T}$ price of adaptivity.\n  In this paper, we propose and analyze a penalized EXP4 algorithm for linear contextual bandits. Our first main result shows that this procedure satisfies the Lai--Wei stability condition and therefore admits valid Wald-type confidence intervals for linear functionals. Our second result establishes that the same algorithm achieves regret guarantees that are minimax optimal up to logarithmic factors, demonstrating that stability and statistical efficiency can coexist within a single contextual bandit method. Finally, we complement our theory with simulations illustrating the empirical normality of the resulting estimators and the sharpness of the corresponding confidence intervals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u7ebf\u6027\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u7684\u60e9\u7f5aEXP4\u7b97\u6cd5\uff0c\u8bc1\u660e\u5176\u6ee1\u8db3\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u53ef\u6784\u5efa\u6709\u6548\u7f6e\u4fe1\u533a\u95f4\uff0c\u4e14\u8fbe\u5230\u8fd1\u6700\u4f18\u540e\u6094\u754c\uff0c\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u3002", "motivation": "\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u6570\u636e\u7684\u81ea\u9002\u5e94\u3001\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7279\u6027\u4f7f\u7edf\u8ba1\u63a8\u65ad\u590d\u6742\uff0c\u7ecf\u5178\u6700\u5c0f\u4e8c\u4e58\u63a8\u65ad\u53ef\u80fd\u5931\u6548\uff0c\u9700\u4ed8\u51fa\u9002\u5e94\u6027\u4ee3\u4ef7\uff0c\u7814\u7a76\u65e8\u5728\u514b\u670d\u6b64\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u5e76\u5206\u6790\u7ebf\u6027\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u7684\u60e9\u7f5aEXP4\u7b97\u6cd5\u3002", "result": "\u8be5\u7b97\u6cd5\u6ee1\u8db3Lai - Wei\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u53ef\u6784\u5efa\u6709\u6548Wald\u578b\u7f6e\u4fe1\u533a\u95f4\uff0c\u8fbe\u5230\u8fd1\u6700\u4f18\u540e\u6094\u754c\uff0c\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u91cf\u7684\u7ecf\u9a8c\u6b63\u6001\u6027\u548c\u7f6e\u4fe1\u533a\u95f4\u7684\u5c16\u9510\u6027\u3002", "conclusion": "\u7a33\u5b9a\u6027\u548c\u7edf\u8ba1\u6548\u7387\u53ef\u5728\u5355\u4e2a\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u65b9\u6cd5\u4e2d\u5e76\u5b58\u3002"}}
{"id": "2512.20203", "pdf": "https://arxiv.org/pdf/2512.20203", "abs": "https://arxiv.org/abs/2512.20203", "authors": ["Zhenlei Ye", "Xiaobing Sun", "Sicong Cao", "Lili Bo", "Bin Li"], "title": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair", "categories": ["cs.SE"], "comment": "Accepted by ICSE 2026", "summary": "The advances of large language models (LLMs) have paved the way for automated software vulnerability repair approaches, which iteratively refine the patch until it becomes plausible. Nevertheless, existing LLM-based vulnerability repair approaches face notable limitations: 1) they ignore the concern of locations that need to be patched and focus solely on the repair content. 2) they lack quality assessment for generated candidate patches in the iterative process.\n  To tackle the two limitations, we propose \\sysname, an LLM-based approach that provides information about where should be patched first. Furthermore, \\sysname improves the iterative repair strategy by assessing the quality of test-failing patches and selecting the best patch for the next iteration. We introduce two dimensions to assess the quality of patches: whether they introduce new vulnerabilities and the taint statement coverage. We evaluated \\sysname on a real-world C/C++ vulnerability repair dataset VulnLoc+, which contains 40 vulnerabilities and their Proofs-of-Vulnerability. The experimental results demonstrate that \\sysname exhibits substantial improvements compared with the Neural Machine Translation-based, Program Analysis-based, and LLM-based state-of-the-art vulnerability repair approaches. Specifically, \\sysname is able to generate 27 plausible patches, which is comparable to or even 8 to 22 more plausible patches than the baselines. In terms of correct patch generation, \\sysname repairs 8 to 13 additional vulnerabilities compared with existing approaches.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u5b58\u5728\u5ffd\u7565\u8865\u4e01\u4f4d\u7f6e\u548c\u7f3a\u4e4f\u5019\u9009\u8865\u4e01\u8d28\u91cf\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fasysname\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\u5176\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u5b58\u5728\u5ffd\u7565\u8865\u4e01\u4f4d\u7f6e\u548c\u7f3a\u4e4f\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u5019\u9009\u8865\u4e01\u8d28\u91cf\u8bc4\u4f30\u7684\u5c40\u9650\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fasysname\u65b9\u6cd5\uff0c\u5148\u63d0\u4f9b\u8865\u4e01\u4f4d\u7f6e\u4fe1\u606f\uff0c\u901a\u8fc7\u8bc4\u4f30\u6d4b\u8bd5\u5931\u8d25\u8865\u4e01\u7684\u8d28\u91cf\u6539\u8fdb\u8fed\u4ee3\u4fee\u590d\u7b56\u7565\uff0c\u5f15\u5165\u662f\u5426\u5f15\u5165\u65b0\u6f0f\u6d1e\u548c\u6c61\u70b9\u8bed\u53e5\u8986\u76d6\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u8865\u4e01\u8d28\u91cf\u3002", "result": "\u5728VulnLoc+\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0csysname\u80fd\u751f\u621027\u4e2a\u5408\u7406\u8865\u4e01\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u591a8 - 22\u4e2a\uff1b\u5728\u6b63\u786e\u8865\u4e01\u751f\u6210\u65b9\u9762\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u591a\u4fee\u590d8 - 13\u4e2a\u6f0f\u6d1e\u3002", "conclusion": "sysname\u65b9\u6cd5\u76f8\u6bd4\u57fa\u4e8e\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\u3001\u7a0b\u5e8f\u5206\u6790\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u73b0\u6709\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2512.19703", "pdf": "https://arxiv.org/pdf/2512.19703", "abs": "https://arxiv.org/abs/2512.19703", "authors": ["Siyuan Fu", "Xuchen Guo", "Mingjun Liu", "Hongxiang Li", "Boyin Tan", "Gongxi Zhu", "Xianwei Zhuang", "Jinghan Ru", "Yuxin Xie", "Yuguo Yin"], "title": "ASK: Adaptive Self-improving Knowledge Framework for Audio Text Retrieval", "categories": ["eess.AS", "cs.IR", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "The dominant paradigm for Audio-Text Retrieval (ATR) relies on mini-batch-based contrastive learning. This process, however, is inherently limited by what we formalize as the Gradient Locality Bottleneck (GLB), which structurally prevents models from leveraging out-of-batch knowledge and thus impairs fine-grained and long-tail learning. While external knowledge-enhanced methods can alleviate the GLB, we identify a critical, unaddressed side effect: the Representation-Drift Mismatch (RDM), where a static knowledge base becomes progressively misaligned with the evolving model, turning guidance into noise. To address this dual challenge, we propose the Adaptive Self-improving Knowledge (ASK) framework, a model-agnostic, plug-and-play solution. ASK breaks the GLB via multi-grained knowledge injection, systematically mitigates RDM through dynamic knowledge refinement, and introduces a novel adaptive reliability weighting scheme to ensure consistent knowledge contributes to optimization. Experimental results on two benchmark datasets with superior, state-of-the-art performance justify the efficacy of our proposed ASK framework.", "AI": {"tldr": "\u73b0\u6709\u97f3\u9891 - \u6587\u672c\u68c0\u7d22\u8303\u5f0f\u6709\u68af\u5ea6\u5c40\u90e8\u74f6\u9888\u548c\u8868\u5f81\u6f02\u79fb\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u51faASK\u6846\u67b6\u89e3\u51b3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u97f3\u9891 - \u6587\u672c\u68c0\u7d22\u4f9d\u8d56\u7684\u5c0f\u6279\u91cf\u5bf9\u6bd4\u5b66\u4e60\u5b58\u5728\u68af\u5ea6\u5c40\u90e8\u74f6\u9888\uff0c\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\u6709\u8868\u5f81\u6f02\u79fb\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u3001\u5373\u63d2\u5373\u7528\u7684ASK\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u77e5\u8bc6\u6ce8\u5165\u6253\u7834GLB\uff0c\u52a8\u6001\u77e5\u8bc6\u7ec6\u5316\u7f13\u89e3RDM\uff0c\u5f15\u5165\u81ea\u9002\u5e94\u53ef\u9760\u6027\u52a0\u6743\u65b9\u6848\u3002", "result": "\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684ASK\u6846\u67b6\u6709\u6548\u3002"}}
{"id": "2512.20052", "pdf": "https://arxiv.org/pdf/2512.20052", "abs": "https://arxiv.org/abs/2512.20052", "authors": ["Hung-Chieh Fang", "Kuo-Han Hung", "Chu-Rong Chen", "Po-Jung Chou", "Chun-Kai Yang", "Po-Chen Ko", "Yu-Chiang Wang", "Yueh-Hua Wu", "Min-Hung Chen", "Shao-Hua Sun"], "title": "Learning Skills from Action-Free Videos", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.", "AI": {"tldr": "\u63d0\u51faSOF\u6846\u67b6\u4ece\u65e0\u52a8\u4f5c\u89c6\u9891\u4e2d\u5b66\u4e60\u6f5c\u5728\u6280\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u63d0\u9ad8\u591a\u4efb\u52a1\u548c\u957f\u7a0b\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u751f\u6210\u6a21\u578b\u96be\u8f6c\u5316\u4e3a\u4f4e\u7ea7\u52a8\u4f5c\uff0c\u6f5c\u5728\u52a8\u4f5c\u6a21\u578b\u7f3a\u4e4f\u9ad8\u7ea7\u89c4\u5212\u80fd\u529b\uff0c\u9700\u5f25\u5408\u5dee\u8ddd\u3002", "method": "\u5f15\u5165SOF\u6846\u67b6\uff0c\u57fa\u4e8e\u5149\u6d41\u7684\u4e2d\u95f4\u8868\u793a\u5b66\u4e60\u6f5c\u5728\u6280\u80fd\u7a7a\u95f4\uff0c\u5728\u57fa\u4e8e\u6d41\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5b66\u4e60\u6280\u80fd\u3002", "result": "\u5728\u591a\u4efb\u52a1\u548c\u957f\u7a0b\u8bbe\u7f6e\u4e2d\u6301\u7eed\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u80fd\u76f4\u63a5\u4ece\u539f\u59cb\u89c6\u89c9\u6570\u636e\u83b7\u53d6\u548c\u7ec4\u5408\u6280\u80fd\u3002", "conclusion": "SOF\u6846\u67b6\u6709\u6548\uff0c\u53ef\u4ece\u65e0\u52a8\u4f5c\u89c6\u9891\u5b66\u4e60\u6f5c\u5728\u6280\u80fd\u5e76\u8f6c\u5316\u4e3a\u52a8\u4f5c\uff0c\u63d0\u5347\u673a\u5668\u4eba\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2512.19721", "pdf": "https://arxiv.org/pdf/2512.19721", "abs": "https://arxiv.org/abs/2512.19721", "authors": ["Vineet Yadav"], "title": "Sign-Aware Multistate Jaccard Kernels and Geometry for Real and Complex-Valued Signals", "categories": ["cs.LG", "cs.IT"], "comment": null, "summary": "We introduce a sign-aware, multistate Jaccard/Tanimoto framework that extends overlap-based distances from nonnegative vectors and measures to arbitrary real- and complex-valued signals while retaining bounded metric and positive-semidefinite kernel structure. Formally, the construction is a set- and measure-theoretic geometry: signals are represented as atomic measures on a signed state space, and similarity is given by a generalized Jaccard overlap of these measures. Each signal is embedded into a nonnegative multistate representation, using positive/negative splits for real signals, Cartesian and polar decompositions for complex signals, and user-defined state partitions for refined regime analysis. Applying the Tanimoto construction to these embeddings yields a family of $[0,1]$ distances that satisfy the triangle inequality and define positive-semidefinite kernels usable directly in kernel methods and graph-based learning. Beyond pairwise distances, we develop coalition analysis via M\u00f6bius inversion, which decomposes signal magnitude into nonnegative, additive contributions with exact budget closure across coalitions of signals. Normalizing the same embeddings produces probability measures on coordinate -- state configurations, so that the distance becomes a monotone transform of total variation and admits a regime -- intensity decomposition. The resulting construction yields a single, mechanistically interpretable distance that simultaneously provides bounded metric structure, positive-semidefinite kernels, probabilistic semantics, and transparent budget accounting within one sign-aware framework, supporting correlograms, feature engineering, similarity graphs, and other analytical tools in scientific and financial applications.", "AI": {"tldr": "\u63d0\u51fa\u5e26\u7b26\u53f7\u611f\u77e5\u7684\u591a\u72b6\u6001Jaccard/Tanimoto\u6846\u67b6\uff0c\u6269\u5c55\u91cd\u53e0\u8ddd\u79bb\uff0c\u7528\u4e8e\u4efb\u610f\u5b9e\u503c\u548c\u590d\u503c\u4fe1\u53f7\uff0c\u5177\u6709\u591a\u79cd\u6027\u8d28\u548c\u5206\u6790\u65b9\u6cd5\uff0c\u652f\u6301\u591a\u5e94\u7528\u3002", "motivation": "\u5c06\u57fa\u4e8e\u91cd\u53e0\u7684\u8ddd\u79bb\u4ece\u975e\u8d1f\u5411\u91cf\u548c\u6d4b\u5ea6\u6269\u5c55\u5230\u4efb\u610f\u5b9e\u503c\u548c\u590d\u503c\u4fe1\u53f7\u3002", "method": "\u5c06\u4fe1\u53f7\u8868\u793a\u4e3a\u6709\u7b26\u53f7\u72b6\u6001\u7a7a\u95f4\u4e0a\u7684\u539f\u5b50\u6d4b\u5ea6\uff0c\u8fdb\u884c\u5d4c\u5165\uff0c\u5e94\u7528Tanimoto\u6784\u9020\uff0c\u901a\u8fc7M\u00f6bius\u53cd\u6f14\u8fdb\u884c\u8054\u76df\u5206\u6790\uff0c\u5f52\u4e00\u5316\u5f97\u5230\u6982\u7387\u6d4b\u5ea6\u3002", "result": "\u5f97\u5230\u6ee1\u8db3\u4e09\u89d2\u4e0d\u7b49\u5f0f\u3001\u5b9a\u4e49\u534a\u6b63\u5b9a\u6838\u7684[0,1]\u8ddd\u79bb\uff0c\u53ef\u8fdb\u884c\u4fe1\u53f7\u5e45\u5ea6\u5206\u89e3\u548c\u6982\u7387\u8bed\u4e49\u5206\u6790\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4e00\u4e2a\u5e26\u7b26\u53f7\u611f\u77e5\u7684\u6846\u67b6\u5185\u540c\u65f6\u63d0\u4f9b\u6709\u754c\u5ea6\u91cf\u7ed3\u6784\u3001\u534a\u6b63\u5b9a\u6838\u3001\u6982\u7387\u8bed\u4e49\u548c\u900f\u660e\u9884\u7b97\u6838\u7b97\uff0c\u652f\u6301\u591a\u9886\u57df\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2512.20562", "pdf": "https://arxiv.org/pdf/2512.20562", "abs": "https://arxiv.org/abs/2512.20562", "authors": ["Yingzhen Yang"], "title": "Shallow Neural Networks Learn Low-Degree Spherical Polynomials with Learnable Channel Attention", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "We study the problem of learning a low-degree spherical polynomial of degree $\\ell_0 = \u0398(1) \\ge 1$ defined on the unit sphere in $\\RR^d$ by training an over-parameterized two-layer neural network (NN) with channel attention in this paper. Our main result is the significantly improved sample complexity for learning such low-degree polynomials. We show that, for any regression risk $\\eps \\in (0,1)$, a carefully designed two-layer NN with channel attention and finite width of $m \\ge \u0398({n^4 \\log (2n/\u03b4)}/{d^{2\\ell_0}})$ trained by the vanilla gradient descent (GD) requires the lowest sample complexity of $n \\asymp \u0398(d^{\\ell_0}/\\eps)$ with probability $1-\u03b4$ for every $\u03b4\\in (0,1)$, in contrast with the representative sample complexity $\u0398\\pth{d^{\\ell_0} \\max\\set{\\eps^{-2},\\log d}}$, where $n$ is the training daata size. Moreover, such sample complexity is not improvable since the trained network renders a sharp rate of the nonparametric regression risk of the order $\u0398(d^{\\ell_0}/{n})$ with probability at least $1-\u03b4$. On the other hand, the minimax optimal rate for the regression risk with a kernel of rank $\u0398(d^{\\ell_0})$ is $\u0398(d^{\\ell_0}/{n})$, so that the rate of the nonparametric regression risk of the network trained by GD is minimax optimal. The training of the two-layer NN with channel attention consists of two stages. In Stage 1, a provable learnable channel selection algorithm identifies the ground-truth channel number $\\ell_0$ from the initial $L \\ge \\ell_0$ channels in the first-layer activation, with high probability. This learnable selection is achieved by an efficient one-step GD update on both layers, enabling feature learning for low-degree polynomial targets. In Stage 2, the second layer is trained by standard GD using the activation function with the selected channels.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2512.20328", "pdf": "https://arxiv.org/pdf/2512.20328", "abs": "https://arxiv.org/abs/2512.20328", "authors": ["Antonio Vitale", "Khai-Nguyen Nguyen", "Denys Poshyvanyk", "Rocco Oliveto", "Simone Scalabrino", "Antonio Mastropaolo"], "title": "Toward Explaining Large Language Models in Software Engineering Tasks", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u3001\u6a21\u578b\u65e0\u5173\u7684\u53ef\u89e3\u91ca\u6027\u6846\u67b6FeatureSHAP\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u52a9\u4ece\u4e1a\u8005\u51b3\u7b56\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9ed1\u76d2\u7279\u6027\u963b\u788d\u5176\u5728\u9ad8\u98ce\u9669\u548c\u5b89\u5168\u5173\u952e\u9886\u57df\u5e94\u7528\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7279\u5b9a\u9886\u57df\u89e3\u91ca\u3002", "method": "\u57fa\u4e8eShapley\u503c\uff0c\u901a\u8fc7\u7cfb\u7edf\u8f93\u5165\u6270\u52a8\u548c\u7279\u5b9a\u4efb\u52a1\u76f8\u4f3c\u6027\u6bd4\u8f83\uff0c\u5c06\u6a21\u578b\u8f93\u51fa\u5f52\u56e0\u4e8e\u9ad8\u7ea7\u8f93\u5165\u7279\u5f81\uff0c\u517c\u5bb9\u5f00\u6e90\u548c\u4e13\u6709\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u4ee3\u7801\u751f\u6210\u548c\u4ee3\u7801\u6458\u8981\u4efb\u52a1\u4e2d\uff0c\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u66f4\u80fd\u964d\u4f4e\u65e0\u5173\u7279\u5f81\u91cd\u8981\u6027\uff0c\u89e3\u91ca\u4fdd\u771f\u5ea6\u66f4\u9ad8\uff1b\u4ece\u4e1a\u8005\u8c03\u67e5\u663e\u793a\u6709\u52a9\u4e8e\u89e3\u91ca\u6a21\u578b\u8f93\u51fa\u548c\u51b3\u7b56\u3002", "conclusion": "FeatureSHAP\u662f\u8fc8\u5411\u5b9e\u7528\u8f6f\u4ef6\u5de5\u7a0b\u53ef\u89e3\u91caAI\u7684\u6709\u610f\u4e49\u4e00\u6b65\u3002"}}
{"id": "2512.20184", "pdf": "https://arxiv.org/pdf/2512.20184", "abs": "https://arxiv.org/abs/2512.20184", "authors": ["Chaoyi Ruan", "Yiliang Wang", "Ziji Shi", "Jialin Li"], "title": "Reaching Agreement Among Reasoning LLM Agents", "categories": ["cs.DC"], "comment": null, "summary": "Multi-agent systems have extended the capability of agentic AI. Instead of single inference passes, multiple agents perform collective reasoning to derive high quality answers. However, existing multi-agent orchestration relies on static heuristic workflows such as fixed loop limits and barrier synchronization. These ad-hoc approaches waste computational resources, incur high latency due to stragglers, and risk finalizing transient agreements. We argue that reliable multi-agent reasoning requires a formal foundation analogous to classical distributed consensus problem.\n  To that end, we propose a formal model of the multi-agent refinement problem. The model includes definitions of the correctness guarantees and formal semantics of agent reasoning. We then introduce Aegean, a consensus protocol designed for stochastic reasoning agents that solves multi-agent refinement. We implement the protocol in Aegean-Serve, a consensus-aware serving engine that performs incremental quorum detection across concurrent agent executions, enabling early termination when sufficient agents converge. Evaluation using four mathematical reasoning benchmarks shows that Aegean provides provable safety and liveness guarantees while reducing latency by 1.2--20$\\times$ compared to state-of-the-art baselines, maintaining answer quality within 2.5%. Consistent gains across both local GPU deployments and commercial API providers validate that consensus-based orchestration eliminates straggler delays without sacrificing correctness.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7f16\u6392\u65b9\u6cd5\u5b58\u5728\u95ee\u9898\uff0c\u63d0\u51fa\u5f62\u5f0f\u5316\u6a21\u578b\u548cAegean\u5171\u8bc6\u534f\u8bae\uff0c\u7ecf\u8bc4\u4f30\u53ef\u4fdd\u969c\u5b89\u5168\u548c\u6d3b\u6027\uff0c\u964d\u4f4e\u5ef6\u8fdf\u4e14\u4e0d\u727a\u7272\u7b54\u6848\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7f16\u6392\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u5de5\u4f5c\u6d41\uff0c\u5b58\u5728\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u3001\u9ad8\u5ef6\u8fdf\u548c\u8fbe\u6210\u4e34\u65f6\u534f\u8bae\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e3a\u53ef\u9760\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u5efa\u7acb\u5f62\u5f0f\u5316\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7ec6\u5316\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5f15\u5165Aegean\u5171\u8bc6\u534f\u8bae\uff0c\u5728Aegean - Serve\u670d\u52a1\u5f15\u64ce\u4e2d\u5b9e\u73b0\u8be5\u534f\u8bae\uff0c\u8fdb\u884c\u589e\u91cf\u6cd5\u5b9a\u4eba\u6570\u68c0\u6d4b\u4ee5\u5b9e\u73b0\u63d0\u524d\u7ec8\u6b62\u3002", "result": "\u4f7f\u7528\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u8bc4\u4f30\uff0cAegean\u53ef\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u548c\u6d3b\u6027\u4fdd\u8bc1\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5ef6\u8fdf\u964d\u4f4e1.2 - 20\u500d\uff0c\u7b54\u6848\u8d28\u91cf\u4fdd\u6301\u57282.5%\u4ee5\u5185\u3002", "conclusion": "\u57fa\u4e8e\u5171\u8bc6\u7684\u7f16\u6392\u6d88\u9664\u4e86\u62d6\u540e\u817f\u8005\u7684\u5ef6\u8fdf\uff0c\u4e14\u4e0d\u727a\u7272\u6b63\u786e\u6027\uff0c\u5728\u672c\u5730GPU\u90e8\u7f72\u548c\u5546\u4e1aAPI\u63d0\u4f9b\u5546\u4e2d\u5747\u6709\u4e00\u81f4\u6536\u76ca\u3002"}}
{"id": "2512.19834", "pdf": "https://arxiv.org/pdf/2512.19834", "abs": "https://arxiv.org/abs/2512.19834", "authors": ["Davi Juv\u00eancio Gomes de Sousa", "Nelson Alves Ferreira Neto", "Christiano M. S. Nascimento", "Lucas Q. Galv\u00e3o", "Mauro Queiroz Nooblath Neto", "Micael Andrade Dias", "C\u00e1ssio de Castro Silva", "Braian Pinheiro da Silva", "Alexandre B. Tacla", "Val\u00e9ria Loureiro da Silva"], "title": "Towards a point-to-point CV-QKD system: Implementation challenges and perspectives", "categories": ["quant-ph", "cs.ET", "cs.IR", "cs.IT", "eess.SP"], "comment": "33 pages with 8 figures", "summary": "This article presents an analysis of the practical challenges and implementation perspectives of point-to-point continuous-variable quantum key distribution (CV-QKD) systems over optical fiber. The study addresses the physical layer, including the design of transmitters, quantum channels, and receivers, with emphasis on impairments such as attenuation, chromatic dispersion, polarization fluctuations, and coexistence with classical channels. We further examine the role of digital signal processing (DSP) as the bridge between quantum state transmission and classical post-processing, highlighting its impact on excess noise mitigation, covariance matrix estimation, and reconciliation efficiency. The post-processing pipeline is detailed with a focus on parameter estimation in the finite-size regime, information reconciliation using LDPC-based codes optimized for low-SNR conditions, and privacy amplification employing large-block universal hashing. From a hardware perspective, we discuss modular digital architectures that integrate dedicated accelerators with programmable processors, supported by a reference software framework (CV-QKD-ModSim) for algorithm validation and hardware co-design. Finally, we outline perspectives for the deployment of CV-QKD in Brazil, starting from metropolitan testbeds and extending toward hybrid fiber/FSO and space-based infrastructures. The work establishes the foundations for the first point-to-point CV-QKD system in Brazil, while providing a roadmap for scalable and interoperable quantum communication networks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u5149\u7ea4\u70b9\u5bf9\u70b9\u8fde\u7eed\u53d8\u91cf\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08CV - QKD\uff09\u7cfb\u7edf\u7684\u6311\u6218\u4e0e\u5b9e\u73b0\u524d\u666f\uff0c\u6d89\u53ca\u7269\u7406\u5c42\u3001\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u3001\u540e\u5904\u7406\u6d41\u7a0b\u3001\u786c\u4ef6\u67b6\u6784\uff0c\u5e76\u7ed9\u51fa\u5df4\u897f\u90e8\u7f72\u5c55\u671b\u3002", "motivation": "\u4e3a\u5df4\u897f\u5efa\u7acb\u9996\u4e2a\u70b9\u5bf9\u70b9CV - QKD\u7cfb\u7edf\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u4e92\u64cd\u4f5c\u7684\u91cf\u5b50\u901a\u4fe1\u7f51\u7edc\u8def\u7ebf\u56fe\u3002", "method": "\u7814\u7a76\u7269\u7406\u5c42\u8bbe\u8ba1\uff0c\u5206\u6790\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u4f5c\u7528\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u540e\u5904\u7406\u6d41\u7a0b\uff0c\u8ba8\u8bba\u6a21\u5757\u5316\u6570\u5b57\u67b6\u6784\u5e76\u4f7f\u7528\u53c2\u8003\u8f6f\u4ef6\u6846\u67b6\u9a8c\u8bc1\u3002", "result": "\u660e\u786e\u4e86CV - QKD\u7cfb\u7edf\u5404\u65b9\u9762\u7684\u8bbe\u8ba1\u548c\u5b9e\u73b0\u65b9\u6cd5\uff0c\u7ed9\u51fa\u5df4\u897f\u90e8\u7f72\u7684\u521d\u6b65\u65b9\u6848\u3002", "conclusion": "\u4e3a\u5df4\u897fCV - QKD\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\uff0c\u63d0\u4f9b\u91cf\u5b50\u901a\u4fe1\u7f51\u7edc\u53d1\u5c55\u8def\u7ebf\u3002"}}
{"id": "2512.20056", "pdf": "https://arxiv.org/pdf/2512.20056", "abs": "https://arxiv.org/abs/2512.20056", "authors": ["Hao Li", "Fabian Deuser", "Wenping Yin", "Steffen Knoblauch", "Wufan Zhao", "Filip Biljecki", "Yong Xue", "Wei Huang"], "title": "Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProbGLC\u65b9\u6cd5\u7528\u4e8e\u5feb\u901f\u707e\u5bb3\u54cd\u5e94\uff0c\u7ed3\u5408\u6982\u7387\u548c\u786e\u5b9a\u6027\u5730\u7406\u5b9a\u4f4d\u6a21\u578b\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u9ad8\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4ee3\u7801\u516c\u5f00\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u4f7f\u707e\u5bb3\u9891\u53d1\uff0c\u5feb\u901f\u51c6\u786e\u8bc6\u522b\u707e\u5bb3\u4f4d\u7f6e\u5bf9\u707e\u5bb3\u54cd\u5e94\u51b3\u7b56\u548c\u8d44\u6e90\u5206\u914d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faProbabilistic Cross - view Geolocalization\uff08ProbGLC\uff09\u65b9\u6cd5\uff0c\u5c06\u6982\u7387\u548c\u786e\u5b9a\u6027\u5730\u7406\u5b9a\u4f4d\u6a21\u578b\u6574\u5408\u5230\u7edf\u4e00\u6846\u67b6\u3002", "result": "\u5728MultiIAN\u548cSAGAINDisaster\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cAcc@1km\u4e3a0.86\uff0cAcc@25km\u4e3a0.97\uff0c\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u5730\u7406\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "ProbGLC\u65b9\u6cd5\u6709\u5f88\u5927\u6f5c\u529b\uff0c\u5229\u7528\u751f\u6210\u5f0f\u8de8\u89c6\u56fe\u65b9\u6cd5\u53ef\u4fc3\u8fdb\u4f4d\u7f6e\u611f\u77e5\uff0c\u5b9e\u73b0\u66f4\u597d\u66f4\u5feb\u7684\u707e\u5bb3\u54cd\u5e94\u3002"}}
{"id": "2512.19722", "pdf": "https://arxiv.org/pdf/2512.19722", "abs": "https://arxiv.org/abs/2512.19722", "authors": ["Alessandro Casadei", "Clemens Grupp", "Sreyoshi Bhaduri", "Lu Guo", "Wilson Fung", "Rohit Malshe", "Raj Ratan", "Ankush Pole", "Arkajit Rakshit"], "title": "Node-Level Financial Optimization in Demand Forecasting Through Dynamic Cost Asymmetry and Feedback Mechanism", "categories": ["cs.LG"], "comment": "Accepted to Amazon internal conference (AFSS). Now sharing with general public. This is submission is replacing a previous submission with the same title: the main paper is now submitted, while previously we submitted a summary", "summary": "This work introduces a methodology to adjust forecasts based on node-specific cost function asymmetry. The proposed model generates savings by dynamically incorporating the cost asymmetry into the forecasting error probability distribution to favor the least expensive scenario. Savings are calculated and a self-regulation mechanism modulates the adjustments magnitude based on the observed savings, enabling the model to adapt to station-specific conditions and unmodeled factors such as calibration errors or shifting macroeconomic dynamics. Finally, empirical results demonstrate the model's ability to achieve \\$5.1M annual savings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8282\u70b9\u7279\u5b9a\u6210\u672c\u51fd\u6570\u4e0d\u5bf9\u79f0\u6027\u8c03\u6574\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u80fd\u52a8\u6001\u7ed3\u5408\u6210\u672c\u4e0d\u5bf9\u79f0\u6027\uff0c\u6709\u81ea\u6211\u8c03\u8282\u673a\u5236\uff0c\u5b9e\u73b0\u6bcf\u5e74510\u4e07\u7f8e\u5143\u7684\u8282\u7701\u3002", "motivation": "\u4e3a\u4e86\u5229\u7528\u8282\u70b9\u7279\u5b9a\u6210\u672c\u51fd\u6570\u4e0d\u5bf9\u79f0\u6027\u6765\u8c03\u6574\u9884\u6d4b\uff0c\u5b9e\u73b0\u8282\u7ea6\u6210\u672c\u3002", "method": "\u5c06\u6210\u672c\u4e0d\u5bf9\u79f0\u6027\u52a8\u6001\u7eb3\u5165\u9884\u6d4b\u8bef\u5dee\u6982\u7387\u5206\u5e03\uff0c\u91cd\u70b9\u8003\u8651\u6210\u672c\u6700\u4f4e\u7684\u60c5\u666f\uff1b\u901a\u8fc7\u8ba1\u7b97\u8282\u7ea6\u989d\uff0c\u5229\u7528\u81ea\u6211\u8c03\u8282\u673a\u5236\u6839\u636e\u89c2\u5bdf\u5230\u7684\u8282\u7ea6\u989d\u8c03\u6574\u8c03\u6574\u5e45\u5ea6\u3002", "result": "\u8be5\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u6bcf\u5e74510\u4e07\u7f8e\u5143\u7684\u8282\u7701\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u5229\u7528\u6210\u672c\u51fd\u6570\u4e0d\u5bf9\u79f0\u6027\uff0c\u6709\u6548\u6839\u636e\u7ad9\u70b9\u7279\u5b9a\u6761\u4ef6\u548c\u672a\u5efa\u6a21\u56e0\u7d20\u8fdb\u884c\u8c03\u6574\u5b9e\u73b0\u5927\u5e45\u8282\u7ea6\u3002"}}
{"id": "2512.16239", "pdf": "https://arxiv.org/pdf/2512.16239", "abs": "https://arxiv.org/abs/2512.16239", "authors": ["Bohan Wu", "Eli N. Weinstein", "David M. Blei"], "title": "Bayesian Empirical Bayes: Simultaneous Inference from Probabilistic Symmetries", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Empirical Bayes (EB) improves the accuracy of simultaneous inference \"by learning from the experience of others\" (Efron, 2012). Classical EB theory focuses on latent variables that are iid draws from a fitted prior (Efron, 2019). Modern applications, however, feature complex structure, like arrays, spatial processes, or covariates. How can we apply EB ideas to these settings? We propose a generalized approach to empirical Bayes based on the notion of probabilistic symmetry. Our method pairs a simultaneous inference problem-with an unknown prior-to a symmetry assumption on the joint distribution of the latent variables. Each symmetry implies an ergodic decomposition, which we use to derive a corresponding empirical Bayes method. We call this methodBayesian empirical Bayes (BEB). We show how BEB recovers the classical methods of empirical Bayes, which implicitly assume exchangeability. We then use it to extend EB to other probabilistic symmetries: (i) EB matrix recovery for arrays and graphs; (ii) covariate-assisted EB for conditional data; (iii) EB spatial regression under shift invariance. We develop scalable algorithms based on variational inference and neural networks. In simulations, BEB outperforms existing approaches to denoising arrays and spatial data. On real data, we demonstrate BEB by denoising a cancer gene-expression matrix and analyzing spatial air-quality data from New York City.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6982\u7387\u5bf9\u79f0\u6982\u5ff5\u7684\u5e7f\u4e49\u7ecf\u9a8c\u8d1d\u53f6\u65af\u65b9\u6cd5BEB\uff0c\u62d3\u5c55EB\u5e94\u7528\uff0c\u5f00\u53d1\u7b97\u6cd5\uff0c\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u4ee3\u5e94\u7528\u6709\u590d\u6742\u7ed3\u6784\uff0c\u9700\u5c06\u7ecf\u9a8c\u8d1d\u53f6\u65af\u601d\u60f3\u5e94\u7528\u4e8e\u8fd9\u4e9b\u573a\u666f\u3002", "method": "\u5c06\u540c\u65f6\u63a8\u7406\u95ee\u9898\u4e0e\u6f5c\u5728\u53d8\u91cf\u8054\u5408\u5206\u5e03\u7684\u5bf9\u79f0\u5047\u8bbe\u914d\u5bf9\uff0c\u5229\u7528\u904d\u5386\u5206\u89e3\u63a8\u5bfc\u5bf9\u5e94\u7ecf\u9a8c\u8d1d\u53f6\u65af\u65b9\u6cd5BEB\uff0c\u5f00\u53d1\u57fa\u4e8e\u53d8\u5206\u63a8\u7406\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u53ef\u6269\u5c55\u7b97\u6cd5\u3002", "result": "BEB\u80fd\u6062\u590d\u7ecf\u5178\u7ecf\u9a8c\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u53ef\u62d3\u5c55\u5230\u5176\u4ed6\u6982\u7387\u5bf9\u79f0\u60c5\u51b5\uff0c\u6a21\u62df\u4e2d\u5728\u53bb\u566a\u9635\u5217\u548c\u7a7a\u95f4\u6570\u636e\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u5bf9\u764c\u75c7\u57fa\u56e0\u8868\u8fbe\u77e9\u9635\u53bb\u566a\u548c\u5206\u6790\u7ebd\u7ea6\u5e02\u7a7a\u95f4\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\u6709\u6548\u3002", "conclusion": "\u57fa\u4e8e\u6982\u7387\u5bf9\u79f0\u7684BEB\u65b9\u6cd5\u6709\u6548\u62d3\u5c55\u4e86\u7ecf\u9a8c\u8d1d\u53f6\u65af\u7684\u5e94\u7528\uff0c\u4e14\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2512.20334", "pdf": "https://arxiv.org/pdf/2512.20334", "abs": "https://arxiv.org/abs/2512.20334", "authors": ["Yuan Huang", "Yukang Zhou", "Xiangping Chen", "Zibin Zheng"], "title": "Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation", "categories": ["cs.SE"], "comment": "This paper has been accepted by FSE 2026 (ACM International Conference on the Foundations of Software Engineering). This is a preprint version and may differ from the final published version", "summary": "With the rapid development of large language models in code generation, AI-powered editors such as GitHub Copilot and Cursor are revolutionizing software development practices. At the same time, studies have identified potential defects in the generated code. Previous research has predominantly examined how code context influences the generation of defective code, often overlooking the impact of defects within commented-out code (CO code). AI coding assistants' interpretation of CO code in prompts affects the code they generate.\n  This study evaluates how AI coding assistants, GitHub Copilot and Cursor, are influenced by defective CO code. The experimental results show that defective CO code in the context causes AI coding assistants to generate more defective code, reaching up to 58.17 percent. Our findings further demonstrate that the tools do not simply copy the defective code from the context. Instead, they actively reason to complete incomplete defect patterns and continue to produce defective code despite distractions such as incorrect indentation or tags. Even with explicit instructions to ignore the defective CO code, the reduction in defects does not exceed 21.84 percent. These findings underscore the need for improved robustness and security measures in AI coding assistants.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86GitHub Copilot\u548cCursor\u53d7\u6ce8\u91ca\u6389\u7684\u6709\u7f3a\u9677\u4ee3\u7801\u5f71\u54cd\uff0c\u53d1\u73b0\u4f1a\u4f7f\u751f\u6210\u4ee3\u7801\u7f3a\u9677\u589e\u591a\uff0c\u9700\u63d0\u5347AI\u7f16\u7801\u52a9\u624b\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u65f6\u5b58\u5728\u6f5c\u5728\u7f3a\u9677\uff0c\u4ee5\u5f80\u7814\u7a76\u591a\u5ffd\u89c6\u6ce8\u91ca\u6389\u7684\u4ee3\u7801\uff08CO\u4ee3\u7801\uff09\u7f3a\u9677\u7684\u5f71\u54cd\uff0c\u800cAI\u7f16\u7801\u52a9\u624b\u5bf9CO\u4ee3\u7801\u7684\u89e3\u8bfb\u4f1a\u5f71\u54cd\u751f\u6210\u4ee3\u7801\u3002", "method": "\u8bc4\u4f30AI\u7f16\u7801\u52a9\u624bGitHub Copilot\u548cCursor\u53d7\u6709\u7f3a\u9677\u7684CO\u4ee3\u7801\u7684\u5f71\u54cd\u3002", "result": "\u4e0a\u4e0b\u6587\u4e2d\u6709\u7f3a\u9677\u7684CO\u4ee3\u7801\u4f7fAI\u7f16\u7801\u52a9\u624b\u751f\u6210\u66f4\u591a\u7f3a\u9677\u4ee3\u7801\uff0c\u6700\u9ad8\u8fbe58.17%\uff1b\u5de5\u5177\u5e76\u975e\u7b80\u5355\u590d\u5236\u7f3a\u9677\u4ee3\u7801\uff0c\u4f1a\u4e3b\u52a8\u63a8\u7406\u5b8c\u6210\u4e0d\u5b8c\u6574\u7f3a\u9677\u6a21\u5f0f\uff1b\u5373\u4fbf\u660e\u786e\u8981\u6c42\u5ffd\u7565\u7f3a\u9677CO\u4ee3\u7801\uff0c\u7f3a\u9677\u51cf\u5c11\u4e0d\u8d8521.84%\u3002", "conclusion": "\u6709\u5fc5\u8981\u6539\u8fdbAI\u7f16\u7801\u52a9\u624b\u7684\u9c81\u68d2\u6027\u548c\u5b89\u5168\u63aa\u65bd\u3002"}}
{"id": "2512.20210", "pdf": "https://arxiv.org/pdf/2512.20210", "abs": "https://arxiv.org/abs/2512.20210", "authors": ["Yinan Ni", "Xiao Yang", "Yuqi Tang", "Zhimin Qiu", "Chen Wang", "Tingzhou Yuan"], "title": "Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs", "categories": ["cs.DC"], "comment": null, "summary": "The serverless computing paradigm offers compelling advantages for deploying Large Language Model (LLM) inference services, including elastic scaling and pay-per-use billing. However, serving multiple fine-tuned LLMs via Low-Rank Adaptation (LoRA) in serverless environments faces critical challenges: reactive adapter loading causes significant cold start latency, and frequent adapter swapping leads to severe GPU memory fragmentation. In this paper, we present Predictive-LoRA (P-LoRA), a proactive and fragmentation-aware serverless inference system for LoRA-based LLMs. P-LoRA introduces two key innovations: (1) a lightweight LSTM-based traffic predictor that forecasts adapter demand and proactively prefetches hot adapters from host memory to GPU, reducing cold start latency by up to 68%; and (2) a page-based adapter memory management mechanism inspired by operating system virtual memory, which keeps GPU memory utilization above 87% even under heterogeneous adapter ranks. We evaluate P-LoRA using production-like workloads derived from the Azure Functions trace. Experimental results demonstrate that P-LoRA achieves 1.52x higher throughput than S-LoRA while reducing the average Time-To-First-Token (TTFT) by 35% under high concurrency scenarios.", "AI": {"tldr": "\u63d0\u51faP-LoRA\u7cfb\u7edf\u89e3\u51b3\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e0b\u591a\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6311\u6218\uff0c\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\uff0c\u63d0\u9ad8GPU\u5185\u5b58\u5229\u7528\u7387\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u670d\u52a1\u6709\u4f18\u52bf\uff0c\u4f46\u901a\u8fc7LoRA\u670d\u52a1\u591a\u5fae\u8c03\u6a21\u578b\u9762\u4e34\u51b7\u542f\u52a8\u5ef6\u8fdf\u548cGPU\u5185\u5b58\u788e\u7247\u5316\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7LSTM\u6d41\u91cf\u9884\u6d4b\u5668\u9884\u53d6\u70ed\u9002\u914d\u5668\uff0c\u91c7\u7528\u57fa\u4e8e\u9875\u9762\u7684\u9002\u914d\u5668\u5185\u5b58\u7ba1\u7406\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660eP-LoRA\u541e\u5410\u91cf\u6bd4S-LoRA\u9ad81.52\u500d\uff0c\u9ad8\u5e76\u53d1\u4e0b\u5e73\u5747TTFT\u964d\u4f4e35%\u3002", "conclusion": "P-LoRA\u80fd\u6709\u6548\u89e3\u51b3\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e0bLoRA\u6a21\u578b\u63a8\u7406\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2512.20145", "pdf": "https://arxiv.org/pdf/2512.20145", "abs": "https://arxiv.org/abs/2512.20145", "authors": ["Xiang Chen", "Yixin Ou", "Quan Feng", "Lei Li", "Piji Li", "Haibo Ye", "Sheng-Jun Huang", "Shuofei Qiao", "Shumin Deng", "Huajun Chen", "Ningyu Zhang"], "title": "Retrieval-augmented Prompt Learning for Pre-trained Foundation Models", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "comment": "IEEE/ACM Transactions on Audio, Speech and Language Processing", "summary": "The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.", "AI": {"tldr": "\u63d0\u51faRetroPrompt\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u77e5\u8bc6\u5e73\u8861\u8bb0\u5fc6\u4e0e\u6cdb\u5316\uff0c\u5728\u591a\u6570\u636e\u96c6\u591a\u4efb\u52a1\u7684\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u51cf\u5c11\u6b7b\u8bb0\u786c\u80cc\u4f9d\u8d56\uff0c\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684\u63d0\u793a\u5b66\u4e60\u9075\u5faa\u53c2\u6570\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u5728\u8bb0\u5fc6\u548c\u6b7b\u8bb0\u786c\u80cc\u5b66\u4e60\u4e2d\u6cdb\u5316\u7a33\u5b9a\u6027\u4e0d\u8db3\uff0c\u5168\u76d1\u7763\u8bad\u7ec3\u65f6\u96be\u4ee5\u5145\u5206\u5229\u7528\u975e\u5178\u578b\u5b9e\u4f8b\u548c\u907f\u514d\u8fc7\u62df\u5408\u3002", "method": "\u63d0\u51faRetroPrompt\u65b9\u6cd5\uff0c\u5229\u7528\u8bad\u7ec3\u6570\u636e\u751f\u6210\u516c\u5171\u77e5\u8bc6\u5e93\uff0c\u5728\u8f93\u5165\u3001\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u5f15\u5165\u68c0\u7d22\u673a\u5236\uff0c\u8ba9\u6a21\u578b\u4ece\u8bed\u6599\u5e93\u4e2d\u4e3b\u52a8\u68c0\u7d22\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u7684\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cRetroPrompt\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "RetroPrompt\u6709\u6548\u51cf\u5c11\u5bf9\u6b7b\u8bb0\u786c\u80cc\u7684\u4f9d\u8d56\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.20061", "pdf": "https://arxiv.org/pdf/2512.20061", "abs": "https://arxiv.org/abs/2512.20061", "authors": ["Hamed Firooz", "Rui Liu", "Yuchen Lu", "Zhenyu Hou", "Fangzhou Xiong", "Xiaoyang Zhang", "Changshu Jian", "Zhicheng Zhu", "Jiayuan Ma", "Jacob Tao", "Chaitali Gupta", "Xiaochang Peng", "Shike Mei", "Hang Cui", "Yang Qin", "Shuo Tang", "Jason Gaedtke", "Arpit Mittal"], "title": "Scaling Reinforcement Learning for Content Moderation with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.", "AI": {"tldr": "\u63a2\u8ba8\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u5185\u5bb9\u5206\u7c7b\u4ee5\u5b9e\u73b0\u5185\u5bb9\u5ba1\u6838\uff0c\u7814\u7a76\u8868\u660e\u5f3a\u5316\u5b66\u4e60\u6709\u7c7b\u4f3cS\u578b\u7684\u6269\u5c55\u884c\u4e3a\uff0c\u4e14\u5728\u6570\u636e\u6548\u7387\u4e0a\u9ad8\u4e8e\u76d1\u7763\u5fae\u8c03\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u751f\u6001\u4e2d\u5927\u89c4\u6a21\u5185\u5bb9\u5ba1\u6838\u662f\u6311\u6218\uff0c\u867d\u5927\u8bed\u8a00\u6a21\u578b\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5b9e\u73b0\u4e13\u5bb6\u7ea7\u51c6\u786e\u7387\u7684\u5b9e\u9645\u6311\u6218\u4ecd\u5f85\u63a2\u7d22\u3002", "method": "\u5bf9\u7528\u4e8e\u5185\u5bb9\u5206\u7c7b\u7684\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65b9\u6cd5\u548c\u5956\u52b1\u5851\u9020\u7b56\u7565\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u5448\u73b0\u7c7b\u4f3cS\u578b\u7684\u6269\u5c55\u884c\u4e3a\uff0c\u6027\u80fd\u968f\u8bad\u7ec3\u6570\u636e\u3001\u6eda\u52a8\u548c\u4f18\u5316\u6b65\u9aa4\u589e\u52a0\u800c\u63d0\u5347\u76f4\u81f3\u9971\u548c\uff1b\u5728\u9700\u8981\u590d\u6742\u57fa\u4e8e\u7b56\u7565\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u5927\u5e45\u63d0\u5347\u6027\u80fd\uff0c\u6570\u636e\u6548\u7387\u6bd4\u76d1\u7763\u5fae\u8c03\u9ad8100\u500d\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5728\u5de5\u4e1a\u89c4\u6a21\u7684\u5ba1\u6838\u7cfb\u7edf\u4e2d\u5f88\u6709\u6548\uff0c\u5c24\u5176\u5728\u4e13\u5bb6\u6807\u6ce8\u7a00\u7f3a\u6216\u6210\u672c\u9ad8\u7684\u9886\u57df\u3002"}}
{"id": "2512.19723", "pdf": "https://arxiv.org/pdf/2512.19723", "abs": "https://arxiv.org/abs/2512.19723", "authors": ["Firas Bayram", "Bestoun S. Ahmed", "Erik Hallin"], "title": "End-to-End Data Quality-Driven Framework for Machine Learning in Production Environment", "categories": ["cs.LG"], "comment": "38 Pages", "summary": "This paper introduces a novel end-to-end framework that efficiently integrates data quality assessment with machine learning (ML) model operations in real-time production environments. While existing approaches treat data quality assessment and ML systems as isolated processes, our framework addresses the critical gap between theoretical methods and practical implementation by combining dynamic drift detection, adaptive data quality metrics, and MLOps into a cohesive, lightweight system. The key innovation lies in its operational efficiency, enabling real-time, quality-driven ML decision-making with minimal computational overhead. We validate the framework in a steel manufacturing company's Electroslag Remelting (ESR) vacuum pumping process, demonstrating a 12% improvement in model performance (R2 = 94%) and a fourfold reduction in prediction latency. By exploring the impact of data quality acceptability thresholds, we provide actionable insights into balancing data quality standards and predictive performance in industrial applications. This framework represents a significant advancement in MLOps, offering a robust solution for time-sensitive, data-driven decision-making in dynamic industrial environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7ed3\u5408\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u64cd\u4f5c\uff0c\u5728\u94a2\u94c1\u5236\u9020\u516c\u53f8\u9a8c\u8bc1\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u964d\u4f4e\u9884\u6d4b\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u548cML\u7cfb\u7edf\u89c6\u4e3a\u5b64\u7acb\u8fc7\u7a0b\uff0c\u9700\u586b\u8865\u7406\u8bba\u65b9\u6cd5\u4e0e\u5b9e\u9645\u5e94\u7528\u7684\u5dee\u8ddd\u3002", "method": "\u5c06\u52a8\u6001\u6f02\u79fb\u68c0\u6d4b\u3001\u81ea\u9002\u5e94\u6570\u636e\u8d28\u91cf\u6307\u6807\u548cMLOps\u7ed3\u5408\u6210\u8f7b\u91cf\u7ea7\u7cfb\u7edf\u3002", "result": "\u5728\u94a2\u94c1\u5236\u9020\u516c\u53f8\u7684ESR\u771f\u7a7a\u6cf5\u8fc7\u7a0b\u9a8c\u8bc1\uff0c\u6a21\u578b\u6027\u80fd\u63d0\u534712%\uff08R2 = 94%\uff09\uff0c\u9884\u6d4b\u5ef6\u8fdf\u964d\u4f4e\u56db\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u662fMLOps\u7684\u91cd\u5927\u8fdb\u6b65\uff0c\u4e3a\u52a8\u6001\u5de5\u4e1a\u73af\u5883\u4e2d\u65f6\u95f4\u654f\u611f\u3001\u6570\u636e\u9a71\u52a8\u7684\u51b3\u7b56\u63d0\u4f9b\u6709\u529b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.20345", "pdf": "https://arxiv.org/pdf/2512.20345", "abs": "https://arxiv.org/abs/2512.20345", "authors": ["Xiaoxue Ma", "Wanwei Zhan", "Jiale Chen", "Yishu Li", "Jacky Keung", "Federica Sarro"], "title": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems", "categories": ["cs.SE"], "comment": null, "summary": "In today's data-driven era, deep learning is vital for processing massive datasets, yet single-device training is constrained by computational and memory limits. Distributed deep learning overcomes these challenges by leveraging multiple GPUs or machines in parallel. While general-purpose frameworks (e.g., TensorFlow and PyTorch) provide distributed capabilities, these are often add-on features that demand significant manual effort for advanced parallelism, underscoring the need for specialized frameworks. This study conducts the first large-scale empirical analysis of practitioner challenges in dedicated distributed frameworks. We examine 849 real-world issues from DeepSpeed, Megatron-LM, and Colossal-AI and construct a taxonomy of 34 bug symptoms, 28 root causes, and 6 fix patterns. Crucially, we establish explicit mappings between symptoms, causes, and fixes across distributed training stages, enabling a systematic understanding of how issues emerge and are resolved. Our results show that 45.1\\% of bug symptoms are unique to distributed frameworks, with setup failures, memory issues, and performance anomalies being the most prevalent. Moreover, 95\\% of issues in the communication setup stage occur exclusively in distributed contexts. We also find over 60\\% of cases can be resolved through version and dependency management, and distributed feature, API, and communication tuning. Based on these findings, we provide actionable implications.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u4e13\u7528\u5206\u5e03\u5f0f\u6846\u67b6\u4e2d\u4ece\u4e1a\u8005\u9762\u4e34\u7684\u6311\u6218\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u6784\u5efa\u95ee\u9898\u5206\u7c7b\u4f53\u7cfb\uff0c\u53d1\u73b0\u95ee\u9898\u7279\u70b9\u5e76\u7ed9\u51fa\u89e3\u51b3\u5efa\u8bae\u3002", "motivation": "\u5355\u8bbe\u5907\u8bad\u7ec3\u6709\u8ba1\u7b97\u548c\u5185\u5b58\u9650\u5236\uff0c\u901a\u7528\u6846\u67b6\u5206\u5e03\u5f0f\u529f\u80fd\u9700\u5927\u91cf\u624b\u52a8\u5de5\u4f5c\uff0c\u9700\u8981\u4e13\u7528\u6846\u67b6\uff0c\u7814\u7a76\u4ece\u4e1a\u8005\u5728\u4e13\u7528\u5206\u5e03\u5f0f\u6846\u67b6\u4e2d\u7684\u6311\u6218\u3002", "method": "\u5206\u6790DeepSpeed\u3001Megatron - LM\u548cColossal - AI\u7684849\u4e2a\u5b9e\u9645\u95ee\u9898\uff0c\u6784\u5efa\u75c7\u72b6\u3001\u6839\u6e90\u548c\u4fee\u590d\u6a21\u5f0f\u5206\u7c7b\u4f53\u7cfb\uff0c\u5efa\u7acb\u4e09\u8005\u6620\u5c04\u3002", "result": "45.1%\u7684\u9519\u8bef\u75c7\u72b6\u662f\u5206\u5e03\u5f0f\u6846\u67b6\u7279\u6709\u7684\uff0c\u901a\u4fe1\u8bbe\u7f6e\u9636\u6bb595%\u7684\u95ee\u9898\u4ec5\u5728\u5206\u5e03\u5f0f\u73af\u5883\u51fa\u73b0\uff0c\u8d8560%\u7684\u95ee\u9898\u53ef\u901a\u8fc7\u7248\u672c\u548c\u4f9d\u8d56\u7ba1\u7406\u7b49\u89e3\u51b3\u3002", "conclusion": "\u57fa\u4e8e\u7ed3\u679c\u7ed9\u51fa\u4e86\u53ef\u64cd\u4f5c\u7684\u5efa\u8bae\u3002"}}
{"id": "2512.20394", "pdf": "https://arxiv.org/pdf/2512.20394", "abs": "https://arxiv.org/abs/2512.20394", "authors": ["Mohammad Walid Charrwi", "Zaid Hussain"], "title": "Resilient Packet Forwarding: A Reinforcement Learning Approach to Routing in Gaussian Interconnected Networks with Clustered Faults", "categories": ["cs.DC"], "comment": null, "summary": "As Network-on-Chip (NoC) and Wireless Sensor Network architectures continue to scale, the topology of the underlying network becomes a critical factor in performance. Gaussian Interconnected Networks based on the arithmetic of Gaussian integers, offer attractive properties regarding diameter and symmetry. Despite their attractive theoretical properties, adaptive routing techniques in these networks are vulnerable to node and link faults, leading to rapid degradation in communication reliability. Node failures (particularly those following Gaussian distributions, such as thermal hotspots or physical damage clusters) pose severe challenges to traditional deterministic routing. This paper proposes a fault-aware Reinforcement Learning (RL) routing scheme tailored for Gaussian Interconnected Networks. By utilizing a PPO (Proximal Policy Optimization) agent with a specific reward structure designed to penalize fault proximity, the system dynamically learns to bypass faulty regions. We compare our proposed RL-based routing protocol against a greedy adaptive shortest-path routing algorithm. Experimental results demonstrate that the RL agent significantly outperforms the adaptive routing sustaining a Packet Delivery Ratio (PDR) of 0.95 at 40% fault density compared to 0.66 for the greedy. Furthermore, the RL approach exhibits effective delivery rates compared to the greedy adaptive routing, particularly under low network load of 20% at 0.57 vs. 0.43, showing greater proficiency in managing congestion, validating its efficacy in stochastic, fault-prone topologies", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u9ad8\u65af\u4e92\u8fde\u7f51\u7edc\u63d0\u51fa\u6545\u969c\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u8def\u7531\u65b9\u6848\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6848\u5728\u6570\u636e\u5305\u4f20\u8f93\u7387\u548c\u62e5\u585e\u7ba1\u7406\u4e0a\u4f18\u4e8e\u8d2a\u5a6a\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\u3002", "motivation": "\u9ad8\u65af\u4e92\u8fde\u7f51\u7edc\u4e2d\u81ea\u9002\u5e94\u8def\u7531\u6280\u672f\u6613\u53d7\u8282\u70b9\u548c\u94fe\u8def\u6545\u969c\u5f71\u54cd\uff0c\u4f20\u7edf\u786e\u5b9a\u6027\u8def\u7531\u96be\u4ee5\u5e94\u5bf9\u8282\u70b9\u6545\u969c\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u8def\u7531\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8ePPO\u4ee3\u7406\u548c\u7279\u5b9a\u5956\u52b1\u7ed3\u6784\u7684\u6545\u969c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u8def\u7531\u65b9\u6848\uff0c\u5e76\u4e0e\u8d2a\u5a6a\u81ea\u9002\u5e94\u6700\u77ed\u8def\u5f84\u8def\u7531\u7b97\u6cd5\u5bf9\u6bd4\u3002", "result": "\u572840%\u6545\u969c\u5bc6\u5ea6\u4e0b\uff0c\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u6570\u636e\u5305\u4f20\u8f93\u7387\u8fbe0.95\uff0c\u4f18\u4e8e\u8d2a\u5a6a\u7b97\u6cd5\u76840.66\uff1b\u572820%\u4f4e\u7f51\u7edc\u8d1f\u8f7d\u4e0b\uff0c\u4f20\u8f93\u7387\u4e3a0.57\uff0c\u4f18\u4e8e\u8d2a\u5a6a\u7b97\u6cd5\u76840.43\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u8def\u7531\u65b9\u6848\u5728\u968f\u673a\u3001\u6613\u6545\u969c\u62d3\u6251\u4e2d\u6709\u6548\uff0c\u80fd\u66f4\u597d\u7ba1\u7406\u62e5\u585e\u3002"}}
{"id": "2512.20174", "pdf": "https://arxiv.org/pdf/2512.20174", "abs": "https://arxiv.org/abs/2512.20174", "authors": ["Hao Guo", "Xugong Qin", "Jun Jie Ou Yang", "Peng Zhang", "Gangyan Zeng", "Yubo Li", "Hailun Lin"], "title": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark", "categories": ["cs.CV", "cs.CL", "cs.IR"], "comment": "CVPR 2025", "summary": "Document image retrieval (DIR) aims to retrieve document images from a gallery according to a given query. Existing DIR methods are primarily based on image queries that retrieve documents within the same coarse semantic category, e.g., newspapers or receipts. However, these methods struggle to effectively retrieve document images in real-world scenarios where textual queries with fine-grained semantics are usually provided. To bridge this gap, we introduce a new Natural Language-based Document Image Retrieval (NL-DIR) benchmark with corresponding evaluation metrics. In this work, natural language descriptions serve as semantically rich queries for the DIR task. The NL-DIR dataset contains 41K authentic document images, each paired with five high-quality, fine-grained semantic queries generated and evaluated through large language models in conjunction with manual verification. We perform zero-shot and fine-tuning evaluations of existing mainstream contrastive vision-language models and OCR-free visual document understanding (VDU) models. A two-stage retrieval method is further investigated for performance improvement while achieving both time and space efficiency. We hope the proposed NL-DIR benchmark can bring new opportunities and facilitate research for the VDU community. Datasets and codes will be publicly available at huggingface.co/datasets/nianbing/NL-DIR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u7684\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u6587\u6863\u56fe\u50cf\u68c0\u7d22\uff08NL - DIR\uff09\u57fa\u51c6\uff0c\u542b\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u6307\u6807\uff0c\u5bf9\u73b0\u6709\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u7814\u7a76\u4e24\u9636\u6bb5\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e0c\u671b\u4e3aVDU\u793e\u533a\u5e26\u6765\u65b0\u673a\u9047\u3002", "motivation": "\u73b0\u6709\u6587\u6863\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5\u96be\u5904\u7406\u5177\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7684\u6587\u672c\u67e5\u8be2\uff0c\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5f15\u5165NL - DIR\u57fa\u51c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u4f5c\u67e5\u8be2\uff1b\u6784\u5efa\u542b41K\u6587\u6863\u56fe\u50cf\u53ca\u5bf9\u5e94\u67e5\u8be2\u7684\u6570\u636e\u96c6\uff1b\u5bf9\u4e3b\u6d41\u5bf9\u6bd4\u89c6\u89c9 - \u8bed\u8a00\u6a21\u578b\u548c\u65e0OCR\u89c6\u89c9\u6587\u6863\u7406\u89e3\u6a21\u578b\u8fdb\u884c\u96f6\u6837\u672c\u548c\u5fae\u8c03\u8bc4\u4f30\uff1b\u7814\u7a76\u4e24\u9636\u6bb5\u68c0\u7d22\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86NL - DIR\u6570\u636e\u96c6\uff0c\u5bf9\u73b0\u6709\u6a21\u578b\u8bc4\u4f30\uff0c\u7814\u7a76\u51fa\u4e24\u9636\u6bb5\u68c0\u7d22\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\u5e76\u517c\u987e\u65f6\u7a7a\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684NL - DIR\u57fa\u51c6\u80fd\u4e3aVDU\u793e\u533a\u5e26\u6765\u65b0\u673a\u4f1a\uff0c\u63a8\u52a8\u76f8\u5173\u7814\u7a76\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5c06\u516c\u5f00\u3002"}}
{"id": "2512.20074", "pdf": "https://arxiv.org/pdf/2512.20074", "abs": "https://arxiv.org/abs/2512.20074", "authors": ["H M Quamran Hasan", "Housam Khalifa Bashier", "Jiayi Dai", "Mi-Young Kim", "Randy Goebel"], "title": "Reason2Decide: Rationale-Driven Multi-Task Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.", "AI": {"tldr": "\u63d0\u51faReason2Decide\u6846\u67b6\u89e3\u51b3\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u9884\u6d4b\u4e0e\u89e3\u91ca\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u591a\u533b\u7597\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\uff0c\u51cf\u5c11\u5bf9\u4eba\u5de5\u6807\u6ce8\u4f9d\u8d56\u4e14\u9002\u5408\u8d44\u6e90\u53d7\u9650\u90e8\u7f72\u3002", "motivation": "\u89e3\u51b3\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5728\u5b9e\u73b0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u751f\u6210\u4e0e\u9884\u6d4b\u4e00\u81f4\u7684\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u514b\u670d\u5f53\u524d\u65b9\u6cd5\u7684\u66b4\u9732\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6Reason2Decide\uff0c\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u7406\u7531\u751f\u6210\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8054\u5408\u8bad\u7ec3\u6807\u7b7e\u9884\u6d4b\u548c\u7406\u7531\u751f\u6210\uff0c\u91c7\u7528\u8ba1\u5212\u91c7\u6837\u3002", "result": "\u5728\u591a\u4e2a\u533b\u7597\u6570\u636e\u96c6\u4e0a\uff0cReason2Decide\u5728\u9884\u6d4b\u548c\u7406\u7531\u4fdd\u771f\u5ea6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u5fae\u8c03\u57fa\u7ebf\u548c\u4e00\u4e9b\u96f6\u6837\u672c\u5927\u6a21\u578b\uff0c\u5728\u5206\u8bca\u4e2d\u5bf9\u4e0d\u540c\u6765\u6e90\u7406\u7531\u6709\u9c81\u68d2\u6027\uff0c\u4f7f\u7528\u5927\u6a21\u578b\u751f\u6210\u7406\u7531\u9884\u8bad\u7ec3\u8868\u73b0\u597d\u3002", "conclusion": "Reason2Decide\u80fd\u89e3\u51b3\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u5173\u952e\u95ee\u9898\uff0c\u51cf\u5c11\u5bf9\u4eba\u5de5\u6807\u6ce8\u4f9d\u8d56\uff0c\u4e14\u5c0f\u6a21\u578b\u4e5f\u80fd\u53d6\u5f97\u597d\u6548\u679c\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u90e8\u7f72\u3002"}}
{"id": "2512.19725", "pdf": "https://arxiv.org/pdf/2512.19725", "abs": "https://arxiv.org/abs/2512.19725", "authors": ["Srishti Gupta", "Riccardo Balia", "Daniele Angioni", "Fabio Brau", "Maura Pintor", "Ambra Demontis", "Alessandro Sebastian", "Salvatore Mario Carta", "Fabio Roli", "Battista Biggio"], "title": "Out-of-Distribution Detection for Continual Learning: Design Principles and Benchmarking", "categories": ["cs.LG"], "comment": "International Journal of Computer Vision", "summary": "Recent years have witnessed significant progress in the development of machine learning models across a wide range of fields, fueled by increased computational resources, large-scale datasets, and the rise of deep learning architectures. From malware detection to enabling autonomous navigation, modern machine learning systems have demonstrated remarkable capabilities. However, as these models are deployed in ever-changing real-world scenarios, their ability to remain reliable and adaptive over time becomes increasingly important. For example, in the real world, new malware families are continuously developed, whereas autonomous driving cars are employed in many different cities and weather conditions. Models trained in fixed settings can not respond effectively to novel conditions encountered post-deployment. In fact, most machine learning models are still developed under the assumption that training and test data are independent and identically distributed (i.i.d.), i.e., sampled from the same underlying (unknown) distribution. While this assumption simplifies model development and evaluation, it does not hold in many real-world applications, where data changes over time and unexpected inputs frequently occur. Retraining models from scratch whenever new data appears is computationally expensive, time-consuming, and impractical in resource-constrained environments. These limitations underscore the need for Continual Learning (CL), which enables models to incrementally learn from evolving data streams without forgetting past knowledge, and Out-of-Distribution (OOD) detection, which allows systems to identify and respond to novel or anomalous inputs. Jointly addressing both challenges is critical to developing robust, efficient, and adaptive AI systems.", "AI": {"tldr": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u9762\u4e34\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\u95ee\u9898\uff0c\u9700\u6301\u7eed\u5b66\u4e60\u548c\u5206\u5e03\u5916\u68c0\u6d4b\u6765\u5e94\u5bf9\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u6570\u636e\u53d8\u5316\u548c\u5206\u5e03\u4e0d\u540c\uff0c\u96be\u4ee5\u4fdd\u6301\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\uff0c\u4f20\u7edf\u8bad\u7ec3\u65b9\u6cd5\u6210\u672c\u9ad8\u4e14\u4e0d\u5b9e\u7528\uff0c\u6240\u4ee5\u9700\u8981\u65b0\u65b9\u6cd5\u3002", "method": "\u672a\u63d0\u53ca\u5177\u4f53\u65b9\u6cd5\u3002", "result": "\u672a\u63d0\u53ca\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u8054\u5408\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u548c\u5206\u5e03\u5916\u68c0\u6d4b\u95ee\u9898\u5bf9\u5f00\u53d1\u5f3a\u5927\u3001\u9ad8\u6548\u548c\u81ea\u9002\u5e94\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2512.19855", "pdf": "https://arxiv.org/pdf/2512.19855", "abs": "https://arxiv.org/abs/2512.19855", "authors": ["Andrew Stirling", "Mykola Lukashchuk", "Dmitry Bagaev", "Wouter Kouw", "James R. Forbes"], "title": "Gaussian Variational Inference with Non-Gaussian Factors for State Estimation: A UWB Localization Case Study", "categories": ["cs.RO", "stat.ML"], "comment": null, "summary": "This letter extends the exactly sparse Gaussian variational inference (ESGVI) algorithm for state estimation in two complementary directions. First, ESGVI is generalized to operate on matrix Lie groups, enabling the estimation of states with orientation components while respecting the underlying group structure. Second, factors are introduced to accommodate heavy-tailed and skewed noise distributions, as commonly encountered in ultra-wideband (UWB) localization due to non-line-of-sight (NLOS) and multipath effects. Both extensions are shown to integrate naturally within the ESGVI framework while preserving its sparse and derivative-free structure. The proposed approach is validated in a UWB localization experiment with NLOS-rich measurements, demonstrating improved accuracy and comparable consistency. Finally, a Python implementation within a factor-graph-based estimation framework is made open-source (https://github.com/decargroup/gvi_ws) to support broader research use.", "AI": {"tldr": "\u672c\u6587\u5c06ESGVI\u7b97\u6cd5\u5728\u4e24\u4e2a\u65b9\u5411\u6269\u5c55\uff0c\u7528\u4e8e\u72b6\u6001\u4f30\u8ba1\uff0c\u5728UWB\u5b9a\u4f4d\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u679c\u5e76\u5f00\u6e90\u4ee3\u7801", "motivation": "\u5c06ESGVI\u7b97\u6cd5\u6269\u5c55\u4ee5\u5904\u7406\u542b\u65b9\u5411\u5206\u91cf\u72b6\u6001\u4f30\u8ba1\u53ca\u9002\u5e94\u91cd\u5c3e\u548c\u504f\u6001\u566a\u58f0\u5206\u5e03", "method": "\u5c06ESGVI\u63a8\u5e7f\u5230\u77e9\u9635\u674e\u7fa4\uff0c\u5f15\u5165\u56e0\u5b50\u9002\u5e94\u91cd\u5c3e\u548c\u504f\u6001\u566a\u58f0\u5206\u5e03", "result": "\u5728\u5bcc\u975e\u89c6\u8ddd\u6d4b\u91cf\u7684UWB\u5b9a\u4f4d\u5b9e\u9a8c\u4e2d\u63d0\u9ad8\u4e86\u7cbe\u5ea6\uff0c\u5177\u6709\u76f8\u5f53\u7684\u4e00\u81f4\u6027", "conclusion": "\u6269\u5c55\u80fd\u81ea\u7136\u878d\u5165ESGVI\u6846\u67b6\uff0c\u4fdd\u6301\u5176\u7a00\u758f\u65e0\u5bfc\u6570\u7ed3\u6784\uff0c\u5f00\u6e90\u4ee3\u7801\u652f\u6301\u7814\u7a76\u3002"}}
{"id": "2512.20381", "pdf": "https://arxiv.org/pdf/2512.20381", "abs": "https://arxiv.org/abs/2512.20381", "authors": ["Syeda Tasnim Fabiha", "Saad Shafiq", "Wesley Klewerton Guez Assun\u00e7\u00e3o", "Nenad Medvidovi\u0107"], "title": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning", "categories": ["cs.SE", "cs.AI"], "comment": "22 pages, 6 figures", "summary": "Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684Rake\u6280\u672f\u7528\u4e8e\u4ece\u5b9e\u73b0\u5de5\u4ef6\u4e2d\u8bc6\u522b\u5408\u9002\u5927\u5c0f\u7684\u670d\u52a1\uff0c\u5e94\u7528\u4e8e\u56db\u4e2a\u5f00\u6e90\u9879\u76ee\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5f3a\u8c03\u5e73\u8861\u76ee\u6807\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u5b9a\u4e49\u5408\u9002\u5927\u5c0f\u670d\u52a1\u7684\u65b9\u6cd5\u5728\u5f88\u591a\u73b0\u5b9e\u573a\u666f\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u4f9d\u8d56\u6587\u6863\u3001\u4eba\u5458\u6216\u5148\u9a8c\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684Rake\u6280\u672f\uff0c\u5229\u7528\u7cfb\u7edf\u6587\u6863\u548c\u6e90\u4ee3\u7801\u5728\u5b9e\u73b0\u65b9\u6cd5\u5c42\u9762\u6307\u5bfc\u670d\u52a1\u5206\u89e3\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u76ee\u6807\u51fd\u6570\u3002", "result": "Rake\u5728\u56db\u4e2a\u5f00\u6e90\u9879\u76ee\u4e2d\u5e73\u5747\u6a21\u5757\u5316\u8d28\u91cf\u63d0\u9ad87 - 14%\uff0c\u4e1a\u52a1\u80fd\u529b\u5bf9\u9f50\u5ea6\u63d0\u9ad818 - 22%\u3002", "conclusion": "\u5728\u7d27\u5bc6\u8026\u5408\u7cfb\u7edf\u4e2d\u5355\u7eaf\u4f18\u5316\u4e1a\u52a1\u4e0a\u4e0b\u6587\u4f1a\u964d\u4f4e\u5206\u89e3\u8d28\u91cf\uff0c\u9700\u8981\u5e73\u8861\u76ee\u6807\u3002"}}
{"id": "2512.20485", "pdf": "https://arxiv.org/pdf/2512.20485", "abs": "https://arxiv.org/abs/2512.20485", "authors": ["Tanisha Fonseca", "Gengrui Zhang"], "title": "WOC: Dual-Path Weighted Object Consensus Made Efficient", "categories": ["cs.DC"], "comment": null, "summary": "Modern distributed systems face a critical challenge: existing consensus protocols optimize for either node heterogeneity or workload independence, but not both. For example, Cabinet leverages weighted quorums to handle node heterogeneity but serializes all operations through a global leader, limiting parallelism. EPaxos enables parallel execution for independent operations but treats all nodes uniformly, ignoring performance differences. To tackle this problem, we present WOC, a dual-path consensus protocol that dynamically routes operations into two paths based on their access patterns. Independent operations execute through a fast path that uses object-specific weighted quorums and completes in one network round-trip. Conflicting or shared objects route through a leader-coordinated slow path employing node-weighted consensus. Our evaluation demonstrates that WOC achieves up to 4X higher throughput than Cabinet for workloads with >70% independent objects, while maintaining equivalent performance under high contention.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u8def\u5f84\u5171\u8bc6\u534f\u8baeWOC\uff0c\u53ef\u6839\u636e\u64cd\u4f5c\u8bbf\u95ee\u6a21\u5f0f\u8def\u7531\u64cd\u4f5c\uff0c\u5728\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u541e\u5410\u91cf\u6bd4Cabinet\u9ad84\u500d\u3002", "motivation": "\u73b0\u6709\u5171\u8bc6\u534f\u8bae\u53ea\u80fd\u4f18\u5316\u8282\u70b9\u5f02\u6784\u6027\u6216\u5de5\u4f5c\u8d1f\u8f7d\u72ec\u7acb\u6027\u5176\u4e2d\u4e4b\u4e00\uff0c\u4e0d\u80fd\u517c\u987e\u3002", "method": "\u63d0\u51faWOC\u534f\u8bae\uff0c\u6839\u636e\u64cd\u4f5c\u8bbf\u95ee\u6a21\u5f0f\u5c06\u64cd\u4f5c\u52a8\u6001\u8def\u7531\u5230\u4e24\u6761\u8def\u5f84\uff0c\u72ec\u7acb\u64cd\u4f5c\u8d70\u5feb\u901f\u8def\u5f84\uff0c\u51b2\u7a81\u6216\u5171\u4eab\u5bf9\u8c61\u8d70\u6162\u901f\u8def\u5f84\u3002", "result": "\u5bf9\u4e8e\u72ec\u7acb\u5bf9\u8c61\u8d8570%\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0cWOC\u541e\u5410\u91cf\u6bd4Cabinet\u9ad84\u500d\uff0c\u9ad8\u7ade\u4e89\u4e0b\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "WOC\u534f\u8bae\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5171\u8bc6\u534f\u8bae\u4e0d\u80fd\u517c\u987e\u8282\u70b9\u5f02\u6784\u6027\u548c\u5de5\u4f5c\u8d1f\u8f7d\u72ec\u7acb\u6027\u7684\u95ee\u9898\u3002"}}
{"id": "2512.20082", "pdf": "https://arxiv.org/pdf/2512.20082", "abs": "https://arxiv.org/abs/2512.20082", "authors": ["Chaithra", "Kamesh Kadimisetty", "Biju R Mohan"], "title": "Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches", "categories": ["cs.AI"], "comment": "Accepted in CODS 2025", "summary": "Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u80a1\u5e02\u53cd\u9988\u7684\u81ea\u9002\u5e94\u6846\u67b6\u7528\u4e8e\u5370\u5ea6\u80a1\u5e02\u60c5\u611f\u5206\u7c7b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7cfb\u7edf\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u91d1\u878d\u60c5\u611f\u5206\u6790\u5de5\u4f5c\u672a\u8003\u8651\u80a1\u4ef7\u6216\u5e02\u573a\u53cd\u9988\u5f71\u54cd\uff0c\u4e3a\u63d0\u9ad8\u60c5\u611f\u5206\u7c7b\u51c6\u786e\u6027\u800c\u5f00\u5c55\u7814\u7a76\u3002", "method": "\u5229\u7528\u6307\u4ee4\u5b66\u4e60\u5728SentiFin\u6570\u636e\u96c6\u4e0a\u5fae\u8c03LLaMA 3.2 3B\u6a21\u578b\uff1b\u91c7\u7528RAG\u7ba1\u9053\u52a8\u6001\u9009\u62e9\u591a\u6e90\u4e0a\u4e0b\u6587\u4fe1\u606f\uff1b\u5f15\u5165\u53cd\u9988\u9a71\u52a8\u6a21\u5757\u8c03\u6574\u6570\u636e\u6e90\u53ef\u9760\u6027\uff1b\u7ed3\u5408\u57fa\u4e8ePPO\u8bad\u7ec3\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u4f18\u5316\u6e90\u6743\u91cd\u7b56\u7565\u3002", "result": "\u57282024 - 2025\u5e74NIFTY 50\u65b0\u95fb\u5934\u6761\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u3001F1\u5206\u6570\u548c\u5e02\u573a\u4e00\u81f4\u6027\u3002", "conclusion": "\u7ed3\u5408\u6307\u4ee4\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u3001\u52a8\u6001\u53cd\u9988\u548c\u5f3a\u5316\u5b66\u4e60\u53ef\u7528\u4e8e\u6784\u5efa\u5065\u58ee\u7684\u3001\u5177\u6709\u5e02\u573a\u611f\u77e5\u80fd\u529b\u7684\u91d1\u878d\u60c5\u611f\u6a21\u578b\u3002"}}
{"id": "2512.19726", "pdf": "https://arxiv.org/pdf/2512.19726", "abs": "https://arxiv.org/abs/2512.19726", "authors": ["Carlos Purves"], "title": "Tiny, On-Device Decision Makers with the MiniConv Library", "categories": ["cs.LG", "cs.AI"], "comment": "14 Pages, 5 Figures", "summary": "Reinforcement learning (RL) has achieved strong results, but deploying visual policies on resource-constrained edge devices remains challenging due to computational cost and communication latency. Many deployments therefore offload policy inference to a remote server, incurring network round trips and requiring transmission of high-dimensional observations. We introduce a split-policy architecture in which a small on-device encoder, implemented as OpenGL fragment-shader passes for broad embedded GPU support, transforms each observation into a compact feature tensor that is transmitted to a remote policy head. In RL, this communication overhead manifests as closed-loop decision latency rather than only per-request inference latency. The proposed approach reduces transmitted data, lowers decision latency in bandwidth-limited settings, and reduces server-side compute per request, whilst achieving broadly comparable learning performance by final return (mean over the final 100 episodes) in single-run benchmarks, with modest trade-offs in mean return. We evaluate across an NVIDIA Jetson Nano, a Raspberry Pi 4B, and a Raspberry Pi Zero 2 W, reporting learning results, on-device execution behaviour under sustained load, and end-to-end decision latency and scalability measurements under bandwidth shaping. Code for training, deployment, and measurement is released as open source.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5272\u7b56\u7565\u67b6\u6784\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u89c6\u89c9\u7b56\u7565\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u96be\u9898\uff0c\u5728\u964d\u4f4e\u6570\u636e\u4f20\u8f93\u3001\u51b3\u7b56\u5ef6\u8fdf\u7b49\u65b9\u9762\u6709\u6548\u679c\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u89c6\u89c9\u7b56\u7565\u5728\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u56e0\u8ba1\u7b97\u6210\u672c\u548c\u901a\u4fe1\u5ef6\u8fdf\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u5378\u8f7d\u7b56\u7565\u5b58\u5728\u95ee\u9898\u3002", "method": "\u5f15\u5165\u5206\u5272\u7b56\u7565\u67b6\u6784\uff0c\u7528OpenGL\u7247\u6bb5\u7740\u8272\u5668\u5b9e\u73b0\u8bbe\u5907\u7aef\u7f16\u7801\u5668\u5c06\u89c2\u6d4b\u8f6c\u6362\u4e3a\u7d27\u51d1\u7279\u5f81\u5f20\u91cf\u4f20\u8f93\u7ed9\u8fdc\u7a0b\u7b56\u7565\u5934\u3002", "result": "\u51cf\u5c11\u4f20\u8f93\u6570\u636e\u3001\u964d\u4f4e\u5e26\u5bbd\u53d7\u9650\u573a\u666f\u4e0b\u51b3\u7b56\u5ef6\u8fdf\u548c\u670d\u52a1\u5668\u7aef\u8ba1\u7b97\u91cf\uff0c\u5355\u6b21\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6700\u7ec8\u56de\u62a5\u5b66\u4e60\u6027\u80fd\u76f8\u5f53\u3002\u5728\u591a\u79cd\u8bbe\u5907\u8bc4\u4f30\uff0c\u516c\u5f00\u4ee3\u7801\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5272\u7b56\u7565\u67b6\u6784\u80fd\u6709\u6548\u89e3\u51b3\u8fb9\u7f18\u8bbe\u5907\u5f3a\u5316\u5b66\u4e60\u89c6\u89c9\u7b56\u7565\u90e8\u7f72\u95ee\u9898\uff0c\u6709\u4e00\u5b9a\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.19861", "pdf": "https://arxiv.org/pdf/2512.19861", "abs": "https://arxiv.org/abs/2512.19861", "authors": ["Anna Guo", "David Benkeser", "Razieh Nabi"], "title": "Causal Inference with the \"Napkin Graph\"", "categories": ["stat.ME", "stat.ML"], "comment": null, "summary": "Unmeasured confounding can render identification strategies based on adjustment functionals invalid. We study the \"Napkin graph\", a causal structure that encapsulates patterns of M-bias, instrumental variables, and the classical back-door and front-door models within a single graphical framework, yet requires a nonstandard identification strategy: the average treatment effect is expressed as a ratio of two g-formulas. We develop novel estimators for this functional, including doubly robust one-step and targeted minimum loss-based estimators that remain asymptotically linear when nuisance functions are estimated at slower-than-parametric rates using machine learning. We also show how a generalized independence restriction encoded by the Napkin graph, known as a Verma constraint, can be exploited to improve efficiency, illustrating more generally how such constraints in hidden variable DAGs can inform semiparametric inference. The proposed methods are validated through simulations and applied to the Finnish Life Course study to estimate the effect of educational attainment on income. An accompanying R package, napkincausal, implements all proposed procedures.", "AI": {"tldr": "\u7814\u7a76\u2018\u9910\u5dfe\u56fe\u2019\u56e0\u679c\u7ed3\u6784\uff0c\u63d0\u51fa\u65b0\u4f30\u8ba1\u91cf\uff0c\u5229\u7528Verma\u7ea6\u675f\u63d0\u9ad8\u6548\u7387\uff0c\u7ecf\u6a21\u62df\u9a8c\u8bc1\u5e76\u5e94\u7528\u4e8e\u82ac\u5170\u7814\u7a76\uff0c\u6709R\u5305\u5b9e\u73b0\u3002", "motivation": "\u672a\u6d4b\u91cf\u7684\u6df7\u6742\u56e0\u7d20\u4f1a\u4f7f\u57fa\u4e8e\u8c03\u6574\u51fd\u6570\u7684\u8bc6\u522b\u7b56\u7565\u5931\u6548\uff0c\u9700\u7814\u7a76\u65b0\u7684\u8bc6\u522b\u7b56\u7565\u3002", "method": "\u7814\u7a76\u2018\u9910\u5dfe\u56fe\u2019\uff0c\u5f00\u53d1\u65b0\u7684\u529f\u80fd\u4f30\u8ba1\u91cf\uff0c\u5305\u62ec\u53cc\u7a33\u5065\u5355\u6b65\u548c\u76ee\u6807\u6700\u5c0f\u635f\u5931\u4f30\u8ba1\u91cf\uff0c\u5229\u7528Verma\u7ea6\u675f\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\uff0c\u5e94\u7528\u4e8e\u82ac\u5170\u751f\u547d\u5386\u7a0b\u7814\u7a76\u4f30\u8ba1\u6559\u80b2\u7a0b\u5ea6\u5bf9\u6536\u5165\u7684\u5f71\u54cd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0cR\u5305napkincausal\u53ef\u5b9e\u73b0\u6240\u6709\u7a0b\u5e8f\u3002"}}
{"id": "2512.20482", "pdf": "https://arxiv.org/pdf/2512.20482", "abs": "https://arxiv.org/abs/2512.20482", "authors": ["Revanth Gangi Reddy", "Ye Liu", "Wenting Zhao", "JaeHyeok Doo", "Tarun Suresh", "Daniel Lee", "Caiming Xiong", "Yingbo Zhou", "Semih Yavuz", "Shafiq Joty"], "title": "SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Maintaining large-scale, multilingual codebases hinges on accurately localizing issues, which requires mapping natural-language error descriptions to the relevant functions that need to be modified. However, existing ranking approaches are often Python-centric and perform a single-pass search over the codebase. This work introduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code ranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn reasoning over the code repository. SweRankMulti comprises a code embedding retriever and a listwise LLM reranker, and is trained using a carefully curated large-scale issue localization dataset spanning multiple popular programming languages. SweRankAgent adopts an agentic search loop that moves beyond single-shot localization with a memory buffer to reason and accumulate relevant localization candidates over multiple turns. Our experiments on issue localization benchmarks spanning various languages demonstrate new state-of-the-art performance with SweRankMulti, while SweRankAgent further improves localization over single-pass ranking.", "AI": {"tldr": "\u63d0\u51faSweRank+\u6846\u67b6\u7528\u4e8e\u591a\u8bed\u8a00\u4ee3\u7801\u5e93\u95ee\u9898\u5b9a\u4f4d\uff0c\u542bSweRankMulti\u548cSweRankAgent\uff0c\u5b9e\u9a8c\u8fbe\u65b0SOTA\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u5e93\u95ee\u9898\u5b9a\u4f4d\u6392\u540d\u65b9\u6cd5\u591a\u4ee5Python\u4e3a\u4e3b\u4e14\u5355\u904d\u641c\u7d22\uff0c\u9700\u66f4\u597d\u65b9\u6cd5\u3002", "method": "\u5f15\u5165SweRank+\u6846\u67b6\uff0cSweRankMulti\u542b\u4ee3\u7801\u5d4c\u5165\u68c0\u7d22\u5668\u548c\u5217\u8868\u5f0fLLM\u91cd\u6392\u5668\u5e76\u5728\u591a\u8bed\u8a00\u6570\u636e\u96c6\u8bad\u7ec3\uff0cSweRankAgent\u91c7\u7528\u4ee3\u7406\u641c\u7d22\u5faa\u73af\u3002", "result": "SweRankMulti\u5728\u95ee\u9898\u5b9a\u4f4d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0cSweRankAgent\u8fdb\u4e00\u6b65\u63d0\u5347\u5b9a\u4f4d\u6548\u679c\u3002", "conclusion": "SweRank+\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u591a\u8bed\u8a00\u4ee3\u7801\u5e93\u95ee\u9898\u5b9a\u4f4d\uff0c\u4f18\u4e8e\u73b0\u6709\u5355\u904d\u6392\u540d\u65b9\u6cd5\u3002"}}
{"id": "2512.19777", "pdf": "https://arxiv.org/pdf/2512.19777", "abs": "https://arxiv.org/abs/2512.19777", "authors": ["Antonio Tarizzo", "Mohammad Kazemi", "Deniz G\u00fcnd\u00fcz"], "title": "Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning", "categories": ["cs.IT", "cs.AI", "cs.DC"], "comment": null, "summary": "Federated edge learning (FEEL) enables wireless devices to collaboratively train a centralised model without sharing raw data, but repeated uplink transmission of model updates makes communication the dominant bottleneck. Over-the-air (OTA) aggregation alleviates this by exploiting the superposition property of the wireless channel, enabling simultaneous transmission and merging communication with computation. Digital OTA schemes extend this principle by incorporating the robustness of conventional digital communication, but current designs remain limited in low signal-to-noise ratio (SNR) regimes. This work proposes a learned digital OTA framework that improves recovery accuracy, convergence behaviour, and robustness to challenging SNR conditions while maintaining the same uplink overhead as state-of-the-art methods. The design integrates an unsourced random access (URA) codebook with vector quantisation and AMP-DA-Net, an unrolled approximate message passing (AMP)-style decoder trained end-to-end with the digital codebook and parameter server local training statistics. The proposed design extends OTA aggregation beyond averaging to a broad class of symmetric functions, including trimmed means and majority-based rules. Experiments on highly heterogeneous device datasets and varying numbers of active devices show that the proposed design extends reliable digital OTA operation by more than 10 dB into low SNR regimes while matching or improving performance across the full SNR range. The learned decoder remains effective under message corruption and nonlinear aggregation, highlighting the broader potential of end-to-end learned design for digital OTA communication in FEEL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5b66\u4e60\u578b\u6570\u5b57OTA\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u6062\u590d\u7cbe\u5ea6\u3001\u6536\u655b\u6027\u548c\u5bf9\u4f4e\u4fe1\u566a\u6bd4\u7684\u9c81\u68d2\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\u4e2d\u91cd\u590d\u7684\u6a21\u578b\u66f4\u65b0\u4e0a\u884c\u4f20\u8f93\u4f7f\u901a\u4fe1\u6210\u4e3a\u74f6\u9888\uff0c\u73b0\u6709\u6570\u5b57OTA\u65b9\u6848\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u6709\u5c40\u9650\u3002", "method": "\u5c06\u65e0\u4fe1\u6e90\u968f\u673a\u63a5\u5165\uff08URA\uff09\u7801\u672c\u4e0e\u77e2\u91cf\u91cf\u5316\u548cAMP - DA - Net\u96c6\u6210\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u89e3\u7801\u5668\uff0c\u5e76\u5c06OTA\u805a\u5408\u6269\u5c55\u5230\u5bf9\u79f0\u51fd\u6570\u3002", "result": "\u5728\u9ad8\u5ea6\u5f02\u6784\u8bbe\u5907\u6570\u636e\u96c6\u548c\u4e0d\u540c\u6570\u91cf\u6d3b\u8dc3\u8bbe\u5907\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u8bbe\u8ba1\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u53ef\u9760\u8fd0\u884c\u8303\u56f4\u6269\u5c55\u8d8510dB\uff0c\u5168\u4fe1\u566a\u6bd4\u8303\u56f4\u6027\u80fd\u5339\u914d\u6216\u63d0\u5347\u3002", "conclusion": "\u7aef\u5230\u7aef\u5b66\u4e60\u8bbe\u8ba1\u5728\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\u7684\u6570\u5b57OTA\u901a\u4fe1\u4e2d\u6709\u66f4\u5e7f\u6cdb\u6f5c\u529b\u3002"}}
{"id": "2512.20135", "pdf": "https://arxiv.org/pdf/2512.20135", "abs": "https://arxiv.org/abs/2512.20135", "authors": ["Zhuo Yang", "Yeyun chen", "Jiaqing Xie", "Ben Gao", "Shuaike Shen", "Wanhao Liu", "Liujia Yang", "Beilun Wang", "Tianfan Fu", "Yuqiang Li"], "title": "MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed \"thinking\" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open \"thinking\" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed \"thinking\" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.", "AI": {"tldr": "\u63d0\u51faMolAct\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u5206\u5b50\u7f16\u8f91\u548c\u4f18\u5316\u95ee\u9898\uff0c\u8bad\u7ec3\u4e24\u79cd\u6a21\u578b\uff0c\u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u5206\u5b50\u7f16\u8f91\u548c\u4f18\u5316\u4e2d\u9700\u8fed\u4ee3\u6539\u5584\u5c5e\u6027\u5e76\u4fdd\u6301\u5206\u5b50\u5316\u5b66\u6709\u6548\u6027\u548c\u7ed3\u6784\u76f8\u4f3c\u6027\u7684\u591a\u6b65\u95ee\u9898\u3002", "method": "\u5c06\u4efb\u52a1\u89c6\u4e3a\u987a\u5e8f\u3001\u5de5\u5177\u5f15\u5bfc\u7684\u51b3\u7b56\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff0c\u6846\u67b6\u4f7f\u667a\u80fd\u4f53\u591a\u8f6e\u4ea4\u4e92\u5e76\u5229\u7528\u5316\u5b66\u5de5\u5177\u53cd\u9988\u4f18\u5316\u540e\u7eed\u7f16\u8f91\u3002", "result": "MolEditAgent\u5728\u5206\u5b50\u7f16\u8f91\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0cMolOptAgent\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\u8d85\u8d8a\u90e8\u5206\u57fa\u7ebf\u3002", "conclusion": "\u5c06\u5206\u5b50\u8bbe\u8ba1\u89c6\u4e3a\u591a\u6b65\u3001\u5de5\u5177\u589e\u5f3a\u8fc7\u7a0b\u662f\u5b9e\u73b0\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u6539\u8fdb\u7684\u5173\u952e\u3002"}}
{"id": "2512.19727", "pdf": "https://arxiv.org/pdf/2512.19727", "abs": "https://arxiv.org/abs/2512.19727", "authors": ["Peng-Hung Tsai", "Daniel Berleant"], "title": "Trend Extrapolation for Technology Forecasting: Leveraging LSTM Neural Networks for Trend Analysis of Space Exploration Vessels", "categories": ["cs.LG"], "comment": null, "summary": "Forecasting technological advancement in complex domains such as space exploration presents significant challenges due to the intricate interaction of technical, economic, and policy-related factors. The field of technology forecasting has long relied on quantitative trend extrapolation techniques, such as growth curves (e.g., Moore's law) and time series models, to project technological progress. To assess the current state of these methods, we conducted an updated systematic literature review (SLR) that incorporates recent advances. This review highlights a growing trend toward machine learning-based hybrid models.\n  Motivated by this review, we developed a forecasting model that combines long short-term memory (LSTM) neural networks with an augmentation of Moore's law to predict spacecraft lifetimes. Operational lifetime is an important engineering characteristic of spacecraft and a potential proxy for technological progress in space exploration. Lifetimes were modeled as depending on launch date and additional predictors.\n  Our modeling analysis introduces a novel advance in the recently introduced Start Time End Time Integration (STETI) approach. STETI addresses a critical right censoring problem known to bias lifetime analyses: the more recent the launch dates, the shorter the lifetimes of the spacecraft that have failed and can thus contribute lifetime data. Longer-lived spacecraft are still operating and therefore do not contribute data. This systematically distorts putative lifetime versus launch date curves by biasing lifetime estimates for recent launch dates downward. STETI mitigates this distortion by interconverting between expressing lifetimes as functions of launch time and modeling them as functions of failure time. The results provide insights relevant to space mission planning and policy decision-making.", "AI": {"tldr": "\u6587\u7ae0\u901a\u8fc7\u66f4\u65b0\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u8bc4\u4f30\u6280\u672f\u9884\u6d4b\u65b9\u6cd5\uff0c\u5f00\u53d1\u7ed3\u5408LSTM\u795e\u7ecf\u7f51\u7edc\u4e0e\u6469\u5c14\u5b9a\u5f8b\u62d3\u5c55\u7684\u6a21\u578b\u9884\u6d4b\u822a\u5929\u5668\u5bff\u547d\uff0c\u6539\u8fdbSTETI\u65b9\u6cd5\u5904\u7406\u6570\u636e\u504f\u5dee\uff0c\u7ed3\u679c\u5bf9\u822a\u5929\u4efb\u52a1\u89c4\u5212\u548c\u653f\u7b56\u5236\u5b9a\u6709\u6307\u5bfc\u610f\u4e49\u3002", "motivation": "\u590d\u6742\u9886\u57df\u6280\u672f\u9884\u6d4b\u5b58\u5728\u6311\u6218\uff0c\u9700\u8bc4\u4f30\u73b0\u6709\u6280\u672f\u9884\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u9884\u6d4b\u592a\u7a7a\u63a2\u7d22\u6280\u672f\u8fdb\u6b65\u3002", "method": "\u8fdb\u884c\u66f4\u65b0\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u5f00\u53d1\u7ed3\u5408LSTM\u795e\u7ecf\u7f51\u7edc\u4e0e\u6469\u5c14\u5b9a\u5f8b\u62d3\u5c55\u7684\u6a21\u578b\uff0c\u6539\u8fdbSTETI\u65b9\u6cd5\u5904\u7406\u53f3\u5220\u5931\u95ee\u9898\u3002", "result": "\u7814\u7a76\u83b7\u5f97\u4e86\u53ef\u4ee5\u4e3a\u592a\u7a7a\u4efb\u52a1\u89c4\u5212\u548c\u653f\u7b56\u51b3\u7b56\u63d0\u4f9b\u53c2\u8003\u7684\u76f8\u5173\u7ed3\u679c\u3002", "conclusion": "\u7814\u7a76\u65b9\u6cd5\u6709\u52a9\u4e8e\u89e3\u51b3\u822a\u5929\u5668\u5bff\u547d\u9884\u6d4b\u95ee\u9898\uff0c\u5bf9\u822a\u5929\u9886\u57df\u89c4\u5212\u548c\u51b3\u7b56\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.20039", "pdf": "https://arxiv.org/pdf/2512.20039", "abs": "https://arxiv.org/abs/2512.20039", "authors": ["Shubhanshu Shekhar"], "title": "Optimal Anytime-Valid Tests for Composite Nulls", "categories": ["math.ST", "cs.IT", "cs.LG", "stat.ML"], "comment": "24 pages, 1 figure", "summary": "We consider the problem of designing optimal level-$\u03b1$ power-one tests for composite nulls. Given a parameter $\u03b1\\in (0,1)$ and a stream of $\\mathcal{X}$-valued observations $\\{X_n: n \\geq 1\\} \\overset{i.i.d.}{\\sim} P$, the goal is to design a level-$\u03b1$ power-one test $\u03c4_\u03b1$ for the null $H_0: P \\in \\mathcal{P}_0 \\subset \\mathcal{P}(\\mathcal{X})$. Prior works have shown that any such $\u03c4_\u03b1$ must satisfy $\\mathbb{E}_P[\u03c4_\u03b1] \\geq \\tfrac{\\log(1/\u03b1)}{\u03b3^*(P, \\mathcal{P}_0)}$, where $\u03b3^*(P, \\mathcal{P}_0)$ is the so-called $\\mathrm{KL}_{\\inf}$ or minimum divergence of $P$ to the null class. In this paper, our objective is to develop and analyze constructive schemes that match this lower bound as $\u03b1\\downarrow 0$.\n  We first consider the finite-alphabet case~($|\\mathcal{X}| = m < \\infty$), and show that a test based on \\emph{universal} $e$-process~(formed by the ratio of a universal predictor and the running null MLE) is optimal in the above sense. The proof relies on a Donsker-Varadhan~(DV) based saddle-point representation of $\\mathrm{KL}_{\\inf}$, and an application of Sion's minimax theorem. This characterization motivates a general method for arbitrary $\\mathcal{X}$: construct an $e$-process based on the empirical solutions to the saddle-point representation over a sufficiently rich class of test functions. We give sufficient conditions for the optimality of this test for compact convex nulls, and verify them for H\u00f6lder smooth density models. We end the paper with a discussion on the computational aspects of implementing our proposed tests in some practical settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u590d\u5408\u539f\u5047\u8bbe\u4e0b\u6700\u4f18\u6c34\u5e73 - \u03b1 \u529f\u6548 - 1 \u68c0\u9a8c\u7684\u8bbe\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u6784\u9020\u6027\u65b9\u6848\u4ee5\u5339\u914d\u5df2\u77e5\u4e0b\u754c\uff0c\u5728\u6709\u9650\u5b57\u6bcd\u8868\u60c5\u51b5\u8bc1\u660e\u4e00\u79cd\u68c0\u9a8c\u65b9\u6cd5\u7684\u6700\u4f18\u6027\uff0c\u5e76\u7ed9\u51fa\u4efb\u610f\u5b57\u6bcd\u8868\u60c5\u51b5\u4e0b\u7684\u901a\u7528\u65b9\u6cd5\u53ca\u5145\u5206\u6761\u4ef6\uff0c\u6700\u540e\u8ba8\u8bba\u5b9e\u9645\u8ba1\u7b97\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7ed9\u51fa\u6c34\u5e73 - \u03b1 \u529f\u6548 - 1 \u68c0\u9a8c\u7684\u4e0b\u754c\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u80fd\u5728 \u03b1 \u8d8b\u8fd1\u4e8e 0 \u65f6\u8fbe\u5230\u8be5\u4e0b\u754c\u7684\u6784\u9020\u6027\u65b9\u6848\u3002", "method": "\u5148\u8003\u8651\u6709\u9650\u5b57\u6bcd\u8868\u60c5\u51b5\uff0c\u5229\u7528\u57fa\u4e8e\u901a\u7528 e - \u8fc7\u7a0b\u7684\u68c0\u9a8c\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7 Donsker - Varadhan \u978d\u70b9\u8868\u793a\u548c Sion \u6781\u5c0f\u6781\u5927\u5b9a\u7406\u8bc1\u660e\u5176\u6700\u4f18\u6027\u3002\u7136\u540e\u9488\u5bf9\u4efb\u610f\u5b57\u6bcd\u8868\u60c5\u51b5\uff0c\u57fa\u4e8e\u5bf9\u4e30\u5bcc\u6d4b\u8bd5\u51fd\u6570\u7c7b\u7684\u978d\u70b9\u8868\u793a\u7684\u7ecf\u9a8c\u89e3\u6784\u9020 e - \u8fc7\u7a0b\u3002", "result": "\u8bc1\u660e\u4e86\u6709\u9650\u5b57\u6bcd\u8868\u60c5\u51b5\u4e0b\u57fa\u4e8e\u901a\u7528 e - \u8fc7\u7a0b\u7684\u68c0\u9a8c\u65b9\u6cd5\u7684\u6700\u4f18\u6027\uff0c\u7ed9\u51fa\u4efb\u610f\u5b57\u6bcd\u8868\u60c5\u51b5\u4e0b\u9488\u5bf9\u7d27\u81f4\u51f8\u539f\u5047\u8bbe\u68c0\u9a8c\u6700\u4f18\u6027\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u5728 H\u00f6lder \u5149\u6ed1\u5bc6\u5ea6\u6a21\u578b\u4e2d\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u7684\u6784\u9020\u6027\u65b9\u6848\u80fd\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\u5339\u914d\u6c34\u5e73 - \u03b1 \u529f\u6548 - 1 \u68c0\u9a8c\u7684\u4e0b\u754c\uff0c\u8fd8\u8ba8\u8bba\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u95ee\u9898\u3002"}}
{"id": "2512.20363", "pdf": "https://arxiv.org/pdf/2512.20363", "abs": "https://arxiv.org/abs/2512.20363", "authors": ["Daniel M. Jimenez-Gutierrez", "Mehrdad Hassanzadeh", "Aris Anagnostopoulos", "Ioannis Chatzigiannakis", "Andrea Vitaletti"], "title": "Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.DC", "stat.AP", "stat.ML"], "comment": "Accepted for publication to the 40th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2026)", "summary": "Federated learning (FL) supports privacy-preserving, decentralized machine learning (ML) model training by keeping data on client devices. However, non-independent and identically distributed (non-IID) data across clients biases updates and degrades performance. To alleviate these issues, we propose Clust-PSI-PFL, a clustering-based personalized FL framework that uses the Population Stability Index (PSI) to quantify the level of non-IID data. We compute a weighted PSI metric, $WPSI^L$, which we show to be more informative than common non-IID metrics (Hellinger, Jensen-Shannon, and Earth Mover's distance). Using PSI features, we form distributionally homogeneous groups of clients via K-means++; the number of optimal clusters is chosen by a systematic silhouette-based procedure, typically yielding few clusters with modest overhead. Across six datasets (tabular, image, and text modalities), two partition protocols (Dirichlet with parameter $\u03b1$ and Similarity with parameter S), and multiple client sizes, Clust-PSI-PFL delivers up to 18% higher global accuracy than state-of-the-art baselines and markedly improves client fairness by a relative improvement of 37% under severe non-IID data. These results establish PSI-guided clustering as a principled, lightweight mechanism for robust PFL under label skew.", "AI": {"tldr": "\u63d0\u51faClust - PSI - PFL\u6846\u67b6\uff0c\u7528PSI\u91cf\u5316\u975eIID\u6570\u636e\uff0c\u5728\u591a\u6570\u636e\u96c6\u548c\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u6570\u636e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u4f1a\u5bfc\u81f4\u66f4\u65b0\u504f\u5dee\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faClust - PSI - PFL\u6846\u67b6\uff0c\u8ba1\u7b97\u52a0\u6743PSI\u6307\u6807$WPSI^L$\uff0c\u7528K - means++\u5bf9\u5ba2\u6237\u7aef\u5206\u7ec4\uff0c\u901a\u8fc7\u8f6e\u5ed3\u7cfb\u6570\u9009\u62e9\u6700\u4f18\u7c07\u6570\u3002", "result": "\u5728\u516d\u4e2a\u6570\u636e\u96c6\u3001\u4e24\u79cd\u5206\u533a\u534f\u8bae\u548c\u591a\u79cd\u5ba2\u6237\u7aef\u89c4\u6a21\u4e0b\uff0c\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u5168\u7403\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534718%\uff0c\u5ba2\u6237\u7aef\u516c\u5e73\u6027\u76f8\u5bf9\u63d0\u534737%\u3002", "conclusion": "PSI\u5f15\u5bfc\u805a\u7c7b\u662f\u6807\u7b7e\u504f\u659c\u4e0b\u5b9e\u73b0\u7a33\u5065\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u7684\u6709\u6548\u8f7b\u91cf\u7ea7\u673a\u5236\u3002"}}
{"id": "2512.20140", "pdf": "https://arxiv.org/pdf/2512.20140", "abs": "https://arxiv.org/abs/2512.20140", "authors": ["Xingyou Yin", "Ceyao Zhang", "Min Hu", "Kai Chen"], "title": "Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection", "categories": ["cs.AI"], "comment": "9 pages,3 figures", "summary": "Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u6807\u8bb0\u5316\u524d\u5411\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u6ce8\u5165\u566a\u58f0\u7684\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u8fdb\u884c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5e38\u4f9d\u8d56\u5fae\u8c03\u4e13\u4e1a\u6a21\u5757\uff0c\u800c\u4f7f\u7528\u5b8c\u5168\u73b0\u6210\u3001\u672a\u7ecf\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65f6\uff0c\u5176\u6027\u80fd\u5bf9\u8f93\u5165\u6570\u636e\u7684\u6587\u672c\u8868\u793a\u654f\u611f\uff0c\u5b58\u5728\u8106\u6027\u95ee\u9898\u3002", "method": "\u5728\u6807\u8bb0\u5316\u524d\u5411\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u6ce8\u5165\u566a\u58f0\uff0c\u4f5c\u4e3a\u63a8\u7406\u65f6\u589e\u5f3a\u65b9\u6cd5\uff1b\u5f15\u5165\u4e24\u4e2a\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4ee5\u6d88\u9664\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u7684\u6f5c\u5728\u504f\u5dee\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u7684\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u8bc1\u660e\u8be5\u7b56\u7565\u6709\u6548\uff0c\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u89c2\u5bdf\u5230\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u76f4\u63a5\u5229\u7528\u73b0\u6210\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u8fc8\u51fa\u4e86\u8fdb\u4e00\u6b65\u7684\u4e00\u6b65\u3002"}}
{"id": "2512.19728", "pdf": "https://arxiv.org/pdf/2512.19728", "abs": "https://arxiv.org/abs/2512.19728", "authors": ["Haocheng Lu", "Minjun Zhu", "Henry Yu"], "title": "Hard Negative Sample-Augmented DPO Post-Training for Small Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) continue to struggle with mathematical reasoning, and common post-training pipelines often reduce each generated solution to a binary outcome: correct or incorrect. This perspective is limiting in practice, as failures in chain-of-thought (CoT) reasoning are frequently structured; solutions may appear convincing while containing subtle logical, algebraic, or numerical flaws. Meanwhile, reinforcement learning from human feedback (RLHF) variants that rely on large reward models or LLM-as-a-judge signals are often expensive, difficult to scale, and unstable to iterate. We propose a lightweight and pragmatic post-training pipeline that targets such structured errors under realistic compute budgets. Starting from supervised fine-tuning (SFT) on MetaMathQA-style CoT data, we introduce a compact MathVerifier that decomposes a candidate solution into a six-dimensional error profile and aggregates it into interpretable wrongness and absurdity scores. These verifier signals serve two roles: (i) mining hard negatives that are near-correct yet structurally flawed, and (ii) defining per-sample importance weights that emphasize the most informative preference pairs. We integrate both into an offline Direct Preference Optimization (DPO) objective via a verifier-guided weighted formulation. Experiments on a 1.5B-parameter Qwen2.5 model show that verifier-guided, weighted DPO yields more targeted improvements than vanilla SFT and unweighted DPO, particularly on problems where solutions are numerically close to correct but logically inconsistent, while avoiding the overhead of training large reward models or relying on external judges.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u7ba1\u9053\uff0c\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u7684\u7ed3\u6784\u5316\u9519\u8bef\uff0c\u5728Qwen2.5\u6a21\u578b\u5b9e\u9a8c\u4e2d\u6548\u679c\u597d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u5b58\u5728\u95ee\u9898\uff0c\u73b0\u6709\u540e\u8bad\u7ec3\u7ba1\u9053\u89c6\u89d2\u6709\u9650\uff0c\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u53d8\u4f53\u6709\u6210\u672c\u9ad8\u3001\u96be\u6269\u5c55\u7b49\u95ee\u9898\u3002", "method": "\u4eceMetaMathQA\u5f0f\u601d\u7ef4\u94fe\u6570\u636e\u76d1\u7763\u5fae\u8c03\u5f00\u59cb\uff0c\u5f15\u5165MathVerifier\u5206\u89e3\u5019\u9009\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u9a8c\u8bc1\u5668\u4fe1\u53f7\u6316\u6398\u786c\u8d1f\u6837\u672c\u548c\u5b9a\u4e49\u6837\u672c\u91cd\u8981\u6027\u6743\u91cd\uff0c\u96c6\u6210\u5230\u79bb\u7ebf\u76f4\u63a5\u504f\u597d\u4f18\u5316\u76ee\u6807\u4e2d\u3002", "result": "\u57281.5B\u53c2\u6570\u7684Qwen2.5\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u9a8c\u8bc1\u5668\u5f15\u5bfc\u7684\u52a0\u6743DPO\u6bd4\u666e\u901aSFT\u548c\u672a\u52a0\u6743DPO\u6709\u66f4\u6709\u9488\u5bf9\u6027\u7684\u6539\u8fdb\u3002", "conclusion": "\u6240\u63d0\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u7ba1\u9053\u80fd\u6709\u6548\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u7684\u7ed3\u6784\u5316\u9519\u8bef\uff0c\u4e14\u907f\u514d\u8bad\u7ec3\u5927\u5956\u52b1\u6a21\u578b\u6216\u4f9d\u8d56\u5916\u90e8\u8bc4\u5224\u7684\u5f00\u9500\u3002"}}
{"id": "2512.20057", "pdf": "https://arxiv.org/pdf/2512.20057", "abs": "https://arxiv.org/abs/2512.20057", "authors": ["Dianjun Lin", "Bing Li", "Lingzhou Xue"], "title": "Structure-Preserving Nonlinear Sufficient Dimension Reduction for Tensors", "categories": ["math.ST", "stat.ME", "stat.ML"], "comment": "34 pages", "summary": "We introduce two nonlinear sufficient dimension reduction methods for regressions with tensor-valued predictors. Our goal is two-fold: the first is to preserve the tensor structure when performing dimension reduction, particularly the meaning of the tensor modes, for improved interpretation; the second is to substantially reduce the number of parameters in dimension reduction, thereby achieving model parsimony and enhancing estimation accuracy. Our two tensor dimension reduction methods echo the two commonly used tensor decomposition mechanisms: one is the Tucker decomposition, which reduces a larger tensor to a smaller one; the other is the CP-decomposition, which represents an arbitrary tensor as a sequence of rank-one tensors. We developed the Fisher consistency of our methods at the population level and established their consistency and convergence rates. Both methods are easy to implement numerically: the Tucker-form can be implemented through a sequence of least-squares steps, and the CP-form can be implemented through a sequence of singular value decompositions. We investigated the finite-sample performance of our methods and showed substantial improvement in accuracy over existing methods in simulations and two data applications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e24\u79cd\u9488\u5bf9\u5f20\u91cf\u503c\u9884\u6d4b\u53d8\u91cf\u56de\u5f52\u7684\u975e\u7ebf\u6027\u5145\u5206\u964d\u7ef4\u65b9\u6cd5\uff0c\u5206\u522b\u57fa\u4e8eTucker\u5206\u89e3\u548cCP\u5206\u89e3\uff0c\u5177\u6709\u826f\u597d\u6027\u8d28\uff0c\u5728\u6a21\u62df\u548c\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u964d\u7ef4\u65f6\u4fdd\u7559\u5f20\u91cf\u7ed3\u6784\u4ee5\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\uff0c\u51cf\u5c11\u964d\u7ef4\u53c2\u6570\u4ee5\u5b9e\u73b0\u6a21\u578b\u7b80\u6d01\u6027\u5e76\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u3002", "method": "\u4e24\u79cd\u5f20\u91cf\u964d\u7ef4\u65b9\u6cd5\u5206\u522b\u57fa\u4e8eTucker\u5206\u89e3\uff08\u5c06\u5927\u5f20\u91cf\u964d\u4e3a\u5c0f\u5f20\u91cf\uff09\u548cCP\u5206\u89e3\uff08\u5c06\u4efb\u610f\u5f20\u91cf\u8868\u793a\u4e3a\u4e00\u7cfb\u5217\u79e9\u4e00\u5f20\u91cf\uff09\u3002", "result": "\u5728\u603b\u4f53\u5c42\u9762\u8bc1\u660e\u65b9\u6cd5\u7684Fisher\u4e00\u81f4\u6027\uff0c\u5efa\u7acb\u4e00\u81f4\u6027\u548c\u6536\u655b\u901f\u7387\uff0c\u6570\u503c\u4e0a\u6613\u4e8e\u5b9e\u73b0\uff0c\u5728\u6a21\u62df\u548c\u4e24\u4e2a\u6570\u636e\u5e94\u7528\u4e2d\u7cbe\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u5927\u5e45\u63d0\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u79cd\u5f20\u91cf\u964d\u7ef4\u65b9\u6cd5\u6709\u6548\uff0c\u80fd\u6539\u5584\u56de\u5f52\u5206\u6790\u7684\u6027\u80fd\u3002"}}
{"id": "2512.19997", "pdf": "https://arxiv.org/pdf/2512.19997", "abs": "https://arxiv.org/abs/2512.19997", "authors": ["Yanjing Yang", "He Zhang", "Bohan Liu", "Jinwei Xu", "Jinghao Hu", "Liming Dong", "Zhewen Mao", "Dongxue Pan"], "title": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations", "categories": ["cs.CR", "cs.SE"], "comment": "The full version of this work consists of 15 pages and has been submitted to IEEE Transactions on Software Engineering (TSE)", "summary": "Broken Access Control (BAC) violations, which consistently rank among the top five security risks in the OWASP API Security Top 10, refer to unauthorized access attempts arising from BAC vulnerabilities, whose successful exploitation can impose significant risks on exposed application programming interfaces (APIs). In recent years, learning-based methods have demonstrated promising prospects in detecting various types of malicious activities. However, in real-network operation and maintenance scenarios, leveraging learning-based methods for BAC detection faces two critical challenges. Firstly, under the RESTful API design principles, most systems omit recording composite traffic for performance, and together with ethical and legal bans on directly testing real-world systems, this leads to a critical shortage of training data for detecting BAC violations. Secondly, common malicious behaviors such as SQL injection typically generate individual access traffic that is inherently anomalous. In contrast, BAC is usually composed of multiple correlated access requests that appear normal when examined in isolation. To tackle these problems, we introduce \\BAC, an approach for establishing a BAC violation detection model by generating and utilizing API traffic data. The \\BAC consists of an API Traffic Generator and a BAC Detector. Experimental results show that \\BAC outperforms current state-of-the-art invariant-based and learning-based methods with the $\\text{F}_1$ and MCC improving by 21.2\\% and 24.1\\%.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2512.20573", "pdf": "https://arxiv.org/pdf/2512.20573", "abs": "https://arxiv.org/abs/2512.20573", "authors": ["Rui Pan", "Zhuofu Chen", "Ravi Netravali"], "title": "Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It \"fails fast\" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and \"wins big\" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\\times$ speedup over vanilla decoding, 1.7$\\times$ over the best naive dLLM drafter, and 1.4$\\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8edLLM\u7684\u63a8\u6d4b\u89e3\u7801\u6846\u67b6FailFast\uff0c\u53ef\u65e0\u635f\u52a0\u901f\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u79cd\u6a21\u578b\u548c\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u5b9e\u73b0\u663e\u8457\u901f\u5ea6\u63d0\u5347\u5e76\u5f00\u6e90\u3002", "motivation": "Diffusion Large Language Models (dLLMs) \u5355\u72ec\u4f7f\u7528\u65f6\u5b58\u5728\u6548\u7387 - \u8d28\u91cf\u6743\u8861\u95ee\u9898\uff0c\u63a2\u7d22\u5176\u5728\u63a8\u6d4b\u89e3\u7801\u4e2d\u7684\u5e94\u7528\u4ee5\u53d1\u6325\u4f18\u52bf\u3002", "method": "\u63d0\u51faFailFast\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u63a8\u6d4b\u957f\u5ea6\uff0c\u5728\u96be\u63a8\u6d4b\u533a\u57df\u51cf\u5c11\u8ba1\u7b97\u91cf\u4ee5\u7f29\u77ed\u63a8\u6d4b\u5ef6\u8fdf\uff0c\u5728\u6613\u63a8\u6d4b\u533a\u57df\u589e\u52a0\u8349\u7a3f\u957f\u5ea6\u4ee5\u51cf\u5c11\u9a8c\u8bc1\u5ef6\u8fdf\u3002", "result": "FailFast \u5b9e\u73b0\u4e86\u5bf9\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u635f\u52a0\u901f\uff0c\u5728\u591a\u79cd\u6a21\u578b\u548c\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe 4.9 \u500d\u4e8e\u666e\u901a\u89e3\u7801\u30011.7 \u500d\u4e8e\u6700\u4f73\u7684\u7b80\u5355 dLLM \u8d77\u8349\u5668\u30011.4 \u500d\u4e8e EAGLE - 3 \u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u8868\u660e\u5408\u7406\u5229\u7528 dLLM \u7684\u5c5e\u6027\u53ef\u5728\u63a8\u6d4b\u89e3\u7801\u4e2d\u53d1\u6325\u4f18\u52bf\uff0cFailFast \u662f\u4e00\u79cd\u6709\u6548\u7684\u63d0\u5347\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u7801\u901f\u5ea6\u7684\u65b9\u6cd5\u3002"}}
{"id": "2512.20161", "pdf": "https://arxiv.org/pdf/2512.20161", "abs": "https://arxiv.org/abs/2512.20161", "authors": ["Dhivya Dharshini Kannan", "Anupam Trivedi", "Dipti Srinivasan"], "title": "A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers", "categories": ["cs.AI"], "comment": "2025 International Joint Conference on Neural Networks (IJCNN), Rome, Italy, 2025, https://ieeexplore.ieee.org/document/11227238", "summary": "Data centers account for significant global energy consumption and a carbon footprint. The recent increasing demand for edge computing and AI advancements drives the growth of data center storage capacity. Energy efficiency is a cost-effective way to combat climate change, cut energy costs, improve business competitiveness, and promote IT and environmental sustainability. Thus, optimizing data center energy management is the most important factor in the sustainability of the world. Power Usage Effectiveness (PUE) is used to represent the operational efficiency of the data center. Predicting PUE using Neural Networks provides an understanding of the effect of each feature on energy consumption, thus enabling targeted modifications of those key features to improve energy efficiency. In this paper, we have developed Bidirectional Gated Recurrent Unit (BiGRU) based PUE prediction model and compared the model performance with GRU. The data set comprises 52,560 samples with 117 features using EnergyPlus, simulating a DC in Singapore. Sets of the most relevant features are selected using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm for different parameter settings. These feature sets are used to find the optimal hyperparameter configuration and train the BiGRU model. The performance of the optimized BiGRU-based PUE prediction model is then compared with that of GRU using mean squared error (MSE), mean absolute error (MAE), and R-squared metrics.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u57fa\u4e8e\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08BiGRU\uff09\u7684PUE\u9884\u6d4b\u6a21\u578b\uff0c\u4e0eGRU\u5bf9\u6bd4\u6027\u80fd\uff0c\u7528\u80fd\u6e90\u6a21\u62df\u6570\u636e\u53ca\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\u4f18\u5316\u6a21\u578b\u3002", "motivation": "\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u5927\uff0c\u4f18\u5316\u80fd\u6e90\u7ba1\u7406\u5bf9\u5168\u7403\u53ef\u6301\u7eed\u6027\u81f3\u5173\u91cd\u8981\uff0c\u7528\u795e\u7ecf\u7f51\u7edc\u9884\u6d4bPUE\u53ef\u63d0\u9ad8\u80fd\u6548\u3002", "method": "\u5f00\u53d1BiGRU\u6a21\u578b\uff0c\u7528RFECV\u7b97\u6cd5\u9009\u7279\u5f81\uff0c\u7528\u4e0d\u540c\u53c2\u6570\u914d\u7f6e\u627e\u6700\u4f18\u8d85\u53c2\u6570\uff0c\u7528MSE\u3001MAE\u548cR\u5e73\u65b9\u6307\u6807\u5bf9\u6bd4BiGRU\u548cGRU\u6027\u80fd\u3002", "result": "\u5c06\u901a\u8fc7\u5bf9\u6bd4MSE\u3001MAE\u548cR\u5e73\u65b9\u6307\u6807\u5f97\u51faBiGRU\u548cGRU\u6a21\u578b\u6027\u80fd\u7ed3\u679c\uff0c\u4f46\u6587\u4e2d\u672a\u660e\u786e\u7ed9\u51fa\u3002", "conclusion": "\u6587\u4e2d\u672a\u660e\u786e\u7ed9\u51fa\u7ed3\u8bba\uff0c\u4f46\u9884\u671f\u53ef\u5224\u65adBiGRU\u6a21\u578b\u5728PUE\u9884\u6d4b\u4e0a\u662f\u5426\u66f4\u4f18\u4ee5\u63d0\u9ad8\u6570\u636e\u4e2d\u5fc3\u80fd\u6548\u3002"}}
{"id": "2512.19729", "pdf": "https://arxiv.org/pdf/2512.19729", "abs": "https://arxiv.org/abs/2512.19729", "authors": ["Kosuke Ukita", "Tsuyoshi Okita"], "title": "High-Performance Self-Supervised Learning by Joint Training of Flow Matching", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 6 pages", "summary": "Diffusion models can learn rich representations during data generation, showing potential for Self-Supervised Learning (SSL), but they face a trade-off between generative quality and discriminative performance. Their iterative sampling also incurs substantial computational and energy costs, hindering industrial and edge AI applications. To address these issues, we propose the Flow Matching-based Foundation Model (FlowFM), which jointly trains a representation encoder and a conditional flow matching generator. This decoupled design achieves both high-fidelity generation and effective recognition. By using flow matching to learn a simpler velocity field, FlowFM accelerates and stabilizes training, improving its efficiency for representation learning. Experiments on wearable sensor data show FlowFM reduces training time by 50.4\\% compared to a diffusion-based approach. On downstream tasks, FlowFM surpassed the state-of-the-art SSL method (SSL-Wearables) on all five datasets while achieving up to a 51.0x inference speedup and maintaining high generative quality. The implementation code is available at https://github.com/Okita-Laboratory/jointOptimizationFlowMatching.", "AI": {"tldr": "\u63d0\u51faFlowFM\u89e3\u51b3\u6269\u6563\u6a21\u578b\u5728\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u95ee\u9898\uff0c\u5728\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6570\u636e\u5b9e\u9a8c\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u9762\u4e34\u751f\u6210\u8d28\u91cf\u548c\u5224\u522b\u6027\u80fd\u6743\u8861\u95ee\u9898\uff0c\u4e14\u8fed\u4ee3\u91c7\u6837\u6210\u672c\u9ad8\uff0c\u963b\u788d\u5de5\u4e1a\u548c\u8fb9\u7f18AI\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u57fa\u7840\u6a21\u578bFlowFM\uff0c\u8054\u5408\u8bad\u7ec3\u8868\u793a\u7f16\u7801\u5668\u548c\u6761\u4ef6\u6d41\u5339\u914d\u751f\u6210\u5668\u3002", "result": "\u5728\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6570\u636e\u4e0a\uff0cFlowFM\u76f8\u6bd4\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u51cf\u5c1150.4%\u8bad\u7ec3\u65f6\u95f4\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8d85\u8d8aSSL - Wearables\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8fbe51.0x\u5e76\u4fdd\u6301\u9ad8\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "FlowFM\u901a\u8fc7\u89e3\u8026\u8bbe\u8ba1\u548c\u6d41\u5339\u914d\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u6a21\u578b\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u8868\u793a\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2512.20169", "pdf": "https://arxiv.org/pdf/2512.20169", "abs": "https://arxiv.org/abs/2512.20169", "authors": ["Junghyun Lee", "Branislav Kveton", "Sunav Choudhary", "Subhojyoti Mukherjee", "Anup Rao", "Ryan A. Rossi", "Alexa Siu"], "title": "Learning to Reason in LLMs by Expectation Maximization", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "12 pages, 3 figures, 1 table", "summary": "Large language models (LLMs) solve reasoning problems by first generating a rationale and then answering. We formalize reasoning as a latent variable model and derive an expectation-maximization (EM) objective for learning to reason. This view connects EM and modern reward-based optimization, and shows that the main challenge lies in designing a sampling distribution that generates rationales that justify correct answers. We instantiate and compare several sampling schemes: rejection sampling with a budget, self-taught reasoner (STaR), and prompt posterior sampling (PPS), which only keeps the rationalization stage of STaR. Our experiments on the ARC, MMLU, and OpenBookQA datasets with the Llama and Qwen models show that the sampling scheme can significantly affect the accuracy of learned reasoning models. Despite its simplicity, we observe that PPS outperforms the other sampling schemes.", "AI": {"tldr": "\u672c\u6587\u5c06\u63a8\u7406\u5f62\u5f0f\u5316\u4e3a\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\uff0c\u63a8\u5bfc\u5b66\u4e60\u63a8\u7406\u7684\u76ee\u6807\uff0c\u6bd4\u8f83\u591a\u79cd\u91c7\u6837\u65b9\u6848\uff0c\u53d1\u73b0PPS\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u95ee\u9898\uff0c\u63a2\u7d22\u5b66\u4e60\u63a8\u7406\u7684\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u5c06\u63a8\u7406\u5f62\u5f0f\u5316\u4e3a\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\uff0c\u63a8\u5bfc\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u76ee\u6807\uff1b\u5b9e\u4f8b\u5316\u5e76\u6bd4\u8f83\u62d2\u7edd\u91c7\u6837\u3001STaR\u548cPPS\u4e09\u79cd\u91c7\u6837\u65b9\u6848\u3002", "result": "\u5728ARC\u3001MMLU\u548cOpenBookQA\u6570\u636e\u96c6\u4e0a\uff0c\u91c7\u6837\u65b9\u6848\u663e\u8457\u5f71\u54cd\u63a8\u7406\u6a21\u578b\u51c6\u786e\u7387\uff0cPPS\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u91c7\u6837\u65b9\u6848\u3002", "conclusion": "PPS\u867d\u7b80\u5355\u4f46\u5728\u5927\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u63a8\u7406\u4e2d\u6027\u80fd\u66f4\u597d\u3002"}}
{"id": "2512.20162", "pdf": "https://arxiv.org/pdf/2512.20162", "abs": "https://arxiv.org/abs/2512.20162", "authors": ["Arghavan Bazigaran", "Hansem Sohn"], "title": "Concept Generalization in Humans and Large Language Models: Insights from the Number Game", "categories": ["cs.AI"], "comment": null, "summary": "We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.", "AI": {"tldr": "\u5bf9\u6bd4\u4eba\u7c7b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u6e38\u620f\u4e2d\u6cdb\u5316\u80fd\u529b\uff0c\u63ed\u793a\u4e8c\u8005\u5728\u63a8\u7406\u548c\u6cdb\u5316\u6570\u5b66\u6982\u5ff5\u4e0a\u7684\u5dee\u5f02", "motivation": "\u7814\u7a76\u4eba\u7c7b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6982\u5ff5\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u5f02\u540c", "method": "\u91c7\u7528\u8d1d\u53f6\u65af\u6a21\u578b\u4f5c\u4e3a\u5206\u6790\u6846\u67b6\uff0c\u7814\u7a76\u4eba\u7c7b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f52\u7eb3\u504f\u5dee\u548c\u63a8\u7406\u7b56\u7565", "result": "\u8d1d\u53f6\u65af\u6a21\u578b\u66f4\u80fd\u4f53\u73b0\u4eba\u7c7b\u884c\u4e3a\uff0c\u4eba\u7c7b\u66f4\u7075\u6d3b\uff0c\u80fd\u5c11\u6837\u672c\u6cdb\u5316\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u6570\u5b66\u89c4\u5219\u4e14\u9700\u66f4\u591a\u6837\u672c\u624d\u80fd\u6cdb\u5316", "conclusion": "\u4eba\u7c7b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u6cdb\u5316\u6570\u5b66\u6982\u5ff5\u4e0a\u5b58\u5728\u6839\u672c\u5dee\u5f02"}}
{"id": "2512.19730", "pdf": "https://arxiv.org/pdf/2512.19730", "abs": "https://arxiv.org/abs/2512.19730", "authors": ["Zhonghao Yang", "Cheng Luo", "Daojing He", "Yiming Li", "Yu Li"], "title": "ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures", "categories": ["cs.LG", "cs.CR"], "comment": "16 pages, 8 figures. This article was accepted by IEEE Transactions on Information Forensics and Security. DOI: 10.1109/TIFS.2025.3610254", "summary": "Backdoor attacks pose a significant threat to the security and reliability of deep learning models. To mitigate such attacks, one promising approach is to learn to extract features from the target model and use these features for backdoor detection. However, we discover that existing learning-based neural backdoor detection methods do not generalize well to new architectures not seen during the learning phase. In this paper, we analyze the root cause of this issue and propose a novel black-box neural backdoor detection method called ArcGen. Our method aims to obtain architecture-invariant model features, i.e., aligned features, for effective backdoor detection. Specifically, in contrast to existing methods directly using model outputs as model features, we introduce an additional alignment layer in the feature extraction function to further process these features. This reduces the direct influence of architecture information on the features. Then, we design two alignment losses to train the feature extraction function. These losses explicitly require that features from models with similar backdoor behaviors but different architectures are aligned at both the distribution and sample levels. With these techniques, our method demonstrates up to 42.5% improvements in detection performance (e.g., AUC) on unseen model architectures. This is based on a large-scale evaluation involving 16,896 models trained on diverse datasets, subjected to various backdoor attacks, and utilizing different model architectures. Our code is available at https://github.com/SeRAlab/ArcGen.", "AI": {"tldr": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684\u795e\u7ecf\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\u6cdb\u5316\u6027\u5dee\uff0c\u672c\u6587\u63d0\u51faArcGen\u65b9\u6cd5\uff0c\u5f15\u5165\u5bf9\u9f50\u5c42\u548c\u5bf9\u9f50\u635f\u5931\uff0c\u5728\u672a\u89c1\u6a21\u578b\u67b6\u6784\u4e0a\u68c0\u6d4b\u6027\u80fd\u63d0\u5347\u8fbe42.5%\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684\u795e\u7ecf\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\u5728\u5b66\u4e60\u9636\u6bb5\u672a\u89c1\u7684\u65b0\u67b6\u6784\u4e0a\u6cdb\u5316\u6027\u5dee\uff0c\u9700\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51faArcGen\u65b9\u6cd5\uff0c\u5728\u7279\u5f81\u63d0\u53d6\u51fd\u6570\u4e2d\u5f15\u5165\u989d\u5916\u5bf9\u9f50\u5c42\u5904\u7406\u7279\u5f81\uff0c\u8bbe\u8ba1\u4e24\u4e2a\u5bf9\u9f50\u635f\u5931\u8bad\u7ec3\u7279\u5f81\u63d0\u53d6\u51fd\u6570\u3002", "result": "\u5728\u6d89\u53ca16896\u4e2a\u6a21\u578b\u7684\u5927\u89c4\u6a21\u8bc4\u4f30\u4e2d\uff0c\u5728\u672a\u89c1\u6a21\u578b\u67b6\u6784\u4e0a\u68c0\u6d4b\u6027\u80fd\uff08\u5982AUC\uff09\u63d0\u5347\u8fbe42.5%\u3002", "conclusion": "ArcGen\u65b9\u6cd5\u80fd\u6709\u6548\u83b7\u53d6\u67b6\u6784\u65e0\u5173\u7684\u6a21\u578b\u7279\u5f81\uff0c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u540e\u95e8\u68c0\u6d4b\u3002"}}
{"id": "2512.20173", "pdf": "https://arxiv.org/pdf/2512.20173", "abs": "https://arxiv.org/abs/2512.20173", "authors": ["Ze Gong", "Pradeep Varakantham", "Akshat Kumar"], "title": "Offline Safe Policy Optimization From Heterogeneous Feedback", "categories": ["cs.AI"], "comment": "Accepted at AAMAS 2026 (Extended Abstract)", "summary": "Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \\textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \\textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u76f4\u63a5\u57fa\u4e8e\u504f\u597d\u548c\u5b89\u5168\u6807\u7b7e\u5b66\u4e60\u7b56\u7565\u7684\u6846\u67b6PreSa\uff0c\u907f\u514d\u663e\u5f0f\u5b66\u4e60\u5956\u60e9\u6a21\u578b\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u79bb\u7ebf\u57fa\u4e8e\u504f\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u957f\u65f6\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u4f7f\u7528\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4f1a\u56e0\u5956\u60e9\u8bef\u5dee\u7d2f\u79ef\u5bfc\u81f4\u6027\u80fd\u53d7\u635f\uff0c\u9700\u89e3\u51b3\u5b89\u5168\u4fdd\u969c\u95ee\u9898\u3002", "method": "\u5f15\u5165\u76f4\u63a5\u57fa\u4e8e\u6210\u5bf9\u504f\u597d\u548c\u5b89\u5168\u6807\u7b7e\u5b66\u4e60\u7b56\u7565\u7684\u6846\u67b6\uff0c\u63d0\u51faPreSa\u65b9\u6cd5\uff0c\u5728\u62c9\u683c\u6717\u65e5\u8303\u5f0f\u4e0b\u89e3\u51b3\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u76f4\u63a5\u5b66\u4e60\u5956\u52b1\u6700\u5927\u5316\u7684\u5b89\u5168\u7b56\u7565\u3002", "result": "\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5b66\u4e60\u5230\u9ad8\u5956\u52b1\u7684\u5b89\u5168\u7b56\u7565\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u548c\u57fa\u4e8e\u771f\u5b9e\u5956\u60e9\u7684\u79bb\u7ebf\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u548c\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u79bb\u7ebf\u57fa\u4e8e\u504f\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5b89\u5168\u6311\u6218\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u6709\u826f\u597d\u8868\u73b0\u3002"}}
{"id": "2512.19731", "pdf": "https://arxiv.org/pdf/2512.19731", "abs": "https://arxiv.org/abs/2512.19731", "authors": ["Xiangzhong Luo", "Weichen Liu"], "title": "Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted by IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "summary": "Thanks to the evolving network depth, convolutional neural networks (CNNs) have achieved remarkable success across various embedded scenarios, paving the way for ubiquitous embedded intelligence. Despite its promise, the evolving network depth comes at the cost of degraded hardware efficiency. In contrast to deep networks, shallow networks can deliver superior hardware efficiency but often suffer from inferior accuracy. To address this dilemma, we propose Double-Win NAS, a novel deep-to-shallow transformable neural architecture search (NAS) paradigm tailored for resource-constrained intelligent embedded systems. Specifically, Double-Win NAS strives to automatically explore deep networks to first win strong accuracy, which are then equivalently transformed into their shallow counterparts to further win strong hardware efficiency. In addition to search, we also propose two enhanced training techniques, including hybrid transformable training towards better training accuracy and arbitrary-resolution elastic training towards enabling natural network elasticity across arbitrary input resolutions. Extensive experimental results on two popular intelligent embedded systems (i.e., NVIDIA Jetson AGX Xavier and NVIDIA Jetson Nano) and two representative large-scale datasets (i.e., ImageNet and ImageNet-100) clearly demonstrate the superiority of Double-Win NAS over previous state-of-the-art NAS approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDouble - Win NAS\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff0c\u7ed3\u5408\u6df1\u5ea6\u548c\u6d45\u5c42\u7f51\u7edc\u4f18\u52bf\uff0c\u8fd8\u6709\u589e\u5f3a\u8bad\u7ec3\u6280\u672f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709NAS\u65b9\u6cd5\u3002", "motivation": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u786c\u4ef6\u6548\u7387\u4f4e\uff0c\u6d45\u5c42\u7f51\u7edc\u7cbe\u5ea6\u5dee\uff0c\u9700\u89e3\u51b3\u6b64\u56f0\u5883\u3002", "method": "\u63d0\u51faDouble - Win NAS\u8303\u5f0f\u81ea\u52a8\u63a2\u7d22\u6df1\u5ea6\u7f51\u7edc\u83b7\u9ad8\u7cbe\u5ea6\uff0c\u518d\u8f6c\u5316\u4e3a\u6d45\u5c42\u7f51\u7edc\u83b7\u9ad8\u786c\u4ef6\u6548\u7387\uff0c\u8fd8\u63d0\u51fa\u6df7\u5408\u53ef\u8f6c\u6362\u8bad\u7ec3\u548c\u4efb\u610f\u5206\u8fa8\u7387\u5f39\u6027\u8bad\u7ec3\u4e24\u79cd\u589e\u5f3a\u8bad\u7ec3\u6280\u672f\u3002", "result": "\u5728NVIDIA Jetson AGX Xavier\u548cNVIDIA Jetson Nano\u4e24\u79cd\u5d4c\u5165\u5f0f\u7cfb\u7edf\u53caImageNet\u548cImageNet - 100\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cDouble - Win NAS\u4f18\u4e8e\u5148\u524d\u7684NAS\u65b9\u6cd5\u3002", "conclusion": "Double - Win NAS\u80fd\u6709\u6548\u89e3\u51b3\u6df1\u5ea6\u548c\u6d45\u5c42\u7f51\u7edc\u7684\u95ee\u9898\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u6709\u4f18\u52bf\u3002"}}
{"id": "2512.20432", "pdf": "https://arxiv.org/pdf/2512.20432", "abs": "https://arxiv.org/abs/2512.20432", "authors": ["Ji Song", "Xing Wang", "Jianguo Wu", "Xiaowei Yue"], "title": "High Dimensional Data Decomposition for Anomaly Detection of Textured Images", "categories": ["cs.CV", "stat.ML"], "comment": null, "summary": "In the realm of diverse high-dimensional data, images play a significant role across various processes of manufacturing systems where efficient image anomaly detection has emerged as a core technology of utmost importance. However, when applied to textured defect images, conventional anomaly detection methods have limitations including non-negligible misidentification, low robustness, and excessive reliance on large-scale and structured datasets. This paper proposes a texture basis integrated smooth decomposition (TBSD) approach, which is targeted at efficient anomaly detection in textured images with smooth backgrounds and sparse anomalies. Mathematical formulation of quasi-periodicity and its theoretical properties are investigated for image texture estimation. TBSD method consists of two principal processes: the first process learns the texture basis functions to effectively extract quasi-periodic texture patterns; the subsequent anomaly detection process utilizes that texture basis as prior knowledge to prevent texture misidentification and capture potential anomalies with high accuracy.The proposed method surpasses benchmarks with less misidentification, smaller training dataset requirement, and superior anomaly detection performance on both simulation and real-world datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTBSD\u65b9\u6cd5\u7528\u4e8e\u7eb9\u7406\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u7eb9\u7406\u7f3a\u9677\u56fe\u50cf\u65f6\u5b58\u5728\u8bef\u8bc6\u522b\u3001\u9c81\u68d2\u6027\u4f4e\u548c\u4f9d\u8d56\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u96c6\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7eb9\u7406\u57fa\u96c6\u6210\u5e73\u6ed1\u5206\u89e3\uff08TBSD\uff09\u65b9\u6cd5\uff0c\u5305\u62ec\u5b66\u4e60\u7eb9\u7406\u57fa\u51fd\u6570\u63d0\u53d6\u51c6\u5468\u671f\u7eb9\u7406\u6a21\u5f0f\u548c\u5229\u7528\u7eb9\u7406\u57fa\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u4e24\u4e2a\u4e3b\u8981\u8fc7\u7a0b\uff0c\u5e76\u7814\u7a76\u51c6\u5468\u671f\u6027\u7684\u6570\u5b66\u516c\u5f0f\u53ca\u5176\u7406\u8bba\u6027\u8d28\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bef\u8bc6\u522b\u66f4\u5c11\u3001\u6240\u9700\u8bad\u7ec3\u6570\u636e\u96c6\u66f4\u5c0f\uff0c\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "TBSD\u65b9\u6cd5\u5728\u7eb9\u7406\u56fe\u50cf\u5f02\u5e38\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2512.20396", "pdf": "https://arxiv.org/pdf/2512.20396", "abs": "https://arxiv.org/abs/2512.20396", "authors": ["Narges Khakpour", "Nicolas Berthier"], "title": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs", "categories": ["cs.CR", "cs.FL", "cs.PL", "cs.SE"], "comment": null, "summary": "We introduce a scalable, modular, and sound approach for automatically constructing formal security specifications for Java bytecode programs in the form of method summaries. A summary provides an abstract representation of a method's security behavior, consisting of the conditions under which the method can be securely invoked, together with specifications of information flows and aliasing updates. Such summaries can be consumed by static code analysis tools and also help developers understand the behavior of code segments, such as libraries, in order to evaluate their security implications when reused in applications. Our approach is implemented in a tool called Symmaries, which automates the generation of security summaries. We applied Symmaries to Java API libraries to extract their security specifications and to large real-world applications to evaluate its scalability. Our results show that the tool successfully scales to analyze applications with hundreds of thousands of lines of code, and that Symmaries achieves a promising precision depending on the heap model used. We prove the soundness of our approach in terms of guaranteeing termination-insensitive non-interference.", "AI": {"tldr": "\u4ecb\u7ecd\u4e00\u79cd\u4e3aJava\u5b57\u8282\u7801\u7a0b\u5e8f\u81ea\u52a8\u6784\u5efa\u5b89\u5168\u89c4\u8303\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5de5\u5177Symmaries\u5e76\u9a8c\u8bc1\u5176\u53ef\u6269\u5c55\u6027\u548c\u7cbe\u5ea6\u3002", "motivation": "\u4e3aJava\u5b57\u8282\u7801\u7a0b\u5e8f\u81ea\u52a8\u6784\u5efa\u5f62\u5f0f\u5316\u5b89\u5168\u89c4\u8303\uff0c\u5e2e\u52a9\u9759\u6001\u4ee3\u7801\u5206\u6790\u5de5\u5177\u548c\u5f00\u53d1\u8005\u7406\u89e3\u4ee3\u7801\u5b89\u5168\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6a21\u5757\u5316\u4e14\u5408\u7406\u7684\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u5de5\u5177Symmaries\u81ea\u52a8\u751f\u6210\u5b89\u5168\u6458\u8981\u3002", "result": "Symmaries\u53ef\u6269\u5c55\u5206\u6790\u6570\u5341\u4e07\u884c\u4ee3\u7801\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u6839\u636e\u5806\u6a21\u578b\u8fbe\u5230\u4e00\u5b9a\u7cbe\u5ea6\u3002", "conclusion": "\u8bc1\u660e\u4e86\u65b9\u6cd5\u5728\u4fdd\u8bc1\u7ec8\u6b62\u4e0d\u654f\u611f\u975e\u5e72\u6270\u65b9\u9762\u7684\u5408\u7406\u6027\u3002"}}
{"id": "2512.20206", "pdf": "https://arxiv.org/pdf/2512.20206", "abs": "https://arxiv.org/abs/2512.20206", "authors": ["Zhe Sun", "Kunlun Wu", "Chuanjian Fu", "Zeming Song", "Langyong Shi", "Zihe Xue", "Bohan Jing", "Ying Yang", "Xiaomeng Gao", "Aijia Li", "Tianyu Guo", "Huiying Li", "Xueyuan Yang", "Rongkai Liu", "Xinyi He", "Yuxi Wang", "Yue Li", "Mingyuan Liu", "Yujie Lu", "Hongzhao Xie", "Shiyun Zhao", "Bo Dai", "Wei Wang", "Tao Yuan", "Song-Chun Zhu", "Yujia Peng", "Zhenliang Zhang"], "title": "TongSIM: A General Platform for Simulating Intelligent Machines", "categories": ["cs.AI"], "comment": null, "summary": "As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.", "AI": {"tldr": "\u968f\u7740AI\u53d1\u5c55\uff0c\u7814\u7a76\u8f6c\u5411\u591a\u6a21\u6001\u548c\u5177\u8eabAI\uff0c\u4f46\u73b0\u6709\u6a21\u62df\u5e73\u53f0\u9488\u5bf9\u6027\u5f3a\uff0c\u672c\u6587\u63a8\u51fa\u901a\u7528\u5e73\u53f0TongSIM\uff0c\u53ef\u652f\u6301\u591a\u6837\u573a\u666f\u4e0e\u8bc4\u4f30\uff0c\u6709\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u62df\u5e73\u53f0\u9488\u5bf9\u6027\u5f3a\uff0c\u7f3a\u4e4f\u80fd\u652f\u6301\u4ece\u4f4e\u5c42\u6b21\u5177\u8eab\u5bfc\u822a\u5230\u9ad8\u5c42\u6b21\u590d\u5408\u6d3b\u52a8\u7684\u901a\u7528\u8bad\u7ec3\u73af\u5883\u3002", "method": "\u63a8\u51fa\u9ad8\u4fdd\u771f\u3001\u901a\u7528\u7684\u5e73\u53f0TongSIM\uff0c\u63d0\u4f9b\u591a\u6837\u5ba4\u5185\u5916\u573a\u666f\uff0c\u6709\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u51c6\u3002", "result": "TongSIM\u80fd\u7cbe\u786e\u8bc4\u4f30\u667a\u80fd\u4f53\u591a\u79cd\u80fd\u529b\uff0c\u6709\u5b9a\u5236\u573a\u666f\u7b49\u529f\u80fd\uff0c\u63d0\u4f9b\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "TongSIM\u4f5c\u4e3a\u7edf\u4e00\u5e73\u53f0\uff0c\u53ef\u52a0\u901f\u901a\u7528\u5177\u8eab\u667a\u80fd\u7684\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u53d1\u5c55\u3002"}}
{"id": "2512.19732", "pdf": "https://arxiv.org/pdf/2512.19732", "abs": "https://arxiv.org/abs/2512.19732", "authors": ["Gaurav Kumar Sharma"], "title": "Leakage-Aware Bandgap Prediction on the JARVIS-DFT Dataset: A Phase-Wise Feature Analysis", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": "21 pages, 11 figures", "summary": "In this study, we perform a systematic analysis of the JARVIS-DFT bandgap dataset and identify and remove descriptors that may inadvertently encode band-structure information, such as effective masses. This process yields a curated, leakage-controlled subset of 2280 materials. Using this dataset, a three-phase modeling framework is implemented that incrementally incorporates basic physical descriptors, engineered features, and compositional attributes. The results show that tree-based models achieve R2 values of approximately 0.88 to 0.90 across all phases, indicating that expanding the descriptor space does not substantially improve predictive accuracy when leakage is controlled. SHAP analysis consistently identifies the dielectric tensor components as the dominant contributors. This work provides a curated dataset and baseline performance metrics for future leakage-aware bandgap prediction studies.", "AI": {"tldr": "\u5bf9JARVIS - DFT\u5e26\u9699\u6570\u636e\u96c6\u7cfb\u7edf\u5206\u6790\uff0c\u53bb\u9664\u542b\u80fd\u5e26\u7ed3\u6784\u4fe1\u606f\u63cf\u8ff0\u7b26\u5f972280\u79cd\u6750\u6599\u5b50\u96c6\uff0c\u7528\u4e09\u76f8\u5efa\u6a21\u6846\u67b6\u5efa\u6a21\uff0c\u6811\u6a21\u578bR2\u7ea60.88 - 0.90\uff0cSHAP\u5206\u6790\u6307\u51fa\u4ecb\u7535\u5f20\u91cf\u5206\u91cf\u4e3a\u4e3b\u8981\u8d21\u732e\u8005\uff0c\u4e3a\u540e\u7eed\u5e26\u9699\u9884\u6d4b\u7814\u7a76\u63d0\u4f9b\u6570\u636e\u548c\u6307\u6807\u3002", "motivation": "\u4e3a\u672a\u6765\u5e26\u9699\u9884\u6d4b\u7814\u7a76\u63d0\u4f9b\u53d7\u6cc4\u6f0f\u63a7\u5236\u7684\u6570\u636e\u96c6\u4e0e\u57fa\u7ebf\u6027\u80fd\u6307\u6807\u3002", "method": "\u5bf9\u6570\u636e\u96c6\u7cfb\u7edf\u5206\u6790\u53bb\u9664\u7279\u5b9a\u63cf\u8ff0\u7b26\uff0c\u5f97\u5230\u53d7\u6cc4\u6f0f\u63a7\u5236\u7684\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e09\u76f8\u5efa\u6a21\u6846\u67b6\u9010\u6b65\u7eb3\u5165\u57fa\u672c\u7269\u7406\u63cf\u8ff0\u7b26\u3001\u5de5\u7a0b\u7279\u5f81\u548c\u6210\u5206\u5c5e\u6027\u3002", "result": "\u6811\u6a21\u578b\u5728\u5404\u9636\u6bb5R2\u7ea6\u4e3a0.88 - 0.90\uff0cSHAP\u5206\u6790\u8868\u660e\u4ecb\u7535\u5f20\u91cf\u5206\u91cf\u662f\u4e3b\u8981\u8d21\u732e\u8005\u3002", "conclusion": "\u5728\u63a7\u5236\u6cc4\u6f0f\u65f6\uff0c\u6269\u5927\u63cf\u8ff0\u7b26\u7a7a\u95f4\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u63d0\u5347\u4e0d\u663e\u8457\uff0c\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u7528\u7684\u6570\u636e\u96c6\u548c\u6307\u6807\u3002"}}
{"id": "2512.20523", "pdf": "https://arxiv.org/pdf/2512.20523", "abs": "https://arxiv.org/abs/2512.20523", "authors": ["Masahiro Kato"], "title": "ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification", "categories": ["econ.EM", "cs.LG", "math.ST", "stat.ME", "stat.ML"], "comment": null, "summary": "This study proposes Riesz representer estimation methods based on score matching. The Riesz representer is a key component in debiased machine learning for constructing $\\sqrt{n}$-consistent and efficient estimators in causal inference and structural parameter estimation. To estimate the Riesz representer, direct approaches have garnered attention, such as Riesz regression and the covariate balancing propensity score. These approaches can also be interpreted as variants of direct density ratio estimation (DRE) in several applications such as average treatment effect estimation. In DRE, it is well known that flexible models can easily overfit the observed data due to the estimand and the form of the loss function. To address this issue, recent work has proposed modeling the density ratio as a product of multiple intermediate density ratios and estimating it using score-matching techniques, which are often used in the diffusion model literature. We extend score-matching-based DRE methods to Riesz representer estimation. Our proposed method not only mitigates overfitting but also provides insights for causal inference by bridging marginal effects and average policy effects through time score functions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f97\u5206\u5339\u914d\u7684Riesz\u8868\u793a\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7f13\u89e3\u8fc7\u62df\u5408\uff0c\u4e3a\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "\u76f4\u63a5\u4f30\u8ba1Riesz\u8868\u793a\u7684\u65b9\u6cd5\u5728DRE\u4e2d\u6613\u8fc7\u62df\u5408\uff0c\u9700\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u5c06\u57fa\u4e8e\u5f97\u5206\u5339\u914d\u7684DRE\u65b9\u6cd5\u6269\u5c55\u5230Riesz\u8868\u793a\u4f30\u8ba1\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u7f13\u89e3\u8fc7\u62df\u5408\uff0c\u901a\u8fc7\u65f6\u95f4\u5f97\u5206\u51fd\u6570\u8fde\u63a5\u8fb9\u9645\u6548\u5e94\u548c\u5e73\u5747\u653f\u7b56\u6548\u5e94\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\uff0c\u4e3a\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u4fe1\u606f\u3002"}}
{"id": "2512.20402", "pdf": "https://arxiv.org/pdf/2512.20402", "abs": "https://arxiv.org/abs/2512.20402", "authors": ["Niccol\u00f2 Scatena", "Pericle Perazzo", "Giovanni Nardini"], "title": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "This paper proposes iblock, a comprehensive C++ library for Bitcoin simulation, designed for OMNeT++. iblock offers superior efficiency and scalability with respect to state-of-the-art simulators, which are typically written in high-level languages. Moreover, the possible integration with other OMNeT++ libraries allows highly detailed simulations. We measure iblock's performance against a state-of-the-art blockchain simulator, proving that it is more efficient at the same level of simulation detail. We also validate iblock by using it to simulate different scenarios such as the normal Bitcoin operation and the selfish mine attack, showing that simulation results are coherent with theoretical expectations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8eOMNeT++\u7684\u6bd4\u7279\u5e01\u6a21\u62dfC++\u5e93iblock\uff0c\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u4f73\uff0c\u7ecf\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u80fd\u8fdb\u884c\u9ad8\u8be6\u7ec6\u5ea6\u6a21\u62df\u7684\u6bd4\u7279\u5e01\u6a21\u62df\u5e93\u3002", "method": "\u63d0\u51faiblock\u5e93\uff0c\u4e0e\u73b0\u6709\u533a\u5757\u94fe\u6a21\u62df\u5668\u5bf9\u6bd4\u6027\u80fd\uff0c\u5e76\u6a21\u62df\u4e0d\u540c\u573a\u666f\u9a8c\u8bc1\u3002", "result": "iblock\u5728\u76f8\u540c\u6a21\u62df\u7ec6\u8282\u6c34\u5e73\u4e0b\u66f4\u9ad8\u6548\uff0c\u6a21\u62df\u7ed3\u679c\u7b26\u5408\u7406\u8bba\u9884\u671f\u3002", "conclusion": "iblock\u662f\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u6bd4\u7279\u5e01\u6a21\u62df\u5e93\u3002"}}
{"id": "2512.20237", "pdf": "https://arxiv.org/pdf/2512.20237", "abs": "https://arxiv.org/abs/2512.20237", "authors": ["Xingbo Du", "Loka Li", "Duzhen Zhang", "Le Song"], "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents", "categories": ["cs.AI"], "comment": "16 pages, 6 figures", "summary": "Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.", "AI": {"tldr": "\u6587\u7ae0\u6784\u5efa\u4e86\u540d\u4e3aMemR\u00b3\u7684\u8bb0\u5fc6\u68c0\u7d22\u4ee3\u7406\u7cfb\u7edf\uff0c\u80fd\u901a\u8fc7\u95ed\u73af\u63a7\u5236\u5b9e\u73b0\u81ea\u4e3b\u51b3\u7b56\uff0c\u5728LoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u8bb0\u5fc6\u7cfb\u7edf\u591a\u6ce8\u91cd\u538b\u7f29\u548c\u5b58\u50a8\uff0c\u5bf9\u8bb0\u5fc6\u68c0\u7d22\u7684\u663e\u5f0f\u95ed\u73af\u63a7\u5236\u91cd\u89c6\u4e0d\u8db3\u3002", "method": "\u6784\u5efaMemR\u00b3\u7cfb\u7edf\uff0c\u5305\u542b\u9009\u62e9\u68c0\u7d22\u3001\u53cd\u601d\u548c\u56de\u7b54\u64cd\u4f5c\u7684\u8def\u7531\u5668\u53ca\u8ffd\u8e2a\u8bc1\u636e\u6536\u96c6\u8fc7\u7a0b\u7684\u5168\u5c40\u8bc1\u636e\u5dee\u8ddd\u8ffd\u8e2a\u5668\u3002", "result": "\u5728LoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMemR\u00b3\u5728LLM\u8bc4\u5ba1\u5206\u6570\u4e0a\u8d85\u8fc7\u5f3a\u57fa\u7ebf\uff0c\u4f7f\u7528GPT - 4.1 - mini\u540e\u7aef\uff0c\u6574\u4f53\u63d0\u5347RAG 7.29%\u3001Zep 1.94%\u3002", "conclusion": "MemR\u00b3\u4e3a\u73b0\u6709\u8bb0\u5fc6\u5b58\u50a8\u63d0\u4f9b\u4e86\u5373\u63d2\u5373\u7528\u7684\u63a7\u5236\u5668\u3002"}}
{"id": "2512.19734", "pdf": "https://arxiv.org/pdf/2512.19734", "abs": "https://arxiv.org/abs/2512.19734", "authors": ["Cl\u00e9ment Cornet", "Romaric Besan\u00e7on", "Herv\u00e9 Le Borgne"], "title": "The Deleuzian Representation Hypothesis", "categories": ["cs.LG"], "comment": null, "summary": "We propose an alternative to sparse autoencoders (SAEs) as a simple and effective unsupervised method for extracting interpretable concepts from neural networks. The core idea is to cluster differences in activations, which we formally justify within a discriminant analysis framework. To enhance the diversity of extracted concepts, we refine the approach by weighting the clustering using the skewness of activations. The method aligns with Deleuze's modern view of concepts as differences. We evaluate the approach across five models and three modalities (vision, language, and audio), measuring concept quality, diversity, and consistency. Our results show that the proposed method achieves concept quality surpassing prior unsupervised SAE variants while approaching supervised baselines, and that the extracted concepts enable steering of a model's inner representations, demonstrating their causal influence on downstream behavior.", "AI": {"tldr": "\u63d0\u51fa\u66ff\u4ee3\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u63d0\u53d6\u795e\u7ecf\u7f51\u7edc\u4e2d\u53ef\u89e3\u91ca\u6982\u5ff5\uff0c\u7ecf\u591a\u6a21\u578b\u591a\u6a21\u6001\u8bc4\u4f30\u6548\u679c\u597d\u3002", "motivation": "\u5bfb\u627e\u7b80\u5355\u6709\u6548\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u4ece\u795e\u7ecf\u7f51\u7edc\u4e2d\u63d0\u53d6\u53ef\u89e3\u91ca\u6982\u5ff5\u3002", "method": "\u5728\u5224\u522b\u5206\u6790\u6846\u67b6\u4e0b\u5bf9\u6fc0\u6d3b\u5dee\u5f02\u8fdb\u884c\u805a\u7c7b\uff0c\u7528\u6fc0\u6d3b\u504f\u5ea6\u52a0\u6743\u805a\u7c7b\u4ee5\u589e\u5f3a\u6982\u5ff5\u591a\u6837\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u6982\u5ff5\u8d28\u91cf\u8d85\u8d8a\u5148\u524d\u65e0\u76d1\u7763\u7a00\u758f\u81ea\u7f16\u7801\u5668\u53d8\u4f53\uff0c\u63a5\u8fd1\u76d1\u7763\u57fa\u7ebf\uff0c\u63d0\u53d6\u6982\u5ff5\u80fd\u63a7\u5236\u6a21\u578b\u5185\u90e8\u8868\u793a\u3002", "conclusion": "\u6240\u63d0\u51fa\u65b9\u6cd5\u662f\u6709\u6548\u63d0\u53d6\u53ef\u89e3\u91ca\u6982\u5ff5\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u3002"}}
{"id": "2512.20552", "pdf": "https://arxiv.org/pdf/2512.20552", "abs": "https://arxiv.org/abs/2512.20552", "authors": ["Sung En Chiang", "Zhaolu Liu", "Robert L. Peach", "Mauricio Barahona"], "title": "Information-theoretic signatures of causality in Bayesian networks and hypergraphs", "categories": ["cs.IT", "stat.ML"], "comment": "20 pages, 3 figures", "summary": "Analyzing causality in multivariate systems involves establishing how information is generated, distributed and combined, and thus requires tools that capture interactions beyond pairwise relations. Higher-order information theory provides such tools. In particular, Partial Information Decomposition (PID) allows the decomposition of the information that a set of sources provides about a target into redundant, unique, and synergistic components. Yet the mathematical connection between such higher-order information-theoretic measures and causal structure remains undeveloped. Here we establish the first theoretical correspondence between PID components and causal structure in both Bayesian networks and hypergraphs. We first show that in Bayesian networks unique information precisely characterizes direct causal neighbors, while synergy identifies collider relationships. This establishes a localist causal discovery paradigm in which the structure surrounding each variable can be recovered from its immediate informational footprint, eliminating the need for global search over graph space. Extending these results to higher-order systems, we prove that PID signatures in Bayesian hypergraphs differentiate parents, children, co-heads, and co-tails, revealing a higher-order collider effect unique to multi-tail hyperedges. We also present procedures by which our results can be used to characterize systematically the causal structure of Bayesian networks and hypergraphs. Our results position PID as a rigorous, model-agnostic foundation for inferring both pairwise and higher-order causal structure, and introduce a fundamentally local information-theoretic viewpoint on causal discovery.", "AI": {"tldr": "\u6587\u7ae0\u5efa\u7acb\u4e86Partial Information Decomposition (PID) \u7ec4\u4ef6\u4e0e\u8d1d\u53f6\u65af\u7f51\u7edc\u548c\u8d85\u56fe\u4e2d\u56e0\u679c\u7ed3\u6784\u7684\u7406\u8bba\u5bf9\u5e94\u5173\u7cfb\uff0c\u4e3a\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u73b0\u6709\u9ad8\u9636\u4fe1\u606f\u8bba\u6d4b\u5ea6\u4e0e\u56e0\u679c\u7ed3\u6784\u7684\u6570\u5b66\u8054\u7cfb\u672a\u5145\u5206\u53d1\u5c55\uff0c\u9700\u5efa\u7acb\u5bf9\u5e94\u5173\u7cfb\u3002", "method": "\u5148\u5728\u8d1d\u53f6\u65af\u7f51\u7edc\u4e2d\u5206\u6790PID\u7ec4\u4ef6\u4e0e\u56e0\u679c\u7ed3\u6784\u5173\u7cfb\uff0c\u540e\u6269\u5c55\u5230\u9ad8\u9636\u7cfb\u7edf\uff0c\u8fd8\u7ed9\u51fa\u8868\u5f81\u56e0\u679c\u7ed3\u6784\u7684\u7a0b\u5e8f\u3002", "result": "\u5728\u8d1d\u53f6\u65af\u7f51\u7edc\u4e2d\uff0c\u552f\u4e00\u4fe1\u606f\u8868\u5f81\u76f4\u63a5\u56e0\u679c\u90bb\u5c45\uff0c\u534f\u540c\u8bc6\u522b\u5bf9\u649e\u5173\u7cfb\uff1b\u5728\u8d1d\u53f6\u65af\u8d85\u56fe\u4e2d\uff0cPID\u7279\u5f81\u53ef\u533a\u5206\u4e0d\u540c\u8282\u70b9\u5173\u7cfb\uff0c\u63ed\u793a\u9ad8\u9636\u5bf9\u649e\u6548\u5e94\u3002", "conclusion": "PID\u53ef\u4f5c\u4e3a\u63a8\u65ad\u56e0\u679c\u7ed3\u6784\u7684\u4e25\u683c\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u57fa\u7840\uff0c\u5f15\u5165\u4e86\u5c40\u90e8\u4fe1\u606f\u8bba\u7684\u56e0\u679c\u53d1\u73b0\u89c2\u70b9\u3002"}}
{"id": "2512.20275", "pdf": "https://arxiv.org/pdf/2512.20275", "abs": "https://arxiv.org/abs/2512.20275", "authors": ["Divya Vijay", "Vignesh Ethiraj"], "title": "Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks", "categories": ["cs.AI", "cs.NI"], "comment": "15 pages, 3 figures, 3 tables", "summary": "As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.", "AI": {"tldr": "\u968f\u7740\u7f51\u7edc\u54115G\u72ec\u7acb\u548c6G\u6f14\u8fdb\uff0c\u4f20\u7edf\u81ea\u52a8\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u53d7\u9650\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u98ce\u9669\uff0c\u672c\u6587\u63d0\u51faG - SPEC\u6846\u67b6\uff0c\u8bd5\u9a8c\u663e\u793a\u5176\u6548\u679c\u826f\u597d\u4e14\u6709\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u7f51\u7edc\u54115G\u72ec\u7acb\u548c6G\u6f14\u8fdb\u65f6\uff0c\u4f20\u7edf\u65b9\u6cd5\u6709\u5c40\u9650\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5165\u968f\u673a\u98ce\u9669\uff0c\u9700\u8981\u65b0\u6846\u67b6\u89e3\u51b3\u95ee\u9898\u3002", "method": "\u63d0\u51faGraph - Symbolic Policy Enforcement and Control (G - SPEC)\u6846\u67b6\uff0c\u4f9d\u8d56\u6cbb\u7406\u4e09\u5143\u7ec4\uff08TSLAM - 4B\u3001NKG\u548cSHACL\u7ea6\u675f\uff09\u3002", "result": "\u5728\u6a21\u62df450\u8282\u70b95G\u6838\u5fc3\u7f51\u8bc4\u4f30\uff0c\u96f6\u5b89\u5168\u8fdd\u89c4\uff0c\u4fee\u590d\u6210\u529f\u738794.1%\uff0c\u8fdc\u8d8582.4%\u57fa\u7ebf\uff1b\u6d88\u878d\u5206\u6790\u663e\u793aNKG\u9a8c\u8bc1\u8d21\u732e68%\u5b89\u5168\u589e\u76ca\uff1b\u53ef\u6269\u5c55\u6027\u6d4b\u8bd5\u663e\u793a\u9a8c\u8bc1\u5ef6\u8fdf\u4e0e\u5b50\u56fe\u5927\u5c0f\u5173\u7cfb\u53ca\u5c11\u91cf\u5904\u7406\u5f00\u9500\u3002", "conclusion": "G - SPEC\u5728\u670d\u52a1\u7ba1\u7406\u64cd\u4f5c\u5c42\uff08SMO\uff09\u53ef\u884c\u3002"}}
